import{S as os,i as ss,s as ls,e as s,k as f,w as h,t as n,M as rs,c as l,d as t,m as d,a as i,x as m,h as p,b as u,N as as,G as a,g as r,y as c,L as is,q as _,o as g,B as v,v as ns}from"../../chunks/vendor-hf-doc-builder.js";import{I as _e}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as O}from"../../chunks/CodeBlock-hf-doc-builder.js";function ps(lo){let w,Ze,y,I,Ie,L,Xt,je,Zt,et,ge,ea,tt,$,j,ze,H,ta,Ue,aa,at,ve,oa,ot,V,st,z,sa,Y,la,ra,lt,R,rt,b,U,Ne,J,ia,De,na,it,we,pa,nt,K,pt,Q,ua,W,fa,ut,ye,da,ft,X,ro,dt,E,N,Se,Z,ha,Ce,ma,ht,$e,ca,mt,ee,ct,te,_a,ae,ga,_t,be,va,gt,oe,io,vt,k,D,Fe,se,wa,Be,ya,wt,Ee,$a,yt,S,ke,ba,Te,Ea,ka,le,xa,Ge,Pa,Aa,$t,x,Me,qa,Ia,re,ja,za,bt,xe,Ua,Et,P,C,Oe,ie,Na,Le,Da,kt,Pe,Sa,xt,ne,Pt,Ae,Ca,At,pe,qt,F,Fa,ue,He,Ba,Ta,It,A,B,Ve,fe,Ga,Ye,Ma,jt,T,Oa,de,Re,La,Ha,zt,he,Ut,q,Je,Va,Ya,Ke,Ra,Ja,Nt,qe,Ka,Dt,me,St,G,Qa,Qe,Wa,Xa,Ct,M,Za,ce,eo,to,Ft;return L=new _e({}),H=new _e({}),V=new O({props:{code:"pip install diffusers[training] accelerate datasets",highlighted:"pip install diffusers[training] accelerate datasets"}}),R=new O({props:{code:"accelerate config",highlighted:"accelerate config"}}),J=new _e({}),K=new O({props:{code:`accelerate launch train_unconditional.py \\
  --dataset_name="huggan/flowers-102-categories" \\
  --resolution=64 \\
  --output_dir="ddpm-ema-flowers-64" \\
  --train_batch_size=16 \\
  --num_epochs=100 \\
  --gradient_accumulation_steps=1 \\
  --learning_rate=1e-4 \\
  --lr_warmup_steps=500 \\
  --mixed_precision=no \\
  --push_to_hub`,highlighted:`accelerate launch train_unconditional.py \\
  --dataset_name=<span class="hljs-string">&quot;huggan/flowers-102-categories&quot;</span> \\
  --resolution=64 \\
  --output_dir=<span class="hljs-string">&quot;ddpm-ema-flowers-64&quot;</span> \\
  --train_batch_size=16 \\
  --num_epochs=100 \\
  --gradient_accumulation_steps=1 \\
  --learning_rate=1e-4 \\
  --lr_warmup_steps=500 \\
  --mixed_precision=no \\
  --push_to_hub`}}),Z=new _e({}),ee=new O({props:{code:`accelerate launch train_unconditional.py \\
  --dataset_name="huggan/pokemon" \\
  --resolution=64 \\
  --output_dir="ddpm-ema-pokemon-64" \\
  --train_batch_size=16 \\
  --num_epochs=100 \\
  --gradient_accumulation_steps=1 \\
  --learning_rate=1e-4 \\
  --lr_warmup_steps=500 \\
  --mixed_precision=no \\
  --push_to_hub`,highlighted:`accelerate launch train_unconditional.py \\
  --dataset_name=<span class="hljs-string">&quot;huggan/pokemon&quot;</span> \\
  --resolution=64 \\
  --output_dir=<span class="hljs-string">&quot;ddpm-ema-pokemon-64&quot;</span> \\
  --train_batch_size=16 \\
  --num_epochs=100 \\
  --gradient_accumulation_steps=1 \\
  --learning_rate=1e-4 \\
  --lr_warmup_steps=500 \\
  --mixed_precision=no \\
  --push_to_hub`}}),se=new _e({}),ie=new _e({}),ne=new O({props:{code:`data_dir/xxx.png
data_dir/xxy.png
data_dir/[...]/xxz.png`,highlighted:`data_dir/xxx.png
data_dir/xxy.png
data_dir/[...]/xxz.png`}}),pe=new O({props:{code:`accelerate launch train_unconditional.py \\
    --train_data_dir <path-to-train-directory> \\
    <other-arguments>`,highlighted:`accelerate launch train_unconditional.py \\
    --train_data_dir &lt;path-to-train-directory&gt; \\
    &lt;other-arguments&gt;`}}),fe=new _e({}),he=new O({props:{code:`from datasets import load_dataset

# example 1: local folder
dataset = load_dataset("imagefolder", data_dir="path_to_your_folder")

# example 2: local files (suppoted formats are tar, gzip, zip, xz, rar, zstd)
dataset = load_dataset("imagefolder", data_files="path_to_zip_file")

# example 3: remote files (supported formats are tar, gzip, zip, xz, rar, zstd)
dataset = load_dataset(
    "imagefolder",
    data_files="https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip",
)

# example 4: providing several splits
dataset = load_dataset(
    "imagefolder", data_files={"train": ["path/to/file1", "path/to/file2"], "test": ["path/to/file3", "path/to/file4"]}
)`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-comment"># example 1: local folder</span>
dataset = load_dataset(<span class="hljs-string">&quot;imagefolder&quot;</span>, data_dir=<span class="hljs-string">&quot;path_to_your_folder&quot;</span>)

<span class="hljs-comment"># example 2: local files (suppoted formats are tar, gzip, zip, xz, rar, zstd)</span>
dataset = load_dataset(<span class="hljs-string">&quot;imagefolder&quot;</span>, data_files=<span class="hljs-string">&quot;path_to_zip_file&quot;</span>)

<span class="hljs-comment"># example 3: remote files (supported formats are tar, gzip, zip, xz, rar, zstd)</span>
dataset = load_dataset(
    <span class="hljs-string">&quot;imagefolder&quot;</span>,
    data_files=<span class="hljs-string">&quot;https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip&quot;</span>,
)

<span class="hljs-comment"># example 4: providing several splits</span>
dataset = load_dataset(
    <span class="hljs-string">&quot;imagefolder&quot;</span>, data_files={<span class="hljs-string">&quot;train&quot;</span>: [<span class="hljs-string">&quot;path/to/file1&quot;</span>, <span class="hljs-string">&quot;path/to/file2&quot;</span>], <span class="hljs-string">&quot;test&quot;</span>: [<span class="hljs-string">&quot;path/to/file3&quot;</span>, <span class="hljs-string">&quot;path/to/file4&quot;</span>]}
)`}}),me=new O({props:{code:`# assuming you have ran the huggingface-cli login command in a terminal
dataset.push_to_hub("name_of_your_dataset")

# if you want to push to a private repo, simply pass private=True:
dataset.push_to_hub("name_of_your_dataset", private=True)`,highlighted:`<span class="hljs-comment"># assuming you have ran the huggingface-cli login command in a terminal</span>
dataset.push_to_hub(<span class="hljs-string">&quot;name_of_your_dataset&quot;</span>)

<span class="hljs-comment"># if you want to push to a private repo, simply pass private=True:</span>
dataset.push_to_hub(<span class="hljs-string">&quot;name_of_your_dataset&quot;</span>, private=<span class="hljs-literal">True</span>)`}}),{c(){w=s("meta"),Ze=f(),y=s("h1"),I=s("a"),Ie=s("span"),h(L.$$.fragment),Xt=f(),je=s("span"),Zt=n("Unconditional Image-Generation"),et=f(),ge=s("p"),ea=n(`In this section, we explain how one can train an unconditional image generation diffusion
model. \u201CUnconditional\u201D because the model is not conditioned on any context to generate an image - once trained the model will simply generate images that resemble its training data
distribution.`),tt=f(),$=s("h2"),j=s("a"),ze=s("span"),h(H.$$.fragment),ta=f(),Ue=s("span"),aa=n("Installing the dependencies"),at=f(),ve=s("p"),oa=n("Before running the scipts, make sure to install the library\u2019s training dependencies:"),ot=f(),h(V.$$.fragment),st=f(),z=s("p"),sa=n("And initialize an "),Y=s("a"),la=n("\u{1F917}Accelerate"),ra=n(" environment with:"),lt=f(),h(R.$$.fragment),rt=f(),b=s("h2"),U=s("a"),Ne=s("span"),h(J.$$.fragment),ia=f(),De=s("span"),na=n("Unconditional Flowers"),it=f(),we=s("p"),pa=n("The command to train a DDPM UNet model on the Oxford Flowers dataset:"),nt=f(),h(K.$$.fragment),pt=f(),Q=s("p"),ua=n("An example trained model: "),W=s("a"),fa=n("https://huggingface.co/anton-l/ddpm-ema-flowers-64"),ut=f(),ye=s("p"),da=n("A full training run takes 2 hours on 4xV100 GPUs."),ft=f(),X=s("img"),dt=f(),E=s("h2"),N=s("a"),Se=s("span"),h(Z.$$.fragment),ha=f(),Ce=s("span"),ma=n("Unconditional Pokemon"),ht=f(),$e=s("p"),ca=n("The command to train a DDPM UNet model on the Pokemon dataset:"),mt=f(),h(ee.$$.fragment),ct=f(),te=s("p"),_a=n("An example trained model: "),ae=s("a"),ga=n("https://huggingface.co/anton-l/ddpm-ema-pokemon-64"),_t=f(),be=s("p"),va=n("A full training run takes 2 hours on 4xV100 GPUs."),gt=f(),oe=s("img"),vt=f(),k=s("h2"),D=s("a"),Fe=s("span"),h(se.$$.fragment),wa=f(),Be=s("span"),ya=n("Using your own data"),wt=f(),Ee=s("p"),$a=n("To use your own dataset, there are 2 ways:"),yt=f(),S=s("ul"),ke=s("li"),ba=n("you can either provide your own folder as "),Te=s("code"),Ea=n("--train_data_dir"),ka=f(),le=s("li"),xa=n("or you can upload your dataset to the hub (possibly as a private repo, if you prefer so), and simply pass the "),Ge=s("code"),Pa=n("--dataset_name"),Aa=n(" argument."),$t=f(),x=s("p"),Me=s("strong"),qa=n("Note"),Ia=n(": If you want to create your own training dataset please have a look at "),re=s("a"),ja=n("this document"),za=n("."),bt=f(),xe=s("p"),Ua=n("Below, we explain both in more detail."),Et=f(),P=s("h3"),C=s("a"),Oe=s("span"),h(ie.$$.fragment),Na=f(),Le=s("span"),Da=n("Provide the dataset as a folder"),kt=f(),Pe=s("p"),Sa=n("If you provide your own folders with images, the script expects the following directory structure:"),xt=f(),h(ne.$$.fragment),Pt=f(),Ae=s("p"),Ca=n("In other words, the script will take care of gathering all images inside the folder. You can then run the script like this:"),At=f(),h(pe.$$.fragment),qt=f(),F=s("p"),Fa=n("Internally, the script will use the "),ue=s("a"),He=s("code"),Ba=n("ImageFolder"),Ta=n(" feature which will automatically turn the folders into \u{1F917} Dataset objects."),It=f(),A=s("h3"),B=s("a"),Ve=s("span"),h(fe.$$.fragment),Ga=f(),Ye=s("span"),Ma=n("Upload your data to the hub, as a (possibly private) repo"),jt=f(),T=s("p"),Oa=n("It\u2019s very easy (and convenient) to upload your image dataset to the hub using the "),de=s("a"),Re=s("code"),La=n("ImageFolder"),Ha=n(" feature available in \u{1F917} Datasets. Simply do the following:"),zt=f(),h(he.$$.fragment),Ut=f(),q=s("p"),Je=s("code"),Va=n("ImageFolder"),Ya=n(" will create an "),Ke=s("code"),Ra=n("image"),Ja=n(" column containing the PIL-encoded images."),Nt=f(),qe=s("p"),Ka=n("Next, push it to the hub!"),Dt=f(),h(me.$$.fragment),St=f(),G=s("p"),Qa=n("and that\u2019s it! You can now train your model by simply setting the "),Qe=s("code"),Wa=n("--dataset_name"),Xa=n(" argument to the name of your dataset on the hub."),Ct=f(),M=s("p"),Za=n("More on this can also be found in "),ce=s("a"),eo=n("this blog post"),to=n("."),this.h()},l(e){const o=rs('[data-svelte="svelte-1phssyn"]',document.head);w=l(o,"META",{name:!0,content:!0}),o.forEach(t),Ze=d(e),y=l(e,"H1",{class:!0});var Bt=i(y);I=l(Bt,"A",{id:!0,class:!0,href:!0});var no=i(I);Ie=l(no,"SPAN",{});var po=i(Ie);m(L.$$.fragment,po),po.forEach(t),no.forEach(t),Xt=d(Bt),je=l(Bt,"SPAN",{});var uo=i(je);Zt=p(uo,"Unconditional Image-Generation"),uo.forEach(t),Bt.forEach(t),et=d(e),ge=l(e,"P",{});var fo=i(ge);ea=p(fo,`In this section, we explain how one can train an unconditional image generation diffusion
model. \u201CUnconditional\u201D because the model is not conditioned on any context to generate an image - once trained the model will simply generate images that resemble its training data
distribution.`),fo.forEach(t),tt=d(e),$=l(e,"H2",{class:!0});var Tt=i($);j=l(Tt,"A",{id:!0,class:!0,href:!0});var ho=i(j);ze=l(ho,"SPAN",{});var mo=i(ze);m(H.$$.fragment,mo),mo.forEach(t),ho.forEach(t),ta=d(Tt),Ue=l(Tt,"SPAN",{});var co=i(Ue);aa=p(co,"Installing the dependencies"),co.forEach(t),Tt.forEach(t),at=d(e),ve=l(e,"P",{});var _o=i(ve);oa=p(_o,"Before running the scipts, make sure to install the library\u2019s training dependencies:"),_o.forEach(t),ot=d(e),m(V.$$.fragment,e),st=d(e),z=l(e,"P",{});var Gt=i(z);sa=p(Gt,"And initialize an "),Y=l(Gt,"A",{href:!0,rel:!0});var go=i(Y);la=p(go,"\u{1F917}Accelerate"),go.forEach(t),ra=p(Gt," environment with:"),Gt.forEach(t),lt=d(e),m(R.$$.fragment,e),rt=d(e),b=l(e,"H2",{class:!0});var Mt=i(b);U=l(Mt,"A",{id:!0,class:!0,href:!0});var vo=i(U);Ne=l(vo,"SPAN",{});var wo=i(Ne);m(J.$$.fragment,wo),wo.forEach(t),vo.forEach(t),ia=d(Mt),De=l(Mt,"SPAN",{});var yo=i(De);na=p(yo,"Unconditional Flowers"),yo.forEach(t),Mt.forEach(t),it=d(e),we=l(e,"P",{});var $o=i(we);pa=p($o,"The command to train a DDPM UNet model on the Oxford Flowers dataset:"),$o.forEach(t),nt=d(e),m(K.$$.fragment,e),pt=d(e),Q=l(e,"P",{});var ao=i(Q);ua=p(ao,"An example trained model: "),W=l(ao,"A",{href:!0,rel:!0});var bo=i(W);fa=p(bo,"https://huggingface.co/anton-l/ddpm-ema-flowers-64"),bo.forEach(t),ao.forEach(t),ut=d(e),ye=l(e,"P",{});var Eo=i(ye);da=p(Eo,"A full training run takes 2 hours on 4xV100 GPUs."),Eo.forEach(t),ft=d(e),X=l(e,"IMG",{src:!0,width:!0}),dt=d(e),E=l(e,"H2",{class:!0});var Ot=i(E);N=l(Ot,"A",{id:!0,class:!0,href:!0});var ko=i(N);Se=l(ko,"SPAN",{});var xo=i(Se);m(Z.$$.fragment,xo),xo.forEach(t),ko.forEach(t),ha=d(Ot),Ce=l(Ot,"SPAN",{});var Po=i(Ce);ma=p(Po,"Unconditional Pokemon"),Po.forEach(t),Ot.forEach(t),ht=d(e),$e=l(e,"P",{});var Ao=i($e);ca=p(Ao,"The command to train a DDPM UNet model on the Pokemon dataset:"),Ao.forEach(t),mt=d(e),m(ee.$$.fragment,e),ct=d(e),te=l(e,"P",{});var oo=i(te);_a=p(oo,"An example trained model: "),ae=l(oo,"A",{href:!0,rel:!0});var qo=i(ae);ga=p(qo,"https://huggingface.co/anton-l/ddpm-ema-pokemon-64"),qo.forEach(t),oo.forEach(t),_t=d(e),be=l(e,"P",{});var Io=i(be);va=p(Io,"A full training run takes 2 hours on 4xV100 GPUs."),Io.forEach(t),gt=d(e),oe=l(e,"IMG",{src:!0,width:!0}),vt=d(e),k=l(e,"H2",{class:!0});var Lt=i(k);D=l(Lt,"A",{id:!0,class:!0,href:!0});var jo=i(D);Fe=l(jo,"SPAN",{});var zo=i(Fe);m(se.$$.fragment,zo),zo.forEach(t),jo.forEach(t),wa=d(Lt),Be=l(Lt,"SPAN",{});var Uo=i(Be);ya=p(Uo,"Using your own data"),Uo.forEach(t),Lt.forEach(t),wt=d(e),Ee=l(e,"P",{});var No=i(Ee);$a=p(No,"To use your own dataset, there are 2 ways:"),No.forEach(t),yt=d(e),S=l(e,"UL",{});var Ht=i(S);ke=l(Ht,"LI",{});var so=i(ke);ba=p(so,"you can either provide your own folder as "),Te=l(so,"CODE",{});var Do=i(Te);Ea=p(Do,"--train_data_dir"),Do.forEach(t),so.forEach(t),ka=d(Ht),le=l(Ht,"LI",{});var Vt=i(le);xa=p(Vt,"or you can upload your dataset to the hub (possibly as a private repo, if you prefer so), and simply pass the "),Ge=l(Vt,"CODE",{});var So=i(Ge);Pa=p(So,"--dataset_name"),So.forEach(t),Aa=p(Vt," argument."),Vt.forEach(t),Ht.forEach(t),$t=d(e),x=l(e,"P",{});var We=i(x);Me=l(We,"STRONG",{});var Co=i(Me);qa=p(Co,"Note"),Co.forEach(t),Ia=p(We,": If you want to create your own training dataset please have a look at "),re=l(We,"A",{href:!0,rel:!0});var Fo=i(re);ja=p(Fo,"this document"),Fo.forEach(t),za=p(We,"."),We.forEach(t),bt=d(e),xe=l(e,"P",{});var Bo=i(xe);Ua=p(Bo,"Below, we explain both in more detail."),Bo.forEach(t),Et=d(e),P=l(e,"H3",{class:!0});var Yt=i(P);C=l(Yt,"A",{id:!0,class:!0,href:!0});var To=i(C);Oe=l(To,"SPAN",{});var Go=i(Oe);m(ie.$$.fragment,Go),Go.forEach(t),To.forEach(t),Na=d(Yt),Le=l(Yt,"SPAN",{});var Mo=i(Le);Da=p(Mo,"Provide the dataset as a folder"),Mo.forEach(t),Yt.forEach(t),kt=d(e),Pe=l(e,"P",{});var Oo=i(Pe);Sa=p(Oo,"If you provide your own folders with images, the script expects the following directory structure:"),Oo.forEach(t),xt=d(e),m(ne.$$.fragment,e),Pt=d(e),Ae=l(e,"P",{});var Lo=i(Ae);Ca=p(Lo,"In other words, the script will take care of gathering all images inside the folder. You can then run the script like this:"),Lo.forEach(t),At=d(e),m(pe.$$.fragment,e),qt=d(e),F=l(e,"P",{});var Rt=i(F);Fa=p(Rt,"Internally, the script will use the "),ue=l(Rt,"A",{href:!0,rel:!0});var Ho=i(ue);He=l(Ho,"CODE",{});var Vo=i(He);Ba=p(Vo,"ImageFolder"),Vo.forEach(t),Ho.forEach(t),Ta=p(Rt," feature which will automatically turn the folders into \u{1F917} Dataset objects."),Rt.forEach(t),It=d(e),A=l(e,"H3",{class:!0});var Jt=i(A);B=l(Jt,"A",{id:!0,class:!0,href:!0});var Yo=i(B);Ve=l(Yo,"SPAN",{});var Ro=i(Ve);m(fe.$$.fragment,Ro),Ro.forEach(t),Yo.forEach(t),Ga=d(Jt),Ye=l(Jt,"SPAN",{});var Jo=i(Ye);Ma=p(Jo,"Upload your data to the hub, as a (possibly private) repo"),Jo.forEach(t),Jt.forEach(t),jt=d(e),T=l(e,"P",{});var Kt=i(T);Oa=p(Kt,"It\u2019s very easy (and convenient) to upload your image dataset to the hub using the "),de=l(Kt,"A",{href:!0,rel:!0});var Ko=i(de);Re=l(Ko,"CODE",{});var Qo=i(Re);La=p(Qo,"ImageFolder"),Qo.forEach(t),Ko.forEach(t),Ha=p(Kt," feature available in \u{1F917} Datasets. Simply do the following:"),Kt.forEach(t),zt=d(e),m(he.$$.fragment,e),Ut=d(e),q=l(e,"P",{});var Xe=i(q);Je=l(Xe,"CODE",{});var Wo=i(Je);Va=p(Wo,"ImageFolder"),Wo.forEach(t),Ya=p(Xe," will create an "),Ke=l(Xe,"CODE",{});var Xo=i(Ke);Ra=p(Xo,"image"),Xo.forEach(t),Ja=p(Xe," column containing the PIL-encoded images."),Xe.forEach(t),Nt=d(e),qe=l(e,"P",{});var Zo=i(qe);Ka=p(Zo,"Next, push it to the hub!"),Zo.forEach(t),Dt=d(e),m(me.$$.fragment,e),St=d(e),G=l(e,"P",{});var Qt=i(G);Qa=p(Qt,"and that\u2019s it! You can now train your model by simply setting the "),Qe=l(Qt,"CODE",{});var es=i(Qe);Wa=p(es,"--dataset_name"),es.forEach(t),Xa=p(Qt," argument to the name of your dataset on the hub."),Qt.forEach(t),Ct=d(e),M=l(e,"P",{});var Wt=i(M);Za=p(Wt,"More on this can also be found in "),ce=l(Wt,"A",{href:!0,rel:!0});var ts=i(ce);eo=p(ts,"this blog post"),ts.forEach(t),to=p(Wt,"."),Wt.forEach(t),this.h()},h(){u(w,"name","hf:doc:metadata"),u(w,"content",JSON.stringify(us)),u(I,"id","unconditional-imagegeneration"),u(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(I,"href","#unconditional-imagegeneration"),u(y,"class","relative group"),u(j,"id","installing-the-dependencies"),u(j,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(j,"href","#installing-the-dependencies"),u($,"class","relative group"),u(Y,"href","https://github.com/huggingface/accelerate/"),u(Y,"rel","nofollow"),u(U,"id","unconditional-flowers"),u(U,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(U,"href","#unconditional-flowers"),u(b,"class","relative group"),u(W,"href","https://huggingface.co/anton-l/ddpm-ema-flowers-64"),u(W,"rel","nofollow"),as(X.src,ro="https://user-images.githubusercontent.com/26864830/180248660-a0b143d0-b89a-42c5-8656-2ebf6ece7e52.png")||u(X,"src",ro),u(X,"width","700"),u(N,"id","unconditional-pokemon"),u(N,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(N,"href","#unconditional-pokemon"),u(E,"class","relative group"),u(ae,"href","https://huggingface.co/anton-l/ddpm-ema-pokemon-64"),u(ae,"rel","nofollow"),as(oe.src,io="https://user-images.githubusercontent.com/26864830/180248200-928953b4-db38-48db-b0c6-8b740fe6786f.png")||u(oe,"src",io),u(oe,"width","700"),u(D,"id","using-your-own-data"),u(D,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(D,"href","#using-your-own-data"),u(k,"class","relative group"),u(re,"href","https://huggingface.co/docs/datasets/image_process#image-datasets"),u(re,"rel","nofollow"),u(C,"id","provide-the-dataset-as-a-folder"),u(C,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(C,"href","#provide-the-dataset-as-a-folder"),u(P,"class","relative group"),u(ue,"href","https://huggingface.co/docs/datasets/v2.0.0/en/image_process#imagefolder"),u(ue,"rel","nofollow"),u(B,"id","upload-your-data-to-the-hub-as-a-possibly-private-repo"),u(B,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(B,"href","#upload-your-data-to-the-hub-as-a-possibly-private-repo"),u(A,"class","relative group"),u(de,"href","https://huggingface.co/docs/datasets/v2.0.0/en/image_process#imagefolder"),u(de,"rel","nofollow"),u(ce,"href","https://huggingface.co/blog/image-search-datasets"),u(ce,"rel","nofollow")},m(e,o){a(document.head,w),r(e,Ze,o),r(e,y,o),a(y,I),a(I,Ie),c(L,Ie,null),a(y,Xt),a(y,je),a(je,Zt),r(e,et,o),r(e,ge,o),a(ge,ea),r(e,tt,o),r(e,$,o),a($,j),a(j,ze),c(H,ze,null),a($,ta),a($,Ue),a(Ue,aa),r(e,at,o),r(e,ve,o),a(ve,oa),r(e,ot,o),c(V,e,o),r(e,st,o),r(e,z,o),a(z,sa),a(z,Y),a(Y,la),a(z,ra),r(e,lt,o),c(R,e,o),r(e,rt,o),r(e,b,o),a(b,U),a(U,Ne),c(J,Ne,null),a(b,ia),a(b,De),a(De,na),r(e,it,o),r(e,we,o),a(we,pa),r(e,nt,o),c(K,e,o),r(e,pt,o),r(e,Q,o),a(Q,ua),a(Q,W),a(W,fa),r(e,ut,o),r(e,ye,o),a(ye,da),r(e,ft,o),r(e,X,o),r(e,dt,o),r(e,E,o),a(E,N),a(N,Se),c(Z,Se,null),a(E,ha),a(E,Ce),a(Ce,ma),r(e,ht,o),r(e,$e,o),a($e,ca),r(e,mt,o),c(ee,e,o),r(e,ct,o),r(e,te,o),a(te,_a),a(te,ae),a(ae,ga),r(e,_t,o),r(e,be,o),a(be,va),r(e,gt,o),r(e,oe,o),r(e,vt,o),r(e,k,o),a(k,D),a(D,Fe),c(se,Fe,null),a(k,wa),a(k,Be),a(Be,ya),r(e,wt,o),r(e,Ee,o),a(Ee,$a),r(e,yt,o),r(e,S,o),a(S,ke),a(ke,ba),a(ke,Te),a(Te,Ea),a(S,ka),a(S,le),a(le,xa),a(le,Ge),a(Ge,Pa),a(le,Aa),r(e,$t,o),r(e,x,o),a(x,Me),a(Me,qa),a(x,Ia),a(x,re),a(re,ja),a(x,za),r(e,bt,o),r(e,xe,o),a(xe,Ua),r(e,Et,o),r(e,P,o),a(P,C),a(C,Oe),c(ie,Oe,null),a(P,Na),a(P,Le),a(Le,Da),r(e,kt,o),r(e,Pe,o),a(Pe,Sa),r(e,xt,o),c(ne,e,o),r(e,Pt,o),r(e,Ae,o),a(Ae,Ca),r(e,At,o),c(pe,e,o),r(e,qt,o),r(e,F,o),a(F,Fa),a(F,ue),a(ue,He),a(He,Ba),a(F,Ta),r(e,It,o),r(e,A,o),a(A,B),a(B,Ve),c(fe,Ve,null),a(A,Ga),a(A,Ye),a(Ye,Ma),r(e,jt,o),r(e,T,o),a(T,Oa),a(T,de),a(de,Re),a(Re,La),a(T,Ha),r(e,zt,o),c(he,e,o),r(e,Ut,o),r(e,q,o),a(q,Je),a(Je,Va),a(q,Ya),a(q,Ke),a(Ke,Ra),a(q,Ja),r(e,Nt,o),r(e,qe,o),a(qe,Ka),r(e,Dt,o),c(me,e,o),r(e,St,o),r(e,G,o),a(G,Qa),a(G,Qe),a(Qe,Wa),a(G,Xa),r(e,Ct,o),r(e,M,o),a(M,Za),a(M,ce),a(ce,eo),a(M,to),Ft=!0},p:is,i(e){Ft||(_(L.$$.fragment,e),_(H.$$.fragment,e),_(V.$$.fragment,e),_(R.$$.fragment,e),_(J.$$.fragment,e),_(K.$$.fragment,e),_(Z.$$.fragment,e),_(ee.$$.fragment,e),_(se.$$.fragment,e),_(ie.$$.fragment,e),_(ne.$$.fragment,e),_(pe.$$.fragment,e),_(fe.$$.fragment,e),_(he.$$.fragment,e),_(me.$$.fragment,e),Ft=!0)},o(e){g(L.$$.fragment,e),g(H.$$.fragment,e),g(V.$$.fragment,e),g(R.$$.fragment,e),g(J.$$.fragment,e),g(K.$$.fragment,e),g(Z.$$.fragment,e),g(ee.$$.fragment,e),g(se.$$.fragment,e),g(ie.$$.fragment,e),g(ne.$$.fragment,e),g(pe.$$.fragment,e),g(fe.$$.fragment,e),g(he.$$.fragment,e),g(me.$$.fragment,e),Ft=!1},d(e){t(w),e&&t(Ze),e&&t(y),v(L),e&&t(et),e&&t(ge),e&&t(tt),e&&t($),v(H),e&&t(at),e&&t(ve),e&&t(ot),v(V,e),e&&t(st),e&&t(z),e&&t(lt),v(R,e),e&&t(rt),e&&t(b),v(J),e&&t(it),e&&t(we),e&&t(nt),v(K,e),e&&t(pt),e&&t(Q),e&&t(ut),e&&t(ye),e&&t(ft),e&&t(X),e&&t(dt),e&&t(E),v(Z),e&&t(ht),e&&t($e),e&&t(mt),v(ee,e),e&&t(ct),e&&t(te),e&&t(_t),e&&t(be),e&&t(gt),e&&t(oe),e&&t(vt),e&&t(k),v(se),e&&t(wt),e&&t(Ee),e&&t(yt),e&&t(S),e&&t($t),e&&t(x),e&&t(bt),e&&t(xe),e&&t(Et),e&&t(P),v(ie),e&&t(kt),e&&t(Pe),e&&t(xt),v(ne,e),e&&t(Pt),e&&t(Ae),e&&t(At),v(pe,e),e&&t(qt),e&&t(F),e&&t(It),e&&t(A),v(fe),e&&t(jt),e&&t(T),e&&t(zt),v(he,e),e&&t(Ut),e&&t(q),e&&t(Nt),e&&t(qe),e&&t(Dt),v(me,e),e&&t(St),e&&t(G),e&&t(Ct),e&&t(M)}}}const us={local:"unconditional-imagegeneration",sections:[{local:"installing-the-dependencies",title:"Installing the dependencies"},{local:"unconditional-flowers",title:"Unconditional Flowers  "},{local:"unconditional-pokemon",title:"Unconditional Pokemon "},{local:"using-your-own-data",sections:[{local:"provide-the-dataset-as-a-folder",title:"Provide the dataset as a folder"},{local:"upload-your-data-to-the-hub-as-a-possibly-private-repo",title:"Upload your data to the hub, as a (possibly private) repo"}],title:"Using your own data"}],title:"Unconditional Image-Generation"};function fs(lo){return ns(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class cs extends os{constructor(w){super();ss(this,w,fs,ps,ls,{})}}export{cs as default,us as metadata};
