import{S as Jr,i as Kr,s as Qr,e as i,k as f,w as x,t,M as Zr,c as r,d as o,m as p,a,x as $,h as n,b as _,G as e,g as y,y as D,q as k,o as P,B as M,v as ea,L as ir}from"../../chunks/vendor-hf-doc-builder.js";import{T as ao}from"../../chunks/Tip-hf-doc-builder.js";import{D as J}from"../../chunks/Docstring-hf-doc-builder.js";import{C as rr}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as oa}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as nr}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function ta(I){let l,g,c,h,u,d,m,w;return{c(){l=i("p"),g=t("It is required to be logged in ("),c=i("code"),h=t("huggingface-cli login"),u=t(") when you want to use private or "),d=i("a"),m=t(`gated
models`),w=t("."),this.h()},l(X){l=r(X,"P",{});var F=a(l);g=n(F,"It is required to be logged in ("),c=r(F,"CODE",{});var L=a(c);h=n(L,"huggingface-cli login"),L.forEach(o),u=n(F,") when you want to use private or "),d=r(F,"A",{href:!0,rel:!0});var A=a(d);m=n(A,`gated
models`),A.forEach(o),w=n(F,"."),F.forEach(o),this.h()},h(){_(d,"href","https://huggingface.co/docs/hub/models-gated#gated-models"),_(d,"rel","nofollow")},m(X,F){y(X,l,F),e(l,g),e(l,c),e(c,h),e(l,u),e(l,d),e(d,m),e(l,w)},d(X){X&&o(l)}}}function na(I){let l,g,c,h,u;return{c(){l=i("p"),g=t("Activate the special "),c=i("a"),h=t("\u201Coffline-mode\u201D"),u=t(` to use
this method in a firewalled environment.`),this.h()},l(d){l=r(d,"P",{});var m=a(l);g=n(m,"Activate the special "),c=r(m,"A",{href:!0,rel:!0});var w=a(c);h=n(w,"\u201Coffline-mode\u201D"),w.forEach(o),u=n(m,` to use
this method in a firewalled environment.`),m.forEach(o),this.h()},h(){_(c,"href","https://huggingface.co/diffusers/installation.html#offline-mode"),_(c,"rel","nofollow")},m(d,m){y(d,l,m),e(l,g),e(l,c),e(c,h),e(l,u)},d(d){d&&o(l)}}}function ia(I){let l,g,c,h,u,d,m,w,X,F,L,A,G;return{c(){l=i("p"),g=t("It is required to be logged in ("),c=i("code"),h=t("huggingface-cli login"),u=t(") when you want to use private or "),d=i("a"),m=t(`gated
models`),w=t(", "),X=i("em"),F=t("e.g."),L=f(),A=i("code"),G=t('"runwayml/stable-diffusion-v1-5"'),this.h()},l(O){l=r(O,"P",{});var b=a(l);g=n(b,"It is required to be logged in ("),c=r(b,"CODE",{});var K=a(c);h=n(K,"huggingface-cli login"),K.forEach(o),u=n(b,") when you want to use private or "),d=r(b,"A",{href:!0,rel:!0});var E=a(d);m=n(E,`gated
models`),E.forEach(o),w=n(b,", "),X=r(b,"EM",{});var R=a(X);F=n(R,"e.g."),R.forEach(o),L=p(b),A=r(b,"CODE",{});var oe=a(A);G=n(oe,'"runwayml/stable-diffusion-v1-5"'),oe.forEach(o),b.forEach(o),this.h()},h(){_(d,"href","https://huggingface.co/docs/hub/models-gated#gated-models"),_(d,"rel","nofollow")},m(O,b){y(O,l,b),e(l,g),e(l,c),e(c,h),e(l,u),e(l,d),e(d,m),e(l,w),e(l,X),e(X,F),e(l,L),e(l,A),e(A,G)},d(O){O&&o(l)}}}function ra(I){let l,g,c,h,u;return{c(){l=i("p"),g=t("Activate the special "),c=i("a"),h=t("\u201Coffline-mode\u201D"),u=t(` to use
this method in a firewalled environment.`),this.h()},l(d){l=r(d,"P",{});var m=a(l);g=n(m,"Activate the special "),c=r(m,"A",{href:!0,rel:!0});var w=a(c);h=n(w,"\u201Coffline-mode\u201D"),w.forEach(o),u=n(m,` to use
this method in a firewalled environment.`),m.forEach(o),this.h()},h(){_(c,"href","https://huggingface.co/diffusers/installation.html#offline-mode"),_(c,"rel","nofollow")},m(d,m){y(d,l,m),e(l,g),e(l,c),e(c,h),e(l,u)},d(d){d&&o(l)}}}function aa(I){let l,g,c,h,u;return h=new rr({props:{code:`from diffusers import DiffusionPipeline

# Download pipeline from huggingface.co and cache.
pipeline = DiffusionPipeline.from_pretrained("CompVis/ldm-text2im-large-256")

# Download pipeline that requires an authorization token
# For more information on access tokens, please refer to this section
# of the documentation](https://huggingface.co/docs/hub/security-tokens)
pipeline = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")

# Download pipeline, but overwrite scheduler
from diffusers import LMSDiscreteScheduler

scheduler = LMSDiscreteScheduler.from_config("runwayml/stable-diffusion-v1-5", subfolder="scheduler")
pipeline = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", scheduler=scheduler)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download pipeline from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pipeline = DiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;CompVis/ldm-text2im-large-256&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download pipeline that requires an authorization token</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># For more information on access tokens, please refer to this section</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># of the documentation](https://huggingface.co/docs/hub/security-tokens)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pipeline = DiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download pipeline, but overwrite scheduler</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> LMSDiscreteScheduler

<span class="hljs-meta">&gt;&gt;&gt; </span>scheduler = LMSDiscreteScheduler.from_config(<span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>, subfolder=<span class="hljs-string">&quot;scheduler&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>pipeline = DiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>, scheduler=scheduler)`}}),{c(){l=i("p"),g=t("Examples:"),c=f(),x(h.$$.fragment)},l(d){l=r(d,"P",{});var m=a(l);g=n(m,"Examples:"),m.forEach(o),c=p(d),$(h.$$.fragment,d)},m(d,m){y(d,l,m),e(l,g),y(d,c,m),D(h,d,m),u=!0},p:ir,i(d){u||(k(h.$$.fragment,d),u=!0)},o(d){P(h.$$.fragment,d),u=!1},d(d){d&&o(l),d&&o(c),M(h,d)}}}function sa(I){let l,g,c,h,u;return h=new rr({props:{code:`from diffusers import FlaxUNet2DConditionModel

# Download model and configuration from huggingface.co and cache.
model, params = FlaxUNet2DConditionModel.from_pretrained("runwayml/stable-diffusion-v1-5")
# Model was saved using *save_pretrained('./test/saved_model/')* (for example purposes, not runnable).
model, params = FlaxUNet2DConditionModel.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> FlaxUNet2DConditionModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model, params = FlaxUNet2DConditionModel.from_pretrained(<span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Model was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)* (for example purposes, not runnable).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model, params = FlaxUNet2DConditionModel.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){l=i("p"),g=t("Examples:"),c=f(),x(h.$$.fragment)},l(d){l=r(d,"P",{});var m=a(l);g=n(m,"Examples:"),m.forEach(o),c=p(d),$(h.$$.fragment,d)},m(d,m){y(d,l,m),e(l,g),y(d,c,m),D(h,d,m),u=!0},p:ir,i(d){u||(k(h.$$.fragment,d),u=!0)},o(d){P(h.$$.fragment,d),u=!1},d(d){d&&o(l),d&&o(c),M(h,d)}}}function da(I){let l,g,c,h,u,d,m,w,X,F,L,A,G;return{c(){l=i("p"),g=t("It is required to be logged in ("),c=i("code"),h=t("huggingface-cli login"),u=t(") when you want to use private or "),d=i("a"),m=t(`gated
models`),w=t(", "),X=i("em"),F=t("e.g."),L=f(),A=i("code"),G=t('"runwayml/stable-diffusion-v1-5"'),this.h()},l(O){l=r(O,"P",{});var b=a(l);g=n(b,"It is required to be logged in ("),c=r(b,"CODE",{});var K=a(c);h=n(K,"huggingface-cli login"),K.forEach(o),u=n(b,") when you want to use private or "),d=r(b,"A",{href:!0,rel:!0});var E=a(d);m=n(E,`gated
models`),E.forEach(o),w=n(b,", "),X=r(b,"EM",{});var R=a(X);F=n(R,"e.g."),R.forEach(o),L=p(b),A=r(b,"CODE",{});var oe=a(A);G=n(oe,'"runwayml/stable-diffusion-v1-5"'),oe.forEach(o),b.forEach(o),this.h()},h(){_(d,"href","https://huggingface.co/docs/hub/models-gated#gated-models"),_(d,"rel","nofollow")},m(O,b){y(O,l,b),e(l,g),e(l,c),e(c,h),e(l,u),e(l,d),e(d,m),e(l,w),e(l,X),e(X,F),e(l,L),e(l,A),e(A,G)},d(O){O&&o(l)}}}function la(I){let l,g,c,h,u;return{c(){l=i("p"),g=t("Activate the special "),c=i("a"),h=t("\u201Coffline-mode\u201D"),u=t(` to use
this method in a firewalled environment.`),this.h()},l(d){l=r(d,"P",{});var m=a(l);g=n(m,"Activate the special "),c=r(m,"A",{href:!0,rel:!0});var w=a(c);h=n(w,"\u201Coffline-mode\u201D"),w.forEach(o),u=n(m,` to use
this method in a firewalled environment.`),m.forEach(o),this.h()},h(){_(c,"href","https://huggingface.co/diffusers/installation.html#offline-mode"),_(c,"rel","nofollow")},m(d,m){y(d,l,m),e(l,g),e(l,c),e(c,h),e(l,u)},d(d){d&&o(l)}}}function ca(I){let l,g,c,h,u;return h=new rr({props:{code:`from diffusers import FlaxDiffusionPipeline

# Download pipeline from huggingface.co and cache.
pipeline = FlaxDiffusionPipeline.from_pretrained("CompVis/ldm-text2im-large-256")

# Download pipeline that requires an authorization token
# For more information on access tokens, please refer to this section
# of the documentation](https://huggingface.co/docs/hub/security-tokens)
pipeline = FlaxDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")

# Download pipeline, but overwrite scheduler
from diffusers import LMSDiscreteScheduler

scheduler = LMSDiscreteScheduler.from_config("runwayml/stable-diffusion-v1-5", subfolder="scheduler")
pipeline = FlaxDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", scheduler=scheduler)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> FlaxDiffusionPipeline

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download pipeline from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pipeline = FlaxDiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;CompVis/ldm-text2im-large-256&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download pipeline that requires an authorization token</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># For more information on access tokens, please refer to this section</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># of the documentation](https://huggingface.co/docs/hub/security-tokens)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pipeline = FlaxDiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download pipeline, but overwrite scheduler</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> LMSDiscreteScheduler

<span class="hljs-meta">&gt;&gt;&gt; </span>scheduler = LMSDiscreteScheduler.from_config(<span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>, subfolder=<span class="hljs-string">&quot;scheduler&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>pipeline = FlaxDiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>, scheduler=scheduler)`}}),{c(){l=i("p"),g=t("Examples:"),c=f(),x(h.$$.fragment)},l(d){l=r(d,"P",{});var m=a(l);g=n(m,"Examples:"),m.forEach(o),c=p(d),$(h.$$.fragment,d)},m(d,m){y(d,l,m),e(l,g),y(d,c,m),D(h,d,m),u=!0},p:ir,i(d){u||(k(h.$$.fragment,d),u=!0)},o(d){P(h.$$.fragment,d),u=!1},d(d){d&&o(l),d&&o(c),M(h,d)}}}function fa(I){let l,g,c,h,u,d,m,w,X,F,L,A,G,O,b,K,E,R,oe,so,kt,Pt,Re,Je,Mt,Et,Xt,lo,Q,co,Ft,Tt,fo,jt,It,Ke,qt,Ct,Lt,Y,be,At,po,Yt,Ut,te,Wt,mo,St,zt,ho,Ot,Vt,Nt,we,Bt,uo,Ht,Gt,Rt,ye,Jt,go,Kt,Qt,Zt,ne,en,ie,on,re,xe,tn,$e,nn,_o,rn,an,et,T,De,sn,vo,dn,ln,Qe,Ze,cn,fn,pn,ke,bo,mn,hn,wo,un,gn,yo,_n,vn,xo,ae,$o,bn,wn,Do,yn,xn,$n,q,Pe,Dn,ko,kn,Pn,Me,Mn,Po,En,Xn,Fn,Ee,Tn,Mo,jn,In,qn,Xe,Cn,Eo,Ln,An,Yn,se,Un,de,Wn,le,Sn,ce,Fe,zn,Te,On,Xo,Vn,Nn,ot,V,je,Bn,Fo,Hn,Gn,eo,oo,Rn,Jn,Kn,B,Ie,Qn,To,Zn,ei,qe,oi,jo,ti,ni,ii,Ce,ri,Io,ai,si,di,fe,li,pe,Le,ci,Ae,fi,qo,pi,mi,tt,j,Ye,hi,Co,ui,gi,to,no,_i,vi,bi,Lo,Ao,wi,yi,Yo,xi,$i,Uo,me,Wo,Di,ki,So,Pi,Mi,Ei,C,Ue,Xi,zo,Fi,Ti,We,ji,Oo,Ii,qi,Ci,Se,Li,Vo,Ai,Yi,Ui,ze,Wi,No,Si,zi,Oi,he,Vi,ue,Ni,ge,Bi,_e,Oe,Hi,Ve,Gi,Bo,Ri,Ji,nt,ve,Ki,Ne,Qi,Zi,it;return d=new oa({}),R=new J({props:{name:"class diffusers.ModelMixin",anchor:"diffusers.ModelMixin",parameters:[],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/modeling_utils.py#L123"}}),be=new J({props:{name:"from_pretrained",anchor:"diffusers.ModelMixin.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:": typing.Union[str, os.PathLike, NoneType]"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.ModelMixin.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids should have an organization name, like <code>google/ddpm-celebahq-256</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using <code>~ModelMixin.save_config</code>, e.g.,
<code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"diffusers.ModelMixin.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>Union[str, os.PathLike]</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"diffusers.ModelMixin.from_pretrained.torch_dtype",description:`<strong>torch_dtype</strong> (<code>str</code> or <code>torch.dtype</code>, <em>optional</em>) &#x2014;
Override the default <code>torch.dtype</code> and load the model under this dtype. If <code>&quot;auto&quot;</code> is passed the dtype
will be automatically derived from the model&#x2019;s weights.`,name:"torch_dtype"},{anchor:"diffusers.ModelMixin.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"diffusers.ModelMixin.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"diffusers.ModelMixin.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"diffusers.ModelMixin.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"diffusers.ModelMixin.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (i.e., do not try to download the model).`,name:"local_files_only(bool,"},{anchor:"diffusers.ModelMixin.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>diffusers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"diffusers.ModelMixin.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"diffusers.ModelMixin.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&quot;</code>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo (either remote in
huggingface.co or downloaded locally), you can specify the folder name here.`,name:"subfolder"},{anchor:"diffusers.ModelMixin.from_pretrained.mirror",description:`<strong>mirror</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Mirror source to accelerate downloads in China. If you are from China and have an accessibility
problem, you can set this option to resolve it. Note that we do not guarantee the timeliness or safety.
Please refer to the mirror site for more information.`,name:"mirror"},{anchor:"diffusers.ModelMixin.from_pretrained.device_map",description:`<strong>device_map</strong> (<code>str</code> or <code>Dict[str, Union[int, str, torch.device]]</code>, <em>optional</em>) &#x2014;
A map that specifies where each submodule should go. It doesn&#x2019;t need to be refined to each
parameter/buffer name, once a given module name is inside, every submodule of it will be sent to the
same device.</p>
<p>To have Accelerate compute the most optimized <code>device_map</code> automatically, set <code>device_map=&quot;auto&quot;</code>. For
more information about each option see <a href="https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map" rel="nofollow">designing a device
map</a>.`,name:"device_map"},{anchor:"diffusers.ModelMixin.from_pretrained.low_cpu_mem_usage",description:`<strong>low_cpu_mem_usage</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code> if torch version &gt;= 1.9.0 else <code>False</code>) &#x2014;
Speed up model loading by not initializing the weights and only loading the pre-trained weights. This
also tries to not use more than 1x model size in CPU memory (including peak memory) while loading the
model. This is only supported when torch version &gt;= 1.9.0. If you are using an older version of torch,
setting this argument to <code>True</code> will raise an error.`,name:"low_cpu_mem_usage"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/modeling_utils.py#L221"}}),ne=new ao({props:{$$slots:{default:[ta]},$$scope:{ctx:I}}}),ie=new ao({props:{$$slots:{default:[na]},$$scope:{ctx:I}}}),xe=new J({props:{name:"save_pretrained",anchor:"diffusers.ModelMixin.save_pretrained",parameters:[{name:"save_directory",val:": typing.Union[str, os.PathLike]"},{name:"is_main_process",val:": bool = True"},{name:"save_function",val:": typing.Callable = <function save at 0x7ff245744670>"}],parametersDescription:[{anchor:"diffusers.ModelMixin.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Directory to which to save. Will be created if it doesn&#x2019;t exist.`,name:"save_directory"},{anchor:"diffusers.ModelMixin.save_pretrained.is_main_process",description:`<strong>is_main_process</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether the process calling this is the main process or not. Useful when in distributed training like
TPUs and need to call this function on all processes. In this case, set <code>is_main_process=True</code> only on
the main process to avoid race conditions.`,name:"is_main_process"},{anchor:"diffusers.ModelMixin.save_pretrained.save_function",description:`<strong>save_function</strong> (<code>Callable</code>) &#x2014;
The function to use to save the state dictionary. Useful on distributed training like TPUs when one
need to replace <code>torch.save</code> by another method.`,name:"save_function"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/modeling_utils.py#L171"}}),De=new J({props:{name:"class diffusers.DiffusionPipeline",anchor:"diffusers.DiffusionPipeline",parameters:[],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipeline_utils.py#L112"}}),Pe=new J({props:{name:"from_pretrained",anchor:"diffusers.DiffusionPipeline.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:": typing.Union[str, os.PathLike, NoneType]"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.DiffusionPipeline.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>repo id</em> of a pretrained pipeline hosted inside a model repo on
<a href="https://huggingface.co/" rel="nofollow">https://huggingface.co/</a> Valid repo ids have to be located under a user or organization name, like
<code>CompVis/ldm-text2im-large-256</code>.</li>
<li>A path to a <em>directory</em> containing pipeline weights saved using
<a href="/docs/diffusers/main/en/using-diffusers/loading#diffusers.DiffusionPipeline.save_pretrained">save_pretrained()</a>, e.g., <code>./my_pipeline_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.torch_dtype",description:`<strong>torch_dtype</strong> (<code>str</code> or <code>torch.dtype</code>, <em>optional</em>) &#x2014;
Override the default <code>torch.dtype</code> and load the model under this dtype. If <code>&quot;auto&quot;</code> is passed the dtype
will be automatically derived from the model&#x2019;s weights.`,name:"torch_dtype"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.custom_pipeline",description:`<strong>custom_pipeline</strong> (<code>str</code>, <em>optional</em>) &#x2014;</p>
<div class="course-tip course-tip-orange bg-gradient-to-br dark:bg-gradient-to-r before:border-orange-500 dark:before:border-orange-800 from-orange-50 dark:from-gray-900 to-white dark:to-gray-950 border border-orange-50 text-orange-700 dark:text-gray-400">
						
<p>This is an experimental feature and is likely to change in the future.</p>

					</div>
<p>Can be either:</p>
<ul>
<li>
<p>A string, the <em>repo id</em> of a custom pipeline hosted inside a model repo on
<a href="https://huggingface.co/" rel="nofollow">https://huggingface.co/</a>. Valid repo ids have to be located under a user or organization name,
like <code>hf-internal-testing/diffusers-dummy-pipeline</code>.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>It is required that the model repo has a file, called <code>pipeline.py</code> that defines the custom
pipeline.</p>

					</div>
</li>
<li>
<p>A string, the <em>file name</em> of a community pipeline hosted on GitHub under
<a href="https://github.com/huggingface/diffusers/tree/main/examples/community" rel="nofollow">https://github.com/huggingface/diffusers/tree/main/examples/community</a>. Valid file names have to
match exactly the file name without <code>.py</code> located under the above link, <em>e.g.</em>
<code>clip_guided_stable_diffusion</code>.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>Community pipelines are always loaded from the current <code>main</code> branch of GitHub.</p>

					</div>
</li>
<li>
<p>A path to a <em>directory</em> containing a custom pipeline, e.g., <code>./my_pipeline_directory/</code>.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>It is required that the directory has a file, called <code>pipeline.py</code> that defines the custom
pipeline.</p>

					</div>
</li>
</ul>
<p>For more information on how to load and create custom pipelines, please have a look at <a href="https://huggingface.co/docs/diffusers/main/en/using-diffusers/custom_pipelines" rel="nofollow">Loading and
Creating Custom
Pipelines</a>`,name:"custom_pipeline"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.torch_dtype",description:"<strong>torch_dtype</strong> (<code>str</code> or <code>torch.dtype</code>, <em>optional</em>) &#x2014;",name:"torch_dtype"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (i.e., do not try to download the model).`,name:"local_files_only(bool,"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.mirror",description:`<strong>mirror</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Mirror source to accelerate downloads in China. If you are from China and have an accessibility
problem, you can set this option to resolve it. Note that we do not guarantee the timeliness or safety.
Please refer to the mirror site for more information. specify the folder name here.`,name:"mirror"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.device_map",description:`<strong>device_map</strong> (<code>str</code> or <code>Dict[str, Union[int, str, torch.device]]</code>, <em>optional</em>) &#x2014;
A map that specifies where each submodule should go. It doesn&#x2019;t need to be refined to each
parameter/buffer name, once a given module name is inside, every submodule of it will be sent to the
same device.</p>
<p>To have Accelerate compute the most optimized <code>device_map</code> automatically, set <code>device_map=&quot;auto&quot;</code>. For
more information about each option see <a href="https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map" rel="nofollow">designing a device
map</a>.`,name:"device_map"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.low_cpu_mem_usage",description:`<strong>low_cpu_mem_usage</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code> if torch version &gt;= 1.9.0 else <code>False</code>) &#x2014;
Speed up model loading by not initializing the weights and only loading the pre-trained weights. This
also tries to not use more than 1x model size in CPU memory (including peak memory) while loading the
model. This is only supported when torch version &gt;= 1.9.0. If you are using an older version of torch,
setting this argument to <code>True</code> will raise an error.`,name:"low_cpu_mem_usage"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.kwargs",description:`<strong>kwargs</strong> (remaining dictionary of keyword arguments, <em>optional</em>) &#x2014;
Can be used to overwrite load - and saveable variables - <em>i.e.</em> the pipeline components - of the
specific pipeline class. The overwritten components are then directly passed to the pipelines
<code>__init__</code> method. See example below for more information.`,name:"kwargs"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipeline_utils.py#L237"}}),se=new ao({props:{$$slots:{default:[ia]},$$scope:{ctx:I}}}),de=new ao({props:{$$slots:{default:[ra]},$$scope:{ctx:I}}}),le=new nr({props:{anchor:"diffusers.DiffusionPipeline.from_pretrained.example",$$slots:{default:[aa]},$$scope:{ctx:I}}}),Fe=new J({props:{name:"save_pretrained",anchor:"diffusers.DiffusionPipeline.save_pretrained",parameters:[{name:"save_directory",val:": typing.Union[str, os.PathLike]"}],parametersDescription:[{anchor:"diffusers.DiffusionPipeline.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Directory to which to save. Will be created if it doesn&#x2019;t exist.`,name:"save_directory"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipeline_utils.py#L162"}}),je=new J({props:{name:"class diffusers.FlaxModelMixin",anchor:"diffusers.FlaxModelMixin",parameters:[],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/modeling_flax_utils.py#L45"}}),Ie=new J({props:{name:"from_pretrained",anchor:"diffusers.FlaxModelMixin.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:": typing.Union[str, os.PathLike]"},{name:"dtype",val:": dtype = <class 'jax.numpy.float32'>"},{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.FlaxModelMixin.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids are namespaced under a user or organization name, like
<code>runwayml/stable-diffusion-v1-5</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using <a href="/docs/diffusers/main/en/using-diffusers/loading#diffusers.ModelMixin.save_pretrained">save_pretrained()</a>,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"diffusers.FlaxModelMixin.from_pretrained.dtype",description:`<strong>dtype</strong> (<code>jax.numpy.dtype</code>, <em>optional</em>, defaults to <code>jax.numpy.float32</code>) &#x2014;
The data type of the computation. Can be one of <code>jax.numpy.float32</code>, <code>jax.numpy.float16</code> (on GPUs) and
<code>jax.numpy.bfloat16</code> (on TPUs).</p>
<p>This can be used to enable mixed-precision training or half-precision inference on GPUs or TPUs. If
specified all the computation will be performed with the given <code>dtype</code>.</p>
<p><strong>Note that this only specifies the dtype of the computation and does not influence the dtype of model
parameters.</strong></p>
<p>If you wish to change the dtype of the model parameters, see <code>~ModelMixin.to_fp16</code> and
<code>~ModelMixin.to_bf16</code>.`,name:"dtype"},{anchor:"diffusers.FlaxModelMixin.from_pretrained.model_args",description:`<strong>model_args</strong> (sequence of positional arguments, <em>optional</em>) &#x2014;
All remaining positional arguments will be passed to the underlying model&#x2019;s <code>__init__</code> method.`,name:"model_args"},{anchor:"diffusers.FlaxModelMixin.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>Union[str, os.PathLike]</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"diffusers.FlaxModelMixin.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"diffusers.FlaxModelMixin.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"diffusers.FlaxModelMixin.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"diffusers.FlaxModelMixin.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (i.e., do not try to download the model).`,name:"local_files_only(bool,"},{anchor:"diffusers.FlaxModelMixin.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"diffusers.FlaxModelMixin.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file.`,name:"from_pt"},{anchor:"diffusers.FlaxModelMixin.from_pretrained.kwargs",description:`<strong>kwargs</strong> (remaining dictionary of keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin.from_config">from_config()</a>). Each key of <code>kwargs</code> that corresponds to
a configuration attribute will be used to override said attribute with the supplied <code>kwargs</code>
value. Remaining keys that do not correspond to any configuration attribute will be passed to the
underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/modeling_flax_utils.py#L195"}}),fe=new nr({props:{anchor:"diffusers.FlaxModelMixin.from_pretrained.example",$$slots:{default:[sa]},$$scope:{ctx:I}}}),Le=new J({props:{name:"save_pretrained",anchor:"diffusers.FlaxModelMixin.save_pretrained",parameters:[{name:"save_directory",val:": typing.Union[str, os.PathLike]"},{name:"params",val:": typing.Union[typing.Dict, flax.core.frozen_dict.FrozenDict]"},{name:"is_main_process",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.FlaxModelMixin.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Directory to which to save. Will be created if it doesn&#x2019;t exist.`,name:"save_directory"},{anchor:"diffusers.FlaxModelMixin.save_pretrained.params",description:`<strong>params</strong> (<code>Union[Dict, FrozenDict]</code>) &#x2014;
A <code>PyTree</code> of model parameters.`,name:"params"},{anchor:"diffusers.FlaxModelMixin.save_pretrained.is_main_process",description:`<strong>is_main_process</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether the process calling this is the main process or not. Useful when in distributed training like
TPUs and need to call this function on all processes. In this case, set <code>is_main_process=True</code> only on
the main process to avoid race conditions.`,name:"is_main_process"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/modeling_flax_utils.py#L487"}}),Ye=new J({props:{name:"class diffusers.FlaxDiffusionPipeline",anchor:"diffusers.FlaxDiffusionPipeline",parameters:[],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipeline_flax_utils.py#L93"}}),Ue=new J({props:{name:"from_pretrained",anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:": typing.Union[str, os.PathLike, NoneType]"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>repo id</em> of a pretrained pipeline hosted inside a model repo on
<a href="https://huggingface.co/" rel="nofollow">https://huggingface.co/</a> Valid repo ids have to be located under a user or organization name, like
<code>CompVis/ldm-text2im-large-256</code>.</li>
<li>A path to a <em>directory</em> containing pipeline weights saved using
<a href="/docs/diffusers/main/en/using-diffusers/loading#diffusers.FlaxDiffusionPipeline.save_pretrained">save_pretrained()</a>, e.g., <code>./my_pipeline_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.dtype",description:`<strong>dtype</strong> (<code>str</code> or <code>jnp.dtype</code>, <em>optional</em>) &#x2014;
Override the default <code>jnp.dtype</code> and load the model under this dtype. If <code>&quot;auto&quot;</code> is passed the dtype
will be automatically derived from the model&#x2019;s weights.`,name:"dtype"},{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (i.e., do not try to download the model).`,name:"local_files_only(bool,"},{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.mirror",description:`<strong>mirror</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Mirror source to accelerate downloads in China. If you are from China and have an accessibility
problem, you can set this option to resolve it. Note that we do not guarantee the timeliness or safety.
Please refer to the mirror site for more information. specify the folder name here.`,name:"mirror"},{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.kwargs",description:`<strong>kwargs</strong> (remaining dictionary of keyword arguments, <em>optional</em>) &#x2014;
Can be used to overwrite load - and saveable variables - <em>i.e.</em> the pipeline components - of the
specific pipeline class. The overwritten components are then directly passed to the pipelines
<code>__init__</code> method. See example below for more information.`,name:"kwargs"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipeline_flax_utils.py#L193"}}),he=new ao({props:{$$slots:{default:[da]},$$scope:{ctx:I}}}),ue=new ao({props:{$$slots:{default:[la]},$$scope:{ctx:I}}}),ge=new nr({props:{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.example",$$slots:{default:[ca]},$$scope:{ctx:I}}}),Oe=new J({props:{name:"save_pretrained",anchor:"diffusers.FlaxDiffusionPipeline.save_pretrained",parameters:[{name:"save_directory",val:": typing.Union[str, os.PathLike]"},{name:"params",val:": typing.Union[typing.Dict, flax.core.frozen_dict.FrozenDict]"}],parametersDescription:[{anchor:"diffusers.FlaxDiffusionPipeline.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Directory to which to save. Will be created if it doesn&#x2019;t exist.`,name:"save_directory"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipeline_flax_utils.py#L143"}}),{c(){l=i("meta"),g=f(),c=i("h1"),h=i("a"),u=i("span"),x(d.$$.fragment),m=f(),w=i("span"),X=t("Loading"),F=f(),L=i("p"),A=t("The core functionality for saving and loading systems in "),G=i("code"),O=t("Diffusers"),b=t(" is the HuggingFace Hub."),K=f(),E=i("div"),x(R.$$.fragment),oe=f(),so=i("p"),kt=t("Base class for all models."),Pt=f(),Re=i("p"),Je=i("a"),Mt=t("ModelMixin"),Et=t(` takes care of storing the configuration of the models and handles methods for loading, downloading
and saving models.`),Xt=f(),lo=i("ul"),Q=i("li"),co=i("strong"),Ft=t("config_name"),Tt=t(" ("),fo=i("code"),jt=t("str"),It=t(`) \u2014 A filename under which the model should be stored when calling
`),Ke=i("a"),qt=t("save_pretrained()"),Ct=t("."),Lt=f(),Y=i("div"),x(be.$$.fragment),At=f(),po=i("p"),Yt=t("Instantiate a pretrained pytorch model from a pre-trained model configuration."),Ut=f(),te=i("p"),Wt=t("The model is set in evaluation mode by default using "),mo=i("code"),St=t("model.eval()"),zt=t(` (Dropout modules are deactivated). To train
the model, you should first set it back in training mode with `),ho=i("code"),Ot=t("model.train()"),Vt=t("."),Nt=f(),we=i("p"),Bt=t("The warning "),uo=i("em"),Ht=t("Weights from XXX not initialized from pretrained model"),Gt=t(` means that the weights of XXX do not come
pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning
task.`),Rt=f(),ye=i("p"),Jt=t("The warning "),go=i("em"),Kt=t("Weights from XXX not used in YYY"),Qt=t(` means that the layer XXX is not used by YYY, therefore those
weights are discarded.`),Zt=f(),x(ne.$$.fragment),en=f(),x(ie.$$.fragment),on=f(),re=i("div"),x(xe.$$.fragment),tn=f(),$e=i("p"),nn=t(`Save a model and its configuration file to a directory, so that it can be re-loaded using the
`),_o=i("code"),rn=t("[from_pretrained()](/docs/diffusers/main/en/using-diffusers/loading#diffusers.ModelMixin.from_pretrained)"),an=t(" class method."),et=f(),T=i("div"),x(De.$$.fragment),sn=f(),vo=i("p"),dn=t("Base class for all models."),ln=f(),Qe=i("p"),Ze=i("a"),cn=t("DiffusionPipeline"),fn=t(` takes care of storing all components (models, schedulers, processors) for diffusion pipelines
and handles methods for loading, downloading and saving models as well as a few methods common to all pipelines to:`),pn=f(),ke=i("ul"),bo=i("li"),mn=t("move all PyTorch modules to the device of your choice"),hn=f(),wo=i("li"),un=t("enabling/disabling the progress bar for the denoising iteration"),gn=f(),yo=i("p"),_n=t("Class attributes:"),vn=f(),xo=i("ul"),ae=i("li"),$o=i("strong"),bn=t("config_name"),wn=t(" ("),Do=i("code"),yn=t("str"),xn=t(`) \u2014 name of the config file that will store the class and module names of all
components of the diffusion pipeline.`),$n=f(),q=i("div"),x(Pe.$$.fragment),Dn=f(),ko=i("p"),kn=t("Instantiate a PyTorch diffusion pipeline from pre-trained pipeline weights."),Pn=f(),Me=i("p"),Mn=t("The pipeline is set in evaluation mode by default using "),Po=i("code"),En=t("model.eval()"),Xn=t(" (Dropout modules are deactivated)."),Fn=f(),Ee=i("p"),Tn=t("The warning "),Mo=i("em"),jn=t("Weights from XXX not initialized from pretrained model"),In=t(` means that the weights of XXX do not come
pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning
task.`),qn=f(),Xe=i("p"),Cn=t("The warning "),Eo=i("em"),Ln=t("Weights from XXX not used in YYY"),An=t(` means that the layer XXX is not used by YYY, therefore those
weights are discarded.`),Yn=f(),x(se.$$.fragment),Un=f(),x(de.$$.fragment),Wn=f(),x(le.$$.fragment),Sn=f(),ce=i("div"),x(Fe.$$.fragment),zn=f(),Te=i("p"),On=t(`Save all variables of the pipeline that can be saved and loaded as well as the pipelines configuration file to
a directory. A pipeline variable can be saved and loaded if its class implements both a save and loading
method. The pipeline can easily be re-loaded using the `),Xo=i("code"),Vn=t("[from_pretrained()](/docs/diffusers/main/en/using-diffusers/loading#diffusers.DiffusionPipeline.from_pretrained)"),Nn=t(" class method."),ot=f(),V=i("div"),x(je.$$.fragment),Bn=f(),Fo=i("p"),Hn=t("Base class for all flax models."),Gn=f(),eo=i("p"),oo=i("a"),Rn=t("FlaxModelMixin"),Jn=t(` takes care of storing the configuration of the models and handles methods for loading,
downloading and saving models.`),Kn=f(),B=i("div"),x(Ie.$$.fragment),Qn=f(),To=i("p"),Zn=t("Instantiate a pretrained flax model from a pre-trained model configuration."),ei=f(),qe=i("p"),oi=t("The warning "),jo=i("em"),ti=t("Weights from XXX not initialized from pretrained model"),ni=t(` means that the weights of XXX do not come
pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning
task.`),ii=f(),Ce=i("p"),ri=t("The warning "),Io=i("em"),ai=t("Weights from XXX not used in YYY"),si=t(` means that the layer XXX is not used by YYY, therefore those
weights are discarded.`),di=f(),x(fe.$$.fragment),li=f(),pe=i("div"),x(Le.$$.fragment),ci=f(),Ae=i("p"),fi=t(`Save a model and its configuration file to a directory, so that it can be re-loaded using the
`),qo=i("code"),pi=t("[from_pretrained()](/docs/diffusers/main/en/using-diffusers/loading#diffusers.FlaxModelMixin.from_pretrained)"),mi=t(" class method"),tt=f(),j=i("div"),x(Ye.$$.fragment),hi=f(),Co=i("p"),ui=t("Base class for all models."),gi=f(),to=i("p"),no=i("a"),_i=t("FlaxDiffusionPipeline"),vi=t(` takes care of storing all components (models, schedulers, processors) for diffusion
pipelines and handles methods for loading, downloading and saving models as well as a few methods common to all
pipelines to:`),bi=f(),Lo=i("ul"),Ao=i("li"),wi=t("enabling/disabling the progress bar for the denoising iteration"),yi=f(),Yo=i("p"),xi=t("Class attributes:"),$i=f(),Uo=i("ul"),me=i("li"),Wo=i("strong"),Di=t("config_name"),ki=t(" ("),So=i("code"),Pi=t("str"),Mi=t(`) \u2014 name of the config file that will store the class and module names of all
components of the diffusion pipeline.`),Ei=f(),C=i("div"),x(Ue.$$.fragment),Xi=f(),zo=i("p"),Fi=t("Instantiate a Flax diffusion pipeline from pre-trained pipeline weights."),Ti=f(),We=i("p"),ji=t("The pipeline is set in evaluation mode by default using "),Oo=i("code"),Ii=t("model.eval()"),qi=t(" (Dropout modules are deactivated)."),Ci=f(),Se=i("p"),Li=t("The warning "),Vo=i("em"),Ai=t("Weights from XXX not initialized from pretrained model"),Yi=t(` means that the weights of XXX do not come
pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning
task.`),Ui=f(),ze=i("p"),Wi=t("The warning "),No=i("em"),Si=t("Weights from XXX not used in YYY"),zi=t(` means that the layer XXX is not used by YYY, therefore those
weights are discarded.`),Oi=f(),x(he.$$.fragment),Vi=f(),x(ue.$$.fragment),Ni=f(),x(ge.$$.fragment),Bi=f(),_e=i("div"),x(Oe.$$.fragment),Hi=f(),Ve=i("p"),Gi=t(`Save all variables of the pipeline that can be saved and loaded as well as the pipelines configuration file to
a directory. A pipeline variable can be saved and loaded if its class implements both a save and loading
method. The pipeline can easily be re-loaded using the `),Bo=i("code"),Ri=t("[from_pretrained()](/docs/diffusers/main/en/using-diffusers/loading#diffusers.FlaxDiffusionPipeline.from_pretrained)"),Ji=t(` class
method.`),nt=f(),ve=i("p"),Ki=t("Under further construction \u{1F6A7}, open a "),Ne=i("a"),Qi=t("PR"),Zi=t(" if you want to contribute!"),this.h()},l(s){const v=Zr('[data-svelte="svelte-1phssyn"]',document.head);l=r(v,"META",{name:!0,content:!0}),v.forEach(o),g=p(s),c=r(s,"H1",{class:!0});var Be=a(c);h=r(Be,"A",{id:!0,class:!0,href:!0});var Ho=a(h);u=r(Ho,"SPAN",{});var Go=a(u);$(d.$$.fragment,Go),Go.forEach(o),Ho.forEach(o),m=p(Be),w=r(Be,"SPAN",{});var Ro=a(w);X=n(Ro,"Loading"),Ro.forEach(o),Be.forEach(o),F=p(s),L=r(s,"P",{});var He=a(L);A=n(He,"The core functionality for saving and loading systems in "),G=r(He,"CODE",{});var Jo=a(G);O=n(Jo,"Diffusers"),Jo.forEach(o),b=n(He," is the HuggingFace Hub."),He.forEach(o),K=p(s),E=r(s,"DIV",{class:!0});var N=a(E);$(R.$$.fragment,N),oe=p(N),so=r(N,"P",{});var Ko=a(so);kt=n(Ko,"Base class for all models."),Ko.forEach(o),Pt=p(N),Re=r(N,"P",{});var io=a(Re);Je=r(io,"A",{href:!0});var ar=a(Je);Mt=n(ar,"ModelMixin"),ar.forEach(o),Et=n(io,` takes care of storing the configuration of the models and handles methods for loading, downloading
and saving models.`),io.forEach(o),Xt=p(N),lo=r(N,"UL",{});var sr=a(lo);Q=r(sr,"LI",{});var Ge=a(Q);co=r(Ge,"STRONG",{});var dr=a(co);Ft=n(dr,"config_name"),dr.forEach(o),Tt=n(Ge," ("),fo=r(Ge,"CODE",{});var lr=a(fo);jt=n(lr,"str"),lr.forEach(o),It=n(Ge,`) \u2014 A filename under which the model should be stored when calling
`),Ke=r(Ge,"A",{href:!0});var cr=a(Ke);qt=n(cr,"save_pretrained()"),cr.forEach(o),Ct=n(Ge,"."),Ge.forEach(o),sr.forEach(o),Lt=p(N),Y=r(N,"DIV",{class:!0});var H=a(Y);$(be.$$.fragment,H),At=p(H),po=r(H,"P",{});var fr=a(po);Yt=n(fr,"Instantiate a pretrained pytorch model from a pre-trained model configuration."),fr.forEach(o),Ut=p(H),te=r(H,"P",{});var ro=a(te);Wt=n(ro,"The model is set in evaluation mode by default using "),mo=r(ro,"CODE",{});var pr=a(mo);St=n(pr,"model.eval()"),pr.forEach(o),zt=n(ro,` (Dropout modules are deactivated). To train
the model, you should first set it back in training mode with `),ho=r(ro,"CODE",{});var mr=a(ho);Ot=n(mr,"model.train()"),mr.forEach(o),Vt=n(ro,"."),ro.forEach(o),Nt=p(H),we=r(H,"P",{});var rt=a(we);Bt=n(rt,"The warning "),uo=r(rt,"EM",{});var hr=a(uo);Ht=n(hr,"Weights from XXX not initialized from pretrained model"),hr.forEach(o),Gt=n(rt,` means that the weights of XXX do not come
pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning
task.`),rt.forEach(o),Rt=p(H),ye=r(H,"P",{});var at=a(ye);Jt=n(at,"The warning "),go=r(at,"EM",{});var ur=a(go);Kt=n(ur,"Weights from XXX not used in YYY"),ur.forEach(o),Qt=n(at,` means that the layer XXX is not used by YYY, therefore those
weights are discarded.`),at.forEach(o),Zt=p(H),$(ne.$$.fragment,H),en=p(H),$(ie.$$.fragment,H),H.forEach(o),on=p(N),re=r(N,"DIV",{class:!0});var st=a(re);$(xe.$$.fragment,st),tn=p(st),$e=r(st,"P",{});var dt=a($e);nn=n(dt,`Save a model and its configuration file to a directory, so that it can be re-loaded using the
`),_o=r(dt,"CODE",{});var gr=a(_o);rn=n(gr,"[from_pretrained()](/docs/diffusers/main/en/using-diffusers/loading#diffusers.ModelMixin.from_pretrained)"),gr.forEach(o),an=n(dt," class method."),dt.forEach(o),st.forEach(o),N.forEach(o),et=p(s),T=r(s,"DIV",{class:!0});var U=a(T);$(De.$$.fragment,U),sn=p(U),vo=r(U,"P",{});var _r=a(vo);dn=n(_r,"Base class for all models."),_r.forEach(o),ln=p(U),Qe=r(U,"P",{});var er=a(Qe);Ze=r(er,"A",{href:!0});var vr=a(Ze);cn=n(vr,"DiffusionPipeline"),vr.forEach(o),fn=n(er,` takes care of storing all components (models, schedulers, processors) for diffusion pipelines
and handles methods for loading, downloading and saving models as well as a few methods common to all pipelines to:`),er.forEach(o),pn=p(U),ke=r(U,"UL",{});var lt=a(ke);bo=r(lt,"LI",{});var br=a(bo);mn=n(br,"move all PyTorch modules to the device of your choice"),br.forEach(o),hn=p(lt),wo=r(lt,"LI",{});var wr=a(wo);un=n(wr,"enabling/disabling the progress bar for the denoising iteration"),wr.forEach(o),lt.forEach(o),gn=p(U),yo=r(U,"P",{});var yr=a(yo);_n=n(yr,"Class attributes:"),yr.forEach(o),vn=p(U),xo=r(U,"UL",{});var xr=a(xo);ae=r(xr,"LI",{});var Qo=a(ae);$o=r(Qo,"STRONG",{});var $r=a($o);bn=n($r,"config_name"),$r.forEach(o),wn=n(Qo," ("),Do=r(Qo,"CODE",{});var Dr=a(Do);yn=n(Dr,"str"),Dr.forEach(o),xn=n(Qo,`) \u2014 name of the config file that will store the class and module names of all
components of the diffusion pipeline.`),Qo.forEach(o),xr.forEach(o),$n=p(U),q=r(U,"DIV",{class:!0});var W=a(q);$(Pe.$$.fragment,W),Dn=p(W),ko=r(W,"P",{});var kr=a(ko);kn=n(kr,"Instantiate a PyTorch diffusion pipeline from pre-trained pipeline weights."),kr.forEach(o),Pn=p(W),Me=r(W,"P",{});var ct=a(Me);Mn=n(ct,"The pipeline is set in evaluation mode by default using "),Po=r(ct,"CODE",{});var Pr=a(Po);En=n(Pr,"model.eval()"),Pr.forEach(o),Xn=n(ct," (Dropout modules are deactivated)."),ct.forEach(o),Fn=p(W),Ee=r(W,"P",{});var ft=a(Ee);Tn=n(ft,"The warning "),Mo=r(ft,"EM",{});var Mr=a(Mo);jn=n(Mr,"Weights from XXX not initialized from pretrained model"),Mr.forEach(o),In=n(ft,` means that the weights of XXX do not come
pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning
task.`),ft.forEach(o),qn=p(W),Xe=r(W,"P",{});var pt=a(Xe);Cn=n(pt,"The warning "),Eo=r(pt,"EM",{});var Er=a(Eo);Ln=n(Er,"Weights from XXX not used in YYY"),Er.forEach(o),An=n(pt,` means that the layer XXX is not used by YYY, therefore those
weights are discarded.`),pt.forEach(o),Yn=p(W),$(se.$$.fragment,W),Un=p(W),$(de.$$.fragment,W),Wn=p(W),$(le.$$.fragment,W),W.forEach(o),Sn=p(U),ce=r(U,"DIV",{class:!0});var mt=a(ce);$(Fe.$$.fragment,mt),zn=p(mt),Te=r(mt,"P",{});var ht=a(Te);On=n(ht,`Save all variables of the pipeline that can be saved and loaded as well as the pipelines configuration file to
a directory. A pipeline variable can be saved and loaded if its class implements both a save and loading
method. The pipeline can easily be re-loaded using the `),Xo=r(ht,"CODE",{});var Xr=a(Xo);Vn=n(Xr,"[from_pretrained()](/docs/diffusers/main/en/using-diffusers/loading#diffusers.DiffusionPipeline.from_pretrained)"),Xr.forEach(o),Nn=n(ht," class method."),ht.forEach(o),mt.forEach(o),U.forEach(o),ot=p(s),V=r(s,"DIV",{class:!0});var Z=a(V);$(je.$$.fragment,Z),Bn=p(Z),Fo=r(Z,"P",{});var Fr=a(Fo);Hn=n(Fr,"Base class for all flax models."),Fr.forEach(o),Gn=p(Z),eo=r(Z,"P",{});var or=a(eo);oo=r(or,"A",{href:!0});var Tr=a(oo);Rn=n(Tr,"FlaxModelMixin"),Tr.forEach(o),Jn=n(or,` takes care of storing the configuration of the models and handles methods for loading,
downloading and saving models.`),or.forEach(o),Kn=p(Z),B=r(Z,"DIV",{class:!0});var ee=a(B);$(Ie.$$.fragment,ee),Qn=p(ee),To=r(ee,"P",{});var jr=a(To);Zn=n(jr,"Instantiate a pretrained flax model from a pre-trained model configuration."),jr.forEach(o),ei=p(ee),qe=r(ee,"P",{});var ut=a(qe);oi=n(ut,"The warning "),jo=r(ut,"EM",{});var Ir=a(jo);ti=n(Ir,"Weights from XXX not initialized from pretrained model"),Ir.forEach(o),ni=n(ut,` means that the weights of XXX do not come
pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning
task.`),ut.forEach(o),ii=p(ee),Ce=r(ee,"P",{});var gt=a(Ce);ri=n(gt,"The warning "),Io=r(gt,"EM",{});var qr=a(Io);ai=n(qr,"Weights from XXX not used in YYY"),qr.forEach(o),si=n(gt,` means that the layer XXX is not used by YYY, therefore those
weights are discarded.`),gt.forEach(o),di=p(ee),$(fe.$$.fragment,ee),ee.forEach(o),li=p(Z),pe=r(Z,"DIV",{class:!0});var _t=a(pe);$(Le.$$.fragment,_t),ci=p(_t),Ae=r(_t,"P",{});var vt=a(Ae);fi=n(vt,`Save a model and its configuration file to a directory, so that it can be re-loaded using the
`),qo=r(vt,"CODE",{});var Cr=a(qo);pi=n(Cr,"[from_pretrained()](/docs/diffusers/main/en/using-diffusers/loading#diffusers.FlaxModelMixin.from_pretrained)"),Cr.forEach(o),mi=n(vt," class method"),vt.forEach(o),_t.forEach(o),Z.forEach(o),tt=p(s),j=r(s,"DIV",{class:!0});var S=a(j);$(Ye.$$.fragment,S),hi=p(S),Co=r(S,"P",{});var Lr=a(Co);ui=n(Lr,"Base class for all models."),Lr.forEach(o),gi=p(S),to=r(S,"P",{});var tr=a(to);no=r(tr,"A",{href:!0});var Ar=a(no);_i=n(Ar,"FlaxDiffusionPipeline"),Ar.forEach(o),vi=n(tr,` takes care of storing all components (models, schedulers, processors) for diffusion
pipelines and handles methods for loading, downloading and saving models as well as a few methods common to all
pipelines to:`),tr.forEach(o),bi=p(S),Lo=r(S,"UL",{});var Yr=a(Lo);Ao=r(Yr,"LI",{});var Ur=a(Ao);wi=n(Ur,"enabling/disabling the progress bar for the denoising iteration"),Ur.forEach(o),Yr.forEach(o),yi=p(S),Yo=r(S,"P",{});var Wr=a(Yo);xi=n(Wr,"Class attributes:"),Wr.forEach(o),$i=p(S),Uo=r(S,"UL",{});var Sr=a(Uo);me=r(Sr,"LI",{});var Zo=a(me);Wo=r(Zo,"STRONG",{});var zr=a(Wo);Di=n(zr,"config_name"),zr.forEach(o),ki=n(Zo," ("),So=r(Zo,"CODE",{});var Or=a(So);Pi=n(Or,"str"),Or.forEach(o),Mi=n(Zo,`) \u2014 name of the config file that will store the class and module names of all
components of the diffusion pipeline.`),Zo.forEach(o),Sr.forEach(o),Ei=p(S),C=r(S,"DIV",{class:!0});var z=a(C);$(Ue.$$.fragment,z),Xi=p(z),zo=r(z,"P",{});var Vr=a(zo);Fi=n(Vr,"Instantiate a Flax diffusion pipeline from pre-trained pipeline weights."),Vr.forEach(o),Ti=p(z),We=r(z,"P",{});var bt=a(We);ji=n(bt,"The pipeline is set in evaluation mode by default using "),Oo=r(bt,"CODE",{});var Nr=a(Oo);Ii=n(Nr,"model.eval()"),Nr.forEach(o),qi=n(bt," (Dropout modules are deactivated)."),bt.forEach(o),Ci=p(z),Se=r(z,"P",{});var wt=a(Se);Li=n(wt,"The warning "),Vo=r(wt,"EM",{});var Br=a(Vo);Ai=n(Br,"Weights from XXX not initialized from pretrained model"),Br.forEach(o),Yi=n(wt,` means that the weights of XXX do not come
pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning
task.`),wt.forEach(o),Ui=p(z),ze=r(z,"P",{});var yt=a(ze);Wi=n(yt,"The warning "),No=r(yt,"EM",{});var Hr=a(No);Si=n(Hr,"Weights from XXX not used in YYY"),Hr.forEach(o),zi=n(yt,` means that the layer XXX is not used by YYY, therefore those
weights are discarded.`),yt.forEach(o),Oi=p(z),$(he.$$.fragment,z),Vi=p(z),$(ue.$$.fragment,z),Ni=p(z),$(ge.$$.fragment,z),z.forEach(o),Bi=p(S),_e=r(S,"DIV",{class:!0});var xt=a(_e);$(Oe.$$.fragment,xt),Hi=p(xt),Ve=r(xt,"P",{});var $t=a(Ve);Gi=n($t,`Save all variables of the pipeline that can be saved and loaded as well as the pipelines configuration file to
a directory. A pipeline variable can be saved and loaded if its class implements both a save and loading
method. The pipeline can easily be re-loaded using the `),Bo=r($t,"CODE",{});var Gr=a(Bo);Ri=n(Gr,"[from_pretrained()](/docs/diffusers/main/en/using-diffusers/loading#diffusers.FlaxDiffusionPipeline.from_pretrained)"),Gr.forEach(o),Ji=n($t,` class
method.`),$t.forEach(o),xt.forEach(o),S.forEach(o),nt=p(s),ve=r(s,"P",{});var Dt=a(ve);Ki=n(Dt,"Under further construction \u{1F6A7}, open a "),Ne=r(Dt,"A",{href:!0,rel:!0});var Rr=a(Ne);Qi=n(Rr,"PR"),Rr.forEach(o),Zi=n(Dt," if you want to contribute!"),Dt.forEach(o),this.h()},h(){_(l,"name","hf:doc:metadata"),_(l,"content",JSON.stringify(pa)),_(h,"id","diffusers.ModelMixin"),_(h,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(h,"href","#diffusers.ModelMixin"),_(c,"class","relative group"),_(Je,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.ModelMixin"),_(Ke,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.ModelMixin.save_pretrained"),_(Y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(re,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(E,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(Ze,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.DiffusionPipeline"),_(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(ce,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(T,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(oo,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.FlaxModelMixin"),_(B,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(pe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(V,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(no,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.FlaxDiffusionPipeline"),_(C,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(_e,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(j,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(Ne,"href","https://github.com/huggingface/diffusers/compare"),_(Ne,"rel","nofollow")},m(s,v){e(document.head,l),y(s,g,v),y(s,c,v),e(c,h),e(h,u),D(d,u,null),e(c,m),e(c,w),e(w,X),y(s,F,v),y(s,L,v),e(L,A),e(L,G),e(G,O),e(L,b),y(s,K,v),y(s,E,v),D(R,E,null),e(E,oe),e(E,so),e(so,kt),e(E,Pt),e(E,Re),e(Re,Je),e(Je,Mt),e(Re,Et),e(E,Xt),e(E,lo),e(lo,Q),e(Q,co),e(co,Ft),e(Q,Tt),e(Q,fo),e(fo,jt),e(Q,It),e(Q,Ke),e(Ke,qt),e(Q,Ct),e(E,Lt),e(E,Y),D(be,Y,null),e(Y,At),e(Y,po),e(po,Yt),e(Y,Ut),e(Y,te),e(te,Wt),e(te,mo),e(mo,St),e(te,zt),e(te,ho),e(ho,Ot),e(te,Vt),e(Y,Nt),e(Y,we),e(we,Bt),e(we,uo),e(uo,Ht),e(we,Gt),e(Y,Rt),e(Y,ye),e(ye,Jt),e(ye,go),e(go,Kt),e(ye,Qt),e(Y,Zt),D(ne,Y,null),e(Y,en),D(ie,Y,null),e(E,on),e(E,re),D(xe,re,null),e(re,tn),e(re,$e),e($e,nn),e($e,_o),e(_o,rn),e($e,an),y(s,et,v),y(s,T,v),D(De,T,null),e(T,sn),e(T,vo),e(vo,dn),e(T,ln),e(T,Qe),e(Qe,Ze),e(Ze,cn),e(Qe,fn),e(T,pn),e(T,ke),e(ke,bo),e(bo,mn),e(ke,hn),e(ke,wo),e(wo,un),e(T,gn),e(T,yo),e(yo,_n),e(T,vn),e(T,xo),e(xo,ae),e(ae,$o),e($o,bn),e(ae,wn),e(ae,Do),e(Do,yn),e(ae,xn),e(T,$n),e(T,q),D(Pe,q,null),e(q,Dn),e(q,ko),e(ko,kn),e(q,Pn),e(q,Me),e(Me,Mn),e(Me,Po),e(Po,En),e(Me,Xn),e(q,Fn),e(q,Ee),e(Ee,Tn),e(Ee,Mo),e(Mo,jn),e(Ee,In),e(q,qn),e(q,Xe),e(Xe,Cn),e(Xe,Eo),e(Eo,Ln),e(Xe,An),e(q,Yn),D(se,q,null),e(q,Un),D(de,q,null),e(q,Wn),D(le,q,null),e(T,Sn),e(T,ce),D(Fe,ce,null),e(ce,zn),e(ce,Te),e(Te,On),e(Te,Xo),e(Xo,Vn),e(Te,Nn),y(s,ot,v),y(s,V,v),D(je,V,null),e(V,Bn),e(V,Fo),e(Fo,Hn),e(V,Gn),e(V,eo),e(eo,oo),e(oo,Rn),e(eo,Jn),e(V,Kn),e(V,B),D(Ie,B,null),e(B,Qn),e(B,To),e(To,Zn),e(B,ei),e(B,qe),e(qe,oi),e(qe,jo),e(jo,ti),e(qe,ni),e(B,ii),e(B,Ce),e(Ce,ri),e(Ce,Io),e(Io,ai),e(Ce,si),e(B,di),D(fe,B,null),e(V,li),e(V,pe),D(Le,pe,null),e(pe,ci),e(pe,Ae),e(Ae,fi),e(Ae,qo),e(qo,pi),e(Ae,mi),y(s,tt,v),y(s,j,v),D(Ye,j,null),e(j,hi),e(j,Co),e(Co,ui),e(j,gi),e(j,to),e(to,no),e(no,_i),e(to,vi),e(j,bi),e(j,Lo),e(Lo,Ao),e(Ao,wi),e(j,yi),e(j,Yo),e(Yo,xi),e(j,$i),e(j,Uo),e(Uo,me),e(me,Wo),e(Wo,Di),e(me,ki),e(me,So),e(So,Pi),e(me,Mi),e(j,Ei),e(j,C),D(Ue,C,null),e(C,Xi),e(C,zo),e(zo,Fi),e(C,Ti),e(C,We),e(We,ji),e(We,Oo),e(Oo,Ii),e(We,qi),e(C,Ci),e(C,Se),e(Se,Li),e(Se,Vo),e(Vo,Ai),e(Se,Yi),e(C,Ui),e(C,ze),e(ze,Wi),e(ze,No),e(No,Si),e(ze,zi),e(C,Oi),D(he,C,null),e(C,Vi),D(ue,C,null),e(C,Ni),D(ge,C,null),e(j,Bi),e(j,_e),D(Oe,_e,null),e(_e,Hi),e(_e,Ve),e(Ve,Gi),e(Ve,Bo),e(Bo,Ri),e(Ve,Ji),y(s,nt,v),y(s,ve,v),e(ve,Ki),e(ve,Ne),e(Ne,Qi),e(ve,Zi),it=!0},p(s,[v]){const Be={};v&2&&(Be.$$scope={dirty:v,ctx:s}),ne.$set(Be);const Ho={};v&2&&(Ho.$$scope={dirty:v,ctx:s}),ie.$set(Ho);const Go={};v&2&&(Go.$$scope={dirty:v,ctx:s}),se.$set(Go);const Ro={};v&2&&(Ro.$$scope={dirty:v,ctx:s}),de.$set(Ro);const He={};v&2&&(He.$$scope={dirty:v,ctx:s}),le.$set(He);const Jo={};v&2&&(Jo.$$scope={dirty:v,ctx:s}),fe.$set(Jo);const N={};v&2&&(N.$$scope={dirty:v,ctx:s}),he.$set(N);const Ko={};v&2&&(Ko.$$scope={dirty:v,ctx:s}),ue.$set(Ko);const io={};v&2&&(io.$$scope={dirty:v,ctx:s}),ge.$set(io)},i(s){it||(k(d.$$.fragment,s),k(R.$$.fragment,s),k(be.$$.fragment,s),k(ne.$$.fragment,s),k(ie.$$.fragment,s),k(xe.$$.fragment,s),k(De.$$.fragment,s),k(Pe.$$.fragment,s),k(se.$$.fragment,s),k(de.$$.fragment,s),k(le.$$.fragment,s),k(Fe.$$.fragment,s),k(je.$$.fragment,s),k(Ie.$$.fragment,s),k(fe.$$.fragment,s),k(Le.$$.fragment,s),k(Ye.$$.fragment,s),k(Ue.$$.fragment,s),k(he.$$.fragment,s),k(ue.$$.fragment,s),k(ge.$$.fragment,s),k(Oe.$$.fragment,s),it=!0)},o(s){P(d.$$.fragment,s),P(R.$$.fragment,s),P(be.$$.fragment,s),P(ne.$$.fragment,s),P(ie.$$.fragment,s),P(xe.$$.fragment,s),P(De.$$.fragment,s),P(Pe.$$.fragment,s),P(se.$$.fragment,s),P(de.$$.fragment,s),P(le.$$.fragment,s),P(Fe.$$.fragment,s),P(je.$$.fragment,s),P(Ie.$$.fragment,s),P(fe.$$.fragment,s),P(Le.$$.fragment,s),P(Ye.$$.fragment,s),P(Ue.$$.fragment,s),P(he.$$.fragment,s),P(ue.$$.fragment,s),P(ge.$$.fragment,s),P(Oe.$$.fragment,s),it=!1},d(s){o(l),s&&o(g),s&&o(c),M(d),s&&o(F),s&&o(L),s&&o(K),s&&o(E),M(R),M(be),M(ne),M(ie),M(xe),s&&o(et),s&&o(T),M(De),M(Pe),M(se),M(de),M(le),M(Fe),s&&o(ot),s&&o(V),M(je),M(Ie),M(fe),M(Le),s&&o(tt),s&&o(j),M(Ye),M(Ue),M(he),M(ue),M(ge),M(Oe),s&&o(nt),s&&o(ve)}}}const pa={local:"diffusers.ModelMixin",title:"Loading"};function ma(I){return ea(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class wa extends Jr{constructor(l){super();Kr(this,l,ma,fa,Qr,{})}}export{wa as default,pa as metadata};
