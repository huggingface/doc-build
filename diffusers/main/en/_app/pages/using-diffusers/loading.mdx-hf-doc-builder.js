import{S as h5,i as m5,s as g5,e as n,k as d,w as v,t as s,M as _5,c as r,d as t,m as f,a,x as b,h as i,b as c,N as v5,G as e,g as p,y as w,q as y,o as E,B as D,v as b5,L as Aw}from"../../chunks/vendor-hf-doc-builder.js";import{T as $n}from"../../chunks/Tip-hf-doc-builder.js";import{D as $e}from"../../chunks/Docstring-hf-doc-builder.js";import{C as j}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as wo}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as Sw}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function w5(L){let h,x,m,_,$,u,g,k;return{c(){h=n("p"),x=s("It is required to be logged in ("),m=n("code"),_=s("huggingface-cli login"),$=s(") when you want to use private or "),u=n("a"),g=s(`gated
models`),k=s("."),this.h()},l(T){h=r(T,"P",{});var I=a(h);x=i(I,"It is required to be logged in ("),m=r(I,"CODE",{});var X=a(m);_=i(X,"huggingface-cli login"),X.forEach(t),$=i(I,") when you want to use private or "),u=r(I,"A",{href:!0,rel:!0});var z=a(u);g=i(z,`gated
models`),z.forEach(t),k=i(I,"."),I.forEach(t),this.h()},h(){c(u,"href","https://huggingface.co/docs/hub/models-gated#gated-models"),c(u,"rel","nofollow")},m(T,I){p(T,h,I),e(h,x),e(h,m),e(m,_),e(h,$),e(h,u),e(u,g),e(h,k)},d(T){T&&t(h)}}}function y5(L){let h,x,m,_,$;return{c(){h=n("p"),x=s("Activate the special "),m=n("a"),_=s("\u201Coffline-mode\u201D"),$=s(` to use
this method in a firewalled environment.`),this.h()},l(u){h=r(u,"P",{});var g=a(h);x=i(g,"Activate the special "),m=r(g,"A",{href:!0,rel:!0});var k=a(m);_=i(k,"\u201Coffline-mode\u201D"),k.forEach(t),$=i(g,` to use
this method in a firewalled environment.`),g.forEach(t),this.h()},h(){c(m,"href","https://huggingface.co/diffusers/installation.html#offline-mode"),c(m,"rel","nofollow")},m(u,g){p(u,h,g),e(h,x),e(h,m),e(m,_),e(h,$)},d(u){u&&t(h)}}}function E5(L){let h,x,m,_,$,u,g,k,T,I,X,z,ce;return{c(){h=n("p"),x=s("It is required to be logged in ("),m=n("code"),_=s("huggingface-cli login"),$=s(") when you want to use private or "),u=n("a"),g=s(`gated
models`),k=s(", "),T=n("em"),I=s("e.g."),X=d(),z=n("code"),ce=s('"runwayml/stable-diffusion-v1-5"'),this.h()},l(J){h=r(J,"P",{});var P=a(h);x=i(P,"It is required to be logged in ("),m=r(P,"CODE",{});var Me=a(m);_=i(Me,"huggingface-cli login"),Me.forEach(t),$=i(P,") when you want to use private or "),u=r(P,"A",{href:!0,rel:!0});var he=a(u);g=i(he,`gated
models`),he.forEach(t),k=i(P,", "),T=r(P,"EM",{});var io=a(T);I=i(io,"e.g."),io.forEach(t),X=f(P),z=r(P,"CODE",{});var je=a(z);ce=i(je,'"runwayml/stable-diffusion-v1-5"'),je.forEach(t),P.forEach(t),this.h()},h(){c(u,"href","https://huggingface.co/docs/hub/models-gated#gated-models"),c(u,"rel","nofollow")},m(J,P){p(J,h,P),e(h,x),e(h,m),e(m,_),e(h,$),e(h,u),e(u,g),e(h,k),e(h,T),e(T,I),e(h,X),e(h,z),e(z,ce)},d(J){J&&t(h)}}}function D5(L){let h,x,m,_,$;return{c(){h=n("p"),x=s("Activate the special "),m=n("a"),_=s("\u201Coffline-mode\u201D"),$=s(` to use
this method in a firewalled environment.`),this.h()},l(u){h=r(u,"P",{});var g=a(h);x=i(g,"Activate the special "),m=r(g,"A",{href:!0,rel:!0});var k=a(m);_=i(k,"\u201Coffline-mode\u201D"),k.forEach(t),$=i(g,` to use
this method in a firewalled environment.`),g.forEach(t),this.h()},h(){c(m,"href","https://huggingface.co/diffusers/installation.html#offline-mode"),c(m,"rel","nofollow")},m(u,g){p(u,h,g),e(h,x),e(h,m),e(m,_),e(h,$)},d(u){u&&t(h)}}}function $5(L){let h,x,m,_,$;return _=new j({props:{code:`from diffusers import DiffusionPipeline

# Download pipeline from huggingface.co and cache.
pipeline = DiffusionPipeline.from_pretrained("CompVis/ldm-text2im-large-256")

# Download pipeline that requires an authorization token
# For more information on access tokens, please refer to this section
# of the documentation](https://huggingface.co/docs/hub/security-tokens)
pipeline = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")

# Download pipeline, but overwrite scheduler
from diffusers import LMSDiscreteScheduler

scheduler = LMSDiscreteScheduler.from_config("runwayml/stable-diffusion-v1-5", subfolder="scheduler")
pipeline = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", scheduler=scheduler)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download pipeline from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pipeline = DiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;CompVis/ldm-text2im-large-256&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download pipeline that requires an authorization token</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># For more information on access tokens, please refer to this section</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># of the documentation](https://huggingface.co/docs/hub/security-tokens)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pipeline = DiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download pipeline, but overwrite scheduler</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> LMSDiscreteScheduler

<span class="hljs-meta">&gt;&gt;&gt; </span>scheduler = LMSDiscreteScheduler.from_config(<span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>, subfolder=<span class="hljs-string">&quot;scheduler&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>pipeline = DiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>, scheduler=scheduler)`}}),{c(){h=n("p"),x=s("Examples:"),m=d(),v(_.$$.fragment)},l(u){h=r(u,"P",{});var g=a(h);x=i(g,"Examples:"),g.forEach(t),m=f(u),b(_.$$.fragment,u)},m(u,g){p(u,h,g),e(h,x),p(u,m,g),w(_,u,g),$=!0},p:Aw,i(u){$||(y(_.$$.fragment,u),$=!0)},o(u){E(_.$$.fragment,u),$=!1},d(u){u&&t(h),u&&t(m),D(_,u)}}}function x5(L){let h,x,m,_,$;return _=new j({props:{code:`from diffusers import FlaxUNet2DConditionModel

# Download model and configuration from huggingface.co and cache.
model, params = FlaxUNet2DConditionModel.from_pretrained("runwayml/stable-diffusion-v1-5")
# Model was saved using *save_pretrained('./test/saved_model/')* (for example purposes, not runnable).
model, params = FlaxUNet2DConditionModel.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> FlaxUNet2DConditionModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model, params = FlaxUNet2DConditionModel.from_pretrained(<span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Model was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)* (for example purposes, not runnable).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model, params = FlaxUNet2DConditionModel.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){h=n("p"),x=s("Examples:"),m=d(),v(_.$$.fragment)},l(u){h=r(u,"P",{});var g=a(h);x=i(g,"Examples:"),g.forEach(t),m=f(u),b(_.$$.fragment,u)},m(u,g){p(u,h,g),e(h,x),p(u,m,g),w(_,u,g),$=!0},p:Aw,i(u){$||(y(_.$$.fragment,u),$=!0)},o(u){E(_.$$.fragment,u),$=!1},d(u){u&&t(h),u&&t(m),D(_,u)}}}function P5(L){let h,x,m,_,$,u,g,k,T,I,X,z,ce;return{c(){h=n("p"),x=s("It is required to be logged in ("),m=n("code"),_=s("huggingface-cli login"),$=s(") when you want to use private or "),u=n("a"),g=s(`gated
models`),k=s(", "),T=n("em"),I=s("e.g."),X=d(),z=n("code"),ce=s('"runwayml/stable-diffusion-v1-5"'),this.h()},l(J){h=r(J,"P",{});var P=a(h);x=i(P,"It is required to be logged in ("),m=r(P,"CODE",{});var Me=a(m);_=i(Me,"huggingface-cli login"),Me.forEach(t),$=i(P,") when you want to use private or "),u=r(P,"A",{href:!0,rel:!0});var he=a(u);g=i(he,`gated
models`),he.forEach(t),k=i(P,", "),T=r(P,"EM",{});var io=a(T);I=i(io,"e.g."),io.forEach(t),X=f(P),z=r(P,"CODE",{});var je=a(z);ce=i(je,'"runwayml/stable-diffusion-v1-5"'),je.forEach(t),P.forEach(t),this.h()},h(){c(u,"href","https://huggingface.co/docs/hub/models-gated#gated-models"),c(u,"rel","nofollow")},m(J,P){p(J,h,P),e(h,x),e(h,m),e(m,_),e(h,$),e(h,u),e(u,g),e(h,k),e(h,T),e(T,I),e(h,X),e(h,z),e(z,ce)},d(J){J&&t(h)}}}function k5(L){let h,x,m,_,$;return{c(){h=n("p"),x=s("Activate the special "),m=n("a"),_=s("\u201Coffline-mode\u201D"),$=s(` to use
this method in a firewalled environment.`),this.h()},l(u){h=r(u,"P",{});var g=a(h);x=i(g,"Activate the special "),m=r(g,"A",{href:!0,rel:!0});var k=a(m);_=i(k,"\u201Coffline-mode\u201D"),k.forEach(t),$=i(g,` to use
this method in a firewalled environment.`),g.forEach(t),this.h()},h(){c(m,"href","https://huggingface.co/diffusers/installation.html#offline-mode"),c(m,"rel","nofollow")},m(u,g){p(u,h,g),e(h,x),e(h,m),e(m,_),e(h,$)},d(u){u&&t(h)}}}function M5(L){let h,x,m,_,$;return _=new j({props:{code:`from diffusers import FlaxDiffusionPipeline

# Download pipeline from huggingface.co and cache.
pipeline = FlaxDiffusionPipeline.from_pretrained("CompVis/ldm-text2im-large-256")

# Download pipeline that requires an authorization token
# For more information on access tokens, please refer to this section
# of the documentation](https://huggingface.co/docs/hub/security-tokens)
pipeline = FlaxDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")

# Download pipeline, but overwrite scheduler
from diffusers import LMSDiscreteScheduler

scheduler = LMSDiscreteScheduler.from_config("runwayml/stable-diffusion-v1-5", subfolder="scheduler")
pipeline = FlaxDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", scheduler=scheduler)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> FlaxDiffusionPipeline

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download pipeline from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pipeline = FlaxDiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;CompVis/ldm-text2im-large-256&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download pipeline that requires an authorization token</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># For more information on access tokens, please refer to this section</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># of the documentation](https://huggingface.co/docs/hub/security-tokens)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pipeline = FlaxDiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download pipeline, but overwrite scheduler</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> LMSDiscreteScheduler

<span class="hljs-meta">&gt;&gt;&gt; </span>scheduler = LMSDiscreteScheduler.from_config(<span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>, subfolder=<span class="hljs-string">&quot;scheduler&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>pipeline = FlaxDiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>, scheduler=scheduler)`}}),{c(){h=n("p"),x=s("Examples:"),m=d(),v(_.$$.fragment)},l(u){h=r(u,"P",{});var g=a(h);x=i(g,"Examples:"),g.forEach(t),m=f(u),b(_.$$.fragment,u)},m(u,g){p(u,h,g),e(h,x),p(u,m,g),w(_,u,g),$=!0},p:Aw,i(u){$||(y(_.$$.fragment,u),$=!0)},o(u){E(_.$$.fragment,u),$=!1},d(u){u&&t(h),u&&t(m),D(_,u)}}}function j5(L){let h,x,m,_,$,u,g,k,T,I,X,z,ce,J,P,Me,he,io,je,qe,dt,xn,Wf,Hf,Bs,Bf,Rf,ft,Pn,Gf,Kf,Rs,Jf,Qf,ct,kn,Zf,ec,Gs,oc,Tl,no,yo,Mn,pt,tc,jn,sc,Il,me,ic,Ks,nc,rc,ut,ac,lc,ht,dc,fc,Sl,mt,Al,N,cc,Js,pc,uc,qn,hc,mc,Qs,gc,_c,Tn,vc,bc,Eo,wc,In,yc,Ec,Dc,Sn,$c,xc,Ll,Do,Pc,Zs,kc,Mc,Cl,gt,Ol,q,jc,An,qc,Tc,Ln,Ic,Sc,Cn,Ac,Lc,On,Cc,Oc,ei,Fc,Xc,oi,zc,Nc,_t,Uc,Vc,ti,Yc,Wc,Fl,ro,$o,Fn,vt,Hc,Xn,Bc,Xl,Te,Rc,zn,Gc,Kc,bt,Nn,Jc,Qc,zl,wt,Nl,Ie,Zc,Un,ep,op,yt,tp,sp,Ul,Et,Vl,Se,ip,Vn,np,rp,Dt,ap,lp,Yl,xe,dp,fp,si,Lw,cp,pp,Wl,ii,up,Hl,$t,Bl,oe,hp,xt,mp,gp,Yn,_p,vp,Wn,bp,wp,Hn,yp,Ep,Rl,Pt,Gl,ni,Dp,Kl,ao,xo,Bn,kt,$p,Rn,xp,Jl,ri,Pp,Ql,Ae,kp,ai,Mp,jp,Mt,qp,Tp,Zl,Le,Ip,jt,Gn,Sp,Ap,qt,Lp,Cp,ed,Tt,od,Ce,Op,Kn,Fp,Xp,Jn,zp,Np,td,It,sd,Oe,Up,Qn,Vp,Yp,li,Wp,Hp,id,lo,Po,Zn,St,Bp,er,Rp,nd,te,Gp,or,Kp,Jp,At,Qp,Zp,di,eu,ou,fi,tu,su,rd,Pe,tr,iu,nu,ci,ru,au,pi,lu,du,ad,Lt,ld,ui,fu,dd,Fe,Ct,cu,hi,pu,uu,hu,ko,mu,sr,gu,_u,Ot,vu,bu,U,wu,ir,yu,Eu,mi,Du,$u,gi,xu,Pu,nr,ku,Mu,rr,ju,qu,ar,Tu,Iu,lr,Su,fd,ge,Au,dr,Lu,Cu,Ft,Ou,Fu,fr,Xu,zu,cd,Xe,Nu,cr,Uu,Vu,pr,Yu,Wu,pd,Xt,ud,se,Hu,ur,Bu,Ru,zt,hr,Gu,Ku,_i,Ju,Qu,vi,Zu,eh,hd,Nt,md,Mo,oh,bi,th,sh,gd,fo,jo,mr,Ut,ih,gr,nh,_d,qo,rh,wi,ah,lh,vd,To,pe,dh,_r,fh,ch,vr,ph,uh,yi,hh,mh,br,gh,_h,vh,ue,bh,wr,wh,yh,Ei,Eh,Dh,yr,$h,xh,Er,Ph,kh,bd,ie,Mh,Dr,jh,qh,Di,Th,Ih,Vt,$r,Sh,Ah,xr,Lh,Ch,wd,Yt,yd,Wt,Pr,Oh,Fh,Ed,Ht,Dd,ze,Xh,$i,zh,Nh,kr,Uh,Vh,$d,ne,co,Mr,Yh,Wh,jr,Hh,Bh,Bt,Rh,Gh,Rt,qr,Kh,Jh,xi,Qh,Zh,po,Tr,em,om,Ir,tm,sm,Io,im,Sr,nm,rm,Gt,Ar,am,lm,Pi,dm,fm,Kt,Lr,cm,pm,ki,um,xd,_e,hm,Cr,mm,gm,Jt,Or,_m,vm,Fr,bm,wm,Pd,Qt,kd,M,ym,Xr,Em,Dm,zr,$m,xm,Nr,Pm,km,Ur,Mm,jm,Vr,qm,Tm,Yr,Im,Sm,Wr,Am,Lm,Hr,Cm,Om,Br,Fm,Xm,Md,So,Rr,zm,Nm,Gr,Um,jd,Ne,Vm,Kr,Ym,Wm,Jr,Hm,Bm,qd,Zt,Td,Ue,Ao,Qr,Rm,Gm,Zr,Km,Jm,Qm,Lo,ea,Zm,eg,oa,og,tg,sg,ta,ig,Id,es,Sd,Ve,Ye,ng,sa,rg,ag,os,lg,dg,ts,fg,cg,Q,pg,ia,ug,hg,na,mg,gg,ra,_g,vg,aa,bg,wg,la,yg,Eg,Dg,ve,$g,da,xg,Pg,fa,kg,Mg,ss,ca,jg,qg,Mi,Tg,Ad,uo,Co,pa,is,Ig,ua,Sg,Ld,be,Ag,ns,Lg,Cg,ji,Og,Fg,qi,Xg,zg,Cd,Oo,ke,Ng,ha,Ug,Vg,Ti,Yg,Wg,ma,Hg,Bg,Rg,ho,Gg,ga,Kg,Jg,Ii,Qg,Zg,Od,we,e_,Si,o_,t_,_a,s_,i_,va,n_,r_,Fd,Ai,a_,Xd,rs,zd,ye,l_,ba,d_,f_,Li,c_,p_,as,u_,h_,Nd,We,m_,Ci,g_,__,Oi,v_,b_,Ud,ls,Vd,He,w_,ds,wa,y_,E_,ya,D_,$_,Yd,fs,Wd,mo,Fo,Ea,cs,x_,Da,P_,Hd,re,k_,$a,M_,j_,Fi,q_,T_,xa,I_,S_,Pa,A_,L_,Bd,Xi,C_,Rd,V,ka,zi,O_,F_,Ma,Ni,X_,z_,ja,Ui,N_,U_,qa,Vi,V_,Y_,Ta,Yi,W_,H_,Ia,Wi,B_,R_,Sa,Hi,G_,Gd,Xo,K_,Bi,J_,Q_,Kd,ps,Jd,go,zo,Aa,us,Z_,La,ev,Qd,H,hs,ov,Ca,tv,sv,Ri,Gi,iv,nv,rv,Oa,Be,Fa,av,lv,Xa,dv,fv,Ki,cv,pv,uv,Y,ms,hv,za,mv,gv,_o,_v,Na,vv,bv,Ua,wv,yv,Ev,gs,Dv,Va,$v,xv,Pv,_s,kv,Ya,Mv,jv,qv,No,Tv,Uo,Iv,Vo,vs,Sv,bs,Av,Wa,Lv,Cv,Zd,S,ws,Ov,Ha,Fv,Xv,Ji,Qi,zv,Nv,Uv,ys,Ba,Vv,Yv,Ra,Wv,Hv,Ga,Bv,Rv,Ka,Yo,Ja,Gv,Kv,Qa,Jv,Qv,Zv,C,Es,eb,Za,ob,tb,Ds,sb,el,ib,nb,rb,$s,ab,ol,lb,db,fb,xs,cb,tl,pb,ub,hb,Wo,mb,Ho,gb,Bo,_b,Ro,Ps,vb,ks,bb,sl,wb,yb,ef,Z,Ms,Eb,il,Db,$b,Zi,en,xb,Pb,kb,ae,js,Mb,nl,jb,qb,qs,Tb,rl,Ib,Sb,Ab,Ts,Lb,al,Cb,Ob,Fb,Go,Xb,Ko,Is,zb,Ss,Nb,ll,Ub,Vb,of,A,As,Yb,dl,Wb,Hb,on,tn,Bb,Rb,Gb,fl,cl,Kb,Jb,pl,Qb,Zb,ul,Jo,hl,ew,ow,ml,tw,sw,iw,O,Ls,nw,gl,rw,aw,Cs,lw,_l,dw,fw,cw,Os,pw,vl,uw,hw,mw,Fs,gw,bl,_w,vw,bw,Qo,ww,Zo,yw,et,Ew,ot,Xs,Dw,zs,$w,wl,xw,Pw,tf;return u=new wo({}),pt=new wo({}),mt=new j({props:{code:`from diffusers import DiffusionPipeline

repo_id = "CompVis/ldm-text2im-large-256"
ldm = DiffusionPipeline.from_pretrained(repo_id)`,highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline

repo_id = <span class="hljs-string">&quot;CompVis/ldm-text2im-large-256&quot;</span>
ldm = DiffusionPipeline.from_pretrained(repo_id)`}}),gt=new j({props:{code:`from diffusers import LDMTextToImagePipeline

repo_id = "CompVis/ldm-text2im-large-256"
ldm = LDMTextToImagePipeline.from_pretrained(repo_id)`,highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> LDMTextToImagePipeline

repo_id = <span class="hljs-string">&quot;CompVis/ldm-text2im-large-256&quot;</span>
ldm = LDMTextToImagePipeline.from_pretrained(repo_id)`}}),vt=new wo({}),wt=new j({props:{code:`from diffusers import DiffusionPipeline

repo_id = "runwayml/stable-diffusion-v1-5"
stable_diffusion = DiffusionPipeline.from_pretrained(repo_id)`,highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline

repo_id = <span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>
stable_diffusion = DiffusionPipeline.from_pretrained(repo_id)`}}),Et=new j({props:{code:"OSError: runwayml/stable-diffusion-v1-5 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login`",highlighted:'OSError: runwayml/stable-diffusion-v1<span class="hljs-number">-5</span> is <span class="hljs-keyword">not</span> <span class="hljs-keyword">a</span> <span class="hljs-built_in">local</span> <span class="hljs-built_in">folder</span> <span class="hljs-keyword">and</span> is <span class="hljs-keyword">not</span> <span class="hljs-keyword">a</span> valid model identifier listed <span class="hljs-keyword">on</span> <span class="hljs-string">&#x27;https://huggingface.co/models&#x27;</span>\nIf this is <span class="hljs-keyword">a</span> <span class="hljs-keyword">private</span> repository, make sure <span class="hljs-built_in">to</span> pass <span class="hljs-keyword">a</span> <span class="hljs-keyword">token</span> having permission <span class="hljs-built_in">to</span> this repo <span class="hljs-keyword">with</span> `use_auth_token` <span class="hljs-keyword">or</span> <span class="hljs-built_in">log</span> <span class="hljs-keyword">in</span> <span class="hljs-keyword">with</span> `huggingface-cli login`'}}),$t=new j({props:{code:"huggingface-cli login",highlighted:'huggingface-<span class="hljs-keyword">cli</span> login'}}),Pt=new j({props:{code:`from diffusers import DiffusionPipeline

repo_id = "runwayml/stable-diffusion-v1-5"
stable_diffusion = DiffusionPipeline.from_pretrained(repo_id, use_auth_token="<your-access-token>")`,highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline

repo_id = <span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>
stable_diffusion = DiffusionPipeline.from_pretrained(repo_id, use_auth_token=<span class="hljs-string">&quot;&lt;your-access-token&gt;&quot;</span>)`}}),kt=new wo({}),Tt=new j({props:{code:`git lfs install
git clone https://huggingface.co/runwayml/stable-diffusion-v1-5`,highlighted:`git lfs install
git clone https:<span class="hljs-regexp">//</span>huggingface.co<span class="hljs-regexp">/runwayml/</span>stable-diffusion-v1-<span class="hljs-number">5</span>`}}),It=new j({props:{code:`from diffusers import DiffusionPipeline

repo_id = "./stable-diffusion-v1-5"
stable_diffusion = DiffusionPipeline.from_pretrained(repo_id)`,highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline

repo_id = <span class="hljs-string">&quot;./stable-diffusion-v1-5&quot;</span>
stable_diffusion = DiffusionPipeline.from_pretrained(repo_id)`}}),St=new wo({}),Lt=new j({props:{code:`from diffusers import DiffusionPipeline, EulerDiscreteScheduler, DPMSolverMultistepScheduler

repo_id = "runwayml/stable-diffusion-v1-5"

scheduler = EulerDiscreteScheduler.from_config(repo_id, subfolder="scheduler")
# or
# scheduler = DPMSolverMultistepScheduler.from_config(repo_id, subfolder="scheduler")

stable_diffusion = DiffusionPipeline.from_pretrained(repo_id, scheduler=scheduler)`,highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline, EulerDiscreteScheduler, DPMSolverMultistepScheduler

repo_id = <span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>

scheduler = EulerDiscreteScheduler.from_config(repo_id, subfolder=<span class="hljs-string">&quot;scheduler&quot;</span>)
<span class="hljs-comment"># or</span>
<span class="hljs-comment"># scheduler = DPMSolverMultistepScheduler.from_config(repo_id, subfolder=&quot;scheduler&quot;)</span>

stable_diffusion = DiffusionPipeline.from_pretrained(repo_id, scheduler=scheduler)`}}),Xt=new j({props:{code:`from diffusers import DiffusionPipeline, EulerDiscreteScheduler, DPMSolverMultistepScheduler

stable_diffusion = DiffusionPipeline.from_pretrained(repo_id, safety_checker=None)`,highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline, EulerDiscreteScheduler, DPMSolverMultistepScheduler

stable_diffusion = DiffusionPipeline.from_pretrained(repo_id, safety_checker=<span class="hljs-literal">None</span>)`}}),Nt=new j({props:{code:`from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline

model_id = "runwayml/stable-diffusion-v1-5"
stable_diffusion_txt2img = StableDiffusionPipeline.from_pretrained(model_id)

components = stable_diffusion_txt2img.components

# weights are not reloaded into RAM
stable_diffusion_img2img = StableDiffusionImg2ImgPipeline(**components)`,highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionPipeline, StableDiffusionImg2ImgPipeline

model_id = <span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>
stable_diffusion_txt2img = StableDiffusionPipeline.from_pretrained(model_id)

components = stable_diffusion_txt2img.components

<span class="hljs-comment"># weights are not reloaded into RAM</span>
stable_diffusion_img2img = StableDiffusionImg2ImgPipeline(**components)`}}),Ut=new wo({}),Yt=new j({props:{code:`from diffusers import DiffusionPipeline

repo_id = "CompVis/ldm-text2im-large-256"
ldm = DiffusionPipeline.from_pretrained(repo_id)
print(ldm)`,highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline

repo_id = <span class="hljs-string">&quot;CompVis/ldm-text2im-large-256&quot;</span>
ldm = DiffusionPipeline.from_pretrained(repo_id)
<span class="hljs-built_in">print</span>(ldm)`}}),Ht=new j({props:{code:`LDMTextToImagePipeline {
  "bert": [
    "latent_diffusion",
    "LDMBertModel"
  ],
  "scheduler": [
    "diffusers",
    "DDIMScheduler"
  ],
  "tokenizer": [
    "transformers",
    "BertTokenizer"
  ],
  "unet": [
    "diffusers",
    "UNet2DConditionModel"
  ],
  "vqvae": [
    "diffusers",
    "AutoencoderKL"
  ]
}`,highlighted:`<span class="hljs-symbol">LDMTextToImagePipeline</span> {
  <span class="hljs-string">&quot;bert&quot;</span>: [
    <span class="hljs-string">&quot;latent_diffusion&quot;</span>,
    <span class="hljs-string">&quot;LDMBertModel&quot;</span>
  ],
  <span class="hljs-string">&quot;scheduler&quot;</span>: [
    <span class="hljs-string">&quot;diffusers&quot;</span>,
    <span class="hljs-string">&quot;DDIMScheduler&quot;</span>
  ],
  <span class="hljs-string">&quot;tokenizer&quot;</span>: [
    <span class="hljs-string">&quot;transformers&quot;</span>,
    <span class="hljs-string">&quot;BertTokenizer&quot;</span>
  ],
  <span class="hljs-string">&quot;unet&quot;</span>: [
    <span class="hljs-string">&quot;diffusers&quot;</span>,
    <span class="hljs-string">&quot;UNet2DConditionModel&quot;</span>
  ],
  <span class="hljs-string">&quot;vqvae&quot;</span>: [
    <span class="hljs-string">&quot;diffusers&quot;</span>,
    <span class="hljs-string">&quot;AutoencoderKL&quot;</span>
  ]
}`}}),Qt=new j({props:{code:`.
\u251C\u2500\u2500 bert
\u2502\xA0\xA0 \u251C\u2500\u2500 config.json
\u2502\xA0\xA0 \u2514\u2500\u2500 pytorch_model.bin
\u251C\u2500\u2500 model_index.json
\u251C\u2500\u2500 scheduler
\u2502\xA0\xA0 \u2514\u2500\u2500 scheduler_config.json
\u251C\u2500\u2500 tokenizer
\u2502\xA0\xA0 \u251C\u2500\u2500 special_tokens_map.json
\u2502\xA0\xA0 \u251C\u2500\u2500 tokenizer_config.json
\u2502\xA0\xA0 \u2514\u2500\u2500 vocab.txt
\u251C\u2500\u2500 unet
\u2502\xA0\xA0 \u251C\u2500\u2500 config.json
\u2502\xA0\xA0 \u2514\u2500\u2500 diffusion_pytorch_model.bin
\u2514\u2500\u2500 vqvae
    \u251C\u2500\u2500 config.json
    \u2514\u2500\u2500 diffusion_pytorch_model.bin`,highlighted:`.
\u251C\u2500\u2500 <span class="hljs-keyword">bert
</span>\u2502\xA0\xA0 \u251C\u2500\u2500 <span class="hljs-built_in">config</span>.<span class="hljs-keyword">json
</span>\u2502\xA0\xA0 \u2514\u2500\u2500 pytorch_model.<span class="hljs-keyword">bin
</span>\u251C\u2500\u2500 model_index.<span class="hljs-keyword">json
</span>\u251C\u2500\u2500 <span class="hljs-keyword">scheduler
</span>\u2502\xA0\xA0 \u2514\u2500\u2500 <span class="hljs-keyword">scheduler_config.json
</span>\u251C\u2500\u2500 tokenizer
\u2502\xA0\xA0 \u251C\u2500\u2500 special_tokens_map.<span class="hljs-keyword">json
</span>\u2502\xA0\xA0 \u251C\u2500\u2500 tokenizer_config.<span class="hljs-keyword">json
</span>\u2502\xA0\xA0 \u2514\u2500\u2500 vocab.txt
\u251C\u2500\u2500 unet
\u2502\xA0\xA0 \u251C\u2500\u2500 <span class="hljs-built_in">config</span>.<span class="hljs-keyword">json
</span>\u2502\xA0\xA0 \u2514\u2500\u2500 <span class="hljs-keyword">diffusion_pytorch_model.bin
</span>\u2514\u2500\u2500 vqvae
    \u251C\u2500\u2500 <span class="hljs-built_in">config</span>.<span class="hljs-keyword">json
</span>    \u2514\u2500\u2500 <span class="hljs-keyword">diffusion_pytorch_model.bin</span>`}}),Zt=new j({props:{code:`{
  "_class_name": "LDMTextToImagePipeline",
  "_diffusers_version": "0.0.4",
  "bert": [
    "latent_diffusion",
    "LDMBertModel"
  ],
  "scheduler": [
    "diffusers",
    "DDIMScheduler"
  ],
  "tokenizer": [
    "transformers",
    "BertTokenizer"
  ],
  "unet": [
    "diffusers",
    "UNet2DConditionModel"
  ],
  "vqvae": [
    "diffusers",
    "AutoencoderKL"
  ]
}`,highlighted:`{
  <span class="hljs-string">&quot;_class_name&quot;</span>: <span class="hljs-string">&quot;LDMTextToImagePipeline&quot;</span>,
  <span class="hljs-string">&quot;_diffusers_version&quot;</span>: <span class="hljs-string">&quot;0.0.4&quot;</span>,
  <span class="hljs-string">&quot;bert&quot;</span>: [
    <span class="hljs-string">&quot;latent_diffusion&quot;</span>,
    <span class="hljs-string">&quot;LDMBertModel&quot;</span>
  ],
  <span class="hljs-string">&quot;scheduler&quot;</span>: [
    <span class="hljs-string">&quot;diffusers&quot;</span>,
    <span class="hljs-string">&quot;DDIMScheduler&quot;</span>
  ],
  <span class="hljs-string">&quot;tokenizer&quot;</span>: [
    <span class="hljs-string">&quot;transformers&quot;</span>,
    <span class="hljs-string">&quot;BertTokenizer&quot;</span>
  ],
  <span class="hljs-string">&quot;unet&quot;</span>: [
    <span class="hljs-string">&quot;diffusers&quot;</span>,
    <span class="hljs-string">&quot;UNet2DConditionModel&quot;</span>
  ],
  <span class="hljs-string">&quot;vqvae&quot;</span>: [
    <span class="hljs-string">&quot;diffusers&quot;</span>,
    <span class="hljs-string">&quot;AutoencoderKL&quot;</span>
  ]
}`}}),es=new j({props:{code:`"name" : [
  "library",
  "class"
]`,highlighted:`<span class="hljs-string">&quot;name&quot;</span> : [
  <span class="hljs-string">&quot;library&quot;</span>,
  <span class="hljs-string">&quot;class&quot;</span>
]`}}),is=new wo({}),rs=new j({props:{code:`from diffusers import UNet2DConditionModel

repo_id = "CompVis/ldm-text2im-large-256"
model = UNet2DConditionModel.from_pretrained(repo_id, subfolder="unet")`,highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> UNet2DConditionModel

repo_id = <span class="hljs-string">&quot;CompVis/ldm-text2im-large-256&quot;</span>
model = UNet2DConditionModel.from_pretrained(repo_id, subfolder=<span class="hljs-string">&quot;unet&quot;</span>)`}}),ls=new j({props:{code:`from diffusers import DiffusionPipeline

repo_id = "CompVis/ldm-text2im-large-256"
ldm = DiffusionPipeline.from_pretrained(repo_id, unet=model)`,highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline

repo_id = <span class="hljs-string">&quot;CompVis/ldm-text2im-large-256&quot;</span>
ldm = DiffusionPipeline.from_pretrained(repo_id, unet=model)`}}),fs=new j({props:{code:`from diffusers import UNet2DModel

repo_id = "google/ddpm-cifar10-32"
model = UNet2DModel.from_pretrained(repo_id)`,highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> UNet2DModel

repo_id = <span class="hljs-string">&quot;google/ddpm-cifar10-32&quot;</span>
model = UNet2DModel.from_pretrained(repo_id)`}}),cs=new wo({}),ps=new j({props:{code:`from diffusers import StableDiffusionPipeline
from diffusers import (
    DDPMScheduler,
    DDIMScheduler,
    PNDMScheduler,
    LMSDiscreteScheduler,
    EulerDiscreteScheduler,
    EulerAncestralDiscreteScheduler,
    DPMSolverMultistepScheduler,
)

repo_id = "runwayml/stable-diffusion-v1-5"

ddpm = DDPMScheduler.from_config(repo_id, subfolder="scheduler")
ddim = DDIMScheduler.from_config(repo_id, subfolder="scheduler")
pndm = PNDMScheduler.from_config(repo_id, subfolder="scheduler")
lms = LMSDiscreteScheduler.from_config(repo_id, subfolder="scheduler")
euler_anc = EulerAncestralDiscreteScheduler.from_config(repo_id, subfolder="scheduler")
euler = EulerDiscreteScheduler.from_config(repo_id, subfolder="scheduler")
dpm = DPMSolverMultistepScheduler.from_config(repo_id, subfolder="scheduler")

# replace \`dpm\` with any of \`ddpm\`, \`ddim\`, \`pndm\`, \`lms\`, \`euler\`, \`euler_anc\`
pipeline = StableDiffusionPipeline.from_pretrained(repo_id, scheduler=dpm)`,highlighted:`<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionPipeline
<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> (
    DDPMScheduler,
    DDIMScheduler,
    PNDMScheduler,
    LMSDiscreteScheduler,
    EulerDiscreteScheduler,
    EulerAncestralDiscreteScheduler,
    DPMSolverMultistepScheduler,
)

repo_id = <span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>

ddpm = DDPMScheduler.from_config(repo_id, subfolder=<span class="hljs-string">&quot;scheduler&quot;</span>)
ddim = DDIMScheduler.from_config(repo_id, subfolder=<span class="hljs-string">&quot;scheduler&quot;</span>)
pndm = PNDMScheduler.from_config(repo_id, subfolder=<span class="hljs-string">&quot;scheduler&quot;</span>)
lms = LMSDiscreteScheduler.from_config(repo_id, subfolder=<span class="hljs-string">&quot;scheduler&quot;</span>)
euler_anc = EulerAncestralDiscreteScheduler.from_config(repo_id, subfolder=<span class="hljs-string">&quot;scheduler&quot;</span>)
euler = EulerDiscreteScheduler.from_config(repo_id, subfolder=<span class="hljs-string">&quot;scheduler&quot;</span>)
dpm = DPMSolverMultistepScheduler.from_config(repo_id, subfolder=<span class="hljs-string">&quot;scheduler&quot;</span>)

<span class="hljs-comment"># replace \`dpm\` with any of \`ddpm\`, \`ddim\`, \`pndm\`, \`lms\`, \`euler\`, \`euler_anc\`</span>
pipeline = StableDiffusionPipeline.from_pretrained(repo_id, scheduler=dpm)`}}),us=new wo({}),hs=new $e({props:{name:"class diffusers.ModelMixin",anchor:"diffusers.ModelMixin",parameters:[],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/modeling_utils.py#L134"}}),ms=new $e({props:{name:"from_pretrained",anchor:"diffusers.ModelMixin.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:": typing.Union[str, os.PathLike, NoneType]"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.ModelMixin.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids should have an organization name, like <code>google/ddpm-celebahq-256</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using <code>~ModelMixin.save_config</code>, e.g.,
<code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"diffusers.ModelMixin.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>Union[str, os.PathLike]</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"diffusers.ModelMixin.from_pretrained.torch_dtype",description:`<strong>torch_dtype</strong> (<code>str</code> or <code>torch.dtype</code>, <em>optional</em>) &#x2014;
Override the default <code>torch.dtype</code> and load the model under this dtype. If <code>&quot;auto&quot;</code> is passed the dtype
will be automatically derived from the model&#x2019;s weights.`,name:"torch_dtype"},{anchor:"diffusers.ModelMixin.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"diffusers.ModelMixin.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"diffusers.ModelMixin.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"diffusers.ModelMixin.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"diffusers.ModelMixin.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (i.e., do not try to download the model).`,name:"local_files_only(bool,"},{anchor:"diffusers.ModelMixin.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>diffusers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"diffusers.ModelMixin.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"diffusers.ModelMixin.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&quot;</code>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo (either remote in
huggingface.co or downloaded locally), you can specify the folder name here.`,name:"subfolder"},{anchor:"diffusers.ModelMixin.from_pretrained.mirror",description:`<strong>mirror</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Mirror source to accelerate downloads in China. If you are from China and have an accessibility
problem, you can set this option to resolve it. Note that we do not guarantee the timeliness or safety.
Please refer to the mirror site for more information.`,name:"mirror"},{anchor:"diffusers.ModelMixin.from_pretrained.device_map",description:`<strong>device_map</strong> (<code>str</code> or <code>Dict[str, Union[int, str, torch.device]]</code>, <em>optional</em>) &#x2014;
A map that specifies where each submodule should go. It doesn&#x2019;t need to be refined to each
parameter/buffer name, once a given module name is inside, every submodule of it will be sent to the
same device.</p>
<p>To have Accelerate compute the most optimized <code>device_map</code> automatically, set <code>device_map=&quot;auto&quot;</code>. For
more information about each option see <a href="https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map" rel="nofollow">designing a device
map</a>.`,name:"device_map"},{anchor:"diffusers.ModelMixin.from_pretrained.low_cpu_mem_usage",description:`<strong>low_cpu_mem_usage</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code> if torch version &gt;= 1.9.0 else <code>False</code>) &#x2014;
Speed up model loading by not initializing the weights and only loading the pre-trained weights. This
also tries to not use more than 1x model size in CPU memory (including peak memory) while loading the
model. This is only supported when torch version &gt;= 1.9.0. If you are using an older version of torch,
setting this argument to <code>True</code> will raise an error.`,name:"low_cpu_mem_usage"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/modeling_utils.py#L232"}}),No=new $n({props:{$$slots:{default:[w5]},$$scope:{ctx:L}}}),Uo=new $n({props:{$$slots:{default:[y5]},$$scope:{ctx:L}}}),vs=new $e({props:{name:"save_pretrained",anchor:"diffusers.ModelMixin.save_pretrained",parameters:[{name:"save_directory",val:": typing.Union[str, os.PathLike]"},{name:"is_main_process",val:": bool = True"},{name:"save_function",val:": typing.Callable = <function save at 0x7f9c6a650670>"}],parametersDescription:[{anchor:"diffusers.ModelMixin.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Directory to which to save. Will be created if it doesn&#x2019;t exist.`,name:"save_directory"},{anchor:"diffusers.ModelMixin.save_pretrained.is_main_process",description:`<strong>is_main_process</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether the process calling this is the main process or not. Useful when in distributed training like
TPUs and need to call this function on all processes. In this case, set <code>is_main_process=True</code> only on
the main process to avoid race conditions.`,name:"is_main_process"},{anchor:"diffusers.ModelMixin.save_pretrained.save_function",description:`<strong>save_function</strong> (<code>Callable</code>) &#x2014;
The function to use to save the state dictionary. Useful on distributed training like TPUs when one
need to replace <code>torch.save</code> by another method.`,name:"save_function"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/modeling_utils.py#L182"}}),ws=new $e({props:{name:"class diffusers.DiffusionPipeline",anchor:"diffusers.DiffusionPipeline",parameters:[],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipeline_utils.py#L113"}}),Es=new $e({props:{name:"from_pretrained",anchor:"diffusers.DiffusionPipeline.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:": typing.Union[str, os.PathLike, NoneType]"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.DiffusionPipeline.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>repo id</em> of a pretrained pipeline hosted inside a model repo on
<a href="https://huggingface.co/" rel="nofollow">https://huggingface.co/</a> Valid repo ids have to be located under a user or organization name, like
<code>CompVis/ldm-text2im-large-256</code>.</li>
<li>A path to a <em>directory</em> containing pipeline weights saved using
<a href="/docs/diffusers/main/en/using-diffusers/loading#diffusers.DiffusionPipeline.save_pretrained">save_pretrained()</a>, e.g., <code>./my_pipeline_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.torch_dtype",description:`<strong>torch_dtype</strong> (<code>str</code> or <code>torch.dtype</code>, <em>optional</em>) &#x2014;
Override the default <code>torch.dtype</code> and load the model under this dtype. If <code>&quot;auto&quot;</code> is passed the dtype
will be automatically derived from the model&#x2019;s weights.`,name:"torch_dtype"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.custom_pipeline",description:`<strong>custom_pipeline</strong> (<code>str</code>, <em>optional</em>) &#x2014;</p>
<div class="course-tip course-tip-orange bg-gradient-to-br dark:bg-gradient-to-r before:border-orange-500 dark:before:border-orange-800 from-orange-50 dark:from-gray-900 to-white dark:to-gray-950 border border-orange-50 text-orange-700 dark:text-gray-400">
						
<p>This is an experimental feature and is likely to change in the future.</p>

					</div>
<p>Can be either:</p>
<ul>
<li>
<p>A string, the <em>repo id</em> of a custom pipeline hosted inside a model repo on
<a href="https://huggingface.co/" rel="nofollow">https://huggingface.co/</a>. Valid repo ids have to be located under a user or organization name,
like <code>hf-internal-testing/diffusers-dummy-pipeline</code>.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>It is required that the model repo has a file, called <code>pipeline.py</code> that defines the custom
pipeline.</p>

					</div>
</li>
<li>
<p>A string, the <em>file name</em> of a community pipeline hosted on GitHub under
<a href="https://github.com/huggingface/diffusers/tree/main/examples/community" rel="nofollow">https://github.com/huggingface/diffusers/tree/main/examples/community</a>. Valid file names have to
match exactly the file name without <code>.py</code> located under the above link, <em>e.g.</em>
<code>clip_guided_stable_diffusion</code>.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>Community pipelines are always loaded from the current <code>main</code> branch of GitHub.</p>

					</div>
</li>
<li>
<p>A path to a <em>directory</em> containing a custom pipeline, e.g., <code>./my_pipeline_directory/</code>.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>It is required that the directory has a file, called <code>pipeline.py</code> that defines the custom
pipeline.</p>

					</div>
</li>
</ul>
<p>For more information on how to load and create custom pipelines, please have a look at <a href="https://huggingface.co/docs/diffusers/using-diffusers/custom_pipeline_overview" rel="nofollow">Loading and
Adding Custom
Pipelines</a>`,name:"custom_pipeline"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.torch_dtype",description:"<strong>torch_dtype</strong> (<code>str</code> or <code>torch.dtype</code>, <em>optional</em>) &#x2014;",name:"torch_dtype"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (i.e., do not try to download the model).`,name:"local_files_only(bool,"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.mirror",description:`<strong>mirror</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Mirror source to accelerate downloads in China. If you are from China and have an accessibility
problem, you can set this option to resolve it. Note that we do not guarantee the timeliness or safety.
Please refer to the mirror site for more information. specify the folder name here.`,name:"mirror"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.device_map",description:`<strong>device_map</strong> (<code>str</code> or <code>Dict[str, Union[int, str, torch.device]]</code>, <em>optional</em>) &#x2014;
A map that specifies where each submodule should go. It doesn&#x2019;t need to be refined to each
parameter/buffer name, once a given module name is inside, every submodule of it will be sent to the
same device.</p>
<p>To have Accelerate compute the most optimized <code>device_map</code> automatically, set <code>device_map=&quot;auto&quot;</code>. For
more information about each option see <a href="https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map" rel="nofollow">designing a device
map</a>.`,name:"device_map"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.low_cpu_mem_usage",description:`<strong>low_cpu_mem_usage</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code> if torch version &gt;= 1.9.0 else <code>False</code>) &#x2014;
Speed up model loading by not initializing the weights and only loading the pre-trained weights. This
also tries to not use more than 1x model size in CPU memory (including peak memory) while loading the
model. This is only supported when torch version &gt;= 1.9.0. If you are using an older version of torch,
setting this argument to <code>True</code> will raise an error.`,name:"low_cpu_mem_usage"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.kwargs",description:`<strong>kwargs</strong> (remaining dictionary of keyword arguments, <em>optional</em>) &#x2014;
Can be used to overwrite load - and saveable variables - <em>i.e.</em> the pipeline components - of the
specific pipeline class. The overwritten components are then directly passed to the pipelines
<code>__init__</code> method. See example below for more information.`,name:"kwargs"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipeline_utils.py#L238"}}),Wo=new $n({props:{$$slots:{default:[E5]},$$scope:{ctx:L}}}),Ho=new $n({props:{$$slots:{default:[D5]},$$scope:{ctx:L}}}),Bo=new Sw({props:{anchor:"diffusers.DiffusionPipeline.from_pretrained.example",$$slots:{default:[$5]},$$scope:{ctx:L}}}),Ps=new $e({props:{name:"save_pretrained",anchor:"diffusers.DiffusionPipeline.save_pretrained",parameters:[{name:"save_directory",val:": typing.Union[str, os.PathLike]"}],parametersDescription:[{anchor:"diffusers.DiffusionPipeline.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Directory to which to save. Will be created if it doesn&#x2019;t exist.`,name:"save_directory"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipeline_utils.py#L163"}}),Ms=new $e({props:{name:"class diffusers.FlaxModelMixin",anchor:"diffusers.FlaxModelMixin",parameters:[],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/modeling_flax_utils.py#L45"}}),js=new $e({props:{name:"from_pretrained",anchor:"diffusers.FlaxModelMixin.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:": typing.Union[str, os.PathLike]"},{name:"dtype",val:": dtype = <class 'jax.numpy.float32'>"},{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.FlaxModelMixin.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids are namespaced under a user or organization name, like
<code>runwayml/stable-diffusion-v1-5</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using <a href="/docs/diffusers/main/en/using-diffusers/loading#diffusers.ModelMixin.save_pretrained">save_pretrained()</a>,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"diffusers.FlaxModelMixin.from_pretrained.dtype",description:`<strong>dtype</strong> (<code>jax.numpy.dtype</code>, <em>optional</em>, defaults to <code>jax.numpy.float32</code>) &#x2014;
The data type of the computation. Can be one of <code>jax.numpy.float32</code>, <code>jax.numpy.float16</code> (on GPUs) and
<code>jax.numpy.bfloat16</code> (on TPUs).</p>
<p>This can be used to enable mixed-precision training or half-precision inference on GPUs or TPUs. If
specified all the computation will be performed with the given <code>dtype</code>.</p>
<p><strong>Note that this only specifies the dtype of the computation and does not influence the dtype of model
parameters.</strong></p>
<p>If you wish to change the dtype of the model parameters, see <code>~ModelMixin.to_fp16</code> and
<code>~ModelMixin.to_bf16</code>.`,name:"dtype"},{anchor:"diffusers.FlaxModelMixin.from_pretrained.model_args",description:`<strong>model_args</strong> (sequence of positional arguments, <em>optional</em>) &#x2014;
All remaining positional arguments will be passed to the underlying model&#x2019;s <code>__init__</code> method.`,name:"model_args"},{anchor:"diffusers.FlaxModelMixin.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>Union[str, os.PathLike]</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"diffusers.FlaxModelMixin.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"diffusers.FlaxModelMixin.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"diffusers.FlaxModelMixin.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"diffusers.FlaxModelMixin.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (i.e., do not try to download the model).`,name:"local_files_only(bool,"},{anchor:"diffusers.FlaxModelMixin.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"diffusers.FlaxModelMixin.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file.`,name:"from_pt"},{anchor:"diffusers.FlaxModelMixin.from_pretrained.kwargs",description:`<strong>kwargs</strong> (remaining dictionary of keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin.from_config">from_config()</a>). Each key of <code>kwargs</code> that corresponds to
a configuration attribute will be used to override said attribute with the supplied <code>kwargs</code>
value. Remaining keys that do not correspond to any configuration attribute will be passed to the
underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/modeling_flax_utils.py#L195"}}),Go=new Sw({props:{anchor:"diffusers.FlaxModelMixin.from_pretrained.example",$$slots:{default:[x5]},$$scope:{ctx:L}}}),Is=new $e({props:{name:"save_pretrained",anchor:"diffusers.FlaxModelMixin.save_pretrained",parameters:[{name:"save_directory",val:": typing.Union[str, os.PathLike]"},{name:"params",val:": typing.Union[typing.Dict, flax.core.frozen_dict.FrozenDict]"},{name:"is_main_process",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.FlaxModelMixin.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Directory to which to save. Will be created if it doesn&#x2019;t exist.`,name:"save_directory"},{anchor:"diffusers.FlaxModelMixin.save_pretrained.params",description:`<strong>params</strong> (<code>Union[Dict, FrozenDict]</code>) &#x2014;
A <code>PyTree</code> of model parameters.`,name:"params"},{anchor:"diffusers.FlaxModelMixin.save_pretrained.is_main_process",description:`<strong>is_main_process</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether the process calling this is the main process or not. Useful when in distributed training like
TPUs and need to call this function on all processes. In this case, set <code>is_main_process=True</code> only on
the main process to avoid race conditions.`,name:"is_main_process"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/modeling_flax_utils.py#L487"}}),As=new $e({props:{name:"class diffusers.FlaxDiffusionPipeline",anchor:"diffusers.FlaxDiffusionPipeline",parameters:[],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipeline_flax_utils.py#L93"}}),Ls=new $e({props:{name:"from_pretrained",anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:": typing.Union[str, os.PathLike, NoneType]"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>repo id</em> of a pretrained pipeline hosted inside a model repo on
<a href="https://huggingface.co/" rel="nofollow">https://huggingface.co/</a> Valid repo ids have to be located under a user or organization name, like
<code>CompVis/ldm-text2im-large-256</code>.</li>
<li>A path to a <em>directory</em> containing pipeline weights saved using
<a href="/docs/diffusers/main/en/using-diffusers/loading#diffusers.FlaxDiffusionPipeline.save_pretrained">save_pretrained()</a>, e.g., <code>./my_pipeline_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.dtype",description:`<strong>dtype</strong> (<code>str</code> or <code>jnp.dtype</code>, <em>optional</em>) &#x2014;
Override the default <code>jnp.dtype</code> and load the model under this dtype. If <code>&quot;auto&quot;</code> is passed the dtype
will be automatically derived from the model&#x2019;s weights.`,name:"dtype"},{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (i.e., do not try to download the model).`,name:"local_files_only(bool,"},{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.mirror",description:`<strong>mirror</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Mirror source to accelerate downloads in China. If you are from China and have an accessibility
problem, you can set this option to resolve it. Note that we do not guarantee the timeliness or safety.
Please refer to the mirror site for more information. specify the folder name here.`,name:"mirror"},{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.kwargs",description:`<strong>kwargs</strong> (remaining dictionary of keyword arguments, <em>optional</em>) &#x2014;
Can be used to overwrite load - and saveable variables - <em>i.e.</em> the pipeline components - of the
specific pipeline class. The overwritten components are then directly passed to the pipelines
<code>__init__</code> method. See example below for more information.`,name:"kwargs"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipeline_flax_utils.py#L193"}}),Qo=new $n({props:{$$slots:{default:[P5]},$$scope:{ctx:L}}}),Zo=new $n({props:{$$slots:{default:[k5]},$$scope:{ctx:L}}}),et=new Sw({props:{anchor:"diffusers.FlaxDiffusionPipeline.from_pretrained.example",$$slots:{default:[M5]},$$scope:{ctx:L}}}),Xs=new $e({props:{name:"save_pretrained",anchor:"diffusers.FlaxDiffusionPipeline.save_pretrained",parameters:[{name:"save_directory",val:": typing.Union[str, os.PathLike]"},{name:"params",val:": typing.Union[typing.Dict, flax.core.frozen_dict.FrozenDict]"}],parametersDescription:[{anchor:"diffusers.FlaxDiffusionPipeline.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Directory to which to save. Will be created if it doesn&#x2019;t exist.`,name:"save_directory"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipeline_flax_utils.py#L143"}}),{c(){h=n("meta"),x=d(),m=n("h1"),_=n("a"),$=n("span"),v(u.$$.fragment),g=d(),k=n("span"),T=s("Loading"),I=d(),X=n("p"),z=s("A core premise of the diffusers library is to make diffusion models "),ce=n("strong"),J=s("as accessible as possible"),P=s(`.
Accessibility is therefore achieved by providing an API to load complete diffusion pipelines as well as individual components with a single line of code.`),Me=d(),he=n("p"),io=s("In the following we explain in-detail how to easily load:"),je=d(),qe=n("ul"),dt=n("li"),xn=n("em"),Wf=s("Complete Diffusion Pipelines"),Hf=s(" via the "),Bs=n("a"),Bf=s("DiffusionPipeline.from_pretrained()"),Rf=d(),ft=n("li"),Pn=n("em"),Gf=s("Diffusion Models"),Kf=s(" via "),Rs=n("a"),Jf=s("ModelMixin.from_pretrained()"),Qf=d(),ct=n("li"),kn=n("em"),Zf=s("Schedulers"),ec=s(" via "),Gs=n("a"),oc=s("ConfigMixin.from_config()"),Tl=d(),no=n("h2"),yo=n("a"),Mn=n("span"),v(pt.$$.fragment),tc=d(),jn=n("span"),sc=s("Loading pipelines"),Il=d(),me=n("p"),ic=s("The "),Ks=n("a"),nc=s("DiffusionPipeline"),rc=s(" class is the easiest way to access any diffusion model that is "),ut=n("a"),ac=s("available on the Hub"),lc=s(". Let\u2019s look at an example on how to download "),ht=n("a"),dc=s("CompVis\u2019 Latent Diffusion model"),fc=s("."),Sl=d(),v(mt.$$.fragment),Al=d(),N=n("p"),cc=s("Here "),Js=n("a"),pc=s("DiffusionPipeline"),uc=s(" automatically detects the correct pipeline ("),qn=n("em"),hc=s("i.e."),mc=d(),Qs=n("a"),gc=s("LDMTextToImagePipeline"),_c=s("), downloads and caches all required configuration and weight files (if not already done so), and finally returns a pipeline instance, called "),Tn=n("code"),vc=s("ldm"),bc=s(`.
The pipeline instance can then be called using `),Eo=n("a"),wc=s("LDMTextToImagePipeline."),In=n("strong"),yc=s("call"),Ec=s("()"),Dc=s(" (i.e., "),Sn=n("code"),$c=s('ldm("image of a astronaut riding a horse")'),xc=s(") for text-to-image generation."),Ll=d(),Do=n("p"),Pc=s("Instead of using the generic "),Zs=n("a"),kc=s("DiffusionPipeline"),Mc=s(" class for loading, you can also load the appropriate pipeline class directly. The code snippet above yields the same instance as when doing:"),Cl=d(),v(gt.$$.fragment),Ol=d(),q=n("p"),jc=s("Diffusion pipelines like "),An=n("code"),qc=s("LDMTextToImagePipeline"),Tc=s(" often consist of multiple components. These components can be both parameterized models, such as "),Ln=n("code"),Ic=s('"unet"'),Sc=s(", "),Cn=n("code"),Ac=s('"vqvae"'),Lc=s(" and \u201Cbert\u201D, tokenizers or schedulers. These components can interact in complex ways with each other when using the pipeline in inference, "),On=n("em"),Cc=s("e.g."),Oc=s(" for "),ei=n("a"),Fc=s("LDMTextToImagePipeline"),Xc=s(" or "),oi=n("a"),zc=s("StableDiffusionPipeline"),Nc=s(" the inference call is explained "),_t=n("a"),Uc=s("here"),Vc=s(`.
The purpose of the `),ti=n("a"),Yc=s("pipeline classes"),Wc=s(" is to wrap the complexity of these diffusion systems and give the user an easy-to-use API while staying flexible for customization, as will be shown later."),Fl=d(),ro=n("h3"),$o=n("a"),Fn=n("span"),v(vt.$$.fragment),Hc=d(),Xn=n("span"),Bc=s("Loading pipelines that require access request"),Xl=d(),Te=n("p"),Rc=s("Due to the capabilities of diffusion models to generate extremely realistic images, there is a certain danger that such models might be misused for unwanted applications, "),zn=n("em"),Gc=s("e.g."),Kc=s(` generating pornography or violent images.
In order to minimize the possibility of such unsolicited use cases, some of the most powerful diffusion models require users to acknowledge a license before being able to use the model. If the user does not agree to the license, the pipeline cannot be downloaded.
If you try to load `),bt=n("a"),Nn=n("code"),Jc=s("runwayml/stable-diffusion-v1-5"),Qc=s(" the same way as done previously:"),zl=d(),v(wt.$$.fragment),Nl=d(),Ie=n("p"),Zc=s("it will only work if you have both "),Un=n("em"),ep=s("click-accepted"),op=s(" the license on "),yt=n("a"),tp=s("the model card"),sp=s(` and are logged into the Hugging Face Hub. Otherwise you will get an error message
such as the following:`),Ul=d(),v(Et.$$.fragment),Vl=d(),Se=n("p"),ip=s("Therefore, we need to make sure to "),Vn=n("em"),np=s("click-accept"),rp=s(` the license. You can do this by simply visiting
the `),Dt=n("a"),ap=s("model card"),lp=s(" and clicking on \u201CAgree and access repository\u201D:"),Yl=d(),xe=n("p"),dp=n("br"),fp=d(),si=n("img"),cp=d(),pp=n("br"),Wl=d(),ii=n("p"),up=s("Second, you need to login with your access token:"),Hl=d(),v($t.$$.fragment),Bl=d(),oe=n("p"),hp=s("before trying to load the model. Or alternatively, you can pass "),xt=n("a"),mp=s("your access token"),gp=s(" directly via the flag "),Yn=n("code"),_p=s("use_auth_token"),vp=s(". In this case you do "),Wn=n("strong"),bp=s("not"),wp=s(` need
to run `),Hn=n("code"),yp=s("huggingface-cli login"),Ep=s(" before:"),Rl=d(),v(Pt.$$.fragment),Gl=d(),ni=n("p"),Dp=s("The final option to use pipelines that require access without having to rely on the Hugging Face Hub is to load the pipeline locally as explained in the next section."),Kl=d(),ao=n("h3"),xo=n("a"),Bn=n("span"),v(kt.$$.fragment),$p=d(),Rn=n("span"),xp=s("Loading pipelines locally"),Jl=d(),ri=n("p"),Pp=s(`If you prefer to have complete control over the pipeline and its corresponding files or, as said before, if you want to use pipelines that require an access request without having to be connected to the Hugging Face Hub,
we recommend loading pipelines locally.`),Ql=d(),Ae=n("p"),kp=s("To load a diffusion pipeline locally, you first need to manually download the whole folder structure on your local disk and then pass a local path to the "),ai=n("a"),Mp=s("DiffusionPipeline.from_pretrained()"),jp=s(`. Let\u2019s again look at an example for
`),Mt=n("a"),qp=s("CompVis\u2019 Latent Diffusion model"),Tp=s("."),Zl=d(),Le=n("p"),Ip=s("First, you should make use of "),jt=n("a"),Gn=n("code"),Sp=s("git-lfs"),Ap=s(" to download the whole folder structure that has been uploaded to the "),qt=n("a"),Lp=s("model repository"),Cp=s(":"),ed=d(),v(Tt.$$.fragment),od=d(),Ce=n("p"),Op=s("The command above will create a local folder called "),Kn=n("code"),Fp=s("./stable-diffusion-v1-5"),Xp=s(` on your disk.
Now, all you have to do is to simply pass the local folder path to `),Jn=n("code"),zp=s("from_pretrained"),Np=s(":"),td=d(),v(It.$$.fragment),sd=d(),Oe=n("p"),Up=s("If "),Qn=n("code"),Vp=s("repo_id"),Yp=s(" is a local path, as it is the case here, "),li=n("a"),Wp=s("DiffusionPipeline.from_pretrained()"),Hp=s(` will automatically detect it and therefore not try to download any files from the Hub.
While we usually recommend to load weights directly from the Hub to be certain to stay up to date with the newest changes, loading pipelines locally should be preferred if one
wants to stay anonymous, self-contained applications, etc\u2026`),id=d(),lo=n("h3"),Po=n("a"),Zn=n("span"),v(St.$$.fragment),Bp=d(),er=n("span"),Rp=s("Loading customized pipelines"),nd=d(),te=n("p"),Gp=s("Advanced users that want to load customized versions of diffusion pipelines can do so by swapping any of the default components, "),or=n("em"),Kp=s("e.g."),Jp=s(` the scheduler, with other scheduler classes.
A classical use case of this functionality is to swap the scheduler. `),At=n("a"),Qp=s("Stable Diffusion v1-5"),Zp=s(" uses the "),di=n("a"),eu=s("PNDMScheduler"),ou=s(` by default which is generally not the most performant scheduler. Since the release
of stable diffusion, multiple improved schedulers have been published. To use those, the user has to manually load their preferred scheduler and pass it into `),fi=n("a"),tu=s("DiffusionPipeline.from_pretrained()"),su=s("."),rd=d(),Pe=n("p"),tr=n("em"),iu=s("E.g."),nu=s(" to use "),ci=n("a"),ru=s("EulerDiscreteScheduler"),au=s(" or "),pi=n("a"),lu=s("DPMSolverMultistepScheduler"),du=s(" to have a better quality vs. generation speed trade-off for inference, one could load them as follows:"),ad=d(),v(Lt.$$.fragment),ld=d(),ui=n("p"),fu=s("Three things are worth paying attention to here."),dd=d(),Fe=n("ul"),Ct=n("li"),cu=s("First, the scheduler is loaded with "),hi=n("a"),pu=s("ConfigMixin.from_config()"),uu=s(" since it only depends on a configuration file and not any parameterized weights"),hu=d(),ko=n("li"),mu=s("Second, the scheduler is loaded with a function argument, called "),sr=n("code"),gu=s('subfolder="scheduler"'),_u=s(" as the configuration of stable diffusion\u2019s scheduling is defined in a "),Ot=n("a"),vu=s("subfolder of the official pipeline repository"),bu=d(),U=n("li"),wu=s("Third, the scheduler instance can simply be passed with the "),ir=n("code"),yu=s("scheduler"),Eu=s(" keyword argument to "),mi=n("a"),Du=s("DiffusionPipeline.from_pretrained()"),$u=s(". This works because the "),gi=n("a"),xu=s("StableDiffusionPipeline"),Pu=s(" defines its scheduler with the "),nr=n("code"),ku=s("scheduler"),Mu=s(" attribute. It\u2019s not possible to use a different name, such as "),rr=n("code"),ju=s("sampler=scheduler"),qu=s(" since "),ar=n("code"),Tu=s("sampler"),Iu=s(" is not a defined keyword for "),lr=n("code"),Su=s("StableDiffusionPipeline.__init__()"),fd=d(),ge=n("p"),Au=s("Not only the scheduler components can be customized for diffusion pipelines; in theory, all components of a pipeline can be customized. In practice, however, it often only makes sense to switch out a component that has "),dr=n("strong"),Lu=s("compatible"),Cu=s(` alternatives to what the pipeline expects.
Many scheduler classes are compatible with each other as can be seen `),Ft=n("a"),Ou=s("here"),Fu=s(". This is not always the case for other components, such as the "),fr=n("code"),Xu=s('"unet"'),zu=s("."),cd=d(),Xe=n("p"),Nu=s("One special case that can also be customized is the "),cr=n("code"),Uu=s('"safety_checker"'),Vu=s(" of stable diffusion. If you believe the safety checker doesn\u2019t serve you any good, you can simply disable it by passing "),pr=n("code"),Yu=s("None"),Wu=s(":"),pd=d(),v(Xt.$$.fragment),ud=d(),se=n("p"),Hu=s("Another common use case is to reuse the same components in multiple pipelines, "),ur=n("em"),Bu=s("e.g."),Ru=s(" the weights and configurations of "),zt=n("a"),hr=n("code"),Gu=s('"runwayml/stable-diffusion-v1-5"'),Ku=s(" can be used for both "),_i=n("a"),Ju=s("StableDiffusionPipeline"),Qu=s(" and "),vi=n("a"),Zu=s("StableDiffusionImg2ImgPipeline"),eh=s(` and we might not want to
use the exact same weights into RAM twice. In this case, customizing all the input instances would help us
to only load the weights into RAM once:`),hd=d(),v(Nt.$$.fragment),md=d(),Mo=n("p"),oh=s("Note how the above code snippet makes use of "),bi=n("a"),th=s("DiffusionPipeline.components"),sh=s("."),gd=d(),fo=n("h3"),jo=n("a"),mr=n("span"),v(Ut.$$.fragment),ih=d(),gr=n("span"),nh=s("How does loading work?"),_d=d(),qo=n("p"),rh=s("As a class method, "),wi=n("a"),ah=s("DiffusionPipeline.from_pretrained()"),lh=s(" is responsible for two things:"),vd=d(),To=n("ul"),pe=n("li"),dh=s("Download the latest version of the folder structure required to run the "),_r=n("code"),fh=s("repo_id"),ch=s(" with "),vr=n("code"),ph=s("diffusers"),uh=s(" and cache them. If the latest folder structure is available in the local cache, "),yi=n("a"),hh=s("DiffusionPipeline.from_pretrained()"),mh=s(" will simply reuse the cache and "),br=n("strong"),gh=s("not"),_h=s(" re-download the files."),vh=d(),ue=n("li"),bh=s("Load the cached weights into the "),wr=n("em"),wh=s("correct"),yh=s(" pipeline class \u2013 one of the "),Ei=n("a"),Eh=s("officially supported pipeline classes"),Dh=s(" - and return an instance of the class. The "),yr=n("em"),$h=s("correct"),xh=s(" pipeline class is thereby retrieved from the "),Er=n("code"),Ph=s("model_index.json"),kh=s(" file."),bd=d(),ie=n("p"),Mh=s("The underlying folder structure of diffusion pipelines correspond 1-to-1 to their corresponding class instances, "),Dr=n("em"),jh=s("e.g."),qh=d(),Di=n("a"),Th=s("LDMTextToImagePipeline"),Ih=s(" for "),Vt=n("a"),$r=n("code"),Sh=s("CompVis/ldm-text2im-large-256"),Ah=s(`
This can be understood better by looking at an example. Let\u2019s print out pipeline class instance `),xr=n("code"),Lh=s("pipeline"),Ch=s(" we just defined:"),wd=d(),v(Yt.$$.fragment),yd=d(),Wt=n("p"),Pr=n("em"),Oh=s("Output"),Fh=s(":"),Ed=d(),v(Ht.$$.fragment),Dd=d(),ze=n("p"),Xh=s("First, we see that the official pipeline is the "),$i=n("a"),zh=s("LDMTextToImagePipeline"),Nh=s(", and second we see that the "),kr=n("code"),Uh=s("LDMTextToImagePipeline"),Vh=s(" consists of 5 components:"),$d=d(),ne=n("ul"),co=n("li"),Mr=n("code"),Yh=s('"bert"'),Wh=s(" of class "),jr=n("code"),Hh=s("LDMBertModel"),Bh=s(" as defined "),Bt=n("a"),Rh=s("in the pipeline"),Gh=d(),Rt=n("li"),qr=n("code"),Kh=s('"scheduler"'),Jh=s(" of class "),xi=n("a"),Qh=s("DDIMScheduler"),Zh=d(),po=n("li"),Tr=n("code"),em=s('"tokenizer"'),om=s(" of class "),Ir=n("code"),tm=s("BertTokenizer"),sm=s(" as defined "),Io=n("a"),im=s("in "),Sr=n("code"),nm=s("transformers"),rm=d(),Gt=n("li"),Ar=n("code"),am=s('"unet"'),lm=s(" of class "),Pi=n("a"),dm=s("UNet2DConditionModel"),fm=d(),Kt=n("li"),Lr=n("code"),cm=s('"vqvae"'),pm=s(" of class "),ki=n("a"),um=s("AutoencoderKL"),xd=d(),_e=n("p"),hm=s("Let\u2019s now compare the pipeline instance to the folder structure of the model repository "),Cr=n("code"),mm=s("CompVis/ldm-text2im-large-256"),gm=s(". Looking at the folder structure of "),Jt=n("a"),Or=n("code"),_m=s("CompVis/ldm-text2im-large-256"),vm=s(" on the Hub, we can see it matches 1-to-1 the printed out instance of "),Fr=n("code"),bm=s("LDMTextToImagePipeline"),wm=s(" above:"),Pd=d(),v(Qt.$$.fragment),kd=d(),M=n("p"),ym=s("As we can see each attribute of the instance of "),Xr=n("code"),Em=s("LDMTextToImagePipeline"),Dm=s(" has its configuration and possibly weights defined in a subfolder that is called "),zr=n("strong"),$m=s("exactly"),xm=s(" like the class attribute ("),Nr=n("code"),Pm=s('"bert"'),km=s(", "),Ur=n("code"),Mm=s('"scheduler"'),jm=s(", "),Vr=n("code"),qm=s('"tokenizer"'),Tm=s(", "),Yr=n("code"),Im=s('"unet"'),Sm=s(", "),Wr=n("code"),Am=s('"vqvae"'),Lm=s("). Importantly, every pipeline expects a "),Hr=n("code"),Cm=s("model_index.json"),Om=s(" file that tells the "),Br=n("code"),Fm=s("DiffusionPipeline"),Xm=s(" both:"),Md=d(),So=n("ul"),Rr=n("li"),zm=s("which pipeline class should be loaded, and"),Nm=d(),Gr=n("li"),Um=s("what sub-classes from which library are stored in which subfolders"),jd=d(),Ne=n("p"),Vm=s("In the case of "),Kr=n("code"),Ym=s("CompVis/ldm-text2im-large-256"),Wm=s(" the "),Jr=n("code"),Hm=s("model_index.json"),Bm=s(" is therefore defined as follows:"),qd=d(),v(Zt.$$.fragment),Td=d(),Ue=n("ul"),Ao=n("li"),Qr=n("code"),Rm=s("_class_name"),Gm=s(" tells "),Zr=n("code"),Km=s("DiffusionPipeline"),Jm=s(" which pipeline class should be loaded."),Qm=d(),Lo=n("li"),ea=n("code"),Zm=s("_diffusers_version"),eg=s(" can be useful to know under which "),oa=n("code"),og=s("diffusers"),tg=s(" version this model was created."),sg=d(),ta=n("li"),ig=s("Every component of the pipeline is then defined under the form:"),Id=d(),v(es.$$.fragment),Sd=d(),Ve=n("ul"),Ye=n("li"),ng=s("The "),sa=n("code"),rg=s('"name"'),ag=s(" field corresponds both to the name of the subfolder in which the configuration and weights are stored as well as the attribute name of the pipeline class (as can be seen "),os=n("a"),lg=s("here"),dg=s(" and "),ts=n("a"),fg=s("here"),cg=d(),Q=n("li"),pg=s("The "),ia=n("code"),ug=s('"library"'),hg=s(" field corresponds to the name of the library, "),na=n("em"),mg=s("e.g."),gg=d(),ra=n("code"),_g=s("diffusers"),vg=s(" or "),aa=n("code"),bg=s("transformers"),wg=s(" from which the "),la=n("code"),yg=s('"class"'),Eg=s(" should be loaded"),Dg=d(),ve=n("li"),$g=s("The "),da=n("code"),xg=s('"class"'),Pg=s(" field corresponds to the name of the class, "),fa=n("em"),kg=s("e.g."),Mg=d(),ss=n("a"),ca=n("code"),jg=s("BertTokenizer"),qg=s(" or "),Mi=n("a"),Tg=s("UNet2DConditionModel"),Ad=d(),uo=n("h2"),Co=n("a"),pa=n("span"),v(is.$$.fragment),Ig=d(),ua=n("span"),Sg=s("Loading models"),Ld=d(),be=n("p"),Ag=s("Models as defined under "),ns=n("a"),Lg=s("src/diffusers/models"),Cg=s(" can be loaded via the "),ji=n("a"),Og=s("ModelMixin.from_pretrained()"),Fg=s(" function. The API is very similar the "),qi=n("a"),Xg=s("DiffusionPipeline.from_pretrained()"),zg=s(" and works in the same way:"),Cd=d(),Oo=n("ul"),ke=n("li"),Ng=s("Download the latest version of the model weights and configuration with "),ha=n("code"),Ug=s("diffusers"),Vg=s(" and cache them. If the latest files are available in the local cache, "),Ti=n("a"),Yg=s("ModelMixin.from_pretrained()"),Wg=s(" will simply reuse the cache and "),ma=n("strong"),Hg=s("not"),Bg=s(" re-download the files."),Rg=d(),ho=n("li"),Gg=s("Load the cached weights into the "),ga=n("em"),Kg=s("defined"),Jg=s(" model class - one of "),Ii=n("a"),Qg=s("the existing model classes"),Zg=s(" - and return an instance of the class."),Od=d(),we=n("p"),e_=s("In constrast to "),Si=n("a"),o_=s("DiffusionPipeline.from_pretrained()"),t_=s(", models rely on fewer files that usually don\u2019t require a folder structure, but just a "),_a=n("code"),s_=s("diffusion_pytorch_model.bin"),i_=s(" and "),va=n("code"),n_=s("config.json"),r_=s(" file."),Fd=d(),Ai=n("p"),a_=s("Let\u2019s look at an example:"),Xd=d(),v(rs.$$.fragment),zd=d(),ye=n("p"),l_=s("Note how we have to define the "),ba=n("code"),d_=s('subfolder="unet"'),f_=s(" argument to tell "),Li=n("a"),c_=s("ModelMixin.from_pretrained()"),p_=s(" that the model weights are located in a "),as=n("a"),u_=s("subfolder of the repository"),h_=s("."),Nd=d(),We=n("p"),m_=s("As explained in "),Ci=n("a"),g_=s("Loading customized pipelines"),__=s(", one can pass a loaded model to a diffusion pipeline, via "),Oi=n("a"),v_=s("DiffusionPipeline.from_pretrained()"),b_=s(":"),Ud=d(),v(ls.$$.fragment),Vd=d(),He=n("p"),w_=s("If the model files can be found directly at the root level, which is usually only the case for some very simple diffusion models, such as "),ds=n("a"),wa=n("code"),y_=s("google/ddpm-cifar10-32"),E_=s(`, we don\u2019t
need to pass a `),ya=n("code"),D_=s("subfolder"),$_=s(" argument:"),Yd=d(),v(fs.$$.fragment),Wd=d(),mo=n("h2"),Fo=n("a"),Ea=n("span"),v(cs.$$.fragment),x_=d(),Da=n("span"),P_=s("Loading schedulers"),Hd=d(),re=n("p"),k_=s("Schedulers cannot be loaded via a "),$a=n("code"),M_=s("from_pretrained"),j_=s(" method, but instead rely on "),Fi=n("a"),q_=s("ConfigMixin.from_config()"),T_=s(". Schedulers are "),xa=n("strong"),I_=s("not parameterized"),S_=s(" or "),Pa=n("strong"),A_=s("trained"),L_=s(`, but instead purely defined by a configuration file.
Therefore the loading method was given a different name here.`),Bd=d(),Xi=n("p"),C_=s(`In constrast to pipelines or models, loading schedulers does not consume any significant amount of memory and the same configuration file can often be used for a variety of different schedulers.
For example, all of:`),Rd=d(),V=n("ul"),ka=n("li"),zi=n("a"),O_=s("DDPMScheduler"),F_=d(),Ma=n("li"),Ni=n("a"),X_=s("DDIMScheduler"),z_=d(),ja=n("li"),Ui=n("a"),N_=s("PNDMScheduler"),U_=d(),qa=n("li"),Vi=n("a"),V_=s("LMSDiscreteScheduler"),Y_=d(),Ta=n("li"),Yi=n("a"),W_=s("EulerDiscreteScheduler"),H_=d(),Ia=n("li"),Wi=n("a"),B_=s("EulerAncestralDiscreteScheduler"),R_=d(),Sa=n("li"),Hi=n("a"),G_=s("DPMSolverMultistepScheduler"),Gd=d(),Xo=n("p"),K_=s("are compatible with "),Bi=n("a"),J_=s("StableDiffusionPipeline"),Q_=s(" and therefore the same scheduler configuration file can be loaded in any of those classes:"),Kd=d(),v(ps.$$.fragment),Jd=d(),go=n("h2"),zo=n("a"),Aa=n("span"),v(us.$$.fragment),Z_=d(),La=n("span"),ev=s("API"),Qd=d(),H=n("div"),v(hs.$$.fragment),ov=d(),Ca=n("p"),tv=s("Base class for all models."),sv=d(),Ri=n("p"),Gi=n("a"),iv=s("ModelMixin"),nv=s(` takes care of storing the configuration of the models and handles methods for loading, downloading
and saving models.`),rv=d(),Oa=n("ul"),Be=n("li"),Fa=n("strong"),av=s("config_name"),lv=s(" ("),Xa=n("code"),dv=s("str"),fv=s(`) \u2014 A filename under which the model should be stored when calling
`),Ki=n("a"),cv=s("save_pretrained()"),pv=s("."),uv=d(),Y=n("div"),v(ms.$$.fragment),hv=d(),za=n("p"),mv=s("Instantiate a pretrained pytorch model from a pre-trained model configuration."),gv=d(),_o=n("p"),_v=s("The model is set in evaluation mode by default using "),Na=n("code"),vv=s("model.eval()"),bv=s(` (Dropout modules are deactivated). To train
the model, you should first set it back in training mode with `),Ua=n("code"),wv=s("model.train()"),yv=s("."),Ev=d(),gs=n("p"),Dv=s("The warning "),Va=n("em"),$v=s("Weights from XXX not initialized from pretrained model"),xv=s(` means that the weights of XXX do not come
pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning
task.`),Pv=d(),_s=n("p"),kv=s("The warning "),Ya=n("em"),Mv=s("Weights from XXX not used in YYY"),jv=s(` means that the layer XXX is not used by YYY, therefore those
weights are discarded.`),qv=d(),v(No.$$.fragment),Tv=d(),v(Uo.$$.fragment),Iv=d(),Vo=n("div"),v(vs.$$.fragment),Sv=d(),bs=n("p"),Av=s(`Save a model and its configuration file to a directory, so that it can be re-loaded using the
`),Wa=n("code"),Lv=s("[from_pretrained()](/docs/diffusers/main/en/using-diffusers/loading#diffusers.ModelMixin.from_pretrained)"),Cv=s(" class method."),Zd=d(),S=n("div"),v(ws.$$.fragment),Ov=d(),Ha=n("p"),Fv=s("Base class for all models."),Xv=d(),Ji=n("p"),Qi=n("a"),zv=s("DiffusionPipeline"),Nv=s(` takes care of storing all components (models, schedulers, processors) for diffusion pipelines
and handles methods for loading, downloading and saving models as well as a few methods common to all pipelines to:`),Uv=d(),ys=n("ul"),Ba=n("li"),Vv=s("move all PyTorch modules to the device of your choice"),Yv=d(),Ra=n("li"),Wv=s("enabling/disabling the progress bar for the denoising iteration"),Hv=d(),Ga=n("p"),Bv=s("Class attributes:"),Rv=d(),Ka=n("ul"),Yo=n("li"),Ja=n("strong"),Gv=s("config_name"),Kv=s(" ("),Qa=n("code"),Jv=s("str"),Qv=s(`) \u2014 name of the config file that will store the class and module names of all
components of the diffusion pipeline.`),Zv=d(),C=n("div"),v(Es.$$.fragment),eb=d(),Za=n("p"),ob=s("Instantiate a PyTorch diffusion pipeline from pre-trained pipeline weights."),tb=d(),Ds=n("p"),sb=s("The pipeline is set in evaluation mode by default using "),el=n("code"),ib=s("model.eval()"),nb=s(" (Dropout modules are deactivated)."),rb=d(),$s=n("p"),ab=s("The warning "),ol=n("em"),lb=s("Weights from XXX not initialized from pretrained model"),db=s(` means that the weights of XXX do not come
pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning
task.`),fb=d(),xs=n("p"),cb=s("The warning "),tl=n("em"),pb=s("Weights from XXX not used in YYY"),ub=s(` means that the layer XXX is not used by YYY, therefore those
weights are discarded.`),hb=d(),v(Wo.$$.fragment),mb=d(),v(Ho.$$.fragment),gb=d(),v(Bo.$$.fragment),_b=d(),Ro=n("div"),v(Ps.$$.fragment),vb=d(),ks=n("p"),bb=s(`Save all variables of the pipeline that can be saved and loaded as well as the pipelines configuration file to
a directory. A pipeline variable can be saved and loaded if its class implements both a save and loading
method. The pipeline can easily be re-loaded using the `),sl=n("code"),wb=s("[from_pretrained()](/docs/diffusers/main/en/using-diffusers/loading#diffusers.DiffusionPipeline.from_pretrained)"),yb=s(" class method."),ef=d(),Z=n("div"),v(Ms.$$.fragment),Eb=d(),il=n("p"),Db=s("Base class for all flax models."),$b=d(),Zi=n("p"),en=n("a"),xb=s("FlaxModelMixin"),Pb=s(` takes care of storing the configuration of the models and handles methods for loading,
downloading and saving models.`),kb=d(),ae=n("div"),v(js.$$.fragment),Mb=d(),nl=n("p"),jb=s("Instantiate a pretrained flax model from a pre-trained model configuration."),qb=d(),qs=n("p"),Tb=s("The warning "),rl=n("em"),Ib=s("Weights from XXX not initialized from pretrained model"),Sb=s(` means that the weights of XXX do not come
pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning
task.`),Ab=d(),Ts=n("p"),Lb=s("The warning "),al=n("em"),Cb=s("Weights from XXX not used in YYY"),Ob=s(` means that the layer XXX is not used by YYY, therefore those
weights are discarded.`),Fb=d(),v(Go.$$.fragment),Xb=d(),Ko=n("div"),v(Is.$$.fragment),zb=d(),Ss=n("p"),Nb=s(`Save a model and its configuration file to a directory, so that it can be re-loaded using the
`),ll=n("code"),Ub=s("[from_pretrained()](/docs/diffusers/main/en/using-diffusers/loading#diffusers.FlaxModelMixin.from_pretrained)"),Vb=s(" class method"),of=d(),A=n("div"),v(As.$$.fragment),Yb=d(),dl=n("p"),Wb=s("Base class for all models."),Hb=d(),on=n("p"),tn=n("a"),Bb=s("FlaxDiffusionPipeline"),Rb=s(` takes care of storing all components (models, schedulers, processors) for diffusion
pipelines and handles methods for loading, downloading and saving models as well as a few methods common to all
pipelines to:`),Gb=d(),fl=n("ul"),cl=n("li"),Kb=s("enabling/disabling the progress bar for the denoising iteration"),Jb=d(),pl=n("p"),Qb=s("Class attributes:"),Zb=d(),ul=n("ul"),Jo=n("li"),hl=n("strong"),ew=s("config_name"),ow=s(" ("),ml=n("code"),tw=s("str"),sw=s(`) \u2014 name of the config file that will store the class and module names of all
components of the diffusion pipeline.`),iw=d(),O=n("div"),v(Ls.$$.fragment),nw=d(),gl=n("p"),rw=s("Instantiate a Flax diffusion pipeline from pre-trained pipeline weights."),aw=d(),Cs=n("p"),lw=s("The pipeline is set in evaluation mode by default using "),_l=n("code"),dw=s("model.eval()"),fw=s(" (Dropout modules are deactivated)."),cw=d(),Os=n("p"),pw=s("The warning "),vl=n("em"),uw=s("Weights from XXX not initialized from pretrained model"),hw=s(` means that the weights of XXX do not come
pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning
task.`),mw=d(),Fs=n("p"),gw=s("The warning "),bl=n("em"),_w=s("Weights from XXX not used in YYY"),vw=s(` means that the layer XXX is not used by YYY, therefore those
weights are discarded.`),bw=d(),v(Qo.$$.fragment),ww=d(),v(Zo.$$.fragment),yw=d(),v(et.$$.fragment),Ew=d(),ot=n("div"),v(Xs.$$.fragment),Dw=d(),zs=n("p"),$w=s(`Save all variables of the pipeline that can be saved and loaded as well as the pipelines configuration file to
a directory. A pipeline variable can be saved and loaded if its class implements both a save and loading
method. The pipeline can easily be re-loaded using the `),wl=n("code"),xw=s("[from_pretrained()](/docs/diffusers/main/en/using-diffusers/loading#diffusers.FlaxDiffusionPipeline.from_pretrained)"),Pw=s(` class
method.`),this.h()},l(o){const l=_5('[data-svelte="svelte-1phssyn"]',document.head);h=r(l,"META",{name:!0,content:!0}),l.forEach(t),x=f(o),m=r(o,"H1",{class:!0});var Ns=a(m);_=r(Ns,"A",{id:!0,class:!0,href:!0});var yl=a(_);$=r(yl,"SPAN",{});var El=a($);b(u.$$.fragment,El),El.forEach(t),yl.forEach(t),g=f(Ns),k=r(Ns,"SPAN",{});var Dl=a(k);T=i(Dl,"Loading"),Dl.forEach(t),Ns.forEach(t),I=f(o),X=r(o,"P",{});var Us=a(X);z=i(Us,"A core premise of the diffusers library is to make diffusion models "),ce=r(Us,"STRONG",{});var $l=a(ce);J=i($l,"as accessible as possible"),$l.forEach(t),P=i(Us,`.
Accessibility is therefore achieved by providing an API to load complete diffusion pipelines as well as individual components with a single line of code.`),Us.forEach(t),Me=f(o),he=r(o,"P",{});var xl=a(he);io=i(xl,"In the following we explain in-detail how to easily load:"),xl.forEach(t),je=f(o),qe=r(o,"UL",{});var vo=a(qe);dt=r(vo,"LI",{});var Vs=a(dt);xn=r(Vs,"EM",{});var Cw=a(xn);Wf=i(Cw,"Complete Diffusion Pipelines"),Cw.forEach(t),Hf=i(Vs," via the "),Bs=r(Vs,"A",{href:!0});var Ow=a(Bs);Bf=i(Ow,"DiffusionPipeline.from_pretrained()"),Ow.forEach(t),Vs.forEach(t),Rf=f(vo),ft=r(vo,"LI",{});var sf=a(ft);Pn=r(sf,"EM",{});var Fw=a(Pn);Gf=i(Fw,"Diffusion Models"),Fw.forEach(t),Kf=i(sf," via "),Rs=r(sf,"A",{href:!0});var Xw=a(Rs);Jf=i(Xw,"ModelMixin.from_pretrained()"),Xw.forEach(t),sf.forEach(t),Qf=f(vo),ct=r(vo,"LI",{});var nf=a(ct);kn=r(nf,"EM",{});var zw=a(kn);Zf=i(zw,"Schedulers"),zw.forEach(t),ec=i(nf," via "),Gs=r(nf,"A",{href:!0});var Nw=a(Gs);oc=i(Nw,"ConfigMixin.from_config()"),Nw.forEach(t),nf.forEach(t),vo.forEach(t),Tl=f(o),no=r(o,"H2",{class:!0});var rf=a(no);yo=r(rf,"A",{id:!0,class:!0,href:!0});var Uw=a(yo);Mn=r(Uw,"SPAN",{});var Vw=a(Mn);b(pt.$$.fragment,Vw),Vw.forEach(t),Uw.forEach(t),tc=f(rf),jn=r(rf,"SPAN",{});var Yw=a(jn);sc=i(Yw,"Loading pipelines"),Yw.forEach(t),rf.forEach(t),Il=f(o),me=r(o,"P",{});var tt=a(me);ic=i(tt,"The "),Ks=r(tt,"A",{href:!0});var Ww=a(Ks);nc=i(Ww,"DiffusionPipeline"),Ww.forEach(t),rc=i(tt," class is the easiest way to access any diffusion model that is "),ut=r(tt,"A",{href:!0,rel:!0});var Hw=a(ut);ac=i(Hw,"available on the Hub"),Hw.forEach(t),lc=i(tt,". Let\u2019s look at an example on how to download "),ht=r(tt,"A",{href:!0,rel:!0});var Bw=a(ht);dc=i(Bw,"CompVis\u2019 Latent Diffusion model"),Bw.forEach(t),fc=i(tt,"."),tt.forEach(t),Sl=f(o),b(mt.$$.fragment,o),Al=f(o),N=r(o,"P",{});var le=a(N);cc=i(le,"Here "),Js=r(le,"A",{href:!0});var Rw=a(Js);pc=i(Rw,"DiffusionPipeline"),Rw.forEach(t),uc=i(le," automatically detects the correct pipeline ("),qn=r(le,"EM",{});var Gw=a(qn);hc=i(Gw,"i.e."),Gw.forEach(t),mc=f(le),Qs=r(le,"A",{href:!0});var Kw=a(Qs);gc=i(Kw,"LDMTextToImagePipeline"),Kw.forEach(t),_c=i(le,"), downloads and caches all required configuration and weight files (if not already done so), and finally returns a pipeline instance, called "),Tn=r(le,"CODE",{});var Jw=a(Tn);vc=i(Jw,"ldm"),Jw.forEach(t),bc=i(le,`.
The pipeline instance can then be called using `),Eo=r(le,"A",{href:!0});var af=a(Eo);wc=i(af,"LDMTextToImagePipeline."),In=r(af,"STRONG",{});var Qw=a(In);yc=i(Qw,"call"),Qw.forEach(t),Ec=i(af,"()"),af.forEach(t),Dc=i(le," (i.e., "),Sn=r(le,"CODE",{});var Zw=a(Sn);$c=i(Zw,'ldm("image of a astronaut riding a horse")'),Zw.forEach(t),xc=i(le,") for text-to-image generation."),le.forEach(t),Ll=f(o),Do=r(o,"P",{});var lf=a(Do);Pc=i(lf,"Instead of using the generic "),Zs=r(lf,"A",{href:!0});var ey=a(Zs);kc=i(ey,"DiffusionPipeline"),ey.forEach(t),Mc=i(lf," class for loading, you can also load the appropriate pipeline class directly. The code snippet above yields the same instance as when doing:"),lf.forEach(t),Cl=f(o),b(gt.$$.fragment,o),Ol=f(o),q=r(o,"P",{});var W=a(q);jc=i(W,"Diffusion pipelines like "),An=r(W,"CODE",{});var oy=a(An);qc=i(oy,"LDMTextToImagePipeline"),oy.forEach(t),Tc=i(W," often consist of multiple components. These components can be both parameterized models, such as "),Ln=r(W,"CODE",{});var ty=a(Ln);Ic=i(ty,'"unet"'),ty.forEach(t),Sc=i(W,", "),Cn=r(W,"CODE",{});var sy=a(Cn);Ac=i(sy,'"vqvae"'),sy.forEach(t),Lc=i(W," and \u201Cbert\u201D, tokenizers or schedulers. These components can interact in complex ways with each other when using the pipeline in inference, "),On=r(W,"EM",{});var iy=a(On);Cc=i(iy,"e.g."),iy.forEach(t),Oc=i(W," for "),ei=r(W,"A",{href:!0});var ny=a(ei);Fc=i(ny,"LDMTextToImagePipeline"),ny.forEach(t),Xc=i(W," or "),oi=r(W,"A",{href:!0});var ry=a(oi);zc=i(ry,"StableDiffusionPipeline"),ry.forEach(t),Nc=i(W," the inference call is explained "),_t=r(W,"A",{href:!0,rel:!0});var ay=a(_t);Uc=i(ay,"here"),ay.forEach(t),Vc=i(W,`.
The purpose of the `),ti=r(W,"A",{href:!0});var ly=a(ti);Yc=i(ly,"pipeline classes"),ly.forEach(t),Wc=i(W," is to wrap the complexity of these diffusion systems and give the user an easy-to-use API while staying flexible for customization, as will be shown later."),W.forEach(t),Fl=f(o),ro=r(o,"H3",{class:!0});var df=a(ro);$o=r(df,"A",{id:!0,class:!0,href:!0});var dy=a($o);Fn=r(dy,"SPAN",{});var fy=a(Fn);b(vt.$$.fragment,fy),fy.forEach(t),dy.forEach(t),Hc=f(df),Xn=r(df,"SPAN",{});var cy=a(Xn);Bc=i(cy,"Loading pipelines that require access request"),cy.forEach(t),df.forEach(t),Xl=f(o),Te=r(o,"P",{});var sn=a(Te);Rc=i(sn,"Due to the capabilities of diffusion models to generate extremely realistic images, there is a certain danger that such models might be misused for unwanted applications, "),zn=r(sn,"EM",{});var py=a(zn);Gc=i(py,"e.g."),py.forEach(t),Kc=i(sn,` generating pornography or violent images.
In order to minimize the possibility of such unsolicited use cases, some of the most powerful diffusion models require users to acknowledge a license before being able to use the model. If the user does not agree to the license, the pipeline cannot be downloaded.
If you try to load `),bt=r(sn,"A",{href:!0,rel:!0});var uy=a(bt);Nn=r(uy,"CODE",{});var hy=a(Nn);Jc=i(hy,"runwayml/stable-diffusion-v1-5"),hy.forEach(t),uy.forEach(t),Qc=i(sn," the same way as done previously:"),sn.forEach(t),zl=f(o),b(wt.$$.fragment,o),Nl=f(o),Ie=r(o,"P",{});var nn=a(Ie);Zc=i(nn,"it will only work if you have both "),Un=r(nn,"EM",{});var my=a(Un);ep=i(my,"click-accepted"),my.forEach(t),op=i(nn," the license on "),yt=r(nn,"A",{href:!0,rel:!0});var gy=a(yt);tp=i(gy,"the model card"),gy.forEach(t),sp=i(nn,` and are logged into the Hugging Face Hub. Otherwise you will get an error message
such as the following:`),nn.forEach(t),Ul=f(o),b(Et.$$.fragment,o),Vl=f(o),Se=r(o,"P",{});var rn=a(Se);ip=i(rn,"Therefore, we need to make sure to "),Vn=r(rn,"EM",{});var _y=a(Vn);np=i(_y,"click-accept"),_y.forEach(t),rp=i(rn,` the license. You can do this by simply visiting
the `),Dt=r(rn,"A",{href:!0,rel:!0});var vy=a(Dt);ap=i(vy,"model card"),vy.forEach(t),lp=i(rn," and clicking on \u201CAgree and access repository\u201D:"),rn.forEach(t),Yl=f(o),xe=r(o,"P",{align:!0});var an=a(xe);dp=r(an,"BR",{}),fp=f(an),si=r(an,"IMG",{src:!0,width:!0}),cp=f(an),pp=r(an,"BR",{}),an.forEach(t),Wl=f(o),ii=r(o,"P",{});var by=a(ii);up=i(by,"Second, you need to login with your access token:"),by.forEach(t),Hl=f(o),b($t.$$.fragment,o),Bl=f(o),oe=r(o,"P",{});var Re=a(oe);hp=i(Re,"before trying to load the model. Or alternatively, you can pass "),xt=r(Re,"A",{href:!0,rel:!0});var wy=a(xt);mp=i(wy,"your access token"),wy.forEach(t),gp=i(Re," directly via the flag "),Yn=r(Re,"CODE",{});var yy=a(Yn);_p=i(yy,"use_auth_token"),yy.forEach(t),vp=i(Re,". In this case you do "),Wn=r(Re,"STRONG",{});var Ey=a(Wn);bp=i(Ey,"not"),Ey.forEach(t),wp=i(Re,` need
to run `),Hn=r(Re,"CODE",{});var Dy=a(Hn);yp=i(Dy,"huggingface-cli login"),Dy.forEach(t),Ep=i(Re," before:"),Re.forEach(t),Rl=f(o),b(Pt.$$.fragment,o),Gl=f(o),ni=r(o,"P",{});var $y=a(ni);Dp=i($y,"The final option to use pipelines that require access without having to rely on the Hugging Face Hub is to load the pipeline locally as explained in the next section."),$y.forEach(t),Kl=f(o),ao=r(o,"H3",{class:!0});var ff=a(ao);xo=r(ff,"A",{id:!0,class:!0,href:!0});var xy=a(xo);Bn=r(xy,"SPAN",{});var Py=a(Bn);b(kt.$$.fragment,Py),Py.forEach(t),xy.forEach(t),$p=f(ff),Rn=r(ff,"SPAN",{});var ky=a(Rn);xp=i(ky,"Loading pipelines locally"),ky.forEach(t),ff.forEach(t),Jl=f(o),ri=r(o,"P",{});var My=a(ri);Pp=i(My,`If you prefer to have complete control over the pipeline and its corresponding files or, as said before, if you want to use pipelines that require an access request without having to be connected to the Hugging Face Hub,
we recommend loading pipelines locally.`),My.forEach(t),Ql=f(o),Ae=r(o,"P",{});var ln=a(Ae);kp=i(ln,"To load a diffusion pipeline locally, you first need to manually download the whole folder structure on your local disk and then pass a local path to the "),ai=r(ln,"A",{href:!0});var jy=a(ai);Mp=i(jy,"DiffusionPipeline.from_pretrained()"),jy.forEach(t),jp=i(ln,`. Let\u2019s again look at an example for
`),Mt=r(ln,"A",{href:!0,rel:!0});var qy=a(Mt);qp=i(qy,"CompVis\u2019 Latent Diffusion model"),qy.forEach(t),Tp=i(ln,"."),ln.forEach(t),Zl=f(o),Le=r(o,"P",{});var dn=a(Le);Ip=i(dn,"First, you should make use of "),jt=r(dn,"A",{href:!0,rel:!0});var Ty=a(jt);Gn=r(Ty,"CODE",{});var Iy=a(Gn);Sp=i(Iy,"git-lfs"),Iy.forEach(t),Ty.forEach(t),Ap=i(dn," to download the whole folder structure that has been uploaded to the "),qt=r(dn,"A",{href:!0,rel:!0});var Sy=a(qt);Lp=i(Sy,"model repository"),Sy.forEach(t),Cp=i(dn,":"),dn.forEach(t),ed=f(o),b(Tt.$$.fragment,o),od=f(o),Ce=r(o,"P",{});var fn=a(Ce);Op=i(fn,"The command above will create a local folder called "),Kn=r(fn,"CODE",{});var Ay=a(Kn);Fp=i(Ay,"./stable-diffusion-v1-5"),Ay.forEach(t),Xp=i(fn,` on your disk.
Now, all you have to do is to simply pass the local folder path to `),Jn=r(fn,"CODE",{});var Ly=a(Jn);zp=i(Ly,"from_pretrained"),Ly.forEach(t),Np=i(fn,":"),fn.forEach(t),td=f(o),b(It.$$.fragment,o),sd=f(o),Oe=r(o,"P",{});var cn=a(Oe);Up=i(cn,"If "),Qn=r(cn,"CODE",{});var Cy=a(Qn);Vp=i(Cy,"repo_id"),Cy.forEach(t),Yp=i(cn," is a local path, as it is the case here, "),li=r(cn,"A",{href:!0});var Oy=a(li);Wp=i(Oy,"DiffusionPipeline.from_pretrained()"),Oy.forEach(t),Hp=i(cn,` will automatically detect it and therefore not try to download any files from the Hub.
While we usually recommend to load weights directly from the Hub to be certain to stay up to date with the newest changes, loading pipelines locally should be preferred if one
wants to stay anonymous, self-contained applications, etc\u2026`),cn.forEach(t),id=f(o),lo=r(o,"H3",{class:!0});var cf=a(lo);Po=r(cf,"A",{id:!0,class:!0,href:!0});var Fy=a(Po);Zn=r(Fy,"SPAN",{});var Xy=a(Zn);b(St.$$.fragment,Xy),Xy.forEach(t),Fy.forEach(t),Bp=f(cf),er=r(cf,"SPAN",{});var zy=a(er);Rp=i(zy,"Loading customized pipelines"),zy.forEach(t),cf.forEach(t),nd=f(o),te=r(o,"P",{});var Ge=a(te);Gp=i(Ge,"Advanced users that want to load customized versions of diffusion pipelines can do so by swapping any of the default components, "),or=r(Ge,"EM",{});var Ny=a(or);Kp=i(Ny,"e.g."),Ny.forEach(t),Jp=i(Ge,` the scheduler, with other scheduler classes.
A classical use case of this functionality is to swap the scheduler. `),At=r(Ge,"A",{href:!0,rel:!0});var Uy=a(At);Qp=i(Uy,"Stable Diffusion v1-5"),Uy.forEach(t),Zp=i(Ge," uses the "),di=r(Ge,"A",{href:!0});var Vy=a(di);eu=i(Vy,"PNDMScheduler"),Vy.forEach(t),ou=i(Ge,` by default which is generally not the most performant scheduler. Since the release
of stable diffusion, multiple improved schedulers have been published. To use those, the user has to manually load their preferred scheduler and pass it into `),fi=r(Ge,"A",{href:!0});var Yy=a(fi);tu=i(Yy,"DiffusionPipeline.from_pretrained()"),Yy.forEach(t),su=i(Ge,"."),Ge.forEach(t),rd=f(o),Pe=r(o,"P",{});var Ys=a(Pe);tr=r(Ys,"EM",{});var Wy=a(tr);iu=i(Wy,"E.g."),Wy.forEach(t),nu=i(Ys," to use "),ci=r(Ys,"A",{href:!0});var Hy=a(ci);ru=i(Hy,"EulerDiscreteScheduler"),Hy.forEach(t),au=i(Ys," or "),pi=r(Ys,"A",{href:!0});var By=a(pi);lu=i(By,"DPMSolverMultistepScheduler"),By.forEach(t),du=i(Ys," to have a better quality vs. generation speed trade-off for inference, one could load them as follows:"),Ys.forEach(t),ad=f(o),b(Lt.$$.fragment,o),ld=f(o),ui=r(o,"P",{});var Ry=a(ui);fu=i(Ry,"Three things are worth paying attention to here."),Ry.forEach(t),dd=f(o),Fe=r(o,"UL",{});var pn=a(Fe);Ct=r(pn,"LI",{});var pf=a(Ct);cu=i(pf,"First, the scheduler is loaded with "),hi=r(pf,"A",{href:!0});var Gy=a(hi);pu=i(Gy,"ConfigMixin.from_config()"),Gy.forEach(t),uu=i(pf," since it only depends on a configuration file and not any parameterized weights"),pf.forEach(t),hu=f(pn),ko=r(pn,"LI",{});var Pl=a(ko);mu=i(Pl,"Second, the scheduler is loaded with a function argument, called "),sr=r(Pl,"CODE",{});var Ky=a(sr);gu=i(Ky,'subfolder="scheduler"'),Ky.forEach(t),_u=i(Pl," as the configuration of stable diffusion\u2019s scheduling is defined in a "),Ot=r(Pl,"A",{href:!0,rel:!0});var Jy=a(Ot);vu=i(Jy,"subfolder of the official pipeline repository"),Jy.forEach(t),Pl.forEach(t),bu=f(pn),U=r(pn,"LI",{});var ee=a(U);wu=i(ee,"Third, the scheduler instance can simply be passed with the "),ir=r(ee,"CODE",{});var Qy=a(ir);yu=i(Qy,"scheduler"),Qy.forEach(t),Eu=i(ee," keyword argument to "),mi=r(ee,"A",{href:!0});var Zy=a(mi);Du=i(Zy,"DiffusionPipeline.from_pretrained()"),Zy.forEach(t),$u=i(ee,". This works because the "),gi=r(ee,"A",{href:!0});var e1=a(gi);xu=i(e1,"StableDiffusionPipeline"),e1.forEach(t),Pu=i(ee," defines its scheduler with the "),nr=r(ee,"CODE",{});var o1=a(nr);ku=i(o1,"scheduler"),o1.forEach(t),Mu=i(ee," attribute. It\u2019s not possible to use a different name, such as "),rr=r(ee,"CODE",{});var t1=a(rr);ju=i(t1,"sampler=scheduler"),t1.forEach(t),qu=i(ee," since "),ar=r(ee,"CODE",{});var s1=a(ar);Tu=i(s1,"sampler"),s1.forEach(t),Iu=i(ee," is not a defined keyword for "),lr=r(ee,"CODE",{});var i1=a(lr);Su=i(i1,"StableDiffusionPipeline.__init__()"),i1.forEach(t),ee.forEach(t),pn.forEach(t),fd=f(o),ge=r(o,"P",{});var st=a(ge);Au=i(st,"Not only the scheduler components can be customized for diffusion pipelines; in theory, all components of a pipeline can be customized. In practice, however, it often only makes sense to switch out a component that has "),dr=r(st,"STRONG",{});var n1=a(dr);Lu=i(n1,"compatible"),n1.forEach(t),Cu=i(st,` alternatives to what the pipeline expects.
Many scheduler classes are compatible with each other as can be seen `),Ft=r(st,"A",{href:!0,rel:!0});var r1=a(Ft);Ou=i(r1,"here"),r1.forEach(t),Fu=i(st,". This is not always the case for other components, such as the "),fr=r(st,"CODE",{});var a1=a(fr);Xu=i(a1,'"unet"'),a1.forEach(t),zu=i(st,"."),st.forEach(t),cd=f(o),Xe=r(o,"P",{});var un=a(Xe);Nu=i(un,"One special case that can also be customized is the "),cr=r(un,"CODE",{});var l1=a(cr);Uu=i(l1,'"safety_checker"'),l1.forEach(t),Vu=i(un," of stable diffusion. If you believe the safety checker doesn\u2019t serve you any good, you can simply disable it by passing "),pr=r(un,"CODE",{});var d1=a(pr);Yu=i(d1,"None"),d1.forEach(t),Wu=i(un,":"),un.forEach(t),pd=f(o),b(Xt.$$.fragment,o),ud=f(o),se=r(o,"P",{});var Ke=a(se);Hu=i(Ke,"Another common use case is to reuse the same components in multiple pipelines, "),ur=r(Ke,"EM",{});var f1=a(ur);Bu=i(f1,"e.g."),f1.forEach(t),Ru=i(Ke," the weights and configurations of "),zt=r(Ke,"A",{href:!0,rel:!0});var c1=a(zt);hr=r(c1,"CODE",{});var p1=a(hr);Gu=i(p1,'"runwayml/stable-diffusion-v1-5"'),p1.forEach(t),c1.forEach(t),Ku=i(Ke," can be used for both "),_i=r(Ke,"A",{href:!0});var u1=a(_i);Ju=i(u1,"StableDiffusionPipeline"),u1.forEach(t),Qu=i(Ke," and "),vi=r(Ke,"A",{href:!0});var h1=a(vi);Zu=i(h1,"StableDiffusionImg2ImgPipeline"),h1.forEach(t),eh=i(Ke,` and we might not want to
use the exact same weights into RAM twice. In this case, customizing all the input instances would help us
to only load the weights into RAM once:`),Ke.forEach(t),hd=f(o),b(Nt.$$.fragment,o),md=f(o),Mo=r(o,"P",{});var uf=a(Mo);oh=i(uf,"Note how the above code snippet makes use of "),bi=r(uf,"A",{href:!0});var m1=a(bi);th=i(m1,"DiffusionPipeline.components"),m1.forEach(t),sh=i(uf,"."),uf.forEach(t),gd=f(o),fo=r(o,"H3",{class:!0});var hf=a(fo);jo=r(hf,"A",{id:!0,class:!0,href:!0});var g1=a(jo);mr=r(g1,"SPAN",{});var _1=a(mr);b(Ut.$$.fragment,_1),_1.forEach(t),g1.forEach(t),ih=f(hf),gr=r(hf,"SPAN",{});var v1=a(gr);nh=i(v1,"How does loading work?"),v1.forEach(t),hf.forEach(t),_d=f(o),qo=r(o,"P",{});var mf=a(qo);rh=i(mf,"As a class method, "),wi=r(mf,"A",{href:!0});var b1=a(wi);ah=i(b1,"DiffusionPipeline.from_pretrained()"),b1.forEach(t),lh=i(mf," is responsible for two things:"),mf.forEach(t),vd=f(o),To=r(o,"UL",{});var gf=a(To);pe=r(gf,"LI",{});var Je=a(pe);dh=i(Je,"Download the latest version of the folder structure required to run the "),_r=r(Je,"CODE",{});var w1=a(_r);fh=i(w1,"repo_id"),w1.forEach(t),ch=i(Je," with "),vr=r(Je,"CODE",{});var y1=a(vr);ph=i(y1,"diffusers"),y1.forEach(t),uh=i(Je," and cache them. If the latest folder structure is available in the local cache, "),yi=r(Je,"A",{href:!0});var E1=a(yi);hh=i(E1,"DiffusionPipeline.from_pretrained()"),E1.forEach(t),mh=i(Je," will simply reuse the cache and "),br=r(Je,"STRONG",{});var D1=a(br);gh=i(D1,"not"),D1.forEach(t),_h=i(Je," re-download the files."),Je.forEach(t),vh=f(gf),ue=r(gf,"LI",{});var Qe=a(ue);bh=i(Qe,"Load the cached weights into the "),wr=r(Qe,"EM",{});var $1=a(wr);wh=i($1,"correct"),$1.forEach(t),yh=i(Qe," pipeline class \u2013 one of the "),Ei=r(Qe,"A",{href:!0});var x1=a(Ei);Eh=i(x1,"officially supported pipeline classes"),x1.forEach(t),Dh=i(Qe," - and return an instance of the class. The "),yr=r(Qe,"EM",{});var P1=a(yr);$h=i(P1,"correct"),P1.forEach(t),xh=i(Qe," pipeline class is thereby retrieved from the "),Er=r(Qe,"CODE",{});var k1=a(Er);Ph=i(k1,"model_index.json"),k1.forEach(t),kh=i(Qe," file."),Qe.forEach(t),gf.forEach(t),bd=f(o),ie=r(o,"P",{});var Ze=a(ie);Mh=i(Ze,"The underlying folder structure of diffusion pipelines correspond 1-to-1 to their corresponding class instances, "),Dr=r(Ze,"EM",{});var M1=a(Dr);jh=i(M1,"e.g."),M1.forEach(t),qh=f(Ze),Di=r(Ze,"A",{href:!0});var j1=a(Di);Th=i(j1,"LDMTextToImagePipeline"),j1.forEach(t),Ih=i(Ze," for "),Vt=r(Ze,"A",{href:!0,rel:!0});var q1=a(Vt);$r=r(q1,"CODE",{});var T1=a($r);Sh=i(T1,"CompVis/ldm-text2im-large-256"),T1.forEach(t),q1.forEach(t),Ah=i(Ze,`
This can be understood better by looking at an example. Let\u2019s print out pipeline class instance `),xr=r(Ze,"CODE",{});var I1=a(xr);Lh=i(I1,"pipeline"),I1.forEach(t),Ch=i(Ze," we just defined:"),Ze.forEach(t),wd=f(o),b(Yt.$$.fragment,o),yd=f(o),Wt=r(o,"P",{});var kw=a(Wt);Pr=r(kw,"EM",{});var S1=a(Pr);Oh=i(S1,"Output"),S1.forEach(t),Fh=i(kw,":"),kw.forEach(t),Ed=f(o),b(Ht.$$.fragment,o),Dd=f(o),ze=r(o,"P",{});var hn=a(ze);Xh=i(hn,"First, we see that the official pipeline is the "),$i=r(hn,"A",{href:!0});var A1=a($i);zh=i(A1,"LDMTextToImagePipeline"),A1.forEach(t),Nh=i(hn,", and second we see that the "),kr=r(hn,"CODE",{});var L1=a(kr);Uh=i(L1,"LDMTextToImagePipeline"),L1.forEach(t),Vh=i(hn," consists of 5 components:"),hn.forEach(t),$d=f(o),ne=r(o,"UL",{});var eo=a(ne);co=r(eo,"LI",{});var mn=a(co);Mr=r(mn,"CODE",{});var C1=a(Mr);Yh=i(C1,'"bert"'),C1.forEach(t),Wh=i(mn," of class "),jr=r(mn,"CODE",{});var O1=a(jr);Hh=i(O1,"LDMBertModel"),O1.forEach(t),Bh=i(mn," as defined "),Bt=r(mn,"A",{href:!0,rel:!0});var F1=a(Bt);Rh=i(F1,"in the pipeline"),F1.forEach(t),mn.forEach(t),Gh=f(eo),Rt=r(eo,"LI",{});var _f=a(Rt);qr=r(_f,"CODE",{});var X1=a(qr);Kh=i(X1,'"scheduler"'),X1.forEach(t),Jh=i(_f," of class "),xi=r(_f,"A",{href:!0});var z1=a(xi);Qh=i(z1,"DDIMScheduler"),z1.forEach(t),_f.forEach(t),Zh=f(eo),po=r(eo,"LI",{});var gn=a(po);Tr=r(gn,"CODE",{});var N1=a(Tr);em=i(N1,'"tokenizer"'),N1.forEach(t),om=i(gn," of class "),Ir=r(gn,"CODE",{});var U1=a(Ir);tm=i(U1,"BertTokenizer"),U1.forEach(t),sm=i(gn," as defined "),Io=r(gn,"A",{href:!0,rel:!0});var Mw=a(Io);im=i(Mw,"in "),Sr=r(Mw,"CODE",{});var V1=a(Sr);nm=i(V1,"transformers"),V1.forEach(t),Mw.forEach(t),gn.forEach(t),rm=f(eo),Gt=r(eo,"LI",{});var vf=a(Gt);Ar=r(vf,"CODE",{});var Y1=a(Ar);am=i(Y1,'"unet"'),Y1.forEach(t),lm=i(vf," of class "),Pi=r(vf,"A",{href:!0});var W1=a(Pi);dm=i(W1,"UNet2DConditionModel"),W1.forEach(t),vf.forEach(t),fm=f(eo),Kt=r(eo,"LI",{});var bf=a(Kt);Lr=r(bf,"CODE",{});var H1=a(Lr);cm=i(H1,'"vqvae"'),H1.forEach(t),pm=i(bf," of class "),ki=r(bf,"A",{href:!0});var B1=a(ki);um=i(B1,"AutoencoderKL"),B1.forEach(t),bf.forEach(t),eo.forEach(t),xd=f(o),_e=r(o,"P",{});var it=a(_e);hm=i(it,"Let\u2019s now compare the pipeline instance to the folder structure of the model repository "),Cr=r(it,"CODE",{});var R1=a(Cr);mm=i(R1,"CompVis/ldm-text2im-large-256"),R1.forEach(t),gm=i(it,". Looking at the folder structure of "),Jt=r(it,"A",{href:!0,rel:!0});var G1=a(Jt);Or=r(G1,"CODE",{});var K1=a(Or);_m=i(K1,"CompVis/ldm-text2im-large-256"),K1.forEach(t),G1.forEach(t),vm=i(it," on the Hub, we can see it matches 1-to-1 the printed out instance of "),Fr=r(it,"CODE",{});var J1=a(Fr);bm=i(J1,"LDMTextToImagePipeline"),J1.forEach(t),wm=i(it," above:"),it.forEach(t),Pd=f(o),b(Qt.$$.fragment,o),kd=f(o),M=r(o,"P",{});var F=a(M);ym=i(F,"As we can see each attribute of the instance of "),Xr=r(F,"CODE",{});var Q1=a(Xr);Em=i(Q1,"LDMTextToImagePipeline"),Q1.forEach(t),Dm=i(F," has its configuration and possibly weights defined in a subfolder that is called "),zr=r(F,"STRONG",{});var Z1=a(zr);$m=i(Z1,"exactly"),Z1.forEach(t),xm=i(F," like the class attribute ("),Nr=r(F,"CODE",{});var e2=a(Nr);Pm=i(e2,'"bert"'),e2.forEach(t),km=i(F,", "),Ur=r(F,"CODE",{});var o2=a(Ur);Mm=i(o2,'"scheduler"'),o2.forEach(t),jm=i(F,", "),Vr=r(F,"CODE",{});var t2=a(Vr);qm=i(t2,'"tokenizer"'),t2.forEach(t),Tm=i(F,", "),Yr=r(F,"CODE",{});var s2=a(Yr);Im=i(s2,'"unet"'),s2.forEach(t),Sm=i(F,", "),Wr=r(F,"CODE",{});var i2=a(Wr);Am=i(i2,'"vqvae"'),i2.forEach(t),Lm=i(F,"). Importantly, every pipeline expects a "),Hr=r(F,"CODE",{});var n2=a(Hr);Cm=i(n2,"model_index.json"),n2.forEach(t),Om=i(F," file that tells the "),Br=r(F,"CODE",{});var r2=a(Br);Fm=i(r2,"DiffusionPipeline"),r2.forEach(t),Xm=i(F," both:"),F.forEach(t),Md=f(o),So=r(o,"UL",{});var wf=a(So);Rr=r(wf,"LI",{});var a2=a(Rr);zm=i(a2,"which pipeline class should be loaded, and"),a2.forEach(t),Nm=f(wf),Gr=r(wf,"LI",{});var l2=a(Gr);Um=i(l2,"what sub-classes from which library are stored in which subfolders"),l2.forEach(t),wf.forEach(t),jd=f(o),Ne=r(o,"P",{});var _n=a(Ne);Vm=i(_n,"In the case of "),Kr=r(_n,"CODE",{});var d2=a(Kr);Ym=i(d2,"CompVis/ldm-text2im-large-256"),d2.forEach(t),Wm=i(_n," the "),Jr=r(_n,"CODE",{});var f2=a(Jr);Hm=i(f2,"model_index.json"),f2.forEach(t),Bm=i(_n," is therefore defined as follows:"),_n.forEach(t),qd=f(o),b(Zt.$$.fragment,o),Td=f(o),Ue=r(o,"UL",{});var vn=a(Ue);Ao=r(vn,"LI",{});var kl=a(Ao);Qr=r(kl,"CODE",{});var c2=a(Qr);Rm=i(c2,"_class_name"),c2.forEach(t),Gm=i(kl," tells "),Zr=r(kl,"CODE",{});var p2=a(Zr);Km=i(p2,"DiffusionPipeline"),p2.forEach(t),Jm=i(kl," which pipeline class should be loaded."),kl.forEach(t),Qm=f(vn),Lo=r(vn,"LI",{});var Ml=a(Lo);ea=r(Ml,"CODE",{});var u2=a(ea);Zm=i(u2,"_diffusers_version"),u2.forEach(t),eg=i(Ml," can be useful to know under which "),oa=r(Ml,"CODE",{});var h2=a(oa);og=i(h2,"diffusers"),h2.forEach(t),tg=i(Ml," version this model was created."),Ml.forEach(t),sg=f(vn),ta=r(vn,"LI",{});var m2=a(ta);ig=i(m2,"Every component of the pipeline is then defined under the form:"),m2.forEach(t),vn.forEach(t),Id=f(o),b(es.$$.fragment,o),Sd=f(o),Ve=r(o,"UL",{});var bn=a(Ve);Ye=r(bn,"LI",{});var Ws=a(Ye);ng=i(Ws,"The "),sa=r(Ws,"CODE",{});var g2=a(sa);rg=i(g2,'"name"'),g2.forEach(t),ag=i(Ws," field corresponds both to the name of the subfolder in which the configuration and weights are stored as well as the attribute name of the pipeline class (as can be seen "),os=r(Ws,"A",{href:!0,rel:!0});var _2=a(os);lg=i(_2,"here"),_2.forEach(t),dg=i(Ws," and "),ts=r(Ws,"A",{href:!0,rel:!0});var v2=a(ts);fg=i(v2,"here"),v2.forEach(t),Ws.forEach(t),cg=f(bn),Q=r(bn,"LI",{});var Ee=a(Q);pg=i(Ee,"The "),ia=r(Ee,"CODE",{});var b2=a(ia);ug=i(b2,'"library"'),b2.forEach(t),hg=i(Ee," field corresponds to the name of the library, "),na=r(Ee,"EM",{});var w2=a(na);mg=i(w2,"e.g."),w2.forEach(t),gg=f(Ee),ra=r(Ee,"CODE",{});var y2=a(ra);_g=i(y2,"diffusers"),y2.forEach(t),vg=i(Ee," or "),aa=r(Ee,"CODE",{});var E2=a(aa);bg=i(E2,"transformers"),E2.forEach(t),wg=i(Ee," from which the "),la=r(Ee,"CODE",{});var D2=a(la);yg=i(D2,'"class"'),D2.forEach(t),Eg=i(Ee," should be loaded"),Ee.forEach(t),Dg=f(bn),ve=r(bn,"LI",{});var bo=a(ve);$g=i(bo,"The "),da=r(bo,"CODE",{});var $2=a(da);xg=i($2,'"class"'),$2.forEach(t),Pg=i(bo," field corresponds to the name of the class, "),fa=r(bo,"EM",{});var x2=a(fa);kg=i(x2,"e.g."),x2.forEach(t),Mg=f(bo),ss=r(bo,"A",{href:!0,rel:!0});var P2=a(ss);ca=r(P2,"CODE",{});var k2=a(ca);jg=i(k2,"BertTokenizer"),k2.forEach(t),P2.forEach(t),qg=i(bo," or "),Mi=r(bo,"A",{href:!0});var M2=a(Mi);Tg=i(M2,"UNet2DConditionModel"),M2.forEach(t),bo.forEach(t),bn.forEach(t),Ad=f(o),uo=r(o,"H2",{class:!0});var yf=a(uo);Co=r(yf,"A",{id:!0,class:!0,href:!0});var j2=a(Co);pa=r(j2,"SPAN",{});var q2=a(pa);b(is.$$.fragment,q2),q2.forEach(t),j2.forEach(t),Ig=f(yf),ua=r(yf,"SPAN",{});var T2=a(ua);Sg=i(T2,"Loading models"),T2.forEach(t),yf.forEach(t),Ld=f(o),be=r(o,"P",{});var nt=a(be);Ag=i(nt,"Models as defined under "),ns=r(nt,"A",{href:!0,rel:!0});var I2=a(ns);Lg=i(I2,"src/diffusers/models"),I2.forEach(t),Cg=i(nt," can be loaded via the "),ji=r(nt,"A",{href:!0});var S2=a(ji);Og=i(S2,"ModelMixin.from_pretrained()"),S2.forEach(t),Fg=i(nt," function. The API is very similar the "),qi=r(nt,"A",{href:!0});var A2=a(qi);Xg=i(A2,"DiffusionPipeline.from_pretrained()"),A2.forEach(t),zg=i(nt," and works in the same way:"),nt.forEach(t),Cd=f(o),Oo=r(o,"UL",{});var Ef=a(Oo);ke=r(Ef,"LI",{});var rt=a(ke);Ng=i(rt,"Download the latest version of the model weights and configuration with "),ha=r(rt,"CODE",{});var L2=a(ha);Ug=i(L2,"diffusers"),L2.forEach(t),Vg=i(rt," and cache them. If the latest files are available in the local cache, "),Ti=r(rt,"A",{href:!0});var C2=a(Ti);Yg=i(C2,"ModelMixin.from_pretrained()"),C2.forEach(t),Wg=i(rt," will simply reuse the cache and "),ma=r(rt,"STRONG",{});var O2=a(ma);Hg=i(O2,"not"),O2.forEach(t),Bg=i(rt," re-download the files."),rt.forEach(t),Rg=f(Ef),ho=r(Ef,"LI",{});var wn=a(ho);Gg=i(wn,"Load the cached weights into the "),ga=r(wn,"EM",{});var F2=a(ga);Kg=i(F2,"defined"),F2.forEach(t),Jg=i(wn," model class - one of "),Ii=r(wn,"A",{href:!0});var X2=a(Ii);Qg=i(X2,"the existing model classes"),X2.forEach(t),Zg=i(wn," - and return an instance of the class."),wn.forEach(t),Ef.forEach(t),Od=f(o),we=r(o,"P",{});var at=a(we);e_=i(at,"In constrast to "),Si=r(at,"A",{href:!0});var z2=a(Si);o_=i(z2,"DiffusionPipeline.from_pretrained()"),z2.forEach(t),t_=i(at,", models rely on fewer files that usually don\u2019t require a folder structure, but just a "),_a=r(at,"CODE",{});var N2=a(_a);s_=i(N2,"diffusion_pytorch_model.bin"),N2.forEach(t),i_=i(at," and "),va=r(at,"CODE",{});var U2=a(va);n_=i(U2,"config.json"),U2.forEach(t),r_=i(at," file."),at.forEach(t),Fd=f(o),Ai=r(o,"P",{});var V2=a(Ai);a_=i(V2,"Let\u2019s look at an example:"),V2.forEach(t),Xd=f(o),b(rs.$$.fragment,o),zd=f(o),ye=r(o,"P",{});var lt=a(ye);l_=i(lt,"Note how we have to define the "),ba=r(lt,"CODE",{});var Y2=a(ba);d_=i(Y2,'subfolder="unet"'),Y2.forEach(t),f_=i(lt," argument to tell "),Li=r(lt,"A",{href:!0});var W2=a(Li);c_=i(W2,"ModelMixin.from_pretrained()"),W2.forEach(t),p_=i(lt," that the model weights are located in a "),as=r(lt,"A",{href:!0,rel:!0});var H2=a(as);u_=i(H2,"subfolder of the repository"),H2.forEach(t),h_=i(lt,"."),lt.forEach(t),Nd=f(o),We=r(o,"P",{});var yn=a(We);m_=i(yn,"As explained in "),Ci=r(yn,"A",{href:!0});var B2=a(Ci);g_=i(B2,"Loading customized pipelines"),B2.forEach(t),__=i(yn,", one can pass a loaded model to a diffusion pipeline, via "),Oi=r(yn,"A",{href:!0});var R2=a(Oi);v_=i(R2,"DiffusionPipeline.from_pretrained()"),R2.forEach(t),b_=i(yn,":"),yn.forEach(t),Ud=f(o),b(ls.$$.fragment,o),Vd=f(o),He=r(o,"P",{});var En=a(He);w_=i(En,"If the model files can be found directly at the root level, which is usually only the case for some very simple diffusion models, such as "),ds=r(En,"A",{href:!0,rel:!0});var G2=a(ds);wa=r(G2,"CODE",{});var K2=a(wa);y_=i(K2,"google/ddpm-cifar10-32"),K2.forEach(t),G2.forEach(t),E_=i(En,`, we don\u2019t
need to pass a `),ya=r(En,"CODE",{});var J2=a(ya);D_=i(J2,"subfolder"),J2.forEach(t),$_=i(En," argument:"),En.forEach(t),Yd=f(o),b(fs.$$.fragment,o),Wd=f(o),mo=r(o,"H2",{class:!0});var Df=a(mo);Fo=r(Df,"A",{id:!0,class:!0,href:!0});var Q2=a(Fo);Ea=r(Q2,"SPAN",{});var Z2=a(Ea);b(cs.$$.fragment,Z2),Z2.forEach(t),Q2.forEach(t),x_=f(Df),Da=r(Df,"SPAN",{});var eE=a(Da);P_=i(eE,"Loading schedulers"),eE.forEach(t),Df.forEach(t),Hd=f(o),re=r(o,"P",{});var oo=a(re);k_=i(oo,"Schedulers cannot be loaded via a "),$a=r(oo,"CODE",{});var oE=a($a);M_=i(oE,"from_pretrained"),oE.forEach(t),j_=i(oo," method, but instead rely on "),Fi=r(oo,"A",{href:!0});var tE=a(Fi);q_=i(tE,"ConfigMixin.from_config()"),tE.forEach(t),T_=i(oo,". Schedulers are "),xa=r(oo,"STRONG",{});var sE=a(xa);I_=i(sE,"not parameterized"),sE.forEach(t),S_=i(oo," or "),Pa=r(oo,"STRONG",{});var iE=a(Pa);A_=i(iE,"trained"),iE.forEach(t),L_=i(oo,`, but instead purely defined by a configuration file.
Therefore the loading method was given a different name here.`),oo.forEach(t),Bd=f(o),Xi=r(o,"P",{});var nE=a(Xi);C_=i(nE,`In constrast to pipelines or models, loading schedulers does not consume any significant amount of memory and the same configuration file can often be used for a variety of different schedulers.
For example, all of:`),nE.forEach(t),Rd=f(o),V=r(o,"UL",{});var de=a(V);ka=r(de,"LI",{});var rE=a(ka);zi=r(rE,"A",{href:!0});var aE=a(zi);O_=i(aE,"DDPMScheduler"),aE.forEach(t),rE.forEach(t),F_=f(de),Ma=r(de,"LI",{});var lE=a(Ma);Ni=r(lE,"A",{href:!0});var dE=a(Ni);X_=i(dE,"DDIMScheduler"),dE.forEach(t),lE.forEach(t),z_=f(de),ja=r(de,"LI",{});var fE=a(ja);Ui=r(fE,"A",{href:!0});var cE=a(Ui);N_=i(cE,"PNDMScheduler"),cE.forEach(t),fE.forEach(t),U_=f(de),qa=r(de,"LI",{});var pE=a(qa);Vi=r(pE,"A",{href:!0});var uE=a(Vi);V_=i(uE,"LMSDiscreteScheduler"),uE.forEach(t),pE.forEach(t),Y_=f(de),Ta=r(de,"LI",{});var hE=a(Ta);Yi=r(hE,"A",{href:!0});var mE=a(Yi);W_=i(mE,"EulerDiscreteScheduler"),mE.forEach(t),hE.forEach(t),H_=f(de),Ia=r(de,"LI",{});var gE=a(Ia);Wi=r(gE,"A",{href:!0});var _E=a(Wi);B_=i(_E,"EulerAncestralDiscreteScheduler"),_E.forEach(t),gE.forEach(t),R_=f(de),Sa=r(de,"LI",{});var vE=a(Sa);Hi=r(vE,"A",{href:!0});var bE=a(Hi);G_=i(bE,"DPMSolverMultistepScheduler"),bE.forEach(t),vE.forEach(t),de.forEach(t),Gd=f(o),Xo=r(o,"P",{});var $f=a(Xo);K_=i($f,"are compatible with "),Bi=r($f,"A",{href:!0});var wE=a(Bi);J_=i(wE,"StableDiffusionPipeline"),wE.forEach(t),Q_=i($f," and therefore the same scheduler configuration file can be loaded in any of those classes:"),$f.forEach(t),Kd=f(o),b(ps.$$.fragment,o),Jd=f(o),go=r(o,"H2",{class:!0});var xf=a(go);zo=r(xf,"A",{id:!0,class:!0,href:!0});var yE=a(zo);Aa=r(yE,"SPAN",{});var EE=a(Aa);b(us.$$.fragment,EE),EE.forEach(t),yE.forEach(t),Z_=f(xf),La=r(xf,"SPAN",{});var DE=a(La);ev=i(DE,"API"),DE.forEach(t),xf.forEach(t),Qd=f(o),H=r(o,"DIV",{class:!0});var De=a(H);b(hs.$$.fragment,De),ov=f(De),Ca=r(De,"P",{});var $E=a(Ca);tv=i($E,"Base class for all models."),$E.forEach(t),sv=f(De),Ri=r(De,"P",{});var jw=a(Ri);Gi=r(jw,"A",{href:!0});var xE=a(Gi);iv=i(xE,"ModelMixin"),xE.forEach(t),nv=i(jw,` takes care of storing the configuration of the models and handles methods for loading, downloading
and saving models.`),jw.forEach(t),rv=f(De),Oa=r(De,"UL",{});var PE=a(Oa);Be=r(PE,"LI",{});var Hs=a(Be);Fa=r(Hs,"STRONG",{});var kE=a(Fa);av=i(kE,"config_name"),kE.forEach(t),lv=i(Hs," ("),Xa=r(Hs,"CODE",{});var ME=a(Xa);dv=i(ME,"str"),ME.forEach(t),fv=i(Hs,`) \u2014 A filename under which the model should be stored when calling
`),Ki=r(Hs,"A",{href:!0});var jE=a(Ki);cv=i(jE,"save_pretrained()"),jE.forEach(t),pv=i(Hs,"."),Hs.forEach(t),PE.forEach(t),uv=f(De),Y=r(De,"DIV",{class:!0});var fe=a(Y);b(ms.$$.fragment,fe),hv=f(fe),za=r(fe,"P",{});var qE=a(za);mv=i(qE,"Instantiate a pretrained pytorch model from a pre-trained model configuration."),qE.forEach(t),gv=f(fe),_o=r(fe,"P",{});var Dn=a(_o);_v=i(Dn,"The model is set in evaluation mode by default using "),Na=r(Dn,"CODE",{});var TE=a(Na);vv=i(TE,"model.eval()"),TE.forEach(t),bv=i(Dn,` (Dropout modules are deactivated). To train
the model, you should first set it back in training mode with `),Ua=r(Dn,"CODE",{});var IE=a(Ua);wv=i(IE,"model.train()"),IE.forEach(t),yv=i(Dn,"."),Dn.forEach(t),Ev=f(fe),gs=r(fe,"P",{});var Pf=a(gs);Dv=i(Pf,"The warning "),Va=r(Pf,"EM",{});var SE=a(Va);$v=i(SE,"Weights from XXX not initialized from pretrained model"),SE.forEach(t),xv=i(Pf,` means that the weights of XXX do not come
pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning
task.`),Pf.forEach(t),Pv=f(fe),_s=r(fe,"P",{});var kf=a(_s);kv=i(kf,"The warning "),Ya=r(kf,"EM",{});var AE=a(Ya);Mv=i(AE,"Weights from XXX not used in YYY"),AE.forEach(t),jv=i(kf,` means that the layer XXX is not used by YYY, therefore those
weights are discarded.`),kf.forEach(t),qv=f(fe),b(No.$$.fragment,fe),Tv=f(fe),b(Uo.$$.fragment,fe),fe.forEach(t),Iv=f(De),Vo=r(De,"DIV",{class:!0});var Mf=a(Vo);b(vs.$$.fragment,Mf),Sv=f(Mf),bs=r(Mf,"P",{});var jf=a(bs);Av=i(jf,`Save a model and its configuration file to a directory, so that it can be re-loaded using the
`),Wa=r(jf,"CODE",{});var LE=a(Wa);Lv=i(LE,"[from_pretrained()](/docs/diffusers/main/en/using-diffusers/loading#diffusers.ModelMixin.from_pretrained)"),LE.forEach(t),Cv=i(jf," class method."),jf.forEach(t),Mf.forEach(t),De.forEach(t),Zd=f(o),S=r(o,"DIV",{class:!0});var B=a(S);b(ws.$$.fragment,B),Ov=f(B),Ha=r(B,"P",{});var CE=a(Ha);Fv=i(CE,"Base class for all models."),CE.forEach(t),Xv=f(B),Ji=r(B,"P",{});var qw=a(Ji);Qi=r(qw,"A",{href:!0});var OE=a(Qi);zv=i(OE,"DiffusionPipeline"),OE.forEach(t),Nv=i(qw,` takes care of storing all components (models, schedulers, processors) for diffusion pipelines
and handles methods for loading, downloading and saving models as well as a few methods common to all pipelines to:`),qw.forEach(t),Uv=f(B),ys=r(B,"UL",{});var qf=a(ys);Ba=r(qf,"LI",{});var FE=a(Ba);Vv=i(FE,"move all PyTorch modules to the device of your choice"),FE.forEach(t),Yv=f(qf),Ra=r(qf,"LI",{});var XE=a(Ra);Wv=i(XE,"enabling/disabling the progress bar for the denoising iteration"),XE.forEach(t),qf.forEach(t),Hv=f(B),Ga=r(B,"P",{});var zE=a(Ga);Bv=i(zE,"Class attributes:"),zE.forEach(t),Rv=f(B),Ka=r(B,"UL",{});var NE=a(Ka);Yo=r(NE,"LI",{});var jl=a(Yo);Ja=r(jl,"STRONG",{});var UE=a(Ja);Gv=i(UE,"config_name"),UE.forEach(t),Kv=i(jl," ("),Qa=r(jl,"CODE",{});var VE=a(Qa);Jv=i(VE,"str"),VE.forEach(t),Qv=i(jl,`) \u2014 name of the config file that will store the class and module names of all
components of the diffusion pipeline.`),jl.forEach(t),NE.forEach(t),Zv=f(B),C=r(B,"DIV",{class:!0});var R=a(C);b(Es.$$.fragment,R),eb=f(R),Za=r(R,"P",{});var YE=a(Za);ob=i(YE,"Instantiate a PyTorch diffusion pipeline from pre-trained pipeline weights."),YE.forEach(t),tb=f(R),Ds=r(R,"P",{});var Tf=a(Ds);sb=i(Tf,"The pipeline is set in evaluation mode by default using "),el=r(Tf,"CODE",{});var WE=a(el);ib=i(WE,"model.eval()"),WE.forEach(t),nb=i(Tf," (Dropout modules are deactivated)."),Tf.forEach(t),rb=f(R),$s=r(R,"P",{});var If=a($s);ab=i(If,"The warning "),ol=r(If,"EM",{});var HE=a(ol);lb=i(HE,"Weights from XXX not initialized from pretrained model"),HE.forEach(t),db=i(If,` means that the weights of XXX do not come
pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning
task.`),If.forEach(t),fb=f(R),xs=r(R,"P",{});var Sf=a(xs);cb=i(Sf,"The warning "),tl=r(Sf,"EM",{});var BE=a(tl);pb=i(BE,"Weights from XXX not used in YYY"),BE.forEach(t),ub=i(Sf,` means that the layer XXX is not used by YYY, therefore those
weights are discarded.`),Sf.forEach(t),hb=f(R),b(Wo.$$.fragment,R),mb=f(R),b(Ho.$$.fragment,R),gb=f(R),b(Bo.$$.fragment,R),R.forEach(t),_b=f(B),Ro=r(B,"DIV",{class:!0});var Af=a(Ro);b(Ps.$$.fragment,Af),vb=f(Af),ks=r(Af,"P",{});var Lf=a(ks);bb=i(Lf,`Save all variables of the pipeline that can be saved and loaded as well as the pipelines configuration file to
a directory. A pipeline variable can be saved and loaded if its class implements both a save and loading
method. The pipeline can easily be re-loaded using the `),sl=r(Lf,"CODE",{});var RE=a(sl);wb=i(RE,"[from_pretrained()](/docs/diffusers/main/en/using-diffusers/loading#diffusers.DiffusionPipeline.from_pretrained)"),RE.forEach(t),yb=i(Lf," class method."),Lf.forEach(t),Af.forEach(t),B.forEach(t),ef=f(o),Z=r(o,"DIV",{class:!0});var to=a(Z);b(Ms.$$.fragment,to),Eb=f(to),il=r(to,"P",{});var GE=a(il);Db=i(GE,"Base class for all flax models."),GE.forEach(t),$b=f(to),Zi=r(to,"P",{});var Tw=a(Zi);en=r(Tw,"A",{href:!0});var KE=a(en);xb=i(KE,"FlaxModelMixin"),KE.forEach(t),Pb=i(Tw,` takes care of storing the configuration of the models and handles methods for loading,
downloading and saving models.`),Tw.forEach(t),kb=f(to),ae=r(to,"DIV",{class:!0});var so=a(ae);b(js.$$.fragment,so),Mb=f(so),nl=r(so,"P",{});var JE=a(nl);jb=i(JE,"Instantiate a pretrained flax model from a pre-trained model configuration."),JE.forEach(t),qb=f(so),qs=r(so,"P",{});var Cf=a(qs);Tb=i(Cf,"The warning "),rl=r(Cf,"EM",{});var QE=a(rl);Ib=i(QE,"Weights from XXX not initialized from pretrained model"),QE.forEach(t),Sb=i(Cf,` means that the weights of XXX do not come
pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning
task.`),Cf.forEach(t),Ab=f(so),Ts=r(so,"P",{});var Of=a(Ts);Lb=i(Of,"The warning "),al=r(Of,"EM",{});var ZE=a(al);Cb=i(ZE,"Weights from XXX not used in YYY"),ZE.forEach(t),Ob=i(Of,` means that the layer XXX is not used by YYY, therefore those
weights are discarded.`),Of.forEach(t),Fb=f(so),b(Go.$$.fragment,so),so.forEach(t),Xb=f(to),Ko=r(to,"DIV",{class:!0});var Ff=a(Ko);b(Is.$$.fragment,Ff),zb=f(Ff),Ss=r(Ff,"P",{});var Xf=a(Ss);Nb=i(Xf,`Save a model and its configuration file to a directory, so that it can be re-loaded using the
`),ll=r(Xf,"CODE",{});var e5=a(ll);Ub=i(e5,"[from_pretrained()](/docs/diffusers/main/en/using-diffusers/loading#diffusers.FlaxModelMixin.from_pretrained)"),e5.forEach(t),Vb=i(Xf," class method"),Xf.forEach(t),Ff.forEach(t),to.forEach(t),of=f(o),A=r(o,"DIV",{class:!0});var G=a(A);b(As.$$.fragment,G),Yb=f(G),dl=r(G,"P",{});var o5=a(dl);Wb=i(o5,"Base class for all models."),o5.forEach(t),Hb=f(G),on=r(G,"P",{});var Iw=a(on);tn=r(Iw,"A",{href:!0});var t5=a(tn);Bb=i(t5,"FlaxDiffusionPipeline"),t5.forEach(t),Rb=i(Iw,` takes care of storing all components (models, schedulers, processors) for diffusion
pipelines and handles methods for loading, downloading and saving models as well as a few methods common to all
pipelines to:`),Iw.forEach(t),Gb=f(G),fl=r(G,"UL",{});var s5=a(fl);cl=r(s5,"LI",{});var i5=a(cl);Kb=i(i5,"enabling/disabling the progress bar for the denoising iteration"),i5.forEach(t),s5.forEach(t),Jb=f(G),pl=r(G,"P",{});var n5=a(pl);Qb=i(n5,"Class attributes:"),n5.forEach(t),Zb=f(G),ul=r(G,"UL",{});var r5=a(ul);Jo=r(r5,"LI",{});var ql=a(Jo);hl=r(ql,"STRONG",{});var a5=a(hl);ew=i(a5,"config_name"),a5.forEach(t),ow=i(ql," ("),ml=r(ql,"CODE",{});var l5=a(ml);tw=i(l5,"str"),l5.forEach(t),sw=i(ql,`) \u2014 name of the config file that will store the class and module names of all
components of the diffusion pipeline.`),ql.forEach(t),r5.forEach(t),iw=f(G),O=r(G,"DIV",{class:!0});var K=a(O);b(Ls.$$.fragment,K),nw=f(K),gl=r(K,"P",{});var d5=a(gl);rw=i(d5,"Instantiate a Flax diffusion pipeline from pre-trained pipeline weights."),d5.forEach(t),aw=f(K),Cs=r(K,"P",{});var zf=a(Cs);lw=i(zf,"The pipeline is set in evaluation mode by default using "),_l=r(zf,"CODE",{});var f5=a(_l);dw=i(f5,"model.eval()"),f5.forEach(t),fw=i(zf," (Dropout modules are deactivated)."),zf.forEach(t),cw=f(K),Os=r(K,"P",{});var Nf=a(Os);pw=i(Nf,"The warning "),vl=r(Nf,"EM",{});var c5=a(vl);uw=i(c5,"Weights from XXX not initialized from pretrained model"),c5.forEach(t),hw=i(Nf,` means that the weights of XXX do not come
pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning
task.`),Nf.forEach(t),mw=f(K),Fs=r(K,"P",{});var Uf=a(Fs);gw=i(Uf,"The warning "),bl=r(Uf,"EM",{});var p5=a(bl);_w=i(p5,"Weights from XXX not used in YYY"),p5.forEach(t),vw=i(Uf,` means that the layer XXX is not used by YYY, therefore those
weights are discarded.`),Uf.forEach(t),bw=f(K),b(Qo.$$.fragment,K),ww=f(K),b(Zo.$$.fragment,K),yw=f(K),b(et.$$.fragment,K),K.forEach(t),Ew=f(G),ot=r(G,"DIV",{class:!0});var Vf=a(ot);b(Xs.$$.fragment,Vf),Dw=f(Vf),zs=r(Vf,"P",{});var Yf=a(zs);$w=i(Yf,`Save all variables of the pipeline that can be saved and loaded as well as the pipelines configuration file to
a directory. A pipeline variable can be saved and loaded if its class implements both a save and loading
method. The pipeline can easily be re-loaded using the `),wl=r(Yf,"CODE",{});var u5=a(wl);xw=i(u5,"[from_pretrained()](/docs/diffusers/main/en/using-diffusers/loading#diffusers.FlaxDiffusionPipeline.from_pretrained)"),u5.forEach(t),Pw=i(Yf,` class
method.`),Yf.forEach(t),Vf.forEach(t),G.forEach(t),this.h()},h(){c(h,"name","hf:doc:metadata"),c(h,"content",JSON.stringify(q5)),c(_,"id","loading"),c(_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_,"href","#loading"),c(m,"class","relative group"),c(Bs,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.DiffusionPipeline.from_pretrained"),c(Rs,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.ModelMixin.from_pretrained"),c(Gs,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin.from_config"),c(yo,"id","loading-pipelines"),c(yo,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yo,"href","#loading-pipelines"),c(no,"class","relative group"),c(Ks,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.DiffusionPipeline"),c(ut,"href","https://huggingface.co/models?library=diffusers"),c(ut,"rel","nofollow"),c(ht,"href","https://huggingface.co/CompVis/ldm-text2im-large-256"),c(ht,"rel","nofollow"),c(Js,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.DiffusionPipeline"),c(Qs,"href","/docs/diffusers/main/en/api/pipelines/latent_diffusion#diffusers.LDMTextToImagePipeline"),c(Eo,"href","/docs/diffusers/main/en/api/pipelines/latent_diffusion#diffusers.LDMTextToImagePipeline.__call__"),c(Zs,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.DiffusionPipeline"),c(ei,"href","/docs/diffusers/main/en/api/pipelines/latent_diffusion#diffusers.LDMTextToImagePipeline"),c(oi,"href","/docs/diffusers/main/en/api/pipelines/stable_diffusion#diffusers.StableDiffusionPipeline"),c(_t,"href","https://huggingface.co/blog/stable_diffusion#how-does-stable-diffusion-work"),c(_t,"rel","nofollow"),c(ti,"href","./api/overview#diffusers-summary"),c($o,"id","loading-pipelines-that-require-access-request"),c($o,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($o,"href","#loading-pipelines-that-require-access-request"),c(ro,"class","relative group"),c(bt,"href","https://huggingface.co/runwayml/stable-diffusion-v1-5"),c(bt,"rel","nofollow"),c(yt,"href","https://huggingface.co/runwayml/stable-diffusion-v1-5"),c(yt,"rel","nofollow"),c(Dt,"href","https://huggingface.co/runwayml/stable-diffusion-v1-5"),c(Dt,"rel","nofollow"),v5(si.src,Lw="https://raw.githubusercontent.com/huggingface/diffusers/main/docs/source/imgs/access_request.png")||c(si,"src",Lw),c(si,"width","400"),c(xe,"align","center"),c(xt,"href","https://huggingface.co/docs/hub/security-tokens#user-access-tokens"),c(xt,"rel","nofollow"),c(xo,"id","loading-pipelines-locally"),c(xo,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(xo,"href","#loading-pipelines-locally"),c(ao,"class","relative group"),c(ai,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.DiffusionPipeline.from_pretrained"),c(Mt,"href","https://huggingface.co/CompVis/ldm-text2im-large-256"),c(Mt,"rel","nofollow"),c(jt,"href","https://git-lfs.github.com/"),c(jt,"rel","nofollow"),c(qt,"href","https://huggingface.co/CompVis/ldm-text2im-large-256/tree/main"),c(qt,"rel","nofollow"),c(li,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.DiffusionPipeline.from_pretrained"),c(Po,"id","loading-customized-pipelines"),c(Po,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Po,"href","#loading-customized-pipelines"),c(lo,"class","relative group"),c(At,"href","https://huggingface.co/runwayml/stable-diffusion-v1-5"),c(At,"rel","nofollow"),c(di,"href","/docs/diffusers/main/en/api/schedulers#diffusers.PNDMScheduler"),c(fi,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.DiffusionPipeline.from_pretrained"),c(ci,"href","/docs/diffusers/main/en/api/schedulers#diffusers.EulerDiscreteScheduler"),c(pi,"href","/docs/diffusers/main/en/api/schedulers#diffusers.DPMSolverMultistepScheduler"),c(hi,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin.from_config"),c(Ot,"href","https://huggingface.co/runwayml/stable-diffusion-v1-5/tree/main/scheduler"),c(Ot,"rel","nofollow"),c(mi,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.DiffusionPipeline.from_pretrained"),c(gi,"href","/docs/diffusers/main/en/api/pipelines/stable_diffusion#diffusers.StableDiffusionPipeline"),c(Ft,"href","https://github.com/huggingface/diffusers/blob/0dd8c6b4dbab4069de9ed1cafb53cbd495873879/src/diffusers/schedulers/scheduling_ddim.py#L112"),c(Ft,"rel","nofollow"),c(zt,"href","https://huggingface.co/runwayml/stable-diffusion-v1-5"),c(zt,"rel","nofollow"),c(_i,"href","/docs/diffusers/main/en/api/pipelines/stable_diffusion#diffusers.StableDiffusionPipeline"),c(vi,"href","/docs/diffusers/main/en/api/pipelines/stable_diffusion#diffusers.StableDiffusionImg2ImgPipeline"),c(bi,"href","/docs/diffusers/main/en/api/diffusion_pipeline#diffusers.DiffusionPipeline.components"),c(jo,"id","how-does-loading-work"),c(jo,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(jo,"href","#how-does-loading-work"),c(fo,"class","relative group"),c(wi,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.DiffusionPipeline.from_pretrained"),c(yi,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.DiffusionPipeline.from_pretrained"),c(Ei,"href","./api/overview#diffusers-summary"),c(Di,"href","/docs/diffusers/main/en/api/pipelines/latent_diffusion#diffusers.LDMTextToImagePipeline"),c(Vt,"href","https://huggingface.co/CompVis/ldm-text2im-large-256"),c(Vt,"rel","nofollow"),c($i,"href","/docs/diffusers/main/en/api/pipelines/latent_diffusion#diffusers.LDMTextToImagePipeline"),c(Bt,"href","https://github.com/huggingface/diffusers/blob/cd502b25cf0debac6f98d27a6638ef95208d1ea2/src/diffusers/pipelines/latent_diffusion/pipeline_latent_diffusion.py#L664"),c(Bt,"rel","nofollow"),c(xi,"href","/docs/diffusers/main/en/api/schedulers#diffusers.DDIMScheduler"),c(Io,"href","https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertTokenizer"),c(Io,"rel","nofollow"),c(Pi,"href","/docs/diffusers/main/en/api/models#diffusers.UNet2DConditionModel"),c(ki,"href","/docs/diffusers/main/en/api/models#diffusers.AutoencoderKL"),c(Jt,"href","https://huggingface.co/CompVis/ldm-text2im-large-256/tree/main"),c(Jt,"rel","nofollow"),c(os,"href","https://huggingface.co/CompVis/ldm-text2im-large-256/tree/main/bert"),c(os,"rel","nofollow"),c(ts,"href","https://github.com/huggingface/diffusers/blob/cd502b25cf0debac6f98d27a6638ef95208d1ea2/src/diffusers/pipelines/latent_diffusion/pipeline_latent_diffusion.py#L42"),c(ts,"rel","nofollow"),c(ss,"href","https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertTokenizer"),c(ss,"rel","nofollow"),c(Mi,"href","/docs/diffusers/main/en/api/models#diffusers.UNet2DConditionModel"),c(Co,"id","loading-models"),c(Co,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Co,"href","#loading-models"),c(uo,"class","relative group"),c(ns,"href","https://github.com/huggingface/diffusers/tree/main/src/diffusers/models"),c(ns,"rel","nofollow"),c(ji,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.ModelMixin.from_pretrained"),c(qi,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.DiffusionPipeline.from_pretrained"),c(Ti,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.ModelMixin.from_pretrained"),c(Ii,"href","./api/models"),c(Si,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.DiffusionPipeline.from_pretrained"),c(Li,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.ModelMixin.from_pretrained"),c(as,"href","https://huggingface.co/CompVis/ldm-text2im-large-256/tree/main/unet"),c(as,"rel","nofollow"),c(Ci,"href","%22./using-diffusers/loading#loading-customized-pipelines%22"),c(Oi,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.DiffusionPipeline.from_pretrained"),c(ds,"href","https://huggingface.co/google/ddpm-cifar10-32"),c(ds,"rel","nofollow"),c(Fo,"id","loading-schedulers"),c(Fo,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Fo,"href","#loading-schedulers"),c(mo,"class","relative group"),c(Fi,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin.from_config"),c(zi,"href","/docs/diffusers/main/en/api/schedulers#diffusers.DDPMScheduler"),c(Ni,"href","/docs/diffusers/main/en/api/schedulers#diffusers.DDIMScheduler"),c(Ui,"href","/docs/diffusers/main/en/api/schedulers#diffusers.PNDMScheduler"),c(Vi,"href","/docs/diffusers/main/en/api/schedulers#diffusers.LMSDiscreteScheduler"),c(Yi,"href","/docs/diffusers/main/en/api/schedulers#diffusers.EulerDiscreteScheduler"),c(Wi,"href","/docs/diffusers/main/en/api/schedulers#diffusers.EulerAncestralDiscreteScheduler"),c(Hi,"href","/docs/diffusers/main/en/api/schedulers#diffusers.DPMSolverMultistepScheduler"),c(Bi,"href","/docs/diffusers/main/en/api/pipelines/stable_diffusion#diffusers.StableDiffusionPipeline"),c(zo,"id","diffusers.ModelMixin"),c(zo,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zo,"href","#diffusers.ModelMixin"),c(go,"class","relative group"),c(Gi,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.ModelMixin"),c(Ki,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.ModelMixin.save_pretrained"),c(Y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(H,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qi,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.DiffusionPipeline"),c(C,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(S,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(en,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.FlaxModelMixin"),c(ae,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tn,"href","/docs/diffusers/main/en/using-diffusers/loading#diffusers.FlaxDiffusionPipeline"),c(O,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(A,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(o,l){e(document.head,h),p(o,x,l),p(o,m,l),e(m,_),e(_,$),w(u,$,null),e(m,g),e(m,k),e(k,T),p(o,I,l),p(o,X,l),e(X,z),e(X,ce),e(ce,J),e(X,P),p(o,Me,l),p(o,he,l),e(he,io),p(o,je,l),p(o,qe,l),e(qe,dt),e(dt,xn),e(xn,Wf),e(dt,Hf),e(dt,Bs),e(Bs,Bf),e(qe,Rf),e(qe,ft),e(ft,Pn),e(Pn,Gf),e(ft,Kf),e(ft,Rs),e(Rs,Jf),e(qe,Qf),e(qe,ct),e(ct,kn),e(kn,Zf),e(ct,ec),e(ct,Gs),e(Gs,oc),p(o,Tl,l),p(o,no,l),e(no,yo),e(yo,Mn),w(pt,Mn,null),e(no,tc),e(no,jn),e(jn,sc),p(o,Il,l),p(o,me,l),e(me,ic),e(me,Ks),e(Ks,nc),e(me,rc),e(me,ut),e(ut,ac),e(me,lc),e(me,ht),e(ht,dc),e(me,fc),p(o,Sl,l),w(mt,o,l),p(o,Al,l),p(o,N,l),e(N,cc),e(N,Js),e(Js,pc),e(N,uc),e(N,qn),e(qn,hc),e(N,mc),e(N,Qs),e(Qs,gc),e(N,_c),e(N,Tn),e(Tn,vc),e(N,bc),e(N,Eo),e(Eo,wc),e(Eo,In),e(In,yc),e(Eo,Ec),e(N,Dc),e(N,Sn),e(Sn,$c),e(N,xc),p(o,Ll,l),p(o,Do,l),e(Do,Pc),e(Do,Zs),e(Zs,kc),e(Do,Mc),p(o,Cl,l),w(gt,o,l),p(o,Ol,l),p(o,q,l),e(q,jc),e(q,An),e(An,qc),e(q,Tc),e(q,Ln),e(Ln,Ic),e(q,Sc),e(q,Cn),e(Cn,Ac),e(q,Lc),e(q,On),e(On,Cc),e(q,Oc),e(q,ei),e(ei,Fc),e(q,Xc),e(q,oi),e(oi,zc),e(q,Nc),e(q,_t),e(_t,Uc),e(q,Vc),e(q,ti),e(ti,Yc),e(q,Wc),p(o,Fl,l),p(o,ro,l),e(ro,$o),e($o,Fn),w(vt,Fn,null),e(ro,Hc),e(ro,Xn),e(Xn,Bc),p(o,Xl,l),p(o,Te,l),e(Te,Rc),e(Te,zn),e(zn,Gc),e(Te,Kc),e(Te,bt),e(bt,Nn),e(Nn,Jc),e(Te,Qc),p(o,zl,l),w(wt,o,l),p(o,Nl,l),p(o,Ie,l),e(Ie,Zc),e(Ie,Un),e(Un,ep),e(Ie,op),e(Ie,yt),e(yt,tp),e(Ie,sp),p(o,Ul,l),w(Et,o,l),p(o,Vl,l),p(o,Se,l),e(Se,ip),e(Se,Vn),e(Vn,np),e(Se,rp),e(Se,Dt),e(Dt,ap),e(Se,lp),p(o,Yl,l),p(o,xe,l),e(xe,dp),e(xe,fp),e(xe,si),e(xe,cp),e(xe,pp),p(o,Wl,l),p(o,ii,l),e(ii,up),p(o,Hl,l),w($t,o,l),p(o,Bl,l),p(o,oe,l),e(oe,hp),e(oe,xt),e(xt,mp),e(oe,gp),e(oe,Yn),e(Yn,_p),e(oe,vp),e(oe,Wn),e(Wn,bp),e(oe,wp),e(oe,Hn),e(Hn,yp),e(oe,Ep),p(o,Rl,l),w(Pt,o,l),p(o,Gl,l),p(o,ni,l),e(ni,Dp),p(o,Kl,l),p(o,ao,l),e(ao,xo),e(xo,Bn),w(kt,Bn,null),e(ao,$p),e(ao,Rn),e(Rn,xp),p(o,Jl,l),p(o,ri,l),e(ri,Pp),p(o,Ql,l),p(o,Ae,l),e(Ae,kp),e(Ae,ai),e(ai,Mp),e(Ae,jp),e(Ae,Mt),e(Mt,qp),e(Ae,Tp),p(o,Zl,l),p(o,Le,l),e(Le,Ip),e(Le,jt),e(jt,Gn),e(Gn,Sp),e(Le,Ap),e(Le,qt),e(qt,Lp),e(Le,Cp),p(o,ed,l),w(Tt,o,l),p(o,od,l),p(o,Ce,l),e(Ce,Op),e(Ce,Kn),e(Kn,Fp),e(Ce,Xp),e(Ce,Jn),e(Jn,zp),e(Ce,Np),p(o,td,l),w(It,o,l),p(o,sd,l),p(o,Oe,l),e(Oe,Up),e(Oe,Qn),e(Qn,Vp),e(Oe,Yp),e(Oe,li),e(li,Wp),e(Oe,Hp),p(o,id,l),p(o,lo,l),e(lo,Po),e(Po,Zn),w(St,Zn,null),e(lo,Bp),e(lo,er),e(er,Rp),p(o,nd,l),p(o,te,l),e(te,Gp),e(te,or),e(or,Kp),e(te,Jp),e(te,At),e(At,Qp),e(te,Zp),e(te,di),e(di,eu),e(te,ou),e(te,fi),e(fi,tu),e(te,su),p(o,rd,l),p(o,Pe,l),e(Pe,tr),e(tr,iu),e(Pe,nu),e(Pe,ci),e(ci,ru),e(Pe,au),e(Pe,pi),e(pi,lu),e(Pe,du),p(o,ad,l),w(Lt,o,l),p(o,ld,l),p(o,ui,l),e(ui,fu),p(o,dd,l),p(o,Fe,l),e(Fe,Ct),e(Ct,cu),e(Ct,hi),e(hi,pu),e(Ct,uu),e(Fe,hu),e(Fe,ko),e(ko,mu),e(ko,sr),e(sr,gu),e(ko,_u),e(ko,Ot),e(Ot,vu),e(Fe,bu),e(Fe,U),e(U,wu),e(U,ir),e(ir,yu),e(U,Eu),e(U,mi),e(mi,Du),e(U,$u),e(U,gi),e(gi,xu),e(U,Pu),e(U,nr),e(nr,ku),e(U,Mu),e(U,rr),e(rr,ju),e(U,qu),e(U,ar),e(ar,Tu),e(U,Iu),e(U,lr),e(lr,Su),p(o,fd,l),p(o,ge,l),e(ge,Au),e(ge,dr),e(dr,Lu),e(ge,Cu),e(ge,Ft),e(Ft,Ou),e(ge,Fu),e(ge,fr),e(fr,Xu),e(ge,zu),p(o,cd,l),p(o,Xe,l),e(Xe,Nu),e(Xe,cr),e(cr,Uu),e(Xe,Vu),e(Xe,pr),e(pr,Yu),e(Xe,Wu),p(o,pd,l),w(Xt,o,l),p(o,ud,l),p(o,se,l),e(se,Hu),e(se,ur),e(ur,Bu),e(se,Ru),e(se,zt),e(zt,hr),e(hr,Gu),e(se,Ku),e(se,_i),e(_i,Ju),e(se,Qu),e(se,vi),e(vi,Zu),e(se,eh),p(o,hd,l),w(Nt,o,l),p(o,md,l),p(o,Mo,l),e(Mo,oh),e(Mo,bi),e(bi,th),e(Mo,sh),p(o,gd,l),p(o,fo,l),e(fo,jo),e(jo,mr),w(Ut,mr,null),e(fo,ih),e(fo,gr),e(gr,nh),p(o,_d,l),p(o,qo,l),e(qo,rh),e(qo,wi),e(wi,ah),e(qo,lh),p(o,vd,l),p(o,To,l),e(To,pe),e(pe,dh),e(pe,_r),e(_r,fh),e(pe,ch),e(pe,vr),e(vr,ph),e(pe,uh),e(pe,yi),e(yi,hh),e(pe,mh),e(pe,br),e(br,gh),e(pe,_h),e(To,vh),e(To,ue),e(ue,bh),e(ue,wr),e(wr,wh),e(ue,yh),e(ue,Ei),e(Ei,Eh),e(ue,Dh),e(ue,yr),e(yr,$h),e(ue,xh),e(ue,Er),e(Er,Ph),e(ue,kh),p(o,bd,l),p(o,ie,l),e(ie,Mh),e(ie,Dr),e(Dr,jh),e(ie,qh),e(ie,Di),e(Di,Th),e(ie,Ih),e(ie,Vt),e(Vt,$r),e($r,Sh),e(ie,Ah),e(ie,xr),e(xr,Lh),e(ie,Ch),p(o,wd,l),w(Yt,o,l),p(o,yd,l),p(o,Wt,l),e(Wt,Pr),e(Pr,Oh),e(Wt,Fh),p(o,Ed,l),w(Ht,o,l),p(o,Dd,l),p(o,ze,l),e(ze,Xh),e(ze,$i),e($i,zh),e(ze,Nh),e(ze,kr),e(kr,Uh),e(ze,Vh),p(o,$d,l),p(o,ne,l),e(ne,co),e(co,Mr),e(Mr,Yh),e(co,Wh),e(co,jr),e(jr,Hh),e(co,Bh),e(co,Bt),e(Bt,Rh),e(ne,Gh),e(ne,Rt),e(Rt,qr),e(qr,Kh),e(Rt,Jh),e(Rt,xi),e(xi,Qh),e(ne,Zh),e(ne,po),e(po,Tr),e(Tr,em),e(po,om),e(po,Ir),e(Ir,tm),e(po,sm),e(po,Io),e(Io,im),e(Io,Sr),e(Sr,nm),e(ne,rm),e(ne,Gt),e(Gt,Ar),e(Ar,am),e(Gt,lm),e(Gt,Pi),e(Pi,dm),e(ne,fm),e(ne,Kt),e(Kt,Lr),e(Lr,cm),e(Kt,pm),e(Kt,ki),e(ki,um),p(o,xd,l),p(o,_e,l),e(_e,hm),e(_e,Cr),e(Cr,mm),e(_e,gm),e(_e,Jt),e(Jt,Or),e(Or,_m),e(_e,vm),e(_e,Fr),e(Fr,bm),e(_e,wm),p(o,Pd,l),w(Qt,o,l),p(o,kd,l),p(o,M,l),e(M,ym),e(M,Xr),e(Xr,Em),e(M,Dm),e(M,zr),e(zr,$m),e(M,xm),e(M,Nr),e(Nr,Pm),e(M,km),e(M,Ur),e(Ur,Mm),e(M,jm),e(M,Vr),e(Vr,qm),e(M,Tm),e(M,Yr),e(Yr,Im),e(M,Sm),e(M,Wr),e(Wr,Am),e(M,Lm),e(M,Hr),e(Hr,Cm),e(M,Om),e(M,Br),e(Br,Fm),e(M,Xm),p(o,Md,l),p(o,So,l),e(So,Rr),e(Rr,zm),e(So,Nm),e(So,Gr),e(Gr,Um),p(o,jd,l),p(o,Ne,l),e(Ne,Vm),e(Ne,Kr),e(Kr,Ym),e(Ne,Wm),e(Ne,Jr),e(Jr,Hm),e(Ne,Bm),p(o,qd,l),w(Zt,o,l),p(o,Td,l),p(o,Ue,l),e(Ue,Ao),e(Ao,Qr),e(Qr,Rm),e(Ao,Gm),e(Ao,Zr),e(Zr,Km),e(Ao,Jm),e(Ue,Qm),e(Ue,Lo),e(Lo,ea),e(ea,Zm),e(Lo,eg),e(Lo,oa),e(oa,og),e(Lo,tg),e(Ue,sg),e(Ue,ta),e(ta,ig),p(o,Id,l),w(es,o,l),p(o,Sd,l),p(o,Ve,l),e(Ve,Ye),e(Ye,ng),e(Ye,sa),e(sa,rg),e(Ye,ag),e(Ye,os),e(os,lg),e(Ye,dg),e(Ye,ts),e(ts,fg),e(Ve,cg),e(Ve,Q),e(Q,pg),e(Q,ia),e(ia,ug),e(Q,hg),e(Q,na),e(na,mg),e(Q,gg),e(Q,ra),e(ra,_g),e(Q,vg),e(Q,aa),e(aa,bg),e(Q,wg),e(Q,la),e(la,yg),e(Q,Eg),e(Ve,Dg),e(Ve,ve),e(ve,$g),e(ve,da),e(da,xg),e(ve,Pg),e(ve,fa),e(fa,kg),e(ve,Mg),e(ve,ss),e(ss,ca),e(ca,jg),e(ve,qg),e(ve,Mi),e(Mi,Tg),p(o,Ad,l),p(o,uo,l),e(uo,Co),e(Co,pa),w(is,pa,null),e(uo,Ig),e(uo,ua),e(ua,Sg),p(o,Ld,l),p(o,be,l),e(be,Ag),e(be,ns),e(ns,Lg),e(be,Cg),e(be,ji),e(ji,Og),e(be,Fg),e(be,qi),e(qi,Xg),e(be,zg),p(o,Cd,l),p(o,Oo,l),e(Oo,ke),e(ke,Ng),e(ke,ha),e(ha,Ug),e(ke,Vg),e(ke,Ti),e(Ti,Yg),e(ke,Wg),e(ke,ma),e(ma,Hg),e(ke,Bg),e(Oo,Rg),e(Oo,ho),e(ho,Gg),e(ho,ga),e(ga,Kg),e(ho,Jg),e(ho,Ii),e(Ii,Qg),e(ho,Zg),p(o,Od,l),p(o,we,l),e(we,e_),e(we,Si),e(Si,o_),e(we,t_),e(we,_a),e(_a,s_),e(we,i_),e(we,va),e(va,n_),e(we,r_),p(o,Fd,l),p(o,Ai,l),e(Ai,a_),p(o,Xd,l),w(rs,o,l),p(o,zd,l),p(o,ye,l),e(ye,l_),e(ye,ba),e(ba,d_),e(ye,f_),e(ye,Li),e(Li,c_),e(ye,p_),e(ye,as),e(as,u_),e(ye,h_),p(o,Nd,l),p(o,We,l),e(We,m_),e(We,Ci),e(Ci,g_),e(We,__),e(We,Oi),e(Oi,v_),e(We,b_),p(o,Ud,l),w(ls,o,l),p(o,Vd,l),p(o,He,l),e(He,w_),e(He,ds),e(ds,wa),e(wa,y_),e(He,E_),e(He,ya),e(ya,D_),e(He,$_),p(o,Yd,l),w(fs,o,l),p(o,Wd,l),p(o,mo,l),e(mo,Fo),e(Fo,Ea),w(cs,Ea,null),e(mo,x_),e(mo,Da),e(Da,P_),p(o,Hd,l),p(o,re,l),e(re,k_),e(re,$a),e($a,M_),e(re,j_),e(re,Fi),e(Fi,q_),e(re,T_),e(re,xa),e(xa,I_),e(re,S_),e(re,Pa),e(Pa,A_),e(re,L_),p(o,Bd,l),p(o,Xi,l),e(Xi,C_),p(o,Rd,l),p(o,V,l),e(V,ka),e(ka,zi),e(zi,O_),e(V,F_),e(V,Ma),e(Ma,Ni),e(Ni,X_),e(V,z_),e(V,ja),e(ja,Ui),e(Ui,N_),e(V,U_),e(V,qa),e(qa,Vi),e(Vi,V_),e(V,Y_),e(V,Ta),e(Ta,Yi),e(Yi,W_),e(V,H_),e(V,Ia),e(Ia,Wi),e(Wi,B_),e(V,R_),e(V,Sa),e(Sa,Hi),e(Hi,G_),p(o,Gd,l),p(o,Xo,l),e(Xo,K_),e(Xo,Bi),e(Bi,J_),e(Xo,Q_),p(o,Kd,l),w(ps,o,l),p(o,Jd,l),p(o,go,l),e(go,zo),e(zo,Aa),w(us,Aa,null),e(go,Z_),e(go,La),e(La,ev),p(o,Qd,l),p(o,H,l),w(hs,H,null),e(H,ov),e(H,Ca),e(Ca,tv),e(H,sv),e(H,Ri),e(Ri,Gi),e(Gi,iv),e(Ri,nv),e(H,rv),e(H,Oa),e(Oa,Be),e(Be,Fa),e(Fa,av),e(Be,lv),e(Be,Xa),e(Xa,dv),e(Be,fv),e(Be,Ki),e(Ki,cv),e(Be,pv),e(H,uv),e(H,Y),w(ms,Y,null),e(Y,hv),e(Y,za),e(za,mv),e(Y,gv),e(Y,_o),e(_o,_v),e(_o,Na),e(Na,vv),e(_o,bv),e(_o,Ua),e(Ua,wv),e(_o,yv),e(Y,Ev),e(Y,gs),e(gs,Dv),e(gs,Va),e(Va,$v),e(gs,xv),e(Y,Pv),e(Y,_s),e(_s,kv),e(_s,Ya),e(Ya,Mv),e(_s,jv),e(Y,qv),w(No,Y,null),e(Y,Tv),w(Uo,Y,null),e(H,Iv),e(H,Vo),w(vs,Vo,null),e(Vo,Sv),e(Vo,bs),e(bs,Av),e(bs,Wa),e(Wa,Lv),e(bs,Cv),p(o,Zd,l),p(o,S,l),w(ws,S,null),e(S,Ov),e(S,Ha),e(Ha,Fv),e(S,Xv),e(S,Ji),e(Ji,Qi),e(Qi,zv),e(Ji,Nv),e(S,Uv),e(S,ys),e(ys,Ba),e(Ba,Vv),e(ys,Yv),e(ys,Ra),e(Ra,Wv),e(S,Hv),e(S,Ga),e(Ga,Bv),e(S,Rv),e(S,Ka),e(Ka,Yo),e(Yo,Ja),e(Ja,Gv),e(Yo,Kv),e(Yo,Qa),e(Qa,Jv),e(Yo,Qv),e(S,Zv),e(S,C),w(Es,C,null),e(C,eb),e(C,Za),e(Za,ob),e(C,tb),e(C,Ds),e(Ds,sb),e(Ds,el),e(el,ib),e(Ds,nb),e(C,rb),e(C,$s),e($s,ab),e($s,ol),e(ol,lb),e($s,db),e(C,fb),e(C,xs),e(xs,cb),e(xs,tl),e(tl,pb),e(xs,ub),e(C,hb),w(Wo,C,null),e(C,mb),w(Ho,C,null),e(C,gb),w(Bo,C,null),e(S,_b),e(S,Ro),w(Ps,Ro,null),e(Ro,vb),e(Ro,ks),e(ks,bb),e(ks,sl),e(sl,wb),e(ks,yb),p(o,ef,l),p(o,Z,l),w(Ms,Z,null),e(Z,Eb),e(Z,il),e(il,Db),e(Z,$b),e(Z,Zi),e(Zi,en),e(en,xb),e(Zi,Pb),e(Z,kb),e(Z,ae),w(js,ae,null),e(ae,Mb),e(ae,nl),e(nl,jb),e(ae,qb),e(ae,qs),e(qs,Tb),e(qs,rl),e(rl,Ib),e(qs,Sb),e(ae,Ab),e(ae,Ts),e(Ts,Lb),e(Ts,al),e(al,Cb),e(Ts,Ob),e(ae,Fb),w(Go,ae,null),e(Z,Xb),e(Z,Ko),w(Is,Ko,null),e(Ko,zb),e(Ko,Ss),e(Ss,Nb),e(Ss,ll),e(ll,Ub),e(Ss,Vb),p(o,of,l),p(o,A,l),w(As,A,null),e(A,Yb),e(A,dl),e(dl,Wb),e(A,Hb),e(A,on),e(on,tn),e(tn,Bb),e(on,Rb),e(A,Gb),e(A,fl),e(fl,cl),e(cl,Kb),e(A,Jb),e(A,pl),e(pl,Qb),e(A,Zb),e(A,ul),e(ul,Jo),e(Jo,hl),e(hl,ew),e(Jo,ow),e(Jo,ml),e(ml,tw),e(Jo,sw),e(A,iw),e(A,O),w(Ls,O,null),e(O,nw),e(O,gl),e(gl,rw),e(O,aw),e(O,Cs),e(Cs,lw),e(Cs,_l),e(_l,dw),e(Cs,fw),e(O,cw),e(O,Os),e(Os,pw),e(Os,vl),e(vl,uw),e(Os,hw),e(O,mw),e(O,Fs),e(Fs,gw),e(Fs,bl),e(bl,_w),e(Fs,vw),e(O,bw),w(Qo,O,null),e(O,ww),w(Zo,O,null),e(O,yw),w(et,O,null),e(A,Ew),e(A,ot),w(Xs,ot,null),e(ot,Dw),e(ot,zs),e(zs,$w),e(zs,wl),e(wl,xw),e(zs,Pw),tf=!0},p(o,[l]){const Ns={};l&2&&(Ns.$$scope={dirty:l,ctx:o}),No.$set(Ns);const yl={};l&2&&(yl.$$scope={dirty:l,ctx:o}),Uo.$set(yl);const El={};l&2&&(El.$$scope={dirty:l,ctx:o}),Wo.$set(El);const Dl={};l&2&&(Dl.$$scope={dirty:l,ctx:o}),Ho.$set(Dl);const Us={};l&2&&(Us.$$scope={dirty:l,ctx:o}),Bo.$set(Us);const $l={};l&2&&($l.$$scope={dirty:l,ctx:o}),Go.$set($l);const xl={};l&2&&(xl.$$scope={dirty:l,ctx:o}),Qo.$set(xl);const vo={};l&2&&(vo.$$scope={dirty:l,ctx:o}),Zo.$set(vo);const Vs={};l&2&&(Vs.$$scope={dirty:l,ctx:o}),et.$set(Vs)},i(o){tf||(y(u.$$.fragment,o),y(pt.$$.fragment,o),y(mt.$$.fragment,o),y(gt.$$.fragment,o),y(vt.$$.fragment,o),y(wt.$$.fragment,o),y(Et.$$.fragment,o),y($t.$$.fragment,o),y(Pt.$$.fragment,o),y(kt.$$.fragment,o),y(Tt.$$.fragment,o),y(It.$$.fragment,o),y(St.$$.fragment,o),y(Lt.$$.fragment,o),y(Xt.$$.fragment,o),y(Nt.$$.fragment,o),y(Ut.$$.fragment,o),y(Yt.$$.fragment,o),y(Ht.$$.fragment,o),y(Qt.$$.fragment,o),y(Zt.$$.fragment,o),y(es.$$.fragment,o),y(is.$$.fragment,o),y(rs.$$.fragment,o),y(ls.$$.fragment,o),y(fs.$$.fragment,o),y(cs.$$.fragment,o),y(ps.$$.fragment,o),y(us.$$.fragment,o),y(hs.$$.fragment,o),y(ms.$$.fragment,o),y(No.$$.fragment,o),y(Uo.$$.fragment,o),y(vs.$$.fragment,o),y(ws.$$.fragment,o),y(Es.$$.fragment,o),y(Wo.$$.fragment,o),y(Ho.$$.fragment,o),y(Bo.$$.fragment,o),y(Ps.$$.fragment,o),y(Ms.$$.fragment,o),y(js.$$.fragment,o),y(Go.$$.fragment,o),y(Is.$$.fragment,o),y(As.$$.fragment,o),y(Ls.$$.fragment,o),y(Qo.$$.fragment,o),y(Zo.$$.fragment,o),y(et.$$.fragment,o),y(Xs.$$.fragment,o),tf=!0)},o(o){E(u.$$.fragment,o),E(pt.$$.fragment,o),E(mt.$$.fragment,o),E(gt.$$.fragment,o),E(vt.$$.fragment,o),E(wt.$$.fragment,o),E(Et.$$.fragment,o),E($t.$$.fragment,o),E(Pt.$$.fragment,o),E(kt.$$.fragment,o),E(Tt.$$.fragment,o),E(It.$$.fragment,o),E(St.$$.fragment,o),E(Lt.$$.fragment,o),E(Xt.$$.fragment,o),E(Nt.$$.fragment,o),E(Ut.$$.fragment,o),E(Yt.$$.fragment,o),E(Ht.$$.fragment,o),E(Qt.$$.fragment,o),E(Zt.$$.fragment,o),E(es.$$.fragment,o),E(is.$$.fragment,o),E(rs.$$.fragment,o),E(ls.$$.fragment,o),E(fs.$$.fragment,o),E(cs.$$.fragment,o),E(ps.$$.fragment,o),E(us.$$.fragment,o),E(hs.$$.fragment,o),E(ms.$$.fragment,o),E(No.$$.fragment,o),E(Uo.$$.fragment,o),E(vs.$$.fragment,o),E(ws.$$.fragment,o),E(Es.$$.fragment,o),E(Wo.$$.fragment,o),E(Ho.$$.fragment,o),E(Bo.$$.fragment,o),E(Ps.$$.fragment,o),E(Ms.$$.fragment,o),E(js.$$.fragment,o),E(Go.$$.fragment,o),E(Is.$$.fragment,o),E(As.$$.fragment,o),E(Ls.$$.fragment,o),E(Qo.$$.fragment,o),E(Zo.$$.fragment,o),E(et.$$.fragment,o),E(Xs.$$.fragment,o),tf=!1},d(o){t(h),o&&t(x),o&&t(m),D(u),o&&t(I),o&&t(X),o&&t(Me),o&&t(he),o&&t(je),o&&t(qe),o&&t(Tl),o&&t(no),D(pt),o&&t(Il),o&&t(me),o&&t(Sl),D(mt,o),o&&t(Al),o&&t(N),o&&t(Ll),o&&t(Do),o&&t(Cl),D(gt,o),o&&t(Ol),o&&t(q),o&&t(Fl),o&&t(ro),D(vt),o&&t(Xl),o&&t(Te),o&&t(zl),D(wt,o),o&&t(Nl),o&&t(Ie),o&&t(Ul),D(Et,o),o&&t(Vl),o&&t(Se),o&&t(Yl),o&&t(xe),o&&t(Wl),o&&t(ii),o&&t(Hl),D($t,o),o&&t(Bl),o&&t(oe),o&&t(Rl),D(Pt,o),o&&t(Gl),o&&t(ni),o&&t(Kl),o&&t(ao),D(kt),o&&t(Jl),o&&t(ri),o&&t(Ql),o&&t(Ae),o&&t(Zl),o&&t(Le),o&&t(ed),D(Tt,o),o&&t(od),o&&t(Ce),o&&t(td),D(It,o),o&&t(sd),o&&t(Oe),o&&t(id),o&&t(lo),D(St),o&&t(nd),o&&t(te),o&&t(rd),o&&t(Pe),o&&t(ad),D(Lt,o),o&&t(ld),o&&t(ui),o&&t(dd),o&&t(Fe),o&&t(fd),o&&t(ge),o&&t(cd),o&&t(Xe),o&&t(pd),D(Xt,o),o&&t(ud),o&&t(se),o&&t(hd),D(Nt,o),o&&t(md),o&&t(Mo),o&&t(gd),o&&t(fo),D(Ut),o&&t(_d),o&&t(qo),o&&t(vd),o&&t(To),o&&t(bd),o&&t(ie),o&&t(wd),D(Yt,o),o&&t(yd),o&&t(Wt),o&&t(Ed),D(Ht,o),o&&t(Dd),o&&t(ze),o&&t($d),o&&t(ne),o&&t(xd),o&&t(_e),o&&t(Pd),D(Qt,o),o&&t(kd),o&&t(M),o&&t(Md),o&&t(So),o&&t(jd),o&&t(Ne),o&&t(qd),D(Zt,o),o&&t(Td),o&&t(Ue),o&&t(Id),D(es,o),o&&t(Sd),o&&t(Ve),o&&t(Ad),o&&t(uo),D(is),o&&t(Ld),o&&t(be),o&&t(Cd),o&&t(Oo),o&&t(Od),o&&t(we),o&&t(Fd),o&&t(Ai),o&&t(Xd),D(rs,o),o&&t(zd),o&&t(ye),o&&t(Nd),o&&t(We),o&&t(Ud),D(ls,o),o&&t(Vd),o&&t(He),o&&t(Yd),D(fs,o),o&&t(Wd),o&&t(mo),D(cs),o&&t(Hd),o&&t(re),o&&t(Bd),o&&t(Xi),o&&t(Rd),o&&t(V),o&&t(Gd),o&&t(Xo),o&&t(Kd),D(ps,o),o&&t(Jd),o&&t(go),D(us),o&&t(Qd),o&&t(H),D(hs),D(ms),D(No),D(Uo),D(vs),o&&t(Zd),o&&t(S),D(ws),D(Es),D(Wo),D(Ho),D(Bo),D(Ps),o&&t(ef),o&&t(Z),D(Ms),D(js),D(Go),D(Is),o&&t(of),o&&t(A),D(As),D(Ls),D(Qo),D(Zo),D(et),D(Xs)}}}const q5={local:"loading",sections:[{local:"loading-pipelines",sections:[{local:"loading-pipelines-that-require-access-request",title:"Loading pipelines that require access request"},{local:"loading-pipelines-locally",title:"Loading pipelines locally"},{local:"loading-customized-pipelines",title:"Loading customized pipelines"},{local:"how-does-loading-work",title:"How does loading work?"}],title:"Loading pipelines"},{local:"loading-models",title:"Loading models"},{local:"loading-schedulers",title:"Loading schedulers"},{local:"diffusers.ModelMixin",title:"API"}],title:"Loading"};function T5(L){return b5(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class F5 extends h5{constructor(h){super();m5(this,h,T5,j5,g5,{})}}export{F5 as default,q5 as metadata};
