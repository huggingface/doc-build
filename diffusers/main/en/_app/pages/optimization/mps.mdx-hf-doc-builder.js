import{S as Qo,i as Xo,s as Zo,e as r,k as l,w as te,t as i,M as er,c as s,d as o,m as p,a,x as oe,h as n,b as f,G as e,g as c,y as re,L as tr,q as se,o as ae,B as ie,v as or}from"../../chunks/vendor-hf-doc-builder.js";import{I as Ne}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as rr}from"../../chunks/CodeBlock-hf-doc-builder.js";function sr(ho){let d,je,v,k,ne,j,it,le,nt,He,A,lt,pe,pt,ft,Le,w,M,fe,H,ht,he,ct,Oe,u,ce,ut,mt,ue,dt,vt,me,wt,_t,_,gt,L,bt,Et,de,yt,$t,Re,g,D,ve,O,Pt,we,St,Be,m,kt,_e,At,Mt,ge,Dt,Tt,Ue,K,qt,We,R,Ge,b,T,be,B,xt,Ee,It,Fe,q,U,Ct,W,Nt,jt,Ht,E,Lt,G,Ot,Rt,x,ye,Bt,Ut,Wt,Ve,y,I,$e,F,Gt,Pe,Ft,Ke,Y,Vt,Ye,C,Se,$,ke,Kt,Yt,Ae,Jt,zt,Me,Qt,Xt,V,P,De,Zt,eo,Te,to,oo,qe,ro,so,S,xe,ao,io,Ie,no,lo,Ce,po,Je;return j=new Ne({}),H=new Ne({}),O=new Ne({}),R=new rr({props:{code:`# make sure you're logged in with \`huggingface-cli login\`
from diffusers import StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")
pipe = pipe.to("mps")

prompt = "a photo of an astronaut riding a horse on mars"

# First-time "warmup" pass (see explanation above)
_ = pipe(prompt, num_inference_steps=1)

# Results match those from the CPU device after the warmup pass.
image = pipe(prompt).images[0]`,highlighted:`<span class="hljs-comment"># make sure you&#x27;re logged in with \`huggingface-cli login\`</span>
<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>)
pipe = pipe.to(<span class="hljs-string">&quot;mps&quot;</span>)

prompt = <span class="hljs-string">&quot;a photo of an astronaut riding a horse on mars&quot;</span>

<span class="hljs-comment"># First-time &quot;warmup&quot; pass (see explanation above)</span>
_ = pipe(prompt, num_inference_steps=<span class="hljs-number">1</span>)

<span class="hljs-comment"># Results match those from the CPU device after the warmup pass.</span>
image = pipe(prompt).images[<span class="hljs-number">0</span>]`}}),B=new Ne({}),F=new Ne({}),{c(){d=r("meta"),je=l(),v=r("h1"),k=r("a"),ne=r("span"),te(j.$$.fragment),it=l(),le=r("span"),nt=i("How to use Stable Diffusion in Apple Silicon (M1/M2)"),He=l(),A=r("p"),lt=i("\u{1F917} Diffusers is compatible with Apple silicon for Stable Diffusion inference, using the PyTorch "),pe=r("code"),pt=i("mps"),ft=i(" device. These are the steps you need to follow to use your M1 or M2 computer with Stable Diffusion."),Le=l(),w=r("h2"),M=r("a"),fe=r("span"),te(H.$$.fragment),ht=l(),he=r("span"),ct=i("Requirements"),Oe=l(),u=r("ul"),ce=r("li"),ut=i("Mac computer with Apple silicon (M1/M2) hardware."),mt=l(),ue=r("li"),dt=i("macOS 12.3 or later."),vt=l(),me=r("li"),wt=i("arm64 version of Python."),_t=l(),_=r("li"),gt=i("PyTorch "),L=r("a"),bt=i("Preview (Nightly)"),Et=i(", version "),de=r("code"),yt=i("1.14.0.dev20221007"),$t=i(" or later."),Re=l(),g=r("h2"),D=r("a"),ve=r("span"),te(O.$$.fragment),Pt=l(),we=r("span"),St=i("Inference Pipeline"),Be=l(),m=r("p"),kt=i("The snippet below demonstrates how to use the "),_e=r("code"),At=i("mps"),Mt=i(" backend using the familiar "),ge=r("code"),Dt=i("to()"),Tt=i(" interface to move the Stable Diffusion pipeline to your M1 or M2 device."),Ue=l(),K=r("p"),qt=i("We recommend to \u201Cprime\u201D the pipeline using an additional one-time pass through it. This is a temporary workaround for a weird issue we have detected: the first inference pass produces slightly different results than subsequent ones. You only need to do this pass once, and it\u2019s ok to use just one inference step and discard the result."),We=l(),te(R.$$.fragment),Ge=l(),b=r("h2"),T=r("a"),be=r("span"),te(B.$$.fragment),xt=l(),Ee=r("span"),It=i("Known Issues"),Fe=l(),q=r("ul"),U=r("li"),Ct=i("As mentioned above, we are investigating a strange "),W=r("a"),Nt=i("first-time inference issue"),jt=i("."),Ht=l(),E=r("li"),Lt=i("Generating multiple prompts in a batch "),G=r("a"),Ot=i("crashes or doesn\u2019t work reliably"),Rt=i(". We believe this might be related to the "),x=r("a"),ye=r("code"),Bt=i("mps"),Ut=i(" backend in PyTorch"),Wt=i(", but we need to investigate in more depth. For now, we recommend to iterate instead of batching."),Ve=l(),y=r("h2"),I=r("a"),$e=r("span"),te(F.$$.fragment),Gt=l(),Pe=r("span"),Ft=i("Performance"),Ke=l(),Y=r("p"),Vt=i("These are the results we got on a M1 Max MacBook Pro with 64 GB of RAM, running macOS Ventura Version 13.0 Beta (22A5331f). We performed Stable Diffusion text-to-image generation of the same prompt for 50 inference steps, using a guidance scale of 7.5."),Ye=l(),C=r("table"),Se=r("thead"),$=r("tr"),ke=r("th"),Kt=i("Device"),Yt=l(),Ae=r("th"),Jt=i("Steps"),zt=l(),Me=r("th"),Qt=i("Time"),Xt=l(),V=r("tbody"),P=r("tr"),De=r("td"),Zt=i("CPU"),eo=l(),Te=r("td"),to=i("50"),oo=l(),qe=r("td"),ro=i("213.46s"),so=l(),S=r("tr"),xe=r("td"),ao=i("MPS"),io=l(),Ie=r("td"),no=i("50"),lo=l(),Ce=r("td"),po=i("30.81s"),this.h()},l(t){const h=er('[data-svelte="svelte-1phssyn"]',document.head);d=s(h,"META",{name:!0,content:!0}),h.forEach(o),je=p(t),v=s(t,"H1",{class:!0});var ze=a(v);k=s(ze,"A",{id:!0,class:!0,href:!0});var co=a(k);ne=s(co,"SPAN",{});var uo=a(ne);oe(j.$$.fragment,uo),uo.forEach(o),co.forEach(o),it=p(ze),le=s(ze,"SPAN",{});var mo=a(le);nt=n(mo,"How to use Stable Diffusion in Apple Silicon (M1/M2)"),mo.forEach(o),ze.forEach(o),He=p(t),A=s(t,"P",{});var Qe=a(A);lt=n(Qe,"\u{1F917} Diffusers is compatible with Apple silicon for Stable Diffusion inference, using the PyTorch "),pe=s(Qe,"CODE",{});var vo=a(pe);pt=n(vo,"mps"),vo.forEach(o),ft=n(Qe," device. These are the steps you need to follow to use your M1 or M2 computer with Stable Diffusion."),Qe.forEach(o),Le=p(t),w=s(t,"H2",{class:!0});var Xe=a(w);M=s(Xe,"A",{id:!0,class:!0,href:!0});var wo=a(M);fe=s(wo,"SPAN",{});var _o=a(fe);oe(H.$$.fragment,_o),_o.forEach(o),wo.forEach(o),ht=p(Xe),he=s(Xe,"SPAN",{});var go=a(he);ct=n(go,"Requirements"),go.forEach(o),Xe.forEach(o),Oe=p(t),u=s(t,"UL",{});var N=a(u);ce=s(N,"LI",{});var bo=a(ce);ut=n(bo,"Mac computer with Apple silicon (M1/M2) hardware."),bo.forEach(o),mt=p(N),ue=s(N,"LI",{});var Eo=a(ue);dt=n(Eo,"macOS 12.3 or later."),Eo.forEach(o),vt=p(N),me=s(N,"LI",{});var yo=a(me);wt=n(yo,"arm64 version of Python."),yo.forEach(o),_t=p(N),_=s(N,"LI",{});var J=a(_);gt=n(J,"PyTorch "),L=s(J,"A",{href:!0,rel:!0});var $o=a(L);bt=n($o,"Preview (Nightly)"),$o.forEach(o),Et=n(J,", version "),de=s(J,"CODE",{});var Po=a(de);yt=n(Po,"1.14.0.dev20221007"),Po.forEach(o),$t=n(J," or later."),J.forEach(o),N.forEach(o),Re=p(t),g=s(t,"H2",{class:!0});var Ze=a(g);D=s(Ze,"A",{id:!0,class:!0,href:!0});var So=a(D);ve=s(So,"SPAN",{});var ko=a(ve);oe(O.$$.fragment,ko),ko.forEach(o),So.forEach(o),Pt=p(Ze),we=s(Ze,"SPAN",{});var Ao=a(we);St=n(Ao,"Inference Pipeline"),Ao.forEach(o),Ze.forEach(o),Be=p(t),m=s(t,"P",{});var z=a(m);kt=n(z,"The snippet below demonstrates how to use the "),_e=s(z,"CODE",{});var Mo=a(_e);At=n(Mo,"mps"),Mo.forEach(o),Mt=n(z," backend using the familiar "),ge=s(z,"CODE",{});var Do=a(ge);Dt=n(Do,"to()"),Do.forEach(o),Tt=n(z," interface to move the Stable Diffusion pipeline to your M1 or M2 device."),z.forEach(o),Ue=p(t),K=s(t,"P",{});var To=a(K);qt=n(To,"We recommend to \u201Cprime\u201D the pipeline using an additional one-time pass through it. This is a temporary workaround for a weird issue we have detected: the first inference pass produces slightly different results than subsequent ones. You only need to do this pass once, and it\u2019s ok to use just one inference step and discard the result."),To.forEach(o),We=p(t),oe(R.$$.fragment,t),Ge=p(t),b=s(t,"H2",{class:!0});var et=a(b);T=s(et,"A",{id:!0,class:!0,href:!0});var qo=a(T);be=s(qo,"SPAN",{});var xo=a(be);oe(B.$$.fragment,xo),xo.forEach(o),qo.forEach(o),xt=p(et),Ee=s(et,"SPAN",{});var Io=a(Ee);It=n(Io,"Known Issues"),Io.forEach(o),et.forEach(o),Fe=p(t),q=s(t,"UL",{});var tt=a(q);U=s(tt,"LI",{});var ot=a(U);Ct=n(ot,"As mentioned above, we are investigating a strange "),W=s(ot,"A",{href:!0,rel:!0});var Co=a(W);Nt=n(Co,"first-time inference issue"),Co.forEach(o),jt=n(ot,"."),ot.forEach(o),Ht=p(tt),E=s(tt,"LI",{});var Q=a(E);Lt=n(Q,"Generating multiple prompts in a batch "),G=s(Q,"A",{href:!0,rel:!0});var No=a(G);Ot=n(No,"crashes or doesn\u2019t work reliably"),No.forEach(o),Rt=n(Q,". We believe this might be related to the "),x=s(Q,"A",{href:!0,rel:!0});var fo=a(x);ye=s(fo,"CODE",{});var jo=a(ye);Bt=n(jo,"mps"),jo.forEach(o),Ut=n(fo," backend in PyTorch"),fo.forEach(o),Wt=n(Q,", but we need to investigate in more depth. For now, we recommend to iterate instead of batching."),Q.forEach(o),tt.forEach(o),Ve=p(t),y=s(t,"H2",{class:!0});var rt=a(y);I=s(rt,"A",{id:!0,class:!0,href:!0});var Ho=a(I);$e=s(Ho,"SPAN",{});var Lo=a($e);oe(F.$$.fragment,Lo),Lo.forEach(o),Ho.forEach(o),Gt=p(rt),Pe=s(rt,"SPAN",{});var Oo=a(Pe);Ft=n(Oo,"Performance"),Oo.forEach(o),rt.forEach(o),Ke=p(t),Y=s(t,"P",{});var Ro=a(Y);Vt=n(Ro,"These are the results we got on a M1 Max MacBook Pro with 64 GB of RAM, running macOS Ventura Version 13.0 Beta (22A5331f). We performed Stable Diffusion text-to-image generation of the same prompt for 50 inference steps, using a guidance scale of 7.5."),Ro.forEach(o),Ye=p(t),C=s(t,"TABLE",{});var st=a(C);Se=s(st,"THEAD",{});var Bo=a(Se);$=s(Bo,"TR",{});var X=a($);ke=s(X,"TH",{});var Uo=a(ke);Kt=n(Uo,"Device"),Uo.forEach(o),Yt=p(X),Ae=s(X,"TH",{});var Wo=a(Ae);Jt=n(Wo,"Steps"),Wo.forEach(o),zt=p(X),Me=s(X,"TH",{});var Go=a(Me);Qt=n(Go,"Time"),Go.forEach(o),X.forEach(o),Bo.forEach(o),Xt=p(st),V=s(st,"TBODY",{});var at=a(V);P=s(at,"TR",{});var Z=a(P);De=s(Z,"TD",{});var Fo=a(De);Zt=n(Fo,"CPU"),Fo.forEach(o),eo=p(Z),Te=s(Z,"TD",{});var Vo=a(Te);to=n(Vo,"50"),Vo.forEach(o),oo=p(Z),qe=s(Z,"TD",{});var Ko=a(qe);ro=n(Ko,"213.46s"),Ko.forEach(o),Z.forEach(o),so=p(at),S=s(at,"TR",{});var ee=a(S);xe=s(ee,"TD",{});var Yo=a(xe);ao=n(Yo,"MPS"),Yo.forEach(o),io=p(ee),Ie=s(ee,"TD",{});var Jo=a(Ie);no=n(Jo,"50"),Jo.forEach(o),lo=p(ee),Ce=s(ee,"TD",{});var zo=a(Ce);po=n(zo,"30.81s"),zo.forEach(o),ee.forEach(o),at.forEach(o),st.forEach(o),this.h()},h(){f(d,"name","hf:doc:metadata"),f(d,"content",JSON.stringify(ar)),f(k,"id","how-to-use-stable-diffusion-in-apple-silicon-m1m2"),f(k,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(k,"href","#how-to-use-stable-diffusion-in-apple-silicon-m1m2"),f(v,"class","relative group"),f(M,"id","requirements"),f(M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(M,"href","#requirements"),f(w,"class","relative group"),f(L,"href","https://pytorch.org/get-started/locally/"),f(L,"rel","nofollow"),f(D,"id","inference-pipeline"),f(D,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(D,"href","#inference-pipeline"),f(g,"class","relative group"),f(T,"id","known-issues"),f(T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(T,"href","#known-issues"),f(b,"class","relative group"),f(W,"href","https://github.com/huggingface/diffusers/issues/372"),f(W,"rel","nofollow"),f(G,"href","https://github.com/huggingface/diffusers/issues/363"),f(G,"rel","nofollow"),f(x,"href","https://github.com/pytorch/pytorch/issues/84039#issuecomment-1237735249"),f(x,"rel","nofollow"),f(I,"id","performance"),f(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(I,"href","#performance"),f(y,"class","relative group")},m(t,h){e(document.head,d),c(t,je,h),c(t,v,h),e(v,k),e(k,ne),re(j,ne,null),e(v,it),e(v,le),e(le,nt),c(t,He,h),c(t,A,h),e(A,lt),e(A,pe),e(pe,pt),e(A,ft),c(t,Le,h),c(t,w,h),e(w,M),e(M,fe),re(H,fe,null),e(w,ht),e(w,he),e(he,ct),c(t,Oe,h),c(t,u,h),e(u,ce),e(ce,ut),e(u,mt),e(u,ue),e(ue,dt),e(u,vt),e(u,me),e(me,wt),e(u,_t),e(u,_),e(_,gt),e(_,L),e(L,bt),e(_,Et),e(_,de),e(de,yt),e(_,$t),c(t,Re,h),c(t,g,h),e(g,D),e(D,ve),re(O,ve,null),e(g,Pt),e(g,we),e(we,St),c(t,Be,h),c(t,m,h),e(m,kt),e(m,_e),e(_e,At),e(m,Mt),e(m,ge),e(ge,Dt),e(m,Tt),c(t,Ue,h),c(t,K,h),e(K,qt),c(t,We,h),re(R,t,h),c(t,Ge,h),c(t,b,h),e(b,T),e(T,be),re(B,be,null),e(b,xt),e(b,Ee),e(Ee,It),c(t,Fe,h),c(t,q,h),e(q,U),e(U,Ct),e(U,W),e(W,Nt),e(U,jt),e(q,Ht),e(q,E),e(E,Lt),e(E,G),e(G,Ot),e(E,Rt),e(E,x),e(x,ye),e(ye,Bt),e(x,Ut),e(E,Wt),c(t,Ve,h),c(t,y,h),e(y,I),e(I,$e),re(F,$e,null),e(y,Gt),e(y,Pe),e(Pe,Ft),c(t,Ke,h),c(t,Y,h),e(Y,Vt),c(t,Ye,h),c(t,C,h),e(C,Se),e(Se,$),e($,ke),e(ke,Kt),e($,Yt),e($,Ae),e(Ae,Jt),e($,zt),e($,Me),e(Me,Qt),e(C,Xt),e(C,V),e(V,P),e(P,De),e(De,Zt),e(P,eo),e(P,Te),e(Te,to),e(P,oo),e(P,qe),e(qe,ro),e(V,so),e(V,S),e(S,xe),e(xe,ao),e(S,io),e(S,Ie),e(Ie,no),e(S,lo),e(S,Ce),e(Ce,po),Je=!0},p:tr,i(t){Je||(se(j.$$.fragment,t),se(H.$$.fragment,t),se(O.$$.fragment,t),se(R.$$.fragment,t),se(B.$$.fragment,t),se(F.$$.fragment,t),Je=!0)},o(t){ae(j.$$.fragment,t),ae(H.$$.fragment,t),ae(O.$$.fragment,t),ae(R.$$.fragment,t),ae(B.$$.fragment,t),ae(F.$$.fragment,t),Je=!1},d(t){o(d),t&&o(je),t&&o(v),ie(j),t&&o(He),t&&o(A),t&&o(Le),t&&o(w),ie(H),t&&o(Oe),t&&o(u),t&&o(Re),t&&o(g),ie(O),t&&o(Be),t&&o(m),t&&o(Ue),t&&o(K),t&&o(We),ie(R,t),t&&o(Ge),t&&o(b),ie(B),t&&o(Fe),t&&o(q),t&&o(Ve),t&&o(y),ie(F),t&&o(Ke),t&&o(Y),t&&o(Ye),t&&o(C)}}}const ar={local:"how-to-use-stable-diffusion-in-apple-silicon-m1m2",sections:[{local:"requirements",title:"Requirements"},{local:"inference-pipeline",title:"Inference Pipeline"},{local:"known-issues",title:"Known Issues"},{local:"performance",title:"Performance"}],title:"How to use Stable Diffusion in Apple Silicon (M1/M2)"};function ir(ho){return or(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class fr extends Qo{constructor(d){super();Xo(this,d,ir,sr,Zo,{})}}export{fr as default,ar as metadata};
