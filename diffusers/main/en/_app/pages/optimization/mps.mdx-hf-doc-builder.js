import{S as $o,i as Eo,s as Po,e as s,k as c,w as Y,t as a,M as ko,c as r,d as o,m as u,a as i,x as K,h as n,b as p,G as t,g as f,y as F,L as Ao,q as J,o as z,B as Q,v as Mo}from"../../chunks/vendor-hf-doc-builder.js";import{I as Ee}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as bo}from"../../chunks/CodeBlock-hf-doc-builder.js";function So(Ht){let w,Pe,y,P,oe,R,Fe,se,Je,ke,k,ze,re,Qe,Ve,Ae,g,A,ie,j,Xe,ae,Ze,Me,h,ne,et,tt,le,ot,st,pe,rt,it,m,at,fe,nt,lt,ce,pt,ft,C,ct,ut,Se,_,M,ue,L,ht,he,mt,De,d,dt,me,vt,wt,de,yt,gt,qe,V,_t,Te,N,xe,b,S,ve,G,bt,we,$t,Ie,X,Et,Re,v,Pt,ye,kt,At,ge,Mt,St,je,O,Ce,$,D,_e,B,Dt,be,qt,Le,q,H,Tt,W,xt,It,Rt,E,jt,U,Ct,Lt,T,$e,Nt,Gt,Ot,Ne;return R=new Ee({}),j=new Ee({}),L=new Ee({}),N=new bo({props:{code:`# make sure you're logged in with \`huggingface-cli login\`
from diffusers import StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")
pipe = pipe.to("mps")

# Recommended if your computer has < 64 GB of RAM
pipe.enable_attention_slicing()

prompt = "a photo of an astronaut riding a horse on mars"

# First-time "warmup" pass (see explanation above)
_ = pipe(prompt, num_inference_steps=1)

# Results match those from the CPU device after the warmup pass.
image = pipe(prompt).images[0]`,highlighted:`<span class="hljs-comment"># make sure you&#x27;re logged in with \`huggingface-cli login\`</span>
<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>)
pipe = pipe.to(<span class="hljs-string">&quot;mps&quot;</span>)

<span class="hljs-comment"># Recommended if your computer has &lt; 64 GB of RAM</span>
pipe.enable_attention_slicing()

prompt = <span class="hljs-string">&quot;a photo of an astronaut riding a horse on mars&quot;</span>

<span class="hljs-comment"># First-time &quot;warmup&quot; pass (see explanation above)</span>
_ = pipe(prompt, num_inference_steps=<span class="hljs-number">1</span>)

<span class="hljs-comment"># Results match those from the CPU device after the warmup pass.</span>
image = pipe(prompt).images[<span class="hljs-number">0</span>]`}}),G=new Ee({}),O=new bo({props:{code:"pipeline.enable_attention_slicing()",highlighted:"pipeline.enable_attention_slicing()"}}),B=new Ee({}),{c(){w=s("meta"),Pe=c(),y=s("h1"),P=s("a"),oe=s("span"),Y(R.$$.fragment),Fe=c(),se=s("span"),Je=a("How to use Stable Diffusion in Apple Silicon (M1/M2)"),ke=c(),k=s("p"),ze=a("\u{1F917} Diffusers is compatible with Apple silicon for Stable Diffusion inference, using the PyTorch "),re=s("code"),Qe=a("mps"),Ve=a(" device. These are the steps you need to follow to use your M1 or M2 computer with Stable Diffusion."),Ae=c(),g=s("h2"),A=s("a"),ie=s("span"),Y(j.$$.fragment),Xe=c(),ae=s("span"),Ze=a("Requirements"),Me=c(),h=s("ul"),ne=s("li"),et=a("Mac computer with Apple silicon (M1/M2) hardware."),tt=c(),le=s("li"),ot=a("macOS 12.6 or later (13.0 or later recommended)."),st=c(),pe=s("li"),rt=a("arm64 version of Python."),it=c(),m=s("li"),at=a("PyTorch 1.13. You can install it with "),fe=s("code"),nt=a("pip"),lt=a(" or "),ce=s("code"),pt=a("conda"),ft=a(" using the instructions in "),C=s("a"),ct=a("https://pytorch.org/get-started/locally/"),ut=a("."),Se=c(),_=s("h2"),M=s("a"),ue=s("span"),Y(L.$$.fragment),ht=c(),he=s("span"),mt=a("Inference Pipeline"),De=c(),d=s("p"),dt=a("The snippet below demonstrates how to use the "),me=s("code"),vt=a("mps"),wt=a(" backend using the familiar "),de=s("code"),yt=a("to()"),gt=a(" interface to move the Stable Diffusion pipeline to your M1 or M2 device."),qe=c(),V=s("p"),_t=a("We recommend to \u201Cprime\u201D the pipeline using an additional one-time pass through it. This is a temporary workaround for a weird issue we have detected: the first inference pass produces slightly different results than subsequent ones. You only need to do this pass once, and it\u2019s ok to use just one inference step and discard the result."),Te=c(),Y(N.$$.fragment),xe=c(),b=s("h2"),S=s("a"),ve=s("span"),Y(G.$$.fragment),bt=c(),we=s("span"),$t=a("Performance Recommendations"),Ie=c(),X=s("p"),Et=a("M1/M2 performance is very sensitive to memory pressure. The system will automatically swap if it needs to, but performance will degrade significantly when it does."),Re=c(),v=s("p"),Pt=a("We recommend you use "),ye=s("em"),kt=a("attention slicing"),At=a(" to reduce memory pressure during inference and prevent swapping, particularly if your computer has lass than 64 GB of system RAM, or if you generate images at non-standard resolutions larger than 512 \xD7 512 pixels. Attention slicing performs the costly attention operation in multiple steps instead of all at once. It usually has a performance impact of ~20% in computers without universal memory, but we have observed "),ge=s("em"),Mt=a("better performance"),St=a(" in most Apple Silicon computers, unless you have 64 GB or more."),je=c(),Y(O.$$.fragment),Ce=c(),$=s("h2"),D=s("a"),_e=s("span"),Y(B.$$.fragment),Dt=c(),be=s("span"),qt=a("Known Issues"),Le=c(),q=s("ul"),H=s("li"),Tt=a("As mentioned above, we are investigating a strange "),W=s("a"),xt=a("first-time inference issue"),It=a("."),Rt=c(),E=s("li"),jt=a("Generating multiple prompts in a batch "),U=s("a"),Ct=a("crashes or doesn\u2019t work reliably"),Lt=a(". We believe this is related to the "),T=s("a"),$e=s("code"),Nt=a("mps"),Gt=a(" backend in PyTorch"),Ot=a(". This is being resolved, but for now we recommend to iterate instead of batching."),this.h()},l(e){const l=ko('[data-svelte="svelte-1phssyn"]',document.head);w=r(l,"META",{name:!0,content:!0}),l.forEach(o),Pe=u(e),y=r(e,"H1",{class:!0});var Ge=i(y);P=r(Ge,"A",{id:!0,class:!0,href:!0});var Wt=i(P);oe=r(Wt,"SPAN",{});var Ut=i(oe);K(R.$$.fragment,Ut),Ut.forEach(o),Wt.forEach(o),Fe=u(Ge),se=r(Ge,"SPAN",{});var Yt=i(se);Je=n(Yt,"How to use Stable Diffusion in Apple Silicon (M1/M2)"),Yt.forEach(o),Ge.forEach(o),ke=u(e),k=r(e,"P",{});var Oe=i(k);ze=n(Oe,"\u{1F917} Diffusers is compatible with Apple silicon for Stable Diffusion inference, using the PyTorch "),re=r(Oe,"CODE",{});var Kt=i(re);Qe=n(Kt,"mps"),Kt.forEach(o),Ve=n(Oe," device. These are the steps you need to follow to use your M1 or M2 computer with Stable Diffusion."),Oe.forEach(o),Ae=u(e),g=r(e,"H2",{class:!0});var Be=i(g);A=r(Be,"A",{id:!0,class:!0,href:!0});var Ft=i(A);ie=r(Ft,"SPAN",{});var Jt=i(ie);K(j.$$.fragment,Jt),Jt.forEach(o),Ft.forEach(o),Xe=u(Be),ae=r(Be,"SPAN",{});var zt=i(ae);Ze=n(zt,"Requirements"),zt.forEach(o),Be.forEach(o),Me=u(e),h=r(e,"UL",{});var x=i(h);ne=r(x,"LI",{});var Qt=i(ne);et=n(Qt,"Mac computer with Apple silicon (M1/M2) hardware."),Qt.forEach(o),tt=u(x),le=r(x,"LI",{});var Vt=i(le);ot=n(Vt,"macOS 12.6 or later (13.0 or later recommended)."),Vt.forEach(o),st=u(x),pe=r(x,"LI",{});var Xt=i(pe);rt=n(Xt,"arm64 version of Python."),Xt.forEach(o),it=u(x),m=r(x,"LI",{});var I=i(m);at=n(I,"PyTorch 1.13. You can install it with "),fe=r(I,"CODE",{});var Zt=i(fe);nt=n(Zt,"pip"),Zt.forEach(o),lt=n(I," or "),ce=r(I,"CODE",{});var eo=i(ce);pt=n(eo,"conda"),eo.forEach(o),ft=n(I," using the instructions in "),C=r(I,"A",{href:!0,rel:!0});var to=i(C);ct=n(to,"https://pytorch.org/get-started/locally/"),to.forEach(o),ut=n(I,"."),I.forEach(o),x.forEach(o),Se=u(e),_=r(e,"H2",{class:!0});var He=i(_);M=r(He,"A",{id:!0,class:!0,href:!0});var oo=i(M);ue=r(oo,"SPAN",{});var so=i(ue);K(L.$$.fragment,so),so.forEach(o),oo.forEach(o),ht=u(He),he=r(He,"SPAN",{});var ro=i(he);mt=n(ro,"Inference Pipeline"),ro.forEach(o),He.forEach(o),De=u(e),d=r(e,"P",{});var Z=i(d);dt=n(Z,"The snippet below demonstrates how to use the "),me=r(Z,"CODE",{});var io=i(me);vt=n(io,"mps"),io.forEach(o),wt=n(Z," backend using the familiar "),de=r(Z,"CODE",{});var ao=i(de);yt=n(ao,"to()"),ao.forEach(o),gt=n(Z," interface to move the Stable Diffusion pipeline to your M1 or M2 device."),Z.forEach(o),qe=u(e),V=r(e,"P",{});var no=i(V);_t=n(no,"We recommend to \u201Cprime\u201D the pipeline using an additional one-time pass through it. This is a temporary workaround for a weird issue we have detected: the first inference pass produces slightly different results than subsequent ones. You only need to do this pass once, and it\u2019s ok to use just one inference step and discard the result."),no.forEach(o),Te=u(e),K(N.$$.fragment,e),xe=u(e),b=r(e,"H2",{class:!0});var We=i(b);S=r(We,"A",{id:!0,class:!0,href:!0});var lo=i(S);ve=r(lo,"SPAN",{});var po=i(ve);K(G.$$.fragment,po),po.forEach(o),lo.forEach(o),bt=u(We),we=r(We,"SPAN",{});var fo=i(we);$t=n(fo,"Performance Recommendations"),fo.forEach(o),We.forEach(o),Ie=u(e),X=r(e,"P",{});var co=i(X);Et=n(co,"M1/M2 performance is very sensitive to memory pressure. The system will automatically swap if it needs to, but performance will degrade significantly when it does."),co.forEach(o),Re=u(e),v=r(e,"P",{});var ee=i(v);Pt=n(ee,"We recommend you use "),ye=r(ee,"EM",{});var uo=i(ye);kt=n(uo,"attention slicing"),uo.forEach(o),At=n(ee," to reduce memory pressure during inference and prevent swapping, particularly if your computer has lass than 64 GB of system RAM, or if you generate images at non-standard resolutions larger than 512 \xD7 512 pixels. Attention slicing performs the costly attention operation in multiple steps instead of all at once. It usually has a performance impact of ~20% in computers without universal memory, but we have observed "),ge=r(ee,"EM",{});var ho=i(ge);Mt=n(ho,"better performance"),ho.forEach(o),St=n(ee," in most Apple Silicon computers, unless you have 64 GB or more."),ee.forEach(o),je=u(e),K(O.$$.fragment,e),Ce=u(e),$=r(e,"H2",{class:!0});var Ue=i($);D=r(Ue,"A",{id:!0,class:!0,href:!0});var mo=i(D);_e=r(mo,"SPAN",{});var vo=i(_e);K(B.$$.fragment,vo),vo.forEach(o),mo.forEach(o),Dt=u(Ue),be=r(Ue,"SPAN",{});var wo=i(be);qt=n(wo,"Known Issues"),wo.forEach(o),Ue.forEach(o),Le=u(e),q=r(e,"UL",{});var Ye=i(q);H=r(Ye,"LI",{});var Ke=i(H);Tt=n(Ke,"As mentioned above, we are investigating a strange "),W=r(Ke,"A",{href:!0,rel:!0});var yo=i(W);xt=n(yo,"first-time inference issue"),yo.forEach(o),It=n(Ke,"."),Ke.forEach(o),Rt=u(Ye),E=r(Ye,"LI",{});var te=i(E);jt=n(te,"Generating multiple prompts in a batch "),U=r(te,"A",{href:!0,rel:!0});var go=i(U);Ct=n(go,"crashes or doesn\u2019t work reliably"),go.forEach(o),Lt=n(te,". We believe this is related to the "),T=r(te,"A",{href:!0,rel:!0});var Bt=i(T);$e=r(Bt,"CODE",{});var _o=i($e);Nt=n(_o,"mps"),_o.forEach(o),Gt=n(Bt," backend in PyTorch"),Bt.forEach(o),Ot=n(te,". This is being resolved, but for now we recommend to iterate instead of batching."),te.forEach(o),Ye.forEach(o),this.h()},h(){p(w,"name","hf:doc:metadata"),p(w,"content",JSON.stringify(Do)),p(P,"id","how-to-use-stable-diffusion-in-apple-silicon-m1m2"),p(P,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(P,"href","#how-to-use-stable-diffusion-in-apple-silicon-m1m2"),p(y,"class","relative group"),p(A,"id","requirements"),p(A,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(A,"href","#requirements"),p(g,"class","relative group"),p(C,"href","https://pytorch.org/get-started/locally/"),p(C,"rel","nofollow"),p(M,"id","inference-pipeline"),p(M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(M,"href","#inference-pipeline"),p(_,"class","relative group"),p(S,"id","performance-recommendations"),p(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(S,"href","#performance-recommendations"),p(b,"class","relative group"),p(D,"id","known-issues"),p(D,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(D,"href","#known-issues"),p($,"class","relative group"),p(W,"href","https://github.com/huggingface/diffusers/issues/372"),p(W,"rel","nofollow"),p(U,"href","https://github.com/huggingface/diffusers/issues/363"),p(U,"rel","nofollow"),p(T,"href","https://github.com/pytorch/pytorch/issues/84039"),p(T,"rel","nofollow")},m(e,l){t(document.head,w),f(e,Pe,l),f(e,y,l),t(y,P),t(P,oe),F(R,oe,null),t(y,Fe),t(y,se),t(se,Je),f(e,ke,l),f(e,k,l),t(k,ze),t(k,re),t(re,Qe),t(k,Ve),f(e,Ae,l),f(e,g,l),t(g,A),t(A,ie),F(j,ie,null),t(g,Xe),t(g,ae),t(ae,Ze),f(e,Me,l),f(e,h,l),t(h,ne),t(ne,et),t(h,tt),t(h,le),t(le,ot),t(h,st),t(h,pe),t(pe,rt),t(h,it),t(h,m),t(m,at),t(m,fe),t(fe,nt),t(m,lt),t(m,ce),t(ce,pt),t(m,ft),t(m,C),t(C,ct),t(m,ut),f(e,Se,l),f(e,_,l),t(_,M),t(M,ue),F(L,ue,null),t(_,ht),t(_,he),t(he,mt),f(e,De,l),f(e,d,l),t(d,dt),t(d,me),t(me,vt),t(d,wt),t(d,de),t(de,yt),t(d,gt),f(e,qe,l),f(e,V,l),t(V,_t),f(e,Te,l),F(N,e,l),f(e,xe,l),f(e,b,l),t(b,S),t(S,ve),F(G,ve,null),t(b,bt),t(b,we),t(we,$t),f(e,Ie,l),f(e,X,l),t(X,Et),f(e,Re,l),f(e,v,l),t(v,Pt),t(v,ye),t(ye,kt),t(v,At),t(v,ge),t(ge,Mt),t(v,St),f(e,je,l),F(O,e,l),f(e,Ce,l),f(e,$,l),t($,D),t(D,_e),F(B,_e,null),t($,Dt),t($,be),t(be,qt),f(e,Le,l),f(e,q,l),t(q,H),t(H,Tt),t(H,W),t(W,xt),t(H,It),t(q,Rt),t(q,E),t(E,jt),t(E,U),t(U,Ct),t(E,Lt),t(E,T),t(T,$e),t($e,Nt),t(T,Gt),t(E,Ot),Ne=!0},p:Ao,i(e){Ne||(J(R.$$.fragment,e),J(j.$$.fragment,e),J(L.$$.fragment,e),J(N.$$.fragment,e),J(G.$$.fragment,e),J(O.$$.fragment,e),J(B.$$.fragment,e),Ne=!0)},o(e){z(R.$$.fragment,e),z(j.$$.fragment,e),z(L.$$.fragment,e),z(N.$$.fragment,e),z(G.$$.fragment,e),z(O.$$.fragment,e),z(B.$$.fragment,e),Ne=!1},d(e){o(w),e&&o(Pe),e&&o(y),Q(R),e&&o(ke),e&&o(k),e&&o(Ae),e&&o(g),Q(j),e&&o(Me),e&&o(h),e&&o(Se),e&&o(_),Q(L),e&&o(De),e&&o(d),e&&o(qe),e&&o(V),e&&o(Te),Q(N,e),e&&o(xe),e&&o(b),Q(G),e&&o(Ie),e&&o(X),e&&o(Re),e&&o(v),e&&o(je),Q(O,e),e&&o(Ce),e&&o($),Q(B),e&&o(Le),e&&o(q)}}}const Do={local:"how-to-use-stable-diffusion-in-apple-silicon-m1m2",sections:[{local:"requirements",title:"Requirements"},{local:"inference-pipeline",title:"Inference Pipeline"},{local:"performance-recommendations",title:"Performance Recommendations"},{local:"known-issues",title:"Known Issues"}],title:"How to use Stable Diffusion in Apple Silicon (M1/M2)"};function qo(Ht){return Mo(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ro extends $o{constructor(w){super();Eo(this,w,qo,So,Po,{})}}export{Ro as default,Do as metadata};
