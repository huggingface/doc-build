import{S as Tv,i as Ov,s as kv,e as s,k as l,w as p,t as i,M as Vv,c as n,d as r,m as c,a as o,x as h,h as a,b as d,G as e,g as f,y as m,q as g,o as _,B as v,v as Cv}from"../../chunks/vendor-hf-doc-builder.js";import{T as Nv}from"../../chunks/Tip-hf-doc-builder.js";import{D as b}from"../../chunks/Docstring-hf-doc-builder.js";import{I as q}from"../../chunks/IconCopyLink-hf-doc-builder.js";function Av(ai){let K,Pe;return{c(){K=s("p"),Pe=i("Score SDE-VP is under construction.")},l(U){K=n(U,"P",{});var re=o(K);Pe=a(re,"Score SDE-VP is under construction."),re.forEach(r)},m(U,re){f(U,K,re),e(K,Pe)},d(U){U&&r(K)}}}function Iv(ai){let K,Pe,U,re,en,Tt,rd,tn,sd,di,Zr,nd,li,le,Te,rn,Ot,od,sn,id,ci,Oe,ad,nn,dd,ld,ui,ke,es,cd,kt,on,ud,fd,an,pd,hd,ce,md,dn,gd,_d,ln,vd,bd,fi,ue,Ve,cn,Vt,Sd,un,$d,pi,P,Dd,fn,Ed,xd,ts,yd,wd,rs,Md,Pd,pn,Td,Od,ss,kd,Vd,hn,Cd,Nd,hi,fe,Ce,mn,Ct,Ad,gn,Id,mi,ns,Fd,gi,Ne,_n,Ld,Kd,vn,qd,_i,pe,Ae,bn,Nt,Ud,Sn,Hd,vi,os,Rd,bi,ne,At,Wd,$n,Bd,Gd,Yd,It,zd,Dn,Jd,jd,Qd,En,Xd,Si,Ie,Zd,is,el,tl,$i,he,Fe,xn,Ft,rl,yn,sl,Di,me,Lt,nl,wn,ol,Ei,ge,Le,Mn,Kt,il,Pn,al,xi,_e,qt,dl,Tn,ll,yi,ve,Ke,On,Ut,cl,kn,ul,wi,be,qe,Vn,Ht,fl,Cn,pl,Mi,as,hl,Pi,x,Rt,ml,Nn,gl,_l,T,ds,vl,bl,An,Sl,$l,In,Dl,El,Fn,xl,yl,ls,wl,Ml,cs,Pl,Tl,us,Ol,kl,Vl,fs,Cl,Wt,Nl,Al,Ue,Bt,Il,Ln,Fl,Ll,He,Gt,Kl,Kn,ql,Ul,Re,Yt,Hl,qn,Rl,Ti,Se,We,Un,zt,Wl,Hn,Bl,Oi,Be,Gl,Jt,Yl,zl,ki,y,jt,Jl,Rn,jl,Ql,O,ps,Xl,Zl,Wn,ec,tc,Bn,rc,sc,Gn,nc,oc,hs,ic,ac,ms,dc,lc,gs,cc,uc,fc,_s,pc,Qt,hc,mc,Ge,Xt,gc,Yn,_c,vc,Ye,Zt,bc,zn,Sc,$c,ze,er,Dc,Jn,Ec,Vi,$e,Je,jn,tr,xc,Qn,yc,Ci,je,wc,rr,Mc,Pc,Ni,S,sr,Tc,Xn,Oc,kc,Qe,Vc,nr,Cc,Nc,or,Ac,Ic,k,vs,Fc,Lc,Zn,Kc,qc,eo,Uc,Hc,to,Rc,Wc,bs,Bc,Gc,Ss,Yc,zc,$s,Jc,jc,Qc,ir,Xc,ar,Zc,eu,tu,oe,dr,ru,ro,su,nu,so,ou,iu,Xe,lr,au,no,du,lu,Ze,cr,cu,oo,uu,fu,et,ur,pu,io,hu,mu,tt,fr,gu,ao,_u,Ai,De,rt,lo,pr,vu,co,bu,Ii,st,Su,hr,$u,Du,Fi,w,mr,Eu,Ds,xu,gr,yu,wu,V,Es,Mu,Pu,uo,Tu,Ou,fo,ku,Vu,po,Cu,Nu,xs,Au,Iu,ys,Fu,Lu,ws,Ku,qu,Uu,nt,_r,Hu,ho,Ru,Wu,ot,vr,Bu,br,Gu,mo,Yu,zu,Ju,it,Sr,ju,go,Qu,Xu,at,$r,Zu,_o,ef,Li,Ee,dt,vo,Dr,tf,bo,rf,Ki,lt,sf,Er,nf,of,qi,$,xr,af,So,df,lf,C,Ms,cf,uf,$o,ff,pf,Do,hf,mf,Eo,gf,_f,Ps,vf,bf,Ts,Sf,$f,Os,Df,Ef,xf,ks,yf,yr,wf,Mf,ct,wr,Pf,xo,Tf,Of,ut,Mr,kf,yo,Vf,Cf,ie,Pr,Nf,wo,Af,If,se,Ff,Mo,Lf,Kf,Po,qf,Uf,To,Hf,Rf,Wf,ft,Tr,Bf,Oo,Gf,Yf,pt,Or,zf,ko,Jf,Ui,xe,ht,Vo,kr,jf,Co,Qf,Hi,mt,Xf,Vr,Zf,ep,Ri,D,Cr,tp,No,rp,sp,Vs,np,Nr,op,ip,N,Cs,ap,dp,Ao,lp,cp,Io,up,fp,Fo,pp,hp,Ns,mp,gp,As,_p,vp,Is,bp,Sp,$p,gt,Ar,Dp,Lo,Ep,xp,ae,Ir,yp,Ko,wp,Mp,ye,Pp,qo,Tp,Op,Uo,kp,Vp,Cp,_t,Fr,Np,Ho,Ap,Ip,vt,Lr,Fp,Ro,Lp,Kp,bt,Kr,qp,Wo,Up,Wi,we,St,Bo,qr,Hp,Go,Rp,Bi,$t,Wp,Ur,Bp,Gp,Gi,M,Hr,Yp,Fs,zp,Rr,Jp,jp,A,Ls,Qp,Xp,Yo,Zp,eh,zo,th,rh,Jo,sh,nh,Ks,oh,ih,qs,ah,dh,Us,lh,ch,uh,Hs,fh,Wr,ph,hh,Dt,Br,mh,jo,gh,_h,Et,Gr,vh,Qo,bh,Sh,xt,Yr,$h,Xo,Dh,Yi,Me,yt,Zo,zr,Eh,ei,xh,zi,wt,yh,Jr,wh,Mh,Ji,Mt,ji,H,jr,Ph,ti,Th,Oh,I,Rs,kh,Vh,ri,Ch,Nh,si,Ah,Ih,ni,Fh,Lh,Ws,Kh,qh,Bs,Uh,Hh,Gs,Rh,Wh,Bh,Ys,Gh,Qr,Yh,zh,oi,Jh,Qi;return Tt=new q({}),Ot=new q({}),Vt=new q({}),Ct=new q({}),Nt=new q({}),Ft=new q({}),Lt=new b({props:{name:"class diffusers.SchedulerMixin",anchor:"diffusers.SchedulerMixin",parameters:[],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_utils.py#L38"}}),Kt=new q({}),qt=new b({props:{name:"class diffusers.schedulers.scheduling_utils.SchedulerOutput",anchor:"diffusers.schedulers.scheduling_utils.SchedulerOutput",parameters:[{name:"prev_sample",val:": FloatTensor"}],parametersDescription:[{anchor:"diffusers.schedulers.scheduling_utils.SchedulerOutput.prev_sample",description:`<strong>prev_sample</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, num_channels, height, width)</code> for images) &#x2014;
Computed sample (x_{t-1}) of previous timestep. <code>prev_sample</code> should be used as next model input in the
denoising loop.`,name:"prev_sample"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_utils.py#L25"}}),Ut=new q({}),Ht=new q({}),Rt=new b({props:{name:"class diffusers.DDIMScheduler",anchor:"diffusers.DDIMScheduler",parameters:[{name:"num_train_timesteps",val:": int = 1000"},{name:"beta_start",val:": float = 0.0001"},{name:"beta_end",val:": float = 0.02"},{name:"beta_schedule",val:": str = 'linear'"},{name:"trained_betas",val:": typing.Optional[numpy.ndarray] = None"},{name:"clip_sample",val:": bool = True"},{name:"set_alpha_to_one",val:": bool = True"},{name:"steps_offset",val:": int = 0"}],parametersDescription:[{anchor:"diffusers.DDIMScheduler.num_train_timesteps",description:"<strong>num_train_timesteps</strong> (<code>int</code>) &#x2014; number of diffusion steps used to train the model.",name:"num_train_timesteps"},{anchor:"diffusers.DDIMScheduler.beta_start",description:"<strong>beta_start</strong> (<code>float</code>) &#x2014; the starting <code>beta</code> value of inference.",name:"beta_start"},{anchor:"diffusers.DDIMScheduler.beta_end",description:"<strong>beta_end</strong> (<code>float</code>) &#x2014; the final <code>beta</code> value.",name:"beta_end"},{anchor:"diffusers.DDIMScheduler.beta_schedule",description:`<strong>beta_schedule</strong> (<code>str</code>) &#x2014;
the beta schedule, a mapping from a beta range to a sequence of betas for stepping the model. Choose from
<code>linear</code>, <code>scaled_linear</code>, or <code>squaredcos_cap_v2</code>.`,name:"beta_schedule"},{anchor:"diffusers.DDIMScheduler.trained_betas",description:`<strong>trained_betas</strong> (<code>np.ndarray</code>, optional) &#x2014;
option to pass an array of betas directly to the constructor to bypass <code>beta_start</code>, <code>beta_end</code> etc.`,name:"trained_betas"},{anchor:"diffusers.DDIMScheduler.clip_sample",description:`<strong>clip_sample</strong> (<code>bool</code>, default <code>True</code>) &#x2014;
option to clip predicted sample between -1 and 1 for numerical stability.`,name:"clip_sample"},{anchor:"diffusers.DDIMScheduler.set_alpha_to_one",description:`<strong>set_alpha_to_one</strong> (<code>bool</code>, default <code>True</code>) &#x2014;
each diffusion step uses the value of alphas product at that step and at the previous one. For the final
step there is no previous alpha. When this option is <code>True</code> the previous alpha product is fixed to <code>1</code>,
otherwise it uses the value of alpha at step 0.`,name:"set_alpha_to_one"},{anchor:"diffusers.DDIMScheduler.steps_offset",description:`<strong>steps_offset</strong> (<code>int</code>, default <code>0</code>) &#x2014;
an offset added to the inference steps. You can use a combination of <code>offset=1</code> and
<code>set_alpha_to_one=False</code>, to make the last step use step 0 for the previous alpha product, as done in
stable diffusion.`,name:"steps_offset"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddim.py#L78"}}),Bt=new b({props:{name:"scale_model_input",anchor:"diffusers.DDIMScheduler.scale_model_input",parameters:[{name:"sample",val:": FloatTensor"},{name:"timestep",val:": typing.Optional[int] = None"}],parametersDescription:[{anchor:"diffusers.DDIMScheduler.scale_model_input.sample",description:"<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014; input sample",name:"sample"},{anchor:"diffusers.DDIMScheduler.scale_model_input.timestep",description:"<strong>timestep</strong> (<code>int</code>, optional) &#x2014; current timestep",name:"timestep"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddim.py#L163",returnDescription:`
<p>scaled input sample</p>
`,returnType:`
<p><code>torch.FloatTensor</code></p>
`}}),Gt=new b({props:{name:"set_timesteps",anchor:"diffusers.DDIMScheduler.set_timesteps",parameters:[{name:"num_inference_steps",val:": int"},{name:"device",val:": typing.Union[str, torch.device] = None"}],parametersDescription:[{anchor:"diffusers.DDIMScheduler.set_timesteps.num_inference_steps",description:`<strong>num_inference_steps</strong> (<code>int</code>) &#x2014;
the number of diffusion steps used when generating samples with a pre-trained model.`,name:"num_inference_steps"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddim.py#L187"}}),Yt=new b({props:{name:"step",anchor:"diffusers.DDIMScheduler.step",parameters:[{name:"model_output",val:": FloatTensor"},{name:"timestep",val:": int"},{name:"sample",val:": FloatTensor"},{name:"eta",val:": float = 0.0"},{name:"use_clipped_model_output",val:": bool = False"},{name:"generator",val:" = None"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.DDIMScheduler.step.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.DDIMScheduler.step.timestep",description:"<strong>timestep</strong> (<code>int</code>) &#x2014; current discrete timestep in the diffusion chain.",name:"timestep"},{anchor:"diffusers.DDIMScheduler.step.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014;
current instance of sample being created by diffusion process.`,name:"sample"},{anchor:"diffusers.DDIMScheduler.step.eta",description:"<strong>eta</strong> (<code>float</code>) &#x2014; weight of noise for added noise in diffusion step.",name:"eta"},{anchor:"diffusers.DDIMScheduler.step.use_clipped_model_output",description:`<strong>use_clipped_model_output</strong> (<code>bool</code>) &#x2014; TODO
generator &#x2014; random number generator.`,name:"use_clipped_model_output"},{anchor:"diffusers.DDIMScheduler.step.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than DDIMSchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddim.py#L203",returnDescription:`
<p><code>~schedulers.scheduling_utils.DDIMSchedulerOutput</code> if <code>return_dict</code> is True, otherwise a <code>tuple</code>. When
returning a tuple, the first element is the sample tensor.</p>
`,returnType:`
<p><code>~schedulers.scheduling_utils.DDIMSchedulerOutput</code> or <code>tuple</code></p>
`}}),zt=new q({}),jt=new b({props:{name:"class diffusers.DDPMScheduler",anchor:"diffusers.DDPMScheduler",parameters:[{name:"num_train_timesteps",val:": int = 1000"},{name:"beta_start",val:": float = 0.0001"},{name:"beta_end",val:": float = 0.02"},{name:"beta_schedule",val:": str = 'linear'"},{name:"trained_betas",val:": typing.Optional[numpy.ndarray] = None"},{name:"variance_type",val:": str = 'fixed_small'"},{name:"clip_sample",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.DDPMScheduler.num_train_timesteps",description:"<strong>num_train_timesteps</strong> (<code>int</code>) &#x2014; number of diffusion steps used to train the model.",name:"num_train_timesteps"},{anchor:"diffusers.DDPMScheduler.beta_start",description:"<strong>beta_start</strong> (<code>float</code>) &#x2014; the starting <code>beta</code> value of inference.",name:"beta_start"},{anchor:"diffusers.DDPMScheduler.beta_end",description:"<strong>beta_end</strong> (<code>float</code>) &#x2014; the final <code>beta</code> value.",name:"beta_end"},{anchor:"diffusers.DDPMScheduler.beta_schedule",description:`<strong>beta_schedule</strong> (<code>str</code>) &#x2014;
the beta schedule, a mapping from a beta range to a sequence of betas for stepping the model. Choose from
<code>linear</code>, <code>scaled_linear</code>, or <code>squaredcos_cap_v2</code>.`,name:"beta_schedule"},{anchor:"diffusers.DDPMScheduler.trained_betas",description:`<strong>trained_betas</strong> (<code>np.ndarray</code>, optional) &#x2014;
option to pass an array of betas directly to the constructor to bypass <code>beta_start</code>, <code>beta_end</code> etc.`,name:"trained_betas"},{anchor:"diffusers.DDPMScheduler.variance_type",description:`<strong>variance_type</strong> (<code>str</code>) &#x2014;
options to clip the variance used when adding noise to the denoised sample. Choose from <code>fixed_small</code>,
<code>fixed_small_log</code>, <code>fixed_large</code>, <code>fixed_large_log</code>, <code>learned</code> or <code>learned_range</code>.`,name:"variance_type"},{anchor:"diffusers.DDPMScheduler.clip_sample",description:`<strong>clip_sample</strong> (<code>bool</code>, default <code>True</code>) &#x2014;
option to clip predicted sample between -1 and 1 for numerical stability.`,name:"clip_sample"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddpm.py#L76"}}),Xt=new b({props:{name:"scale_model_input",anchor:"diffusers.DDPMScheduler.scale_model_input",parameters:[{name:"sample",val:": FloatTensor"},{name:"timestep",val:": typing.Optional[int] = None"}],parametersDescription:[{anchor:"diffusers.DDPMScheduler.scale_model_input.sample",description:"<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014; input sample",name:"sample"},{anchor:"diffusers.DDPMScheduler.scale_model_input.timestep",description:"<strong>timestep</strong> (<code>int</code>, optional) &#x2014; current timestep",name:"timestep"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddpm.py#L156",returnDescription:`
<p>scaled input sample</p>
`,returnType:`
<p><code>torch.FloatTensor</code></p>
`}}),Zt=new b({props:{name:"set_timesteps",anchor:"diffusers.DDPMScheduler.set_timesteps",parameters:[{name:"num_inference_steps",val:": int"},{name:"device",val:": typing.Union[str, torch.device] = None"}],parametersDescription:[{anchor:"diffusers.DDPMScheduler.set_timesteps.num_inference_steps",description:`<strong>num_inference_steps</strong> (<code>int</code>) &#x2014;
the number of diffusion steps used when generating samples with a pre-trained model.`,name:"num_inference_steps"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddpm.py#L170"}}),er=new b({props:{name:"step",anchor:"diffusers.DDPMScheduler.step",parameters:[{name:"model_output",val:": FloatTensor"},{name:"timestep",val:": int"},{name:"sample",val:": FloatTensor"},{name:"predict_epsilon",val:" = True"},{name:"generator",val:" = None"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.DDPMScheduler.step.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.DDPMScheduler.step.timestep",description:"<strong>timestep</strong> (<code>int</code>) &#x2014; current discrete timestep in the diffusion chain.",name:"timestep"},{anchor:"diffusers.DDPMScheduler.step.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014;
current instance of sample being created by diffusion process.`,name:"sample"},{anchor:"diffusers.DDPMScheduler.step.predict_epsilon",description:`<strong>predict_epsilon</strong> (<code>bool</code>) &#x2014;
optional flag to use when model predicts the samples directly instead of the noise, epsilon.
generator &#x2014; random number generator.`,name:"predict_epsilon"},{anchor:"diffusers.DDPMScheduler.step.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than DDPMSchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddpm.py#L218",returnDescription:`
<p><code>~schedulers.scheduling_utils.DDPMSchedulerOutput</code> if <code>return_dict</code> is True, otherwise a <code>tuple</code>. When
returning a tuple, the first element is the sample tensor.</p>
`,returnType:`
<p><code>~schedulers.scheduling_utils.DDPMSchedulerOutput</code> or <code>tuple</code></p>
`}}),tr=new q({}),sr=new b({props:{name:"class diffusers.KarrasVeScheduler",anchor:"diffusers.KarrasVeScheduler",parameters:[{name:"sigma_min",val:": float = 0.02"},{name:"sigma_max",val:": float = 100"},{name:"s_noise",val:": float = 1.007"},{name:"s_churn",val:": float = 80"},{name:"s_min",val:": float = 0.05"},{name:"s_max",val:": float = 50"}],parametersDescription:[{anchor:"diffusers.KarrasVeScheduler.sigma_min",description:"<strong>sigma_min</strong> (<code>float</code>) &#x2014; minimum noise magnitude",name:"sigma_min"},{anchor:"diffusers.KarrasVeScheduler.sigma_max",description:"<strong>sigma_max</strong> (<code>float</code>) &#x2014; maximum noise magnitude",name:"sigma_max"},{anchor:"diffusers.KarrasVeScheduler.s_noise",description:`<strong>s_noise</strong> (<code>float</code>) &#x2014; the amount of additional noise to counteract loss of detail during sampling.
A reasonable range is [1.000, 1.011].`,name:"s_noise"},{anchor:"diffusers.KarrasVeScheduler.s_churn",description:`<strong>s_churn</strong> (<code>float</code>) &#x2014; the parameter controlling the overall amount of stochasticity.
A reasonable range is [0, 100].`,name:"s_churn"},{anchor:"diffusers.KarrasVeScheduler.s_min",description:`<strong>s_min</strong> (<code>float</code>) &#x2014; the start value of the sigma range where we add noise (enable stochasticity).
A reasonable range is [0, 10].`,name:"s_min"},{anchor:"diffusers.KarrasVeScheduler.s_max",description:`<strong>s_max</strong> (<code>float</code>) &#x2014; the end value of the sigma range where we add noise.
A reasonable range is [0.2, 80].`,name:"s_max"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_karras_ve.py#L48"}}),dr=new b({props:{name:"add_noise_to_input",anchor:"diffusers.KarrasVeScheduler.add_noise_to_input",parameters:[{name:"sample",val:": FloatTensor"},{name:"sigma",val:": float"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_karras_ve.py#L133"}}),lr=new b({props:{name:"scale_model_input",anchor:"diffusers.KarrasVeScheduler.scale_model_input",parameters:[{name:"sample",val:": FloatTensor"},{name:"timestep",val:": typing.Optional[int] = None"}],parametersDescription:[{anchor:"diffusers.KarrasVeScheduler.scale_model_input.sample",description:"<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014; input sample",name:"sample"},{anchor:"diffusers.KarrasVeScheduler.scale_model_input.timestep",description:"<strong>timestep</strong> (<code>int</code>, optional) &#x2014; current timestep",name:"timestep"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_karras_ve.py#L98",returnDescription:`
<p>scaled input sample</p>
`,returnType:`
<p><code>torch.FloatTensor</code></p>
`}}),cr=new b({props:{name:"set_timesteps",anchor:"diffusers.KarrasVeScheduler.set_timesteps",parameters:[{name:"num_inference_steps",val:": int"},{name:"device",val:": typing.Union[str, torch.device] = None"}],parametersDescription:[{anchor:"diffusers.KarrasVeScheduler.set_timesteps.num_inference_steps",description:`<strong>num_inference_steps</strong> (<code>int</code>) &#x2014;
the number of diffusion steps used when generating samples with a pre-trained model.`,name:"num_inference_steps"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_karras_ve.py#L112"}}),ur=new b({props:{name:"step",anchor:"diffusers.KarrasVeScheduler.step",parameters:[{name:"model_output",val:": FloatTensor"},{name:"sigma_hat",val:": float"},{name:"sigma_prev",val:": float"},{name:"sample_hat",val:": FloatTensor"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.KarrasVeScheduler.step.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.KarrasVeScheduler.step.sigma_hat",description:"<strong>sigma_hat</strong> (<code>float</code>) &#x2014; TODO",name:"sigma_hat"},{anchor:"diffusers.KarrasVeScheduler.step.sigma_prev",description:"<strong>sigma_prev</strong> (<code>float</code>) &#x2014; TODO",name:"sigma_prev"},{anchor:"diffusers.KarrasVeScheduler.step.sample_hat",description:"<strong>sample_hat</strong> (<code>torch.FloatTensor</code>) &#x2014; TODO",name:"sample_hat"},{anchor:"diffusers.KarrasVeScheduler.step.return_dict",description:`<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than KarrasVeOutput class</p>
<p>KarrasVeOutput &#x2014; updated sample in the diffusion chain and derivative (TODO double check).`,name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_karras_ve.py#L154",returnDescription:`
<p><code>KarrasVeOutput</code> if <code>return_dict</code> is True, otherwise a <code>tuple</code>. When
returning a tuple, the first element is the sample tensor.</p>
`,returnType:`
<p><code>KarrasVeOutput</code> or <code>tuple</code></p>
`}}),fr=new b({props:{name:"step_correct",anchor:"diffusers.KarrasVeScheduler.step_correct",parameters:[{name:"model_output",val:": FloatTensor"},{name:"sigma_hat",val:": float"},{name:"sigma_prev",val:": float"},{name:"sample_hat",val:": FloatTensor"},{name:"sample_prev",val:": FloatTensor"},{name:"derivative",val:": FloatTensor"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.KarrasVeScheduler.step_correct.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.KarrasVeScheduler.step_correct.sigma_hat",description:"<strong>sigma_hat</strong> (<code>float</code>) &#x2014; TODO",name:"sigma_hat"},{anchor:"diffusers.KarrasVeScheduler.step_correct.sigma_prev",description:"<strong>sigma_prev</strong> (<code>float</code>) &#x2014; TODO",name:"sigma_prev"},{anchor:"diffusers.KarrasVeScheduler.step_correct.sample_hat",description:"<strong>sample_hat</strong> (<code>torch.FloatTensor</code>) &#x2014; TODO",name:"sample_hat"},{anchor:"diffusers.KarrasVeScheduler.step_correct.sample_prev",description:"<strong>sample_prev</strong> (<code>torch.FloatTensor</code>) &#x2014; TODO",name:"sample_prev"},{anchor:"diffusers.KarrasVeScheduler.step_correct.derivative",description:"<strong>derivative</strong> (<code>torch.FloatTensor</code>) &#x2014; TODO",name:"derivative"},{anchor:"diffusers.KarrasVeScheduler.step_correct.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than KarrasVeOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_karras_ve.py#L192",returnDescription:`
<p>updated sample in the diffusion chain. derivative (TODO): TODO</p>
`,returnType:`
<p>prev_sample (TODO)</p>
`}}),pr=new q({}),mr=new b({props:{name:"class diffusers.LMSDiscreteScheduler",anchor:"diffusers.LMSDiscreteScheduler",parameters:[{name:"num_train_timesteps",val:": int = 1000"},{name:"beta_start",val:": float = 0.0001"},{name:"beta_end",val:": float = 0.02"},{name:"beta_schedule",val:": str = 'linear'"},{name:"trained_betas",val:": typing.Optional[numpy.ndarray] = None"}],parametersDescription:[{anchor:"diffusers.LMSDiscreteScheduler.num_train_timesteps",description:"<strong>num_train_timesteps</strong> (<code>int</code>) &#x2014; number of diffusion steps used to train the model.",name:"num_train_timesteps"},{anchor:"diffusers.LMSDiscreteScheduler.beta_start",description:"<strong>beta_start</strong> (<code>float</code>) &#x2014; the starting <code>beta</code> value of inference.",name:"beta_start"},{anchor:"diffusers.LMSDiscreteScheduler.beta_end",description:"<strong>beta_end</strong> (<code>float</code>) &#x2014; the final <code>beta</code> value.",name:"beta_end"},{anchor:"diffusers.LMSDiscreteScheduler.beta_schedule",description:`<strong>beta_schedule</strong> (<code>str</code>) &#x2014;
the beta schedule, a mapping from a beta range to a sequence of betas for stepping the model. Choose from
<code>linear</code> or <code>scaled_linear</code>.`,name:"beta_schedule"},{anchor:"diffusers.LMSDiscreteScheduler.trained_betas",description:`<strong>trained_betas</strong> (<code>np.ndarray</code>, optional) &#x2014;
option to pass an array of betas directly to the constructor to bypass <code>beta_start</code>, <code>beta_end</code> etc.`,name:"trained_betas"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_lms_discrete.py#L47"}}),_r=new b({props:{name:"get_lms_coefficient",anchor:"diffusers.LMSDiscreteScheduler.get_lms_coefficient",parameters:[{name:"order",val:""},{name:"t",val:""},{name:"current_order",val:""}],parametersDescription:[{anchor:"diffusers.LMSDiscreteScheduler.get_lms_coefficient.order",description:"<strong>order</strong> (TODO) &#x2014;",name:"order"},{anchor:"diffusers.LMSDiscreteScheduler.get_lms_coefficient.t",description:"<strong>t</strong> (TODO) &#x2014;",name:"t"},{anchor:"diffusers.LMSDiscreteScheduler.get_lms_coefficient.current_order",description:"<strong>current_order</strong> (TODO) &#x2014;",name:"current_order"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_lms_discrete.py#L137"}}),vr=new b({props:{name:"scale_model_input",anchor:"diffusers.LMSDiscreteScheduler.scale_model_input",parameters:[{name:"sample",val:": FloatTensor"},{name:"timestep",val:": typing.Union[float, torch.FloatTensor]"}],parametersDescription:[{anchor:"diffusers.LMSDiscreteScheduler.scale_model_input.sample",description:"<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014; input sample",name:"sample"},{anchor:"diffusers.LMSDiscreteScheduler.scale_model_input.timestep",description:"<strong>timestep</strong> (<code>float</code> or <code>torch.FloatTensor</code>) &#x2014; the current timestep in the diffusion chain",name:"timestep"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_lms_discrete.py#L116",returnDescription:`
<p>scaled input sample</p>
`,returnType:`
<p><code>torch.FloatTensor</code></p>
`}}),Sr=new b({props:{name:"set_timesteps",anchor:"diffusers.LMSDiscreteScheduler.set_timesteps",parameters:[{name:"num_inference_steps",val:": int"},{name:"device",val:": typing.Union[str, torch.device] = None"}],parametersDescription:[{anchor:"diffusers.LMSDiscreteScheduler.set_timesteps.num_inference_steps",description:`<strong>num_inference_steps</strong> (<code>int</code>) &#x2014;
the number of diffusion steps used when generating samples with a pre-trained model.`,name:"num_inference_steps"},{anchor:"diffusers.LMSDiscreteScheduler.set_timesteps.device",description:`<strong>device</strong> (<code>str</code> or <code>torch.device</code>, optional) &#x2014;
the device to which the timesteps should be moved to. If <code>None</code>, the timesteps are not moved.`,name:"device"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_lms_discrete.py#L159"}}),$r=new b({props:{name:"step",anchor:"diffusers.LMSDiscreteScheduler.step",parameters:[{name:"model_output",val:": FloatTensor"},{name:"timestep",val:": typing.Union[float, torch.FloatTensor]"},{name:"sample",val:": FloatTensor"},{name:"order",val:": int = 4"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.LMSDiscreteScheduler.step.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.LMSDiscreteScheduler.step.timestep",description:"<strong>timestep</strong> (<code>float</code>) &#x2014; current timestep in the diffusion chain.",name:"timestep"},{anchor:"diffusers.LMSDiscreteScheduler.step.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014;
current instance of sample being created by diffusion process.
order &#x2014; coefficient for multi-step inference.`,name:"sample"},{anchor:"diffusers.LMSDiscreteScheduler.step.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than LMSDiscreteSchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_lms_discrete.py#L180",returnDescription:`
<p><code>~schedulers.scheduling_utils.LMSDiscreteSchedulerOutput</code> if <code>return_dict</code> is True, otherwise a <code>tuple</code>.
When returning a tuple, the first element is the sample tensor.</p>
`,returnType:`
<p><code>~schedulers.scheduling_utils.LMSDiscreteSchedulerOutput</code> or <code>tuple</code></p>
`}}),Dr=new q({}),xr=new b({props:{name:"class diffusers.PNDMScheduler",anchor:"diffusers.PNDMScheduler",parameters:[{name:"num_train_timesteps",val:": int = 1000"},{name:"beta_start",val:": float = 0.0001"},{name:"beta_end",val:": float = 0.02"},{name:"beta_schedule",val:": str = 'linear'"},{name:"trained_betas",val:": typing.Optional[numpy.ndarray] = None"},{name:"skip_prk_steps",val:": bool = False"},{name:"set_alpha_to_one",val:": bool = False"},{name:"steps_offset",val:": int = 0"}],parametersDescription:[{anchor:"diffusers.PNDMScheduler.num_train_timesteps",description:"<strong>num_train_timesteps</strong> (<code>int</code>) &#x2014; number of diffusion steps used to train the model.",name:"num_train_timesteps"},{anchor:"diffusers.PNDMScheduler.beta_start",description:"<strong>beta_start</strong> (<code>float</code>) &#x2014; the starting <code>beta</code> value of inference.",name:"beta_start"},{anchor:"diffusers.PNDMScheduler.beta_end",description:"<strong>beta_end</strong> (<code>float</code>) &#x2014; the final <code>beta</code> value.",name:"beta_end"},{anchor:"diffusers.PNDMScheduler.beta_schedule",description:`<strong>beta_schedule</strong> (<code>str</code>) &#x2014;
the beta schedule, a mapping from a beta range to a sequence of betas for stepping the model. Choose from
<code>linear</code>, <code>scaled_linear</code>, or <code>squaredcos_cap_v2</code>.`,name:"beta_schedule"},{anchor:"diffusers.PNDMScheduler.trained_betas",description:`<strong>trained_betas</strong> (<code>np.ndarray</code>, optional) &#x2014;
option to pass an array of betas directly to the constructor to bypass <code>beta_start</code>, <code>beta_end</code> etc.`,name:"trained_betas"},{anchor:"diffusers.PNDMScheduler.skip_prk_steps",description:`<strong>skip_prk_steps</strong> (<code>bool</code>) &#x2014;
allows the scheduler to skip the Runge-Kutta steps that are defined in the original paper as being required
before plms steps; defaults to <code>False</code>.`,name:"skip_prk_steps"},{anchor:"diffusers.PNDMScheduler.set_alpha_to_one",description:`<strong>set_alpha_to_one</strong> (<code>bool</code>, default <code>False</code>) &#x2014;
each diffusion step uses the value of alphas product at that step and at the previous one. For the final
step there is no previous alpha. When this option is <code>True</code> the previous alpha product is fixed to <code>1</code>,
otherwise it uses the value of alpha at step 0.`,name:"set_alpha_to_one"},{anchor:"diffusers.PNDMScheduler.steps_offset",description:`<strong>steps_offset</strong> (<code>int</code>, default <code>0</code>) &#x2014;
an offset added to the inference steps. You can use a combination of <code>offset=1</code> and
<code>set_alpha_to_one=False</code>, to make the last step use step 0 for the previous alpha product, as done in
stable diffusion.`,name:"steps_offset"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_pndm.py#L56"}}),wr=new b({props:{name:"scale_model_input",anchor:"diffusers.PNDMScheduler.scale_model_input",parameters:[{name:"sample",val:": FloatTensor"},{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.PNDMScheduler.scale_model_input.sample",description:"<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014; input sample",name:"sample"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_pndm.py#L344",returnDescription:`
<p>scaled input sample</p>
`,returnType:`
<p><code>torch.FloatTensor</code></p>
`}}),Mr=new b({props:{name:"set_timesteps",anchor:"diffusers.PNDMScheduler.set_timesteps",parameters:[{name:"num_inference_steps",val:": int"},{name:"device",val:": typing.Union[str, torch.device] = None"}],parametersDescription:[{anchor:"diffusers.PNDMScheduler.set_timesteps.num_inference_steps",description:`<strong>num_inference_steps</strong> (<code>int</code>) &#x2014;
the number of diffusion steps used when generating samples with a pre-trained model.`,name:"num_inference_steps"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_pndm.py#L152"}}),Pr=new b({props:{name:"step",anchor:"diffusers.PNDMScheduler.step",parameters:[{name:"model_output",val:": FloatTensor"},{name:"timestep",val:": int"},{name:"sample",val:": FloatTensor"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.PNDMScheduler.step.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.PNDMScheduler.step.timestep",description:"<strong>timestep</strong> (<code>int</code>) &#x2014; current discrete timestep in the diffusion chain.",name:"timestep"},{anchor:"diffusers.PNDMScheduler.step.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014;
current instance of sample being created by diffusion process.`,name:"sample"},{anchor:"diffusers.PNDMScheduler.step.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than SchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_pndm.py#L191",returnDescription:`
<p><a
  href="/docs/diffusers/main/en/api/schedulers#diffusers.schedulers.scheduling_utils.SchedulerOutput"
>SchedulerOutput</a> if <code>return_dict</code> is True, otherwise a <code>tuple</code>. When
returning a tuple, the first element is the sample tensor.</p>
`,returnType:`
<p><a
  href="/docs/diffusers/main/en/api/schedulers#diffusers.schedulers.scheduling_utils.SchedulerOutput"
>SchedulerOutput</a> or <code>tuple</code></p>
`}}),Tr=new b({props:{name:"step_plms",anchor:"diffusers.PNDMScheduler.step_plms",parameters:[{name:"model_output",val:": FloatTensor"},{name:"timestep",val:": int"},{name:"sample",val:": FloatTensor"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.PNDMScheduler.step_plms.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.PNDMScheduler.step_plms.timestep",description:"<strong>timestep</strong> (<code>int</code>) &#x2014; current discrete timestep in the diffusion chain.",name:"timestep"},{anchor:"diffusers.PNDMScheduler.step_plms.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014;
current instance of sample being created by diffusion process.`,name:"sample"},{anchor:"diffusers.PNDMScheduler.step_plms.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than SchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_pndm.py#L277",returnDescription:`
<p><code>~scheduling_utils.SchedulerOutput</code> if <code>return_dict</code> is
True, otherwise a <code>tuple</code>. When returning a tuple, the first element is the sample tensor.</p>
`,returnType:`
<p><code>~scheduling_utils.SchedulerOutput</code> or <code>tuple</code></p>
`}}),Or=new b({props:{name:"step_prk",anchor:"diffusers.PNDMScheduler.step_prk",parameters:[{name:"model_output",val:": FloatTensor"},{name:"timestep",val:": int"},{name:"sample",val:": FloatTensor"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.PNDMScheduler.step_prk.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.PNDMScheduler.step_prk.timestep",description:"<strong>timestep</strong> (<code>int</code>) &#x2014; current discrete timestep in the diffusion chain.",name:"timestep"},{anchor:"diffusers.PNDMScheduler.step_prk.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014;
current instance of sample being created by diffusion process.`,name:"sample"},{anchor:"diffusers.PNDMScheduler.step_prk.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than SchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_pndm.py#L222",returnDescription:`
<p><code>~scheduling_utils.SchedulerOutput</code> if <code>return_dict</code> is
True, otherwise a <code>tuple</code>. When returning a tuple, the first element is the sample tensor.</p>
`,returnType:`
<p><code>~scheduling_utils.SchedulerOutput</code> or <code>tuple</code></p>
`}}),kr=new q({}),Cr=new b({props:{name:"class diffusers.ScoreSdeVeScheduler",anchor:"diffusers.ScoreSdeVeScheduler",parameters:[{name:"num_train_timesteps",val:": int = 2000"},{name:"snr",val:": float = 0.15"},{name:"sigma_min",val:": float = 0.01"},{name:"sigma_max",val:": float = 1348.0"},{name:"sampling_eps",val:": float = 1e-05"},{name:"correct_steps",val:": int = 1"}],parametersDescription:[{anchor:"diffusers.ScoreSdeVeScheduler.num_train_timesteps",description:"<strong>num_train_timesteps</strong> (<code>int</code>) &#x2014; number of diffusion steps used to train the model.",name:"num_train_timesteps"},{anchor:"diffusers.ScoreSdeVeScheduler.snr",description:`<strong>snr</strong> (<code>float</code>) &#x2014;
coefficient weighting the step from the model_output sample (from the network) to the random noise.`,name:"snr"},{anchor:"diffusers.ScoreSdeVeScheduler.sigma_min",description:`<strong>sigma_min</strong> (<code>float</code>) &#x2014;
initial noise scale for sigma sequence in sampling procedure. The minimum sigma should mirror the
distribution of the data.`,name:"sigma_min"},{anchor:"diffusers.ScoreSdeVeScheduler.sigma_max",description:"<strong>sigma_max</strong> (<code>float</code>) &#x2014; maximum value used for the range of continuous timesteps passed into the model.",name:"sigma_max"},{anchor:"diffusers.ScoreSdeVeScheduler.sampling_eps",description:`<strong>sampling_eps</strong> (<code>float</code>) &#x2014; the end value of sampling, where timesteps decrease progressively from 1 to
epsilon. &#x2014;`,name:"sampling_eps"},{anchor:"diffusers.ScoreSdeVeScheduler.correct_steps",description:"<strong>correct_steps</strong> (<code>int</code>) &#x2014; number of correction steps performed on a produced sample.",name:"correct_steps"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_sde_ve.py#L45"}}),Ar=new b({props:{name:"scale_model_input",anchor:"diffusers.ScoreSdeVeScheduler.scale_model_input",parameters:[{name:"sample",val:": FloatTensor"},{name:"timestep",val:": typing.Optional[int] = None"}],parametersDescription:[{anchor:"diffusers.ScoreSdeVeScheduler.scale_model_input.sample",description:"<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014; input sample",name:"sample"},{anchor:"diffusers.ScoreSdeVeScheduler.scale_model_input.timestep",description:"<strong>timestep</strong> (<code>int</code>, optional) &#x2014; current timestep",name:"timestep"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_sde_ve.py#L87",returnDescription:`
<p>scaled input sample</p>
`,returnType:`
<p><code>torch.FloatTensor</code></p>
`}}),Ir=new b({props:{name:"set_sigmas",anchor:"diffusers.ScoreSdeVeScheduler.set_sigmas",parameters:[{name:"num_inference_steps",val:": int"},{name:"sigma_min",val:": float = None"},{name:"sigma_max",val:": float = None"},{name:"sampling_eps",val:": float = None"}],parametersDescription:[{anchor:"diffusers.ScoreSdeVeScheduler.set_sigmas.num_inference_steps",description:`<strong>num_inference_steps</strong> (<code>int</code>) &#x2014;
the number of diffusion steps used when generating samples with a pre-trained model.`,name:"num_inference_steps"},{anchor:"diffusers.ScoreSdeVeScheduler.set_sigmas.sigma_min",description:`<strong>sigma_min</strong> (<code>float</code>, optional) &#x2014;
initial noise scale value (overrides value given at Scheduler instantiation).`,name:"sigma_min"},{anchor:"diffusers.ScoreSdeVeScheduler.set_sigmas.sigma_max",description:"<strong>sigma_max</strong> (<code>float</code>, optional) &#x2014; final noise scale value (overrides value given at Scheduler instantiation).",name:"sigma_max"},{anchor:"diffusers.ScoreSdeVeScheduler.set_sigmas.sampling_eps",description:"<strong>sampling_eps</strong> (<code>float</code>, optional) &#x2014; final timestep value (overrides value given at Scheduler instantiation).",name:"sampling_eps"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_sde_ve.py#L117"}}),Fr=new b({props:{name:"set_timesteps",anchor:"diffusers.ScoreSdeVeScheduler.set_timesteps",parameters:[{name:"num_inference_steps",val:": int"},{name:"sampling_eps",val:": float = None"},{name:"device",val:": typing.Union[str, torch.device] = None"}],parametersDescription:[{anchor:"diffusers.ScoreSdeVeScheduler.set_timesteps.num_inference_steps",description:`<strong>num_inference_steps</strong> (<code>int</code>) &#x2014;
the number of diffusion steps used when generating samples with a pre-trained model.`,name:"num_inference_steps"},{anchor:"diffusers.ScoreSdeVeScheduler.set_timesteps.sampling_eps",description:"<strong>sampling_eps</strong> (<code>float</code>, optional) &#x2014; final timestep value (overrides value given at Scheduler instantiation).",name:"sampling_eps"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_sde_ve.py#L101"}}),Lr=new b({props:{name:"step_correct",anchor:"diffusers.ScoreSdeVeScheduler.step_correct",parameters:[{name:"model_output",val:": FloatTensor"},{name:"sample",val:": FloatTensor"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.ScoreSdeVeScheduler.step_correct.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.ScoreSdeVeScheduler.step_correct.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014;
current instance of sample being created by diffusion process.
generator &#x2014; random number generator.`,name:"sample"},{anchor:"diffusers.ScoreSdeVeScheduler.step_correct.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than SchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_sde_ve.py#L212",returnDescription:`
<p><code>SdeVeOutput</code> if
<code>return_dict</code> is True, otherwise a <code>tuple</code>. When returning a tuple, the first element is the sample tensor.</p>
`,returnType:`
<p><code>SdeVeOutput</code> or <code>tuple</code></p>
`}}),Kr=new b({props:{name:"step_pred",anchor:"diffusers.ScoreSdeVeScheduler.step_pred",parameters:[{name:"model_output",val:": FloatTensor"},{name:"timestep",val:": int"},{name:"sample",val:": FloatTensor"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.ScoreSdeVeScheduler.step_pred.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.ScoreSdeVeScheduler.step_pred.timestep",description:"<strong>timestep</strong> (<code>int</code>) &#x2014; current discrete timestep in the diffusion chain.",name:"timestep"},{anchor:"diffusers.ScoreSdeVeScheduler.step_pred.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014;
current instance of sample being created by diffusion process.
generator &#x2014; random number generator.`,name:"sample"},{anchor:"diffusers.ScoreSdeVeScheduler.step_pred.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than SchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_sde_ve.py#L151",returnDescription:`
<p><code>SdeVeOutput</code> if
<code>return_dict</code> is True, otherwise a <code>tuple</code>. When returning a tuple, the first element is the sample tensor.</p>
`,returnType:`
<p><code>SdeVeOutput</code> or <code>tuple</code></p>
`}}),qr=new q({}),Hr=new b({props:{name:"class diffusers.IPNDMScheduler",anchor:"diffusers.IPNDMScheduler",parameters:[{name:"num_train_timesteps",val:": int = 1000"}],parametersDescription:[{anchor:"diffusers.IPNDMScheduler.num_train_timesteps",description:"<strong>num_train_timesteps</strong> (<code>int</code>) &#x2014; number of diffusion steps used to train the model.",name:"num_train_timesteps"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ipndm.py#L24"}}),Br=new b({props:{name:"scale_model_input",anchor:"diffusers.IPNDMScheduler.scale_model_input",parameters:[{name:"sample",val:": FloatTensor"},{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.IPNDMScheduler.scale_model_input.sample",description:"<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014; input sample",name:"sample"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ipndm.py#L126",returnDescription:`
<p>scaled input sample</p>
`,returnType:`
<p><code>torch.FloatTensor</code></p>
`}}),Gr=new b({props:{name:"set_timesteps",anchor:"diffusers.IPNDMScheduler.set_timesteps",parameters:[{name:"num_inference_steps",val:": int"},{name:"device",val:": typing.Union[str, torch.device] = None"}],parametersDescription:[{anchor:"diffusers.IPNDMScheduler.set_timesteps.num_inference_steps",description:`<strong>num_inference_steps</strong> (<code>int</code>) &#x2014;
the number of diffusion steps used when generating samples with a pre-trained model.`,name:"num_inference_steps"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ipndm.py#L56"}}),Yr=new b({props:{name:"step",anchor:"diffusers.IPNDMScheduler.step",parameters:[{name:"model_output",val:": FloatTensor"},{name:"timestep",val:": int"},{name:"sample",val:": FloatTensor"},{name:"return_dict",val:": bool = True"}],parametersDescription:[{anchor:"diffusers.IPNDMScheduler.step.model_output",description:"<strong>model_output</strong> (<code>torch.FloatTensor</code>) &#x2014; direct output from learned diffusion model.",name:"model_output"},{anchor:"diffusers.IPNDMScheduler.step.timestep",description:"<strong>timestep</strong> (<code>int</code>) &#x2014; current discrete timestep in the diffusion chain.",name:"timestep"},{anchor:"diffusers.IPNDMScheduler.step.sample",description:`<strong>sample</strong> (<code>torch.FloatTensor</code>) &#x2014;
current instance of sample being created by diffusion process.`,name:"sample"},{anchor:"diffusers.IPNDMScheduler.step.return_dict",description:"<strong>return_dict</strong> (<code>bool</code>) &#x2014; option for returning tuple rather than SchedulerOutput class",name:"return_dict"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ipndm.py#L76",returnDescription:`
<p><code>~scheduling_utils.SchedulerOutput</code> if <code>return_dict</code> is
True, otherwise a <code>tuple</code>. When returning a tuple, the first element is the sample tensor.</p>
`,returnType:`
<p><code>~scheduling_utils.SchedulerOutput</code> or <code>tuple</code></p>
`}}),zr=new q({}),Mt=new Nv({props:{warning:!0,$$slots:{default:[Av]},$$scope:{ctx:ai}}}),jr=new b({props:{name:"class diffusers.schedulers.ScoreSdeVpScheduler",anchor:"diffusers.schedulers.ScoreSdeVpScheduler",parameters:[{name:"num_train_timesteps",val:" = 2000"},{name:"beta_min",val:" = 0.1"},{name:"beta_max",val:" = 20"},{name:"sampling_eps",val:" = 0.001"}],source:"https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_sde_vp.py#L26"}}),{c(){K=s("meta"),Pe=l(),U=s("h1"),re=s("a"),en=s("span"),p(Tt.$$.fragment),rd=l(),tn=s("span"),sd=i("Schedulers"),di=l(),Zr=s("p"),nd=i("Diffusers contains multiple pre-built schedule functions for the diffusion process."),li=l(),le=s("h2"),Te=s("a"),rn=s("span"),p(Ot.$$.fragment),od=l(),sn=s("span"),id=i("What is a scheduler?"),ci=l(),Oe=s("p"),ad=i("The schedule functions, denoted "),nn=s("em"),dd=i("Schedulers"),ld=i(" in the library take in the output of a trained model, a sample which the diffusion process is iterating on, and a timestep to return a denoised sample."),ui=l(),ke=s("ul"),es=s("li"),cd=i("Schedulers define the methodology for iteratively adding noise to an image or for updating a sample based on model outputs."),kt=s("ul"),on=s("li"),ud=i("adding noise in different manners represent the algorithmic processes to train a diffusion model by adding noise to images."),fd=l(),an=s("li"),pd=i("for inference, the scheduler defines how to update a sample based on an output from a pretrained model."),hd=l(),ce=s("li"),md=i("Schedulers are often defined by a "),dn=s("em"),gd=i("noise schedule"),_d=i(" and an "),ln=s("em"),vd=i("update rule"),bd=i(" to solve the differential equation solution."),fi=l(),ue=s("h3"),Ve=s("a"),cn=s("span"),p(Vt.$$.fragment),Sd=l(),un=s("span"),$d=i("Discrete versus continuous schedulers"),pi=l(),P=s("p"),Dd=i(`All schedulers take in a timestep to predict the updated version of the sample being diffused.
The timesteps dictate where in the diffusion process the step is, where data is generated by iterating forward in time and inference is executed by propagating backwards through timesteps.
Different algorithms use timesteps that both discrete (accepting `),fn=s("code"),Ed=i("int"),xd=i(" inputs), such as the "),ts=s("a"),yd=i("DDPMScheduler"),wd=i(" or "),rs=s("a"),Md=i("PNDMScheduler"),Pd=i(", and continuous (accepting "),pn=s("code"),Td=i("float"),Od=i(" inputs), such as the score-based schedulers "),ss=s("a"),kd=i("ScoreSdeVeScheduler"),Vd=i(" or "),hn=s("code"),Cd=i("ScoreSdeVpScheduler"),Nd=i("."),hi=l(),fe=s("h2"),Ce=s("a"),mn=s("span"),p(Ct.$$.fragment),Ad=l(),gn=s("span"),Id=i("Designing Re-usable schedulers"),mi=l(),ns=s("p"),Fd=i(`The core design principle between the schedule functions is to be model, system, and framework independent.
This allows for rapid experimentation and cleaner abstractions in the code, where the model prediction is separated from the sample update.
To this end, the design of schedulers is such that:`),gi=l(),Ne=s("ul"),_n=s("li"),Ld=i("Schedulers can be used interchangeably between diffusion models in inference to find the preferred trade-off between speed and generation quality."),Kd=l(),vn=s("li"),qd=i("Schedulers are currently by default in PyTorch, but are designed to be framework independent (partial Jax support currently exists)."),_i=l(),pe=s("h2"),Ae=s("a"),bn=s("span"),p(Nt.$$.fragment),Ud=l(),Sn=s("span"),Hd=i("API"),vi=l(),os=s("p"),Rd=i("The core API for any new scheduler must follow a limited structure."),bi=l(),ne=s("ul"),At=s("li"),Wd=i("Schedulers should provide one or more "),$n=s("code"),Bd=i("def step(...)"),Gd=i(" functions that should be called to update the generated sample iteratively."),Yd=l(),It=s("li"),zd=i("Schedulers should provide a "),Dn=s("code"),Jd=i("set_timesteps(...)"),jd=i(" method that configures the parameters of a schedule function for a specific inference task."),Qd=l(),En=s("li"),Xd=i("Schedulers should be framework-specific."),Si=l(),Ie=s("p"),Zd=i("The base class "),is=s("a"),el=i("SchedulerMixin"),tl=i(" implements low level utilities used by multiple schedulers."),$i=l(),he=s("h3"),Fe=s("a"),xn=s("span"),p(Ft.$$.fragment),rl=l(),yn=s("span"),sl=i("SchedulerMixin"),Di=l(),me=s("div"),p(Lt.$$.fragment),nl=l(),wn=s("p"),ol=i("Mixin containing common functions for the schedulers."),Ei=l(),ge=s("h3"),Le=s("a"),Mn=s("span"),p(Kt.$$.fragment),il=l(),Pn=s("span"),al=i("SchedulerOutput"),xi=i("\n\nThe class `SchedulerOutput` contains the outputs from any schedulers `step(...)` call.\n"),_e=s("div"),p(qt.$$.fragment),dl=l(),Tn=s("p"),ll=i("Base class for the scheduler\u2019s step function output."),yi=l(),ve=s("h3"),Ke=s("a"),On=s("span"),p(Ut.$$.fragment),cl=l(),kn=s("span"),ul=i("Implemented Schedulers"),wi=l(),be=s("h4"),qe=s("a"),Vn=s("span"),p(Ht.$$.fragment),fl=l(),Cn=s("span"),pl=i("Denoising diffusion implicit models (DDIM)"),Mi=l(),as=s("p"),hl=i("Original paper can be found here."),Pi=l(),x=s("div"),p(Rt.$$.fragment),ml=l(),Nn=s("p"),gl=i(`Denoising diffusion implicit models is a scheduler that extends the denoising procedure introduced in denoising
diffusion probabilistic models (DDPMs) with non-Markovian guidance.`),_l=l(),T=s("p"),ds=s("a"),vl=i("~ConfigMixin"),bl=i(" takes care of storing all config attributes that are passed in the scheduler\u2019s "),An=s("code"),Sl=i("__init__"),$l=i(`
function, such as `),In=s("code"),Dl=i("num_train_timesteps"),El=i(". They can be accessed via "),Fn=s("code"),xl=i("scheduler.config.num_train_timesteps"),yl=i(`.
`),ls=s("a"),wl=i("~ConfigMixin"),Ml=i(" also provides general loading and saving functionality via the "),cs=s("a"),Pl=i("save_config()"),Tl=i(` and
`),us=s("a"),Ol=i("from_config()"),kl=i(" functions."),Vl=l(),fs=s("p"),Cl=i("For more details, see the original paper: "),Wt=s("a"),Nl=i("https://arxiv.org/abs/2010.02502"),Al=l(),Ue=s("div"),p(Bt.$$.fragment),Il=l(),Ln=s("p"),Fl=i(`Ensures interchangeability with schedulers that need to scale the denoising model input depending on the
current timestep.`),Ll=l(),He=s("div"),p(Gt.$$.fragment),Kl=l(),Kn=s("p"),ql=i("Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference."),Ul=l(),Re=s("div"),p(Yt.$$.fragment),Hl=l(),qn=s("p"),Rl=i(`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),Ti=l(),Se=s("h4"),We=s("a"),Un=s("span"),p(zt.$$.fragment),Wl=l(),Hn=s("span"),Bl=i("Denoising diffusion probabilistic models (DDPM)"),Oi=l(),Be=s("p"),Gl=i("Original paper can be found "),Jt=s("a"),Yl=i("here"),zl=i("."),ki=l(),y=s("div"),p(jt.$$.fragment),Jl=l(),Rn=s("p"),jl=i(`Denoising diffusion probabilistic models (DDPMs) explores the connections between denoising score matching and
Langevin dynamics sampling.`),Ql=l(),O=s("p"),ps=s("a"),Xl=i("~ConfigMixin"),Zl=i(" takes care of storing all config attributes that are passed in the scheduler\u2019s "),Wn=s("code"),ec=i("__init__"),tc=i(`
function, such as `),Bn=s("code"),rc=i("num_train_timesteps"),sc=i(". They can be accessed via "),Gn=s("code"),nc=i("scheduler.config.num_train_timesteps"),oc=i(`.
`),hs=s("a"),ic=i("~ConfigMixin"),ac=i(" also provides general loading and saving functionality via the "),ms=s("a"),dc=i("save_config()"),lc=i(` and
`),gs=s("a"),cc=i("from_config()"),uc=i(" functions."),fc=l(),_s=s("p"),pc=i("For more details, see the original paper: "),Qt=s("a"),hc=i("https://arxiv.org/abs/2006.11239"),mc=l(),Ge=s("div"),p(Xt.$$.fragment),gc=l(),Yn=s("p"),_c=i(`Ensures interchangeability with schedulers that need to scale the denoising model input depending on the
current timestep.`),vc=l(),Ye=s("div"),p(Zt.$$.fragment),bc=l(),zn=s("p"),Sc=i("Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference."),$c=l(),ze=s("div"),p(er.$$.fragment),Dc=l(),Jn=s("p"),Ec=i(`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),Vi=l(),$e=s("h4"),Je=s("a"),jn=s("span"),p(tr.$$.fragment),xc=l(),Qn=s("span"),yc=i("Variance exploding, stochastic sampling from Karras et. al"),Ci=l(),je=s("p"),wc=i("Original paper can be found "),rr=s("a"),Mc=i("here"),Pc=i("."),Ni=l(),S=s("div"),p(sr.$$.fragment),Tc=l(),Xn=s("p"),Oc=i(`Stochastic sampling from Karras et al. [1] tailored to the Variance-Expanding (VE) models [2]. Use Algorithm 2 and
the VE column of Table 1 from [1] for reference.`),kc=l(),Qe=s("p"),Vc=i(`[1] Karras, Tero, et al. \u201CElucidating the Design Space of Diffusion-Based Generative Models.\u201D
`),nr=s("a"),Cc=i("https://arxiv.org/abs/2206.00364"),Nc=i(` [2] Song, Yang, et al. \u201CScore-based generative modeling through stochastic
differential equations.\u201D `),or=s("a"),Ac=i("https://arxiv.org/abs/2011.13456"),Ic=l(),k=s("p"),vs=s("a"),Fc=i("~ConfigMixin"),Lc=i(" takes care of storing all config attributes that are passed in the scheduler\u2019s "),Zn=s("code"),Kc=i("__init__"),qc=i(`
function, such as `),eo=s("code"),Uc=i("num_train_timesteps"),Hc=i(". They can be accessed via "),to=s("code"),Rc=i("scheduler.config.num_train_timesteps"),Wc=i(`.
`),bs=s("a"),Bc=i("~ConfigMixin"),Gc=i(" also provides general loading and saving functionality via the "),Ss=s("a"),Yc=i("save_config()"),zc=i(` and
`),$s=s("a"),Jc=i("from_config()"),jc=i(" functions."),Qc=l(),ir=s("p"),Xc=i(`For more details on the parameters, see the original paper\u2019s Appendix E.: \u201CElucidating the Design Space of
Diffusion-Based Generative Models.\u201D `),ar=s("a"),Zc=i("https://arxiv.org/abs/2206.00364"),eu=i(`. The grid search values used to find the
optimal {s_noise, s_churn, s_min, s_max} for a specific model are described in Table 5 of the paper.`),tu=l(),oe=s("div"),p(dr.$$.fragment),ru=l(),ro=s("p"),su=i(`Explicit Langevin-like \u201Cchurn\u201D step of adding noise to the sample according to a factor gamma_i \u2265 0 to reach a
higher noise level sigma_hat = sigma_i + gamma_i*sigma_i.`),nu=l(),so=s("p"),ou=i("TODO Args:"),iu=l(),Xe=s("div"),p(lr.$$.fragment),au=l(),no=s("p"),du=i(`Ensures interchangeability with schedulers that need to scale the denoising model input depending on the
current timestep.`),lu=l(),Ze=s("div"),p(cr.$$.fragment),cu=l(),oo=s("p"),uu=i("Sets the continuous timesteps used for the diffusion chain. Supporting function to be run before inference."),fu=l(),et=s("div"),p(ur.$$.fragment),pu=l(),io=s("p"),hu=i(`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),mu=l(),tt=s("div"),p(fr.$$.fragment),gu=l(),ao=s("p"),_u=i("Correct the predicted sample based on the output model_output of the network. TODO complete description"),Ai=l(),De=s("h4"),rt=s("a"),lo=s("span"),p(pr.$$.fragment),vu=l(),co=s("span"),bu=i("Linear multistep scheduler for discrete beta schedules"),Ii=l(),st=s("p"),Su=i("Original implementation can be found "),hr=s("a"),$u=i("here"),Du=i("."),Fi=l(),w=s("div"),p(mr.$$.fragment),Eu=l(),Ds=s("p"),xu=i(`Linear Multistep Scheduler for discrete beta schedules. Based on the original k-diffusion implementation by
Katherine Crowson:
`),gr=s("a"),yu=i("https://github.com/crowsonkb/k-diffusion/blob/481677d114f6ea445aa009cf5bd7a9cdee909e47/k_diffusion/sampling.py#L181"),wu=l(),V=s("p"),Es=s("a"),Mu=i("~ConfigMixin"),Pu=i(" takes care of storing all config attributes that are passed in the scheduler\u2019s "),uo=s("code"),Tu=i("__init__"),Ou=i(`
function, such as `),fo=s("code"),ku=i("num_train_timesteps"),Vu=i(". They can be accessed via "),po=s("code"),Cu=i("scheduler.config.num_train_timesteps"),Nu=i(`.
`),xs=s("a"),Au=i("~ConfigMixin"),Iu=i(" also provides general loading and saving functionality via the "),ys=s("a"),Fu=i("save_config()"),Lu=i(` and
`),ws=s("a"),Ku=i("from_config()"),qu=i(" functions."),Uu=l(),nt=s("div"),p(_r.$$.fragment),Hu=l(),ho=s("p"),Ru=i("Compute a linear multistep coefficient."),Wu=l(),ot=s("div"),p(vr.$$.fragment),Bu=l(),br=s("p"),Gu=i("Scales the denoising model input by "),mo=s("code"),Yu=i("(sigma**2 + 1) ** 0.5"),zu=i(" to match the K-LMS algorithm."),Ju=l(),it=s("div"),p(Sr.$$.fragment),ju=l(),go=s("p"),Qu=i("Sets the timesteps used for the diffusion chain. Supporting function to be run before inference."),Xu=l(),at=s("div"),p($r.$$.fragment),Zu=l(),_o=s("p"),ef=i(`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),Li=l(),Ee=s("h4"),dt=s("a"),vo=s("span"),p(Dr.$$.fragment),tf=l(),bo=s("span"),rf=i("Pseudo numerical methods for diffusion models (PNDM)"),Ki=l(),lt=s("p"),sf=i("Original implementation can be found "),Er=s("a"),nf=i("here"),of=i("."),qi=l(),$=s("div"),p(xr.$$.fragment),af=l(),So=s("p"),df=i(`Pseudo numerical methods for diffusion models (PNDM) proposes using more advanced ODE integration techniques,
namely Runge-Kutta method and a linear multi-step method.`),lf=l(),C=s("p"),Ms=s("a"),cf=i("~ConfigMixin"),uf=i(" takes care of storing all config attributes that are passed in the scheduler\u2019s "),$o=s("code"),ff=i("__init__"),pf=i(`
function, such as `),Do=s("code"),hf=i("num_train_timesteps"),mf=i(". They can be accessed via "),Eo=s("code"),gf=i("scheduler.config.num_train_timesteps"),_f=i(`.
`),Ps=s("a"),vf=i("~ConfigMixin"),bf=i(" also provides general loading and saving functionality via the "),Ts=s("a"),Sf=i("save_config()"),$f=i(` and
`),Os=s("a"),Df=i("from_config()"),Ef=i(" functions."),xf=l(),ks=s("p"),yf=i("For more details, see the original paper: "),yr=s("a"),wf=i("https://arxiv.org/abs/2202.09778"),Mf=l(),ct=s("div"),p(wr.$$.fragment),Pf=l(),xo=s("p"),Tf=i(`Ensures interchangeability with schedulers that need to scale the denoising model input depending on the
current timestep.`),Of=l(),ut=s("div"),p(Mr.$$.fragment),kf=l(),yo=s("p"),Vf=i("Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference."),Cf=l(),ie=s("div"),p(Pr.$$.fragment),Nf=l(),wo=s("p"),Af=i(`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),If=l(),se=s("p"),Ff=i("This function calls "),Mo=s("code"),Lf=i("step_prk()"),Kf=i(" or "),Po=s("code"),qf=i("step_plms()"),Uf=i(" depending on the internal variable "),To=s("code"),Hf=i("counter"),Rf=i("."),Wf=l(),ft=s("div"),p(Tr.$$.fragment),Bf=l(),Oo=s("p"),Gf=i(`Step function propagating the sample with the linear multi-step method. This has one forward pass with multiple
times to approximate the solution.`),Yf=l(),pt=s("div"),p(Or.$$.fragment),zf=l(),ko=s("p"),Jf=i(`Step function propagating the sample with the Runge-Kutta method. RK takes 4 forward passes to approximate the
solution to the differential equation.`),Ui=l(),xe=s("h4"),ht=s("a"),Vo=s("span"),p(kr.$$.fragment),jf=l(),Co=s("span"),Qf=i("variance exploding stochastic differential equation (VE-SDE) scheduler"),Hi=l(),mt=s("p"),Xf=i("Original paper can be found "),Vr=s("a"),Zf=i("here"),ep=i("."),Ri=l(),D=s("div"),p(Cr.$$.fragment),tp=l(),No=s("p"),rp=i("The variance exploding stochastic differential equation (SDE) scheduler."),sp=l(),Vs=s("p"),np=i("For more information, see the original paper: "),Nr=s("a"),op=i("https://arxiv.org/abs/2011.13456"),ip=l(),N=s("p"),Cs=s("a"),ap=i("~ConfigMixin"),dp=i(" takes care of storing all config attributes that are passed in the scheduler\u2019s "),Ao=s("code"),lp=i("__init__"),cp=i(`
function, such as `),Io=s("code"),up=i("num_train_timesteps"),fp=i(". They can be accessed via "),Fo=s("code"),pp=i("scheduler.config.num_train_timesteps"),hp=i(`.
`),Ns=s("a"),mp=i("~ConfigMixin"),gp=i(" also provides general loading and saving functionality via the "),As=s("a"),_p=i("save_config()"),vp=i(` and
`),Is=s("a"),bp=i("from_config()"),Sp=i(" functions."),$p=l(),gt=s("div"),p(Ar.$$.fragment),Dp=l(),Lo=s("p"),Ep=i(`Ensures interchangeability with schedulers that need to scale the denoising model input depending on the
current timestep.`),xp=l(),ae=s("div"),p(Ir.$$.fragment),yp=l(),Ko=s("p"),wp=i("Sets the noise scales used for the diffusion chain. Supporting function to be run before inference."),Mp=l(),ye=s("p"),Pp=i("The sigmas control the weight of the "),qo=s("code"),Tp=i("drift"),Op=i(" and "),Uo=s("code"),kp=i("diffusion"),Vp=i(" components of sample update."),Cp=l(),_t=s("div"),p(Fr.$$.fragment),Np=l(),Ho=s("p"),Ap=i("Sets the continuous timesteps used for the diffusion chain. Supporting function to be run before inference."),Ip=l(),vt=s("div"),p(Lr.$$.fragment),Fp=l(),Ro=s("p"),Lp=i(`Correct the predicted sample based on the output model_output of the network. This is often run repeatedly
after making the prediction for the previous timestep.`),Kp=l(),bt=s("div"),p(Kr.$$.fragment),qp=l(),Wo=s("p"),Up=i(`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),Wi=l(),we=s("h4"),St=s("a"),Bo=s("span"),p(qr.$$.fragment),Hp=l(),Go=s("span"),Rp=i("improved pseudo numerical methods for diffusion models (iPNDM)"),Bi=l(),$t=s("p"),Wp=i("Original implementation can be found "),Ur=s("a"),Bp=i("here"),Gp=i("."),Gi=l(),M=s("div"),p(Hr.$$.fragment),Yp=l(),Fs=s("p"),zp=i(`Improved Pseudo numerical methods for diffusion models (iPNDM) ported from @crowsonkb\u2019s amazing k-diffusion
`),Rr=s("a"),Jp=i("library"),jp=l(),A=s("p"),Ls=s("a"),Qp=i("~ConfigMixin"),Xp=i(" takes care of storing all config attributes that are passed in the scheduler\u2019s "),Yo=s("code"),Zp=i("__init__"),eh=i(`
function, such as `),zo=s("code"),th=i("num_train_timesteps"),rh=i(". They can be accessed via "),Jo=s("code"),sh=i("scheduler.config.num_train_timesteps"),nh=i(`.
`),Ks=s("a"),oh=i("~ConfigMixin"),ih=i(" also provides general loading and saving functionality via the "),qs=s("a"),ah=i("save_config()"),dh=i(` and
`),Us=s("a"),lh=i("from_config()"),ch=i(" functions."),uh=l(),Hs=s("p"),fh=i("For more details, see the original paper: "),Wr=s("a"),ph=i("https://arxiv.org/abs/2202.09778"),hh=l(),Dt=s("div"),p(Br.$$.fragment),mh=l(),jo=s("p"),gh=i(`Ensures interchangeability with schedulers that need to scale the denoising model input depending on the
current timestep.`),_h=l(),Et=s("div"),p(Gr.$$.fragment),vh=l(),Qo=s("p"),bh=i("Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference."),Sh=l(),xt=s("div"),p(Yr.$$.fragment),$h=l(),Xo=s("p"),Dh=i(`Step function propagating the sample with the linear multi-step method. This has one forward pass with multiple
times to approximate the solution.`),Yi=l(),Me=s("h4"),yt=s("a"),Zo=s("span"),p(zr.$$.fragment),Eh=l(),ei=s("span"),xh=i("variance preserving stochastic differential equation (VP-SDE) scheduler"),zi=l(),wt=s("p"),yh=i("Original paper can be found "),Jr=s("a"),wh=i("here"),Mh=i("."),Ji=l(),p(Mt.$$.fragment),ji=l(),H=s("div"),p(jr.$$.fragment),Ph=l(),ti=s("p"),Th=i("The variance preserving stochastic differential equation (SDE) scheduler."),Oh=l(),I=s("p"),Rs=s("a"),kh=i("~ConfigMixin"),Vh=i(" takes care of storing all config attributes that are passed in the scheduler\u2019s "),ri=s("code"),Ch=i("__init__"),Nh=i(`
function, such as `),si=s("code"),Ah=i("num_train_timesteps"),Ih=i(". They can be accessed via "),ni=s("code"),Fh=i("scheduler.config.num_train_timesteps"),Lh=i(`.
`),Ws=s("a"),Kh=i("~ConfigMixin"),qh=i(" also provides general loading and saving functionality via the "),Bs=s("a"),Uh=i("save_config()"),Hh=i(` and
`),Gs=s("a"),Rh=i("from_config()"),Wh=i(" functions."),Bh=l(),Ys=s("p"),Gh=i("For more information, see the original paper: "),Qr=s("a"),Yh=i("https://arxiv.org/abs/2011.13456"),zh=l(),oi=s("p"),Jh=i("UNDER CONSTRUCTION"),this.h()},l(t){const u=Vv('[data-svelte="svelte-1phssyn"]',document.head);K=n(u,"META",{name:!0,content:!0}),u.forEach(r),Pe=c(t),U=n(t,"H1",{class:!0});var Xr=o(U);re=n(Xr,"A",{id:!0,class:!0,href:!0});var om=o(re);en=n(om,"SPAN",{});var im=o(en);h(Tt.$$.fragment,im),im.forEach(r),om.forEach(r),rd=c(Xr),tn=n(Xr,"SPAN",{});var am=o(tn);sd=a(am,"Schedulers"),am.forEach(r),Xr.forEach(r),di=c(t),Zr=n(t,"P",{});var dm=o(Zr);nd=a(dm,"Diffusers contains multiple pre-built schedule functions for the diffusion process."),dm.forEach(r),li=c(t),le=n(t,"H2",{class:!0});var Xi=o(le);Te=n(Xi,"A",{id:!0,class:!0,href:!0});var lm=o(Te);rn=n(lm,"SPAN",{});var cm=o(rn);h(Ot.$$.fragment,cm),cm.forEach(r),lm.forEach(r),od=c(Xi),sn=n(Xi,"SPAN",{});var um=o(sn);id=a(um,"What is a scheduler?"),um.forEach(r),Xi.forEach(r),ci=c(t),Oe=n(t,"P",{});var Zi=o(Oe);ad=a(Zi,"The schedule functions, denoted "),nn=n(Zi,"EM",{});var fm=o(nn);dd=a(fm,"Schedulers"),fm.forEach(r),ld=a(Zi," in the library take in the output of a trained model, a sample which the diffusion process is iterating on, and a timestep to return a denoised sample."),Zi.forEach(r),ui=c(t),ke=n(t,"UL",{});var ea=o(ke);es=n(ea,"LI",{});var jh=o(es);cd=a(jh,"Schedulers define the methodology for iteratively adding noise to an image or for updating a sample based on model outputs."),kt=n(jh,"UL",{});var ta=o(kt);on=n(ta,"LI",{});var pm=o(on);ud=a(pm,"adding noise in different manners represent the algorithmic processes to train a diffusion model by adding noise to images."),pm.forEach(r),fd=c(ta),an=n(ta,"LI",{});var hm=o(an);pd=a(hm,"for inference, the scheduler defines how to update a sample based on an output from a pretrained model."),hm.forEach(r),ta.forEach(r),jh.forEach(r),hd=c(ea),ce=n(ea,"LI",{});var zs=o(ce);md=a(zs,"Schedulers are often defined by a "),dn=n(zs,"EM",{});var mm=o(dn);gd=a(mm,"noise schedule"),mm.forEach(r),_d=a(zs," and an "),ln=n(zs,"EM",{});var gm=o(ln);vd=a(gm,"update rule"),gm.forEach(r),bd=a(zs," to solve the differential equation solution."),zs.forEach(r),ea.forEach(r),fi=c(t),ue=n(t,"H3",{class:!0});var ra=o(ue);Ve=n(ra,"A",{id:!0,class:!0,href:!0});var _m=o(Ve);cn=n(_m,"SPAN",{});var vm=o(cn);h(Vt.$$.fragment,vm),vm.forEach(r),_m.forEach(r),Sd=c(ra),un=n(ra,"SPAN",{});var bm=o(un);$d=a(bm,"Discrete versus continuous schedulers"),bm.forEach(r),ra.forEach(r),pi=c(t),P=n(t,"P",{});var Q=o(P);Dd=a(Q,`All schedulers take in a timestep to predict the updated version of the sample being diffused.
The timesteps dictate where in the diffusion process the step is, where data is generated by iterating forward in time and inference is executed by propagating backwards through timesteps.
Different algorithms use timesteps that both discrete (accepting `),fn=n(Q,"CODE",{});var Sm=o(fn);Ed=a(Sm,"int"),Sm.forEach(r),xd=a(Q," inputs), such as the "),ts=n(Q,"A",{href:!0});var $m=o(ts);yd=a($m,"DDPMScheduler"),$m.forEach(r),wd=a(Q," or "),rs=n(Q,"A",{href:!0});var Dm=o(rs);Md=a(Dm,"PNDMScheduler"),Dm.forEach(r),Pd=a(Q,", and continuous (accepting "),pn=n(Q,"CODE",{});var Em=o(pn);Td=a(Em,"float"),Em.forEach(r),Od=a(Q," inputs), such as the score-based schedulers "),ss=n(Q,"A",{href:!0});var xm=o(ss);kd=a(xm,"ScoreSdeVeScheduler"),xm.forEach(r),Vd=a(Q," or "),hn=n(Q,"CODE",{});var ym=o(hn);Cd=a(ym,"ScoreSdeVpScheduler"),ym.forEach(r),Nd=a(Q,"."),Q.forEach(r),hi=c(t),fe=n(t,"H2",{class:!0});var sa=o(fe);Ce=n(sa,"A",{id:!0,class:!0,href:!0});var wm=o(Ce);mn=n(wm,"SPAN",{});var Mm=o(mn);h(Ct.$$.fragment,Mm),Mm.forEach(r),wm.forEach(r),Ad=c(sa),gn=n(sa,"SPAN",{});var Pm=o(gn);Id=a(Pm,"Designing Re-usable schedulers"),Pm.forEach(r),sa.forEach(r),mi=c(t),ns=n(t,"P",{});var Tm=o(ns);Fd=a(Tm,`The core design principle between the schedule functions is to be model, system, and framework independent.
This allows for rapid experimentation and cleaner abstractions in the code, where the model prediction is separated from the sample update.
To this end, the design of schedulers is such that:`),Tm.forEach(r),gi=c(t),Ne=n(t,"UL",{});var na=o(Ne);_n=n(na,"LI",{});var Om=o(_n);Ld=a(Om,"Schedulers can be used interchangeably between diffusion models in inference to find the preferred trade-off between speed and generation quality."),Om.forEach(r),Kd=c(na),vn=n(na,"LI",{});var km=o(vn);qd=a(km,"Schedulers are currently by default in PyTorch, but are designed to be framework independent (partial Jax support currently exists)."),km.forEach(r),na.forEach(r),_i=c(t),pe=n(t,"H2",{class:!0});var oa=o(pe);Ae=n(oa,"A",{id:!0,class:!0,href:!0});var Vm=o(Ae);bn=n(Vm,"SPAN",{});var Cm=o(bn);h(Nt.$$.fragment,Cm),Cm.forEach(r),Vm.forEach(r),Ud=c(oa),Sn=n(oa,"SPAN",{});var Nm=o(Sn);Hd=a(Nm,"API"),Nm.forEach(r),oa.forEach(r),vi=c(t),os=n(t,"P",{});var Am=o(os);Rd=a(Am,"The core API for any new scheduler must follow a limited structure."),Am.forEach(r),bi=c(t),ne=n(t,"UL",{});var Js=o(ne);At=n(Js,"LI",{});var ia=o(At);Wd=a(ia,"Schedulers should provide one or more "),$n=n(ia,"CODE",{});var Im=o($n);Bd=a(Im,"def step(...)"),Im.forEach(r),Gd=a(ia," functions that should be called to update the generated sample iteratively."),ia.forEach(r),Yd=c(Js),It=n(Js,"LI",{});var aa=o(It);zd=a(aa,"Schedulers should provide a "),Dn=n(aa,"CODE",{});var Fm=o(Dn);Jd=a(Fm,"set_timesteps(...)"),Fm.forEach(r),jd=a(aa," method that configures the parameters of a schedule function for a specific inference task."),aa.forEach(r),Qd=c(Js),En=n(Js,"LI",{});var Lm=o(En);Xd=a(Lm,"Schedulers should be framework-specific."),Lm.forEach(r),Js.forEach(r),Si=c(t),Ie=n(t,"P",{});var da=o(Ie);Zd=a(da,"The base class "),is=n(da,"A",{href:!0});var Km=o(is);el=a(Km,"SchedulerMixin"),Km.forEach(r),tl=a(da," implements low level utilities used by multiple schedulers."),da.forEach(r),$i=c(t),he=n(t,"H3",{class:!0});var la=o(he);Fe=n(la,"A",{id:!0,class:!0,href:!0});var qm=o(Fe);xn=n(qm,"SPAN",{});var Um=o(xn);h(Ft.$$.fragment,Um),Um.forEach(r),qm.forEach(r),rl=c(la),yn=n(la,"SPAN",{});var Hm=o(yn);sl=a(Hm,"SchedulerMixin"),Hm.forEach(r),la.forEach(r),Di=c(t),me=n(t,"DIV",{class:!0});var ca=o(me);h(Lt.$$.fragment,ca),nl=c(ca),wn=n(ca,"P",{});var Rm=o(wn);ol=a(Rm,"Mixin containing common functions for the schedulers."),Rm.forEach(r),ca.forEach(r),Ei=c(t),ge=n(t,"H3",{class:!0});var ua=o(ge);Le=n(ua,"A",{id:!0,class:!0,href:!0});var Wm=o(Le);Mn=n(Wm,"SPAN",{});var Bm=o(Mn);h(Kt.$$.fragment,Bm),Bm.forEach(r),Wm.forEach(r),il=c(ua),Pn=n(ua,"SPAN",{});var Gm=o(Pn);al=a(Gm,"SchedulerOutput"),Gm.forEach(r),ua.forEach(r),xi=a(t,"\n\nThe class `SchedulerOutput` contains the outputs from any schedulers `step(...)` call.\n"),_e=n(t,"DIV",{class:!0});var fa=o(_e);h(qt.$$.fragment,fa),dl=c(fa),Tn=n(fa,"P",{});var Ym=o(Tn);ll=a(Ym,"Base class for the scheduler\u2019s step function output."),Ym.forEach(r),fa.forEach(r),yi=c(t),ve=n(t,"H3",{class:!0});var pa=o(ve);Ke=n(pa,"A",{id:!0,class:!0,href:!0});var zm=o(Ke);On=n(zm,"SPAN",{});var Jm=o(On);h(Ut.$$.fragment,Jm),Jm.forEach(r),zm.forEach(r),cl=c(pa),kn=n(pa,"SPAN",{});var jm=o(kn);ul=a(jm,"Implemented Schedulers"),jm.forEach(r),pa.forEach(r),wi=c(t),be=n(t,"H4",{class:!0});var ha=o(be);qe=n(ha,"A",{id:!0,class:!0,href:!0});var Qm=o(qe);Vn=n(Qm,"SPAN",{});var Xm=o(Vn);h(Ht.$$.fragment,Xm),Xm.forEach(r),Qm.forEach(r),fl=c(ha),Cn=n(ha,"SPAN",{});var Zm=o(Cn);pl=a(Zm,"Denoising diffusion implicit models (DDIM)"),Zm.forEach(r),ha.forEach(r),Mi=c(t),as=n(t,"P",{});var eg=o(as);hl=a(eg,"Original paper can be found here."),eg.forEach(r),Pi=c(t),x=n(t,"DIV",{class:!0});var X=o(x);h(Rt.$$.fragment,X),ml=c(X),Nn=n(X,"P",{});var tg=o(Nn);gl=a(tg,`Denoising diffusion implicit models is a scheduler that extends the denoising procedure introduced in denoising
diffusion probabilistic models (DDPMs) with non-Markovian guidance.`),tg.forEach(r),_l=c(X),T=n(X,"P",{});var R=o(T);ds=n(R,"A",{href:!0});var rg=o(ds);vl=a(rg,"~ConfigMixin"),rg.forEach(r),bl=a(R," takes care of storing all config attributes that are passed in the scheduler\u2019s "),An=n(R,"CODE",{});var sg=o(An);Sl=a(sg,"__init__"),sg.forEach(r),$l=a(R,`
function, such as `),In=n(R,"CODE",{});var ng=o(In);Dl=a(ng,"num_train_timesteps"),ng.forEach(r),El=a(R,". They can be accessed via "),Fn=n(R,"CODE",{});var og=o(Fn);xl=a(og,"scheduler.config.num_train_timesteps"),og.forEach(r),yl=a(R,`.
`),ls=n(R,"A",{href:!0});var ig=o(ls);wl=a(ig,"~ConfigMixin"),ig.forEach(r),Ml=a(R," also provides general loading and saving functionality via the "),cs=n(R,"A",{href:!0});var ag=o(cs);Pl=a(ag,"save_config()"),ag.forEach(r),Tl=a(R,` and
`),us=n(R,"A",{href:!0});var dg=o(us);Ol=a(dg,"from_config()"),dg.forEach(r),kl=a(R," functions."),R.forEach(r),Vl=c(X),fs=n(X,"P",{});var Qh=o(fs);Cl=a(Qh,"For more details, see the original paper: "),Wt=n(Qh,"A",{href:!0,rel:!0});var lg=o(Wt);Nl=a(lg,"https://arxiv.org/abs/2010.02502"),lg.forEach(r),Qh.forEach(r),Al=c(X),Ue=n(X,"DIV",{class:!0});var ma=o(Ue);h(Bt.$$.fragment,ma),Il=c(ma),Ln=n(ma,"P",{});var cg=o(Ln);Fl=a(cg,`Ensures interchangeability with schedulers that need to scale the denoising model input depending on the
current timestep.`),cg.forEach(r),ma.forEach(r),Ll=c(X),He=n(X,"DIV",{class:!0});var ga=o(He);h(Gt.$$.fragment,ga),Kl=c(ga),Kn=n(ga,"P",{});var ug=o(Kn);ql=a(ug,"Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference."),ug.forEach(r),ga.forEach(r),Ul=c(X),Re=n(X,"DIV",{class:!0});var _a=o(Re);h(Yt.$$.fragment,_a),Hl=c(_a),qn=n(_a,"P",{});var fg=o(qn);Rl=a(fg,`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),fg.forEach(r),_a.forEach(r),X.forEach(r),Ti=c(t),Se=n(t,"H4",{class:!0});var va=o(Se);We=n(va,"A",{id:!0,class:!0,href:!0});var pg=o(We);Un=n(pg,"SPAN",{});var hg=o(Un);h(zt.$$.fragment,hg),hg.forEach(r),pg.forEach(r),Wl=c(va),Hn=n(va,"SPAN",{});var mg=o(Hn);Bl=a(mg,"Denoising diffusion probabilistic models (DDPM)"),mg.forEach(r),va.forEach(r),Oi=c(t),Be=n(t,"P",{});var ba=o(Be);Gl=a(ba,"Original paper can be found "),Jt=n(ba,"A",{href:!0,rel:!0});var gg=o(Jt);Yl=a(gg,"here"),gg.forEach(r),zl=a(ba,"."),ba.forEach(r),ki=c(t),y=n(t,"DIV",{class:!0});var Z=o(y);h(jt.$$.fragment,Z),Jl=c(Z),Rn=n(Z,"P",{});var _g=o(Rn);jl=a(_g,`Denoising diffusion probabilistic models (DDPMs) explores the connections between denoising score matching and
Langevin dynamics sampling.`),_g.forEach(r),Ql=c(Z),O=n(Z,"P",{});var W=o(O);ps=n(W,"A",{href:!0});var vg=o(ps);Xl=a(vg,"~ConfigMixin"),vg.forEach(r),Zl=a(W," takes care of storing all config attributes that are passed in the scheduler\u2019s "),Wn=n(W,"CODE",{});var bg=o(Wn);ec=a(bg,"__init__"),bg.forEach(r),tc=a(W,`
function, such as `),Bn=n(W,"CODE",{});var Sg=o(Bn);rc=a(Sg,"num_train_timesteps"),Sg.forEach(r),sc=a(W,". They can be accessed via "),Gn=n(W,"CODE",{});var $g=o(Gn);nc=a($g,"scheduler.config.num_train_timesteps"),$g.forEach(r),oc=a(W,`.
`),hs=n(W,"A",{href:!0});var Dg=o(hs);ic=a(Dg,"~ConfigMixin"),Dg.forEach(r),ac=a(W," also provides general loading and saving functionality via the "),ms=n(W,"A",{href:!0});var Eg=o(ms);dc=a(Eg,"save_config()"),Eg.forEach(r),lc=a(W,` and
`),gs=n(W,"A",{href:!0});var xg=o(gs);cc=a(xg,"from_config()"),xg.forEach(r),uc=a(W," functions."),W.forEach(r),fc=c(Z),_s=n(Z,"P",{});var Xh=o(_s);pc=a(Xh,"For more details, see the original paper: "),Qt=n(Xh,"A",{href:!0,rel:!0});var yg=o(Qt);hc=a(yg,"https://arxiv.org/abs/2006.11239"),yg.forEach(r),Xh.forEach(r),mc=c(Z),Ge=n(Z,"DIV",{class:!0});var Sa=o(Ge);h(Xt.$$.fragment,Sa),gc=c(Sa),Yn=n(Sa,"P",{});var wg=o(Yn);_c=a(wg,`Ensures interchangeability with schedulers that need to scale the denoising model input depending on the
current timestep.`),wg.forEach(r),Sa.forEach(r),vc=c(Z),Ye=n(Z,"DIV",{class:!0});var $a=o(Ye);h(Zt.$$.fragment,$a),bc=c($a),zn=n($a,"P",{});var Mg=o(zn);Sc=a(Mg,"Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference."),Mg.forEach(r),$a.forEach(r),$c=c(Z),ze=n(Z,"DIV",{class:!0});var Da=o(ze);h(er.$$.fragment,Da),Dc=c(Da),Jn=n(Da,"P",{});var Pg=o(Jn);Ec=a(Pg,`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),Pg.forEach(r),Da.forEach(r),Z.forEach(r),Vi=c(t),$e=n(t,"H4",{class:!0});var Ea=o($e);Je=n(Ea,"A",{id:!0,class:!0,href:!0});var Tg=o(Je);jn=n(Tg,"SPAN",{});var Og=o(jn);h(tr.$$.fragment,Og),Og.forEach(r),Tg.forEach(r),xc=c(Ea),Qn=n(Ea,"SPAN",{});var kg=o(Qn);yc=a(kg,"Variance exploding, stochastic sampling from Karras et. al"),kg.forEach(r),Ea.forEach(r),Ci=c(t),je=n(t,"P",{});var xa=o(je);wc=a(xa,"Original paper can be found "),rr=n(xa,"A",{href:!0,rel:!0});var Vg=o(rr);Mc=a(Vg,"here"),Vg.forEach(r),Pc=a(xa,"."),xa.forEach(r),Ni=c(t),S=n(t,"DIV",{class:!0});var E=o(S);h(sr.$$.fragment,E),Tc=c(E),Xn=n(E,"P",{});var Cg=o(Xn);Oc=a(Cg,`Stochastic sampling from Karras et al. [1] tailored to the Variance-Expanding (VE) models [2]. Use Algorithm 2 and
the VE column of Table 1 from [1] for reference.`),Cg.forEach(r),kc=c(E),Qe=n(E,"P",{});var ii=o(Qe);Vc=a(ii,`[1] Karras, Tero, et al. \u201CElucidating the Design Space of Diffusion-Based Generative Models.\u201D
`),nr=n(ii,"A",{href:!0,rel:!0});var Ng=o(nr);Cc=a(Ng,"https://arxiv.org/abs/2206.00364"),Ng.forEach(r),Nc=a(ii,` [2] Song, Yang, et al. \u201CScore-based generative modeling through stochastic
differential equations.\u201D `),or=n(ii,"A",{href:!0,rel:!0});var Ag=o(or);Ac=a(Ag,"https://arxiv.org/abs/2011.13456"),Ag.forEach(r),ii.forEach(r),Ic=c(E),k=n(E,"P",{});var B=o(k);vs=n(B,"A",{href:!0});var Ig=o(vs);Fc=a(Ig,"~ConfigMixin"),Ig.forEach(r),Lc=a(B," takes care of storing all config attributes that are passed in the scheduler\u2019s "),Zn=n(B,"CODE",{});var Fg=o(Zn);Kc=a(Fg,"__init__"),Fg.forEach(r),qc=a(B,`
function, such as `),eo=n(B,"CODE",{});var Lg=o(eo);Uc=a(Lg,"num_train_timesteps"),Lg.forEach(r),Hc=a(B,". They can be accessed via "),to=n(B,"CODE",{});var Kg=o(to);Rc=a(Kg,"scheduler.config.num_train_timesteps"),Kg.forEach(r),Wc=a(B,`.
`),bs=n(B,"A",{href:!0});var qg=o(bs);Bc=a(qg,"~ConfigMixin"),qg.forEach(r),Gc=a(B," also provides general loading and saving functionality via the "),Ss=n(B,"A",{href:!0});var Ug=o(Ss);Yc=a(Ug,"save_config()"),Ug.forEach(r),zc=a(B,` and
`),$s=n(B,"A",{href:!0});var Hg=o($s);Jc=a(Hg,"from_config()"),Hg.forEach(r),jc=a(B," functions."),B.forEach(r),Qc=c(E),ir=n(E,"P",{});var ya=o(ir);Xc=a(ya,`For more details on the parameters, see the original paper\u2019s Appendix E.: \u201CElucidating the Design Space of
Diffusion-Based Generative Models.\u201D `),ar=n(ya,"A",{href:!0,rel:!0});var Rg=o(ar);Zc=a(Rg,"https://arxiv.org/abs/2206.00364"),Rg.forEach(r),eu=a(ya,`. The grid search values used to find the
optimal {s_noise, s_churn, s_min, s_max} for a specific model are described in Table 5 of the paper.`),ya.forEach(r),tu=c(E),oe=n(E,"DIV",{class:!0});var js=o(oe);h(dr.$$.fragment,js),ru=c(js),ro=n(js,"P",{});var Wg=o(ro);su=a(Wg,`Explicit Langevin-like \u201Cchurn\u201D step of adding noise to the sample according to a factor gamma_i \u2265 0 to reach a
higher noise level sigma_hat = sigma_i + gamma_i*sigma_i.`),Wg.forEach(r),nu=c(js),so=n(js,"P",{});var Bg=o(so);ou=a(Bg,"TODO Args:"),Bg.forEach(r),js.forEach(r),iu=c(E),Xe=n(E,"DIV",{class:!0});var wa=o(Xe);h(lr.$$.fragment,wa),au=c(wa),no=n(wa,"P",{});var Gg=o(no);du=a(Gg,`Ensures interchangeability with schedulers that need to scale the denoising model input depending on the
current timestep.`),Gg.forEach(r),wa.forEach(r),lu=c(E),Ze=n(E,"DIV",{class:!0});var Ma=o(Ze);h(cr.$$.fragment,Ma),cu=c(Ma),oo=n(Ma,"P",{});var Yg=o(oo);uu=a(Yg,"Sets the continuous timesteps used for the diffusion chain. Supporting function to be run before inference."),Yg.forEach(r),Ma.forEach(r),fu=c(E),et=n(E,"DIV",{class:!0});var Pa=o(et);h(ur.$$.fragment,Pa),pu=c(Pa),io=n(Pa,"P",{});var zg=o(io);hu=a(zg,`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),zg.forEach(r),Pa.forEach(r),mu=c(E),tt=n(E,"DIV",{class:!0});var Ta=o(tt);h(fr.$$.fragment,Ta),gu=c(Ta),ao=n(Ta,"P",{});var Jg=o(ao);_u=a(Jg,"Correct the predicted sample based on the output model_output of the network. TODO complete description"),Jg.forEach(r),Ta.forEach(r),E.forEach(r),Ai=c(t),De=n(t,"H4",{class:!0});var Oa=o(De);rt=n(Oa,"A",{id:!0,class:!0,href:!0});var jg=o(rt);lo=n(jg,"SPAN",{});var Qg=o(lo);h(pr.$$.fragment,Qg),Qg.forEach(r),jg.forEach(r),vu=c(Oa),co=n(Oa,"SPAN",{});var Xg=o(co);bu=a(Xg,"Linear multistep scheduler for discrete beta schedules"),Xg.forEach(r),Oa.forEach(r),Ii=c(t),st=n(t,"P",{});var ka=o(st);Su=a(ka,"Original implementation can be found "),hr=n(ka,"A",{href:!0,rel:!0});var Zg=o(hr);$u=a(Zg,"here"),Zg.forEach(r),Du=a(ka,"."),ka.forEach(r),Fi=c(t),w=n(t,"DIV",{class:!0});var ee=o(w);h(mr.$$.fragment,ee),Eu=c(ee),Ds=n(ee,"P",{});var Zh=o(Ds);xu=a(Zh,`Linear Multistep Scheduler for discrete beta schedules. Based on the original k-diffusion implementation by
Katherine Crowson:
`),gr=n(Zh,"A",{href:!0,rel:!0});var e_=o(gr);yu=a(e_,"https://github.com/crowsonkb/k-diffusion/blob/481677d114f6ea445aa009cf5bd7a9cdee909e47/k_diffusion/sampling.py#L181"),e_.forEach(r),Zh.forEach(r),wu=c(ee),V=n(ee,"P",{});var G=o(V);Es=n(G,"A",{href:!0});var t_=o(Es);Mu=a(t_,"~ConfigMixin"),t_.forEach(r),Pu=a(G," takes care of storing all config attributes that are passed in the scheduler\u2019s "),uo=n(G,"CODE",{});var r_=o(uo);Tu=a(r_,"__init__"),r_.forEach(r),Ou=a(G,`
function, such as `),fo=n(G,"CODE",{});var s_=o(fo);ku=a(s_,"num_train_timesteps"),s_.forEach(r),Vu=a(G,". They can be accessed via "),po=n(G,"CODE",{});var n_=o(po);Cu=a(n_,"scheduler.config.num_train_timesteps"),n_.forEach(r),Nu=a(G,`.
`),xs=n(G,"A",{href:!0});var o_=o(xs);Au=a(o_,"~ConfigMixin"),o_.forEach(r),Iu=a(G," also provides general loading and saving functionality via the "),ys=n(G,"A",{href:!0});var i_=o(ys);Fu=a(i_,"save_config()"),i_.forEach(r),Lu=a(G,` and
`),ws=n(G,"A",{href:!0});var a_=o(ws);Ku=a(a_,"from_config()"),a_.forEach(r),qu=a(G," functions."),G.forEach(r),Uu=c(ee),nt=n(ee,"DIV",{class:!0});var Va=o(nt);h(_r.$$.fragment,Va),Hu=c(Va),ho=n(Va,"P",{});var d_=o(ho);Ru=a(d_,"Compute a linear multistep coefficient."),d_.forEach(r),Va.forEach(r),Wu=c(ee),ot=n(ee,"DIV",{class:!0});var Ca=o(ot);h(vr.$$.fragment,Ca),Bu=c(Ca),br=n(Ca,"P",{});var Na=o(br);Gu=a(Na,"Scales the denoising model input by "),mo=n(Na,"CODE",{});var l_=o(mo);Yu=a(l_,"(sigma**2 + 1) ** 0.5"),l_.forEach(r),zu=a(Na," to match the K-LMS algorithm."),Na.forEach(r),Ca.forEach(r),Ju=c(ee),it=n(ee,"DIV",{class:!0});var Aa=o(it);h(Sr.$$.fragment,Aa),ju=c(Aa),go=n(Aa,"P",{});var c_=o(go);Qu=a(c_,"Sets the timesteps used for the diffusion chain. Supporting function to be run before inference."),c_.forEach(r),Aa.forEach(r),Xu=c(ee),at=n(ee,"DIV",{class:!0});var Ia=o(at);h($r.$$.fragment,Ia),Zu=c(Ia),_o=n(Ia,"P",{});var u_=o(_o);ef=a(u_,`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),u_.forEach(r),Ia.forEach(r),ee.forEach(r),Li=c(t),Ee=n(t,"H4",{class:!0});var Fa=o(Ee);dt=n(Fa,"A",{id:!0,class:!0,href:!0});var f_=o(dt);vo=n(f_,"SPAN",{});var p_=o(vo);h(Dr.$$.fragment,p_),p_.forEach(r),f_.forEach(r),tf=c(Fa),bo=n(Fa,"SPAN",{});var h_=o(bo);rf=a(h_,"Pseudo numerical methods for diffusion models (PNDM)"),h_.forEach(r),Fa.forEach(r),Ki=c(t),lt=n(t,"P",{});var La=o(lt);sf=a(La,"Original implementation can be found "),Er=n(La,"A",{href:!0,rel:!0});var m_=o(Er);nf=a(m_,"here"),m_.forEach(r),of=a(La,"."),La.forEach(r),qi=c(t),$=n(t,"DIV",{class:!0});var F=o($);h(xr.$$.fragment,F),af=c(F),So=n(F,"P",{});var g_=o(So);df=a(g_,`Pseudo numerical methods for diffusion models (PNDM) proposes using more advanced ODE integration techniques,
namely Runge-Kutta method and a linear multi-step method.`),g_.forEach(r),lf=c(F),C=n(F,"P",{});var Y=o(C);Ms=n(Y,"A",{href:!0});var __=o(Ms);cf=a(__,"~ConfigMixin"),__.forEach(r),uf=a(Y," takes care of storing all config attributes that are passed in the scheduler\u2019s "),$o=n(Y,"CODE",{});var v_=o($o);ff=a(v_,"__init__"),v_.forEach(r),pf=a(Y,`
function, such as `),Do=n(Y,"CODE",{});var b_=o(Do);hf=a(b_,"num_train_timesteps"),b_.forEach(r),mf=a(Y,". They can be accessed via "),Eo=n(Y,"CODE",{});var S_=o(Eo);gf=a(S_,"scheduler.config.num_train_timesteps"),S_.forEach(r),_f=a(Y,`.
`),Ps=n(Y,"A",{href:!0});var $_=o(Ps);vf=a($_,"~ConfigMixin"),$_.forEach(r),bf=a(Y," also provides general loading and saving functionality via the "),Ts=n(Y,"A",{href:!0});var D_=o(Ts);Sf=a(D_,"save_config()"),D_.forEach(r),$f=a(Y,` and
`),Os=n(Y,"A",{href:!0});var E_=o(Os);Df=a(E_,"from_config()"),E_.forEach(r),Ef=a(Y," functions."),Y.forEach(r),xf=c(F),ks=n(F,"P",{});var em=o(ks);yf=a(em,"For more details, see the original paper: "),yr=n(em,"A",{href:!0,rel:!0});var x_=o(yr);wf=a(x_,"https://arxiv.org/abs/2202.09778"),x_.forEach(r),em.forEach(r),Mf=c(F),ct=n(F,"DIV",{class:!0});var Ka=o(ct);h(wr.$$.fragment,Ka),Pf=c(Ka),xo=n(Ka,"P",{});var y_=o(xo);Tf=a(y_,`Ensures interchangeability with schedulers that need to scale the denoising model input depending on the
current timestep.`),y_.forEach(r),Ka.forEach(r),Of=c(F),ut=n(F,"DIV",{class:!0});var qa=o(ut);h(Mr.$$.fragment,qa),kf=c(qa),yo=n(qa,"P",{});var w_=o(yo);Vf=a(w_,"Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference."),w_.forEach(r),qa.forEach(r),Cf=c(F),ie=n(F,"DIV",{class:!0});var Qs=o(ie);h(Pr.$$.fragment,Qs),Nf=c(Qs),wo=n(Qs,"P",{});var M_=o(wo);Af=a(M_,`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),M_.forEach(r),If=c(Qs),se=n(Qs,"P",{});var Pt=o(se);Ff=a(Pt,"This function calls "),Mo=n(Pt,"CODE",{});var P_=o(Mo);Lf=a(P_,"step_prk()"),P_.forEach(r),Kf=a(Pt," or "),Po=n(Pt,"CODE",{});var T_=o(Po);qf=a(T_,"step_plms()"),T_.forEach(r),Uf=a(Pt," depending on the internal variable "),To=n(Pt,"CODE",{});var O_=o(To);Hf=a(O_,"counter"),O_.forEach(r),Rf=a(Pt,"."),Pt.forEach(r),Qs.forEach(r),Wf=c(F),ft=n(F,"DIV",{class:!0});var Ua=o(ft);h(Tr.$$.fragment,Ua),Bf=c(Ua),Oo=n(Ua,"P",{});var k_=o(Oo);Gf=a(k_,`Step function propagating the sample with the linear multi-step method. This has one forward pass with multiple
times to approximate the solution.`),k_.forEach(r),Ua.forEach(r),Yf=c(F),pt=n(F,"DIV",{class:!0});var Ha=o(pt);h(Or.$$.fragment,Ha),zf=c(Ha),ko=n(Ha,"P",{});var V_=o(ko);Jf=a(V_,`Step function propagating the sample with the Runge-Kutta method. RK takes 4 forward passes to approximate the
solution to the differential equation.`),V_.forEach(r),Ha.forEach(r),F.forEach(r),Ui=c(t),xe=n(t,"H4",{class:!0});var Ra=o(xe);ht=n(Ra,"A",{id:!0,class:!0,href:!0});var C_=o(ht);Vo=n(C_,"SPAN",{});var N_=o(Vo);h(kr.$$.fragment,N_),N_.forEach(r),C_.forEach(r),jf=c(Ra),Co=n(Ra,"SPAN",{});var A_=o(Co);Qf=a(A_,"variance exploding stochastic differential equation (VE-SDE) scheduler"),A_.forEach(r),Ra.forEach(r),Hi=c(t),mt=n(t,"P",{});var Wa=o(mt);Xf=a(Wa,"Original paper can be found "),Vr=n(Wa,"A",{href:!0,rel:!0});var I_=o(Vr);Zf=a(I_,"here"),I_.forEach(r),ep=a(Wa,"."),Wa.forEach(r),Ri=c(t),D=n(t,"DIV",{class:!0});var L=o(D);h(Cr.$$.fragment,L),tp=c(L),No=n(L,"P",{});var F_=o(No);rp=a(F_,"The variance exploding stochastic differential equation (SDE) scheduler."),F_.forEach(r),sp=c(L),Vs=n(L,"P",{});var tm=o(Vs);np=a(tm,"For more information, see the original paper: "),Nr=n(tm,"A",{href:!0,rel:!0});var L_=o(Nr);op=a(L_,"https://arxiv.org/abs/2011.13456"),L_.forEach(r),tm.forEach(r),ip=c(L),N=n(L,"P",{});var z=o(N);Cs=n(z,"A",{href:!0});var K_=o(Cs);ap=a(K_,"~ConfigMixin"),K_.forEach(r),dp=a(z," takes care of storing all config attributes that are passed in the scheduler\u2019s "),Ao=n(z,"CODE",{});var q_=o(Ao);lp=a(q_,"__init__"),q_.forEach(r),cp=a(z,`
function, such as `),Io=n(z,"CODE",{});var U_=o(Io);up=a(U_,"num_train_timesteps"),U_.forEach(r),fp=a(z,". They can be accessed via "),Fo=n(z,"CODE",{});var H_=o(Fo);pp=a(H_,"scheduler.config.num_train_timesteps"),H_.forEach(r),hp=a(z,`.
`),Ns=n(z,"A",{href:!0});var R_=o(Ns);mp=a(R_,"~ConfigMixin"),R_.forEach(r),gp=a(z," also provides general loading and saving functionality via the "),As=n(z,"A",{href:!0});var W_=o(As);_p=a(W_,"save_config()"),W_.forEach(r),vp=a(z,` and
`),Is=n(z,"A",{href:!0});var B_=o(Is);bp=a(B_,"from_config()"),B_.forEach(r),Sp=a(z," functions."),z.forEach(r),$p=c(L),gt=n(L,"DIV",{class:!0});var Ba=o(gt);h(Ar.$$.fragment,Ba),Dp=c(Ba),Lo=n(Ba,"P",{});var G_=o(Lo);Ep=a(G_,`Ensures interchangeability with schedulers that need to scale the denoising model input depending on the
current timestep.`),G_.forEach(r),Ba.forEach(r),xp=c(L),ae=n(L,"DIV",{class:!0});var Xs=o(ae);h(Ir.$$.fragment,Xs),yp=c(Xs),Ko=n(Xs,"P",{});var Y_=o(Ko);wp=a(Y_,"Sets the noise scales used for the diffusion chain. Supporting function to be run before inference."),Y_.forEach(r),Mp=c(Xs),ye=n(Xs,"P",{});var Zs=o(ye);Pp=a(Zs,"The sigmas control the weight of the "),qo=n(Zs,"CODE",{});var z_=o(qo);Tp=a(z_,"drift"),z_.forEach(r),Op=a(Zs," and "),Uo=n(Zs,"CODE",{});var J_=o(Uo);kp=a(J_,"diffusion"),J_.forEach(r),Vp=a(Zs," components of sample update."),Zs.forEach(r),Xs.forEach(r),Cp=c(L),_t=n(L,"DIV",{class:!0});var Ga=o(_t);h(Fr.$$.fragment,Ga),Np=c(Ga),Ho=n(Ga,"P",{});var j_=o(Ho);Ap=a(j_,"Sets the continuous timesteps used for the diffusion chain. Supporting function to be run before inference."),j_.forEach(r),Ga.forEach(r),Ip=c(L),vt=n(L,"DIV",{class:!0});var Ya=o(vt);h(Lr.$$.fragment,Ya),Fp=c(Ya),Ro=n(Ya,"P",{});var Q_=o(Ro);Lp=a(Q_,`Correct the predicted sample based on the output model_output of the network. This is often run repeatedly
after making the prediction for the previous timestep.`),Q_.forEach(r),Ya.forEach(r),Kp=c(L),bt=n(L,"DIV",{class:!0});var za=o(bt);h(Kr.$$.fragment,za),qp=c(za),Wo=n(za,"P",{});var X_=o(Wo);Up=a(X_,`Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion
process from the learned model outputs (most often the predicted noise).`),X_.forEach(r),za.forEach(r),L.forEach(r),Wi=c(t),we=n(t,"H4",{class:!0});var Ja=o(we);St=n(Ja,"A",{id:!0,class:!0,href:!0});var Z_=o(St);Bo=n(Z_,"SPAN",{});var ev=o(Bo);h(qr.$$.fragment,ev),ev.forEach(r),Z_.forEach(r),Hp=c(Ja),Go=n(Ja,"SPAN",{});var tv=o(Go);Rp=a(tv,"improved pseudo numerical methods for diffusion models (iPNDM)"),tv.forEach(r),Ja.forEach(r),Bi=c(t),$t=n(t,"P",{});var ja=o($t);Wp=a(ja,"Original implementation can be found "),Ur=n(ja,"A",{href:!0,rel:!0});var rv=o(Ur);Bp=a(rv,"here"),rv.forEach(r),Gp=a(ja,"."),ja.forEach(r),Gi=c(t),M=n(t,"DIV",{class:!0});var te=o(M);h(Hr.$$.fragment,te),Yp=c(te),Fs=n(te,"P",{});var rm=o(Fs);zp=a(rm,`Improved Pseudo numerical methods for diffusion models (iPNDM) ported from @crowsonkb\u2019s amazing k-diffusion
`),Rr=n(rm,"A",{href:!0,rel:!0});var sv=o(Rr);Jp=a(sv,"library"),sv.forEach(r),rm.forEach(r),jp=c(te),A=n(te,"P",{});var J=o(A);Ls=n(J,"A",{href:!0});var nv=o(Ls);Qp=a(nv,"~ConfigMixin"),nv.forEach(r),Xp=a(J," takes care of storing all config attributes that are passed in the scheduler\u2019s "),Yo=n(J,"CODE",{});var ov=o(Yo);Zp=a(ov,"__init__"),ov.forEach(r),eh=a(J,`
function, such as `),zo=n(J,"CODE",{});var iv=o(zo);th=a(iv,"num_train_timesteps"),iv.forEach(r),rh=a(J,". They can be accessed via "),Jo=n(J,"CODE",{});var av=o(Jo);sh=a(av,"scheduler.config.num_train_timesteps"),av.forEach(r),nh=a(J,`.
`),Ks=n(J,"A",{href:!0});var dv=o(Ks);oh=a(dv,"~ConfigMixin"),dv.forEach(r),ih=a(J," also provides general loading and saving functionality via the "),qs=n(J,"A",{href:!0});var lv=o(qs);ah=a(lv,"save_config()"),lv.forEach(r),dh=a(J,` and
`),Us=n(J,"A",{href:!0});var cv=o(Us);lh=a(cv,"from_config()"),cv.forEach(r),ch=a(J," functions."),J.forEach(r),uh=c(te),Hs=n(te,"P",{});var sm=o(Hs);fh=a(sm,"For more details, see the original paper: "),Wr=n(sm,"A",{href:!0,rel:!0});var uv=o(Wr);ph=a(uv,"https://arxiv.org/abs/2202.09778"),uv.forEach(r),sm.forEach(r),hh=c(te),Dt=n(te,"DIV",{class:!0});var Qa=o(Dt);h(Br.$$.fragment,Qa),mh=c(Qa),jo=n(Qa,"P",{});var fv=o(jo);gh=a(fv,`Ensures interchangeability with schedulers that need to scale the denoising model input depending on the
current timestep.`),fv.forEach(r),Qa.forEach(r),_h=c(te),Et=n(te,"DIV",{class:!0});var Xa=o(Et);h(Gr.$$.fragment,Xa),vh=c(Xa),Qo=n(Xa,"P",{});var pv=o(Qo);bh=a(pv,"Sets the discrete timesteps used for the diffusion chain. Supporting function to be run before inference."),pv.forEach(r),Xa.forEach(r),Sh=c(te),xt=n(te,"DIV",{class:!0});var Za=o(xt);h(Yr.$$.fragment,Za),$h=c(Za),Xo=n(Za,"P",{});var hv=o(Xo);Dh=a(hv,`Step function propagating the sample with the linear multi-step method. This has one forward pass with multiple
times to approximate the solution.`),hv.forEach(r),Za.forEach(r),te.forEach(r),Yi=c(t),Me=n(t,"H4",{class:!0});var ed=o(Me);yt=n(ed,"A",{id:!0,class:!0,href:!0});var mv=o(yt);Zo=n(mv,"SPAN",{});var gv=o(Zo);h(zr.$$.fragment,gv),gv.forEach(r),mv.forEach(r),Eh=c(ed),ei=n(ed,"SPAN",{});var _v=o(ei);xh=a(_v,"variance preserving stochastic differential equation (VP-SDE) scheduler"),_v.forEach(r),ed.forEach(r),zi=c(t),wt=n(t,"P",{});var td=o(wt);yh=a(td,"Original paper can be found "),Jr=n(td,"A",{href:!0,rel:!0});var vv=o(Jr);wh=a(vv,"here"),vv.forEach(r),Mh=a(td,"."),td.forEach(r),Ji=c(t),h(Mt.$$.fragment,t),ji=c(t),H=n(t,"DIV",{class:!0});var de=o(H);h(jr.$$.fragment,de),Ph=c(de),ti=n(de,"P",{});var bv=o(ti);Th=a(bv,"The variance preserving stochastic differential equation (SDE) scheduler."),bv.forEach(r),Oh=c(de),I=n(de,"P",{});var j=o(I);Rs=n(j,"A",{href:!0});var Sv=o(Rs);kh=a(Sv,"~ConfigMixin"),Sv.forEach(r),Vh=a(j," takes care of storing all config attributes that are passed in the scheduler\u2019s "),ri=n(j,"CODE",{});var $v=o(ri);Ch=a($v,"__init__"),$v.forEach(r),Nh=a(j,`
function, such as `),si=n(j,"CODE",{});var Dv=o(si);Ah=a(Dv,"num_train_timesteps"),Dv.forEach(r),Ih=a(j,". They can be accessed via "),ni=n(j,"CODE",{});var Ev=o(ni);Fh=a(Ev,"scheduler.config.num_train_timesteps"),Ev.forEach(r),Lh=a(j,`.
`),Ws=n(j,"A",{href:!0});var xv=o(Ws);Kh=a(xv,"~ConfigMixin"),xv.forEach(r),qh=a(j," also provides general loading and saving functionality via the "),Bs=n(j,"A",{href:!0});var yv=o(Bs);Uh=a(yv,"save_config()"),yv.forEach(r),Hh=a(j,` and
`),Gs=n(j,"A",{href:!0});var wv=o(Gs);Rh=a(wv,"from_config()"),wv.forEach(r),Wh=a(j," functions."),j.forEach(r),Bh=c(de),Ys=n(de,"P",{});var nm=o(Ys);Gh=a(nm,"For more information, see the original paper: "),Qr=n(nm,"A",{href:!0,rel:!0});var Mv=o(Qr);Yh=a(Mv,"https://arxiv.org/abs/2011.13456"),Mv.forEach(r),nm.forEach(r),zh=c(de),oi=n(de,"P",{});var Pv=o(oi);Jh=a(Pv,"UNDER CONSTRUCTION"),Pv.forEach(r),de.forEach(r),this.h()},h(){d(K,"name","hf:doc:metadata"),d(K,"content",JSON.stringify(Fv)),d(re,"id","schedulers"),d(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(re,"href","#schedulers"),d(U,"class","relative group"),d(Te,"id","what-is-a-scheduler"),d(Te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Te,"href","#what-is-a-scheduler"),d(le,"class","relative group"),d(Ve,"id","discrete-versus-continuous-schedulers"),d(Ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ve,"href","#discrete-versus-continuous-schedulers"),d(ue,"class","relative group"),d(ts,"href","/docs/diffusers/main/en/api/schedulers#diffusers.DDPMScheduler"),d(rs,"href","/docs/diffusers/main/en/api/schedulers#diffusers.PNDMScheduler"),d(ss,"href","/docs/diffusers/main/en/api/schedulers#diffusers.ScoreSdeVeScheduler"),d(Ce,"id","designing-reusable-schedulers"),d(Ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ce,"href","#designing-reusable-schedulers"),d(fe,"class","relative group"),d(Ae,"id","api"),d(Ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ae,"href","#api"),d(pe,"class","relative group"),d(is,"href","/docs/diffusers/main/en/api/schedulers#diffusers.SchedulerMixin"),d(Fe,"id","diffusers.SchedulerMixin"),d(Fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Fe,"href","#diffusers.SchedulerMixin"),d(he,"class","relative group"),d(me,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Le,"id","diffusers.schedulers.scheduling_utils.SchedulerOutput"),d(Le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Le,"href","#diffusers.schedulers.scheduling_utils.SchedulerOutput"),d(ge,"class","relative group"),d(_e,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ke,"id","implemented-schedulers"),d(Ke,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ke,"href","#implemented-schedulers"),d(ve,"class","relative group"),d(qe,"id","diffusers.DDIMScheduler"),d(qe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(qe,"href","#diffusers.DDIMScheduler"),d(be,"class","relative group"),d(ds,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin"),d(ls,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin"),d(cs,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin.save_config"),d(us,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin.from_config"),d(Wt,"href","https://arxiv.org/abs/2010.02502"),d(Wt,"rel","nofollow"),d(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Re,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(x,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(We,"id","diffusers.DDPMScheduler"),d(We,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(We,"href","#diffusers.DDPMScheduler"),d(Se,"class","relative group"),d(Jt,"href","https://arxiv.org/abs/2010.02502"),d(Jt,"rel","nofollow"),d(ps,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin"),d(hs,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin"),d(ms,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin.save_config"),d(gs,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin.from_config"),d(Qt,"href","https://arxiv.org/abs/2006.11239"),d(Qt,"rel","nofollow"),d(Ge,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Je,"id","diffusers.KarrasVeScheduler"),d(Je,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Je,"href","#diffusers.KarrasVeScheduler"),d($e,"class","relative group"),d(rr,"href","https://arxiv.org/abs/2006.11239"),d(rr,"rel","nofollow"),d(nr,"href","https://arxiv.org/abs/2206.00364"),d(nr,"rel","nofollow"),d(or,"href","https://arxiv.org/abs/2011.13456"),d(or,"rel","nofollow"),d(vs,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin"),d(bs,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin"),d(Ss,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin.save_config"),d($s,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin.from_config"),d(ar,"href","https://arxiv.org/abs/2206.00364"),d(ar,"rel","nofollow"),d(oe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Xe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(S,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(rt,"id","diffusers.LMSDiscreteScheduler"),d(rt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(rt,"href","#diffusers.LMSDiscreteScheduler"),d(De,"class","relative group"),d(hr,"href","https://arxiv.org/abs/2206.00364"),d(hr,"rel","nofollow"),d(gr,"href","https://github.com/crowsonkb/k-diffusion/blob/481677d114f6ea445aa009cf5bd7a9cdee909e47/k_diffusion/sampling.py#L181"),d(gr,"rel","nofollow"),d(Es,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin"),d(xs,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin"),d(ys,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin.save_config"),d(ws,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin.from_config"),d(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(w,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(dt,"id","diffusers.PNDMScheduler"),d(dt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(dt,"href","#diffusers.PNDMScheduler"),d(Ee,"class","relative group"),d(Er,"href","https://github.com/crowsonkb/k-diffusion/blob/481677d114f6ea445aa009cf5bd7a9cdee909e47/k_diffusion/sampling.py#L181"),d(Er,"rel","nofollow"),d(Ms,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin"),d(Ps,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin"),d(Ts,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin.save_config"),d(Os,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin.from_config"),d(yr,"href","https://arxiv.org/abs/2202.09778"),d(yr,"rel","nofollow"),d(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ie,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ht,"id","diffusers.ScoreSdeVeScheduler"),d(ht,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ht,"href","#diffusers.ScoreSdeVeScheduler"),d(xe,"class","relative group"),d(Vr,"href","https://arxiv.org/abs/2011.13456"),d(Vr,"rel","nofollow"),d(Nr,"href","https://arxiv.org/abs/2011.13456"),d(Nr,"rel","nofollow"),d(Cs,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin"),d(Ns,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin"),d(As,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin.save_config"),d(Is,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin.from_config"),d(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ae,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(D,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(St,"id","diffusers.IPNDMScheduler"),d(St,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(St,"href","#diffusers.IPNDMScheduler"),d(we,"class","relative group"),d(Ur,"href","https://github.com/crowsonkb/v-diffusion-pytorch/blob/987f8985e38208345c1959b0ea767a625831cc9b/diffusion/sampling.py#L296"),d(Ur,"rel","nofollow"),d(Rr,"href","https://github.com/crowsonkb/v-diffusion-pytorch/blob/987f8985e38208345c1959b0ea767a625831cc9b/diffusion/sampling.py#L296"),d(Rr,"rel","nofollow"),d(Ls,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin"),d(Ks,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin"),d(qs,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin.save_config"),d(Us,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin.from_config"),d(Wr,"href","https://arxiv.org/abs/2202.09778"),d(Wr,"rel","nofollow"),d(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(yt,"id","diffusers.schedulers.ScoreSdeVpScheduler"),d(yt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(yt,"href","#diffusers.schedulers.ScoreSdeVpScheduler"),d(Me,"class","relative group"),d(Jr,"href","https://arxiv.org/abs/2011.13456"),d(Jr,"rel","nofollow"),d(Rs,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin"),d(Ws,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin"),d(Bs,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin.save_config"),d(Gs,"href","/docs/diffusers/main/en/using-diffusers/configuration#diffusers.ConfigMixin.from_config"),d(Qr,"href","https://arxiv.org/abs/2011.13456"),d(Qr,"rel","nofollow"),d(H,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(t,u){e(document.head,K),f(t,Pe,u),f(t,U,u),e(U,re),e(re,en),m(Tt,en,null),e(U,rd),e(U,tn),e(tn,sd),f(t,di,u),f(t,Zr,u),e(Zr,nd),f(t,li,u),f(t,le,u),e(le,Te),e(Te,rn),m(Ot,rn,null),e(le,od),e(le,sn),e(sn,id),f(t,ci,u),f(t,Oe,u),e(Oe,ad),e(Oe,nn),e(nn,dd),e(Oe,ld),f(t,ui,u),f(t,ke,u),e(ke,es),e(es,cd),e(es,kt),e(kt,on),e(on,ud),e(kt,fd),e(kt,an),e(an,pd),e(ke,hd),e(ke,ce),e(ce,md),e(ce,dn),e(dn,gd),e(ce,_d),e(ce,ln),e(ln,vd),e(ce,bd),f(t,fi,u),f(t,ue,u),e(ue,Ve),e(Ve,cn),m(Vt,cn,null),e(ue,Sd),e(ue,un),e(un,$d),f(t,pi,u),f(t,P,u),e(P,Dd),e(P,fn),e(fn,Ed),e(P,xd),e(P,ts),e(ts,yd),e(P,wd),e(P,rs),e(rs,Md),e(P,Pd),e(P,pn),e(pn,Td),e(P,Od),e(P,ss),e(ss,kd),e(P,Vd),e(P,hn),e(hn,Cd),e(P,Nd),f(t,hi,u),f(t,fe,u),e(fe,Ce),e(Ce,mn),m(Ct,mn,null),e(fe,Ad),e(fe,gn),e(gn,Id),f(t,mi,u),f(t,ns,u),e(ns,Fd),f(t,gi,u),f(t,Ne,u),e(Ne,_n),e(_n,Ld),e(Ne,Kd),e(Ne,vn),e(vn,qd),f(t,_i,u),f(t,pe,u),e(pe,Ae),e(Ae,bn),m(Nt,bn,null),e(pe,Ud),e(pe,Sn),e(Sn,Hd),f(t,vi,u),f(t,os,u),e(os,Rd),f(t,bi,u),f(t,ne,u),e(ne,At),e(At,Wd),e(At,$n),e($n,Bd),e(At,Gd),e(ne,Yd),e(ne,It),e(It,zd),e(It,Dn),e(Dn,Jd),e(It,jd),e(ne,Qd),e(ne,En),e(En,Xd),f(t,Si,u),f(t,Ie,u),e(Ie,Zd),e(Ie,is),e(is,el),e(Ie,tl),f(t,$i,u),f(t,he,u),e(he,Fe),e(Fe,xn),m(Ft,xn,null),e(he,rl),e(he,yn),e(yn,sl),f(t,Di,u),f(t,me,u),m(Lt,me,null),e(me,nl),e(me,wn),e(wn,ol),f(t,Ei,u),f(t,ge,u),e(ge,Le),e(Le,Mn),m(Kt,Mn,null),e(ge,il),e(ge,Pn),e(Pn,al),f(t,xi,u),f(t,_e,u),m(qt,_e,null),e(_e,dl),e(_e,Tn),e(Tn,ll),f(t,yi,u),f(t,ve,u),e(ve,Ke),e(Ke,On),m(Ut,On,null),e(ve,cl),e(ve,kn),e(kn,ul),f(t,wi,u),f(t,be,u),e(be,qe),e(qe,Vn),m(Ht,Vn,null),e(be,fl),e(be,Cn),e(Cn,pl),f(t,Mi,u),f(t,as,u),e(as,hl),f(t,Pi,u),f(t,x,u),m(Rt,x,null),e(x,ml),e(x,Nn),e(Nn,gl),e(x,_l),e(x,T),e(T,ds),e(ds,vl),e(T,bl),e(T,An),e(An,Sl),e(T,$l),e(T,In),e(In,Dl),e(T,El),e(T,Fn),e(Fn,xl),e(T,yl),e(T,ls),e(ls,wl),e(T,Ml),e(T,cs),e(cs,Pl),e(T,Tl),e(T,us),e(us,Ol),e(T,kl),e(x,Vl),e(x,fs),e(fs,Cl),e(fs,Wt),e(Wt,Nl),e(x,Al),e(x,Ue),m(Bt,Ue,null),e(Ue,Il),e(Ue,Ln),e(Ln,Fl),e(x,Ll),e(x,He),m(Gt,He,null),e(He,Kl),e(He,Kn),e(Kn,ql),e(x,Ul),e(x,Re),m(Yt,Re,null),e(Re,Hl),e(Re,qn),e(qn,Rl),f(t,Ti,u),f(t,Se,u),e(Se,We),e(We,Un),m(zt,Un,null),e(Se,Wl),e(Se,Hn),e(Hn,Bl),f(t,Oi,u),f(t,Be,u),e(Be,Gl),e(Be,Jt),e(Jt,Yl),e(Be,zl),f(t,ki,u),f(t,y,u),m(jt,y,null),e(y,Jl),e(y,Rn),e(Rn,jl),e(y,Ql),e(y,O),e(O,ps),e(ps,Xl),e(O,Zl),e(O,Wn),e(Wn,ec),e(O,tc),e(O,Bn),e(Bn,rc),e(O,sc),e(O,Gn),e(Gn,nc),e(O,oc),e(O,hs),e(hs,ic),e(O,ac),e(O,ms),e(ms,dc),e(O,lc),e(O,gs),e(gs,cc),e(O,uc),e(y,fc),e(y,_s),e(_s,pc),e(_s,Qt),e(Qt,hc),e(y,mc),e(y,Ge),m(Xt,Ge,null),e(Ge,gc),e(Ge,Yn),e(Yn,_c),e(y,vc),e(y,Ye),m(Zt,Ye,null),e(Ye,bc),e(Ye,zn),e(zn,Sc),e(y,$c),e(y,ze),m(er,ze,null),e(ze,Dc),e(ze,Jn),e(Jn,Ec),f(t,Vi,u),f(t,$e,u),e($e,Je),e(Je,jn),m(tr,jn,null),e($e,xc),e($e,Qn),e(Qn,yc),f(t,Ci,u),f(t,je,u),e(je,wc),e(je,rr),e(rr,Mc),e(je,Pc),f(t,Ni,u),f(t,S,u),m(sr,S,null),e(S,Tc),e(S,Xn),e(Xn,Oc),e(S,kc),e(S,Qe),e(Qe,Vc),e(Qe,nr),e(nr,Cc),e(Qe,Nc),e(Qe,or),e(or,Ac),e(S,Ic),e(S,k),e(k,vs),e(vs,Fc),e(k,Lc),e(k,Zn),e(Zn,Kc),e(k,qc),e(k,eo),e(eo,Uc),e(k,Hc),e(k,to),e(to,Rc),e(k,Wc),e(k,bs),e(bs,Bc),e(k,Gc),e(k,Ss),e(Ss,Yc),e(k,zc),e(k,$s),e($s,Jc),e(k,jc),e(S,Qc),e(S,ir),e(ir,Xc),e(ir,ar),e(ar,Zc),e(ir,eu),e(S,tu),e(S,oe),m(dr,oe,null),e(oe,ru),e(oe,ro),e(ro,su),e(oe,nu),e(oe,so),e(so,ou),e(S,iu),e(S,Xe),m(lr,Xe,null),e(Xe,au),e(Xe,no),e(no,du),e(S,lu),e(S,Ze),m(cr,Ze,null),e(Ze,cu),e(Ze,oo),e(oo,uu),e(S,fu),e(S,et),m(ur,et,null),e(et,pu),e(et,io),e(io,hu),e(S,mu),e(S,tt),m(fr,tt,null),e(tt,gu),e(tt,ao),e(ao,_u),f(t,Ai,u),f(t,De,u),e(De,rt),e(rt,lo),m(pr,lo,null),e(De,vu),e(De,co),e(co,bu),f(t,Ii,u),f(t,st,u),e(st,Su),e(st,hr),e(hr,$u),e(st,Du),f(t,Fi,u),f(t,w,u),m(mr,w,null),e(w,Eu),e(w,Ds),e(Ds,xu),e(Ds,gr),e(gr,yu),e(w,wu),e(w,V),e(V,Es),e(Es,Mu),e(V,Pu),e(V,uo),e(uo,Tu),e(V,Ou),e(V,fo),e(fo,ku),e(V,Vu),e(V,po),e(po,Cu),e(V,Nu),e(V,xs),e(xs,Au),e(V,Iu),e(V,ys),e(ys,Fu),e(V,Lu),e(V,ws),e(ws,Ku),e(V,qu),e(w,Uu),e(w,nt),m(_r,nt,null),e(nt,Hu),e(nt,ho),e(ho,Ru),e(w,Wu),e(w,ot),m(vr,ot,null),e(ot,Bu),e(ot,br),e(br,Gu),e(br,mo),e(mo,Yu),e(br,zu),e(w,Ju),e(w,it),m(Sr,it,null),e(it,ju),e(it,go),e(go,Qu),e(w,Xu),e(w,at),m($r,at,null),e(at,Zu),e(at,_o),e(_o,ef),f(t,Li,u),f(t,Ee,u),e(Ee,dt),e(dt,vo),m(Dr,vo,null),e(Ee,tf),e(Ee,bo),e(bo,rf),f(t,Ki,u),f(t,lt,u),e(lt,sf),e(lt,Er),e(Er,nf),e(lt,of),f(t,qi,u),f(t,$,u),m(xr,$,null),e($,af),e($,So),e(So,df),e($,lf),e($,C),e(C,Ms),e(Ms,cf),e(C,uf),e(C,$o),e($o,ff),e(C,pf),e(C,Do),e(Do,hf),e(C,mf),e(C,Eo),e(Eo,gf),e(C,_f),e(C,Ps),e(Ps,vf),e(C,bf),e(C,Ts),e(Ts,Sf),e(C,$f),e(C,Os),e(Os,Df),e(C,Ef),e($,xf),e($,ks),e(ks,yf),e(ks,yr),e(yr,wf),e($,Mf),e($,ct),m(wr,ct,null),e(ct,Pf),e(ct,xo),e(xo,Tf),e($,Of),e($,ut),m(Mr,ut,null),e(ut,kf),e(ut,yo),e(yo,Vf),e($,Cf),e($,ie),m(Pr,ie,null),e(ie,Nf),e(ie,wo),e(wo,Af),e(ie,If),e(ie,se),e(se,Ff),e(se,Mo),e(Mo,Lf),e(se,Kf),e(se,Po),e(Po,qf),e(se,Uf),e(se,To),e(To,Hf),e(se,Rf),e($,Wf),e($,ft),m(Tr,ft,null),e(ft,Bf),e(ft,Oo),e(Oo,Gf),e($,Yf),e($,pt),m(Or,pt,null),e(pt,zf),e(pt,ko),e(ko,Jf),f(t,Ui,u),f(t,xe,u),e(xe,ht),e(ht,Vo),m(kr,Vo,null),e(xe,jf),e(xe,Co),e(Co,Qf),f(t,Hi,u),f(t,mt,u),e(mt,Xf),e(mt,Vr),e(Vr,Zf),e(mt,ep),f(t,Ri,u),f(t,D,u),m(Cr,D,null),e(D,tp),e(D,No),e(No,rp),e(D,sp),e(D,Vs),e(Vs,np),e(Vs,Nr),e(Nr,op),e(D,ip),e(D,N),e(N,Cs),e(Cs,ap),e(N,dp),e(N,Ao),e(Ao,lp),e(N,cp),e(N,Io),e(Io,up),e(N,fp),e(N,Fo),e(Fo,pp),e(N,hp),e(N,Ns),e(Ns,mp),e(N,gp),e(N,As),e(As,_p),e(N,vp),e(N,Is),e(Is,bp),e(N,Sp),e(D,$p),e(D,gt),m(Ar,gt,null),e(gt,Dp),e(gt,Lo),e(Lo,Ep),e(D,xp),e(D,ae),m(Ir,ae,null),e(ae,yp),e(ae,Ko),e(Ko,wp),e(ae,Mp),e(ae,ye),e(ye,Pp),e(ye,qo),e(qo,Tp),e(ye,Op),e(ye,Uo),e(Uo,kp),e(ye,Vp),e(D,Cp),e(D,_t),m(Fr,_t,null),e(_t,Np),e(_t,Ho),e(Ho,Ap),e(D,Ip),e(D,vt),m(Lr,vt,null),e(vt,Fp),e(vt,Ro),e(Ro,Lp),e(D,Kp),e(D,bt),m(Kr,bt,null),e(bt,qp),e(bt,Wo),e(Wo,Up),f(t,Wi,u),f(t,we,u),e(we,St),e(St,Bo),m(qr,Bo,null),e(we,Hp),e(we,Go),e(Go,Rp),f(t,Bi,u),f(t,$t,u),e($t,Wp),e($t,Ur),e(Ur,Bp),e($t,Gp),f(t,Gi,u),f(t,M,u),m(Hr,M,null),e(M,Yp),e(M,Fs),e(Fs,zp),e(Fs,Rr),e(Rr,Jp),e(M,jp),e(M,A),e(A,Ls),e(Ls,Qp),e(A,Xp),e(A,Yo),e(Yo,Zp),e(A,eh),e(A,zo),e(zo,th),e(A,rh),e(A,Jo),e(Jo,sh),e(A,nh),e(A,Ks),e(Ks,oh),e(A,ih),e(A,qs),e(qs,ah),e(A,dh),e(A,Us),e(Us,lh),e(A,ch),e(M,uh),e(M,Hs),e(Hs,fh),e(Hs,Wr),e(Wr,ph),e(M,hh),e(M,Dt),m(Br,Dt,null),e(Dt,mh),e(Dt,jo),e(jo,gh),e(M,_h),e(M,Et),m(Gr,Et,null),e(Et,vh),e(Et,Qo),e(Qo,bh),e(M,Sh),e(M,xt),m(Yr,xt,null),e(xt,$h),e(xt,Xo),e(Xo,Dh),f(t,Yi,u),f(t,Me,u),e(Me,yt),e(yt,Zo),m(zr,Zo,null),e(Me,Eh),e(Me,ei),e(ei,xh),f(t,zi,u),f(t,wt,u),e(wt,yh),e(wt,Jr),e(Jr,wh),e(wt,Mh),f(t,Ji,u),m(Mt,t,u),f(t,ji,u),f(t,H,u),m(jr,H,null),e(H,Ph),e(H,ti),e(ti,Th),e(H,Oh),e(H,I),e(I,Rs),e(Rs,kh),e(I,Vh),e(I,ri),e(ri,Ch),e(I,Nh),e(I,si),e(si,Ah),e(I,Ih),e(I,ni),e(ni,Fh),e(I,Lh),e(I,Ws),e(Ws,Kh),e(I,qh),e(I,Bs),e(Bs,Uh),e(I,Hh),e(I,Gs),e(Gs,Rh),e(I,Wh),e(H,Bh),e(H,Ys),e(Ys,Gh),e(Ys,Qr),e(Qr,Yh),e(H,zh),e(H,oi),e(oi,Jh),Qi=!0},p(t,[u]){const Xr={};u&2&&(Xr.$$scope={dirty:u,ctx:t}),Mt.$set(Xr)},i(t){Qi||(g(Tt.$$.fragment,t),g(Ot.$$.fragment,t),g(Vt.$$.fragment,t),g(Ct.$$.fragment,t),g(Nt.$$.fragment,t),g(Ft.$$.fragment,t),g(Lt.$$.fragment,t),g(Kt.$$.fragment,t),g(qt.$$.fragment,t),g(Ut.$$.fragment,t),g(Ht.$$.fragment,t),g(Rt.$$.fragment,t),g(Bt.$$.fragment,t),g(Gt.$$.fragment,t),g(Yt.$$.fragment,t),g(zt.$$.fragment,t),g(jt.$$.fragment,t),g(Xt.$$.fragment,t),g(Zt.$$.fragment,t),g(er.$$.fragment,t),g(tr.$$.fragment,t),g(sr.$$.fragment,t),g(dr.$$.fragment,t),g(lr.$$.fragment,t),g(cr.$$.fragment,t),g(ur.$$.fragment,t),g(fr.$$.fragment,t),g(pr.$$.fragment,t),g(mr.$$.fragment,t),g(_r.$$.fragment,t),g(vr.$$.fragment,t),g(Sr.$$.fragment,t),g($r.$$.fragment,t),g(Dr.$$.fragment,t),g(xr.$$.fragment,t),g(wr.$$.fragment,t),g(Mr.$$.fragment,t),g(Pr.$$.fragment,t),g(Tr.$$.fragment,t),g(Or.$$.fragment,t),g(kr.$$.fragment,t),g(Cr.$$.fragment,t),g(Ar.$$.fragment,t),g(Ir.$$.fragment,t),g(Fr.$$.fragment,t),g(Lr.$$.fragment,t),g(Kr.$$.fragment,t),g(qr.$$.fragment,t),g(Hr.$$.fragment,t),g(Br.$$.fragment,t),g(Gr.$$.fragment,t),g(Yr.$$.fragment,t),g(zr.$$.fragment,t),g(Mt.$$.fragment,t),g(jr.$$.fragment,t),Qi=!0)},o(t){_(Tt.$$.fragment,t),_(Ot.$$.fragment,t),_(Vt.$$.fragment,t),_(Ct.$$.fragment,t),_(Nt.$$.fragment,t),_(Ft.$$.fragment,t),_(Lt.$$.fragment,t),_(Kt.$$.fragment,t),_(qt.$$.fragment,t),_(Ut.$$.fragment,t),_(Ht.$$.fragment,t),_(Rt.$$.fragment,t),_(Bt.$$.fragment,t),_(Gt.$$.fragment,t),_(Yt.$$.fragment,t),_(zt.$$.fragment,t),_(jt.$$.fragment,t),_(Xt.$$.fragment,t),_(Zt.$$.fragment,t),_(er.$$.fragment,t),_(tr.$$.fragment,t),_(sr.$$.fragment,t),_(dr.$$.fragment,t),_(lr.$$.fragment,t),_(cr.$$.fragment,t),_(ur.$$.fragment,t),_(fr.$$.fragment,t),_(pr.$$.fragment,t),_(mr.$$.fragment,t),_(_r.$$.fragment,t),_(vr.$$.fragment,t),_(Sr.$$.fragment,t),_($r.$$.fragment,t),_(Dr.$$.fragment,t),_(xr.$$.fragment,t),_(wr.$$.fragment,t),_(Mr.$$.fragment,t),_(Pr.$$.fragment,t),_(Tr.$$.fragment,t),_(Or.$$.fragment,t),_(kr.$$.fragment,t),_(Cr.$$.fragment,t),_(Ar.$$.fragment,t),_(Ir.$$.fragment,t),_(Fr.$$.fragment,t),_(Lr.$$.fragment,t),_(Kr.$$.fragment,t),_(qr.$$.fragment,t),_(Hr.$$.fragment,t),_(Br.$$.fragment,t),_(Gr.$$.fragment,t),_(Yr.$$.fragment,t),_(zr.$$.fragment,t),_(Mt.$$.fragment,t),_(jr.$$.fragment,t),Qi=!1},d(t){r(K),t&&r(Pe),t&&r(U),v(Tt),t&&r(di),t&&r(Zr),t&&r(li),t&&r(le),v(Ot),t&&r(ci),t&&r(Oe),t&&r(ui),t&&r(ke),t&&r(fi),t&&r(ue),v(Vt),t&&r(pi),t&&r(P),t&&r(hi),t&&r(fe),v(Ct),t&&r(mi),t&&r(ns),t&&r(gi),t&&r(Ne),t&&r(_i),t&&r(pe),v(Nt),t&&r(vi),t&&r(os),t&&r(bi),t&&r(ne),t&&r(Si),t&&r(Ie),t&&r($i),t&&r(he),v(Ft),t&&r(Di),t&&r(me),v(Lt),t&&r(Ei),t&&r(ge),v(Kt),t&&r(xi),t&&r(_e),v(qt),t&&r(yi),t&&r(ve),v(Ut),t&&r(wi),t&&r(be),v(Ht),t&&r(Mi),t&&r(as),t&&r(Pi),t&&r(x),v(Rt),v(Bt),v(Gt),v(Yt),t&&r(Ti),t&&r(Se),v(zt),t&&r(Oi),t&&r(Be),t&&r(ki),t&&r(y),v(jt),v(Xt),v(Zt),v(er),t&&r(Vi),t&&r($e),v(tr),t&&r(Ci),t&&r(je),t&&r(Ni),t&&r(S),v(sr),v(dr),v(lr),v(cr),v(ur),v(fr),t&&r(Ai),t&&r(De),v(pr),t&&r(Ii),t&&r(st),t&&r(Fi),t&&r(w),v(mr),v(_r),v(vr),v(Sr),v($r),t&&r(Li),t&&r(Ee),v(Dr),t&&r(Ki),t&&r(lt),t&&r(qi),t&&r($),v(xr),v(wr),v(Mr),v(Pr),v(Tr),v(Or),t&&r(Ui),t&&r(xe),v(kr),t&&r(Hi),t&&r(mt),t&&r(Ri),t&&r(D),v(Cr),v(Ar),v(Ir),v(Fr),v(Lr),v(Kr),t&&r(Wi),t&&r(we),v(qr),t&&r(Bi),t&&r($t),t&&r(Gi),t&&r(M),v(Hr),v(Br),v(Gr),v(Yr),t&&r(Yi),t&&r(Me),v(zr),t&&r(zi),t&&r(wt),t&&r(Ji),v(Mt,t),t&&r(ji),t&&r(H),v(jr)}}}const Fv={local:"schedulers",sections:[{local:"what-is-a-scheduler",sections:[{local:"discrete-versus-continuous-schedulers",title:"Discrete versus continuous schedulers"}],title:"What is a scheduler?"},{local:"designing-reusable-schedulers",title:"Designing Re-usable schedulers"},{local:"api",sections:[{local:"diffusers.SchedulerMixin",title:"SchedulerMixin"},{local:"diffusers.schedulers.scheduling_utils.SchedulerOutput",title:"SchedulerOutput"},{local:"implemented-schedulers",sections:[{local:"diffusers.DDIMScheduler",title:"Denoising diffusion implicit models (DDIM)"},{local:"diffusers.DDPMScheduler",title:"Denoising diffusion probabilistic models (DDPM)"},{local:"diffusers.KarrasVeScheduler",title:"Variance exploding, stochastic sampling from Karras et. al"},{local:"diffusers.LMSDiscreteScheduler",title:"Linear multistep scheduler for discrete beta schedules"},{local:"diffusers.PNDMScheduler",title:"Pseudo numerical methods for diffusion models (PNDM)"},{local:"diffusers.ScoreSdeVeScheduler",title:"variance exploding stochastic differential equation (VE-SDE) scheduler"},{local:"diffusers.IPNDMScheduler",title:"improved pseudo numerical methods for diffusion models (iPNDM)"},{local:"diffusers.schedulers.ScoreSdeVpScheduler",title:"variance preserving stochastic differential equation (VP-SDE) scheduler"}],title:"Implemented Schedulers"}],title:"API"}],title:"Schedulers"};function Lv(ai){return Cv(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Rv extends Tv{constructor(K){super();Ov(this,K,Lv,Iv,kv,{})}}export{Rv as default,Fv as metadata};
