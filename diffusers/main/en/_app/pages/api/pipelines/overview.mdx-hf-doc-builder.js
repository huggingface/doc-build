import{S as Mg,i as jg,s as Cg,e as o,k as f,w as S,t as r,M as Lg,c as a,d as t,m as d,a as n,x as $,h as i,b as s,N as ha,G as e,g as h,y as G,L as qg,q as O,o as M,B as j,v as Rg}from"../../../chunks/vendor-hf-doc-builder.js";import{I as _e}from"../../../chunks/IconCopyLink-hf-doc-builder.js";import{C as kh}from"../../../chunks/CodeBlock-hf-doc-builder.js";function Ng(xh){let le,Rl,re,ve,ca,Ze,Nr,ua,Hr,Nl,lo,Ur,Hl,be,Br,et,Yr,zr,Ul,b,ma,ro,Fr,Vr,ga,io,Qr,Wr,_a,tt,Jr,Kr,ot,Xr,so,Zr,ei,ti,at,oi,nt,ai,ni,li,lt,ri,fo,ii,si,Bl,po,fi,Yl,I,va,ba,C,di,Ea,pi,hi,rt,ci,ui,it,mi,gi,_i,ya,ho,st,vi,co,bi,Ei,yi,wa,uo,ft,wi,mo,Di,Ii,Ti,Da,go,dt,ki,_o,xi,Ai,zl,L,Ia,Pi,Si,Ta,$i,Gi,pt,Oi,Mi,Fl,ie,Ee,ka,ht,ji,xa,Ci,Vl,vo,Li,Ql,ye,Aa,q,Pa,qi,Ri,Sa,Ni,Hi,bo,Ui,Bi,Eo,Yi,zi,c,R,$a,yo,Fi,Vi,Ga,ct,Oa,Qi,Wi,wo,Ji,Ki,Ma,Xi,N,ja,Do,Zi,es,Ca,ut,La,ts,os,Io,as,ns,qa,ls,H,Ra,To,rs,is,Na,mt,Ha,ss,fs,ko,ds,ps,Ua,hs,U,Ba,xo,cs,us,Ya,gt,za,ms,gs,Ao,_s,vs,Fa,bs,B,Va,Po,Es,ys,Qa,_t,Wa,ws,Ds,So,Is,Ts,Ja,ks,Y,Ka,$o,xs,As,Xa,vt,Za,Ps,Ss,Go,$s,Gs,en,Os,z,tn,Oo,Ms,js,on,bt,an,Cs,Ls,Mo,qs,Rs,nn,Ns,F,ln,jo,Hs,Us,rn,Et,sn,Bs,Ys,Co,zs,Fs,fn,Vs,V,dn,Lo,Qs,Ws,pn,yt,hn,Js,Ks,qo,Xs,Zs,cn,ef,Q,un,Ro,tf,of,mn,wt,gn,af,nf,No,lf,rf,Ho,Dt,Uo,Ah,sf,W,_n,Bo,ff,df,vn,It,bn,pf,hf,Yo,cf,uf,zo,Tt,Fo,Ph,mf,J,En,Vo,gf,_f,yn,kt,wn,vf,bf,Qo,Ef,yf,Wo,xt,Jo,Sh,wf,K,Dn,Ko,Df,If,In,At,Tn,Tf,kf,Xo,xf,Af,kn,Pf,X,xn,Zo,Sf,$f,An,Pt,Gf,Of,ea,Mf,jf,Pn,Wl,St,Sn,Cf,Lf,Jl,we,qf,ta,Rf,Nf,Kl,se,De,$n,$t,Hf,Gn,Uf,Xl,oa,Bf,Zl,ee,Yf,On,zf,Ff,Gt,Vf,Qf,er,T,m,Ot,Mn,Wf,Jf,Kf,jn,Xf,Zf,Mt,ed,td,Cn,od,ad,Ln,nd,ld,qn,rd,id,jt,sd,fd,Rn,dd,pd,Nn,hd,cd,Hn,ud,md,Un,gd,_d,vd,_,aa,Bn,bd,Ed,Yn,yd,wd,zn,Dd,Id,Fn,Td,kd,Vn,xd,Ad,Qn,Pd,Sd,Wn,$d,Gd,Jn,Od,Md,jd,y,na,Kn,Cd,Ld,Xn,qd,Rd,Zn,Nd,Hd,el,Ud,Bd,fe,Yd,tl,zd,Fd,Vd,Qd,E,ol,Wd,Jd,al,Kd,Xd,nl,Zd,ep,ll,tp,op,la,rl,ap,np,Ct,lp,rp,tr,k,il,ip,sp,sl,fp,dp,Lt,fl,pp,hp,qt,cp,or,de,Ie,dl,Rt,up,pl,mp,ar,w,gp,hl,_p,vp,cl,bp,Ep,ul,yp,wp,ml,Dp,Ip,nr,x,Te,gl,Tp,kp,Nt,_l,xp,Ap,Pp,Sp,te,vl,$p,Gp,bl,Op,Mp,El,jp,Cp,Lp,oe,yl,qp,Rp,Ht,Np,Hp,ra,Up,Bp,Yp,A,wl,zp,Fp,Dl,Vp,Qp,Il,Wp,Jp,Tl,Kp,Xp,lr,pe,ke,kl,Ut,Zp,xl,eh,rr,he,xe,Al,Bt,th,Pl,oh,ir,Yt,sr,ce,Ae,Sl,zt,ah,$l,nh,fr,Pe,lh,Gl,rh,ih,dr,Ft,pr,Vt,sh,Qt,ia,$h,hr,ue,Se,Ol,Wt,fh,Ml,dh,cr,ae,ph,Jt,hh,ch,Kt,sa,Gh,uh,ur,me,$e,jl,Xt,mh,Cl,gh,mr,Ge,_h,Ll,vh,bh,gr,Zt,_r,eo,Eh,to,fa,Oh,vr;return Ze=new _e({}),ht=new _e({}),$t=new _e({}),Rt=new _e({}),Ut=new _e({}),Bt=new _e({}),Yt=new kh({props:{code:`# make sure you're logged in with \`huggingface-cli login\`
from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler

pipe = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")
pipe = pipe.to("cuda")

prompt = "a photo of an astronaut riding a horse on mars"
image = pipe(prompt).images[0]

image.save("astronaut_rides_horse.png")`,highlighted:`<span class="hljs-comment"># make sure you&#x27;re logged in with \`huggingface-cli login\`</span>
<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionPipeline, LMSDiscreteScheduler

pipe = StableDiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>)
pipe = pipe.to(<span class="hljs-string">&quot;cuda&quot;</span>)

prompt = <span class="hljs-string">&quot;a photo of an astronaut riding a horse on mars&quot;</span>
image = pipe(prompt).images[<span class="hljs-number">0</span>]

image.save(<span class="hljs-string">&quot;astronaut_rides_horse.png&quot;</span>)`}}),zt=new _e({}),Ft=new kh({props:{code:`import requests
from PIL import Image
from io import BytesIO

from diffusers import StableDiffusionImg2ImgPipeline

# load the pipeline
device = "cuda"
pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5", revision="fp16", torch_dtype=torch.float16
).to(device)

# let's download an initial image
url = "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg"

response = requests.get(url)
init_image = Image.open(BytesIO(response.content)).convert("RGB")
init_image = init_image.resize((768, 512))

prompt = "A fantasy landscape, trending on artstation"

images = pipe(prompt=prompt, init_image=init_image, strength=0.75, guidance_scale=7.5).images

images[0].save("fantasy_landscape.png")`,highlighted:`<span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-keyword">from</span> io <span class="hljs-keyword">import</span> BytesIO

<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionImg2ImgPipeline

<span class="hljs-comment"># load the pipeline</span>
device = <span class="hljs-string">&quot;cuda&quot;</span>
pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
    <span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>, revision=<span class="hljs-string">&quot;fp16&quot;</span>, torch_dtype=torch.float16
).to(device)

<span class="hljs-comment"># let&#x27;s download an initial image</span>
url = <span class="hljs-string">&quot;https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg&quot;</span>

response = requests.get(url)
init_image = Image.<span class="hljs-built_in">open</span>(BytesIO(response.content)).convert(<span class="hljs-string">&quot;RGB&quot;</span>)
init_image = init_image.resize((<span class="hljs-number">768</span>, <span class="hljs-number">512</span>))

prompt = <span class="hljs-string">&quot;A fantasy landscape, trending on artstation&quot;</span>

images = pipe(prompt=prompt, init_image=init_image, strength=<span class="hljs-number">0.75</span>, guidance_scale=<span class="hljs-number">7.5</span>).images

images[<span class="hljs-number">0</span>].save(<span class="hljs-string">&quot;fantasy_landscape.png&quot;</span>)`}}),Wt=new _e({}),Xt=new _e({}),Zt=new kh({props:{code:`import PIL
import requests
import torch
from io import BytesIO

from diffusers import StableDiffusionInpaintPipeline


def download_image(url):
    response = requests.get(url)
    return PIL.Image.open(BytesIO(response.content)).convert("RGB")


img_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
mask_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"

init_image = download_image(img_url).resize((512, 512))
mask_image = download_image(mask_url).resize((512, 512))

pipe = StableDiffusionInpaintPipeline.from_pretrained(
    "runwayml/stable-diffusion-inpainting",
    revision="fp16",
    torch_dtype=torch.float16,
)
pipe = pipe.to("cuda")

prompt = "Face of a yellow cat, high resolution, sitting on a park bench"
image = pipe(prompt=prompt, image=init_image, mask_image=mask_image).images[0]`,highlighted:`<span class="hljs-keyword">import</span> PIL
<span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> io <span class="hljs-keyword">import</span> BytesIO

<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionInpaintPipeline


<span class="hljs-keyword">def</span> <span class="hljs-title function_">download_image</span>(<span class="hljs-params">url</span>):
    response = requests.get(url)
    <span class="hljs-keyword">return</span> PIL.Image.<span class="hljs-built_in">open</span>(BytesIO(response.content)).convert(<span class="hljs-string">&quot;RGB&quot;</span>)


img_url = <span class="hljs-string">&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png&quot;</span>
mask_url = <span class="hljs-string">&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png&quot;</span>

init_image = download_image(img_url).resize((<span class="hljs-number">512</span>, <span class="hljs-number">512</span>))
mask_image = download_image(mask_url).resize((<span class="hljs-number">512</span>, <span class="hljs-number">512</span>))

pipe = StableDiffusionInpaintPipeline.from_pretrained(
    <span class="hljs-string">&quot;runwayml/stable-diffusion-inpainting&quot;</span>,
    revision=<span class="hljs-string">&quot;fp16&quot;</span>,
    torch_dtype=torch.float16,
)
pipe = pipe.to(<span class="hljs-string">&quot;cuda&quot;</span>)

prompt = <span class="hljs-string">&quot;Face of a yellow cat, high resolution, sitting on a park bench&quot;</span>
image = pipe(prompt=prompt, image=init_image, mask_image=mask_image).images[<span class="hljs-number">0</span>]`}}),{c(){le=o("meta"),Rl=f(),re=o("h1"),ve=o("a"),ca=o("span"),S(Ze.$$.fragment),Nr=f(),ua=o("span"),Hr=r("Pipelines"),Nl=f(),lo=o("p"),Ur=r(`Pipelines provide a simple way to run state-of-the-art diffusion models in inference.
Most diffusion systems consist of multiple independently-trained models and highly adaptable scheduler
components - all of which are needed to have a functioning end-to-end diffusion system.`),Hl=f(),be=o("p"),Br=r("As an example, "),et=o("a"),Yr=r("Stable Diffusion"),zr=r(" has three independently trained models:"),Ul=f(),b=o("ul"),ma=o("li"),ro=o("a"),Fr=r("Autoencoder"),Vr=f(),ga=o("li"),io=o("a"),Qr=r("Conditional Unet"),Wr=f(),_a=o("li"),tt=o("a"),Jr=r("CLIP text encoder"),Kr=f(),ot=o("li"),Xr=r("a scheduler component, "),so=o("a"),Zr=r("scheduler"),ei=r(","),ti=f(),at=o("li"),oi=r("a "),nt=o("a"),ai=r("CLIPFeatureExtractor"),ni=r(","),li=f(),lt=o("li"),ri=r("as well as a "),fo=o("a"),ii=r("safety checker"),si=r(`.
All of these components are necessary to run stable diffusion in inference even though they were trained
or created independently from each other.`),Bl=f(),po=o("p"),fi=r(`To that end, we strive to offer all open-sourced, state-of-the-art diffusion system under a unified API.
More specifically, we strive to provide pipelines that`),Yl=f(),I=o("ul"),va=o("li"),ba=o("ol"),C=o("li"),di=r("can load the officially published weights and yield 1-to-1 the same outputs as the original implementation according to the corresponding paper ("),Ea=o("em"),pi=r("e.g."),hi=f(),rt=o("a"),ci=r("LDMTextToImagePipeline"),ui=r(", uses the officially released weights of "),it=o("a"),mi=r("High-Resolution Image Synthesis with Latent Diffusion Models"),gi=r("),"),_i=f(),ya=o("li"),ho=o("ol"),st=o("li"),vi=r("have a simple user interface to run the model in inference (see the "),co=o("a"),bi=r("Pipelines API"),Ei=r(" section),"),yi=f(),wa=o("li"),uo=o("ol"),ft=o("li"),wi=r("are easy to understand with code that is self-explanatory and can be read along-side the official paper (see "),mo=o("a"),Di=r("Pipelines summary"),Ii=r("),"),Ti=f(),Da=o("li"),go=o("ol"),dt=o("li"),ki=r("can easily be contributed by the community (see the "),_o=o("a"),xi=r("Contribution"),Ai=r(" section)."),zl=f(),L=o("p"),Ia=o("strong"),Pi=r("Note"),Si=r(` that pipelines do not (and should not) offer any training functionality.
If you are looking for `),Ta=o("em"),$i=r("official"),Gi=r(" training examples, please have a look at "),pt=o("a"),Oi=r("examples"),Mi=r("."),Fl=f(),ie=o("h2"),Ee=o("a"),ka=o("span"),S(ht.$$.fragment),ji=f(),xa=o("span"),Ci=r("\u{1F9E8} Diffusers Summary"),Vl=f(),vo=o("p"),Li=r(`The following table summarizes all officially supported pipelines, their corresponding paper, and if
available a colab notebook to directly try them out.`),Ql=f(),ye=o("table"),Aa=o("thead"),q=o("tr"),Pa=o("th"),qi=r("Pipeline"),Ri=f(),Sa=o("th"),Ni=r("Paper"),Hi=f(),bo=o("th"),Ui=r("Tasks"),Bi=f(),Eo=o("th"),Yi=r("Colab"),zi=f(),c=o("tbody"),R=o("tr"),$a=o("td"),yo=o("a"),Fi=r("cycle_diffusion"),Vi=f(),Ga=o("td"),ct=o("a"),Oa=o("strong"),Qi=r("Cycle Diffusion"),Wi=f(),wo=o("td"),Ji=r("Image-to-Image Text-Guided Generation"),Ki=f(),Ma=o("td"),Xi=f(),N=o("tr"),ja=o("td"),Do=o("a"),Zi=r("dance_diffusion"),es=f(),Ca=o("td"),ut=o("a"),La=o("strong"),ts=r("Dance Diffusion"),os=f(),Io=o("td"),as=r("Unconditional Audio Generation"),ns=f(),qa=o("td"),ls=f(),H=o("tr"),Ra=o("td"),To=o("a"),rs=r("ddpm"),is=f(),Na=o("td"),mt=o("a"),Ha=o("strong"),ss=r("Denoising Diffusion Probabilistic Models"),fs=f(),ko=o("td"),ds=r("Unconditional Image Generation"),ps=f(),Ua=o("td"),hs=f(),U=o("tr"),Ba=o("td"),xo=o("a"),cs=r("ddim"),us=f(),Ya=o("td"),gt=o("a"),za=o("strong"),ms=r("Denoising Diffusion Implicit Models"),gs=f(),Ao=o("td"),_s=r("Unconditional Image Generation"),vs=f(),Fa=o("td"),bs=f(),B=o("tr"),Va=o("td"),Po=o("a"),Es=r("latent_diffusion"),ys=f(),Qa=o("td"),_t=o("a"),Wa=o("strong"),ws=r("High-Resolution Image Synthesis with Latent Diffusion Models"),Ds=f(),So=o("td"),Is=r("Text-to-Image Generation"),Ts=f(),Ja=o("td"),ks=f(),Y=o("tr"),Ka=o("td"),$o=o("a"),xs=r("latent_diffusion_uncond"),As=f(),Xa=o("td"),vt=o("a"),Za=o("strong"),Ps=r("High-Resolution Image Synthesis with Latent Diffusion Models"),Ss=f(),Go=o("td"),$s=r("Unconditional Image Generation"),Gs=f(),en=o("td"),Os=f(),z=o("tr"),tn=o("td"),Oo=o("a"),Ms=r("pndm"),js=f(),on=o("td"),bt=o("a"),an=o("strong"),Cs=r("Pseudo Numerical Methods for Diffusion Models on Manifolds"),Ls=f(),Mo=o("td"),qs=r("Unconditional Image Generation"),Rs=f(),nn=o("td"),Ns=f(),F=o("tr"),ln=o("td"),jo=o("a"),Hs=r("score_sde_ve"),Us=f(),rn=o("td"),Et=o("a"),sn=o("strong"),Bs=r("Score-Based Generative Modeling through Stochastic Differential Equations"),Ys=f(),Co=o("td"),zs=r("Unconditional Image Generation"),Fs=f(),fn=o("td"),Vs=f(),V=o("tr"),dn=o("td"),Lo=o("a"),Qs=r("score_sde_vp"),Ws=f(),pn=o("td"),yt=o("a"),hn=o("strong"),Js=r("Score-Based Generative Modeling through Stochastic Differential Equations"),Ks=f(),qo=o("td"),Xs=r("Unconditional Image Generation"),Zs=f(),cn=o("td"),ef=f(),Q=o("tr"),un=o("td"),Ro=o("a"),tf=r("stable_diffusion"),of=f(),mn=o("td"),wt=o("a"),gn=o("strong"),af=r("Stable Diffusion"),nf=f(),No=o("td"),lf=r("Text-to-Image Generation"),rf=f(),Ho=o("td"),Dt=o("a"),Uo=o("img"),sf=f(),W=o("tr"),_n=o("td"),Bo=o("a"),ff=r("stable_diffusion"),df=f(),vn=o("td"),It=o("a"),bn=o("strong"),pf=r("Stable Diffusion"),hf=f(),Yo=o("td"),cf=r("Image-to-Image Text-Guided Generation"),uf=f(),zo=o("td"),Tt=o("a"),Fo=o("img"),mf=f(),J=o("tr"),En=o("td"),Vo=o("a"),gf=r("stable_diffusion"),_f=f(),yn=o("td"),kt=o("a"),wn=o("strong"),vf=r("Stable Diffusion"),bf=f(),Qo=o("td"),Ef=r("Text-Guided Image Inpainting"),yf=f(),Wo=o("td"),xt=o("a"),Jo=o("img"),wf=f(),K=o("tr"),Dn=o("td"),Ko=o("a"),Df=r("stochastic_karras_ve"),If=f(),In=o("td"),At=o("a"),Tn=o("strong"),Tf=r("Elucidating the Design Space of Diffusion-Based Generative Models"),kf=f(),Xo=o("td"),xf=r("Unconditional Image Generation"),Af=f(),kn=o("td"),Pf=f(),X=o("tr"),xn=o("td"),Zo=o("a"),Sf=r("vq_diffusion"),$f=f(),An=o("td"),Pt=o("a"),Gf=r("Vector Quantized Diffusion Model for Text-to-Image Synthesis"),Of=f(),ea=o("td"),Mf=r("Text-to-Image Generation"),jf=f(),Pn=o("td"),Wl=f(),St=o("p"),Sn=o("strong"),Cf=r("Note"),Lf=r(": Pipelines are simple examples of how to play around with the diffusion systems as described in the corresponding papers."),Jl=f(),we=o("p"),qf=r("However, most of them can be adapted to use different scheduler components or even different model components. Some pipeline examples are shown in the "),ta=o("a"),Rf=r("Examples"),Nf=r(" below."),Kl=f(),se=o("h2"),De=o("a"),$n=o("span"),S($t.$$.fragment),Hf=f(),Gn=o("span"),Uf=r("Pipelines API"),Xl=f(),oa=o("p"),Bf=r("Diffusion models often consist of multiple independently-trained models or other previously existing components."),Zl=f(),ee=o("p"),Yf=r(`Each model has been trained independently on a different task and the scheduler can easily be swapped out and replaced with a different one.
During inference, we however want to be able to easily load all components and use them in inference - even if one component, `),On=o("em"),zf=r("e.g."),Ff=r(" CLIP\u2019s text encoder, originates from a different library, such as "),Gt=o("a"),Vf=r("Transformers"),Qf=r(". To that end, all pipelines provide the following functionality:"),er=f(),T=o("ul"),m=o("li"),Ot=o("a"),Mn=o("code"),Wf=r("from_pretrained"),Jf=r(" method"),Kf=r(" that accepts a Hugging Face Hub repository id, "),jn=o("em"),Xf=r("e.g."),Zf=f(),Mt=o("a"),ed=r("runwayml/stable-diffusion-v1-5"),td=r(" or a path to a local directory, "),Cn=o("em"),od=r("e.g."),ad=r(`
\u201D./stable-diffusion\u201D. To correctly retrieve which models and components should be loaded, one has to provide a `),Ln=o("code"),nd=r("model_index.json"),ld=r(" file, "),qn=o("em"),rd=r("e.g."),id=f(),jt=o("a"),sd=r("runwayml/stable-diffusion-v1-5/model_index.json"),fd=r(`, which defines all components that should be
loaded into the pipelines. More specifically, for each model/component one needs to define the format `),Rn=o("code"),dd=r('<name>: ["<library>", "<class name>"]'),pd=r(". "),Nn=o("code"),hd=r("<name>"),cd=r(" is the attribute name given to the loaded instance of "),Hn=o("code"),ud=r("<class name>"),md=r(" which can be found in the library or pipeline folder called "),Un=o("code"),gd=r('"<library>"'),_d=r("."),vd=f(),_=o("li"),aa=o("a"),Bn=o("code"),bd=r("save_pretrained"),Ed=r(" that accepts a local path, "),Yn=o("em"),yd=r("e.g."),wd=f(),zn=o("code"),Dd=r("./stable-diffusion"),Id=r(" under which all models/components of the pipeline will be saved. For each component/model a folder is created inside the local path that is named after the given attribute name, "),Fn=o("em"),Td=r("e.g."),kd=f(),Vn=o("code"),xd=r("./stable_diffusion/unet"),Ad=r(`.
In addition, a `),Qn=o("code"),Pd=r("model_index.json"),Sd=r(" file is created at the root of the local path, "),Wn=o("em"),$d=r("e.g."),Gd=f(),Jn=o("code"),Od=r("./stable_diffusion/model_index.json"),Md=r(` so that the complete pipeline can again be instantiated
from the local path.`),jd=f(),y=o("li"),na=o("a"),Kn=o("code"),Cd=r("to"),Ld=r(" which accepts a "),Xn=o("code"),qd=r("string"),Rd=r(" or "),Zn=o("code"),Nd=r("torch.device"),Hd=r(" to move all models that are of type "),el=o("code"),Ud=r("torch.nn.Module"),Bd=r(" to the passed device. The behavior is fully analogous to "),fe=o("a"),Yd=r("PyTorch\u2019s "),tl=o("code"),zd=r("to"),Fd=r(" method"),Vd=r("."),Qd=f(),E=o("li"),ol=o("code"),Wd=r("__call__"),Jd=r(" method to use the pipeline in inference. "),al=o("code"),Kd=r("__call__"),Xd=r(" defines inference logic of the pipeline and should ideally encompass all aspects of it, from pre-processing to forwarding tensors to the different models and schedulers, as well as post-processing. The API of the "),nl=o("code"),Zd=r("__call__"),ep=r(" method can strongly vary from pipeline to pipeline. "),ll=o("em"),tp=r("E.g."),op=r(" a text-to-image pipeline, such as "),la=o("a"),rl=o("code"),ap=r("StableDiffusionPipeline"),np=r(" should accept among other things the text prompt to generate the image. A pure image generation pipeline, such as "),Ct=o("a"),lp=r("DDPMPipeline"),rp=r(` on the other hand can be run without providing any inputs. To better understand what inputs can be adapted for
each pipeline, one should look directly into the respective pipeline.`),tr=f(),k=o("p"),il=o("strong"),ip=r("Note"),sp=r(": All pipelines have PyTorch\u2019s autograd disabled by decorating the "),sl=o("code"),fp=r("__call__"),dp=r(" method with a "),Lt=o("a"),fl=o("code"),pp=r("torch.no_grad"),hp=r(` decorator because pipelines should
not be used for training. If you want to store the gradients during the forward pass, we recommend writing your own pipeline, see also our `),qt=o("a"),cp=r("community-examples"),or=f(),de=o("h2"),Ie=o("a"),dl=o("span"),S(Rt.$$.fragment),up=f(),pl=o("span"),mp=r("Contribution"),ar=f(),w=o("p"),gp=r(`We are more than happy about any contribution to the officially supported pipelines \u{1F917}. We aspire
all of our pipelines to be  `),hl=o("strong"),_p=r("self-contained"),vp=r(", "),cl=o("strong"),bp=r("easy-to-tweak"),Ep=r(", "),ul=o("strong"),yp=r("beginner-friendly"),wp=r(" and for "),ml=o("strong"),Dp=r("one-purpose-only"),Ip=r("."),nr=f(),x=o("ul"),Te=o("li"),gl=o("strong"),Tp=r("Self-contained"),kp=r(": A pipeline shall be as self-contained as possible. More specifically, this means that all functionality should be either directly defined in the pipeline file itself, should be inherited from (and only from) the "),Nt=o("a"),_l=o("code"),xp=r("DiffusionPipeline"),Ap=r(" class"),Pp=r(" or be directly attached to the model and scheduler components of the pipeline."),Sp=f(),te=o("li"),vl=o("strong"),$p=r("Easy-to-use"),Gp=r(`: Pipelines should be extremely easy to use - one should be able to load the pipeline and
use it for its designated task, `),bl=o("em"),Op=r("e.g."),Mp=r(` text-to-image generation, in just a couple of lines of code. Most
logic including pre-processing, an unrolled diffusion loop, and post-processing should all happen inside the `),El=o("code"),jp=r("__call__"),Cp=r(" method."),Lp=f(),oe=o("li"),yl=o("strong"),qp=r("Easy-to-tweak"),Rp=r(": Certain pipelines will not be able to handle all use cases and tasks that you might like them to. If you want to use a certain pipeline for a specific use case that is not yet supported, you might have to copy the pipeline file and tweak the code to your needs. We try to make the pipeline code as readable as possible so that each part \u2013from pre-processing to diffusing to post-processing\u2013 can easily be adapted. If you would like the community to benefit from your customized pipeline, we would love to see a contribution to our "),Ht=o("a"),Np=r("community-examples"),Hp=r(". If you feel that an important pipeline should be part of the official pipelines but isn\u2019t, a contribution to the "),ra=o("a"),Up=r("official pipelines"),Bp=r(" would be even better."),Yp=f(),A=o("li"),wl=o("strong"),zp=r("One-purpose-only"),Fp=r(": Pipelines should be used for one task and one task only. Even if two tasks are very similar from a modeling point of view, "),Dl=o("em"),Vp=r("e.g."),Qp=r(" image2image translation and in-painting, pipelines shall be used for one task only to keep them "),Il=o("em"),Wp=r("easy-to-tweak"),Jp=r(" and "),Tl=o("em"),Kp=r("readable"),Xp=r("."),lr=f(),pe=o("h2"),ke=o("a"),kl=o("span"),S(Ut.$$.fragment),Zp=f(),xl=o("span"),eh=r("Examples"),rr=f(),he=o("h3"),xe=o("a"),Al=o("span"),S(Bt.$$.fragment),th=f(),Pl=o("span"),oh=r("Text-to-Image generation with Stable Diffusion"),ir=f(),S(Yt.$$.fragment),sr=f(),ce=o("h3"),Ae=o("a"),Sl=o("span"),S(zt.$$.fragment),ah=f(),$l=o("span"),nh=r("Image-to-Image text-guided generation with Stable Diffusion"),fr=f(),Pe=o("p"),lh=r("The "),Gl=o("code"),rh=r("StableDiffusionImg2ImgPipeline"),ih=r(" lets you pass a text prompt and an initial image to condition the generation of new images."),dr=f(),S(Ft.$$.fragment),pr=f(),Vt=o("p"),sh=r("You can also run this example on colab "),Qt=o("a"),ia=o("img"),hr=f(),ue=o("h3"),Se=o("a"),Ol=o("span"),S(Wt.$$.fragment),fh=f(),Ml=o("span"),dh=r("Tweak prompts reusing seeds and latents"),cr=f(),ae=o("p"),ph=r("You can generate your own latents to reproduce results, or tweak your prompt on a specific result you liked. "),Jt=o("a"),hh=r("This notebook"),ch=r(" shows how to do it step by step. You can also run it in Google Colab "),Kt=o("a"),sa=o("img"),uh=r("."),ur=f(),me=o("h3"),$e=o("a"),jl=o("span"),S(Xt.$$.fragment),mh=f(),Cl=o("span"),gh=r("In-painting using Stable Diffusion"),mr=f(),Ge=o("p"),_h=r("The "),Ll=o("code"),vh=r("StableDiffusionInpaintPipeline"),bh=r(" lets you edit specific parts of an image by providing a mask and text prompt."),gr=f(),S(Zt.$$.fragment),_r=f(),eo=o("p"),Eh=r("You can also run this example on colab "),to=o("a"),fa=o("img"),this.h()},l(l){const p=Lg('[data-svelte="svelte-1phssyn"]',document.head);le=a(p,"META",{name:!0,content:!0}),p.forEach(t),Rl=d(l),re=a(l,"H1",{class:!0});var br=n(re);ve=a(br,"A",{id:!0,class:!0,href:!0});var Mh=n(ve);ca=a(Mh,"SPAN",{});var jh=n(ca);$(Ze.$$.fragment,jh),jh.forEach(t),Mh.forEach(t),Nr=d(br),ua=a(br,"SPAN",{});var Ch=n(ua);Hr=i(Ch,"Pipelines"),Ch.forEach(t),br.forEach(t),Nl=d(l),lo=a(l,"P",{});var Lh=n(lo);Ur=i(Lh,`Pipelines provide a simple way to run state-of-the-art diffusion models in inference.
Most diffusion systems consist of multiple independently-trained models and highly adaptable scheduler
components - all of which are needed to have a functioning end-to-end diffusion system.`),Lh.forEach(t),Hl=d(l),be=a(l,"P",{});var Er=n(be);Br=i(Er,"As an example, "),et=a(Er,"A",{href:!0,rel:!0});var qh=n(et);Yr=i(qh,"Stable Diffusion"),qh.forEach(t),zr=i(Er," has three independently trained models:"),Er.forEach(t),Ul=d(l),b=a(l,"UL",{});var P=n(b);ma=a(P,"LI",{});var Rh=n(ma);ro=a(Rh,"A",{href:!0});var Nh=n(ro);Fr=i(Nh,"Autoencoder"),Nh.forEach(t),Rh.forEach(t),Vr=d(P),ga=a(P,"LI",{});var Hh=n(ga);io=a(Hh,"A",{href:!0});var Uh=n(io);Qr=i(Uh,"Conditional Unet"),Uh.forEach(t),Hh.forEach(t),Wr=d(P),_a=a(P,"LI",{});var Bh=n(_a);tt=a(Bh,"A",{href:!0,rel:!0});var Yh=n(tt);Jr=i(Yh,"CLIP text encoder"),Yh.forEach(t),Bh.forEach(t),Kr=d(P),ot=a(P,"LI",{});var yr=n(ot);Xr=i(yr,"a scheduler component, "),so=a(yr,"A",{href:!0});var zh=n(so);Zr=i(zh,"scheduler"),zh.forEach(t),ei=i(yr,","),yr.forEach(t),ti=d(P),at=a(P,"LI",{});var wr=n(at);oi=i(wr,"a "),nt=a(wr,"A",{href:!0,rel:!0});var Fh=n(nt);ai=i(Fh,"CLIPFeatureExtractor"),Fh.forEach(t),ni=i(wr,","),wr.forEach(t),li=d(P),lt=a(P,"LI",{});var Dr=n(lt);ri=i(Dr,"as well as a "),fo=a(Dr,"A",{href:!0});var Vh=n(fo);ii=i(Vh,"safety checker"),Vh.forEach(t),si=i(Dr,`.
All of these components are necessary to run stable diffusion in inference even though they were trained
or created independently from each other.`),Dr.forEach(t),P.forEach(t),Bl=d(l),po=a(l,"P",{});var Qh=n(po);fi=i(Qh,`To that end, we strive to offer all open-sourced, state-of-the-art diffusion system under a unified API.
More specifically, we strive to provide pipelines that`),Qh.forEach(t),Yl=d(l),I=a(l,"UL",{});var Oe=n(I);va=a(Oe,"LI",{});var Wh=n(va);ba=a(Wh,"OL",{});var Jh=n(ba);C=a(Jh,"LI",{});var Me=n(C);di=i(Me,"can load the officially published weights and yield 1-to-1 the same outputs as the original implementation according to the corresponding paper ("),Ea=a(Me,"EM",{});var Kh=n(Ea);pi=i(Kh,"e.g."),Kh.forEach(t),hi=d(Me),rt=a(Me,"A",{href:!0,rel:!0});var Xh=n(rt);ci=i(Xh,"LDMTextToImagePipeline"),Xh.forEach(t),ui=i(Me,", uses the officially released weights of "),it=a(Me,"A",{href:!0,rel:!0});var Zh=n(it);mi=i(Zh,"High-Resolution Image Synthesis with Latent Diffusion Models"),Zh.forEach(t),gi=i(Me,"),"),Me.forEach(t),Jh.forEach(t),Wh.forEach(t),_i=d(Oe),ya=a(Oe,"LI",{});var ec=n(ya);ho=a(ec,"OL",{start:!0});var tc=n(ho);st=a(tc,"LI",{});var Ir=n(st);vi=i(Ir,"have a simple user interface to run the model in inference (see the "),co=a(Ir,"A",{href:!0});var oc=n(co);bi=i(oc,"Pipelines API"),oc.forEach(t),Ei=i(Ir," section),"),Ir.forEach(t),tc.forEach(t),ec.forEach(t),yi=d(Oe),wa=a(Oe,"LI",{});var ac=n(wa);uo=a(ac,"OL",{start:!0});var nc=n(uo);ft=a(nc,"LI",{});var Tr=n(ft);wi=i(Tr,"are easy to understand with code that is self-explanatory and can be read along-side the official paper (see "),mo=a(Tr,"A",{href:!0});var lc=n(mo);Di=i(lc,"Pipelines summary"),lc.forEach(t),Ii=i(Tr,"),"),Tr.forEach(t),nc.forEach(t),ac.forEach(t),Ti=d(Oe),Da=a(Oe,"LI",{});var rc=n(Da);go=a(rc,"OL",{start:!0});var ic=n(go);dt=a(ic,"LI",{});var kr=n(dt);ki=i(kr,"can easily be contributed by the community (see the "),_o=a(kr,"A",{href:!0});var sc=n(_o);xi=i(sc,"Contribution"),sc.forEach(t),Ai=i(kr," section)."),kr.forEach(t),ic.forEach(t),rc.forEach(t),Oe.forEach(t),zl=d(l),L=a(l,"P",{});var oo=n(L);Ia=a(oo,"STRONG",{});var fc=n(Ia);Pi=i(fc,"Note"),fc.forEach(t),Si=i(oo,` that pipelines do not (and should not) offer any training functionality.
If you are looking for `),Ta=a(oo,"EM",{});var dc=n(Ta);$i=i(dc,"official"),dc.forEach(t),Gi=i(oo," training examples, please have a look at "),pt=a(oo,"A",{href:!0,rel:!0});var pc=n(pt);Oi=i(pc,"examples"),pc.forEach(t),Mi=i(oo,"."),oo.forEach(t),Fl=d(l),ie=a(l,"H2",{class:!0});var xr=n(ie);Ee=a(xr,"A",{id:!0,class:!0,href:!0});var hc=n(Ee);ka=a(hc,"SPAN",{});var cc=n(ka);$(ht.$$.fragment,cc),cc.forEach(t),hc.forEach(t),ji=d(xr),xa=a(xr,"SPAN",{});var uc=n(xa);Ci=i(uc,"\u{1F9E8} Diffusers Summary"),uc.forEach(t),xr.forEach(t),Vl=d(l),vo=a(l,"P",{});var mc=n(vo);Li=i(mc,`The following table summarizes all officially supported pipelines, their corresponding paper, and if
available a colab notebook to directly try them out.`),mc.forEach(t),Ql=d(l),ye=a(l,"TABLE",{});var Ar=n(ye);Aa=a(Ar,"THEAD",{});var gc=n(Aa);q=a(gc,"TR",{});var je=n(q);Pa=a(je,"TH",{});var _c=n(Pa);qi=i(_c,"Pipeline"),_c.forEach(t),Ri=d(je),Sa=a(je,"TH",{});var vc=n(Sa);Ni=i(vc,"Paper"),vc.forEach(t),Hi=d(je),bo=a(je,"TH",{align:!0});var bc=n(bo);Ui=i(bc,"Tasks"),bc.forEach(t),Bi=d(je),Eo=a(je,"TH",{align:!0});var Ec=n(Eo);Yi=i(Ec,"Colab"),Ec.forEach(t),je.forEach(t),gc.forEach(t),zi=d(Ar),c=a(Ar,"TBODY",{});var u=n(c);R=a(u,"TR",{});var Ce=n(R);$a=a(Ce,"TD",{});var yc=n($a);yo=a(yc,"A",{href:!0});var wc=n(yo);Fi=i(wc,"cycle_diffusion"),wc.forEach(t),yc.forEach(t),Vi=d(Ce),Ga=a(Ce,"TD",{});var Dc=n(Ga);ct=a(Dc,"A",{href:!0,rel:!0});var Ic=n(ct);Oa=a(Ic,"STRONG",{});var Tc=n(Oa);Qi=i(Tc,"Cycle Diffusion"),Tc.forEach(t),Ic.forEach(t),Dc.forEach(t),Wi=d(Ce),wo=a(Ce,"TD",{align:!0});var kc=n(wo);Ji=i(kc,"Image-to-Image Text-Guided Generation"),kc.forEach(t),Ki=d(Ce),Ma=a(Ce,"TD",{align:!0}),n(Ma).forEach(t),Ce.forEach(t),Xi=d(u),N=a(u,"TR",{});var Le=n(N);ja=a(Le,"TD",{});var xc=n(ja);Do=a(xc,"A",{href:!0});var Ac=n(Do);Zi=i(Ac,"dance_diffusion"),Ac.forEach(t),xc.forEach(t),es=d(Le),Ca=a(Le,"TD",{});var Pc=n(Ca);ut=a(Pc,"A",{href:!0,rel:!0});var Sc=n(ut);La=a(Sc,"STRONG",{});var $c=n(La);ts=i($c,"Dance Diffusion"),$c.forEach(t),Sc.forEach(t),Pc.forEach(t),os=d(Le),Io=a(Le,"TD",{align:!0});var Gc=n(Io);as=i(Gc,"Unconditional Audio Generation"),Gc.forEach(t),ns=d(Le),qa=a(Le,"TD",{align:!0}),n(qa).forEach(t),Le.forEach(t),ls=d(u),H=a(u,"TR",{});var qe=n(H);Ra=a(qe,"TD",{});var Oc=n(Ra);To=a(Oc,"A",{href:!0});var Mc=n(To);rs=i(Mc,"ddpm"),Mc.forEach(t),Oc.forEach(t),is=d(qe),Na=a(qe,"TD",{});var jc=n(Na);mt=a(jc,"A",{href:!0,rel:!0});var Cc=n(mt);Ha=a(Cc,"STRONG",{});var Lc=n(Ha);ss=i(Lc,"Denoising Diffusion Probabilistic Models"),Lc.forEach(t),Cc.forEach(t),jc.forEach(t),fs=d(qe),ko=a(qe,"TD",{align:!0});var qc=n(ko);ds=i(qc,"Unconditional Image Generation"),qc.forEach(t),ps=d(qe),Ua=a(qe,"TD",{align:!0}),n(Ua).forEach(t),qe.forEach(t),hs=d(u),U=a(u,"TR",{});var Re=n(U);Ba=a(Re,"TD",{});var Rc=n(Ba);xo=a(Rc,"A",{href:!0});var Nc=n(xo);cs=i(Nc,"ddim"),Nc.forEach(t),Rc.forEach(t),us=d(Re),Ya=a(Re,"TD",{});var Hc=n(Ya);gt=a(Hc,"A",{href:!0,rel:!0});var Uc=n(gt);za=a(Uc,"STRONG",{});var Bc=n(za);ms=i(Bc,"Denoising Diffusion Implicit Models"),Bc.forEach(t),Uc.forEach(t),Hc.forEach(t),gs=d(Re),Ao=a(Re,"TD",{align:!0});var Yc=n(Ao);_s=i(Yc,"Unconditional Image Generation"),Yc.forEach(t),vs=d(Re),Fa=a(Re,"TD",{align:!0}),n(Fa).forEach(t),Re.forEach(t),bs=d(u),B=a(u,"TR",{});var Ne=n(B);Va=a(Ne,"TD",{});var zc=n(Va);Po=a(zc,"A",{href:!0});var Fc=n(Po);Es=i(Fc,"latent_diffusion"),Fc.forEach(t),zc.forEach(t),ys=d(Ne),Qa=a(Ne,"TD",{});var Vc=n(Qa);_t=a(Vc,"A",{href:!0,rel:!0});var Qc=n(_t);Wa=a(Qc,"STRONG",{});var Wc=n(Wa);ws=i(Wc,"High-Resolution Image Synthesis with Latent Diffusion Models"),Wc.forEach(t),Qc.forEach(t),Vc.forEach(t),Ds=d(Ne),So=a(Ne,"TD",{align:!0});var Jc=n(So);Is=i(Jc,"Text-to-Image Generation"),Jc.forEach(t),Ts=d(Ne),Ja=a(Ne,"TD",{align:!0}),n(Ja).forEach(t),Ne.forEach(t),ks=d(u),Y=a(u,"TR",{});var He=n(Y);Ka=a(He,"TD",{});var Kc=n(Ka);$o=a(Kc,"A",{href:!0});var Xc=n($o);xs=i(Xc,"latent_diffusion_uncond"),Xc.forEach(t),Kc.forEach(t),As=d(He),Xa=a(He,"TD",{});var Zc=n(Xa);vt=a(Zc,"A",{href:!0,rel:!0});var eu=n(vt);Za=a(eu,"STRONG",{});var tu=n(Za);Ps=i(tu,"High-Resolution Image Synthesis with Latent Diffusion Models"),tu.forEach(t),eu.forEach(t),Zc.forEach(t),Ss=d(He),Go=a(He,"TD",{align:!0});var ou=n(Go);$s=i(ou,"Unconditional Image Generation"),ou.forEach(t),Gs=d(He),en=a(He,"TD",{align:!0}),n(en).forEach(t),He.forEach(t),Os=d(u),z=a(u,"TR",{});var Ue=n(z);tn=a(Ue,"TD",{});var au=n(tn);Oo=a(au,"A",{href:!0});var nu=n(Oo);Ms=i(nu,"pndm"),nu.forEach(t),au.forEach(t),js=d(Ue),on=a(Ue,"TD",{});var lu=n(on);bt=a(lu,"A",{href:!0,rel:!0});var ru=n(bt);an=a(ru,"STRONG",{});var iu=n(an);Cs=i(iu,"Pseudo Numerical Methods for Diffusion Models on Manifolds"),iu.forEach(t),ru.forEach(t),lu.forEach(t),Ls=d(Ue),Mo=a(Ue,"TD",{align:!0});var su=n(Mo);qs=i(su,"Unconditional Image Generation"),su.forEach(t),Rs=d(Ue),nn=a(Ue,"TD",{align:!0}),n(nn).forEach(t),Ue.forEach(t),Ns=d(u),F=a(u,"TR",{});var Be=n(F);ln=a(Be,"TD",{});var fu=n(ln);jo=a(fu,"A",{href:!0});var du=n(jo);Hs=i(du,"score_sde_ve"),du.forEach(t),fu.forEach(t),Us=d(Be),rn=a(Be,"TD",{});var pu=n(rn);Et=a(pu,"A",{href:!0,rel:!0});var hu=n(Et);sn=a(hu,"STRONG",{});var cu=n(sn);Bs=i(cu,"Score-Based Generative Modeling through Stochastic Differential Equations"),cu.forEach(t),hu.forEach(t),pu.forEach(t),Ys=d(Be),Co=a(Be,"TD",{align:!0});var uu=n(Co);zs=i(uu,"Unconditional Image Generation"),uu.forEach(t),Fs=d(Be),fn=a(Be,"TD",{align:!0}),n(fn).forEach(t),Be.forEach(t),Vs=d(u),V=a(u,"TR",{});var Ye=n(V);dn=a(Ye,"TD",{});var mu=n(dn);Lo=a(mu,"A",{href:!0});var gu=n(Lo);Qs=i(gu,"score_sde_vp"),gu.forEach(t),mu.forEach(t),Ws=d(Ye),pn=a(Ye,"TD",{});var _u=n(pn);yt=a(_u,"A",{href:!0,rel:!0});var vu=n(yt);hn=a(vu,"STRONG",{});var bu=n(hn);Js=i(bu,"Score-Based Generative Modeling through Stochastic Differential Equations"),bu.forEach(t),vu.forEach(t),_u.forEach(t),Ks=d(Ye),qo=a(Ye,"TD",{align:!0});var Eu=n(qo);Xs=i(Eu,"Unconditional Image Generation"),Eu.forEach(t),Zs=d(Ye),cn=a(Ye,"TD",{align:!0}),n(cn).forEach(t),Ye.forEach(t),ef=d(u),Q=a(u,"TR",{});var ze=n(Q);un=a(ze,"TD",{});var yu=n(un);Ro=a(yu,"A",{href:!0});var wu=n(Ro);tf=i(wu,"stable_diffusion"),wu.forEach(t),yu.forEach(t),of=d(ze),mn=a(ze,"TD",{});var Du=n(mn);wt=a(Du,"A",{href:!0,rel:!0});var Iu=n(wt);gn=a(Iu,"STRONG",{});var Tu=n(gn);af=i(Tu,"Stable Diffusion"),Tu.forEach(t),Iu.forEach(t),Du.forEach(t),nf=d(ze),No=a(ze,"TD",{align:!0});var ku=n(No);lf=i(ku,"Text-to-Image Generation"),ku.forEach(t),rf=d(ze),Ho=a(ze,"TD",{align:!0});var xu=n(Ho);Dt=a(xu,"A",{href:!0,rel:!0});var Au=n(Dt);Uo=a(Au,"IMG",{src:!0,alt:!0}),Au.forEach(t),xu.forEach(t),ze.forEach(t),sf=d(u),W=a(u,"TR",{});var Fe=n(W);_n=a(Fe,"TD",{});var Pu=n(_n);Bo=a(Pu,"A",{href:!0});var Su=n(Bo);ff=i(Su,"stable_diffusion"),Su.forEach(t),Pu.forEach(t),df=d(Fe),vn=a(Fe,"TD",{});var $u=n(vn);It=a($u,"A",{href:!0,rel:!0});var Gu=n(It);bn=a(Gu,"STRONG",{});var Ou=n(bn);pf=i(Ou,"Stable Diffusion"),Ou.forEach(t),Gu.forEach(t),$u.forEach(t),hf=d(Fe),Yo=a(Fe,"TD",{align:!0});var Mu=n(Yo);cf=i(Mu,"Image-to-Image Text-Guided Generation"),Mu.forEach(t),uf=d(Fe),zo=a(Fe,"TD",{align:!0});var ju=n(zo);Tt=a(ju,"A",{href:!0,rel:!0});var Cu=n(Tt);Fo=a(Cu,"IMG",{src:!0,alt:!0}),Cu.forEach(t),ju.forEach(t),Fe.forEach(t),mf=d(u),J=a(u,"TR",{});var Ve=n(J);En=a(Ve,"TD",{});var Lu=n(En);Vo=a(Lu,"A",{href:!0});var qu=n(Vo);gf=i(qu,"stable_diffusion"),qu.forEach(t),Lu.forEach(t),_f=d(Ve),yn=a(Ve,"TD",{});var Ru=n(yn);kt=a(Ru,"A",{href:!0,rel:!0});var Nu=n(kt);wn=a(Nu,"STRONG",{});var Hu=n(wn);vf=i(Hu,"Stable Diffusion"),Hu.forEach(t),Nu.forEach(t),Ru.forEach(t),bf=d(Ve),Qo=a(Ve,"TD",{align:!0});var Uu=n(Qo);Ef=i(Uu,"Text-Guided Image Inpainting"),Uu.forEach(t),yf=d(Ve),Wo=a(Ve,"TD",{align:!0});var Bu=n(Wo);xt=a(Bu,"A",{href:!0,rel:!0});var Yu=n(xt);Jo=a(Yu,"IMG",{src:!0,alt:!0}),Yu.forEach(t),Bu.forEach(t),Ve.forEach(t),wf=d(u),K=a(u,"TR",{});var Qe=n(K);Dn=a(Qe,"TD",{});var zu=n(Dn);Ko=a(zu,"A",{href:!0});var Fu=n(Ko);Df=i(Fu,"stochastic_karras_ve"),Fu.forEach(t),zu.forEach(t),If=d(Qe),In=a(Qe,"TD",{});var Vu=n(In);At=a(Vu,"A",{href:!0,rel:!0});var Qu=n(At);Tn=a(Qu,"STRONG",{});var Wu=n(Tn);Tf=i(Wu,"Elucidating the Design Space of Diffusion-Based Generative Models"),Wu.forEach(t),Qu.forEach(t),Vu.forEach(t),kf=d(Qe),Xo=a(Qe,"TD",{align:!0});var Ju=n(Xo);xf=i(Ju,"Unconditional Image Generation"),Ju.forEach(t),Af=d(Qe),kn=a(Qe,"TD",{align:!0}),n(kn).forEach(t),Qe.forEach(t),Pf=d(u),X=a(u,"TR",{});var We=n(X);xn=a(We,"TD",{});var Ku=n(xn);Zo=a(Ku,"A",{href:!0});var Xu=n(Zo);Sf=i(Xu,"vq_diffusion"),Xu.forEach(t),Ku.forEach(t),$f=d(We),An=a(We,"TD",{});var Zu=n(An);Pt=a(Zu,"A",{href:!0,rel:!0});var em=n(Pt);Gf=i(em,"Vector Quantized Diffusion Model for Text-to-Image Synthesis"),em.forEach(t),Zu.forEach(t),Of=d(We),ea=a(We,"TD",{align:!0});var tm=n(ea);Mf=i(tm,"Text-to-Image Generation"),tm.forEach(t),jf=d(We),Pn=a(We,"TD",{align:!0}),n(Pn).forEach(t),We.forEach(t),u.forEach(t),Ar.forEach(t),Wl=d(l),St=a(l,"P",{});var yh=n(St);Sn=a(yh,"STRONG",{});var om=n(Sn);Cf=i(om,"Note"),om.forEach(t),Lf=i(yh,": Pipelines are simple examples of how to play around with the diffusion systems as described in the corresponding papers."),yh.forEach(t),Jl=d(l),we=a(l,"P",{});var Pr=n(we);qf=i(Pr,"However, most of them can be adapted to use different scheduler components or even different model components. Some pipeline examples are shown in the "),ta=a(Pr,"A",{href:!0});var am=n(ta);Rf=i(am,"Examples"),am.forEach(t),Nf=i(Pr," below."),Pr.forEach(t),Kl=d(l),se=a(l,"H2",{class:!0});var Sr=n(se);De=a(Sr,"A",{id:!0,class:!0,href:!0});var nm=n(De);$n=a(nm,"SPAN",{});var lm=n($n);$($t.$$.fragment,lm),lm.forEach(t),nm.forEach(t),Hf=d(Sr),Gn=a(Sr,"SPAN",{});var rm=n(Gn);Uf=i(rm,"Pipelines API"),rm.forEach(t),Sr.forEach(t),Xl=d(l),oa=a(l,"P",{});var im=n(oa);Bf=i(im,"Diffusion models often consist of multiple independently-trained models or other previously existing components."),im.forEach(t),Zl=d(l),ee=a(l,"P",{});var da=n(ee);Yf=i(da,`Each model has been trained independently on a different task and the scheduler can easily be swapped out and replaced with a different one.
During inference, we however want to be able to easily load all components and use them in inference - even if one component, `),On=a(da,"EM",{});var sm=n(On);zf=i(sm,"e.g."),sm.forEach(t),Ff=i(da," CLIP\u2019s text encoder, originates from a different library, such as "),Gt=a(da,"A",{href:!0,rel:!0});var fm=n(Gt);Vf=i(fm,"Transformers"),fm.forEach(t),Qf=i(da,". To that end, all pipelines provide the following functionality:"),da.forEach(t),er=d(l),T=a(l,"UL",{});var Je=n(T);m=a(Je,"LI",{});var g=n(m);Ot=a(g,"A",{href:!0});var wh=n(Ot);Mn=a(wh,"CODE",{});var dm=n(Mn);Wf=i(dm,"from_pretrained"),dm.forEach(t),Jf=i(wh," method"),wh.forEach(t),Kf=i(g," that accepts a Hugging Face Hub repository id, "),jn=a(g,"EM",{});var pm=n(jn);Xf=i(pm,"e.g."),pm.forEach(t),Zf=d(g),Mt=a(g,"A",{href:!0,rel:!0});var hm=n(Mt);ed=i(hm,"runwayml/stable-diffusion-v1-5"),hm.forEach(t),td=i(g," or a path to a local directory, "),Cn=a(g,"EM",{});var cm=n(Cn);od=i(cm,"e.g."),cm.forEach(t),ad=i(g,`
\u201D./stable-diffusion\u201D. To correctly retrieve which models and components should be loaded, one has to provide a `),Ln=a(g,"CODE",{});var um=n(Ln);nd=i(um,"model_index.json"),um.forEach(t),ld=i(g," file, "),qn=a(g,"EM",{});var mm=n(qn);rd=i(mm,"e.g."),mm.forEach(t),id=d(g),jt=a(g,"A",{href:!0,rel:!0});var gm=n(jt);sd=i(gm,"runwayml/stable-diffusion-v1-5/model_index.json"),gm.forEach(t),fd=i(g,`, which defines all components that should be
loaded into the pipelines. More specifically, for each model/component one needs to define the format `),Rn=a(g,"CODE",{});var _m=n(Rn);dd=i(_m,'<name>: ["<library>", "<class name>"]'),_m.forEach(t),pd=i(g,". "),Nn=a(g,"CODE",{});var vm=n(Nn);hd=i(vm,"<name>"),vm.forEach(t),cd=i(g," is the attribute name given to the loaded instance of "),Hn=a(g,"CODE",{});var bm=n(Hn);ud=i(bm,"<class name>"),bm.forEach(t),md=i(g," which can be found in the library or pipeline folder called "),Un=a(g,"CODE",{});var Em=n(Un);gd=i(Em,'"<library>"'),Em.forEach(t),_d=i(g,"."),g.forEach(t),vd=d(Je),_=a(Je,"LI",{});var v=n(_);aa=a(v,"A",{href:!0});var ym=n(aa);Bn=a(ym,"CODE",{});var wm=n(Bn);bd=i(wm,"save_pretrained"),wm.forEach(t),ym.forEach(t),Ed=i(v," that accepts a local path, "),Yn=a(v,"EM",{});var Dm=n(Yn);yd=i(Dm,"e.g."),Dm.forEach(t),wd=d(v),zn=a(v,"CODE",{});var Im=n(zn);Dd=i(Im,"./stable-diffusion"),Im.forEach(t),Id=i(v," under which all models/components of the pipeline will be saved. For each component/model a folder is created inside the local path that is named after the given attribute name, "),Fn=a(v,"EM",{});var Tm=n(Fn);Td=i(Tm,"e.g."),Tm.forEach(t),kd=d(v),Vn=a(v,"CODE",{});var km=n(Vn);xd=i(km,"./stable_diffusion/unet"),km.forEach(t),Ad=i(v,`.
In addition, a `),Qn=a(v,"CODE",{});var xm=n(Qn);Pd=i(xm,"model_index.json"),xm.forEach(t),Sd=i(v," file is created at the root of the local path, "),Wn=a(v,"EM",{});var Am=n(Wn);$d=i(Am,"e.g."),Am.forEach(t),Gd=d(v),Jn=a(v,"CODE",{});var Pm=n(Jn);Od=i(Pm,"./stable_diffusion/model_index.json"),Pm.forEach(t),Md=i(v,` so that the complete pipeline can again be instantiated
from the local path.`),v.forEach(t),jd=d(Je),y=a(Je,"LI",{});var Z=n(y);na=a(Z,"A",{href:!0});var Sm=n(na);Kn=a(Sm,"CODE",{});var $m=n(Kn);Cd=i($m,"to"),$m.forEach(t),Sm.forEach(t),Ld=i(Z," which accepts a "),Xn=a(Z,"CODE",{});var Gm=n(Xn);qd=i(Gm,"string"),Gm.forEach(t),Rd=i(Z," or "),Zn=a(Z,"CODE",{});var Om=n(Zn);Nd=i(Om,"torch.device"),Om.forEach(t),Hd=i(Z," to move all models that are of type "),el=a(Z,"CODE",{});var Mm=n(el);Ud=i(Mm,"torch.nn.Module"),Mm.forEach(t),Bd=i(Z," to the passed device. The behavior is fully analogous to "),fe=a(Z,"A",{href:!0,rel:!0});var $r=n(fe);Yd=i($r,"PyTorch\u2019s "),tl=a($r,"CODE",{});var jm=n(tl);zd=i(jm,"to"),jm.forEach(t),Fd=i($r," method"),$r.forEach(t),Vd=i(Z,"."),Z.forEach(t),Qd=d(Je),E=a(Je,"LI",{});var D=n(E);ol=a(D,"CODE",{});var Cm=n(ol);Wd=i(Cm,"__call__"),Cm.forEach(t),Jd=i(D," method to use the pipeline in inference. "),al=a(D,"CODE",{});var Lm=n(al);Kd=i(Lm,"__call__"),Lm.forEach(t),Xd=i(D," defines inference logic of the pipeline and should ideally encompass all aspects of it, from pre-processing to forwarding tensors to the different models and schedulers, as well as post-processing. The API of the "),nl=a(D,"CODE",{});var qm=n(nl);Zd=i(qm,"__call__"),qm.forEach(t),ep=i(D," method can strongly vary from pipeline to pipeline. "),ll=a(D,"EM",{});var Rm=n(ll);tp=i(Rm,"E.g."),Rm.forEach(t),op=i(D," a text-to-image pipeline, such as "),la=a(D,"A",{href:!0});var Nm=n(la);rl=a(Nm,"CODE",{});var Hm=n(rl);ap=i(Hm,"StableDiffusionPipeline"),Hm.forEach(t),Nm.forEach(t),np=i(D," should accept among other things the text prompt to generate the image. A pure image generation pipeline, such as "),Ct=a(D,"A",{href:!0,rel:!0});var Um=n(Ct);lp=i(Um,"DDPMPipeline"),Um.forEach(t),rp=i(D,` on the other hand can be run without providing any inputs. To better understand what inputs can be adapted for
each pipeline, one should look directly into the respective pipeline.`),D.forEach(t),Je.forEach(t),tr=d(l),k=a(l,"P",{});var Ke=n(k);il=a(Ke,"STRONG",{});var Bm=n(il);ip=i(Bm,"Note"),Bm.forEach(t),sp=i(Ke,": All pipelines have PyTorch\u2019s autograd disabled by decorating the "),sl=a(Ke,"CODE",{});var Ym=n(sl);fp=i(Ym,"__call__"),Ym.forEach(t),dp=i(Ke," method with a "),Lt=a(Ke,"A",{href:!0,rel:!0});var zm=n(Lt);fl=a(zm,"CODE",{});var Fm=n(fl);pp=i(Fm,"torch.no_grad"),Fm.forEach(t),zm.forEach(t),hp=i(Ke,` decorator because pipelines should
not be used for training. If you want to store the gradients during the forward pass, we recommend writing your own pipeline, see also our `),qt=a(Ke,"A",{href:!0,rel:!0});var Vm=n(qt);cp=i(Vm,"community-examples"),Vm.forEach(t),Ke.forEach(t),or=d(l),de=a(l,"H2",{class:!0});var Gr=n(de);Ie=a(Gr,"A",{id:!0,class:!0,href:!0});var Qm=n(Ie);dl=a(Qm,"SPAN",{});var Wm=n(dl);$(Rt.$$.fragment,Wm),Wm.forEach(t),Qm.forEach(t),up=d(Gr),pl=a(Gr,"SPAN",{});var Jm=n(pl);mp=i(Jm,"Contribution"),Jm.forEach(t),Gr.forEach(t),ar=d(l),w=a(l,"P",{});var ne=n(w);gp=i(ne,`We are more than happy about any contribution to the officially supported pipelines \u{1F917}. We aspire
all of our pipelines to be  `),hl=a(ne,"STRONG",{});var Km=n(hl);_p=i(Km,"self-contained"),Km.forEach(t),vp=i(ne,", "),cl=a(ne,"STRONG",{});var Xm=n(cl);bp=i(Xm,"easy-to-tweak"),Xm.forEach(t),Ep=i(ne,", "),ul=a(ne,"STRONG",{});var Zm=n(ul);yp=i(Zm,"beginner-friendly"),Zm.forEach(t),wp=i(ne," and for "),ml=a(ne,"STRONG",{});var eg=n(ml);Dp=i(eg,"one-purpose-only"),eg.forEach(t),Ip=i(ne,"."),ne.forEach(t),nr=d(l),x=a(l,"UL",{});var Xe=n(x);Te=a(Xe,"LI",{});var ql=n(Te);gl=a(ql,"STRONG",{});var tg=n(gl);Tp=i(tg,"Self-contained"),tg.forEach(t),kp=i(ql,": A pipeline shall be as self-contained as possible. More specifically, this means that all functionality should be either directly defined in the pipeline file itself, should be inherited from (and only from) the "),Nt=a(ql,"A",{href:!0});var Dh=n(Nt);_l=a(Dh,"CODE",{});var og=n(_l);xp=i(og,"DiffusionPipeline"),og.forEach(t),Ap=i(Dh," class"),Dh.forEach(t),Pp=i(ql," or be directly attached to the model and scheduler components of the pipeline."),ql.forEach(t),Sp=d(Xe),te=a(Xe,"LI",{});var ao=n(te);vl=a(ao,"STRONG",{});var ag=n(vl);$p=i(ag,"Easy-to-use"),ag.forEach(t),Gp=i(ao,`: Pipelines should be extremely easy to use - one should be able to load the pipeline and
use it for its designated task, `),bl=a(ao,"EM",{});var ng=n(bl);Op=i(ng,"e.g."),ng.forEach(t),Mp=i(ao,` text-to-image generation, in just a couple of lines of code. Most
logic including pre-processing, an unrolled diffusion loop, and post-processing should all happen inside the `),El=a(ao,"CODE",{});var lg=n(El);jp=i(lg,"__call__"),lg.forEach(t),Cp=i(ao," method."),ao.forEach(t),Lp=d(Xe),oe=a(Xe,"LI",{});var no=n(oe);yl=a(no,"STRONG",{});var rg=n(yl);qp=i(rg,"Easy-to-tweak"),rg.forEach(t),Rp=i(no,": Certain pipelines will not be able to handle all use cases and tasks that you might like them to. If you want to use a certain pipeline for a specific use case that is not yet supported, you might have to copy the pipeline file and tweak the code to your needs. We try to make the pipeline code as readable as possible so that each part \u2013from pre-processing to diffusing to post-processing\u2013 can easily be adapted. If you would like the community to benefit from your customized pipeline, we would love to see a contribution to our "),Ht=a(no,"A",{href:!0,rel:!0});var ig=n(Ht);Np=i(ig,"community-examples"),ig.forEach(t),Hp=i(no,". If you feel that an important pipeline should be part of the official pipelines but isn\u2019t, a contribution to the "),ra=a(no,"A",{href:!0});var sg=n(ra);Up=i(sg,"official pipelines"),sg.forEach(t),Bp=i(no," would be even better."),no.forEach(t),Yp=d(Xe),A=a(Xe,"LI",{});var ge=n(A);wl=a(ge,"STRONG",{});var fg=n(wl);zp=i(fg,"One-purpose-only"),fg.forEach(t),Fp=i(ge,": Pipelines should be used for one task and one task only. Even if two tasks are very similar from a modeling point of view, "),Dl=a(ge,"EM",{});var dg=n(Dl);Vp=i(dg,"e.g."),dg.forEach(t),Qp=i(ge," image2image translation and in-painting, pipelines shall be used for one task only to keep them "),Il=a(ge,"EM",{});var pg=n(Il);Wp=i(pg,"easy-to-tweak"),pg.forEach(t),Jp=i(ge," and "),Tl=a(ge,"EM",{});var hg=n(Tl);Kp=i(hg,"readable"),hg.forEach(t),Xp=i(ge,"."),ge.forEach(t),Xe.forEach(t),lr=d(l),pe=a(l,"H2",{class:!0});var Or=n(pe);ke=a(Or,"A",{id:!0,class:!0,href:!0});var cg=n(ke);kl=a(cg,"SPAN",{});var ug=n(kl);$(Ut.$$.fragment,ug),ug.forEach(t),cg.forEach(t),Zp=d(Or),xl=a(Or,"SPAN",{});var mg=n(xl);eh=i(mg,"Examples"),mg.forEach(t),Or.forEach(t),rr=d(l),he=a(l,"H3",{class:!0});var Mr=n(he);xe=a(Mr,"A",{id:!0,class:!0,href:!0});var gg=n(xe);Al=a(gg,"SPAN",{});var _g=n(Al);$(Bt.$$.fragment,_g),_g.forEach(t),gg.forEach(t),th=d(Mr),Pl=a(Mr,"SPAN",{});var vg=n(Pl);oh=i(vg,"Text-to-Image generation with Stable Diffusion"),vg.forEach(t),Mr.forEach(t),ir=d(l),$(Yt.$$.fragment,l),sr=d(l),ce=a(l,"H3",{class:!0});var jr=n(ce);Ae=a(jr,"A",{id:!0,class:!0,href:!0});var bg=n(Ae);Sl=a(bg,"SPAN",{});var Eg=n(Sl);$(zt.$$.fragment,Eg),Eg.forEach(t),bg.forEach(t),ah=d(jr),$l=a(jr,"SPAN",{});var yg=n($l);nh=i(yg,"Image-to-Image text-guided generation with Stable Diffusion"),yg.forEach(t),jr.forEach(t),fr=d(l),Pe=a(l,"P",{});var Cr=n(Pe);lh=i(Cr,"The "),Gl=a(Cr,"CODE",{});var wg=n(Gl);rh=i(wg,"StableDiffusionImg2ImgPipeline"),wg.forEach(t),ih=i(Cr," lets you pass a text prompt and an initial image to condition the generation of new images."),Cr.forEach(t),dr=d(l),$(Ft.$$.fragment,l),pr=d(l),Vt=a(l,"P",{});var Ih=n(Vt);sh=i(Ih,"You can also run this example on colab "),Qt=a(Ih,"A",{href:!0,rel:!0});var Dg=n(Qt);ia=a(Dg,"IMG",{src:!0,alt:!0}),Dg.forEach(t),Ih.forEach(t),hr=d(l),ue=a(l,"H3",{class:!0});var Lr=n(ue);Se=a(Lr,"A",{id:!0,class:!0,href:!0});var Ig=n(Se);Ol=a(Ig,"SPAN",{});var Tg=n(Ol);$(Wt.$$.fragment,Tg),Tg.forEach(t),Ig.forEach(t),fh=d(Lr),Ml=a(Lr,"SPAN",{});var kg=n(Ml);dh=i(kg,"Tweak prompts reusing seeds and latents"),kg.forEach(t),Lr.forEach(t),cr=d(l),ae=a(l,"P",{});var pa=n(ae);ph=i(pa,"You can generate your own latents to reproduce results, or tweak your prompt on a specific result you liked. "),Jt=a(pa,"A",{href:!0,rel:!0});var xg=n(Jt);hh=i(xg,"This notebook"),xg.forEach(t),ch=i(pa," shows how to do it step by step. You can also run it in Google Colab "),Kt=a(pa,"A",{href:!0,rel:!0});var Ag=n(Kt);sa=a(Ag,"IMG",{src:!0,alt:!0}),Ag.forEach(t),uh=i(pa,"."),pa.forEach(t),ur=d(l),me=a(l,"H3",{class:!0});var qr=n(me);$e=a(qr,"A",{id:!0,class:!0,href:!0});var Pg=n($e);jl=a(Pg,"SPAN",{});var Sg=n(jl);$(Xt.$$.fragment,Sg),Sg.forEach(t),Pg.forEach(t),mh=d(qr),Cl=a(qr,"SPAN",{});var $g=n(Cl);gh=i($g,"In-painting using Stable Diffusion"),$g.forEach(t),qr.forEach(t),mr=d(l),Ge=a(l,"P",{});var Rr=n(Ge);_h=i(Rr,"The "),Ll=a(Rr,"CODE",{});var Gg=n(Ll);vh=i(Gg,"StableDiffusionInpaintPipeline"),Gg.forEach(t),bh=i(Rr," lets you edit specific parts of an image by providing a mask and text prompt."),Rr.forEach(t),gr=d(l),$(Zt.$$.fragment,l),_r=d(l),eo=a(l,"P",{});var Th=n(eo);Eh=i(Th,"You can also run this example on colab "),to=a(Th,"A",{href:!0,rel:!0});var Og=n(to);fa=a(Og,"IMG",{src:!0,alt:!0}),Og.forEach(t),Th.forEach(t),this.h()},h(){s(le,"name","hf:doc:metadata"),s(le,"content",JSON.stringify(Hg)),s(ve,"id","pipelines"),s(ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(ve,"href","#pipelines"),s(re,"class","relative group"),s(et,"href","https://huggingface.co/blog/stable_diffusion"),s(et,"rel","nofollow"),s(ro,"href","./api/models#vae"),s(io,"href","./api/models#UNet2DConditionModel"),s(tt,"href","https://huggingface.co/docs/transformers/v4.21.2/en/model_doc/clip#transformers.CLIPTextModel"),s(tt,"rel","nofollow"),s(so,"href","./api/scheduler#pndm"),s(nt,"href","https://huggingface.co/docs/transformers/v4.21.2/en/model_doc/clip#transformers.CLIPFeatureExtractor"),s(nt,"rel","nofollow"),s(fo,"href","./stable_diffusion#safety_checker"),s(rt,"href","https://github.com/huggingface/diffusers/tree/main/src/diffusers/pipelines/latent_diffusion"),s(rt,"rel","nofollow"),s(it,"href","https://arxiv.org/abs/2112.10752"),s(it,"rel","nofollow"),s(co,"href","#pipelines-api"),s(ho,"start","2"),s(mo,"href","#pipelines-summary"),s(uo,"start","3"),s(_o,"href","#contribution"),s(go,"start","4"),s(pt,"href","https://github.com/huggingface/diffusers/tree/main/examples"),s(pt,"rel","nofollow"),s(Ee,"id","diffusers-summary"),s(Ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(Ee,"href","#diffusers-summary"),s(ie,"class","relative group"),s(bo,"align","center"),s(Eo,"align","center"),s(yo,"href","./api/pipelines/cycle_diffusion"),s(ct,"href","https://arxiv.org/abs/2210.05559"),s(ct,"rel","nofollow"),s(wo,"align","center"),s(Ma,"align","center"),s(Do,"href","./api/pipelines/dance_diffusion"),s(ut,"href","https://github.com/williamberman/diffusers.git"),s(ut,"rel","nofollow"),s(Io,"align","center"),s(qa,"align","center"),s(To,"href","./api/pipelines/ddpm"),s(mt,"href","https://arxiv.org/abs/2006.11239"),s(mt,"rel","nofollow"),s(ko,"align","center"),s(Ua,"align","center"),s(xo,"href","./api/pipelines/ddim"),s(gt,"href","https://arxiv.org/abs/2010.02502"),s(gt,"rel","nofollow"),s(Ao,"align","center"),s(Fa,"align","center"),s(Po,"href","./api/pipelines/latent_diffusion"),s(_t,"href","https://arxiv.org/abs/2112.10752"),s(_t,"rel","nofollow"),s(So,"align","center"),s(Ja,"align","center"),s($o,"href","./api/pipelines/latent_diffusion_uncond"),s(vt,"href","https://arxiv.org/abs/2112.10752"),s(vt,"rel","nofollow"),s(Go,"align","center"),s(en,"align","center"),s(Oo,"href","./api/pipelines/pndm"),s(bt,"href","https://arxiv.org/abs/2202.09778"),s(bt,"rel","nofollow"),s(Mo,"align","center"),s(nn,"align","center"),s(jo,"href","./api/pipelines/score_sde_ve"),s(Et,"href","https://openreview.net/forum?id=PxTIG12RRHS"),s(Et,"rel","nofollow"),s(Co,"align","center"),s(fn,"align","center"),s(Lo,"href","./api/pipelines/score_sde_vp"),s(yt,"href","https://openreview.net/forum?id=PxTIG12RRHS"),s(yt,"rel","nofollow"),s(qo,"align","center"),s(cn,"align","center"),s(Ro,"href","./api/pipelines/stable_diffusion"),s(wt,"href","https://stability.ai/blog/stable-diffusion-public-release"),s(wt,"rel","nofollow"),s(No,"align","center"),ha(Uo.src,Ah="https://colab.research.google.com/assets/colab-badge.svg")||s(Uo,"src",Ah),s(Uo,"alt","Open In Colab"),s(Dt,"href","https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/training_example.ipynb"),s(Dt,"rel","nofollow"),s(Ho,"align","center"),s(Bo,"href","./api/pipelines/stable_diffusion"),s(It,"href","https://stability.ai/blog/stable-diffusion-public-release"),s(It,"rel","nofollow"),s(Yo,"align","center"),ha(Fo.src,Ph="https://colab.research.google.com/assets/colab-badge.svg")||s(Fo,"src",Ph),s(Fo,"alt","Open In Colab"),s(Tt,"href","https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/image_2_image_using_diffusers.ipynb"),s(Tt,"rel","nofollow"),s(zo,"align","center"),s(Vo,"href","./api/pipelines/stable_diffusion"),s(kt,"href","https://stability.ai/blog/stable-diffusion-public-release"),s(kt,"rel","nofollow"),s(Qo,"align","center"),ha(Jo.src,Sh="https://colab.research.google.com/assets/colab-badge.svg")||s(Jo,"src",Sh),s(Jo,"alt","Open In Colab"),s(xt,"href","https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/in_painting_with_stable_diffusion_using_diffusers.ipynb"),s(xt,"rel","nofollow"),s(Wo,"align","center"),s(Ko,"href","./api/pipelines/stochastic_karras_ve"),s(At,"href","https://arxiv.org/abs/2206.00364"),s(At,"rel","nofollow"),s(Xo,"align","center"),s(kn,"align","center"),s(Zo,"href","./api/pipelines/vq_diffusion"),s(Pt,"href","https://arxiv.org/abs/2111.14822"),s(Pt,"rel","nofollow"),s(ea,"align","center"),s(Pn,"align","center"),s(ta,"href","#examples"),s(De,"id","pipelines-api"),s(De,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(De,"href","#pipelines-api"),s(se,"class","relative group"),s(Gt,"href","https://github.com/huggingface/transformers"),s(Gt,"rel","nofollow"),s(Ot,"href","../diffusion_pipeline"),s(Mt,"href","https://huggingface.co/runwayml/stable-diffusion-v1-5"),s(Mt,"rel","nofollow"),s(jt,"href","https://huggingface.co/runwayml/stable-diffusion-v1-5/blob/main/model_index.json"),s(jt,"rel","nofollow"),s(aa,"href","../diffusion_pipeline"),s(na,"href","../diffusion_pipeline"),s(fe,"href","https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to"),s(fe,"rel","nofollow"),s(la,"href","./stable_diffusion"),s(Ct,"href","https://github.com/huggingface/diffusers/tree/main/src/diffusers/pipelines/ddpm"),s(Ct,"rel","nofollow"),s(Lt,"href","https://pytorch.org/docs/stable/generated/torch.no_grad.html"),s(Lt,"rel","nofollow"),s(qt,"href","https://github.com/huggingface/diffusers/tree/main/examples/community"),s(qt,"rel","nofollow"),s(Ie,"id","contribution"),s(Ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(Ie,"href","#contribution"),s(de,"class","relative group"),s(Nt,"href",".../diffusion_pipeline"),s(Ht,"href","https://github.com/huggingface/diffusers/tree/main/examples/community"),s(Ht,"rel","nofollow"),s(ra,"href","./overview"),s(ke,"id","examples"),s(ke,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(ke,"href","#examples"),s(pe,"class","relative group"),s(xe,"id","texttoimage-generation-with-stable-diffusion"),s(xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(xe,"href","#texttoimage-generation-with-stable-diffusion"),s(he,"class","relative group"),s(Ae,"id","imagetoimage-textguided-generation-with-stable-diffusion"),s(Ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(Ae,"href","#imagetoimage-textguided-generation-with-stable-diffusion"),s(ce,"class","relative group"),ha(ia.src,$h="https://colab.research.google.com/assets/colab-badge.svg")||s(ia,"src",$h),s(ia,"alt","Open In Colab"),s(Qt,"href","https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/image_2_image_using_diffusers.ipynb"),s(Qt,"rel","nofollow"),s(Se,"id","tweak-prompts-reusing-seeds-and-latents"),s(Se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(Se,"href","#tweak-prompts-reusing-seeds-and-latents"),s(ue,"class","relative group"),s(Jt,"href","https://github.com/pcuenca/diffusers-examples/blob/main/notebooks/stable-diffusion-seeds.ipynb"),s(Jt,"rel","nofollow"),ha(sa.src,Gh="https://colab.research.google.com/assets/colab-badge.svg")||s(sa,"src",Gh),s(sa,"alt","Open In Colab"),s(Kt,"href","https://colab.research.google.com/github/pcuenca/diffusers-examples/blob/main/notebooks/stable-diffusion-seeds.ipynb"),s(Kt,"rel","nofollow"),s($e,"id","inpainting-using-stable-diffusion"),s($e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s($e,"href","#inpainting-using-stable-diffusion"),s(me,"class","relative group"),ha(fa.src,Oh="https://colab.research.google.com/assets/colab-badge.svg")||s(fa,"src",Oh),s(fa,"alt","Open In Colab"),s(to,"href","https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/in_painting_with_stable_diffusion_using_diffusers.ipynb"),s(to,"rel","nofollow")},m(l,p){e(document.head,le),h(l,Rl,p),h(l,re,p),e(re,ve),e(ve,ca),G(Ze,ca,null),e(re,Nr),e(re,ua),e(ua,Hr),h(l,Nl,p),h(l,lo,p),e(lo,Ur),h(l,Hl,p),h(l,be,p),e(be,Br),e(be,et),e(et,Yr),e(be,zr),h(l,Ul,p),h(l,b,p),e(b,ma),e(ma,ro),e(ro,Fr),e(b,Vr),e(b,ga),e(ga,io),e(io,Qr),e(b,Wr),e(b,_a),e(_a,tt),e(tt,Jr),e(b,Kr),e(b,ot),e(ot,Xr),e(ot,so),e(so,Zr),e(ot,ei),e(b,ti),e(b,at),e(at,oi),e(at,nt),e(nt,ai),e(at,ni),e(b,li),e(b,lt),e(lt,ri),e(lt,fo),e(fo,ii),e(lt,si),h(l,Bl,p),h(l,po,p),e(po,fi),h(l,Yl,p),h(l,I,p),e(I,va),e(va,ba),e(ba,C),e(C,di),e(C,Ea),e(Ea,pi),e(C,hi),e(C,rt),e(rt,ci),e(C,ui),e(C,it),e(it,mi),e(C,gi),e(I,_i),e(I,ya),e(ya,ho),e(ho,st),e(st,vi),e(st,co),e(co,bi),e(st,Ei),e(I,yi),e(I,wa),e(wa,uo),e(uo,ft),e(ft,wi),e(ft,mo),e(mo,Di),e(ft,Ii),e(I,Ti),e(I,Da),e(Da,go),e(go,dt),e(dt,ki),e(dt,_o),e(_o,xi),e(dt,Ai),h(l,zl,p),h(l,L,p),e(L,Ia),e(Ia,Pi),e(L,Si),e(L,Ta),e(Ta,$i),e(L,Gi),e(L,pt),e(pt,Oi),e(L,Mi),h(l,Fl,p),h(l,ie,p),e(ie,Ee),e(Ee,ka),G(ht,ka,null),e(ie,ji),e(ie,xa),e(xa,Ci),h(l,Vl,p),h(l,vo,p),e(vo,Li),h(l,Ql,p),h(l,ye,p),e(ye,Aa),e(Aa,q),e(q,Pa),e(Pa,qi),e(q,Ri),e(q,Sa),e(Sa,Ni),e(q,Hi),e(q,bo),e(bo,Ui),e(q,Bi),e(q,Eo),e(Eo,Yi),e(ye,zi),e(ye,c),e(c,R),e(R,$a),e($a,yo),e(yo,Fi),e(R,Vi),e(R,Ga),e(Ga,ct),e(ct,Oa),e(Oa,Qi),e(R,Wi),e(R,wo),e(wo,Ji),e(R,Ki),e(R,Ma),e(c,Xi),e(c,N),e(N,ja),e(ja,Do),e(Do,Zi),e(N,es),e(N,Ca),e(Ca,ut),e(ut,La),e(La,ts),e(N,os),e(N,Io),e(Io,as),e(N,ns),e(N,qa),e(c,ls),e(c,H),e(H,Ra),e(Ra,To),e(To,rs),e(H,is),e(H,Na),e(Na,mt),e(mt,Ha),e(Ha,ss),e(H,fs),e(H,ko),e(ko,ds),e(H,ps),e(H,Ua),e(c,hs),e(c,U),e(U,Ba),e(Ba,xo),e(xo,cs),e(U,us),e(U,Ya),e(Ya,gt),e(gt,za),e(za,ms),e(U,gs),e(U,Ao),e(Ao,_s),e(U,vs),e(U,Fa),e(c,bs),e(c,B),e(B,Va),e(Va,Po),e(Po,Es),e(B,ys),e(B,Qa),e(Qa,_t),e(_t,Wa),e(Wa,ws),e(B,Ds),e(B,So),e(So,Is),e(B,Ts),e(B,Ja),e(c,ks),e(c,Y),e(Y,Ka),e(Ka,$o),e($o,xs),e(Y,As),e(Y,Xa),e(Xa,vt),e(vt,Za),e(Za,Ps),e(Y,Ss),e(Y,Go),e(Go,$s),e(Y,Gs),e(Y,en),e(c,Os),e(c,z),e(z,tn),e(tn,Oo),e(Oo,Ms),e(z,js),e(z,on),e(on,bt),e(bt,an),e(an,Cs),e(z,Ls),e(z,Mo),e(Mo,qs),e(z,Rs),e(z,nn),e(c,Ns),e(c,F),e(F,ln),e(ln,jo),e(jo,Hs),e(F,Us),e(F,rn),e(rn,Et),e(Et,sn),e(sn,Bs),e(F,Ys),e(F,Co),e(Co,zs),e(F,Fs),e(F,fn),e(c,Vs),e(c,V),e(V,dn),e(dn,Lo),e(Lo,Qs),e(V,Ws),e(V,pn),e(pn,yt),e(yt,hn),e(hn,Js),e(V,Ks),e(V,qo),e(qo,Xs),e(V,Zs),e(V,cn),e(c,ef),e(c,Q),e(Q,un),e(un,Ro),e(Ro,tf),e(Q,of),e(Q,mn),e(mn,wt),e(wt,gn),e(gn,af),e(Q,nf),e(Q,No),e(No,lf),e(Q,rf),e(Q,Ho),e(Ho,Dt),e(Dt,Uo),e(c,sf),e(c,W),e(W,_n),e(_n,Bo),e(Bo,ff),e(W,df),e(W,vn),e(vn,It),e(It,bn),e(bn,pf),e(W,hf),e(W,Yo),e(Yo,cf),e(W,uf),e(W,zo),e(zo,Tt),e(Tt,Fo),e(c,mf),e(c,J),e(J,En),e(En,Vo),e(Vo,gf),e(J,_f),e(J,yn),e(yn,kt),e(kt,wn),e(wn,vf),e(J,bf),e(J,Qo),e(Qo,Ef),e(J,yf),e(J,Wo),e(Wo,xt),e(xt,Jo),e(c,wf),e(c,K),e(K,Dn),e(Dn,Ko),e(Ko,Df),e(K,If),e(K,In),e(In,At),e(At,Tn),e(Tn,Tf),e(K,kf),e(K,Xo),e(Xo,xf),e(K,Af),e(K,kn),e(c,Pf),e(c,X),e(X,xn),e(xn,Zo),e(Zo,Sf),e(X,$f),e(X,An),e(An,Pt),e(Pt,Gf),e(X,Of),e(X,ea),e(ea,Mf),e(X,jf),e(X,Pn),h(l,Wl,p),h(l,St,p),e(St,Sn),e(Sn,Cf),e(St,Lf),h(l,Jl,p),h(l,we,p),e(we,qf),e(we,ta),e(ta,Rf),e(we,Nf),h(l,Kl,p),h(l,se,p),e(se,De),e(De,$n),G($t,$n,null),e(se,Hf),e(se,Gn),e(Gn,Uf),h(l,Xl,p),h(l,oa,p),e(oa,Bf),h(l,Zl,p),h(l,ee,p),e(ee,Yf),e(ee,On),e(On,zf),e(ee,Ff),e(ee,Gt),e(Gt,Vf),e(ee,Qf),h(l,er,p),h(l,T,p),e(T,m),e(m,Ot),e(Ot,Mn),e(Mn,Wf),e(Ot,Jf),e(m,Kf),e(m,jn),e(jn,Xf),e(m,Zf),e(m,Mt),e(Mt,ed),e(m,td),e(m,Cn),e(Cn,od),e(m,ad),e(m,Ln),e(Ln,nd),e(m,ld),e(m,qn),e(qn,rd),e(m,id),e(m,jt),e(jt,sd),e(m,fd),e(m,Rn),e(Rn,dd),e(m,pd),e(m,Nn),e(Nn,hd),e(m,cd),e(m,Hn),e(Hn,ud),e(m,md),e(m,Un),e(Un,gd),e(m,_d),e(T,vd),e(T,_),e(_,aa),e(aa,Bn),e(Bn,bd),e(_,Ed),e(_,Yn),e(Yn,yd),e(_,wd),e(_,zn),e(zn,Dd),e(_,Id),e(_,Fn),e(Fn,Td),e(_,kd),e(_,Vn),e(Vn,xd),e(_,Ad),e(_,Qn),e(Qn,Pd),e(_,Sd),e(_,Wn),e(Wn,$d),e(_,Gd),e(_,Jn),e(Jn,Od),e(_,Md),e(T,jd),e(T,y),e(y,na),e(na,Kn),e(Kn,Cd),e(y,Ld),e(y,Xn),e(Xn,qd),e(y,Rd),e(y,Zn),e(Zn,Nd),e(y,Hd),e(y,el),e(el,Ud),e(y,Bd),e(y,fe),e(fe,Yd),e(fe,tl),e(tl,zd),e(fe,Fd),e(y,Vd),e(T,Qd),e(T,E),e(E,ol),e(ol,Wd),e(E,Jd),e(E,al),e(al,Kd),e(E,Xd),e(E,nl),e(nl,Zd),e(E,ep),e(E,ll),e(ll,tp),e(E,op),e(E,la),e(la,rl),e(rl,ap),e(E,np),e(E,Ct),e(Ct,lp),e(E,rp),h(l,tr,p),h(l,k,p),e(k,il),e(il,ip),e(k,sp),e(k,sl),e(sl,fp),e(k,dp),e(k,Lt),e(Lt,fl),e(fl,pp),e(k,hp),e(k,qt),e(qt,cp),h(l,or,p),h(l,de,p),e(de,Ie),e(Ie,dl),G(Rt,dl,null),e(de,up),e(de,pl),e(pl,mp),h(l,ar,p),h(l,w,p),e(w,gp),e(w,hl),e(hl,_p),e(w,vp),e(w,cl),e(cl,bp),e(w,Ep),e(w,ul),e(ul,yp),e(w,wp),e(w,ml),e(ml,Dp),e(w,Ip),h(l,nr,p),h(l,x,p),e(x,Te),e(Te,gl),e(gl,Tp),e(Te,kp),e(Te,Nt),e(Nt,_l),e(_l,xp),e(Nt,Ap),e(Te,Pp),e(x,Sp),e(x,te),e(te,vl),e(vl,$p),e(te,Gp),e(te,bl),e(bl,Op),e(te,Mp),e(te,El),e(El,jp),e(te,Cp),e(x,Lp),e(x,oe),e(oe,yl),e(yl,qp),e(oe,Rp),e(oe,Ht),e(Ht,Np),e(oe,Hp),e(oe,ra),e(ra,Up),e(oe,Bp),e(x,Yp),e(x,A),e(A,wl),e(wl,zp),e(A,Fp),e(A,Dl),e(Dl,Vp),e(A,Qp),e(A,Il),e(Il,Wp),e(A,Jp),e(A,Tl),e(Tl,Kp),e(A,Xp),h(l,lr,p),h(l,pe,p),e(pe,ke),e(ke,kl),G(Ut,kl,null),e(pe,Zp),e(pe,xl),e(xl,eh),h(l,rr,p),h(l,he,p),e(he,xe),e(xe,Al),G(Bt,Al,null),e(he,th),e(he,Pl),e(Pl,oh),h(l,ir,p),G(Yt,l,p),h(l,sr,p),h(l,ce,p),e(ce,Ae),e(Ae,Sl),G(zt,Sl,null),e(ce,ah),e(ce,$l),e($l,nh),h(l,fr,p),h(l,Pe,p),e(Pe,lh),e(Pe,Gl),e(Gl,rh),e(Pe,ih),h(l,dr,p),G(Ft,l,p),h(l,pr,p),h(l,Vt,p),e(Vt,sh),e(Vt,Qt),e(Qt,ia),h(l,hr,p),h(l,ue,p),e(ue,Se),e(Se,Ol),G(Wt,Ol,null),e(ue,fh),e(ue,Ml),e(Ml,dh),h(l,cr,p),h(l,ae,p),e(ae,ph),e(ae,Jt),e(Jt,hh),e(ae,ch),e(ae,Kt),e(Kt,sa),e(ae,uh),h(l,ur,p),h(l,me,p),e(me,$e),e($e,jl),G(Xt,jl,null),e(me,mh),e(me,Cl),e(Cl,gh),h(l,mr,p),h(l,Ge,p),e(Ge,_h),e(Ge,Ll),e(Ll,vh),e(Ge,bh),h(l,gr,p),G(Zt,l,p),h(l,_r,p),h(l,eo,p),e(eo,Eh),e(eo,to),e(to,fa),vr=!0},p:qg,i(l){vr||(O(Ze.$$.fragment,l),O(ht.$$.fragment,l),O($t.$$.fragment,l),O(Rt.$$.fragment,l),O(Ut.$$.fragment,l),O(Bt.$$.fragment,l),O(Yt.$$.fragment,l),O(zt.$$.fragment,l),O(Ft.$$.fragment,l),O(Wt.$$.fragment,l),O(Xt.$$.fragment,l),O(Zt.$$.fragment,l),vr=!0)},o(l){M(Ze.$$.fragment,l),M(ht.$$.fragment,l),M($t.$$.fragment,l),M(Rt.$$.fragment,l),M(Ut.$$.fragment,l),M(Bt.$$.fragment,l),M(Yt.$$.fragment,l),M(zt.$$.fragment,l),M(Ft.$$.fragment,l),M(Wt.$$.fragment,l),M(Xt.$$.fragment,l),M(Zt.$$.fragment,l),vr=!1},d(l){t(le),l&&t(Rl),l&&t(re),j(Ze),l&&t(Nl),l&&t(lo),l&&t(Hl),l&&t(be),l&&t(Ul),l&&t(b),l&&t(Bl),l&&t(po),l&&t(Yl),l&&t(I),l&&t(zl),l&&t(L),l&&t(Fl),l&&t(ie),j(ht),l&&t(Vl),l&&t(vo),l&&t(Ql),l&&t(ye),l&&t(Wl),l&&t(St),l&&t(Jl),l&&t(we),l&&t(Kl),l&&t(se),j($t),l&&t(Xl),l&&t(oa),l&&t(Zl),l&&t(ee),l&&t(er),l&&t(T),l&&t(tr),l&&t(k),l&&t(or),l&&t(de),j(Rt),l&&t(ar),l&&t(w),l&&t(nr),l&&t(x),l&&t(lr),l&&t(pe),j(Ut),l&&t(rr),l&&t(he),j(Bt),l&&t(ir),j(Yt,l),l&&t(sr),l&&t(ce),j(zt),l&&t(fr),l&&t(Pe),l&&t(dr),j(Ft,l),l&&t(pr),l&&t(Vt),l&&t(hr),l&&t(ue),j(Wt),l&&t(cr),l&&t(ae),l&&t(ur),l&&t(me),j(Xt),l&&t(mr),l&&t(Ge),l&&t(gr),j(Zt,l),l&&t(_r),l&&t(eo)}}}const Hg={local:"pipelines",sections:[{local:"diffusers-summary",title:"\u{1F9E8} Diffusers Summary"},{local:"pipelines-api",title:"Pipelines API"},{local:"contribution",title:"Contribution"},{local:"examples",sections:[{local:"texttoimage-generation-with-stable-diffusion",title:"Text-to-Image generation with Stable Diffusion"},{local:"imagetoimage-textguided-generation-with-stable-diffusion",title:"Image-to-Image text-guided generation with Stable Diffusion"},{local:"tweak-prompts-reusing-seeds-and-latents",title:"Tweak prompts reusing seeds and latents"},{local:"inpainting-using-stable-diffusion",title:"In-painting using Stable Diffusion"}],title:"Examples"}],title:"Pipelines"};function Ug(xh){return Rg(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Fg extends Mg{constructor(le){super();jg(this,le,Ug,Ng,Cg,{})}}export{Fg as default,Hg as metadata};
