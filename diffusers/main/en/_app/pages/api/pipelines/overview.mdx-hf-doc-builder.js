import{S as n_,i as r_,s as l_,e as o,k as f,w as S,t as l,M as i_,c as a,d as t,m as d,a as n,x as $,h as i,b as s,N as va,G as e,g as p,y as G,L as s_,q as O,o as M,B as j,v as f_}from"../../../chunks/vendor-hf-doc-builder.js";import{I as ve}from"../../../chunks/IconCopyLink-hf-doc-builder.js";import{C as Bp}from"../../../chunks/CodeBlock-hf-doc-builder.js";function d_(Yp){let le,Qr,ie,be,ba,tt,Wl,Ea,Jl,Wr,so,Kl,Jr,Ee,Xl,ot,Zl,ei,Kr,b,ya,fo,ti,oi,wa,ho,ai,ni,Da,at,ri,li,nt,ii,po,si,fi,di,rt,hi,lt,pi,ci,ui,it,mi,co,gi,_i,Xr,uo,vi,Zr,I,Ia,Ta,C,bi,ka,Ei,yi,st,wi,Di,ft,Ii,Ti,ki,xa,mo,dt,xi,go,Ai,Pi,Si,Aa,_o,ht,$i,vo,Gi,Oi,Mi,Pa,bo,pt,ji,Eo,Ci,Li,el,L,Sa,Ri,qi,$a,Ni,Hi,ct,Ui,Bi,tl,se,ye,Ga,ut,Yi,Oa,zi,ol,yo,Fi,al,we,Ma,R,ja,Vi,Qi,Ca,Wi,Ji,wo,Ki,Xi,Do,Zi,es,c,q,La,Io,ts,os,Ra,mt,qa,as,ns,To,rs,ls,ko,is,ss,N,Na,xo,fs,ds,Ha,gt,Ua,hs,ps,Ao,cs,us,Ba,ms,H,Ya,Po,gs,_s,za,_t,Fa,vs,bs,So,Es,ys,Va,ws,U,Qa,$o,Ds,Is,Wa,vt,Ja,Ts,ks,Go,xs,As,Ka,Ps,B,Xa,Oo,Ss,$s,Za,bt,en,Gs,Os,Mo,Ms,js,tn,Cs,Y,on,jo,Ls,Rs,an,Et,nn,qs,Ns,Co,Hs,Us,rn,Bs,z,ln,Lo,Ys,zs,sn,yt,fn,Fs,Vs,Ro,Qs,Ws,dn,Js,F,hn,qo,Ks,Xs,pn,wt,cn,Zs,ef,No,tf,of,un,af,V,mn,Ho,nf,rf,gn,Dt,_n,lf,sf,Uo,ff,df,vn,hf,Q,bn,Bo,pf,cf,En,It,yn,uf,mf,Yo,gf,_f,wn,vf,W,Dn,zo,bf,Ef,In,Tt,Tn,yf,wf,Fo,Df,If,Vo,kt,Qo,zp,Tf,J,kn,Wo,kf,xf,xn,xt,An,Af,Pf,Jo,Sf,$f,Ko,At,Xo,Fp,Gf,K,Pn,Zo,Of,Mf,Sn,Pt,$n,jf,Cf,ea,Lf,Rf,ta,St,oa,Vp,qf,X,Gn,aa,Nf,Hf,On,$t,Mn,Uf,Bf,na,Yf,zf,jn,Ff,Z,Cn,ra,Vf,Qf,Ln,Gt,Wf,Jf,la,Kf,Xf,Rn,nl,Ot,qn,Zf,ed,rl,De,td,ia,od,ad,ll,fe,Ie,Nn,Mt,nd,Hn,rd,il,sa,ld,sl,te,id,Un,sd,fd,jt,dd,hd,fl,T,m,Ct,Bn,pd,cd,ud,Yn,md,gd,Lt,_d,vd,zn,bd,Ed,Fn,yd,wd,Vn,Dd,Id,Rt,Td,kd,Qn,xd,Ad,Wn,Pd,Sd,Jn,$d,Gd,Kn,Od,Md,jd,_,fa,Xn,Cd,Ld,Zn,Rd,qd,er,Nd,Hd,tr,Ud,Bd,or,Yd,zd,ar,Fd,Vd,nr,Qd,Wd,rr,Jd,Kd,Xd,y,da,lr,Zd,eh,ir,th,oh,sr,ah,nh,fr,rh,lh,de,ih,dr,sh,fh,dh,hh,E,hr,ph,ch,pr,uh,mh,cr,gh,_h,ur,vh,bh,ha,mr,Eh,yh,qt,wh,Dh,dl,k,gr,Ih,Th,_r,kh,xh,Nt,vr,Ah,Ph,Ht,Sh,hl,he,Te,br,Ut,$h,Er,Gh,pl,w,Oh,yr,Mh,jh,wr,Ch,Lh,Dr,Rh,qh,Ir,Nh,Hh,cl,x,ke,Tr,Uh,Bh,Bt,kr,Yh,zh,Fh,Vh,oe,xr,Qh,Wh,Ar,Jh,Kh,Pr,Xh,Zh,ep,ae,Sr,tp,op,Yt,ap,np,pa,rp,lp,ip,A,$r,sp,fp,Gr,dp,hp,Or,pp,cp,Mr,up,mp,ul,pe,xe,jr,zt,gp,Cr,_p,ml,ce,Ae,Lr,Ft,vp,Rr,bp,gl,Vt,_l,ue,Pe,qr,Qt,Ep,Nr,yp,vl,Se,wp,Hr,Dp,Ip,bl,Wt,El,Jt,Tp,Kt,ca,Qp,yl,me,$e,Ur,Xt,kp,Br,xp,wl,ne,Ap,Zt,Pp,Sp,eo,ua,Wp,$p,Dl,ge,Ge,Yr,to,Gp,zr,Op,Il,Oe,Mp,Fr,jp,Cp,Tl,oo,kl,ao,Lp,no,ma,Jp,xl;return tt=new ve({}),ut=new ve({}),Mt=new ve({}),Ut=new ve({}),zt=new ve({}),Ft=new ve({}),Vt=new Bp({props:{code:`# make sure you're logged in with \`huggingface-cli login\`
from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler

pipe = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")
pipe = pipe.to("cuda")

prompt = "a photo of an astronaut riding a horse on mars"
image = pipe(prompt).images[0]

image.save("astronaut_rides_horse.png")`,highlighted:`<span class="hljs-comment"># make sure you&#x27;re logged in with \`huggingface-cli login\`</span>
<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionPipeline, LMSDiscreteScheduler

pipe = StableDiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>)
pipe = pipe.to(<span class="hljs-string">&quot;cuda&quot;</span>)

prompt = <span class="hljs-string">&quot;a photo of an astronaut riding a horse on mars&quot;</span>
image = pipe(prompt).images[<span class="hljs-number">0</span>]

image.save(<span class="hljs-string">&quot;astronaut_rides_horse.png&quot;</span>)`}}),Qt=new ve({}),Wt=new Bp({props:{code:`import requests
from PIL import Image
from io import BytesIO

from diffusers import StableDiffusionImg2ImgPipeline

# load the pipeline
device = "cuda"
pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5", revision="fp16", torch_dtype=torch.float16
).to(device)

# let's download an initial image
url = "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg"

response = requests.get(url)
init_image = Image.open(BytesIO(response.content)).convert("RGB")
init_image = init_image.resize((768, 512))

prompt = "A fantasy landscape, trending on artstation"

images = pipe(prompt=prompt, init_image=init_image, strength=0.75, guidance_scale=7.5).images

images[0].save("fantasy_landscape.png")`,highlighted:`<span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-keyword">from</span> io <span class="hljs-keyword">import</span> BytesIO

<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionImg2ImgPipeline

<span class="hljs-comment"># load the pipeline</span>
device = <span class="hljs-string">&quot;cuda&quot;</span>
pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
    <span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>, revision=<span class="hljs-string">&quot;fp16&quot;</span>, torch_dtype=torch.float16
).to(device)

<span class="hljs-comment"># let&#x27;s download an initial image</span>
url = <span class="hljs-string">&quot;https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg&quot;</span>

response = requests.get(url)
init_image = Image.<span class="hljs-built_in">open</span>(BytesIO(response.content)).convert(<span class="hljs-string">&quot;RGB&quot;</span>)
init_image = init_image.resize((<span class="hljs-number">768</span>, <span class="hljs-number">512</span>))

prompt = <span class="hljs-string">&quot;A fantasy landscape, trending on artstation&quot;</span>

images = pipe(prompt=prompt, init_image=init_image, strength=<span class="hljs-number">0.75</span>, guidance_scale=<span class="hljs-number">7.5</span>).images

images[<span class="hljs-number">0</span>].save(<span class="hljs-string">&quot;fantasy_landscape.png&quot;</span>)`}}),Xt=new ve({}),to=new ve({}),oo=new Bp({props:{code:`import PIL
import requests
import torch
from io import BytesIO

from diffusers import StableDiffusionInpaintPipeline


def download_image(url):
    response = requests.get(url)
    return PIL.Image.open(BytesIO(response.content)).convert("RGB")


img_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
mask_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"

init_image = download_image(img_url).resize((512, 512))
mask_image = download_image(mask_url).resize((512, 512))

pipe = StableDiffusionInpaintPipeline.from_pretrained(
    "runwayml/stable-diffusion-inpainting",
    revision="fp16",
    torch_dtype=torch.float16,
)
pipe = pipe.to("cuda")

prompt = "Face of a yellow cat, high resolution, sitting on a park bench"
image = pipe(prompt=prompt, image=init_image, mask_image=mask_image).images[0]`,highlighted:`<span class="hljs-keyword">import</span> PIL
<span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> io <span class="hljs-keyword">import</span> BytesIO

<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionInpaintPipeline


<span class="hljs-keyword">def</span> <span class="hljs-title function_">download_image</span>(<span class="hljs-params">url</span>):
    response = requests.get(url)
    <span class="hljs-keyword">return</span> PIL.Image.<span class="hljs-built_in">open</span>(BytesIO(response.content)).convert(<span class="hljs-string">&quot;RGB&quot;</span>)


img_url = <span class="hljs-string">&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png&quot;</span>
mask_url = <span class="hljs-string">&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png&quot;</span>

init_image = download_image(img_url).resize((<span class="hljs-number">512</span>, <span class="hljs-number">512</span>))
mask_image = download_image(mask_url).resize((<span class="hljs-number">512</span>, <span class="hljs-number">512</span>))

pipe = StableDiffusionInpaintPipeline.from_pretrained(
    <span class="hljs-string">&quot;runwayml/stable-diffusion-inpainting&quot;</span>,
    revision=<span class="hljs-string">&quot;fp16&quot;</span>,
    torch_dtype=torch.float16,
)
pipe = pipe.to(<span class="hljs-string">&quot;cuda&quot;</span>)

prompt = <span class="hljs-string">&quot;Face of a yellow cat, high resolution, sitting on a park bench&quot;</span>
image = pipe(prompt=prompt, image=init_image, mask_image=mask_image).images[<span class="hljs-number">0</span>]`}}),{c(){le=o("meta"),Qr=f(),ie=o("h1"),be=o("a"),ba=o("span"),S(tt.$$.fragment),Wl=f(),Ea=o("span"),Jl=l("Pipelines"),Wr=f(),so=o("p"),Kl=l(`Pipelines provide a simple way to run state-of-the-art diffusion models in inference.
Most diffusion systems consist of multiple independently-trained models and highly adaptable scheduler
components - all of which are needed to have a functioning end-to-end diffusion system.`),Jr=f(),Ee=o("p"),Xl=l("As an example, "),ot=o("a"),Zl=l("Stable Diffusion"),ei=l(" has three independently trained models:"),Kr=f(),b=o("ul"),ya=o("li"),fo=o("a"),ti=l("Autoencoder"),oi=f(),wa=o("li"),ho=o("a"),ai=l("Conditional Unet"),ni=f(),Da=o("li"),at=o("a"),ri=l("CLIP text encoder"),li=f(),nt=o("li"),ii=l("a scheduler component, "),po=o("a"),si=l("scheduler"),fi=l(","),di=f(),rt=o("li"),hi=l("a "),lt=o("a"),pi=l("CLIPFeatureExtractor"),ci=l(","),ui=f(),it=o("li"),mi=l("as well as a "),co=o("a"),gi=l("safety checker"),_i=l(`.
All of these components are necessary to run stable diffusion in inference even though they were trained
or created independently from each other.`),Xr=f(),uo=o("p"),vi=l(`To that end, we strive to offer all open-sourced, state-of-the-art diffusion system under a unified API.
More specifically, we strive to provide pipelines that`),Zr=f(),I=o("ul"),Ia=o("li"),Ta=o("ol"),C=o("li"),bi=l("can load the officially published weights and yield 1-to-1 the same outputs as the original implementation according to the corresponding paper ("),ka=o("em"),Ei=l("e.g."),yi=f(),st=o("a"),wi=l("LDMTextToImagePipeline"),Di=l(", uses the officially released weights of "),ft=o("a"),Ii=l("High-Resolution Image Synthesis with Latent Diffusion Models"),Ti=l("),"),ki=f(),xa=o("li"),mo=o("ol"),dt=o("li"),xi=l("have a simple user interface to run the model in inference (see the "),go=o("a"),Ai=l("Pipelines API"),Pi=l(" section),"),Si=f(),Aa=o("li"),_o=o("ol"),ht=o("li"),$i=l("are easy to understand with code that is self-explanatory and can be read along-side the official paper (see "),vo=o("a"),Gi=l("Pipelines summary"),Oi=l("),"),Mi=f(),Pa=o("li"),bo=o("ol"),pt=o("li"),ji=l("can easily be contributed by the community (see the "),Eo=o("a"),Ci=l("Contribution"),Li=l(" section)."),el=f(),L=o("p"),Sa=o("strong"),Ri=l("Note"),qi=l(` that pipelines do not (and should not) offer any training functionality.
If you are looking for `),$a=o("em"),Ni=l("official"),Hi=l(" training examples, please have a look at "),ct=o("a"),Ui=l("examples"),Bi=l("."),tl=f(),se=o("h2"),ye=o("a"),Ga=o("span"),S(ut.$$.fragment),Yi=f(),Oa=o("span"),zi=l("\u{1F9E8} Diffusers Summary"),ol=f(),yo=o("p"),Fi=l(`The following table summarizes all officially supported pipelines, their corresponding paper, and if
available a colab notebook to directly try them out.`),al=f(),we=o("table"),Ma=o("thead"),R=o("tr"),ja=o("th"),Vi=l("Pipeline"),Qi=f(),Ca=o("th"),Wi=l("Paper"),Ji=f(),wo=o("th"),Ki=l("Tasks"),Xi=f(),Do=o("th"),Zi=l("Colab"),es=f(),c=o("tbody"),q=o("tr"),La=o("td"),Io=o("a"),ts=l("alt_diffusion"),os=f(),Ra=o("td"),mt=o("a"),qa=o("strong"),as=l("AltDiffusion"),ns=f(),To=o("td"),rs=l("Image-to-Image Text-Guided Generation"),ls=f(),ko=o("td"),is=l("-"),ss=f(),N=o("tr"),Na=o("td"),xo=o("a"),fs=l("cycle_diffusion"),ds=f(),Ha=o("td"),gt=o("a"),Ua=o("strong"),hs=l("Cycle Diffusion"),ps=f(),Ao=o("td"),cs=l("Image-to-Image Text-Guided Generation"),us=f(),Ba=o("td"),ms=f(),H=o("tr"),Ya=o("td"),Po=o("a"),gs=l("dance_diffusion"),_s=f(),za=o("td"),_t=o("a"),Fa=o("strong"),vs=l("Dance Diffusion"),bs=f(),So=o("td"),Es=l("Unconditional Audio Generation"),ys=f(),Va=o("td"),ws=f(),U=o("tr"),Qa=o("td"),$o=o("a"),Ds=l("ddpm"),Is=f(),Wa=o("td"),vt=o("a"),Ja=o("strong"),Ts=l("Denoising Diffusion Probabilistic Models"),ks=f(),Go=o("td"),xs=l("Unconditional Image Generation"),As=f(),Ka=o("td"),Ps=f(),B=o("tr"),Xa=o("td"),Oo=o("a"),Ss=l("ddim"),$s=f(),Za=o("td"),bt=o("a"),en=o("strong"),Gs=l("Denoising Diffusion Implicit Models"),Os=f(),Mo=o("td"),Ms=l("Unconditional Image Generation"),js=f(),tn=o("td"),Cs=f(),Y=o("tr"),on=o("td"),jo=o("a"),Ls=l("latent_diffusion"),Rs=f(),an=o("td"),Et=o("a"),nn=o("strong"),qs=l("High-Resolution Image Synthesis with Latent Diffusion Models"),Ns=f(),Co=o("td"),Hs=l("Text-to-Image Generation"),Us=f(),rn=o("td"),Bs=f(),z=o("tr"),ln=o("td"),Lo=o("a"),Ys=l("latent_diffusion_uncond"),zs=f(),sn=o("td"),yt=o("a"),fn=o("strong"),Fs=l("High-Resolution Image Synthesis with Latent Diffusion Models"),Vs=f(),Ro=o("td"),Qs=l("Unconditional Image Generation"),Ws=f(),dn=o("td"),Js=f(),F=o("tr"),hn=o("td"),qo=o("a"),Ks=l("pndm"),Xs=f(),pn=o("td"),wt=o("a"),cn=o("strong"),Zs=l("Pseudo Numerical Methods for Diffusion Models on Manifolds"),ef=f(),No=o("td"),tf=l("Unconditional Image Generation"),of=f(),un=o("td"),af=f(),V=o("tr"),mn=o("td"),Ho=o("a"),nf=l("score_sde_ve"),rf=f(),gn=o("td"),Dt=o("a"),_n=o("strong"),lf=l("Score-Based Generative Modeling through Stochastic Differential Equations"),sf=f(),Uo=o("td"),ff=l("Unconditional Image Generation"),df=f(),vn=o("td"),hf=f(),Q=o("tr"),bn=o("td"),Bo=o("a"),pf=l("score_sde_vp"),cf=f(),En=o("td"),It=o("a"),yn=o("strong"),uf=l("Score-Based Generative Modeling through Stochastic Differential Equations"),mf=f(),Yo=o("td"),gf=l("Unconditional Image Generation"),_f=f(),wn=o("td"),vf=f(),W=o("tr"),Dn=o("td"),zo=o("a"),bf=l("stable_diffusion"),Ef=f(),In=o("td"),Tt=o("a"),Tn=o("strong"),yf=l("Stable Diffusion"),wf=f(),Fo=o("td"),Df=l("Text-to-Image Generation"),If=f(),Vo=o("td"),kt=o("a"),Qo=o("img"),Tf=f(),J=o("tr"),kn=o("td"),Wo=o("a"),kf=l("stable_diffusion"),xf=f(),xn=o("td"),xt=o("a"),An=o("strong"),Af=l("Stable Diffusion"),Pf=f(),Jo=o("td"),Sf=l("Image-to-Image Text-Guided Generation"),$f=f(),Ko=o("td"),At=o("a"),Xo=o("img"),Gf=f(),K=o("tr"),Pn=o("td"),Zo=o("a"),Of=l("stable_diffusion"),Mf=f(),Sn=o("td"),Pt=o("a"),$n=o("strong"),jf=l("Stable Diffusion"),Cf=f(),ea=o("td"),Lf=l("Text-Guided Image Inpainting"),Rf=f(),ta=o("td"),St=o("a"),oa=o("img"),qf=f(),X=o("tr"),Gn=o("td"),aa=o("a"),Nf=l("stochastic_karras_ve"),Hf=f(),On=o("td"),$t=o("a"),Mn=o("strong"),Uf=l("Elucidating the Design Space of Diffusion-Based Generative Models"),Bf=f(),na=o("td"),Yf=l("Unconditional Image Generation"),zf=f(),jn=o("td"),Ff=f(),Z=o("tr"),Cn=o("td"),ra=o("a"),Vf=l("vq_diffusion"),Qf=f(),Ln=o("td"),Gt=o("a"),Wf=l("Vector Quantized Diffusion Model for Text-to-Image Synthesis"),Jf=f(),la=o("td"),Kf=l("Text-to-Image Generation"),Xf=f(),Rn=o("td"),nl=f(),Ot=o("p"),qn=o("strong"),Zf=l("Note"),ed=l(": Pipelines are simple examples of how to play around with the diffusion systems as described in the corresponding papers."),rl=f(),De=o("p"),td=l("However, most of them can be adapted to use different scheduler components or even different model components. Some pipeline examples are shown in the "),ia=o("a"),od=l("Examples"),ad=l(" below."),ll=f(),fe=o("h2"),Ie=o("a"),Nn=o("span"),S(Mt.$$.fragment),nd=f(),Hn=o("span"),rd=l("Pipelines API"),il=f(),sa=o("p"),ld=l("Diffusion models often consist of multiple independently-trained models or other previously existing components."),sl=f(),te=o("p"),id=l(`Each model has been trained independently on a different task and the scheduler can easily be swapped out and replaced with a different one.
During inference, we however want to be able to easily load all components and use them in inference - even if one component, `),Un=o("em"),sd=l("e.g."),fd=l(" CLIP\u2019s text encoder, originates from a different library, such as "),jt=o("a"),dd=l("Transformers"),hd=l(". To that end, all pipelines provide the following functionality:"),fl=f(),T=o("ul"),m=o("li"),Ct=o("a"),Bn=o("code"),pd=l("from_pretrained"),cd=l(" method"),ud=l(" that accepts a Hugging Face Hub repository id, "),Yn=o("em"),md=l("e.g."),gd=f(),Lt=o("a"),_d=l("runwayml/stable-diffusion-v1-5"),vd=l(" or a path to a local directory, "),zn=o("em"),bd=l("e.g."),Ed=l(`
\u201D./stable-diffusion\u201D. To correctly retrieve which models and components should be loaded, one has to provide a `),Fn=o("code"),yd=l("model_index.json"),wd=l(" file, "),Vn=o("em"),Dd=l("e.g."),Id=f(),Rt=o("a"),Td=l("runwayml/stable-diffusion-v1-5/model_index.json"),kd=l(`, which defines all components that should be
loaded into the pipelines. More specifically, for each model/component one needs to define the format `),Qn=o("code"),xd=l('<name>: ["<library>", "<class name>"]'),Ad=l(". "),Wn=o("code"),Pd=l("<name>"),Sd=l(" is the attribute name given to the loaded instance of "),Jn=o("code"),$d=l("<class name>"),Gd=l(" which can be found in the library or pipeline folder called "),Kn=o("code"),Od=l('"<library>"'),Md=l("."),jd=f(),_=o("li"),fa=o("a"),Xn=o("code"),Cd=l("save_pretrained"),Ld=l(" that accepts a local path, "),Zn=o("em"),Rd=l("e.g."),qd=f(),er=o("code"),Nd=l("./stable-diffusion"),Hd=l(" under which all models/components of the pipeline will be saved. For each component/model a folder is created inside the local path that is named after the given attribute name, "),tr=o("em"),Ud=l("e.g."),Bd=f(),or=o("code"),Yd=l("./stable_diffusion/unet"),zd=l(`.
In addition, a `),ar=o("code"),Fd=l("model_index.json"),Vd=l(" file is created at the root of the local path, "),nr=o("em"),Qd=l("e.g."),Wd=f(),rr=o("code"),Jd=l("./stable_diffusion/model_index.json"),Kd=l(` so that the complete pipeline can again be instantiated
from the local path.`),Xd=f(),y=o("li"),da=o("a"),lr=o("code"),Zd=l("to"),eh=l(" which accepts a "),ir=o("code"),th=l("string"),oh=l(" or "),sr=o("code"),ah=l("torch.device"),nh=l(" to move all models that are of type "),fr=o("code"),rh=l("torch.nn.Module"),lh=l(" to the passed device. The behavior is fully analogous to "),de=o("a"),ih=l("PyTorch\u2019s "),dr=o("code"),sh=l("to"),fh=l(" method"),dh=l("."),hh=f(),E=o("li"),hr=o("code"),ph=l("__call__"),ch=l(" method to use the pipeline in inference. "),pr=o("code"),uh=l("__call__"),mh=l(" defines inference logic of the pipeline and should ideally encompass all aspects of it, from pre-processing to forwarding tensors to the different models and schedulers, as well as post-processing. The API of the "),cr=o("code"),gh=l("__call__"),_h=l(" method can strongly vary from pipeline to pipeline. "),ur=o("em"),vh=l("E.g."),bh=l(" a text-to-image pipeline, such as "),ha=o("a"),mr=o("code"),Eh=l("StableDiffusionPipeline"),yh=l(" should accept among other things the text prompt to generate the image. A pure image generation pipeline, such as "),qt=o("a"),wh=l("DDPMPipeline"),Dh=l(` on the other hand can be run without providing any inputs. To better understand what inputs can be adapted for
each pipeline, one should look directly into the respective pipeline.`),dl=f(),k=o("p"),gr=o("strong"),Ih=l("Note"),Th=l(": All pipelines have PyTorch\u2019s autograd disabled by decorating the "),_r=o("code"),kh=l("__call__"),xh=l(" method with a "),Nt=o("a"),vr=o("code"),Ah=l("torch.no_grad"),Ph=l(` decorator because pipelines should
not be used for training. If you want to store the gradients during the forward pass, we recommend writing your own pipeline, see also our `),Ht=o("a"),Sh=l("community-examples"),hl=f(),he=o("h2"),Te=o("a"),br=o("span"),S(Ut.$$.fragment),$h=f(),Er=o("span"),Gh=l("Contribution"),pl=f(),w=o("p"),Oh=l(`We are more than happy about any contribution to the officially supported pipelines \u{1F917}. We aspire
all of our pipelines to be  `),yr=o("strong"),Mh=l("self-contained"),jh=l(", "),wr=o("strong"),Ch=l("easy-to-tweak"),Lh=l(", "),Dr=o("strong"),Rh=l("beginner-friendly"),qh=l(" and for "),Ir=o("strong"),Nh=l("one-purpose-only"),Hh=l("."),cl=f(),x=o("ul"),ke=o("li"),Tr=o("strong"),Uh=l("Self-contained"),Bh=l(": A pipeline shall be as self-contained as possible. More specifically, this means that all functionality should be either directly defined in the pipeline file itself, should be inherited from (and only from) the "),Bt=o("a"),kr=o("code"),Yh=l("DiffusionPipeline"),zh=l(" class"),Fh=l(" or be directly attached to the model and scheduler components of the pipeline."),Vh=f(),oe=o("li"),xr=o("strong"),Qh=l("Easy-to-use"),Wh=l(`: Pipelines should be extremely easy to use - one should be able to load the pipeline and
use it for its designated task, `),Ar=o("em"),Jh=l("e.g."),Kh=l(` text-to-image generation, in just a couple of lines of code. Most
logic including pre-processing, an unrolled diffusion loop, and post-processing should all happen inside the `),Pr=o("code"),Xh=l("__call__"),Zh=l(" method."),ep=f(),ae=o("li"),Sr=o("strong"),tp=l("Easy-to-tweak"),op=l(": Certain pipelines will not be able to handle all use cases and tasks that you might like them to. If you want to use a certain pipeline for a specific use case that is not yet supported, you might have to copy the pipeline file and tweak the code to your needs. We try to make the pipeline code as readable as possible so that each part \u2013from pre-processing to diffusing to post-processing\u2013 can easily be adapted. If you would like the community to benefit from your customized pipeline, we would love to see a contribution to our "),Yt=o("a"),ap=l("community-examples"),np=l(". If you feel that an important pipeline should be part of the official pipelines but isn\u2019t, a contribution to the "),pa=o("a"),rp=l("official pipelines"),lp=l(" would be even better."),ip=f(),A=o("li"),$r=o("strong"),sp=l("One-purpose-only"),fp=l(": Pipelines should be used for one task and one task only. Even if two tasks are very similar from a modeling point of view, "),Gr=o("em"),dp=l("e.g."),hp=l(" image2image translation and in-painting, pipelines shall be used for one task only to keep them "),Or=o("em"),pp=l("easy-to-tweak"),cp=l(" and "),Mr=o("em"),up=l("readable"),mp=l("."),ul=f(),pe=o("h2"),xe=o("a"),jr=o("span"),S(zt.$$.fragment),gp=f(),Cr=o("span"),_p=l("Examples"),ml=f(),ce=o("h3"),Ae=o("a"),Lr=o("span"),S(Ft.$$.fragment),vp=f(),Rr=o("span"),bp=l("Text-to-Image generation with Stable Diffusion"),gl=f(),S(Vt.$$.fragment),_l=f(),ue=o("h3"),Pe=o("a"),qr=o("span"),S(Qt.$$.fragment),Ep=f(),Nr=o("span"),yp=l("Image-to-Image text-guided generation with Stable Diffusion"),vl=f(),Se=o("p"),wp=l("The "),Hr=o("code"),Dp=l("StableDiffusionImg2ImgPipeline"),Ip=l(" lets you pass a text prompt and an initial image to condition the generation of new images."),bl=f(),S(Wt.$$.fragment),El=f(),Jt=o("p"),Tp=l("You can also run this example on colab "),Kt=o("a"),ca=o("img"),yl=f(),me=o("h3"),$e=o("a"),Ur=o("span"),S(Xt.$$.fragment),kp=f(),Br=o("span"),xp=l("Tweak prompts reusing seeds and latents"),wl=f(),ne=o("p"),Ap=l("You can generate your own latents to reproduce results, or tweak your prompt on a specific result you liked. "),Zt=o("a"),Pp=l("This notebook"),Sp=l(" shows how to do it step by step. You can also run it in Google Colab "),eo=o("a"),ua=o("img"),$p=l("."),Dl=f(),ge=o("h3"),Ge=o("a"),Yr=o("span"),S(to.$$.fragment),Gp=f(),zr=o("span"),Op=l("In-painting using Stable Diffusion"),Il=f(),Oe=o("p"),Mp=l("The "),Fr=o("code"),jp=l("StableDiffusionInpaintPipeline"),Cp=l(" lets you edit specific parts of an image by providing a mask and text prompt."),Tl=f(),S(oo.$$.fragment),kl=f(),ao=o("p"),Lp=l("You can also run this example on colab "),no=o("a"),ma=o("img"),this.h()},l(r){const h=i_('[data-svelte="svelte-1phssyn"]',document.head);le=a(h,"META",{name:!0,content:!0}),h.forEach(t),Qr=d(r),ie=a(r,"H1",{class:!0});var Al=n(ie);be=a(Al,"A",{id:!0,class:!0,href:!0});var Kp=n(be);ba=a(Kp,"SPAN",{});var Xp=n(ba);$(tt.$$.fragment,Xp),Xp.forEach(t),Kp.forEach(t),Wl=d(Al),Ea=a(Al,"SPAN",{});var Zp=n(Ea);Jl=i(Zp,"Pipelines"),Zp.forEach(t),Al.forEach(t),Wr=d(r),so=a(r,"P",{});var ec=n(so);Kl=i(ec,`Pipelines provide a simple way to run state-of-the-art diffusion models in inference.
Most diffusion systems consist of multiple independently-trained models and highly adaptable scheduler
components - all of which are needed to have a functioning end-to-end diffusion system.`),ec.forEach(t),Jr=d(r),Ee=a(r,"P",{});var Pl=n(Ee);Xl=i(Pl,"As an example, "),ot=a(Pl,"A",{href:!0,rel:!0});var tc=n(ot);Zl=i(tc,"Stable Diffusion"),tc.forEach(t),ei=i(Pl," has three independently trained models:"),Pl.forEach(t),Kr=d(r),b=a(r,"UL",{});var P=n(b);ya=a(P,"LI",{});var oc=n(ya);fo=a(oc,"A",{href:!0});var ac=n(fo);ti=i(ac,"Autoencoder"),ac.forEach(t),oc.forEach(t),oi=d(P),wa=a(P,"LI",{});var nc=n(wa);ho=a(nc,"A",{href:!0});var rc=n(ho);ai=i(rc,"Conditional Unet"),rc.forEach(t),nc.forEach(t),ni=d(P),Da=a(P,"LI",{});var lc=n(Da);at=a(lc,"A",{href:!0,rel:!0});var ic=n(at);ri=i(ic,"CLIP text encoder"),ic.forEach(t),lc.forEach(t),li=d(P),nt=a(P,"LI",{});var Sl=n(nt);ii=i(Sl,"a scheduler component, "),po=a(Sl,"A",{href:!0});var sc=n(po);si=i(sc,"scheduler"),sc.forEach(t),fi=i(Sl,","),Sl.forEach(t),di=d(P),rt=a(P,"LI",{});var $l=n(rt);hi=i($l,"a "),lt=a($l,"A",{href:!0,rel:!0});var fc=n(lt);pi=i(fc,"CLIPFeatureExtractor"),fc.forEach(t),ci=i($l,","),$l.forEach(t),ui=d(P),it=a(P,"LI",{});var Gl=n(it);mi=i(Gl,"as well as a "),co=a(Gl,"A",{href:!0});var dc=n(co);gi=i(dc,"safety checker"),dc.forEach(t),_i=i(Gl,`.
All of these components are necessary to run stable diffusion in inference even though they were trained
or created independently from each other.`),Gl.forEach(t),P.forEach(t),Xr=d(r),uo=a(r,"P",{});var hc=n(uo);vi=i(hc,`To that end, we strive to offer all open-sourced, state-of-the-art diffusion system under a unified API.
More specifically, we strive to provide pipelines that`),hc.forEach(t),Zr=d(r),I=a(r,"UL",{});var Me=n(I);Ia=a(Me,"LI",{});var pc=n(Ia);Ta=a(pc,"OL",{});var cc=n(Ta);C=a(cc,"LI",{});var je=n(C);bi=i(je,"can load the officially published weights and yield 1-to-1 the same outputs as the original implementation according to the corresponding paper ("),ka=a(je,"EM",{});var uc=n(ka);Ei=i(uc,"e.g."),uc.forEach(t),yi=d(je),st=a(je,"A",{href:!0,rel:!0});var mc=n(st);wi=i(mc,"LDMTextToImagePipeline"),mc.forEach(t),Di=i(je,", uses the officially released weights of "),ft=a(je,"A",{href:!0,rel:!0});var gc=n(ft);Ii=i(gc,"High-Resolution Image Synthesis with Latent Diffusion Models"),gc.forEach(t),Ti=i(je,"),"),je.forEach(t),cc.forEach(t),pc.forEach(t),ki=d(Me),xa=a(Me,"LI",{});var _c=n(xa);mo=a(_c,"OL",{start:!0});var vc=n(mo);dt=a(vc,"LI",{});var Ol=n(dt);xi=i(Ol,"have a simple user interface to run the model in inference (see the "),go=a(Ol,"A",{href:!0});var bc=n(go);Ai=i(bc,"Pipelines API"),bc.forEach(t),Pi=i(Ol," section),"),Ol.forEach(t),vc.forEach(t),_c.forEach(t),Si=d(Me),Aa=a(Me,"LI",{});var Ec=n(Aa);_o=a(Ec,"OL",{start:!0});var yc=n(_o);ht=a(yc,"LI",{});var Ml=n(ht);$i=i(Ml,"are easy to understand with code that is self-explanatory and can be read along-side the official paper (see "),vo=a(Ml,"A",{href:!0});var wc=n(vo);Gi=i(wc,"Pipelines summary"),wc.forEach(t),Oi=i(Ml,"),"),Ml.forEach(t),yc.forEach(t),Ec.forEach(t),Mi=d(Me),Pa=a(Me,"LI",{});var Dc=n(Pa);bo=a(Dc,"OL",{start:!0});var Ic=n(bo);pt=a(Ic,"LI",{});var jl=n(pt);ji=i(jl,"can easily be contributed by the community (see the "),Eo=a(jl,"A",{href:!0});var Tc=n(Eo);Ci=i(Tc,"Contribution"),Tc.forEach(t),Li=i(jl," section)."),jl.forEach(t),Ic.forEach(t),Dc.forEach(t),Me.forEach(t),el=d(r),L=a(r,"P",{});var ro=n(L);Sa=a(ro,"STRONG",{});var kc=n(Sa);Ri=i(kc,"Note"),kc.forEach(t),qi=i(ro,` that pipelines do not (and should not) offer any training functionality.
If you are looking for `),$a=a(ro,"EM",{});var xc=n($a);Ni=i(xc,"official"),xc.forEach(t),Hi=i(ro," training examples, please have a look at "),ct=a(ro,"A",{href:!0,rel:!0});var Ac=n(ct);Ui=i(Ac,"examples"),Ac.forEach(t),Bi=i(ro,"."),ro.forEach(t),tl=d(r),se=a(r,"H2",{class:!0});var Cl=n(se);ye=a(Cl,"A",{id:!0,class:!0,href:!0});var Pc=n(ye);Ga=a(Pc,"SPAN",{});var Sc=n(Ga);$(ut.$$.fragment,Sc),Sc.forEach(t),Pc.forEach(t),Yi=d(Cl),Oa=a(Cl,"SPAN",{});var $c=n(Oa);zi=i($c,"\u{1F9E8} Diffusers Summary"),$c.forEach(t),Cl.forEach(t),ol=d(r),yo=a(r,"P",{});var Gc=n(yo);Fi=i(Gc,`The following table summarizes all officially supported pipelines, their corresponding paper, and if
available a colab notebook to directly try them out.`),Gc.forEach(t),al=d(r),we=a(r,"TABLE",{});var Ll=n(we);Ma=a(Ll,"THEAD",{});var Oc=n(Ma);R=a(Oc,"TR",{});var Ce=n(R);ja=a(Ce,"TH",{});var Mc=n(ja);Vi=i(Mc,"Pipeline"),Mc.forEach(t),Qi=d(Ce),Ca=a(Ce,"TH",{});var jc=n(Ca);Wi=i(jc,"Paper"),jc.forEach(t),Ji=d(Ce),wo=a(Ce,"TH",{align:!0});var Cc=n(wo);Ki=i(Cc,"Tasks"),Cc.forEach(t),Xi=d(Ce),Do=a(Ce,"TH",{align:!0});var Lc=n(Do);Zi=i(Lc,"Colab"),Lc.forEach(t),Ce.forEach(t),Oc.forEach(t),es=d(Ll),c=a(Ll,"TBODY",{});var u=n(c);q=a(u,"TR",{});var Le=n(q);La=a(Le,"TD",{});var Rc=n(La);Io=a(Rc,"A",{href:!0});var qc=n(Io);ts=i(qc,"alt_diffusion"),qc.forEach(t),Rc.forEach(t),os=d(Le),Ra=a(Le,"TD",{});var Nc=n(Ra);mt=a(Nc,"A",{href:!0,rel:!0});var Hc=n(mt);qa=a(Hc,"STRONG",{});var Uc=n(qa);as=i(Uc,"AltDiffusion"),Uc.forEach(t),Hc.forEach(t),Nc.forEach(t),ns=d(Le),To=a(Le,"TD",{align:!0});var Bc=n(To);rs=i(Bc,"Image-to-Image Text-Guided Generation"),Bc.forEach(t),ls=d(Le),ko=a(Le,"TD",{align:!0});var Yc=n(ko);is=i(Yc,"-"),Yc.forEach(t),Le.forEach(t),ss=d(u),N=a(u,"TR",{});var Re=n(N);Na=a(Re,"TD",{});var zc=n(Na);xo=a(zc,"A",{href:!0});var Fc=n(xo);fs=i(Fc,"cycle_diffusion"),Fc.forEach(t),zc.forEach(t),ds=d(Re),Ha=a(Re,"TD",{});var Vc=n(Ha);gt=a(Vc,"A",{href:!0,rel:!0});var Qc=n(gt);Ua=a(Qc,"STRONG",{});var Wc=n(Ua);hs=i(Wc,"Cycle Diffusion"),Wc.forEach(t),Qc.forEach(t),Vc.forEach(t),ps=d(Re),Ao=a(Re,"TD",{align:!0});var Jc=n(Ao);cs=i(Jc,"Image-to-Image Text-Guided Generation"),Jc.forEach(t),us=d(Re),Ba=a(Re,"TD",{align:!0}),n(Ba).forEach(t),Re.forEach(t),ms=d(u),H=a(u,"TR",{});var qe=n(H);Ya=a(qe,"TD",{});var Kc=n(Ya);Po=a(Kc,"A",{href:!0});var Xc=n(Po);gs=i(Xc,"dance_diffusion"),Xc.forEach(t),Kc.forEach(t),_s=d(qe),za=a(qe,"TD",{});var Zc=n(za);_t=a(Zc,"A",{href:!0,rel:!0});var eu=n(_t);Fa=a(eu,"STRONG",{});var tu=n(Fa);vs=i(tu,"Dance Diffusion"),tu.forEach(t),eu.forEach(t),Zc.forEach(t),bs=d(qe),So=a(qe,"TD",{align:!0});var ou=n(So);Es=i(ou,"Unconditional Audio Generation"),ou.forEach(t),ys=d(qe),Va=a(qe,"TD",{align:!0}),n(Va).forEach(t),qe.forEach(t),ws=d(u),U=a(u,"TR",{});var Ne=n(U);Qa=a(Ne,"TD",{});var au=n(Qa);$o=a(au,"A",{href:!0});var nu=n($o);Ds=i(nu,"ddpm"),nu.forEach(t),au.forEach(t),Is=d(Ne),Wa=a(Ne,"TD",{});var ru=n(Wa);vt=a(ru,"A",{href:!0,rel:!0});var lu=n(vt);Ja=a(lu,"STRONG",{});var iu=n(Ja);Ts=i(iu,"Denoising Diffusion Probabilistic Models"),iu.forEach(t),lu.forEach(t),ru.forEach(t),ks=d(Ne),Go=a(Ne,"TD",{align:!0});var su=n(Go);xs=i(su,"Unconditional Image Generation"),su.forEach(t),As=d(Ne),Ka=a(Ne,"TD",{align:!0}),n(Ka).forEach(t),Ne.forEach(t),Ps=d(u),B=a(u,"TR",{});var He=n(B);Xa=a(He,"TD",{});var fu=n(Xa);Oo=a(fu,"A",{href:!0});var du=n(Oo);Ss=i(du,"ddim"),du.forEach(t),fu.forEach(t),$s=d(He),Za=a(He,"TD",{});var hu=n(Za);bt=a(hu,"A",{href:!0,rel:!0});var pu=n(bt);en=a(pu,"STRONG",{});var cu=n(en);Gs=i(cu,"Denoising Diffusion Implicit Models"),cu.forEach(t),pu.forEach(t),hu.forEach(t),Os=d(He),Mo=a(He,"TD",{align:!0});var uu=n(Mo);Ms=i(uu,"Unconditional Image Generation"),uu.forEach(t),js=d(He),tn=a(He,"TD",{align:!0}),n(tn).forEach(t),He.forEach(t),Cs=d(u),Y=a(u,"TR",{});var Ue=n(Y);on=a(Ue,"TD",{});var mu=n(on);jo=a(mu,"A",{href:!0});var gu=n(jo);Ls=i(gu,"latent_diffusion"),gu.forEach(t),mu.forEach(t),Rs=d(Ue),an=a(Ue,"TD",{});var _u=n(an);Et=a(_u,"A",{href:!0,rel:!0});var vu=n(Et);nn=a(vu,"STRONG",{});var bu=n(nn);qs=i(bu,"High-Resolution Image Synthesis with Latent Diffusion Models"),bu.forEach(t),vu.forEach(t),_u.forEach(t),Ns=d(Ue),Co=a(Ue,"TD",{align:!0});var Eu=n(Co);Hs=i(Eu,"Text-to-Image Generation"),Eu.forEach(t),Us=d(Ue),rn=a(Ue,"TD",{align:!0}),n(rn).forEach(t),Ue.forEach(t),Bs=d(u),z=a(u,"TR",{});var Be=n(z);ln=a(Be,"TD",{});var yu=n(ln);Lo=a(yu,"A",{href:!0});var wu=n(Lo);Ys=i(wu,"latent_diffusion_uncond"),wu.forEach(t),yu.forEach(t),zs=d(Be),sn=a(Be,"TD",{});var Du=n(sn);yt=a(Du,"A",{href:!0,rel:!0});var Iu=n(yt);fn=a(Iu,"STRONG",{});var Tu=n(fn);Fs=i(Tu,"High-Resolution Image Synthesis with Latent Diffusion Models"),Tu.forEach(t),Iu.forEach(t),Du.forEach(t),Vs=d(Be),Ro=a(Be,"TD",{align:!0});var ku=n(Ro);Qs=i(ku,"Unconditional Image Generation"),ku.forEach(t),Ws=d(Be),dn=a(Be,"TD",{align:!0}),n(dn).forEach(t),Be.forEach(t),Js=d(u),F=a(u,"TR",{});var Ye=n(F);hn=a(Ye,"TD",{});var xu=n(hn);qo=a(xu,"A",{href:!0});var Au=n(qo);Ks=i(Au,"pndm"),Au.forEach(t),xu.forEach(t),Xs=d(Ye),pn=a(Ye,"TD",{});var Pu=n(pn);wt=a(Pu,"A",{href:!0,rel:!0});var Su=n(wt);cn=a(Su,"STRONG",{});var $u=n(cn);Zs=i($u,"Pseudo Numerical Methods for Diffusion Models on Manifolds"),$u.forEach(t),Su.forEach(t),Pu.forEach(t),ef=d(Ye),No=a(Ye,"TD",{align:!0});var Gu=n(No);tf=i(Gu,"Unconditional Image Generation"),Gu.forEach(t),of=d(Ye),un=a(Ye,"TD",{align:!0}),n(un).forEach(t),Ye.forEach(t),af=d(u),V=a(u,"TR",{});var ze=n(V);mn=a(ze,"TD",{});var Ou=n(mn);Ho=a(Ou,"A",{href:!0});var Mu=n(Ho);nf=i(Mu,"score_sde_ve"),Mu.forEach(t),Ou.forEach(t),rf=d(ze),gn=a(ze,"TD",{});var ju=n(gn);Dt=a(ju,"A",{href:!0,rel:!0});var Cu=n(Dt);_n=a(Cu,"STRONG",{});var Lu=n(_n);lf=i(Lu,"Score-Based Generative Modeling through Stochastic Differential Equations"),Lu.forEach(t),Cu.forEach(t),ju.forEach(t),sf=d(ze),Uo=a(ze,"TD",{align:!0});var Ru=n(Uo);ff=i(Ru,"Unconditional Image Generation"),Ru.forEach(t),df=d(ze),vn=a(ze,"TD",{align:!0}),n(vn).forEach(t),ze.forEach(t),hf=d(u),Q=a(u,"TR",{});var Fe=n(Q);bn=a(Fe,"TD",{});var qu=n(bn);Bo=a(qu,"A",{href:!0});var Nu=n(Bo);pf=i(Nu,"score_sde_vp"),Nu.forEach(t),qu.forEach(t),cf=d(Fe),En=a(Fe,"TD",{});var Hu=n(En);It=a(Hu,"A",{href:!0,rel:!0});var Uu=n(It);yn=a(Uu,"STRONG",{});var Bu=n(yn);uf=i(Bu,"Score-Based Generative Modeling through Stochastic Differential Equations"),Bu.forEach(t),Uu.forEach(t),Hu.forEach(t),mf=d(Fe),Yo=a(Fe,"TD",{align:!0});var Yu=n(Yo);gf=i(Yu,"Unconditional Image Generation"),Yu.forEach(t),_f=d(Fe),wn=a(Fe,"TD",{align:!0}),n(wn).forEach(t),Fe.forEach(t),vf=d(u),W=a(u,"TR",{});var Ve=n(W);Dn=a(Ve,"TD",{});var zu=n(Dn);zo=a(zu,"A",{href:!0});var Fu=n(zo);bf=i(Fu,"stable_diffusion"),Fu.forEach(t),zu.forEach(t),Ef=d(Ve),In=a(Ve,"TD",{});var Vu=n(In);Tt=a(Vu,"A",{href:!0,rel:!0});var Qu=n(Tt);Tn=a(Qu,"STRONG",{});var Wu=n(Tn);yf=i(Wu,"Stable Diffusion"),Wu.forEach(t),Qu.forEach(t),Vu.forEach(t),wf=d(Ve),Fo=a(Ve,"TD",{align:!0});var Ju=n(Fo);Df=i(Ju,"Text-to-Image Generation"),Ju.forEach(t),If=d(Ve),Vo=a(Ve,"TD",{align:!0});var Ku=n(Vo);kt=a(Ku,"A",{href:!0,rel:!0});var Xu=n(kt);Qo=a(Xu,"IMG",{src:!0,alt:!0}),Xu.forEach(t),Ku.forEach(t),Ve.forEach(t),Tf=d(u),J=a(u,"TR",{});var Qe=n(J);kn=a(Qe,"TD",{});var Zu=n(kn);Wo=a(Zu,"A",{href:!0});var em=n(Wo);kf=i(em,"stable_diffusion"),em.forEach(t),Zu.forEach(t),xf=d(Qe),xn=a(Qe,"TD",{});var tm=n(xn);xt=a(tm,"A",{href:!0,rel:!0});var om=n(xt);An=a(om,"STRONG",{});var am=n(An);Af=i(am,"Stable Diffusion"),am.forEach(t),om.forEach(t),tm.forEach(t),Pf=d(Qe),Jo=a(Qe,"TD",{align:!0});var nm=n(Jo);Sf=i(nm,"Image-to-Image Text-Guided Generation"),nm.forEach(t),$f=d(Qe),Ko=a(Qe,"TD",{align:!0});var rm=n(Ko);At=a(rm,"A",{href:!0,rel:!0});var lm=n(At);Xo=a(lm,"IMG",{src:!0,alt:!0}),lm.forEach(t),rm.forEach(t),Qe.forEach(t),Gf=d(u),K=a(u,"TR",{});var We=n(K);Pn=a(We,"TD",{});var im=n(Pn);Zo=a(im,"A",{href:!0});var sm=n(Zo);Of=i(sm,"stable_diffusion"),sm.forEach(t),im.forEach(t),Mf=d(We),Sn=a(We,"TD",{});var fm=n(Sn);Pt=a(fm,"A",{href:!0,rel:!0});var dm=n(Pt);$n=a(dm,"STRONG",{});var hm=n($n);jf=i(hm,"Stable Diffusion"),hm.forEach(t),dm.forEach(t),fm.forEach(t),Cf=d(We),ea=a(We,"TD",{align:!0});var pm=n(ea);Lf=i(pm,"Text-Guided Image Inpainting"),pm.forEach(t),Rf=d(We),ta=a(We,"TD",{align:!0});var cm=n(ta);St=a(cm,"A",{href:!0,rel:!0});var um=n(St);oa=a(um,"IMG",{src:!0,alt:!0}),um.forEach(t),cm.forEach(t),We.forEach(t),qf=d(u),X=a(u,"TR",{});var Je=n(X);Gn=a(Je,"TD",{});var mm=n(Gn);aa=a(mm,"A",{href:!0});var gm=n(aa);Nf=i(gm,"stochastic_karras_ve"),gm.forEach(t),mm.forEach(t),Hf=d(Je),On=a(Je,"TD",{});var _m=n(On);$t=a(_m,"A",{href:!0,rel:!0});var vm=n($t);Mn=a(vm,"STRONG",{});var bm=n(Mn);Uf=i(bm,"Elucidating the Design Space of Diffusion-Based Generative Models"),bm.forEach(t),vm.forEach(t),_m.forEach(t),Bf=d(Je),na=a(Je,"TD",{align:!0});var Em=n(na);Yf=i(Em,"Unconditional Image Generation"),Em.forEach(t),zf=d(Je),jn=a(Je,"TD",{align:!0}),n(jn).forEach(t),Je.forEach(t),Ff=d(u),Z=a(u,"TR",{});var Ke=n(Z);Cn=a(Ke,"TD",{});var ym=n(Cn);ra=a(ym,"A",{href:!0});var wm=n(ra);Vf=i(wm,"vq_diffusion"),wm.forEach(t),ym.forEach(t),Qf=d(Ke),Ln=a(Ke,"TD",{});var Dm=n(Ln);Gt=a(Dm,"A",{href:!0,rel:!0});var Im=n(Gt);Wf=i(Im,"Vector Quantized Diffusion Model for Text-to-Image Synthesis"),Im.forEach(t),Dm.forEach(t),Jf=d(Ke),la=a(Ke,"TD",{align:!0});var Tm=n(la);Kf=i(Tm,"Text-to-Image Generation"),Tm.forEach(t),Xf=d(Ke),Rn=a(Ke,"TD",{align:!0}),n(Rn).forEach(t),Ke.forEach(t),u.forEach(t),Ll.forEach(t),nl=d(r),Ot=a(r,"P",{});var Rp=n(Ot);qn=a(Rp,"STRONG",{});var km=n(qn);Zf=i(km,"Note"),km.forEach(t),ed=i(Rp,": Pipelines are simple examples of how to play around with the diffusion systems as described in the corresponding papers."),Rp.forEach(t),rl=d(r),De=a(r,"P",{});var Rl=n(De);td=i(Rl,"However, most of them can be adapted to use different scheduler components or even different model components. Some pipeline examples are shown in the "),ia=a(Rl,"A",{href:!0});var xm=n(ia);od=i(xm,"Examples"),xm.forEach(t),ad=i(Rl," below."),Rl.forEach(t),ll=d(r),fe=a(r,"H2",{class:!0});var ql=n(fe);Ie=a(ql,"A",{id:!0,class:!0,href:!0});var Am=n(Ie);Nn=a(Am,"SPAN",{});var Pm=n(Nn);$(Mt.$$.fragment,Pm),Pm.forEach(t),Am.forEach(t),nd=d(ql),Hn=a(ql,"SPAN",{});var Sm=n(Hn);rd=i(Sm,"Pipelines API"),Sm.forEach(t),ql.forEach(t),il=d(r),sa=a(r,"P",{});var $m=n(sa);ld=i($m,"Diffusion models often consist of multiple independently-trained models or other previously existing components."),$m.forEach(t),sl=d(r),te=a(r,"P",{});var ga=n(te);id=i(ga,`Each model has been trained independently on a different task and the scheduler can easily be swapped out and replaced with a different one.
During inference, we however want to be able to easily load all components and use them in inference - even if one component, `),Un=a(ga,"EM",{});var Gm=n(Un);sd=i(Gm,"e.g."),Gm.forEach(t),fd=i(ga," CLIP\u2019s text encoder, originates from a different library, such as "),jt=a(ga,"A",{href:!0,rel:!0});var Om=n(jt);dd=i(Om,"Transformers"),Om.forEach(t),hd=i(ga,". To that end, all pipelines provide the following functionality:"),ga.forEach(t),fl=d(r),T=a(r,"UL",{});var Xe=n(T);m=a(Xe,"LI",{});var g=n(m);Ct=a(g,"A",{href:!0});var qp=n(Ct);Bn=a(qp,"CODE",{});var Mm=n(Bn);pd=i(Mm,"from_pretrained"),Mm.forEach(t),cd=i(qp," method"),qp.forEach(t),ud=i(g," that accepts a Hugging Face Hub repository id, "),Yn=a(g,"EM",{});var jm=n(Yn);md=i(jm,"e.g."),jm.forEach(t),gd=d(g),Lt=a(g,"A",{href:!0,rel:!0});var Cm=n(Lt);_d=i(Cm,"runwayml/stable-diffusion-v1-5"),Cm.forEach(t),vd=i(g," or a path to a local directory, "),zn=a(g,"EM",{});var Lm=n(zn);bd=i(Lm,"e.g."),Lm.forEach(t),Ed=i(g,`
\u201D./stable-diffusion\u201D. To correctly retrieve which models and components should be loaded, one has to provide a `),Fn=a(g,"CODE",{});var Rm=n(Fn);yd=i(Rm,"model_index.json"),Rm.forEach(t),wd=i(g," file, "),Vn=a(g,"EM",{});var qm=n(Vn);Dd=i(qm,"e.g."),qm.forEach(t),Id=d(g),Rt=a(g,"A",{href:!0,rel:!0});var Nm=n(Rt);Td=i(Nm,"runwayml/stable-diffusion-v1-5/model_index.json"),Nm.forEach(t),kd=i(g,`, which defines all components that should be
loaded into the pipelines. More specifically, for each model/component one needs to define the format `),Qn=a(g,"CODE",{});var Hm=n(Qn);xd=i(Hm,'<name>: ["<library>", "<class name>"]'),Hm.forEach(t),Ad=i(g,". "),Wn=a(g,"CODE",{});var Um=n(Wn);Pd=i(Um,"<name>"),Um.forEach(t),Sd=i(g," is the attribute name given to the loaded instance of "),Jn=a(g,"CODE",{});var Bm=n(Jn);$d=i(Bm,"<class name>"),Bm.forEach(t),Gd=i(g," which can be found in the library or pipeline folder called "),Kn=a(g,"CODE",{});var Ym=n(Kn);Od=i(Ym,'"<library>"'),Ym.forEach(t),Md=i(g,"."),g.forEach(t),jd=d(Xe),_=a(Xe,"LI",{});var v=n(_);fa=a(v,"A",{href:!0});var zm=n(fa);Xn=a(zm,"CODE",{});var Fm=n(Xn);Cd=i(Fm,"save_pretrained"),Fm.forEach(t),zm.forEach(t),Ld=i(v," that accepts a local path, "),Zn=a(v,"EM",{});var Vm=n(Zn);Rd=i(Vm,"e.g."),Vm.forEach(t),qd=d(v),er=a(v,"CODE",{});var Qm=n(er);Nd=i(Qm,"./stable-diffusion"),Qm.forEach(t),Hd=i(v," under which all models/components of the pipeline will be saved. For each component/model a folder is created inside the local path that is named after the given attribute name, "),tr=a(v,"EM",{});var Wm=n(tr);Ud=i(Wm,"e.g."),Wm.forEach(t),Bd=d(v),or=a(v,"CODE",{});var Jm=n(or);Yd=i(Jm,"./stable_diffusion/unet"),Jm.forEach(t),zd=i(v,`.
In addition, a `),ar=a(v,"CODE",{});var Km=n(ar);Fd=i(Km,"model_index.json"),Km.forEach(t),Vd=i(v," file is created at the root of the local path, "),nr=a(v,"EM",{});var Xm=n(nr);Qd=i(Xm,"e.g."),Xm.forEach(t),Wd=d(v),rr=a(v,"CODE",{});var Zm=n(rr);Jd=i(Zm,"./stable_diffusion/model_index.json"),Zm.forEach(t),Kd=i(v,` so that the complete pipeline can again be instantiated
from the local path.`),v.forEach(t),Xd=d(Xe),y=a(Xe,"LI",{});var ee=n(y);da=a(ee,"A",{href:!0});var eg=n(da);lr=a(eg,"CODE",{});var tg=n(lr);Zd=i(tg,"to"),tg.forEach(t),eg.forEach(t),eh=i(ee," which accepts a "),ir=a(ee,"CODE",{});var og=n(ir);th=i(og,"string"),og.forEach(t),oh=i(ee," or "),sr=a(ee,"CODE",{});var ag=n(sr);ah=i(ag,"torch.device"),ag.forEach(t),nh=i(ee," to move all models that are of type "),fr=a(ee,"CODE",{});var ng=n(fr);rh=i(ng,"torch.nn.Module"),ng.forEach(t),lh=i(ee," to the passed device. The behavior is fully analogous to "),de=a(ee,"A",{href:!0,rel:!0});var Nl=n(de);ih=i(Nl,"PyTorch\u2019s "),dr=a(Nl,"CODE",{});var rg=n(dr);sh=i(rg,"to"),rg.forEach(t),fh=i(Nl," method"),Nl.forEach(t),dh=i(ee,"."),ee.forEach(t),hh=d(Xe),E=a(Xe,"LI",{});var D=n(E);hr=a(D,"CODE",{});var lg=n(hr);ph=i(lg,"__call__"),lg.forEach(t),ch=i(D," method to use the pipeline in inference. "),pr=a(D,"CODE",{});var ig=n(pr);uh=i(ig,"__call__"),ig.forEach(t),mh=i(D," defines inference logic of the pipeline and should ideally encompass all aspects of it, from pre-processing to forwarding tensors to the different models and schedulers, as well as post-processing. The API of the "),cr=a(D,"CODE",{});var sg=n(cr);gh=i(sg,"__call__"),sg.forEach(t),_h=i(D," method can strongly vary from pipeline to pipeline. "),ur=a(D,"EM",{});var fg=n(ur);vh=i(fg,"E.g."),fg.forEach(t),bh=i(D," a text-to-image pipeline, such as "),ha=a(D,"A",{href:!0});var dg=n(ha);mr=a(dg,"CODE",{});var hg=n(mr);Eh=i(hg,"StableDiffusionPipeline"),hg.forEach(t),dg.forEach(t),yh=i(D," should accept among other things the text prompt to generate the image. A pure image generation pipeline, such as "),qt=a(D,"A",{href:!0,rel:!0});var pg=n(qt);wh=i(pg,"DDPMPipeline"),pg.forEach(t),Dh=i(D,` on the other hand can be run without providing any inputs. To better understand what inputs can be adapted for
each pipeline, one should look directly into the respective pipeline.`),D.forEach(t),Xe.forEach(t),dl=d(r),k=a(r,"P",{});var Ze=n(k);gr=a(Ze,"STRONG",{});var cg=n(gr);Ih=i(cg,"Note"),cg.forEach(t),Th=i(Ze,": All pipelines have PyTorch\u2019s autograd disabled by decorating the "),_r=a(Ze,"CODE",{});var ug=n(_r);kh=i(ug,"__call__"),ug.forEach(t),xh=i(Ze," method with a "),Nt=a(Ze,"A",{href:!0,rel:!0});var mg=n(Nt);vr=a(mg,"CODE",{});var gg=n(vr);Ah=i(gg,"torch.no_grad"),gg.forEach(t),mg.forEach(t),Ph=i(Ze,` decorator because pipelines should
not be used for training. If you want to store the gradients during the forward pass, we recommend writing your own pipeline, see also our `),Ht=a(Ze,"A",{href:!0,rel:!0});var _g=n(Ht);Sh=i(_g,"community-examples"),_g.forEach(t),Ze.forEach(t),hl=d(r),he=a(r,"H2",{class:!0});var Hl=n(he);Te=a(Hl,"A",{id:!0,class:!0,href:!0});var vg=n(Te);br=a(vg,"SPAN",{});var bg=n(br);$(Ut.$$.fragment,bg),bg.forEach(t),vg.forEach(t),$h=d(Hl),Er=a(Hl,"SPAN",{});var Eg=n(Er);Gh=i(Eg,"Contribution"),Eg.forEach(t),Hl.forEach(t),pl=d(r),w=a(r,"P",{});var re=n(w);Oh=i(re,`We are more than happy about any contribution to the officially supported pipelines \u{1F917}. We aspire
all of our pipelines to be  `),yr=a(re,"STRONG",{});var yg=n(yr);Mh=i(yg,"self-contained"),yg.forEach(t),jh=i(re,", "),wr=a(re,"STRONG",{});var wg=n(wr);Ch=i(wg,"easy-to-tweak"),wg.forEach(t),Lh=i(re,", "),Dr=a(re,"STRONG",{});var Dg=n(Dr);Rh=i(Dg,"beginner-friendly"),Dg.forEach(t),qh=i(re," and for "),Ir=a(re,"STRONG",{});var Ig=n(Ir);Nh=i(Ig,"one-purpose-only"),Ig.forEach(t),Hh=i(re,"."),re.forEach(t),cl=d(r),x=a(r,"UL",{});var et=n(x);ke=a(et,"LI",{});var Vr=n(ke);Tr=a(Vr,"STRONG",{});var Tg=n(Tr);Uh=i(Tg,"Self-contained"),Tg.forEach(t),Bh=i(Vr,": A pipeline shall be as self-contained as possible. More specifically, this means that all functionality should be either directly defined in the pipeline file itself, should be inherited from (and only from) the "),Bt=a(Vr,"A",{href:!0});var Np=n(Bt);kr=a(Np,"CODE",{});var kg=n(kr);Yh=i(kg,"DiffusionPipeline"),kg.forEach(t),zh=i(Np," class"),Np.forEach(t),Fh=i(Vr," or be directly attached to the model and scheduler components of the pipeline."),Vr.forEach(t),Vh=d(et),oe=a(et,"LI",{});var lo=n(oe);xr=a(lo,"STRONG",{});var xg=n(xr);Qh=i(xg,"Easy-to-use"),xg.forEach(t),Wh=i(lo,`: Pipelines should be extremely easy to use - one should be able to load the pipeline and
use it for its designated task, `),Ar=a(lo,"EM",{});var Ag=n(Ar);Jh=i(Ag,"e.g."),Ag.forEach(t),Kh=i(lo,` text-to-image generation, in just a couple of lines of code. Most
logic including pre-processing, an unrolled diffusion loop, and post-processing should all happen inside the `),Pr=a(lo,"CODE",{});var Pg=n(Pr);Xh=i(Pg,"__call__"),Pg.forEach(t),Zh=i(lo," method."),lo.forEach(t),ep=d(et),ae=a(et,"LI",{});var io=n(ae);Sr=a(io,"STRONG",{});var Sg=n(Sr);tp=i(Sg,"Easy-to-tweak"),Sg.forEach(t),op=i(io,": Certain pipelines will not be able to handle all use cases and tasks that you might like them to. If you want to use a certain pipeline for a specific use case that is not yet supported, you might have to copy the pipeline file and tweak the code to your needs. We try to make the pipeline code as readable as possible so that each part \u2013from pre-processing to diffusing to post-processing\u2013 can easily be adapted. If you would like the community to benefit from your customized pipeline, we would love to see a contribution to our "),Yt=a(io,"A",{href:!0,rel:!0});var $g=n(Yt);ap=i($g,"community-examples"),$g.forEach(t),np=i(io,". If you feel that an important pipeline should be part of the official pipelines but isn\u2019t, a contribution to the "),pa=a(io,"A",{href:!0});var Gg=n(pa);rp=i(Gg,"official pipelines"),Gg.forEach(t),lp=i(io," would be even better."),io.forEach(t),ip=d(et),A=a(et,"LI",{});var _e=n(A);$r=a(_e,"STRONG",{});var Og=n($r);sp=i(Og,"One-purpose-only"),Og.forEach(t),fp=i(_e,": Pipelines should be used for one task and one task only. Even if two tasks are very similar from a modeling point of view, "),Gr=a(_e,"EM",{});var Mg=n(Gr);dp=i(Mg,"e.g."),Mg.forEach(t),hp=i(_e," image2image translation and in-painting, pipelines shall be used for one task only to keep them "),Or=a(_e,"EM",{});var jg=n(Or);pp=i(jg,"easy-to-tweak"),jg.forEach(t),cp=i(_e," and "),Mr=a(_e,"EM",{});var Cg=n(Mr);up=i(Cg,"readable"),Cg.forEach(t),mp=i(_e,"."),_e.forEach(t),et.forEach(t),ul=d(r),pe=a(r,"H2",{class:!0});var Ul=n(pe);xe=a(Ul,"A",{id:!0,class:!0,href:!0});var Lg=n(xe);jr=a(Lg,"SPAN",{});var Rg=n(jr);$(zt.$$.fragment,Rg),Rg.forEach(t),Lg.forEach(t),gp=d(Ul),Cr=a(Ul,"SPAN",{});var qg=n(Cr);_p=i(qg,"Examples"),qg.forEach(t),Ul.forEach(t),ml=d(r),ce=a(r,"H3",{class:!0});var Bl=n(ce);Ae=a(Bl,"A",{id:!0,class:!0,href:!0});var Ng=n(Ae);Lr=a(Ng,"SPAN",{});var Hg=n(Lr);$(Ft.$$.fragment,Hg),Hg.forEach(t),Ng.forEach(t),vp=d(Bl),Rr=a(Bl,"SPAN",{});var Ug=n(Rr);bp=i(Ug,"Text-to-Image generation with Stable Diffusion"),Ug.forEach(t),Bl.forEach(t),gl=d(r),$(Vt.$$.fragment,r),_l=d(r),ue=a(r,"H3",{class:!0});var Yl=n(ue);Pe=a(Yl,"A",{id:!0,class:!0,href:!0});var Bg=n(Pe);qr=a(Bg,"SPAN",{});var Yg=n(qr);$(Qt.$$.fragment,Yg),Yg.forEach(t),Bg.forEach(t),Ep=d(Yl),Nr=a(Yl,"SPAN",{});var zg=n(Nr);yp=i(zg,"Image-to-Image text-guided generation with Stable Diffusion"),zg.forEach(t),Yl.forEach(t),vl=d(r),Se=a(r,"P",{});var zl=n(Se);wp=i(zl,"The "),Hr=a(zl,"CODE",{});var Fg=n(Hr);Dp=i(Fg,"StableDiffusionImg2ImgPipeline"),Fg.forEach(t),Ip=i(zl," lets you pass a text prompt and an initial image to condition the generation of new images."),zl.forEach(t),bl=d(r),$(Wt.$$.fragment,r),El=d(r),Jt=a(r,"P",{});var Hp=n(Jt);Tp=i(Hp,"You can also run this example on colab "),Kt=a(Hp,"A",{href:!0,rel:!0});var Vg=n(Kt);ca=a(Vg,"IMG",{src:!0,alt:!0}),Vg.forEach(t),Hp.forEach(t),yl=d(r),me=a(r,"H3",{class:!0});var Fl=n(me);$e=a(Fl,"A",{id:!0,class:!0,href:!0});var Qg=n($e);Ur=a(Qg,"SPAN",{});var Wg=n(Ur);$(Xt.$$.fragment,Wg),Wg.forEach(t),Qg.forEach(t),kp=d(Fl),Br=a(Fl,"SPAN",{});var Jg=n(Br);xp=i(Jg,"Tweak prompts reusing seeds and latents"),Jg.forEach(t),Fl.forEach(t),wl=d(r),ne=a(r,"P",{});var _a=n(ne);Ap=i(_a,"You can generate your own latents to reproduce results, or tweak your prompt on a specific result you liked. "),Zt=a(_a,"A",{href:!0,rel:!0});var Kg=n(Zt);Pp=i(Kg,"This notebook"),Kg.forEach(t),Sp=i(_a," shows how to do it step by step. You can also run it in Google Colab "),eo=a(_a,"A",{href:!0,rel:!0});var Xg=n(eo);ua=a(Xg,"IMG",{src:!0,alt:!0}),Xg.forEach(t),$p=i(_a,"."),_a.forEach(t),Dl=d(r),ge=a(r,"H3",{class:!0});var Vl=n(ge);Ge=a(Vl,"A",{id:!0,class:!0,href:!0});var Zg=n(Ge);Yr=a(Zg,"SPAN",{});var e_=n(Yr);$(to.$$.fragment,e_),e_.forEach(t),Zg.forEach(t),Gp=d(Vl),zr=a(Vl,"SPAN",{});var t_=n(zr);Op=i(t_,"In-painting using Stable Diffusion"),t_.forEach(t),Vl.forEach(t),Il=d(r),Oe=a(r,"P",{});var Ql=n(Oe);Mp=i(Ql,"The "),Fr=a(Ql,"CODE",{});var o_=n(Fr);jp=i(o_,"StableDiffusionInpaintPipeline"),o_.forEach(t),Cp=i(Ql," lets you edit specific parts of an image by providing a mask and text prompt."),Ql.forEach(t),Tl=d(r),$(oo.$$.fragment,r),kl=d(r),ao=a(r,"P",{});var Up=n(ao);Lp=i(Up,"You can also run this example on colab "),no=a(Up,"A",{href:!0,rel:!0});var a_=n(no);ma=a(a_,"IMG",{src:!0,alt:!0}),a_.forEach(t),Up.forEach(t),this.h()},h(){s(le,"name","hf:doc:metadata"),s(le,"content",JSON.stringify(h_)),s(be,"id","pipelines"),s(be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(be,"href","#pipelines"),s(ie,"class","relative group"),s(ot,"href","https://huggingface.co/blog/stable_diffusion"),s(ot,"rel","nofollow"),s(fo,"href","./api/models#vae"),s(ho,"href","./api/models#UNet2DConditionModel"),s(at,"href","https://huggingface.co/docs/transformers/v4.21.2/en/model_doc/clip#transformers.CLIPTextModel"),s(at,"rel","nofollow"),s(po,"href","./api/scheduler#pndm"),s(lt,"href","https://huggingface.co/docs/transformers/v4.21.2/en/model_doc/clip#transformers.CLIPFeatureExtractor"),s(lt,"rel","nofollow"),s(co,"href","./stable_diffusion#safety_checker"),s(st,"href","https://github.com/huggingface/diffusers/tree/main/src/diffusers/pipelines/latent_diffusion"),s(st,"rel","nofollow"),s(ft,"href","https://arxiv.org/abs/2112.10752"),s(ft,"rel","nofollow"),s(go,"href","#pipelines-api"),s(mo,"start","2"),s(vo,"href","#pipelines-summary"),s(_o,"start","3"),s(Eo,"href","#contribution"),s(bo,"start","4"),s(ct,"href","https://github.com/huggingface/diffusers/tree/main/examples"),s(ct,"rel","nofollow"),s(ye,"id","diffusers-summary"),s(ye,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(ye,"href","#diffusers-summary"),s(se,"class","relative group"),s(wo,"align","center"),s(Do,"align","center"),s(Io,"href","./api/pipelines/alt_diffusion"),s(mt,"href","https://arxiv.org/abs/2211.06679"),s(mt,"rel","nofollow"),s(To,"align","center"),s(ko,"align","center"),s(xo,"href","./api/pipelines/cycle_diffusion"),s(gt,"href","https://arxiv.org/abs/2210.05559"),s(gt,"rel","nofollow"),s(Ao,"align","center"),s(Ba,"align","center"),s(Po,"href","./api/pipelines/dance_diffusion"),s(_t,"href","https://github.com/williamberman/diffusers.git"),s(_t,"rel","nofollow"),s(So,"align","center"),s(Va,"align","center"),s($o,"href","./api/pipelines/ddpm"),s(vt,"href","https://arxiv.org/abs/2006.11239"),s(vt,"rel","nofollow"),s(Go,"align","center"),s(Ka,"align","center"),s(Oo,"href","./api/pipelines/ddim"),s(bt,"href","https://arxiv.org/abs/2010.02502"),s(bt,"rel","nofollow"),s(Mo,"align","center"),s(tn,"align","center"),s(jo,"href","./api/pipelines/latent_diffusion"),s(Et,"href","https://arxiv.org/abs/2112.10752"),s(Et,"rel","nofollow"),s(Co,"align","center"),s(rn,"align","center"),s(Lo,"href","./api/pipelines/latent_diffusion_uncond"),s(yt,"href","https://arxiv.org/abs/2112.10752"),s(yt,"rel","nofollow"),s(Ro,"align","center"),s(dn,"align","center"),s(qo,"href","./api/pipelines/pndm"),s(wt,"href","https://arxiv.org/abs/2202.09778"),s(wt,"rel","nofollow"),s(No,"align","center"),s(un,"align","center"),s(Ho,"href","./api/pipelines/score_sde_ve"),s(Dt,"href","https://openreview.net/forum?id=PxTIG12RRHS"),s(Dt,"rel","nofollow"),s(Uo,"align","center"),s(vn,"align","center"),s(Bo,"href","./api/pipelines/score_sde_vp"),s(It,"href","https://openreview.net/forum?id=PxTIG12RRHS"),s(It,"rel","nofollow"),s(Yo,"align","center"),s(wn,"align","center"),s(zo,"href","./api/pipelines/stable_diffusion"),s(Tt,"href","https://stability.ai/blog/stable-diffusion-public-release"),s(Tt,"rel","nofollow"),s(Fo,"align","center"),va(Qo.src,zp="https://colab.research.google.com/assets/colab-badge.svg")||s(Qo,"src",zp),s(Qo,"alt","Open In Colab"),s(kt,"href","https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/training_example.ipynb"),s(kt,"rel","nofollow"),s(Vo,"align","center"),s(Wo,"href","./api/pipelines/stable_diffusion"),s(xt,"href","https://stability.ai/blog/stable-diffusion-public-release"),s(xt,"rel","nofollow"),s(Jo,"align","center"),va(Xo.src,Fp="https://colab.research.google.com/assets/colab-badge.svg")||s(Xo,"src",Fp),s(Xo,"alt","Open In Colab"),s(At,"href","https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/image_2_image_using_diffusers.ipynb"),s(At,"rel","nofollow"),s(Ko,"align","center"),s(Zo,"href","./api/pipelines/stable_diffusion"),s(Pt,"href","https://stability.ai/blog/stable-diffusion-public-release"),s(Pt,"rel","nofollow"),s(ea,"align","center"),va(oa.src,Vp="https://colab.research.google.com/assets/colab-badge.svg")||s(oa,"src",Vp),s(oa,"alt","Open In Colab"),s(St,"href","https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/in_painting_with_stable_diffusion_using_diffusers.ipynb"),s(St,"rel","nofollow"),s(ta,"align","center"),s(aa,"href","./api/pipelines/stochastic_karras_ve"),s($t,"href","https://arxiv.org/abs/2206.00364"),s($t,"rel","nofollow"),s(na,"align","center"),s(jn,"align","center"),s(ra,"href","./api/pipelines/vq_diffusion"),s(Gt,"href","https://arxiv.org/abs/2111.14822"),s(Gt,"rel","nofollow"),s(la,"align","center"),s(Rn,"align","center"),s(ia,"href","#examples"),s(Ie,"id","pipelines-api"),s(Ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(Ie,"href","#pipelines-api"),s(fe,"class","relative group"),s(jt,"href","https://github.com/huggingface/transformers"),s(jt,"rel","nofollow"),s(Ct,"href","../diffusion_pipeline"),s(Lt,"href","https://huggingface.co/runwayml/stable-diffusion-v1-5"),s(Lt,"rel","nofollow"),s(Rt,"href","https://huggingface.co/runwayml/stable-diffusion-v1-5/blob/main/model_index.json"),s(Rt,"rel","nofollow"),s(fa,"href","../diffusion_pipeline"),s(da,"href","../diffusion_pipeline"),s(de,"href","https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to"),s(de,"rel","nofollow"),s(ha,"href","./stable_diffusion"),s(qt,"href","https://github.com/huggingface/diffusers/tree/main/src/diffusers/pipelines/ddpm"),s(qt,"rel","nofollow"),s(Nt,"href","https://pytorch.org/docs/stable/generated/torch.no_grad.html"),s(Nt,"rel","nofollow"),s(Ht,"href","https://github.com/huggingface/diffusers/tree/main/examples/community"),s(Ht,"rel","nofollow"),s(Te,"id","contribution"),s(Te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(Te,"href","#contribution"),s(he,"class","relative group"),s(Bt,"href",".../diffusion_pipeline"),s(Yt,"href","https://github.com/huggingface/diffusers/tree/main/examples/community"),s(Yt,"rel","nofollow"),s(pa,"href","./overview"),s(xe,"id","examples"),s(xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(xe,"href","#examples"),s(pe,"class","relative group"),s(Ae,"id","texttoimage-generation-with-stable-diffusion"),s(Ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(Ae,"href","#texttoimage-generation-with-stable-diffusion"),s(ce,"class","relative group"),s(Pe,"id","imagetoimage-textguided-generation-with-stable-diffusion"),s(Pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(Pe,"href","#imagetoimage-textguided-generation-with-stable-diffusion"),s(ue,"class","relative group"),va(ca.src,Qp="https://colab.research.google.com/assets/colab-badge.svg")||s(ca,"src",Qp),s(ca,"alt","Open In Colab"),s(Kt,"href","https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/image_2_image_using_diffusers.ipynb"),s(Kt,"rel","nofollow"),s($e,"id","tweak-prompts-reusing-seeds-and-latents"),s($e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s($e,"href","#tweak-prompts-reusing-seeds-and-latents"),s(me,"class","relative group"),s(Zt,"href","https://github.com/pcuenca/diffusers-examples/blob/main/notebooks/stable-diffusion-seeds.ipynb"),s(Zt,"rel","nofollow"),va(ua.src,Wp="https://colab.research.google.com/assets/colab-badge.svg")||s(ua,"src",Wp),s(ua,"alt","Open In Colab"),s(eo,"href","https://colab.research.google.com/github/pcuenca/diffusers-examples/blob/main/notebooks/stable-diffusion-seeds.ipynb"),s(eo,"rel","nofollow"),s(Ge,"id","inpainting-using-stable-diffusion"),s(Ge,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(Ge,"href","#inpainting-using-stable-diffusion"),s(ge,"class","relative group"),va(ma.src,Jp="https://colab.research.google.com/assets/colab-badge.svg")||s(ma,"src",Jp),s(ma,"alt","Open In Colab"),s(no,"href","https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/in_painting_with_stable_diffusion_using_diffusers.ipynb"),s(no,"rel","nofollow")},m(r,h){e(document.head,le),p(r,Qr,h),p(r,ie,h),e(ie,be),e(be,ba),G(tt,ba,null),e(ie,Wl),e(ie,Ea),e(Ea,Jl),p(r,Wr,h),p(r,so,h),e(so,Kl),p(r,Jr,h),p(r,Ee,h),e(Ee,Xl),e(Ee,ot),e(ot,Zl),e(Ee,ei),p(r,Kr,h),p(r,b,h),e(b,ya),e(ya,fo),e(fo,ti),e(b,oi),e(b,wa),e(wa,ho),e(ho,ai),e(b,ni),e(b,Da),e(Da,at),e(at,ri),e(b,li),e(b,nt),e(nt,ii),e(nt,po),e(po,si),e(nt,fi),e(b,di),e(b,rt),e(rt,hi),e(rt,lt),e(lt,pi),e(rt,ci),e(b,ui),e(b,it),e(it,mi),e(it,co),e(co,gi),e(it,_i),p(r,Xr,h),p(r,uo,h),e(uo,vi),p(r,Zr,h),p(r,I,h),e(I,Ia),e(Ia,Ta),e(Ta,C),e(C,bi),e(C,ka),e(ka,Ei),e(C,yi),e(C,st),e(st,wi),e(C,Di),e(C,ft),e(ft,Ii),e(C,Ti),e(I,ki),e(I,xa),e(xa,mo),e(mo,dt),e(dt,xi),e(dt,go),e(go,Ai),e(dt,Pi),e(I,Si),e(I,Aa),e(Aa,_o),e(_o,ht),e(ht,$i),e(ht,vo),e(vo,Gi),e(ht,Oi),e(I,Mi),e(I,Pa),e(Pa,bo),e(bo,pt),e(pt,ji),e(pt,Eo),e(Eo,Ci),e(pt,Li),p(r,el,h),p(r,L,h),e(L,Sa),e(Sa,Ri),e(L,qi),e(L,$a),e($a,Ni),e(L,Hi),e(L,ct),e(ct,Ui),e(L,Bi),p(r,tl,h),p(r,se,h),e(se,ye),e(ye,Ga),G(ut,Ga,null),e(se,Yi),e(se,Oa),e(Oa,zi),p(r,ol,h),p(r,yo,h),e(yo,Fi),p(r,al,h),p(r,we,h),e(we,Ma),e(Ma,R),e(R,ja),e(ja,Vi),e(R,Qi),e(R,Ca),e(Ca,Wi),e(R,Ji),e(R,wo),e(wo,Ki),e(R,Xi),e(R,Do),e(Do,Zi),e(we,es),e(we,c),e(c,q),e(q,La),e(La,Io),e(Io,ts),e(q,os),e(q,Ra),e(Ra,mt),e(mt,qa),e(qa,as),e(q,ns),e(q,To),e(To,rs),e(q,ls),e(q,ko),e(ko,is),e(c,ss),e(c,N),e(N,Na),e(Na,xo),e(xo,fs),e(N,ds),e(N,Ha),e(Ha,gt),e(gt,Ua),e(Ua,hs),e(N,ps),e(N,Ao),e(Ao,cs),e(N,us),e(N,Ba),e(c,ms),e(c,H),e(H,Ya),e(Ya,Po),e(Po,gs),e(H,_s),e(H,za),e(za,_t),e(_t,Fa),e(Fa,vs),e(H,bs),e(H,So),e(So,Es),e(H,ys),e(H,Va),e(c,ws),e(c,U),e(U,Qa),e(Qa,$o),e($o,Ds),e(U,Is),e(U,Wa),e(Wa,vt),e(vt,Ja),e(Ja,Ts),e(U,ks),e(U,Go),e(Go,xs),e(U,As),e(U,Ka),e(c,Ps),e(c,B),e(B,Xa),e(Xa,Oo),e(Oo,Ss),e(B,$s),e(B,Za),e(Za,bt),e(bt,en),e(en,Gs),e(B,Os),e(B,Mo),e(Mo,Ms),e(B,js),e(B,tn),e(c,Cs),e(c,Y),e(Y,on),e(on,jo),e(jo,Ls),e(Y,Rs),e(Y,an),e(an,Et),e(Et,nn),e(nn,qs),e(Y,Ns),e(Y,Co),e(Co,Hs),e(Y,Us),e(Y,rn),e(c,Bs),e(c,z),e(z,ln),e(ln,Lo),e(Lo,Ys),e(z,zs),e(z,sn),e(sn,yt),e(yt,fn),e(fn,Fs),e(z,Vs),e(z,Ro),e(Ro,Qs),e(z,Ws),e(z,dn),e(c,Js),e(c,F),e(F,hn),e(hn,qo),e(qo,Ks),e(F,Xs),e(F,pn),e(pn,wt),e(wt,cn),e(cn,Zs),e(F,ef),e(F,No),e(No,tf),e(F,of),e(F,un),e(c,af),e(c,V),e(V,mn),e(mn,Ho),e(Ho,nf),e(V,rf),e(V,gn),e(gn,Dt),e(Dt,_n),e(_n,lf),e(V,sf),e(V,Uo),e(Uo,ff),e(V,df),e(V,vn),e(c,hf),e(c,Q),e(Q,bn),e(bn,Bo),e(Bo,pf),e(Q,cf),e(Q,En),e(En,It),e(It,yn),e(yn,uf),e(Q,mf),e(Q,Yo),e(Yo,gf),e(Q,_f),e(Q,wn),e(c,vf),e(c,W),e(W,Dn),e(Dn,zo),e(zo,bf),e(W,Ef),e(W,In),e(In,Tt),e(Tt,Tn),e(Tn,yf),e(W,wf),e(W,Fo),e(Fo,Df),e(W,If),e(W,Vo),e(Vo,kt),e(kt,Qo),e(c,Tf),e(c,J),e(J,kn),e(kn,Wo),e(Wo,kf),e(J,xf),e(J,xn),e(xn,xt),e(xt,An),e(An,Af),e(J,Pf),e(J,Jo),e(Jo,Sf),e(J,$f),e(J,Ko),e(Ko,At),e(At,Xo),e(c,Gf),e(c,K),e(K,Pn),e(Pn,Zo),e(Zo,Of),e(K,Mf),e(K,Sn),e(Sn,Pt),e(Pt,$n),e($n,jf),e(K,Cf),e(K,ea),e(ea,Lf),e(K,Rf),e(K,ta),e(ta,St),e(St,oa),e(c,qf),e(c,X),e(X,Gn),e(Gn,aa),e(aa,Nf),e(X,Hf),e(X,On),e(On,$t),e($t,Mn),e(Mn,Uf),e(X,Bf),e(X,na),e(na,Yf),e(X,zf),e(X,jn),e(c,Ff),e(c,Z),e(Z,Cn),e(Cn,ra),e(ra,Vf),e(Z,Qf),e(Z,Ln),e(Ln,Gt),e(Gt,Wf),e(Z,Jf),e(Z,la),e(la,Kf),e(Z,Xf),e(Z,Rn),p(r,nl,h),p(r,Ot,h),e(Ot,qn),e(qn,Zf),e(Ot,ed),p(r,rl,h),p(r,De,h),e(De,td),e(De,ia),e(ia,od),e(De,ad),p(r,ll,h),p(r,fe,h),e(fe,Ie),e(Ie,Nn),G(Mt,Nn,null),e(fe,nd),e(fe,Hn),e(Hn,rd),p(r,il,h),p(r,sa,h),e(sa,ld),p(r,sl,h),p(r,te,h),e(te,id),e(te,Un),e(Un,sd),e(te,fd),e(te,jt),e(jt,dd),e(te,hd),p(r,fl,h),p(r,T,h),e(T,m),e(m,Ct),e(Ct,Bn),e(Bn,pd),e(Ct,cd),e(m,ud),e(m,Yn),e(Yn,md),e(m,gd),e(m,Lt),e(Lt,_d),e(m,vd),e(m,zn),e(zn,bd),e(m,Ed),e(m,Fn),e(Fn,yd),e(m,wd),e(m,Vn),e(Vn,Dd),e(m,Id),e(m,Rt),e(Rt,Td),e(m,kd),e(m,Qn),e(Qn,xd),e(m,Ad),e(m,Wn),e(Wn,Pd),e(m,Sd),e(m,Jn),e(Jn,$d),e(m,Gd),e(m,Kn),e(Kn,Od),e(m,Md),e(T,jd),e(T,_),e(_,fa),e(fa,Xn),e(Xn,Cd),e(_,Ld),e(_,Zn),e(Zn,Rd),e(_,qd),e(_,er),e(er,Nd),e(_,Hd),e(_,tr),e(tr,Ud),e(_,Bd),e(_,or),e(or,Yd),e(_,zd),e(_,ar),e(ar,Fd),e(_,Vd),e(_,nr),e(nr,Qd),e(_,Wd),e(_,rr),e(rr,Jd),e(_,Kd),e(T,Xd),e(T,y),e(y,da),e(da,lr),e(lr,Zd),e(y,eh),e(y,ir),e(ir,th),e(y,oh),e(y,sr),e(sr,ah),e(y,nh),e(y,fr),e(fr,rh),e(y,lh),e(y,de),e(de,ih),e(de,dr),e(dr,sh),e(de,fh),e(y,dh),e(T,hh),e(T,E),e(E,hr),e(hr,ph),e(E,ch),e(E,pr),e(pr,uh),e(E,mh),e(E,cr),e(cr,gh),e(E,_h),e(E,ur),e(ur,vh),e(E,bh),e(E,ha),e(ha,mr),e(mr,Eh),e(E,yh),e(E,qt),e(qt,wh),e(E,Dh),p(r,dl,h),p(r,k,h),e(k,gr),e(gr,Ih),e(k,Th),e(k,_r),e(_r,kh),e(k,xh),e(k,Nt),e(Nt,vr),e(vr,Ah),e(k,Ph),e(k,Ht),e(Ht,Sh),p(r,hl,h),p(r,he,h),e(he,Te),e(Te,br),G(Ut,br,null),e(he,$h),e(he,Er),e(Er,Gh),p(r,pl,h),p(r,w,h),e(w,Oh),e(w,yr),e(yr,Mh),e(w,jh),e(w,wr),e(wr,Ch),e(w,Lh),e(w,Dr),e(Dr,Rh),e(w,qh),e(w,Ir),e(Ir,Nh),e(w,Hh),p(r,cl,h),p(r,x,h),e(x,ke),e(ke,Tr),e(Tr,Uh),e(ke,Bh),e(ke,Bt),e(Bt,kr),e(kr,Yh),e(Bt,zh),e(ke,Fh),e(x,Vh),e(x,oe),e(oe,xr),e(xr,Qh),e(oe,Wh),e(oe,Ar),e(Ar,Jh),e(oe,Kh),e(oe,Pr),e(Pr,Xh),e(oe,Zh),e(x,ep),e(x,ae),e(ae,Sr),e(Sr,tp),e(ae,op),e(ae,Yt),e(Yt,ap),e(ae,np),e(ae,pa),e(pa,rp),e(ae,lp),e(x,ip),e(x,A),e(A,$r),e($r,sp),e(A,fp),e(A,Gr),e(Gr,dp),e(A,hp),e(A,Or),e(Or,pp),e(A,cp),e(A,Mr),e(Mr,up),e(A,mp),p(r,ul,h),p(r,pe,h),e(pe,xe),e(xe,jr),G(zt,jr,null),e(pe,gp),e(pe,Cr),e(Cr,_p),p(r,ml,h),p(r,ce,h),e(ce,Ae),e(Ae,Lr),G(Ft,Lr,null),e(ce,vp),e(ce,Rr),e(Rr,bp),p(r,gl,h),G(Vt,r,h),p(r,_l,h),p(r,ue,h),e(ue,Pe),e(Pe,qr),G(Qt,qr,null),e(ue,Ep),e(ue,Nr),e(Nr,yp),p(r,vl,h),p(r,Se,h),e(Se,wp),e(Se,Hr),e(Hr,Dp),e(Se,Ip),p(r,bl,h),G(Wt,r,h),p(r,El,h),p(r,Jt,h),e(Jt,Tp),e(Jt,Kt),e(Kt,ca),p(r,yl,h),p(r,me,h),e(me,$e),e($e,Ur),G(Xt,Ur,null),e(me,kp),e(me,Br),e(Br,xp),p(r,wl,h),p(r,ne,h),e(ne,Ap),e(ne,Zt),e(Zt,Pp),e(ne,Sp),e(ne,eo),e(eo,ua),e(ne,$p),p(r,Dl,h),p(r,ge,h),e(ge,Ge),e(Ge,Yr),G(to,Yr,null),e(ge,Gp),e(ge,zr),e(zr,Op),p(r,Il,h),p(r,Oe,h),e(Oe,Mp),e(Oe,Fr),e(Fr,jp),e(Oe,Cp),p(r,Tl,h),G(oo,r,h),p(r,kl,h),p(r,ao,h),e(ao,Lp),e(ao,no),e(no,ma),xl=!0},p:s_,i(r){xl||(O(tt.$$.fragment,r),O(ut.$$.fragment,r),O(Mt.$$.fragment,r),O(Ut.$$.fragment,r),O(zt.$$.fragment,r),O(Ft.$$.fragment,r),O(Vt.$$.fragment,r),O(Qt.$$.fragment,r),O(Wt.$$.fragment,r),O(Xt.$$.fragment,r),O(to.$$.fragment,r),O(oo.$$.fragment,r),xl=!0)},o(r){M(tt.$$.fragment,r),M(ut.$$.fragment,r),M(Mt.$$.fragment,r),M(Ut.$$.fragment,r),M(zt.$$.fragment,r),M(Ft.$$.fragment,r),M(Vt.$$.fragment,r),M(Qt.$$.fragment,r),M(Wt.$$.fragment,r),M(Xt.$$.fragment,r),M(to.$$.fragment,r),M(oo.$$.fragment,r),xl=!1},d(r){t(le),r&&t(Qr),r&&t(ie),j(tt),r&&t(Wr),r&&t(so),r&&t(Jr),r&&t(Ee),r&&t(Kr),r&&t(b),r&&t(Xr),r&&t(uo),r&&t(Zr),r&&t(I),r&&t(el),r&&t(L),r&&t(tl),r&&t(se),j(ut),r&&t(ol),r&&t(yo),r&&t(al),r&&t(we),r&&t(nl),r&&t(Ot),r&&t(rl),r&&t(De),r&&t(ll),r&&t(fe),j(Mt),r&&t(il),r&&t(sa),r&&t(sl),r&&t(te),r&&t(fl),r&&t(T),r&&t(dl),r&&t(k),r&&t(hl),r&&t(he),j(Ut),r&&t(pl),r&&t(w),r&&t(cl),r&&t(x),r&&t(ul),r&&t(pe),j(zt),r&&t(ml),r&&t(ce),j(Ft),r&&t(gl),j(Vt,r),r&&t(_l),r&&t(ue),j(Qt),r&&t(vl),r&&t(Se),r&&t(bl),j(Wt,r),r&&t(El),r&&t(Jt),r&&t(yl),r&&t(me),j(Xt),r&&t(wl),r&&t(ne),r&&t(Dl),r&&t(ge),j(to),r&&t(Il),r&&t(Oe),r&&t(Tl),j(oo,r),r&&t(kl),r&&t(ao)}}}const h_={local:"pipelines",sections:[{local:"diffusers-summary",title:"\u{1F9E8} Diffusers Summary"},{local:"pipelines-api",title:"Pipelines API"},{local:"contribution",title:"Contribution"},{local:"examples",sections:[{local:"texttoimage-generation-with-stable-diffusion",title:"Text-to-Image generation with Stable Diffusion"},{local:"imagetoimage-textguided-generation-with-stable-diffusion",title:"Image-to-Image text-guided generation with Stable Diffusion"},{local:"tweak-prompts-reusing-seeds-and-latents",title:"Tweak prompts reusing seeds and latents"},{local:"inpainting-using-stable-diffusion",title:"In-painting using Stable Diffusion"}],title:"Examples"}],title:"Pipelines"};function p_(Yp){return f_(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class g_ extends n_{constructor(le){super();r_(this,le,p_,d_,l_,{})}}export{g_ as default,h_ as metadata};
