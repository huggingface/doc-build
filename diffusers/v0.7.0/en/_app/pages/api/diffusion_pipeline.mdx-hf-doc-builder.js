import{S as $o,i as wo,s as Po,e as o,k as f,w as D,t as r,M as Do,c as n,d as i,m as p,a as s,x as E,h as a,b as h,G as e,g as b,y as k,q as x,o as I,B as j,v as Eo,L as bo}from"../../chunks/vendor-hf-doc-builder.js";import{T as Xi}from"../../chunks/Tip-hf-doc-builder.js";import{D as ye}from"../../chunks/Docstring-hf-doc-builder.js";import{C as yo}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as Mi}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as vo}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function ko(q){let d;return{c(){d=r("One should not use the Diffusion Pipeline class for training or fine-tuning a diffusion model. Individual \n	components of diffusion pipelines are usually trained individually, so we suggest to directly work \n	with `UNetModel` and `UNetConditionModel`.")},l(v){d=a(v,"One should not use the Diffusion Pipeline class for training or fine-tuning a diffusion model. Individual \n	components of diffusion pipelines are usually trained individually, so we suggest to directly work \n	with `UNetModel` and `UNetConditionModel`.")},m(v,c){b(v,d,c)},d(v){v&&i(d)}}}function xo(q){let d,v,c,u,y,l,g,C,N,H,A,z,O;return{c(){d=o("p"),v=r("It is required to be logged in ("),c=o("code"),u=r("huggingface-cli login"),y=r(") when you want to use private or "),l=o("a"),g=r(`gated
models`),C=r(", "),N=o("em"),H=r("e.g."),A=f(),z=o("code"),O=r('"runwayml/stable-diffusion-v1-5"'),this.h()},l(U){d=n(U,"P",{});var T=s(d);v=a(T,"It is required to be logged in ("),c=n(T,"CODE",{});var X=s(c);u=a(X,"huggingface-cli login"),X.forEach(i),y=a(T,") when you want to use private or "),l=n(T,"A",{href:!0,rel:!0});var $e=s(l);g=a($e,`gated
models`),$e.forEach(i),C=a(T,", "),N=n(T,"EM",{});var we=s(N);H=a(we,"e.g."),we.forEach(i),A=p(T),z=n(T,"CODE",{});var oe=s(z);O=a(oe,'"runwayml/stable-diffusion-v1-5"'),oe.forEach(i),T.forEach(i),this.h()},h(){h(l,"href","https://huggingface.co/docs/hub/models-gated#gated-models"),h(l,"rel","nofollow")},m(U,T){b(U,d,T),e(d,v),e(d,c),e(c,u),e(d,y),e(d,l),e(l,g),e(d,C),e(d,N),e(N,H),e(d,A),e(d,z),e(z,O)},d(U){U&&i(d)}}}function Io(q){let d,v,c,u,y;return{c(){d=o("p"),v=r("Activate the special "),c=o("a"),u=r("\u201Coffline-mode\u201D"),y=r(` to use
this method in a firewalled environment.`),this.h()},l(l){d=n(l,"P",{});var g=s(d);v=a(g,"Activate the special "),c=n(g,"A",{href:!0,rel:!0});var C=s(c);u=a(C,"\u201Coffline-mode\u201D"),C.forEach(i),y=a(g,` to use
this method in a firewalled environment.`),g.forEach(i),this.h()},h(){h(c,"href","https://huggingface.co/diffusers/installation.html#offline-mode"),h(c,"rel","nofollow")},m(l,g){b(l,d,g),e(d,v),e(d,c),e(c,u),e(d,y)},d(l){l&&i(d)}}}function jo(q){let d,v,c,u,y;return u=new yo({props:{code:`from diffusers import DiffusionPipeline

# Download pipeline from huggingface.co and cache.
pipeline = DiffusionPipeline.from_pretrained("CompVis/ldm-text2im-large-256")

# Download pipeline that requires an authorization token
# For more information on access tokens, please refer to this section
# of the documentation](https://huggingface.co/docs/hub/security-tokens)
pipeline = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")

# Download pipeline, but overwrite scheduler
from diffusers import LMSDiscreteScheduler

scheduler = LMSDiscreteScheduler.from_config("runwayml/stable-diffusion-v1-5", subfolder="scheduler")
pipeline = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", scheduler=scheduler)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> DiffusionPipeline

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download pipeline from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pipeline = DiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;CompVis/ldm-text2im-large-256&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download pipeline that requires an authorization token</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># For more information on access tokens, please refer to this section</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># of the documentation](https://huggingface.co/docs/hub/security-tokens)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pipeline = DiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download pipeline, but overwrite scheduler</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> LMSDiscreteScheduler

<span class="hljs-meta">&gt;&gt;&gt; </span>scheduler = LMSDiscreteScheduler.from_config(<span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>, subfolder=<span class="hljs-string">&quot;scheduler&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>pipeline = DiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>, scheduler=scheduler)`}}),{c(){d=o("p"),v=r("Examples:"),c=f(),D(u.$$.fragment)},l(l){d=n(l,"P",{});var g=s(d);v=a(g,"Examples:"),g.forEach(i),c=p(l),E(u.$$.fragment,l)},m(l,g){b(l,d,g),e(d,v),b(l,c,g),k(u,l,g),y=!0},p:bo,i(l){y||(x(u.$$.fragment,l),y=!0)},o(l){I(u.$$.fragment,l),y=!1},d(l){l&&i(d),l&&i(c),j(u,l)}}}function So(q){let d,v,c,u,y;return u=new yo({props:{code:`from diffusers import (
    StableDiffusionPipeline,
    StableDiffusionImg2ImgPipeline,
    StableDiffusionInpaintPipeline,
)

img2text = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")
img2img = StableDiffusionImg2ImgPipeline(**img2text.components)
inpaint = StableDiffusionInpaintPipeline(**img2text.components)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> (
<span class="hljs-meta">... </span>    StableDiffusionPipeline,
<span class="hljs-meta">... </span>    StableDiffusionImg2ImgPipeline,
<span class="hljs-meta">... </span>    StableDiffusionInpaintPipeline,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>img2text = StableDiffusionPipeline.from_pretrained(<span class="hljs-string">&quot;runwayml/stable-diffusion-v1-5&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>img2img = StableDiffusionImg2ImgPipeline(**img2text.components)
<span class="hljs-meta">&gt;&gt;&gt; </span>inpaint = StableDiffusionInpaintPipeline(**img2text.components)`}}),{c(){d=o("p"),v=r("Examples:"),c=f(),D(u.$$.fragment)},l(l){d=n(l,"P",{});var g=s(d);v=a(g,"Examples:"),g.forEach(i),c=p(l),E(u.$$.fragment,l)},m(l,g){b(l,d,g),e(d,v),b(l,c,g),k(u,l,g),y=!0},p:bo,i(l){y||(x(u.$$.fragment,l),y=!0)},o(l){I(u.$$.fragment,l),y=!1},d(l){l&&i(d),l&&i(c),j(u,l)}}}function To(q){let d,v,c,u,y,l,g,C,N,H,A,z,O,U,T,X,$e,we,oe,B,ot,P,$t,Pe,wt,Pt,Te,Dt,Et,De,kt,xt,Ae,It,jt,Le,St,Tt,qe,At,Lt,nt,G,qt,Ee,Ct,Ot,st,V,R,Ce,ne,Xt,Oe,Mt,rt,_,se,Nt,Xe,zt,Ut,ke,xe,Vt,Yt,Wt,re,Me,Ft,Ht,Ne,Bt,Gt,ze,Rt,Jt,Ue,J,Ve,Kt,Qt,Ye,Zt,ei,ti,w,ae,ii,We,oi,ni,le,si,Fe,ri,ai,li,de,di,He,fi,pi,ci,fe,ui,Be,mi,hi,gi,K,_i,Q,vi,Z,bi,ee,pe,yi,ce,$i,Ge,wi,Pi,Di,Ie,ue,Ei,je,me,ki,M,he,xi,ge,Ii,Re,ji,Si,Ti,te,at,Y,ie,Je,_e,Ai,Ke,Li,lt,W,ve,qi,Qe,Ci,dt;return l=new Mi({}),B=new Xi({props:{$$slots:{default:[ko]},$$scope:{ctx:q}}}),ne=new Mi({}),se=new ye({props:{name:"class diffusers.DiffusionPipeline",anchor:"diffusers.DiffusionPipeline",parameters:[],source:"https://github.com/huggingface/diffusers/blob/v0.7.0/src/diffusers/pipeline_utils.py#L113"}}),ae=new ye({props:{name:"from_pretrained",anchor:"diffusers.DiffusionPipeline.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:": typing.Union[str, os.PathLike, NoneType]"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"diffusers.DiffusionPipeline.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>repo id</em> of a pretrained pipeline hosted inside a model repo on
<a href="https://huggingface.co/" rel="nofollow">https://huggingface.co/</a> Valid repo ids have to be located under a user or organization name, like
<code>CompVis/ldm-text2im-large-256</code>.</li>
<li>A path to a <em>directory</em> containing pipeline weights saved using
<a href="/docs/diffusers/v0.7.0/en/using-diffusers/loading#diffusers.DiffusionPipeline.save_pretrained">save_pretrained()</a>, e.g., <code>./my_pipeline_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.torch_dtype",description:`<strong>torch_dtype</strong> (<code>str</code> or <code>torch.dtype</code>, <em>optional</em>) &#x2014;
Override the default <code>torch.dtype</code> and load the model under this dtype. If <code>&quot;auto&quot;</code> is passed the dtype
will be automatically derived from the model&#x2019;s weights.`,name:"torch_dtype"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.custom_pipeline",description:`<strong>custom_pipeline</strong> (<code>str</code>, <em>optional</em>) &#x2014;</p>
<div class="course-tip course-tip-orange bg-gradient-to-br dark:bg-gradient-to-r before:border-orange-500 dark:before:border-orange-800 from-orange-50 dark:from-gray-900 to-white dark:to-gray-950 border border-orange-50 text-orange-700 dark:text-gray-400">
						
<p>This is an experimental feature and is likely to change in the future.</p>

					</div>
<p>Can be either:</p>
<ul>
<li>
<p>A string, the <em>repo id</em> of a custom pipeline hosted inside a model repo on
<a href="https://huggingface.co/" rel="nofollow">https://huggingface.co/</a>. Valid repo ids have to be located under a user or organization name,
like <code>hf-internal-testing/diffusers-dummy-pipeline</code>.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>It is required that the model repo has a file, called <code>pipeline.py</code> that defines the custom
pipeline.</p>

					</div>
</li>
<li>
<p>A string, the <em>file name</em> of a community pipeline hosted on GitHub under
<a href="https://github.com/huggingface/diffusers/tree/main/examples/community" rel="nofollow">https://github.com/huggingface/diffusers/tree/main/examples/community</a>. Valid file names have to
match exactly the file name without <code>.py</code> located under the above link, <em>e.g.</em>
<code>clip_guided_stable_diffusion</code>.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>Community pipelines are always loaded from the current <code>main</code> branch of GitHub.</p>

					</div>
</li>
<li>
<p>A path to a <em>directory</em> containing a custom pipeline, e.g., <code>./my_pipeline_directory/</code>.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>It is required that the directory has a file, called <code>pipeline.py</code> that defines the custom
pipeline.</p>

					</div>
</li>
</ul>
<p>For more information on how to load and create custom pipelines, please have a look at <a href="https://huggingface.co/docs/diffusers/main/en/using-diffusers/custom_pipelines" rel="nofollow">Loading and
Creating Custom
Pipelines</a>`,name:"custom_pipeline"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.torch_dtype",description:"<strong>torch_dtype</strong> (<code>str</code> or <code>torch.dtype</code>, <em>optional</em>) &#x2014;",name:"torch_dtype"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (i.e., do not try to download the model).`,name:"local_files_only(bool,"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.mirror",description:`<strong>mirror</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Mirror source to accelerate downloads in China. If you are from China and have an accessibility
problem, you can set this option to resolve it. Note that we do not guarantee the timeliness or safety.
Please refer to the mirror site for more information. specify the folder name here.`,name:"mirror"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.device_map",description:`<strong>device_map</strong> (<code>str</code> or <code>Dict[str, Union[int, str, torch.device]]</code>, <em>optional</em>) &#x2014;
A map that specifies where each submodule should go. It doesn&#x2019;t need to be refined to each
parameter/buffer name, once a given module name is inside, every submodule of it will be sent to the
same device.</p>
<p>To have Accelerate compute the most optimized <code>device_map</code> automatically, set <code>device_map=&quot;auto&quot;</code>. For
more information about each option see <a href="https://hf.co/docs/accelerate/main/en/usage_guides/big_modeling#designing-a-device-map" rel="nofollow">designing a device
map</a>.`,name:"device_map"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.low_cpu_mem_usage",description:`<strong>low_cpu_mem_usage</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code> if torch version &gt;= 1.9.0 else <code>False</code>) &#x2014;
Speed up model loading by not initializing the weights and only loading the pre-trained weights. This
also tries to not use more than 1x model size in CPU memory (including peak memory) while loading the
model. This is only supported when torch version &gt;= 1.9.0. If you are using an older version of torch,
setting this argument to <code>True</code> will raise an error.`,name:"low_cpu_mem_usage"},{anchor:"diffusers.DiffusionPipeline.from_pretrained.kwargs",description:`<strong>kwargs</strong> (remaining dictionary of keyword arguments, <em>optional</em>) &#x2014;
Can be used to overwrite load - and saveable variables - <em>i.e.</em> the pipeline components - of the
specific pipeline class. The overwritten components are then directly passed to the pipelines
<code>__init__</code> method. See example below for more information.`,name:"kwargs"}],source:"https://github.com/huggingface/diffusers/blob/v0.7.0/src/diffusers/pipeline_utils.py#L238"}}),K=new Xi({props:{$$slots:{default:[xo]},$$scope:{ctx:q}}}),Q=new Xi({props:{$$slots:{default:[Io]},$$scope:{ctx:q}}}),Z=new vo({props:{anchor:"diffusers.DiffusionPipeline.from_pretrained.example",$$slots:{default:[jo]},$$scope:{ctx:q}}}),pe=new ye({props:{name:"save_pretrained",anchor:"diffusers.DiffusionPipeline.save_pretrained",parameters:[{name:"save_directory",val:": typing.Union[str, os.PathLike]"}],parametersDescription:[{anchor:"diffusers.DiffusionPipeline.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Directory to which to save. Will be created if it doesn&#x2019;t exist.`,name:"save_directory"}],source:"https://github.com/huggingface/diffusers/blob/v0.7.0/src/diffusers/pipeline_utils.py#L163"}}),ue=new ye({props:{name:"to",anchor:"diffusers.DiffusionPipeline.to",parameters:[{name:"torch_device",val:": typing.Union[str, torch.device, NoneType] = None"}],source:"https://github.com/huggingface/diffusers/blob/v0.7.0/src/diffusers/pipeline_utils.py#L204"}}),me=new ye({props:{name:"device",anchor:"diffusers.DiffusionPipeline.device",parameters:[],source:"https://github.com/huggingface/diffusers/blob/v0.7.0/src/diffusers/pipeline_utils.py#L223",returnDescription:`
<p>The torch device on which the pipeline is located.</p>
`,returnType:`
<p><code>torch.device</code></p>
`}}),he=new ye({props:{name:"components",anchor:"diffusers.DiffusionPipeline.components",parameters:[],source:"https://github.com/huggingface/diffusers/blob/v0.7.0/src/diffusers/pipeline_utils.py#L650",returnDescription:`
<p>A dictionaly containing all the modules needed to initialize the pipeline.</p>
`}}),te=new vo({props:{anchor:"diffusers.DiffusionPipeline.components.example",$$slots:{default:[So]},$$scope:{ctx:q}}}),_e=new Mi({}),ve=new ye({props:{name:"class diffusers.pipeline_utils.ImagePipelineOutput",anchor:"diffusers.pipeline_utils.ImagePipelineOutput",parameters:[{name:"images",val:": typing.Union[typing.List[PIL.Image.Image], numpy.ndarray]"}],parametersDescription:[{anchor:"diffusers.pipeline_utils.ImagePipelineOutput.images",description:`<strong>images</strong> (<code>List[PIL.Image.Image]</code> or <code>np.ndarray</code>) &#x2014;
List of denoised PIL images of length <code>batch_size</code> or numpy array of shape <code>(batch_size, height, width, num_channels)</code>. PIL images or numpy array present the denoised images of the diffusion pipeline.`,name:"images"}],source:"https://github.com/huggingface/diffusers/blob/v0.7.0/src/diffusers/pipeline_utils.py#L86"}}),{c(){d=o("meta"),v=f(),c=o("h1"),u=o("a"),y=o("span"),D(l.$$.fragment),g=f(),C=o("span"),N=r("Pipelines"),H=f(),A=o("p"),z=r("The "),O=o("a"),U=r("DiffusionPipeline"),T=r(" is the easiest way to load any pretrained diffusion pipeline from the "),X=o("a"),$e=r("Hub"),we=r(" and to use it in inference."),oe=f(),D(B.$$.fragment),ot=f(),P=o("p"),$t=r("Any diffusion pipeline that is loaded with "),Pe=o("a"),wt=r("from_pretrained()"),Pt=r(` will automatically
detect the pipeline type, `),Te=o("em"),Dt=r("e.g."),Et=f(),De=o("a"),kt=r("StableDiffusionPipeline"),xt=r(` and consequently load each component of the
pipeline and pass them into the `),Ae=o("code"),It=r("__init__"),jt=r(" function of the pipeline, "),Le=o("em"),St=r("e.g."),Tt=f(),qe=o("code"),At=r("__init__()"),Lt=r("."),nt=f(),G=o("p"),qt=r("Any pipeline object can be saved locally with "),Ee=o("a"),Ct=r("save_pretrained()"),Ot=r("."),st=f(),V=o("h2"),R=o("a"),Ce=o("span"),D(ne.$$.fragment),Xt=f(),Oe=o("span"),Mt=r("DiffusionPipeline"),rt=f(),_=o("div"),D(se.$$.fragment),Nt=f(),Xe=o("p"),zt=r("Base class for all models."),Ut=f(),ke=o("p"),xe=o("a"),Vt=r("DiffusionPipeline"),Yt=r(` takes care of storing all components (models, schedulers, processors) for diffusion pipelines
and handles methods for loading, downloading and saving models as well as a few methods common to all pipelines to:`),Wt=f(),re=o("ul"),Me=o("li"),Ft=r("move all PyTorch modules to the device of your choice"),Ht=f(),Ne=o("li"),Bt=r("enabling/disabling the progress bar for the denoising iteration"),Gt=f(),ze=o("p"),Rt=r("Class attributes:"),Jt=f(),Ue=o("ul"),J=o("li"),Ve=o("strong"),Kt=r("config_name"),Qt=r(" ("),Ye=o("code"),Zt=r("str"),ei=r(`) \u2014 name of the config file that will store the class and module names of all
components of the diffusion pipeline.`),ti=f(),w=o("div"),D(ae.$$.fragment),ii=f(),We=o("p"),oi=r("Instantiate a PyTorch diffusion pipeline from pre-trained pipeline weights."),ni=f(),le=o("p"),si=r("The pipeline is set in evaluation mode by default using "),Fe=o("code"),ri=r("model.eval()"),ai=r(" (Dropout modules are deactivated)."),li=f(),de=o("p"),di=r("The warning "),He=o("em"),fi=r("Weights from XXX not initialized from pretrained model"),pi=r(` means that the weights of XXX do not come
pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning
task.`),ci=f(),fe=o("p"),ui=r("The warning "),Be=o("em"),mi=r("Weights from XXX not used in YYY"),hi=r(` means that the layer XXX is not used by YYY, therefore those
weights are discarded.`),gi=f(),D(K.$$.fragment),_i=f(),D(Q.$$.fragment),vi=f(),D(Z.$$.fragment),bi=f(),ee=o("div"),D(pe.$$.fragment),yi=f(),ce=o("p"),$i=r(`Save all variables of the pipeline that can be saved and loaded as well as the pipelines configuration file to
a directory. A pipeline variable can be saved and loaded if its class implements both a save and loading
method. The pipeline can easily be re-loaded using the `),Ge=o("code"),wi=r("[from_pretrained()](/docs/diffusers/v0.7.0/en/using-diffusers/loading#diffusers.DiffusionPipeline.from_pretrained)"),Pi=r(" class method."),Di=f(),Ie=o("div"),D(ue.$$.fragment),Ei=f(),je=o("div"),D(me.$$.fragment),ki=f(),M=o("div"),D(he.$$.fragment),xi=f(),ge=o("p"),Ii=r("The "),Re=o("code"),ji=r("self.components"),Si=r(` property can be useful to run different pipelines with the same weights and
configurations to not have to re-allocate memory.`),Ti=f(),D(te.$$.fragment),at=f(),Y=o("h2"),ie=o("a"),Je=o("span"),D(_e.$$.fragment),Ai=f(),Ke=o("span"),Li=r("ImagePipelineOutput"),lt=r(`

By default diffusion pipelines return an object of class
`),W=o("div"),D(ve.$$.fragment),qi=f(),Qe=o("p"),Ci=r("Output class for image pipelines."),this.h()},l(t){const m=Do('[data-svelte="svelte-1phssyn"]',document.head);d=n(m,"META",{name:!0,content:!0}),m.forEach(i),v=p(t),c=n(t,"H1",{class:!0});var be=s(c);u=n(be,"A",{id:!0,class:!0,href:!0});var Ze=s(u);y=n(Ze,"SPAN",{});var et=s(y);E(l.$$.fragment,et),et.forEach(i),Ze.forEach(i),g=p(be),C=n(be,"SPAN",{});var tt=s(C);N=a(tt,"Pipelines"),tt.forEach(i),be.forEach(i),H=p(t),A=n(t,"P",{});var F=s(A);z=a(F,"The "),O=n(F,"A",{href:!0});var Ni=s(O);U=a(Ni,"DiffusionPipeline"),Ni.forEach(i),T=a(F," is the easiest way to load any pretrained diffusion pipeline from the "),X=n(F,"A",{href:!0,rel:!0});var zi=s(X);$e=a(zi,"Hub"),zi.forEach(i),we=a(F," and to use it in inference."),F.forEach(i),oe=p(t),E(B.$$.fragment,t),ot=p(t),P=n(t,"P",{});var L=s(P);$t=a(L,"Any diffusion pipeline that is loaded with "),Pe=n(L,"A",{href:!0});var Ui=s(Pe);wt=a(Ui,"from_pretrained()"),Ui.forEach(i),Pt=a(L,` will automatically
detect the pipeline type, `),Te=n(L,"EM",{});var Vi=s(Te);Dt=a(Vi,"e.g."),Vi.forEach(i),Et=p(L),De=n(L,"A",{href:!0});var Yi=s(De);kt=a(Yi,"StableDiffusionPipeline"),Yi.forEach(i),xt=a(L,` and consequently load each component of the
pipeline and pass them into the `),Ae=n(L,"CODE",{});var Wi=s(Ae);It=a(Wi,"__init__"),Wi.forEach(i),jt=a(L," function of the pipeline, "),Le=n(L,"EM",{});var Fi=s(Le);St=a(Fi,"e.g."),Fi.forEach(i),Tt=p(L),qe=n(L,"CODE",{});var Hi=s(qe);At=a(Hi,"__init__()"),Hi.forEach(i),Lt=a(L,"."),L.forEach(i),nt=p(t),G=n(t,"P",{});var ft=s(G);qt=a(ft,"Any pipeline object can be saved locally with "),Ee=n(ft,"A",{href:!0});var Bi=s(Ee);Ct=a(Bi,"save_pretrained()"),Bi.forEach(i),Ot=a(ft,"."),ft.forEach(i),st=p(t),V=n(t,"H2",{class:!0});var pt=s(V);R=n(pt,"A",{id:!0,class:!0,href:!0});var Gi=s(R);Ce=n(Gi,"SPAN",{});var Ri=s(Ce);E(ne.$$.fragment,Ri),Ri.forEach(i),Gi.forEach(i),Xt=p(pt),Oe=n(pt,"SPAN",{});var Ji=s(Oe);Mt=a(Ji,"DiffusionPipeline"),Ji.forEach(i),pt.forEach(i),rt=p(t),_=n(t,"DIV",{class:!0});var $=s(_);E(se.$$.fragment,$),Nt=p($),Xe=n($,"P",{});var Ki=s(Xe);zt=a(Ki,"Base class for all models."),Ki.forEach(i),Ut=p($),ke=n($,"P",{});var Oi=s(ke);xe=n(Oi,"A",{href:!0});var Qi=s(xe);Vt=a(Qi,"DiffusionPipeline"),Qi.forEach(i),Yt=a(Oi,` takes care of storing all components (models, schedulers, processors) for diffusion pipelines
and handles methods for loading, downloading and saving models as well as a few methods common to all pipelines to:`),Oi.forEach(i),Wt=p($),re=n($,"UL",{});var ct=s(re);Me=n(ct,"LI",{});var Zi=s(Me);Ft=a(Zi,"move all PyTorch modules to the device of your choice"),Zi.forEach(i),Ht=p(ct),Ne=n(ct,"LI",{});var eo=s(Ne);Bt=a(eo,"enabling/disabling the progress bar for the denoising iteration"),eo.forEach(i),ct.forEach(i),Gt=p($),ze=n($,"P",{});var to=s(ze);Rt=a(to,"Class attributes:"),to.forEach(i),Jt=p($),Ue=n($,"UL",{});var io=s(Ue);J=n(io,"LI",{});var it=s(J);Ve=n(it,"STRONG",{});var oo=s(Ve);Kt=a(oo,"config_name"),oo.forEach(i),Qt=a(it," ("),Ye=n(it,"CODE",{});var no=s(Ye);Zt=a(no,"str"),no.forEach(i),ei=a(it,`) \u2014 name of the config file that will store the class and module names of all
components of the diffusion pipeline.`),it.forEach(i),io.forEach(i),ti=p($),w=n($,"DIV",{class:!0});var S=s(w);E(ae.$$.fragment,S),ii=p(S),We=n(S,"P",{});var so=s(We);oi=a(so,"Instantiate a PyTorch diffusion pipeline from pre-trained pipeline weights."),so.forEach(i),ni=p(S),le=n(S,"P",{});var ut=s(le);si=a(ut,"The pipeline is set in evaluation mode by default using "),Fe=n(ut,"CODE",{});var ro=s(Fe);ri=a(ro,"model.eval()"),ro.forEach(i),ai=a(ut," (Dropout modules are deactivated)."),ut.forEach(i),li=p(S),de=n(S,"P",{});var mt=s(de);di=a(mt,"The warning "),He=n(mt,"EM",{});var ao=s(He);fi=a(ao,"Weights from XXX not initialized from pretrained model"),ao.forEach(i),pi=a(mt,` means that the weights of XXX do not come
pretrained with the rest of the model. It is up to you to train those weights with a downstream fine-tuning
task.`),mt.forEach(i),ci=p(S),fe=n(S,"P",{});var ht=s(fe);ui=a(ht,"The warning "),Be=n(ht,"EM",{});var lo=s(Be);mi=a(lo,"Weights from XXX not used in YYY"),lo.forEach(i),hi=a(ht,` means that the layer XXX is not used by YYY, therefore those
weights are discarded.`),ht.forEach(i),gi=p(S),E(K.$$.fragment,S),_i=p(S),E(Q.$$.fragment,S),vi=p(S),E(Z.$$.fragment,S),S.forEach(i),bi=p($),ee=n($,"DIV",{class:!0});var gt=s(ee);E(pe.$$.fragment,gt),yi=p(gt),ce=n(gt,"P",{});var _t=s(ce);$i=a(_t,`Save all variables of the pipeline that can be saved and loaded as well as the pipelines configuration file to
a directory. A pipeline variable can be saved and loaded if its class implements both a save and loading
method. The pipeline can easily be re-loaded using the `),Ge=n(_t,"CODE",{});var fo=s(Ge);wi=a(fo,"[from_pretrained()](/docs/diffusers/v0.7.0/en/using-diffusers/loading#diffusers.DiffusionPipeline.from_pretrained)"),fo.forEach(i),Pi=a(_t," class method."),_t.forEach(i),gt.forEach(i),Di=p($),Ie=n($,"DIV",{class:!0});var po=s(Ie);E(ue.$$.fragment,po),po.forEach(i),Ei=p($),je=n($,"DIV",{class:!0});var co=s(je);E(me.$$.fragment,co),co.forEach(i),ki=p($),M=n($,"DIV",{class:!0});var Se=s(M);E(he.$$.fragment,Se),xi=p(Se),ge=n(Se,"P",{});var vt=s(ge);Ii=a(vt,"The "),Re=n(vt,"CODE",{});var uo=s(Re);ji=a(uo,"self.components"),uo.forEach(i),Si=a(vt,` property can be useful to run different pipelines with the same weights and
configurations to not have to re-allocate memory.`),vt.forEach(i),Ti=p(Se),E(te.$$.fragment,Se),Se.forEach(i),$.forEach(i),at=p(t),Y=n(t,"H2",{class:!0});var bt=s(Y);ie=n(bt,"A",{id:!0,class:!0,href:!0});var mo=s(ie);Je=n(mo,"SPAN",{});var ho=s(Je);E(_e.$$.fragment,ho),ho.forEach(i),mo.forEach(i),Ai=p(bt),Ke=n(bt,"SPAN",{});var go=s(Ke);Li=a(go,"ImagePipelineOutput"),go.forEach(i),bt.forEach(i),lt=a(t,`

By default diffusion pipelines return an object of class
`),W=n(t,"DIV",{class:!0});var yt=s(W);E(ve.$$.fragment,yt),qi=p(yt),Qe=n(yt,"P",{});var _o=s(Qe);Ci=a(_o,"Output class for image pipelines."),_o.forEach(i),yt.forEach(i),this.h()},h(){h(d,"name","hf:doc:metadata"),h(d,"content",JSON.stringify(Ao)),h(u,"id","pipelines"),h(u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(u,"href","#pipelines"),h(c,"class","relative group"),h(O,"href","/docs/diffusers/v0.7.0/en/using-diffusers/loading#diffusers.DiffusionPipeline"),h(X,"href","https://huggingface.co/models?library=diffusers"),h(X,"rel","nofollow"),h(Pe,"href","/docs/diffusers/v0.7.0/en/using-diffusers/loading#diffusers.DiffusionPipeline.from_pretrained"),h(De,"href","/docs/diffusers/v0.7.0/en/api/pipelines/stable_diffusion#diffusers.StableDiffusionPipeline"),h(Ee,"href","/docs/diffusers/v0.7.0/en/using-diffusers/loading#diffusers.DiffusionPipeline.save_pretrained"),h(R,"id","diffusers.DiffusionPipeline"),h(R,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(R,"href","#diffusers.DiffusionPipeline"),h(V,"class","relative group"),h(xe,"href","/docs/diffusers/v0.7.0/en/using-diffusers/loading#diffusers.DiffusionPipeline"),h(w,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(ee,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(Ie,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(ie,"id","diffusers.pipeline_utils.ImagePipelineOutput"),h(ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ie,"href","#diffusers.pipeline_utils.ImagePipelineOutput"),h(Y,"class","relative group"),h(W,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(t,m){e(document.head,d),b(t,v,m),b(t,c,m),e(c,u),e(u,y),k(l,y,null),e(c,g),e(c,C),e(C,N),b(t,H,m),b(t,A,m),e(A,z),e(A,O),e(O,U),e(A,T),e(A,X),e(X,$e),e(A,we),b(t,oe,m),k(B,t,m),b(t,ot,m),b(t,P,m),e(P,$t),e(P,Pe),e(Pe,wt),e(P,Pt),e(P,Te),e(Te,Dt),e(P,Et),e(P,De),e(De,kt),e(P,xt),e(P,Ae),e(Ae,It),e(P,jt),e(P,Le),e(Le,St),e(P,Tt),e(P,qe),e(qe,At),e(P,Lt),b(t,nt,m),b(t,G,m),e(G,qt),e(G,Ee),e(Ee,Ct),e(G,Ot),b(t,st,m),b(t,V,m),e(V,R),e(R,Ce),k(ne,Ce,null),e(V,Xt),e(V,Oe),e(Oe,Mt),b(t,rt,m),b(t,_,m),k(se,_,null),e(_,Nt),e(_,Xe),e(Xe,zt),e(_,Ut),e(_,ke),e(ke,xe),e(xe,Vt),e(ke,Yt),e(_,Wt),e(_,re),e(re,Me),e(Me,Ft),e(re,Ht),e(re,Ne),e(Ne,Bt),e(_,Gt),e(_,ze),e(ze,Rt),e(_,Jt),e(_,Ue),e(Ue,J),e(J,Ve),e(Ve,Kt),e(J,Qt),e(J,Ye),e(Ye,Zt),e(J,ei),e(_,ti),e(_,w),k(ae,w,null),e(w,ii),e(w,We),e(We,oi),e(w,ni),e(w,le),e(le,si),e(le,Fe),e(Fe,ri),e(le,ai),e(w,li),e(w,de),e(de,di),e(de,He),e(He,fi),e(de,pi),e(w,ci),e(w,fe),e(fe,ui),e(fe,Be),e(Be,mi),e(fe,hi),e(w,gi),k(K,w,null),e(w,_i),k(Q,w,null),e(w,vi),k(Z,w,null),e(_,bi),e(_,ee),k(pe,ee,null),e(ee,yi),e(ee,ce),e(ce,$i),e(ce,Ge),e(Ge,wi),e(ce,Pi),e(_,Di),e(_,Ie),k(ue,Ie,null),e(_,Ei),e(_,je),k(me,je,null),e(_,ki),e(_,M),k(he,M,null),e(M,xi),e(M,ge),e(ge,Ii),e(ge,Re),e(Re,ji),e(ge,Si),e(M,Ti),k(te,M,null),b(t,at,m),b(t,Y,m),e(Y,ie),e(ie,Je),k(_e,Je,null),e(Y,Ai),e(Y,Ke),e(Ke,Li),b(t,lt,m),b(t,W,m),k(ve,W,null),e(W,qi),e(W,Qe),e(Qe,Ci),dt=!0},p(t,[m]){const be={};m&2&&(be.$$scope={dirty:m,ctx:t}),B.$set(be);const Ze={};m&2&&(Ze.$$scope={dirty:m,ctx:t}),K.$set(Ze);const et={};m&2&&(et.$$scope={dirty:m,ctx:t}),Q.$set(et);const tt={};m&2&&(tt.$$scope={dirty:m,ctx:t}),Z.$set(tt);const F={};m&2&&(F.$$scope={dirty:m,ctx:t}),te.$set(F)},i(t){dt||(x(l.$$.fragment,t),x(B.$$.fragment,t),x(ne.$$.fragment,t),x(se.$$.fragment,t),x(ae.$$.fragment,t),x(K.$$.fragment,t),x(Q.$$.fragment,t),x(Z.$$.fragment,t),x(pe.$$.fragment,t),x(ue.$$.fragment,t),x(me.$$.fragment,t),x(he.$$.fragment,t),x(te.$$.fragment,t),x(_e.$$.fragment,t),x(ve.$$.fragment,t),dt=!0)},o(t){I(l.$$.fragment,t),I(B.$$.fragment,t),I(ne.$$.fragment,t),I(se.$$.fragment,t),I(ae.$$.fragment,t),I(K.$$.fragment,t),I(Q.$$.fragment,t),I(Z.$$.fragment,t),I(pe.$$.fragment,t),I(ue.$$.fragment,t),I(me.$$.fragment,t),I(he.$$.fragment,t),I(te.$$.fragment,t),I(_e.$$.fragment,t),I(ve.$$.fragment,t),dt=!1},d(t){i(d),t&&i(v),t&&i(c),j(l),t&&i(H),t&&i(A),t&&i(oe),j(B,t),t&&i(ot),t&&i(P),t&&i(nt),t&&i(G),t&&i(st),t&&i(V),j(ne),t&&i(rt),t&&i(_),j(se),j(ae),j(K),j(Q),j(Z),j(pe),j(ue),j(me),j(he),j(te),t&&i(at),t&&i(Y),j(_e),t&&i(lt),t&&i(W),j(ve)}}}const Ao={local:"pipelines",sections:[{local:"diffusers.DiffusionPipeline",title:"DiffusionPipeline"},{local:"diffusers.pipeline_utils.ImagePipelineOutput",title:"ImagePipelineOutput"}],title:"Pipelines"};function Lo(q){return Eo(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class zo extends $o{constructor(d){super();wo(this,d,Lo,To,Po,{})}}export{zo as default,Ao as metadata};
