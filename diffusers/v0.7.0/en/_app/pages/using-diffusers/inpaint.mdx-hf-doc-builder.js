import{S as rt,i as lt,s as pt,e as s,k as h,w as me,t as u,M as ct,c as i,d as a,m as g,a as o,x as de,h as f,b as n,N as he,G as t,g as _,y as ge,q as _e,o as ve,B as be,v as ut}from"../../chunks/vendor-hf-doc-builder.js";import{T as ot}from"../../chunks/Tip-hf-doc-builder.js";import{I as ft}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as mt}from"../../chunks/CodeBlock-hf-doc-builder.js";function dt(H){let p,l,d,m,$,b,w,I,P;return{c(){p=u(`Note that this model is distributed separately from the regular Stable Diffusion model, so you have to accept its license even if you accepted the Stable Diffusion one in the past.
`),l=s("p"),d=u("Please, visit the "),m=s("a"),$=u("model card"),b=u(", read the license carefully and tick the checkbox if you agree. You have to be a registered user in \u{1F917} Hugging Face Hub, and you\u2019ll also need to use an access token for the code to work. For more information on access tokens, please refer to "),w=s("a"),I=u("this section"),P=u(" of the documentation."),this.h()},l(v){p=f(v,`Note that this model is distributed separately from the regular Stable Diffusion model, so you have to accept its license even if you accepted the Stable Diffusion one in the past.
`),l=i(v,"P",{});var c=o(l);d=f(c,"Please, visit the "),m=i(c,"A",{href:!0,rel:!0});var F=o(m);$=f(F,"model card"),F.forEach(a),b=f(c,", read the license carefully and tick the checkbox if you agree. You have to be a registered user in \u{1F917} Hugging Face Hub, and you\u2019ll also need to use an access token for the code to work. For more information on access tokens, please refer to "),w=i(c,"A",{href:!0,rel:!0});var E=o(w);I=f(E,"this section"),E.forEach(a),P=f(c," of the documentation."),c.forEach(a),this.h()},h(){n(m,"href","https://huggingface.co/runwayml/stable-diffusion-inpainting"),n(m,"rel","nofollow"),n(w,"href","https://huggingface.co/docs/hub/security-tokens"),n(w,"rel","nofollow")},m(v,c){_(v,p,c),_(v,l,c),t(l,d),t(l,m),t(m,$),t(l,b),t(l,w),t(w,I),t(l,P)},d(v){v&&a(p),v&&a(l)}}}function ht(H){let p;return{c(){p=u("A previous experimental implementation of in-painting used a different, lower-quality process. To ensure backwards compatibility, loading a pretrained pipeline that doesn't contain the new model will still apply the old in-painting method.")},l(l){p=f(l,"A previous experimental implementation of in-painting used a different, lower-quality process. To ensure backwards compatibility, loading a pretrained pipeline that doesn't contain the new model will still apply the old in-painting method.")},m(l,d){_(l,p,d)},d(l){l&&a(p)}}}function gt(H){let p,l,d,m,$,b,w,I,P,v,c,F,E,we,ye,ne,x,oe,S,re,T,K,y,M,W,ke,$e,N,X,Ie,Ee,L,Z,xe,Te,R,ee,je,qe,te,k,Q,C,Ge,De,V,O,Ye,Pe,z,ae,se,Se,Ce,J,A,Be,le,G,Oe,Y,U,He,pe,j,ce;return b=new ft({}),x=new ot({props:{warning:!0,$$slots:{default:[dt]},$$scope:{ctx:H}}}),S=new mt({props:{code:`import PIL
import requests
import torch
from io import BytesIO

from diffusers import StableDiffusionInpaintPipeline


def download_image(url):
    response = requests.get(url)
    return PIL.Image.open(BytesIO(response.content)).convert("RGB")


img_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
mask_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"

init_image = download_image(img_url).resize((512, 512))
mask_image = download_image(mask_url).resize((512, 512))

pipe = StableDiffusionInpaintPipeline.from_pretrained(
    "runwayml/stable-diffusion-inpainting",
    revision="fp16",
    torch_dtype=torch.float16,
)
pipe = pipe.to("cuda")

prompt = "Face of a yellow cat, high resolution, sitting on a park bench"
image = pipe(prompt=prompt, image=init_image, mask_image=mask_image).images[0]`,highlighted:`<span class="hljs-keyword">import</span> PIL
<span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> io <span class="hljs-keyword">import</span> BytesIO

<span class="hljs-keyword">from</span> diffusers <span class="hljs-keyword">import</span> StableDiffusionInpaintPipeline


<span class="hljs-keyword">def</span> <span class="hljs-title function_">download_image</span>(<span class="hljs-params">url</span>):
    response = requests.get(url)
    <span class="hljs-keyword">return</span> PIL.Image.<span class="hljs-built_in">open</span>(BytesIO(response.content)).convert(<span class="hljs-string">&quot;RGB&quot;</span>)


img_url = <span class="hljs-string">&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png&quot;</span>
mask_url = <span class="hljs-string">&quot;https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png&quot;</span>

init_image = download_image(img_url).resize((<span class="hljs-number">512</span>, <span class="hljs-number">512</span>))
mask_image = download_image(mask_url).resize((<span class="hljs-number">512</span>, <span class="hljs-number">512</span>))

pipe = StableDiffusionInpaintPipeline.from_pretrained(
    <span class="hljs-string">&quot;runwayml/stable-diffusion-inpainting&quot;</span>,
    revision=<span class="hljs-string">&quot;fp16&quot;</span>,
    torch_dtype=torch.float16,
)
pipe = pipe.to(<span class="hljs-string">&quot;cuda&quot;</span>)

prompt = <span class="hljs-string">&quot;Face of a yellow cat, high resolution, sitting on a park bench&quot;</span>
image = pipe(prompt=prompt, image=init_image, mask_image=mask_image).images[<span class="hljs-number">0</span>]`}}),j=new ot({props:{warning:!0,$$slots:{default:[ht]},$$scope:{ctx:H}}}),{c(){p=s("meta"),l=h(),d=s("h1"),m=s("a"),$=s("span"),me(b.$$.fragment),w=h(),I=s("span"),P=u("Text-Guided Image-Inpainting"),v=h(),c=s("p"),F=u("The "),E=s("a"),we=u("StableDiffusionInpaintPipeline"),ye=u(" lets you edit specific parts of an image by providing a mask and a text prompt. It uses a version of Stable Diffusion specifically trained for in-painting tasks."),ne=h(),me(x.$$.fragment),oe=h(),me(S.$$.fragment),re=h(),T=s("table"),K=s("thead"),y=s("tr"),M=s("th"),W=s("code"),ke=u("image"),$e=h(),N=s("th"),X=s("code"),Ie=u("mask_image"),Ee=h(),L=s("th"),Z=s("code"),xe=u("prompt"),Te=h(),R=s("th"),ee=s("strong"),je=u("Output"),qe=h(),te=s("tbody"),k=s("tr"),Q=s("td"),C=s("img"),De=h(),V=s("td"),O=s("img"),Pe=h(),z=s("td"),ae=s("strong"),se=s("em"),Se=u("Face of a yellow cat, high resolution, sitting on a park bench"),Ce=h(),J=s("td"),A=s("img"),le=h(),G=s("p"),Oe=u("You can also run this example on colab "),Y=s("a"),U=s("img"),pe=h(),me(j.$$.fragment),this.h()},l(e){const r=ct('[data-svelte="svelte-1phssyn"]',document.head);p=i(r,"META",{name:!0,content:!0}),r.forEach(a),l=g(e),d=i(e,"H1",{class:!0});var B=o(d);m=i(B,"A",{id:!0,class:!0,href:!0});var ie=o(m);$=i(ie,"SPAN",{});var Fe=o($);de(b.$$.fragment,Fe),Fe.forEach(a),ie.forEach(a),w=g(B),I=i(B,"SPAN",{});var Me=o(I);P=f(Me,"Text-Guided Image-Inpainting"),Me.forEach(a),B.forEach(a),v=g(e),c=i(e,"P",{});var ue=o(c);F=f(ue,"The "),E=i(ue,"A",{href:!0});var Ne=o(E);we=f(Ne,"StableDiffusionInpaintPipeline"),Ne.forEach(a),ye=f(ue," lets you edit specific parts of an image by providing a mask and a text prompt. It uses a version of Stable Diffusion specifically trained for in-painting tasks."),ue.forEach(a),ne=g(e),de(x.$$.fragment,e),oe=g(e),de(S.$$.fragment,e),re=g(e),T=i(e,"TABLE",{});var fe=o(T);K=i(fe,"THEAD",{});var Le=o(K);y=i(Le,"TR",{});var q=o(y);M=i(q,"TH",{align:!0});var Re=o(M);W=i(Re,"CODE",{});var Qe=o(W);ke=f(Qe,"image"),Qe.forEach(a),Re.forEach(a),$e=g(q),N=i(q,"TH",{align:!0});var Ve=o(N);X=i(Ve,"CODE",{});var ze=o(X);Ie=f(ze,"mask_image"),ze.forEach(a),Ve.forEach(a),Ee=g(q),L=i(q,"TH",{align:!0});var Je=o(L);Z=i(Je,"CODE",{});var Ue=o(Z);xe=f(Ue,"prompt"),Ue.forEach(a),Je.forEach(a),Te=g(q),R=i(q,"TH",{align:!0});var Ke=o(R);ee=i(Ke,"STRONG",{});var We=o(ee);je=f(We,"Output"),We.forEach(a),Ke.forEach(a),q.forEach(a),Le.forEach(a),qe=g(fe),te=i(fe,"TBODY",{});var Xe=o(te);k=i(Xe,"TR",{});var D=o(k);Q=i(D,"TD",{align:!0});var Ze=o(Q);C=i(Ze,"IMG",{src:!0,alt:!0,width:!0}),Ze.forEach(a),De=g(D),V=i(D,"TD",{align:!0});var et=o(V);O=i(et,"IMG",{src:!0,alt:!0,width:!0}),et.forEach(a),Pe=g(D),z=i(D,"TD",{align:!0});var tt=o(z);ae=i(tt,"STRONG",{});var at=o(ae);se=i(at,"EM",{});var st=o(se);Se=f(st,"Face of a yellow cat, high resolution, sitting on a park bench"),st.forEach(a),at.forEach(a),tt.forEach(a),Ce=g(D),J=i(D,"TD",{align:!0});var it=o(J);A=i(it,"IMG",{src:!0,alt:!0,width:!0}),it.forEach(a),D.forEach(a),Xe.forEach(a),fe.forEach(a),le=g(e),G=i(e,"P",{});var Ae=o(G);Oe=f(Ae,"You can also run this example on colab "),Y=i(Ae,"A",{href:!0,rel:!0});var nt=o(Y);U=i(nt,"IMG",{src:!0,alt:!0}),nt.forEach(a),Ae.forEach(a),pe=g(e),de(j.$$.fragment,e),this.h()},h(){n(p,"name","hf:doc:metadata"),n(p,"content",JSON.stringify(_t)),n(m,"id","textguided-imageinpainting"),n(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),n(m,"href","#textguided-imageinpainting"),n(d,"class","relative group"),n(E,"href","/docs/diffusers/v0.7.0/en/api/pipelines/stable_diffusion#diffusers.StableDiffusionInpaintPipeline"),n(M,"align","center"),n(N,"align","center"),n(L,"align","center"),n(R,"align","right"),he(C.src,Ge="https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png")||n(C,"src",Ge),n(C,"alt","drawing"),n(C,"width","250"),n(Q,"align","center"),he(O.src,Ye="https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png")||n(O,"src",Ye),n(O,"alt","drawing"),n(O,"width","250"),n(V,"align","center"),n(z,"align","center"),he(A.src,Be="https://huggingface.co/datasets/patrickvonplaten/images/resolve/main/test.png")||n(A,"src",Be),n(A,"alt","drawing"),n(A,"width","250"),n(J,"align","right"),he(U.src,He="https://colab.research.google.com/assets/colab-badge.svg")||n(U,"src",He),n(U,"alt","Open In Colab"),n(Y,"href","https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/in_painting_with_stable_diffusion_using_diffusers.ipynb"),n(Y,"rel","nofollow")},m(e,r){t(document.head,p),_(e,l,r),_(e,d,r),t(d,m),t(m,$),ge(b,$,null),t(d,w),t(d,I),t(I,P),_(e,v,r),_(e,c,r),t(c,F),t(c,E),t(E,we),t(c,ye),_(e,ne,r),ge(x,e,r),_(e,oe,r),ge(S,e,r),_(e,re,r),_(e,T,r),t(T,K),t(K,y),t(y,M),t(M,W),t(W,ke),t(y,$e),t(y,N),t(N,X),t(X,Ie),t(y,Ee),t(y,L),t(L,Z),t(Z,xe),t(y,Te),t(y,R),t(R,ee),t(ee,je),t(T,qe),t(T,te),t(te,k),t(k,Q),t(Q,C),t(k,De),t(k,V),t(V,O),t(k,Pe),t(k,z),t(z,ae),t(ae,se),t(se,Se),t(k,Ce),t(k,J),t(J,A),_(e,le,r),_(e,G,r),t(G,Oe),t(G,Y),t(Y,U),_(e,pe,r),ge(j,e,r),ce=!0},p(e,[r]){const B={};r&2&&(B.$$scope={dirty:r,ctx:e}),x.$set(B);const ie={};r&2&&(ie.$$scope={dirty:r,ctx:e}),j.$set(ie)},i(e){ce||(_e(b.$$.fragment,e),_e(x.$$.fragment,e),_e(S.$$.fragment,e),_e(j.$$.fragment,e),ce=!0)},o(e){ve(b.$$.fragment,e),ve(x.$$.fragment,e),ve(S.$$.fragment,e),ve(j.$$.fragment,e),ce=!1},d(e){a(p),e&&a(l),e&&a(d),be(b),e&&a(v),e&&a(c),e&&a(ne),be(x,e),e&&a(oe),be(S,e),e&&a(re),e&&a(T),e&&a(le),e&&a(G),e&&a(pe),be(j,e)}}}const _t={local:"textguided-imageinpainting",title:"Text-Guided Image-Inpainting"};function vt(H){return ut(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class $t extends rt{constructor(p){super();lt(this,p,vt,gt,pt,{})}}export{$t as default,_t as metadata};
