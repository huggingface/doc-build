import{S as Zn,i as ea,s as oa,e as n,k as d,w,t as i,M as ta,c as a,d as t,m as l,a as r,x,h as s,b as g,G as e,g as u,y as k,q as $,o as M,B as E,v as na}from"../../chunks/vendor-hf-doc-builder.js";import{T as mn}from"../../chunks/Tip-hf-doc-builder.js";import{D as W}from"../../chunks/Docstring-hf-doc-builder.js";import{I as po}from"../../chunks/IconCopyLink-hf-doc-builder.js";function aa(Y){let h,H,p,_,v;return{c(){h=n("p"),H=i("Passing "),p=n("code"),_=i("use_auth_token=True"),v=i(` is required when you want to use a
private model.`)},l(m){h=a(m,"P",{});var f=r(h);H=s(f,"Passing "),p=a(f,"CODE",{});var P=r(p);_=s(P,"use_auth_token=True"),P.forEach(t),v=s(f,` is required when you want to use a
private model.`),f.forEach(t)},m(m,f){u(m,h,f),e(h,H),e(h,p),e(p,_),e(h,v)},d(m){m&&t(h)}}}function ra(Y){let h,H,p,_,v;return{c(){h=n("p"),H=i("Passing "),p=n("code"),_=i("use_auth_token=True"),v=i(` is required when you want to use a private
model.`)},l(m){h=a(m,"P",{});var f=r(h);H=s(f,"Passing "),p=a(f,"CODE",{});var P=r(p);_=s(P,"use_auth_token=True"),P.forEach(t),v=s(f,` is required when you want to use a private
model.`),f.forEach(t)},m(m,f){u(m,h,f),e(h,H),e(h,p),e(p,_),e(h,v)},d(m){m&&t(h)}}}function ia(Y){let h,H,p,_,v,m,f,P,de;return{c(){h=n("p"),H=i("Raises the following error:"),p=d(),_=n("ul"),v=n("li"),m=n("a"),f=n("em"),P=i("ValueError"),de=i(`
if the user is not log on to the Hugging Face Hub.`),this.h()},l(T){h=a(T,"P",{});var z=r(h);H=s(z,"Raises the following error:"),z.forEach(t),p=l(T),_=a(T,"UL",{});var N=r(_);v=a(N,"LI",{});var q=r(v);m=a(q,"A",{href:!0,rel:!0});var L=r(m);f=a(L,"EM",{});var He=r(f);P=s(He,"ValueError"),He.forEach(t),L.forEach(t),de=s(q,`
if the user is not log on to the Hugging Face Hub.`),q.forEach(t),N.forEach(t),this.h()},h(){g(m,"href","https://docs.python.org/3/library/exceptions.html#ValueError"),g(m,"rel","nofollow")},m(T,z){u(T,h,z),e(h,H),u(T,p,z),u(T,_,z),e(_,v),e(v,m),e(m,f),e(f,P),e(v,de)},d(T){T&&t(h),T&&t(p),T&&t(_)}}}function sa(Y){let h,H,p,_,v,m,f,P,de,T,z,N,q,L,He,Ne,Uo,_o,J,Ko,Se,Vo,Ro,fo,U,Q,Ae,le,jo,Ie,Bo,bo,D,ce,Go,S,Yo,Le,Jo,Qo,Ce,Xo,Zo,Fe,et,ot,tt,C,he,nt,K,at,We,rt,it,qe,st,dt,lt,X,ct,Z,ge,ht,ue,gt,Ue,ut,mt,pt,ee,me,_t,Ke,ft,vo,V,oe,Ve,pe,bt,Re,vt,yo,A,_e,yt,je,wt,xt,te,wo,R,fe,kt,be,$t,Be,Mt,Et,xo,j,ve,Ht,Ge,Tt,ko,I,ye,zt,Ye,Pt,Dt,we,Te,Je,Ot,Nt,St,ne,Qe,At,It,Xe,Lt,Ct,$o,B,ae,Ze,xe,Ft,eo,Wt,Mo,G,ke,qt,oo,Ut,Eo,O,$e,Kt,Me,Vt,to,Rt,jt,Bt,b,Gt,no,Yt,Jt,ao,Qt,Xt,ro,Zt,en,io,on,tn,so,nn,an,lo,rn,sn,co,dn,ln,ho,cn,hn,gn,re,Ho;return m=new po({}),L=new po({}),le=new po({}),ce=new W({props:{name:"class huggingface_hub.ModelHubMixin",anchor:"huggingface_hub.ModelHubMixin",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/v0.8.0.rc4/src/huggingface_hub/hub_mixin.py#L22"}}),he=new W({props:{name:"from_pretrained",anchor:"huggingface_hub.ModelHubMixin.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:": str"},{name:"force_download",val:": bool = False"},{name:"resume_download",val:": bool = False"},{name:"proxies",val:": typing.Dict = None"},{name:"use_auth_token",val:": typing.Optional[str] = None"},{name:"cache_dir",val:": typing.Optional[str] = None"},{name:"local_files_only",val:": bool = False"},{name:"**model_kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:<ul>
<li>A string, the <code>model id</code> of a pretrained model
hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level,
like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like
<code>dbmdz/bert-base-german-cased</code>.</li>
<li>You can add <code>revision</code> by appending <code>@</code> at the end
of model_id simply like this:
<code>dbmdz/bert-base-german-cased@main</code> Revision is
the specific model version to use. It can be a
branch name, a tag name, or a commit id, since we
use a git-based system for storing models and
other artifacts on huggingface.co, so <code>revision</code>
can be any identifier allowed by git.</li>
<li>A path to a <code>directory</code> containing model weights
saved using
<code>save_pretrained</code>,
e.g., <code>./my_model_directory/</code>.</li>
<li><code>None</code> if you are both providing the configuration
and state dictionary (resp. with keyword arguments
<code>config</code> and <code>state_dict</code>).</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to force the (re-)download of the model weights
and configuration files, overriding the cached versions
if they exist.`,name:"force_download"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to delete incompletely received files. Will
attempt to resume the download if such a file exists.`,name:"resume_download"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or
endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are
used on each request.`,name:"proxies"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote
files. If <code>True</code>, will use the token generated when
running <code>transformers-cli login</code> (stored in
<code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>Union[str, os.PathLike]</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained
model configuration should be cached if the standard
cache should not be used.`,name:"cache_dir"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to only look at local files (i.e., do not try to
download the model).`,name:"local_files_only(bool,"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.model_kwargs",description:`<strong>model_kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
model_kwargs will be passed to the model during
initialization`,name:"model_kwargs"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.8.0.rc4/src/huggingface_hub/hub_mixin.py#L73"}}),X=new mn({props:{$$slots:{default:[aa]},$$scope:{ctx:Y}}}),ge=new W({props:{name:"push_to_hub",anchor:"huggingface_hub.ModelHubMixin.push_to_hub",parameters:[{name:"repo_path_or_name",val:": typing.Optional[str] = None"},{name:"repo_url",val:": typing.Optional[str] = None"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"organization",val:": typing.Optional[str] = None"},{name:"private",val:": typing.Optional[bool] = None"},{name:"api_endpoint",val:": typing.Optional[str] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = None"},{name:"git_user",val:": typing.Optional[str] = None"},{name:"git_email",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"},{name:"skip_lfs_files",val:": bool = False"}],parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.repo_path_or_name",description:`<strong>repo_path_or_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Can either be a repository name for your model or tokenizer in
the Hub or a path to a local folder (in which case the
repository will have the name of that local folder). If not
specified, will default to the name given by <code>repo_url</code> and a
local directory with that name will be created.`,name:"repo_path_or_name"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.repo_url",description:`<strong>repo_url</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Specify this in case you want to push to an existing repository
in the hub. If unspecified, a new repository will be created in
your namespace (unless you specify an <code>organization</code>) with
<code>repo_name</code>.`,name:"repo_url"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Message to commit while pushing. Will default to <code>&quot;add config&quot;</code>,
<code>&quot;add tokenizer&quot;</code> or <code>&quot;add model&quot;</code> depending on the type of the
class.`,name:"commit_message"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.organization",description:`<strong>organization</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Organization in which you want to push your model or tokenizer
(you must be a member of this organization).`,name:"organization"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.api_endpoint",description:`<strong>api_endpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The API endpoint to use when pushing the model to the hub.`,name:"api_endpoint"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.use_auth_token",description:`<strong>use_auth_token</strong> (<code>bool</code> or <code>str</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files.
If <code>True</code>, will use the token generated when running
<code>transformers-cli login</code> (stored in <code>~/.huggingface</code>). Will
default to <code>True</code> if <code>repo_url</code> is not specified.`,name:"use_auth_token"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.git_user",description:`<strong>git_user</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.name</code> for committing and
pushing files to the hub.`,name:"git_user"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.git_email",description:`<strong>git_email</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.email</code> for committing and
pushing files to the hub.`,name:"git_email"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.skip_lfs_files",description:`<strong>skip_lfs_files</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to skip git-LFS files or not.`,name:"skip_lfs_files"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.8.0.rc4/src/huggingface_hub/hub_mixin.py#L211",returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),me=new W({props:{name:"save_pretrained",anchor:"huggingface_hub.ModelHubMixin.save_pretrained",parameters:[{name:"save_directory",val:": str"},{name:"config",val:": typing.Optional[dict] = None"},{name:"push_to_hub",val:": bool = False"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code>) &#x2014;
Specify directory in which you want to save weights.`,name:"save_directory"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
specify config (must be dict) in case you want to save
it.`,name:"config"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.push_to_hub",description:`<strong>push_to_hub</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Set it to <code>True</code> in case you want to push your weights
to huggingface_hub`,name:"push_to_hub"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
kwargs will be passed to <code>push_to_hub</code>`,name:"kwargs"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.8.0.rc4/src/huggingface_hub/hub_mixin.py#L30"}}),pe=new po({}),_e=new W({props:{name:"huggingface_hub.from_pretrained_keras",anchor:"huggingface_hub.from_pretrained_keras",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.from_pretrained_keras.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:<ul>
<li>A string, the <code>model id</code> of a pretrained model hosted inside a
model repo on huggingface.co. Valid model ids can be located
at the root-level, like <code>bert-base-uncased</code>, or namespaced
under a user or organization name, like
<code>dbmdz/bert-base-german-cased</code>.</li>
<li>You can add <code>revision</code> by appending <code>@</code> at the end of model_id
simply like this: <code>dbmdz/bert-base-german-cased@main</code> Revision
is the specific model version to use. It can be a branch name,
a tag name, or a commit id, since we use a git-based system
for storing models and other artifacts on huggingface.co, so
<code>revision</code> can be any identifier allowed by git.</li>
<li>A path to a <code>directory</code> containing model weights saved using
<code>save_pretrained</code>, e.g.,
<code>./my_model_directory/</code>.</li>
<li><code>None</code> if you are both providing the configuration and state
dictionary (resp. with keyword arguments <code>config</code> and
<code>state_dict</code>).</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"huggingface_hub.from_pretrained_keras.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to force the (re-)download of the model weights and
configuration files, overriding the cached versions if they exist.`,name:"force_download"},{anchor:"huggingface_hub.from_pretrained_keras.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to delete incompletely received files. Will attempt to
resume the download if such a file exists.`,name:"resume_download"},{anchor:"huggingface_hub.from_pretrained_keras.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g.,
<code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The
proxies are used on each request.`,name:"proxies"},{anchor:"huggingface_hub.from_pretrained_keras.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If
<code>True</code>, will use the token generated when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"huggingface_hub.from_pretrained_keras.cache_dir",description:`<strong>cache_dir</strong> (<code>Union[str, os.PathLike]</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model
configuration should be cached if the standard cache should not be
used.`,name:"cache_dir"},{anchor:"huggingface_hub.from_pretrained_keras.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to only look at local files (i.e., do not try to download
the model).`,name:"local_files_only(bool,"},{anchor:"huggingface_hub.from_pretrained_keras.model_kwargs",description:`<strong>model_kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
model_kwargs will be passed to the model during initialization`,name:"model_kwargs"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.8.0.rc4/src/huggingface_hub/keras_mixin.py#L202"}}),te=new mn({props:{$$slots:{default:[ra]},$$scope:{ctx:Y}}}),fe=new W({props:{name:"huggingface_hub.push_to_hub_keras",anchor:"huggingface_hub.push_to_hub_keras",parameters:[{name:"model",val:""},{name:"repo_path_or_name",val:": typing.Optional[str] = None"},{name:"repo_url",val:": typing.Optional[str] = None"},{name:"log_dir",val:": typing.Optional[str] = None"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"organization",val:": typing.Optional[str] = None"},{name:"private",val:": typing.Optional[bool] = None"},{name:"api_endpoint",val:": typing.Optional[str] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = True"},{name:"git_user",val:": typing.Optional[str] = None"},{name:"git_email",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"},{name:"include_optimizer",val:": typing.Optional[bool] = False"},{name:"tags",val:": typing.Union[list, str, NoneType] = None"},{name:"plot_model",val:": typing.Optional[bool] = True"},{name:"**model_save_kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.push_to_hub_keras.model",description:`<strong>model</strong> (<code>Keras.Model</code>) &#x2014;
The <a href="%60https://www.tensorflow.org/api_docs/python/tf/keras/Model%60">Keras
model</a>
you&#x2019;d like to push to the Hub. The model must be compiled and built.`,name:"model"},{anchor:"huggingface_hub.push_to_hub_keras.repo_path_or_name",description:`<strong>repo_path_or_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Can either be a repository name for your model or tokenizer in the
Hub or a path to a local folder (in which case the repository will
have the name of that local folder). If not specified, will default
to the name given by <code>repo_url</code> and a local directory with that name
will be created.`,name:"repo_path_or_name"},{anchor:"huggingface_hub.push_to_hub_keras.repo_url",description:`<strong>repo_url</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Specify this in case you want to push to an existing repository in
the Hub. If unspecified, a new repository will be created in your
namespace (unless you specify an <code>organization</code>) with <code>repo_name</code>.`,name:"repo_url"},{anchor:"huggingface_hub.push_to_hub_keras.log_dir",description:`<strong>log_dir</strong> (<code>str</code>, <em>optional</em>) &#x2014;
TensorBoard logging directory to be pushed. The Hub automatically
hosts and displays a TensorBoard instance if log files are included
in the repository.`,name:"log_dir"},{anchor:"huggingface_hub.push_to_hub_keras.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>, defaults to &#x201C;Add message&#x201D;) &#x2014;
Message to commit while pushing.`,name:"commit_message"},{anchor:"huggingface_hub.push_to_hub_keras.organization",description:`<strong>organization</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Organization in which you want to push your model or tokenizer (you
must be a member of this organization).`,name:"organization"},{anchor:"huggingface_hub.push_to_hub_keras.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.push_to_hub_keras.api_endpoint",description:`<strong>api_endpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The API endpoint to use when pushing the model to the hub.`,name:"api_endpoint"},{anchor:"huggingface_hub.push_to_hub_keras.use_auth_token",description:`<strong>use_auth_token</strong> (<code>bool</code> or <code>str</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If
<code>True</code>, will use the token generated when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>). Will default to <code>True</code>.`,name:"use_auth_token"},{anchor:"huggingface_hub.push_to_hub_keras.git_user",description:`<strong>git_user</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.name</code> for committing and pushing
files to the Hub.`,name:"git_user"},{anchor:"huggingface_hub.push_to_hub_keras.git_email",description:`<strong>git_email</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.email</code> for committing and pushing
files to the Hub.`,name:"git_email"},{anchor:"huggingface_hub.push_to_hub_keras.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"},{anchor:"huggingface_hub.push_to_hub_keras.include_optimizer",description:`<strong>include_optimizer</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to include optimizer during serialization.`,name:"include_optimizer"},{anchor:"huggingface_hub.push_to_hub_keras.tags",description:`<strong>tags</strong> (Union[<code>list</code>, <code>str</code>], <em>optional</em>) &#x2014;
List of tags that are related to model or string of a single tag. See example tags
<a href="https://github.com/huggingface/hub-docs/blame/main/modelcard.md" rel="nofollow">here</a>.`,name:"tags"},{anchor:"huggingface_hub.push_to_hub_keras.plot_model",description:`<strong>plot_model</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Setting this to <code>True</code> will plot the model and put it in the model
card. Requires graphviz and pydot to be installed.`,name:"plot_model"},{anchor:"huggingface_hub.push_to_hub_keras.model_save_kwargs(dict,",description:`<strong>model_save_kwargs(<code>dict</code>,</strong> <em>optional</em>) &#x2014;
model_save_kwargs will be passed to
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model" rel="nofollow"><code>tf.keras.models.save_model()</code></a>.`,name:"model_save_kwargs(dict,"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.8.0.rc4/src/huggingface_hub/keras_mixin.py#L261",returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),ve=new W({props:{name:"huggingface_hub.save_pretrained_keras",anchor:"huggingface_hub.save_pretrained_keras",parameters:[{name:"model",val:""},{name:"save_directory",val:": str"},{name:"config",val:": typing.Union[typing.Dict[str, typing.Any], NoneType] = None"},{name:"include_optimizer",val:": typing.Optional[bool] = False"},{name:"plot_model",val:": typing.Optional[bool] = True"},{name:"tags",val:": typing.Union[list, str, NoneType] = None"},{name:"**model_save_kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.save_pretrained_keras.model",description:`<strong>model</strong> (<code>Keras.Model</code>) &#x2014;
The <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" rel="nofollow">Keras
model</a>
you&#x2019;d like to save. The model must be compiled and built.`,name:"model"},{anchor:"huggingface_hub.save_pretrained_keras.save_directory",description:`<strong>save_directory</strong> (<code>str</code>) &#x2014;
Specify directory in which you want to save the Keras model.`,name:"save_directory"},{anchor:"huggingface_hub.save_pretrained_keras.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"},{anchor:"huggingface_hub.save_pretrained_keras.include_optimizer(bool,",description:`<strong>include_optimizer(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to include optimizer in serialization.`,name:"include_optimizer(bool,"},{anchor:"huggingface_hub.save_pretrained_keras.plot_model",description:`<strong>plot_model</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Setting this to <code>True</code> will plot the model and put it in the model
card. Requires graphviz and pydot to be installed.`,name:"plot_model"},{anchor:"huggingface_hub.save_pretrained_keras.tags",description:`<strong>tags</strong> (Union[<code>str</code>,<code>list</code>], <em>optional</em>) &#x2014;
List of tags that are related to model or string of a single tag. See example tags
<a href="https://github.com/huggingface/hub-docs/blame/main/modelcard.md" rel="nofollow">here</a>.`,name:"tags"},{anchor:"huggingface_hub.save_pretrained_keras.model_save_kwargs(dict,",description:`<strong>model_save_kwargs(<code>dict</code>,</strong> <em>optional</em>) &#x2014;
model_save_kwargs will be passed to
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model" rel="nofollow"><code>tf.keras.models.save_model()</code></a>.`,name:"model_save_kwargs(dict,"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.8.0.rc4/src/huggingface_hub/keras_mixin.py#L110"}}),ye=new W({props:{name:"class huggingface_hub.KerasModelHubMixin",anchor:"huggingface_hub.KerasModelHubMixin",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.8.0.rc4/src/huggingface_hub/keras_mixin.py#L403"}}),xe=new po({}),ke=new W({props:{name:"huggingface_hub.from_pretrained_fastai",anchor:"huggingface_hub.from_pretrained_fastai",parameters:[{name:"repo_id",val:": str"},{name:"revision",val:": typing.Optional[str] = None"}],parametersDescription:[{anchor:"huggingface_hub.from_pretrained_fastai.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
The location where the pickled fastai.Learner is. It can be either of the two:<ul>
<li>Hosted on the Hugging Face Hub. E.g.: &#x2018;espejelomar/fatai-pet-breeds-classification&#x2019; or &#x2018;distilgpt2&#x2019;.
You can add a <code>revision</code> by appending <code>@</code> at the end of <code>repo_id</code>. E.g.: <code>dbmdz/bert-base-german-cased@main</code>.
Revision is the specific model version to use. Since we use a git-based system for storing models and other
artifacts on the Hugging Face Hub, it can be a branch name, a tag name, or a commit id.</li>
<li>Hosted locally. <code>repo_id</code> would be a directory containing the pickle and a pyproject.toml
indicating the fastai and fastcore versions used to build the <code>fastai.Learner</code>. E.g.: <code>./my_model_directory/</code>.</li>
</ul>`,name:"repo_id"},{anchor:"huggingface_hub.from_pretrained_fastai.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Revision at which the repo&#x2019;s files are downloaded. See documentation of <code>snapshot_download</code>.`,name:"revision"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.8.0.rc4/src/huggingface_hub/fastai_utils.py#L308",returnDescription:`
<p>The <code>fastai.Learner</code> model in the <code>repo_id</code> repo.</p>
`}}),$e=new W({props:{name:"huggingface_hub.push_to_hub_fastai",anchor:"huggingface_hub.push_to_hub_fastai",parameters:[{name:"learner",val:""},{name:"repo_id",val:": str"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"private",val:": typing.Optional[bool] = None"},{name:"token",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.push_to_hub_fastai.learner",description:`<strong>learner</strong> (<em>Learner</em>) &#x2014;
The *fastai.Learner&#x2019; you&#x2019;d like to push to the Hub.`,name:"learner"},{anchor:"huggingface_hub.push_to_hub_fastai.repo_id",description:`<strong>repo_id</strong> (<em>str</em>) &#x2014;
The repository id for your model in Hub in the format of &#x201C;namespace/repo_name&#x201D;. The namespace can be your individual account or an organization to which you have write access (for example, &#x2018;stanfordnlp/stanza-de&#x2019;).`,name:"repo_id"},{anchor:"huggingface_hub.push_to_hub_fastai.commit_message",description:"<strong>commit_message</strong> (<em>str`, </em>optional*) &#x2014; Message to commit while pushing. Will default to <code>&quot;add model&quot;</code>.",name:"commit_message"},{anchor:"huggingface_hub.push_to_hub_fastai.private",description:`<strong>private</strong> (<em>bool</em>, <em>optional</em>) &#x2014;
Whether or not the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.push_to_hub_fastai.token",description:`<strong>token</strong> (<em>str</em>, <em>optional</em>) &#x2014;
The Hugging Face account token to use as HTTP bearer authorization for remote files. If <code>None</code>, the token will be asked by a prompt.`,name:"token"},{anchor:"huggingface_hub.push_to_hub_fastai.config",description:`<strong>config</strong> (<em>dict</em>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.8.0.rc4/src/huggingface_hub/fastai_utils.py#L352",returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),re=new mn({props:{$$slots:{default:[ia]},$$scope:{ctx:Y}}}),{c(){h=n("meta"),H=d(),p=n("h1"),_=n("a"),v=n("span"),w(m.$$.fragment),f=d(),P=n("span"),de=i("Mixins & serialization methods"),T=d(),z=n("h2"),N=n("a"),q=n("span"),w(L.$$.fragment),He=d(),Ne=n("span"),Uo=i("Mixins"),_o=d(),J=n("p"),Ko=i("The "),Se=n("code"),Vo=i("huggingface_hub"),Ro=i(` library offers a range of mixins that can be used as a parent class for your
objects, in order to provide simple uploading and downloading functions.`),fo=d(),U=n("h3"),Q=n("a"),Ae=n("span"),w(le.$$.fragment),jo=d(),Ie=n("span"),Bo=i("PyTorch"),bo=d(),D=n("div"),w(ce.$$.fragment),Go=d(),S=n("p"),Yo=i(`A Generic Base Model Hub Mixin. Define your own mixin for anything by
inheriting from this class and overwriting `),Le=n("code"),Jo=i("_from_pretrained"),Qo=i(` and
`),Ce=n("code"),Xo=i("_save_pretrained"),Zo=i(` to define custom logic for saving/loading your classes.
See `),Fe=n("code"),et=i("huggingface_hub.PyTorchModelHubMixin"),ot=i(" for an example."),tt=d(),C=n("div"),w(he.$$.fragment),nt=d(),K=n("p"),at=i(`Instantiate a pretrained PyTorch model from a pre-trained model
configuration from huggingface-hub. The model is set in
evaluation mode by default using `),We=n("code"),rt=i("model.eval()"),it=i(` (Dropout modules
are deactivated). To train the model, you should first set it
back in training mode with `),qe=n("code"),st=i("model.train()"),dt=i("."),lt=d(),w(X.$$.fragment),ct=d(),Z=n("div"),w(ge.$$.fragment),ht=d(),ue=n("p"),gt=i(`Upload model checkpoint or tokenizer files to the Hub while
synchronizing a local clone of the repo in `),Ue=n("code"),ut=i("repo_path_or_name"),mt=i("."),pt=d(),ee=n("div"),w(me.$$.fragment),_t=d(),Ke=n("p"),ft=i("Save weights in local directory."),vo=d(),V=n("h3"),oe=n("a"),Ve=n("span"),w(pe.$$.fragment),bt=d(),Re=n("span"),vt=i("Keras"),yo=d(),A=n("div"),w(_e.$$.fragment),yt=d(),je=n("p"),wt=i("Instantiate a pretrained Keras model from a pre-trained model from the Hub.\nThe model is expected to be in SavedModel format.```"),xt=d(),w(te.$$.fragment),wo=d(),R=n("div"),w(fe.$$.fragment),kt=d(),be=n("p"),$t=i(`Upload model checkpoint or tokenizer files to the Hub while synchronizing a
local clone of the repo in `),Be=n("code"),Mt=i("repo_path_or_name"),Et=i("."),xo=d(),j=n("div"),w(ve.$$.fragment),Ht=d(),Ge=n("p"),Tt=i(`Saves a Keras model to save_directory in SavedModel format. Use this if
you\u2019re using the Functional or Sequential APIs.`),ko=d(),I=n("div"),w(ye.$$.fragment),zt=d(),Ye=n("p"),Pt=i(`Mixin to provide model Hub upload/download capabilities to Keras models.
Override this class to obtain the following internal methods:`),Dt=d(),we=n("ul"),Te=n("li"),Je=n("code"),Ot=i("_from_pretrained"),Nt=i(", to load a model from the Hub or from local files."),St=d(),ne=n("li"),Qe=n("code"),At=i("_save_pretrained"),It=i(", to save a model in the "),Xe=n("code"),Lt=i("SavedModel"),Ct=i(" format."),$o=d(),B=n("h3"),ae=n("a"),Ze=n("span"),w(xe.$$.fragment),Ft=d(),eo=n("span"),Wt=i("Fastai"),Mo=d(),G=n("div"),w(ke.$$.fragment),qt=d(),oo=n("p"),Ut=i("Load pretrained fastai model from the Hub or from a local directory."),Eo=d(),O=n("div"),w($e.$$.fragment),Kt=d(),Me=n("p"),Vt=i(`Upload learner checkpoint files to the Hub while synchronizing a local clone of the repo in
`),to=n("code"),Rt=i("repo_id"),jt=i("."),Bt=d(),b=n("p"),Gt=i(`Keyword Args:
api_endpoint (`),no=n("em"),Yt=i("str"),Jt=i(", "),ao=n("em"),Qt=i("optional"),Xt=i(`):
The API endpoint to use when pushing the model to the hub.
git_user (`),ro=n("em"),Zt=i("str"),en=i(", "),io=n("em"),on=i("optional"),tn=i(`):
Will override the `),so=n("code"),nn=i("git config user.name"),an=i(` for committing and pushing files to the hub.
git_email (`),lo=n("em"),rn=i("str"),sn=i(", "),co=n("em"),dn=i("optional"),ln=i(`):
Will override the `),ho=n("code"),cn=i("git config user.email"),hn=i(" for committing and pushing files to the hub."),gn=d(),w(re.$$.fragment),this.h()},l(o){const c=ta('[data-svelte="svelte-1phssyn"]',document.head);h=a(c,"META",{name:!0,content:!0}),c.forEach(t),H=l(o),p=a(o,"H1",{class:!0});var Ee=r(p);_=a(Ee,"A",{id:!0,class:!0,href:!0});var go=r(_);v=a(go,"SPAN",{});var uo=r(v);x(m.$$.fragment,uo),uo.forEach(t),go.forEach(t),f=l(Ee),P=a(Ee,"SPAN",{});var pn=r(P);de=s(pn,"Mixins & serialization methods"),pn.forEach(t),Ee.forEach(t),T=l(o),z=a(o,"H2",{class:!0});var To=r(z);N=a(To,"A",{id:!0,class:!0,href:!0});var _n=r(N);q=a(_n,"SPAN",{});var fn=r(q);x(L.$$.fragment,fn),fn.forEach(t),_n.forEach(t),He=l(To),Ne=a(To,"SPAN",{});var bn=r(Ne);Uo=s(bn,"Mixins"),bn.forEach(t),To.forEach(t),_o=l(o),J=a(o,"P",{});var zo=r(J);Ko=s(zo,"The "),Se=a(zo,"CODE",{});var vn=r(Se);Vo=s(vn,"huggingface_hub"),vn.forEach(t),Ro=s(zo,` library offers a range of mixins that can be used as a parent class for your
objects, in order to provide simple uploading and downloading functions.`),zo.forEach(t),fo=l(o),U=a(o,"H3",{class:!0});var Po=r(U);Q=a(Po,"A",{id:!0,class:!0,href:!0});var yn=r(Q);Ae=a(yn,"SPAN",{});var wn=r(Ae);x(le.$$.fragment,wn),wn.forEach(t),yn.forEach(t),jo=l(Po),Ie=a(Po,"SPAN",{});var xn=r(Ie);Bo=s(xn,"PyTorch"),xn.forEach(t),Po.forEach(t),bo=l(o),D=a(o,"DIV",{class:!0});var F=r(D);x(ce.$$.fragment,F),Go=l(F),S=a(F,"P",{});var ie=r(S);Yo=s(ie,`A Generic Base Model Hub Mixin. Define your own mixin for anything by
inheriting from this class and overwriting `),Le=a(ie,"CODE",{});var kn=r(Le);Jo=s(kn,"_from_pretrained"),kn.forEach(t),Qo=s(ie,` and
`),Ce=a(ie,"CODE",{});var $n=r(Ce);Xo=s($n,"_save_pretrained"),$n.forEach(t),Zo=s(ie,` to define custom logic for saving/loading your classes.
See `),Fe=a(ie,"CODE",{});var Mn=r(Fe);et=s(Mn,"huggingface_hub.PyTorchModelHubMixin"),Mn.forEach(t),ot=s(ie," for an example."),ie.forEach(t),tt=l(F),C=a(F,"DIV",{class:!0});var ze=r(C);x(he.$$.fragment,ze),nt=l(ze),K=a(ze,"P",{});var Pe=r(K);at=s(Pe,`Instantiate a pretrained PyTorch model from a pre-trained model
configuration from huggingface-hub. The model is set in
evaluation mode by default using `),We=a(Pe,"CODE",{});var En=r(We);rt=s(En,"model.eval()"),En.forEach(t),it=s(Pe,` (Dropout modules
are deactivated). To train the model, you should first set it
back in training mode with `),qe=a(Pe,"CODE",{});var Hn=r(qe);st=s(Hn,"model.train()"),Hn.forEach(t),dt=s(Pe,"."),Pe.forEach(t),lt=l(ze),x(X.$$.fragment,ze),ze.forEach(t),ct=l(F),Z=a(F,"DIV",{class:!0});var Do=r(Z);x(ge.$$.fragment,Do),ht=l(Do),ue=a(Do,"P",{});var Oo=r(ue);gt=s(Oo,`Upload model checkpoint or tokenizer files to the Hub while
synchronizing a local clone of the repo in `),Ue=a(Oo,"CODE",{});var Tn=r(Ue);ut=s(Tn,"repo_path_or_name"),Tn.forEach(t),mt=s(Oo,"."),Oo.forEach(t),Do.forEach(t),pt=l(F),ee=a(F,"DIV",{class:!0});var No=r(ee);x(me.$$.fragment,No),_t=l(No),Ke=a(No,"P",{});var zn=r(Ke);ft=s(zn,"Save weights in local directory."),zn.forEach(t),No.forEach(t),F.forEach(t),vo=l(o),V=a(o,"H3",{class:!0});var So=r(V);oe=a(So,"A",{id:!0,class:!0,href:!0});var Pn=r(oe);Ve=a(Pn,"SPAN",{});var Dn=r(Ve);x(pe.$$.fragment,Dn),Dn.forEach(t),Pn.forEach(t),bt=l(So),Re=a(So,"SPAN",{});var On=r(Re);vt=s(On,"Keras"),On.forEach(t),So.forEach(t),yo=l(o),A=a(o,"DIV",{class:!0});var De=r(A);x(_e.$$.fragment,De),yt=l(De),je=a(De,"P",{});var Nn=r(je);wt=s(Nn,"Instantiate a pretrained Keras model from a pre-trained model from the Hub.\nThe model is expected to be in SavedModel format.```"),Nn.forEach(t),xt=l(De),x(te.$$.fragment,De),De.forEach(t),wo=l(o),R=a(o,"DIV",{class:!0});var Ao=r(R);x(fe.$$.fragment,Ao),kt=l(Ao),be=a(Ao,"P",{});var Io=r(be);$t=s(Io,`Upload model checkpoint or tokenizer files to the Hub while synchronizing a
local clone of the repo in `),Be=a(Io,"CODE",{});var Sn=r(Be);Mt=s(Sn,"repo_path_or_name"),Sn.forEach(t),Et=s(Io,"."),Io.forEach(t),Ao.forEach(t),xo=l(o),j=a(o,"DIV",{class:!0});var Lo=r(j);x(ve.$$.fragment,Lo),Ht=l(Lo),Ge=a(Lo,"P",{});var An=r(Ge);Tt=s(An,`Saves a Keras model to save_directory in SavedModel format. Use this if
you\u2019re using the Functional or Sequential APIs.`),An.forEach(t),Lo.forEach(t),ko=l(o),I=a(o,"DIV",{class:!0});var Oe=r(I);x(ye.$$.fragment,Oe),zt=l(Oe),Ye=a(Oe,"P",{});var In=r(Ye);Pt=s(In,`Mixin to provide model Hub upload/download capabilities to Keras models.
Override this class to obtain the following internal methods:`),In.forEach(t),Dt=l(Oe),we=a(Oe,"UL",{});var Co=r(we);Te=a(Co,"LI",{});var un=r(Te);Je=a(un,"CODE",{});var Ln=r(Je);Ot=s(Ln,"_from_pretrained"),Ln.forEach(t),Nt=s(un,", to load a model from the Hub or from local files."),un.forEach(t),St=l(Co),ne=a(Co,"LI",{});var mo=r(ne);Qe=a(mo,"CODE",{});var Cn=r(Qe);At=s(Cn,"_save_pretrained"),Cn.forEach(t),It=s(mo,", to save a model in the "),Xe=a(mo,"CODE",{});var Fn=r(Xe);Lt=s(Fn,"SavedModel"),Fn.forEach(t),Ct=s(mo," format."),mo.forEach(t),Co.forEach(t),Oe.forEach(t),$o=l(o),B=a(o,"H3",{class:!0});var Fo=r(B);ae=a(Fo,"A",{id:!0,class:!0,href:!0});var Wn=r(ae);Ze=a(Wn,"SPAN",{});var qn=r(Ze);x(xe.$$.fragment,qn),qn.forEach(t),Wn.forEach(t),Ft=l(Fo),eo=a(Fo,"SPAN",{});var Un=r(eo);Wt=s(Un,"Fastai"),Un.forEach(t),Fo.forEach(t),Mo=l(o),G=a(o,"DIV",{class:!0});var Wo=r(G);x(ke.$$.fragment,Wo),qt=l(Wo),oo=a(Wo,"P",{});var Kn=r(oo);Ut=s(Kn,"Load pretrained fastai model from the Hub or from a local directory."),Kn.forEach(t),Wo.forEach(t),Eo=l(o),O=a(o,"DIV",{class:!0});var se=r(O);x($e.$$.fragment,se),Kt=l(se),Me=a(se,"P",{});var qo=r(Me);Vt=s(qo,`Upload learner checkpoint files to the Hub while synchronizing a local clone of the repo in
`),to=a(qo,"CODE",{});var Vn=r(to);Rt=s(Vn,"repo_id"),Vn.forEach(t),jt=s(qo,"."),qo.forEach(t),Bt=l(se),b=a(se,"P",{});var y=r(b);Gt=s(y,`Keyword Args:
api_endpoint (`),no=a(y,"EM",{});var Rn=r(no);Yt=s(Rn,"str"),Rn.forEach(t),Jt=s(y,", "),ao=a(y,"EM",{});var jn=r(ao);Qt=s(jn,"optional"),jn.forEach(t),Xt=s(y,`):
The API endpoint to use when pushing the model to the hub.
git_user (`),ro=a(y,"EM",{});var Bn=r(ro);Zt=s(Bn,"str"),Bn.forEach(t),en=s(y,", "),io=a(y,"EM",{});var Gn=r(io);on=s(Gn,"optional"),Gn.forEach(t),tn=s(y,`):
Will override the `),so=a(y,"CODE",{});var Yn=r(so);nn=s(Yn,"git config user.name"),Yn.forEach(t),an=s(y,` for committing and pushing files to the hub.
git_email (`),lo=a(y,"EM",{});var Jn=r(lo);rn=s(Jn,"str"),Jn.forEach(t),sn=s(y,", "),co=a(y,"EM",{});var Qn=r(co);dn=s(Qn,"optional"),Qn.forEach(t),ln=s(y,`):
Will override the `),ho=a(y,"CODE",{});var Xn=r(ho);cn=s(Xn,"git config user.email"),Xn.forEach(t),hn=s(y," for committing and pushing files to the hub."),y.forEach(t),gn=l(se),x(re.$$.fragment,se),se.forEach(t),this.h()},h(){g(h,"name","hf:doc:metadata"),g(h,"content",JSON.stringify(da)),g(_,"id","mixins-serialization-methods"),g(_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(_,"href","#mixins-serialization-methods"),g(p,"class","relative group"),g(N,"id","mixins"),g(N,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(N,"href","#mixins"),g(z,"class","relative group"),g(Q,"id","huggingface_hub.ModelHubMixin"),g(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(Q,"href","#huggingface_hub.ModelHubMixin"),g(U,"class","relative group"),g(C,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(Z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(ee,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(D,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(oe,"id","huggingface_hub.from_pretrained_keras"),g(oe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(oe,"href","#huggingface_hub.from_pretrained_keras"),g(V,"class","relative group"),g(A,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(R,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(j,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(I,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(ae,"id","huggingface_hub.from_pretrained_fastai"),g(ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(ae,"href","#huggingface_hub.from_pretrained_fastai"),g(B,"class","relative group"),g(G,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(O,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(o,c){e(document.head,h),u(o,H,c),u(o,p,c),e(p,_),e(_,v),k(m,v,null),e(p,f),e(p,P),e(P,de),u(o,T,c),u(o,z,c),e(z,N),e(N,q),k(L,q,null),e(z,He),e(z,Ne),e(Ne,Uo),u(o,_o,c),u(o,J,c),e(J,Ko),e(J,Se),e(Se,Vo),e(J,Ro),u(o,fo,c),u(o,U,c),e(U,Q),e(Q,Ae),k(le,Ae,null),e(U,jo),e(U,Ie),e(Ie,Bo),u(o,bo,c),u(o,D,c),k(ce,D,null),e(D,Go),e(D,S),e(S,Yo),e(S,Le),e(Le,Jo),e(S,Qo),e(S,Ce),e(Ce,Xo),e(S,Zo),e(S,Fe),e(Fe,et),e(S,ot),e(D,tt),e(D,C),k(he,C,null),e(C,nt),e(C,K),e(K,at),e(K,We),e(We,rt),e(K,it),e(K,qe),e(qe,st),e(K,dt),e(C,lt),k(X,C,null),e(D,ct),e(D,Z),k(ge,Z,null),e(Z,ht),e(Z,ue),e(ue,gt),e(ue,Ue),e(Ue,ut),e(ue,mt),e(D,pt),e(D,ee),k(me,ee,null),e(ee,_t),e(ee,Ke),e(Ke,ft),u(o,vo,c),u(o,V,c),e(V,oe),e(oe,Ve),k(pe,Ve,null),e(V,bt),e(V,Re),e(Re,vt),u(o,yo,c),u(o,A,c),k(_e,A,null),e(A,yt),e(A,je),e(je,wt),e(A,xt),k(te,A,null),u(o,wo,c),u(o,R,c),k(fe,R,null),e(R,kt),e(R,be),e(be,$t),e(be,Be),e(Be,Mt),e(be,Et),u(o,xo,c),u(o,j,c),k(ve,j,null),e(j,Ht),e(j,Ge),e(Ge,Tt),u(o,ko,c),u(o,I,c),k(ye,I,null),e(I,zt),e(I,Ye),e(Ye,Pt),e(I,Dt),e(I,we),e(we,Te),e(Te,Je),e(Je,Ot),e(Te,Nt),e(we,St),e(we,ne),e(ne,Qe),e(Qe,At),e(ne,It),e(ne,Xe),e(Xe,Lt),e(ne,Ct),u(o,$o,c),u(o,B,c),e(B,ae),e(ae,Ze),k(xe,Ze,null),e(B,Ft),e(B,eo),e(eo,Wt),u(o,Mo,c),u(o,G,c),k(ke,G,null),e(G,qt),e(G,oo),e(oo,Ut),u(o,Eo,c),u(o,O,c),k($e,O,null),e(O,Kt),e(O,Me),e(Me,Vt),e(Me,to),e(to,Rt),e(Me,jt),e(O,Bt),e(O,b),e(b,Gt),e(b,no),e(no,Yt),e(b,Jt),e(b,ao),e(ao,Qt),e(b,Xt),e(b,ro),e(ro,Zt),e(b,en),e(b,io),e(io,on),e(b,tn),e(b,so),e(so,nn),e(b,an),e(b,lo),e(lo,rn),e(b,sn),e(b,co),e(co,dn),e(b,ln),e(b,ho),e(ho,cn),e(b,hn),e(O,gn),k(re,O,null),Ho=!0},p(o,[c]){const Ee={};c&2&&(Ee.$$scope={dirty:c,ctx:o}),X.$set(Ee);const go={};c&2&&(go.$$scope={dirty:c,ctx:o}),te.$set(go);const uo={};c&2&&(uo.$$scope={dirty:c,ctx:o}),re.$set(uo)},i(o){Ho||($(m.$$.fragment,o),$(L.$$.fragment,o),$(le.$$.fragment,o),$(ce.$$.fragment,o),$(he.$$.fragment,o),$(X.$$.fragment,o),$(ge.$$.fragment,o),$(me.$$.fragment,o),$(pe.$$.fragment,o),$(_e.$$.fragment,o),$(te.$$.fragment,o),$(fe.$$.fragment,o),$(ve.$$.fragment,o),$(ye.$$.fragment,o),$(xe.$$.fragment,o),$(ke.$$.fragment,o),$($e.$$.fragment,o),$(re.$$.fragment,o),Ho=!0)},o(o){M(m.$$.fragment,o),M(L.$$.fragment,o),M(le.$$.fragment,o),M(ce.$$.fragment,o),M(he.$$.fragment,o),M(X.$$.fragment,o),M(ge.$$.fragment,o),M(me.$$.fragment,o),M(pe.$$.fragment,o),M(_e.$$.fragment,o),M(te.$$.fragment,o),M(fe.$$.fragment,o),M(ve.$$.fragment,o),M(ye.$$.fragment,o),M(xe.$$.fragment,o),M(ke.$$.fragment,o),M($e.$$.fragment,o),M(re.$$.fragment,o),Ho=!1},d(o){t(h),o&&t(H),o&&t(p),E(m),o&&t(T),o&&t(z),E(L),o&&t(_o),o&&t(J),o&&t(fo),o&&t(U),E(le),o&&t(bo),o&&t(D),E(ce),E(he),E(X),E(ge),E(me),o&&t(vo),o&&t(V),E(pe),o&&t(yo),o&&t(A),E(_e),E(te),o&&t(wo),o&&t(R),E(fe),o&&t(xo),o&&t(j),E(ve),o&&t(ko),o&&t(I),E(ye),o&&t($o),o&&t(B),E(xe),o&&t(Mo),o&&t(G),E(ke),o&&t(Eo),o&&t(O),E($e),E(re)}}}const da={local:"mixins-serialization-methods",sections:[{local:"mixins",sections:[{local:"huggingface_hub.ModelHubMixin",title:"PyTorch"},{local:"huggingface_hub.from_pretrained_keras",title:"Keras"},{local:"huggingface_hub.from_pretrained_fastai",title:"Fastai"}],title:"Mixins"}],title:"Mixins & serialization methods"};function la(Y){return na(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ma extends Zn{constructor(h){super();ea(this,h,la,sa,oa,{})}}export{ma as default,da as metadata};
