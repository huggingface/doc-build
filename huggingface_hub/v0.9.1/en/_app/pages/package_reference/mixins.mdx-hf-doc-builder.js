import{S as Ta,i as Ha,s as Na,e as n,k as d,w,t as i,M as Pa,c as a,d as t,m as l,a as r,x,h as s,b as h,G as e,g as p,y as $,q as k,o as E,B as M,v as Oa}from"../../chunks/vendor-hf-doc-builder.js";import{T as Ln}from"../../chunks/Tip-hf-doc-builder.js";import{D as V}from"../../chunks/Docstring-hf-doc-builder.js";import{I as Mo}from"../../chunks/IconCopyLink-hf-doc-builder.js";function Da(X){let g,T,m,f,v;return{c(){g=n("p"),T=i("Passing "),m=n("code"),f=i("use_auth_token=True"),v=i(` is required when you want to use a
private model.`)},l(u){g=a(u,"P",{});var _=r(g);T=s(_,"Passing "),m=a(_,"CODE",{});var P=r(m);f=s(P,"use_auth_token=True"),P.forEach(t),v=s(_,` is required when you want to use a
private model.`),_.forEach(t)},m(u,_){p(u,g,_),e(g,T),e(g,m),e(m,f),e(g,v)},d(u){u&&t(g)}}}function za(X){let g,T,m,f,v;return{c(){g=n("p"),T=i("Passing "),m=n("code"),f=i("use_auth_token=True"),v=i(` is required when you want to use a private
model.`)},l(u){g=a(u,"P",{});var _=r(g);T=s(_,"Passing "),m=a(_,"CODE",{});var P=r(m);f=s(P,"use_auth_token=True"),P.forEach(t),v=s(_,` is required when you want to use a private
model.`),_.forEach(t)},m(u,_){p(u,g,_),e(g,T),e(g,m),e(m,f),e(g,v)},d(u){u&&t(g)}}}function Aa(X){let g,T,m,f,v,u,_,P,ge;return{c(){g=n("p"),T=i("Raises the following error:"),m=d(),f=n("ul"),v=n("li"),u=n("a"),_=n("em"),P=i("ValueError"),ge=i(`
if the user is not log on to the Hugging Face Hub.`),this.h()},l(H){g=a(H,"P",{});var N=r(g);T=s(N,"Raises the following error:"),N.forEach(t),m=l(H),f=a(H,"UL",{});var z=r(f);v=a(z,"LI",{});var R=r(v);u=a(R,"A",{href:!0,rel:!0});var U=r(u);_=a(U,"EM",{});var Pe=r(_);P=s(Pe,"ValueError"),Pe.forEach(t),U.forEach(t),ge=s(R,`
if the user is not log on to the Hugging Face Hub.`),R.forEach(t),z.forEach(t),this.h()},h(){h(u,"href","https://docs.python.org/3/library/exceptions.html#ValueError"),h(u,"rel","nofollow")},m(H,N){p(H,g,N),e(g,T),p(H,m,N),p(H,f,N),e(f,v),e(v,u),e(u,_),e(_,P),e(v,ge)},d(H){H&&t(g),H&&t(m),H&&t(f)}}}function Sa(X){let g,T,m,f,v,u,_,P,ge,H,N,z,R,U,Pe,Ue,Jo,To,Z,Qo,qe,Xo,Zo,Ho,j,ee,We,pe,et,Ke,ot,No,O,ue,tt,A,nt,Ve,at,rt,Re,it,st,je,dt,lt,ct,q,me,ht,B,gt,Be,pt,ut,Ye,mt,ft,_t,oe,bt,W,fe,vt,Ge,yt,wt,S,xt,Je,$t,kt,Qe,Et,Mt,Oe,Tt,Ht,Nt,te,_e,Pt,Xe,Ot,Po,Y,ne,Ze,be,Dt,eo,zt,Oo,L,ve,At,oo,St,Lt,ae,Do,I,ye,It,we,Ct,to,Ft,Ut,qt,C,Wt,no,Kt,Vt,ao,Rt,jt,De,Bt,Yt,zo,G,xe,Gt,ro,Jt,Ao,F,$e,Qt,io,Xt,Zt,ke,ze,so,en,on,tn,re,lo,nn,an,co,rn,sn,So,J,ie,ho,Ee,dn,go,ln,Lo,Q,Me,cn,po,hn,Io,D,Te,gn,He,pn,uo,un,mn,fn,b,_n,mo,bn,vn,fo,yn,wn,_o,xn,$n,bo,kn,En,vo,Mn,Tn,yo,Hn,Nn,wo,Pn,On,xo,Dn,zn,An,se,Co;return u=new Mo({}),U=new Mo({}),pe=new Mo({}),ue=new V({props:{name:"class huggingface_hub.ModelHubMixin",anchor:"huggingface_hub.ModelHubMixin",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/v0.9.1/src/huggingface_hub/hub_mixin.py#L24"}}),me=new V({props:{name:"from_pretrained",anchor:"huggingface_hub.ModelHubMixin.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:": str"},{name:"force_download",val:": bool = False"},{name:"resume_download",val:": bool = False"},{name:"proxies",val:": typing.Dict = None"},{name:"use_auth_token",val:": typing.Optional[str] = None"},{name:"cache_dir",val:": typing.Optional[str] = None"},{name:"local_files_only",val:": bool = False"},{name:"**model_kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:<ul>
<li>A string, the <code>model id</code> of a pretrained model
hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level,
like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like
<code>dbmdz/bert-base-german-cased</code>.</li>
<li>You can add <code>revision</code> by appending <code>@</code> at the end
of model_id simply like this:
<code>dbmdz/bert-base-german-cased@main</code> Revision is
the specific model version to use. It can be a
branch name, a tag name, or a commit id, since we
use a git-based system for storing models and
other artifacts on huggingface.co, so <code>revision</code>
can be any identifier allowed by git.</li>
<li>A path to a <code>directory</code> containing model weights
saved using
<a href="https://huggingface.co/docs/transformers/v4.21.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained" rel="nofollow">save_pretrained</a>,
e.g., <code>./my_model_directory/</code>.</li>
<li><code>None</code> if you are both providing the configuration
and state dictionary (resp. with keyword arguments
<code>config</code> and <code>state_dict</code>).</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to force the (re-)download of the model weights
and configuration files, overriding the cached versions
if they exist.`,name:"force_download"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to delete incompletely received files. Will
attempt to resume the download if such a file exists.`,name:"resume_download"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or
endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are
used on each request.`,name:"proxies"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote
files. If <code>True</code>, will use the token generated when
running <code>transformers-cli login</code> (stored in
<code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>Union[str, os.PathLike]</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained
model configuration should be cached if the standard
cache should not be used.`,name:"cache_dir"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to only look at local files (i.e., do not try to
download the model).`,name:"local_files_only(bool,"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.model_kwargs",description:`<strong>model_kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
model_kwargs will be passed to the model during
initialization`,name:"model_kwargs"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.9.1/src/huggingface_hub/hub_mixin.py#L100"}}),oe=new Ln({props:{$$slots:{default:[Da]},$$scope:{ctx:X}}}),fe=new V({props:{name:"push_to_hub",anchor:"huggingface_hub.ModelHubMixin.push_to_hub",parameters:[{name:"repo_path_or_name",val:": typing.Optional[str] = None"},{name:"repo_url",val:": typing.Optional[str] = None"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"organization",val:": typing.Optional[str] = None"},{name:"private",val:": typing.Optional[bool] = None"},{name:"api_endpoint",val:": typing.Optional[str] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = None"},{name:"git_user",val:": typing.Optional[str] = None"},{name:"git_email",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"},{name:"skip_lfs_files",val:": bool = False"},{name:"repo_id",val:": typing.Optional[str] = None"},{name:"token",val:": typing.Optional[str] = None"},{name:"branch",val:": typing.Optional[str] = None"},{name:"create_pr",val:": typing.Optional[bool] = None"},{name:"allow_patterns",val:": typing.Union[typing.List[str], str, NoneType] = None"},{name:"ignore_patterns",val:": typing.Union[typing.List[str], str, NoneType] = None"}],parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.repo_id",description:`<strong>repo_id</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Repository name to which push.`,name:"repo_id"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Message to commit while pushing.`,name:"commit_message"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.api_endpoint",description:`<strong>api_endpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The API endpoint to use when pushing the model to the hub.`,name:"api_endpoint"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files.
If not set, will use the token set when logging in with
<code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"token"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.branch",description:`<strong>branch</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The git branch on which to push the model. This defaults to
the default branch as specified in your repository, which
defaults to <code>&quot;main&quot;</code>.`,name:"branch"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.create_pr",description:`<strong>create_pr</strong> (<code>boolean</code>, <em>optional</em>) &#x2014;
Whether or not to create a Pull Request from <code>branch</code> with that commit.
Defaults to <code>False</code>.`,name:"create_pr"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.allow_patterns",description:`<strong>allow_patterns</strong> (<code>List[str]</code> or <code>str</code>, <em>optional</em>) &#x2014;
If provided, only files matching at least one pattern are pushed.`,name:"allow_patterns"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.ignore_patterns",description:`<strong>ignore_patterns</strong> (<code>List[str]</code> or <code>str</code>, <em>optional</em>) &#x2014;
If provided, files matching any of the patterns are not pushed.`,name:"ignore_patterns"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.9.1/src/huggingface_hub/hub_mixin.py#L238",returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),_e=new V({props:{name:"save_pretrained",anchor:"huggingface_hub.ModelHubMixin.save_pretrained",parameters:[{name:"save_directory",val:": str"},{name:"config",val:": typing.Optional[dict] = None"},{name:"push_to_hub",val:": bool = False"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code>) &#x2014;
Specify directory in which you want to save weights.`,name:"save_directory"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Specify config (must be dict) in case you want to save
it.`,name:"config"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.push_to_hub",description:`<strong>push_to_hub</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to push your model to the Hugging Face model hub after
saving it. You can specify the repository you want to push to with
<code>repo_id</code> (will default to the name of <code>save_directory</code> in your
namespace).
kwargs &#x2014;
Additional key word arguments passed along to the
<code>push_to_hub</code> method.`,name:"push_to_hub"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.9.1/src/huggingface_hub/hub_mixin.py#L32"}}),be=new Mo({}),ve=new V({props:{name:"huggingface_hub.from_pretrained_keras",anchor:"huggingface_hub.from_pretrained_keras",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.from_pretrained_keras.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:<ul>
<li>A string, the <code>model id</code> of a pretrained model hosted inside a
model repo on huggingface.co. Valid model ids can be located
at the root-level, like <code>bert-base-uncased</code>, or namespaced
under a user or organization name, like
<code>dbmdz/bert-base-german-cased</code>.</li>
<li>You can add <code>revision</code> by appending <code>@</code> at the end of model_id
simply like this: <code>dbmdz/bert-base-german-cased@main</code> Revision
is the specific model version to use. It can be a branch name,
a tag name, or a commit id, since we use a git-based system
for storing models and other artifacts on huggingface.co, so
<code>revision</code> can be any identifier allowed by git.</li>
<li>A path to a <code>directory</code> containing model weights saved using
<a href="https://huggingface.co/docs/transformers/v4.21.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained" rel="nofollow">save_pretrained</a>, e.g.,
<code>./my_model_directory/</code>.</li>
<li><code>None</code> if you are both providing the configuration and state
dictionary (resp. with keyword arguments <code>config</code> and
<code>state_dict</code>).</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"huggingface_hub.from_pretrained_keras.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to force the (re-)download of the model weights and
configuration files, overriding the cached versions if they exist.`,name:"force_download"},{anchor:"huggingface_hub.from_pretrained_keras.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to delete incompletely received files. Will attempt to
resume the download if such a file exists.`,name:"resume_download"},{anchor:"huggingface_hub.from_pretrained_keras.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g.,
<code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The
proxies are used on each request.`,name:"proxies"},{anchor:"huggingface_hub.from_pretrained_keras.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If
<code>True</code>, will use the token generated when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"huggingface_hub.from_pretrained_keras.cache_dir",description:`<strong>cache_dir</strong> (<code>Union[str, os.PathLike]</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model
configuration should be cached if the standard cache should not be
used.`,name:"cache_dir"},{anchor:"huggingface_hub.from_pretrained_keras.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to only look at local files (i.e., do not try to download
the model).`,name:"local_files_only(bool,"},{anchor:"huggingface_hub.from_pretrained_keras.model_kwargs",description:`<strong>model_kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
model_kwargs will be passed to the model during initialization`,name:"model_kwargs"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.9.1/src/huggingface_hub/keras_mixin.py#L238"}}),ae=new Ln({props:{$$slots:{default:[za]},$$scope:{ctx:X}}}),ye=new V({props:{name:"huggingface_hub.push_to_hub_keras",anchor:"huggingface_hub.push_to_hub_keras",parameters:[{name:"model",val:""},{name:"repo_path_or_name",val:": typing.Optional[str] = None"},{name:"repo_url",val:": typing.Optional[str] = None"},{name:"log_dir",val:": typing.Optional[str] = None"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"organization",val:": typing.Optional[str] = None"},{name:"private",val:": typing.Optional[bool] = None"},{name:"api_endpoint",val:": typing.Optional[str] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = True"},{name:"git_user",val:": typing.Optional[str] = None"},{name:"git_email",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"},{name:"include_optimizer",val:": typing.Optional[bool] = False"},{name:"tags",val:": typing.Union[list, str, NoneType] = None"},{name:"plot_model",val:": typing.Optional[bool] = True"},{name:"token",val:": typing.Optional[str] = True"},{name:"repo_id",val:": typing.Optional[str] = None"},{name:"branch",val:": typing.Optional[str] = None"},{name:"create_pr",val:": typing.Optional[bool] = None"},{name:"allow_patterns",val:": typing.Union[typing.List[str], str, NoneType] = None"},{name:"ignore_patterns",val:": typing.Union[typing.List[str], str, NoneType] = None"},{name:"**model_save_kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.push_to_hub_keras.model",description:`<strong>model</strong> (<code>Keras.Model</code>) &#x2014;
The <a href="%60https://www.tensorflow.org/api_docs/python/tf/keras/Model%60">Keras
model</a>
you&#x2019;d like to push to the Hub. The model must be compiled and built.`,name:"model"},{anchor:"huggingface_hub.push_to_hub_keras.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
Repository name to which push`,name:"repo_id"},{anchor:"huggingface_hub.push_to_hub_keras.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>, defaults to &#x201C;Add message&#x201D;) &#x2014;
Message to commit while pushing.`,name:"commit_message"},{anchor:"huggingface_hub.push_to_hub_keras.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.push_to_hub_keras.api_endpoint",description:`<strong>api_endpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The API endpoint to use when pushing the model to the hub.`,name:"api_endpoint"},{anchor:"huggingface_hub.push_to_hub_keras.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If
not set, will use the token set when logging in with
<code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"token"},{anchor:"huggingface_hub.push_to_hub_keras.branch",description:`<strong>branch</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The git branch on which to push the model. This defaults to
the default branch as specified in your repository, which
defaults to <code>&quot;main&quot;</code>.`,name:"branch"},{anchor:"huggingface_hub.push_to_hub_keras.create_pr",description:`<strong>create_pr</strong> (<code>boolean</code>, <em>optional</em>) &#x2014;
Whether or not to create a Pull Request from <code>branch</code> with that commit.
Defaults to <code>False</code>.`,name:"create_pr"},{anchor:"huggingface_hub.push_to_hub_keras.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"},{anchor:"huggingface_hub.push_to_hub_keras.allow_patterns",description:`<strong>allow_patterns</strong> (<code>List[str]</code> or <code>str</code>, <em>optional</em>) &#x2014;
If provided, only files matching at least one pattern are pushed.`,name:"allow_patterns"},{anchor:"huggingface_hub.push_to_hub_keras.ignore_patterns",description:`<strong>ignore_patterns</strong> (<code>List[str]</code> or <code>str</code>, <em>optional</em>) &#x2014;
If provided, files matching any of the patterns are not pushed.`,name:"ignore_patterns"},{anchor:"huggingface_hub.push_to_hub_keras.log_dir",description:`<strong>log_dir</strong> (<code>str</code>, <em>optional</em>) &#x2014;
TensorBoard logging directory to be pushed. The Hub automatically
hosts and displays a TensorBoard instance if log files are included
in the repository.`,name:"log_dir"},{anchor:"huggingface_hub.push_to_hub_keras.include_optimizer",description:`<strong>include_optimizer</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to include optimizer during serialization.`,name:"include_optimizer"},{anchor:"huggingface_hub.push_to_hub_keras.tags",description:`<strong>tags</strong> (Union[<code>list</code>, <code>str</code>], <em>optional</em>) &#x2014;
List of tags that are related to model or string of a single tag. See example tags
<a href="https://github.com/huggingface/hub-docs/blame/main/modelcard.md" rel="nofollow">here</a>.`,name:"tags"},{anchor:"huggingface_hub.push_to_hub_keras.plot_model",description:`<strong>plot_model</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Setting this to <code>True</code> will plot the model and put it in the model
card. Requires graphviz and pydot to be installed.`,name:"plot_model"},{anchor:"huggingface_hub.push_to_hub_keras.model_save_kwargs(dict,",description:`<strong>model_save_kwargs(<code>dict</code>,</strong> <em>optional</em>) &#x2014;
model_save_kwargs will be passed to
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model" rel="nofollow"><code>tf.keras.models.save_model()</code></a>.`,name:"model_save_kwargs(dict,"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.9.1/src/huggingface_hub/keras_mixin.py#L297",returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),xe=new V({props:{name:"huggingface_hub.save_pretrained_keras",anchor:"huggingface_hub.save_pretrained_keras",parameters:[{name:"model",val:""},{name:"save_directory",val:": str"},{name:"config",val:": typing.Union[typing.Dict[str, typing.Any], NoneType] = None"},{name:"include_optimizer",val:": typing.Optional[bool] = False"},{name:"plot_model",val:": typing.Optional[bool] = True"},{name:"tags",val:": typing.Union[list, str, NoneType] = None"},{name:"**model_save_kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.save_pretrained_keras.model",description:`<strong>model</strong> (<code>Keras.Model</code>) &#x2014;
The <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" rel="nofollow">Keras
model</a>
you&#x2019;d like to save. The model must be compiled and built.`,name:"model"},{anchor:"huggingface_hub.save_pretrained_keras.save_directory",description:`<strong>save_directory</strong> (<code>str</code>) &#x2014;
Specify directory in which you want to save the Keras model.`,name:"save_directory"},{anchor:"huggingface_hub.save_pretrained_keras.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"},{anchor:"huggingface_hub.save_pretrained_keras.include_optimizer(bool,",description:`<strong>include_optimizer(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to include optimizer in serialization.`,name:"include_optimizer(bool,"},{anchor:"huggingface_hub.save_pretrained_keras.plot_model",description:`<strong>plot_model</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Setting this to <code>True</code> will plot the model and put it in the model
card. Requires graphviz and pydot to be installed.`,name:"plot_model"},{anchor:"huggingface_hub.save_pretrained_keras.tags",description:`<strong>tags</strong> (Union[<code>str</code>,<code>list</code>], <em>optional</em>) &#x2014;
List of tags that are related to model or string of a single tag. See example tags
<a href="https://github.com/huggingface/hub-docs/blame/main/modelcard.md" rel="nofollow">here</a>.`,name:"tags"},{anchor:"huggingface_hub.save_pretrained_keras.model_save_kwargs(dict,",description:`<strong>model_save_kwargs(<code>dict</code>,</strong> <em>optional</em>) &#x2014;
model_save_kwargs will be passed to
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model" rel="nofollow"><code>tf.keras.models.save_model()</code></a>.`,name:"model_save_kwargs(dict,"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.9.1/src/huggingface_hub/keras_mixin.py#L146"}}),$e=new V({props:{name:"class huggingface_hub.KerasModelHubMixin",anchor:"huggingface_hub.KerasModelHubMixin",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.9.1/src/huggingface_hub/keras_mixin.py#L542"}}),Ee=new Mo({}),Me=new V({props:{name:"huggingface_hub.from_pretrained_fastai",anchor:"huggingface_hub.from_pretrained_fastai",parameters:[{name:"repo_id",val:": str"},{name:"revision",val:": typing.Optional[str] = None"}],parametersDescription:[{anchor:"huggingface_hub.from_pretrained_fastai.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
The location where the pickled fastai.Learner is. It can be either of the two:<ul>
<li>Hosted on the Hugging Face Hub. E.g.: &#x2018;espejelomar/fatai-pet-breeds-classification&#x2019; or &#x2018;distilgpt2&#x2019;.
You can add a <code>revision</code> by appending <code>@</code> at the end of <code>repo_id</code>. E.g.: <code>dbmdz/bert-base-german-cased@main</code>.
Revision is the specific model version to use. Since we use a git-based system for storing models and other
artifacts on the Hugging Face Hub, it can be a branch name, a tag name, or a commit id.</li>
<li>Hosted locally. <code>repo_id</code> would be a directory containing the pickle and a pyproject.toml
indicating the fastai and fastcore versions used to build the <code>fastai.Learner</code>. E.g.: <code>./my_model_directory/</code>.</li>
</ul>`,name:"repo_id"},{anchor:"huggingface_hub.from_pretrained_fastai.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Revision at which the repo&#x2019;s files are downloaded. See documentation of <code>snapshot_download</code>.`,name:"revision"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.9.1/src/huggingface_hub/fastai_utils.py#L308",returnDescription:`
<p>The <code>fastai.Learner</code> model in the <code>repo_id</code> repo.</p>
`}}),Te=new V({props:{name:"huggingface_hub.push_to_hub_fastai",anchor:"huggingface_hub.push_to_hub_fastai",parameters:[{name:"learner",val:""},{name:"repo_id",val:": str"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"private",val:": typing.Optional[bool] = None"},{name:"token",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.push_to_hub_fastai.learner",description:`<strong>learner</strong> (<em>Learner</em>) &#x2014;
The *fastai.Learner&#x2019; you&#x2019;d like to push to the Hub.`,name:"learner"},{anchor:"huggingface_hub.push_to_hub_fastai.repo_id",description:`<strong>repo_id</strong> (<em>str</em>) &#x2014;
The repository id for your model in Hub in the format of &#x201C;namespace/repo_name&#x201D;. The namespace can be your individual account or an organization to which you have write access (for example, &#x2018;stanfordnlp/stanza-de&#x2019;).`,name:"repo_id"},{anchor:"huggingface_hub.push_to_hub_fastai.commit_message",description:"<strong>commit_message</strong> (<em>str`, </em>optional*) &#x2014; Message to commit while pushing. Will default to <code>&quot;add model&quot;</code>.",name:"commit_message"},{anchor:"huggingface_hub.push_to_hub_fastai.private",description:`<strong>private</strong> (<em>bool</em>, <em>optional</em>) &#x2014;
Whether or not the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.push_to_hub_fastai.token",description:`<strong>token</strong> (<em>str</em>, <em>optional</em>) &#x2014;
The Hugging Face account token to use as HTTP bearer authorization for remote files. If <code>None</code>, the token will be asked by a prompt.`,name:"token"},{anchor:"huggingface_hub.push_to_hub_fastai.config",description:`<strong>config</strong> (<em>dict</em>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.9.1/src/huggingface_hub/fastai_utils.py#L352",returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),se=new Ln({props:{$$slots:{default:[Aa]},$$scope:{ctx:X}}}),{c(){g=n("meta"),T=d(),m=n("h1"),f=n("a"),v=n("span"),w(u.$$.fragment),_=d(),P=n("span"),ge=i("Mixins & serialization methods"),H=d(),N=n("h2"),z=n("a"),R=n("span"),w(U.$$.fragment),Pe=d(),Ue=n("span"),Jo=i("Mixins"),To=d(),Z=n("p"),Qo=i("The "),qe=n("code"),Xo=i("huggingface_hub"),Zo=i(` library offers a range of mixins that can be used as a parent class for your
objects, in order to provide simple uploading and downloading functions.`),Ho=d(),j=n("h3"),ee=n("a"),We=n("span"),w(pe.$$.fragment),et=d(),Ke=n("span"),ot=i("PyTorch"),No=d(),O=n("div"),w(ue.$$.fragment),tt=d(),A=n("p"),nt=i(`A Generic Base Model Hub Mixin. Define your own mixin for anything by
inheriting from this class and overwriting `),Ve=n("code"),at=i("_from_pretrained"),rt=i(` and
`),Re=n("code"),it=i("_save_pretrained"),st=i(` to define custom logic for saving/loading your classes.
See `),je=n("code"),dt=i("huggingface_hub.PyTorchModelHubMixin"),lt=i(" for an example."),ct=d(),q=n("div"),w(me.$$.fragment),ht=d(),B=n("p"),gt=i(`Instantiate a pretrained PyTorch model from a pre-trained model
configuration from huggingface-hub. The model is set in
evaluation mode by default using `),Be=n("code"),pt=i("model.eval()"),ut=i(` (Dropout modules
are deactivated). To train the model, you should first set it
back in training mode with `),Ye=n("code"),mt=i("model.train()"),ft=i("."),_t=d(),w(oe.$$.fragment),bt=d(),W=n("div"),w(fe.$$.fragment),vt=d(),Ge=n("p"),yt=i("Upload model checkpoint to the Hub."),wt=d(),S=n("p"),xt=i("Use "),Je=n("code"),$t=i("allow_patterns"),kt=i(" and "),Qe=n("code"),Et=i("ignore_patterns"),Mt=i(` to precisely filter which files
should be pushed to the hub. See `),Oe=n("a"),Tt=i("upload_folder()"),Ht=i(" reference for more details."),Nt=d(),te=n("div"),w(_e.$$.fragment),Pt=d(),Xe=n("p"),Ot=i("Save weights in local directory."),Po=d(),Y=n("h3"),ne=n("a"),Ze=n("span"),w(be.$$.fragment),Dt=d(),eo=n("span"),zt=i("Keras"),Oo=d(),L=n("div"),w(ve.$$.fragment),At=d(),oo=n("p"),St=i("Instantiate a pretrained Keras model from a pre-trained model from the Hub.\nThe model is expected to be in SavedModel format.```"),Lt=d(),w(ae.$$.fragment),Do=d(),I=n("div"),w(ye.$$.fragment),It=d(),we=n("p"),Ct=i(`Upload model checkpoint or tokenizer files to the Hub while synchronizing a
local clone of the repo in `),to=n("code"),Ft=i("repo_path_or_name"),Ut=i("."),qt=d(),C=n("p"),Wt=i("Use "),no=n("code"),Kt=i("allow_patterns"),Vt=i(" and "),ao=n("code"),Rt=i("ignore_patterns"),jt=i(` to precisely filter which files should be
pushed to the hub. See `),De=n("a"),Bt=i("upload_folder()"),Yt=i(" reference for more details."),zo=d(),G=n("div"),w(xe.$$.fragment),Gt=d(),ro=n("p"),Jt=i(`Saves a Keras model to save_directory in SavedModel format. Use this if
you\u2019re using the Functional or Sequential APIs.`),Ao=d(),F=n("div"),w($e.$$.fragment),Qt=d(),io=n("p"),Xt=i(`Mixin to provide model Hub upload/download capabilities to Keras models.
Override this class to obtain the following internal methods:`),Zt=d(),ke=n("ul"),ze=n("li"),so=n("code"),en=i("_from_pretrained"),on=i(", to load a model from the Hub or from local files."),tn=d(),re=n("li"),lo=n("code"),nn=i("_save_pretrained"),an=i(", to save a model in the "),co=n("code"),rn=i("SavedModel"),sn=i(" format."),So=d(),J=n("h3"),ie=n("a"),ho=n("span"),w(Ee.$$.fragment),dn=d(),go=n("span"),ln=i("Fastai"),Lo=d(),Q=n("div"),w(Me.$$.fragment),cn=d(),po=n("p"),hn=i("Load pretrained fastai model from the Hub or from a local directory."),Io=d(),D=n("div"),w(Te.$$.fragment),gn=d(),He=n("p"),pn=i(`Upload learner checkpoint files to the Hub while synchronizing a local clone of the repo in
`),uo=n("code"),un=i("repo_id"),mn=i("."),fn=d(),b=n("p"),_n=i(`Keyword Args:
api_endpoint (`),mo=n("em"),bn=i("str"),vn=i(", "),fo=n("em"),yn=i("optional"),wn=i(`):
The API endpoint to use when pushing the model to the hub.
git_user (`),_o=n("em"),xn=i("str"),$n=i(", "),bo=n("em"),kn=i("optional"),En=i(`):
Will override the `),vo=n("code"),Mn=i("git config user.name"),Tn=i(` for committing and pushing files to the hub.
git_email (`),yo=n("em"),Hn=i("str"),Nn=i(", "),wo=n("em"),Pn=i("optional"),On=i(`):
Will override the `),xo=n("code"),Dn=i("git config user.email"),zn=i(" for committing and pushing files to the hub."),An=d(),w(se.$$.fragment),this.h()},l(o){const c=Pa('[data-svelte="svelte-1phssyn"]',document.head);g=a(c,"META",{name:!0,content:!0}),c.forEach(t),T=l(o),m=a(o,"H1",{class:!0});var Ne=r(m);f=a(Ne,"A",{id:!0,class:!0,href:!0});var $o=r(f);v=a($o,"SPAN",{});var ko=r(v);x(u.$$.fragment,ko),ko.forEach(t),$o.forEach(t),_=l(Ne),P=a(Ne,"SPAN",{});var In=r(P);ge=s(In,"Mixins & serialization methods"),In.forEach(t),Ne.forEach(t),H=l(o),N=a(o,"H2",{class:!0});var Fo=r(N);z=a(Fo,"A",{id:!0,class:!0,href:!0});var Cn=r(z);R=a(Cn,"SPAN",{});var Fn=r(R);x(U.$$.fragment,Fn),Fn.forEach(t),Cn.forEach(t),Pe=l(Fo),Ue=a(Fo,"SPAN",{});var Un=r(Ue);Jo=s(Un,"Mixins"),Un.forEach(t),Fo.forEach(t),To=l(o),Z=a(o,"P",{});var Uo=r(Z);Qo=s(Uo,"The "),qe=a(Uo,"CODE",{});var qn=r(qe);Xo=s(qn,"huggingface_hub"),qn.forEach(t),Zo=s(Uo,` library offers a range of mixins that can be used as a parent class for your
objects, in order to provide simple uploading and downloading functions.`),Uo.forEach(t),Ho=l(o),j=a(o,"H3",{class:!0});var qo=r(j);ee=a(qo,"A",{id:!0,class:!0,href:!0});var Wn=r(ee);We=a(Wn,"SPAN",{});var Kn=r(We);x(pe.$$.fragment,Kn),Kn.forEach(t),Wn.forEach(t),et=l(qo),Ke=a(qo,"SPAN",{});var Vn=r(Ke);ot=s(Vn,"PyTorch"),Vn.forEach(t),qo.forEach(t),No=l(o),O=a(o,"DIV",{class:!0});var K=r(O);x(ue.$$.fragment,K),tt=l(K),A=a(K,"P",{});var de=r(A);nt=s(de,`A Generic Base Model Hub Mixin. Define your own mixin for anything by
inheriting from this class and overwriting `),Ve=a(de,"CODE",{});var Rn=r(Ve);at=s(Rn,"_from_pretrained"),Rn.forEach(t),rt=s(de,` and
`),Re=a(de,"CODE",{});var jn=r(Re);it=s(jn,"_save_pretrained"),jn.forEach(t),st=s(de,` to define custom logic for saving/loading your classes.
See `),je=a(de,"CODE",{});var Bn=r(je);dt=s(Bn,"huggingface_hub.PyTorchModelHubMixin"),Bn.forEach(t),lt=s(de," for an example."),de.forEach(t),ct=l(K),q=a(K,"DIV",{class:!0});var Ae=r(q);x(me.$$.fragment,Ae),ht=l(Ae),B=a(Ae,"P",{});var Se=r(B);gt=s(Se,`Instantiate a pretrained PyTorch model from a pre-trained model
configuration from huggingface-hub. The model is set in
evaluation mode by default using `),Be=a(Se,"CODE",{});var Yn=r(Be);pt=s(Yn,"model.eval()"),Yn.forEach(t),ut=s(Se,` (Dropout modules
are deactivated). To train the model, you should first set it
back in training mode with `),Ye=a(Se,"CODE",{});var Gn=r(Ye);mt=s(Gn,"model.train()"),Gn.forEach(t),ft=s(Se,"."),Se.forEach(t),_t=l(Ae),x(oe.$$.fragment,Ae),Ae.forEach(t),bt=l(K),W=a(K,"DIV",{class:!0});var Le=r(W);x(fe.$$.fragment,Le),vt=l(Le),Ge=a(Le,"P",{});var Jn=r(Ge);yt=s(Jn,"Upload model checkpoint to the Hub."),Jn.forEach(t),wt=l(Le),S=a(Le,"P",{});var le=r(S);xt=s(le,"Use "),Je=a(le,"CODE",{});var Qn=r(Je);$t=s(Qn,"allow_patterns"),Qn.forEach(t),kt=s(le," and "),Qe=a(le,"CODE",{});var Xn=r(Qe);Et=s(Xn,"ignore_patterns"),Xn.forEach(t),Mt=s(le,` to precisely filter which files
should be pushed to the hub. See `),Oe=a(le,"A",{href:!0});var Zn=r(Oe);Tt=s(Zn,"upload_folder()"),Zn.forEach(t),Ht=s(le," reference for more details."),le.forEach(t),Le.forEach(t),Nt=l(K),te=a(K,"DIV",{class:!0});var Wo=r(te);x(_e.$$.fragment,Wo),Pt=l(Wo),Xe=a(Wo,"P",{});var ea=r(Xe);Ot=s(ea,"Save weights in local directory."),ea.forEach(t),Wo.forEach(t),K.forEach(t),Po=l(o),Y=a(o,"H3",{class:!0});var Ko=r(Y);ne=a(Ko,"A",{id:!0,class:!0,href:!0});var oa=r(ne);Ze=a(oa,"SPAN",{});var ta=r(Ze);x(be.$$.fragment,ta),ta.forEach(t),oa.forEach(t),Dt=l(Ko),eo=a(Ko,"SPAN",{});var na=r(eo);zt=s(na,"Keras"),na.forEach(t),Ko.forEach(t),Oo=l(o),L=a(o,"DIV",{class:!0});var Ie=r(L);x(ve.$$.fragment,Ie),At=l(Ie),oo=a(Ie,"P",{});var aa=r(oo);St=s(aa,"Instantiate a pretrained Keras model from a pre-trained model from the Hub.\nThe model is expected to be in SavedModel format.```"),aa.forEach(t),Lt=l(Ie),x(ae.$$.fragment,Ie),Ie.forEach(t),Do=l(o),I=a(o,"DIV",{class:!0});var Ce=r(I);x(ye.$$.fragment,Ce),It=l(Ce),we=a(Ce,"P",{});var Vo=r(we);Ct=s(Vo,`Upload model checkpoint or tokenizer files to the Hub while synchronizing a
local clone of the repo in `),to=a(Vo,"CODE",{});var ra=r(to);Ft=s(ra,"repo_path_or_name"),ra.forEach(t),Ut=s(Vo,"."),Vo.forEach(t),qt=l(Ce),C=a(Ce,"P",{});var ce=r(C);Wt=s(ce,"Use "),no=a(ce,"CODE",{});var ia=r(no);Kt=s(ia,"allow_patterns"),ia.forEach(t),Vt=s(ce," and "),ao=a(ce,"CODE",{});var sa=r(ao);Rt=s(sa,"ignore_patterns"),sa.forEach(t),jt=s(ce,` to precisely filter which files should be
pushed to the hub. See `),De=a(ce,"A",{href:!0});var da=r(De);Bt=s(da,"upload_folder()"),da.forEach(t),Yt=s(ce," reference for more details."),ce.forEach(t),Ce.forEach(t),zo=l(o),G=a(o,"DIV",{class:!0});var Ro=r(G);x(xe.$$.fragment,Ro),Gt=l(Ro),ro=a(Ro,"P",{});var la=r(ro);Jt=s(la,`Saves a Keras model to save_directory in SavedModel format. Use this if
you\u2019re using the Functional or Sequential APIs.`),la.forEach(t),Ro.forEach(t),Ao=l(o),F=a(o,"DIV",{class:!0});var Fe=r(F);x($e.$$.fragment,Fe),Qt=l(Fe),io=a(Fe,"P",{});var ca=r(io);Xt=s(ca,`Mixin to provide model Hub upload/download capabilities to Keras models.
Override this class to obtain the following internal methods:`),ca.forEach(t),Zt=l(Fe),ke=a(Fe,"UL",{});var jo=r(ke);ze=a(jo,"LI",{});var Sn=r(ze);so=a(Sn,"CODE",{});var ha=r(so);en=s(ha,"_from_pretrained"),ha.forEach(t),on=s(Sn,", to load a model from the Hub or from local files."),Sn.forEach(t),tn=l(jo),re=a(jo,"LI",{});var Eo=r(re);lo=a(Eo,"CODE",{});var ga=r(lo);nn=s(ga,"_save_pretrained"),ga.forEach(t),an=s(Eo,", to save a model in the "),co=a(Eo,"CODE",{});var pa=r(co);rn=s(pa,"SavedModel"),pa.forEach(t),sn=s(Eo," format."),Eo.forEach(t),jo.forEach(t),Fe.forEach(t),So=l(o),J=a(o,"H3",{class:!0});var Bo=r(J);ie=a(Bo,"A",{id:!0,class:!0,href:!0});var ua=r(ie);ho=a(ua,"SPAN",{});var ma=r(ho);x(Ee.$$.fragment,ma),ma.forEach(t),ua.forEach(t),dn=l(Bo),go=a(Bo,"SPAN",{});var fa=r(go);ln=s(fa,"Fastai"),fa.forEach(t),Bo.forEach(t),Lo=l(o),Q=a(o,"DIV",{class:!0});var Yo=r(Q);x(Me.$$.fragment,Yo),cn=l(Yo),po=a(Yo,"P",{});var _a=r(po);hn=s(_a,"Load pretrained fastai model from the Hub or from a local directory."),_a.forEach(t),Yo.forEach(t),Io=l(o),D=a(o,"DIV",{class:!0});var he=r(D);x(Te.$$.fragment,he),gn=l(he),He=a(he,"P",{});var Go=r(He);pn=s(Go,`Upload learner checkpoint files to the Hub while synchronizing a local clone of the repo in
`),uo=a(Go,"CODE",{});var ba=r(uo);un=s(ba,"repo_id"),ba.forEach(t),mn=s(Go,"."),Go.forEach(t),fn=l(he),b=a(he,"P",{});var y=r(b);_n=s(y,`Keyword Args:
api_endpoint (`),mo=a(y,"EM",{});var va=r(mo);bn=s(va,"str"),va.forEach(t),vn=s(y,", "),fo=a(y,"EM",{});var ya=r(fo);yn=s(ya,"optional"),ya.forEach(t),wn=s(y,`):
The API endpoint to use when pushing the model to the hub.
git_user (`),_o=a(y,"EM",{});var wa=r(_o);xn=s(wa,"str"),wa.forEach(t),$n=s(y,", "),bo=a(y,"EM",{});var xa=r(bo);kn=s(xa,"optional"),xa.forEach(t),En=s(y,`):
Will override the `),vo=a(y,"CODE",{});var $a=r(vo);Mn=s($a,"git config user.name"),$a.forEach(t),Tn=s(y,` for committing and pushing files to the hub.
git_email (`),yo=a(y,"EM",{});var ka=r(yo);Hn=s(ka,"str"),ka.forEach(t),Nn=s(y,", "),wo=a(y,"EM",{});var Ea=r(wo);Pn=s(Ea,"optional"),Ea.forEach(t),On=s(y,`):
Will override the `),xo=a(y,"CODE",{});var Ma=r(xo);Dn=s(Ma,"git config user.email"),Ma.forEach(t),zn=s(y," for committing and pushing files to the hub."),y.forEach(t),An=l(he),x(se.$$.fragment,he),he.forEach(t),this.h()},h(){h(g,"name","hf:doc:metadata"),h(g,"content",JSON.stringify(La)),h(f,"id","mixins-serialization-methods"),h(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(f,"href","#mixins-serialization-methods"),h(m,"class","relative group"),h(z,"id","mixins"),h(z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(z,"href","#mixins"),h(N,"class","relative group"),h(ee,"id","huggingface_hub.ModelHubMixin"),h(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ee,"href","#huggingface_hub.ModelHubMixin"),h(j,"class","relative group"),h(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(Oe,"href","/docs/huggingface_hub/v0.9.1/en/package_reference/hf_api#huggingface_hub.HfApi.upload_folder"),h(W,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(te,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(O,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(ne,"id","huggingface_hub.from_pretrained_keras"),h(ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ne,"href","#huggingface_hub.from_pretrained_keras"),h(Y,"class","relative group"),h(L,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(De,"href","/docs/huggingface_hub/v0.9.1/en/package_reference/hf_api#huggingface_hub.HfApi.upload_folder"),h(I,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(G,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(ie,"id","huggingface_hub.from_pretrained_fastai"),h(ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ie,"href","#huggingface_hub.from_pretrained_fastai"),h(J,"class","relative group"),h(Q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(D,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(o,c){e(document.head,g),p(o,T,c),p(o,m,c),e(m,f),e(f,v),$(u,v,null),e(m,_),e(m,P),e(P,ge),p(o,H,c),p(o,N,c),e(N,z),e(z,R),$(U,R,null),e(N,Pe),e(N,Ue),e(Ue,Jo),p(o,To,c),p(o,Z,c),e(Z,Qo),e(Z,qe),e(qe,Xo),e(Z,Zo),p(o,Ho,c),p(o,j,c),e(j,ee),e(ee,We),$(pe,We,null),e(j,et),e(j,Ke),e(Ke,ot),p(o,No,c),p(o,O,c),$(ue,O,null),e(O,tt),e(O,A),e(A,nt),e(A,Ve),e(Ve,at),e(A,rt),e(A,Re),e(Re,it),e(A,st),e(A,je),e(je,dt),e(A,lt),e(O,ct),e(O,q),$(me,q,null),e(q,ht),e(q,B),e(B,gt),e(B,Be),e(Be,pt),e(B,ut),e(B,Ye),e(Ye,mt),e(B,ft),e(q,_t),$(oe,q,null),e(O,bt),e(O,W),$(fe,W,null),e(W,vt),e(W,Ge),e(Ge,yt),e(W,wt),e(W,S),e(S,xt),e(S,Je),e(Je,$t),e(S,kt),e(S,Qe),e(Qe,Et),e(S,Mt),e(S,Oe),e(Oe,Tt),e(S,Ht),e(O,Nt),e(O,te),$(_e,te,null),e(te,Pt),e(te,Xe),e(Xe,Ot),p(o,Po,c),p(o,Y,c),e(Y,ne),e(ne,Ze),$(be,Ze,null),e(Y,Dt),e(Y,eo),e(eo,zt),p(o,Oo,c),p(o,L,c),$(ve,L,null),e(L,At),e(L,oo),e(oo,St),e(L,Lt),$(ae,L,null),p(o,Do,c),p(o,I,c),$(ye,I,null),e(I,It),e(I,we),e(we,Ct),e(we,to),e(to,Ft),e(we,Ut),e(I,qt),e(I,C),e(C,Wt),e(C,no),e(no,Kt),e(C,Vt),e(C,ao),e(ao,Rt),e(C,jt),e(C,De),e(De,Bt),e(C,Yt),p(o,zo,c),p(o,G,c),$(xe,G,null),e(G,Gt),e(G,ro),e(ro,Jt),p(o,Ao,c),p(o,F,c),$($e,F,null),e(F,Qt),e(F,io),e(io,Xt),e(F,Zt),e(F,ke),e(ke,ze),e(ze,so),e(so,en),e(ze,on),e(ke,tn),e(ke,re),e(re,lo),e(lo,nn),e(re,an),e(re,co),e(co,rn),e(re,sn),p(o,So,c),p(o,J,c),e(J,ie),e(ie,ho),$(Ee,ho,null),e(J,dn),e(J,go),e(go,ln),p(o,Lo,c),p(o,Q,c),$(Me,Q,null),e(Q,cn),e(Q,po),e(po,hn),p(o,Io,c),p(o,D,c),$(Te,D,null),e(D,gn),e(D,He),e(He,pn),e(He,uo),e(uo,un),e(He,mn),e(D,fn),e(D,b),e(b,_n),e(b,mo),e(mo,bn),e(b,vn),e(b,fo),e(fo,yn),e(b,wn),e(b,_o),e(_o,xn),e(b,$n),e(b,bo),e(bo,kn),e(b,En),e(b,vo),e(vo,Mn),e(b,Tn),e(b,yo),e(yo,Hn),e(b,Nn),e(b,wo),e(wo,Pn),e(b,On),e(b,xo),e(xo,Dn),e(b,zn),e(D,An),$(se,D,null),Co=!0},p(o,[c]){const Ne={};c&2&&(Ne.$$scope={dirty:c,ctx:o}),oe.$set(Ne);const $o={};c&2&&($o.$$scope={dirty:c,ctx:o}),ae.$set($o);const ko={};c&2&&(ko.$$scope={dirty:c,ctx:o}),se.$set(ko)},i(o){Co||(k(u.$$.fragment,o),k(U.$$.fragment,o),k(pe.$$.fragment,o),k(ue.$$.fragment,o),k(me.$$.fragment,o),k(oe.$$.fragment,o),k(fe.$$.fragment,o),k(_e.$$.fragment,o),k(be.$$.fragment,o),k(ve.$$.fragment,o),k(ae.$$.fragment,o),k(ye.$$.fragment,o),k(xe.$$.fragment,o),k($e.$$.fragment,o),k(Ee.$$.fragment,o),k(Me.$$.fragment,o),k(Te.$$.fragment,o),k(se.$$.fragment,o),Co=!0)},o(o){E(u.$$.fragment,o),E(U.$$.fragment,o),E(pe.$$.fragment,o),E(ue.$$.fragment,o),E(me.$$.fragment,o),E(oe.$$.fragment,o),E(fe.$$.fragment,o),E(_e.$$.fragment,o),E(be.$$.fragment,o),E(ve.$$.fragment,o),E(ae.$$.fragment,o),E(ye.$$.fragment,o),E(xe.$$.fragment,o),E($e.$$.fragment,o),E(Ee.$$.fragment,o),E(Me.$$.fragment,o),E(Te.$$.fragment,o),E(se.$$.fragment,o),Co=!1},d(o){t(g),o&&t(T),o&&t(m),M(u),o&&t(H),o&&t(N),M(U),o&&t(To),o&&t(Z),o&&t(Ho),o&&t(j),M(pe),o&&t(No),o&&t(O),M(ue),M(me),M(oe),M(fe),M(_e),o&&t(Po),o&&t(Y),M(be),o&&t(Oo),o&&t(L),M(ve),M(ae),o&&t(Do),o&&t(I),M(ye),o&&t(zo),o&&t(G),M(xe),o&&t(Ao),o&&t(F),M($e),o&&t(So),o&&t(J),M(Ee),o&&t(Lo),o&&t(Q),M(Me),o&&t(Io),o&&t(D),M(Te),M(se)}}}const La={local:"mixins-serialization-methods",sections:[{local:"mixins",sections:[{local:"huggingface_hub.ModelHubMixin",title:"PyTorch"},{local:"huggingface_hub.from_pretrained_keras",title:"Keras"},{local:"huggingface_hub.from_pretrained_fastai",title:"Fastai"}],title:"Mixins"}],title:"Mixins & serialization methods"};function Ia(X){return Oa(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Wa extends Ta{constructor(g){super();Ha(this,g,Ia,Sa,Na,{})}}export{Wa as default,La as metadata};
