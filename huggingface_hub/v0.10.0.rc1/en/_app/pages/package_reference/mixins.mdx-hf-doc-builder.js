import{S as na,i as aa,s as ra,e as n,k as d,w as v,t as i,M as ia,c as a,d as t,m as l,a as r,x as y,h as s,b as h,G as e,g as p,y as w,q as x,o as $,B as k,v as sa}from"../../chunks/vendor-hf-doc-builder.js";import{T as _n}from"../../chunks/Tip-hf-doc-builder.js";import{D as K}from"../../chunks/Docstring-hf-doc-builder.js";import{I as yo}from"../../chunks/IconCopyLink-hf-doc-builder.js";function da(Q){let g,E,m,f,b;return{c(){g=n("p"),E=i("Passing "),m=n("code"),f=i("use_auth_token=True"),b=i(` is required when you want to use a
private model.`)},l(u){g=a(u,"P",{});var _=r(g);E=s(_,"Passing "),m=a(_,"CODE",{});var H=r(m);f=s(H,"use_auth_token=True"),H.forEach(t),b=s(_,` is required when you want to use a
private model.`),_.forEach(t)},m(u,_){p(u,g,_),e(g,E),e(g,m),e(m,f),e(g,b)},d(u){u&&t(g)}}}function la(Q){let g,E,m,f,b;return{c(){g=n("p"),E=i("Passing "),m=n("code"),f=i("use_auth_token=True"),b=i(` is required when you want to use a private
model.`)},l(u){g=a(u,"P",{});var _=r(g);E=s(_,"Passing "),m=a(_,"CODE",{});var H=r(m);f=s(H,"use_auth_token=True"),H.forEach(t),b=s(_,` is required when you want to use a private
model.`),_.forEach(t)},m(u,_){p(u,g,_),e(g,E),e(g,m),e(m,f),e(g,b)},d(u){u&&t(g)}}}function ca(Q){let g,E,m,f,b,u,_,H,ge;return{c(){g=n("p"),E=i("Raises the following error:"),m=d(),f=n("ul"),b=n("li"),u=n("a"),_=n("em"),H=i("ValueError"),ge=i(`
if the user is not log on to the Hugging Face Hub.`),this.h()},l(M){g=a(M,"P",{});var T=r(g);E=s(T,"Raises the following error:"),T.forEach(t),m=l(M),f=a(M,"UL",{});var O=r(f);b=a(O,"LI",{});var V=r(b);u=a(V,"A",{href:!0,rel:!0});var U=r(u);_=a(U,"EM",{});var Ne=r(_);H=s(Ne,"ValueError"),Ne.forEach(t),U.forEach(t),ge=s(V,`
if the user is not log on to the Hugging Face Hub.`),V.forEach(t),O.forEach(t),this.h()},h(){h(u,"href","https://docs.python.org/3/library/exceptions.html#ValueError"),h(u,"rel","nofollow")},m(M,T){p(M,g,T),e(g,E),p(M,m,T),p(M,f,T),e(f,b),e(b,u),e(u,_),e(_,H),e(b,ge)},d(M){M&&t(g),M&&t(m),M&&t(f)}}}function ha(Q){let g,E,m,f,b,u,_,H,ge,M,T,O,V,U,Ne,Ue,Ko,wo,X,Vo,Ce,Ro,jo,xo,R,Z,qe,pe,Bo,We,Yo,$o,N,ue,Go,D,Jo,Ke,Qo,Xo,Ve,Zo,et,Re,ot,tt,nt,C,me,at,j,rt,je,it,st,Be,dt,lt,ct,ee,ht,q,fe,gt,Ye,pt,ut,S,mt,Ge,ft,_t,Je,bt,vt,Pe,yt,wt,xt,oe,_e,$t,Qe,kt,ko,B,te,Xe,be,Et,Ze,Mt,Eo,z,ve,Tt,eo,Ht,Nt,ne,Mo,L,ye,Pt,we,Ot,oo,Dt,St,zt,A,Lt,to,At,It,no,Ft,Ut,Oe,Ct,qt,To,Y,xe,Wt,ao,Kt,Ho,I,$e,Vt,ro,Rt,jt,ke,De,io,Bt,Yt,Gt,ae,so,Jt,Qt,lo,Xt,Zt,No,G,re,co,Ee,en,ho,on,Po,J,Me,tn,go,nn,Oo,P,Te,an,po,rn,sn,F,dn,uo,ln,cn,mo,hn,gn,fo,pn,un,mn,ie,Do;return u=new yo({}),U=new yo({}),pe=new yo({}),ue=new K({props:{name:"class huggingface_hub.ModelHubMixin",anchor:"huggingface_hub.ModelHubMixin",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/v0.10.0.rc1/src/huggingface_hub/hub_mixin.py#L23"}}),me=new K({props:{name:"from_pretrained",anchor:"huggingface_hub.ModelHubMixin.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:": str"},{name:"force_download",val:": bool = False"},{name:"resume_download",val:": bool = False"},{name:"proxies",val:": typing.Dict = None"},{name:"use_auth_token",val:": typing.Optional[str] = None"},{name:"cache_dir",val:": typing.Optional[str] = None"},{name:"local_files_only",val:": bool = False"},{name:"**model_kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:<ul>
<li>A string, the <code>model id</code> of a pretrained model
hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level,
like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like
<code>dbmdz/bert-base-german-cased</code>.</li>
<li>You can add <code>revision</code> by appending <code>@</code> at the end
of model_id simply like this:
<code>dbmdz/bert-base-german-cased@main</code> Revision is
the specific model version to use. It can be a
branch name, a tag name, or a commit id, since we
use a git-based system for storing models and
other artifacts on huggingface.co, so <code>revision</code>
can be any identifier allowed by git.</li>
<li>A path to a <code>directory</code> containing model weights
saved using
<a href="https://huggingface.co/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained" rel="nofollow">save_pretrained</a>,
e.g., <code>./my_model_directory/</code>.</li>
<li><code>None</code> if you are both providing the configuration
and state dictionary (resp. with keyword arguments
<code>config</code> and <code>state_dict</code>).</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to force the (re-)download of the model weights
and configuration files, overriding the cached versions
if they exist.`,name:"force_download"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to delete incompletely received files. Will
attempt to resume the download if such a file exists.`,name:"resume_download"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or
endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are
used on each request.`,name:"proxies"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote
files. If <code>True</code>, will use the token generated when
running <code>transformers-cli login</code> (stored in
<code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>Union[str, os.PathLike]</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained
model configuration should be cached if the standard
cache should not be used.`,name:"cache_dir"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to only look at local files (i.e., do not try to
download the model).`,name:"local_files_only(bool,"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.model_kwargs",description:`<strong>model_kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
model_kwargs will be passed to the model during
initialization`,name:"model_kwargs"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.10.0.rc1/src/huggingface_hub/hub_mixin.py#L99"}}),ee=new _n({props:{$$slots:{default:[da]},$$scope:{ctx:Q}}}),fe=new K({props:{name:"push_to_hub",anchor:"huggingface_hub.ModelHubMixin.push_to_hub",parameters:[{name:"repo_path_or_name",val:": typing.Optional[str] = None"},{name:"repo_url",val:": typing.Optional[str] = None"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"organization",val:": typing.Optional[str] = None"},{name:"private",val:": bool = False"},{name:"api_endpoint",val:": typing.Optional[str] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = None"},{name:"git_user",val:": typing.Optional[str] = None"},{name:"git_email",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"},{name:"skip_lfs_files",val:": bool = False"},{name:"repo_id",val:": typing.Optional[str] = None"},{name:"token",val:": typing.Optional[str] = None"},{name:"branch",val:": typing.Optional[str] = None"},{name:"create_pr",val:": typing.Optional[bool] = None"},{name:"allow_patterns",val:": typing.Union[typing.List[str], str, NoneType] = None"},{name:"ignore_patterns",val:": typing.Union[typing.List[str], str, NoneType] = None"}],parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.repo_id",description:`<strong>repo_id</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Repository name to which push.`,name:"repo_id"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Message to commit while pushing.`,name:"commit_message"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.api_endpoint",description:`<strong>api_endpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The API endpoint to use when pushing the model to the hub.`,name:"api_endpoint"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files.
If not set, will use the token set when logging in with
<code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"token"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.branch",description:`<strong>branch</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The git branch on which to push the model. This defaults to
the default branch as specified in your repository, which
defaults to <code>&quot;main&quot;</code>.`,name:"branch"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.create_pr",description:`<strong>create_pr</strong> (<code>boolean</code>, <em>optional</em>) &#x2014;
Whether or not to create a Pull Request from <code>branch</code> with that commit.
Defaults to <code>False</code>.`,name:"create_pr"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.allow_patterns",description:`<strong>allow_patterns</strong> (<code>List[str]</code> or <code>str</code>, <em>optional</em>) &#x2014;
If provided, only files matching at least one pattern are pushed.`,name:"allow_patterns"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.ignore_patterns",description:`<strong>ignore_patterns</strong> (<code>List[str]</code> or <code>str</code>, <em>optional</em>) &#x2014;
If provided, files matching any of the patterns are not pushed.`,name:"ignore_patterns"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.10.0.rc1/src/huggingface_hub/hub_mixin.py#L240",returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),_e=new K({props:{name:"save_pretrained",anchor:"huggingface_hub.ModelHubMixin.save_pretrained",parameters:[{name:"save_directory",val:": str"},{name:"config",val:": typing.Optional[dict] = None"},{name:"push_to_hub",val:": bool = False"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code>) &#x2014;
Specify directory in which you want to save weights.`,name:"save_directory"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Specify config (must be dict) in case you want to save
it.`,name:"config"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.push_to_hub",description:`<strong>push_to_hub</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to push your model to the Hugging Face model hub after
saving it. You can specify the repository you want to push to with
<code>repo_id</code> (will default to the name of <code>save_directory</code> in your
namespace).
kwargs &#x2014;
Additional key word arguments passed along to the
<code>push_to_hub</code> method.`,name:"push_to_hub"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.10.0.rc1/src/huggingface_hub/hub_mixin.py#L31"}}),be=new yo({}),ve=new K({props:{name:"huggingface_hub.from_pretrained_keras",anchor:"huggingface_hub.from_pretrained_keras",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.from_pretrained_keras.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:<ul>
<li>A string, the <code>model id</code> of a pretrained model hosted inside a
model repo on huggingface.co. Valid model ids can be located
at the root-level, like <code>bert-base-uncased</code>, or namespaced
under a user or organization name, like
<code>dbmdz/bert-base-german-cased</code>.</li>
<li>You can add <code>revision</code> by appending <code>@</code> at the end of model_id
simply like this: <code>dbmdz/bert-base-german-cased@main</code> Revision
is the specific model version to use. It can be a branch name,
a tag name, or a commit id, since we use a git-based system
for storing models and other artifacts on huggingface.co, so
<code>revision</code> can be any identifier allowed by git.</li>
<li>A path to a <code>directory</code> containing model weights saved using
<a href="https://huggingface.co/docs/transformers/v4.22.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained" rel="nofollow">save_pretrained</a>, e.g.,
<code>./my_model_directory/</code>.</li>
<li><code>None</code> if you are both providing the configuration and state
dictionary (resp. with keyword arguments <code>config</code> and
<code>state_dict</code>).</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"huggingface_hub.from_pretrained_keras.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to force the (re-)download of the model weights and
configuration files, overriding the cached versions if they exist.`,name:"force_download"},{anchor:"huggingface_hub.from_pretrained_keras.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to delete incompletely received files. Will attempt to
resume the download if such a file exists.`,name:"resume_download"},{anchor:"huggingface_hub.from_pretrained_keras.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g.,
<code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The
proxies are used on each request.`,name:"proxies"},{anchor:"huggingface_hub.from_pretrained_keras.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If
<code>True</code>, will use the token generated when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"huggingface_hub.from_pretrained_keras.cache_dir",description:`<strong>cache_dir</strong> (<code>Union[str, os.PathLike]</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model
configuration should be cached if the standard cache should not be
used.`,name:"cache_dir"},{anchor:"huggingface_hub.from_pretrained_keras.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to only look at local files (i.e., do not try to download
the model).`,name:"local_files_only(bool,"},{anchor:"huggingface_hub.from_pretrained_keras.model_kwargs",description:`<strong>model_kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
model_kwargs will be passed to the model during initialization`,name:"model_kwargs"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.10.0.rc1/src/huggingface_hub/keras_mixin.py#L228"}}),ne=new _n({props:{$$slots:{default:[la]},$$scope:{ctx:Q}}}),ye=new K({props:{name:"huggingface_hub.push_to_hub_keras",anchor:"huggingface_hub.push_to_hub_keras",parameters:[{name:"model",val:""},{name:"repo_path_or_name",val:": typing.Optional[str] = None"},{name:"repo_url",val:": typing.Optional[str] = None"},{name:"log_dir",val:": typing.Optional[str] = None"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"organization",val:": typing.Optional[str] = None"},{name:"private",val:": bool = False"},{name:"api_endpoint",val:": typing.Optional[str] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = True"},{name:"git_user",val:": typing.Optional[str] = None"},{name:"git_email",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"},{name:"include_optimizer",val:": typing.Optional[bool] = False"},{name:"tags",val:": typing.Union[list, str, NoneType] = None"},{name:"plot_model",val:": typing.Optional[bool] = True"},{name:"token",val:": typing.Optional[str] = True"},{name:"repo_id",val:": typing.Optional[str] = None"},{name:"branch",val:": typing.Optional[str] = None"},{name:"create_pr",val:": typing.Optional[bool] = None"},{name:"allow_patterns",val:": typing.Union[typing.List[str], str, NoneType] = None"},{name:"ignore_patterns",val:": typing.Union[typing.List[str], str, NoneType] = None"},{name:"**model_save_kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.push_to_hub_keras.model",description:`<strong>model</strong> (<code>Keras.Model</code>) &#x2014;
The <a href="%60https://www.tensorflow.org/api_docs/python/tf/keras/Model%60">Keras
model</a>
you&#x2019;d like to push to the Hub. The model must be compiled and built.`,name:"model"},{anchor:"huggingface_hub.push_to_hub_keras.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
Repository name to which push`,name:"repo_id"},{anchor:"huggingface_hub.push_to_hub_keras.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>, defaults to &#x201C;Add message&#x201D;) &#x2014;
Message to commit while pushing.`,name:"commit_message"},{anchor:"huggingface_hub.push_to_hub_keras.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.push_to_hub_keras.api_endpoint",description:`<strong>api_endpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The API endpoint to use when pushing the model to the hub.`,name:"api_endpoint"},{anchor:"huggingface_hub.push_to_hub_keras.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If
not set, will use the token set when logging in with
<code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"token"},{anchor:"huggingface_hub.push_to_hub_keras.branch",description:`<strong>branch</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The git branch on which to push the model. This defaults to
the default branch as specified in your repository, which
defaults to <code>&quot;main&quot;</code>.`,name:"branch"},{anchor:"huggingface_hub.push_to_hub_keras.create_pr",description:`<strong>create_pr</strong> (<code>boolean</code>, <em>optional</em>) &#x2014;
Whether or not to create a Pull Request from <code>branch</code> with that commit.
Defaults to <code>False</code>.`,name:"create_pr"},{anchor:"huggingface_hub.push_to_hub_keras.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"},{anchor:"huggingface_hub.push_to_hub_keras.allow_patterns",description:`<strong>allow_patterns</strong> (<code>List[str]</code> or <code>str</code>, <em>optional</em>) &#x2014;
If provided, only files matching at least one pattern are pushed.`,name:"allow_patterns"},{anchor:"huggingface_hub.push_to_hub_keras.ignore_patterns",description:`<strong>ignore_patterns</strong> (<code>List[str]</code> or <code>str</code>, <em>optional</em>) &#x2014;
If provided, files matching any of the patterns are not pushed.`,name:"ignore_patterns"},{anchor:"huggingface_hub.push_to_hub_keras.log_dir",description:`<strong>log_dir</strong> (<code>str</code>, <em>optional</em>) &#x2014;
TensorBoard logging directory to be pushed. The Hub automatically
hosts and displays a TensorBoard instance if log files are included
in the repository.`,name:"log_dir"},{anchor:"huggingface_hub.push_to_hub_keras.include_optimizer",description:`<strong>include_optimizer</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to include optimizer during serialization.`,name:"include_optimizer"},{anchor:"huggingface_hub.push_to_hub_keras.tags",description:`<strong>tags</strong> (Union[<code>list</code>, <code>str</code>], <em>optional</em>) &#x2014;
List of tags that are related to model or string of a single tag. See example tags
<a href="https://github.com/huggingface/hub-docs/blame/main/modelcard.md" rel="nofollow">here</a>.`,name:"tags"},{anchor:"huggingface_hub.push_to_hub_keras.plot_model",description:`<strong>plot_model</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Setting this to <code>True</code> will plot the model and put it in the model
card. Requires graphviz and pydot to be installed.`,name:"plot_model"},{anchor:"huggingface_hub.push_to_hub_keras.model_save_kwargs(dict,",description:`<strong>model_save_kwargs(<code>dict</code>,</strong> <em>optional</em>) &#x2014;
model_save_kwargs will be passed to
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model" rel="nofollow"><code>tf.keras.models.save_model()</code></a>.`,name:"model_save_kwargs(dict,"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.10.0.rc1/src/huggingface_hub/keras_mixin.py#L287",returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),xe=new K({props:{name:"huggingface_hub.save_pretrained_keras",anchor:"huggingface_hub.save_pretrained_keras",parameters:[{name:"model",val:""},{name:"save_directory",val:": str"},{name:"config",val:": typing.Union[typing.Dict[str, typing.Any], NoneType] = None"},{name:"include_optimizer",val:": typing.Optional[bool] = False"},{name:"plot_model",val:": typing.Optional[bool] = True"},{name:"tags",val:": typing.Union[list, str, NoneType] = None"},{name:"**model_save_kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.save_pretrained_keras.model",description:`<strong>model</strong> (<code>Keras.Model</code>) &#x2014;
The <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" rel="nofollow">Keras
model</a>
you&#x2019;d like to save. The model must be compiled and built.`,name:"model"},{anchor:"huggingface_hub.save_pretrained_keras.save_directory",description:`<strong>save_directory</strong> (<code>str</code>) &#x2014;
Specify directory in which you want to save the Keras model.`,name:"save_directory"},{anchor:"huggingface_hub.save_pretrained_keras.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"},{anchor:"huggingface_hub.save_pretrained_keras.include_optimizer(bool,",description:`<strong>include_optimizer(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to include optimizer in serialization.`,name:"include_optimizer(bool,"},{anchor:"huggingface_hub.save_pretrained_keras.plot_model",description:`<strong>plot_model</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Setting this to <code>True</code> will plot the model and put it in the model
card. Requires graphviz and pydot to be installed.`,name:"plot_model"},{anchor:"huggingface_hub.save_pretrained_keras.tags",description:`<strong>tags</strong> (Union[<code>str</code>,<code>list</code>], <em>optional</em>) &#x2014;
List of tags that are related to model or string of a single tag. See example tags
<a href="https://github.com/huggingface/hub-docs/blame/main/modelcard.md" rel="nofollow">here</a>.`,name:"tags"},{anchor:"huggingface_hub.save_pretrained_keras.model_save_kwargs(dict,",description:`<strong>model_save_kwargs(<code>dict</code>,</strong> <em>optional</em>) &#x2014;
model_save_kwargs will be passed to
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model" rel="nofollow"><code>tf.keras.models.save_model()</code></a>.`,name:"model_save_kwargs(dict,"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.10.0.rc1/src/huggingface_hub/keras_mixin.py#L136"}}),$e=new K({props:{name:"class huggingface_hub.KerasModelHubMixin",anchor:"huggingface_hub.KerasModelHubMixin",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.10.0.rc1/src/huggingface_hub/keras_mixin.py#L533"}}),Ee=new yo({}),Me=new K({props:{name:"huggingface_hub.from_pretrained_fastai",anchor:"huggingface_hub.from_pretrained_fastai",parameters:[{name:"repo_id",val:": str"},{name:"revision",val:": typing.Optional[str] = None"}],parametersDescription:[{anchor:"huggingface_hub.from_pretrained_fastai.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
The location where the pickled fastai.Learner is. It can be either of the two:<ul>
<li>Hosted on the Hugging Face Hub. E.g.: &#x2018;espejelomar/fatai-pet-breeds-classification&#x2019; or &#x2018;distilgpt2&#x2019;.
You can add a <code>revision</code> by appending <code>@</code> at the end of <code>repo_id</code>. E.g.: <code>dbmdz/bert-base-german-cased@main</code>.
Revision is the specific model version to use. Since we use a git-based system for storing models and other
artifacts on the Hugging Face Hub, it can be a branch name, a tag name, or a commit id.</li>
<li>Hosted locally. <code>repo_id</code> would be a directory containing the pickle and a pyproject.toml
indicating the fastai and fastcore versions used to build the <code>fastai.Learner</code>. E.g.: <code>./my_model_directory/</code>.</li>
</ul>`,name:"repo_id"},{anchor:"huggingface_hub.from_pretrained_fastai.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Revision at which the repo&#x2019;s files are downloaded. See documentation of <code>snapshot_download</code>.`,name:"revision"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.10.0.rc1/src/huggingface_hub/fastai_utils.py#L311",returnDescription:`
<p>The <code>fastai.Learner</code> model in the <code>repo_id</code> repo.</p>
`}}),Te=new K({props:{name:"huggingface_hub.push_to_hub_fastai",anchor:"huggingface_hub.push_to_hub_fastai",parameters:[{name:"learner",val:""},{name:"repo_id",val:": str"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"private",val:": bool = False"},{name:"token",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"},{name:"branch",val:": typing.Optional[str] = None"},{name:"create_pr",val:": typing.Optional[bool] = None"},{name:"allow_patterns",val:": typing.Union[typing.List[str], str, NoneType] = None"},{name:"ignore_patterns",val:": typing.Union[typing.List[str], str, NoneType] = None"},{name:"api_endpoint",val:": typing.Optional[str] = None"},{name:"git_user",val:": typing.Optional[str] = None"},{name:"git_email",val:": typing.Optional[str] = None"}],parametersDescription:[{anchor:"huggingface_hub.push_to_hub_fastai.learner",description:`<strong>learner</strong> (<em>Learner</em>) &#x2014;
The *fastai.Learner&#x2019; you&#x2019;d like to push to the Hub.`,name:"learner"},{anchor:"huggingface_hub.push_to_hub_fastai.repo_id",description:`<strong>repo_id</strong> (<em>str</em>) &#x2014;
The repository id for your model in Hub in the format of &#x201C;namespace/repo_name&#x201D;. The namespace can be your individual account or an organization to which you have write access (for example, &#x2018;stanfordnlp/stanza-de&#x2019;).`,name:"repo_id"},{anchor:"huggingface_hub.push_to_hub_fastai.commit_message",description:"<strong>commit_message</strong> (<em>str`, </em>optional*) &#x2014; Message to commit while pushing. Will default to <code>&quot;add model&quot;</code>.",name:"commit_message"},{anchor:"huggingface_hub.push_to_hub_fastai.private",description:`<strong>private</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.push_to_hub_fastai.token",description:`<strong>token</strong> (<em>str</em>, <em>optional</em>) &#x2014;
The Hugging Face account token to use as HTTP bearer authorization for remote files. If <code>None</code>, the token will be asked by a prompt.`,name:"token"},{anchor:"huggingface_hub.push_to_hub_fastai.config",description:`<strong>config</strong> (<em>dict</em>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"},{anchor:"huggingface_hub.push_to_hub_fastai.branch",description:`<strong>branch</strong> (<em>str</em>, <em>optional</em>) &#x2014;
The git branch on which to push the model. This defaults to
the default branch as specified in your repository, which
defaults to <em>&#x201C;main&#x201D;</em>.`,name:"branch"},{anchor:"huggingface_hub.push_to_hub_fastai.create_pr",description:`<strong>create_pr</strong> (<em>boolean</em>, <em>optional</em>) &#x2014;
Whether or not to create a Pull Request from <em>branch</em> with that commit.
Defaults to <em>False</em>.`,name:"create_pr"},{anchor:"huggingface_hub.push_to_hub_fastai.api_endpoint",description:`<strong>api_endpoint</strong> (<em>str</em>, <em>optional</em>) &#x2014;
The API endpoint to use when pushing the model to the hub.`,name:"api_endpoint"},{anchor:"huggingface_hub.push_to_hub_fastai.allow_patterns",description:`<strong>allow_patterns</strong> (<em>List[str]</em> or <em>str</em>, <em>optional</em>) &#x2014;
If provided, only files matching at least one pattern are pushed.`,name:"allow_patterns"},{anchor:"huggingface_hub.push_to_hub_fastai.ignore_patterns",description:`<strong>ignore_patterns</strong> (<em>List[str]</em> or <em>str</em>, <em>optional</em>) &#x2014;
If provided, files matching any of the patterns are not pushed.`,name:"ignore_patterns"}],source:"https://github.com/huggingface/huggingface_hub/blob/v0.10.0.rc1/src/huggingface_hub/fastai_utils.py#L356",returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),ie=new _n({props:{$$slots:{default:[ca]},$$scope:{ctx:Q}}}),{c(){g=n("meta"),E=d(),m=n("h1"),f=n("a"),b=n("span"),v(u.$$.fragment),_=d(),H=n("span"),ge=i("Mixins & serialization methods"),M=d(),T=n("h2"),O=n("a"),V=n("span"),v(U.$$.fragment),Ne=d(),Ue=n("span"),Ko=i("Mixins"),wo=d(),X=n("p"),Vo=i("The "),Ce=n("code"),Ro=i("huggingface_hub"),jo=i(` library offers a range of mixins that can be used as a parent class for your
objects, in order to provide simple uploading and downloading functions.`),xo=d(),R=n("h3"),Z=n("a"),qe=n("span"),v(pe.$$.fragment),Bo=d(),We=n("span"),Yo=i("PyTorch"),$o=d(),N=n("div"),v(ue.$$.fragment),Go=d(),D=n("p"),Jo=i(`A Generic Base Model Hub Mixin. Define your own mixin for anything by
inheriting from this class and overwriting `),Ke=n("code"),Qo=i("_from_pretrained"),Xo=i(` and
`),Ve=n("code"),Zo=i("_save_pretrained"),et=i(` to define custom logic for saving/loading your classes.
See `),Re=n("code"),ot=i("huggingface_hub.PyTorchModelHubMixin"),tt=i(" for an example."),nt=d(),C=n("div"),v(me.$$.fragment),at=d(),j=n("p"),rt=i(`Instantiate a pretrained PyTorch model from a pre-trained model
configuration from huggingface-hub. The model is set in
evaluation mode by default using `),je=n("code"),it=i("model.eval()"),st=i(` (Dropout modules
are deactivated). To train the model, you should first set it
back in training mode with `),Be=n("code"),dt=i("model.train()"),lt=i("."),ct=d(),v(ee.$$.fragment),ht=d(),q=n("div"),v(fe.$$.fragment),gt=d(),Ye=n("p"),pt=i("Upload model checkpoint to the Hub."),ut=d(),S=n("p"),mt=i("Use "),Ge=n("code"),ft=i("allow_patterns"),_t=i(" and "),Je=n("code"),bt=i("ignore_patterns"),vt=i(` to precisely filter which files
should be pushed to the hub. See `),Pe=n("a"),yt=i("upload_folder()"),wt=i(" reference for more details."),xt=d(),oe=n("div"),v(_e.$$.fragment),$t=d(),Qe=n("p"),kt=i("Save weights in local directory."),ko=d(),B=n("h3"),te=n("a"),Xe=n("span"),v(be.$$.fragment),Et=d(),Ze=n("span"),Mt=i("Keras"),Eo=d(),z=n("div"),v(ve.$$.fragment),Tt=d(),eo=n("p"),Ht=i("Instantiate a pretrained Keras model from a pre-trained model from the Hub.\nThe model is expected to be in SavedModel format.```"),Nt=d(),v(ne.$$.fragment),Mo=d(),L=n("div"),v(ye.$$.fragment),Pt=d(),we=n("p"),Ot=i(`Upload model checkpoint or tokenizer files to the Hub while synchronizing a
local clone of the repo in `),oo=n("code"),Dt=i("repo_path_or_name"),St=i("."),zt=d(),A=n("p"),Lt=i("Use "),to=n("code"),At=i("allow_patterns"),It=i(" and "),no=n("code"),Ft=i("ignore_patterns"),Ut=i(` to precisely filter which files should be
pushed to the hub. See `),Oe=n("a"),Ct=i("upload_folder()"),qt=i(" reference for more details."),To=d(),Y=n("div"),v(xe.$$.fragment),Wt=d(),ao=n("p"),Kt=i(`Saves a Keras model to save_directory in SavedModel format. Use this if
you\u2019re using the Functional or Sequential APIs.`),Ho=d(),I=n("div"),v($e.$$.fragment),Vt=d(),ro=n("p"),Rt=i(`Mixin to provide model Hub upload/download capabilities to Keras models.
Override this class to obtain the following internal methods:`),jt=d(),ke=n("ul"),De=n("li"),io=n("code"),Bt=i("_from_pretrained"),Yt=i(", to load a model from the Hub or from local files."),Gt=d(),ae=n("li"),so=n("code"),Jt=i("_save_pretrained"),Qt=i(", to save a model in the "),lo=n("code"),Xt=i("SavedModel"),Zt=i(" format."),No=d(),G=n("h3"),re=n("a"),co=n("span"),v(Ee.$$.fragment),en=d(),ho=n("span"),on=i("Fastai"),Po=d(),J=n("div"),v(Me.$$.fragment),tn=d(),go=n("p"),nn=i("Load pretrained fastai model from the Hub or from a local directory."),Oo=d(),P=n("div"),v(Te.$$.fragment),an=d(),po=n("p"),rn=i("Upload learner checkpoint files to the Hub."),sn=d(),F=n("p"),dn=i("Use "),uo=n("em"),ln=i("allow_patterns"),cn=i(" and "),mo=n("em"),hn=i("ignore_patterns"),gn=i(` to precisely filter which files should be
pushed to the hub. See [`),fo=n("em"),pn=i("upload_folder"),un=i("] reference for more details."),mn=d(),v(ie.$$.fragment),this.h()},l(o){const c=ia('[data-svelte="svelte-1phssyn"]',document.head);g=a(c,"META",{name:!0,content:!0}),c.forEach(t),E=l(o),m=a(o,"H1",{class:!0});var He=r(m);f=a(He,"A",{id:!0,class:!0,href:!0});var _o=r(f);b=a(_o,"SPAN",{});var bo=r(b);y(u.$$.fragment,bo),bo.forEach(t),_o.forEach(t),_=l(He),H=a(He,"SPAN",{});var bn=r(H);ge=s(bn,"Mixins & serialization methods"),bn.forEach(t),He.forEach(t),M=l(o),T=a(o,"H2",{class:!0});var So=r(T);O=a(So,"A",{id:!0,class:!0,href:!0});var vn=r(O);V=a(vn,"SPAN",{});var yn=r(V);y(U.$$.fragment,yn),yn.forEach(t),vn.forEach(t),Ne=l(So),Ue=a(So,"SPAN",{});var wn=r(Ue);Ko=s(wn,"Mixins"),wn.forEach(t),So.forEach(t),wo=l(o),X=a(o,"P",{});var zo=r(X);Vo=s(zo,"The "),Ce=a(zo,"CODE",{});var xn=r(Ce);Ro=s(xn,"huggingface_hub"),xn.forEach(t),jo=s(zo,` library offers a range of mixins that can be used as a parent class for your
objects, in order to provide simple uploading and downloading functions.`),zo.forEach(t),xo=l(o),R=a(o,"H3",{class:!0});var Lo=r(R);Z=a(Lo,"A",{id:!0,class:!0,href:!0});var $n=r(Z);qe=a($n,"SPAN",{});var kn=r(qe);y(pe.$$.fragment,kn),kn.forEach(t),$n.forEach(t),Bo=l(Lo),We=a(Lo,"SPAN",{});var En=r(We);Yo=s(En,"PyTorch"),En.forEach(t),Lo.forEach(t),$o=l(o),N=a(o,"DIV",{class:!0});var W=r(N);y(ue.$$.fragment,W),Go=l(W),D=a(W,"P",{});var se=r(D);Jo=s(se,`A Generic Base Model Hub Mixin. Define your own mixin for anything by
inheriting from this class and overwriting `),Ke=a(se,"CODE",{});var Mn=r(Ke);Qo=s(Mn,"_from_pretrained"),Mn.forEach(t),Xo=s(se,` and
`),Ve=a(se,"CODE",{});var Tn=r(Ve);Zo=s(Tn,"_save_pretrained"),Tn.forEach(t),et=s(se,` to define custom logic for saving/loading your classes.
See `),Re=a(se,"CODE",{});var Hn=r(Re);ot=s(Hn,"huggingface_hub.PyTorchModelHubMixin"),Hn.forEach(t),tt=s(se," for an example."),se.forEach(t),nt=l(W),C=a(W,"DIV",{class:!0});var Se=r(C);y(me.$$.fragment,Se),at=l(Se),j=a(Se,"P",{});var ze=r(j);rt=s(ze,`Instantiate a pretrained PyTorch model from a pre-trained model
configuration from huggingface-hub. The model is set in
evaluation mode by default using `),je=a(ze,"CODE",{});var Nn=r(je);it=s(Nn,"model.eval()"),Nn.forEach(t),st=s(ze,` (Dropout modules
are deactivated). To train the model, you should first set it
back in training mode with `),Be=a(ze,"CODE",{});var Pn=r(Be);dt=s(Pn,"model.train()"),Pn.forEach(t),lt=s(ze,"."),ze.forEach(t),ct=l(Se),y(ee.$$.fragment,Se),Se.forEach(t),ht=l(W),q=a(W,"DIV",{class:!0});var Le=r(q);y(fe.$$.fragment,Le),gt=l(Le),Ye=a(Le,"P",{});var On=r(Ye);pt=s(On,"Upload model checkpoint to the Hub."),On.forEach(t),ut=l(Le),S=a(Le,"P",{});var de=r(S);mt=s(de,"Use "),Ge=a(de,"CODE",{});var Dn=r(Ge);ft=s(Dn,"allow_patterns"),Dn.forEach(t),_t=s(de," and "),Je=a(de,"CODE",{});var Sn=r(Je);bt=s(Sn,"ignore_patterns"),Sn.forEach(t),vt=s(de,` to precisely filter which files
should be pushed to the hub. See `),Pe=a(de,"A",{href:!0});var zn=r(Pe);yt=s(zn,"upload_folder()"),zn.forEach(t),wt=s(de," reference for more details."),de.forEach(t),Le.forEach(t),xt=l(W),oe=a(W,"DIV",{class:!0});var Ao=r(oe);y(_e.$$.fragment,Ao),$t=l(Ao),Qe=a(Ao,"P",{});var Ln=r(Qe);kt=s(Ln,"Save weights in local directory."),Ln.forEach(t),Ao.forEach(t),W.forEach(t),ko=l(o),B=a(o,"H3",{class:!0});var Io=r(B);te=a(Io,"A",{id:!0,class:!0,href:!0});var An=r(te);Xe=a(An,"SPAN",{});var In=r(Xe);y(be.$$.fragment,In),In.forEach(t),An.forEach(t),Et=l(Io),Ze=a(Io,"SPAN",{});var Fn=r(Ze);Mt=s(Fn,"Keras"),Fn.forEach(t),Io.forEach(t),Eo=l(o),z=a(o,"DIV",{class:!0});var Ae=r(z);y(ve.$$.fragment,Ae),Tt=l(Ae),eo=a(Ae,"P",{});var Un=r(eo);Ht=s(Un,"Instantiate a pretrained Keras model from a pre-trained model from the Hub.\nThe model is expected to be in SavedModel format.```"),Un.forEach(t),Nt=l(Ae),y(ne.$$.fragment,Ae),Ae.forEach(t),Mo=l(o),L=a(o,"DIV",{class:!0});var Ie=r(L);y(ye.$$.fragment,Ie),Pt=l(Ie),we=a(Ie,"P",{});var Fo=r(we);Ot=s(Fo,`Upload model checkpoint or tokenizer files to the Hub while synchronizing a
local clone of the repo in `),oo=a(Fo,"CODE",{});var Cn=r(oo);Dt=s(Cn,"repo_path_or_name"),Cn.forEach(t),St=s(Fo,"."),Fo.forEach(t),zt=l(Ie),A=a(Ie,"P",{});var le=r(A);Lt=s(le,"Use "),to=a(le,"CODE",{});var qn=r(to);At=s(qn,"allow_patterns"),qn.forEach(t),It=s(le," and "),no=a(le,"CODE",{});var Wn=r(no);Ft=s(Wn,"ignore_patterns"),Wn.forEach(t),Ut=s(le,` to precisely filter which files should be
pushed to the hub. See `),Oe=a(le,"A",{href:!0});var Kn=r(Oe);Ct=s(Kn,"upload_folder()"),Kn.forEach(t),qt=s(le," reference for more details."),le.forEach(t),Ie.forEach(t),To=l(o),Y=a(o,"DIV",{class:!0});var Uo=r(Y);y(xe.$$.fragment,Uo),Wt=l(Uo),ao=a(Uo,"P",{});var Vn=r(ao);Kt=s(Vn,`Saves a Keras model to save_directory in SavedModel format. Use this if
you\u2019re using the Functional or Sequential APIs.`),Vn.forEach(t),Uo.forEach(t),Ho=l(o),I=a(o,"DIV",{class:!0});var Fe=r(I);y($e.$$.fragment,Fe),Vt=l(Fe),ro=a(Fe,"P",{});var Rn=r(ro);Rt=s(Rn,`Mixin to provide model Hub upload/download capabilities to Keras models.
Override this class to obtain the following internal methods:`),Rn.forEach(t),jt=l(Fe),ke=a(Fe,"UL",{});var Co=r(ke);De=a(Co,"LI",{});var fn=r(De);io=a(fn,"CODE",{});var jn=r(io);Bt=s(jn,"_from_pretrained"),jn.forEach(t),Yt=s(fn,", to load a model from the Hub or from local files."),fn.forEach(t),Gt=l(Co),ae=a(Co,"LI",{});var vo=r(ae);so=a(vo,"CODE",{});var Bn=r(so);Jt=s(Bn,"_save_pretrained"),Bn.forEach(t),Qt=s(vo,", to save a model in the "),lo=a(vo,"CODE",{});var Yn=r(lo);Xt=s(Yn,"SavedModel"),Yn.forEach(t),Zt=s(vo," format."),vo.forEach(t),Co.forEach(t),Fe.forEach(t),No=l(o),G=a(o,"H3",{class:!0});var qo=r(G);re=a(qo,"A",{id:!0,class:!0,href:!0});var Gn=r(re);co=a(Gn,"SPAN",{});var Jn=r(co);y(Ee.$$.fragment,Jn),Jn.forEach(t),Gn.forEach(t),en=l(qo),ho=a(qo,"SPAN",{});var Qn=r(ho);on=s(Qn,"Fastai"),Qn.forEach(t),qo.forEach(t),Po=l(o),J=a(o,"DIV",{class:!0});var Wo=r(J);y(Me.$$.fragment,Wo),tn=l(Wo),go=a(Wo,"P",{});var Xn=r(go);nn=s(Xn,"Load pretrained fastai model from the Hub or from a local directory."),Xn.forEach(t),Wo.forEach(t),Oo=l(o),P=a(o,"DIV",{class:!0});var ce=r(P);y(Te.$$.fragment,ce),an=l(ce),po=a(ce,"P",{});var Zn=r(po);rn=s(Zn,"Upload learner checkpoint files to the Hub."),Zn.forEach(t),sn=l(ce),F=a(ce,"P",{});var he=r(F);dn=s(he,"Use "),uo=a(he,"EM",{});var ea=r(uo);ln=s(ea,"allow_patterns"),ea.forEach(t),cn=s(he," and "),mo=a(he,"EM",{});var oa=r(mo);hn=s(oa,"ignore_patterns"),oa.forEach(t),gn=s(he,` to precisely filter which files should be
pushed to the hub. See [`),fo=a(he,"EM",{});var ta=r(fo);pn=s(ta,"upload_folder"),ta.forEach(t),un=s(he,"] reference for more details."),he.forEach(t),mn=l(ce),y(ie.$$.fragment,ce),ce.forEach(t),this.h()},h(){h(g,"name","hf:doc:metadata"),h(g,"content",JSON.stringify(ga)),h(f,"id","mixins-serialization-methods"),h(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(f,"href","#mixins-serialization-methods"),h(m,"class","relative group"),h(O,"id","mixins"),h(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(O,"href","#mixins"),h(T,"class","relative group"),h(Z,"id","huggingface_hub.ModelHubMixin"),h(Z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Z,"href","#huggingface_hub.ModelHubMixin"),h(R,"class","relative group"),h(C,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(Pe,"href","/docs/huggingface_hub/v0.10.0.rc1/en/package_reference/hf_api#huggingface_hub.HfApi.upload_folder"),h(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(oe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(N,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(te,"id","huggingface_hub.from_pretrained_keras"),h(te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(te,"href","#huggingface_hub.from_pretrained_keras"),h(B,"class","relative group"),h(z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(Oe,"href","/docs/huggingface_hub/v0.10.0.rc1/en/package_reference/hf_api#huggingface_hub.HfApi.upload_folder"),h(L,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(Y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(I,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(re,"id","huggingface_hub.from_pretrained_fastai"),h(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(re,"href","#huggingface_hub.from_pretrained_fastai"),h(G,"class","relative group"),h(J,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),h(P,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(o,c){e(document.head,g),p(o,E,c),p(o,m,c),e(m,f),e(f,b),w(u,b,null),e(m,_),e(m,H),e(H,ge),p(o,M,c),p(o,T,c),e(T,O),e(O,V),w(U,V,null),e(T,Ne),e(T,Ue),e(Ue,Ko),p(o,wo,c),p(o,X,c),e(X,Vo),e(X,Ce),e(Ce,Ro),e(X,jo),p(o,xo,c),p(o,R,c),e(R,Z),e(Z,qe),w(pe,qe,null),e(R,Bo),e(R,We),e(We,Yo),p(o,$o,c),p(o,N,c),w(ue,N,null),e(N,Go),e(N,D),e(D,Jo),e(D,Ke),e(Ke,Qo),e(D,Xo),e(D,Ve),e(Ve,Zo),e(D,et),e(D,Re),e(Re,ot),e(D,tt),e(N,nt),e(N,C),w(me,C,null),e(C,at),e(C,j),e(j,rt),e(j,je),e(je,it),e(j,st),e(j,Be),e(Be,dt),e(j,lt),e(C,ct),w(ee,C,null),e(N,ht),e(N,q),w(fe,q,null),e(q,gt),e(q,Ye),e(Ye,pt),e(q,ut),e(q,S),e(S,mt),e(S,Ge),e(Ge,ft),e(S,_t),e(S,Je),e(Je,bt),e(S,vt),e(S,Pe),e(Pe,yt),e(S,wt),e(N,xt),e(N,oe),w(_e,oe,null),e(oe,$t),e(oe,Qe),e(Qe,kt),p(o,ko,c),p(o,B,c),e(B,te),e(te,Xe),w(be,Xe,null),e(B,Et),e(B,Ze),e(Ze,Mt),p(o,Eo,c),p(o,z,c),w(ve,z,null),e(z,Tt),e(z,eo),e(eo,Ht),e(z,Nt),w(ne,z,null),p(o,Mo,c),p(o,L,c),w(ye,L,null),e(L,Pt),e(L,we),e(we,Ot),e(we,oo),e(oo,Dt),e(we,St),e(L,zt),e(L,A),e(A,Lt),e(A,to),e(to,At),e(A,It),e(A,no),e(no,Ft),e(A,Ut),e(A,Oe),e(Oe,Ct),e(A,qt),p(o,To,c),p(o,Y,c),w(xe,Y,null),e(Y,Wt),e(Y,ao),e(ao,Kt),p(o,Ho,c),p(o,I,c),w($e,I,null),e(I,Vt),e(I,ro),e(ro,Rt),e(I,jt),e(I,ke),e(ke,De),e(De,io),e(io,Bt),e(De,Yt),e(ke,Gt),e(ke,ae),e(ae,so),e(so,Jt),e(ae,Qt),e(ae,lo),e(lo,Xt),e(ae,Zt),p(o,No,c),p(o,G,c),e(G,re),e(re,co),w(Ee,co,null),e(G,en),e(G,ho),e(ho,on),p(o,Po,c),p(o,J,c),w(Me,J,null),e(J,tn),e(J,go),e(go,nn),p(o,Oo,c),p(o,P,c),w(Te,P,null),e(P,an),e(P,po),e(po,rn),e(P,sn),e(P,F),e(F,dn),e(F,uo),e(uo,ln),e(F,cn),e(F,mo),e(mo,hn),e(F,gn),e(F,fo),e(fo,pn),e(F,un),e(P,mn),w(ie,P,null),Do=!0},p(o,[c]){const He={};c&2&&(He.$$scope={dirty:c,ctx:o}),ee.$set(He);const _o={};c&2&&(_o.$$scope={dirty:c,ctx:o}),ne.$set(_o);const bo={};c&2&&(bo.$$scope={dirty:c,ctx:o}),ie.$set(bo)},i(o){Do||(x(u.$$.fragment,o),x(U.$$.fragment,o),x(pe.$$.fragment,o),x(ue.$$.fragment,o),x(me.$$.fragment,o),x(ee.$$.fragment,o),x(fe.$$.fragment,o),x(_e.$$.fragment,o),x(be.$$.fragment,o),x(ve.$$.fragment,o),x(ne.$$.fragment,o),x(ye.$$.fragment,o),x(xe.$$.fragment,o),x($e.$$.fragment,o),x(Ee.$$.fragment,o),x(Me.$$.fragment,o),x(Te.$$.fragment,o),x(ie.$$.fragment,o),Do=!0)},o(o){$(u.$$.fragment,o),$(U.$$.fragment,o),$(pe.$$.fragment,o),$(ue.$$.fragment,o),$(me.$$.fragment,o),$(ee.$$.fragment,o),$(fe.$$.fragment,o),$(_e.$$.fragment,o),$(be.$$.fragment,o),$(ve.$$.fragment,o),$(ne.$$.fragment,o),$(ye.$$.fragment,o),$(xe.$$.fragment,o),$($e.$$.fragment,o),$(Ee.$$.fragment,o),$(Me.$$.fragment,o),$(Te.$$.fragment,o),$(ie.$$.fragment,o),Do=!1},d(o){t(g),o&&t(E),o&&t(m),k(u),o&&t(M),o&&t(T),k(U),o&&t(wo),o&&t(X),o&&t(xo),o&&t(R),k(pe),o&&t($o),o&&t(N),k(ue),k(me),k(ee),k(fe),k(_e),o&&t(ko),o&&t(B),k(be),o&&t(Eo),o&&t(z),k(ve),k(ne),o&&t(Mo),o&&t(L),k(ye),o&&t(To),o&&t(Y),k(xe),o&&t(Ho),o&&t(I),k($e),o&&t(No),o&&t(G),k(Ee),o&&t(Po),o&&t(J),k(Me),o&&t(Oo),o&&t(P),k(Te),k(ie)}}}const ga={local:"mixins-serialization-methods",sections:[{local:"mixins",sections:[{local:"huggingface_hub.ModelHubMixin",title:"PyTorch"},{local:"huggingface_hub.from_pretrained_keras",title:"Keras"},{local:"huggingface_hub.from_pretrained_fastai",title:"Fastai"}],title:"Mixins"}],title:"Mixins & serialization methods"};function pa(Q){return sa(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ba extends na{constructor(g){super();aa(this,g,pa,ha,ra,{})}}export{ba as default,ga as metadata};
