import{S as qs,i as Fs,s as Ms,e as t,k as d,w as N,t as l,M as Hs,c as n,d as a,m as h,a as s,x as P,h as r,b as p,G as e,g as c,y as R,q as S,o as L,B as q,v as Us,L as Bs}from"../../chunks/vendor-hf-doc-builder.js";import{T as Cn}from"../../chunks/Tip-hf-doc-builder.js";import{D as An}from"../../chunks/Docstring-hf-doc-builder.js";import{C as To}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as Do}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as zs}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function Vs(ge){let b,C,_,f,g,u,v,F,M,y,w,D,V,k,m,E,H,J,U,j,T,W,pe,Q,A,$,I,oe,_e,X,ve,ue,ne,ae,Y,se,we,Ke,G,me,O,be;return{c(){b=t("p"),C=l("Raises the following errors:"),_=d(),f=t("ul"),g=t("li"),u=t("a"),v=t("code"),F=l("EnvironmentError"),M=l(`
if `),y=t("code"),w=l("use_auth_token=True"),D=l(" and the token cannot be found."),V=d(),k=t("li"),m=t("a"),E=t("code"),H=l("OSError"),J=l(`
if ETag cannot be determined.`),U=d(),j=t("li"),T=t("a"),W=t("code"),pe=l("ValueError"),Q=l(`
if some parameter value is invalid`),A=d(),$=t("li"),I=t("a"),oe=l("RepositoryNotFoundError"),_e=l(`
If the repository to download from cannot be found. This may be because it doesn\u2019t exist,
or because it is set to `),X=t("code"),ve=l("private"),ue=l(" and you do not have access."),ne=d(),ae=t("li"),Y=t("a"),se=l("RevisionNotFoundError"),we=l(`
If the revision to download from cannot be found.`),Ke=d(),G=t("li"),me=t("a"),O=l("EntryNotFoundError"),be=l(`
If the file to download cannot be found.`),this.h()},l(K){b=n(K,"P",{});var le=s(b);C=r(le,"Raises the following errors:"),le.forEach(a),_=h(K),f=n(K,"UL",{});var B=s(f);g=n(B,"LI",{});var je=s(g);u=n(je,"A",{href:!0,rel:!0});var Oe=s(u);v=n(Oe,"CODE",{});var co=s(v);F=r(co,"EnvironmentError"),co.forEach(a),Oe.forEach(a),M=r(je,`
if `),y=n(je,"CODE",{});var ho=s(y);w=r(ho,"use_auth_token=True"),ho.forEach(a),D=r(je," and the token cannot be found."),je.forEach(a),V=h(B),k=n(B,"LI",{});var ke=s(k);m=n(ke,"A",{href:!0,rel:!0});var fo=s(m);E=n(fo,"CODE",{});var po=s(E);H=r(po,"OSError"),po.forEach(a),fo.forEach(a),J=r(ke,`
if ETag cannot be determined.`),ke.forEach(a),U=h(B),j=n(B,"LI",{});var re=s(j);T=n(re,"A",{href:!0,rel:!0});var Je=s(T);W=n(Je,"CODE",{});var x=s(W);pe=r(x,"ValueError"),x.forEach(a),Je.forEach(a),Q=r(re,`
if some parameter value is invalid`),re.forEach(a),A=h(B),$=n(B,"LI",{});var te=s($);I=n(te,"A",{href:!0});var uo=s(I);oe=r(uo,"RepositoryNotFoundError"),uo.forEach(a),_e=r(te,`
If the repository to download from cannot be found. This may be because it doesn\u2019t exist,
or because it is set to `),X=n(te,"CODE",{});var Ne=s(X);ve=r(Ne,"private"),Ne.forEach(a),ue=r(te," and you do not have access."),te.forEach(a),ne=h(B),ae=n(B,"LI",{});var Qe=s(ae);Y=n(Qe,"A",{href:!0});var mo=s(Y);se=r(mo,"RevisionNotFoundError"),mo.forEach(a),we=r(Qe,`
If the revision to download from cannot be found.`),Qe.forEach(a),Ke=h(B),G=n(B,"LI",{});var xe=s(G);me=n(xe,"A",{href:!0});var bo=s(me);O=r(bo,"EntryNotFoundError"),bo.forEach(a),be=r(xe,`
If the file to download cannot be found.`),xe.forEach(a),B.forEach(a),this.h()},h(){p(u,"href","https://docs.python.org/3/library/exceptions.html#EnvironmentError"),p(u,"rel","nofollow"),p(m,"href","https://docs.python.org/3/library/exceptions.html#OSError"),p(m,"rel","nofollow"),p(T,"href","https://docs.python.org/3/library/exceptions.html#ValueError"),p(T,"rel","nofollow"),p(I,"href","/docs/huggingface_hub/main/en/package_reference/utilities#huggingface_hub.utils.RepositoryNotFoundError"),p(Y,"href","/docs/huggingface_hub/main/en/package_reference/utilities#huggingface_hub.utils.RevisionNotFoundError"),p(me,"href","/docs/huggingface_hub/main/en/package_reference/utilities#huggingface_hub.utils.EntryNotFoundError")},m(K,le){c(K,b,le),e(b,C),c(K,_,le),c(K,f,le),e(f,g),e(g,u),e(u,v),e(v,F),e(g,M),e(g,y),e(y,w),e(g,D),e(f,V),e(f,k),e(k,m),e(m,E),e(E,H),e(k,J),e(f,U),e(f,j),e(j,T),e(T,W),e(W,pe),e(j,Q),e(f,A),e(f,$),e($,I),e(I,oe),e($,_e),e($,X),e(X,ve),e($,ue),e(f,ne),e(f,ae),e(ae,Y),e(Y,se),e(ae,we),e(f,Ke),e(f,G),e(G,me),e(me,O),e(G,be)},d(K){K&&a(b),K&&a(_),K&&a(f)}}}function Ws(ge){let b,C,_,f,g,u,v,F,M,y,w,D,V,k,m,E,H,J,U,j,T,W,pe,Q;return{c(){b=t("p"),C=l("Raises the following errors:"),_=d(),f=t("ul"),g=t("li"),u=t("a"),v=t("code"),F=l("EnvironmentError"),M=l(`
if `),y=t("code"),w=l("use_auth_token=True"),D=l(" and the token cannot be found."),V=d(),k=t("li"),m=t("a"),E=t("code"),H=l("OSError"),J=l(` if
ETag cannot be determined.`),U=d(),j=t("li"),T=t("a"),W=t("code"),pe=l("ValueError"),Q=l(`
if some parameter value is invalid`),this.h()},l(A){b=n(A,"P",{});var $=s(b);C=r($,"Raises the following errors:"),$.forEach(a),_=h(A),f=n(A,"UL",{});var I=s(f);g=n(I,"LI",{});var oe=s(g);u=n(oe,"A",{href:!0,rel:!0});var _e=s(u);v=n(_e,"CODE",{});var X=s(v);F=r(X,"EnvironmentError"),X.forEach(a),_e.forEach(a),M=r(oe,`
if `),y=n(oe,"CODE",{});var ve=s(y);w=r(ve,"use_auth_token=True"),ve.forEach(a),D=r(oe," and the token cannot be found."),oe.forEach(a),V=h(I),k=n(I,"LI",{});var ue=s(k);m=n(ue,"A",{href:!0,rel:!0});var ne=s(m);E=n(ne,"CODE",{});var ae=s(E);H=r(ae,"OSError"),ae.forEach(a),ne.forEach(a),J=r(ue,` if
ETag cannot be determined.`),ue.forEach(a),U=h(I),j=n(I,"LI",{});var Y=s(j);T=n(Y,"A",{href:!0,rel:!0});var se=s(T);W=n(se,"CODE",{});var we=s(W);pe=r(we,"ValueError"),we.forEach(a),se.forEach(a),Q=r(Y,`
if some parameter value is invalid`),Y.forEach(a),I.forEach(a),this.h()},h(){p(u,"href","https://docs.python.org/3/library/exceptions.html#EnvironmentError"),p(u,"rel","nofollow"),p(m,"href","https://docs.python.org/3/library/exceptions.html#OSError"),p(m,"rel","nofollow"),p(T,"href","https://docs.python.org/3/library/exceptions.html#ValueError"),p(T,"rel","nofollow")},m(A,$){c(A,b,$),e(b,C),c(A,_,$),c(A,f,$),e(f,g),e(g,u),e(u,v),e(v,F),e(g,M),e(g,y),e(y,w),e(g,D),e(f,V),e(f,k),e(k,m),e(m,E),e(E,H),e(k,J),e(f,U),e(f,j),e(j,T),e(T,W),e(W,pe),e(j,Q)},d(A){A&&a(b),A&&a(_),A&&a(f)}}}function Gs(ge){let b,C,_,f,g;return f=new To({props:{code:`from huggingface_hub import hf_hub_url

hf_hub_url(
    repo_id="julien-c/EsperBERTo-small", filename="pytorch_model.bin"
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> hf_hub_url

<span class="hljs-meta">&gt;&gt;&gt; </span>hf_hub_url(
<span class="hljs-meta">... </span>    repo_id=<span class="hljs-string">&quot;julien-c/EsperBERTo-small&quot;</span>, filename=<span class="hljs-string">&quot;pytorch_model.bin&quot;</span>
<span class="hljs-meta">... </span>)
<span class="hljs-string">&#x27;https://huggingface.co/julien-c/EsperBERTo-small/resolve/main/pytorch_model.bin&#x27;</span>`}}),{c(){b=t("p"),C=l("Example:"),_=d(),N(f.$$.fragment)},l(u){b=n(u,"P",{});var v=s(b);C=r(v,"Example:"),v.forEach(a),_=h(u),P(f.$$.fragment,u)},m(u,v){c(u,b,v),e(b,C),c(u,_,v),R(f,u,v),g=!0},p:Bs,i(u){g||(S(f.$$.fragment,u),g=!0)},o(u){L(f.$$.fragment,u),g=!1},d(u){u&&a(b),u&&a(_),q(f,u)}}}function Ks(ge){let b,C,_,f,g,u,v,F,M,y,w,D,V,k;return{c(){b=t("p"),C=l("Notes:"),_=d(),f=t("p"),g=l(`Cloudfront is replicated over the globe so downloads are way faster for
the end user (and it also lowers our bandwidth costs).`),u=d(),v=t("p"),F=l(`Cloudfront aggressively caches files by default (default TTL is 24
hours), however this is not an issue here because we implement a
git-based versioning system on huggingface.co, which means that we store
the files on S3/Cloudfront in a content-addressable way (i.e., the file
name is its hash). Using content-addressable filenames means cache can\u2019t
ever be stale.`),M=d(),y=t("p"),w=l(`In terms of client-side caching from this library, we base our caching
on the objects\u2019 entity tag (`),D=t("code"),V=l("ETag"),k=l(`), which is an identifier of a
specific version of a resource [1]_. An object\u2019s ETag is: its git-sha1
if stored in git, or its sha256 if stored in git-lfs.`)},l(m){b=n(m,"P",{});var E=s(b);C=r(E,"Notes:"),E.forEach(a),_=h(m),f=n(m,"P",{});var H=s(f);g=r(H,`Cloudfront is replicated over the globe so downloads are way faster for
the end user (and it also lowers our bandwidth costs).`),H.forEach(a),u=h(m),v=n(m,"P",{});var J=s(v);F=r(J,`Cloudfront aggressively caches files by default (default TTL is 24
hours), however this is not an issue here because we implement a
git-based versioning system on huggingface.co, which means that we store
the files on S3/Cloudfront in a content-addressable way (i.e., the file
name is its hash). Using content-addressable filenames means cache can\u2019t
ever be stale.`),J.forEach(a),M=h(m),y=n(m,"P",{});var U=s(y);w=r(U,`In terms of client-side caching from this library, we base our caching
on the objects\u2019 entity tag (`),D=n(U,"CODE",{});var j=s(D);V=r(j,"ETag"),j.forEach(a),k=r(U,`), which is an identifier of a
specific version of a resource [1]_. An object\u2019s ETag is: its git-sha1
if stored in git, or its sha256 if stored in git-lfs.`),U.forEach(a)},m(m,E){c(m,b,E),e(b,C),c(m,_,E),c(m,f,E),e(f,g),c(m,u,E),c(m,v,E),e(v,F),c(m,M,E),c(m,y,E),e(y,w),e(y,D),e(D,V),e(y,k)},d(m){m&&a(b),m&&a(_),m&&a(f),m&&a(u),m&&a(v),m&&a(M),m&&a(y)}}}function Js(ge){let b,C,_,f,g,u,v,F,M,y,w,D,V,k,m,E,H,J,U,j,T,W,pe,Q,A,$,I,oe,_e,X,ve,ue,ne,ae,Y,se,we,Ke,G,me,O,be,K,le,B,je,Oe,co,ho,ke,fo,po,re,Je,x,te,uo,Ne,Qe,mo,xe,bo,Ya,Pe,Za,Re,et,Co,ot,at,Ao,go,tt,Xe,nt,ua,De,Se,Io,Ye,st,Oo,lt,ma,_o,rt,ba,vo,it,ga,Ze,_a,ie,ct,No,dt,ht,Po,ft,pt,Ro,ut,mt,va,wo,bt,wa,eo,Ea,Eo,gt,ya,yo,_t,$a,oo,ja,$o,vt,ka,Te,Le,So,ao,wt,Lo,Et,xa,Z,yt,qo,$t,jt,Fo,kt,xt,Mo,Dt,Tt,Ho,Ct,At,Da,ce,It,Uo,Ot,Nt,Bo,Pt,Rt,zo,St,Lt,Ta,de,qt,Vo,Ft,Mt,Wo,Ht,Ut,Go,Bt,zt,Ca,Ce,qe,Ko,to,Vt,Jo,Wt,Aa,Fe,Gt,Qo,Kt,Jt,Ia,Ae,Me,Xo,no,Qt,Yo,Xt,Oa,He,Yt,Zo,Zt,en,Na,z,on,ea,an,tn,oa,nn,sn,aa,ln,rn,ta,cn,dn,na,hn,fn,Pa,Ee,pn,sa,un,mn,la,bn,gn,Ra,so,Sa,Ue,_n,ra,vn,wn,La,Be,En,ia,yn,$n,qa,Ie,ze,ca,lo,jn,da,kn,Fa,jo,xn,Ma,ro,Ha;return u=new Do({}),D=new An({props:{name:"huggingface_hub.hf_hub_download",anchor:"huggingface_hub.hf_hub_download",parameters:[{name:"repo_id",val:": str"},{name:"filename",val:": str"},{name:"subfolder",val:": typing.Optional[str] = None"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"revision",val:": typing.Optional[str] = None"},{name:"library_name",val:": typing.Optional[str] = None"},{name:"library_version",val:": typing.Optional[str] = None"},{name:"cache_dir",val:": typing.Union[str, pathlib.Path, NoneType] = None"},{name:"user_agent",val:": typing.Union[typing.Dict, str, NoneType] = None"},{name:"force_download",val:": typing.Optional[bool] = False"},{name:"force_filename",val:": typing.Optional[str] = None"},{name:"proxies",val:": typing.Optional[typing.Dict] = None"},{name:"etag_timeout",val:": typing.Optional[float] = 10"},{name:"resume_download",val:": typing.Optional[bool] = False"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = None"},{name:"local_files_only",val:": typing.Optional[bool] = False"},{name:"legacy_cache_layout",val:": typing.Optional[bool] = False"}],parametersDescription:[{anchor:"huggingface_hub.hf_hub_download.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
A user or an organization name and a repo name separated by a <code>/</code>.`,name:"repo_id"},{anchor:"huggingface_hub.hf_hub_download.filename",description:`<strong>filename</strong> (<code>str</code>) &#x2014;
The name of the file in the repo.`,name:"filename"},{anchor:"huggingface_hub.hf_hub_download.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An optional value corresponding to a folder inside the model repo.`,name:"subfolder"},{anchor:"huggingface_hub.hf_hub_download.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if uploading to a dataset or space,
<code>None</code> or <code>&quot;model&quot;</code> if uploading to a model. Default is <code>None</code>.`,name:"repo_type"},{anchor:"huggingface_hub.hf_hub_download.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An optional Git revision id which can be a branch name, a tag, or a
commit hash.`,name:"revision"},{anchor:"huggingface_hub.hf_hub_download.library_name",description:`<strong>library_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The name of the library to which the object corresponds.`,name:"library_name"},{anchor:"huggingface_hub.hf_hub_download.library_version",description:`<strong>library_version</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The version of the library.`,name:"library_version"},{anchor:"huggingface_hub.hf_hub_download.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code>, <code>Path</code>, <em>optional</em>) &#x2014;
Path to the folder where cached files are stored.`,name:"cache_dir"},{anchor:"huggingface_hub.hf_hub_download.user_agent",description:`<strong>user_agent</strong> (<code>dict</code>, <code>str</code>, <em>optional</em>) &#x2014;
The user-agent info in the form of a dictionary or a string.`,name:"user_agent"},{anchor:"huggingface_hub.hf_hub_download.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether the file should be downloaded even if it already exists in
the local cache.`,name:"force_download"},{anchor:"huggingface_hub.hf_hub_download.proxies",description:`<strong>proxies</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Dictionary mapping protocol to the URL of the proxy passed to
<code>requests.request</code>.`,name:"proxies"},{anchor:"huggingface_hub.hf_hub_download.etag_timeout",description:`<strong>etag_timeout</strong> (<code>float</code>, <em>optional</em>, defaults to <code>10</code>) &#x2014;
When fetching ETag, how many seconds to wait for the server to send
data before giving up which is passed to <code>requests.request</code>.`,name:"etag_timeout"},{anchor:"huggingface_hub.hf_hub_download.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>True</code>, resume a previously interrupted download.`,name:"resume_download"},{anchor:"huggingface_hub.hf_hub_download.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code>, <code>bool</code>, <em>optional</em>) &#x2014;
A token to be used for the download.<ul>
<li>If <code>True</code>, the token is read from the HuggingFace config
folder.</li>
<li>If a string, it&#x2019;s used as the authentication token.</li>
</ul>`,name:"use_auth_token"},{anchor:"huggingface_hub.hf_hub_download.local_files_only",description:`<strong>local_files_only</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>True</code>, avoid downloading the file and return the path to the
local cached file if it exists.`,name:"local_files_only"},{anchor:"huggingface_hub.hf_hub_download.legacy_cache_layout",description:`<strong>legacy_cache_layout</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>True</code>, uses the legacy file cache layout i.e. just call <a href="/docs/huggingface_hub/main/en/package_reference/file_download#huggingface_hub.hf_hub_url">hf_hub_url()</a>
then <code>cached_download</code>. This is deprecated as the new cache layout is
more powerful.`,name:"legacy_cache_layout"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/file_download.py#L800",returnDescription:`
<p>Local path (string) of file or if networking is off, last version of
file cached on disk.</p>
`}}),G=new Cn({props:{$$slots:{default:[Vs]},$$scope:{ctx:ge}}}),be=new An({props:{name:"huggingface_hub.snapshot_download",anchor:"huggingface_hub.snapshot_download",parameters:[{name:"repo_id",val:": str"},{name:"revision",val:": typing.Optional[str] = None"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"cache_dir",val:": typing.Union[str, pathlib.Path, NoneType] = None"},{name:"library_name",val:": typing.Optional[str] = None"},{name:"library_version",val:": typing.Optional[str] = None"},{name:"user_agent",val:": typing.Union[typing.Dict, str, NoneType] = None"},{name:"proxies",val:": typing.Optional[typing.Dict] = None"},{name:"etag_timeout",val:": typing.Optional[float] = 10"},{name:"resume_download",val:": typing.Optional[bool] = False"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = None"},{name:"local_files_only",val:": typing.Optional[bool] = False"},{name:"allow_regex",val:": typing.Union[typing.List[str], str, NoneType] = None"},{name:"ignore_regex",val:": typing.Union[typing.List[str], str, NoneType] = None"}],parametersDescription:[{anchor:"huggingface_hub.snapshot_download.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
A user or an organization name and a repo name separated by a <code>/</code>.`,name:"repo_id"},{anchor:"huggingface_hub.snapshot_download.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An optional Git revision id which can be a branch name, a tag, or a
commit hash.`,name:"revision"},{anchor:"huggingface_hub.snapshot_download.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if uploading to a dataset or space,
<code>None</code> or <code>&quot;model&quot;</code> if uploading to a model. Default is <code>None</code>.`,name:"repo_type"},{anchor:"huggingface_hub.snapshot_download.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code>, <code>Path</code>, <em>optional</em>) &#x2014;
Path to the folder where cached files are stored.`,name:"cache_dir"},{anchor:"huggingface_hub.snapshot_download.library_name",description:`<strong>library_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The name of the library to which the object corresponds.`,name:"library_name"},{anchor:"huggingface_hub.snapshot_download.library_version",description:`<strong>library_version</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The version of the library.`,name:"library_version"},{anchor:"huggingface_hub.snapshot_download.user_agent",description:`<strong>user_agent</strong> (<code>str</code>, <code>dict</code>, <em>optional</em>) &#x2014;
The user-agent info in the form of a dictionary or a string.`,name:"user_agent"},{anchor:"huggingface_hub.snapshot_download.proxies",description:`<strong>proxies</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Dictionary mapping protocol to the URL of the proxy passed to
<code>requests.request</code>.`,name:"proxies"},{anchor:"huggingface_hub.snapshot_download.etag_timeout",description:`<strong>etag_timeout</strong> (<code>float</code>, <em>optional</em>, defaults to <code>10</code>) &#x2014;
When fetching ETag, how many seconds to wait for the server to send
data before giving up which is passed to <code>requests.request</code>.`,name:"etag_timeout"},{anchor:"huggingface_hub.snapshot_download.resume_download",description:"<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False) -- If </code>True`, resume a previously interrupted download.",name:"resume_download"},{anchor:"huggingface_hub.snapshot_download.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code>, <code>bool</code>, <em>optional</em>) &#x2014;
A token to be used for the download.<ul>
<li>If <code>True</code>, the token is read from the HuggingFace config
folder.</li>
<li>If a string, it&#x2019;s used as the authentication token.</li>
</ul>`,name:"use_auth_token"},{anchor:"huggingface_hub.snapshot_download.local_files_only",description:`<strong>local_files_only</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>True</code>, avoid downloading the file and return the path to the
local cached file if it exists.`,name:"local_files_only"},{anchor:"huggingface_hub.snapshot_download.allow_regex",description:`<strong>allow_regex</strong> (<code>list of str</code>, <code>str</code>, <em>optional</em>) &#x2014;
If provided, only files matching this regex are downloaded.`,name:"allow_regex"},{anchor:"huggingface_hub.snapshot_download.ignore_regex",description:`<strong>ignore_regex</strong> (<code>list of str</code>, <code>str</code>, <em>optional</em>) &#x2014;
If provided, files matching this regex are not downloaded.`,name:"ignore_regex"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/_snapshot_download.py#L41",returnDescription:`
<p>Local folder path (string) of repo snapshot</p>
`}}),re=new Cn({props:{$$slots:{default:[Ws]},$$scope:{ctx:ge}}}),te=new An({props:{name:"huggingface_hub.hf_hub_url",anchor:"huggingface_hub.hf_hub_url",parameters:[{name:"repo_id",val:": str"},{name:"filename",val:": str"},{name:"subfolder",val:": typing.Optional[str] = None"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"revision",val:": typing.Optional[str] = None"}],parametersDescription:[{anchor:"huggingface_hub.hf_hub_url.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
A namespace (user or an organization) name and a repo name separated
by a <code>/</code>.`,name:"repo_id"},{anchor:"huggingface_hub.hf_hub_url.filename",description:`<strong>filename</strong> (<code>str</code>) &#x2014;
The name of the file in the repo.`,name:"filename"},{anchor:"huggingface_hub.hf_hub_url.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An optional value corresponding to a folder inside the repo.`,name:"subfolder"},{anchor:"huggingface_hub.hf_hub_url.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if uploading to a dataset or space,
<code>None</code> or <code>&quot;model&quot;</code> if uploading to a model. Default is <code>None</code>.`,name:"repo_type"},{anchor:"huggingface_hub.hf_hub_url.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An optional Git revision id which can be a branch name, a tag, or a
commit hash.`,name:"revision"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/file_download.py#L154"}}),Pe=new zs({props:{anchor:"huggingface_hub.hf_hub_url.example",$$slots:{default:[Gs]},$$scope:{ctx:ge}}}),Re=new Cn({props:{$$slots:{default:[Ks]},$$scope:{ctx:ge}}}),Ye=new Do({}),Ze=new To({props:{code:`<CACHE_DIR>
\u251C\u2500 <MODELS>
\u251C\u2500 <DATASETS>
\u251C\u2500 <SPACES>`,highlighted:`<span class="hljs-tag">&lt;<span class="hljs-name">CACHE_DIR</span>&gt;</span>
\u251C\u2500 <span class="hljs-tag">&lt;<span class="hljs-name">MODELS</span>&gt;</span>
\u251C\u2500 <span class="hljs-tag">&lt;<span class="hljs-name">DATASETS</span>&gt;</span>
\u251C\u2500 <span class="hljs-tag">&lt;<span class="hljs-name">SPACES</span>&gt;</span>`}}),eo=new To({props:{code:`<CACHE_DIR>
\u251C\u2500 models--julien-c--EsperBERTo-small
\u251C\u2500 models--lysandrejik--arxiv-nlp
\u251C\u2500 models--bert-base-cased
\u251C\u2500 datasets--glue
\u251C\u2500 datasets--huggingface--DataMeasurementsFiles
\u251C\u2500 spaces--dalle-mini--dalle-mini`,highlighted:`&lt;<span class="hljs-comment">CACHE_DIR</span>&gt;
<span class="hljs-comment">\u251C\u2500</span> <span class="hljs-comment">models</span>--<span class="hljs-comment">julien</span><span class="hljs-literal">-</span><span class="hljs-comment">c</span>--<span class="hljs-comment">EsperBERTo</span><span class="hljs-literal">-</span><span class="hljs-comment">small</span>
<span class="hljs-comment">\u251C\u2500</span> <span class="hljs-comment">models</span>--<span class="hljs-comment">lysandrejik</span>--<span class="hljs-comment">arxiv</span><span class="hljs-literal">-</span><span class="hljs-comment">nlp</span>
<span class="hljs-comment">\u251C\u2500</span> <span class="hljs-comment">models</span>--<span class="hljs-comment">bert</span><span class="hljs-literal">-</span><span class="hljs-comment">base</span><span class="hljs-literal">-</span><span class="hljs-comment">cased</span>
<span class="hljs-comment">\u251C\u2500</span> <span class="hljs-comment">datasets</span>--<span class="hljs-comment">glue</span>
<span class="hljs-comment">\u251C\u2500</span> <span class="hljs-comment">datasets</span>--<span class="hljs-comment">huggingface</span>--<span class="hljs-comment">DataMeasurementsFiles</span>
<span class="hljs-comment">\u251C\u2500</span> <span class="hljs-comment">spaces</span>--<span class="hljs-comment">dalle</span><span class="hljs-literal">-</span><span class="hljs-comment">mini</span>--<span class="hljs-comment">dalle</span><span class="hljs-literal">-</span><span class="hljs-comment">mini</span>`}}),oo=new To({props:{code:`<CACHE_DIR>
\u251C\u2500 datasets--glue
\u2502  \u251C\u2500 refs
\u2502  \u251C\u2500 blobs
\u2502  \u251C\u2500 snapshots
...`,highlighted:`&lt;CACHE_DIR&gt;
\u251C\u2500 datasets<span class="hljs-params">--glue</span>
\u2502  \u251C\u2500 refs
\u2502  \u251C\u2500 blobs
\u2502  \u251C\u2500 snapshots
<span class="hljs-string">...</span>`}}),ao=new Do({}),to=new Do({}),no=new Do({}),so=new To({props:{code:"<CACHE_DIR>/<REPO_NAME>/snapshots/aaaaaa/README.md",highlighted:'&lt;CACHE_DIR&gt;<span class="hljs-regexp">/&lt;REPO_NAME&gt;/</span>snapshots<span class="hljs-regexp">/aaaaaa/</span>README.md'}}),lo=new Do({}),ro=new To({props:{code:`    [  96]  .
    \u2514\u2500\u2500 [ 160]  models--julien-c--EsperBERTo-small
        \u251C\u2500\u2500 [ 160]  blobs
        \u2502   \u251C\u2500\u2500 [321M]  403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
        \u2502   \u251C\u2500\u2500 [ 398]  7cb18dc9bafbfcf74629a4b760af1b160957a83e
        \u2502   \u2514\u2500\u2500 [1.4K]  d7edf6bd2a681fb0175f7735299831ee1b22b812
        \u251C\u2500\u2500 [  96]  refs
        \u2502   \u2514\u2500\u2500 [  40]  main
        \u2514\u2500\u2500 [ 128]  snapshots
            \u251C\u2500\u2500 [ 128]  2439f60ef33a0d46d85da5001d52aeda5b00ce9f
            \u2502   \u251C\u2500\u2500 [  52]  README.md -> ../../blobs/d7edf6bd2a681fb0175f7735299831ee1b22b812
            \u2502   \u2514\u2500\u2500 [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
            \u2514\u2500\u2500 [ 128]  bbc77c8132af1cc5cf678da3f1ddf2de43606d48
                \u251C\u2500\u2500 [  52]  README.md -> ../../blobs/7cb18dc9bafbfcf74629a4b760af1b160957a83e
                \u2514\u2500\u2500 [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd`,highlighted:`    <span class="hljs-selector-attr">[  96]</span>  .
    \u2514\u2500\u2500 <span class="hljs-selector-attr">[ 160]</span>  models<span class="hljs-attr">--julien-c--EsperBERTo-small</span>
        \u251C\u2500\u2500 <span class="hljs-selector-attr">[ 160]</span>  blobs
        \u2502   \u251C\u2500\u2500 <span class="hljs-selector-attr">[321M]</span>  <span class="hljs-number">403450</span>e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
        \u2502   \u251C\u2500\u2500 <span class="hljs-selector-attr">[ 398]</span>  <span class="hljs-number">7</span>cb18dc9bafbfcf74629a4b760af1b160957a83e
        \u2502   \u2514\u2500\u2500 <span class="hljs-selector-attr">[1.4K]</span>  d7edf6bd2a681fb0175f7735299831ee1b22b812
        \u251C\u2500\u2500 <span class="hljs-selector-attr">[  96]</span>  refs
        \u2502   \u2514\u2500\u2500 <span class="hljs-selector-attr">[  40]</span>  <span class="hljs-selector-tag">main</span>
        \u2514\u2500\u2500 <span class="hljs-selector-attr">[ 128]</span>  snapshots
            \u251C\u2500\u2500 <span class="hljs-selector-attr">[ 128]</span>  <span class="hljs-number">2439</span>f60ef33a0d46d85da5001d52aeda5b00ce9f
            \u2502   \u251C\u2500\u2500 <span class="hljs-selector-attr">[  52]</span>  README<span class="hljs-selector-class">.md</span> -&gt; ../../blobs/d7edf6bd2a681fb0175f7735299831ee1b22b812
            \u2502   \u2514\u2500\u2500 <span class="hljs-selector-attr">[  76]</span>  pytorch_model<span class="hljs-selector-class">.bin</span> -&gt; ../../blobs/<span class="hljs-number">403450</span>e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
            \u2514\u2500\u2500 <span class="hljs-selector-attr">[ 128]</span>  bbc77c8132af1cc5cf678da3f1ddf2de43606d48
                \u251C\u2500\u2500 <span class="hljs-selector-attr">[  52]</span>  README<span class="hljs-selector-class">.md</span> -&gt; ../../blobs/<span class="hljs-number">7</span>cb18dc9bafbfcf74629a4b760af1b160957a83e
                \u2514\u2500\u2500 <span class="hljs-selector-attr">[  76]</span>  pytorch_model<span class="hljs-selector-class">.bin</span> -&gt; ../../blobs/<span class="hljs-number">403450</span>e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd`}}),{c(){b=t("meta"),C=d(),_=t("h1"),f=t("a"),g=t("span"),N(u.$$.fragment),v=d(),F=t("span"),M=l("Downloading files"),y=d(),w=t("div"),N(D.$$.fragment),V=d(),k=t("p"),m=l("Download a given file if it\u2019s not already present in the local cache."),E=d(),H=t("p"),J=l("The new cache file layout looks like this:"),U=d(),j=t("ul"),T=t("li"),W=l("The cache directory contains one subfolder per repo_id (namespaced by repo type)"),pe=d(),Q=t("li"),A=l("inside each repo folder:"),$=t("ul"),I=t("li"),oe=l("refs is a list of the latest known revision => commit_hash pairs"),_e=d(),X=t("li"),ve=l(`blobs contains the actual file blobs (identified by their git-sha or sha256, depending on
whether they\u2019re LFS files or not)`),ue=d(),ne=t("li"),ae=l(`snapshots contains one subfolder per commit, each \u201Ccommit\u201D contains the subset of the files
that have been resolved at that particular commit. Each filename is a symlink to the blob
at that particular commit.`),Y=d(),se=t("p"),we=l(`[  96]  .
\u2514\u2500\u2500 [ 160]  models\u2014julien-c\u2014EsperBERTo-small
\u251C\u2500\u2500 [ 160]  blobs
\u2502   \u251C\u2500\u2500 [321M]  403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
\u2502   \u251C\u2500\u2500 [ 398]  7cb18dc9bafbfcf74629a4b760af1b160957a83e
\u2502   \u2514\u2500\u2500 [1.4K]  d7edf6bd2a681fb0175f7735299831ee1b22b812
\u251C\u2500\u2500 [  96]  refs
\u2502   \u2514\u2500\u2500 [  40]  main
\u2514\u2500\u2500 [ 128]  snapshots
\u251C\u2500\u2500 [ 128]  2439f60ef33a0d46d85da5001d52aeda5b00ce9f
\u2502   \u251C\u2500\u2500 [  52]  README.md -> ../../blobs/d7edf6bd2a681fb0175f7735299831ee1b22b812
\u2502   \u2514\u2500\u2500 [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
\u2514\u2500\u2500 [ 128]  bbc77c8132af1cc5cf678da3f1ddf2de43606d48
\u251C\u2500\u2500 [  52]  README.md -> ../../blobs/7cb18dc9bafbfcf74629a4b760af1b160957a83e
\u2514\u2500\u2500 [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd`),Ke=d(),N(G.$$.fragment),me=d(),O=t("div"),N(be.$$.fragment),K=d(),le=t("p"),B=l("Download all files of a repo."),je=d(),Oe=t("p"),co=l(`Downloads a whole snapshot of a repo\u2019s files at the specified revision. This
is useful when you want all files from a repo, because you don\u2019t know which
ones you will need a priori. All files are nested inside a folder in order
to keep their actual filename relative to that folder.`),ho=d(),ke=t("p"),fo=l(`An alternative would be to just clone a repo but this would require that the
user always has git and git-lfs installed, and properly configured.`),po=d(),N(re.$$.fragment),Je=d(),x=t("div"),N(te.$$.fragment),uo=d(),Ne=t("p"),Qe=l("Construct the URL of a file from the given information."),mo=d(),xe=t("p"),bo=l(`The resolved address can either be a huggingface.co-hosted url, or a link to
Cloudfront (a Content Delivery Network, or CDN) for large files which are
more than a few MBs.`),Ya=d(),N(Pe.$$.fragment),Za=d(),N(Re.$$.fragment),et=d(),Co=t("p"),ot=l("References:"),at=d(),Ao=t("ul"),go=t("li"),tt=l("[1] "),Xe=t("a"),nt=l("https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag"),ua=d(),De=t("h2"),Se=t("a"),Io=t("span"),N(Ye.$$.fragment),st=d(),Oo=t("span"),lt=l("Caching"),ma=d(),_o=t("p"),rt=l(`The methods displayed above are designed to work with a caching system that prevents re-downloading files.
The caching system was updated in v0.8.0 to allow directory structure and file sharing across
libraries that depend on the hub.`),ba=d(),vo=t("p"),it=l("The caching system is designed as follows:"),ga=d(),N(Ze.$$.fragment),_a=d(),ie=t("p"),ct=l("The "),No=t("code"),dt=l("<CACHE_DIR>"),ht=l(` is usually your user\u2019s home directory. However, it is customizable with the
`),Po=t("code"),ft=l("cache_dir"),pt=l(" argument on all methods, or by specifying the "),Ro=t("code"),ut=l("HF_HOME"),mt=l(" environment variable."),va=d(),wo=t("p"),bt=l(`Models, datasets and spaces share a common root. Each of these repositories contains the namespace
(organization, username) if it exists, alongside the repository name:`),wa=d(),N(eo.$$.fragment),Ea=d(),Eo=t("p"),gt=l(`It is within these folders that all files will now be downloaded from the hub. Caching ensures that
a file isn\u2019t downloaded twice if it already exists and wasn\u2019t updated; but if it was updated,
and you\u2019re asking for the latest file, then it will download the latest file (while keeping
the previous file intact in case you need it again).`),ya=d(),yo=t("p"),_t=l("In order to achieve this, all folders contain the same skeleton:"),$a=d(),N(oo.$$.fragment),ja=d(),$o=t("p"),vt=l("Each folder is designed to contain the following:"),ka=d(),Te=t("h3"),Le=t("a"),So=t("span"),N(ao.$$.fragment),wt=d(),Lo=t("span"),Et=l("Refs"),xa=d(),Z=t("p"),yt=l("The "),qo=t("code"),$t=l("refs"),jt=l(` folder contains files which indicates the latest revision of the given reference. For example,
if we have previously fetched a file from the `),Fo=t("code"),kt=l("main"),xt=l(" branch of a repository, the "),Mo=t("code"),Dt=l("refs"),Tt=l(`
folder will contain a file named `),Ho=t("code"),Ct=l("main"),At=l(", which will itself contain the commit identifier of the current head."),Da=d(),ce=t("p"),It=l("If the latest commit of "),Uo=t("code"),Ot=l("main"),Nt=l(" has "),Bo=t("code"),Pt=l("aaaaaa"),Rt=l(" as identifier, then it will contain "),zo=t("code"),St=l("aaaaaa"),Lt=l("."),Ta=d(),de=t("p"),qt=l("If that same branch gets updated with a new commit, that has "),Vo=t("code"),Ft=l("bbbbbb"),Mt=l(` as an identifier, then
redownloading a file from that reference will update the `),Wo=t("code"),Ht=l("refs/main"),Ut=l(" file to contain "),Go=t("code"),Bt=l("bbbbbb"),zt=l("."),Ca=d(),Ce=t("h3"),qe=t("a"),Ko=t("span"),N(to.$$.fragment),Vt=d(),Jo=t("span"),Wt=l("Blobs"),Aa=d(),Fe=t("p"),Gt=l("The "),Qo=t("code"),Kt=l("blobs"),Jt=l(" folder contains the actual files that we have downloaded. The name of each file is their hash."),Ia=d(),Ae=t("h3"),Me=t("a"),Xo=t("span"),N(no.$$.fragment),Qt=d(),Yo=t("span"),Xt=l("Snapshots"),Oa=d(),He=t("p"),Yt=l("The "),Zo=t("code"),Zt=l("snapshots"),en=l(` folder contains symlinks to the blobs mentioned above. It is itself made up of several folders:
one per known revision!`),Na=d(),z=t("p"),on=l("In the explanation above, we had initially fetched a file from the "),ea=t("code"),an=l("aaaaaa"),tn=l(` revision, before fetching a file from
the `),oa=t("code"),nn=l("bbbbbb"),sn=l(" revision. In this situation, we would now have two folders in the "),aa=t("code"),ln=l("snapshots"),rn=l(" folder: "),ta=t("code"),cn=l("aaaaaa"),dn=l(`
and `),na=t("code"),hn=l("bbbbbb"),fn=l("."),Pa=d(),Ee=t("p"),pn=l(`In each of these folders, live symlinks that have the names of the files that we have downloaded. For example,
if we had downloaded the `),sa=t("code"),un=l("READMD.md"),mn=l(" file at revision "),la=t("code"),bn=l("aaaaaa"),gn=l(", we would have the following path:"),Ra=d(),N(so.$$.fragment),Sa=d(),Ue=t("p"),_n=l("That "),ra=t("code"),vn=l("README.md"),wn=l(" file is actually a symlink linking to the blob that has the hash of the file."),La=d(),Be=t("p"),En=l(`Creating the skeleton this way means opens up the mechanism to file sharing: if the same file was fetched in
revision `),ia=t("code"),yn=l("bbbbbb"),$n=l(", it would have the same hash and the file would not need to be redownloaded."),qa=d(),Ie=t("h3"),ze=t("a"),ca=t("span"),N(lo.$$.fragment),jn=d(),da=t("span"),kn=l("In practice"),Fa=d(),jo=t("p"),xn=l("In practice, it should look like the following tree in your cache:"),Ma=d(),N(ro.$$.fragment),this.h()},l(o){const i=Hs('[data-svelte="svelte-1phssyn"]',document.head);b=n(i,"META",{name:!0,content:!0}),i.forEach(a),C=h(o),_=n(o,"H1",{class:!0});var io=s(_);f=n(io,"A",{id:!0,class:!0,href:!0});var ha=s(f);g=n(ha,"SPAN",{});var fa=s(g);P(u.$$.fragment,fa),fa.forEach(a),ha.forEach(a),v=h(io),F=n(io,"SPAN",{});var pa=s(F);M=r(pa,"Downloading files"),pa.forEach(a),io.forEach(a),y=h(o),w=n(o,"DIV",{class:!0});var he=s(w);P(D.$$.fragment,he),V=h(he),k=n(he,"P",{});var In=s(k);m=r(In,"Download a given file if it\u2019s not already present in the local cache."),In.forEach(a),E=h(he),H=n(he,"P",{});var On=s(H);J=r(On,"The new cache file layout looks like this:"),On.forEach(a),U=h(he),j=n(he,"UL",{});var Ua=s(j);T=n(Ua,"LI",{});var Nn=s(T);W=r(Nn,"The cache directory contains one subfolder per repo_id (namespaced by repo type)"),Nn.forEach(a),pe=h(Ua),Q=n(Ua,"LI",{});var Dn=s(Q);A=r(Dn,"inside each repo folder:"),$=n(Dn,"UL",{});var ko=s($);I=n(ko,"LI",{});var Pn=s(I);oe=r(Pn,"refs is a list of the latest known revision => commit_hash pairs"),Pn.forEach(a),_e=h(ko),X=n(ko,"LI",{});var Rn=s(X);ve=r(Rn,`blobs contains the actual file blobs (identified by their git-sha or sha256, depending on
whether they\u2019re LFS files or not)`),Rn.forEach(a),ue=h(ko),ne=n(ko,"LI",{});var Sn=s(ne);ae=r(Sn,`snapshots contains one subfolder per commit, each \u201Ccommit\u201D contains the subset of the files
that have been resolved at that particular commit. Each filename is a symlink to the blob
at that particular commit.`),Sn.forEach(a),ko.forEach(a),Dn.forEach(a),Ua.forEach(a),Y=h(he),se=n(he,"P",{});var Ln=s(se);we=r(Ln,`[  96]  .
\u2514\u2500\u2500 [ 160]  models\u2014julien-c\u2014EsperBERTo-small
\u251C\u2500\u2500 [ 160]  blobs
\u2502   \u251C\u2500\u2500 [321M]  403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
\u2502   \u251C\u2500\u2500 [ 398]  7cb18dc9bafbfcf74629a4b760af1b160957a83e
\u2502   \u2514\u2500\u2500 [1.4K]  d7edf6bd2a681fb0175f7735299831ee1b22b812
\u251C\u2500\u2500 [  96]  refs
\u2502   \u2514\u2500\u2500 [  40]  main
\u2514\u2500\u2500 [ 128]  snapshots
\u251C\u2500\u2500 [ 128]  2439f60ef33a0d46d85da5001d52aeda5b00ce9f
\u2502   \u251C\u2500\u2500 [  52]  README.md -> ../../blobs/d7edf6bd2a681fb0175f7735299831ee1b22b812
\u2502   \u2514\u2500\u2500 [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
\u2514\u2500\u2500 [ 128]  bbc77c8132af1cc5cf678da3f1ddf2de43606d48
\u251C\u2500\u2500 [  52]  README.md -> ../../blobs/7cb18dc9bafbfcf74629a4b760af1b160957a83e
\u2514\u2500\u2500 [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd`),Ln.forEach(a),Ke=h(he),P(G.$$.fragment,he),he.forEach(a),me=h(o),O=n(o,"DIV",{class:!0});var ye=s(O);P(be.$$.fragment,ye),K=h(ye),le=n(ye,"P",{});var qn=s(le);B=r(qn,"Download all files of a repo."),qn.forEach(a),je=h(ye),Oe=n(ye,"P",{});var Fn=s(Oe);co=r(Fn,`Downloads a whole snapshot of a repo\u2019s files at the specified revision. This
is useful when you want all files from a repo, because you don\u2019t know which
ones you will need a priori. All files are nested inside a folder in order
to keep their actual filename relative to that folder.`),Fn.forEach(a),ho=h(ye),ke=n(ye,"P",{});var Mn=s(ke);fo=r(Mn,`An alternative would be to just clone a repo but this would require that the
user always has git and git-lfs installed, and properly configured.`),Mn.forEach(a),po=h(ye),P(re.$$.fragment,ye),ye.forEach(a),Je=h(o),x=n(o,"DIV",{class:!0});var ee=s(x);P(te.$$.fragment,ee),uo=h(ee),Ne=n(ee,"P",{});var Hn=s(Ne);Qe=r(Hn,"Construct the URL of a file from the given information."),Hn.forEach(a),mo=h(ee),xe=n(ee,"P",{});var Un=s(xe);bo=r(Un,`The resolved address can either be a huggingface.co-hosted url, or a link to
Cloudfront (a Content Delivery Network, or CDN) for large files which are
more than a few MBs.`),Un.forEach(a),Ya=h(ee),P(Pe.$$.fragment,ee),Za=h(ee),P(Re.$$.fragment,ee),et=h(ee),Co=n(ee,"P",{});var Bn=s(Co);ot=r(Bn,"References:"),Bn.forEach(a),at=h(ee),Ao=n(ee,"UL",{});var zn=s(Ao);go=n(zn,"LI",{});var Tn=s(go);tt=r(Tn,"[1] "),Xe=n(Tn,"A",{href:!0,rel:!0});var Vn=s(Xe);nt=r(Vn,"https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag"),Vn.forEach(a),Tn.forEach(a),zn.forEach(a),ee.forEach(a),ua=h(o),De=n(o,"H2",{class:!0});var Ba=s(De);Se=n(Ba,"A",{id:!0,class:!0,href:!0});var Wn=s(Se);Io=n(Wn,"SPAN",{});var Gn=s(Io);P(Ye.$$.fragment,Gn),Gn.forEach(a),Wn.forEach(a),st=h(Ba),Oo=n(Ba,"SPAN",{});var Kn=s(Oo);lt=r(Kn,"Caching"),Kn.forEach(a),Ba.forEach(a),ma=h(o),_o=n(o,"P",{});var Jn=s(_o);rt=r(Jn,`The methods displayed above are designed to work with a caching system that prevents re-downloading files.
The caching system was updated in v0.8.0 to allow directory structure and file sharing across
libraries that depend on the hub.`),Jn.forEach(a),ba=h(o),vo=n(o,"P",{});var Qn=s(vo);it=r(Qn,"The caching system is designed as follows:"),Qn.forEach(a),ga=h(o),P(Ze.$$.fragment,o),_a=h(o),ie=n(o,"P",{});var Ve=s(ie);ct=r(Ve,"The "),No=n(Ve,"CODE",{});var Xn=s(No);dt=r(Xn,"<CACHE_DIR>"),Xn.forEach(a),ht=r(Ve,` is usually your user\u2019s home directory. However, it is customizable with the
`),Po=n(Ve,"CODE",{});var Yn=s(Po);ft=r(Yn,"cache_dir"),Yn.forEach(a),pt=r(Ve," argument on all methods, or by specifying the "),Ro=n(Ve,"CODE",{});var Zn=s(Ro);ut=r(Zn,"HF_HOME"),Zn.forEach(a),mt=r(Ve," environment variable."),Ve.forEach(a),va=h(o),wo=n(o,"P",{});var es=s(wo);bt=r(es,`Models, datasets and spaces share a common root. Each of these repositories contains the namespace
(organization, username) if it exists, alongside the repository name:`),es.forEach(a),wa=h(o),P(eo.$$.fragment,o),Ea=h(o),Eo=n(o,"P",{});var os=s(Eo);gt=r(os,`It is within these folders that all files will now be downloaded from the hub. Caching ensures that
a file isn\u2019t downloaded twice if it already exists and wasn\u2019t updated; but if it was updated,
and you\u2019re asking for the latest file, then it will download the latest file (while keeping
the previous file intact in case you need it again).`),os.forEach(a),ya=h(o),yo=n(o,"P",{});var as=s(yo);_t=r(as,"In order to achieve this, all folders contain the same skeleton:"),as.forEach(a),$a=h(o),P(oo.$$.fragment,o),ja=h(o),$o=n(o,"P",{});var ts=s($o);vt=r(ts,"Each folder is designed to contain the following:"),ts.forEach(a),ka=h(o),Te=n(o,"H3",{class:!0});var za=s(Te);Le=n(za,"A",{id:!0,class:!0,href:!0});var ns=s(Le);So=n(ns,"SPAN",{});var ss=s(So);P(ao.$$.fragment,ss),ss.forEach(a),ns.forEach(a),wt=h(za),Lo=n(za,"SPAN",{});var ls=s(Lo);Et=r(ls,"Refs"),ls.forEach(a),za.forEach(a),xa=h(o),Z=n(o,"P",{});var $e=s(Z);yt=r($e,"The "),qo=n($e,"CODE",{});var rs=s(qo);$t=r(rs,"refs"),rs.forEach(a),jt=r($e,` folder contains files which indicates the latest revision of the given reference. For example,
if we have previously fetched a file from the `),Fo=n($e,"CODE",{});var is=s(Fo);kt=r(is,"main"),is.forEach(a),xt=r($e," branch of a repository, the "),Mo=n($e,"CODE",{});var cs=s(Mo);Dt=r(cs,"refs"),cs.forEach(a),Tt=r($e,`
folder will contain a file named `),Ho=n($e,"CODE",{});var ds=s(Ho);Ct=r(ds,"main"),ds.forEach(a),At=r($e,", which will itself contain the commit identifier of the current head."),$e.forEach(a),Da=h(o),ce=n(o,"P",{});var We=s(ce);It=r(We,"If the latest commit of "),Uo=n(We,"CODE",{});var hs=s(Uo);Ot=r(hs,"main"),hs.forEach(a),Nt=r(We," has "),Bo=n(We,"CODE",{});var fs=s(Bo);Pt=r(fs,"aaaaaa"),fs.forEach(a),Rt=r(We," as identifier, then it will contain "),zo=n(We,"CODE",{});var ps=s(zo);St=r(ps,"aaaaaa"),ps.forEach(a),Lt=r(We,"."),We.forEach(a),Ta=h(o),de=n(o,"P",{});var Ge=s(de);qt=r(Ge,"If that same branch gets updated with a new commit, that has "),Vo=n(Ge,"CODE",{});var us=s(Vo);Ft=r(us,"bbbbbb"),us.forEach(a),Mt=r(Ge,` as an identifier, then
redownloading a file from that reference will update the `),Wo=n(Ge,"CODE",{});var ms=s(Wo);Ht=r(ms,"refs/main"),ms.forEach(a),Ut=r(Ge," file to contain "),Go=n(Ge,"CODE",{});var bs=s(Go);Bt=r(bs,"bbbbbb"),bs.forEach(a),zt=r(Ge,"."),Ge.forEach(a),Ca=h(o),Ce=n(o,"H3",{class:!0});var Va=s(Ce);qe=n(Va,"A",{id:!0,class:!0,href:!0});var gs=s(qe);Ko=n(gs,"SPAN",{});var _s=s(Ko);P(to.$$.fragment,_s),_s.forEach(a),gs.forEach(a),Vt=h(Va),Jo=n(Va,"SPAN",{});var vs=s(Jo);Wt=r(vs,"Blobs"),vs.forEach(a),Va.forEach(a),Aa=h(o),Fe=n(o,"P",{});var Wa=s(Fe);Gt=r(Wa,"The "),Qo=n(Wa,"CODE",{});var ws=s(Qo);Kt=r(ws,"blobs"),ws.forEach(a),Jt=r(Wa," folder contains the actual files that we have downloaded. The name of each file is their hash."),Wa.forEach(a),Ia=h(o),Ae=n(o,"H3",{class:!0});var Ga=s(Ae);Me=n(Ga,"A",{id:!0,class:!0,href:!0});var Es=s(Me);Xo=n(Es,"SPAN",{});var ys=s(Xo);P(no.$$.fragment,ys),ys.forEach(a),Es.forEach(a),Qt=h(Ga),Yo=n(Ga,"SPAN",{});var $s=s(Yo);Xt=r($s,"Snapshots"),$s.forEach(a),Ga.forEach(a),Oa=h(o),He=n(o,"P",{});var Ka=s(He);Yt=r(Ka,"The "),Zo=n(Ka,"CODE",{});var js=s(Zo);Zt=r(js,"snapshots"),js.forEach(a),en=r(Ka,` folder contains symlinks to the blobs mentioned above. It is itself made up of several folders:
one per known revision!`),Ka.forEach(a),Na=h(o),z=n(o,"P",{});var fe=s(z);on=r(fe,"In the explanation above, we had initially fetched a file from the "),ea=n(fe,"CODE",{});var ks=s(ea);an=r(ks,"aaaaaa"),ks.forEach(a),tn=r(fe,` revision, before fetching a file from
the `),oa=n(fe,"CODE",{});var xs=s(oa);nn=r(xs,"bbbbbb"),xs.forEach(a),sn=r(fe," revision. In this situation, we would now have two folders in the "),aa=n(fe,"CODE",{});var Ds=s(aa);ln=r(Ds,"snapshots"),Ds.forEach(a),rn=r(fe," folder: "),ta=n(fe,"CODE",{});var Ts=s(ta);cn=r(Ts,"aaaaaa"),Ts.forEach(a),dn=r(fe,`
and `),na=n(fe,"CODE",{});var Cs=s(na);hn=r(Cs,"bbbbbb"),Cs.forEach(a),fn=r(fe,"."),fe.forEach(a),Pa=h(o),Ee=n(o,"P",{});var xo=s(Ee);pn=r(xo,`In each of these folders, live symlinks that have the names of the files that we have downloaded. For example,
if we had downloaded the `),sa=n(xo,"CODE",{});var As=s(sa);un=r(As,"READMD.md"),As.forEach(a),mn=r(xo," file at revision "),la=n(xo,"CODE",{});var Is=s(la);bn=r(Is,"aaaaaa"),Is.forEach(a),gn=r(xo,", we would have the following path:"),xo.forEach(a),Ra=h(o),P(so.$$.fragment,o),Sa=h(o),Ue=n(o,"P",{});var Ja=s(Ue);_n=r(Ja,"That "),ra=n(Ja,"CODE",{});var Os=s(ra);vn=r(Os,"README.md"),Os.forEach(a),wn=r(Ja," file is actually a symlink linking to the blob that has the hash of the file."),Ja.forEach(a),La=h(o),Be=n(o,"P",{});var Qa=s(Be);En=r(Qa,`Creating the skeleton this way means opens up the mechanism to file sharing: if the same file was fetched in
revision `),ia=n(Qa,"CODE",{});var Ns=s(ia);yn=r(Ns,"bbbbbb"),Ns.forEach(a),$n=r(Qa,", it would have the same hash and the file would not need to be redownloaded."),Qa.forEach(a),qa=h(o),Ie=n(o,"H3",{class:!0});var Xa=s(Ie);ze=n(Xa,"A",{id:!0,class:!0,href:!0});var Ps=s(ze);ca=n(Ps,"SPAN",{});var Rs=s(ca);P(lo.$$.fragment,Rs),Rs.forEach(a),Ps.forEach(a),jn=h(Xa),da=n(Xa,"SPAN",{});var Ss=s(da);kn=r(Ss,"In practice"),Ss.forEach(a),Xa.forEach(a),Fa=h(o),jo=n(o,"P",{});var Ls=s(jo);xn=r(Ls,"In practice, it should look like the following tree in your cache:"),Ls.forEach(a),Ma=h(o),P(ro.$$.fragment,o),this.h()},h(){p(b,"name","hf:doc:metadata"),p(b,"content",JSON.stringify(Qs)),p(f,"id","huggingface_hub.hf_hub_download"),p(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(f,"href","#huggingface_hub.hf_hub_download"),p(_,"class","relative group"),p(w,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),p(O,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),p(Xe,"href","https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag"),p(Xe,"rel","nofollow"),p(x,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),p(Se,"id","caching"),p(Se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Se,"href","#caching"),p(De,"class","relative group"),p(Le,"id","refs"),p(Le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Le,"href","#refs"),p(Te,"class","relative group"),p(qe,"id","blobs"),p(qe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(qe,"href","#blobs"),p(Ce,"class","relative group"),p(Me,"id","snapshots"),p(Me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Me,"href","#snapshots"),p(Ae,"class","relative group"),p(ze,"id","in-practice"),p(ze,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ze,"href","#in-practice"),p(Ie,"class","relative group")},m(o,i){e(document.head,b),c(o,C,i),c(o,_,i),e(_,f),e(f,g),R(u,g,null),e(_,v),e(_,F),e(F,M),c(o,y,i),c(o,w,i),R(D,w,null),e(w,V),e(w,k),e(k,m),e(w,E),e(w,H),e(H,J),e(w,U),e(w,j),e(j,T),e(T,W),e(j,pe),e(j,Q),e(Q,A),e(Q,$),e($,I),e(I,oe),e($,_e),e($,X),e(X,ve),e($,ue),e($,ne),e(ne,ae),e(w,Y),e(w,se),e(se,we),e(w,Ke),R(G,w,null),c(o,me,i),c(o,O,i),R(be,O,null),e(O,K),e(O,le),e(le,B),e(O,je),e(O,Oe),e(Oe,co),e(O,ho),e(O,ke),e(ke,fo),e(O,po),R(re,O,null),c(o,Je,i),c(o,x,i),R(te,x,null),e(x,uo),e(x,Ne),e(Ne,Qe),e(x,mo),e(x,xe),e(xe,bo),e(x,Ya),R(Pe,x,null),e(x,Za),R(Re,x,null),e(x,et),e(x,Co),e(Co,ot),e(x,at),e(x,Ao),e(Ao,go),e(go,tt),e(go,Xe),e(Xe,nt),c(o,ua,i),c(o,De,i),e(De,Se),e(Se,Io),R(Ye,Io,null),e(De,st),e(De,Oo),e(Oo,lt),c(o,ma,i),c(o,_o,i),e(_o,rt),c(o,ba,i),c(o,vo,i),e(vo,it),c(o,ga,i),R(Ze,o,i),c(o,_a,i),c(o,ie,i),e(ie,ct),e(ie,No),e(No,dt),e(ie,ht),e(ie,Po),e(Po,ft),e(ie,pt),e(ie,Ro),e(Ro,ut),e(ie,mt),c(o,va,i),c(o,wo,i),e(wo,bt),c(o,wa,i),R(eo,o,i),c(o,Ea,i),c(o,Eo,i),e(Eo,gt),c(o,ya,i),c(o,yo,i),e(yo,_t),c(o,$a,i),R(oo,o,i),c(o,ja,i),c(o,$o,i),e($o,vt),c(o,ka,i),c(o,Te,i),e(Te,Le),e(Le,So),R(ao,So,null),e(Te,wt),e(Te,Lo),e(Lo,Et),c(o,xa,i),c(o,Z,i),e(Z,yt),e(Z,qo),e(qo,$t),e(Z,jt),e(Z,Fo),e(Fo,kt),e(Z,xt),e(Z,Mo),e(Mo,Dt),e(Z,Tt),e(Z,Ho),e(Ho,Ct),e(Z,At),c(o,Da,i),c(o,ce,i),e(ce,It),e(ce,Uo),e(Uo,Ot),e(ce,Nt),e(ce,Bo),e(Bo,Pt),e(ce,Rt),e(ce,zo),e(zo,St),e(ce,Lt),c(o,Ta,i),c(o,de,i),e(de,qt),e(de,Vo),e(Vo,Ft),e(de,Mt),e(de,Wo),e(Wo,Ht),e(de,Ut),e(de,Go),e(Go,Bt),e(de,zt),c(o,Ca,i),c(o,Ce,i),e(Ce,qe),e(qe,Ko),R(to,Ko,null),e(Ce,Vt),e(Ce,Jo),e(Jo,Wt),c(o,Aa,i),c(o,Fe,i),e(Fe,Gt),e(Fe,Qo),e(Qo,Kt),e(Fe,Jt),c(o,Ia,i),c(o,Ae,i),e(Ae,Me),e(Me,Xo),R(no,Xo,null),e(Ae,Qt),e(Ae,Yo),e(Yo,Xt),c(o,Oa,i),c(o,He,i),e(He,Yt),e(He,Zo),e(Zo,Zt),e(He,en),c(o,Na,i),c(o,z,i),e(z,on),e(z,ea),e(ea,an),e(z,tn),e(z,oa),e(oa,nn),e(z,sn),e(z,aa),e(aa,ln),e(z,rn),e(z,ta),e(ta,cn),e(z,dn),e(z,na),e(na,hn),e(z,fn),c(o,Pa,i),c(o,Ee,i),e(Ee,pn),e(Ee,sa),e(sa,un),e(Ee,mn),e(Ee,la),e(la,bn),e(Ee,gn),c(o,Ra,i),R(so,o,i),c(o,Sa,i),c(o,Ue,i),e(Ue,_n),e(Ue,ra),e(ra,vn),e(Ue,wn),c(o,La,i),c(o,Be,i),e(Be,En),e(Be,ia),e(ia,yn),e(Be,$n),c(o,qa,i),c(o,Ie,i),e(Ie,ze),e(ze,ca),R(lo,ca,null),e(Ie,jn),e(Ie,da),e(da,kn),c(o,Fa,i),c(o,jo,i),e(jo,xn),c(o,Ma,i),R(ro,o,i),Ha=!0},p(o,[i]){const io={};i&2&&(io.$$scope={dirty:i,ctx:o}),G.$set(io);const ha={};i&2&&(ha.$$scope={dirty:i,ctx:o}),re.$set(ha);const fa={};i&2&&(fa.$$scope={dirty:i,ctx:o}),Pe.$set(fa);const pa={};i&2&&(pa.$$scope={dirty:i,ctx:o}),Re.$set(pa)},i(o){Ha||(S(u.$$.fragment,o),S(D.$$.fragment,o),S(G.$$.fragment,o),S(be.$$.fragment,o),S(re.$$.fragment,o),S(te.$$.fragment,o),S(Pe.$$.fragment,o),S(Re.$$.fragment,o),S(Ye.$$.fragment,o),S(Ze.$$.fragment,o),S(eo.$$.fragment,o),S(oo.$$.fragment,o),S(ao.$$.fragment,o),S(to.$$.fragment,o),S(no.$$.fragment,o),S(so.$$.fragment,o),S(lo.$$.fragment,o),S(ro.$$.fragment,o),Ha=!0)},o(o){L(u.$$.fragment,o),L(D.$$.fragment,o),L(G.$$.fragment,o),L(be.$$.fragment,o),L(re.$$.fragment,o),L(te.$$.fragment,o),L(Pe.$$.fragment,o),L(Re.$$.fragment,o),L(Ye.$$.fragment,o),L(Ze.$$.fragment,o),L(eo.$$.fragment,o),L(oo.$$.fragment,o),L(ao.$$.fragment,o),L(to.$$.fragment,o),L(no.$$.fragment,o),L(so.$$.fragment,o),L(lo.$$.fragment,o),L(ro.$$.fragment,o),Ha=!1},d(o){a(b),o&&a(C),o&&a(_),q(u),o&&a(y),o&&a(w),q(D),q(G),o&&a(me),o&&a(O),q(be),q(re),o&&a(Je),o&&a(x),q(te),q(Pe),q(Re),o&&a(ua),o&&a(De),q(Ye),o&&a(ma),o&&a(_o),o&&a(ba),o&&a(vo),o&&a(ga),q(Ze,o),o&&a(_a),o&&a(ie),o&&a(va),o&&a(wo),o&&a(wa),q(eo,o),o&&a(Ea),o&&a(Eo),o&&a(ya),o&&a(yo),o&&a($a),q(oo,o),o&&a(ja),o&&a($o),o&&a(ka),o&&a(Te),q(ao),o&&a(xa),o&&a(Z),o&&a(Da),o&&a(ce),o&&a(Ta),o&&a(de),o&&a(Ca),o&&a(Ce),q(to),o&&a(Aa),o&&a(Fe),o&&a(Ia),o&&a(Ae),q(no),o&&a(Oa),o&&a(He),o&&a(Na),o&&a(z),o&&a(Pa),o&&a(Ee),o&&a(Ra),q(so,o),o&&a(Sa),o&&a(Ue),o&&a(La),o&&a(Be),o&&a(qa),o&&a(Ie),q(lo),o&&a(Fa),o&&a(jo),o&&a(Ma),q(ro,o)}}}const Qs={local:"huggingface_hub.hf_hub_download",sections:[{local:"caching",sections:[{local:"refs",title:"Refs"},{local:"blobs",title:"Blobs"},{local:"snapshots",title:"Snapshots"},{local:"in-practice",title:"In practice"}],title:"Caching"}],title:"Downloading files"};function Xs(ge){return Us(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class nl extends qs{constructor(b){super();Fs(this,b,Xs,Js,Ms,{})}}export{nl as default,Qs as metadata};
