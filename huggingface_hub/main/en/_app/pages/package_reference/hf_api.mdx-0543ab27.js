import{S as xl,i as Dl,s as ql,e as s,k as l,w as f,t as r,M as Fl,c as n,d as a,m as g,a as o,x as u,h as i,b as c,F as e,g as y,y as m,q as _,o as b,B as v,v as Nl}from"../../chunks/vendor-d3924577.js";import{T as cs}from"../../chunks/Tip-4377bed8.js";import{D}from"../../chunks/Docstring-8a91f8bd.js";import{C as be}from"../../chunks/CodeBlock-ff545b14.js";import{I as pi}from"../../chunks/IconCopyLink-f94c3d80.js";function Pl(J){let p,q,A,w,H,$,j,N,O,F,E,P,T,U,C;return{c(){p=s("p"),q=r("Raises the following errors:"),A=l(),w=s("ul"),H=s("li"),$=s("a"),j=s("code"),N=r("HTTPError"),O=r(`
if the HuggingFace API returned an error`),F=l(),E=s("li"),P=s("a"),T=s("code"),U=r("ValueError"),C=r(`
if some parameter value is invalid`),this.h()},l(x){p=n(x,"P",{});var L=o(p);q=i(L,"Raises the following errors:"),L.forEach(a),A=g(x),w=n(x,"UL",{});var G=o(w);H=n(G,"LI",{});var W=o(H);$=n(W,"A",{href:!0,rel:!0});var de=o($);j=n(de,"CODE",{});var fe=o(j);N=i(fe,"HTTPError"),fe.forEach(a),de.forEach(a),O=i(W,`
if the HuggingFace API returned an error`),W.forEach(a),F=g(G),E=n(G,"LI",{});var Q=o(E);P=n(Q,"A",{href:!0,rel:!0});var X=o(P);T=n(X,"CODE",{});var ue=o(T);U=i(ue,"ValueError"),ue.forEach(a),X.forEach(a),C=i(Q,`
if some parameter value is invalid`),Q.forEach(a),G.forEach(a),this.h()},h(){c($,"href","https://2.python-requests.org/en/master/api/#requests.HTTPError"),c($,"rel","nofollow"),c(P,"href","https://docs.python.org/3/library/exceptions.html#ValueError"),c(P,"rel","nofollow")},m(x,L){y(x,p,L),e(p,q),y(x,A,L),y(x,w,L),e(w,H),e(H,$),e($,j),e(j,N),e(H,O),e(w,F),e(w,E),e(E,P),e(P,T),e(T,U),e(E,C)},d(x){x&&a(p),x&&a(A),x&&a(w)}}}function Ll(J){let p,q,A,w,H;return{c(){p=s("p"),q=r(`Warning: Deprecated, will be removed in v0.7. Please use
`),A=s("a"),w=r("HfApi.set_access_token()"),H=r(" instead."),this.h()},l($){p=n($,"P",{});var j=o(p);q=i(j,`Warning: Deprecated, will be removed in v0.7. Please use
`),A=n(j,"A",{href:!0});var N=o(A);w=i(N,"HfApi.set_access_token()"),N.forEach(a),H=i(j," instead."),j.forEach(a),this.h()},h(){c(A,"href","/docs/huggingface_hub/main/en/package_reference/hf_api#huggingface_hub.HfApi.set_access_token")},m($,j){y($,p,j),e(p,q),e(p,A),e(A,w),e(p,H)},d($){$&&a(p)}}}function Tl(J){let p,q,A,w,H,$,j,N,O;return{c(){p=s("p"),q=r("Raises the following errors:"),A=l(),w=s("ul"),H=s("li"),$=s("a"),j=s("code"),N=r("HTTPError"),O=r(`
if credentials are invalid`),this.h()},l(F){p=n(F,"P",{});var E=o(p);q=i(E,"Raises the following errors:"),E.forEach(a),A=g(F),w=n(F,"UL",{});var P=o(w);H=n(P,"LI",{});var T=o(H);$=n(T,"A",{href:!0,rel:!0});var U=o($);j=n(U,"CODE",{});var C=o(j);N=i(C,"HTTPError"),C.forEach(a),U.forEach(a),O=i(T,`
if credentials are invalid`),T.forEach(a),P.forEach(a),this.h()},h(){c($,"href","https://2.python-requests.org/en/master/api/#requests.HTTPError"),c($,"rel","nofollow")},m(F,E){y(F,p,E),e(p,q),y(F,A,E),y(F,w,E),e(w,H),e(H,$),e($,j),e(j,N),e(H,O)},d(F){F&&a(p),F&&a(A),F&&a(w)}}}function Il(J){let p,q,A,w,H;return{c(){p=s("p"),q=r(`Warning: Deprecated, will be removed in v0.7. Please use
`),A=s("a"),w=r("HfApi.unset_access_token()"),H=r(" instead."),this.h()},l($){p=n($,"P",{});var j=o(p);q=i(j,`Warning: Deprecated, will be removed in v0.7. Please use
`),A=n(j,"A",{href:!0});var N=o(A);w=i(N,"HfApi.unset_access_token()"),N.forEach(a),H=i(j," instead."),j.forEach(a),this.h()},h(){c(A,"href","/docs/huggingface_hub/main/en/package_reference/hf_api#huggingface_hub.HfApi.unset_access_token")},m($,j){y($,p,j),e(p,q),e(p,A),e(A,w),e(p,H)},d($){$&&a(p)}}}function Ml(J){let p,q,A,w,H,$,j,N,O,F,E,P,T,U,C;return{c(){p=s("p"),q=r("Raises the following errors:"),A=l(),w=s("ul"),H=s("li"),$=s("a"),j=s("code"),N=r("HTTPError"),O=r(`
if the HuggingFace API returned an error`),F=l(),E=s("li"),P=s("a"),T=s("code"),U=r("ValueError"),C=r(`
if some parameter value is invalid`),this.h()},l(x){p=n(x,"P",{});var L=o(p);q=i(L,"Raises the following errors:"),L.forEach(a),A=g(x),w=n(x,"UL",{});var G=o(w);H=n(G,"LI",{});var W=o(H);$=n(W,"A",{href:!0,rel:!0});var de=o($);j=n(de,"CODE",{});var fe=o(j);N=i(fe,"HTTPError"),fe.forEach(a),de.forEach(a),O=i(W,`
if the HuggingFace API returned an error`),W.forEach(a),F=g(G),E=n(G,"LI",{});var Q=o(E);P=n(Q,"A",{href:!0,rel:!0});var X=o(P);T=n(X,"CODE",{});var ue=o(T);U=i(ue,"ValueError"),ue.forEach(a),X.forEach(a),C=i(Q,`
if some parameter value is invalid`),Q.forEach(a),G.forEach(a),this.h()},h(){c($,"href","https://2.python-requests.org/en/master/api/#requests.HTTPError"),c($,"rel","nofollow"),c(P,"href","https://docs.python.org/3/library/exceptions.html#ValueError"),c(P,"rel","nofollow")},m(x,L){y(x,p,L),e(p,q),y(x,A,L),y(x,w,L),e(w,H),e(H,$),e($,j),e(j,N),e(H,O),e(w,F),e(w,E),e(E,P),e(P,T),e(T,U),e(E,C)},d(x){x&&a(p),x&&a(A),x&&a(w)}}}function Ol(J){let p,q,A,w,H,$,j,N,O,F,E,P,T,U,C,x,L,G,W,de,fe,Q,X,ue,ps,We,hs,ve,Bs,oa,Ks,Js,ds,Be,fs,$e,Qs,ra,Xs,Ys,us,d,Ke,Zs,Y,Je,en,ia,tn,an,la,sn,nn,ga,Bt,on,Qe,rn,ln,S,Xe,gn,ca,cn,pn,pa,hn,dn,ha,fn,un,da,Kt,mn,Ye,_n,bn,re,Ze,vn,fa,$n,yn,ye,kn,Z,et,wn,ua,An,jn,ma,Hn,En,_a,Jt,xn,tt,Dn,qn,ke,at,Fn,ba,Nn,Pn,we,st,Ln,va,Tn,In,Ae,nt,Mn,$a,On,Un,I,ot,Cn,ya,Sn,zn,rt,Rn,ka,Vn,Gn,Wn,it,Bn,lt,Kn,wa,Jn,Qn,Xn,gt,Yn,je,ct,Zn,Aa,eo,to,M,pt,ao,ja,so,no,ht,oo,Ha,ro,io,lo,dt,go,ft,co,Ea,po,ho,fo,ut,uo,ee,mt,mo,xa,_o,bo,Da,vo,$o,qa,Qt,yo,_t,ko,wo,te,bt,Ao,Fa,jo,Ho,He,Eo,Ee,xo,ie,vt,Do,Na,qo,Fo,xe,No,z,$t,Po,Pa,Lo,To,La,Io,Mo,Ta,Oo,Uo,Ia,Xt,Co,yt,So,zo,R,kt,Ro,Ma,Vo,Go,wt,Wo,At,Bo,Ko,Jo,Oa,Qo,Xo,Ua,Yt,Yo,jt,Zo,er,De,Ht,tr,Ca,ar,sr,qe,Et,nr,Sa,or,rr,ae,xt,ir,za,lr,gr,Ra,cr,pr,Va,Zt,hr,Dt,dr,fr,V,qt,ur,Ga,mr,_r,Fe,br,Wa,vr,$r,Ft,yr,Ne,Nt,kr,Ba,wr,ms,me,Pe,Ka,Pt,Ar,Ja,jr,_s,Lt,Qa,Hr,Er,bs,Le,xr,ea,Dr,qr,vs,B,Tt,Fr,Te,It,Nr,Xa,Pr,Lr,le,Mt,Tr,Ya,Ir,Mr,Ot,Or,Za,Ur,Cr,Sr,Ie,Ut,zr,es,Rr,$s,_e,Me,ts,Ct,Vr,as,Gr,ys,Oe,Wr,ss,Br,Kr,ks,K,St,Jr,ns,Qr,Xr,os,Yr,Zr,zt,ws,oe,Rt,ei,rs,ti,ai,Vt,As;return $=new pi({}),We=new be({props:{code:`from huggingface_hub import list_models

models = list_models()`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> list_models

models = list_models()`}}),Be=new be({props:{code:`from huggingface_hub import HfApi

hf_api = HfApi()
models = hf_api.list_models()`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> HfApi

hf_api = HfApi()
models = hf_api.list_models()`}}),Ke=new D({props:{name:"class huggingface_hub.HfApi",anchor:"huggingface_hub.HfApi",parameters:[{name:"endpoint",val:" = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L474"}}),Je=new D({props:{name:"create_repo",anchor:"huggingface_hub.HfApi.create_repo",parameters:[{name:"repo_id",val:": str = None"},{name:"token",val:": typing.Optional[str] = None"},{name:"organization",val:": typing.Optional[str] = None"},{name:"private",val:": typing.Optional[bool] = None"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"exist_ok",val:": typing.Optional[bool] = False"},{name:"space_sdk",val:": typing.Optional[str] = None"},{name:"name",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1222",parametersDescription:[{anchor:"huggingface_hub.HfApi.create_repo.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
A namespace (user or an organization) and a repo name separated
by a <code>/</code>.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>Version added: 0.5</p>

					</div>`,name:"repo_id"},{anchor:"huggingface_hub.HfApi.create_repo.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An authentication token [1]_.`,name:"token"},{anchor:"huggingface_hub.HfApi.create_repo.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether the model repo should be private.`,name:"private"},{anchor:"huggingface_hub.HfApi.create_repo.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if uploading to a dataset or
space, <code>None</code> or <code>&quot;model&quot;</code> if uploading to a model. Default is
<code>None</code>.`,name:"repo_type"},{anchor:"huggingface_hub.HfApi.create_repo.exist_ok",description:`<strong>exist_ok</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>True</code>, do not raise an error if repo already exists.`,name:"exist_ok"},{anchor:"huggingface_hub.HfApi.create_repo.space_sdk",description:`<strong>space_sdk</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Choice of SDK to use if repo_type is &#x201C;space&#x201D;. Can be
&#x201C;streamlit&#x201D;, &#x201C;gradio&#x201D;, or &#x201C;static&#x201D;.`,name:"space_sdk"}],returnDescription:`
<p>URL to the newly created repo.</p>
`,returnType:`
<p><code>str</code></p>
`}}),Xe=new D({props:{name:"dataset_info",anchor:"huggingface_hub.HfApi.dataset_info",parameters:[{name:"repo_id",val:": str"},{name:"revision",val:": typing.Optional[str] = None"},{name:"token",val:": typing.Optional[str] = None"},{name:"timeout",val:": typing.Optional[float] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1174",parametersDescription:[{anchor:"huggingface_hub.HfApi.dataset_info.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
A namespace (user or an organization) and a repo name separated
by a <code>/</code>.`,name:"repo_id"},{anchor:"huggingface_hub.HfApi.dataset_info.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The revision of the dataset repository from which to get the
information.`,name:"revision"},{anchor:"huggingface_hub.HfApi.dataset_info.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An authentication token [1]_.`,name:"token"},{anchor:"huggingface_hub.HfApi.dataset_info.timeout",description:`<strong>timeout</strong> (<code>float</code>, <em>optional</em>) &#x2014;
Whether to set a timeout for the request to the Hub.`,name:"timeout"}],returnDescription:`
<p>The dataset repository information.</p>
`,returnType:`
<p><code>DatasetInfo</code></p>
`}}),Ze=new D({props:{name:"delete_file",anchor:"huggingface_hub.HfApi.delete_file",parameters:[{name:"path_in_repo",val:": str"},{name:"repo_id",val:": str"},{name:"token",val:": typing.Optional[str] = None"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"revision",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1734",parametersDescription:[{anchor:"huggingface_hub.HfApi.delete_file.path_in_repo",description:`<strong>path_in_repo</strong> (<code>str</code>) &#x2014;
Relative filepath in the repo, for example:
<code>&quot;checkpoints/1fec34a/weights.bin&quot;</code>`,name:"path_in_repo"},{anchor:"huggingface_hub.HfApi.delete_file.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
The repository from which the file will be deleted, for example:
<code>&quot;username/custom_transformers&quot;</code>`,name:"repo_id"},{anchor:"huggingface_hub.HfApi.delete_file.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Authentication token, obtained with <code>HfApi.login</code> method. Will
default to the stored token.`,name:"token"},{anchor:"huggingface_hub.HfApi.delete_file.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if the file is in a dataset or
space, <code>None</code> or <code>&quot;model&quot;</code> if in a model. Default is <code>None</code>.`,name:"repo_type"},{anchor:"huggingface_hub.HfApi.delete_file.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The git revision to commit from. Defaults to the head of the
<code>&quot;main&quot;</code> branch.`,name:"revision"}]}}),ye=new cs({props:{$$slots:{default:[Pl]},$$scope:{ctx:J}}}),et=new D({props:{name:"delete_repo",anchor:"huggingface_hub.HfApi.delete_repo",parameters:[{name:"repo_id",val:": str = None"},{name:"token",val:": typing.Optional[str] = None"},{name:"organization",val:": typing.Optional[str] = None"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"name",val:": str = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1356",parametersDescription:[{anchor:"huggingface_hub.HfApi.delete_repo.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
A namespace (user or an organization) and a repo name separated
by a <code>/</code>.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>Version added: 0.5</p>

					</div>`,name:"repo_id"},{anchor:"huggingface_hub.HfApi.delete_repo.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An authentication token [1]_.`,name:"token"},{anchor:"huggingface_hub.HfApi.delete_repo.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if uploading to a dataset or
space, <code>None</code> or <code>&quot;model&quot;</code> if uploading to a model.`,name:"repo_type"}]}}),at=new D({props:{name:"get_dataset_tags",anchor:"huggingface_hub.HfApi.get_dataset_tags",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L673"}}),st=new D({props:{name:"get_full_repo_name",anchor:"huggingface_hub.HfApi.get_full_repo_name",parameters:[{name:"model_id",val:": str"},{name:"organization",val:": typing.Optional[str] = None"},{name:"token",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1793",parametersDescription:[{anchor:"huggingface_hub.HfApi.get_full_repo_name.model_id",description:`<strong>model_id</strong> (<code>str</code>) &#x2014;
The name of the model.`,name:"model_id"},{anchor:"huggingface_hub.HfApi.get_full_repo_name.organization",description:`<strong>organization</strong> (<code>str</code>, <em>optional</em>) &#x2014;
If passed, the repository name will be in the organization
namespace instead of the user namespace.`,name:"organization"},{anchor:"huggingface_hub.HfApi.get_full_repo_name.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The Hugging Face authentication token`,name:"token"}],returnDescription:`
<p>The repository name in the user\u2019s namespace
({username}/{model_id}) if no organization is passed, and under the
organization namespace ({organization}/{model_id}) otherwise.</p>
`,returnType:`
<p><code>str</code></p>
`}}),nt=new D({props:{name:"get_model_tags",anchor:"huggingface_hub.HfApi.get_model_tags",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L665"}}),ot=new D({props:{name:"list_datasets",anchor:"huggingface_hub.HfApi.list_datasets",parameters:[{name:"filter",val:": typing.Union[huggingface_hub.utils.endpoint_helpers.DatasetFilter, str, typing.Iterable[str], NoneType] = None"},{name:"author",val:": typing.Optional[str] = None"},{name:"search",val:": typing.Optional[str] = None"},{name:"sort",val:": typing.Union[typing.Literal['lastModified'], str, NoneType] = None"},{name:"direction",val:": typing.Optional[typing.Literal[-1]] = None"},{name:"limit",val:": typing.Optional[int] = None"},{name:"cardData",val:": typing.Optional[bool] = None"},{name:"full",val:": typing.Optional[bool] = None"},{name:"use_auth_token",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L891",parametersDescription:[{anchor:"huggingface_hub.HfApi.list_datasets.filter",description:`<strong>filter</strong> (<a href="/docs/huggingface_hub/main/en/package_reference/hf_api#huggingface_hub.DatasetFilter">DatasetFilter</a> or <code>str</code> or <code>Iterable</code>, <em>optional</em>) &#x2014;
A string or <a href="/docs/huggingface_hub/main/en/package_reference/hf_api#huggingface_hub.DatasetFilter">DatasetFilter</a> which can be used to identify
datasets on the hub.`,name:"filter"},{anchor:"huggingface_hub.HfApi.list_datasets.author",description:`<strong>author</strong> (<code>str</code>, <em>optional</em>) &#x2014;
A string which identify the author of the returned models`,name:"author"},{anchor:"huggingface_hub.HfApi.list_datasets.search",description:`<strong>search</strong> (<code>str</code>, <em>optional</em>) &#x2014;
A string that will be contained in the returned models.`,name:"search"},{anchor:"huggingface_hub.HfApi.list_datasets.sort",description:`<strong>sort</strong> (<code>Literal[&quot;lastModified&quot;]</code> or <code>str</code>, <em>optional</em>) &#x2014;
The key with which to sort the resulting datasets. Possible
values are the properties of the <code>DatasetInfo</code> class.`,name:"sort"},{anchor:"huggingface_hub.HfApi.list_datasets.direction",description:`<strong>direction</strong> (<code>Literal[-1]</code> or <code>int</code>, <em>optional</em>) &#x2014;
Direction in which to sort. The value <code>-1</code> sorts by descending
order while all other values sort by ascending order.`,name:"direction"},{anchor:"huggingface_hub.HfApi.list_datasets.limit",description:`<strong>limit</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The limit on the number of datasets fetched. Leaving this option
to <code>None</code> fetches all datasets.`,name:"limit"},{anchor:"huggingface_hub.HfApi.list_datasets.cardData",description:`<strong>cardData</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether to grab the metadata for the dataset as well. Can
contain useful information such as the PapersWithCode ID.`,name:"cardData"},{anchor:"huggingface_hub.HfApi.list_datasets.full",description:`<strong>full</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether to fetch all dataset data, including the <code>lastModified</code>
and the <code>cardData</code>.`,name:"full"},{anchor:"huggingface_hub.HfApi.list_datasets.use_auth_token",description:`<strong>use_auth_token</strong> (<code>bool</code> or <code>str</code>, <em>optional</em>) &#x2014;
Whether to use the <code>auth_token</code> provided from the
<code>huggingface_hub</code> cli. If not logged in, a valid <code>auth_token</code>
can be passed in as a string.`,name:"use_auth_token"}]}}),it=new be({props:{code:`from huggingface_hub import HfApi

api = HfApi()

# List all datasets
api.list_datasets()

# Get all valid search arguments
args = DatasetSearchArguments()

# List only the text classification datasets
api.list_datasets(filter="task_categories:text-classification")
# Using the \`DatasetFilter\`
filt = DatasetFilter(task_categories="text-classification")
# With \`DatasetSearchArguments\`
filt = DatasetFilter(task=args.task_categories.text_classification)
api.list_models(filter=filt)

# List only the datasets in russian for language modeling
api.list_datasets(
    filter=("languages:ru", "task_ids:language-modeling")
)
# Using the \`DatasetFilter\`
filt = DatasetFilter(languages="ru", task_ids="language-modeling")
# With \`DatasetSearchArguments\`
filt = DatasetFilter(
    languages=args.languages.ru,
    task_ids=args.task_ids.language_modeling,
)
api.list_datasets(filter=filt)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> HfApi

<span class="hljs-meta">&gt;&gt;&gt; </span>api = HfApi()

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># List all datasets</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_datasets()

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Get all valid search arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>args = DatasetSearchArguments()

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># List only the text classification datasets</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_datasets(<span class="hljs-built_in">filter</span>=<span class="hljs-string">&quot;task_categories:text-classification&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using the \`DatasetFilter\`</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>filt = DatasetFilter(task_categories=<span class="hljs-string">&quot;text-classification&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># With \`DatasetSearchArguments\`</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>filt = DatasetFilter(task=args.task_categories.text_classification)
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_models(<span class="hljs-built_in">filter</span>=filt)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># List only the datasets in russian for language modeling</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_datasets(
<span class="hljs-meta">... </span>    <span class="hljs-built_in">filter</span>=(<span class="hljs-string">&quot;languages:ru&quot;</span>, <span class="hljs-string">&quot;task_ids:language-modeling&quot;</span>)
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using the \`DatasetFilter\`</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>filt = DatasetFilter(languages=<span class="hljs-string">&quot;ru&quot;</span>, task_ids=<span class="hljs-string">&quot;language-modeling&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># With \`DatasetSearchArguments\`</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>filt = DatasetFilter(
<span class="hljs-meta">... </span>    languages=args.languages.ru,
<span class="hljs-meta">... </span>    task_ids=args.task_ids.language_modeling,
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_datasets(<span class="hljs-built_in">filter</span>=filt)`}}),gt=new be({props:{code:`from huggingface_hub import HfApi

api = HfApi()

# List all datasets with "text" in their name
api.list_datasets(search="text")

# List all datasets with "text" in their name made by google
api.list_datasets(search="text", author="google")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> HfApi

<span class="hljs-meta">&gt;&gt;&gt; </span>api = HfApi()

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># List all datasets with &quot;text&quot; in their name</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_datasets(search=<span class="hljs-string">&quot;text&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># List all datasets with &quot;text&quot; in their name made by google</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_datasets(search=<span class="hljs-string">&quot;text&quot;</span>, author=<span class="hljs-string">&quot;google&quot;</span>)`}}),ct=new D({props:{name:"list_metrics",anchor:"huggingface_hub.HfApi.list_metrics",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1057",returnDescription:`
<p>a list of <code>MetricInfo</code> objects which.</p>
`,returnType:`
<p><code>List[MetricInfo]</code></p>
`}}),pt=new D({props:{name:"list_models",anchor:"huggingface_hub.HfApi.list_models",parameters:[{name:"filter",val:": typing.Union[huggingface_hub.utils.endpoint_helpers.ModelFilter, str, typing.Iterable[str], NoneType] = None"},{name:"author",val:": typing.Optional[str] = None"},{name:"search",val:": typing.Optional[str] = None"},{name:"emissions_thresholds",val:": typing.Union[typing.Tuple[float, float], NoneType] = None"},{name:"sort",val:": typing.Union[typing.Literal['lastModified'], str, NoneType] = None"},{name:"direction",val:": typing.Optional[typing.Literal[-1]] = None"},{name:"limit",val:": typing.Optional[int] = None"},{name:"full",val:": typing.Optional[bool] = None"},{name:"cardData",val:": typing.Optional[bool] = None"},{name:"fetch_config",val:": typing.Optional[bool] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L683",parametersDescription:[{anchor:"huggingface_hub.HfApi.list_models.filter",description:`<strong>filter</strong> (<a href="/docs/huggingface_hub/main/en/package_reference/hf_api#huggingface_hub.ModelFilter">ModelFilter</a> or <code>str</code> or <code>Iterable</code>, <em>optional</em>) &#x2014;
A string or <a href="/docs/huggingface_hub/main/en/package_reference/hf_api#huggingface_hub.ModelFilter">ModelFilter</a> which can be used to identify models
on the Hub.`,name:"filter"},{anchor:"huggingface_hub.HfApi.list_models.author",description:`<strong>author</strong> (<code>str</code>, <em>optional</em>) &#x2014;
A string which identify the author (user or organization) of the
returned models`,name:"author"},{anchor:"huggingface_hub.HfApi.list_models.search",description:`<strong>search</strong> (<code>str</code>, <em>optional</em>) &#x2014;
A string that will be contained in the returned models Example
usage:`,name:"search"},{anchor:"huggingface_hub.HfApi.list_models.emissions_thresholds",description:`<strong>emissions_thresholds</strong> (<code>Tuple</code>, <em>optional</em>) &#x2014;
A tuple of two ints or floats representing a minimum and maximum
carbon footprint to filter the resulting models with in grams.`,name:"emissions_thresholds"},{anchor:"huggingface_hub.HfApi.list_models.sort",description:`<strong>sort</strong> (<code>Literal[&quot;lastModified&quot;]</code> or <code>str</code>, <em>optional</em>) &#x2014;
The key with which to sort the resulting models. Possible values
are the properties of the <code>ModelInfo</code> class.`,name:"sort"},{anchor:"huggingface_hub.HfApi.list_models.direction",description:`<strong>direction</strong> (<code>Literal[-1]</code> or <code>int</code>, <em>optional</em>) &#x2014;
Direction in which to sort. The value <code>-1</code> sorts by descending
order while all other values sort by ascending order.`,name:"direction"},{anchor:"huggingface_hub.HfApi.list_models.limit",description:`<strong>limit</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The limit on the number of models fetched. Leaving this option
to <code>None</code> fetches all models.`,name:"limit"},{anchor:"huggingface_hub.HfApi.list_models.full",description:`<strong>full</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether to fetch all model data, including the <code>lastModified</code>,
the <code>sha</code>, the files and the <code>tags</code>. This is set to <code>True</code> by
default when using a filter.`,name:"full"},{anchor:"huggingface_hub.HfApi.list_models.cardData",description:`<strong>cardData</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether to grab the metadata for the model as well. Can contain
useful information such as carbon emissions, metrics, and
datasets trained on.`,name:"cardData"},{anchor:"huggingface_hub.HfApi.list_models.fetch_config",description:`<strong>fetch_config</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether to fetch the model configs as well. This is not included
in <code>full</code> due to its size.`,name:"fetch_config"},{anchor:"huggingface_hub.HfApi.list_models.use_auth_token",description:`<strong>use_auth_token</strong> (<code>bool</code> or <code>str</code>, <em>optional</em>) &#x2014;
Whether to use the <code>auth_token</code> provided from the
<code>huggingface_hub</code> cli. If not logged in, a valid <code>auth_token</code>
can be passed in as a string.`,name:"use_auth_token"}]}}),dt=new be({props:{code:`from huggingface_hub import HfApi

api = HfApi()

# List all models
api.list_models()

# Get all valid search arguments
args = ModelSearchArguments()

# List only the text classification models
api.list_models(filter="text-classification")
# Using the \`ModelFilter\`
filt = ModelFilter(task="text-classification")
# With \`ModelSearchArguments\`
filt = ModelFilter(task=args.pipeline_tags.TextClassification)
api.list_models(filter=filt)

# Using \`ModelFilter\` and \`ModelSearchArguments\` to find text classification in both PyTorch and TensorFlow
filt = ModelFilter(
    task=args.pipeline_tags.TextClassification,
    library=[args.library.PyTorch, args.library.TensorFlow],
)
api.list_models(filter=filt)

# List only models from the AllenNLP library
api.list_models(filter="allennlp")
# Using \`ModelFilter\` and \`ModelSearchArguments\`
filt = ModelFilter(library=args.library.allennlp)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> HfApi

<span class="hljs-meta">&gt;&gt;&gt; </span>api = HfApi()

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># List all models</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_models()

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Get all valid search arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>args = ModelSearchArguments()

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># List only the text classification models</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_models(<span class="hljs-built_in">filter</span>=<span class="hljs-string">&quot;text-classification&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using the \`ModelFilter\`</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>filt = ModelFilter(task=<span class="hljs-string">&quot;text-classification&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># With \`ModelSearchArguments\`</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>filt = ModelFilter(task=args.pipeline_tags.TextClassification)
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_models(<span class="hljs-built_in">filter</span>=filt)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using \`ModelFilter\` and \`ModelSearchArguments\` to find text classification in both PyTorch and TensorFlow</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>filt = ModelFilter(
<span class="hljs-meta">... </span>    task=args.pipeline_tags.TextClassification,
<span class="hljs-meta">... </span>    library=[args.library.PyTorch, args.library.TensorFlow],
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_models(<span class="hljs-built_in">filter</span>=filt)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># List only models from the AllenNLP library</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_models(<span class="hljs-built_in">filter</span>=<span class="hljs-string">&quot;allennlp&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using \`ModelFilter\` and \`ModelSearchArguments\`</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>filt = ModelFilter(library=args.library.allennlp)`}}),ut=new be({props:{code:`from huggingface_hub import HfApi

api = HfApi()

# List all models with "bert" in their name
api.list_models(search="bert")

# List all models with "bert" in their name made by google
api.list_models(search="bert", author="google")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> HfApi

<span class="hljs-meta">&gt;&gt;&gt; </span>api = HfApi()

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># List all models with &quot;bert&quot; in their name</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_models(search=<span class="hljs-string">&quot;bert&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># List all models with &quot;bert&quot; in their name made by google</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_models(search=<span class="hljs-string">&quot;bert&quot;</span>, author=<span class="hljs-string">&quot;google&quot;</span>)`}}),mt=new D({props:{name:"list_repo_files",anchor:"huggingface_hub.HfApi.list_repo_files",parameters:[{name:"repo_id",val:": str"},{name:"revision",val:": typing.Optional[str] = None"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"token",val:": typing.Optional[str] = None"},{name:"timeout",val:": typing.Optional[float] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1125",parametersDescription:[{anchor:"huggingface_hub.HfApi.list_repo_files.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
A namespace (user or an organization) and a repo name separated
by a <code>/</code>.`,name:"repo_id"},{anchor:"huggingface_hub.HfApi.list_repo_files.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The revision of the model repository from which to get the
information.`,name:"revision"},{anchor:"huggingface_hub.HfApi.list_repo_files.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if uploading to a dataset or
space, <code>None</code> or <code>&quot;model&quot;</code> if uploading to a model. Default is
<code>None</code>.`,name:"repo_type"},{anchor:"huggingface_hub.HfApi.list_repo_files.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An authentication token [1]_.`,name:"token"},{anchor:"huggingface_hub.HfApi.list_repo_files.timeout",description:`<strong>timeout</strong> (<code>float</code>, <em>optional</em>) &#x2014;
Whether to set a timeout for the request to the Hub.`,name:"timeout"}],returnDescription:`
<p>the list of files in a given repository.</p>
`,returnType:`
<p><code>List[str]</code></p>
`}}),bt=new D({props:{name:"login",anchor:"huggingface_hub.HfApi.login",parameters:[{name:"username",val:": str"},{name:"password",val:": str"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L478",parametersDescription:[{anchor:"huggingface_hub.HfApi.login.username",description:`<strong>username</strong> (<code>str</code>) &#x2014;
The username of the account with which to login.`,name:"username"},{anchor:"huggingface_hub.HfApi.login.password",description:`<strong>password</strong> (<code>str</code>) &#x2014;
The password of the account with which to login.`,name:"password"}],returnDescription:`
<p>token if credentials are valid</p>
`,returnType:`
<p><code>str</code></p>
`}}),He=new cs({props:{$$slots:{default:[Ll]},$$scope:{ctx:J}}}),Ee=new cs({props:{$$slots:{default:[Tl]},$$scope:{ctx:J}}}),vt=new D({props:{name:"logout",anchor:"huggingface_hub.HfApi.logout",parameters:[{name:"token",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L610",parametersDescription:[{anchor:"huggingface_hub.HfApi.logout.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Hugging Face token. Will default to the locally saved token if
not provided.`,name:"token"}]}}),xe=new cs({props:{$$slots:{default:[Il]},$$scope:{ctx:J}}}),$t=new D({props:{name:"model_info",anchor:"huggingface_hub.HfApi.model_info",parameters:[{name:"repo_id",val:": str"},{name:"revision",val:": typing.Optional[str] = None"},{name:"token",val:": typing.Optional[str] = None"},{name:"timeout",val:": typing.Optional[float] = None"},{name:"securityStatus",val:": typing.Optional[bool] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1071",parametersDescription:[{anchor:"huggingface_hub.HfApi.model_info.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
A namespace (user or an organization) and a repo name separated
by a <code>/</code>.`,name:"repo_id"},{anchor:"huggingface_hub.HfApi.model_info.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The revision of the model repository from which to get the
information.`,name:"revision"},{anchor:"huggingface_hub.HfApi.model_info.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An authentication token [1]_.`,name:"token"},{anchor:"huggingface_hub.HfApi.model_info.timeout",description:`<strong>timeout</strong> (<code>float</code>, <em>optional</em>) &#x2014;
Whether to set a timeout for the request to the Hub.`,name:"timeout"},{anchor:"huggingface_hub.HfApi.model_info.securityStatus",description:`<strong>securityStatus</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether to retrieve the security status from the model
repository as well.`,name:"securityStatus"}],returnDescription:`
<p>The model repository information.</p>
`,returnType:`
<p><code>ModelInfo</code></p>
`}}),kt=new D({props:{name:"move_repo",anchor:"huggingface_hub.HfApi.move_repo",parameters:[{name:"from_id",val:": str"},{name:"to_id",val:": str"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"token",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1521",parametersDescription:[{anchor:"huggingface_hub.HfApi.move_repo.from_id",description:`<strong>from_id</strong> (<code>str</code>) &#x2014;
A namespace (user or an organization) and a repo name separated
by a <code>/</code>. Original repository identifier.`,name:"from_id"},{anchor:"huggingface_hub.HfApi.move_repo.to_id",description:`<strong>to_id</strong> (<code>str</code>) &#x2014;
A namespace (user or an organization) and a repo name separated
by a <code>/</code>. Final repository identifier.`,name:"to_id"},{anchor:"huggingface_hub.HfApi.move_repo.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if uploading to a dataset or
space, <code>None</code> or <code>&quot;model&quot;</code> if uploading to a model. Default is
<code>None</code>.`,name:"repo_type"},{anchor:"huggingface_hub.HfApi.move_repo.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An authentication token [1]_.`,name:"token"}]}}),Ht=new D({props:{name:"set_access_token",anchor:"huggingface_hub.HfApi.set_access_token",parameters:[{name:"access_token",val:": str"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L646",parametersDescription:[{anchor:"huggingface_hub.HfApi.set_access_token.access_token",description:`<strong>access_token</strong> (<code>str</code>) &#x2014;
The access token to save.`,name:"access_token"}]}}),Et=new D({props:{name:"unset_access_token",anchor:"huggingface_hub.HfApi.unset_access_token",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L658"}}),xt=new D({props:{name:"update_repo_visibility",anchor:"huggingface_hub.HfApi.update_repo_visibility",parameters:[{name:"repo_id",val:": str = None"},{name:"private",val:": bool = False"},{name:"token",val:": typing.Optional[str] = None"},{name:"organization",val:": typing.Optional[str] = None"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"name",val:": str = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1451",parametersDescription:[{anchor:"huggingface_hub.HfApi.update_repo_visibility.repo_id",description:`<strong>repo_id</strong> (<code>str</code>, <em>optional</em>) &#x2014;
A namespace (user or an organization) and a repo name separated
by a <code>/</code>.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>Version added: 0.5</p>

					</div>`,name:"repo_id"},{anchor:"huggingface_hub.HfApi.update_repo_visibility.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether the model repo should be private.`,name:"private"},{anchor:"huggingface_hub.HfApi.update_repo_visibility.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An authentication token [1]_.`,name:"token"},{anchor:"huggingface_hub.HfApi.update_repo_visibility.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if uploading to a dataset or
space, <code>None</code> or <code>&quot;model&quot;</code> if uploading to a model. Default is
<code>None</code>.`,name:"repo_type"}],returnDescription:`
<p>The HTTP response in json.</p>
`}}),qt=new D({props:{name:"upload_file",anchor:"huggingface_hub.HfApi.upload_file",parameters:[{name:"path_or_fileobj",val:": typing.Union[str, bytes, typing.IO]"},{name:"path_in_repo",val:": str"},{name:"repo_id",val:": str"},{name:"token",val:": typing.Optional[str] = None"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"revision",val:": typing.Optional[str] = None"},{name:"identical_ok",val:": bool = True"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1590",parametersDescription:[{anchor:"huggingface_hub.HfApi.upload_file.path_or_fileobj",description:`<strong>path_or_fileobj</strong> (<code>str</code>, <code>bytes</code>, or <code>IO</code>) &#x2014;
Path to a file on the local machine or binary data stream /
fileobj / buffer.`,name:"path_or_fileobj"},{anchor:"huggingface_hub.HfApi.upload_file.path_in_repo",description:`<strong>path_in_repo</strong> (<code>str</code>) &#x2014;
Relative filepath in the repo, for example:
<code>&quot;checkpoints/1fec34a/weights.bin&quot;</code>`,name:"path_in_repo"},{anchor:"huggingface_hub.HfApi.upload_file.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
The repository to which the file will be uploaded, for example:
<code>&quot;username/custom_transformers&quot;</code>`,name:"repo_id"},{anchor:"huggingface_hub.HfApi.upload_file.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Authentication token, obtained with <code>HfApi.login</code> method. Will
default to the stored token.`,name:"token"},{anchor:"huggingface_hub.HfApi.upload_file.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if uploading to a dataset or
space, <code>None</code> or <code>&quot;model&quot;</code> if uploading to a model. Default is
<code>None</code>.`,name:"repo_type"},{anchor:"huggingface_hub.HfApi.upload_file.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The git revision to commit from. Defaults to the head of the
<code>&quot;main&quot;</code> branch.`,name:"revision"},{anchor:"huggingface_hub.HfApi.upload_file.identical_ok",description:`<strong>identical_ok</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
When set to false, will raise an <a href="https://2.python-requests.org/en/master/api/#requests.HTTPError" rel="nofollow">HTTPError</a>
when the file you&#x2019;re trying to upload already exists on the hub
and its content did not change.`,name:"identical_ok"}],returnDescription:`
<p>The URL to visualize the uploaded file on the hub</p>
`,returnType:`
<p><code>str</code></p>
`}}),Fe=new cs({props:{$$slots:{default:[Ml]},$$scope:{ctx:J}}}),Ft=new be({props:{code:`with open("./local/filepath", "rb") as fobj:
    upload_file(
        path_or_fileobj=fileobj,
        path_in_repo="remote/file/path.h5",
        repo_id="username/my-dataset",
        repo_type="datasets",
        token="my_token",
    )

upload_file(
    path_or_fileobj=".\\\\local\\\\file\\\\path",
    path_in_repo="remote/file/path.h5",
    repo_id="username/my-model",
    token="my_token",
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./local/filepath&quot;</span>, <span class="hljs-string">&quot;rb&quot;</span>) <span class="hljs-keyword">as</span> fobj:
<span class="hljs-meta">... </span>    upload_file(
<span class="hljs-meta">... </span>        path_or_fileobj=fileobj,
<span class="hljs-meta">... </span>        path_in_repo=<span class="hljs-string">&quot;remote/file/path.h5&quot;</span>,
<span class="hljs-meta">... </span>        repo_id=<span class="hljs-string">&quot;username/my-dataset&quot;</span>,
<span class="hljs-meta">... </span>        repo_type=<span class="hljs-string">&quot;datasets&quot;</span>,
<span class="hljs-meta">... </span>        token=<span class="hljs-string">&quot;my_token&quot;</span>,
<span class="hljs-meta">... </span>    )
<span class="hljs-string">&quot;https://huggingface.co/datasets/username/my-dataset/blob/main/remote/file/path.h5&quot;</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>upload_file(
<span class="hljs-meta">... </span>    path_or_fileobj=<span class="hljs-string">&quot;.\\\\local\\\\file\\\\path&quot;</span>,
<span class="hljs-meta">... </span>    path_in_repo=<span class="hljs-string">&quot;remote/file/path.h5&quot;</span>,
<span class="hljs-meta">... </span>    repo_id=<span class="hljs-string">&quot;username/my-model&quot;</span>,
<span class="hljs-meta">... </span>    token=<span class="hljs-string">&quot;my_token&quot;</span>,
<span class="hljs-meta">... </span>)
<span class="hljs-string">&quot;https://huggingface.co/username/my-model/blob/main/remote/file/path.h5&quot;</span>`}}),Nt=new D({props:{name:"whoami",anchor:"huggingface_hub.HfApi.whoami",parameters:[{name:"token",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L520",parametersDescription:[{anchor:"huggingface_hub.HfApi.whoami.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Hugging Face token. Will default to the locally saved token if
not provided.`,name:"token"}]}}),Pt=new pi({}),Tt=new D({props:{name:"class huggingface_hub.HfFolder",anchor:"huggingface_hub.HfFolder",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1829"}}),It=new D({props:{name:"delete_token",anchor:"huggingface_hub.HfFolder.delete_token",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1866"}}),Mt=new D({props:{name:"get_token",anchor:"huggingface_hub.HfFolder.get_token",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1845",returnDescription:`
<p>The token, <code>None</code> if it doesn\u2019t exist.</p>
`,returnType:`
<p><code>str</code> or <code>None</code></p>
`}}),Ut=new D({props:{name:"save_token",anchor:"huggingface_hub.HfFolder.save_token",parameters:[{name:"token",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1832",parametersDescription:[{anchor:"huggingface_hub.HfFolder.save_token.token",description:`<strong>token</strong> (<code>str</code>) &#x2014;
The token to save to the <a href="/docs/huggingface_hub/main/en/package_reference/hf_api#huggingface_hub.HfFolder">HfFolder</a>`,name:"token"}]}}),Ct=new pi({}),St=new D({props:{name:"class huggingface_hub.DatasetFilter",anchor:"huggingface_hub.DatasetFilter",parameters:[{name:"author",val:": str = None"},{name:"benchmark",val:": typing.Union[str, typing.List[str]] = None"},{name:"dataset_name",val:": str = None"},{name:"language_creators",val:": typing.Union[str, typing.List[str]] = None"},{name:"languages",val:": typing.Union[str, typing.List[str]] = None"},{name:"multilinguality",val:": typing.Union[str, typing.List[str]] = None"},{name:"size_categories",val:": typing.Union[str, typing.List[str]] = None"},{name:"task_categories",val:": typing.Union[str, typing.List[str]] = None"},{name:"task_ids",val:": typing.Union[str, typing.List[str]] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/utils/endpoint_helpers.py#L67",parametersDescription:[{anchor:"huggingface_hub.DatasetFilter.author",description:`<strong>author</strong> (<code>str</code>, <em>optional</em>) &#x2014;
A string or list of strings that can be used to identify datasets on
the Hub by the original uploader (author or organization), such as
<code>facebook</code> or <code>huggingface</code>.`,name:"author"},{anchor:"huggingface_hub.DatasetFilter.benchmark",description:`<strong>benchmark</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string or list of strings that can be used to identify datasets on
the Hub by their official benchmark.`,name:"benchmark"},{anchor:"huggingface_hub.DatasetFilter.dataset_name",description:`<strong>dataset_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
A string or list of strings that can be used to identify datasets on
the Hub by its name, such as <code>SQAC</code> or <code>wikineural</code>`,name:"dataset_name"},{anchor:"huggingface_hub.DatasetFilter.language_creators",description:`<strong>language_creators</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string or list of strings that can be used to identify datasets on
the Hub with how the data was curated, such as <code>crowdsourced</code> or
<code>machine_generated</code>.`,name:"language_creators"},{anchor:"huggingface_hub.DatasetFilter.languages",description:`<strong>languages</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string or list of strings representing a two-character language to
filter datasets by on the Hub.`,name:"languages"},{anchor:"huggingface_hub.DatasetFilter.multilinguality",description:`<strong>multilinguality</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string or list of strings representing a filter for datasets that
contain multiple languages.`,name:"multilinguality"},{anchor:"huggingface_hub.DatasetFilter.size_categories",description:`<strong>size_categories</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string or list of strings that can be used to identify datasets on
the Hub by the size of the dataset such as <code>100K&lt;n&lt;1M</code> or
<code>1M&lt;n&lt;10M</code>.`,name:"size_categories"},{anchor:"huggingface_hub.DatasetFilter.task_categories",description:`<strong>task_categories</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string or list of strings that can be used to identify datasets on
the Hub by the designed task, such as <code>audio_classification</code> or
<code>named_entity_recognition</code>.`,name:"task_categories"},{anchor:"huggingface_hub.DatasetFilter.task_ids",description:`<strong>task_ids</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string or list of strings that can be used to identify datasets on
the Hub by the specific task such as <code>speech_emotion_recognition</code> or
<code>paraphrase</code>.`,name:"task_ids"}]}}),zt=new be({props:{code:`from huggingface_hub import DatasetFilter

# Using author
new_filter = DatasetFilter(author="facebook")

# Using benchmark
new_filter = DatasetFilter(benchmark="raft")

# Using dataset_name
new_filter = DatasetFilter(dataset_name="wikineural")

# Using language_creator
new_filter = DatasetFilter(language_creator="crowdsourced")

# Using language
new_filter = DatasetFilter(language="en")

# Using multilinguality
new_filter = DatasetFilter(multilinguality="yes")

# Using size_categories
new_filter = DatasetFilter(size_categories="100K<n<1M")

# Using task_categories
new_filter = DatasetFilter(task_categories="audio_classification")

# Using task_ids
new_filter = DatasetFilter(task_ids="paraphrase")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> DatasetFilter

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using author</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = DatasetFilter(author=<span class="hljs-string">&quot;facebook&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using benchmark</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = DatasetFilter(benchmark=<span class="hljs-string">&quot;raft&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using dataset_name</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = DatasetFilter(dataset_name=<span class="hljs-string">&quot;wikineural&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using language_creator</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = DatasetFilter(language_creator=<span class="hljs-string">&quot;crowdsourced&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using language</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = DatasetFilter(language=<span class="hljs-string">&quot;en&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using multilinguality</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = DatasetFilter(multilinguality=<span class="hljs-string">&quot;yes&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using size_categories</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = DatasetFilter(size_categories=<span class="hljs-string">&quot;100K&lt;n&lt;1M&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using task_categories</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = DatasetFilter(task_categories=<span class="hljs-string">&quot;audio_classification&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using task_ids</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = DatasetFilter(task_ids=<span class="hljs-string">&quot;paraphrase&quot;</span>)`}}),Rt=new D({props:{name:"class huggingface_hub.ModelFilter",anchor:"huggingface_hub.ModelFilter",parameters:[{name:"author",val:": str = None"},{name:"library",val:": typing.Union[str, typing.List[str]] = None"},{name:"language",val:": typing.Union[str, typing.List[str]] = None"},{name:"model_name",val:": str = None"},{name:"task",val:": typing.Union[str, typing.List[str]] = None"},{name:"trained_dataset",val:": typing.Union[str, typing.List[str]] = None"},{name:"tags",val:": typing.Union[str, typing.List[str]] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/utils/endpoint_helpers.py#L153",parametersDescription:[{anchor:"huggingface_hub.ModelFilter.author",description:`<strong>author</strong> (<code>str</code>, <em>optional</em>) &#x2014;
A string that can be used to identify models on the Hub by the
original uploader (author or organization), such as <code>facebook</code> or
<code>huggingface</code>.`,name:"author"},{anchor:"huggingface_hub.ModelFilter.library",description:`<strong>library</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string or list of strings of foundational libraries models were
originally trained from, such as pytorch, tensorflow, or allennlp.`,name:"library"},{anchor:"huggingface_hub.ModelFilter.language",description:`<strong>language</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string or list of strings of languages, both by name and country
code, such as &#x201C;en&#x201D; or &#x201C;English&#x201D;`,name:"language"},{anchor:"huggingface_hub.ModelFilter.model_name",description:`<strong>model_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
A string that contain complete or partial names for models on the
Hub, such as &#x201C;bert&#x201D; or &#x201C;bert-base-cased&#x201D;`,name:"model_name"},{anchor:"huggingface_hub.ModelFilter.task",description:`<strong>task</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string or list of strings of tasks models were designed for, such
as: &#x201C;fill-mask&#x201D; or &#x201C;automatic-speech-recognition&#x201D;`,name:"task"},{anchor:"huggingface_hub.ModelFilter.tags",description:`<strong>tags</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string tag or a list of tags to filter models on the Hub by, such
as <code>text-generation</code> or <code>spacy</code>.`,name:"tags"},{anchor:"huggingface_hub.ModelFilter.trained_dataset",description:`<strong>trained_dataset</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string tag or a list of string tags of the trained dataset for a
model on the Hub.`,name:"trained_dataset"}]}}),Vt=new be({props:{code:`from huggingface_hub import ModelFilter

# For the author_or_organization
new_filter = ModelFilter(author_or_organization="facebook")

# For the library
new_filter = ModelFilter(library="pytorch")

# For the language
new_filter = ModelFilter(language="french")

# For the model_name
new_filter = ModelFilter(model_name="bert")

# For the task
new_filter = ModelFilter(task="text-classification")

# Retrieving tags using the \`HfApi.get_model_tags\` method
from huggingface_hub import HfApi

api = HfApi()

api.get_model_tags()

api.get_dataset_tags()
new_filter = ModelFilter(tags="benchmark:raft")

# Related to the dataset
new_filter = ModelFilter(trained_dataset="common_voice")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> ModelFilter

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># For the author_or_organization</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = ModelFilter(author_or_organization=<span class="hljs-string">&quot;facebook&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># For the library</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = ModelFilter(library=<span class="hljs-string">&quot;pytorch&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># For the language</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = ModelFilter(language=<span class="hljs-string">&quot;french&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># For the model_name</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = ModelFilter(model_name=<span class="hljs-string">&quot;bert&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># For the task</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = ModelFilter(task=<span class="hljs-string">&quot;text-classification&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Retrieving tags using the \`HfApi.get_model_tags\` method</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> HfApi

<span class="hljs-meta">&gt;&gt;&gt; </span>api = HfApi()
<span class="hljs-comment"># To list model tags</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>api.get_model_tags()
<span class="hljs-comment"># To list dataset tags</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>api.get_dataset_tags()
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = ModelFilter(tags=<span class="hljs-string">&quot;benchmark:raft&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Related to the dataset</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = ModelFilter(trained_dataset=<span class="hljs-string">&quot;common_voice&quot;</span>)`}}),{c(){p=s("meta"),q=l(),A=s("h1"),w=s("a"),H=s("span"),f($.$$.fragment),j=l(),N=s("span"),O=r("Hugging Face Hub API"),F=l(),E=s("p"),P=r("Below is the documentation for the "),T=s("code"),U=r("HfApi"),C=r(` class, which serves as a Python wrapper for the Hugging Face
Hub\u2019s API.`),x=l(),L=s("p"),G=r("All methods from the "),W=s("code"),de=r("HfApi"),fe=r(` are also accessible from the package\u2019s root directly, both approaches are detailed
below.`),Q=l(),X=s("p"),ue=r("The following approach uses the method from the root of the package:"),ps=l(),f(We.$$.fragment),hs=l(),ve=s("p"),Bs=r("The following approach uses the "),oa=s("code"),Ks=r("HfApi"),Js=r(" class:"),ds=l(),f(Be.$$.fragment),fs=l(),$e=s("p"),Qs=r("Using the "),ra=s("code"),Xs=r("HfApi"),Ys=r(" class directly enables you to set a different endpoint to that of the Hugging Face\u2019s Hub."),us=l(),d=s("div"),f(Ke.$$.fragment),Zs=l(),Y=s("div"),f(Je.$$.fragment),en=l(),ia=s("p"),tn=r("Create an empty repo on the HuggingFace Hub."),an=l(),la=s("p"),sn=r("References:"),nn=l(),ga=s("ul"),Bt=s("li"),on=r("[1] "),Qe=s("a"),rn=r("https://huggingface.co/settings/tokens"),ln=l(),S=s("div"),f(Xe.$$.fragment),gn=l(),ca=s("p"),cn=r("Get info on one specific dataset on huggingface.co"),pn=l(),pa=s("p"),hn=r("Dataset can be private if you pass an acceptable token."),dn=l(),ha=s("p"),fn=r("References:"),un=l(),da=s("ul"),Kt=s("li"),mn=r("[1] "),Ye=s("a"),_n=r("https://huggingface.co/settings/tokens"),bn=l(),re=s("div"),f(Ze.$$.fragment),vn=l(),fa=s("p"),$n=r("Deletes a file in the given repo."),yn=l(),f(ye.$$.fragment),kn=l(),Z=s("div"),f(et.$$.fragment),wn=l(),ua=s("p"),An=r("Delete a repo from the HuggingFace Hub. CAUTION: this is irreversible."),jn=l(),ma=s("p"),Hn=r("References:"),En=l(),_a=s("ul"),Jt=s("li"),xn=r("[1] "),tt=s("a"),Dn=r("https://huggingface.co/settings/tokens"),qn=l(),ke=s("div"),f(at.$$.fragment),Fn=l(),ba=s("p"),Nn=r("Gets all valid dataset tags as a nested namespace object."),Pn=l(),we=s("div"),f(st.$$.fragment),Ln=l(),va=s("p"),Tn=r(`Returns the repository name for a given model ID and optional
organization.`),In=l(),Ae=s("div"),f(nt.$$.fragment),Mn=l(),$a=s("p"),On=r("Gets all valid model tags as a nested namespace object"),Un=l(),I=s("div"),f(ot.$$.fragment),Cn=l(),ya=s("p"),Sn=r("Get the public list of all the datasets on huggingface.co"),zn=l(),rt=s("p"),Rn=r("Example usage with the "),ka=s("code"),Vn=r("filter"),Gn=r(" argument:"),Wn=l(),f(it.$$.fragment),Bn=l(),lt=s("p"),Kn=r("Example usage with the "),wa=s("code"),Jn=r("search"),Qn=r(" argument:"),Xn=l(),f(gt.$$.fragment),Yn=l(),je=s("div"),f(ct.$$.fragment),Zn=l(),Aa=s("p"),eo=r("Get the public list of all the metrics on huggingface.co"),to=l(),M=s("div"),f(pt.$$.fragment),ao=l(),ja=s("p"),so=r("Get the public list of all the models on huggingface.co"),no=l(),ht=s("p"),oo=r("Example usage with the "),Ha=s("code"),ro=r("filter"),io=r(" argument:"),lo=l(),f(dt.$$.fragment),go=l(),ft=s("p"),co=r("Example usage with the "),Ea=s("code"),po=r("search"),ho=r(" argument:"),fo=l(),f(ut.$$.fragment),uo=l(),ee=s("div"),f(mt.$$.fragment),mo=l(),xa=s("p"),_o=r("Get the list of files in a given repo."),bo=l(),Da=s("p"),vo=r("References:"),$o=l(),qa=s("ul"),Qt=s("li"),yo=r("[1] "),_t=s("a"),ko=r("https://huggingface.co/settings/tokens"),wo=l(),te=s("div"),f(bt.$$.fragment),Ao=l(),Fa=s("p"),jo=r("Call HF API to sign in a user and get a token if credentials are valid."),Ho=l(),f(He.$$.fragment),Eo=l(),f(Ee.$$.fragment),xo=l(),ie=s("div"),f(vt.$$.fragment),Do=l(),Na=s("p"),qo=r("Call HF API to log out."),Fo=l(),f(xe.$$.fragment),No=l(),z=s("div"),f($t.$$.fragment),Po=l(),Pa=s("p"),Lo=r("Get info on one specific model on huggingface.co"),To=l(),La=s("p"),Io=r("Model can be private if you pass an acceptable token or are logged in."),Mo=l(),Ta=s("p"),Oo=r("References:"),Uo=l(),Ia=s("ul"),Xt=s("li"),Co=r("[1] "),yt=s("a"),So=r("https://huggingface.co/settings/tokens"),zo=l(),R=s("div"),f(kt.$$.fragment),Ro=l(),Ma=s("p"),Vo=r("Moving a repository from namespace1/repo_name1 to namespace2/repo_name2"),Go=l(),wt=s("p"),Wo=r(`Note there are certain limitations. For more information about moving
repositories, please see
`),At=s("a"),Bo=r("https://hf.co/docs/hub/main#how-can-i-rename-or-transfer-a-repo"),Ko=r("."),Jo=l(),Oa=s("p"),Qo=r("References:"),Xo=l(),Ua=s("ul"),Yt=s("li"),Yo=r("[1] "),jt=s("a"),Zo=r("https://huggingface.co/settings/tokens"),er=l(),De=s("div"),f(Ht.$$.fragment),tr=l(),Ca=s("p"),ar=r(`Saves the passed access token so git can correctly authenticate the
user.`),sr=l(),qe=s("div"),f(Et.$$.fragment),nr=l(),Sa=s("p"),or=r("Resets the user\u2019s access token."),rr=l(),ae=s("div"),f(xt.$$.fragment),ir=l(),za=s("p"),lr=r("Update the visibility setting of a repository."),gr=l(),Ra=s("p"),cr=r("References:"),pr=l(),Va=s("ul"),Zt=s("li"),hr=r("[1] "),Dt=s("a"),dr=r("https://huggingface.co/settings/tokens"),fr=l(),V=s("div"),f(qt.$$.fragment),ur=l(),Ga=s("p"),mr=r(`Upload a local file (up to 5GB) to the given repo. The upload is done
through a HTTP post request, and doesn\u2019t require git or git-lfs to be
installed.`),_r=l(),f(Fe.$$.fragment),br=l(),Wa=s("p"),vr=r("Example usage:"),$r=l(),f(Ft.$$.fragment),yr=l(),Ne=s("div"),f(Nt.$$.fragment),kr=l(),Ba=s("p"),wr=r("Call HF API to know \u201Cwhoami\u201D."),ms=l(),me=s("h2"),Pe=s("a"),Ka=s("span"),f(Pt.$$.fragment),Ar=l(),Ja=s("span"),jr=r("Hugging Face local storage"),_s=l(),Lt=s("p"),Qa=s("code"),Hr=r("huggingface_hub"),Er=r(` stores the authentication information locally so that it may be re-used in subsequent
methods.`),bs=l(),Le=s("p"),xr=r("It does this using the "),ea=s("a"),Dr=r("HfFolder"),qr=r(" utility, which saves data at the root of the user."),vs=l(),B=s("div"),f(Tt.$$.fragment),Fr=l(),Te=s("div"),f(It.$$.fragment),Nr=l(),Xa=s("p"),Pr=r("Deletes the token from storage. Does not fail if token does not exist."),Lr=l(),le=s("div"),f(Mt.$$.fragment),Tr=l(),Ya=s("p"),Ir=r("Get token or None if not existent."),Mr=l(),Ot=s("p"),Or=r("Note that a token can be also provided using the "),Za=s("code"),Ur=r("HUGGING_FACE_HUB_TOKEN"),Cr=r(`
environment variable.`),Sr=l(),Ie=s("div"),f(Ut.$$.fragment),zr=l(),es=s("p"),Rr=r("Save token, creating folder as needed."),$s=l(),_e=s("h2"),Me=s("a"),ts=s("span"),f(Ct.$$.fragment),Vr=l(),as=s("span"),Gr=r("Filtering helpers"),ys=l(),Oe=s("p"),Wr=r("Some helpers to filter repositories on the Hub are available in the "),ss=s("code"),Br=r("huggingface_hub"),Kr=r(" package."),ks=l(),K=s("div"),f(St.$$.fragment),Jr=l(),ns=s("p"),Qr=r(`A class that converts human-readable dataset search parameters into ones
compatible with the REST API. For all parameters capitalization does not
matter.`),Xr=l(),os=s("p"),Yr=r("Examples:"),Zr=l(),f(zt.$$.fragment),ws=l(),oe=s("div"),f(Rt.$$.fragment),ei=l(),rs=s("p"),ti=r(`A class that converts human-readable model search parameters into ones
compatible with the REST API. For all parameters capitalization does not
matter.`),ai=l(),f(Vt.$$.fragment),this.h()},l(t){const h=Fl('[data-svelte="svelte-1phssyn"]',document.head);p=n(h,"META",{name:!0,content:!0}),h.forEach(a),q=g(t),A=n(t,"H1",{class:!0});var Gt=o(A);w=n(Gt,"A",{id:!0,class:!0,href:!0});var is=o(w);H=n(is,"SPAN",{});var ls=o(H);u($.$$.fragment,ls),ls.forEach(a),is.forEach(a),j=g(Gt),N=n(Gt,"SPAN",{});var gs=o(N);O=i(gs,"Hugging Face Hub API"),gs.forEach(a),Gt.forEach(a),F=g(t),E=n(t,"P",{});var Wt=o(E);P=i(Wt,"Below is the documentation for the "),T=n(Wt,"CODE",{});var hi=o(T);U=i(hi,"HfApi"),hi.forEach(a),C=i(Wt,` class, which serves as a Python wrapper for the Hugging Face
Hub\u2019s API.`),Wt.forEach(a),x=g(t),L=n(t,"P",{});var js=o(L);G=i(js,"All methods from the "),W=n(js,"CODE",{});var di=o(W);de=i(di,"HfApi"),di.forEach(a),fe=i(js,` are also accessible from the package\u2019s root directly, both approaches are detailed
below.`),js.forEach(a),Q=g(t),X=n(t,"P",{});var fi=o(X);ue=i(fi,"The following approach uses the method from the root of the package:"),fi.forEach(a),ps=g(t),u(We.$$.fragment,t),hs=g(t),ve=n(t,"P",{});var Hs=o(ve);Bs=i(Hs,"The following approach uses the "),oa=n(Hs,"CODE",{});var ui=o(oa);Ks=i(ui,"HfApi"),ui.forEach(a),Js=i(Hs," class:"),Hs.forEach(a),ds=g(t),u(Be.$$.fragment,t),fs=g(t),$e=n(t,"P",{});var Es=o($e);Qs=i(Es,"Using the "),ra=n(Es,"CODE",{});var mi=o(ra);Xs=i(mi,"HfApi"),mi.forEach(a),Ys=i(Es," class directly enables you to set a different endpoint to that of the Hugging Face\u2019s Hub."),Es.forEach(a),us=g(t),d=n(t,"DIV",{class:!0});var k=o(d);u(Ke.$$.fragment,k),Zs=g(k),Y=n(k,"DIV",{class:!0});var Ue=o(Y);u(Je.$$.fragment,Ue),en=g(Ue),ia=n(Ue,"P",{});var _i=o(ia);tn=i(_i,"Create an empty repo on the HuggingFace Hub."),_i.forEach(a),an=g(Ue),la=n(Ue,"P",{});var bi=o(la);sn=i(bi,"References:"),bi.forEach(a),nn=g(Ue),ga=n(Ue,"UL",{});var vi=o(ga);Bt=n(vi,"LI",{});var si=o(Bt);on=i(si,"[1] "),Qe=n(si,"A",{href:!0,rel:!0});var $i=o(Qe);rn=i($i,"https://huggingface.co/settings/tokens"),$i.forEach(a),si.forEach(a),vi.forEach(a),Ue.forEach(a),ln=g(k),S=n(k,"DIV",{class:!0});var ge=o(S);u(Xe.$$.fragment,ge),gn=g(ge),ca=n(ge,"P",{});var yi=o(ca);cn=i(yi,"Get info on one specific dataset on huggingface.co"),yi.forEach(a),pn=g(ge),pa=n(ge,"P",{});var ki=o(pa);hn=i(ki,"Dataset can be private if you pass an acceptable token."),ki.forEach(a),dn=g(ge),ha=n(ge,"P",{});var wi=o(ha);fn=i(wi,"References:"),wi.forEach(a),un=g(ge),da=n(ge,"UL",{});var Ai=o(da);Kt=n(Ai,"LI",{});var ni=o(Kt);mn=i(ni,"[1] "),Ye=n(ni,"A",{href:!0,rel:!0});var ji=o(Ye);_n=i(ji,"https://huggingface.co/settings/tokens"),ji.forEach(a),ni.forEach(a),Ai.forEach(a),ge.forEach(a),bn=g(k),re=n(k,"DIV",{class:!0});var ta=o(re);u(Ze.$$.fragment,ta),vn=g(ta),fa=n(ta,"P",{});var Hi=o(fa);$n=i(Hi,"Deletes a file in the given repo."),Hi.forEach(a),yn=g(ta),u(ye.$$.fragment,ta),ta.forEach(a),kn=g(k),Z=n(k,"DIV",{class:!0});var Ce=o(Z);u(et.$$.fragment,Ce),wn=g(Ce),ua=n(Ce,"P",{});var Ei=o(ua);An=i(Ei,"Delete a repo from the HuggingFace Hub. CAUTION: this is irreversible."),Ei.forEach(a),jn=g(Ce),ma=n(Ce,"P",{});var xi=o(ma);Hn=i(xi,"References:"),xi.forEach(a),En=g(Ce),_a=n(Ce,"UL",{});var Di=o(_a);Jt=n(Di,"LI",{});var oi=o(Jt);xn=i(oi,"[1] "),tt=n(oi,"A",{href:!0,rel:!0});var qi=o(tt);Dn=i(qi,"https://huggingface.co/settings/tokens"),qi.forEach(a),oi.forEach(a),Di.forEach(a),Ce.forEach(a),qn=g(k),ke=n(k,"DIV",{class:!0});var xs=o(ke);u(at.$$.fragment,xs),Fn=g(xs),ba=n(xs,"P",{});var Fi=o(ba);Nn=i(Fi,"Gets all valid dataset tags as a nested namespace object."),Fi.forEach(a),xs.forEach(a),Pn=g(k),we=n(k,"DIV",{class:!0});var Ds=o(we);u(st.$$.fragment,Ds),Ln=g(Ds),va=n(Ds,"P",{});var Ni=o(va);Tn=i(Ni,`Returns the repository name for a given model ID and optional
organization.`),Ni.forEach(a),Ds.forEach(a),In=g(k),Ae=n(k,"DIV",{class:!0});var qs=o(Ae);u(nt.$$.fragment,qs),Mn=g(qs),$a=n(qs,"P",{});var Pi=o($a);On=i(Pi,"Gets all valid model tags as a nested namespace object"),Pi.forEach(a),qs.forEach(a),Un=g(k),I=n(k,"DIV",{class:!0});var se=o(I);u(ot.$$.fragment,se),Cn=g(se),ya=n(se,"P",{});var Li=o(ya);Sn=i(Li,"Get the public list of all the datasets on huggingface.co"),Li.forEach(a),zn=g(se),rt=n(se,"P",{});var Fs=o(rt);Rn=i(Fs,"Example usage with the "),ka=n(Fs,"CODE",{});var Ti=o(ka);Vn=i(Ti,"filter"),Ti.forEach(a),Gn=i(Fs," argument:"),Fs.forEach(a),Wn=g(se),u(it.$$.fragment,se),Bn=g(se),lt=n(se,"P",{});var Ns=o(lt);Kn=i(Ns,"Example usage with the "),wa=n(Ns,"CODE",{});var Ii=o(wa);Jn=i(Ii,"search"),Ii.forEach(a),Qn=i(Ns," argument:"),Ns.forEach(a),Xn=g(se),u(gt.$$.fragment,se),se.forEach(a),Yn=g(k),je=n(k,"DIV",{class:!0});var Ps=o(je);u(ct.$$.fragment,Ps),Zn=g(Ps),Aa=n(Ps,"P",{});var Mi=o(Aa);eo=i(Mi,"Get the public list of all the metrics on huggingface.co"),Mi.forEach(a),Ps.forEach(a),to=g(k),M=n(k,"DIV",{class:!0});var ne=o(M);u(pt.$$.fragment,ne),ao=g(ne),ja=n(ne,"P",{});var Oi=o(ja);so=i(Oi,"Get the public list of all the models on huggingface.co"),Oi.forEach(a),no=g(ne),ht=n(ne,"P",{});var Ls=o(ht);oo=i(Ls,"Example usage with the "),Ha=n(Ls,"CODE",{});var Ui=o(Ha);ro=i(Ui,"filter"),Ui.forEach(a),io=i(Ls," argument:"),Ls.forEach(a),lo=g(ne),u(dt.$$.fragment,ne),go=g(ne),ft=n(ne,"P",{});var Ts=o(ft);co=i(Ts,"Example usage with the "),Ea=n(Ts,"CODE",{});var Ci=o(Ea);po=i(Ci,"search"),Ci.forEach(a),ho=i(Ts," argument:"),Ts.forEach(a),fo=g(ne),u(ut.$$.fragment,ne),ne.forEach(a),uo=g(k),ee=n(k,"DIV",{class:!0});var Se=o(ee);u(mt.$$.fragment,Se),mo=g(Se),xa=n(Se,"P",{});var Si=o(xa);_o=i(Si,"Get the list of files in a given repo."),Si.forEach(a),bo=g(Se),Da=n(Se,"P",{});var zi=o(Da);vo=i(zi,"References:"),zi.forEach(a),$o=g(Se),qa=n(Se,"UL",{});var Ri=o(qa);Qt=n(Ri,"LI",{});var ri=o(Qt);yo=i(ri,"[1] "),_t=n(ri,"A",{href:!0,rel:!0});var Vi=o(_t);ko=i(Vi,"https://huggingface.co/settings/tokens"),Vi.forEach(a),ri.forEach(a),Ri.forEach(a),Se.forEach(a),wo=g(k),te=n(k,"DIV",{class:!0});var ze=o(te);u(bt.$$.fragment,ze),Ao=g(ze),Fa=n(ze,"P",{});var Gi=o(Fa);jo=i(Gi,"Call HF API to sign in a user and get a token if credentials are valid."),Gi.forEach(a),Ho=g(ze),u(He.$$.fragment,ze),Eo=g(ze),u(Ee.$$.fragment,ze),ze.forEach(a),xo=g(k),ie=n(k,"DIV",{class:!0});var aa=o(ie);u(vt.$$.fragment,aa),Do=g(aa),Na=n(aa,"P",{});var Wi=o(Na);qo=i(Wi,"Call HF API to log out."),Wi.forEach(a),Fo=g(aa),u(xe.$$.fragment,aa),aa.forEach(a),No=g(k),z=n(k,"DIV",{class:!0});var ce=o(z);u($t.$$.fragment,ce),Po=g(ce),Pa=n(ce,"P",{});var Bi=o(Pa);Lo=i(Bi,"Get info on one specific model on huggingface.co"),Bi.forEach(a),To=g(ce),La=n(ce,"P",{});var Ki=o(La);Io=i(Ki,"Model can be private if you pass an acceptable token or are logged in."),Ki.forEach(a),Mo=g(ce),Ta=n(ce,"P",{});var Ji=o(Ta);Oo=i(Ji,"References:"),Ji.forEach(a),Uo=g(ce),Ia=n(ce,"UL",{});var Qi=o(Ia);Xt=n(Qi,"LI",{});var ii=o(Xt);Co=i(ii,"[1] "),yt=n(ii,"A",{href:!0,rel:!0});var Xi=o(yt);So=i(Xi,"https://huggingface.co/settings/tokens"),Xi.forEach(a),ii.forEach(a),Qi.forEach(a),ce.forEach(a),zo=g(k),R=n(k,"DIV",{class:!0});var pe=o(R);u(kt.$$.fragment,pe),Ro=g(pe),Ma=n(pe,"P",{});var Yi=o(Ma);Vo=i(Yi,"Moving a repository from namespace1/repo_name1 to namespace2/repo_name2"),Yi.forEach(a),Go=g(pe),wt=n(pe,"P",{});var Is=o(wt);Wo=i(Is,`Note there are certain limitations. For more information about moving
repositories, please see
`),At=n(Is,"A",{href:!0,rel:!0});var Zi=o(At);Bo=i(Zi,"https://hf.co/docs/hub/main#how-can-i-rename-or-transfer-a-repo"),Zi.forEach(a),Ko=i(Is,"."),Is.forEach(a),Jo=g(pe),Oa=n(pe,"P",{});var el=o(Oa);Qo=i(el,"References:"),el.forEach(a),Xo=g(pe),Ua=n(pe,"UL",{});var tl=o(Ua);Yt=n(tl,"LI",{});var li=o(Yt);Yo=i(li,"[1] "),jt=n(li,"A",{href:!0,rel:!0});var al=o(jt);Zo=i(al,"https://huggingface.co/settings/tokens"),al.forEach(a),li.forEach(a),tl.forEach(a),pe.forEach(a),er=g(k),De=n(k,"DIV",{class:!0});var Ms=o(De);u(Ht.$$.fragment,Ms),tr=g(Ms),Ca=n(Ms,"P",{});var sl=o(Ca);ar=i(sl,`Saves the passed access token so git can correctly authenticate the
user.`),sl.forEach(a),Ms.forEach(a),sr=g(k),qe=n(k,"DIV",{class:!0});var Os=o(qe);u(Et.$$.fragment,Os),nr=g(Os),Sa=n(Os,"P",{});var nl=o(Sa);or=i(nl,"Resets the user\u2019s access token."),nl.forEach(a),Os.forEach(a),rr=g(k),ae=n(k,"DIV",{class:!0});var Re=o(ae);u(xt.$$.fragment,Re),ir=g(Re),za=n(Re,"P",{});var ol=o(za);lr=i(ol,"Update the visibility setting of a repository."),ol.forEach(a),gr=g(Re),Ra=n(Re,"P",{});var rl=o(Ra);cr=i(rl,"References:"),rl.forEach(a),pr=g(Re),Va=n(Re,"UL",{});var il=o(Va);Zt=n(il,"LI",{});var gi=o(Zt);hr=i(gi,"[1] "),Dt=n(gi,"A",{href:!0,rel:!0});var ll=o(Dt);dr=i(ll,"https://huggingface.co/settings/tokens"),ll.forEach(a),gi.forEach(a),il.forEach(a),Re.forEach(a),fr=g(k),V=n(k,"DIV",{class:!0});var he=o(V);u(qt.$$.fragment,he),ur=g(he),Ga=n(he,"P",{});var gl=o(Ga);mr=i(gl,`Upload a local file (up to 5GB) to the given repo. The upload is done
through a HTTP post request, and doesn\u2019t require git or git-lfs to be
installed.`),gl.forEach(a),_r=g(he),u(Fe.$$.fragment,he),br=g(he),Wa=n(he,"P",{});var cl=o(Wa);vr=i(cl,"Example usage:"),cl.forEach(a),$r=g(he),u(Ft.$$.fragment,he),he.forEach(a),yr=g(k),Ne=n(k,"DIV",{class:!0});var Us=o(Ne);u(Nt.$$.fragment,Us),kr=g(Us),Ba=n(Us,"P",{});var pl=o(Ba);wr=i(pl,"Call HF API to know \u201Cwhoami\u201D."),pl.forEach(a),Us.forEach(a),k.forEach(a),ms=g(t),me=n(t,"H2",{class:!0});var Cs=o(me);Pe=n(Cs,"A",{id:!0,class:!0,href:!0});var hl=o(Pe);Ka=n(hl,"SPAN",{});var dl=o(Ka);u(Pt.$$.fragment,dl),dl.forEach(a),hl.forEach(a),Ar=g(Cs),Ja=n(Cs,"SPAN",{});var fl=o(Ja);jr=i(fl,"Hugging Face local storage"),fl.forEach(a),Cs.forEach(a),_s=g(t),Lt=n(t,"P",{});var ci=o(Lt);Qa=n(ci,"CODE",{});var ul=o(Qa);Hr=i(ul,"huggingface_hub"),ul.forEach(a),Er=i(ci,` stores the authentication information locally so that it may be re-used in subsequent
methods.`),ci.forEach(a),bs=g(t),Le=n(t,"P",{});var Ss=o(Le);xr=i(Ss,"It does this using the "),ea=n(Ss,"A",{href:!0});var ml=o(ea);Dr=i(ml,"HfFolder"),ml.forEach(a),qr=i(Ss," utility, which saves data at the root of the user."),Ss.forEach(a),vs=g(t),B=n(t,"DIV",{class:!0});var Ve=o(B);u(Tt.$$.fragment,Ve),Fr=g(Ve),Te=n(Ve,"DIV",{class:!0});var zs=o(Te);u(It.$$.fragment,zs),Nr=g(zs),Xa=n(zs,"P",{});var _l=o(Xa);Pr=i(_l,"Deletes the token from storage. Does not fail if token does not exist."),_l.forEach(a),zs.forEach(a),Lr=g(Ve),le=n(Ve,"DIV",{class:!0});var sa=o(le);u(Mt.$$.fragment,sa),Tr=g(sa),Ya=n(sa,"P",{});var bl=o(Ya);Ir=i(bl,"Get token or None if not existent."),bl.forEach(a),Mr=g(sa),Ot=n(sa,"P",{});var Rs=o(Ot);Or=i(Rs,"Note that a token can be also provided using the "),Za=n(Rs,"CODE",{});var vl=o(Za);Ur=i(vl,"HUGGING_FACE_HUB_TOKEN"),vl.forEach(a),Cr=i(Rs,`
environment variable.`),Rs.forEach(a),sa.forEach(a),Sr=g(Ve),Ie=n(Ve,"DIV",{class:!0});var Vs=o(Ie);u(Ut.$$.fragment,Vs),zr=g(Vs),es=n(Vs,"P",{});var $l=o(es);Rr=i($l,"Save token, creating folder as needed."),$l.forEach(a),Vs.forEach(a),Ve.forEach(a),$s=g(t),_e=n(t,"H2",{class:!0});var Gs=o(_e);Me=n(Gs,"A",{id:!0,class:!0,href:!0});var yl=o(Me);ts=n(yl,"SPAN",{});var kl=o(ts);u(Ct.$$.fragment,kl),kl.forEach(a),yl.forEach(a),Vr=g(Gs),as=n(Gs,"SPAN",{});var wl=o(as);Gr=i(wl,"Filtering helpers"),wl.forEach(a),Gs.forEach(a),ys=g(t),Oe=n(t,"P",{});var Ws=o(Oe);Wr=i(Ws,"Some helpers to filter repositories on the Hub are available in the "),ss=n(Ws,"CODE",{});var Al=o(ss);Br=i(Al,"huggingface_hub"),Al.forEach(a),Kr=i(Ws," package."),Ws.forEach(a),ks=g(t),K=n(t,"DIV",{class:!0});var Ge=o(K);u(St.$$.fragment,Ge),Jr=g(Ge),ns=n(Ge,"P",{});var jl=o(ns);Qr=i(jl,`A class that converts human-readable dataset search parameters into ones
compatible with the REST API. For all parameters capitalization does not
matter.`),jl.forEach(a),Xr=g(Ge),os=n(Ge,"P",{});var Hl=o(os);Yr=i(Hl,"Examples:"),Hl.forEach(a),Zr=g(Ge),u(zt.$$.fragment,Ge),Ge.forEach(a),ws=g(t),oe=n(t,"DIV",{class:!0});var na=o(oe);u(Rt.$$.fragment,na),ei=g(na),rs=n(na,"P",{});var El=o(rs);ti=i(El,`A class that converts human-readable model search parameters into ones
compatible with the REST API. For all parameters capitalization does not
matter.`),El.forEach(a),ai=g(na),u(Vt.$$.fragment,na),na.forEach(a),this.h()},h(){c(p,"name","hf:doc:metadata"),c(p,"content",JSON.stringify(Ul)),c(w,"id","huggingface_hub.HfApi"),c(w,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(w,"href","#huggingface_hub.HfApi"),c(A,"class","relative group"),c(Qe,"href","https://huggingface.co/settings/tokens"),c(Qe,"rel","nofollow"),c(Y,"class","docstring"),c(Ye,"href","https://huggingface.co/settings/tokens"),c(Ye,"rel","nofollow"),c(S,"class","docstring"),c(re,"class","docstring"),c(tt,"href","https://huggingface.co/settings/tokens"),c(tt,"rel","nofollow"),c(Z,"class","docstring"),c(ke,"class","docstring"),c(we,"class","docstring"),c(Ae,"class","docstring"),c(I,"class","docstring"),c(je,"class","docstring"),c(M,"class","docstring"),c(_t,"href","https://huggingface.co/settings/tokens"),c(_t,"rel","nofollow"),c(ee,"class","docstring"),c(te,"class","docstring"),c(ie,"class","docstring"),c(yt,"href","https://huggingface.co/settings/tokens"),c(yt,"rel","nofollow"),c(z,"class","docstring"),c(At,"href","https://hf.co/docs/hub/main#how-can-i-rename-or-transfer-a-repo"),c(At,"rel","nofollow"),c(jt,"href","https://huggingface.co/settings/tokens"),c(jt,"rel","nofollow"),c(R,"class","docstring"),c(De,"class","docstring"),c(qe,"class","docstring"),c(Dt,"href","https://huggingface.co/settings/tokens"),c(Dt,"rel","nofollow"),c(ae,"class","docstring"),c(V,"class","docstring"),c(Ne,"class","docstring"),c(d,"class","docstring"),c(Pe,"id","huggingface_hub.HfFolder"),c(Pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Pe,"href","#huggingface_hub.HfFolder"),c(me,"class","relative group"),c(ea,"href","/docs/huggingface_hub/main/en/package_reference/hf_api#huggingface_hub.HfFolder"),c(Te,"class","docstring"),c(le,"class","docstring"),c(Ie,"class","docstring"),c(B,"class","docstring"),c(Me,"id","huggingface_hub.DatasetFilter"),c(Me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Me,"href","#huggingface_hub.DatasetFilter"),c(_e,"class","relative group"),c(K,"class","docstring"),c(oe,"class","docstring")},m(t,h){e(document.head,p),y(t,q,h),y(t,A,h),e(A,w),e(w,H),m($,H,null),e(A,j),e(A,N),e(N,O),y(t,F,h),y(t,E,h),e(E,P),e(E,T),e(T,U),e(E,C),y(t,x,h),y(t,L,h),e(L,G),e(L,W),e(W,de),e(L,fe),y(t,Q,h),y(t,X,h),e(X,ue),y(t,ps,h),m(We,t,h),y(t,hs,h),y(t,ve,h),e(ve,Bs),e(ve,oa),e(oa,Ks),e(ve,Js),y(t,ds,h),m(Be,t,h),y(t,fs,h),y(t,$e,h),e($e,Qs),e($e,ra),e(ra,Xs),e($e,Ys),y(t,us,h),y(t,d,h),m(Ke,d,null),e(d,Zs),e(d,Y),m(Je,Y,null),e(Y,en),e(Y,ia),e(ia,tn),e(Y,an),e(Y,la),e(la,sn),e(Y,nn),e(Y,ga),e(ga,Bt),e(Bt,on),e(Bt,Qe),e(Qe,rn),e(d,ln),e(d,S),m(Xe,S,null),e(S,gn),e(S,ca),e(ca,cn),e(S,pn),e(S,pa),e(pa,hn),e(S,dn),e(S,ha),e(ha,fn),e(S,un),e(S,da),e(da,Kt),e(Kt,mn),e(Kt,Ye),e(Ye,_n),e(d,bn),e(d,re),m(Ze,re,null),e(re,vn),e(re,fa),e(fa,$n),e(re,yn),m(ye,re,null),e(d,kn),e(d,Z),m(et,Z,null),e(Z,wn),e(Z,ua),e(ua,An),e(Z,jn),e(Z,ma),e(ma,Hn),e(Z,En),e(Z,_a),e(_a,Jt),e(Jt,xn),e(Jt,tt),e(tt,Dn),e(d,qn),e(d,ke),m(at,ke,null),e(ke,Fn),e(ke,ba),e(ba,Nn),e(d,Pn),e(d,we),m(st,we,null),e(we,Ln),e(we,va),e(va,Tn),e(d,In),e(d,Ae),m(nt,Ae,null),e(Ae,Mn),e(Ae,$a),e($a,On),e(d,Un),e(d,I),m(ot,I,null),e(I,Cn),e(I,ya),e(ya,Sn),e(I,zn),e(I,rt),e(rt,Rn),e(rt,ka),e(ka,Vn),e(rt,Gn),e(I,Wn),m(it,I,null),e(I,Bn),e(I,lt),e(lt,Kn),e(lt,wa),e(wa,Jn),e(lt,Qn),e(I,Xn),m(gt,I,null),e(d,Yn),e(d,je),m(ct,je,null),e(je,Zn),e(je,Aa),e(Aa,eo),e(d,to),e(d,M),m(pt,M,null),e(M,ao),e(M,ja),e(ja,so),e(M,no),e(M,ht),e(ht,oo),e(ht,Ha),e(Ha,ro),e(ht,io),e(M,lo),m(dt,M,null),e(M,go),e(M,ft),e(ft,co),e(ft,Ea),e(Ea,po),e(ft,ho),e(M,fo),m(ut,M,null),e(d,uo),e(d,ee),m(mt,ee,null),e(ee,mo),e(ee,xa),e(xa,_o),e(ee,bo),e(ee,Da),e(Da,vo),e(ee,$o),e(ee,qa),e(qa,Qt),e(Qt,yo),e(Qt,_t),e(_t,ko),e(d,wo),e(d,te),m(bt,te,null),e(te,Ao),e(te,Fa),e(Fa,jo),e(te,Ho),m(He,te,null),e(te,Eo),m(Ee,te,null),e(d,xo),e(d,ie),m(vt,ie,null),e(ie,Do),e(ie,Na),e(Na,qo),e(ie,Fo),m(xe,ie,null),e(d,No),e(d,z),m($t,z,null),e(z,Po),e(z,Pa),e(Pa,Lo),e(z,To),e(z,La),e(La,Io),e(z,Mo),e(z,Ta),e(Ta,Oo),e(z,Uo),e(z,Ia),e(Ia,Xt),e(Xt,Co),e(Xt,yt),e(yt,So),e(d,zo),e(d,R),m(kt,R,null),e(R,Ro),e(R,Ma),e(Ma,Vo),e(R,Go),e(R,wt),e(wt,Wo),e(wt,At),e(At,Bo),e(wt,Ko),e(R,Jo),e(R,Oa),e(Oa,Qo),e(R,Xo),e(R,Ua),e(Ua,Yt),e(Yt,Yo),e(Yt,jt),e(jt,Zo),e(d,er),e(d,De),m(Ht,De,null),e(De,tr),e(De,Ca),e(Ca,ar),e(d,sr),e(d,qe),m(Et,qe,null),e(qe,nr),e(qe,Sa),e(Sa,or),e(d,rr),e(d,ae),m(xt,ae,null),e(ae,ir),e(ae,za),e(za,lr),e(ae,gr),e(ae,Ra),e(Ra,cr),e(ae,pr),e(ae,Va),e(Va,Zt),e(Zt,hr),e(Zt,Dt),e(Dt,dr),e(d,fr),e(d,V),m(qt,V,null),e(V,ur),e(V,Ga),e(Ga,mr),e(V,_r),m(Fe,V,null),e(V,br),e(V,Wa),e(Wa,vr),e(V,$r),m(Ft,V,null),e(d,yr),e(d,Ne),m(Nt,Ne,null),e(Ne,kr),e(Ne,Ba),e(Ba,wr),y(t,ms,h),y(t,me,h),e(me,Pe),e(Pe,Ka),m(Pt,Ka,null),e(me,Ar),e(me,Ja),e(Ja,jr),y(t,_s,h),y(t,Lt,h),e(Lt,Qa),e(Qa,Hr),e(Lt,Er),y(t,bs,h),y(t,Le,h),e(Le,xr),e(Le,ea),e(ea,Dr),e(Le,qr),y(t,vs,h),y(t,B,h),m(Tt,B,null),e(B,Fr),e(B,Te),m(It,Te,null),e(Te,Nr),e(Te,Xa),e(Xa,Pr),e(B,Lr),e(B,le),m(Mt,le,null),e(le,Tr),e(le,Ya),e(Ya,Ir),e(le,Mr),e(le,Ot),e(Ot,Or),e(Ot,Za),e(Za,Ur),e(Ot,Cr),e(B,Sr),e(B,Ie),m(Ut,Ie,null),e(Ie,zr),e(Ie,es),e(es,Rr),y(t,$s,h),y(t,_e,h),e(_e,Me),e(Me,ts),m(Ct,ts,null),e(_e,Vr),e(_e,as),e(as,Gr),y(t,ys,h),y(t,Oe,h),e(Oe,Wr),e(Oe,ss),e(ss,Br),e(Oe,Kr),y(t,ks,h),y(t,K,h),m(St,K,null),e(K,Jr),e(K,ns),e(ns,Qr),e(K,Xr),e(K,os),e(os,Yr),e(K,Zr),m(zt,K,null),y(t,ws,h),y(t,oe,h),m(Rt,oe,null),e(oe,ei),e(oe,rs),e(rs,ti),e(oe,ai),m(Vt,oe,null),As=!0},p(t,[h]){const Gt={};h&2&&(Gt.$$scope={dirty:h,ctx:t}),ye.$set(Gt);const is={};h&2&&(is.$$scope={dirty:h,ctx:t}),He.$set(is);const ls={};h&2&&(ls.$$scope={dirty:h,ctx:t}),Ee.$set(ls);const gs={};h&2&&(gs.$$scope={dirty:h,ctx:t}),xe.$set(gs);const Wt={};h&2&&(Wt.$$scope={dirty:h,ctx:t}),Fe.$set(Wt)},i(t){As||(_($.$$.fragment,t),_(We.$$.fragment,t),_(Be.$$.fragment,t),_(Ke.$$.fragment,t),_(Je.$$.fragment,t),_(Xe.$$.fragment,t),_(Ze.$$.fragment,t),_(ye.$$.fragment,t),_(et.$$.fragment,t),_(at.$$.fragment,t),_(st.$$.fragment,t),_(nt.$$.fragment,t),_(ot.$$.fragment,t),_(it.$$.fragment,t),_(gt.$$.fragment,t),_(ct.$$.fragment,t),_(pt.$$.fragment,t),_(dt.$$.fragment,t),_(ut.$$.fragment,t),_(mt.$$.fragment,t),_(bt.$$.fragment,t),_(He.$$.fragment,t),_(Ee.$$.fragment,t),_(vt.$$.fragment,t),_(xe.$$.fragment,t),_($t.$$.fragment,t),_(kt.$$.fragment,t),_(Ht.$$.fragment,t),_(Et.$$.fragment,t),_(xt.$$.fragment,t),_(qt.$$.fragment,t),_(Fe.$$.fragment,t),_(Ft.$$.fragment,t),_(Nt.$$.fragment,t),_(Pt.$$.fragment,t),_(Tt.$$.fragment,t),_(It.$$.fragment,t),_(Mt.$$.fragment,t),_(Ut.$$.fragment,t),_(Ct.$$.fragment,t),_(St.$$.fragment,t),_(zt.$$.fragment,t),_(Rt.$$.fragment,t),_(Vt.$$.fragment,t),As=!0)},o(t){b($.$$.fragment,t),b(We.$$.fragment,t),b(Be.$$.fragment,t),b(Ke.$$.fragment,t),b(Je.$$.fragment,t),b(Xe.$$.fragment,t),b(Ze.$$.fragment,t),b(ye.$$.fragment,t),b(et.$$.fragment,t),b(at.$$.fragment,t),b(st.$$.fragment,t),b(nt.$$.fragment,t),b(ot.$$.fragment,t),b(it.$$.fragment,t),b(gt.$$.fragment,t),b(ct.$$.fragment,t),b(pt.$$.fragment,t),b(dt.$$.fragment,t),b(ut.$$.fragment,t),b(mt.$$.fragment,t),b(bt.$$.fragment,t),b(He.$$.fragment,t),b(Ee.$$.fragment,t),b(vt.$$.fragment,t),b(xe.$$.fragment,t),b($t.$$.fragment,t),b(kt.$$.fragment,t),b(Ht.$$.fragment,t),b(Et.$$.fragment,t),b(xt.$$.fragment,t),b(qt.$$.fragment,t),b(Fe.$$.fragment,t),b(Ft.$$.fragment,t),b(Nt.$$.fragment,t),b(Pt.$$.fragment,t),b(Tt.$$.fragment,t),b(It.$$.fragment,t),b(Mt.$$.fragment,t),b(Ut.$$.fragment,t),b(Ct.$$.fragment,t),b(St.$$.fragment,t),b(zt.$$.fragment,t),b(Rt.$$.fragment,t),b(Vt.$$.fragment,t),As=!1},d(t){a(p),t&&a(q),t&&a(A),v($),t&&a(F),t&&a(E),t&&a(x),t&&a(L),t&&a(Q),t&&a(X),t&&a(ps),v(We,t),t&&a(hs),t&&a(ve),t&&a(ds),v(Be,t),t&&a(fs),t&&a($e),t&&a(us),t&&a(d),v(Ke),v(Je),v(Xe),v(Ze),v(ye),v(et),v(at),v(st),v(nt),v(ot),v(it),v(gt),v(ct),v(pt),v(dt),v(ut),v(mt),v(bt),v(He),v(Ee),v(vt),v(xe),v($t),v(kt),v(Ht),v(Et),v(xt),v(qt),v(Fe),v(Ft),v(Nt),t&&a(ms),t&&a(me),v(Pt),t&&a(_s),t&&a(Lt),t&&a(bs),t&&a(Le),t&&a(vs),t&&a(B),v(Tt),v(It),v(Mt),v(Ut),t&&a($s),t&&a(_e),v(Ct),t&&a(ys),t&&a(Oe),t&&a(ks),t&&a(K),v(St),v(zt),t&&a(ws),t&&a(oe),v(Rt),v(Vt)}}}const Ul={local:"huggingface_hub.HfApi",sections:[{local:"huggingface_hub.HfFolder",title:"Hugging Face local storage"},{local:"huggingface_hub.DatasetFilter",title:"Filtering helpers"}],title:"Hugging Face Hub API"};function Cl(J){return Nl(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Wl extends xl{constructor(p){super();Dl(this,p,Cl,Ol,ql,{})}}export{Wl as default,Ul as metadata};
