import{S as At,i as Ct,s as qt,e as n,k as d,w as v,t as i,M as Lt,c as a,d as t,m as l,a as r,x as y,h as s,b as g,F as e,g as u,y as w,q as x,o as k,B as $,v as Ft}from"../../chunks/vendor-d3924577.js";import{T as It}from"../../chunks/Tip-4377bed8.js";import{D as Y}from"../../chunks/Docstring-6e765b82.js";import{I as so}from"../../chunks/IconCopyLink-f94c3d80.js";function Ut(he){let h,T,m,f,M;return{c(){h=n("p"),T=i("Passing "),m=n("code"),f=i("use_auth_token=True"),M=i(` is required when you want to use a
private model.`)},l(p){h=a(p,"P",{});var _=r(h);T=s(_,"Passing "),m=a(_,"CODE",{});var E=r(m);f=s(E,"use_auth_token=True"),E.forEach(t),M=s(_,` is required when you want to use a
private model.`),_.forEach(t)},m(p,_){u(p,h,_),e(h,T),e(h,m),e(m,f),e(h,M)},d(p){p&&t(h)}}}function Kt(he){let h,T,m,f,M;return{c(){h=n("p"),T=i("Passing "),m=n("code"),f=i("use_auth_token=True"),M=i(` is required when you want to use a private
model.`)},l(p){h=a(p,"P",{});var _=r(h);T=s(_,"Passing "),m=a(_,"CODE",{});var E=r(m);f=s(E,"use_auth_token=True"),E.forEach(t),M=s(_,` is required when you want to use a private
model.`),_.forEach(t)},m(p,_){u(p,h,_),e(h,T),e(h,m),e(m,f),e(h,M)},d(p){p&&t(h)}}}function Wt(he){let h,T,m,f,M,p,_,E,lo,Fe,N,L,fe,J,co,be,ho,Ue,F,go,ve,uo,mo,Ke,S,U,ye,Q,po,we,_o,We,b,X,fo,H,bo,xe,vo,yo,ke,wo,xo,$e,ko,$o,Mo,O,Z,To,I,Eo,Me,Ho,zo,Te,Po,Oo,Do,K,No,W,ee,So,oe,Io,Ee,Ao,Co,qo,V,te,Lo,He,Fo,Ve,A,j,ze,ne,Uo,Pe,Ko,je,z,ae,Wo,Oe,Vo,jo,B,Be,C,re,Bo,ie,Ro,De,Go,Yo,Re,q,se,Jo,Ne,Qo,Ge,P,de,Xo,Se,Zo,et,le,ge,Ie,ot,tt,nt,R,Ae,at,rt,Ce,it,st,Ye;return p=new so({}),J=new so({}),Q=new so({}),X=new Y({props:{name:"class huggingface_hub.ModelHubMixin",anchor:"huggingface_hub.ModelHubMixin",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hub_mixin.py#L22"}}),Z=new Y({props:{name:"from_pretrained",anchor:"huggingface_hub.ModelHubMixin.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:": str"},{name:"force_download",val:": bool = False"},{name:"resume_download",val:": bool = False"},{name:"proxies",val:": typing.Dict = None"},{name:"use_auth_token",val:": typing.Optional[str] = None"},{name:"cache_dir",val:": typing.Optional[str] = None"},{name:"local_files_only",val:": bool = False"},{name:"**model_kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:<ul>
<li>A string, the <code>model id</code> of a pretrained model
hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level,
like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like
<code>dbmdz/bert-base-german-cased</code>.</li>
<li>You can add <code>revision</code> by appending <code>@</code> at the end
of model_id simply like this:
<code>dbmdz/bert-base-german-cased@main</code> Revision is
the specific model version to use. It can be a
branch name, a tag name, or a commit id, since we
use a git-based system for storing models and
other artifacts on huggingface.co, so <code>revision</code>
can be any identifier allowed by git.</li>
<li>A path to a <code>directory</code> containing model weights
saved using
<code>save_pretrained</code>,
e.g., <code>./my_model_directory/</code>.</li>
<li><code>None</code> if you are both providing the configuration
and state dictionary (resp. with keyword arguments
<code>config</code> and <code>state_dict</code>).</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to force the (re-)download of the model weights
and configuration files, overriding the cached versions
if they exist.`,name:"force_download"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to delete incompletely received files. Will
attempt to resume the download if such a file exists.`,name:"resume_download"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or
endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are
used on each request.`,name:"proxies"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote
files. If <code>True</code>, will use the token generated when
running <code>transformers-cli login</code> (stored in
<code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>Union[str, os.PathLike]</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained
model configuration should be cached if the standard
cache should not be used.`,name:"cache_dir"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to only look at local files (i.e., do not try to
download the model).`,name:"local_files_only(bool,"},{anchor:"huggingface_hub.ModelHubMixin.from_pretrained.model_kwargs",description:`<strong>model_kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
model_kwargs will be passed to the model during
initialization`,name:"model_kwargs"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hub_mixin.py#L73"}}),K=new It({props:{$$slots:{default:[Ut]},$$scope:{ctx:he}}}),ee=new Y({props:{name:"push_to_hub",anchor:"huggingface_hub.ModelHubMixin.push_to_hub",parameters:[{name:"repo_path_or_name",val:": typing.Optional[str] = None"},{name:"repo_url",val:": typing.Optional[str] = None"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"organization",val:": typing.Optional[str] = None"},{name:"private",val:": typing.Optional[bool] = None"},{name:"api_endpoint",val:": typing.Optional[str] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = None"},{name:"git_user",val:": typing.Optional[str] = None"},{name:"git_email",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"}],parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.repo_path_or_name",description:`<strong>repo_path_or_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Can either be a repository name for your model or tokenizer in
the Hub or a path to a local folder (in which case the
repository will have the name of that local folder). If not
specified, will default to the name given by <code>repo_url</code> and a
local directory with that name will be created.`,name:"repo_path_or_name"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.repo_url",description:`<strong>repo_url</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Specify this in case you want to push to an existing repository
in the hub. If unspecified, a new repository will be created in
your namespace (unless you specify an <code>organization</code>) with
<code>repo_name</code>.`,name:"repo_url"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Message to commit while pushing. Will default to <code>&quot;add config&quot;</code>,
<code>&quot;add tokenizer&quot;</code> or <code>&quot;add model&quot;</code> depending on the type of the
class.`,name:"commit_message"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.organization",description:`<strong>organization</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Organization in which you want to push your model or tokenizer
(you must be a member of this organization).`,name:"organization"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.api_endpoint",description:`<strong>api_endpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The API endpoint to use when pushing the model to the hub.`,name:"api_endpoint"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.use_auth_token",description:`<strong>use_auth_token</strong> (<code>bool</code> or <code>str</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files.
If <code>True</code>, will use the token generated when running
<code>transformers-cli login</code> (stored in <code>~/.huggingface</code>). Will
default to <code>True</code> if <code>repo_url</code> is not specified.`,name:"use_auth_token"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.git_user",description:`<strong>git_user</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.name</code> for committing and
pushing files to the hub.`,name:"git_user"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.git_email",description:`<strong>git_email</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.email</code> for committing and
pushing files to the hub.`,name:"git_email"},{anchor:"huggingface_hub.ModelHubMixin.push_to_hub.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hub_mixin.py#L211",returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),te=new Y({props:{name:"save_pretrained",anchor:"huggingface_hub.ModelHubMixin.save_pretrained",parameters:[{name:"save_directory",val:": str"},{name:"config",val:": typing.Optional[dict] = None"},{name:"push_to_hub",val:": bool = False"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code>) &#x2014;
Specify directory in which you want to save weights.`,name:"save_directory"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
specify config (must be dict) in case you want to save
it.`,name:"config"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.push_to_hub",description:`<strong>push_to_hub</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Set it to <code>True</code> in case you want to push your weights
to huggingface_hub`,name:"push_to_hub"},{anchor:"huggingface_hub.ModelHubMixin.save_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
kwargs will be passed to <code>push_to_hub</code>`,name:"kwargs"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hub_mixin.py#L30"}}),ne=new so({}),ae=new Y({props:{name:"huggingface_hub.from_pretrained_keras",anchor:"huggingface_hub.from_pretrained_keras",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.from_pretrained_keras.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:<ul>
<li>A string, the <code>model id</code> of a pretrained model hosted inside a
model repo on huggingface.co. Valid model ids can be located
at the root-level, like <code>bert-base-uncased</code>, or namespaced
under a user or organization name, like
<code>dbmdz/bert-base-german-cased</code>.</li>
<li>You can add <code>revision</code> by appending <code>@</code> at the end of model_id
simply like this: <code>dbmdz/bert-base-german-cased@main</code> Revision
is the specific model version to use. It can be a branch name,
a tag name, or a commit id, since we use a git-based system
for storing models and other artifacts on huggingface.co, so
<code>revision</code> can be any identifier allowed by git.</li>
<li>A path to a <code>directory</code> containing model weights saved using
<code>save_pretrained</code>, e.g.,
<code>./my_model_directory/</code>.</li>
<li><code>None</code> if you are both providing the configuration and state
dictionary (resp. with keyword arguments <code>config</code> and
<code>state_dict</code>).</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"huggingface_hub.from_pretrained_keras.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to force the (re-)download of the model weights and
configuration files, overriding the cached versions if they exist.`,name:"force_download"},{anchor:"huggingface_hub.from_pretrained_keras.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to delete incompletely received files. Will attempt to
resume the download if such a file exists.`,name:"resume_download"},{anchor:"huggingface_hub.from_pretrained_keras.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g.,
<code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The
proxies are used on each request.`,name:"proxies"},{anchor:"huggingface_hub.from_pretrained_keras.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If
<code>True</code>, will use the token generated when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"huggingface_hub.from_pretrained_keras.cache_dir",description:`<strong>cache_dir</strong> (<code>Union[str, os.PathLike]</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model
configuration should be cached if the standard cache should not be
used.`,name:"cache_dir"},{anchor:"huggingface_hub.from_pretrained_keras.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to only look at local files (i.e., do not try to download
the model).`,name:"local_files_only(bool,"},{anchor:"huggingface_hub.from_pretrained_keras.model_kwargs",description:`<strong>model_kwargs</strong> (<code>Dict</code>, <em>optional</em>) &#x2014;
model_kwargs will be passed to the model during initialization`,name:"model_kwargs"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/keras_mixin.py#L227"}}),B=new It({props:{$$slots:{default:[Kt]},$$scope:{ctx:he}}}),re=new Y({props:{name:"huggingface_hub.push_to_hub_keras",anchor:"huggingface_hub.push_to_hub_keras",parameters:[{name:"model",val:""},{name:"repo_path_or_name",val:": typing.Optional[str] = None"},{name:"repo_url",val:": typing.Optional[str] = None"},{name:"log_dir",val:": typing.Optional[str] = None"},{name:"commit_message",val:": typing.Optional[str] = 'Add model'"},{name:"organization",val:": typing.Optional[str] = None"},{name:"private",val:": typing.Optional[bool] = None"},{name:"api_endpoint",val:": typing.Optional[str] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = True"},{name:"git_user",val:": typing.Optional[str] = None"},{name:"git_email",val:": typing.Optional[str] = None"},{name:"config",val:": typing.Optional[dict] = None"},{name:"include_optimizer",val:": typing.Optional[bool] = False"},{name:"tags",val:": typing.Union[list, str, NoneType] = None"},{name:"plot_model",val:": typing.Optional[bool] = True"},{name:"**model_save_kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.push_to_hub_keras.model",description:`<strong>model</strong> (<code>Keras.Model</code>) &#x2014;
The <a href="%60https://www.tensorflow.org/api_docs/python/tf/keras/Model%60">Keras
model</a>
you&#x2019;d like to push to the Hub. The model must be compiled and built.`,name:"model"},{anchor:"huggingface_hub.push_to_hub_keras.repo_path_or_name",description:`<strong>repo_path_or_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Can either be a repository name for your model or tokenizer in the
Hub or a path to a local folder (in which case the repository will
have the name of that local folder). If not specified, will default
to the name given by <code>repo_url</code> and a local directory with that name
will be created.`,name:"repo_path_or_name"},{anchor:"huggingface_hub.push_to_hub_keras.repo_url",description:`<strong>repo_url</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Specify this in case you want to push to an existing repository in
the Hub. If unspecified, a new repository will be created in your
namespace (unless you specify an <code>organization</code>) with <code>repo_name</code>.`,name:"repo_url"},{anchor:"huggingface_hub.push_to_hub_keras.log_dir",description:`<strong>log_dir</strong> (<code>str</code>, <em>optional</em>) &#x2014;
TensorBoard logging directory to be pushed. The Hub automatically
hosts and displays a TensorBoard instance if log files are included
in the repository.`,name:"log_dir"},{anchor:"huggingface_hub.push_to_hub_keras.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>, defaults to &#x201C;Add message&#x201D;) &#x2014;
Message to commit while pushing.`,name:"commit_message"},{anchor:"huggingface_hub.push_to_hub_keras.organization",description:`<strong>organization</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Organization in which you want to push your model or tokenizer (you
must be a member of this organization).`,name:"organization"},{anchor:"huggingface_hub.push_to_hub_keras.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether the repository created should be private.`,name:"private"},{anchor:"huggingface_hub.push_to_hub_keras.api_endpoint",description:`<strong>api_endpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The API endpoint to use when pushing the model to the hub.`,name:"api_endpoint"},{anchor:"huggingface_hub.push_to_hub_keras.use_auth_token",description:`<strong>use_auth_token</strong> (<code>bool</code> or <code>str</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If
<code>True</code>, will use the token generated when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>). Will default to <code>True</code>.`,name:"use_auth_token"},{anchor:"huggingface_hub.push_to_hub_keras.git_user",description:`<strong>git_user</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.name</code> for committing and pushing
files to the Hub.`,name:"git_user"},{anchor:"huggingface_hub.push_to_hub_keras.git_email",description:`<strong>git_email</strong> (<code>str</code>, <em>optional</em>) &#x2014;
will override the <code>git config user.email</code> for committing and pushing
files to the Hub.`,name:"git_email"},{anchor:"huggingface_hub.push_to_hub_keras.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"},{anchor:"huggingface_hub.push_to_hub_keras.include_optimizer",description:`<strong>include_optimizer</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to include optimizer during serialization.`,name:"include_optimizer"},{anchor:"huggingface_hub.push_to_hub_keras.tags",description:`<strong>tags</strong> (Union[<code>list</code>, <code>str</code>], <em>optional</em>) &#x2014;
List of tags that are related to model or string of a single tag. See example tags
<a href="https://github.com/huggingface/hub-docs/blame/main/modelcard.md" rel="nofollow">here</a>.`,name:"tags"},{anchor:"huggingface_hub.push_to_hub_keras.plot_model",description:`<strong>plot_model</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Setting this to <code>True</code> will plot the model and put it in the model
card. Requires graphviz and pydot to be installed.`,name:"plot_model"},{anchor:"huggingface_hub.push_to_hub_keras.model_save_kwargs(dict,",description:`<strong>model_save_kwargs(<code>dict</code>,</strong> <em>optional</em>) &#x2014;
model_save_kwargs will be passed to
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model" rel="nofollow"><code>tf.keras.models.save_model()</code></a>.`,name:"model_save_kwargs(dict,"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/keras_mixin.py#L286",returnDescription:`
<p>The url of the commit of your model in the given repository.</p>
`}}),se=new Y({props:{name:"huggingface_hub.save_pretrained_keras",anchor:"huggingface_hub.save_pretrained_keras",parameters:[{name:"model",val:""},{name:"save_directory",val:": str"},{name:"config",val:": typing.Union[typing.Dict[str, typing.Any], NoneType] = None"},{name:"include_optimizer",val:": typing.Optional[bool] = False"},{name:"plot_model",val:": typing.Optional[bool] = True"},{name:"tags",val:": typing.Union[list, str, NoneType] = None"},{name:"**model_save_kwargs",val:""}],parametersDescription:[{anchor:"huggingface_hub.save_pretrained_keras.model",description:`<strong>model</strong> (<code>Keras.Model</code>) &#x2014;
The <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" rel="nofollow">Keras
model</a>
you&#x2019;d like to save. The model must be compiled and built.`,name:"model"},{anchor:"huggingface_hub.save_pretrained_keras.save_directory",description:`<strong>save_directory</strong> (<code>str</code>) &#x2014;
Specify directory in which you want to save the Keras model.`,name:"save_directory"},{anchor:"huggingface_hub.save_pretrained_keras.config",description:`<strong>config</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Configuration object to be saved alongside the model weights.`,name:"config"},{anchor:"huggingface_hub.save_pretrained_keras.include_optimizer(bool,",description:`<strong>include_optimizer(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to include optimizer in serialization.`,name:"include_optimizer(bool,"},{anchor:"huggingface_hub.save_pretrained_keras.plot_model",description:`<strong>plot_model</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Setting this to <code>True</code> will plot the model and put it in the model
card. Requires graphviz and pydot to be installed.`,name:"plot_model"},{anchor:"huggingface_hub.save_pretrained_keras.tags",description:`<strong>tags</strong> (Union[<code>str</code>,<code>list</code>], <em>optional</em>) &#x2014;
List of tags that are related to model or string of a single tag. See example tags
<a href="https://github.com/huggingface/hub-docs/blame/main/modelcard.md" rel="nofollow">here</a>.`,name:"tags"},{anchor:"huggingface_hub.save_pretrained_keras.model_save_kwargs(dict,",description:`<strong>model_save_kwargs(<code>dict</code>,</strong> <em>optional</em>) &#x2014;
model_save_kwargs will be passed to
<a href="https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model" rel="nofollow"><code>tf.keras.models.save_model()</code></a>.`,name:"model_save_kwargs(dict,"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/keras_mixin.py#L148"}}),de=new Y({props:{name:"class huggingface_hub.KerasModelHubMixin",anchor:"huggingface_hub.KerasModelHubMixin",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/keras_mixin.py#L427"}}),{c(){h=n("meta"),T=d(),m=n("h1"),f=n("a"),M=n("span"),v(p.$$.fragment),_=d(),E=n("span"),lo=i("Mixins & serialization methods"),Fe=d(),N=n("h2"),L=n("a"),fe=n("span"),v(J.$$.fragment),co=d(),be=n("span"),ho=i("Mixins"),Ue=d(),F=n("p"),go=i("The "),ve=n("code"),uo=i("huggingface_hub"),mo=i(` library offers a range of mixins that can be used as a parent class for your
objects, in order to provide simple uploading and downloading functions.`),Ke=d(),S=n("h3"),U=n("a"),ye=n("span"),v(Q.$$.fragment),po=d(),we=n("span"),_o=i("PyTorch"),We=d(),b=n("div"),v(X.$$.fragment),fo=d(),H=n("p"),bo=i(`A Generic Base Model Hub Mixin. Define your own mixin for anything by
inheriting from this class and overwriting `),xe=n("code"),vo=i("_from_pretrained"),yo=i(` and
`),ke=n("code"),wo=i("_save_pretrained"),xo=i(` to define custom logic for saving/loading your classes.
See `),$e=n("code"),ko=i("huggingface_hub.PyTorchModelHubMixin"),$o=i(" for an example."),Mo=d(),O=n("div"),v(Z.$$.fragment),To=d(),I=n("p"),Eo=i(`Instantiate a pretrained PyTorch model from a pre-trained model
configuration from huggingface-hub. The model is set in
evaluation mode by default using `),Me=n("code"),Ho=i("model.eval()"),zo=i(` (Dropout modules
are deactivated). To train the model, you should first set it
back in training mode with `),Te=n("code"),Po=i("model.train()"),Oo=i("."),Do=d(),v(K.$$.fragment),No=d(),W=n("div"),v(ee.$$.fragment),So=d(),oe=n("p"),Io=i(`Upload model checkpoint or tokenizer files to the Hub while
synchronizing a local clone of the repo in `),Ee=n("code"),Ao=i("repo_path_or_name"),Co=i("."),qo=d(),V=n("div"),v(te.$$.fragment),Lo=d(),He=n("p"),Fo=i("Save weights in local directory."),Ve=d(),A=n("h3"),j=n("a"),ze=n("span"),v(ne.$$.fragment),Uo=d(),Pe=n("span"),Ko=i("Keras"),je=d(),z=n("div"),v(ae.$$.fragment),Wo=d(),Oe=n("p"),Vo=i("Instantiate a pretrained Keras model from a pre-trained model from the Hub.\nThe model is expected to be in SavedModel format.```"),jo=d(),v(B.$$.fragment),Be=d(),C=n("div"),v(re.$$.fragment),Bo=d(),ie=n("p"),Ro=i(`Upload model checkpoint or tokenizer files to the Hub while synchronizing a
local clone of the repo in `),De=n("code"),Go=i("repo_path_or_name"),Yo=i("."),Re=d(),q=n("div"),v(se.$$.fragment),Jo=d(),Ne=n("p"),Qo=i(`Saves a Keras model to save_directory in SavedModel format. Use this if
you\u2019re using the Functional or Sequential APIs.`),Ge=d(),P=n("div"),v(de.$$.fragment),Xo=d(),Se=n("p"),Zo=i(`Mixin to provide model Hub upload/download capabilities to Keras models.
Override this class to obtain the following internal methods:`),et=d(),le=n("ul"),ge=n("li"),Ie=n("code"),ot=i("_from_pretrained"),tt=i(", to load a model from the Hub or from local files."),nt=d(),R=n("li"),Ae=n("code"),at=i("_save_pretrained"),rt=i(", to save a model in the "),Ce=n("code"),it=i("SavedModel"),st=i(" format."),this.h()},l(o){const c=Lt('[data-svelte="svelte-1phssyn"]',document.head);h=a(c,"META",{name:!0,content:!0}),c.forEach(t),T=l(o),m=a(o,"H1",{class:!0});var ce=r(m);f=a(ce,"A",{id:!0,class:!0,href:!0});var qe=r(f);M=a(qe,"SPAN",{});var lt=r(M);y(p.$$.fragment,lt),lt.forEach(t),qe.forEach(t),_=l(ce),E=a(ce,"SPAN",{});var ct=r(E);lo=s(ct,"Mixins & serialization methods"),ct.forEach(t),ce.forEach(t),Fe=l(o),N=a(o,"H2",{class:!0});var Je=r(N);L=a(Je,"A",{id:!0,class:!0,href:!0});var ht=r(L);fe=a(ht,"SPAN",{});var gt=r(fe);y(J.$$.fragment,gt),gt.forEach(t),ht.forEach(t),co=l(Je),be=a(Je,"SPAN",{});var ut=r(be);ho=s(ut,"Mixins"),ut.forEach(t),Je.forEach(t),Ue=l(o),F=a(o,"P",{});var Qe=r(F);go=s(Qe,"The "),ve=a(Qe,"CODE",{});var mt=r(ve);uo=s(mt,"huggingface_hub"),mt.forEach(t),mo=s(Qe,` library offers a range of mixins that can be used as a parent class for your
objects, in order to provide simple uploading and downloading functions.`),Qe.forEach(t),Ke=l(o),S=a(o,"H3",{class:!0});var Xe=r(S);U=a(Xe,"A",{id:!0,class:!0,href:!0});var pt=r(U);ye=a(pt,"SPAN",{});var _t=r(ye);y(Q.$$.fragment,_t),_t.forEach(t),pt.forEach(t),po=l(Xe),we=a(Xe,"SPAN",{});var ft=r(we);_o=s(ft,"PyTorch"),ft.forEach(t),Xe.forEach(t),We=l(o),b=a(o,"DIV",{class:!0});var D=r(b);y(X.$$.fragment,D),fo=l(D),H=a(D,"P",{});var G=r(H);bo=s(G,`A Generic Base Model Hub Mixin. Define your own mixin for anything by
inheriting from this class and overwriting `),xe=a(G,"CODE",{});var bt=r(xe);vo=s(bt,"_from_pretrained"),bt.forEach(t),yo=s(G,` and
`),ke=a(G,"CODE",{});var vt=r(ke);wo=s(vt,"_save_pretrained"),vt.forEach(t),xo=s(G,` to define custom logic for saving/loading your classes.
See `),$e=a(G,"CODE",{});var yt=r($e);ko=s(yt,"huggingface_hub.PyTorchModelHubMixin"),yt.forEach(t),$o=s(G," for an example."),G.forEach(t),Mo=l(D),O=a(D,"DIV",{class:!0});var ue=r(O);y(Z.$$.fragment,ue),To=l(ue),I=a(ue,"P",{});var me=r(I);Eo=s(me,`Instantiate a pretrained PyTorch model from a pre-trained model
configuration from huggingface-hub. The model is set in
evaluation mode by default using `),Me=a(me,"CODE",{});var wt=r(Me);Ho=s(wt,"model.eval()"),wt.forEach(t),zo=s(me,` (Dropout modules
are deactivated). To train the model, you should first set it
back in training mode with `),Te=a(me,"CODE",{});var xt=r(Te);Po=s(xt,"model.train()"),xt.forEach(t),Oo=s(me,"."),me.forEach(t),Do=l(ue),y(K.$$.fragment,ue),ue.forEach(t),No=l(D),W=a(D,"DIV",{class:!0});var Ze=r(W);y(ee.$$.fragment,Ze),So=l(Ze),oe=a(Ze,"P",{});var eo=r(oe);Io=s(eo,`Upload model checkpoint or tokenizer files to the Hub while
synchronizing a local clone of the repo in `),Ee=a(eo,"CODE",{});var kt=r(Ee);Ao=s(kt,"repo_path_or_name"),kt.forEach(t),Co=s(eo,"."),eo.forEach(t),Ze.forEach(t),qo=l(D),V=a(D,"DIV",{class:!0});var oo=r(V);y(te.$$.fragment,oo),Lo=l(oo),He=a(oo,"P",{});var $t=r(He);Fo=s($t,"Save weights in local directory."),$t.forEach(t),oo.forEach(t),D.forEach(t),Ve=l(o),A=a(o,"H3",{class:!0});var to=r(A);j=a(to,"A",{id:!0,class:!0,href:!0});var Mt=r(j);ze=a(Mt,"SPAN",{});var Tt=r(ze);y(ne.$$.fragment,Tt),Tt.forEach(t),Mt.forEach(t),Uo=l(to),Pe=a(to,"SPAN",{});var Et=r(Pe);Ko=s(Et,"Keras"),Et.forEach(t),to.forEach(t),je=l(o),z=a(o,"DIV",{class:!0});var pe=r(z);y(ae.$$.fragment,pe),Wo=l(pe),Oe=a(pe,"P",{});var Ht=r(Oe);Vo=s(Ht,"Instantiate a pretrained Keras model from a pre-trained model from the Hub.\nThe model is expected to be in SavedModel format.```"),Ht.forEach(t),jo=l(pe),y(B.$$.fragment,pe),pe.forEach(t),Be=l(o),C=a(o,"DIV",{class:!0});var no=r(C);y(re.$$.fragment,no),Bo=l(no),ie=a(no,"P",{});var ao=r(ie);Ro=s(ao,`Upload model checkpoint or tokenizer files to the Hub while synchronizing a
local clone of the repo in `),De=a(ao,"CODE",{});var zt=r(De);Go=s(zt,"repo_path_or_name"),zt.forEach(t),Yo=s(ao,"."),ao.forEach(t),no.forEach(t),Re=l(o),q=a(o,"DIV",{class:!0});var ro=r(q);y(se.$$.fragment,ro),Jo=l(ro),Ne=a(ro,"P",{});var Pt=r(Ne);Qo=s(Pt,`Saves a Keras model to save_directory in SavedModel format. Use this if
you\u2019re using the Functional or Sequential APIs.`),Pt.forEach(t),ro.forEach(t),Ge=l(o),P=a(o,"DIV",{class:!0});var _e=r(P);y(de.$$.fragment,_e),Xo=l(_e),Se=a(_e,"P",{});var Ot=r(Se);Zo=s(Ot,`Mixin to provide model Hub upload/download capabilities to Keras models.
Override this class to obtain the following internal methods:`),Ot.forEach(t),et=l(_e),le=a(_e,"UL",{});var io=r(le);ge=a(io,"LI",{});var dt=r(ge);Ie=a(dt,"CODE",{});var Dt=r(Ie);ot=s(Dt,"_from_pretrained"),Dt.forEach(t),tt=s(dt,", to load a model from the Hub or from local files."),dt.forEach(t),nt=l(io),R=a(io,"LI",{});var Le=r(R);Ae=a(Le,"CODE",{});var Nt=r(Ae);at=s(Nt,"_save_pretrained"),Nt.forEach(t),rt=s(Le,", to save a model in the "),Ce=a(Le,"CODE",{});var St=r(Ce);it=s(St,"SavedModel"),St.forEach(t),st=s(Le," format."),Le.forEach(t),io.forEach(t),_e.forEach(t),this.h()},h(){g(h,"name","hf:doc:metadata"),g(h,"content",JSON.stringify(Vt)),g(f,"id","mixins-serialization-methods"),g(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(f,"href","#mixins-serialization-methods"),g(m,"class","relative group"),g(L,"id","mixins"),g(L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(L,"href","#mixins"),g(N,"class","relative group"),g(U,"id","huggingface_hub.ModelHubMixin"),g(U,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(U,"href","#huggingface_hub.ModelHubMixin"),g(S,"class","relative group"),g(O,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(W,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(V,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(b,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(j,"id","huggingface_hub.from_pretrained_keras"),g(j,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(j,"href","#huggingface_hub.from_pretrained_keras"),g(A,"class","relative group"),g(z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(C,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),g(P,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(o,c){e(document.head,h),u(o,T,c),u(o,m,c),e(m,f),e(f,M),w(p,M,null),e(m,_),e(m,E),e(E,lo),u(o,Fe,c),u(o,N,c),e(N,L),e(L,fe),w(J,fe,null),e(N,co),e(N,be),e(be,ho),u(o,Ue,c),u(o,F,c),e(F,go),e(F,ve),e(ve,uo),e(F,mo),u(o,Ke,c),u(o,S,c),e(S,U),e(U,ye),w(Q,ye,null),e(S,po),e(S,we),e(we,_o),u(o,We,c),u(o,b,c),w(X,b,null),e(b,fo),e(b,H),e(H,bo),e(H,xe),e(xe,vo),e(H,yo),e(H,ke),e(ke,wo),e(H,xo),e(H,$e),e($e,ko),e(H,$o),e(b,Mo),e(b,O),w(Z,O,null),e(O,To),e(O,I),e(I,Eo),e(I,Me),e(Me,Ho),e(I,zo),e(I,Te),e(Te,Po),e(I,Oo),e(O,Do),w(K,O,null),e(b,No),e(b,W),w(ee,W,null),e(W,So),e(W,oe),e(oe,Io),e(oe,Ee),e(Ee,Ao),e(oe,Co),e(b,qo),e(b,V),w(te,V,null),e(V,Lo),e(V,He),e(He,Fo),u(o,Ve,c),u(o,A,c),e(A,j),e(j,ze),w(ne,ze,null),e(A,Uo),e(A,Pe),e(Pe,Ko),u(o,je,c),u(o,z,c),w(ae,z,null),e(z,Wo),e(z,Oe),e(Oe,Vo),e(z,jo),w(B,z,null),u(o,Be,c),u(o,C,c),w(re,C,null),e(C,Bo),e(C,ie),e(ie,Ro),e(ie,De),e(De,Go),e(ie,Yo),u(o,Re,c),u(o,q,c),w(se,q,null),e(q,Jo),e(q,Ne),e(Ne,Qo),u(o,Ge,c),u(o,P,c),w(de,P,null),e(P,Xo),e(P,Se),e(Se,Zo),e(P,et),e(P,le),e(le,ge),e(ge,Ie),e(Ie,ot),e(ge,tt),e(le,nt),e(le,R),e(R,Ae),e(Ae,at),e(R,rt),e(R,Ce),e(Ce,it),e(R,st),Ye=!0},p(o,[c]){const ce={};c&2&&(ce.$$scope={dirty:c,ctx:o}),K.$set(ce);const qe={};c&2&&(qe.$$scope={dirty:c,ctx:o}),B.$set(qe)},i(o){Ye||(x(p.$$.fragment,o),x(J.$$.fragment,o),x(Q.$$.fragment,o),x(X.$$.fragment,o),x(Z.$$.fragment,o),x(K.$$.fragment,o),x(ee.$$.fragment,o),x(te.$$.fragment,o),x(ne.$$.fragment,o),x(ae.$$.fragment,o),x(B.$$.fragment,o),x(re.$$.fragment,o),x(se.$$.fragment,o),x(de.$$.fragment,o),Ye=!0)},o(o){k(p.$$.fragment,o),k(J.$$.fragment,o),k(Q.$$.fragment,o),k(X.$$.fragment,o),k(Z.$$.fragment,o),k(K.$$.fragment,o),k(ee.$$.fragment,o),k(te.$$.fragment,o),k(ne.$$.fragment,o),k(ae.$$.fragment,o),k(B.$$.fragment,o),k(re.$$.fragment,o),k(se.$$.fragment,o),k(de.$$.fragment,o),Ye=!1},d(o){t(h),o&&t(T),o&&t(m),$(p),o&&t(Fe),o&&t(N),$(J),o&&t(Ue),o&&t(F),o&&t(Ke),o&&t(S),$(Q),o&&t(We),o&&t(b),$(X),$(Z),$(K),$(ee),$(te),o&&t(Ve),o&&t(A),$(ne),o&&t(je),o&&t(z),$(ae),$(B),o&&t(Be),o&&t(C),$(re),o&&t(Re),o&&t(q),$(se),o&&t(Ge),o&&t(P),$(de)}}}const Vt={local:"mixins-serialization-methods",sections:[{local:"mixins",sections:[{local:"huggingface_hub.ModelHubMixin",title:"PyTorch"},{local:"huggingface_hub.from_pretrained_keras",title:"Keras"}],title:"Mixins"}],title:"Mixins & serialization methods"};function jt(he){return Ft(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Jt extends At{constructor(h){super();Ct(this,h,jt,Wt,qt,{})}}export{Jt as default,Vt as metadata};
