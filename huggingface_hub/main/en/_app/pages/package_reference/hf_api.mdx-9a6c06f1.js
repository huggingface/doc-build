import{S as $l,i as yl,s as kl,e as s,k as r,w as f,t as l,M as wl,c as n,d as a,m as i,a as o,x as u,h as g,b as c,F as e,g as y,y as m,q as _,o as b,B as v,v as Al}from"../../chunks/vendor-7b1da053.js";import{T as is}from"../../chunks/Tip-41a95816.js";import{D}from"../../chunks/Docstring-f1352b16.js";import{C as _e}from"../../chunks/CodeBlock-5f39b59e.js";import{I as ni}from"../../chunks/IconCopyLink-d24e9a6f.js";function jl(J){let p,q,A,w,H,$,j,N,O,F,E,P,T,U,C;return{c(){p=s("p"),q=l("Raises the following errors:"),A=r(),w=s("ul"),H=s("li"),$=s("a"),j=s("code"),N=l("HTTPError"),O=l(`
if the HuggingFace API returned an error`),F=r(),E=s("li"),P=s("a"),T=s("code"),U=l("ValueError"),C=l(`
if some parameter value is invalid`),this.h()},l(x){p=n(x,"P",{});var L=o(p);q=g(L,"Raises the following errors:"),L.forEach(a),A=i(x),w=n(x,"UL",{});var W=o(w);H=n(W,"LI",{});var G=o(H);$=n(G,"A",{href:!0,rel:!0});var he=o($);j=n(he,"CODE",{});var de=o(j);N=g(de,"HTTPError"),de.forEach(a),he.forEach(a),O=g(G,`
if the HuggingFace API returned an error`),G.forEach(a),F=i(W),E=n(W,"LI",{});var Q=o(E);P=n(Q,"A",{href:!0,rel:!0});var X=o(P);T=n(X,"CODE",{});var fe=o(T);U=g(fe,"ValueError"),fe.forEach(a),X.forEach(a),C=g(Q,`
if some parameter value is invalid`),Q.forEach(a),W.forEach(a),this.h()},h(){c($,"href","https://2.python-requests.org/en/master/api/#requests.HTTPError"),c($,"rel","nofollow"),c(P,"href","https://docs.python.org/3/library/exceptions.html#ValueError"),c(P,"rel","nofollow")},m(x,L){y(x,p,L),e(p,q),y(x,A,L),y(x,w,L),e(w,H),e(H,$),e($,j),e(j,N),e(H,O),e(w,F),e(w,E),e(E,P),e(P,T),e(T,U),e(E,C)},d(x){x&&a(p),x&&a(A),x&&a(w)}}}function Hl(J){let p,q,A,w,H;return{c(){p=s("p"),q=l(`Warning: Deprecated, will be removed in v0.7. Please use
`),A=s("a"),w=l("HfApi.set_access_token()"),H=l(" instead."),this.h()},l($){p=n($,"P",{});var j=o(p);q=g(j,`Warning: Deprecated, will be removed in v0.7. Please use
`),A=n(j,"A",{href:!0});var N=o(A);w=g(N,"HfApi.set_access_token()"),N.forEach(a),H=g(j," instead."),j.forEach(a),this.h()},h(){c(A,"href","/docs/huggingface_hub/main/en/package_reference/hf_api#huggingface_hub.HfApi.set_access_token")},m($,j){y($,p,j),e(p,q),e(p,A),e(A,w),e(p,H)},d($){$&&a(p)}}}function El(J){let p,q,A,w,H,$,j,N,O;return{c(){p=s("p"),q=l("Raises the following errors:"),A=r(),w=s("ul"),H=s("li"),$=s("a"),j=s("code"),N=l("HTTPError"),O=l(`
if credentials are invalid`),this.h()},l(F){p=n(F,"P",{});var E=o(p);q=g(E,"Raises the following errors:"),E.forEach(a),A=i(F),w=n(F,"UL",{});var P=o(w);H=n(P,"LI",{});var T=o(H);$=n(T,"A",{href:!0,rel:!0});var U=o($);j=n(U,"CODE",{});var C=o(j);N=g(C,"HTTPError"),C.forEach(a),U.forEach(a),O=g(T,`
if credentials are invalid`),T.forEach(a),P.forEach(a),this.h()},h(){c($,"href","https://2.python-requests.org/en/master/api/#requests.HTTPError"),c($,"rel","nofollow")},m(F,E){y(F,p,E),e(p,q),y(F,A,E),y(F,w,E),e(w,H),e(H,$),e($,j),e(j,N),e(H,O)},d(F){F&&a(p),F&&a(A),F&&a(w)}}}function xl(J){let p,q,A,w,H;return{c(){p=s("p"),q=l(`Warning: Deprecated, will be removed in v0.7. Please use
`),A=s("a"),w=l("HfApi.unset_access_token()"),H=l(" instead."),this.h()},l($){p=n($,"P",{});var j=o(p);q=g(j,`Warning: Deprecated, will be removed in v0.7. Please use
`),A=n(j,"A",{href:!0});var N=o(A);w=g(N,"HfApi.unset_access_token()"),N.forEach(a),H=g(j," instead."),j.forEach(a),this.h()},h(){c(A,"href","/docs/huggingface_hub/main/en/package_reference/hf_api#huggingface_hub.HfApi.unset_access_token")},m($,j){y($,p,j),e(p,q),e(p,A),e(A,w),e(p,H)},d($){$&&a(p)}}}function Dl(J){let p,q,A,w,H,$,j,N,O,F,E,P,T,U,C;return{c(){p=s("p"),q=l("Raises the following errors:"),A=r(),w=s("ul"),H=s("li"),$=s("a"),j=s("code"),N=l("HTTPError"),O=l(`
if the HuggingFace API returned an error`),F=r(),E=s("li"),P=s("a"),T=s("code"),U=l("ValueError"),C=l(`
if some parameter value is invalid`),this.h()},l(x){p=n(x,"P",{});var L=o(p);q=g(L,"Raises the following errors:"),L.forEach(a),A=i(x),w=n(x,"UL",{});var W=o(w);H=n(W,"LI",{});var G=o(H);$=n(G,"A",{href:!0,rel:!0});var he=o($);j=n(he,"CODE",{});var de=o(j);N=g(de,"HTTPError"),de.forEach(a),he.forEach(a),O=g(G,`
if the HuggingFace API returned an error`),G.forEach(a),F=i(W),E=n(W,"LI",{});var Q=o(E);P=n(Q,"A",{href:!0,rel:!0});var X=o(P);T=n(X,"CODE",{});var fe=o(T);U=g(fe,"ValueError"),fe.forEach(a),X.forEach(a),C=g(Q,`
if some parameter value is invalid`),Q.forEach(a),W.forEach(a),this.h()},h(){c($,"href","https://2.python-requests.org/en/master/api/#requests.HTTPError"),c($,"rel","nofollow"),c(P,"href","https://docs.python.org/3/library/exceptions.html#ValueError"),c(P,"rel","nofollow")},m(x,L){y(x,p,L),e(p,q),y(x,A,L),y(x,w,L),e(w,H),e(H,$),e($,j),e(j,N),e(H,O),e(w,F),e(w,E),e(E,P),e(P,T),e(T,U),e(E,C)},d(x){x&&a(p),x&&a(A),x&&a(w)}}}function ql(J){let p,q,A,w,H,$,j,N,O,F,E,P,T,U,C,x,L,W,G,he,de,Q,X,fe,ls,Ge,gs,be,Vs,sa,Ws,Gs,cs,Be,ps,ve,Bs,na,Ks,Js,hs,d,Ke,Qs,Y,Je,Xs,oa,Ys,Zs,ra,en,tn,ia,Gt,an,Qe,sn,nn,S,Xe,on,la,rn,ln,ga,gn,cn,ca,pn,hn,pa,Bt,dn,Ye,fn,un,re,Ze,mn,ha,_n,bn,$e,vn,Z,et,$n,da,yn,kn,fa,wn,An,ua,Kt,jn,tt,Hn,En,ye,at,xn,ma,Dn,qn,ke,st,Fn,_a,Nn,Pn,we,nt,Ln,ba,Tn,In,I,ot,Mn,va,On,Un,rt,Cn,$a,Sn,zn,Rn,it,Vn,lt,Wn,ya,Gn,Bn,Kn,gt,Jn,Ae,ct,Qn,ka,Xn,Yn,M,pt,Zn,wa,eo,to,ht,ao,Aa,so,no,oo,dt,ro,ft,io,ja,lo,go,co,ut,po,ee,mt,ho,Ha,fo,uo,Ea,mo,_o,xa,Jt,bo,_t,vo,$o,te,bt,yo,Da,ko,wo,je,Ao,He,jo,ie,vt,Ho,qa,Eo,xo,Ee,Do,z,$t,qo,Fa,Fo,No,Na,Po,Lo,Pa,To,Io,La,Qt,Mo,yt,Oo,Uo,R,kt,Co,Ta,So,zo,wt,Ro,At,Vo,Wo,Go,Ia,Bo,Ko,Ma,Xt,Jo,jt,Qo,Xo,xe,Ht,Yo,Oa,Zo,er,De,Et,tr,Ua,ar,sr,ae,xt,nr,Ca,or,rr,Sa,ir,lr,za,Yt,gr,Dt,cr,pr,V,qt,hr,Ra,dr,fr,qe,ur,Va,mr,_r,Ft,br,Fe,Nt,vr,Wa,$r,ds,ue,Ne,Ga,Pt,yr,Ba,kr,fs,Lt,Ka,wr,Ar,us,Pe,jr,Zt,Hr,Er,ms,B,Tt,xr,Le,It,Dr,Ja,qr,Fr,Te,Mt,Nr,Qa,Pr,Lr,Ie,Ot,Tr,Xa,Ir,_s,me,Me,Ya,Ut,Mr,Za,Or,bs,Oe,Ur,es,Cr,Sr,vs,K,Ct,zr,ts,Rr,Vr,as,Wr,Gr,St,$s,oe,zt,Br,ss,Kr,Jr,Rt,ys;return $=new ni({}),Ge=new _e({props:{code:`from huggingface_hub import list_models

models = list_models()`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> list_models

models = list_models()`}}),Be=new _e({props:{code:`from huggingface_hub import HfApi

hf_api = HfApi()
models = hf_api.list_models()`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> HfApi

hf_api = HfApi()
models = hf_api.list_models()`}}),Ke=new D({props:{name:"class huggingface_hub.HfApi",anchor:"huggingface_hub.HfApi",parameters:[{name:"endpoint",val:" = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L462"}}),Je=new D({props:{name:"create_repo",anchor:"huggingface_hub.HfApi.create_repo",parameters:[{name:"repo_id",val:": str = None"},{name:"token",val:": typing.Optional[str] = None"},{name:"organization",val:": typing.Optional[str] = None"},{name:"private",val:": typing.Optional[bool] = None"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"exist_ok",val:": typing.Optional[bool] = False"},{name:"space_sdk",val:": typing.Optional[str] = None"},{name:"name",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1212",parametersDescription:[{anchor:"huggingface_hub.HfApi.create_repo.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
A namespace (user or an organization) and a repo name separated
by a <code>/</code>.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>Version added: 0.5</p>

					</div>`,name:"repo_id"},{anchor:"huggingface_hub.HfApi.create_repo.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An authentication token [1]_.`,name:"token"},{anchor:"huggingface_hub.HfApi.create_repo.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether the model repo should be private.`,name:"private"},{anchor:"huggingface_hub.HfApi.create_repo.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if uploading to a dataset or
space, <code>None</code> or <code>&quot;model&quot;</code> if uploading to a model. Default is
<code>None</code>.`,name:"repo_type"},{anchor:"huggingface_hub.HfApi.create_repo.exist_ok",description:`<strong>exist_ok</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>True</code>, do not raise an error if repo already exists.`,name:"exist_ok"},{anchor:"huggingface_hub.HfApi.create_repo.space_sdk",description:`<strong>space_sdk</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Choice of SDK to use if repo_type is &#x201C;space&#x201D;. Can be
&#x201C;streamlit&#x201D;, &#x201C;gradio&#x201D;, or &#x201C;static&#x201D;.`,name:"space_sdk"}],returnDescription:`
<p>URL to the newly created repo.</p>
`,returnType:`
<p><code>str</code></p>
`}}),Xe=new D({props:{name:"dataset_info",anchor:"huggingface_hub.HfApi.dataset_info",parameters:[{name:"repo_id",val:": str"},{name:"revision",val:": typing.Optional[str] = None"},{name:"token",val:": typing.Optional[str] = None"},{name:"timeout",val:": typing.Optional[float] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1164",parametersDescription:[{anchor:"huggingface_hub.HfApi.dataset_info.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
A namespace (user or an organization) and a repo name separated
by a <code>/</code>.`,name:"repo_id"},{anchor:"huggingface_hub.HfApi.dataset_info.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The revision of the dataset repository from which to get the
information.`,name:"revision"},{anchor:"huggingface_hub.HfApi.dataset_info.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An authentication token [1]_.`,name:"token"},{anchor:"huggingface_hub.HfApi.dataset_info.timeout",description:`<strong>timeout</strong> (<code>float</code>, <em>optional</em>) &#x2014;
Whether to set a timeout for the request to the Hub.`,name:"timeout"}],returnDescription:`
<p>The dataset repository information.</p>
`,returnType:`
<p><code>DatasetInfo</code></p>
`}}),Ze=new D({props:{name:"delete_file",anchor:"huggingface_hub.HfApi.delete_file",parameters:[{name:"path_in_repo",val:": str"},{name:"repo_id",val:": str"},{name:"token",val:": typing.Optional[str] = None"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"revision",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1724",parametersDescription:[{anchor:"huggingface_hub.HfApi.delete_file.path_in_repo",description:`<strong>path_in_repo</strong> (<code>str</code>) &#x2014;
Relative filepath in the repo, for example:
<code>&quot;checkpoints/1fec34a/weights.bin&quot;</code>`,name:"path_in_repo"},{anchor:"huggingface_hub.HfApi.delete_file.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
The repository from which the file will be deleted, for example:
<code>&quot;username/custom_transformers&quot;</code>`,name:"repo_id"},{anchor:"huggingface_hub.HfApi.delete_file.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Authentication token, obtained with <code>HfApi.login</code> method. Will
default to the stored token.`,name:"token"},{anchor:"huggingface_hub.HfApi.delete_file.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if the file is in a dataset or
space, <code>None</code> or <code>&quot;model&quot;</code> if in a model. Default is <code>None</code>.`,name:"repo_type"},{anchor:"huggingface_hub.HfApi.delete_file.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The git revision to commit from. Defaults to the head of the
<code>&quot;main&quot;</code> branch.`,name:"revision"}]}}),$e=new is({props:{$$slots:{default:[jl]},$$scope:{ctx:J}}}),et=new D({props:{name:"delete_repo",anchor:"huggingface_hub.HfApi.delete_repo",parameters:[{name:"repo_id",val:": str = None"},{name:"token",val:": typing.Optional[str] = None"},{name:"organization",val:": typing.Optional[str] = None"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"name",val:": str = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1346",parametersDescription:[{anchor:"huggingface_hub.HfApi.delete_repo.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
A namespace (user or an organization) and a repo name separated
by a <code>/</code>.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>Version added: 0.5</p>

					</div>`,name:"repo_id"},{anchor:"huggingface_hub.HfApi.delete_repo.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An authentication token [1]_.`,name:"token"},{anchor:"huggingface_hub.HfApi.delete_repo.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if uploading to a dataset or
space, <code>None</code> or <code>&quot;model&quot;</code> if uploading to a model.`,name:"repo_type"}]}}),at=new D({props:{name:"get_dataset_tags",anchor:"huggingface_hub.HfApi.get_dataset_tags",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L663"}}),st=new D({props:{name:"get_full_repo_name",anchor:"huggingface_hub.HfApi.get_full_repo_name",parameters:[{name:"model_id",val:": str"},{name:"organization",val:": typing.Optional[str] = None"},{name:"token",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1783",parametersDescription:[{anchor:"huggingface_hub.HfApi.get_full_repo_name.model_id",description:`<strong>model_id</strong> (<code>str</code>) &#x2014;
The name of the model.`,name:"model_id"},{anchor:"huggingface_hub.HfApi.get_full_repo_name.organization",description:`<strong>organization</strong> (<code>str</code>, <em>optional</em>) &#x2014;
If passed, the repository name will be in the organization
namespace instead of the user namespace.`,name:"organization"},{anchor:"huggingface_hub.HfApi.get_full_repo_name.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The Hugging Face authentication token`,name:"token"}],returnDescription:`
<p>The repository name in the user\u2019s namespace
({username}/{model_id}) if no organization is passed, and under the
organization namespace ({organization}/{model_id}) otherwise.</p>
`,returnType:`
<p><code>str</code></p>
`}}),nt=new D({props:{name:"get_model_tags",anchor:"huggingface_hub.HfApi.get_model_tags",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L655"}}),ot=new D({props:{name:"list_datasets",anchor:"huggingface_hub.HfApi.list_datasets",parameters:[{name:"filter",val:": typing.Union[huggingface_hub.utils.endpoint_helpers.DatasetFilter, str, typing.Iterable[str], NoneType] = None"},{name:"author",val:": typing.Optional[str] = None"},{name:"search",val:": typing.Optional[str] = None"},{name:"sort",val:": typing.Union[typing.Literal['lastModified'], str, NoneType] = None"},{name:"direction",val:": typing.Optional[typing.Literal[-1]] = None"},{name:"limit",val:": typing.Optional[int] = None"},{name:"cardData",val:": typing.Optional[bool] = None"},{name:"full",val:": typing.Optional[bool] = None"},{name:"use_auth_token",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L881",parametersDescription:[{anchor:"huggingface_hub.HfApi.list_datasets.filter",description:`<strong>filter</strong> (<a href="/docs/huggingface_hub/main/en/package_reference/hf_api#huggingface_hub.DatasetFilter">DatasetFilter</a> or <code>str</code> or <code>Iterable</code>, <em>optional</em>) &#x2014;
A string or <a href="/docs/huggingface_hub/main/en/package_reference/hf_api#huggingface_hub.DatasetFilter">DatasetFilter</a> which can be used to identify
datasets on the hub.`,name:"filter"},{anchor:"huggingface_hub.HfApi.list_datasets.author",description:`<strong>author</strong> (<code>str</code>, <em>optional</em>) &#x2014;
A string which identify the author of the returned models`,name:"author"},{anchor:"huggingface_hub.HfApi.list_datasets.search",description:`<strong>search</strong> (<code>str</code>, <em>optional</em>) &#x2014;
A string that will be contained in the returned models.`,name:"search"},{anchor:"huggingface_hub.HfApi.list_datasets.sort",description:`<strong>sort</strong> (<code>Literal[&quot;lastModified&quot;]</code> or <code>str</code>, <em>optional</em>) &#x2014;
The key with which to sort the resulting datasets. Possible
values are the properties of the <code>DatasetInfo</code> class.`,name:"sort"},{anchor:"huggingface_hub.HfApi.list_datasets.direction",description:`<strong>direction</strong> (<code>Literal[-1]</code> or <code>int</code>, <em>optional</em>) &#x2014;
Direction in which to sort. The value <code>-1</code> sorts by descending
order while all other values sort by ascending order.`,name:"direction"},{anchor:"huggingface_hub.HfApi.list_datasets.limit",description:`<strong>limit</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The limit on the number of datasets fetched. Leaving this option
to <code>None</code> fetches all datasets.`,name:"limit"},{anchor:"huggingface_hub.HfApi.list_datasets.cardData",description:`<strong>cardData</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether to grab the metadata for the dataset as well. Can
contain useful information such as the PapersWithCode ID.`,name:"cardData"},{anchor:"huggingface_hub.HfApi.list_datasets.full",description:`<strong>full</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether to fetch all dataset data, including the <code>lastModified</code>
and the <code>cardData</code>.`,name:"full"},{anchor:"huggingface_hub.HfApi.list_datasets.use_auth_token",description:`<strong>use_auth_token</strong> (<code>bool</code> or <code>str</code>, <em>optional</em>) &#x2014;
Whether to use the <code>auth_token</code> provided from the
<code>huggingface_hub</code> cli. If not logged in, a valid <code>auth_token</code>
can be passed in as a string.`,name:"use_auth_token"}]}}),it=new _e({props:{code:`from huggingface_hub import HfApi

api = HfApi()

# List all datasets
api.list_datasets()

# Get all valid search arguments
args = DatasetSearchArguments()

# List only the text classification datasets
api.list_datasets(filter="task_categories:text-classification")
# Using the \`DatasetFilter\`
filt = DatasetFilter(task_categories="text-classification")
# With \`DatasetSearchArguments\`
filt = DatasetFilter(task=args.task_categories.text_classification)
api.list_models(filter=filt)

# List only the datasets in russian for language modeling
api.list_datasets(
    filter=("languages:ru", "task_ids:language-modeling")
)
# Using the \`DatasetFilter\`
filt = DatasetFilter(languages="ru", task_ids="language-modeling")
# With \`DatasetSearchArguments\`
filt = DatasetFilter(
    languages=args.languages.ru,
    task_ids=args.task_ids.language_modeling,
)
api.list_datasets(filter=filt)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> HfApi

<span class="hljs-meta">&gt;&gt;&gt; </span>api = HfApi()

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># List all datasets</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_datasets()

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Get all valid search arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>args = DatasetSearchArguments()

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># List only the text classification datasets</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_datasets(<span class="hljs-built_in">filter</span>=<span class="hljs-string">&quot;task_categories:text-classification&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using the \`DatasetFilter\`</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>filt = DatasetFilter(task_categories=<span class="hljs-string">&quot;text-classification&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># With \`DatasetSearchArguments\`</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>filt = DatasetFilter(task=args.task_categories.text_classification)
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_models(<span class="hljs-built_in">filter</span>=filt)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># List only the datasets in russian for language modeling</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_datasets(
<span class="hljs-meta">... </span>    <span class="hljs-built_in">filter</span>=(<span class="hljs-string">&quot;languages:ru&quot;</span>, <span class="hljs-string">&quot;task_ids:language-modeling&quot;</span>)
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using the \`DatasetFilter\`</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>filt = DatasetFilter(languages=<span class="hljs-string">&quot;ru&quot;</span>, task_ids=<span class="hljs-string">&quot;language-modeling&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># With \`DatasetSearchArguments\`</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>filt = DatasetFilter(
<span class="hljs-meta">... </span>    languages=args.languages.ru,
<span class="hljs-meta">... </span>    task_ids=args.task_ids.language_modeling,
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_datasets(<span class="hljs-built_in">filter</span>=filt)`}}),gt=new _e({props:{code:`from huggingface_hub import HfApi

api = HfApi()

# List all datasets with "text" in their name
api.list_datasets(search="text")

# List all datasets with "text" in their name made by google
api.list_datasets(search="text", author="google")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> HfApi

<span class="hljs-meta">&gt;&gt;&gt; </span>api = HfApi()

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># List all datasets with &quot;text&quot; in their name</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_datasets(search=<span class="hljs-string">&quot;text&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># List all datasets with &quot;text&quot; in their name made by google</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_datasets(search=<span class="hljs-string">&quot;text&quot;</span>, author=<span class="hljs-string">&quot;google&quot;</span>)`}}),ct=new D({props:{name:"list_metrics",anchor:"huggingface_hub.HfApi.list_metrics",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1047",returnDescription:`
<p>a list of <code>MetricInfo</code> objects which.</p>
`,returnType:`
<p><code>List[MetricInfo]</code></p>
`}}),pt=new D({props:{name:"list_models",anchor:"huggingface_hub.HfApi.list_models",parameters:[{name:"filter",val:": typing.Union[huggingface_hub.utils.endpoint_helpers.ModelFilter, str, typing.Iterable[str], NoneType] = None"},{name:"author",val:": typing.Optional[str] = None"},{name:"search",val:": typing.Optional[str] = None"},{name:"emissions_thresholds",val:": typing.Union[typing.Tuple[float, float], NoneType] = None"},{name:"sort",val:": typing.Union[typing.Literal['lastModified'], str, NoneType] = None"},{name:"direction",val:": typing.Optional[typing.Literal[-1]] = None"},{name:"limit",val:": typing.Optional[int] = None"},{name:"full",val:": typing.Optional[bool] = None"},{name:"cardData",val:": typing.Optional[bool] = None"},{name:"fetch_config",val:": typing.Optional[bool] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L673",parametersDescription:[{anchor:"huggingface_hub.HfApi.list_models.filter",description:`<strong>filter</strong> (<a href="/docs/huggingface_hub/main/en/package_reference/hf_api#huggingface_hub.ModelFilter">ModelFilter</a> or <code>str</code> or <code>Iterable</code>, <em>optional</em>) &#x2014;
A string or <a href="/docs/huggingface_hub/main/en/package_reference/hf_api#huggingface_hub.ModelFilter">ModelFilter</a> which can be used to identify models
on the Hub.`,name:"filter"},{anchor:"huggingface_hub.HfApi.list_models.author",description:`<strong>author</strong> (<code>str</code>, <em>optional</em>) &#x2014;
A string which identify the author (user or organization) of the
returned models`,name:"author"},{anchor:"huggingface_hub.HfApi.list_models.search",description:`<strong>search</strong> (<code>str</code>, <em>optional</em>) &#x2014;
A string that will be contained in the returned models Example
usage:`,name:"search"},{anchor:"huggingface_hub.HfApi.list_models.emissions_thresholds",description:`<strong>emissions_thresholds</strong> (<code>Tuple</code>, <em>optional</em>) &#x2014;
A tuple of two ints or floats representing a minimum and maximum
carbon footprint to filter the resulting models with in grams.`,name:"emissions_thresholds"},{anchor:"huggingface_hub.HfApi.list_models.sort",description:`<strong>sort</strong> (<code>Literal[&quot;lastModified&quot;]</code> or <code>str</code>, <em>optional</em>) &#x2014;
The key with which to sort the resulting models. Possible values
are the properties of the <code>ModelInfo</code> class.`,name:"sort"},{anchor:"huggingface_hub.HfApi.list_models.direction",description:`<strong>direction</strong> (<code>Literal[-1]</code> or <code>int</code>, <em>optional</em>) &#x2014;
Direction in which to sort. The value <code>-1</code> sorts by descending
order while all other values sort by ascending order.`,name:"direction"},{anchor:"huggingface_hub.HfApi.list_models.limit",description:`<strong>limit</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The limit on the number of models fetched. Leaving this option
to <code>None</code> fetches all models.`,name:"limit"},{anchor:"huggingface_hub.HfApi.list_models.full",description:`<strong>full</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether to fetch all model data, including the <code>lastModified</code>,
the <code>sha</code>, the files and the <code>tags</code>. This is set to <code>True</code> by
default when using a filter.`,name:"full"},{anchor:"huggingface_hub.HfApi.list_models.cardData",description:`<strong>cardData</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether to grab the metadata for the model as well. Can contain
useful information such as carbon emissions, metrics, and
datasets trained on.`,name:"cardData"},{anchor:"huggingface_hub.HfApi.list_models.fetch_config",description:`<strong>fetch_config</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether to fetch the model configs as well. This is not included
in <code>full</code> due to its size.`,name:"fetch_config"},{anchor:"huggingface_hub.HfApi.list_models.use_auth_token",description:`<strong>use_auth_token</strong> (<code>bool</code> or <code>str</code>, <em>optional</em>) &#x2014;
Whether to use the <code>auth_token</code> provided from the
<code>huggingface_hub</code> cli. If not logged in, a valid <code>auth_token</code>
can be passed in as a string.`,name:"use_auth_token"}]}}),dt=new _e({props:{code:`from huggingface_hub import HfApi

api = HfApi()

# List all models
api.list_models()

# Get all valid search arguments
args = ModelSearchArguments()

# List only the text classification models
api.list_models(filter="text-classification")
# Using the \`ModelFilter\`
filt = ModelFilter(task="text-classification")
# With \`ModelSearchArguments\`
filt = ModelFilter(task=args.pipeline_tags.TextClassification)
api.list_models(filter=filt)

# Using \`ModelFilter\` and \`ModelSearchArguments\` to find text classification in both PyTorch and TensorFlow
filt = ModelFilter(
    task=args.pipeline_tags.TextClassification,
    library=[args.library.PyTorch, args.library.TensorFlow],
)
api.list_models(filter=filt)

# List only models from the AllenNLP library
api.list_models(filter="allennlp")
# Using \`ModelFilter\` and \`ModelSearchArguments\`
filt = ModelFilter(library=args.library.allennlp)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> HfApi

<span class="hljs-meta">&gt;&gt;&gt; </span>api = HfApi()

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># List all models</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_models()

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Get all valid search arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>args = ModelSearchArguments()

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># List only the text classification models</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_models(<span class="hljs-built_in">filter</span>=<span class="hljs-string">&quot;text-classification&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using the \`ModelFilter\`</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>filt = ModelFilter(task=<span class="hljs-string">&quot;text-classification&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># With \`ModelSearchArguments\`</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>filt = ModelFilter(task=args.pipeline_tags.TextClassification)
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_models(<span class="hljs-built_in">filter</span>=filt)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using \`ModelFilter\` and \`ModelSearchArguments\` to find text classification in both PyTorch and TensorFlow</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>filt = ModelFilter(
<span class="hljs-meta">... </span>    task=args.pipeline_tags.TextClassification,
<span class="hljs-meta">... </span>    library=[args.library.PyTorch, args.library.TensorFlow],
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_models(<span class="hljs-built_in">filter</span>=filt)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># List only models from the AllenNLP library</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_models(<span class="hljs-built_in">filter</span>=<span class="hljs-string">&quot;allennlp&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using \`ModelFilter\` and \`ModelSearchArguments\`</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>filt = ModelFilter(library=args.library.allennlp)`}}),ut=new _e({props:{code:`from huggingface_hub import HfApi

api = HfApi()

# List all models with "bert" in their name
api.list_models(search="bert")

# List all models with "bert" in their name made by google
api.list_models(search="bert", author="google")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> HfApi

<span class="hljs-meta">&gt;&gt;&gt; </span>api = HfApi()

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># List all models with &quot;bert&quot; in their name</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_models(search=<span class="hljs-string">&quot;bert&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># List all models with &quot;bert&quot; in their name made by google</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>api.list_models(search=<span class="hljs-string">&quot;bert&quot;</span>, author=<span class="hljs-string">&quot;google&quot;</span>)`}}),mt=new D({props:{name:"list_repo_files",anchor:"huggingface_hub.HfApi.list_repo_files",parameters:[{name:"repo_id",val:": str"},{name:"revision",val:": typing.Optional[str] = None"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"token",val:": typing.Optional[str] = None"},{name:"timeout",val:": typing.Optional[float] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1115",parametersDescription:[{anchor:"huggingface_hub.HfApi.list_repo_files.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
A namespace (user or an organization) and a repo name separated
by a <code>/</code>.`,name:"repo_id"},{anchor:"huggingface_hub.HfApi.list_repo_files.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The revision of the model repository from which to get the
information.`,name:"revision"},{anchor:"huggingface_hub.HfApi.list_repo_files.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if uploading to a dataset or
space, <code>None</code> or <code>&quot;model&quot;</code> if uploading to a model. Default is
<code>None</code>.`,name:"repo_type"},{anchor:"huggingface_hub.HfApi.list_repo_files.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An authentication token [1]_.`,name:"token"},{anchor:"huggingface_hub.HfApi.list_repo_files.timeout",description:`<strong>timeout</strong> (<code>float</code>, <em>optional</em>) &#x2014;
Whether to set a timeout for the request to the Hub.`,name:"timeout"}],returnDescription:`
<p>the list of files in a given repository.</p>
`,returnType:`
<p><code>List[str]</code></p>
`}}),bt=new D({props:{name:"login",anchor:"huggingface_hub.HfApi.login",parameters:[{name:"username",val:": str"},{name:"password",val:": str"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L468",parametersDescription:[{anchor:"huggingface_hub.HfApi.login.username",description:`<strong>username</strong> (<code>str</code>) &#x2014;
The username of the account with which to login.`,name:"username"},{anchor:"huggingface_hub.HfApi.login.password",description:`<strong>password</strong> (<code>str</code>) &#x2014;
The password of the account with which to login.`,name:"password"}],returnDescription:`
<p>token if credentials are valid</p>
`,returnType:`
<p><code>str</code></p>
`}}),je=new is({props:{$$slots:{default:[Hl]},$$scope:{ctx:J}}}),He=new is({props:{$$slots:{default:[El]},$$scope:{ctx:J}}}),vt=new D({props:{name:"logout",anchor:"huggingface_hub.HfApi.logout",parameters:[{name:"token",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L600",parametersDescription:[{anchor:"huggingface_hub.HfApi.logout.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Hugging Face token. Will default to the locally saved token if
not provided.`,name:"token"}]}}),Ee=new is({props:{$$slots:{default:[xl]},$$scope:{ctx:J}}}),$t=new D({props:{name:"model_info",anchor:"huggingface_hub.HfApi.model_info",parameters:[{name:"repo_id",val:": str"},{name:"revision",val:": typing.Optional[str] = None"},{name:"token",val:": typing.Optional[str] = None"},{name:"timeout",val:": typing.Optional[float] = None"},{name:"securityStatus",val:": typing.Optional[bool] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1061",parametersDescription:[{anchor:"huggingface_hub.HfApi.model_info.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
A namespace (user or an organization) and a repo name separated
by a <code>/</code>.`,name:"repo_id"},{anchor:"huggingface_hub.HfApi.model_info.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The revision of the model repository from which to get the
information.`,name:"revision"},{anchor:"huggingface_hub.HfApi.model_info.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An authentication token [1]_.`,name:"token"},{anchor:"huggingface_hub.HfApi.model_info.timeout",description:`<strong>timeout</strong> (<code>float</code>, <em>optional</em>) &#x2014;
Whether to set a timeout for the request to the Hub.`,name:"timeout"},{anchor:"huggingface_hub.HfApi.model_info.securityStatus",description:`<strong>securityStatus</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether to retrieve the security status from the model
repository as well.`,name:"securityStatus"}],returnDescription:`
<p>The model repository information.</p>
`,returnType:`
<p><code>ModelInfo</code></p>
`}}),kt=new D({props:{name:"move_repo",anchor:"huggingface_hub.HfApi.move_repo",parameters:[{name:"from_id",val:": str"},{name:"to_id",val:": str"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"token",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1511",parametersDescription:[{anchor:"huggingface_hub.HfApi.move_repo.from_id",description:`<strong>from_id</strong> (<code>str</code>) &#x2014;
A namespace (user or an organization) and a repo name separated
by a <code>/</code>. Original repository identifier.`,name:"from_id"},{anchor:"huggingface_hub.HfApi.move_repo.to_id",description:`<strong>to_id</strong> (<code>str</code>) &#x2014;
A namespace (user or an organization) and a repo name separated
by a <code>/</code>. Final repository identifier.`,name:"to_id"},{anchor:"huggingface_hub.HfApi.move_repo.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if uploading to a dataset or
space, <code>None</code> or <code>&quot;model&quot;</code> if uploading to a model. Default is
<code>None</code>.`,name:"repo_type"},{anchor:"huggingface_hub.HfApi.move_repo.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An authentication token [1]_.`,name:"token"}]}}),Ht=new D({props:{name:"set_access_token",anchor:"huggingface_hub.HfApi.set_access_token",parameters:[{name:"access_token",val:": str"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L636",parametersDescription:[{anchor:"huggingface_hub.HfApi.set_access_token.access_token",description:`<strong>access_token</strong> (<code>str</code>) &#x2014;
The access token to save.`,name:"access_token"}]}}),Et=new D({props:{name:"unset_access_token",anchor:"huggingface_hub.HfApi.unset_access_token",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L648"}}),xt=new D({props:{name:"update_repo_visibility",anchor:"huggingface_hub.HfApi.update_repo_visibility",parameters:[{name:"repo_id",val:": str = None"},{name:"private",val:": bool = False"},{name:"token",val:": typing.Optional[str] = None"},{name:"organization",val:": typing.Optional[str] = None"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"name",val:": str = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1441",parametersDescription:[{anchor:"huggingface_hub.HfApi.update_repo_visibility.repo_id",description:`<strong>repo_id</strong> (<code>str</code>, <em>optional</em>) &#x2014;
A namespace (user or an organization) and a repo name separated
by a <code>/</code>.</p>
<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">
						
<p>Version added: 0.5</p>

					</div>`,name:"repo_id"},{anchor:"huggingface_hub.HfApi.update_repo_visibility.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether the model repo should be private.`,name:"private"},{anchor:"huggingface_hub.HfApi.update_repo_visibility.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An authentication token [1]_.`,name:"token"},{anchor:"huggingface_hub.HfApi.update_repo_visibility.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if uploading to a dataset or
space, <code>None</code> or <code>&quot;model&quot;</code> if uploading to a model. Default is
<code>None</code>.`,name:"repo_type"}],returnDescription:`
<p>The HTTP response in json.</p>
`}}),qt=new D({props:{name:"upload_file",anchor:"huggingface_hub.HfApi.upload_file",parameters:[{name:"path_or_fileobj",val:": typing.Union[str, bytes, typing.IO]"},{name:"path_in_repo",val:": str"},{name:"repo_id",val:": str"},{name:"token",val:": typing.Optional[str] = None"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"revision",val:": typing.Optional[str] = None"},{name:"identical_ok",val:": bool = True"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1580",parametersDescription:[{anchor:"huggingface_hub.HfApi.upload_file.path_or_fileobj",description:`<strong>path_or_fileobj</strong> (<code>str</code>, <code>bytes</code>, or <code>IO</code>) &#x2014;
Path to a file on the local machine or binary data stream /
fileobj / buffer.`,name:"path_or_fileobj"},{anchor:"huggingface_hub.HfApi.upload_file.path_in_repo",description:`<strong>path_in_repo</strong> (<code>str</code>) &#x2014;
Relative filepath in the repo, for example:
<code>&quot;checkpoints/1fec34a/weights.bin&quot;</code>`,name:"path_in_repo"},{anchor:"huggingface_hub.HfApi.upload_file.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
The repository to which the file will be uploaded, for example:
<code>&quot;username/custom_transformers&quot;</code>`,name:"repo_id"},{anchor:"huggingface_hub.HfApi.upload_file.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Authentication token, obtained with <code>HfApi.login</code> method. Will
default to the stored token.`,name:"token"},{anchor:"huggingface_hub.HfApi.upload_file.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if uploading to a dataset or
space, <code>None</code> or <code>&quot;model&quot;</code> if uploading to a model. Default is
<code>None</code>.`,name:"repo_type"},{anchor:"huggingface_hub.HfApi.upload_file.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The git revision to commit from. Defaults to the head of the
<code>&quot;main&quot;</code> branch.`,name:"revision"},{anchor:"huggingface_hub.HfApi.upload_file.identical_ok",description:`<strong>identical_ok</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
When set to false, will raise an <a href="https://2.python-requests.org/en/master/api/#requests.HTTPError" rel="nofollow">HTTPError</a>
when the file you&#x2019;re trying to upload already exists on the hub
and its content did not change.`,name:"identical_ok"}],returnDescription:`
<p>The URL to visualize the uploaded file on the hub</p>
`,returnType:`
<p><code>str</code></p>
`}}),qe=new is({props:{$$slots:{default:[Dl]},$$scope:{ctx:J}}}),Ft=new _e({props:{code:`with open("./local/filepath", "rb") as fobj:
    upload_file(
        path_or_fileobj=fileobj,
        path_in_repo="remote/file/path.h5",
        repo_id="username/my-dataset",
        repo_type="datasets",
        token="my_token",
    )

upload_file(
    path_or_fileobj=".\\\\local\\\\file\\\\path",
    path_in_repo="remote/file/path.h5",
    repo_id="username/my-model",
    token="my_token",
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;./local/filepath&quot;</span>, <span class="hljs-string">&quot;rb&quot;</span>) <span class="hljs-keyword">as</span> fobj:
<span class="hljs-meta">... </span>    upload_file(
<span class="hljs-meta">... </span>        path_or_fileobj=fileobj,
<span class="hljs-meta">... </span>        path_in_repo=<span class="hljs-string">&quot;remote/file/path.h5&quot;</span>,
<span class="hljs-meta">... </span>        repo_id=<span class="hljs-string">&quot;username/my-dataset&quot;</span>,
<span class="hljs-meta">... </span>        repo_type=<span class="hljs-string">&quot;datasets&quot;</span>,
<span class="hljs-meta">... </span>        token=<span class="hljs-string">&quot;my_token&quot;</span>,
<span class="hljs-meta">... </span>    )
<span class="hljs-string">&quot;https://huggingface.co/datasets/username/my-dataset/blob/main/remote/file/path.h5&quot;</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>upload_file(
<span class="hljs-meta">... </span>    path_or_fileobj=<span class="hljs-string">&quot;.\\\\local\\\\file\\\\path&quot;</span>,
<span class="hljs-meta">... </span>    path_in_repo=<span class="hljs-string">&quot;remote/file/path.h5&quot;</span>,
<span class="hljs-meta">... </span>    repo_id=<span class="hljs-string">&quot;username/my-model&quot;</span>,
<span class="hljs-meta">... </span>    token=<span class="hljs-string">&quot;my_token&quot;</span>,
<span class="hljs-meta">... </span>)
<span class="hljs-string">&quot;https://huggingface.co/username/my-model/blob/main/remote/file/path.h5&quot;</span>`}}),Nt=new D({props:{name:"whoami",anchor:"huggingface_hub.HfApi.whoami",parameters:[{name:"token",val:": typing.Optional[str] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L510",parametersDescription:[{anchor:"huggingface_hub.HfApi.whoami.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Hugging Face token. Will default to the locally saved token if
not provided.`,name:"token"}]}}),Pt=new ni({}),Tt=new D({props:{name:"class huggingface_hub.HfFolder",anchor:"huggingface_hub.HfFolder",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1819"}}),It=new D({props:{name:"delete_token",anchor:"huggingface_hub.HfFolder.delete_token",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1850"}}),Mt=new D({props:{name:"get_token",anchor:"huggingface_hub.HfFolder.get_token",parameters:[],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1835",returnDescription:`
<p>The token, <code>None</code> if it doesn\u2019t exist.</p>
`,returnType:`
<p><code>str</code> or <code>None</code></p>
`}}),Ot=new D({props:{name:"save_token",anchor:"huggingface_hub.HfFolder.save_token",parameters:[{name:"token",val:""}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/hf_api.py#L1822",parametersDescription:[{anchor:"huggingface_hub.HfFolder.save_token.token",description:`<strong>token</strong> (<code>str</code>) &#x2014;
The token to save to the <a href="/docs/huggingface_hub/main/en/package_reference/hf_api#huggingface_hub.HfFolder">HfFolder</a>`,name:"token"}]}}),Ut=new ni({}),Ct=new D({props:{name:"class huggingface_hub.DatasetFilter",anchor:"huggingface_hub.DatasetFilter",parameters:[{name:"author",val:": str = None"},{name:"benchmark",val:": typing.Union[str, typing.List[str]] = None"},{name:"dataset_name",val:": str = None"},{name:"language_creators",val:": typing.Union[str, typing.List[str]] = None"},{name:"languages",val:": typing.Union[str, typing.List[str]] = None"},{name:"multilinguality",val:": typing.Union[str, typing.List[str]] = None"},{name:"size_categories",val:": typing.Union[str, typing.List[str]] = None"},{name:"task_categories",val:": typing.Union[str, typing.List[str]] = None"},{name:"task_ids",val:": typing.Union[str, typing.List[str]] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/utils/endpoint_helpers.py#L67",parametersDescription:[{anchor:"huggingface_hub.DatasetFilter.author",description:`<strong>author</strong> (<code>str</code>, <em>optional</em>) &#x2014;
A string or list of strings that can be used to identify datasets on
the Hub by the original uploader (author or organization), such as
<code>facebook</code> or <code>huggingface</code>.`,name:"author"},{anchor:"huggingface_hub.DatasetFilter.benchmark",description:`<strong>benchmark</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string or list of strings that can be used to identify datasets on
the Hub by their official benchmark.`,name:"benchmark"},{anchor:"huggingface_hub.DatasetFilter.dataset_name",description:`<strong>dataset_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
A string or list of strings that can be used to identify datasets on
the Hub by its name, such as <code>SQAC</code> or <code>wikineural</code>`,name:"dataset_name"},{anchor:"huggingface_hub.DatasetFilter.language_creators",description:`<strong>language_creators</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string or list of strings that can be used to identify datasets on
the Hub with how the data was curated, such as <code>crowdsourced</code> or
<code>machine_generated</code>.`,name:"language_creators"},{anchor:"huggingface_hub.DatasetFilter.languages",description:`<strong>languages</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string or list of strings representing a two-character language to
filter datasets by on the Hub.`,name:"languages"},{anchor:"huggingface_hub.DatasetFilter.multilinguality",description:`<strong>multilinguality</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string or list of strings representing a filter for datasets that
contain multiple languages.`,name:"multilinguality"},{anchor:"huggingface_hub.DatasetFilter.size_categories",description:`<strong>size_categories</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string or list of strings that can be used to identify datasets on
the Hub by the size of the dataset such as <code>100K&lt;n&lt;1M</code> or
<code>1M&lt;n&lt;10M</code>.`,name:"size_categories"},{anchor:"huggingface_hub.DatasetFilter.task_categories",description:`<strong>task_categories</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string or list of strings that can be used to identify datasets on
the Hub by the designed task, such as <code>audio_classification</code> or
<code>named_entity_recognition</code>.`,name:"task_categories"},{anchor:"huggingface_hub.DatasetFilter.task_ids",description:`<strong>task_ids</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string or list of strings that can be used to identify datasets on
the Hub by the specific task such as <code>speech_emotion_recognition</code> or
<code>paraphrase</code>.`,name:"task_ids"}]}}),St=new _e({props:{code:`from huggingface_hub import DatasetFilter

# Using author
new_filter = DatasetFilter(author="facebook")

# Using benchmark
new_filter = DatasetFilter(benchmark="raft")

# Using dataset_name
new_filter = DatasetFilter(dataset_name="wikineural")

# Using language_creator
new_filter = DatasetFilter(language_creator="crowdsourced")

# Using language
new_filter = DatasetFilter(language="en")

# Using multilinguality
new_filter = DatasetFilter(multilinguality="yes")

# Using size_categories
new_filter = DatasetFilter(size_categories="100K<n<1M")

# Using task_categories
new_filter = DatasetFilter(task_categories="audio_classification")

# Using task_ids
new_filter = DatasetFilter(task_ids="paraphrase")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> DatasetFilter

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using author</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = DatasetFilter(author=<span class="hljs-string">&quot;facebook&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using benchmark</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = DatasetFilter(benchmark=<span class="hljs-string">&quot;raft&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using dataset_name</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = DatasetFilter(dataset_name=<span class="hljs-string">&quot;wikineural&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using language_creator</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = DatasetFilter(language_creator=<span class="hljs-string">&quot;crowdsourced&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using language</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = DatasetFilter(language=<span class="hljs-string">&quot;en&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using multilinguality</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = DatasetFilter(multilinguality=<span class="hljs-string">&quot;yes&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using size_categories</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = DatasetFilter(size_categories=<span class="hljs-string">&quot;100K&lt;n&lt;1M&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using task_categories</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = DatasetFilter(task_categories=<span class="hljs-string">&quot;audio_classification&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Using task_ids</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = DatasetFilter(task_ids=<span class="hljs-string">&quot;paraphrase&quot;</span>)`}}),zt=new D({props:{name:"class huggingface_hub.ModelFilter",anchor:"huggingface_hub.ModelFilter",parameters:[{name:"author",val:": str = None"},{name:"library",val:": typing.Union[str, typing.List[str]] = None"},{name:"language",val:": typing.Union[str, typing.List[str]] = None"},{name:"model_name",val:": str = None"},{name:"task",val:": typing.Union[str, typing.List[str]] = None"},{name:"trained_dataset",val:": typing.Union[str, typing.List[str]] = None"},{name:"tags",val:": typing.Union[str, typing.List[str]] = None"}],source:"https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/utils/endpoint_helpers.py#L153",parametersDescription:[{anchor:"huggingface_hub.ModelFilter.author",description:`<strong>author</strong> (<code>str</code>, <em>optional</em>) &#x2014;
A string that can be used to identify models on the Hub by the
original uploader (author or organization), such as <code>facebook</code> or
<code>huggingface</code>.`,name:"author"},{anchor:"huggingface_hub.ModelFilter.library",description:`<strong>library</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string or list of strings of foundational libraries models were
originally trained from, such as pytorch, tensorflow, or allennlp.`,name:"library"},{anchor:"huggingface_hub.ModelFilter.language",description:`<strong>language</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string or list of strings of languages, both by name and country
code, such as &#x201C;en&#x201D; or &#x201C;English&#x201D;`,name:"language"},{anchor:"huggingface_hub.ModelFilter.model_name",description:`<strong>model_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
A string that contain complete or partial names for models on the
Hub, such as &#x201C;bert&#x201D; or &#x201C;bert-base-cased&#x201D;`,name:"model_name"},{anchor:"huggingface_hub.ModelFilter.task",description:`<strong>task</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string or list of strings of tasks models were designed for, such
as: &#x201C;fill-mask&#x201D; or &#x201C;automatic-speech-recognition&#x201D;`,name:"task"},{anchor:"huggingface_hub.ModelFilter.tags",description:`<strong>tags</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string tag or a list of tags to filter models on the Hub by, such
as <code>text-generation</code> or <code>spacy</code>.`,name:"tags"},{anchor:"huggingface_hub.ModelFilter.trained_dataset",description:`<strong>trained_dataset</strong> (<code>str</code> or <code>List</code>, <em>optional</em>) &#x2014;
A string tag or a list of string tags of the trained dataset for a
model on the Hub.`,name:"trained_dataset"}]}}),Rt=new _e({props:{code:`from huggingface_hub import ModelFilter

# For the author_or_organization
new_filter = ModelFilter(author_or_organization="facebook")

# For the library
new_filter = ModelFilter(library="pytorch")

# For the language
new_filter = ModelFilter(language="french")

# For the model_name
new_filter = ModelFilter(model_name="bert")

# For the task
new_filter = ModelFilter(task="text-classification")

# Retrieving tags using the \`HfApi.get_model_tags\` method
from huggingface_hub import HfApi

api = HfApi()

api.get_model_tags()

api.get_dataset_tags()
new_filter = ModelFilter(tags="benchmark:raft")

# Related to the dataset
new_filter = ModelFilter(trained_dataset="common_voice")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> ModelFilter

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># For the author_or_organization</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = ModelFilter(author_or_organization=<span class="hljs-string">&quot;facebook&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># For the library</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = ModelFilter(library=<span class="hljs-string">&quot;pytorch&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># For the language</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = ModelFilter(language=<span class="hljs-string">&quot;french&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># For the model_name</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = ModelFilter(model_name=<span class="hljs-string">&quot;bert&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># For the task</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = ModelFilter(task=<span class="hljs-string">&quot;text-classification&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Retrieving tags using the \`HfApi.get_model_tags\` method</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> HfApi

<span class="hljs-meta">&gt;&gt;&gt; </span>api = HfApi()
<span class="hljs-comment"># To list model tags</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>api.get_model_tags()
<span class="hljs-comment"># To list dataset tags</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>api.get_dataset_tags()
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = ModelFilter(tags=<span class="hljs-string">&quot;benchmark:raft&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Related to the dataset</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>new_filter = ModelFilter(trained_dataset=<span class="hljs-string">&quot;common_voice&quot;</span>)`}}),{c(){p=s("meta"),q=r(),A=s("h1"),w=s("a"),H=s("span"),f($.$$.fragment),j=r(),N=s("span"),O=l("Hugging Face Hub API"),F=r(),E=s("p"),P=l("Below is the documentation for the "),T=s("code"),U=l("HfApi"),C=l(` class, which serves as a Python wrapper for the Hugging Face
Hub\u2019s API.`),x=r(),L=s("p"),W=l("All methods from the "),G=s("code"),he=l("HfApi"),de=l(` are also accessible from the package\u2019s root directly, both approaches are detailed
below.`),Q=r(),X=s("p"),fe=l("The following approach uses the method from the root of the package:"),ls=r(),f(Ge.$$.fragment),gs=r(),be=s("p"),Vs=l("The following approach uses the "),sa=s("code"),Ws=l("HfApi"),Gs=l(" class:"),cs=r(),f(Be.$$.fragment),ps=r(),ve=s("p"),Bs=l("Using the "),na=s("code"),Ks=l("HfApi"),Js=l(" class directly enables you to set a different endpoint to that of the Hugging Face\u2019s Hub."),hs=r(),d=s("div"),f(Ke.$$.fragment),Qs=r(),Y=s("div"),f(Je.$$.fragment),Xs=r(),oa=s("p"),Ys=l("Create an empty repo on the HuggingFace Hub."),Zs=r(),ra=s("p"),en=l("References:"),tn=r(),ia=s("ul"),Gt=s("li"),an=l("[1] "),Qe=s("a"),sn=l("https://huggingface.co/settings/tokens"),nn=r(),S=s("div"),f(Xe.$$.fragment),on=r(),la=s("p"),rn=l("Get info on one specific dataset on huggingface.co"),ln=r(),ga=s("p"),gn=l("Dataset can be private if you pass an acceptable token."),cn=r(),ca=s("p"),pn=l("References:"),hn=r(),pa=s("ul"),Bt=s("li"),dn=l("[1] "),Ye=s("a"),fn=l("https://huggingface.co/settings/tokens"),un=r(),re=s("div"),f(Ze.$$.fragment),mn=r(),ha=s("p"),_n=l("Deletes a file in the given repo."),bn=r(),f($e.$$.fragment),vn=r(),Z=s("div"),f(et.$$.fragment),$n=r(),da=s("p"),yn=l("Delete a repo from the HuggingFace Hub. CAUTION: this is irreversible."),kn=r(),fa=s("p"),wn=l("References:"),An=r(),ua=s("ul"),Kt=s("li"),jn=l("[1] "),tt=s("a"),Hn=l("https://huggingface.co/settings/tokens"),En=r(),ye=s("div"),f(at.$$.fragment),xn=r(),ma=s("p"),Dn=l("Gets all valid dataset tags as a nested namespace object."),qn=r(),ke=s("div"),f(st.$$.fragment),Fn=r(),_a=s("p"),Nn=l(`Returns the repository name for a given model ID and optional
organization.`),Pn=r(),we=s("div"),f(nt.$$.fragment),Ln=r(),ba=s("p"),Tn=l("Gets all valid model tags as a nested namespace object"),In=r(),I=s("div"),f(ot.$$.fragment),Mn=r(),va=s("p"),On=l("Get the public list of all the datasets on huggingface.co"),Un=r(),rt=s("p"),Cn=l("Example usage with the "),$a=s("code"),Sn=l("filter"),zn=l(" argument:"),Rn=r(),f(it.$$.fragment),Vn=r(),lt=s("p"),Wn=l("Example usage with the "),ya=s("code"),Gn=l("search"),Bn=l(" argument:"),Kn=r(),f(gt.$$.fragment),Jn=r(),Ae=s("div"),f(ct.$$.fragment),Qn=r(),ka=s("p"),Xn=l("Get the public list of all the metrics on huggingface.co"),Yn=r(),M=s("div"),f(pt.$$.fragment),Zn=r(),wa=s("p"),eo=l("Get the public list of all the models on huggingface.co"),to=r(),ht=s("p"),ao=l("Example usage with the "),Aa=s("code"),so=l("filter"),no=l(" argument:"),oo=r(),f(dt.$$.fragment),ro=r(),ft=s("p"),io=l("Example usage with the "),ja=s("code"),lo=l("search"),go=l(" argument:"),co=r(),f(ut.$$.fragment),po=r(),ee=s("div"),f(mt.$$.fragment),ho=r(),Ha=s("p"),fo=l("Get the list of files in a given repo."),uo=r(),Ea=s("p"),mo=l("References:"),_o=r(),xa=s("ul"),Jt=s("li"),bo=l("[1] "),_t=s("a"),vo=l("https://huggingface.co/settings/tokens"),$o=r(),te=s("div"),f(bt.$$.fragment),yo=r(),Da=s("p"),ko=l("Call HF API to sign in a user and get a token if credentials are valid."),wo=r(),f(je.$$.fragment),Ao=r(),f(He.$$.fragment),jo=r(),ie=s("div"),f(vt.$$.fragment),Ho=r(),qa=s("p"),Eo=l("Call HF API to log out."),xo=r(),f(Ee.$$.fragment),Do=r(),z=s("div"),f($t.$$.fragment),qo=r(),Fa=s("p"),Fo=l("Get info on one specific model on huggingface.co"),No=r(),Na=s("p"),Po=l("Model can be private if you pass an acceptable token or are logged in."),Lo=r(),Pa=s("p"),To=l("References:"),Io=r(),La=s("ul"),Qt=s("li"),Mo=l("[1] "),yt=s("a"),Oo=l("https://huggingface.co/settings/tokens"),Uo=r(),R=s("div"),f(kt.$$.fragment),Co=r(),Ta=s("p"),So=l("Moving a repository from namespace1/repo_name1 to namespace2/repo_name2"),zo=r(),wt=s("p"),Ro=l(`Note there are certain limitations. For more information about moving
repositories, please see
`),At=s("a"),Vo=l("https://hf.co/docs/hub/main#how-can-i-rename-or-transfer-a-repo"),Wo=l("."),Go=r(),Ia=s("p"),Bo=l("References:"),Ko=r(),Ma=s("ul"),Xt=s("li"),Jo=l("[1] "),jt=s("a"),Qo=l("https://huggingface.co/settings/tokens"),Xo=r(),xe=s("div"),f(Ht.$$.fragment),Yo=r(),Oa=s("p"),Zo=l(`Saves the passed access token so git can correctly authenticate the
user.`),er=r(),De=s("div"),f(Et.$$.fragment),tr=r(),Ua=s("p"),ar=l("Resets the user\u2019s access token."),sr=r(),ae=s("div"),f(xt.$$.fragment),nr=r(),Ca=s("p"),or=l("Update the visibility setting of a repository."),rr=r(),Sa=s("p"),ir=l("References:"),lr=r(),za=s("ul"),Yt=s("li"),gr=l("[1] "),Dt=s("a"),cr=l("https://huggingface.co/settings/tokens"),pr=r(),V=s("div"),f(qt.$$.fragment),hr=r(),Ra=s("p"),dr=l(`Upload a local file (up to 5GB) to the given repo. The upload is done
through a HTTP post request, and doesn\u2019t require git or git-lfs to be
installed.`),fr=r(),f(qe.$$.fragment),ur=r(),Va=s("p"),mr=l("Example usage:"),_r=r(),f(Ft.$$.fragment),br=r(),Fe=s("div"),f(Nt.$$.fragment),vr=r(),Wa=s("p"),$r=l("Call HF API to know \u201Cwhoami\u201D."),ds=r(),ue=s("h2"),Ne=s("a"),Ga=s("span"),f(Pt.$$.fragment),yr=r(),Ba=s("span"),kr=l("Hugging Face local storage"),fs=r(),Lt=s("p"),Ka=s("code"),wr=l("huggingface_hub"),Ar=l(` stores the authentication information locally so that it may be re-used in subsequent
methods.`),us=r(),Pe=s("p"),jr=l("It does this using the "),Zt=s("a"),Hr=l("HfFolder"),Er=l(" utility, which saves data at the root of the user."),ms=r(),B=s("div"),f(Tt.$$.fragment),xr=r(),Le=s("div"),f(It.$$.fragment),Dr=r(),Ja=s("p"),qr=l("Deletes the token from storage. Does not fail if token does not exist."),Fr=r(),Te=s("div"),f(Mt.$$.fragment),Nr=r(),Qa=s("p"),Pr=l("Retrieves the token"),Lr=r(),Ie=s("div"),f(Ot.$$.fragment),Tr=r(),Xa=s("p"),Ir=l("Save token, creating folder as needed."),_s=r(),me=s("h2"),Me=s("a"),Ya=s("span"),f(Ut.$$.fragment),Mr=r(),Za=s("span"),Or=l("Filtering helpers"),bs=r(),Oe=s("p"),Ur=l("Some helpers to filter repositories on the Hub are available in the "),es=s("code"),Cr=l("huggingface_hub"),Sr=l(" package."),vs=r(),K=s("div"),f(Ct.$$.fragment),zr=r(),ts=s("p"),Rr=l(`A class that converts human-readable dataset search parameters into ones
compatible with the REST API. For all parameters capitalization does not
matter.`),Vr=r(),as=s("p"),Wr=l("Examples:"),Gr=r(),f(St.$$.fragment),$s=r(),oe=s("div"),f(zt.$$.fragment),Br=r(),ss=s("p"),Kr=l(`A class that converts human-readable model search parameters into ones
compatible with the REST API. For all parameters capitalization does not
matter.`),Jr=r(),f(Rt.$$.fragment),this.h()},l(t){const h=wl('[data-svelte="svelte-1phssyn"]',document.head);p=n(h,"META",{name:!0,content:!0}),h.forEach(a),q=i(t),A=n(t,"H1",{class:!0});var Vt=o(A);w=n(Vt,"A",{id:!0,class:!0,href:!0});var ns=o(w);H=n(ns,"SPAN",{});var os=o(H);u($.$$.fragment,os),os.forEach(a),ns.forEach(a),j=i(Vt),N=n(Vt,"SPAN",{});var rs=o(N);O=g(rs,"Hugging Face Hub API"),rs.forEach(a),Vt.forEach(a),F=i(t),E=n(t,"P",{});var Wt=o(E);P=g(Wt,"Below is the documentation for the "),T=n(Wt,"CODE",{});var oi=o(T);U=g(oi,"HfApi"),oi.forEach(a),C=g(Wt,` class, which serves as a Python wrapper for the Hugging Face
Hub\u2019s API.`),Wt.forEach(a),x=i(t),L=n(t,"P",{});var ks=o(L);W=g(ks,"All methods from the "),G=n(ks,"CODE",{});var ri=o(G);he=g(ri,"HfApi"),ri.forEach(a),de=g(ks,` are also accessible from the package\u2019s root directly, both approaches are detailed
below.`),ks.forEach(a),Q=i(t),X=n(t,"P",{});var ii=o(X);fe=g(ii,"The following approach uses the method from the root of the package:"),ii.forEach(a),ls=i(t),u(Ge.$$.fragment,t),gs=i(t),be=n(t,"P",{});var ws=o(be);Vs=g(ws,"The following approach uses the "),sa=n(ws,"CODE",{});var li=o(sa);Ws=g(li,"HfApi"),li.forEach(a),Gs=g(ws," class:"),ws.forEach(a),cs=i(t),u(Be.$$.fragment,t),ps=i(t),ve=n(t,"P",{});var As=o(ve);Bs=g(As,"Using the "),na=n(As,"CODE",{});var gi=o(na);Ks=g(gi,"HfApi"),gi.forEach(a),Js=g(As," class directly enables you to set a different endpoint to that of the Hugging Face\u2019s Hub."),As.forEach(a),hs=i(t),d=n(t,"DIV",{class:!0});var k=o(d);u(Ke.$$.fragment,k),Qs=i(k),Y=n(k,"DIV",{class:!0});var Ue=o(Y);u(Je.$$.fragment,Ue),Xs=i(Ue),oa=n(Ue,"P",{});var ci=o(oa);Ys=g(ci,"Create an empty repo on the HuggingFace Hub."),ci.forEach(a),Zs=i(Ue),ra=n(Ue,"P",{});var pi=o(ra);en=g(pi,"References:"),pi.forEach(a),tn=i(Ue),ia=n(Ue,"UL",{});var hi=o(ia);Gt=n(hi,"LI",{});var Qr=o(Gt);an=g(Qr,"[1] "),Qe=n(Qr,"A",{href:!0,rel:!0});var di=o(Qe);sn=g(di,"https://huggingface.co/settings/tokens"),di.forEach(a),Qr.forEach(a),hi.forEach(a),Ue.forEach(a),nn=i(k),S=n(k,"DIV",{class:!0});var le=o(S);u(Xe.$$.fragment,le),on=i(le),la=n(le,"P",{});var fi=o(la);rn=g(fi,"Get info on one specific dataset on huggingface.co"),fi.forEach(a),ln=i(le),ga=n(le,"P",{});var ui=o(ga);gn=g(ui,"Dataset can be private if you pass an acceptable token."),ui.forEach(a),cn=i(le),ca=n(le,"P",{});var mi=o(ca);pn=g(mi,"References:"),mi.forEach(a),hn=i(le),pa=n(le,"UL",{});var _i=o(pa);Bt=n(_i,"LI",{});var Xr=o(Bt);dn=g(Xr,"[1] "),Ye=n(Xr,"A",{href:!0,rel:!0});var bi=o(Ye);fn=g(bi,"https://huggingface.co/settings/tokens"),bi.forEach(a),Xr.forEach(a),_i.forEach(a),le.forEach(a),un=i(k),re=n(k,"DIV",{class:!0});var ea=o(re);u(Ze.$$.fragment,ea),mn=i(ea),ha=n(ea,"P",{});var vi=o(ha);_n=g(vi,"Deletes a file in the given repo."),vi.forEach(a),bn=i(ea),u($e.$$.fragment,ea),ea.forEach(a),vn=i(k),Z=n(k,"DIV",{class:!0});var Ce=o(Z);u(et.$$.fragment,Ce),$n=i(Ce),da=n(Ce,"P",{});var $i=o(da);yn=g($i,"Delete a repo from the HuggingFace Hub. CAUTION: this is irreversible."),$i.forEach(a),kn=i(Ce),fa=n(Ce,"P",{});var yi=o(fa);wn=g(yi,"References:"),yi.forEach(a),An=i(Ce),ua=n(Ce,"UL",{});var ki=o(ua);Kt=n(ki,"LI",{});var Yr=o(Kt);jn=g(Yr,"[1] "),tt=n(Yr,"A",{href:!0,rel:!0});var wi=o(tt);Hn=g(wi,"https://huggingface.co/settings/tokens"),wi.forEach(a),Yr.forEach(a),ki.forEach(a),Ce.forEach(a),En=i(k),ye=n(k,"DIV",{class:!0});var js=o(ye);u(at.$$.fragment,js),xn=i(js),ma=n(js,"P",{});var Ai=o(ma);Dn=g(Ai,"Gets all valid dataset tags as a nested namespace object."),Ai.forEach(a),js.forEach(a),qn=i(k),ke=n(k,"DIV",{class:!0});var Hs=o(ke);u(st.$$.fragment,Hs),Fn=i(Hs),_a=n(Hs,"P",{});var ji=o(_a);Nn=g(ji,`Returns the repository name for a given model ID and optional
organization.`),ji.forEach(a),Hs.forEach(a),Pn=i(k),we=n(k,"DIV",{class:!0});var Es=o(we);u(nt.$$.fragment,Es),Ln=i(Es),ba=n(Es,"P",{});var Hi=o(ba);Tn=g(Hi,"Gets all valid model tags as a nested namespace object"),Hi.forEach(a),Es.forEach(a),In=i(k),I=n(k,"DIV",{class:!0});var se=o(I);u(ot.$$.fragment,se),Mn=i(se),va=n(se,"P",{});var Ei=o(va);On=g(Ei,"Get the public list of all the datasets on huggingface.co"),Ei.forEach(a),Un=i(se),rt=n(se,"P",{});var xs=o(rt);Cn=g(xs,"Example usage with the "),$a=n(xs,"CODE",{});var xi=o($a);Sn=g(xi,"filter"),xi.forEach(a),zn=g(xs," argument:"),xs.forEach(a),Rn=i(se),u(it.$$.fragment,se),Vn=i(se),lt=n(se,"P",{});var Ds=o(lt);Wn=g(Ds,"Example usage with the "),ya=n(Ds,"CODE",{});var Di=o(ya);Gn=g(Di,"search"),Di.forEach(a),Bn=g(Ds," argument:"),Ds.forEach(a),Kn=i(se),u(gt.$$.fragment,se),se.forEach(a),Jn=i(k),Ae=n(k,"DIV",{class:!0});var qs=o(Ae);u(ct.$$.fragment,qs),Qn=i(qs),ka=n(qs,"P",{});var qi=o(ka);Xn=g(qi,"Get the public list of all the metrics on huggingface.co"),qi.forEach(a),qs.forEach(a),Yn=i(k),M=n(k,"DIV",{class:!0});var ne=o(M);u(pt.$$.fragment,ne),Zn=i(ne),wa=n(ne,"P",{});var Fi=o(wa);eo=g(Fi,"Get the public list of all the models on huggingface.co"),Fi.forEach(a),to=i(ne),ht=n(ne,"P",{});var Fs=o(ht);ao=g(Fs,"Example usage with the "),Aa=n(Fs,"CODE",{});var Ni=o(Aa);so=g(Ni,"filter"),Ni.forEach(a),no=g(Fs," argument:"),Fs.forEach(a),oo=i(ne),u(dt.$$.fragment,ne),ro=i(ne),ft=n(ne,"P",{});var Ns=o(ft);io=g(Ns,"Example usage with the "),ja=n(Ns,"CODE",{});var Pi=o(ja);lo=g(Pi,"search"),Pi.forEach(a),go=g(Ns," argument:"),Ns.forEach(a),co=i(ne),u(ut.$$.fragment,ne),ne.forEach(a),po=i(k),ee=n(k,"DIV",{class:!0});var Se=o(ee);u(mt.$$.fragment,Se),ho=i(Se),Ha=n(Se,"P",{});var Li=o(Ha);fo=g(Li,"Get the list of files in a given repo."),Li.forEach(a),uo=i(Se),Ea=n(Se,"P",{});var Ti=o(Ea);mo=g(Ti,"References:"),Ti.forEach(a),_o=i(Se),xa=n(Se,"UL",{});var Ii=o(xa);Jt=n(Ii,"LI",{});var Zr=o(Jt);bo=g(Zr,"[1] "),_t=n(Zr,"A",{href:!0,rel:!0});var Mi=o(_t);vo=g(Mi,"https://huggingface.co/settings/tokens"),Mi.forEach(a),Zr.forEach(a),Ii.forEach(a),Se.forEach(a),$o=i(k),te=n(k,"DIV",{class:!0});var ze=o(te);u(bt.$$.fragment,ze),yo=i(ze),Da=n(ze,"P",{});var Oi=o(Da);ko=g(Oi,"Call HF API to sign in a user and get a token if credentials are valid."),Oi.forEach(a),wo=i(ze),u(je.$$.fragment,ze),Ao=i(ze),u(He.$$.fragment,ze),ze.forEach(a),jo=i(k),ie=n(k,"DIV",{class:!0});var ta=o(ie);u(vt.$$.fragment,ta),Ho=i(ta),qa=n(ta,"P",{});var Ui=o(qa);Eo=g(Ui,"Call HF API to log out."),Ui.forEach(a),xo=i(ta),u(Ee.$$.fragment,ta),ta.forEach(a),Do=i(k),z=n(k,"DIV",{class:!0});var ge=o(z);u($t.$$.fragment,ge),qo=i(ge),Fa=n(ge,"P",{});var Ci=o(Fa);Fo=g(Ci,"Get info on one specific model on huggingface.co"),Ci.forEach(a),No=i(ge),Na=n(ge,"P",{});var Si=o(Na);Po=g(Si,"Model can be private if you pass an acceptable token or are logged in."),Si.forEach(a),Lo=i(ge),Pa=n(ge,"P",{});var zi=o(Pa);To=g(zi,"References:"),zi.forEach(a),Io=i(ge),La=n(ge,"UL",{});var Ri=o(La);Qt=n(Ri,"LI",{});var ei=o(Qt);Mo=g(ei,"[1] "),yt=n(ei,"A",{href:!0,rel:!0});var Vi=o(yt);Oo=g(Vi,"https://huggingface.co/settings/tokens"),Vi.forEach(a),ei.forEach(a),Ri.forEach(a),ge.forEach(a),Uo=i(k),R=n(k,"DIV",{class:!0});var ce=o(R);u(kt.$$.fragment,ce),Co=i(ce),Ta=n(ce,"P",{});var Wi=o(Ta);So=g(Wi,"Moving a repository from namespace1/repo_name1 to namespace2/repo_name2"),Wi.forEach(a),zo=i(ce),wt=n(ce,"P",{});var Ps=o(wt);Ro=g(Ps,`Note there are certain limitations. For more information about moving
repositories, please see
`),At=n(Ps,"A",{href:!0,rel:!0});var Gi=o(At);Vo=g(Gi,"https://hf.co/docs/hub/main#how-can-i-rename-or-transfer-a-repo"),Gi.forEach(a),Wo=g(Ps,"."),Ps.forEach(a),Go=i(ce),Ia=n(ce,"P",{});var Bi=o(Ia);Bo=g(Bi,"References:"),Bi.forEach(a),Ko=i(ce),Ma=n(ce,"UL",{});var Ki=o(Ma);Xt=n(Ki,"LI",{});var ti=o(Xt);Jo=g(ti,"[1] "),jt=n(ti,"A",{href:!0,rel:!0});var Ji=o(jt);Qo=g(Ji,"https://huggingface.co/settings/tokens"),Ji.forEach(a),ti.forEach(a),Ki.forEach(a),ce.forEach(a),Xo=i(k),xe=n(k,"DIV",{class:!0});var Ls=o(xe);u(Ht.$$.fragment,Ls),Yo=i(Ls),Oa=n(Ls,"P",{});var Qi=o(Oa);Zo=g(Qi,`Saves the passed access token so git can correctly authenticate the
user.`),Qi.forEach(a),Ls.forEach(a),er=i(k),De=n(k,"DIV",{class:!0});var Ts=o(De);u(Et.$$.fragment,Ts),tr=i(Ts),Ua=n(Ts,"P",{});var Xi=o(Ua);ar=g(Xi,"Resets the user\u2019s access token."),Xi.forEach(a),Ts.forEach(a),sr=i(k),ae=n(k,"DIV",{class:!0});var Re=o(ae);u(xt.$$.fragment,Re),nr=i(Re),Ca=n(Re,"P",{});var Yi=o(Ca);or=g(Yi,"Update the visibility setting of a repository."),Yi.forEach(a),rr=i(Re),Sa=n(Re,"P",{});var Zi=o(Sa);ir=g(Zi,"References:"),Zi.forEach(a),lr=i(Re),za=n(Re,"UL",{});var el=o(za);Yt=n(el,"LI",{});var ai=o(Yt);gr=g(ai,"[1] "),Dt=n(ai,"A",{href:!0,rel:!0});var tl=o(Dt);cr=g(tl,"https://huggingface.co/settings/tokens"),tl.forEach(a),ai.forEach(a),el.forEach(a),Re.forEach(a),pr=i(k),V=n(k,"DIV",{class:!0});var pe=o(V);u(qt.$$.fragment,pe),hr=i(pe),Ra=n(pe,"P",{});var al=o(Ra);dr=g(al,`Upload a local file (up to 5GB) to the given repo. The upload is done
through a HTTP post request, and doesn\u2019t require git or git-lfs to be
installed.`),al.forEach(a),fr=i(pe),u(qe.$$.fragment,pe),ur=i(pe),Va=n(pe,"P",{});var sl=o(Va);mr=g(sl,"Example usage:"),sl.forEach(a),_r=i(pe),u(Ft.$$.fragment,pe),pe.forEach(a),br=i(k),Fe=n(k,"DIV",{class:!0});var Is=o(Fe);u(Nt.$$.fragment,Is),vr=i(Is),Wa=n(Is,"P",{});var nl=o(Wa);$r=g(nl,"Call HF API to know \u201Cwhoami\u201D."),nl.forEach(a),Is.forEach(a),k.forEach(a),ds=i(t),ue=n(t,"H2",{class:!0});var Ms=o(ue);Ne=n(Ms,"A",{id:!0,class:!0,href:!0});var ol=o(Ne);Ga=n(ol,"SPAN",{});var rl=o(Ga);u(Pt.$$.fragment,rl),rl.forEach(a),ol.forEach(a),yr=i(Ms),Ba=n(Ms,"SPAN",{});var il=o(Ba);kr=g(il,"Hugging Face local storage"),il.forEach(a),Ms.forEach(a),fs=i(t),Lt=n(t,"P",{});var si=o(Lt);Ka=n(si,"CODE",{});var ll=o(Ka);wr=g(ll,"huggingface_hub"),ll.forEach(a),Ar=g(si,` stores the authentication information locally so that it may be re-used in subsequent
methods.`),si.forEach(a),us=i(t),Pe=n(t,"P",{});var Os=o(Pe);jr=g(Os,"It does this using the "),Zt=n(Os,"A",{href:!0});var gl=o(Zt);Hr=g(gl,"HfFolder"),gl.forEach(a),Er=g(Os," utility, which saves data at the root of the user."),Os.forEach(a),ms=i(t),B=n(t,"DIV",{class:!0});var Ve=o(B);u(Tt.$$.fragment,Ve),xr=i(Ve),Le=n(Ve,"DIV",{class:!0});var Us=o(Le);u(It.$$.fragment,Us),Dr=i(Us),Ja=n(Us,"P",{});var cl=o(Ja);qr=g(cl,"Deletes the token from storage. Does not fail if token does not exist."),cl.forEach(a),Us.forEach(a),Fr=i(Ve),Te=n(Ve,"DIV",{class:!0});var Cs=o(Te);u(Mt.$$.fragment,Cs),Nr=i(Cs),Qa=n(Cs,"P",{});var pl=o(Qa);Pr=g(pl,"Retrieves the token"),pl.forEach(a),Cs.forEach(a),Lr=i(Ve),Ie=n(Ve,"DIV",{class:!0});var Ss=o(Ie);u(Ot.$$.fragment,Ss),Tr=i(Ss),Xa=n(Ss,"P",{});var hl=o(Xa);Ir=g(hl,"Save token, creating folder as needed."),hl.forEach(a),Ss.forEach(a),Ve.forEach(a),_s=i(t),me=n(t,"H2",{class:!0});var zs=o(me);Me=n(zs,"A",{id:!0,class:!0,href:!0});var dl=o(Me);Ya=n(dl,"SPAN",{});var fl=o(Ya);u(Ut.$$.fragment,fl),fl.forEach(a),dl.forEach(a),Mr=i(zs),Za=n(zs,"SPAN",{});var ul=o(Za);Or=g(ul,"Filtering helpers"),ul.forEach(a),zs.forEach(a),bs=i(t),Oe=n(t,"P",{});var Rs=o(Oe);Ur=g(Rs,"Some helpers to filter repositories on the Hub are available in the "),es=n(Rs,"CODE",{});var ml=o(es);Cr=g(ml,"huggingface_hub"),ml.forEach(a),Sr=g(Rs," package."),Rs.forEach(a),vs=i(t),K=n(t,"DIV",{class:!0});var We=o(K);u(Ct.$$.fragment,We),zr=i(We),ts=n(We,"P",{});var _l=o(ts);Rr=g(_l,`A class that converts human-readable dataset search parameters into ones
compatible with the REST API. For all parameters capitalization does not
matter.`),_l.forEach(a),Vr=i(We),as=n(We,"P",{});var bl=o(as);Wr=g(bl,"Examples:"),bl.forEach(a),Gr=i(We),u(St.$$.fragment,We),We.forEach(a),$s=i(t),oe=n(t,"DIV",{class:!0});var aa=o(oe);u(zt.$$.fragment,aa),Br=i(aa),ss=n(aa,"P",{});var vl=o(ss);Kr=g(vl,`A class that converts human-readable model search parameters into ones
compatible with the REST API. For all parameters capitalization does not
matter.`),vl.forEach(a),Jr=i(aa),u(Rt.$$.fragment,aa),aa.forEach(a),this.h()},h(){c(p,"name","hf:doc:metadata"),c(p,"content",JSON.stringify(Fl)),c(w,"id","huggingface_hub.HfApi"),c(w,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(w,"href","#huggingface_hub.HfApi"),c(A,"class","relative group"),c(Qe,"href","https://huggingface.co/settings/tokens"),c(Qe,"rel","nofollow"),c(Y,"class","docstring"),c(Ye,"href","https://huggingface.co/settings/tokens"),c(Ye,"rel","nofollow"),c(S,"class","docstring"),c(re,"class","docstring"),c(tt,"href","https://huggingface.co/settings/tokens"),c(tt,"rel","nofollow"),c(Z,"class","docstring"),c(ye,"class","docstring"),c(ke,"class","docstring"),c(we,"class","docstring"),c(I,"class","docstring"),c(Ae,"class","docstring"),c(M,"class","docstring"),c(_t,"href","https://huggingface.co/settings/tokens"),c(_t,"rel","nofollow"),c(ee,"class","docstring"),c(te,"class","docstring"),c(ie,"class","docstring"),c(yt,"href","https://huggingface.co/settings/tokens"),c(yt,"rel","nofollow"),c(z,"class","docstring"),c(At,"href","https://hf.co/docs/hub/main#how-can-i-rename-or-transfer-a-repo"),c(At,"rel","nofollow"),c(jt,"href","https://huggingface.co/settings/tokens"),c(jt,"rel","nofollow"),c(R,"class","docstring"),c(xe,"class","docstring"),c(De,"class","docstring"),c(Dt,"href","https://huggingface.co/settings/tokens"),c(Dt,"rel","nofollow"),c(ae,"class","docstring"),c(V,"class","docstring"),c(Fe,"class","docstring"),c(d,"class","docstring"),c(Ne,"id","huggingface_hub.HfFolder"),c(Ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ne,"href","#huggingface_hub.HfFolder"),c(ue,"class","relative group"),c(Zt,"href","/docs/huggingface_hub/main/en/package_reference/hf_api#huggingface_hub.HfFolder"),c(Le,"class","docstring"),c(Te,"class","docstring"),c(Ie,"class","docstring"),c(B,"class","docstring"),c(Me,"id","huggingface_hub.DatasetFilter"),c(Me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Me,"href","#huggingface_hub.DatasetFilter"),c(me,"class","relative group"),c(K,"class","docstring"),c(oe,"class","docstring")},m(t,h){e(document.head,p),y(t,q,h),y(t,A,h),e(A,w),e(w,H),m($,H,null),e(A,j),e(A,N),e(N,O),y(t,F,h),y(t,E,h),e(E,P),e(E,T),e(T,U),e(E,C),y(t,x,h),y(t,L,h),e(L,W),e(L,G),e(G,he),e(L,de),y(t,Q,h),y(t,X,h),e(X,fe),y(t,ls,h),m(Ge,t,h),y(t,gs,h),y(t,be,h),e(be,Vs),e(be,sa),e(sa,Ws),e(be,Gs),y(t,cs,h),m(Be,t,h),y(t,ps,h),y(t,ve,h),e(ve,Bs),e(ve,na),e(na,Ks),e(ve,Js),y(t,hs,h),y(t,d,h),m(Ke,d,null),e(d,Qs),e(d,Y),m(Je,Y,null),e(Y,Xs),e(Y,oa),e(oa,Ys),e(Y,Zs),e(Y,ra),e(ra,en),e(Y,tn),e(Y,ia),e(ia,Gt),e(Gt,an),e(Gt,Qe),e(Qe,sn),e(d,nn),e(d,S),m(Xe,S,null),e(S,on),e(S,la),e(la,rn),e(S,ln),e(S,ga),e(ga,gn),e(S,cn),e(S,ca),e(ca,pn),e(S,hn),e(S,pa),e(pa,Bt),e(Bt,dn),e(Bt,Ye),e(Ye,fn),e(d,un),e(d,re),m(Ze,re,null),e(re,mn),e(re,ha),e(ha,_n),e(re,bn),m($e,re,null),e(d,vn),e(d,Z),m(et,Z,null),e(Z,$n),e(Z,da),e(da,yn),e(Z,kn),e(Z,fa),e(fa,wn),e(Z,An),e(Z,ua),e(ua,Kt),e(Kt,jn),e(Kt,tt),e(tt,Hn),e(d,En),e(d,ye),m(at,ye,null),e(ye,xn),e(ye,ma),e(ma,Dn),e(d,qn),e(d,ke),m(st,ke,null),e(ke,Fn),e(ke,_a),e(_a,Nn),e(d,Pn),e(d,we),m(nt,we,null),e(we,Ln),e(we,ba),e(ba,Tn),e(d,In),e(d,I),m(ot,I,null),e(I,Mn),e(I,va),e(va,On),e(I,Un),e(I,rt),e(rt,Cn),e(rt,$a),e($a,Sn),e(rt,zn),e(I,Rn),m(it,I,null),e(I,Vn),e(I,lt),e(lt,Wn),e(lt,ya),e(ya,Gn),e(lt,Bn),e(I,Kn),m(gt,I,null),e(d,Jn),e(d,Ae),m(ct,Ae,null),e(Ae,Qn),e(Ae,ka),e(ka,Xn),e(d,Yn),e(d,M),m(pt,M,null),e(M,Zn),e(M,wa),e(wa,eo),e(M,to),e(M,ht),e(ht,ao),e(ht,Aa),e(Aa,so),e(ht,no),e(M,oo),m(dt,M,null),e(M,ro),e(M,ft),e(ft,io),e(ft,ja),e(ja,lo),e(ft,go),e(M,co),m(ut,M,null),e(d,po),e(d,ee),m(mt,ee,null),e(ee,ho),e(ee,Ha),e(Ha,fo),e(ee,uo),e(ee,Ea),e(Ea,mo),e(ee,_o),e(ee,xa),e(xa,Jt),e(Jt,bo),e(Jt,_t),e(_t,vo),e(d,$o),e(d,te),m(bt,te,null),e(te,yo),e(te,Da),e(Da,ko),e(te,wo),m(je,te,null),e(te,Ao),m(He,te,null),e(d,jo),e(d,ie),m(vt,ie,null),e(ie,Ho),e(ie,qa),e(qa,Eo),e(ie,xo),m(Ee,ie,null),e(d,Do),e(d,z),m($t,z,null),e(z,qo),e(z,Fa),e(Fa,Fo),e(z,No),e(z,Na),e(Na,Po),e(z,Lo),e(z,Pa),e(Pa,To),e(z,Io),e(z,La),e(La,Qt),e(Qt,Mo),e(Qt,yt),e(yt,Oo),e(d,Uo),e(d,R),m(kt,R,null),e(R,Co),e(R,Ta),e(Ta,So),e(R,zo),e(R,wt),e(wt,Ro),e(wt,At),e(At,Vo),e(wt,Wo),e(R,Go),e(R,Ia),e(Ia,Bo),e(R,Ko),e(R,Ma),e(Ma,Xt),e(Xt,Jo),e(Xt,jt),e(jt,Qo),e(d,Xo),e(d,xe),m(Ht,xe,null),e(xe,Yo),e(xe,Oa),e(Oa,Zo),e(d,er),e(d,De),m(Et,De,null),e(De,tr),e(De,Ua),e(Ua,ar),e(d,sr),e(d,ae),m(xt,ae,null),e(ae,nr),e(ae,Ca),e(Ca,or),e(ae,rr),e(ae,Sa),e(Sa,ir),e(ae,lr),e(ae,za),e(za,Yt),e(Yt,gr),e(Yt,Dt),e(Dt,cr),e(d,pr),e(d,V),m(qt,V,null),e(V,hr),e(V,Ra),e(Ra,dr),e(V,fr),m(qe,V,null),e(V,ur),e(V,Va),e(Va,mr),e(V,_r),m(Ft,V,null),e(d,br),e(d,Fe),m(Nt,Fe,null),e(Fe,vr),e(Fe,Wa),e(Wa,$r),y(t,ds,h),y(t,ue,h),e(ue,Ne),e(Ne,Ga),m(Pt,Ga,null),e(ue,yr),e(ue,Ba),e(Ba,kr),y(t,fs,h),y(t,Lt,h),e(Lt,Ka),e(Ka,wr),e(Lt,Ar),y(t,us,h),y(t,Pe,h),e(Pe,jr),e(Pe,Zt),e(Zt,Hr),e(Pe,Er),y(t,ms,h),y(t,B,h),m(Tt,B,null),e(B,xr),e(B,Le),m(It,Le,null),e(Le,Dr),e(Le,Ja),e(Ja,qr),e(B,Fr),e(B,Te),m(Mt,Te,null),e(Te,Nr),e(Te,Qa),e(Qa,Pr),e(B,Lr),e(B,Ie),m(Ot,Ie,null),e(Ie,Tr),e(Ie,Xa),e(Xa,Ir),y(t,_s,h),y(t,me,h),e(me,Me),e(Me,Ya),m(Ut,Ya,null),e(me,Mr),e(me,Za),e(Za,Or),y(t,bs,h),y(t,Oe,h),e(Oe,Ur),e(Oe,es),e(es,Cr),e(Oe,Sr),y(t,vs,h),y(t,K,h),m(Ct,K,null),e(K,zr),e(K,ts),e(ts,Rr),e(K,Vr),e(K,as),e(as,Wr),e(K,Gr),m(St,K,null),y(t,$s,h),y(t,oe,h),m(zt,oe,null),e(oe,Br),e(oe,ss),e(ss,Kr),e(oe,Jr),m(Rt,oe,null),ys=!0},p(t,[h]){const Vt={};h&2&&(Vt.$$scope={dirty:h,ctx:t}),$e.$set(Vt);const ns={};h&2&&(ns.$$scope={dirty:h,ctx:t}),je.$set(ns);const os={};h&2&&(os.$$scope={dirty:h,ctx:t}),He.$set(os);const rs={};h&2&&(rs.$$scope={dirty:h,ctx:t}),Ee.$set(rs);const Wt={};h&2&&(Wt.$$scope={dirty:h,ctx:t}),qe.$set(Wt)},i(t){ys||(_($.$$.fragment,t),_(Ge.$$.fragment,t),_(Be.$$.fragment,t),_(Ke.$$.fragment,t),_(Je.$$.fragment,t),_(Xe.$$.fragment,t),_(Ze.$$.fragment,t),_($e.$$.fragment,t),_(et.$$.fragment,t),_(at.$$.fragment,t),_(st.$$.fragment,t),_(nt.$$.fragment,t),_(ot.$$.fragment,t),_(it.$$.fragment,t),_(gt.$$.fragment,t),_(ct.$$.fragment,t),_(pt.$$.fragment,t),_(dt.$$.fragment,t),_(ut.$$.fragment,t),_(mt.$$.fragment,t),_(bt.$$.fragment,t),_(je.$$.fragment,t),_(He.$$.fragment,t),_(vt.$$.fragment,t),_(Ee.$$.fragment,t),_($t.$$.fragment,t),_(kt.$$.fragment,t),_(Ht.$$.fragment,t),_(Et.$$.fragment,t),_(xt.$$.fragment,t),_(qt.$$.fragment,t),_(qe.$$.fragment,t),_(Ft.$$.fragment,t),_(Nt.$$.fragment,t),_(Pt.$$.fragment,t),_(Tt.$$.fragment,t),_(It.$$.fragment,t),_(Mt.$$.fragment,t),_(Ot.$$.fragment,t),_(Ut.$$.fragment,t),_(Ct.$$.fragment,t),_(St.$$.fragment,t),_(zt.$$.fragment,t),_(Rt.$$.fragment,t),ys=!0)},o(t){b($.$$.fragment,t),b(Ge.$$.fragment,t),b(Be.$$.fragment,t),b(Ke.$$.fragment,t),b(Je.$$.fragment,t),b(Xe.$$.fragment,t),b(Ze.$$.fragment,t),b($e.$$.fragment,t),b(et.$$.fragment,t),b(at.$$.fragment,t),b(st.$$.fragment,t),b(nt.$$.fragment,t),b(ot.$$.fragment,t),b(it.$$.fragment,t),b(gt.$$.fragment,t),b(ct.$$.fragment,t),b(pt.$$.fragment,t),b(dt.$$.fragment,t),b(ut.$$.fragment,t),b(mt.$$.fragment,t),b(bt.$$.fragment,t),b(je.$$.fragment,t),b(He.$$.fragment,t),b(vt.$$.fragment,t),b(Ee.$$.fragment,t),b($t.$$.fragment,t),b(kt.$$.fragment,t),b(Ht.$$.fragment,t),b(Et.$$.fragment,t),b(xt.$$.fragment,t),b(qt.$$.fragment,t),b(qe.$$.fragment,t),b(Ft.$$.fragment,t),b(Nt.$$.fragment,t),b(Pt.$$.fragment,t),b(Tt.$$.fragment,t),b(It.$$.fragment,t),b(Mt.$$.fragment,t),b(Ot.$$.fragment,t),b(Ut.$$.fragment,t),b(Ct.$$.fragment,t),b(St.$$.fragment,t),b(zt.$$.fragment,t),b(Rt.$$.fragment,t),ys=!1},d(t){a(p),t&&a(q),t&&a(A),v($),t&&a(F),t&&a(E),t&&a(x),t&&a(L),t&&a(Q),t&&a(X),t&&a(ls),v(Ge,t),t&&a(gs),t&&a(be),t&&a(cs),v(Be,t),t&&a(ps),t&&a(ve),t&&a(hs),t&&a(d),v(Ke),v(Je),v(Xe),v(Ze),v($e),v(et),v(at),v(st),v(nt),v(ot),v(it),v(gt),v(ct),v(pt),v(dt),v(ut),v(mt),v(bt),v(je),v(He),v(vt),v(Ee),v($t),v(kt),v(Ht),v(Et),v(xt),v(qt),v(qe),v(Ft),v(Nt),t&&a(ds),t&&a(ue),v(Pt),t&&a(fs),t&&a(Lt),t&&a(us),t&&a(Pe),t&&a(ms),t&&a(B),v(Tt),v(It),v(Mt),v(Ot),t&&a(_s),t&&a(me),v(Ut),t&&a(bs),t&&a(Oe),t&&a(vs),t&&a(K),v(Ct),v(St),t&&a($s),t&&a(oe),v(zt),v(Rt)}}}const Fl={local:"huggingface_hub.HfApi",sections:[{local:"huggingface_hub.HfFolder",title:"Hugging Face local storage"},{local:"huggingface_hub.DatasetFilter",title:"Filtering helpers"}],title:"Hugging Face Hub API"};function Nl(J){return Al(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ol extends $l{constructor(p){super();yl(this,p,Nl,ql,kl,{})}}export{Ol as default,Fl as metadata};
