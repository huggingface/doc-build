import{S as qn,i as Fn,s as Bn,e as a,k as l,w as m,t as c,M as Wn,c as s,d as r,m as n,a as o,x as f,h as d,b as u,G as t,g as p,y as h,q as v,o as g,B as _,v as jn}from"../chunks/vendor-hf-doc-builder.js";import{T as Jn}from"../chunks/Tip-hf-doc-builder.js";import{D as b}from"../chunks/Docstring-hf-doc-builder.js";import{I as _e}from"../chunks/IconCopyLink-hf-doc-builder.js";function Kn(kr){let $,re;return{c(){$=a("p"),re=c("Make sure all processes will reach this instruction otherwise one of your processes will hang forever.")},l(y){$=s(y,"P",{});var E=o($);re=d(E,"Make sure all processes will reach this instruction otherwise one of your processes will hang forever."),E.forEach(r)},m(y,E){p(y,$,E),t($,re)},d(y){y&&r($)}}}function Qn(kr){let $,re,y,E,xt,be,Ha,Tt,qa,Lr,rt,Fa,Nr,U,ae,Pt,$e,Ba,Dt,Wa,Cr,at,ja,Ur,w,ye,Ja,kt,Ka,Qa,Lt,Xa,Ya,x,st,Nt,Za,es,ts,ot,Ct,rs,as,ss,lt,Ut,os,ls,ns,nt,It,is,cs,ds,it,At,ps,us,Ir,T,Ee,ms,St,fs,hs,Ot,vs,gs,D,ct,Rt,_s,bs,$s,dt,Vt,ys,Es,ws,pt,Mt,xs,Ts,Ps,ut,zt,Ds,ks,Ar,P,we,Ls,Gt,Ns,Cs,Ht,Us,Is,I,mt,qt,As,Ss,Os,ft,Ft,Rs,Vs,Ms,ht,Bt,zs,Gs,Sr,A,se,Wt,xe,Hs,jt,qs,Or,oe,Fs,Jt,Bs,Ws,Rr,S,Te,js,Kt,Js,Vr,O,Pe,Ks,Qt,Qs,Mr,R,De,Xs,Xt,Ys,zr,V,ke,Zs,Yt,eo,Gr,M,Le,to,Zt,ro,Hr,z,Ne,ao,er,so,qr,G,le,tr,Ce,oo,rr,lo,Fr,vt,no,Br,H,Ue,io,ar,co,Wr,q,Ie,po,sr,uo,jr,F,Ae,mo,or,fo,Jr,B,Se,ho,Oe,vo,lr,go,_o,Kr,W,ne,nr,Re,bo,ir,$o,Qr,j,Ve,yo,cr,Eo,Xr,ie,wo,dr,xo,To,Yr,J,ce,pr,Me,Po,ur,Do,Zr,gt,ko,ea,K,ze,Lo,mr,No,ta,k,Ge,Co,fr,Uo,Io,He,hr,Ao,So,_t,Oo,vr,Ro,ra,Q,qe,Vo,gr,Mo,aa,X,de,_r,Fe,zo,br,Go,sa,bt,Ho,oa,Y,Be,qo,$r,Fo,la,Z,We,Bo,je,Wo,yr,jo,Jo,na,L,Je,Ko,Er,Qo,Xo,pe,ia,ee,ue,wr,Ke,Yo,xr,Zo,ca,$t,el,da,te,Qe,tl,N,rl,Tr,al,sl,Pr,ol,ll,Dr,nl,il,pa,Xe,Ye,ua,Ze,et,ma;return be=new _e({}),$e=new _e({}),ye=new b({props:{name:"class accelerate.DistributedType",anchor:"accelerate.DistributedType",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/dataclasses.py#L106"}}),Ee=new b({props:{name:"class accelerate.utils.LoggerType",anchor:"accelerate.utils.LoggerType",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/dataclasses.py#L183"}}),we=new b({props:{name:"class accelerate.utils.PrecisionType",anchor:"accelerate.utils.PrecisionType",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/dataclasses.py#L200"}}),xe=new _e({}),Te=new b({props:{name:"accelerate.utils.broadcast",anchor:"accelerate.utils.broadcast",parameters:[{name:"tensor",val:""},{name:"from_process",val:": int = 0"}],parametersDescription:[{anchor:"accelerate.utils.broadcast.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to gather.`,name:"tensor"},{anchor:"accelerate.utils.broadcast.from_process",description:`<strong>from_process</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The process from which to send the data`,name:"from_process"}],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/operations.py#L281",returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors broadcasted to the proper device.</p>
`}}),Pe=new b({props:{name:"accelerate.utils.concatenate",anchor:"accelerate.utils.concatenate",parameters:[{name:"data",val:""},{name:"dim",val:" = 0"}],parametersDescription:[{anchor:"accelerate.utils.concatenate.data",description:`<strong>data</strong> (nested list/tuple/dictionary of lists of tensors <code>torch.Tensor</code>) &#x2014;
The data to concatenate.`,name:"data"},{anchor:"accelerate.utils.concatenate.dim",description:`<strong>dim</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The dimension on which to concatenate.`,name:"dim"}],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/operations.py#L347",returnDescription:`
<p>The same data structure as <code>data</code> with all the tensors concatenated.</p>
`}}),De=new b({props:{name:"accelerate.utils.gather",anchor:"accelerate.utils.gather",parameters:[{name:"tensor",val:""}],parametersDescription:[{anchor:"accelerate.utils.gather.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to gather.`,name:"tensor"}],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/operations.py#L207",returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors sent to the proper device.</p>
`}}),ke=new b({props:{name:"accelerate.utils.pad_across_processes",anchor:"accelerate.utils.pad_across_processes",parameters:[{name:"tensor",val:""},{name:"dim",val:" = 0"},{name:"pad_index",val:" = 0"},{name:"pad_first",val:" = False"}],parametersDescription:[{anchor:"accelerate.utils.pad_across_processes.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to gather.`,name:"tensor"},{anchor:"accelerate.utils.pad_across_processes.dim",description:`<strong>dim</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The dimension on which to pad.`,name:"dim"},{anchor:"accelerate.utils.pad_across_processes.pad_index",description:`<strong>pad_index</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The value with which to pad.`,name:"pad_index"},{anchor:"accelerate.utils.pad_across_processes.pad_first",description:`<strong>pad_first</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to pad at the beginning or the end.`,name:"pad_first"}],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/operations.py#L369"}}),Le=new b({props:{name:"accelerate.utils.reduce",anchor:"accelerate.utils.reduce",parameters:[{name:"tensor",val:""},{name:"reduction",val:" = 'mean'"}],parametersDescription:[{anchor:"accelerate.utils.reduce.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to reduce.`,name:"tensor"},{anchor:"accelerate.utils.reduce.reduction",description:`<strong>reduction</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;mean&quot;</code>) &#x2014;
A reduction method. Can be of &#x201C;mean&#x201D;, &#x201C;sum&#x201D;, or &#x201C;none&#x201D;`,name:"reduction"}],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/operations.py#L415",returnDescription:`
<p>The same data structure as <code>data</code> with all the tensors reduced.</p>
`}}),Ne=new b({props:{name:"accelerate.utils.send_to_device",anchor:"accelerate.utils.send_to_device",parameters:[{name:"tensor",val:""},{name:"device",val:""}],parametersDescription:[{anchor:"accelerate.utils.send_to_device.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to send to a given device.`,name:"tensor"},{anchor:"accelerate.utils.send_to_device.device",description:`<strong>device</strong> (<code>torch.device</code>) &#x2014;
The device to send the data to.`,name:"device"}],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/operations.py#L106",returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors sent to the proper device.</p>
`}}),Ce=new _e({}),Ue=new b({props:{name:"accelerate.utils.get_max_memory",anchor:"accelerate.utils.get_max_memory",parameters:[{name:"max_memory",val:": typing.Union[typing.Dict[typing.Union[int, str], typing.Union[int, str]], NoneType] = None"}],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/modeling.py#L272"}}),Ie=new b({props:{name:"accelerate.utils.is_bf16_available",anchor:"accelerate.utils.is_bf16_available",parameters:[{name:"ignore_tpu",val:" = False"}],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/imports.py#L78"}}),Ae=new b({props:{name:"accelerate.utils.is_torch_version",anchor:"accelerate.utils.is_torch_version",parameters:[{name:"operation",val:": str"},{name:"version",val:": str"}],parametersDescription:[{anchor:"accelerate.utils.is_torch_version.operation",description:`<strong>operation</strong> (<code>str</code>) &#x2014;
A string representation of an operator, such as <code>&quot;&gt;&quot;</code> or <code>&quot;&lt;=&quot;</code>`,name:"operation"},{anchor:"accelerate.utils.is_torch_version.version",description:`<strong>version</strong> (<code>str</code>) &#x2014;
A string version of PyTorch`,name:"version"}],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/versions.py#L51"}}),Se=new b({props:{name:"accelerate.utils.is_tpu_available",anchor:"accelerate.utils.is_tpu_available",parameters:[{name:"check_device",val:" = True"}],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/imports.py#L54"}}),Re=new _e({}),Ve=new b({props:{name:"accelerate.utils.write_basic_config",anchor:"accelerate.utils.write_basic_config",parameters:[{name:"mixed_precision",val:" = 'no'"},{name:"save_location",val:": str = '/github/home/.cache/huggingface/accelerate/default_config.yaml'"}],parametersDescription:[{anchor:"accelerate.utils.write_basic_config.mixed_precision",description:`<strong>mixed_precision</strong> (<code>str</code>, <em>optional</em>, defaults to &#x201C;no&#x201D;) &#x2014;
Mixed Precision to use. Should be one of &#x201C;no&#x201D;, &#x201C;fp16&#x201D;, or &#x201C;bf16&#x201D;`,name:"mixed_precision"},{anchor:"accelerate.utils.write_basic_config.save_location",description:`<strong>save_location</strong> (<code>str</code>, <em>optional</em>, defaults to <code>default_json_config_file</code>) &#x2014;
Optional custom save location. Should be passed to <code>--config_file</code> when using <code>accelerate launch</code>. Default
location is inside the huggingface cache folder (<code>~/.cache/huggingface</code>) but can be overriden by setting
the <code>HF_HOME</code> environmental variable, followed by <code>accelerate/default_config.yaml</code>.`,name:"save_location"}],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/other.py#L117"}}),Me=new _e({}),ze=new b({props:{name:"accelerate.utils.extract_model_from_parallel",anchor:"accelerate.utils.extract_model_from_parallel",parameters:[{name:"model",val:""}],parametersDescription:[{anchor:"accelerate.utils.extract_model_from_parallel.model",description:"<strong>model</strong> (<code>torch.nn.Module</code>) &#x2014; The model to extract.",name:"model"}],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/other.py#L35",returnDescription:`
<p>The extracted model.</p>
`,returnType:`
<p><code>torch.nn.Module</code></p>
`}}),Ge=new b({props:{name:"accelerate.utils.get_max_layer_size",anchor:"accelerate.utils.get_max_layer_size",parameters:[{name:"modules",val:": typing.List[typing.Tuple[str, torch.nn.modules.module.Module]]"},{name:"module_sizes",val:": typing.Dict[str, int]"},{name:"no_split_module_classes",val:": typing.List[str]"}],parametersDescription:[{anchor:"accelerate.utils.get_max_layer_size.modules",description:`<strong>modules</strong> (<code>List[Tuple[str, torch.nn.Module]]</code>) &#x2014;
The list of named modules where we want to determine the maximum layer size.`,name:"modules"},{anchor:"accelerate.utils.get_max_layer_size.module_sizes",description:`<strong>module_sizes</strong> (<code>Dict[str, int]</code>) &#x2014;
A dictionary mapping each layer name to its size (as generated by <code>compute_module_sizes</code>).`,name:"module_sizes"},{anchor:"accelerate.utils.get_max_layer_size.no_split_module_classes",description:`<strong>no_split_module_classes</strong> (<code>List[str]</code>) &#x2014;
A list of class names for layers we don&#x2019;t want to be split.`,name:"no_split_module_classes"}],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/modeling.py#L233",returnDescription:`
<p>The maximum size of a layer with the list of layer names realizing that maximum size.</p>
`,returnType:`
<p><code>Tuple[int, List[str]]</code></p>
`}}),qe=new b({props:{name:"accelerate.utils.offload_state_dict",anchor:"accelerate.utils.offload_state_dict",parameters:[{name:"save_dir",val:": typing.Union[str, os.PathLike]"},{name:"state_dict",val:": typing.Dict[str, torch.Tensor]"}],parametersDescription:[{anchor:"accelerate.utils.offload_state_dict.save_dir",description:"<strong>save_dir</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014; The directory in which to offload the state dict.",name:"save_dir"},{anchor:"accelerate.utils.offload_state_dict.state_dict",description:"<strong>state_dict</strong> (<code>Dict[str, torch.Tensor]</code>) &#x2014; The dictionary of tensors to offload.",name:"state_dict"}],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/offload.py#L84"}}),Fe=new _e({}),Be=new b({props:{name:"accelerate.utils.extract_model_from_parallel",anchor:"accelerate.utils.extract_model_from_parallel",parameters:[{name:"model",val:""}],parametersDescription:[{anchor:"accelerate.utils.extract_model_from_parallel.model",description:"<strong>model</strong> (<code>torch.nn.Module</code>) &#x2014; The model to extract.",name:"model"}],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/other.py#L35",returnDescription:`
<p>The extracted model.</p>
`,returnType:`
<p><code>torch.nn.Module</code></p>
`}}),We=new b({props:{name:"accelerate.utils.save",anchor:"accelerate.utils.save",parameters:[{name:"obj",val:""},{name:"f",val:""}],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/other.py#L74"}}),Je=new b({props:{name:"accelerate.utils.wait_for_everyone",anchor:"accelerate.utils.wait_for_everyone",parameters:[],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/other.py#L54"}}),pe=new Jn({props:{warning:!0,$$slots:{default:[Kn]},$$scope:{ctx:kr}}}),Ke=new _e({}),Qe=new b({props:{name:"accelerate.utils.set_seed",anchor:"accelerate.utils.set_seed",parameters:[{name:"seed",val:": int"},{name:"device_specific",val:": bool = False"}],parametersDescription:[{anchor:"accelerate.utils.set_seed.seed",description:"<strong>seed</strong> (<code>int</code>) &#x2014; The seed to set.",name:"seed"},{anchor:"accelerate.utils.set_seed.device_specific",description:`<strong>device_specific</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to differ the seed on each device slightly with <code>self.process_index</code>.`,name:"device_specific"}],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/random.py#L30"}}),Ye=new b({props:{name:"accelerate.utils.synchronize_rng_state",anchor:"accelerate.utils.synchronize_rng_state",parameters:[{name:"rng_type",val:": typing.Optional[accelerate.utils.dataclasses.RNGType] = None"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"}],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/random.py#L50"}}),et=new b({props:{name:"accelerate.synchronize_rng_states",anchor:"accelerate.synchronize_rng_states",parameters:[{name:"rng_types",val:": typing.List[typing.Union[str, accelerate.utils.dataclasses.RNGType]]"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"}],source:"https://github.com/huggingface/accelerate/blob/v0.11.0/src/accelerate/utils/random.py#L85"}}),{c(){$=a("meta"),re=l(),y=a("h1"),E=a("a"),xt=a("span"),m(be.$$.fragment),Ha=l(),Tt=a("span"),qa=c("Helpful Utilities"),Lr=l(),rt=a("p"),Fa=c("Below are a variety of utility functions that \u{1F917} Accelerate provides, broken down by use-case."),Nr=l(),U=a("h2"),ae=a("a"),Pt=a("span"),m($e.$$.fragment),Ba=l(),Dt=a("span"),Wa=c("Data Classes"),Cr=l(),at=a("p"),ja=c("These are basic dataclasses used throughout \u{1F917} Accelerate and they can be passed in as parameters."),Ur=l(),w=a("div"),m(ye.$$.fragment),Ja=l(),kt=a("p"),Ka=c("Represents a type of distributed environment."),Qa=l(),Lt=a("p"),Xa=c("Values:"),Ya=l(),x=a("ul"),st=a("li"),Nt=a("strong"),Za=c("NO"),es=c(" \u2014 Not a distributed environment, just a single process."),ts=l(),ot=a("li"),Ct=a("strong"),rs=c("MULTI_CPU"),as=c(" \u2014 Distributed on multiple CPU nodes."),ss=l(),lt=a("li"),Ut=a("strong"),os=c("MULTI_GPU"),ls=c(" \u2014 Distributed on multiple GPUs."),ns=l(),nt=a("li"),It=a("strong"),is=c("DEEPSPEED"),cs=c(" \u2014 Using DeepSpeed."),ds=l(),it=a("li"),At=a("strong"),ps=c("TPU"),us=c(" \u2014 Distributed on TPUs."),Ir=l(),T=a("div"),m(Ee.$$.fragment),ms=l(),St=a("p"),fs=c("Represents a type of supported experiment tracker"),hs=l(),Ot=a("p"),vs=c("Values:"),gs=l(),D=a("ul"),ct=a("li"),Rt=a("strong"),_s=c("ALL"),bs=c(" \u2014 all available trackers in the environment that are supported"),$s=l(),dt=a("li"),Vt=a("strong"),ys=c("TENSORBOARD"),Es=c(" \u2014 TensorBoard as an experiment tracker"),ws=l(),pt=a("li"),Mt=a("strong"),xs=c("WANDB"),Ts=c(" \u2014 wandb as an experiment tracker"),Ps=l(),ut=a("li"),zt=a("strong"),Ds=c("COMETML"),ks=c(" \u2014 comet_ml as an experiment tracker"),Ar=l(),P=a("div"),m(we.$$.fragment),Ls=l(),Gt=a("p"),Ns=c("Represents a type of precision used on floating point values"),Cs=l(),Ht=a("p"),Us=c("Values:"),Is=l(),I=a("ul"),mt=a("li"),qt=a("strong"),As=c("NO"),Ss=c(" \u2014 using full precision (FP32)"),Os=l(),ft=a("li"),Ft=a("strong"),Rs=c("FP16"),Vs=c(" \u2014 using half precision"),Ms=l(),ht=a("li"),Bt=a("strong"),zs=c("BF16"),Gs=c(" \u2014 using brain floating point precision"),Sr=l(),A=a("h2"),se=a("a"),Wt=a("span"),m(xe.$$.fragment),Hs=l(),jt=a("span"),qs=c("Data Manipulation and Operations"),Or=l(),oe=a("p"),Fs=c("These include data operations that mimic the same "),Jt=a("code"),Bs=c("torch"),Ws=c(" ops but can be used on distributed processes."),Rr=l(),S=a("div"),m(Te.$$.fragment),js=l(),Kt=a("p"),Js=c("Recursively broadcast tensor in a nested list/tuple/dictionary of tensors to all devices."),Vr=l(),O=a("div"),m(Pe.$$.fragment),Ks=l(),Qt=a("p"),Qs=c("Recursively concatenate the tensors in a nested list/tuple/dictionary of lists of tensors with the same shape."),Mr=l(),R=a("div"),m(De.$$.fragment),Xs=l(),Xt=a("p"),Ys=c("Recursively gather tensor in a nested list/tuple/dictionary of tensors from all devices."),zr=l(),V=a("div"),m(ke.$$.fragment),Zs=l(),Yt=a("p"),eo=c(`Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so they
can safely be gathered.`),Gr=l(),M=a("div"),m(Le.$$.fragment),to=l(),Zt=a("p"),ro=c(`Recursively reduce the tensors in a nested list/tuple/dictionary of lists of tensors across all processes by the
mean of a given operation.`),Hr=l(),z=a("div"),m(Ne.$$.fragment),ao=l(),er=a("p"),so=c("Recursively sends the elements in a nested list/tuple/dictionary of tensors to a given device."),qr=l(),G=a("h2"),le=a("a"),tr=a("span"),m(Ce.$$.fragment),oo=l(),rr=a("span"),lo=c("Environment Checks"),Fr=l(),vt=a("p"),no=c("These functionalities check the state of the current working environment including information about the operating system itself, what it can support, and if particular dependencies are installed."),Br=l(),H=a("div"),m(Ue.$$.fragment),io=l(),ar=a("p"),co=c("Get the maximum memory available if nothing is passed, converts string to int otherwise."),Wr=l(),q=a("div"),m(Ie.$$.fragment),po=l(),sr=a("p"),uo=c("Checks if bf16 is supported, optionally ignoring the TPU"),jr=l(),F=a("div"),m(Ae.$$.fragment),mo=l(),or=a("p"),fo=c("Compares the current PyTorch version to a given reference with an operation."),Jr=l(),B=a("div"),m(Se.$$.fragment),ho=l(),Oe=a("p"),vo=c("Checks if "),lr=a("code"),go=c("torch_xla"),_o=c(" is installed and potentially if a TPU is in the environment"),Kr=l(),W=a("h2"),ne=a("a"),nr=a("span"),m(Re.$$.fragment),bo=l(),ir=a("span"),$o=c("Environment Configuration"),Qr=l(),j=a("div"),m(Ve.$$.fragment),yo=l(),cr=a("p"),Eo=c(`Creates and saves a basic cluster config to be used on a local machine with potentially multiple GPUs. Will also
set CPU if it is a CPU-only machine.`),Xr=l(),ie=a("p"),wo=c("When setting up \u{1F917} Accelerate for the first time, rather than running "),dr=a("code"),xo=c("accelerate config"),To=c(" [~utils.write_basic_config] can be used as an alternative for quick configuration."),Yr=l(),J=a("h2"),ce=a("a"),pr=a("span"),m(Me.$$.fragment),Po=l(),ur=a("span"),Do=c("Modeling"),Zr=l(),gt=a("p"),ko=c("These utilities relate to interacting with PyTorch models"),ea=l(),K=a("div"),m(ze.$$.fragment),Lo=l(),mr=a("p"),No=c("Extract a model from its distributed containers."),ta=l(),k=a("div"),m(Ge.$$.fragment),Co=l(),fr=a("p"),Uo=c(`Utility function that will scan a list of named modules and return the maximum size used by one full layer. The
definition of a layer being:`),Io=l(),He=a("ul"),hr=a("li"),Ao=c("a module with no direct children (just parameters and buffers)"),So=l(),_t=a("li"),Oo=c("a module whose class name is in the list "),vr=a("code"),Ro=c("no_split_module_classes"),ra=l(),Q=a("div"),m(qe.$$.fragment),Vo=l(),gr=a("p"),Mo=c("Offload a state dict in a given folder."),aa=l(),X=a("h2"),de=a("a"),_r=a("span"),m(Fe.$$.fragment),zo=l(),br=a("span"),Go=c("Parallel"),sa=l(),bt=a("p"),Ho=c("These include general utilities that should be used when working in parallel."),oa=l(),Y=a("div"),m(Be.$$.fragment),qo=l(),$r=a("p"),Fo=c("Extract a model from its distributed containers."),la=l(),Z=a("div"),m(We.$$.fragment),Bo=l(),je=a("p"),Wo=c("Save the data to disk. Use in place of "),yr=a("code"),jo=c("torch.save()"),Jo=c("."),na=l(),L=a("div"),m(Je.$$.fragment),Ko=l(),Er=a("p"),Qo=c("Introduces a blocking point in the script, making sure all processes have reached this point before continuing."),Xo=l(),m(pe.$$.fragment),ia=l(),ee=a("h2"),ue=a("a"),wr=a("span"),m(Ke.$$.fragment),Yo=l(),xr=a("span"),Zo=c("Random"),ca=l(),$t=a("p"),el=c("These utilities relate to setting and synchronizing of all the random states."),da=l(),te=a("div"),m(Qe.$$.fragment),tl=l(),N=a("p"),rl=c("Helper function for reproducible behavior to set the seed in "),Tr=a("code"),al=c("random"),sl=c(", "),Pr=a("code"),ol=c("numpy"),ll=c(", "),Dr=a("code"),nl=c("torch"),il=c("."),pa=l(),Xe=a("div"),m(Ye.$$.fragment),ua=l(),Ze=a("div"),m(et.$$.fragment),this.h()},l(e){const i=Wn('[data-svelte="svelte-1phssyn"]',document.head);$=s(i,"META",{name:!0,content:!0}),i.forEach(r),re=n(e),y=s(e,"H1",{class:!0});var tt=o(y);E=s(tt,"A",{id:!0,class:!0,href:!0});var El=o(E);xt=s(El,"SPAN",{});var wl=o(xt);f(be.$$.fragment,wl),wl.forEach(r),El.forEach(r),Ha=n(tt),Tt=s(tt,"SPAN",{});var xl=o(Tt);qa=d(xl,"Helpful Utilities"),xl.forEach(r),tt.forEach(r),Lr=n(e),rt=s(e,"P",{});var Tl=o(rt);Fa=d(Tl,"Below are a variety of utility functions that \u{1F917} Accelerate provides, broken down by use-case."),Tl.forEach(r),Nr=n(e),U=s(e,"H2",{class:!0});var fa=o(U);ae=s(fa,"A",{id:!0,class:!0,href:!0});var Pl=o(ae);Pt=s(Pl,"SPAN",{});var Dl=o(Pt);f($e.$$.fragment,Dl),Dl.forEach(r),Pl.forEach(r),Ba=n(fa),Dt=s(fa,"SPAN",{});var kl=o(Dt);Wa=d(kl,"Data Classes"),kl.forEach(r),fa.forEach(r),Cr=n(e),at=s(e,"P",{});var Ll=o(at);ja=d(Ll,"These are basic dataclasses used throughout \u{1F917} Accelerate and they can be passed in as parameters."),Ll.forEach(r),Ur=n(e),w=s(e,"DIV",{class:!0});var me=o(w);f(ye.$$.fragment,me),Ja=n(me),kt=s(me,"P",{});var Nl=o(kt);Ka=d(Nl,"Represents a type of distributed environment."),Nl.forEach(r),Qa=n(me),Lt=s(me,"P",{});var Cl=o(Lt);Xa=d(Cl,"Values:"),Cl.forEach(r),Ya=n(me),x=s(me,"UL",{});var C=o(x);st=s(C,"LI",{});var cl=o(st);Nt=s(cl,"STRONG",{});var Ul=o(Nt);Za=d(Ul,"NO"),Ul.forEach(r),es=d(cl," \u2014 Not a distributed environment, just a single process."),cl.forEach(r),ts=n(C),ot=s(C,"LI",{});var dl=o(ot);Ct=s(dl,"STRONG",{});var Il=o(Ct);rs=d(Il,"MULTI_CPU"),Il.forEach(r),as=d(dl," \u2014 Distributed on multiple CPU nodes."),dl.forEach(r),ss=n(C),lt=s(C,"LI",{});var pl=o(lt);Ut=s(pl,"STRONG",{});var Al=o(Ut);os=d(Al,"MULTI_GPU"),Al.forEach(r),ls=d(pl," \u2014 Distributed on multiple GPUs."),pl.forEach(r),ns=n(C),nt=s(C,"LI",{});var ul=o(nt);It=s(ul,"STRONG",{});var Sl=o(It);is=d(Sl,"DEEPSPEED"),Sl.forEach(r),cs=d(ul," \u2014 Using DeepSpeed."),ul.forEach(r),ds=n(C),it=s(C,"LI",{});var ml=o(it);At=s(ml,"STRONG",{});var Ol=o(At);ps=d(Ol,"TPU"),Ol.forEach(r),us=d(ml," \u2014 Distributed on TPUs."),ml.forEach(r),C.forEach(r),me.forEach(r),Ir=n(e),T=s(e,"DIV",{class:!0});var fe=o(T);f(Ee.$$.fragment,fe),ms=n(fe),St=s(fe,"P",{});var Rl=o(St);fs=d(Rl,"Represents a type of supported experiment tracker"),Rl.forEach(r),hs=n(fe),Ot=s(fe,"P",{});var Vl=o(Ot);vs=d(Vl,"Values:"),Vl.forEach(r),gs=n(fe),D=s(fe,"UL",{});var he=o(D);ct=s(he,"LI",{});var fl=o(ct);Rt=s(fl,"STRONG",{});var Ml=o(Rt);_s=d(Ml,"ALL"),Ml.forEach(r),bs=d(fl," \u2014 all available trackers in the environment that are supported"),fl.forEach(r),$s=n(he),dt=s(he,"LI",{});var hl=o(dt);Vt=s(hl,"STRONG",{});var zl=o(Vt);ys=d(zl,"TENSORBOARD"),zl.forEach(r),Es=d(hl," \u2014 TensorBoard as an experiment tracker"),hl.forEach(r),ws=n(he),pt=s(he,"LI",{});var vl=o(pt);Mt=s(vl,"STRONG",{});var Gl=o(Mt);xs=d(Gl,"WANDB"),Gl.forEach(r),Ts=d(vl," \u2014 wandb as an experiment tracker"),vl.forEach(r),Ps=n(he),ut=s(he,"LI",{});var gl=o(ut);zt=s(gl,"STRONG",{});var Hl=o(zt);Ds=d(Hl,"COMETML"),Hl.forEach(r),ks=d(gl," \u2014 comet_ml as an experiment tracker"),gl.forEach(r),he.forEach(r),fe.forEach(r),Ar=n(e),P=s(e,"DIV",{class:!0});var ve=o(P);f(we.$$.fragment,ve),Ls=n(ve),Gt=s(ve,"P",{});var ql=o(Gt);Ns=d(ql,"Represents a type of precision used on floating point values"),ql.forEach(r),Cs=n(ve),Ht=s(ve,"P",{});var Fl=o(Ht);Us=d(Fl,"Values:"),Fl.forEach(r),Is=n(ve),I=s(ve,"UL",{});var yt=o(I);mt=s(yt,"LI",{});var _l=o(mt);qt=s(_l,"STRONG",{});var Bl=o(qt);As=d(Bl,"NO"),Bl.forEach(r),Ss=d(_l," \u2014 using full precision (FP32)"),_l.forEach(r),Os=n(yt),ft=s(yt,"LI",{});var bl=o(ft);Ft=s(bl,"STRONG",{});var Wl=o(Ft);Rs=d(Wl,"FP16"),Wl.forEach(r),Vs=d(bl," \u2014 using half precision"),bl.forEach(r),Ms=n(yt),ht=s(yt,"LI",{});var $l=o(ht);Bt=s($l,"STRONG",{});var jl=o(Bt);zs=d(jl,"BF16"),jl.forEach(r),Gs=d($l," \u2014 using brain floating point precision"),$l.forEach(r),yt.forEach(r),ve.forEach(r),Sr=n(e),A=s(e,"H2",{class:!0});var ha=o(A);se=s(ha,"A",{id:!0,class:!0,href:!0});var Jl=o(se);Wt=s(Jl,"SPAN",{});var Kl=o(Wt);f(xe.$$.fragment,Kl),Kl.forEach(r),Jl.forEach(r),Hs=n(ha),jt=s(ha,"SPAN",{});var Ql=o(jt);qs=d(Ql,"Data Manipulation and Operations"),Ql.forEach(r),ha.forEach(r),Or=n(e),oe=s(e,"P",{});var va=o(oe);Fs=d(va,"These include data operations that mimic the same "),Jt=s(va,"CODE",{});var Xl=o(Jt);Bs=d(Xl,"torch"),Xl.forEach(r),Ws=d(va," ops but can be used on distributed processes."),va.forEach(r),Rr=n(e),S=s(e,"DIV",{class:!0});var ga=o(S);f(Te.$$.fragment,ga),js=n(ga),Kt=s(ga,"P",{});var Yl=o(Kt);Js=d(Yl,"Recursively broadcast tensor in a nested list/tuple/dictionary of tensors to all devices."),Yl.forEach(r),ga.forEach(r),Vr=n(e),O=s(e,"DIV",{class:!0});var _a=o(O);f(Pe.$$.fragment,_a),Ks=n(_a),Qt=s(_a,"P",{});var Zl=o(Qt);Qs=d(Zl,"Recursively concatenate the tensors in a nested list/tuple/dictionary of lists of tensors with the same shape."),Zl.forEach(r),_a.forEach(r),Mr=n(e),R=s(e,"DIV",{class:!0});var ba=o(R);f(De.$$.fragment,ba),Xs=n(ba),Xt=s(ba,"P",{});var en=o(Xt);Ys=d(en,"Recursively gather tensor in a nested list/tuple/dictionary of tensors from all devices."),en.forEach(r),ba.forEach(r),zr=n(e),V=s(e,"DIV",{class:!0});var $a=o(V);f(ke.$$.fragment,$a),Zs=n($a),Yt=s($a,"P",{});var tn=o(Yt);eo=d(tn,`Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so they
can safely be gathered.`),tn.forEach(r),$a.forEach(r),Gr=n(e),M=s(e,"DIV",{class:!0});var ya=o(M);f(Le.$$.fragment,ya),to=n(ya),Zt=s(ya,"P",{});var rn=o(Zt);ro=d(rn,`Recursively reduce the tensors in a nested list/tuple/dictionary of lists of tensors across all processes by the
mean of a given operation.`),rn.forEach(r),ya.forEach(r),Hr=n(e),z=s(e,"DIV",{class:!0});var Ea=o(z);f(Ne.$$.fragment,Ea),ao=n(Ea),er=s(Ea,"P",{});var an=o(er);so=d(an,"Recursively sends the elements in a nested list/tuple/dictionary of tensors to a given device."),an.forEach(r),Ea.forEach(r),qr=n(e),G=s(e,"H2",{class:!0});var wa=o(G);le=s(wa,"A",{id:!0,class:!0,href:!0});var sn=o(le);tr=s(sn,"SPAN",{});var on=o(tr);f(Ce.$$.fragment,on),on.forEach(r),sn.forEach(r),oo=n(wa),rr=s(wa,"SPAN",{});var ln=o(rr);lo=d(ln,"Environment Checks"),ln.forEach(r),wa.forEach(r),Fr=n(e),vt=s(e,"P",{});var nn=o(vt);no=d(nn,"These functionalities check the state of the current working environment including information about the operating system itself, what it can support, and if particular dependencies are installed."),nn.forEach(r),Br=n(e),H=s(e,"DIV",{class:!0});var xa=o(H);f(Ue.$$.fragment,xa),io=n(xa),ar=s(xa,"P",{});var cn=o(ar);co=d(cn,"Get the maximum memory available if nothing is passed, converts string to int otherwise."),cn.forEach(r),xa.forEach(r),Wr=n(e),q=s(e,"DIV",{class:!0});var Ta=o(q);f(Ie.$$.fragment,Ta),po=n(Ta),sr=s(Ta,"P",{});var dn=o(sr);uo=d(dn,"Checks if bf16 is supported, optionally ignoring the TPU"),dn.forEach(r),Ta.forEach(r),jr=n(e),F=s(e,"DIV",{class:!0});var Pa=o(F);f(Ae.$$.fragment,Pa),mo=n(Pa),or=s(Pa,"P",{});var pn=o(or);fo=d(pn,"Compares the current PyTorch version to a given reference with an operation."),pn.forEach(r),Pa.forEach(r),Jr=n(e),B=s(e,"DIV",{class:!0});var Da=o(B);f(Se.$$.fragment,Da),ho=n(Da),Oe=s(Da,"P",{});var ka=o(Oe);vo=d(ka,"Checks if "),lr=s(ka,"CODE",{});var un=o(lr);go=d(un,"torch_xla"),un.forEach(r),_o=d(ka," is installed and potentially if a TPU is in the environment"),ka.forEach(r),Da.forEach(r),Kr=n(e),W=s(e,"H2",{class:!0});var La=o(W);ne=s(La,"A",{id:!0,class:!0,href:!0});var mn=o(ne);nr=s(mn,"SPAN",{});var fn=o(nr);f(Re.$$.fragment,fn),fn.forEach(r),mn.forEach(r),bo=n(La),ir=s(La,"SPAN",{});var hn=o(ir);$o=d(hn,"Environment Configuration"),hn.forEach(r),La.forEach(r),Qr=n(e),j=s(e,"DIV",{class:!0});var Na=o(j);f(Ve.$$.fragment,Na),yo=n(Na),cr=s(Na,"P",{});var vn=o(cr);Eo=d(vn,`Creates and saves a basic cluster config to be used on a local machine with potentially multiple GPUs. Will also
set CPU if it is a CPU-only machine.`),vn.forEach(r),Na.forEach(r),Xr=n(e),ie=s(e,"P",{});var Ca=o(ie);wo=d(Ca,"When setting up \u{1F917} Accelerate for the first time, rather than running "),dr=s(Ca,"CODE",{});var gn=o(dr);xo=d(gn,"accelerate config"),gn.forEach(r),To=d(Ca," [~utils.write_basic_config] can be used as an alternative for quick configuration."),Ca.forEach(r),Yr=n(e),J=s(e,"H2",{class:!0});var Ua=o(J);ce=s(Ua,"A",{id:!0,class:!0,href:!0});var _n=o(ce);pr=s(_n,"SPAN",{});var bn=o(pr);f(Me.$$.fragment,bn),bn.forEach(r),_n.forEach(r),Po=n(Ua),ur=s(Ua,"SPAN",{});var $n=o(ur);Do=d($n,"Modeling"),$n.forEach(r),Ua.forEach(r),Zr=n(e),gt=s(e,"P",{});var yn=o(gt);ko=d(yn,"These utilities relate to interacting with PyTorch models"),yn.forEach(r),ea=n(e),K=s(e,"DIV",{class:!0});var Ia=o(K);f(ze.$$.fragment,Ia),Lo=n(Ia),mr=s(Ia,"P",{});var En=o(mr);No=d(En,"Extract a model from its distributed containers."),En.forEach(r),Ia.forEach(r),ta=n(e),k=s(e,"DIV",{class:!0});var Et=o(k);f(Ge.$$.fragment,Et),Co=n(Et),fr=s(Et,"P",{});var wn=o(fr);Uo=d(wn,`Utility function that will scan a list of named modules and return the maximum size used by one full layer. The
definition of a layer being:`),wn.forEach(r),Io=n(Et),He=s(Et,"UL",{});var Aa=o(He);hr=s(Aa,"LI",{});var xn=o(hr);Ao=d(xn,"a module with no direct children (just parameters and buffers)"),xn.forEach(r),So=n(Aa),_t=s(Aa,"LI",{});var yl=o(_t);Oo=d(yl,"a module whose class name is in the list "),vr=s(yl,"CODE",{});var Tn=o(vr);Ro=d(Tn,"no_split_module_classes"),Tn.forEach(r),yl.forEach(r),Aa.forEach(r),Et.forEach(r),ra=n(e),Q=s(e,"DIV",{class:!0});var Sa=o(Q);f(qe.$$.fragment,Sa),Vo=n(Sa),gr=s(Sa,"P",{});var Pn=o(gr);Mo=d(Pn,"Offload a state dict in a given folder."),Pn.forEach(r),Sa.forEach(r),aa=n(e),X=s(e,"H2",{class:!0});var Oa=o(X);de=s(Oa,"A",{id:!0,class:!0,href:!0});var Dn=o(de);_r=s(Dn,"SPAN",{});var kn=o(_r);f(Fe.$$.fragment,kn),kn.forEach(r),Dn.forEach(r),zo=n(Oa),br=s(Oa,"SPAN",{});var Ln=o(br);Go=d(Ln,"Parallel"),Ln.forEach(r),Oa.forEach(r),sa=n(e),bt=s(e,"P",{});var Nn=o(bt);Ho=d(Nn,"These include general utilities that should be used when working in parallel."),Nn.forEach(r),oa=n(e),Y=s(e,"DIV",{class:!0});var Ra=o(Y);f(Be.$$.fragment,Ra),qo=n(Ra),$r=s(Ra,"P",{});var Cn=o($r);Fo=d(Cn,"Extract a model from its distributed containers."),Cn.forEach(r),Ra.forEach(r),la=n(e),Z=s(e,"DIV",{class:!0});var Va=o(Z);f(We.$$.fragment,Va),Bo=n(Va),je=s(Va,"P",{});var Ma=o(je);Wo=d(Ma,"Save the data to disk. Use in place of "),yr=s(Ma,"CODE",{});var Un=o(yr);jo=d(Un,"torch.save()"),Un.forEach(r),Jo=d(Ma,"."),Ma.forEach(r),Va.forEach(r),na=n(e),L=s(e,"DIV",{class:!0});var wt=o(L);f(Je.$$.fragment,wt),Ko=n(wt),Er=s(wt,"P",{});var In=o(Er);Qo=d(In,"Introduces a blocking point in the script, making sure all processes have reached this point before continuing."),In.forEach(r),Xo=n(wt),f(pe.$$.fragment,wt),wt.forEach(r),ia=n(e),ee=s(e,"H2",{class:!0});var za=o(ee);ue=s(za,"A",{id:!0,class:!0,href:!0});var An=o(ue);wr=s(An,"SPAN",{});var Sn=o(wr);f(Ke.$$.fragment,Sn),Sn.forEach(r),An.forEach(r),Yo=n(za),xr=s(za,"SPAN",{});var On=o(xr);Zo=d(On,"Random"),On.forEach(r),za.forEach(r),ca=n(e),$t=s(e,"P",{});var Rn=o($t);el=d(Rn,"These utilities relate to setting and synchronizing of all the random states."),Rn.forEach(r),da=n(e),te=s(e,"DIV",{class:!0});var Ga=o(te);f(Qe.$$.fragment,Ga),tl=n(Ga),N=s(Ga,"P",{});var ge=o(N);rl=d(ge,"Helper function for reproducible behavior to set the seed in "),Tr=s(ge,"CODE",{});var Vn=o(Tr);al=d(Vn,"random"),Vn.forEach(r),sl=d(ge,", "),Pr=s(ge,"CODE",{});var Mn=o(Pr);ol=d(Mn,"numpy"),Mn.forEach(r),ll=d(ge,", "),Dr=s(ge,"CODE",{});var zn=o(Dr);nl=d(zn,"torch"),zn.forEach(r),il=d(ge,"."),ge.forEach(r),Ga.forEach(r),pa=n(e),Xe=s(e,"DIV",{class:!0});var Gn=o(Xe);f(Ye.$$.fragment,Gn),Gn.forEach(r),ua=n(e),Ze=s(e,"DIV",{class:!0});var Hn=o(Ze);f(et.$$.fragment,Hn),Hn.forEach(r),this.h()},h(){u($,"name","hf:doc:metadata"),u($,"content",JSON.stringify(Xn)),u(E,"id","helpful-utilities"),u(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(E,"href","#helpful-utilities"),u(y,"class","relative group"),u(ae,"id","accelerate.DistributedType"),u(ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ae,"href","#accelerate.DistributedType"),u(U,"class","relative group"),u(w,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(T,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(P,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(se,"id","accelerate.utils.broadcast"),u(se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(se,"href","#accelerate.utils.broadcast"),u(A,"class","relative group"),u(S,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(O,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(R,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(V,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(le,"id","accelerate.utils.get_max_memory"),u(le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(le,"href","#accelerate.utils.get_max_memory"),u(G,"class","relative group"),u(H,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(B,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(ne,"id","accelerate.utils.write_basic_config"),u(ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ne,"href","#accelerate.utils.write_basic_config"),u(W,"class","relative group"),u(j,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(ce,"id","accelerate.utils.extract_model_from_parallel"),u(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ce,"href","#accelerate.utils.extract_model_from_parallel"),u(J,"class","relative group"),u(K,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(k,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(Q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(de,"id","accelerate.utils.extract_model_from_parallel"),u(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(de,"href","#accelerate.utils.extract_model_from_parallel"),u(X,"class","relative group"),u(Y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(Z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(L,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(ue,"id","accelerate.utils.set_seed"),u(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ue,"href","#accelerate.utils.set_seed"),u(ee,"class","relative group"),u(te,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(Xe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,i){t(document.head,$),p(e,re,i),p(e,y,i),t(y,E),t(E,xt),h(be,xt,null),t(y,Ha),t(y,Tt),t(Tt,qa),p(e,Lr,i),p(e,rt,i),t(rt,Fa),p(e,Nr,i),p(e,U,i),t(U,ae),t(ae,Pt),h($e,Pt,null),t(U,Ba),t(U,Dt),t(Dt,Wa),p(e,Cr,i),p(e,at,i),t(at,ja),p(e,Ur,i),p(e,w,i),h(ye,w,null),t(w,Ja),t(w,kt),t(kt,Ka),t(w,Qa),t(w,Lt),t(Lt,Xa),t(w,Ya),t(w,x),t(x,st),t(st,Nt),t(Nt,Za),t(st,es),t(x,ts),t(x,ot),t(ot,Ct),t(Ct,rs),t(ot,as),t(x,ss),t(x,lt),t(lt,Ut),t(Ut,os),t(lt,ls),t(x,ns),t(x,nt),t(nt,It),t(It,is),t(nt,cs),t(x,ds),t(x,it),t(it,At),t(At,ps),t(it,us),p(e,Ir,i),p(e,T,i),h(Ee,T,null),t(T,ms),t(T,St),t(St,fs),t(T,hs),t(T,Ot),t(Ot,vs),t(T,gs),t(T,D),t(D,ct),t(ct,Rt),t(Rt,_s),t(ct,bs),t(D,$s),t(D,dt),t(dt,Vt),t(Vt,ys),t(dt,Es),t(D,ws),t(D,pt),t(pt,Mt),t(Mt,xs),t(pt,Ts),t(D,Ps),t(D,ut),t(ut,zt),t(zt,Ds),t(ut,ks),p(e,Ar,i),p(e,P,i),h(we,P,null),t(P,Ls),t(P,Gt),t(Gt,Ns),t(P,Cs),t(P,Ht),t(Ht,Us),t(P,Is),t(P,I),t(I,mt),t(mt,qt),t(qt,As),t(mt,Ss),t(I,Os),t(I,ft),t(ft,Ft),t(Ft,Rs),t(ft,Vs),t(I,Ms),t(I,ht),t(ht,Bt),t(Bt,zs),t(ht,Gs),p(e,Sr,i),p(e,A,i),t(A,se),t(se,Wt),h(xe,Wt,null),t(A,Hs),t(A,jt),t(jt,qs),p(e,Or,i),p(e,oe,i),t(oe,Fs),t(oe,Jt),t(Jt,Bs),t(oe,Ws),p(e,Rr,i),p(e,S,i),h(Te,S,null),t(S,js),t(S,Kt),t(Kt,Js),p(e,Vr,i),p(e,O,i),h(Pe,O,null),t(O,Ks),t(O,Qt),t(Qt,Qs),p(e,Mr,i),p(e,R,i),h(De,R,null),t(R,Xs),t(R,Xt),t(Xt,Ys),p(e,zr,i),p(e,V,i),h(ke,V,null),t(V,Zs),t(V,Yt),t(Yt,eo),p(e,Gr,i),p(e,M,i),h(Le,M,null),t(M,to),t(M,Zt),t(Zt,ro),p(e,Hr,i),p(e,z,i),h(Ne,z,null),t(z,ao),t(z,er),t(er,so),p(e,qr,i),p(e,G,i),t(G,le),t(le,tr),h(Ce,tr,null),t(G,oo),t(G,rr),t(rr,lo),p(e,Fr,i),p(e,vt,i),t(vt,no),p(e,Br,i),p(e,H,i),h(Ue,H,null),t(H,io),t(H,ar),t(ar,co),p(e,Wr,i),p(e,q,i),h(Ie,q,null),t(q,po),t(q,sr),t(sr,uo),p(e,jr,i),p(e,F,i),h(Ae,F,null),t(F,mo),t(F,or),t(or,fo),p(e,Jr,i),p(e,B,i),h(Se,B,null),t(B,ho),t(B,Oe),t(Oe,vo),t(Oe,lr),t(lr,go),t(Oe,_o),p(e,Kr,i),p(e,W,i),t(W,ne),t(ne,nr),h(Re,nr,null),t(W,bo),t(W,ir),t(ir,$o),p(e,Qr,i),p(e,j,i),h(Ve,j,null),t(j,yo),t(j,cr),t(cr,Eo),p(e,Xr,i),p(e,ie,i),t(ie,wo),t(ie,dr),t(dr,xo),t(ie,To),p(e,Yr,i),p(e,J,i),t(J,ce),t(ce,pr),h(Me,pr,null),t(J,Po),t(J,ur),t(ur,Do),p(e,Zr,i),p(e,gt,i),t(gt,ko),p(e,ea,i),p(e,K,i),h(ze,K,null),t(K,Lo),t(K,mr),t(mr,No),p(e,ta,i),p(e,k,i),h(Ge,k,null),t(k,Co),t(k,fr),t(fr,Uo),t(k,Io),t(k,He),t(He,hr),t(hr,Ao),t(He,So),t(He,_t),t(_t,Oo),t(_t,vr),t(vr,Ro),p(e,ra,i),p(e,Q,i),h(qe,Q,null),t(Q,Vo),t(Q,gr),t(gr,Mo),p(e,aa,i),p(e,X,i),t(X,de),t(de,_r),h(Fe,_r,null),t(X,zo),t(X,br),t(br,Go),p(e,sa,i),p(e,bt,i),t(bt,Ho),p(e,oa,i),p(e,Y,i),h(Be,Y,null),t(Y,qo),t(Y,$r),t($r,Fo),p(e,la,i),p(e,Z,i),h(We,Z,null),t(Z,Bo),t(Z,je),t(je,Wo),t(je,yr),t(yr,jo),t(je,Jo),p(e,na,i),p(e,L,i),h(Je,L,null),t(L,Ko),t(L,Er),t(Er,Qo),t(L,Xo),h(pe,L,null),p(e,ia,i),p(e,ee,i),t(ee,ue),t(ue,wr),h(Ke,wr,null),t(ee,Yo),t(ee,xr),t(xr,Zo),p(e,ca,i),p(e,$t,i),t($t,el),p(e,da,i),p(e,te,i),h(Qe,te,null),t(te,tl),t(te,N),t(N,rl),t(N,Tr),t(Tr,al),t(N,sl),t(N,Pr),t(Pr,ol),t(N,ll),t(N,Dr),t(Dr,nl),t(N,il),p(e,pa,i),p(e,Xe,i),h(Ye,Xe,null),p(e,ua,i),p(e,Ze,i),h(et,Ze,null),ma=!0},p(e,[i]){const tt={};i&2&&(tt.$$scope={dirty:i,ctx:e}),pe.$set(tt)},i(e){ma||(v(be.$$.fragment,e),v($e.$$.fragment,e),v(ye.$$.fragment,e),v(Ee.$$.fragment,e),v(we.$$.fragment,e),v(xe.$$.fragment,e),v(Te.$$.fragment,e),v(Pe.$$.fragment,e),v(De.$$.fragment,e),v(ke.$$.fragment,e),v(Le.$$.fragment,e),v(Ne.$$.fragment,e),v(Ce.$$.fragment,e),v(Ue.$$.fragment,e),v(Ie.$$.fragment,e),v(Ae.$$.fragment,e),v(Se.$$.fragment,e),v(Re.$$.fragment,e),v(Ve.$$.fragment,e),v(Me.$$.fragment,e),v(ze.$$.fragment,e),v(Ge.$$.fragment,e),v(qe.$$.fragment,e),v(Fe.$$.fragment,e),v(Be.$$.fragment,e),v(We.$$.fragment,e),v(Je.$$.fragment,e),v(pe.$$.fragment,e),v(Ke.$$.fragment,e),v(Qe.$$.fragment,e),v(Ye.$$.fragment,e),v(et.$$.fragment,e),ma=!0)},o(e){g(be.$$.fragment,e),g($e.$$.fragment,e),g(ye.$$.fragment,e),g(Ee.$$.fragment,e),g(we.$$.fragment,e),g(xe.$$.fragment,e),g(Te.$$.fragment,e),g(Pe.$$.fragment,e),g(De.$$.fragment,e),g(ke.$$.fragment,e),g(Le.$$.fragment,e),g(Ne.$$.fragment,e),g(Ce.$$.fragment,e),g(Ue.$$.fragment,e),g(Ie.$$.fragment,e),g(Ae.$$.fragment,e),g(Se.$$.fragment,e),g(Re.$$.fragment,e),g(Ve.$$.fragment,e),g(Me.$$.fragment,e),g(ze.$$.fragment,e),g(Ge.$$.fragment,e),g(qe.$$.fragment,e),g(Fe.$$.fragment,e),g(Be.$$.fragment,e),g(We.$$.fragment,e),g(Je.$$.fragment,e),g(pe.$$.fragment,e),g(Ke.$$.fragment,e),g(Qe.$$.fragment,e),g(Ye.$$.fragment,e),g(et.$$.fragment,e),ma=!1},d(e){r($),e&&r(re),e&&r(y),_(be),e&&r(Lr),e&&r(rt),e&&r(Nr),e&&r(U),_($e),e&&r(Cr),e&&r(at),e&&r(Ur),e&&r(w),_(ye),e&&r(Ir),e&&r(T),_(Ee),e&&r(Ar),e&&r(P),_(we),e&&r(Sr),e&&r(A),_(xe),e&&r(Or),e&&r(oe),e&&r(Rr),e&&r(S),_(Te),e&&r(Vr),e&&r(O),_(Pe),e&&r(Mr),e&&r(R),_(De),e&&r(zr),e&&r(V),_(ke),e&&r(Gr),e&&r(M),_(Le),e&&r(Hr),e&&r(z),_(Ne),e&&r(qr),e&&r(G),_(Ce),e&&r(Fr),e&&r(vt),e&&r(Br),e&&r(H),_(Ue),e&&r(Wr),e&&r(q),_(Ie),e&&r(jr),e&&r(F),_(Ae),e&&r(Jr),e&&r(B),_(Se),e&&r(Kr),e&&r(W),_(Re),e&&r(Qr),e&&r(j),_(Ve),e&&r(Xr),e&&r(ie),e&&r(Yr),e&&r(J),_(Me),e&&r(Zr),e&&r(gt),e&&r(ea),e&&r(K),_(ze),e&&r(ta),e&&r(k),_(Ge),e&&r(ra),e&&r(Q),_(qe),e&&r(aa),e&&r(X),_(Fe),e&&r(sa),e&&r(bt),e&&r(oa),e&&r(Y),_(Be),e&&r(la),e&&r(Z),_(We),e&&r(na),e&&r(L),_(Je),_(pe),e&&r(ia),e&&r(ee),_(Ke),e&&r(ca),e&&r($t),e&&r(da),e&&r(te),_(Qe),e&&r(pa),e&&r(Xe),_(Ye),e&&r(ua),e&&r(Ze),_(et)}}}const Xn={local:"helpful-utilities",sections:[{local:"accelerate.DistributedType",title:"Data Classes"},{local:"accelerate.utils.broadcast",title:"Data Manipulation and Operations"},{local:"accelerate.utils.get_max_memory",title:"Environment Checks"},{local:"accelerate.utils.write_basic_config",title:"Environment Configuration"},{local:"accelerate.utils.extract_model_from_parallel",title:"Modeling"},{local:"accelerate.utils.extract_model_from_parallel",title:"Parallel"},{local:"accelerate.utils.set_seed",title:"Random"}],title:"Helpful Utilities"};function Yn(kr){return jn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ai extends qn{constructor($){super();Fn(this,$,Yn,Qn,Bn,{})}}export{ai as default,Xn as metadata};
