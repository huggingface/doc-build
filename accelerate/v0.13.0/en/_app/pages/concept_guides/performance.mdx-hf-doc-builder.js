import{S as Ps,i as ys,s as Ts,e as s,k as h,w as A,t as n,M as Ss,c as r,d as a,m as f,a as l,x as U,h as i,b as p,G as t,g as c,y as z,q as G,o as x,B,v as ks}from"../../chunks/vendor-hf-doc-builder.js";import{T as gs}from"../../chunks/Tip-hf-doc-builder.js";import{I as Et}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as Ga}from"../../chunks/CodeBlock-hf-doc-builder.js";function As(te){let d,v;return{c(){d=s("p"),v=n("In this example there are two GPUs for \u201CMulti-GPU\u201D and a TPU pod with 8 workers")},l(u){d=r(u,"P",{});var m=l(d);v=i(m,"In this example there are two GPUs for \u201CMulti-GPU\u201D and a TPU pod with 8 workers"),m.forEach(a)},m(u,m){c(u,d,m),t(d,v)},d(u){u&&a(d)}}}function Us(te){let d,v;return{c(){d=s("p"),v=n(`Since users can have their own learning rate schedulers defined, we leave this up to the user to decide if they wish to scale their
learning rate or not.`)},l(u){d=r(u,"P",{});var m=l(d);v=i(m,`Since users can have their own learning rate schedulers defined, we leave this up to the user to decide if they wish to scale their
learning rate or not.`),m.forEach(a)},m(u,m){c(u,d,m),t(d,v)},d(u){u&&a(d)}}}function zs(te){let d,v,u,m,ue,j,gt,me,Pt,Ye,ae,yt,Ke,se,Tt,Qe,re,St,Ve,$,ve,_e,kt,At,we,$e,Ut,zt,be,Ee,Gt,Xe,b,R,ge,F,xt,Pe,Bt,Ze,D,Rt,le,Dt,Nt,et,J,tt,N,Ot,ye,Lt,qt,at,Y,st,oe,Wt,rt,E,O,Te,K,Ht,Se,Mt,lt,L,Ct,ke,It,jt,ot,ne,Ft,nt,q,it,W,Ae,g,Ue,Jt,Yt,ze,Kt,Qt,Ge,Vt,Xt,w,P,xe,Zt,ea,Be,ta,aa,Re,sa,ra,y,De,la,oa,Ne,na,ia,Oe,ha,fa,T,Le,ca,da,qe,pa,ua,We,ma,va,S,He,_a,wa,Me,$a,ba,Ce,Ea,ht,k,H,Ie,Q,ga,je,Pa,ft,_,ya,V,Ta,Sa,X,ka,Aa,Fe,Ua,za,ct,M,dt,Z,pt;return j=new Et({}),F=new Et({}),J=new Ga({props:{code:`from accelerate import set_seed

set_seed(42)`,highlighted:`<span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> set_seed

set_seed(<span class="hljs-number">42</span>)`}}),Y=new Ga({props:{code:`    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    # ^^ safe to call this function even if cuda is not available
    if is_tpu_available():
        xm.set_rng_state(seed)`,highlighted:`    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    <span class="hljs-comment"># ^^ safe to call this function even if cuda is not available</span>
    <span class="hljs-keyword">if</span> is_tpu_available():
        xm.set_rng_state(seed)`}}),K=new Et({}),q=new gs({props:{$$slots:{default:[As]},$$scope:{ctx:te}}}),Q=new Et({}),M=new gs({props:{$$slots:{default:[Us]},$$scope:{ctx:te}}}),Z=new Ga({props:{code:`learning_rate = 1e-3
accelerator = Accelerator()
learning_rate *= accelerator.num_processes

optimizer = AdamW(params=model.parameters(), lr=learning_rate)`,highlighted:`learning_rate = <span class="hljs-number">1e-3</span>
accelerator = Accelerator()
learning_rate *= accelerator.num_processes

optimizer = AdamW(params=model.parameters(), lr=learning_rate)`}}),{c(){d=s("meta"),v=h(),u=s("h1"),m=s("a"),ue=s("span"),A(j.$$.fragment),gt=h(),me=s("span"),Pt=n("Comparing performance between different device setups"),Ye=h(),ae=s("p"),yt=n(`Evaluating and comparing the performance from different setups can be quite tricky if you don\u2019t know what to look for.
For example, you cannot run the same script with the same batch size across TPU, multi-GPU, and single-GPU with Accelerate
and expect your results to line up.`),Ke=h(),se=s("p"),Tt=n("But why?"),Qe=h(),re=s("p"),St=n("There\u2019s three reasons for this that this tutorial will cover:"),Ve=h(),$=s("ol"),ve=s("li"),_e=s("strong"),kt=n("Setting the right seeds"),At=h(),we=s("li"),$e=s("strong"),Ut=n("Observed Batch Sizes"),zt=h(),be=s("li"),Ee=s("strong"),Gt=n("Learning Rates"),Xe=h(),b=s("h2"),R=s("a"),ge=s("span"),A(F.$$.fragment),xt=h(),Pe=s("span"),Bt=n("Setting the Seed"),Ze=h(),D=s("p"),Rt=n("While this issue has not come up as much, make sure to use "),le=s("a"),Dt=n("utils.set_seed()"),Nt=n(" to fully set the seed in all distributed cases so training will be reproducable:"),et=h(),A(J.$$.fragment),tt=h(),N=s("p"),Ot=n("Why is this important? Under the hood this will set "),ye=s("strong"),Lt=n("5"),qt=n(" different seed settings:"),at=h(),A(Y.$$.fragment),st=h(),oe=s("p"),Wt=n("The random state, numpy\u2019s state, torch, torch\u2019s cuda state, and if TPUs are available torch_xla\u2019s cuda state."),rt=h(),E=s("h2"),O=s("a"),Te=s("span"),A(K.$$.fragment),Ht=h(),Se=s("span"),Mt=n("Observed Batch Sizes"),lt=h(),L=s("p"),Ct=n("When training with Accelerate, the batch size passed to the dataloader is the "),ke=s("strong"),It=n("batch size per GPU"),jt=n(`. What this entails is
a batch size of 64 on two GPUs is truly a batch size of 128. As a result, when testing on a single GPU this needs to be accounted for,
as well as similarly for TPUs.`),ot=h(),ne=s("p"),Ft=n("The below table can be used as a quick reference to try out different batch sizes:"),nt=h(),A(q.$$.fragment),it=h(),W=s("table"),Ae=s("thead"),g=s("tr"),Ue=s("th"),Jt=n("Single GPU Batch Size"),Yt=h(),ze=s("th"),Kt=n("Multi-GPU Equivalent Batch Size"),Qt=h(),Ge=s("th"),Vt=n("TPU Equivalent Batch Size"),Xt=h(),w=s("tbody"),P=s("tr"),xe=s("td"),Zt=n("256"),ea=h(),Be=s("td"),ta=n("128"),aa=h(),Re=s("td"),sa=n("32"),ra=h(),y=s("tr"),De=s("td"),la=n("128"),oa=h(),Ne=s("td"),na=n("64"),ia=h(),Oe=s("td"),ha=n("16"),fa=h(),T=s("tr"),Le=s("td"),ca=n("64"),da=h(),qe=s("td"),pa=n("32"),ua=h(),We=s("td"),ma=n("8"),va=h(),S=s("tr"),He=s("td"),_a=n("32"),wa=h(),Me=s("td"),$a=n("16"),ba=h(),Ce=s("td"),Ea=n("4"),ht=h(),k=s("h2"),H=s("a"),Ie=s("span"),A(Q.$$.fragment),ga=h(),je=s("span"),Pa=n("Learning Rates"),ft=h(),_=s("p"),ya=n("As noted in multiple sources["),V=s("a"),Ta=n("1"),Sa=n("]["),X=s("a"),ka=n("2"),Aa=n("], the learning rate should be scaled "),Fe=s("em"),Ua=n("linearly"),za=n(` based on the number of devices present. The below
snippet shows doing so with Accelerate:`),ct=h(),A(M.$$.fragment),dt=h(),A(Z.$$.fragment),this.h()},l(e){const o=Ss('[data-svelte="svelte-1phssyn"]',document.head);d=r(o,"META",{name:!0,content:!0}),o.forEach(a),v=f(e),u=r(e,"H1",{class:!0});var ee=l(u);m=r(ee,"A",{id:!0,class:!0,href:!0});var Je=l(m);ue=r(Je,"SPAN",{});var xa=l(ue);U(j.$$.fragment,xa),xa.forEach(a),Je.forEach(a),gt=f(ee),me=r(ee,"SPAN",{});var Ba=l(me);Pt=i(Ba,"Comparing performance between different device setups"),Ba.forEach(a),ee.forEach(a),Ye=f(e),ae=r(e,"P",{});var Ra=l(ae);yt=i(Ra,`Evaluating and comparing the performance from different setups can be quite tricky if you don\u2019t know what to look for.
For example, you cannot run the same script with the same batch size across TPU, multi-GPU, and single-GPU with Accelerate
and expect your results to line up.`),Ra.forEach(a),Ke=f(e),se=r(e,"P",{});var Da=l(se);Tt=i(Da,"But why?"),Da.forEach(a),Qe=f(e),re=r(e,"P",{});var Na=l(re);St=i(Na,"There\u2019s three reasons for this that this tutorial will cover:"),Na.forEach(a),Ve=f(e),$=r(e,"OL",{});var ie=l($);ve=r(ie,"LI",{});var Oa=l(ve);_e=r(Oa,"STRONG",{});var La=l(_e);kt=i(La,"Setting the right seeds"),La.forEach(a),Oa.forEach(a),At=f(ie),we=r(ie,"LI",{});var qa=l(we);$e=r(qa,"STRONG",{});var Wa=l($e);Ut=i(Wa,"Observed Batch Sizes"),Wa.forEach(a),qa.forEach(a),zt=f(ie),be=r(ie,"LI",{});var Ha=l(be);Ee=r(Ha,"STRONG",{});var Ma=l(Ee);Gt=i(Ma,"Learning Rates"),Ma.forEach(a),Ha.forEach(a),ie.forEach(a),Xe=f(e),b=r(e,"H2",{class:!0});var ut=l(b);R=r(ut,"A",{id:!0,class:!0,href:!0});var Ca=l(R);ge=r(Ca,"SPAN",{});var Ia=l(ge);U(F.$$.fragment,Ia),Ia.forEach(a),Ca.forEach(a),xt=f(ut),Pe=r(ut,"SPAN",{});var ja=l(Pe);Bt=i(ja,"Setting the Seed"),ja.forEach(a),ut.forEach(a),Ze=f(e),D=r(e,"P",{});var mt=l(D);Rt=i(mt,"While this issue has not come up as much, make sure to use "),le=r(mt,"A",{href:!0});var Fa=l(le);Dt=i(Fa,"utils.set_seed()"),Fa.forEach(a),Nt=i(mt," to fully set the seed in all distributed cases so training will be reproducable:"),mt.forEach(a),et=f(e),U(J.$$.fragment,e),tt=f(e),N=r(e,"P",{});var vt=l(N);Ot=i(vt,"Why is this important? Under the hood this will set "),ye=r(vt,"STRONG",{});var Ja=l(ye);Lt=i(Ja,"5"),Ja.forEach(a),qt=i(vt," different seed settings:"),vt.forEach(a),at=f(e),U(Y.$$.fragment,e),st=f(e),oe=r(e,"P",{});var Ya=l(oe);Wt=i(Ya,"The random state, numpy\u2019s state, torch, torch\u2019s cuda state, and if TPUs are available torch_xla\u2019s cuda state."),Ya.forEach(a),rt=f(e),E=r(e,"H2",{class:!0});var _t=l(E);O=r(_t,"A",{id:!0,class:!0,href:!0});var Ka=l(O);Te=r(Ka,"SPAN",{});var Qa=l(Te);U(K.$$.fragment,Qa),Qa.forEach(a),Ka.forEach(a),Ht=f(_t),Se=r(_t,"SPAN",{});var Va=l(Se);Mt=i(Va,"Observed Batch Sizes"),Va.forEach(a),_t.forEach(a),lt=f(e),L=r(e,"P",{});var wt=l(L);Ct=i(wt,"When training with Accelerate, the batch size passed to the dataloader is the "),ke=r(wt,"STRONG",{});var Xa=l(ke);It=i(Xa,"batch size per GPU"),Xa.forEach(a),jt=i(wt,`. What this entails is
a batch size of 64 on two GPUs is truly a batch size of 128. As a result, when testing on a single GPU this needs to be accounted for,
as well as similarly for TPUs.`),wt.forEach(a),ot=f(e),ne=r(e,"P",{});var Za=l(ne);Ft=i(Za,"The below table can be used as a quick reference to try out different batch sizes:"),Za.forEach(a),nt=f(e),U(q.$$.fragment,e),it=f(e),W=r(e,"TABLE",{});var $t=l(W);Ae=r($t,"THEAD",{});var es=l(Ae);g=r(es,"TR",{});var he=l(g);Ue=r(he,"TH",{});var ts=l(Ue);Jt=i(ts,"Single GPU Batch Size"),ts.forEach(a),Yt=f(he),ze=r(he,"TH",{});var as=l(ze);Kt=i(as,"Multi-GPU Equivalent Batch Size"),as.forEach(a),Qt=f(he),Ge=r(he,"TH",{});var ss=l(Ge);Vt=i(ss,"TPU Equivalent Batch Size"),ss.forEach(a),he.forEach(a),es.forEach(a),Xt=f($t),w=r($t,"TBODY",{});var C=l(w);P=r(C,"TR",{});var fe=l(P);xe=r(fe,"TD",{});var rs=l(xe);Zt=i(rs,"256"),rs.forEach(a),ea=f(fe),Be=r(fe,"TD",{});var ls=l(Be);ta=i(ls,"128"),ls.forEach(a),aa=f(fe),Re=r(fe,"TD",{});var os=l(Re);sa=i(os,"32"),os.forEach(a),fe.forEach(a),ra=f(C),y=r(C,"TR",{});var ce=l(y);De=r(ce,"TD",{});var ns=l(De);la=i(ns,"128"),ns.forEach(a),oa=f(ce),Ne=r(ce,"TD",{});var is=l(Ne);na=i(is,"64"),is.forEach(a),ia=f(ce),Oe=r(ce,"TD",{});var hs=l(Oe);ha=i(hs,"16"),hs.forEach(a),ce.forEach(a),fa=f(C),T=r(C,"TR",{});var de=l(T);Le=r(de,"TD",{});var fs=l(Le);ca=i(fs,"64"),fs.forEach(a),da=f(de),qe=r(de,"TD",{});var cs=l(qe);pa=i(cs,"32"),cs.forEach(a),ua=f(de),We=r(de,"TD",{});var ds=l(We);ma=i(ds,"8"),ds.forEach(a),de.forEach(a),va=f(C),S=r(C,"TR",{});var pe=l(S);He=r(pe,"TD",{});var ps=l(He);_a=i(ps,"32"),ps.forEach(a),wa=f(pe),Me=r(pe,"TD",{});var us=l(Me);$a=i(us,"16"),us.forEach(a),ba=f(pe),Ce=r(pe,"TD",{});var ms=l(Ce);Ea=i(ms,"4"),ms.forEach(a),pe.forEach(a),C.forEach(a),$t.forEach(a),ht=f(e),k=r(e,"H2",{class:!0});var bt=l(k);H=r(bt,"A",{id:!0,class:!0,href:!0});var vs=l(H);Ie=r(vs,"SPAN",{});var _s=l(Ie);U(Q.$$.fragment,_s),_s.forEach(a),vs.forEach(a),ga=f(bt),je=r(bt,"SPAN",{});var ws=l(je);Pa=i(ws,"Learning Rates"),ws.forEach(a),bt.forEach(a),ft=f(e),_=r(e,"P",{});var I=l(_);ya=i(I,"As noted in multiple sources["),V=r(I,"A",{href:!0,rel:!0});var $s=l(V);Ta=i($s,"1"),$s.forEach(a),Sa=i(I,"]["),X=r(I,"A",{href:!0,rel:!0});var bs=l(X);ka=i(bs,"2"),bs.forEach(a),Aa=i(I,"], the learning rate should be scaled "),Fe=r(I,"EM",{});var Es=l(Fe);Ua=i(Es,"linearly"),Es.forEach(a),za=i(I,` based on the number of devices present. The below
snippet shows doing so with Accelerate:`),I.forEach(a),ct=f(e),U(M.$$.fragment,e),dt=f(e),U(Z.$$.fragment,e),this.h()},h(){p(d,"name","hf:doc:metadata"),p(d,"content",JSON.stringify(Gs)),p(m,"id","comparing-performance-between-different-device-setups"),p(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(m,"href","#comparing-performance-between-different-device-setups"),p(u,"class","relative group"),p(R,"id","setting-the-seed"),p(R,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(R,"href","#setting-the-seed"),p(b,"class","relative group"),p(le,"href","/docs/accelerate/v0.13.0/en/package_reference/utilities#accelerate.utils.set_seed"),p(O,"id","observed-batch-sizes"),p(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(O,"href","#observed-batch-sizes"),p(E,"class","relative group"),p(H,"id","learning-rates"),p(H,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(H,"href","#learning-rates"),p(k,"class","relative group"),p(V,"href","https://aws.amazon.com/blogs/machine-learning/scalable-multi-node-deep-learning-training-using-gpus-in-the-aws-cloud/"),p(V,"rel","nofollow"),p(X,"href","https://docs.nvidia.com/clara/tlt-mi_archive/clara-train-sdk-v2.0/nvmidl/appendix/training_with_multiple_gpus.html"),p(X,"rel","nofollow")},m(e,o){t(document.head,d),c(e,v,o),c(e,u,o),t(u,m),t(m,ue),z(j,ue,null),t(u,gt),t(u,me),t(me,Pt),c(e,Ye,o),c(e,ae,o),t(ae,yt),c(e,Ke,o),c(e,se,o),t(se,Tt),c(e,Qe,o),c(e,re,o),t(re,St),c(e,Ve,o),c(e,$,o),t($,ve),t(ve,_e),t(_e,kt),t($,At),t($,we),t(we,$e),t($e,Ut),t($,zt),t($,be),t(be,Ee),t(Ee,Gt),c(e,Xe,o),c(e,b,o),t(b,R),t(R,ge),z(F,ge,null),t(b,xt),t(b,Pe),t(Pe,Bt),c(e,Ze,o),c(e,D,o),t(D,Rt),t(D,le),t(le,Dt),t(D,Nt),c(e,et,o),z(J,e,o),c(e,tt,o),c(e,N,o),t(N,Ot),t(N,ye),t(ye,Lt),t(N,qt),c(e,at,o),z(Y,e,o),c(e,st,o),c(e,oe,o),t(oe,Wt),c(e,rt,o),c(e,E,o),t(E,O),t(O,Te),z(K,Te,null),t(E,Ht),t(E,Se),t(Se,Mt),c(e,lt,o),c(e,L,o),t(L,Ct),t(L,ke),t(ke,It),t(L,jt),c(e,ot,o),c(e,ne,o),t(ne,Ft),c(e,nt,o),z(q,e,o),c(e,it,o),c(e,W,o),t(W,Ae),t(Ae,g),t(g,Ue),t(Ue,Jt),t(g,Yt),t(g,ze),t(ze,Kt),t(g,Qt),t(g,Ge),t(Ge,Vt),t(W,Xt),t(W,w),t(w,P),t(P,xe),t(xe,Zt),t(P,ea),t(P,Be),t(Be,ta),t(P,aa),t(P,Re),t(Re,sa),t(w,ra),t(w,y),t(y,De),t(De,la),t(y,oa),t(y,Ne),t(Ne,na),t(y,ia),t(y,Oe),t(Oe,ha),t(w,fa),t(w,T),t(T,Le),t(Le,ca),t(T,da),t(T,qe),t(qe,pa),t(T,ua),t(T,We),t(We,ma),t(w,va),t(w,S),t(S,He),t(He,_a),t(S,wa),t(S,Me),t(Me,$a),t(S,ba),t(S,Ce),t(Ce,Ea),c(e,ht,o),c(e,k,o),t(k,H),t(H,Ie),z(Q,Ie,null),t(k,ga),t(k,je),t(je,Pa),c(e,ft,o),c(e,_,o),t(_,ya),t(_,V),t(V,Ta),t(_,Sa),t(_,X),t(X,ka),t(_,Aa),t(_,Fe),t(Fe,Ua),t(_,za),c(e,ct,o),z(M,e,o),c(e,dt,o),z(Z,e,o),pt=!0},p(e,[o]){const ee={};o&2&&(ee.$$scope={dirty:o,ctx:e}),q.$set(ee);const Je={};o&2&&(Je.$$scope={dirty:o,ctx:e}),M.$set(Je)},i(e){pt||(G(j.$$.fragment,e),G(F.$$.fragment,e),G(J.$$.fragment,e),G(Y.$$.fragment,e),G(K.$$.fragment,e),G(q.$$.fragment,e),G(Q.$$.fragment,e),G(M.$$.fragment,e),G(Z.$$.fragment,e),pt=!0)},o(e){x(j.$$.fragment,e),x(F.$$.fragment,e),x(J.$$.fragment,e),x(Y.$$.fragment,e),x(K.$$.fragment,e),x(q.$$.fragment,e),x(Q.$$.fragment,e),x(M.$$.fragment,e),x(Z.$$.fragment,e),pt=!1},d(e){a(d),e&&a(v),e&&a(u),B(j),e&&a(Ye),e&&a(ae),e&&a(Ke),e&&a(se),e&&a(Qe),e&&a(re),e&&a(Ve),e&&a($),e&&a(Xe),e&&a(b),B(F),e&&a(Ze),e&&a(D),e&&a(et),B(J,e),e&&a(tt),e&&a(N),e&&a(at),B(Y,e),e&&a(st),e&&a(oe),e&&a(rt),e&&a(E),B(K),e&&a(lt),e&&a(L),e&&a(ot),e&&a(ne),e&&a(nt),B(q,e),e&&a(it),e&&a(W),e&&a(ht),e&&a(k),B(Q),e&&a(ft),e&&a(_),e&&a(ct),B(M,e),e&&a(dt),B(Z,e)}}}const Gs={local:"comparing-performance-between-different-device-setups",sections:[{local:"setting-the-seed",title:"Setting the Seed "},{local:"observed-batch-sizes",title:"Observed Batch Sizes "},{local:"learning-rates",title:"Learning Rates "}],title:"Comparing performance between different device setups"};function xs(te){return ks(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Os extends Ps{constructor(d){super();ys(this,d,xs,zs,Ts,{})}}export{Os as default,Gs as metadata};
