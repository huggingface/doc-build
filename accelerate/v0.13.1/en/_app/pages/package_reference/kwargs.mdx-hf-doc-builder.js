import{S as It,i as jt,s as zt,e as r,k as p,w as I,t as s,M as Nt,c as o,d as a,m as u,a as l,x as j,h as n,b as c,G as t,g as d,y as z,q as N,o as C,B as H,v as Ct}from"../../chunks/vendor-hf-doc-builder.js";import{T as Tt}from"../../chunks/Tip-hf-doc-builder.js";import{D as ft}from"../../chunks/Docstring-hf-doc-builder.js";import{I as Ie}from"../../chunks/IconCopyLink-hf-doc-builder.js";function Ht(re){let i,v,m,g,_,f,b,K,B;return{c(){i=r("p"),v=r("code"),m=s("gradient_as_bucket_view"),g=s(" is only available in PyTorch 1.7.0 and later versions."),_=p(),f=r("p"),b=r("code"),K=s("static_graph"),B=s(" is only available in PyTorch 1.11.0 and later versions.")},l($){i=o($,"P",{});var w=l(i);v=o(w,"CODE",{});var oe=l(v);m=n(oe,"gradient_as_bucket_view"),oe.forEach(a),g=n(w," is only available in PyTorch 1.7.0 and later versions."),w.forEach(a),_=u($),f=o($,"P",{});var D=l(f);b=o(D,"CODE",{});var le=l(b);K=n(le,"static_graph"),le.forEach(a),B=n(D," is only available in PyTorch 1.11.0 and later versions."),D.forEach(a)},m($,w){d($,i,w),t(i,v),t(v,m),t(i,g),d($,_,w),d($,f,w),t(f,b),t(b,K),t(f,B)},d($){$&&a(i),$&&a(_),$&&a(f)}}}function Ot(re){let i,v,m,g;return{c(){i=r("p"),v=r("code"),m=s("GradScaler"),g=s(" is only available in PyTorch 1.5.0 and later versions.")},l(_){i=o(_,"P",{});var f=l(i);v=o(f,"CODE",{});var b=l(v);m=n(b,"GradScaler"),b.forEach(a),g=n(f," is only available in PyTorch 1.5.0 and later versions."),f.forEach(a)},m(_,f){d(_,i,f),t(i,v),t(v,m),t(i,g)},d(_){_&&a(i)}}}function Ut(re){let i,v,m,g,_,f,b,K,B,$,w,oe,D,le,je,be,k,O,de,J,ze,pe,Ne,ye,y,R,Ce,P,He,se,Oe,Ue,ue,Le,Fe,Q,qe,Me,Ve,U,Pe,S,L,me,W,Be,ve,Je,Ee,E,X,Re,A,Qe,ne,We,Xe,ge,Ye,Ze,Y,et,tt,at,F,Ae,G,q,_e,Z,rt,$e,ot,De,x,ee,lt,T,st,ce,nt,ct,te,it,ht,Ke;return f=new Ie({}),J=new Ie({}),R=new ft({props:{name:"class accelerate.DistributedDataParallelKwargs",anchor:"accelerate.DistributedDataParallelKwargs",parameters:[{name:"dim",val:": int = 0"},{name:"broadcast_buffers",val:": bool = True"},{name:"bucket_cap_mb",val:": int = 25"},{name:"find_unused_parameters",val:": bool = False"},{name:"check_reduction",val:": bool = False"},{name:"gradient_as_bucket_view",val:": bool = False"},{name:"static_graph",val:": bool = False"}],source:"https://github.com/huggingface/accelerate/blob/v0.13.1/src/accelerate/utils/dataclasses.py#L52"}}),U=new Tt({props:{warning:!0,$$slots:{default:[Ht]},$$scope:{ctx:re}}}),W=new Ie({}),X=new ft({props:{name:"class accelerate.GradScalerKwargs",anchor:"accelerate.GradScalerKwargs",parameters:[{name:"init_scale",val:": float = 65536.0"},{name:"growth_factor",val:": float = 2.0"},{name:"backoff_factor",val:": float = 0.5"},{name:"growth_interval",val:": int = 2000"},{name:"enabled",val:": bool = True"}],source:"https://github.com/huggingface/accelerate/blob/v0.13.1/src/accelerate/utils/dataclasses.py#L77"}}),F=new Tt({props:{warning:!0,$$slots:{default:[Ot]},$$scope:{ctx:re}}}),Z=new Ie({}),ee=new ft({props:{name:"class accelerate.InitProcessGroupKwargs",anchor:"accelerate.InitProcessGroupKwargs",parameters:[{name:"init_method",val:": typing.Optional[str] = None"},{name:"timeout",val:": timedelta = datetime.timedelta(seconds=1800)"}],source:"https://github.com/huggingface/accelerate/blob/v0.13.1/src/accelerate/utils/dataclasses.py#L97"}}),{c(){i=r("meta"),v=p(),m=r("h1"),g=r("a"),_=r("span"),I(f.$$.fragment),b=p(),K=r("span"),B=s("Kwargs Handlers"),$=p(),w=r("p"),oe=s("The following objects can be passed to the main "),D=r("a"),le=s("Accelerator"),je=s(` to customize how some PyTorch objects
related to distributed training or mixed precision are created.`),be=p(),k=r("h2"),O=r("a"),de=r("span"),I(J.$$.fragment),ze=p(),pe=r("span"),Ne=s("DistributedDataParallelKwargs"),ye=p(),y=r("div"),I(R.$$.fragment),Ce=p(),P=r("p"),He=s("Use this object in your "),se=r("a"),Oe=s("Accelerator"),Ue=s(` to customize how your model is wrapped in a
`),ue=r("code"),Le=s("torch.nn.parallel.DistributedDataParallel"),Fe=s(`. Please refer to the documentation of this
`),Q=r("a"),qe=s("wrapper"),Me=s(` for more
information on each argument.`),Ve=p(),I(U.$$.fragment),Pe=p(),S=r("h2"),L=r("a"),me=r("span"),I(W.$$.fragment),Be=p(),ve=r("span"),Je=s("GradScalerKwargs"),Ee=p(),E=r("div"),I(X.$$.fragment),Re=p(),A=r("p"),Qe=s("Use this object in your "),ne=r("a"),We=s("Accelerator"),Xe=s(` to customize the behavior of mixed precision, specifically how the
`),ge=r("code"),Ye=s("torch.cuda.amp.GradScaler"),Ze=s(` used is created. Please refer to the documentation of this
`),Y=r("a"),et=s("scaler"),tt=s(" for more information on each argument."),at=p(),I(F.$$.fragment),Ae=p(),G=r("h2"),q=r("a"),_e=r("span"),I(Z.$$.fragment),rt=p(),$e=r("span"),ot=s("InitProcessGroupKwargs"),De=p(),x=r("div"),I(ee.$$.fragment),lt=p(),T=r("p"),st=s("Use this object in your "),ce=r("a"),nt=s("Accelerator"),ct=s(` to customize the initialization of the distributed processes. Please refer
to the documentation of this
`),te=r("a"),it=s("method"),ht=s(` for more
information on each argument.`),this.h()},l(e){const h=Nt('[data-svelte="svelte-1phssyn"]',document.head);i=o(h,"META",{name:!0,content:!0}),h.forEach(a),v=u(e),m=o(e,"H1",{class:!0});var ae=l(m);g=o(ae,"A",{id:!0,class:!0,href:!0});var we=l(g);_=o(we,"SPAN",{});var dt=l(_);j(f.$$.fragment,dt),dt.forEach(a),we.forEach(a),b=u(ae),K=o(ae,"SPAN",{});var pt=l(K);B=n(pt,"Kwargs Handlers"),pt.forEach(a),ae.forEach(a),$=u(e),w=o(e,"P",{});var ke=l(w);oe=n(ke,"The following objects can be passed to the main "),D=o(ke,"A",{href:!0});var ut=l(D);le=n(ut,"Accelerator"),ut.forEach(a),je=n(ke,` to customize how some PyTorch objects
related to distributed training or mixed precision are created.`),ke.forEach(a),be=u(e),k=o(e,"H2",{class:!0});var Se=l(k);O=o(Se,"A",{id:!0,class:!0,href:!0});var mt=l(O);de=o(mt,"SPAN",{});var vt=l(de);j(J.$$.fragment,vt),vt.forEach(a),mt.forEach(a),ze=u(Se),pe=o(Se,"SPAN",{});var gt=l(pe);Ne=n(gt,"DistributedDataParallelKwargs"),gt.forEach(a),Se.forEach(a),ye=u(e),y=o(e,"DIV",{class:!0});var ie=l(y);j(R.$$.fragment,ie),Ce=u(ie),P=o(ie,"P",{});var M=l(P);He=n(M,"Use this object in your "),se=o(M,"A",{href:!0});var _t=l(se);Oe=n(_t,"Accelerator"),_t.forEach(a),Ue=n(M,` to customize how your model is wrapped in a
`),ue=o(M,"CODE",{});var $t=l(ue);Le=n($t,"torch.nn.parallel.DistributedDataParallel"),$t.forEach(a),Fe=n(M,`. Please refer to the documentation of this
`),Q=o(M,"A",{href:!0,rel:!0});var wt=l(Q);qe=n(wt,"wrapper"),wt.forEach(a),Me=n(M,` for more
information on each argument.`),M.forEach(a),Ve=u(ie),j(U.$$.fragment,ie),ie.forEach(a),Pe=u(e),S=o(e,"H2",{class:!0});var Ge=l(S);L=o(Ge,"A",{id:!0,class:!0,href:!0});var bt=l(L);me=o(bt,"SPAN",{});var yt=l(me);j(W.$$.fragment,yt),yt.forEach(a),bt.forEach(a),Be=u(Ge),ve=o(Ge,"SPAN",{});var Pt=l(ve);Je=n(Pt,"GradScalerKwargs"),Pt.forEach(a),Ge.forEach(a),Ee=u(e),E=o(e,"DIV",{class:!0});var he=l(E);j(X.$$.fragment,he),Re=u(he),A=o(he,"P",{});var V=l(A);Qe=n(V,"Use this object in your "),ne=o(V,"A",{href:!0});var Et=l(ne);We=n(Et,"Accelerator"),Et.forEach(a),Xe=n(V,` to customize the behavior of mixed precision, specifically how the
`),ge=o(V,"CODE",{});var At=l(ge);Ye=n(At,"torch.cuda.amp.GradScaler"),At.forEach(a),Ze=n(V,` used is created. Please refer to the documentation of this
`),Y=o(V,"A",{href:!0,rel:!0});var Dt=l(Y);et=n(Dt,"scaler"),Dt.forEach(a),tt=n(V," for more information on each argument."),V.forEach(a),at=u(he),j(F.$$.fragment,he),he.forEach(a),Ae=u(e),G=o(e,"H2",{class:!0});var xe=l(G);q=o(xe,"A",{id:!0,class:!0,href:!0});var Kt=l(q);_e=o(Kt,"SPAN",{});var kt=l(_e);j(Z.$$.fragment,kt),kt.forEach(a),Kt.forEach(a),rt=u(xe),$e=o(xe,"SPAN",{});var St=l($e);ot=n(St,"InitProcessGroupKwargs"),St.forEach(a),xe.forEach(a),De=u(e),x=o(e,"DIV",{class:!0});var Te=l(x);j(ee.$$.fragment,Te),lt=u(Te),T=o(Te,"P",{});var fe=l(T);st=n(fe,"Use this object in your "),ce=o(fe,"A",{href:!0});var Gt=l(ce);nt=n(Gt,"Accelerator"),Gt.forEach(a),ct=n(fe,` to customize the initialization of the distributed processes. Please refer
to the documentation of this
`),te=o(fe,"A",{href:!0,rel:!0});var xt=l(te);it=n(xt,"method"),xt.forEach(a),ht=n(fe,` for more
information on each argument.`),fe.forEach(a),Te.forEach(a),this.h()},h(){c(i,"name","hf:doc:metadata"),c(i,"content",JSON.stringify(Lt)),c(g,"id","kwargs-handlers"),c(g,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(g,"href","#kwargs-handlers"),c(m,"class","relative group"),c(D,"href","/docs/accelerate/v0.13.1/en/package_reference/accelerator#accelerate.Accelerator"),c(O,"id","accelerate.DistributedDataParallelKwargs"),c(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(O,"href","#accelerate.DistributedDataParallelKwargs"),c(k,"class","relative group"),c(se,"href","/docs/accelerate/v0.13.1/en/package_reference/accelerator#accelerate.Accelerator"),c(Q,"href","https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html"),c(Q,"rel","nofollow"),c(y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(L,"id","accelerate.GradScalerKwargs"),c(L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(L,"href","#accelerate.GradScalerKwargs"),c(S,"class","relative group"),c(ne,"href","/docs/accelerate/v0.13.1/en/package_reference/accelerator#accelerate.Accelerator"),c(Y,"href","https://pytorch.org/docs/stable/amp.html?highlight=gradscaler"),c(Y,"rel","nofollow"),c(E,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(q,"id","accelerate.InitProcessGroupKwargs"),c(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(q,"href","#accelerate.InitProcessGroupKwargs"),c(G,"class","relative group"),c(ce,"href","/docs/accelerate/v0.13.1/en/package_reference/accelerator#accelerate.Accelerator"),c(te,"href","https://pytorch.org/docs/stable/distributed.html#torch.distributed.init_process_group"),c(te,"rel","nofollow"),c(x,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,h){t(document.head,i),d(e,v,h),d(e,m,h),t(m,g),t(g,_),z(f,_,null),t(m,b),t(m,K),t(K,B),d(e,$,h),d(e,w,h),t(w,oe),t(w,D),t(D,le),t(w,je),d(e,be,h),d(e,k,h),t(k,O),t(O,de),z(J,de,null),t(k,ze),t(k,pe),t(pe,Ne),d(e,ye,h),d(e,y,h),z(R,y,null),t(y,Ce),t(y,P),t(P,He),t(P,se),t(se,Oe),t(P,Ue),t(P,ue),t(ue,Le),t(P,Fe),t(P,Q),t(Q,qe),t(P,Me),t(y,Ve),z(U,y,null),d(e,Pe,h),d(e,S,h),t(S,L),t(L,me),z(W,me,null),t(S,Be),t(S,ve),t(ve,Je),d(e,Ee,h),d(e,E,h),z(X,E,null),t(E,Re),t(E,A),t(A,Qe),t(A,ne),t(ne,We),t(A,Xe),t(A,ge),t(ge,Ye),t(A,Ze),t(A,Y),t(Y,et),t(A,tt),t(E,at),z(F,E,null),d(e,Ae,h),d(e,G,h),t(G,q),t(q,_e),z(Z,_e,null),t(G,rt),t(G,$e),t($e,ot),d(e,De,h),d(e,x,h),z(ee,x,null),t(x,lt),t(x,T),t(T,st),t(T,ce),t(ce,nt),t(T,ct),t(T,te),t(te,it),t(T,ht),Ke=!0},p(e,[h]){const ae={};h&2&&(ae.$$scope={dirty:h,ctx:e}),U.$set(ae);const we={};h&2&&(we.$$scope={dirty:h,ctx:e}),F.$set(we)},i(e){Ke||(N(f.$$.fragment,e),N(J.$$.fragment,e),N(R.$$.fragment,e),N(U.$$.fragment,e),N(W.$$.fragment,e),N(X.$$.fragment,e),N(F.$$.fragment,e),N(Z.$$.fragment,e),N(ee.$$.fragment,e),Ke=!0)},o(e){C(f.$$.fragment,e),C(J.$$.fragment,e),C(R.$$.fragment,e),C(U.$$.fragment,e),C(W.$$.fragment,e),C(X.$$.fragment,e),C(F.$$.fragment,e),C(Z.$$.fragment,e),C(ee.$$.fragment,e),Ke=!1},d(e){a(i),e&&a(v),e&&a(m),H(f),e&&a($),e&&a(w),e&&a(be),e&&a(k),H(J),e&&a(ye),e&&a(y),H(R),H(U),e&&a(Pe),e&&a(S),H(W),e&&a(Ee),e&&a(E),H(X),H(F),e&&a(Ae),e&&a(G),H(Z),e&&a(De),e&&a(x),H(ee)}}}const Lt={local:"kwargs-handlers",sections:[{local:"accelerate.DistributedDataParallelKwargs",title:"DistributedDataParallelKwargs"},{local:"accelerate.GradScalerKwargs",title:"GradScalerKwargs"},{local:"accelerate.InitProcessGroupKwargs",title:"InitProcessGroupKwargs"}],title:"Kwargs Handlers"};function Ft(re){return Ct(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Jt extends It{constructor(i){super();jt(this,i,Ft,Ut,zt,{})}}export{Jt as default,Lt as metadata};
