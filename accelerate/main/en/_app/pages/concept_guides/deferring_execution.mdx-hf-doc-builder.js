import{S as Jt,i as Rt,s as Kt,e as o,k as p,w as $,t as l,M as Qt,c as r,d as t,m as d,a as n,x as y,h as c,b as f,G as a,g as i,y as k,q as E,o as b,B as j,v as Vt}from"../../chunks/vendor-hf-doc-builder.js";import{T as Yt}from"../../chunks/Tip-hf-doc-builder.js";import{I as ke}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as ce}from"../../chunks/CodeBlock-hf-doc-builder.js";function Xt(ee){let h,v,u,_,w,m,P,A;return{c(){h=o("p"),v=l("Some of these are utilized with the "),u=o("a"),_=l("main_process_first()"),w=l(" context manager, which utilizes "),m=o("a"),P=l("wait_for_everyone()"),A=l(` to
run a particular set of code on the main process beforehand before triggering and launching the other processes`),this.h()},l(q){h=r(q,"P",{});var g=n(h);v=c(g,"Some of these are utilized with the "),u=r(g,"A",{href:!0});var x=n(u);_=c(x,"main_process_first()"),x.forEach(t),w=c(g," context manager, which utilizes "),m=r(g,"A",{href:!0});var te=n(m);P=c(te,"wait_for_everyone()"),te.forEach(t),A=c(g,` to
run a particular set of code on the main process beforehand before triggering and launching the other processes`),g.forEach(t),this.h()},h(){f(u,"href","/docs/accelerate/main/en/package_reference/accelerator#accelerate.Accelerator.main_process_first"),f(m,"href","/docs/accelerate/main/en/package_reference/accelerator#accelerate.Accelerator.wait_for_everyone")},m(q,g){i(q,h,g),a(h,v),a(h,u),a(u,_),a(h,w),a(h,m),a(m,P),a(h,A)},d(q){q&&t(h)}}}function Zt(ee){let h,v,u,_;return{c(){h=o("p"),v=o("code"),u=l("load_dataset"),_=l(` will perform a lock under the hood to stop multiple downloads from happening at once, but if you are downloading something
not using this library you should use this method.`)},l(w){h=r(w,"P",{});var m=n(h);v=r(m,"CODE",{});var P=n(v);u=c(P,"load_dataset"),P.forEach(t),_=c(m,` will perform a lock under the hood to stop multiple downloads from happening at once, but if you are downloading something
not using this library you should use this method.`),m.forEach(t)},m(w,m){i(w,h,m),a(h,v),a(v,u),a(h,_)},d(w){w&&t(h)}}}function ea(ee){let h,v,u,_,w,m,P,A,q,g,x,te,Ee,ae,Ve,be,M,je,se,Xe,Pe,oe,Ze,Ae,z,qe,S,N,he,B,et,pe,tt,xe,re,at,Se,T,De,I,Ce,ne,st,Ue,Y,ze,D,W,de,J,ot,ie,rt,fe,nt,Ne,O,it,ue,lt,ct,Te,R,We,C,G,me,K,ht,le,pt,_e,dt,Oe,H,ft,we,ut,mt,Ge,Q,He,U,L,ve,V,_t,ge,wt,Le,F,vt,$e,gt,$t,Fe,X,Me;return m=new ke({}),M=new ce({props:{code:"accelerator.wait_for_everyone()",highlighted:'accelerator.wait<span class="hljs-constructor">_for_everyone()</span>'}}),z=new Yt({props:{$$slots:{default:[Xt]},$$scope:{ctx:ee}}}),B=new ke({}),T=new Yt({props:{$$slots:{default:[Zt]},$$scope:{ctx:ee}}}),I=new ce({props:{code:`with accelerator.main_process_first():
    datasets = load_dataset("glue", "mrpc")`,highlighted:`<span class="hljs-keyword">with</span> accelerator.main_process_first():
    datasets = load_dataset(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mrpc&quot;</span>)`}}),Y=new ce({props:{code:`# First do something on the main process
if accelerator.is_main_process:
    datasets = load_dataset("glue", "mrpc")
else:
    accelerator.wait_for_everyone()

# And then send it to the rest of them
if not accelerator.is_main_process:
    datasets = load_dataset("glue", "mrpc")
else:
    accelerator.wait_for_everyone()`,highlighted:`<span class="hljs-comment"># First do something on the main process</span>
<span class="hljs-keyword">if</span> accelerator.is_main_process:
    datasets = load_dataset(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mrpc&quot;</span>)
<span class="hljs-keyword">else</span>:
    accelerator.wait_for_everyone()

<span class="hljs-comment"># And then send it to the rest of them</span>
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> accelerator.is_main_process:
    datasets = load_dataset(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mrpc&quot;</span>)
<span class="hljs-keyword">else</span>:
    accelerator.wait_for_everyone()`}}),J=new ke({}),R=new ce({props:{code:`if accelerator.is_main_process:
    model = accelerator.unwrap_model(model)
    torch.save(model.state_dict(), "weights.pth")`,highlighted:`<span class="hljs-keyword">if</span> accelerator.is_main_process:
    model = accelerator.unwrap_model(model)
    torch.save(model.state_dict(), <span class="hljs-string">&quot;weights.pth&quot;</span>)`}}),K=new ke({}),Q=new ce({props:{code:`with accelerator.main_process_first():
    state = torch.load("weights.pth")
    model.load_state_dict(state)`,highlighted:`<span class="hljs-keyword">with</span> accelerator.main_process_first():
    state = torch.load(<span class="hljs-string">&quot;weights.pth&quot;</span>)
    model.load_state_dict(state)`}}),V=new ke({}),X=new ce({props:{code:`datasets = load_dataset("glue", "mrpc")

with accelerator.main_process_first():
    tokenized_datasets = datasets.map(
        tokenize_function,
        batched=True,
        remove_columns=["idx", "sentence1", "sentence2"],
    )`,highlighted:`datasets = load_dataset(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mrpc&quot;</span>)

<span class="hljs-keyword">with</span> accelerator.main_process_first():
    tokenized_datasets = datasets.<span class="hljs-built_in">map</span>(
        tokenize_function,
        batched=<span class="hljs-literal">True</span>,
        remove_columns=[<span class="hljs-string">&quot;idx&quot;</span>, <span class="hljs-string">&quot;sentence1&quot;</span>, <span class="hljs-string">&quot;sentence2&quot;</span>],
    )`}}),{c(){h=o("meta"),v=p(),u=o("h1"),_=o("a"),w=o("span"),$(m.$$.fragment),P=p(),A=o("span"),q=l("Deferring Executions"),g=p(),x=o("p"),te=l(`When you run your usual script, instructions are executed in order. Using \u{1F917} Accelerate to deploy your script on several
GPUs at the same time introduces a complication: while each process executes all instructions in order, some may be
faster than others.`),Ee=p(),ae=o("p"),Ve=l(`You might need to wait for all processes to have reached a certain point before executing a given instruction. For
instance, you shouldn\u2019t save a model before being sure every process is done with training, and you wouldn\u2019t want to
continue training before all the model weights have been loaded in. To do this, just write the following line in your code:`),be=p(),$(M.$$.fragment),je=p(),se=o("p"),Xe=l(`This instruction will block all the processes that arrive first until all the other processes have reached that
point (if you run your script on just one GPU or CPU, this won\u2019t do anything).`),Pe=p(),oe=o("p"),Ze=l("A few example cases for when to use this utility are listed below:"),Ae=p(),$(z.$$.fragment),qe=p(),S=o("h2"),N=o("a"),he=o("span"),$(B.$$.fragment),et=p(),pe=o("span"),tt=l("Downloading a Dataset"),xe=p(),re=o("p"),at=l("When downloading a dataset, you should download it first on the main process and then loading the cached dataset in afterwards"),Se=p(),$(T.$$.fragment),De=p(),$(I.$$.fragment),Ce=p(),ne=o("p"),st=l("Under the hood this is the same as calling:"),Ue=p(),$(Y.$$.fragment),ze=p(),D=o("h2"),W=o("a"),de=o("span"),$(J.$$.fragment),ot=p(),ie=o("span"),rt=l("Saving the "),fe=o("code"),nt=l("state_dict"),Ne=p(),O=o("p"),it=l("When saving the "),ue=o("code"),lt=l("state_dict"),ct=l(` of the model, since you would normally save one file on just the main process
you should specify that:`),Te=p(),$(R.$$.fragment),We=p(),C=o("h2"),G=o("a"),me=o("span"),$(K.$$.fragment),ht=p(),le=o("span"),pt=l("Loading in the "),_e=o("code"),dt=l("state_dict"),Oe=p(),H=o("p"),ft=l("When loading in the "),we=o("code"),ut=l("state_dict"),mt=l(` to a model, optimizer, or scheduler, you should wait
for all workers to have the weights loaded in before moving on to training`),Ge=p(),$(Q.$$.fragment),He=p(),U=o("h2"),L=o("a"),ve=o("span"),$(V.$$.fragment),_t=p(),ge=o("span"),wt=l("Applying a multi-worker CPU operation"),Le=p(),F=o("p"),vt=l("Applying a "),$e=o("code"),gt=l("map()"),$t=l(` operation on multiple workers, such as tokenizing should be done on the
main process first, and then propagated to each one.`),Fe=p(),$(X.$$.fragment),this.h()},l(e){const s=Qt('[data-svelte="svelte-1phssyn"]',document.head);h=r(s,"META",{name:!0,content:!0}),s.forEach(t),v=d(e),u=r(e,"H1",{class:!0});var Z=n(u);_=r(Z,"A",{id:!0,class:!0,href:!0});var ye=n(_);w=r(ye,"SPAN",{});var Et=n(w);y(m.$$.fragment,Et),Et.forEach(t),ye.forEach(t),P=d(Z),A=r(Z,"SPAN",{});var bt=n(A);q=c(bt,"Deferring Executions"),bt.forEach(t),Z.forEach(t),g=d(e),x=r(e,"P",{});var jt=n(x);te=c(jt,`When you run your usual script, instructions are executed in order. Using \u{1F917} Accelerate to deploy your script on several
GPUs at the same time introduces a complication: while each process executes all instructions in order, some may be
faster than others.`),jt.forEach(t),Ee=d(e),ae=r(e,"P",{});var Pt=n(ae);Ve=c(Pt,`You might need to wait for all processes to have reached a certain point before executing a given instruction. For
instance, you shouldn\u2019t save a model before being sure every process is done with training, and you wouldn\u2019t want to
continue training before all the model weights have been loaded in. To do this, just write the following line in your code:`),Pt.forEach(t),be=d(e),y(M.$$.fragment,e),je=d(e),se=r(e,"P",{});var At=n(se);Xe=c(At,`This instruction will block all the processes that arrive first until all the other processes have reached that
point (if you run your script on just one GPU or CPU, this won\u2019t do anything).`),At.forEach(t),Pe=d(e),oe=r(e,"P",{});var qt=n(oe);Ze=c(qt,"A few example cases for when to use this utility are listed below:"),qt.forEach(t),Ae=d(e),y(z.$$.fragment,e),qe=d(e),S=r(e,"H2",{class:!0});var Be=n(S);N=r(Be,"A",{id:!0,class:!0,href:!0});var xt=n(N);he=r(xt,"SPAN",{});var St=n(he);y(B.$$.fragment,St),St.forEach(t),xt.forEach(t),et=d(Be),pe=r(Be,"SPAN",{});var Dt=n(pe);tt=c(Dt,"Downloading a Dataset"),Dt.forEach(t),Be.forEach(t),xe=d(e),re=r(e,"P",{});var Ct=n(re);at=c(Ct,"When downloading a dataset, you should download it first on the main process and then loading the cached dataset in afterwards"),Ct.forEach(t),Se=d(e),y(T.$$.fragment,e),De=d(e),y(I.$$.fragment,e),Ce=d(e),ne=r(e,"P",{});var Ut=n(ne);st=c(Ut,"Under the hood this is the same as calling:"),Ut.forEach(t),Ue=d(e),y(Y.$$.fragment,e),ze=d(e),D=r(e,"H2",{class:!0});var Ie=n(D);W=r(Ie,"A",{id:!0,class:!0,href:!0});var zt=n(W);de=r(zt,"SPAN",{});var Nt=n(de);y(J.$$.fragment,Nt),Nt.forEach(t),zt.forEach(t),ot=d(Ie),ie=r(Ie,"SPAN",{});var yt=n(ie);rt=c(yt,"Saving the "),fe=r(yt,"CODE",{});var Tt=n(fe);nt=c(Tt,"state_dict"),Tt.forEach(t),yt.forEach(t),Ie.forEach(t),Ne=d(e),O=r(e,"P",{});var Ye=n(O);it=c(Ye,"When saving the "),ue=r(Ye,"CODE",{});var Wt=n(ue);lt=c(Wt,"state_dict"),Wt.forEach(t),ct=c(Ye,` of the model, since you would normally save one file on just the main process
you should specify that:`),Ye.forEach(t),Te=d(e),y(R.$$.fragment,e),We=d(e),C=r(e,"H2",{class:!0});var Je=n(C);G=r(Je,"A",{id:!0,class:!0,href:!0});var Ot=n(G);me=r(Ot,"SPAN",{});var Gt=n(me);y(K.$$.fragment,Gt),Gt.forEach(t),Ot.forEach(t),ht=d(Je),le=r(Je,"SPAN",{});var kt=n(le);pt=c(kt,"Loading in the "),_e=r(kt,"CODE",{});var Ht=n(_e);dt=c(Ht,"state_dict"),Ht.forEach(t),kt.forEach(t),Je.forEach(t),Oe=d(e),H=r(e,"P",{});var Re=n(H);ft=c(Re,"When loading in the "),we=r(Re,"CODE",{});var Lt=n(we);ut=c(Lt,"state_dict"),Lt.forEach(t),mt=c(Re,` to a model, optimizer, or scheduler, you should wait
for all workers to have the weights loaded in before moving on to training`),Re.forEach(t),Ge=d(e),y(Q.$$.fragment,e),He=d(e),U=r(e,"H2",{class:!0});var Ke=n(U);L=r(Ke,"A",{id:!0,class:!0,href:!0});var Ft=n(L);ve=r(Ft,"SPAN",{});var Mt=n(ve);y(V.$$.fragment,Mt),Mt.forEach(t),Ft.forEach(t),_t=d(Ke),ge=r(Ke,"SPAN",{});var Bt=n(ge);wt=c(Bt,"Applying a multi-worker CPU operation"),Bt.forEach(t),Ke.forEach(t),Le=d(e),F=r(e,"P",{});var Qe=n(F);vt=c(Qe,"Applying a "),$e=r(Qe,"CODE",{});var It=n($e);gt=c(It,"map()"),It.forEach(t),$t=c(Qe,` operation on multiple workers, such as tokenizing should be done on the
main process first, and then propagated to each one.`),Qe.forEach(t),Fe=d(e),y(X.$$.fragment,e),this.h()},h(){f(h,"name","hf:doc:metadata"),f(h,"content",JSON.stringify(ta)),f(_,"id","deferring-executions"),f(_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(_,"href","#deferring-executions"),f(u,"class","relative group"),f(N,"id","downloading-a-dataset"),f(N,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(N,"href","#downloading-a-dataset"),f(S,"class","relative group"),f(W,"id","saving-the-statedict"),f(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(W,"href","#saving-the-statedict"),f(D,"class","relative group"),f(G,"id","loading-in-the-statedict"),f(G,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(G,"href","#loading-in-the-statedict"),f(C,"class","relative group"),f(L,"id","applying-a-multiworker-cpu-operation"),f(L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(L,"href","#applying-a-multiworker-cpu-operation"),f(U,"class","relative group")},m(e,s){a(document.head,h),i(e,v,s),i(e,u,s),a(u,_),a(_,w),k(m,w,null),a(u,P),a(u,A),a(A,q),i(e,g,s),i(e,x,s),a(x,te),i(e,Ee,s),i(e,ae,s),a(ae,Ve),i(e,be,s),k(M,e,s),i(e,je,s),i(e,se,s),a(se,Xe),i(e,Pe,s),i(e,oe,s),a(oe,Ze),i(e,Ae,s),k(z,e,s),i(e,qe,s),i(e,S,s),a(S,N),a(N,he),k(B,he,null),a(S,et),a(S,pe),a(pe,tt),i(e,xe,s),i(e,re,s),a(re,at),i(e,Se,s),k(T,e,s),i(e,De,s),k(I,e,s),i(e,Ce,s),i(e,ne,s),a(ne,st),i(e,Ue,s),k(Y,e,s),i(e,ze,s),i(e,D,s),a(D,W),a(W,de),k(J,de,null),a(D,ot),a(D,ie),a(ie,rt),a(ie,fe),a(fe,nt),i(e,Ne,s),i(e,O,s),a(O,it),a(O,ue),a(ue,lt),a(O,ct),i(e,Te,s),k(R,e,s),i(e,We,s),i(e,C,s),a(C,G),a(G,me),k(K,me,null),a(C,ht),a(C,le),a(le,pt),a(le,_e),a(_e,dt),i(e,Oe,s),i(e,H,s),a(H,ft),a(H,we),a(we,ut),a(H,mt),i(e,Ge,s),k(Q,e,s),i(e,He,s),i(e,U,s),a(U,L),a(L,ve),k(V,ve,null),a(U,_t),a(U,ge),a(ge,wt),i(e,Le,s),i(e,F,s),a(F,vt),a(F,$e),a($e,gt),a(F,$t),i(e,Fe,s),k(X,e,s),Me=!0},p(e,[s]){const Z={};s&2&&(Z.$$scope={dirty:s,ctx:e}),z.$set(Z);const ye={};s&2&&(ye.$$scope={dirty:s,ctx:e}),T.$set(ye)},i(e){Me||(E(m.$$.fragment,e),E(M.$$.fragment,e),E(z.$$.fragment,e),E(B.$$.fragment,e),E(T.$$.fragment,e),E(I.$$.fragment,e),E(Y.$$.fragment,e),E(J.$$.fragment,e),E(R.$$.fragment,e),E(K.$$.fragment,e),E(Q.$$.fragment,e),E(V.$$.fragment,e),E(X.$$.fragment,e),Me=!0)},o(e){b(m.$$.fragment,e),b(M.$$.fragment,e),b(z.$$.fragment,e),b(B.$$.fragment,e),b(T.$$.fragment,e),b(I.$$.fragment,e),b(Y.$$.fragment,e),b(J.$$.fragment,e),b(R.$$.fragment,e),b(K.$$.fragment,e),b(Q.$$.fragment,e),b(V.$$.fragment,e),b(X.$$.fragment,e),Me=!1},d(e){t(h),e&&t(v),e&&t(u),j(m),e&&t(g),e&&t(x),e&&t(Ee),e&&t(ae),e&&t(be),j(M,e),e&&t(je),e&&t(se),e&&t(Pe),e&&t(oe),e&&t(Ae),j(z,e),e&&t(qe),e&&t(S),j(B),e&&t(xe),e&&t(re),e&&t(Se),j(T,e),e&&t(De),j(I,e),e&&t(Ce),e&&t(ne),e&&t(Ue),j(Y,e),e&&t(ze),e&&t(D),j(J),e&&t(Ne),e&&t(O),e&&t(Te),j(R,e),e&&t(We),e&&t(C),j(K),e&&t(Oe),e&&t(H),e&&t(Ge),j(Q,e),e&&t(He),e&&t(U),j(V),e&&t(Le),e&&t(F),e&&t(Fe),j(X,e)}}}const ta={local:"deferring-executions",sections:[{local:"downloading-a-dataset",title:"Downloading a Dataset "},{local:"saving-the-statedict",title:"Saving the `state_dict`"},{local:"loading-in-the-statedict",title:"Loading in the `state_dict`"},{local:"applying-a-multiworker-cpu-operation",title:"Applying a multi-worker CPU operation "}],title:"Deferring Executions"};function aa(ee){return Vt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ia extends Jt{constructor(h){super();Rt(this,h,aa,ea,Kt,{})}}export{ia as default,ta as metadata};
