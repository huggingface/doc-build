import{S as bO,i as PO,s as SO,e as a,k as d,w as b,t as l,M as yO,c,d as t,m as f,a as i,x as P,h as r,b as h,G as e,g as n,y as S,L as TO,q as y,o as T,B as A,v as AO}from"../../chunks/vendor-hf-doc-builder.js";import{I as Bt}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as Yo}from"../../chunks/CodeBlock-hf-doc-builder.js";function IO(m5){let ne,cn,de,me,Dl,Kt,Ef,wl,vf,sn,Zo,mf,nn,fe,ge,bl,Xt,gf,Pl,Cf,dn,jt,Sl,Of,Df,fn,Ce,yl,wf,bf,Tl,Pf,hn,Oe,Sf,Al,yf,Tf,pn,Yt,Il,Af,If,un,Zt,_n,qt,Ll,Lf,$f,En,De,m,$l,Nf,Uf,Nl,Mf,kf,Ul,Gf,xf,Ml,Rf,Ff,kl,Wf,Hf,Gl,zf,Bf,Kf,B,xl,Xf,jf,Rl,Yf,Zf,Fl,qf,Jf,vn,he,we,Wl,Jt,Qf,Hl,Vf,mn,Qt,zl,eh,th,gn,be,Bl,oh,lh,Kl,rh,Cn,qo,ah,On,Vt,Xl,ch,ih,Dn,eo,wn,to,jl,sh,nh,bn,K,Yl,g,Zl,dh,fh,ql,hh,ph,Jl,uh,_h,Ql,Eh,vh,Vl,mh,gh,er,Ch,Oh,Dh,tr,X,or,wh,bh,lr,Ph,Sh,rr,yh,Th,Ah,ar,Pe,cr,Ih,Lh,ir,$h,Nh,Pn,pe,Se,sr,oo,Uh,nr,Mh,Sn,lo,dr,kh,Gh,yn,ye,fr,xh,Rh,hr,Fh,Tn,Jo,Wh,An,ro,pr,Hh,zh,In,ao,Ln,co,ur,Bh,Kh,$n,Te,_r,C,Er,Xh,jh,vr,Yh,Zh,mr,qh,Jh,gr,Qh,Vh,Cr,ep,tp,Or,op,lp,rp,Dr,j,wr,ap,cp,br,ip,sp,Pr,np,dp,Nn,ue,Ae,Sr,io,fp,yr,hp,Un,so,Tr,pp,up,Mn,Ie,Ar,_p,Ep,Ir,vp,kn,Le,mp,no,gp,Cp,Gn,fo,Lr,Op,Dp,xn,ho,Rn,po,$r,wp,bp,Fn,$e,O,Nr,Pp,Sp,Ur,yp,Tp,Mr,Ap,Ip,kr,Lp,$p,Gr,Np,Up,xr,Mp,kp,Gp,Y,Rr,xp,Rp,Fr,Fp,Wp,Wr,Hp,zp,Wn,_e,Ne,Hr,uo,Bp,zr,Kp,Hn,_o,Br,Xp,jp,zn,Ue,Kr,Yp,Zp,Xr,qp,Bn,Qo,Jp,Kn,Eo,jr,Qp,Vp,Xn,vo,jn,mo,Yr,eu,tu,Yn,Me,Vo,Zr,ou,lu,ru,el,qr,au,cu,Zn,go,Jr,iu,su,qn,I,Z,Qr,nu,du,Vr,fu,hu,ea,pu,uu,_u,ke,ta,Eu,vu,oa,mu,gu,Cu,q,la,Ou,Du,ra,wu,bu,aa,Pu,Su,yu,Ge,ca,Tu,Au,ia,Iu,Lu,$u,xe,sa,Nu,Uu,na,Mu,ku,Jn,J,Gu,da,xu,Ru,fa,Fu,Wu,Qn,Co,ha,Hu,zu,Vn,F,Re,pa,Bu,Ku,ua,Xu,ju,Yu,Fe,_a,Zu,qu,Ea,Ju,Qu,Vu,We,va,e_,t_,ma,o_,l_,r_,He,ga,a_,c_,Ca,i_,s_,ed,Oo,Oa,n_,d_,td,tl,f_,od,W,ze,Da,h_,p_,wa,u_,__,E_,Be,ba,v_,m_,Pa,g_,C_,O_,Ke,Sa,D_,w_,ya,b_,P_,S_,Xe,Ta,y_,T_,Aa,A_,I_,ld,Do,Ia,L_,$_,rd,ol,N_,ad,Q,je,La,U_,M_,$a,k_,G_,x_,Ye,Na,R_,F_,Ua,W_,H_,z_,Ze,Ma,B_,K_,ka,X_,j_,cd,wo,Ga,Y_,Z_,id,V,q_,xa,J_,Q_,Ra,V_,e1,sd,_,qe,Fa,t1,o1,Wa,l1,r1,a1,Je,Ha,c1,i1,za,s1,n1,d1,Qe,Ba,f1,h1,Ka,p1,u1,_1,Ve,Xa,E1,v1,ja,m1,g1,C1,et,Ya,O1,D1,Za,w1,b1,P1,tt,qa,S1,y1,Ja,T1,A1,I1,ot,Qa,L1,$1,Va,N1,U1,M1,lt,ec,k1,G1,tc,x1,R1,nd,bo,oc,F1,W1,dd,ee,H1,lc,z1,B1,rc,K1,X1,fd,rt,at,ac,j1,Y1,cc,Z1,q1,J1,ct,ic,Q1,V1,sc,eE,tE,hd,Po,nc,oE,lE,pd,H,rE,dc,aE,cE,fc,iE,sE,hc,nE,dE,ud,p,it,pc,fE,hE,uc,pE,uE,_E,st,_c,EE,vE,Ec,mE,gE,CE,nt,vc,OE,DE,mc,wE,bE,PE,dt,gc,SE,yE,Cc,TE,AE,IE,ft,Oc,LE,$E,Dc,NE,UE,ME,ht,wc,kE,GE,bc,xE,RE,FE,te,Pc,WE,HE,Sc,zE,BE,yc,KE,XE,jE,pt,Tc,YE,ZE,Ac,qE,JE,QE,ut,Ic,VE,ev,Lc,tv,ov,lv,_t,$c,rv,av,Nc,cv,iv,sv,Et,Uc,nv,dv,Mc,fv,hv,pv,vt,kc,uv,_v,Gc,Ev,vv,_d,So,xc,mv,gv,Ed,oe,Cv,Rc,Ov,Dv,Fc,wv,bv,vd,E,mt,Wc,Pv,Sv,Hc,yv,Tv,Av,gt,zc,Iv,Lv,Bc,$v,Nv,Uv,Ct,Kc,Mv,kv,Xc,Gv,xv,Rv,Ot,jc,Fv,Wv,Yc,Hv,zv,Bv,L,Zc,Kv,Xv,qc,jv,Yv,Jc,Zv,qv,Qc,Jv,Qv,Vc,Vv,em,tm,Dt,ei,om,lm,ti,rm,am,cm,wt,oi,im,sm,li,nm,dm,md,yo,ri,fm,hm,gd,le,pm,ai,um,_m,ci,Em,vm,Cd,v,ll,ii,mm,gm,Cm,rl,si,Om,Dm,wm,al,ni,bm,Pm,Sm,cl,di,ym,Tm,Am,il,fi,Im,Lm,$m,sl,hi,Nm,Um,Mm,nl,pi,km,Gm,Od,To,ui,xm,Rm,Dd,dl,Fm,wd,bt,Pt,_i,Wm,Hm,Ei,zm,Bm,Km,St,vi,Xm,jm,mi,Ym,Zm,bd,Ee,yt,gi,Ao,qm,Ci,Jm,Pd,fl,Oi,Qm,Sd,Io,Di,Vm,e2,yd,Lo,Td,$o,wi,t2,o2,Ad,hl,re,bi,l2,r2,Pi,a2,c2,Si,i2,s2,Id,No,yi,n2,d2,Ld,Tt,f2,Ti,h2,p2,$d,ae,At,Ai,u2,_2,Ii,E2,v2,m2,It,Li,g2,C2,$i,O2,D2,w2,Lt,Ni,b2,P2,Ui,S2,y2,Nd,Uo,Mi,T2,A2,Ud,pl,I2,Md,$,$t,ki,L2,$2,Gi,N2,U2,M2,Nt,xi,k2,G2,Ri,x2,R2,F2,Ut,Fi,W2,H2,Wi,z2,B2,K2,Mt,Hi,X2,j2,zi,Y2,Z2,q2,kt,Bi,J2,Q2,Ki,V2,e3,kd,ve,Gt,Xi,Mo,t3,ji,o3,Gd,xt,Yi,l3,r3,Zi,a3,xd,Rt,c3,qi,i3,s3,Rd,ko,Ji,n3,d3,Fd,Go,Wd,xo,Qi,f3,h3,Hd,Ft,D,Vi,p3,u3,es,_3,E3,ts,v3,m3,os,g3,C3,ls,O3,D3,rs,w3,b3,P3,ce,as,S3,y3,cs,T3,A3,is,I3,L3,zd;return Kt=new Bt({}),Xt=new Bt({}),Zt=new Yo({props:{code:"accelerate config [arguments]",highlighted:"accelerate config [arguments]"}}),Jt=new Bt({}),eo=new Yo({props:{code:"accelerate config default [arguments]",highlighted:"accelerate config default [arguments]"}}),oo=new Bt({}),ao=new Yo({props:{code:"accelerate config update [arguments]",highlighted:"accelerate config update [arguments]"}}),io=new Bt({}),ho=new Yo({props:{code:"accelerate env [arguments]",highlighted:'accelerate <span class="hljs-built_in">env</span> [arguments]'}}),uo=new Bt({}),vo=new Yo({props:{code:"accelerate launch [arguments] {training_script} --{training_script-argument-1} --{training_script-argument-2} ...",highlighted:"accelerate launch [arguments] {training_script} --{training_script-argument-1} --{training_script-argument-2} ..."}}),Ao=new Bt({}),Lo=new Yo({props:{code:"accelerate tpu-config [arguments]",highlighted:"accelerate tpu-config [arguments]"}}),Mo=new Bt({}),Go=new Yo({props:{code:"accelerate test [arguments]",highlighted:'accelerate <span class="hljs-built_in">test</span> [arguments]'}}),{c(){ne=a("meta"),cn=d(),de=a("h1"),me=a("a"),Dl=a("span"),b(Kt.$$.fragment),Ef=d(),wl=a("span"),vf=l("The Command Line"),sn=d(),Zo=a("p"),mf=l("Below is a list of all the available commands \u{1F917} Accelerate with their parameters"),nn=d(),fe=a("h2"),ge=a("a"),bl=a("span"),b(Xt.$$.fragment),gf=d(),Pl=a("span"),Cf=l("accelerate config"),dn=d(),jt=a("p"),Sl=a("strong"),Of=l("Command"),Df=l(":"),fn=d(),Ce=a("p"),yl=a("code"),wf=l("accelerate config"),bf=l(" or "),Tl=a("code"),Pf=l("accelerate-config"),hn=d(),Oe=a("p"),Sf=l("Launches a series of prompts to create and save a "),Al=a("code"),yf=l("default_config.yml"),Tf=l(` configuration file for your training system. Should
always be ran first on your machine.`),pn=d(),Yt=a("p"),Il=a("strong"),Af=l("Usage"),If=l(":"),un=d(),b(Zt.$$.fragment),_n=d(),qt=a("p"),Ll=a("strong"),Lf=l("Optional Arguments"),$f=l(":"),En=d(),De=a("ul"),m=a("li"),$l=a("code"),Nf=l("--config_file CONFIG_FILE"),Uf=l(" ("),Nl=a("code"),Mf=l("str"),kf=l(`) \u2014 The path to use to store the config file. Will default to a file named default_config.yaml in the cache location, which is the content
of the environment `),Ul=a("code"),Gf=l("HF_HOME"),xf=l(` suffixed with \u2018accelerate\u2019, or if you don\u2019t have such an environment variable, your cache directory
(`),Ml=a("code"),Rf=l("~/.cache"),Ff=l(" or the content of "),kl=a("code"),Wf=l("XDG_CACHE_HOME"),Hf=l(") suffixed with "),Gl=a("code"),zf=l("huggingface"),Bf=l("."),Kf=d(),B=a("li"),xl=a("code"),Xf=l("-h"),jf=l(", "),Rl=a("code"),Yf=l("--help"),Zf=l(" ("),Fl=a("code"),qf=l("bool"),Jf=l(") \u2014 Show a help message and exit"),vn=d(),he=a("h2"),we=a("a"),Wl=a("span"),b(Jt.$$.fragment),Qf=d(),Hl=a("span"),Vf=l("accelerate config default"),mn=d(),Qt=a("p"),zl=a("strong"),eh=l("Command"),th=l(":"),gn=d(),be=a("p"),Bl=a("code"),oh=l("accelerate config default"),lh=l(" or "),Kl=a("code"),rh=l("accelerate-config default"),Cn=d(),qo=a("p"),ah=l("Create a default config file for Accelerate with only a few flags set."),On=d(),Vt=a("p"),Xl=a("strong"),ch=l("Usage"),ih=l(":"),Dn=d(),b(eo.$$.fragment),wn=d(),to=a("p"),jl=a("strong"),sh=l("Optional Arguments"),nh=l(":"),bn=d(),K=a("ul"),Yl=a("li"),g=a("p"),Zl=a("code"),dh=l("--config_file CONFIG_FILE"),fh=l(" ("),ql=a("code"),hh=l("str"),ph=l(`) \u2014 The path to use to store the config file. Will default to a file named default_config.yaml in the cache location, which is the content
of the environment `),Jl=a("code"),uh=l("HF_HOME"),_h=l(` suffixed with \u2018accelerate\u2019, or if you don\u2019t have such an environment variable, your cache directory
(`),Ql=a("code"),Eh=l("~/.cache"),vh=l(" or the content of "),Vl=a("code"),mh=l("XDG_CACHE_HOME"),gh=l(") suffixed with "),er=a("code"),Ch=l("huggingface"),Oh=l("."),Dh=d(),tr=a("li"),X=a("p"),or=a("code"),wh=l("-h"),bh=l(", "),lr=a("code"),Ph=l("--help"),Sh=l(" ("),rr=a("code"),yh=l("bool"),Th=l(") \u2014 Show a help message and exit"),Ah=d(),ar=a("li"),Pe=a("p"),cr=a("code"),Ih=l("--mixed_precision {no,fp16,bf16}"),Lh=l(" ("),ir=a("code"),$h=l("str"),Nh=l(") \u2014 Whether or not to use mixed precision training. Choose between FP16 and BF16 (bfloat16) training. BF16 training is only supported on Nvidia Ampere GPUs and PyTorch 1.10 or later."),Pn=d(),pe=a("h2"),Se=a("a"),sr=a("span"),b(oo.$$.fragment),Uh=d(),nr=a("span"),Mh=l("accelerate config update"),Sn=d(),lo=a("p"),dr=a("strong"),kh=l("Command"),Gh=l(":"),yn=d(),ye=a("p"),fr=a("code"),xh=l("accelerate config update"),Rh=l(" or "),hr=a("code"),Fh=l("accelerate-config update"),Tn=d(),Jo=a("p"),Wh=l("Update an existing config file with the latest defaults while maintaining the old configuration."),An=d(),ro=a("p"),pr=a("strong"),Hh=l("Usage"),zh=l(":"),In=d(),b(ao.$$.fragment),Ln=d(),co=a("p"),ur=a("strong"),Bh=l("Optional Arguments"),Kh=l(":"),$n=d(),Te=a("ul"),_r=a("li"),C=a("p"),Er=a("code"),Xh=l("--config_file CONFIG_FILE"),jh=l(" ("),vr=a("code"),Yh=l("str"),Zh=l(`) \u2014 The path to the config file to update. Will default to a file named default_config.yaml in the cache location, which is the content
of the environment `),mr=a("code"),qh=l("HF_HOME"),Jh=l(` suffixed with \u2018accelerate\u2019, or if you don\u2019t have such an environment variable, your cache directory
(`),gr=a("code"),Qh=l("~/.cache"),Vh=l(" or the content of "),Cr=a("code"),ep=l("XDG_CACHE_HOME"),tp=l(") suffixed with "),Or=a("code"),op=l("huggingface"),lp=l("."),rp=d(),Dr=a("li"),j=a("p"),wr=a("code"),ap=l("-h"),cp=l(", "),br=a("code"),ip=l("--help"),sp=l(" ("),Pr=a("code"),np=l("bool"),dp=l(") \u2014 Show a help message and exit"),Nn=d(),ue=a("h2"),Ae=a("a"),Sr=a("span"),b(io.$$.fragment),fp=d(),yr=a("span"),hp=l("accelerate env"),Un=d(),so=a("p"),Tr=a("strong"),pp=l("Command"),up=l(":"),Mn=d(),Ie=a("p"),Ar=a("code"),_p=l("accelerate env"),Ep=l(" or "),Ir=a("code"),vp=l("accelerate-env"),kn=d(),Le=a("p"),mp=l("Lists the contents of the passed \u{1F917} Accelerate configuration file. Should always be used when opening an issue on the "),no=a("a"),gp=l("GitHub repository"),Cp=l("."),Gn=d(),fo=a("p"),Lr=a("strong"),Op=l("Usage"),Dp=l(":"),xn=d(),b(ho.$$.fragment),Rn=d(),po=a("p"),$r=a("strong"),wp=l("Optional Arguments"),bp=l(":"),Fn=d(),$e=a("ul"),O=a("li"),Nr=a("code"),Pp=l("--config_file CONFIG_FILE"),Sp=l(" ("),Ur=a("code"),yp=l("str"),Tp=l(`) \u2014 The path to use to store the config file. Will default to a file named default_config.yaml in the cache location, which is the content
of the environment `),Mr=a("code"),Ap=l("HF_HOME"),Ip=l(` suffixed with \u2018accelerate\u2019, or if you don\u2019t have such an environment variable, your cache directory
(`),kr=a("code"),Lp=l("~/.cache"),$p=l(" or the content of "),Gr=a("code"),Np=l("XDG_CACHE_HOME"),Up=l(") suffixed with "),xr=a("code"),Mp=l("huggingface"),kp=l("."),Gp=d(),Y=a("li"),Rr=a("code"),xp=l("-h"),Rp=l(", "),Fr=a("code"),Fp=l("--help"),Wp=l(" ("),Wr=a("code"),Hp=l("bool"),zp=l(") \u2014 Show a help message and exit"),Wn=d(),_e=a("h2"),Ne=a("a"),Hr=a("span"),b(uo.$$.fragment),Bp=d(),zr=a("span"),Kp=l("accelerate launch"),Hn=d(),_o=a("p"),Br=a("strong"),Xp=l("Command"),jp=l(":"),zn=d(),Ue=a("p"),Kr=a("code"),Yp=l("accelerate launch"),Zp=l(" or "),Xr=a("code"),qp=l("accelerate-launch"),Bn=d(),Qo=a("p"),Jp=l("Launches a specified script on a distributed system with the right parameters."),Kn=d(),Eo=a("p"),jr=a("strong"),Qp=l("Usage"),Vp=l(":"),Xn=d(),b(vo.$$.fragment),jn=d(),mo=a("p"),Yr=a("strong"),eu=l("Positional Arguments"),tu=l(":"),Yn=d(),Me=a("ul"),Vo=a("li"),Zr=a("code"),ou=l("{training_script}"),lu=l(" \u2014 The full path to the script to be launched in parallel"),ru=d(),el=a("li"),qr=a("code"),au=l("--{training_script-argument-1}"),cu=l(" \u2014 Arguments of the training script"),Zn=d(),go=a("p"),Jr=a("strong"),iu=l("Optional Arguments"),su=l(":"),qn=d(),I=a("ul"),Z=a("li"),Qr=a("code"),nu=l("-h"),du=l(", "),Vr=a("code"),fu=l("--help"),hu=l(" ("),ea=a("code"),pu=l("bool"),uu=l(") \u2014 Show a help message and exit"),_u=d(),ke=a("li"),ta=a("code"),Eu=l("--config_file CONFIG_FILE"),vu=l(" ("),oa=a("code"),mu=l("str"),gu=l(")\u2014 The config file to use for the default values in the launching script."),Cu=d(),q=a("li"),la=a("code"),Ou=l("-m"),Du=l(", "),ra=a("code"),wu=l("--module"),bu=l(" ("),aa=a("code"),Pu=l("bool"),Su=l(") \u2014 Change each process to interpret the launch script as a Python module, executing with the same behavior as \u2018python -m\u2019."),yu=d(),Ge=a("li"),ca=a("code"),Tu=l("--no_python"),Au=l(" ("),ia=a("code"),Iu=l("bool"),Lu=l(") \u2014 Skip prepending the training script with \u2018python\u2019 - just execute it directly. Useful when the script is not a Python script."),$u=d(),xe=a("li"),sa=a("code"),Nu=l("--debug"),Uu=l(" ("),na=a("code"),Mu=l("bool"),ku=l(") \u2014 Whether to print out the torch.distributed stack trace when something fails."),Jn=d(),J=a("p"),Gu=l("The rest of these arguments are configured through "),da=a("code"),xu=l("accelerate config"),Ru=l(" and are read in from the specified "),fa=a("code"),Fu=l("--config_file"),Wu=l(` (or default configuration) for their
values. They can also be passed in manually.`),Qn=d(),Co=a("p"),ha=a("strong"),Hu=l("Hardware Selection Arguments"),zu=l(":"),Vn=d(),F=a("ul"),Re=a("li"),pa=a("code"),Bu=l("--cpu"),Ku=l(" ("),ua=a("code"),Xu=l("bool"),ju=l(") \u2014 Whether or not to force the training on the CPU."),Yu=d(),Fe=a("li"),_a=a("code"),Zu=l("--multi_gpu"),qu=l(" ("),Ea=a("code"),Ju=l("bool"),Qu=l(") \u2014 Whether or not this should launch a distributed GPU training."),Vu=d(),We=a("li"),va=a("code"),e_=l("--mps"),t_=l(" ("),ma=a("code"),o_=l("bool"),l_=l(") \u2014 Whether or not this should use MPS-enabled GPU device on MacOS machines."),r_=d(),He=a("li"),ga=a("code"),a_=l("--tpu"),c_=l(" ("),Ca=a("code"),i_=l("bool"),s_=l(") \u2014 Whether or not this should launch a TPU training."),ed=d(),Oo=a("p"),Oa=a("strong"),n_=l("Resource Selection Arguments"),d_=l(":"),td=d(),tl=a("p"),f_=l("The following arguments are useful for fine-tuning how available hardware should be used"),od=d(),W=a("ul"),ze=a("li"),Da=a("code"),h_=l("--mixed_precision {no,fp16,bf16}"),p_=l(" ("),wa=a("code"),u_=l("str"),__=l(") \u2014 Whether or not to use mixed precision training. Choose between FP16 and BF16 (bfloat16) training. BF16 training is only supported on Nvidia Ampere GPUs and PyTorch 1.10 or later."),E_=d(),Be=a("li"),ba=a("code"),v_=l("--num_processes NUM_PROCESSES"),m_=l(" ("),Pa=a("code"),g_=l("int"),C_=l(") \u2014 The total number of processes to be launched in parallel."),O_=d(),Ke=a("li"),Sa=a("code"),D_=l("--num_machines NUM_MACHINES"),w_=l(" ("),ya=a("code"),b_=l("int"),P_=l(") \u2014 The total number of machines used in this training."),S_=d(),Xe=a("li"),Ta=a("code"),y_=l("--num_cpu_threads_per_process NUM_CPU_THREADS_PER_PROCESS"),T_=l(" ("),Aa=a("code"),A_=l("int"),I_=l(") \u2014 The number of CPU threads per process. Can be tuned for optimal performance."),ld=d(),Do=a("p"),Ia=a("strong"),L_=l("Training Paradigm Arguments"),$_=l(":"),rd=d(),ol=a("p"),N_=l("The following arguments are useful for selecting which training paradigm to use."),ad=d(),Q=a("ul"),je=a("li"),La=a("code"),U_=l("--use_deepspeed"),M_=l(" ("),$a=a("code"),k_=l("bool"),G_=l(") \u2014 Whether or not to use DeepSpeed for training."),x_=d(),Ye=a("li"),Na=a("code"),R_=l("--use_fsdp"),F_=l(" ("),Ua=a("code"),W_=l("bool"),H_=l(") \u2014 Whether or not to use FullyShardedDataParallel for training."),z_=d(),Ze=a("li"),Ma=a("code"),B_=l("--use_megatron_lm"),K_=l(" ("),ka=a("code"),X_=l("bool"),j_=l(") \u2014 Whether or not to use Megatron-LM for training."),cd=d(),wo=a("p"),Ga=a("strong"),Y_=l("Distributed GPU Arguments"),Z_=l(":"),id=d(),V=a("p"),q_=l("The following arguments are only useful when "),xa=a("code"),J_=l("multi_gpu"),Q_=l(" is passed or multi-gpu training is configured through "),Ra=a("code"),V_=l("accelerate config"),e1=l(":"),sd=d(),_=a("ul"),qe=a("li"),Fa=a("code"),t1=l("--gpu_ids"),o1=l(" ("),Wa=a("code"),l1=l("str"),r1=l(") \u2014 What GPUs (by id) should be used for training on this machine as a comma-seperated list"),a1=d(),Je=a("li"),Ha=a("code"),c1=l("--same_network"),i1=l(" ("),za=a("code"),s1=l("bool"),n1=l(") \u2014 Whether all machines used for multinode training exist on the same local network."),d1=d(),Qe=a("li"),Ba=a("code"),f1=l("--machine_rank MACHINE_RANK"),h1=l(" ("),Ka=a("code"),p1=l("int"),u1=l(") \u2014 The rank of the machine on which this script is launched."),_1=d(),Ve=a("li"),Xa=a("code"),E1=l("--main_process_ip MAIN_PROCESS_IP"),v1=l(" ("),ja=a("code"),m1=l("str"),g1=l(") \u2014 The IP address of the machine of rank 0."),C1=d(),et=a("li"),Ya=a("code"),O1=l("--main_process_port MAIN_PROCESS_PORT"),D1=l(" ("),Za=a("code"),w1=l("int"),b1=l(") \u2014 The port to use to communicate with the machine of rank 0."),P1=d(),tt=a("li"),qa=a("code"),S1=l("--rdzv_conf"),y1=l(" ("),Ja=a("code"),T1=l("str"),A1=l(") \u2014 Additional rendezvous configuration (<key1>=<value1>,<key2>=<value2>,\u2026)."),I1=d(),ot=a("li"),Qa=a("code"),L1=l("--max_restarts"),$1=l(" ("),Va=a("code"),N1=l("int"),U1=l(") \u2014 Maximum number of worker group restarts before failing."),M1=d(),lt=a("li"),ec=a("code"),k1=l("--monitor_interval"),G1=l(" ("),tc=a("code"),x1=l("float"),R1=l(") \u2014 Interval, in seconds, to monitor the state of workers."),nd=d(),bo=a("p"),oc=a("strong"),F1=l("TPU Arguments"),W1=l(":"),dd=d(),ee=a("p"),H1=l("The following arguments are only useful when "),lc=a("code"),z1=l("tpu"),B1=l(" is passed or TPU training is configured through "),rc=a("code"),K1=l("accelerate config"),X1=l(":"),fd=d(),rt=a("ul"),at=a("li"),ac=a("code"),j1=l("--main_training_function MAIN_TRAINING_FUNCTION"),Y1=l(" ("),cc=a("code"),Z1=l("str"),q1=l(") \u2014 The name of the main function to be executed in your script."),J1=d(),ct=a("li"),ic=a("code"),Q1=l("--downcast_bf16"),V1=l(" ("),sc=a("code"),eE=l("bool"),tE=l(") \u2014 Whether when using bf16 precision on TPUs if both float and double tensors are cast to bfloat16 or if double tensors remain as float32."),hd=d(),Po=a("p"),nc=a("strong"),oE=l("DeepSpeed Arguments"),lE=l(":"),pd=d(),H=a("p"),rE=l("The following arguments are only useful when "),dc=a("code"),aE=l("use_deepspeed"),cE=l(" is passed or "),fc=a("code"),iE=l("deepspeed"),sE=l(" is configured through "),hc=a("code"),nE=l("accelerate config"),dE=l(":"),ud=d(),p=a("ul"),it=a("li"),pc=a("code"),fE=l("--deepspeed_config_file"),hE=l(" ("),uc=a("code"),pE=l("str"),uE=l(") \u2014 DeepSpeed config file."),_E=d(),st=a("li"),_c=a("code"),EE=l("--zero_stage"),vE=l(" ("),Ec=a("code"),mE=l("int"),gE=l(") \u2014 DeepSpeed\u2019s ZeRO optimization stage."),CE=d(),nt=a("li"),vc=a("code"),OE=l("--offload_optimizer_device"),DE=l(" ("),mc=a("code"),wE=l("str"),bE=l(") \u2014 Decides where (none|cpu|nvme) to offload optimizer states."),PE=d(),dt=a("li"),gc=a("code"),SE=l("--offload_param_device"),yE=l(" ("),Cc=a("code"),TE=l("str"),AE=l(") \u2014 Decides where (none|cpu|nvme) to offload parameters."),IE=d(),ft=a("li"),Oc=a("code"),LE=l("--gradient_accumulation_steps"),$E=l(" ("),Dc=a("code"),NE=l("int"),UE=l(") \u2014 No of gradient_accumulation_steps used in your training script."),ME=d(),ht=a("li"),wc=a("code"),kE=l("--gradient_clipping"),GE=l(" ("),bc=a("code"),xE=l("float"),RE=l(") \u2014 Gradient clipping value used in your training script."),FE=d(),te=a("li"),Pc=a("code"),WE=l("--zero3_init_flag"),HE=l(" ("),Sc=a("code"),zE=l("str"),BE=l(") \u2014 Decides Whether (true|false) to enable "),yc=a("code"),KE=l("deepspeed.zero.Init"),XE=l(" for constructing massive models. Only applicable with DeepSpeed ZeRO Stage-3."),jE=d(),pt=a("li"),Tc=a("code"),YE=l("--zero3_save_16bit_model"),ZE=l(" ("),Ac=a("code"),qE=l("str"),JE=l(") \u2014 Decides Whether (true|false) to save 16-bit model weights when using ZeRO Stage-3. Only applicable with DeepSpeed ZeRO Stage-3."),QE=d(),ut=a("li"),Ic=a("code"),VE=l("--deepspeed_hostfile"),ev=l(" ("),Lc=a("code"),tv=l("str"),ov=l(") \u2014 DeepSpeed hostfile for configuring multi-node compute resources."),lv=d(),_t=a("li"),$c=a("code"),rv=l("--deepspeed_exclusion_filter"),av=l(" ("),Nc=a("code"),cv=l("str"),iv=l(") \u2014 DeepSpeed exclusion filter string when using mutli-node setup."),sv=d(),Et=a("li"),Uc=a("code"),nv=l("--deepspeed_inclusion_filter"),dv=l(" ("),Mc=a("code"),fv=l("str"),hv=l(") \u2014 DeepSpeed inclusion filter string when using mutli-node setup."),pv=d(),vt=a("li"),kc=a("code"),uv=l("--deepspeed_multinode_launcher"),_v=l(" ("),Gc=a("code"),Ev=l("str"),vv=l(") \u2014 DeepSpeed multi-node launcher to use."),_d=d(),So=a("p"),xc=a("strong"),mv=l("Fully Sharded Data Parallelism Arguments"),gv=l(":"),Ed=d(),oe=a("p"),Cv=l("The following arguments are only useful when "),Rc=a("code"),Ov=l("use_fdsp"),Dv=l(" is passed or Fully Sharded Data Parallelism is configured through "),Fc=a("code"),wv=l("accelerate config"),bv=l(":"),vd=d(),E=a("ul"),mt=a("li"),Wc=a("code"),Pv=l("--fsdp_offload_params"),Sv=l(" ("),Hc=a("code"),yv=l("str"),Tv=l(") \u2014 Decides Whether (true|false) to offload parameters and gradients to CPU."),Av=d(),gt=a("li"),zc=a("code"),Iv=l("--fsdp_min_num_params"),Lv=l(" ("),Bc=a("code"),$v=l("int"),Nv=l(") \u2014 FSDP\u2019s minimum number of parameters for Default Auto Wrapping."),Uv=d(),Ct=a("li"),Kc=a("code"),Mv=l("--fsdp_sharding_strategy"),kv=l(" ("),Xc=a("code"),Gv=l("int"),xv=l(") \u2014 FSDP\u2019s Sharding Strategy."),Rv=d(),Ot=a("li"),jc=a("code"),Fv=l("--fsdp_auto_wrap_policy"),Wv=l(" ("),Yc=a("code"),Hv=l("str"),zv=l(") \u2014 FSDP\u2019s auto wrap policy."),Bv=d(),L=a("li"),Zc=a("code"),Kv=l("--fsdp_transformer_layer_cls_to_wrap"),Xv=l(" ("),qc=a("code"),jv=l("str"),Yv=l(") \u2014 Transformer layer class name (case-sensitive) to wrap, e.g, "),Jc=a("code"),Zv=l("BertLayer"),qv=l(", "),Qc=a("code"),Jv=l("GPTJBlock"),Qv=l(", "),Vc=a("code"),Vv=l("T5Block"),em=l(" \u2026"),tm=d(),Dt=a("li"),ei=a("code"),om=l("--fsdp_backward_prefetch_policy"),lm=l(" ("),ti=a("code"),rm=l("str"),am=l(") \u2014 FSDP\u2019s backward prefetch policy."),cm=d(),wt=a("li"),oi=a("code"),im=l("--fsdp_state_dict_type"),sm=l(" ("),li=a("code"),nm=l("str"),dm=l(") \u2014 FSDP\u2019s state dict type."),md=d(),yo=a("p"),ri=a("strong"),fm=l("Megatron-LM Arguments"),hm=l(":"),gd=d(),le=a("p"),pm=l("The following arguments are only useful when "),ai=a("code"),um=l("use_megatron_lm"),_m=l(" is passed or Megatron-LM is configured through "),ci=a("code"),Em=l("accelerate config"),vm=l(":"),Cd=d(),v=a("ul"),ll=a("li"),ii=a("code"),mm=l("--megatron_lm_tp_degree"),gm=l(" (\u201C) \u2014 Megatron-LM\u2019s Tensor Parallelism (TP) degree."),Cm=d(),rl=a("li"),si=a("code"),Om=l("--megatron_lm_pp_degree"),Dm=l(" (\u201C) \u2014 Megatron-LM\u2019s Pipeline Parallelism (PP) degree."),wm=d(),al=a("li"),ni=a("code"),bm=l("--megatron_lm_num_micro_batches"),Pm=l(" (\u201C) \u2014 Megatron-LM\u2019s number of micro batches when PP degree > 1."),Sm=d(),cl=a("li"),di=a("code"),ym=l("--megatron_lm_sequence_parallelism"),Tm=l(" (\u201C) \u2014 Decides Whether (true|false) to enable Sequence Parallelism when TP degree > 1."),Am=d(),il=a("li"),fi=a("code"),Im=l("--megatron_lm_recompute_activations"),Lm=l(" (\u201C) \u2014 Decides Whether (true|false) to enable Selective Activation Recomputation."),$m=d(),sl=a("li"),hi=a("code"),Nm=l("--megatron_lm_use_distributed_optimizer"),Um=l(" (\u201C) \u2014 Decides Whether (true|false) to use distributed optimizer which shards optimizer state and gradients across Data Pralellel (DP) ranks."),Mm=d(),nl=a("li"),pi=a("code"),km=l("--megatron_lm_gradient_clipping"),Gm=l(" (\u201C) \u2014 Megatron-LM\u2019s gradient clipping value based on global L2 Norm (0 to disable)."),Od=d(),To=a("p"),ui=a("strong"),xm=l("AWS SageMaker Arguments"),Rm=l(":"),Dd=d(),dl=a("p"),Fm=l("The following arguments are only useful when training in SageMaker"),wd=d(),bt=a("ul"),Pt=a("li"),_i=a("code"),Wm=l("--aws_access_key_id AWS_ACCESS_KEY_ID"),Hm=l(" ("),Ei=a("code"),zm=l("str"),Bm=l(") \u2014 The AWS_ACCESS_KEY_ID used to launch the Amazon SageMaker training job"),Km=d(),St=a("li"),vi=a("code"),Xm=l("--aws_secret_access_key AWS_SECRET_ACCESS_KEY"),jm=l(" ("),mi=a("code"),Ym=l("str"),Zm=l(") \u2014 The AWS_SECRET_ACCESS_KEY used to launch the Amazon SageMaker training job"),bd=d(),Ee=a("h2"),yt=a("a"),gi=a("span"),b(Ao.$$.fragment),qm=d(),Ci=a("span"),Jm=l("accelerate tpu-config"),Pd=d(),fl=a("p"),Oi=a("code"),Qm=l("accelerate tpu-config"),Sd=d(),Io=a("p"),Di=a("strong"),Vm=l("Usage"),e2=l(":"),yd=d(),b(Lo.$$.fragment),Td=d(),$o=a("p"),wi=a("strong"),t2=l("Optional Arguments"),o2=l(":"),Ad=d(),hl=a("ul"),re=a("li"),bi=a("code"),l2=l("-h"),r2=l(", "),Pi=a("code"),a2=l("--help"),c2=l(" ("),Si=a("code"),i2=l("bool"),s2=l(") \u2014 Show a help message and exit"),Id=d(),No=a("p"),yi=a("strong"),n2=l("Config Arguments"),d2=l(":"),Ld=d(),Tt=a("p"),f2=l("Arguments that can be configured through "),Ti=a("code"),h2=l("accelerate config"),p2=l("."),$d=d(),ae=a("ul"),At=a("li"),Ai=a("code"),u2=l("--config_file"),_2=l(" ("),Ii=a("code"),E2=l("str"),v2=l(") \u2014 Path to the config file to use for accelerate."),m2=d(),It=a("li"),Li=a("code"),g2=l("--tpu_name"),C2=l(" ("),$i=a("code"),O2=l("str"),D2=l(") \u2014 The name of the TPU to use. If not specified, will use the TPU specified in the config file."),w2=d(),Lt=a("li"),Ni=a("code"),b2=l("--tpu_zone"),P2=l(" ("),Ui=a("code"),S2=l("str"),y2=l(") \u2014 The zone of the TPU to use. If not specified, will use the zone specified in the config file."),Nd=d(),Uo=a("p"),Mi=a("strong"),T2=l("TPU Arguments"),A2=l(":"),Ud=d(),pl=a("p"),I2=l("Arguments for options ran inside the TPU."),Md=d(),$=a("ul"),$t=a("li"),ki=a("code"),L2=l("--command_file"),$2=l(" ("),Gi=a("code"),N2=l("str"),U2=l(") \u2014 The path to the file containing the commands to run on the pod on startup."),M2=d(),Nt=a("li"),xi=a("code"),k2=l("--command"),G2=l(" ("),Ri=a("code"),x2=l("str"),R2=l(") \u2014 A command to run on the pod. Can be passed multiple times."),F2=d(),Ut=a("li"),Fi=a("code"),W2=l("--install_accelerate"),H2=l(" ("),Wi=a("code"),z2=l("bool"),B2=l(") \u2014 Whether to install accelerate on the pod. Defaults to False."),K2=d(),Mt=a("li"),Hi=a("code"),X2=l("--accelerate_version"),j2=l(" ("),zi=a("code"),Y2=l("str"),Z2=l(") \u2014 The version of accelerate to install on the pod. If not specified, will use the latest pypi version. Specify \u2018dev\u2019 to install from GitHub."),q2=d(),kt=a("li"),Bi=a("code"),J2=l("--debug"),Q2=l(" ("),Ki=a("code"),V2=l("bool"),e3=l(") \u2014 If set, will print the command that would be run instead of running it."),kd=d(),ve=a("h2"),Gt=a("a"),Xi=a("span"),b(Mo.$$.fragment),t3=d(),ji=a("span"),o3=l("accelerate test"),Gd=d(),xt=a("p"),Yi=a("code"),l3=l("accelerate test"),r3=l(" or "),Zi=a("code"),a3=l("accelerate-test"),xd=d(),Rt=a("p"),c3=l("Runs "),qi=a("code"),i3=l("accelerate/test_utils/test_script.py"),s3=l(" to verify that \u{1F917} Accelerate has been properly configured on your system and runs."),Rd=d(),ko=a("p"),Ji=a("strong"),n3=l("Usage"),d3=l(":"),Fd=d(),b(Go.$$.fragment),Wd=d(),xo=a("p"),Qi=a("strong"),f3=l("Optional Arguments"),h3=l(":"),Hd=d(),Ft=a("ul"),D=a("li"),Vi=a("code"),p3=l("--config_file CONFIG_FILE"),u3=l(" ("),es=a("code"),_3=l("str"),E3=l(`) \u2014 The path to use to store the config file. Will default to a file named default_config.yaml in the cache location, which is the content
of the environment `),ts=a("code"),v3=l("HF_HOME"),m3=l(` suffixed with \u2018accelerate\u2019, or if you don\u2019t have such an environment variable, your cache directory
(`),os=a("code"),g3=l("~/.cache"),C3=l(" or the content of "),ls=a("code"),O3=l("XDG_CACHE_HOME"),D3=l(") suffixed with "),rs=a("code"),w3=l("huggingface"),b3=l("."),P3=d(),ce=a("li"),as=a("code"),S3=l("-h"),y3=l(", "),cs=a("code"),T3=l("--help"),A3=l(" ("),is=a("code"),I3=l("bool"),L3=l(") \u2014 Show a help message and exit"),this.h()},l(o){const s=yO('[data-svelte="svelte-1phssyn"]',document.head);ne=c(s,"META",{name:!0,content:!0}),s.forEach(t),cn=f(o),de=c(o,"H1",{class:!0});var Bd=i(de);me=c(Bd,"A",{id:!0,class:!0,href:!0});var g5=i(me);Dl=c(g5,"SPAN",{});var C5=i(Dl);P(Kt.$$.fragment,C5),C5.forEach(t),g5.forEach(t),Ef=f(Bd),wl=c(Bd,"SPAN",{});var O5=i(wl);vf=r(O5,"The Command Line"),O5.forEach(t),Bd.forEach(t),sn=f(o),Zo=c(o,"P",{});var D5=i(Zo);mf=r(D5,"Below is a list of all the available commands \u{1F917} Accelerate with their parameters"),D5.forEach(t),nn=f(o),fe=c(o,"H2",{class:!0});var Kd=i(fe);ge=c(Kd,"A",{id:!0,class:!0,href:!0});var w5=i(ge);bl=c(w5,"SPAN",{});var b5=i(bl);P(Xt.$$.fragment,b5),b5.forEach(t),w5.forEach(t),gf=f(Kd),Pl=c(Kd,"SPAN",{});var P5=i(Pl);Cf=r(P5,"accelerate config"),P5.forEach(t),Kd.forEach(t),dn=f(o),jt=c(o,"P",{});var $3=i(jt);Sl=c($3,"STRONG",{});var S5=i(Sl);Of=r(S5,"Command"),S5.forEach(t),Df=r($3,":"),$3.forEach(t),fn=f(o),Ce=c(o,"P",{});var Xd=i(Ce);yl=c(Xd,"CODE",{});var y5=i(yl);wf=r(y5,"accelerate config"),y5.forEach(t),bf=r(Xd," or "),Tl=c(Xd,"CODE",{});var T5=i(Tl);Pf=r(T5,"accelerate-config"),T5.forEach(t),Xd.forEach(t),hn=f(o),Oe=c(o,"P",{});var jd=i(Oe);Sf=r(jd,"Launches a series of prompts to create and save a "),Al=c(jd,"CODE",{});var A5=i(Al);yf=r(A5,"default_config.yml"),A5.forEach(t),Tf=r(jd,` configuration file for your training system. Should
always be ran first on your machine.`),jd.forEach(t),pn=f(o),Yt=c(o,"P",{});var N3=i(Yt);Il=c(N3,"STRONG",{});var I5=i(Il);Af=r(I5,"Usage"),I5.forEach(t),If=r(N3,":"),N3.forEach(t),un=f(o),P(Zt.$$.fragment,o),_n=f(o),qt=c(o,"P",{});var U3=i(qt);Ll=c(U3,"STRONG",{});var L5=i(Ll);Lf=r(L5,"Optional Arguments"),L5.forEach(t),$f=r(U3,":"),U3.forEach(t),En=f(o),De=c(o,"UL",{});var Yd=i(De);m=c(Yd,"LI",{});var M=i(m);$l=c(M,"CODE",{});var $5=i($l);Nf=r($5,"--config_file CONFIG_FILE"),$5.forEach(t),Uf=r(M," ("),Nl=c(M,"CODE",{});var N5=i(Nl);Mf=r(N5,"str"),N5.forEach(t),kf=r(M,`) \u2014 The path to use to store the config file. Will default to a file named default_config.yaml in the cache location, which is the content
of the environment `),Ul=c(M,"CODE",{});var U5=i(Ul);Gf=r(U5,"HF_HOME"),U5.forEach(t),xf=r(M,` suffixed with \u2018accelerate\u2019, or if you don\u2019t have such an environment variable, your cache directory
(`),Ml=c(M,"CODE",{});var M5=i(Ml);Rf=r(M5,"~/.cache"),M5.forEach(t),Ff=r(M," or the content of "),kl=c(M,"CODE",{});var k5=i(kl);Wf=r(k5,"XDG_CACHE_HOME"),k5.forEach(t),Hf=r(M,") suffixed with "),Gl=c(M,"CODE",{});var G5=i(Gl);zf=r(G5,"huggingface"),G5.forEach(t),Bf=r(M,"."),M.forEach(t),Kf=f(Yd),B=c(Yd,"LI",{});var Ro=i(B);xl=c(Ro,"CODE",{});var x5=i(xl);Xf=r(x5,"-h"),x5.forEach(t),jf=r(Ro,", "),Rl=c(Ro,"CODE",{});var R5=i(Rl);Yf=r(R5,"--help"),R5.forEach(t),Zf=r(Ro," ("),Fl=c(Ro,"CODE",{});var F5=i(Fl);qf=r(F5,"bool"),F5.forEach(t),Jf=r(Ro,") \u2014 Show a help message and exit"),Ro.forEach(t),Yd.forEach(t),vn=f(o),he=c(o,"H2",{class:!0});var Zd=i(he);we=c(Zd,"A",{id:!0,class:!0,href:!0});var W5=i(we);Wl=c(W5,"SPAN",{});var H5=i(Wl);P(Jt.$$.fragment,H5),H5.forEach(t),W5.forEach(t),Qf=f(Zd),Hl=c(Zd,"SPAN",{});var z5=i(Hl);Vf=r(z5,"accelerate config default"),z5.forEach(t),Zd.forEach(t),mn=f(o),Qt=c(o,"P",{});var M3=i(Qt);zl=c(M3,"STRONG",{});var B5=i(zl);eh=r(B5,"Command"),B5.forEach(t),th=r(M3,":"),M3.forEach(t),gn=f(o),be=c(o,"P",{});var qd=i(be);Bl=c(qd,"CODE",{});var K5=i(Bl);oh=r(K5,"accelerate config default"),K5.forEach(t),lh=r(qd," or "),Kl=c(qd,"CODE",{});var X5=i(Kl);rh=r(X5,"accelerate-config default"),X5.forEach(t),qd.forEach(t),Cn=f(o),qo=c(o,"P",{});var j5=i(qo);ah=r(j5,"Create a default config file for Accelerate with only a few flags set."),j5.forEach(t),On=f(o),Vt=c(o,"P",{});var k3=i(Vt);Xl=c(k3,"STRONG",{});var Y5=i(Xl);ch=r(Y5,"Usage"),Y5.forEach(t),ih=r(k3,":"),k3.forEach(t),Dn=f(o),P(eo.$$.fragment,o),wn=f(o),to=c(o,"P",{});var G3=i(to);jl=c(G3,"STRONG",{});var Z5=i(jl);sh=r(Z5,"Optional Arguments"),Z5.forEach(t),nh=r(G3,":"),G3.forEach(t),bn=f(o),K=c(o,"UL",{});var ul=i(K);Yl=c(ul,"LI",{});var q5=i(Yl);g=c(q5,"P",{});var k=i(g);Zl=c(k,"CODE",{});var J5=i(Zl);dh=r(J5,"--config_file CONFIG_FILE"),J5.forEach(t),fh=r(k," ("),ql=c(k,"CODE",{});var Q5=i(ql);hh=r(Q5,"str"),Q5.forEach(t),ph=r(k,`) \u2014 The path to use to store the config file. Will default to a file named default_config.yaml in the cache location, which is the content
of the environment `),Jl=c(k,"CODE",{});var V5=i(Jl);uh=r(V5,"HF_HOME"),V5.forEach(t),_h=r(k,` suffixed with \u2018accelerate\u2019, or if you don\u2019t have such an environment variable, your cache directory
(`),Ql=c(k,"CODE",{});var e4=i(Ql);Eh=r(e4,"~/.cache"),e4.forEach(t),vh=r(k," or the content of "),Vl=c(k,"CODE",{});var t4=i(Vl);mh=r(t4,"XDG_CACHE_HOME"),t4.forEach(t),gh=r(k,") suffixed with "),er=c(k,"CODE",{});var o4=i(er);Ch=r(o4,"huggingface"),o4.forEach(t),Oh=r(k,"."),k.forEach(t),q5.forEach(t),Dh=f(ul),tr=c(ul,"LI",{});var l4=i(tr);X=c(l4,"P",{});var Fo=i(X);or=c(Fo,"CODE",{});var r4=i(or);wh=r(r4,"-h"),r4.forEach(t),bh=r(Fo,", "),lr=c(Fo,"CODE",{});var a4=i(lr);Ph=r(a4,"--help"),a4.forEach(t),Sh=r(Fo," ("),rr=c(Fo,"CODE",{});var c4=i(rr);yh=r(c4,"bool"),c4.forEach(t),Th=r(Fo,") \u2014 Show a help message and exit"),Fo.forEach(t),l4.forEach(t),Ah=f(ul),ar=c(ul,"LI",{});var i4=i(ar);Pe=c(i4,"P",{});var ss=i(Pe);cr=c(ss,"CODE",{});var s4=i(cr);Ih=r(s4,"--mixed_precision {no,fp16,bf16}"),s4.forEach(t),Lh=r(ss," ("),ir=c(ss,"CODE",{});var n4=i(ir);$h=r(n4,"str"),n4.forEach(t),Nh=r(ss,") \u2014 Whether or not to use mixed precision training. Choose between FP16 and BF16 (bfloat16) training. BF16 training is only supported on Nvidia Ampere GPUs and PyTorch 1.10 or later."),ss.forEach(t),i4.forEach(t),ul.forEach(t),Pn=f(o),pe=c(o,"H2",{class:!0});var Jd=i(pe);Se=c(Jd,"A",{id:!0,class:!0,href:!0});var d4=i(Se);sr=c(d4,"SPAN",{});var f4=i(sr);P(oo.$$.fragment,f4),f4.forEach(t),d4.forEach(t),Uh=f(Jd),nr=c(Jd,"SPAN",{});var h4=i(nr);Mh=r(h4,"accelerate config update"),h4.forEach(t),Jd.forEach(t),Sn=f(o),lo=c(o,"P",{});var x3=i(lo);dr=c(x3,"STRONG",{});var p4=i(dr);kh=r(p4,"Command"),p4.forEach(t),Gh=r(x3,":"),x3.forEach(t),yn=f(o),ye=c(o,"P",{});var Qd=i(ye);fr=c(Qd,"CODE",{});var u4=i(fr);xh=r(u4,"accelerate config update"),u4.forEach(t),Rh=r(Qd," or "),hr=c(Qd,"CODE",{});var _4=i(hr);Fh=r(_4,"accelerate-config update"),_4.forEach(t),Qd.forEach(t),Tn=f(o),Jo=c(o,"P",{});var E4=i(Jo);Wh=r(E4,"Update an existing config file with the latest defaults while maintaining the old configuration."),E4.forEach(t),An=f(o),ro=c(o,"P",{});var R3=i(ro);pr=c(R3,"STRONG",{});var v4=i(pr);Hh=r(v4,"Usage"),v4.forEach(t),zh=r(R3,":"),R3.forEach(t),In=f(o),P(ao.$$.fragment,o),Ln=f(o),co=c(o,"P",{});var F3=i(co);ur=c(F3,"STRONG",{});var m4=i(ur);Bh=r(m4,"Optional Arguments"),m4.forEach(t),Kh=r(F3,":"),F3.forEach(t),$n=f(o),Te=c(o,"UL",{});var Vd=i(Te);_r=c(Vd,"LI",{});var g4=i(_r);C=c(g4,"P",{});var G=i(C);Er=c(G,"CODE",{});var C4=i(Er);Xh=r(C4,"--config_file CONFIG_FILE"),C4.forEach(t),jh=r(G," ("),vr=c(G,"CODE",{});var O4=i(vr);Yh=r(O4,"str"),O4.forEach(t),Zh=r(G,`) \u2014 The path to the config file to update. Will default to a file named default_config.yaml in the cache location, which is the content
of the environment `),mr=c(G,"CODE",{});var D4=i(mr);qh=r(D4,"HF_HOME"),D4.forEach(t),Jh=r(G,` suffixed with \u2018accelerate\u2019, or if you don\u2019t have such an environment variable, your cache directory
(`),gr=c(G,"CODE",{});var w4=i(gr);Qh=r(w4,"~/.cache"),w4.forEach(t),Vh=r(G," or the content of "),Cr=c(G,"CODE",{});var b4=i(Cr);ep=r(b4,"XDG_CACHE_HOME"),b4.forEach(t),tp=r(G,") suffixed with "),Or=c(G,"CODE",{});var P4=i(Or);op=r(P4,"huggingface"),P4.forEach(t),lp=r(G,"."),G.forEach(t),g4.forEach(t),rp=f(Vd),Dr=c(Vd,"LI",{});var S4=i(Dr);j=c(S4,"P",{});var Wo=i(j);wr=c(Wo,"CODE",{});var y4=i(wr);ap=r(y4,"-h"),y4.forEach(t),cp=r(Wo,", "),br=c(Wo,"CODE",{});var T4=i(br);ip=r(T4,"--help"),T4.forEach(t),sp=r(Wo," ("),Pr=c(Wo,"CODE",{});var A4=i(Pr);np=r(A4,"bool"),A4.forEach(t),dp=r(Wo,") \u2014 Show a help message and exit"),Wo.forEach(t),S4.forEach(t),Vd.forEach(t),Nn=f(o),ue=c(o,"H2",{class:!0});var ef=i(ue);Ae=c(ef,"A",{id:!0,class:!0,href:!0});var I4=i(Ae);Sr=c(I4,"SPAN",{});var L4=i(Sr);P(io.$$.fragment,L4),L4.forEach(t),I4.forEach(t),fp=f(ef),yr=c(ef,"SPAN",{});var $4=i(yr);hp=r($4,"accelerate env"),$4.forEach(t),ef.forEach(t),Un=f(o),so=c(o,"P",{});var W3=i(so);Tr=c(W3,"STRONG",{});var N4=i(Tr);pp=r(N4,"Command"),N4.forEach(t),up=r(W3,":"),W3.forEach(t),Mn=f(o),Ie=c(o,"P",{});var tf=i(Ie);Ar=c(tf,"CODE",{});var U4=i(Ar);_p=r(U4,"accelerate env"),U4.forEach(t),Ep=r(tf," or "),Ir=c(tf,"CODE",{});var M4=i(Ir);vp=r(M4,"accelerate-env"),M4.forEach(t),tf.forEach(t),kn=f(o),Le=c(o,"P",{});var of=i(Le);mp=r(of,"Lists the contents of the passed \u{1F917} Accelerate configuration file. Should always be used when opening an issue on the "),no=c(of,"A",{href:!0,rel:!0});var k4=i(no);gp=r(k4,"GitHub repository"),k4.forEach(t),Cp=r(of,"."),of.forEach(t),Gn=f(o),fo=c(o,"P",{});var H3=i(fo);Lr=c(H3,"STRONG",{});var G4=i(Lr);Op=r(G4,"Usage"),G4.forEach(t),Dp=r(H3,":"),H3.forEach(t),xn=f(o),P(ho.$$.fragment,o),Rn=f(o),po=c(o,"P",{});var z3=i(po);$r=c(z3,"STRONG",{});var x4=i($r);wp=r(x4,"Optional Arguments"),x4.forEach(t),bp=r(z3,":"),z3.forEach(t),Fn=f(o),$e=c(o,"UL",{});var lf=i($e);O=c(lf,"LI",{});var x=i(O);Nr=c(x,"CODE",{});var R4=i(Nr);Pp=r(R4,"--config_file CONFIG_FILE"),R4.forEach(t),Sp=r(x," ("),Ur=c(x,"CODE",{});var F4=i(Ur);yp=r(F4,"str"),F4.forEach(t),Tp=r(x,`) \u2014 The path to use to store the config file. Will default to a file named default_config.yaml in the cache location, which is the content
of the environment `),Mr=c(x,"CODE",{});var W4=i(Mr);Ap=r(W4,"HF_HOME"),W4.forEach(t),Ip=r(x,` suffixed with \u2018accelerate\u2019, or if you don\u2019t have such an environment variable, your cache directory
(`),kr=c(x,"CODE",{});var H4=i(kr);Lp=r(H4,"~/.cache"),H4.forEach(t),$p=r(x," or the content of "),Gr=c(x,"CODE",{});var z4=i(Gr);Np=r(z4,"XDG_CACHE_HOME"),z4.forEach(t),Up=r(x,") suffixed with "),xr=c(x,"CODE",{});var B4=i(xr);Mp=r(B4,"huggingface"),B4.forEach(t),kp=r(x,"."),x.forEach(t),Gp=f(lf),Y=c(lf,"LI",{});var Ho=i(Y);Rr=c(Ho,"CODE",{});var K4=i(Rr);xp=r(K4,"-h"),K4.forEach(t),Rp=r(Ho,", "),Fr=c(Ho,"CODE",{});var X4=i(Fr);Fp=r(X4,"--help"),X4.forEach(t),Wp=r(Ho," ("),Wr=c(Ho,"CODE",{});var j4=i(Wr);Hp=r(j4,"bool"),j4.forEach(t),zp=r(Ho,") \u2014 Show a help message and exit"),Ho.forEach(t),lf.forEach(t),Wn=f(o),_e=c(o,"H2",{class:!0});var rf=i(_e);Ne=c(rf,"A",{id:!0,class:!0,href:!0});var Y4=i(Ne);Hr=c(Y4,"SPAN",{});var Z4=i(Hr);P(uo.$$.fragment,Z4),Z4.forEach(t),Y4.forEach(t),Bp=f(rf),zr=c(rf,"SPAN",{});var q4=i(zr);Kp=r(q4,"accelerate launch"),q4.forEach(t),rf.forEach(t),Hn=f(o),_o=c(o,"P",{});var B3=i(_o);Br=c(B3,"STRONG",{});var J4=i(Br);Xp=r(J4,"Command"),J4.forEach(t),jp=r(B3,":"),B3.forEach(t),zn=f(o),Ue=c(o,"P",{});var af=i(Ue);Kr=c(af,"CODE",{});var Q4=i(Kr);Yp=r(Q4,"accelerate launch"),Q4.forEach(t),Zp=r(af," or "),Xr=c(af,"CODE",{});var V4=i(Xr);qp=r(V4,"accelerate-launch"),V4.forEach(t),af.forEach(t),Bn=f(o),Qo=c(o,"P",{});var eg=i(Qo);Jp=r(eg,"Launches a specified script on a distributed system with the right parameters."),eg.forEach(t),Kn=f(o),Eo=c(o,"P",{});var K3=i(Eo);jr=c(K3,"STRONG",{});var tg=i(jr);Qp=r(tg,"Usage"),tg.forEach(t),Vp=r(K3,":"),K3.forEach(t),Xn=f(o),P(vo.$$.fragment,o),jn=f(o),mo=c(o,"P",{});var X3=i(mo);Yr=c(X3,"STRONG",{});var og=i(Yr);eu=r(og,"Positional Arguments"),og.forEach(t),tu=r(X3,":"),X3.forEach(t),Yn=f(o),Me=c(o,"UL",{});var cf=i(Me);Vo=c(cf,"LI",{});var j3=i(Vo);Zr=c(j3,"CODE",{});var lg=i(Zr);ou=r(lg,"{training_script}"),lg.forEach(t),lu=r(j3," \u2014 The full path to the script to be launched in parallel"),j3.forEach(t),ru=f(cf),el=c(cf,"LI",{});var Y3=i(el);qr=c(Y3,"CODE",{});var rg=i(qr);au=r(rg,"--{training_script-argument-1}"),rg.forEach(t),cu=r(Y3," \u2014 Arguments of the training script"),Y3.forEach(t),cf.forEach(t),Zn=f(o),go=c(o,"P",{});var Z3=i(go);Jr=c(Z3,"STRONG",{});var ag=i(Jr);iu=r(ag,"Optional Arguments"),ag.forEach(t),su=r(Z3,":"),Z3.forEach(t),qn=f(o),I=c(o,"UL",{});var ie=i(I);Z=c(ie,"LI",{});var zo=i(Z);Qr=c(zo,"CODE",{});var cg=i(Qr);nu=r(cg,"-h"),cg.forEach(t),du=r(zo,", "),Vr=c(zo,"CODE",{});var ig=i(Vr);fu=r(ig,"--help"),ig.forEach(t),hu=r(zo," ("),ea=c(zo,"CODE",{});var sg=i(ea);pu=r(sg,"bool"),sg.forEach(t),uu=r(zo,") \u2014 Show a help message and exit"),zo.forEach(t),_u=f(ie),ke=c(ie,"LI",{});var ns=i(ke);ta=c(ns,"CODE",{});var ng=i(ta);Eu=r(ng,"--config_file CONFIG_FILE"),ng.forEach(t),vu=r(ns," ("),oa=c(ns,"CODE",{});var dg=i(oa);mu=r(dg,"str"),dg.forEach(t),gu=r(ns,")\u2014 The config file to use for the default values in the launching script."),ns.forEach(t),Cu=f(ie),q=c(ie,"LI",{});var Bo=i(q);la=c(Bo,"CODE",{});var fg=i(la);Ou=r(fg,"-m"),fg.forEach(t),Du=r(Bo,", "),ra=c(Bo,"CODE",{});var hg=i(ra);wu=r(hg,"--module"),hg.forEach(t),bu=r(Bo," ("),aa=c(Bo,"CODE",{});var pg=i(aa);Pu=r(pg,"bool"),pg.forEach(t),Su=r(Bo,") \u2014 Change each process to interpret the launch script as a Python module, executing with the same behavior as \u2018python -m\u2019."),Bo.forEach(t),yu=f(ie),Ge=c(ie,"LI",{});var ds=i(Ge);ca=c(ds,"CODE",{});var ug=i(ca);Tu=r(ug,"--no_python"),ug.forEach(t),Au=r(ds," ("),ia=c(ds,"CODE",{});var _g=i(ia);Iu=r(_g,"bool"),_g.forEach(t),Lu=r(ds,") \u2014 Skip prepending the training script with \u2018python\u2019 - just execute it directly. Useful when the script is not a Python script."),ds.forEach(t),$u=f(ie),xe=c(ie,"LI",{});var fs=i(xe);sa=c(fs,"CODE",{});var Eg=i(sa);Nu=r(Eg,"--debug"),Eg.forEach(t),Uu=r(fs," ("),na=c(fs,"CODE",{});var vg=i(na);Mu=r(vg,"bool"),vg.forEach(t),ku=r(fs,") \u2014 Whether to print out the torch.distributed stack trace when something fails."),fs.forEach(t),ie.forEach(t),Jn=f(o),J=c(o,"P",{});var _l=i(J);Gu=r(_l,"The rest of these arguments are configured through "),da=c(_l,"CODE",{});var mg=i(da);xu=r(mg,"accelerate config"),mg.forEach(t),Ru=r(_l," and are read in from the specified "),fa=c(_l,"CODE",{});var gg=i(fa);Fu=r(gg,"--config_file"),gg.forEach(t),Wu=r(_l,` (or default configuration) for their
values. They can also be passed in manually.`),_l.forEach(t),Qn=f(o),Co=c(o,"P",{});var q3=i(Co);ha=c(q3,"STRONG",{});var Cg=i(ha);Hu=r(Cg,"Hardware Selection Arguments"),Cg.forEach(t),zu=r(q3,":"),q3.forEach(t),Vn=f(o),F=c(o,"UL",{});var Wt=i(F);Re=c(Wt,"LI",{});var hs=i(Re);pa=c(hs,"CODE",{});var Og=i(pa);Bu=r(Og,"--cpu"),Og.forEach(t),Ku=r(hs," ("),ua=c(hs,"CODE",{});var Dg=i(ua);Xu=r(Dg,"bool"),Dg.forEach(t),ju=r(hs,") \u2014 Whether or not to force the training on the CPU."),hs.forEach(t),Yu=f(Wt),Fe=c(Wt,"LI",{});var ps=i(Fe);_a=c(ps,"CODE",{});var wg=i(_a);Zu=r(wg,"--multi_gpu"),wg.forEach(t),qu=r(ps," ("),Ea=c(ps,"CODE",{});var bg=i(Ea);Ju=r(bg,"bool"),bg.forEach(t),Qu=r(ps,") \u2014 Whether or not this should launch a distributed GPU training."),ps.forEach(t),Vu=f(Wt),We=c(Wt,"LI",{});var us=i(We);va=c(us,"CODE",{});var Pg=i(va);e_=r(Pg,"--mps"),Pg.forEach(t),t_=r(us," ("),ma=c(us,"CODE",{});var Sg=i(ma);o_=r(Sg,"bool"),Sg.forEach(t),l_=r(us,") \u2014 Whether or not this should use MPS-enabled GPU device on MacOS machines."),us.forEach(t),r_=f(Wt),He=c(Wt,"LI",{});var _s=i(He);ga=c(_s,"CODE",{});var yg=i(ga);a_=r(yg,"--tpu"),yg.forEach(t),c_=r(_s," ("),Ca=c(_s,"CODE",{});var Tg=i(Ca);i_=r(Tg,"bool"),Tg.forEach(t),s_=r(_s,") \u2014 Whether or not this should launch a TPU training."),_s.forEach(t),Wt.forEach(t),ed=f(o),Oo=c(o,"P",{});var J3=i(Oo);Oa=c(J3,"STRONG",{});var Ag=i(Oa);n_=r(Ag,"Resource Selection Arguments"),Ag.forEach(t),d_=r(J3,":"),J3.forEach(t),td=f(o),tl=c(o,"P",{});var Ig=i(tl);f_=r(Ig,"The following arguments are useful for fine-tuning how available hardware should be used"),Ig.forEach(t),od=f(o),W=c(o,"UL",{});var Ht=i(W);ze=c(Ht,"LI",{});var Es=i(ze);Da=c(Es,"CODE",{});var Lg=i(Da);h_=r(Lg,"--mixed_precision {no,fp16,bf16}"),Lg.forEach(t),p_=r(Es," ("),wa=c(Es,"CODE",{});var $g=i(wa);u_=r($g,"str"),$g.forEach(t),__=r(Es,") \u2014 Whether or not to use mixed precision training. Choose between FP16 and BF16 (bfloat16) training. BF16 training is only supported on Nvidia Ampere GPUs and PyTorch 1.10 or later."),Es.forEach(t),E_=f(Ht),Be=c(Ht,"LI",{});var vs=i(Be);ba=c(vs,"CODE",{});var Ng=i(ba);v_=r(Ng,"--num_processes NUM_PROCESSES"),Ng.forEach(t),m_=r(vs," ("),Pa=c(vs,"CODE",{});var Ug=i(Pa);g_=r(Ug,"int"),Ug.forEach(t),C_=r(vs,") \u2014 The total number of processes to be launched in parallel."),vs.forEach(t),O_=f(Ht),Ke=c(Ht,"LI",{});var ms=i(Ke);Sa=c(ms,"CODE",{});var Mg=i(Sa);D_=r(Mg,"--num_machines NUM_MACHINES"),Mg.forEach(t),w_=r(ms," ("),ya=c(ms,"CODE",{});var kg=i(ya);b_=r(kg,"int"),kg.forEach(t),P_=r(ms,") \u2014 The total number of machines used in this training."),ms.forEach(t),S_=f(Ht),Xe=c(Ht,"LI",{});var gs=i(Xe);Ta=c(gs,"CODE",{});var Gg=i(Ta);y_=r(Gg,"--num_cpu_threads_per_process NUM_CPU_THREADS_PER_PROCESS"),Gg.forEach(t),T_=r(gs," ("),Aa=c(gs,"CODE",{});var xg=i(Aa);A_=r(xg,"int"),xg.forEach(t),I_=r(gs,") \u2014 The number of CPU threads per process. Can be tuned for optimal performance."),gs.forEach(t),Ht.forEach(t),ld=f(o),Do=c(o,"P",{});var Q3=i(Do);Ia=c(Q3,"STRONG",{});var Rg=i(Ia);L_=r(Rg,"Training Paradigm Arguments"),Rg.forEach(t),$_=r(Q3,":"),Q3.forEach(t),rd=f(o),ol=c(o,"P",{});var Fg=i(ol);N_=r(Fg,"The following arguments are useful for selecting which training paradigm to use."),Fg.forEach(t),ad=f(o),Q=c(o,"UL",{});var El=i(Q);je=c(El,"LI",{});var Cs=i(je);La=c(Cs,"CODE",{});var Wg=i(La);U_=r(Wg,"--use_deepspeed"),Wg.forEach(t),M_=r(Cs," ("),$a=c(Cs,"CODE",{});var Hg=i($a);k_=r(Hg,"bool"),Hg.forEach(t),G_=r(Cs,") \u2014 Whether or not to use DeepSpeed for training."),Cs.forEach(t),x_=f(El),Ye=c(El,"LI",{});var Os=i(Ye);Na=c(Os,"CODE",{});var zg=i(Na);R_=r(zg,"--use_fsdp"),zg.forEach(t),F_=r(Os," ("),Ua=c(Os,"CODE",{});var Bg=i(Ua);W_=r(Bg,"bool"),Bg.forEach(t),H_=r(Os,") \u2014 Whether or not to use FullyShardedDataParallel for training."),Os.forEach(t),z_=f(El),Ze=c(El,"LI",{});var Ds=i(Ze);Ma=c(Ds,"CODE",{});var Kg=i(Ma);B_=r(Kg,"--use_megatron_lm"),Kg.forEach(t),K_=r(Ds," ("),ka=c(Ds,"CODE",{});var Xg=i(ka);X_=r(Xg,"bool"),Xg.forEach(t),j_=r(Ds,") \u2014 Whether or not to use Megatron-LM for training."),Ds.forEach(t),El.forEach(t),cd=f(o),wo=c(o,"P",{});var V3=i(wo);Ga=c(V3,"STRONG",{});var jg=i(Ga);Y_=r(jg,"Distributed GPU Arguments"),jg.forEach(t),Z_=r(V3,":"),V3.forEach(t),id=f(o),V=c(o,"P",{});var vl=i(V);q_=r(vl,"The following arguments are only useful when "),xa=c(vl,"CODE",{});var Yg=i(xa);J_=r(Yg,"multi_gpu"),Yg.forEach(t),Q_=r(vl," is passed or multi-gpu training is configured through "),Ra=c(vl,"CODE",{});var Zg=i(Ra);V_=r(Zg,"accelerate config"),Zg.forEach(t),e1=r(vl,":"),vl.forEach(t),sd=f(o),_=c(o,"UL",{});var w=i(_);qe=c(w,"LI",{});var ws=i(qe);Fa=c(ws,"CODE",{});var qg=i(Fa);t1=r(qg,"--gpu_ids"),qg.forEach(t),o1=r(ws," ("),Wa=c(ws,"CODE",{});var Jg=i(Wa);l1=r(Jg,"str"),Jg.forEach(t),r1=r(ws,") \u2014 What GPUs (by id) should be used for training on this machine as a comma-seperated list"),ws.forEach(t),a1=f(w),Je=c(w,"LI",{});var bs=i(Je);Ha=c(bs,"CODE",{});var Qg=i(Ha);c1=r(Qg,"--same_network"),Qg.forEach(t),i1=r(bs," ("),za=c(bs,"CODE",{});var Vg=i(za);s1=r(Vg,"bool"),Vg.forEach(t),n1=r(bs,") \u2014 Whether all machines used for multinode training exist on the same local network."),bs.forEach(t),d1=f(w),Qe=c(w,"LI",{});var Ps=i(Qe);Ba=c(Ps,"CODE",{});var e6=i(Ba);f1=r(e6,"--machine_rank MACHINE_RANK"),e6.forEach(t),h1=r(Ps," ("),Ka=c(Ps,"CODE",{});var t6=i(Ka);p1=r(t6,"int"),t6.forEach(t),u1=r(Ps,") \u2014 The rank of the machine on which this script is launched."),Ps.forEach(t),_1=f(w),Ve=c(w,"LI",{});var Ss=i(Ve);Xa=c(Ss,"CODE",{});var o6=i(Xa);E1=r(o6,"--main_process_ip MAIN_PROCESS_IP"),o6.forEach(t),v1=r(Ss," ("),ja=c(Ss,"CODE",{});var l6=i(ja);m1=r(l6,"str"),l6.forEach(t),g1=r(Ss,") \u2014 The IP address of the machine of rank 0."),Ss.forEach(t),C1=f(w),et=c(w,"LI",{});var ys=i(et);Ya=c(ys,"CODE",{});var r6=i(Ya);O1=r(r6,"--main_process_port MAIN_PROCESS_PORT"),r6.forEach(t),D1=r(ys," ("),Za=c(ys,"CODE",{});var a6=i(Za);w1=r(a6,"int"),a6.forEach(t),b1=r(ys,") \u2014 The port to use to communicate with the machine of rank 0."),ys.forEach(t),P1=f(w),tt=c(w,"LI",{});var Ts=i(tt);qa=c(Ts,"CODE",{});var c6=i(qa);S1=r(c6,"--rdzv_conf"),c6.forEach(t),y1=r(Ts," ("),Ja=c(Ts,"CODE",{});var i6=i(Ja);T1=r(i6,"str"),i6.forEach(t),A1=r(Ts,") \u2014 Additional rendezvous configuration (<key1>=<value1>,<key2>=<value2>,\u2026)."),Ts.forEach(t),I1=f(w),ot=c(w,"LI",{});var As=i(ot);Qa=c(As,"CODE",{});var s6=i(Qa);L1=r(s6,"--max_restarts"),s6.forEach(t),$1=r(As," ("),Va=c(As,"CODE",{});var n6=i(Va);N1=r(n6,"int"),n6.forEach(t),U1=r(As,") \u2014 Maximum number of worker group restarts before failing."),As.forEach(t),M1=f(w),lt=c(w,"LI",{});var Is=i(lt);ec=c(Is,"CODE",{});var d6=i(ec);k1=r(d6,"--monitor_interval"),d6.forEach(t),G1=r(Is," ("),tc=c(Is,"CODE",{});var f6=i(tc);x1=r(f6,"float"),f6.forEach(t),R1=r(Is,") \u2014 Interval, in seconds, to monitor the state of workers."),Is.forEach(t),w.forEach(t),nd=f(o),bo=c(o,"P",{});var e5=i(bo);oc=c(e5,"STRONG",{});var h6=i(oc);F1=r(h6,"TPU Arguments"),h6.forEach(t),W1=r(e5,":"),e5.forEach(t),dd=f(o),ee=c(o,"P",{});var ml=i(ee);H1=r(ml,"The following arguments are only useful when "),lc=c(ml,"CODE",{});var p6=i(lc);z1=r(p6,"tpu"),p6.forEach(t),B1=r(ml," is passed or TPU training is configured through "),rc=c(ml,"CODE",{});var u6=i(rc);K1=r(u6,"accelerate config"),u6.forEach(t),X1=r(ml,":"),ml.forEach(t),fd=f(o),rt=c(o,"UL",{});var sf=i(rt);at=c(sf,"LI",{});var Ls=i(at);ac=c(Ls,"CODE",{});var _6=i(ac);j1=r(_6,"--main_training_function MAIN_TRAINING_FUNCTION"),_6.forEach(t),Y1=r(Ls," ("),cc=c(Ls,"CODE",{});var E6=i(cc);Z1=r(E6,"str"),E6.forEach(t),q1=r(Ls,") \u2014 The name of the main function to be executed in your script."),Ls.forEach(t),J1=f(sf),ct=c(sf,"LI",{});var $s=i(ct);ic=c($s,"CODE",{});var v6=i(ic);Q1=r(v6,"--downcast_bf16"),v6.forEach(t),V1=r($s," ("),sc=c($s,"CODE",{});var m6=i(sc);eE=r(m6,"bool"),m6.forEach(t),tE=r($s,") \u2014 Whether when using bf16 precision on TPUs if both float and double tensors are cast to bfloat16 or if double tensors remain as float32."),$s.forEach(t),sf.forEach(t),hd=f(o),Po=c(o,"P",{});var t5=i(Po);nc=c(t5,"STRONG",{});var g6=i(nc);oE=r(g6,"DeepSpeed Arguments"),g6.forEach(t),lE=r(t5,":"),t5.forEach(t),pd=f(o),H=c(o,"P",{});var zt=i(H);rE=r(zt,"The following arguments are only useful when "),dc=c(zt,"CODE",{});var C6=i(dc);aE=r(C6,"use_deepspeed"),C6.forEach(t),cE=r(zt," is passed or "),fc=c(zt,"CODE",{});var O6=i(fc);iE=r(O6,"deepspeed"),O6.forEach(t),sE=r(zt," is configured through "),hc=c(zt,"CODE",{});var D6=i(hc);nE=r(D6,"accelerate config"),D6.forEach(t),dE=r(zt,":"),zt.forEach(t),ud=f(o),p=c(o,"UL",{});var u=i(p);it=c(u,"LI",{});var Ns=i(it);pc=c(Ns,"CODE",{});var w6=i(pc);fE=r(w6,"--deepspeed_config_file"),w6.forEach(t),hE=r(Ns," ("),uc=c(Ns,"CODE",{});var b6=i(uc);pE=r(b6,"str"),b6.forEach(t),uE=r(Ns,") \u2014 DeepSpeed config file."),Ns.forEach(t),_E=f(u),st=c(u,"LI",{});var Us=i(st);_c=c(Us,"CODE",{});var P6=i(_c);EE=r(P6,"--zero_stage"),P6.forEach(t),vE=r(Us," ("),Ec=c(Us,"CODE",{});var S6=i(Ec);mE=r(S6,"int"),S6.forEach(t),gE=r(Us,") \u2014 DeepSpeed\u2019s ZeRO optimization stage."),Us.forEach(t),CE=f(u),nt=c(u,"LI",{});var Ms=i(nt);vc=c(Ms,"CODE",{});var y6=i(vc);OE=r(y6,"--offload_optimizer_device"),y6.forEach(t),DE=r(Ms," ("),mc=c(Ms,"CODE",{});var T6=i(mc);wE=r(T6,"str"),T6.forEach(t),bE=r(Ms,") \u2014 Decides where (none|cpu|nvme) to offload optimizer states."),Ms.forEach(t),PE=f(u),dt=c(u,"LI",{});var ks=i(dt);gc=c(ks,"CODE",{});var A6=i(gc);SE=r(A6,"--offload_param_device"),A6.forEach(t),yE=r(ks," ("),Cc=c(ks,"CODE",{});var I6=i(Cc);TE=r(I6,"str"),I6.forEach(t),AE=r(ks,") \u2014 Decides where (none|cpu|nvme) to offload parameters."),ks.forEach(t),IE=f(u),ft=c(u,"LI",{});var Gs=i(ft);Oc=c(Gs,"CODE",{});var L6=i(Oc);LE=r(L6,"--gradient_accumulation_steps"),L6.forEach(t),$E=r(Gs," ("),Dc=c(Gs,"CODE",{});var $6=i(Dc);NE=r($6,"int"),$6.forEach(t),UE=r(Gs,") \u2014 No of gradient_accumulation_steps used in your training script."),Gs.forEach(t),ME=f(u),ht=c(u,"LI",{});var xs=i(ht);wc=c(xs,"CODE",{});var N6=i(wc);kE=r(N6,"--gradient_clipping"),N6.forEach(t),GE=r(xs," ("),bc=c(xs,"CODE",{});var U6=i(bc);xE=r(U6,"float"),U6.forEach(t),RE=r(xs,") \u2014 Gradient clipping value used in your training script."),xs.forEach(t),FE=f(u),te=c(u,"LI",{});var Ko=i(te);Pc=c(Ko,"CODE",{});var M6=i(Pc);WE=r(M6,"--zero3_init_flag"),M6.forEach(t),HE=r(Ko," ("),Sc=c(Ko,"CODE",{});var k6=i(Sc);zE=r(k6,"str"),k6.forEach(t),BE=r(Ko,") \u2014 Decides Whether (true|false) to enable "),yc=c(Ko,"CODE",{});var G6=i(yc);KE=r(G6,"deepspeed.zero.Init"),G6.forEach(t),XE=r(Ko," for constructing massive models. Only applicable with DeepSpeed ZeRO Stage-3."),Ko.forEach(t),jE=f(u),pt=c(u,"LI",{});var Rs=i(pt);Tc=c(Rs,"CODE",{});var x6=i(Tc);YE=r(x6,"--zero3_save_16bit_model"),x6.forEach(t),ZE=r(Rs," ("),Ac=c(Rs,"CODE",{});var R6=i(Ac);qE=r(R6,"str"),R6.forEach(t),JE=r(Rs,") \u2014 Decides Whether (true|false) to save 16-bit model weights when using ZeRO Stage-3. Only applicable with DeepSpeed ZeRO Stage-3."),Rs.forEach(t),QE=f(u),ut=c(u,"LI",{});var Fs=i(ut);Ic=c(Fs,"CODE",{});var F6=i(Ic);VE=r(F6,"--deepspeed_hostfile"),F6.forEach(t),ev=r(Fs," ("),Lc=c(Fs,"CODE",{});var W6=i(Lc);tv=r(W6,"str"),W6.forEach(t),ov=r(Fs,") \u2014 DeepSpeed hostfile for configuring multi-node compute resources."),Fs.forEach(t),lv=f(u),_t=c(u,"LI",{});var Ws=i(_t);$c=c(Ws,"CODE",{});var H6=i($c);rv=r(H6,"--deepspeed_exclusion_filter"),H6.forEach(t),av=r(Ws," ("),Nc=c(Ws,"CODE",{});var z6=i(Nc);cv=r(z6,"str"),z6.forEach(t),iv=r(Ws,") \u2014 DeepSpeed exclusion filter string when using mutli-node setup."),Ws.forEach(t),sv=f(u),Et=c(u,"LI",{});var Hs=i(Et);Uc=c(Hs,"CODE",{});var B6=i(Uc);nv=r(B6,"--deepspeed_inclusion_filter"),B6.forEach(t),dv=r(Hs," ("),Mc=c(Hs,"CODE",{});var K6=i(Mc);fv=r(K6,"str"),K6.forEach(t),hv=r(Hs,") \u2014 DeepSpeed inclusion filter string when using mutli-node setup."),Hs.forEach(t),pv=f(u),vt=c(u,"LI",{});var zs=i(vt);kc=c(zs,"CODE",{});var X6=i(kc);uv=r(X6,"--deepspeed_multinode_launcher"),X6.forEach(t),_v=r(zs," ("),Gc=c(zs,"CODE",{});var j6=i(Gc);Ev=r(j6,"str"),j6.forEach(t),vv=r(zs,") \u2014 DeepSpeed multi-node launcher to use."),zs.forEach(t),u.forEach(t),_d=f(o),So=c(o,"P",{});var o5=i(So);xc=c(o5,"STRONG",{});var Y6=i(xc);mv=r(Y6,"Fully Sharded Data Parallelism Arguments"),Y6.forEach(t),gv=r(o5,":"),o5.forEach(t),Ed=f(o),oe=c(o,"P",{});var gl=i(oe);Cv=r(gl,"The following arguments are only useful when "),Rc=c(gl,"CODE",{});var Z6=i(Rc);Ov=r(Z6,"use_fdsp"),Z6.forEach(t),Dv=r(gl," is passed or Fully Sharded Data Parallelism is configured through "),Fc=c(gl,"CODE",{});var q6=i(Fc);wv=r(q6,"accelerate config"),q6.forEach(t),bv=r(gl,":"),gl.forEach(t),vd=f(o),E=c(o,"UL",{});var N=i(E);mt=c(N,"LI",{});var Bs=i(mt);Wc=c(Bs,"CODE",{});var J6=i(Wc);Pv=r(J6,"--fsdp_offload_params"),J6.forEach(t),Sv=r(Bs," ("),Hc=c(Bs,"CODE",{});var Q6=i(Hc);yv=r(Q6,"str"),Q6.forEach(t),Tv=r(Bs,") \u2014 Decides Whether (true|false) to offload parameters and gradients to CPU."),Bs.forEach(t),Av=f(N),gt=c(N,"LI",{});var Ks=i(gt);zc=c(Ks,"CODE",{});var V6=i(zc);Iv=r(V6,"--fsdp_min_num_params"),V6.forEach(t),Lv=r(Ks," ("),Bc=c(Ks,"CODE",{});var eC=i(Bc);$v=r(eC,"int"),eC.forEach(t),Nv=r(Ks,") \u2014 FSDP\u2019s minimum number of parameters for Default Auto Wrapping."),Ks.forEach(t),Uv=f(N),Ct=c(N,"LI",{});var Xs=i(Ct);Kc=c(Xs,"CODE",{});var tC=i(Kc);Mv=r(tC,"--fsdp_sharding_strategy"),tC.forEach(t),kv=r(Xs," ("),Xc=c(Xs,"CODE",{});var oC=i(Xc);Gv=r(oC,"int"),oC.forEach(t),xv=r(Xs,") \u2014 FSDP\u2019s Sharding Strategy."),Xs.forEach(t),Rv=f(N),Ot=c(N,"LI",{});var js=i(Ot);jc=c(js,"CODE",{});var lC=i(jc);Fv=r(lC,"--fsdp_auto_wrap_policy"),lC.forEach(t),Wv=r(js," ("),Yc=c(js,"CODE",{});var rC=i(Yc);Hv=r(rC,"str"),rC.forEach(t),zv=r(js,") \u2014 FSDP\u2019s auto wrap policy."),js.forEach(t),Bv=f(N),L=c(N,"LI",{});var z=i(L);Zc=c(z,"CODE",{});var aC=i(Zc);Kv=r(aC,"--fsdp_transformer_layer_cls_to_wrap"),aC.forEach(t),Xv=r(z," ("),qc=c(z,"CODE",{});var cC=i(qc);jv=r(cC,"str"),cC.forEach(t),Yv=r(z,") \u2014 Transformer layer class name (case-sensitive) to wrap, e.g, "),Jc=c(z,"CODE",{});var iC=i(Jc);Zv=r(iC,"BertLayer"),iC.forEach(t),qv=r(z,", "),Qc=c(z,"CODE",{});var sC=i(Qc);Jv=r(sC,"GPTJBlock"),sC.forEach(t),Qv=r(z,", "),Vc=c(z,"CODE",{});var nC=i(Vc);Vv=r(nC,"T5Block"),nC.forEach(t),em=r(z," \u2026"),z.forEach(t),tm=f(N),Dt=c(N,"LI",{});var Ys=i(Dt);ei=c(Ys,"CODE",{});var dC=i(ei);om=r(dC,"--fsdp_backward_prefetch_policy"),dC.forEach(t),lm=r(Ys," ("),ti=c(Ys,"CODE",{});var fC=i(ti);rm=r(fC,"str"),fC.forEach(t),am=r(Ys,") \u2014 FSDP\u2019s backward prefetch policy."),Ys.forEach(t),cm=f(N),wt=c(N,"LI",{});var Zs=i(wt);oi=c(Zs,"CODE",{});var hC=i(oi);im=r(hC,"--fsdp_state_dict_type"),hC.forEach(t),sm=r(Zs," ("),li=c(Zs,"CODE",{});var pC=i(li);nm=r(pC,"str"),pC.forEach(t),dm=r(Zs,") \u2014 FSDP\u2019s state dict type."),Zs.forEach(t),N.forEach(t),md=f(o),yo=c(o,"P",{});var l5=i(yo);ri=c(l5,"STRONG",{});var uC=i(ri);fm=r(uC,"Megatron-LM Arguments"),uC.forEach(t),hm=r(l5,":"),l5.forEach(t),gd=f(o),le=c(o,"P",{});var Cl=i(le);pm=r(Cl,"The following arguments are only useful when "),ai=c(Cl,"CODE",{});var _C=i(ai);um=r(_C,"use_megatron_lm"),_C.forEach(t),_m=r(Cl," is passed or Megatron-LM is configured through "),ci=c(Cl,"CODE",{});var EC=i(ci);Em=r(EC,"accelerate config"),EC.forEach(t),vm=r(Cl,":"),Cl.forEach(t),Cd=f(o),v=c(o,"UL",{});var U=i(v);ll=c(U,"LI",{});var r5=i(ll);ii=c(r5,"CODE",{});var vC=i(ii);mm=r(vC,"--megatron_lm_tp_degree"),vC.forEach(t),gm=r(r5," (\u201C) \u2014 Megatron-LM\u2019s Tensor Parallelism (TP) degree."),r5.forEach(t),Cm=f(U),rl=c(U,"LI",{});var a5=i(rl);si=c(a5,"CODE",{});var mC=i(si);Om=r(mC,"--megatron_lm_pp_degree"),mC.forEach(t),Dm=r(a5," (\u201C) \u2014 Megatron-LM\u2019s Pipeline Parallelism (PP) degree."),a5.forEach(t),wm=f(U),al=c(U,"LI",{});var c5=i(al);ni=c(c5,"CODE",{});var gC=i(ni);bm=r(gC,"--megatron_lm_num_micro_batches"),gC.forEach(t),Pm=r(c5," (\u201C) \u2014 Megatron-LM\u2019s number of micro batches when PP degree > 1."),c5.forEach(t),Sm=f(U),cl=c(U,"LI",{});var i5=i(cl);di=c(i5,"CODE",{});var CC=i(di);ym=r(CC,"--megatron_lm_sequence_parallelism"),CC.forEach(t),Tm=r(i5," (\u201C) \u2014 Decides Whether (true|false) to enable Sequence Parallelism when TP degree > 1."),i5.forEach(t),Am=f(U),il=c(U,"LI",{});var s5=i(il);fi=c(s5,"CODE",{});var OC=i(fi);Im=r(OC,"--megatron_lm_recompute_activations"),OC.forEach(t),Lm=r(s5," (\u201C) \u2014 Decides Whether (true|false) to enable Selective Activation Recomputation."),s5.forEach(t),$m=f(U),sl=c(U,"LI",{});var n5=i(sl);hi=c(n5,"CODE",{});var DC=i(hi);Nm=r(DC,"--megatron_lm_use_distributed_optimizer"),DC.forEach(t),Um=r(n5," (\u201C) \u2014 Decides Whether (true|false) to use distributed optimizer which shards optimizer state and gradients across Data Pralellel (DP) ranks."),n5.forEach(t),Mm=f(U),nl=c(U,"LI",{});var d5=i(nl);pi=c(d5,"CODE",{});var wC=i(pi);km=r(wC,"--megatron_lm_gradient_clipping"),wC.forEach(t),Gm=r(d5," (\u201C) \u2014 Megatron-LM\u2019s gradient clipping value based on global L2 Norm (0 to disable)."),d5.forEach(t),U.forEach(t),Od=f(o),To=c(o,"P",{});var f5=i(To);ui=c(f5,"STRONG",{});var bC=i(ui);xm=r(bC,"AWS SageMaker Arguments"),bC.forEach(t),Rm=r(f5,":"),f5.forEach(t),Dd=f(o),dl=c(o,"P",{});var PC=i(dl);Fm=r(PC,"The following arguments are only useful when training in SageMaker"),PC.forEach(t),wd=f(o),bt=c(o,"UL",{});var nf=i(bt);Pt=c(nf,"LI",{});var qs=i(Pt);_i=c(qs,"CODE",{});var SC=i(_i);Wm=r(SC,"--aws_access_key_id AWS_ACCESS_KEY_ID"),SC.forEach(t),Hm=r(qs," ("),Ei=c(qs,"CODE",{});var yC=i(Ei);zm=r(yC,"str"),yC.forEach(t),Bm=r(qs,") \u2014 The AWS_ACCESS_KEY_ID used to launch the Amazon SageMaker training job"),qs.forEach(t),Km=f(nf),St=c(nf,"LI",{});var Js=i(St);vi=c(Js,"CODE",{});var TC=i(vi);Xm=r(TC,"--aws_secret_access_key AWS_SECRET_ACCESS_KEY"),TC.forEach(t),jm=r(Js," ("),mi=c(Js,"CODE",{});var AC=i(mi);Ym=r(AC,"str"),AC.forEach(t),Zm=r(Js,") \u2014 The AWS_SECRET_ACCESS_KEY used to launch the Amazon SageMaker training job"),Js.forEach(t),nf.forEach(t),bd=f(o),Ee=c(o,"H2",{class:!0});var df=i(Ee);yt=c(df,"A",{id:!0,class:!0,href:!0});var IC=i(yt);gi=c(IC,"SPAN",{});var LC=i(gi);P(Ao.$$.fragment,LC),LC.forEach(t),IC.forEach(t),qm=f(df),Ci=c(df,"SPAN",{});var $C=i(Ci);Jm=r($C,"accelerate tpu-config"),$C.forEach(t),df.forEach(t),Pd=f(o),fl=c(o,"P",{});var NC=i(fl);Oi=c(NC,"CODE",{});var UC=i(Oi);Qm=r(UC,"accelerate tpu-config"),UC.forEach(t),NC.forEach(t),Sd=f(o),Io=c(o,"P",{});var h5=i(Io);Di=c(h5,"STRONG",{});var MC=i(Di);Vm=r(MC,"Usage"),MC.forEach(t),e2=r(h5,":"),h5.forEach(t),yd=f(o),P(Lo.$$.fragment,o),Td=f(o),$o=c(o,"P",{});var p5=i($o);wi=c(p5,"STRONG",{});var kC=i(wi);t2=r(kC,"Optional Arguments"),kC.forEach(t),o2=r(p5,":"),p5.forEach(t),Ad=f(o),hl=c(o,"UL",{});var GC=i(hl);re=c(GC,"LI",{});var Xo=i(re);bi=c(Xo,"CODE",{});var xC=i(bi);l2=r(xC,"-h"),xC.forEach(t),r2=r(Xo,", "),Pi=c(Xo,"CODE",{});var RC=i(Pi);a2=r(RC,"--help"),RC.forEach(t),c2=r(Xo," ("),Si=c(Xo,"CODE",{});var FC=i(Si);i2=r(FC,"bool"),FC.forEach(t),s2=r(Xo,") \u2014 Show a help message and exit"),Xo.forEach(t),GC.forEach(t),Id=f(o),No=c(o,"P",{});var u5=i(No);yi=c(u5,"STRONG",{});var WC=i(yi);n2=r(WC,"Config Arguments"),WC.forEach(t),d2=r(u5,":"),u5.forEach(t),Ld=f(o),Tt=c(o,"P",{});var ff=i(Tt);f2=r(ff,"Arguments that can be configured through "),Ti=c(ff,"CODE",{});var HC=i(Ti);h2=r(HC,"accelerate config"),HC.forEach(t),p2=r(ff,"."),ff.forEach(t),$d=f(o),ae=c(o,"UL",{});var Ol=i(ae);At=c(Ol,"LI",{});var Qs=i(At);Ai=c(Qs,"CODE",{});var zC=i(Ai);u2=r(zC,"--config_file"),zC.forEach(t),_2=r(Qs," ("),Ii=c(Qs,"CODE",{});var BC=i(Ii);E2=r(BC,"str"),BC.forEach(t),v2=r(Qs,") \u2014 Path to the config file to use for accelerate."),Qs.forEach(t),m2=f(Ol),It=c(Ol,"LI",{});var Vs=i(It);Li=c(Vs,"CODE",{});var KC=i(Li);g2=r(KC,"--tpu_name"),KC.forEach(t),C2=r(Vs," ("),$i=c(Vs,"CODE",{});var XC=i($i);O2=r(XC,"str"),XC.forEach(t),D2=r(Vs,") \u2014 The name of the TPU to use. If not specified, will use the TPU specified in the config file."),Vs.forEach(t),w2=f(Ol),Lt=c(Ol,"LI",{});var en=i(Lt);Ni=c(en,"CODE",{});var jC=i(Ni);b2=r(jC,"--tpu_zone"),jC.forEach(t),P2=r(en," ("),Ui=c(en,"CODE",{});var YC=i(Ui);S2=r(YC,"str"),YC.forEach(t),y2=r(en,") \u2014 The zone of the TPU to use. If not specified, will use the zone specified in the config file."),en.forEach(t),Ol.forEach(t),Nd=f(o),Uo=c(o,"P",{});var _5=i(Uo);Mi=c(_5,"STRONG",{});var ZC=i(Mi);T2=r(ZC,"TPU Arguments"),ZC.forEach(t),A2=r(_5,":"),_5.forEach(t),Ud=f(o),pl=c(o,"P",{});var qC=i(pl);I2=r(qC,"Arguments for options ran inside the TPU."),qC.forEach(t),Md=f(o),$=c(o,"UL",{});var se=i($);$t=c(se,"LI",{});var tn=i($t);ki=c(tn,"CODE",{});var JC=i(ki);L2=r(JC,"--command_file"),JC.forEach(t),$2=r(tn," ("),Gi=c(tn,"CODE",{});var QC=i(Gi);N2=r(QC,"str"),QC.forEach(t),U2=r(tn,") \u2014 The path to the file containing the commands to run on the pod on startup."),tn.forEach(t),M2=f(se),Nt=c(se,"LI",{});var on=i(Nt);xi=c(on,"CODE",{});var VC=i(xi);k2=r(VC,"--command"),VC.forEach(t),G2=r(on," ("),Ri=c(on,"CODE",{});var eO=i(Ri);x2=r(eO,"str"),eO.forEach(t),R2=r(on,") \u2014 A command to run on the pod. Can be passed multiple times."),on.forEach(t),F2=f(se),Ut=c(se,"LI",{});var ln=i(Ut);Fi=c(ln,"CODE",{});var tO=i(Fi);W2=r(tO,"--install_accelerate"),tO.forEach(t),H2=r(ln," ("),Wi=c(ln,"CODE",{});var oO=i(Wi);z2=r(oO,"bool"),oO.forEach(t),B2=r(ln,") \u2014 Whether to install accelerate on the pod. Defaults to False."),ln.forEach(t),K2=f(se),Mt=c(se,"LI",{});var rn=i(Mt);Hi=c(rn,"CODE",{});var lO=i(Hi);X2=r(lO,"--accelerate_version"),lO.forEach(t),j2=r(rn," ("),zi=c(rn,"CODE",{});var rO=i(zi);Y2=r(rO,"str"),rO.forEach(t),Z2=r(rn,") \u2014 The version of accelerate to install on the pod. If not specified, will use the latest pypi version. Specify \u2018dev\u2019 to install from GitHub."),rn.forEach(t),q2=f(se),kt=c(se,"LI",{});var an=i(kt);Bi=c(an,"CODE",{});var aO=i(Bi);J2=r(aO,"--debug"),aO.forEach(t),Q2=r(an," ("),Ki=c(an,"CODE",{});var cO=i(Ki);V2=r(cO,"bool"),cO.forEach(t),e3=r(an,") \u2014 If set, will print the command that would be run instead of running it."),an.forEach(t),se.forEach(t),kd=f(o),ve=c(o,"H2",{class:!0});var hf=i(ve);Gt=c(hf,"A",{id:!0,class:!0,href:!0});var iO=i(Gt);Xi=c(iO,"SPAN",{});var sO=i(Xi);P(Mo.$$.fragment,sO),sO.forEach(t),iO.forEach(t),t3=f(hf),ji=c(hf,"SPAN",{});var nO=i(ji);o3=r(nO,"accelerate test"),nO.forEach(t),hf.forEach(t),Gd=f(o),xt=c(o,"P",{});var pf=i(xt);Yi=c(pf,"CODE",{});var dO=i(Yi);l3=r(dO,"accelerate test"),dO.forEach(t),r3=r(pf," or "),Zi=c(pf,"CODE",{});var fO=i(Zi);a3=r(fO,"accelerate-test"),fO.forEach(t),pf.forEach(t),xd=f(o),Rt=c(o,"P",{});var uf=i(Rt);c3=r(uf,"Runs "),qi=c(uf,"CODE",{});var hO=i(qi);i3=r(hO,"accelerate/test_utils/test_script.py"),hO.forEach(t),s3=r(uf," to verify that \u{1F917} Accelerate has been properly configured on your system and runs."),uf.forEach(t),Rd=f(o),ko=c(o,"P",{});var E5=i(ko);Ji=c(E5,"STRONG",{});var pO=i(Ji);n3=r(pO,"Usage"),pO.forEach(t),d3=r(E5,":"),E5.forEach(t),Fd=f(o),P(Go.$$.fragment,o),Wd=f(o),xo=c(o,"P",{});var v5=i(xo);Qi=c(v5,"STRONG",{});var uO=i(Qi);f3=r(uO,"Optional Arguments"),uO.forEach(t),h3=r(v5,":"),v5.forEach(t),Hd=f(o),Ft=c(o,"UL",{});var _f=i(Ft);D=c(_f,"LI",{});var R=i(D);Vi=c(R,"CODE",{});var _O=i(Vi);p3=r(_O,"--config_file CONFIG_FILE"),_O.forEach(t),u3=r(R," ("),es=c(R,"CODE",{});var EO=i(es);_3=r(EO,"str"),EO.forEach(t),E3=r(R,`) \u2014 The path to use to store the config file. Will default to a file named default_config.yaml in the cache location, which is the content
of the environment `),ts=c(R,"CODE",{});var vO=i(ts);v3=r(vO,"HF_HOME"),vO.forEach(t),m3=r(R,` suffixed with \u2018accelerate\u2019, or if you don\u2019t have such an environment variable, your cache directory
(`),os=c(R,"CODE",{});var mO=i(os);g3=r(mO,"~/.cache"),mO.forEach(t),C3=r(R," or the content of "),ls=c(R,"CODE",{});var gO=i(ls);O3=r(gO,"XDG_CACHE_HOME"),gO.forEach(t),D3=r(R,") suffixed with "),rs=c(R,"CODE",{});var CO=i(rs);w3=r(CO,"huggingface"),CO.forEach(t),b3=r(R,"."),R.forEach(t),P3=f(_f),ce=c(_f,"LI",{});var jo=i(ce);as=c(jo,"CODE",{});var OO=i(as);S3=r(OO,"-h"),OO.forEach(t),y3=r(jo,", "),cs=c(jo,"CODE",{});var DO=i(cs);T3=r(DO,"--help"),DO.forEach(t),A3=r(jo," ("),is=c(jo,"CODE",{});var wO=i(is);I3=r(wO,"bool"),wO.forEach(t),L3=r(jo,") \u2014 Show a help message and exit"),jo.forEach(t),_f.forEach(t),this.h()},h(){h(ne,"name","hf:doc:metadata"),h(ne,"content",JSON.stringify(LO)),h(me,"id","the-command-line"),h(me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(me,"href","#the-command-line"),h(de,"class","relative group"),h(ge,"id","accelerate-config"),h(ge,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ge,"href","#accelerate-config"),h(fe,"class","relative group"),h(we,"id","accelerate-config-default"),h(we,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(we,"href","#accelerate-config-default"),h(he,"class","relative group"),h(Se,"id","accelerate-config-update"),h(Se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Se,"href","#accelerate-config-update"),h(pe,"class","relative group"),h(Ae,"id","accelerate-env"),h(Ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ae,"href","#accelerate-env"),h(ue,"class","relative group"),h(no,"href","https://github.com/huggingface/accelerate"),h(no,"rel","nofollow"),h(Ne,"id","accelerate-launch"),h(Ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ne,"href","#accelerate-launch"),h(_e,"class","relative group"),h(yt,"id","accelerate-tpuconfig"),h(yt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(yt,"href","#accelerate-tpuconfig"),h(Ee,"class","relative group"),h(Gt,"id","accelerate-test"),h(Gt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Gt,"href","#accelerate-test"),h(ve,"class","relative group")},m(o,s){e(document.head,ne),n(o,cn,s),n(o,de,s),e(de,me),e(me,Dl),S(Kt,Dl,null),e(de,Ef),e(de,wl),e(wl,vf),n(o,sn,s),n(o,Zo,s),e(Zo,mf),n(o,nn,s),n(o,fe,s),e(fe,ge),e(ge,bl),S(Xt,bl,null),e(fe,gf),e(fe,Pl),e(Pl,Cf),n(o,dn,s),n(o,jt,s),e(jt,Sl),e(Sl,Of),e(jt,Df),n(o,fn,s),n(o,Ce,s),e(Ce,yl),e(yl,wf),e(Ce,bf),e(Ce,Tl),e(Tl,Pf),n(o,hn,s),n(o,Oe,s),e(Oe,Sf),e(Oe,Al),e(Al,yf),e(Oe,Tf),n(o,pn,s),n(o,Yt,s),e(Yt,Il),e(Il,Af),e(Yt,If),n(o,un,s),S(Zt,o,s),n(o,_n,s),n(o,qt,s),e(qt,Ll),e(Ll,Lf),e(qt,$f),n(o,En,s),n(o,De,s),e(De,m),e(m,$l),e($l,Nf),e(m,Uf),e(m,Nl),e(Nl,Mf),e(m,kf),e(m,Ul),e(Ul,Gf),e(m,xf),e(m,Ml),e(Ml,Rf),e(m,Ff),e(m,kl),e(kl,Wf),e(m,Hf),e(m,Gl),e(Gl,zf),e(m,Bf),e(De,Kf),e(De,B),e(B,xl),e(xl,Xf),e(B,jf),e(B,Rl),e(Rl,Yf),e(B,Zf),e(B,Fl),e(Fl,qf),e(B,Jf),n(o,vn,s),n(o,he,s),e(he,we),e(we,Wl),S(Jt,Wl,null),e(he,Qf),e(he,Hl),e(Hl,Vf),n(o,mn,s),n(o,Qt,s),e(Qt,zl),e(zl,eh),e(Qt,th),n(o,gn,s),n(o,be,s),e(be,Bl),e(Bl,oh),e(be,lh),e(be,Kl),e(Kl,rh),n(o,Cn,s),n(o,qo,s),e(qo,ah),n(o,On,s),n(o,Vt,s),e(Vt,Xl),e(Xl,ch),e(Vt,ih),n(o,Dn,s),S(eo,o,s),n(o,wn,s),n(o,to,s),e(to,jl),e(jl,sh),e(to,nh),n(o,bn,s),n(o,K,s),e(K,Yl),e(Yl,g),e(g,Zl),e(Zl,dh),e(g,fh),e(g,ql),e(ql,hh),e(g,ph),e(g,Jl),e(Jl,uh),e(g,_h),e(g,Ql),e(Ql,Eh),e(g,vh),e(g,Vl),e(Vl,mh),e(g,gh),e(g,er),e(er,Ch),e(g,Oh),e(K,Dh),e(K,tr),e(tr,X),e(X,or),e(or,wh),e(X,bh),e(X,lr),e(lr,Ph),e(X,Sh),e(X,rr),e(rr,yh),e(X,Th),e(K,Ah),e(K,ar),e(ar,Pe),e(Pe,cr),e(cr,Ih),e(Pe,Lh),e(Pe,ir),e(ir,$h),e(Pe,Nh),n(o,Pn,s),n(o,pe,s),e(pe,Se),e(Se,sr),S(oo,sr,null),e(pe,Uh),e(pe,nr),e(nr,Mh),n(o,Sn,s),n(o,lo,s),e(lo,dr),e(dr,kh),e(lo,Gh),n(o,yn,s),n(o,ye,s),e(ye,fr),e(fr,xh),e(ye,Rh),e(ye,hr),e(hr,Fh),n(o,Tn,s),n(o,Jo,s),e(Jo,Wh),n(o,An,s),n(o,ro,s),e(ro,pr),e(pr,Hh),e(ro,zh),n(o,In,s),S(ao,o,s),n(o,Ln,s),n(o,co,s),e(co,ur),e(ur,Bh),e(co,Kh),n(o,$n,s),n(o,Te,s),e(Te,_r),e(_r,C),e(C,Er),e(Er,Xh),e(C,jh),e(C,vr),e(vr,Yh),e(C,Zh),e(C,mr),e(mr,qh),e(C,Jh),e(C,gr),e(gr,Qh),e(C,Vh),e(C,Cr),e(Cr,ep),e(C,tp),e(C,Or),e(Or,op),e(C,lp),e(Te,rp),e(Te,Dr),e(Dr,j),e(j,wr),e(wr,ap),e(j,cp),e(j,br),e(br,ip),e(j,sp),e(j,Pr),e(Pr,np),e(j,dp),n(o,Nn,s),n(o,ue,s),e(ue,Ae),e(Ae,Sr),S(io,Sr,null),e(ue,fp),e(ue,yr),e(yr,hp),n(o,Un,s),n(o,so,s),e(so,Tr),e(Tr,pp),e(so,up),n(o,Mn,s),n(o,Ie,s),e(Ie,Ar),e(Ar,_p),e(Ie,Ep),e(Ie,Ir),e(Ir,vp),n(o,kn,s),n(o,Le,s),e(Le,mp),e(Le,no),e(no,gp),e(Le,Cp),n(o,Gn,s),n(o,fo,s),e(fo,Lr),e(Lr,Op),e(fo,Dp),n(o,xn,s),S(ho,o,s),n(o,Rn,s),n(o,po,s),e(po,$r),e($r,wp),e(po,bp),n(o,Fn,s),n(o,$e,s),e($e,O),e(O,Nr),e(Nr,Pp),e(O,Sp),e(O,Ur),e(Ur,yp),e(O,Tp),e(O,Mr),e(Mr,Ap),e(O,Ip),e(O,kr),e(kr,Lp),e(O,$p),e(O,Gr),e(Gr,Np),e(O,Up),e(O,xr),e(xr,Mp),e(O,kp),e($e,Gp),e($e,Y),e(Y,Rr),e(Rr,xp),e(Y,Rp),e(Y,Fr),e(Fr,Fp),e(Y,Wp),e(Y,Wr),e(Wr,Hp),e(Y,zp),n(o,Wn,s),n(o,_e,s),e(_e,Ne),e(Ne,Hr),S(uo,Hr,null),e(_e,Bp),e(_e,zr),e(zr,Kp),n(o,Hn,s),n(o,_o,s),e(_o,Br),e(Br,Xp),e(_o,jp),n(o,zn,s),n(o,Ue,s),e(Ue,Kr),e(Kr,Yp),e(Ue,Zp),e(Ue,Xr),e(Xr,qp),n(o,Bn,s),n(o,Qo,s),e(Qo,Jp),n(o,Kn,s),n(o,Eo,s),e(Eo,jr),e(jr,Qp),e(Eo,Vp),n(o,Xn,s),S(vo,o,s),n(o,jn,s),n(o,mo,s),e(mo,Yr),e(Yr,eu),e(mo,tu),n(o,Yn,s),n(o,Me,s),e(Me,Vo),e(Vo,Zr),e(Zr,ou),e(Vo,lu),e(Me,ru),e(Me,el),e(el,qr),e(qr,au),e(el,cu),n(o,Zn,s),n(o,go,s),e(go,Jr),e(Jr,iu),e(go,su),n(o,qn,s),n(o,I,s),e(I,Z),e(Z,Qr),e(Qr,nu),e(Z,du),e(Z,Vr),e(Vr,fu),e(Z,hu),e(Z,ea),e(ea,pu),e(Z,uu),e(I,_u),e(I,ke),e(ke,ta),e(ta,Eu),e(ke,vu),e(ke,oa),e(oa,mu),e(ke,gu),e(I,Cu),e(I,q),e(q,la),e(la,Ou),e(q,Du),e(q,ra),e(ra,wu),e(q,bu),e(q,aa),e(aa,Pu),e(q,Su),e(I,yu),e(I,Ge),e(Ge,ca),e(ca,Tu),e(Ge,Au),e(Ge,ia),e(ia,Iu),e(Ge,Lu),e(I,$u),e(I,xe),e(xe,sa),e(sa,Nu),e(xe,Uu),e(xe,na),e(na,Mu),e(xe,ku),n(o,Jn,s),n(o,J,s),e(J,Gu),e(J,da),e(da,xu),e(J,Ru),e(J,fa),e(fa,Fu),e(J,Wu),n(o,Qn,s),n(o,Co,s),e(Co,ha),e(ha,Hu),e(Co,zu),n(o,Vn,s),n(o,F,s),e(F,Re),e(Re,pa),e(pa,Bu),e(Re,Ku),e(Re,ua),e(ua,Xu),e(Re,ju),e(F,Yu),e(F,Fe),e(Fe,_a),e(_a,Zu),e(Fe,qu),e(Fe,Ea),e(Ea,Ju),e(Fe,Qu),e(F,Vu),e(F,We),e(We,va),e(va,e_),e(We,t_),e(We,ma),e(ma,o_),e(We,l_),e(F,r_),e(F,He),e(He,ga),e(ga,a_),e(He,c_),e(He,Ca),e(Ca,i_),e(He,s_),n(o,ed,s),n(o,Oo,s),e(Oo,Oa),e(Oa,n_),e(Oo,d_),n(o,td,s),n(o,tl,s),e(tl,f_),n(o,od,s),n(o,W,s),e(W,ze),e(ze,Da),e(Da,h_),e(ze,p_),e(ze,wa),e(wa,u_),e(ze,__),e(W,E_),e(W,Be),e(Be,ba),e(ba,v_),e(Be,m_),e(Be,Pa),e(Pa,g_),e(Be,C_),e(W,O_),e(W,Ke),e(Ke,Sa),e(Sa,D_),e(Ke,w_),e(Ke,ya),e(ya,b_),e(Ke,P_),e(W,S_),e(W,Xe),e(Xe,Ta),e(Ta,y_),e(Xe,T_),e(Xe,Aa),e(Aa,A_),e(Xe,I_),n(o,ld,s),n(o,Do,s),e(Do,Ia),e(Ia,L_),e(Do,$_),n(o,rd,s),n(o,ol,s),e(ol,N_),n(o,ad,s),n(o,Q,s),e(Q,je),e(je,La),e(La,U_),e(je,M_),e(je,$a),e($a,k_),e(je,G_),e(Q,x_),e(Q,Ye),e(Ye,Na),e(Na,R_),e(Ye,F_),e(Ye,Ua),e(Ua,W_),e(Ye,H_),e(Q,z_),e(Q,Ze),e(Ze,Ma),e(Ma,B_),e(Ze,K_),e(Ze,ka),e(ka,X_),e(Ze,j_),n(o,cd,s),n(o,wo,s),e(wo,Ga),e(Ga,Y_),e(wo,Z_),n(o,id,s),n(o,V,s),e(V,q_),e(V,xa),e(xa,J_),e(V,Q_),e(V,Ra),e(Ra,V_),e(V,e1),n(o,sd,s),n(o,_,s),e(_,qe),e(qe,Fa),e(Fa,t1),e(qe,o1),e(qe,Wa),e(Wa,l1),e(qe,r1),e(_,a1),e(_,Je),e(Je,Ha),e(Ha,c1),e(Je,i1),e(Je,za),e(za,s1),e(Je,n1),e(_,d1),e(_,Qe),e(Qe,Ba),e(Ba,f1),e(Qe,h1),e(Qe,Ka),e(Ka,p1),e(Qe,u1),e(_,_1),e(_,Ve),e(Ve,Xa),e(Xa,E1),e(Ve,v1),e(Ve,ja),e(ja,m1),e(Ve,g1),e(_,C1),e(_,et),e(et,Ya),e(Ya,O1),e(et,D1),e(et,Za),e(Za,w1),e(et,b1),e(_,P1),e(_,tt),e(tt,qa),e(qa,S1),e(tt,y1),e(tt,Ja),e(Ja,T1),e(tt,A1),e(_,I1),e(_,ot),e(ot,Qa),e(Qa,L1),e(ot,$1),e(ot,Va),e(Va,N1),e(ot,U1),e(_,M1),e(_,lt),e(lt,ec),e(ec,k1),e(lt,G1),e(lt,tc),e(tc,x1),e(lt,R1),n(o,nd,s),n(o,bo,s),e(bo,oc),e(oc,F1),e(bo,W1),n(o,dd,s),n(o,ee,s),e(ee,H1),e(ee,lc),e(lc,z1),e(ee,B1),e(ee,rc),e(rc,K1),e(ee,X1),n(o,fd,s),n(o,rt,s),e(rt,at),e(at,ac),e(ac,j1),e(at,Y1),e(at,cc),e(cc,Z1),e(at,q1),e(rt,J1),e(rt,ct),e(ct,ic),e(ic,Q1),e(ct,V1),e(ct,sc),e(sc,eE),e(ct,tE),n(o,hd,s),n(o,Po,s),e(Po,nc),e(nc,oE),e(Po,lE),n(o,pd,s),n(o,H,s),e(H,rE),e(H,dc),e(dc,aE),e(H,cE),e(H,fc),e(fc,iE),e(H,sE),e(H,hc),e(hc,nE),e(H,dE),n(o,ud,s),n(o,p,s),e(p,it),e(it,pc),e(pc,fE),e(it,hE),e(it,uc),e(uc,pE),e(it,uE),e(p,_E),e(p,st),e(st,_c),e(_c,EE),e(st,vE),e(st,Ec),e(Ec,mE),e(st,gE),e(p,CE),e(p,nt),e(nt,vc),e(vc,OE),e(nt,DE),e(nt,mc),e(mc,wE),e(nt,bE),e(p,PE),e(p,dt),e(dt,gc),e(gc,SE),e(dt,yE),e(dt,Cc),e(Cc,TE),e(dt,AE),e(p,IE),e(p,ft),e(ft,Oc),e(Oc,LE),e(ft,$E),e(ft,Dc),e(Dc,NE),e(ft,UE),e(p,ME),e(p,ht),e(ht,wc),e(wc,kE),e(ht,GE),e(ht,bc),e(bc,xE),e(ht,RE),e(p,FE),e(p,te),e(te,Pc),e(Pc,WE),e(te,HE),e(te,Sc),e(Sc,zE),e(te,BE),e(te,yc),e(yc,KE),e(te,XE),e(p,jE),e(p,pt),e(pt,Tc),e(Tc,YE),e(pt,ZE),e(pt,Ac),e(Ac,qE),e(pt,JE),e(p,QE),e(p,ut),e(ut,Ic),e(Ic,VE),e(ut,ev),e(ut,Lc),e(Lc,tv),e(ut,ov),e(p,lv),e(p,_t),e(_t,$c),e($c,rv),e(_t,av),e(_t,Nc),e(Nc,cv),e(_t,iv),e(p,sv),e(p,Et),e(Et,Uc),e(Uc,nv),e(Et,dv),e(Et,Mc),e(Mc,fv),e(Et,hv),e(p,pv),e(p,vt),e(vt,kc),e(kc,uv),e(vt,_v),e(vt,Gc),e(Gc,Ev),e(vt,vv),n(o,_d,s),n(o,So,s),e(So,xc),e(xc,mv),e(So,gv),n(o,Ed,s),n(o,oe,s),e(oe,Cv),e(oe,Rc),e(Rc,Ov),e(oe,Dv),e(oe,Fc),e(Fc,wv),e(oe,bv),n(o,vd,s),n(o,E,s),e(E,mt),e(mt,Wc),e(Wc,Pv),e(mt,Sv),e(mt,Hc),e(Hc,yv),e(mt,Tv),e(E,Av),e(E,gt),e(gt,zc),e(zc,Iv),e(gt,Lv),e(gt,Bc),e(Bc,$v),e(gt,Nv),e(E,Uv),e(E,Ct),e(Ct,Kc),e(Kc,Mv),e(Ct,kv),e(Ct,Xc),e(Xc,Gv),e(Ct,xv),e(E,Rv),e(E,Ot),e(Ot,jc),e(jc,Fv),e(Ot,Wv),e(Ot,Yc),e(Yc,Hv),e(Ot,zv),e(E,Bv),e(E,L),e(L,Zc),e(Zc,Kv),e(L,Xv),e(L,qc),e(qc,jv),e(L,Yv),e(L,Jc),e(Jc,Zv),e(L,qv),e(L,Qc),e(Qc,Jv),e(L,Qv),e(L,Vc),e(Vc,Vv),e(L,em),e(E,tm),e(E,Dt),e(Dt,ei),e(ei,om),e(Dt,lm),e(Dt,ti),e(ti,rm),e(Dt,am),e(E,cm),e(E,wt),e(wt,oi),e(oi,im),e(wt,sm),e(wt,li),e(li,nm),e(wt,dm),n(o,md,s),n(o,yo,s),e(yo,ri),e(ri,fm),e(yo,hm),n(o,gd,s),n(o,le,s),e(le,pm),e(le,ai),e(ai,um),e(le,_m),e(le,ci),e(ci,Em),e(le,vm),n(o,Cd,s),n(o,v,s),e(v,ll),e(ll,ii),e(ii,mm),e(ll,gm),e(v,Cm),e(v,rl),e(rl,si),e(si,Om),e(rl,Dm),e(v,wm),e(v,al),e(al,ni),e(ni,bm),e(al,Pm),e(v,Sm),e(v,cl),e(cl,di),e(di,ym),e(cl,Tm),e(v,Am),e(v,il),e(il,fi),e(fi,Im),e(il,Lm),e(v,$m),e(v,sl),e(sl,hi),e(hi,Nm),e(sl,Um),e(v,Mm),e(v,nl),e(nl,pi),e(pi,km),e(nl,Gm),n(o,Od,s),n(o,To,s),e(To,ui),e(ui,xm),e(To,Rm),n(o,Dd,s),n(o,dl,s),e(dl,Fm),n(o,wd,s),n(o,bt,s),e(bt,Pt),e(Pt,_i),e(_i,Wm),e(Pt,Hm),e(Pt,Ei),e(Ei,zm),e(Pt,Bm),e(bt,Km),e(bt,St),e(St,vi),e(vi,Xm),e(St,jm),e(St,mi),e(mi,Ym),e(St,Zm),n(o,bd,s),n(o,Ee,s),e(Ee,yt),e(yt,gi),S(Ao,gi,null),e(Ee,qm),e(Ee,Ci),e(Ci,Jm),n(o,Pd,s),n(o,fl,s),e(fl,Oi),e(Oi,Qm),n(o,Sd,s),n(o,Io,s),e(Io,Di),e(Di,Vm),e(Io,e2),n(o,yd,s),S(Lo,o,s),n(o,Td,s),n(o,$o,s),e($o,wi),e(wi,t2),e($o,o2),n(o,Ad,s),n(o,hl,s),e(hl,re),e(re,bi),e(bi,l2),e(re,r2),e(re,Pi),e(Pi,a2),e(re,c2),e(re,Si),e(Si,i2),e(re,s2),n(o,Id,s),n(o,No,s),e(No,yi),e(yi,n2),e(No,d2),n(o,Ld,s),n(o,Tt,s),e(Tt,f2),e(Tt,Ti),e(Ti,h2),e(Tt,p2),n(o,$d,s),n(o,ae,s),e(ae,At),e(At,Ai),e(Ai,u2),e(At,_2),e(At,Ii),e(Ii,E2),e(At,v2),e(ae,m2),e(ae,It),e(It,Li),e(Li,g2),e(It,C2),e(It,$i),e($i,O2),e(It,D2),e(ae,w2),e(ae,Lt),e(Lt,Ni),e(Ni,b2),e(Lt,P2),e(Lt,Ui),e(Ui,S2),e(Lt,y2),n(o,Nd,s),n(o,Uo,s),e(Uo,Mi),e(Mi,T2),e(Uo,A2),n(o,Ud,s),n(o,pl,s),e(pl,I2),n(o,Md,s),n(o,$,s),e($,$t),e($t,ki),e(ki,L2),e($t,$2),e($t,Gi),e(Gi,N2),e($t,U2),e($,M2),e($,Nt),e(Nt,xi),e(xi,k2),e(Nt,G2),e(Nt,Ri),e(Ri,x2),e(Nt,R2),e($,F2),e($,Ut),e(Ut,Fi),e(Fi,W2),e(Ut,H2),e(Ut,Wi),e(Wi,z2),e(Ut,B2),e($,K2),e($,Mt),e(Mt,Hi),e(Hi,X2),e(Mt,j2),e(Mt,zi),e(zi,Y2),e(Mt,Z2),e($,q2),e($,kt),e(kt,Bi),e(Bi,J2),e(kt,Q2),e(kt,Ki),e(Ki,V2),e(kt,e3),n(o,kd,s),n(o,ve,s),e(ve,Gt),e(Gt,Xi),S(Mo,Xi,null),e(ve,t3),e(ve,ji),e(ji,o3),n(o,Gd,s),n(o,xt,s),e(xt,Yi),e(Yi,l3),e(xt,r3),e(xt,Zi),e(Zi,a3),n(o,xd,s),n(o,Rt,s),e(Rt,c3),e(Rt,qi),e(qi,i3),e(Rt,s3),n(o,Rd,s),n(o,ko,s),e(ko,Ji),e(Ji,n3),e(ko,d3),n(o,Fd,s),S(Go,o,s),n(o,Wd,s),n(o,xo,s),e(xo,Qi),e(Qi,f3),e(xo,h3),n(o,Hd,s),n(o,Ft,s),e(Ft,D),e(D,Vi),e(Vi,p3),e(D,u3),e(D,es),e(es,_3),e(D,E3),e(D,ts),e(ts,v3),e(D,m3),e(D,os),e(os,g3),e(D,C3),e(D,ls),e(ls,O3),e(D,D3),e(D,rs),e(rs,w3),e(D,b3),e(Ft,P3),e(Ft,ce),e(ce,as),e(as,S3),e(ce,y3),e(ce,cs),e(cs,T3),e(ce,A3),e(ce,is),e(is,I3),e(ce,L3),zd=!0},p:TO,i(o){zd||(y(Kt.$$.fragment,o),y(Xt.$$.fragment,o),y(Zt.$$.fragment,o),y(Jt.$$.fragment,o),y(eo.$$.fragment,o),y(oo.$$.fragment,o),y(ao.$$.fragment,o),y(io.$$.fragment,o),y(ho.$$.fragment,o),y(uo.$$.fragment,o),y(vo.$$.fragment,o),y(Ao.$$.fragment,o),y(Lo.$$.fragment,o),y(Mo.$$.fragment,o),y(Go.$$.fragment,o),zd=!0)},o(o){T(Kt.$$.fragment,o),T(Xt.$$.fragment,o),T(Zt.$$.fragment,o),T(Jt.$$.fragment,o),T(eo.$$.fragment,o),T(oo.$$.fragment,o),T(ao.$$.fragment,o),T(io.$$.fragment,o),T(ho.$$.fragment,o),T(uo.$$.fragment,o),T(vo.$$.fragment,o),T(Ao.$$.fragment,o),T(Lo.$$.fragment,o),T(Mo.$$.fragment,o),T(Go.$$.fragment,o),zd=!1},d(o){t(ne),o&&t(cn),o&&t(de),A(Kt),o&&t(sn),o&&t(Zo),o&&t(nn),o&&t(fe),A(Xt),o&&t(dn),o&&t(jt),o&&t(fn),o&&t(Ce),o&&t(hn),o&&t(Oe),o&&t(pn),o&&t(Yt),o&&t(un),A(Zt,o),o&&t(_n),o&&t(qt),o&&t(En),o&&t(De),o&&t(vn),o&&t(he),A(Jt),o&&t(mn),o&&t(Qt),o&&t(gn),o&&t(be),o&&t(Cn),o&&t(qo),o&&t(On),o&&t(Vt),o&&t(Dn),A(eo,o),o&&t(wn),o&&t(to),o&&t(bn),o&&t(K),o&&t(Pn),o&&t(pe),A(oo),o&&t(Sn),o&&t(lo),o&&t(yn),o&&t(ye),o&&t(Tn),o&&t(Jo),o&&t(An),o&&t(ro),o&&t(In),A(ao,o),o&&t(Ln),o&&t(co),o&&t($n),o&&t(Te),o&&t(Nn),o&&t(ue),A(io),o&&t(Un),o&&t(so),o&&t(Mn),o&&t(Ie),o&&t(kn),o&&t(Le),o&&t(Gn),o&&t(fo),o&&t(xn),A(ho,o),o&&t(Rn),o&&t(po),o&&t(Fn),o&&t($e),o&&t(Wn),o&&t(_e),A(uo),o&&t(Hn),o&&t(_o),o&&t(zn),o&&t(Ue),o&&t(Bn),o&&t(Qo),o&&t(Kn),o&&t(Eo),o&&t(Xn),A(vo,o),o&&t(jn),o&&t(mo),o&&t(Yn),o&&t(Me),o&&t(Zn),o&&t(go),o&&t(qn),o&&t(I),o&&t(Jn),o&&t(J),o&&t(Qn),o&&t(Co),o&&t(Vn),o&&t(F),o&&t(ed),o&&t(Oo),o&&t(td),o&&t(tl),o&&t(od),o&&t(W),o&&t(ld),o&&t(Do),o&&t(rd),o&&t(ol),o&&t(ad),o&&t(Q),o&&t(cd),o&&t(wo),o&&t(id),o&&t(V),o&&t(sd),o&&t(_),o&&t(nd),o&&t(bo),o&&t(dd),o&&t(ee),o&&t(fd),o&&t(rt),o&&t(hd),o&&t(Po),o&&t(pd),o&&t(H),o&&t(ud),o&&t(p),o&&t(_d),o&&t(So),o&&t(Ed),o&&t(oe),o&&t(vd),o&&t(E),o&&t(md),o&&t(yo),o&&t(gd),o&&t(le),o&&t(Cd),o&&t(v),o&&t(Od),o&&t(To),o&&t(Dd),o&&t(dl),o&&t(wd),o&&t(bt),o&&t(bd),o&&t(Ee),A(Ao),o&&t(Pd),o&&t(fl),o&&t(Sd),o&&t(Io),o&&t(yd),A(Lo,o),o&&t(Td),o&&t($o),o&&t(Ad),o&&t(hl),o&&t(Id),o&&t(No),o&&t(Ld),o&&t(Tt),o&&t($d),o&&t(ae),o&&t(Nd),o&&t(Uo),o&&t(Ud),o&&t(pl),o&&t(Md),o&&t($),o&&t(kd),o&&t(ve),A(Mo),o&&t(Gd),o&&t(xt),o&&t(xd),o&&t(Rt),o&&t(Rd),o&&t(ko),o&&t(Fd),A(Go,o),o&&t(Wd),o&&t(xo),o&&t(Hd),o&&t(Ft)}}}const LO={local:"the-command-line",sections:[{local:"accelerate-config",title:"accelerate config"},{local:"accelerate-config-default",title:"accelerate config default"},{local:"accelerate-config-update",title:"accelerate config update"},{local:"accelerate-env",title:"accelerate env"},{local:"accelerate-launch",title:"accelerate launch"},{local:"accelerate-tpuconfig",title:"accelerate tpu-config"},{local:"accelerate-test",title:"accelerate test"}],title:"The Command Line "};function $O(m5){return AO(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class kO extends bO{constructor(ne){super();PO(this,ne,$O,IO,SO,{})}}export{kO as default,LO as metadata};
