import{S as Pi,i as ki,s as Ni,e as a,k as l,w as m,t as i,M as Li,c as s,d as r,m as n,a as o,x as f,h as c,b as u,G as t,g as p,y as h,q as v,o as g,B as _,v as Ci}from"../../chunks/vendor-hf-doc-builder.js";import{T as Ai}from"../../chunks/Tip-hf-doc-builder.js";import{D as b}from"../../chunks/Docstring-hf-doc-builder.js";import{I as se}from"../../chunks/IconCopyLink-hf-doc-builder.js";function Ii(Fr){let $,oe;return{c(){$=a("p"),oe=i("Make sure all processes will reach this instruction otherwise one of your processes will hang forever.")},l(y){$=s(y,"P",{});var E=o($);oe=c(E,"Make sure all processes will reach this instruction otherwise one of your processes will hang forever."),E.forEach(r)},m(y,E){p(y,$,E),t($,oe)},d(y){y&&r($)}}}function Ui(Fr){let $,oe,y,E,At,xe,ns,It,is,Br,ct,cs,Wr,I,le,Ut,Te,ds,Ot,ps,jr,dt,us,Jr,w,De,ms,St,fs,hs,Rt,vs,gs,x,pt,zt,_s,bs,$s,ut,Mt,ys,Es,ws,mt,Vt,xs,Ts,Ds,ft,Gt,Ps,ks,Ns,ht,Ht,Ls,Cs,Kr,T,Pe,As,qt,Is,Us,Ft,Os,Ss,P,vt,Bt,Rs,zs,Ms,gt,Wt,Vs,Gs,Hs,_t,jt,qs,Fs,Bs,bt,Jt,Ws,js,Qr,D,ke,Js,Kt,Ks,Qs,Qt,Xs,Ys,U,$t,Xt,Zs,eo,to,yt,Yt,ro,ao,so,Et,Zt,oo,lo,Xr,O,ne,er,Ne,no,tr,io,Yr,ie,co,rr,po,uo,Zr,S,Le,mo,ar,fo,ea,R,Ce,ho,sr,vo,ta,z,Ae,go,or,_o,ra,M,Ie,bo,lr,$o,aa,V,Ue,yo,nr,Eo,sa,G,Oe,wo,ir,xo,oa,H,ce,cr,Se,To,dr,Do,la,wt,Po,na,q,Re,ko,pr,No,ia,F,ze,Lo,ur,Co,ca,B,Me,Ao,Ve,Io,mr,Uo,Oo,da,W,de,fr,Ge,So,hr,Ro,pa,j,He,zo,vr,Mo,ua,pe,Vo,gr,Go,Ho,ma,J,ue,_r,qe,qo,br,Fo,fa,K,Fe,Bo,$r,Wo,ha,k,Be,jo,me,Jo,yr,Ko,Qo,Er,Xo,Yo,fe,wr,Zo,el,xr,tl,rl,va,Q,he,Tr,We,al,Dr,sl,ga,xt,ol,_a,X,je,ll,Pr,nl,ba,N,Je,il,kr,cl,dl,Ke,Nr,pl,ul,Tt,ml,Lr,fl,$a,Y,Qe,hl,Cr,vl,ya,Z,ve,Ar,Xe,gl,Ir,_l,Ea,Dt,bl,wa,ee,Ye,$l,Ur,yl,xa,te,Ze,El,et,wl,Or,xl,Tl,Ta,L,tt,Dl,Sr,Pl,kl,ge,Da,re,_e,Rr,rt,Nl,zr,Ll,Pa,Pt,Cl,ka,ae,at,Al,C,Il,Mr,Ul,Ol,Vr,Sl,Rl,Gr,zl,Ml,Na,st,ot,La,lt,nt,Ca;return xe=new se({}),Te=new se({}),De=new b({props:{name:"class accelerate.DistributedType",anchor:"accelerate.DistributedType",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/dataclasses.py#L106"}}),Pe=new b({props:{name:"class accelerate.utils.LoggerType",anchor:"accelerate.utils.LoggerType",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/dataclasses.py#L184"}}),ke=new b({props:{name:"class accelerate.utils.PrecisionType",anchor:"accelerate.utils.PrecisionType",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/dataclasses.py#L201"}}),Ne=new se({}),Le=new b({props:{name:"accelerate.utils.broadcast",anchor:"accelerate.utils.broadcast",parameters:[{name:"tensor",val:""},{name:"from_process",val:": int = 0"}],parametersDescription:[{anchor:"accelerate.utils.broadcast.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to gather.`,name:"tensor"},{anchor:"accelerate.utils.broadcast.from_process",description:`<strong>from_process</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The process from which to send the data`,name:"from_process"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/operations.py#L285",returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors broadcasted to the proper device.</p>
`}}),Ce=new b({props:{name:"accelerate.utils.concatenate",anchor:"accelerate.utils.concatenate",parameters:[{name:"data",val:""},{name:"dim",val:" = 0"}],parametersDescription:[{anchor:"accelerate.utils.concatenate.data",description:`<strong>data</strong> (nested list/tuple/dictionary of lists of tensors <code>torch.Tensor</code>) &#x2014;
The data to concatenate.`,name:"data"},{anchor:"accelerate.utils.concatenate.dim",description:`<strong>dim</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The dimension on which to concatenate.`,name:"dim"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/operations.py#L359",returnDescription:`
<p>The same data structure as <code>data</code> with all the tensors concatenated.</p>
`}}),Ae=new b({props:{name:"accelerate.utils.gather",anchor:"accelerate.utils.gather",parameters:[{name:"tensor",val:""}],parametersDescription:[{anchor:"accelerate.utils.gather.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to gather.`,name:"tensor"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/operations.py#L207",returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors sent to the proper device.</p>
`}}),Ie=new b({props:{name:"accelerate.utils.pad_across_processes",anchor:"accelerate.utils.pad_across_processes",parameters:[{name:"tensor",val:""},{name:"dim",val:" = 0"},{name:"pad_index",val:" = 0"},{name:"pad_first",val:" = False"}],parametersDescription:[{anchor:"accelerate.utils.pad_across_processes.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to gather.`,name:"tensor"},{anchor:"accelerate.utils.pad_across_processes.dim",description:`<strong>dim</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The dimension on which to pad.`,name:"dim"},{anchor:"accelerate.utils.pad_across_processes.pad_index",description:`<strong>pad_index</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The value with which to pad.`,name:"pad_index"},{anchor:"accelerate.utils.pad_across_processes.pad_first",description:`<strong>pad_first</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to pad at the beginning or the end.`,name:"pad_first"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/operations.py#L381"}}),Ue=new b({props:{name:"accelerate.utils.reduce",anchor:"accelerate.utils.reduce",parameters:[{name:"tensor",val:""},{name:"reduction",val:" = 'mean'"}],parametersDescription:[{anchor:"accelerate.utils.reduce.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to reduce.`,name:"tensor"},{anchor:"accelerate.utils.reduce.reduction",description:`<strong>reduction</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;mean&quot;</code>) &#x2014;
A reduction method. Can be of &#x201C;mean&#x201D;, &#x201C;sum&#x201D;, or &#x201C;none&#x201D;`,name:"reduction"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/operations.py#L427",returnDescription:`
<p>The same data structure as <code>data</code> with all the tensors reduced.</p>
`}}),Oe=new b({props:{name:"accelerate.utils.send_to_device",anchor:"accelerate.utils.send_to_device",parameters:[{name:"tensor",val:""},{name:"device",val:""}],parametersDescription:[{anchor:"accelerate.utils.send_to_device.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to send to a given device.`,name:"tensor"},{anchor:"accelerate.utils.send_to_device.device",description:`<strong>device</strong> (<code>torch.device</code>) &#x2014;
The device to send the data to.`,name:"device"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/operations.py#L106",returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors sent to the proper device.</p>
`}}),Se=new se({}),Re=new b({props:{name:"accelerate.utils.is_bf16_available",anchor:"accelerate.utils.is_bf16_available",parameters:[{name:"ignore_tpu",val:" = False"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/imports.py#L77"}}),ze=new b({props:{name:"accelerate.utils.is_torch_version",anchor:"accelerate.utils.is_torch_version",parameters:[{name:"operation",val:": str"},{name:"version",val:": str"}],parametersDescription:[{anchor:"accelerate.utils.is_torch_version.operation",description:`<strong>operation</strong> (<code>str</code>) &#x2014;
A string representation of an operator, such as <code>&quot;&gt;&quot;</code> or <code>&quot;&lt;=&quot;</code>`,name:"operation"},{anchor:"accelerate.utils.is_torch_version.version",description:`<strong>version</strong> (<code>str</code>) &#x2014;
A string version of PyTorch`,name:"version"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/versions.py#L51"}}),Me=new b({props:{name:"accelerate.utils.is_tpu_available",anchor:"accelerate.utils.is_tpu_available",parameters:[{name:"check_device",val:" = True"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/imports.py#L53"}}),Ge=new se({}),He=new b({props:{name:"accelerate.utils.write_basic_config",anchor:"accelerate.utils.write_basic_config",parameters:[{name:"mixed_precision",val:" = 'no'"},{name:"save_location",val:": str = '/github/home/.cache/huggingface/accelerate/default_config.yaml'"}],parametersDescription:[{anchor:"accelerate.utils.write_basic_config.mixed_precision",description:`<strong>mixed_precision</strong> (<code>str</code>, <em>optional</em>, defaults to &#x201C;no&#x201D;) &#x2014;
Mixed Precision to use. Should be one of &#x201C;no&#x201D;, &#x201C;fp16&#x201D;, or &#x201C;bf16&#x201D;`,name:"mixed_precision"},{anchor:"accelerate.utils.write_basic_config.save_location",description:`<strong>save_location</strong> (<code>str</code>, <em>optional</em>, defaults to <code>default_json_config_file</code>) &#x2014;
Optional custom save location. Should be passed to <code>--config_file</code> when using <code>accelerate launch</code>. Default
location is inside the huggingface cache folder (<code>~/.cache/huggingface</code>) but can be overriden by setting
the <code>HF_HOME</code> environmental variable, followed by <code>accelerate/default_config.yaml</code>.`,name:"save_location"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/other.py#L118"}}),qe=new se({}),Fe=new b({props:{name:"accelerate.utils.get_max_memory",anchor:"accelerate.utils.get_max_memory",parameters:[{name:"max_memory",val:": typing.Union[typing.Dict[typing.Union[int, str], typing.Union[int, str]], NoneType] = None"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/modeling.py#L275"}}),Be=new b({props:{name:"accelerate.find_executable_batch_size",anchor:"accelerate.find_executable_batch_size",parameters:[{name:"function",val:": callable = None"},{name:"starting_batch_size",val:": int = 128"}],parametersDescription:[{anchor:"accelerate.find_executable_batch_size.function",description:`<strong>function</strong> (<code>callable</code>, <em>optional</em>) &#x2014;
A function to wrap`,name:"function"},{anchor:"accelerate.find_executable_batch_size.starting_batch_size",description:`<strong>starting_batch_size</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The batch size to try and fit into memory`,name:"starting_batch_size"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/memory.py#L45"}}),We=new se({}),je=new b({props:{name:"accelerate.utils.extract_model_from_parallel",anchor:"accelerate.utils.extract_model_from_parallel",parameters:[{name:"model",val:""}],parametersDescription:[{anchor:"accelerate.utils.extract_model_from_parallel.model",description:"<strong>model</strong> (<code>torch.nn.Module</code>) &#x2014; The model to extract.",name:"model"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/other.py#L35",returnDescription:`
<p>The extracted model.</p>
`,returnType:`
<p><code>torch.nn.Module</code></p>
`}}),Je=new b({props:{name:"accelerate.utils.get_max_layer_size",anchor:"accelerate.utils.get_max_layer_size",parameters:[{name:"modules",val:": typing.List[typing.Tuple[str, torch.nn.modules.module.Module]]"},{name:"module_sizes",val:": typing.Dict[str, int]"},{name:"no_split_module_classes",val:": typing.List[str]"}],parametersDescription:[{anchor:"accelerate.utils.get_max_layer_size.modules",description:`<strong>modules</strong> (<code>List[Tuple[str, torch.nn.Module]]</code>) &#x2014;
The list of named modules where we want to determine the maximum layer size.`,name:"modules"},{anchor:"accelerate.utils.get_max_layer_size.module_sizes",description:`<strong>module_sizes</strong> (<code>Dict[str, int]</code>) &#x2014;
A dictionary mapping each layer name to its size (as generated by <code>compute_module_sizes</code>).`,name:"module_sizes"},{anchor:"accelerate.utils.get_max_layer_size.no_split_module_classes",description:`<strong>no_split_module_classes</strong> (<code>List[str]</code>) &#x2014;
A list of class names for layers we don&#x2019;t want to be split.`,name:"no_split_module_classes"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/modeling.py#L236",returnDescription:`
<p>The maximum size of a layer with the list of layer names realizing that maximum size.</p>
`,returnType:`
<p><code>Tuple[int, List[str]]</code></p>
`}}),Qe=new b({props:{name:"accelerate.utils.offload_state_dict",anchor:"accelerate.utils.offload_state_dict",parameters:[{name:"save_dir",val:": typing.Union[str, os.PathLike]"},{name:"state_dict",val:": typing.Dict[str, torch.Tensor]"}],parametersDescription:[{anchor:"accelerate.utils.offload_state_dict.save_dir",description:"<strong>save_dir</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014; The directory in which to offload the state dict.",name:"save_dir"},{anchor:"accelerate.utils.offload_state_dict.state_dict",description:"<strong>state_dict</strong> (<code>Dict[str, torch.Tensor]</code>) &#x2014; The dictionary of tensors to offload.",name:"state_dict"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/offload.py#L84"}}),Xe=new se({}),Ye=new b({props:{name:"accelerate.utils.extract_model_from_parallel",anchor:"accelerate.utils.extract_model_from_parallel",parameters:[{name:"model",val:""}],parametersDescription:[{anchor:"accelerate.utils.extract_model_from_parallel.model",description:"<strong>model</strong> (<code>torch.nn.Module</code>) &#x2014; The model to extract.",name:"model"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/other.py#L35",returnDescription:`
<p>The extracted model.</p>
`,returnType:`
<p><code>torch.nn.Module</code></p>
`}}),Ze=new b({props:{name:"accelerate.utils.save",anchor:"accelerate.utils.save",parameters:[{name:"obj",val:""},{name:"f",val:""}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/other.py#L75"}}),tt=new b({props:{name:"accelerate.utils.wait_for_everyone",anchor:"accelerate.utils.wait_for_everyone",parameters:[],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/other.py#L54"}}),ge=new Ai({props:{warning:!0,$$slots:{default:[Ii]},$$scope:{ctx:Fr}}}),rt=new se({}),at=new b({props:{name:"accelerate.utils.set_seed",anchor:"accelerate.utils.set_seed",parameters:[{name:"seed",val:": int"},{name:"device_specific",val:": bool = False"}],parametersDescription:[{anchor:"accelerate.utils.set_seed.seed",description:"<strong>seed</strong> (<code>int</code>) &#x2014; The seed to set.",name:"seed"},{anchor:"accelerate.utils.set_seed.device_specific",description:`<strong>device_specific</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to differ the seed on each device slightly with <code>self.process_index</code>.`,name:"device_specific"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/random.py#L30"}}),ot=new b({props:{name:"accelerate.utils.synchronize_rng_state",anchor:"accelerate.utils.synchronize_rng_state",parameters:[{name:"rng_type",val:": typing.Optional[accelerate.utils.dataclasses.RNGType] = None"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/random.py#L50"}}),nt=new b({props:{name:"accelerate.synchronize_rng_states",anchor:"accelerate.synchronize_rng_states",parameters:[{name:"rng_types",val:": typing.List[typing.Union[str, accelerate.utils.dataclasses.RNGType]]"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/random.py#L85"}}),{c(){$=a("meta"),oe=l(),y=a("h1"),E=a("a"),At=a("span"),m(xe.$$.fragment),ns=l(),It=a("span"),is=i("Helpful Utilities"),Br=l(),ct=a("p"),cs=i("Below are a variety of utility functions that \u{1F917} Accelerate provides, broken down by use-case."),Wr=l(),I=a("h2"),le=a("a"),Ut=a("span"),m(Te.$$.fragment),ds=l(),Ot=a("span"),ps=i("Data Classes"),jr=l(),dt=a("p"),us=i("These are basic dataclasses used throughout \u{1F917} Accelerate and they can be passed in as parameters."),Jr=l(),w=a("div"),m(De.$$.fragment),ms=l(),St=a("p"),fs=i("Represents a type of distributed environment."),hs=l(),Rt=a("p"),vs=i("Values:"),gs=l(),x=a("ul"),pt=a("li"),zt=a("strong"),_s=i("NO"),bs=i(" \u2014 Not a distributed environment, just a single process."),$s=l(),ut=a("li"),Mt=a("strong"),ys=i("MULTI_CPU"),Es=i(" \u2014 Distributed on multiple CPU nodes."),ws=l(),mt=a("li"),Vt=a("strong"),xs=i("MULTI_GPU"),Ts=i(" \u2014 Distributed on multiple GPUs."),Ds=l(),ft=a("li"),Gt=a("strong"),Ps=i("DEEPSPEED"),ks=i(" \u2014 Using DeepSpeed."),Ns=l(),ht=a("li"),Ht=a("strong"),Ls=i("TPU"),Cs=i(" \u2014 Distributed on TPUs."),Kr=l(),T=a("div"),m(Pe.$$.fragment),As=l(),qt=a("p"),Is=i("Represents a type of supported experiment tracker"),Us=l(),Ft=a("p"),Os=i("Values:"),Ss=l(),P=a("ul"),vt=a("li"),Bt=a("strong"),Rs=i("ALL"),zs=i(" \u2014 all available trackers in the environment that are supported"),Ms=l(),gt=a("li"),Wt=a("strong"),Vs=i("TENSORBOARD"),Gs=i(" \u2014 TensorBoard as an experiment tracker"),Hs=l(),_t=a("li"),jt=a("strong"),qs=i("WANDB"),Fs=i(" \u2014 wandb as an experiment tracker"),Bs=l(),bt=a("li"),Jt=a("strong"),Ws=i("COMETML"),js=i(" \u2014 comet_ml as an experiment tracker"),Qr=l(),D=a("div"),m(ke.$$.fragment),Js=l(),Kt=a("p"),Ks=i("Represents a type of precision used on floating point values"),Qs=l(),Qt=a("p"),Xs=i("Values:"),Ys=l(),U=a("ul"),$t=a("li"),Xt=a("strong"),Zs=i("NO"),eo=i(" \u2014 using full precision (FP32)"),to=l(),yt=a("li"),Yt=a("strong"),ro=i("FP16"),ao=i(" \u2014 using half precision"),so=l(),Et=a("li"),Zt=a("strong"),oo=i("BF16"),lo=i(" \u2014 using brain floating point precision"),Xr=l(),O=a("h2"),ne=a("a"),er=a("span"),m(Ne.$$.fragment),no=l(),tr=a("span"),io=i("Data Manipulation and Operations"),Yr=l(),ie=a("p"),co=i("These include data operations that mimic the same "),rr=a("code"),po=i("torch"),uo=i(" ops but can be used on distributed processes."),Zr=l(),S=a("div"),m(Le.$$.fragment),mo=l(),ar=a("p"),fo=i("Recursively broadcast tensor in a nested list/tuple/dictionary of tensors to all devices."),ea=l(),R=a("div"),m(Ce.$$.fragment),ho=l(),sr=a("p"),vo=i("Recursively concatenate the tensors in a nested list/tuple/dictionary of lists of tensors with the same shape."),ta=l(),z=a("div"),m(Ae.$$.fragment),go=l(),or=a("p"),_o=i("Recursively gather tensor in a nested list/tuple/dictionary of tensors from all devices."),ra=l(),M=a("div"),m(Ie.$$.fragment),bo=l(),lr=a("p"),$o=i(`Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so they
can safely be gathered.`),aa=l(),V=a("div"),m(Ue.$$.fragment),yo=l(),nr=a("p"),Eo=i(`Recursively reduce the tensors in a nested list/tuple/dictionary of lists of tensors across all processes by the
mean of a given operation.`),sa=l(),G=a("div"),m(Oe.$$.fragment),wo=l(),ir=a("p"),xo=i("Recursively sends the elements in a nested list/tuple/dictionary of tensors to a given device."),oa=l(),H=a("h2"),ce=a("a"),cr=a("span"),m(Se.$$.fragment),To=l(),dr=a("span"),Do=i("Environment Checks"),la=l(),wt=a("p"),Po=i("These functionalities check the state of the current working environment including information about the operating system itself, what it can support, and if particular dependencies are installed."),na=l(),q=a("div"),m(Re.$$.fragment),ko=l(),pr=a("p"),No=i("Checks if bf16 is supported, optionally ignoring the TPU"),ia=l(),F=a("div"),m(ze.$$.fragment),Lo=l(),ur=a("p"),Co=i("Compares the current PyTorch version to a given reference with an operation."),ca=l(),B=a("div"),m(Me.$$.fragment),Ao=l(),Ve=a("p"),Io=i("Checks if "),mr=a("code"),Uo=i("torch_xla"),Oo=i(" is installed and potentially if a TPU is in the environment"),da=l(),W=a("h2"),de=a("a"),fr=a("span"),m(Ge.$$.fragment),So=l(),hr=a("span"),Ro=i("Environment Configuration"),pa=l(),j=a("div"),m(He.$$.fragment),zo=l(),vr=a("p"),Mo=i(`Creates and saves a basic cluster config to be used on a local machine with potentially multiple GPUs. Will also
set CPU if it is a CPU-only machine.`),ua=l(),pe=a("p"),Vo=i("When setting up \u{1F917} Accelerate for the first time, rather than running "),gr=a("code"),Go=i("accelerate config"),Ho=i(" [~utils.write_basic_config] can be used as an alternative for quick configuration."),ma=l(),J=a("h2"),ue=a("a"),_r=a("span"),m(qe.$$.fragment),qo=l(),br=a("span"),Fo=i("Memory"),fa=l(),K=a("div"),m(Fe.$$.fragment),Bo=l(),$r=a("p"),Wo=i("Get the maximum memory available if nothing is passed, converts string to int otherwise."),ha=l(),k=a("div"),m(Be.$$.fragment),jo=l(),me=a("p"),Jo=i("A basic decorator that will try to execute "),yr=a("code"),Ko=i("function"),Qo=i(`. If it fails from exceptions related to out-of-memory or
CUDNN, the batch size is cut in half and passed to `),Er=a("code"),Xo=i("function"),Yo=l(),fe=a("p"),wr=a("code"),Zo=i("function"),el=i(" must take in a "),xr=a("code"),tl=i("batch_size"),rl=i(" parameter as its first argument."),va=l(),Q=a("h2"),he=a("a"),Tr=a("span"),m(We.$$.fragment),al=l(),Dr=a("span"),sl=i("Modeling"),ga=l(),xt=a("p"),ol=i("These utilities relate to interacting with PyTorch models"),_a=l(),X=a("div"),m(je.$$.fragment),ll=l(),Pr=a("p"),nl=i("Extract a model from its distributed containers."),ba=l(),N=a("div"),m(Je.$$.fragment),il=l(),kr=a("p"),cl=i(`Utility function that will scan a list of named modules and return the maximum size used by one full layer. The
definition of a layer being:`),dl=l(),Ke=a("ul"),Nr=a("li"),pl=i("a module with no direct children (just parameters and buffers)"),ul=l(),Tt=a("li"),ml=i("a module whose class name is in the list "),Lr=a("code"),fl=i("no_split_module_classes"),$a=l(),Y=a("div"),m(Qe.$$.fragment),hl=l(),Cr=a("p"),vl=i("Offload a state dict in a given folder."),ya=l(),Z=a("h2"),ve=a("a"),Ar=a("span"),m(Xe.$$.fragment),gl=l(),Ir=a("span"),_l=i("Parallel"),Ea=l(),Dt=a("p"),bl=i("These include general utilities that should be used when working in parallel."),wa=l(),ee=a("div"),m(Ye.$$.fragment),$l=l(),Ur=a("p"),yl=i("Extract a model from its distributed containers."),xa=l(),te=a("div"),m(Ze.$$.fragment),El=l(),et=a("p"),wl=i("Save the data to disk. Use in place of "),Or=a("code"),xl=i("torch.save()"),Tl=i("."),Ta=l(),L=a("div"),m(tt.$$.fragment),Dl=l(),Sr=a("p"),Pl=i("Introduces a blocking point in the script, making sure all processes have reached this point before continuing."),kl=l(),m(ge.$$.fragment),Da=l(),re=a("h2"),_e=a("a"),Rr=a("span"),m(rt.$$.fragment),Nl=l(),zr=a("span"),Ll=i("Random"),Pa=l(),Pt=a("p"),Cl=i("These utilities relate to setting and synchronizing of all the random states."),ka=l(),ae=a("div"),m(at.$$.fragment),Al=l(),C=a("p"),Il=i("Helper function for reproducible behavior to set the seed in "),Mr=a("code"),Ul=i("random"),Ol=i(", "),Vr=a("code"),Sl=i("numpy"),Rl=i(", "),Gr=a("code"),zl=i("torch"),Ml=i("."),Na=l(),st=a("div"),m(ot.$$.fragment),La=l(),lt=a("div"),m(nt.$$.fragment),this.h()},l(e){const d=Li('[data-svelte="svelte-1phssyn"]',document.head);$=s(d,"META",{name:!0,content:!0}),d.forEach(r),oe=n(e),y=s(e,"H1",{class:!0});var it=o(y);E=s(it,"A",{id:!0,class:!0,href:!0});var Zl=o(E);At=s(Zl,"SPAN",{});var en=o(At);f(xe.$$.fragment,en),en.forEach(r),Zl.forEach(r),ns=n(it),It=s(it,"SPAN",{});var tn=o(It);is=c(tn,"Helpful Utilities"),tn.forEach(r),it.forEach(r),Br=n(e),ct=s(e,"P",{});var rn=o(ct);cs=c(rn,"Below are a variety of utility functions that \u{1F917} Accelerate provides, broken down by use-case."),rn.forEach(r),Wr=n(e),I=s(e,"H2",{class:!0});var Aa=o(I);le=s(Aa,"A",{id:!0,class:!0,href:!0});var an=o(le);Ut=s(an,"SPAN",{});var sn=o(Ut);f(Te.$$.fragment,sn),sn.forEach(r),an.forEach(r),ds=n(Aa),Ot=s(Aa,"SPAN",{});var on=o(Ot);ps=c(on,"Data Classes"),on.forEach(r),Aa.forEach(r),jr=n(e),dt=s(e,"P",{});var ln=o(dt);us=c(ln,"These are basic dataclasses used throughout \u{1F917} Accelerate and they can be passed in as parameters."),ln.forEach(r),Jr=n(e),w=s(e,"DIV",{class:!0});var be=o(w);f(De.$$.fragment,be),ms=n(be),St=s(be,"P",{});var nn=o(St);fs=c(nn,"Represents a type of distributed environment."),nn.forEach(r),hs=n(be),Rt=s(be,"P",{});var cn=o(Rt);vs=c(cn,"Values:"),cn.forEach(r),gs=n(be),x=s(be,"UL",{});var A=o(x);pt=s(A,"LI",{});var Vl=o(pt);zt=s(Vl,"STRONG",{});var dn=o(zt);_s=c(dn,"NO"),dn.forEach(r),bs=c(Vl," \u2014 Not a distributed environment, just a single process."),Vl.forEach(r),$s=n(A),ut=s(A,"LI",{});var Gl=o(ut);Mt=s(Gl,"STRONG",{});var pn=o(Mt);ys=c(pn,"MULTI_CPU"),pn.forEach(r),Es=c(Gl," \u2014 Distributed on multiple CPU nodes."),Gl.forEach(r),ws=n(A),mt=s(A,"LI",{});var Hl=o(mt);Vt=s(Hl,"STRONG",{});var un=o(Vt);xs=c(un,"MULTI_GPU"),un.forEach(r),Ts=c(Hl," \u2014 Distributed on multiple GPUs."),Hl.forEach(r),Ds=n(A),ft=s(A,"LI",{});var ql=o(ft);Gt=s(ql,"STRONG",{});var mn=o(Gt);Ps=c(mn,"DEEPSPEED"),mn.forEach(r),ks=c(ql," \u2014 Using DeepSpeed."),ql.forEach(r),Ns=n(A),ht=s(A,"LI",{});var Fl=o(ht);Ht=s(Fl,"STRONG",{});var fn=o(Ht);Ls=c(fn,"TPU"),fn.forEach(r),Cs=c(Fl," \u2014 Distributed on TPUs."),Fl.forEach(r),A.forEach(r),be.forEach(r),Kr=n(e),T=s(e,"DIV",{class:!0});var $e=o(T);f(Pe.$$.fragment,$e),As=n($e),qt=s($e,"P",{});var hn=o(qt);Is=c(hn,"Represents a type of supported experiment tracker"),hn.forEach(r),Us=n($e),Ft=s($e,"P",{});var vn=o(Ft);Os=c(vn,"Values:"),vn.forEach(r),Ss=n($e),P=s($e,"UL",{});var ye=o(P);vt=s(ye,"LI",{});var Bl=o(vt);Bt=s(Bl,"STRONG",{});var gn=o(Bt);Rs=c(gn,"ALL"),gn.forEach(r),zs=c(Bl," \u2014 all available trackers in the environment that are supported"),Bl.forEach(r),Ms=n(ye),gt=s(ye,"LI",{});var Wl=o(gt);Wt=s(Wl,"STRONG",{});var _n=o(Wt);Vs=c(_n,"TENSORBOARD"),_n.forEach(r),Gs=c(Wl," \u2014 TensorBoard as an experiment tracker"),Wl.forEach(r),Hs=n(ye),_t=s(ye,"LI",{});var jl=o(_t);jt=s(jl,"STRONG",{});var bn=o(jt);qs=c(bn,"WANDB"),bn.forEach(r),Fs=c(jl," \u2014 wandb as an experiment tracker"),jl.forEach(r),Bs=n(ye),bt=s(ye,"LI",{});var Jl=o(bt);Jt=s(Jl,"STRONG",{});var $n=o(Jt);Ws=c($n,"COMETML"),$n.forEach(r),js=c(Jl," \u2014 comet_ml as an experiment tracker"),Jl.forEach(r),ye.forEach(r),$e.forEach(r),Qr=n(e),D=s(e,"DIV",{class:!0});var Ee=o(D);f(ke.$$.fragment,Ee),Js=n(Ee),Kt=s(Ee,"P",{});var yn=o(Kt);Ks=c(yn,"Represents a type of precision used on floating point values"),yn.forEach(r),Qs=n(Ee),Qt=s(Ee,"P",{});var En=o(Qt);Xs=c(En,"Values:"),En.forEach(r),Ys=n(Ee),U=s(Ee,"UL",{});var kt=o(U);$t=s(kt,"LI",{});var Kl=o($t);Xt=s(Kl,"STRONG",{});var wn=o(Xt);Zs=c(wn,"NO"),wn.forEach(r),eo=c(Kl," \u2014 using full precision (FP32)"),Kl.forEach(r),to=n(kt),yt=s(kt,"LI",{});var Ql=o(yt);Yt=s(Ql,"STRONG",{});var xn=o(Yt);ro=c(xn,"FP16"),xn.forEach(r),ao=c(Ql," \u2014 using half precision"),Ql.forEach(r),so=n(kt),Et=s(kt,"LI",{});var Xl=o(Et);Zt=s(Xl,"STRONG",{});var Tn=o(Zt);oo=c(Tn,"BF16"),Tn.forEach(r),lo=c(Xl," \u2014 using brain floating point precision"),Xl.forEach(r),kt.forEach(r),Ee.forEach(r),Xr=n(e),O=s(e,"H2",{class:!0});var Ia=o(O);ne=s(Ia,"A",{id:!0,class:!0,href:!0});var Dn=o(ne);er=s(Dn,"SPAN",{});var Pn=o(er);f(Ne.$$.fragment,Pn),Pn.forEach(r),Dn.forEach(r),no=n(Ia),tr=s(Ia,"SPAN",{});var kn=o(tr);io=c(kn,"Data Manipulation and Operations"),kn.forEach(r),Ia.forEach(r),Yr=n(e),ie=s(e,"P",{});var Ua=o(ie);co=c(Ua,"These include data operations that mimic the same "),rr=s(Ua,"CODE",{});var Nn=o(rr);po=c(Nn,"torch"),Nn.forEach(r),uo=c(Ua," ops but can be used on distributed processes."),Ua.forEach(r),Zr=n(e),S=s(e,"DIV",{class:!0});var Oa=o(S);f(Le.$$.fragment,Oa),mo=n(Oa),ar=s(Oa,"P",{});var Ln=o(ar);fo=c(Ln,"Recursively broadcast tensor in a nested list/tuple/dictionary of tensors to all devices."),Ln.forEach(r),Oa.forEach(r),ea=n(e),R=s(e,"DIV",{class:!0});var Sa=o(R);f(Ce.$$.fragment,Sa),ho=n(Sa),sr=s(Sa,"P",{});var Cn=o(sr);vo=c(Cn,"Recursively concatenate the tensors in a nested list/tuple/dictionary of lists of tensors with the same shape."),Cn.forEach(r),Sa.forEach(r),ta=n(e),z=s(e,"DIV",{class:!0});var Ra=o(z);f(Ae.$$.fragment,Ra),go=n(Ra),or=s(Ra,"P",{});var An=o(or);_o=c(An,"Recursively gather tensor in a nested list/tuple/dictionary of tensors from all devices."),An.forEach(r),Ra.forEach(r),ra=n(e),M=s(e,"DIV",{class:!0});var za=o(M);f(Ie.$$.fragment,za),bo=n(za),lr=s(za,"P",{});var In=o(lr);$o=c(In,`Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so they
can safely be gathered.`),In.forEach(r),za.forEach(r),aa=n(e),V=s(e,"DIV",{class:!0});var Ma=o(V);f(Ue.$$.fragment,Ma),yo=n(Ma),nr=s(Ma,"P",{});var Un=o(nr);Eo=c(Un,`Recursively reduce the tensors in a nested list/tuple/dictionary of lists of tensors across all processes by the
mean of a given operation.`),Un.forEach(r),Ma.forEach(r),sa=n(e),G=s(e,"DIV",{class:!0});var Va=o(G);f(Oe.$$.fragment,Va),wo=n(Va),ir=s(Va,"P",{});var On=o(ir);xo=c(On,"Recursively sends the elements in a nested list/tuple/dictionary of tensors to a given device."),On.forEach(r),Va.forEach(r),oa=n(e),H=s(e,"H2",{class:!0});var Ga=o(H);ce=s(Ga,"A",{id:!0,class:!0,href:!0});var Sn=o(ce);cr=s(Sn,"SPAN",{});var Rn=o(cr);f(Se.$$.fragment,Rn),Rn.forEach(r),Sn.forEach(r),To=n(Ga),dr=s(Ga,"SPAN",{});var zn=o(dr);Do=c(zn,"Environment Checks"),zn.forEach(r),Ga.forEach(r),la=n(e),wt=s(e,"P",{});var Mn=o(wt);Po=c(Mn,"These functionalities check the state of the current working environment including information about the operating system itself, what it can support, and if particular dependencies are installed."),Mn.forEach(r),na=n(e),q=s(e,"DIV",{class:!0});var Ha=o(q);f(Re.$$.fragment,Ha),ko=n(Ha),pr=s(Ha,"P",{});var Vn=o(pr);No=c(Vn,"Checks if bf16 is supported, optionally ignoring the TPU"),Vn.forEach(r),Ha.forEach(r),ia=n(e),F=s(e,"DIV",{class:!0});var qa=o(F);f(ze.$$.fragment,qa),Lo=n(qa),ur=s(qa,"P",{});var Gn=o(ur);Co=c(Gn,"Compares the current PyTorch version to a given reference with an operation."),Gn.forEach(r),qa.forEach(r),ca=n(e),B=s(e,"DIV",{class:!0});var Fa=o(B);f(Me.$$.fragment,Fa),Ao=n(Fa),Ve=s(Fa,"P",{});var Ba=o(Ve);Io=c(Ba,"Checks if "),mr=s(Ba,"CODE",{});var Hn=o(mr);Uo=c(Hn,"torch_xla"),Hn.forEach(r),Oo=c(Ba," is installed and potentially if a TPU is in the environment"),Ba.forEach(r),Fa.forEach(r),da=n(e),W=s(e,"H2",{class:!0});var Wa=o(W);de=s(Wa,"A",{id:!0,class:!0,href:!0});var qn=o(de);fr=s(qn,"SPAN",{});var Fn=o(fr);f(Ge.$$.fragment,Fn),Fn.forEach(r),qn.forEach(r),So=n(Wa),hr=s(Wa,"SPAN",{});var Bn=o(hr);Ro=c(Bn,"Environment Configuration"),Bn.forEach(r),Wa.forEach(r),pa=n(e),j=s(e,"DIV",{class:!0});var ja=o(j);f(He.$$.fragment,ja),zo=n(ja),vr=s(ja,"P",{});var Wn=o(vr);Mo=c(Wn,`Creates and saves a basic cluster config to be used on a local machine with potentially multiple GPUs. Will also
set CPU if it is a CPU-only machine.`),Wn.forEach(r),ja.forEach(r),ua=n(e),pe=s(e,"P",{});var Ja=o(pe);Vo=c(Ja,"When setting up \u{1F917} Accelerate for the first time, rather than running "),gr=s(Ja,"CODE",{});var jn=o(gr);Go=c(jn,"accelerate config"),jn.forEach(r),Ho=c(Ja," [~utils.write_basic_config] can be used as an alternative for quick configuration."),Ja.forEach(r),ma=n(e),J=s(e,"H2",{class:!0});var Ka=o(J);ue=s(Ka,"A",{id:!0,class:!0,href:!0});var Jn=o(ue);_r=s(Jn,"SPAN",{});var Kn=o(_r);f(qe.$$.fragment,Kn),Kn.forEach(r),Jn.forEach(r),qo=n(Ka),br=s(Ka,"SPAN",{});var Qn=o(br);Fo=c(Qn,"Memory"),Qn.forEach(r),Ka.forEach(r),fa=n(e),K=s(e,"DIV",{class:!0});var Qa=o(K);f(Fe.$$.fragment,Qa),Bo=n(Qa),$r=s(Qa,"P",{});var Xn=o($r);Wo=c(Xn,"Get the maximum memory available if nothing is passed, converts string to int otherwise."),Xn.forEach(r),Qa.forEach(r),ha=n(e),k=s(e,"DIV",{class:!0});var Nt=o(k);f(Be.$$.fragment,Nt),jo=n(Nt),me=s(Nt,"P",{});var Hr=o(me);Jo=c(Hr,"A basic decorator that will try to execute "),yr=s(Hr,"CODE",{});var Yn=o(yr);Ko=c(Yn,"function"),Yn.forEach(r),Qo=c(Hr,`. If it fails from exceptions related to out-of-memory or
CUDNN, the batch size is cut in half and passed to `),Er=s(Hr,"CODE",{});var Zn=o(Er);Xo=c(Zn,"function"),Zn.forEach(r),Hr.forEach(r),Yo=n(Nt),fe=s(Nt,"P",{});var qr=o(fe);wr=s(qr,"CODE",{});var ei=o(wr);Zo=c(ei,"function"),ei.forEach(r),el=c(qr," must take in a "),xr=s(qr,"CODE",{});var ti=o(xr);tl=c(ti,"batch_size"),ti.forEach(r),rl=c(qr," parameter as its first argument."),qr.forEach(r),Nt.forEach(r),va=n(e),Q=s(e,"H2",{class:!0});var Xa=o(Q);he=s(Xa,"A",{id:!0,class:!0,href:!0});var ri=o(he);Tr=s(ri,"SPAN",{});var ai=o(Tr);f(We.$$.fragment,ai),ai.forEach(r),ri.forEach(r),al=n(Xa),Dr=s(Xa,"SPAN",{});var si=o(Dr);sl=c(si,"Modeling"),si.forEach(r),Xa.forEach(r),ga=n(e),xt=s(e,"P",{});var oi=o(xt);ol=c(oi,"These utilities relate to interacting with PyTorch models"),oi.forEach(r),_a=n(e),X=s(e,"DIV",{class:!0});var Ya=o(X);f(je.$$.fragment,Ya),ll=n(Ya),Pr=s(Ya,"P",{});var li=o(Pr);nl=c(li,"Extract a model from its distributed containers."),li.forEach(r),Ya.forEach(r),ba=n(e),N=s(e,"DIV",{class:!0});var Lt=o(N);f(Je.$$.fragment,Lt),il=n(Lt),kr=s(Lt,"P",{});var ni=o(kr);cl=c(ni,`Utility function that will scan a list of named modules and return the maximum size used by one full layer. The
definition of a layer being:`),ni.forEach(r),dl=n(Lt),Ke=s(Lt,"UL",{});var Za=o(Ke);Nr=s(Za,"LI",{});var ii=o(Nr);pl=c(ii,"a module with no direct children (just parameters and buffers)"),ii.forEach(r),ul=n(Za),Tt=s(Za,"LI",{});var Yl=o(Tt);ml=c(Yl,"a module whose class name is in the list "),Lr=s(Yl,"CODE",{});var ci=o(Lr);fl=c(ci,"no_split_module_classes"),ci.forEach(r),Yl.forEach(r),Za.forEach(r),Lt.forEach(r),$a=n(e),Y=s(e,"DIV",{class:!0});var es=o(Y);f(Qe.$$.fragment,es),hl=n(es),Cr=s(es,"P",{});var di=o(Cr);vl=c(di,"Offload a state dict in a given folder."),di.forEach(r),es.forEach(r),ya=n(e),Z=s(e,"H2",{class:!0});var ts=o(Z);ve=s(ts,"A",{id:!0,class:!0,href:!0});var pi=o(ve);Ar=s(pi,"SPAN",{});var ui=o(Ar);f(Xe.$$.fragment,ui),ui.forEach(r),pi.forEach(r),gl=n(ts),Ir=s(ts,"SPAN",{});var mi=o(Ir);_l=c(mi,"Parallel"),mi.forEach(r),ts.forEach(r),Ea=n(e),Dt=s(e,"P",{});var fi=o(Dt);bl=c(fi,"These include general utilities that should be used when working in parallel."),fi.forEach(r),wa=n(e),ee=s(e,"DIV",{class:!0});var rs=o(ee);f(Ye.$$.fragment,rs),$l=n(rs),Ur=s(rs,"P",{});var hi=o(Ur);yl=c(hi,"Extract a model from its distributed containers."),hi.forEach(r),rs.forEach(r),xa=n(e),te=s(e,"DIV",{class:!0});var as=o(te);f(Ze.$$.fragment,as),El=n(as),et=s(as,"P",{});var ss=o(et);wl=c(ss,"Save the data to disk. Use in place of "),Or=s(ss,"CODE",{});var vi=o(Or);xl=c(vi,"torch.save()"),vi.forEach(r),Tl=c(ss,"."),ss.forEach(r),as.forEach(r),Ta=n(e),L=s(e,"DIV",{class:!0});var Ct=o(L);f(tt.$$.fragment,Ct),Dl=n(Ct),Sr=s(Ct,"P",{});var gi=o(Sr);Pl=c(gi,"Introduces a blocking point in the script, making sure all processes have reached this point before continuing."),gi.forEach(r),kl=n(Ct),f(ge.$$.fragment,Ct),Ct.forEach(r),Da=n(e),re=s(e,"H2",{class:!0});var os=o(re);_e=s(os,"A",{id:!0,class:!0,href:!0});var _i=o(_e);Rr=s(_i,"SPAN",{});var bi=o(Rr);f(rt.$$.fragment,bi),bi.forEach(r),_i.forEach(r),Nl=n(os),zr=s(os,"SPAN",{});var $i=o(zr);Ll=c($i,"Random"),$i.forEach(r),os.forEach(r),Pa=n(e),Pt=s(e,"P",{});var yi=o(Pt);Cl=c(yi,"These utilities relate to setting and synchronizing of all the random states."),yi.forEach(r),ka=n(e),ae=s(e,"DIV",{class:!0});var ls=o(ae);f(at.$$.fragment,ls),Al=n(ls),C=s(ls,"P",{});var we=o(C);Il=c(we,"Helper function for reproducible behavior to set the seed in "),Mr=s(we,"CODE",{});var Ei=o(Mr);Ul=c(Ei,"random"),Ei.forEach(r),Ol=c(we,", "),Vr=s(we,"CODE",{});var wi=o(Vr);Sl=c(wi,"numpy"),wi.forEach(r),Rl=c(we,", "),Gr=s(we,"CODE",{});var xi=o(Gr);zl=c(xi,"torch"),xi.forEach(r),Ml=c(we,"."),we.forEach(r),ls.forEach(r),Na=n(e),st=s(e,"DIV",{class:!0});var Ti=o(st);f(ot.$$.fragment,Ti),Ti.forEach(r),La=n(e),lt=s(e,"DIV",{class:!0});var Di=o(lt);f(nt.$$.fragment,Di),Di.forEach(r),this.h()},h(){u($,"name","hf:doc:metadata"),u($,"content",JSON.stringify(Oi)),u(E,"id","helpful-utilities"),u(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(E,"href","#helpful-utilities"),u(y,"class","relative group"),u(le,"id","accelerate.DistributedType"),u(le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(le,"href","#accelerate.DistributedType"),u(I,"class","relative group"),u(w,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(T,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(D,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(ne,"id","accelerate.utils.broadcast"),u(ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ne,"href","#accelerate.utils.broadcast"),u(O,"class","relative group"),u(S,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(R,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(V,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(G,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(ce,"id","accelerate.utils.is_bf16_available"),u(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ce,"href","#accelerate.utils.is_bf16_available"),u(H,"class","relative group"),u(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(B,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(de,"id","accelerate.utils.write_basic_config"),u(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(de,"href","#accelerate.utils.write_basic_config"),u(W,"class","relative group"),u(j,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(ue,"id","accelerate.utils.get_max_memory"),u(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ue,"href","#accelerate.utils.get_max_memory"),u(J,"class","relative group"),u(K,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(k,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(he,"id","accelerate.utils.extract_model_from_parallel"),u(he,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(he,"href","#accelerate.utils.extract_model_from_parallel"),u(Q,"class","relative group"),u(X,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(N,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(Y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(ve,"id","accelerate.utils.extract_model_from_parallel"),u(ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ve,"href","#accelerate.utils.extract_model_from_parallel"),u(Z,"class","relative group"),u(ee,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(te,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(L,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(_e,"id","accelerate.utils.set_seed"),u(_e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(_e,"href","#accelerate.utils.set_seed"),u(re,"class","relative group"),u(ae,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,d){t(document.head,$),p(e,oe,d),p(e,y,d),t(y,E),t(E,At),h(xe,At,null),t(y,ns),t(y,It),t(It,is),p(e,Br,d),p(e,ct,d),t(ct,cs),p(e,Wr,d),p(e,I,d),t(I,le),t(le,Ut),h(Te,Ut,null),t(I,ds),t(I,Ot),t(Ot,ps),p(e,jr,d),p(e,dt,d),t(dt,us),p(e,Jr,d),p(e,w,d),h(De,w,null),t(w,ms),t(w,St),t(St,fs),t(w,hs),t(w,Rt),t(Rt,vs),t(w,gs),t(w,x),t(x,pt),t(pt,zt),t(zt,_s),t(pt,bs),t(x,$s),t(x,ut),t(ut,Mt),t(Mt,ys),t(ut,Es),t(x,ws),t(x,mt),t(mt,Vt),t(Vt,xs),t(mt,Ts),t(x,Ds),t(x,ft),t(ft,Gt),t(Gt,Ps),t(ft,ks),t(x,Ns),t(x,ht),t(ht,Ht),t(Ht,Ls),t(ht,Cs),p(e,Kr,d),p(e,T,d),h(Pe,T,null),t(T,As),t(T,qt),t(qt,Is),t(T,Us),t(T,Ft),t(Ft,Os),t(T,Ss),t(T,P),t(P,vt),t(vt,Bt),t(Bt,Rs),t(vt,zs),t(P,Ms),t(P,gt),t(gt,Wt),t(Wt,Vs),t(gt,Gs),t(P,Hs),t(P,_t),t(_t,jt),t(jt,qs),t(_t,Fs),t(P,Bs),t(P,bt),t(bt,Jt),t(Jt,Ws),t(bt,js),p(e,Qr,d),p(e,D,d),h(ke,D,null),t(D,Js),t(D,Kt),t(Kt,Ks),t(D,Qs),t(D,Qt),t(Qt,Xs),t(D,Ys),t(D,U),t(U,$t),t($t,Xt),t(Xt,Zs),t($t,eo),t(U,to),t(U,yt),t(yt,Yt),t(Yt,ro),t(yt,ao),t(U,so),t(U,Et),t(Et,Zt),t(Zt,oo),t(Et,lo),p(e,Xr,d),p(e,O,d),t(O,ne),t(ne,er),h(Ne,er,null),t(O,no),t(O,tr),t(tr,io),p(e,Yr,d),p(e,ie,d),t(ie,co),t(ie,rr),t(rr,po),t(ie,uo),p(e,Zr,d),p(e,S,d),h(Le,S,null),t(S,mo),t(S,ar),t(ar,fo),p(e,ea,d),p(e,R,d),h(Ce,R,null),t(R,ho),t(R,sr),t(sr,vo),p(e,ta,d),p(e,z,d),h(Ae,z,null),t(z,go),t(z,or),t(or,_o),p(e,ra,d),p(e,M,d),h(Ie,M,null),t(M,bo),t(M,lr),t(lr,$o),p(e,aa,d),p(e,V,d),h(Ue,V,null),t(V,yo),t(V,nr),t(nr,Eo),p(e,sa,d),p(e,G,d),h(Oe,G,null),t(G,wo),t(G,ir),t(ir,xo),p(e,oa,d),p(e,H,d),t(H,ce),t(ce,cr),h(Se,cr,null),t(H,To),t(H,dr),t(dr,Do),p(e,la,d),p(e,wt,d),t(wt,Po),p(e,na,d),p(e,q,d),h(Re,q,null),t(q,ko),t(q,pr),t(pr,No),p(e,ia,d),p(e,F,d),h(ze,F,null),t(F,Lo),t(F,ur),t(ur,Co),p(e,ca,d),p(e,B,d),h(Me,B,null),t(B,Ao),t(B,Ve),t(Ve,Io),t(Ve,mr),t(mr,Uo),t(Ve,Oo),p(e,da,d),p(e,W,d),t(W,de),t(de,fr),h(Ge,fr,null),t(W,So),t(W,hr),t(hr,Ro),p(e,pa,d),p(e,j,d),h(He,j,null),t(j,zo),t(j,vr),t(vr,Mo),p(e,ua,d),p(e,pe,d),t(pe,Vo),t(pe,gr),t(gr,Go),t(pe,Ho),p(e,ma,d),p(e,J,d),t(J,ue),t(ue,_r),h(qe,_r,null),t(J,qo),t(J,br),t(br,Fo),p(e,fa,d),p(e,K,d),h(Fe,K,null),t(K,Bo),t(K,$r),t($r,Wo),p(e,ha,d),p(e,k,d),h(Be,k,null),t(k,jo),t(k,me),t(me,Jo),t(me,yr),t(yr,Ko),t(me,Qo),t(me,Er),t(Er,Xo),t(k,Yo),t(k,fe),t(fe,wr),t(wr,Zo),t(fe,el),t(fe,xr),t(xr,tl),t(fe,rl),p(e,va,d),p(e,Q,d),t(Q,he),t(he,Tr),h(We,Tr,null),t(Q,al),t(Q,Dr),t(Dr,sl),p(e,ga,d),p(e,xt,d),t(xt,ol),p(e,_a,d),p(e,X,d),h(je,X,null),t(X,ll),t(X,Pr),t(Pr,nl),p(e,ba,d),p(e,N,d),h(Je,N,null),t(N,il),t(N,kr),t(kr,cl),t(N,dl),t(N,Ke),t(Ke,Nr),t(Nr,pl),t(Ke,ul),t(Ke,Tt),t(Tt,ml),t(Tt,Lr),t(Lr,fl),p(e,$a,d),p(e,Y,d),h(Qe,Y,null),t(Y,hl),t(Y,Cr),t(Cr,vl),p(e,ya,d),p(e,Z,d),t(Z,ve),t(ve,Ar),h(Xe,Ar,null),t(Z,gl),t(Z,Ir),t(Ir,_l),p(e,Ea,d),p(e,Dt,d),t(Dt,bl),p(e,wa,d),p(e,ee,d),h(Ye,ee,null),t(ee,$l),t(ee,Ur),t(Ur,yl),p(e,xa,d),p(e,te,d),h(Ze,te,null),t(te,El),t(te,et),t(et,wl),t(et,Or),t(Or,xl),t(et,Tl),p(e,Ta,d),p(e,L,d),h(tt,L,null),t(L,Dl),t(L,Sr),t(Sr,Pl),t(L,kl),h(ge,L,null),p(e,Da,d),p(e,re,d),t(re,_e),t(_e,Rr),h(rt,Rr,null),t(re,Nl),t(re,zr),t(zr,Ll),p(e,Pa,d),p(e,Pt,d),t(Pt,Cl),p(e,ka,d),p(e,ae,d),h(at,ae,null),t(ae,Al),t(ae,C),t(C,Il),t(C,Mr),t(Mr,Ul),t(C,Ol),t(C,Vr),t(Vr,Sl),t(C,Rl),t(C,Gr),t(Gr,zl),t(C,Ml),p(e,Na,d),p(e,st,d),h(ot,st,null),p(e,La,d),p(e,lt,d),h(nt,lt,null),Ca=!0},p(e,[d]){const it={};d&2&&(it.$$scope={dirty:d,ctx:e}),ge.$set(it)},i(e){Ca||(v(xe.$$.fragment,e),v(Te.$$.fragment,e),v(De.$$.fragment,e),v(Pe.$$.fragment,e),v(ke.$$.fragment,e),v(Ne.$$.fragment,e),v(Le.$$.fragment,e),v(Ce.$$.fragment,e),v(Ae.$$.fragment,e),v(Ie.$$.fragment,e),v(Ue.$$.fragment,e),v(Oe.$$.fragment,e),v(Se.$$.fragment,e),v(Re.$$.fragment,e),v(ze.$$.fragment,e),v(Me.$$.fragment,e),v(Ge.$$.fragment,e),v(He.$$.fragment,e),v(qe.$$.fragment,e),v(Fe.$$.fragment,e),v(Be.$$.fragment,e),v(We.$$.fragment,e),v(je.$$.fragment,e),v(Je.$$.fragment,e),v(Qe.$$.fragment,e),v(Xe.$$.fragment,e),v(Ye.$$.fragment,e),v(Ze.$$.fragment,e),v(tt.$$.fragment,e),v(ge.$$.fragment,e),v(rt.$$.fragment,e),v(at.$$.fragment,e),v(ot.$$.fragment,e),v(nt.$$.fragment,e),Ca=!0)},o(e){g(xe.$$.fragment,e),g(Te.$$.fragment,e),g(De.$$.fragment,e),g(Pe.$$.fragment,e),g(ke.$$.fragment,e),g(Ne.$$.fragment,e),g(Le.$$.fragment,e),g(Ce.$$.fragment,e),g(Ae.$$.fragment,e),g(Ie.$$.fragment,e),g(Ue.$$.fragment,e),g(Oe.$$.fragment,e),g(Se.$$.fragment,e),g(Re.$$.fragment,e),g(ze.$$.fragment,e),g(Me.$$.fragment,e),g(Ge.$$.fragment,e),g(He.$$.fragment,e),g(qe.$$.fragment,e),g(Fe.$$.fragment,e),g(Be.$$.fragment,e),g(We.$$.fragment,e),g(je.$$.fragment,e),g(Je.$$.fragment,e),g(Qe.$$.fragment,e),g(Xe.$$.fragment,e),g(Ye.$$.fragment,e),g(Ze.$$.fragment,e),g(tt.$$.fragment,e),g(ge.$$.fragment,e),g(rt.$$.fragment,e),g(at.$$.fragment,e),g(ot.$$.fragment,e),g(nt.$$.fragment,e),Ca=!1},d(e){r($),e&&r(oe),e&&r(y),_(xe),e&&r(Br),e&&r(ct),e&&r(Wr),e&&r(I),_(Te),e&&r(jr),e&&r(dt),e&&r(Jr),e&&r(w),_(De),e&&r(Kr),e&&r(T),_(Pe),e&&r(Qr),e&&r(D),_(ke),e&&r(Xr),e&&r(O),_(Ne),e&&r(Yr),e&&r(ie),e&&r(Zr),e&&r(S),_(Le),e&&r(ea),e&&r(R),_(Ce),e&&r(ta),e&&r(z),_(Ae),e&&r(ra),e&&r(M),_(Ie),e&&r(aa),e&&r(V),_(Ue),e&&r(sa),e&&r(G),_(Oe),e&&r(oa),e&&r(H),_(Se),e&&r(la),e&&r(wt),e&&r(na),e&&r(q),_(Re),e&&r(ia),e&&r(F),_(ze),e&&r(ca),e&&r(B),_(Me),e&&r(da),e&&r(W),_(Ge),e&&r(pa),e&&r(j),_(He),e&&r(ua),e&&r(pe),e&&r(ma),e&&r(J),_(qe),e&&r(fa),e&&r(K),_(Fe),e&&r(ha),e&&r(k),_(Be),e&&r(va),e&&r(Q),_(We),e&&r(ga),e&&r(xt),e&&r(_a),e&&r(X),_(je),e&&r(ba),e&&r(N),_(Je),e&&r($a),e&&r(Y),_(Qe),e&&r(ya),e&&r(Z),_(Xe),e&&r(Ea),e&&r(Dt),e&&r(wa),e&&r(ee),_(Ye),e&&r(xa),e&&r(te),_(Ze),e&&r(Ta),e&&r(L),_(tt),_(ge),e&&r(Da),e&&r(re),_(rt),e&&r(Pa),e&&r(Pt),e&&r(ka),e&&r(ae),_(at),e&&r(Na),e&&r(st),_(ot),e&&r(La),e&&r(lt),_(nt)}}}const Oi={local:"helpful-utilities",sections:[{local:"accelerate.DistributedType",title:"Data Classes"},{local:"accelerate.utils.broadcast",title:"Data Manipulation and Operations"},{local:"accelerate.utils.is_bf16_available",title:"Environment Checks"},{local:"accelerate.utils.write_basic_config",title:"Environment Configuration"},{local:"accelerate.utils.get_max_memory",title:"Memory"},{local:"accelerate.utils.extract_model_from_parallel",title:"Modeling"},{local:"accelerate.utils.extract_model_from_parallel",title:"Parallel"},{local:"accelerate.utils.set_seed",title:"Random"}],title:"Helpful Utilities"};function Si(Fr){return Ci(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Gi extends Pi{constructor($){super();ki(this,$,Si,Ui,Ni,{})}}export{Gi as default,Oi as metadata};
