import{S as Pi,i as ki,s as Ni,e as a,k as l,w as m,t as i,M as Li,c as o,d as r,m as n,a as s,x as f,h as c,b as u,G as t,g as p,y as h,q as v,o as g,B as _,v as Ci}from"../../chunks/vendor-hf-doc-builder.js";import{T as Ai}from"../../chunks/Tip-hf-doc-builder.js";import{D as b}from"../../chunks/Docstring-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";function Ii(Fr){let $,se;return{c(){$=a("p"),se=i("Make sure all processes will reach this instruction otherwise one of your processes will hang forever.")},l(y){$=o(y,"P",{});var E=s($);se=c(E,"Make sure all processes will reach this instruction otherwise one of your processes will hang forever."),E.forEach(r)},m(y,E){p(y,$,E),t($,se)},d(y){y&&r($)}}}function Ui(Fr){let $,se,y,E,At,xe,no,It,io,Br,ct,co,Wr,I,le,Ut,Te,po,Ot,uo,jr,dt,mo,Jr,w,De,fo,St,ho,vo,Rt,go,_o,x,pt,zt,bo,$o,yo,ut,Mt,Eo,wo,xo,mt,Vt,To,Do,Po,ft,Gt,ko,No,Lo,ht,Ht,Co,Ao,Kr,T,Pe,Io,qt,Uo,Oo,Ft,So,Ro,P,vt,Bt,zo,Mo,Vo,gt,Wt,Go,Ho,qo,_t,jt,Fo,Bo,Wo,bt,Jt,jo,Jo,Qr,D,ke,Ko,Kt,Qo,Xo,Qt,Yo,Zo,U,$t,Xt,es,ts,rs,yt,Yt,as,os,ss,Et,Zt,ls,ns,Xr,O,ne,er,Ne,is,tr,cs,Yr,ie,ds,rr,ps,us,Zr,S,Le,ms,ar,fs,ea,R,Ce,hs,or,vs,ta,z,Ae,gs,sr,_s,ra,M,Ie,bs,lr,$s,aa,V,Ue,ys,nr,Es,oa,G,Oe,ws,ir,xs,sa,H,ce,cr,Se,Ts,dr,Ds,la,wt,Ps,na,q,Re,ks,pr,Ns,ia,F,ze,Ls,ur,Cs,ca,B,Me,As,Ve,Is,mr,Us,Os,da,W,de,fr,Ge,Ss,hr,Rs,pa,j,He,zs,vr,Ms,ua,pe,Vs,gr,Gs,Hs,ma,J,ue,_r,qe,qs,br,Fs,fa,K,Fe,Bs,$r,Ws,ha,k,Be,js,me,Js,yr,Ks,Qs,Er,Xs,Ys,fe,wr,Zs,el,xr,tl,rl,va,Q,he,Tr,We,al,Dr,ol,ga,xt,sl,_a,X,je,ll,Pr,nl,ba,N,Je,il,kr,cl,dl,Ke,Nr,pl,ul,Tt,ml,Lr,fl,$a,Y,Qe,hl,Cr,vl,ya,Z,ve,Ar,Xe,gl,Ir,_l,Ea,Dt,bl,wa,ee,Ye,$l,Ur,yl,xa,te,Ze,El,et,wl,Or,xl,Tl,Ta,L,tt,Dl,Sr,Pl,kl,ge,Da,re,_e,Rr,rt,Nl,zr,Ll,Pa,Pt,Cl,ka,ae,at,Al,C,Il,Mr,Ul,Ol,Vr,Sl,Rl,Gr,zl,Ml,Na,ot,st,La,lt,nt,Ca;return xe=new oe({}),Te=new oe({}),De=new b({props:{name:"class accelerate.DistributedType",anchor:"accelerate.DistributedType",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/dataclasses.py#L109"}}),Pe=new b({props:{name:"class accelerate.utils.LoggerType",anchor:"accelerate.utils.LoggerType",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/dataclasses.py#L187"}}),ke=new b({props:{name:"class accelerate.utils.PrecisionType",anchor:"accelerate.utils.PrecisionType",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/dataclasses.py#L205"}}),Ne=new oe({}),Le=new b({props:{name:"accelerate.utils.broadcast",anchor:"accelerate.utils.broadcast",parameters:[{name:"tensor",val:""},{name:"from_process",val:": int = 0"}],parametersDescription:[{anchor:"accelerate.utils.broadcast.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to gather.`,name:"tensor"},{anchor:"accelerate.utils.broadcast.from_process",description:`<strong>from_process</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The process from which to send the data`,name:"from_process"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/operations.py#L288",returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors broadcasted to the proper device.</p>
`}}),Ce=new b({props:{name:"accelerate.utils.concatenate",anchor:"accelerate.utils.concatenate",parameters:[{name:"data",val:""},{name:"dim",val:" = 0"}],parametersDescription:[{anchor:"accelerate.utils.concatenate.data",description:`<strong>data</strong> (nested list/tuple/dictionary of lists of tensors <code>torch.Tensor</code>) &#x2014;
The data to concatenate.`,name:"data"},{anchor:"accelerate.utils.concatenate.dim",description:`<strong>dim</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The dimension on which to concatenate.`,name:"dim"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/operations.py#L362",returnDescription:`
<p>The same data structure as <code>data</code> with all the tensors concatenated.</p>
`}}),Ae=new b({props:{name:"accelerate.utils.gather",anchor:"accelerate.utils.gather",parameters:[{name:"tensor",val:""}],parametersDescription:[{anchor:"accelerate.utils.gather.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to gather.`,name:"tensor"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/operations.py#L210",returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors sent to the proper device.</p>
`}}),Ie=new b({props:{name:"accelerate.utils.pad_across_processes",anchor:"accelerate.utils.pad_across_processes",parameters:[{name:"tensor",val:""},{name:"dim",val:" = 0"},{name:"pad_index",val:" = 0"},{name:"pad_first",val:" = False"}],parametersDescription:[{anchor:"accelerate.utils.pad_across_processes.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to gather.`,name:"tensor"},{anchor:"accelerate.utils.pad_across_processes.dim",description:`<strong>dim</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The dimension on which to pad.`,name:"dim"},{anchor:"accelerate.utils.pad_across_processes.pad_index",description:`<strong>pad_index</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The value with which to pad.`,name:"pad_index"},{anchor:"accelerate.utils.pad_across_processes.pad_first",description:`<strong>pad_first</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to pad at the beginning or the end.`,name:"pad_first"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/operations.py#L384"}}),Ue=new b({props:{name:"accelerate.utils.reduce",anchor:"accelerate.utils.reduce",parameters:[{name:"tensor",val:""},{name:"reduction",val:" = 'mean'"}],parametersDescription:[{anchor:"accelerate.utils.reduce.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to reduce.`,name:"tensor"},{anchor:"accelerate.utils.reduce.reduction",description:`<strong>reduction</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;mean&quot;</code>) &#x2014;
A reduction method. Can be of &#x201C;mean&#x201D;, &#x201C;sum&#x201D;, or &#x201C;none&#x201D;`,name:"reduction"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/operations.py#L430",returnDescription:`
<p>The same data structure as <code>data</code> with all the tensors reduced.</p>
`}}),Oe=new b({props:{name:"accelerate.utils.send_to_device",anchor:"accelerate.utils.send_to_device",parameters:[{name:"tensor",val:""},{name:"device",val:""},{name:"non_blocking",val:" = False"}],parametersDescription:[{anchor:"accelerate.utils.send_to_device.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to send to a given device.`,name:"tensor"},{anchor:"accelerate.utils.send_to_device.device",description:`<strong>device</strong> (<code>torch.device</code>) &#x2014;
The device to send the data to.`,name:"device"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/operations.py#L106",returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors sent to the proper device.</p>
`}}),Se=new oe({}),Re=new b({props:{name:"accelerate.utils.is_bf16_available",anchor:"accelerate.utils.is_bf16_available",parameters:[{name:"ignore_tpu",val:" = False"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/imports.py#L79"}}),ze=new b({props:{name:"accelerate.utils.is_torch_version",anchor:"accelerate.utils.is_torch_version",parameters:[{name:"operation",val:": str"},{name:"version",val:": str"}],parametersDescription:[{anchor:"accelerate.utils.is_torch_version.operation",description:`<strong>operation</strong> (<code>str</code>) &#x2014;
A string representation of an operator, such as <code>&quot;&gt;&quot;</code> or <code>&quot;&lt;=&quot;</code>`,name:"operation"},{anchor:"accelerate.utils.is_torch_version.version",description:`<strong>version</strong> (<code>str</code>) &#x2014;
A string version of PyTorch`,name:"version"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/versions.py#L51"}}),Me=new b({props:{name:"accelerate.utils.is_tpu_available",anchor:"accelerate.utils.is_tpu_available",parameters:[{name:"check_device",val:" = True"}]}}),Ge=new oe({}),He=new b({props:{name:"accelerate.utils.write_basic_config",anchor:"accelerate.utils.write_basic_config",parameters:[{name:"mixed_precision",val:" = 'no'"},{name:"save_location",val:": str = '/github/home/.cache/huggingface/accelerate/default_config.yaml'"}],parametersDescription:[{anchor:"accelerate.utils.write_basic_config.mixed_precision",description:`<strong>mixed_precision</strong> (<code>str</code>, <em>optional</em>, defaults to &#x201C;no&#x201D;) &#x2014;
Mixed Precision to use. Should be one of &#x201C;no&#x201D;, &#x201C;fp16&#x201D;, or &#x201C;bf16&#x201D;`,name:"mixed_precision"},{anchor:"accelerate.utils.write_basic_config.save_location",description:`<strong>save_location</strong> (<code>str</code>, <em>optional</em>, defaults to <code>default_json_config_file</code>) &#x2014;
Optional custom save location. Should be passed to <code>--config_file</code> when using <code>accelerate launch</code>. Default
location is inside the huggingface cache folder (<code>~/.cache/huggingface</code>) but can be overriden by setting
the <code>HF_HOME</code> environmental variable, followed by <code>accelerate/default_config.yaml</code>.`,name:"save_location"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/other.py#L118"}}),qe=new oe({}),Fe=new b({props:{name:"accelerate.utils.get_max_memory",anchor:"accelerate.utils.get_max_memory",parameters:[{name:"max_memory",val:": typing.Union[typing.Dict[typing.Union[int, str], typing.Union[int, str]], NoneType] = None"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/modeling.py#L275"}}),Be=new b({props:{name:"accelerate.find_executable_batch_size",anchor:"accelerate.find_executable_batch_size",parameters:[{name:"function",val:": callable = None"},{name:"starting_batch_size",val:": int = 128"}],parametersDescription:[{anchor:"accelerate.find_executable_batch_size.function",description:`<strong>function</strong> (<code>callable</code>, <em>optional</em>) &#x2014;
A function to wrap`,name:"function"},{anchor:"accelerate.find_executable_batch_size.starting_batch_size",description:`<strong>starting_batch_size</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The batch size to try and fit into memory`,name:"starting_batch_size"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/memory.py#L45"}}),We=new oe({}),je=new b({props:{name:"accelerate.utils.extract_model_from_parallel",anchor:"accelerate.utils.extract_model_from_parallel",parameters:[{name:"model",val:""}],parametersDescription:[{anchor:"accelerate.utils.extract_model_from_parallel.model",description:"<strong>model</strong> (<code>torch.nn.Module</code>) &#x2014; The model to extract.",name:"model"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/other.py#L35",returnDescription:`
<p>The extracted model.</p>
`,returnType:`
<p><code>torch.nn.Module</code></p>
`}}),Je=new b({props:{name:"accelerate.utils.get_max_layer_size",anchor:"accelerate.utils.get_max_layer_size",parameters:[{name:"modules",val:": typing.List[typing.Tuple[str, torch.nn.modules.module.Module]]"},{name:"module_sizes",val:": typing.Dict[str, int]"},{name:"no_split_module_classes",val:": typing.List[str]"}],parametersDescription:[{anchor:"accelerate.utils.get_max_layer_size.modules",description:`<strong>modules</strong> (<code>List[Tuple[str, torch.nn.Module]]</code>) &#x2014;
The list of named modules where we want to determine the maximum layer size.`,name:"modules"},{anchor:"accelerate.utils.get_max_layer_size.module_sizes",description:`<strong>module_sizes</strong> (<code>Dict[str, int]</code>) &#x2014;
A dictionary mapping each layer name to its size (as generated by <code>compute_module_sizes</code>).`,name:"module_sizes"},{anchor:"accelerate.utils.get_max_layer_size.no_split_module_classes",description:`<strong>no_split_module_classes</strong> (<code>List[str]</code>) &#x2014;
A list of class names for layers we don&#x2019;t want to be split.`,name:"no_split_module_classes"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/modeling.py#L236",returnDescription:`
<p>The maximum size of a layer with the list of layer names realizing that maximum size.</p>
`,returnType:`
<p><code>Tuple[int, List[str]]</code></p>
`}}),Qe=new b({props:{name:"accelerate.utils.offload_state_dict",anchor:"accelerate.utils.offload_state_dict",parameters:[{name:"save_dir",val:": typing.Union[str, os.PathLike]"},{name:"state_dict",val:": typing.Dict[str, torch.Tensor]"}],parametersDescription:[{anchor:"accelerate.utils.offload_state_dict.save_dir",description:"<strong>save_dir</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014; The directory in which to offload the state dict.",name:"save_dir"},{anchor:"accelerate.utils.offload_state_dict.state_dict",description:"<strong>state_dict</strong> (<code>Dict[str, torch.Tensor]</code>) &#x2014; The dictionary of tensors to offload.",name:"state_dict"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/offload.py#L84"}}),Xe=new oe({}),Ye=new b({props:{name:"accelerate.utils.extract_model_from_parallel",anchor:"accelerate.utils.extract_model_from_parallel",parameters:[{name:"model",val:""}],parametersDescription:[{anchor:"accelerate.utils.extract_model_from_parallel.model",description:"<strong>model</strong> (<code>torch.nn.Module</code>) &#x2014; The model to extract.",name:"model"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/other.py#L35",returnDescription:`
<p>The extracted model.</p>
`,returnType:`
<p><code>torch.nn.Module</code></p>
`}}),Ze=new b({props:{name:"accelerate.utils.save",anchor:"accelerate.utils.save",parameters:[{name:"obj",val:""},{name:"f",val:""}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/other.py#L75"}}),tt=new b({props:{name:"accelerate.utils.wait_for_everyone",anchor:"accelerate.utils.wait_for_everyone",parameters:[],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/other.py#L54"}}),ge=new Ai({props:{warning:!0,$$slots:{default:[Ii]},$$scope:{ctx:Fr}}}),rt=new oe({}),at=new b({props:{name:"accelerate.utils.set_seed",anchor:"accelerate.utils.set_seed",parameters:[{name:"seed",val:": int"},{name:"device_specific",val:": bool = False"}],parametersDescription:[{anchor:"accelerate.utils.set_seed.seed",description:"<strong>seed</strong> (<code>int</code>) &#x2014; The seed to set.",name:"seed"},{anchor:"accelerate.utils.set_seed.device_specific",description:`<strong>device_specific</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to differ the seed on each device slightly with <code>self.process_index</code>.`,name:"device_specific"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/random.py#L30"}}),st=new b({props:{name:"accelerate.utils.synchronize_rng_state",anchor:"accelerate.utils.synchronize_rng_state",parameters:[{name:"rng_type",val:": typing.Optional[accelerate.utils.dataclasses.RNGType] = None"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/random.py#L50"}}),nt=new b({props:{name:"accelerate.synchronize_rng_states",anchor:"accelerate.synchronize_rng_states",parameters:[{name:"rng_types",val:": typing.List[typing.Union[str, accelerate.utils.dataclasses.RNGType]]"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/random.py#L85"}}),{c(){$=a("meta"),se=l(),y=a("h1"),E=a("a"),At=a("span"),m(xe.$$.fragment),no=l(),It=a("span"),io=i("Helpful Utilities"),Br=l(),ct=a("p"),co=i("Below are a variety of utility functions that \u{1F917} Accelerate provides, broken down by use-case."),Wr=l(),I=a("h2"),le=a("a"),Ut=a("span"),m(Te.$$.fragment),po=l(),Ot=a("span"),uo=i("Data Classes"),jr=l(),dt=a("p"),mo=i("These are basic dataclasses used throughout \u{1F917} Accelerate and they can be passed in as parameters."),Jr=l(),w=a("div"),m(De.$$.fragment),fo=l(),St=a("p"),ho=i("Represents a type of distributed environment."),vo=l(),Rt=a("p"),go=i("Values:"),_o=l(),x=a("ul"),pt=a("li"),zt=a("strong"),bo=i("NO"),$o=i(" \u2014 Not a distributed environment, just a single process."),yo=l(),ut=a("li"),Mt=a("strong"),Eo=i("MULTI_CPU"),wo=i(" \u2014 Distributed on multiple CPU nodes."),xo=l(),mt=a("li"),Vt=a("strong"),To=i("MULTI_GPU"),Do=i(" \u2014 Distributed on multiple GPUs."),Po=l(),ft=a("li"),Gt=a("strong"),ko=i("DEEPSPEED"),No=i(" \u2014 Using DeepSpeed."),Lo=l(),ht=a("li"),Ht=a("strong"),Co=i("TPU"),Ao=i(" \u2014 Distributed on TPUs."),Kr=l(),T=a("div"),m(Pe.$$.fragment),Io=l(),qt=a("p"),Uo=i("Represents a type of supported experiment tracker"),Oo=l(),Ft=a("p"),So=i("Values:"),Ro=l(),P=a("ul"),vt=a("li"),Bt=a("strong"),zo=i("ALL"),Mo=i(" \u2014 all available trackers in the environment that are supported"),Vo=l(),gt=a("li"),Wt=a("strong"),Go=i("TENSORBOARD"),Ho=i(" \u2014 TensorBoard as an experiment tracker"),qo=l(),_t=a("li"),jt=a("strong"),Fo=i("WANDB"),Bo=i(" \u2014 wandb as an experiment tracker"),Wo=l(),bt=a("li"),Jt=a("strong"),jo=i("COMETML"),Jo=i(" \u2014 comet_ml as an experiment tracker"),Qr=l(),D=a("div"),m(ke.$$.fragment),Ko=l(),Kt=a("p"),Qo=i("Represents a type of precision used on floating point values"),Xo=l(),Qt=a("p"),Yo=i("Values:"),Zo=l(),U=a("ul"),$t=a("li"),Xt=a("strong"),es=i("NO"),ts=i(" \u2014 using full precision (FP32)"),rs=l(),yt=a("li"),Yt=a("strong"),as=i("FP16"),os=i(" \u2014 using half precision"),ss=l(),Et=a("li"),Zt=a("strong"),ls=i("BF16"),ns=i(" \u2014 using brain floating point precision"),Xr=l(),O=a("h2"),ne=a("a"),er=a("span"),m(Ne.$$.fragment),is=l(),tr=a("span"),cs=i("Data Manipulation and Operations"),Yr=l(),ie=a("p"),ds=i("These include data operations that mimic the same "),rr=a("code"),ps=i("torch"),us=i(" ops but can be used on distributed processes."),Zr=l(),S=a("div"),m(Le.$$.fragment),ms=l(),ar=a("p"),fs=i("Recursively broadcast tensor in a nested list/tuple/dictionary of tensors to all devices."),ea=l(),R=a("div"),m(Ce.$$.fragment),hs=l(),or=a("p"),vs=i("Recursively concatenate the tensors in a nested list/tuple/dictionary of lists of tensors with the same shape."),ta=l(),z=a("div"),m(Ae.$$.fragment),gs=l(),sr=a("p"),_s=i("Recursively gather tensor in a nested list/tuple/dictionary of tensors from all devices."),ra=l(),M=a("div"),m(Ie.$$.fragment),bs=l(),lr=a("p"),$s=i(`Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so they
can safely be gathered.`),aa=l(),V=a("div"),m(Ue.$$.fragment),ys=l(),nr=a("p"),Es=i(`Recursively reduce the tensors in a nested list/tuple/dictionary of lists of tensors across all processes by the
mean of a given operation.`),oa=l(),G=a("div"),m(Oe.$$.fragment),ws=l(),ir=a("p"),xs=i("Recursively sends the elements in a nested list/tuple/dictionary of tensors to a given device."),sa=l(),H=a("h2"),ce=a("a"),cr=a("span"),m(Se.$$.fragment),Ts=l(),dr=a("span"),Ds=i("Environment Checks"),la=l(),wt=a("p"),Ps=i("These functionalities check the state of the current working environment including information about the operating system itself, what it can support, and if particular dependencies are installed."),na=l(),q=a("div"),m(Re.$$.fragment),ks=l(),pr=a("p"),Ns=i("Checks if bf16 is supported, optionally ignoring the TPU"),ia=l(),F=a("div"),m(ze.$$.fragment),Ls=l(),ur=a("p"),Cs=i("Compares the current PyTorch version to a given reference with an operation."),ca=l(),B=a("div"),m(Me.$$.fragment),As=l(),Ve=a("p"),Is=i("Checks if "),mr=a("code"),Us=i("torch_xla"),Os=i(" is installed and potentially if a TPU is in the environment"),da=l(),W=a("h2"),de=a("a"),fr=a("span"),m(Ge.$$.fragment),Ss=l(),hr=a("span"),Rs=i("Environment Configuration"),pa=l(),j=a("div"),m(He.$$.fragment),zs=l(),vr=a("p"),Ms=i(`Creates and saves a basic cluster config to be used on a local machine with potentially multiple GPUs. Will also
set CPU if it is a CPU-only machine.`),ua=l(),pe=a("p"),Vs=i("When setting up \u{1F917} Accelerate for the first time, rather than running "),gr=a("code"),Gs=i("accelerate config"),Hs=i(" [~utils.write_basic_config] can be used as an alternative for quick configuration."),ma=l(),J=a("h2"),ue=a("a"),_r=a("span"),m(qe.$$.fragment),qs=l(),br=a("span"),Fs=i("Memory"),fa=l(),K=a("div"),m(Fe.$$.fragment),Bs=l(),$r=a("p"),Ws=i("Get the maximum memory available if nothing is passed, converts string to int otherwise."),ha=l(),k=a("div"),m(Be.$$.fragment),js=l(),me=a("p"),Js=i("A basic decorator that will try to execute "),yr=a("code"),Ks=i("function"),Qs=i(`. If it fails from exceptions related to out-of-memory or
CUDNN, the batch size is cut in half and passed to `),Er=a("code"),Xs=i("function"),Ys=l(),fe=a("p"),wr=a("code"),Zs=i("function"),el=i(" must take in a "),xr=a("code"),tl=i("batch_size"),rl=i(" parameter as its first argument."),va=l(),Q=a("h2"),he=a("a"),Tr=a("span"),m(We.$$.fragment),al=l(),Dr=a("span"),ol=i("Modeling"),ga=l(),xt=a("p"),sl=i("These utilities relate to interacting with PyTorch models"),_a=l(),X=a("div"),m(je.$$.fragment),ll=l(),Pr=a("p"),nl=i("Extract a model from its distributed containers."),ba=l(),N=a("div"),m(Je.$$.fragment),il=l(),kr=a("p"),cl=i(`Utility function that will scan a list of named modules and return the maximum size used by one full layer. The
definition of a layer being:`),dl=l(),Ke=a("ul"),Nr=a("li"),pl=i("a module with no direct children (just parameters and buffers)"),ul=l(),Tt=a("li"),ml=i("a module whose class name is in the list "),Lr=a("code"),fl=i("no_split_module_classes"),$a=l(),Y=a("div"),m(Qe.$$.fragment),hl=l(),Cr=a("p"),vl=i("Offload a state dict in a given folder."),ya=l(),Z=a("h2"),ve=a("a"),Ar=a("span"),m(Xe.$$.fragment),gl=l(),Ir=a("span"),_l=i("Parallel"),Ea=l(),Dt=a("p"),bl=i("These include general utilities that should be used when working in parallel."),wa=l(),ee=a("div"),m(Ye.$$.fragment),$l=l(),Ur=a("p"),yl=i("Extract a model from its distributed containers."),xa=l(),te=a("div"),m(Ze.$$.fragment),El=l(),et=a("p"),wl=i("Save the data to disk. Use in place of "),Or=a("code"),xl=i("torch.save()"),Tl=i("."),Ta=l(),L=a("div"),m(tt.$$.fragment),Dl=l(),Sr=a("p"),Pl=i("Introduces a blocking point in the script, making sure all processes have reached this point before continuing."),kl=l(),m(ge.$$.fragment),Da=l(),re=a("h2"),_e=a("a"),Rr=a("span"),m(rt.$$.fragment),Nl=l(),zr=a("span"),Ll=i("Random"),Pa=l(),Pt=a("p"),Cl=i("These utilities relate to setting and synchronizing of all the random states."),ka=l(),ae=a("div"),m(at.$$.fragment),Al=l(),C=a("p"),Il=i("Helper function for reproducible behavior to set the seed in "),Mr=a("code"),Ul=i("random"),Ol=i(", "),Vr=a("code"),Sl=i("numpy"),Rl=i(", "),Gr=a("code"),zl=i("torch"),Ml=i("."),Na=l(),ot=a("div"),m(st.$$.fragment),La=l(),lt=a("div"),m(nt.$$.fragment),this.h()},l(e){const d=Li('[data-svelte="svelte-1phssyn"]',document.head);$=o(d,"META",{name:!0,content:!0}),d.forEach(r),se=n(e),y=o(e,"H1",{class:!0});var it=s(y);E=o(it,"A",{id:!0,class:!0,href:!0});var Zl=s(E);At=o(Zl,"SPAN",{});var en=s(At);f(xe.$$.fragment,en),en.forEach(r),Zl.forEach(r),no=n(it),It=o(it,"SPAN",{});var tn=s(It);io=c(tn,"Helpful Utilities"),tn.forEach(r),it.forEach(r),Br=n(e),ct=o(e,"P",{});var rn=s(ct);co=c(rn,"Below are a variety of utility functions that \u{1F917} Accelerate provides, broken down by use-case."),rn.forEach(r),Wr=n(e),I=o(e,"H2",{class:!0});var Aa=s(I);le=o(Aa,"A",{id:!0,class:!0,href:!0});var an=s(le);Ut=o(an,"SPAN",{});var on=s(Ut);f(Te.$$.fragment,on),on.forEach(r),an.forEach(r),po=n(Aa),Ot=o(Aa,"SPAN",{});var sn=s(Ot);uo=c(sn,"Data Classes"),sn.forEach(r),Aa.forEach(r),jr=n(e),dt=o(e,"P",{});var ln=s(dt);mo=c(ln,"These are basic dataclasses used throughout \u{1F917} Accelerate and they can be passed in as parameters."),ln.forEach(r),Jr=n(e),w=o(e,"DIV",{class:!0});var be=s(w);f(De.$$.fragment,be),fo=n(be),St=o(be,"P",{});var nn=s(St);ho=c(nn,"Represents a type of distributed environment."),nn.forEach(r),vo=n(be),Rt=o(be,"P",{});var cn=s(Rt);go=c(cn,"Values:"),cn.forEach(r),_o=n(be),x=o(be,"UL",{});var A=s(x);pt=o(A,"LI",{});var Vl=s(pt);zt=o(Vl,"STRONG",{});var dn=s(zt);bo=c(dn,"NO"),dn.forEach(r),$o=c(Vl," \u2014 Not a distributed environment, just a single process."),Vl.forEach(r),yo=n(A),ut=o(A,"LI",{});var Gl=s(ut);Mt=o(Gl,"STRONG",{});var pn=s(Mt);Eo=c(pn,"MULTI_CPU"),pn.forEach(r),wo=c(Gl," \u2014 Distributed on multiple CPU nodes."),Gl.forEach(r),xo=n(A),mt=o(A,"LI",{});var Hl=s(mt);Vt=o(Hl,"STRONG",{});var un=s(Vt);To=c(un,"MULTI_GPU"),un.forEach(r),Do=c(Hl," \u2014 Distributed on multiple GPUs."),Hl.forEach(r),Po=n(A),ft=o(A,"LI",{});var ql=s(ft);Gt=o(ql,"STRONG",{});var mn=s(Gt);ko=c(mn,"DEEPSPEED"),mn.forEach(r),No=c(ql," \u2014 Using DeepSpeed."),ql.forEach(r),Lo=n(A),ht=o(A,"LI",{});var Fl=s(ht);Ht=o(Fl,"STRONG",{});var fn=s(Ht);Co=c(fn,"TPU"),fn.forEach(r),Ao=c(Fl," \u2014 Distributed on TPUs."),Fl.forEach(r),A.forEach(r),be.forEach(r),Kr=n(e),T=o(e,"DIV",{class:!0});var $e=s(T);f(Pe.$$.fragment,$e),Io=n($e),qt=o($e,"P",{});var hn=s(qt);Uo=c(hn,"Represents a type of supported experiment tracker"),hn.forEach(r),Oo=n($e),Ft=o($e,"P",{});var vn=s(Ft);So=c(vn,"Values:"),vn.forEach(r),Ro=n($e),P=o($e,"UL",{});var ye=s(P);vt=o(ye,"LI",{});var Bl=s(vt);Bt=o(Bl,"STRONG",{});var gn=s(Bt);zo=c(gn,"ALL"),gn.forEach(r),Mo=c(Bl," \u2014 all available trackers in the environment that are supported"),Bl.forEach(r),Vo=n(ye),gt=o(ye,"LI",{});var Wl=s(gt);Wt=o(Wl,"STRONG",{});var _n=s(Wt);Go=c(_n,"TENSORBOARD"),_n.forEach(r),Ho=c(Wl," \u2014 TensorBoard as an experiment tracker"),Wl.forEach(r),qo=n(ye),_t=o(ye,"LI",{});var jl=s(_t);jt=o(jl,"STRONG",{});var bn=s(jt);Fo=c(bn,"WANDB"),bn.forEach(r),Bo=c(jl," \u2014 wandb as an experiment tracker"),jl.forEach(r),Wo=n(ye),bt=o(ye,"LI",{});var Jl=s(bt);Jt=o(Jl,"STRONG",{});var $n=s(Jt);jo=c($n,"COMETML"),$n.forEach(r),Jo=c(Jl," \u2014 comet_ml as an experiment tracker"),Jl.forEach(r),ye.forEach(r),$e.forEach(r),Qr=n(e),D=o(e,"DIV",{class:!0});var Ee=s(D);f(ke.$$.fragment,Ee),Ko=n(Ee),Kt=o(Ee,"P",{});var yn=s(Kt);Qo=c(yn,"Represents a type of precision used on floating point values"),yn.forEach(r),Xo=n(Ee),Qt=o(Ee,"P",{});var En=s(Qt);Yo=c(En,"Values:"),En.forEach(r),Zo=n(Ee),U=o(Ee,"UL",{});var kt=s(U);$t=o(kt,"LI",{});var Kl=s($t);Xt=o(Kl,"STRONG",{});var wn=s(Xt);es=c(wn,"NO"),wn.forEach(r),ts=c(Kl," \u2014 using full precision (FP32)"),Kl.forEach(r),rs=n(kt),yt=o(kt,"LI",{});var Ql=s(yt);Yt=o(Ql,"STRONG",{});var xn=s(Yt);as=c(xn,"FP16"),xn.forEach(r),os=c(Ql," \u2014 using half precision"),Ql.forEach(r),ss=n(kt),Et=o(kt,"LI",{});var Xl=s(Et);Zt=o(Xl,"STRONG",{});var Tn=s(Zt);ls=c(Tn,"BF16"),Tn.forEach(r),ns=c(Xl," \u2014 using brain floating point precision"),Xl.forEach(r),kt.forEach(r),Ee.forEach(r),Xr=n(e),O=o(e,"H2",{class:!0});var Ia=s(O);ne=o(Ia,"A",{id:!0,class:!0,href:!0});var Dn=s(ne);er=o(Dn,"SPAN",{});var Pn=s(er);f(Ne.$$.fragment,Pn),Pn.forEach(r),Dn.forEach(r),is=n(Ia),tr=o(Ia,"SPAN",{});var kn=s(tr);cs=c(kn,"Data Manipulation and Operations"),kn.forEach(r),Ia.forEach(r),Yr=n(e),ie=o(e,"P",{});var Ua=s(ie);ds=c(Ua,"These include data operations that mimic the same "),rr=o(Ua,"CODE",{});var Nn=s(rr);ps=c(Nn,"torch"),Nn.forEach(r),us=c(Ua," ops but can be used on distributed processes."),Ua.forEach(r),Zr=n(e),S=o(e,"DIV",{class:!0});var Oa=s(S);f(Le.$$.fragment,Oa),ms=n(Oa),ar=o(Oa,"P",{});var Ln=s(ar);fs=c(Ln,"Recursively broadcast tensor in a nested list/tuple/dictionary of tensors to all devices."),Ln.forEach(r),Oa.forEach(r),ea=n(e),R=o(e,"DIV",{class:!0});var Sa=s(R);f(Ce.$$.fragment,Sa),hs=n(Sa),or=o(Sa,"P",{});var Cn=s(or);vs=c(Cn,"Recursively concatenate the tensors in a nested list/tuple/dictionary of lists of tensors with the same shape."),Cn.forEach(r),Sa.forEach(r),ta=n(e),z=o(e,"DIV",{class:!0});var Ra=s(z);f(Ae.$$.fragment,Ra),gs=n(Ra),sr=o(Ra,"P",{});var An=s(sr);_s=c(An,"Recursively gather tensor in a nested list/tuple/dictionary of tensors from all devices."),An.forEach(r),Ra.forEach(r),ra=n(e),M=o(e,"DIV",{class:!0});var za=s(M);f(Ie.$$.fragment,za),bs=n(za),lr=o(za,"P",{});var In=s(lr);$s=c(In,`Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so they
can safely be gathered.`),In.forEach(r),za.forEach(r),aa=n(e),V=o(e,"DIV",{class:!0});var Ma=s(V);f(Ue.$$.fragment,Ma),ys=n(Ma),nr=o(Ma,"P",{});var Un=s(nr);Es=c(Un,`Recursively reduce the tensors in a nested list/tuple/dictionary of lists of tensors across all processes by the
mean of a given operation.`),Un.forEach(r),Ma.forEach(r),oa=n(e),G=o(e,"DIV",{class:!0});var Va=s(G);f(Oe.$$.fragment,Va),ws=n(Va),ir=o(Va,"P",{});var On=s(ir);xs=c(On,"Recursively sends the elements in a nested list/tuple/dictionary of tensors to a given device."),On.forEach(r),Va.forEach(r),sa=n(e),H=o(e,"H2",{class:!0});var Ga=s(H);ce=o(Ga,"A",{id:!0,class:!0,href:!0});var Sn=s(ce);cr=o(Sn,"SPAN",{});var Rn=s(cr);f(Se.$$.fragment,Rn),Rn.forEach(r),Sn.forEach(r),Ts=n(Ga),dr=o(Ga,"SPAN",{});var zn=s(dr);Ds=c(zn,"Environment Checks"),zn.forEach(r),Ga.forEach(r),la=n(e),wt=o(e,"P",{});var Mn=s(wt);Ps=c(Mn,"These functionalities check the state of the current working environment including information about the operating system itself, what it can support, and if particular dependencies are installed."),Mn.forEach(r),na=n(e),q=o(e,"DIV",{class:!0});var Ha=s(q);f(Re.$$.fragment,Ha),ks=n(Ha),pr=o(Ha,"P",{});var Vn=s(pr);Ns=c(Vn,"Checks if bf16 is supported, optionally ignoring the TPU"),Vn.forEach(r),Ha.forEach(r),ia=n(e),F=o(e,"DIV",{class:!0});var qa=s(F);f(ze.$$.fragment,qa),Ls=n(qa),ur=o(qa,"P",{});var Gn=s(ur);Cs=c(Gn,"Compares the current PyTorch version to a given reference with an operation."),Gn.forEach(r),qa.forEach(r),ca=n(e),B=o(e,"DIV",{class:!0});var Fa=s(B);f(Me.$$.fragment,Fa),As=n(Fa),Ve=o(Fa,"P",{});var Ba=s(Ve);Is=c(Ba,"Checks if "),mr=o(Ba,"CODE",{});var Hn=s(mr);Us=c(Hn,"torch_xla"),Hn.forEach(r),Os=c(Ba," is installed and potentially if a TPU is in the environment"),Ba.forEach(r),Fa.forEach(r),da=n(e),W=o(e,"H2",{class:!0});var Wa=s(W);de=o(Wa,"A",{id:!0,class:!0,href:!0});var qn=s(de);fr=o(qn,"SPAN",{});var Fn=s(fr);f(Ge.$$.fragment,Fn),Fn.forEach(r),qn.forEach(r),Ss=n(Wa),hr=o(Wa,"SPAN",{});var Bn=s(hr);Rs=c(Bn,"Environment Configuration"),Bn.forEach(r),Wa.forEach(r),pa=n(e),j=o(e,"DIV",{class:!0});var ja=s(j);f(He.$$.fragment,ja),zs=n(ja),vr=o(ja,"P",{});var Wn=s(vr);Ms=c(Wn,`Creates and saves a basic cluster config to be used on a local machine with potentially multiple GPUs. Will also
set CPU if it is a CPU-only machine.`),Wn.forEach(r),ja.forEach(r),ua=n(e),pe=o(e,"P",{});var Ja=s(pe);Vs=c(Ja,"When setting up \u{1F917} Accelerate for the first time, rather than running "),gr=o(Ja,"CODE",{});var jn=s(gr);Gs=c(jn,"accelerate config"),jn.forEach(r),Hs=c(Ja," [~utils.write_basic_config] can be used as an alternative for quick configuration."),Ja.forEach(r),ma=n(e),J=o(e,"H2",{class:!0});var Ka=s(J);ue=o(Ka,"A",{id:!0,class:!0,href:!0});var Jn=s(ue);_r=o(Jn,"SPAN",{});var Kn=s(_r);f(qe.$$.fragment,Kn),Kn.forEach(r),Jn.forEach(r),qs=n(Ka),br=o(Ka,"SPAN",{});var Qn=s(br);Fs=c(Qn,"Memory"),Qn.forEach(r),Ka.forEach(r),fa=n(e),K=o(e,"DIV",{class:!0});var Qa=s(K);f(Fe.$$.fragment,Qa),Bs=n(Qa),$r=o(Qa,"P",{});var Xn=s($r);Ws=c(Xn,"Get the maximum memory available if nothing is passed, converts string to int otherwise."),Xn.forEach(r),Qa.forEach(r),ha=n(e),k=o(e,"DIV",{class:!0});var Nt=s(k);f(Be.$$.fragment,Nt),js=n(Nt),me=o(Nt,"P",{});var Hr=s(me);Js=c(Hr,"A basic decorator that will try to execute "),yr=o(Hr,"CODE",{});var Yn=s(yr);Ks=c(Yn,"function"),Yn.forEach(r),Qs=c(Hr,`. If it fails from exceptions related to out-of-memory or
CUDNN, the batch size is cut in half and passed to `),Er=o(Hr,"CODE",{});var Zn=s(Er);Xs=c(Zn,"function"),Zn.forEach(r),Hr.forEach(r),Ys=n(Nt),fe=o(Nt,"P",{});var qr=s(fe);wr=o(qr,"CODE",{});var ei=s(wr);Zs=c(ei,"function"),ei.forEach(r),el=c(qr," must take in a "),xr=o(qr,"CODE",{});var ti=s(xr);tl=c(ti,"batch_size"),ti.forEach(r),rl=c(qr," parameter as its first argument."),qr.forEach(r),Nt.forEach(r),va=n(e),Q=o(e,"H2",{class:!0});var Xa=s(Q);he=o(Xa,"A",{id:!0,class:!0,href:!0});var ri=s(he);Tr=o(ri,"SPAN",{});var ai=s(Tr);f(We.$$.fragment,ai),ai.forEach(r),ri.forEach(r),al=n(Xa),Dr=o(Xa,"SPAN",{});var oi=s(Dr);ol=c(oi,"Modeling"),oi.forEach(r),Xa.forEach(r),ga=n(e),xt=o(e,"P",{});var si=s(xt);sl=c(si,"These utilities relate to interacting with PyTorch models"),si.forEach(r),_a=n(e),X=o(e,"DIV",{class:!0});var Ya=s(X);f(je.$$.fragment,Ya),ll=n(Ya),Pr=o(Ya,"P",{});var li=s(Pr);nl=c(li,"Extract a model from its distributed containers."),li.forEach(r),Ya.forEach(r),ba=n(e),N=o(e,"DIV",{class:!0});var Lt=s(N);f(Je.$$.fragment,Lt),il=n(Lt),kr=o(Lt,"P",{});var ni=s(kr);cl=c(ni,`Utility function that will scan a list of named modules and return the maximum size used by one full layer. The
definition of a layer being:`),ni.forEach(r),dl=n(Lt),Ke=o(Lt,"UL",{});var Za=s(Ke);Nr=o(Za,"LI",{});var ii=s(Nr);pl=c(ii,"a module with no direct children (just parameters and buffers)"),ii.forEach(r),ul=n(Za),Tt=o(Za,"LI",{});var Yl=s(Tt);ml=c(Yl,"a module whose class name is in the list "),Lr=o(Yl,"CODE",{});var ci=s(Lr);fl=c(ci,"no_split_module_classes"),ci.forEach(r),Yl.forEach(r),Za.forEach(r),Lt.forEach(r),$a=n(e),Y=o(e,"DIV",{class:!0});var eo=s(Y);f(Qe.$$.fragment,eo),hl=n(eo),Cr=o(eo,"P",{});var di=s(Cr);vl=c(di,"Offload a state dict in a given folder."),di.forEach(r),eo.forEach(r),ya=n(e),Z=o(e,"H2",{class:!0});var to=s(Z);ve=o(to,"A",{id:!0,class:!0,href:!0});var pi=s(ve);Ar=o(pi,"SPAN",{});var ui=s(Ar);f(Xe.$$.fragment,ui),ui.forEach(r),pi.forEach(r),gl=n(to),Ir=o(to,"SPAN",{});var mi=s(Ir);_l=c(mi,"Parallel"),mi.forEach(r),to.forEach(r),Ea=n(e),Dt=o(e,"P",{});var fi=s(Dt);bl=c(fi,"These include general utilities that should be used when working in parallel."),fi.forEach(r),wa=n(e),ee=o(e,"DIV",{class:!0});var ro=s(ee);f(Ye.$$.fragment,ro),$l=n(ro),Ur=o(ro,"P",{});var hi=s(Ur);yl=c(hi,"Extract a model from its distributed containers."),hi.forEach(r),ro.forEach(r),xa=n(e),te=o(e,"DIV",{class:!0});var ao=s(te);f(Ze.$$.fragment,ao),El=n(ao),et=o(ao,"P",{});var oo=s(et);wl=c(oo,"Save the data to disk. Use in place of "),Or=o(oo,"CODE",{});var vi=s(Or);xl=c(vi,"torch.save()"),vi.forEach(r),Tl=c(oo,"."),oo.forEach(r),ao.forEach(r),Ta=n(e),L=o(e,"DIV",{class:!0});var Ct=s(L);f(tt.$$.fragment,Ct),Dl=n(Ct),Sr=o(Ct,"P",{});var gi=s(Sr);Pl=c(gi,"Introduces a blocking point in the script, making sure all processes have reached this point before continuing."),gi.forEach(r),kl=n(Ct),f(ge.$$.fragment,Ct),Ct.forEach(r),Da=n(e),re=o(e,"H2",{class:!0});var so=s(re);_e=o(so,"A",{id:!0,class:!0,href:!0});var _i=s(_e);Rr=o(_i,"SPAN",{});var bi=s(Rr);f(rt.$$.fragment,bi),bi.forEach(r),_i.forEach(r),Nl=n(so),zr=o(so,"SPAN",{});var $i=s(zr);Ll=c($i,"Random"),$i.forEach(r),so.forEach(r),Pa=n(e),Pt=o(e,"P",{});var yi=s(Pt);Cl=c(yi,"These utilities relate to setting and synchronizing of all the random states."),yi.forEach(r),ka=n(e),ae=o(e,"DIV",{class:!0});var lo=s(ae);f(at.$$.fragment,lo),Al=n(lo),C=o(lo,"P",{});var we=s(C);Il=c(we,"Helper function for reproducible behavior to set the seed in "),Mr=o(we,"CODE",{});var Ei=s(Mr);Ul=c(Ei,"random"),Ei.forEach(r),Ol=c(we,", "),Vr=o(we,"CODE",{});var wi=s(Vr);Sl=c(wi,"numpy"),wi.forEach(r),Rl=c(we,", "),Gr=o(we,"CODE",{});var xi=s(Gr);zl=c(xi,"torch"),xi.forEach(r),Ml=c(we,"."),we.forEach(r),lo.forEach(r),Na=n(e),ot=o(e,"DIV",{class:!0});var Ti=s(ot);f(st.$$.fragment,Ti),Ti.forEach(r),La=n(e),lt=o(e,"DIV",{class:!0});var Di=s(lt);f(nt.$$.fragment,Di),Di.forEach(r),this.h()},h(){u($,"name","hf:doc:metadata"),u($,"content",JSON.stringify(Oi)),u(E,"id","helpful-utilities"),u(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(E,"href","#helpful-utilities"),u(y,"class","relative group"),u(le,"id","accelerate.DistributedType"),u(le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(le,"href","#accelerate.DistributedType"),u(I,"class","relative group"),u(w,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(T,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(D,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(ne,"id","accelerate.utils.broadcast"),u(ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ne,"href","#accelerate.utils.broadcast"),u(O,"class","relative group"),u(S,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(R,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(V,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(G,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(ce,"id","accelerate.utils.is_bf16_available"),u(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ce,"href","#accelerate.utils.is_bf16_available"),u(H,"class","relative group"),u(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(B,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(de,"id","accelerate.utils.write_basic_config"),u(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(de,"href","#accelerate.utils.write_basic_config"),u(W,"class","relative group"),u(j,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(ue,"id","accelerate.utils.get_max_memory"),u(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ue,"href","#accelerate.utils.get_max_memory"),u(J,"class","relative group"),u(K,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(k,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(he,"id","accelerate.utils.extract_model_from_parallel"),u(he,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(he,"href","#accelerate.utils.extract_model_from_parallel"),u(Q,"class","relative group"),u(X,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(N,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(Y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(ve,"id","accelerate.utils.extract_model_from_parallel"),u(ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ve,"href","#accelerate.utils.extract_model_from_parallel"),u(Z,"class","relative group"),u(ee,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(te,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(L,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(_e,"id","accelerate.utils.set_seed"),u(_e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(_e,"href","#accelerate.utils.set_seed"),u(re,"class","relative group"),u(ae,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),u(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,d){t(document.head,$),p(e,se,d),p(e,y,d),t(y,E),t(E,At),h(xe,At,null),t(y,no),t(y,It),t(It,io),p(e,Br,d),p(e,ct,d),t(ct,co),p(e,Wr,d),p(e,I,d),t(I,le),t(le,Ut),h(Te,Ut,null),t(I,po),t(I,Ot),t(Ot,uo),p(e,jr,d),p(e,dt,d),t(dt,mo),p(e,Jr,d),p(e,w,d),h(De,w,null),t(w,fo),t(w,St),t(St,ho),t(w,vo),t(w,Rt),t(Rt,go),t(w,_o),t(w,x),t(x,pt),t(pt,zt),t(zt,bo),t(pt,$o),t(x,yo),t(x,ut),t(ut,Mt),t(Mt,Eo),t(ut,wo),t(x,xo),t(x,mt),t(mt,Vt),t(Vt,To),t(mt,Do),t(x,Po),t(x,ft),t(ft,Gt),t(Gt,ko),t(ft,No),t(x,Lo),t(x,ht),t(ht,Ht),t(Ht,Co),t(ht,Ao),p(e,Kr,d),p(e,T,d),h(Pe,T,null),t(T,Io),t(T,qt),t(qt,Uo),t(T,Oo),t(T,Ft),t(Ft,So),t(T,Ro),t(T,P),t(P,vt),t(vt,Bt),t(Bt,zo),t(vt,Mo),t(P,Vo),t(P,gt),t(gt,Wt),t(Wt,Go),t(gt,Ho),t(P,qo),t(P,_t),t(_t,jt),t(jt,Fo),t(_t,Bo),t(P,Wo),t(P,bt),t(bt,Jt),t(Jt,jo),t(bt,Jo),p(e,Qr,d),p(e,D,d),h(ke,D,null),t(D,Ko),t(D,Kt),t(Kt,Qo),t(D,Xo),t(D,Qt),t(Qt,Yo),t(D,Zo),t(D,U),t(U,$t),t($t,Xt),t(Xt,es),t($t,ts),t(U,rs),t(U,yt),t(yt,Yt),t(Yt,as),t(yt,os),t(U,ss),t(U,Et),t(Et,Zt),t(Zt,ls),t(Et,ns),p(e,Xr,d),p(e,O,d),t(O,ne),t(ne,er),h(Ne,er,null),t(O,is),t(O,tr),t(tr,cs),p(e,Yr,d),p(e,ie,d),t(ie,ds),t(ie,rr),t(rr,ps),t(ie,us),p(e,Zr,d),p(e,S,d),h(Le,S,null),t(S,ms),t(S,ar),t(ar,fs),p(e,ea,d),p(e,R,d),h(Ce,R,null),t(R,hs),t(R,or),t(or,vs),p(e,ta,d),p(e,z,d),h(Ae,z,null),t(z,gs),t(z,sr),t(sr,_s),p(e,ra,d),p(e,M,d),h(Ie,M,null),t(M,bs),t(M,lr),t(lr,$s),p(e,aa,d),p(e,V,d),h(Ue,V,null),t(V,ys),t(V,nr),t(nr,Es),p(e,oa,d),p(e,G,d),h(Oe,G,null),t(G,ws),t(G,ir),t(ir,xs),p(e,sa,d),p(e,H,d),t(H,ce),t(ce,cr),h(Se,cr,null),t(H,Ts),t(H,dr),t(dr,Ds),p(e,la,d),p(e,wt,d),t(wt,Ps),p(e,na,d),p(e,q,d),h(Re,q,null),t(q,ks),t(q,pr),t(pr,Ns),p(e,ia,d),p(e,F,d),h(ze,F,null),t(F,Ls),t(F,ur),t(ur,Cs),p(e,ca,d),p(e,B,d),h(Me,B,null),t(B,As),t(B,Ve),t(Ve,Is),t(Ve,mr),t(mr,Us),t(Ve,Os),p(e,da,d),p(e,W,d),t(W,de),t(de,fr),h(Ge,fr,null),t(W,Ss),t(W,hr),t(hr,Rs),p(e,pa,d),p(e,j,d),h(He,j,null),t(j,zs),t(j,vr),t(vr,Ms),p(e,ua,d),p(e,pe,d),t(pe,Vs),t(pe,gr),t(gr,Gs),t(pe,Hs),p(e,ma,d),p(e,J,d),t(J,ue),t(ue,_r),h(qe,_r,null),t(J,qs),t(J,br),t(br,Fs),p(e,fa,d),p(e,K,d),h(Fe,K,null),t(K,Bs),t(K,$r),t($r,Ws),p(e,ha,d),p(e,k,d),h(Be,k,null),t(k,js),t(k,me),t(me,Js),t(me,yr),t(yr,Ks),t(me,Qs),t(me,Er),t(Er,Xs),t(k,Ys),t(k,fe),t(fe,wr),t(wr,Zs),t(fe,el),t(fe,xr),t(xr,tl),t(fe,rl),p(e,va,d),p(e,Q,d),t(Q,he),t(he,Tr),h(We,Tr,null),t(Q,al),t(Q,Dr),t(Dr,ol),p(e,ga,d),p(e,xt,d),t(xt,sl),p(e,_a,d),p(e,X,d),h(je,X,null),t(X,ll),t(X,Pr),t(Pr,nl),p(e,ba,d),p(e,N,d),h(Je,N,null),t(N,il),t(N,kr),t(kr,cl),t(N,dl),t(N,Ke),t(Ke,Nr),t(Nr,pl),t(Ke,ul),t(Ke,Tt),t(Tt,ml),t(Tt,Lr),t(Lr,fl),p(e,$a,d),p(e,Y,d),h(Qe,Y,null),t(Y,hl),t(Y,Cr),t(Cr,vl),p(e,ya,d),p(e,Z,d),t(Z,ve),t(ve,Ar),h(Xe,Ar,null),t(Z,gl),t(Z,Ir),t(Ir,_l),p(e,Ea,d),p(e,Dt,d),t(Dt,bl),p(e,wa,d),p(e,ee,d),h(Ye,ee,null),t(ee,$l),t(ee,Ur),t(Ur,yl),p(e,xa,d),p(e,te,d),h(Ze,te,null),t(te,El),t(te,et),t(et,wl),t(et,Or),t(Or,xl),t(et,Tl),p(e,Ta,d),p(e,L,d),h(tt,L,null),t(L,Dl),t(L,Sr),t(Sr,Pl),t(L,kl),h(ge,L,null),p(e,Da,d),p(e,re,d),t(re,_e),t(_e,Rr),h(rt,Rr,null),t(re,Nl),t(re,zr),t(zr,Ll),p(e,Pa,d),p(e,Pt,d),t(Pt,Cl),p(e,ka,d),p(e,ae,d),h(at,ae,null),t(ae,Al),t(ae,C),t(C,Il),t(C,Mr),t(Mr,Ul),t(C,Ol),t(C,Vr),t(Vr,Sl),t(C,Rl),t(C,Gr),t(Gr,zl),t(C,Ml),p(e,Na,d),p(e,ot,d),h(st,ot,null),p(e,La,d),p(e,lt,d),h(nt,lt,null),Ca=!0},p(e,[d]){const it={};d&2&&(it.$$scope={dirty:d,ctx:e}),ge.$set(it)},i(e){Ca||(v(xe.$$.fragment,e),v(Te.$$.fragment,e),v(De.$$.fragment,e),v(Pe.$$.fragment,e),v(ke.$$.fragment,e),v(Ne.$$.fragment,e),v(Le.$$.fragment,e),v(Ce.$$.fragment,e),v(Ae.$$.fragment,e),v(Ie.$$.fragment,e),v(Ue.$$.fragment,e),v(Oe.$$.fragment,e),v(Se.$$.fragment,e),v(Re.$$.fragment,e),v(ze.$$.fragment,e),v(Me.$$.fragment,e),v(Ge.$$.fragment,e),v(He.$$.fragment,e),v(qe.$$.fragment,e),v(Fe.$$.fragment,e),v(Be.$$.fragment,e),v(We.$$.fragment,e),v(je.$$.fragment,e),v(Je.$$.fragment,e),v(Qe.$$.fragment,e),v(Xe.$$.fragment,e),v(Ye.$$.fragment,e),v(Ze.$$.fragment,e),v(tt.$$.fragment,e),v(ge.$$.fragment,e),v(rt.$$.fragment,e),v(at.$$.fragment,e),v(st.$$.fragment,e),v(nt.$$.fragment,e),Ca=!0)},o(e){g(xe.$$.fragment,e),g(Te.$$.fragment,e),g(De.$$.fragment,e),g(Pe.$$.fragment,e),g(ke.$$.fragment,e),g(Ne.$$.fragment,e),g(Le.$$.fragment,e),g(Ce.$$.fragment,e),g(Ae.$$.fragment,e),g(Ie.$$.fragment,e),g(Ue.$$.fragment,e),g(Oe.$$.fragment,e),g(Se.$$.fragment,e),g(Re.$$.fragment,e),g(ze.$$.fragment,e),g(Me.$$.fragment,e),g(Ge.$$.fragment,e),g(He.$$.fragment,e),g(qe.$$.fragment,e),g(Fe.$$.fragment,e),g(Be.$$.fragment,e),g(We.$$.fragment,e),g(je.$$.fragment,e),g(Je.$$.fragment,e),g(Qe.$$.fragment,e),g(Xe.$$.fragment,e),g(Ye.$$.fragment,e),g(Ze.$$.fragment,e),g(tt.$$.fragment,e),g(ge.$$.fragment,e),g(rt.$$.fragment,e),g(at.$$.fragment,e),g(st.$$.fragment,e),g(nt.$$.fragment,e),Ca=!1},d(e){r($),e&&r(se),e&&r(y),_(xe),e&&r(Br),e&&r(ct),e&&r(Wr),e&&r(I),_(Te),e&&r(jr),e&&r(dt),e&&r(Jr),e&&r(w),_(De),e&&r(Kr),e&&r(T),_(Pe),e&&r(Qr),e&&r(D),_(ke),e&&r(Xr),e&&r(O),_(Ne),e&&r(Yr),e&&r(ie),e&&r(Zr),e&&r(S),_(Le),e&&r(ea),e&&r(R),_(Ce),e&&r(ta),e&&r(z),_(Ae),e&&r(ra),e&&r(M),_(Ie),e&&r(aa),e&&r(V),_(Ue),e&&r(oa),e&&r(G),_(Oe),e&&r(sa),e&&r(H),_(Se),e&&r(la),e&&r(wt),e&&r(na),e&&r(q),_(Re),e&&r(ia),e&&r(F),_(ze),e&&r(ca),e&&r(B),_(Me),e&&r(da),e&&r(W),_(Ge),e&&r(pa),e&&r(j),_(He),e&&r(ua),e&&r(pe),e&&r(ma),e&&r(J),_(qe),e&&r(fa),e&&r(K),_(Fe),e&&r(ha),e&&r(k),_(Be),e&&r(va),e&&r(Q),_(We),e&&r(ga),e&&r(xt),e&&r(_a),e&&r(X),_(je),e&&r(ba),e&&r(N),_(Je),e&&r($a),e&&r(Y),_(Qe),e&&r(ya),e&&r(Z),_(Xe),e&&r(Ea),e&&r(Dt),e&&r(wa),e&&r(ee),_(Ye),e&&r(xa),e&&r(te),_(Ze),e&&r(Ta),e&&r(L),_(tt),_(ge),e&&r(Da),e&&r(re),_(rt),e&&r(Pa),e&&r(Pt),e&&r(ka),e&&r(ae),_(at),e&&r(Na),e&&r(ot),_(st),e&&r(La),e&&r(lt),_(nt)}}}const Oi={local:"helpful-utilities",sections:[{local:"accelerate.DistributedType",title:"Data Classes"},{local:"accelerate.utils.broadcast",title:"Data Manipulation and Operations"},{local:"accelerate.utils.is_bf16_available",title:"Environment Checks"},{local:"accelerate.utils.write_basic_config",title:"Environment Configuration"},{local:"accelerate.utils.get_max_memory",title:"Memory"},{local:"accelerate.utils.extract_model_from_parallel",title:"Modeling"},{local:"accelerate.utils.extract_model_from_parallel",title:"Parallel"},{local:"accelerate.utils.set_seed",title:"Random"}],title:"Helpful Utilities"};function Si(Fr){return Ci(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Gi extends Pi{constructor($){super();ki(this,$,Si,Ui,Ni,{})}}export{Gi as default,Oi as metadata};
