import{S as Pi,i as ki,s as Ni,e as a,k as n,w as u,t as i,M as Li,c as o,d as r,m as l,a as s,x as f,h as c,b as m,G as t,g as p,y as h,q as v,o as g,B as _,v as Ci}from"../../chunks/vendor-hf-doc-builder.js";import{T as Ai}from"../../chunks/Tip-hf-doc-builder.js";import{D as b}from"../../chunks/Docstring-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";function Ii(Fr){let $,se;return{c(){$=a("p"),se=i("Make sure all processes will reach this instruction otherwise one of your processes will hang forever.")},l(y){$=o(y,"P",{});var E=s($);se=c(E,"Make sure all processes will reach this instruction otherwise one of your processes will hang forever."),E.forEach(r)},m(y,E){p(y,$,E),t($,se)},d(y){y&&r($)}}}function Ui(Fr){let $,se,y,E,At,xe,lo,It,io,Br,ct,co,Wr,I,ne,Ut,Te,po,Ot,mo,jr,dt,uo,Jr,w,De,fo,St,ho,vo,Rt,go,_o,x,pt,zt,bo,$o,yo,mt,Mt,Eo,wo,xo,ut,Vt,To,Do,Po,ft,Gt,ko,No,Lo,ht,Ht,Co,Ao,Kr,T,Pe,Io,qt,Uo,Oo,Ft,So,Ro,P,vt,Bt,zo,Mo,Vo,gt,Wt,Go,Ho,qo,_t,jt,Fo,Bo,Wo,bt,Jt,jo,Jo,Qr,D,ke,Ko,Kt,Qo,Xo,Qt,Yo,Zo,U,$t,Xt,es,ts,rs,yt,Yt,as,os,ss,Et,Zt,ns,ls,Xr,O,le,er,Ne,is,tr,cs,Yr,ie,ds,rr,ps,ms,Zr,S,Le,us,ar,fs,ea,R,Ce,hs,or,vs,ta,z,Ae,gs,sr,_s,ra,M,Ie,bs,nr,$s,aa,V,Ue,ys,lr,Es,oa,G,Oe,ws,ir,xs,sa,H,ce,cr,Se,Ts,dr,Ds,na,wt,Ps,la,q,Re,ks,pr,Ns,ia,F,ze,Ls,mr,Cs,ca,B,Me,As,Ve,Is,ur,Us,Os,da,W,de,fr,Ge,Ss,hr,Rs,pa,j,He,zs,vr,Ms,ma,pe,Vs,gr,Gs,Hs,ua,J,me,_r,qe,qs,br,Fs,fa,K,Fe,Bs,$r,Ws,ha,k,Be,js,ue,Js,yr,Ks,Qs,Er,Xs,Ys,fe,wr,Zs,en,xr,tn,rn,va,Q,he,Tr,We,an,Dr,on,ga,xt,sn,_a,X,je,nn,Pr,ln,ba,N,Je,cn,kr,dn,pn,Ke,Nr,mn,un,Tt,fn,Lr,hn,$a,Y,Qe,vn,Cr,gn,ya,Z,ve,Ar,Xe,_n,Ir,bn,Ea,Dt,$n,wa,ee,Ye,yn,Ur,En,xa,te,Ze,wn,et,xn,Or,Tn,Dn,Ta,L,tt,Pn,Sr,kn,Nn,ge,Da,re,_e,Rr,rt,Ln,zr,Cn,Pa,Pt,An,ka,ae,at,In,C,Un,Mr,On,Sn,Vr,Rn,zn,Gr,Mn,Vn,Na,ot,st,La,nt,lt,Ca;return xe=new oe({}),Te=new oe({}),De=new b({props:{name:"class accelerate.DistributedType",anchor:"accelerate.DistributedType",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/dataclasses.py#L111"}}),Pe=new b({props:{name:"class accelerate.utils.LoggerType",anchor:"accelerate.utils.LoggerType",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/dataclasses.py#L234"}}),ke=new b({props:{name:"class accelerate.utils.PrecisionType",anchor:"accelerate.utils.PrecisionType",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/dataclasses.py#L253"}}),Ne=new oe({}),Le=new b({props:{name:"accelerate.utils.broadcast",anchor:"accelerate.utils.broadcast",parameters:[{name:"tensor",val:""},{name:"from_process",val:": int = 0"}],parametersDescription:[{anchor:"accelerate.utils.broadcast.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to gather.`,name:"tensor"},{anchor:"accelerate.utils.broadcast.from_process",description:`<strong>from_process</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The process from which to send the data`,name:"from_process"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/operations.py#L281",returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors broadcasted to the proper device.</p>
`}}),Ce=new b({props:{name:"accelerate.utils.concatenate",anchor:"accelerate.utils.concatenate",parameters:[{name:"data",val:""},{name:"dim",val:" = 0"}],parametersDescription:[{anchor:"accelerate.utils.concatenate.data",description:`<strong>data</strong> (nested list/tuple/dictionary of lists of tensors <code>torch.Tensor</code>) &#x2014;
The data to concatenate.`,name:"data"},{anchor:"accelerate.utils.concatenate.dim",description:`<strong>dim</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The dimension on which to concatenate.`,name:"dim"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/operations.py#L347",returnDescription:`
<p>The same data structure as <code>data</code> with all the tensors concatenated.</p>
`}}),Ae=new b({props:{name:"accelerate.utils.gather",anchor:"accelerate.utils.gather",parameters:[{name:"tensor",val:""}],parametersDescription:[{anchor:"accelerate.utils.gather.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to gather.`,name:"tensor"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/operations.py#L211",returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors sent to the proper device.</p>
`}}),Ie=new b({props:{name:"accelerate.utils.pad_across_processes",anchor:"accelerate.utils.pad_across_processes",parameters:[{name:"tensor",val:""},{name:"dim",val:" = 0"},{name:"pad_index",val:" = 0"},{name:"pad_first",val:" = False"}],parametersDescription:[{anchor:"accelerate.utils.pad_across_processes.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to gather.`,name:"tensor"},{anchor:"accelerate.utils.pad_across_processes.dim",description:`<strong>dim</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The dimension on which to pad.`,name:"dim"},{anchor:"accelerate.utils.pad_across_processes.pad_index",description:`<strong>pad_index</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The value with which to pad.`,name:"pad_index"},{anchor:"accelerate.utils.pad_across_processes.pad_first",description:`<strong>pad_first</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to pad at the beginning or the end.`,name:"pad_first"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/operations.py#L369"}}),Ue=new b({props:{name:"accelerate.utils.reduce",anchor:"accelerate.utils.reduce",parameters:[{name:"tensor",val:""},{name:"reduction",val:" = 'mean'"}],parametersDescription:[{anchor:"accelerate.utils.reduce.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to reduce.`,name:"tensor"},{anchor:"accelerate.utils.reduce.reduction",description:`<strong>reduction</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;mean&quot;</code>) &#x2014;
A reduction method. Can be of &#x201C;mean&#x201D;, &#x201C;sum&#x201D;, or &#x201C;none&#x201D;`,name:"reduction"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/operations.py#L415",returnDescription:`
<p>The same data structure as <code>data</code> with all the tensors reduced.</p>
`}}),Oe=new b({props:{name:"accelerate.utils.send_to_device",anchor:"accelerate.utils.send_to_device",parameters:[{name:"tensor",val:""},{name:"device",val:""},{name:"non_blocking",val:" = False"}],parametersDescription:[{anchor:"accelerate.utils.send_to_device.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to send to a given device.`,name:"tensor"},{anchor:"accelerate.utils.send_to_device.device",description:`<strong>device</strong> (<code>torch.device</code>) &#x2014;
The device to send the data to.`,name:"device"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/operations.py#L107",returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors sent to the proper device.</p>
`}}),Se=new oe({}),Re=new b({props:{name:"accelerate.utils.is_bf16_available",anchor:"accelerate.utils.is_bf16_available",parameters:[{name:"ignore_tpu",val:" = False"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/imports.py#L84"}}),ze=new b({props:{name:"accelerate.utils.is_torch_version",anchor:"accelerate.utils.is_torch_version",parameters:[{name:"operation",val:": str"},{name:"version",val:": str"}],parametersDescription:[{anchor:"accelerate.utils.is_torch_version.operation",description:`<strong>operation</strong> (<code>str</code>) &#x2014;
A string representation of an operator, such as <code>&quot;&gt;&quot;</code> or <code>&quot;&lt;=&quot;</code>`,name:"operation"},{anchor:"accelerate.utils.is_torch_version.version",description:`<strong>version</strong> (<code>str</code>) &#x2014;
A string version of PyTorch`,name:"version"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/versions.py#L51"}}),Me=new b({props:{name:"accelerate.utils.is_tpu_available",anchor:"accelerate.utils.is_tpu_available",parameters:[{name:"check_device",val:" = True"}]}}),Ge=new oe({}),He=new b({props:{name:"accelerate.commands.config.default.write_basic_config",anchor:"accelerate.commands.config.default.write_basic_config",parameters:[{name:"mixed_precision",val:" = 'no'"},{name:"save_location",val:": str = '/github/home/.cache/huggingface/accelerate/default_config.yaml'"},{name:"dynamo_backend",val:" = 'no'"}],parametersDescription:[{anchor:"accelerate.commands.config.default.write_basic_config.mixed_precision",description:`<strong>mixed_precision</strong> (<code>str</code>, <em>optional</em>, defaults to &#x201C;no&#x201D;) &#x2014;
Mixed Precision to use. Should be one of &#x201C;no&#x201D;, &#x201C;fp16&#x201D;, or &#x201C;bf16&#x201D;`,name:"mixed_precision"},{anchor:"accelerate.commands.config.default.write_basic_config.save_location",description:`<strong>save_location</strong> (<code>str</code>, <em>optional</em>, defaults to <code>default_json_config_file</code>) &#x2014;
Optional custom save location. Should be passed to <code>--config_file</code> when using <code>accelerate launch</code>. Default
location is inside the huggingface cache folder (<code>~/.cache/huggingface</code>) but can be overriden by setting
the <code>HF_HOME</code> environmental variable, followed by <code>accelerate/default_config.yaml</code>.`,name:"save_location"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/commands/config/default.py#L26"}}),qe=new oe({}),Fe=new b({props:{name:"accelerate.utils.get_max_memory",anchor:"accelerate.utils.get_max_memory",parameters:[{name:"max_memory",val:": typing.Union[typing.Dict[typing.Union[int, str], typing.Union[int, str]], NoneType] = None"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/modeling.py#L275"}}),Be=new b({props:{name:"accelerate.find_executable_batch_size",anchor:"accelerate.find_executable_batch_size",parameters:[{name:"function",val:": callable = None"},{name:"starting_batch_size",val:": int = 128"}],parametersDescription:[{anchor:"accelerate.find_executable_batch_size.function",description:`<strong>function</strong> (<code>callable</code>, <em>optional</em>) &#x2014;
A function to wrap`,name:"function"},{anchor:"accelerate.find_executable_batch_size.starting_batch_size",description:`<strong>starting_batch_size</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The batch size to try and fit into memory`,name:"starting_batch_size"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/memory.py#L45"}}),We=new oe({}),je=new b({props:{name:"accelerate.utils.extract_model_from_parallel",anchor:"accelerate.utils.extract_model_from_parallel",parameters:[{name:"model",val:""}],parametersDescription:[{anchor:"accelerate.utils.extract_model_from_parallel.model",description:"<strong>model</strong> (<code>torch.nn.Module</code>) &#x2014; The model to extract.",name:"model"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/other.py#L33",returnDescription:`
<p>The extracted model.</p>
`,returnType:`
<p><code>torch.nn.Module</code></p>
`}}),Je=new b({props:{name:"accelerate.utils.get_max_layer_size",anchor:"accelerate.utils.get_max_layer_size",parameters:[{name:"modules",val:": typing.List[typing.Tuple[str, torch.nn.modules.module.Module]]"},{name:"module_sizes",val:": typing.Dict[str, int]"},{name:"no_split_module_classes",val:": typing.List[str]"}],parametersDescription:[{anchor:"accelerate.utils.get_max_layer_size.modules",description:`<strong>modules</strong> (<code>List[Tuple[str, torch.nn.Module]]</code>) &#x2014;
The list of named modules where we want to determine the maximum layer size.`,name:"modules"},{anchor:"accelerate.utils.get_max_layer_size.module_sizes",description:`<strong>module_sizes</strong> (<code>Dict[str, int]</code>) &#x2014;
A dictionary mapping each layer name to its size (as generated by <code>compute_module_sizes</code>).`,name:"module_sizes"},{anchor:"accelerate.utils.get_max_layer_size.no_split_module_classes",description:`<strong>no_split_module_classes</strong> (<code>List[str]</code>) &#x2014;
A list of class names for layers we don&#x2019;t want to be split.`,name:"no_split_module_classes"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/modeling.py#L236",returnDescription:`
<p>The maximum size of a layer with the list of layer names realizing that maximum size.</p>
`,returnType:`
<p><code>Tuple[int, List[str]]</code></p>
`}}),Qe=new b({props:{name:"accelerate.utils.offload_state_dict",anchor:"accelerate.utils.offload_state_dict",parameters:[{name:"save_dir",val:": typing.Union[str, os.PathLike]"},{name:"state_dict",val:": typing.Dict[str, torch.Tensor]"}],parametersDescription:[{anchor:"accelerate.utils.offload_state_dict.save_dir",description:"<strong>save_dir</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014; The directory in which to offload the state dict.",name:"save_dir"},{anchor:"accelerate.utils.offload_state_dict.state_dict",description:"<strong>state_dict</strong> (<code>Dict[str, torch.Tensor]</code>) &#x2014; The dictionary of tensors to offload.",name:"state_dict"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/offload.py#L84"}}),Xe=new oe({}),Ye=new b({props:{name:"accelerate.utils.extract_model_from_parallel",anchor:"accelerate.utils.extract_model_from_parallel",parameters:[{name:"model",val:""}],parametersDescription:[{anchor:"accelerate.utils.extract_model_from_parallel.model",description:"<strong>model</strong> (<code>torch.nn.Module</code>) &#x2014; The model to extract.",name:"model"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/other.py#L33",returnDescription:`
<p>The extracted model.</p>
`,returnType:`
<p><code>torch.nn.Module</code></p>
`}}),Ze=new b({props:{name:"accelerate.utils.save",anchor:"accelerate.utils.save",parameters:[{name:"obj",val:""},{name:"f",val:""}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/other.py#L73"}}),tt=new b({props:{name:"accelerate.utils.wait_for_everyone",anchor:"accelerate.utils.wait_for_everyone",parameters:[],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/other.py#L52"}}),ge=new Ai({props:{warning:!0,$$slots:{default:[Ii]},$$scope:{ctx:Fr}}}),rt=new oe({}),at=new b({props:{name:"accelerate.utils.set_seed",anchor:"accelerate.utils.set_seed",parameters:[{name:"seed",val:": int"},{name:"device_specific",val:": bool = False"}],parametersDescription:[{anchor:"accelerate.utils.set_seed.seed",description:"<strong>seed</strong> (<code>int</code>) &#x2014; The seed to set.",name:"seed"},{anchor:"accelerate.utils.set_seed.device_specific",description:`<strong>device_specific</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to differ the seed on each device slightly with <code>self.process_index</code>.`,name:"device_specific"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/random.py#L31"}}),st=new b({props:{name:"accelerate.utils.synchronize_rng_state",anchor:"accelerate.utils.synchronize_rng_state",parameters:[{name:"rng_type",val:": typing.Optional[accelerate.utils.dataclasses.RNGType] = None"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/random.py#L51"}}),lt=new b({props:{name:"accelerate.synchronize_rng_states",anchor:"accelerate.synchronize_rng_states",parameters:[{name:"rng_types",val:": typing.List[typing.Union[str, accelerate.utils.dataclasses.RNGType]]"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils/random.py#L86"}}),{c(){$=a("meta"),se=n(),y=a("h1"),E=a("a"),At=a("span"),u(xe.$$.fragment),lo=n(),It=a("span"),io=i("Helpful Utilities"),Br=n(),ct=a("p"),co=i("Below are a variety of utility functions that \u{1F917} Accelerate provides, broken down by use-case."),Wr=n(),I=a("h2"),ne=a("a"),Ut=a("span"),u(Te.$$.fragment),po=n(),Ot=a("span"),mo=i("Data Classes"),jr=n(),dt=a("p"),uo=i("These are basic dataclasses used throughout \u{1F917} Accelerate and they can be passed in as parameters."),Jr=n(),w=a("div"),u(De.$$.fragment),fo=n(),St=a("p"),ho=i("Represents a type of distributed environment."),vo=n(),Rt=a("p"),go=i("Values:"),_o=n(),x=a("ul"),pt=a("li"),zt=a("strong"),bo=i("NO"),$o=i(" \u2014 Not a distributed environment, just a single process."),yo=n(),mt=a("li"),Mt=a("strong"),Eo=i("MULTI_CPU"),wo=i(" \u2014 Distributed on multiple CPU nodes."),xo=n(),ut=a("li"),Vt=a("strong"),To=i("MULTI_GPU"),Do=i(" \u2014 Distributed on multiple GPUs."),Po=n(),ft=a("li"),Gt=a("strong"),ko=i("DEEPSPEED"),No=i(" \u2014 Using DeepSpeed."),Lo=n(),ht=a("li"),Ht=a("strong"),Co=i("TPU"),Ao=i(" \u2014 Distributed on TPUs."),Kr=n(),T=a("div"),u(Pe.$$.fragment),Io=n(),qt=a("p"),Uo=i("Represents a type of supported experiment tracker"),Oo=n(),Ft=a("p"),So=i("Values:"),Ro=n(),P=a("ul"),vt=a("li"),Bt=a("strong"),zo=i("ALL"),Mo=i(" \u2014 all available trackers in the environment that are supported"),Vo=n(),gt=a("li"),Wt=a("strong"),Go=i("TENSORBOARD"),Ho=i(" \u2014 TensorBoard as an experiment tracker"),qo=n(),_t=a("li"),jt=a("strong"),Fo=i("WANDB"),Bo=i(" \u2014 wandb as an experiment tracker"),Wo=n(),bt=a("li"),Jt=a("strong"),jo=i("COMETML"),Jo=i(" \u2014 comet_ml as an experiment tracker"),Qr=n(),D=a("div"),u(ke.$$.fragment),Ko=n(),Kt=a("p"),Qo=i("Represents a type of precision used on floating point values"),Xo=n(),Qt=a("p"),Yo=i("Values:"),Zo=n(),U=a("ul"),$t=a("li"),Xt=a("strong"),es=i("NO"),ts=i(" \u2014 using full precision (FP32)"),rs=n(),yt=a("li"),Yt=a("strong"),as=i("FP16"),os=i(" \u2014 using half precision"),ss=n(),Et=a("li"),Zt=a("strong"),ns=i("BF16"),ls=i(" \u2014 using brain floating point precision"),Xr=n(),O=a("h2"),le=a("a"),er=a("span"),u(Ne.$$.fragment),is=n(),tr=a("span"),cs=i("Data Manipulation and Operations"),Yr=n(),ie=a("p"),ds=i("These include data operations that mimic the same "),rr=a("code"),ps=i("torch"),ms=i(" ops but can be used on distributed processes."),Zr=n(),S=a("div"),u(Le.$$.fragment),us=n(),ar=a("p"),fs=i("Recursively broadcast tensor in a nested list/tuple/dictionary of tensors to all devices."),ea=n(),R=a("div"),u(Ce.$$.fragment),hs=n(),or=a("p"),vs=i("Recursively concatenate the tensors in a nested list/tuple/dictionary of lists of tensors with the same shape."),ta=n(),z=a("div"),u(Ae.$$.fragment),gs=n(),sr=a("p"),_s=i("Recursively gather tensor in a nested list/tuple/dictionary of tensors from all devices."),ra=n(),M=a("div"),u(Ie.$$.fragment),bs=n(),nr=a("p"),$s=i(`Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so they
can safely be gathered.`),aa=n(),V=a("div"),u(Ue.$$.fragment),ys=n(),lr=a("p"),Es=i(`Recursively reduce the tensors in a nested list/tuple/dictionary of lists of tensors across all processes by the
mean of a given operation.`),oa=n(),G=a("div"),u(Oe.$$.fragment),ws=n(),ir=a("p"),xs=i("Recursively sends the elements in a nested list/tuple/dictionary of tensors to a given device."),sa=n(),H=a("h2"),ce=a("a"),cr=a("span"),u(Se.$$.fragment),Ts=n(),dr=a("span"),Ds=i("Environment Checks"),na=n(),wt=a("p"),Ps=i("These functionalities check the state of the current working environment including information about the operating system itself, what it can support, and if particular dependencies are installed."),la=n(),q=a("div"),u(Re.$$.fragment),ks=n(),pr=a("p"),Ns=i("Checks if bf16 is supported, optionally ignoring the TPU"),ia=n(),F=a("div"),u(ze.$$.fragment),Ls=n(),mr=a("p"),Cs=i("Compares the current PyTorch version to a given reference with an operation."),ca=n(),B=a("div"),u(Me.$$.fragment),As=n(),Ve=a("p"),Is=i("Checks if "),ur=a("code"),Us=i("torch_xla"),Os=i(" is installed and potentially if a TPU is in the environment"),da=n(),W=a("h2"),de=a("a"),fr=a("span"),u(Ge.$$.fragment),Ss=n(),hr=a("span"),Rs=i("Environment Configuration"),pa=n(),j=a("div"),u(He.$$.fragment),zs=n(),vr=a("p"),Ms=i(`Creates and saves a basic cluster config to be used on a local machine with potentially multiple GPUs. Will also
set CPU if it is a CPU-only machine.`),ma=n(),pe=a("p"),Vs=i("When setting up \u{1F917} Accelerate for the first time, rather than running "),gr=a("code"),Gs=i("accelerate config"),Hs=i(" [~utils.write_basic_config] can be used as an alternative for quick configuration."),ua=n(),J=a("h2"),me=a("a"),_r=a("span"),u(qe.$$.fragment),qs=n(),br=a("span"),Fs=i("Memory"),fa=n(),K=a("div"),u(Fe.$$.fragment),Bs=n(),$r=a("p"),Ws=i("Get the maximum memory available if nothing is passed, converts string to int otherwise."),ha=n(),k=a("div"),u(Be.$$.fragment),js=n(),ue=a("p"),Js=i("A basic decorator that will try to execute "),yr=a("code"),Ks=i("function"),Qs=i(`. If it fails from exceptions related to out-of-memory or
CUDNN, the batch size is cut in half and passed to `),Er=a("code"),Xs=i("function"),Ys=n(),fe=a("p"),wr=a("code"),Zs=i("function"),en=i(" must take in a "),xr=a("code"),tn=i("batch_size"),rn=i(" parameter as its first argument."),va=n(),Q=a("h2"),he=a("a"),Tr=a("span"),u(We.$$.fragment),an=n(),Dr=a("span"),on=i("Modeling"),ga=n(),xt=a("p"),sn=i("These utilities relate to interacting with PyTorch models"),_a=n(),X=a("div"),u(je.$$.fragment),nn=n(),Pr=a("p"),ln=i("Extract a model from its distributed containers."),ba=n(),N=a("div"),u(Je.$$.fragment),cn=n(),kr=a("p"),dn=i(`Utility function that will scan a list of named modules and return the maximum size used by one full layer. The
definition of a layer being:`),pn=n(),Ke=a("ul"),Nr=a("li"),mn=i("a module with no direct children (just parameters and buffers)"),un=n(),Tt=a("li"),fn=i("a module whose class name is in the list "),Lr=a("code"),hn=i("no_split_module_classes"),$a=n(),Y=a("div"),u(Qe.$$.fragment),vn=n(),Cr=a("p"),gn=i("Offload a state dict in a given folder."),ya=n(),Z=a("h2"),ve=a("a"),Ar=a("span"),u(Xe.$$.fragment),_n=n(),Ir=a("span"),bn=i("Parallel"),Ea=n(),Dt=a("p"),$n=i("These include general utilities that should be used when working in parallel."),wa=n(),ee=a("div"),u(Ye.$$.fragment),yn=n(),Ur=a("p"),En=i("Extract a model from its distributed containers."),xa=n(),te=a("div"),u(Ze.$$.fragment),wn=n(),et=a("p"),xn=i("Save the data to disk. Use in place of "),Or=a("code"),Tn=i("torch.save()"),Dn=i("."),Ta=n(),L=a("div"),u(tt.$$.fragment),Pn=n(),Sr=a("p"),kn=i("Introduces a blocking point in the script, making sure all processes have reached this point before continuing."),Nn=n(),u(ge.$$.fragment),Da=n(),re=a("h2"),_e=a("a"),Rr=a("span"),u(rt.$$.fragment),Ln=n(),zr=a("span"),Cn=i("Random"),Pa=n(),Pt=a("p"),An=i("These utilities relate to setting and synchronizing of all the random states."),ka=n(),ae=a("div"),u(at.$$.fragment),In=n(),C=a("p"),Un=i("Helper function for reproducible behavior to set the seed in "),Mr=a("code"),On=i("random"),Sn=i(", "),Vr=a("code"),Rn=i("numpy"),zn=i(", "),Gr=a("code"),Mn=i("torch"),Vn=i("."),Na=n(),ot=a("div"),u(st.$$.fragment),La=n(),nt=a("div"),u(lt.$$.fragment),this.h()},l(e){const d=Li('[data-svelte="svelte-1phssyn"]',document.head);$=o(d,"META",{name:!0,content:!0}),d.forEach(r),se=l(e),y=o(e,"H1",{class:!0});var it=s(y);E=o(it,"A",{id:!0,class:!0,href:!0});var el=s(E);At=o(el,"SPAN",{});var tl=s(At);f(xe.$$.fragment,tl),tl.forEach(r),el.forEach(r),lo=l(it),It=o(it,"SPAN",{});var rl=s(It);io=c(rl,"Helpful Utilities"),rl.forEach(r),it.forEach(r),Br=l(e),ct=o(e,"P",{});var al=s(ct);co=c(al,"Below are a variety of utility functions that \u{1F917} Accelerate provides, broken down by use-case."),al.forEach(r),Wr=l(e),I=o(e,"H2",{class:!0});var Aa=s(I);ne=o(Aa,"A",{id:!0,class:!0,href:!0});var ol=s(ne);Ut=o(ol,"SPAN",{});var sl=s(Ut);f(Te.$$.fragment,sl),sl.forEach(r),ol.forEach(r),po=l(Aa),Ot=o(Aa,"SPAN",{});var nl=s(Ot);mo=c(nl,"Data Classes"),nl.forEach(r),Aa.forEach(r),jr=l(e),dt=o(e,"P",{});var ll=s(dt);uo=c(ll,"These are basic dataclasses used throughout \u{1F917} Accelerate and they can be passed in as parameters."),ll.forEach(r),Jr=l(e),w=o(e,"DIV",{class:!0});var be=s(w);f(De.$$.fragment,be),fo=l(be),St=o(be,"P",{});var il=s(St);ho=c(il,"Represents a type of distributed environment."),il.forEach(r),vo=l(be),Rt=o(be,"P",{});var cl=s(Rt);go=c(cl,"Values:"),cl.forEach(r),_o=l(be),x=o(be,"UL",{});var A=s(x);pt=o(A,"LI",{});var Gn=s(pt);zt=o(Gn,"STRONG",{});var dl=s(zt);bo=c(dl,"NO"),dl.forEach(r),$o=c(Gn," \u2014 Not a distributed environment, just a single process."),Gn.forEach(r),yo=l(A),mt=o(A,"LI",{});var Hn=s(mt);Mt=o(Hn,"STRONG",{});var pl=s(Mt);Eo=c(pl,"MULTI_CPU"),pl.forEach(r),wo=c(Hn," \u2014 Distributed on multiple CPU nodes."),Hn.forEach(r),xo=l(A),ut=o(A,"LI",{});var qn=s(ut);Vt=o(qn,"STRONG",{});var ml=s(Vt);To=c(ml,"MULTI_GPU"),ml.forEach(r),Do=c(qn," \u2014 Distributed on multiple GPUs."),qn.forEach(r),Po=l(A),ft=o(A,"LI",{});var Fn=s(ft);Gt=o(Fn,"STRONG",{});var ul=s(Gt);ko=c(ul,"DEEPSPEED"),ul.forEach(r),No=c(Fn," \u2014 Using DeepSpeed."),Fn.forEach(r),Lo=l(A),ht=o(A,"LI",{});var Bn=s(ht);Ht=o(Bn,"STRONG",{});var fl=s(Ht);Co=c(fl,"TPU"),fl.forEach(r),Ao=c(Bn," \u2014 Distributed on TPUs."),Bn.forEach(r),A.forEach(r),be.forEach(r),Kr=l(e),T=o(e,"DIV",{class:!0});var $e=s(T);f(Pe.$$.fragment,$e),Io=l($e),qt=o($e,"P",{});var hl=s(qt);Uo=c(hl,"Represents a type of supported experiment tracker"),hl.forEach(r),Oo=l($e),Ft=o($e,"P",{});var vl=s(Ft);So=c(vl,"Values:"),vl.forEach(r),Ro=l($e),P=o($e,"UL",{});var ye=s(P);vt=o(ye,"LI",{});var Wn=s(vt);Bt=o(Wn,"STRONG",{});var gl=s(Bt);zo=c(gl,"ALL"),gl.forEach(r),Mo=c(Wn," \u2014 all available trackers in the environment that are supported"),Wn.forEach(r),Vo=l(ye),gt=o(ye,"LI",{});var jn=s(gt);Wt=o(jn,"STRONG",{});var _l=s(Wt);Go=c(_l,"TENSORBOARD"),_l.forEach(r),Ho=c(jn," \u2014 TensorBoard as an experiment tracker"),jn.forEach(r),qo=l(ye),_t=o(ye,"LI",{});var Jn=s(_t);jt=o(Jn,"STRONG",{});var bl=s(jt);Fo=c(bl,"WANDB"),bl.forEach(r),Bo=c(Jn," \u2014 wandb as an experiment tracker"),Jn.forEach(r),Wo=l(ye),bt=o(ye,"LI",{});var Kn=s(bt);Jt=o(Kn,"STRONG",{});var $l=s(Jt);jo=c($l,"COMETML"),$l.forEach(r),Jo=c(Kn," \u2014 comet_ml as an experiment tracker"),Kn.forEach(r),ye.forEach(r),$e.forEach(r),Qr=l(e),D=o(e,"DIV",{class:!0});var Ee=s(D);f(ke.$$.fragment,Ee),Ko=l(Ee),Kt=o(Ee,"P",{});var yl=s(Kt);Qo=c(yl,"Represents a type of precision used on floating point values"),yl.forEach(r),Xo=l(Ee),Qt=o(Ee,"P",{});var El=s(Qt);Yo=c(El,"Values:"),El.forEach(r),Zo=l(Ee),U=o(Ee,"UL",{});var kt=s(U);$t=o(kt,"LI",{});var Qn=s($t);Xt=o(Qn,"STRONG",{});var wl=s(Xt);es=c(wl,"NO"),wl.forEach(r),ts=c(Qn," \u2014 using full precision (FP32)"),Qn.forEach(r),rs=l(kt),yt=o(kt,"LI",{});var Xn=s(yt);Yt=o(Xn,"STRONG",{});var xl=s(Yt);as=c(xl,"FP16"),xl.forEach(r),os=c(Xn," \u2014 using half precision"),Xn.forEach(r),ss=l(kt),Et=o(kt,"LI",{});var Yn=s(Et);Zt=o(Yn,"STRONG",{});var Tl=s(Zt);ns=c(Tl,"BF16"),Tl.forEach(r),ls=c(Yn," \u2014 using brain floating point precision"),Yn.forEach(r),kt.forEach(r),Ee.forEach(r),Xr=l(e),O=o(e,"H2",{class:!0});var Ia=s(O);le=o(Ia,"A",{id:!0,class:!0,href:!0});var Dl=s(le);er=o(Dl,"SPAN",{});var Pl=s(er);f(Ne.$$.fragment,Pl),Pl.forEach(r),Dl.forEach(r),is=l(Ia),tr=o(Ia,"SPAN",{});var kl=s(tr);cs=c(kl,"Data Manipulation and Operations"),kl.forEach(r),Ia.forEach(r),Yr=l(e),ie=o(e,"P",{});var Ua=s(ie);ds=c(Ua,"These include data operations that mimic the same "),rr=o(Ua,"CODE",{});var Nl=s(rr);ps=c(Nl,"torch"),Nl.forEach(r),ms=c(Ua," ops but can be used on distributed processes."),Ua.forEach(r),Zr=l(e),S=o(e,"DIV",{class:!0});var Oa=s(S);f(Le.$$.fragment,Oa),us=l(Oa),ar=o(Oa,"P",{});var Ll=s(ar);fs=c(Ll,"Recursively broadcast tensor in a nested list/tuple/dictionary of tensors to all devices."),Ll.forEach(r),Oa.forEach(r),ea=l(e),R=o(e,"DIV",{class:!0});var Sa=s(R);f(Ce.$$.fragment,Sa),hs=l(Sa),or=o(Sa,"P",{});var Cl=s(or);vs=c(Cl,"Recursively concatenate the tensors in a nested list/tuple/dictionary of lists of tensors with the same shape."),Cl.forEach(r),Sa.forEach(r),ta=l(e),z=o(e,"DIV",{class:!0});var Ra=s(z);f(Ae.$$.fragment,Ra),gs=l(Ra),sr=o(Ra,"P",{});var Al=s(sr);_s=c(Al,"Recursively gather tensor in a nested list/tuple/dictionary of tensors from all devices."),Al.forEach(r),Ra.forEach(r),ra=l(e),M=o(e,"DIV",{class:!0});var za=s(M);f(Ie.$$.fragment,za),bs=l(za),nr=o(za,"P",{});var Il=s(nr);$s=c(Il,`Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so they
can safely be gathered.`),Il.forEach(r),za.forEach(r),aa=l(e),V=o(e,"DIV",{class:!0});var Ma=s(V);f(Ue.$$.fragment,Ma),ys=l(Ma),lr=o(Ma,"P",{});var Ul=s(lr);Es=c(Ul,`Recursively reduce the tensors in a nested list/tuple/dictionary of lists of tensors across all processes by the
mean of a given operation.`),Ul.forEach(r),Ma.forEach(r),oa=l(e),G=o(e,"DIV",{class:!0});var Va=s(G);f(Oe.$$.fragment,Va),ws=l(Va),ir=o(Va,"P",{});var Ol=s(ir);xs=c(Ol,"Recursively sends the elements in a nested list/tuple/dictionary of tensors to a given device."),Ol.forEach(r),Va.forEach(r),sa=l(e),H=o(e,"H2",{class:!0});var Ga=s(H);ce=o(Ga,"A",{id:!0,class:!0,href:!0});var Sl=s(ce);cr=o(Sl,"SPAN",{});var Rl=s(cr);f(Se.$$.fragment,Rl),Rl.forEach(r),Sl.forEach(r),Ts=l(Ga),dr=o(Ga,"SPAN",{});var zl=s(dr);Ds=c(zl,"Environment Checks"),zl.forEach(r),Ga.forEach(r),na=l(e),wt=o(e,"P",{});var Ml=s(wt);Ps=c(Ml,"These functionalities check the state of the current working environment including information about the operating system itself, what it can support, and if particular dependencies are installed."),Ml.forEach(r),la=l(e),q=o(e,"DIV",{class:!0});var Ha=s(q);f(Re.$$.fragment,Ha),ks=l(Ha),pr=o(Ha,"P",{});var Vl=s(pr);Ns=c(Vl,"Checks if bf16 is supported, optionally ignoring the TPU"),Vl.forEach(r),Ha.forEach(r),ia=l(e),F=o(e,"DIV",{class:!0});var qa=s(F);f(ze.$$.fragment,qa),Ls=l(qa),mr=o(qa,"P",{});var Gl=s(mr);Cs=c(Gl,"Compares the current PyTorch version to a given reference with an operation."),Gl.forEach(r),qa.forEach(r),ca=l(e),B=o(e,"DIV",{class:!0});var Fa=s(B);f(Me.$$.fragment,Fa),As=l(Fa),Ve=o(Fa,"P",{});var Ba=s(Ve);Is=c(Ba,"Checks if "),ur=o(Ba,"CODE",{});var Hl=s(ur);Us=c(Hl,"torch_xla"),Hl.forEach(r),Os=c(Ba," is installed and potentially if a TPU is in the environment"),Ba.forEach(r),Fa.forEach(r),da=l(e),W=o(e,"H2",{class:!0});var Wa=s(W);de=o(Wa,"A",{id:!0,class:!0,href:!0});var ql=s(de);fr=o(ql,"SPAN",{});var Fl=s(fr);f(Ge.$$.fragment,Fl),Fl.forEach(r),ql.forEach(r),Ss=l(Wa),hr=o(Wa,"SPAN",{});var Bl=s(hr);Rs=c(Bl,"Environment Configuration"),Bl.forEach(r),Wa.forEach(r),pa=l(e),j=o(e,"DIV",{class:!0});var ja=s(j);f(He.$$.fragment,ja),zs=l(ja),vr=o(ja,"P",{});var Wl=s(vr);Ms=c(Wl,`Creates and saves a basic cluster config to be used on a local machine with potentially multiple GPUs. Will also
set CPU if it is a CPU-only machine.`),Wl.forEach(r),ja.forEach(r),ma=l(e),pe=o(e,"P",{});var Ja=s(pe);Vs=c(Ja,"When setting up \u{1F917} Accelerate for the first time, rather than running "),gr=o(Ja,"CODE",{});var jl=s(gr);Gs=c(jl,"accelerate config"),jl.forEach(r),Hs=c(Ja," [~utils.write_basic_config] can be used as an alternative for quick configuration."),Ja.forEach(r),ua=l(e),J=o(e,"H2",{class:!0});var Ka=s(J);me=o(Ka,"A",{id:!0,class:!0,href:!0});var Jl=s(me);_r=o(Jl,"SPAN",{});var Kl=s(_r);f(qe.$$.fragment,Kl),Kl.forEach(r),Jl.forEach(r),qs=l(Ka),br=o(Ka,"SPAN",{});var Ql=s(br);Fs=c(Ql,"Memory"),Ql.forEach(r),Ka.forEach(r),fa=l(e),K=o(e,"DIV",{class:!0});var Qa=s(K);f(Fe.$$.fragment,Qa),Bs=l(Qa),$r=o(Qa,"P",{});var Xl=s($r);Ws=c(Xl,"Get the maximum memory available if nothing is passed, converts string to int otherwise."),Xl.forEach(r),Qa.forEach(r),ha=l(e),k=o(e,"DIV",{class:!0});var Nt=s(k);f(Be.$$.fragment,Nt),js=l(Nt),ue=o(Nt,"P",{});var Hr=s(ue);Js=c(Hr,"A basic decorator that will try to execute "),yr=o(Hr,"CODE",{});var Yl=s(yr);Ks=c(Yl,"function"),Yl.forEach(r),Qs=c(Hr,`. If it fails from exceptions related to out-of-memory or
CUDNN, the batch size is cut in half and passed to `),Er=o(Hr,"CODE",{});var Zl=s(Er);Xs=c(Zl,"function"),Zl.forEach(r),Hr.forEach(r),Ys=l(Nt),fe=o(Nt,"P",{});var qr=s(fe);wr=o(qr,"CODE",{});var ei=s(wr);Zs=c(ei,"function"),ei.forEach(r),en=c(qr," must take in a "),xr=o(qr,"CODE",{});var ti=s(xr);tn=c(ti,"batch_size"),ti.forEach(r),rn=c(qr," parameter as its first argument."),qr.forEach(r),Nt.forEach(r),va=l(e),Q=o(e,"H2",{class:!0});var Xa=s(Q);he=o(Xa,"A",{id:!0,class:!0,href:!0});var ri=s(he);Tr=o(ri,"SPAN",{});var ai=s(Tr);f(We.$$.fragment,ai),ai.forEach(r),ri.forEach(r),an=l(Xa),Dr=o(Xa,"SPAN",{});var oi=s(Dr);on=c(oi,"Modeling"),oi.forEach(r),Xa.forEach(r),ga=l(e),xt=o(e,"P",{});var si=s(xt);sn=c(si,"These utilities relate to interacting with PyTorch models"),si.forEach(r),_a=l(e),X=o(e,"DIV",{class:!0});var Ya=s(X);f(je.$$.fragment,Ya),nn=l(Ya),Pr=o(Ya,"P",{});var ni=s(Pr);ln=c(ni,"Extract a model from its distributed containers."),ni.forEach(r),Ya.forEach(r),ba=l(e),N=o(e,"DIV",{class:!0});var Lt=s(N);f(Je.$$.fragment,Lt),cn=l(Lt),kr=o(Lt,"P",{});var li=s(kr);dn=c(li,`Utility function that will scan a list of named modules and return the maximum size used by one full layer. The
definition of a layer being:`),li.forEach(r),pn=l(Lt),Ke=o(Lt,"UL",{});var Za=s(Ke);Nr=o(Za,"LI",{});var ii=s(Nr);mn=c(ii,"a module with no direct children (just parameters and buffers)"),ii.forEach(r),un=l(Za),Tt=o(Za,"LI",{});var Zn=s(Tt);fn=c(Zn,"a module whose class name is in the list "),Lr=o(Zn,"CODE",{});var ci=s(Lr);hn=c(ci,"no_split_module_classes"),ci.forEach(r),Zn.forEach(r),Za.forEach(r),Lt.forEach(r),$a=l(e),Y=o(e,"DIV",{class:!0});var eo=s(Y);f(Qe.$$.fragment,eo),vn=l(eo),Cr=o(eo,"P",{});var di=s(Cr);gn=c(di,"Offload a state dict in a given folder."),di.forEach(r),eo.forEach(r),ya=l(e),Z=o(e,"H2",{class:!0});var to=s(Z);ve=o(to,"A",{id:!0,class:!0,href:!0});var pi=s(ve);Ar=o(pi,"SPAN",{});var mi=s(Ar);f(Xe.$$.fragment,mi),mi.forEach(r),pi.forEach(r),_n=l(to),Ir=o(to,"SPAN",{});var ui=s(Ir);bn=c(ui,"Parallel"),ui.forEach(r),to.forEach(r),Ea=l(e),Dt=o(e,"P",{});var fi=s(Dt);$n=c(fi,"These include general utilities that should be used when working in parallel."),fi.forEach(r),wa=l(e),ee=o(e,"DIV",{class:!0});var ro=s(ee);f(Ye.$$.fragment,ro),yn=l(ro),Ur=o(ro,"P",{});var hi=s(Ur);En=c(hi,"Extract a model from its distributed containers."),hi.forEach(r),ro.forEach(r),xa=l(e),te=o(e,"DIV",{class:!0});var ao=s(te);f(Ze.$$.fragment,ao),wn=l(ao),et=o(ao,"P",{});var oo=s(et);xn=c(oo,"Save the data to disk. Use in place of "),Or=o(oo,"CODE",{});var vi=s(Or);Tn=c(vi,"torch.save()"),vi.forEach(r),Dn=c(oo,"."),oo.forEach(r),ao.forEach(r),Ta=l(e),L=o(e,"DIV",{class:!0});var Ct=s(L);f(tt.$$.fragment,Ct),Pn=l(Ct),Sr=o(Ct,"P",{});var gi=s(Sr);kn=c(gi,"Introduces a blocking point in the script, making sure all processes have reached this point before continuing."),gi.forEach(r),Nn=l(Ct),f(ge.$$.fragment,Ct),Ct.forEach(r),Da=l(e),re=o(e,"H2",{class:!0});var so=s(re);_e=o(so,"A",{id:!0,class:!0,href:!0});var _i=s(_e);Rr=o(_i,"SPAN",{});var bi=s(Rr);f(rt.$$.fragment,bi),bi.forEach(r),_i.forEach(r),Ln=l(so),zr=o(so,"SPAN",{});var $i=s(zr);Cn=c($i,"Random"),$i.forEach(r),so.forEach(r),Pa=l(e),Pt=o(e,"P",{});var yi=s(Pt);An=c(yi,"These utilities relate to setting and synchronizing of all the random states."),yi.forEach(r),ka=l(e),ae=o(e,"DIV",{class:!0});var no=s(ae);f(at.$$.fragment,no),In=l(no),C=o(no,"P",{});var we=s(C);Un=c(we,"Helper function for reproducible behavior to set the seed in "),Mr=o(we,"CODE",{});var Ei=s(Mr);On=c(Ei,"random"),Ei.forEach(r),Sn=c(we,", "),Vr=o(we,"CODE",{});var wi=s(Vr);Rn=c(wi,"numpy"),wi.forEach(r),zn=c(we,", "),Gr=o(we,"CODE",{});var xi=s(Gr);Mn=c(xi,"torch"),xi.forEach(r),Vn=c(we,"."),we.forEach(r),no.forEach(r),Na=l(e),ot=o(e,"DIV",{class:!0});var Ti=s(ot);f(st.$$.fragment,Ti),Ti.forEach(r),La=l(e),nt=o(e,"DIV",{class:!0});var Di=s(nt);f(lt.$$.fragment,Di),Di.forEach(r),this.h()},h(){m($,"name","hf:doc:metadata"),m($,"content",JSON.stringify(Oi)),m(E,"id","helpful-utilities"),m(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(E,"href","#helpful-utilities"),m(y,"class","relative group"),m(ne,"id","accelerate.DistributedType"),m(ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ne,"href","#accelerate.DistributedType"),m(I,"class","relative group"),m(w,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(T,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(D,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(le,"id","accelerate.utils.broadcast"),m(le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(le,"href","#accelerate.utils.broadcast"),m(O,"class","relative group"),m(S,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(R,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(V,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(G,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ce,"id","accelerate.utils.is_bf16_available"),m(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ce,"href","#accelerate.utils.is_bf16_available"),m(H,"class","relative group"),m(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(B,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(de,"id","accelerate.commands.config.default.write_basic_config"),m(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(de,"href","#accelerate.commands.config.default.write_basic_config"),m(W,"class","relative group"),m(j,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(me,"id","accelerate.utils.get_max_memory"),m(me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(me,"href","#accelerate.utils.get_max_memory"),m(J,"class","relative group"),m(K,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(k,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(he,"id","accelerate.utils.extract_model_from_parallel"),m(he,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(he,"href","#accelerate.utils.extract_model_from_parallel"),m(Q,"class","relative group"),m(X,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(N,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ve,"id","accelerate.utils.extract_model_from_parallel"),m(ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ve,"href","#accelerate.utils.extract_model_from_parallel"),m(Z,"class","relative group"),m(ee,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(te,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(L,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_e,"id","accelerate.utils.set_seed"),m(_e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(_e,"href","#accelerate.utils.set_seed"),m(re,"class","relative group"),m(ae,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,d){t(document.head,$),p(e,se,d),p(e,y,d),t(y,E),t(E,At),h(xe,At,null),t(y,lo),t(y,It),t(It,io),p(e,Br,d),p(e,ct,d),t(ct,co),p(e,Wr,d),p(e,I,d),t(I,ne),t(ne,Ut),h(Te,Ut,null),t(I,po),t(I,Ot),t(Ot,mo),p(e,jr,d),p(e,dt,d),t(dt,uo),p(e,Jr,d),p(e,w,d),h(De,w,null),t(w,fo),t(w,St),t(St,ho),t(w,vo),t(w,Rt),t(Rt,go),t(w,_o),t(w,x),t(x,pt),t(pt,zt),t(zt,bo),t(pt,$o),t(x,yo),t(x,mt),t(mt,Mt),t(Mt,Eo),t(mt,wo),t(x,xo),t(x,ut),t(ut,Vt),t(Vt,To),t(ut,Do),t(x,Po),t(x,ft),t(ft,Gt),t(Gt,ko),t(ft,No),t(x,Lo),t(x,ht),t(ht,Ht),t(Ht,Co),t(ht,Ao),p(e,Kr,d),p(e,T,d),h(Pe,T,null),t(T,Io),t(T,qt),t(qt,Uo),t(T,Oo),t(T,Ft),t(Ft,So),t(T,Ro),t(T,P),t(P,vt),t(vt,Bt),t(Bt,zo),t(vt,Mo),t(P,Vo),t(P,gt),t(gt,Wt),t(Wt,Go),t(gt,Ho),t(P,qo),t(P,_t),t(_t,jt),t(jt,Fo),t(_t,Bo),t(P,Wo),t(P,bt),t(bt,Jt),t(Jt,jo),t(bt,Jo),p(e,Qr,d),p(e,D,d),h(ke,D,null),t(D,Ko),t(D,Kt),t(Kt,Qo),t(D,Xo),t(D,Qt),t(Qt,Yo),t(D,Zo),t(D,U),t(U,$t),t($t,Xt),t(Xt,es),t($t,ts),t(U,rs),t(U,yt),t(yt,Yt),t(Yt,as),t(yt,os),t(U,ss),t(U,Et),t(Et,Zt),t(Zt,ns),t(Et,ls),p(e,Xr,d),p(e,O,d),t(O,le),t(le,er),h(Ne,er,null),t(O,is),t(O,tr),t(tr,cs),p(e,Yr,d),p(e,ie,d),t(ie,ds),t(ie,rr),t(rr,ps),t(ie,ms),p(e,Zr,d),p(e,S,d),h(Le,S,null),t(S,us),t(S,ar),t(ar,fs),p(e,ea,d),p(e,R,d),h(Ce,R,null),t(R,hs),t(R,or),t(or,vs),p(e,ta,d),p(e,z,d),h(Ae,z,null),t(z,gs),t(z,sr),t(sr,_s),p(e,ra,d),p(e,M,d),h(Ie,M,null),t(M,bs),t(M,nr),t(nr,$s),p(e,aa,d),p(e,V,d),h(Ue,V,null),t(V,ys),t(V,lr),t(lr,Es),p(e,oa,d),p(e,G,d),h(Oe,G,null),t(G,ws),t(G,ir),t(ir,xs),p(e,sa,d),p(e,H,d),t(H,ce),t(ce,cr),h(Se,cr,null),t(H,Ts),t(H,dr),t(dr,Ds),p(e,na,d),p(e,wt,d),t(wt,Ps),p(e,la,d),p(e,q,d),h(Re,q,null),t(q,ks),t(q,pr),t(pr,Ns),p(e,ia,d),p(e,F,d),h(ze,F,null),t(F,Ls),t(F,mr),t(mr,Cs),p(e,ca,d),p(e,B,d),h(Me,B,null),t(B,As),t(B,Ve),t(Ve,Is),t(Ve,ur),t(ur,Us),t(Ve,Os),p(e,da,d),p(e,W,d),t(W,de),t(de,fr),h(Ge,fr,null),t(W,Ss),t(W,hr),t(hr,Rs),p(e,pa,d),p(e,j,d),h(He,j,null),t(j,zs),t(j,vr),t(vr,Ms),p(e,ma,d),p(e,pe,d),t(pe,Vs),t(pe,gr),t(gr,Gs),t(pe,Hs),p(e,ua,d),p(e,J,d),t(J,me),t(me,_r),h(qe,_r,null),t(J,qs),t(J,br),t(br,Fs),p(e,fa,d),p(e,K,d),h(Fe,K,null),t(K,Bs),t(K,$r),t($r,Ws),p(e,ha,d),p(e,k,d),h(Be,k,null),t(k,js),t(k,ue),t(ue,Js),t(ue,yr),t(yr,Ks),t(ue,Qs),t(ue,Er),t(Er,Xs),t(k,Ys),t(k,fe),t(fe,wr),t(wr,Zs),t(fe,en),t(fe,xr),t(xr,tn),t(fe,rn),p(e,va,d),p(e,Q,d),t(Q,he),t(he,Tr),h(We,Tr,null),t(Q,an),t(Q,Dr),t(Dr,on),p(e,ga,d),p(e,xt,d),t(xt,sn),p(e,_a,d),p(e,X,d),h(je,X,null),t(X,nn),t(X,Pr),t(Pr,ln),p(e,ba,d),p(e,N,d),h(Je,N,null),t(N,cn),t(N,kr),t(kr,dn),t(N,pn),t(N,Ke),t(Ke,Nr),t(Nr,mn),t(Ke,un),t(Ke,Tt),t(Tt,fn),t(Tt,Lr),t(Lr,hn),p(e,$a,d),p(e,Y,d),h(Qe,Y,null),t(Y,vn),t(Y,Cr),t(Cr,gn),p(e,ya,d),p(e,Z,d),t(Z,ve),t(ve,Ar),h(Xe,Ar,null),t(Z,_n),t(Z,Ir),t(Ir,bn),p(e,Ea,d),p(e,Dt,d),t(Dt,$n),p(e,wa,d),p(e,ee,d),h(Ye,ee,null),t(ee,yn),t(ee,Ur),t(Ur,En),p(e,xa,d),p(e,te,d),h(Ze,te,null),t(te,wn),t(te,et),t(et,xn),t(et,Or),t(Or,Tn),t(et,Dn),p(e,Ta,d),p(e,L,d),h(tt,L,null),t(L,Pn),t(L,Sr),t(Sr,kn),t(L,Nn),h(ge,L,null),p(e,Da,d),p(e,re,d),t(re,_e),t(_e,Rr),h(rt,Rr,null),t(re,Ln),t(re,zr),t(zr,Cn),p(e,Pa,d),p(e,Pt,d),t(Pt,An),p(e,ka,d),p(e,ae,d),h(at,ae,null),t(ae,In),t(ae,C),t(C,Un),t(C,Mr),t(Mr,On),t(C,Sn),t(C,Vr),t(Vr,Rn),t(C,zn),t(C,Gr),t(Gr,Mn),t(C,Vn),p(e,Na,d),p(e,ot,d),h(st,ot,null),p(e,La,d),p(e,nt,d),h(lt,nt,null),Ca=!0},p(e,[d]){const it={};d&2&&(it.$$scope={dirty:d,ctx:e}),ge.$set(it)},i(e){Ca||(v(xe.$$.fragment,e),v(Te.$$.fragment,e),v(De.$$.fragment,e),v(Pe.$$.fragment,e),v(ke.$$.fragment,e),v(Ne.$$.fragment,e),v(Le.$$.fragment,e),v(Ce.$$.fragment,e),v(Ae.$$.fragment,e),v(Ie.$$.fragment,e),v(Ue.$$.fragment,e),v(Oe.$$.fragment,e),v(Se.$$.fragment,e),v(Re.$$.fragment,e),v(ze.$$.fragment,e),v(Me.$$.fragment,e),v(Ge.$$.fragment,e),v(He.$$.fragment,e),v(qe.$$.fragment,e),v(Fe.$$.fragment,e),v(Be.$$.fragment,e),v(We.$$.fragment,e),v(je.$$.fragment,e),v(Je.$$.fragment,e),v(Qe.$$.fragment,e),v(Xe.$$.fragment,e),v(Ye.$$.fragment,e),v(Ze.$$.fragment,e),v(tt.$$.fragment,e),v(ge.$$.fragment,e),v(rt.$$.fragment,e),v(at.$$.fragment,e),v(st.$$.fragment,e),v(lt.$$.fragment,e),Ca=!0)},o(e){g(xe.$$.fragment,e),g(Te.$$.fragment,e),g(De.$$.fragment,e),g(Pe.$$.fragment,e),g(ke.$$.fragment,e),g(Ne.$$.fragment,e),g(Le.$$.fragment,e),g(Ce.$$.fragment,e),g(Ae.$$.fragment,e),g(Ie.$$.fragment,e),g(Ue.$$.fragment,e),g(Oe.$$.fragment,e),g(Se.$$.fragment,e),g(Re.$$.fragment,e),g(ze.$$.fragment,e),g(Me.$$.fragment,e),g(Ge.$$.fragment,e),g(He.$$.fragment,e),g(qe.$$.fragment,e),g(Fe.$$.fragment,e),g(Be.$$.fragment,e),g(We.$$.fragment,e),g(je.$$.fragment,e),g(Je.$$.fragment,e),g(Qe.$$.fragment,e),g(Xe.$$.fragment,e),g(Ye.$$.fragment,e),g(Ze.$$.fragment,e),g(tt.$$.fragment,e),g(ge.$$.fragment,e),g(rt.$$.fragment,e),g(at.$$.fragment,e),g(st.$$.fragment,e),g(lt.$$.fragment,e),Ca=!1},d(e){r($),e&&r(se),e&&r(y),_(xe),e&&r(Br),e&&r(ct),e&&r(Wr),e&&r(I),_(Te),e&&r(jr),e&&r(dt),e&&r(Jr),e&&r(w),_(De),e&&r(Kr),e&&r(T),_(Pe),e&&r(Qr),e&&r(D),_(ke),e&&r(Xr),e&&r(O),_(Ne),e&&r(Yr),e&&r(ie),e&&r(Zr),e&&r(S),_(Le),e&&r(ea),e&&r(R),_(Ce),e&&r(ta),e&&r(z),_(Ae),e&&r(ra),e&&r(M),_(Ie),e&&r(aa),e&&r(V),_(Ue),e&&r(oa),e&&r(G),_(Oe),e&&r(sa),e&&r(H),_(Se),e&&r(na),e&&r(wt),e&&r(la),e&&r(q),_(Re),e&&r(ia),e&&r(F),_(ze),e&&r(ca),e&&r(B),_(Me),e&&r(da),e&&r(W),_(Ge),e&&r(pa),e&&r(j),_(He),e&&r(ma),e&&r(pe),e&&r(ua),e&&r(J),_(qe),e&&r(fa),e&&r(K),_(Fe),e&&r(ha),e&&r(k),_(Be),e&&r(va),e&&r(Q),_(We),e&&r(ga),e&&r(xt),e&&r(_a),e&&r(X),_(je),e&&r(ba),e&&r(N),_(Je),e&&r($a),e&&r(Y),_(Qe),e&&r(ya),e&&r(Z),_(Xe),e&&r(Ea),e&&r(Dt),e&&r(wa),e&&r(ee),_(Ye),e&&r(xa),e&&r(te),_(Ze),e&&r(Ta),e&&r(L),_(tt),_(ge),e&&r(Da),e&&r(re),_(rt),e&&r(Pa),e&&r(Pt),e&&r(ka),e&&r(ae),_(at),e&&r(Na),e&&r(ot),_(st),e&&r(La),e&&r(nt),_(lt)}}}const Oi={local:"helpful-utilities",sections:[{local:"accelerate.DistributedType",title:"Data Classes"},{local:"accelerate.utils.broadcast",title:"Data Manipulation and Operations"},{local:"accelerate.utils.is_bf16_available",title:"Environment Checks"},{local:"accelerate.commands.config.default.write_basic_config",title:"Environment Configuration"},{local:"accelerate.utils.get_max_memory",title:"Memory"},{local:"accelerate.utils.extract_model_from_parallel",title:"Modeling"},{local:"accelerate.utils.extract_model_from_parallel",title:"Parallel"},{local:"accelerate.utils.set_seed",title:"Random"}],title:"Helpful Utilities"};function Si(Fr){return Ci(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Gi extends Pi{constructor($){super();ki(this,$,Si,Ui,Ni,{})}}export{Gi as default,Oi as metadata};
