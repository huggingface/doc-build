import{S as Zs,i as en,s as tn,e as r,k as d,w as u,t as n,M as an,c as o,d as a,m as h,a as s,x as g,h as l,b as i,F as t,g as p,y as v,q as _,o as b,B as $,v as rn}from"../chunks/vendor-19e06bd2.js";import{T as Mo}from"../chunks/Tip-f0fa2d82.js";import{D as x}from"../chunks/Docstring-395e5a9c.js";import{I as B}from"../chunks/IconCopyLink-3c713d38.js";function on(oe){let m,D,f,y,T;return{c(){m=r("p"),D=n("This does not support "),f=r("code"),y=n("BatchSampler"),T=n(" with varying batch size yet.")},l(w){m=o(w,"P",{});var E=s(m);D=l(E,"This does not support "),f=o(E,"CODE",{});var L=s(f);y=l(L,"BatchSampler"),L.forEach(a),T=l(E," with varying batch size yet."),E.forEach(a)},m(w,E){p(w,m,E),t(m,D),t(m,f),t(f,y),t(m,T)},d(w){w&&a(m)}}}function sn(oe){let m,D,f,y,T;return{c(){m=r("p"),D=n("This does not support "),f=r("code"),y=n("BatchSampler"),T=n(" with varying batch size yet.")},l(w){m=o(w,"P",{});var E=s(m);D=l(E,"This does not support "),f=o(E,"CODE",{});var L=s(f);y=l(L,"BatchSampler"),L.forEach(a),T=l(E," with varying batch size yet."),E.forEach(a)},m(w,E){p(w,m,E),t(m,D),t(m,f),t(f,y),t(m,T)},d(w){w&&a(m)}}}function nn(oe){let m,D;return{c(){m=r("p"),D=n("Make sure all processes will reach this instruction otherwise one of your processes will hang forever.")},l(f){m=o(f,"P",{});var y=s(m);D=l(y,"Make sure all processes will reach this instruction otherwise one of your processes will hang forever."),y.forEach(a)},m(f,y){p(f,m,y),t(m,D)},d(f){f&&a(m)}}}function ln(oe){let m,D,f,y,T,w,E,L,Ma,ta,G,se,nt,we,ja,lt,Xa,aa,q,Ee,Ja,ct,Ka,ra,F,ne,it,De,Qa,dt,Ya,oa,le,Za,ht,er,tr,sa,P,Se,ar,xe,rr,pt,or,sr,nr,R,lr,mt,cr,ir,ft,dr,hr,pr,ce,na,W,ie,ut,Te,mr,gt,fr,la,V,Pe,ur,Ae,gr,vt,vr,_r,ca,H,de,_t,ze,br,bt,$r,ia,N,Ie,yr,k,wr,$t,Er,Dr,yt,Sr,xr,wt,Tr,Pr,Ar,he,da,M,pe,Et,Le,zr,Dt,Ir,ha,j,Ne,Lr,S,Nr,St,kr,Or,xt,Cr,Ur,Tt,Br,Gr,Pt,qr,Fr,At,Rr,Wr,pa,X,me,zt,ke,Vr,It,Hr,ma,J,fe,Lt,Oe,Mr,Nt,jr,fa,K,Ce,Xr,Q,Jr,Ue,Kr,Qr,kt,Yr,Zr,ua,Y,ue,Ot,Be,eo,Ct,to,ga,A,Ge,ao,Ut,ro,oo,Bt,so,no,z,Qe,Gt,lo,co,io,Ye,qt,ho,po,mo,Ze,Ft,fo,uo,go,et,Rt,vo,_o,bo,tt,Wt,$o,yo,va,Z,ge,Vt,qe,wo,Ht,Eo,_a,ee,Fe,Do,Mt,So,ba,te,Re,xo,jt,To,$a,ae,We,Po,Xt,Ao,ya,re,Ve,zo,O,Io,Jt,Lo,No,Kt,ko,Oo,Qt,Co,Uo,wa,He,Me,Ea,je,Xe,Da,C,Je,Bo,Yt,Go,qo,ve,Sa;return w=new B({}),we=new B({}),Ee=new x({props:{name:"class accelerate.optimizer.AcceleratedOptimizer",anchor:"accelerate.optimizer.AcceleratedOptimizer",parameters:[{name:"optimizer",val:""},{name:"device_placement",val:" = True"},{name:"scaler",val:" = None"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/optimizer.py#L39",parametersDescription:[{anchor:"accelerate.optimizer.AcceleratedOptimizer.optimizer",description:`<strong>optimizer</strong> (<code>torch.optim.optimizer.Optimizer</code>) &#x2014;
The optimizer to wrap.`,name:"optimizer"},{anchor:"accelerate.optimizer.AcceleratedOptimizer.device_placement",description:`<strong>device_placement</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not the optimizer should handle device placement. If so, it will place the state dictionary of
<code>optimizer</code> on the right device.`,name:"device_placement"},{anchor:"accelerate.optimizer.AcceleratedOptimizer.scaler",description:`<strong>scaler</strong> (<code>torch.cuda.amp.grad_scaler.GradScaler</code>, <em>optional</em>) &#x2014;
The scaler to use in the step function if training with mixed precision.`,name:"scaler"}]}}),De=new B({}),Se=new x({props:{name:"accelerate.data_loader.prepare_data_loader",anchor:"accelerate.data_loader.prepare_data_loader",parameters:[{name:"dataloader",val:": DataLoader"},{name:"device",val:": typing.Optional[torch.device] = None"},{name:"num_processes",val:": typing.Optional[int] = None"},{name:"process_index",val:": typing.Optional[int] = None"},{name:"split_batches",val:": bool = False"},{name:"put_on_device",val:": bool = False"},{name:"rng_types",val:": typing.Union[typing.List[typing.Union[str, accelerate.utils.RNGType]], NoneType] = None"},{name:"dispatch_batches",val:": typing.Optional[bool] = None"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/data_loader.py#L417",parametersDescription:[{anchor:"accelerate.data_loader.prepare_data_loader.dataloader",description:`<strong>dataloader</strong> (<code>torch.utils.data.dataloader.DataLoader</code>) &#x2014;
The data loader to split across several devices.`,name:"dataloader"},{anchor:"accelerate.data_loader.prepare_data_loader.device",description:`<strong>device</strong> (<code>torch.device</code>) &#x2014;
The target device for the returned <code>DataLoader</code>.`,name:"device"},{anchor:"accelerate.data_loader.prepare_data_loader.num_processes",description:`<strong>num_processes</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The number of processes running concurrently. Will default to the value given by
<a href="/docs/accelerate/main/en/internal#accelerate.state.AcceleratorState">AcceleratorState</a>.`,name:"num_processes"},{anchor:"accelerate.data_loader.prepare_data_loader.process_index",description:`<strong>process_index</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The index of the current process. Will default to the value given by <a href="/docs/accelerate/main/en/internal#accelerate.state.AcceleratorState">AcceleratorState</a>.`,name:"process_index"},{anchor:"accelerate.data_loader.prepare_data_loader.split_batches",description:`<strong>split_batches</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether the resulting <code>DataLoader</code> should split the batches of the original data loader across devices or
yield full batches (in which case it will yield batches starting at the <code>process_index</code>-th and advancing of
<code>num_processes</code> batches at each iteration).</p>
<p>Another way to see this is that the observed batch size will be the same as the initial <code>dataloader</code> if
this option is set to <code>True</code>, the batch size of the initial <code>dataloader</code> multiplied by <code>num_processes</code>
otherwise.</p>
<p>Setting this option to <code>True</code> requires that the batch size of the <code>dataloader</code> is a round multiple of
<code>batch_size</code>.`,name:"split_batches"},{anchor:"accelerate.data_loader.prepare_data_loader.put_on_device",description:`<strong>put_on_device</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to put the batches on <code>device</code> (only works if the batches are nested list, tuples or
dictionaries of tensors).`,name:"put_on_device"},{anchor:"accelerate.data_loader.prepare_data_loader.rng_types",description:`<strong>rng_types</strong> (list of <code>str</code> or <code>RNGType</code> &#x2014;
The list of random number generators to synchronize at the beginning of each iteration. Should be one or
several of:</p>
<ul>
<li><code>&quot;torch&quot;</code>: the base torch random number generator</li>
<li><code>&quot;cuda&quot;</code>: the CUDA random number generator (GPU only)</li>
<li><code>&quot;xla&quot;</code>: the XLA random number generator (TPU only)</li>
<li><code>&quot;generator&quot;</code>: the <code>torch.Generator</code> of the sampler (or batch sampler if there is no sampler in your
dataloader) or of the iterable dataset (if it exists) if the underlying dataset is of that type.</li>
</ul>`,name:"rng_types"},{anchor:"accelerate.data_loader.prepare_data_loader.dispatch_batches",description:`<strong>dispatch_batches</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
If set to <code>True</code>, the datalaoder prepared is only iterated through on the main process and then the batches
are split and broadcast to each process. Will default to <code>True</code> when the underlying dataset is an
<code>IterableDataset</code>, <code>False</code> otherwise.`,name:"dispatch_batches"}],returnDescription:`
<p>A new data loader that will yield the portion of the batches</p>
`,returnType:`
<p><code>torch.utils.data.dataloader.DataLoader</code></p>
`}}),ce=new Mo({props:{warning:!0,$$slots:{default:[on]},$$scope:{ctx:oe}}}),Te=new B({}),Pe=new x({props:{name:"class accelerate.data_loader.DataLoaderShard",anchor:"accelerate.data_loader.DataLoaderShard",parameters:[{name:"*args",val:""},{name:"**kwds",val:""}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/data_loader.py#L270",parametersDescription:[{anchor:"accelerate.data_loader.DataLoaderShard.dataset",description:`<strong>dataset</strong> (<code>torch.utils.data.dataset.Dataset</code>) &#x2014;
The dataset to use to build this datalaoder.`,name:"dataset"},{anchor:"accelerate.data_loader.DataLoaderShard.device",description:`<strong>device</strong> (<code>torch.device</code>, <em>optional</em>) &#x2014;
If passed, the device to put all batches on.`,name:"device"},{anchor:"accelerate.data_loader.DataLoaderShard.rng_types",description:`<strong>rng_types</strong> (list of <code>str</code> or <code>RNGType</code> &#x2014;
The list of random number generators to synchronize at the beginning of each iteration. Should be one or
several of:</p>
<ul>
<li><code>&quot;torch&quot;</code>: the base torch random number generator</li>
<li><code>&quot;cuda&quot;</code>: the CUDA random number generator (GPU only)</li>
<li><code>&quot;xla&quot;</code>: the XLA random number generator (TPU only)</li>
<li><code>&quot;generator&quot;</code>: an optional <code>torch.Generator</code></li>
</ul>`,name:"rng_types"},{anchor:"accelerate.data_loader.DataLoaderShard.generator",description:`<strong>generator</strong> (<code>torch.Generator</code>, <em>optional</em>) &#x2014;
A random number generator to keep synchronized across processes.
kwargs &#x2014;
All other keyword arguments to pass to the regular <code>DataLoader</code> initialization.`,name:"generator"}]}}),ze=new B({}),Ie=new x({props:{name:"class accelerate.data_loader.BatchSamplerShard",anchor:"accelerate.data_loader.BatchSamplerShard",parameters:[{name:"*args",val:""},{name:"**kwds",val:""}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/data_loader.py#L68",parametersDescription:[{anchor:"accelerate.data_loader.BatchSamplerShard.batch_sampler",description:`<strong>batch_sampler</strong> (<code>torch.utils.data.sampler.BatchSampler</code>) &#x2014;
The batch sampler to split in several shards.`,name:"batch_sampler"},{anchor:"accelerate.data_loader.BatchSamplerShard.num_processes",description:`<strong>num_processes</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
The number of processes running concurrently.`,name:"num_processes"},{anchor:"accelerate.data_loader.BatchSamplerShard.process_index",description:`<strong>process_index</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The index of the current process.`,name:"process_index"},{anchor:"accelerate.data_loader.BatchSamplerShard.split_batches",description:`<strong>split_batches</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether the shards should be created by splitting a batch to give a piece of it on each process, or by
yielding different full batches on each process.</p>
<p>On two processes with a sampler of <code>[[0, 1, 2, 3], [4, 5, 6, 7]]</code>, this will result in:</p>
<ul>
<li>the sampler on process 0 to yield <code>[0, 1, 2, 3]</code> and the sampler on process 1 to yield <code>[4, 5, 6, 7]</code> if
this argument is set to <code>False</code>.</li>
<li>the sampler on process 0 to yield <code>[0, 1]</code> then <code>[4, 5]</code> and the sampler on process 1 to yield <code>[2, 3]</code>
then <code>[6, 7]</code> if this argument is set to <code>True</code>.</li>
</ul>`,name:"split_batches"}]}}),he=new Mo({props:{warning:!0,$$slots:{default:[sn]},$$scope:{ctx:oe}}}),Le=new B({}),Ne=new x({props:{name:"class accelerate.data_loader.IterableDatasetShard",anchor:"accelerate.data_loader.IterableDatasetShard",parameters:[{name:"*args",val:""},{name:"**kwds",val:""}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/data_loader.py#L189",parametersDescription:[{anchor:"accelerate.data_loader.IterableDatasetShard.dataset",description:`<strong>dataset</strong> (<code>torch.utils.data.dataset.IterableDataset</code>) &#x2014;
The batch sampler to split in several shards.`,name:"dataset"},{anchor:"accelerate.data_loader.IterableDatasetShard.batch_size",description:`<strong>batch_size</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
The size of the batches per shard (if <code>split_batches=False</code>) or the size of the batches (if
<code>split_batches=True</code>).`,name:"batch_size"},{anchor:"accelerate.data_loader.IterableDatasetShard.drop_last",description:`<strong>drop_last</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to drop the last incomplete batch or complete the last batches by using the samples from the
beginning.`,name:"drop_last"},{anchor:"accelerate.data_loader.IterableDatasetShard.num_processes",description:`<strong>num_processes</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
The number of processes running concurrently.`,name:"num_processes"},{anchor:"accelerate.data_loader.IterableDatasetShard.process_index",description:`<strong>process_index</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The index of the current process.`,name:"process_index"},{anchor:"accelerate.data_loader.IterableDatasetShard.split_batches",description:`<strong>split_batches</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether the shards should be created by splitting a batch to give a piece of it on each process, or by
yielding different full batches on each process.</p>
<p>On two processes with an iterable dataset yielding of <code>[0, 1, 2, 3, 4, 5, 6, 7]</code>, this will result in:</p>
<ul>
<li>the shard on process 0 to yield <code>[0, 1, 2, 3]</code> and the shard on process 1 to yield <code>[4, 5, 6, 7]</code> if this
argument is set to <code>False</code>.</li>
<li>the shard on process 0 to yield <code>[0, 1, 4, 5]</code> and the sampler on process 1 to yield <code>[2, 3, 6, 7]</code> if
this argument is set to <code>True</code>.</li>
</ul>`,name:"split_batches"}]}}),ke=new B({}),Oe=new B({}),Ce=new x({props:{name:"class accelerate.state.AcceleratorState",anchor:"accelerate.state.AcceleratorState",parameters:[{name:"mixed_precision",val:": str = None"},{name:"cpu",val:": bool = False"},{name:"deepspeed_plugin",val:" = None"},{name:"_from_accelerator",val:": bool = False"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/state.py#L128",parametersDescription:[{anchor:"accelerate.state.AcceleratorState.-",description:"<strong>-</strong> <strong>device</strong> (<code>torch.device</code>) &#x2014; The device to use. &#x2014;",name:"-"},{anchor:"accelerate.state.AcceleratorState.-",description:`<strong>-</strong> <strong>distributed_type</strong> (<code>~accelerate.state.DistributedType</code>) &#x2014; The type of distributed environment currently &#x2014;
in use.`,name:"-"},{anchor:"accelerate.state.AcceleratorState.-",description:"<strong>-</strong> <strong>num_processes</strong> (<code>int</code>) &#x2014; The number of processes currently launched in parallel. &#x2014;",name:"-"},{anchor:"accelerate.state.AcceleratorState.-",description:"<strong>-</strong> <strong>process_index</strong> (<code>int</code>) &#x2014; The index of the current process. &#x2014;",name:"-"},{anchor:"accelerate.state.AcceleratorState.-",description:"<strong>-</strong> <strong>local_process_index</strong> (<code>int</code>) &#x2014; The index of the current process on the current server. &#x2014;",name:"-"},{anchor:"accelerate.state.AcceleratorState.-",description:`<strong>-</strong> <strong>mixed_precision</strong> (<code>str</code>) &#x2014; Whether or not the current script will use mixed precision. If you are using &#x2014;
mixed precision, define if you want to use FP16 or BF16 (bfloat16) as the floating point.`,name:"-"}]}}),Be=new B({}),Ge=new x({props:{name:"class accelerate.DistributedType",anchor:"accelerate.DistributedType",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/state.py#L74"}}),qe=new B({}),Fe=new x({props:{name:"accelerate.utils.extract_model_from_parallel",anchor:"accelerate.utils.extract_model_from_parallel",parameters:[{name:"model",val:""}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils.py#L302",parametersDescription:[{anchor:"accelerate.utils.extract_model_from_parallel.model",description:"<strong>model</strong> (<code>torch.nn.Module</code>) &#x2014; The model to extract.",name:"model"}],returnDescription:`
<p>The extracted model.</p>
`,returnType:`
<p><code>torch.nn.Module</code></p>
`}}),Re=new x({props:{name:"accelerate.utils.gather",anchor:"accelerate.utils.gather",parameters:[{name:"tensor",val:""}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils.py#L347",parametersDescription:[{anchor:"accelerate.utils.gather.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to gather.`,name:"tensor"}],returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors sent to the proper device.</p>
`}}),We=new x({props:{name:"accelerate.utils.send_to_device",anchor:"accelerate.utils.send_to_device",parameters:[{name:"tensor",val:""},{name:"device",val:""}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils.py#L197",parametersDescription:[{anchor:"accelerate.utils.send_to_device.tensor",description:`<strong>tensor</strong> (nested list/tuple/dictionary of <code>torch.Tensor</code>) &#x2014;
The data to send to a given device.`,name:"tensor"},{anchor:"accelerate.utils.send_to_device.device",description:`<strong>device</strong> (<code>torch.device</code>) &#x2014;
The device to send the data to.`,name:"device"}],returnDescription:`
<p>The same data structure as <code>tensor</code> with all tensors sent to the proper device.</p>
`}}),Ve=new x({props:{name:"accelerate.utils.set_seed",anchor:"accelerate.utils.set_seed",parameters:[{name:"seed",val:": int"},{name:"device_specific",val:": bool = False"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils.py#L67",parametersDescription:[{anchor:"accelerate.utils.set_seed.seed",description:"<strong>seed</strong> (<code>int</code>) &#x2014; The seed to set.",name:"seed"},{anchor:"accelerate.utils.set_seed.device_specific",description:`<strong>device_specific</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to differ the seed on each device slightly with <code>self.process_index</code>.`,name:"device_specific"}]}}),Me=new x({props:{name:"accelerate.utils.synchronize_rng_state",anchor:"accelerate.utils.synchronize_rng_state",parameters:[{name:"rng_type",val:": typing.Optional[accelerate.utils.RNGType] = None"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils.py#L87"}}),Xe=new x({props:{name:"accelerate.synchronize_rng_states",anchor:"accelerate.synchronize_rng_states",parameters:[{name:"rng_types",val:": typing.List[typing.Union[str, accelerate.utils.RNGType]]"},{name:"generator",val:": typing.Optional[torch._C.Generator] = None"}],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils.py#L122"}}),Je=new x({props:{name:"accelerate.utils.wait_for_everyone",anchor:"accelerate.utils.wait_for_everyone",parameters:[],source:"https://github.com/huggingface/accelerate/blob/main/src/accelerate/utils.py#L571"}}),ve=new Mo({props:{warning:!0,$$slots:{default:[nn]},$$scope:{ctx:oe}}}),{c(){m=r("meta"),D=d(),f=r("h1"),y=r("a"),T=r("span"),u(w.$$.fragment),E=d(),L=r("span"),Ma=n("Internals"),ta=d(),G=r("h2"),se=r("a"),nt=r("span"),u(we.$$.fragment),ja=d(),lt=r("span"),Xa=n("Optimizer"),aa=d(),q=r("div"),u(Ee.$$.fragment),Ja=d(),ct=r("p"),Ka=n("Internal wrapper around a torch optimizer."),ra=d(),F=r("h2"),ne=r("a"),it=r("span"),u(De.$$.fragment),Qa=d(),dt=r("span"),Ya=n("DataLoader"),oa=d(),le=r("p"),Za=n("The main work on your PyTorch "),ht=r("code"),er=n("DataLoader"),tr=n(" is done by the following function:"),sa=d(),P=r("div"),u(Se.$$.fragment),ar=d(),xe=r("p"),rr=n("Wraps a PyTorch "),pt=r("code"),or=n("DataLoader"),sr=n(" to generate batches for one of the processes only."),nr=d(),R=r("p"),lr=n("Depending on the value of the "),mt=r("code"),cr=n("drop_last"),ir=n(" attribute of the "),ft=r("code"),dr=n("dataloader"),hr=n(` passed, it will either stop the iteration
at the first batch that would be too small / not present on all processes or loop with indices from the beginning.`),pr=d(),u(ce.$$.fragment),na=d(),W=r("h3"),ie=r("a"),ut=r("span"),u(Te.$$.fragment),mr=d(),gt=r("span"),fr=n("BatchSamplerShard"),la=d(),V=r("div"),u(Pe.$$.fragment),ur=d(),Ae=r("p"),gr=n("Subclass of a PyTorch "),vt=r("code"),vr=n("DataLoader"),_r=n(" that will deal with device placement and current distributed setup."),ca=d(),H=r("h3"),de=r("a"),_t=r("span"),u(ze.$$.fragment),br=d(),bt=r("span"),$r=n("BatchSamplerShard"),ia=d(),N=r("div"),u(Ie.$$.fragment),yr=d(),k=r("p"),wr=n("Wraps a PyTorch "),$t=r("code"),Er=n("BatchSampler"),Dr=n(` to generate batches for one of the processes only. Instances of this class will
always yield a number of batches that is a round multiple of `),yt=r("code"),Sr=n("num_processes"),xr=n(` and that all have the same size.
Depending on the value of the `),wt=r("code"),Tr=n("drop_last"),Pr=n(` attribute of the batch sampler passed, it will either stop the iteration
at the first batch that would be too small / not present on all processes or loop with indices from the beginning.`),Ar=d(),u(he.$$.fragment),da=d(),M=r("h3"),pe=r("a"),Et=r("span"),u(Le.$$.fragment),zr=d(),Dt=r("span"),Ir=n("IterableDatasetShard"),ha=d(),j=r("div"),u(Ne.$$.fragment),Lr=d(),S=r("p"),Nr=n("Wraps a PyTorch "),St=r("code"),kr=n("IterableDataset"),Or=n(` to generate samples for one of the processes only. Instances of this class will
always yield a number of samples that is a round multiple of the actual batch size (depending of the value of
`),xt=r("code"),Cr=n("split_batches"),Ur=n(", this is either "),Tt=r("code"),Br=n("batch_size"),Gr=n(" or "),Pt=r("code"),qr=n("batch_size x num_processes"),Fr=n(`). Depending on the value of the
`),At=r("code"),Rr=n("drop_last"),Wr=n(` attribute of the batch sampler passed, it will either stop the iteration at the first batch that would
be too small or loop with indices from the beginning.`),pa=d(),X=r("h2"),me=r("a"),zt=r("span"),u(ke.$$.fragment),Vr=d(),It=r("span"),Hr=n("Distributed Config"),ma=d(),J=r("h3"),fe=r("a"),Lt=r("span"),u(Oe.$$.fragment),Mr=d(),Nt=r("span"),jr=n("AcceleratorState"),fa=d(),K=r("div"),u(Ce.$$.fragment),Xr=d(),Q=r("p"),Jr=n("This is a variation of a "),Ue=r("a"),Kr=n("singleton class"),Qr=n(` in the sense that all
instance of `),kt=r("code"),Yr=n("AcceleratorState"),Zr=n(" share the same state, which is initialized on the first instantiation."),ua=d(),Y=r("h3"),ue=r("a"),Ot=r("span"),u(Be.$$.fragment),eo=d(),Ct=r("span"),to=n("DistributedType"),ga=d(),A=r("div"),u(Ge.$$.fragment),ao=d(),Ut=r("p"),ro=n("Represents a type of distributed environment."),oo=d(),Bt=r("p"),so=n("Values:"),no=d(),z=r("ul"),Qe=r("li"),Gt=r("strong"),lo=n("NO"),co=n(" \u2014 Not a distributed environment, just a single process."),io=d(),Ye=r("li"),qt=r("strong"),ho=n("MULTI_CPU"),po=n(" \u2014 Distributed on multiple CPU nodes."),mo=d(),Ze=r("li"),Ft=r("strong"),fo=n("MULTI_GPU"),uo=n(" \u2014 Distributed on multiple GPUs."),go=d(),et=r("li"),Rt=r("strong"),vo=n("DEEPSPEED"),_o=n(" \u2014 Using DeepSpeed."),bo=d(),tt=r("li"),Wt=r("strong"),$o=n("TPU"),yo=n(" \u2014 Distributed on TPUs."),va=d(),Z=r("h2"),ge=r("a"),Vt=r("span"),u(qe.$$.fragment),wo=d(),Ht=r("span"),Eo=n("Utilities"),_a=d(),ee=r("div"),u(Fe.$$.fragment),Do=d(),Mt=r("p"),So=n("Extract a model from its distributed containers."),ba=d(),te=r("div"),u(Re.$$.fragment),xo=d(),jt=r("p"),To=n("Recursively gather tensor in a nested list/tuple/dictionary of tensors from all devices."),$a=d(),ae=r("div"),u(We.$$.fragment),Po=d(),Xt=r("p"),Ao=n("Recursively sends the elements in a nested list/tuple/dictionary of tensors to a given device."),ya=d(),re=r("div"),u(Ve.$$.fragment),zo=d(),O=r("p"),Io=n("Helper function for reproducible behavior to set the seed in "),Jt=r("code"),Lo=n("random"),No=n(", "),Kt=r("code"),ko=n("numpy"),Oo=n(", "),Qt=r("code"),Co=n("torch"),Uo=n("."),wa=d(),He=r("div"),u(Me.$$.fragment),Ea=d(),je=r("div"),u(Xe.$$.fragment),Da=d(),C=r("div"),u(Je.$$.fragment),Bo=d(),Yt=r("p"),Go=n("Introduces a blocking point in the script, making sure all processes have reached this point before continuing."),qo=d(),u(ve.$$.fragment),this.h()},l(e){const c=an('[data-svelte="svelte-1phssyn"]',document.head);m=o(c,"META",{name:!0,content:!0}),c.forEach(a),D=h(e),f=o(e,"H1",{class:!0});var Ke=s(f);y=o(Ke,"A",{id:!0,class:!0,href:!0});var Zt=s(y);T=o(Zt,"SPAN",{});var ea=s(T);g(w.$$.fragment,ea),ea.forEach(a),Zt.forEach(a),E=h(Ke),L=o(Ke,"SPAN",{});var jo=s(L);Ma=l(jo,"Internals"),jo.forEach(a),Ke.forEach(a),ta=h(e),G=o(e,"H2",{class:!0});var xa=s(G);se=o(xa,"A",{id:!0,class:!0,href:!0});var Xo=s(se);nt=o(Xo,"SPAN",{});var Jo=s(nt);g(we.$$.fragment,Jo),Jo.forEach(a),Xo.forEach(a),ja=h(xa),lt=o(xa,"SPAN",{});var Ko=s(lt);Xa=l(Ko,"Optimizer"),Ko.forEach(a),xa.forEach(a),aa=h(e),q=o(e,"DIV",{class:!0});var Ta=s(q);g(Ee.$$.fragment,Ta),Ja=h(Ta),ct=o(Ta,"P",{});var Qo=s(ct);Ka=l(Qo,"Internal wrapper around a torch optimizer."),Qo.forEach(a),Ta.forEach(a),ra=h(e),F=o(e,"H2",{class:!0});var Pa=s(F);ne=o(Pa,"A",{id:!0,class:!0,href:!0});var Yo=s(ne);it=o(Yo,"SPAN",{});var Zo=s(it);g(De.$$.fragment,Zo),Zo.forEach(a),Yo.forEach(a),Qa=h(Pa),dt=o(Pa,"SPAN",{});var es=s(dt);Ya=l(es,"DataLoader"),es.forEach(a),Pa.forEach(a),oa=h(e),le=o(e,"P",{});var Aa=s(le);Za=l(Aa,"The main work on your PyTorch "),ht=o(Aa,"CODE",{});var ts=s(ht);er=l(ts,"DataLoader"),ts.forEach(a),tr=l(Aa," is done by the following function:"),Aa.forEach(a),sa=h(e),P=o(e,"DIV",{class:!0});var _e=s(P);g(Se.$$.fragment,_e),ar=h(_e),xe=o(_e,"P",{});var za=s(xe);rr=l(za,"Wraps a PyTorch "),pt=o(za,"CODE",{});var as=s(pt);or=l(as,"DataLoader"),as.forEach(a),sr=l(za," to generate batches for one of the processes only."),za.forEach(a),nr=h(_e),R=o(_e,"P",{});var at=s(R);lr=l(at,"Depending on the value of the "),mt=o(at,"CODE",{});var rs=s(mt);cr=l(rs,"drop_last"),rs.forEach(a),ir=l(at," attribute of the "),ft=o(at,"CODE",{});var os=s(ft);dr=l(os,"dataloader"),os.forEach(a),hr=l(at,` passed, it will either stop the iteration
at the first batch that would be too small / not present on all processes or loop with indices from the beginning.`),at.forEach(a),pr=h(_e),g(ce.$$.fragment,_e),_e.forEach(a),na=h(e),W=o(e,"H3",{class:!0});var Ia=s(W);ie=o(Ia,"A",{id:!0,class:!0,href:!0});var ss=s(ie);ut=o(ss,"SPAN",{});var ns=s(ut);g(Te.$$.fragment,ns),ns.forEach(a),ss.forEach(a),mr=h(Ia),gt=o(Ia,"SPAN",{});var ls=s(gt);fr=l(ls,"BatchSamplerShard"),ls.forEach(a),Ia.forEach(a),la=h(e),V=o(e,"DIV",{class:!0});var La=s(V);g(Pe.$$.fragment,La),ur=h(La),Ae=o(La,"P",{});var Na=s(Ae);gr=l(Na,"Subclass of a PyTorch "),vt=o(Na,"CODE",{});var cs=s(vt);vr=l(cs,"DataLoader"),cs.forEach(a),_r=l(Na," that will deal with device placement and current distributed setup."),Na.forEach(a),La.forEach(a),ca=h(e),H=o(e,"H3",{class:!0});var ka=s(H);de=o(ka,"A",{id:!0,class:!0,href:!0});var is=s(de);_t=o(is,"SPAN",{});var ds=s(_t);g(ze.$$.fragment,ds),ds.forEach(a),is.forEach(a),br=h(ka),bt=o(ka,"SPAN",{});var hs=s(bt);$r=l(hs,"BatchSamplerShard"),hs.forEach(a),ka.forEach(a),ia=h(e),N=o(e,"DIV",{class:!0});var rt=s(N);g(Ie.$$.fragment,rt),yr=h(rt),k=o(rt,"P",{});var be=s(k);wr=l(be,"Wraps a PyTorch "),$t=o(be,"CODE",{});var ps=s($t);Er=l(ps,"BatchSampler"),ps.forEach(a),Dr=l(be,` to generate batches for one of the processes only. Instances of this class will
always yield a number of batches that is a round multiple of `),yt=o(be,"CODE",{});var ms=s(yt);Sr=l(ms,"num_processes"),ms.forEach(a),xr=l(be,` and that all have the same size.
Depending on the value of the `),wt=o(be,"CODE",{});var fs=s(wt);Tr=l(fs,"drop_last"),fs.forEach(a),Pr=l(be,` attribute of the batch sampler passed, it will either stop the iteration
at the first batch that would be too small / not present on all processes or loop with indices from the beginning.`),be.forEach(a),Ar=h(rt),g(he.$$.fragment,rt),rt.forEach(a),da=h(e),M=o(e,"H3",{class:!0});var Oa=s(M);pe=o(Oa,"A",{id:!0,class:!0,href:!0});var us=s(pe);Et=o(us,"SPAN",{});var gs=s(Et);g(Le.$$.fragment,gs),gs.forEach(a),us.forEach(a),zr=h(Oa),Dt=o(Oa,"SPAN",{});var vs=s(Dt);Ir=l(vs,"IterableDatasetShard"),vs.forEach(a),Oa.forEach(a),ha=h(e),j=o(e,"DIV",{class:!0});var Ca=s(j);g(Ne.$$.fragment,Ca),Lr=h(Ca),S=o(Ca,"P",{});var I=s(S);Nr=l(I,"Wraps a PyTorch "),St=o(I,"CODE",{});var _s=s(St);kr=l(_s,"IterableDataset"),_s.forEach(a),Or=l(I,` to generate samples for one of the processes only. Instances of this class will
always yield a number of samples that is a round multiple of the actual batch size (depending of the value of
`),xt=o(I,"CODE",{});var bs=s(xt);Cr=l(bs,"split_batches"),bs.forEach(a),Ur=l(I,", this is either "),Tt=o(I,"CODE",{});var $s=s(Tt);Br=l($s,"batch_size"),$s.forEach(a),Gr=l(I," or "),Pt=o(I,"CODE",{});var ys=s(Pt);qr=l(ys,"batch_size x num_processes"),ys.forEach(a),Fr=l(I,`). Depending on the value of the
`),At=o(I,"CODE",{});var ws=s(At);Rr=l(ws,"drop_last"),ws.forEach(a),Wr=l(I,` attribute of the batch sampler passed, it will either stop the iteration at the first batch that would
be too small or loop with indices from the beginning.`),I.forEach(a),Ca.forEach(a),pa=h(e),X=o(e,"H2",{class:!0});var Ua=s(X);me=o(Ua,"A",{id:!0,class:!0,href:!0});var Es=s(me);zt=o(Es,"SPAN",{});var Ds=s(zt);g(ke.$$.fragment,Ds),Ds.forEach(a),Es.forEach(a),Vr=h(Ua),It=o(Ua,"SPAN",{});var Ss=s(It);Hr=l(Ss,"Distributed Config"),Ss.forEach(a),Ua.forEach(a),ma=h(e),J=o(e,"H3",{class:!0});var Ba=s(J);fe=o(Ba,"A",{id:!0,class:!0,href:!0});var xs=s(fe);Lt=o(xs,"SPAN",{});var Ts=s(Lt);g(Oe.$$.fragment,Ts),Ts.forEach(a),xs.forEach(a),Mr=h(Ba),Nt=o(Ba,"SPAN",{});var Ps=s(Nt);jr=l(Ps,"AcceleratorState"),Ps.forEach(a),Ba.forEach(a),fa=h(e),K=o(e,"DIV",{class:!0});var Ga=s(K);g(Ce.$$.fragment,Ga),Xr=h(Ga),Q=o(Ga,"P",{});var ot=s(Q);Jr=l(ot,"This is a variation of a "),Ue=o(ot,"A",{href:!0,rel:!0});var As=s(Ue);Kr=l(As,"singleton class"),As.forEach(a),Qr=l(ot,` in the sense that all
instance of `),kt=o(ot,"CODE",{});var zs=s(kt);Yr=l(zs,"AcceleratorState"),zs.forEach(a),Zr=l(ot," share the same state, which is initialized on the first instantiation."),ot.forEach(a),Ga.forEach(a),ua=h(e),Y=o(e,"H3",{class:!0});var qa=s(Y);ue=o(qa,"A",{id:!0,class:!0,href:!0});var Is=s(ue);Ot=o(Is,"SPAN",{});var Ls=s(Ot);g(Be.$$.fragment,Ls),Ls.forEach(a),Is.forEach(a),eo=h(qa),Ct=o(qa,"SPAN",{});var Ns=s(Ct);to=l(Ns,"DistributedType"),Ns.forEach(a),qa.forEach(a),ga=h(e),A=o(e,"DIV",{class:!0});var $e=s(A);g(Ge.$$.fragment,$e),ao=h($e),Ut=o($e,"P",{});var ks=s(Ut);ro=l(ks,"Represents a type of distributed environment."),ks.forEach(a),oo=h($e),Bt=o($e,"P",{});var Os=s(Bt);so=l(Os,"Values:"),Os.forEach(a),no=h($e),z=o($e,"UL",{});var U=s(z);Qe=o(U,"LI",{});var Fo=s(Qe);Gt=o(Fo,"STRONG",{});var Cs=s(Gt);lo=l(Cs,"NO"),Cs.forEach(a),co=l(Fo," \u2014 Not a distributed environment, just a single process."),Fo.forEach(a),io=h(U),Ye=o(U,"LI",{});var Ro=s(Ye);qt=o(Ro,"STRONG",{});var Us=s(qt);ho=l(Us,"MULTI_CPU"),Us.forEach(a),po=l(Ro," \u2014 Distributed on multiple CPU nodes."),Ro.forEach(a),mo=h(U),Ze=o(U,"LI",{});var Wo=s(Ze);Ft=o(Wo,"STRONG",{});var Bs=s(Ft);fo=l(Bs,"MULTI_GPU"),Bs.forEach(a),uo=l(Wo," \u2014 Distributed on multiple GPUs."),Wo.forEach(a),go=h(U),et=o(U,"LI",{});var Vo=s(et);Rt=o(Vo,"STRONG",{});var Gs=s(Rt);vo=l(Gs,"DEEPSPEED"),Gs.forEach(a),_o=l(Vo," \u2014 Using DeepSpeed."),Vo.forEach(a),bo=h(U),tt=o(U,"LI",{});var Ho=s(tt);Wt=o(Ho,"STRONG",{});var qs=s(Wt);$o=l(qs,"TPU"),qs.forEach(a),yo=l(Ho," \u2014 Distributed on TPUs."),Ho.forEach(a),U.forEach(a),$e.forEach(a),va=h(e),Z=o(e,"H2",{class:!0});var Fa=s(Z);ge=o(Fa,"A",{id:!0,class:!0,href:!0});var Fs=s(ge);Vt=o(Fs,"SPAN",{});var Rs=s(Vt);g(qe.$$.fragment,Rs),Rs.forEach(a),Fs.forEach(a),wo=h(Fa),Ht=o(Fa,"SPAN",{});var Ws=s(Ht);Eo=l(Ws,"Utilities"),Ws.forEach(a),Fa.forEach(a),_a=h(e),ee=o(e,"DIV",{class:!0});var Ra=s(ee);g(Fe.$$.fragment,Ra),Do=h(Ra),Mt=o(Ra,"P",{});var Vs=s(Mt);So=l(Vs,"Extract a model from its distributed containers."),Vs.forEach(a),Ra.forEach(a),ba=h(e),te=o(e,"DIV",{class:!0});var Wa=s(te);g(Re.$$.fragment,Wa),xo=h(Wa),jt=o(Wa,"P",{});var Hs=s(jt);To=l(Hs,"Recursively gather tensor in a nested list/tuple/dictionary of tensors from all devices."),Hs.forEach(a),Wa.forEach(a),$a=h(e),ae=o(e,"DIV",{class:!0});var Va=s(ae);g(We.$$.fragment,Va),Po=h(Va),Xt=o(Va,"P",{});var Ms=s(Xt);Ao=l(Ms,"Recursively sends the elements in a nested list/tuple/dictionary of tensors to a given device."),Ms.forEach(a),Va.forEach(a),ya=h(e),re=o(e,"DIV",{class:!0});var Ha=s(re);g(Ve.$$.fragment,Ha),zo=h(Ha),O=o(Ha,"P",{});var ye=s(O);Io=l(ye,"Helper function for reproducible behavior to set the seed in "),Jt=o(ye,"CODE",{});var js=s(Jt);Lo=l(js,"random"),js.forEach(a),No=l(ye,", "),Kt=o(ye,"CODE",{});var Xs=s(Kt);ko=l(Xs,"numpy"),Xs.forEach(a),Oo=l(ye,", "),Qt=o(ye,"CODE",{});var Js=s(Qt);Co=l(Js,"torch"),Js.forEach(a),Uo=l(ye,"."),ye.forEach(a),Ha.forEach(a),wa=h(e),He=o(e,"DIV",{class:!0});var Ks=s(He);g(Me.$$.fragment,Ks),Ks.forEach(a),Ea=h(e),je=o(e,"DIV",{class:!0});var Qs=s(je);g(Xe.$$.fragment,Qs),Qs.forEach(a),Da=h(e),C=o(e,"DIV",{class:!0});var st=s(C);g(Je.$$.fragment,st),Bo=h(st),Yt=o(st,"P",{});var Ys=s(Yt);Go=l(Ys,"Introduces a blocking point in the script, making sure all processes have reached this point before continuing."),Ys.forEach(a),qo=h(st),g(ve.$$.fragment,st),st.forEach(a),this.h()},h(){i(m,"name","hf:doc:metadata"),i(m,"content",JSON.stringify(cn)),i(y,"id","internals"),i(y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(y,"href","#internals"),i(f,"class","relative group"),i(se,"id","accelerate.optimizer.AcceleratedOptimizer"),i(se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(se,"href","#accelerate.optimizer.AcceleratedOptimizer"),i(G,"class","relative group"),i(q,"class","docstring"),i(ne,"id","accelerate.data_loader.prepare_data_loader"),i(ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(ne,"href","#accelerate.data_loader.prepare_data_loader"),i(F,"class","relative group"),i(P,"class","docstring"),i(ie,"id","accelerate.data_loader.DataLoaderShard"),i(ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(ie,"href","#accelerate.data_loader.DataLoaderShard"),i(W,"class","relative group"),i(V,"class","docstring"),i(de,"id","accelerate.data_loader.BatchSamplerShard"),i(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(de,"href","#accelerate.data_loader.BatchSamplerShard"),i(H,"class","relative group"),i(N,"class","docstring"),i(pe,"id","accelerate.data_loader.IterableDatasetShard"),i(pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(pe,"href","#accelerate.data_loader.IterableDatasetShard"),i(M,"class","relative group"),i(j,"class","docstring"),i(me,"id","distributed-config"),i(me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(me,"href","#distributed-config"),i(X,"class","relative group"),i(fe,"id","accelerate.state.AcceleratorState"),i(fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(fe,"href","#accelerate.state.AcceleratorState"),i(J,"class","relative group"),i(Ue,"href","https://en.wikipedia.org/wiki/Singleton_pattern"),i(Ue,"rel","nofollow"),i(K,"class","docstring"),i(ue,"id","accelerate.DistributedType"),i(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(ue,"href","#accelerate.DistributedType"),i(Y,"class","relative group"),i(A,"class","docstring"),i(ge,"id","accelerate.utils.extract_model_from_parallel"),i(ge,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(ge,"href","#accelerate.utils.extract_model_from_parallel"),i(Z,"class","relative group"),i(ee,"class","docstring"),i(te,"class","docstring"),i(ae,"class","docstring"),i(re,"class","docstring"),i(He,"class","docstring"),i(je,"class","docstring"),i(C,"class","docstring")},m(e,c){t(document.head,m),p(e,D,c),p(e,f,c),t(f,y),t(y,T),v(w,T,null),t(f,E),t(f,L),t(L,Ma),p(e,ta,c),p(e,G,c),t(G,se),t(se,nt),v(we,nt,null),t(G,ja),t(G,lt),t(lt,Xa),p(e,aa,c),p(e,q,c),v(Ee,q,null),t(q,Ja),t(q,ct),t(ct,Ka),p(e,ra,c),p(e,F,c),t(F,ne),t(ne,it),v(De,it,null),t(F,Qa),t(F,dt),t(dt,Ya),p(e,oa,c),p(e,le,c),t(le,Za),t(le,ht),t(ht,er),t(le,tr),p(e,sa,c),p(e,P,c),v(Se,P,null),t(P,ar),t(P,xe),t(xe,rr),t(xe,pt),t(pt,or),t(xe,sr),t(P,nr),t(P,R),t(R,lr),t(R,mt),t(mt,cr),t(R,ir),t(R,ft),t(ft,dr),t(R,hr),t(P,pr),v(ce,P,null),p(e,na,c),p(e,W,c),t(W,ie),t(ie,ut),v(Te,ut,null),t(W,mr),t(W,gt),t(gt,fr),p(e,la,c),p(e,V,c),v(Pe,V,null),t(V,ur),t(V,Ae),t(Ae,gr),t(Ae,vt),t(vt,vr),t(Ae,_r),p(e,ca,c),p(e,H,c),t(H,de),t(de,_t),v(ze,_t,null),t(H,br),t(H,bt),t(bt,$r),p(e,ia,c),p(e,N,c),v(Ie,N,null),t(N,yr),t(N,k),t(k,wr),t(k,$t),t($t,Er),t(k,Dr),t(k,yt),t(yt,Sr),t(k,xr),t(k,wt),t(wt,Tr),t(k,Pr),t(N,Ar),v(he,N,null),p(e,da,c),p(e,M,c),t(M,pe),t(pe,Et),v(Le,Et,null),t(M,zr),t(M,Dt),t(Dt,Ir),p(e,ha,c),p(e,j,c),v(Ne,j,null),t(j,Lr),t(j,S),t(S,Nr),t(S,St),t(St,kr),t(S,Or),t(S,xt),t(xt,Cr),t(S,Ur),t(S,Tt),t(Tt,Br),t(S,Gr),t(S,Pt),t(Pt,qr),t(S,Fr),t(S,At),t(At,Rr),t(S,Wr),p(e,pa,c),p(e,X,c),t(X,me),t(me,zt),v(ke,zt,null),t(X,Vr),t(X,It),t(It,Hr),p(e,ma,c),p(e,J,c),t(J,fe),t(fe,Lt),v(Oe,Lt,null),t(J,Mr),t(J,Nt),t(Nt,jr),p(e,fa,c),p(e,K,c),v(Ce,K,null),t(K,Xr),t(K,Q),t(Q,Jr),t(Q,Ue),t(Ue,Kr),t(Q,Qr),t(Q,kt),t(kt,Yr),t(Q,Zr),p(e,ua,c),p(e,Y,c),t(Y,ue),t(ue,Ot),v(Be,Ot,null),t(Y,eo),t(Y,Ct),t(Ct,to),p(e,ga,c),p(e,A,c),v(Ge,A,null),t(A,ao),t(A,Ut),t(Ut,ro),t(A,oo),t(A,Bt),t(Bt,so),t(A,no),t(A,z),t(z,Qe),t(Qe,Gt),t(Gt,lo),t(Qe,co),t(z,io),t(z,Ye),t(Ye,qt),t(qt,ho),t(Ye,po),t(z,mo),t(z,Ze),t(Ze,Ft),t(Ft,fo),t(Ze,uo),t(z,go),t(z,et),t(et,Rt),t(Rt,vo),t(et,_o),t(z,bo),t(z,tt),t(tt,Wt),t(Wt,$o),t(tt,yo),p(e,va,c),p(e,Z,c),t(Z,ge),t(ge,Vt),v(qe,Vt,null),t(Z,wo),t(Z,Ht),t(Ht,Eo),p(e,_a,c),p(e,ee,c),v(Fe,ee,null),t(ee,Do),t(ee,Mt),t(Mt,So),p(e,ba,c),p(e,te,c),v(Re,te,null),t(te,xo),t(te,jt),t(jt,To),p(e,$a,c),p(e,ae,c),v(We,ae,null),t(ae,Po),t(ae,Xt),t(Xt,Ao),p(e,ya,c),p(e,re,c),v(Ve,re,null),t(re,zo),t(re,O),t(O,Io),t(O,Jt),t(Jt,Lo),t(O,No),t(O,Kt),t(Kt,ko),t(O,Oo),t(O,Qt),t(Qt,Co),t(O,Uo),p(e,wa,c),p(e,He,c),v(Me,He,null),p(e,Ea,c),p(e,je,c),v(Xe,je,null),p(e,Da,c),p(e,C,c),v(Je,C,null),t(C,Bo),t(C,Yt),t(Yt,Go),t(C,qo),v(ve,C,null),Sa=!0},p(e,[c]){const Ke={};c&2&&(Ke.$$scope={dirty:c,ctx:e}),ce.$set(Ke);const Zt={};c&2&&(Zt.$$scope={dirty:c,ctx:e}),he.$set(Zt);const ea={};c&2&&(ea.$$scope={dirty:c,ctx:e}),ve.$set(ea)},i(e){Sa||(_(w.$$.fragment,e),_(we.$$.fragment,e),_(Ee.$$.fragment,e),_(De.$$.fragment,e),_(Se.$$.fragment,e),_(ce.$$.fragment,e),_(Te.$$.fragment,e),_(Pe.$$.fragment,e),_(ze.$$.fragment,e),_(Ie.$$.fragment,e),_(he.$$.fragment,e),_(Le.$$.fragment,e),_(Ne.$$.fragment,e),_(ke.$$.fragment,e),_(Oe.$$.fragment,e),_(Ce.$$.fragment,e),_(Be.$$.fragment,e),_(Ge.$$.fragment,e),_(qe.$$.fragment,e),_(Fe.$$.fragment,e),_(Re.$$.fragment,e),_(We.$$.fragment,e),_(Ve.$$.fragment,e),_(Me.$$.fragment,e),_(Xe.$$.fragment,e),_(Je.$$.fragment,e),_(ve.$$.fragment,e),Sa=!0)},o(e){b(w.$$.fragment,e),b(we.$$.fragment,e),b(Ee.$$.fragment,e),b(De.$$.fragment,e),b(Se.$$.fragment,e),b(ce.$$.fragment,e),b(Te.$$.fragment,e),b(Pe.$$.fragment,e),b(ze.$$.fragment,e),b(Ie.$$.fragment,e),b(he.$$.fragment,e),b(Le.$$.fragment,e),b(Ne.$$.fragment,e),b(ke.$$.fragment,e),b(Oe.$$.fragment,e),b(Ce.$$.fragment,e),b(Be.$$.fragment,e),b(Ge.$$.fragment,e),b(qe.$$.fragment,e),b(Fe.$$.fragment,e),b(Re.$$.fragment,e),b(We.$$.fragment,e),b(Ve.$$.fragment,e),b(Me.$$.fragment,e),b(Xe.$$.fragment,e),b(Je.$$.fragment,e),b(ve.$$.fragment,e),Sa=!1},d(e){a(m),e&&a(D),e&&a(f),$(w),e&&a(ta),e&&a(G),$(we),e&&a(aa),e&&a(q),$(Ee),e&&a(ra),e&&a(F),$(De),e&&a(oa),e&&a(le),e&&a(sa),e&&a(P),$(Se),$(ce),e&&a(na),e&&a(W),$(Te),e&&a(la),e&&a(V),$(Pe),e&&a(ca),e&&a(H),$(ze),e&&a(ia),e&&a(N),$(Ie),$(he),e&&a(da),e&&a(M),$(Le),e&&a(ha),e&&a(j),$(Ne),e&&a(pa),e&&a(X),$(ke),e&&a(ma),e&&a(J),$(Oe),e&&a(fa),e&&a(K),$(Ce),e&&a(ua),e&&a(Y),$(Be),e&&a(ga),e&&a(A),$(Ge),e&&a(va),e&&a(Z),$(qe),e&&a(_a),e&&a(ee),$(Fe),e&&a(ba),e&&a(te),$(Re),e&&a($a),e&&a(ae),$(We),e&&a(ya),e&&a(re),$(Ve),e&&a(wa),e&&a(He),$(Me),e&&a(Ea),e&&a(je),$(Xe),e&&a(Da),e&&a(C),$(Je),$(ve)}}}const cn={local:"internals",sections:[{local:"accelerate.optimizer.AcceleratedOptimizer",title:"Optimizer"},{local:"accelerate.data_loader.prepare_data_loader",sections:[{local:"accelerate.data_loader.DataLoaderShard",title:"BatchSamplerShard"},{local:"accelerate.data_loader.BatchSamplerShard",title:"BatchSamplerShard"},{local:"accelerate.data_loader.IterableDatasetShard",title:"IterableDatasetShard"}],title:"DataLoader"},{local:"distributed-config",sections:[{local:"accelerate.state.AcceleratorState",title:"AcceleratorState"},{local:"accelerate.DistributedType",title:"DistributedType"}],title:"Distributed Config"},{local:"accelerate.utils.extract_model_from_parallel",title:"Utilities"}],title:"Internals"};function dn(oe){return rn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class un extends Zs{constructor(m){super();en(this,m,dn,ln,tn,{})}}export{un as default,cn as metadata};
