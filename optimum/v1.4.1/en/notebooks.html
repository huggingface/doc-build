<meta charset="utf-8" /><meta http-equiv="content-security-policy" content=""><meta name="hf:doc:metadata" content="{&quot;local&quot;:&quot;optimum-notebooks&quot;,&quot;sections&quot;:[{&quot;local&quot;:&quot;optimum-graphcore-examples&quot;,&quot;title&quot;:&quot;Optimum Graphcore examples&quot;},{&quot;local&quot;:&quot;optimum-intel-examples&quot;,&quot;title&quot;:&quot;Optimum Intel examples&quot;},{&quot;local&quot;:&quot;onnx-runtime-examples&quot;,&quot;title&quot;:&quot;ONNX Runtime examples&quot;}],&quot;title&quot;:&quot;ðŸ¤— Optimum notebooks&quot;}" data-svelte="svelte-1phssyn">
	<link rel="modulepreload" href="/docs/optimum/v1.4.1/en/_app/assets/pages/__layout.svelte-hf-doc-builder.css">
	<link rel="modulepreload" href="/docs/optimum/v1.4.1/en/_app/start-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/optimum/v1.4.1/en/_app/chunks/vendor-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/optimum/v1.4.1/en/_app/chunks/paths-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/optimum/v1.4.1/en/_app/pages/__layout.svelte-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/optimum/v1.4.1/en/_app/pages/notebooks.mdx-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/optimum/v1.4.1/en/_app/chunks/IconCopyLink-hf-doc-builder.js"> 






<h1 class="relative group"><a id="optimum-notebooks" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#optimum-notebooks"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>ðŸ¤— Optimum notebooks
	</span></h1>

<p>You can find here a list of the notebooks associated with each accelerator in ðŸ¤— Optimum.</p>
<h2 class="relative group"><a id="optimum-graphcore-examples" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#optimum-graphcore-examples"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Optimum Graphcore examples
	</span></h2>

<table><thead><tr><th align="left">Notebook</th>
<th align="left">Description</th>
<th align="left"></th></tr></thead>
<tbody><tr><td align="left"><a href="https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/introduction_to_optimum_graphcore.ipynb" rel="nofollow">Introduction to Optimum Graphcore</a></td>
<td align="left">Introduce Optimum-Graphcore with a BERT fine-tuning example.</td>
<td align="left"><a href="https://console.paperspace.com/github/gradient-ai/Graphcore-HuggingFace?machine=Free-IPU-POD16&container=graphcore%2Fpytorch-jupyter%3A2.6.0-ubuntu-20.04-20220804&file=%2Fnotebook-tutorials%2Fintroduction_to_optimum_graphcore.ipynb" rel="nofollow"><img src="https://assets.paperspace.io/img/gradient-badge.svg" alt="Gradient"></a></td></tr>
<tr><td align="left"><a href="https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/external_model.ipynb" rel="nofollow">Train an external model</a></td>
<td align="left">Show how to train an external model that is not supported by Optimum or Transformers.</td>
<td align="left"></td></tr>
<tr><td align="left"><a href="https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/language_modelling_from_scratch.ipynb" rel="nofollow">Train your language model</a></td>
<td align="left">Show how to train a model for causal or masked language modelling from scratch.</td>
<td align="left"></td></tr>
<tr><td align="left"><a href="https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/text_classification.ipynb" rel="nofollow">How to fine-tune a model on text classification</a></td>
<td align="left">Show how to preprocess the data and fine-tune a pretrained model on any GLUE task.</td>
<td align="left"><a href="https://console.paperspace.com/github/gradient-ai/Graphcore-HuggingFace?machine=Free-IPU-POD16&container=graphcore%2Fpytorch-jupyter%3A2.6.0-ubuntu-20.04-20220804&file=%2Fnotebook-tutorials%2Ftext_classification.ipynb" rel="nofollow"><img src="https://assets.paperspace.io/img/gradient-badge.svg" alt="Gradient"></a></td></tr>
<tr><td align="left"><a href="https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/language_modeling.ipynb" rel="nofollow">How to fine-tune a model on language modeling</a></td>
<td align="left">Show how to preprocess the data and fine-tune a pretrained model on a causal or masked LM task.</td>
<td align="left"></td></tr>
<tr><td align="left"><a href="https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/token_classification.ipynb" rel="nofollow">How to fine-tune a model on token classification</a></td>
<td align="left">Show how to preprocess the data and fine-tune a pretrained model on a token classification task (NER, PoS).</td>
<td align="left"></td></tr>
<tr><td align="left"><a href="https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/question_answering.ipynb" rel="nofollow">How to fine-tune a model on question answering</a></td>
<td align="left">Show how to preprocess the data and fine-tune a pretrained model on SQUAD.</td>
<td align="left"></td></tr>
<tr><td align="left"><a href="https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/multiple_choice.ipynb" rel="nofollow">How to fine-tune a model on multiple choice</a></td>
<td align="left">Show how to preprocess the data and fine-tune a pretrained model on SWAG.</td>
<td align="left"></td></tr>
<tr><td align="left"><a href="https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/translation.ipynb" rel="nofollow">How to fine-tune a model on translation</a></td>
<td align="left">Show how to preprocess the data and fine-tune a pretrained model on WMT.</td>
<td align="left"></td></tr>
<tr><td align="left"><a href="https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/summarization.ipynb" rel="nofollow">How to fine-tune a model on summarization</a></td>
<td align="left">Show how to preprocess the data and fine-tune a pretrained model on XSUM.</td>
<td align="left"></td></tr>
<tr><td align="left"><a href="https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/audio_classification.ipynb" rel="nofollow">How to fine-tune a model on audio classification</a></td>
<td align="left">Show how to preprocess the data and fine-tune a pretrained Speech model on Keyword Spotting</td>
<td align="left"></td></tr>
<tr><td align="left"><a href="https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/image_classification.ipynb" rel="nofollow">How to fine-tune a model on image classfication</a></td>
<td align="left">Show how to preprocess the data and fine-tune a pretrained model on image classification.</td>
<td align="left"><a href="https://console.paperspace.com/github/gradient-ai/Graphcore-HuggingFace?machine=Free-IPU-POD16&container=graphcore%2Fpytorch-jupyter%3A2.6.0-ubuntu-20.04-20220804&file=%2Fget-started%2Fwalkthrough.ipynb" rel="nofollow"><img src="https://assets.paperspace.io/img/gradient-badge.svg" alt="Gradient"></a></td></tr>
<tr><td align="left"><a href="https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/wav2vec2/wav2vec2-fine-tuning-checkpoint.ipynb" rel="nofollow">wav2vec 2.0 Fine-Tuning on IPU</a></td>
<td align="left">How to fine-tune a pre-trained wav2vec 2.0 model with PyTorch on the Graphcore IPU-POD16 system.</td>
<td align="left"></td></tr>
<tr><td align="left"><a href="https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/wav2vec2/wav2vec2-inference-checkpoint.ipynb" rel="nofollow">wav2vec 2.0 Inference on IPU</a></td>
<td align="left">How to run inference on the wav2vec 2.0 model with PyTorch on the Graphcore IPU-POD16 system.</td>
<td align="left"></td></tr></tbody></table>
<h2 class="relative group"><a id="optimum-intel-examples" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#optimum-intel-examples"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Optimum Intel examples
	</span></h2>

<table><thead><tr><th align="left">Notebook</th>
<th align="left">Description</th>
<th align="left"></th>
<th align="right"></th></tr></thead>
<tbody><tr><td align="left"><a href="https://github.com/huggingface/notebooks/blob/main/examples/text_classification_quantization_inc.ipynb" rel="nofollow">How to quantize a model with Intel Neural Compressor for text classification</a></td>
<td align="left">Show how to apply static, dynamic and aware training quantization on a model using <a href="https://github.com/intel/neural-compressor" rel="nofollow">Intel Neural Compressor (INC)</a> for any GLUE task.</td>
<td align="left"><a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification_quantization_inc.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab"></a></td>
<td align="right"><a href="https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification_quantization_inc.ipynb" rel="nofollow"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open in AWS Studio"></a></td></tr></tbody></table>
<h2 class="relative group"><a id="onnx-runtime-examples" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#onnx-runtime-examples"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>ONNX Runtime examples
	</span></h2>

<table><thead><tr><th align="left">Notebook</th>
<th align="left">Description</th>
<th align="left"></th>
<th align="right"></th></tr></thead>
<tbody><tr><td align="left"><a href="https://github.com/huggingface/notebooks/blob/main/examples/text_classification_quantization_ort.ipynb" rel="nofollow">How to quantize a model with ONNX Runtime for text classification</a></td>
<td align="left">Show how to apply static and dynamic quantization on a model using <a href="https://github.com/microsoft/onnxruntime" rel="nofollow">ONNX Runtime</a> for any GLUE task.</td>
<td align="left"><a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification_quantization_ort.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab"></a></td>
<td align="right"><a href="https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification_quantization_ort.ipynb" rel="nofollow"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open in AWS Studio"></a></td></tr>
<tr><td align="left"><a href="https://github.com/huggingface/notebooks/blob/main/examples/text_classification_ort.ipynb" rel="nofollow">How to fine-tune a model for text classification with ONNX Runtime</a></td>
<td align="left">Show how to DistilBERT model on GLUE tasks using <a href="https://github.com/microsoft/onnxruntime" rel="nofollow">ONNX Runtime</a>.</td>
<td align="left"><a href="https://colab.research.google.com/github.com/huggingface/notebooks/blob/main/examples/text_classification_ort.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab"></a></td>
<td align="right"><a href="https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification_quantization_ort.ipynb" rel="nofollow"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open in AWS Studio"></a></td></tr>
<tr><td align="left"><a href="https://github.com/huggingface/notebooks/blob/main/examples/summarization_ort.ipynb" rel="nofollow">How to fine-tune a model for summarization with ONNX Runtime</a></td>
<td align="left">Show how to fine-tune a T5 model on the BBC news corpus.</td>
<td align="left"><a href="https://colab.research.google.com/github.com/huggingface/notebooks/blob/main/examples/summarization_ort.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab"></a></td>
<td align="right"><a href="https://studiolab.sagemaker.aws/import/github.com/huggingface/notebooks/blob/main/examples/summarization_ort.ipynb" rel="nofollow"><img src="https://studiolab.sagemaker.aws/studiolab.svg" alt="Open in AWS Studio"></a></td></tr></tbody></table>


		<script type="module" data-hydrate="6jz4cx">
		import { start } from "/docs/optimum/v1.4.1/en/_app/start-hf-doc-builder.js";
		start({
			target: document.querySelector('[data-hydrate="6jz4cx"]').parentNode,
			paths: {"base":"/docs/optimum/v1.4.1/en","assets":"/docs/optimum/v1.4.1/en"},
			session: {},
			route: false,
			spa: false,
			trailing_slash: "never",
			hydrate: {
				status: 200,
				error: null,
				nodes: [
					import("/docs/optimum/v1.4.1/en/_app/pages/__layout.svelte-hf-doc-builder.js"),
						import("/docs/optimum/v1.4.1/en/_app/pages/notebooks.mdx-hf-doc-builder.js")
				],
				params: {}
			}
		});
	</script>
