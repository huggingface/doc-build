import{S as Uo,i as Go,s as Lo,e as i,k as u,w as d,t as o,M as Bo,c as n,d as r,m as f,a,x as g,h as s,b as m,G as t,g as p,y as _,q as v,o as T,B as w,v as Fo}from"../../../chunks/vendor-hf-doc-builder.js";import{T as Yo}from"../../../chunks/Tip-hf-doc-builder.js";import{I as V}from"../../../chunks/IconCopyLink-hf-doc-builder.js";import{C as W}from"../../../chunks/CodeBlock-hf-doc-builder.js";function Mo(Ve){let h,D,c,y,x;return{c(){h=i("p"),D=o(`DeepSpeed is supported by ONNX Runtime(only ZeRO stage 1 and 2 for the moment).
You can find some `),c=i("a"),y=o("DeepSpeed configuration examples"),x=o(`
in the Optimum repository.`),this.h()},l($){h=n($,"P",{});var E=a(h);D=s(E,`DeepSpeed is supported by ONNX Runtime(only ZeRO stage 1 and 2 for the moment).
You can find some `),c=n(E,"A",{href:!0,rel:!0});var X=a(c);y=s(X,"DeepSpeed configuration examples"),X.forEach(r),x=s(E,`
in the Optimum repository.`),E.forEach(r),this.h()},h(){m(c,"href","https://github.com/huggingface/optimum/tree/main/tests/onnxruntime/ds_configs"),m(c,"rel","nofollow")},m($,E){p($,h,E),t(h,D),t(h,c),t(c,y),t(h,x)},d($){$&&r(h)}}}function Zo(Ve){let h,D,c,y,x;return{c(){h=i("p"),D=o(`DeepSpeed is supported by ONNX Runtime(only ZeRO stage 1 and 2 for the moment).
You can find some `),c=i("a"),y=o("DeepSpeed configuration examples"),x=o(`
in the Optimum repository.`),this.h()},l($){h=n($,"P",{});var E=a(h);D=s(E,`DeepSpeed is supported by ONNX Runtime(only ZeRO stage 1 and 2 for the moment).
You can find some `),c=n(E,"A",{href:!0,rel:!0});var X=a(c);y=s(X,"DeepSpeed configuration examples"),X.forEach(r),x=s(E,`
in the Optimum repository.`),E.forEach(r),this.h()},h(){m(c,"href","https://github.com/huggingface/optimum/tree/main/tests/onnxruntime/ds_configs"),m(c,"rel","nofollow")},m($,E){p($,h,E),t(h,D),t(h,c),t(c,y),t(h,x)},d($){$&&r(h)}}}function Vo(Ve){let h,D,c,y,x,$,E,X,Qr,rr,O,ei,nt,ti,ri,at,ii,ni,ot,he,ai,oi,st,si,li,lt,mi,pi,mt,ui,fi,ir,Y,J,pt,ce,hi,ut,ci,nr,We,di,ar,z,gi,ft,_i,vi,ht,Ti,wi,or,U,K,ct,de,$i,dt,Oi,sr,I,Si,gt,qi,Ei,ge,yi,Ri,lr,Q,bi,_e,Ni,Ai,mr,ve,pr,Je,ki,ur,Te,fr,Ke,xi,hr,we,cr,G,ee,_t,$e,Di,vt,Pi,dr,Qe,Ci,gr,Oe,_r,et,Xi,vr,Se,Tr,te,zi,qe,Ii,ji,wr,L,re,Tt,Ee,Hi,wt,Yi,$r,S,Ui,$t,Gi,Li,ye,Ot,Bi,Fi,St,Mi,Zi,qt,Vi,Wi,Et,Ji,Ki,yt,Qi,en,Or,Re,Sr,ie,tn,be,rn,nn,qr,B,ne,Rt,Ne,an,bt,on,Er,q,sn,Nt,ln,mn,Ae,At,pn,un,kt,fn,hn,xt,cn,dn,Dt,gn,_n,Pt,vn,Tn,yr,ke,Rr,ae,wn,xe,$n,On,br,F,oe,Ct,De,Sn,Xt,qn,Nr,R,En,zt,yn,Rn,Pe,It,bn,Nn,jt,An,kn,Ht,xn,Dn,Ar,Ce,kr,se,xr,M,le,Yt,Xe,Pn,Ut,Cn,Dr,b,Xn,Gt,zn,In,ze,Lt,jn,Hn,Bt,Yn,Un,Ft,Gn,Ln,Pr,Ie,Cr,me,Xr,Z,pe,Mt,je,Bn,Zt,Fn,zr,P,Vt,He,Mn,Zn,Wt,Ye,Vn,Wn,Jt,Ue,Jn,Kn,tt,Qn,Ge,Kt,Le,ea,ta,Qt,Be,ra,Ir,C,ia,er,na,aa,Fe,oa,sa,Me,la,ma,jr;return $=new V({}),ce=new V({}),de=new V({}),ve=new W({props:{code:"docker build -f Dockerfile-ort1.12.0-cu113 -t <imagename:tag> .",highlighted:"docker build -f Dockerfile-ort1.12.0-cu113 -t &lt;imagename:tag&gt; ."}}),Te=new W({props:{code:`pip install onnx==1.12.0 ninja
pip install onnxruntime-training==1.12.0+cu113 -f https://download.onnxruntime.ai/onnxruntime_stable_cu113.html
pip install torch==1.12.0+cu113 -f https://download.pytorch.org/whl/torch_stable.html
pip install torch-ort
pip install transformers datasets accelerate
pip install --upgrade protobuf==3.20.1`,highlighted:`pip install onnx==1.12.0 ninja
pip install onnxruntime-training==1.12.0+cu113 -f https://download.onnxruntime.ai/onnxruntime_stable_cu113.html
pip install torch==1.12.0+cu113 -f https://download.pytorch.org/whl/torch_stable.html
pip install torch-ort
pip install transformers datasets accelerate
pip install --upgrade protobuf==3.20.1`}}),we=new W({props:{code:"python -m torch_ort.configure",highlighted:"python -m torch_ort.configure"}}),$e=new V({}),Oe=new W({props:{code:"pip install optimum",highlighted:"pip install optimum"}}),Se=new W({props:{code:"pip install git+https://github.com/huggingface/optimum.git",highlighted:"pip install git+https://github.com/huggingface/optimum.git"}}),Ee=new V({}),Re=new W({props:{code:`-from transformers import Trainer
+from optimum.onnxruntime import ORTTrainer

# Step 1: Create your ONNX Runtime Trainer
-trainer = Trainer(
+trainer = ORTTrainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    compute_metrics=compute_metrics,
    tokenizer=tokenizer,
    data_collator=default_data_collator,
+   feature="sequence-classification",
)

# Step 2: Use ONNX Runtime for training!\u{1F917}
train_result = trainer.train()`,highlighted:`<span class="hljs-deletion">-from transformers import Trainer</span>
<span class="hljs-addition">+from optimum.onnxruntime import ORTTrainer</span>

# Step 1: Create your ONNX Runtime Trainer
<span class="hljs-deletion">-trainer = Trainer(</span>
<span class="hljs-addition">+trainer = ORTTrainer(</span>
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    compute_metrics=compute_metrics,
    tokenizer=tokenizer,
    data_collator=default_data_collator,
<span class="hljs-addition">+   feature=&quot;sequence-classification&quot;,</span>
)

# Step 2: Use ONNX Runtime for training!\u{1F917}
train_result = trainer.train()`}}),Ne=new V({}),ke=new W({props:{code:`-from transformers import Seq2SeqTrainer
+from optimum.onnxruntime import ORTSeq2SeqTrainer

# Step 1: Create your ONNX Runtime Seq2SeqTrainer
-trainer = Seq2SeqTrainer(
trainer = ORTSeq2SeqTrainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=valid_dataset,
    compute_metrics=compute_metrics if training_args.predict_with_generate else None,
    tokenizer=tokenizer,
    data_collator=data_collator,
+   feature="seq2seq-lm",
)

# Step 2: Use ONNX Runtime for training!\u{1F917}
train_result = trainer.train()`,highlighted:`<span class="hljs-deletion">-from transformers import Seq2SeqTrainer</span>
<span class="hljs-addition">+from optimum.onnxruntime import ORTSeq2SeqTrainer</span>

# Step 1: Create your ONNX Runtime Seq2SeqTrainer
<span class="hljs-deletion">-trainer = Seq2SeqTrainer(</span>
trainer = ORTSeq2SeqTrainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=valid_dataset,
    compute_metrics=compute_metrics if training_args.predict_with_generate else None,
    tokenizer=tokenizer,
    data_collator=data_collator,
<span class="hljs-addition">+   feature=&quot;seq2seq-lm&quot;,</span>
)

# Step 2: Use ONNX Runtime for training!\u{1F917}
train_result = trainer.train()`}}),De=new V({}),Ce=new W({props:{code:`-from transformers import TrainingArguments
+from optimum.onnxruntime import ORTTrainingArguments

-training_args = TrainingArguments(
+training_args =  ORTTrainingArguments(
    output_dir=tmp_dir,
    num_train_epochs=1,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    warmup_steps=500,
    weight_decay=0.01,
    logging_dir=tmp_dir,
    optim="adamw_ort_fused",  # Fused Adam optimizer implemented by ORT
)`,highlighted:`<span class="hljs-deletion">-from transformers import TrainingArguments</span>
<span class="hljs-addition">+from optimum.onnxruntime import ORTTrainingArguments</span>

<span class="hljs-deletion">-training_args = TrainingArguments(</span>
<span class="hljs-addition">+training_args =  ORTTrainingArguments(</span>
    output_dir=tmp_dir,
    num_train_epochs=1,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    warmup_steps=500,
    weight_decay=0.01,
    logging_dir=tmp_dir,
    optim=&quot;adamw_ort_fused&quot;,  # Fused Adam optimizer implemented by ORT
)`}}),se=new Yo({props:{warning:!1,$$slots:{default:[Mo]},$$scope:{ctx:Ve}}}),Xe=new V({}),Ie=new W({props:{code:`-from transformers import Seq2SeqTrainingArguments
+from optimum.onnxruntime import ORTSeq2SeqTrainingArguments

-training_args = Seq2SeqTrainingArguments(
+training_args =  ORTSeq2SeqTrainingArguments(
    output_dir=tmp_dir,
    num_train_epochs=1,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    warmup_steps=500,
    weight_decay=0.01,
    logging_dir=tmp_dir,
    optim="adamw_ort_fused",  # Fused Adam optimizer implemented by ORT
)`,highlighted:`<span class="hljs-deletion">-from transformers import Seq2SeqTrainingArguments</span>
<span class="hljs-addition">+from optimum.onnxruntime import ORTSeq2SeqTrainingArguments</span>

<span class="hljs-deletion">-training_args = Seq2SeqTrainingArguments(</span>
<span class="hljs-addition">+training_args =  ORTSeq2SeqTrainingArguments(</span>
    output_dir=tmp_dir,
    num_train_epochs=1,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    warmup_steps=500,
    weight_decay=0.01,
    logging_dir=tmp_dir,
    optim=&quot;adamw_ort_fused&quot;,  # Fused Adam optimizer implemented by ORT
)`}}),me=new Yo({props:{warning:!1,$$slots:{default:[Zo]},$$scope:{ctx:Ve}}}),je=new V({}),{c(){h=i("meta"),D=u(),c=i("h1"),y=i("a"),x=i("span"),d($.$$.fragment),E=u(),X=i("span"),Qr=o("Trainer"),rr=u(),O=i("p"),ei=o("The "),nt=i("code"),ti=o("ORTTrainer"),ri=o(" and "),at=i("code"),ii=o("ORTSeq2SeqTrainer"),ni=o(" classes provide APIs for training PyTorch models with "),ot=i("strong"),he=i("a"),ai=o("ONNX Runtime (ORT)"),oi=o(`.
Taking ONNX Runtime as backend, `),st=i("code"),si=o("ORTTrainer"),li=o(" and "),lt=i("code"),mi=o("ORTSeq2SeqTrainer"),pi=o(` optimize the computation graph and the memory usage. They also support
mixed precision training implemented by ORT, as well as distributed training on multiple GPUs. With them, you will be able to achieve
`),mt=i("strong"),ui=o("lower latency, higher throughput, and larger maximum batch size"),fi=o(" while training large transformers models."),ir=u(),Y=i("h2"),J=i("a"),pt=i("span"),d(ce.$$.fragment),hi=u(),ut=i("span"),ci=o("Prerequisite"),nr=u(),We=i("p"),di=o("To use ONNX Runtime for training, you need a machine with at least one NVIDIA or AMD GPU."),ar=u(),z=i("p"),gi=o("To use "),ft=i("code"),_i=o("ORTTrainer"),vi=o(" or "),ht=i("code"),Ti=o("ORTSeq2SeqTrainer"),wi=o(", you need to install ONNX Runtime Training module and Optimum."),or=u(),U=i("h3"),K=i("a"),ct=i("span"),d(de.$$.fragment),$i=u(),dt=i("span"),Oi=o("Install ONNX Runtime"),sr=u(),I=i("p"),Si=o("To set up the environment, we "),gt=i("strong"),qi=o("strongly recommend"),Ei=o(` you install the dependencies with Docker to ensure that the versions are correct and well
configured. You can find dockerfiles with various combinations `),ge=i("a"),yi=o("here"),Ri=o("."),lr=u(),Q=i("p"),bi=o("For example, if you want to install "),_e=i("a"),Ni=o("onnxruntime-training 1.12.0"),Ai=o(" via Dockerfile:"),mr=u(),d(ve.$$.fragment),pr=u(),Je=i("p"),ki=o("If you want to install the dependencies beyond in a local Python environment. You can pip install them once you have CUDA 11.3 and cuDNN 8 well installed."),ur=u(),d(Te.$$.fragment),fr=u(),Ke=i("p"),xi=o("And run post-installation configuration:"),hr=u(),d(we.$$.fragment),cr=u(),G=i("h3"),ee=i("a"),_t=i("span"),d($e.$$.fragment),Di=u(),vt=i("span"),Pi=o("Install Optimum"),dr=u(),Qe=i("p"),Ci=o("You can install Optimum via pypi:"),gr=u(),d(Oe.$$.fragment),_r=u(),et=i("p"),Xi=o("Or install from source:"),vr=u(),d(Se.$$.fragment),Tr=u(),te=i("p"),zi=o(`This command installs the current main dev version of Optimum, which could include latest developments(new features, bug fixes). However, the
main version might not be very stable. If you run into any problem, please open an `),qe=i("a"),Ii=o("issue"),ji=o(` so
that we can fix it as soon as possible.`),wr=u(),L=i("h2"),re=i("a"),Tt=i("span"),d(Ee.$$.fragment),Hi=u(),wt=i("span"),Yi=o("ORTTrainer"),$r=u(),S=i("p"),Ui=o("The "),$t=i("code"),Gi=o("ORTTrainer"),Li=o(" class inherits the "),ye=i("a"),Ot=i("code"),Bi=o("Trainer"),Fi=o(`
of Transformers. You can easily adapt the codes by replacing `),St=i("code"),Mi=o("Trainer"),Zi=o(" of transformers with "),qt=i("code"),Vi=o("ORTTrainer"),Wi=o(` to take advantage of the acceleration
empowered by ONNX Runtime. Here is an example of how to use `),Et=i("code"),Ji=o("ORTTrainer"),Ki=o(" compared with "),yt=i("code"),Qi=o("Trainer"),en=o(":"),Or=u(),d(Re.$$.fragment),Sr=u(),ie=i("p"),tn=o("Check out more detailed "),be=i("a"),rn=o("example scripts"),nn=o(" in the optimum repository."),qr=u(),B=i("h2"),ne=i("a"),Rt=i("span"),d(Ne.$$.fragment),an=u(),bt=i("span"),on=o("ORTSeq2SeqTrainer"),Er=u(),q=i("p"),sn=o("The "),Nt=i("code"),ln=o("ORTSeq2SeqTrainer"),mn=o(" class is similar to the "),Ae=i("a"),At=i("code"),pn=o("Seq2SeqTrainer"),un=o(`
of Transformers. You can easily adapt the codes by replacing `),kt=i("code"),fn=o("Seq2SeqTrainer"),hn=o(" of transformers with "),xt=i("code"),cn=o("ORTSeq2SeqTrainer"),dn=o(` to take advantage of the acceleration
empowered by ONNX Runtime. Here is an example of how to use `),Dt=i("code"),gn=o("ORTSeq2SeqTrainer"),_n=o(" compared with "),Pt=i("code"),vn=o("Seq2SeqTrainer"),Tn=o(":"),yr=u(),d(ke.$$.fragment),Rr=u(),ae=i("p"),wn=o("Check out more detailed "),xe=i("a"),$n=o("example scripts"),On=o(" in the optimum repository."),br=u(),F=i("h2"),oe=i("a"),Ct=i("span"),d(De.$$.fragment),Sn=u(),Xt=i("span"),qn=o("ORTTrainingArguments"),Nr=u(),R=i("p"),En=o("The "),zt=i("code"),yn=o("ORTTrainingArguments"),Rn=o(" class inherits the "),Pe=i("a"),It=i("code"),bn=o("TrainingArguments"),Nn=o(`
class in Transformers. Besides the optimizers implemented in Transformers, it allows you to use the optimizers implemented in ONNX Runtime.
Replace `),jt=i("code"),An=o("Seq2SeqTrainingArguments"),kn=o(" with "),Ht=i("code"),xn=o("ORTSeq2SeqTrainingArguments"),Dn=o(":"),Ar=u(),d(Ce.$$.fragment),kr=u(),d(se.$$.fragment),xr=u(),M=i("h2"),le=i("a"),Yt=i("span"),d(Xe.$$.fragment),Pn=u(),Ut=i("span"),Cn=o("ORTSeq2SeqTrainingArguments"),Dr=u(),b=i("p"),Xn=o("The "),Gt=i("code"),zn=o("ORTSeq2SeqTrainingArguments"),In=o(" class inherits the "),ze=i("a"),Lt=i("code"),jn=o("Seq2SeqTrainingArguments"),Hn=o(`
class in Transformers. Besides the optimizers implemented in Transformers, it allows you to use the optimizers implemented in ONNX Runtime.
Replace `),Bt=i("code"),Yn=o("Seq2SeqTrainingArguments"),Un=o(" with "),Ft=i("code"),Gn=o("ORTSeq2SeqTrainingArguments"),Ln=o(":"),Pr=u(),d(Ie.$$.fragment),Cr=u(),d(me.$$.fragment),Xr=u(),Z=i("h2"),pe=i("a"),Mt=i("span"),d(je.$$.fragment),Bn=u(),Zt=i("span"),Fn=o("Other Resources"),zr=u(),P=i("ul"),Vt=i("li"),He=i("a"),Mn=o("ONNX Runtime github"),Zn=u(),Wt=i("li"),Ye=i("a"),Vn=o("Torch ORT github"),Wn=u(),Jt=i("li"),Ue=i("a"),Jn=o("Download ONNX Runtime stable versions"),Kn=u(),tt=i("li"),Qn=o("Blog posts"),Ge=i("ul"),Kt=i("li"),Le=i("a"),ea=o("Accelerate PyTorch transformer model training with ONNX Runtime \u2013 a deep dive"),ta=u(),Qt=i("li"),Be=i("a"),ra=o("ONNX Runtime Training Technical Deep Dive"),Ir=u(),C=i("p"),ia=o("If you have any problems or questions regarding "),er=i("code"),na=o("ORTTrainer"),aa=o(", please file an issue with "),Fe=i("a"),oa=o("Optimum Github"),sa=o(`
or discuss with us on `),Me=i("a"),la=o("HuggingFace\u2019s community forum"),ma=o(", cheers \u{1F917} !"),this.h()},l(e){const l=Bo('[data-svelte="svelte-1phssyn"]',document.head);h=n(l,"META",{name:!0,content:!0}),l.forEach(r),D=f(e),c=n(e,"H1",{class:!0});var Ze=a(c);y=n(Ze,"A",{id:!0,class:!0,href:!0});var tr=a(y);x=n(tr,"SPAN",{});var ua=a(x);g($.$$.fragment,ua),ua.forEach(r),tr.forEach(r),E=f(Ze),X=n(Ze,"SPAN",{});var fa=a(X);Qr=s(fa,"Trainer"),fa.forEach(r),Ze.forEach(r),rr=f(e),O=n(e,"P",{});var N=a(O);ei=s(N,"The "),nt=n(N,"CODE",{});var ha=a(nt);ti=s(ha,"ORTTrainer"),ha.forEach(r),ri=s(N," and "),at=n(N,"CODE",{});var ca=a(at);ii=s(ca,"ORTSeq2SeqTrainer"),ca.forEach(r),ni=s(N," classes provide APIs for training PyTorch models with "),ot=n(N,"STRONG",{});var da=a(ot);he=n(da,"A",{href:!0,rel:!0});var ga=a(he);ai=s(ga,"ONNX Runtime (ORT)"),ga.forEach(r),da.forEach(r),oi=s(N,`.
Taking ONNX Runtime as backend, `),st=n(N,"CODE",{});var _a=a(st);si=s(_a,"ORTTrainer"),_a.forEach(r),li=s(N," and "),lt=n(N,"CODE",{});var va=a(lt);mi=s(va,"ORTSeq2SeqTrainer"),va.forEach(r),pi=s(N,` optimize the computation graph and the memory usage. They also support
mixed precision training implemented by ORT, as well as distributed training on multiple GPUs. With them, you will be able to achieve
`),mt=n(N,"STRONG",{});var Ta=a(mt);ui=s(Ta,"lower latency, higher throughput, and larger maximum batch size"),Ta.forEach(r),fi=s(N," while training large transformers models."),N.forEach(r),ir=f(e),Y=n(e,"H2",{class:!0});var Hr=a(Y);J=n(Hr,"A",{id:!0,class:!0,href:!0});var wa=a(J);pt=n(wa,"SPAN",{});var $a=a(pt);g(ce.$$.fragment,$a),$a.forEach(r),wa.forEach(r),hi=f(Hr),ut=n(Hr,"SPAN",{});var Oa=a(ut);ci=s(Oa,"Prerequisite"),Oa.forEach(r),Hr.forEach(r),nr=f(e),We=n(e,"P",{});var Sa=a(We);di=s(Sa,"To use ONNX Runtime for training, you need a machine with at least one NVIDIA or AMD GPU."),Sa.forEach(r),ar=f(e),z=n(e,"P",{});var rt=a(z);gi=s(rt,"To use "),ft=n(rt,"CODE",{});var qa=a(ft);_i=s(qa,"ORTTrainer"),qa.forEach(r),vi=s(rt," or "),ht=n(rt,"CODE",{});var Ea=a(ht);Ti=s(Ea,"ORTSeq2SeqTrainer"),Ea.forEach(r),wi=s(rt,", you need to install ONNX Runtime Training module and Optimum."),rt.forEach(r),or=f(e),U=n(e,"H3",{class:!0});var Yr=a(U);K=n(Yr,"A",{id:!0,class:!0,href:!0});var ya=a(K);ct=n(ya,"SPAN",{});var Ra=a(ct);g(de.$$.fragment,Ra),Ra.forEach(r),ya.forEach(r),$i=f(Yr),dt=n(Yr,"SPAN",{});var ba=a(dt);Oi=s(ba,"Install ONNX Runtime"),ba.forEach(r),Yr.forEach(r),sr=f(e),I=n(e,"P",{});var it=a(I);Si=s(it,"To set up the environment, we "),gt=n(it,"STRONG",{});var Na=a(gt);qi=s(Na,"strongly recommend"),Na.forEach(r),Ei=s(it,` you install the dependencies with Docker to ensure that the versions are correct and well
configured. You can find dockerfiles with various combinations `),ge=n(it,"A",{href:!0,rel:!0});var Aa=a(ge);yi=s(Aa,"here"),Aa.forEach(r),Ri=s(it,"."),it.forEach(r),lr=f(e),Q=n(e,"P",{});var Ur=a(Q);bi=s(Ur,"For example, if you want to install "),_e=n(Ur,"A",{href:!0,rel:!0});var ka=a(_e);Ni=s(ka,"onnxruntime-training 1.12.0"),ka.forEach(r),Ai=s(Ur," via Dockerfile:"),Ur.forEach(r),mr=f(e),g(ve.$$.fragment,e),pr=f(e),Je=n(e,"P",{});var xa=a(Je);ki=s(xa,"If you want to install the dependencies beyond in a local Python environment. You can pip install them once you have CUDA 11.3 and cuDNN 8 well installed."),xa.forEach(r),ur=f(e),g(Te.$$.fragment,e),fr=f(e),Ke=n(e,"P",{});var Da=a(Ke);xi=s(Da,"And run post-installation configuration:"),Da.forEach(r),hr=f(e),g(we.$$.fragment,e),cr=f(e),G=n(e,"H3",{class:!0});var Gr=a(G);ee=n(Gr,"A",{id:!0,class:!0,href:!0});var Pa=a(ee);_t=n(Pa,"SPAN",{});var Ca=a(_t);g($e.$$.fragment,Ca),Ca.forEach(r),Pa.forEach(r),Di=f(Gr),vt=n(Gr,"SPAN",{});var Xa=a(vt);Pi=s(Xa,"Install Optimum"),Xa.forEach(r),Gr.forEach(r),dr=f(e),Qe=n(e,"P",{});var za=a(Qe);Ci=s(za,"You can install Optimum via pypi:"),za.forEach(r),gr=f(e),g(Oe.$$.fragment,e),_r=f(e),et=n(e,"P",{});var Ia=a(et);Xi=s(Ia,"Or install from source:"),Ia.forEach(r),vr=f(e),g(Se.$$.fragment,e),Tr=f(e),te=n(e,"P",{});var Lr=a(te);zi=s(Lr,`This command installs the current main dev version of Optimum, which could include latest developments(new features, bug fixes). However, the
main version might not be very stable. If you run into any problem, please open an `),qe=n(Lr,"A",{href:!0,rel:!0});var ja=a(qe);Ii=s(ja,"issue"),ja.forEach(r),ji=s(Lr,` so
that we can fix it as soon as possible.`),Lr.forEach(r),wr=f(e),L=n(e,"H2",{class:!0});var Br=a(L);re=n(Br,"A",{id:!0,class:!0,href:!0});var Ha=a(re);Tt=n(Ha,"SPAN",{});var Ya=a(Tt);g(Ee.$$.fragment,Ya),Ya.forEach(r),Ha.forEach(r),Hi=f(Br),wt=n(Br,"SPAN",{});var Ua=a(wt);Yi=s(Ua,"ORTTrainer"),Ua.forEach(r),Br.forEach(r),$r=f(e),S=n(e,"P",{});var A=a(S);Ui=s(A,"The "),$t=n(A,"CODE",{});var Ga=a($t);Gi=s(Ga,"ORTTrainer"),Ga.forEach(r),Li=s(A," class inherits the "),ye=n(A,"A",{href:!0,rel:!0});var La=a(ye);Ot=n(La,"CODE",{});var Ba=a(Ot);Bi=s(Ba,"Trainer"),Ba.forEach(r),La.forEach(r),Fi=s(A,`
of Transformers. You can easily adapt the codes by replacing `),St=n(A,"CODE",{});var Fa=a(St);Mi=s(Fa,"Trainer"),Fa.forEach(r),Zi=s(A," of transformers with "),qt=n(A,"CODE",{});var Ma=a(qt);Vi=s(Ma,"ORTTrainer"),Ma.forEach(r),Wi=s(A,` to take advantage of the acceleration
empowered by ONNX Runtime. Here is an example of how to use `),Et=n(A,"CODE",{});var Za=a(Et);Ji=s(Za,"ORTTrainer"),Za.forEach(r),Ki=s(A," compared with "),yt=n(A,"CODE",{});var Va=a(yt);Qi=s(Va,"Trainer"),Va.forEach(r),en=s(A,":"),A.forEach(r),Or=f(e),g(Re.$$.fragment,e),Sr=f(e),ie=n(e,"P",{});var Fr=a(ie);tn=s(Fr,"Check out more detailed "),be=n(Fr,"A",{href:!0,rel:!0});var Wa=a(be);rn=s(Wa,"example scripts"),Wa.forEach(r),nn=s(Fr," in the optimum repository."),Fr.forEach(r),qr=f(e),B=n(e,"H2",{class:!0});var Mr=a(B);ne=n(Mr,"A",{id:!0,class:!0,href:!0});var Ja=a(ne);Rt=n(Ja,"SPAN",{});var Ka=a(Rt);g(Ne.$$.fragment,Ka),Ka.forEach(r),Ja.forEach(r),an=f(Mr),bt=n(Mr,"SPAN",{});var Qa=a(bt);on=s(Qa,"ORTSeq2SeqTrainer"),Qa.forEach(r),Mr.forEach(r),Er=f(e),q=n(e,"P",{});var k=a(q);sn=s(k,"The "),Nt=n(k,"CODE",{});var eo=a(Nt);ln=s(eo,"ORTSeq2SeqTrainer"),eo.forEach(r),mn=s(k," class is similar to the "),Ae=n(k,"A",{href:!0,rel:!0});var to=a(Ae);At=n(to,"CODE",{});var ro=a(At);pn=s(ro,"Seq2SeqTrainer"),ro.forEach(r),to.forEach(r),un=s(k,`
of Transformers. You can easily adapt the codes by replacing `),kt=n(k,"CODE",{});var io=a(kt);fn=s(io,"Seq2SeqTrainer"),io.forEach(r),hn=s(k," of transformers with "),xt=n(k,"CODE",{});var no=a(xt);cn=s(no,"ORTSeq2SeqTrainer"),no.forEach(r),dn=s(k,` to take advantage of the acceleration
empowered by ONNX Runtime. Here is an example of how to use `),Dt=n(k,"CODE",{});var ao=a(Dt);gn=s(ao,"ORTSeq2SeqTrainer"),ao.forEach(r),_n=s(k," compared with "),Pt=n(k,"CODE",{});var oo=a(Pt);vn=s(oo,"Seq2SeqTrainer"),oo.forEach(r),Tn=s(k,":"),k.forEach(r),yr=f(e),g(ke.$$.fragment,e),Rr=f(e),ae=n(e,"P",{});var Zr=a(ae);wn=s(Zr,"Check out more detailed "),xe=n(Zr,"A",{href:!0,rel:!0});var so=a(xe);$n=s(so,"example scripts"),so.forEach(r),On=s(Zr," in the optimum repository."),Zr.forEach(r),br=f(e),F=n(e,"H2",{class:!0});var Vr=a(F);oe=n(Vr,"A",{id:!0,class:!0,href:!0});var lo=a(oe);Ct=n(lo,"SPAN",{});var mo=a(Ct);g(De.$$.fragment,mo),mo.forEach(r),lo.forEach(r),Sn=f(Vr),Xt=n(Vr,"SPAN",{});var po=a(Xt);qn=s(po,"ORTTrainingArguments"),po.forEach(r),Vr.forEach(r),Nr=f(e),R=n(e,"P",{});var j=a(R);En=s(j,"The "),zt=n(j,"CODE",{});var uo=a(zt);yn=s(uo,"ORTTrainingArguments"),uo.forEach(r),Rn=s(j," class inherits the "),Pe=n(j,"A",{href:!0,rel:!0});var fo=a(Pe);It=n(fo,"CODE",{});var ho=a(It);bn=s(ho,"TrainingArguments"),ho.forEach(r),fo.forEach(r),Nn=s(j,`
class in Transformers. Besides the optimizers implemented in Transformers, it allows you to use the optimizers implemented in ONNX Runtime.
Replace `),jt=n(j,"CODE",{});var co=a(jt);An=s(co,"Seq2SeqTrainingArguments"),co.forEach(r),kn=s(j," with "),Ht=n(j,"CODE",{});var go=a(Ht);xn=s(go,"ORTSeq2SeqTrainingArguments"),go.forEach(r),Dn=s(j,":"),j.forEach(r),Ar=f(e),g(Ce.$$.fragment,e),kr=f(e),g(se.$$.fragment,e),xr=f(e),M=n(e,"H2",{class:!0});var Wr=a(M);le=n(Wr,"A",{id:!0,class:!0,href:!0});var _o=a(le);Yt=n(_o,"SPAN",{});var vo=a(Yt);g(Xe.$$.fragment,vo),vo.forEach(r),_o.forEach(r),Pn=f(Wr),Ut=n(Wr,"SPAN",{});var To=a(Ut);Cn=s(To,"ORTSeq2SeqTrainingArguments"),To.forEach(r),Wr.forEach(r),Dr=f(e),b=n(e,"P",{});var H=a(b);Xn=s(H,"The "),Gt=n(H,"CODE",{});var wo=a(Gt);zn=s(wo,"ORTSeq2SeqTrainingArguments"),wo.forEach(r),In=s(H," class inherits the "),ze=n(H,"A",{href:!0,rel:!0});var $o=a(ze);Lt=n($o,"CODE",{});var Oo=a(Lt);jn=s(Oo,"Seq2SeqTrainingArguments"),Oo.forEach(r),$o.forEach(r),Hn=s(H,`
class in Transformers. Besides the optimizers implemented in Transformers, it allows you to use the optimizers implemented in ONNX Runtime.
Replace `),Bt=n(H,"CODE",{});var So=a(Bt);Yn=s(So,"Seq2SeqTrainingArguments"),So.forEach(r),Un=s(H," with "),Ft=n(H,"CODE",{});var qo=a(Ft);Gn=s(qo,"ORTSeq2SeqTrainingArguments"),qo.forEach(r),Ln=s(H,":"),H.forEach(r),Pr=f(e),g(Ie.$$.fragment,e),Cr=f(e),g(me.$$.fragment,e),Xr=f(e),Z=n(e,"H2",{class:!0});var Jr=a(Z);pe=n(Jr,"A",{id:!0,class:!0,href:!0});var Eo=a(pe);Mt=n(Eo,"SPAN",{});var yo=a(Mt);g(je.$$.fragment,yo),yo.forEach(r),Eo.forEach(r),Bn=f(Jr),Zt=n(Jr,"SPAN",{});var Ro=a(Zt);Fn=s(Ro,"Other Resources"),Ro.forEach(r),Jr.forEach(r),zr=f(e),P=n(e,"UL",{});var ue=a(P);Vt=n(ue,"LI",{});var bo=a(Vt);He=n(bo,"A",{href:!0,rel:!0});var No=a(He);Mn=s(No,"ONNX Runtime github"),No.forEach(r),bo.forEach(r),Zn=f(ue),Wt=n(ue,"LI",{});var Ao=a(Wt);Ye=n(Ao,"A",{href:!0,rel:!0});var ko=a(Ye);Vn=s(ko,"Torch ORT github"),ko.forEach(r),Ao.forEach(r),Wn=f(ue),Jt=n(ue,"LI",{});var xo=a(Jt);Ue=n(xo,"A",{href:!0,rel:!0});var Do=a(Ue);Jn=s(Do,"Download ONNX Runtime stable versions"),Do.forEach(r),xo.forEach(r),Kn=f(ue),tt=n(ue,"LI",{});var pa=a(tt);Qn=s(pa,"Blog posts"),Ge=n(pa,"UL",{});var Kr=a(Ge);Kt=n(Kr,"LI",{});var Po=a(Kt);Le=n(Po,"A",{href:!0,rel:!0});var Co=a(Le);ea=s(Co,"Accelerate PyTorch transformer model training with ONNX Runtime \u2013 a deep dive"),Co.forEach(r),Po.forEach(r),ta=f(Kr),Qt=n(Kr,"LI",{});var Xo=a(Qt);Be=n(Xo,"A",{href:!0,rel:!0});var zo=a(Be);ra=s(zo,"ONNX Runtime Training Technical Deep Dive"),zo.forEach(r),Xo.forEach(r),Kr.forEach(r),pa.forEach(r),ue.forEach(r),Ir=f(e),C=n(e,"P",{});var fe=a(C);ia=s(fe,"If you have any problems or questions regarding "),er=n(fe,"CODE",{});var Io=a(er);na=s(Io,"ORTTrainer"),Io.forEach(r),aa=s(fe,", please file an issue with "),Fe=n(fe,"A",{href:!0,rel:!0});var jo=a(Fe);oa=s(jo,"Optimum Github"),jo.forEach(r),sa=s(fe,`
or discuss with us on `),Me=n(fe,"A",{href:!0,rel:!0});var Ho=a(Me);la=s(Ho,"HuggingFace\u2019s community forum"),Ho.forEach(r),ma=s(fe,", cheers \u{1F917} !"),fe.forEach(r),this.h()},h(){m(h,"name","hf:doc:metadata"),m(h,"content",JSON.stringify(Wo)),m(y,"id","trainer"),m(y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(y,"href","#trainer"),m(c,"class","relative group"),m(he,"href","https://onnxruntime.ai/"),m(he,"rel","nofollow"),m(J,"id","prerequisite"),m(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(J,"href","#prerequisite"),m(Y,"class","relative group"),m(K,"id","install-onnx-runtime"),m(K,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(K,"href","#install-onnx-runtime"),m(U,"class","relative group"),m(ge,"href","https://github.com/huggingface/optimum/tree/main/examples/onnxruntime/training/docker"),m(ge,"rel","nofollow"),m(_e,"href","https://github.com/huggingface/optimum/blob/main/examples/onnxruntime/training/docker/Dockerfile-ort1.12.0-cu113"),m(_e,"rel","nofollow"),m(ee,"id","install-optimum"),m(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ee,"href","#install-optimum"),m(G,"class","relative group"),m(qe,"href","https://github.com/huggingface/optimum/issues"),m(qe,"rel","nofollow"),m(re,"id","orttrainer"),m(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(re,"href","#orttrainer"),m(L,"class","relative group"),m(ye,"href","https://huggingface.co/docs/transformers/main/en/main_classes/trainer#trainer"),m(ye,"rel","nofollow"),m(be,"href","https://github.com/huggingface/optimum/tree/main/examples/onnxruntime/training"),m(be,"rel","nofollow"),m(ne,"id","ortseq2seqtrainer"),m(ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ne,"href","#ortseq2seqtrainer"),m(B,"class","relative group"),m(Ae,"href","https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Seq2SeqTrainer"),m(Ae,"rel","nofollow"),m(xe,"href","https://github.com/huggingface/optimum/tree/main/examples/onnxruntime/training"),m(xe,"rel","nofollow"),m(oe,"id","orttrainingarguments"),m(oe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(oe,"href","#orttrainingarguments"),m(F,"class","relative group"),m(Pe,"href","https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments"),m(Pe,"rel","nofollow"),m(le,"id","ortseq2seqtrainingarguments"),m(le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(le,"href","#ortseq2seqtrainingarguments"),m(M,"class","relative group"),m(ze,"href","https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Seq2SeqTrainingArguments"),m(ze,"rel","nofollow"),m(pe,"id","other-resources"),m(pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(pe,"href","#other-resources"),m(Z,"class","relative group"),m(He,"href","https://github.com/microsoft/onnxruntime"),m(He,"rel","nofollow"),m(Ye,"href","https://github.com/pytorch/ort"),m(Ye,"rel","nofollow"),m(Ue,"href","https://download.onnxruntime.ai/"),m(Ue,"rel","nofollow"),m(Le,"href","https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/accelerate-pytorch-transformer-model-training-with-onnx-runtime/ba-p/2540471"),m(Le,"rel","nofollow"),m(Be,"href","https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/onnx-runtime-training-technical-deep-dive/ba-p/1398310"),m(Be,"rel","nofollow"),m(Fe,"href","https://github.com/huggingface/optimum"),m(Fe,"rel","nofollow"),m(Me,"href","https://discuss.huggingface.co/c/optimum/"),m(Me,"rel","nofollow")},m(e,l){t(document.head,h),p(e,D,l),p(e,c,l),t(c,y),t(y,x),_($,x,null),t(c,E),t(c,X),t(X,Qr),p(e,rr,l),p(e,O,l),t(O,ei),t(O,nt),t(nt,ti),t(O,ri),t(O,at),t(at,ii),t(O,ni),t(O,ot),t(ot,he),t(he,ai),t(O,oi),t(O,st),t(st,si),t(O,li),t(O,lt),t(lt,mi),t(O,pi),t(O,mt),t(mt,ui),t(O,fi),p(e,ir,l),p(e,Y,l),t(Y,J),t(J,pt),_(ce,pt,null),t(Y,hi),t(Y,ut),t(ut,ci),p(e,nr,l),p(e,We,l),t(We,di),p(e,ar,l),p(e,z,l),t(z,gi),t(z,ft),t(ft,_i),t(z,vi),t(z,ht),t(ht,Ti),t(z,wi),p(e,or,l),p(e,U,l),t(U,K),t(K,ct),_(de,ct,null),t(U,$i),t(U,dt),t(dt,Oi),p(e,sr,l),p(e,I,l),t(I,Si),t(I,gt),t(gt,qi),t(I,Ei),t(I,ge),t(ge,yi),t(I,Ri),p(e,lr,l),p(e,Q,l),t(Q,bi),t(Q,_e),t(_e,Ni),t(Q,Ai),p(e,mr,l),_(ve,e,l),p(e,pr,l),p(e,Je,l),t(Je,ki),p(e,ur,l),_(Te,e,l),p(e,fr,l),p(e,Ke,l),t(Ke,xi),p(e,hr,l),_(we,e,l),p(e,cr,l),p(e,G,l),t(G,ee),t(ee,_t),_($e,_t,null),t(G,Di),t(G,vt),t(vt,Pi),p(e,dr,l),p(e,Qe,l),t(Qe,Ci),p(e,gr,l),_(Oe,e,l),p(e,_r,l),p(e,et,l),t(et,Xi),p(e,vr,l),_(Se,e,l),p(e,Tr,l),p(e,te,l),t(te,zi),t(te,qe),t(qe,Ii),t(te,ji),p(e,wr,l),p(e,L,l),t(L,re),t(re,Tt),_(Ee,Tt,null),t(L,Hi),t(L,wt),t(wt,Yi),p(e,$r,l),p(e,S,l),t(S,Ui),t(S,$t),t($t,Gi),t(S,Li),t(S,ye),t(ye,Ot),t(Ot,Bi),t(S,Fi),t(S,St),t(St,Mi),t(S,Zi),t(S,qt),t(qt,Vi),t(S,Wi),t(S,Et),t(Et,Ji),t(S,Ki),t(S,yt),t(yt,Qi),t(S,en),p(e,Or,l),_(Re,e,l),p(e,Sr,l),p(e,ie,l),t(ie,tn),t(ie,be),t(be,rn),t(ie,nn),p(e,qr,l),p(e,B,l),t(B,ne),t(ne,Rt),_(Ne,Rt,null),t(B,an),t(B,bt),t(bt,on),p(e,Er,l),p(e,q,l),t(q,sn),t(q,Nt),t(Nt,ln),t(q,mn),t(q,Ae),t(Ae,At),t(At,pn),t(q,un),t(q,kt),t(kt,fn),t(q,hn),t(q,xt),t(xt,cn),t(q,dn),t(q,Dt),t(Dt,gn),t(q,_n),t(q,Pt),t(Pt,vn),t(q,Tn),p(e,yr,l),_(ke,e,l),p(e,Rr,l),p(e,ae,l),t(ae,wn),t(ae,xe),t(xe,$n),t(ae,On),p(e,br,l),p(e,F,l),t(F,oe),t(oe,Ct),_(De,Ct,null),t(F,Sn),t(F,Xt),t(Xt,qn),p(e,Nr,l),p(e,R,l),t(R,En),t(R,zt),t(zt,yn),t(R,Rn),t(R,Pe),t(Pe,It),t(It,bn),t(R,Nn),t(R,jt),t(jt,An),t(R,kn),t(R,Ht),t(Ht,xn),t(R,Dn),p(e,Ar,l),_(Ce,e,l),p(e,kr,l),_(se,e,l),p(e,xr,l),p(e,M,l),t(M,le),t(le,Yt),_(Xe,Yt,null),t(M,Pn),t(M,Ut),t(Ut,Cn),p(e,Dr,l),p(e,b,l),t(b,Xn),t(b,Gt),t(Gt,zn),t(b,In),t(b,ze),t(ze,Lt),t(Lt,jn),t(b,Hn),t(b,Bt),t(Bt,Yn),t(b,Un),t(b,Ft),t(Ft,Gn),t(b,Ln),p(e,Pr,l),_(Ie,e,l),p(e,Cr,l),_(me,e,l),p(e,Xr,l),p(e,Z,l),t(Z,pe),t(pe,Mt),_(je,Mt,null),t(Z,Bn),t(Z,Zt),t(Zt,Fn),p(e,zr,l),p(e,P,l),t(P,Vt),t(Vt,He),t(He,Mn),t(P,Zn),t(P,Wt),t(Wt,Ye),t(Ye,Vn),t(P,Wn),t(P,Jt),t(Jt,Ue),t(Ue,Jn),t(P,Kn),t(P,tt),t(tt,Qn),t(tt,Ge),t(Ge,Kt),t(Kt,Le),t(Le,ea),t(Ge,ta),t(Ge,Qt),t(Qt,Be),t(Be,ra),p(e,Ir,l),p(e,C,l),t(C,ia),t(C,er),t(er,na),t(C,aa),t(C,Fe),t(Fe,oa),t(C,sa),t(C,Me),t(Me,la),t(C,ma),jr=!0},p(e,[l]){const Ze={};l&2&&(Ze.$$scope={dirty:l,ctx:e}),se.$set(Ze);const tr={};l&2&&(tr.$$scope={dirty:l,ctx:e}),me.$set(tr)},i(e){jr||(v($.$$.fragment,e),v(ce.$$.fragment,e),v(de.$$.fragment,e),v(ve.$$.fragment,e),v(Te.$$.fragment,e),v(we.$$.fragment,e),v($e.$$.fragment,e),v(Oe.$$.fragment,e),v(Se.$$.fragment,e),v(Ee.$$.fragment,e),v(Re.$$.fragment,e),v(Ne.$$.fragment,e),v(ke.$$.fragment,e),v(De.$$.fragment,e),v(Ce.$$.fragment,e),v(se.$$.fragment,e),v(Xe.$$.fragment,e),v(Ie.$$.fragment,e),v(me.$$.fragment,e),v(je.$$.fragment,e),jr=!0)},o(e){T($.$$.fragment,e),T(ce.$$.fragment,e),T(de.$$.fragment,e),T(ve.$$.fragment,e),T(Te.$$.fragment,e),T(we.$$.fragment,e),T($e.$$.fragment,e),T(Oe.$$.fragment,e),T(Se.$$.fragment,e),T(Ee.$$.fragment,e),T(Re.$$.fragment,e),T(Ne.$$.fragment,e),T(ke.$$.fragment,e),T(De.$$.fragment,e),T(Ce.$$.fragment,e),T(se.$$.fragment,e),T(Xe.$$.fragment,e),T(Ie.$$.fragment,e),T(me.$$.fragment,e),T(je.$$.fragment,e),jr=!1},d(e){r(h),e&&r(D),e&&r(c),w($),e&&r(rr),e&&r(O),e&&r(ir),e&&r(Y),w(ce),e&&r(nr),e&&r(We),e&&r(ar),e&&r(z),e&&r(or),e&&r(U),w(de),e&&r(sr),e&&r(I),e&&r(lr),e&&r(Q),e&&r(mr),w(ve,e),e&&r(pr),e&&r(Je),e&&r(ur),w(Te,e),e&&r(fr),e&&r(Ke),e&&r(hr),w(we,e),e&&r(cr),e&&r(G),w($e),e&&r(dr),e&&r(Qe),e&&r(gr),w(Oe,e),e&&r(_r),e&&r(et),e&&r(vr),w(Se,e),e&&r(Tr),e&&r(te),e&&r(wr),e&&r(L),w(Ee),e&&r($r),e&&r(S),e&&r(Or),w(Re,e),e&&r(Sr),e&&r(ie),e&&r(qr),e&&r(B),w(Ne),e&&r(Er),e&&r(q),e&&r(yr),w(ke,e),e&&r(Rr),e&&r(ae),e&&r(br),e&&r(F),w(De),e&&r(Nr),e&&r(R),e&&r(Ar),w(Ce,e),e&&r(kr),w(se,e),e&&r(xr),e&&r(M),w(Xe),e&&r(Dr),e&&r(b),e&&r(Pr),w(Ie,e),e&&r(Cr),w(me,e),e&&r(Xr),e&&r(Z),w(je),e&&r(zr),e&&r(P),e&&r(Ir),e&&r(C)}}}const Wo={local:"trainer",sections:[{local:"prerequisite",sections:[{local:"install-onnx-runtime",title:"Install ONNX Runtime"},{local:"install-optimum",title:"Install Optimum"}],title:"Prerequisite"},{local:"orttrainer",title:"ORTTrainer"},{local:"ortseq2seqtrainer",title:"ORTSeq2SeqTrainer"},{local:"orttrainingarguments",title:"ORTTrainingArguments"},{local:"ortseq2seqtrainingarguments",title:"ORTSeq2SeqTrainingArguments"},{local:"other-resources",title:"Other Resources"}],title:"Trainer"};function Jo(Ve){return Fo(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class rs extends Uo{constructor(h){super();Go(this,h,Jo,Vo,Lo,{})}}export{rs as default,Wo as metadata};
