import{S as Te,i as $e,s as ke,e as n,k as s,w as T,t as $,M as Ne,c as i,d as o,m as l,a,x as k,h as N,b as m,F as t,g as P,y as L,L as Pe,q as F,o as E,B as A,v as Le}from"../../chunks/vendor-19e06bd2.js";import{D as Y}from"../../chunks/Docstring-395e5a9c.js";import{I as Re}from"../../chunks/IconCopyLink-3c713d38.js";function Fe(he){let d,G,u,g,W,b,Z,I,ee,q,c,f,D,v,te,X,oe,B,r,z,ne,S,ie,ae,_,y,re,C,me,se,x,w,le,H,pe,de,O,R,ue,U,ce,V;return b=new Re({}),v=new Re({}),z=new Y({props:{name:"class optimum.onnxruntime.ORTOptimizer",anchor:"optimum.onnxruntime.ORTOptimizer",parameters:[{name:"ort_config",val:": ORTConfig"},{name:"optimization_config",val:": OptimizationConfig"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/optimum/blob/v1.0.0/src/optimum/onnxruntime/optimization.py#L43"}}),y=new Y({props:{name:"export",anchor:"optimum.onnxruntime.ORTOptimizer.export",parameters:[{name:"model_name_or_path",val:": typing.Union[str, os.PathLike]"},{name:"output_path",val:": typing.Union[str, os.PathLike]"},{name:"feature",val:": str = 'default'"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/optimum/blob/v1.0.0/src/optimum/onnxruntime/optimization.py#L89",parametersDescription:[{anchor:"optimum.onnxruntime.ORTOptimizer.export.model_name_or_path",description:`<strong>model_name_or_path</strong> (<em>Union[str, os.PathLike]</em>) &#x2014;
Repository name in the Hugging Face Hub or path to a local directory hosting the model.`,name:"model_name_or_path"},{anchor:"optimum.onnxruntime.ORTOptimizer.export.output_path",description:`<strong>output_path</strong> (<em>os.PathLike</em>) &#x2014;
The path used to save the model exported to an ONNX Intermediate Representation (IR).`,name:"output_path"},{anchor:"optimum.onnxruntime.ORTOptimizer.export.feature",description:`<strong>feature</strong> (<em>str</em>, defaults to <em>&#x201C;default&#x201D;</em>) &#x2014;
Feature to use when exporting the model.`,name:"feature"},{anchor:"optimum.onnxruntime.ORTOptimizer.export.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"optimum.onnxruntime.ORTOptimizer.export.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"optimum.onnxruntime.ORTOptimizer.export.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"optimum.onnxruntime.ORTOptimizer.export.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>) &#x2014;
The specific version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"}]}}),w=new Y({props:{name:"fit",anchor:"optimum.onnxruntime.ORTOptimizer.fit",parameters:[{name:"model_name_or_path",val:": typing.Union[str, os.PathLike]"},{name:"output_dir",val:": typing.Union[str, os.PathLike]"},{name:"feature",val:": str = 'default'"},{name:"config",val:": typing.Optional[transformers.configuration_utils.PretrainedConfig] = None"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/optimum/blob/v1.0.0/src/optimum/onnxruntime/optimization.py#L142",parametersDescription:[{anchor:"optimum.onnxruntime.ORTOptimizer.fit.model_name_or_path",description:`<strong>model_name_or_path</strong> (<em>Union[str, os.PathLike]</em>) &#x2014;
Repository name in the Hugging Face Hub, path to a local directory hosting the model or path to a
pre-existing onnx model.`,name:"model_name_or_path"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.output_dir",description:`<strong>output_dir</strong> (<em>Union[str, os.PathLike]</em>) &#x2014;
The output directory where the optimized model will be saved.`,name:"output_dir"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.feature",description:`<strong>feature</strong> (<em>str</em>, defaults to <em>&#x201C;default&#x201D;</em>) &#x2014;
Feature to use when exporting the model.`,name:"feature"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.config",description:`<strong>config</strong> (<em>PretrainedConfig</em>, <em>optional</em>) &#x2014;
A configuration associated to the pre-existing ONNX model.`,name:"config"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.cache_dir",description:`<strong>cache_dir</strong> (<em>str</em>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.force_download",description:`<strong>force_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.resume_download",description:`<strong>resume_download</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.revision(str,",description:`<strong>revision(<em>str</em>,</strong> <em>optional</em>) &#x2014;
The specific version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision(str,"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.disable_gelu",description:`<strong>disable_gelu</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to disable Gelu fusion.`,name:"disable_gelu"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.disable_layer_norm",description:`<strong>disable_layer_norm</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to disable LayerNormalization fusion.`,name:"disable_layer_norm"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.disable_attention",description:`<strong>disable_attention</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to disable Attention fusion.`,name:"disable_attention"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.disable_skip_layer_norm",description:`<strong>disable_skip_layer_norm</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to disable SkipLayerNormalization fusion.`,name:"disable_skip_layer_norm"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.disable_bias_skip_layer_norm",description:`<strong>disable_bias_skip_layer_norm</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to disable Add Bias and SkipLayerNormalization fusion.`,name:"disable_bias_skip_layer_norm"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.disable_bias_gelu",description:`<strong>disable_bias_gelu</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to disable Add Bias and Gelu/FastGelu fusion.`,name:"disable_bias_gelu"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.enable_gelu_approximation",description:`<strong>enable_gelu_approximation</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to enable Gelu/BiasGelu to FastGelu conversion. The default value
is set to <em>False</em> since the approximation might slightly impact the accuracy of
models.`,name:"enable_gelu_approximation"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.use_mask_index",description:`<strong>use_mask_index</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
Whether or not to use mask index instead of raw attention mask in attention operator.`,name:"use_mask_index"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.no_attention_mask",description:`<strong>no_attention_mask</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>False</em>) &#x2014;
No attention mask. Only works for <em>model_type=bert</em>.`,name:"no_attention_mask"},{anchor:"optimum.onnxruntime.ORTOptimizer.fit.disable_embed_layer_norm",description:`<strong>disable_embed_layer_norm</strong> (<em>bool</em>, <em>optional</em>, defaults to <em>True</em>) &#x2014;
Whether or not to disable EmbedLayerNormalization fusion. The default value is set to
<em>True</em> since the fusion is incompatible with ONNX Runtime quantization.`,name:"disable_embed_layer_norm"}]}}),R=new Y({props:{name:"get_optimize_details",anchor:"optimum.onnxruntime.ORTOptimizer.get_optimize_details",parameters:[{name:"onnx_model_path",val:": typing.Optional[str] = None"},{name:"optimized_model_path",val:": typing.Optional[str] = None"},{name:"summary",val:": bool = True"},{name:"nodes_details",val:": bool = True"}],source:"https://github.com/huggingface/optimum/blob/v1.0.0/src/optimum/onnxruntime/optimization.py#L256",parametersDescription:[{anchor:"optimum.onnxruntime.ORTOptimizer.get_optimize_details.onnx_model_path",description:`<strong>onnx_model_path</strong> (<code>str</code>, <code>optional</code>) &#x2014;
Path of a stored ONNX model.`,name:"onnx_model_path"},{anchor:"optimum.onnxruntime.ORTOptimizer.get_optimize_details.optimized_model_path",description:`<strong>optimized_model_path</strong> (<code>str</code>, <code>optional</code>) &#x2014;
Path of the corresponding optimized ONNX model.`,name:"optimized_model_path"},{anchor:"optimum.onnxruntime.ORTOptimizer.get_optimize_details.summary",description:`<strong>summary</strong> (<code>bool</code>, defaults to <code>True</code>) &#x2014;
Whether report the optimization details: reduction of nodes, and complex node fusions.`,name:"summary"},{anchor:"optimum.onnxruntime.ORTOptimizer.get_optimize_details.nodes_details",description:`<strong>nodes_details</strong> (<code>bool</code>, defaults to <code>True</code>) &#x2014;
Whether report the top 5 reduced op_types, and return the detailed node change list.`,name:"nodes_details"}],returnDescription:`
<p>Returns a sorted list with op types and its change after the optimization.</p>
`,returnType:`
<p>sorted_nodes_change (<code>List[Tuple[str, int]]</code>)</p>
`}}),{c(){d=n("meta"),G=s(),u=n("h1"),g=n("a"),W=n("span"),T(b.$$.fragment),Z=s(),I=n("span"),ee=$("Optimization"),q=s(),c=n("h2"),f=n("a"),D=n("span"),T(v.$$.fragment),te=s(),X=n("span"),oe=$("ORTOptimizer"),B=s(),r=n("div"),T(z.$$.fragment),ne=s(),S=n("p"),ie=$("Handles the ONNX Runtime optimization process for models shared on huggingface.co/models."),ae=s(),_=n("div"),T(y.$$.fragment),re=s(),C=n("p"),me=$("Loads and exports a model to an ONNX Intermediate Representation (IR)."),se=s(),x=n("div"),T(w.$$.fragment),le=s(),H=n("p"),pe=$("Applies the ONNX Runtime graph-level optimization on a given model and saves the resulting model."),de=s(),O=n("div"),T(R.$$.fragment),ue=s(),U=n("p"),ce=$("Returns a dictionary reporting the optimization."),this.h()},l(e){const h=Ne('[data-svelte="svelte-1phssyn"]',document.head);d=i(h,"META",{name:!0,content:!0}),h.forEach(o),G=l(e),u=i(e,"H1",{class:!0});var M=a(u);g=i(M,"A",{id:!0,class:!0,href:!0});var ge=a(g);W=i(ge,"SPAN",{});var fe=a(W);k(b.$$.fragment,fe),fe.forEach(o),ge.forEach(o),Z=l(M),I=i(M,"SPAN",{});var _e=a(I);ee=N(_e,"Optimization"),_e.forEach(o),M.forEach(o),q=l(e),c=i(e,"H2",{class:!0});var J=a(c);f=i(J,"A",{id:!0,class:!0,href:!0});var xe=a(f);D=i(xe,"SPAN",{});var Oe=a(D);k(v.$$.fragment,Oe),Oe.forEach(o),xe.forEach(o),te=l(J),X=i(J,"SPAN",{});var be=a(X);oe=N(be,"ORTOptimizer"),be.forEach(o),J.forEach(o),B=l(e),r=i(e,"DIV",{class:!0});var p=a(r);k(z.$$.fragment,p),ne=l(p),S=i(p,"P",{});var ve=a(S);ie=N(ve,"Handles the ONNX Runtime optimization process for models shared on huggingface.co/models."),ve.forEach(o),ae=l(p),_=i(p,"DIV",{class:!0});var j=a(_);k(y.$$.fragment,j),re=l(j),C=i(j,"P",{});var ze=a(C);me=N(ze,"Loads and exports a model to an ONNX Intermediate Representation (IR)."),ze.forEach(o),j.forEach(o),se=l(p),x=i(p,"DIV",{class:!0});var K=a(x);k(w.$$.fragment,K),le=l(K),H=i(K,"P",{});var ye=a(H);pe=N(ye,"Applies the ONNX Runtime graph-level optimization on a given model and saves the resulting model."),ye.forEach(o),K.forEach(o),de=l(p),O=i(p,"DIV",{class:!0});var Q=a(O);k(R.$$.fragment,Q),ue=l(Q),U=i(Q,"P",{});var we=a(U);ce=N(we,"Returns a dictionary reporting the optimization."),we.forEach(o),Q.forEach(o),p.forEach(o),this.h()},h(){m(d,"name","hf:doc:metadata"),m(d,"content",JSON.stringify(Ee)),m(g,"id","optimization"),m(g,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(g,"href","#optimization"),m(u,"class","relative group"),m(f,"id","optimum.onnxruntime.ORTOptimizer"),m(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(f,"href","#optimum.onnxruntime.ORTOptimizer"),m(c,"class","relative group"),m(_,"class","docstring"),m(x,"class","docstring"),m(O,"class","docstring"),m(r,"class","docstring")},m(e,h){t(document.head,d),P(e,G,h),P(e,u,h),t(u,g),t(g,W),L(b,W,null),t(u,Z),t(u,I),t(I,ee),P(e,q,h),P(e,c,h),t(c,f),t(f,D),L(v,D,null),t(c,te),t(c,X),t(X,oe),P(e,B,h),P(e,r,h),L(z,r,null),t(r,ne),t(r,S),t(S,ie),t(r,ae),t(r,_),L(y,_,null),t(_,re),t(_,C),t(C,me),t(r,se),t(r,x),L(w,x,null),t(x,le),t(x,H),t(H,pe),t(r,de),t(r,O),L(R,O,null),t(O,ue),t(O,U),t(U,ce),V=!0},p:Pe,i(e){V||(F(b.$$.fragment,e),F(v.$$.fragment,e),F(z.$$.fragment,e),F(y.$$.fragment,e),F(w.$$.fragment,e),F(R.$$.fragment,e),V=!0)},o(e){E(b.$$.fragment,e),E(v.$$.fragment,e),E(z.$$.fragment,e),E(y.$$.fragment,e),E(w.$$.fragment,e),E(R.$$.fragment,e),V=!1},d(e){o(d),e&&o(G),e&&o(u),A(b),e&&o(q),e&&o(c),A(v),e&&o(B),e&&o(r),A(z),A(y),A(w),A(R)}}}const Ee={local:"optimization",sections:[{local:"optimum.onnxruntime.ORTOptimizer",title:"ORTOptimizer"}],title:"Optimization"};function Ae(he){return Le(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Xe extends Te{constructor(d){super();$e(this,d,Ae,Fe,ke,{})}}export{Xe as default,Ee as metadata};
