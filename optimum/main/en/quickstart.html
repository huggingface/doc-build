<meta charset="utf-8" /><meta http-equiv="content-security-policy" content=""><meta name="hf:doc:metadata" content="{&quot;local&quot;:&quot;quickstart&quot;,&quot;title&quot;:&quot;Quickstart&quot;}" data-svelte="svelte-1phssyn">
	<link rel="stylesheet" href="/docs/optimum/main/en/_app/assets/pages/__layout.svelte-0adcc46b.css">
	<link rel="modulepreload" href="/docs/optimum/main/en/_app/start-3090ee43.js">
	<link rel="modulepreload" href="/docs/optimum/main/en/_app/chunks/vendor-19e06bd2.js">
	<link rel="modulepreload" href="/docs/optimum/main/en/_app/chunks/paths-4b3c6e7e.js">
	<link rel="modulepreload" href="/docs/optimum/main/en/_app/pages/__layout.svelte-00a862c5.js">
	<link rel="modulepreload" href="/docs/optimum/main/en/_app/pages/quickstart.mdx-a2cb417a.js">
	<link rel="modulepreload" href="/docs/optimum/main/en/_app/chunks/IconCopyLink-3c713d38.js">
	<link rel="modulepreload" href="/docs/optimum/main/en/_app/chunks/CodeBlock-9dd1fdfb.js"> 






<h1 class="relative group"><a id="quickstart" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#quickstart"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Quickstart
	</span></h1>

<p>At its core, ðŸ¤— Optimum uses <em>configuration objects</em> to define parameters for optimization on different accelerators. These objects are then used to instantiate dedicated <em>optimizers</em>, <em>quantizers</em>, and <em>pruners</em>. For example, hereâ€™s how you can apply dynamic quantization with ONNX Runtime:</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START --><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> optimum.onnxruntime <span class="hljs-keyword">import</span> ORTConfig, ORTQuantizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># The model we wish to quantize</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model_ckpt = <span class="hljs-string">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># The type of quantization to apply</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>ort_config = ORTConfig(quantization_approach=<span class="hljs-string">&quot;dynamic&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>quantizer = ORTQuantizer(ort_config)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Quantize the model!</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>quantizer.fit(model_ckpt, output_dir=<span class="hljs-string">&quot;.&quot;</span>, feature=<span class="hljs-string">&quot;sequence-classification&quot;</span>)<!-- HTML_TAG_END --></pre></div>
<p>In this example, weâ€™ve quantized a model from the Hugging Face Hub, but it could also be a path to a local model directory. The <code>feature</code> argument in the <code>fit()</code> method corresponds to the type of task that we wish to quantize the model for. The result from applying the <code>fit()</code> method is a <code>model-quantized.onnx</code> file that can be used to run inference. Hereâ€™s an example of how to load an ONNX Runtime model and generate predictions with it:</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START --><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> optimum.onnxruntime <span class="hljs-keyword">import</span> ORTModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load quantized model</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>ort_model = ORTModel(<span class="hljs-string">&quot;model-quantized.onnx&quot;</span>, quantizer.onnx_config)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Create a dataset or load one from the Hub</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = Dataset.from_dict({<span class="hljs-string">&quot;sentence&quot;</span>: [<span class="hljs-string">&quot;I love burritos!&quot;</span>]})
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Tokenize the inputs &amp; convert to PyTorch tensors</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_ckpt)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_fn</span>(<span class="hljs-params">ex</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> tokenizer(ex[<span class="hljs-string">&quot;sentence&quot;</span>])

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_ds = ds.<span class="hljs-built_in">map</span>(preprocess_fn, remove_columns=ds.column_names)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_ds.set_format(<span class="hljs-string">&quot;torch&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Create dataloader and run evaluation</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>dataloader = DataLoader(tokenized_ds)
<span class="hljs-meta">&gt;&gt;&gt; </span>ort_outputs = ort_model.evaluation_loop(dataloader)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Extract logits!</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>ort_outputs.predictions<!-- HTML_TAG_END --></pre></div>
<p>Similarly, you can apply static quantization by simply changing the <code>quantization_approach</code> in the <code>ORTConfig</code> object:</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START --><span class="hljs-meta">&gt;&gt;&gt; </span>ort_config = ORTConfig(quantization_approach=<span class="hljs-string">&quot;static&quot;</span>)<!-- HTML_TAG_END --></pre></div>
<p>Static quantization relies on feeding batches of data through the model to observe the activation patterns ahead of inference time. The ideal quantization scheme is then calculated and saved. To support this, ðŸ¤— Optimum allows you to provide a <em>calibration dataset</em>. The calibration dataset can be a simple <code>Dataset</code> object from the ðŸ¤— Datasets library, or any dataset thatâ€™s hosted on the Hugging Face Hub. For this example, weâ€™ll pick the <a href="https://huggingface.co/datasets/glue/viewer/sst2/test" rel="nofollow"><code>sst2</code></a> dataset that the model was originally trained on:</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START --><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorWithPadding

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># We use a data collator to pad the examples in a batch</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DataCollatorWithPadding(tokenizer)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># For calibration we define the dataset and preprocessing function</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>quantizer = ORTQuantizer(
<span class="hljs-meta">... </span>    ort_config,
<span class="hljs-meta">... </span>    dataset_name=<span class="hljs-string">&quot;glue&quot;</span>,
<span class="hljs-meta">... </span>    dataset_config_name=<span class="hljs-string">&quot;sst2&quot;</span>,
<span class="hljs-meta">... </span>    preprocess_function=preprocess_fn,
<span class="hljs-meta">... </span>    data_collator=data_collator,
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Quantize the same way we did for dynamic quantization!</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>quantizer.fit(model_ckpt, output_dir=<span class="hljs-string">&quot;.&quot;</span>, feature=<span class="hljs-string">&quot;sequence-classification&quot;</span>)<!-- HTML_TAG_END --></pre></div>
<p>As a final example, letâ€™s take a look at applying <em>graph optimizations</em> techniques such as operator fusion and constant folding. As before, we load a configuration object, but this time by setting the optimization level instead of the quantization approach:</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START --><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># opt_level=99 enables all graph optimisations</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>ort_config = ORTConfig(opt_level=<span class="hljs-number">99</span>)<!-- HTML_TAG_END --></pre></div>
<p>Next, we load an <em>optimizer</em> to apply these optimisations to our model:</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START --><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> optimum.onnxruntime <span class="hljs-keyword">import</span> ORTOptimizer

<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer = ORTOptimizer(ort_config)
<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer.fit(model_ckpt, output_dir=<span class="hljs-string">&quot;.&quot;</span>, feature=<span class="hljs-string">&quot;sequence-classification&quot;</span>)<!-- HTML_TAG_END --></pre></div>
<p>And thatâ€™s it - the model is now optimized and ready for inference! As you can see, the process is similar in each case:</p>
<ol><li>Define the optimization / quantization strategies via an <code>ORTConfig</code> object</li>
<li>Instantiate a <code>ORTQuantizer</code> or <code>ORTOptimizer</code> class</li>
<li>Apply the <code>fit()</code> method</li>
<li>Run inference</li></ol>
<p>Check out the <a href="https://github.com/huggingface/optimum/tree/main/examples" rel="nofollow"><code>examples</code></a> directory for more sophisticated usage.</p>
<p>Happy optimising ðŸ¤—!</p>


		<script type="module" data-hydrate="11wnsax">
		import { start } from "/docs/optimum/main/en/_app/start-3090ee43.js";
		start({
			target: document.querySelector('[data-hydrate="11wnsax"]').parentNode,
			paths: {"base":"/docs/optimum/main/en","assets":"/docs/optimum/main/en"},
			session: {},
			route: false,
			spa: false,
			trailing_slash: "never",
			hydrate: {
				status: 200,
				error: null,
				nodes: [
					import("/docs/optimum/main/en/_app/pages/__layout.svelte-00a862c5.js"),
						import("/docs/optimum/main/en/_app/pages/quickstart.mdx-a2cb417a.js")
				],
				params: {}
			}
		});
	</script>
