import{S as Ds,i as xs,s as Ss,e as o,k as n,w as no,t as h,M as As,c as r,d as e,m as i,a as l,x as io,h as c,b as a,$ as y,G as t,g,y as so,L as Hs,q as ho,o as co,B as fo,v as Ns}from"../chunks/vendor-hf-doc-builder.js";import{I as uo}from"../chunks/IconCopyLink-hf-doc-builder.js";function Os(dn){let k,go,D,W,ka,dt,Uo,Da,zo,mo,Qt,qo,po,x,Y,xa,ut,Mo,Sa,Bo,bo,j,Aa,S,Jt,Lo,Fo,Vt,Xo,Co,Ha,Wo,f,A,Zt,gt,Yo,jo,te,Ko,Qo,ee,mt,ae,un,Jo,H,oe,pt,Vo,Zo,re,tr,er,Na,ar,N,le,bt,or,rr,ne,lr,nr,Oa,ir,O,ie,vt,sr,hr,se,cr,fr,he,_t,ce,gn,dr,G,fe,wt,ur,gr,de,mr,pr,Ga,br,R,ue,Et,vr,_r,ge,wr,Er,Ra,Tr,$,me,Tt,yr,kr,pe,Dr,xr,$a,Sr,I,be,yt,Ar,Hr,ve,Nr,Or,Ia,Gr,P,_e,kt,Rr,$r,we,Ir,Pr,Pa,Ur,U,Ee,Dt,zr,qr,Te,Mr,Br,Ua,Lr,z,ye,xt,Fr,Xr,ke,Cr,Wr,za,Yr,q,De,St,jr,Kr,xe,Qr,Jr,Se,At,Ae,mn,Vr,M,He,Ht,Zr,tl,Ne,el,al,qa,ol,B,Oe,Nt,rl,ll,Ge,nl,il,Ma,vo,L,K,Ba,Ot,sl,La,hl,_o,Q,Fa,m,Re,cl,fl,$e,dl,ul,Xa,gl,Ca,ml,Wa,p,Ie,Gt,pl,bl,Pe,vl,_l,Ya,wl,ja,wo,F,J,Ka,Rt,El,Qa,Tl,Eo,V,Ja,b,Ue,yl,kl,ze,Dl,xl,Va,Sl,Za,Al,to,v,qe,$t,Hl,Nl,Z,Ol,It,Gl,Rl,$l,Me,Pt,Be,pn,Il,Le,Ut,Fe,bn,To,X,tt,eo,zt,Pl,ao,Ul,yo,et,oo,_,Xe,zl,ql,Ce,Ml,Bl,ro,Ll,lo,Fl,C,w,We,qt,Xl,Cl,at,Wl,Mt,Yl,jl,Kl,Ye,Bt,je,vn,Ql,Ke,Lt,Qe,_n,Jl,E,Je,Ft,Vl,Zl,ot,tn,Xt,en,an,on,Ve,Ct,Ze,wn,rn,ta,Wt,ea,En,ln,T,aa,Yt,nn,sn,oa,hn,cn,ra,jt,la,Tn,fn,na,Kt,ia,yn,ko;return dt=new uo({}),ut=new uo({}),Ot=new uo({}),Rt=new uo({}),zt=new uo({}),{c(){k=o("meta"),go=n(),D=o("h1"),W=o("a"),ka=o("span"),no(dt.$$.fragment),Uo=n(),Da=o("span"),zo=h("\u{1F917} Optimum notebooks"),mo=n(),Qt=o("p"),qo=h("You can find here a list of the notebooks associated with each accelerator in \u{1F917} Optimum."),po=n(),x=o("h2"),Y=o("a"),xa=o("span"),no(ut.$$.fragment),Mo=n(),Sa=o("span"),Bo=h("Optimum Graphcore examples"),bo=n(),j=o("table"),Aa=o("thead"),S=o("tr"),Jt=o("th"),Lo=h("Notebook"),Fo=n(),Vt=o("th"),Xo=h("Description"),Co=n(),Ha=o("th"),Wo=n(),f=o("tbody"),A=o("tr"),Zt=o("td"),gt=o("a"),Yo=h("Introduction to Optimum Graphcore"),jo=n(),te=o("td"),Ko=h("Introduce Optimum-Graphcore with a BERT fine-tuning example."),Qo=n(),ee=o("td"),mt=o("a"),ae=o("img"),Jo=n(),H=o("tr"),oe=o("td"),pt=o("a"),Vo=h("Train an external model"),Zo=n(),re=o("td"),tr=h("Show how to train an external model that is not supported by Optimum or Transformers."),er=n(),Na=o("td"),ar=n(),N=o("tr"),le=o("td"),bt=o("a"),or=h("Train your language model"),rr=n(),ne=o("td"),lr=h("Show how to train a model for causal or masked language modelling from scratch."),nr=n(),Oa=o("td"),ir=n(),O=o("tr"),ie=o("td"),vt=o("a"),sr=h("How to fine-tune a model on text classification"),hr=n(),se=o("td"),cr=h("Show how to preprocess the data and fine-tune a pretrained model on any GLUE task."),fr=n(),he=o("td"),_t=o("a"),ce=o("img"),dr=n(),G=o("tr"),fe=o("td"),wt=o("a"),ur=h("How to fine-tune a model on language modeling"),gr=n(),de=o("td"),mr=h("Show how to preprocess the data and fine-tune a pretrained model on a causal or masked LM task."),pr=n(),Ga=o("td"),br=n(),R=o("tr"),ue=o("td"),Et=o("a"),vr=h("How to fine-tune a model on token classification"),_r=n(),ge=o("td"),wr=h("Show how to preprocess the data and fine-tune a pretrained model on a token classification task (NER, PoS)."),Er=n(),Ra=o("td"),Tr=n(),$=o("tr"),me=o("td"),Tt=o("a"),yr=h("How to fine-tune a model on question answering"),kr=n(),pe=o("td"),Dr=h("Show how to preprocess the data and fine-tune a pretrained model on SQUAD."),xr=n(),$a=o("td"),Sr=n(),I=o("tr"),be=o("td"),yt=o("a"),Ar=h("How to fine-tune a model on multiple choice"),Hr=n(),ve=o("td"),Nr=h("Show how to preprocess the data and fine-tune a pretrained model on SWAG."),Or=n(),Ia=o("td"),Gr=n(),P=o("tr"),_e=o("td"),kt=o("a"),Rr=h("How to fine-tune a model on translation"),$r=n(),we=o("td"),Ir=h("Show how to preprocess the data and fine-tune a pretrained model on WMT."),Pr=n(),Pa=o("td"),Ur=n(),U=o("tr"),Ee=o("td"),Dt=o("a"),zr=h("How to fine-tune a model on summarization"),qr=n(),Te=o("td"),Mr=h("Show how to preprocess the data and fine-tune a pretrained model on XSUM."),Br=n(),Ua=o("td"),Lr=n(),z=o("tr"),ye=o("td"),xt=o("a"),Fr=h("How to fine-tune a model on audio classification"),Xr=n(),ke=o("td"),Cr=h("Show how to preprocess the data and fine-tune a pretrained Speech model on Keyword Spotting"),Wr=n(),za=o("td"),Yr=n(),q=o("tr"),De=o("td"),St=o("a"),jr=h("How to fine-tune a model on image classfication"),Kr=n(),xe=o("td"),Qr=h("Show how to preprocess the data and fine-tune a pretrained model on image classification."),Jr=n(),Se=o("td"),At=o("a"),Ae=o("img"),Vr=n(),M=o("tr"),He=o("td"),Ht=o("a"),Zr=h("wav2vec 2.0 Fine-Tuning on IPU"),tl=n(),Ne=o("td"),el=h("How to fine-tune a pre-trained wav2vec 2.0 model with PyTorch on the Graphcore IPU-POD16 system."),al=n(),qa=o("td"),ol=n(),B=o("tr"),Oe=o("td"),Nt=o("a"),rl=h("wav2vec 2.0 Inference on IPU"),ll=n(),Ge=o("td"),nl=h("How to run inference on the wav2vec 2.0 model with PyTorch on the Graphcore IPU-POD16 system."),il=n(),Ma=o("td"),vo=n(),L=o("h2"),K=o("a"),Ba=o("span"),no(Ot.$$.fragment),sl=n(),La=o("span"),hl=h("Optimum Habana examples"),_o=n(),Q=o("table"),Fa=o("thead"),m=o("tr"),Re=o("th"),cl=h("Notebook"),fl=n(),$e=o("th"),dl=h("Description"),ul=n(),Xa=o("th"),gl=n(),Ca=o("th"),ml=n(),Wa=o("tbody"),p=o("tr"),Ie=o("td"),Gt=o("a"),pl=h("How to use DeepSpeed to train models with billions of parameters on Habana Gaudi"),bl=n(),Pe=o("td"),vl=h("Show how to use DeepSpeed to pre-train/fine-tune the 1.6B-parameter GPT2-XL for causal language modeling on Habana Gaudi."),_l=n(),Ya=o("td"),wl=n(),ja=o("td"),wo=n(),F=o("h2"),J=o("a"),Ka=o("span"),no(Rt.$$.fragment),El=n(),Qa=o("span"),Tl=h("Optimum Intel examples"),Eo=n(),V=o("table"),Ja=o("thead"),b=o("tr"),Ue=o("th"),yl=h("Notebook"),kl=n(),ze=o("th"),Dl=h("Description"),xl=n(),Va=o("th"),Sl=n(),Za=o("th"),Al=n(),to=o("tbody"),v=o("tr"),qe=o("td"),$t=o("a"),Hl=h("How to quantize a model with Intel Neural Compressor for text classification"),Nl=n(),Z=o("td"),Ol=h("Show how to apply static, dynamic and aware training quantization on a model using "),It=o("a"),Gl=h("Intel Neural Compressor (INC)"),Rl=h(" for any GLUE task."),$l=n(),Me=o("td"),Pt=o("a"),Be=o("img"),Il=n(),Le=o("td"),Ut=o("a"),Fe=o("img"),To=n(),X=o("h2"),tt=o("a"),eo=o("span"),no(zt.$$.fragment),Pl=n(),ao=o("span"),Ul=h("ONNX Runtime examples"),yo=n(),et=o("table"),oo=o("thead"),_=o("tr"),Xe=o("th"),zl=h("Notebook"),ql=n(),Ce=o("th"),Ml=h("Description"),Bl=n(),ro=o("th"),Ll=n(),lo=o("th"),Fl=n(),C=o("tbody"),w=o("tr"),We=o("td"),qt=o("a"),Xl=h("How to quantize a model with ONNX Runtime for text classification"),Cl=n(),at=o("td"),Wl=h("Show how to apply static and dynamic quantization on a model using "),Mt=o("a"),Yl=h("ONNX Runtime"),jl=h(" for any GLUE task."),Kl=n(),Ye=o("td"),Bt=o("a"),je=o("img"),Ql=n(),Ke=o("td"),Lt=o("a"),Qe=o("img"),Jl=n(),E=o("tr"),Je=o("td"),Ft=o("a"),Vl=h("How to fine-tune a model for text classification with ONNX Runtime"),Zl=n(),ot=o("td"),tn=h("Show how to DistilBERT model on GLUE tasks using "),Xt=o("a"),en=h("ONNX Runtime"),an=h("."),on=n(),Ve=o("td"),Ct=o("a"),Ze=o("img"),rn=n(),ta=o("td"),Wt=o("a"),ea=o("img"),ln=n(),T=o("tr"),aa=o("td"),Yt=o("a"),nn=h("How to fine-tune a model for summarization with ONNX Runtime"),sn=n(),oa=o("td"),hn=h("Show how to fine-tune a T5 model on the BBC news corpus."),cn=n(),ra=o("td"),jt=o("a"),la=o("img"),fn=n(),na=o("td"),Kt=o("a"),ia=o("img"),this.h()},l(s){const u=As('[data-svelte="svelte-1phssyn"]',document.head);k=r(u,"META",{name:!0,content:!0}),u.forEach(e),go=i(s),D=r(s,"H1",{class:!0});var Do=l(D);W=r(Do,"A",{id:!0,class:!0,href:!0});var kn=l(W);ka=r(kn,"SPAN",{});var Dn=l(ka);io(dt.$$.fragment,Dn),Dn.forEach(e),kn.forEach(e),Uo=i(Do),Da=r(Do,"SPAN",{});var xn=l(Da);zo=c(xn,"\u{1F917} Optimum notebooks"),xn.forEach(e),Do.forEach(e),mo=i(s),Qt=r(s,"P",{});var Sn=l(Qt);qo=c(Sn,"You can find here a list of the notebooks associated with each accelerator in \u{1F917} Optimum."),Sn.forEach(e),po=i(s),x=r(s,"H2",{class:!0});var xo=l(x);Y=r(xo,"A",{id:!0,class:!0,href:!0});var An=l(Y);xa=r(An,"SPAN",{});var Hn=l(xa);io(ut.$$.fragment,Hn),Hn.forEach(e),An.forEach(e),Mo=i(xo),Sa=r(xo,"SPAN",{});var Nn=l(Sa);Bo=c(Nn,"Optimum Graphcore examples"),Nn.forEach(e),xo.forEach(e),bo=i(s),j=r(s,"TABLE",{});var So=l(j);Aa=r(So,"THEAD",{});var On=l(Aa);S=r(On,"TR",{});var sa=l(S);Jt=r(sa,"TH",{align:!0});var Gn=l(Jt);Lo=c(Gn,"Notebook"),Gn.forEach(e),Fo=i(sa),Vt=r(sa,"TH",{align:!0});var Rn=l(Vt);Xo=c(Rn,"Description"),Rn.forEach(e),Co=i(sa),Ha=r(sa,"TH",{align:!0}),l(Ha).forEach(e),sa.forEach(e),On.forEach(e),Wo=i(So),f=r(So,"TBODY",{});var d=l(f);A=r(d,"TR",{});var ha=l(A);Zt=r(ha,"TD",{align:!0});var $n=l(Zt);gt=r($n,"A",{href:!0,rel:!0});var In=l(gt);Yo=c(In,"Introduction to Optimum Graphcore"),In.forEach(e),$n.forEach(e),jo=i(ha),te=r(ha,"TD",{align:!0});var Pn=l(te);Ko=c(Pn,"Introduce Optimum-Graphcore with a BERT fine-tuning example."),Pn.forEach(e),Qo=i(ha),ee=r(ha,"TD",{align:!0});var Un=l(ee);mt=r(Un,"A",{href:!0,rel:!0});var zn=l(mt);ae=r(zn,"IMG",{src:!0,alt:!0}),zn.forEach(e),Un.forEach(e),ha.forEach(e),Jo=i(d),H=r(d,"TR",{});var ca=l(H);oe=r(ca,"TD",{align:!0});var qn=l(oe);pt=r(qn,"A",{href:!0,rel:!0});var Mn=l(pt);Vo=c(Mn,"Train an external model"),Mn.forEach(e),qn.forEach(e),Zo=i(ca),re=r(ca,"TD",{align:!0});var Bn=l(re);tr=c(Bn,"Show how to train an external model that is not supported by Optimum or Transformers."),Bn.forEach(e),er=i(ca),Na=r(ca,"TD",{align:!0}),l(Na).forEach(e),ca.forEach(e),ar=i(d),N=r(d,"TR",{});var fa=l(N);le=r(fa,"TD",{align:!0});var Ln=l(le);bt=r(Ln,"A",{href:!0,rel:!0});var Fn=l(bt);or=c(Fn,"Train your language model"),Fn.forEach(e),Ln.forEach(e),rr=i(fa),ne=r(fa,"TD",{align:!0});var Xn=l(ne);lr=c(Xn,"Show how to train a model for causal or masked language modelling from scratch."),Xn.forEach(e),nr=i(fa),Oa=r(fa,"TD",{align:!0}),l(Oa).forEach(e),fa.forEach(e),ir=i(d),O=r(d,"TR",{});var da=l(O);ie=r(da,"TD",{align:!0});var Cn=l(ie);vt=r(Cn,"A",{href:!0,rel:!0});var Wn=l(vt);sr=c(Wn,"How to fine-tune a model on text classification"),Wn.forEach(e),Cn.forEach(e),hr=i(da),se=r(da,"TD",{align:!0});var Yn=l(se);cr=c(Yn,"Show how to preprocess the data and fine-tune a pretrained model on any GLUE task."),Yn.forEach(e),fr=i(da),he=r(da,"TD",{align:!0});var jn=l(he);_t=r(jn,"A",{href:!0,rel:!0});var Kn=l(_t);ce=r(Kn,"IMG",{src:!0,alt:!0}),Kn.forEach(e),jn.forEach(e),da.forEach(e),dr=i(d),G=r(d,"TR",{});var ua=l(G);fe=r(ua,"TD",{align:!0});var Qn=l(fe);wt=r(Qn,"A",{href:!0,rel:!0});var Jn=l(wt);ur=c(Jn,"How to fine-tune a model on language modeling"),Jn.forEach(e),Qn.forEach(e),gr=i(ua),de=r(ua,"TD",{align:!0});var Vn=l(de);mr=c(Vn,"Show how to preprocess the data and fine-tune a pretrained model on a causal or masked LM task."),Vn.forEach(e),pr=i(ua),Ga=r(ua,"TD",{align:!0}),l(Ga).forEach(e),ua.forEach(e),br=i(d),R=r(d,"TR",{});var ga=l(R);ue=r(ga,"TD",{align:!0});var Zn=l(ue);Et=r(Zn,"A",{href:!0,rel:!0});var ti=l(Et);vr=c(ti,"How to fine-tune a model on token classification"),ti.forEach(e),Zn.forEach(e),_r=i(ga),ge=r(ga,"TD",{align:!0});var ei=l(ge);wr=c(ei,"Show how to preprocess the data and fine-tune a pretrained model on a token classification task (NER, PoS)."),ei.forEach(e),Er=i(ga),Ra=r(ga,"TD",{align:!0}),l(Ra).forEach(e),ga.forEach(e),Tr=i(d),$=r(d,"TR",{});var ma=l($);me=r(ma,"TD",{align:!0});var ai=l(me);Tt=r(ai,"A",{href:!0,rel:!0});var oi=l(Tt);yr=c(oi,"How to fine-tune a model on question answering"),oi.forEach(e),ai.forEach(e),kr=i(ma),pe=r(ma,"TD",{align:!0});var ri=l(pe);Dr=c(ri,"Show how to preprocess the data and fine-tune a pretrained model on SQUAD."),ri.forEach(e),xr=i(ma),$a=r(ma,"TD",{align:!0}),l($a).forEach(e),ma.forEach(e),Sr=i(d),I=r(d,"TR",{});var pa=l(I);be=r(pa,"TD",{align:!0});var li=l(be);yt=r(li,"A",{href:!0,rel:!0});var ni=l(yt);Ar=c(ni,"How to fine-tune a model on multiple choice"),ni.forEach(e),li.forEach(e),Hr=i(pa),ve=r(pa,"TD",{align:!0});var ii=l(ve);Nr=c(ii,"Show how to preprocess the data and fine-tune a pretrained model on SWAG."),ii.forEach(e),Or=i(pa),Ia=r(pa,"TD",{align:!0}),l(Ia).forEach(e),pa.forEach(e),Gr=i(d),P=r(d,"TR",{});var ba=l(P);_e=r(ba,"TD",{align:!0});var si=l(_e);kt=r(si,"A",{href:!0,rel:!0});var hi=l(kt);Rr=c(hi,"How to fine-tune a model on translation"),hi.forEach(e),si.forEach(e),$r=i(ba),we=r(ba,"TD",{align:!0});var ci=l(we);Ir=c(ci,"Show how to preprocess the data and fine-tune a pretrained model on WMT."),ci.forEach(e),Pr=i(ba),Pa=r(ba,"TD",{align:!0}),l(Pa).forEach(e),ba.forEach(e),Ur=i(d),U=r(d,"TR",{});var va=l(U);Ee=r(va,"TD",{align:!0});var fi=l(Ee);Dt=r(fi,"A",{href:!0,rel:!0});var di=l(Dt);zr=c(di,"How to fine-tune a model on summarization"),di.forEach(e),fi.forEach(e),qr=i(va),Te=r(va,"TD",{align:!0});var ui=l(Te);Mr=c(ui,"Show how to preprocess the data and fine-tune a pretrained model on XSUM."),ui.forEach(e),Br=i(va),Ua=r(va,"TD",{align:!0}),l(Ua).forEach(e),va.forEach(e),Lr=i(d),z=r(d,"TR",{});var _a=l(z);ye=r(_a,"TD",{align:!0});var gi=l(ye);xt=r(gi,"A",{href:!0,rel:!0});var mi=l(xt);Fr=c(mi,"How to fine-tune a model on audio classification"),mi.forEach(e),gi.forEach(e),Xr=i(_a),ke=r(_a,"TD",{align:!0});var pi=l(ke);Cr=c(pi,"Show how to preprocess the data and fine-tune a pretrained Speech model on Keyword Spotting"),pi.forEach(e),Wr=i(_a),za=r(_a,"TD",{align:!0}),l(za).forEach(e),_a.forEach(e),Yr=i(d),q=r(d,"TR",{});var wa=l(q);De=r(wa,"TD",{align:!0});var bi=l(De);St=r(bi,"A",{href:!0,rel:!0});var vi=l(St);jr=c(vi,"How to fine-tune a model on image classfication"),vi.forEach(e),bi.forEach(e),Kr=i(wa),xe=r(wa,"TD",{align:!0});var _i=l(xe);Qr=c(_i,"Show how to preprocess the data and fine-tune a pretrained model on image classification."),_i.forEach(e),Jr=i(wa),Se=r(wa,"TD",{align:!0});var wi=l(Se);At=r(wi,"A",{href:!0,rel:!0});var Ei=l(At);Ae=r(Ei,"IMG",{src:!0,alt:!0}),Ei.forEach(e),wi.forEach(e),wa.forEach(e),Vr=i(d),M=r(d,"TR",{});var Ea=l(M);He=r(Ea,"TD",{align:!0});var Ti=l(He);Ht=r(Ti,"A",{href:!0,rel:!0});var yi=l(Ht);Zr=c(yi,"wav2vec 2.0 Fine-Tuning on IPU"),yi.forEach(e),Ti.forEach(e),tl=i(Ea),Ne=r(Ea,"TD",{align:!0});var ki=l(Ne);el=c(ki,"How to fine-tune a pre-trained wav2vec 2.0 model with PyTorch on the Graphcore IPU-POD16 system."),ki.forEach(e),al=i(Ea),qa=r(Ea,"TD",{align:!0}),l(qa).forEach(e),Ea.forEach(e),ol=i(d),B=r(d,"TR",{});var Ta=l(B);Oe=r(Ta,"TD",{align:!0});var Di=l(Oe);Nt=r(Di,"A",{href:!0,rel:!0});var xi=l(Nt);rl=c(xi,"wav2vec 2.0 Inference on IPU"),xi.forEach(e),Di.forEach(e),ll=i(Ta),Ge=r(Ta,"TD",{align:!0});var Si=l(Ge);nl=c(Si,"How to run inference on the wav2vec 2.0 model with PyTorch on the Graphcore IPU-POD16 system."),Si.forEach(e),il=i(Ta),Ma=r(Ta,"TD",{align:!0}),l(Ma).forEach(e),Ta.forEach(e),d.forEach(e),So.forEach(e),vo=i(s),L=r(s,"H2",{class:!0});var Ao=l(L);K=r(Ao,"A",{id:!0,class:!0,href:!0});var Ai=l(K);Ba=r(Ai,"SPAN",{});var Hi=l(Ba);io(Ot.$$.fragment,Hi),Hi.forEach(e),Ai.forEach(e),sl=i(Ao),La=r(Ao,"SPAN",{});var Ni=l(La);hl=c(Ni,"Optimum Habana examples"),Ni.forEach(e),Ao.forEach(e),_o=i(s),Q=r(s,"TABLE",{});var Ho=l(Q);Fa=r(Ho,"THEAD",{});var Oi=l(Fa);m=r(Oi,"TR",{});var rt=l(m);Re=r(rt,"TH",{align:!0});var Gi=l(Re);cl=c(Gi,"Notebook"),Gi.forEach(e),fl=i(rt),$e=r(rt,"TH",{align:!0});var Ri=l($e);dl=c(Ri,"Description"),Ri.forEach(e),ul=i(rt),Xa=r(rt,"TH",{align:!0}),l(Xa).forEach(e),gl=i(rt),Ca=r(rt,"TH",{align:!0}),l(Ca).forEach(e),rt.forEach(e),Oi.forEach(e),ml=i(Ho),Wa=r(Ho,"TBODY",{});var $i=l(Wa);p=r($i,"TR",{});var lt=l(p);Ie=r(lt,"TD",{align:!0});var Ii=l(Ie);Gt=r(Ii,"A",{href:!0,rel:!0});var Pi=l(Gt);pl=c(Pi,"How to use DeepSpeed to train models with billions of parameters on Habana Gaudi"),Pi.forEach(e),Ii.forEach(e),bl=i(lt),Pe=r(lt,"TD",{align:!0});var Ui=l(Pe);vl=c(Ui,"Show how to use DeepSpeed to pre-train/fine-tune the 1.6B-parameter GPT2-XL for causal language modeling on Habana Gaudi."),Ui.forEach(e),_l=i(lt),Ya=r(lt,"TD",{align:!0}),l(Ya).forEach(e),wl=i(lt),ja=r(lt,"TD",{align:!0}),l(ja).forEach(e),lt.forEach(e),$i.forEach(e),Ho.forEach(e),wo=i(s),F=r(s,"H2",{class:!0});var No=l(F);J=r(No,"A",{id:!0,class:!0,href:!0});var zi=l(J);Ka=r(zi,"SPAN",{});var qi=l(Ka);io(Rt.$$.fragment,qi),qi.forEach(e),zi.forEach(e),El=i(No),Qa=r(No,"SPAN",{});var Mi=l(Qa);Tl=c(Mi,"Optimum Intel examples"),Mi.forEach(e),No.forEach(e),Eo=i(s),V=r(s,"TABLE",{});var Oo=l(V);Ja=r(Oo,"THEAD",{});var Bi=l(Ja);b=r(Bi,"TR",{});var nt=l(b);Ue=r(nt,"TH",{align:!0});var Li=l(Ue);yl=c(Li,"Notebook"),Li.forEach(e),kl=i(nt),ze=r(nt,"TH",{align:!0});var Fi=l(ze);Dl=c(Fi,"Description"),Fi.forEach(e),xl=i(nt),Va=r(nt,"TH",{align:!0}),l(Va).forEach(e),Sl=i(nt),Za=r(nt,"TH",{align:!0}),l(Za).forEach(e),nt.forEach(e),Bi.forEach(e),Al=i(Oo),to=r(Oo,"TBODY",{});var Xi=l(to);v=r(Xi,"TR",{});var it=l(v);qe=r(it,"TD",{align:!0});var Ci=l(qe);$t=r(Ci,"A",{href:!0,rel:!0});var Wi=l($t);Hl=c(Wi,"How to quantize a model with Intel Neural Compressor for text classification"),Wi.forEach(e),Ci.forEach(e),Nl=i(it),Z=r(it,"TD",{align:!0});var Go=l(Z);Ol=c(Go,"Show how to apply static, dynamic and aware training quantization on a model using "),It=r(Go,"A",{href:!0,rel:!0});var Yi=l(It);Gl=c(Yi,"Intel Neural Compressor (INC)"),Yi.forEach(e),Rl=c(Go," for any GLUE task."),Go.forEach(e),$l=i(it),Me=r(it,"TD",{align:!0});var ji=l(Me);Pt=r(ji,"A",{href:!0,rel:!0});var Ki=l(Pt);Be=r(Ki,"IMG",{src:!0,alt:!0}),Ki.forEach(e),ji.forEach(e),Il=i(it),Le=r(it,"TD",{align:!0});var Qi=l(Le);Ut=r(Qi,"A",{href:!0,rel:!0});var Ji=l(Ut);Fe=r(Ji,"IMG",{src:!0,alt:!0}),Ji.forEach(e),Qi.forEach(e),it.forEach(e),Xi.forEach(e),Oo.forEach(e),To=i(s),X=r(s,"H2",{class:!0});var Ro=l(X);tt=r(Ro,"A",{id:!0,class:!0,href:!0});var Vi=l(tt);eo=r(Vi,"SPAN",{});var Zi=l(eo);io(zt.$$.fragment,Zi),Zi.forEach(e),Vi.forEach(e),Pl=i(Ro),ao=r(Ro,"SPAN",{});var ts=l(ao);Ul=c(ts,"ONNX Runtime examples"),ts.forEach(e),Ro.forEach(e),yo=i(s),et=r(s,"TABLE",{});var $o=l(et);oo=r($o,"THEAD",{});var es=l(oo);_=r(es,"TR",{});var st=l(_);Xe=r(st,"TH",{align:!0});var as=l(Xe);zl=c(as,"Notebook"),as.forEach(e),ql=i(st),Ce=r(st,"TH",{align:!0});var os=l(Ce);Ml=c(os,"Description"),os.forEach(e),Bl=i(st),ro=r(st,"TH",{align:!0}),l(ro).forEach(e),Ll=i(st),lo=r(st,"TH",{align:!0}),l(lo).forEach(e),st.forEach(e),es.forEach(e),Fl=i($o),C=r($o,"TBODY",{});var ya=l(C);w=r(ya,"TR",{});var ht=l(w);We=r(ht,"TD",{align:!0});var rs=l(We);qt=r(rs,"A",{href:!0,rel:!0});var ls=l(qt);Xl=c(ls,"How to quantize a model with ONNX Runtime for text classification"),ls.forEach(e),rs.forEach(e),Cl=i(ht),at=r(ht,"TD",{align:!0});var Io=l(at);Wl=c(Io,"Show how to apply static and dynamic quantization on a model using "),Mt=r(Io,"A",{href:!0,rel:!0});var ns=l(Mt);Yl=c(ns,"ONNX Runtime"),ns.forEach(e),jl=c(Io," for any GLUE task."),Io.forEach(e),Kl=i(ht),Ye=r(ht,"TD",{align:!0});var is=l(Ye);Bt=r(is,"A",{href:!0,rel:!0});var ss=l(Bt);je=r(ss,"IMG",{src:!0,alt:!0}),ss.forEach(e),is.forEach(e),Ql=i(ht),Ke=r(ht,"TD",{align:!0});var hs=l(Ke);Lt=r(hs,"A",{href:!0,rel:!0});var cs=l(Lt);Qe=r(cs,"IMG",{src:!0,alt:!0}),cs.forEach(e),hs.forEach(e),ht.forEach(e),Jl=i(ya),E=r(ya,"TR",{});var ct=l(E);Je=r(ct,"TD",{align:!0});var fs=l(Je);Ft=r(fs,"A",{href:!0,rel:!0});var ds=l(Ft);Vl=c(ds,"How to fine-tune a model for text classification with ONNX Runtime"),ds.forEach(e),fs.forEach(e),Zl=i(ct),ot=r(ct,"TD",{align:!0});var Po=l(ot);tn=c(Po,"Show how to DistilBERT model on GLUE tasks using "),Xt=r(Po,"A",{href:!0,rel:!0});var us=l(Xt);en=c(us,"ONNX Runtime"),us.forEach(e),an=c(Po,"."),Po.forEach(e),on=i(ct),Ve=r(ct,"TD",{align:!0});var gs=l(Ve);Ct=r(gs,"A",{href:!0,rel:!0});var ms=l(Ct);Ze=r(ms,"IMG",{src:!0,alt:!0}),ms.forEach(e),gs.forEach(e),rn=i(ct),ta=r(ct,"TD",{align:!0});var ps=l(ta);Wt=r(ps,"A",{href:!0,rel:!0});var bs=l(Wt);ea=r(bs,"IMG",{src:!0,alt:!0}),bs.forEach(e),ps.forEach(e),ct.forEach(e),ln=i(ya),T=r(ya,"TR",{});var ft=l(T);aa=r(ft,"TD",{align:!0});var vs=l(aa);Yt=r(vs,"A",{href:!0,rel:!0});var _s=l(Yt);nn=c(_s,"How to fine-tune a model for summarization with ONNX Runtime"),_s.forEach(e),vs.forEach(e),sn=i(ft),oa=r(ft,"TD",{align:!0});var ws=l(oa);hn=c(ws,"Show how to fine-tune a T5 model on the BBC news corpus."),ws.forEach(e),cn=i(ft),ra=r(ft,"TD",{align:!0});var Es=l(ra);jt=r(Es,"A",{href:!0,rel:!0});var Ts=l(jt);la=r(Ts,"IMG",{src:!0,alt:!0}),Ts.forEach(e),Es.forEach(e),fn=i(ft),na=r(ft,"TD",{align:!0});var ys=l(na);Kt=r(ys,"A",{href:!0,rel:!0});var ks=l(Kt);ia=r(ks,"IMG",{src:!0,alt:!0}),ks.forEach(e),ys.forEach(e),ft.forEach(e),ya.forEach(e),$o.forEach(e),this.h()},h(){a(k,"name","hf:doc:metadata"),a(k,"content",JSON.stringify(Gs)),a(W,"id","optimum-notebooks"),a(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),a(W,"href","#optimum-notebooks"),a(D,"class","relative group"),a(Y,"id","optimum-graphcore-examples"),a(Y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),a(Y,"href","#optimum-graphcore-examples"),a(x,"class","relative group"),a(Jt,"align","left"),a(Vt,"align","left"),a(Ha,"align","left"),a(gt,"href","https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/introduction_to_optimum_graphcore.ipynb"),a(gt,"rel","nofollow"),a(Zt,"align","left"),a(te,"align","left"),y(ae.src,un="https://assets.paperspace.io/img/gradient-badge.svg")||a(ae,"src",un),a(ae,"alt","Gradient"),a(mt,"href","https://console.paperspace.com/github/gradient-ai/Graphcore-HuggingFace?machine=Free-IPU-POD16&container=graphcore%2Fpytorch-jupyter%3A2.6.0-ubuntu-20.04-20220804&file=%2Fnotebook-tutorials%2Fintroduction_to_optimum_graphcore.ipynb"),a(mt,"rel","nofollow"),a(ee,"align","left"),a(pt,"href","https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/external_model.ipynb"),a(pt,"rel","nofollow"),a(oe,"align","left"),a(re,"align","left"),a(Na,"align","left"),a(bt,"href","https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/language_modelling_from_scratch.ipynb"),a(bt,"rel","nofollow"),a(le,"align","left"),a(ne,"align","left"),a(Oa,"align","left"),a(vt,"href","https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/text_classification.ipynb"),a(vt,"rel","nofollow"),a(ie,"align","left"),a(se,"align","left"),y(ce.src,gn="https://assets.paperspace.io/img/gradient-badge.svg")||a(ce,"src",gn),a(ce,"alt","Gradient"),a(_t,"href","https://console.paperspace.com/github/gradient-ai/Graphcore-HuggingFace?machine=Free-IPU-POD16&container=graphcore%2Fpytorch-jupyter%3A2.6.0-ubuntu-20.04-20220804&file=%2Fnotebook-tutorials%2Ftext_classification.ipynb"),a(_t,"rel","nofollow"),a(he,"align","left"),a(wt,"href","https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/language_modeling.ipynb"),a(wt,"rel","nofollow"),a(fe,"align","left"),a(de,"align","left"),a(Ga,"align","left"),a(Et,"href","https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/token_classification.ipynb"),a(Et,"rel","nofollow"),a(ue,"align","left"),a(ge,"align","left"),a(Ra,"align","left"),a(Tt,"href","https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/question_answering.ipynb"),a(Tt,"rel","nofollow"),a(me,"align","left"),a(pe,"align","left"),a($a,"align","left"),a(yt,"href","https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/multiple_choice.ipynb"),a(yt,"rel","nofollow"),a(be,"align","left"),a(ve,"align","left"),a(Ia,"align","left"),a(kt,"href","https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/translation.ipynb"),a(kt,"rel","nofollow"),a(_e,"align","left"),a(we,"align","left"),a(Pa,"align","left"),a(Dt,"href","https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/summarization.ipynb"),a(Dt,"rel","nofollow"),a(Ee,"align","left"),a(Te,"align","left"),a(Ua,"align","left"),a(xt,"href","https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/audio_classification.ipynb"),a(xt,"rel","nofollow"),a(ye,"align","left"),a(ke,"align","left"),a(za,"align","left"),a(St,"href","https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/image_classification.ipynb"),a(St,"rel","nofollow"),a(De,"align","left"),a(xe,"align","left"),y(Ae.src,mn="https://assets.paperspace.io/img/gradient-badge.svg")||a(Ae,"src",mn),a(Ae,"alt","Gradient"),a(At,"href","https://console.paperspace.com/github/gradient-ai/Graphcore-HuggingFace?machine=Free-IPU-POD16&container=graphcore%2Fpytorch-jupyter%3A2.6.0-ubuntu-20.04-20220804&file=%2Fget-started%2Fwalkthrough.ipynb"),a(At,"rel","nofollow"),a(Se,"align","left"),a(Ht,"href","https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/wav2vec2/wav2vec2-fine-tuning-checkpoint.ipynb"),a(Ht,"rel","nofollow"),a(He,"align","left"),a(Ne,"align","left"),a(qa,"align","left"),a(Nt,"href","https://github.com/huggingface/optimum-graphcore/blob/main/notebooks/wav2vec2/wav2vec2-inference-checkpoint.ipynb"),a(Nt,"rel","nofollow"),a(Oe,"align","left"),a(Ge,"align","left"),a(Ma,"align","left"),a(K,"id","optimum-habana-examples"),a(K,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),a(K,"href","#optimum-habana-examples"),a(L,"class","relative group"),a(Re,"align","left"),a($e,"align","left"),a(Xa,"align","left"),a(Ca,"align","right"),a(Gt,"href","https://github.com/huggingface/optimum-habana/blob/main/notebooks/AI_HW_Summit_2022.ipynb"),a(Gt,"rel","nofollow"),a(Ie,"align","left"),a(Pe,"align","left"),a(Ya,"align","left"),a(ja,"align","right"),a(J,"id","optimum-intel-examples"),a(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),a(J,"href","#optimum-intel-examples"),a(F,"class","relative group"),a(Ue,"align","left"),a(ze,"align","left"),a(Va,"align","left"),a(Za,"align","right"),a($t,"href","https://github.com/huggingface/notebooks/blob/main/examples/text_classification_quantization_inc.ipynb"),a($t,"rel","nofollow"),a(qe,"align","left"),a(It,"href","https://github.com/intel/neural-compressor"),a(It,"rel","nofollow"),a(Z,"align","left"),y(Be.src,pn="https://colab.research.google.com/assets/colab-badge.svg")||a(Be,"src",pn),a(Be,"alt","Open in Colab"),a(Pt,"href","https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification_quantization_inc.ipynb"),a(Pt,"rel","nofollow"),a(Me,"align","left"),y(Fe.src,bn="https://studiolab.sagemaker.aws/studiolab.svg")||a(Fe,"src",bn),a(Fe,"alt","Open in AWS Studio"),a(Ut,"href","https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification_quantization_inc.ipynb"),a(Ut,"rel","nofollow"),a(Le,"align","right"),a(tt,"id","onnx-runtime-examples"),a(tt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),a(tt,"href","#onnx-runtime-examples"),a(X,"class","relative group"),a(Xe,"align","left"),a(Ce,"align","left"),a(ro,"align","left"),a(lo,"align","right"),a(qt,"href","https://github.com/huggingface/notebooks/blob/main/examples/text_classification_quantization_ort.ipynb"),a(qt,"rel","nofollow"),a(We,"align","left"),a(Mt,"href","https://github.com/microsoft/onnxruntime"),a(Mt,"rel","nofollow"),a(at,"align","left"),y(je.src,vn="https://colab.research.google.com/assets/colab-badge.svg")||a(je,"src",vn),a(je,"alt","Open in Colab"),a(Bt,"href","https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification_quantization_ort.ipynb"),a(Bt,"rel","nofollow"),a(Ye,"align","left"),y(Qe.src,_n="https://studiolab.sagemaker.aws/studiolab.svg")||a(Qe,"src",_n),a(Qe,"alt","Open in AWS Studio"),a(Lt,"href","https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification_quantization_ort.ipynb"),a(Lt,"rel","nofollow"),a(Ke,"align","right"),a(Ft,"href","https://github.com/huggingface/notebooks/blob/main/examples/text_classification_ort.ipynb"),a(Ft,"rel","nofollow"),a(Je,"align","left"),a(Xt,"href","https://github.com/microsoft/onnxruntime"),a(Xt,"rel","nofollow"),a(ot,"align","left"),y(Ze.src,wn="https://colab.research.google.com/assets/colab-badge.svg")||a(Ze,"src",wn),a(Ze,"alt","Open in Colab"),a(Ct,"href","https://colab.research.google.com/github.com/huggingface/notebooks/blob/main/examples/text_classification_ort.ipynb"),a(Ct,"rel","nofollow"),a(Ve,"align","left"),y(ea.src,En="https://studiolab.sagemaker.aws/studiolab.svg")||a(ea,"src",En),a(ea,"alt","Open in AWS Studio"),a(Wt,"href","https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/examples/text_classification_quantization_ort.ipynb"),a(Wt,"rel","nofollow"),a(ta,"align","right"),a(Yt,"href","https://github.com/huggingface/notebooks/blob/main/examples/summarization_ort.ipynb"),a(Yt,"rel","nofollow"),a(aa,"align","left"),a(oa,"align","left"),y(la.src,Tn="https://colab.research.google.com/assets/colab-badge.svg")||a(la,"src",Tn),a(la,"alt","Open in Colab"),a(jt,"href","https://colab.research.google.com/github.com/huggingface/notebooks/blob/main/examples/summarization_ort.ipynb"),a(jt,"rel","nofollow"),a(ra,"align","left"),y(ia.src,yn="https://studiolab.sagemaker.aws/studiolab.svg")||a(ia,"src",yn),a(ia,"alt","Open in AWS Studio"),a(Kt,"href","https://studiolab.sagemaker.aws/import/github.com/huggingface/notebooks/blob/main/examples/summarization_ort.ipynb"),a(Kt,"rel","nofollow"),a(na,"align","right")},m(s,u){t(document.head,k),g(s,go,u),g(s,D,u),t(D,W),t(W,ka),so(dt,ka,null),t(D,Uo),t(D,Da),t(Da,zo),g(s,mo,u),g(s,Qt,u),t(Qt,qo),g(s,po,u),g(s,x,u),t(x,Y),t(Y,xa),so(ut,xa,null),t(x,Mo),t(x,Sa),t(Sa,Bo),g(s,bo,u),g(s,j,u),t(j,Aa),t(Aa,S),t(S,Jt),t(Jt,Lo),t(S,Fo),t(S,Vt),t(Vt,Xo),t(S,Co),t(S,Ha),t(j,Wo),t(j,f),t(f,A),t(A,Zt),t(Zt,gt),t(gt,Yo),t(A,jo),t(A,te),t(te,Ko),t(A,Qo),t(A,ee),t(ee,mt),t(mt,ae),t(f,Jo),t(f,H),t(H,oe),t(oe,pt),t(pt,Vo),t(H,Zo),t(H,re),t(re,tr),t(H,er),t(H,Na),t(f,ar),t(f,N),t(N,le),t(le,bt),t(bt,or),t(N,rr),t(N,ne),t(ne,lr),t(N,nr),t(N,Oa),t(f,ir),t(f,O),t(O,ie),t(ie,vt),t(vt,sr),t(O,hr),t(O,se),t(se,cr),t(O,fr),t(O,he),t(he,_t),t(_t,ce),t(f,dr),t(f,G),t(G,fe),t(fe,wt),t(wt,ur),t(G,gr),t(G,de),t(de,mr),t(G,pr),t(G,Ga),t(f,br),t(f,R),t(R,ue),t(ue,Et),t(Et,vr),t(R,_r),t(R,ge),t(ge,wr),t(R,Er),t(R,Ra),t(f,Tr),t(f,$),t($,me),t(me,Tt),t(Tt,yr),t($,kr),t($,pe),t(pe,Dr),t($,xr),t($,$a),t(f,Sr),t(f,I),t(I,be),t(be,yt),t(yt,Ar),t(I,Hr),t(I,ve),t(ve,Nr),t(I,Or),t(I,Ia),t(f,Gr),t(f,P),t(P,_e),t(_e,kt),t(kt,Rr),t(P,$r),t(P,we),t(we,Ir),t(P,Pr),t(P,Pa),t(f,Ur),t(f,U),t(U,Ee),t(Ee,Dt),t(Dt,zr),t(U,qr),t(U,Te),t(Te,Mr),t(U,Br),t(U,Ua),t(f,Lr),t(f,z),t(z,ye),t(ye,xt),t(xt,Fr),t(z,Xr),t(z,ke),t(ke,Cr),t(z,Wr),t(z,za),t(f,Yr),t(f,q),t(q,De),t(De,St),t(St,jr),t(q,Kr),t(q,xe),t(xe,Qr),t(q,Jr),t(q,Se),t(Se,At),t(At,Ae),t(f,Vr),t(f,M),t(M,He),t(He,Ht),t(Ht,Zr),t(M,tl),t(M,Ne),t(Ne,el),t(M,al),t(M,qa),t(f,ol),t(f,B),t(B,Oe),t(Oe,Nt),t(Nt,rl),t(B,ll),t(B,Ge),t(Ge,nl),t(B,il),t(B,Ma),g(s,vo,u),g(s,L,u),t(L,K),t(K,Ba),so(Ot,Ba,null),t(L,sl),t(L,La),t(La,hl),g(s,_o,u),g(s,Q,u),t(Q,Fa),t(Fa,m),t(m,Re),t(Re,cl),t(m,fl),t(m,$e),t($e,dl),t(m,ul),t(m,Xa),t(m,gl),t(m,Ca),t(Q,ml),t(Q,Wa),t(Wa,p),t(p,Ie),t(Ie,Gt),t(Gt,pl),t(p,bl),t(p,Pe),t(Pe,vl),t(p,_l),t(p,Ya),t(p,wl),t(p,ja),g(s,wo,u),g(s,F,u),t(F,J),t(J,Ka),so(Rt,Ka,null),t(F,El),t(F,Qa),t(Qa,Tl),g(s,Eo,u),g(s,V,u),t(V,Ja),t(Ja,b),t(b,Ue),t(Ue,yl),t(b,kl),t(b,ze),t(ze,Dl),t(b,xl),t(b,Va),t(b,Sl),t(b,Za),t(V,Al),t(V,to),t(to,v),t(v,qe),t(qe,$t),t($t,Hl),t(v,Nl),t(v,Z),t(Z,Ol),t(Z,It),t(It,Gl),t(Z,Rl),t(v,$l),t(v,Me),t(Me,Pt),t(Pt,Be),t(v,Il),t(v,Le),t(Le,Ut),t(Ut,Fe),g(s,To,u),g(s,X,u),t(X,tt),t(tt,eo),so(zt,eo,null),t(X,Pl),t(X,ao),t(ao,Ul),g(s,yo,u),g(s,et,u),t(et,oo),t(oo,_),t(_,Xe),t(Xe,zl),t(_,ql),t(_,Ce),t(Ce,Ml),t(_,Bl),t(_,ro),t(_,Ll),t(_,lo),t(et,Fl),t(et,C),t(C,w),t(w,We),t(We,qt),t(qt,Xl),t(w,Cl),t(w,at),t(at,Wl),t(at,Mt),t(Mt,Yl),t(at,jl),t(w,Kl),t(w,Ye),t(Ye,Bt),t(Bt,je),t(w,Ql),t(w,Ke),t(Ke,Lt),t(Lt,Qe),t(C,Jl),t(C,E),t(E,Je),t(Je,Ft),t(Ft,Vl),t(E,Zl),t(E,ot),t(ot,tn),t(ot,Xt),t(Xt,en),t(ot,an),t(E,on),t(E,Ve),t(Ve,Ct),t(Ct,Ze),t(E,rn),t(E,ta),t(ta,Wt),t(Wt,ea),t(C,ln),t(C,T),t(T,aa),t(aa,Yt),t(Yt,nn),t(T,sn),t(T,oa),t(oa,hn),t(T,cn),t(T,ra),t(ra,jt),t(jt,la),t(T,fn),t(T,na),t(na,Kt),t(Kt,ia),ko=!0},p:Hs,i(s){ko||(ho(dt.$$.fragment,s),ho(ut.$$.fragment,s),ho(Ot.$$.fragment,s),ho(Rt.$$.fragment,s),ho(zt.$$.fragment,s),ko=!0)},o(s){co(dt.$$.fragment,s),co(ut.$$.fragment,s),co(Ot.$$.fragment,s),co(Rt.$$.fragment,s),co(zt.$$.fragment,s),ko=!1},d(s){e(k),s&&e(go),s&&e(D),fo(dt),s&&e(mo),s&&e(Qt),s&&e(po),s&&e(x),fo(ut),s&&e(bo),s&&e(j),s&&e(vo),s&&e(L),fo(Ot),s&&e(_o),s&&e(Q),s&&e(wo),s&&e(F),fo(Rt),s&&e(Eo),s&&e(V),s&&e(To),s&&e(X),fo(zt),s&&e(yo),s&&e(et)}}}const Gs={local:"optimum-notebooks",sections:[{local:"optimum-graphcore-examples",title:"Optimum Graphcore examples"},{local:"optimum-habana-examples",title:"Optimum Habana examples"},{local:"optimum-intel-examples",title:"Optimum Intel examples"},{local:"onnx-runtime-examples",title:"ONNX Runtime examples"}],title:"\u{1F917} Optimum notebooks"};function Rs(dn){return Ns(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ps extends Ds{constructor(k){super();xs(this,k,Rs,Os,Ss,{})}}export{Ps as default,Gs as metadata};
