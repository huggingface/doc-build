import{S as oe,i as re,s as ie,e as a,k as s,w as f,t as u,M as se,c as o,d as n,m,a as r,x as b,h as d,b as c,G as t,g as G,y as z,L as me,q as x,o as v,B as T,v as ce}from"../../../chunks/vendor-hf-doc-builder.js";import{D as S}from"../../../chunks/Docstring-hf-doc-builder.js";import{I as ae}from"../../../chunks/IconCopyLink-hf-doc-builder.js";function le(Vt){let p,et,h,y,H,D,gt,M,_t,nt,g,$,X,E,ft,B,bt,at,i,P,zt,J,xt,vt,V,N,Tt,q,C,yt,j,$t,qt,O,F,Ot,k,Qt,K,Rt,wt,Dt,Q,L,Et,I,Pt,Y,Nt,Ct,Ft,R,U,kt,Z,Lt,It,w,A,Ut,W,At,tt,Wt,St,ot;return D=new ae({}),E=new ae({}),P=new S({props:{name:"class optimum.onnxruntime.ORTQuantizer",anchor:"optimum.onnxruntime.ORTQuantizer",parameters:[{name:"onnx_model_path",val:": typing.List[pathlib.Path]"}],source:"https://github.com/huggingface/optimum/blob/main/optimum/onnxruntime/quantization.py#L81"}}),N=new S({props:{name:"compute_ranges",anchor:"optimum.onnxruntime.ORTQuantizer.compute_ranges",parameters:[],source:"https://github.com/huggingface/optimum/blob/main/optimum/onnxruntime/quantization.py#L247",returnDescription:`
<p>The dictionary mapping the nodes name to their quantization ranges.</p>
`}}),C=new S({props:{name:"fit",anchor:"optimum.onnxruntime.ORTQuantizer.fit",parameters:[{name:"dataset",val:": Dataset"},{name:"calibration_config",val:": CalibrationConfig"},{name:"onnx_augmented_model_name",val:": str = 'augmented_model.onnx'"},{name:"operators_to_quantize",val:": typing.Optional[typing.List[str]] = None"},{name:"batch_size",val:": int = 1"},{name:"use_external_data_format",val:": bool = False"},{name:"use_gpu",val:": bool = False"},{name:"force_symmetric_range",val:": bool = False"}],parametersDescription:[{anchor:"optimum.onnxruntime.ORTQuantizer.fit.dataset",description:`<strong>dataset</strong> (<code>Dataset</code>) &#x2014;
The dataset to use when performing the calibration step.`,name:"dataset"},{anchor:"optimum.onnxruntime.ORTQuantizer.fit.calibration_config",description:`<strong>calibration_config</strong> (<code>CalibrationConfig</code>) &#x2014;
The configuration containing the parameters related to the calibration step.`,name:"calibration_config"},{anchor:"optimum.onnxruntime.ORTQuantizer.fit.onnx_augmented_model_name",description:`<strong>onnx_augmented_model_name</strong> (<code>Union[str, os.PathLike]</code>) &#x2014;
The path used to save the augmented model used to collect the quantization ranges.`,name:"onnx_augmented_model_name"},{anchor:"optimum.onnxruntime.ORTQuantizer.fit.operators_to_quantize",description:`<strong>operators_to_quantize</strong> (<code>list</code>, <em>optional</em>) &#x2014;
List of the operators types to quantize.`,name:"operators_to_quantize"},{anchor:"optimum.onnxruntime.ORTQuantizer.fit.batch_size",description:`<strong>batch_size</strong> (<code>int</code>, defaults to 1) &#x2014;
The batch size to use when collecting the quantization ranges values.`,name:"batch_size"},{anchor:"optimum.onnxruntime.ORTQuantizer.fit.use_external_data_format",description:`<strong>use_external_data_format</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
Whether uto se external data format to store model which size is &gt;= 2Gb.`,name:"use_external_data_format"},{anchor:"optimum.onnxruntime.ORTQuantizer.fit.use_gpu",description:`<strong>use_gpu</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
Whether to use the GPU when collecting the quantization ranges values.`,name:"use_gpu"},{anchor:"optimum.onnxruntime.ORTQuantizer.fit.force_symmetric_range",description:`<strong>force_symmetric_range</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
Whether to make the quantization ranges symmetric.`,name:"force_symmetric_range"}],source:"https://github.com/huggingface/optimum/blob/main/optimum/onnxruntime/quantization.py#L140",returnDescription:`
<p>The dictionary mapping the nodes name to their quantization ranges.</p>
`}}),F=new S({props:{name:"from_pretrained",anchor:"optimum.onnxruntime.ORTQuantizer.from_pretrained",parameters:[{name:"model_or_path",val:": typing.Union[str, pathlib.Path]"},{name:"file_name",val:": typing.Optional[str] = None"}],parametersDescription:[{anchor:"optimum.onnxruntime.ORTQuantizer.from_pretrained.model_or_path",description:`<strong>model_or_path</strong> (<code>Union[str, Path]</code>) &#x2014;
Can be either:<ul>
<li>A path to a saved exported ONNX Intermediate Representation (IR) model, e.g., \`./my_model_directory/.</li>
<li>Or a <code>ORTModelForXX</code> class, e.g., <code>ORTModelForQuestionAnswering</code>.</li>
</ul>`,name:"model_or_path"},{anchor:"optimum.onnxruntime.ORTQuantizer.from_pretrained.file_name(`Union[str,",description:"<strong>file_name(`Union[str,</strong> List[str]]<code>, *optional*) -- Overwrites the default model file name from </code>&#x201C;model.onnx&#x201D;<code>to</code>file_name`.\nThis allows you to load different model files from the same repository or directory.",name:"file_name(`Union[str,"}],source:"https://github.com/huggingface/optimum/blob/main/optimum/onnxruntime/quantization.py#L96",returnDescription:`
<p>An instance of <code>ORTQuantizer</code>.</p>
`}}),L=new S({props:{name:"get_calibration_dataset",anchor:"optimum.onnxruntime.ORTQuantizer.get_calibration_dataset",parameters:[{name:"dataset_name",val:": str"},{name:"num_samples",val:": int = 100"},{name:"dataset_config_name",val:": typing.Optional[str] = None"},{name:"dataset_split",val:": typing.Optional[str] = None"},{name:"preprocess_function",val:": typing.Optional[typing.Callable] = None"},{name:"preprocess_batch",val:": bool = True"},{name:"seed",val:": int = 2016"},{name:"use_auth_token",val:": bool = False"}],parametersDescription:[{anchor:"optimum.onnxruntime.ORTQuantizer.get_calibration_dataset.dataset_name",description:`<strong>dataset_name</strong> (<code>str</code>) &#x2014;
The dataset repository name on the Hugging Face Hub or path to a local directory containing data files
to load to use for the calibration step.`,name:"dataset_name"},{anchor:"optimum.onnxruntime.ORTQuantizer.get_calibration_dataset.num_samples",description:`<strong>num_samples</strong> (<code>int</code>, defaults to 100) &#x2014;
The maximum number of samples composing the calibration dataset.`,name:"num_samples"},{anchor:"optimum.onnxruntime.ORTQuantizer.get_calibration_dataset.dataset_config_name",description:`<strong>dataset_config_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The name of the dataset configuration.`,name:"dataset_config_name"},{anchor:"optimum.onnxruntime.ORTQuantizer.get_calibration_dataset.dataset_split",description:`<strong>dataset_split</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Which split of the dataset to use to perform the calibration step.`,name:"dataset_split"},{anchor:"optimum.onnxruntime.ORTQuantizer.get_calibration_dataset.preprocess_function",description:`<strong>preprocess_function</strong> (<code>Callable</code>, <em>optional</em>) &#x2014;
Processing function to apply to each example after loading dataset.`,name:"preprocess_function"},{anchor:"optimum.onnxruntime.ORTQuantizer.get_calibration_dataset.preprocess_batch",description:`<strong>preprocess_batch</strong> (<code>bool</code>, defaults to <code>True</code>) &#x2014;
Whether the <code>preprocess_function</code> should be batched.`,name:"preprocess_batch"},{anchor:"optimum.onnxruntime.ORTQuantizer.get_calibration_dataset.seed",description:`<strong>seed</strong> (<code>int</code>, defaults to 2016) &#x2014;
The random seed to use when shuffling the calibration dataset.`,name:"seed"},{anchor:"optimum.onnxruntime.ORTQuantizer.get_calibration_dataset.use_auth_token",description:`<strong>use_auth_token</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
Whether to use the token generated when running <code>transformers-cli login</code> (necessary for some datasets
like ImageNet).`,name:"use_auth_token"}],source:"https://github.com/huggingface/optimum/blob/main/optimum/onnxruntime/quantization.py#L393",returnDescription:`
<p>The calibration <code>datasets.Dataset</code> to use for the post-training static quantization calibration
step.</p>
`}}),U=new S({props:{name:"partial_fit",anchor:"optimum.onnxruntime.ORTQuantizer.partial_fit",parameters:[{name:"dataset",val:": Dataset"},{name:"calibration_config",val:": CalibrationConfig"},{name:"onnx_augmented_model_name",val:": str = 'augmented_model.onnx'"},{name:"operators_to_quantize",val:": typing.Optional[typing.List[str]] = None"},{name:"batch_size",val:": int = 1"},{name:"use_external_data_format",val:": bool = False"},{name:"use_gpu",val:": bool = False"},{name:"force_symmetric_range",val:": bool = False"}],parametersDescription:[{anchor:"optimum.onnxruntime.ORTQuantizer.partial_fit.dataset",description:`<strong>dataset</strong> (<code>Dataset</code>) &#x2014;
The dataset to use when performing the calibration step.`,name:"dataset"},{anchor:"optimum.onnxruntime.ORTQuantizer.partial_fit.calibration_config",description:`<strong>calibration_config</strong> (<code>CalibrationConfig</code>) &#x2014;
The configuration containing the parameters related to the calibration step.`,name:"calibration_config"},{anchor:"optimum.onnxruntime.ORTQuantizer.partial_fit.onnx_augmented_model_name",description:`<strong>onnx_augmented_model_name</strong> (<code>Union[str, os.PathLike]</code>) &#x2014;
The path used to save the augmented model used to collect the quantization ranges.`,name:"onnx_augmented_model_name"},{anchor:"optimum.onnxruntime.ORTQuantizer.partial_fit.operators_to_quantize",description:`<strong>operators_to_quantize</strong> (<code>list</code>, <em>optional</em>) &#x2014;
List of the operators types to quantize.`,name:"operators_to_quantize"},{anchor:"optimum.onnxruntime.ORTQuantizer.partial_fit.batch_size",description:`<strong>batch_size</strong> (<code>int</code>, defaults to 1) &#x2014;
The batch size to use when collecting the quantization ranges values.`,name:"batch_size"},{anchor:"optimum.onnxruntime.ORTQuantizer.partial_fit.use_external_data_format",description:`<strong>use_external_data_format</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
Whether uto se external data format to store model which size is &gt;= 2Gb.`,name:"use_external_data_format"},{anchor:"optimum.onnxruntime.ORTQuantizer.partial_fit.use_gpu",description:`<strong>use_gpu</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
Whether to use the GPU when collecting the quantization ranges values.`,name:"use_gpu"},{anchor:"optimum.onnxruntime.ORTQuantizer.partial_fit.force_symmetric_range",description:`<strong>force_symmetric_range</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
Whether to make the quantization ranges symmetric.`,name:"force_symmetric_range"}],source:"https://github.com/huggingface/optimum/blob/main/optimum/onnxruntime/quantization.py#L194",returnDescription:`
<p>The dictionary mapping the nodes name to their quantization ranges.</p>
`}}),A=new S({props:{name:"quantize",anchor:"optimum.onnxruntime.ORTQuantizer.quantize",parameters:[{name:"quantization_config",val:": QuantizationConfig"},{name:"save_dir",val:": typing.Union[str, pathlib.Path]"},{name:"file_suffix",val:": typing.Optional[str] = 'quantized'"},{name:"calibration_tensors_range",val:": typing.Union[typing.Dict[str, typing.Tuple[float, float]], NoneType] = None"},{name:"use_external_data_format",val:": bool = False"},{name:"preprocessor",val:": typing.Optional[optimum.onnxruntime.preprocessors.quantization.QuantizationPreprocessor] = None"}],parametersDescription:[{anchor:"optimum.onnxruntime.ORTQuantizer.quantize.quantization_config",description:`<strong>quantization_config</strong> (<code>QuantizationConfig</code>) &#x2014;
The configuration containing the parameters related to quantization.`,name:"quantization_config"},{anchor:"optimum.onnxruntime.ORTQuantizer.quantize.save_dir",description:`<strong>save_dir</strong> (<code>Union[str, Path]</code>) &#x2014;
The directory where the quantized model should be saved.`,name:"save_dir"},{anchor:"optimum.onnxruntime.ORTQuantizer.quantize.file_suffix",description:`<strong>file_suffix</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;quantized&quot;</code>) &#x2014;
The file_suffix used to save the quantized model.`,name:"file_suffix"},{anchor:"optimum.onnxruntime.ORTQuantizer.quantize.calibration_tensors_range",description:`<strong>calibration_tensors_range</strong> (<code>Dict[NodeName, Tuple[float, float]]</code>, <em>optional</em>) &#x2014;
The dictionary mapping the nodes name to their quantization ranges, used and required only when applying
static quantization.`,name:"calibration_tensors_range"},{anchor:"optimum.onnxruntime.ORTQuantizer.quantize.use_external_data_format",description:`<strong>use_external_data_format</strong> (<code>bool</code>, defaults to <code>False</code>) &#x2014;
Whether to use external data format to store model which size is &gt;= 2Gb.`,name:"use_external_data_format"},{anchor:"optimum.onnxruntime.ORTQuantizer.quantize.preprocessor",description:`<strong>preprocessor</strong> (<code>QuantizationPreprocessor</code>, <em>optional</em>) &#x2014;
The preprocessor to use to collect the nodes to include or exclude from quantization.`,name:"preprocessor"}],source:"https://github.com/huggingface/optimum/blob/main/optimum/onnxruntime/quantization.py#L260",returnDescription:`
<p>The path of the resulting quantized model.</p>
`}}),{c(){p=a("meta"),et=s(),h=a("h1"),y=a("a"),H=a("span"),f(D.$$.fragment),gt=s(),M=a("span"),_t=u("Quantization"),nt=s(),g=a("h2"),$=a("a"),X=a("span"),f(E.$$.fragment),ft=s(),B=a("span"),bt=u("ORTQuantizer"),at=s(),i=a("div"),f(P.$$.fragment),zt=s(),J=a("p"),xt=u("Handles the ONNX Runtime quantization process for models shared on huggingface.co/models."),vt=s(),V=a("div"),f(N.$$.fragment),Tt=s(),q=a("div"),f(C.$$.fragment),yt=s(),j=a("p"),$t=u("Perform the calibration step and collect the quantization ranges."),qt=s(),O=a("div"),f(F.$$.fragment),Ot=s(),k=a("p"),Qt=u("Instantiate a "),K=a("code"),Rt=u("ORTQuantizer"),wt=u(" from a pretrained pytorch model and preprocessor."),Dt=s(),Q=a("div"),f(L.$$.fragment),Et=s(),I=a("p"),Pt=u("Create the calibration "),Y=a("code"),Nt=u("datasets.Dataset"),Ct=u(" to use for the post-training static quantization calibration step"),Ft=s(),R=a("div"),f(U.$$.fragment),kt=s(),Z=a("p"),Lt=u("Perform the calibration step and collect the quantization ranges."),It=s(),w=a("div"),f(A.$$.fragment),Ut=s(),W=a("p"),At=u("Quantize a model given the optimization specifications defined in "),tt=a("code"),Wt=u("quantization_config"),St=u("."),this.h()},l(e){const _=se('[data-svelte="svelte-1phssyn"]',document.head);p=o(_,"META",{name:!0,content:!0}),_.forEach(n),et=m(e),h=o(e,"H1",{class:!0});var rt=r(h);y=o(rt,"A",{id:!0,class:!0,href:!0});var Gt=r(y);H=o(Gt,"SPAN",{});var Ht=r(H);b(D.$$.fragment,Ht),Ht.forEach(n),Gt.forEach(n),gt=m(rt),M=o(rt,"SPAN",{});var Mt=r(M);_t=d(Mt,"Quantization"),Mt.forEach(n),rt.forEach(n),nt=m(e),g=o(e,"H2",{class:!0});var it=r(g);$=o(it,"A",{id:!0,class:!0,href:!0});var Xt=r($);X=o(Xt,"SPAN",{});var Bt=r(X);b(E.$$.fragment,Bt),Bt.forEach(n),Xt.forEach(n),ft=m(it),B=o(it,"SPAN",{});var Jt=r(B);bt=d(Jt,"ORTQuantizer"),Jt.forEach(n),it.forEach(n),at=m(e),i=o(e,"DIV",{class:!0});var l=r(i);b(P.$$.fragment,l),zt=m(l),J=o(l,"P",{});var jt=r(J);xt=d(jt,"Handles the ONNX Runtime quantization process for models shared on huggingface.co/models."),jt.forEach(n),vt=m(l),V=o(l,"DIV",{class:!0});var Kt=r(V);b(N.$$.fragment,Kt),Kt.forEach(n),Tt=m(l),q=o(l,"DIV",{class:!0});var st=r(q);b(C.$$.fragment,st),yt=m(st),j=o(st,"P",{});var Yt=r(j);$t=d(Yt,"Perform the calibration step and collect the quantization ranges."),Yt.forEach(n),st.forEach(n),qt=m(l),O=o(l,"DIV",{class:!0});var mt=r(O);b(F.$$.fragment,mt),Ot=m(mt),k=o(mt,"P",{});var ct=r(k);Qt=d(ct,"Instantiate a "),K=o(ct,"CODE",{});var Zt=r(K);Rt=d(Zt,"ORTQuantizer"),Zt.forEach(n),wt=d(ct," from a pretrained pytorch model and preprocessor."),ct.forEach(n),mt.forEach(n),Dt=m(l),Q=o(l,"DIV",{class:!0});var lt=r(Q);b(L.$$.fragment,lt),Et=m(lt),I=o(lt,"P",{});var ut=r(I);Pt=d(ut,"Create the calibration "),Y=o(ut,"CODE",{});var te=r(Y);Nt=d(te,"datasets.Dataset"),te.forEach(n),Ct=d(ut," to use for the post-training static quantization calibration step"),ut.forEach(n),lt.forEach(n),Ft=m(l),R=o(l,"DIV",{class:!0});var dt=r(R);b(U.$$.fragment,dt),kt=m(dt),Z=o(dt,"P",{});var ee=r(Z);Lt=d(ee,"Perform the calibration step and collect the quantization ranges."),ee.forEach(n),dt.forEach(n),It=m(l),w=o(l,"DIV",{class:!0});var pt=r(w);b(A.$$.fragment,pt),Ut=m(pt),W=o(pt,"P",{});var ht=r(W);At=d(ht,"Quantize a model given the optimization specifications defined in "),tt=o(ht,"CODE",{});var ne=r(tt);Wt=d(ne,"quantization_config"),ne.forEach(n),St=d(ht,"."),ht.forEach(n),pt.forEach(n),l.forEach(n),this.h()},h(){c(p,"name","hf:doc:metadata"),c(p,"content",JSON.stringify(ue)),c(y,"id","quantization"),c(y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(y,"href","#quantization"),c(h,"class","relative group"),c($,"id","optimum.onnxruntime.ORTQuantizer"),c($,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($,"href","#optimum.onnxruntime.ORTQuantizer"),c(g,"class","relative group"),c(V,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(O,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(R,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(w,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(i,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,_){t(document.head,p),G(e,et,_),G(e,h,_),t(h,y),t(y,H),z(D,H,null),t(h,gt),t(h,M),t(M,_t),G(e,nt,_),G(e,g,_),t(g,$),t($,X),z(E,X,null),t(g,ft),t(g,B),t(B,bt),G(e,at,_),G(e,i,_),z(P,i,null),t(i,zt),t(i,J),t(J,xt),t(i,vt),t(i,V),z(N,V,null),t(i,Tt),t(i,q),z(C,q,null),t(q,yt),t(q,j),t(j,$t),t(i,qt),t(i,O),z(F,O,null),t(O,Ot),t(O,k),t(k,Qt),t(k,K),t(K,Rt),t(k,wt),t(i,Dt),t(i,Q),z(L,Q,null),t(Q,Et),t(Q,I),t(I,Pt),t(I,Y),t(Y,Nt),t(I,Ct),t(i,Ft),t(i,R),z(U,R,null),t(R,kt),t(R,Z),t(Z,Lt),t(i,It),t(i,w),z(A,w,null),t(w,Ut),t(w,W),t(W,At),t(W,tt),t(tt,Wt),t(W,St),ot=!0},p:me,i(e){ot||(x(D.$$.fragment,e),x(E.$$.fragment,e),x(P.$$.fragment,e),x(N.$$.fragment,e),x(C.$$.fragment,e),x(F.$$.fragment,e),x(L.$$.fragment,e),x(U.$$.fragment,e),x(A.$$.fragment,e),ot=!0)},o(e){v(D.$$.fragment,e),v(E.$$.fragment,e),v(P.$$.fragment,e),v(N.$$.fragment,e),v(C.$$.fragment,e),v(F.$$.fragment,e),v(L.$$.fragment,e),v(U.$$.fragment,e),v(A.$$.fragment,e),ot=!1},d(e){n(p),e&&n(et),e&&n(h),T(D),e&&n(nt),e&&n(g),T(E),e&&n(at),e&&n(i),T(P),T(N),T(C),T(F),T(L),T(U),T(A)}}}const ue={local:"quantization",sections:[{local:"optimum.onnxruntime.ORTQuantizer",title:"ORTQuantizer"}],title:"Quantization"};function de(Vt){return ce(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class _e extends oe{constructor(p){super();re(this,p,de,le,ie,{})}}export{_e as default,ue as metadata};
