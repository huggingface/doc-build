import{S as Xa,i as Ga,s as Ba,e as s,k as m,w as b,t as o,M as Ua,c as n,d as i,m as f,a as l,x as w,h as a,b as d,G as t,g as p,y as E,L as Ha,q as y,o as $,B as j,v as Wa}from"../../../chunks/vendor-hf-doc-builder.js";import{I as Qt}from"../../../chunks/IconCopyLink-hf-doc-builder.js";import{C as qe}from"../../../chunks/CodeBlock-hf-doc-builder.js";function Ya(Yo){let x,rt,C,A,Re,X,Vt,Ae,Zt,pt,g,ei,Le,ti,ii,G,oi,ai,mt,T,L,Se,B,si,ce,ni,Ne,li,ft,z,ri,ue,pi,mi,Fe,fi,di,dt,he,U,ci,Me,ui,hi,ct,H,ut,W,Pe,_i,ht,Y,_t,k,S,Ie,J,gi,De,zi,gt,O,Oi,_e,vi,bi,ge,wi,Ei,zt,ze,yi,Ot,h,Oe,Xe,$i,ji,xi,ve,Ge,Ci,Ti,ki,be,Be,qi,Ri,Ai,we,Ue,Li,Si,vt,N,Ni,K,Fi,Mi,bt,q,He,Pi,Ii,We,Di,Xi,wt,c,Q,Gi,Ye,Bi,Ui,Hi,V,Wi,Je,Yi,Ji,Ki,Z,Qi,Ke,Vi,Zi,eo,ee,to,Qe,io,oo,ao,te,so,Ve,no,lo,ro,ie,po,Ze,mo,fo,co,oe,uo,et,ho,_o,Et,v,go,Ee,zo,Oo,ye,vo,bo,yt,_,tt,wo,Eo,ae,yo,it,$o,jo,xo,ot,Co,To,at,ko,$t,se,qo,$e,Ro,jt,ne,xt,je,Ao,Ct,le,Tt,R,F,st,re,Lo,nt,So,kt,M,No,pe,Fo,Mo,qt,me,Rt,P,Po,fe,Io,Do,At,de,Lt;return X=new Qt({}),B=new Qt({}),H=new qe({props:{code:`from optimum.onnxruntime import ORTOptimizer, ORTModelForSequenceClassification

model = ORTModelForSequenceClassification.from_pretrained("optimum/distilbert-base-uncased-finetuned-sst-2-english")

optimizer = ORTOptimizer.from_pretrained(model)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> optimum.onnxruntime <span class="hljs-keyword">import</span> ORTOptimizer, ORTModelForSequenceClassification

<span class="hljs-comment"># Loading ONNX Model from the Hub</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = ORTModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;optimum/distilbert-base-uncased-finetuned-sst-2-english&quot;</span>)

<span class="hljs-comment"># Create an optimizer from an ORTModelForXXX</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer = ORTOptimizer.from_pretrained(model)`}}),Y=new qe({props:{code:`from optimum.onnxruntime import ORTOptimizer

optimizer = ORTOptimizer.from_pretrained("path/to/model")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> optimum.onnxruntime <span class="hljs-keyword">import</span> ORTOptimizer

<span class="hljs-comment"># This assumes a model.onnx exists in path/to/model</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer = ORTOptimizer.from_pretrained(<span class="hljs-string">&quot;path/to/model&quot;</span>)`}}),J=new Qt({}),ne=new qe({props:{code:`from optimum.onnxruntime import AutoOptimizationConfig
optimization_config = AutoOptimizationConfig.O2()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> optimum.onnxruntime <span class="hljs-keyword">import</span> AutoOptimizationConfig
<span class="hljs-meta">&gt;&gt;&gt; </span>optimization_config = AutoOptimizationConfig.O2()`}}),le=new qe({props:{code:`from optimum.onnxruntime import AutoOptimizationConfig
optimization_config = AutoOptimizationConfig.O2(disable_embed_layer_norm_fusion=False)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> optimum.onnxruntime <span class="hljs-keyword">import</span> AutoOptimizationConfig
<span class="hljs-meta">&gt;&gt;&gt; </span>optimization_config = AutoOptimizationConfig.O2(disable_embed_layer_norm_fusion=<span class="hljs-literal">False</span>)`}}),re=new Qt({}),me=new qe({props:{code:`from optimum.onnxruntime import ORTOptimizer, ORTModelForSequenceClassification, OptimizationConfig

model_id = "distilbert-base-uncased-finetuned-sst-2-english"
save_dir = "/tmp/outputs"

model = ORTModelForSequenceClassification.from_pretrained(model_id, from_transformers=True)

optimizer = ORTOptimizer.from_pretrained(model)

optimization_config = OptimizationConfig(

optimizer.optimize(save_dir=save_dir, optimization_config=optimization_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> optimum.onnxruntime <span class="hljs-keyword">import</span> ORTOptimizer, ORTModelForSequenceClassification, OptimizationConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>model_id = <span class="hljs-string">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>save_dir = <span class="hljs-string">&quot;/tmp/outputs&quot;</span>

<span class="hljs-comment"># Load a PyTorch model and export it to the ONNX format</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = ORTModelForSequenceClassification.from_pretrained(model_id, from_transformers=<span class="hljs-literal">True</span>)

<span class="hljs-comment"># Create the optimizer</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer = ORTOptimizer.from_pretrained(model)

<span class="hljs-comment"># Define the optimization strategy by creating the appropriate configuration</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>optimization_config = OptimizationConfig(
    optimization_level=<span class="hljs-number">2</span>,
    enable_transformers_specific_optimizations=<span class="hljs-literal">True</span>,
    optimize_for_gpu=<span class="hljs-literal">False</span>,
)

<span class="hljs-comment"># Optimize the model</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer.optimize(save_dir=save_dir, optimization_config=optimization_config)`}}),de=new qe({props:{code:`from optimum.onnxruntime import ORTOptimizer, ORTModelForSeq2SeqLM, OptimizationConfig
from transformers import AutoTokenizer

model_id = "sshleifer/distilbart-cnn-12-6"
save_dir = "/tmp/outputs"

model = ORTModelForSeq2SeqLM.from_pretrained(model_id, from_transformers=True)

optimizer = ORTOptimizer.from_pretrained(model)

optimization_config = OptimizationConfig(

optimizer.optimize(save_dir=save_dir, optimization_config=optimization_config)

optimized_model = ORTModelForSeq2SeqLM.from_pretrained(
tokenizer = AutoTokenizer.from_pretrained(model_id)
tokens = tokenizer("This is a sample input", return_tensors="pt")
outputs = optimized_model.generate(**tokens)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> optimum.onnxruntime <span class="hljs-keyword">import</span> ORTOptimizer, ORTModelForSeq2SeqLM, OptimizationConfig
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>model_id = <span class="hljs-string">&quot;sshleifer/distilbart-cnn-12-6&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>save_dir = <span class="hljs-string">&quot;/tmp/outputs&quot;</span>

<span class="hljs-comment"># Load a PyTorch model and export it to the ONNX format</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = ORTModelForSeq2SeqLM.from_pretrained(model_id, from_transformers=<span class="hljs-literal">True</span>)

<span class="hljs-comment"># Create the optimizer</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer = ORTOptimizer.from_pretrained(model)

<span class="hljs-comment"># Define the optimization strategy by creating the appropriate configuration</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>optimization_config = OptimizationConfig(
    optimization_level=<span class="hljs-number">2</span>,
    enable_transformers_specific_optimizations=<span class="hljs-literal">True</span>,
    optimize_for_gpu=<span class="hljs-literal">False</span>,
)

<span class="hljs-comment"># Optimize the model</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer.optimize(save_dir=save_dir, optimization_config=optimization_config)

<span class="hljs-comment"># Load the resulting optimized model</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>optimized_model = ORTModelForSeq2SeqLM.from_pretrained(
    save_dir,
    encoder_file_name=<span class="hljs-string">&quot;encoder_model_optimized.onnx&quot;</span>,
    decoder_file_name=<span class="hljs-string">&quot;decoder_model_optimized.onnx&quot;</span>,
    decoder_file_with_past_name=<span class="hljs-string">&quot;decoder_with_past_model_optimized.onnx&quot;</span>,
)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_id)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokens = tokenizer(<span class="hljs-string">&quot;This is a sample input&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = optimized_model.generate(**tokens)`}}),{c(){x=s("meta"),rt=m(),C=s("h1"),A=s("a"),Re=s("span"),b(X.$$.fragment),Vt=m(),Ae=s("span"),Zt=o("Optimization"),pt=m(),g=s("p"),ei=o("\u{1F917} Optimum provides an "),Le=s("code"),ti=o("optimum.onnxruntime"),ii=o(" package that enables you to apply graph optimization on many model hosted on the \u{1F917} hub using the "),G=s("a"),oi=o("ONNX Runtime"),ai=o(" model optimization tool."),mt=m(),T=s("h2"),L=s("a"),Se=s("span"),b(B.$$.fragment),si=m(),ce=s("span"),ni=o("Creating an "),Ne=s("code"),li=o("ORTOptimizer"),ft=m(),z=s("p"),ri=o("The "),ue=s("a"),pi=o("ORTOptimizer"),mi=o(" class is used to optimize your ONNX model. The class can be initialized using the "),Fe=s("code"),fi=o("from_pretrained()"),di=o(" method, which supports different checkpoint formats."),dt=m(),he=s("ol"),U=s("li"),ci=o("Using an already initialized "),Me=s("code"),ui=o("ORTModelForXXX"),hi=o(" class."),ct=m(),b(H.$$.fragment),ut=m(),W=s("ol"),Pe=s("li"),_i=o("Using a local ONNX model from a directory."),ht=m(),b(Y.$$.fragment),_t=m(),k=s("h2"),S=s("a"),Ie=s("span"),b(J.$$.fragment),gi=m(),De=s("span"),zi=o("Optimization Configuration"),gt=m(),O=s("p"),Oi=o("The "),_e=s("a"),vi=o("OptimizationConfig"),bi=o(" class allows to specify how the optimization should be performed by the "),ge=s("a"),wi=o("ORTOptimizer"),Ei=o("."),zt=m(),ze=s("p"),yi=o("In the optimization configuration, there are 4 possible optimization levels:"),Ot=m(),h=s("ul"),Oe=s("li"),Xe=s("code"),$i=o("optimization_level=0"),ji=o(": to disable all optimizations"),xi=m(),ve=s("li"),Ge=s("code"),Ci=o("optimization_level=1"),Ti=o(": to enable basic optimizations such as constant folding or redundant node eliminations"),ki=m(),be=s("li"),Be=s("code"),qi=o("optimization_level=2"),Ri=o(": to enable extended graph optimizations such as node fusions"),Ai=m(),we=s("li"),Ue=s("code"),Li=o("optimization_level=99"),Si=o(": to enable data layout optimizations"),vt=m(),N=s("p"),Ni=o(`Choosing a level enables the optimizations of that level, as well as the optimizations of all preceding levels.
More information `),K=s("a"),Fi=o("here"),Mi=o("."),bt=m(),q=s("p"),He=s("code"),Pi=o("enable_transformers_specific_optimizations=True"),Ii=o(" means that "),We=s("code"),Di=o("transformers"),Xi=o(`-specific graph fusion and approximation are performed in addition to the ONNX Runtime optimizations described above.
Here is a list of the possible optimizations you can enable:`),wt=m(),c=s("ul"),Q=s("li"),Gi=o("Gelu fusion with "),Ye=s("code"),Bi=o("disable_gelu_fusion=False"),Ui=o(","),Hi=m(),V=s("li"),Wi=o("Layer Normalization fusion with "),Je=s("code"),Yi=o("disable_layer_norm_fusion=False"),Ji=o(","),Ki=m(),Z=s("li"),Qi=o("Attention fusion with "),Ke=s("code"),Vi=o("disable_attention_fusion=False"),Zi=o(","),eo=m(),ee=s("li"),to=o("SkipLayerNormalization fusion with "),Qe=s("code"),io=o("disable_skip_layer_norm_fusion=False"),oo=o(","),ao=m(),te=s("li"),so=o("Add Bias and SkipLayerNormalization fusion with "),Ve=s("code"),no=o("disable_bias_skip_layer_norm_fusion=False"),lo=o(","),ro=m(),ie=s("li"),po=o("Add Bias and Gelu / FastGelu fusion with "),Ze=s("code"),mo=o("disable_bias_gelu_fusion=False"),fo=o(","),co=m(),oe=s("li"),uo=o("Gelu approximation with "),et=s("code"),ho=o("enable_gelu_approximation=True"),_o=o("."),Et=m(),v=s("p"),go=o("While "),Ee=s("a"),zo=o("OptimizationConfig"),Oo=o(" gives you full control on how to do optimization, it can be hard to know what to enable / disable. Instead, you can use "),ye=s("a"),vo=o("AutoOptimizationConfig"),bo=o(" which provides 3 common optimizations levels:"),yt=m(),_=s("ul"),tt=s("li"),wo=o("O1: basic general optimizations."),Eo=m(),ae=s("li"),yo=o("O2: basic and extended general optimizations, "),it=s("code"),$o=o("transformers"),jo=o("-specific fusions."),xo=m(),ot=s("li"),Co=o("O3: same as O2 with Gelu approximation."),To=m(),at=s("li"),ko=o("O4: same as O3 with mixed precision."),$t=m(),se=s("p"),qo=o("Example: Loading a O2 "),$e=s("a"),Ro=o("OptimizationConfig"),jt=m(),b(ne.$$.fragment),xt=m(),je=s("p"),Ao=o("You can also specify custom argument that were not defined in the O2 configuration, for instance:"),Ct=m(),b(le.$$.fragment),Tt=m(),R=s("h2"),F=s("a"),st=s("span"),b(re.$$.fragment),Lo=m(),nt=s("span"),So=o("Optimization examples"),kt=m(),M=s("p"),No=o("Below you will find an easy end-to-end example on how to optimize "),pe=s("a"),Fo=o("distilbert-base-uncased-finetuned-sst-2-english"),Mo=o("."),qt=m(),b(me.$$.fragment),Rt=m(),P=s("p"),Po=o("Below you will find an easy end-to-end example on how to optimize a Seq2Seq model "),fe=s("a"),Io=o("sshleifer/distilbart-cnn-12-6\u201D"),Do=o("."),At=m(),b(de.$$.fragment),this.h()},l(e){const r=Ua('[data-svelte="svelte-1phssyn"]',document.head);x=n(r,"META",{name:!0,content:!0}),r.forEach(i),rt=f(e),C=n(e,"H1",{class:!0});var St=l(C);A=n(St,"A",{id:!0,class:!0,href:!0});var Jo=l(A);Re=n(Jo,"SPAN",{});var Ko=l(Re);w(X.$$.fragment,Ko),Ko.forEach(i),Jo.forEach(i),Vt=f(St),Ae=n(St,"SPAN",{});var Qo=l(Ae);Zt=a(Qo,"Optimization"),Qo.forEach(i),St.forEach(i),pt=f(e),g=n(e,"P",{});var xe=l(g);ei=a(xe,"\u{1F917} Optimum provides an "),Le=n(xe,"CODE",{});var Vo=l(Le);ti=a(Vo,"optimum.onnxruntime"),Vo.forEach(i),ii=a(xe," package that enables you to apply graph optimization on many model hosted on the \u{1F917} hub using the "),G=n(xe,"A",{href:!0,rel:!0});var Zo=l(G);oi=a(Zo,"ONNX Runtime"),Zo.forEach(i),ai=a(xe," model optimization tool."),xe.forEach(i),mt=f(e),T=n(e,"H2",{class:!0});var Nt=l(T);L=n(Nt,"A",{id:!0,class:!0,href:!0});var ea=l(L);Se=n(ea,"SPAN",{});var ta=l(Se);w(B.$$.fragment,ta),ta.forEach(i),ea.forEach(i),si=f(Nt),ce=n(Nt,"SPAN",{});var Xo=l(ce);ni=a(Xo,"Creating an "),Ne=n(Xo,"CODE",{});var ia=l(Ne);li=a(ia,"ORTOptimizer"),ia.forEach(i),Xo.forEach(i),Nt.forEach(i),ft=f(e),z=n(e,"P",{});var Ce=l(z);ri=a(Ce,"The "),ue=n(Ce,"A",{href:!0});var oa=l(ue);pi=a(oa,"ORTOptimizer"),oa.forEach(i),mi=a(Ce," class is used to optimize your ONNX model. The class can be initialized using the "),Fe=n(Ce,"CODE",{});var aa=l(Fe);fi=a(aa,"from_pretrained()"),aa.forEach(i),di=a(Ce," method, which supports different checkpoint formats."),Ce.forEach(i),dt=f(e),he=n(e,"OL",{});var sa=l(he);U=n(sa,"LI",{});var Ft=l(U);ci=a(Ft,"Using an already initialized "),Me=n(Ft,"CODE",{});var na=l(Me);ui=a(na,"ORTModelForXXX"),na.forEach(i),hi=a(Ft," class."),Ft.forEach(i),sa.forEach(i),ct=f(e),w(H.$$.fragment,e),ut=f(e),W=n(e,"OL",{start:!0});var la=l(W);Pe=n(la,"LI",{});var ra=l(Pe);_i=a(ra,"Using a local ONNX model from a directory."),ra.forEach(i),la.forEach(i),ht=f(e),w(Y.$$.fragment,e),_t=f(e),k=n(e,"H2",{class:!0});var Mt=l(k);S=n(Mt,"A",{id:!0,class:!0,href:!0});var pa=l(S);Ie=n(pa,"SPAN",{});var ma=l(Ie);w(J.$$.fragment,ma),ma.forEach(i),pa.forEach(i),gi=f(Mt),De=n(Mt,"SPAN",{});var fa=l(De);zi=a(fa,"Optimization Configuration"),fa.forEach(i),Mt.forEach(i),gt=f(e),O=n(e,"P",{});var Te=l(O);Oi=a(Te,"The "),_e=n(Te,"A",{href:!0});var da=l(_e);vi=a(da,"OptimizationConfig"),da.forEach(i),bi=a(Te," class allows to specify how the optimization should be performed by the "),ge=n(Te,"A",{href:!0});var ca=l(ge);wi=a(ca,"ORTOptimizer"),ca.forEach(i),Ei=a(Te,"."),Te.forEach(i),zt=f(e),ze=n(e,"P",{});var ua=l(ze);yi=a(ua,"In the optimization configuration, there are 4 possible optimization levels:"),ua.forEach(i),Ot=f(e),h=n(e,"UL",{});var I=l(h);Oe=n(I,"LI",{});var Go=l(Oe);Xe=n(Go,"CODE",{});var ha=l(Xe);$i=a(ha,"optimization_level=0"),ha.forEach(i),ji=a(Go,": to disable all optimizations"),Go.forEach(i),xi=f(I),ve=n(I,"LI",{});var Bo=l(ve);Ge=n(Bo,"CODE",{});var _a=l(Ge);Ci=a(_a,"optimization_level=1"),_a.forEach(i),Ti=a(Bo,": to enable basic optimizations such as constant folding or redundant node eliminations"),Bo.forEach(i),ki=f(I),be=n(I,"LI",{});var Uo=l(be);Be=n(Uo,"CODE",{});var ga=l(Be);qi=a(ga,"optimization_level=2"),ga.forEach(i),Ri=a(Uo,": to enable extended graph optimizations such as node fusions"),Uo.forEach(i),Ai=f(I),we=n(I,"LI",{});var Ho=l(we);Ue=n(Ho,"CODE",{});var za=l(Ue);Li=a(za,"optimization_level=99"),za.forEach(i),Si=a(Ho,": to enable data layout optimizations"),Ho.forEach(i),I.forEach(i),vt=f(e),N=n(e,"P",{});var Pt=l(N);Ni=a(Pt,`Choosing a level enables the optimizations of that level, as well as the optimizations of all preceding levels.
More information `),K=n(Pt,"A",{href:!0,rel:!0});var Oa=l(K);Fi=a(Oa,"here"),Oa.forEach(i),Mi=a(Pt,"."),Pt.forEach(i),bt=f(e),q=n(e,"P",{});var lt=l(q);He=n(lt,"CODE",{});var va=l(He);Pi=a(va,"enable_transformers_specific_optimizations=True"),va.forEach(i),Ii=a(lt," means that "),We=n(lt,"CODE",{});var ba=l(We);Di=a(ba,"transformers"),ba.forEach(i),Xi=a(lt,`-specific graph fusion and approximation are performed in addition to the ONNX Runtime optimizations described above.
Here is a list of the possible optimizations you can enable:`),lt.forEach(i),wt=f(e),c=n(e,"UL",{});var u=l(c);Q=n(u,"LI",{});var It=l(Q);Gi=a(It,"Gelu fusion with "),Ye=n(It,"CODE",{});var wa=l(Ye);Bi=a(wa,"disable_gelu_fusion=False"),wa.forEach(i),Ui=a(It,","),It.forEach(i),Hi=f(u),V=n(u,"LI",{});var Dt=l(V);Wi=a(Dt,"Layer Normalization fusion with "),Je=n(Dt,"CODE",{});var Ea=l(Je);Yi=a(Ea,"disable_layer_norm_fusion=False"),Ea.forEach(i),Ji=a(Dt,","),Dt.forEach(i),Ki=f(u),Z=n(u,"LI",{});var Xt=l(Z);Qi=a(Xt,"Attention fusion with "),Ke=n(Xt,"CODE",{});var ya=l(Ke);Vi=a(ya,"disable_attention_fusion=False"),ya.forEach(i),Zi=a(Xt,","),Xt.forEach(i),eo=f(u),ee=n(u,"LI",{});var Gt=l(ee);to=a(Gt,"SkipLayerNormalization fusion with "),Qe=n(Gt,"CODE",{});var $a=l(Qe);io=a($a,"disable_skip_layer_norm_fusion=False"),$a.forEach(i),oo=a(Gt,","),Gt.forEach(i),ao=f(u),te=n(u,"LI",{});var Bt=l(te);so=a(Bt,"Add Bias and SkipLayerNormalization fusion with "),Ve=n(Bt,"CODE",{});var ja=l(Ve);no=a(ja,"disable_bias_skip_layer_norm_fusion=False"),ja.forEach(i),lo=a(Bt,","),Bt.forEach(i),ro=f(u),ie=n(u,"LI",{});var Ut=l(ie);po=a(Ut,"Add Bias and Gelu / FastGelu fusion with "),Ze=n(Ut,"CODE",{});var xa=l(Ze);mo=a(xa,"disable_bias_gelu_fusion=False"),xa.forEach(i),fo=a(Ut,","),Ut.forEach(i),co=f(u),oe=n(u,"LI",{});var Ht=l(oe);uo=a(Ht,"Gelu approximation with "),et=n(Ht,"CODE",{});var Ca=l(et);ho=a(Ca,"enable_gelu_approximation=True"),Ca.forEach(i),_o=a(Ht,"."),Ht.forEach(i),u.forEach(i),Et=f(e),v=n(e,"P",{});var ke=l(v);go=a(ke,"While "),Ee=n(ke,"A",{href:!0});var Ta=l(Ee);zo=a(Ta,"OptimizationConfig"),Ta.forEach(i),Oo=a(ke," gives you full control on how to do optimization, it can be hard to know what to enable / disable. Instead, you can use "),ye=n(ke,"A",{href:!0});var ka=l(ye);vo=a(ka,"AutoOptimizationConfig"),ka.forEach(i),bo=a(ke," which provides 3 common optimizations levels:"),ke.forEach(i),yt=f(e),_=n(e,"UL",{});var D=l(_);tt=n(D,"LI",{});var qa=l(tt);wo=a(qa,"O1: basic general optimizations."),qa.forEach(i),Eo=f(D),ae=n(D,"LI",{});var Wt=l(ae);yo=a(Wt,"O2: basic and extended general optimizations, "),it=n(Wt,"CODE",{});var Ra=l(it);$o=a(Ra,"transformers"),Ra.forEach(i),jo=a(Wt,"-specific fusions."),Wt.forEach(i),xo=f(D),ot=n(D,"LI",{});var Aa=l(ot);Co=a(Aa,"O3: same as O2 with Gelu approximation."),Aa.forEach(i),To=f(D),at=n(D,"LI",{});var La=l(at);ko=a(La,"O4: same as O3 with mixed precision."),La.forEach(i),D.forEach(i),$t=f(e),se=n(e,"P",{});var Wo=l(se);qo=a(Wo,"Example: Loading a O2 "),$e=n(Wo,"A",{href:!0});var Sa=l($e);Ro=a(Sa,"OptimizationConfig"),Sa.forEach(i),Wo.forEach(i),jt=f(e),w(ne.$$.fragment,e),xt=f(e),je=n(e,"P",{});var Na=l(je);Ao=a(Na,"You can also specify custom argument that were not defined in the O2 configuration, for instance:"),Na.forEach(i),Ct=f(e),w(le.$$.fragment,e),Tt=f(e),R=n(e,"H2",{class:!0});var Yt=l(R);F=n(Yt,"A",{id:!0,class:!0,href:!0});var Fa=l(F);st=n(Fa,"SPAN",{});var Ma=l(st);w(re.$$.fragment,Ma),Ma.forEach(i),Fa.forEach(i),Lo=f(Yt),nt=n(Yt,"SPAN",{});var Pa=l(nt);So=a(Pa,"Optimization examples"),Pa.forEach(i),Yt.forEach(i),kt=f(e),M=n(e,"P",{});var Jt=l(M);No=a(Jt,"Below you will find an easy end-to-end example on how to optimize "),pe=n(Jt,"A",{href:!0,rel:!0});var Ia=l(pe);Fo=a(Ia,"distilbert-base-uncased-finetuned-sst-2-english"),Ia.forEach(i),Mo=a(Jt,"."),Jt.forEach(i),qt=f(e),w(me.$$.fragment,e),Rt=f(e),P=n(e,"P",{});var Kt=l(P);Po=a(Kt,"Below you will find an easy end-to-end example on how to optimize a Seq2Seq model "),fe=n(Kt,"A",{href:!0,rel:!0});var Da=l(fe);Io=a(Da,"sshleifer/distilbart-cnn-12-6\u201D"),Da.forEach(i),Do=a(Kt,"."),Kt.forEach(i),At=f(e),w(de.$$.fragment,e),this.h()},h(){d(x,"name","hf:doc:metadata"),d(x,"content",JSON.stringify(Ja)),d(A,"id","optimization"),d(A,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(A,"href","#optimization"),d(C,"class","relative group"),d(G,"href","https://github.com/microsoft/onnxruntime/tree/master/onnxruntime/python/tools/transformers"),d(G,"rel","nofollow"),d(L,"id","creating-an-ortoptimizer"),d(L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(L,"href","#creating-an-ortoptimizer"),d(T,"class","relative group"),d(ue,"href","/docs/optimum/main/en/onnxruntime/package_reference/optimization#optimum.onnxruntime.ORTOptimizer"),d(W,"start","2"),d(S,"id","optimization-configuration"),d(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(S,"href","#optimization-configuration"),d(k,"class","relative group"),d(_e,"href","/docs/optimum/main/en/onnxruntime/package_reference/configuration#optimum.onnxruntime.OptimizationConfig"),d(ge,"href","/docs/optimum/main/en/onnxruntime/package_reference/optimization#optimum.onnxruntime.ORTOptimizer"),d(K,"href","https://onnxruntime.ai/docs/performance/graph-optimizations.html"),d(K,"rel","nofollow"),d(Ee,"href","/docs/optimum/main/en/onnxruntime/package_reference/configuration#optimum.onnxruntime.OptimizationConfig"),d(ye,"href","/docs/optimum/main/en/onnxruntime/package_reference/configuration#optimum.onnxruntime.AutoOptimizationConfig"),d($e,"href","/docs/optimum/main/en/onnxruntime/package_reference/configuration#optimum.onnxruntime.OptimizationConfig"),d(F,"id","optimization-examples"),d(F,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(F,"href","#optimization-examples"),d(R,"class","relative group"),d(pe,"href","https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english"),d(pe,"rel","nofollow"),d(fe,"href","https://huggingface.co/sshleifer/distilbart-cnn-12-6"),d(fe,"rel","nofollow")},m(e,r){t(document.head,x),p(e,rt,r),p(e,C,r),t(C,A),t(A,Re),E(X,Re,null),t(C,Vt),t(C,Ae),t(Ae,Zt),p(e,pt,r),p(e,g,r),t(g,ei),t(g,Le),t(Le,ti),t(g,ii),t(g,G),t(G,oi),t(g,ai),p(e,mt,r),p(e,T,r),t(T,L),t(L,Se),E(B,Se,null),t(T,si),t(T,ce),t(ce,ni),t(ce,Ne),t(Ne,li),p(e,ft,r),p(e,z,r),t(z,ri),t(z,ue),t(ue,pi),t(z,mi),t(z,Fe),t(Fe,fi),t(z,di),p(e,dt,r),p(e,he,r),t(he,U),t(U,ci),t(U,Me),t(Me,ui),t(U,hi),p(e,ct,r),E(H,e,r),p(e,ut,r),p(e,W,r),t(W,Pe),t(Pe,_i),p(e,ht,r),E(Y,e,r),p(e,_t,r),p(e,k,r),t(k,S),t(S,Ie),E(J,Ie,null),t(k,gi),t(k,De),t(De,zi),p(e,gt,r),p(e,O,r),t(O,Oi),t(O,_e),t(_e,vi),t(O,bi),t(O,ge),t(ge,wi),t(O,Ei),p(e,zt,r),p(e,ze,r),t(ze,yi),p(e,Ot,r),p(e,h,r),t(h,Oe),t(Oe,Xe),t(Xe,$i),t(Oe,ji),t(h,xi),t(h,ve),t(ve,Ge),t(Ge,Ci),t(ve,Ti),t(h,ki),t(h,be),t(be,Be),t(Be,qi),t(be,Ri),t(h,Ai),t(h,we),t(we,Ue),t(Ue,Li),t(we,Si),p(e,vt,r),p(e,N,r),t(N,Ni),t(N,K),t(K,Fi),t(N,Mi),p(e,bt,r),p(e,q,r),t(q,He),t(He,Pi),t(q,Ii),t(q,We),t(We,Di),t(q,Xi),p(e,wt,r),p(e,c,r),t(c,Q),t(Q,Gi),t(Q,Ye),t(Ye,Bi),t(Q,Ui),t(c,Hi),t(c,V),t(V,Wi),t(V,Je),t(Je,Yi),t(V,Ji),t(c,Ki),t(c,Z),t(Z,Qi),t(Z,Ke),t(Ke,Vi),t(Z,Zi),t(c,eo),t(c,ee),t(ee,to),t(ee,Qe),t(Qe,io),t(ee,oo),t(c,ao),t(c,te),t(te,so),t(te,Ve),t(Ve,no),t(te,lo),t(c,ro),t(c,ie),t(ie,po),t(ie,Ze),t(Ze,mo),t(ie,fo),t(c,co),t(c,oe),t(oe,uo),t(oe,et),t(et,ho),t(oe,_o),p(e,Et,r),p(e,v,r),t(v,go),t(v,Ee),t(Ee,zo),t(v,Oo),t(v,ye),t(ye,vo),t(v,bo),p(e,yt,r),p(e,_,r),t(_,tt),t(tt,wo),t(_,Eo),t(_,ae),t(ae,yo),t(ae,it),t(it,$o),t(ae,jo),t(_,xo),t(_,ot),t(ot,Co),t(_,To),t(_,at),t(at,ko),p(e,$t,r),p(e,se,r),t(se,qo),t(se,$e),t($e,Ro),p(e,jt,r),E(ne,e,r),p(e,xt,r),p(e,je,r),t(je,Ao),p(e,Ct,r),E(le,e,r),p(e,Tt,r),p(e,R,r),t(R,F),t(F,st),E(re,st,null),t(R,Lo),t(R,nt),t(nt,So),p(e,kt,r),p(e,M,r),t(M,No),t(M,pe),t(pe,Fo),t(M,Mo),p(e,qt,r),E(me,e,r),p(e,Rt,r),p(e,P,r),t(P,Po),t(P,fe),t(fe,Io),t(P,Do),p(e,At,r),E(de,e,r),Lt=!0},p:Ha,i(e){Lt||(y(X.$$.fragment,e),y(B.$$.fragment,e),y(H.$$.fragment,e),y(Y.$$.fragment,e),y(J.$$.fragment,e),y(ne.$$.fragment,e),y(le.$$.fragment,e),y(re.$$.fragment,e),y(me.$$.fragment,e),y(de.$$.fragment,e),Lt=!0)},o(e){$(X.$$.fragment,e),$(B.$$.fragment,e),$(H.$$.fragment,e),$(Y.$$.fragment,e),$(J.$$.fragment,e),$(ne.$$.fragment,e),$(le.$$.fragment,e),$(re.$$.fragment,e),$(me.$$.fragment,e),$(de.$$.fragment,e),Lt=!1},d(e){i(x),e&&i(rt),e&&i(C),j(X),e&&i(pt),e&&i(g),e&&i(mt),e&&i(T),j(B),e&&i(ft),e&&i(z),e&&i(dt),e&&i(he),e&&i(ct),j(H,e),e&&i(ut),e&&i(W),e&&i(ht),j(Y,e),e&&i(_t),e&&i(k),j(J),e&&i(gt),e&&i(O),e&&i(zt),e&&i(ze),e&&i(Ot),e&&i(h),e&&i(vt),e&&i(N),e&&i(bt),e&&i(q),e&&i(wt),e&&i(c),e&&i(Et),e&&i(v),e&&i(yt),e&&i(_),e&&i($t),e&&i(se),e&&i(jt),j(ne,e),e&&i(xt),e&&i(je),e&&i(Ct),j(le,e),e&&i(Tt),e&&i(R),j(re),e&&i(kt),e&&i(M),e&&i(qt),j(me,e),e&&i(Rt),e&&i(P),e&&i(At),j(de,e)}}}const Ja={local:"optimization",sections:[{local:"creating-an-ortoptimizer",title:"Creating an `ORTOptimizer`"},{local:"optimization-configuration",title:"Optimization Configuration"},{local:"optimization-examples",title:"Optimization examples"}],title:"Optimization"};function Ka(Yo){return Wa(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class es extends Xa{constructor(x){super();Ga(this,x,Ka,Ya,Ba,{})}}export{es as default,Ja as metadata};
