<meta charset="utf-8" /><meta http-equiv="content-security-policy" content=""><meta name="hf:doc:metadata" content="{&quot;local&quot;:&quot;optimum-habana&quot;,&quot;sections&quot;:[{&quot;local&quot;:&quot;what-is-a-habana-processing-unit-hpu&quot;,&quot;title&quot;:&quot;What is a Habana Processing Unit (HPU)?&quot;},{&quot;local&quot;:&quot;install&quot;,&quot;title&quot;:&quot;Install&quot;},{&quot;local&quot;:&quot;validated-models&quot;,&quot;title&quot;:&quot;Validated Models&quot;},{&quot;local&quot;:&quot;gaudi-setup&quot;,&quot;title&quot;:&quot;Gaudi Setup&quot;}],&quot;title&quot;:&quot;Optimum Habana&quot;}" data-svelte="svelte-1phssyn">
	<link rel="modulepreload" href="/docs/optimum.habana/main/en/_app/assets/pages/__layout.svelte-hf-doc-builder.css">
	<link rel="modulepreload" href="/docs/optimum.habana/main/en/_app/start-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/optimum.habana/main/en/_app/chunks/vendor-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/optimum.habana/main/en/_app/chunks/paths-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/optimum.habana/main/en/_app/pages/__layout.svelte-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/optimum.habana/main/en/_app/pages/index.mdx-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/optimum.habana/main/en/_app/chunks/CodeBlock-hf-doc-builder.js"> 






<h1 class="relative group"><a id="optimum-habana" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#optimum-habana"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Optimum Habana
	</span></h1>

<p>ðŸ¤— Optimum Habana is the interface between the ðŸ¤— Transformers library and <a href="https://docs.habana.ai/en/latest/index.html" rel="nofollow">Habanaâ€™s Gaudi processor (HPU)</a>.
It provides a set of tools enabling easy model loading and fine-tuning on single- and multi-HPU settings for different downstream tasks.
The current release focuses on question answering and text classification and enables users to try other models for other tasks with only a few changes.</p>
<h2 class="relative group"><a id="what-is-a-habana-processing-unit-hpu" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#what-is-a-habana-processing-unit-hpu"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>What is a Habana Processing Unit (HPU)?
	</span></h2>

<p>Quote from the Hugging Face <a href="https://huggingface.co/blog/habana" rel="nofollow">blog post</a>:</p>
<blockquote><p>Habana Gaudi training solutions, which power Amazonâ€™s EC2 DL1 instances and Supermicroâ€™s X12 Gaudi AI Training Server, deliver price/performance up to 40% lower than comparable training solutions and enable customers to train more while spending less. The integration of ten 100 Gigabit Ethernet ports onto every Gaudi processor enables system scaling from 1 to thousands of Gaudis with ease and cost-efficiency. Habanaâ€™s SynapseAIÂ® is optimizedâ€”at inceptionâ€”to enable Gaudi performance and usability, supports TensorFlow and PyTorch frameworks, with a focus on computer vision and natural language processing applications.</p></blockquote>
<h2 class="relative group"><a id="install" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#install"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Install
	</span></h2>

To install the latest release of this package:
<p><code>pip install optimum[habana]</code></p>
<p>Optimum Habana is a fast-moving project, and you may want to install it from source:</p>
<p><code>pip install git+https://github.com/huggingface/optimum-habana.git</code></p>
<p>Last but not least, donâ€™t forget to install requirements for every example:</p>
<p><code>cd &lt;example-folder&gt; pip install -r requirements.txt</code></p>
<blockquote><p>Alternatively, you can install the package without pip as follows:</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START -->git <span class="hljs-built_in">clone</span> https://github.com/huggingface/optimum-habana.git
<span class="hljs-built_in">cd</span> optimum-habana
python setup.py install<!-- HTML_TAG_END --></pre></div></blockquote>
<h2 class="relative group"><a id="validated-models" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#validated-models"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Validated Models
	</span></h2>

<p>The following model architectures, tasks and device distributions have been validated for ðŸ¤— Optimum Habana:
|            | Text Classification | Question Answering | Language Modeling  | Summarization      | Translation        | Single Card        | Multi Card         |
|------------|:-------------------:|:------------------:|:------------------:|:------------------:|:-----------------:|:------------------:|:------------------:|
| BERT       | :heavy_check_mark:  | :heavy_check_mark: | âœ—                  | âœ—                  | âœ—                  | :heavy_check_mark: | :heavy_check_mark: |
| RoBERTa    | âœ—                   | :heavy_check_mark: | âœ—                  | âœ—                  | âœ—                  | :heavy_check_mark: | :heavy_check_mark: |
| ALBERT     | âœ—                   | :heavy_check_mark: | âœ—                  | âœ—                  | âœ—                  | :heavy_check_mark: | :heavy_check_mark: |
| DistilBERT | âœ—                   | :heavy_check_mark: | âœ—                  | âœ—                  | âœ—                  | :heavy_check_mark: | :heavy_check_mark: |
| GPT2       | âœ—                   | âœ—                  | :heavy_check_mark: | âœ—                  | âœ—                  | :heavy_check_mark: | :heavy_check_mark: |
| T5         | âœ—                   | âœ—                  | âœ—                  | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: |</p>
<p>Other models and tasks supported by the ðŸ¤— Transformers library may also work. You can refer to this <a href="https://github.com/huggingface/optimum-habana#how-to-use-it" rel="nofollow">section</a> for using them with ðŸ¤— Optimum Habana. Besides, <a href="https://github.com/huggingface/optimum-habana/tree/main/examples" rel="nofollow">this page</a> explains how to modify any <a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch" rel="nofollow">example</a> from the ðŸ¤— Transformers library to make it work with ðŸ¤— Optimum Habana.</p>
<p>If you find any issue while using those, please open an issue or a pull request.</p>
<h2 class="relative group"><a id="gaudi-setup" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#gaudi-setup"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Gaudi Setup
	</span></h2>

<p>Please refer to Habana Gaudiâ€™s official <a href="https://docs.habana.ai/en/latest/Installation_Guide/index.html" rel="nofollow">installation guide</a>.</p>
<blockquote><p>Tests should be run in a Docker container based on Habana Docker images.</p></blockquote>


		<script type="module" data-hydrate="cd35et">
		import { start } from "/docs/optimum.habana/main/en/_app/start-hf-doc-builder.js";
		start({
			target: document.querySelector('[data-hydrate="cd35et"]').parentNode,
			paths: {"base":"/docs/optimum.habana/main/en","assets":"/docs/optimum.habana/main/en"},
			session: {},
			route: false,
			spa: false,
			trailing_slash: "never",
			hydrate: {
				status: 200,
				error: null,
				nodes: [
					import("/docs/optimum.habana/main/en/_app/pages/__layout.svelte-hf-doc-builder.js"),
						import("/docs/optimum.habana/main/en/_app/pages/index.mdx-hf-doc-builder.js")
				],
				params: {}
			}
		});
	</script>
