- sections:
  - local: index
    title: ü§ó Optimum
  - local: installation
    title: Installation
  - local: quicktour
    title: Quick tour
  - local: notebooks
    title: Notebooks
  - sections:
    - local: concept_guides/quantization
      title: Quantization
    title: Conceptual guides
  - sections:
    - local: package_reference/modeling_base
      title: Optimized models
    - local: package_reference/benchmark
      title: Benchmark
    title: Reference
  title: Overview
- sections:
  - local: onnxruntime/overview
    title: Overview
  - local: onnxruntime/quickstart
    title: Quick tour
  - sections:
    - local: onnxruntime/tutorials/overview
      title: Overview
    title: Tutorials
  - sections:
    - local: onnxruntime/usage_guides/pipelines
      title: Inference pipelines
    - local: onnxruntime/usage_guides/models
      title: Models for inference
    - local: onnxruntime/usage_guides/optimization
      title: How to apply graph optimization
    - local: onnxruntime/usage_guides/quantization
      title: How to apply dynamic and static quantization
    - local: onnxruntime/usage_guides/trainer
      title: How to accelerate training
    - local: onnxruntime/usage_guides/gpu
      title: Accelerated inference on NVIDIA GPUs
    title: How-to guides
  - sections:
    - local: onnxruntime/concept_guides/onnx
      title: ONNX ü§ù ONNX Runtime
    title: Conceptual guides
  - sections:
    - local: onnxruntime/package_reference/modeling_ort
      title: ONNX Runtime Models
    - local: onnxruntime/package_reference/configuration
      title: Configuration
    - local: onnxruntime/package_reference/optimization
      title: Optimization
    - local: onnxruntime/package_reference/quantization
      title: Quantization
    - local: onnxruntime/package_reference/trainer
      title: Trainer
    title: Reference
  title: ONNX Runtime
- sections:
  - local: fx/overview
    title: Overview
  - sections:
    - local: fx/tutorials/overview
      title: Overview
    title: Tutorials
  - sections:
    - local: fx/usage_guides/optimization
      title: Optimization
    title: How-to guides
  - sections:
    - local: fx/concept_guides/symbolic_tracer
      title: Symbolic tracer
    title: Conceptual guides
  - sections:
    - local: fx/package_reference/optimization
      title: Optimization
    title: Reference
  title: Torch FX
- sections:
  - local: graphcore/index
    title: ü§ó Optimum Graphcore
  - local: graphcore/quickstart
    title: Quickstart
  - local: graphcore/ipu_config
    title: IPU Configuration
  - local: graphcore/trainer
    title: IPU Trainer
  - local: graphcore/add_support_for_new_model
    title: Add support for an architecutre
  title: Optimum Graphcore
- sections:
  - local: habana/index
    title: ü§ó Optimum Habana
  - local: habana/installation
    title: Installation
  - local: habana/quickstart
    title: Quickstart
  - sections:
    - local: habana/tutorials/accelerate_training
      title: Accelerating Training
    - local: habana/tutorials/pretraining
      title: Pretraining Transformers
    title: Tutorials
  - sections:
    - local: habana/usage_guides/single_hpu
      title: Single-HPU Training
    - local: habana/usage_guides/distributed
      title: Distributed Training
    - local: habana/usage_guides/deepspeed
      title: DeepSpeed
    title: How-To Guides
  - sections:
    - local: habana/concept_guides/hpu
      title: What is a Habana Processing Unit?
    title: Conceptual Guides
  - sections:
    - local: habana/package_reference/trainer
      title: Gaudi Trainer
    - local: habana/package_reference/gaudi_config
      title: Gaudi Configuration
    - local: habana/package_reference/distributed_runner
      title: Distributed Runner
    title: Reference
  title: Optimum Habana
- sections:
  - local: intel/index
    title: ü§ó Optimum Intel
  - sections:
    - local: intel/optimization_inc
      title: Optimization
    - local: intel/distributed_training
      title: Distributed Training
    - local: intel/reference_inc
      title: Reference
    title: Neural Compressor
  - sections:
    - local: intel/inference
      title: Models for inference
    - local: intel/optimization_ov
      title: Optimization
    - local: intel/reference_ov
      title: Reference
    title: OpenVINO
  title: Optimum Intel
