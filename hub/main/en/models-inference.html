<meta charset="utf-8" /><meta http-equiv="content-security-policy" content=""><meta name="hf:doc:metadata" content="{&quot;local&quot;:&quot;inference-api&quot;,&quot;sections&quot;:[{&quot;local&quot;:&quot;what-technology-do-you-use-to-power-the-inference-api&quot;,&quot;title&quot;:&quot;What technology do you use to power the inference API?&quot;},{&quot;local&quot;:&quot;how-can-i-turn-off-the-inference-api-for-my-model&quot;,&quot;title&quot;:&quot;How can I turn off the inference API for my model?&quot;},{&quot;local&quot;:&quot;can-i-send-large-volumes-of-requests-can-i-get-accelerated-apis&quot;,&quot;title&quot;:&quot;Can I send large volumes of requests? Can I get accelerated APIs?&quot;},{&quot;local&quot;:&quot;how-can-i-see-my-usage&quot;,&quot;title&quot;:&quot;How can I see my usage?&quot;},{&quot;local&quot;:&quot;is-there-programmatic-access-to-the-inference-api&quot;,&quot;title&quot;:&quot;Is there programmatic access to the Inference API?&quot;}],&quot;title&quot;:&quot;Inference API&quot;}" data-svelte="svelte-1phssyn">
	<link rel="modulepreload" href="/docs/hub/main/en/_app/assets/pages/__layout.svelte-hf-doc-builder.css">
	<link rel="modulepreload" href="/docs/hub/main/en/_app/start-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/hub/main/en/_app/chunks/vendor-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/hub/main/en/_app/chunks/paths-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/hub/main/en/_app/pages/__layout.svelte-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/hub/main/en/_app/pages/models-inference.mdx-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/hub/main/en/_app/chunks/IconCopyLink-hf-doc-builder.js"> 





<h1 class="relative group"><a id="inference-api" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#inference-api"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Inference API
	</span></h1>

<p>Please refer to <a href="https://huggingface.co/docs/api-inference" rel="nofollow">Inference API Documentation</a> for detailed information.</p>
<h2 class="relative group"><a id="what-technology-do-you-use-to-power-the-inference-api" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#what-technology-do-you-use-to-power-the-inference-api"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>What technology do you use to power the inference API?
	</span></h2>

<p>For ðŸ¤— Transformers models, <a href="https://huggingface.co/transformers/main_classes/pipelines.html" rel="nofollow">Pipelines</a> power the API.</p>
<p>On top of <code>Pipelines</code> and depending on the model type, there are several production optimizations like:</p>
<ul><li>compiling models to optimized intermediary representations (e.g. <a href="https://medium.com/microsoftazure/accelerate-your-nlp-pipelines-using-hugging-face-transformers-and-onnx-runtime-2443578f4333" rel="nofollow">ONNX</a>),</li>
<li>maintaining a Least Recently Used cache, ensuring that the most popular models are always loaded,</li>
<li>scaling the underlying compute infrastructure on the fly depending on the load constraints.</li></ul>
<p>For models from <a href="./models-libraries">other libraries</a>, the API uses <a href="https://www.starlette.io" rel="nofollow">Starlette</a> and runs in <a href="https://github.com/huggingface/api-inference-community/tree/main/docker_images" rel="nofollow">Docker containers</a>. Each library defines the implementation of <a href="https://github.com/huggingface/api-inference-community/tree/main/docker_images/sentence_transformers/app/pipelines" rel="nofollow">different pipelines</a>.</p>
<h2 class="relative group"><a id="how-can-i-turn-off-the-inference-api-for-my-model" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#how-can-i-turn-off-the-inference-api-for-my-model"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>How can I turn off the inference API for my model?
	</span></h2>

<p>Specify <code>inference: false</code> in your model cardâ€™s metadata.</p>
<h2 class="relative group"><a id="can-i-send-large-volumes-of-requests-can-i-get-accelerated-apis" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#can-i-send-large-volumes-of-requests-can-i-get-accelerated-apis"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Can I send large volumes of requests? Can I get accelerated APIs?
	</span></h2>

<p>If you are interested in accelerated inference, higher volumes of requests, or an SLA, please contact us at <code>api-enterprise at huggingface.co</code>.</p>
<h2 class="relative group"><a id="how-can-i-see-my-usage" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#how-can-i-see-my-usage"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>How can I see my usage?
	</span></h2>

<p>You can head to the <a href="https://api-inference.huggingface.co/dashboard/" rel="nofollow">Inference API dashboard</a>. Learn more about it in the <a href="https://huggingface.co/docs/api-inference/usage" rel="nofollow">Inference API documentation</a>.</p>
<h2 class="relative group"><a id="is-there-programmatic-access-to-the-inference-api" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#is-there-programmatic-access-to-the-inference-api"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Is there programmatic access to the Inference API?
	</span></h2>

<p>Yes, the <code>huggingface_hub</code> library has a client wrapper documented <a href="https://huggingface.co/docs/huggingface_hub/how-to-inference" rel="nofollow">here</a>.</p>


		<script type="module" data-hydrate="apeik">
		import { start } from "/docs/hub/main/en/_app/start-hf-doc-builder.js";
		start({
			target: document.querySelector('[data-hydrate="apeik"]').parentNode,
			paths: {"base":"/docs/hub/main/en","assets":"/docs/hub/main/en"},
			session: {},
			route: false,
			spa: false,
			trailing_slash: "never",
			hydrate: {
				status: 200,
				error: null,
				nodes: [
					import("/docs/hub/main/en/_app/pages/__layout.svelte-hf-doc-builder.js"),
						import("/docs/hub/main/en/_app/pages/models-inference.mdx-hf-doc-builder.js")
				],
				params: {}
			}
		});
	</script>
