<meta charset="utf-8" /><meta http-equiv="content-security-policy" content=""><meta name="hf:doc:metadata" content="{&quot;local&quot;:&quot;using-transformers-at-hugging-face&quot;,&quot;sections&quot;:[{&quot;local&quot;:&quot;exploring-transformers-in-the-hub&quot;,&quot;title&quot;:&quot;Exploring ü§ó transformers in the Hub&quot;},{&quot;local&quot;:&quot;using-existing-models&quot;,&quot;title&quot;:&quot;Using existing models&quot;},{&quot;local&quot;:&quot;sharing-your-models&quot;,&quot;title&quot;:&quot;Sharing your models&quot;},{&quot;local&quot;:&quot;additional-resources&quot;,&quot;title&quot;:&quot;Additional resources&quot;}],&quot;title&quot;:&quot;Using ü§ó `transformers` at Hugging Face&quot;}" data-svelte="svelte-1phssyn">
	<link rel="modulepreload" href="/docs/hub/main/en/_app/assets/pages/__layout.svelte-hf-doc-builder.css">
	<link rel="modulepreload" href="/docs/hub/main/en/_app/start-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/hub/main/en/_app/chunks/vendor-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/hub/main/en/_app/chunks/paths-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/hub/main/en/_app/pages/__layout.svelte-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/hub/main/en/_app/pages/transformers.mdx-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/hub/main/en/_app/chunks/IconCopyLink-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/hub/main/en/_app/chunks/CodeBlock-hf-doc-builder.js"> 





<h1 class="relative group"><a id="using-transformers-at-hugging-face" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#using-transformers-at-hugging-face"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Using ü§ó <code>transformers</code> at Hugging Face
	</span></h1>

<p>ü§ó <code>transformers</code> is a library with state-of-the-art Machine Learning for Pytorch, TensorFlow and JAX. It provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio. We are a bit biased, but we really like ü§ó <code>transformers</code>!</p>
<h2 class="relative group"><a id="exploring-transformers-in-the-hub" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#exploring-transformers-in-the-hub"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Exploring ü§ó transformers in the Hub
	</span></h2>

<p>There are over 25,000 <code>transformers</code> models in the Hub which you can find by filtering at the left of <a href="https://huggingface.co/models?library=transformers&sort=downloads" rel="nofollow">the models page</a>. </p>
<p>You can find models for many different tasks:</p>
<ul><li>Extracting the answer from a context (<a href="https://huggingface.co/models?library=transformers&pipeline_tag=question-answering&sort=downloads" rel="nofollow">question-answering</a>).</li>
<li>Creating summaries from a large text (<a href="https://huggingface.co/models?library=transformers&pipeline_tag=summarization&sort=downloads" rel="nofollow">summarization</a>).</li>
<li>Classify text (e.g. as spam or not spam, <a href="https://huggingface.co/models?library=transformers&pipeline_tag=text-classification&sort=downloads" rel="nofollow">text-classification</a>).</li>
<li>Generate a new text with models such as GPT (<a href="https://huggingface.co/models?library=transformers&pipeline_tag=text-generation&sort=downloads" rel="nofollow">text-generation</a>).</li>
<li>Identify parts of speech (verb, subject, etc.) or entities (country, organization, etc.) in a sentence (<a href="https://huggingface.co/models?library=transformers&pipeline_tag=token-classification&sort=downloads" rel="nofollow">token-classification</a>).</li>
<li>Transcribe audio files to text (<a href="https://huggingface.co/models?library=transformers&pipeline_tag=automatic-speech-recognition&sort=downloads" rel="nofollow">automatic-speech-recognition</a>).</li>
<li>Classify the speaker or language in an audio file (<a href="https://huggingface.co/models?library=transformers&pipeline_tag=audio-classification&sort=downloads" rel="nofollow">audio-classification</a>).</li>
<li>Detect objects in an image (<a href="https://huggingface.co/models?library=transformers&pipeline_tag=object-detection&sort=downloads" rel="nofollow">object-detection</a>).</li>
<li>Segment an image (<a href="https://huggingface.co/models?library=transformers&pipeline_tag=image-segmentation&sort=downloads" rel="nofollow">image-segmentation</a>).</li>
<li>Do Reinforcement Learning (<a href="https://huggingface.co/models?library=transformers&pipeline_tag=reinforcement-learning&sort=downloads" rel="nofollow">reinforcement-learning</a>)!</li></ul>
<p>You can try out the models directly in the browser if you want to test them out without downloading them thanks to the in-browser widgets! </p>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/libraries-transformers_widget.png">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/libraries-transformers_widget-dark.png"></div>
<h2 class="relative group"><a id="using-existing-models" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#using-existing-models"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Using existing models
	</span></h2>

<p>All <code>transformer</code> models are a line away from being used! Depending on how you want to use them, you can use the high-level API using the <code>pipeline</code> function or you can use <code>AutoModel</code> for more control.</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START --><span class="hljs-comment"># With pipeline, just specify the task and the model id from the Hub.</span>
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline
pipe = pipeline(<span class="hljs-string">&quot;text-generation&quot;</span>, model=<span class="hljs-string">&quot;distilgpt2&quot;</span>)

<span class="hljs-comment"># If you want more control, you will need to define the tokenizer and model.</span>
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForCausalLM
tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilgpt2&quot;</span>)
model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;distilgpt2&quot;</span>)<!-- HTML_TAG_END --></pre></div>
<p>You can also load a model from a specific version (based on commit hash, tag name, or branch) as follows:</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START -->model = AutoModel.from_pretrained(
    <span class="hljs-string">&quot;julien-c/EsperBERTo-small&quot;</span>, revision=<span class="hljs-string">&quot;v2.0.1&quot;</span>  <span class="hljs-comment"># tag name, or branch name, or commit hash</span>
)<!-- HTML_TAG_END --></pre></div>
<p>If you want to see how to load a specific model, you can click <code>Use in Transformers</code> and you will be given a working snippet that you can load it! If you need further information about the model architecture, you can also click the ‚ÄúRead model documentation‚Äù at the bottom of the snippet.</p>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/libraries-transformers_snippet.png">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/libraries-transformers_snippet-dark.png"></div>
<h2 class="relative group"><a id="sharing-your-models" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#sharing-your-models"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Sharing your models
	</span></h2>

<p>To read all about sharing models with <code>transformers</code>, please head out to the <a href="https://huggingface.co/docs/transformers/model_sharing" rel="nofollow">Share a model</a> guide in the official documentation.</p>
<p>Many classes in <code>transformers</code>, such as the models and tokenizers, have a <code>push_to_hub</code> method that allows to easily upload the files to a repository.</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START --><span class="hljs-comment"># Pushing model to your own account</span>
model.push_to_hub(<span class="hljs-string">&quot;my-awesome-model&quot;</span>)

<span class="hljs-comment"># Pushing your tokenizer</span>
tokenizer.push_to_hub(<span class="hljs-string">&quot;my-awesome-model&quot;</span>)

<span class="hljs-comment"># Pushing all things after training</span>
trainer.push_to_hub()<!-- HTML_TAG_END --></pre></div>
<p>There is much more you can do, so we suggest to review the <a href="https://huggingface.co/docs/transformers/model_sharing" rel="nofollow">Share a model</a> guide.</p>
<h2 class="relative group"><a id="additional-resources" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#additional-resources"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Additional resources
	</span></h2>

<ul><li>Transformers <a href="https://github.com/huggingface/transformers" rel="nofollow">library</a>.</li>
<li>Transformers <a href="https://huggingface.co/docs/transformers/index" rel="nofollow">docs</a>.</li>
<li>Share a model <a href="https://huggingface.co/docs/transformers/model_sharing" rel="nofollow">guide</a>.</li></ul>


		<script type="module" data-hydrate="jv11ms">
		import { start } from "/docs/hub/main/en/_app/start-hf-doc-builder.js";
		start({
			target: document.querySelector('[data-hydrate="jv11ms"]').parentNode,
			paths: {"base":"/docs/hub/main/en","assets":"/docs/hub/main/en"},
			session: {},
			route: false,
			spa: false,
			trailing_slash: "never",
			hydrate: {
				status: 200,
				error: null,
				nodes: [
					import("/docs/hub/main/en/_app/pages/__layout.svelte-hf-doc-builder.js"),
						import("/docs/hub/main/en/_app/pages/transformers.mdx-hf-doc-builder.js")
				],
				params: {}
			}
		});
	</script>
