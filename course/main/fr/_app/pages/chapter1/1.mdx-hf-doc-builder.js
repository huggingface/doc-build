import{S as Bo,i as Ro,s as Uo,e as o,k as c,w as yt,t as a,M as Yo,c as l,d as r,m as d,a as n,x as At,h as s,b as i,N as jo,G as e,g as p,y as Nt,L as Jo,q as $t,o as zt,B as It,v as Ko}from"../../chunks/vendor-hf-doc-builder.js";import{Y as Qo}from"../../chunks/Youtube-hf-doc-builder.js";import{I as cr}from"../../chunks/IconCopyLink-hf-doc-builder.js";function Vo(As){let P,Tt,L,D,ze,K,dr,Ie,mr,St,y,F,Te,Q,fr,Se,hr,Mt,V,Ht,m,vr,W,gr,Er,G,_r,Me,br,wr,C,qr,He,Pr,Lr,O,yr,xe,Ar,Nr,j,$r,ke,zr,Ir,X,De,Tr,Sr,xt,A,B,Fe,Z,Mr,Ge,Hr,kt,_e,xr,Dt,N,ee,Ns,kr,te,$s,Ft,b,f,Dr,Ce,Fr,Gr,Oe,Cr,Or,re,je,jr,Br,Be,Rr,Ur,Re,Yr,Jr,Kr,$,Qr,Ue,Vr,Wr,Ye,Xr,Zr,ea,z,ta,Je,ra,aa,Ke,sa,oa,Gt,be,la,Ct,w,Qe,na,ia,g,ua,ae,pa,ca,se,Ve,da,ma,oe,We,fa,ha,va,I,ga,le,Ea,_a,ne,ba,wa,Ot,R,qa,ie,Pa,La,jt,T,U,Xe,ue,ya,Ze,Aa,Bt,we,Na,Rt,Y,$a,pe,za,Ia,Ut,S,et,Ta,Sa,tt,Ma,Ha,Yt,M,rt,xa,ka,at,Da,Fa,Jt,E,st,Ga,Ca,ot,Oa,ja,ce,lt,Ba,Ra,Kt,de,nt,Ua,Ya,Qt,H,it,Ja,Ka,ut,Qa,Va,Vt,x,pt,Wa,Xa,ct,Za,es,Wt,k,dt,ts,rs,me,mt,as,ss,Xt,_,ft,os,ls,ht,ns,is,fe,vt,us,ps,Zt,qe,cs,er,q,he,ds,gt,ms,fs,hs,ve,vs,Et,gs,Es,_s,_t,bs,tr;return K=new cr({}),Q=new cr({}),V=new Qo({props:{id:"00GKzGyWFEs"}}),Z=new cr({}),ue=new cr({}),{c(){P=o("meta"),Tt=c(),L=o("h1"),D=o("a"),ze=o("span"),yt(K.$$.fragment),dr=c(),Ie=o("span"),mr=a("Introduction"),St=c(),y=o("h2"),F=o("a"),Te=o("span"),yt(Q.$$.fragment),fr=c(),Se=o("span"),hr=a("Bienvenue au cours \u{1F917} !"),Mt=c(),yt(V.$$.fragment),Ht=c(),m=o("p"),vr=a("Ce cours vous apprendra \xE0 utiliser les biblioth\xE8ques de NLP de l\u2019\xE9cosyst\xE8me "),W=o("a"),gr=a("Hugging Face"),Er=a(" : "),G=o("a"),_r=a("\u{1F917} "),Me=o("em"),br=a("Transformers"),wr=a(", "),C=o("a"),qr=a("\u{1F917} "),He=o("em"),Pr=a("Datasets"),Lr=a(", "),O=o("a"),yr=a("\u{1F917} "),xe=o("em"),Ar=a("Tokenizers"),Nr=a(" et "),j=o("a"),$r=a("\u{1F917} "),ke=o("em"),zr=a("Accelerate"),Ir=a(", ainsi que le "),X=o("a"),De=o("em"),Tr=a("Hub"),Sr=a(". C\u2019est totalement gratuit et sans publicit\xE9."),xt=c(),A=o("h2"),B=o("a"),Fe=o("span"),yt(Z.$$.fragment),Mr=c(),Ge=o("span"),Hr=a("\xC0 quoi s'attendre ?"),kt=c(),_e=o("p"),xr=a("Voici un bref aper\xE7u du cours :"),Dt=c(),N=o("div"),ee=o("img"),kr=c(),te=o("img"),Ft=c(),b=o("ul"),f=o("li"),Dr=a("Les chapitres 1 \xE0 4 pr\xE9sentent les principaux concepts de la biblioth\xE8que \u{1F917} "),Ce=o("em"),Fr=a("Transformers"),Gr=a(". \xC0 la fin de ce chapitre, vous serez familier avec le fonctionnement des "),Oe=o("em"),Cr=a("transformers"),Or=a(" et vous saurez comment utiliser un mod\xE8le pr\xE9sent sur le "),re=o("a"),je=o("em"),jr=a("Hub"),Br=a(", le "),Be=o("em"),Rr=a("finetuner"),Ur=a(" sur un jeu de donn\xE9es, et partager vos r\xE9sultats sur le "),Re=o("em"),Yr=a("Hub"),Jr=a(" !"),Kr=c(),$=o("li"),Qr=a("Les chapitres 5 \xE0 8 pr\xE9sentent les bases des librairies \u{1F917} "),Ue=o("em"),Vr=a("Datasets"),Wr=a(" et \u{1F917} "),Ye=o("em"),Xr=a("Tokenizers"),Zr=a(" ainsi qu\u2019une d\xE9couverte des probl\xE8mes classiques de NLP. \xC0 la fin de ce chapitre, vous serez capable de r\xE9soudre les probl\xE8mes de NLP les plus communs par vous-m\xEAme."),ea=c(),z=o("li"),ta=a("Les chapitres 9 \xE0 12 proposent d\u2019aller plus loin et d\u2019explorer comment les "),Je=o("em"),ra=a("transformers"),aa=a(" peuvent \xEAtre utilis\xE9s pour r\xE9soudre des probl\xE8mes de traitement de la parole et de vision par ordinateur. En suivant ces chapitres, vous apprendrez \xE0 construire et \xE0 partager vos mod\xE8les via des d\xE9monstrateurs, et vous serez capable d\u2019optimiser ces mod\xE8les pour des environnements de production. Enfin, vous serez pr\xEAt \xE0 appliquer \u{1F917} "),Ke=o("em"),sa=a("Transformers"),oa=a(" \xE0 (presque) n\u2019importe quel probl\xE8me d\u2019apprentissage automatique !"),Gt=c(),be=o("p"),la=a("Ce cours :"),Ct=c(),w=o("ul"),Qe=o("li"),na=a("requiert un bon niveau en Python,"),ia=c(),g=o("li"),ua=a("se comprend mieux si vous avez d\xE9j\xE0 suivi un cours d\u2019introduction \xE0 l\u2019apprentissage profond comme "),ae=o("a"),pa=a("fast.ai\u2019s"),ca=a(", "),se=o("a"),Ve=o("em"),da=a("Practical Deep Learning for Coders"),ma=a(" ou un des cours d\xE9velopp\xE9s par "),oe=o("a"),We=o("em"),fa=a("DeepLearning.AI"),ha=a(","),va=c(),I=o("li"),ga=a("n\u2019attend pas une connaissance appronfondie de "),le=o("a"),Ea=a("PyTorch"),_a=a(" ou de "),ne=o("a"),ba=a("TensorFlow"),wa=a(", bien qu\u2019\xEAtre familiaris\xE9 avec l\u2019un d\u2019entre eux peut aider."),Ot=c(),R=o("p"),qa=a("Apr\xE8s avoir termin\xE9 ce cours, nous vous recommandons de suivre la "),ie=o("a"),Pa=a("Sp\xE9cialisation en NLP"),La=a(" dispens\xE9e par DeepLearning.AI, qui couvre une grande partie des mod\xE8les traditionnels de NLP comme le Bay\xE9sien na\xEFf et les LSTMs qui sont importants \xE0 conna\xEEtre!"),jt=c(),T=o("h2"),U=o("a"),Xe=o("span"),yt(ue.$$.fragment),ya=c(),Ze=o("span"),Aa=a("Qui sommes-nous ?"),Bt=c(),we=o("p"),Na=a("\xC0 propos des auteurs de ce cours :"),Rt=c(),Y=o("p"),$a=a("*Abubakar Abid** a obtenu son doctorat \xE0 Stanford en apprentissage automatique appliqu\xE9. Pendant son doctorat, il a fond\xE9 "),pe=o("a"),za=a("Gradio"),Ia=a(", une biblioth\xE8que Python open-source qui a \xE9t\xE9 utilis\xE9e pour construire plus de 600 000 d\xE9mos d\u2019apprentissage automatique. Gradio a \xE9t\xE9 rachet\xE9e par Hugging Face, o\xF9 Abubakar occupe d\xE9sormais le poste de responsable de l\u2019\xE9quipe d\u2019apprentissage automatique."),Ut=c(),S=o("p"),et=o("strong"),Ta=a("Matthew Carrigan"),Sa=a(" est ing\xE9nieur en apprentissage machine chez Hugging Face. Il vit \xE0 Dublin en Irlande. Il a travaill\xE9 auparavant comme ing\xE9nieur en apprentissage machine chez Parse.ly et avant cela comme chercheur postdoctoral au Trinity College Dublin. Il ne croit pas que nous arrivions \xE0 l\u2019"),tt=o("em"),Ma=a("AGI"),Ha=a(" en mettant \xE0 l\u2019\xE9chelle les architectures existantes mais a tout de m\xEAme beaucoup d\u2019espoir dans l\u2019immortalit\xE9 des robots."),Yt=c(),M=o("p"),rt=o("strong"),xa=a("Lysandre Debut"),ka=a(" est ing\xE9nieur en apprentissage machine chez Hugging Face et a travaill\xE9 sur la biblioth\xE8que \u{1F917} "),at=o("em"),Da=a("Transformers"),Fa=a(" depuis les premi\xE8res phases de d\xE9veloppement. Son but est de rendre le NLP accessible \xE0 tous en d\xE9veloppant des outils disposant d\u2019une API tr\xE8s simple."),Jt=c(),E=o("p"),st=o("strong"),Ga=a("Sylvain Gugger"),Ca=a(" est ing\xE9nieur recherche chez Hugging Face et un des principaux responsables de la biblioth\xE8que \u{1F917} "),ot=o("em"),Oa=a("Transformers"),ja=a(". Avant cela, il \xE9tait chercheur en en apprentissage machine chez fast.ai et a \xE9crit le livre "),ce=o("a"),lt=o("em"),Ba=a("Deep Learning for Coders with fastai and PyTorch"),Ra=a(" avec Jeremy Howard. Son but est de rendre l\u2019apprentissage profond plus accessible, en d\xE9veloppant et en am\xE9liorant des techniques permettant aux mod\xE8les d\u2019apprendre rapidement sur des ressources limit\xE9es."),Kt=c(),de=o("p"),nt=o("strong"),Ua=a("Dawood Khan"),Ya=a(" est un ing\xE9nieur en apprentissage automatique chez Hugging Face. Il vient de New York et est dipl\xF4m\xE9 de l\u2019Universit\xE9 de New York en informatique. Apr\xE8s avoir travaill\xE9 comme ing\xE9nieur iOS pendant quelques ann\xE9es, Dawood a quitt\xE9 son poste pour cr\xE9er Gradio avec ses cofondateurs. Gradio a finalement \xE9t\xE9 acquis par Hugging Face."),Qt=c(),H=o("p"),it=o("strong"),Ja=a("Merve Noyan"),Ka=a(" est d\xE9veloppeuse "),ut=o("em"),Qa=a("advocate"),Va=a(" chez Hugging Face et travaille \xE0 la cr\xE9ation d\u2019outils et de contenus visant \xE0 d\xE9mocratiser l\u2019apprentissage machine pour tous."),Vt=c(),x=o("p"),pt=o("strong"),Wa=a("Lucile Saulnier"),Xa=a(" est ing\xE9nieure en apprentissage machine chez Hugging Face et travaille au d\xE9veloppement et \xE0 l\u2019impl\xE9mentation de nombreux outils "),ct=o("em"),Za=a("open source"),es=a(". Elle est \xE9galement activement impliqu\xE9e dans de nombreux projets de recherche dans le domaine du NLP comme l\u2019entra\xEEnement collaboratif de mod\xE8les et le projet BigScience."),Wt=c(),k=o("p"),dt=o("strong"),ts=a("Lewis Tunstall"),rs=a(" est ing\xE9nieur en apprentissage machine chez Hugging Face et d\xE9vou\xE9 au d\xE9veloppement d\u2019outils open source avec la volont\xE9 de les rendre accessibles \xE0 une communaut\xE9 plus large. Il est \xE9galement co-auteur du livre "),me=o("a"),mt=o("em"),as=a("Natural Language Processing with Transformers"),ss=a("."),Xt=c(),_=o("p"),ft=o("strong"),os=a("Leandro von Werra"),ls=a(" est ing\xE9nieur en apprentissage machine dans l\u2019\xE9quipe "),ht=o("em"),ns=a("open source"),is=a(" d\u2019Hugging Face et \xE9galement co-auteur du livre "),fe=o("a"),vt=o("em"),us=a("Natural Language Processing with Transformers"),ps=a(". Il a plusieurs ann\xE9es d\u2019exp\xE9rience dans l\u2019industrie o\xF9 il a pu d\xE9ployer des projets de NLP en production et travailler sur toutes les \xE9tapes clefs du d\xE9ploiement."),Zt=c(),qe=o("p"),cs=a("\xCAtes-vous pr\xEAt \xE0 commencer ? Dans ce chapitre, vous apprendrez :"),er=c(),q=o("ul"),he=o("li"),ds=a("\xE0 utiliser la fonction "),gt=o("code"),ms=a("pipeline()"),fs=a(" pour r\xE9soudre des probl\xE8mes de NLP comme la g\xE9n\xE9ration de texte et la classification,"),hs=c(),ve=o("li"),vs=a("l\u2019architecture d\u2019un "),Et=o("em"),gs=a("transformer"),Es=a(","),_s=c(),_t=o("li"),bs=a("comment faire la distinction entre les diff\xE9rentes architectures d\u2019encodeur, de d\xE9codeur et d\u2019encodeur-d\xE9codeur ainsi que leurs diff\xE9rents cas d\u2019usage."),this.h()},l(t){const u=Yo('[data-svelte="svelte-1phssyn"]',document.head);P=l(u,"META",{name:!0,content:!0}),u.forEach(r),Tt=d(t),L=l(t,"H1",{class:!0});var rr=n(L);D=l(rr,"A",{id:!0,class:!0,href:!0});var zs=n(D);ze=l(zs,"SPAN",{});var Is=n(ze);At(K.$$.fragment,Is),Is.forEach(r),zs.forEach(r),dr=d(rr),Ie=l(rr,"SPAN",{});var Ts=n(Ie);mr=s(Ts,"Introduction"),Ts.forEach(r),rr.forEach(r),St=d(t),y=l(t,"H2",{class:!0});var ar=n(y);F=l(ar,"A",{id:!0,class:!0,href:!0});var Ss=n(F);Te=l(Ss,"SPAN",{});var Ms=n(Te);At(Q.$$.fragment,Ms),Ms.forEach(r),Ss.forEach(r),fr=d(ar),Se=l(ar,"SPAN",{});var Hs=n(Se);hr=s(Hs,"Bienvenue au cours \u{1F917} !"),Hs.forEach(r),ar.forEach(r),Mt=d(t),At(V.$$.fragment,t),Ht=d(t),m=l(t,"P",{});var h=n(m);vr=s(h,"Ce cours vous apprendra \xE0 utiliser les biblioth\xE8ques de NLP de l\u2019\xE9cosyst\xE8me "),W=l(h,"A",{href:!0,rel:!0});var xs=n(W);gr=s(xs,"Hugging Face"),xs.forEach(r),Er=s(h," : "),G=l(h,"A",{href:!0,rel:!0});var ws=n(G);_r=s(ws,"\u{1F917} "),Me=l(ws,"EM",{});var ks=n(Me);br=s(ks,"Transformers"),ks.forEach(r),ws.forEach(r),wr=s(h,", "),C=l(h,"A",{href:!0,rel:!0});var qs=n(C);qr=s(qs,"\u{1F917} "),He=l(qs,"EM",{});var Ds=n(He);Pr=s(Ds,"Datasets"),Ds.forEach(r),qs.forEach(r),Lr=s(h,", "),O=l(h,"A",{href:!0,rel:!0});var Ps=n(O);yr=s(Ps,"\u{1F917} "),xe=l(Ps,"EM",{});var Fs=n(xe);Ar=s(Fs,"Tokenizers"),Fs.forEach(r),Ps.forEach(r),Nr=s(h," et "),j=l(h,"A",{href:!0,rel:!0});var Ls=n(j);$r=s(Ls,"\u{1F917} "),ke=l(Ls,"EM",{});var Gs=n(ke);zr=s(Gs,"Accelerate"),Gs.forEach(r),Ls.forEach(r),Ir=s(h,", ainsi que le "),X=l(h,"A",{href:!0,rel:!0});var Cs=n(X);De=l(Cs,"EM",{});var Os=n(De);Tr=s(Os,"Hub"),Os.forEach(r),Cs.forEach(r),Sr=s(h,". C\u2019est totalement gratuit et sans publicit\xE9."),h.forEach(r),xt=d(t),A=l(t,"H2",{class:!0});var sr=n(A);B=l(sr,"A",{id:!0,class:!0,href:!0});var js=n(B);Fe=l(js,"SPAN",{});var Bs=n(Fe);At(Z.$$.fragment,Bs),Bs.forEach(r),js.forEach(r),Mr=d(sr),Ge=l(sr,"SPAN",{});var Rs=n(Ge);Hr=s(Rs,"\xC0 quoi s'attendre ?"),Rs.forEach(r),sr.forEach(r),kt=d(t),_e=l(t,"P",{});var Us=n(_e);xr=s(Us,"Voici un bref aper\xE7u du cours :"),Us.forEach(r),Dt=d(t),N=l(t,"DIV",{class:!0});var or=n(N);ee=l(or,"IMG",{class:!0,src:!0,alt:!0}),kr=d(or),te=l(or,"IMG",{class:!0,src:!0,alt:!0}),or.forEach(r),Ft=d(t),b=l(t,"UL",{});var Pe=n(b);f=l(Pe,"LI",{});var v=n(f);Dr=s(v,"Les chapitres 1 \xE0 4 pr\xE9sentent les principaux concepts de la biblioth\xE8que \u{1F917} "),Ce=l(v,"EM",{});var Ys=n(Ce);Fr=s(Ys,"Transformers"),Ys.forEach(r),Gr=s(v,". \xC0 la fin de ce chapitre, vous serez familier avec le fonctionnement des "),Oe=l(v,"EM",{});var Js=n(Oe);Cr=s(Js,"transformers"),Js.forEach(r),Or=s(v," et vous saurez comment utiliser un mod\xE8le pr\xE9sent sur le "),re=l(v,"A",{href:!0,rel:!0});var Ks=n(re);je=l(Ks,"EM",{});var Qs=n(je);jr=s(Qs,"Hub"),Qs.forEach(r),Ks.forEach(r),Br=s(v,", le "),Be=l(v,"EM",{});var Vs=n(Be);Rr=s(Vs,"finetuner"),Vs.forEach(r),Ur=s(v," sur un jeu de donn\xE9es, et partager vos r\xE9sultats sur le "),Re=l(v,"EM",{});var Ws=n(Re);Yr=s(Ws,"Hub"),Ws.forEach(r),Jr=s(v," !"),v.forEach(r),Kr=d(Pe),$=l(Pe,"LI",{});var Le=n($);Qr=s(Le,"Les chapitres 5 \xE0 8 pr\xE9sentent les bases des librairies \u{1F917} "),Ue=l(Le,"EM",{});var Xs=n(Ue);Vr=s(Xs,"Datasets"),Xs.forEach(r),Wr=s(Le," et \u{1F917} "),Ye=l(Le,"EM",{});var Zs=n(Ye);Xr=s(Zs,"Tokenizers"),Zs.forEach(r),Zr=s(Le," ainsi qu\u2019une d\xE9couverte des probl\xE8mes classiques de NLP. \xC0 la fin de ce chapitre, vous serez capable de r\xE9soudre les probl\xE8mes de NLP les plus communs par vous-m\xEAme."),Le.forEach(r),ea=d(Pe),z=l(Pe,"LI",{});var ye=n(z);ta=s(ye,"Les chapitres 9 \xE0 12 proposent d\u2019aller plus loin et d\u2019explorer comment les "),Je=l(ye,"EM",{});var eo=n(Je);ra=s(eo,"transformers"),eo.forEach(r),aa=s(ye," peuvent \xEAtre utilis\xE9s pour r\xE9soudre des probl\xE8mes de traitement de la parole et de vision par ordinateur. En suivant ces chapitres, vous apprendrez \xE0 construire et \xE0 partager vos mod\xE8les via des d\xE9monstrateurs, et vous serez capable d\u2019optimiser ces mod\xE8les pour des environnements de production. Enfin, vous serez pr\xEAt \xE0 appliquer \u{1F917} "),Ke=l(ye,"EM",{});var to=n(Ke);sa=s(to,"Transformers"),to.forEach(r),oa=s(ye," \xE0 (presque) n\u2019importe quel probl\xE8me d\u2019apprentissage automatique !"),ye.forEach(r),Pe.forEach(r),Gt=d(t),be=l(t,"P",{});var ro=n(be);la=s(ro,"Ce cours :"),ro.forEach(r),Ct=d(t),w=l(t,"UL",{});var Ae=n(w);Qe=l(Ae,"LI",{});var ao=n(Qe);na=s(ao,"requiert un bon niveau en Python,"),ao.forEach(r),ia=d(Ae),g=l(Ae,"LI",{});var J=n(g);ua=s(J,"se comprend mieux si vous avez d\xE9j\xE0 suivi un cours d\u2019introduction \xE0 l\u2019apprentissage profond comme "),ae=l(J,"A",{href:!0,rel:!0});var so=n(ae);pa=s(so,"fast.ai\u2019s"),so.forEach(r),ca=s(J,", "),se=l(J,"A",{href:!0,rel:!0});var oo=n(se);Ve=l(oo,"EM",{});var lo=n(Ve);da=s(lo,"Practical Deep Learning for Coders"),lo.forEach(r),oo.forEach(r),ma=s(J," ou un des cours d\xE9velopp\xE9s par "),oe=l(J,"A",{href:!0,rel:!0});var no=n(oe);We=l(no,"EM",{});var io=n(We);fa=s(io,"DeepLearning.AI"),io.forEach(r),no.forEach(r),ha=s(J,","),J.forEach(r),va=d(Ae),I=l(Ae,"LI",{});var Ne=n(I);ga=s(Ne,"n\u2019attend pas une connaissance appronfondie de "),le=l(Ne,"A",{href:!0,rel:!0});var uo=n(le);Ea=s(uo,"PyTorch"),uo.forEach(r),_a=s(Ne," ou de "),ne=l(Ne,"A",{href:!0,rel:!0});var po=n(ne);ba=s(po,"TensorFlow"),po.forEach(r),wa=s(Ne,", bien qu\u2019\xEAtre familiaris\xE9 avec l\u2019un d\u2019entre eux peut aider."),Ne.forEach(r),Ae.forEach(r),Ot=d(t),R=l(t,"P",{});var lr=n(R);qa=s(lr,"Apr\xE8s avoir termin\xE9 ce cours, nous vous recommandons de suivre la "),ie=l(lr,"A",{href:!0,rel:!0});var co=n(ie);Pa=s(co,"Sp\xE9cialisation en NLP"),co.forEach(r),La=s(lr," dispens\xE9e par DeepLearning.AI, qui couvre une grande partie des mod\xE8les traditionnels de NLP comme le Bay\xE9sien na\xEFf et les LSTMs qui sont importants \xE0 conna\xEEtre!"),lr.forEach(r),jt=d(t),T=l(t,"H2",{class:!0});var nr=n(T);U=l(nr,"A",{id:!0,class:!0,href:!0});var mo=n(U);Xe=l(mo,"SPAN",{});var fo=n(Xe);At(ue.$$.fragment,fo),fo.forEach(r),mo.forEach(r),ya=d(nr),Ze=l(nr,"SPAN",{});var ho=n(Ze);Aa=s(ho,"Qui sommes-nous ?"),ho.forEach(r),nr.forEach(r),Bt=d(t),we=l(t,"P",{});var vo=n(we);Na=s(vo,"\xC0 propos des auteurs de ce cours :"),vo.forEach(r),Rt=d(t),Y=l(t,"P",{});var ir=n(Y);$a=s(ir,"*Abubakar Abid** a obtenu son doctorat \xE0 Stanford en apprentissage automatique appliqu\xE9. Pendant son doctorat, il a fond\xE9 "),pe=l(ir,"A",{href:!0,rel:!0});var go=n(pe);za=s(go,"Gradio"),go.forEach(r),Ia=s(ir,", une biblioth\xE8que Python open-source qui a \xE9t\xE9 utilis\xE9e pour construire plus de 600 000 d\xE9mos d\u2019apprentissage automatique. Gradio a \xE9t\xE9 rachet\xE9e par Hugging Face, o\xF9 Abubakar occupe d\xE9sormais le poste de responsable de l\u2019\xE9quipe d\u2019apprentissage automatique."),ir.forEach(r),Ut=d(t),S=l(t,"P",{});var bt=n(S);et=l(bt,"STRONG",{});var Eo=n(et);Ta=s(Eo,"Matthew Carrigan"),Eo.forEach(r),Sa=s(bt," est ing\xE9nieur en apprentissage machine chez Hugging Face. Il vit \xE0 Dublin en Irlande. Il a travaill\xE9 auparavant comme ing\xE9nieur en apprentissage machine chez Parse.ly et avant cela comme chercheur postdoctoral au Trinity College Dublin. Il ne croit pas que nous arrivions \xE0 l\u2019"),tt=l(bt,"EM",{});var _o=n(tt);Ma=s(_o,"AGI"),_o.forEach(r),Ha=s(bt," en mettant \xE0 l\u2019\xE9chelle les architectures existantes mais a tout de m\xEAme beaucoup d\u2019espoir dans l\u2019immortalit\xE9 des robots."),bt.forEach(r),Yt=d(t),M=l(t,"P",{});var wt=n(M);rt=l(wt,"STRONG",{});var bo=n(rt);xa=s(bo,"Lysandre Debut"),bo.forEach(r),ka=s(wt," est ing\xE9nieur en apprentissage machine chez Hugging Face et a travaill\xE9 sur la biblioth\xE8que \u{1F917} "),at=l(wt,"EM",{});var wo=n(at);Da=s(wo,"Transformers"),wo.forEach(r),Fa=s(wt," depuis les premi\xE8res phases de d\xE9veloppement. Son but est de rendre le NLP accessible \xE0 tous en d\xE9veloppant des outils disposant d\u2019une API tr\xE8s simple."),wt.forEach(r),Jt=d(t),E=l(t,"P",{});var ge=n(E);st=l(ge,"STRONG",{});var qo=n(st);Ga=s(qo,"Sylvain Gugger"),qo.forEach(r),Ca=s(ge," est ing\xE9nieur recherche chez Hugging Face et un des principaux responsables de la biblioth\xE8que \u{1F917} "),ot=l(ge,"EM",{});var Po=n(ot);Oa=s(Po,"Transformers"),Po.forEach(r),ja=s(ge,". Avant cela, il \xE9tait chercheur en en apprentissage machine chez fast.ai et a \xE9crit le livre "),ce=l(ge,"A",{href:!0,rel:!0});var Lo=n(ce);lt=l(Lo,"EM",{});var yo=n(lt);Ba=s(yo,"Deep Learning for Coders with fastai and PyTorch"),yo.forEach(r),Lo.forEach(r),Ra=s(ge," avec Jeremy Howard. Son but est de rendre l\u2019apprentissage profond plus accessible, en d\xE9veloppant et en am\xE9liorant des techniques permettant aux mod\xE8les d\u2019apprendre rapidement sur des ressources limit\xE9es."),ge.forEach(r),Kt=d(t),de=l(t,"P",{});var ys=n(de);nt=l(ys,"STRONG",{});var Ao=n(nt);Ua=s(Ao,"Dawood Khan"),Ao.forEach(r),Ya=s(ys," est un ing\xE9nieur en apprentissage automatique chez Hugging Face. Il vient de New York et est dipl\xF4m\xE9 de l\u2019Universit\xE9 de New York en informatique. Apr\xE8s avoir travaill\xE9 comme ing\xE9nieur iOS pendant quelques ann\xE9es, Dawood a quitt\xE9 son poste pour cr\xE9er Gradio avec ses cofondateurs. Gradio a finalement \xE9t\xE9 acquis par Hugging Face."),ys.forEach(r),Qt=d(t),H=l(t,"P",{});var qt=n(H);it=l(qt,"STRONG",{});var No=n(it);Ja=s(No,"Merve Noyan"),No.forEach(r),Ka=s(qt," est d\xE9veloppeuse "),ut=l(qt,"EM",{});var $o=n(ut);Qa=s($o,"advocate"),$o.forEach(r),Va=s(qt," chez Hugging Face et travaille \xE0 la cr\xE9ation d\u2019outils et de contenus visant \xE0 d\xE9mocratiser l\u2019apprentissage machine pour tous."),qt.forEach(r),Vt=d(t),x=l(t,"P",{});var Pt=n(x);pt=l(Pt,"STRONG",{});var zo=n(pt);Wa=s(zo,"Lucile Saulnier"),zo.forEach(r),Xa=s(Pt," est ing\xE9nieure en apprentissage machine chez Hugging Face et travaille au d\xE9veloppement et \xE0 l\u2019impl\xE9mentation de nombreux outils "),ct=l(Pt,"EM",{});var Io=n(ct);Za=s(Io,"open source"),Io.forEach(r),es=s(Pt,". Elle est \xE9galement activement impliqu\xE9e dans de nombreux projets de recherche dans le domaine du NLP comme l\u2019entra\xEEnement collaboratif de mod\xE8les et le projet BigScience."),Pt.forEach(r),Wt=d(t),k=l(t,"P",{});var Lt=n(k);dt=l(Lt,"STRONG",{});var To=n(dt);ts=s(To,"Lewis Tunstall"),To.forEach(r),rs=s(Lt," est ing\xE9nieur en apprentissage machine chez Hugging Face et d\xE9vou\xE9 au d\xE9veloppement d\u2019outils open source avec la volont\xE9 de les rendre accessibles \xE0 une communaut\xE9 plus large. Il est \xE9galement co-auteur du livre "),me=l(Lt,"A",{href:!0,rel:!0});var So=n(me);mt=l(So,"EM",{});var Mo=n(mt);as=s(Mo,"Natural Language Processing with Transformers"),Mo.forEach(r),So.forEach(r),ss=s(Lt,"."),Lt.forEach(r),Xt=d(t),_=l(t,"P",{});var Ee=n(_);ft=l(Ee,"STRONG",{});var Ho=n(ft);os=s(Ho,"Leandro von Werra"),Ho.forEach(r),ls=s(Ee," est ing\xE9nieur en apprentissage machine dans l\u2019\xE9quipe "),ht=l(Ee,"EM",{});var xo=n(ht);ns=s(xo,"open source"),xo.forEach(r),is=s(Ee," d\u2019Hugging Face et \xE9galement co-auteur du livre "),fe=l(Ee,"A",{href:!0,rel:!0});var ko=n(fe);vt=l(ko,"EM",{});var Do=n(vt);us=s(Do,"Natural Language Processing with Transformers"),Do.forEach(r),ko.forEach(r),ps=s(Ee,". Il a plusieurs ann\xE9es d\u2019exp\xE9rience dans l\u2019industrie o\xF9 il a pu d\xE9ployer des projets de NLP en production et travailler sur toutes les \xE9tapes clefs du d\xE9ploiement."),Ee.forEach(r),Zt=d(t),qe=l(t,"P",{});var Fo=n(qe);cs=s(Fo,"\xCAtes-vous pr\xEAt \xE0 commencer ? Dans ce chapitre, vous apprendrez :"),Fo.forEach(r),er=d(t),q=l(t,"UL",{});var $e=n(q);he=l($e,"LI",{});var ur=n(he);ds=s(ur,"\xE0 utiliser la fonction "),gt=l(ur,"CODE",{});var Go=n(gt);ms=s(Go,"pipeline()"),Go.forEach(r),fs=s(ur," pour r\xE9soudre des probl\xE8mes de NLP comme la g\xE9n\xE9ration de texte et la classification,"),ur.forEach(r),hs=d($e),ve=l($e,"LI",{});var pr=n(ve);vs=s(pr,"l\u2019architecture d\u2019un "),Et=l(pr,"EM",{});var Co=n(Et);gs=s(Co,"transformer"),Co.forEach(r),Es=s(pr,","),pr.forEach(r),_s=d($e),_t=l($e,"LI",{});var Oo=n(_t);bs=s(Oo,"comment faire la distinction entre les diff\xE9rentes architectures d\u2019encodeur, de d\xE9codeur et d\u2019encodeur-d\xE9codeur ainsi que leurs diff\xE9rents cas d\u2019usage."),Oo.forEach(r),$e.forEach(r),this.h()},h(){i(P,"name","hf:doc:metadata"),i(P,"content",JSON.stringify(Wo)),i(D,"id","introduction"),i(D,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(D,"href","#introduction"),i(L,"class","relative group"),i(F,"id","bienvenue-au-cours"),i(F,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(F,"href","#bienvenue-au-cours"),i(y,"class","relative group"),i(W,"href","https://huggingface.co/"),i(W,"rel","nofollow"),i(G,"href","https://github.com/huggingface/transformers"),i(G,"rel","nofollow"),i(C,"href","https://github.com/huggingface/datasets"),i(C,"rel","nofollow"),i(O,"href","https://github.com/huggingface/tokenizers"),i(O,"rel","nofollow"),i(j,"href","https://github.com/huggingface/accelerate"),i(j,"rel","nofollow"),i(X,"href","https://huggingface.co/models"),i(X,"rel","nofollow"),i(B,"id","quoi-sattendre"),i(B,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(B,"href","#quoi-sattendre"),i(A,"class","relative group"),i(ee,"class","block dark:hidden"),jo(ee.src,Ns="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary.svg")||i(ee,"src",Ns),i(ee,"alt","Bref aper\xE7u du contenu du cours."),i(te,"class","hidden dark:block"),jo(te.src,$s="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary-dark.svg")||i(te,"src",$s),i(te,"alt","Bref aper\xE7u des diff\xE9rents chapitres du cours."),i(N,"class","flex justify-center"),i(re,"href","https://huggingface.co/models"),i(re,"rel","nofollow"),i(ae,"href","https://www.fast.ai/"),i(ae,"rel","nofollow"),i(se,"href","https://course.fast.ai/"),i(se,"rel","nofollow"),i(oe,"href","https://www.deeplearning.ai/"),i(oe,"rel","nofollow"),i(le,"href","https://pytorch.org/"),i(le,"rel","nofollow"),i(ne,"href","https://www.tensorflow.org/"),i(ne,"rel","nofollow"),i(ie,"href","https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearning-ai&utm_medium=institutions&utm_campaign=20211011-nlp-2-hugging_face-page-nlp-refresh"),i(ie,"rel","nofollow"),i(U,"id","qui-sommesnous"),i(U,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(U,"href","#qui-sommesnous"),i(T,"class","relative group"),i(pe,"href","https://github.com/gradio-app/gradio"),i(pe,"rel","nofollow"),i(ce,"href","https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/"),i(ce,"rel","nofollow"),i(me,"href","https://www.oreilly.com/library/view/natural-language-processing/9781098103231/"),i(me,"rel","nofollow"),i(fe,"href","https://www.oreilly.com/library/view/natural-language-processing/9781098103231/"),i(fe,"rel","nofollow")},m(t,u){e(document.head,P),p(t,Tt,u),p(t,L,u),e(L,D),e(D,ze),Nt(K,ze,null),e(L,dr),e(L,Ie),e(Ie,mr),p(t,St,u),p(t,y,u),e(y,F),e(F,Te),Nt(Q,Te,null),e(y,fr),e(y,Se),e(Se,hr),p(t,Mt,u),Nt(V,t,u),p(t,Ht,u),p(t,m,u),e(m,vr),e(m,W),e(W,gr),e(m,Er),e(m,G),e(G,_r),e(G,Me),e(Me,br),e(m,wr),e(m,C),e(C,qr),e(C,He),e(He,Pr),e(m,Lr),e(m,O),e(O,yr),e(O,xe),e(xe,Ar),e(m,Nr),e(m,j),e(j,$r),e(j,ke),e(ke,zr),e(m,Ir),e(m,X),e(X,De),e(De,Tr),e(m,Sr),p(t,xt,u),p(t,A,u),e(A,B),e(B,Fe),Nt(Z,Fe,null),e(A,Mr),e(A,Ge),e(Ge,Hr),p(t,kt,u),p(t,_e,u),e(_e,xr),p(t,Dt,u),p(t,N,u),e(N,ee),e(N,kr),e(N,te),p(t,Ft,u),p(t,b,u),e(b,f),e(f,Dr),e(f,Ce),e(Ce,Fr),e(f,Gr),e(f,Oe),e(Oe,Cr),e(f,Or),e(f,re),e(re,je),e(je,jr),e(f,Br),e(f,Be),e(Be,Rr),e(f,Ur),e(f,Re),e(Re,Yr),e(f,Jr),e(b,Kr),e(b,$),e($,Qr),e($,Ue),e(Ue,Vr),e($,Wr),e($,Ye),e(Ye,Xr),e($,Zr),e(b,ea),e(b,z),e(z,ta),e(z,Je),e(Je,ra),e(z,aa),e(z,Ke),e(Ke,sa),e(z,oa),p(t,Gt,u),p(t,be,u),e(be,la),p(t,Ct,u),p(t,w,u),e(w,Qe),e(Qe,na),e(w,ia),e(w,g),e(g,ua),e(g,ae),e(ae,pa),e(g,ca),e(g,se),e(se,Ve),e(Ve,da),e(g,ma),e(g,oe),e(oe,We),e(We,fa),e(g,ha),e(w,va),e(w,I),e(I,ga),e(I,le),e(le,Ea),e(I,_a),e(I,ne),e(ne,ba),e(I,wa),p(t,Ot,u),p(t,R,u),e(R,qa),e(R,ie),e(ie,Pa),e(R,La),p(t,jt,u),p(t,T,u),e(T,U),e(U,Xe),Nt(ue,Xe,null),e(T,ya),e(T,Ze),e(Ze,Aa),p(t,Bt,u),p(t,we,u),e(we,Na),p(t,Rt,u),p(t,Y,u),e(Y,$a),e(Y,pe),e(pe,za),e(Y,Ia),p(t,Ut,u),p(t,S,u),e(S,et),e(et,Ta),e(S,Sa),e(S,tt),e(tt,Ma),e(S,Ha),p(t,Yt,u),p(t,M,u),e(M,rt),e(rt,xa),e(M,ka),e(M,at),e(at,Da),e(M,Fa),p(t,Jt,u),p(t,E,u),e(E,st),e(st,Ga),e(E,Ca),e(E,ot),e(ot,Oa),e(E,ja),e(E,ce),e(ce,lt),e(lt,Ba),e(E,Ra),p(t,Kt,u),p(t,de,u),e(de,nt),e(nt,Ua),e(de,Ya),p(t,Qt,u),p(t,H,u),e(H,it),e(it,Ja),e(H,Ka),e(H,ut),e(ut,Qa),e(H,Va),p(t,Vt,u),p(t,x,u),e(x,pt),e(pt,Wa),e(x,Xa),e(x,ct),e(ct,Za),e(x,es),p(t,Wt,u),p(t,k,u),e(k,dt),e(dt,ts),e(k,rs),e(k,me),e(me,mt),e(mt,as),e(k,ss),p(t,Xt,u),p(t,_,u),e(_,ft),e(ft,os),e(_,ls),e(_,ht),e(ht,ns),e(_,is),e(_,fe),e(fe,vt),e(vt,us),e(_,ps),p(t,Zt,u),p(t,qe,u),e(qe,cs),p(t,er,u),p(t,q,u),e(q,he),e(he,ds),e(he,gt),e(gt,ms),e(he,fs),e(q,hs),e(q,ve),e(ve,vs),e(ve,Et),e(Et,gs),e(ve,Es),e(q,_s),e(q,_t),e(_t,bs),tr=!0},p:Jo,i(t){tr||($t(K.$$.fragment,t),$t(Q.$$.fragment,t),$t(V.$$.fragment,t),$t(Z.$$.fragment,t),$t(ue.$$.fragment,t),tr=!0)},o(t){zt(K.$$.fragment,t),zt(Q.$$.fragment,t),zt(V.$$.fragment,t),zt(Z.$$.fragment,t),zt(ue.$$.fragment,t),tr=!1},d(t){r(P),t&&r(Tt),t&&r(L),It(K),t&&r(St),t&&r(y),It(Q),t&&r(Mt),It(V,t),t&&r(Ht),t&&r(m),t&&r(xt),t&&r(A),It(Z),t&&r(kt),t&&r(_e),t&&r(Dt),t&&r(N),t&&r(Ft),t&&r(b),t&&r(Gt),t&&r(be),t&&r(Ct),t&&r(w),t&&r(Ot),t&&r(R),t&&r(jt),t&&r(T),It(ue),t&&r(Bt),t&&r(we),t&&r(Rt),t&&r(Y),t&&r(Ut),t&&r(S),t&&r(Yt),t&&r(M),t&&r(Jt),t&&r(E),t&&r(Kt),t&&r(de),t&&r(Qt),t&&r(H),t&&r(Vt),t&&r(x),t&&r(Wt),t&&r(k),t&&r(Xt),t&&r(_),t&&r(Zt),t&&r(qe),t&&r(er),t&&r(q)}}}const Wo={local:"introduction",sections:[{local:"bienvenue-au-cours",title:"Bienvenue au cours \u{1F917} !"},{local:"quoi-sattendre",title:"\xC0 quoi s'attendre ?"},{local:"qui-sommesnous",title:"Qui sommes-nous ?"}],title:"Introduction"};function Xo(As){return Ko(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class rl extends Bo{constructor(P){super();Ro(this,P,Xo,Vo,Uo,{})}}export{rl as default,Wo as metadata};
