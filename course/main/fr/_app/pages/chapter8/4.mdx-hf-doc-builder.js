import{S as db,i as cb,s as mb,e as l,k as p,w as c,t as a,M as fb,c as i,d as s,m as d,x as m,a as u,h as n,b as q,G as t,g as o,y as f,q as v,o as h,B as _,v as vb}from"../../chunks/vendor-hf-doc-builder.js";import{T as Ht}from"../../chunks/Tip-hf-doc-builder.js";import{Y as hb}from"../../chunks/Youtube-hf-doc-builder.js";import{I as M}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as $}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as _b}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as bb}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function qb(P){let b,E,g,j,y;return{c(){b=l("p"),E=a("\u270F\uFE0F "),g=l("em"),j=a("A votre tour !"),y=a(" V\xE9rifiez que tout semble correct avec le deuxi\xE8me \xE9l\xE9ment du jeu de donn\xE9es d\u2019entra\xEEnement.")},l(k){b=i(k,"P",{});var z=u(b);E=n(z,"\u270F\uFE0F "),g=i(z,"EM",{});var w=u(g);j=n(w,"A votre tour !"),w.forEach(s),y=n(z," V\xE9rifiez que tout semble correct avec le deuxi\xE8me \xE9l\xE9ment du jeu de donn\xE9es d\u2019entra\xEEnement."),z.forEach(s)},m(k,z){o(k,b,z),t(b,E),t(b,g),t(g,j),t(b,y)},d(k){k&&s(b)}}}function $b(P){let b,E,g,j,y;return{c(){b=l("p"),E=a("Dans la prochaine partie du cours, nous examinerons des techniques plus avanc\xE9es qui peuvent vous aider \xE0 r\xE9duire votre empreinte m\xE9moire et vous permettre de "),g=l("i"),j=a("finetuner"),y=a(" les plus grands mod\xE8les.")},l(k){b=i(k,"P",{});var z=u(b);E=n(z,"Dans la prochaine partie du cours, nous examinerons des techniques plus avanc\xE9es qui peuvent vous aider \xE0 r\xE9duire votre empreinte m\xE9moire et vous permettre de "),g=i(z,"I",{});var w=u(g);j=n(w,"finetuner"),w.forEach(s),y=n(z," les plus grands mod\xE8les."),z.forEach(s)},m(k,z){o(k,b,z),t(b,E),t(b,g),t(g,j),t(b,y)},d(k){k&&s(b)}}}function gb(P){let b,E,g,j,y,k,z,w;return{c(){b=l("p"),E=a("\u{1F4A1} Vous devriez toujours vous assurer que vous pouvez ex\xE9cuter "),g=l("code"),j=a("trainer.evaluate()"),y=a(" avant de lancer "),k=l("code"),z=a("trainer.train()"),w=a(", pour \xE9viter de gaspiller beaucoup de ressources de calcul avant de tomber sur une erreur.")},l(S){b=i(S,"P",{});var x=u(b);E=n(x,"\u{1F4A1} Vous devriez toujours vous assurer que vous pouvez ex\xE9cuter "),g=i(x,"CODE",{});var Z=u(g);j=n(Z,"trainer.evaluate()"),Z.forEach(s),y=n(x," avant de lancer "),k=i(x,"CODE",{});var N=u(k);z=n(N,"trainer.train()"),N.forEach(s),w=n(x,", pour \xE9viter de gaspiller beaucoup de ressources de calcul avant de tomber sur une erreur."),x.forEach(s)},m(S,x){o(S,b,x),t(b,E),t(b,g),t(g,j),t(b,y),t(b,k),t(k,z),t(b,w)},d(S){S&&s(b)}}}function kb(P){let b,E,g,j,y,k,z,w,S,x,Z;return{c(){b=l("p"),E=a("\u{1F4A1} Si vous utilisez une boucle d\u2019entra\xEEnement manuelle, les m\xEAmes \xE9tapes s\u2019appliquent pour d\xE9boguer votre pipeline d\u2019entra\xEEnement, mais il est plus facile de les s\xE9parer. Assurez-vous cependant de ne pas avoir oubli\xE9 le "),g=l("code"),j=a("model.eval()"),y=a(" ou le "),k=l("code"),z=a("model.train()"),w=a(" aux bons endroits, ou le "),S=l("code"),x=a("zero_grad()"),Z=a(" \xE0 chaque \xE9tape !")},l(N){b=i(N,"P",{});var C=u(b);E=n(C,"\u{1F4A1} Si vous utilisez une boucle d\u2019entra\xEEnement manuelle, les m\xEAmes \xE9tapes s\u2019appliquent pour d\xE9boguer votre pipeline d\u2019entra\xEEnement, mais il est plus facile de les s\xE9parer. Assurez-vous cependant de ne pas avoir oubli\xE9 le "),g=i(C,"CODE",{});var js=u(g);j=n(js,"model.eval()"),js.forEach(s),y=n(C," ou le "),k=i(C,"CODE",{});var L=u(k);z=n(L,"model.train()"),L.forEach(s),w=n(C," aux bons endroits, ou le "),S=i(C,"CODE",{});var Bt=u(S);x=n(Bt,"zero_grad()"),Bt.forEach(s),Z=n(C," \xE0 chaque \xE9tape !"),C.forEach(s)},m(N,C){o(N,b,C),t(b,E),t(b,g),t(g,j),t(b,y),t(b,k),t(k,z),t(b,w),t(b,S),t(S,x),t(b,Z)},d(N){N&&s(b)}}}function jb(P){let b,E;return{c(){b=l("p"),E=a("\u26A0\uFE0F Si vous effectuez un entra\xEEnement distribu\xE9, imprimez des \xE9chantillons de votre ensemble de donn\xE9es dans chaque processus et v\xE9rifiez par trois fois que vous obtenez la m\xEAme chose. Un bug courant consiste \xE0 avoir une source d\u2019al\xE9a dans la cr\xE9ation des donn\xE9es qui fait que chaque processus a une version diff\xE9rente du jeu de donn\xE9es.")},l(g){b=i(g,"P",{});var j=u(b);E=n(j,"\u26A0\uFE0F Si vous effectuez un entra\xEEnement distribu\xE9, imprimez des \xE9chantillons de votre ensemble de donn\xE9es dans chaque processus et v\xE9rifiez par trois fois que vous obtenez la m\xEAme chose. Un bug courant consiste \xE0 avoir une source d\u2019al\xE9a dans la cr\xE9ation des donn\xE9es qui fait que chaque processus a une version diff\xE9rente du jeu de donn\xE9es."),j.forEach(s)},m(g,j){o(g,b,j),t(b,E)},d(g){g&&s(b)}}}function Eb(P){let b,E;return{c(){b=l("p"),E=a("\u{1F4A1} Si vos donn\xE9es d\u2019entra\xEEnement ne sont pas \xE9quilibr\xE9es, veillez \xE0 cr\xE9er un batch de donn\xE9es d\u2019entra\xEEnement contenant toutes les \xE9tiquettes.")},l(g){b=i(g,"P",{});var j=u(b);E=n(j,"\u{1F4A1} Si vos donn\xE9es d\u2019entra\xEEnement ne sont pas \xE9quilibr\xE9es, veillez \xE0 cr\xE9er un batch de donn\xE9es d\u2019entra\xEEnement contenant toutes les \xE9tiquettes."),j.forEach(s)},m(g,j){o(g,b,j),t(b,E)},d(g){g&&s(b)}}}function zb(P){let b,E,g,j,y;return{c(){b=l("p"),E=a("\u26A0\uFE0F Vous devrez recr\xE9er votre mod\xE8le et votre "),g=l("code"),j=a("Trainer"),y=a(" apr\xE8s ce test, car le mod\xE8le obtenu ne sera probablement pas capable de r\xE9cup\xE9rer et d\u2019apprendre quelque chose d\u2019utile sur votre jeu de donn\xE9es complet.")},l(k){b=i(k,"P",{});var z=u(b);E=n(z,"\u26A0\uFE0F Vous devrez recr\xE9er votre mod\xE8le et votre "),g=i(z,"CODE",{});var w=u(g);j=n(w,"Trainer"),w.forEach(s),y=n(z," apr\xE8s ce test, car le mod\xE8le obtenu ne sera probablement pas capable de r\xE9cup\xE9rer et d\u2019apprendre quelque chose d\u2019utile sur votre jeu de donn\xE9es complet."),z.forEach(s)},m(k,z){o(k,b,z),t(b,E),t(b,g),t(g,j),t(b,y)},d(k){k&&s(b)}}}function yb(P){let b,E,g,j,y,k,z,w,S,x,Z,N,C,js,L,Bt,Or,Du,Tu,Yt,Su,Lu,Vr,Uu,Nu,Qn,ue,ge,Ir,Es,Mu,Fr,Ou,Zn,zs,Xn,X,Vu,Gr,Iu,Fu,Wr,Gu,Wu,eo,ke,Ru,Rr,Hu,Bu,so,ee,Yu,Hr,Ju,Ku,ys,Qu,Zu,to,ws,ro,Jt,Xu,ao,xs,no,pe,je,Br,Cs,ep,Yr,sp,oo,Ee,tp,Jr,rp,ap,lo,ze,np,Kr,op,lp,io,Ps,uo,As,po,se,ip,Qr,up,pp,Zr,dp,cp,co,A,mp,Xr,fp,vp,ea,hp,_p,sa,bp,qp,ta,$p,gp,ra,kp,jp,mo,Ds,fo,Kt,Ep,vo,Ts,ho,ye,zp,aa,yp,wp,_o,Ss,bo,Qt,xp,qo,we,Cp,na,Pp,Ap,$o,Ls,go,Us,ko,Zt,Dp,jo,Ns,Eo,Ms,zo,U,Tp,oa,Sp,Lp,la,Up,Np,ia,Mp,Op,ua,Vp,Ip,yo,Os,wo,Vs,xo,te,Fp,Is,Gp,Wp,pa,Rp,Hp,Co,xe,Bp,da,Yp,Jp,Po,Fs,Ao,Gs,Do,Ce,Kp,ca,Qp,Zp,To,Ws,So,Rs,Lo,Xt,Xp,Uo,Hs,No,Bs,Mo,re,ed,ma,sd,td,fa,rd,ad,Oo,Ys,Vo,Js,Io,ae,nd,va,od,ld,ha,id,ud,Fo,Pe,pd,_a,dd,cd,Go,Ae,Wo,er,md,Ro,sr,fd,Ho,de,De,ba,Ks,vd,qa,hd,Bo,D,_d,$a,bd,qd,ga,$d,gd,ka,kd,jd,ja,Ed,zd,Ea,yd,wd,Yo,Qs,Jo,ne,xd,za,Cd,Pd,ya,Ad,Dd,Ko,Zs,Qo,O,Td,wa,Sd,Ld,xa,Ud,Nd,Ca,Md,Od,Zo,Xs,Xo,et,el,V,Vd,Pa,Id,Fd,Aa,Gd,Wd,Da,Rd,Hd,sl,I,Bd,Ta,Yd,Jd,Sa,Kd,Qd,La,Zd,Xd,tl,st,rl,tr,ec,al,tt,nl,rr,sc,ol,ar,tc,ll,rt,il,T,rc,Ua,ac,nc,Na,oc,lc,Ma,ic,uc,Oa,pc,dc,Va,cc,mc,ul,at,pl,nr,fc,dl,or,vc,cl,ce,Te,Ia,nt,hc,Fa,_c,ml,lr,bc,fl,ot,vl,F,qc,Ga,$c,gc,Wa,kc,jc,Ra,Ec,zc,hl,Se,yc,Ha,wc,xc,_l,Le,Cc,Ba,Pc,Ac,bl,Ue,Dc,Ya,Tc,Sc,ql,lt,$l,it,gl,Ne,Lc,Ja,Uc,Nc,kl,ut,jl,pt,El,ir,Mc,zl,dt,yl,Me,Oc,Ka,Vc,Ic,wl,ct,xl,ur,Fc,Cl,mt,Pl,Oe,Gc,Qa,Wc,Rc,Al,me,Ve,Za,ft,Hc,Xa,Bc,Dl,pr,Yc,Tl,Ie,Jc,en,Kc,Qc,Sl,vt,Ll,dr,Zc,Ul,oe,Xc,sn,em,sm,tn,tm,rm,Nl,ht,Ml,Fe,am,rn,nm,om,Ol,fe,Ge,an,_t,lm,cr,im,nn,um,Vl,We,pm,on,dm,cm,Il,mr,mm,Fl,Re,Gl,ve,He,ln,bt,fm,un,vm,Wl,Be,hm,pn,_m,bm,Rl,qt,Hl,$t,Bl,fr,qm,Yl,Ye,$m,dn,gm,km,Jl,gt,Kl,kt,Ql,Je,Zl,vr,jm,Xl,jt,ei,Ke,Em,cn,zm,ym,si,Et,ti,G,wm,mn,xm,Cm,fn,Pm,Am,vn,Dm,Tm,ri,zt,ai,yt,ni,W,Sm,hn,Lm,Um,_n,Nm,Mm,bn,Om,Vm,oi,wt,li,xt,ii,Qe,Im,qn,Fm,Gm,ui,Ct,pi,Pt,di,hr,Wm,ci,_r,Rm,mi,At,fi,Ze,Hm,$n,Bm,Ym,vi,Xe,hi,he,es,gn,Dt,Jm,kn,Km,_i,br,Qm,bi,_e,ss,jn,Tt,Zm,En,Xm,qi,ts,ef,zn,sf,tf,$i,R,yn,rf,af,wn,nf,of,xn,lf,uf,Cn,pf,gi,rs,ki,as,df,Pn,cf,mf,ji,qr,ff,Ei,$r,vf,zi,be,ns,An,St,hf,Dn,_f,yi,gr,bf,wi,le,qf,Tn,$f,gf,Sn,kf,jf,xi,Lt,Ci,os,Pi,ls,Ef,Ln,zf,yf,Ai,Ut,Di,Nt,Ti,kr,wf,Si,jr,xf,Li,is,Ui,qe,us,Un,Mt,Cf,Nn,Pf,Ni,ps,Af,Mn,Df,Tf,Mi,ds,Sf,On,Lf,Uf,Oi,Er,Nf,Vi,$e,cs,Vn,Ot,Mf,In,Of,Ii,ms,Vf,Vt,If,Ff,Fi,zr,Gf,Gi,H,yr,It,Wf,Rf,Hf,wr,Ft,Bf,Yf,Jf,xr,Gt,Kf,Qf,Zf,Cr,Wt,Xf,ev,Wi,B,sv,Fn,tv,rv,Gn,av,nv,Wn,ov,lv,Ri;return g=new bb({props:{fw:P[0]}}),w=new M({}),C=new _b({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter8/section4_pt.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter8/section4_pt.ipynb"}]}}),Es=new M({}),zs=new hb({props:{id:"L-WSwUWde1U"}}),ws=new $({props:{code:`from datasets import load_dataset, load_metric
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = load_metric("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    return metric.compute(predictions=predictions, references=labels)


trainer = Trainer(
    model,
    args,
    train_dataset=raw_datasets["train"],
    eval_dataset=raw_datasets["validation_matched"],
    compute_metrics=compute_metrics,
)
trainer.train()`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, load_metric
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mnli&quot;</span>)

model_checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&quot;premise&quot;</span>], examples[<span class="hljs-string">&quot;hypothesis&quot;</span>], truncation=<span class="hljs-literal">True</span>)


tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(preprocess_function, batched=<span class="hljs-literal">True</span>)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
    <span class="hljs-string">f&quot;distilbert-finetuned-mnli&quot;</span>,
    evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    learning_rate=<span class="hljs-number">2e-5</span>,
    num_train_epochs=<span class="hljs-number">3</span>,
    weight_decay=<span class="hljs-number">0.01</span>,
)

metric = load_metric(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mnli&quot;</span>)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):
    predictions, labels = eval_pred
    <span class="hljs-keyword">return</span> metric.compute(predictions=predictions, references=labels)


trainer = Trainer(
    model,
    args,
    train_dataset=raw_datasets[<span class="hljs-string">&quot;train&quot;</span>],
    eval_dataset=raw_datasets[<span class="hljs-string">&quot;validation_matched&quot;</span>],
    compute_metrics=compute_metrics,
)
trainer.train()`}}),xs=new $({props:{code:"'ValueError: You have to specify either input_ids or inputs_embeds'",highlighted:'<span class="hljs-string">&#x27;ValueError: You have to specify either input_ids or inputs_embeds&#x27;</span>'}}),Cs=new M({}),Ps=new $({props:{code:"trainer.train_dataset[0]",highlighted:'trainer.train_dataset[<span class="hljs-number">0</span>]'}}),As=new $({props:{code:`{'hypothesis': 'Product and geography are what make cream skimming work. ',
 'idx': 0,
 'label': 1,
 'premise': 'Conceptually cream skimming has two basic dimensions - product and geography.'}`,highlighted:`{<span class="hljs-string">&#x27;hypothesis&#x27;</span>: <span class="hljs-string">&#x27;Product and geography are what make cream skimming work. &#x27;</span>,
 <span class="hljs-string">&#x27;idx&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">1</span>,
 <span class="hljs-string">&#x27;premise&#x27;</span>: <span class="hljs-string">&#x27;Conceptually cream skimming has two basic dimensions - product and geography.&#x27;</span>}`}}),Ds=new $({props:{code:`from datasets import load_dataset, load_metric
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = load_metric("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    return metric.compute(predictions=predictions, references=labels)


trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation_matched"],
    compute_metrics=compute_metrics,
)
trainer.train()`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, load_metric
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mnli&quot;</span>)

model_checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&quot;premise&quot;</span>], examples[<span class="hljs-string">&quot;hypothesis&quot;</span>], truncation=<span class="hljs-literal">True</span>)


tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(preprocess_function, batched=<span class="hljs-literal">True</span>)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
    <span class="hljs-string">f&quot;distilbert-finetuned-mnli&quot;</span>,
    evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    learning_rate=<span class="hljs-number">2e-5</span>,
    num_train_epochs=<span class="hljs-number">3</span>,
    weight_decay=<span class="hljs-number">0.01</span>,
)

metric = load_metric(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mnli&quot;</span>)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):
    predictions, labels = eval_pred
    <span class="hljs-keyword">return</span> metric.compute(predictions=predictions, references=labels)


trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],
    eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;validation_matched&quot;</span>],
    compute_metrics=compute_metrics,
)
trainer.train()`}}),Ts=new $({props:{code:"'ValueError: expected sequence of length 43 at dim 1 (got 37)'",highlighted:'<span class="hljs-string">&#x27;ValueError: expected sequence of length 43 at dim 1 (got 37)&#x27;</span>'}}),Ss=new $({props:{code:`~/git/transformers/src/transformers/data/data_collator.py in torch_default_data_collator(features)
    105                 batch[k] = torch.stack([f[k] for f in features])
    106             else:
--> 107                 batch[k] = torch.tensor([f[k] for f in features])
    108 
    109     return batch`,highlighted:`~/git/transformers/src/transformers/data/data_collator.py <span class="hljs-keyword">in</span> torch_default_data_collator(features)
    <span class="hljs-number">105</span>                 batch[k] = torch.stack([f[k] <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> features])
    <span class="hljs-number">106</span>             <span class="hljs-keyword">else</span>:
--&gt; <span class="hljs-number">107</span>                 batch[k] = torch.tensor([f[k] <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> features])
    <span class="hljs-number">108</span> 
    <span class="hljs-number">109</span>     <span class="hljs-keyword">return</span> batch`}}),Ls=new $({props:{code:'tokenizer.decode(trainer.train_dataset[0]["input_ids"])',highlighted:'tokenizer.decode(trainer.train_dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;input_ids&quot;</span>])'}}),Us=new $({props:{code:"'[CLS] conceptually cream skimming has two basic dimensions - product and geography. [SEP] product and geography are what make cream skimming work. [SEP]'",highlighted:'<span class="hljs-string">&#x27;[CLS] conceptually cream skimming has two basic dimensions - product and geography. [SEP] product and geography are what make cream skimming work. [SEP]&#x27;</span>'}}),Ns=new $({props:{code:"trainer.train_dataset[0].keys()",highlighted:'trainer.train_dataset[<span class="hljs-number">0</span>].keys()'}}),Ms=new $({props:{code:"dict_keys(['attention_mask', 'hypothesis', 'idx', 'input_ids', 'label', 'premise'])",highlighted:'dict_keys([<span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;hypothesis&#x27;</span>, <span class="hljs-string">&#x27;idx&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;label&#x27;</span>, <span class="hljs-string">&#x27;premise&#x27;</span>])'}}),Os=new $({props:{code:"type(trainer.model)",highlighted:'<span class="hljs-built_in">type</span>(trainer.model)'}}),Vs=new $({props:{code:"transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification",highlighted:"transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification"}}),Fs=new $({props:{code:'tokenizer.decode(trainer.train_dataset[0]["attention_mask"])',highlighted:'tokenizer.decode(trainer.train_dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;attention_mask&quot;</span>])'}}),Gs=new $({props:{code:"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]",highlighted:'[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]'}}),Ws=new $({props:{code:`len(trainer.train_dataset[0]["attention_mask"]) == len(
    trainer.train_dataset[0]["input_ids"]
)`,highlighted:`<span class="hljs-built_in">len</span>(trainer.train_dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;attention_mask&quot;</span>]) == <span class="hljs-built_in">len</span>(
    trainer.train_dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;input_ids&quot;</span>]
)`}}),Rs=new $({props:{code:"True",highlighted:'<span class="hljs-literal">True</span>'}}),Hs=new $({props:{code:'trainer.train_dataset[0]["label"]',highlighted:'trainer.train_dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;label&quot;</span>]'}}),Bs=new $({props:{code:"1",highlighted:'<span class="hljs-number">1</span>'}}),Ys=new $({props:{code:'trainer.train_dataset.features["label"].names',highlighted:'trainer.train_dataset.features[<span class="hljs-string">&quot;label&quot;</span>].names'}}),Js=new $({props:{code:"['entailment', 'neutral', 'contradiction']",highlighted:'[<span class="hljs-string">&#x27;entailment&#x27;</span>, <span class="hljs-string">&#x27;neutral&#x27;</span>, <span class="hljs-string">&#x27;contradiction&#x27;</span>]'}}),Ae=new Ht({props:{$$slots:{default:[qb]},$$scope:{ctx:P}}}),Ks=new M({}),Qs=new $({props:{code:`for batch in trainer.get_train_dataloader():
    break`,highlighted:`<span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> trainer.get_train_dataloader():
    <span class="hljs-keyword">break</span>`}}),Zs=new $({props:{code:`~/git/transformers/src/transformers/data/data_collator.py in torch_default_data_collator(features)
    105                 batch[k] = torch.stack([f[k] for f in features])
    106             else:
--> 107                 batch[k] = torch.tensor([f[k] for f in features])
    108 
    109     return batch

ValueError: expected sequence of length 45 at dim 1 (got 76)`,highlighted:`~/git/transformers/src/transformers/data/data_collator.py <span class="hljs-keyword">in</span> torch_default_data_collator(features)
    <span class="hljs-number">105</span>                 batch[k] = torch.stack([f[k] <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> features])
    <span class="hljs-number">106</span>             <span class="hljs-keyword">else</span>:
--&gt; <span class="hljs-number">107</span>                 batch[k] = torch.tensor([f[k] <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> features])
    <span class="hljs-number">108</span> 
    <span class="hljs-number">109</span>     <span class="hljs-keyword">return</span> batch

ValueError: expected sequence of length <span class="hljs-number">45</span> at dim <span class="hljs-number">1</span> (got <span class="hljs-number">76</span>)`}}),Xs=new $({props:{code:`data_collator = trainer.get_train_dataloader().collate_fn
data_collator`,highlighted:`data_collator = trainer.get_train_dataloader().collate_fn
data_collator`}}),et=new $({props:{code:"<function transformers.data.data_collator.default_data_collator(features: List[InputDataClass], return_tensors='pt') -> Dict[str, Any]>",highlighted:'&lt;function transformers.data.data_collator.default_data_collator(features: <span class="hljs-type">List</span>[InputDataClass], return_tensors=<span class="hljs-string">&#x27;pt&#x27;</span>) -&gt; <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-type">Any</span>]&gt;'}}),st=new $({props:{code:`from datasets import load_dataset, load_metric
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    DataCollatorWithPadding,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = load_metric("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    return metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation_matched"],
    compute_metrics=compute_metrics,
    data_collator=data_collator,
    tokenizer=tokenizer,
)
trainer.train()`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, load_metric
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    DataCollatorWithPadding,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mnli&quot;</span>)

model_checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&quot;premise&quot;</span>], examples[<span class="hljs-string">&quot;hypothesis&quot;</span>], truncation=<span class="hljs-literal">True</span>)


tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(preprocess_function, batched=<span class="hljs-literal">True</span>)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)

args = TrainingArguments(
    <span class="hljs-string">f&quot;distilbert-finetuned-mnli&quot;</span>,
    evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    learning_rate=<span class="hljs-number">2e-5</span>,
    num_train_epochs=<span class="hljs-number">3</span>,
    weight_decay=<span class="hljs-number">0.01</span>,
)

metric = load_metric(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mnli&quot;</span>)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):
    predictions, labels = eval_pred
    <span class="hljs-keyword">return</span> metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],
    eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;validation_matched&quot;</span>],
    compute_metrics=compute_metrics,
    data_collator=data_collator,
    tokenizer=tokenizer,
)
trainer.train()`}}),tt=new $({props:{code:"RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`",highlighted:"RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`"}}),rt=new $({props:{code:`data_collator = trainer.get_train_dataloader().collate_fn
batch = data_collator([trainer.train_dataset[i] for i in range(4)])`,highlighted:`data_collator = trainer.get_train_dataloader().collate_fn
batch = data_collator([trainer.train_dataset[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)])`}}),at=new $({props:{code:`data_collator = trainer.get_train_dataloader().collate_fn
actual_train_set = trainer._remove_unused_columns(trainer.train_dataset)
batch = data_collator([actual_train_set[i] for i in range(4)])`,highlighted:`data_collator = trainer.get_train_dataloader().collate_fn
actual_train_set = trainer._remove_unused_columns(trainer.train_dataset)
batch = data_collator([actual_train_set[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>)])`}}),nt=new M({}),ot=new $({props:{code:`for batch in trainer.get_train_dataloader():
    break`,highlighted:`<span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> trainer.get_train_dataloader():
    <span class="hljs-keyword">break</span>`}}),lt=new $({props:{code:"outputs = trainer.model.cpu()(**batch)",highlighted:"outputs = trainer.model.cpu()(**batch)"}}),it=new $({props:{code:`~/.pyenv/versions/3.7.9/envs/base/lib/python3.7/site-packages/torch/nn/functional.py in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction)
   2386         )
   2387     if dim == 2:
-> 2388         ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
   2389     elif dim == 4:
   2390         ret = torch._C._nn.nll_loss2d(input, target, weight, _Reduction.get_enum(reduction), ignore_index)

IndexError: Target 2 is out of bounds.`,highlighted:`~/.pyenv/versions/<span class="hljs-number">3.7</span><span class="hljs-number">.9</span>/envs/base/lib/python3<span class="hljs-number">.7</span>/site-packages/torch/nn/functional.py <span class="hljs-keyword">in</span> nll_loss(<span class="hljs-built_in">input</span>, target, weight, size_average, ignore_index, reduce, reduction)
   <span class="hljs-number">2386</span>         )
   <span class="hljs-number">2387</span>     <span class="hljs-keyword">if</span> dim == <span class="hljs-number">2</span>:
-&gt; <span class="hljs-number">2388</span>         ret = torch._C._nn.nll_loss(<span class="hljs-built_in">input</span>, target, weight, _Reduction.get_enum(reduction), ignore_index)
   <span class="hljs-number">2389</span>     <span class="hljs-keyword">elif</span> dim == <span class="hljs-number">4</span>:
   <span class="hljs-number">2390</span>         ret = torch._C._nn.nll_loss2d(<span class="hljs-built_in">input</span>, target, weight, _Reduction.get_enum(reduction), ignore_index)

IndexError: Target <span class="hljs-number">2</span> <span class="hljs-keyword">is</span> out of bounds.`}}),ut=new $({props:{code:"trainer.model.config.num_labels",highlighted:"trainer.model.config.num_labels"}}),pt=new $({props:{code:"2",highlighted:'<span class="hljs-number">2</span>'}}),dt=new $({props:{code:`from datasets import load_dataset, load_metric
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    DataCollatorWithPadding,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = load_metric("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    return metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation_matched"],
    compute_metrics=compute_metrics,
    data_collator=data_collator,
    tokenizer=tokenizer,
)`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, load_metric
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    DataCollatorWithPadding,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mnli&quot;</span>)

model_checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&quot;premise&quot;</span>], examples[<span class="hljs-string">&quot;hypothesis&quot;</span>], truncation=<span class="hljs-literal">True</span>)


tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(preprocess_function, batched=<span class="hljs-literal">True</span>)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=<span class="hljs-number">3</span>)

args = TrainingArguments(
    <span class="hljs-string">f&quot;distilbert-finetuned-mnli&quot;</span>,
    evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    learning_rate=<span class="hljs-number">2e-5</span>,
    num_train_epochs=<span class="hljs-number">3</span>,
    weight_decay=<span class="hljs-number">0.01</span>,
)

metric = load_metric(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mnli&quot;</span>)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):
    predictions, labels = eval_pred
    <span class="hljs-keyword">return</span> metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],
    eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;validation_matched&quot;</span>],
    compute_metrics=compute_metrics,
    data_collator=data_collator,
    tokenizer=tokenizer,
)`}}),ct=new $({props:{code:`for batch in trainer.get_train_dataloader():
    break

outputs = trainer.model.cpu()(**batch)`,highlighted:`<span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> trainer.get_train_dataloader():
    <span class="hljs-keyword">break</span>

outputs = trainer.model.cpu()(**batch)`}}),mt=new $({props:{code:`import torch

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
batch = {k: v.to(device) for k, v in batch.items()}

outputs = trainer.model.to(device)(**batch)`,highlighted:`<span class="hljs-keyword">import</span> torch

device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>) <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)
batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}

outputs = trainer.model.to(device)(**batch)`}}),ft=new M({}),vt=new $({props:{code:`loss = outputs.loss
loss.backward()`,highlighted:`loss = outputs.loss
loss.backward()`}}),ht=new $({props:{code:`trainer.create_optimizer()
trainer.optimizer.step()`,highlighted:`trainer.create_optimizer()
trainer.optimizer.step()`}}),_t=new M({}),Re=new Ht({props:{$$slots:{default:[$b]},$$scope:{ctx:P}}}),bt=new M({}),qt=new $({props:{code:`# Cela prendra beaucoup de temps et se soldera par une erreur, vous ne devriez donc pas utiliser cette cellule.
trainer.train()`,highlighted:`<span class="hljs-comment"># Cela prendra beaucoup de temps et se soldera par une erreur, vous ne devriez donc pas utiliser cette cellule.</span>
trainer.train()`}}),$t=new $({props:{code:"TypeError: only size-1 arrays can be converted to Python scalars",highlighted:'TypeError: only size-<span class="hljs-number">1</span> arrays can be converted to Python scalars'}}),gt=new $({props:{code:"trainer.evaluate()",highlighted:"trainer.evaluate()"}}),kt=new $({props:{code:"TypeError: only size-1 arrays can be converted to Python scalars",highlighted:'TypeError: only size-<span class="hljs-number">1</span> arrays can be converted to Python scalars'}}),Je=new Ht({props:{$$slots:{default:[gb]},$$scope:{ctx:P}}}),jt=new $({props:{code:`for batch in trainer.get_eval_dataloader():
    break

batch = {k: v.to(device) for k, v in batch.items()}

with torch.no_grad():
    outputs = trainer.model(**batch)`,highlighted:`<span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> trainer.get_eval_dataloader():
    <span class="hljs-keyword">break</span>

batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}

<span class="hljs-keyword">with</span> torch.no_grad():
    outputs = trainer.model(**batch)`}}),Et=new $({props:{code:`~/git/datasets/src/datasets/metric.py in add_batch(self, predictions, references)
    431         """
    432         batch = {"predictions": predictions, "references": references}
--> 433         batch = self.info.features.encode_batch(batch)
    434         if self.writer is None:
    435             self._init_writer()`,highlighted:`~/git/datasets/src/datasets/metric.py <span class="hljs-keyword">in</span> add_batch(self, predictions, references)
    <span class="hljs-number">431</span>         <span class="hljs-string">&quot;&quot;&quot;
    432         batch = {&quot;predictions&quot;: predictions, &quot;references&quot;: references}
--&gt; 433         batch = self.info.features.encode_batch(batch)
    434         if self.writer is None:
    435             self._init_writer()</span>`}}),zt=new $({props:{code:`predictions = outputs.logits.cpu().numpy()
labels = batch["labels"].cpu().numpy()

compute_metrics((predictions, labels))`,highlighted:`predictions = outputs.logits.cpu().numpy()
labels = batch[<span class="hljs-string">&quot;labels&quot;</span>].cpu().numpy()

compute_metrics((predictions, labels))`}}),yt=new $({props:{code:"TypeError: only size-1 arrays can be converted to Python scalars",highlighted:'TypeError: only size-<span class="hljs-number">1</span> arrays can be converted to Python scalars'}}),wt=new $({props:{code:"predictions.shape, labels.shape",highlighted:"predictions.shape, labels.shape"}}),xt=new $({props:{code:"((8, 3), (8,))",highlighted:'((<span class="hljs-number">8</span>, <span class="hljs-number">3</span>), (<span class="hljs-number">8</span>,))'}}),Ct=new $({props:{code:`import numpy as np


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    return metric.compute(predictions=predictions, references=labels)


compute_metrics((predictions, labels))`,highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np


<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=<span class="hljs-number">1</span>)
    <span class="hljs-keyword">return</span> metric.compute(predictions=predictions, references=labels)


compute_metrics((predictions, labels))`}}),Pt=new $({props:{code:"{'accuracy': 0.625}",highlighted:'{<span class="hljs-string">&#x27;accuracy&#x27;</span>: <span class="hljs-number">0.625</span>}'}}),At=new $({props:{code:`import numpy as np
from datasets import load_dataset, load_metric
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    DataCollatorWithPadding,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset("glue", "mnli")

model_checkpoint = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


def preprocess_function(examples):
    return tokenizer(examples["premise"], examples["hypothesis"], truncation=True)


tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=3)

args = TrainingArguments(
    f"distilbert-finetuned-mnli",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

metric = load_metric("glue", "mnli")


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    return metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation_matched"],
    compute_metrics=compute_metrics,
    data_collator=data_collator,
    tokenizer=tokenizer,
)
trainer.train()`,highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, load_metric
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    DataCollatorWithPadding,
    TrainingArguments,
    Trainer,
)

raw_datasets = load_dataset(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mnli&quot;</span>)

model_checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&quot;premise&quot;</span>], examples[<span class="hljs-string">&quot;hypothesis&quot;</span>], truncation=<span class="hljs-literal">True</span>)


tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(preprocess_function, batched=<span class="hljs-literal">True</span>)
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=<span class="hljs-number">3</span>)

args = TrainingArguments(
    <span class="hljs-string">f&quot;distilbert-finetuned-mnli&quot;</span>,
    evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    learning_rate=<span class="hljs-number">2e-5</span>,
    num_train_epochs=<span class="hljs-number">3</span>,
    weight_decay=<span class="hljs-number">0.01</span>,
)

metric = load_metric(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mnli&quot;</span>)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=<span class="hljs-number">1</span>)
    <span class="hljs-keyword">return</span> metric.compute(predictions=predictions, references=labels)


data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

trainer = Trainer(
    model,
    args,
    train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],
    eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;validation_matched&quot;</span>],
    compute_metrics=compute_metrics,
    data_collator=data_collator,
    tokenizer=tokenizer,
)
trainer.train()`}}),Xe=new Ht({props:{$$slots:{default:[kb]},$$scope:{ctx:P}}}),Dt=new M({}),Tt=new M({}),rs=new Ht({props:{warning:!0,$$slots:{default:[jb]},$$scope:{ctx:P}}}),St=new M({}),Lt=new $({props:{code:`for batch in trainer.get_train_dataloader():
    break

batch = {k: v.to(device) for k, v in batch.items()}
trainer.create_optimizer()

for _ in range(20):
    outputs = trainer.model(**batch)
    loss = outputs.loss
    loss.backward()
    trainer.optimizer.step()
    trainer.optimizer.zero_grad()`,highlighted:`<span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> trainer.get_train_dataloader():
    <span class="hljs-keyword">break</span>

batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}
trainer.create_optimizer()

<span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">20</span>):
    outputs = trainer.model(**batch)
    loss = outputs.loss
    loss.backward()
    trainer.optimizer.step()
    trainer.optimizer.zero_grad()`}}),os=new Ht({props:{$$slots:{default:[Eb]},$$scope:{ctx:P}}}),Ut=new $({props:{code:`with torch.no_grad():
    outputs = trainer.model(**batch)
preds = outputs.logits
labels = batch["labels"]

compute_metrics((preds.cpu().numpy(), labels.cpu().numpy()))`,highlighted:`<span class="hljs-keyword">with</span> torch.no_grad():
    outputs = trainer.model(**batch)
preds = outputs.logits
labels = batch[<span class="hljs-string">&quot;labels&quot;</span>]

compute_metrics((preds.cpu().numpy(), labels.cpu().numpy()))`}}),Nt=new $({props:{code:"{'accuracy': 1.0}",highlighted:'{<span class="hljs-string">&#x27;accuracy&#x27;</span>: <span class="hljs-number">1.0</span>}'}}),is=new Ht({props:{warning:!0,$$slots:{default:[zb]},$$scope:{ctx:P}}}),Mt=new M({}),Ot=new M({}),{c(){b=l("meta"),E=p(),c(g.$$.fragment),j=p(),y=l("h1"),k=l("a"),z=l("span"),c(w.$$.fragment),S=p(),x=l("span"),Z=a("D\xE9bogage du pipeline d'entra\xEEnement"),N=p(),c(C.$$.fragment),js=p(),L=l("p"),Bt=a("Vous avez \xE9crit un magnifique script pour entra\xEEner ou "),Or=l("em"),Du=a("finetuner"),Tu=a(" un mod\xE8le sur une t\xE2che donn\xE9e en suivant consciencieusement les conseils du "),Yt=l("a"),Su=a("chapitre 7"),Lu=a(". Mais lorsque vous lancez la commande "),Vr=l("code"),Uu=a("model.fit()"),Nu=a(", quelque chose d\u2019horrible se produit : vous obtenez une erreur \u{1F631} ! Ou pire, tout semble aller bien et l\u2019entra\xEEnement se d\xE9roule sans erreur mais le mod\xE8le r\xE9sultant est mauvais. Dans cette section, nous allons vous montrer ce que vous pouvez faire pour d\xE9boguer ce genre de probl\xE8mes."),Qn=p(),ue=l("h2"),ge=l("a"),Ir=l("span"),c(Es.$$.fragment),Mu=p(),Fr=l("span"),Ou=a("D\xE9boguer le pipeline d'entra\xEEnement"),Zn=p(),c(zs.$$.fragment),Xn=p(),X=l("p"),Vu=a("Le probl\xE8me lorsque vous rencontrez une erreur dans "),Gr=l("code"),Iu=a("trainer.train()"),Fu=a(" est qu\u2019elle peut provenir de plusieurs sources, car la fonction "),Wr=l("code"),Gu=a("Trainer"),Wu=a(" assemble g\xE9n\xE9ralement des batchs de choses. Elle convertit les jeux de donn\xE9es en chargeurs de donn\xE9es donc le probl\xE8me pourrait \xEAtre quelque chose d\u2019erron\xE9 dans votre jeu de donn\xE9es, ou un probl\xE8me en essayant de regrouper les \xE9l\xE9ments des jeux de donn\xE9es ensemble. Ensuite, elle prend un batch de donn\xE9es et le transmet au mod\xE8le, le probl\xE8me peut donc se situer dans le code du mod\xE8le. Apr\xE8s cela, elle calcule les gradients et effectue l\u2019\xE9tape d\u2019optimisation, le probl\xE8me peut donc \xE9galement se situer dans votre optimiseur. Et m\xEAme si tout se passe bien pendant l\u2019entra\xEEnement, quelque chose peut encore mal tourner pendant l\u2019\xE9valuation si votre m\xE9trique pose probl\xE8me."),eo=p(),ke=l("p"),Ru=a("La meilleure fa\xE7on de d\xE9boguer une erreur qui survient dans "),Rr=l("code"),Hu=a("trainer.train()"),Bu=a(" est de passer manuellement en revue tout le pipeline pour voir o\xF9 les choses se sont mal pass\xE9es. L\u2019erreur est alors souvent tr\xE8s facile \xE0 r\xE9soudre."),so=p(),ee=l("p"),Yu=a("Pour le d\xE9montrer, nous utiliserons le script suivant qui tente de "),Hr=l("em"),Ju=a("finetuner"),Ku=a(" un mod\xE8le DistilBERT sur le "),ys=l("a"),Qu=a("jeu de donn\xE9es MNLI"),Zu=a(" :"),to=p(),c(ws.$$.fragment),ro=p(),Jt=l("p"),Xu=a("Si vous essayez de l\u2019ex\xE9cuter, vous serez confront\xE9 \xE0 une erreur plut\xF4t cryptique :"),ao=p(),c(xs.$$.fragment),no=p(),pe=l("h3"),je=l("a"),Br=l("span"),c(Cs.$$.fragment),ep=p(),Yr=l("span"),sp=a("V\xE9rifiez vos donn\xE9es"),oo=p(),Ee=l("p"),tp=a("Cela va sans dire, mais si vos donn\xE9es sont corrompues, le "),Jr=l("code"),rp=a("Trainer"),ap=a(" ne sera pas capable de former des batchs et encore moins d\u2019entra\xEEner votre mod\xE8le. Donc, tout d\u2019abord, vous devez jeter un coup d\u2019oeil \xE0 ce qui se trouve dans votre jeu d\u2019entra\xEEnement."),lo=p(),ze=l("p"),np=a("Pour \xE9viter d\u2019innombrables heures pass\xE9es \xE0 essayer de corriger quelque chose qui n\u2019est pas la source du bug, nous vous recommandons d\u2019utiliser "),Kr=l("code"),op=a("trainer.train_dataset"),lp=a(" pour vos v\xE9rifications et rien d\u2019autre. Faisons donc cela ici :"),io=p(),c(Ps.$$.fragment),uo=p(),c(As.$$.fragment),po=p(),se=l("p"),ip=a("Vous remarquez quelque chose d\u2019anormal ? Ceci, en conjonction avec le message d\u2019erreur sur les "),Qr=l("code"),up=a("input_ids"),pp=a(" manquants, devrait vous faire r\xE9aliser que ce sont des textes et non des nombres que le mod\xE8le peut comprendre. Ici, l\u2019erreur originale est tr\xE8s trompeuse parce que le "),Zr=l("code"),dp=a("Trainer"),cp=a(" enl\xE8ve automatiquement les colonnes qui ne correspondent pas \xE0 la signature du mod\xE8le (c\u2019est-\xE0-dire, les arguments attendus par le mod\xE8le). Cela signifie qu\u2019ici, tout, sauf les \xE9tiquettes, a \xE9t\xE9 \xE9limin\xE9. Il n\u2019y avait donc aucun probl\xE8me \xE0 cr\xE9er des batchs et \xE0 les envoyer ensuite au mod\xE8le, qui s\u2019est plaint \xE0 son tour de ne pas avoir re\xE7u les bons arguments."),co=p(),A=l("p"),mp=a("Pourquoi les donn\xE9es n\u2019ont-elles pas \xE9t\xE9 trait\xE9es ? Nous avons utilis\xE9 la m\xE9thode "),Xr=l("code"),fp=a("Dataset.map()"),vp=a(" sur les jeux de donn\xE9es pour appliquer le "),ea=l("em"),hp=a("tokenizer"),_p=a(" sur chaque \xE9chantillon. Mais si vous regardez attentivement le code, vous verrez que nous avons fait une erreur en passant les ensembles d\u2019entra\xEEnement et d\u2019\xE9valuation au "),sa=l("code"),bp=a("Trainer"),qp=a(". Au lieu d\u2019utiliser "),ta=l("code"),$p=a("tokenized_datasets"),gp=a(" ici, nous avons utilis\xE9 "),ra=l("code"),kp=a("raw_datasets"),jp=a(" \u{1F926}. Alors corrigeons \xE7a !"),mo=p(),c(Ds.$$.fragment),fo=p(),Kt=l("p"),Ep=a("Ce nouveau code donnera maintenant une erreur diff\xE9rente (c\u2019est un progr\xE8s !) :"),vo=p(),c(Ts.$$.fragment),ho=p(),ye=l("p"),zp=a("En regardant le "),aa=l("em"),yp=a("traceback"),wp=a(", nous pouvons voir que l\u2019erreur se produit dans l\u2019\xE9tape de collationnement des donn\xE9es :"),_o=p(),c(Ss.$$.fragment),bo=p(),Qt=l("p"),xp=a("Donc, nous devrions passer \xE0 cela. Mais avant finissons d\u2019inspecter nos donn\xE9es, pour \xEAtre s\xFBrs \xE0 100% qu\u2019elles sont correctes."),qo=p(),we=l("p"),Cp=a("Une chose que vous devriez toujours faire lorsque vous d\xE9boguez une session d\u2019entra\xEEnement est de jeter un coup d\u2019oeil aux entr\xE9es d\xE9cod\xE9es de votre mod\xE8le. Nous ne pouvons pas donner un sens aux chiffres que nous lui fournissons directement, nous devons donc examiner ce que ces chiffres repr\xE9sentent. Dans le domaine de la vision par ordinateur cela signifie regarder les images d\xE9cod\xE9es des pixels que vous passez, dans le domaine de la parole cela signifie \xE9couter les \xE9chantillons audio d\xE9cod\xE9s, et pour notre exemple de NLP cela signifie utiliser notre "),na=l("em"),Pp=a("tokenizer"),Ap=a(" pour d\xE9coder les entr\xE9es :"),$o=p(),c(Ls.$$.fragment),go=p(),c(Us.$$.fragment),ko=p(),Zt=l("p"),Dp=a("Cela semble correct. Vous devriez faire cela pour toutes les cl\xE9s dans les entr\xE9es :"),jo=p(),c(Ns.$$.fragment),Eo=p(),c(Ms.$$.fragment),zo=p(),U=l("p"),Tp=a("Notez que les cl\xE9s qui ne correspondent pas \xE0 des entr\xE9es accept\xE9es par le mod\xE8le seront automatiquement \xE9cart\xE9es, donc ici nous ne garderons que "),oa=l("code"),Sp=a("input_ids"),Lp=a(", "),la=l("code"),Up=a("attention_mask"),Np=a(", et "),ia=l("code"),Mp=a("label"),Op=a(" (qui sera renomm\xE9 "),ua=l("code"),Vp=a("labels"),Ip=a("). Pour rev\xE9rifier la signature du mod\xE8le, vous pouvez imprimer la classe de votre mod\xE8le, puis aller consulter sa documentation :"),yo=p(),c(Os.$$.fragment),wo=p(),c(Vs.$$.fragment),xo=p(),te=l("p"),Fp=a("Donc dans notre cas, nous pouvons v\xE9rifier les param\xE8tres accept\xE9s sur "),Is=l("a"),Gp=a("cette page"),Wp=a(". Le "),pa=l("code"),Rp=a("Trainer"),Hp=a(" va \xE9galement enregistrer les colonnes qu\u2019il rejette."),Co=p(),xe=l("p"),Bp=a("Nous avons v\xE9rifi\xE9 que les identifiants d\u2019entr\xE9e sont corrects en les d\xE9codant. Ensuite, il y a le "),da=l("code"),Yp=a("attention_mask"),Jp=a(" :"),Po=p(),c(Fs.$$.fragment),Ao=p(),c(Gs.$$.fragment),Do=p(),Ce=l("p"),Kp=a("Comme nous n\u2019avons pas appliqu\xE9 de "),ca=l("em"),Qp=a("padding"),Zp=a(" dans notre pr\xE9traitement, cela semble parfaitement naturel. Pour \xEAtre s\xFBr qu\u2019il n\u2019y a pas de probl\xE8me avec ce masque d\u2019attention, v\xE9rifions qu\u2019il est de la m\xEAme longueur que nos identifiants d\u2019entr\xE9e :"),To=p(),c(Ws.$$.fragment),So=p(),c(Rs.$$.fragment),Lo=p(),Xt=l("p"),Xp=a("C\u2019est bien ! Enfin, v\xE9rifions notre \xE9tiquette :"),Uo=p(),c(Hs.$$.fragment),No=p(),c(Bs.$$.fragment),Mo=p(),re=l("p"),ed=a("Comme les identifiants d\u2019entr\xE9e, c\u2019est un nombre qui n\u2019a pas vraiment de sens en soi. Comme nous l\u2019avons vu pr\xE9c\xE9demment, la correspondance entre les entiers et les noms d\u2019\xE9tiquettes est stock\xE9e dans l\u2019attribut "),ma=l("code"),sd=a("names"),td=a(" de la "),fa=l("em"),rd=a("caract\xE9ristique"),ad=a(" correspondante du jeu de donn\xE9es :"),Oo=p(),c(Ys.$$.fragment),Vo=p(),c(Js.$$.fragment),Io=p(),ae=l("p"),nd=a("Donc "),va=l("code"),od=a("1"),ld=a(" signifie "),ha=l("code"),id=a("neutral"),ud=a(", ce qui signifie que les deux phrases que nous avons vues ci-dessus ne sont pas en contradiction : la premi\xE8re n\u2019implique pas la seconde. Cela semble correct !"),Fo=p(),Pe=l("p"),pd=a("Nous n\u2019avons pas de "),_a=l("em"),dd=a("token"),cd=a(" de type identifiant ici puisque DistilBERT ne les attend pas. Si vous en avez dans votre mod\xE8le, vous devriez \xE9galement vous assurer qu\u2019ils correspondent correctement \xE0 l\u2019endroit o\xF9 se trouvent la premi\xE8re et la deuxi\xE8me phrase dans l\u2019entr\xE9e."),Go=p(),c(Ae.$$.fragment),Wo=p(),er=l("p"),md=a("Ici nous ne v\xE9rifions que le jeu d\u2019entra\xEEnement. Vous devez bien s\xFBr v\xE9rifier de la m\xEAme fa\xE7on les jeux de validation et de test."),Ro=p(),sr=l("p"),fd=a("Maintenant que nous savons que nos jeux de donn\xE9es sont bons, il est temps de v\xE9rifier l\u2019\xE9tape suivante du pipeline d\u2019entra\xEEnement."),Ho=p(),de=l("h3"),De=l("a"),ba=l("span"),c(Ks.$$.fragment),vd=p(),qa=l("span"),hd=a("Des jeux de donn\xE9es aux chargeurs de donn\xE9es"),Bo=p(),D=l("p"),_d=a("La prochaine chose qui peut mal tourner dans le pipeline d\u2019entra\xEEnement est lorsque le "),$a=l("code"),bd=a("Trainer"),qd=a(" essaie de former des batchs \xE0 partir du jeu d\u2019entra\xEEnement ou de validation. Une fois que vous \xEAtes s\xFBr que les jeux de donn\xE9es du "),ga=l("code"),$d=a("Trainer"),gd=a(" sont corrects, vous pouvez essayer de former manuellement un batch en ex\xE9cutant ce qui suit (remplacez "),ka=l("code"),kd=a("train"),jd=a(" par "),ja=l("code"),Ed=a("eval"),zd=a(" pour le "),Ea=l("em"),yd=a("dataloader"),wd=a(" de validation) :"),Yo=p(),c(Qs.$$.fragment),Jo=p(),ne=l("p"),xd=a("Ce code cr\xE9e le "),za=l("em"),Cd=a("dataloader"),Pd=a(" d\u2019entra\xEEnement puis le parcourt en s\u2019arr\xEAtant \xE0 la premi\xE8re it\xE9ration. Si le code s\u2019ex\xE9cute sans erreur, vous avez le premier batch d\u2019entra\xEEnement que vous pouvez inspecter, et si le code se trompe, vous \xEAtes s\xFBr que le probl\xE8me se situe dans le "),ya=l("em"),Ad=a("dataloader"),Dd=a(", comme c\u2019est le cas ici :"),Ko=p(),c(Zs.$$.fragment),Qo=p(),O=l("p"),Td=a("L\u2019inspection de la derni\xE8re image du "),wa=l("em"),Sd=a("traceback"),Ld=a(" devrait suffire \xE0 vous donner un indice mais creusons un peu plus. La plupart des probl\xE8mes lors de la cr\xE9ation d\u2019un batch sont dus \xE0 l\u2019assemblage des exemples en un seul batch. La premi\xE8re chose \xE0 v\xE9rifier en cas de doute est le "),xa=l("code"),Ud=a("collate_fn"),Nd=a(" utilis\xE9 par votre "),Ca=l("code"),Md=a("DataLoader"),Od=a(" :"),Zo=p(),c(Xs.$$.fragment),Xo=p(),c(et.$$.fragment),el=p(),V=l("p"),Vd=a("C\u2019est donc "),Pa=l("code"),Id=a("default_data_collator"),Fd=a(", mais ce n\u2019est pas ce que nous voulons dans ce cas. Nous voulons rembourrer nos exemples \xE0 la phrase la plus longue du batch, ce qui est fait par "),Aa=l("code"),Gd=a("DataCollatorWithPadding"),Wd=a(". Et cette assembleur de donn\xE9es est cens\xE9 \xEAtre utilis\xE9 par d\xE9faut par le "),Da=l("code"),Rd=a("Trainer"),Hd=a(", alors pourquoi n\u2019est-il pas utilis\xE9 ici ?"),sl=p(),I=l("p"),Bd=a("La r\xE9ponse est que nous n\u2019avons pas pass\xE9 le "),Ta=l("code"),Yd=a("tokenizer"),Jd=a(" au "),Sa=l("code"),Kd=a("Trainer"),Qd=a(", donc il ne pouvait pas cr\xE9er le "),La=l("code"),Zd=a("DataCollatorWithPadding"),Xd=a(" que nous voulons. En pratique, il ne faut jamais h\xE9siter \xE0 transmettre explicitement l\u2019assembleur de donn\xE9es que l\u2019on veut utiliser pour \xEAtre s\xFBr d\u2019\xE9viter ce genre d\u2019erreurs. Adaptons notre code pour faire exactement cela :"),tl=p(),c(st.$$.fragment),rl=p(),tr=l("p"),ec=a("La bonne nouvelle ? Nous n\u2019avons plus la m\xEAme erreur qu\u2019avant, ce qui est un progr\xE8s certain. La mauvaise nouvelle ? Nous obtenons une erreur CUDA inf\xE2me \xE0 la place :"),al=p(),c(tt.$$.fragment),nl=p(),rr=l("p"),sc=a("C\u2019est une mauvaise chose car les erreurs CUDA sont extr\xEAmement difficiles \xE0 d\xE9boguer en g\xE9n\xE9ral. Nous verrons dans une minute comment r\xE9soudre ce probl\xE8me mais terminons d\u2019abord notre analyse de la cr\xE9ation de batchs."),ol=p(),ar=l("p"),tc=a("Si vous \xEAtes s\xFBr que votre collecteur de donn\xE9es est le bon, vous devriez essayer de l\u2019appliquer sur quelques \xE9chantillons de votre jeu de donn\xE9es :"),ll=p(),c(rt.$$.fragment),il=p(),T=l("p"),rc=a("Ce code \xE9chouera parce que le "),Ua=l("code"),ac=a("train_dataset"),nc=a(" contient des colonnes de type "),Na=l("em"),oc=a("string"),lc=a(" que le "),Ma=l("code"),ic=a("Trainer"),uc=a(" supprime habituellement. Vous pouvez les supprimer manuellement ou si vous voulez reproduire exactement ce que le "),Oa=l("code"),pc=a("Trainer"),dc=a(" fait en coulisse, vous pouvez appeler la m\xE9thode "),Va=l("code"),cc=a("Trainer._remove_unused_columns()"),mc=a(" qui fait cela :"),ul=p(),c(at.$$.fragment),pl=p(),nr=l("p"),fc=a("Vous devriez alors \xEAtre en mesure de d\xE9boguer manuellement ce qui se passe dans le collecteur de donn\xE9es si l\u2019erreur persiste."),dl=p(),or=l("p"),vc=a("Maintenant que nous avons d\xE9bogu\xE9 le processus de cr\xE9ation de batch, il est temps d\u2019en passer un dans le mod\xE8le !"),cl=p(),ce=l("h3"),Te=l("a"),Ia=l("span"),c(nt.$$.fragment),hc=p(),Fa=l("span"),_c=a("Passage par le mod\xE8le"),ml=p(),lr=l("p"),bc=a("Vous devriez \xEAtre en mesure d\u2019obtenir un batch en ex\xE9cutant la commande suivante :"),fl=p(),c(ot.$$.fragment),vl=p(),F=l("p"),qc=a("Si vous ex\xE9cutez ce code dans un "),Ga=l("em"),$c=a("notebook"),gc=a(", vous risquez d\u2019obtenir une erreur CUDA similaire \xE0 celle que nous avons vue pr\xE9c\xE9demment, auquel cas vous devrez red\xE9marrer votre "),Wa=l("em"),kc=a("notebook"),jc=a(" et r\xE9ex\xE9cuter le dernier extrait sans la ligne "),Ra=l("code"),Ec=a("trainer.train()"),zc=a(". C\u2019est la deuxi\xE8me chose la plus ennuyeuse \xE0 propos des erreurs CUDA : elles cassent irr\xE9m\xE9diablement votre noyau. La premi\xE8re plus ennuyeuse est le fait qu\u2019elles sont difficiles \xE0 d\xE9boguer."),hl=p(),Se=l("p"),yc=a("Comment cela se fait-il ? Cela tient \xE0 la fa\xE7on dont les GPUs fonctionnent. Ils sont extr\xEAmement efficaces pour ex\xE9cuter un batch d\u2019op\xE9rations en parall\xE8le, mais l\u2019inconv\xE9nient est que lorsque l\u2019une de ces instructions entra\xEEne une erreur, vous ne le savez pas imm\xE9diatement. Ce n\u2019est que lorsque le programme appelle une synchronisation des multiples processus sur le GPU qu\u2019il r\xE9alise que quelque chose s\u2019est mal pass\xE9, de sorte que l\u2019erreur est en fait mentionn\xE9e \xE0 un endroit qui n\u2019a rien \xE0 voir avec ce qui l\u2019a cr\xE9\xE9e. Par exemple, si nous regardons notre "),Ha=l("em"),wc=a("traceback"),xc=a(" pr\xE9c\xE9dent, l\u2019erreur a \xE9t\xE9 soulev\xE9e pendant la passe arri\xE8re, mais nous verrons dans une minute qu\u2019elle provient en fait de quelque chose dans la passe avant."),_l=p(),Le=l("p"),Cc=a("Alors comment d\xE9boguer ces erreurs ? La r\xE9ponse est simple : nous ne le faisons pas. \xC0 moins que votre erreur CUDA ne soit une erreur "),Ba=l("em"),Pc=a("out-of-memory"),Ac=a(" (ce qui signifie qu\u2019il n\u2019y a pas assez de m\xE9moire dans votre GPU), vous devez toujours revenir au CPU pour la d\xE9boguer."),bl=p(),Ue=l("p"),Dc=a("Pour faire cela dans notre cas, nous devons juste remettre le mod\xE8le sur le CPU et l\u2019appeler sur notre batch. Le batch retourn\xE9 par le "),Ya=l("code"),Tc=a("DataLoader"),Sc=a(" n\u2019a pas encore \xE9t\xE9 d\xE9plac\xE9 sur le GPU :"),ql=p(),c(lt.$$.fragment),$l=p(),c(it.$$.fragment),gl=p(),Ne=l("p"),Lc=a("L\u2019image devient plus claire. Au lieu d\u2019avoir une erreur CUDA, nous avons maintenant une "),Ja=l("code"),Uc=a("IndexError"),Nc=a(" dans le calcul de la perte (donc rien \xE0 voir avec la passe arri\xE8re comme nous l\u2019avons dit plus t\xF4t). Plus pr\xE9cis\xE9ment, nous pouvons voir que c\u2019est la cible 2 qui cr\xE9e l\u2019erreur, donc c\u2019est un bon moment pour v\xE9rifier le nombre de labels de notre mod\xE8le :"),kl=p(),c(ut.$$.fragment),jl=p(),c(pt.$$.fragment),El=p(),ir=l("p"),Mc=a("Avec deux \xE9tiquettes, seuls les 0 et les 1 sont autoris\xE9s comme cibles, mais d\u2019apr\xE8s le message d\u2019erreur, nous avons obtenu un 2. Obtenir un 2 est en fait normal : si nous nous souvenons des noms des \xE9tiquettes que nous avons extraits plus t\xF4t, il y en avait trois, donc nous avons les indices 0, 1 et 2 dans notre jeu de donn\xE9es. Le probl\xE8me est que nous n\u2019avons pas indiqu\xE9 cela \xE0 notre mod\xE8le, qui aurait d\xFB \xEAtre cr\xE9\xE9 avec trois \xE9tiquettes. Alors, corrigeons cela !"),zl=p(),c(dt.$$.fragment),yl=p(),Me=l("p"),Oc=a("Nous n\u2019incluons pas encore la ligne "),Ka=l("code"),Vc=a("trainer.train()"),Ic=a(" pour prendre le temps de v\xE9rifier que tout se passe bien. Si nous passons un batch \xE0 notre mod\xE8le, il fonctionne maintenant sans erreur !"),wl=p(),c(ct.$$.fragment),xl=p(),ur=l("p"),Fc=a("L\u2019\xE9tape suivante consiste alors \xE0 revenir au GPU et \xE0 v\xE9rifier que tout fonctionne encore :"),Cl=p(),c(mt.$$.fragment),Pl=p(),Oe=l("p"),Gc=a("Si vous obtenez toujours une erreur, assurez-vous de red\xE9marrer votre "),Qa=l("em"),Wc=a("notebook"),Rc=a(" et d\u2019ex\xE9cuter uniquement la derni\xE8re version du script."),Al=p(),me=l("h3"),Ve=l("a"),Za=l("span"),c(ft.$$.fragment),Hc=p(),Xa=l("span"),Bc=a("Ex\xE9cution d'une \xE9tape d'optimisation"),Dl=p(),pr=l("p"),Yc=a("Maintenant que nous savons que nous pouvons construire des batchs qui passent r\xE9ellement par le mod\xE8le, nous sommes pr\xEAts pour l\u2019\xE9tape suivante du pipeline d\u2019entra\xEEnement : calculer les gradients et effectuer une \xE9tape d\u2019optimisation."),Tl=p(),Ie=l("p"),Jc=a("La premi\xE8re partie est juste une question d\u2019appel de la m\xE9thode "),en=l("code"),Kc=a("backward()"),Qc=a(" sur la perte :"),Sl=p(),c(vt.$$.fragment),Ll=p(),dr=l("p"),Zc=a("Il est plut\xF4t rare d\u2019obtenir une erreur \xE0 ce stade, mais si vous en obtenez une, assurez-vous de retourner au CPU pour obtenir un message d\u2019erreur utile."),Ul=p(),oe=l("p"),Xc=a("Pour effectuer l\u2019\xE9tape d\u2019optimisation, il suffit de cr\xE9er le "),sn=l("code"),em=a("optimizer"),sm=a(" et d\u2019appeler sa m\xE9thode "),tn=l("code"),tm=a("step()"),rm=a(" :"),Nl=p(),c(ht.$$.fragment),Ml=p(),Fe=l("p"),am=a("Encore une fois, si vous utilisez l\u2019optimiseur par d\xE9faut dans le "),rn=l("code"),nm=a("Trainer"),om=a(", vous ne devriez pas avoir d\u2019erreur \xE0 ce stade, mais si vous avez un optimiseur personnalis\xE9, il pourrait y avoir quelques probl\xE8mes \xE0 d\xE9boguer ici. N\u2019oubliez pas de revenir au CPU si vous obtenez une erreur CUDA bizarre \xE0 ce stade. En parlant d\u2019erreurs CUDA, nous avons mentionn\xE9 pr\xE9c\xE9demment un cas particulier. Voyons cela maintenant."),Ol=p(),fe=l("h3"),Ge=l("a"),an=l("span"),c(_t.$$.fragment),lm=p(),cr=l("span"),im=a("G\xE9rer les erreurs "),nn=l("i"),um=a("CUDA out of memory"),Vl=p(),We=l("p"),pm=a("Chaque fois que vous obtenez un message d\u2019erreur qui commence par "),on=l("code"),dm=a("RuntimeError : CUDA out of memory"),cm=a(", cela indique que vous \xEAtes \xE0 court de m\xE9moire GPU. Cela n\u2019est pas directement li\xE9 \xE0 votre code et peut arriver avec un script qui fonctionne parfaitement bien. Cette erreur signifie que vous avez essay\xE9 de mettre trop de choses dans la m\xE9moire interne de votre GPU et que cela a entra\xEEn\xE9 une erreur. Comme pour d\u2019autres erreurs CUDA, vous devrez red\xE9marrer votre noyau pour \xEAtre en mesure d\u2019ex\xE9cuter \xE0 nouveau votre entra\xEEnement."),Il=p(),mr=l("p"),mm=a("Pour r\xE9soudre ce probl\xE8me, il suffit d\u2019utiliser moins d\u2019espace GPU, ce qui est souvent plus facile \xE0 dire qu\u2019\xE0 faire. Tout d\u2019abord, assurez-vous que vous n\u2019avez pas deux mod\xE8les sur le GPU en m\xEAme temps (sauf si cela est n\xE9cessaire pour votre probl\xE8me, bien s\xFBr). Ensuite, vous devriez probablement r\xE9duire la taille de votre batch car elle affecte directement les tailles de toutes les sorties interm\xE9diaires du mod\xE8le et leurs gradients. Si le probl\xE8me persiste, envisagez d\u2019utiliser une version plus petite de votre mod\xE8le."),Fl=p(),c(Re.$$.fragment),Gl=p(),ve=l("h3"),He=l("a"),ln=l("span"),c(bt.$$.fragment),fm=p(),un=l("span"),vm=a("\xC9valuation du mod\xE8le"),Wl=p(),Be=l("p"),hm=a("Maintenant que nous avons r\xE9solu tous les probl\xE8mes li\xE9s \xE0 notre code, tout est parfait et l\u2019entra\xEEnement devrait se d\xE9rouler sans probl\xE8me, n\u2019est-ce pas ? Pas si vite ! Si vous ex\xE9cutez la commande "),pn=l("code"),_m=a("trainer.train()"),bm=a(", tout aura l\u2019air bien au d\xE9but, mais apr\xE8s un moment vous obtiendrez ce qui suit :"),Rl=p(),c(qt.$$.fragment),Hl=p(),c($t.$$.fragment),Bl=p(),fr=l("p"),qm=a("Vous r\xE9aliserez que cette erreur appara\xEEt pendant la phase d\u2019\xE9valuation, donc c\u2019est la derni\xE8re chose que nous aurons besoin de d\xE9boguer."),Yl=p(),Ye=l("p"),$m=a("Vous pouvez ex\xE9cuter la boucle d\u2019\xE9valuation du "),dn=l("code"),gm=a("Trainer"),km=a(" ind\xE9pendamment de l\u2019entra\xEEnement comme ceci :"),Jl=p(),c(gt.$$.fragment),Kl=p(),c(kt.$$.fragment),Ql=p(),c(Je.$$.fragment),Zl=p(),vr=l("p"),jm=a("Avant de tenter de d\xE9boguer un probl\xE8me dans la boucle d\u2019\xE9valuation, vous devez d\u2019abord vous assurer que vous avez examin\xE9 les donn\xE9es, que vous \xEAtes en mesure de former un batch correctement et que vous pouvez ex\xE9cuter votre mod\xE8le sur ces donn\xE9es. Nous avons effectu\xE9 toutes ces \xE9tapes, et le code suivant peut donc \xEAtre ex\xE9cut\xE9 sans erreur :"),Xl=p(),c(jt.$$.fragment),ei=p(),Ke=l("p"),Em=a("L\u2019erreur survient plus tard, \xE0 la fin de la phase d\u2019\xE9valuation, et si nous regardons le "),cn=l("em"),zm=a("traceback"),ym=a(", nous voyons ceci :"),si=p(),c(Et.$$.fragment),ti=p(),G=l("p"),wm=a("Cela nous indique que l\u2019erreur provient du module "),mn=l("code"),xm=a("datasets/metric.py"),Cm=a(" donc c\u2019est un probl\xE8me avec notre fonction "),fn=l("code"),Pm=a("compute_metrics()"),Am=a(". Elle prend un "),vn=l("em"),Dm=a("tuple"),Tm=a(" avec les logits et les labels sous forme de tableaux NumPy, alors essayons de lui fournir cela :"),ri=p(),c(zt.$$.fragment),ai=p(),c(yt.$$.fragment),ni=p(),W=l("p"),Sm=a("Nous obtenons la m\xEAme erreur, donc le probl\xE8me vient bien de cette fonction. Si on regarde son code, on voit qu\u2019elle transmet simplement les "),hn=l("code"),Lm=a("predictions"),Um=a(" et les "),_n=l("code"),Nm=a("labels"),Mm=a(" \xE0 "),bn=l("code"),Om=a("metric.compute()"),Vm=a(". Y a-t-il donc un probl\xE8me avec cette m\xE9thode ? Pas vraiment. Jetons un coup d\u2019oeil rapide aux formes :"),oi=p(),c(wt.$$.fragment),li=p(),c(xt.$$.fragment),ii=p(),Qe=l("p"),Im=a("Nos pr\xE9dictions sont toujours des logits et non les pr\xE9dictions r\xE9elles, c\u2019est pourquoi la m\xE9trique retourne cette erreur (quelque peu obscure). La correction est assez simple, il suffit d\u2019ajouter un argmax dans la fonction "),qn=l("code"),Fm=a("compute_metrics()"),Gm=a(" :"),ui=p(),c(Ct.$$.fragment),pi=p(),c(Pt.$$.fragment),di=p(),hr=l("p"),Wm=a("Maintenant notre erreur est corrig\xE9e ! C\u2019\xE9tait la derni\xE8re, donc notre script va maintenant entra\xEEner un mod\xE8le correctement."),ci=p(),_r=l("p"),Rm=a("Pour r\xE9f\xE9rence, voici le script compl\xE8tement corrig\xE9 :"),mi=p(),c(At.$$.fragment),fi=p(),Ze=l("p"),Hm=a("Dans ce cas, il n\u2019y a plus de probl\xE8me, et notre script va "),$n=l("em"),Bm=a("finetuner"),Ym=a(" un mod\xE8le qui devrait donner des r\xE9sultats raisonnables. Mais que faire lorsque l\u2019entra\xEEnement se d\xE9roule sans erreur et que le mod\xE8le entra\xEEn\xE9 n\u2019est pas du tout performant ? C\u2019est la partie la plus difficile de l\u2019apprentissage automatique et nous allons vous montrer quelques techniques qui peuvent vous aider."),vi=p(),c(Xe.$$.fragment),hi=p(),he=l("h2"),es=l("a"),gn=l("span"),c(Dt.$$.fragment),Jm=p(),kn=l("span"),Km=a("D\xE9boguer les erreurs silencieuses pendant l'entra\xEEnement"),_i=p(),br=l("p"),Qm=a("Que peut-on faire pour d\xE9boguer un entra\xEEnement qui se termine sans erreur mais qui ne donne pas de bons r\xE9sultats ? Nous allons vous donner quelques pistes ici, mais sachez que ce type de d\xE9bogage est la partie la plus difficile de l\u2019apprentissage automatique et qu\u2019il n\u2019y a pas de r\xE9ponse magique."),bi=p(),_e=l("h3"),ss=l("a"),jn=l("span"),c(Tt.$$.fragment),Zm=p(),En=l("span"),Xm=a("V\xE9rifiez vos donn\xE9es (encore !)"),qi=p(),ts=l("p"),ef=a("Votre mod\xE8le n\u2019apprendra quelque chose que s\u2019il est r\xE9ellement possible d\u2019apprendre quelque chose de vos donn\xE9es. Si un "),zn=l("em"),sf=a("bug"),tf=a(" corrompt les donn\xE9es ou si les \xE9tiquettes sont attribu\xE9es de mani\xE8re al\xE9atoire, il est tr\xE8s probable que vous n\u2019obtiendrez aucun entra\xEEnement de mod\xE8le sur votre jeu de donn\xE9es. Commencez donc toujours par rev\xE9rifier vos entr\xE9es et \xE9tiquettes d\xE9cod\xE9es, et posez-vous les questions suivantes :"),$i=p(),R=l("ul"),yn=l("li"),rf=a("les donn\xE9es d\xE9cod\xE9es sont-elles compr\xE9hensibles ?"),af=p(),wn=l("li"),nf=a("\xEAtes-vous d\u2019accord avec les \xE9tiquettes ?"),of=p(),xn=l("li"),lf=a("y a-t-il une \xE9tiquette qui est plus courante que les autres ?"),uf=p(),Cn=l("li"),pf=a("quelle devrait \xEAtre la perte/m\xE9trique si le mod\xE8le pr\xE9disait une r\xE9ponse al\xE9atoire/toujours la m\xEAme r\xE9ponse ?"),gi=p(),c(rs.$$.fragment),ki=p(),as=l("p"),df=a("Apr\xE8s avoir examin\xE9 vos donn\xE9es, examinez quelques-unes des pr\xE9dictions du mod\xE8le. Si votre mod\xE8le produit des "),Pn=l("em"),cf=a("tokens"),mf=a(", essayez aussi de les d\xE9coder ! Si le mod\xE8le pr\xE9dit toujours la m\xEAme chose, cela peut \xEAtre d\xFB au fait que votre jeu de donn\xE9es est biais\xE9 en faveur d\u2019une cat\xE9gorie (pour les probl\xE8mes de classification). Des techniques telles que le sur\xE9chantillonnage des classes rares peuvent aider. D\u2019autre part, cela peut \xE9galement \xEAtre d\xFB \xE0 des probl\xE8mes d\u2019entra\xEEnement tels que de mauvais r\xE9glages des hyperparam\xE8tres."),ji=p(),qr=l("p"),ff=a("Si la perte/la m\xE9trique que vous obtenez sur votre mod\xE8le initial avant entra\xEEnement est tr\xE8s diff\xE9rente de la perte/la m\xE9trique \xE0 laquelle vous vous attendez pour des pr\xE9dictions al\xE9atoires, v\xE9rifiez la fa\xE7on dont votre perte ou votre m\xE9trique est calcul\xE9e. Il y a probablement un bug. Si vous utilisez plusieurs pertes que vous ajoutez \xE0 la fin, assurez-vous qu\u2019elles sont de la m\xEAme \xE9chelle."),Ei=p(),$r=l("p"),vf=a("Lorsque vous \xEAtes s\xFBr que vos donn\xE9es sont parfaites, vous pouvez voir si le mod\xE8le est capable de s\u2019entra\xEEner sur elles gr\xE2ce \xE0 un test simple."),zi=p(),be=l("h3"),ns=l("a"),An=l("span"),c(St.$$.fragment),hf=p(),Dn=l("span"),_f=a("Surentra\xEEnement du mod\xE8le sur un seul batch"),yi=p(),gr=l("p"),bf=a("Le surentra\xEEnement est g\xE9n\xE9ralement une chose que nous essayons d\u2019\xE9viter lors de l\u2019entra\xEEnement car cela signifie que le mod\xE8le n\u2019apprend pas \xE0 reconna\xEEtre les caract\xE9ristiques g\xE9n\xE9rales que nous voulons qu\u2019il reconnaisse et se contente de m\xE9moriser les \xE9chantillons d\u2019entra\xEEnement. Cependant, essayer d\u2019entra\xEEner votre mod\xE8le sur un batch encore et encore est un bon test pour v\xE9rifier si le probl\xE8me tel que vous l\u2019avez formul\xE9 peut \xEAtre r\xE9solu par le mod\xE8le que vous essayez d\u2019entra\xEEner. Cela vous aidera \xE9galement \xE0 voir si votre taux d\u2019apprentissage initial est trop \xE9lev\xE9."),wi=p(),le=l("p"),qf=a("Une fois que vous avez d\xE9fini votre "),Tn=l("code"),$f=a("mod\xE8le"),gf=a(", c\u2019est tr\xE8s facile. Il suffit de prendre un batch de donn\xE9es d\u2019entra\xEEnement, puis de le traiter comme votre jeu de donn\xE9es entier que vous "),Sn=l("em"),kf=a("finetunez"),jf=a(" sur un grand nombre d\u2019\xE9poques :"),xi=p(),c(Lt.$$.fragment),Ci=p(),c(os.$$.fragment),Pi=p(),ls=l("p"),Ef=a("Le mod\xE8le r\xE9sultant devrait avoir des r\xE9sultats proches de la perfection sur le m\xEAme "),Ln=l("code"),zf=a("batch"),yf=a(". Calculons la m\xE9trique sur les pr\xE9dictions r\xE9sultantes :"),Ai=p(),c(Ut.$$.fragment),Di=p(),c(Nt.$$.fragment),Ti=p(),kr=l("p"),wf=a("100% de pr\xE9cision, voil\xE0 un bel exemple de surentra\xEEnement (ce qui signifie que si vous essayez votre mod\xE8le sur n\u2019importe quelle autre phrase, il vous donnera tr\xE8s probablement une mauvaise r\xE9ponse) !"),Si=p(),jr=l("p"),xf=a("Si vous ne parvenez pas \xE0 ce que votre mod\xE8le obtienne des r\xE9sultats parfaits comme celui-ci, cela signifie qu\u2019il y a quelque chose qui ne va pas dans la fa\xE7on dont vous avez formul\xE9 le probl\xE8me ou dans vos donn\xE9es. Vous devez donc y rem\xE9dier. Ce n\u2019est que lorsque vous parviendrez \xE0 passer le test de surentra\xEEnement que vous pourrez \xEAtre s\xFBr que votre mod\xE8le peut r\xE9ellement apprendre quelque chose."),Li=p(),c(is.$$.fragment),Ui=p(),qe=l("h3"),us=l("a"),Un=l("span"),c(Mt.$$.fragment),Cf=p(),Nn=l("span"),Pf=a("Ne r\xE9glez rien tant que vous n'avez pas une premi\xE8re ligne de base"),Ni=p(),ps=l("p"),Af=a("Le r\xE9glage des hyperparam\xE8tres est toujours consid\xE9r\xE9 comme la partie la plus difficile de l\u2019apprentissage automatique mais c\u2019est juste la derni\xE8re \xE9tape pour vous aider \xE0 gagner un peu sur la m\xE9trique. La plupart du temps, les hyperparam\xE8tres par d\xE9faut du "),Mn=l("code"),Df=a("Trainer"),Tf=a(" fonctionneront tr\xE8s bien pour vous donner de bons r\xE9sultats. Donc ne vous lancez pas dans une recherche d\u2019hyperparam\xE8tres longue et co\xFBteuse jusqu\u2019\xE0 ce que vous ayez quelque chose qui batte la ligne de base que vous avez sur votre jeu de donn\xE9es."),Mi=p(),ds=l("p"),Sf=a("Une fois que vous avez un mod\xE8le suffisamment bon, vous pouvez commencer \xE0 le "),On=l("em"),Lf=a("finetuner"),Uf=a(" un peu. N\u2019essayez pas de lancer un millier d\u2019ex\xE9cutions avec diff\xE9rents hyperparam\xE8tres mais comparez quelques ex\xE9cutions avec diff\xE9rentes valeurs pour un hyperparam\xE8tre afin de vous faire une id\xE9e de celui qui a le plus d\u2019impact."),Oi=p(),Er=l("p"),Nf=a("Si vous modifiez le mod\xE8le lui-m\xEAme, restez simple et n\u2019essayez rien que vous ne puissiez raisonnablement justifier. Veillez toujours \xE0 revenir au test de surentra\xEEnement pour v\xE9rifier que votre modification n\u2019a pas eu de cons\xE9quences inattendues."),Vi=p(),$e=l("h3"),cs=l("a"),Vn=l("span"),c(Ot.$$.fragment),Mf=p(),In=l("span"),Of=a("Demander de l'aide"),Ii=p(),ms=l("p"),Vf=a("Nous esp\xE9rons que vous avez trouv\xE9 dans cette section des conseils qui vous ont aid\xE9 \xE0 r\xE9soudre votre probl\xE8me. Si ce n\u2019est pas le cas, n\u2019oubliez pas que vous pouvez toujours demander de l\u2019aide \xE0 la communaut\xE9 sur le "),Vt=l("a"),If=a("forum"),Ff=a("."),Fi=p(),zr=l("p"),Gf=a("Voici quelques ressources (en anglais) suppl\xE9mentaires qui peuvent s\u2019av\xE9rer utiles :"),Gi=p(),H=l("ul"),yr=l("li"),It=l("a"),Wf=a("La reproductibilit\xE9 comme vecteur des meilleures pratiques d\u2019ing\xE9nierie"),Rf=a(" par Joel Grus"),Hf=p(),wr=l("li"),Ft=l("a"),Bf=a("Liste de contr\xF4le pour le d\xE9bogage des r\xE9seaux de neurones"),Yf=a(" par Cecelia Shao"),Jf=p(),xr=l("li"),Gt=l("a"),Kf=a("Comment tester unitairement le code d\u2019apprentissage automatique"),Qf=a(" par Chase Roberts"),Zf=p(),Cr=l("li"),Wt=l("a"),Xf=a("Une recette pour entra\xEEner les r\xE9seaux de neurones"),ev=a(" par Andrej Karpathy"),Wi=p(),B=l("p"),sv=a("Bien s\xFBr, tous les probl\xE8mes rencontr\xE9s lors de l\u2019entra\xEEnement ne sont pas forc\xE9ment de votre faute ! Si vous rencontrez quelque chose dans la biblioth\xE8que \u{1F917} "),Fn=l("em"),tv=a("Transformers"),rv=a(" ou \u{1F917} "),Gn=l("em"),av=a("Datasets"),nv=a(" qui ne semble pas correct, vous avez peut-\xEAtre trouver un "),Wn=l("em"),ov=a("bug"),lv=a(". Vous devez absolument nous en parler pour qu\u2019on puisse le corriger. Dans la section suivante, nous allons vous expliquer exactement comment faire."),this.h()},l(e){const r=fb('[data-svelte="svelte-1phssyn"]',document.head);b=i(r,"META",{name:!0,content:!0}),r.forEach(s),E=d(e),m(g.$$.fragment,e),j=d(e),y=i(e,"H1",{class:!0});var Rt=u(y);k=i(Rt,"A",{id:!0,class:!0,href:!0});var Rn=u(k);z=i(Rn,"SPAN",{});var Hn=u(z);m(w.$$.fragment,Hn),Hn.forEach(s),Rn.forEach(s),S=d(Rt),x=i(Rt,"SPAN",{});var Bn=u(x);Z=n(Bn,"D\xE9bogage du pipeline d'entra\xEEnement"),Bn.forEach(s),Rt.forEach(s),N=d(e),m(C.$$.fragment,e),js=d(e),L=i(e,"P",{});var Q=u(L);Bt=n(Q,"Vous avez \xE9crit un magnifique script pour entra\xEEner ou "),Or=i(Q,"EM",{});var Yn=u(Or);Du=n(Yn,"finetuner"),Yn.forEach(s),Tu=n(Q," un mod\xE8le sur une t\xE2che donn\xE9e en suivant consciencieusement les conseils du "),Yt=i(Q,"A",{href:!0});var Jn=u(Yt);Su=n(Jn,"chapitre 7"),Jn.forEach(s),Lu=n(Q,". Mais lorsque vous lancez la commande "),Vr=i(Q,"CODE",{});var Kn=u(Vr);Uu=n(Kn,"model.fit()"),Kn.forEach(s),Nu=n(Q,", quelque chose d\u2019horrible se produit : vous obtenez une erreur \u{1F631} ! Ou pire, tout semble aller bien et l\u2019entra\xEEnement se d\xE9roule sans erreur mais le mod\xE8le r\xE9sultant est mauvais. Dans cette section, nous allons vous montrer ce que vous pouvez faire pour d\xE9boguer ce genre de probl\xE8mes."),Q.forEach(s),Qn=d(e),ue=i(e,"H2",{class:!0});var Hi=u(ue);ge=i(Hi,"A",{id:!0,class:!0,href:!0});var mv=u(ge);Ir=i(mv,"SPAN",{});var fv=u(Ir);m(Es.$$.fragment,fv),fv.forEach(s),mv.forEach(s),Mu=d(Hi),Fr=i(Hi,"SPAN",{});var vv=u(Fr);Ou=n(vv,"D\xE9boguer le pipeline d'entra\xEEnement"),vv.forEach(s),Hi.forEach(s),Zn=d(e),m(zs.$$.fragment,e),Xn=d(e),X=i(e,"P",{});var Pr=u(X);Vu=n(Pr,"Le probl\xE8me lorsque vous rencontrez une erreur dans "),Gr=i(Pr,"CODE",{});var hv=u(Gr);Iu=n(hv,"trainer.train()"),hv.forEach(s),Fu=n(Pr," est qu\u2019elle peut provenir de plusieurs sources, car la fonction "),Wr=i(Pr,"CODE",{});var _v=u(Wr);Gu=n(_v,"Trainer"),_v.forEach(s),Wu=n(Pr," assemble g\xE9n\xE9ralement des batchs de choses. Elle convertit les jeux de donn\xE9es en chargeurs de donn\xE9es donc le probl\xE8me pourrait \xEAtre quelque chose d\u2019erron\xE9 dans votre jeu de donn\xE9es, ou un probl\xE8me en essayant de regrouper les \xE9l\xE9ments des jeux de donn\xE9es ensemble. Ensuite, elle prend un batch de donn\xE9es et le transmet au mod\xE8le, le probl\xE8me peut donc se situer dans le code du mod\xE8le. Apr\xE8s cela, elle calcule les gradients et effectue l\u2019\xE9tape d\u2019optimisation, le probl\xE8me peut donc \xE9galement se situer dans votre optimiseur. Et m\xEAme si tout se passe bien pendant l\u2019entra\xEEnement, quelque chose peut encore mal tourner pendant l\u2019\xE9valuation si votre m\xE9trique pose probl\xE8me."),Pr.forEach(s),eo=d(e),ke=i(e,"P",{});var Bi=u(ke);Ru=n(Bi,"La meilleure fa\xE7on de d\xE9boguer une erreur qui survient dans "),Rr=i(Bi,"CODE",{});var bv=u(Rr);Hu=n(bv,"trainer.train()"),bv.forEach(s),Bu=n(Bi," est de passer manuellement en revue tout le pipeline pour voir o\xF9 les choses se sont mal pass\xE9es. L\u2019erreur est alors souvent tr\xE8s facile \xE0 r\xE9soudre."),Bi.forEach(s),so=d(e),ee=i(e,"P",{});var Ar=u(ee);Yu=n(Ar,"Pour le d\xE9montrer, nous utiliserons le script suivant qui tente de "),Hr=i(Ar,"EM",{});var qv=u(Hr);Ju=n(qv,"finetuner"),qv.forEach(s),Ku=n(Ar," un mod\xE8le DistilBERT sur le "),ys=i(Ar,"A",{href:!0,rel:!0});var $v=u(ys);Qu=n($v,"jeu de donn\xE9es MNLI"),$v.forEach(s),Zu=n(Ar," :"),Ar.forEach(s),to=d(e),m(ws.$$.fragment,e),ro=d(e),Jt=i(e,"P",{});var gv=u(Jt);Xu=n(gv,"Si vous essayez de l\u2019ex\xE9cuter, vous serez confront\xE9 \xE0 une erreur plut\xF4t cryptique :"),gv.forEach(s),ao=d(e),m(xs.$$.fragment,e),no=d(e),pe=i(e,"H3",{class:!0});var Yi=u(pe);je=i(Yi,"A",{id:!0,class:!0,href:!0});var kv=u(je);Br=i(kv,"SPAN",{});var jv=u(Br);m(Cs.$$.fragment,jv),jv.forEach(s),kv.forEach(s),ep=d(Yi),Yr=i(Yi,"SPAN",{});var Ev=u(Yr);sp=n(Ev,"V\xE9rifiez vos donn\xE9es"),Ev.forEach(s),Yi.forEach(s),oo=d(e),Ee=i(e,"P",{});var Ji=u(Ee);tp=n(Ji,"Cela va sans dire, mais si vos donn\xE9es sont corrompues, le "),Jr=i(Ji,"CODE",{});var zv=u(Jr);rp=n(zv,"Trainer"),zv.forEach(s),ap=n(Ji," ne sera pas capable de former des batchs et encore moins d\u2019entra\xEEner votre mod\xE8le. Donc, tout d\u2019abord, vous devez jeter un coup d\u2019oeil \xE0 ce qui se trouve dans votre jeu d\u2019entra\xEEnement."),Ji.forEach(s),lo=d(e),ze=i(e,"P",{});var Ki=u(ze);np=n(Ki,"Pour \xE9viter d\u2019innombrables heures pass\xE9es \xE0 essayer de corriger quelque chose qui n\u2019est pas la source du bug, nous vous recommandons d\u2019utiliser "),Kr=i(Ki,"CODE",{});var yv=u(Kr);op=n(yv,"trainer.train_dataset"),yv.forEach(s),lp=n(Ki," pour vos v\xE9rifications et rien d\u2019autre. Faisons donc cela ici :"),Ki.forEach(s),io=d(e),m(Ps.$$.fragment,e),uo=d(e),m(As.$$.fragment,e),po=d(e),se=i(e,"P",{});var Dr=u(se);ip=n(Dr,"Vous remarquez quelque chose d\u2019anormal ? Ceci, en conjonction avec le message d\u2019erreur sur les "),Qr=i(Dr,"CODE",{});var wv=u(Qr);up=n(wv,"input_ids"),wv.forEach(s),pp=n(Dr," manquants, devrait vous faire r\xE9aliser que ce sont des textes et non des nombres que le mod\xE8le peut comprendre. Ici, l\u2019erreur originale est tr\xE8s trompeuse parce que le "),Zr=i(Dr,"CODE",{});var xv=u(Zr);dp=n(xv,"Trainer"),xv.forEach(s),cp=n(Dr," enl\xE8ve automatiquement les colonnes qui ne correspondent pas \xE0 la signature du mod\xE8le (c\u2019est-\xE0-dire, les arguments attendus par le mod\xE8le). Cela signifie qu\u2019ici, tout, sauf les \xE9tiquettes, a \xE9t\xE9 \xE9limin\xE9. Il n\u2019y avait donc aucun probl\xE8me \xE0 cr\xE9er des batchs et \xE0 les envoyer ensuite au mod\xE8le, qui s\u2019est plaint \xE0 son tour de ne pas avoir re\xE7u les bons arguments."),Dr.forEach(s),co=d(e),A=i(e,"P",{});var Y=u(A);mp=n(Y,"Pourquoi les donn\xE9es n\u2019ont-elles pas \xE9t\xE9 trait\xE9es ? Nous avons utilis\xE9 la m\xE9thode "),Xr=i(Y,"CODE",{});var Cv=u(Xr);fp=n(Cv,"Dataset.map()"),Cv.forEach(s),vp=n(Y," sur les jeux de donn\xE9es pour appliquer le "),ea=i(Y,"EM",{});var Pv=u(ea);hp=n(Pv,"tokenizer"),Pv.forEach(s),_p=n(Y," sur chaque \xE9chantillon. Mais si vous regardez attentivement le code, vous verrez que nous avons fait une erreur en passant les ensembles d\u2019entra\xEEnement et d\u2019\xE9valuation au "),sa=i(Y,"CODE",{});var Av=u(sa);bp=n(Av,"Trainer"),Av.forEach(s),qp=n(Y,". Au lieu d\u2019utiliser "),ta=i(Y,"CODE",{});var Dv=u(ta);$p=n(Dv,"tokenized_datasets"),Dv.forEach(s),gp=n(Y," ici, nous avons utilis\xE9 "),ra=i(Y,"CODE",{});var Tv=u(ra);kp=n(Tv,"raw_datasets"),Tv.forEach(s),jp=n(Y," \u{1F926}. Alors corrigeons \xE7a !"),Y.forEach(s),mo=d(e),m(Ds.$$.fragment,e),fo=d(e),Kt=i(e,"P",{});var Sv=u(Kt);Ep=n(Sv,"Ce nouveau code donnera maintenant une erreur diff\xE9rente (c\u2019est un progr\xE8s !) :"),Sv.forEach(s),vo=d(e),m(Ts.$$.fragment,e),ho=d(e),ye=i(e,"P",{});var Qi=u(ye);zp=n(Qi,"En regardant le "),aa=i(Qi,"EM",{});var Lv=u(aa);yp=n(Lv,"traceback"),Lv.forEach(s),wp=n(Qi,", nous pouvons voir que l\u2019erreur se produit dans l\u2019\xE9tape de collationnement des donn\xE9es :"),Qi.forEach(s),_o=d(e),m(Ss.$$.fragment,e),bo=d(e),Qt=i(e,"P",{});var Uv=u(Qt);xp=n(Uv,"Donc, nous devrions passer \xE0 cela. Mais avant finissons d\u2019inspecter nos donn\xE9es, pour \xEAtre s\xFBrs \xE0 100% qu\u2019elles sont correctes."),Uv.forEach(s),qo=d(e),we=i(e,"P",{});var Zi=u(we);Cp=n(Zi,"Une chose que vous devriez toujours faire lorsque vous d\xE9boguez une session d\u2019entra\xEEnement est de jeter un coup d\u2019oeil aux entr\xE9es d\xE9cod\xE9es de votre mod\xE8le. Nous ne pouvons pas donner un sens aux chiffres que nous lui fournissons directement, nous devons donc examiner ce que ces chiffres repr\xE9sentent. Dans le domaine de la vision par ordinateur cela signifie regarder les images d\xE9cod\xE9es des pixels que vous passez, dans le domaine de la parole cela signifie \xE9couter les \xE9chantillons audio d\xE9cod\xE9s, et pour notre exemple de NLP cela signifie utiliser notre "),na=i(Zi,"EM",{});var Nv=u(na);Pp=n(Nv,"tokenizer"),Nv.forEach(s),Ap=n(Zi," pour d\xE9coder les entr\xE9es :"),Zi.forEach(s),$o=d(e),m(Ls.$$.fragment,e),go=d(e),m(Us.$$.fragment,e),ko=d(e),Zt=i(e,"P",{});var Mv=u(Zt);Dp=n(Mv,"Cela semble correct. Vous devriez faire cela pour toutes les cl\xE9s dans les entr\xE9es :"),Mv.forEach(s),jo=d(e),m(Ns.$$.fragment,e),Eo=d(e),m(Ms.$$.fragment,e),zo=d(e),U=i(e,"P",{});var ie=u(U);Tp=n(ie,"Notez que les cl\xE9s qui ne correspondent pas \xE0 des entr\xE9es accept\xE9es par le mod\xE8le seront automatiquement \xE9cart\xE9es, donc ici nous ne garderons que "),oa=i(ie,"CODE",{});var Ov=u(oa);Sp=n(Ov,"input_ids"),Ov.forEach(s),Lp=n(ie,", "),la=i(ie,"CODE",{});var Vv=u(la);Up=n(Vv,"attention_mask"),Vv.forEach(s),Np=n(ie,", et "),ia=i(ie,"CODE",{});var Iv=u(ia);Mp=n(Iv,"label"),Iv.forEach(s),Op=n(ie," (qui sera renomm\xE9 "),ua=i(ie,"CODE",{});var Fv=u(ua);Vp=n(Fv,"labels"),Fv.forEach(s),Ip=n(ie,"). Pour rev\xE9rifier la signature du mod\xE8le, vous pouvez imprimer la classe de votre mod\xE8le, puis aller consulter sa documentation :"),ie.forEach(s),yo=d(e),m(Os.$$.fragment,e),wo=d(e),m(Vs.$$.fragment,e),xo=d(e),te=i(e,"P",{});var Tr=u(te);Fp=n(Tr,"Donc dans notre cas, nous pouvons v\xE9rifier les param\xE8tres accept\xE9s sur "),Is=i(Tr,"A",{href:!0,rel:!0});var Gv=u(Is);Gp=n(Gv,"cette page"),Gv.forEach(s),Wp=n(Tr,". Le "),pa=i(Tr,"CODE",{});var Wv=u(pa);Rp=n(Wv,"Trainer"),Wv.forEach(s),Hp=n(Tr," va \xE9galement enregistrer les colonnes qu\u2019il rejette."),Tr.forEach(s),Co=d(e),xe=i(e,"P",{});var Xi=u(xe);Bp=n(Xi,"Nous avons v\xE9rifi\xE9 que les identifiants d\u2019entr\xE9e sont corrects en les d\xE9codant. Ensuite, il y a le "),da=i(Xi,"CODE",{});var Rv=u(da);Yp=n(Rv,"attention_mask"),Rv.forEach(s),Jp=n(Xi," :"),Xi.forEach(s),Po=d(e),m(Fs.$$.fragment,e),Ao=d(e),m(Gs.$$.fragment,e),Do=d(e),Ce=i(e,"P",{});var eu=u(Ce);Kp=n(eu,"Comme nous n\u2019avons pas appliqu\xE9 de "),ca=i(eu,"EM",{});var Hv=u(ca);Qp=n(Hv,"padding"),Hv.forEach(s),Zp=n(eu," dans notre pr\xE9traitement, cela semble parfaitement naturel. Pour \xEAtre s\xFBr qu\u2019il n\u2019y a pas de probl\xE8me avec ce masque d\u2019attention, v\xE9rifions qu\u2019il est de la m\xEAme longueur que nos identifiants d\u2019entr\xE9e :"),eu.forEach(s),To=d(e),m(Ws.$$.fragment,e),So=d(e),m(Rs.$$.fragment,e),Lo=d(e),Xt=i(e,"P",{});var Bv=u(Xt);Xp=n(Bv,"C\u2019est bien ! Enfin, v\xE9rifions notre \xE9tiquette :"),Bv.forEach(s),Uo=d(e),m(Hs.$$.fragment,e),No=d(e),m(Bs.$$.fragment,e),Mo=d(e),re=i(e,"P",{});var Sr=u(re);ed=n(Sr,"Comme les identifiants d\u2019entr\xE9e, c\u2019est un nombre qui n\u2019a pas vraiment de sens en soi. Comme nous l\u2019avons vu pr\xE9c\xE9demment, la correspondance entre les entiers et les noms d\u2019\xE9tiquettes est stock\xE9e dans l\u2019attribut "),ma=i(Sr,"CODE",{});var Yv=u(ma);sd=n(Yv,"names"),Yv.forEach(s),td=n(Sr," de la "),fa=i(Sr,"EM",{});var Jv=u(fa);rd=n(Jv,"caract\xE9ristique"),Jv.forEach(s),ad=n(Sr," correspondante du jeu de donn\xE9es :"),Sr.forEach(s),Oo=d(e),m(Ys.$$.fragment,e),Vo=d(e),m(Js.$$.fragment,e),Io=d(e),ae=i(e,"P",{});var Lr=u(ae);nd=n(Lr,"Donc "),va=i(Lr,"CODE",{});var Kv=u(va);od=n(Kv,"1"),Kv.forEach(s),ld=n(Lr," signifie "),ha=i(Lr,"CODE",{});var Qv=u(ha);id=n(Qv,"neutral"),Qv.forEach(s),ud=n(Lr,", ce qui signifie que les deux phrases que nous avons vues ci-dessus ne sont pas en contradiction : la premi\xE8re n\u2019implique pas la seconde. Cela semble correct !"),Lr.forEach(s),Fo=d(e),Pe=i(e,"P",{});var su=u(Pe);pd=n(su,"Nous n\u2019avons pas de "),_a=i(su,"EM",{});var Zv=u(_a);dd=n(Zv,"token"),Zv.forEach(s),cd=n(su," de type identifiant ici puisque DistilBERT ne les attend pas. Si vous en avez dans votre mod\xE8le, vous devriez \xE9galement vous assurer qu\u2019ils correspondent correctement \xE0 l\u2019endroit o\xF9 se trouvent la premi\xE8re et la deuxi\xE8me phrase dans l\u2019entr\xE9e."),su.forEach(s),Go=d(e),m(Ae.$$.fragment,e),Wo=d(e),er=i(e,"P",{});var Xv=u(er);md=n(Xv,"Ici nous ne v\xE9rifions que le jeu d\u2019entra\xEEnement. Vous devez bien s\xFBr v\xE9rifier de la m\xEAme fa\xE7on les jeux de validation et de test."),Xv.forEach(s),Ro=d(e),sr=i(e,"P",{});var eh=u(sr);fd=n(eh,"Maintenant que nous savons que nos jeux de donn\xE9es sont bons, il est temps de v\xE9rifier l\u2019\xE9tape suivante du pipeline d\u2019entra\xEEnement."),eh.forEach(s),Ho=d(e),de=i(e,"H3",{class:!0});var tu=u(de);De=i(tu,"A",{id:!0,class:!0,href:!0});var sh=u(De);ba=i(sh,"SPAN",{});var th=u(ba);m(Ks.$$.fragment,th),th.forEach(s),sh.forEach(s),vd=d(tu),qa=i(tu,"SPAN",{});var rh=u(qa);hd=n(rh,"Des jeux de donn\xE9es aux chargeurs de donn\xE9es"),rh.forEach(s),tu.forEach(s),Bo=d(e),D=i(e,"P",{});var J=u(D);_d=n(J,"La prochaine chose qui peut mal tourner dans le pipeline d\u2019entra\xEEnement est lorsque le "),$a=i(J,"CODE",{});var ah=u($a);bd=n(ah,"Trainer"),ah.forEach(s),qd=n(J," essaie de former des batchs \xE0 partir du jeu d\u2019entra\xEEnement ou de validation. Une fois que vous \xEAtes s\xFBr que les jeux de donn\xE9es du "),ga=i(J,"CODE",{});var nh=u(ga);$d=n(nh,"Trainer"),nh.forEach(s),gd=n(J," sont corrects, vous pouvez essayer de former manuellement un batch en ex\xE9cutant ce qui suit (remplacez "),ka=i(J,"CODE",{});var oh=u(ka);kd=n(oh,"train"),oh.forEach(s),jd=n(J," par "),ja=i(J,"CODE",{});var lh=u(ja);Ed=n(lh,"eval"),lh.forEach(s),zd=n(J," pour le "),Ea=i(J,"EM",{});var ih=u(Ea);yd=n(ih,"dataloader"),ih.forEach(s),wd=n(J," de validation) :"),J.forEach(s),Yo=d(e),m(Qs.$$.fragment,e),Jo=d(e),ne=i(e,"P",{});var Ur=u(ne);xd=n(Ur,"Ce code cr\xE9e le "),za=i(Ur,"EM",{});var uh=u(za);Cd=n(uh,"dataloader"),uh.forEach(s),Pd=n(Ur," d\u2019entra\xEEnement puis le parcourt en s\u2019arr\xEAtant \xE0 la premi\xE8re it\xE9ration. Si le code s\u2019ex\xE9cute sans erreur, vous avez le premier batch d\u2019entra\xEEnement que vous pouvez inspecter, et si le code se trompe, vous \xEAtes s\xFBr que le probl\xE8me se situe dans le "),ya=i(Ur,"EM",{});var ph=u(ya);Ad=n(ph,"dataloader"),ph.forEach(s),Dd=n(Ur,", comme c\u2019est le cas ici :"),Ur.forEach(s),Ko=d(e),m(Zs.$$.fragment,e),Qo=d(e),O=i(e,"P",{});var fs=u(O);Td=n(fs,"L\u2019inspection de la derni\xE8re image du "),wa=i(fs,"EM",{});var dh=u(wa);Sd=n(dh,"traceback"),dh.forEach(s),Ld=n(fs," devrait suffire \xE0 vous donner un indice mais creusons un peu plus. La plupart des probl\xE8mes lors de la cr\xE9ation d\u2019un batch sont dus \xE0 l\u2019assemblage des exemples en un seul batch. La premi\xE8re chose \xE0 v\xE9rifier en cas de doute est le "),xa=i(fs,"CODE",{});var ch=u(xa);Ud=n(ch,"collate_fn"),ch.forEach(s),Nd=n(fs," utilis\xE9 par votre "),Ca=i(fs,"CODE",{});var mh=u(Ca);Md=n(mh,"DataLoader"),mh.forEach(s),Od=n(fs," :"),fs.forEach(s),Zo=d(e),m(Xs.$$.fragment,e),Xo=d(e),m(et.$$.fragment,e),el=d(e),V=i(e,"P",{});var vs=u(V);Vd=n(vs,"C\u2019est donc "),Pa=i(vs,"CODE",{});var fh=u(Pa);Id=n(fh,"default_data_collator"),fh.forEach(s),Fd=n(vs,", mais ce n\u2019est pas ce que nous voulons dans ce cas. Nous voulons rembourrer nos exemples \xE0 la phrase la plus longue du batch, ce qui est fait par "),Aa=i(vs,"CODE",{});var vh=u(Aa);Gd=n(vh,"DataCollatorWithPadding"),vh.forEach(s),Wd=n(vs,". Et cette assembleur de donn\xE9es est cens\xE9 \xEAtre utilis\xE9 par d\xE9faut par le "),Da=i(vs,"CODE",{});var hh=u(Da);Rd=n(hh,"Trainer"),hh.forEach(s),Hd=n(vs,", alors pourquoi n\u2019est-il pas utilis\xE9 ici ?"),vs.forEach(s),sl=d(e),I=i(e,"P",{});var hs=u(I);Bd=n(hs,"La r\xE9ponse est que nous n\u2019avons pas pass\xE9 le "),Ta=i(hs,"CODE",{});var _h=u(Ta);Yd=n(_h,"tokenizer"),_h.forEach(s),Jd=n(hs," au "),Sa=i(hs,"CODE",{});var bh=u(Sa);Kd=n(bh,"Trainer"),bh.forEach(s),Qd=n(hs,", donc il ne pouvait pas cr\xE9er le "),La=i(hs,"CODE",{});var qh=u(La);Zd=n(qh,"DataCollatorWithPadding"),qh.forEach(s),Xd=n(hs," que nous voulons. En pratique, il ne faut jamais h\xE9siter \xE0 transmettre explicitement l\u2019assembleur de donn\xE9es que l\u2019on veut utiliser pour \xEAtre s\xFBr d\u2019\xE9viter ce genre d\u2019erreurs. Adaptons notre code pour faire exactement cela :"),hs.forEach(s),tl=d(e),m(st.$$.fragment,e),rl=d(e),tr=i(e,"P",{});var $h=u(tr);ec=n($h,"La bonne nouvelle ? Nous n\u2019avons plus la m\xEAme erreur qu\u2019avant, ce qui est un progr\xE8s certain. La mauvaise nouvelle ? Nous obtenons une erreur CUDA inf\xE2me \xE0 la place :"),$h.forEach(s),al=d(e),m(tt.$$.fragment,e),nl=d(e),rr=i(e,"P",{});var gh=u(rr);sc=n(gh,"C\u2019est une mauvaise chose car les erreurs CUDA sont extr\xEAmement difficiles \xE0 d\xE9boguer en g\xE9n\xE9ral. Nous verrons dans une minute comment r\xE9soudre ce probl\xE8me mais terminons d\u2019abord notre analyse de la cr\xE9ation de batchs."),gh.forEach(s),ol=d(e),ar=i(e,"P",{});var kh=u(ar);tc=n(kh,"Si vous \xEAtes s\xFBr que votre collecteur de donn\xE9es est le bon, vous devriez essayer de l\u2019appliquer sur quelques \xE9chantillons de votre jeu de donn\xE9es :"),kh.forEach(s),ll=d(e),m(rt.$$.fragment,e),il=d(e),T=i(e,"P",{});var K=u(T);rc=n(K,"Ce code \xE9chouera parce que le "),Ua=i(K,"CODE",{});var jh=u(Ua);ac=n(jh,"train_dataset"),jh.forEach(s),nc=n(K," contient des colonnes de type "),Na=i(K,"EM",{});var Eh=u(Na);oc=n(Eh,"string"),Eh.forEach(s),lc=n(K," que le "),Ma=i(K,"CODE",{});var zh=u(Ma);ic=n(zh,"Trainer"),zh.forEach(s),uc=n(K," supprime habituellement. Vous pouvez les supprimer manuellement ou si vous voulez reproduire exactement ce que le "),Oa=i(K,"CODE",{});var yh=u(Oa);pc=n(yh,"Trainer"),yh.forEach(s),dc=n(K," fait en coulisse, vous pouvez appeler la m\xE9thode "),Va=i(K,"CODE",{});var wh=u(Va);cc=n(wh,"Trainer._remove_unused_columns()"),wh.forEach(s),mc=n(K," qui fait cela :"),K.forEach(s),ul=d(e),m(at.$$.fragment,e),pl=d(e),nr=i(e,"P",{});var xh=u(nr);fc=n(xh,"Vous devriez alors \xEAtre en mesure de d\xE9boguer manuellement ce qui se passe dans le collecteur de donn\xE9es si l\u2019erreur persiste."),xh.forEach(s),dl=d(e),or=i(e,"P",{});var Ch=u(or);vc=n(Ch,"Maintenant que nous avons d\xE9bogu\xE9 le processus de cr\xE9ation de batch, il est temps d\u2019en passer un dans le mod\xE8le !"),Ch.forEach(s),cl=d(e),ce=i(e,"H3",{class:!0});var ru=u(ce);Te=i(ru,"A",{id:!0,class:!0,href:!0});var Ph=u(Te);Ia=i(Ph,"SPAN",{});var Ah=u(Ia);m(nt.$$.fragment,Ah),Ah.forEach(s),Ph.forEach(s),hc=d(ru),Fa=i(ru,"SPAN",{});var Dh=u(Fa);_c=n(Dh,"Passage par le mod\xE8le"),Dh.forEach(s),ru.forEach(s),ml=d(e),lr=i(e,"P",{});var Th=u(lr);bc=n(Th,"Vous devriez \xEAtre en mesure d\u2019obtenir un batch en ex\xE9cutant la commande suivante :"),Th.forEach(s),fl=d(e),m(ot.$$.fragment,e),vl=d(e),F=i(e,"P",{});var _s=u(F);qc=n(_s,"Si vous ex\xE9cutez ce code dans un "),Ga=i(_s,"EM",{});var Sh=u(Ga);$c=n(Sh,"notebook"),Sh.forEach(s),gc=n(_s,", vous risquez d\u2019obtenir une erreur CUDA similaire \xE0 celle que nous avons vue pr\xE9c\xE9demment, auquel cas vous devrez red\xE9marrer votre "),Wa=i(_s,"EM",{});var Lh=u(Wa);kc=n(Lh,"notebook"),Lh.forEach(s),jc=n(_s," et r\xE9ex\xE9cuter le dernier extrait sans la ligne "),Ra=i(_s,"CODE",{});var Uh=u(Ra);Ec=n(Uh,"trainer.train()"),Uh.forEach(s),zc=n(_s,". C\u2019est la deuxi\xE8me chose la plus ennuyeuse \xE0 propos des erreurs CUDA : elles cassent irr\xE9m\xE9diablement votre noyau. La premi\xE8re plus ennuyeuse est le fait qu\u2019elles sont difficiles \xE0 d\xE9boguer."),_s.forEach(s),hl=d(e),Se=i(e,"P",{});var au=u(Se);yc=n(au,"Comment cela se fait-il ? Cela tient \xE0 la fa\xE7on dont les GPUs fonctionnent. Ils sont extr\xEAmement efficaces pour ex\xE9cuter un batch d\u2019op\xE9rations en parall\xE8le, mais l\u2019inconv\xE9nient est que lorsque l\u2019une de ces instructions entra\xEEne une erreur, vous ne le savez pas imm\xE9diatement. Ce n\u2019est que lorsque le programme appelle une synchronisation des multiples processus sur le GPU qu\u2019il r\xE9alise que quelque chose s\u2019est mal pass\xE9, de sorte que l\u2019erreur est en fait mentionn\xE9e \xE0 un endroit qui n\u2019a rien \xE0 voir avec ce qui l\u2019a cr\xE9\xE9e. Par exemple, si nous regardons notre "),Ha=i(au,"EM",{});var Nh=u(Ha);wc=n(Nh,"traceback"),Nh.forEach(s),xc=n(au," pr\xE9c\xE9dent, l\u2019erreur a \xE9t\xE9 soulev\xE9e pendant la passe arri\xE8re, mais nous verrons dans une minute qu\u2019elle provient en fait de quelque chose dans la passe avant."),au.forEach(s),_l=d(e),Le=i(e,"P",{});var nu=u(Le);Cc=n(nu,"Alors comment d\xE9boguer ces erreurs ? La r\xE9ponse est simple : nous ne le faisons pas. \xC0 moins que votre erreur CUDA ne soit une erreur "),Ba=i(nu,"EM",{});var Mh=u(Ba);Pc=n(Mh,"out-of-memory"),Mh.forEach(s),Ac=n(nu," (ce qui signifie qu\u2019il n\u2019y a pas assez de m\xE9moire dans votre GPU), vous devez toujours revenir au CPU pour la d\xE9boguer."),nu.forEach(s),bl=d(e),Ue=i(e,"P",{});var ou=u(Ue);Dc=n(ou,"Pour faire cela dans notre cas, nous devons juste remettre le mod\xE8le sur le CPU et l\u2019appeler sur notre batch. Le batch retourn\xE9 par le "),Ya=i(ou,"CODE",{});var Oh=u(Ya);Tc=n(Oh,"DataLoader"),Oh.forEach(s),Sc=n(ou," n\u2019a pas encore \xE9t\xE9 d\xE9plac\xE9 sur le GPU :"),ou.forEach(s),ql=d(e),m(lt.$$.fragment,e),$l=d(e),m(it.$$.fragment,e),gl=d(e),Ne=i(e,"P",{});var lu=u(Ne);Lc=n(lu,"L\u2019image devient plus claire. Au lieu d\u2019avoir une erreur CUDA, nous avons maintenant une "),Ja=i(lu,"CODE",{});var Vh=u(Ja);Uc=n(Vh,"IndexError"),Vh.forEach(s),Nc=n(lu," dans le calcul de la perte (donc rien \xE0 voir avec la passe arri\xE8re comme nous l\u2019avons dit plus t\xF4t). Plus pr\xE9cis\xE9ment, nous pouvons voir que c\u2019est la cible 2 qui cr\xE9e l\u2019erreur, donc c\u2019est un bon moment pour v\xE9rifier le nombre de labels de notre mod\xE8le :"),lu.forEach(s),kl=d(e),m(ut.$$.fragment,e),jl=d(e),m(pt.$$.fragment,e),El=d(e),ir=i(e,"P",{});var Ih=u(ir);Mc=n(Ih,"Avec deux \xE9tiquettes, seuls les 0 et les 1 sont autoris\xE9s comme cibles, mais d\u2019apr\xE8s le message d\u2019erreur, nous avons obtenu un 2. Obtenir un 2 est en fait normal : si nous nous souvenons des noms des \xE9tiquettes que nous avons extraits plus t\xF4t, il y en avait trois, donc nous avons les indices 0, 1 et 2 dans notre jeu de donn\xE9es. Le probl\xE8me est que nous n\u2019avons pas indiqu\xE9 cela \xE0 notre mod\xE8le, qui aurait d\xFB \xEAtre cr\xE9\xE9 avec trois \xE9tiquettes. Alors, corrigeons cela !"),Ih.forEach(s),zl=d(e),m(dt.$$.fragment,e),yl=d(e),Me=i(e,"P",{});var iu=u(Me);Oc=n(iu,"Nous n\u2019incluons pas encore la ligne "),Ka=i(iu,"CODE",{});var Fh=u(Ka);Vc=n(Fh,"trainer.train()"),Fh.forEach(s),Ic=n(iu," pour prendre le temps de v\xE9rifier que tout se passe bien. Si nous passons un batch \xE0 notre mod\xE8le, il fonctionne maintenant sans erreur !"),iu.forEach(s),wl=d(e),m(ct.$$.fragment,e),xl=d(e),ur=i(e,"P",{});var Gh=u(ur);Fc=n(Gh,"L\u2019\xE9tape suivante consiste alors \xE0 revenir au GPU et \xE0 v\xE9rifier que tout fonctionne encore :"),Gh.forEach(s),Cl=d(e),m(mt.$$.fragment,e),Pl=d(e),Oe=i(e,"P",{});var uu=u(Oe);Gc=n(uu,"Si vous obtenez toujours une erreur, assurez-vous de red\xE9marrer votre "),Qa=i(uu,"EM",{});var Wh=u(Qa);Wc=n(Wh,"notebook"),Wh.forEach(s),Rc=n(uu," et d\u2019ex\xE9cuter uniquement la derni\xE8re version du script."),uu.forEach(s),Al=d(e),me=i(e,"H3",{class:!0});var pu=u(me);Ve=i(pu,"A",{id:!0,class:!0,href:!0});var Rh=u(Ve);Za=i(Rh,"SPAN",{});var Hh=u(Za);m(ft.$$.fragment,Hh),Hh.forEach(s),Rh.forEach(s),Hc=d(pu),Xa=i(pu,"SPAN",{});var Bh=u(Xa);Bc=n(Bh,"Ex\xE9cution d'une \xE9tape d'optimisation"),Bh.forEach(s),pu.forEach(s),Dl=d(e),pr=i(e,"P",{});var Yh=u(pr);Yc=n(Yh,"Maintenant que nous savons que nous pouvons construire des batchs qui passent r\xE9ellement par le mod\xE8le, nous sommes pr\xEAts pour l\u2019\xE9tape suivante du pipeline d\u2019entra\xEEnement : calculer les gradients et effectuer une \xE9tape d\u2019optimisation."),Yh.forEach(s),Tl=d(e),Ie=i(e,"P",{});var du=u(Ie);Jc=n(du,"La premi\xE8re partie est juste une question d\u2019appel de la m\xE9thode "),en=i(du,"CODE",{});var Jh=u(en);Kc=n(Jh,"backward()"),Jh.forEach(s),Qc=n(du," sur la perte :"),du.forEach(s),Sl=d(e),m(vt.$$.fragment,e),Ll=d(e),dr=i(e,"P",{});var Kh=u(dr);Zc=n(Kh,"Il est plut\xF4t rare d\u2019obtenir une erreur \xE0 ce stade, mais si vous en obtenez une, assurez-vous de retourner au CPU pour obtenir un message d\u2019erreur utile."),Kh.forEach(s),Ul=d(e),oe=i(e,"P",{});var Nr=u(oe);Xc=n(Nr,"Pour effectuer l\u2019\xE9tape d\u2019optimisation, il suffit de cr\xE9er le "),sn=i(Nr,"CODE",{});var Qh=u(sn);em=n(Qh,"optimizer"),Qh.forEach(s),sm=n(Nr," et d\u2019appeler sa m\xE9thode "),tn=i(Nr,"CODE",{});var Zh=u(tn);tm=n(Zh,"step()"),Zh.forEach(s),rm=n(Nr," :"),Nr.forEach(s),Nl=d(e),m(ht.$$.fragment,e),Ml=d(e),Fe=i(e,"P",{});var cu=u(Fe);am=n(cu,"Encore une fois, si vous utilisez l\u2019optimiseur par d\xE9faut dans le "),rn=i(cu,"CODE",{});var Xh=u(rn);nm=n(Xh,"Trainer"),Xh.forEach(s),om=n(cu,", vous ne devriez pas avoir d\u2019erreur \xE0 ce stade, mais si vous avez un optimiseur personnalis\xE9, il pourrait y avoir quelques probl\xE8mes \xE0 d\xE9boguer ici. N\u2019oubliez pas de revenir au CPU si vous obtenez une erreur CUDA bizarre \xE0 ce stade. En parlant d\u2019erreurs CUDA, nous avons mentionn\xE9 pr\xE9c\xE9demment un cas particulier. Voyons cela maintenant."),cu.forEach(s),Ol=d(e),fe=i(e,"H3",{class:!0});var mu=u(fe);Ge=i(mu,"A",{id:!0,class:!0,href:!0});var e_=u(Ge);an=i(e_,"SPAN",{});var s_=u(an);m(_t.$$.fragment,s_),s_.forEach(s),e_.forEach(s),lm=d(mu),cr=i(mu,"SPAN",{});var iv=u(cr);im=n(iv,"G\xE9rer les erreurs "),nn=i(iv,"I",{});var t_=u(nn);um=n(t_,"CUDA out of memory"),t_.forEach(s),iv.forEach(s),mu.forEach(s),Vl=d(e),We=i(e,"P",{});var fu=u(We);pm=n(fu,"Chaque fois que vous obtenez un message d\u2019erreur qui commence par "),on=i(fu,"CODE",{});var r_=u(on);dm=n(r_,"RuntimeError : CUDA out of memory"),r_.forEach(s),cm=n(fu,", cela indique que vous \xEAtes \xE0 court de m\xE9moire GPU. Cela n\u2019est pas directement li\xE9 \xE0 votre code et peut arriver avec un script qui fonctionne parfaitement bien. Cette erreur signifie que vous avez essay\xE9 de mettre trop de choses dans la m\xE9moire interne de votre GPU et que cela a entra\xEEn\xE9 une erreur. Comme pour d\u2019autres erreurs CUDA, vous devrez red\xE9marrer votre noyau pour \xEAtre en mesure d\u2019ex\xE9cuter \xE0 nouveau votre entra\xEEnement."),fu.forEach(s),Il=d(e),mr=i(e,"P",{});var a_=u(mr);mm=n(a_,"Pour r\xE9soudre ce probl\xE8me, il suffit d\u2019utiliser moins d\u2019espace GPU, ce qui est souvent plus facile \xE0 dire qu\u2019\xE0 faire. Tout d\u2019abord, assurez-vous que vous n\u2019avez pas deux mod\xE8les sur le GPU en m\xEAme temps (sauf si cela est n\xE9cessaire pour votre probl\xE8me, bien s\xFBr). Ensuite, vous devriez probablement r\xE9duire la taille de votre batch car elle affecte directement les tailles de toutes les sorties interm\xE9diaires du mod\xE8le et leurs gradients. Si le probl\xE8me persiste, envisagez d\u2019utiliser une version plus petite de votre mod\xE8le."),a_.forEach(s),Fl=d(e),m(Re.$$.fragment,e),Gl=d(e),ve=i(e,"H3",{class:!0});var vu=u(ve);He=i(vu,"A",{id:!0,class:!0,href:!0});var n_=u(He);ln=i(n_,"SPAN",{});var o_=u(ln);m(bt.$$.fragment,o_),o_.forEach(s),n_.forEach(s),fm=d(vu),un=i(vu,"SPAN",{});var l_=u(un);vm=n(l_,"\xC9valuation du mod\xE8le"),l_.forEach(s),vu.forEach(s),Wl=d(e),Be=i(e,"P",{});var hu=u(Be);hm=n(hu,"Maintenant que nous avons r\xE9solu tous les probl\xE8mes li\xE9s \xE0 notre code, tout est parfait et l\u2019entra\xEEnement devrait se d\xE9rouler sans probl\xE8me, n\u2019est-ce pas ? Pas si vite ! Si vous ex\xE9cutez la commande "),pn=i(hu,"CODE",{});var i_=u(pn);_m=n(i_,"trainer.train()"),i_.forEach(s),bm=n(hu,", tout aura l\u2019air bien au d\xE9but, mais apr\xE8s un moment vous obtiendrez ce qui suit :"),hu.forEach(s),Rl=d(e),m(qt.$$.fragment,e),Hl=d(e),m($t.$$.fragment,e),Bl=d(e),fr=i(e,"P",{});var u_=u(fr);qm=n(u_,"Vous r\xE9aliserez que cette erreur appara\xEEt pendant la phase d\u2019\xE9valuation, donc c\u2019est la derni\xE8re chose que nous aurons besoin de d\xE9boguer."),u_.forEach(s),Yl=d(e),Ye=i(e,"P",{});var _u=u(Ye);$m=n(_u,"Vous pouvez ex\xE9cuter la boucle d\u2019\xE9valuation du "),dn=i(_u,"CODE",{});var p_=u(dn);gm=n(p_,"Trainer"),p_.forEach(s),km=n(_u," ind\xE9pendamment de l\u2019entra\xEEnement comme ceci :"),_u.forEach(s),Jl=d(e),m(gt.$$.fragment,e),Kl=d(e),m(kt.$$.fragment,e),Ql=d(e),m(Je.$$.fragment,e),Zl=d(e),vr=i(e,"P",{});var d_=u(vr);jm=n(d_,"Avant de tenter de d\xE9boguer un probl\xE8me dans la boucle d\u2019\xE9valuation, vous devez d\u2019abord vous assurer que vous avez examin\xE9 les donn\xE9es, que vous \xEAtes en mesure de former un batch correctement et que vous pouvez ex\xE9cuter votre mod\xE8le sur ces donn\xE9es. Nous avons effectu\xE9 toutes ces \xE9tapes, et le code suivant peut donc \xEAtre ex\xE9cut\xE9 sans erreur :"),d_.forEach(s),Xl=d(e),m(jt.$$.fragment,e),ei=d(e),Ke=i(e,"P",{});var bu=u(Ke);Em=n(bu,"L\u2019erreur survient plus tard, \xE0 la fin de la phase d\u2019\xE9valuation, et si nous regardons le "),cn=i(bu,"EM",{});var c_=u(cn);zm=n(c_,"traceback"),c_.forEach(s),ym=n(bu,", nous voyons ceci :"),bu.forEach(s),si=d(e),m(Et.$$.fragment,e),ti=d(e),G=i(e,"P",{});var bs=u(G);wm=n(bs,"Cela nous indique que l\u2019erreur provient du module "),mn=i(bs,"CODE",{});var m_=u(mn);xm=n(m_,"datasets/metric.py"),m_.forEach(s),Cm=n(bs," donc c\u2019est un probl\xE8me avec notre fonction "),fn=i(bs,"CODE",{});var f_=u(fn);Pm=n(f_,"compute_metrics()"),f_.forEach(s),Am=n(bs,". Elle prend un "),vn=i(bs,"EM",{});var v_=u(vn);Dm=n(v_,"tuple"),v_.forEach(s),Tm=n(bs," avec les logits et les labels sous forme de tableaux NumPy, alors essayons de lui fournir cela :"),bs.forEach(s),ri=d(e),m(zt.$$.fragment,e),ai=d(e),m(yt.$$.fragment,e),ni=d(e),W=i(e,"P",{});var qs=u(W);Sm=n(qs,"Nous obtenons la m\xEAme erreur, donc le probl\xE8me vient bien de cette fonction. Si on regarde son code, on voit qu\u2019elle transmet simplement les "),hn=i(qs,"CODE",{});var h_=u(hn);Lm=n(h_,"predictions"),h_.forEach(s),Um=n(qs," et les "),_n=i(qs,"CODE",{});var __=u(_n);Nm=n(__,"labels"),__.forEach(s),Mm=n(qs," \xE0 "),bn=i(qs,"CODE",{});var b_=u(bn);Om=n(b_,"metric.compute()"),b_.forEach(s),Vm=n(qs,". Y a-t-il donc un probl\xE8me avec cette m\xE9thode ? Pas vraiment. Jetons un coup d\u2019oeil rapide aux formes :"),qs.forEach(s),oi=d(e),m(wt.$$.fragment,e),li=d(e),m(xt.$$.fragment,e),ii=d(e),Qe=i(e,"P",{});var qu=u(Qe);Im=n(qu,"Nos pr\xE9dictions sont toujours des logits et non les pr\xE9dictions r\xE9elles, c\u2019est pourquoi la m\xE9trique retourne cette erreur (quelque peu obscure). La correction est assez simple, il suffit d\u2019ajouter un argmax dans la fonction "),qn=i(qu,"CODE",{});var q_=u(qn);Fm=n(q_,"compute_metrics()"),q_.forEach(s),Gm=n(qu," :"),qu.forEach(s),ui=d(e),m(Ct.$$.fragment,e),pi=d(e),m(Pt.$$.fragment,e),di=d(e),hr=i(e,"P",{});var $_=u(hr);Wm=n($_,"Maintenant notre erreur est corrig\xE9e ! C\u2019\xE9tait la derni\xE8re, donc notre script va maintenant entra\xEEner un mod\xE8le correctement."),$_.forEach(s),ci=d(e),_r=i(e,"P",{});var g_=u(_r);Rm=n(g_,"Pour r\xE9f\xE9rence, voici le script compl\xE8tement corrig\xE9 :"),g_.forEach(s),mi=d(e),m(At.$$.fragment,e),fi=d(e),Ze=i(e,"P",{});var $u=u(Ze);Hm=n($u,"Dans ce cas, il n\u2019y a plus de probl\xE8me, et notre script va "),$n=i($u,"EM",{});var k_=u($n);Bm=n(k_,"finetuner"),k_.forEach(s),Ym=n($u," un mod\xE8le qui devrait donner des r\xE9sultats raisonnables. Mais que faire lorsque l\u2019entra\xEEnement se d\xE9roule sans erreur et que le mod\xE8le entra\xEEn\xE9 n\u2019est pas du tout performant ? C\u2019est la partie la plus difficile de l\u2019apprentissage automatique et nous allons vous montrer quelques techniques qui peuvent vous aider."),$u.forEach(s),vi=d(e),m(Xe.$$.fragment,e),hi=d(e),he=i(e,"H2",{class:!0});var gu=u(he);es=i(gu,"A",{id:!0,class:!0,href:!0});var j_=u(es);gn=i(j_,"SPAN",{});var E_=u(gn);m(Dt.$$.fragment,E_),E_.forEach(s),j_.forEach(s),Jm=d(gu),kn=i(gu,"SPAN",{});var z_=u(kn);Km=n(z_,"D\xE9boguer les erreurs silencieuses pendant l'entra\xEEnement"),z_.forEach(s),gu.forEach(s),_i=d(e),br=i(e,"P",{});var y_=u(br);Qm=n(y_,"Que peut-on faire pour d\xE9boguer un entra\xEEnement qui se termine sans erreur mais qui ne donne pas de bons r\xE9sultats ? Nous allons vous donner quelques pistes ici, mais sachez que ce type de d\xE9bogage est la partie la plus difficile de l\u2019apprentissage automatique et qu\u2019il n\u2019y a pas de r\xE9ponse magique."),y_.forEach(s),bi=d(e),_e=i(e,"H3",{class:!0});var ku=u(_e);ss=i(ku,"A",{id:!0,class:!0,href:!0});var w_=u(ss);jn=i(w_,"SPAN",{});var x_=u(jn);m(Tt.$$.fragment,x_),x_.forEach(s),w_.forEach(s),Zm=d(ku),En=i(ku,"SPAN",{});var C_=u(En);Xm=n(C_,"V\xE9rifiez vos donn\xE9es (encore !)"),C_.forEach(s),ku.forEach(s),qi=d(e),ts=i(e,"P",{});var ju=u(ts);ef=n(ju,"Votre mod\xE8le n\u2019apprendra quelque chose que s\u2019il est r\xE9ellement possible d\u2019apprendre quelque chose de vos donn\xE9es. Si un "),zn=i(ju,"EM",{});var P_=u(zn);sf=n(P_,"bug"),P_.forEach(s),tf=n(ju," corrompt les donn\xE9es ou si les \xE9tiquettes sont attribu\xE9es de mani\xE8re al\xE9atoire, il est tr\xE8s probable que vous n\u2019obtiendrez aucun entra\xEEnement de mod\xE8le sur votre jeu de donn\xE9es. Commencez donc toujours par rev\xE9rifier vos entr\xE9es et \xE9tiquettes d\xE9cod\xE9es, et posez-vous les questions suivantes :"),ju.forEach(s),$i=d(e),R=i(e,"UL",{});var $s=u(R);yn=i($s,"LI",{});var A_=u(yn);rf=n(A_,"les donn\xE9es d\xE9cod\xE9es sont-elles compr\xE9hensibles ?"),A_.forEach(s),af=d($s),wn=i($s,"LI",{});var D_=u(wn);nf=n(D_,"\xEAtes-vous d\u2019accord avec les \xE9tiquettes ?"),D_.forEach(s),of=d($s),xn=i($s,"LI",{});var T_=u(xn);lf=n(T_,"y a-t-il une \xE9tiquette qui est plus courante que les autres ?"),T_.forEach(s),uf=d($s),Cn=i($s,"LI",{});var S_=u(Cn);pf=n(S_,"quelle devrait \xEAtre la perte/m\xE9trique si le mod\xE8le pr\xE9disait une r\xE9ponse al\xE9atoire/toujours la m\xEAme r\xE9ponse ?"),S_.forEach(s),$s.forEach(s),gi=d(e),m(rs.$$.fragment,e),ki=d(e),as=i(e,"P",{});var Eu=u(as);df=n(Eu,"Apr\xE8s avoir examin\xE9 vos donn\xE9es, examinez quelques-unes des pr\xE9dictions du mod\xE8le. Si votre mod\xE8le produit des "),Pn=i(Eu,"EM",{});var L_=u(Pn);cf=n(L_,"tokens"),L_.forEach(s),mf=n(Eu,", essayez aussi de les d\xE9coder ! Si le mod\xE8le pr\xE9dit toujours la m\xEAme chose, cela peut \xEAtre d\xFB au fait que votre jeu de donn\xE9es est biais\xE9 en faveur d\u2019une cat\xE9gorie (pour les probl\xE8mes de classification). Des techniques telles que le sur\xE9chantillonnage des classes rares peuvent aider. D\u2019autre part, cela peut \xE9galement \xEAtre d\xFB \xE0 des probl\xE8mes d\u2019entra\xEEnement tels que de mauvais r\xE9glages des hyperparam\xE8tres."),Eu.forEach(s),ji=d(e),qr=i(e,"P",{});var U_=u(qr);ff=n(U_,"Si la perte/la m\xE9trique que vous obtenez sur votre mod\xE8le initial avant entra\xEEnement est tr\xE8s diff\xE9rente de la perte/la m\xE9trique \xE0 laquelle vous vous attendez pour des pr\xE9dictions al\xE9atoires, v\xE9rifiez la fa\xE7on dont votre perte ou votre m\xE9trique est calcul\xE9e. Il y a probablement un bug. Si vous utilisez plusieurs pertes que vous ajoutez \xE0 la fin, assurez-vous qu\u2019elles sont de la m\xEAme \xE9chelle."),U_.forEach(s),Ei=d(e),$r=i(e,"P",{});var N_=u($r);vf=n(N_,"Lorsque vous \xEAtes s\xFBr que vos donn\xE9es sont parfaites, vous pouvez voir si le mod\xE8le est capable de s\u2019entra\xEEner sur elles gr\xE2ce \xE0 un test simple."),N_.forEach(s),zi=d(e),be=i(e,"H3",{class:!0});var zu=u(be);ns=i(zu,"A",{id:!0,class:!0,href:!0});var M_=u(ns);An=i(M_,"SPAN",{});var O_=u(An);m(St.$$.fragment,O_),O_.forEach(s),M_.forEach(s),hf=d(zu),Dn=i(zu,"SPAN",{});var V_=u(Dn);_f=n(V_,"Surentra\xEEnement du mod\xE8le sur un seul batch"),V_.forEach(s),zu.forEach(s),yi=d(e),gr=i(e,"P",{});var I_=u(gr);bf=n(I_,"Le surentra\xEEnement est g\xE9n\xE9ralement une chose que nous essayons d\u2019\xE9viter lors de l\u2019entra\xEEnement car cela signifie que le mod\xE8le n\u2019apprend pas \xE0 reconna\xEEtre les caract\xE9ristiques g\xE9n\xE9rales que nous voulons qu\u2019il reconnaisse et se contente de m\xE9moriser les \xE9chantillons d\u2019entra\xEEnement. Cependant, essayer d\u2019entra\xEEner votre mod\xE8le sur un batch encore et encore est un bon test pour v\xE9rifier si le probl\xE8me tel que vous l\u2019avez formul\xE9 peut \xEAtre r\xE9solu par le mod\xE8le que vous essayez d\u2019entra\xEEner. Cela vous aidera \xE9galement \xE0 voir si votre taux d\u2019apprentissage initial est trop \xE9lev\xE9."),I_.forEach(s),wi=d(e),le=i(e,"P",{});var Mr=u(le);qf=n(Mr,"Une fois que vous avez d\xE9fini votre "),Tn=i(Mr,"CODE",{});var F_=u(Tn);$f=n(F_,"mod\xE8le"),F_.forEach(s),gf=n(Mr,", c\u2019est tr\xE8s facile. Il suffit de prendre un batch de donn\xE9es d\u2019entra\xEEnement, puis de le traiter comme votre jeu de donn\xE9es entier que vous "),Sn=i(Mr,"EM",{});var G_=u(Sn);kf=n(G_,"finetunez"),G_.forEach(s),jf=n(Mr," sur un grand nombre d\u2019\xE9poques :"),Mr.forEach(s),xi=d(e),m(Lt.$$.fragment,e),Ci=d(e),m(os.$$.fragment,e),Pi=d(e),ls=i(e,"P",{});var yu=u(ls);Ef=n(yu,"Le mod\xE8le r\xE9sultant devrait avoir des r\xE9sultats proches de la perfection sur le m\xEAme "),Ln=i(yu,"CODE",{});var W_=u(Ln);zf=n(W_,"batch"),W_.forEach(s),yf=n(yu,". Calculons la m\xE9trique sur les pr\xE9dictions r\xE9sultantes :"),yu.forEach(s),Ai=d(e),m(Ut.$$.fragment,e),Di=d(e),m(Nt.$$.fragment,e),Ti=d(e),kr=i(e,"P",{});var R_=u(kr);wf=n(R_,"100% de pr\xE9cision, voil\xE0 un bel exemple de surentra\xEEnement (ce qui signifie que si vous essayez votre mod\xE8le sur n\u2019importe quelle autre phrase, il vous donnera tr\xE8s probablement une mauvaise r\xE9ponse) !"),R_.forEach(s),Si=d(e),jr=i(e,"P",{});var H_=u(jr);xf=n(H_,"Si vous ne parvenez pas \xE0 ce que votre mod\xE8le obtienne des r\xE9sultats parfaits comme celui-ci, cela signifie qu\u2019il y a quelque chose qui ne va pas dans la fa\xE7on dont vous avez formul\xE9 le probl\xE8me ou dans vos donn\xE9es. Vous devez donc y rem\xE9dier. Ce n\u2019est que lorsque vous parviendrez \xE0 passer le test de surentra\xEEnement que vous pourrez \xEAtre s\xFBr que votre mod\xE8le peut r\xE9ellement apprendre quelque chose."),H_.forEach(s),Li=d(e),m(is.$$.fragment,e),Ui=d(e),qe=i(e,"H3",{class:!0});var wu=u(qe);us=i(wu,"A",{id:!0,class:!0,href:!0});var B_=u(us);Un=i(B_,"SPAN",{});var Y_=u(Un);m(Mt.$$.fragment,Y_),Y_.forEach(s),B_.forEach(s),Cf=d(wu),Nn=i(wu,"SPAN",{});var J_=u(Nn);Pf=n(J_,"Ne r\xE9glez rien tant que vous n'avez pas une premi\xE8re ligne de base"),J_.forEach(s),wu.forEach(s),Ni=d(e),ps=i(e,"P",{});var xu=u(ps);Af=n(xu,"Le r\xE9glage des hyperparam\xE8tres est toujours consid\xE9r\xE9 comme la partie la plus difficile de l\u2019apprentissage automatique mais c\u2019est juste la derni\xE8re \xE9tape pour vous aider \xE0 gagner un peu sur la m\xE9trique. La plupart du temps, les hyperparam\xE8tres par d\xE9faut du "),Mn=i(xu,"CODE",{});var K_=u(Mn);Df=n(K_,"Trainer"),K_.forEach(s),Tf=n(xu," fonctionneront tr\xE8s bien pour vous donner de bons r\xE9sultats. Donc ne vous lancez pas dans une recherche d\u2019hyperparam\xE8tres longue et co\xFBteuse jusqu\u2019\xE0 ce que vous ayez quelque chose qui batte la ligne de base que vous avez sur votre jeu de donn\xE9es."),xu.forEach(s),Mi=d(e),ds=i(e,"P",{});var Cu=u(ds);Sf=n(Cu,"Une fois que vous avez un mod\xE8le suffisamment bon, vous pouvez commencer \xE0 le "),On=i(Cu,"EM",{});var Q_=u(On);Lf=n(Q_,"finetuner"),Q_.forEach(s),Uf=n(Cu," un peu. N\u2019essayez pas de lancer un millier d\u2019ex\xE9cutions avec diff\xE9rents hyperparam\xE8tres mais comparez quelques ex\xE9cutions avec diff\xE9rentes valeurs pour un hyperparam\xE8tre afin de vous faire une id\xE9e de celui qui a le plus d\u2019impact."),Cu.forEach(s),Oi=d(e),Er=i(e,"P",{});var Z_=u(Er);Nf=n(Z_,"Si vous modifiez le mod\xE8le lui-m\xEAme, restez simple et n\u2019essayez rien que vous ne puissiez raisonnablement justifier. Veillez toujours \xE0 revenir au test de surentra\xEEnement pour v\xE9rifier que votre modification n\u2019a pas eu de cons\xE9quences inattendues."),Z_.forEach(s),Vi=d(e),$e=i(e,"H3",{class:!0});var Pu=u($e);cs=i(Pu,"A",{id:!0,class:!0,href:!0});var X_=u(cs);Vn=i(X_,"SPAN",{});var eb=u(Vn);m(Ot.$$.fragment,eb),eb.forEach(s),X_.forEach(s),Mf=d(Pu),In=i(Pu,"SPAN",{});var sb=u(In);Of=n(sb,"Demander de l'aide"),sb.forEach(s),Pu.forEach(s),Ii=d(e),ms=i(e,"P",{});var Au=u(ms);Vf=n(Au,"Nous esp\xE9rons que vous avez trouv\xE9 dans cette section des conseils qui vous ont aid\xE9 \xE0 r\xE9soudre votre probl\xE8me. Si ce n\u2019est pas le cas, n\u2019oubliez pas que vous pouvez toujours demander de l\u2019aide \xE0 la communaut\xE9 sur le "),Vt=i(Au,"A",{href:!0,rel:!0});var tb=u(Vt);If=n(tb,"forum"),tb.forEach(s),Ff=n(Au,"."),Au.forEach(s),Fi=d(e),zr=i(e,"P",{});var rb=u(zr);Gf=n(rb,"Voici quelques ressources (en anglais) suppl\xE9mentaires qui peuvent s\u2019av\xE9rer utiles :"),rb.forEach(s),Gi=d(e),H=i(e,"UL",{});var gs=u(H);yr=i(gs,"LI",{});var uv=u(yr);It=i(uv,"A",{href:!0,rel:!0});var ab=u(It);Wf=n(ab,"La reproductibilit\xE9 comme vecteur des meilleures pratiques d\u2019ing\xE9nierie"),ab.forEach(s),Rf=n(uv," par Joel Grus"),uv.forEach(s),Hf=d(gs),wr=i(gs,"LI",{});var pv=u(wr);Ft=i(pv,"A",{href:!0,rel:!0});var nb=u(Ft);Bf=n(nb,"Liste de contr\xF4le pour le d\xE9bogage des r\xE9seaux de neurones"),nb.forEach(s),Yf=n(pv," par Cecelia Shao"),pv.forEach(s),Jf=d(gs),xr=i(gs,"LI",{});var dv=u(xr);Gt=i(dv,"A",{href:!0,rel:!0});var ob=u(Gt);Kf=n(ob,"Comment tester unitairement le code d\u2019apprentissage automatique"),ob.forEach(s),Qf=n(dv," par Chase Roberts"),dv.forEach(s),Zf=d(gs),Cr=i(gs,"LI",{});var cv=u(Cr);Wt=i(cv,"A",{href:!0,rel:!0});var lb=u(Wt);Xf=n(lb,"Une recette pour entra\xEEner les r\xE9seaux de neurones"),lb.forEach(s),ev=n(cv," par Andrej Karpathy"),cv.forEach(s),gs.forEach(s),Wi=d(e),B=i(e,"P",{});var ks=u(B);sv=n(ks,"Bien s\xFBr, tous les probl\xE8mes rencontr\xE9s lors de l\u2019entra\xEEnement ne sont pas forc\xE9ment de votre faute ! Si vous rencontrez quelque chose dans la biblioth\xE8que \u{1F917} "),Fn=i(ks,"EM",{});var ib=u(Fn);tv=n(ib,"Transformers"),ib.forEach(s),rv=n(ks," ou \u{1F917} "),Gn=i(ks,"EM",{});var ub=u(Gn);av=n(ub,"Datasets"),ub.forEach(s),nv=n(ks," qui ne semble pas correct, vous avez peut-\xEAtre trouver un "),Wn=i(ks,"EM",{});var pb=u(Wn);ov=n(pb,"bug"),pb.forEach(s),lv=n(ks,". Vous devez absolument nous en parler pour qu\u2019on puisse le corriger. Dans la section suivante, nous allons vous expliquer exactement comment faire."),ks.forEach(s),this.h()},h(){q(b,"name","hf:doc:metadata"),q(b,"content",JSON.stringify(wb)),q(k,"id","dbogage-du-pipeline-dentranement"),q(k,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(k,"href","#dbogage-du-pipeline-dentranement"),q(y,"class","relative group"),q(Yt,"href","/course/fr/chapter7"),q(ge,"id","dboguer-le-pipeline-dentranement"),q(ge,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(ge,"href","#dboguer-le-pipeline-dentranement"),q(ue,"class","relative group"),q(ys,"href","https://huggingface.co/datasets/glue"),q(ys,"rel","nofollow"),q(je,"id","vrifiez-vos-donnes"),q(je,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(je,"href","#vrifiez-vos-donnes"),q(pe,"class","relative group"),q(Is,"href","https://huggingface.co/transformers/model_doc/distilbert.html#distilbertforsequenceclassification"),q(Is,"rel","nofollow"),q(De,"id","des-jeux-de-donnes-aux-chargeurs-de-donnes"),q(De,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(De,"href","#des-jeux-de-donnes-aux-chargeurs-de-donnes"),q(de,"class","relative group"),q(Te,"id","passage-par-le-modle"),q(Te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(Te,"href","#passage-par-le-modle"),q(ce,"class","relative group"),q(Ve,"id","excution-dune-tape-doptimisation"),q(Ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(Ve,"href","#excution-dune-tape-doptimisation"),q(me,"class","relative group"),q(Ge,"id","grer-les-erreurs-icuda-out-of-memoryi"),q(Ge,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(Ge,"href","#grer-les-erreurs-icuda-out-of-memoryi"),q(fe,"class","relative group"),q(He,"id","valuation-du-modle"),q(He,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(He,"href","#valuation-du-modle"),q(ve,"class","relative group"),q(es,"id","dboguer-les-erreurs-silencieuses-pendant-lentranement"),q(es,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(es,"href","#dboguer-les-erreurs-silencieuses-pendant-lentranement"),q(he,"class","relative group"),q(ss,"id","vrifiez-vos-donnes-encore"),q(ss,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(ss,"href","#vrifiez-vos-donnes-encore"),q(_e,"class","relative group"),q(ns,"id","surentranement-du-modle-sur-un-seul-batch"),q(ns,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(ns,"href","#surentranement-du-modle-sur-un-seul-batch"),q(be,"class","relative group"),q(us,"id","ne-rglez-rien-tant-que-vous-navez-pas-une-premire-ligne-de-base"),q(us,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(us,"href","#ne-rglez-rien-tant-que-vous-navez-pas-une-premire-ligne-de-base"),q(qe,"class","relative group"),q(cs,"id","demander-de-laide"),q(cs,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(cs,"href","#demander-de-laide"),q($e,"class","relative group"),q(Vt,"href","https://discuss.huggingface.co/"),q(Vt,"rel","nofollow"),q(It,"href","https://docs.google.com/presentation/d/1yHLPvPhUs2KGI5ZWo0sU-PKU3GimAk3iTsI38Z-B5Gw/edit#slide=id.p"),q(It,"rel","nofollow"),q(Ft,"href","https://towardsdatascience.com/checklist-for-debugging-neural-networks-d8b2a9434f21"),q(Ft,"rel","nofollow"),q(Gt,"href","https://medium.com/@keeper6928/how-to-unit-test-machine-learning-code-57cf6fd81765"),q(Gt,"rel","nofollow"),q(Wt,"href","http://karpathy.github.io/2019/04/25/recipe/"),q(Wt,"rel","nofollow")},m(e,r){t(document.head,b),o(e,E,r),f(g,e,r),o(e,j,r),o(e,y,r),t(y,k),t(k,z),f(w,z,null),t(y,S),t(y,x),t(x,Z),o(e,N,r),f(C,e,r),o(e,js,r),o(e,L,r),t(L,Bt),t(L,Or),t(Or,Du),t(L,Tu),t(L,Yt),t(Yt,Su),t(L,Lu),t(L,Vr),t(Vr,Uu),t(L,Nu),o(e,Qn,r),o(e,ue,r),t(ue,ge),t(ge,Ir),f(Es,Ir,null),t(ue,Mu),t(ue,Fr),t(Fr,Ou),o(e,Zn,r),f(zs,e,r),o(e,Xn,r),o(e,X,r),t(X,Vu),t(X,Gr),t(Gr,Iu),t(X,Fu),t(X,Wr),t(Wr,Gu),t(X,Wu),o(e,eo,r),o(e,ke,r),t(ke,Ru),t(ke,Rr),t(Rr,Hu),t(ke,Bu),o(e,so,r),o(e,ee,r),t(ee,Yu),t(ee,Hr),t(Hr,Ju),t(ee,Ku),t(ee,ys),t(ys,Qu),t(ee,Zu),o(e,to,r),f(ws,e,r),o(e,ro,r),o(e,Jt,r),t(Jt,Xu),o(e,ao,r),f(xs,e,r),o(e,no,r),o(e,pe,r),t(pe,je),t(je,Br),f(Cs,Br,null),t(pe,ep),t(pe,Yr),t(Yr,sp),o(e,oo,r),o(e,Ee,r),t(Ee,tp),t(Ee,Jr),t(Jr,rp),t(Ee,ap),o(e,lo,r),o(e,ze,r),t(ze,np),t(ze,Kr),t(Kr,op),t(ze,lp),o(e,io,r),f(Ps,e,r),o(e,uo,r),f(As,e,r),o(e,po,r),o(e,se,r),t(se,ip),t(se,Qr),t(Qr,up),t(se,pp),t(se,Zr),t(Zr,dp),t(se,cp),o(e,co,r),o(e,A,r),t(A,mp),t(A,Xr),t(Xr,fp),t(A,vp),t(A,ea),t(ea,hp),t(A,_p),t(A,sa),t(sa,bp),t(A,qp),t(A,ta),t(ta,$p),t(A,gp),t(A,ra),t(ra,kp),t(A,jp),o(e,mo,r),f(Ds,e,r),o(e,fo,r),o(e,Kt,r),t(Kt,Ep),o(e,vo,r),f(Ts,e,r),o(e,ho,r),o(e,ye,r),t(ye,zp),t(ye,aa),t(aa,yp),t(ye,wp),o(e,_o,r),f(Ss,e,r),o(e,bo,r),o(e,Qt,r),t(Qt,xp),o(e,qo,r),o(e,we,r),t(we,Cp),t(we,na),t(na,Pp),t(we,Ap),o(e,$o,r),f(Ls,e,r),o(e,go,r),f(Us,e,r),o(e,ko,r),o(e,Zt,r),t(Zt,Dp),o(e,jo,r),f(Ns,e,r),o(e,Eo,r),f(Ms,e,r),o(e,zo,r),o(e,U,r),t(U,Tp),t(U,oa),t(oa,Sp),t(U,Lp),t(U,la),t(la,Up),t(U,Np),t(U,ia),t(ia,Mp),t(U,Op),t(U,ua),t(ua,Vp),t(U,Ip),o(e,yo,r),f(Os,e,r),o(e,wo,r),f(Vs,e,r),o(e,xo,r),o(e,te,r),t(te,Fp),t(te,Is),t(Is,Gp),t(te,Wp),t(te,pa),t(pa,Rp),t(te,Hp),o(e,Co,r),o(e,xe,r),t(xe,Bp),t(xe,da),t(da,Yp),t(xe,Jp),o(e,Po,r),f(Fs,e,r),o(e,Ao,r),f(Gs,e,r),o(e,Do,r),o(e,Ce,r),t(Ce,Kp),t(Ce,ca),t(ca,Qp),t(Ce,Zp),o(e,To,r),f(Ws,e,r),o(e,So,r),f(Rs,e,r),o(e,Lo,r),o(e,Xt,r),t(Xt,Xp),o(e,Uo,r),f(Hs,e,r),o(e,No,r),f(Bs,e,r),o(e,Mo,r),o(e,re,r),t(re,ed),t(re,ma),t(ma,sd),t(re,td),t(re,fa),t(fa,rd),t(re,ad),o(e,Oo,r),f(Ys,e,r),o(e,Vo,r),f(Js,e,r),o(e,Io,r),o(e,ae,r),t(ae,nd),t(ae,va),t(va,od),t(ae,ld),t(ae,ha),t(ha,id),t(ae,ud),o(e,Fo,r),o(e,Pe,r),t(Pe,pd),t(Pe,_a),t(_a,dd),t(Pe,cd),o(e,Go,r),f(Ae,e,r),o(e,Wo,r),o(e,er,r),t(er,md),o(e,Ro,r),o(e,sr,r),t(sr,fd),o(e,Ho,r),o(e,de,r),t(de,De),t(De,ba),f(Ks,ba,null),t(de,vd),t(de,qa),t(qa,hd),o(e,Bo,r),o(e,D,r),t(D,_d),t(D,$a),t($a,bd),t(D,qd),t(D,ga),t(ga,$d),t(D,gd),t(D,ka),t(ka,kd),t(D,jd),t(D,ja),t(ja,Ed),t(D,zd),t(D,Ea),t(Ea,yd),t(D,wd),o(e,Yo,r),f(Qs,e,r),o(e,Jo,r),o(e,ne,r),t(ne,xd),t(ne,za),t(za,Cd),t(ne,Pd),t(ne,ya),t(ya,Ad),t(ne,Dd),o(e,Ko,r),f(Zs,e,r),o(e,Qo,r),o(e,O,r),t(O,Td),t(O,wa),t(wa,Sd),t(O,Ld),t(O,xa),t(xa,Ud),t(O,Nd),t(O,Ca),t(Ca,Md),t(O,Od),o(e,Zo,r),f(Xs,e,r),o(e,Xo,r),f(et,e,r),o(e,el,r),o(e,V,r),t(V,Vd),t(V,Pa),t(Pa,Id),t(V,Fd),t(V,Aa),t(Aa,Gd),t(V,Wd),t(V,Da),t(Da,Rd),t(V,Hd),o(e,sl,r),o(e,I,r),t(I,Bd),t(I,Ta),t(Ta,Yd),t(I,Jd),t(I,Sa),t(Sa,Kd),t(I,Qd),t(I,La),t(La,Zd),t(I,Xd),o(e,tl,r),f(st,e,r),o(e,rl,r),o(e,tr,r),t(tr,ec),o(e,al,r),f(tt,e,r),o(e,nl,r),o(e,rr,r),t(rr,sc),o(e,ol,r),o(e,ar,r),t(ar,tc),o(e,ll,r),f(rt,e,r),o(e,il,r),o(e,T,r),t(T,rc),t(T,Ua),t(Ua,ac),t(T,nc),t(T,Na),t(Na,oc),t(T,lc),t(T,Ma),t(Ma,ic),t(T,uc),t(T,Oa),t(Oa,pc),t(T,dc),t(T,Va),t(Va,cc),t(T,mc),o(e,ul,r),f(at,e,r),o(e,pl,r),o(e,nr,r),t(nr,fc),o(e,dl,r),o(e,or,r),t(or,vc),o(e,cl,r),o(e,ce,r),t(ce,Te),t(Te,Ia),f(nt,Ia,null),t(ce,hc),t(ce,Fa),t(Fa,_c),o(e,ml,r),o(e,lr,r),t(lr,bc),o(e,fl,r),f(ot,e,r),o(e,vl,r),o(e,F,r),t(F,qc),t(F,Ga),t(Ga,$c),t(F,gc),t(F,Wa),t(Wa,kc),t(F,jc),t(F,Ra),t(Ra,Ec),t(F,zc),o(e,hl,r),o(e,Se,r),t(Se,yc),t(Se,Ha),t(Ha,wc),t(Se,xc),o(e,_l,r),o(e,Le,r),t(Le,Cc),t(Le,Ba),t(Ba,Pc),t(Le,Ac),o(e,bl,r),o(e,Ue,r),t(Ue,Dc),t(Ue,Ya),t(Ya,Tc),t(Ue,Sc),o(e,ql,r),f(lt,e,r),o(e,$l,r),f(it,e,r),o(e,gl,r),o(e,Ne,r),t(Ne,Lc),t(Ne,Ja),t(Ja,Uc),t(Ne,Nc),o(e,kl,r),f(ut,e,r),o(e,jl,r),f(pt,e,r),o(e,El,r),o(e,ir,r),t(ir,Mc),o(e,zl,r),f(dt,e,r),o(e,yl,r),o(e,Me,r),t(Me,Oc),t(Me,Ka),t(Ka,Vc),t(Me,Ic),o(e,wl,r),f(ct,e,r),o(e,xl,r),o(e,ur,r),t(ur,Fc),o(e,Cl,r),f(mt,e,r),o(e,Pl,r),o(e,Oe,r),t(Oe,Gc),t(Oe,Qa),t(Qa,Wc),t(Oe,Rc),o(e,Al,r),o(e,me,r),t(me,Ve),t(Ve,Za),f(ft,Za,null),t(me,Hc),t(me,Xa),t(Xa,Bc),o(e,Dl,r),o(e,pr,r),t(pr,Yc),o(e,Tl,r),o(e,Ie,r),t(Ie,Jc),t(Ie,en),t(en,Kc),t(Ie,Qc),o(e,Sl,r),f(vt,e,r),o(e,Ll,r),o(e,dr,r),t(dr,Zc),o(e,Ul,r),o(e,oe,r),t(oe,Xc),t(oe,sn),t(sn,em),t(oe,sm),t(oe,tn),t(tn,tm),t(oe,rm),o(e,Nl,r),f(ht,e,r),o(e,Ml,r),o(e,Fe,r),t(Fe,am),t(Fe,rn),t(rn,nm),t(Fe,om),o(e,Ol,r),o(e,fe,r),t(fe,Ge),t(Ge,an),f(_t,an,null),t(fe,lm),t(fe,cr),t(cr,im),t(cr,nn),t(nn,um),o(e,Vl,r),o(e,We,r),t(We,pm),t(We,on),t(on,dm),t(We,cm),o(e,Il,r),o(e,mr,r),t(mr,mm),o(e,Fl,r),f(Re,e,r),o(e,Gl,r),o(e,ve,r),t(ve,He),t(He,ln),f(bt,ln,null),t(ve,fm),t(ve,un),t(un,vm),o(e,Wl,r),o(e,Be,r),t(Be,hm),t(Be,pn),t(pn,_m),t(Be,bm),o(e,Rl,r),f(qt,e,r),o(e,Hl,r),f($t,e,r),o(e,Bl,r),o(e,fr,r),t(fr,qm),o(e,Yl,r),o(e,Ye,r),t(Ye,$m),t(Ye,dn),t(dn,gm),t(Ye,km),o(e,Jl,r),f(gt,e,r),o(e,Kl,r),f(kt,e,r),o(e,Ql,r),f(Je,e,r),o(e,Zl,r),o(e,vr,r),t(vr,jm),o(e,Xl,r),f(jt,e,r),o(e,ei,r),o(e,Ke,r),t(Ke,Em),t(Ke,cn),t(cn,zm),t(Ke,ym),o(e,si,r),f(Et,e,r),o(e,ti,r),o(e,G,r),t(G,wm),t(G,mn),t(mn,xm),t(G,Cm),t(G,fn),t(fn,Pm),t(G,Am),t(G,vn),t(vn,Dm),t(G,Tm),o(e,ri,r),f(zt,e,r),o(e,ai,r),f(yt,e,r),o(e,ni,r),o(e,W,r),t(W,Sm),t(W,hn),t(hn,Lm),t(W,Um),t(W,_n),t(_n,Nm),t(W,Mm),t(W,bn),t(bn,Om),t(W,Vm),o(e,oi,r),f(wt,e,r),o(e,li,r),f(xt,e,r),o(e,ii,r),o(e,Qe,r),t(Qe,Im),t(Qe,qn),t(qn,Fm),t(Qe,Gm),o(e,ui,r),f(Ct,e,r),o(e,pi,r),f(Pt,e,r),o(e,di,r),o(e,hr,r),t(hr,Wm),o(e,ci,r),o(e,_r,r),t(_r,Rm),o(e,mi,r),f(At,e,r),o(e,fi,r),o(e,Ze,r),t(Ze,Hm),t(Ze,$n),t($n,Bm),t(Ze,Ym),o(e,vi,r),f(Xe,e,r),o(e,hi,r),o(e,he,r),t(he,es),t(es,gn),f(Dt,gn,null),t(he,Jm),t(he,kn),t(kn,Km),o(e,_i,r),o(e,br,r),t(br,Qm),o(e,bi,r),o(e,_e,r),t(_e,ss),t(ss,jn),f(Tt,jn,null),t(_e,Zm),t(_e,En),t(En,Xm),o(e,qi,r),o(e,ts,r),t(ts,ef),t(ts,zn),t(zn,sf),t(ts,tf),o(e,$i,r),o(e,R,r),t(R,yn),t(yn,rf),t(R,af),t(R,wn),t(wn,nf),t(R,of),t(R,xn),t(xn,lf),t(R,uf),t(R,Cn),t(Cn,pf),o(e,gi,r),f(rs,e,r),o(e,ki,r),o(e,as,r),t(as,df),t(as,Pn),t(Pn,cf),t(as,mf),o(e,ji,r),o(e,qr,r),t(qr,ff),o(e,Ei,r),o(e,$r,r),t($r,vf),o(e,zi,r),o(e,be,r),t(be,ns),t(ns,An),f(St,An,null),t(be,hf),t(be,Dn),t(Dn,_f),o(e,yi,r),o(e,gr,r),t(gr,bf),o(e,wi,r),o(e,le,r),t(le,qf),t(le,Tn),t(Tn,$f),t(le,gf),t(le,Sn),t(Sn,kf),t(le,jf),o(e,xi,r),f(Lt,e,r),o(e,Ci,r),f(os,e,r),o(e,Pi,r),o(e,ls,r),t(ls,Ef),t(ls,Ln),t(Ln,zf),t(ls,yf),o(e,Ai,r),f(Ut,e,r),o(e,Di,r),f(Nt,e,r),o(e,Ti,r),o(e,kr,r),t(kr,wf),o(e,Si,r),o(e,jr,r),t(jr,xf),o(e,Li,r),f(is,e,r),o(e,Ui,r),o(e,qe,r),t(qe,us),t(us,Un),f(Mt,Un,null),t(qe,Cf),t(qe,Nn),t(Nn,Pf),o(e,Ni,r),o(e,ps,r),t(ps,Af),t(ps,Mn),t(Mn,Df),t(ps,Tf),o(e,Mi,r),o(e,ds,r),t(ds,Sf),t(ds,On),t(On,Lf),t(ds,Uf),o(e,Oi,r),o(e,Er,r),t(Er,Nf),o(e,Vi,r),o(e,$e,r),t($e,cs),t(cs,Vn),f(Ot,Vn,null),t($e,Mf),t($e,In),t(In,Of),o(e,Ii,r),o(e,ms,r),t(ms,Vf),t(ms,Vt),t(Vt,If),t(ms,Ff),o(e,Fi,r),o(e,zr,r),t(zr,Gf),o(e,Gi,r),o(e,H,r),t(H,yr),t(yr,It),t(It,Wf),t(yr,Rf),t(H,Hf),t(H,wr),t(wr,Ft),t(Ft,Bf),t(wr,Yf),t(H,Jf),t(H,xr),t(xr,Gt),t(Gt,Kf),t(xr,Qf),t(H,Zf),t(H,Cr),t(Cr,Wt),t(Wt,Xf),t(Cr,ev),o(e,Wi,r),o(e,B,r),t(B,sv),t(B,Fn),t(Fn,tv),t(B,rv),t(B,Gn),t(Gn,av),t(B,nv),t(B,Wn),t(Wn,ov),t(B,lv),Ri=!0},p(e,[r]){const Rt={};r&1&&(Rt.fw=e[0]),g.$set(Rt);const Rn={};r&2&&(Rn.$$scope={dirty:r,ctx:e}),Ae.$set(Rn);const Hn={};r&2&&(Hn.$$scope={dirty:r,ctx:e}),Re.$set(Hn);const Bn={};r&2&&(Bn.$$scope={dirty:r,ctx:e}),Je.$set(Bn);const Q={};r&2&&(Q.$$scope={dirty:r,ctx:e}),Xe.$set(Q);const Yn={};r&2&&(Yn.$$scope={dirty:r,ctx:e}),rs.$set(Yn);const Jn={};r&2&&(Jn.$$scope={dirty:r,ctx:e}),os.$set(Jn);const Kn={};r&2&&(Kn.$$scope={dirty:r,ctx:e}),is.$set(Kn)},i(e){Ri||(v(g.$$.fragment,e),v(w.$$.fragment,e),v(C.$$.fragment,e),v(Es.$$.fragment,e),v(zs.$$.fragment,e),v(ws.$$.fragment,e),v(xs.$$.fragment,e),v(Cs.$$.fragment,e),v(Ps.$$.fragment,e),v(As.$$.fragment,e),v(Ds.$$.fragment,e),v(Ts.$$.fragment,e),v(Ss.$$.fragment,e),v(Ls.$$.fragment,e),v(Us.$$.fragment,e),v(Ns.$$.fragment,e),v(Ms.$$.fragment,e),v(Os.$$.fragment,e),v(Vs.$$.fragment,e),v(Fs.$$.fragment,e),v(Gs.$$.fragment,e),v(Ws.$$.fragment,e),v(Rs.$$.fragment,e),v(Hs.$$.fragment,e),v(Bs.$$.fragment,e),v(Ys.$$.fragment,e),v(Js.$$.fragment,e),v(Ae.$$.fragment,e),v(Ks.$$.fragment,e),v(Qs.$$.fragment,e),v(Zs.$$.fragment,e),v(Xs.$$.fragment,e),v(et.$$.fragment,e),v(st.$$.fragment,e),v(tt.$$.fragment,e),v(rt.$$.fragment,e),v(at.$$.fragment,e),v(nt.$$.fragment,e),v(ot.$$.fragment,e),v(lt.$$.fragment,e),v(it.$$.fragment,e),v(ut.$$.fragment,e),v(pt.$$.fragment,e),v(dt.$$.fragment,e),v(ct.$$.fragment,e),v(mt.$$.fragment,e),v(ft.$$.fragment,e),v(vt.$$.fragment,e),v(ht.$$.fragment,e),v(_t.$$.fragment,e),v(Re.$$.fragment,e),v(bt.$$.fragment,e),v(qt.$$.fragment,e),v($t.$$.fragment,e),v(gt.$$.fragment,e),v(kt.$$.fragment,e),v(Je.$$.fragment,e),v(jt.$$.fragment,e),v(Et.$$.fragment,e),v(zt.$$.fragment,e),v(yt.$$.fragment,e),v(wt.$$.fragment,e),v(xt.$$.fragment,e),v(Ct.$$.fragment,e),v(Pt.$$.fragment,e),v(At.$$.fragment,e),v(Xe.$$.fragment,e),v(Dt.$$.fragment,e),v(Tt.$$.fragment,e),v(rs.$$.fragment,e),v(St.$$.fragment,e),v(Lt.$$.fragment,e),v(os.$$.fragment,e),v(Ut.$$.fragment,e),v(Nt.$$.fragment,e),v(is.$$.fragment,e),v(Mt.$$.fragment,e),v(Ot.$$.fragment,e),Ri=!0)},o(e){h(g.$$.fragment,e),h(w.$$.fragment,e),h(C.$$.fragment,e),h(Es.$$.fragment,e),h(zs.$$.fragment,e),h(ws.$$.fragment,e),h(xs.$$.fragment,e),h(Cs.$$.fragment,e),h(Ps.$$.fragment,e),h(As.$$.fragment,e),h(Ds.$$.fragment,e),h(Ts.$$.fragment,e),h(Ss.$$.fragment,e),h(Ls.$$.fragment,e),h(Us.$$.fragment,e),h(Ns.$$.fragment,e),h(Ms.$$.fragment,e),h(Os.$$.fragment,e),h(Vs.$$.fragment,e),h(Fs.$$.fragment,e),h(Gs.$$.fragment,e),h(Ws.$$.fragment,e),h(Rs.$$.fragment,e),h(Hs.$$.fragment,e),h(Bs.$$.fragment,e),h(Ys.$$.fragment,e),h(Js.$$.fragment,e),h(Ae.$$.fragment,e),h(Ks.$$.fragment,e),h(Qs.$$.fragment,e),h(Zs.$$.fragment,e),h(Xs.$$.fragment,e),h(et.$$.fragment,e),h(st.$$.fragment,e),h(tt.$$.fragment,e),h(rt.$$.fragment,e),h(at.$$.fragment,e),h(nt.$$.fragment,e),h(ot.$$.fragment,e),h(lt.$$.fragment,e),h(it.$$.fragment,e),h(ut.$$.fragment,e),h(pt.$$.fragment,e),h(dt.$$.fragment,e),h(ct.$$.fragment,e),h(mt.$$.fragment,e),h(ft.$$.fragment,e),h(vt.$$.fragment,e),h(ht.$$.fragment,e),h(_t.$$.fragment,e),h(Re.$$.fragment,e),h(bt.$$.fragment,e),h(qt.$$.fragment,e),h($t.$$.fragment,e),h(gt.$$.fragment,e),h(kt.$$.fragment,e),h(Je.$$.fragment,e),h(jt.$$.fragment,e),h(Et.$$.fragment,e),h(zt.$$.fragment,e),h(yt.$$.fragment,e),h(wt.$$.fragment,e),h(xt.$$.fragment,e),h(Ct.$$.fragment,e),h(Pt.$$.fragment,e),h(At.$$.fragment,e),h(Xe.$$.fragment,e),h(Dt.$$.fragment,e),h(Tt.$$.fragment,e),h(rs.$$.fragment,e),h(St.$$.fragment,e),h(Lt.$$.fragment,e),h(os.$$.fragment,e),h(Ut.$$.fragment,e),h(Nt.$$.fragment,e),h(is.$$.fragment,e),h(Mt.$$.fragment,e),h(Ot.$$.fragment,e),Ri=!1},d(e){s(b),e&&s(E),_(g,e),e&&s(j),e&&s(y),_(w),e&&s(N),_(C,e),e&&s(js),e&&s(L),e&&s(Qn),e&&s(ue),_(Es),e&&s(Zn),_(zs,e),e&&s(Xn),e&&s(X),e&&s(eo),e&&s(ke),e&&s(so),e&&s(ee),e&&s(to),_(ws,e),e&&s(ro),e&&s(Jt),e&&s(ao),_(xs,e),e&&s(no),e&&s(pe),_(Cs),e&&s(oo),e&&s(Ee),e&&s(lo),e&&s(ze),e&&s(io),_(Ps,e),e&&s(uo),_(As,e),e&&s(po),e&&s(se),e&&s(co),e&&s(A),e&&s(mo),_(Ds,e),e&&s(fo),e&&s(Kt),e&&s(vo),_(Ts,e),e&&s(ho),e&&s(ye),e&&s(_o),_(Ss,e),e&&s(bo),e&&s(Qt),e&&s(qo),e&&s(we),e&&s($o),_(Ls,e),e&&s(go),_(Us,e),e&&s(ko),e&&s(Zt),e&&s(jo),_(Ns,e),e&&s(Eo),_(Ms,e),e&&s(zo),e&&s(U),e&&s(yo),_(Os,e),e&&s(wo),_(Vs,e),e&&s(xo),e&&s(te),e&&s(Co),e&&s(xe),e&&s(Po),_(Fs,e),e&&s(Ao),_(Gs,e),e&&s(Do),e&&s(Ce),e&&s(To),_(Ws,e),e&&s(So),_(Rs,e),e&&s(Lo),e&&s(Xt),e&&s(Uo),_(Hs,e),e&&s(No),_(Bs,e),e&&s(Mo),e&&s(re),e&&s(Oo),_(Ys,e),e&&s(Vo),_(Js,e),e&&s(Io),e&&s(ae),e&&s(Fo),e&&s(Pe),e&&s(Go),_(Ae,e),e&&s(Wo),e&&s(er),e&&s(Ro),e&&s(sr),e&&s(Ho),e&&s(de),_(Ks),e&&s(Bo),e&&s(D),e&&s(Yo),_(Qs,e),e&&s(Jo),e&&s(ne),e&&s(Ko),_(Zs,e),e&&s(Qo),e&&s(O),e&&s(Zo),_(Xs,e),e&&s(Xo),_(et,e),e&&s(el),e&&s(V),e&&s(sl),e&&s(I),e&&s(tl),_(st,e),e&&s(rl),e&&s(tr),e&&s(al),_(tt,e),e&&s(nl),e&&s(rr),e&&s(ol),e&&s(ar),e&&s(ll),_(rt,e),e&&s(il),e&&s(T),e&&s(ul),_(at,e),e&&s(pl),e&&s(nr),e&&s(dl),e&&s(or),e&&s(cl),e&&s(ce),_(nt),e&&s(ml),e&&s(lr),e&&s(fl),_(ot,e),e&&s(vl),e&&s(F),e&&s(hl),e&&s(Se),e&&s(_l),e&&s(Le),e&&s(bl),e&&s(Ue),e&&s(ql),_(lt,e),e&&s($l),_(it,e),e&&s(gl),e&&s(Ne),e&&s(kl),_(ut,e),e&&s(jl),_(pt,e),e&&s(El),e&&s(ir),e&&s(zl),_(dt,e),e&&s(yl),e&&s(Me),e&&s(wl),_(ct,e),e&&s(xl),e&&s(ur),e&&s(Cl),_(mt,e),e&&s(Pl),e&&s(Oe),e&&s(Al),e&&s(me),_(ft),e&&s(Dl),e&&s(pr),e&&s(Tl),e&&s(Ie),e&&s(Sl),_(vt,e),e&&s(Ll),e&&s(dr),e&&s(Ul),e&&s(oe),e&&s(Nl),_(ht,e),e&&s(Ml),e&&s(Fe),e&&s(Ol),e&&s(fe),_(_t),e&&s(Vl),e&&s(We),e&&s(Il),e&&s(mr),e&&s(Fl),_(Re,e),e&&s(Gl),e&&s(ve),_(bt),e&&s(Wl),e&&s(Be),e&&s(Rl),_(qt,e),e&&s(Hl),_($t,e),e&&s(Bl),e&&s(fr),e&&s(Yl),e&&s(Ye),e&&s(Jl),_(gt,e),e&&s(Kl),_(kt,e),e&&s(Ql),_(Je,e),e&&s(Zl),e&&s(vr),e&&s(Xl),_(jt,e),e&&s(ei),e&&s(Ke),e&&s(si),_(Et,e),e&&s(ti),e&&s(G),e&&s(ri),_(zt,e),e&&s(ai),_(yt,e),e&&s(ni),e&&s(W),e&&s(oi),_(wt,e),e&&s(li),_(xt,e),e&&s(ii),e&&s(Qe),e&&s(ui),_(Ct,e),e&&s(pi),_(Pt,e),e&&s(di),e&&s(hr),e&&s(ci),e&&s(_r),e&&s(mi),_(At,e),e&&s(fi),e&&s(Ze),e&&s(vi),_(Xe,e),e&&s(hi),e&&s(he),_(Dt),e&&s(_i),e&&s(br),e&&s(bi),e&&s(_e),_(Tt),e&&s(qi),e&&s(ts),e&&s($i),e&&s(R),e&&s(gi),_(rs,e),e&&s(ki),e&&s(as),e&&s(ji),e&&s(qr),e&&s(Ei),e&&s($r),e&&s(zi),e&&s(be),_(St),e&&s(yi),e&&s(gr),e&&s(wi),e&&s(le),e&&s(xi),_(Lt,e),e&&s(Ci),_(os,e),e&&s(Pi),e&&s(ls),e&&s(Ai),_(Ut,e),e&&s(Di),_(Nt,e),e&&s(Ti),e&&s(kr),e&&s(Si),e&&s(jr),e&&s(Li),_(is,e),e&&s(Ui),e&&s(qe),_(Mt),e&&s(Ni),e&&s(ps),e&&s(Mi),e&&s(ds),e&&s(Oi),e&&s(Er),e&&s(Vi),e&&s($e),_(Ot),e&&s(Ii),e&&s(ms),e&&s(Fi),e&&s(zr),e&&s(Gi),e&&s(H),e&&s(Wi),e&&s(B)}}}const wb={local:"dbogage-du-pipeline-dentranement",sections:[{local:"dboguer-le-pipeline-dentranement",sections:[{local:"vrifiez-vos-donnes",title:"V\xE9rifiez vos donn\xE9es"},{local:"des-jeux-de-donnes-aux-chargeurs-de-donnes",title:"Des jeux de donn\xE9es aux chargeurs de donn\xE9es"},{local:"passage-par-le-modle",title:"Passage par le mod\xE8le"},{local:"excution-dune-tape-doptimisation",title:"Ex\xE9cution d'une \xE9tape d'optimisation"},{local:"grer-les-erreurs-icuda-out-of-memoryi",title:"G\xE9rer les erreurs <i>CUDA out of memory</i>"},{local:"valuation-du-modle",title:"\xC9valuation du mod\xE8le"}],title:"D\xE9boguer le pipeline d'entra\xEEnement"},{local:"dboguer-les-erreurs-silencieuses-pendant-lentranement",sections:[{local:"vrifiez-vos-donnes-encore",title:"V\xE9rifiez vos donn\xE9es (encore !)"},{local:"surentranement-du-modle-sur-un-seul-batch",title:"Surentra\xEEnement du mod\xE8le sur un seul batch"},{local:"ne-rglez-rien-tant-que-vous-navez-pas-une-premire-ligne-de-base",title:"Ne r\xE9glez rien tant que vous n'avez pas une premi\xE8re ligne de base"},{local:"demander-de-laide",title:"Demander de l'aide"}],title:"D\xE9boguer les erreurs silencieuses pendant l'entra\xEEnement"}],title:"D\xE9bogage du pipeline d'entra\xEEnement"};function xb(P,b,E){let g="pt";return vb(()=>{const j=new URLSearchParams(window.location.search);E(0,g=j.get("fw")||"pt")}),[g]}class Ub extends db{constructor(b){super();cb(this,b,xb,yb,mb,{})}}export{Ub as default,wb as metadata};
