import{S as wt,i as yt,s as $t,e as o,k as _,w as It,t as r,M as Tt,c as a,d as t,m as E,a as l,x as At,h as n,b as f,G as e,g as h,y as Nt,L as jt,q as Dt,o as St,B as Ct,v as Ut}from"../../chunks/vendor-hf-doc-builder.js";import{I as Bt}from"../../chunks/IconCopyLink-hf-doc-builder.js";function Gt(ot){let k,Z,q,b,j,L,ie,D,ue,ee,i,ce,y,me,pe,S,de,fe,C,he,ve,U,_e,Ee,B,ke,qe,te,u,ze,G,xe,be,M,Me,H,ge,Pe,J,Le,we,g,ye,O,$e,Ie,R,Te,Ae,re,$,Ne,ne,m,z,je,F,De,Se,K,Ce,Ue,Be,w,Ge,Q,He,Je,Oe,V,Re,Fe,x,Ke,W,Qe,Ve,X,We,Xe,se,v,Ye,I,Ze,et,Y,tt,rt,oe;return L=new Bt({}),{c(){k=o("meta"),Z=_(),q=o("h1"),b=o("a"),j=o("span"),It(L.$$.fragment),ie=_(),D=o("span"),ue=r("Introduction"),ee=_(),i=o("p"),ce=r("Dans le "),y=o("a"),me=r("chapitre 3"),pe=r(", nous avons vu comment "),S=o("em"),de=r("finetuner"),fe=r(" un mod\xE8le sur une t\xE2che donn\xE9e. Pour ce faire, nous utilisons le m\xEAme "),C=o("em"),he=r("tokenizer"),ve=r(" que celui avec lequel le mod\xE8le a \xE9t\xE9 pr\xE9-entra\xEEn\xE9. Mais que faisons-nous lorsque nous voulons entra\xEEner un mod\xE8le \xE0 partir de z\xE9ro ? Dans ces cas, l\u2019utilisation d\u2019un "),U=o("em"),_e=r("tokenizer"),Ee=r(" qui a \xE9t\xE9 pr\xE9-entra\xEEn\xE9 sur un corpus d\u2019un autre domaine ou d\u2019une autre langue est g\xE9n\xE9ralement sous-optimale. Par exemple, un "),B=o("em"),ke=r("tokenizer"),qe=r(" entra\xEEn\xE9 sur un corpus anglais sera peu performant sur un corpus de textes japonais car l\u2019utilisation des espaces et de la ponctuation est tr\xE8s diff\xE9rente entre les deux langues."),te=_(),u=o("p"),ze=r("Dans ce chapitre, vous apprendrez \xE0 entra\xEEner un tout nouveau "),G=o("em"),xe=r("tokenizer"),be=r(" sur un corpus de textes afin qu\u2019il puisse ensuite \xEAtre utilis\xE9 pour pr\xE9-entra\xEEner un mod\xE8le de langue. Tout cela se fera \xE0 l\u2019aide de la biblioth\xE8que "),M=o("a"),Me=r("\u{1F917} "),H=o("em"),ge=r("Tokenizers"),Pe=r(", qui fournit les "),J=o("em"),Le=r("tokenizers"),we=r(" \xAB rapides \xBB de la biblioth\xE8que "),g=o("a"),ye=r("\u{1F917} "),O=o("em"),$e=r("Transformers"),Ie=r(". Nous examinerons de pr\xE8s les fonctionnalit\xE9s offertes par cette biblioth\xE8que et nous \xE9tudierons comment les "),R=o("em"),Te=r("tokenizers"),Ae=r(" rapides diff\xE8rent des versions \xAB lentes \xBB."),re=_(),$=o("p"),Ne=r("Les sujets que nous couvrirons comprennent :"),ne=_(),m=o("ul"),z=o("li"),je=r("comment entra\xEEner sur un nouveau corpus de textes, un nouveau "),F=o("em"),De=r("tokenizer"),Se=r(" similaire \xE0 celui utilis\xE9 par un "),K=o("em"),Ce=r("checkpoint"),Ue=r(" donn\xE9,"),Be=_(),w=o("li"),Ge=r("les caract\xE9ristiques sp\xE9ciales des "),Q=o("em"),He=r("tokenizers"),Je=r(" rapides,"),Oe=_(),V=o("li"),Re=r("les diff\xE9rences entre les trois principaux algorithmes de tok\xE9nisation utilis\xE9s aujourd\u2019hui en NLP,"),Fe=_(),x=o("li"),Ke=r("comment construire un "),W=o("em"),Qe=r("tokenizer"),Ve=r(" \xE0 partir de z\xE9ro avec la biblioth\xE8que \u{1F917} "),X=o("em"),We=r("Tokenizers"),Xe=r(" et l\u2019entra\xEEner sur des donn\xE9es."),se=_(),v=o("p"),Ye=r("Les techniques pr\xE9sent\xE9es dans ce chapitre vous pr\xE9pareront \xE0 la section du "),I=o("a"),Ze=r("chapitre 7"),et=r(" o\xF9 nous verrons comment cr\xE9er un mod\xE8le de langue pour le langage Python. Commen\xE7ons par examiner ce que signifie \xAB entra\xEEner \xBB un "),Y=o("em"),tt=r("tokenizer"),rt=r("."),this.h()},l(s){const c=Tt('[data-svelte="svelte-1phssyn"]',document.head);k=a(c,"META",{name:!0,content:!0}),c.forEach(t),Z=E(s),q=a(s,"H1",{class:!0});var ae=l(q);b=a(ae,"A",{id:!0,class:!0,href:!0});var at=l(b);j=a(at,"SPAN",{});var lt=l(j);At(L.$$.fragment,lt),lt.forEach(t),at.forEach(t),ie=E(ae),D=a(ae,"SPAN",{});var it=l(D);ue=n(it,"Introduction"),it.forEach(t),ae.forEach(t),ee=E(s),i=a(s,"P",{});var p=l(i);ce=n(p,"Dans le "),y=a(p,"A",{href:!0});var ut=l(y);me=n(ut,"chapitre 3"),ut.forEach(t),pe=n(p,", nous avons vu comment "),S=a(p,"EM",{});var ct=l(S);de=n(ct,"finetuner"),ct.forEach(t),fe=n(p," un mod\xE8le sur une t\xE2che donn\xE9e. Pour ce faire, nous utilisons le m\xEAme "),C=a(p,"EM",{});var mt=l(C);he=n(mt,"tokenizer"),mt.forEach(t),ve=n(p," que celui avec lequel le mod\xE8le a \xE9t\xE9 pr\xE9-entra\xEEn\xE9. Mais que faisons-nous lorsque nous voulons entra\xEEner un mod\xE8le \xE0 partir de z\xE9ro ? Dans ces cas, l\u2019utilisation d\u2019un "),U=a(p,"EM",{});var pt=l(U);_e=n(pt,"tokenizer"),pt.forEach(t),Ee=n(p," qui a \xE9t\xE9 pr\xE9-entra\xEEn\xE9 sur un corpus d\u2019un autre domaine ou d\u2019une autre langue est g\xE9n\xE9ralement sous-optimale. Par exemple, un "),B=a(p,"EM",{});var dt=l(B);ke=n(dt,"tokenizer"),dt.forEach(t),qe=n(p," entra\xEEn\xE9 sur un corpus anglais sera peu performant sur un corpus de textes japonais car l\u2019utilisation des espaces et de la ponctuation est tr\xE8s diff\xE9rente entre les deux langues."),p.forEach(t),te=E(s),u=a(s,"P",{});var d=l(u);ze=n(d,"Dans ce chapitre, vous apprendrez \xE0 entra\xEEner un tout nouveau "),G=a(d,"EM",{});var ft=l(G);xe=n(ft,"tokenizer"),ft.forEach(t),be=n(d," sur un corpus de textes afin qu\u2019il puisse ensuite \xEAtre utilis\xE9 pour pr\xE9-entra\xEEner un mod\xE8le de langue. Tout cela se fera \xE0 l\u2019aide de la biblioth\xE8que "),M=a(d,"A",{href:!0,rel:!0});var nt=l(M);Me=n(nt,"\u{1F917} "),H=a(nt,"EM",{});var ht=l(H);ge=n(ht,"Tokenizers"),ht.forEach(t),nt.forEach(t),Pe=n(d,", qui fournit les "),J=a(d,"EM",{});var vt=l(J);Le=n(vt,"tokenizers"),vt.forEach(t),we=n(d," \xAB rapides \xBB de la biblioth\xE8que "),g=a(d,"A",{href:!0,rel:!0});var st=l(g);ye=n(st,"\u{1F917} "),O=a(st,"EM",{});var _t=l(O);$e=n(_t,"Transformers"),_t.forEach(t),st.forEach(t),Ie=n(d,". Nous examinerons de pr\xE8s les fonctionnalit\xE9s offertes par cette biblioth\xE8que et nous \xE9tudierons comment les "),R=a(d,"EM",{});var Et=l(R);Te=n(Et,"tokenizers"),Et.forEach(t),Ae=n(d," rapides diff\xE8rent des versions \xAB lentes \xBB."),d.forEach(t),re=E(s),$=a(s,"P",{});var kt=l($);Ne=n(kt,"Les sujets que nous couvrirons comprennent :"),kt.forEach(t),ne=E(s),m=a(s,"UL",{});var P=l(m);z=a(P,"LI",{});var T=l(z);je=n(T,"comment entra\xEEner sur un nouveau corpus de textes, un nouveau "),F=a(T,"EM",{});var qt=l(F);De=n(qt,"tokenizer"),qt.forEach(t),Se=n(T," similaire \xE0 celui utilis\xE9 par un "),K=a(T,"EM",{});var zt=l(K);Ce=n(zt,"checkpoint"),zt.forEach(t),Ue=n(T," donn\xE9,"),T.forEach(t),Be=E(P),w=a(P,"LI",{});var le=l(w);Ge=n(le,"les caract\xE9ristiques sp\xE9ciales des "),Q=a(le,"EM",{});var xt=l(Q);He=n(xt,"tokenizers"),xt.forEach(t),Je=n(le," rapides,"),le.forEach(t),Oe=E(P),V=a(P,"LI",{});var bt=l(V);Re=n(bt,"les diff\xE9rences entre les trois principaux algorithmes de tok\xE9nisation utilis\xE9s aujourd\u2019hui en NLP,"),bt.forEach(t),Fe=E(P),x=a(P,"LI",{});var A=l(x);Ke=n(A,"comment construire un "),W=a(A,"EM",{});var Mt=l(W);Qe=n(Mt,"tokenizer"),Mt.forEach(t),Ve=n(A," \xE0 partir de z\xE9ro avec la biblioth\xE8que \u{1F917} "),X=a(A,"EM",{});var gt=l(X);We=n(gt,"Tokenizers"),gt.forEach(t),Xe=n(A," et l\u2019entra\xEEner sur des donn\xE9es."),A.forEach(t),P.forEach(t),se=E(s),v=a(s,"P",{});var N=l(v);Ye=n(N,"Les techniques pr\xE9sent\xE9es dans ce chapitre vous pr\xE9pareront \xE0 la section du "),I=a(N,"A",{href:!0});var Pt=l(I);Ze=n(Pt,"chapitre 7"),Pt.forEach(t),et=n(N," o\xF9 nous verrons comment cr\xE9er un mod\xE8le de langue pour le langage Python. Commen\xE7ons par examiner ce que signifie \xAB entra\xEEner \xBB un "),Y=a(N,"EM",{});var Lt=l(Y);tt=n(Lt,"tokenizer"),Lt.forEach(t),rt=n(N,"."),N.forEach(t),this.h()},h(){f(k,"name","hf:doc:metadata"),f(k,"content",JSON.stringify(Ht)),f(b,"id","introduction"),f(b,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(b,"href","#introduction"),f(q,"class","relative group"),f(y,"href","/course/fr/chapter3"),f(M,"href","https://github.com/huggingface/tokenizers"),f(M,"rel","nofollow"),f(g,"href","https://github.com/huggingface/transformers"),f(g,"rel","nofollow"),f(I,"href","/course/fr/chapter7/6")},m(s,c){e(document.head,k),h(s,Z,c),h(s,q,c),e(q,b),e(b,j),Nt(L,j,null),e(q,ie),e(q,D),e(D,ue),h(s,ee,c),h(s,i,c),e(i,ce),e(i,y),e(y,me),e(i,pe),e(i,S),e(S,de),e(i,fe),e(i,C),e(C,he),e(i,ve),e(i,U),e(U,_e),e(i,Ee),e(i,B),e(B,ke),e(i,qe),h(s,te,c),h(s,u,c),e(u,ze),e(u,G),e(G,xe),e(u,be),e(u,M),e(M,Me),e(M,H),e(H,ge),e(u,Pe),e(u,J),e(J,Le),e(u,we),e(u,g),e(g,ye),e(g,O),e(O,$e),e(u,Ie),e(u,R),e(R,Te),e(u,Ae),h(s,re,c),h(s,$,c),e($,Ne),h(s,ne,c),h(s,m,c),e(m,z),e(z,je),e(z,F),e(F,De),e(z,Se),e(z,K),e(K,Ce),e(z,Ue),e(m,Be),e(m,w),e(w,Ge),e(w,Q),e(Q,He),e(w,Je),e(m,Oe),e(m,V),e(V,Re),e(m,Fe),e(m,x),e(x,Ke),e(x,W),e(W,Qe),e(x,Ve),e(x,X),e(X,We),e(x,Xe),h(s,se,c),h(s,v,c),e(v,Ye),e(v,I),e(I,Ze),e(v,et),e(v,Y),e(Y,tt),e(v,rt),oe=!0},p:jt,i(s){oe||(Dt(L.$$.fragment,s),oe=!0)},o(s){St(L.$$.fragment,s),oe=!1},d(s){t(k),s&&t(Z),s&&t(q),Ct(L),s&&t(ee),s&&t(i),s&&t(te),s&&t(u),s&&t(re),s&&t($),s&&t(ne),s&&t(m),s&&t(se),s&&t(v)}}}const Ht={local:"introduction",title:"Introduction"};function Jt(ot){return Ut(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ft extends wt{constructor(k){super();yt(this,k,Jt,Gt,$t,{})}}export{Ft as default,Ht as metadata};
