import{S as Xv,i as Zv,s as Kv,e as l,w as j,k as c,t as n,c as r,a as o,x as w,d as s,m as d,h as a,b as _,g as u,G as e,y as x,q as b,o as $,B as C,M as Yv,N as ed,p as Yo,v as Jv,n as Jo,L as Hv}from"../../chunks/vendor-hf-doc-builder.js";import{T as Qo}from"../../chunks/Tip-hf-doc-builder.js";import{Y as Gv}from"../../chunks/Youtube-hf-doc-builder.js";import{I as it}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as A}from"../../chunks/CodeBlock-hf-doc-builder.js";import{C as Wv}from"../../chunks/CourseFloatingBanner-hf-doc-builder.js";import{F as Qv}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function eh(X){let p,g;return p=new Wv({props:{chapter:7,classNames:"absolute z-10 right-0 top-0",notebooks:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/fr/chapter7/section2_tf.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/fr/chapter7/section2_tf.ipynb"}]}}),{c(){j(p.$$.fragment)},l(v){w(p.$$.fragment,v)},m(v,q){x(p,v,q),g=!0},i(v){g||(b(p.$$.fragment,v),g=!0)},o(v){$(p.$$.fragment,v),g=!1},d(v){C(p,v)}}}function sh(X){let p,g;return p=new Wv({props:{chapter:7,classNames:"absolute z-10 right-0 top-0",notebooks:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/fr/chapter7/section2_pt.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/fr/chapter7/section2_pt.ipynb"}]}}),{c(){j(p.$$.fragment)},l(v){w(p.$$.fragment,v)},m(v,q){x(p,v,q),g=!0},i(v){g||(b(p.$$.fragment,v),g=!0)},o(v){$(p.$$.fragment,v),g=!1},d(v){C(p,v)}}}function th(X){let p,g,v,q,z,E,k,P;return{c(){p=l("p"),g=n("\u{1F4A1} Tant que votre jeu de donn\xE9es consiste en des textes divis\xE9s en mots avec leurs \xE9tiquettes correspondantes, vous pourrez adapter les proc\xE9dures de traitement des donn\xE9es d\xE9crites ici \xE0 votre propre jeu de donn\xE9es. Reportez-vous au "),v=l("a"),q=n("chapitre 5"),z=n(" si vous avez besoin d\u2019un rafra\xEEchissement sur la fa\xE7on de charger vos propres donn\xE9es personnalis\xE9es dans un "),E=l("code"),k=n("Dataset"),P=n("."),this.h()},l(y){p=r(y,"P",{});var O=o(p);g=a(O,"\u{1F4A1} Tant que votre jeu de donn\xE9es consiste en des textes divis\xE9s en mots avec leurs \xE9tiquettes correspondantes, vous pourrez adapter les proc\xE9dures de traitement des donn\xE9es d\xE9crites ici \xE0 votre propre jeu de donn\xE9es. Reportez-vous au "),v=r(O,"A",{href:!0});var H=o(v);q=a(H,"chapitre 5"),H.forEach(s),z=a(O," si vous avez besoin d\u2019un rafra\xEEchissement sur la fa\xE7on de charger vos propres donn\xE9es personnalis\xE9es dans un "),E=r(O,"CODE",{});var I=o(E);k=a(I,"Dataset"),I.forEach(s),P=a(O,"."),O.forEach(s),this.h()},h(){_(v,"href","/course/fr/chapter5")},m(y,O){u(y,p,O),e(p,g),e(p,v),e(v,q),e(p,z),e(p,E),e(E,k),e(p,P)},d(y){y&&s(p)}}}function nh(X){let p,g,v,q,z,E,k,P;return{c(){p=l("p"),g=n("\u270F\uFE0F "),v=l("em"),q=n("A votre tour !"),z=n(" Affichez les deux m\xEAmes phrases avec leurs \xE9tiquettes POS ou "),E=l("em"),k=n("chunking"),P=n(".")},l(y){p=r(y,"P",{});var O=o(p);g=a(O,"\u270F\uFE0F "),v=r(O,"EM",{});var H=o(v);q=a(H,"A votre tour !"),H.forEach(s),z=a(O," Affichez les deux m\xEAmes phrases avec leurs \xE9tiquettes POS ou "),E=r(O,"EM",{});var I=o(E);k=a(I,"chunking"),I.forEach(s),P=a(O,"."),O.forEach(s)},m(y,O){u(y,p,O),e(p,g),e(p,v),e(v,q),e(p,z),e(p,E),e(E,k),e(p,P)},d(y){y&&s(p)}}}function ah(X){let p,g,v,q,z,E,k,P,y,O,H;return{c(){p=l("p"),g=n("\u270F\uFE0F "),v=l("em"),q=n("A votre tour !"),z=n(" Certains chercheurs pr\xE9f\xE8rent n\u2019attribuer qu\u2019une seule \xE9tiquette par mot et attribuer "),E=l("code"),k=n("-100"),P=n(" aux autres sous-"),y=l("em"),O=n("tokens"),H=n(" dans un mot donn\xE9. Ceci afin d\u2019\xE9viter que les longs mots qui se divisent en plusieurs batchs ne contribuent fortement \xE0 la perte. Changez la fonction pr\xE9c\xE9dente pour aligner les \xE9tiquettes avec les identifiants d\u2019entr\xE9e en suivant cette r\xE8gle.")},l(I){p=r(I,"P",{});var L=o(p);g=a(L,"\u270F\uFE0F "),v=r(L,"EM",{});var F=o(v);q=a(F,"A votre tour !"),F.forEach(s),z=a(L," Certains chercheurs pr\xE9f\xE8rent n\u2019attribuer qu\u2019une seule \xE9tiquette par mot et attribuer "),E=r(L,"CODE",{});var T=o(E);k=a(T,"-100"),T.forEach(s),P=a(L," aux autres sous-"),y=r(L,"EM",{});var U=o(y);O=a(U,"tokens"),U.forEach(s),H=a(L," dans un mot donn\xE9. Ceci afin d\u2019\xE9viter que les longs mots qui se divisent en plusieurs batchs ne contribuent fortement \xE0 la perte. Changez la fonction pr\xE9c\xE9dente pour aligner les \xE9tiquettes avec les identifiants d\u2019entr\xE9e en suivant cette r\xE8gle."),L.forEach(s)},m(I,L){u(I,p,L),e(p,g),e(p,v),e(v,q),e(p,z),e(p,E),e(E,k),e(p,P),e(p,y),e(y,O),e(p,H)},d(I){I&&s(p)}}}function lh(X){let p,g,v,q,z,E,k,P,y,O,H,I,L;return q=new it({}),{c(){p=l("h2"),g=l("a"),v=l("span"),j(q.$$.fragment),z=c(),E=l("span"),k=l("i"),P=n("Finetuning"),y=n(" du mod\xE8le avec Keras"),O=c(),H=l("p"),I=n("Le code utilisant Keras sera tr\xE8s similaire au pr\xE9c\xE9dent. Les seuls changements sont la fa\xE7on dont les donn\xE9es sont rassembl\xE9es dans un batch ainsi que la fonction de calcul de la m\xE9trique."),this.h()},l(F){p=r(F,"H2",{class:!0});var T=o(p);g=r(T,"A",{id:!0,class:!0,href:!0});var U=o(g);v=r(U,"SPAN",{});var W=o(v);w(q.$$.fragment,W),W.forEach(s),U.forEach(s),z=d(T),E=r(T,"SPAN",{});var D=o(E);k=r(D,"I",{});var M=o(k);P=a(M,"Finetuning"),M.forEach(s),y=a(D," du mod\xE8le avec Keras"),D.forEach(s),T.forEach(s),O=d(F),H=r(F,"P",{});var V=o(H);I=a(V,"Le code utilisant Keras sera tr\xE8s similaire au pr\xE9c\xE9dent. Les seuls changements sont la fa\xE7on dont les donn\xE9es sont rassembl\xE9es dans un batch ainsi que la fonction de calcul de la m\xE9trique."),V.forEach(s),this.h()},h(){_(g,"id","ifinetuningi-du-modle-avec-keras"),_(g,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(g,"href","#ifinetuningi-du-modle-avec-keras"),_(p,"class","relative group")},m(F,T){u(F,p,T),e(p,g),e(g,v),x(q,v,null),e(p,z),e(p,E),e(E,k),e(k,P),e(E,y),u(F,O,T),u(F,H,T),e(H,I),L=!0},i(F){L||(b(q.$$.fragment,F),L=!0)},o(F){$(q.$$.fragment,F),L=!1},d(F){F&&s(p),C(q),F&&s(O),F&&s(H)}}}function rh(X){let p,g,v,q,z,E,k,P,y,O,H,I,L,F,T,U,W,D;return q=new it({}),{c(){p=l("h2"),g=l("a"),v=l("span"),j(q.$$.fragment),z=c(),E=l("span"),k=l("i"),P=n("Finetuning"),y=n(" du mod\xE8le avec l'API "),O=l("code"),H=n("Trainer"),I=c(),L=l("p"),F=n("Le code utilisant "),T=l("code"),U=n("Trainer"),W=n(" sera le m\xEAme que pr\xE9c\xE9demment. Les seuls changements sont la fa\xE7on dont les donn\xE9es sont rassembl\xE9es dans un batch ainsi que la fonction de calcul de la m\xE9trique."),this.h()},l(M){p=r(M,"H2",{class:!0});var V=o(p);g=r(V,"A",{id:!0,class:!0,href:!0});var Y=o(g);v=r(Y,"SPAN",{});var se=o(v);w(q.$$.fragment,se),se.forEach(s),Y.forEach(s),z=d(V),E=r(V,"SPAN",{});var N=o(E);k=r(N,"I",{});var G=o(k);P=a(G,"Finetuning"),G.forEach(s),y=a(N," du mod\xE8le avec l'API "),O=r(N,"CODE",{});var te=o(O);H=a(te,"Trainer"),te.forEach(s),N.forEach(s),V.forEach(s),I=d(M),L=r(M,"P",{});var J=o(L);F=a(J,"Le code utilisant "),T=r(J,"CODE",{});var ee=o(T);U=a(ee,"Trainer"),ee.forEach(s),W=a(J," sera le m\xEAme que pr\xE9c\xE9demment. Les seuls changements sont la fa\xE7on dont les donn\xE9es sont rassembl\xE9es dans un batch ainsi que la fonction de calcul de la m\xE9trique."),J.forEach(s),this.h()},h(){_(g,"id","ifinetuningi-du-modle-avec-lapi-trainer"),_(g,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(g,"href","#ifinetuningi-du-modle-avec-lapi-trainer"),_(p,"class","relative group")},m(M,V){u(M,p,V),e(p,g),e(g,v),x(q,v,null),e(p,z),e(p,E),e(E,k),e(k,P),e(E,y),e(E,O),e(O,H),u(M,I,V),u(M,L,V),e(L,F),e(L,T),e(T,U),e(L,W),D=!0},i(M){D||(b(q.$$.fragment,M),D=!0)},o(M){$(q.$$.fragment,M),D=!1},d(M){M&&s(p),C(q),M&&s(I),M&&s(L)}}}function oh(X){let p,g;return p=new A({props:{code:`from transformers import DataCollatorForTokenClassification

data_collator = DataCollatorForTokenClassification(
    tokenizer=tokenizer, return_tensors="tf"
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForTokenClassification

data_collator = DataCollatorForTokenClassification(
    tokenizer=tokenizer, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>
)`}}),{c(){j(p.$$.fragment)},l(v){w(p.$$.fragment,v)},m(v,q){x(p,v,q),g=!0},i(v){g||(b(p.$$.fragment,v),g=!0)},o(v){$(p.$$.fragment,v),g=!1},d(v){C(p,v)}}}function ih(X){let p,g;return p=new A({props:{code:`from transformers import DataCollatorForTokenClassification

data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForTokenClassification

data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)`}}),{c(){j(p.$$.fragment)},l(v){w(p.$$.fragment,v)},m(v,q){x(p,v,q),g=!0},i(v){g||(b(p.$$.fragment,v),g=!0)},o(v){$(p.$$.fragment,v),g=!1},d(v){C(p,v)}}}function uh(X){let p,g,v,q,z,E,k,P,y,O,H,I,L,F,T,U,W;return L=new A({props:{code:`tf_train_dataset = tokenized_datasets["train"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "labels", "token_type_ids"],
    collate_fn=data_collator,
    shuffle=True,
    batch_size=16,
)

tf_eval_dataset = tokenized_datasets["validation"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "labels", "token_type_ids"],
    collate_fn=data_collator,
    shuffle=False,
    batch_size=16,
)`,highlighted:`tf_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].to_tf_dataset(
    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
    collate_fn=data_collator,
    shuffle=<span class="hljs-literal">True</span>,
    batch_size=<span class="hljs-number">16</span>,
)

tf_eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>].to_tf_dataset(
    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
    collate_fn=data_collator,
    shuffle=<span class="hljs-literal">False</span>,
    batch_size=<span class="hljs-number">16</span>,
)`}}),{c(){p=l("p"),g=n("Notre assembleur de donn\xE9es est pr\xEAt \xE0 fonctionner ! Maintenant, utilisons-le pour cr\xE9er un "),v=l("code"),q=n("tf.data.Dataset"),z=n(" avec la m\xE9thode "),E=l("code"),k=n("to_tf_dataset()"),P=n(". Une alternative est d\u2019utiliser "),y=l("code"),O=n("model.prepare_tf_dataset()"),H=n(" pour faire cela qui prend un peu moins de code passe-partout. Vous verrez cela dans certaines des autres sections de ce chapitre."),I=c(),j(L.$$.fragment),F=c(),T=l("p"),U=n("Prochain arr\xEAt : le mod\xE8le lui-m\xEAme.")},l(D){p=r(D,"P",{});var M=o(p);g=a(M,"Notre assembleur de donn\xE9es est pr\xEAt \xE0 fonctionner ! Maintenant, utilisons-le pour cr\xE9er un "),v=r(M,"CODE",{});var V=o(v);q=a(V,"tf.data.Dataset"),V.forEach(s),z=a(M," avec la m\xE9thode "),E=r(M,"CODE",{});var Y=o(E);k=a(Y,"to_tf_dataset()"),Y.forEach(s),P=a(M,". Une alternative est d\u2019utiliser "),y=r(M,"CODE",{});var se=o(y);O=a(se,"model.prepare_tf_dataset()"),se.forEach(s),H=a(M," pour faire cela qui prend un peu moins de code passe-partout. Vous verrez cela dans certaines des autres sections de ce chapitre."),M.forEach(s),I=d(D),w(L.$$.fragment,D),F=d(D),T=r(D,"P",{});var N=o(T);U=a(N,"Prochain arr\xEAt : le mod\xE8le lui-m\xEAme."),N.forEach(s)},m(D,M){u(D,p,M),e(p,g),e(p,v),e(v,q),e(p,z),e(p,E),e(E,k),e(p,P),e(p,y),e(y,O),e(p,H),u(D,I,M),x(L,D,M),u(D,F,M),u(D,T,M),e(T,U),W=!0},i(D){W||(b(L.$$.fragment,D),W=!0)},o(D){$(L.$$.fragment,D),W=!1},d(D){D&&s(p),D&&s(I),C(L,D),D&&s(F),D&&s(T)}}}function ph(X){let p,g,v,q,z;return{c(){p=l("p"),g=n("Comme nous pouvons le voir, le deuxi\xE8me jeu d\u2019\xE9tiquettes a \xE9t\xE9 compl\xE9t\xE9 \xE0 la longueur du premier en utilisant des "),v=l("code"),q=n("-100"),z=n(".")},l(E){p=r(E,"P",{});var k=o(p);g=a(k,"Comme nous pouvons le voir, le deuxi\xE8me jeu d\u2019\xE9tiquettes a \xE9t\xE9 compl\xE9t\xE9 \xE0 la longueur du premier en utilisant des "),v=r(k,"CODE",{});var P=o(v);q=a(P,"-100"),P.forEach(s),z=a(k,"."),k.forEach(s)},m(E,k){u(E,p,k),e(p,g),e(p,v),e(v,q),e(p,z)},i:Hv,o:Hv,d(E){E&&s(p)}}}function Uv(X){let p,g,v,q,z,E,k,P,y,O,H,I,L,F,T,U,W,D,M,V,Y,se,N,G,te,J,ee,R,K,de,Pe,he,B,le,Q,oe,Z,pe,Qe,_e,ge,ys,Ce,De,es,ae,ms,fs,Mt,qa,ne,ka,dn,zs,ja,wa,ut,ss,mn,Se,fn,ts,pt,ye,Le,Os,ns,xa,as,ct,Ca,vn,hn,ze,_n,dt,ya,Un,vs,Ws,ls,Ps,Ds,At,Xs,bn,Nt,Zs,Vn,Ee,mt,Wn,qe,Tt,$n,ie,rs,gn,Ks,ft,St,Xn,Ys,Lt,os,It,me,za,Ft,hs,Ve,Js,Me,Oa,Ms,Pa,Zn,ke,En,qn,Kn,Ae,vt,kn,jn,Yn,_s,wn,Ie,is,bs,ht,Rt,As,Jn,je,Ne,Bt,$s,Da,Ns,_t,Ma,Qn,us,bt,Ht,gs,Aa,$t,Qs,et,st,We,xn,Fe,Cn,re,ea,$e,Na,yn,gt,Ta,zn,Et,Sa,On,Gt,Ut,Pn,Dn,Xe,Mn;return q=new it({}),B=new A({props:{code:`id2label = {i: label for i, label in enumerate(label_names)}
label2id = {v: k for k, v in id2label.items()}`,highlighted:`id2label = {i: label <span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(label_names)}
label2id = {v: k <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> id2label.items()}`}}),De=new A({props:{code:`from transformers import TFAutoModelForTokenClassification

model = TFAutoModelForTokenClassification.from_pretrained(
    model_checkpoint,
    id2label=id2label,
    label2id=label2id,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForTokenClassification

model = TFAutoModelForTokenClassification.from_pretrained(
    model_checkpoint,
    id2label=id2label,
    label2id=label2id,
)`}}),ss=new A({props:{code:"model.config.num_labels",highlighted:"model.config.num_labels"}}),Se=new A({props:{code:"9",highlighted:'<span class="hljs-number">9</span>'}}),ts=new Qo({props:{warning:!0,$$slots:{default:[ch]},$$scope:{ctx:X}}}),ns=new it({}),Ws=new A({props:{code:`from huggingface_hub import notebook_login

notebook_login()`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

notebook_login()`}}),Tt=new A({props:{code:"huggingface-cli login",highlighted:"huggingface-cli login"}}),Ve=new A({props:{code:`from transformers import create_optimizer
import tensorflow as tf

# Entra\xEEner en mixed-precision float16
# Commentez cette ligne si vous utilisez un GPU qui ne b\xE9n\xE9ficiera pas de cette fonction
tf.keras.mixed_precision.set_global_policy("mixed_float16")

# Le nombre d'\xE9tapes d'entra\xEEnement est le nombre d'\xE9chantillons dans l'ensemble de donn\xE9es, divis\xE9 par la taille du batch puis multipli\xE9 par le nombre total d'\xE9poques
# par le nombre total d'\xE9poques. Notez que le jeu de donn\xE9es tf_train_dataset est ici un batchtf.data.Dataset,
# et non le jeu de donn\xE9es original Hugging Face Dataset, donc son len() est d\xE9j\xE0 num_samples // batch_size
num_epochs = 3
num_train_steps = len(tf_train_dataset) * num_epochs

optimizer, schedule = create_optimizer(
    init_lr=2e-5,
    num_warmup_steps=0,
    num_train_steps=num_train_steps,
    weight_decay_rate=0.01,
)
model.compile(optimizer=optimizer)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> create_optimizer
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-comment"># Entra\xEEner en mixed-precision float16</span>
<span class="hljs-comment"># Commentez cette ligne si vous utilisez un GPU qui ne b\xE9n\xE9ficiera pas de cette fonction</span>
tf.keras.mixed_precision.set_global_policy(<span class="hljs-string">&quot;mixed_float16&quot;</span>)

<span class="hljs-comment"># Le nombre d&#x27;\xE9tapes d&#x27;entra\xEEnement est le nombre d&#x27;\xE9chantillons dans l&#x27;ensemble de donn\xE9es, divis\xE9 par la taille du batch puis multipli\xE9 par le nombre total d&#x27;\xE9poques</span>
<span class="hljs-comment"># par le nombre total d&#x27;\xE9poques. Notez que le jeu de donn\xE9es tf_train_dataset est ici un batchtf.data.Dataset,</span>
<span class="hljs-comment"># et non le jeu de donn\xE9es original Hugging Face Dataset, donc son len() est d\xE9j\xE0 num_samples // batch_size</span>
num_epochs = <span class="hljs-number">3</span>
num_train_steps = <span class="hljs-built_in">len</span>(tf_train_dataset) * num_epochs

optimizer, schedule = create_optimizer(
    init_lr=<span class="hljs-number">2e-5</span>,
    num_warmup_steps=<span class="hljs-number">0</span>,
    num_train_steps=num_train_steps,
    weight_decay_rate=<span class="hljs-number">0.01</span>,
)
model.<span class="hljs-built_in">compile</span>(optimizer=optimizer)`}}),As=new A({props:{code:`from transformers.keras_callbacks import PushToHubCallback

callback = PushToHubCallback(output_dir="bert-finetuned-ner", tokenizer=tokenizer)

model.fit(
    tf_train_dataset,
    validation_data=tf_eval_dataset,
    callbacks=[callback],
    epochs=num_epochs,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers.keras_callbacks <span class="hljs-keyword">import</span> PushToHubCallback

callback = PushToHubCallback(output_dir=<span class="hljs-string">&quot;bert-finetuned-ner&quot;</span>, tokenizer=tokenizer)

model.fit(
    tf_train_dataset,
    validation_data=tf_eval_dataset,
    callbacks=[callback],
    epochs=num_epochs,
)`}}),et=new Qo({props:{$$slots:{default:[dh]},$$scope:{ctx:X}}}),{c(){p=l("h3"),g=l("a"),v=l("span"),j(q.$$.fragment),z=c(),E=l("span"),k=n("D\xE9finir le mod\xE8le"),P=c(),y=l("p"),O=n("Puisque nous travaillons sur un probl\xE8me de classification de "),H=l("em"),I=n("tokens"),L=n(", nous allons utiliser la classe "),F=l("code"),T=n("TFAutoModelForTokenClassification"),U=n(". La principale chose \xE0 retenir lors de la d\xE9finition de ce mod\xE8le est de transmettre des informations sur le nombre d\u2019\xE9tiquettes que nous avons. La fa\xE7on la plus simple de le faire est de passer ce nombre avec l\u2019argument "),W=l("code"),D=n("num_labels"),M=n(", mais si nous voulons un joli "),V=l("em"),Y=n("widget"),se=n(" d\u2019inf\xE9rence fonctionnant comme celui que nous avons vu au d\xE9but de cette section, il est pr\xE9f\xE9rable de d\xE9finir les correspondances correctes des \xE9tiquettes \xE0 la place."),N=c(),G=l("p"),te=n("Elles devraient \xEAtre d\xE9finies par deux dictionnaires, "),J=l("code"),ee=n("id2label"),R=n(" et "),K=l("code"),de=n("label2id"),Pe=n(", qui contiennent la correspondance de l\u2019identifiant \xE0 l\u2019\xE9tiquette et vice versa :"),he=c(),j(B.$$.fragment),le=c(),Q=l("p"),oe=n("Maintenant, nous pouvons simplement les passer \xE0 la m\xE9thode "),Z=l("code"),pe=n("TFAutoModelForTokenClassification.from_pretrained()"),Qe=n(", et ils seront d\xE9finis dans la configuration du mod\xE8le puis correctement enregistr\xE9s et t\xE9l\xE9charg\xE9s vers le "),_e=l("em"),ge=n("Hub"),ys=n(" :"),Ce=c(),j(De.$$.fragment),es=c(),ae=l("p"),ms=n("Comme lorsque nous avons d\xE9fini notre "),fs=l("code"),Mt=n("TFAutoModelForSequenceClassification"),qa=n(" au "),ne=l("a"),ka=n("chapitre 3"),dn=n(", la cr\xE9ation du mod\xE8le \xE9met un avertissement indiquant que certains poids n\u2019ont pas \xE9t\xE9 utilis\xE9s (ceux de la t\xEAte de pr\xE9-entra\xEEnement) et que d\u2019autres poids ont \xE9t\xE9 initialis\xE9s de mani\xE8re al\xE9atoire (ceux de la t\xEAte de classification des nouveaux "),zs=l("em"),ja=n("tokens"),wa=n("), et que ce mod\xE8le doit \xEAtre entra\xEEn\xE9. Nous ferons cela dans une minute mais v\xE9rifions d\u2019abord que notre mod\xE8le a le bon nombre d\u2019\xE9tiquettes :"),ut=c(),j(ss.$$.fragment),mn=c(),j(Se.$$.fragment),fn=c(),j(ts.$$.fragment),pt=c(),ye=l("h3"),Le=l("a"),Os=l("span"),j(ns.$$.fragment),xa=c(),as=l("span"),ct=l("i"),Ca=n("Finetuning"),vn=n(" du mod\xE8le"),hn=c(),ze=l("p"),_n=n("Nous sommes maintenant pr\xEAts \xE0 entra\xEEner notre mod\xE8le ! Mais nous devons d\u2019abord faire un peu de m\xE9nage : nous devons nous connecter \xE0 Hugging Face et d\xE9finir nos hyperparam\xE8tres d\u2019entra\xEEnement. Si vous travaillez dans un "),dt=l("em"),ya=n("notebook"),Un=n(", il y a une fonction pratique pour vous aider \xE0 le faire :"),vs=c(),j(Ws.$$.fragment),ls=c(),Ps=l("p"),Ds=n("Cela affichera un "),At=l("em"),Xs=n("widget"),bn=n(" o\xF9 vous pourrez entrer vos identifiants de connexion \xE0 Hugging Face."),Nt=c(),Zs=l("p"),Vn=n("Si vous ne travaillez pas dans un "),Ee=l("em"),mt=n("notebook"),Wn=n(", tapez simplement la ligne suivante dans votre terminal :"),qe=c(),j(Tt.$$.fragment),$n=c(),ie=l("p"),rs=n("Apr\xE8s s\u2019\xEAtre connect\xE9, nous pouvons pr\xE9parer tout ce dont nous avons besoin pour compiler notre mod\xE8le. \u{1F917} "),gn=l("em"),Ks=n("Transformers"),ft=n(" fournit une fonction pratique "),St=l("code"),Xn=n("create_optimizer()"),Ys=n(" qui vous donnera un optimiseur "),Lt=l("code"),os=n("AdamW"),It=n(" avec des param\xE8tres appropri\xE9s pour le taux de d\xE9croissance des poids et le taux de d\xE9croissance de l\u2019apprentissage, les deux am\xE9liorant les performances de votre mod\xE8le par rapport \xE0 l\u2019optimiseur "),me=l("code"),za=n("Adam"),Ft=n(" :"),hs=c(),j(Ve.$$.fragment),Js=c(),Me=l("p"),Oa=n("Notez \xE9galement que nous ne fournissons pas d\u2019argument "),Ms=l("code"),Pa=n("loss"),Zn=n(" \xE0 "),ke=l("code"),En=n("compile()"),qn=n(". C\u2019est parce que les mod\xE8les peuvent en fait calculer la perte en interne. Si vous compilez sans perte et fournissez vos \xE9tiquettes dans le dictionnaire d\u2019entr\xE9e (comme nous le faisons dans nos jeux de donn\xE9es), alors le mod\xE8le s\u2019entra\xEEnera en utilisant cette perte interne, qui sera appropri\xE9e pour la t\xE2che et le type de mod\xE8le que vous avez choisi."),Kn=c(),Ae=l("p"),vt=n("Ensuite, nous d\xE9finissons un "),kn=l("code"),jn=n("PushToHubCallback"),Yn=n(" pour t\xE9l\xE9charger notre mod\xE8le vers le "),_s=l("em"),wn=n("Hub"),Ie=n(" pendant l\u2019entra\xEEnement, et nous ajustons le mod\xE8le avec ce "),is=l("em"),bs=n("callback"),ht=n(" :"),Rt=c(),j(As.$$.fragment),Jn=c(),je=l("p"),Ne=n("Vous pouvez sp\xE9cifier le nom complet du d\xE9p\xF4t vers lequel vous voulez pousser avec l\u2019argument "),Bt=l("code"),$s=n("hub_model_id"),Da=n(" (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),Ns=l("a"),_t=l("code"),Ma=n("huggingface-course"),Qn=n(", nous avons ajout\xE9 "),us=l("code"),bt=n('hub_model_id="huggingface-course/bert-finetuned-ner"'),Ht=n(". Par d\xE9faut, le d\xE9p\xF4t utilis\xE9 sera dans votre espace de noms et nomm\xE9 apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini, par exemple "),gs=l("code"),Aa=n('"cool_huggingface_user/bert-finetuned-ner"'),$t=n("."),Qs=c(),j(et.$$.fragment),st=c(),We=l("p"),xn=n("Notez que pendant l\u2019entra\xEEnement, chaque fois que le mod\xE8le est sauvegard\xE9 (ici, \xE0 chaque \xE9poque), il est t\xE9l\xE9charg\xE9 sur le "),Fe=l("em"),Cn=n("Hub"),re=n(" en arri\xE8re-plan. De cette fa\xE7on, vous pourrez reprendre votre entra\xEEnement sur une autre machine si n\xE9cessaire."),ea=c(),$e=l("p"),Na=n("A ce stade, vous pouvez utiliser le "),yn=l("em"),gt=n("widget"),Ta=n(" d\u2019inf\xE9rence sur le "),zn=l("em"),Et=n("Hub"),Sa=n(" pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 "),On=l("em"),Gt=n("finetuner"),Ut=n(" un mod\xE8le sur une t\xE2che de classification de "),Pn=l("em"),Dn=n("tokens"),Xe=n(". F\xE9licitations ! Mais quelle est la qualit\xE9 r\xE9elle de notre mod\xE8le ? Nous devons \xE9valuer certaines m\xE9triques pour le d\xE9couvrir."),this.h()},l(f){p=r(f,"H3",{class:!0});var S=o(p);g=r(S,"A",{id:!0,class:!0,href:!0});var An=o(g);v=r(An,"SPAN",{});var La=o(v);w(q.$$.fragment,La),La.forEach(s),An.forEach(s),z=d(S),E=r(S,"SPAN",{});var Ts=o(E);k=a(Ts,"D\xE9finir le mod\xE8le"),Ts.forEach(s),S.forEach(s),P=d(f),y=r(f,"P",{});var be=o(y);O=a(be,"Puisque nous travaillons sur un probl\xE8me de classification de "),H=r(be,"EM",{});var Nn=o(H);I=a(Nn,"tokens"),Nn.forEach(s),L=a(be,", nous allons utiliser la classe "),F=r(be,"CODE",{});var Es=o(F);T=a(Es,"TFAutoModelForTokenClassification"),Es.forEach(s),U=a(be,". La principale chose \xE0 retenir lors de la d\xE9finition de ce mod\xE8le est de transmettre des informations sur le nombre d\u2019\xE9tiquettes que nous avons. La fa\xE7on la plus simple de le faire est de passer ce nombre avec l\u2019argument "),W=r(be,"CODE",{});var Ia=o(W);D=a(Ia,"num_labels"),Ia.forEach(s),M=a(be,", mais si nous voulons un joli "),V=r(be,"EM",{});var Ss=o(V);Y=a(Ss,"widget"),Ss.forEach(s),se=a(be," d\u2019inf\xE9rence fonctionnant comme celui que nous avons vu au d\xE9but de cette section, il est pr\xE9f\xE9rable de d\xE9finir les correspondances correctes des \xE9tiquettes \xE0 la place."),be.forEach(s),N=d(f),G=r(f,"P",{});var Vt=o(G);te=a(Vt,"Elles devraient \xEAtre d\xE9finies par deux dictionnaires, "),J=r(Vt,"CODE",{});var Tn=o(J);ee=a(Tn,"id2label"),Tn.forEach(s),R=a(Vt," et "),K=r(Vt,"CODE",{});var qt=o(K);de=a(qt,"label2id"),qt.forEach(s),Pe=a(Vt,", qui contiennent la correspondance de l\u2019identifiant \xE0 l\u2019\xE9tiquette et vice versa :"),Vt.forEach(s),he=d(f),w(B.$$.fragment,f),le=d(f),Q=r(f,"P",{});var Wt=o(Q);oe=a(Wt,"Maintenant, nous pouvons simplement les passer \xE0 la m\xE9thode "),Z=r(Wt,"CODE",{});var Xt=o(Z);pe=a(Xt,"TFAutoModelForTokenClassification.from_pretrained()"),Xt.forEach(s),Qe=a(Wt,", et ils seront d\xE9finis dans la configuration du mod\xE8le puis correctement enregistr\xE9s et t\xE9l\xE9charg\xE9s vers le "),_e=r(Wt,"EM",{});var Zt=o(_e);ge=a(Zt,"Hub"),Zt.forEach(s),ys=a(Wt," :"),Wt.forEach(s),Ce=d(f),w(De.$$.fragment,f),es=d(f),ae=r(f,"P",{});var Ls=o(ae);ms=a(Ls,"Comme lorsque nous avons d\xE9fini notre "),fs=r(Ls,"CODE",{});var kt=o(fs);Mt=a(kt,"TFAutoModelForSequenceClassification"),kt.forEach(s),qa=a(Ls," au "),ne=r(Ls,"A",{href:!0});var Is=o(ne);ka=a(Is,"chapitre 3"),Is.forEach(s),dn=a(Ls,", la cr\xE9ation du mod\xE8le \xE9met un avertissement indiquant que certains poids n\u2019ont pas \xE9t\xE9 utilis\xE9s (ceux de la t\xEAte de pr\xE9-entra\xEEnement) et que d\u2019autres poids ont \xE9t\xE9 initialis\xE9s de mani\xE8re al\xE9atoire (ceux de la t\xEAte de classification des nouveaux "),zs=r(Ls,"EM",{});var fe=o(zs);ja=a(fe,"tokens"),fe.forEach(s),wa=a(Ls,"), et que ce mod\xE8le doit \xEAtre entra\xEEn\xE9. Nous ferons cela dans une minute mais v\xE9rifions d\u2019abord que notre mod\xE8le a le bon nombre d\u2019\xE9tiquettes :"),Ls.forEach(s),ut=d(f),w(ss.$$.fragment,f),mn=d(f),w(Se.$$.fragment,f),fn=d(f),w(ts.$$.fragment,f),pt=d(f),ye=r(f,"H3",{class:!0});var Kt=o(ye);Le=r(Kt,"A",{id:!0,class:!0,href:!0});var tt=o(Le);Os=r(tt,"SPAN",{});var wl=o(Os);w(ns.$$.fragment,wl),wl.forEach(s),tt.forEach(s),xa=d(Kt),as=r(Kt,"SPAN",{});var Sn=o(as);ct=r(Sn,"I",{});var sa=o(ct);Ca=a(sa,"Finetuning"),sa.forEach(s),vn=a(Sn," du mod\xE8le"),Sn.forEach(s),Kt.forEach(s),hn=d(f),ze=r(f,"P",{});var Ln=o(ze);_n=a(Ln,"Nous sommes maintenant pr\xEAts \xE0 entra\xEEner notre mod\xE8le ! Mais nous devons d\u2019abord faire un peu de m\xE9nage : nous devons nous connecter \xE0 Hugging Face et d\xE9finir nos hyperparam\xE8tres d\u2019entra\xEEnement. Si vous travaillez dans un "),dt=r(Ln,"EM",{});var ps=o(dt);ya=a(ps,"notebook"),ps.forEach(s),Un=a(Ln,", il y a une fonction pratique pour vous aider \xE0 le faire :"),Ln.forEach(s),vs=d(f),w(Ws.$$.fragment,f),ls=d(f),Ps=r(f,"P",{});var Yt=o(Ps);Ds=a(Yt,"Cela affichera un "),At=r(Yt,"EM",{});var ta=o(At);Xs=a(ta,"widget"),ta.forEach(s),bn=a(Yt," o\xF9 vous pourrez entrer vos identifiants de connexion \xE0 Hugging Face."),Yt.forEach(s),Nt=d(f),Zs=r(f,"P",{});var na=o(Zs);Vn=a(na,"Si vous ne travaillez pas dans un "),Ee=r(na,"EM",{});var aa=o(Ee);mt=a(aa,"notebook"),aa.forEach(s),Wn=a(na,", tapez simplement la ligne suivante dans votre terminal :"),na.forEach(s),qe=d(f),w(Tt.$$.fragment,f),$n=d(f),ie=r(f,"P",{});var Ze=o(ie);rs=a(Ze,"Apr\xE8s s\u2019\xEAtre connect\xE9, nous pouvons pr\xE9parer tout ce dont nous avons besoin pour compiler notre mod\xE8le. \u{1F917} "),gn=r(Ze,"EM",{});var xl=o(gn);Ks=a(xl,"Transformers"),xl.forEach(s),ft=a(Ze," fournit une fonction pratique "),St=r(Ze,"CODE",{});var la=o(St);Xn=a(la,"create_optimizer()"),la.forEach(s),Ys=a(Ze," qui vous donnera un optimiseur "),Lt=r(Ze,"CODE",{});var ra=o(Lt);os=a(ra,"AdamW"),ra.forEach(s),It=a(Ze," avec des param\xE8tres appropri\xE9s pour le taux de d\xE9croissance des poids et le taux de d\xE9croissance de l\u2019apprentissage, les deux am\xE9liorant les performances de votre mod\xE8le par rapport \xE0 l\u2019optimiseur "),me=r(Ze,"CODE",{});var Cl=o(me);za=a(Cl,"Adam"),Cl.forEach(s),Ft=a(Ze," :"),Ze.forEach(s),hs=d(f),w(Ve.$$.fragment,f),Js=d(f),Me=r(f,"P",{});var jt=o(Me);Oa=a(jt,"Notez \xE9galement que nous ne fournissons pas d\u2019argument "),Ms=r(jt,"CODE",{});var wt=o(Ms);Pa=a(wt,"loss"),wt.forEach(s),Zn=a(jt," \xE0 "),ke=r(jt,"CODE",{});var xt=o(ke);En=a(xt,"compile()"),xt.forEach(s),qn=a(jt,". C\u2019est parce que les mod\xE8les peuvent en fait calculer la perte en interne. Si vous compilez sans perte et fournissez vos \xE9tiquettes dans le dictionnaire d\u2019entr\xE9e (comme nous le faisons dans nos jeux de donn\xE9es), alors le mod\xE8le s\u2019entra\xEEnera en utilisant cette perte interne, qui sera appropri\xE9e pour la t\xE2che et le type de mod\xE8le que vous avez choisi."),jt.forEach(s),Kn=d(f),Ae=r(f,"P",{});var Re=o(Ae);vt=a(Re,"Ensuite, nous d\xE9finissons un "),kn=r(Re,"CODE",{});var nt=o(kn);jn=a(nt,"PushToHubCallback"),nt.forEach(s),Yn=a(Re," pour t\xE9l\xE9charger notre mod\xE8le vers le "),_s=r(Re,"EM",{});var Fs=o(_s);wn=a(Fs,"Hub"),Fs.forEach(s),Ie=a(Re," pendant l\u2019entra\xEEnement, et nous ajustons le mod\xE8le avec ce "),is=r(Re,"EM",{});var oa=o(is);bs=a(oa,"callback"),oa.forEach(s),ht=a(Re," :"),Re.forEach(s),Rt=d(f),w(As.$$.fragment,f),Jn=d(f),je=r(f,"P",{});var Be=o(je);Ne=a(Be,"Vous pouvez sp\xE9cifier le nom complet du d\xE9p\xF4t vers lequel vous voulez pousser avec l\u2019argument "),Bt=r(Be,"CODE",{});var yl=o(Bt);$s=a(yl,"hub_model_id"),yl.forEach(s),Da=a(Be," (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),Ns=r(Be,"A",{href:!0,rel:!0});var Fa=o(Ns);_t=r(Fa,"CODE",{});var at=o(_t);Ma=a(at,"huggingface-course"),at.forEach(s),Fa.forEach(s),Qn=a(Be,", nous avons ajout\xE9 "),us=r(Be,"CODE",{});var Ra=o(us);bt=a(Ra,'hub_model_id="huggingface-course/bert-finetuned-ner"'),Ra.forEach(s),Ht=a(Be,". Par d\xE9faut, le d\xE9p\xF4t utilis\xE9 sera dans votre espace de noms et nomm\xE9 apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini, par exemple "),gs=r(Be,"CODE",{});var Rs=o(gs);Aa=a(Rs,'"cool_huggingface_user/bert-finetuned-ner"'),Rs.forEach(s),$t=a(Be,"."),Be.forEach(s),Qs=d(f),w(et.$$.fragment,f),st=d(f),We=r(f,"P",{});var In=o(We);xn=a(In,"Notez que pendant l\u2019entra\xEEnement, chaque fois que le mod\xE8le est sauvegard\xE9 (ici, \xE0 chaque \xE9poque), il est t\xE9l\xE9charg\xE9 sur le "),Fe=r(In,"EM",{});var Oe=o(Fe);Cn=a(Oe,"Hub"),Oe.forEach(s),re=a(In," en arri\xE8re-plan. De cette fa\xE7on, vous pourrez reprendre votre entra\xEEnement sur une autre machine si n\xE9cessaire."),In.forEach(s),ea=d(f),$e=r(f,"P",{});var He=o($e);Na=a(He,"A ce stade, vous pouvez utiliser le "),yn=r(He,"EM",{});var ia=o(yn);gt=a(ia,"widget"),ia.forEach(s),Ta=a(He," d\u2019inf\xE9rence sur le "),zn=r(He,"EM",{});var ua=o(zn);Et=a(ua,"Hub"),ua.forEach(s),Sa=a(He," pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 "),On=r(He,"EM",{});var zl=o(On);Gt=a(zl,"finetuner"),zl.forEach(s),Ut=a(He," un mod\xE8le sur une t\xE2che de classification de "),Pn=r(He,"EM",{});var Ol=o(Pn);Dn=a(Ol,"tokens"),Ol.forEach(s),Xe=a(He,". F\xE9licitations ! Mais quelle est la qualit\xE9 r\xE9elle de notre mod\xE8le ? Nous devons \xE9valuer certaines m\xE9triques pour le d\xE9couvrir."),He.forEach(s),this.h()},h(){_(g,"id","dfinir-le-modle"),_(g,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(g,"href","#dfinir-le-modle"),_(p,"class","relative group"),_(ne,"href","/course/fr/chapter3"),_(Le,"id","ifinetuningi-du-modle"),_(Le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Le,"href","#ifinetuningi-du-modle"),_(ye,"class","relative group"),_(Ns,"href","https://huggingface.co/huggingface-course"),_(Ns,"rel","nofollow")},m(f,S){u(f,p,S),e(p,g),e(g,v),x(q,v,null),e(p,z),e(p,E),e(E,k),u(f,P,S),u(f,y,S),e(y,O),e(y,H),e(H,I),e(y,L),e(y,F),e(F,T),e(y,U),e(y,W),e(W,D),e(y,M),e(y,V),e(V,Y),e(y,se),u(f,N,S),u(f,G,S),e(G,te),e(G,J),e(J,ee),e(G,R),e(G,K),e(K,de),e(G,Pe),u(f,he,S),x(B,f,S),u(f,le,S),u(f,Q,S),e(Q,oe),e(Q,Z),e(Z,pe),e(Q,Qe),e(Q,_e),e(_e,ge),e(Q,ys),u(f,Ce,S),x(De,f,S),u(f,es,S),u(f,ae,S),e(ae,ms),e(ae,fs),e(fs,Mt),e(ae,qa),e(ae,ne),e(ne,ka),e(ae,dn),e(ae,zs),e(zs,ja),e(ae,wa),u(f,ut,S),x(ss,f,S),u(f,mn,S),x(Se,f,S),u(f,fn,S),x(ts,f,S),u(f,pt,S),u(f,ye,S),e(ye,Le),e(Le,Os),x(ns,Os,null),e(ye,xa),e(ye,as),e(as,ct),e(ct,Ca),e(as,vn),u(f,hn,S),u(f,ze,S),e(ze,_n),e(ze,dt),e(dt,ya),e(ze,Un),u(f,vs,S),x(Ws,f,S),u(f,ls,S),u(f,Ps,S),e(Ps,Ds),e(Ps,At),e(At,Xs),e(Ps,bn),u(f,Nt,S),u(f,Zs,S),e(Zs,Vn),e(Zs,Ee),e(Ee,mt),e(Zs,Wn),u(f,qe,S),x(Tt,f,S),u(f,$n,S),u(f,ie,S),e(ie,rs),e(ie,gn),e(gn,Ks),e(ie,ft),e(ie,St),e(St,Xn),e(ie,Ys),e(ie,Lt),e(Lt,os),e(ie,It),e(ie,me),e(me,za),e(ie,Ft),u(f,hs,S),x(Ve,f,S),u(f,Js,S),u(f,Me,S),e(Me,Oa),e(Me,Ms),e(Ms,Pa),e(Me,Zn),e(Me,ke),e(ke,En),e(Me,qn),u(f,Kn,S),u(f,Ae,S),e(Ae,vt),e(Ae,kn),e(kn,jn),e(Ae,Yn),e(Ae,_s),e(_s,wn),e(Ae,Ie),e(Ae,is),e(is,bs),e(Ae,ht),u(f,Rt,S),x(As,f,S),u(f,Jn,S),u(f,je,S),e(je,Ne),e(je,Bt),e(Bt,$s),e(je,Da),e(je,Ns),e(Ns,_t),e(_t,Ma),e(je,Qn),e(je,us),e(us,bt),e(je,Ht),e(je,gs),e(gs,Aa),e(je,$t),u(f,Qs,S),x(et,f,S),u(f,st,S),u(f,We,S),e(We,xn),e(We,Fe),e(Fe,Cn),e(We,re),u(f,ea,S),u(f,$e,S),e($e,Na),e($e,yn),e(yn,gt),e($e,Ta),e($e,zn),e(zn,Et),e($e,Sa),e($e,On),e(On,Gt),e($e,Ut),e($e,Pn),e(Pn,Dn),e($e,Xe),Mn=!0},i(f){Mn||(b(q.$$.fragment,f),b(B.$$.fragment,f),b(De.$$.fragment,f),b(ss.$$.fragment,f),b(Se.$$.fragment,f),b(ts.$$.fragment,f),b(ns.$$.fragment,f),b(Ws.$$.fragment,f),b(Tt.$$.fragment,f),b(Ve.$$.fragment,f),b(As.$$.fragment,f),b(et.$$.fragment,f),Mn=!0)},o(f){$(q.$$.fragment,f),$(B.$$.fragment,f),$(De.$$.fragment,f),$(ss.$$.fragment,f),$(Se.$$.fragment,f),$(ts.$$.fragment,f),$(ns.$$.fragment,f),$(Ws.$$.fragment,f),$(Tt.$$.fragment,f),$(Ve.$$.fragment,f),$(As.$$.fragment,f),$(et.$$.fragment,f),Mn=!1},d(f){f&&s(p),C(q),f&&s(P),f&&s(y),f&&s(N),f&&s(G),f&&s(he),C(B,f),f&&s(le),f&&s(Q),f&&s(Ce),C(De,f),f&&s(es),f&&s(ae),f&&s(ut),C(ss,f),f&&s(mn),C(Se,f),f&&s(fn),C(ts,f),f&&s(pt),f&&s(ye),C(ns),f&&s(hn),f&&s(ze),f&&s(vs),C(Ws,f),f&&s(ls),f&&s(Ps),f&&s(Nt),f&&s(Zs),f&&s(qe),C(Tt,f),f&&s($n),f&&s(ie),f&&s(hs),C(Ve,f),f&&s(Js),f&&s(Me),f&&s(Kn),f&&s(Ae),f&&s(Rt),C(As,f),f&&s(Jn),f&&s(je),f&&s(Qs),C(et,f),f&&s(st),f&&s(We),f&&s(ea),f&&s($e)}}}function ch(X){let p,g,v,q,z;return{c(){p=l("p"),g=n("\u26A0\uFE0F Si vous avez un mod\xE8le avec le mauvais nombre d\u2019\xE9tiquettes, vous obtiendrez plus tard une erreur obscure lors de l\u2019appel de "),v=l("code"),q=n("model.fit()"),z=n(". Cela peut \xEAtre ennuyeux \xE0 d\xE9boguer donc assurez-vous de faire cette v\xE9rification pour confirmer que vous avez le nombre d\u2019\xE9tiquettes attendu.")},l(E){p=r(E,"P",{});var k=o(p);g=a(k,"\u26A0\uFE0F Si vous avez un mod\xE8le avec le mauvais nombre d\u2019\xE9tiquettes, vous obtiendrez plus tard une erreur obscure lors de l\u2019appel de "),v=r(k,"CODE",{});var P=o(v);q=a(P,"model.fit()"),P.forEach(s),z=a(k,". Cela peut \xEAtre ennuyeux \xE0 d\xE9boguer donc assurez-vous de faire cette v\xE9rification pour confirmer que vous avez le nombre d\u2019\xE9tiquettes attendu."),k.forEach(s)},m(E,k){u(E,p,k),e(p,g),e(p,v),e(v,q),e(p,z)},d(E){E&&s(p)}}}function dh(X){let p,g,v,q,z;return{c(){p=l("p"),g=n("\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de l\u2019appel de "),v=l("code"),q=n("model.fit()"),z=n(" et devrez d\xE9finir un nouveau nom.")},l(E){p=r(E,"P",{});var k=o(p);g=a(k,"\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de l\u2019appel de "),v=r(k,"CODE",{});var P=o(v);q=a(P,"model.fit()"),P.forEach(s),z=a(k," et devrez d\xE9finir un nouveau nom."),k.forEach(s)},m(E,k){u(E,p,k),e(p,g),e(p,v),e(v,q),e(p,z)},d(E){E&&s(p)}}}function mh(X){let p,g,v,q,z,E,k,P,y,O,H,I,L,F,T,U,W,D,M,V,Y,se,N,G,te,J,ee;return W=new A({props:{code:"!pip install seqeval",highlighted:"!pip install seqeval"}}),{c(){p=l("p"),g=n("Le "),v=l("em"),q=n("framework"),z=n("  traditionnel utilis\xE9 pour \xE9valuer la pr\xE9diction de la classification des "),E=l("em"),k=n("tokens"),P=n(" est "),y=l("a"),O=l("em"),H=n("seqeval"),I=n(". Pour utiliser cette m\xE9trique, nous devons d\u2019abord installer la biblioth\xE8que "),L=l("em"),F=n("seqeval"),T=n(" :"),U=c(),j(W.$$.fragment),D=c(),M=l("p"),V=n("Nous pouvons ensuite le charger via la fonction "),Y=l("code"),se=n("evaluate.load()"),N=n(" comme nous l\u2019avons fait dans le "),G=l("a"),te=n("chapitre 3"),J=n(" :"),this.h()},l(R){p=r(R,"P",{});var K=o(p);g=a(K,"Le "),v=r(K,"EM",{});var de=o(v);q=a(de,"framework"),de.forEach(s),z=a(K,"  traditionnel utilis\xE9 pour \xE9valuer la pr\xE9diction de la classification des "),E=r(K,"EM",{});var Pe=o(E);k=a(Pe,"tokens"),Pe.forEach(s),P=a(K," est "),y=r(K,"A",{href:!0,rel:!0});var he=o(y);O=r(he,"EM",{});var B=o(O);H=a(B,"seqeval"),B.forEach(s),he.forEach(s),I=a(K,". Pour utiliser cette m\xE9trique, nous devons d\u2019abord installer la biblioth\xE8que "),L=r(K,"EM",{});var le=o(L);F=a(le,"seqeval"),le.forEach(s),T=a(K," :"),K.forEach(s),U=d(R),w(W.$$.fragment,R),D=d(R),M=r(R,"P",{});var Q=o(M);V=a(Q,"Nous pouvons ensuite le charger via la fonction "),Y=r(Q,"CODE",{});var oe=o(Y);se=a(oe,"evaluate.load()"),oe.forEach(s),N=a(Q," comme nous l\u2019avons fait dans le "),G=r(Q,"A",{href:!0});var Z=o(G);te=a(Z,"chapitre 3"),Z.forEach(s),J=a(Q," :"),Q.forEach(s),this.h()},h(){_(y,"href","https://github.com/chakki-works/seqeval"),_(y,"rel","nofollow"),_(G,"href","/course/fr/chapter3")},m(R,K){u(R,p,K),e(p,g),e(p,v),e(v,q),e(p,z),e(p,E),e(E,k),e(p,P),e(p,y),e(y,O),e(O,H),e(p,I),e(p,L),e(L,F),e(p,T),u(R,U,K),x(W,R,K),u(R,D,K),u(R,M,K),e(M,V),e(M,Y),e(Y,se),e(M,N),e(M,G),e(G,te),e(M,J),ee=!0},i(R){ee||(b(W.$$.fragment,R),ee=!0)},o(R){$(W.$$.fragment,R),ee=!1},d(R){R&&s(p),R&&s(U),C(W,R),R&&s(D),R&&s(M)}}}function fh(X){let p,g,v,q,z,E,k,P,y,O,H,I,L,F,T,U,W,D,M,V,Y,se,N,G,te,J,ee,R,K,de,Pe,he,B,le,Q,oe;return J=new A({props:{code:"!pip install seqeval",highlighted:"!pip install seqeval"}}),{c(){p=l("p"),g=n("Pour que le "),v=l("code"),q=n("Trainer"),z=n(" calcule une m\xE9trique \xE0 chaque \xE9poque, nous devrons d\xE9finir une fonction "),E=l("code"),k=n("compute_metrics()"),P=n(" qui prend les tableaux de pr\xE9dictions et d\u2019\xE9tiquettes, et retourne un dictionnaire avec les noms et les valeurs des m\xE9triques."),y=c(),O=l("p"),H=n("Le "),I=l("em"),L=n("framework"),F=n(" traditionnel utilis\xE9 pour \xE9valuer la pr\xE9diction de la classification des "),T=l("em"),U=n("tokens"),W=n(" est "),D=l("a"),M=l("em"),V=n("seqeval"),Y=n(". Pour utiliser cette m\xE9trique, nous devons d\u2019abord installer la biblioth\xE8que "),se=l("em"),N=n("seqeval"),G=n(" :"),te=c(),j(J.$$.fragment),ee=c(),R=l("p"),K=n("Nous pouvons ensuite le charger via la fonction "),de=l("code"),Pe=n("evaluate.load()"),he=n(" comme nous l\u2019avons fait dans le "),B=l("a"),le=n("chapitre 3"),Q=n(" :"),this.h()},l(Z){p=r(Z,"P",{});var pe=o(p);g=a(pe,"Pour que le "),v=r(pe,"CODE",{});var Qe=o(v);q=a(Qe,"Trainer"),Qe.forEach(s),z=a(pe," calcule une m\xE9trique \xE0 chaque \xE9poque, nous devrons d\xE9finir une fonction "),E=r(pe,"CODE",{});var _e=o(E);k=a(_e,"compute_metrics()"),_e.forEach(s),P=a(pe," qui prend les tableaux de pr\xE9dictions et d\u2019\xE9tiquettes, et retourne un dictionnaire avec les noms et les valeurs des m\xE9triques."),pe.forEach(s),y=d(Z),O=r(Z,"P",{});var ge=o(O);H=a(ge,"Le "),I=r(ge,"EM",{});var ys=o(I);L=a(ys,"framework"),ys.forEach(s),F=a(ge," traditionnel utilis\xE9 pour \xE9valuer la pr\xE9diction de la classification des "),T=r(ge,"EM",{});var Ce=o(T);U=a(Ce,"tokens"),Ce.forEach(s),W=a(ge," est "),D=r(ge,"A",{href:!0,rel:!0});var De=o(D);M=r(De,"EM",{});var es=o(M);V=a(es,"seqeval"),es.forEach(s),De.forEach(s),Y=a(ge,". Pour utiliser cette m\xE9trique, nous devons d\u2019abord installer la biblioth\xE8que "),se=r(ge,"EM",{});var ae=o(se);N=a(ae,"seqeval"),ae.forEach(s),G=a(ge," :"),ge.forEach(s),te=d(Z),w(J.$$.fragment,Z),ee=d(Z),R=r(Z,"P",{});var ms=o(R);K=a(ms,"Nous pouvons ensuite le charger via la fonction "),de=r(ms,"CODE",{});var fs=o(de);Pe=a(fs,"evaluate.load()"),fs.forEach(s),he=a(ms," comme nous l\u2019avons fait dans le "),B=r(ms,"A",{href:!0});var Mt=o(B);le=a(Mt,"chapitre 3"),Mt.forEach(s),Q=a(ms," :"),ms.forEach(s),this.h()},h(){_(D,"href","https://github.com/chakki-works/seqeval"),_(D,"rel","nofollow"),_(B,"href","/course/fr/chapter3")},m(Z,pe){u(Z,p,pe),e(p,g),e(p,v),e(v,q),e(p,z),e(p,E),e(E,k),e(p,P),u(Z,y,pe),u(Z,O,pe),e(O,H),e(O,I),e(I,L),e(O,F),e(O,T),e(T,U),e(O,W),e(O,D),e(D,M),e(M,V),e(O,Y),e(O,se),e(se,N),e(O,G),u(Z,te,pe),x(J,Z,pe),u(Z,ee,pe),u(Z,R,pe),e(R,K),e(R,de),e(de,Pe),e(R,he),e(R,B),e(B,le),e(R,Q),oe=!0},i(Z){oe||(b(J.$$.fragment,Z),oe=!0)},o(Z){$(J.$$.fragment,Z),oe=!1},d(Z){Z&&s(p),Z&&s(y),Z&&s(O),Z&&s(te),C(J,Z),Z&&s(ee),Z&&s(R)}}}function vh(X){let p,g,v,q,z,E,k,P,y,O,H,I,L,F,T,U,W,D,M,V,Y,se;return U=new A({props:{code:`import numpy as np

all_predictions = []
all_labels = []
for batch in tf_eval_dataset:
    logits = model.predict_on_batch(batch)["logits"]
    labels = batch["labels"]
    predictions = np.argmax(logits, axis=-1)
    for prediction, label in zip(predictions, labels):
        for predicted_idx, label_idx in zip(prediction, label):
            if label_idx == -100:
                continue
            all_predictions.append(label_names[predicted_idx])
            all_labels.append(label_names[label_idx])
metric.compute(predictions=[all_predictions], references=[all_labels])`,highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

all_predictions = []
all_labels = []
<span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> tf_eval_dataset:
    logits = model.predict_on_batch(batch)[<span class="hljs-string">&quot;logits&quot;</span>]
    labels = batch[<span class="hljs-string">&quot;labels&quot;</span>]
    predictions = np.argmax(logits, axis=-<span class="hljs-number">1</span>)
    <span class="hljs-keyword">for</span> prediction, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(predictions, labels):
        <span class="hljs-keyword">for</span> predicted_idx, label_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(prediction, label):
            <span class="hljs-keyword">if</span> label_idx == -<span class="hljs-number">100</span>:
                <span class="hljs-keyword">continue</span>
            all_predictions.append(label_names[predicted_idx])
            all_labels.append(label_names[label_idx])
metric.compute(predictions=[all_predictions], references=[all_labels])`}}),D=new A({props:{code:`{'LOC': {'precision': 0.91, 'recall': 0.92, 'f1': 0.91, 'number': 1668},
 'MISC': {'precision': 0.70, 'recall': 0.79, 'f1': 0.74, 'number': 702},
 'ORG': {'precision': 0.85, 'recall': 0.90, 'f1': 0.88, 'number': 1661},
 'PER': {'precision': 0.95, 'recall': 0.95, 'f1': 0.95, 'number': 1617},
 'overall_precision': 0.87,
 'overall_recall': 0.91,
 'overall_f1': 0.89,
 'overall_accuracy': 0.97}`,highlighted:`{<span class="hljs-string">&#x27;LOC&#x27;</span>: {<span class="hljs-string">&#x27;precision&#x27;</span>: <span class="hljs-number">0.91</span>, <span class="hljs-string">&#x27;recall&#x27;</span>: <span class="hljs-number">0.92</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">0.91</span>, <span class="hljs-string">&#x27;number&#x27;</span>: <span class="hljs-number">1668</span>},
 <span class="hljs-string">&#x27;MISC&#x27;</span>: {<span class="hljs-string">&#x27;precision&#x27;</span>: <span class="hljs-number">0.70</span>, <span class="hljs-string">&#x27;recall&#x27;</span>: <span class="hljs-number">0.79</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">0.74</span>, <span class="hljs-string">&#x27;number&#x27;</span>: <span class="hljs-number">702</span>},
 <span class="hljs-string">&#x27;ORG&#x27;</span>: {<span class="hljs-string">&#x27;precision&#x27;</span>: <span class="hljs-number">0.85</span>, <span class="hljs-string">&#x27;recall&#x27;</span>: <span class="hljs-number">0.90</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">0.88</span>, <span class="hljs-string">&#x27;number&#x27;</span>: <span class="hljs-number">1661</span>},
 <span class="hljs-string">&#x27;PER&#x27;</span>: {<span class="hljs-string">&#x27;precision&#x27;</span>: <span class="hljs-number">0.95</span>, <span class="hljs-string">&#x27;recall&#x27;</span>: <span class="hljs-number">0.95</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">0.95</span>, <span class="hljs-string">&#x27;number&#x27;</span>: <span class="hljs-number">1617</span>},
 <span class="hljs-string">&#x27;overall_precision&#x27;</span>: <span class="hljs-number">0.87</span>,
 <span class="hljs-string">&#x27;overall_recall&#x27;</span>: <span class="hljs-number">0.91</span>,
 <span class="hljs-string">&#x27;overall_f1&#x27;</span>: <span class="hljs-number">0.89</span>,
 <span class="hljs-string">&#x27;overall_accuracy&#x27;</span>: <span class="hljs-number">0.97</span>}`}}),{c(){p=l("p"),g=n("Cela renvoie un batch d\u2019informations ! Nous obtenons la pr\xE9cision, le rappel et le score F1 pour chaque entit\xE9 s\xE9par\xE9e, ainsi que pour l\u2019ensemble. Voyons maintenant ce qui se passe si nous essayons d\u2019utiliser les pr\xE9dictions de notre mod\xE8le pour calculer des scores r\xE9els."),v=c(),q=l("p"),z=n("TensorFlow n\u2019aime pas concat\xE9ner nos pr\xE9dictions ensemble car elles ont des longueurs de s\xE9quence variables. Cela signifie que nous ne pouvons pas simplement utiliser "),E=l("code"),k=n("model.predict()"),P=n(". Mais cela ne va pas nous arr\xEAter. Nous obtiendrons des pr\xE9dictions un batch \xE0 la fois et les concat\xE9nerons en une grande liste longue au fur et \xE0 mesure et en laissant de c\xF4t\xE9 les "),y=l("em"),O=n("tokens"),H=c(),I=l("code"),L=n("-100"),F=n(" qui indiquent le masquage/le remplissage. Puis nous calculerons les m\xE9triques sur la liste \xE0 la fin :"),T=c(),j(U.$$.fragment),W=c(),j(D.$$.fragment),M=c(),V=l("p"),Y=n("Comment s\u2019est comport\xE9 votre mod\xE8le, compar\xE9 au n\xF4tre ? Si vous avez obtenu des chiffres similaires, votre entra\xEEnement a \xE9t\xE9 un succ\xE8s !")},l(N){p=r(N,"P",{});var G=o(p);g=a(G,"Cela renvoie un batch d\u2019informations ! Nous obtenons la pr\xE9cision, le rappel et le score F1 pour chaque entit\xE9 s\xE9par\xE9e, ainsi que pour l\u2019ensemble. Voyons maintenant ce qui se passe si nous essayons d\u2019utiliser les pr\xE9dictions de notre mod\xE8le pour calculer des scores r\xE9els."),G.forEach(s),v=d(N),q=r(N,"P",{});var te=o(q);z=a(te,"TensorFlow n\u2019aime pas concat\xE9ner nos pr\xE9dictions ensemble car elles ont des longueurs de s\xE9quence variables. Cela signifie que nous ne pouvons pas simplement utiliser "),E=r(te,"CODE",{});var J=o(E);k=a(J,"model.predict()"),J.forEach(s),P=a(te,". Mais cela ne va pas nous arr\xEAter. Nous obtiendrons des pr\xE9dictions un batch \xE0 la fois et les concat\xE9nerons en une grande liste longue au fur et \xE0 mesure et en laissant de c\xF4t\xE9 les "),y=r(te,"EM",{});var ee=o(y);O=a(ee,"tokens"),ee.forEach(s),H=d(te),I=r(te,"CODE",{});var R=o(I);L=a(R,"-100"),R.forEach(s),F=a(te," qui indiquent le masquage/le remplissage. Puis nous calculerons les m\xE9triques sur la liste \xE0 la fin :"),te.forEach(s),T=d(N),w(U.$$.fragment,N),W=d(N),w(D.$$.fragment,N),M=d(N),V=r(N,"P",{});var K=o(V);Y=a(K,"Comment s\u2019est comport\xE9 votre mod\xE8le, compar\xE9 au n\xF4tre ? Si vous avez obtenu des chiffres similaires, votre entra\xEEnement a \xE9t\xE9 un succ\xE8s !"),K.forEach(s)},m(N,G){u(N,p,G),e(p,g),u(N,v,G),u(N,q,G),e(q,z),e(q,E),e(E,k),e(q,P),e(q,y),e(y,O),e(q,H),e(q,I),e(I,L),e(q,F),u(N,T,G),x(U,N,G),u(N,W,G),x(D,N,G),u(N,M,G),u(N,V,G),e(V,Y),se=!0},i(N){se||(b(U.$$.fragment,N),b(D.$$.fragment,N),se=!0)},o(N){$(U.$$.fragment,N),$(D.$$.fragment,N),se=!1},d(N){N&&s(p),N&&s(v),N&&s(q),N&&s(T),C(U,N),N&&s(W),C(D,N),N&&s(M),N&&s(V)}}}function hh(X){let p,g,v,q,z,E,k,P,y,O,H,I,L,F,T,U,W,D,M,V,Y,se,N,G,te,J,ee,R,K,de,Pe,he;return M=new A({props:{code:`import numpy as np


def compute_metrics(eval_preds):
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-1)

    # Suppression de l'index ignor\xE9 (tokens sp\xE9ciaux) et conversion en \xE9tiquettes
    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]
    true_predictions = [
        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]
        for prediction, label in zip(predictions, labels)
    ]
    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)
    return {
        "precision": all_metrics["overall_precision"],
        "recall": all_metrics["overall_recall"],
        "f1": all_metrics["overall_f1"],
        "accuracy": all_metrics["overall_accuracy"],
    }`,highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np


<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_preds</span>):
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-<span class="hljs-number">1</span>)

    <span class="hljs-comment"># Suppression de l&#x27;index ignor\xE9 (tokens sp\xE9ciaux) et conversion en \xE9tiquettes</span>
    true_labels = [[label_names[l] <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> label <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels]
    true_predictions = [
        [label_names[p] <span class="hljs-keyword">for</span> (p, l) <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(prediction, label) <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>]
        <span class="hljs-keyword">for</span> prediction, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(predictions, labels)
    ]
    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)
    <span class="hljs-keyword">return</span> {
        <span class="hljs-string">&quot;precision&quot;</span>: all_metrics[<span class="hljs-string">&quot;overall_precision&quot;</span>],
        <span class="hljs-string">&quot;recall&quot;</span>: all_metrics[<span class="hljs-string">&quot;overall_recall&quot;</span>],
        <span class="hljs-string">&quot;f1&quot;</span>: all_metrics[<span class="hljs-string">&quot;overall_f1&quot;</span>],
        <span class="hljs-string">&quot;accuracy&quot;</span>: all_metrics[<span class="hljs-string">&quot;overall_accuracy&quot;</span>],
    }`}}),{c(){p=l("p"),g=n("Cela renvoie un batch d\u2019informations ! Nous obtenons la pr\xE9cision, le rappel et le score F1 pour chaque entit\xE9 s\xE9par\xE9e, ainsi que le score global. Pour notre calcul de m\xE9trique, nous ne garderons que le score global, mais n\u2019h\xE9sitez pas \xE0 modifier la fonction "),v=l("code"),q=n("compute_metrics()"),z=n(" pour retourner toutes les m\xE9triques que vous souhaitez."),E=c(),k=l("p"),P=n("Cette fonction "),y=l("code"),O=n("compute_metrics()"),H=n(" prend d\u2019abord l\u2019argmax des logits pour les convertir en pr\xE9dictions (comme d\u2019habitude, les logits et les probabilit\xE9s sont dans le m\xEAme ordre, donc nous n\u2019avons pas besoin d\u2019appliquer la fonction softmax). Ensuite, nous devons convertir les \xE9tiquettes et les pr\xE9dictions des entiers en cha\xEEnes de caract\xE8res. Nous supprimons toutes les valeurs dont l\u2019\xE9tiquette est "),I=l("code"),L=n("-100"),F=n(", puis nous passons les r\xE9sultats \xE0 la m\xE9thode "),T=l("code"),U=n("metric.compute()"),W=n(" :"),D=c(),j(M.$$.fragment),V=c(),Y=l("p"),se=n("Maintenant que ceci est fait, nous sommes presque pr\xEAts \xE0 d\xE9finir notre "),N=l("code"),G=n("Trainer"),te=n(". Nous avons juste besoin d\u2019un objet "),J=l("code"),ee=n("model"),R=n(" pour "),K=l("em"),de=n("finetuner"),Pe=n(" !")},l(B){p=r(B,"P",{});var le=o(p);g=a(le,"Cela renvoie un batch d\u2019informations ! Nous obtenons la pr\xE9cision, le rappel et le score F1 pour chaque entit\xE9 s\xE9par\xE9e, ainsi que le score global. Pour notre calcul de m\xE9trique, nous ne garderons que le score global, mais n\u2019h\xE9sitez pas \xE0 modifier la fonction "),v=r(le,"CODE",{});var Q=o(v);q=a(Q,"compute_metrics()"),Q.forEach(s),z=a(le," pour retourner toutes les m\xE9triques que vous souhaitez."),le.forEach(s),E=d(B),k=r(B,"P",{});var oe=o(k);P=a(oe,"Cette fonction "),y=r(oe,"CODE",{});var Z=o(y);O=a(Z,"compute_metrics()"),Z.forEach(s),H=a(oe," prend d\u2019abord l\u2019argmax des logits pour les convertir en pr\xE9dictions (comme d\u2019habitude, les logits et les probabilit\xE9s sont dans le m\xEAme ordre, donc nous n\u2019avons pas besoin d\u2019appliquer la fonction softmax). Ensuite, nous devons convertir les \xE9tiquettes et les pr\xE9dictions des entiers en cha\xEEnes de caract\xE8res. Nous supprimons toutes les valeurs dont l\u2019\xE9tiquette est "),I=r(oe,"CODE",{});var pe=o(I);L=a(pe,"-100"),pe.forEach(s),F=a(oe,", puis nous passons les r\xE9sultats \xE0 la m\xE9thode "),T=r(oe,"CODE",{});var Qe=o(T);U=a(Qe,"metric.compute()"),Qe.forEach(s),W=a(oe," :"),oe.forEach(s),D=d(B),w(M.$$.fragment,B),V=d(B),Y=r(B,"P",{});var _e=o(Y);se=a(_e,"Maintenant que ceci est fait, nous sommes presque pr\xEAts \xE0 d\xE9finir notre "),N=r(_e,"CODE",{});var ge=o(N);G=a(ge,"Trainer"),ge.forEach(s),te=a(_e,". Nous avons juste besoin d\u2019un objet "),J=r(_e,"CODE",{});var ys=o(J);ee=a(ys,"model"),ys.forEach(s),R=a(_e," pour "),K=r(_e,"EM",{});var Ce=o(K);de=a(Ce,"finetuner"),Ce.forEach(s),Pe=a(_e," !"),_e.forEach(s)},m(B,le){u(B,p,le),e(p,g),e(p,v),e(v,q),e(p,z),u(B,E,le),u(B,k,le),e(k,P),e(k,y),e(y,O),e(k,H),e(k,I),e(I,L),e(k,F),e(k,T),e(T,U),e(k,W),u(B,D,le),x(M,B,le),u(B,V,le),u(B,Y,le),e(Y,se),e(Y,N),e(N,G),e(Y,te),e(Y,J),e(J,ee),e(Y,R),e(Y,K),e(K,de),e(Y,Pe),he=!0},i(B){he||(b(M.$$.fragment,B),he=!0)},o(B){$(M.$$.fragment,B),he=!1},d(B){B&&s(p),B&&s(E),B&&s(k),B&&s(D),C(M,B),B&&s(V),B&&s(Y)}}}function Vv(X){let p,g,v,q,z,E,k,P,y,O,H,I,L,F,T,U,W,D,M,V,Y,se,N,G,te,J,ee,R,K,de,Pe,he,B,le,Q,oe,Z,pe,Qe,_e,ge,ys,Ce,De,es,ae,ms,fs,Mt,qa,ne,ka,dn,zs,ja,wa,ut,ss,mn,Se,fn,ts,pt,ye,Le,Os,ns,xa,as,ct,Ca,vn,hn,ze,_n,dt,ya,Un,vs,Ws,ls,Ps,Ds,At,Xs,bn,Nt,Zs,Vn,Ee,mt,Wn,qe,Tt,$n,ie,rs,gn,Ks,ft,St,Xn,Ys,Lt,os,It,me,za,Ft,hs,Ve,Js,Me,Oa,Ms,Pa,Zn,ke,En,qn,Kn,Ae,vt,kn,jn,Yn,_s,wn,Ie,is,bs,ht,Rt,As,Jn,je,Ne,Bt,$s,Da,Ns,_t,Ma,Qn,us,bt,Ht,gs,Aa,$t,Qs,et,st,We,xn,Fe,Cn,re,ea,$e,Na,yn,gt,Ta,zn,Et,Sa,On,Gt,Ut,Pn,Dn,Xe,Mn,f,S,An,La,Ts,be,Nn,Es,Ia,Ss,Vt,Tn,qt,Wt,Xt,Zt,Ls,kt,Is,fe,Kt,tt,wl,Sn,sa,Ln,ps,Yt,ta,na,aa,Ze,xl,la,ra,Cl,jt,wt,xt,Re,nt,Fs,oa,Be,yl,Fa,at,Ra,Rs,In,Oe,He,ia,ua,zl,Ol,Ct,Fn,Jr,pa,mr,fr,ei,vr,Qr,Ba,eo,qs,Pl,lt,si,Ha,ti,ni,Ga,ai,li,hr,Jt,_r,so,Ua,Dl,ks,ri,Va,oi,ii,br,Qt,$r,gr,ui,Er,qr,pi,kr,to,Wa,jr,en,no,Xa,Za,wr,yt,xr,Ge,ci,Ka,di,mi,Ya,fi,vi,Cr,Bs,Rn,rt,Ja,yr,zr,hi,Ml,sn,_i,Al,ca,ao,zt,da,Or,ma,Qa,Nl,Tl,lo,fa,Ot,we,bi,el,$i,gi,Sl,Hs,Ei,sl,qi,ki,tl,ji,wi,nl,xi,Ci,Ll,tn,yi,Pr,Gs,zi,al,Oi,Pi,Il,ll,ro,ue,Di,Dr,Mr,Mi,rl,Fl,Rl,Ai,Bl,ol,oo,nn,Ni,Ar,Nr,Ti,io,Pt,uo,xe,Tr,Sr,Si,Lr,Ir,Li,Fr,Rr,Ii,po,Bn,co,il,Hl,an,Fi,ul,Ri,Bi,pl,Hi,Gi,Br,js,mo,Hn,fo,ve,cl,dl,Ui,Vi,Gl;return q=new it({}),B=new A({props:{code:`id2label = {i: label for i, label in enumerate(label_names)}
label2id = {v: k for k, v in id2label.items()}`,highlighted:`id2label = {i: label <span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(label_names)}
label2id = {v: k <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> id2label.items()}`}}),De=new A({props:{code:`from transformers import AutoModelForTokenClassification

model = AutoModelForTokenClassification.from_pretrained(
    model_checkpoint,
    id2label=id2label,
    label2id=label2id,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForTokenClassification

model = AutoModelForTokenClassification.from_pretrained(
    model_checkpoint,
    id2label=id2label,
    label2id=label2id,
)`}}),ss=new A({props:{code:"model.config.num_labels",highlighted:"model.config.num_labels"}}),Se=new A({props:{code:"9",highlighted:'<span class="hljs-number">9</span>'}}),ts=new Qo({props:{warning:!0,$$slots:{default:[_h]},$$scope:{ctx:X}}}),ns=new it({}),Ds=new A({props:{code:`from huggingface_hub import notebook_login

notebook_login()`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

notebook_login()`}}),rs=new A({props:{code:"huggingface-cli login",highlighted:"huggingface-cli login"}}),os=new A({props:{code:`from transformers import TrainingArguments

args = TrainingArguments(
    "bert-finetuned-ner",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
    push_to_hub=True,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

args = TrainingArguments(
    <span class="hljs-string">&quot;bert-finetuned-ner&quot;</span>,
    evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    learning_rate=<span class="hljs-number">2e-5</span>,
    num_train_epochs=<span class="hljs-number">3</span>,
    weight_decay=<span class="hljs-number">0.01</span>,
    push_to_hub=<span class="hljs-literal">True</span>,
)`}}),Ie=new Qo({props:{$$slots:{default:[bh]},$$scope:{ctx:X}}}),Ne=new A({props:{code:`from transformers import Trainer

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    compute_metrics=compute_metrics,
    tokenizer=tokenizer,
)
trainer.train()`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],
    eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>],
    data_collator=data_collator,
    compute_metrics=compute_metrics,
    tokenizer=tokenizer,
)
trainer.train()`}}),Qs=new A({props:{code:'trainer.push_to_hub(commit_message="Training complete")',highlighted:'trainer.push_to_hub(commit_message=<span class="hljs-string">&quot;Training complete&quot;</span>)'}}),Fe=new A({props:{code:"'https://huggingface.co/sgugger/bert-finetuned-ner/commit/26ab21e5b1568f9afeccdaed2d8715f571d786ed'",highlighted:'<span class="hljs-string">&#x27;https://huggingface.co/sgugger/bert-finetuned-ner/commit/26ab21e5b1568f9afeccdaed2d8715f571d786ed&#x27;</span>'}}),Es=new it({}),tt=new it({}),xt=new A({props:{code:`from torch.utils.data import DataLoader

train_dataloader = DataLoader(
    tokenized_datasets["train"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=8,
)
eval_dataloader = DataLoader(
    tokenized_datasets["validation"], collate_fn=data_collator, batch_size=8
)`,highlighted:`<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader

train_dataloader = DataLoader(
    tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],
    shuffle=<span class="hljs-literal">True</span>,
    collate_fn=data_collator,
    batch_size=<span class="hljs-number">8</span>,
)
eval_dataloader = DataLoader(
    tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>], collate_fn=data_collator, batch_size=<span class="hljs-number">8</span>
)`}}),at=new A({props:{code:`model = AutoModelForTokenClassification.from_pretrained(
    model_checkpoint,
    id2label=id2label,
    label2id=label2id,
)`,highlighted:`model = AutoModelForTokenClassification.from_pretrained(
    model_checkpoint,
    id2label=id2label,
    label2id=label2id,
)`}}),Fn=new A({props:{code:`from torch.optim import AdamW

optimizer = AdamW(model.parameters(), lr=2e-5)`,highlighted:`<span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> AdamW

optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">2e-5</span>)`}}),Ba=new A({props:{code:`from accelerate import Accelerator

accelerator = Accelerator()
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)`,highlighted:`<span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> Accelerator

accelerator = Accelerator()
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)`}}),qs=new Qo({props:{$$slots:{default:[$h]},$$scope:{ctx:X}}}),Ua=new A({props:{code:`from transformers import get_scheduler

num_train_epochs = 3
num_update_steps_per_epoch = len(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> get_scheduler

num_train_epochs = <span class="hljs-number">3</span>
num_update_steps_per_epoch = <span class="hljs-built_in">len</span>(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    <span class="hljs-string">&quot;linear&quot;</span>,
    optimizer=optimizer,
    num_warmup_steps=<span class="hljs-number">0</span>,
    num_training_steps=num_training_steps,
)`}}),Wa=new A({props:{code:`from huggingface_hub import Repository, get_full_repo_name

model_name = "bert-finetuned-ner-accelerate"
repo_name = get_full_repo_name(model_name)
repo_name`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> Repository, get_full_repo_name

model_name = <span class="hljs-string">&quot;bert-finetuned-ner-accelerate&quot;</span>
repo_name = get_full_repo_name(model_name)
repo_name`}}),en=new A({props:{code:"'sgugger/bert-finetuned-ner-accelerate'",highlighted:'<span class="hljs-string">&#x27;sgugger/bert-finetuned-ner-accelerate&#x27;</span>'}}),yt=new A({props:{code:`output_dir = "bert-finetuned-ner-accelerate"
repo = Repository(output_dir, clone_from=repo_name)`,highlighted:`output_dir = <span class="hljs-string">&quot;bert-finetuned-ner-accelerate&quot;</span>
repo = Repository(output_dir, clone_from=repo_name)`}}),Ja=new it({}),Qa=new A({props:{code:`def postprocess(predictions, labels):
    predictions = predictions.detach().cpu().clone().numpy()
    labels = labels.detach().cpu().clone().numpy()

    # Suppression de l'index ignor\xE9 (tokens sp\xE9ciaux) et conversion en \xE9tiquettes
    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]
    true_predictions = [
        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]
        for prediction, label in zip(predictions, labels)
    ]
    return true_labels, true_predictions`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">postprocess</span>(<span class="hljs-params">predictions, labels</span>):
    predictions = predictions.detach().cpu().clone().numpy()
    labels = labels.detach().cpu().clone().numpy()

    <span class="hljs-comment"># Suppression de l&#x27;index ignor\xE9 (tokens sp\xE9ciaux) et conversion en \xE9tiquettes</span>
    true_labels = [[label_names[l] <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> label <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels]
    true_predictions = [
        [label_names[p] <span class="hljs-keyword">for</span> (p, l) <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(prediction, label) <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>]
        <span class="hljs-keyword">for</span> prediction, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(predictions, labels)
    ]
    <span class="hljs-keyword">return</span> true_labels, true_predictions`}}),ol=new A({props:{code:`from tqdm.auto import tqdm
import torch

progress_bar = tqdm(range(num_training_steps))

for epoch in range(num_train_epochs):
    # Entra\xEEnement
    model.train()
    for batch in train_dataloader:
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)

    # Evaluation
    model.eval()
    for batch in eval_dataloader:
        with torch.no_grad():
            outputs = model(**batch)

        predictions = outputs.logits.argmax(dim=-1)
        labels = batch["labels"]

        # N\xE9cessaire pour rembourrer les pr\xE9dictions et les \xE9tiquettes \xE0 rassembler
        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)
        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)

        predictions_gathered = accelerator.gather(predictions)
        labels_gathered = accelerator.gather(labels)

        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)
        metric.add_batch(predictions=true_predictions, references=true_labels)

    results = metric.compute()
    print(
        f"epoch {epoch}:",
        {
            key: results[f"overall_{key}"]
            for key in ["precision", "recall", "f1", "accuracy"]
        },
    )

    # Sauvegarder et t\xE9l\xE9charger
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    if accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=f"Training in progress epoch {epoch}", blocking=False
        )`,highlighted:`<span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm
<span class="hljs-keyword">import</span> torch

progress_bar = tqdm(<span class="hljs-built_in">range</span>(num_training_steps))

<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_train_epochs):
    <span class="hljs-comment"># Entra\xEEnement</span>
    model.train()
    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(<span class="hljs-number">1</span>)

    <span class="hljs-comment"># Evaluation</span>
    model.<span class="hljs-built_in">eval</span>()
    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> eval_dataloader:
        <span class="hljs-keyword">with</span> torch.no_grad():
            outputs = model(**batch)

        predictions = outputs.logits.argmax(dim=-<span class="hljs-number">1</span>)
        labels = batch[<span class="hljs-string">&quot;labels&quot;</span>]

        <span class="hljs-comment"># N\xE9cessaire pour rembourrer les pr\xE9dictions et les \xE9tiquettes \xE0 rassembler</span>
        predictions = accelerator.pad_across_processes(predictions, dim=<span class="hljs-number">1</span>, pad_index=-<span class="hljs-number">100</span>)
        labels = accelerator.pad_across_processes(labels, dim=<span class="hljs-number">1</span>, pad_index=-<span class="hljs-number">100</span>)

        predictions_gathered = accelerator.gather(predictions)
        labels_gathered = accelerator.gather(labels)

        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)
        metric.add_batch(predictions=true_predictions, references=true_labels)

    results = metric.compute()
    <span class="hljs-built_in">print</span>(
        <span class="hljs-string">f&quot;epoch <span class="hljs-subst">{epoch}</span>:&quot;</span>,
        {
            key: results[<span class="hljs-string">f&quot;overall_<span class="hljs-subst">{key}</span>&quot;</span>]
            <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;precision&quot;</span>, <span class="hljs-string">&quot;recall&quot;</span>, <span class="hljs-string">&quot;f1&quot;</span>, <span class="hljs-string">&quot;accuracy&quot;</span>]
        },
    )

    <span class="hljs-comment"># Sauvegarder et t\xE9l\xE9charger</span>
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    <span class="hljs-keyword">if</span> accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=<span class="hljs-string">f&quot;Training in progress epoch <span class="hljs-subst">{epoch}</span>&quot;</span>, blocking=<span class="hljs-literal">False</span>
        )`}}),Pt=new A({props:{code:`accelerator.wait_for_everyone()
unwrapped_model = accelerator.unwrap_model(model)
unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)`,highlighted:`accelerator.wait_for_everyone()
unwrapped_model = accelerator.unwrap_model(model)
unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)`}}),{c(){p=l("h3"),g=l("a"),v=l("span"),j(q.$$.fragment),z=c(),E=l("span"),k=n("D\xE9finir le mod\xE8le"),P=c(),y=l("p"),O=n("Puisque nous travaillons sur un probl\xE8me de classification de "),H=l("em"),I=n("tokens"),L=n(", nous allons utiliser la classe "),F=l("code"),T=n("AutoModelForTokenClassification"),U=n(". La principale chose \xE0 retenir lors de la d\xE9finition de ce mod\xE8le est de transmettre des informations sur le nombre d\u2019\xE9tiquettes que nous avons. La fa\xE7on la plus simple de le faire est de passer ce nombre avec l\u2019argument "),W=l("code"),D=n("num_labels"),M=n(", mais si nous voulons un joli "),V=l("em"),Y=n("widget"),se=n(" d\u2019inf\xE9rence fonctionnant comme celui que nous avons vu au d\xE9but de cette section, il est pr\xE9f\xE9rable de d\xE9finir les correspondances des \xE9tiquettes \xE0 la place."),N=c(),G=l("p"),te=n("Elles devraient \xEAtre d\xE9finies par deux dictionnaires, "),J=l("code"),ee=n("id2label"),R=n(" et "),K=l("code"),de=n("label2id"),Pe=n(", qui contiennent les correspondances entre identifiants et \xE9tiquettes et vice versa :"),he=c(),j(B.$$.fragment),le=c(),Q=l("p"),oe=n("Maintenant nous pouvons simplement les passer \xE0 la m\xE9thode "),Z=l("code"),pe=n("AutoModelForTokenClassification.from_pretrained()"),Qe=n(", ils seront d\xE9finis dans la configuration du mod\xE8le puis correctement sauvegard\xE9s et t\xE9l\xE9charg\xE9s vers le "),_e=l("em"),ge=n("Hub"),ys=n(" :"),Ce=c(),j(De.$$.fragment),es=c(),ae=l("p"),ms=n("Comme lorsque nous avons d\xE9fini notre "),fs=l("code"),Mt=n("AutoModelForSequenceClassification"),qa=n(" au "),ne=l("a"),ka=n("chapitre 3"),dn=n(", la cr\xE9ation du mod\xE8le \xE9met un avertissement indiquant que certains poids n\u2019ont pas \xE9t\xE9 utilis\xE9s (ceux de la t\xEAte de pr\xE9-entra\xEEnement) et que d\u2019autres poids ont \xE9t\xE9 initialis\xE9s de mani\xE8re al\xE9atoire (ceux de la t\xEAte de classification des nouveaux "),zs=l("em"),ja=n("tokens"),wa=n("), et que ce mod\xE8le doit \xEAtre entra\xEEn\xE9. Nous ferons cela dans une minute, mais v\xE9rifions d\u2019abord que notre mod\xE8le a le bon nombre d\u2019\xE9tiquettes :"),ut=c(),j(ss.$$.fragment),mn=c(),j(Se.$$.fragment),fn=c(),j(ts.$$.fragment),pt=c(),ye=l("h3"),Le=l("a"),Os=l("span"),j(ns.$$.fragment),xa=c(),as=l("span"),ct=l("i"),Ca=n("Finetuning"),vn=n(" du mod\xE8le"),hn=c(),ze=l("p"),_n=n("Nous sommes maintenant pr\xEAts \xE0 entra\xEEner notre mod\xE8le ! Nous devons juste faire deux derni\xE8res choses avant de d\xE9finir notre "),dt=l("code"),ya=n("Trainer"),Un=n(" : se connecter \xE0 Hugging Face et d\xE9finir nos arguments d\u2019entra\xEEnement. Si vous travaillez dans un "),vs=l("em"),Ws=n("notebook"),ls=n(", il y a une fonction pratique pour vous aider \xE0 le faire :"),Ps=c(),j(Ds.$$.fragment),At=c(),Xs=l("p"),bn=n("Cela affichera un "),Nt=l("em"),Zs=n("widget"),Vn=n(" o\xF9 vous pourrez entrer vos identifiants de connexion \xE0 Hugging Face."),Ee=c(),mt=l("p"),Wn=n("Si vous ne travaillez pas dans un "),qe=l("em"),Tt=n("notebook"),$n=n(", tapez simplement la ligne suivante dans votre terminal :"),ie=c(),j(rs.$$.fragment),gn=c(),Ks=l("p"),ft=n("Une fois ceci fait, nous pouvons d\xE9finir nos "),St=l("code"),Xn=n("TrainingArguments"),Ys=n(" :"),Lt=c(),j(os.$$.fragment),It=c(),me=l("p"),za=n("Vous avez d\xE9j\xE0 vu la plupart d\u2019entre eux. Nous d\xE9finissons quelques hyperparam\xE8tres (comme le taux d\u2019apprentissage, le nombre d\u2019\xE9poques \xE0 entra\xEEner, et le taux de d\xE9croissance des poids), et nous sp\xE9cifions "),Ft=l("code"),hs=n("push_to_hub=True"),Ve=n(" pour indiquer que nous voulons sauvegarder le mod\xE8le, l\u2019\xE9valuer \xE0 la fin de chaque \xE9poque, et que nous voulons t\xE9l\xE9charger nos r\xE9sultats vers le "),Js=l("em"),Me=n("Hub"),Oa=n(". Notez que vous pouvez sp\xE9cifier le nom du d\xE9p\xF4t vers lequel vous voulez pousser avec l\u2019argument "),Ms=l("code"),Pa=n("hub_model_id"),Zn=n(" (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),ke=l("a"),En=l("code"),qn=n("huggingface-course"),Kn=n(", nous avons ajout\xE9 "),Ae=l("code"),vt=n('hub_model_id="huggingface-course/bert-finetuned-ner"``TrainingArguments'),kn=n(". Par d\xE9faut, le d\xE9p\xF4t utilis\xE9 sera dans votre espace de noms et nomm\xE9 d\u2019apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini, donc dans notre cas ce sera "),jn=l("code"),Yn=n('"sgugger/bert-finetuned-ner"'),_s=n("."),wn=c(),j(Ie.$$.fragment),is=c(),bs=l("p"),ht=n("Enfin, nous passons tout au "),Rt=l("code"),As=n("Trainer"),Jn=n(" et lan\xE7ons l\u2019entra\xEEnement :"),je=c(),j(Ne.$$.fragment),Bt=c(),$s=l("p"),Da=n("Notez que pendant l\u2019entra\xEEnement, chaque fois que le mod\xE8le est sauvegard\xE9 (ici, \xE0 chaque \xE9poque), il est t\xE9l\xE9charg\xE9 sur le "),Ns=l("em"),_t=n("Hub"),Ma=n(" en arri\xE8re-plan. De cette fa\xE7on, vous serez en mesure de reprendre votre entra\xEEnement sur une autre machine si n\xE9cessaire."),Qn=c(),us=l("p"),bt=n("Une fois l\u2019entra\xEEnement termin\xE9, nous utilisons la m\xE9thode "),Ht=l("code"),gs=n("push_to_hub()"),Aa=n(" pour nous assurer que nous t\xE9l\xE9chargeons la version la plus r\xE9cente du mod\xE8le :"),$t=c(),j(Qs.$$.fragment),et=c(),st=l("p"),We=n("Cette commande renvoie l\u2019URL du commit qu\u2019elle vient de faire, si vous voulez l\u2019inspecter :"),xn=c(),j(Fe.$$.fragment),Cn=c(),re=l("p"),ea=n("Le "),$e=l("code"),Na=n("Trainer"),yn=n(" r\xE9dige \xE9galement une carte mod\xE8le avec tous les r\xE9sultats de l\u2019\xE9valuation et la t\xE9l\xE9charge. A ce stade, vous pouvez utiliser le "),gt=l("em"),Ta=n("widget"),zn=n(" d\u2019inf\xE9rence sur le "),Et=l("em"),Sa=n("Hub"),On=n(" pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 affiner un mod\xE8le sur une t\xE2che de classification de "),Gt=l("em"),Ut=n("tokens"),Pn=n(". F\xE9licitations !"),Dn=c(),Xe=l("p"),Mn=n("Si vous voulez plonger un peu plus profond\xE9ment dans la boucle d\u2019entra\xEEnement, nous allons maintenant vous montrer comment faire la m\xEAme chose en utilisant \u{1F917} "),f=l("em"),S=n("Accelerate"),An=n("."),La=c(),Ts=l("h2"),be=l("a"),Nn=l("span"),j(Es.$$.fragment),Ia=c(),Ss=l("span"),Vt=n("Une boucle d'entra\xEEnement personnalis\xE9e"),Tn=c(),qt=l("p"),Wt=n("Jetons maintenant un coup d\u2019\u0153il \xE0 la boucle d\u2019entra\xEEnement compl\xE8te afin que vous puissiez facilement personnaliser les parties dont vous avez besoin. Elle ressemblera beaucoup \xE0 ce que nous avons fait dans le "),Xt=l("a"),Zt=n("chapitre 3"),Ls=n(" avec quelques changements pour l\u2019\xE9valuation."),kt=c(),Is=l("h3"),fe=l("a"),Kt=l("span"),j(tt.$$.fragment),wl=c(),Sn=l("span"),sa=n("Pr\xE9parer tout pour l'entra\xEEnement"),Ln=c(),ps=l("p"),Yt=n("D\u2019abord nous devons construire le "),ta=l("code"),na=n("DataLoader"),aa=n("s \xE0 partir de nos jeux de donn\xE9es. Nous r\xE9utilisons notre "),Ze=l("code"),xl=n("data_collator"),la=n(" comme un "),ra=l("code"),Cl=n("collate_fn"),jt=n(" et m\xE9langer l\u2019ensemble d\u2019entra\xEEnement, mais pas l\u2019ensemble de validation :"),wt=c(),j(xt.$$.fragment),Re=c(),nt=l("p"),Fs=n("Ensuite, nous r\xE9instantifions notre mod\xE8le pour nous assurer que nous ne continuons pas le "),oa=l("em"),Be=n("finetuning"),yl=n(" d\u2019avant et que nous repartons bien du mod\xE8le pr\xE9-entra\xEEn\xE9 de BERT :"),Fa=c(),j(at.$$.fragment),Ra=c(),Rs=l("p"),In=n("Ensuite, nous avons besoin d\u2019un optimiseur. Nous utilisons le classique "),Oe=l("code"),He=n("AdamW"),ia=n(", qui est comme "),ua=l("code"),zl=n("Adam"),Ol=n(", mais avec un correctif dans la fa\xE7on dont le taux de d\xE9croissance des poids est appliqu\xE9e :"),Ct=c(),j(Fn.$$.fragment),Jr=c(),pa=l("p"),mr=n("Une fois que nous avons tous ces objets, nous pouvons les envoyer \xE0 la m\xE9thode "),fr=l("code"),ei=n("accelerator.prepare()"),vr=n(" :"),Qr=c(),j(Ba.$$.fragment),eo=c(),j(qs.$$.fragment),Pl=c(),lt=l("p"),si=n("Maintenant que nous avons envoy\xE9 notre "),Ha=l("code"),ti=n("train_dataloader"),ni=n(" \xE0 "),Ga=l("code"),ai=n("accelerator.prepare()"),li=n(", nous pouvons utiliser sa longueur pour calculer le nombre d\u2019\xE9tapes d\u2019entra\xEEnement. Rappelez-vous que nous devrions toujours faire cela apr\xE8s avoir pr\xE9par\xE9 le "),hr=l("em"),Jt=n("dataloader"),_r=n(" car cette m\xE9thode modifiera sa longueur. Nous utilisons un programme lin\xE9aire classique du taux d\u2019apprentissage \xE0 0 :"),so=c(),j(Ua.$$.fragment),Dl=c(),ks=l("p"),ri=n("Enfin, pour pousser notre mod\xE8le vers le "),Va=l("em"),oi=n("Hub"),ii=n(", nous avons besoin de cr\xE9er un objet "),br=l("code"),Qt=n("Repository"),$r=n(" dans un dossier de travail. Tout d\u2019abord, connectez-vous \xE0 Hugging Face si vous n\u2019\xEAtes pas d\xE9j\xE0 connect\xE9. Nous d\xE9terminons le nom du d\xE9p\xF4t \xE0 partir de l\u2019identifiant du mod\xE8le que nous voulons donner \xE0 notre mod\xE8le (n\u2019h\xE9sitez pas \xE0 remplacer le "),gr=l("code"),ui=n("repo_name"),Er=n(" par votre propre choix, il doit juste contenir votre nom d\u2019utilisateur et ce que fait la fonction "),qr=l("code"),pi=n("get_full_repo_name()"),kr=n(") :"),to=c(),j(Wa.$$.fragment),jr=c(),j(en.$$.fragment),no=c(),Xa=l("p"),Za=n("Ensuite, nous pouvons cloner ce d\xE9p\xF4t dans un dossier local. S\u2019il existe d\xE9j\xE0, ce dossier local doit \xEAtre un clone existant du d\xE9p\xF4t avec lequel nous travaillons :"),wr=c(),j(yt.$$.fragment),xr=c(),Ge=l("p"),ci=n("Nous pouvons maintenant t\xE9l\xE9charger tout ce que nous sauvegardons dans "),Ka=l("code"),di=n("output_dir"),mi=n(" en appelant la m\xE9thode "),Ya=l("code"),fi=n("repo.push_to_hub()"),vi=n(". Cela nous aidera \xE0 t\xE9l\xE9charger les mod\xE8les interm\xE9diaires \xE0 la fin de chaque \xE9poque."),Cr=c(),Bs=l("h3"),Rn=l("a"),rt=l("span"),j(Ja.$$.fragment),yr=c(),zr=l("span"),hi=n("Boucle d'entra\xEEnement"),Ml=c(),sn=l("p"),_i=n("Nous sommes maintenant pr\xEAts \xE0 \xE9crire la boucle d\u2019entra\xEEnement compl\xE8te. Pour simplifier sa partie \xE9valuation, nous d\xE9finissons cette fonction "),Al=l("code"),ca=n("postprocess()"),ao=n(" qui prend les pr\xE9dictions et les \xE9tiquettes, et les convertit en listes de cha\xEEnes de caract\xE8res comme notre objet "),zt=l("code"),da=n("metric"),Or=n(" l\u2019attend :"),ma=c(),j(Qa.$$.fragment),Nl=c(),Tl=l("p"),lo=n("Ensuite, nous pouvons \xE9crire la boucle d\u2019entra\xEEnement. Apr\xE8s avoir d\xE9fini une barre de progression pour suivre l\u2019\xE9volution de l\u2019entra\xEEnement, la boucle comporte trois parties :"),fa=c(),Ot=l("ul"),we=l("li"),bi=n("L\u2019entra\xEEnement proprement dit, qui est l\u2019it\xE9ration classique sur le "),el=l("code"),$i=n("train_dataloader"),gi=n(", passage en avant, puis passage en arri\xE8re et \xE9tape d\u2019optimisation."),Sl=c(),Hs=l("li"),Ei=n("L\u2019\xE9valuation, dans laquelle il y a une nouveaut\xE9 apr\xE8s avoir obtenu les sorties de notre mod\xE8le sur un batch : puisque deux processus peuvent avoir padd\xE9 les entr\xE9es et les \xE9tiquettes \xE0 des formes diff\xE9rentes, nous devons utiliser "),sl=l("code"),qi=n("accelerator.pad_across_processes()"),ki=n(" pour rendre les pr\xE9dictions et les \xE9tiquettes de la m\xEAme forme avant d\u2019appeler la m\xE9thode "),tl=l("code"),ji=n("gather()"),wi=n(". Si nous ne le faisons pas, l\u2019\xE9valuation va soit se tromper, soit se bloquer pour toujours. Ensuite, nous envoyons les r\xE9sultats \xE0 "),nl=l("code"),xi=n("metric.add_batch()"),Ci=n(" et appelons "),Ll=l("code"),tn=n("metric.compute()"),yi=n(" une fois que la boucle d\u2019\xE9valuation est termin\xE9e."),Pr=c(),Gs=l("li"),zi=n("Sauvegarde et t\xE9l\xE9chargement, o\xF9 nous sauvegardons d\u2019abord le mod\xE8le et le "),al=l("em"),Oi=n("tokenizer"),Pi=n(", puis appelons "),Il=l("code"),ll=n("repo.push_to_hub()"),ro=n(". Remarquez que nous utilisons l\u2019argument "),ue=l("code"),Di=n("blocking=False"),Dr=n(" pour indiquer \xE0 la biblioth\xE8que \u{1F917} "),Mr=l("em"),Mi=n("Hub"),rl=n(" de pousser dans un processus asynchrone. De cette fa\xE7on, l\u2019entra\xEEnement continue normalement et cette (longue) instruction est ex\xE9cut\xE9e en arri\xE8re-plan."),Fl=c(),Rl=l("p"),Ai=n("Voici le code complet de la boucle d\u2019entra\xEEnement :"),Bl=c(),j(ol.$$.fragment),oo=c(),nn=l("p"),Ni=n("Au cas o\xF9 ce serait la premi\xE8re fois que vous verriez un mod\xE8le enregistr\xE9 avec \u{1F917} "),Ar=l("em"),Nr=n("Accelerate"),Ti=n(", prenons un moment pour inspecter les trois lignes de code qui l\u2019accompagnent :"),io=c(),j(Pt.$$.fragment),uo=c(),xe=l("p"),Tr=n("La premi\xE8re ligne est explicite : elle indique \xE0 tous les processus d\u2019attendre que tout le monde soit \xE0 ce stade avant de continuer. C\u2019est pour s\u2019assurer que nous avons le m\xEAme mod\xE8le dans chaque processus avant de sauvegarder. Ensuite, nous prenons le "),Sr=l("code"),Si=n("unwrapped_model"),Lr=n(" qui est le mod\xE8le de base que nous avons d\xE9fini. La m\xE9thode "),Ir=l("code"),Li=n("accelerator.prepare()"),Fr=n(" modifie le mod\xE8le pour qu\u2019il fonctionne dans l\u2019entra\xEEnement distribu\xE9, donc il n\u2019aura plus la m\xE9thode "),Rr=l("code"),Ii=n("save_pretrained()"),po=n(" ; la m\xE9thode "),Bn=l("code"),co=n("accelerator.unwrap_model()"),il=n(" annule cette \xE9tape. Enfin, nous appelons "),Hl=l("code"),an=n("save_pretrained()"),Fi=n(" mais nous disons \xE0 cette m\xE9thode d\u2019utiliser "),ul=l("code"),Ri=n("accelerator.save()"),Bi=n(" au lieu de "),pl=l("code"),Hi=n("torch.save()"),Gi=n("."),Br=c(),js=l("p"),mo=n("Une fois ceci fait, vous devriez avoir un mod\xE8le qui produit des r\xE9sultats assez similaires \xE0 celui entra\xEEn\xE9 avec le "),Hn=l("code"),fo=n("Trainer"),ve=n(". Vous pouvez v\xE9rifier le mod\xE8le que nous avons form\xE9 en utilisant ce code \xE0 "),cl=l("a"),dl=l("em"),Ui=n("huggingface-course/bert-finetuned-ner-accelerate"),Vi=n(". Et si vous voulez tester des modifications de la boucle d\u2019entra\xEEnement, vous pouvez les impl\xE9menter directement en modifiant le code ci-dessus !"),this.h()},l(i){p=r(i,"H3",{class:!0});var h=o(p);g=r(h,"A",{id:!0,class:!0,href:!0});var vo=o(g);v=r(vo,"SPAN",{});var xu=o(v);w(q.$$.fragment,xu),xu.forEach(s),vo.forEach(s),z=d(h),E=r(h,"SPAN",{});var Cu=o(E);k=a(Cu,"D\xE9finir le mod\xE8le"),Cu.forEach(s),h.forEach(s),P=d(i),y=r(i,"P",{});var ot=o(y);O=a(ot,"Puisque nous travaillons sur un probl\xE8me de classification de "),H=r(ot,"EM",{});var yu=o(H);I=a(yu,"tokens"),yu.forEach(s),L=a(ot,", nous allons utiliser la classe "),F=r(ot,"CODE",{});var zu=o(F);T=a(zu,"AutoModelForTokenClassification"),zu.forEach(s),U=a(ot,". La principale chose \xE0 retenir lors de la d\xE9finition de ce mod\xE8le est de transmettre des informations sur le nombre d\u2019\xE9tiquettes que nous avons. La fa\xE7on la plus simple de le faire est de passer ce nombre avec l\u2019argument "),W=r(ot,"CODE",{});var ho=o(W);D=a(ho,"num_labels"),ho.forEach(s),M=a(ot,", mais si nous voulons un joli "),V=r(ot,"EM",{});var Ou=o(V);Y=a(Ou,"widget"),Ou.forEach(s),se=a(ot," d\u2019inf\xE9rence fonctionnant comme celui que nous avons vu au d\xE9but de cette section, il est pr\xE9f\xE9rable de d\xE9finir les correspondances des \xE9tiquettes \xE0 la place."),ot.forEach(s),N=d(i),G=r(i,"P",{});var Ul=o(G);te=a(Ul,"Elles devraient \xEAtre d\xE9finies par deux dictionnaires, "),J=r(Ul,"CODE",{});var _o=o(J);ee=a(_o,"id2label"),_o.forEach(s),R=a(Ul," et "),K=r(Ul,"CODE",{});var Pu=o(K);de=a(Pu,"label2id"),Pu.forEach(s),Pe=a(Ul,", qui contiennent les correspondances entre identifiants et \xE9tiquettes et vice versa :"),Ul.forEach(s),he=d(i),w(B.$$.fragment,i),le=d(i),Q=r(i,"P",{});var Vl=o(Q);oe=a(Vl,"Maintenant nous pouvons simplement les passer \xE0 la m\xE9thode "),Z=r(Vl,"CODE",{});var bo=o(Z);pe=a(bo,"AutoModelForTokenClassification.from_pretrained()"),bo.forEach(s),Qe=a(Vl,", ils seront d\xE9finis dans la configuration du mod\xE8le puis correctement sauvegard\xE9s et t\xE9l\xE9charg\xE9s vers le "),_e=r(Vl,"EM",{});var Du=o(_e);ge=a(Du,"Hub"),Du.forEach(s),ys=a(Vl," :"),Vl.forEach(s),Ce=d(i),w(De.$$.fragment,i),es=d(i),ae=r(i,"P",{});var va=o(ae);ms=a(va,"Comme lorsque nous avons d\xE9fini notre "),fs=r(va,"CODE",{});var $o=o(fs);Mt=a($o,"AutoModelForSequenceClassification"),$o.forEach(s),qa=a(va," au "),ne=r(va,"A",{href:!0});var Mu=o(ne);ka=a(Mu,"chapitre 3"),Mu.forEach(s),dn=a(va,", la cr\xE9ation du mod\xE8le \xE9met un avertissement indiquant que certains poids n\u2019ont pas \xE9t\xE9 utilis\xE9s (ceux de la t\xEAte de pr\xE9-entra\xEEnement) et que d\u2019autres poids ont \xE9t\xE9 initialis\xE9s de mani\xE8re al\xE9atoire (ceux de la t\xEAte de classification des nouveaux "),zs=r(va,"EM",{});var Au=o(zs);ja=a(Au,"tokens"),Au.forEach(s),wa=a(va,"), et que ce mod\xE8le doit \xEAtre entra\xEEn\xE9. Nous ferons cela dans une minute, mais v\xE9rifions d\u2019abord que notre mod\xE8le a le bon nombre d\u2019\xE9tiquettes :"),va.forEach(s),ut=d(i),w(ss.$$.fragment,i),mn=d(i),w(Se.$$.fragment,i),fn=d(i),w(ts.$$.fragment,i),pt=d(i),ye=r(i,"H3",{class:!0});var Wl=o(ye);Le=r(Wl,"A",{id:!0,class:!0,href:!0});var Nu=o(Le);Os=r(Nu,"SPAN",{});var Tu=o(Os);w(ns.$$.fragment,Tu),Tu.forEach(s),Nu.forEach(s),xa=d(Wl),as=r(Wl,"SPAN",{});var go=o(as);ct=r(go,"I",{});var Us=o(ct);Ca=a(Us,"Finetuning"),Us.forEach(s),vn=a(go," du mod\xE8le"),go.forEach(s),Wl.forEach(s),hn=d(i),ze=r(i,"P",{});var Xl=o(ze);_n=a(Xl,"Nous sommes maintenant pr\xEAts \xE0 entra\xEEner notre mod\xE8le ! Nous devons juste faire deux derni\xE8res choses avant de d\xE9finir notre "),dt=r(Xl,"CODE",{});var Eo=o(dt);ya=a(Eo,"Trainer"),Eo.forEach(s),Un=a(Xl," : se connecter \xE0 Hugging Face et d\xE9finir nos arguments d\u2019entra\xEEnement. Si vous travaillez dans un "),vs=r(Xl,"EM",{});var Su=o(vs);Ws=a(Su,"notebook"),Su.forEach(s),ls=a(Xl,", il y a une fonction pratique pour vous aider \xE0 le faire :"),Xl.forEach(s),Ps=d(i),w(Ds.$$.fragment,i),At=d(i),Xs=r(i,"P",{});var qo=o(Xs);bn=a(qo,"Cela affichera un "),Nt=r(qo,"EM",{});var ko=o(Nt);Zs=a(ko,"widget"),ko.forEach(s),Vn=a(qo," o\xF9 vous pourrez entrer vos identifiants de connexion \xE0 Hugging Face."),qo.forEach(s),Ee=d(i),mt=r(i,"P",{});var jo=o(mt);Wn=a(jo,"Si vous ne travaillez pas dans un "),qe=r(jo,"EM",{});var Lu=o(qe);Tt=a(Lu,"notebook"),Lu.forEach(s),$n=a(jo,", tapez simplement la ligne suivante dans votre terminal :"),jo.forEach(s),ie=d(i),w(rs.$$.fragment,i),gn=d(i),Ks=r(i,"P",{});var Zl=o(Ks);ft=a(Zl,"Une fois ceci fait, nous pouvons d\xE9finir nos "),St=r(Zl,"CODE",{});var Iu=o(St);Xn=a(Iu,"TrainingArguments"),Iu.forEach(s),Ys=a(Zl," :"),Zl.forEach(s),Lt=d(i),w(os.$$.fragment,i),It=d(i),me=r(i,"P",{});var ws=o(me);za=a(ws,"Vous avez d\xE9j\xE0 vu la plupart d\u2019entre eux. Nous d\xE9finissons quelques hyperparam\xE8tres (comme le taux d\u2019apprentissage, le nombre d\u2019\xE9poques \xE0 entra\xEEner, et le taux de d\xE9croissance des poids), et nous sp\xE9cifions "),Ft=r(ws,"CODE",{});var Hr=o(Ft);hs=a(Hr,"push_to_hub=True"),Hr.forEach(s),Ve=a(ws," pour indiquer que nous voulons sauvegarder le mod\xE8le, l\u2019\xE9valuer \xE0 la fin de chaque \xE9poque, et que nous voulons t\xE9l\xE9charger nos r\xE9sultats vers le "),Js=r(ws,"EM",{});var Fu=o(Js);Me=a(Fu,"Hub"),Fu.forEach(s),Oa=a(ws,". Notez que vous pouvez sp\xE9cifier le nom du d\xE9p\xF4t vers lequel vous voulez pousser avec l\u2019argument "),Ms=r(ws,"CODE",{});var Ru=o(Ms);Pa=a(Ru,"hub_model_id"),Ru.forEach(s),Zn=a(ws," (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),ke=r(ws,"A",{href:!0,rel:!0});var Wi=o(ke);En=r(Wi,"CODE",{});var Kl=o(En);qn=a(Kl,"huggingface-course"),Kl.forEach(s),Wi.forEach(s),Kn=a(ws,", nous avons ajout\xE9 "),Ae=r(ws,"CODE",{});var Xi=o(Ae);vt=a(Xi,'hub_model_id="huggingface-course/bert-finetuned-ner"``TrainingArguments'),Xi.forEach(s),kn=a(ws,". Par d\xE9faut, le d\xE9p\xF4t utilis\xE9 sera dans votre espace de noms et nomm\xE9 d\u2019apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini, donc dans notre cas ce sera "),jn=r(ws,"CODE",{});var Yl=o(jn);Yn=a(Yl,'"sgugger/bert-finetuned-ner"'),Yl.forEach(s),_s=a(ws,"."),ws.forEach(s),wn=d(i),w(Ie.$$.fragment,i),is=d(i),bs=r(i,"P",{});var Gr=o(bs);ht=a(Gr,"Enfin, nous passons tout au "),Rt=r(Gr,"CODE",{});var ce=o(Rt);As=a(ce,"Trainer"),ce.forEach(s),Jn=a(Gr," et lan\xE7ons l\u2019entra\xEEnement :"),Gr.forEach(s),je=d(i),w(Ne.$$.fragment,i),Bt=d(i),$s=r(i,"P",{});var wo=o($s);Da=a(wo,"Notez que pendant l\u2019entra\xEEnement, chaque fois que le mod\xE8le est sauvegard\xE9 (ici, \xE0 chaque \xE9poque), il est t\xE9l\xE9charg\xE9 sur le "),Ns=r(wo,"EM",{});var xo=o(Ns);_t=a(xo,"Hub"),xo.forEach(s),Ma=a(wo," en arri\xE8re-plan. De cette fa\xE7on, vous serez en mesure de reprendre votre entra\xEEnement sur une autre machine si n\xE9cessaire."),wo.forEach(s),Qn=d(i),us=r(i,"P",{});var Co=o(us);bt=a(Co,"Une fois l\u2019entra\xEEnement termin\xE9, nous utilisons la m\xE9thode "),Ht=r(Co,"CODE",{});var Bu=o(Ht);gs=a(Bu,"push_to_hub()"),Bu.forEach(s),Aa=a(Co," pour nous assurer que nous t\xE9l\xE9chargeons la version la plus r\xE9cente du mod\xE8le :"),Co.forEach(s),$t=d(i),w(Qs.$$.fragment,i),et=d(i),st=r(i,"P",{});var yo=o(st);We=a(yo,"Cette commande renvoie l\u2019URL du commit qu\u2019elle vient de faire, si vous voulez l\u2019inspecter :"),yo.forEach(s),xn=d(i),w(Fe.$$.fragment,i),Cn=d(i),re=r(i,"P",{});var ln=o(re);ea=a(ln,"Le "),$e=r(ln,"CODE",{});var Hu=o($e);Na=a(Hu,"Trainer"),Hu.forEach(s),yn=a(ln," r\xE9dige \xE9galement une carte mod\xE8le avec tous les r\xE9sultats de l\u2019\xE9valuation et la t\xE9l\xE9charge. A ce stade, vous pouvez utiliser le "),gt=r(ln,"EM",{});var zo=o(gt);Ta=a(zo,"widget"),zo.forEach(s),zn=a(ln," d\u2019inf\xE9rence sur le "),Et=r(ln,"EM",{});var Gu=o(Et);Sa=a(Gu,"Hub"),Gu.forEach(s),On=a(ln," pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 affiner un mod\xE8le sur une t\xE2che de classification de "),Gt=r(ln,"EM",{});var Uu=o(Gt);Ut=a(Uu,"tokens"),Uu.forEach(s),Pn=a(ln,". F\xE9licitations !"),ln.forEach(s),Dn=d(i),Xe=r(i,"P",{});var Jl=o(Xe);Mn=a(Jl,"Si vous voulez plonger un peu plus profond\xE9ment dans la boucle d\u2019entra\xEEnement, nous allons maintenant vous montrer comment faire la m\xEAme chose en utilisant \u{1F917} "),f=r(Jl,"EM",{});var Vu=o(f);S=a(Vu,"Accelerate"),Vu.forEach(s),An=a(Jl,"."),Jl.forEach(s),La=d(i),Ts=r(i,"H2",{class:!0});var Oo=o(Ts);be=r(Oo,"A",{id:!0,class:!0,href:!0});var Po=o(be);Nn=r(Po,"SPAN",{});var Wu=o(Nn);w(Es.$$.fragment,Wu),Wu.forEach(s),Po.forEach(s),Ia=d(Oo),Ss=r(Oo,"SPAN",{});var Xu=o(Ss);Vt=a(Xu,"Une boucle d'entra\xEEnement personnalis\xE9e"),Xu.forEach(s),Oo.forEach(s),Tn=d(i),qt=r(i,"P",{});var Ql=o(qt);Wt=a(Ql,"Jetons maintenant un coup d\u2019\u0153il \xE0 la boucle d\u2019entra\xEEnement compl\xE8te afin que vous puissiez facilement personnaliser les parties dont vous avez besoin. Elle ressemblera beaucoup \xE0 ce que nous avons fait dans le "),Xt=r(Ql,"A",{href:!0});var Zu=o(Xt);Zt=a(Zu,"chapitre 3"),Zu.forEach(s),Ls=a(Ql," avec quelques changements pour l\u2019\xE9valuation."),Ql.forEach(s),kt=d(i),Is=r(i,"H3",{class:!0});var Do=o(Is);fe=r(Do,"A",{id:!0,class:!0,href:!0});var Mo=o(fe);Kt=r(Mo,"SPAN",{});var Ku=o(Kt);w(tt.$$.fragment,Ku),Ku.forEach(s),Mo.forEach(s),wl=d(Do),Sn=r(Do,"SPAN",{});var Yu=o(Sn);sa=a(Yu,"Pr\xE9parer tout pour l'entra\xEEnement"),Yu.forEach(s),Do.forEach(s),Ln=d(i),ps=r(i,"P",{});var rn=o(ps);Yt=a(rn,"D\u2019abord nous devons construire le "),ta=r(rn,"CODE",{});var Ju=o(ta);na=a(Ju,"DataLoader"),Ju.forEach(s),aa=a(rn,"s \xE0 partir de nos jeux de donn\xE9es. Nous r\xE9utilisons notre "),Ze=r(rn,"CODE",{});var Qu=o(Ze);xl=a(Qu,"data_collator"),Qu.forEach(s),la=a(rn," comme un "),ra=r(rn,"CODE",{});var Ao=o(ra);Cl=a(Ao,"collate_fn"),Ao.forEach(s),jt=a(rn," et m\xE9langer l\u2019ensemble d\u2019entra\xEEnement, mais pas l\u2019ensemble de validation :"),rn.forEach(s),wt=d(i),w(xt.$$.fragment,i),Re=d(i),nt=r(i,"P",{});var No=o(nt);Fs=a(No,"Ensuite, nous r\xE9instantifions notre mod\xE8le pour nous assurer que nous ne continuons pas le "),oa=r(No,"EM",{});var ep=o(oa);Be=a(ep,"finetuning"),ep.forEach(s),yl=a(No," d\u2019avant et que nous repartons bien du mod\xE8le pr\xE9-entra\xEEn\xE9 de BERT :"),No.forEach(s),Fa=d(i),w(at.$$.fragment,i),Ra=d(i),Rs=r(i,"P",{});var ha=o(Rs);In=a(ha,"Ensuite, nous avons besoin d\u2019un optimiseur. Nous utilisons le classique "),Oe=r(ha,"CODE",{});var sp=o(Oe);He=a(sp,"AdamW"),sp.forEach(s),ia=a(ha,", qui est comme "),ua=r(ha,"CODE",{});var tp=o(ua);zl=a(tp,"Adam"),tp.forEach(s),Ol=a(ha,", mais avec un correctif dans la fa\xE7on dont le taux de d\xE9croissance des poids est appliqu\xE9e :"),ha.forEach(s),Ct=d(i),w(Fn.$$.fragment,i),Jr=d(i),pa=r(i,"P",{});var Ur=o(pa);mr=a(Ur,"Une fois que nous avons tous ces objets, nous pouvons les envoyer \xE0 la m\xE9thode "),fr=r(Ur,"CODE",{});var er=o(fr);ei=a(er,"accelerator.prepare()"),er.forEach(s),vr=a(Ur," :"),Ur.forEach(s),Qr=d(i),w(Ba.$$.fragment,i),eo=d(i),w(qs.$$.fragment,i),Pl=d(i),lt=r(i,"P",{});var Gn=o(lt);si=a(Gn,"Maintenant que nous avons envoy\xE9 notre "),Ha=r(Gn,"CODE",{});var Vr=o(Ha);ti=a(Vr,"train_dataloader"),Vr.forEach(s),ni=a(Gn," \xE0 "),Ga=r(Gn,"CODE",{});var np=o(Ga);ai=a(np,"accelerator.prepare()"),np.forEach(s),li=a(Gn,", nous pouvons utiliser sa longueur pour calculer le nombre d\u2019\xE9tapes d\u2019entra\xEEnement. Rappelez-vous que nous devrions toujours faire cela apr\xE8s avoir pr\xE9par\xE9 le "),hr=r(Gn,"EM",{});var Zi=o(hr);Jt=a(Zi,"dataloader"),Zi.forEach(s),_r=a(Gn," car cette m\xE9thode modifiera sa longueur. Nous utilisons un programme lin\xE9aire classique du taux d\u2019apprentissage \xE0 0 :"),Gn.forEach(s),so=d(i),w(Ua.$$.fragment,i),Dl=d(i),ks=r(i,"P",{});var xs=o(ks);ri=a(xs,"Enfin, pour pousser notre mod\xE8le vers le "),Va=r(xs,"EM",{});var Ki=o(Va);oi=a(Ki,"Hub"),Ki.forEach(s),ii=a(xs,", nous avons besoin de cr\xE9er un objet "),br=r(xs,"CODE",{});var sr=o(br);Qt=a(sr,"Repository"),sr.forEach(s),$r=a(xs," dans un dossier de travail. Tout d\u2019abord, connectez-vous \xE0 Hugging Face si vous n\u2019\xEAtes pas d\xE9j\xE0 connect\xE9. Nous d\xE9terminons le nom du d\xE9p\xF4t \xE0 partir de l\u2019identifiant du mod\xE8le que nous voulons donner \xE0 notre mod\xE8le (n\u2019h\xE9sitez pas \xE0 remplacer le "),gr=r(xs,"CODE",{});var Yi=o(gr);ui=a(Yi,"repo_name"),Yi.forEach(s),Er=a(xs," par votre propre choix, il doit juste contenir votre nom d\u2019utilisateur et ce que fait la fonction "),qr=r(xs,"CODE",{});var Vs=o(qr);pi=a(Vs,"get_full_repo_name()"),Vs.forEach(s),kr=a(xs,") :"),xs.forEach(s),to=d(i),w(Wa.$$.fragment,i),jr=d(i),w(en.$$.fragment,i),no=d(i),Xa=r(i,"P",{});var ap=o(Xa);Za=a(ap,"Ensuite, nous pouvons cloner ce d\xE9p\xF4t dans un dossier local. S\u2019il existe d\xE9j\xE0, ce dossier local doit \xEAtre un clone existant du d\xE9p\xF4t avec lequel nous travaillons :"),ap.forEach(s),wr=d(i),w(yt.$$.fragment,i),xr=d(i),Ge=r(i,"P",{});var _a=o(Ge);ci=a(_a,"Nous pouvons maintenant t\xE9l\xE9charger tout ce que nous sauvegardons dans "),Ka=r(_a,"CODE",{});var lp=o(Ka);di=a(lp,"output_dir"),lp.forEach(s),mi=a(_a," en appelant la m\xE9thode "),Ya=r(_a,"CODE",{});var rp=o(Ya);fi=a(rp,"repo.push_to_hub()"),rp.forEach(s),vi=a(_a,". Cela nous aidera \xE0 t\xE9l\xE9charger les mod\xE8les interm\xE9diaires \xE0 la fin de chaque \xE9poque."),_a.forEach(s),Cr=d(i),Bs=r(i,"H3",{class:!0});var tr=o(Bs);Rn=r(tr,"A",{id:!0,class:!0,href:!0});var op=o(Rn);rt=r(op,"SPAN",{});var ip=o(rt);w(Ja.$$.fragment,ip),ip.forEach(s),op.forEach(s),yr=d(tr),zr=r(tr,"SPAN",{});var To=o(zr);hi=a(To,"Boucle d'entra\xEEnement"),To.forEach(s),tr.forEach(s),Ml=d(i),sn=r(i,"P",{});var nr=o(sn);_i=a(nr,"Nous sommes maintenant pr\xEAts \xE0 \xE9crire la boucle d\u2019entra\xEEnement compl\xE8te. Pour simplifier sa partie \xE9valuation, nous d\xE9finissons cette fonction "),Al=r(nr,"CODE",{});var up=o(Al);ca=a(up,"postprocess()"),up.forEach(s),ao=a(nr," qui prend les pr\xE9dictions et les \xE9tiquettes, et les convertit en listes de cha\xEEnes de caract\xE8res comme notre objet "),zt=r(nr,"CODE",{});var So=o(zt);da=a(So,"metric"),So.forEach(s),Or=a(nr," l\u2019attend :"),nr.forEach(s),ma=d(i),w(Qa.$$.fragment,i),Nl=d(i),Tl=r(i,"P",{});var pp=o(Tl);lo=a(pp,"Ensuite, nous pouvons \xE9crire la boucle d\u2019entra\xEEnement. Apr\xE8s avoir d\xE9fini une barre de progression pour suivre l\u2019\xE9volution de l\u2019entra\xEEnement, la boucle comporte trois parties :"),pp.forEach(s),fa=d(i),Ot=r(i,"UL",{});var ar=o(Ot);we=r(ar,"LI",{});var Wr=o(we);bi=a(Wr,"L\u2019entra\xEEnement proprement dit, qui est l\u2019it\xE9ration classique sur le "),el=r(Wr,"CODE",{});var ml=o(el);$i=a(ml,"train_dataloader"),ml.forEach(s),gi=a(Wr,", passage en avant, puis passage en arri\xE8re et \xE9tape d\u2019optimisation."),Wr.forEach(s),Sl=d(ar),Hs=r(ar,"LI",{});var Dt=o(Hs);Ei=a(Dt,"L\u2019\xE9valuation, dans laquelle il y a une nouveaut\xE9 apr\xE8s avoir obtenu les sorties de notre mod\xE8le sur un batch : puisque deux processus peuvent avoir padd\xE9 les entr\xE9es et les \xE9tiquettes \xE0 des formes diff\xE9rentes, nous devons utiliser "),sl=r(Dt,"CODE",{});var Ue=o(sl);qi=a(Ue,"accelerator.pad_across_processes()"),Ue.forEach(s),ki=a(Dt," pour rendre les pr\xE9dictions et les \xE9tiquettes de la m\xEAme forme avant d\u2019appeler la m\xE9thode "),tl=r(Dt,"CODE",{});var cp=o(tl);ji=a(cp,"gather()"),cp.forEach(s),wi=a(Dt,". Si nous ne le faisons pas, l\u2019\xE9valuation va soit se tromper, soit se bloquer pour toujours. Ensuite, nous envoyons les r\xE9sultats \xE0 "),nl=r(Dt,"CODE",{});var Lo=o(nl);xi=a(Lo,"metric.add_batch()"),Lo.forEach(s),Ci=a(Dt," et appelons "),Ll=r(Dt,"CODE",{});var dp=o(Ll);tn=a(dp,"metric.compute()"),dp.forEach(s),yi=a(Dt," une fois que la boucle d\u2019\xE9valuation est termin\xE9e."),Dt.forEach(s),Pr=d(ar),Gs=r(ar,"LI",{});var on=o(Gs);zi=a(on,"Sauvegarde et t\xE9l\xE9chargement, o\xF9 nous sauvegardons d\u2019abord le mod\xE8le et le "),al=r(on,"EM",{});var Io=o(al);Oi=a(Io,"tokenizer"),Io.forEach(s),Pi=a(on,", puis appelons "),Il=r(on,"CODE",{});var mp=o(Il);ll=a(mp,"repo.push_to_hub()"),mp.forEach(s),ro=a(on,". Remarquez que nous utilisons l\u2019argument "),ue=r(on,"CODE",{});var fp=o(ue);Di=a(fp,"blocking=False"),fp.forEach(s),Dr=a(on," pour indiquer \xE0 la biblioth\xE8que \u{1F917} "),Mr=r(on,"EM",{});var Fo=o(Mr);Mi=a(Fo,"Hub"),Fo.forEach(s),rl=a(on," de pousser dans un processus asynchrone. De cette fa\xE7on, l\u2019entra\xEEnement continue normalement et cette (longue) instruction est ex\xE9cut\xE9e en arri\xE8re-plan."),on.forEach(s),ar.forEach(s),Fl=d(i),Rl=r(i,"P",{});var vp=o(Rl);Ai=a(vp,"Voici le code complet de la boucle d\u2019entra\xEEnement :"),vp.forEach(s),Bl=d(i),w(ol.$$.fragment,i),oo=d(i),nn=r(i,"P",{});var Ro=o(nn);Ni=a(Ro,"Au cas o\xF9 ce serait la premi\xE8re fois que vous verriez un mod\xE8le enregistr\xE9 avec \u{1F917} "),Ar=r(Ro,"EM",{});var Bo=o(Ar);Nr=a(Bo,"Accelerate"),Bo.forEach(s),Ti=a(Ro,", prenons un moment pour inspecter les trois lignes de code qui l\u2019accompagnent :"),Ro.forEach(s),io=d(i),w(Pt.$$.fragment,i),uo=d(i),xe=r(i,"P",{});var Ke=o(xe);Tr=a(Ke,"La premi\xE8re ligne est explicite : elle indique \xE0 tous les processus d\u2019attendre que tout le monde soit \xE0 ce stade avant de continuer. C\u2019est pour s\u2019assurer que nous avons le m\xEAme mod\xE8le dans chaque processus avant de sauvegarder. Ensuite, nous prenons le "),Sr=r(Ke,"CODE",{});var hp=o(Sr);Si=a(hp,"unwrapped_model"),hp.forEach(s),Lr=a(Ke," qui est le mod\xE8le de base que nous avons d\xE9fini. La m\xE9thode "),Ir=r(Ke,"CODE",{});var Ho=o(Ir);Li=a(Ho,"accelerator.prepare()"),Ho.forEach(s),Fr=a(Ke," modifie le mod\xE8le pour qu\u2019il fonctionne dans l\u2019entra\xEEnement distribu\xE9, donc il n\u2019aura plus la m\xE9thode "),Rr=r(Ke,"CODE",{});var _p=o(Rr);Ii=a(_p,"save_pretrained()"),_p.forEach(s),po=a(Ke," ; la m\xE9thode "),Bn=r(Ke,"CODE",{});var bp=o(Bn);co=a(bp,"accelerator.unwrap_model()"),bp.forEach(s),il=a(Ke," annule cette \xE9tape. Enfin, nous appelons "),Hl=r(Ke,"CODE",{});var Go=o(Hl);an=a(Go,"save_pretrained()"),Go.forEach(s),Fi=a(Ke," mais nous disons \xE0 cette m\xE9thode d\u2019utiliser "),ul=r(Ke,"CODE",{});var $p=o(ul);Ri=a($p,"accelerator.save()"),$p.forEach(s),Bi=a(Ke," au lieu de "),pl=r(Ke,"CODE",{});var gp=o(pl);Hi=a(gp,"torch.save()"),gp.forEach(s),Gi=a(Ke,"."),Ke.forEach(s),Br=d(i),js=r(i,"P",{});var fl=o(js);mo=a(fl,"Une fois ceci fait, vous devriez avoir un mod\xE8le qui produit des r\xE9sultats assez similaires \xE0 celui entra\xEEn\xE9 avec le "),Hn=r(fl,"CODE",{});var lr=o(Hn);fo=a(lr,"Trainer"),lr.forEach(s),ve=a(fl,". Vous pouvez v\xE9rifier le mod\xE8le que nous avons form\xE9 en utilisant ce code \xE0 "),cl=r(fl,"A",{href:!0,rel:!0});var Ji=o(cl);dl=r(Ji,"EM",{});var Xr=o(dl);Ui=a(Xr,"huggingface-course/bert-finetuned-ner-accelerate"),Xr.forEach(s),Ji.forEach(s),Vi=a(fl,". Et si vous voulez tester des modifications de la boucle d\u2019entra\xEEnement, vous pouvez les impl\xE9menter directement en modifiant le code ci-dessus !"),fl.forEach(s),this.h()},h(){_(g,"id","dfinir-le-modle"),_(g,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(g,"href","#dfinir-le-modle"),_(p,"class","relative group"),_(ne,"href","/course/fr/chapter3"),_(Le,"id","ifinetuningi-du-modle"),_(Le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Le,"href","#ifinetuningi-du-modle"),_(ye,"class","relative group"),_(ke,"href","https://huggingface.co/huggingface-course"),_(ke,"rel","nofollow"),_(be,"id","une-boucle-dentranement-personnalise"),_(be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(be,"href","#une-boucle-dentranement-personnalise"),_(Ts,"class","relative group"),_(Xt,"href","/course/fr/chapter3/4"),_(fe,"id","prparer-tout-pour-lentranement"),_(fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(fe,"href","#prparer-tout-pour-lentranement"),_(Is,"class","relative group"),_(Rn,"id","boucle-dentranement"),_(Rn,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Rn,"href","#boucle-dentranement"),_(Bs,"class","relative group"),_(cl,"href","https://huggingface.co/huggingface-course/bert-finetuned-ner-accelerate"),_(cl,"rel","nofollow")},m(i,h){u(i,p,h),e(p,g),e(g,v),x(q,v,null),e(p,z),e(p,E),e(E,k),u(i,P,h),u(i,y,h),e(y,O),e(y,H),e(H,I),e(y,L),e(y,F),e(F,T),e(y,U),e(y,W),e(W,D),e(y,M),e(y,V),e(V,Y),e(y,se),u(i,N,h),u(i,G,h),e(G,te),e(G,J),e(J,ee),e(G,R),e(G,K),e(K,de),e(G,Pe),u(i,he,h),x(B,i,h),u(i,le,h),u(i,Q,h),e(Q,oe),e(Q,Z),e(Z,pe),e(Q,Qe),e(Q,_e),e(_e,ge),e(Q,ys),u(i,Ce,h),x(De,i,h),u(i,es,h),u(i,ae,h),e(ae,ms),e(ae,fs),e(fs,Mt),e(ae,qa),e(ae,ne),e(ne,ka),e(ae,dn),e(ae,zs),e(zs,ja),e(ae,wa),u(i,ut,h),x(ss,i,h),u(i,mn,h),x(Se,i,h),u(i,fn,h),x(ts,i,h),u(i,pt,h),u(i,ye,h),e(ye,Le),e(Le,Os),x(ns,Os,null),e(ye,xa),e(ye,as),e(as,ct),e(ct,Ca),e(as,vn),u(i,hn,h),u(i,ze,h),e(ze,_n),e(ze,dt),e(dt,ya),e(ze,Un),e(ze,vs),e(vs,Ws),e(ze,ls),u(i,Ps,h),x(Ds,i,h),u(i,At,h),u(i,Xs,h),e(Xs,bn),e(Xs,Nt),e(Nt,Zs),e(Xs,Vn),u(i,Ee,h),u(i,mt,h),e(mt,Wn),e(mt,qe),e(qe,Tt),e(mt,$n),u(i,ie,h),x(rs,i,h),u(i,gn,h),u(i,Ks,h),e(Ks,ft),e(Ks,St),e(St,Xn),e(Ks,Ys),u(i,Lt,h),x(os,i,h),u(i,It,h),u(i,me,h),e(me,za),e(me,Ft),e(Ft,hs),e(me,Ve),e(me,Js),e(Js,Me),e(me,Oa),e(me,Ms),e(Ms,Pa),e(me,Zn),e(me,ke),e(ke,En),e(En,qn),e(me,Kn),e(me,Ae),e(Ae,vt),e(me,kn),e(me,jn),e(jn,Yn),e(me,_s),u(i,wn,h),x(Ie,i,h),u(i,is,h),u(i,bs,h),e(bs,ht),e(bs,Rt),e(Rt,As),e(bs,Jn),u(i,je,h),x(Ne,i,h),u(i,Bt,h),u(i,$s,h),e($s,Da),e($s,Ns),e(Ns,_t),e($s,Ma),u(i,Qn,h),u(i,us,h),e(us,bt),e(us,Ht),e(Ht,gs),e(us,Aa),u(i,$t,h),x(Qs,i,h),u(i,et,h),u(i,st,h),e(st,We),u(i,xn,h),x(Fe,i,h),u(i,Cn,h),u(i,re,h),e(re,ea),e(re,$e),e($e,Na),e(re,yn),e(re,gt),e(gt,Ta),e(re,zn),e(re,Et),e(Et,Sa),e(re,On),e(re,Gt),e(Gt,Ut),e(re,Pn),u(i,Dn,h),u(i,Xe,h),e(Xe,Mn),e(Xe,f),e(f,S),e(Xe,An),u(i,La,h),u(i,Ts,h),e(Ts,be),e(be,Nn),x(Es,Nn,null),e(Ts,Ia),e(Ts,Ss),e(Ss,Vt),u(i,Tn,h),u(i,qt,h),e(qt,Wt),e(qt,Xt),e(Xt,Zt),e(qt,Ls),u(i,kt,h),u(i,Is,h),e(Is,fe),e(fe,Kt),x(tt,Kt,null),e(Is,wl),e(Is,Sn),e(Sn,sa),u(i,Ln,h),u(i,ps,h),e(ps,Yt),e(ps,ta),e(ta,na),e(ps,aa),e(ps,Ze),e(Ze,xl),e(ps,la),e(ps,ra),e(ra,Cl),e(ps,jt),u(i,wt,h),x(xt,i,h),u(i,Re,h),u(i,nt,h),e(nt,Fs),e(nt,oa),e(oa,Be),e(nt,yl),u(i,Fa,h),x(at,i,h),u(i,Ra,h),u(i,Rs,h),e(Rs,In),e(Rs,Oe),e(Oe,He),e(Rs,ia),e(Rs,ua),e(ua,zl),e(Rs,Ol),u(i,Ct,h),x(Fn,i,h),u(i,Jr,h),u(i,pa,h),e(pa,mr),e(pa,fr),e(fr,ei),e(pa,vr),u(i,Qr,h),x(Ba,i,h),u(i,eo,h),x(qs,i,h),u(i,Pl,h),u(i,lt,h),e(lt,si),e(lt,Ha),e(Ha,ti),e(lt,ni),e(lt,Ga),e(Ga,ai),e(lt,li),e(lt,hr),e(hr,Jt),e(lt,_r),u(i,so,h),x(Ua,i,h),u(i,Dl,h),u(i,ks,h),e(ks,ri),e(ks,Va),e(Va,oi),e(ks,ii),e(ks,br),e(br,Qt),e(ks,$r),e(ks,gr),e(gr,ui),e(ks,Er),e(ks,qr),e(qr,pi),e(ks,kr),u(i,to,h),x(Wa,i,h),u(i,jr,h),x(en,i,h),u(i,no,h),u(i,Xa,h),e(Xa,Za),u(i,wr,h),x(yt,i,h),u(i,xr,h),u(i,Ge,h),e(Ge,ci),e(Ge,Ka),e(Ka,di),e(Ge,mi),e(Ge,Ya),e(Ya,fi),e(Ge,vi),u(i,Cr,h),u(i,Bs,h),e(Bs,Rn),e(Rn,rt),x(Ja,rt,null),e(Bs,yr),e(Bs,zr),e(zr,hi),u(i,Ml,h),u(i,sn,h),e(sn,_i),e(sn,Al),e(Al,ca),e(sn,ao),e(sn,zt),e(zt,da),e(sn,Or),u(i,ma,h),x(Qa,i,h),u(i,Nl,h),u(i,Tl,h),e(Tl,lo),u(i,fa,h),u(i,Ot,h),e(Ot,we),e(we,bi),e(we,el),e(el,$i),e(we,gi),e(Ot,Sl),e(Ot,Hs),e(Hs,Ei),e(Hs,sl),e(sl,qi),e(Hs,ki),e(Hs,tl),e(tl,ji),e(Hs,wi),e(Hs,nl),e(nl,xi),e(Hs,Ci),e(Hs,Ll),e(Ll,tn),e(Hs,yi),e(Ot,Pr),e(Ot,Gs),e(Gs,zi),e(Gs,al),e(al,Oi),e(Gs,Pi),e(Gs,Il),e(Il,ll),e(Gs,ro),e(Gs,ue),e(ue,Di),e(Gs,Dr),e(Gs,Mr),e(Mr,Mi),e(Gs,rl),u(i,Fl,h),u(i,Rl,h),e(Rl,Ai),u(i,Bl,h),x(ol,i,h),u(i,oo,h),u(i,nn,h),e(nn,Ni),e(nn,Ar),e(Ar,Nr),e(nn,Ti),u(i,io,h),x(Pt,i,h),u(i,uo,h),u(i,xe,h),e(xe,Tr),e(xe,Sr),e(Sr,Si),e(xe,Lr),e(xe,Ir),e(Ir,Li),e(xe,Fr),e(xe,Rr),e(Rr,Ii),e(xe,po),e(xe,Bn),e(Bn,co),e(xe,il),e(xe,Hl),e(Hl,an),e(xe,Fi),e(xe,ul),e(ul,Ri),e(xe,Bi),e(xe,pl),e(pl,Hi),e(xe,Gi),u(i,Br,h),u(i,js,h),e(js,mo),e(js,Hn),e(Hn,fo),e(js,ve),e(js,cl),e(cl,dl),e(dl,Ui),e(js,Vi),Gl=!0},i(i){Gl||(b(q.$$.fragment,i),b(B.$$.fragment,i),b(De.$$.fragment,i),b(ss.$$.fragment,i),b(Se.$$.fragment,i),b(ts.$$.fragment,i),b(ns.$$.fragment,i),b(Ds.$$.fragment,i),b(rs.$$.fragment,i),b(os.$$.fragment,i),b(Ie.$$.fragment,i),b(Ne.$$.fragment,i),b(Qs.$$.fragment,i),b(Fe.$$.fragment,i),b(Es.$$.fragment,i),b(tt.$$.fragment,i),b(xt.$$.fragment,i),b(at.$$.fragment,i),b(Fn.$$.fragment,i),b(Ba.$$.fragment,i),b(qs.$$.fragment,i),b(Ua.$$.fragment,i),b(Wa.$$.fragment,i),b(en.$$.fragment,i),b(yt.$$.fragment,i),b(Ja.$$.fragment,i),b(Qa.$$.fragment,i),b(ol.$$.fragment,i),b(Pt.$$.fragment,i),Gl=!0)},o(i){$(q.$$.fragment,i),$(B.$$.fragment,i),$(De.$$.fragment,i),$(ss.$$.fragment,i),$(Se.$$.fragment,i),$(ts.$$.fragment,i),$(ns.$$.fragment,i),$(Ds.$$.fragment,i),$(rs.$$.fragment,i),$(os.$$.fragment,i),$(Ie.$$.fragment,i),$(Ne.$$.fragment,i),$(Qs.$$.fragment,i),$(Fe.$$.fragment,i),$(Es.$$.fragment,i),$(tt.$$.fragment,i),$(xt.$$.fragment,i),$(at.$$.fragment,i),$(Fn.$$.fragment,i),$(Ba.$$.fragment,i),$(qs.$$.fragment,i),$(Ua.$$.fragment,i),$(Wa.$$.fragment,i),$(en.$$.fragment,i),$(yt.$$.fragment,i),$(Ja.$$.fragment,i),$(Qa.$$.fragment,i),$(ol.$$.fragment,i),$(Pt.$$.fragment,i),Gl=!1},d(i){i&&s(p),C(q),i&&s(P),i&&s(y),i&&s(N),i&&s(G),i&&s(he),C(B,i),i&&s(le),i&&s(Q),i&&s(Ce),C(De,i),i&&s(es),i&&s(ae),i&&s(ut),C(ss,i),i&&s(mn),C(Se,i),i&&s(fn),C(ts,i),i&&s(pt),i&&s(ye),C(ns),i&&s(hn),i&&s(ze),i&&s(Ps),C(Ds,i),i&&s(At),i&&s(Xs),i&&s(Ee),i&&s(mt),i&&s(ie),C(rs,i),i&&s(gn),i&&s(Ks),i&&s(Lt),C(os,i),i&&s(It),i&&s(me),i&&s(wn),C(Ie,i),i&&s(is),i&&s(bs),i&&s(je),C(Ne,i),i&&s(Bt),i&&s($s),i&&s(Qn),i&&s(us),i&&s($t),C(Qs,i),i&&s(et),i&&s(st),i&&s(xn),C(Fe,i),i&&s(Cn),i&&s(re),i&&s(Dn),i&&s(Xe),i&&s(La),i&&s(Ts),C(Es),i&&s(Tn),i&&s(qt),i&&s(kt),i&&s(Is),C(tt),i&&s(Ln),i&&s(ps),i&&s(wt),C(xt,i),i&&s(Re),i&&s(nt),i&&s(Fa),C(at,i),i&&s(Ra),i&&s(Rs),i&&s(Ct),C(Fn,i),i&&s(Jr),i&&s(pa),i&&s(Qr),C(Ba,i),i&&s(eo),C(qs,i),i&&s(Pl),i&&s(lt),i&&s(so),C(Ua,i),i&&s(Dl),i&&s(ks),i&&s(to),C(Wa,i),i&&s(jr),C(en,i),i&&s(no),i&&s(Xa),i&&s(wr),C(yt,i),i&&s(xr),i&&s(Ge),i&&s(Cr),i&&s(Bs),C(Ja),i&&s(Ml),i&&s(sn),i&&s(ma),C(Qa,i),i&&s(Nl),i&&s(Tl),i&&s(fa),i&&s(Ot),i&&s(Fl),i&&s(Rl),i&&s(Bl),C(ol,i),i&&s(oo),i&&s(nn),i&&s(io),C(Pt,i),i&&s(uo),i&&s(xe),i&&s(Br),i&&s(js)}}}function _h(X){let p,g,v,q,z;return{c(){p=l("p"),g=n("\u26A0\uFE0F Si vous avez un mod\xE8le avec le mauvais nombre d\u2019\xE9tiquettes, vous obtiendrez une erreur obscure lors de l\u2019appel de la m\xE9thode "),v=l("code"),q=n("Trainer.train()"),z=n(" (quelque chose comme \u201CCUDA error : device-side assert triggered\u201D). C\u2019est la premi\xE8re cause de bogues signal\xE9s par les utilisateurs pour de telles erreurs, donc assurez-vous de faire cette v\xE9rification pour confirmer que vous avez le nombre d\u2019\xE9tiquettes attendu.")},l(E){p=r(E,"P",{});var k=o(p);g=a(k,"\u26A0\uFE0F Si vous avez un mod\xE8le avec le mauvais nombre d\u2019\xE9tiquettes, vous obtiendrez une erreur obscure lors de l\u2019appel de la m\xE9thode "),v=r(k,"CODE",{});var P=o(v);q=a(P,"Trainer.train()"),P.forEach(s),z=a(k," (quelque chose comme \u201CCUDA error : device-side assert triggered\u201D). C\u2019est la premi\xE8re cause de bogues signal\xE9s par les utilisateurs pour de telles erreurs, donc assurez-vous de faire cette v\xE9rification pour confirmer que vous avez le nombre d\u2019\xE9tiquettes attendu."),k.forEach(s)},m(E,k){u(E,p,k),e(p,g),e(p,v),e(v,q),e(p,z)},d(E){E&&s(p)}}}function bh(X){let p,g,v,q,z;return{c(){p=l("p"),g=n("\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de la d\xE9finition de votre "),v=l("code"),q=n("Trainer"),z=n(" et devrez d\xE9finir un nouveau nom.")},l(E){p=r(E,"P",{});var k=o(p);g=a(k,"\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de la d\xE9finition de votre "),v=r(k,"CODE",{});var P=o(v);q=a(P,"Trainer"),P.forEach(s),z=a(k," et devrez d\xE9finir un nouveau nom."),k.forEach(s)},m(E,k){u(E,p,k),e(p,g),e(p,v),e(v,q),e(p,z)},d(E){E&&s(p)}}}function $h(X){let p,g,v,q,z;return{c(){p=l("p"),g=n("\u{1F6A8} Si vous entra\xEEnez sur un TPU, vous devrez d\xE9placer tout le code \xE0 partir de la cellule ci-dessus dans une fonction d\u2019entra\xEEnement d\xE9di\xE9e. Voir le "),v=l("a"),q=n("chapitre 3"),z=n(" pour plus de d\xE9tails."),this.h()},l(E){p=r(E,"P",{});var k=o(p);g=a(k,"\u{1F6A8} Si vous entra\xEEnez sur un TPU, vous devrez d\xE9placer tout le code \xE0 partir de la cellule ci-dessus dans une fonction d\u2019entra\xEEnement d\xE9di\xE9e. Voir le "),v=r(k,"A",{href:!0});var P=o(v);q=a(P,"chapitre 3"),P.forEach(s),z=a(k," pour plus de d\xE9tails."),k.forEach(s),this.h()},h(){_(v,"href","/course/fr/chapter3")},m(E,k){u(E,p,k),e(p,g),e(p,v),e(v,q),e(p,z)},d(E){E&&s(p)}}}function gh(X){let p,g,v,q,z,E,k,P,y,O,H,I,L,F,T,U,W,D,M,V,Y,se,N,G,te,J,ee,R,K,de,Pe,he,B,le,Q,oe,Z,pe,Qe,_e,ge,ys,Ce,De,es,ae,ms,fs,Mt,qa,ne,ka,dn,zs,ja,wa,ut,ss,mn,Se,fn,ts,pt,ye,Le,Os,ns,xa,as,ct,Ca,vn,hn,ze,_n,dt,ya,Un,vs,Ws,ls,Ps,Ds,At,Xs,bn,Nt,Zs,Vn,Ee,mt,Wn,qe,Tt,$n,ie,rs,gn,Ks,ft,St,Xn,Ys,Lt,os,It,me,za,Ft,hs,Ve,Js,Me,Oa,Ms,Pa,Zn,ke,En,qn,Kn,Ae,vt,kn,jn,Yn,_s,wn,Ie,is,bs,ht,Rt,As,Jn,je,Ne,Bt,$s,Da,Ns,_t,Ma,Qn,us,bt,Ht,gs,Aa,$t,Qs,et,st,We,xn,Fe,Cn,re,ea,$e,Na,yn,gt,Ta,zn,Et,Sa,On,Gt,Ut,Pn,Dn,Xe,Mn,f,S,An,La,Ts,be,Nn,Es,Ia,Ss,Vt,Tn,qt,Wt,Xt,Zt,Ls,kt,Is,fe,Kt,tt,wl,Sn,sa,Ln,ps,Yt,ta,na,aa,Ze,xl,la,ra,Cl,jt,wt,xt,Re,nt,Fs,oa,Be,yl,Fa,at,Ra,Rs,In,Oe,He,ia,ua,zl,Ol,Ct,Fn,Jr,pa,mr,fr,ei,vr,Qr,Ba,eo,qs,Pl,lt,si,Ha,ti,ni,Ga,ai,li,hr,Jt,_r,so,Ua,Dl,ks,ri,Va,oi,ii,br,Qt,$r,gr,ui,Er,qr,pi,kr,to,Wa,jr,en,no,Xa,Za,wr,yt,xr,Ge,ci,Ka,di,mi,Ya,fi,vi,Cr,Bs,Rn,rt,Ja,yr,zr,hi,Ml,sn,_i,Al,ca,ao,zt,da,Or,ma,Qa,Nl,Tl,lo,fa,Ot,we,bi,el,$i,gi,Sl,Hs,Ei,sl,qi,ki,tl,ji,wi,nl,xi,Ci,Ll,tn,yi,Pr,Gs,zi,al,Oi,Pi,Il,ll,ro,ue,Di,Dr,Mr,Mi,rl,Fl,Rl,Ai,Bl,ol,oo,nn,Ni,Ar,Nr,Ti,io,Pt,uo,xe,Tr,Sr,Si,Lr,Ir,Li,Fr,Rr,Ii,po,Bn,co,il,Hl,an,Fi,ul,Ri,Bi,pl,Hi,Gi,Br,js,mo,Hn,fo,ve,cl,dl,Ui,Vi,Gl,i,h,vo,xu,Cu,ot,yu,zu,ho,Ou,Ul,_o,Pu,Vl,bo,Du,va,$o,Mu,Au,Wl,Nu,Tu,go,Us,Xl,Eo,Su,qo,ko,jo,Lu,Zl,Iu,ws,Hr,Fu,Ru,Wi,Kl,Xi,Yl,Gr,ce,wo,xo,Co,Bu,yo,ln,Hu,zo,Gu,Uu,Jl,Vu,Oo,Po,Wu,Xu,Ql,Zu,Do,Mo,Ku,Yu,rn,Ju,Qu,Ao,No,ep,ha,sp,tp,Ur,er,Gn,Vr,np,Zi,xs,Ki,sr,Yi,Vs,ap,_a,lp,rp,tr,op,ip,To,nr,up,So,pp,ar,Wr,ml,Dt,Ue,cp,Lo,dp,on,Io,mp,fp,Fo,vp,Ro,Bo,Ke,hp,Ho,_p,bp,Go,$p,gp,fl,lr,Ji,Xr,sd,fc,Ep,td,vc,Qi,hc,Uo,nd,qp,ad,ld,_c,vl,hl,kp,Zr,Vo,Kp,eu,rd,Yp,od,bc,un,id,Jp,ud,pd,jp,cd,dd,Qp,md,fd,ec,vd,hd,$c,ba,_d,su,sc,bd,$d,tc,gd,Ed,nc,qd,kd,gc,_l,bl,wp,xp,jd,Ec,tu,qc,nu,kc,Cp,wd,jc,au,wc,lu,xc,$l,gl,yp,zp,Kr,Wo,ac,ru,xd,lc,Cd,Cc,El,ql,Op,ou,yc,Pp,yd,zc,iu,Oc,uu,Pc,Dp,zd,Dc,pu,Mc,Mp,Od,Ac,cu,Nc,kl,jl,Ap,Np,Yr,Xo,rc,du,Pd,Tp,Dd,oc,Md,Tc,pn,Ad,ic,Nd,Td,uc,Sd,Ld,pc,Id,Fd,cc,Rd,Bd,Sc,mu,Lc,fu,Ic,Sp,Hd,Fc;v=new Qv({props:{fw:X[0]}}),P=new it({});const Wd=[sh,eh],vu=[];function Xd(t,m){return t[0]==="pt"?0:1}T=Xd(X),U=vu[T]=Wd[T](X),vs=new Gv({props:{id:"wVHdVlPScxA"}}),Me=new it({}),_s=new Qo({props:{$$slots:{default:[th]},$$scope:{ctx:X}}}),ht=new it({}),bt=new A({props:{code:`from datasets import load_dataset

raw_datasets = load_dataset("conll2003")`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

raw_datasets = load_dataset(<span class="hljs-string">&quot;conll2003&quot;</span>)`}}),We=new A({props:{code:"raw_datasets",highlighted:"raw_datasets"}}),Fe=new A({props:{code:`DatasetDict({
    train: Dataset({
        features: ['chunk_tags', 'id', 'ner_tags', 'pos_tags', 'tokens'],
        num_rows: 14041
    })
    validation: Dataset({
        features: ['chunk_tags', 'id', 'ner_tags', 'pos_tags', 'tokens'],
        num_rows: 3250
    })
    test: Dataset({
        features: ['chunk_tags', 'id', 'ner_tags', 'pos_tags', 'tokens'],
        num_rows: 3453
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;chunk_tags&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;ner_tags&#x27;</span>, <span class="hljs-string">&#x27;pos_tags&#x27;</span>, <span class="hljs-string">&#x27;tokens&#x27;</span>],
        num_rows: <span class="hljs-number">14041</span>
    })
    validation: Dataset({
        features: [<span class="hljs-string">&#x27;chunk_tags&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;ner_tags&#x27;</span>, <span class="hljs-string">&#x27;pos_tags&#x27;</span>, <span class="hljs-string">&#x27;tokens&#x27;</span>],
        num_rows: <span class="hljs-number">3250</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;chunk_tags&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;ner_tags&#x27;</span>, <span class="hljs-string">&#x27;pos_tags&#x27;</span>, <span class="hljs-string">&#x27;tokens&#x27;</span>],
        num_rows: <span class="hljs-number">3453</span>
    })
})`}}),Xe=new A({props:{code:'raw_datasets["train"][0]["tokens"]',highlighted:'raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;tokens&quot;</span>]'}}),f=new A({props:{code:"['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']",highlighted:'[<span class="hljs-string">&#x27;EU&#x27;</span>, <span class="hljs-string">&#x27;rejects&#x27;</span>, <span class="hljs-string">&#x27;German&#x27;</span>, <span class="hljs-string">&#x27;call&#x27;</span>, <span class="hljs-string">&#x27;to&#x27;</span>, <span class="hljs-string">&#x27;boycott&#x27;</span>, <span class="hljs-string">&#x27;British&#x27;</span>, <span class="hljs-string">&#x27;lamb&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>]'}}),be=new A({props:{code:'raw_datasets["train"][0]["ner_tags"]',highlighted:'raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;ner_tags&quot;</span>]'}}),Es=new A({props:{code:"[3, 0, 7, 0, 0, 0, 7, 0, 0]",highlighted:'[<span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]'}}),Zt=new A({props:{code:`ner_feature = raw_datasets["train"].features["ner_tags"]
ner_feature`,highlighted:`ner_feature = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>].features[<span class="hljs-string">&quot;ner_tags&quot;</span>]
ner_feature`}}),kt=new A({props:{code:"Sequence(feature=ClassLabel(num_classes=9, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], names_file=None, id=None), length=-1, id=None)",highlighted:'<span class="hljs-type">Sequence</span>(feature=ClassLabel(num_classes=<span class="hljs-number">9</span>, names=[<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-PER&#x27;</span>, <span class="hljs-string">&#x27;I-PER&#x27;</span>, <span class="hljs-string">&#x27;B-ORG&#x27;</span>, <span class="hljs-string">&#x27;I-ORG&#x27;</span>, <span class="hljs-string">&#x27;B-LOC&#x27;</span>, <span class="hljs-string">&#x27;I-LOC&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;I-MISC&#x27;</span>], names_file=<span class="hljs-literal">None</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>), length=-<span class="hljs-number">1</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)'}}),wt=new A({props:{code:`label_names = ner_feature.feature.names
label_names`,highlighted:`label_names = ner_feature.feature.names
label_names`}}),Re=new A({props:{code:"['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']",highlighted:'[<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-PER&#x27;</span>, <span class="hljs-string">&#x27;I-PER&#x27;</span>, <span class="hljs-string">&#x27;B-ORG&#x27;</span>, <span class="hljs-string">&#x27;I-ORG&#x27;</span>, <span class="hljs-string">&#x27;B-LOC&#x27;</span>, <span class="hljs-string">&#x27;I-LOC&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;I-MISC&#x27;</span>]'}}),Za=new A({props:{code:`words = raw_datasets["train"][0]["tokens"]
labels = raw_datasets["train"][0]["ner_tags"]
line1 = ""
line2 = ""
for word, label in zip(words, labels):
    full_label = label_names[label]
    max_length = max(len(word), len(full_label))
    line1 += word + " " * (max_length - len(word) + 1)
    line2 += full_label + " " * (max_length - len(full_label) + 1)

print(line1)
print(line2)`,highlighted:`words = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;tokens&quot;</span>]
labels = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;ner_tags&quot;</span>]
line1 = <span class="hljs-string">&quot;&quot;</span>
line2 = <span class="hljs-string">&quot;&quot;</span>
<span class="hljs-keyword">for</span> word, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(words, labels):
    full_label = label_names[label]
    max_length = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">len</span>(word), <span class="hljs-built_in">len</span>(full_label))
    line1 += word + <span class="hljs-string">&quot; &quot;</span> * (max_length - <span class="hljs-built_in">len</span>(word) + <span class="hljs-number">1</span>)
    line2 += full_label + <span class="hljs-string">&quot; &quot;</span> * (max_length - <span class="hljs-built_in">len</span>(full_label) + <span class="hljs-number">1</span>)

<span class="hljs-built_in">print</span>(line1)
<span class="hljs-built_in">print</span>(line2)`}}),yt=new A({props:{code:`'EU    rejects German call to boycott British lamb .'
'B-ORG O       B-MISC O    O  O       B-MISC  O    O'`,highlighted:`<span class="hljs-string">&#x27;EU    rejects German call to boycott British lamb .&#x27;</span>
<span class="hljs-string">&#x27;B-ORG O       B-MISC O    O  O       B-MISC  O    O&#x27;</span>`}}),Bs=new A({props:{code:`'Germany \\'s representative to the European Union \\'s veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer .'
'B-LOC   O  O              O  O   B-ORG    I-ORG O  O          O         B-PER  I-PER     O    O  O         O         O      O   O         O    O         O     O    B-LOC   O     O   O          O      O   O       O'`,highlighted:`<span class="hljs-string">&#x27;Germany \\&#x27;s representative to the European Union \\&#x27;s veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer .&#x27;</span>
<span class="hljs-string">&#x27;B-LOC   O  O              O  O   B-ORG    I-ORG O  O          O         B-PER  I-PER     O    O  O         O         O      O   O         O    O         O     O    B-LOC   O     O   O          O      O   O       O&#x27;</span>`}}),ca=new Qo({props:{$$slots:{default:[nh]},$$scope:{ctx:X}}}),ma=new it({}),fa=new Gv({props:{id:"iY2AZYdZAr0"}}),ll=new A({props:{code:`from transformers import AutoTokenizer

model_checkpoint = "bert-base-cased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

model_checkpoint = <span class="hljs-string">&quot;bert-base-cased&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)`}}),Bn=new A({props:{code:"tokenizer.is_fast",highlighted:"tokenizer.is_fast"}}),il=new A({props:{code:"True",highlighted:'<span class="hljs-literal">True</span>'}}),js=new A({props:{code:`inputs = tokenizer(raw_datasets["train"][0]["tokens"], is_split_into_words=True)
inputs.tokens()`,highlighted:`inputs = tokenizer(raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;tokens&quot;</span>], is_split_into_words=<span class="hljs-literal">True</span>)
inputs.tokens()`}}),Hn=new A({props:{code:"['[CLS]', 'EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'la', '##mb', '.', '[SEP]']",highlighted:'[<span class="hljs-string">&#x27;[CLS]&#x27;</span>, <span class="hljs-string">&#x27;EU&#x27;</span>, <span class="hljs-string">&#x27;rejects&#x27;</span>, <span class="hljs-string">&#x27;German&#x27;</span>, <span class="hljs-string">&#x27;call&#x27;</span>, <span class="hljs-string">&#x27;to&#x27;</span>, <span class="hljs-string">&#x27;boycott&#x27;</span>, <span class="hljs-string">&#x27;British&#x27;</span>, <span class="hljs-string">&#x27;la&#x27;</span>, <span class="hljs-string">&#x27;##mb&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>]'}}),Kl=new A({props:{code:"inputs.word_ids()",highlighted:"inputs.word_ids()"}}),Yl=new A({props:{code:"[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]",highlighted:'[<span class="hljs-literal">None</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-literal">None</span>]'}}),er=new A({props:{code:`def align_labels_with_tokens(labels, word_ids):
    new_labels = []
    current_word = None
    for word_id in word_ids:
        if word_id != current_word:
            # D\xE9but d'un nouveau mot !
            current_word = word_id
            label = -100 if word_id is None else labels[word_id]
            new_labels.append(label)
        elif word_id is None:
            # Token sp\xE9cial
            new_labels.append(-100)
        else:
            # M\xEAme mot que le token pr\xE9c\xE9dent
            label = labels[word_id]
            # Si l'\xE9tiquette est B-XXX, nous la changeons en I-XXX
            if label % 2 == 1:
                label += 1
            new_labels.append(label)

    return new_labels`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">align_labels_with_tokens</span>(<span class="hljs-params">labels, word_ids</span>):
    new_labels = []
    current_word = <span class="hljs-literal">None</span>
    <span class="hljs-keyword">for</span> word_id <span class="hljs-keyword">in</span> word_ids:
        <span class="hljs-keyword">if</span> word_id != current_word:
            <span class="hljs-comment"># D\xE9but d&#x27;un nouveau mot !</span>
            current_word = word_id
            label = -<span class="hljs-number">100</span> <span class="hljs-keyword">if</span> word_id <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> labels[word_id]
            new_labels.append(label)
        <span class="hljs-keyword">elif</span> word_id <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
            <span class="hljs-comment"># Token sp\xE9cial</span>
            new_labels.append(-<span class="hljs-number">100</span>)
        <span class="hljs-keyword">else</span>:
            <span class="hljs-comment"># M\xEAme mot que le token pr\xE9c\xE9dent</span>
            label = labels[word_id]
            <span class="hljs-comment"># Si l&#x27;\xE9tiquette est B-XXX, nous la changeons en I-XXX</span>
            <span class="hljs-keyword">if</span> label % <span class="hljs-number">2</span> == <span class="hljs-number">1</span>:
                label += <span class="hljs-number">1</span>
            new_labels.append(label)

    <span class="hljs-keyword">return</span> new_labels`}}),xs=new A({props:{code:`labels = raw_datasets["train"][0]["ner_tags"]
word_ids = inputs.word_ids()
print(labels)
print(align_labels_with_tokens(labels, word_ids))`,highlighted:`labels = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;ner_tags&quot;</span>]
word_ids = inputs.word_ids()
<span class="hljs-built_in">print</span>(labels)
<span class="hljs-built_in">print</span>(align_labels_with_tokens(labels, word_ids))`}}),sr=new A({props:{code:`[3, 0, 7, 0, 0, 0, 7, 0, 0]
[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]`,highlighted:`[<span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]
[-<span class="hljs-number">100</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, -<span class="hljs-number">100</span>]`}}),ml=new Qo({props:{$$slots:{default:[ah]},$$scope:{ctx:X}}}),lr=new A({props:{code:`def tokenize_and_align_labels(examples):
    tokenized_inputs = tokenizer(
        examples["tokens"], truncation=True, is_split_into_words=True
    )
    all_labels = examples["ner_tags"]
    new_labels = []
    for i, labels in enumerate(all_labels):
        word_ids = tokenized_inputs.word_ids(i)
        new_labels.append(align_labels_with_tokens(labels, word_ids))

    tokenized_inputs["labels"] = new_labels
    return tokenized_inputs`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_and_align_labels</span>(<span class="hljs-params">examples</span>):
    tokenized_inputs = tokenizer(
        examples[<span class="hljs-string">&quot;tokens&quot;</span>], truncation=<span class="hljs-literal">True</span>, is_split_into_words=<span class="hljs-literal">True</span>
    )
    all_labels = examples[<span class="hljs-string">&quot;ner_tags&quot;</span>]
    new_labels = []
    <span class="hljs-keyword">for</span> i, labels <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(all_labels):
        word_ids = tokenized_inputs.word_ids(i)
        new_labels.append(align_labels_with_tokens(labels, word_ids))

    tokenized_inputs[<span class="hljs-string">&quot;labels&quot;</span>] = new_labels
    <span class="hljs-keyword">return</span> tokenized_inputs`}}),Qi=new A({props:{code:`tokenized_datasets = raw_datasets.map(
    tokenize_and_align_labels,
    batched=True,
    remove_columns=raw_datasets["train"].column_names,
)`,highlighted:`tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(
    tokenize_and_align_labels,
    batched=<span class="hljs-literal">True</span>,
    remove_columns=raw_datasets[<span class="hljs-string">&quot;train&quot;</span>].column_names,
)`}});const Zd=[rh,lh],hu=[];function Kd(t,m){return t[0]==="pt"?0:1}vl=Kd(X),hl=hu[vl]=Zd[vl](X),eu=new it({});const Yd=[ih,oh],_u=[];function Jd(t,m){return t[0]==="pt"?0:1}_l=Jd(X),bl=_u[_l]=Yd[_l](X),tu=new A({props:{code:`batch = data_collator([tokenized_datasets["train"][i] for i in range(2)])
batch["labels"]`,highlighted:`batch = data_collator([tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>][i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>)])
batch[<span class="hljs-string">&quot;labels&quot;</span>]`}}),nu=new A({props:{code:`tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],
        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])`,highlighted:`tensor([[-<span class="hljs-number">100</span>,    <span class="hljs-number">3</span>,    <span class="hljs-number">0</span>,    <span class="hljs-number">7</span>,    <span class="hljs-number">0</span>,    <span class="hljs-number">0</span>,    <span class="hljs-number">0</span>,    <span class="hljs-number">7</span>,    <span class="hljs-number">0</span>,    <span class="hljs-number">0</span>,    <span class="hljs-number">0</span>, -<span class="hljs-number">100</span>],
        [-<span class="hljs-number">100</span>,    <span class="hljs-number">1</span>,    <span class="hljs-number">2</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>]])`}}),au=new A({props:{code:`for i in range(2):
    print(tokenized_datasets["train"][i]["labels"])`,highlighted:`<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>):
    <span class="hljs-built_in">print</span>(tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>][i][<span class="hljs-string">&quot;labels&quot;</span>])`}}),lu=new A({props:{code:`[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]
[-100, 1, 2, -100]`,highlighted:`[-<span class="hljs-number">100</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, -<span class="hljs-number">100</span>]
[-<span class="hljs-number">100</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, -<span class="hljs-number">100</span>]`}});const Qd=[ph,uh],bu=[];function em(t,m){return t[0]==="pt"?0:1}$l=em(X),gl=bu[$l]=Qd[$l](X);let cs=X[0]==="tf"&&Uv(X);ru=new it({});const sm=[fh,mh],$u=[];function tm(t,m){return t[0]==="pt"?0:1}El=tm(X),ql=$u[El]=sm[El](X),ou=new A({props:{code:`import evaluate

metric = evaluate.load("seqeval")`,highlighted:`<span class="hljs-keyword">import</span> evaluate

metric = evaluate.load(<span class="hljs-string">&quot;seqeval&quot;</span>)`}}),iu=new A({props:{code:`labels = raw_datasets["train"][0]["ner_tags"]
labels = [label_names[i] for i in labels]
labels`,highlighted:`labels = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;ner_tags&quot;</span>]
labels = [label_names[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> labels]
labels`}}),uu=new A({props:{code:"['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']",highlighted:'[<span class="hljs-string">&#x27;B-ORG&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>]'}}),pu=new A({props:{code:`predictions = labels.copy()
predictions[2] = "O"
metric.compute(predictions=[predictions], references=[labels])`,highlighted:`predictions = labels.copy()
predictions[<span class="hljs-number">2</span>] = <span class="hljs-string">&quot;O&quot;</span>
metric.compute(predictions=[predictions], references=[labels])`}}),cu=new A({props:{code:`{'MISC': {'precision': 1.0, 'recall': 0.5, 'f1': 0.67, 'number': 2},
 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},
 'overall_precision': 1.0,
 'overall_recall': 0.67,
 'overall_f1': 0.8,
 'overall_accuracy': 0.89}`,highlighted:`{<span class="hljs-string">&#x27;MISC&#x27;</span>: {<span class="hljs-string">&#x27;precision&#x27;</span>: <span class="hljs-number">1.0</span>, <span class="hljs-string">&#x27;recall&#x27;</span>: <span class="hljs-number">0.5</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">0.67</span>, <span class="hljs-string">&#x27;number&#x27;</span>: <span class="hljs-number">2</span>},
 <span class="hljs-string">&#x27;ORG&#x27;</span>: {<span class="hljs-string">&#x27;precision&#x27;</span>: <span class="hljs-number">1.0</span>, <span class="hljs-string">&#x27;recall&#x27;</span>: <span class="hljs-number">1.0</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">1.0</span>, <span class="hljs-string">&#x27;number&#x27;</span>: <span class="hljs-number">1</span>},
 <span class="hljs-string">&#x27;overall_precision&#x27;</span>: <span class="hljs-number">1.0</span>,
 <span class="hljs-string">&#x27;overall_recall&#x27;</span>: <span class="hljs-number">0.67</span>,
 <span class="hljs-string">&#x27;overall_f1&#x27;</span>: <span class="hljs-number">0.8</span>,
 <span class="hljs-string">&#x27;overall_accuracy&#x27;</span>: <span class="hljs-number">0.89</span>}`}});const nm=[hh,vh],gu=[];function am(t,m){return t[0]==="pt"?0:1}kl=am(X),jl=gu[kl]=nm[kl](X);let ds=X[0]==="pt"&&Vv(X);return du=new it({}),mu=new A({props:{code:`from transformers import pipeline

# Remplacez ceci par votre propre checkpoint
model_checkpoint = "huggingface-course/bert-finetuned-ner"
token_classifier = pipeline(
    "token-classification", model=model_checkpoint, aggregation_strategy="simple"
)
token_classifier("My name is Sylvain and I work at Hugging Face in Brooklyn.")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-comment"># Remplacez ceci par votre propre checkpoint</span>
model_checkpoint = <span class="hljs-string">&quot;huggingface-course/bert-finetuned-ner&quot;</span>
token_classifier = pipeline(
    <span class="hljs-string">&quot;token-classification&quot;</span>, model=model_checkpoint, aggregation_strategy=<span class="hljs-string">&quot;simple&quot;</span>
)
token_classifier(<span class="hljs-string">&quot;My name is Sylvain and I work at Hugging Face in Brooklyn.&quot;</span>)`}}),fu=new A({props:{code:`[{'entity_group': 'PER', 'score': 0.9988506, 'word': 'Sylvain', 'start': 11, 'end': 18},
 {'entity_group': 'ORG', 'score': 0.9647625, 'word': 'Hugging Face', 'start': 33, 'end': 45},
 {'entity_group': 'LOC', 'score': 0.9986118, 'word': 'Brooklyn', 'start': 49, 'end': 57}]`,highlighted:`[{<span class="hljs-string">&#x27;entity_group&#x27;</span>: <span class="hljs-string">&#x27;PER&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9988506</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;Sylvain&#x27;</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">11</span>, <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">18</span>},
 {<span class="hljs-string">&#x27;entity_group&#x27;</span>: <span class="hljs-string">&#x27;ORG&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9647625</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;Hugging Face&#x27;</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">33</span>, <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">45</span>},
 {<span class="hljs-string">&#x27;entity_group&#x27;</span>: <span class="hljs-string">&#x27;LOC&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9986118</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;Brooklyn&#x27;</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">49</span>, <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">57</span>}]`}}),{c(){p=l("meta"),g=c(),j(v.$$.fragment),q=c(),z=l("h1"),E=l("a"),k=l("span"),j(P.$$.fragment),y=c(),O=l("span"),H=n("Classification de "),I=l("i"),L=n("tokens"),F=c(),U.c(),W=c(),D=l("p"),M=n("La premi\xE8re application que nous allons explorer est la classification de "),V=l("em"),Y=n("tokens"),se=n(". Cette t\xE2che g\xE9n\xE9rique englobe tous les probl\xE8mes qui peuvent \xEAtre formul\xE9s comme l\u2019attribution d\u2019une \xE9tiquette \xE0 chaque "),N=l("em"),G=n("token"),te=n(" d\u2019une phrase, tels que :"),J=c(),ee=l("ul"),R=l("li"),K=n("la "),de=l("strong"),Pe=n("reconnaissance d\u2019entit\xE9s nomm\xE9es (NER de l\u2019anglais "),he=l("em"),B=n("Named Entity Recognition"),le=n(")"),Q=n(", c\u2019est-\xE0-dire trouver les entit\xE9s (telles que des personnes, des lieux ou des organisations) dans une phrase. Ce t\xE2che peut \xEAtre formul\xE9e comme l\u2019attribution d\u2019une \xE9tiquette \xE0 chaque "),oe=l("em"),Z=n("token"),pe=n(" faisant parti d\u2019une entit\xE9 en ayant une classe sp\xE9cifique par entit\xE9, et une classe pour les "),Qe=l("em"),_e=n("tokens"),ge=n(" ne faisant pas parti d\u2019entit\xE9."),ys=c(),Ce=l("li"),De=n("le "),es=l("strong"),ae=l("em"),ms=n("part-of-speech tagging"),fs=n(" (POS)"),Mt=n(", c\u2019est-\xE0-dire marquer chaque mot dans une phrase comme correspondant \xE0 une partie particuli\xE8re (comme un nom, un verbe, un adjectif, etc.)."),qa=c(),ne=l("li"),ka=n("le "),dn=l("strong"),zs=l("em"),ja=n("chunking"),wa=n(", c\u2019est-\xE0-dire trouver les "),ut=l("em"),ss=n("tokens"),mn=n(" qui appartiennent \xE0 la m\xEAme entit\xE9. Cette t\xE2che (qui peut \xEAtre combin\xE9e avec le POS ou la NER) peut \xEAtre formul\xE9e comme l\u2019attribution d\u2019une \xE9tiquette (habituellement "),Se=l("code"),fn=n("B-"),ts=n(") \xE0 tous les "),pt=l("em"),ye=n("tokens"),Le=n(" qui sont au d\xE9but d\u2019un morceau, une autre \xE9tiquette (habituellement "),Os=l("code"),ns=n("I-"),xa=n(") aux "),as=l("em"),ct=n("tokens"),Ca=n(" qui sont \xE0 l\u2019int\xE9rieur d\u2019un morceau, et une troisi\xE8me \xE9tiquette (habituellement "),vn=l("code"),hn=n("O"),ze=n(") aux "),_n=l("em"),dt=n("tokens"),ya=n(" qui n\u2019appartiennent \xE0 aucun morceau."),Un=c(),j(vs.$$.fragment),Ws=c(),ls=l("p"),Ps=n("Bien s\xFBr, il existe de nombreux autres types de probl\xE8mes de classification de "),Ds=l("em"),At=n("tokens"),Xs=n(". Ce ne sont l\xE0 que quelques exemples repr\xE9sentatifs. Dans cette section, nous allons "),bn=l("em"),Nt=n("finetuner"),Zs=n(" un mod\xE8le (BERT) sur la t\xE2che de NER. Il sera alors capable de calculer des pr\xE9dictions comme celle-ci :"),Vn=c(),Ee=l("iframe"),Wn=c(),qe=l("iframe"),$n=c(),ie=l("a"),rs=l("img"),Ks=c(),ft=l("img"),Xn=c(),Ys=l("p"),Lt=n("Vous pouvez trouver, t\xE9l\xE9charger et v\xE9rifier les pr\xE9cisions de ce mod\xE8le sur le "),os=l("a"),It=l("em"),me=n("Hub"),za=n(" les pr\xE9dictions du mod\xE8le que nous allons entra\xEEner."),Ft=c(),hs=l("h2"),Ve=l("a"),Js=l("span"),j(Me.$$.fragment),Oa=c(),Ms=l("span"),Pa=n("Pr\xE9paration des donn\xE9es"),Zn=c(),ke=l("p"),En=n("Tout d\u2019abord, nous avons besoin d\u2019un jeu de donn\xE9es adapt\xE9 \xE0 la classification des "),qn=l("em"),Kn=n("tokens"),Ae=n(". Dans cette section, nous utiliserons le jeu de donn\xE9es "),vt=l("a"),kn=n("CoNLL-2003"),jn=n(", qui contient des articles de presse de Reuters."),Yn=c(),j(_s.$$.fragment),wn=c(),Ie=l("h3"),is=l("a"),bs=l("span"),j(ht.$$.fragment),Rt=c(),As=l("span"),Jn=n("Le jeu de donn\xE9es CoNLL-2003"),je=c(),Ne=l("p"),Bt=n("Pour charger le jeu de donn\xE9es CoNLL-2003, nous utilisons la m\xE9thode "),$s=l("code"),Da=n("load_dataset()"),Ns=n(" de la biblioth\xE8que \u{1F917} "),_t=l("em"),Ma=n("Datasets"),Qn=n(" :"),us=c(),j(bt.$$.fragment),Ht=c(),gs=l("p"),Aa=n("Cela va t\xE9l\xE9charger et mettre en cache le jeu de donn\xE9es, comme nous l\u2019avons vu dans "),$t=l("a"),Qs=n("chapitre 3"),et=n(" pour le jeu de donn\xE9es GLUE MRPC. L\u2019inspection de cet objet nous montre les colonnes pr\xE9sentes dans ce jeu de donn\xE9es et la r\xE9partition entre les ensembles d\u2019entra\xEEnement, de validation et de test :"),st=c(),j(We.$$.fragment),xn=c(),j(Fe.$$.fragment),Cn=c(),re=l("p"),ea=n("En particulier, nous pouvons voir que le jeu de donn\xE9es contient des \xE9tiquettes pour les trois t\xE2ches que nous avons mentionn\xE9es pr\xE9c\xE9demment : NER, POS et "),$e=l("em"),Na=n("chunking"),yn=n(". Une grande diff\xE9rence avec les autres jeux de donn\xE9es est que les entr\xE9es textuelles ne sont pas pr\xE9sent\xE9s comme des phrases ou des documents, mais comme des listes de mots (la derni\xE8re colonne est appel\xE9e "),gt=l("code"),Ta=n("tokens"),zn=n(", mais elle contient des mots dans le sens o\xF9 ce sont des entr\xE9es pr\xE9tok\xE9nis\xE9es qui doivent encore passer par le "),Et=l("em"),Sa=n("tokenizer"),On=n(" pour la tokenisation en sous-mots)."),Gt=c(),Ut=l("p"),Pn=n("Regardons le premier \xE9l\xE9ment de l\u2019ensemble d\u2019entra\xEEnement :"),Dn=c(),j(Xe.$$.fragment),Mn=c(),j(f.$$.fragment),S=c(),An=l("p"),La=n("Puisque nous voulons effectuer reconna\xEEtre des entit\xE9s nomm\xE9es, nous allons examiner les balises NER :"),Ts=c(),j(be.$$.fragment),Nn=c(),j(Es.$$.fragment),Ia=c(),Ss=l("p"),Vt=n("Ce sont les \xE9tiquettes sous forme d\u2019entiers disponibles pour l\u2019entra\xEEnement mais ne sont pas n\xE9cessairement utiles lorsque nous voulons inspecter les donn\xE9es. Comme pour la classification de texte, nous pouvons acc\xE9der \xE0 la correspondance entre ces entiers et les noms des \xE9tiquettes en regardant l\u2019attribut "),Tn=l("code"),qt=n("features"),Wt=n(" de notre jeu de donn\xE9es :"),Xt=c(),j(Zt.$$.fragment),Ls=c(),j(kt.$$.fragment),Is=c(),fe=l("p"),Kt=n("Cette colonne contient donc des \xE9l\xE9ments qui sont des s\xE9quences de "),tt=l("code"),wl=n("ClassLabel"),Sn=n(". Le type des \xE9l\xE9ments de la s\xE9quence se trouve dans l\u2019attribut "),sa=l("code"),Ln=n("feature"),ps=n(" de cette "),Yt=l("code"),ta=n("ner_feature"),na=n(", et nous pouvons acc\xE9der \xE0 la liste des noms en regardant l\u2019attribut "),aa=l("code"),Ze=n("names"),xl=n(" de cette "),la=l("code"),ra=n("feature"),Cl=n(" :"),jt=c(),j(wt.$$.fragment),xt=c(),j(Re.$$.fragment),nt=c(),Fs=l("p"),oa=n("Nous avons d\xE9j\xE0 vu ces \xE9tiquettes au "),Be=l("a"),yl=n("chapitre 6"),Fa=n(" lorsque nous nous sommes int\xE9ress\xE9s au pipeline "),at=l("code"),Ra=n("token-classification"),Rs=n(" mais nosu pouvons tout de m\xEAme faire un rapide rappel :"),In=c(),Oe=l("ul"),He=l("li"),ia=l("code"),ua=n("O"),zl=n(" signifie que le mot ne correspond \xE0 aucune entit\xE9."),Ol=c(),Ct=l("li"),Fn=l("code"),Jr=n("B-PER"),pa=n("/"),mr=l("code"),fr=n("I-PER"),ei=n(" signifie que le mot correspond au d\xE9but/est \xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),vr=l("em"),Qr=n("personne"),Ba=n("."),eo=c(),qs=l("li"),Pl=l("code"),lt=n("B-ORG"),si=n("/"),Ha=l("code"),ti=n("I-ORG"),ni=n(" signifie que le mot correspond au d\xE9but/est \xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),Ga=l("em"),ai=n("organisation"),li=n("."),hr=c(),Jt=l("li"),_r=l("code"),so=n("B-LOC"),Ua=n("/"),Dl=l("code"),ks=n("I-LOC"),ri=n(" signifie que le mot correspond au d\xE9but/est \xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),Va=l("em"),oi=n("location"),ii=n("."),br=c(),Qt=l("li"),$r=l("code"),gr=n("B-MISC"),ui=n("/"),Er=l("code"),qr=n("I-MISC"),pi=n(" signifie que le mot correspond au d\xE9but/est \xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),kr=l("em"),to=n("divers"),Wa=n("."),jr=c(),en=l("p"),no=n("Maintenant, le d\xE9codage des \xE9tiquettes que nous avons vues pr\xE9c\xE9demment nous donne ceci :"),Xa=c(),j(Za.$$.fragment),wr=c(),j(yt.$$.fragment),xr=c(),Ge=l("p"),ci=n("Et pour un exemple m\xE9langeant les \xE9tiquettes "),Ka=l("code"),di=n("B-"),mi=n(" et "),Ya=l("code"),fi=n("I-"),vi=n(", voici ce que le m\xEAme code nous donne sur le quatri\xE8me \xE9l\xE9ment du jeu d\u2019entra\xEEnement :"),Cr=c(),j(Bs.$$.fragment),Rn=c(),rt=l("p"),Ja=n("Comme on peut le voir, les entit\xE9s couvrant deux mots, comme \xAB European Union \xBB et \xAB Werner Zwingmann \xBB, se voient attribuer une \xE9tiquette "),yr=l("code"),zr=n("B-"),hi=n(" pour le premier mot et une \xE9tiquette "),Ml=l("code"),sn=n("I-"),_i=n(" pour le second."),Al=c(),j(ca.$$.fragment),ao=c(),zt=l("h3"),da=l("a"),Or=l("span"),j(ma.$$.fragment),Qa=c(),Nl=l("span"),Tl=n("Traitement des donn\xE9es"),lo=c(),j(fa.$$.fragment),Ot=c(),we=l("p"),bi=n("Comme d\u2019habitude, nos textes doivent \xEAtre convertis en identifiants de "),el=l("em"),$i=n("tokens"),gi=n(" avant que le mod\xE8le puisse leur donner un sens. Comme nous l\u2019avons vu au "),Sl=l("a"),Hs=n("chapitre 6"),Ei=n(", une grande diff\xE9rence dans le cas des t\xE2ches de classification de "),sl=l("em"),qi=n("tokens"),ki=n(" est que nous avons des entr\xE9es pr\xE9tok\xE9nis\xE9es. Heureusement, l\u2019API "),tl=l("code"),ji=n("tokenizer"),wi=n(" peut g\xE9rer cela assez facilement. Nous devons juste avertir le "),nl=l("code"),xi=n("tokenizer"),Ci=n(" avec un drapeau sp\xE9cial."),Ll=c(),tn=l("p"),yi=n("Pour commencer, nous allons cr\xE9er notre objet "),Pr=l("code"),Gs=n("tokenizer"),zi=n(". Comme nous l\u2019avons dit pr\xE9c\xE9demment, nous allons utiliser un mod\xE8le BERT pr\xE9-entra\xEEn\xE9, donc nous allons commencer par t\xE9l\xE9charger et mettre en cache le "),al=l("em"),Oi=n("tokenizer"),Pi=n(" associ\xE9 :"),Il=c(),j(ll.$$.fragment),ro=c(),ue=l("p"),Di=n("Vous pouvez remplacer le "),Dr=l("code"),Mr=n("model_checkpoint"),Mi=n(" par tout autre mod\xE8le que vous pr\xE9f\xE9rez \xE0 partir du "),rl=l("a"),Fl=l("em"),Rl=n("Hub"),Ai=n(", ou par un dossier local dans lequel vous avez sauvegard\xE9 un mod\xE8le pr\xE9-entra\xEEn\xE9 et un "),Bl=l("em"),ol=n("tokenizer"),oo=n(". La seule contrainte est que le "),nn=l("em"),Ni=n("tokenizer"),Ar=n(" doit \xEAtre soutenu par la biblioth\xE8que \u{1F917} "),Nr=l("em"),Ti=n("Tokenizers"),io=n(". Il y a donc une version rapide disponible. Vous pouvez voir toutes les architectures qui ont une version rapide dans "),Pt=l("a"),uo=n("ce tableau"),xe=n(", et pour v\xE9rifier que l\u2019objet "),Tr=l("code"),Sr=n("tokenizer"),Si=n(" que vous utilisez est bien soutenu par \u{1F917} "),Lr=l("em"),Ir=n("Tokenizers"),Li=n(" vous pouvez regarder son attribut "),Fr=l("code"),Rr=n("is_fast"),Ii=n(" :"),po=c(),j(Bn.$$.fragment),co=c(),j(il.$$.fragment),Hl=c(),an=l("p"),Fi=n("Pour tokeniser une entr\xE9e pr\xE9tokenis\xE9e, nous pouvons utiliser notre "),ul=l("code"),Ri=n("tokenizer"),Bi=n(" comme d\u2019habitude et juste ajouter "),pl=l("code"),Hi=n("is_split_into_words=True"),Gi=n(" :"),Br=c(),j(js.$$.fragment),mo=c(),j(Hn.$$.fragment),fo=c(),ve=l("p"),cl=n("Comme on peut le voir, le "),dl=l("em"),Ui=n("tokenizer"),Vi=n(" a ajout\xE9 les "),Gl=l("em"),i=n("tokens"),h=n(" sp\xE9ciaux utilis\xE9s par le mod\xE8le ("),vo=l("code"),xu=n("[CLS]"),Cu=n(" au d\xE9but et "),ot=l("code"),yu=n("[SEP]"),zu=n(" \xE0 la fin) et n\u2019a pas touch\xE9 \xE0 la plupart des mots. Le mot "),ho=l("code"),Ou=n("lamb"),Ul=n(", cependant, a \xE9t\xE9 tokenis\xE9 en deux sous-mots, "),_o=l("code"),Pu=n("la"),Vl=n(" et "),bo=l("code"),Du=n("##mb"),va=n(". Cela introduit un d\xE9calage entre nos entr\xE9es et les \xE9tiquettes : la liste des \xE9tiquettes n\u2019a que 9 \xE9l\xE9ments, alors que notre entr\xE9e a maintenant 12 "),$o=l("em"),Mu=n("tokens"),Au=n(". Il est facile de tenir compte des "),Wl=l("em"),Nu=n("tokens"),Tu=n(" sp\xE9ciaux (nous savons qu\u2019ils sont au d\xE9but et \xE0 la fin), mais nous devons \xE9galement nous assurer que nous alignons toutes les \xE9tiquettes avec les mots appropri\xE9s."),go=c(),Us=l("p"),Xl=n("Heureusement, comme nous utilisons un "),Eo=l("em"),Su=n("tokenizer"),qo=n(" rapide, nous avons acc\xE8s aux superpouvoirs des \u{1F917} "),ko=l("em"),jo=n("Tokenizers"),Lu=n(", ce qui signifie que nous pouvons facilement faire correspondre chaque "),Zl=l("em"),Iu=n("token"),ws=n(" au mot correspondant (comme on le voit au "),Hr=l("a"),Fu=n("chapitre 6"),Ru=n(") :"),Wi=c(),j(Kl.$$.fragment),Xi=c(),j(Yl.$$.fragment),Gr=c(),ce=l("p"),wo=n("Avec un peu de travail, nous pouvons \xE9tendre notre liste d\u2019\xE9tiquettes pour qu\u2019elle corresponde aux "),xo=l("em"),Co=n("tokens"),Bu=n(". La premi\xE8re r\xE8gle que nous allons appliquer est que les "),yo=l("em"),ln=n("tokens"),Hu=n(" sp\xE9ciaux re\xE7oivent une \xE9tiquette de "),zo=l("code"),Gu=n("-100"),Uu=n(". En effet, par d\xE9faut, "),Jl=l("code"),Vu=n("-100"),Oo=n(" est un indice qui est ignor\xE9 dans la fonction de perte que nous allons utiliser (l\u2019entropie crois\xE9e). Ensuite, chaque "),Po=l("em"),Wu=n("token"),Xu=n(" re\xE7oit la m\xEAme \xE9tiquette que le "),Ql=l("em"),Zu=n("token"),Do=n(" qui a commenc\xE9 le mot dans lequel il se trouve puisqu\u2019ils font partie de la m\xEAme entit\xE9. Pour les "),Mo=l("em"),Ku=n("tokens"),Yu=n(" \xE0 l\u2019int\xE9rieur d\u2019un mot mais pas au d\xE9but, nous rempla\xE7ons le "),rn=l("code"),Ju=n("B-"),Qu=n(" par "),Ao=l("code"),No=n("I-"),ep=n(" (puisque le "),ha=l("em"),sp=n("token"),tp=n(" ne commence pas l\u2019entit\xE9) :"),Ur=c(),j(er.$$.fragment),Gn=c(),Vr=l("p"),np=n("Essayons-le sur notre premi\xE8re phrase :"),Zi=c(),j(xs.$$.fragment),Ki=c(),j(sr.$$.fragment),Yi=c(),Vs=l("p"),ap=n("Comme nous pouvons le voir, notre fonction a ajout\xE9 "),_a=l("code"),lp=n("-100"),rp=n(" pour les deux "),tr=l("em"),op=n("tokens"),ip=n(" sp\xE9ciaux du d\xE9but et de fin, et un nouveau "),To=l("code"),nr=n("0"),up=n(" pour notre mot qui a \xE9t\xE9 divis\xE9 en deux "),So=l("em"),pp=n("tokens"),ar=n("."),Wr=c(),j(ml.$$.fragment),Dt=c(),Ue=l("p"),cp=n("Pour pr\xE9traiter notre jeu de donn\xE9es, nous devons tokeniser toutes les entr\xE9es et appliquer "),Lo=l("code"),dp=n("align_labels_with_tokens()"),on=n(" sur toutes les \xE9tiquettes. Pour profiter de la vitesse de notre "),Io=l("em"),mp=n("tokenizer"),fp=n(" rapide, il est pr\xE9f\xE9rable de tokeniser beaucoup de textes en m\xEAme temps. Nous allons donc \xE9crire une fonction qui traite une liste d\u2019exemples et utiliser la m\xE9thode "),Fo=l("code"),vp=n("Dataset.map()"),Ro=n(" avec l\u2019option "),Bo=l("code"),Ke=n("batched=True"),hp=n(". La seule chose qui diff\xE8re de notre exemple pr\xE9c\xE9dent est que la fonction "),Ho=l("code"),_p=n("word_ids()"),bp=n(" a besoin de r\xE9cup\xE9rer l\u2019index de l\u2019exemple dont nous voulons les identifiants de mots lorsque les entr\xE9es du "),Go=l("em"),$p=n("tokenizer"),gp=n(" sont des listes de textes (ou dans notre cas, des listes de mots), donc nous l\u2019ajoutons aussi :"),fl=c(),j(lr.$$.fragment),Ji=c(),Xr=l("p"),sd=n("Notez que nous n\u2019avons pas encore rembourr\xE9 nos entr\xE9es. Nous le ferons plus tard lors de la cr\xE9ation des batchs avec un assembleur de donn\xE9es."),fc=c(),Ep=l("p"),td=n("Nous pouvons maintenant appliquer tout ce pr\xE9traitement en une seule fois sur les autres divisions de notre jeu de donn\xE9es :"),vc=c(),j(Qi.$$.fragment),hc=c(),Uo=l("p"),nd=n("Nous avons fait la partie la plus difficile ! Maintenant que les donn\xE9es ont \xE9t\xE9 pr\xE9trait\xE9es, l\u2019entra\xEEnement ressemblera beaucoup \xE0 ce que nous avons fait dans le "),qp=l("a"),ad=n("chapitre 3"),ld=n("."),_c=c(),hl.c(),kp=c(),Zr=l("h3"),Vo=l("a"),Kp=l("span"),j(eu.$$.fragment),rd=c(),Yp=l("span"),od=n("Assemblage des donn\xE9es"),bc=c(),un=l("p"),id=n("Nous ne pouvons pas simplement utiliser un "),Jp=l("code"),ud=n("DataCollatorWithPadding"),pd=n(" comme dans le "),jp=l("a"),cd=n("chapitre 3"),dd=n(" car cela ne fait que rembourrer les entr\xE9es (identifiants d\u2019entr\xE9e, masque d\u2019attention et "),Qp=l("em"),md=n("token"),fd=n(" de type identifiants). Ici, nos \xE9tiquettes doivent \xEAtre rembourr\xE9\xE9s exactement de la m\xEAme mani\xE8re que les entr\xE9es afin qu\u2019elles gardent la m\xEAme taille, en utilisant "),ec=l("code"),vd=n("-100"),hd=n(" comme valeur afin que les pr\xE9dictions correspondantes soient ignor\xE9es dans le calcul de la perte."),$c=c(),ba=l("p"),_d=n("Tout ceci est fait par un "),su=l("a"),sc=l("code"),bd=n("DataCollatorForTokenClassification"),$d=n(". Comme le "),tc=l("code"),gd=n("DataCollatorWithPadding"),Ed=n(", il prend le "),nc=l("code"),qd=n("tokenizer"),kd=n(" utilis\xE9 pour pr\xE9traiter les entr\xE9es :"),gc=c(),bl.c(),wp=c(),xp=l("p"),jd=n("Pour tester cette fonction sur quelques \xE9chantillons, nous pouvons simplement l\u2019appeler sur une liste d\u2019exemples provenant de notre jeu d\u2019entra\xEEnement tok\xE9nis\xE9 :"),Ec=c(),j(tu.$$.fragment),qc=c(),j(nu.$$.fragment),kc=c(),Cp=l("p"),wd=n("Comparons cela aux \xE9tiquettes des premier et deuxi\xE8me \xE9l\xE9ments de notre jeu de donn\xE9es :"),jc=c(),j(au.$$.fragment),wc=c(),j(lu.$$.fragment),xc=c(),gl.c(),yp=c(),cs&&cs.c(),zp=c(),Kr=l("h3"),Wo=l("a"),ac=l("span"),j(ru.$$.fragment),xd=c(),lc=l("span"),Cd=n("M\xE9triques"),Cc=c(),ql.c(),Op=c(),j(ou.$$.fragment),yc=c(),Pp=l("p"),yd=n("Cette m\xE9trique ne se comporte pas comme la pr\xE9cision standard : elle prend les listes d\u2019\xE9tiquettes comme des cha\xEEnes de caract\xE8res et non comme des entiers. Nous devrons donc d\xE9coder compl\xE8tement les pr\xE9dictions et les \xE9tiquettes avant de les transmettre \xE0 la m\xE9trique. Voyons comment cela fonctionne. Tout d\u2019abord, nous allons obtenir les \xE9tiquettes pour notre premier exemple d\u2019entra\xEEnement :"),zc=c(),j(iu.$$.fragment),Oc=c(),j(uu.$$.fragment),Pc=c(),Dp=l("p"),zd=n("Nous pouvons alors cr\xE9er de fausses pr\xE9dictions pour celles-ci en changeant simplement la valeur de l\u2019indice 2 :"),Dc=c(),j(pu.$$.fragment),Mc=c(),Mp=l("p"),Od=n("Notez que la m\xE9trique prend une liste de pr\xE9dictions (pas seulement une) et une liste d\u2019\xE9tiquettes. Voici la sortie :"),Ac=c(),j(cu.$$.fragment),Nc=c(),jl.c(),Ap=c(),ds&&ds.c(),Np=c(),Yr=l("h3"),Xo=l("a"),rc=l("span"),j(du.$$.fragment),Pd=c(),Tp=l("span"),Dd=n("Utilisation du mod\xE8le "),oc=l("i"),Md=n("finetun\xE9"),Tc=c(),pn=l("p"),Ad=n("Nous vous avons d\xE9j\xE0 montr\xE9 comment vous pouvez utiliser le mod\xE8le "),ic=l("em"),Nd=n("finetun\xE9"),Td=n(" sur le "),uc=l("em"),Sd=n("Hub"),Ld=n(" avec le "),pc=l("em"),Id=n("widget"),Fd=n(" d\u2019inf\xE9rence. Pour l\u2019utiliser localement dans un "),cc=l("code"),Rd=n("pipeline"),Bd=n(", vous devez juste sp\xE9cifier l\u2019identifiant de mod\xE8le appropri\xE9 :"),Sc=c(),j(mu.$$.fragment),Lc=c(),j(fu.$$.fragment),Ic=c(),Sp=l("p"),Hd=n("Super ! Notre mod\xE8le fonctionne aussi bien que le mod\xE8le par d\xE9faut pour ce pipeline !"),this.h()},l(t){const m=Yv('[data-svelte="svelte-1phssyn"]',document.head);p=r(m,"META",{name:!0,content:!0}),m.forEach(s),g=d(t),w(v.$$.fragment,t),q=d(t),z=r(t,"H1",{class:!0});var Eu=o(z);E=r(Eu,"A",{id:!0,class:!0,href:!0});var Lp=o(E);k=r(Lp,"SPAN",{});var dc=o(k);w(P.$$.fragment,dc),dc.forEach(s),Lp.forEach(s),y=d(Eu),O=r(Eu,"SPAN",{});var Ip=o(O);H=a(Ip,"Classification de "),I=r(Ip,"I",{});var mc=o(I);L=a(mc,"tokens"),mc.forEach(s),Ip.forEach(s),Eu.forEach(s),F=d(t),U.l(t),W=d(t),D=r(t,"P",{});var rr=o(D);M=a(rr,"La premi\xE8re application que nous allons explorer est la classification de "),V=r(rr,"EM",{});var Fp=o(V);Y=a(Fp,"tokens"),Fp.forEach(s),se=a(rr,". Cette t\xE2che g\xE9n\xE9rique englobe tous les probl\xE8mes qui peuvent \xEAtre formul\xE9s comme l\u2019attribution d\u2019une \xE9tiquette \xE0 chaque "),N=r(rr,"EM",{});var Rp=o(N);G=a(Rp,"token"),Rp.forEach(s),te=a(rr," d\u2019une phrase, tels que :"),rr.forEach(s),J=d(t),ee=r(t,"UL",{});var or=o(ee);R=r(or,"LI",{});var $a=o(R);K=a($a,"la "),de=r($a,"STRONG",{});var Rc=o(de);Pe=a(Rc,"reconnaissance d\u2019entit\xE9s nomm\xE9es (NER de l\u2019anglais "),he=r(Rc,"EM",{});var lm=o(he);B=a(lm,"Named Entity Recognition"),lm.forEach(s),le=a(Rc,")"),Rc.forEach(s),Q=a($a,", c\u2019est-\xE0-dire trouver les entit\xE9s (telles que des personnes, des lieux ou des organisations) dans une phrase. Ce t\xE2che peut \xEAtre formul\xE9e comme l\u2019attribution d\u2019une \xE9tiquette \xE0 chaque "),oe=r($a,"EM",{});var rm=o(oe);Z=a(rm,"token"),rm.forEach(s),pe=a($a," faisant parti d\u2019une entit\xE9 en ayant une classe sp\xE9cifique par entit\xE9, et une classe pour les "),Qe=r($a,"EM",{});var om=o(Qe);_e=a(om,"tokens"),om.forEach(s),ge=a($a," ne faisant pas parti d\u2019entit\xE9."),$a.forEach(s),ys=d(or),Ce=r(or,"LI",{});var Bc=o(Ce);De=a(Bc,"le "),es=r(Bc,"STRONG",{});var Gd=o(es);ae=r(Gd,"EM",{});var im=o(ae);ms=a(im,"part-of-speech tagging"),im.forEach(s),fs=a(Gd," (POS)"),Gd.forEach(s),Mt=a(Bc,", c\u2019est-\xE0-dire marquer chaque mot dans une phrase comme correspondant \xE0 une partie particuli\xE8re (comme un nom, un verbe, un adjectif, etc.)."),Bc.forEach(s),qa=d(or),ne=r(or,"LI",{});var Cs=o(ne);ka=a(Cs,"le "),dn=r(Cs,"STRONG",{});var um=o(dn);zs=r(um,"EM",{});var pm=o(zs);ja=a(pm,"chunking"),pm.forEach(s),um.forEach(s),wa=a(Cs,", c\u2019est-\xE0-dire trouver les "),ut=r(Cs,"EM",{});var cm=o(ut);ss=a(cm,"tokens"),cm.forEach(s),mn=a(Cs," qui appartiennent \xE0 la m\xEAme entit\xE9. Cette t\xE2che (qui peut \xEAtre combin\xE9e avec le POS ou la NER) peut \xEAtre formul\xE9e comme l\u2019attribution d\u2019une \xE9tiquette (habituellement "),Se=r(Cs,"CODE",{});var dm=o(Se);fn=a(dm,"B-"),dm.forEach(s),ts=a(Cs,") \xE0 tous les "),pt=r(Cs,"EM",{});var mm=o(pt);ye=a(mm,"tokens"),mm.forEach(s),Le=a(Cs," qui sont au d\xE9but d\u2019un morceau, une autre \xE9tiquette (habituellement "),Os=r(Cs,"CODE",{});var fm=o(Os);ns=a(fm,"I-"),fm.forEach(s),xa=a(Cs,") aux "),as=r(Cs,"EM",{});var vm=o(as);ct=a(vm,"tokens"),vm.forEach(s),Ca=a(Cs," qui sont \xE0 l\u2019int\xE9rieur d\u2019un morceau, et une troisi\xE8me \xE9tiquette (habituellement "),vn=r(Cs,"CODE",{});var hm=o(vn);hn=a(hm,"O"),hm.forEach(s),ze=a(Cs,") aux "),_n=r(Cs,"EM",{});var _m=o(_n);dt=a(_m,"tokens"),_m.forEach(s),ya=a(Cs," qui n\u2019appartiennent \xE0 aucun morceau."),Cs.forEach(s),or.forEach(s),Un=d(t),w(vs.$$.fragment,t),Ws=d(t),ls=r(t,"P",{});var Bp=o(ls);Ps=a(Bp,"Bien s\xFBr, il existe de nombreux autres types de probl\xE8mes de classification de "),Ds=r(Bp,"EM",{});var bm=o(Ds);At=a(bm,"tokens"),bm.forEach(s),Xs=a(Bp,". Ce ne sont l\xE0 que quelques exemples repr\xE9sentatifs. Dans cette section, nous allons "),bn=r(Bp,"EM",{});var $m=o(bn);Nt=a($m,"finetuner"),$m.forEach(s),Zs=a(Bp," un mod\xE8le (BERT) sur la t\xE2che de NER. Il sera alors capable de calculer des pr\xE9dictions comme celle-ci :"),Bp.forEach(s),Vn=d(t),Ee=r(t,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),o(Ee).forEach(s),Wn=d(t),qe=r(t,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),o(qe).forEach(s),$n=d(t),ie=r(t,"A",{class:!0,href:!0});var Hc=o(ie);rs=r(Hc,"IMG",{class:!0,src:!0,alt:!0}),Ks=d(Hc),ft=r(Hc,"IMG",{class:!0,src:!0,alt:!0}),Hc.forEach(s),Xn=d(t),Ys=r(t,"P",{});var Gc=o(Ys);Lt=a(Gc,"Vous pouvez trouver, t\xE9l\xE9charger et v\xE9rifier les pr\xE9cisions de ce mod\xE8le sur le "),os=r(Gc,"A",{href:!0,rel:!0});var gm=o(os);It=r(gm,"EM",{});var Em=o(It);me=a(Em,"Hub"),Em.forEach(s),gm.forEach(s),za=a(Gc," les pr\xE9dictions du mod\xE8le que nous allons entra\xEEner."),Gc.forEach(s),Ft=d(t),hs=r(t,"H2",{class:!0});var Uc=o(hs);Ve=r(Uc,"A",{id:!0,class:!0,href:!0});var qm=o(Ve);Js=r(qm,"SPAN",{});var km=o(Js);w(Me.$$.fragment,km),km.forEach(s),qm.forEach(s),Oa=d(Uc),Ms=r(Uc,"SPAN",{});var jm=o(Ms);Pa=a(jm,"Pr\xE9paration des donn\xE9es"),jm.forEach(s),Uc.forEach(s),Zn=d(t),ke=r(t,"P",{});var Hp=o(ke);En=a(Hp,"Tout d\u2019abord, nous avons besoin d\u2019un jeu de donn\xE9es adapt\xE9 \xE0 la classification des "),qn=r(Hp,"EM",{});var wm=o(qn);Kn=a(wm,"tokens"),wm.forEach(s),Ae=a(Hp,". Dans cette section, nous utiliserons le jeu de donn\xE9es "),vt=r(Hp,"A",{href:!0,rel:!0});var xm=o(vt);kn=a(xm,"CoNLL-2003"),xm.forEach(s),jn=a(Hp,", qui contient des articles de presse de Reuters."),Hp.forEach(s),Yn=d(t),w(_s.$$.fragment,t),wn=d(t),Ie=r(t,"H3",{class:!0});var Vc=o(Ie);is=r(Vc,"A",{id:!0,class:!0,href:!0});var Cm=o(is);bs=r(Cm,"SPAN",{});var ym=o(bs);w(ht.$$.fragment,ym),ym.forEach(s),Cm.forEach(s),Rt=d(Vc),As=r(Vc,"SPAN",{});var zm=o(As);Jn=a(zm,"Le jeu de donn\xE9es CoNLL-2003"),zm.forEach(s),Vc.forEach(s),je=d(t),Ne=r(t,"P",{});var Gp=o(Ne);Bt=a(Gp,"Pour charger le jeu de donn\xE9es CoNLL-2003, nous utilisons la m\xE9thode "),$s=r(Gp,"CODE",{});var Om=o($s);Da=a(Om,"load_dataset()"),Om.forEach(s),Ns=a(Gp," de la biblioth\xE8que \u{1F917} "),_t=r(Gp,"EM",{});var Pm=o(_t);Ma=a(Pm,"Datasets"),Pm.forEach(s),Qn=a(Gp," :"),Gp.forEach(s),us=d(t),w(bt.$$.fragment,t),Ht=d(t),gs=r(t,"P",{});var Wc=o(gs);Aa=a(Wc,"Cela va t\xE9l\xE9charger et mettre en cache le jeu de donn\xE9es, comme nous l\u2019avons vu dans "),$t=r(Wc,"A",{href:!0});var Dm=o($t);Qs=a(Dm,"chapitre 3"),Dm.forEach(s),et=a(Wc," pour le jeu de donn\xE9es GLUE MRPC. L\u2019inspection de cet objet nous montre les colonnes pr\xE9sentes dans ce jeu de donn\xE9es et la r\xE9partition entre les ensembles d\u2019entra\xEEnement, de validation et de test :"),Wc.forEach(s),st=d(t),w(We.$$.fragment,t),xn=d(t),w(Fe.$$.fragment,t),Cn=d(t),re=r(t,"P",{});var Zo=o(re);ea=a(Zo,"En particulier, nous pouvons voir que le jeu de donn\xE9es contient des \xE9tiquettes pour les trois t\xE2ches que nous avons mentionn\xE9es pr\xE9c\xE9demment : NER, POS et "),$e=r(Zo,"EM",{});var Mm=o($e);Na=a(Mm,"chunking"),Mm.forEach(s),yn=a(Zo,". Une grande diff\xE9rence avec les autres jeux de donn\xE9es est que les entr\xE9es textuelles ne sont pas pr\xE9sent\xE9s comme des phrases ou des documents, mais comme des listes de mots (la derni\xE8re colonne est appel\xE9e "),gt=r(Zo,"CODE",{});var Am=o(gt);Ta=a(Am,"tokens"),Am.forEach(s),zn=a(Zo,", mais elle contient des mots dans le sens o\xF9 ce sont des entr\xE9es pr\xE9tok\xE9nis\xE9es qui doivent encore passer par le "),Et=r(Zo,"EM",{});var Nm=o(Et);Sa=a(Nm,"tokenizer"),Nm.forEach(s),On=a(Zo," pour la tokenisation en sous-mots)."),Zo.forEach(s),Gt=d(t),Ut=r(t,"P",{});var Tm=o(Ut);Pn=a(Tm,"Regardons le premier \xE9l\xE9ment de l\u2019ensemble d\u2019entra\xEEnement :"),Tm.forEach(s),Dn=d(t),w(Xe.$$.fragment,t),Mn=d(t),w(f.$$.fragment,t),S=d(t),An=r(t,"P",{});var Sm=o(An);La=a(Sm,"Puisque nous voulons effectuer reconna\xEEtre des entit\xE9s nomm\xE9es, nous allons examiner les balises NER :"),Sm.forEach(s),Ts=d(t),w(be.$$.fragment,t),Nn=d(t),w(Es.$$.fragment,t),Ia=d(t),Ss=r(t,"P",{});var Xc=o(Ss);Vt=a(Xc,"Ce sont les \xE9tiquettes sous forme d\u2019entiers disponibles pour l\u2019entra\xEEnement mais ne sont pas n\xE9cessairement utiles lorsque nous voulons inspecter les donn\xE9es. Comme pour la classification de texte, nous pouvons acc\xE9der \xE0 la correspondance entre ces entiers et les noms des \xE9tiquettes en regardant l\u2019attribut "),Tn=r(Xc,"CODE",{});var Lm=o(Tn);qt=a(Lm,"features"),Lm.forEach(s),Wt=a(Xc," de notre jeu de donn\xE9es :"),Xc.forEach(s),Xt=d(t),w(Zt.$$.fragment,t),Ls=d(t),w(kt.$$.fragment,t),Is=d(t),fe=r(t,"P",{});var ga=o(fe);Kt=a(ga,"Cette colonne contient donc des \xE9l\xE9ments qui sont des s\xE9quences de "),tt=r(ga,"CODE",{});var Im=o(tt);wl=a(Im,"ClassLabel"),Im.forEach(s),Sn=a(ga,". Le type des \xE9l\xE9ments de la s\xE9quence se trouve dans l\u2019attribut "),sa=r(ga,"CODE",{});var Fm=o(sa);Ln=a(Fm,"feature"),Fm.forEach(s),ps=a(ga," de cette "),Yt=r(ga,"CODE",{});var Rm=o(Yt);ta=a(Rm,"ner_feature"),Rm.forEach(s),na=a(ga,", et nous pouvons acc\xE9der \xE0 la liste des noms en regardant l\u2019attribut "),aa=r(ga,"CODE",{});var Bm=o(aa);Ze=a(Bm,"names"),Bm.forEach(s),xl=a(ga," de cette "),la=r(ga,"CODE",{});var Hm=o(la);ra=a(Hm,"feature"),Hm.forEach(s),Cl=a(ga," :"),ga.forEach(s),jt=d(t),w(wt.$$.fragment,t),xt=d(t),w(Re.$$.fragment,t),nt=d(t),Fs=r(t,"P",{});var Up=o(Fs);oa=a(Up,"Nous avons d\xE9j\xE0 vu ces \xE9tiquettes au "),Be=r(Up,"A",{href:!0});var Gm=o(Be);yl=a(Gm,"chapitre 6"),Gm.forEach(s),Fa=a(Up," lorsque nous nous sommes int\xE9ress\xE9s au pipeline "),at=r(Up,"CODE",{});var Um=o(at);Ra=a(Um,"token-classification"),Um.forEach(s),Rs=a(Up," mais nosu pouvons tout de m\xEAme faire un rapide rappel :"),Up.forEach(s),In=d(t),Oe=r(t,"UL",{});var ir=o(Oe);He=r(ir,"LI",{});var Ud=o(He);ia=r(Ud,"CODE",{});var Vm=o(ia);ua=a(Vm,"O"),Vm.forEach(s),zl=a(Ud," signifie que le mot ne correspond \xE0 aucune entit\xE9."),Ud.forEach(s),Ol=d(ir),Ct=r(ir,"LI",{});var qu=o(Ct);Fn=r(qu,"CODE",{});var Wm=o(Fn);Jr=a(Wm,"B-PER"),Wm.forEach(s),pa=a(qu,"/"),mr=r(qu,"CODE",{});var Xm=o(mr);fr=a(Xm,"I-PER"),Xm.forEach(s),ei=a(qu," signifie que le mot correspond au d\xE9but/est \xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),vr=r(qu,"EM",{});var Zm=o(vr);Qr=a(Zm,"personne"),Zm.forEach(s),Ba=a(qu,"."),qu.forEach(s),eo=d(ir),qs=r(ir,"LI",{});var ku=o(qs);Pl=r(ku,"CODE",{});var Km=o(Pl);lt=a(Km,"B-ORG"),Km.forEach(s),si=a(ku,"/"),Ha=r(ku,"CODE",{});var Ym=o(Ha);ti=a(Ym,"I-ORG"),Ym.forEach(s),ni=a(ku," signifie que le mot correspond au d\xE9but/est \xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),Ga=r(ku,"EM",{});var Jm=o(Ga);ai=a(Jm,"organisation"),Jm.forEach(s),li=a(ku,"."),ku.forEach(s),hr=d(ir),Jt=r(ir,"LI",{});var ju=o(Jt);_r=r(ju,"CODE",{});var Qm=o(_r);so=a(Qm,"B-LOC"),Qm.forEach(s),Ua=a(ju,"/"),Dl=r(ju,"CODE",{});var ef=o(Dl);ks=a(ef,"I-LOC"),ef.forEach(s),ri=a(ju," signifie que le mot correspond au d\xE9but/est \xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),Va=r(ju,"EM",{});var sf=o(Va);oi=a(sf,"location"),sf.forEach(s),ii=a(ju,"."),ju.forEach(s),br=d(ir),Qt=r(ir,"LI",{});var wu=o(Qt);$r=r(wu,"CODE",{});var tf=o($r);gr=a(tf,"B-MISC"),tf.forEach(s),ui=a(wu,"/"),Er=r(wu,"CODE",{});var nf=o(Er);qr=a(nf,"I-MISC"),nf.forEach(s),pi=a(wu," signifie que le mot correspond au d\xE9but/est \xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),kr=r(wu,"EM",{});var af=o(kr);to=a(af,"divers"),af.forEach(s),Wa=a(wu,"."),wu.forEach(s),ir.forEach(s),jr=d(t),en=r(t,"P",{});var lf=o(en);no=a(lf,"Maintenant, le d\xE9codage des \xE9tiquettes que nous avons vues pr\xE9c\xE9demment nous donne ceci :"),lf.forEach(s),Xa=d(t),w(Za.$$.fragment,t),wr=d(t),w(yt.$$.fragment,t),xr=d(t),Ge=r(t,"P",{});var Vp=o(Ge);ci=a(Vp,"Et pour un exemple m\xE9langeant les \xE9tiquettes "),Ka=r(Vp,"CODE",{});var rf=o(Ka);di=a(rf,"B-"),rf.forEach(s),mi=a(Vp," et "),Ya=r(Vp,"CODE",{});var of=o(Ya);fi=a(of,"I-"),of.forEach(s),vi=a(Vp,", voici ce que le m\xEAme code nous donne sur le quatri\xE8me \xE9l\xE9ment du jeu d\u2019entra\xEEnement :"),Vp.forEach(s),Cr=d(t),w(Bs.$$.fragment,t),Rn=d(t),rt=r(t,"P",{});var Wp=o(rt);Ja=a(Wp,"Comme on peut le voir, les entit\xE9s couvrant deux mots, comme \xAB European Union \xBB et \xAB Werner Zwingmann \xBB, se voient attribuer une \xE9tiquette "),yr=r(Wp,"CODE",{});var uf=o(yr);zr=a(uf,"B-"),uf.forEach(s),hi=a(Wp," pour le premier mot et une \xE9tiquette "),Ml=r(Wp,"CODE",{});var pf=o(Ml);sn=a(pf,"I-"),pf.forEach(s),_i=a(Wp," pour le second."),Wp.forEach(s),Al=d(t),w(ca.$$.fragment,t),ao=d(t),zt=r(t,"H3",{class:!0});var Zc=o(zt);da=r(Zc,"A",{id:!0,class:!0,href:!0});var cf=o(da);Or=r(cf,"SPAN",{});var df=o(Or);w(ma.$$.fragment,df),df.forEach(s),cf.forEach(s),Qa=d(Zc),Nl=r(Zc,"SPAN",{});var mf=o(Nl);Tl=a(mf,"Traitement des donn\xE9es"),mf.forEach(s),Zc.forEach(s),lo=d(t),w(fa.$$.fragment,t),Ot=d(t),we=r(t,"P",{});var Ea=o(we);bi=a(Ea,"Comme d\u2019habitude, nos textes doivent \xEAtre convertis en identifiants de "),el=r(Ea,"EM",{});var ff=o(el);$i=a(ff,"tokens"),ff.forEach(s),gi=a(Ea," avant que le mod\xE8le puisse leur donner un sens. Comme nous l\u2019avons vu au "),Sl=r(Ea,"A",{href:!0});var vf=o(Sl);Hs=a(vf,"chapitre 6"),vf.forEach(s),Ei=a(Ea,", une grande diff\xE9rence dans le cas des t\xE2ches de classification de "),sl=r(Ea,"EM",{});var hf=o(sl);qi=a(hf,"tokens"),hf.forEach(s),ki=a(Ea," est que nous avons des entr\xE9es pr\xE9tok\xE9nis\xE9es. Heureusement, l\u2019API "),tl=r(Ea,"CODE",{});var _f=o(tl);ji=a(_f,"tokenizer"),_f.forEach(s),wi=a(Ea," peut g\xE9rer cela assez facilement. Nous devons juste avertir le "),nl=r(Ea,"CODE",{});var bf=o(nl);xi=a(bf,"tokenizer"),bf.forEach(s),Ci=a(Ea," avec un drapeau sp\xE9cial."),Ea.forEach(s),Ll=d(t),tn=r(t,"P",{});var Xp=o(tn);yi=a(Xp,"Pour commencer, nous allons cr\xE9er notre objet "),Pr=r(Xp,"CODE",{});var $f=o(Pr);Gs=a($f,"tokenizer"),$f.forEach(s),zi=a(Xp,". Comme nous l\u2019avons dit pr\xE9c\xE9demment, nous allons utiliser un mod\xE8le BERT pr\xE9-entra\xEEn\xE9, donc nous allons commencer par t\xE9l\xE9charger et mettre en cache le "),al=r(Xp,"EM",{});var gf=o(al);Oi=a(gf,"tokenizer"),gf.forEach(s),Pi=a(Xp," associ\xE9 :"),Xp.forEach(s),Il=d(t),w(ll.$$.fragment,t),ro=d(t),ue=r(t,"P",{});var Ye=o(ue);Di=a(Ye,"Vous pouvez remplacer le "),Dr=r(Ye,"CODE",{});var Ef=o(Dr);Mr=a(Ef,"model_checkpoint"),Ef.forEach(s),Mi=a(Ye," par tout autre mod\xE8le que vous pr\xE9f\xE9rez \xE0 partir du "),rl=r(Ye,"A",{href:!0,rel:!0});var qf=o(rl);Fl=r(qf,"EM",{});var kf=o(Fl);Rl=a(kf,"Hub"),kf.forEach(s),qf.forEach(s),Ai=a(Ye,", ou par un dossier local dans lequel vous avez sauvegard\xE9 un mod\xE8le pr\xE9-entra\xEEn\xE9 et un "),Bl=r(Ye,"EM",{});var jf=o(Bl);ol=a(jf,"tokenizer"),jf.forEach(s),oo=a(Ye,". La seule contrainte est que le "),nn=r(Ye,"EM",{});var wf=o(nn);Ni=a(wf,"tokenizer"),wf.forEach(s),Ar=a(Ye," doit \xEAtre soutenu par la biblioth\xE8que \u{1F917} "),Nr=r(Ye,"EM",{});var xf=o(Nr);Ti=a(xf,"Tokenizers"),xf.forEach(s),io=a(Ye,". Il y a donc une version rapide disponible. Vous pouvez voir toutes les architectures qui ont une version rapide dans "),Pt=r(Ye,"A",{href:!0,rel:!0});var Cf=o(Pt);uo=a(Cf,"ce tableau"),Cf.forEach(s),xe=a(Ye,", et pour v\xE9rifier que l\u2019objet "),Tr=r(Ye,"CODE",{});var yf=o(Tr);Sr=a(yf,"tokenizer"),yf.forEach(s),Si=a(Ye," que vous utilisez est bien soutenu par \u{1F917} "),Lr=r(Ye,"EM",{});var zf=o(Lr);Ir=a(zf,"Tokenizers"),zf.forEach(s),Li=a(Ye," vous pouvez regarder son attribut "),Fr=r(Ye,"CODE",{});var Of=o(Fr);Rr=a(Of,"is_fast"),Of.forEach(s),Ii=a(Ye," :"),Ye.forEach(s),po=d(t),w(Bn.$$.fragment,t),co=d(t),w(il.$$.fragment,t),Hl=d(t),an=r(t,"P",{});var Zp=o(an);Fi=a(Zp,"Pour tokeniser une entr\xE9e pr\xE9tokenis\xE9e, nous pouvons utiliser notre "),ul=r(Zp,"CODE",{});var Pf=o(ul);Ri=a(Pf,"tokenizer"),Pf.forEach(s),Bi=a(Zp," comme d\u2019habitude et juste ajouter "),pl=r(Zp,"CODE",{});var Df=o(pl);Hi=a(Df,"is_split_into_words=True"),Df.forEach(s),Gi=a(Zp," :"),Zp.forEach(s),Br=d(t),w(js.$$.fragment,t),mo=d(t),w(Hn.$$.fragment,t),fo=d(t),ve=r(t,"P",{});var Je=o(ve);cl=a(Je,"Comme on peut le voir, le "),dl=r(Je,"EM",{});var Mf=o(dl);Ui=a(Mf,"tokenizer"),Mf.forEach(s),Vi=a(Je," a ajout\xE9 les "),Gl=r(Je,"EM",{});var Af=o(Gl);i=a(Af,"tokens"),Af.forEach(s),h=a(Je," sp\xE9ciaux utilis\xE9s par le mod\xE8le ("),vo=r(Je,"CODE",{});var Nf=o(vo);xu=a(Nf,"[CLS]"),Nf.forEach(s),Cu=a(Je," au d\xE9but et "),ot=r(Je,"CODE",{});var Tf=o(ot);yu=a(Tf,"[SEP]"),Tf.forEach(s),zu=a(Je," \xE0 la fin) et n\u2019a pas touch\xE9 \xE0 la plupart des mots. Le mot "),ho=r(Je,"CODE",{});var Sf=o(ho);Ou=a(Sf,"lamb"),Sf.forEach(s),Ul=a(Je,", cependant, a \xE9t\xE9 tokenis\xE9 en deux sous-mots, "),_o=r(Je,"CODE",{});var Lf=o(_o);Pu=a(Lf,"la"),Lf.forEach(s),Vl=a(Je," et "),bo=r(Je,"CODE",{});var If=o(bo);Du=a(If,"##mb"),If.forEach(s),va=a(Je,". Cela introduit un d\xE9calage entre nos entr\xE9es et les \xE9tiquettes : la liste des \xE9tiquettes n\u2019a que 9 \xE9l\xE9ments, alors que notre entr\xE9e a maintenant 12 "),$o=r(Je,"EM",{});var Ff=o($o);Mu=a(Ff,"tokens"),Ff.forEach(s),Au=a(Je,". Il est facile de tenir compte des "),Wl=r(Je,"EM",{});var Rf=o(Wl);Nu=a(Rf,"tokens"),Rf.forEach(s),Tu=a(Je," sp\xE9ciaux (nous savons qu\u2019ils sont au d\xE9but et \xE0 la fin), mais nous devons \xE9galement nous assurer que nous alignons toutes les \xE9tiquettes avec les mots appropri\xE9s."),Je.forEach(s),go=d(t),Us=r(t,"P",{});var ur=o(Us);Xl=a(ur,"Heureusement, comme nous utilisons un "),Eo=r(ur,"EM",{});var Bf=o(Eo);Su=a(Bf,"tokenizer"),Bf.forEach(s),qo=a(ur," rapide, nous avons acc\xE8s aux superpouvoirs des \u{1F917} "),ko=r(ur,"EM",{});var Hf=o(ko);jo=a(Hf,"Tokenizers"),Hf.forEach(s),Lu=a(ur,", ce qui signifie que nous pouvons facilement faire correspondre chaque "),Zl=r(ur,"EM",{});var Gf=o(Zl);Iu=a(Gf,"token"),Gf.forEach(s),ws=a(ur," au mot correspondant (comme on le voit au "),Hr=r(ur,"A",{href:!0});var Uf=o(Hr);Fu=a(Uf,"chapitre 6"),Uf.forEach(s),Ru=a(ur,") :"),ur.forEach(s),Wi=d(t),w(Kl.$$.fragment,t),Xi=d(t),w(Yl.$$.fragment,t),Gr=d(t),ce=r(t,"P",{});var Te=o(ce);wo=a(Te,"Avec un peu de travail, nous pouvons \xE9tendre notre liste d\u2019\xE9tiquettes pour qu\u2019elle corresponde aux "),xo=r(Te,"EM",{});var Vf=o(xo);Co=a(Vf,"tokens"),Vf.forEach(s),Bu=a(Te,". La premi\xE8re r\xE8gle que nous allons appliquer est que les "),yo=r(Te,"EM",{});var Wf=o(yo);ln=a(Wf,"tokens"),Wf.forEach(s),Hu=a(Te," sp\xE9ciaux re\xE7oivent une \xE9tiquette de "),zo=r(Te,"CODE",{});var Xf=o(zo);Gu=a(Xf,"-100"),Xf.forEach(s),Uu=a(Te,". En effet, par d\xE9faut, "),Jl=r(Te,"CODE",{});var Zf=o(Jl);Vu=a(Zf,"-100"),Zf.forEach(s),Oo=a(Te," est un indice qui est ignor\xE9 dans la fonction de perte que nous allons utiliser (l\u2019entropie crois\xE9e). Ensuite, chaque "),Po=r(Te,"EM",{});var Kf=o(Po);Wu=a(Kf,"token"),Kf.forEach(s),Xu=a(Te," re\xE7oit la m\xEAme \xE9tiquette que le "),Ql=r(Te,"EM",{});var Yf=o(Ql);Zu=a(Yf,"token"),Yf.forEach(s),Do=a(Te," qui a commenc\xE9 le mot dans lequel il se trouve puisqu\u2019ils font partie de la m\xEAme entit\xE9. Pour les "),Mo=r(Te,"EM",{});var Jf=o(Mo);Ku=a(Jf,"tokens"),Jf.forEach(s),Yu=a(Te," \xE0 l\u2019int\xE9rieur d\u2019un mot mais pas au d\xE9but, nous rempla\xE7ons le "),rn=r(Te,"CODE",{});var Qf=o(rn);Ju=a(Qf,"B-"),Qf.forEach(s),Qu=a(Te," par "),Ao=r(Te,"CODE",{});var ev=o(Ao);No=a(ev,"I-"),ev.forEach(s),ep=a(Te," (puisque le "),ha=r(Te,"EM",{});var sv=o(ha);sp=a(sv,"token"),sv.forEach(s),tp=a(Te," ne commence pas l\u2019entit\xE9) :"),Te.forEach(s),Ur=d(t),w(er.$$.fragment,t),Gn=d(t),Vr=r(t,"P",{});var tv=o(Vr);np=a(tv,"Essayons-le sur notre premi\xE8re phrase :"),tv.forEach(s),Zi=d(t),w(xs.$$.fragment,t),Ki=d(t),w(sr.$$.fragment,t),Yi=d(t),Vs=r(t,"P",{});var pr=o(Vs);ap=a(pr,"Comme nous pouvons le voir, notre fonction a ajout\xE9 "),_a=r(pr,"CODE",{});var nv=o(_a);lp=a(nv,"-100"),nv.forEach(s),rp=a(pr," pour les deux "),tr=r(pr,"EM",{});var av=o(tr);op=a(av,"tokens"),av.forEach(s),ip=a(pr," sp\xE9ciaux du d\xE9but et de fin, et un nouveau "),To=r(pr,"CODE",{});var lv=o(To);nr=a(lv,"0"),lv.forEach(s),up=a(pr," pour notre mot qui a \xE9t\xE9 divis\xE9 en deux "),So=r(pr,"EM",{});var rv=o(So);pp=a(rv,"tokens"),rv.forEach(s),ar=a(pr,"."),pr.forEach(s),Wr=d(t),w(ml.$$.fragment,t),Dt=d(t),Ue=r(t,"P",{});var cn=o(Ue);cp=a(cn,"Pour pr\xE9traiter notre jeu de donn\xE9es, nous devons tokeniser toutes les entr\xE9es et appliquer "),Lo=r(cn,"CODE",{});var ov=o(Lo);dp=a(ov,"align_labels_with_tokens()"),ov.forEach(s),on=a(cn," sur toutes les \xE9tiquettes. Pour profiter de la vitesse de notre "),Io=r(cn,"EM",{});var iv=o(Io);mp=a(iv,"tokenizer"),iv.forEach(s),fp=a(cn," rapide, il est pr\xE9f\xE9rable de tokeniser beaucoup de textes en m\xEAme temps. Nous allons donc \xE9crire une fonction qui traite une liste d\u2019exemples et utiliser la m\xE9thode "),Fo=r(cn,"CODE",{});var uv=o(Fo);vp=a(uv,"Dataset.map()"),uv.forEach(s),Ro=a(cn," avec l\u2019option "),Bo=r(cn,"CODE",{});var pv=o(Bo);Ke=a(pv,"batched=True"),pv.forEach(s),hp=a(cn,". La seule chose qui diff\xE8re de notre exemple pr\xE9c\xE9dent est que la fonction "),Ho=r(cn,"CODE",{});var cv=o(Ho);_p=a(cv,"word_ids()"),cv.forEach(s),bp=a(cn," a besoin de r\xE9cup\xE9rer l\u2019index de l\u2019exemple dont nous voulons les identifiants de mots lorsque les entr\xE9es du "),Go=r(cn,"EM",{});var dv=o(Go);$p=a(dv,"tokenizer"),dv.forEach(s),gp=a(cn," sont des listes de textes (ou dans notre cas, des listes de mots), donc nous l\u2019ajoutons aussi :"),cn.forEach(s),fl=d(t),w(lr.$$.fragment,t),Ji=d(t),Xr=r(t,"P",{});var mv=o(Xr);sd=a(mv,"Notez que nous n\u2019avons pas encore rembourr\xE9 nos entr\xE9es. Nous le ferons plus tard lors de la cr\xE9ation des batchs avec un assembleur de donn\xE9es."),mv.forEach(s),fc=d(t),Ep=r(t,"P",{});var fv=o(Ep);td=a(fv,"Nous pouvons maintenant appliquer tout ce pr\xE9traitement en une seule fois sur les autres divisions de notre jeu de donn\xE9es :"),fv.forEach(s),vc=d(t),w(Qi.$$.fragment,t),hc=d(t),Uo=r(t,"P",{});var Kc=o(Uo);nd=a(Kc,"Nous avons fait la partie la plus difficile ! Maintenant que les donn\xE9es ont \xE9t\xE9 pr\xE9trait\xE9es, l\u2019entra\xEEnement ressemblera beaucoup \xE0 ce que nous avons fait dans le "),qp=r(Kc,"A",{href:!0});var vv=o(qp);ad=a(vv,"chapitre 3"),vv.forEach(s),ld=a(Kc,"."),Kc.forEach(s),_c=d(t),hl.l(t),kp=d(t),Zr=r(t,"H3",{class:!0});var Yc=o(Zr);Vo=r(Yc,"A",{id:!0,class:!0,href:!0});var hv=o(Vo);Kp=r(hv,"SPAN",{});var _v=o(Kp);w(eu.$$.fragment,_v),_v.forEach(s),hv.forEach(s),rd=d(Yc),Yp=r(Yc,"SPAN",{});var bv=o(Yp);od=a(bv,"Assemblage des donn\xE9es"),bv.forEach(s),Yc.forEach(s),bc=d(t),un=r(t,"P",{});var cr=o(un);id=a(cr,"Nous ne pouvons pas simplement utiliser un "),Jp=r(cr,"CODE",{});var $v=o(Jp);ud=a($v,"DataCollatorWithPadding"),$v.forEach(s),pd=a(cr," comme dans le "),jp=r(cr,"A",{href:!0});var gv=o(jp);cd=a(gv,"chapitre 3"),gv.forEach(s),dd=a(cr," car cela ne fait que rembourrer les entr\xE9es (identifiants d\u2019entr\xE9e, masque d\u2019attention et "),Qp=r(cr,"EM",{});var Ev=o(Qp);md=a(Ev,"token"),Ev.forEach(s),fd=a(cr," de type identifiants). Ici, nos \xE9tiquettes doivent \xEAtre rembourr\xE9\xE9s exactement de la m\xEAme mani\xE8re que les entr\xE9es afin qu\u2019elles gardent la m\xEAme taille, en utilisant "),ec=r(cr,"CODE",{});var qv=o(ec);vd=a(qv,"-100"),qv.forEach(s),hd=a(cr," comme valeur afin que les pr\xE9dictions correspondantes soient ignor\xE9es dans le calcul de la perte."),cr.forEach(s),$c=d(t),ba=r(t,"P",{});var Ko=o(ba);_d=a(Ko,"Tout ceci est fait par un "),su=r(Ko,"A",{href:!0,rel:!0});var kv=o(su);sc=r(kv,"CODE",{});var jv=o(sc);bd=a(jv,"DataCollatorForTokenClassification"),jv.forEach(s),kv.forEach(s),$d=a(Ko,". Comme le "),tc=r(Ko,"CODE",{});var wv=o(tc);gd=a(wv,"DataCollatorWithPadding"),wv.forEach(s),Ed=a(Ko,", il prend le "),nc=r(Ko,"CODE",{});var xv=o(nc);qd=a(xv,"tokenizer"),xv.forEach(s),kd=a(Ko," utilis\xE9 pour pr\xE9traiter les entr\xE9es :"),Ko.forEach(s),gc=d(t),bl.l(t),wp=d(t),xp=r(t,"P",{});var Cv=o(xp);jd=a(Cv,"Pour tester cette fonction sur quelques \xE9chantillons, nous pouvons simplement l\u2019appeler sur une liste d\u2019exemples provenant de notre jeu d\u2019entra\xEEnement tok\xE9nis\xE9 :"),Cv.forEach(s),Ec=d(t),w(tu.$$.fragment,t),qc=d(t),w(nu.$$.fragment,t),kc=d(t),Cp=r(t,"P",{});var yv=o(Cp);wd=a(yv,"Comparons cela aux \xE9tiquettes des premier et deuxi\xE8me \xE9l\xE9ments de notre jeu de donn\xE9es :"),yv.forEach(s),jc=d(t),w(au.$$.fragment,t),wc=d(t),w(lu.$$.fragment,t),xc=d(t),gl.l(t),yp=d(t),cs&&cs.l(t),zp=d(t),Kr=r(t,"H3",{class:!0});var Jc=o(Kr);Wo=r(Jc,"A",{id:!0,class:!0,href:!0});var zv=o(Wo);ac=r(zv,"SPAN",{});var Ov=o(ac);w(ru.$$.fragment,Ov),Ov.forEach(s),zv.forEach(s),xd=d(Jc),lc=r(Jc,"SPAN",{});var Pv=o(lc);Cd=a(Pv,"M\xE9triques"),Pv.forEach(s),Jc.forEach(s),Cc=d(t),ql.l(t),Op=d(t),w(ou.$$.fragment,t),yc=d(t),Pp=r(t,"P",{});var Dv=o(Pp);yd=a(Dv,"Cette m\xE9trique ne se comporte pas comme la pr\xE9cision standard : elle prend les listes d\u2019\xE9tiquettes comme des cha\xEEnes de caract\xE8res et non comme des entiers. Nous devrons donc d\xE9coder compl\xE8tement les pr\xE9dictions et les \xE9tiquettes avant de les transmettre \xE0 la m\xE9trique. Voyons comment cela fonctionne. Tout d\u2019abord, nous allons obtenir les \xE9tiquettes pour notre premier exemple d\u2019entra\xEEnement :"),Dv.forEach(s),zc=d(t),w(iu.$$.fragment,t),Oc=d(t),w(uu.$$.fragment,t),Pc=d(t),Dp=r(t,"P",{});var Mv=o(Dp);zd=a(Mv,"Nous pouvons alors cr\xE9er de fausses pr\xE9dictions pour celles-ci en changeant simplement la valeur de l\u2019indice 2 :"),Mv.forEach(s),Dc=d(t),w(pu.$$.fragment,t),Mc=d(t),Mp=r(t,"P",{});var Av=o(Mp);Od=a(Av,"Notez que la m\xE9trique prend une liste de pr\xE9dictions (pas seulement une) et une liste d\u2019\xE9tiquettes. Voici la sortie :"),Av.forEach(s),Ac=d(t),w(cu.$$.fragment,t),Nc=d(t),jl.l(t),Ap=d(t),ds&&ds.l(t),Np=d(t),Yr=r(t,"H3",{class:!0});var Qc=o(Yr);Xo=r(Qc,"A",{id:!0,class:!0,href:!0});var Nv=o(Xo);rc=r(Nv,"SPAN",{});var Tv=o(rc);w(du.$$.fragment,Tv),Tv.forEach(s),Nv.forEach(s),Pd=d(Qc),Tp=r(Qc,"SPAN",{});var Vd=o(Tp);Dd=a(Vd,"Utilisation du mod\xE8le "),oc=r(Vd,"I",{});var Sv=o(oc);Md=a(Sv,"finetun\xE9"),Sv.forEach(s),Vd.forEach(s),Qc.forEach(s),Tc=d(t),pn=r(t,"P",{});var dr=o(pn);Ad=a(dr,"Nous vous avons d\xE9j\xE0 montr\xE9 comment vous pouvez utiliser le mod\xE8le "),ic=r(dr,"EM",{});var Lv=o(ic);Nd=a(Lv,"finetun\xE9"),Lv.forEach(s),Td=a(dr," sur le "),uc=r(dr,"EM",{});var Iv=o(uc);Sd=a(Iv,"Hub"),Iv.forEach(s),Ld=a(dr," avec le "),pc=r(dr,"EM",{});var Fv=o(pc);Id=a(Fv,"widget"),Fv.forEach(s),Fd=a(dr," d\u2019inf\xE9rence. Pour l\u2019utiliser localement dans un "),cc=r(dr,"CODE",{});var Rv=o(cc);Rd=a(Rv,"pipeline"),Rv.forEach(s),Bd=a(dr,", vous devez juste sp\xE9cifier l\u2019identifiant de mod\xE8le appropri\xE9 :"),dr.forEach(s),Sc=d(t),w(mu.$$.fragment,t),Lc=d(t),w(fu.$$.fragment,t),Ic=d(t),Sp=r(t,"P",{});var Bv=o(Sp);Hd=a(Bv,"Super ! Notre mod\xE8le fonctionne aussi bien que le mod\xE8le par d\xE9faut pour ce pipeline !"),Bv.forEach(s),this.h()},h(){_(p,"name","hf:doc:metadata"),_(p,"content",JSON.stringify(Eh)),_(E,"id","classification-de-itokensi"),_(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(E,"href","#classification-de-itokensi"),_(z,"class","relative group"),ed(Ee.src,mt="https://hf.space/gradioiframe/course-demos/bert-finetuned-ner/+")||_(Ee,"src",mt),_(Ee,"frameborder","0"),_(Ee,"height","350"),_(Ee,"title","Gradio app"),_(Ee,"class","block dark:hidden container p-0 flex-grow space-iframe"),_(Ee,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),_(Ee,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"),ed(qe.src,Tt="https://hf.space/gradioiframe/course-demos/bert-finetuned-ner-darkmode/+")||_(qe,"src",Tt),_(qe,"frameborder","0"),_(qe,"height","350"),_(qe,"title","Gradio app"),_(qe,"class","hidden dark:block container p-0 flex-grow space-iframe"),_(qe,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),_(qe,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"),_(rs,"class","block dark:hidden lg:w-3/5"),ed(rs.src,gn="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/model-eval-bert-finetuned-ner.png")||_(rs,"src",gn),_(rs,"alt","One-hot encoded labels for question answering."),_(ft,"class","hidden dark:block lg:w-3/5"),ed(ft.src,St="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/model-eval-bert-finetuned-ner-dark.png")||_(ft,"src",St),_(ft,"alt","One-hot encoded labels for question answering."),_(ie,"class","flex justify-center"),_(ie,"href","/huggingface-course/bert-finetuned-ner"),_(os,"href","https://huggingface.co/huggingface-course/bert-finetuned-ner?text=My+nom+est+Sylvain+et+je+travaille+%C3%A0+Hugging+Face+in+Brooklyn"),_(os,"rel","nofollow"),_(Ve,"id","prparation-des-donnes"),_(Ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Ve,"href","#prparation-des-donnes"),_(hs,"class","relative group"),_(vt,"href","https://huggingface.co/datasets/conll2003"),_(vt,"rel","nofollow"),_(is,"id","le-jeu-de-donnes-conll2003"),_(is,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(is,"href","#le-jeu-de-donnes-conll2003"),_(Ie,"class","relative group"),_($t,"href","/course/fr/chapter3"),_(Be,"href","/course/fr/chapter6/3"),_(da,"id","traitement-des-donnes"),_(da,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(da,"href","#traitement-des-donnes"),_(zt,"class","relative group"),_(Sl,"href","/course/fr/chapter6/"),_(rl,"href","https://huggingface.co/models"),_(rl,"rel","nofollow"),_(Pt,"href","https://huggingface.co/transformers/#supported-frameworks"),_(Pt,"rel","nofollow"),_(Hr,"href","/course/fr/chapter6/3"),_(qp,"href","/course/fr/chapter3"),_(Vo,"id","assemblage-des-donnes"),_(Vo,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Vo,"href","#assemblage-des-donnes"),_(Zr,"class","relative group"),_(jp,"href","/course/fr/chapter3"),_(su,"href","https://huggingface.co/transformers/main_classes/data_collator.html#datacollatorfortokenclassification"),_(su,"rel","nofollow"),_(Wo,"id","mtriques"),_(Wo,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Wo,"href","#mtriques"),_(Kr,"class","relative group"),_(Xo,"id","utilisation-du-modle-ifinetuni"),_(Xo,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Xo,"href","#utilisation-du-modle-ifinetuni"),_(Yr,"class","relative group")},m(t,m){e(document.head,p),u(t,g,m),x(v,t,m),u(t,q,m),u(t,z,m),e(z,E),e(E,k),x(P,k,null),e(z,y),e(z,O),e(O,H),e(O,I),e(I,L),u(t,F,m),vu[T].m(t,m),u(t,W,m),u(t,D,m),e(D,M),e(D,V),e(V,Y),e(D,se),e(D,N),e(N,G),e(D,te),u(t,J,m),u(t,ee,m),e(ee,R),e(R,K),e(R,de),e(de,Pe),e(de,he),e(he,B),e(de,le),e(R,Q),e(R,oe),e(oe,Z),e(R,pe),e(R,Qe),e(Qe,_e),e(R,ge),e(ee,ys),e(ee,Ce),e(Ce,De),e(Ce,es),e(es,ae),e(ae,ms),e(es,fs),e(Ce,Mt),e(ee,qa),e(ee,ne),e(ne,ka),e(ne,dn),e(dn,zs),e(zs,ja),e(ne,wa),e(ne,ut),e(ut,ss),e(ne,mn),e(ne,Se),e(Se,fn),e(ne,ts),e(ne,pt),e(pt,ye),e(ne,Le),e(ne,Os),e(Os,ns),e(ne,xa),e(ne,as),e(as,ct),e(ne,Ca),e(ne,vn),e(vn,hn),e(ne,ze),e(ne,_n),e(_n,dt),e(ne,ya),u(t,Un,m),x(vs,t,m),u(t,Ws,m),u(t,ls,m),e(ls,Ps),e(ls,Ds),e(Ds,At),e(ls,Xs),e(ls,bn),e(bn,Nt),e(ls,Zs),u(t,Vn,m),u(t,Ee,m),u(t,Wn,m),u(t,qe,m),u(t,$n,m),u(t,ie,m),e(ie,rs),e(ie,Ks),e(ie,ft),u(t,Xn,m),u(t,Ys,m),e(Ys,Lt),e(Ys,os),e(os,It),e(It,me),e(Ys,za),u(t,Ft,m),u(t,hs,m),e(hs,Ve),e(Ve,Js),x(Me,Js,null),e(hs,Oa),e(hs,Ms),e(Ms,Pa),u(t,Zn,m),u(t,ke,m),e(ke,En),e(ke,qn),e(qn,Kn),e(ke,Ae),e(ke,vt),e(vt,kn),e(ke,jn),u(t,Yn,m),x(_s,t,m),u(t,wn,m),u(t,Ie,m),e(Ie,is),e(is,bs),x(ht,bs,null),e(Ie,Rt),e(Ie,As),e(As,Jn),u(t,je,m),u(t,Ne,m),e(Ne,Bt),e(Ne,$s),e($s,Da),e(Ne,Ns),e(Ne,_t),e(_t,Ma),e(Ne,Qn),u(t,us,m),x(bt,t,m),u(t,Ht,m),u(t,gs,m),e(gs,Aa),e(gs,$t),e($t,Qs),e(gs,et),u(t,st,m),x(We,t,m),u(t,xn,m),x(Fe,t,m),u(t,Cn,m),u(t,re,m),e(re,ea),e(re,$e),e($e,Na),e(re,yn),e(re,gt),e(gt,Ta),e(re,zn),e(re,Et),e(Et,Sa),e(re,On),u(t,Gt,m),u(t,Ut,m),e(Ut,Pn),u(t,Dn,m),x(Xe,t,m),u(t,Mn,m),x(f,t,m),u(t,S,m),u(t,An,m),e(An,La),u(t,Ts,m),x(be,t,m),u(t,Nn,m),x(Es,t,m),u(t,Ia,m),u(t,Ss,m),e(Ss,Vt),e(Ss,Tn),e(Tn,qt),e(Ss,Wt),u(t,Xt,m),x(Zt,t,m),u(t,Ls,m),x(kt,t,m),u(t,Is,m),u(t,fe,m),e(fe,Kt),e(fe,tt),e(tt,wl),e(fe,Sn),e(fe,sa),e(sa,Ln),e(fe,ps),e(fe,Yt),e(Yt,ta),e(fe,na),e(fe,aa),e(aa,Ze),e(fe,xl),e(fe,la),e(la,ra),e(fe,Cl),u(t,jt,m),x(wt,t,m),u(t,xt,m),x(Re,t,m),u(t,nt,m),u(t,Fs,m),e(Fs,oa),e(Fs,Be),e(Be,yl),e(Fs,Fa),e(Fs,at),e(at,Ra),e(Fs,Rs),u(t,In,m),u(t,Oe,m),e(Oe,He),e(He,ia),e(ia,ua),e(He,zl),e(Oe,Ol),e(Oe,Ct),e(Ct,Fn),e(Fn,Jr),e(Ct,pa),e(Ct,mr),e(mr,fr),e(Ct,ei),e(Ct,vr),e(vr,Qr),e(Ct,Ba),e(Oe,eo),e(Oe,qs),e(qs,Pl),e(Pl,lt),e(qs,si),e(qs,Ha),e(Ha,ti),e(qs,ni),e(qs,Ga),e(Ga,ai),e(qs,li),e(Oe,hr),e(Oe,Jt),e(Jt,_r),e(_r,so),e(Jt,Ua),e(Jt,Dl),e(Dl,ks),e(Jt,ri),e(Jt,Va),e(Va,oi),e(Jt,ii),e(Oe,br),e(Oe,Qt),e(Qt,$r),e($r,gr),e(Qt,ui),e(Qt,Er),e(Er,qr),e(Qt,pi),e(Qt,kr),e(kr,to),e(Qt,Wa),u(t,jr,m),u(t,en,m),e(en,no),u(t,Xa,m),x(Za,t,m),u(t,wr,m),x(yt,t,m),u(t,xr,m),u(t,Ge,m),e(Ge,ci),e(Ge,Ka),e(Ka,di),e(Ge,mi),e(Ge,Ya),e(Ya,fi),e(Ge,vi),u(t,Cr,m),x(Bs,t,m),u(t,Rn,m),u(t,rt,m),e(rt,Ja),e(rt,yr),e(yr,zr),e(rt,hi),e(rt,Ml),e(Ml,sn),e(rt,_i),u(t,Al,m),x(ca,t,m),u(t,ao,m),u(t,zt,m),e(zt,da),e(da,Or),x(ma,Or,null),e(zt,Qa),e(zt,Nl),e(Nl,Tl),u(t,lo,m),x(fa,t,m),u(t,Ot,m),u(t,we,m),e(we,bi),e(we,el),e(el,$i),e(we,gi),e(we,Sl),e(Sl,Hs),e(we,Ei),e(we,sl),e(sl,qi),e(we,ki),e(we,tl),e(tl,ji),e(we,wi),e(we,nl),e(nl,xi),e(we,Ci),u(t,Ll,m),u(t,tn,m),e(tn,yi),e(tn,Pr),e(Pr,Gs),e(tn,zi),e(tn,al),e(al,Oi),e(tn,Pi),u(t,Il,m),x(ll,t,m),u(t,ro,m),u(t,ue,m),e(ue,Di),e(ue,Dr),e(Dr,Mr),e(ue,Mi),e(ue,rl),e(rl,Fl),e(Fl,Rl),e(ue,Ai),e(ue,Bl),e(Bl,ol),e(ue,oo),e(ue,nn),e(nn,Ni),e(ue,Ar),e(ue,Nr),e(Nr,Ti),e(ue,io),e(ue,Pt),e(Pt,uo),e(ue,xe),e(ue,Tr),e(Tr,Sr),e(ue,Si),e(ue,Lr),e(Lr,Ir),e(ue,Li),e(ue,Fr),e(Fr,Rr),e(ue,Ii),u(t,po,m),x(Bn,t,m),u(t,co,m),x(il,t,m),u(t,Hl,m),u(t,an,m),e(an,Fi),e(an,ul),e(ul,Ri),e(an,Bi),e(an,pl),e(pl,Hi),e(an,Gi),u(t,Br,m),x(js,t,m),u(t,mo,m),x(Hn,t,m),u(t,fo,m),u(t,ve,m),e(ve,cl),e(ve,dl),e(dl,Ui),e(ve,Vi),e(ve,Gl),e(Gl,i),e(ve,h),e(ve,vo),e(vo,xu),e(ve,Cu),e(ve,ot),e(ot,yu),e(ve,zu),e(ve,ho),e(ho,Ou),e(ve,Ul),e(ve,_o),e(_o,Pu),e(ve,Vl),e(ve,bo),e(bo,Du),e(ve,va),e(ve,$o),e($o,Mu),e(ve,Au),e(ve,Wl),e(Wl,Nu),e(ve,Tu),u(t,go,m),u(t,Us,m),e(Us,Xl),e(Us,Eo),e(Eo,Su),e(Us,qo),e(Us,ko),e(ko,jo),e(Us,Lu),e(Us,Zl),e(Zl,Iu),e(Us,ws),e(Us,Hr),e(Hr,Fu),e(Us,Ru),u(t,Wi,m),x(Kl,t,m),u(t,Xi,m),x(Yl,t,m),u(t,Gr,m),u(t,ce,m),e(ce,wo),e(ce,xo),e(xo,Co),e(ce,Bu),e(ce,yo),e(yo,ln),e(ce,Hu),e(ce,zo),e(zo,Gu),e(ce,Uu),e(ce,Jl),e(Jl,Vu),e(ce,Oo),e(ce,Po),e(Po,Wu),e(ce,Xu),e(ce,Ql),e(Ql,Zu),e(ce,Do),e(ce,Mo),e(Mo,Ku),e(ce,Yu),e(ce,rn),e(rn,Ju),e(ce,Qu),e(ce,Ao),e(Ao,No),e(ce,ep),e(ce,ha),e(ha,sp),e(ce,tp),u(t,Ur,m),x(er,t,m),u(t,Gn,m),u(t,Vr,m),e(Vr,np),u(t,Zi,m),x(xs,t,m),u(t,Ki,m),x(sr,t,m),u(t,Yi,m),u(t,Vs,m),e(Vs,ap),e(Vs,_a),e(_a,lp),e(Vs,rp),e(Vs,tr),e(tr,op),e(Vs,ip),e(Vs,To),e(To,nr),e(Vs,up),e(Vs,So),e(So,pp),e(Vs,ar),u(t,Wr,m),x(ml,t,m),u(t,Dt,m),u(t,Ue,m),e(Ue,cp),e(Ue,Lo),e(Lo,dp),e(Ue,on),e(Ue,Io),e(Io,mp),e(Ue,fp),e(Ue,Fo),e(Fo,vp),e(Ue,Ro),e(Ue,Bo),e(Bo,Ke),e(Ue,hp),e(Ue,Ho),e(Ho,_p),e(Ue,bp),e(Ue,Go),e(Go,$p),e(Ue,gp),u(t,fl,m),x(lr,t,m),u(t,Ji,m),u(t,Xr,m),e(Xr,sd),u(t,fc,m),u(t,Ep,m),e(Ep,td),u(t,vc,m),x(Qi,t,m),u(t,hc,m),u(t,Uo,m),e(Uo,nd),e(Uo,qp),e(qp,ad),e(Uo,ld),u(t,_c,m),hu[vl].m(t,m),u(t,kp,m),u(t,Zr,m),e(Zr,Vo),e(Vo,Kp),x(eu,Kp,null),e(Zr,rd),e(Zr,Yp),e(Yp,od),u(t,bc,m),u(t,un,m),e(un,id),e(un,Jp),e(Jp,ud),e(un,pd),e(un,jp),e(jp,cd),e(un,dd),e(un,Qp),e(Qp,md),e(un,fd),e(un,ec),e(ec,vd),e(un,hd),u(t,$c,m),u(t,ba,m),e(ba,_d),e(ba,su),e(su,sc),e(sc,bd),e(ba,$d),e(ba,tc),e(tc,gd),e(ba,Ed),e(ba,nc),e(nc,qd),e(ba,kd),u(t,gc,m),_u[_l].m(t,m),u(t,wp,m),u(t,xp,m),e(xp,jd),u(t,Ec,m),x(tu,t,m),u(t,qc,m),x(nu,t,m),u(t,kc,m),u(t,Cp,m),e(Cp,wd),u(t,jc,m),x(au,t,m),u(t,wc,m),x(lu,t,m),u(t,xc,m),bu[$l].m(t,m),u(t,yp,m),cs&&cs.m(t,m),u(t,zp,m),u(t,Kr,m),e(Kr,Wo),e(Wo,ac),x(ru,ac,null),e(Kr,xd),e(Kr,lc),e(lc,Cd),u(t,Cc,m),$u[El].m(t,m),u(t,Op,m),x(ou,t,m),u(t,yc,m),u(t,Pp,m),e(Pp,yd),u(t,zc,m),x(iu,t,m),u(t,Oc,m),x(uu,t,m),u(t,Pc,m),u(t,Dp,m),e(Dp,zd),u(t,Dc,m),x(pu,t,m),u(t,Mc,m),u(t,Mp,m),e(Mp,Od),u(t,Ac,m),x(cu,t,m),u(t,Nc,m),gu[kl].m(t,m),u(t,Ap,m),ds&&ds.m(t,m),u(t,Np,m),u(t,Yr,m),e(Yr,Xo),e(Xo,rc),x(du,rc,null),e(Yr,Pd),e(Yr,Tp),e(Tp,Dd),e(Tp,oc),e(oc,Md),u(t,Tc,m),u(t,pn,m),e(pn,Ad),e(pn,ic),e(ic,Nd),e(pn,Td),e(pn,uc),e(uc,Sd),e(pn,Ld),e(pn,pc),e(pc,Id),e(pn,Fd),e(pn,cc),e(cc,Rd),e(pn,Bd),u(t,Sc,m),x(mu,t,m),u(t,Lc,m),x(fu,t,m),u(t,Ic,m),u(t,Sp,m),e(Sp,Hd),Fc=!0},p(t,[m]){const Eu={};m&1&&(Eu.fw=t[0]),v.$set(Eu);let Lp=T;T=Xd(t),T!==Lp&&(Jo(),$(vu[Lp],1,1,()=>{vu[Lp]=null}),Yo(),U=vu[T],U||(U=vu[T]=Wd[T](t),U.c()),b(U,1),U.m(W.parentNode,W));const dc={};m&2&&(dc.$$scope={dirty:m,ctx:t}),_s.$set(dc);const Ip={};m&2&&(Ip.$$scope={dirty:m,ctx:t}),ca.$set(Ip);const mc={};m&2&&(mc.$$scope={dirty:m,ctx:t}),ml.$set(mc);let rr=vl;vl=Kd(t),vl!==rr&&(Jo(),$(hu[rr],1,1,()=>{hu[rr]=null}),Yo(),hl=hu[vl],hl||(hl=hu[vl]=Zd[vl](t),hl.c()),b(hl,1),hl.m(kp.parentNode,kp));let Fp=_l;_l=Jd(t),_l!==Fp&&(Jo(),$(_u[Fp],1,1,()=>{_u[Fp]=null}),Yo(),bl=_u[_l],bl||(bl=_u[_l]=Yd[_l](t),bl.c()),b(bl,1),bl.m(wp.parentNode,wp));let Rp=$l;$l=em(t),$l!==Rp&&(Jo(),$(bu[Rp],1,1,()=>{bu[Rp]=null}),Yo(),gl=bu[$l],gl||(gl=bu[$l]=Qd[$l](t),gl.c()),b(gl,1),gl.m(yp.parentNode,yp)),t[0]==="tf"?cs?m&1&&b(cs,1):(cs=Uv(t),cs.c(),b(cs,1),cs.m(zp.parentNode,zp)):cs&&(Jo(),$(cs,1,1,()=>{cs=null}),Yo());let or=El;El=tm(t),El!==or&&(Jo(),$($u[or],1,1,()=>{$u[or]=null}),Yo(),ql=$u[El],ql||(ql=$u[El]=sm[El](t),ql.c()),b(ql,1),ql.m(Op.parentNode,Op));let $a=kl;kl=am(t),kl!==$a&&(Jo(),$(gu[$a],1,1,()=>{gu[$a]=null}),Yo(),jl=gu[kl],jl||(jl=gu[kl]=nm[kl](t),jl.c()),b(jl,1),jl.m(Ap.parentNode,Ap)),t[0]==="pt"?ds?m&1&&b(ds,1):(ds=Vv(t),ds.c(),b(ds,1),ds.m(Np.parentNode,Np)):ds&&(Jo(),$(ds,1,1,()=>{ds=null}),Yo())},i(t){Fc||(b(v.$$.fragment,t),b(P.$$.fragment,t),b(U),b(vs.$$.fragment,t),b(Me.$$.fragment,t),b(_s.$$.fragment,t),b(ht.$$.fragment,t),b(bt.$$.fragment,t),b(We.$$.fragment,t),b(Fe.$$.fragment,t),b(Xe.$$.fragment,t),b(f.$$.fragment,t),b(be.$$.fragment,t),b(Es.$$.fragment,t),b(Zt.$$.fragment,t),b(kt.$$.fragment,t),b(wt.$$.fragment,t),b(Re.$$.fragment,t),b(Za.$$.fragment,t),b(yt.$$.fragment,t),b(Bs.$$.fragment,t),b(ca.$$.fragment,t),b(ma.$$.fragment,t),b(fa.$$.fragment,t),b(ll.$$.fragment,t),b(Bn.$$.fragment,t),b(il.$$.fragment,t),b(js.$$.fragment,t),b(Hn.$$.fragment,t),b(Kl.$$.fragment,t),b(Yl.$$.fragment,t),b(er.$$.fragment,t),b(xs.$$.fragment,t),b(sr.$$.fragment,t),b(ml.$$.fragment,t),b(lr.$$.fragment,t),b(Qi.$$.fragment,t),b(hl),b(eu.$$.fragment,t),b(bl),b(tu.$$.fragment,t),b(nu.$$.fragment,t),b(au.$$.fragment,t),b(lu.$$.fragment,t),b(gl),b(cs),b(ru.$$.fragment,t),b(ql),b(ou.$$.fragment,t),b(iu.$$.fragment,t),b(uu.$$.fragment,t),b(pu.$$.fragment,t),b(cu.$$.fragment,t),b(jl),b(ds),b(du.$$.fragment,t),b(mu.$$.fragment,t),b(fu.$$.fragment,t),Fc=!0)},o(t){$(v.$$.fragment,t),$(P.$$.fragment,t),$(U),$(vs.$$.fragment,t),$(Me.$$.fragment,t),$(_s.$$.fragment,t),$(ht.$$.fragment,t),$(bt.$$.fragment,t),$(We.$$.fragment,t),$(Fe.$$.fragment,t),$(Xe.$$.fragment,t),$(f.$$.fragment,t),$(be.$$.fragment,t),$(Es.$$.fragment,t),$(Zt.$$.fragment,t),$(kt.$$.fragment,t),$(wt.$$.fragment,t),$(Re.$$.fragment,t),$(Za.$$.fragment,t),$(yt.$$.fragment,t),$(Bs.$$.fragment,t),$(ca.$$.fragment,t),$(ma.$$.fragment,t),$(fa.$$.fragment,t),$(ll.$$.fragment,t),$(Bn.$$.fragment,t),$(il.$$.fragment,t),$(js.$$.fragment,t),$(Hn.$$.fragment,t),$(Kl.$$.fragment,t),$(Yl.$$.fragment,t),$(er.$$.fragment,t),$(xs.$$.fragment,t),$(sr.$$.fragment,t),$(ml.$$.fragment,t),$(lr.$$.fragment,t),$(Qi.$$.fragment,t),$(hl),$(eu.$$.fragment,t),$(bl),$(tu.$$.fragment,t),$(nu.$$.fragment,t),$(au.$$.fragment,t),$(lu.$$.fragment,t),$(gl),$(cs),$(ru.$$.fragment,t),$(ql),$(ou.$$.fragment,t),$(iu.$$.fragment,t),$(uu.$$.fragment,t),$(pu.$$.fragment,t),$(cu.$$.fragment,t),$(jl),$(ds),$(du.$$.fragment,t),$(mu.$$.fragment,t),$(fu.$$.fragment,t),Fc=!1},d(t){s(p),t&&s(g),C(v,t),t&&s(q),t&&s(z),C(P),t&&s(F),vu[T].d(t),t&&s(W),t&&s(D),t&&s(J),t&&s(ee),t&&s(Un),C(vs,t),t&&s(Ws),t&&s(ls),t&&s(Vn),t&&s(Ee),t&&s(Wn),t&&s(qe),t&&s($n),t&&s(ie),t&&s(Xn),t&&s(Ys),t&&s(Ft),t&&s(hs),C(Me),t&&s(Zn),t&&s(ke),t&&s(Yn),C(_s,t),t&&s(wn),t&&s(Ie),C(ht),t&&s(je),t&&s(Ne),t&&s(us),C(bt,t),t&&s(Ht),t&&s(gs),t&&s(st),C(We,t),t&&s(xn),C(Fe,t),t&&s(Cn),t&&s(re),t&&s(Gt),t&&s(Ut),t&&s(Dn),C(Xe,t),t&&s(Mn),C(f,t),t&&s(S),t&&s(An),t&&s(Ts),C(be,t),t&&s(Nn),C(Es,t),t&&s(Ia),t&&s(Ss),t&&s(Xt),C(Zt,t),t&&s(Ls),C(kt,t),t&&s(Is),t&&s(fe),t&&s(jt),C(wt,t),t&&s(xt),C(Re,t),t&&s(nt),t&&s(Fs),t&&s(In),t&&s(Oe),t&&s(jr),t&&s(en),t&&s(Xa),C(Za,t),t&&s(wr),C(yt,t),t&&s(xr),t&&s(Ge),t&&s(Cr),C(Bs,t),t&&s(Rn),t&&s(rt),t&&s(Al),C(ca,t),t&&s(ao),t&&s(zt),C(ma),t&&s(lo),C(fa,t),t&&s(Ot),t&&s(we),t&&s(Ll),t&&s(tn),t&&s(Il),C(ll,t),t&&s(ro),t&&s(ue),t&&s(po),C(Bn,t),t&&s(co),C(il,t),t&&s(Hl),t&&s(an),t&&s(Br),C(js,t),t&&s(mo),C(Hn,t),t&&s(fo),t&&s(ve),t&&s(go),t&&s(Us),t&&s(Wi),C(Kl,t),t&&s(Xi),C(Yl,t),t&&s(Gr),t&&s(ce),t&&s(Ur),C(er,t),t&&s(Gn),t&&s(Vr),t&&s(Zi),C(xs,t),t&&s(Ki),C(sr,t),t&&s(Yi),t&&s(Vs),t&&s(Wr),C(ml,t),t&&s(Dt),t&&s(Ue),t&&s(fl),C(lr,t),t&&s(Ji),t&&s(Xr),t&&s(fc),t&&s(Ep),t&&s(vc),C(Qi,t),t&&s(hc),t&&s(Uo),t&&s(_c),hu[vl].d(t),t&&s(kp),t&&s(Zr),C(eu),t&&s(bc),t&&s(un),t&&s($c),t&&s(ba),t&&s(gc),_u[_l].d(t),t&&s(wp),t&&s(xp),t&&s(Ec),C(tu,t),t&&s(qc),C(nu,t),t&&s(kc),t&&s(Cp),t&&s(jc),C(au,t),t&&s(wc),C(lu,t),t&&s(xc),bu[$l].d(t),t&&s(yp),cs&&cs.d(t),t&&s(zp),t&&s(Kr),C(ru),t&&s(Cc),$u[El].d(t),t&&s(Op),C(ou,t),t&&s(yc),t&&s(Pp),t&&s(zc),C(iu,t),t&&s(Oc),C(uu,t),t&&s(Pc),t&&s(Dp),t&&s(Dc),C(pu,t),t&&s(Mc),t&&s(Mp),t&&s(Ac),C(cu,t),t&&s(Nc),gu[kl].d(t),t&&s(Ap),ds&&ds.d(t),t&&s(Np),t&&s(Yr),C(du),t&&s(Tc),t&&s(pn),t&&s(Sc),C(mu,t),t&&s(Lc),C(fu,t),t&&s(Ic),t&&s(Sp)}}}const Eh={local:"classification-de-itokensi",sections:[{local:"prparation-des-donnes",sections:[{local:"le-jeu-de-donnes-conll2003",title:"Le jeu de donn\xE9es CoNLL-2003"},{local:"traitement-des-donnes",title:"Traitement des donn\xE9es"}],title:"Pr\xE9paration des donn\xE9es"},{local:"ifinetuningi-du-modle-avec-lapi-trainer",title:"<i>Finetuning</i> du mod\xE8le avec l'API `Trainer`"},{local:"ifinetuningi-du-modle-avec-keras",sections:[{local:"assemblage-des-donnes",title:"Assemblage des donn\xE9es"},{local:"dfinir-le-modle",title:"D\xE9finir le mod\xE8le"},{local:"ifinetuningi-du-modle",title:"<i>Finetuning</i> du mod\xE8le"},{local:"mtriques",title:"M\xE9triques"},{local:"dfinir-le-modle",title:"D\xE9finir le mod\xE8le"},{local:"ifinetuningi-du-modle",title:"<i>Finetuning</i> du mod\xE8le"}],title:"<i>Finetuning</i> du mod\xE8le avec Keras"},{local:"une-boucle-dentranement-personnalise",sections:[{local:"prparer-tout-pour-lentranement",title:"Pr\xE9parer tout pour l'entra\xEEnement"},{local:"boucle-dentranement",title:"Boucle d'entra\xEEnement"},{local:"utilisation-du-modle-ifinetuni",title:"Utilisation du mod\xE8le <i>finetun\xE9</i>"}],title:"Une boucle d'entra\xEEnement personnalis\xE9e"}],title:"Classification de <i>tokens</i>"};function qh(X,p,g){let v="pt";return Jv(()=>{const q=new URLSearchParams(window.location.search);g(0,v=q.get("fw")||"pt")}),[v]}class Oh extends Xv{constructor(p){super();Zv(this,p,qh,gh,Kv,{})}}export{Oh as default,Eh as metadata};
