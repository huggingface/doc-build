import{S as Ym,i as Zm,s as ef,e as l,t as n,k as d,c as r,a as o,h as a,d as t,m as c,b as _,g as i,G as s,w as E,x,y as w,q as b,o as $,B as z,M as sf,N as _o,p as kl,v as tf,n as El,L as Xm}from"../../chunks/vendor-hf-doc-builder.js";import{T as va}from"../../chunks/Tip-hf-doc-builder.js";import{Y as Ji}from"../../chunks/Youtube-hf-doc-builder.js";import{I as zt}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as L}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as Jm}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as nf}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function af(Y){let p,g;return p=new Jm({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter7/section4_tf.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter7/section4_tf.ipynb"}]}}),{c(){E(p.$$.fragment)},l(h){x(p.$$.fragment,h)},m(h,y){w(p,h,y),g=!0},i(h){g||(b(p.$$.fragment,h),g=!0)},o(h){$(p.$$.fragment,h),g=!1},d(h){z(p,h)}}}function lf(Y){let p,g;return p=new Jm({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter7/section4_pt.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter7/section4_pt.ipynb"}]}}),{c(){E(p.$$.fragment)},l(h){x(p.$$.fragment,h)},m(h,y){w(p,h,y),g=!0},i(h){g||(b(p.$$.fragment,h),g=!0)},o(h){$(p.$$.fragment,h),g=!1},d(h){z(p,h)}}}function rf(Y){let p,g,h,y,T;return{c(){p=l("p"),g=n("\u270F\uFE0F "),h=l("strong"),y=n("Votre tour !"),T=n(" Un autre mot anglais souvent utilis\xE9 en fran\xE7ais est \u201Cemail\u201D. Trouvez le premier \xE9chantillon dans l\u2019ensemble de donn\xE9es d\u2019entra\xEEnement qui utilise ce mot. Comment est-il traduit ? Comment le mod\xE8le pr\xE9-entra\xEEn\xE9 traduit-il la m\xEAme phrase anglaise ?")},l(v){p=r(v,"P",{});var C=o(p);g=a(C,"\u270F\uFE0F "),h=r(C,"STRONG",{});var S=o(h);y=a(S,"Votre tour !"),S.forEach(t),T=a(C," Un autre mot anglais souvent utilis\xE9 en fran\xE7ais est \u201Cemail\u201D. Trouvez le premier \xE9chantillon dans l\u2019ensemble de donn\xE9es d\u2019entra\xEEnement qui utilise ce mot. Comment est-il traduit ? Comment le mod\xE8le pr\xE9-entra\xEEn\xE9 traduit-il la m\xEAme phrase anglaise ?"),C.forEach(t)},m(v,C){i(v,p,C),s(p,g),s(p,h),s(h,y),s(p,T)},d(v){v&&t(p)}}}function of(Y){let p,g,h,y,T,v,C,S,P,A,R,k,D,M;return{c(){p=l("p"),g=n("\u{1F4A1} Si vous utilisez un "),h=l("em"),y=n("tokenizer"),T=n(" multilingue tel que mBART, mBART-50, ou M2M100, vous devrez d\xE9finir les codes de langue de vos entr\xE9es et cibles dans le "),v=l("em"),C=n("tokenizer"),S=n(" en d\xE9finissant "),P=l("code"),A=n("tokenizer.src_lang"),R=n(" et "),k=l("code"),D=n("tokenizer.tgt_lang"),M=n(" aux bonnes valeurs.")},l(F){p=r(F,"P",{});var U=o(p);g=a(U,"\u{1F4A1} Si vous utilisez un "),h=r(U,"EM",{});var G=o(h);y=a(G,"tokenizer"),G.forEach(t),T=a(U," multilingue tel que mBART, mBART-50, ou M2M100, vous devrez d\xE9finir les codes de langue de vos entr\xE9es et cibles dans le "),v=r(U,"EM",{});var O=o(v);C=a(O,"tokenizer"),O.forEach(t),S=a(U," en d\xE9finissant "),P=r(U,"CODE",{});var V=o(P);A=a(V,"tokenizer.src_lang"),V.forEach(t),R=a(U," et "),k=r(U,"CODE",{});var X=o(k);D=a(X,"tokenizer.tgt_lang"),X.forEach(t),M=a(U," aux bonnes valeurs."),U.forEach(t)},m(F,U){i(F,p,U),s(p,g),s(p,h),s(h,y),s(p,T),s(p,v),s(v,C),s(p,S),s(p,P),s(P,A),s(p,R),s(p,k),s(k,D),s(p,M)},d(F){F&&t(p)}}}function uf(Y){let p,g,h,y,T,v,C,S,P,A,R;return{c(){p=l("p"),g=n("\u{1F4A1} Si vous utilisez un mod\xE8le T5 (plus pr\xE9cis\xE9ment, un des points de contr\xF4le "),h=l("code"),y=n("t5-xxx"),T=n("), le mod\xE8le s\u2019attendra \xE0 ce que les entr\xE9es de texte aient un pr\xE9fixe indiquant la t\xE2che \xE0 accomplir, comme Si vous utilisez un mod\xE8le T5 (plus pr\xE9cis\xE9ment, un des points de contr\xF4le "),v=l("code"),C=n("t5-xxx"),S=n("), le mod\xE8le s\u2019attendra \xE0 ce que les entr\xE9es de texte aient un pr\xE9fixe indiquant la t\xE2che \xE0 accomplir, comme "),P=l("code"),A=n("translate : Anglais vers Fran\xE7ais:"),R=n("..")},l(k){p=r(k,"P",{});var D=o(p);g=a(D,"\u{1F4A1} Si vous utilisez un mod\xE8le T5 (plus pr\xE9cis\xE9ment, un des points de contr\xF4le "),h=r(D,"CODE",{});var M=o(h);y=a(M,"t5-xxx"),M.forEach(t),T=a(D,"), le mod\xE8le s\u2019attendra \xE0 ce que les entr\xE9es de texte aient un pr\xE9fixe indiquant la t\xE2che \xE0 accomplir, comme Si vous utilisez un mod\xE8le T5 (plus pr\xE9cis\xE9ment, un des points de contr\xF4le "),v=r(D,"CODE",{});var F=o(v);C=a(F,"t5-xxx"),F.forEach(t),S=a(D,"), le mod\xE8le s\u2019attendra \xE0 ce que les entr\xE9es de texte aient un pr\xE9fixe indiquant la t\xE2che \xE0 accomplir, comme "),P=r(D,"CODE",{});var U=o(P);A=a(U,"translate : Anglais vers Fran\xE7ais:"),U.forEach(t),R=a(D,".."),D.forEach(t)},m(k,D){i(k,p,D),s(p,g),s(p,h),s(h,y),s(p,T),s(p,v),s(v,C),s(p,S),s(p,P),s(P,A),s(p,R)},d(k){k&&t(p)}}}function pf(Y){let p,g,h,y,T,v,C,S,P,A,R,k,D,M,F,U,G,O,V,X,H,q,J,W,te,Q;return{c(){p=l("p"),g=n("\u26A0\uFE0F Nous ne faisons pas attention au masque d\u2019attention des cibles, car le mod\xE8le ne s\u2019y attend pas. Au lieu de cela, les \xE9tiquettes correspondant \xE0 un "),h=l("em"),y=n("token"),T=n(" de "),v=l("em"),C=n("padding"),S=n(" doivent \xEAtre mises \xE0 "),P=l("code"),A=n("-100"),R=n(" afin qu\u2019elles soient ignor\xE9es dans le calcul de la perte. Cela sera fait par notre collateur de donn\xE9es plus tard puisque nous appliquons le "),k=l("em"),D=n("padding"),M=n(" dynamique, mais si vous utilisez le "),F=l("em"),U=n("padding"),G=n(" ici, vous devriez adapter la fonction de pr\xE9traitement pour mettre tous les labels qui correspondent au "),O=l("em"),V=n("token"),X=n(" de "),H=l("em"),q=n("padding"),J=n(" \xE0 "),W=l("code"),te=n("-100"),Q=n(".")},l(Z){p=r(Z,"P",{});var B=o(p);g=a(B,"\u26A0\uFE0F Nous ne faisons pas attention au masque d\u2019attention des cibles, car le mod\xE8le ne s\u2019y attend pas. Au lieu de cela, les \xE9tiquettes correspondant \xE0 un "),h=r(B,"EM",{});var fe=o(h);y=a(fe,"token"),fe.forEach(t),T=a(B," de "),v=r(B,"EM",{});var se=o(v);C=a(se,"padding"),se.forEach(t),S=a(B," doivent \xEAtre mises \xE0 "),P=r(B,"CODE",{});var he=o(P);A=a(he,"-100"),he.forEach(t),R=a(B," afin qu\u2019elles soient ignor\xE9es dans le calcul de la perte. Cela sera fait par notre collateur de donn\xE9es plus tard puisque nous appliquons le "),k=r(B,"EM",{});var be=o(k);D=a(be,"padding"),be.forEach(t),M=a(B," dynamique, mais si vous utilisez le "),F=r(B,"EM",{});var _e=o(F);U=a(_e,"padding"),_e.forEach(t),G=a(B," ici, vous devriez adapter la fonction de pr\xE9traitement pour mettre tous les labels qui correspondent au "),O=r(B,"EM",{});var oe=o(O);V=a(oe,"token"),oe.forEach(t),X=a(B," de "),H=r(B,"EM",{});var re=o(H);q=a(re,"padding"),re.forEach(t),J=a(B," \xE0 "),W=r(B,"CODE",{});var K=o(W);te=a(K,"-100"),K.forEach(t),Q=a(B,"."),B.forEach(t)},m(Z,B){i(Z,p,B),s(p,g),s(p,h),s(h,y),s(p,T),s(p,v),s(v,C),s(p,S),s(p,P),s(P,A),s(p,R),s(p,k),s(k,D),s(p,M),s(p,F),s(F,U),s(p,G),s(p,O),s(O,V),s(p,X),s(p,H),s(H,q),s(p,J),s(p,W),s(W,te),s(p,Q)},d(Z){Z&&t(p)}}}function df(Y){let p,g,h,y,T,v,C,S,P,A,R,k,D,M,F,U,G,O,V,X,H;return y=new zt({}),O=new L({props:{code:`from transformers import TFAutoModelForSeq2SeqLM

model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint, from_pt=True)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSeq2SeqLM

model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint, from_pt=<span class="hljs-literal">True</span>)`}}),X=new va({props:{warning:!1,$$slots:{default:[mf]},$$scope:{ctx:Y}}}),{c(){p=l("h2"),g=l("a"),h=l("span"),E(y.$$.fragment),T=d(),v=l("span"),C=n("*Finetuning* du mod\xE8le avec Keras"),S=d(),P=l("p"),A=n("Tout d\u2019abord, nous avons besoin d\u2019un mod\xE8le r\xE9el \xE0 "),R=l("em"),k=n("finetuner"),D=n(". Nous allons utiliser l\u2019API habituelle "),M=l("code"),F=n("AutoModel"),U=n(" :"),G=d(),E(O.$$.fragment),V=d(),E(X.$$.fragment),this.h()},l(q){p=r(q,"H2",{class:!0});var J=o(p);g=r(J,"A",{id:!0,class:!0,href:!0});var W=o(g);h=r(W,"SPAN",{});var te=o(h);x(y.$$.fragment,te),te.forEach(t),W.forEach(t),T=c(J),v=r(J,"SPAN",{});var Q=o(v);C=a(Q,"*Finetuning* du mod\xE8le avec Keras"),Q.forEach(t),J.forEach(t),S=c(q),P=r(q,"P",{});var Z=o(P);A=a(Z,"Tout d\u2019abord, nous avons besoin d\u2019un mod\xE8le r\xE9el \xE0 "),R=r(Z,"EM",{});var B=o(R);k=a(B,"finetuner"),B.forEach(t),D=a(Z,". Nous allons utiliser l\u2019API habituelle "),M=r(Z,"CODE",{});var fe=o(M);F=a(fe,"AutoModel"),fe.forEach(t),U=a(Z," :"),Z.forEach(t),G=c(q),x(O.$$.fragment,q),V=c(q),x(X.$$.fragment,q),this.h()},h(){_(g,"id","finetuning-du-modle-avec-keras"),_(g,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(g,"href","#finetuning-du-modle-avec-keras"),_(p,"class","relative group")},m(q,J){i(q,p,J),s(p,g),s(g,h),w(y,h,null),s(p,T),s(p,v),s(v,C),i(q,S,J),i(q,P,J),s(P,A),s(P,R),s(R,k),s(P,D),s(P,M),s(M,F),s(P,U),i(q,G,J),w(O,q,J),i(q,V,J),w(X,q,J),H=!0},i(q){H||(b(y.$$.fragment,q),b(O.$$.fragment,q),b(X.$$.fragment,q),H=!0)},o(q){$(y.$$.fragment,q),$(O.$$.fragment,q),$(X.$$.fragment,q),H=!1},d(q){q&&t(p),z(y),q&&t(S),q&&t(P),q&&t(G),z(O,q),q&&t(V),z(X,q)}}}function cf(Y){let p,g,h,y,T,v,C,S,P,A,R,k,D,M,F,U,G,O,V,X,H,q,J,W,te,Q,Z,B,fe,se,he,be,_e,oe,re;return y=new zt({}),oe=new L({props:{code:`from transformers import AutoModelForSeq2SeqLM

model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSeq2SeqLM

model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)`}}),{c(){p=l("h2"),g=l("a"),h=l("span"),E(y.$$.fragment),T=d(),v=l("span"),C=n("*Finetuner* le mod\xE8le avec l'API "),S=l("code"),P=n("Trainer"),A=n("."),R=d(),k=l("p"),D=n("Le code actuel utilisant le "),M=l("code"),F=n("Trainer"),U=n(" sera le m\xEAme que pr\xE9c\xE9demment, avec juste un petit changement : nous utilisons ici un "),G=l("a"),O=l("code"),V=n("Seq2SeqTrainer"),X=n(", qui est une sous-classe de "),H=l("code"),q=n("Trainer"),J=n(" qui nous permettra de traiter correctement l\u2019\xE9valuation, en utilisant la m\xE9thode "),W=l("code"),te=n("generate()"),Q=n(" pour pr\xE9dire les sorties \xE0 partir des entr\xE9es. Nous y reviendrons plus en d\xE9tail lorsque nous parlerons du calcul de la m\xE9trique."),Z=d(),B=l("p"),fe=n("Tout d\u2019abord, nous avons besoin d\u2019un mod\xE8le r\xE9el \xE0 affiner. Nous allons utiliser l\u2019API habituelle "),se=l("code"),he=n("AutoModel"),be=n(" :"),_e=d(),E(oe.$$.fragment),this.h()},l(K){p=r(K,"H2",{class:!0});var ie=o(p);g=r(ie,"A",{id:!0,class:!0,href:!0});var Ae=o(g);h=r(Ae,"SPAN",{});var de=o(h);x(y.$$.fragment,de),de.forEach(t),Ae.forEach(t),T=c(ie),v=r(ie,"SPAN",{});var ee=o(v);C=a(ee,"*Finetuner* le mod\xE8le avec l'API "),S=r(ee,"CODE",{});var ge=o(S);P=a(ge,"Trainer"),ge.forEach(t),A=a(ee,"."),ee.forEach(t),ie.forEach(t),R=c(K),k=r(K,"P",{});var ue=o(k);D=a(ue,"Le code actuel utilisant le "),M=r(ue,"CODE",{});var ne=o(M);F=a(ne,"Trainer"),ne.forEach(t),U=a(ue," sera le m\xEAme que pr\xE9c\xE9demment, avec juste un petit changement : nous utilisons ici un "),G=r(ue,"A",{href:!0,rel:!0});var Ne=o(G);O=r(Ne,"CODE",{});var me=o(O);V=a(me,"Seq2SeqTrainer"),me.forEach(t),Ne.forEach(t),X=a(ue,", qui est une sous-classe de "),H=r(ue,"CODE",{});var qe=o(H);q=a(qe,"Trainer"),qe.forEach(t),J=a(ue," qui nous permettra de traiter correctement l\u2019\xE9valuation, en utilisant la m\xE9thode "),W=r(ue,"CODE",{});var ae=o(W);te=a(ae,"generate()"),ae.forEach(t),Q=a(ue," pour pr\xE9dire les sorties \xE0 partir des entr\xE9es. Nous y reviendrons plus en d\xE9tail lorsque nous parlerons du calcul de la m\xE9trique."),ue.forEach(t),Z=c(K),B=r(K,"P",{});var ce=o(B);fe=a(ce,"Tout d\u2019abord, nous avons besoin d\u2019un mod\xE8le r\xE9el \xE0 affiner. Nous allons utiliser l\u2019API habituelle "),se=r(ce,"CODE",{});var xe=o(se);he=a(xe,"AutoModel"),xe.forEach(t),be=a(ce," :"),ce.forEach(t),_e=c(K),x(oe.$$.fragment,K),this.h()},h(){_(g,"id","finetuner-le-modle-avec-lapi-trainer"),_(g,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(g,"href","#finetuner-le-modle-avec-lapi-trainer"),_(p,"class","relative group"),_(G,"href","https://huggingface.co/transformers/main_classes/trainer.html#seq2seqtrainer"),_(G,"rel","nofollow")},m(K,ie){i(K,p,ie),s(p,g),s(g,h),w(y,h,null),s(p,T),s(p,v),s(v,C),s(v,S),s(S,P),s(v,A),i(K,R,ie),i(K,k,ie),s(k,D),s(k,M),s(M,F),s(k,U),s(k,G),s(G,O),s(O,V),s(k,X),s(k,H),s(H,q),s(k,J),s(k,W),s(W,te),s(k,Q),i(K,Z,ie),i(K,B,ie),s(B,fe),s(B,se),s(se,he),s(B,be),i(K,_e,ie),w(oe,K,ie),re=!0},i(K){re||(b(y.$$.fragment,K),b(oe.$$.fragment,K),re=!0)},o(K){$(y.$$.fragment,K),$(oe.$$.fragment,K),re=!1},d(K){K&&t(p),z(y),K&&t(R),K&&t(k),K&&t(Z),K&&t(B),K&&t(_e),z(oe,K)}}}function mf(Y){let p,g,h,y,T,v,C,S,P,A,R,k,D,M,F,U,G,O,V,X;return{c(){p=l("p"),g=n("\u{1F4A1} Le "),h=l("em"),y=n("checkpoint"),T=d(),v=l("code"),C=n("Helsinki-NLP/opus-mt-en-fr"),S=n(` ne dispose que de poids PyTorch, donc vous aurez une erreur si vous essayez de charger le mod\xE8le sans utiliser l\u2019argument
`),P=l("code"),A=n("from_pt=True"),R=n(" dans la m\xE9thode "),k=l("code"),D=n("from_pretrained()"),M=n(". Lorsque vous sp\xE9cifiez "),F=l("code"),U=n("from_pt=True"),G=n(", la biblioth\xE8que t\xE9l\xE9chargera et convertira automatiquement les poids PyTorch pour vous. Comme vous pouvez le constater, il est tr\xE8s simple de passer d\u2019un framework \xE0 l\u2019autre dans \u{1F917} "),O=l("em"),V=n("Transformers"),X=n(" !")},l(H){p=r(H,"P",{});var q=o(p);g=a(q,"\u{1F4A1} Le "),h=r(q,"EM",{});var J=o(h);y=a(J,"checkpoint"),J.forEach(t),T=c(q),v=r(q,"CODE",{});var W=o(v);C=a(W,"Helsinki-NLP/opus-mt-en-fr"),W.forEach(t),S=a(q,` ne dispose que de poids PyTorch, donc vous aurez une erreur si vous essayez de charger le mod\xE8le sans utiliser l\u2019argument
`),P=r(q,"CODE",{});var te=o(P);A=a(te,"from_pt=True"),te.forEach(t),R=a(q," dans la m\xE9thode "),k=r(q,"CODE",{});var Q=o(k);D=a(Q,"from_pretrained()"),Q.forEach(t),M=a(q,". Lorsque vous sp\xE9cifiez "),F=r(q,"CODE",{});var Z=o(F);U=a(Z,"from_pt=True"),Z.forEach(t),G=a(q,", la biblioth\xE8que t\xE9l\xE9chargera et convertira automatiquement les poids PyTorch pour vous. Comme vous pouvez le constater, il est tr\xE8s simple de passer d\u2019un framework \xE0 l\u2019autre dans \u{1F917} "),O=r(q,"EM",{});var B=o(O);V=a(B,"Transformers"),B.forEach(t),X=a(q," !"),q.forEach(t)},m(H,q){i(H,p,q),s(p,g),s(p,h),s(h,y),s(p,T),s(p,v),s(v,C),s(p,S),s(p,P),s(P,A),s(p,R),s(p,k),s(k,D),s(p,M),s(p,F),s(F,U),s(p,G),s(p,O),s(O,V),s(p,X)},d(H){H&&t(p)}}}function ff(Y){let p,g;return p=new L({props:{code:`from transformers import DataCollatorForSeq2Seq

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors="tf")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForSeq2Seq

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`}}),{c(){E(p.$$.fragment)},l(h){x(p.$$.fragment,h)},m(h,y){w(p,h,y),g=!0},i(h){g||(b(p.$$.fragment,h),g=!0)},o(h){$(p.$$.fragment,h),g=!1},d(h){z(p,h)}}}function hf(Y){let p,g;return p=new L({props:{code:`from transformers import DataCollatorForSeq2Seq

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForSeq2Seq

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)`}}),{c(){E(p.$$.fragment)},l(h){x(p.$$.fragment,h)},m(h,y){w(p,h,y),g=!0},i(h){g||(b(p.$$.fragment,h),g=!0)},o(h){$(p.$$.fragment,h),g=!1},d(h){z(p,h)}}}function _f(Y){let p,g,h,y,T,v,C,S,P,A,R;return A=new L({props:{code:`tf_train_dataset = tokenized_datasets["train"].to_tf_dataset(
    columns=["input_ids", "attention_mask", "labels"],
    collate_fn=data_collator,
    shuffle=True,
    batch_size=32,
)
tf_eval_dataset = tokenized_datasets["validation"].to_tf_dataset(
    columns=["input_ids", "attention_mask", "labels"],
    collate_fn=data_collator,
    shuffle=False,
    batch_size=16,
)`,highlighted:`tf_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].to_tf_dataset(
    columns=[<span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>],
    collate_fn=data_collator,
    shuffle=<span class="hljs-literal">True</span>,
    batch_size=<span class="hljs-number">32</span>,
)
tf_eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>].to_tf_dataset(
    columns=[<span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>],
    collate_fn=data_collator,
    shuffle=<span class="hljs-literal">False</span>,
    batch_size=<span class="hljs-number">16</span>,
)`}}),{c(){p=l("p"),g=n("Nous pouvons maintenant utiliser ce "),h=l("code"),y=n("data_collator"),T=n(" pour convertir chacun de nos jeux de donn\xE9es en un "),v=l("code"),C=n("tf.data.Dataset"),S=n(", pr\xEAt pour l\u2019entra\xEEnement :"),P=d(),E(A.$$.fragment)},l(k){p=r(k,"P",{});var D=o(p);g=a(D,"Nous pouvons maintenant utiliser ce "),h=r(D,"CODE",{});var M=o(h);y=a(M,"data_collator"),M.forEach(t),T=a(D," pour convertir chacun de nos jeux de donn\xE9es en un "),v=r(D,"CODE",{});var F=o(v);C=a(F,"tf.data.Dataset"),F.forEach(t),S=a(D,", pr\xEAt pour l\u2019entra\xEEnement :"),D.forEach(t),P=c(k),x(A.$$.fragment,k)},m(k,D){i(k,p,D),s(p,g),s(p,h),s(h,y),s(p,T),s(p,v),s(v,C),s(p,S),i(k,P,D),w(A,k,D),R=!0},i(k){R||(b(A.$$.fragment,k),R=!0)},o(k){$(A.$$.fragment,k),R=!1},d(k){k&&t(p),k&&t(P),z(A,k)}}}function vf(Y){let p,g,h,y,T,v,C,S;return{c(){p=l("p"),g=n("Nous allons transmettre ce "),h=l("code"),y=n("data_collator"),T=n(" au "),v=l("code"),C=n("Seq2SeqTrainer"),S=n(". Ensuite, jetons un coup d\u2019oeil \xE0 la m\xE9trique.")},l(P){p=r(P,"P",{});var A=o(p);g=a(A,"Nous allons transmettre ce "),h=r(A,"CODE",{});var R=o(h);y=a(R,"data_collator"),R.forEach(t),T=a(A," au "),v=r(A,"CODE",{});var k=o(v);C=a(k,"Seq2SeqTrainer"),k.forEach(t),S=a(A,". Ensuite, jetons un coup d\u2019oeil \xE0 la m\xE9trique."),A.forEach(t)},m(P,A){i(P,p,A),s(p,g),s(p,h),s(h,y),s(p,T),s(p,v),s(v,C),s(p,S)},i:Xm,o:Xm,d(P){P&&t(p)}}}function Wm(Y){let p,g,h,y,T,v,C,S,P,A,R,k,D,M,F,U,G,O,V,X,H,q,J,W,te,Q,Z,B,fe,se,he,be,_e,oe,re,K,ie,Ae;return{c(){p=l("p"),g=n("La fonctionnalit\xE9 que "),h=l("code"),y=n("Seq2SeqTrainer"),T=n(" ajoute \xE0 sa superclasse "),v=l("code"),C=n("Trainer"),S=n(" est la possibilit\xE9 d\u2019utiliser la m\xE9thode "),P=l("code"),A=n("generate()"),R=n(" pendant l\u2019\xE9valuation ou la pr\xE9diction. Pendant l\u2019entra\xEEnement, le mod\xE8le utilisera les "),k=l("code"),D=n("decoder_input_ids"),M=n(" avec un masque d\u2019attention assurant qu\u2019il n\u2019utilise pas les "),F=l("em"),U=n("tokens"),G=n(" apr\xE8s le "),O=l("em"),V=n("token"),X=n(" qu\u2019il essaie de pr\xE9dire, pour acc\xE9l\xE9rer l\u2019entra\xEEnement. Pendant l\u2019inf\xE9rence, nous ne pourrons pas les utiliser puisque nous n\u2019aurons pas d\u2019\xE9tiquettes, donc c\u2019est une bonne id\xE9e d\u2019\xE9valuer notre mod\xE8le avec la m\xEAme configuration."),H=d(),q=l("p"),J=n("Comme nous l\u2019avons vu dans le "),W=l("a"),te=n("Chapitre 1"),Q=n(", le d\xE9codeur effectue l\u2019inf\xE9rence en pr\xE9disant les "),Z=l("em"),B=n("tokens"),fe=n(" un par un. Quelque chose qui est impl\xE9ment\xE9 en coulisses dans les \u{1F917} Transformers par la m\xE9thode "),se=l("code"),he=n("generate()"),be=n(". Le "),_e=l("code"),oe=n("Seq2SeqTrainer"),re=n(" nous laissera utiliser cette m\xE9thode pour l\u2019\xE9valuation si nous d\xE9finissons "),K=l("code"),ie=n("predict_with_generate=True"),Ae=n("."),this.h()},l(de){p=r(de,"P",{});var ee=o(p);g=a(ee,"La fonctionnalit\xE9 que "),h=r(ee,"CODE",{});var ge=o(h);y=a(ge,"Seq2SeqTrainer"),ge.forEach(t),T=a(ee," ajoute \xE0 sa superclasse "),v=r(ee,"CODE",{});var ue=o(v);C=a(ue,"Trainer"),ue.forEach(t),S=a(ee," est la possibilit\xE9 d\u2019utiliser la m\xE9thode "),P=r(ee,"CODE",{});var ne=o(P);A=a(ne,"generate()"),ne.forEach(t),R=a(ee," pendant l\u2019\xE9valuation ou la pr\xE9diction. Pendant l\u2019entra\xEEnement, le mod\xE8le utilisera les "),k=r(ee,"CODE",{});var Ne=o(k);D=a(Ne,"decoder_input_ids"),Ne.forEach(t),M=a(ee," avec un masque d\u2019attention assurant qu\u2019il n\u2019utilise pas les "),F=r(ee,"EM",{});var me=o(F);U=a(me,"tokens"),me.forEach(t),G=a(ee," apr\xE8s le "),O=r(ee,"EM",{});var qe=o(O);V=a(qe,"token"),qe.forEach(t),X=a(ee," qu\u2019il essaie de pr\xE9dire, pour acc\xE9l\xE9rer l\u2019entra\xEEnement. Pendant l\u2019inf\xE9rence, nous ne pourrons pas les utiliser puisque nous n\u2019aurons pas d\u2019\xE9tiquettes, donc c\u2019est une bonne id\xE9e d\u2019\xE9valuer notre mod\xE8le avec la m\xEAme configuration."),ee.forEach(t),H=c(de),q=r(de,"P",{});var ae=o(q);J=a(ae,"Comme nous l\u2019avons vu dans le "),W=r(ae,"A",{href:!0});var ce=o(W);te=a(ce,"Chapitre 1"),ce.forEach(t),Q=a(ae,", le d\xE9codeur effectue l\u2019inf\xE9rence en pr\xE9disant les "),Z=r(ae,"EM",{});var xe=o(Z);B=a(xe,"tokens"),xe.forEach(t),fe=a(ae," un par un. Quelque chose qui est impl\xE9ment\xE9 en coulisses dans les \u{1F917} Transformers par la m\xE9thode "),se=r(ae,"CODE",{});var Ye=o(se);he=a(Ye,"generate()"),Ye.forEach(t),be=a(ae,". Le "),_e=r(ae,"CODE",{});var Pe=o(_e);oe=a(Pe,"Seq2SeqTrainer"),Pe.forEach(t),re=a(ae," nous laissera utiliser cette m\xE9thode pour l\u2019\xE9valuation si nous d\xE9finissons "),K=r(ae,"CODE",{});var pe=o(K);ie=a(pe,"predict_with_generate=True"),pe.forEach(t),Ae=a(ae,"."),ae.forEach(t),this.h()},h(){_(W,"href","/course/fr/chapter1/6")},m(de,ee){i(de,p,ee),s(p,g),s(p,h),s(h,y),s(p,T),s(p,v),s(v,C),s(p,S),s(p,P),s(P,A),s(p,R),s(p,k),s(k,D),s(p,M),s(p,F),s(F,U),s(p,G),s(p,O),s(O,V),s(p,X),i(de,H,ee),i(de,q,ee),s(q,J),s(q,W),s(W,te),s(q,Q),s(q,Z),s(Z,B),s(q,fe),s(q,se),s(se,he),s(q,be),s(q,_e),s(_e,oe),s(q,re),s(q,K),s(K,ie),s(q,Ae)},d(de){de&&t(p),de&&t(H),de&&t(q)}}}function bf(Y){let p,g,h,y,T,v,C,S,P,A,R;return A=new L({props:{code:`import numpy as np


def compute_metrics(eval_preds):
    preds, labels = eval_preds
    # In case the model returns more than the prediction logits
    if isinstance(preds, tuple):
        preds = preds[0]

    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)

    # Replace -100s in the labels as we can't decode them
    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)

    # Some simple post-processing
    decoded_preds = [pred.strip() for pred in decoded_preds]
    decoded_labels = [[label.strip()] for label in decoded_labels]

    result = metric.compute(predictions=decoded_preds, references=decoded_labels)
    return {"bleu": result["score"]}`,highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np


<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_preds</span>):
    preds, labels = eval_preds
    <span class="hljs-comment"># In case the model returns more than the prediction logits</span>
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(preds, <span class="hljs-built_in">tuple</span>):
        preds = preds[<span class="hljs-number">0</span>]

    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=<span class="hljs-literal">True</span>)

    <span class="hljs-comment"># Replace -100s in the labels as we can&#x27;t decode them</span>
    labels = np.where(labels != -<span class="hljs-number">100</span>, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=<span class="hljs-literal">True</span>)

    <span class="hljs-comment"># Some simple post-processing</span>
    decoded_preds = [pred.strip() <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> decoded_preds]
    decoded_labels = [[label.strip()] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> decoded_labels]

    result = metric.compute(predictions=decoded_preds, references=decoded_labels)
    <span class="hljs-keyword">return</span> {<span class="hljs-string">&quot;bleu&quot;</span>: result[<span class="hljs-string">&quot;score&quot;</span>]}`}}),{c(){p=l("p"),g=n("Pour passer des sorties du mod\xE8le aux textes utilisables par la m\xE9trique, nous allons utiliser la m\xE9thode "),h=l("code"),y=n("tokenizer.batch_decode()"),T=n(". Nous devons juste nettoyer tous les "),v=l("code"),C=n("-100"),S=n("s dans les \xE9tiquettes (le tokenizer fera automatiquement la m\xEAme chose pour le token de remplissage) :"),P=d(),E(A.$$.fragment)},l(k){p=r(k,"P",{});var D=o(p);g=a(D,"Pour passer des sorties du mod\xE8le aux textes utilisables par la m\xE9trique, nous allons utiliser la m\xE9thode "),h=r(D,"CODE",{});var M=o(h);y=a(M,"tokenizer.batch_decode()"),M.forEach(t),T=a(D,". Nous devons juste nettoyer tous les "),v=r(D,"CODE",{});var F=o(v);C=a(F,"-100"),F.forEach(t),S=a(D,"s dans les \xE9tiquettes (le tokenizer fera automatiquement la m\xEAme chose pour le token de remplissage) :"),D.forEach(t),P=c(k),x(A.$$.fragment,k)},m(k,D){i(k,p,D),s(p,g),s(p,h),s(h,y),s(p,T),s(p,v),s(v,C),s(p,S),i(k,P,D),w(A,k,D),R=!0},i(k){R||(b(A.$$.fragment,k),R=!0)},o(k){$(A.$$.fragment,k),R=!1},d(k){k&&t(p),k&&t(P),z(A,k)}}}function $f(Y){let p,g,h,y,T,v,C,S,P,A,R,k,D,M,F,U,G,O,V,X;return V=new L({props:{code:`import numpy as np


def compute_metrics():
    all_preds = []
    all_labels = []
    sampled_dataset = tokenized_datasets["validation"].shuffle().select(range(200))
    tf_generate_dataset = sampled_dataset.to_tf_dataset(
        columns=["input_ids", "attention_mask", "labels"],
        collate_fn=data_collator,
        shuffle=False,
        batch_size=4,
    )
    for batch in tf_generate_dataset:
        predictions = model.generate(
            input_ids=batch["input_ids"], attention_mask=batch["attention_mask"]
        )
        decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)
        labels = batch["labels"].numpy()
        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)
        decoded_preds = [pred.strip() for pred in decoded_preds]
        decoded_labels = [[label.strip()] for label in decoded_labels]
        all_preds.extend(decoded_preds)
        all_labels.extend(decoded_labels)

    result = metric.compute(predictions=all_preds, references=all_labels)
    return {"bleu": result["score"]}`,highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np


<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>():
    all_preds = []
    all_labels = []
    sampled_dataset = tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>].shuffle().select(<span class="hljs-built_in">range</span>(<span class="hljs-number">200</span>))
    tf_generate_dataset = sampled_dataset.to_tf_dataset(
        columns=[<span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>],
        collate_fn=data_collator,
        shuffle=<span class="hljs-literal">False</span>,
        batch_size=<span class="hljs-number">4</span>,
    )
    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> tf_generate_dataset:
        predictions = model.generate(
            input_ids=batch[<span class="hljs-string">&quot;input_ids&quot;</span>], attention_mask=batch[<span class="hljs-string">&quot;attention_mask&quot;</span>]
        )
        decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=<span class="hljs-literal">True</span>)
        labels = batch[<span class="hljs-string">&quot;labels&quot;</span>].numpy()
        labels = np.where(labels != -<span class="hljs-number">100</span>, labels, tokenizer.pad_token_id)
        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=<span class="hljs-literal">True</span>)
        decoded_preds = [pred.strip() <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> decoded_preds]
        decoded_labels = [[label.strip()] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> decoded_labels]
        all_preds.extend(decoded_preds)
        all_labels.extend(decoded_labels)

    result = metric.compute(predictions=all_preds, references=all_labels)
    <span class="hljs-keyword">return</span> {<span class="hljs-string">&quot;bleu&quot;</span>: result[<span class="hljs-string">&quot;score&quot;</span>]}`}}),{c(){p=l("p"),g=n("Pour passer des sorties du mod\xE8le aux textes que la m\xE9trique peut utiliser, nous allons utiliser la m\xE9thode "),h=l("code"),y=n("tokenizer.batch_decode()"),T=n(". Nous devons juste nettoyer tous les "),v=l("code"),C=n("-100"),S=n(" dans les \xE9tiquettes ; le "),P=l("em"),A=n("tokenizer"),R=n(" fera automatiquement la m\xEAme chose pour le "),k=l("em"),D=n("token"),M=n(" de "),F=l("em"),U=n("padding"),G=n(". D\xE9finissons une fonction qui prend notre mod\xE8le et un jeu de donn\xE9es et calcule des m\xE9triques sur ceux-ci. Comme la g\xE9n\xE9ration de longues s\xE9quences peut \xEAtre lente, nous sous-\xE9chantillonnons l\u2019ensemble de validation pour nous assurer que cela ne prend pas une \xE9ternit\xE9 :"),O=d(),E(V.$$.fragment)},l(H){p=r(H,"P",{});var q=o(p);g=a(q,"Pour passer des sorties du mod\xE8le aux textes que la m\xE9trique peut utiliser, nous allons utiliser la m\xE9thode "),h=r(q,"CODE",{});var J=o(h);y=a(J,"tokenizer.batch_decode()"),J.forEach(t),T=a(q,". Nous devons juste nettoyer tous les "),v=r(q,"CODE",{});var W=o(v);C=a(W,"-100"),W.forEach(t),S=a(q," dans les \xE9tiquettes ; le "),P=r(q,"EM",{});var te=o(P);A=a(te,"tokenizer"),te.forEach(t),R=a(q," fera automatiquement la m\xEAme chose pour le "),k=r(q,"EM",{});var Q=o(k);D=a(Q,"token"),Q.forEach(t),M=a(q," de "),F=r(q,"EM",{});var Z=o(F);U=a(Z,"padding"),Z.forEach(t),G=a(q,". D\xE9finissons une fonction qui prend notre mod\xE8le et un jeu de donn\xE9es et calcule des m\xE9triques sur ceux-ci. Comme la g\xE9n\xE9ration de longues s\xE9quences peut \xEAtre lente, nous sous-\xE9chantillonnons l\u2019ensemble de validation pour nous assurer que cela ne prend pas une \xE9ternit\xE9 :"),q.forEach(t),O=c(H),x(V.$$.fragment,H)},m(H,q){i(H,p,q),s(p,g),s(p,h),s(h,y),s(p,T),s(p,v),s(v,C),s(p,S),s(p,P),s(P,A),s(p,R),s(p,k),s(k,D),s(p,M),s(p,F),s(F,U),s(p,G),i(H,O,q),w(V,H,q),X=!0},i(H){X||(b(V.$$.fragment,H),X=!0)},o(H){$(V.$$.fragment,H),X=!1},d(H){H&&t(p),H&&t(O),z(V,H)}}}function gf(Y){let p,g,h,y,T,v,C,S,P,A,R,k,D,M,F,U,G,O,V,X,H,q,J,W,te,Q,Z,B,fe,se,he,be,_e,oe,re,K,ie,Ae,de,ee,ge,ue,ne,Ne,me,qe,ae,ce,xe,Ye,Pe,pe,Ze,os,je,Fs,Be,is,es,Le,we,ss,Ce,j,le,Oe,Ys,Xe,us,Re,Hs,ve,$e,zs,ke,ze,ys,ts,Ee,ye,Zs,et,vs,Xt,Is,We,yt,bs,ft,Qe,Ps,$s,Pt,Bs,ps,Je,gs,qs,Me,st,js,ht,De,_t,Cs,Ue,Ct,Fe,Ds,vt,ns,Wt,bt,tt,ds,Se,Rs,ks,Qt,nt,Es,$t,as,Dt,cs,Ss,ls,xs,ms,at,Ts,lt,As,Ns,St,Ke,Ls,Tt,gt;return D=new L({props:{code:`from transformers import Seq2SeqTrainingArguments

args = Seq2SeqTrainingArguments(
    f"marian-finetuned-kde4-en-to-fr",
    evaluation_strategy="no",
    save_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=32,
    per_device_eval_batch_size=64,
    weight_decay=0.01,
    save_total_limit=3,
    num_train_epochs=3,
    predict_with_generate=True,
    fp16=True,
    push_to_hub=True,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Seq2SeqTrainingArguments

args = Seq2SeqTrainingArguments(
    <span class="hljs-string">f&quot;marian-finetuned-kde4-en-to-fr&quot;</span>,
    evaluation_strategy=<span class="hljs-string">&quot;no&quot;</span>,
    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    learning_rate=<span class="hljs-number">2e-5</span>,
    per_device_train_batch_size=<span class="hljs-number">32</span>,
    per_device_eval_batch_size=<span class="hljs-number">64</span>,
    weight_decay=<span class="hljs-number">0.01</span>,
    save_total_limit=<span class="hljs-number">3</span>,
    num_train_epochs=<span class="hljs-number">3</span>,
    predict_with_generate=<span class="hljs-literal">True</span>,
    fp16=<span class="hljs-literal">True</span>,
    push_to_hub=<span class="hljs-literal">True</span>,
)`}}),ss=new va({props:{$$slots:{default:[jf]},$$scope:{ctx:Y}}}),Re=new L({props:{code:`from transformers import Seq2SeqTrainer

trainer = Seq2SeqTrainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Seq2SeqTrainer

trainer = Seq2SeqTrainer(
    model,
    args,
    train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],
    eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)`}}),ts=new L({props:{code:"trainer.evaluate(max_length=max_target_length)",highlighted:"trainer.evaluate(max_length=max_target_length)"}}),ye=new L({props:{code:`{'eval_loss': 1.6964408159255981,
 'eval_bleu': 39.26865061007616,
 'eval_runtime': 965.8884,
 'eval_samples_per_second': 21.76,
 'eval_steps_per_second': 0.341}`,highlighted:`{<span class="hljs-string">&#x27;eval_loss&#x27;</span>: <span class="hljs-number">1.6964408159255981</span>,
 <span class="hljs-string">&#x27;eval_bleu&#x27;</span>: <span class="hljs-number">39.26865061007616</span>,
 <span class="hljs-string">&#x27;eval_runtime&#x27;</span>: <span class="hljs-number">965.8884</span>,
 <span class="hljs-string">&#x27;eval_samples_per_second&#x27;</span>: <span class="hljs-number">21.76</span>,
 <span class="hljs-string">&#x27;eval_steps_per_second&#x27;</span>: <span class="hljs-number">0.341</span>}`}}),bs=new L({props:{code:"trainer.train()",highlighted:"trainer.train()"}}),Me=new L({props:{code:"trainer.evaluate(max_length=max_target_length)",highlighted:"trainer.evaluate(max_length=max_target_length)"}}),js=new L({props:{code:`{'eval_loss': 0.8558505773544312,
 'eval_bleu': 52.94161337775576,
 'eval_runtime': 714.2576,
 'eval_samples_per_second': 29.426,
 'eval_steps_per_second': 0.461,
 'epoch': 3.0}`,highlighted:`{<span class="hljs-string">&#x27;eval_loss&#x27;</span>: <span class="hljs-number">0.8558505773544312</span>,
 <span class="hljs-string">&#x27;eval_bleu&#x27;</span>: <span class="hljs-number">52.94161337775576</span>,
 <span class="hljs-string">&#x27;eval_runtime&#x27;</span>: <span class="hljs-number">714.2576</span>,
 <span class="hljs-string">&#x27;eval_samples_per_second&#x27;</span>: <span class="hljs-number">29.426</span>,
 <span class="hljs-string">&#x27;eval_steps_per_second&#x27;</span>: <span class="hljs-number">0.461</span>,
 <span class="hljs-string">&#x27;epoch&#x27;</span>: <span class="hljs-number">3.0</span>}`}}),Es=new L({props:{code:'trainer.push_to_hub(tags="translation", commit_message="Training complete")',highlighted:'trainer.push_to_hub(tags=<span class="hljs-string">&quot;translation&quot;</span>, commit_message=<span class="hljs-string">&quot;Training complete&quot;</span>)'}}),Ss=new L({props:{code:"'https://huggingface.co/sgugger/marian-finetuned-kde4-en-to-fr/commit/3601d621e3baae2bc63d3311452535f8f58f6ef3'",highlighted:'<span class="hljs-string">&#x27;https://huggingface.co/sgugger/marian-finetuned-kde4-en-to-fr/commit/3601d621e3baae2bc63d3311452535f8f58f6ef3&#x27;</span>'}}),{c(){p=l("p"),g=n("Une fois ceci fait, nous pouvons d\xE9finir notre "),h=l("code"),y=n("Seq2SeqTrainingArguments"),T=n(". Comme pour le "),v=l("code"),C=n("Trainer"),S=n(", nous utilisons une sous-classe de "),P=l("code"),A=n("TrainingArguments"),R=n(" qui contient quelques champs suppl\xE9mentaires :"),k=d(),E(D.$$.fragment),M=d(),F=l("p"),U=n("En dehors des hyperparam\xE8tres habituels (comme le taux d\u2019apprentissage, le nombre d\u2019\xE9poques, la taille du lot et une certaine d\xE9croissance des poids), voici quelques changements par rapport \xE0 ce que nous avons vu dans les sections pr\xE9c\xE9dentes :"),G=d(),O=l("ul"),V=l("li"),X=n("nous ne d\xE9finissons pas d\u2019\xE9valuation r\xE9guli\xE8re, car l\u2019\xE9valuation prend du temps ; nous allons juste \xE9valuer notre mod\xE8le une fois avant l\u2019entra\xEEnement et apr\xE8s,"),H=d(),q=l("li"),J=n("nous avons mis "),W=l("code"),te=n("fp16=True"),Q=n(", ce qui acc\xE9l\xE8re l\u2019entra\xEEnement sur les GPUs modernes,"),Z=d(),B=l("li"),fe=n("nous d\xE9finissons "),se=l("code"),he=n("predict_with_generate=True"),be=n(", comme discut\xE9 ci-dessus,"),_e=d(),oe=l("li"),re=n("nous utilisons "),K=l("code"),ie=n("push_to_hub=True"),Ae=n(" pour t\xE9l\xE9charger le mod\xE8le sur le "),de=l("em"),ee=n("Hub"),ge=n(" \xE0 la fin de chaque \xE9poque."),ue=d(),ne=l("p"),Ne=n("Notez que vous pouvez sp\xE9cifier le nom complet du r\xE9f\xE9rentiel vers lequel vous voulez pousser avec l\u2019argument "),me=l("code"),qe=n("hub_model_id"),ae=n(" (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),ce=l("a"),xe=l("code"),Ye=n("huggingface-course"),Pe=n(", nous avons ajout\xE9 "),pe=l("code"),Ze=n('hub_model_id="huggingface-course/marian-finetuned-kde4-en-to-fr"'),os=d(),je=l("code"),Fs=n("Seq2SeqTrainingArguments"),Be=n(". Par d\xE9faut, le r\xE9f\xE9rentiel utilis\xE9 sera dans votre espace de noms et nomm\xE9 d\u2019apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini, donc dans notre cas ce sera "),is=l("code"),es=n('"sgugger/marian-finetuned-kde4-en-to-fr"'),Le=n(" (qui est le mod\xE8le que nous avons li\xE9 au d\xE9but de cette section)."),we=d(),E(ss.$$.fragment),Ce=d(),j=l("p"),le=n("Enfin, nous passons tout au "),Oe=l("code"),Ys=n("Seq2SeqTrainer"),Xe=n(" :"),us=d(),E(Re.$$.fragment),Hs=d(),ve=l("p"),$e=n("Avant d\u2019entra\xEEner, nous allons d\u2019abord regarder le score obtenu par notre mod\xE8le, pour v\xE9rifier que nous n\u2019aggravons pas les choses avec notre "),zs=l("em"),ke=n("finetuning"),ze=n(". Cette commande va prendre un peu de temps, vous pouvez donc prendre un caf\xE9 pendant qu\u2019elle s\u2019ex\xE9cute :"),ys=d(),E(ts.$$.fragment),Ee=d(),E(ye.$$.fragment),Zs=d(),et=l("p"),vs=n("A BLEU score of 39 is not too bad, which reflects the fact that our model is already good at translating English sentences to French ones."),Xt=d(),Is=l("p"),We=n("Next is the training, which will also take a bit of time:"),yt=d(),E(bs.$$.fragment),ft=d(),Qe=l("p"),Ps=n("Notez que pendant l\u2019entra\xEEnement, chaque fois que le mod\xE8le est sauvegard\xE9 (ici, \xE0 chaque \xE9poque), il est t\xE9l\xE9charg\xE9 sur le "),$s=l("em"),Pt=n("Hub"),Bs=n(" en arri\xE8re-plan. De cette fa\xE7on, vous serez en mesure de reprendre votre entra\xEEnement sur une autre machine si n\xE9cessaire."),ps=d(),Je=l("p"),gs=n("Une fois l\u2019entra\xEEnement termin\xE9, nous \xE9valuons \xE0 nouveau notre mod\xE8le - avec un peu de chance, nous verrons une am\xE9lioration du score BLEU !"),qs=d(),E(Me.$$.fragment),st=d(),E(js.$$.fragment),ht=d(),De=l("p"),_t=n("C\u2019est une am\xE9lioration de pr\xE8s de 14 points, ce qui est formidable."),Cs=d(),Ue=l("p"),Ct=n("Enfin, nous utilisons la m\xE9thode "),Fe=l("code"),Ds=n("push_to_hub()"),vt=n(" pour nous assurer que nous t\xE9l\xE9chargeons la derni\xE8re version du mod\xE8le. Le "),ns=l("code"),Wt=n("Trainer"),bt=n(" r\xE9dige \xE9galement une carte mod\xE8le avec tous les r\xE9sultats de l\u2019\xE9valuation et la t\xE9l\xE9charge. Cette carte de mod\xE8le contient des m\xE9tadonn\xE9es qui aident le "),tt=l("em"),ds=n("Hub"),Se=n(" \xE0 choisir le widget pour la d\xE9mo d\u2019inf\xE9rence. Habituellement, il n\u2019y a pas besoin de dire quoi que ce soit car il peut inf\xE9rer le bon "),Rs=l("em"),ks=n("widget"),Qt=n(" \xE0 partir de la classe du mod\xE8le, mais dans ce cas, la m\xEAme classe de mod\xE8le peut \xEAtre utilis\xE9e pour toutes sortes de probl\xE8mes de s\xE9quence \xE0 s\xE9quence, donc nous sp\xE9cifions que c\u2019est un mod\xE8le de traduction :"),nt=d(),E(Es.$$.fragment),$t=d(),as=l("p"),Dt=n("Cette commande renvoie l\u2019URL du commit qu\u2019elle vient de faire, si vous voulez l\u2019inspecter :"),cs=d(),E(Ss.$$.fragment),ls=d(),xs=l("p"),ms=n("\xC0 ce stade, vous pouvez utiliser le widget d\u2019inf\xE9rence sur le Hub du mod\xE8le pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 "),at=l("em"),Ts=n("finetuner"),lt=n(" un mod\xE8le sur une t\xE2che de traduction. F\xE9licitations !"),As=d(),Ns=l("p"),St=n("Si vous souhaitez vous plonger un peu plus profond\xE9ment dans la boucle d\u2019entra\xEEnement, nous allons maintenant vous montrer comment faire la m\xEAme chose en utilisant \u{1F917} "),Ke=l("em"),Ls=n("Accelerate"),Tt=n("."),this.h()},l(f){p=r(f,"P",{});var I=o(p);g=a(I,"Une fois ceci fait, nous pouvons d\xE9finir notre "),h=r(I,"CODE",{});var Jt=o(h);y=a(Jt,"Seq2SeqTrainingArguments"),Jt.forEach(t),T=a(I,". Comme pour le "),v=r(I,"CODE",{});var rt=o(v);C=a(rt,"Trainer"),rt.forEach(t),S=a(I,", nous utilisons une sous-classe de "),P=r(I,"CODE",{});var At=o(P);A=a(At,"TrainingArguments"),At.forEach(t),R=a(I," qui contient quelques champs suppl\xE9mentaires :"),I.forEach(t),k=c(f),x(D.$$.fragment,f),M=c(f),F=r(f,"P",{});var Te=o(F);U=a(Te,"En dehors des hyperparam\xE8tres habituels (comme le taux d\u2019apprentissage, le nombre d\u2019\xE9poques, la taille du lot et une certaine d\xE9croissance des poids), voici quelques changements par rapport \xE0 ce que nous avons vu dans les sections pr\xE9c\xE9dentes :"),Te.forEach(t),G=c(f),O=r(f,"UL",{});var ws=o(O);V=r(ws,"LI",{});var He=o(V);X=a(He,"nous ne d\xE9finissons pas d\u2019\xE9valuation r\xE9guli\xE8re, car l\u2019\xE9valuation prend du temps ; nous allons juste \xE9valuer notre mod\xE8le une fois avant l\u2019entra\xEEnement et apr\xE8s,"),He.forEach(t),H=c(ws),q=r(ws,"LI",{});var Nt=o(q);J=a(Nt,"nous avons mis "),W=r(Nt,"CODE",{});var qt=o(W);te=a(qt,"fp16=True"),qt.forEach(t),Q=a(Nt,", ce qui acc\xE9l\xE8re l\u2019entra\xEEnement sur les GPUs modernes,"),Nt.forEach(t),Z=c(ws),B=r(ws,"LI",{});var ot=o(B);fe=a(ot,"nous d\xE9finissons "),se=r(ot,"CODE",{});var hn=o(se);he=a(hn,"predict_with_generate=True"),hn.forEach(t),be=a(ot,", comme discut\xE9 ci-dessus,"),ot.forEach(t),_e=c(ws),oe=r(ws,"LI",{});var Os=o(oe);re=a(Os,"nous utilisons "),K=r(Os,"CODE",{});var Lt=o(K);ie=a(Lt,"push_to_hub=True"),Lt.forEach(t),Ae=a(Os," pour t\xE9l\xE9charger le mod\xE8le sur le "),de=r(Os,"EM",{});var _n=o(de);ee=a(_n,"Hub"),_n.forEach(t),ge=a(Os," \xE0 la fin de chaque \xE9poque."),Os.forEach(t),ws.forEach(t),ue=c(f),ne=r(f,"P",{});var Ie=o(ne);Ne=a(Ie,"Notez que vous pouvez sp\xE9cifier le nom complet du r\xE9f\xE9rentiel vers lequel vous voulez pousser avec l\u2019argument "),me=r(Ie,"CODE",{});var Yt=o(me);qe=a(Yt,"hub_model_id"),Yt.forEach(t),ae=a(Ie," (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),ce=r(Ie,"A",{href:!0,rel:!0});var it=o(ce);xe=r(it,"CODE",{});var Ot=o(xe);Ye=a(Ot,"huggingface-course"),Ot.forEach(t),it.forEach(t),Pe=a(Ie,", nous avons ajout\xE9 "),pe=r(Ie,"CODE",{});var fs=o(pe);Ze=a(fs,'hub_model_id="huggingface-course/marian-finetuned-kde4-en-to-fr"'),fs.forEach(t),os=c(Ie),je=r(Ie,"CODE",{});var Mt=o(je);Fs=a(Mt,"Seq2SeqTrainingArguments"),Mt.forEach(t),Be=a(Ie,". Par d\xE9faut, le r\xE9f\xE9rentiel utilis\xE9 sera dans votre espace de noms et nomm\xE9 d\u2019apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini, donc dans notre cas ce sera "),is=r(Ie,"CODE",{});var Ve=o(is);es=a(Ve,'"sgugger/marian-finetuned-kde4-en-to-fr"'),Ve.forEach(t),Le=a(Ie," (qui est le mod\xE8le que nous avons li\xE9 au d\xE9but de cette section)."),Ie.forEach(t),we=c(f),x(ss.$$.fragment,f),Ce=c(f),j=r(f,"P",{});var jt=o(j);le=a(jt,"Enfin, nous passons tout au "),Oe=r(jt,"CODE",{});var Ks=o(Oe);Ys=a(Ks,"Seq2SeqTrainer"),Ks.forEach(t),Xe=a(jt," :"),jt.forEach(t),us=c(f),x(Re.$$.fragment,f),Hs=c(f),ve=r(f,"P",{});var Ut=o(ve);$e=a(Ut,"Avant d\u2019entra\xEEner, nous allons d\u2019abord regarder le score obtenu par notre mod\xE8le, pour v\xE9rifier que nous n\u2019aggravons pas les choses avec notre "),zs=r(Ut,"EM",{});var Zt=o(zs);ke=a(Zt,"finetuning"),Zt.forEach(t),ze=a(Ut,". Cette commande va prendre un peu de temps, vous pouvez donc prendre un caf\xE9 pendant qu\u2019elle s\u2019ex\xE9cute :"),Ut.forEach(t),ys=c(f),x(ts.$$.fragment,f),Ee=c(f),x(ye.$$.fragment,f),Zs=c(f),et=r(f,"P",{});var hs=o(et);vs=a(hs,"A BLEU score of 39 is not too bad, which reflects the fact that our model is already good at translating English sentences to French ones."),hs.forEach(t),Xt=c(f),Is=r(f,"P",{});var kt=o(Is);We=a(kt,"Next is the training, which will also take a bit of time:"),kt.forEach(t),yt=c(f),x(bs.$$.fragment,f),ft=c(f),Qe=r(f,"P",{});var Vs=o(Qe);Ps=a(Vs,"Notez que pendant l\u2019entra\xEEnement, chaque fois que le mod\xE8le est sauvegard\xE9 (ici, \xE0 chaque \xE9poque), il est t\xE9l\xE9charg\xE9 sur le "),$s=r(Vs,"EM",{});var vn=o($s);Pt=a(vn,"Hub"),vn.forEach(t),Bs=a(Vs," en arri\xE8re-plan. De cette fa\xE7on, vous serez en mesure de reprendre votre entra\xEEnement sur une autre machine si n\xE9cessaire."),Vs.forEach(t),ps=c(f),Je=r(f,"P",{});var Ft=o(Je);gs=a(Ft,"Une fois l\u2019entra\xEEnement termin\xE9, nous \xE9valuons \xE0 nouveau notre mod\xE8le - avec un peu de chance, nous verrons une am\xE9lioration du score BLEU !"),Ft.forEach(t),qs=c(f),x(Me.$$.fragment,f),st=c(f),x(js.$$.fragment,f),ht=c(f),De=r(f,"P",{});var m=o(De);_t=a(m,"C\u2019est une am\xE9lioration de pr\xE8s de 14 points, ce qui est formidable."),m.forEach(t),Cs=c(f),Ue=r(f,"P",{});var N=o(Ue);Ct=a(N,"Enfin, nous utilisons la m\xE9thode "),Fe=r(N,"CODE",{});var Et=o(Fe);Ds=a(Et,"push_to_hub()"),Et.forEach(t),vt=a(N," pour nous assurer que nous t\xE9l\xE9chargeons la derni\xE8re version du mod\xE8le. Le "),ns=r(N,"CODE",{});var bn=o(ns);Wt=a(bn,"Trainer"),bn.forEach(t),bt=a(N," r\xE9dige \xE9galement une carte mod\xE8le avec tous les r\xE9sultats de l\u2019\xE9valuation et la t\xE9l\xE9charge. Cette carte de mod\xE8le contient des m\xE9tadonn\xE9es qui aident le "),tt=r(N,"EM",{});var Ht=o(tt);ds=a(Ht,"Hub"),Ht.forEach(t),Se=a(N," \xE0 choisir le widget pour la d\xE9mo d\u2019inf\xE9rence. Habituellement, il n\u2019y a pas besoin de dire quoi que ce soit car il peut inf\xE9rer le bon "),Rs=r(N,"EM",{});var xt=o(Rs);ks=a(xt,"widget"),xt.forEach(t),Qt=a(N," \xE0 partir de la classe du mod\xE8le, mais dans ce cas, la m\xEAme classe de mod\xE8le peut \xEAtre utilis\xE9e pour toutes sortes de probl\xE8mes de s\xE9quence \xE0 s\xE9quence, donc nous sp\xE9cifions que c\u2019est un mod\xE8le de traduction :"),N.forEach(t),nt=c(f),x(Es.$$.fragment,f),$t=c(f),as=r(f,"P",{});var $n=o(as);Dt=a($n,"Cette commande renvoie l\u2019URL du commit qu\u2019elle vient de faire, si vous voulez l\u2019inspecter :"),$n.forEach(t),cs=c(f),x(Ss.$$.fragment,f),ls=c(f),xs=r(f,"P",{});var Gs=o(xs);ms=a(Gs,"\xC0 ce stade, vous pouvez utiliser le widget d\u2019inf\xE9rence sur le Hub du mod\xE8le pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 "),at=r(Gs,"EM",{});var It=o(at);Ts=a(It,"finetuner"),It.forEach(t),lt=a(Gs," un mod\xE8le sur une t\xE2che de traduction. F\xE9licitations !"),Gs.forEach(t),As=c(f),Ns=r(f,"P",{});var Xs=o(Ns);St=a(Xs,"Si vous souhaitez vous plonger un peu plus profond\xE9ment dans la boucle d\u2019entra\xEEnement, nous allons maintenant vous montrer comment faire la m\xEAme chose en utilisant \u{1F917} "),Ke=r(Xs,"EM",{});var gn=o(Ke);Ls=a(gn,"Accelerate"),gn.forEach(t),Tt=a(Xs,"."),Xs.forEach(t),this.h()},h(){_(ce,"href","https://huggingface.co/huggingface-course"),_(ce,"rel","nofollow")},m(f,I){i(f,p,I),s(p,g),s(p,h),s(h,y),s(p,T),s(p,v),s(v,C),s(p,S),s(p,P),s(P,A),s(p,R),i(f,k,I),w(D,f,I),i(f,M,I),i(f,F,I),s(F,U),i(f,G,I),i(f,O,I),s(O,V),s(V,X),s(O,H),s(O,q),s(q,J),s(q,W),s(W,te),s(q,Q),s(O,Z),s(O,B),s(B,fe),s(B,se),s(se,he),s(B,be),s(O,_e),s(O,oe),s(oe,re),s(oe,K),s(K,ie),s(oe,Ae),s(oe,de),s(de,ee),s(oe,ge),i(f,ue,I),i(f,ne,I),s(ne,Ne),s(ne,me),s(me,qe),s(ne,ae),s(ne,ce),s(ce,xe),s(xe,Ye),s(ne,Pe),s(ne,pe),s(pe,Ze),s(ne,os),s(ne,je),s(je,Fs),s(ne,Be),s(ne,is),s(is,es),s(ne,Le),i(f,we,I),w(ss,f,I),i(f,Ce,I),i(f,j,I),s(j,le),s(j,Oe),s(Oe,Ys),s(j,Xe),i(f,us,I),w(Re,f,I),i(f,Hs,I),i(f,ve,I),s(ve,$e),s(ve,zs),s(zs,ke),s(ve,ze),i(f,ys,I),w(ts,f,I),i(f,Ee,I),w(ye,f,I),i(f,Zs,I),i(f,et,I),s(et,vs),i(f,Xt,I),i(f,Is,I),s(Is,We),i(f,yt,I),w(bs,f,I),i(f,ft,I),i(f,Qe,I),s(Qe,Ps),s(Qe,$s),s($s,Pt),s(Qe,Bs),i(f,ps,I),i(f,Je,I),s(Je,gs),i(f,qs,I),w(Me,f,I),i(f,st,I),w(js,f,I),i(f,ht,I),i(f,De,I),s(De,_t),i(f,Cs,I),i(f,Ue,I),s(Ue,Ct),s(Ue,Fe),s(Fe,Ds),s(Ue,vt),s(Ue,ns),s(ns,Wt),s(Ue,bt),s(Ue,tt),s(tt,ds),s(Ue,Se),s(Ue,Rs),s(Rs,ks),s(Ue,Qt),i(f,nt,I),w(Es,f,I),i(f,$t,I),i(f,as,I),s(as,Dt),i(f,cs,I),w(Ss,f,I),i(f,ls,I),i(f,xs,I),s(xs,ms),s(xs,at),s(at,Ts),s(xs,lt),i(f,As,I),i(f,Ns,I),s(Ns,St),s(Ns,Ke),s(Ke,Ls),s(Ns,Tt),gt=!0},i(f){gt||(b(D.$$.fragment,f),b(ss.$$.fragment,f),b(Re.$$.fragment,f),b(ts.$$.fragment,f),b(ye.$$.fragment,f),b(bs.$$.fragment,f),b(Me.$$.fragment,f),b(js.$$.fragment,f),b(Es.$$.fragment,f),b(Ss.$$.fragment,f),gt=!0)},o(f){$(D.$$.fragment,f),$(ss.$$.fragment,f),$(Re.$$.fragment,f),$(ts.$$.fragment,f),$(ye.$$.fragment,f),$(bs.$$.fragment,f),$(Me.$$.fragment,f),$(js.$$.fragment,f),$(Es.$$.fragment,f),$(Ss.$$.fragment,f),gt=!1},d(f){f&&t(p),f&&t(k),z(D,f),f&&t(M),f&&t(F),f&&t(G),f&&t(O),f&&t(ue),f&&t(ne),f&&t(we),z(ss,f),f&&t(Ce),f&&t(j),f&&t(us),z(Re,f),f&&t(Hs),f&&t(ve),f&&t(ys),z(ts,f),f&&t(Ee),z(ye,f),f&&t(Zs),f&&t(et),f&&t(Xt),f&&t(Is),f&&t(yt),z(bs,f),f&&t(ft),f&&t(Qe),f&&t(ps),f&&t(Je),f&&t(qs),z(Me,f),f&&t(st),z(js,f),f&&t(ht),f&&t(De),f&&t(Cs),f&&t(Ue),f&&t(nt),z(Es,f),f&&t($t),f&&t(as),f&&t(cs),z(Ss,f),f&&t(ls),f&&t(xs),f&&t(As),f&&t(Ns)}}}function qf(Y){let p,g,h,y,T,v,C,S,P,A,R,k,D,M,F,U,G,O,V,X,H,q,J,W,te,Q,Z,B,fe,se,he,be,_e,oe,re,K,ie,Ae,de,ee,ge,ue,ne,Ne,me,qe,ae,ce,xe,Ye,Pe,pe,Ze,os,je,Fs,Be,is,es,Le,we,ss,Ce;return y=new L({props:{code:"print(compute_metrics())",highlighted:'<span class="hljs-built_in">print</span>(compute_metrics())'}}),v=new L({props:{code:"{'bleu': 33.26983701454733}",highlighted:'{&#x27;bleu&#x27;: <span class="hljs-number">33.26983701454733</span>}'}}),M=new L({props:{code:`from transformers import create_optimizer
from transformers.keras_callbacks import PushToHubCallback
import tensorflow as tf

# Le nombre d'\xE9tapes d'entra\xEEnement est le nombre d'\xE9chantillons dans l'ensemble de donn\xE9es, divis\xE9 par la taille du lot, puis multipli\xE9 par le nombre total d'\xE9poques.
# par le nombre total d'\xE9poques. Notez que le jeu de donn\xE9es tf_train_dataset est ici un lot tf.data.Dataset,
# et non le jeu de donn\xE9es original Hugging Face Dataset, donc son len() est d\xE9j\xE0 num_samples // batch_size.
num_epochs = 3
num_train_steps = len(tf_train_dataset) * num_epochs

optimizer, schedule = create_optimizer(
    init_lr=5e-5,
    num_warmup_steps=0,
    num_train_steps=num_train_steps,
    weight_decay_rate=0.01,
)
model.compile(optimizer=optimizer)

# Entra\xEEner en mixed-precision float16
tf.keras.mixed_precision.set_global_policy("mixed_float16")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> create_optimizer
<span class="hljs-keyword">from</span> transformers.keras_callbacks <span class="hljs-keyword">import</span> PushToHubCallback
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-comment"># Le nombre d&#x27;\xE9tapes d&#x27;entra\xEEnement est le nombre d&#x27;\xE9chantillons dans l&#x27;ensemble de donn\xE9es, divis\xE9 par la taille du lot, puis multipli\xE9 par le nombre total d&#x27;\xE9poques.</span>
<span class="hljs-comment"># par le nombre total d&#x27;\xE9poques. Notez que le jeu de donn\xE9es tf_train_dataset est ici un lot tf.data.Dataset,</span>
<span class="hljs-comment"># et non le jeu de donn\xE9es original Hugging Face Dataset, donc son len() est d\xE9j\xE0 num_samples // batch_size.</span>
num_epochs = <span class="hljs-number">3</span>
num_train_steps = <span class="hljs-built_in">len</span>(tf_train_dataset) * num_epochs

optimizer, schedule = create_optimizer(
    init_lr=<span class="hljs-number">5e-5</span>,
    num_warmup_steps=<span class="hljs-number">0</span>,
    num_train_steps=num_train_steps,
    weight_decay_rate=<span class="hljs-number">0.01</span>,
)
model.<span class="hljs-built_in">compile</span>(optimizer=optimizer)

<span class="hljs-comment"># Entra\xEEner en mixed-precision float16</span>
tf.keras.mixed_precision.set_global_policy(<span class="hljs-string">&quot;mixed_float16&quot;</span>)`}}),B=new L({props:{code:`from transformers.keras_callbacks import PushToHubCallback

callback = PushToHubCallback(
    output_dir="marian-finetuned-kde4-en-to-fr", tokenizer=tokenizer
)

model.fit(
    tf_train_dataset,
    validation_data=tf_eval_dataset,
    callbacks=[callback],
    epochs=num_epochs,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers.keras_callbacks <span class="hljs-keyword">import</span> PushToHubCallback

callback = PushToHubCallback(
    output_dir=<span class="hljs-string">&quot;marian-finetuned-kde4-en-to-fr&quot;</span>, tokenizer=tokenizer
)

model.fit(
    tf_train_dataset,
    validation_data=tf_eval_dataset,
    callbacks=[callback],
    epochs=num_epochs,
)`}}),qe=new va({props:{$$slots:{default:[kf]},$$scope:{ctx:Y}}}),Pe=new L({props:{code:"print(compute_metrics())",highlighted:'<span class="hljs-built_in">print</span>(compute_metrics())'}}),Ze=new L({props:{code:"{'bleu': 57.334066271545865}",highlighted:'{&#x27;bleu&#x27;: <span class="hljs-number">57.334066271545865</span>}'}}),{c(){p=l("p"),g=n("Avant de commencer, voyons quel type de r\xE9sultats nous obtenons avec notre mod\xE8le sans entra\xEEnement :"),h=d(),E(y.$$.fragment),T=d(),E(v.$$.fragment),C=d(),S=l("p"),P=n("Une fois ceci fait, nous pouvons pr\xE9parer tout ce dont nous avons besoin pour compiler et entra\xEEner notre mod\xE8le. Notez l\u2019utilisation de "),A=l("code"),R=n('tf.keras.mixed_precision.set_global_policy("mixed_float16")'),k=n(". Ceci indiquera \xE0 Keras de s\u2019entra\xEEner en utilisant float16, ce qui peut donner un gain de vitesse significatif sur les GPUs qui le supportent (Nvidia 20xx/V100 ou plus r\xE9cent)."),D=d(),E(M.$$.fragment),F=d(),U=l("p"),G=n("Ensuite, nous d\xE9finissons un "),O=l("code"),V=n("PushToHubCallback"),X=n(" pour t\xE9l\xE9charger notre mod\xE8le sur le "),H=l("em"),q=n("Hub"),J=n(" pendant l\u2019entra\xEEnement, comme nous l\u2019avons vu dans "),W=l("a"),te=n("section 2"),Q=n(", et ensuite nous ajustons simplement le mod\xE8le avec ce callback :"),Z=d(),E(B.$$.fragment),fe=d(),se=l("p"),he=n("Notez que vous pouvez sp\xE9cifier le nom du r\xE9f\xE9rentiel vers lequel vous voulez pousser avec l\u2019argument "),be=l("code"),_e=n("hub_model_id"),oe=n(" (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),re=l("a"),K=l("code"),ie=n("huggingface-course"),Ae=n(", nous avons ajout\xE9 "),de=l("code"),ee=n('hub_model_id="huggingface-course/marian-finetuned-kde4-en-to-fr"``Seq2SeqTrainingArguments'),ge=n(". Par d\xE9faut, le r\xE9f\xE9rentiel utilis\xE9 sera dans votre espace de noms et nomm\xE9 apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini, donc ici ce sera "),ue=l("code"),ne=n('"sgugger/marian-finetuned-kde4-en-to-fr"'),Ne=n(" (qui est le mod\xE8le que nous avons li\xE9 au d\xE9but de cette section)."),me=d(),E(qe.$$.fragment),ae=d(),ce=l("p"),xe=n("Enfin, voyons \xE0 quoi ressemblent nos mesures maintenant que l\u2019entra\xEEnement est termin\xE9 :"),Ye=d(),E(Pe.$$.fragment),pe=d(),E(Ze.$$.fragment),os=d(),je=l("p"),Fs=n("\xC0 ce stade, vous pouvez utiliser le widget d\u2019inf\xE9rence sur le "),Be=l("em"),is=n("Hub"),es=n(" pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 "),Le=l("em"),we=n("finetuner"),ss=n(" un mod\xE8le sur une t\xE2che de traduction. F\xE9licitations !"),this.h()},l(j){p=r(j,"P",{});var le=o(p);g=a(le,"Avant de commencer, voyons quel type de r\xE9sultats nous obtenons avec notre mod\xE8le sans entra\xEEnement :"),le.forEach(t),h=c(j),x(y.$$.fragment,j),T=c(j),x(v.$$.fragment,j),C=c(j),S=r(j,"P",{});var Oe=o(S);P=a(Oe,"Une fois ceci fait, nous pouvons pr\xE9parer tout ce dont nous avons besoin pour compiler et entra\xEEner notre mod\xE8le. Notez l\u2019utilisation de "),A=r(Oe,"CODE",{});var Ys=o(A);R=a(Ys,'tf.keras.mixed_precision.set_global_policy("mixed_float16")'),Ys.forEach(t),k=a(Oe,". Ceci indiquera \xE0 Keras de s\u2019entra\xEEner en utilisant float16, ce qui peut donner un gain de vitesse significatif sur les GPUs qui le supportent (Nvidia 20xx/V100 ou plus r\xE9cent)."),Oe.forEach(t),D=c(j),x(M.$$.fragment,j),F=c(j),U=r(j,"P",{});var Xe=o(U);G=a(Xe,"Ensuite, nous d\xE9finissons un "),O=r(Xe,"CODE",{});var us=o(O);V=a(us,"PushToHubCallback"),us.forEach(t),X=a(Xe," pour t\xE9l\xE9charger notre mod\xE8le sur le "),H=r(Xe,"EM",{});var Re=o(H);q=a(Re,"Hub"),Re.forEach(t),J=a(Xe," pendant l\u2019entra\xEEnement, comme nous l\u2019avons vu dans "),W=r(Xe,"A",{href:!0});var Hs=o(W);te=a(Hs,"section 2"),Hs.forEach(t),Q=a(Xe,", et ensuite nous ajustons simplement le mod\xE8le avec ce callback :"),Xe.forEach(t),Z=c(j),x(B.$$.fragment,j),fe=c(j),se=r(j,"P",{});var ve=o(se);he=a(ve,"Notez que vous pouvez sp\xE9cifier le nom du r\xE9f\xE9rentiel vers lequel vous voulez pousser avec l\u2019argument "),be=r(ve,"CODE",{});var $e=o(be);_e=a($e,"hub_model_id"),$e.forEach(t),oe=a(ve," (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),re=r(ve,"A",{href:!0,rel:!0});var zs=o(re);K=r(zs,"CODE",{});var ke=o(K);ie=a(ke,"huggingface-course"),ke.forEach(t),zs.forEach(t),Ae=a(ve,", nous avons ajout\xE9 "),de=r(ve,"CODE",{});var ze=o(de);ee=a(ze,'hub_model_id="huggingface-course/marian-finetuned-kde4-en-to-fr"``Seq2SeqTrainingArguments'),ze.forEach(t),ge=a(ve,". Par d\xE9faut, le r\xE9f\xE9rentiel utilis\xE9 sera dans votre espace de noms et nomm\xE9 apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini, donc ici ce sera "),ue=r(ve,"CODE",{});var ys=o(ue);ne=a(ys,'"sgugger/marian-finetuned-kde4-en-to-fr"'),ys.forEach(t),Ne=a(ve," (qui est le mod\xE8le que nous avons li\xE9 au d\xE9but de cette section)."),ve.forEach(t),me=c(j),x(qe.$$.fragment,j),ae=c(j),ce=r(j,"P",{});var ts=o(ce);xe=a(ts,"Enfin, voyons \xE0 quoi ressemblent nos mesures maintenant que l\u2019entra\xEEnement est termin\xE9 :"),ts.forEach(t),Ye=c(j),x(Pe.$$.fragment,j),pe=c(j),x(Ze.$$.fragment,j),os=c(j),je=r(j,"P",{});var Ee=o(je);Fs=a(Ee,"\xC0 ce stade, vous pouvez utiliser le widget d\u2019inf\xE9rence sur le "),Be=r(Ee,"EM",{});var ye=o(Be);is=a(ye,"Hub"),ye.forEach(t),es=a(Ee," pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 "),Le=r(Ee,"EM",{});var Zs=o(Le);we=a(Zs,"finetuner"),Zs.forEach(t),ss=a(Ee," un mod\xE8le sur une t\xE2che de traduction. F\xE9licitations !"),Ee.forEach(t),this.h()},h(){_(W,"href","(/course/fr/chapter7/2)"),_(re,"href","https://huggingface.co/huggingface-course"),_(re,"rel","nofollow")},m(j,le){i(j,p,le),s(p,g),i(j,h,le),w(y,j,le),i(j,T,le),w(v,j,le),i(j,C,le),i(j,S,le),s(S,P),s(S,A),s(A,R),s(S,k),i(j,D,le),w(M,j,le),i(j,F,le),i(j,U,le),s(U,G),s(U,O),s(O,V),s(U,X),s(U,H),s(H,q),s(U,J),s(U,W),s(W,te),s(U,Q),i(j,Z,le),w(B,j,le),i(j,fe,le),i(j,se,le),s(se,he),s(se,be),s(be,_e),s(se,oe),s(se,re),s(re,K),s(K,ie),s(se,Ae),s(se,de),s(de,ee),s(se,ge),s(se,ue),s(ue,ne),s(se,Ne),i(j,me,le),w(qe,j,le),i(j,ae,le),i(j,ce,le),s(ce,xe),i(j,Ye,le),w(Pe,j,le),i(j,pe,le),w(Ze,j,le),i(j,os,le),i(j,je,le),s(je,Fs),s(je,Be),s(Be,is),s(je,es),s(je,Le),s(Le,we),s(je,ss),Ce=!0},i(j){Ce||(b(y.$$.fragment,j),b(v.$$.fragment,j),b(M.$$.fragment,j),b(B.$$.fragment,j),b(qe.$$.fragment,j),b(Pe.$$.fragment,j),b(Ze.$$.fragment,j),Ce=!0)},o(j){$(y.$$.fragment,j),$(v.$$.fragment,j),$(M.$$.fragment,j),$(B.$$.fragment,j),$(qe.$$.fragment,j),$(Pe.$$.fragment,j),$(Ze.$$.fragment,j),Ce=!1},d(j){j&&t(p),j&&t(h),z(y,j),j&&t(T),z(v,j),j&&t(C),j&&t(S),j&&t(D),z(M,j),j&&t(F),j&&t(U),j&&t(Z),z(B,j),j&&t(fe),j&&t(se),j&&t(me),z(qe,j),j&&t(ae),j&&t(ce),j&&t(Ye),z(Pe,j),j&&t(pe),z(Ze,j),j&&t(os),j&&t(je)}}}function jf(Y){let p,g,h,y,T;return{c(){p=l("p"),g=n("\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de la d\xE9finition de votre "),h=l("code"),y=n("Seq2SeqTrainer"),T=n(" et devrez d\xE9finir un nouveau nom.")},l(v){p=r(v,"P",{});var C=o(p);g=a(C,"\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de la d\xE9finition de votre "),h=r(C,"CODE",{});var S=o(h);y=a(S,"Seq2SeqTrainer"),S.forEach(t),T=a(C," et devrez d\xE9finir un nouveau nom."),C.forEach(t)},m(v,C){i(v,p,C),s(p,g),s(p,h),s(h,y),s(p,T)},d(v){v&&t(p)}}}function kf(Y){let p,g,h,y,T;return{c(){p=l("p"),g=n("\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de l\u2019appel de "),h=l("code"),y=n("model.fit()"),T=n(" et devrez d\xE9finir un nouveau nom.")},l(v){p=r(v,"P",{});var C=o(p);g=a(C,"\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de l\u2019appel de "),h=r(C,"CODE",{});var S=o(h);y=a(S,"model.fit()"),S.forEach(t),T=a(C," et devrez d\xE9finir un nouveau nom."),C.forEach(t)},m(v,C){i(v,p,C),s(p,g),s(p,h),s(h,y),s(p,T)},d(v){v&&t(p)}}}function Qm(Y){let p,g,h,y,T,v,C,S,P,A,R,k,D,M,F,U,G,O,V,X,H,q,J,W,te,Q,Z,B,fe,se,he,be,_e,oe,re,K,ie,Ae,de,ee,ge,ue,ne,Ne,me,qe,ae,ce,xe,Ye,Pe,pe,Ze,os,je,Fs,Be,is,es,Le,we,ss,Ce,j,le,Oe,Ys,Xe,us,Re,Hs,ve,$e,zs,ke,ze,ys,ts,Ee,ye,Zs,et,vs,Xt,Is,We,yt,bs,ft,Qe,Ps,$s,Pt,Bs,ps,Je,gs,qs,Me,st,js,ht,De,_t,Cs,Ue,Ct,Fe,Ds,vt,ns,Wt,bt,tt,ds,Se,Rs,ks,Qt,nt,Es,$t,as,Dt,cs,Ss,ls,xs,ms,at,Ts,lt,As,Ns,St,Ke,Ls,Tt,gt,f,I,Jt,rt,At,Te,ws,He,Nt,qt,ot,hn,Os,Lt,_n,Ie,Yt,it,Ot,fs,Mt,Ve,jt,Ks,Ut,Zt,hs,kt,Vs,vn,Ft;return y=new zt({}),H=new zt({}),re=new L({props:{code:`from torch.utils.data import DataLoader

tokenized_datasets.set_format("torch")
train_dataloader = DataLoader(
    tokenized_datasets["train"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=8,
)
eval_dataloader = DataLoader(
    tokenized_datasets["validation"], collate_fn=data_collator, batch_size=8
)`,highlighted:`<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader

tokenized_datasets.set_format(<span class="hljs-string">&quot;torch&quot;</span>)
train_dataloader = DataLoader(
    tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],
    shuffle=<span class="hljs-literal">True</span>,
    collate_fn=data_collator,
    batch_size=<span class="hljs-number">8</span>,
)
eval_dataloader = DataLoader(
    tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>], collate_fn=data_collator, batch_size=<span class="hljs-number">8</span>
)`}}),ee=new L({props:{code:"model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)",highlighted:"model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"}}),me=new L({props:{code:`from transformers import AdamW

optimizer = AdamW(model.parameters(), lr=2e-5)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AdamW

optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">2e-5</span>)`}}),es=new L({props:{code:`from accelerate import Accelerator

accelerator = Accelerator()
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)`,highlighted:`<span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> Accelerator

accelerator = Accelerator()
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)`}}),$e=new L({props:{code:`from transformers import get_scheduler

num_train_epochs = 3
num_update_steps_per_epoch = len(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> get_scheduler

num_train_epochs = <span class="hljs-number">3</span>
num_update_steps_per_epoch = <span class="hljs-built_in">len</span>(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    <span class="hljs-string">&quot;linear&quot;</span>,
    optimizer=optimizer,
    num_warmup_steps=<span class="hljs-number">0</span>,
    num_training_steps=num_training_steps,
)`}}),Qe=new L({props:{code:`from huggingface_hub import Repository, get_full_repo_name

model_name = "marian-finetuned-kde4-en-to-fr-accelerate"
repo_name = get_full_repo_name(model_name)
repo_name`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> Repository, get_full_repo_name

model_name = <span class="hljs-string">&quot;marian-finetuned-kde4-en-to-fr-accelerate&quot;</span>
repo_name = get_full_repo_name(model_name)
repo_name`}}),$s=new L({props:{code:"'sgugger/marian-finetuned-kde4-en-to-fr-accelerate'",highlighted:'<span class="hljs-string">&#x27;sgugger/marian-finetuned-kde4-en-to-fr-accelerate&#x27;</span>'}}),gs=new L({props:{code:`output_dir = "marian-finetuned-kde4-en-to-fr-accelerate"
repo = Repository(output_dir, clone_from=repo_name)`,highlighted:`output_dir = <span class="hljs-string">&quot;marian-finetuned-kde4-en-to-fr-accelerate&quot;</span>
repo = Repository(output_dir, clone_from=repo_name)`}}),ns=new zt({}),cs=new L({props:{code:`def postprocess(predictions, labels):
    predictions = predictions.cpu().numpy()
    labels = labels.cpu().numpy()

    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)

    # Remplacer -100 dans les \xE9tiquettes car nous ne pouvons pas les d\xE9coder.
    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)

    # Quelques post-traitements simples
    decoded_preds = [pred.strip() for pred in decoded_preds]
    decoded_labels = [[label.strip()] for label in decoded_labels]
    return decoded_preds, decoded_labels`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">postprocess</span>(<span class="hljs-params">predictions, labels</span>):
    predictions = predictions.cpu().numpy()
    labels = labels.cpu().numpy()

    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=<span class="hljs-literal">True</span>)

    <span class="hljs-comment"># Remplacer -100 dans les \xE9tiquettes car nous ne pouvons pas les d\xE9coder.</span>
    labels = np.where(labels != -<span class="hljs-number">100</span>, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=<span class="hljs-literal">True</span>)

    <span class="hljs-comment"># Quelques post-traitements simples</span>
    decoded_preds = [pred.strip() <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> decoded_preds]
    decoded_labels = [[label.strip()] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> decoded_labels]
    <span class="hljs-keyword">return</span> decoded_preds, decoded_labels`}}),it=new L({props:{code:`from tqdm.auto import tqdm
import torch

progress_bar = tqdm(range(num_training_steps))

for epoch in range(num_train_epochs):
    # Entra\xEEnement
    model.train()
    for batch in train_dataloader:
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)

    # Evaluation
    model.eval()
    for batch in tqdm(eval_dataloader):
        with torch.no_grad():
            generated_tokens = accelerator.unwrap_model(model).generate(
                batch["input_ids"],
                attention_mask=batch["attention_mask"],
                max_length=128,
            )
        labels = batch["labels"]

        # N\xE9cessaire pour rembourrer les pr\xE9dictions et les \xE9tiquettes \xE0 rassembler
        generated_tokens = accelerator.pad_across_processes(
            generated_tokens, dim=1, pad_index=tokenizer.pad_token_id
        )
        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)

        predictions_gathered = accelerator.gather(generated_tokens)
        labels_gathered = accelerator.gather(labels)

        decoded_preds, decoded_labels = postprocess(predictions_gathered, labels_gathered)
        metric.add_batch(predictions=decoded_preds, references=decoded_labels)

    results = metric.compute()
    print(f"epoch {epoch}, BLEU score: {results['score']:.2f}")

    # Sauvegarder et t\xE9l\xE9charger
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    if accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=f"Training in progress epoch {epoch}", blocking=False
        )`,highlighted:`<span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm
<span class="hljs-keyword">import</span> torch

progress_bar = tqdm(<span class="hljs-built_in">range</span>(num_training_steps))

<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_train_epochs):
    <span class="hljs-comment"># Entra\xEEnement</span>
    model.train()
    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(<span class="hljs-number">1</span>)

    <span class="hljs-comment"># Evaluation</span>
    model.<span class="hljs-built_in">eval</span>()
    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> tqdm(eval_dataloader):
        <span class="hljs-keyword">with</span> torch.no_grad():
            generated_tokens = accelerator.unwrap_model(model).generate(
                batch[<span class="hljs-string">&quot;input_ids&quot;</span>],
                attention_mask=batch[<span class="hljs-string">&quot;attention_mask&quot;</span>],
                max_length=<span class="hljs-number">128</span>,
            )
        labels = batch[<span class="hljs-string">&quot;labels&quot;</span>]

        <span class="hljs-comment"># N\xE9cessaire pour rembourrer les pr\xE9dictions et les \xE9tiquettes \xE0 rassembler</span>
        generated_tokens = accelerator.pad_across_processes(
            generated_tokens, dim=<span class="hljs-number">1</span>, pad_index=tokenizer.pad_token_id
        )
        labels = accelerator.pad_across_processes(labels, dim=<span class="hljs-number">1</span>, pad_index=-<span class="hljs-number">100</span>)

        predictions_gathered = accelerator.gather(generated_tokens)
        labels_gathered = accelerator.gather(labels)

        decoded_preds, decoded_labels = postprocess(predictions_gathered, labels_gathered)
        metric.add_batch(predictions=decoded_preds, references=decoded_labels)

    results = metric.compute()
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;epoch <span class="hljs-subst">{epoch}</span>, BLEU score: <span class="hljs-subst">{results[<span class="hljs-string">&#x27;score&#x27;</span>]:<span class="hljs-number">.2</span>f}</span>&quot;</span>)

    <span class="hljs-comment"># Sauvegarder et t\xE9l\xE9charger</span>
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    <span class="hljs-keyword">if</span> accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=<span class="hljs-string">f&quot;Training in progress epoch <span class="hljs-subst">{epoch}</span>&quot;</span>, blocking=<span class="hljs-literal">False</span>
        )`}}),fs=new L({props:{code:`epoch 0, BLEU score: 53.47
epoch 1, BLEU score: 54.24
epoch 2, BLEU score: 54.44`,highlighted:`epoch <span class="hljs-number">0</span>, BLEU score: <span class="hljs-number">53.47</span>
epoch <span class="hljs-number">1</span>, BLEU score: <span class="hljs-number">54.24</span>
epoch <span class="hljs-number">2</span>, BLEU score: <span class="hljs-number">54.44</span>`}}),{c(){p=l("h2"),g=l("a"),h=l("span"),E(y.$$.fragment),T=d(),v=l("span"),C=n("Une boucle d'entra\xEEnement personnalis\xE9e"),S=d(),P=l("p"),A=n("Jetons maintenant un coup d\u2019\u0153il \xE0 la boucle d\u2019entra\xEEnement compl\xE8te, afin que vous puissiez facilement personnaliser les parties dont vous avez besoin. Elle ressemblera beaucoup \xE0 ce que nous avons fait dans la "),R=l("a"),k=n("section 2"),D=n(" et le "),M=l("a"),F=n("chapitre 3"),U=n("."),G=d(),O=l("h3"),V=l("a"),X=l("span"),E(H.$$.fragment),q=d(),J=l("span"),W=n("Pr\xE9parer le tout pour l'entra\xEEnement"),te=d(),Q=l("p"),Z=n("Vous avez vu tout cela plusieurs fois maintenant, donc nous allons passer en revue le code assez rapidement. D\u2019abord, nous allons construire le "),B=l("code"),fe=n("DataLoader"),se=n(" \xE0 partir de nos jeux de donn\xE9es, apr\xE8s avoir configur\xE9 les jeux de donn\xE9es au format "),he=l("code"),be=n('"torch"'),_e=n(" pour obtenir les tenseurs PyTorch :"),oe=d(),E(re.$$.fragment),K=d(),ie=l("p"),Ae=n("Ensuite, nous r\xE9instantifions notre mod\xE8le, pour nous assurer que nous ne poursuivons pas l\u2019affinage pr\xE9c\xE9dent, mais que nous repartons du mod\xE8le pr\xE9-entra\xEEn\xE9 :"),de=d(),E(ee.$$.fragment),ge=d(),ue=l("p"),ne=n("Nous aurons alors besoin d\u2019un optimiseur :"),Ne=d(),E(me.$$.fragment),qe=d(),ae=l("p"),ce=n("Une fois que nous avons tous ces objets, nous pouvons les envoyer \xE0 la m\xE9thode "),xe=l("code"),Ye=n("accelerator.prepare()"),Pe=n(". Rappelez-vous que si vous voulez vous entra\xEEner sur des TPUs dans un "),pe=l("em"),Ze=n("notebook"),os=n(" de Colab, vous devrez d\xE9placer tout ce code dans une fonction d\u2019entra\xEEnement, et qui ne devrait pas ex\xE9cuter une cellule qui instancie un "),je=l("code"),Fs=n("Accelerator"),Be=n("."),is=d(),E(es.$$.fragment),Le=d(),we=l("p"),ss=n("Maintenant que nous avons envoy\xE9 notre "),Ce=l("code"),j=n("train_dataloader"),le=n(" \xE0 "),Oe=l("code"),Ys=n("accelerator.prepare()"),Xe=n(", nous pouvons utiliser sa longueur pour calculer le nombre d\u2019\xE9tapes d\u2019entra\xEEnement. Rappelez-vous que nous devrions toujours faire cela apr\xE8s avoir pr\xE9par\xE9 le dataloader, car cette m\xE9thode va changer la longueur du "),us=l("code"),Re=n("DataLoader"),Hs=n(". Nous utilisons un programme lin\xE9aire classique du taux d\u2019apprentissage \xE0 0 :"),ve=d(),E($e.$$.fragment),zs=d(),ke=l("p"),ze=n("Enfin, pour pousser notre mod\xE8le vers le Hub, nous aurons besoin de cr\xE9er un objet "),ys=l("code"),ts=n("Repository"),Ee=n(" dans un dossier de travail. Tout d\u2019abord, connectez-vous au "),ye=l("em"),Zs=n("Hub"),et=n(", si vous n\u2019\xEAtes pas d\xE9j\xE0 connect\xE9. Nous d\xE9terminerons le nom du d\xE9p\xF4t \xE0 partir de l\u2019ID du mod\xE8le que nous voulons donner \xE0 notre mod\xE8le (n\u2019h\xE9sitez pas \xE0 remplacer le "),vs=l("code"),Xt=n("repo_name"),Is=n(" par votre propre choix ; il doit juste contenir votre nom d\u2019utilisateur, ce que fait la fonction "),We=l("code"),yt=n("get_full_repo_name()"),bs=n(") :"),ft=d(),E(Qe.$$.fragment),Ps=d(),E($s.$$.fragment),Pt=d(),Bs=l("p"),ps=n("Ensuite, nous pouvons cloner ce r\xE9f\xE9rentiel dans un dossier local. S\u2019il existe d\xE9j\xE0, ce dossier local doit \xEAtre un clone du r\xE9f\xE9rentiel avec lequel nous travaillons :"),Je=d(),E(gs.$$.fragment),qs=d(),Me=l("p"),st=n("Nous pouvons maintenant t\xE9l\xE9charger tout ce que nous sauvegardons dans "),js=l("code"),ht=n("output_dir"),De=n(" en appelant la m\xE9thode "),_t=l("code"),Cs=n("repo.push_to_hub()"),Ue=n(". Cela nous aidera \xE0 t\xE9l\xE9charger les mod\xE8les interm\xE9diaires \xE0 la fin de chaque \xE9poque."),Ct=d(),Fe=l("h3"),Ds=l("a"),vt=l("span"),E(ns.$$.fragment),Wt=d(),bt=l("span"),tt=n("Boucle d'entra\xEEnement"),ds=d(),Se=l("p"),Rs=n("Nous sommes maintenant pr\xEAts \xE0 \xE9crire la boucle d\u2019entra\xEEnement compl\xE8te. Pour simplifier sa partie \xE9valuation, nous d\xE9finissons cette fonction "),ks=l("code"),Qt=n("postprocess()"),nt=n(" qui prend les pr\xE9dictions et les \xE9tiquettes et les convertit en listes de cha\xEEnes de caract\xE8res que notre objet "),Es=l("code"),$t=n("metric"),as=n(" attend :"),Dt=d(),E(cs.$$.fragment),Ss=d(),ls=l("p"),xs=n("La boucle d\u2019entra\xEEnement ressemble beaucoup \xE0 celles de "),ms=l("a"),at=n("section 2"),Ts=n(" et "),lt=l("a"),As=n("chapitre 3"),Ns=n(", avec quelques diff\xE9rences dans la partie \xE9valuation \u2014 alors concentrons-nous sur cela !"),St=d(),Ke=l("p"),Ls=n("La premi\xE8re chose \xE0 noter est que nous utilisons la m\xE9thode "),Tt=l("code"),gt=n("generate()"),f=n(" pour calculer les pr\xE9dictions, mais c\u2019est une m\xE9thode sur notre mod\xE8le de base, pas le mod\xE8le envelopp\xE9 \u{1F917} Accelerate cr\xE9\xE9 dans la m\xE9thode "),I=l("code"),Jt=n("prepare()"),rt=n(". C\u2019est pourquoi nous d\xE9ballons d\u2019abord le mod\xE8le, puis nous appelons cette m\xE9thode."),At=d(),Te=l("p"),ws=n("La deuxi\xE8me chose est que, comme avec "),He=l("a"),Nt=n("token classification"),qt=n(", deux processus peuvent avoir padd\xE9 les entr\xE9es et les \xE9tiquettes \xE0 des formes diff\xE9rentes, donc nous utilisons "),ot=l("code"),hn=n("accelerator.pad_across_processes()"),Os=n(" pour rendre les pr\xE9dictions et les \xE9tiquettes de la m\xEAme forme avant d\u2019appeler la m\xE9thode "),Lt=l("code"),_n=n("gather()"),Ie=n(". Si nous ne faisons pas cela, l\u2019\xE9valuation va soit se tromper, soit se bloquer pour toujours."),Yt=d(),E(it.$$.fragment),Ot=d(),E(fs.$$.fragment),Mt=d(),Ve=l("p"),jt=n("Une fois que c\u2019est fait, vous devriez avoir un mod\xE8le qui a des r\xE9sultats assez similaires \xE0 celui entra\xEEn\xE9 avec le "),Ks=l("code"),Ut=n("Seq2SeqTrainer"),Zt=n(". Vous pouvez v\xE9rifier celui que nous avons form\xE9 en utilisant ce code \xE0 "),hs=l("a"),kt=l("em"),Vs=n("huggingface-course/marian-finetuned-kde4-en-to-fr-accelerate"),vn=n(". Et si vous voulez tester des modifications de la boucle d\u2019entra\xEEnement, vous pouvez les mettre en \u0153uvre directement en modifiant le code ci-dessus !"),this.h()},l(m){p=r(m,"H2",{class:!0});var N=o(p);g=r(N,"A",{id:!0,class:!0,href:!0});var Et=o(g);h=r(Et,"SPAN",{});var bn=o(h);x(y.$$.fragment,bn),bn.forEach(t),Et.forEach(t),T=c(N),v=r(N,"SPAN",{});var Ht=o(v);C=a(Ht,"Une boucle d'entra\xEEnement personnalis\xE9e"),Ht.forEach(t),N.forEach(t),S=c(m),P=r(m,"P",{});var xt=o(P);A=a(xt,"Jetons maintenant un coup d\u2019\u0153il \xE0 la boucle d\u2019entra\xEEnement compl\xE8te, afin que vous puissiez facilement personnaliser les parties dont vous avez besoin. Elle ressemblera beaucoup \xE0 ce que nous avons fait dans la "),R=r(xt,"A",{href:!0});var $n=o(R);k=a($n,"section 2"),$n.forEach(t),D=a(xt," et le "),M=r(xt,"A",{href:!0});var Gs=o(M);F=a(Gs,"chapitre 3"),Gs.forEach(t),U=a(xt,"."),xt.forEach(t),G=c(m),O=r(m,"H3",{class:!0});var It=o(O);V=r(It,"A",{id:!0,class:!0,href:!0});var Xs=o(V);X=r(Xs,"SPAN",{});var gn=o(X);x(H.$$.fragment,gn),gn.forEach(t),Xs.forEach(t),q=c(It),J=r(It,"SPAN",{});var en=o(J);W=a(en,"Pr\xE9parer le tout pour l'entra\xEEnement"),en.forEach(t),It.forEach(t),te=c(m),Q=r(m,"P",{});var qn=o(Q);Z=a(qn,"Vous avez vu tout cela plusieurs fois maintenant, donc nous allons passer en revue le code assez rapidement. D\u2019abord, nous allons construire le "),B=r(qn,"CODE",{});var Kn=o(B);fe=a(Kn,"DataLoader"),Kn.forEach(t),se=a(qn," \xE0 partir de nos jeux de donn\xE9es, apr\xE8s avoir configur\xE9 les jeux de donn\xE9es au format "),he=r(qn,"CODE",{});var xl=o(he);be=a(xl,'"torch"'),xl.forEach(t),_e=a(qn," pour obtenir les tenseurs PyTorch :"),qn.forEach(t),oe=c(m),x(re.$$.fragment,m),K=c(m),ie=r(m,"P",{});var wl=o(ie);Ae=a(wl,"Ensuite, nous r\xE9instantifions notre mod\xE8le, pour nous assurer que nous ne poursuivons pas l\u2019affinage pr\xE9c\xE9dent, mais que nous repartons du mod\xE8le pr\xE9-entra\xEEn\xE9 :"),wl.forEach(t),de=c(m),x(ee.$$.fragment,m),ge=c(m),ue=r(m,"P",{});var ba=o(ue);ne=a(ba,"Nous aurons alors besoin d\u2019un optimiseur :"),ba.forEach(t),Ne=c(m),x(me.$$.fragment,m),qe=c(m),ae=r(m,"P",{});var Ms=o(ae);ce=a(Ms,"Une fois que nous avons tous ces objets, nous pouvons les envoyer \xE0 la m\xE9thode "),xe=r(Ms,"CODE",{});var $a=o(xe);Ye=a($a,"accelerator.prepare()"),$a.forEach(t),Pe=a(Ms,". Rappelez-vous que si vous voulez vous entra\xEEner sur des TPUs dans un "),pe=r(Ms,"EM",{});var jn=o(pe);Ze=a(jn,"notebook"),jn.forEach(t),os=a(Ms," de Colab, vous devrez d\xE9placer tout ce code dans une fonction d\u2019entra\xEEnement, et qui ne devrait pas ex\xE9cuter une cellule qui instancie un "),je=r(Ms,"CODE",{});var ga=o(je);Fs=a(ga,"Accelerator"),ga.forEach(t),Be=a(Ms,"."),Ms.forEach(t),is=c(m),x(es.$$.fragment,m),Le=c(m),we=r(m,"P",{});var Ws=o(we);ss=a(Ws,"Maintenant que nous avons envoy\xE9 notre "),Ce=r(Ws,"CODE",{});var zl=o(Ce);j=a(zl,"train_dataloader"),zl.forEach(t),le=a(Ws," \xE0 "),Oe=r(Ws,"CODE",{});var qa=o(Oe);Ys=a(qa,"accelerator.prepare()"),qa.forEach(t),Xe=a(Ws,", nous pouvons utiliser sa longueur pour calculer le nombre d\u2019\xE9tapes d\u2019entra\xEEnement. Rappelez-vous que nous devrions toujours faire cela apr\xE8s avoir pr\xE9par\xE9 le dataloader, car cette m\xE9thode va changer la longueur du "),us=r(Ws,"CODE",{});var kn=o(us);Re=a(kn,"DataLoader"),kn.forEach(t),Hs=a(Ws,". Nous utilisons un programme lin\xE9aire classique du taux d\u2019apprentissage \xE0 0 :"),Ws.forEach(t),ve=c(m),x($e.$$.fragment,m),zs=c(m),ke=r(m,"P",{});var Qs=o(ke);ze=a(Qs,"Enfin, pour pousser notre mod\xE8le vers le Hub, nous aurons besoin de cr\xE9er un objet "),ys=r(Qs,"CODE",{});var En=o(ys);ts=a(En,"Repository"),En.forEach(t),Ee=a(Qs," dans un dossier de travail. Tout d\u2019abord, connectez-vous au "),ye=r(Qs,"EM",{});var ja=o(ye);Zs=a(ja,"Hub"),ja.forEach(t),et=a(Qs,", si vous n\u2019\xEAtes pas d\xE9j\xE0 connect\xE9. Nous d\xE9terminerons le nom du d\xE9p\xF4t \xE0 partir de l\u2019ID du mod\xE8le que nous voulons donner \xE0 notre mod\xE8le (n\u2019h\xE9sitez pas \xE0 remplacer le "),vs=r(Qs,"CODE",{});var wt=o(vs);Xt=a(wt,"repo_name"),wt.forEach(t),Is=a(Qs," par votre propre choix ; il doit juste contenir votre nom d\u2019utilisateur, ce que fait la fonction "),We=r(Qs,"CODE",{});var yl=o(We);yt=a(yl,"get_full_repo_name()"),yl.forEach(t),bs=a(Qs,") :"),Qs.forEach(t),ft=c(m),x(Qe.$$.fragment,m),Ps=c(m),x($s.$$.fragment,m),Pt=c(m),Bs=r(m,"P",{});var Vn=o(Bs);ps=a(Vn,"Ensuite, nous pouvons cloner ce r\xE9f\xE9rentiel dans un dossier local. S\u2019il existe d\xE9j\xE0, ce dossier local doit \xEAtre un clone du r\xE9f\xE9rentiel avec lequel nous travaillons :"),Vn.forEach(t),Je=c(m),x(gs.$$.fragment,m),qs=c(m),Me=r(m,"P",{});var xn=o(Me);st=a(xn,"Nous pouvons maintenant t\xE9l\xE9charger tout ce que nous sauvegardons dans "),js=r(xn,"CODE",{});var Pl=o(js);ht=a(Pl,"output_dir"),Pl.forEach(t),De=a(xn," en appelant la m\xE9thode "),_t=r(xn,"CODE",{});var Gn=o(_t);Cs=a(Gn,"repo.push_to_hub()"),Gn.forEach(t),Ue=a(xn,". Cela nous aidera \xE0 t\xE9l\xE9charger les mod\xE8les interm\xE9diaires \xE0 la fin de chaque \xE9poque."),xn.forEach(t),Ct=c(m),Fe=r(m,"H3",{class:!0});var Xn=o(Fe);Ds=r(Xn,"A",{id:!0,class:!0,href:!0});var Cl=o(Ds);vt=r(Cl,"SPAN",{});var ka=o(vt);x(ns.$$.fragment,ka),ka.forEach(t),Cl.forEach(t),Wt=c(Xn),bt=r(Xn,"SPAN",{});var wn=o(bt);tt=a(wn,"Boucle d'entra\xEEnement"),wn.forEach(t),Xn.forEach(t),ds=c(m),Se=r(m,"P",{});var sn=o(Se);Rs=a(sn,"Nous sommes maintenant pr\xEAts \xE0 \xE9crire la boucle d\u2019entra\xEEnement compl\xE8te. Pour simplifier sa partie \xE9valuation, nous d\xE9finissons cette fonction "),ks=r(sn,"CODE",{});var tn=o(ks);Qt=a(tn,"postprocess()"),tn.forEach(t),nt=a(sn," qui prend les pr\xE9dictions et les \xE9tiquettes et les convertit en listes de cha\xEEnes de caract\xE8res que notre objet "),Es=r(sn,"CODE",{});var Ea=o(Es);$t=a(Ea,"metric"),Ea.forEach(t),as=a(sn," attend :"),sn.forEach(t),Dt=c(m),x(cs.$$.fragment,m),Ss=c(m),ls=r(m,"P",{});var Us=o(ls);xs=a(Us,"La boucle d\u2019entra\xEEnement ressemble beaucoup \xE0 celles de "),ms=r(Us,"A",{href:!0});var nn=o(ms);at=a(nn,"section 2"),nn.forEach(t),Ts=a(Us," et "),lt=r(Us,"A",{href:!0});var Wn=o(lt);As=a(Wn,"chapitre 3"),Wn.forEach(t),Ns=a(Us,", avec quelques diff\xE9rences dans la partie \xE9valuation \u2014 alors concentrons-nous sur cela !"),Us.forEach(t),St=c(m),Ke=r(m,"P",{});var ut=o(Ke);Ls=a(ut,"La premi\xE8re chose \xE0 noter est que nous utilisons la m\xE9thode "),Tt=r(ut,"CODE",{});var Dl=o(Tt);gt=a(Dl,"generate()"),Dl.forEach(t),f=a(ut," pour calculer les pr\xE9dictions, mais c\u2019est une m\xE9thode sur notre mod\xE8le de base, pas le mod\xE8le envelopp\xE9 \u{1F917} Accelerate cr\xE9\xE9 dans la m\xE9thode "),I=r(ut,"CODE",{});var Qn=o(I);Jt=a(Qn,"prepare()"),Qn.forEach(t),rt=a(ut,". C\u2019est pourquoi nous d\xE9ballons d\u2019abord le mod\xE8le, puis nous appelons cette m\xE9thode."),ut.forEach(t),At=c(m),Te=r(m,"P",{});var Bt=o(Te);ws=a(Bt,"La deuxi\xE8me chose est que, comme avec "),He=r(Bt,"A",{href:!0});var xa=o(He);Nt=a(xa,"token classification"),xa.forEach(t),qt=a(Bt,", deux processus peuvent avoir padd\xE9 les entr\xE9es et les \xE9tiquettes \xE0 des formes diff\xE9rentes, donc nous utilisons "),ot=r(Bt,"CODE",{});var zn=o(ot);hn=a(zn,"accelerator.pad_across_processes()"),zn.forEach(t),Os=a(Bt," pour rendre les pr\xE9dictions et les \xE9tiquettes de la m\xEAme forme avant d\u2019appeler la m\xE9thode "),Lt=r(Bt,"CODE",{});var wa=o(Lt);_n=a(wa,"gather()"),wa.forEach(t),Ie=a(Bt,". Si nous ne faisons pas cela, l\u2019\xE9valuation va soit se tromper, soit se bloquer pour toujours."),Bt.forEach(t),Yt=c(m),x(it.$$.fragment,m),Ot=c(m),x(fs.$$.fragment,m),Mt=c(m),Ve=r(m,"P",{});var Ge=o(Ve);jt=a(Ge,"Une fois que c\u2019est fait, vous devriez avoir un mod\xE8le qui a des r\xE9sultats assez similaires \xE0 celui entra\xEEn\xE9 avec le "),Ks=r(Ge,"CODE",{});var Sl=o(Ks);Ut=a(Sl,"Seq2SeqTrainer"),Sl.forEach(t),Zt=a(Ge,". Vous pouvez v\xE9rifier celui que nous avons form\xE9 en utilisant ce code \xE0 "),hs=r(Ge,"A",{href:!0,rel:!0});var Jn=o(hs);kt=r(Jn,"EM",{});var Tl=o(kt);Vs=a(Tl,"huggingface-course/marian-finetuned-kde4-en-to-fr-accelerate"),Tl.forEach(t),Jn.forEach(t),vn=a(Ge,". Et si vous voulez tester des modifications de la boucle d\u2019entra\xEEnement, vous pouvez les mettre en \u0153uvre directement en modifiant le code ci-dessus !"),Ge.forEach(t),this.h()},h(){_(g,"id","une-boucle-dentranement-personnalise"),_(g,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(g,"href","#une-boucle-dentranement-personnalise"),_(p,"class","relative group"),_(R,"href","/course/fr/chapter7/2"),_(M,"href","/course/fr/chapter3/4"),_(V,"id","prparer-le-tout-pour-lentranement"),_(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(V,"href","#prparer-le-tout-pour-lentranement"),_(O,"class","relative group"),_(Ds,"id","boucle-dentranement"),_(Ds,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Ds,"href","#boucle-dentranement"),_(Fe,"class","relative group"),_(ms,"href","/course/fr/chapter7/2"),_(lt,"href","/course/fr/chapter3"),_(He,"href","/course/fr/chapter7/2"),_(hs,"href","https://huggingface.co/huggingface-course/marian-finetuned-kde4-en-to-fr-accelerate"),_(hs,"rel","nofollow")},m(m,N){i(m,p,N),s(p,g),s(g,h),w(y,h,null),s(p,T),s(p,v),s(v,C),i(m,S,N),i(m,P,N),s(P,A),s(P,R),s(R,k),s(P,D),s(P,M),s(M,F),s(P,U),i(m,G,N),i(m,O,N),s(O,V),s(V,X),w(H,X,null),s(O,q),s(O,J),s(J,W),i(m,te,N),i(m,Q,N),s(Q,Z),s(Q,B),s(B,fe),s(Q,se),s(Q,he),s(he,be),s(Q,_e),i(m,oe,N),w(re,m,N),i(m,K,N),i(m,ie,N),s(ie,Ae),i(m,de,N),w(ee,m,N),i(m,ge,N),i(m,ue,N),s(ue,ne),i(m,Ne,N),w(me,m,N),i(m,qe,N),i(m,ae,N),s(ae,ce),s(ae,xe),s(xe,Ye),s(ae,Pe),s(ae,pe),s(pe,Ze),s(ae,os),s(ae,je),s(je,Fs),s(ae,Be),i(m,is,N),w(es,m,N),i(m,Le,N),i(m,we,N),s(we,ss),s(we,Ce),s(Ce,j),s(we,le),s(we,Oe),s(Oe,Ys),s(we,Xe),s(we,us),s(us,Re),s(we,Hs),i(m,ve,N),w($e,m,N),i(m,zs,N),i(m,ke,N),s(ke,ze),s(ke,ys),s(ys,ts),s(ke,Ee),s(ke,ye),s(ye,Zs),s(ke,et),s(ke,vs),s(vs,Xt),s(ke,Is),s(ke,We),s(We,yt),s(ke,bs),i(m,ft,N),w(Qe,m,N),i(m,Ps,N),w($s,m,N),i(m,Pt,N),i(m,Bs,N),s(Bs,ps),i(m,Je,N),w(gs,m,N),i(m,qs,N),i(m,Me,N),s(Me,st),s(Me,js),s(js,ht),s(Me,De),s(Me,_t),s(_t,Cs),s(Me,Ue),i(m,Ct,N),i(m,Fe,N),s(Fe,Ds),s(Ds,vt),w(ns,vt,null),s(Fe,Wt),s(Fe,bt),s(bt,tt),i(m,ds,N),i(m,Se,N),s(Se,Rs),s(Se,ks),s(ks,Qt),s(Se,nt),s(Se,Es),s(Es,$t),s(Se,as),i(m,Dt,N),w(cs,m,N),i(m,Ss,N),i(m,ls,N),s(ls,xs),s(ls,ms),s(ms,at),s(ls,Ts),s(ls,lt),s(lt,As),s(ls,Ns),i(m,St,N),i(m,Ke,N),s(Ke,Ls),s(Ke,Tt),s(Tt,gt),s(Ke,f),s(Ke,I),s(I,Jt),s(Ke,rt),i(m,At,N),i(m,Te,N),s(Te,ws),s(Te,He),s(He,Nt),s(Te,qt),s(Te,ot),s(ot,hn),s(Te,Os),s(Te,Lt),s(Lt,_n),s(Te,Ie),i(m,Yt,N),w(it,m,N),i(m,Ot,N),w(fs,m,N),i(m,Mt,N),i(m,Ve,N),s(Ve,jt),s(Ve,Ks),s(Ks,Ut),s(Ve,Zt),s(Ve,hs),s(hs,kt),s(kt,Vs),s(Ve,vn),Ft=!0},i(m){Ft||(b(y.$$.fragment,m),b(H.$$.fragment,m),b(re.$$.fragment,m),b(ee.$$.fragment,m),b(me.$$.fragment,m),b(es.$$.fragment,m),b($e.$$.fragment,m),b(Qe.$$.fragment,m),b($s.$$.fragment,m),b(gs.$$.fragment,m),b(ns.$$.fragment,m),b(cs.$$.fragment,m),b(it.$$.fragment,m),b(fs.$$.fragment,m),Ft=!0)},o(m){$(y.$$.fragment,m),$(H.$$.fragment,m),$(re.$$.fragment,m),$(ee.$$.fragment,m),$(me.$$.fragment,m),$(es.$$.fragment,m),$($e.$$.fragment,m),$(Qe.$$.fragment,m),$($s.$$.fragment,m),$(gs.$$.fragment,m),$(ns.$$.fragment,m),$(cs.$$.fragment,m),$(it.$$.fragment,m),$(fs.$$.fragment,m),Ft=!1},d(m){m&&t(p),z(y),m&&t(S),m&&t(P),m&&t(G),m&&t(O),z(H),m&&t(te),m&&t(Q),m&&t(oe),z(re,m),m&&t(K),m&&t(ie),m&&t(de),z(ee,m),m&&t(ge),m&&t(ue),m&&t(Ne),z(me,m),m&&t(qe),m&&t(ae),m&&t(is),z(es,m),m&&t(Le),m&&t(we),m&&t(ve),z($e,m),m&&t(zs),m&&t(ke),m&&t(ft),z(Qe,m),m&&t(Ps),z($s,m),m&&t(Pt),m&&t(Bs),m&&t(Je),z(gs,m),m&&t(qs),m&&t(Me),m&&t(Ct),m&&t(Fe),z(ns),m&&t(ds),m&&t(Se),m&&t(Dt),z(cs,m),m&&t(Ss),m&&t(ls),m&&t(St),m&&t(Ke),m&&t(At),m&&t(Te),m&&t(Yt),z(it,m),m&&t(Ot),z(fs,m),m&&t(Mt),m&&t(Ve)}}}function Ef(Y){let p,g,h,y,T;return{c(){p=l("p"),g=n("\u270F\uFE0F "),h=l("strong"),y=n("Votre tour !"),T=n(" Que retourne le mod\xE8le sur l\u2019\xE9chantillon avec le mot \u201Cemail\u201D que vous avez identifi\xE9 plus t\xF4t ?")},l(v){p=r(v,"P",{});var C=o(p);g=a(C,"\u270F\uFE0F "),h=r(C,"STRONG",{});var S=o(h);y=a(S,"Votre tour !"),S.forEach(t),T=a(C," Que retourne le mod\xE8le sur l\u2019\xE9chantillon avec le mot \u201Cemail\u201D que vous avez identifi\xE9 plus t\xF4t ?"),C.forEach(t)},m(v,C){i(v,p,C),s(p,g),s(p,h),s(h,y),s(p,T)},d(v){v&&t(p)}}}function xf(Y){let p,g,h,y,T,v,C,S,P,A,R,k,D,M,F,U,G,O,V,X,H,q,J,W,te,Q,Z,B,fe,se,he,be,_e,oe,re,K,ie,Ae,de,ee,ge,ue,ne,Ne,me,qe,ae,ce,xe,Ye,Pe,pe,Ze,os,je,Fs,Be,is,es,Le,we,ss,Ce,j,le,Oe,Ys,Xe,us,Re,Hs,ve,$e,zs,ke,ze,ys,ts,Ee,ye,Zs,et,vs,Xt,Is,We,yt,bs,ft,Qe,Ps,$s,Pt,Bs,ps,Je,gs,qs,Me,st,js,ht,De,_t,Cs,Ue,Ct,Fe,Ds,vt,ns,Wt,bt,tt,ds,Se,Rs,ks,Qt,nt,Es,$t,as,Dt,cs,Ss,ls,xs,ms,at,Ts,lt,As,Ns,St,Ke,Ls,Tt,gt,f,I,Jt,rt,At,Te,ws,He,Nt,qt,ot,hn,Os,Lt,_n,Ie,Yt,it,Ot,fs,Mt,Ve,jt,Ks,Ut,Zt,hs,kt,Vs,vn,Ft,m,N,Et,bn,Ht,xt,$n,Gs,It,Xs,gn,en,qn,Kn,xl,wl,ba,Ms,$a,jn,ga,Ws,zl,qa,kn,Qs,En,ja,wt,yl,Vn,xn,Pl,Gn,Xn,Cl,ka,wn,sn,tn,Ea,Us,nn,Wn,ut,Dl,Qn,Bt,xa,zn,wa,Ge,Sl,Jn,Tl,Yi,vr,Zi,eu,br,su,tu,za,nu,au,vo,ya,bo,Rt,lu,$r,ru,ou,Pa,gr,iu,uu,qr,pu,du,$o,Yn,go,yn,cu,jr,mu,fu,kr,hu,_u,qo,Zn,vu,Er,bu,$u,jo,Ca,ko,Pn,gu,xr,qu,ju,wr,ku,Eu,Eo,Cn,xu,zr,wu,zu,yr,yu,Pu,xo,Al,Cu,wo,Da,zo,ea,Du,Pr,Su,Tu,yo,Sa,Po,Ta,Co,Kt,Au,Cr,Nu,Lu,Dr,Ou,Mu,Sr,Uu,Fu,Do,Vt,Hu,Tr,Iu,Bu,Ar,Ru,Ku,Nr,Vu,Gu,So,Aa,To,Nl,Xu,Ao,sa,No,ta,Lo,Ll,Wu,Oo,Na,Mo,na,Qu,Lr,Ju,Yu,Uo,an,ln,Ol,Ml,Zu,Fo,Fn,aa,Or,La,ep,Mr,sp,Ho,pt,tp,Ur,np,ap,Ul,lp,rp,Fr,op,ip,Hr,up,pp,Io,_s,dp,Oa,Ir,cp,mp,Br,fp,hp,Rr,_p,vp,Kr,bp,$p,Vr,gp,qp,Gr,jp,kp,Bo,rn,on,Fl,Hl,Ep,Ro,Ma,Ko,Ua,Vo,la,xp,Xr,wp,zp,Go,Fa,Xo,Ha,Wo,Il,yp,Qo,Ia,Jo,Ba,Yo,Bl,Pp,Zo,Ra,ei,Ka,si,un,pn,Rl,Hn,ra,Wr,Va,Cp,Qr,Dp,ti,Ga,ni,Kl,Dn,Sp,Xa,Tp,Ap,Wa,Np,Lp,ai,Sn,Op,Jr,Mp,Up,Qa,Fp,Hp,li,Ja,ri,Tn,Ip,Yr,Bp,Rp,Vl,Kp,Vp,oi,Ya,ii,Gl,Gp,ui,Xl,Xp,pi,Za,di,el,ci,dt,Wp,sl,Qp,Jp,Zr,Yp,Zp,eo,ed,sd,tl,td,nd,mi,nl,fi,al,hi,ll,_i,rl,vi,Wl,ad,bi,dn,cn,Ql,Jl,ld,$i,In,oa,so,ol,rd,to,od,gi,An,id,no,ud,pd,ao,dd,cd,qi,il,ji,Yl,md,ki,ia,fd,lo,hd,_d,Ei,ul,xi,mn,fn,Zl,er,Bn,ua,ro,pl,vd,oo,bd,wi,ct,$d,io,gd,qd,uo,jd,kd,po,Ed,xd,co,wd,zd,zi,dl,yi,cl,Pi,sr,yd,Ci,ml,Di,fl,Si,tr,Pd,Ti,pa,Ai;h=new nf({props:{fw:Y[0]}}),S=new zt({});const Cd=[lf,af],hl=[];function Dd(e,u){return e[0]==="pt"?0:1}D=Dd(Y),M=hl[D]=Cd[D](Y),ge=new Ji({props:{id:"1JvfrvZgi6c"}}),qs=new zt({}),ks=new zt({}),ms=new L({props:{code:`from datasets import load_dataset, load_metric

raw_datasets = load_dataset("kde4", lang1="en", lang2="fr")`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, load_metric

raw_datasets = load_dataset(<span class="hljs-string">&quot;kde4&quot;</span>, lang1=<span class="hljs-string">&quot;en&quot;</span>, lang2=<span class="hljs-string">&quot;fr&quot;</span>)`}}),rt=new L({props:{code:"raw_datasets",highlighted:"raw_datasets"}}),Te=new L({props:{code:`DatasetDict({
    train: Dataset({
        features: ['id', 'translation'],
        num_rows: 210173
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;translation&#x27;</span>],
        num_rows: <span class="hljs-number">210173</span>
    })
})`}}),fs=new L({props:{code:`split_datasets = raw_datasets["train"].train_test_split(train_size=0.9, seed=20)
split_datasets`,highlighted:`split_datasets = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>].train_test_split(train_size=<span class="hljs-number">0.9</span>, seed=<span class="hljs-number">20</span>)
split_datasets`}}),Ve=new L({props:{code:`DatasetDict({
    train: Dataset({
        features: ['id', 'translation'],
        num_rows: 189155
    })
    test: Dataset({
        features: ['id', 'translation'],
        num_rows: 21018
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;translation&#x27;</span>],
        num_rows: <span class="hljs-number">189155</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;translation&#x27;</span>],
        num_rows: <span class="hljs-number">21018</span>
    })
})`}}),hs=new L({props:{code:'split_datasets["validation"] = split_datasets.pop("test")',highlighted:'split_datasets[<span class="hljs-string">&quot;validation&quot;</span>] = split_datasets.pop(<span class="hljs-string">&quot;test&quot;</span>)'}}),m=new L({props:{code:'split_datasets["train"][1]["translation"]',highlighted:'split_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;translation&quot;</span>]'}}),Et=new L({props:{code:`{'en': 'Default to expanded threads',
 'fr': 'Par d\xE9faut, d\xE9velopper les fils de discussion'}`,highlighted:`{<span class="hljs-string">&#x27;en&#x27;</span>: <span class="hljs-string">&#x27;Default to expanded threads&#x27;</span>,
 <span class="hljs-string">&#x27;fr&#x27;</span>: <span class="hljs-string">&#x27;Par d\xE9faut, d\xE9velopper les fils de discussion&#x27;</span>}`}}),Gs=new L({props:{code:`from transformers import pipeline

model_checkpoint = "Helsinki-NLP/opus-mt-en-fr"
translator = pipeline("translation", model=model_checkpoint)
translator("Default to expanded threads")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

model_checkpoint = <span class="hljs-string">&quot;Helsinki-NLP/opus-mt-en-fr&quot;</span>
translator = pipeline(<span class="hljs-string">&quot;translation&quot;</span>, model=model_checkpoint)
translator(<span class="hljs-string">&quot;Default to expanded threads&quot;</span>)`}}),Xs=new L({props:{code:"[{'translation_text': 'Par d\xE9faut pour les threads \xE9largis'}]",highlighted:'[{<span class="hljs-string">&#x27;translation_text&#x27;</span>: <span class="hljs-string">&#x27;Par d\xE9faut pour les threads \xE9largis&#x27;</span>}]'}}),Ms=new L({props:{code:'split_datasets["train"][172]["translation"]',highlighted:'split_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">172</span>][<span class="hljs-string">&quot;translation&quot;</span>]'}}),jn=new L({props:{code:`{'en': 'Unable to import %1 using the OFX importer plugin. This file is not the correct format.',
 'fr': "Impossible d'importer %1 en utilisant le module d'extension d'importation OFX. Ce fichier n'a pas un format correct."}`,highlighted:`{<span class="hljs-string">&#x27;en&#x27;</span>: <span class="hljs-string">&#x27;Unable to import %1 using the OFX importer plugin. This file is not the correct format.&#x27;</span>,
 <span class="hljs-string">&#x27;fr&#x27;</span>: <span class="hljs-string">&quot;Impossible d&#x27;importer %1 en utilisant le module d&#x27;extension d&#x27;importation OFX. Ce fichier n&#x27;a pas un format correct.&quot;</span>}`}}),kn=new L({props:{code:`translator(
    "Unable to import %1 using the OFX importer plugin. This file is not the correct format."
)`,highlighted:`translator(
    <span class="hljs-string">&quot;Unable to import %1 using the OFX importer plugin. This file is not the correct format.&quot;</span>
)`}}),En=new L({props:{code:`[{'translation_text': "Impossible d'importer %1 en utilisant le plugin d'importateur OFX. Ce fichier n'est pas le bon format."}]`,highlighted:'[{<span class="hljs-string">&#x27;translation_text&#x27;</span>: <span class="hljs-string">&quot;Impossible d&#x27;importer %1 en utilisant le plugin d&#x27;importateur OFX. Ce fichier n&#x27;est pas le bon format.&quot;</span>}]'}}),wn=new Ji({props:{id:"0Oxphw4Q9fo"}}),tn=new va({props:{$$slots:{default:[rf]},$$scope:{ctx:Y}}}),ut=new zt({}),zn=new Ji({props:{id:"XAR8jnZZuUs"}}),ya=new L({props:{code:`from transformers import AutoTokenizer

model_checkpoint = "Helsinki-NLP/opus-mt-en-fr"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors="tf")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

model_checkpoint = <span class="hljs-string">&quot;Helsinki-NLP/opus-mt-en-fr&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`}}),Yn=new va({props:{$$slots:{default:[of]},$$scope:{ctx:Y}}}),Ca=new L({props:{code:`with open(file_path) as f:
    content = f.read()`,highlighted:`<span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_path) <span class="hljs-keyword">as</span> f:
    content = f.<span class="hljs-built_in">read</span>()`}}),Da=new L({props:{code:`en_sentence = split_datasets["train"][1]["translation"]["en"]
fr_sentence = split_datasets["train"][1]["translation"]["fr"]

inputs = tokenizer(en_sentence)
with tokenizer.as_target_tokenizer():
    targets = tokenizer(fr_sentence)`,highlighted:`en_sentence = split_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;translation&quot;</span>][<span class="hljs-string">&quot;en&quot;</span>]
fr_sentence = split_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;translation&quot;</span>][<span class="hljs-string">&quot;fr&quot;</span>]

inputs = tokenizer(en_sentence)
<span class="hljs-keyword">with</span> tokenizer.as_target_tokenizer():
    targets = tokenizer(fr_sentence)`}}),Sa=new L({props:{code:`wrong_targets = tokenizer(fr_sentence)
print(tokenizer.convert_ids_to_tokens(wrong_targets["input_ids"]))
print(tokenizer.convert_ids_to_tokens(targets["input_ids"]))`,highlighted:`wrong_targets = tokenizer(fr_sentence)
<span class="hljs-built_in">print</span>(tokenizer.convert_ids_to_tokens(wrong_targets[<span class="hljs-string">&quot;input_ids&quot;</span>]))
<span class="hljs-built_in">print</span>(tokenizer.convert_ids_to_tokens(targets[<span class="hljs-string">&quot;input_ids&quot;</span>]))`}}),Ta=new L({props:{code:`['\u2581Par', '\u2581d\xE9', 'f', 'aut', ',', '\u2581d\xE9', 've', 'lop', 'per', '\u2581les', '\u2581fil', 's', '\u2581de', '\u2581discussion', '</s>']
['\u2581Par', '\u2581d\xE9faut', ',', '\u2581d\xE9velopper', '\u2581les', '\u2581fils', '\u2581de', '\u2581discussion', '</s>']`,highlighted:`[<span class="hljs-string">&#x27;\u2581Par&#x27;</span>, <span class="hljs-string">&#x27;\u2581d\xE9&#x27;</span>, <span class="hljs-string">&#x27;f&#x27;</span>, <span class="hljs-string">&#x27;aut&#x27;</span>, <span class="hljs-string">&#x27;,&#x27;</span>, <span class="hljs-string">&#x27;\u2581d\xE9&#x27;</span>, <span class="hljs-string">&#x27;ve&#x27;</span>, <span class="hljs-string">&#x27;lop&#x27;</span>, <span class="hljs-string">&#x27;per&#x27;</span>, <span class="hljs-string">&#x27;\u2581les&#x27;</span>, <span class="hljs-string">&#x27;\u2581fil&#x27;</span>, <span class="hljs-string">&#x27;s&#x27;</span>, <span class="hljs-string">&#x27;\u2581de&#x27;</span>, <span class="hljs-string">&#x27;\u2581discussion&#x27;</span>, <span class="hljs-string">&#x27;&lt;/s&gt;&#x27;</span>]
[<span class="hljs-string">&#x27;\u2581Par&#x27;</span>, <span class="hljs-string">&#x27;\u2581d\xE9faut&#x27;</span>, <span class="hljs-string">&#x27;,&#x27;</span>, <span class="hljs-string">&#x27;\u2581d\xE9velopper&#x27;</span>, <span class="hljs-string">&#x27;\u2581les&#x27;</span>, <span class="hljs-string">&#x27;\u2581fils&#x27;</span>, <span class="hljs-string">&#x27;\u2581de&#x27;</span>, <span class="hljs-string">&#x27;\u2581discussion&#x27;</span>, <span class="hljs-string">&#x27;&lt;/s&gt;&#x27;</span>]`}}),Aa=new L({props:{code:`max_input_length = 128
max_target_length = 128


def preprocess_function(examples):
    inputs = [ex["en"] for ex in examples["translation"]]
    targets = [ex["fr"] for ex in examples["translation"]]
    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)

    # Set up the tokenizer for targets
    with tokenizer.as_target_tokenizer():
        labels = tokenizer(targets, max_length=max_target_length, truncation=True)

    model_inputs["labels"] = labels["input_ids"]
    return model_inputs`,highlighted:`max_input_length = <span class="hljs-number">128</span>
max_target_length = <span class="hljs-number">128</span>


<span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
    inputs = [ex[<span class="hljs-string">&quot;en&quot;</span>] <span class="hljs-keyword">for</span> ex <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;translation&quot;</span>]]
    targets = [ex[<span class="hljs-string">&quot;fr&quot;</span>] <span class="hljs-keyword">for</span> ex <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;translation&quot;</span>]]
    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=<span class="hljs-literal">True</span>)

    <span class="hljs-comment"># Set up the tokenizer for targets</span>
    <span class="hljs-keyword">with</span> tokenizer.as_target_tokenizer():
        labels = tokenizer(targets, max_length=max_target_length, truncation=<span class="hljs-literal">True</span>)

    model_inputs[<span class="hljs-string">&quot;labels&quot;</span>] = labels[<span class="hljs-string">&quot;input_ids&quot;</span>]
    <span class="hljs-keyword">return</span> model_inputs`}}),sa=new va({props:{$$slots:{default:[uf]},$$scope:{ctx:Y}}}),ta=new va({props:{warning:!0,$$slots:{default:[pf]},$$scope:{ctx:Y}}}),Na=new L({props:{code:`tokenized_datasets = split_datasets.map(
    preprocess_function,
    batched=True,
    remove_columns=split_datasets["train"].column_names,
)`,highlighted:`tokenized_datasets = split_datasets.<span class="hljs-built_in">map</span>(
    preprocess_function,
    batched=<span class="hljs-literal">True</span>,
    remove_columns=split_datasets[<span class="hljs-string">&quot;train&quot;</span>].column_names,
)`}});const Sd=[cf,df],_l=[];function Td(e,u){return e[0]==="pt"?0:1}an=Td(Y),ln=_l[an]=Sd[an](Y),La=new zt({});const Ad=[hf,ff],vl=[];function Nd(e,u){return e[0]==="pt"?0:1}rn=Nd(Y),on=vl[rn]=Ad[rn](Y),Ma=new L({props:{code:`batch = data_collator([tokenized_datasets["train"][i] for i in range(1, 3)])
batch.keys()`,highlighted:`batch = data_collator([tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>][i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)])
batch.keys()`}}),Ua=new L({props:{code:"dict_keys(['attention_mask', 'input_ids', 'labels', 'decoder_input_ids'])",highlighted:'dict_keys([<span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;labels&#x27;</span>, <span class="hljs-string">&#x27;decoder_input_ids&#x27;</span>])'}}),Fa=new L({props:{code:'batch["labels"]',highlighted:'batch[<span class="hljs-string">&quot;labels&quot;</span>]'}}),Ha=new L({props:{code:`tensor([[  577,  5891,     2,  3184,    16,  2542,     5,  1710,     0,  -100,
          -100,  -100,  -100,  -100,  -100,  -100],
        [ 1211,     3,    49,  9409,  1211,     3, 29140,   817,  3124,   817,
           550,  7032,  5821,  7907, 12649,     0]])`,highlighted:`tensor([[  <span class="hljs-number">577</span>,  <span class="hljs-number">5891</span>,     <span class="hljs-number">2</span>,  <span class="hljs-number">3184</span>,    <span class="hljs-number">16</span>,  <span class="hljs-number">2542</span>,     <span class="hljs-number">5</span>,  <span class="hljs-number">1710</span>,     <span class="hljs-number">0</span>,  -<span class="hljs-number">100</span>,
          -<span class="hljs-number">100</span>,  -<span class="hljs-number">100</span>,  -<span class="hljs-number">100</span>,  -<span class="hljs-number">100</span>,  -<span class="hljs-number">100</span>,  -<span class="hljs-number">100</span>],
        [ <span class="hljs-number">1211</span>,     <span class="hljs-number">3</span>,    <span class="hljs-number">49</span>,  <span class="hljs-number">9409</span>,  <span class="hljs-number">1211</span>,     <span class="hljs-number">3</span>, <span class="hljs-number">29140</span>,   <span class="hljs-number">817</span>,  <span class="hljs-number">3124</span>,   <span class="hljs-number">817</span>,
           <span class="hljs-number">550</span>,  <span class="hljs-number">7032</span>,  <span class="hljs-number">5821</span>,  <span class="hljs-number">7907</span>, <span class="hljs-number">12649</span>,     <span class="hljs-number">0</span>]])`}}),Ia=new L({props:{code:'batch["decoder_input_ids"]',highlighted:'batch[<span class="hljs-string">&quot;decoder_input_ids&quot;</span>]'}}),Ba=new L({props:{code:`tensor([[59513,   577,  5891,     2,  3184,    16,  2542,     5,  1710,     0,
         59513, 59513, 59513, 59513, 59513, 59513],
        [59513,  1211,     3,    49,  9409,  1211,     3, 29140,   817,  3124,
           817,   550,  7032,  5821,  7907, 12649]])`,highlighted:`tensor([[<span class="hljs-number">59513</span>,   <span class="hljs-number">577</span>,  <span class="hljs-number">5891</span>,     <span class="hljs-number">2</span>,  <span class="hljs-number">3184</span>,    <span class="hljs-number">16</span>,  <span class="hljs-number">2542</span>,     <span class="hljs-number">5</span>,  <span class="hljs-number">1710</span>,     <span class="hljs-number">0</span>,
         <span class="hljs-number">59513</span>, <span class="hljs-number">59513</span>, <span class="hljs-number">59513</span>, <span class="hljs-number">59513</span>, <span class="hljs-number">59513</span>, <span class="hljs-number">59513</span>],
        [<span class="hljs-number">59513</span>,  <span class="hljs-number">1211</span>,     <span class="hljs-number">3</span>,    <span class="hljs-number">49</span>,  <span class="hljs-number">9409</span>,  <span class="hljs-number">1211</span>,     <span class="hljs-number">3</span>, <span class="hljs-number">29140</span>,   <span class="hljs-number">817</span>,  <span class="hljs-number">3124</span>,
           <span class="hljs-number">817</span>,   <span class="hljs-number">550</span>,  <span class="hljs-number">7032</span>,  <span class="hljs-number">5821</span>,  <span class="hljs-number">7907</span>, <span class="hljs-number">12649</span>]])`}}),Ra=new L({props:{code:`for i in range(1, 3):
    print(tokenized_datasets["train"][i]["labels"])`,highlighted:`<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>):
    <span class="hljs-built_in">print</span>(tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>][i][<span class="hljs-string">&quot;labels&quot;</span>])`}}),Ka=new L({props:{code:`[577, 5891, 2, 3184, 16, 2542, 5, 1710, 0]
[1211, 3, 49, 9409, 1211, 3, 29140, 817, 3124, 817, 550, 7032, 5821, 7907, 12649, 0]`,highlighted:`[<span class="hljs-number">577</span>, <span class="hljs-number">5891</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3184</span>, <span class="hljs-number">16</span>, <span class="hljs-number">2542</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1710</span>, <span class="hljs-number">0</span>]
[<span class="hljs-number">1211</span>, <span class="hljs-number">3</span>, <span class="hljs-number">49</span>, <span class="hljs-number">9409</span>, <span class="hljs-number">1211</span>, <span class="hljs-number">3</span>, <span class="hljs-number">29140</span>, <span class="hljs-number">817</span>, <span class="hljs-number">3124</span>, <span class="hljs-number">817</span>, <span class="hljs-number">550</span>, <span class="hljs-number">7032</span>, <span class="hljs-number">5821</span>, <span class="hljs-number">7907</span>, <span class="hljs-number">12649</span>, <span class="hljs-number">0</span>]`}});const Ld=[vf,_f],bl=[];function Od(e,u){return e[0]==="pt"?0:1}un=Od(Y),pn=bl[un]=Ld[un](Y),Va=new zt({}),Ga=new Ji({props:{id:"M05L1DhFqcw"}});let Js=Y[0]==="pt"&&Wm();Ja=new L({props:{code:"!pip install sacrebleu",highlighted:"!pip install sacrebleu"}}),Ya=new L({props:{code:`from datasets import load_metric

metric = load_metric("sacrebleu")`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_metric

metric = load_metric(<span class="hljs-string">&quot;sacrebleu&quot;</span>)`}}),Za=new L({props:{code:`predictions = [
    "This plugin lets you translate web pages between several languages automatically."
]
references = [
    [
        "This plugin allows you to automatically translate web pages between several languages."
    ]
]
metric.compute(predictions=predictions, references=references)`,highlighted:`predictions = [
    <span class="hljs-string">&quot;This plugin lets you translate web pages between several languages automatically.&quot;</span>
]
references = [
    [
        <span class="hljs-string">&quot;This plugin allows you to automatically translate web pages between several languages.&quot;</span>
    ]
]
metric.compute(predictions=predictions, references=references)`}}),el=new L({props:{code:`{'score': 46.750469682990165,
 'counts': [11, 6, 4, 3],
 'totals': [12, 11, 10, 9],
 'precisions': [91.67, 54.54, 40.0, 33.33],
 'bp': 0.9200444146293233,
 'sys_len': 12,
 'ref_len': 13}`,highlighted:`{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">46.750469682990165</span>,
 <span class="hljs-string">&#x27;counts&#x27;</span>: [<span class="hljs-number">11</span>, <span class="hljs-number">6</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>],
 <span class="hljs-string">&#x27;totals&#x27;</span>: [<span class="hljs-number">12</span>, <span class="hljs-number">11</span>, <span class="hljs-number">10</span>, <span class="hljs-number">9</span>],
 <span class="hljs-string">&#x27;precisions&#x27;</span>: [<span class="hljs-number">91.67</span>, <span class="hljs-number">54.54</span>, <span class="hljs-number">40.0</span>, <span class="hljs-number">33.33</span>],
 <span class="hljs-string">&#x27;bp&#x27;</span>: <span class="hljs-number">0.9200444146293233</span>,
 <span class="hljs-string">&#x27;sys_len&#x27;</span>: <span class="hljs-number">12</span>,
 <span class="hljs-string">&#x27;ref_len&#x27;</span>: <span class="hljs-number">13</span>}`}}),nl=new L({props:{code:`predictions = ["This This This This"]
references = [
    [
        "This plugin allows you to automatically translate web pages between several languages."
    ]
]
metric.compute(predictions=predictions, references=references)`,highlighted:`predictions = [<span class="hljs-string">&quot;This This This This&quot;</span>]
references = [
    [
        <span class="hljs-string">&quot;This plugin allows you to automatically translate web pages between several languages.&quot;</span>
    ]
]
metric.compute(predictions=predictions, references=references)`}}),al=new L({props:{code:`{'score': 1.683602693167689,
 'counts': [1, 0, 0, 0],
 'totals': [4, 3, 2, 1],
 'precisions': [25.0, 16.67, 12.5, 12.5],
 'bp': 0.10539922456186433,
 'sys_len': 4,
 'ref_len': 13}`,highlighted:`{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">1.683602693167689</span>,
 <span class="hljs-string">&#x27;counts&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
 <span class="hljs-string">&#x27;totals&#x27;</span>: [<span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>],
 <span class="hljs-string">&#x27;precisions&#x27;</span>: [<span class="hljs-number">25.0</span>, <span class="hljs-number">16.67</span>, <span class="hljs-number">12.5</span>, <span class="hljs-number">12.5</span>],
 <span class="hljs-string">&#x27;bp&#x27;</span>: <span class="hljs-number">0.10539922456186433</span>,
 <span class="hljs-string">&#x27;sys_len&#x27;</span>: <span class="hljs-number">4</span>,
 <span class="hljs-string">&#x27;ref_len&#x27;</span>: <span class="hljs-number">13</span>}`}}),ll=new L({props:{code:`predictions = ["This plugin"]
references = [
    [
        "This plugin allows you to automatically translate web pages between several languages."
    ]
]
metric.compute(predictions=predictions, references=references)`,highlighted:`predictions = [<span class="hljs-string">&quot;This plugin&quot;</span>]
references = [
    [
        <span class="hljs-string">&quot;This plugin allows you to automatically translate web pages between several languages.&quot;</span>
    ]
]
metric.compute(predictions=predictions, references=references)`}}),rl=new L({props:{code:`{'score': 0.0,
 'counts': [2, 1, 0, 0],
 'totals': [2, 1, 0, 0],
 'precisions': [100.0, 100.0, 0.0, 0.0],
 'bp': 0.004086771438464067,
 'sys_len': 2,
 'ref_len': 13}`,highlighted:`{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0</span>,
 <span class="hljs-string">&#x27;counts&#x27;</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
 <span class="hljs-string">&#x27;totals&#x27;</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
 <span class="hljs-string">&#x27;precisions&#x27;</span>: [<span class="hljs-number">100.0</span>, <span class="hljs-number">100.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>],
 <span class="hljs-string">&#x27;bp&#x27;</span>: <span class="hljs-number">0.004086771438464067</span>,
 <span class="hljs-string">&#x27;sys_len&#x27;</span>: <span class="hljs-number">2</span>,
 <span class="hljs-string">&#x27;ref_len&#x27;</span>: <span class="hljs-number">13</span>}`}});const Md=[$f,bf],$l=[];function Ud(e,u){return e[0]==="tf"?0:1}dn=Ud(Y),cn=$l[dn]=Md[dn](Y),ol=new zt({}),il=new L({props:{code:`from huggingface_hub import notebook_login

notebook_login()`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

notebook_login()`}}),ul=new L({props:{code:"huggingface-cli login",highlighted:"huggingface-cli login"}});const Fd=[qf,gf],gl=[];function Hd(e,u){return e[0]==="tf"?0:1}mn=Hd(Y),fn=gl[mn]=Fd[mn](Y);let rs=Y[0]==="pt"&&Qm();return pl=new zt({}),dl=new L({props:{code:`from transformers import pipeline

# Remplacez ceci par votre propre checkpoint
model_checkpoint = "huggingface-course/marian-finetuned-kde4-en-to-fr"
translator = pipeline("translation", model=model_checkpoint)
translator("Default to expanded threads")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-comment"># Remplacez ceci par votre propre checkpoint</span>
model_checkpoint = <span class="hljs-string">&quot;huggingface-course/marian-finetuned-kde4-en-to-fr&quot;</span>
translator = pipeline(<span class="hljs-string">&quot;translation&quot;</span>, model=model_checkpoint)
translator(<span class="hljs-string">&quot;Default to expanded threads&quot;</span>)`}}),cl=new L({props:{code:"[{'translation_text': 'Par d\xE9faut, d\xE9velopper les fils de discussion'}]",highlighted:'[{<span class="hljs-string">&#x27;translation_text&#x27;</span>: <span class="hljs-string">&#x27;Par d\xE9faut, d\xE9velopper les fils de discussion&#x27;</span>}]'}}),ml=new L({props:{code:`translator(
    "Unable to import %1 using the OFX importer plugin. This file is not the correct format."
)`,highlighted:`translator(
    <span class="hljs-string">&quot;Unable to import %1 using the OFX importer plugin. This file is not the correct format.&quot;</span>
)`}}),fl=new L({props:{code:`[{'translation_text': "Impossible d'importer %1 en utilisant le module externe d'importation OFX. Ce fichier n'est pas le bon format."}]`,highlighted:'[{<span class="hljs-string">&#x27;translation_text&#x27;</span>: <span class="hljs-string">&quot;Impossible d&#x27;importer %1 en utilisant le module externe d&#x27;importation OFX. Ce fichier n&#x27;est pas le bon format.&quot;</span>}]'}}),pa=new va({props:{$$slots:{default:[Ef]},$$scope:{ctx:Y}}}),{c(){p=l("meta"),g=d(),E(h.$$.fragment),y=d(),T=l("h1"),v=l("a"),C=l("span"),E(S.$$.fragment),P=d(),A=l("span"),R=n("Traduction"),k=d(),M.c(),F=d(),U=l("p"),G=n("Plongeons maintenant dans la traduction. Il s\u2019agit d\u2019une autre "),O=l("a"),V=n("t\xE2che de s\xE9quence \xE0 s\xE9quence"),X=n(", ce qui signifie que c\u2019est un probl\xE8me qui peut \xEAtre formul\xE9 comme le passage d\u2019une s\xE9quence \xE0 une autre. En ce sens, le probl\xE8me est assez proche de la t\xE2che de "),H=l("a"),q=n("r\xE9sum\xE9"),J=n(" et vous pouvez adapter ce que nous allons voir ici \xE0 d\u2019autres probl\xE8mes de s\xE9quence \xE0 s\xE9quence tels que :"),W=d(),te=l("ul"),Q=l("li"),Z=n("le "),B=l("strong"),fe=n("transfert de style"),se=n(" : cr\xE9er un mod\xE8le qui "),he=l("em"),be=n("traduit"),_e=n(" des textes \xE9crits dans un certain style vers un autre (par exemple, du formel au d\xE9contract\xE9 ou de l\u2019anglais shakespearien \xE0 l\u2019anglais moderne)."),oe=d(),re=l("li"),K=n("la "),ie=l("strong"),Ae=n("g\xE9n\xE9ration de r\xE9ponse \xE0 des questions"),de=n(" : Cr\xE9ation d\u2019un mod\xE8le qui g\xE9n\xE8re des r\xE9ponses \xE0 des questions, compte tenu d\u2019un contexte."),ee=d(),E(ge.$$.fragment),ue=d(),ne=l("p"),Ne=n("Si vous disposez d\u2019un corpus suffisamment important de textes en deux langues (ou plus), vous pouvez entra\xEEner un nouveau mod\xE8le de traduction \xE0 partir de z\xE9ro, comme nous le ferons dans la section sur la "),me=l("a"),qe=n("mod\xE9lisation causale du langage"),ae=n(". Il est toutefois plus rapide de "),ce=l("em"),xe=n("finetuner"),Ye=n(" un mod\xE8le de traduction existant, qu\u2019il s\u2019agisse d\u2019un mod\xE8le multilingue comme mT5 ou mBART que vous souhaitez adapter \xE0 une paire de langues sp\xE9cifique, ou m\xEAme d\u2019un mod\xE8le sp\xE9cialis\xE9 dans la traduction d\u2019une langue vers une autre que vous souhaitez adapter \xE0 votre corpus sp\xE9cifique."),Pe=d(),pe=l("p"),Ze=n("Dans cette section, nous allons "),os=l("em"),je=n("finetuner"),Fs=n(" un mod\xE8le Marian pr\xE9-entra\xEEn\xE9 pour traduire de l\u2019anglais au fran\xE7ais (puisque de nombreux employ\xE9s de Hugging Face parlent ces deux langues) sur le "),Be=l("a"),is=n("KDE4 dataset"),es=n(", qui est un jeu de donn\xE9es de fichiers localis\xE9s pour les "),Le=l("a"),we=n("KDE apps"),ss=n(". Le mod\xE8le que nous utiliserons a \xE9t\xE9 pr\xE9-entra\xEEn\xE9 sur un large corpus de textes fran\xE7ais et anglais provenant du "),Ce=l("a"),j=n("jeu de donn\xE9es Opus"),le=n(", qui contient en fait le jeu de donn\xE9es KDE4. Mais m\xEAme si le mod\xE8le pr\xE9-entra\xEEn\xE9 que nous utilisons a vu ces donn\xE9es pendant son pr\xE9-entra\xEEnement, nous verrons que nous pouvons obtenir une meilleure version de ce mod\xE8le apr\xE8s un "),Oe=l("em"),Ys=n("finetuning"),Xe=n("."),us=d(),Re=l("p"),Hs=n("Une fois que nous aurons termin\xE9, nous aurons un mod\xE8le capable de faire des pr\xE9dictions comme celle-ci :"),ve=d(),$e=l("iframe"),ke=d(),ze=l("iframe"),ts=d(),Ee=l("a"),ye=l("img"),et=d(),vs=l("img"),Is=d(),We=l("p"),yt=n("Comme dans les sections pr\xE9c\xE9dentes, vous pouvez trouver le mod\xE8le r\xE9el que nous allons entra\xEEner et t\xE9l\xE9charger sur le "),bs=l("em"),ft=n("Hub"),Qe=n(" en utilisant le code ci-dessous et v\xE9rifier ses pr\xE9dictions "),Ps=l("a"),$s=n("ici"),Pt=n("."),Bs=d(),ps=l("h2"),Je=l("a"),gs=l("span"),E(qs.$$.fragment),Me=d(),st=l("span"),js=n("Pr\xE9paration des donn\xE9es"),ht=d(),De=l("p"),_t=n("Pour affiner ou entra\xEEner un mod\xE8le de traduction \xE0 partir de z\xE9ro, nous avons besoin d\u2019un jeu de donn\xE9es adapt\xE9 \xE0 cette t\xE2che. Comme mentionn\xE9 pr\xE9c\xE9demment, nous utiliserons le jeu de donn\xE9es "),Cs=l("a"),Ue=n("KDE4"),Ct=n(" dans cette section, mais vous pouvez adapter le code pour utiliser vos propres donn\xE9es assez facilement, tant que vous avez des paires de phrases dans les deux langues que vous voulez traduire de et vers. Reportez-vous au "),Fe=l("a"),Ds=n("Chapitre 5"),vt=n(" si vous avez besoin d\u2019un rappel sur la fa\xE7on de charger vos donn\xE9es personnalis\xE9es dans un "),ns=l("code"),Wt=n("Dataset"),bt=n("."),tt=d(),ds=l("h3"),Se=l("a"),Rs=l("span"),E(ks.$$.fragment),Qt=d(),nt=l("span"),Es=n("Le jeu de donn\xE9es KDE4"),$t=d(),as=l("p"),Dt=n("Comme d\u2019habitude, nous t\xE9l\xE9chargeons notre jeu de donn\xE9es en utilisant la fonction "),cs=l("code"),Ss=n("load_dataset()"),ls=n(" :"),xs=d(),E(ms.$$.fragment),at=d(),Ts=l("p"),lt=n("Si vous souhaitez travailler avec une autre paire de langues, vous pouvez les sp\xE9cifier par leurs codes. Au total, 92 langues sont disponibles pour cet ensemble de donn\xE9es ; vous pouvez les voir toutes en d\xE9veloppant les \xE9tiquettes de langue sur sa "),As=l("a"),Ns=n("fiche"),St=n("."),Ke=d(),Ls=l("img"),gt=d(),f=l("p"),I=n("Jetons un coup d\u2019\u0153il au jeu  de donn\xE9es :"),Jt=d(),E(rt.$$.fragment),At=d(),E(Te.$$.fragment),ws=d(),He=l("p"),Nt=n("Nous avons 210 173 paires de phrases, mais dans un seul split, donc nous devrons cr\xE9er notre propre ensemble de validation. Comme nous l\u2019avons vu dans le "),qt=l("a"),ot=n("Chapitre 5"),hn=n(", un "),Os=l("code"),Lt=n("Dataset"),_n=n(" poss\xE8de une m\xE9thode "),Ie=l("code"),Yt=n("train_test_split()"),it=n(" qui peut nous aider. Nous allons fournir une graine pour la reproductibilit\xE9 :"),Ot=d(),E(fs.$$.fragment),Mt=d(),E(Ve.$$.fragment),jt=d(),Ks=l("p"),Ut=n("Nous pouvons renommer la cl\xE9 \u201Ctest\u201D en \u201Cvalidation\u201D comme ceci :"),Zt=d(),E(hs.$$.fragment),kt=d(),Vs=l("p"),vn=n("Examinons maintenant un \xE9l\xE9ment de ce jeu de donn\xE9es :"),Ft=d(),E(m.$$.fragment),N=d(),E(Et.$$.fragment),bn=d(),Ht=l("p"),xt=n(`Nous obtenons un dictionnaire contenant deux phrases dans la paire de langues demand\xE9e.
Une particularit\xE9 de ce jeu de donn\xE9es rempli de termes techniques informatiques est qu\u2019ils sont tous enti\xE8rement traduits en fran\xE7ais. Cependant, les ing\xE9nieurs fran\xE7ais sont souvent paresseux et laissent la plupart des mots sp\xE9cifiques \xE0 l\u2019informatique en anglais lorsqu\u2019ils parlent. Ici, par exemple, le mot \u201Cthreads\u201D pourrait tr\xE8s bien appara\xEEtre dans une phrase fran\xE7aise, surtout dans une conversation technique. Mais dans ce jeu de donn\xE9es, il a \xE9t\xE9 traduit par le plus correct \u201Cfils de discussion\u201D. Le mod\xE8le pr\xE9-entra\xEEn\xE9 que nous utilisons, qui a \xE9t\xE9 pr\xE9-entra\xEEn\xE9 sur un plus grand corpus de phrases fran\xE7aises et anglaises, prend l\u2019option la plus facile de laisser le mot tel quel :`),$n=d(),E(Gs.$$.fragment),It=d(),E(Xs.$$.fragment),gn=d(),en=l("p"),qn=n("Un autre exemple de ce comportement peut \xEAtre observ\xE9 avec le mot \u201D"),Kn=l("em"),xl=n("plugin"),wl=n(`\u201D, qui n\u2019est pas officiellement un mot fran\xE7ais mais que la plupart des locuteurs natifs comprendront et ne prendront pas la peine de traduire.
Dans le jeu de donn\xE9es KDE4, ce mot a \xE9t\xE9 traduit en fran\xE7ais par le plus officiel \u201Cmodule d\u2019extension\u201D :`),ba=d(),E(Ms.$$.fragment),$a=d(),E(jn.$$.fragment),ga=d(),Ws=l("p"),zl=n("Notre mod\xE8le pr\xE9-entra\xEEn\xE9, cependant, s\u2019en tient au mot anglais compact et familier :"),qa=d(),E(kn.$$.fragment),Qs=d(),E(En.$$.fragment),ja=d(),wt=l("p"),yl=n("Il sera int\xE9ressant de voir si notre mod\xE8le "),Vn=l("em"),xn=n("finetun\xE9"),Pl=n(" tient compte de ces particularit\xE9s de l\u2019ensemble de donn\xE9es (alerte "),Gn=l("em"),Xn=n("spoiler"),Cl=n(" : il le fera)."),ka=d(),E(wn.$$.fragment),sn=d(),E(tn.$$.fragment),Ea=d(),Us=l("h3"),nn=l("a"),Wn=l("span"),E(ut.$$.fragment),Dl=d(),Qn=l("span"),Bt=n("Traitement des donn\xE9es"),xa=d(),E(zn.$$.fragment),wa=d(),Ge=l("p"),Sl=n("Vous devriez maintenant conna\xEEtre le principe : les textes doivent tous \xEAtre convertis en ensembles d\u2019ID de "),Jn=l("em"),Tl=n("tokens"),Yi=n(" pour que le mod\xE8le puisse leur donner un sens. Pour cette t\xE2che, nous aurons besoin de tokeniser les entr\xE9es et les cibles. Notre premi\xE8re t\xE2che est de cr\xE9er notre objet "),vr=l("code"),Zi=n("tokenizer"),eu=n(". Comme indiqu\xE9 pr\xE9c\xE9demment, nous utiliserons un mod\xE8le pr\xE9-entra\xEEn\xE9 Marian English to French. Si vous essayez ce code avec une autre paire de langues, assurez-vous d\u2019adapter le "),br=l("em"),su=n("checkpoint"),tu=n(" du mod\xE8le. L\u2019organisation "),za=l("a"),nu=n("Helsinki-NLP"),au=n(" fournit plus de mille mod\xE8les dans plusieurs langues."),vo=d(),E(ya.$$.fragment),bo=d(),Rt=l("p"),lu=n("Vous pouvez \xE9galement remplacer le "),$r=l("code"),ru=n("model_checkpoint"),ou=n(" par tout autre mod\xE8le que vous pr\xE9f\xE9rez \xE0 partir du "),Pa=l("a"),gr=l("em"),iu=n("Hub"),uu=n(", ou un dossier local o\xF9 vous avez sauvegard\xE9 un mod\xE8le pr\xE9-entra\xEEn\xE9 et un "),qr=l("em"),pu=n("tokenizer"),du=n("."),$o=d(),E(Yn.$$.fragment),go=d(),yn=l("p"),cu=n("La pr\xE9paration de nos donn\xE9es est assez simple. Il y a juste une chose \xE0 retenir : vous traitez les entr\xE9es comme d\u2019habitude, mais pour les cibles, vous devez envelopper le "),jr=l("em"),mu=n("tokenizer"),fu=n(" dans le gestionnaire de contexte "),kr=l("code"),hu=n("as_target_tokenizer()"),_u=n("."),qo=d(),Zn=l("p"),vu=n("Un gestionnaire de contexte en Python est introduit avec l\u2019instruction "),Er=l("code"),bu=n("with"),$u=n(" et est utile lorsque vous avez deux op\xE9rations li\xE9es \xE0 ex\xE9cuter en paire. L\u2019exemple le plus courant est lorsque vous \xE9crivez ou lisez un fichier, ce qui est souvent fait dans une instruction comme :"),jo=d(),E(Ca.$$.fragment),ko=d(),Pn=l("p"),gu=n("Ici, les deux op\xE9rations connexes qui sont ex\xE9cut\xE9es en paire sont les actions d\u2019ouverture et de fermeture du fichier. L\u2019objet correspondant au fichier ouvert "),xr=l("code"),qu=n("f"),ju=n(" n\u2019existe qu\u2019\xE0 l\u2019int\xE9rieur du bloc indent\xE9 sous le "),wr=l("code"),ku=n("with"),Eu=n(" ; l\u2019ouverture se produit avant ce bloc et la fermeture \xE0 la fin du bloc."),Eo=d(),Cn=l("p"),xu=n("Dans le cas pr\xE9sent, le gestionnaire de contexte "),zr=l("code"),wu=n("as_target_tokenizer()"),zu=n(" va d\xE9finir le "),yr=l("em"),yu=n("tokenizer"),Pu=n(" dans la langue de sortie (ici, le fran\xE7ais) avant l\u2019ex\xE9cution du bloc indent\xE9, puis le red\xE9finir dans la langue d\u2019entr\xE9e (ici, l\u2019anglais)."),xo=d(),Al=l("p"),Cu=n("Ainsi, le pr\xE9traitement d\u2019un \xE9chantillon ressemble \xE0 ceci :"),wo=d(),E(Da.$$.fragment),zo=d(),ea=l("p"),Du=n("Si nous oublions de tokeniser les cibles dans le gestionnaire de contexte, elles seront tokenis\xE9es par le "),Pr=l("em"),Su=n("tokenizer"),Tu=n(" d\u2019entr\xE9e, ce qui, dans le cas d\u2019un mod\xE8le marial, ne va pas du tout bien se passer :"),yo=d(),E(Sa.$$.fragment),Po=d(),E(Ta.$$.fragment),Co=d(),Kt=l("p"),Au=n("Comme on peut le voir, utiliser le "),Cr=l("em"),Nu=n("tokenizer"),Lu=n(" anglais pour pr\xE9traiter une phrase fran\xE7aise donne un batch de "),Dr=l("em"),Ou=n("tokens"),Mu=n(" plus important, puisque le "),Sr=l("em"),Uu=n("tokenizer"),Fu=n(" ne conna\xEEt aucun mot fran\xE7ais (sauf ceux qui apparaissent aussi en anglais, comme \u201Cdiscussion\u201D)."),Do=d(),Vt=l("p"),Hu=n("Les "),Tr=l("code"),Iu=n("inputs"),Bu=n(" et les "),Ar=l("code"),Ru=n("targets"),Ku=n(" sont des dictionnaires avec nos cl\xE9s habituelles (identifiants d\u2019entr\xE9e, masque d\u2019attention, etc.), donc la derni\xE8re \xE9tape est de d\xE9finir une cl\xE9 "),Nr=l("code"),Vu=n('"labels"'),Gu=n(" dans les entr\xE9es. Nous faisons cela dans la fonction de pr\xE9traitement que nous allons appliquer sur les jeux de donn\xE9es :"),So=d(),E(Aa.$$.fragment),To=d(),Nl=l("p"),Xu=n("Notez que nous avons fix\xE9 des longueurs maximales similaires pour nos entr\xE9es et nos sorties. Comme les textes que nous traitons semblent assez courts, nous utilisons 128."),Ao=d(),E(sa.$$.fragment),No=d(),E(ta.$$.fragment),Lo=d(),Ll=l("p"),Wu=n("Nous pouvons maintenant appliquer ce pr\xE9traitement en une seule fois sur toutes les divisions de notre jeu de donn\xE9es :"),Oo=d(),E(Na.$$.fragment),Mo=d(),na=l("p"),Qu=n("Maintenant que les donn\xE9es ont \xE9t\xE9 pr\xE9trait\xE9es, nous sommes pr\xEAts \xE0 "),Lr=l("em"),Ju=n("finetuner"),Yu=n(" notre mod\xE8le pr\xE9-entra\xEEn\xE9 !"),Uo=d(),ln.c(),Ol=d(),Ml=l("p"),Zu=n("Notez que cette fois-ci, nous utilisons un mod\xE8le qui a \xE9t\xE9 entra\xEEn\xE9 sur une t\xE2che de traduction et qui peut d\xE9j\xE0 \xEAtre utilis\xE9, donc il n\u2019y a pas d\u2019avertissement concernant les poids manquants ou ceux nouvellement initialis\xE9s."),Fo=d(),Fn=l("h3"),aa=l("a"),Or=l("span"),E(La.$$.fragment),ep=d(),Mr=l("span"),sp=n("Collecte des donn\xE9es"),Ho=d(),pt=l("p"),tp=n("Nous aurons besoin d\u2019un assembleur de donn\xE9es pour g\xE9rer le rembourrage pour la mise en lots dynamique. Nous ne pouvons pas simplement utiliser un "),Ur=l("code"),np=n("DataCollatorWithPadding"),ap=n(" comme dans "),Ul=l("a"),lp=n("Chapter 3"),rp=n(" dans ce cas, parce que cela ne rembourre que les entr\xE9es (ID d\u2019entr\xE9e, masque d\u2019attention, et ID de type de jeton). Nos \xE9tiquettes doivent \xE9galement \xEAtre rembourr\xE9es \xE0 la longueur maximale rencontr\xE9e dans les \xE9tiquettes. Et, comme mentionn\xE9 pr\xE9c\xE9demment, la valeur de remplissage utilis\xE9e pour remplir les \xE9tiquettes doit \xEAtre "),Fr=l("code"),op=n("-100"),ip=n(" et non le jeton de remplissage du "),Hr=l("em"),up=n("tokenizer"),pp=n(", pour s\u2019assurer que ces valeurs remplies sont ignor\xE9es dans le calcul de la perte."),Io=d(),_s=l("p"),dp=n("Tout ceci est r\xE9alis\xE9 par un "),Oa=l("a"),Ir=l("code"),cp=n("DataCollatorForSeq2Seq"),mp=n(". Comme le "),Br=l("code"),fp=n("DataCollatorWithPadding"),hp=n(", il prend le "),Rr=l("code"),_p=n("tokenizer"),vp=n(" utilis\xE9 pour pr\xE9traiter les entr\xE9es, mais il prend aussi le "),Kr=l("code"),bp=n("model"),$p=n(". C\u2019est parce que ce collateur de donn\xE9es sera \xE9galement responsable de la pr\xE9paration des ID d\u2019entr\xE9e du d\xE9codeur, qui sont des versions d\xE9cal\xE9es des \xE9tiquettes avec un jeton sp\xE9cial au d\xE9but. Comme ce d\xE9calage est effectu\xE9 de mani\xE8re l\xE9g\xE8rement diff\xE9rente selon les architectures, le "),Vr=l("code"),gp=n("DataCollatorForSeq2Seq"),qp=n(" a besoin de conna\xEEtre l\u2019objet "),Gr=l("code"),jp=n("model"),kp=n(" :"),Bo=d(),on.c(),Fl=d(),Hl=l("p"),Ep=n("Pour le tester sur quelques \xE9chantillons, nous l\u2019appelons simplement sur une liste d\u2019exemples de notre ensemble d\u2019entrainement tok\xE9nis\xE9 :"),Ro=d(),E(Ma.$$.fragment),Ko=d(),E(Ua.$$.fragment),Vo=d(),la=l("p"),xp=n("Nous pouvons v\xE9rifier que nos \xE9tiquettes ont \xE9t\xE9 padd\xE9es \xE0 la longueur maximale du lot, en utilisant "),Xr=l("code"),wp=n("-100"),zp=n(" :"),Go=d(),E(Fa.$$.fragment),Xo=d(),E(Ha.$$.fragment),Wo=d(),Il=l("p"),yp=n("Et nous pouvons \xE9galement jeter un coup d\u2019\u0153il aux ID d\u2019entr\xE9e du d\xE9codeur, pour voir qu\u2019il s\u2019agit de versions d\xE9cal\xE9es des \xE9tiquettes :"),Qo=d(),E(Ia.$$.fragment),Jo=d(),E(Ba.$$.fragment),Yo=d(),Bl=l("p"),Pp=n("Voici les \xE9tiquettes des premier et deuxi\xE8me \xE9l\xE9ments de notre jeu de donn\xE9es :"),Zo=d(),E(Ra.$$.fragment),ei=d(),E(Ka.$$.fragment),si=d(),pn.c(),Rl=d(),Hn=l("h3"),ra=l("a"),Wr=l("span"),E(Va.$$.fragment),Cp=d(),Qr=l("span"),Dp=n("M\xE9triques"),ti=d(),E(Ga.$$.fragment),ni=d(),Js&&Js.c(),Kl=d(),Dn=l("p"),Sp=n("La m\xE9trique traditionnelle utilis\xE9e pour la traduction est le "),Xa=l("a"),Tp=n("score BLEU"),Ap=n(", introduit dans "),Wa=l("a"),Np=n("un article de 2002"),Lp=n(" par Kishore Papineni et al. Le score BLEU \xE9value dans quelle mesure les traductions sont proches de leurs \xE9tiquettes. Il ne mesure pas l\u2019intelligibilit\xE9 ou l\u2019exactitude grammaticale des r\xE9sultats g\xE9n\xE9r\xE9s par le mod\xE8le, mais utilise des r\xE8gles statistiques pour garantir que tous les mots des r\xE9sultats g\xE9n\xE9r\xE9s apparaissent \xE9galement dans les cibles. En outre, il existe des r\xE8gles qui p\xE9nalisent les r\xE9p\xE9titions des m\xEAmes mots s\u2019ils ne sont pas \xE9galement r\xE9p\xE9t\xE9s dans les cibles (pour \xE9viter que le mod\xE8le ne produise des phrases telles que \u201Cthe the the the the the the\u201D) et les phrases produites qui sont plus courtes que celles des cibles (pour \xE9viter que le mod\xE8le ne produise des phrases telles que \u201Cthe\u201D)."),ai=d(),Sn=l("p"),Op=n("L\u2019une des faiblesses de BLEU est qu\u2019il s\u2019attend \xE0 ce que le texte soit d\xE9j\xE0 tokenis\xE9, ce qui rend difficile la comparaison des scores entre les mod\xE8les qui utilisent diff\xE9rents "),Jr=l("em"),Mp=n("tokenizers"),Up=n(". Par cons\xE9quent, la mesure la plus couramment utilis\xE9e aujourd\u2019hui pour \xE9valuer les mod\xE8les de traduction est "),Qa=l("a"),Fp=n("SacreBLEU"),Hp=n(", qui rem\xE9die \xE0 cette faiblesse (et \xE0 d\u2019autres) en standardisant l\u2019\xE9tape de tokenisation. Pour utiliser cette m\xE9trique, nous devons d\u2019abord installer la biblioth\xE8que SacreBLEU :"),li=d(),E(Ja.$$.fragment),ri=d(),Tn=l("p"),Ip=n("Nous pouvons ensuite le charger via "),Yr=l("code"),Bp=n("load_metric()"),Rp=n(" comme nous l\u2019avons fait dans le "),Vl=l("a"),Kp=n("Chapitre 3"),Vp=n(" :"),oi=d(),E(Ya.$$.fragment),ii=d(),Gl=l("p"),Gp=n("Cette m\xE9trique prend des textes comme entr\xE9es et cibles. Elle est con\xE7ue pour accepter plusieurs cibles acceptables, car il y a souvent plusieurs traductions acceptables de la m\xEAme phrase. Le jeu de donn\xE9es que nous utilisons n\u2019en fournit qu\u2019une seule, mais il n\u2019est pas rare en NLP de trouver des jeux de donn\xE9es qui donnent plusieurs phrases comme \xE9tiquettes. Ainsi, les pr\xE9dictions doivent \xEAtre une liste de phrases, mais les r\xE9f\xE9rences doivent \xEAtre une liste de listes de phrases."),ui=d(),Xl=l("p"),Xp=n("Essayons un exemple :"),pi=d(),E(Za.$$.fragment),di=d(),E(el.$$.fragment),ci=d(),dt=l("p"),Wp=n("Cela donne un score BLEU de 46.75, ce qui est plut\xF4t bon. Pour r\xE9f\xE9rence, le Transformer original dans l\u2019article "),sl=l("a"),Qp=n("\u201CAttention Is All You Need\u201D"),Jp=n(" a obtenu un score BLEU de 41.8 sur une t\xE2che de traduction similaire entre l\u2019anglais et le fran\xE7ais ! (Pour plus d\u2019informations sur les m\xE9triques individuelles, comme "),Zr=l("code"),Yp=n("counts"),Zp=n(" et "),eo=l("code"),ed=n("bp"),sd=n(", voir le "),tl=l("a"),td=n("D\xE9p\xF4t SacreBLEU"),nd=n(".) D\u2019autre part, si nous essayons avec les deux mauvais types de pr\xE9dictions (batchs de r\xE9p\xE9titions ou trop courts) qui sortent souvent des mod\xE8les de traduction, nous obtiendrons des scores BLEU plut\xF4t mauvais :"),mi=d(),E(nl.$$.fragment),fi=d(),E(al.$$.fragment),hi=d(),E(ll.$$.fragment),_i=d(),E(rl.$$.fragment),vi=d(),Wl=l("p"),ad=n("Le score peut aller de 0 \xE0 100, et plus il est \xE9lev\xE9, mieux c\u2019est."),bi=d(),cn.c(),Ql=d(),Jl=l("p"),ld=n("Maintenant que c\u2019est fait, nous sommes pr\xEAts \xE0 affiner notre mod\xE8le !"),$i=d(),In=l("h3"),oa=l("a"),so=l("span"),E(ol.$$.fragment),rd=d(),to=l("span"),od=n("*Finetuner* le mod\xE8le"),gi=d(),An=l("p"),id=n("La premi\xE8re \xE9tape consiste \xE0 se connecter \xE0 Hugging Face, afin de pouvoir t\xE9l\xE9charger vos r\xE9sultats sur le "),no=l("em"),ud=n("Hub"),pd=n(". Il y a une fonction pratique pour vous aider \xE0 le faire dans un "),ao=l("em"),dd=n("notebook"),cd=n(" :"),qi=d(),E(il.$$.fragment),ji=d(),Yl=l("p"),md=n("Cela affichera un widget o\xF9 vous pourrez entrer vos identifiants de connexion \xE0 Hugging Face."),ki=d(),ia=l("p"),fd=n("Si vous ne travaillez pas dans un "),lo=l("em"),hd=n("notebook"),_d=n(", tapez simplement la ligne suivante dans votre terminal :"),Ei=d(),E(ul.$$.fragment),xi=d(),fn.c(),Zl=d(),rs&&rs.c(),er=d(),Bn=l("h3"),ua=l("a"),ro=l("span"),E(pl.$$.fragment),vd=d(),oo=l("span"),bd=n("Utilisation du mod\xE8le *finetun\xE9*."),wi=d(),ct=l("p"),$d=n("Nous vous avons d\xE9j\xE0 montr\xE9 comment vous pouvez utiliser le mod\xE8le que nous avons "),io=l("em"),gd=n("finetun\xE9"),qd=n(" sur le "),uo=l("em"),jd=n("Hub"),kd=n(" avec le "),po=l("em"),Ed=n("widget"),xd=n(" d\u2019inf\xE9rence. Pour l\u2019utiliser localement dans un "),co=l("code"),wd=n("pipeline"),zd=n(", nous devons juste sp\xE9cifier l\u2019identifiant de mod\xE8le appropri\xE9 :"),zi=d(),E(dl.$$.fragment),yi=d(),E(cl.$$.fragment),Pi=d(),sr=l("p"),yd=n("Comme pr\xE9vu, notre mod\xE8le pr\xE9-entra\xEEn\xE9 a adapt\xE9 ses connaissances au corpus sur lequel nous l\u2019avons affin\xE9, et au lieu de laisser le mot anglais \u201Cthreads\u201D seul, il le traduit maintenant par la version officielle fran\xE7aise. Il en va de m\xEAme pour \u201Cplugin\u201D :"),Ci=d(),E(ml.$$.fragment),Di=d(),E(fl.$$.fragment),Si=d(),tr=l("p"),Pd=n("Un autre excellent exemple d\u2019adaptation au domaine !"),Ti=d(),E(pa.$$.fragment),this.h()},l(e){const u=sf('[data-svelte="svelte-1phssyn"]',document.head);p=r(u,"META",{name:!0,content:!0}),u.forEach(t),g=c(e),x(h.$$.fragment,e),y=c(e),T=r(e,"H1",{class:!0});var ql=o(T);v=r(ql,"A",{id:!0,class:!0,href:!0});var nr=o(v);C=r(nr,"SPAN",{});var mo=o(C);x(S.$$.fragment,mo),mo.forEach(t),nr.forEach(t),P=c(ql),A=r(ql,"SPAN",{});var fo=o(A);R=a(fo,"Traduction"),fo.forEach(t),ql.forEach(t),k=c(e),M.l(e),F=c(e),U=r(e,"P",{});var Rn=o(U);G=a(Rn,"Plongeons maintenant dans la traduction. Il s\u2019agit d\u2019une autre "),O=r(Rn,"A",{href:!0});var ho=o(O);V=a(ho,"t\xE2che de s\xE9quence \xE0 s\xE9quence"),ho.forEach(t),X=a(Rn,", ce qui signifie que c\u2019est un probl\xE8me qui peut \xEAtre formul\xE9 comme le passage d\u2019une s\xE9quence \xE0 une autre. En ce sens, le probl\xE8me est assez proche de la t\xE2che de "),H=r(Rn,"A",{href:!0});var ar=o(H);q=a(ar,"r\xE9sum\xE9"),ar.forEach(t),J=a(Rn," et vous pouvez adapter ce que nous allons voir ici \xE0 d\u2019autres probl\xE8mes de s\xE9quence \xE0 s\xE9quence tels que :"),Rn.forEach(t),W=c(e),te=r(e,"UL",{});var da=o(te);Q=r(da,"LI",{});var Nn=o(Q);Z=a(Nn,"le "),B=r(Nn,"STRONG",{});var lr=o(B);fe=a(lr,"transfert de style"),lr.forEach(t),se=a(Nn," : cr\xE9er un mod\xE8le qui "),he=r(Nn,"EM",{});var rr=o(he);be=a(rr,"traduit"),rr.forEach(t),_e=a(Nn," des textes \xE9crits dans un certain style vers un autre (par exemple, du formel au d\xE9contract\xE9 ou de l\u2019anglais shakespearien \xE0 l\u2019anglais moderne)."),Nn.forEach(t),oe=c(da),re=r(da,"LI",{});var jl=o(re);K=a(jl,"la "),ie=r(jl,"STRONG",{});var Id=o(ie);Ae=a(Id,"g\xE9n\xE9ration de r\xE9ponse \xE0 des questions"),Id.forEach(t),de=a(jl," : Cr\xE9ation d\u2019un mod\xE8le qui g\xE9n\xE8re des r\xE9ponses \xE0 des questions, compte tenu d\u2019un contexte."),jl.forEach(t),da.forEach(t),ee=c(e),x(ge.$$.fragment,e),ue=c(e),ne=r(e,"P",{});var or=o(ne);Ne=a(or,"Si vous disposez d\u2019un corpus suffisamment important de textes en deux langues (ou plus), vous pouvez entra\xEEner un nouveau mod\xE8le de traduction \xE0 partir de z\xE9ro, comme nous le ferons dans la section sur la "),me=r(or,"A",{href:!0});var Bd=o(me);qe=a(Bd,"mod\xE9lisation causale du langage"),Bd.forEach(t),ae=a(or,". Il est toutefois plus rapide de "),ce=r(or,"EM",{});var Rd=o(ce);xe=a(Rd,"finetuner"),Rd.forEach(t),Ye=a(or," un mod\xE8le de traduction existant, qu\u2019il s\u2019agisse d\u2019un mod\xE8le multilingue comme mT5 ou mBART que vous souhaitez adapter \xE0 une paire de langues sp\xE9cifique, ou m\xEAme d\u2019un mod\xE8le sp\xE9cialis\xE9 dans la traduction d\u2019une langue vers une autre que vous souhaitez adapter \xE0 votre corpus sp\xE9cifique."),or.forEach(t),Pe=c(e),pe=r(e,"P",{});var Gt=o(pe);Ze=a(Gt,"Dans cette section, nous allons "),os=r(Gt,"EM",{});var Kd=o(os);je=a(Kd,"finetuner"),Kd.forEach(t),Fs=a(Gt," un mod\xE8le Marian pr\xE9-entra\xEEn\xE9 pour traduire de l\u2019anglais au fran\xE7ais (puisque de nombreux employ\xE9s de Hugging Face parlent ces deux langues) sur le "),Be=r(Gt,"A",{href:!0,rel:!0});var Vd=o(Be);is=a(Vd,"KDE4 dataset"),Vd.forEach(t),es=a(Gt,", qui est un jeu de donn\xE9es de fichiers localis\xE9s pour les "),Le=r(Gt,"A",{href:!0,rel:!0});var Gd=o(Le);we=a(Gd,"KDE apps"),Gd.forEach(t),ss=a(Gt,". Le mod\xE8le que nous utiliserons a \xE9t\xE9 pr\xE9-entra\xEEn\xE9 sur un large corpus de textes fran\xE7ais et anglais provenant du "),Ce=r(Gt,"A",{href:!0,rel:!0});var Xd=o(Ce);j=a(Xd,"jeu de donn\xE9es Opus"),Xd.forEach(t),le=a(Gt,", qui contient en fait le jeu de donn\xE9es KDE4. Mais m\xEAme si le mod\xE8le pr\xE9-entra\xEEn\xE9 que nous utilisons a vu ces donn\xE9es pendant son pr\xE9-entra\xEEnement, nous verrons que nous pouvons obtenir une meilleure version de ce mod\xE8le apr\xE8s un "),Oe=r(Gt,"EM",{});var Wd=o(Oe);Ys=a(Wd,"finetuning"),Wd.forEach(t),Xe=a(Gt,"."),Gt.forEach(t),us=c(e),Re=r(e,"P",{});var Qd=o(Re);Hs=a(Qd,"Une fois que nous aurons termin\xE9, nous aurons un mod\xE8le capable de faire des pr\xE9dictions comme celle-ci :"),Qd.forEach(t),ve=c(e),$e=r(e,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),o($e).forEach(t),ke=c(e),ze=r(e,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),o(ze).forEach(t),ts=c(e),Ee=r(e,"A",{class:!0,href:!0});var Ni=o(Ee);ye=r(Ni,"IMG",{class:!0,src:!0,alt:!0}),et=c(Ni),vs=r(Ni,"IMG",{class:!0,src:!0,alt:!0}),Ni.forEach(t),Is=c(e),We=r(e,"P",{});var ir=o(We);yt=a(ir,"Comme dans les sections pr\xE9c\xE9dentes, vous pouvez trouver le mod\xE8le r\xE9el que nous allons entra\xEEner et t\xE9l\xE9charger sur le "),bs=r(ir,"EM",{});var Jd=o(bs);ft=a(Jd,"Hub"),Jd.forEach(t),Qe=a(ir," en utilisant le code ci-dessous et v\xE9rifier ses pr\xE9dictions "),Ps=r(ir,"A",{href:!0,rel:!0});var Yd=o(Ps);$s=a(Yd,"ici"),Yd.forEach(t),Pt=a(ir,"."),ir.forEach(t),Bs=c(e),ps=r(e,"H2",{class:!0});var Li=o(ps);Je=r(Li,"A",{id:!0,class:!0,href:!0});var Zd=o(Je);gs=r(Zd,"SPAN",{});var ec=o(gs);x(qs.$$.fragment,ec),ec.forEach(t),Zd.forEach(t),Me=c(Li),st=r(Li,"SPAN",{});var sc=o(st);js=a(sc,"Pr\xE9paration des donn\xE9es"),sc.forEach(t),Li.forEach(t),ht=c(e),De=r(e,"P",{});var ca=o(De);_t=a(ca,"Pour affiner ou entra\xEEner un mod\xE8le de traduction \xE0 partir de z\xE9ro, nous avons besoin d\u2019un jeu de donn\xE9es adapt\xE9 \xE0 cette t\xE2che. Comme mentionn\xE9 pr\xE9c\xE9demment, nous utiliserons le jeu de donn\xE9es "),Cs=r(ca,"A",{href:!0,rel:!0});var tc=o(Cs);Ue=a(tc,"KDE4"),tc.forEach(t),Ct=a(ca," dans cette section, mais vous pouvez adapter le code pour utiliser vos propres donn\xE9es assez facilement, tant que vous avez des paires de phrases dans les deux langues que vous voulez traduire de et vers. Reportez-vous au "),Fe=r(ca,"A",{href:!0});var nc=o(Fe);Ds=a(nc,"Chapitre 5"),nc.forEach(t),vt=a(ca," si vous avez besoin d\u2019un rappel sur la fa\xE7on de charger vos donn\xE9es personnalis\xE9es dans un "),ns=r(ca,"CODE",{});var ac=o(ns);Wt=a(ac,"Dataset"),ac.forEach(t),bt=a(ca,"."),ca.forEach(t),tt=c(e),ds=r(e,"H3",{class:!0});var Oi=o(ds);Se=r(Oi,"A",{id:!0,class:!0,href:!0});var lc=o(Se);Rs=r(lc,"SPAN",{});var rc=o(Rs);x(ks.$$.fragment,rc),rc.forEach(t),lc.forEach(t),Qt=c(Oi),nt=r(Oi,"SPAN",{});var oc=o(nt);Es=a(oc,"Le jeu de donn\xE9es KDE4"),oc.forEach(t),Oi.forEach(t),$t=c(e),as=r(e,"P",{});var Mi=o(as);Dt=a(Mi,"Comme d\u2019habitude, nous t\xE9l\xE9chargeons notre jeu de donn\xE9es en utilisant la fonction "),cs=r(Mi,"CODE",{});var ic=o(cs);Ss=a(ic,"load_dataset()"),ic.forEach(t),ls=a(Mi," :"),Mi.forEach(t),xs=c(e),x(ms.$$.fragment,e),at=c(e),Ts=r(e,"P",{});var Ui=o(Ts);lt=a(Ui,"Si vous souhaitez travailler avec une autre paire de langues, vous pouvez les sp\xE9cifier par leurs codes. Au total, 92 langues sont disponibles pour cet ensemble de donn\xE9es ; vous pouvez les voir toutes en d\xE9veloppant les \xE9tiquettes de langue sur sa "),As=r(Ui,"A",{href:!0,rel:!0});var uc=o(As);Ns=a(uc,"fiche"),uc.forEach(t),St=a(Ui,"."),Ui.forEach(t),Ke=c(e),Ls=r(e,"IMG",{src:!0,alt:!0,width:!0}),gt=c(e),f=r(e,"P",{});var pc=o(f);I=a(pc,"Jetons un coup d\u2019\u0153il au jeu  de donn\xE9es :"),pc.forEach(t),Jt=c(e),x(rt.$$.fragment,e),At=c(e),x(Te.$$.fragment,e),ws=c(e),He=r(e,"P",{});var ma=o(He);Nt=a(ma,"Nous avons 210 173 paires de phrases, mais dans un seul split, donc nous devrons cr\xE9er notre propre ensemble de validation. Comme nous l\u2019avons vu dans le "),qt=r(ma,"A",{href:!0});var dc=o(qt);ot=a(dc,"Chapitre 5"),dc.forEach(t),hn=a(ma,", un "),Os=r(ma,"CODE",{});var cc=o(Os);Lt=a(cc,"Dataset"),cc.forEach(t),_n=a(ma," poss\xE8de une m\xE9thode "),Ie=r(ma,"CODE",{});var mc=o(Ie);Yt=a(mc,"train_test_split()"),mc.forEach(t),it=a(ma," qui peut nous aider. Nous allons fournir une graine pour la reproductibilit\xE9 :"),ma.forEach(t),Ot=c(e),x(fs.$$.fragment,e),Mt=c(e),x(Ve.$$.fragment,e),jt=c(e),Ks=r(e,"P",{});var fc=o(Ks);Ut=a(fc,"Nous pouvons renommer la cl\xE9 \u201Ctest\u201D en \u201Cvalidation\u201D comme ceci :"),fc.forEach(t),Zt=c(e),x(hs.$$.fragment,e),kt=c(e),Vs=r(e,"P",{});var hc=o(Vs);vn=a(hc,"Examinons maintenant un \xE9l\xE9ment de ce jeu de donn\xE9es :"),hc.forEach(t),Ft=c(e),x(m.$$.fragment,e),N=c(e),x(Et.$$.fragment,e),bn=c(e),Ht=r(e,"P",{});var _c=o(Ht);xt=a(_c,`Nous obtenons un dictionnaire contenant deux phrases dans la paire de langues demand\xE9e.
Une particularit\xE9 de ce jeu de donn\xE9es rempli de termes techniques informatiques est qu\u2019ils sont tous enti\xE8rement traduits en fran\xE7ais. Cependant, les ing\xE9nieurs fran\xE7ais sont souvent paresseux et laissent la plupart des mots sp\xE9cifiques \xE0 l\u2019informatique en anglais lorsqu\u2019ils parlent. Ici, par exemple, le mot \u201Cthreads\u201D pourrait tr\xE8s bien appara\xEEtre dans une phrase fran\xE7aise, surtout dans une conversation technique. Mais dans ce jeu de donn\xE9es, il a \xE9t\xE9 traduit par le plus correct \u201Cfils de discussion\u201D. Le mod\xE8le pr\xE9-entra\xEEn\xE9 que nous utilisons, qui a \xE9t\xE9 pr\xE9-entra\xEEn\xE9 sur un plus grand corpus de phrases fran\xE7aises et anglaises, prend l\u2019option la plus facile de laisser le mot tel quel :`),_c.forEach(t),$n=c(e),x(Gs.$$.fragment,e),It=c(e),x(Xs.$$.fragment,e),gn=c(e),en=r(e,"P",{});var Fi=o(en);qn=a(Fi,"Un autre exemple de ce comportement peut \xEAtre observ\xE9 avec le mot \u201D"),Kn=r(Fi,"EM",{});var vc=o(Kn);xl=a(vc,"plugin"),vc.forEach(t),wl=a(Fi,`\u201D, qui n\u2019est pas officiellement un mot fran\xE7ais mais que la plupart des locuteurs natifs comprendront et ne prendront pas la peine de traduire.
Dans le jeu de donn\xE9es KDE4, ce mot a \xE9t\xE9 traduit en fran\xE7ais par le plus officiel \u201Cmodule d\u2019extension\u201D :`),Fi.forEach(t),ba=c(e),x(Ms.$$.fragment,e),$a=c(e),x(jn.$$.fragment,e),ga=c(e),Ws=r(e,"P",{});var bc=o(Ws);zl=a(bc,"Notre mod\xE8le pr\xE9-entra\xEEn\xE9, cependant, s\u2019en tient au mot anglais compact et familier :"),bc.forEach(t),qa=c(e),x(kn.$$.fragment,e),Qs=c(e),x(En.$$.fragment,e),ja=c(e),wt=r(e,"P",{});var ur=o(wt);yl=a(ur,"Il sera int\xE9ressant de voir si notre mod\xE8le "),Vn=r(ur,"EM",{});var $c=o(Vn);xn=a($c,"finetun\xE9"),$c.forEach(t),Pl=a(ur," tient compte de ces particularit\xE9s de l\u2019ensemble de donn\xE9es (alerte "),Gn=r(ur,"EM",{});var gc=o(Gn);Xn=a(gc,"spoiler"),gc.forEach(t),Cl=a(ur," : il le fera)."),ur.forEach(t),ka=c(e),x(wn.$$.fragment,e),sn=c(e),x(tn.$$.fragment,e),Ea=c(e),Us=r(e,"H3",{class:!0});var Hi=o(Us);nn=r(Hi,"A",{id:!0,class:!0,href:!0});var qc=o(nn);Wn=r(qc,"SPAN",{});var jc=o(Wn);x(ut.$$.fragment,jc),jc.forEach(t),qc.forEach(t),Dl=c(Hi),Qn=r(Hi,"SPAN",{});var kc=o(Qn);Bt=a(kc,"Traitement des donn\xE9es"),kc.forEach(t),Hi.forEach(t),xa=c(e),x(zn.$$.fragment,e),wa=c(e),Ge=r(e,"P",{});var Ln=o(Ge);Sl=a(Ln,"Vous devriez maintenant conna\xEEtre le principe : les textes doivent tous \xEAtre convertis en ensembles d\u2019ID de "),Jn=r(Ln,"EM",{});var Ec=o(Jn);Tl=a(Ec,"tokens"),Ec.forEach(t),Yi=a(Ln," pour que le mod\xE8le puisse leur donner un sens. Pour cette t\xE2che, nous aurons besoin de tokeniser les entr\xE9es et les cibles. Notre premi\xE8re t\xE2che est de cr\xE9er notre objet "),vr=r(Ln,"CODE",{});var xc=o(vr);Zi=a(xc,"tokenizer"),xc.forEach(t),eu=a(Ln,". Comme indiqu\xE9 pr\xE9c\xE9demment, nous utiliserons un mod\xE8le pr\xE9-entra\xEEn\xE9 Marian English to French. Si vous essayez ce code avec une autre paire de langues, assurez-vous d\u2019adapter le "),br=r(Ln,"EM",{});var wc=o(br);su=a(wc,"checkpoint"),wc.forEach(t),tu=a(Ln," du mod\xE8le. L\u2019organisation "),za=r(Ln,"A",{href:!0,rel:!0});var zc=o(za);nu=a(zc,"Helsinki-NLP"),zc.forEach(t),au=a(Ln," fournit plus de mille mod\xE8les dans plusieurs langues."),Ln.forEach(t),vo=c(e),x(ya.$$.fragment,e),bo=c(e),Rt=r(e,"P",{});var fa=o(Rt);lu=a(fa,"Vous pouvez \xE9galement remplacer le "),$r=r(fa,"CODE",{});var yc=o($r);ru=a(yc,"model_checkpoint"),yc.forEach(t),ou=a(fa," par tout autre mod\xE8le que vous pr\xE9f\xE9rez \xE0 partir du "),Pa=r(fa,"A",{href:!0,rel:!0});var Pc=o(Pa);gr=r(Pc,"EM",{});var Cc=o(gr);iu=a(Cc,"Hub"),Cc.forEach(t),Pc.forEach(t),uu=a(fa,", ou un dossier local o\xF9 vous avez sauvegard\xE9 un mod\xE8le pr\xE9-entra\xEEn\xE9 et un "),qr=r(fa,"EM",{});var Dc=o(qr);pu=a(Dc,"tokenizer"),Dc.forEach(t),du=a(fa,"."),fa.forEach(t),$o=c(e),x(Yn.$$.fragment,e),go=c(e),yn=r(e,"P",{});var pr=o(yn);cu=a(pr,"La pr\xE9paration de nos donn\xE9es est assez simple. Il y a juste une chose \xE0 retenir : vous traitez les entr\xE9es comme d\u2019habitude, mais pour les cibles, vous devez envelopper le "),jr=r(pr,"EM",{});var Sc=o(jr);mu=a(Sc,"tokenizer"),Sc.forEach(t),fu=a(pr," dans le gestionnaire de contexte "),kr=r(pr,"CODE",{});var Tc=o(kr);hu=a(Tc,"as_target_tokenizer()"),Tc.forEach(t),_u=a(pr,"."),pr.forEach(t),qo=c(e),Zn=r(e,"P",{});var Ii=o(Zn);vu=a(Ii,"Un gestionnaire de contexte en Python est introduit avec l\u2019instruction "),Er=r(Ii,"CODE",{});var Ac=o(Er);bu=a(Ac,"with"),Ac.forEach(t),$u=a(Ii," et est utile lorsque vous avez deux op\xE9rations li\xE9es \xE0 ex\xE9cuter en paire. L\u2019exemple le plus courant est lorsque vous \xE9crivez ou lisez un fichier, ce qui est souvent fait dans une instruction comme :"),Ii.forEach(t),jo=c(e),x(Ca.$$.fragment,e),ko=c(e),Pn=r(e,"P",{});var dr=o(Pn);gu=a(dr,"Ici, les deux op\xE9rations connexes qui sont ex\xE9cut\xE9es en paire sont les actions d\u2019ouverture et de fermeture du fichier. L\u2019objet correspondant au fichier ouvert "),xr=r(dr,"CODE",{});var Nc=o(xr);qu=a(Nc,"f"),Nc.forEach(t),ju=a(dr," n\u2019existe qu\u2019\xE0 l\u2019int\xE9rieur du bloc indent\xE9 sous le "),wr=r(dr,"CODE",{});var Lc=o(wr);ku=a(Lc,"with"),Lc.forEach(t),Eu=a(dr," ; l\u2019ouverture se produit avant ce bloc et la fermeture \xE0 la fin du bloc."),dr.forEach(t),Eo=c(e),Cn=r(e,"P",{});var cr=o(Cn);xu=a(cr,"Dans le cas pr\xE9sent, le gestionnaire de contexte "),zr=r(cr,"CODE",{});var Oc=o(zr);wu=a(Oc,"as_target_tokenizer()"),Oc.forEach(t),zu=a(cr," va d\xE9finir le "),yr=r(cr,"EM",{});var Mc=o(yr);yu=a(Mc,"tokenizer"),Mc.forEach(t),Pu=a(cr," dans la langue de sortie (ici, le fran\xE7ais) avant l\u2019ex\xE9cution du bloc indent\xE9, puis le red\xE9finir dans la langue d\u2019entr\xE9e (ici, l\u2019anglais)."),cr.forEach(t),xo=c(e),Al=r(e,"P",{});var Uc=o(Al);Cu=a(Uc,"Ainsi, le pr\xE9traitement d\u2019un \xE9chantillon ressemble \xE0 ceci :"),Uc.forEach(t),wo=c(e),x(Da.$$.fragment,e),zo=c(e),ea=r(e,"P",{});var Bi=o(ea);Du=a(Bi,"Si nous oublions de tokeniser les cibles dans le gestionnaire de contexte, elles seront tokenis\xE9es par le "),Pr=r(Bi,"EM",{});var Fc=o(Pr);Su=a(Fc,"tokenizer"),Fc.forEach(t),Tu=a(Bi," d\u2019entr\xE9e, ce qui, dans le cas d\u2019un mod\xE8le marial, ne va pas du tout bien se passer :"),Bi.forEach(t),yo=c(e),x(Sa.$$.fragment,e),Po=c(e),x(Ta.$$.fragment,e),Co=c(e),Kt=r(e,"P",{});var ha=o(Kt);Au=a(ha,"Comme on peut le voir, utiliser le "),Cr=r(ha,"EM",{});var Hc=o(Cr);Nu=a(Hc,"tokenizer"),Hc.forEach(t),Lu=a(ha," anglais pour pr\xE9traiter une phrase fran\xE7aise donne un batch de "),Dr=r(ha,"EM",{});var Ic=o(Dr);Ou=a(Ic,"tokens"),Ic.forEach(t),Mu=a(ha," plus important, puisque le "),Sr=r(ha,"EM",{});var Bc=o(Sr);Uu=a(Bc,"tokenizer"),Bc.forEach(t),Fu=a(ha," ne conna\xEEt aucun mot fran\xE7ais (sauf ceux qui apparaissent aussi en anglais, comme \u201Cdiscussion\u201D)."),ha.forEach(t),Do=c(e),Vt=r(e,"P",{});var _a=o(Vt);Hu=a(_a,"Les "),Tr=r(_a,"CODE",{});var Rc=o(Tr);Iu=a(Rc,"inputs"),Rc.forEach(t),Bu=a(_a," et les "),Ar=r(_a,"CODE",{});var Kc=o(Ar);Ru=a(Kc,"targets"),Kc.forEach(t),Ku=a(_a," sont des dictionnaires avec nos cl\xE9s habituelles (identifiants d\u2019entr\xE9e, masque d\u2019attention, etc.), donc la derni\xE8re \xE9tape est de d\xE9finir une cl\xE9 "),Nr=r(_a,"CODE",{});var Vc=o(Nr);Vu=a(Vc,'"labels"'),Vc.forEach(t),Gu=a(_a," dans les entr\xE9es. Nous faisons cela dans la fonction de pr\xE9traitement que nous allons appliquer sur les jeux de donn\xE9es :"),_a.forEach(t),So=c(e),x(Aa.$$.fragment,e),To=c(e),Nl=r(e,"P",{});var Gc=o(Nl);Xu=a(Gc,"Notez que nous avons fix\xE9 des longueurs maximales similaires pour nos entr\xE9es et nos sorties. Comme les textes que nous traitons semblent assez courts, nous utilisons 128."),Gc.forEach(t),Ao=c(e),x(sa.$$.fragment,e),No=c(e),x(ta.$$.fragment,e),Lo=c(e),Ll=r(e,"P",{});var Xc=o(Ll);Wu=a(Xc,"Nous pouvons maintenant appliquer ce pr\xE9traitement en une seule fois sur toutes les divisions de notre jeu de donn\xE9es :"),Xc.forEach(t),Oo=c(e),x(Na.$$.fragment,e),Mo=c(e),na=r(e,"P",{});var Ri=o(na);Qu=a(Ri,"Maintenant que les donn\xE9es ont \xE9t\xE9 pr\xE9trait\xE9es, nous sommes pr\xEAts \xE0 "),Lr=r(Ri,"EM",{});var Wc=o(Lr);Ju=a(Wc,"finetuner"),Wc.forEach(t),Yu=a(Ri," notre mod\xE8le pr\xE9-entra\xEEn\xE9 !"),Ri.forEach(t),Uo=c(e),ln.l(e),Ol=c(e),Ml=r(e,"P",{});var Qc=o(Ml);Zu=a(Qc,"Notez que cette fois-ci, nous utilisons un mod\xE8le qui a \xE9t\xE9 entra\xEEn\xE9 sur une t\xE2che de traduction et qui peut d\xE9j\xE0 \xEAtre utilis\xE9, donc il n\u2019y a pas d\u2019avertissement concernant les poids manquants ou ceux nouvellement initialis\xE9s."),Qc.forEach(t),Fo=c(e),Fn=r(e,"H3",{class:!0});var Ki=o(Fn);aa=r(Ki,"A",{id:!0,class:!0,href:!0});var Jc=o(aa);Or=r(Jc,"SPAN",{});var Yc=o(Or);x(La.$$.fragment,Yc),Yc.forEach(t),Jc.forEach(t),ep=c(Ki),Mr=r(Ki,"SPAN",{});var Zc=o(Mr);sp=a(Zc,"Collecte des donn\xE9es"),Zc.forEach(t),Ki.forEach(t),Ho=c(e),pt=r(e,"P",{});var On=o(pt);tp=a(On,"Nous aurons besoin d\u2019un assembleur de donn\xE9es pour g\xE9rer le rembourrage pour la mise en lots dynamique. Nous ne pouvons pas simplement utiliser un "),Ur=r(On,"CODE",{});var em=o(Ur);np=a(em,"DataCollatorWithPadding"),em.forEach(t),ap=a(On," comme dans "),Ul=r(On,"A",{href:!0});var sm=o(Ul);lp=a(sm,"Chapter 3"),sm.forEach(t),rp=a(On," dans ce cas, parce que cela ne rembourre que les entr\xE9es (ID d\u2019entr\xE9e, masque d\u2019attention, et ID de type de jeton). Nos \xE9tiquettes doivent \xE9galement \xEAtre rembourr\xE9es \xE0 la longueur maximale rencontr\xE9e dans les \xE9tiquettes. Et, comme mentionn\xE9 pr\xE9c\xE9demment, la valeur de remplissage utilis\xE9e pour remplir les \xE9tiquettes doit \xEAtre "),Fr=r(On,"CODE",{});var tm=o(Fr);op=a(tm,"-100"),tm.forEach(t),ip=a(On," et non le jeton de remplissage du "),Hr=r(On,"EM",{});var nm=o(Hr);up=a(nm,"tokenizer"),nm.forEach(t),pp=a(On,", pour s\u2019assurer que ces valeurs remplies sont ignor\xE9es dans le calcul de la perte."),On.forEach(t),Io=c(e),_s=r(e,"P",{});var mt=o(_s);dp=a(mt,"Tout ceci est r\xE9alis\xE9 par un "),Oa=r(mt,"A",{href:!0,rel:!0});var am=o(Oa);Ir=r(am,"CODE",{});var lm=o(Ir);cp=a(lm,"DataCollatorForSeq2Seq"),lm.forEach(t),am.forEach(t),mp=a(mt,". Comme le "),Br=r(mt,"CODE",{});var rm=o(Br);fp=a(rm,"DataCollatorWithPadding"),rm.forEach(t),hp=a(mt,", il prend le "),Rr=r(mt,"CODE",{});var om=o(Rr);_p=a(om,"tokenizer"),om.forEach(t),vp=a(mt," utilis\xE9 pour pr\xE9traiter les entr\xE9es, mais il prend aussi le "),Kr=r(mt,"CODE",{});var im=o(Kr);bp=a(im,"model"),im.forEach(t),$p=a(mt,". C\u2019est parce que ce collateur de donn\xE9es sera \xE9galement responsable de la pr\xE9paration des ID d\u2019entr\xE9e du d\xE9codeur, qui sont des versions d\xE9cal\xE9es des \xE9tiquettes avec un jeton sp\xE9cial au d\xE9but. Comme ce d\xE9calage est effectu\xE9 de mani\xE8re l\xE9g\xE8rement diff\xE9rente selon les architectures, le "),Vr=r(mt,"CODE",{});var um=o(Vr);gp=a(um,"DataCollatorForSeq2Seq"),um.forEach(t),qp=a(mt," a besoin de conna\xEEtre l\u2019objet "),Gr=r(mt,"CODE",{});var pm=o(Gr);jp=a(pm,"model"),pm.forEach(t),kp=a(mt," :"),mt.forEach(t),Bo=c(e),on.l(e),Fl=c(e),Hl=r(e,"P",{});var dm=o(Hl);Ep=a(dm,"Pour le tester sur quelques \xE9chantillons, nous l\u2019appelons simplement sur une liste d\u2019exemples de notre ensemble d\u2019entrainement tok\xE9nis\xE9 :"),dm.forEach(t),Ro=c(e),x(Ma.$$.fragment,e),Ko=c(e),x(Ua.$$.fragment,e),Vo=c(e),la=r(e,"P",{});var Vi=o(la);xp=a(Vi,"Nous pouvons v\xE9rifier que nos \xE9tiquettes ont \xE9t\xE9 padd\xE9es \xE0 la longueur maximale du lot, en utilisant "),Xr=r(Vi,"CODE",{});var cm=o(Xr);wp=a(cm,"-100"),cm.forEach(t),zp=a(Vi," :"),Vi.forEach(t),Go=c(e),x(Fa.$$.fragment,e),Xo=c(e),x(Ha.$$.fragment,e),Wo=c(e),Il=r(e,"P",{});var mm=o(Il);yp=a(mm,"Et nous pouvons \xE9galement jeter un coup d\u2019\u0153il aux ID d\u2019entr\xE9e du d\xE9codeur, pour voir qu\u2019il s\u2019agit de versions d\xE9cal\xE9es des \xE9tiquettes :"),mm.forEach(t),Qo=c(e),x(Ia.$$.fragment,e),Jo=c(e),x(Ba.$$.fragment,e),Yo=c(e),Bl=r(e,"P",{});var fm=o(Bl);Pp=a(fm,"Voici les \xE9tiquettes des premier et deuxi\xE8me \xE9l\xE9ments de notre jeu de donn\xE9es :"),fm.forEach(t),Zo=c(e),x(Ra.$$.fragment,e),ei=c(e),x(Ka.$$.fragment,e),si=c(e),pn.l(e),Rl=c(e),Hn=r(e,"H3",{class:!0});var Gi=o(Hn);ra=r(Gi,"A",{id:!0,class:!0,href:!0});var hm=o(ra);Wr=r(hm,"SPAN",{});var _m=o(Wr);x(Va.$$.fragment,_m),_m.forEach(t),hm.forEach(t),Cp=c(Gi),Qr=r(Gi,"SPAN",{});var vm=o(Qr);Dp=a(vm,"M\xE9triques"),vm.forEach(t),Gi.forEach(t),ti=c(e),x(Ga.$$.fragment,e),ni=c(e),Js&&Js.l(e),Kl=c(e),Dn=r(e,"P",{});var mr=o(Dn);Sp=a(mr,"La m\xE9trique traditionnelle utilis\xE9e pour la traduction est le "),Xa=r(mr,"A",{href:!0,rel:!0});var bm=o(Xa);Tp=a(bm,"score BLEU"),bm.forEach(t),Ap=a(mr,", introduit dans "),Wa=r(mr,"A",{href:!0,rel:!0});var $m=o(Wa);Np=a($m,"un article de 2002"),$m.forEach(t),Lp=a(mr," par Kishore Papineni et al. Le score BLEU \xE9value dans quelle mesure les traductions sont proches de leurs \xE9tiquettes. Il ne mesure pas l\u2019intelligibilit\xE9 ou l\u2019exactitude grammaticale des r\xE9sultats g\xE9n\xE9r\xE9s par le mod\xE8le, mais utilise des r\xE8gles statistiques pour garantir que tous les mots des r\xE9sultats g\xE9n\xE9r\xE9s apparaissent \xE9galement dans les cibles. En outre, il existe des r\xE8gles qui p\xE9nalisent les r\xE9p\xE9titions des m\xEAmes mots s\u2019ils ne sont pas \xE9galement r\xE9p\xE9t\xE9s dans les cibles (pour \xE9viter que le mod\xE8le ne produise des phrases telles que \u201Cthe the the the the the the\u201D) et les phrases produites qui sont plus courtes que celles des cibles (pour \xE9viter que le mod\xE8le ne produise des phrases telles que \u201Cthe\u201D)."),mr.forEach(t),ai=c(e),Sn=r(e,"P",{});var fr=o(Sn);Op=a(fr,"L\u2019une des faiblesses de BLEU est qu\u2019il s\u2019attend \xE0 ce que le texte soit d\xE9j\xE0 tokenis\xE9, ce qui rend difficile la comparaison des scores entre les mod\xE8les qui utilisent diff\xE9rents "),Jr=r(fr,"EM",{});var gm=o(Jr);Mp=a(gm,"tokenizers"),gm.forEach(t),Up=a(fr,". Par cons\xE9quent, la mesure la plus couramment utilis\xE9e aujourd\u2019hui pour \xE9valuer les mod\xE8les de traduction est "),Qa=r(fr,"A",{href:!0,rel:!0});var qm=o(Qa);Fp=a(qm,"SacreBLEU"),qm.forEach(t),Hp=a(fr,", qui rem\xE9die \xE0 cette faiblesse (et \xE0 d\u2019autres) en standardisant l\u2019\xE9tape de tokenisation. Pour utiliser cette m\xE9trique, nous devons d\u2019abord installer la biblioth\xE8que SacreBLEU :"),fr.forEach(t),li=c(e),x(Ja.$$.fragment,e),ri=c(e),Tn=r(e,"P",{});var hr=o(Tn);Ip=a(hr,"Nous pouvons ensuite le charger via "),Yr=r(hr,"CODE",{});var jm=o(Yr);Bp=a(jm,"load_metric()"),jm.forEach(t),Rp=a(hr," comme nous l\u2019avons fait dans le "),Vl=r(hr,"A",{href:!0});var km=o(Vl);Kp=a(km,"Chapitre 3"),km.forEach(t),Vp=a(hr," :"),hr.forEach(t),oi=c(e),x(Ya.$$.fragment,e),ii=c(e),Gl=r(e,"P",{});var Em=o(Gl);Gp=a(Em,"Cette m\xE9trique prend des textes comme entr\xE9es et cibles. Elle est con\xE7ue pour accepter plusieurs cibles acceptables, car il y a souvent plusieurs traductions acceptables de la m\xEAme phrase. Le jeu de donn\xE9es que nous utilisons n\u2019en fournit qu\u2019une seule, mais il n\u2019est pas rare en NLP de trouver des jeux de donn\xE9es qui donnent plusieurs phrases comme \xE9tiquettes. Ainsi, les pr\xE9dictions doivent \xEAtre une liste de phrases, mais les r\xE9f\xE9rences doivent \xEAtre une liste de listes de phrases."),Em.forEach(t),ui=c(e),Xl=r(e,"P",{});var xm=o(Xl);Xp=a(xm,"Essayons un exemple :"),xm.forEach(t),pi=c(e),x(Za.$$.fragment,e),di=c(e),x(el.$$.fragment,e),ci=c(e),dt=r(e,"P",{});var Mn=o(dt);Wp=a(Mn,"Cela donne un score BLEU de 46.75, ce qui est plut\xF4t bon. Pour r\xE9f\xE9rence, le Transformer original dans l\u2019article "),sl=r(Mn,"A",{href:!0,rel:!0});var wm=o(sl);Qp=a(wm,"\u201CAttention Is All You Need\u201D"),wm.forEach(t),Jp=a(Mn," a obtenu un score BLEU de 41.8 sur une t\xE2che de traduction similaire entre l\u2019anglais et le fran\xE7ais ! (Pour plus d\u2019informations sur les m\xE9triques individuelles, comme "),Zr=r(Mn,"CODE",{});var zm=o(Zr);Yp=a(zm,"counts"),zm.forEach(t),Zp=a(Mn," et "),eo=r(Mn,"CODE",{});var ym=o(eo);ed=a(ym,"bp"),ym.forEach(t),sd=a(Mn,", voir le "),tl=r(Mn,"A",{href:!0,rel:!0});var Pm=o(tl);td=a(Pm,"D\xE9p\xF4t SacreBLEU"),Pm.forEach(t),nd=a(Mn,".) D\u2019autre part, si nous essayons avec les deux mauvais types de pr\xE9dictions (batchs de r\xE9p\xE9titions ou trop courts) qui sortent souvent des mod\xE8les de traduction, nous obtiendrons des scores BLEU plut\xF4t mauvais :"),Mn.forEach(t),mi=c(e),x(nl.$$.fragment,e),fi=c(e),x(al.$$.fragment,e),hi=c(e),x(ll.$$.fragment,e),_i=c(e),x(rl.$$.fragment,e),vi=c(e),Wl=r(e,"P",{});var Cm=o(Wl);ad=a(Cm,"Le score peut aller de 0 \xE0 100, et plus il est \xE9lev\xE9, mieux c\u2019est."),Cm.forEach(t),bi=c(e),cn.l(e),Ql=c(e),Jl=r(e,"P",{});var Dm=o(Jl);ld=a(Dm,"Maintenant que c\u2019est fait, nous sommes pr\xEAts \xE0 affiner notre mod\xE8le !"),Dm.forEach(t),$i=c(e),In=r(e,"H3",{class:!0});var Xi=o(In);oa=r(Xi,"A",{id:!0,class:!0,href:!0});var Sm=o(oa);so=r(Sm,"SPAN",{});var Tm=o(so);x(ol.$$.fragment,Tm),Tm.forEach(t),Sm.forEach(t),rd=c(Xi),to=r(Xi,"SPAN",{});var Am=o(to);od=a(Am,"*Finetuner* le mod\xE8le"),Am.forEach(t),Xi.forEach(t),gi=c(e),An=r(e,"P",{});var _r=o(An);id=a(_r,"La premi\xE8re \xE9tape consiste \xE0 se connecter \xE0 Hugging Face, afin de pouvoir t\xE9l\xE9charger vos r\xE9sultats sur le "),no=r(_r,"EM",{});var Nm=o(no);ud=a(Nm,"Hub"),Nm.forEach(t),pd=a(_r,". Il y a une fonction pratique pour vous aider \xE0 le faire dans un "),ao=r(_r,"EM",{});var Lm=o(ao);dd=a(Lm,"notebook"),Lm.forEach(t),cd=a(_r," :"),_r.forEach(t),qi=c(e),x(il.$$.fragment,e),ji=c(e),Yl=r(e,"P",{});var Om=o(Yl);md=a(Om,"Cela affichera un widget o\xF9 vous pourrez entrer vos identifiants de connexion \xE0 Hugging Face."),Om.forEach(t),ki=c(e),ia=r(e,"P",{});var Wi=o(ia);fd=a(Wi,"Si vous ne travaillez pas dans un "),lo=r(Wi,"EM",{});var Mm=o(lo);hd=a(Mm,"notebook"),Mm.forEach(t),_d=a(Wi,", tapez simplement la ligne suivante dans votre terminal :"),Wi.forEach(t),Ei=c(e),x(ul.$$.fragment,e),xi=c(e),fn.l(e),Zl=c(e),rs&&rs.l(e),er=c(e),Bn=r(e,"H3",{class:!0});var Qi=o(Bn);ua=r(Qi,"A",{id:!0,class:!0,href:!0});var Um=o(ua);ro=r(Um,"SPAN",{});var Fm=o(ro);x(pl.$$.fragment,Fm),Fm.forEach(t),Um.forEach(t),vd=c(Qi),oo=r(Qi,"SPAN",{});var Hm=o(oo);bd=a(Hm,"Utilisation du mod\xE8le *finetun\xE9*."),Hm.forEach(t),Qi.forEach(t),wi=c(e),ct=r(e,"P",{});var Un=o(ct);$d=a(Un,"Nous vous avons d\xE9j\xE0 montr\xE9 comment vous pouvez utiliser le mod\xE8le que nous avons "),io=r(Un,"EM",{});var Im=o(io);gd=a(Im,"finetun\xE9"),Im.forEach(t),qd=a(Un," sur le "),uo=r(Un,"EM",{});var Bm=o(uo);jd=a(Bm,"Hub"),Bm.forEach(t),kd=a(Un," avec le "),po=r(Un,"EM",{});var Rm=o(po);Ed=a(Rm,"widget"),Rm.forEach(t),xd=a(Un," d\u2019inf\xE9rence. Pour l\u2019utiliser localement dans un "),co=r(Un,"CODE",{});var Km=o(co);wd=a(Km,"pipeline"),Km.forEach(t),zd=a(Un,", nous devons juste sp\xE9cifier l\u2019identifiant de mod\xE8le appropri\xE9 :"),Un.forEach(t),zi=c(e),x(dl.$$.fragment,e),yi=c(e),x(cl.$$.fragment,e),Pi=c(e),sr=r(e,"P",{});var Vm=o(sr);yd=a(Vm,"Comme pr\xE9vu, notre mod\xE8le pr\xE9-entra\xEEn\xE9 a adapt\xE9 ses connaissances au corpus sur lequel nous l\u2019avons affin\xE9, et au lieu de laisser le mot anglais \u201Cthreads\u201D seul, il le traduit maintenant par la version officielle fran\xE7aise. Il en va de m\xEAme pour \u201Cplugin\u201D :"),Vm.forEach(t),Ci=c(e),x(ml.$$.fragment,e),Di=c(e),x(fl.$$.fragment,e),Si=c(e),tr=r(e,"P",{});var Gm=o(tr);Pd=a(Gm,"Un autre excellent exemple d\u2019adaptation au domaine !"),Gm.forEach(t),Ti=c(e),x(pa.$$.fragment,e),this.h()},h(){_(p,"name","hf:doc:metadata"),_(p,"content",JSON.stringify(wf)),_(v,"id","traduction"),_(v,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(v,"href","#traduction"),_(T,"class","relative group"),_(O,"href","/cours/fr/chapitre1/7"),_(H,"href","/cours/fr/chapitre7/6"),_(me,"href","/cours/fr/chapitre7/6"),_(Be,"href","https://huggingface.co/datasets/kde4"),_(Be,"rel","nofollow"),_(Le,"href","https://apps.kde.org/"),_(Le,"rel","nofollow"),_(Ce,"href","https://opus.nlpl.eu/"),_(Ce,"rel","nofollow"),_o($e.src,zs="https://hf.space/gradioiframe/course-demos/marian-finetuned-kde4-en-to-fr/+")||_($e,"src",zs),_($e,"frameborder","0"),_($e,"height","350"),_($e,"title","Gradio app"),_($e,"class","block dark:hidden container p-0 flex-grow space-iframe"),_($e,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),_($e,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"),_o(ze.src,ys="https://hf.space/gradioiframe/course-demos/marian-finetuned-kde4-en-to-fr-darkmode/+")||_(ze,"src",ys),_(ze,"frameborder","0"),_(ze,"height","350"),_(ze,"title","Gradio app"),_(ze,"class","hidden dark:block container p-0 flex-grow space-iframe"),_(ze,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),_(ze,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"),_(ye,"class","block dark:hidden lg:w-3/5"),_o(ye.src,Zs="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/modeleval-marian-finetuned-kde4-en-to-fr.png")||_(ye,"src",Zs),_(ye,"alt","One-hot encoded labels for question answering."),_(vs,"class","hidden dark:block lg:w-3/5"),_o(vs.src,Xt="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/modeleval-marian-finetuned-kde4-en-to-fr-dark.png")||_(vs,"src",Xt),_(vs,"alt","One-hot encoded labels for question answering."),_(Ee,"class","flex justify-center"),_(Ee,"href","/huggingface-course/marian-finetuned-kde4-en-to-fr"),_(Ps,"href","https://huggingface.co/huggingface-course/marian-finetuned-kde4-en-to-fr?text=This+plugin+allows+you+to+automatically+translate+web+pages+between+several+languages."),_(Ps,"rel","nofollow"),_(Je,"id","prparation-des-donnes"),_(Je,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Je,"href","#prparation-des-donnes"),_(ps,"class","relative group"),_(Cs,"href","https://huggingface.co/datasets/kde4"),_(Cs,"rel","nofollow"),_(Fe,"href","/course/fr/chapter5"),_(Se,"id","le-jeu-de-donnes-kde4"),_(Se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Se,"href","#le-jeu-de-donnes-kde4"),_(ds,"class","relative group"),_(As,"href","https://huggingface.co/datasets/kde4"),_(As,"rel","nofollow"),_o(Ls.src,Tt="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/language_tags.png")||_(Ls,"src",Tt),_(Ls,"alt","Language available for the KDE4 dataset."),_(Ls,"width","100%"),_(qt,"href","/course/fr/chapter5"),_(nn,"id","traitement-des-donnes"),_(nn,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(nn,"href","#traitement-des-donnes"),_(Us,"class","relative group"),_(za,"href","https://huggingface.co/Helsinki-NLP"),_(za,"rel","nofollow"),_(Pa,"href","https://huggingface.co/models"),_(Pa,"rel","nofollow"),_(aa,"id","collecte-des-donnes"),_(aa,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(aa,"href","#collecte-des-donnes"),_(Fn,"class","relative group"),_(Ul,"href","/course/fr/chapter3"),_(Oa,"href","https://huggingface.co/transformers/main_classes/data_collator.html#datacollatorforseq2seq"),_(Oa,"rel","nofollow"),_(ra,"id","mtriques"),_(ra,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(ra,"href","#mtriques"),_(Hn,"class","relative group"),_(Xa,"href","https://en.wikipedia.org/wiki/BLEU"),_(Xa,"rel","nofollow"),_(Wa,"href","https://aclanthology.org/P02-1040.pdf"),_(Wa,"rel","nofollow"),_(Qa,"href","https://github.com/mjpost/sacrebleu"),_(Qa,"rel","nofollow"),_(Vl,"href","/course/fr/chapter3"),_(sl,"href","https://arxiv.org/pdf/1706.03762.pdf"),_(sl,"rel","nofollow"),_(tl,"href","https://github.com/mjpost/sacrebleu/blob/078c440168c6adc89ba75fe6d63f0d922d42bcfe/sacrebleu/metrics/bleu.py#L74"),_(tl,"rel","nofollow"),_(oa,"id","finetuner-le-modle"),_(oa,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(oa,"href","#finetuner-le-modle"),_(In,"class","relative group"),_(ua,"id","utilisation-du-modle-finetun"),_(ua,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(ua,"href","#utilisation-du-modle-finetun"),_(Bn,"class","relative group")},m(e,u){s(document.head,p),i(e,g,u),w(h,e,u),i(e,y,u),i(e,T,u),s(T,v),s(v,C),w(S,C,null),s(T,P),s(T,A),s(A,R),i(e,k,u),hl[D].m(e,u),i(e,F,u),i(e,U,u),s(U,G),s(U,O),s(O,V),s(U,X),s(U,H),s(H,q),s(U,J),i(e,W,u),i(e,te,u),s(te,Q),s(Q,Z),s(Q,B),s(B,fe),s(Q,se),s(Q,he),s(he,be),s(Q,_e),s(te,oe),s(te,re),s(re,K),s(re,ie),s(ie,Ae),s(re,de),i(e,ee,u),w(ge,e,u),i(e,ue,u),i(e,ne,u),s(ne,Ne),s(ne,me),s(me,qe),s(ne,ae),s(ne,ce),s(ce,xe),s(ne,Ye),i(e,Pe,u),i(e,pe,u),s(pe,Ze),s(pe,os),s(os,je),s(pe,Fs),s(pe,Be),s(Be,is),s(pe,es),s(pe,Le),s(Le,we),s(pe,ss),s(pe,Ce),s(Ce,j),s(pe,le),s(pe,Oe),s(Oe,Ys),s(pe,Xe),i(e,us,u),i(e,Re,u),s(Re,Hs),i(e,ve,u),i(e,$e,u),i(e,ke,u),i(e,ze,u),i(e,ts,u),i(e,Ee,u),s(Ee,ye),s(Ee,et),s(Ee,vs),i(e,Is,u),i(e,We,u),s(We,yt),s(We,bs),s(bs,ft),s(We,Qe),s(We,Ps),s(Ps,$s),s(We,Pt),i(e,Bs,u),i(e,ps,u),s(ps,Je),s(Je,gs),w(qs,gs,null),s(ps,Me),s(ps,st),s(st,js),i(e,ht,u),i(e,De,u),s(De,_t),s(De,Cs),s(Cs,Ue),s(De,Ct),s(De,Fe),s(Fe,Ds),s(De,vt),s(De,ns),s(ns,Wt),s(De,bt),i(e,tt,u),i(e,ds,u),s(ds,Se),s(Se,Rs),w(ks,Rs,null),s(ds,Qt),s(ds,nt),s(nt,Es),i(e,$t,u),i(e,as,u),s(as,Dt),s(as,cs),s(cs,Ss),s(as,ls),i(e,xs,u),w(ms,e,u),i(e,at,u),i(e,Ts,u),s(Ts,lt),s(Ts,As),s(As,Ns),s(Ts,St),i(e,Ke,u),i(e,Ls,u),i(e,gt,u),i(e,f,u),s(f,I),i(e,Jt,u),w(rt,e,u),i(e,At,u),w(Te,e,u),i(e,ws,u),i(e,He,u),s(He,Nt),s(He,qt),s(qt,ot),s(He,hn),s(He,Os),s(Os,Lt),s(He,_n),s(He,Ie),s(Ie,Yt),s(He,it),i(e,Ot,u),w(fs,e,u),i(e,Mt,u),w(Ve,e,u),i(e,jt,u),i(e,Ks,u),s(Ks,Ut),i(e,Zt,u),w(hs,e,u),i(e,kt,u),i(e,Vs,u),s(Vs,vn),i(e,Ft,u),w(m,e,u),i(e,N,u),w(Et,e,u),i(e,bn,u),i(e,Ht,u),s(Ht,xt),i(e,$n,u),w(Gs,e,u),i(e,It,u),w(Xs,e,u),i(e,gn,u),i(e,en,u),s(en,qn),s(en,Kn),s(Kn,xl),s(en,wl),i(e,ba,u),w(Ms,e,u),i(e,$a,u),w(jn,e,u),i(e,ga,u),i(e,Ws,u),s(Ws,zl),i(e,qa,u),w(kn,e,u),i(e,Qs,u),w(En,e,u),i(e,ja,u),i(e,wt,u),s(wt,yl),s(wt,Vn),s(Vn,xn),s(wt,Pl),s(wt,Gn),s(Gn,Xn),s(wt,Cl),i(e,ka,u),w(wn,e,u),i(e,sn,u),w(tn,e,u),i(e,Ea,u),i(e,Us,u),s(Us,nn),s(nn,Wn),w(ut,Wn,null),s(Us,Dl),s(Us,Qn),s(Qn,Bt),i(e,xa,u),w(zn,e,u),i(e,wa,u),i(e,Ge,u),s(Ge,Sl),s(Ge,Jn),s(Jn,Tl),s(Ge,Yi),s(Ge,vr),s(vr,Zi),s(Ge,eu),s(Ge,br),s(br,su),s(Ge,tu),s(Ge,za),s(za,nu),s(Ge,au),i(e,vo,u),w(ya,e,u),i(e,bo,u),i(e,Rt,u),s(Rt,lu),s(Rt,$r),s($r,ru),s(Rt,ou),s(Rt,Pa),s(Pa,gr),s(gr,iu),s(Rt,uu),s(Rt,qr),s(qr,pu),s(Rt,du),i(e,$o,u),w(Yn,e,u),i(e,go,u),i(e,yn,u),s(yn,cu),s(yn,jr),s(jr,mu),s(yn,fu),s(yn,kr),s(kr,hu),s(yn,_u),i(e,qo,u),i(e,Zn,u),s(Zn,vu),s(Zn,Er),s(Er,bu),s(Zn,$u),i(e,jo,u),w(Ca,e,u),i(e,ko,u),i(e,Pn,u),s(Pn,gu),s(Pn,xr),s(xr,qu),s(Pn,ju),s(Pn,wr),s(wr,ku),s(Pn,Eu),i(e,Eo,u),i(e,Cn,u),s(Cn,xu),s(Cn,zr),s(zr,wu),s(Cn,zu),s(Cn,yr),s(yr,yu),s(Cn,Pu),i(e,xo,u),i(e,Al,u),s(Al,Cu),i(e,wo,u),w(Da,e,u),i(e,zo,u),i(e,ea,u),s(ea,Du),s(ea,Pr),s(Pr,Su),s(ea,Tu),i(e,yo,u),w(Sa,e,u),i(e,Po,u),w(Ta,e,u),i(e,Co,u),i(e,Kt,u),s(Kt,Au),s(Kt,Cr),s(Cr,Nu),s(Kt,Lu),s(Kt,Dr),s(Dr,Ou),s(Kt,Mu),s(Kt,Sr),s(Sr,Uu),s(Kt,Fu),i(e,Do,u),i(e,Vt,u),s(Vt,Hu),s(Vt,Tr),s(Tr,Iu),s(Vt,Bu),s(Vt,Ar),s(Ar,Ru),s(Vt,Ku),s(Vt,Nr),s(Nr,Vu),s(Vt,Gu),i(e,So,u),w(Aa,e,u),i(e,To,u),i(e,Nl,u),s(Nl,Xu),i(e,Ao,u),w(sa,e,u),i(e,No,u),w(ta,e,u),i(e,Lo,u),i(e,Ll,u),s(Ll,Wu),i(e,Oo,u),w(Na,e,u),i(e,Mo,u),i(e,na,u),s(na,Qu),s(na,Lr),s(Lr,Ju),s(na,Yu),i(e,Uo,u),_l[an].m(e,u),i(e,Ol,u),i(e,Ml,u),s(Ml,Zu),i(e,Fo,u),i(e,Fn,u),s(Fn,aa),s(aa,Or),w(La,Or,null),s(Fn,ep),s(Fn,Mr),s(Mr,sp),i(e,Ho,u),i(e,pt,u),s(pt,tp),s(pt,Ur),s(Ur,np),s(pt,ap),s(pt,Ul),s(Ul,lp),s(pt,rp),s(pt,Fr),s(Fr,op),s(pt,ip),s(pt,Hr),s(Hr,up),s(pt,pp),i(e,Io,u),i(e,_s,u),s(_s,dp),s(_s,Oa),s(Oa,Ir),s(Ir,cp),s(_s,mp),s(_s,Br),s(Br,fp),s(_s,hp),s(_s,Rr),s(Rr,_p),s(_s,vp),s(_s,Kr),s(Kr,bp),s(_s,$p),s(_s,Vr),s(Vr,gp),s(_s,qp),s(_s,Gr),s(Gr,jp),s(_s,kp),i(e,Bo,u),vl[rn].m(e,u),i(e,Fl,u),i(e,Hl,u),s(Hl,Ep),i(e,Ro,u),w(Ma,e,u),i(e,Ko,u),w(Ua,e,u),i(e,Vo,u),i(e,la,u),s(la,xp),s(la,Xr),s(Xr,wp),s(la,zp),i(e,Go,u),w(Fa,e,u),i(e,Xo,u),w(Ha,e,u),i(e,Wo,u),i(e,Il,u),s(Il,yp),i(e,Qo,u),w(Ia,e,u),i(e,Jo,u),w(Ba,e,u),i(e,Yo,u),i(e,Bl,u),s(Bl,Pp),i(e,Zo,u),w(Ra,e,u),i(e,ei,u),w(Ka,e,u),i(e,si,u),bl[un].m(e,u),i(e,Rl,u),i(e,Hn,u),s(Hn,ra),s(ra,Wr),w(Va,Wr,null),s(Hn,Cp),s(Hn,Qr),s(Qr,Dp),i(e,ti,u),w(Ga,e,u),i(e,ni,u),Js&&Js.m(e,u),i(e,Kl,u),i(e,Dn,u),s(Dn,Sp),s(Dn,Xa),s(Xa,Tp),s(Dn,Ap),s(Dn,Wa),s(Wa,Np),s(Dn,Lp),i(e,ai,u),i(e,Sn,u),s(Sn,Op),s(Sn,Jr),s(Jr,Mp),s(Sn,Up),s(Sn,Qa),s(Qa,Fp),s(Sn,Hp),i(e,li,u),w(Ja,e,u),i(e,ri,u),i(e,Tn,u),s(Tn,Ip),s(Tn,Yr),s(Yr,Bp),s(Tn,Rp),s(Tn,Vl),s(Vl,Kp),s(Tn,Vp),i(e,oi,u),w(Ya,e,u),i(e,ii,u),i(e,Gl,u),s(Gl,Gp),i(e,ui,u),i(e,Xl,u),s(Xl,Xp),i(e,pi,u),w(Za,e,u),i(e,di,u),w(el,e,u),i(e,ci,u),i(e,dt,u),s(dt,Wp),s(dt,sl),s(sl,Qp),s(dt,Jp),s(dt,Zr),s(Zr,Yp),s(dt,Zp),s(dt,eo),s(eo,ed),s(dt,sd),s(dt,tl),s(tl,td),s(dt,nd),i(e,mi,u),w(nl,e,u),i(e,fi,u),w(al,e,u),i(e,hi,u),w(ll,e,u),i(e,_i,u),w(rl,e,u),i(e,vi,u),i(e,Wl,u),s(Wl,ad),i(e,bi,u),$l[dn].m(e,u),i(e,Ql,u),i(e,Jl,u),s(Jl,ld),i(e,$i,u),i(e,In,u),s(In,oa),s(oa,so),w(ol,so,null),s(In,rd),s(In,to),s(to,od),i(e,gi,u),i(e,An,u),s(An,id),s(An,no),s(no,ud),s(An,pd),s(An,ao),s(ao,dd),s(An,cd),i(e,qi,u),w(il,e,u),i(e,ji,u),i(e,Yl,u),s(Yl,md),i(e,ki,u),i(e,ia,u),s(ia,fd),s(ia,lo),s(lo,hd),s(ia,_d),i(e,Ei,u),w(ul,e,u),i(e,xi,u),gl[mn].m(e,u),i(e,Zl,u),rs&&rs.m(e,u),i(e,er,u),i(e,Bn,u),s(Bn,ua),s(ua,ro),w(pl,ro,null),s(Bn,vd),s(Bn,oo),s(oo,bd),i(e,wi,u),i(e,ct,u),s(ct,$d),s(ct,io),s(io,gd),s(ct,qd),s(ct,uo),s(uo,jd),s(ct,kd),s(ct,po),s(po,Ed),s(ct,xd),s(ct,co),s(co,wd),s(ct,zd),i(e,zi,u),w(dl,e,u),i(e,yi,u),w(cl,e,u),i(e,Pi,u),i(e,sr,u),s(sr,yd),i(e,Ci,u),w(ml,e,u),i(e,Di,u),w(fl,e,u),i(e,Si,u),i(e,tr,u),s(tr,Pd),i(e,Ti,u),w(pa,e,u),Ai=!0},p(e,[u]){const ql={};u&1&&(ql.fw=e[0]),h.$set(ql);let nr=D;D=Dd(e),D!==nr&&(El(),$(hl[nr],1,1,()=>{hl[nr]=null}),kl(),M=hl[D],M||(M=hl[D]=Cd[D](e),M.c()),b(M,1),M.m(F.parentNode,F));const mo={};u&2&&(mo.$$scope={dirty:u,ctx:e}),tn.$set(mo);const fo={};u&2&&(fo.$$scope={dirty:u,ctx:e}),Yn.$set(fo);const Rn={};u&2&&(Rn.$$scope={dirty:u,ctx:e}),sa.$set(Rn);const ho={};u&2&&(ho.$$scope={dirty:u,ctx:e}),ta.$set(ho);let ar=an;an=Td(e),an!==ar&&(El(),$(_l[ar],1,1,()=>{_l[ar]=null}),kl(),ln=_l[an],ln||(ln=_l[an]=Sd[an](e),ln.c()),b(ln,1),ln.m(Ol.parentNode,Ol));let da=rn;rn=Nd(e),rn!==da&&(El(),$(vl[da],1,1,()=>{vl[da]=null}),kl(),on=vl[rn],on||(on=vl[rn]=Ad[rn](e),on.c()),b(on,1),on.m(Fl.parentNode,Fl));let Nn=un;un=Od(e),un!==Nn&&(El(),$(bl[Nn],1,1,()=>{bl[Nn]=null}),kl(),pn=bl[un],pn||(pn=bl[un]=Ld[un](e),pn.c()),b(pn,1),pn.m(Rl.parentNode,Rl)),e[0]==="pt"?Js||(Js=Wm(),Js.c(),Js.m(Kl.parentNode,Kl)):Js&&(Js.d(1),Js=null);let lr=dn;dn=Ud(e),dn!==lr&&(El(),$($l[lr],1,1,()=>{$l[lr]=null}),kl(),cn=$l[dn],cn||(cn=$l[dn]=Md[dn](e),cn.c()),b(cn,1),cn.m(Ql.parentNode,Ql));let rr=mn;mn=Hd(e),mn!==rr&&(El(),$(gl[rr],1,1,()=>{gl[rr]=null}),kl(),fn=gl[mn],fn||(fn=gl[mn]=Fd[mn](e),fn.c()),b(fn,1),fn.m(Zl.parentNode,Zl)),e[0]==="pt"?rs?u&1&&b(rs,1):(rs=Qm(),rs.c(),b(rs,1),rs.m(er.parentNode,er)):rs&&(El(),$(rs,1,1,()=>{rs=null}),kl());const jl={};u&2&&(jl.$$scope={dirty:u,ctx:e}),pa.$set(jl)},i(e){Ai||(b(h.$$.fragment,e),b(S.$$.fragment,e),b(M),b(ge.$$.fragment,e),b(qs.$$.fragment,e),b(ks.$$.fragment,e),b(ms.$$.fragment,e),b(rt.$$.fragment,e),b(Te.$$.fragment,e),b(fs.$$.fragment,e),b(Ve.$$.fragment,e),b(hs.$$.fragment,e),b(m.$$.fragment,e),b(Et.$$.fragment,e),b(Gs.$$.fragment,e),b(Xs.$$.fragment,e),b(Ms.$$.fragment,e),b(jn.$$.fragment,e),b(kn.$$.fragment,e),b(En.$$.fragment,e),b(wn.$$.fragment,e),b(tn.$$.fragment,e),b(ut.$$.fragment,e),b(zn.$$.fragment,e),b(ya.$$.fragment,e),b(Yn.$$.fragment,e),b(Ca.$$.fragment,e),b(Da.$$.fragment,e),b(Sa.$$.fragment,e),b(Ta.$$.fragment,e),b(Aa.$$.fragment,e),b(sa.$$.fragment,e),b(ta.$$.fragment,e),b(Na.$$.fragment,e),b(ln),b(La.$$.fragment,e),b(on),b(Ma.$$.fragment,e),b(Ua.$$.fragment,e),b(Fa.$$.fragment,e),b(Ha.$$.fragment,e),b(Ia.$$.fragment,e),b(Ba.$$.fragment,e),b(Ra.$$.fragment,e),b(Ka.$$.fragment,e),b(pn),b(Va.$$.fragment,e),b(Ga.$$.fragment,e),b(Ja.$$.fragment,e),b(Ya.$$.fragment,e),b(Za.$$.fragment,e),b(el.$$.fragment,e),b(nl.$$.fragment,e),b(al.$$.fragment,e),b(ll.$$.fragment,e),b(rl.$$.fragment,e),b(cn),b(ol.$$.fragment,e),b(il.$$.fragment,e),b(ul.$$.fragment,e),b(fn),b(rs),b(pl.$$.fragment,e),b(dl.$$.fragment,e),b(cl.$$.fragment,e),b(ml.$$.fragment,e),b(fl.$$.fragment,e),b(pa.$$.fragment,e),Ai=!0)},o(e){$(h.$$.fragment,e),$(S.$$.fragment,e),$(M),$(ge.$$.fragment,e),$(qs.$$.fragment,e),$(ks.$$.fragment,e),$(ms.$$.fragment,e),$(rt.$$.fragment,e),$(Te.$$.fragment,e),$(fs.$$.fragment,e),$(Ve.$$.fragment,e),$(hs.$$.fragment,e),$(m.$$.fragment,e),$(Et.$$.fragment,e),$(Gs.$$.fragment,e),$(Xs.$$.fragment,e),$(Ms.$$.fragment,e),$(jn.$$.fragment,e),$(kn.$$.fragment,e),$(En.$$.fragment,e),$(wn.$$.fragment,e),$(tn.$$.fragment,e),$(ut.$$.fragment,e),$(zn.$$.fragment,e),$(ya.$$.fragment,e),$(Yn.$$.fragment,e),$(Ca.$$.fragment,e),$(Da.$$.fragment,e),$(Sa.$$.fragment,e),$(Ta.$$.fragment,e),$(Aa.$$.fragment,e),$(sa.$$.fragment,e),$(ta.$$.fragment,e),$(Na.$$.fragment,e),$(ln),$(La.$$.fragment,e),$(on),$(Ma.$$.fragment,e),$(Ua.$$.fragment,e),$(Fa.$$.fragment,e),$(Ha.$$.fragment,e),$(Ia.$$.fragment,e),$(Ba.$$.fragment,e),$(Ra.$$.fragment,e),$(Ka.$$.fragment,e),$(pn),$(Va.$$.fragment,e),$(Ga.$$.fragment,e),$(Ja.$$.fragment,e),$(Ya.$$.fragment,e),$(Za.$$.fragment,e),$(el.$$.fragment,e),$(nl.$$.fragment,e),$(al.$$.fragment,e),$(ll.$$.fragment,e),$(rl.$$.fragment,e),$(cn),$(ol.$$.fragment,e),$(il.$$.fragment,e),$(ul.$$.fragment,e),$(fn),$(rs),$(pl.$$.fragment,e),$(dl.$$.fragment,e),$(cl.$$.fragment,e),$(ml.$$.fragment,e),$(fl.$$.fragment,e),$(pa.$$.fragment,e),Ai=!1},d(e){t(p),e&&t(g),z(h,e),e&&t(y),e&&t(T),z(S),e&&t(k),hl[D].d(e),e&&t(F),e&&t(U),e&&t(W),e&&t(te),e&&t(ee),z(ge,e),e&&t(ue),e&&t(ne),e&&t(Pe),e&&t(pe),e&&t(us),e&&t(Re),e&&t(ve),e&&t($e),e&&t(ke),e&&t(ze),e&&t(ts),e&&t(Ee),e&&t(Is),e&&t(We),e&&t(Bs),e&&t(ps),z(qs),e&&t(ht),e&&t(De),e&&t(tt),e&&t(ds),z(ks),e&&t($t),e&&t(as),e&&t(xs),z(ms,e),e&&t(at),e&&t(Ts),e&&t(Ke),e&&t(Ls),e&&t(gt),e&&t(f),e&&t(Jt),z(rt,e),e&&t(At),z(Te,e),e&&t(ws),e&&t(He),e&&t(Ot),z(fs,e),e&&t(Mt),z(Ve,e),e&&t(jt),e&&t(Ks),e&&t(Zt),z(hs,e),e&&t(kt),e&&t(Vs),e&&t(Ft),z(m,e),e&&t(N),z(Et,e),e&&t(bn),e&&t(Ht),e&&t($n),z(Gs,e),e&&t(It),z(Xs,e),e&&t(gn),e&&t(en),e&&t(ba),z(Ms,e),e&&t($a),z(jn,e),e&&t(ga),e&&t(Ws),e&&t(qa),z(kn,e),e&&t(Qs),z(En,e),e&&t(ja),e&&t(wt),e&&t(ka),z(wn,e),e&&t(sn),z(tn,e),e&&t(Ea),e&&t(Us),z(ut),e&&t(xa),z(zn,e),e&&t(wa),e&&t(Ge),e&&t(vo),z(ya,e),e&&t(bo),e&&t(Rt),e&&t($o),z(Yn,e),e&&t(go),e&&t(yn),e&&t(qo),e&&t(Zn),e&&t(jo),z(Ca,e),e&&t(ko),e&&t(Pn),e&&t(Eo),e&&t(Cn),e&&t(xo),e&&t(Al),e&&t(wo),z(Da,e),e&&t(zo),e&&t(ea),e&&t(yo),z(Sa,e),e&&t(Po),z(Ta,e),e&&t(Co),e&&t(Kt),e&&t(Do),e&&t(Vt),e&&t(So),z(Aa,e),e&&t(To),e&&t(Nl),e&&t(Ao),z(sa,e),e&&t(No),z(ta,e),e&&t(Lo),e&&t(Ll),e&&t(Oo),z(Na,e),e&&t(Mo),e&&t(na),e&&t(Uo),_l[an].d(e),e&&t(Ol),e&&t(Ml),e&&t(Fo),e&&t(Fn),z(La),e&&t(Ho),e&&t(pt),e&&t(Io),e&&t(_s),e&&t(Bo),vl[rn].d(e),e&&t(Fl),e&&t(Hl),e&&t(Ro),z(Ma,e),e&&t(Ko),z(Ua,e),e&&t(Vo),e&&t(la),e&&t(Go),z(Fa,e),e&&t(Xo),z(Ha,e),e&&t(Wo),e&&t(Il),e&&t(Qo),z(Ia,e),e&&t(Jo),z(Ba,e),e&&t(Yo),e&&t(Bl),e&&t(Zo),z(Ra,e),e&&t(ei),z(Ka,e),e&&t(si),bl[un].d(e),e&&t(Rl),e&&t(Hn),z(Va),e&&t(ti),z(Ga,e),e&&t(ni),Js&&Js.d(e),e&&t(Kl),e&&t(Dn),e&&t(ai),e&&t(Sn),e&&t(li),z(Ja,e),e&&t(ri),e&&t(Tn),e&&t(oi),z(Ya,e),e&&t(ii),e&&t(Gl),e&&t(ui),e&&t(Xl),e&&t(pi),z(Za,e),e&&t(di),z(el,e),e&&t(ci),e&&t(dt),e&&t(mi),z(nl,e),e&&t(fi),z(al,e),e&&t(hi),z(ll,e),e&&t(_i),z(rl,e),e&&t(vi),e&&t(Wl),e&&t(bi),$l[dn].d(e),e&&t(Ql),e&&t(Jl),e&&t($i),e&&t(In),z(ol),e&&t(gi),e&&t(An),e&&t(qi),z(il,e),e&&t(ji),e&&t(Yl),e&&t(ki),e&&t(ia),e&&t(Ei),z(ul,e),e&&t(xi),gl[mn].d(e),e&&t(Zl),rs&&rs.d(e),e&&t(er),e&&t(Bn),z(pl),e&&t(wi),e&&t(ct),e&&t(zi),z(dl,e),e&&t(yi),z(cl,e),e&&t(Pi),e&&t(sr),e&&t(Ci),z(ml,e),e&&t(Di),z(fl,e),e&&t(Si),e&&t(tr),e&&t(Ti),z(pa,e)}}}const wf={local:"traduction",sections:[{local:"prparation-des-donnes",sections:[{local:"le-jeu-de-donnes-kde4",title:"Le jeu de donn\xE9es KDE4"},{local:"traitement-des-donnes",title:"Traitement des donn\xE9es"}],title:"Pr\xE9paration des donn\xE9es"},{local:"finetuner-le-modle-avec-lapi-trainer",title:"*Finetuner* le mod\xE8le avec l'API `Trainer`."},{local:"finetuning-du-modle-avec-keras",sections:[{local:"collecte-des-donnes",title:"Collecte des donn\xE9es"},{local:"mtriques",title:"M\xE9triques"},{local:"finetuner-le-modle",title:"*Finetuner* le mod\xE8le"}],title:"*Finetuning* du mod\xE8le avec Keras"},{local:"une-boucle-dentranement-personnalise",sections:[{local:"prparer-le-tout-pour-lentranement",title:"Pr\xE9parer le tout pour l'entra\xEEnement"},{local:"boucle-dentranement",title:"Boucle d'entra\xEEnement"},{local:"utilisation-du-modle-finetun",title:"Utilisation du mod\xE8le *finetun\xE9*."}],title:"Une boucle d'entra\xEEnement personnalis\xE9e"}],title:"Traduction"};function zf(Y,p,g){let h="pt";return tf(()=>{const y=new URLSearchParams(window.location.search);g(0,h=y.get("fw")||"pt")}),[h]}class Nf extends Ym{constructor(p){super();Zm(this,p,zf,xf,ef,{})}}export{Nf as default,wf as metadata};
