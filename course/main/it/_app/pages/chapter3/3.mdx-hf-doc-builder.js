import{S as es,i as ts,s as as,e as r,k as c,w as h,t as o,M as os,c as l,d as a,m as p,x as _,a as s,h as i,b as v,G as t,g as d,y as g,q as z,o as $,B as E,v as is}from"../../chunks/vendor-hf-doc-builder.js";import{T as Zl}from"../../chunks/Tip-hf-doc-builder.js";import{Y as rs}from"../../chunks/Youtube-hf-doc-builder.js";import{I as xr}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as I}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as ls}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as ss}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function ns(he){let u,j,m,A,T,b,P,y,B,ee,_e;return{c(){u=r("p"),j=o("\u{1F4A1} Se si vuole caricare automaticamente il modello all\u2019Hub durante l\u2019addestramento, basta passare "),m=r("code"),A=o("push_to_hub=True"),T=o(" come parametro nei "),b=r("code"),P=o("TrainingArguments"),y=o(". Maggiori dettagli verranno forniti nel "),B=r("a"),ee=o("Capitolo 4"),_e=o("."),this.h()},l(W){u=l(W,"P",{});var k=s(u);j=i(k,"\u{1F4A1} Se si vuole caricare automaticamente il modello all\u2019Hub durante l\u2019addestramento, basta passare "),m=l(k,"CODE",{});var ge=s(m);A=i(ge,"push_to_hub=True"),ge.forEach(a),T=i(k," come parametro nei "),b=l(k,"CODE",{});var H=s(b);P=i(H,"TrainingArguments"),H.forEach(a),y=i(k,". Maggiori dettagli verranno forniti nel "),B=l(k,"A",{href:!0});var ze=s(B);ee=i(ze,"Capitolo 4"),ze.forEach(a),_e=i(k,"."),k.forEach(a),this.h()},h(){v(B,"href","/course/chapter4/3")},m(W,k){d(W,u,k),t(u,j),t(u,m),t(m,A),t(u,T),t(u,b),t(b,P),t(u,y),t(u,B),t(B,ee),t(u,_e)},d(W){W&&a(u)}}}function ds(he){let u,j,m,A,T;return{c(){u=r("p"),j=o("\u270F\uFE0F "),m=r("strong"),A=o("Prova tu!"),T=o(" Affinare un modello sul dataset GLUE SST-2 utilizzando il processing dei dati gi\xE0 fatto nella sezione 2.")},l(b){u=l(b,"P",{});var P=s(u);j=i(P,"\u270F\uFE0F "),m=l(P,"STRONG",{});var y=s(m);A=i(y,"Prova tu!"),y.forEach(a),T=i(P," Affinare un modello sul dataset GLUE SST-2 utilizzando il processing dei dati gi\xE0 fatto nella sezione 2."),P.forEach(a)},m(b,P){d(b,u,P),t(u,j),t(u,m),t(m,A),t(u,T)},d(b){b&&a(u)}}}function cs(he){let u,j,m,A,T,b,P,y,B,ee,_e,W,k,ge,H,ze,S,Ha,Ye,Va,Ya,Je,Ja,Xa,Xe,Ka,Za,$e,eo,to,oa,Ue,ao,ia,Ee,ra,te,ie,Ke,be,oo,Ze,io,la,L,ro,et,lo,so,tt,no,co,at,po,uo,sa,ke,na,re,da,V,mo,Ge,fo,vo,ot,ho,_o,ca,Ce,pa,le,go,Me,zo,$o,ua,q,Eo,it,bo,ko,rt,Co,To,lt,Po,qo,st,wo,Do,nt,Oo,jo,ma,Te,fa,w,Ao,dt,yo,So,ct,xo,Io,pt,Lo,Uo,ut,Go,Mo,mt,Fo,No,va,Y,Qo,ft,Ro,Bo,vt,Wo,Ho,ha,Pe,_a,Fe,Vo,ga,se,O,Yo,ht,Jo,Xo,_t,Ko,Zo,gt,ei,ti,zt,ai,oi,$t,ii,ri,li,ae,si,Et,ni,di,bt,ci,pi,za,oe,ne,kt,qe,ui,Ct,mi,$a,D,fi,Tt,vi,hi,Pt,_i,gi,qt,zi,$i,wt,Ei,bi,Dt,ki,Ci,Ea,we,ba,De,ka,f,Ti,Ot,Pi,qi,jt,wi,Di,At,Oi,ji,yt,Ai,yi,St,Si,xi,xt,Ii,Li,It,Ui,Gi,Lt,Mi,Fi,Ca,U,Ni,Ut,Qi,Ri,Gt,Bi,Wi,Ne,Hi,Vi,Ta,Oe,Pa,x,Yi,Mt,Ji,Xi,Ft,Ki,Zi,Nt,er,tr,Qt,ar,or,qa,je,wa,Ae,Da,G,ir,ye,rr,lr,Rt,sr,nr,Bt,dr,cr,Oa,de,pr,Wt,ur,mr,ja,Se,Aa,J,fr,Ht,vr,hr,Vt,_r,gr,ya,xe,Sa,M,zr,Yt,$r,Er,Jt,br,kr,Xt,Cr,Tr,xa,Ie,Ia,Qe,Pr,La,X,qr,Kt,wr,Dr,Zt,Or,jr,Ua,ce,Ar,ea,yr,Sr,Ga,pe,Ma;return m=new ss({props:{fw:he[0]}}),y=new xr({}),k=new ls({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter3/section3.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter3/section3.ipynb"}]}}),H=new rs({props:{id:"nvBXf7s7vTI"}}),Ee=new I({props:{code:`from datasets import load_dataset
from transformers import AutoTokenizer, DataCollatorWithPadding

raw_datasets = load_dataset("glue", "mrpc")
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)


def tokenize_function(example):
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)


tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, DataCollatorWithPadding

raw_datasets = load_dataset(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mrpc&quot;</span>)
checkpoint = <span class="hljs-string">&quot;bert-base-uncased&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(checkpoint)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">example</span>):
    <span class="hljs-keyword">return</span> tokenizer(example[<span class="hljs-string">&quot;sentence1&quot;</span>], example[<span class="hljs-string">&quot;sentence2&quot;</span>], truncation=<span class="hljs-literal">True</span>)


tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)`}}),be=new xr({}),ke=new I({props:{code:`from transformers import TrainingArguments

training_args = TrainingArguments("test-trainer")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

training_args = TrainingArguments(<span class="hljs-string">&quot;test-trainer&quot;</span>)`}}),re=new Zl({props:{$$slots:{default:[ns]},$$scope:{ctx:he}}}),Ce=new I({props:{code:`from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="hljs-number">2</span>)`}}),Te=new I({props:{code:`from transformers import Trainer

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],
    eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>],
    data_collator=data_collator,
    tokenizer=tokenizer,
)`}}),Pe=new I({props:{code:"trainer.train()",highlighted:"trainer.train()"}}),qe=new xr({}),we=new I({props:{code:`predictions = trainer.predict(tokenized_datasets["validation"])
print(predictions.predictions.shape, predictions.label_ids.shape)`,highlighted:`predictions = trainer.predict(tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>])
<span class="hljs-built_in">print</span>(predictions.predictions.shape, predictions.label_ids.shape)`}}),De=new I({props:{code:"(408, 2) (408,)",highlighted:'(<span class="hljs-number">408</span>, <span class="hljs-number">2</span>) (<span class="hljs-number">408</span>,)'}}),Oe=new I({props:{code:`import numpy as np

preds = np.argmax(predictions.predictions, axis=-1)`,highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

preds = np.argmax(predictions.predictions, axis=-<span class="hljs-number">1</span>)`}}),je=new I({props:{code:`from datasets import load_metric

metric = load_metric("glue", "mrpc")
metric.compute(predictions=preds, references=predictions.label_ids)`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_metric

metric = load_metric(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mrpc&quot;</span>)
metric.compute(predictions=preds, references=predictions.label_ids)`}}),Ae=new I({props:{code:"{'accuracy': 0.8578431372549019, 'f1': 0.8996539792387542}",highlighted:'{<span class="hljs-string">&#x27;accuracy&#x27;</span>: <span class="hljs-number">0.8578431372549019</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">0.8996539792387542</span>}'}}),Se=new I({props:{code:`def compute_metrics(eval_preds):
    metric = load_metric("glue", "mrpc")
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_preds</span>):
    metric = load_metric(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mrpc&quot;</span>)
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-<span class="hljs-number">1</span>)
    <span class="hljs-keyword">return</span> metric.compute(predictions=predictions, references=labels)`}}),xe=new I({props:{code:`training_args = TrainingArguments("test-trainer", evaluation_strategy="epoch")
model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)`,highlighted:`training_args = TrainingArguments(<span class="hljs-string">&quot;test-trainer&quot;</span>, evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="hljs-number">2</span>)

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],
    eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)`}}),Ie=new I({props:{code:"trainer.train()",highlighted:'trainer.trai<span class="hljs-meta">n</span>()'}}),pe=new Zl({props:{$$slots:{default:[ds]},$$scope:{ctx:he}}}),{c(){u=r("meta"),j=c(),h(m.$$.fragment),A=c(),T=r("h1"),b=r("a"),P=r("span"),h(y.$$.fragment),B=c(),ee=r("span"),_e=o("Affinare il modello con la Trainer API"),W=c(),h(k.$$.fragment),ge=c(),h(H.$$.fragment),ze=c(),S=r("p"),Ha=o("\u{1F917} Transformers fornisce una classe "),Ye=r("code"),Va=o("Trainer"),Ya=o(" (addestratore) per aiutare con l\u2019affinamento di uno qualsiasi dei modelli pre-addestrati nel dataset. Dopo tutto il lavoro di preprocessing nella sezione precedente, rimangono giusto gli ultimi passi per definire il "),Je=r("code"),Ja=o("Trainer"),Xa=o(". Probabilmente la parte pi\xF9 complicata sar\xE0 preparare l\u2019ambiente per eseguire "),Xe=r("code"),Ka=o("Trainer.train()"),Za=o(", poich\xE9 sar\xE0 molto lento su una CPU. Se non avete una GPU a disposizione, potete avere accesso gratuitamente a GPU o TPU su "),$e=r("a"),eo=o("Google Colab"),to=o("."),oa=c(),Ue=r("p"),ao=o("Gli esempi di codice qui sotto partono dal presupposto che gli esempi nella sezione precedente siano gi\xE0 stati eseguiti. Ecco un breve riassunto di cosa serve:"),ia=c(),h(Ee.$$.fragment),ra=c(),te=r("h3"),ie=r("a"),Ke=r("span"),h(be.$$.fragment),oo=c(),Ze=r("span"),io=o("Addestramento"),la=c(),L=r("p"),ro=o("Il primo passo per definire un "),et=r("code"),lo=o("Trainer"),so=o(" \xE8 la definizione di una classe "),tt=r("code"),no=o("TrainingArguments"),co=o(" che contenga tutti gli iperparametri che verranno usati dal "),at=r("code"),po=o("Trainer"),uo=o(" per l\u2019addestramento e la valutazione. L\u2019unico parametro da fornire \xE8 la cartella dove verranno salvati il modello addestrato e i vari checkpoint. Per tutto il resto si possono lasciare i parametri di default, che dovrebbero funzionare bene per un affinamento di base."),sa=c(),h(ke.$$.fragment),na=c(),h(re.$$.fragment),da=c(),V=r("p"),mo=o("Il secondo passo \xE8 definire il modello. Come nel "),Ge=r("a"),fo=o("capitolo precedente"),vo=o(", utilizzeremo la classe "),ot=r("code"),ho=o("AutoModelForSequenceClassification"),_o=o(" con due label:"),ca=c(),h(Ce.$$.fragment),pa=c(),le=r("p"),go=o("Diversamente dal "),Me=r("a"),zo=o("Capitolo 2"),$o=o(", un avviso di avvertimento verr\xE0 visualizzato dopo aver istanziato questo modello pre-addestrato. Ci\xF2 avviene perch\xE9 BERT non \xE8 stato pre-addestrato per classificare coppie di frasi, quindi la testa del modello pre-addestrato viene scartata e una nuova testa adeguata per il compito di classificazione di sequenze \xE8 stata inserita. Gli avvertimenti indicano che alcuni pesi non verranno usati (quelli corrispondenti alla testa scartata del modello pre-addestrato) e che altri pesi sono stati inizializzati con valori casuali (quelli per la nuova testa). L\u2019avvertimento viene concluso con un\u2019esortazione ad addestrare il modello, che \xE8 esattamente ci\xF2 che stiamo per fare."),ua=c(),q=r("p"),Eo=o("Una volta ottenuto il modello, si pu\xF2 definire un "),it=r("code"),bo=o("Trainer"),ko=o(" passandogli tutti gli oggetti costruiti fino ad adesso \u2014 il "),rt=r("code"),Co=o("model"),To=o(", i "),lt=r("code"),Po=o("training_args"),qo=o(", i dataset di addestramento e validazione, il "),st=r("code"),wo=o("data_collator"),Do=o(", e il "),nt=r("code"),Oo=o("tokenizer"),jo=o(":"),ma=c(),h(Te.$$.fragment),fa=c(),w=r("p"),Ao=o("Quando si passa l\u2019argomento "),dt=r("code"),yo=o("tokenizer"),So=o(" come appena fatto, il "),ct=r("code"),xo=o("data_collator"),Io=o(" usato di default dal "),pt=r("code"),Lo=o("Trainer"),Uo=o(" sar\xE0 del tipo "),ut=r("code"),Go=o("DataCollatorWithPadding"),Mo=o(", come definito precedentemente, quindi si potrebbe evitare di specificare l\u2019argomento "),mt=r("code"),Fo=o("data_collator=data_collator"),No=o(" in questa chiamata. Tuttavia era comunque importante mostrare questa parte del processing nella sezione 2!"),va=c(),Y=r("p"),Qo=o("Per affinare il modello sul nostro dataset, bisogna solo chiamare il metodo "),ft=r("code"),Ro=o("train()"),Bo=o(" del "),vt=r("code"),Wo=o("Trainer"),Ho=o(":"),ha=c(),h(Pe.$$.fragment),_a=c(),Fe=r("p"),Vo=o("Questo far\xE0 partire l\u2019affinamento (che richieder\xE0 un paio di minuti su una GPU) e produrr\xE0 un report della funzione obiettivo dell\u2019addestramento ogni 500 passi. Tuttavia, non vi far\xE0 sapere quanto sia buona (o cattiva) la performance del modello. Ci\xF2 \xE8 dovuto al fatto che:"),ga=c(),se=r("ol"),O=r("li"),Yo=o("Non \xE8 stato detto al "),ht=r("code"),Jo=o("Trainer"),Xo=o(" di valutare il modello durante l\u2019addestramento, settando "),_t=r("code"),Ko=o("evaluation_strategy"),Zo=o(" o al valore "),gt=r("code"),ei=o('"steps"'),ti=o(" (valuta il modello ogni "),zt=r("code"),ai=o("eval_steps"),oi=o(") oppure al valore "),$t=r("code"),ii=o('"epoch"'),ri=o(" (valuta il modello alla fine di ogni epoca)."),li=c(),ae=r("li"),si=o("Non \xE8 stato fornito al "),Et=r("code"),ni=o("Trainer"),di=o(" una funzione "),bt=r("code"),ci=o("compute_metrics()"),pi=o(" per calcolare le metriche di valutazione (altrimenti la valutazione stamperebbe solo il valore della funzione obiettivo, che non \xE8 un valore molto intuitivo)."),za=c(),oe=r("h3"),ne=r("a"),kt=r("span"),h(qe.$$.fragment),ui=c(),Ct=r("span"),mi=o("Valutazione"),$a=c(),D=r("p"),fi=o("Vediamo come si pu\xF2 costruire una funzione "),Tt=r("code"),vi=o("compute_metrics()"),hi=o(" utile e usarla per il prossimo addestramento. La funzione deve prendere come parametro un oggetto "),Pt=r("code"),_i=o("EvalPrediction"),gi=o(" (che \xE8 una named tuple avente un campo "),qt=r("code"),zi=o("predictions"),$i=o(" \u2013 predizioni \u2013 e un campo "),wt=r("code"),Ei=o("label_ids"),bi=o(" \u2013 id delle etichette \u2013) e restituir\xE0 un dizionario che associa stringhe a numeri floating point (le stringhe saranno i nomi delle metriche, i numeri i loro valori). Per ottenere delle predizioni, si pu\xF2 usare il comando "),Dt=r("code"),ki=o("Trainer.predict()"),Ci=o(":"),Ea=c(),h(we.$$.fragment),ba=c(),h(De.$$.fragment),ka=c(),f=r("p"),Ti=o("Il risultato del metodo "),Ot=r("code"),Pi=o("predict()"),qi=o(" \xE8 un\u2019altra named tuple con tre campi: "),jt=r("code"),wi=o("predictions"),Di=o(", "),At=r("code"),Oi=o("label_ids"),ji=o(", e "),yt=r("code"),Ai=o("metrics"),yi=o(". Il campo "),St=r("code"),Si=o("metrics"),xi=o(" conterr\xE0 solo il valore della funzione obiettivo sul dataset, in aggiunta ad alcune metriche legate al tempo (il tempo necessario per calcolare le predizioni, in totale e in media). Una volta completata la funzione "),xt=r("code"),Ii=o("compute_metrics()"),Li=o(" e passata al "),It=r("code"),Ui=o("Trainer"),Gi=o(", quel campo conterr\xE0 anche le metriche restituite da "),Lt=r("code"),Mi=o("compute_metrics()"),Fi=o("."),Ca=c(),U=r("p"),Ni=o("Come si pu\xF2 vedere, "),Ut=r("code"),Qi=o("predictions"),Ri=o(" \xE8 un array bi-dimensionale con dimensioni 408 x 2 (poich\xE9 408 \xE8 il numero di elementi nel dataset). Questi sono i logit per ogni elemento del dataset passato a "),Gt=r("code"),Bi=o("predict()"),Wi=o(" (come gi\xE0 visto nel "),Ne=r("a"),Hi=o("capitolo precedente"),Vi=o(", tutti i modelli Transformer restituiscono logit). Per trasformarli in predizioni associabili alle etichette, bisogna prendere l\u2019indice col valore massimo sul secondo asse:"),Ta=c(),h(Oe.$$.fragment),Pa=c(),x=r("p"),Yi=o("Ora si possono paragonare i "),Mt=r("code"),Ji=o("preds"),Xi=o(" con le etichette. Per costruire la funzione "),Ft=r("code"),Ki=o("compute_metric()"),Zi=o(", verranno utilizzate le metriche dalla libreria \u{1F917} Dataset. Si possono caricare le metriche associate con il dataset MRPC in maniera semplice, utilizzando la funzione "),Nt=r("code"),er=o("load_metric()"),tr=o(". L\u2019oggetto restituito ha un metodo "),Qt=r("code"),ar=o("compute()"),or=o(" (calcola) che possiamo usare per calcolare le metriche:"),qa=c(),h(je.$$.fragment),wa=c(),h(Ae.$$.fragment),Da=c(),G=r("p"),ir=o("L\u2019esatto valore dei risultati potrebbe essere diverso nel vostro caso, a casa dell\u2019inizializzazione casuale della testa del modello. In questo caso il nostro modello ha un\u2019accuratezza del 85.78% sul set di validazione e un valore F1 di 89.97. Queste sono le due metriche utilizzate per valutare i risultati sul dataset MRPC per il benchmark GLUE. La tabella nell\u2019"),ye=r("a"),rr=o("articolo su BERT"),lr=o(" riportava un F1 di 88.9 per il modello base. Quello era il modello "),Rt=r("code"),sr=o("uncased"),nr=o(" (senza distinzione fra minuscole e maiuscole) mentre noi stiamo usando quello "),Bt=r("code"),dr=o("cased"),cr=o(", il che spiega il risultato migliore."),Oa=c(),de=r("p"),pr=o("Mettendo tutto insieme si ottiene la funzione "),Wt=r("code"),ur=o("compute_metrics()"),mr=o(":"),ja=c(),h(Se.$$.fragment),Aa=c(),J=r("p"),fr=o("Per vederla in azione e fare il report delle metriche alla fine di ogni epoca, ecco come si definisce un nuovo "),Ht=r("code"),vr=o("Trainer"),hr=o(" che includa questa funzione "),Vt=r("code"),_r=o("compute_metrics()"),gr=o(":"),ya=c(),h(xe.$$.fragment),Sa=c(),M=r("p"),zr=o("Da notare che bisogna creare un nuovo oggetto "),Yt=r("code"),$r=o("TrainingArguments"),Er=o(" con il valore di "),Jt=r("code"),br=o("evaluation_strategy"),kr=o(" pari a "),Xt=r("code"),Cr=o('"epoch"'),Tr=o(" e un nuovo modello \u2014 altrimenti si continuerebbe l\u2019addestramento del modello gi\xE0 addestrato. Per lanciare una nuova esecuzione dell\u2019addestramento si usa:"),xa=c(),h(Ie.$$.fragment),Ia=c(),Qe=r("p"),Pr=o("Stavolta vi sar\xE0 il report della funzione obiettivo di validazione alla fine di ogni epoca, in aggiunta alla funzione obiettivo dell\u2019addestramento. Di nuovo, i valori esatti di accuratezza/F1 ottenuti da voi potrebbero variare leggermente da quelli mostrati qui a causa dell\u2019inizializzazione casuale della testa del modello, ma dovrebbero essere comparabili."),La=c(),X=r("p"),qr=o("Il "),Kt=r("code"),wr=o("Trainer"),Dr=o(" funzioner\xE0 direttamente su svariate GPU e TPU e ha molte opzioni, tra cui addestramento in precisione mista (utilizzare "),Zt=r("code"),Or=o("fp16 = True"),jr=o(" negli argomenti). I dettagli delle opzioni verranno esplorati nel Capitolo 10."),Ua=c(),ce=r("p"),Ar=o("Qui si conclude l\u2019introduzione all\u2019affinamento usando l\u2019API del "),ea=r("code"),yr=o("Trainer"),Sr=o(". Esempi per i compiti pi\xF9 comuni in NLP verranno forniti nel Capitolo 7, ma per ora vediamo come ottenere la stessa cosa usando puramente Pytorch."),Ga=c(),h(pe.$$.fragment),this.h()},l(e){const n=os('[data-svelte="svelte-1phssyn"]',document.head);u=l(n,"META",{name:!0,content:!0}),n.forEach(a),j=p(e),_(m.$$.fragment,e),A=p(e),T=l(e,"H1",{class:!0});var Le=s(T);b=l(Le,"A",{id:!0,class:!0,href:!0});var ta=s(b);P=l(ta,"SPAN",{});var aa=s(P);_(y.$$.fragment,aa),aa.forEach(a),ta.forEach(a),B=p(Le),ee=l(Le,"SPAN",{});var Ir=s(ee);_e=i(Ir,"Affinare il modello con la Trainer API"),Ir.forEach(a),Le.forEach(a),W=p(e),_(k.$$.fragment,e),ge=p(e),_(H.$$.fragment,e),ze=p(e),S=l(e,"P",{});var K=s(S);Ha=i(K,"\u{1F917} Transformers fornisce una classe "),Ye=l(K,"CODE",{});var Lr=s(Ye);Va=i(Lr,"Trainer"),Lr.forEach(a),Ya=i(K," (addestratore) per aiutare con l\u2019affinamento di uno qualsiasi dei modelli pre-addestrati nel dataset. Dopo tutto il lavoro di preprocessing nella sezione precedente, rimangono giusto gli ultimi passi per definire il "),Je=l(K,"CODE",{});var Ur=s(Je);Ja=i(Ur,"Trainer"),Ur.forEach(a),Xa=i(K,". Probabilmente la parte pi\xF9 complicata sar\xE0 preparare l\u2019ambiente per eseguire "),Xe=l(K,"CODE",{});var Gr=s(Xe);Ka=i(Gr,"Trainer.train()"),Gr.forEach(a),Za=i(K,", poich\xE9 sar\xE0 molto lento su una CPU. Se non avete una GPU a disposizione, potete avere accesso gratuitamente a GPU o TPU su "),$e=l(K,"A",{href:!0,rel:!0});var Mr=s($e);eo=i(Mr,"Google Colab"),Mr.forEach(a),to=i(K,"."),K.forEach(a),oa=p(e),Ue=l(e,"P",{});var Fr=s(Ue);ao=i(Fr,"Gli esempi di codice qui sotto partono dal presupposto che gli esempi nella sezione precedente siano gi\xE0 stati eseguiti. Ecco un breve riassunto di cosa serve:"),Fr.forEach(a),ia=p(e),_(Ee.$$.fragment,e),ra=p(e),te=l(e,"H3",{class:!0});var Fa=s(te);ie=l(Fa,"A",{id:!0,class:!0,href:!0});var Nr=s(ie);Ke=l(Nr,"SPAN",{});var Qr=s(Ke);_(be.$$.fragment,Qr),Qr.forEach(a),Nr.forEach(a),oo=p(Fa),Ze=l(Fa,"SPAN",{});var Rr=s(Ze);io=i(Rr,"Addestramento"),Rr.forEach(a),Fa.forEach(a),la=p(e),L=l(e,"P",{});var ue=s(L);ro=i(ue,"Il primo passo per definire un "),et=l(ue,"CODE",{});var Br=s(et);lo=i(Br,"Trainer"),Br.forEach(a),so=i(ue," \xE8 la definizione di una classe "),tt=l(ue,"CODE",{});var Wr=s(tt);no=i(Wr,"TrainingArguments"),Wr.forEach(a),co=i(ue," che contenga tutti gli iperparametri che verranno usati dal "),at=l(ue,"CODE",{});var Hr=s(at);po=i(Hr,"Trainer"),Hr.forEach(a),uo=i(ue," per l\u2019addestramento e la valutazione. L\u2019unico parametro da fornire \xE8 la cartella dove verranno salvati il modello addestrato e i vari checkpoint. Per tutto il resto si possono lasciare i parametri di default, che dovrebbero funzionare bene per un affinamento di base."),ue.forEach(a),sa=p(e),_(ke.$$.fragment,e),na=p(e),_(re.$$.fragment,e),da=p(e),V=l(e,"P",{});var Re=s(V);mo=i(Re,"Il secondo passo \xE8 definire il modello. Come nel "),Ge=l(Re,"A",{href:!0});var Vr=s(Ge);fo=i(Vr,"capitolo precedente"),Vr.forEach(a),vo=i(Re,", utilizzeremo la classe "),ot=l(Re,"CODE",{});var Yr=s(ot);ho=i(Yr,"AutoModelForSequenceClassification"),Yr.forEach(a),_o=i(Re," con due label:"),Re.forEach(a),ca=p(e),_(Ce.$$.fragment,e),pa=p(e),le=l(e,"P",{});var Na=s(le);go=i(Na,"Diversamente dal "),Me=l(Na,"A",{href:!0});var Jr=s(Me);zo=i(Jr,"Capitolo 2"),Jr.forEach(a),$o=i(Na,", un avviso di avvertimento verr\xE0 visualizzato dopo aver istanziato questo modello pre-addestrato. Ci\xF2 avviene perch\xE9 BERT non \xE8 stato pre-addestrato per classificare coppie di frasi, quindi la testa del modello pre-addestrato viene scartata e una nuova testa adeguata per il compito di classificazione di sequenze \xE8 stata inserita. Gli avvertimenti indicano che alcuni pesi non verranno usati (quelli corrispondenti alla testa scartata del modello pre-addestrato) e che altri pesi sono stati inizializzati con valori casuali (quelli per la nuova testa). L\u2019avvertimento viene concluso con un\u2019esortazione ad addestrare il modello, che \xE8 esattamente ci\xF2 che stiamo per fare."),Na.forEach(a),ua=p(e),q=l(e,"P",{});var F=s(q);Eo=i(F,"Una volta ottenuto il modello, si pu\xF2 definire un "),it=l(F,"CODE",{});var Xr=s(it);bo=i(Xr,"Trainer"),Xr.forEach(a),ko=i(F," passandogli tutti gli oggetti costruiti fino ad adesso \u2014 il "),rt=l(F,"CODE",{});var Kr=s(rt);Co=i(Kr,"model"),Kr.forEach(a),To=i(F,", i "),lt=l(F,"CODE",{});var Zr=s(lt);Po=i(Zr,"training_args"),Zr.forEach(a),qo=i(F,", i dataset di addestramento e validazione, il "),st=l(F,"CODE",{});var el=s(st);wo=i(el,"data_collator"),el.forEach(a),Do=i(F,", e il "),nt=l(F,"CODE",{});var tl=s(nt);Oo=i(tl,"tokenizer"),tl.forEach(a),jo=i(F,":"),F.forEach(a),ma=p(e),_(Te.$$.fragment,e),fa=p(e),w=l(e,"P",{});var N=s(w);Ao=i(N,"Quando si passa l\u2019argomento "),dt=l(N,"CODE",{});var al=s(dt);yo=i(al,"tokenizer"),al.forEach(a),So=i(N," come appena fatto, il "),ct=l(N,"CODE",{});var ol=s(ct);xo=i(ol,"data_collator"),ol.forEach(a),Io=i(N," usato di default dal "),pt=l(N,"CODE",{});var il=s(pt);Lo=i(il,"Trainer"),il.forEach(a),Uo=i(N," sar\xE0 del tipo "),ut=l(N,"CODE",{});var rl=s(ut);Go=i(rl,"DataCollatorWithPadding"),rl.forEach(a),Mo=i(N,", come definito precedentemente, quindi si potrebbe evitare di specificare l\u2019argomento "),mt=l(N,"CODE",{});var ll=s(mt);Fo=i(ll,"data_collator=data_collator"),ll.forEach(a),No=i(N," in questa chiamata. Tuttavia era comunque importante mostrare questa parte del processing nella sezione 2!"),N.forEach(a),va=p(e),Y=l(e,"P",{});var Be=s(Y);Qo=i(Be,"Per affinare il modello sul nostro dataset, bisogna solo chiamare il metodo "),ft=l(Be,"CODE",{});var sl=s(ft);Ro=i(sl,"train()"),sl.forEach(a),Bo=i(Be," del "),vt=l(Be,"CODE",{});var nl=s(vt);Wo=i(nl,"Trainer"),nl.forEach(a),Ho=i(Be,":"),Be.forEach(a),ha=p(e),_(Pe.$$.fragment,e),_a=p(e),Fe=l(e,"P",{});var dl=s(Fe);Vo=i(dl,"Questo far\xE0 partire l\u2019affinamento (che richieder\xE0 un paio di minuti su una GPU) e produrr\xE0 un report della funzione obiettivo dell\u2019addestramento ogni 500 passi. Tuttavia, non vi far\xE0 sapere quanto sia buona (o cattiva) la performance del modello. Ci\xF2 \xE8 dovuto al fatto che:"),dl.forEach(a),ga=p(e),se=l(e,"OL",{});var Qa=s(se);O=l(Qa,"LI",{});var Q=s(O);Yo=i(Q,"Non \xE8 stato detto al "),ht=l(Q,"CODE",{});var cl=s(ht);Jo=i(cl,"Trainer"),cl.forEach(a),Xo=i(Q," di valutare il modello durante l\u2019addestramento, settando "),_t=l(Q,"CODE",{});var pl=s(_t);Ko=i(pl,"evaluation_strategy"),pl.forEach(a),Zo=i(Q," o al valore "),gt=l(Q,"CODE",{});var ul=s(gt);ei=i(ul,'"steps"'),ul.forEach(a),ti=i(Q," (valuta il modello ogni "),zt=l(Q,"CODE",{});var ml=s(zt);ai=i(ml,"eval_steps"),ml.forEach(a),oi=i(Q,") oppure al valore "),$t=l(Q,"CODE",{});var fl=s($t);ii=i(fl,'"epoch"'),fl.forEach(a),ri=i(Q," (valuta il modello alla fine di ogni epoca)."),Q.forEach(a),li=p(Qa),ae=l(Qa,"LI",{});var We=s(ae);si=i(We,"Non \xE8 stato fornito al "),Et=l(We,"CODE",{});var vl=s(Et);ni=i(vl,"Trainer"),vl.forEach(a),di=i(We," una funzione "),bt=l(We,"CODE",{});var hl=s(bt);ci=i(hl,"compute_metrics()"),hl.forEach(a),pi=i(We," per calcolare le metriche di valutazione (altrimenti la valutazione stamperebbe solo il valore della funzione obiettivo, che non \xE8 un valore molto intuitivo)."),We.forEach(a),Qa.forEach(a),za=p(e),oe=l(e,"H3",{class:!0});var Ra=s(oe);ne=l(Ra,"A",{id:!0,class:!0,href:!0});var _l=s(ne);kt=l(_l,"SPAN",{});var gl=s(kt);_(qe.$$.fragment,gl),gl.forEach(a),_l.forEach(a),ui=p(Ra),Ct=l(Ra,"SPAN",{});var zl=s(Ct);mi=i(zl,"Valutazione"),zl.forEach(a),Ra.forEach(a),$a=p(e),D=l(e,"P",{});var R=s(D);fi=i(R,"Vediamo come si pu\xF2 costruire una funzione "),Tt=l(R,"CODE",{});var $l=s(Tt);vi=i($l,"compute_metrics()"),$l.forEach(a),hi=i(R," utile e usarla per il prossimo addestramento. La funzione deve prendere come parametro un oggetto "),Pt=l(R,"CODE",{});var El=s(Pt);_i=i(El,"EvalPrediction"),El.forEach(a),gi=i(R," (che \xE8 una named tuple avente un campo "),qt=l(R,"CODE",{});var bl=s(qt);zi=i(bl,"predictions"),bl.forEach(a),$i=i(R," \u2013 predizioni \u2013 e un campo "),wt=l(R,"CODE",{});var kl=s(wt);Ei=i(kl,"label_ids"),kl.forEach(a),bi=i(R," \u2013 id delle etichette \u2013) e restituir\xE0 un dizionario che associa stringhe a numeri floating point (le stringhe saranno i nomi delle metriche, i numeri i loro valori). Per ottenere delle predizioni, si pu\xF2 usare il comando "),Dt=l(R,"CODE",{});var Cl=s(Dt);ki=i(Cl,"Trainer.predict()"),Cl.forEach(a),Ci=i(R,":"),R.forEach(a),Ea=p(e),_(we.$$.fragment,e),ba=p(e),_(De.$$.fragment,e),ka=p(e),f=l(e,"P",{});var C=s(f);Ti=i(C,"Il risultato del metodo "),Ot=l(C,"CODE",{});var Tl=s(Ot);Pi=i(Tl,"predict()"),Tl.forEach(a),qi=i(C," \xE8 un\u2019altra named tuple con tre campi: "),jt=l(C,"CODE",{});var Pl=s(jt);wi=i(Pl,"predictions"),Pl.forEach(a),Di=i(C,", "),At=l(C,"CODE",{});var ql=s(At);Oi=i(ql,"label_ids"),ql.forEach(a),ji=i(C,", e "),yt=l(C,"CODE",{});var wl=s(yt);Ai=i(wl,"metrics"),wl.forEach(a),yi=i(C,". Il campo "),St=l(C,"CODE",{});var Dl=s(St);Si=i(Dl,"metrics"),Dl.forEach(a),xi=i(C," conterr\xE0 solo il valore della funzione obiettivo sul dataset, in aggiunta ad alcune metriche legate al tempo (il tempo necessario per calcolare le predizioni, in totale e in media). Una volta completata la funzione "),xt=l(C,"CODE",{});var Ol=s(xt);Ii=i(Ol,"compute_metrics()"),Ol.forEach(a),Li=i(C," e passata al "),It=l(C,"CODE",{});var jl=s(It);Ui=i(jl,"Trainer"),jl.forEach(a),Gi=i(C,", quel campo conterr\xE0 anche le metriche restituite da "),Lt=l(C,"CODE",{});var Al=s(Lt);Mi=i(Al,"compute_metrics()"),Al.forEach(a),Fi=i(C,"."),C.forEach(a),Ca=p(e),U=l(e,"P",{});var me=s(U);Ni=i(me,"Come si pu\xF2 vedere, "),Ut=l(me,"CODE",{});var yl=s(Ut);Qi=i(yl,"predictions"),yl.forEach(a),Ri=i(me," \xE8 un array bi-dimensionale con dimensioni 408 x 2 (poich\xE9 408 \xE8 il numero di elementi nel dataset). Questi sono i logit per ogni elemento del dataset passato a "),Gt=l(me,"CODE",{});var Sl=s(Gt);Bi=i(Sl,"predict()"),Sl.forEach(a),Wi=i(me," (come gi\xE0 visto nel "),Ne=l(me,"A",{href:!0});var xl=s(Ne);Hi=i(xl,"capitolo precedente"),xl.forEach(a),Vi=i(me,", tutti i modelli Transformer restituiscono logit). Per trasformarli in predizioni associabili alle etichette, bisogna prendere l\u2019indice col valore massimo sul secondo asse:"),me.forEach(a),Ta=p(e),_(Oe.$$.fragment,e),Pa=p(e),x=l(e,"P",{});var Z=s(x);Yi=i(Z,"Ora si possono paragonare i "),Mt=l(Z,"CODE",{});var Il=s(Mt);Ji=i(Il,"preds"),Il.forEach(a),Xi=i(Z," con le etichette. Per costruire la funzione "),Ft=l(Z,"CODE",{});var Ll=s(Ft);Ki=i(Ll,"compute_metric()"),Ll.forEach(a),Zi=i(Z,", verranno utilizzate le metriche dalla libreria \u{1F917} Dataset. Si possono caricare le metriche associate con il dataset MRPC in maniera semplice, utilizzando la funzione "),Nt=l(Z,"CODE",{});var Ul=s(Nt);er=i(Ul,"load_metric()"),Ul.forEach(a),tr=i(Z,". L\u2019oggetto restituito ha un metodo "),Qt=l(Z,"CODE",{});var Gl=s(Qt);ar=i(Gl,"compute()"),Gl.forEach(a),or=i(Z," (calcola) che possiamo usare per calcolare le metriche:"),Z.forEach(a),qa=p(e),_(je.$$.fragment,e),wa=p(e),_(Ae.$$.fragment,e),Da=p(e),G=l(e,"P",{});var fe=s(G);ir=i(fe,"L\u2019esatto valore dei risultati potrebbe essere diverso nel vostro caso, a casa dell\u2019inizializzazione casuale della testa del modello. In questo caso il nostro modello ha un\u2019accuratezza del 85.78% sul set di validazione e un valore F1 di 89.97. Queste sono le due metriche utilizzate per valutare i risultati sul dataset MRPC per il benchmark GLUE. La tabella nell\u2019"),ye=l(fe,"A",{href:!0,rel:!0});var Ml=s(ye);rr=i(Ml,"articolo su BERT"),Ml.forEach(a),lr=i(fe," riportava un F1 di 88.9 per il modello base. Quello era il modello "),Rt=l(fe,"CODE",{});var Fl=s(Rt);sr=i(Fl,"uncased"),Fl.forEach(a),nr=i(fe," (senza distinzione fra minuscole e maiuscole) mentre noi stiamo usando quello "),Bt=l(fe,"CODE",{});var Nl=s(Bt);dr=i(Nl,"cased"),Nl.forEach(a),cr=i(fe,", il che spiega il risultato migliore."),fe.forEach(a),Oa=p(e),de=l(e,"P",{});var Ba=s(de);pr=i(Ba,"Mettendo tutto insieme si ottiene la funzione "),Wt=l(Ba,"CODE",{});var Ql=s(Wt);ur=i(Ql,"compute_metrics()"),Ql.forEach(a),mr=i(Ba,":"),Ba.forEach(a),ja=p(e),_(Se.$$.fragment,e),Aa=p(e),J=l(e,"P",{});var He=s(J);fr=i(He,"Per vederla in azione e fare il report delle metriche alla fine di ogni epoca, ecco come si definisce un nuovo "),Ht=l(He,"CODE",{});var Rl=s(Ht);vr=i(Rl,"Trainer"),Rl.forEach(a),hr=i(He," che includa questa funzione "),Vt=l(He,"CODE",{});var Bl=s(Vt);_r=i(Bl,"compute_metrics()"),Bl.forEach(a),gr=i(He,":"),He.forEach(a),ya=p(e),_(xe.$$.fragment,e),Sa=p(e),M=l(e,"P",{});var ve=s(M);zr=i(ve,"Da notare che bisogna creare un nuovo oggetto "),Yt=l(ve,"CODE",{});var Wl=s(Yt);$r=i(Wl,"TrainingArguments"),Wl.forEach(a),Er=i(ve," con il valore di "),Jt=l(ve,"CODE",{});var Hl=s(Jt);br=i(Hl,"evaluation_strategy"),Hl.forEach(a),kr=i(ve," pari a "),Xt=l(ve,"CODE",{});var Vl=s(Xt);Cr=i(Vl,'"epoch"'),Vl.forEach(a),Tr=i(ve," e un nuovo modello \u2014 altrimenti si continuerebbe l\u2019addestramento del modello gi\xE0 addestrato. Per lanciare una nuova esecuzione dell\u2019addestramento si usa:"),ve.forEach(a),xa=p(e),_(Ie.$$.fragment,e),Ia=p(e),Qe=l(e,"P",{});var Yl=s(Qe);Pr=i(Yl,"Stavolta vi sar\xE0 il report della funzione obiettivo di validazione alla fine di ogni epoca, in aggiunta alla funzione obiettivo dell\u2019addestramento. Di nuovo, i valori esatti di accuratezza/F1 ottenuti da voi potrebbero variare leggermente da quelli mostrati qui a causa dell\u2019inizializzazione casuale della testa del modello, ma dovrebbero essere comparabili."),Yl.forEach(a),La=p(e),X=l(e,"P",{});var Ve=s(X);qr=i(Ve,"Il "),Kt=l(Ve,"CODE",{});var Jl=s(Kt);wr=i(Jl,"Trainer"),Jl.forEach(a),Dr=i(Ve," funzioner\xE0 direttamente su svariate GPU e TPU e ha molte opzioni, tra cui addestramento in precisione mista (utilizzare "),Zt=l(Ve,"CODE",{});var Xl=s(Zt);Or=i(Xl,"fp16 = True"),Xl.forEach(a),jr=i(Ve," negli argomenti). I dettagli delle opzioni verranno esplorati nel Capitolo 10."),Ve.forEach(a),Ua=p(e),ce=l(e,"P",{});var Wa=s(ce);Ar=i(Wa,"Qui si conclude l\u2019introduzione all\u2019affinamento usando l\u2019API del "),ea=l(Wa,"CODE",{});var Kl=s(ea);yr=i(Kl,"Trainer"),Kl.forEach(a),Sr=i(Wa,". Esempi per i compiti pi\xF9 comuni in NLP verranno forniti nel Capitolo 7, ma per ora vediamo come ottenere la stessa cosa usando puramente Pytorch."),Wa.forEach(a),Ga=p(e),_(pe.$$.fragment,e),this.h()},h(){v(u,"name","hf:doc:metadata"),v(u,"content",JSON.stringify(ps)),v(b,"id","affinare-il-modello-con-la-trainer-api"),v(b,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),v(b,"href","#affinare-il-modello-con-la-trainer-api"),v(T,"class","relative group"),v($e,"href","https://colab.research.google.com/"),v($e,"rel","nofollow"),v(ie,"id","addestramento"),v(ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),v(ie,"href","#addestramento"),v(te,"class","relative group"),v(Ge,"href","/course/chapter2"),v(Me,"href","/course/chapter2"),v(ne,"id","valutazione"),v(ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),v(ne,"href","#valutazione"),v(oe,"class","relative group"),v(Ne,"href","/course/chapter2"),v(ye,"href","https://arxiv.org/pdf/1810.04805.pdf"),v(ye,"rel","nofollow")},m(e,n){t(document.head,u),d(e,j,n),g(m,e,n),d(e,A,n),d(e,T,n),t(T,b),t(b,P),g(y,P,null),t(T,B),t(T,ee),t(ee,_e),d(e,W,n),g(k,e,n),d(e,ge,n),g(H,e,n),d(e,ze,n),d(e,S,n),t(S,Ha),t(S,Ye),t(Ye,Va),t(S,Ya),t(S,Je),t(Je,Ja),t(S,Xa),t(S,Xe),t(Xe,Ka),t(S,Za),t(S,$e),t($e,eo),t(S,to),d(e,oa,n),d(e,Ue,n),t(Ue,ao),d(e,ia,n),g(Ee,e,n),d(e,ra,n),d(e,te,n),t(te,ie),t(ie,Ke),g(be,Ke,null),t(te,oo),t(te,Ze),t(Ze,io),d(e,la,n),d(e,L,n),t(L,ro),t(L,et),t(et,lo),t(L,so),t(L,tt),t(tt,no),t(L,co),t(L,at),t(at,po),t(L,uo),d(e,sa,n),g(ke,e,n),d(e,na,n),g(re,e,n),d(e,da,n),d(e,V,n),t(V,mo),t(V,Ge),t(Ge,fo),t(V,vo),t(V,ot),t(ot,ho),t(V,_o),d(e,ca,n),g(Ce,e,n),d(e,pa,n),d(e,le,n),t(le,go),t(le,Me),t(Me,zo),t(le,$o),d(e,ua,n),d(e,q,n),t(q,Eo),t(q,it),t(it,bo),t(q,ko),t(q,rt),t(rt,Co),t(q,To),t(q,lt),t(lt,Po),t(q,qo),t(q,st),t(st,wo),t(q,Do),t(q,nt),t(nt,Oo),t(q,jo),d(e,ma,n),g(Te,e,n),d(e,fa,n),d(e,w,n),t(w,Ao),t(w,dt),t(dt,yo),t(w,So),t(w,ct),t(ct,xo),t(w,Io),t(w,pt),t(pt,Lo),t(w,Uo),t(w,ut),t(ut,Go),t(w,Mo),t(w,mt),t(mt,Fo),t(w,No),d(e,va,n),d(e,Y,n),t(Y,Qo),t(Y,ft),t(ft,Ro),t(Y,Bo),t(Y,vt),t(vt,Wo),t(Y,Ho),d(e,ha,n),g(Pe,e,n),d(e,_a,n),d(e,Fe,n),t(Fe,Vo),d(e,ga,n),d(e,se,n),t(se,O),t(O,Yo),t(O,ht),t(ht,Jo),t(O,Xo),t(O,_t),t(_t,Ko),t(O,Zo),t(O,gt),t(gt,ei),t(O,ti),t(O,zt),t(zt,ai),t(O,oi),t(O,$t),t($t,ii),t(O,ri),t(se,li),t(se,ae),t(ae,si),t(ae,Et),t(Et,ni),t(ae,di),t(ae,bt),t(bt,ci),t(ae,pi),d(e,za,n),d(e,oe,n),t(oe,ne),t(ne,kt),g(qe,kt,null),t(oe,ui),t(oe,Ct),t(Ct,mi),d(e,$a,n),d(e,D,n),t(D,fi),t(D,Tt),t(Tt,vi),t(D,hi),t(D,Pt),t(Pt,_i),t(D,gi),t(D,qt),t(qt,zi),t(D,$i),t(D,wt),t(wt,Ei),t(D,bi),t(D,Dt),t(Dt,ki),t(D,Ci),d(e,Ea,n),g(we,e,n),d(e,ba,n),g(De,e,n),d(e,ka,n),d(e,f,n),t(f,Ti),t(f,Ot),t(Ot,Pi),t(f,qi),t(f,jt),t(jt,wi),t(f,Di),t(f,At),t(At,Oi),t(f,ji),t(f,yt),t(yt,Ai),t(f,yi),t(f,St),t(St,Si),t(f,xi),t(f,xt),t(xt,Ii),t(f,Li),t(f,It),t(It,Ui),t(f,Gi),t(f,Lt),t(Lt,Mi),t(f,Fi),d(e,Ca,n),d(e,U,n),t(U,Ni),t(U,Ut),t(Ut,Qi),t(U,Ri),t(U,Gt),t(Gt,Bi),t(U,Wi),t(U,Ne),t(Ne,Hi),t(U,Vi),d(e,Ta,n),g(Oe,e,n),d(e,Pa,n),d(e,x,n),t(x,Yi),t(x,Mt),t(Mt,Ji),t(x,Xi),t(x,Ft),t(Ft,Ki),t(x,Zi),t(x,Nt),t(Nt,er),t(x,tr),t(x,Qt),t(Qt,ar),t(x,or),d(e,qa,n),g(je,e,n),d(e,wa,n),g(Ae,e,n),d(e,Da,n),d(e,G,n),t(G,ir),t(G,ye),t(ye,rr),t(G,lr),t(G,Rt),t(Rt,sr),t(G,nr),t(G,Bt),t(Bt,dr),t(G,cr),d(e,Oa,n),d(e,de,n),t(de,pr),t(de,Wt),t(Wt,ur),t(de,mr),d(e,ja,n),g(Se,e,n),d(e,Aa,n),d(e,J,n),t(J,fr),t(J,Ht),t(Ht,vr),t(J,hr),t(J,Vt),t(Vt,_r),t(J,gr),d(e,ya,n),g(xe,e,n),d(e,Sa,n),d(e,M,n),t(M,zr),t(M,Yt),t(Yt,$r),t(M,Er),t(M,Jt),t(Jt,br),t(M,kr),t(M,Xt),t(Xt,Cr),t(M,Tr),d(e,xa,n),g(Ie,e,n),d(e,Ia,n),d(e,Qe,n),t(Qe,Pr),d(e,La,n),d(e,X,n),t(X,qr),t(X,Kt),t(Kt,wr),t(X,Dr),t(X,Zt),t(Zt,Or),t(X,jr),d(e,Ua,n),d(e,ce,n),t(ce,Ar),t(ce,ea),t(ea,yr),t(ce,Sr),d(e,Ga,n),g(pe,e,n),Ma=!0},p(e,[n]){const Le={};n&1&&(Le.fw=e[0]),m.$set(Le);const ta={};n&2&&(ta.$$scope={dirty:n,ctx:e}),re.$set(ta);const aa={};n&2&&(aa.$$scope={dirty:n,ctx:e}),pe.$set(aa)},i(e){Ma||(z(m.$$.fragment,e),z(y.$$.fragment,e),z(k.$$.fragment,e),z(H.$$.fragment,e),z(Ee.$$.fragment,e),z(be.$$.fragment,e),z(ke.$$.fragment,e),z(re.$$.fragment,e),z(Ce.$$.fragment,e),z(Te.$$.fragment,e),z(Pe.$$.fragment,e),z(qe.$$.fragment,e),z(we.$$.fragment,e),z(De.$$.fragment,e),z(Oe.$$.fragment,e),z(je.$$.fragment,e),z(Ae.$$.fragment,e),z(Se.$$.fragment,e),z(xe.$$.fragment,e),z(Ie.$$.fragment,e),z(pe.$$.fragment,e),Ma=!0)},o(e){$(m.$$.fragment,e),$(y.$$.fragment,e),$(k.$$.fragment,e),$(H.$$.fragment,e),$(Ee.$$.fragment,e),$(be.$$.fragment,e),$(ke.$$.fragment,e),$(re.$$.fragment,e),$(Ce.$$.fragment,e),$(Te.$$.fragment,e),$(Pe.$$.fragment,e),$(qe.$$.fragment,e),$(we.$$.fragment,e),$(De.$$.fragment,e),$(Oe.$$.fragment,e),$(je.$$.fragment,e),$(Ae.$$.fragment,e),$(Se.$$.fragment,e),$(xe.$$.fragment,e),$(Ie.$$.fragment,e),$(pe.$$.fragment,e),Ma=!1},d(e){a(u),e&&a(j),E(m,e),e&&a(A),e&&a(T),E(y),e&&a(W),E(k,e),e&&a(ge),E(H,e),e&&a(ze),e&&a(S),e&&a(oa),e&&a(Ue),e&&a(ia),E(Ee,e),e&&a(ra),e&&a(te),E(be),e&&a(la),e&&a(L),e&&a(sa),E(ke,e),e&&a(na),E(re,e),e&&a(da),e&&a(V),e&&a(ca),E(Ce,e),e&&a(pa),e&&a(le),e&&a(ua),e&&a(q),e&&a(ma),E(Te,e),e&&a(fa),e&&a(w),e&&a(va),e&&a(Y),e&&a(ha),E(Pe,e),e&&a(_a),e&&a(Fe),e&&a(ga),e&&a(se),e&&a(za),e&&a(oe),E(qe),e&&a($a),e&&a(D),e&&a(Ea),E(we,e),e&&a(ba),E(De,e),e&&a(ka),e&&a(f),e&&a(Ca),e&&a(U),e&&a(Ta),E(Oe,e),e&&a(Pa),e&&a(x),e&&a(qa),E(je,e),e&&a(wa),E(Ae,e),e&&a(Da),e&&a(G),e&&a(Oa),e&&a(de),e&&a(ja),E(Se,e),e&&a(Aa),e&&a(J),e&&a(ya),E(xe,e),e&&a(Sa),e&&a(M),e&&a(xa),E(Ie,e),e&&a(Ia),e&&a(Qe),e&&a(La),e&&a(X),e&&a(Ua),e&&a(ce),e&&a(Ga),E(pe,e)}}}const ps={local:"affinare-il-modello-con-la-trainer-api",sections:[{local:"addestramento",title:"Addestramento"},{local:"valutazione",title:"Valutazione"}],title:"Affinare il modello con la Trainer API"};function us(he,u,j){let m="pt";return is(()=>{const A=new URLSearchParams(window.location.search);j(0,m=A.get("fw")||"pt")}),[m]}class $s extends es{constructor(u){super();ts(this,u,us,cs,as,{})}}export{$s as default,ps as metadata};
