import{S as ye,i as ze,s as Le,e as o,k as d,w as Ce,t as i,M as Ne,c as r,d as a,m,a as s,x as Pe,h as l,b as C,G as t,g as v,y as De,L as Se,q as we,o as ke,B as qe,v as xe}from"../../chunks/vendor-hf-doc-builder.js";import{I as Fe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as He}from"../../chunks/CourseFloatingBanner-hf-doc-builder.js";import"../../chunks/DocNotebookDropdown-hf-doc-builder.js";function Ie(ce){let f,F,p,_,k,b,G,q,J,H,E,I,P,R,A,n,y,j,K,h,Q,z,V,W,L,X,Y,Z,$,ee,N,te,ae,oe,S,re,ie,x,se,T,g,le,D,ne,ue,B;return b=new Fe({}),E=new He({props:{chapter:5,classNames:"absolute z-10 right-0 top-0"}}),{c(){f=o("meta"),F=d(),p=o("h1"),_=o("a"),k=o("span"),Ce(b.$$.fragment),G=d(),q=o("span"),J=i("\u{1F917} Datasets, check!"),H=d(),Ce(E.$$.fragment),I=d(),P=o("p"),R=i("Beh, abbiamo fatto un bel giro nella libreria \u{1F917} Datasets: complimenti per aver raggiunto quest\u2019obiettivo! Con le conoscenze che hai ottenuto da questo capitolo, sei in grado di:"),A=d(),n=o("ul"),y=o("li"),j=i("Caricare dataset da ogni luogo, sia esso l\u2019Hub di Hugging Face, il tuo portatile, o un server in remoto della tua compagnia."),K=d(),h=o("li"),Q=i("Fare data-wrangling usando un mix delle funzioni "),z=o("code"),V=i("Dataset.map()"),W=i(" e "),L=o("code"),X=i("Dataset.filter()"),Y=i("."),Z=d(),$=o("li"),ee=i("Passare velocemente tra diversi formati di dati domce Pandas e NumPy usando "),N=o("code"),te=i("Dataset.set_format()"),ae=i("."),oe=d(),S=o("li"),re=i("Creare il tuo dataset e condividerlo sull\u2019Hub Hugging Face."),ie=d(),x=o("li"),se=i("Creare embedding dei tuoi documenti usando un modello Transformer, e costruire un motore di ricerca semantico usando FAISS."),T=d(),g=o("p"),le=i("Nel "),D=o("a"),ne=i("Capitolo 7"),ue=i(", faremo buon uso di tutto questo mentre ci avventureremo nei task principali NLP, per i quali i modelli Transformer sono un\u2019ottima soluzione. Prima di andare oltre, per\xF2, metti alla prova la tua conoscenza di \u{1F917} Datasets con un quiz!"),this.h()},l(e){const u=Ne('[data-svelte="svelte-1phssyn"]',document.head);f=r(u,"META",{name:!0,content:!0}),u.forEach(a),F=m(e),p=r(e,"H1",{class:!0});var O=s(p);_=r(O,"A",{id:!0,class:!0,href:!0});var de=s(_);k=r(de,"SPAN",{});var me=s(k);Pe(b.$$.fragment,me),me.forEach(a),de.forEach(a),G=m(O),q=r(O,"SPAN",{});var fe=s(q);J=l(fe,"\u{1F917} Datasets, check!"),fe.forEach(a),O.forEach(a),H=m(e),Pe(E.$$.fragment,e),I=m(e),P=r(e,"P",{});var pe=s(P);R=l(pe,"Beh, abbiamo fatto un bel giro nella libreria \u{1F917} Datasets: complimenti per aver raggiunto quest\u2019obiettivo! Con le conoscenze che hai ottenuto da questo capitolo, sei in grado di:"),pe.forEach(a),A=m(e),n=r(e,"UL",{});var c=s(n);y=r(c,"LI",{});var he=s(y);j=l(he,"Caricare dataset da ogni luogo, sia esso l\u2019Hub di Hugging Face, il tuo portatile, o un server in remoto della tua compagnia."),he.forEach(a),K=m(c),h=r(c,"LI",{});var w=s(h);Q=l(w,"Fare data-wrangling usando un mix delle funzioni "),z=r(w,"CODE",{});var ve=s(z);V=l(ve,"Dataset.map()"),ve.forEach(a),W=l(w," e "),L=r(w,"CODE",{});var _e=s(L);X=l(_e,"Dataset.filter()"),_e.forEach(a),Y=l(w,"."),w.forEach(a),Z=m(c),$=r(c,"LI",{});var M=s($);ee=l(M,"Passare velocemente tra diversi formati di dati domce Pandas e NumPy usando "),N=r(M,"CODE",{});var ge=s(N);te=l(ge,"Dataset.set_format()"),ge.forEach(a),ae=l(M,"."),M.forEach(a),oe=m(c),S=r(c,"LI",{});var be=s(S);re=l(be,"Creare il tuo dataset e condividerlo sull\u2019Hub Hugging Face."),be.forEach(a),ie=m(c),x=r(c,"LI",{});var Ee=s(x);se=l(Ee,"Creare embedding dei tuoi documenti usando un modello Transformer, e costruire un motore di ricerca semantico usando FAISS."),Ee.forEach(a),c.forEach(a),T=m(e),g=r(e,"P",{});var U=s(g);le=l(U,"Nel "),D=r(U,"A",{href:!0});var $e=s(D);ne=l($e,"Capitolo 7"),$e.forEach(a),ue=l(U,", faremo buon uso di tutto questo mentre ci avventureremo nei task principali NLP, per i quali i modelli Transformer sono un\u2019ottima soluzione. Prima di andare oltre, per\xF2, metti alla prova la tua conoscenza di \u{1F917} Datasets con un quiz!"),U.forEach(a),this.h()},h(){C(f,"name","hf:doc:metadata"),C(f,"content",JSON.stringify(Ae)),C(_,"id","datasets-check"),C(_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),C(_,"href","#datasets-check"),C(p,"class","relative group"),C(D,"href","/course/chapter7")},m(e,u){t(document.head,f),v(e,F,u),v(e,p,u),t(p,_),t(_,k),De(b,k,null),t(p,G),t(p,q),t(q,J),v(e,H,u),De(E,e,u),v(e,I,u),v(e,P,u),t(P,R),v(e,A,u),v(e,n,u),t(n,y),t(y,j),t(n,K),t(n,h),t(h,Q),t(h,z),t(z,V),t(h,W),t(h,L),t(L,X),t(h,Y),t(n,Z),t(n,$),t($,ee),t($,N),t(N,te),t($,ae),t(n,oe),t(n,S),t(S,re),t(n,ie),t(n,x),t(x,se),v(e,T,u),v(e,g,u),t(g,le),t(g,D),t(D,ne),t(g,ue),B=!0},p:Se,i(e){B||(we(b.$$.fragment,e),we(E.$$.fragment,e),B=!0)},o(e){ke(b.$$.fragment,e),ke(E.$$.fragment,e),B=!1},d(e){a(f),e&&a(F),e&&a(p),qe(b),e&&a(H),qe(E,e),e&&a(I),e&&a(P),e&&a(A),e&&a(n),e&&a(T),e&&a(g)}}}const Ae={local:"datasets-check",title:"\u{1F917} Datasets, check!"};function Te(ce){return xe(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ge extends ye{constructor(f){super();ze(this,f,Te,Ie,Le,{})}}export{Ge as default,Ae as metadata};
