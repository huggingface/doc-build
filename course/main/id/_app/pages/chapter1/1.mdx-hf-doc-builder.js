import{S as Ul,i as Yl,s as Jl,e as i,c as l,a as s,d as n,b as o,T as Pn,g as m,L as ki,k as d,w as Fe,t,R as Wl,m as g,x as Be,h as r,G as e,y as Ie,q as Ge,o as Re,B as Ce,v as Vl}from"../../chunks/vendor-hf-doc-builder.js";import{I as wn}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as Ql}from"../../chunks/CourseFloatingBanner-hf-doc-builder.js";function Xl(ee){let p,A;return{c(){p=i("iframe"),this.h()},l(h){p=l(h,"IFRAME",{class:!0,src:!0,title:!0,frameborder:!0,allow:!0}),s(p).forEach(n),this.h()},h(){o(p,"class","w-full xl:w-4/6 h-80"),Pn(p.src,A="https://www.youtube-nocookie.com/embed/"+ee[0])||o(p,"src",A),o(p,"title","YouTube video player"),o(p,"frameborder","0"),o(p,"allow","accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"),p.allowFullscreen=!0},m(h,b){m(h,p,b)},p(h,[b]){b&1&&!Pn(p.src,A="https://www.youtube-nocookie.com/embed/"+h[0])&&o(p,"src",A)},i:ki,o:ki,d(h){h&&n(p)}}}function Zl(ee,p,A){let{id:h}=p;return ee.$$set=b=>{"id"in b&&A(0,h=b.id)},[h]}class es extends Ul{constructor(p){super();Yl(this,p,Zl,Xl,Jl,{id:0})}}function as(ee){let p,A,h,b,xe,ae,Ln,Oe,Sn,Ua,ne,Ya,R,Y,ze,te,Tn,Ke,An,Ja,re,Wa,k,Mn,qe,$n,Nn,ie,jn,Hn,le,Dn,Fn,se,Bn,In,oe,Gn,Rn,ue,Cn,xn,me,On,zn,Va,C,J,Ue,de,Kn,Ye,qn,Qa,Me,Un,Xa,x,ge,fi,Yn,pe,ci,Za,S,M,Jn,Je,Wn,Vn,he,Qn,Xn,We,Zn,et,at,Ve,nt,tt,Qe,rt,it,w,lt,Xe,st,ot,Ze,ut,mt,ea,dt,gt,aa,pt,ht,en,$e,kt,an,T,na,ft,ct,ta,bt,vt,B,Et,ke,_t,yt,fe,wt,Pt,ce,Lt,St,O,Tt,be,At,Mt,ve,$t,Nt,nn,W,jt,Ee,Ht,Dt,tn,z,V,ra,_e,Ft,ia,Bt,rn,v,la,It,Gt,ye,Rt,Ct,sa,xt,Ot,oa,zt,Kt,ua,qt,Ut,ln,$,ma,Yt,Jt,da,Wt,Vt,ga,Qt,Xt,sn,K,pa,Zt,er,ha,ar,nr,on,f,ka,tr,rr,fa,ir,lr,ca,sr,or,ba,ur,mr,va,we,dr,gr,Ea,pr,hr,un,E,_a,kr,fr,ya,cr,br,wa,vr,Er,Pa,_r,yr,La,wr,Pr,mn,N,Sa,Lr,Sr,Ta,Tr,Ar,Aa,Mr,$r,dn,_,Ma,Nr,jr,$a,Hr,Dr,Na,Fr,Br,ja,Ir,Gr,Ha,Rr,Cr,gn,P,Da,xr,Or,Fa,zr,Kr,Ba,qr,Ur,Pe,Yr,Jr,pn,y,Ia,Wr,Vr,Ga,Qr,Xr,Ra,Zr,ei,Le,ai,ni,Ca,ti,ri,hn,Ne,ii,kn,I,q,li,xa,si,oi,Oa,ui,mi,di,za,gi,pi,Ka,hi,fn;return ae=new wn({}),ne=new Ql({props:{chapter:1,classNames:"absolute z-10 right-0 top-0"}}),te=new wn({}),re=new es({props:{id:"00GKzGyWFEs"}}),de=new wn({}),_e=new wn({}),{c(){p=i("meta"),A=d(),h=i("h1"),b=i("a"),xe=i("span"),Fe(ae.$$.fragment),Ln=d(),Oe=i("span"),Sn=t("Pendahuluan"),Ua=d(),Fe(ne.$$.fragment),Ya=d(),R=i("h2"),Y=i("a"),ze=i("span"),Fe(te.$$.fragment),Tn=d(),Ke=i("span"),An=t("Selamat datang di Kursus \u{1F917}!"),Ja=d(),Fe(re.$$.fragment),Wa=d(),k=i("p"),Mn=t("Pada kursus ini, anda akan belajar mengenai "),qe=i("em"),$n=t("natural language processing"),Nn=t(" (pemrosesan bahasa natural) atau NLP menggunakan modul-modul dari ekosistem "),ie=i("a"),jn=t("Hugging Face"),Hn=t(" - "),le=i("a"),Dn=t("\u{1F917} Transformers"),Fn=t(", "),se=i("a"),Bn=t("\u{1F917} Datasets"),In=t(", "),oe=i("a"),Gn=t("\u{1F917} Tokenizers"),Rn=t(", and "),ue=i("a"),Cn=t("\u{1F917} Accelerate"),xn=t(" \u2014 as well as the "),me=i("a"),On=t("Hugging Face Hub"),zn=t(". Kursus ini 100% gratis tanpa iklan."),Va=d(),C=i("h2"),J=i("a"),Ue=i("span"),Fe(de.$$.fragment),Kn=d(),Ye=i("span"),qn=t("Silabus"),Qa=d(),Me=i("p"),Un=t("Silabus kursus ini adalah sebagai berikut:"),Xa=d(),x=i("div"),ge=i("img"),Yn=d(),pe=i("img"),Za=d(),S=i("ul"),M=i("li"),Jn=t("Bab 1-4 akan mencakup pengenalan konsep-konsep dasar modul \u{1F917} Transformers. Di akhir bab 4, anda akan tahu bagaimana menggunakan model-model "),Je=i("em"),Wn=t("Transformer"),Vn=t(" dari "),he=i("a"),Qn=t("Hugging Face Hub"),Xn=t(", melakukan model "),We=i("em"),Zn=t("fine-tuning"),et=t(" untuk dataset anda, dan membagikan model anda di Hugging Face Hub!"),at=d(),Ve=i("li"),nt=t("Bab 5-8 akan mencakup dasar-dasar dari \u{1F917} Datasets dan \u{1F917} Tokenizers sebelum anda diperkenalkan ke kasus-kasus yang dapat ditangani dengan NLP. Diakhir kursus ini, anda akan mampu menangani dan menyelesaikan kasus-kasus NLP."),tt=d(),Qe=i("li"),rt=t("Chapters 9 to 12 go beyond NLP, and explore how Transformer models can be used tackle tasks in speech processing and computer vision. Along the way, you\u2019ll learn how to build and share demos of your models, and optimize them for production environments. By the end of this part, you will be ready to apply \u{1F917} Transformers to (almost) any machine learning problem!"),it=d(),w=i("li"),lt=t("Setelah NLP, di bab 9-12, anda akan mengeksplorasi bagaimana model-model Transformer dapat digunakan untuk menangani kasus-kasus lain seperti "),Xe=i("em"),st=t("speech processing"),ot=t(" (pemrosesan ucapan) dan "),Ze=i("em"),ut=t("computer vision"),mt=t(" (penglihatan komputer). Selain itu, anda akan belajar cara membuat dan membagikan demo (prototype) dari model anda, serta cara mengoptimisasi model anda untuk "),ea=i("em"),dt=t("production environment"),gt=t(" (penerapan di kasus asli). Di akhir bab 12, anda akan siap mengimplementasikan \u{1F917} Transformers untuk (hampir) semua kasus "),aa=i("em"),pt=t("machine learning"),ht=t(" (pembelajaran mesin)!"),en=d(),$e=i("p"),kt=t("Syarat mengikuti kursus:"),an=d(),T=i("ul"),na=i("li"),ft=t("Requires a good knowledge of Python"),ct=d(),ta=i("li"),bt=t("Pengetahuan mengenai Python"),vt=d(),B=i("li"),Et=t("Akan lebih baik jika sudah mengenal deep learning dengan mengambil kursus dari "),ke=i("a"),_t=t("fast.ai"),yt=t(" \u201D"),fe=i("a"),wt=t("Practical Deep Learning for Coders"),Pt=t("\u201D atau program-program yang dikembangkan oleh "),ce=i("a"),Lt=t("DeepLearning.AI"),St=d(),O=i("li"),Tt=t("Tidak perlu pengetahuan mengenai "),be=i("a"),At=t("PyTorch"),Mt=t(" atau "),ve=i("a"),$t=t("TensorFlow"),Nt=t(". Tapi, akan lebih baik jika sudah terbiasa dengan salah satu framework tersebut."),nn=d(),W=i("p"),jt=t("Setelah menyelesaikan kursus ini, sangat direkomendasikan untuk mengikuti kursus dari DeepLearning.AI "),Ee=i("a"),Ht=t("Natural Language Processing Specialization"),Dt=t(" yang akan mencakup model-model NLP klasik seperti naive Bayes dan LSTM. Pengetahuan tersebut akan sangat berharga bagi anda!"),tn=d(),z=i("h2"),V=i("a"),ra=i("span"),Fe(_e.$$.fragment),Ft=d(),ia=i("span"),Bt=t("Tentang penulis"),rn=d(),v=i("p"),la=i("strong"),It=t("Abubakar Abid"),Gt=t(" adalah lulusan PhD dari Stanford dengan konsentrasi aplikasi pembelajaran mesin. Sembari menyelesaikan pendidikan PhD, beliau menciptakan "),ye=i("a"),Rt=t("Gradio"),Ct=t(", sebuah modul "),sa=i("em"),xt=t("open-source"),Ot=t(" Python yang sudah digunakan untuk membuat lebih dari 600.000 demo (prototype) model "),oa=i("em"),zt=t("machine learning"),Kt=t(". Gradio telah diakusisi oleh Hugging Face, tempat dimana Abubakar bekerja sebagai "),ua=i("em"),qt=t("machine learning team lead"),Ut=t("."),ln=d(),$=i("p"),ma=i("strong"),Yt=t("Matthew Carrigan"),Jt=t(" bekerja sebagai "),da=i("em"),Wt=t("Machine Learning Engineer"),Vt=t(" di Hugging Face. Beliau tinggal di Dublin, Irlandia, pernah bekerja sebagai "),ga=i("em"),Qt=t("ML engineer"),Xt=t(" di Parse.ly dan sebelumnya merupakan peneliti post-doctoral di Trinity College Dublin. Beliau tidak percaya kita akan mencapai Artificial general intelligence (AGI) dengan menambahkan skala dari arsitektur yang digunakan sekarang, namun memiliki optimisme mengenai imortalitas robot."),sn=d(),K=i("p"),pa=i("strong"),Zt=t("Lysandre Debut"),er=t(" bekerja sebagai "),ha=i("em"),ar=t("Machine Learning Engineer"),nr=t(" di Hugging Face dan berfokus mengembangkan modul \u{1F917} Transformers sejak seumur jagung. Beliau mempunya mimpi untuk agar NLP dapat diakses oleh semua orang dengan mengembangkan alat-alat atau aplikasi-aplikasi sederhana menggunkan API."),on=d(),f=i("p"),ka=i("strong"),tr=t("Sylvain Gugger"),rr=t(" adalah "),fa=i("em"),ir=t("Research Engineer"),lr=t(" di Hugging Face dan merupakan salah satu "),ca=i("em"),sr=t("maintainer"),or=t(" dari modul \u{1F917} Transformers. Beliau pernah bekerja sebagai "),ba=i("em"),ur=t("Research Scientist"),mr=t(" di fast.ai, dan bersama Jeremy Howard menulis "),va=i("em"),we=i("a"),dr=t("Deep Learning for Coders with fastai and PyTorch"),gr=t(". Fokus utama dari penelitian beliau adalah membuat "),Ea=i("em"),pr=t("deep learning"),hr=t(" lebih mudah diakses dengan mendesain dan memperbaiki teknik-teknik untuk melatih model dengan sumber daya terbatas."),un=d(),E=i("p"),_a=i("strong"),kr=t("Dawood Khan"),fr=t(" bekerja sebagai "),ya=i("em"),cr=t("Machine Learning Engineer"),br=t(" di Hugging Face. Beliau berasal dari NYC dan merupakan lulusan New York University jurusan "),wa=i("em"),vr=t("Computer Science"),Er=t(". Sempat bekerja sebagai iOS "),Pa=i("em"),_r=t("Engineer"),yr=t(" untuk beberapa tahun, Dawood memutuskan untuk "),La=i("em"),wr=t("resign"),Pr=t(" dan mengembangkan Gradio bersama rekan-rekan co-foundernya. Seiring berjalannya waktu, Gradio diakusisi oleh Hugging Face."),mn=d(),N=i("p"),Sa=i("strong"),Lr=t("Merve Noyan"),Sr=t(" adalah advokat "),Ta=i("em"),Tr=t("developer"),Ar=t(" di Hugging Face, beliau bertugas untuk mengembangkan konten beserta medianya untuk mendemokrasikan "),Aa=i("em"),Mr=t("machine learning"),$r=t(" untuk semua orang."),dn=d(),_=i("p"),Ma=i("strong"),Nr=t("Lucile Saulnier"),jr=t(" adalah "),$a=i("em"),Hr=t("machine learning engineer"),Dr=t(" di Hugging Face, bertugas untuk mengembangkan dan mendukung penggunaan alat-alat "),Na=i("em"),Fr=t("open source"),Br=t(". Beliau juga aktif dalam banyak riset mengenai "),ja=i("em"),Ir=t("Natural Language Processing"),Gr=t(" seperti "),Ha=i("em"),Rr=t("collaborative training"),Cr=t(" dan BigScience."),gn=d(),P=i("p"),Da=i("strong"),xr=t("Lewis Tunstall"),Or=t("  merupakan "),Fa=i("em"),zr=t("machine learning engineer"),Kr=t(" di Hugging Face, bertugas untuk mengembangkan alat-alat "),Ba=i("em"),qr=t("open source"),Ur=t(" dan membuatnya dapat diakses oleh komunitas. Beliau juga merupakan salah satu penulis dari buku terbitan O\u2019Reilly berjudul "),Pe=i("a"),Yr=t("Natural Language Processing with Transformers"),Jr=t("."),pn=d(),y=i("p"),Ia=i("strong"),Wr=t("Leandro von Werra"),Vr=t("  bekerja sebagai "),Ga=i("em"),Qr=t("machine learning engineer"),Xr=t(" untuk tim "),Ra=i("em"),Zr=t("open-source"),ei=t(" di Hugging Face dan juga merupkan salah satu penulis buku "),Le=i("a"),ai=t("Natural Language Processing with Transformers"),ni=t(" yang diterbitkan oleh O\u2019Reilly. Beliau memiliki memiliki pengalaman mengembangkan proyek-proyek NLP untuk kasus nyata pada berbagai macam "),Ca=i("em"),ti=t("machine learning stack"),ri=t(" selama beberapa tahun."),hn=d(),Ne=i("p"),ii=t("Sudah siap untuk belajar? Di bab ini anda akan belajar mengenai:"),kn=d(),I=i("ul"),q=i("li"),li=t("Penggunaan fungsi "),xa=i("code"),si=t("pipeline()"),oi=t(" untuk memecahkan masalah-masalah NLP seperti "),Oa=i("em"),ui=t("text generation"),mi=t(" (pembuatan teks) dan klasifikasi."),di=d(),za=i("li"),gi=t("Arsitektur Transformer"),pi=d(),Ka=i("li"),hi=t("Bagaimana membedakan arsitektur encoder, decoder, dan encoder-decoder beserta kasus-kasus terkait."),this.h()},l(a){const u=Wl('[data-svelte="svelte-1phssyn"]',document.head);p=l(u,"META",{name:!0,content:!0}),u.forEach(n),A=g(a),h=l(a,"H1",{class:!0});var cn=s(h);b=l(cn,"A",{id:!0,class:!0,href:!0});var bi=s(b);xe=l(bi,"SPAN",{});var vi=s(xe);Be(ae.$$.fragment,vi),vi.forEach(n),bi.forEach(n),Ln=g(cn),Oe=l(cn,"SPAN",{});var Ei=s(Oe);Sn=r(Ei,"Pendahuluan"),Ei.forEach(n),cn.forEach(n),Ua=g(a),Be(ne.$$.fragment,a),Ya=g(a),R=l(a,"H2",{class:!0});var bn=s(R);Y=l(bn,"A",{id:!0,class:!0,href:!0});var _i=s(Y);ze=l(_i,"SPAN",{});var yi=s(ze);Be(te.$$.fragment,yi),yi.forEach(n),_i.forEach(n),Tn=g(bn),Ke=l(bn,"SPAN",{});var wi=s(Ke);An=r(wi,"Selamat datang di Kursus \u{1F917}!"),wi.forEach(n),bn.forEach(n),Ja=g(a),Be(re.$$.fragment,a),Wa=g(a),k=l(a,"P",{});var c=s(k);Mn=r(c,"Pada kursus ini, anda akan belajar mengenai "),qe=l(c,"EM",{});var Pi=s(qe);$n=r(Pi,"natural language processing"),Pi.forEach(n),Nn=r(c," (pemrosesan bahasa natural) atau NLP menggunakan modul-modul dari ekosistem "),ie=l(c,"A",{href:!0,rel:!0});var Li=s(ie);jn=r(Li,"Hugging Face"),Li.forEach(n),Hn=r(c," - "),le=l(c,"A",{href:!0,rel:!0});var Si=s(le);Dn=r(Si,"\u{1F917} Transformers"),Si.forEach(n),Fn=r(c,", "),se=l(c,"A",{href:!0,rel:!0});var Ti=s(se);Bn=r(Ti,"\u{1F917} Datasets"),Ti.forEach(n),In=r(c,", "),oe=l(c,"A",{href:!0,rel:!0});var Ai=s(oe);Gn=r(Ai,"\u{1F917} Tokenizers"),Ai.forEach(n),Rn=r(c,", and "),ue=l(c,"A",{href:!0,rel:!0});var Mi=s(ue);Cn=r(Mi,"\u{1F917} Accelerate"),Mi.forEach(n),xn=r(c," \u2014 as well as the "),me=l(c,"A",{href:!0,rel:!0});var $i=s(me);On=r($i,"Hugging Face Hub"),$i.forEach(n),zn=r(c,". Kursus ini 100% gratis tanpa iklan."),c.forEach(n),Va=g(a),C=l(a,"H2",{class:!0});var vn=s(C);J=l(vn,"A",{id:!0,class:!0,href:!0});var Ni=s(J);Ue=l(Ni,"SPAN",{});var ji=s(Ue);Be(de.$$.fragment,ji),ji.forEach(n),Ni.forEach(n),Kn=g(vn),Ye=l(vn,"SPAN",{});var Hi=s(Ye);qn=r(Hi,"Silabus"),Hi.forEach(n),vn.forEach(n),Qa=g(a),Me=l(a,"P",{});var Di=s(Me);Un=r(Di,"Silabus kursus ini adalah sebagai berikut:"),Di.forEach(n),Xa=g(a),x=l(a,"DIV",{class:!0});var En=s(x);ge=l(En,"IMG",{class:!0,src:!0,alt:!0}),Yn=g(En),pe=l(En,"IMG",{class:!0,src:!0,alt:!0}),En.forEach(n),Za=g(a),S=l(a,"UL",{});var Q=s(S);M=l(Q,"LI",{});var X=s(M);Jn=r(X,"Bab 1-4 akan mencakup pengenalan konsep-konsep dasar modul \u{1F917} Transformers. Di akhir bab 4, anda akan tahu bagaimana menggunakan model-model "),Je=l(X,"EM",{});var Fi=s(Je);Wn=r(Fi,"Transformer"),Fi.forEach(n),Vn=r(X," dari "),he=l(X,"A",{href:!0,rel:!0});var Bi=s(he);Qn=r(Bi,"Hugging Face Hub"),Bi.forEach(n),Xn=r(X,", melakukan model "),We=l(X,"EM",{});var Ii=s(We);Zn=r(Ii,"fine-tuning"),Ii.forEach(n),et=r(X," untuk dataset anda, dan membagikan model anda di Hugging Face Hub!"),X.forEach(n),at=g(Q),Ve=l(Q,"LI",{});var Gi=s(Ve);nt=r(Gi,"Bab 5-8 akan mencakup dasar-dasar dari \u{1F917} Datasets dan \u{1F917} Tokenizers sebelum anda diperkenalkan ke kasus-kasus yang dapat ditangani dengan NLP. Diakhir kursus ini, anda akan mampu menangani dan menyelesaikan kasus-kasus NLP."),Gi.forEach(n),tt=g(Q),Qe=l(Q,"LI",{});var Ri=s(Qe);rt=r(Ri,"Chapters 9 to 12 go beyond NLP, and explore how Transformer models can be used tackle tasks in speech processing and computer vision. Along the way, you\u2019ll learn how to build and share demos of your models, and optimize them for production environments. By the end of this part, you will be ready to apply \u{1F917} Transformers to (almost) any machine learning problem!"),Ri.forEach(n),it=g(Q),w=l(Q,"LI",{});var G=s(w);lt=r(G,"Setelah NLP, di bab 9-12, anda akan mengeksplorasi bagaimana model-model Transformer dapat digunakan untuk menangani kasus-kasus lain seperti "),Xe=l(G,"EM",{});var Ci=s(Xe);st=r(Ci,"speech processing"),Ci.forEach(n),ot=r(G," (pemrosesan ucapan) dan "),Ze=l(G,"EM",{});var xi=s(Ze);ut=r(xi,"computer vision"),xi.forEach(n),mt=r(G," (penglihatan komputer). Selain itu, anda akan belajar cara membuat dan membagikan demo (prototype) dari model anda, serta cara mengoptimisasi model anda untuk "),ea=l(G,"EM",{});var Oi=s(ea);dt=r(Oi,"production environment"),Oi.forEach(n),gt=r(G," (penerapan di kasus asli). Di akhir bab 12, anda akan siap mengimplementasikan \u{1F917} Transformers untuk (hampir) semua kasus "),aa=l(G,"EM",{});var zi=s(aa);pt=r(zi,"machine learning"),zi.forEach(n),ht=r(G," (pembelajaran mesin)!"),G.forEach(n),Q.forEach(n),en=g(a),$e=l(a,"P",{});var Ki=s($e);kt=r(Ki,"Syarat mengikuti kursus:"),Ki.forEach(n),an=g(a),T=l(a,"UL",{});var Z=s(T);na=l(Z,"LI",{});var qi=s(na);ft=r(qi,"Requires a good knowledge of Python"),qi.forEach(n),ct=g(Z),ta=l(Z,"LI",{});var Ui=s(ta);bt=r(Ui,"Pengetahuan mengenai Python"),Ui.forEach(n),vt=g(Z),B=l(Z,"LI",{});var Se=s(B);Et=r(Se,"Akan lebih baik jika sudah mengenal deep learning dengan mengambil kursus dari "),ke=l(Se,"A",{href:!0,rel:!0});var Yi=s(ke);_t=r(Yi,"fast.ai"),Yi.forEach(n),yt=r(Se," \u201D"),fe=l(Se,"A",{href:!0,rel:!0});var Ji=s(fe);wt=r(Ji,"Practical Deep Learning for Coders"),Ji.forEach(n),Pt=r(Se,"\u201D atau program-program yang dikembangkan oleh "),ce=l(Se,"A",{href:!0,rel:!0});var Wi=s(ce);Lt=r(Wi,"DeepLearning.AI"),Wi.forEach(n),Se.forEach(n),St=g(Z),O=l(Z,"LI",{});var je=s(O);Tt=r(je,"Tidak perlu pengetahuan mengenai "),be=l(je,"A",{href:!0,rel:!0});var Vi=s(be);At=r(Vi,"PyTorch"),Vi.forEach(n),Mt=r(je," atau "),ve=l(je,"A",{href:!0,rel:!0});var Qi=s(ve);$t=r(Qi,"TensorFlow"),Qi.forEach(n),Nt=r(je,". Tapi, akan lebih baik jika sudah terbiasa dengan salah satu framework tersebut."),je.forEach(n),Z.forEach(n),nn=g(a),W=l(a,"P",{});var _n=s(W);jt=r(_n,"Setelah menyelesaikan kursus ini, sangat direkomendasikan untuk mengikuti kursus dari DeepLearning.AI "),Ee=l(_n,"A",{href:!0,rel:!0});var Xi=s(Ee);Ht=r(Xi,"Natural Language Processing Specialization"),Xi.forEach(n),Dt=r(_n," yang akan mencakup model-model NLP klasik seperti naive Bayes dan LSTM. Pengetahuan tersebut akan sangat berharga bagi anda!"),_n.forEach(n),tn=g(a),z=l(a,"H2",{class:!0});var yn=s(z);V=l(yn,"A",{id:!0,class:!0,href:!0});var Zi=s(V);ra=l(Zi,"SPAN",{});var el=s(ra);Be(_e.$$.fragment,el),el.forEach(n),Zi.forEach(n),Ft=g(yn),ia=l(yn,"SPAN",{});var al=s(ia);Bt=r(al,"Tentang penulis"),al.forEach(n),yn.forEach(n),rn=g(a),v=l(a,"P",{});var j=s(v);la=l(j,"STRONG",{});var nl=s(la);It=r(nl,"Abubakar Abid"),nl.forEach(n),Gt=r(j," adalah lulusan PhD dari Stanford dengan konsentrasi aplikasi pembelajaran mesin. Sembari menyelesaikan pendidikan PhD, beliau menciptakan "),ye=l(j,"A",{href:!0,rel:!0});var tl=s(ye);Rt=r(tl,"Gradio"),tl.forEach(n),Ct=r(j,", sebuah modul "),sa=l(j,"EM",{});var rl=s(sa);xt=r(rl,"open-source"),rl.forEach(n),Ot=r(j," Python yang sudah digunakan untuk membuat lebih dari 600.000 demo (prototype) model "),oa=l(j,"EM",{});var il=s(oa);zt=r(il,"machine learning"),il.forEach(n),Kt=r(j,". Gradio telah diakusisi oleh Hugging Face, tempat dimana Abubakar bekerja sebagai "),ua=l(j,"EM",{});var ll=s(ua);qt=r(ll,"machine learning team lead"),ll.forEach(n),Ut=r(j,"."),j.forEach(n),ln=g(a),$=l(a,"P",{});var Te=s($);ma=l(Te,"STRONG",{});var sl=s(ma);Yt=r(sl,"Matthew Carrigan"),sl.forEach(n),Jt=r(Te," bekerja sebagai "),da=l(Te,"EM",{});var ol=s(da);Wt=r(ol,"Machine Learning Engineer"),ol.forEach(n),Vt=r(Te," di Hugging Face. Beliau tinggal di Dublin, Irlandia, pernah bekerja sebagai "),ga=l(Te,"EM",{});var ul=s(ga);Qt=r(ul,"ML engineer"),ul.forEach(n),Xt=r(Te," di Parse.ly dan sebelumnya merupakan peneliti post-doctoral di Trinity College Dublin. Beliau tidak percaya kita akan mencapai Artificial general intelligence (AGI) dengan menambahkan skala dari arsitektur yang digunakan sekarang, namun memiliki optimisme mengenai imortalitas robot."),Te.forEach(n),sn=g(a),K=l(a,"P",{});var qa=s(K);pa=l(qa,"STRONG",{});var ml=s(pa);Zt=r(ml,"Lysandre Debut"),ml.forEach(n),er=r(qa," bekerja sebagai "),ha=l(qa,"EM",{});var dl=s(ha);ar=r(dl,"Machine Learning Engineer"),dl.forEach(n),nr=r(qa," di Hugging Face dan berfokus mengembangkan modul \u{1F917} Transformers sejak seumur jagung. Beliau mempunya mimpi untuk agar NLP dapat diakses oleh semua orang dengan mengembangkan alat-alat atau aplikasi-aplikasi sederhana menggunkan API."),qa.forEach(n),on=g(a),f=l(a,"P",{});var L=s(f);ka=l(L,"STRONG",{});var gl=s(ka);tr=r(gl,"Sylvain Gugger"),gl.forEach(n),rr=r(L," adalah "),fa=l(L,"EM",{});var pl=s(fa);ir=r(pl,"Research Engineer"),pl.forEach(n),lr=r(L," di Hugging Face dan merupakan salah satu "),ca=l(L,"EM",{});var hl=s(ca);sr=r(hl,"maintainer"),hl.forEach(n),or=r(L," dari modul \u{1F917} Transformers. Beliau pernah bekerja sebagai "),ba=l(L,"EM",{});var kl=s(ba);ur=r(kl,"Research Scientist"),kl.forEach(n),mr=r(L," di fast.ai, dan bersama Jeremy Howard menulis "),va=l(L,"EM",{});var fl=s(va);we=l(fl,"A",{href:!0,rel:!0});var cl=s(we);dr=r(cl,"Deep Learning for Coders with fastai and PyTorch"),cl.forEach(n),fl.forEach(n),gr=r(L,". Fokus utama dari penelitian beliau adalah membuat "),Ea=l(L,"EM",{});var bl=s(Ea);pr=r(bl,"deep learning"),bl.forEach(n),hr=r(L," lebih mudah diakses dengan mendesain dan memperbaiki teknik-teknik untuk melatih model dengan sumber daya terbatas."),L.forEach(n),un=g(a),E=l(a,"P",{});var H=s(E);_a=l(H,"STRONG",{});var vl=s(_a);kr=r(vl,"Dawood Khan"),vl.forEach(n),fr=r(H," bekerja sebagai "),ya=l(H,"EM",{});var El=s(ya);cr=r(El,"Machine Learning Engineer"),El.forEach(n),br=r(H," di Hugging Face. Beliau berasal dari NYC dan merupakan lulusan New York University jurusan "),wa=l(H,"EM",{});var _l=s(wa);vr=r(_l,"Computer Science"),_l.forEach(n),Er=r(H,". Sempat bekerja sebagai iOS "),Pa=l(H,"EM",{});var yl=s(Pa);_r=r(yl,"Engineer"),yl.forEach(n),yr=r(H," untuk beberapa tahun, Dawood memutuskan untuk "),La=l(H,"EM",{});var wl=s(La);wr=r(wl,"resign"),wl.forEach(n),Pr=r(H," dan mengembangkan Gradio bersama rekan-rekan co-foundernya. Seiring berjalannya waktu, Gradio diakusisi oleh Hugging Face."),H.forEach(n),mn=g(a),N=l(a,"P",{});var Ae=s(N);Sa=l(Ae,"STRONG",{});var Pl=s(Sa);Lr=r(Pl,"Merve Noyan"),Pl.forEach(n),Sr=r(Ae," adalah advokat "),Ta=l(Ae,"EM",{});var Ll=s(Ta);Tr=r(Ll,"developer"),Ll.forEach(n),Ar=r(Ae," di Hugging Face, beliau bertugas untuk mengembangkan konten beserta medianya untuk mendemokrasikan "),Aa=l(Ae,"EM",{});var Sl=s(Aa);Mr=r(Sl,"machine learning"),Sl.forEach(n),$r=r(Ae," untuk semua orang."),Ae.forEach(n),dn=g(a),_=l(a,"P",{});var D=s(_);Ma=l(D,"STRONG",{});var Tl=s(Ma);Nr=r(Tl,"Lucile Saulnier"),Tl.forEach(n),jr=r(D," adalah "),$a=l(D,"EM",{});var Al=s($a);Hr=r(Al,"machine learning engineer"),Al.forEach(n),Dr=r(D," di Hugging Face, bertugas untuk mengembangkan dan mendukung penggunaan alat-alat "),Na=l(D,"EM",{});var Ml=s(Na);Fr=r(Ml,"open source"),Ml.forEach(n),Br=r(D,". Beliau juga aktif dalam banyak riset mengenai "),ja=l(D,"EM",{});var $l=s(ja);Ir=r($l,"Natural Language Processing"),$l.forEach(n),Gr=r(D," seperti "),Ha=l(D,"EM",{});var Nl=s(Ha);Rr=r(Nl,"collaborative training"),Nl.forEach(n),Cr=r(D," dan BigScience."),D.forEach(n),gn=g(a),P=l(a,"P",{});var U=s(P);Da=l(U,"STRONG",{});var jl=s(Da);xr=r(jl,"Lewis Tunstall"),jl.forEach(n),Or=r(U,"  merupakan "),Fa=l(U,"EM",{});var Hl=s(Fa);zr=r(Hl,"machine learning engineer"),Hl.forEach(n),Kr=r(U," di Hugging Face, bertugas untuk mengembangkan alat-alat "),Ba=l(U,"EM",{});var Dl=s(Ba);qr=r(Dl,"open source"),Dl.forEach(n),Ur=r(U," dan membuatnya dapat diakses oleh komunitas. Beliau juga merupakan salah satu penulis dari buku terbitan O\u2019Reilly berjudul "),Pe=l(U,"A",{href:!0,rel:!0});var Fl=s(Pe);Yr=r(Fl,"Natural Language Processing with Transformers"),Fl.forEach(n),Jr=r(U,"."),U.forEach(n),pn=g(a),y=l(a,"P",{});var F=s(y);Ia=l(F,"STRONG",{});var Bl=s(Ia);Wr=r(Bl,"Leandro von Werra"),Bl.forEach(n),Vr=r(F,"  bekerja sebagai "),Ga=l(F,"EM",{});var Il=s(Ga);Qr=r(Il,"machine learning engineer"),Il.forEach(n),Xr=r(F," untuk tim "),Ra=l(F,"EM",{});var Gl=s(Ra);Zr=r(Gl,"open-source"),Gl.forEach(n),ei=r(F," di Hugging Face dan juga merupkan salah satu penulis buku "),Le=l(F,"A",{href:!0,rel:!0});var Rl=s(Le);ai=r(Rl,"Natural Language Processing with Transformers"),Rl.forEach(n),ni=r(F," yang diterbitkan oleh O\u2019Reilly. Beliau memiliki memiliki pengalaman mengembangkan proyek-proyek NLP untuk kasus nyata pada berbagai macam "),Ca=l(F,"EM",{});var Cl=s(Ca);ti=r(Cl,"machine learning stack"),Cl.forEach(n),ri=r(F," selama beberapa tahun."),F.forEach(n),hn=g(a),Ne=l(a,"P",{});var xl=s(Ne);ii=r(xl,"Sudah siap untuk belajar? Di bab ini anda akan belajar mengenai:"),xl.forEach(n),kn=g(a),I=l(a,"UL",{});var He=s(I);q=l(He,"LI",{});var De=s(q);li=r(De,"Penggunaan fungsi "),xa=l(De,"CODE",{});var Ol=s(xa);si=r(Ol,"pipeline()"),Ol.forEach(n),oi=r(De," untuk memecahkan masalah-masalah NLP seperti "),Oa=l(De,"EM",{});var zl=s(Oa);ui=r(zl,"text generation"),zl.forEach(n),mi=r(De," (pembuatan teks) dan klasifikasi."),De.forEach(n),di=g(He),za=l(He,"LI",{});var Kl=s(za);gi=r(Kl,"Arsitektur Transformer"),Kl.forEach(n),pi=g(He),Ka=l(He,"LI",{});var ql=s(Ka);hi=r(ql,"Bagaimana membedakan arsitektur encoder, decoder, dan encoder-decoder beserta kasus-kasus terkait."),ql.forEach(n),He.forEach(n),this.h()},h(){o(p,"name","hf:doc:metadata"),o(p,"content",JSON.stringify(ns)),o(b,"id","pendahuluan"),o(b,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(b,"href","#pendahuluan"),o(h,"class","relative group"),o(Y,"id","selamat-datang-di-kursus"),o(Y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(Y,"href","#selamat-datang-di-kursus"),o(R,"class","relative group"),o(ie,"href","https://huggingface.co/"),o(ie,"rel","nofollow"),o(le,"href","https://github.com/huggingface/transformers"),o(le,"rel","nofollow"),o(se,"href","https://github.com/huggingface/datasets"),o(se,"rel","nofollow"),o(oe,"href","https://github.com/huggingface/tokenizers"),o(oe,"rel","nofollow"),o(ue,"href","https://github.com/huggingface/accelerate"),o(ue,"rel","nofollow"),o(me,"href","https://huggingface.co/models"),o(me,"rel","nofollow"),o(J,"id","silabus"),o(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(J,"href","#silabus"),o(C,"class","relative group"),o(ge,"class","block dark:hidden"),Pn(ge.src,fi="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary.svg")||o(ge,"src",fi),o(ge,"alt","Brief overview of the chapters of the course."),o(pe,"class","hidden dark:block"),Pn(pe.src,ci="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary-dark.svg")||o(pe,"src",ci),o(pe,"alt","Brief overview of the chapters of the course."),o(x,"class","flex justify-center"),o(he,"href","https://huggingface.co/models"),o(he,"rel","nofollow"),o(ke,"href","https://www.fast.ai/"),o(ke,"rel","nofollow"),o(fe,"href","https://course.fast.ai/"),o(fe,"rel","nofollow"),o(ce,"href","https://www.deeplearning.ai/"),o(ce,"rel","nofollow"),o(be,"href","https://pytorch.org/"),o(be,"rel","nofollow"),o(ve,"href","https://www.tensorflow.org/"),o(ve,"rel","nofollow"),o(Ee,"href","https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearning-ai&utm_medium=institutions&utm_campaign=20211011-nlp-2-hugging_face-page-nlp-refresh"),o(Ee,"rel","nofollow"),o(V,"id","tentang-penulis"),o(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(V,"href","#tentang-penulis"),o(z,"class","relative group"),o(ye,"href","https://github.com/gradio-app/gradio"),o(ye,"rel","nofollow"),o(we,"href","https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/"),o(we,"rel","nofollow"),o(Pe,"href","https://www.oreilly.com/library/view/natural-language-processing/9781098136789/"),o(Pe,"rel","nofollow"),o(Le,"href","https://www.oreilly.com/library/view/natural-language-processing/9781098136789/"),o(Le,"rel","nofollow")},m(a,u){e(document.head,p),m(a,A,u),m(a,h,u),e(h,b),e(b,xe),Ie(ae,xe,null),e(h,Ln),e(h,Oe),e(Oe,Sn),m(a,Ua,u),Ie(ne,a,u),m(a,Ya,u),m(a,R,u),e(R,Y),e(Y,ze),Ie(te,ze,null),e(R,Tn),e(R,Ke),e(Ke,An),m(a,Ja,u),Ie(re,a,u),m(a,Wa,u),m(a,k,u),e(k,Mn),e(k,qe),e(qe,$n),e(k,Nn),e(k,ie),e(ie,jn),e(k,Hn),e(k,le),e(le,Dn),e(k,Fn),e(k,se),e(se,Bn),e(k,In),e(k,oe),e(oe,Gn),e(k,Rn),e(k,ue),e(ue,Cn),e(k,xn),e(k,me),e(me,On),e(k,zn),m(a,Va,u),m(a,C,u),e(C,J),e(J,Ue),Ie(de,Ue,null),e(C,Kn),e(C,Ye),e(Ye,qn),m(a,Qa,u),m(a,Me,u),e(Me,Un),m(a,Xa,u),m(a,x,u),e(x,ge),e(x,Yn),e(x,pe),m(a,Za,u),m(a,S,u),e(S,M),e(M,Jn),e(M,Je),e(Je,Wn),e(M,Vn),e(M,he),e(he,Qn),e(M,Xn),e(M,We),e(We,Zn),e(M,et),e(S,at),e(S,Ve),e(Ve,nt),e(S,tt),e(S,Qe),e(Qe,rt),e(S,it),e(S,w),e(w,lt),e(w,Xe),e(Xe,st),e(w,ot),e(w,Ze),e(Ze,ut),e(w,mt),e(w,ea),e(ea,dt),e(w,gt),e(w,aa),e(aa,pt),e(w,ht),m(a,en,u),m(a,$e,u),e($e,kt),m(a,an,u),m(a,T,u),e(T,na),e(na,ft),e(T,ct),e(T,ta),e(ta,bt),e(T,vt),e(T,B),e(B,Et),e(B,ke),e(ke,_t),e(B,yt),e(B,fe),e(fe,wt),e(B,Pt),e(B,ce),e(ce,Lt),e(T,St),e(T,O),e(O,Tt),e(O,be),e(be,At),e(O,Mt),e(O,ve),e(ve,$t),e(O,Nt),m(a,nn,u),m(a,W,u),e(W,jt),e(W,Ee),e(Ee,Ht),e(W,Dt),m(a,tn,u),m(a,z,u),e(z,V),e(V,ra),Ie(_e,ra,null),e(z,Ft),e(z,ia),e(ia,Bt),m(a,rn,u),m(a,v,u),e(v,la),e(la,It),e(v,Gt),e(v,ye),e(ye,Rt),e(v,Ct),e(v,sa),e(sa,xt),e(v,Ot),e(v,oa),e(oa,zt),e(v,Kt),e(v,ua),e(ua,qt),e(v,Ut),m(a,ln,u),m(a,$,u),e($,ma),e(ma,Yt),e($,Jt),e($,da),e(da,Wt),e($,Vt),e($,ga),e(ga,Qt),e($,Xt),m(a,sn,u),m(a,K,u),e(K,pa),e(pa,Zt),e(K,er),e(K,ha),e(ha,ar),e(K,nr),m(a,on,u),m(a,f,u),e(f,ka),e(ka,tr),e(f,rr),e(f,fa),e(fa,ir),e(f,lr),e(f,ca),e(ca,sr),e(f,or),e(f,ba),e(ba,ur),e(f,mr),e(f,va),e(va,we),e(we,dr),e(f,gr),e(f,Ea),e(Ea,pr),e(f,hr),m(a,un,u),m(a,E,u),e(E,_a),e(_a,kr),e(E,fr),e(E,ya),e(ya,cr),e(E,br),e(E,wa),e(wa,vr),e(E,Er),e(E,Pa),e(Pa,_r),e(E,yr),e(E,La),e(La,wr),e(E,Pr),m(a,mn,u),m(a,N,u),e(N,Sa),e(Sa,Lr),e(N,Sr),e(N,Ta),e(Ta,Tr),e(N,Ar),e(N,Aa),e(Aa,Mr),e(N,$r),m(a,dn,u),m(a,_,u),e(_,Ma),e(Ma,Nr),e(_,jr),e(_,$a),e($a,Hr),e(_,Dr),e(_,Na),e(Na,Fr),e(_,Br),e(_,ja),e(ja,Ir),e(_,Gr),e(_,Ha),e(Ha,Rr),e(_,Cr),m(a,gn,u),m(a,P,u),e(P,Da),e(Da,xr),e(P,Or),e(P,Fa),e(Fa,zr),e(P,Kr),e(P,Ba),e(Ba,qr),e(P,Ur),e(P,Pe),e(Pe,Yr),e(P,Jr),m(a,pn,u),m(a,y,u),e(y,Ia),e(Ia,Wr),e(y,Vr),e(y,Ga),e(Ga,Qr),e(y,Xr),e(y,Ra),e(Ra,Zr),e(y,ei),e(y,Le),e(Le,ai),e(y,ni),e(y,Ca),e(Ca,ti),e(y,ri),m(a,hn,u),m(a,Ne,u),e(Ne,ii),m(a,kn,u),m(a,I,u),e(I,q),e(q,li),e(q,xa),e(xa,si),e(q,oi),e(q,Oa),e(Oa,ui),e(q,mi),e(I,di),e(I,za),e(za,gi),e(I,pi),e(I,Ka),e(Ka,hi),fn=!0},p:ki,i(a){fn||(Ge(ae.$$.fragment,a),Ge(ne.$$.fragment,a),Ge(te.$$.fragment,a),Ge(re.$$.fragment,a),Ge(de.$$.fragment,a),Ge(_e.$$.fragment,a),fn=!0)},o(a){Re(ae.$$.fragment,a),Re(ne.$$.fragment,a),Re(te.$$.fragment,a),Re(re.$$.fragment,a),Re(de.$$.fragment,a),Re(_e.$$.fragment,a),fn=!1},d(a){n(p),a&&n(A),a&&n(h),Ce(ae),a&&n(Ua),Ce(ne,a),a&&n(Ya),a&&n(R),Ce(te),a&&n(Ja),Ce(re,a),a&&n(Wa),a&&n(k),a&&n(Va),a&&n(C),Ce(de),a&&n(Qa),a&&n(Me),a&&n(Xa),a&&n(x),a&&n(Za),a&&n(S),a&&n(en),a&&n($e),a&&n(an),a&&n(T),a&&n(nn),a&&n(W),a&&n(tn),a&&n(z),Ce(_e),a&&n(rn),a&&n(v),a&&n(ln),a&&n($),a&&n(sn),a&&n(K),a&&n(on),a&&n(f),a&&n(un),a&&n(E),a&&n(mn),a&&n(N),a&&n(dn),a&&n(_),a&&n(gn),a&&n(P),a&&n(pn),a&&n(y),a&&n(hn),a&&n(Ne),a&&n(kn),a&&n(I)}}}const ns={local:"pendahuluan",sections:[{local:"selamat-datang-di-kursus",title:"Selamat datang di Kursus \u{1F917}!"},{local:"silabus",title:"Silabus"},{local:"tentang-penulis",title:"Tentang penulis"}],title:"Pendahuluan"};function ts(ee){return Vl(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ss extends Ul{constructor(p){super();Yl(this,p,ts,as,Jl,{})}}export{ss as default,ns as metadata};
