import{S as qe,i as ze,s as Ce,e as a,k as d,w as Le,t as f,R as Me,c as t,d as l,m as c,a as i,x as Te,h as u,b as o,G as r,g as m,y as Pe,L as Ne,q as xe,o as Ie,B as Se,v as He}from"../../chunks/vendor-hf-doc-builder.js";import{Y as Ue}from"../../chunks/Youtube-hf-doc-builder.js";import{I as De}from"../../chunks/IconCopyLink-hf-doc-builder.js";function Je(de){let p,M,k,v,T,E,Q,P,F,N,y,H,_,K,x,V,W,U,R,X,D,A,Z,J,L,ee,Y,s,I,g,le,re,S,w,ae,te,q,$,ie,ne,z,b,oe,se,C,B,me,j;return E=new De({}),y=new Ue({props:{id:"MUqNwgPjJvQ"}}),{c(){p=a("meta"),M=d(),k=a("h1"),v=a("a"),T=a("span"),Le(E.$$.fragment),Q=d(),P=a("span"),F=f("Encoder modelleri"),N=d(),Le(y.$$.fragment),H=d(),_=a("p"),K=f("Encoder modelleri Transformer modellerinin sadece encoder k\u0131sm\u0131n\u0131 kulan\u0131r.Her a\u015Famada, attention katmanlar\u0131 ilk c\xFCmlenin b\xFCt\xFCn kelimelerine eri\u015Fir. Bu modeller genellikle \xE7ift y\xF6nl\xFC attention olarak nitelendirilir ve genellikle "),x=a("em"),V=f("auto-encoding models"),W=f(" olarak adland\u0131r\u0131l\u0131r."),U=d(),R=a("p"),X=f("Bu modellerin \xF6ne\u011Fitimi genellikle verilen c\xFCmleyi bozmaya y\xF6neliktir (\xF6rnek olarak, i\xE7indeki rastgele kelimeleri maskeleyerek) ve model ilk c\xFCmleyi bulma veya yeniden olu\u015Fturma ile g\xF6revlendirilir."),D=d(),A=a("p"),Z=f("Encoder modelleri c\xFCmle s\u0131n\u0131fland\u0131rma, varl\u0131k tan\u0131ma (daha spesifik olarak s\xF6zc\xFCk s\u0131n\u0131fland\u0131rma) ve extractive soru yan\u0131tlama gibi c\xFCmlenin tam anla\u015F\u0131lmas\u0131n\u0131 gerektiren g\xF6revler i\xE7in uygundur."),J=d(),L=a("p"),ee=f("Bu model ailesinin temsilcileri \u015Funlard\u0131r:"),Y=d(),s=a("ul"),I=a("li"),g=a("a"),le=f("ALBERT"),re=d(),S=a("li"),w=a("a"),ae=f("BERT"),te=d(),q=a("li"),$=a("a"),ie=f("DistilBERT"),ne=d(),z=a("li"),b=a("a"),oe=f("ELECTRA"),se=d(),C=a("li"),B=a("a"),me=f("RoBERTa"),this.h()},l(e){const n=Me('[data-svelte="svelte-1phssyn"]',document.head);p=t(n,"META",{name:!0,content:!0}),n.forEach(l),M=c(e),k=t(e,"H1",{class:!0});var G=i(k);v=t(G,"A",{id:!0,class:!0,href:!0});var fe=i(v);T=t(fe,"SPAN",{});var ce=i(T);Te(E.$$.fragment,ce),ce.forEach(l),fe.forEach(l),Q=c(G),P=t(G,"SPAN",{});var ue=i(P);F=u(ue,"Encoder modelleri"),ue.forEach(l),G.forEach(l),N=c(e),Te(y.$$.fragment,e),H=c(e),_=t(e,"P",{});var O=i(_);K=u(O,"Encoder modelleri Transformer modellerinin sadece encoder k\u0131sm\u0131n\u0131 kulan\u0131r.Her a\u015Famada, attention katmanlar\u0131 ilk c\xFCmlenin b\xFCt\xFCn kelimelerine eri\u015Fir. Bu modeller genellikle \xE7ift y\xF6nl\xFC attention olarak nitelendirilir ve genellikle "),x=t(O,"EM",{});var he=i(x);V=u(he,"auto-encoding models"),he.forEach(l),W=u(O," olarak adland\u0131r\u0131l\u0131r."),O.forEach(l),U=c(e),R=t(e,"P",{});var pe=i(R);X=u(pe,"Bu modellerin \xF6ne\u011Fitimi genellikle verilen c\xFCmleyi bozmaya y\xF6neliktir (\xF6rnek olarak, i\xE7indeki rastgele kelimeleri maskeleyerek) ve model ilk c\xFCmleyi bulma veya yeniden olu\u015Fturma ile g\xF6revlendirilir."),pe.forEach(l),D=c(e),A=t(e,"P",{});var ke=i(A);Z=u(ke,"Encoder modelleri c\xFCmle s\u0131n\u0131fland\u0131rma, varl\u0131k tan\u0131ma (daha spesifik olarak s\xF6zc\xFCk s\u0131n\u0131fland\u0131rma) ve extractive soru yan\u0131tlama gibi c\xFCmlenin tam anla\u015F\u0131lmas\u0131n\u0131 gerektiren g\xF6revler i\xE7in uygundur."),ke.forEach(l),J=c(e),L=t(e,"P",{});var ve=i(L);ee=u(ve,"Bu model ailesinin temsilcileri \u015Funlard\u0131r:"),ve.forEach(l),Y=c(e),s=t(e,"UL",{});var h=i(s);I=t(h,"LI",{});var _e=i(I);g=t(_e,"A",{href:!0,rel:!0});var Ee=i(g);le=u(Ee,"ALBERT"),Ee.forEach(l),_e.forEach(l),re=c(h),S=t(h,"LI",{});var ye=i(S);w=t(ye,"A",{href:!0,rel:!0});var ge=i(w);ae=u(ge,"BERT"),ge.forEach(l),ye.forEach(l),te=c(h),q=t(h,"LI",{});var we=i(q);$=t(we,"A",{href:!0,rel:!0});var $e=i($);ie=u($e,"DistilBERT"),$e.forEach(l),we.forEach(l),ne=c(h),z=t(h,"LI",{});var be=i(z);b=t(be,"A",{href:!0,rel:!0});var Be=i(b);oe=u(Be,"ELECTRA"),Be.forEach(l),be.forEach(l),se=c(h),C=t(h,"LI",{});var Re=i(C);B=t(Re,"A",{href:!0,rel:!0});var Ae=i(B);me=u(Ae,"RoBERTa"),Ae.forEach(l),Re.forEach(l),h.forEach(l),this.h()},h(){o(p,"name","hf:doc:metadata"),o(p,"content",JSON.stringify(Ye)),o(v,"id","encoder-modelleri"),o(v,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(v,"href","#encoder-modelleri"),o(k,"class","relative group"),o(g,"href","https://huggingface.co/transformers/model_doc/albert.html"),o(g,"rel","nofollow"),o(w,"href","https://huggingface.co/transformers/model_doc/bert.html"),o(w,"rel","nofollow"),o($,"href","https://huggingface.co/transformers/model_doc/distilbert.html"),o($,"rel","nofollow"),o(b,"href","https://huggingface.co/transformers/model_doc/electra.html"),o(b,"rel","nofollow"),o(B,"href","https://huggingface.co/transformers/model_doc/roberta.html"),o(B,"rel","nofollow")},m(e,n){r(document.head,p),m(e,M,n),m(e,k,n),r(k,v),r(v,T),Pe(E,T,null),r(k,Q),r(k,P),r(P,F),m(e,N,n),Pe(y,e,n),m(e,H,n),m(e,_,n),r(_,K),r(_,x),r(x,V),r(_,W),m(e,U,n),m(e,R,n),r(R,X),m(e,D,n),m(e,A,n),r(A,Z),m(e,J,n),m(e,L,n),r(L,ee),m(e,Y,n),m(e,s,n),r(s,I),r(I,g),r(g,le),r(s,re),r(s,S),r(S,w),r(w,ae),r(s,te),r(s,q),r(q,$),r($,ie),r(s,ne),r(s,z),r(z,b),r(b,oe),r(s,se),r(s,C),r(C,B),r(B,me),j=!0},p:Ne,i(e){j||(xe(E.$$.fragment,e),xe(y.$$.fragment,e),j=!0)},o(e){Ie(E.$$.fragment,e),Ie(y.$$.fragment,e),j=!1},d(e){l(p),e&&l(M),e&&l(k),Se(E),e&&l(N),Se(y,e),e&&l(H),e&&l(_),e&&l(U),e&&l(R),e&&l(D),e&&l(A),e&&l(J),e&&l(L),e&&l(Y),e&&l(s)}}}const Ye={local:"encoder-modelleri",title:"Encoder modelleri"};function je(de){return He(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Fe extends qe{constructor(p){super();ze(this,p,je,Je,Ce,{})}}export{Fe as default,Ye as metadata};
