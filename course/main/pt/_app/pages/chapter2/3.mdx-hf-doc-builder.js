import{S as Lt,i as Yt,s as Kt,e as d,k as _,w as M,t as i,M as Qt,c as m,d as a,m as h,x as B,a as u,h as n,b as j,G as t,g as c,y as A,o as b,p as Ie,q as $,B as T,v as Wt,n as Re}from"../../chunks/vendor-hf-doc-builder.js";import{Y as Gt}from"../../chunks/Youtube-hf-doc-builder.js";import{I as vo}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as F}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as Jt}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as Xt}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function Zt(g){let r,l;return r=new Jt({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter2/section3_tf.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter2/section3_tf.ipynb"}]}}),{c(){M(r.$$.fragment)},l(o){B(r.$$.fragment,o)},m(o,f){A(r,o,f),l=!0},i(o){l||($(r.$$.fragment,o),l=!0)},o(o){b(r.$$.fragment,o),l=!1},d(o){T(r,o)}}}function es(g){let r,l;return r=new Jt({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter2/section3_pt.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter2/section3_pt.ipynb"}]}}),{c(){M(r.$$.fragment)},l(o){B(r.$$.fragment,o)},m(o,f){A(r,o,f),l=!0},i(o){l||($(r.$$.fragment,o),l=!0)},o(o){b(r.$$.fragment,o),l=!1},d(o){T(r,o)}}}function os(g){let r,l;return r=new Gt({props:{id:"d3JVgghSOew"}}),{c(){M(r.$$.fragment)},l(o){B(r.$$.fragment,o)},m(o,f){A(r,o,f),l=!0},i(o){l||($(r.$$.fragment,o),l=!0)},o(o){b(r.$$.fragment,o),l=!1},d(o){T(r,o)}}}function as(g){let r,l;return r=new Gt({props:{id:"AhChOFRegn4"}}),{c(){M(r.$$.fragment)},l(o){B(r.$$.fragment,o)},m(o,f){A(r,o,f),l=!0},i(o){l||($(r.$$.fragment,o),l=!0)},o(o){b(r.$$.fragment,o),l=!1},d(o){T(r,o)}}}function rs(g){let r,l,o,f,w,E,k,z,y,q,C;return{c(){r=d("p"),l=i("Nesta se\xE7\xE3o, vamos analisar mais de perto a cria\xE7\xE3o e a utiliza\xE7\xE3o de um modelo. Vamos utilizar a classe "),o=d("code"),f=i("TFAutoModel"),w=i(", que \xE9 \xFAtil quando voc\xEA quer instanciar qualquer modelo a partir de um checkpoint."),E=_(),k=d("p"),z=i("A classe "),y=d("code"),q=i("TFAutoModel"),C=i(" e todas as classes filhas s\xE3o na verdade simples  wrapper sobre a grande variedade de modelos dispon\xEDveis na biblioteca. \xC9 um wrapper inteligente, pois pode automaticamente \u201Cadivinhar\u201D a arquitetura apropriada do modelo para seu checkpoint, e ent\xE3o instancia um modelo com esta arquitetura.")},l(p){r=m(p,"P",{});var v=u(r);l=n(v,"Nesta se\xE7\xE3o, vamos analisar mais de perto a cria\xE7\xE3o e a utiliza\xE7\xE3o de um modelo. Vamos utilizar a classe "),o=m(v,"CODE",{});var O=u(o);f=n(O,"TFAutoModel"),O.forEach(a),w=n(v,", que \xE9 \xFAtil quando voc\xEA quer instanciar qualquer modelo a partir de um checkpoint."),v.forEach(a),E=h(p),k=m(p,"P",{});var P=u(k);z=n(P,"A classe "),y=m(P,"CODE",{});var N=u(y);q=n(N,"TFAutoModel"),N.forEach(a),C=n(P," e todas as classes filhas s\xE3o na verdade simples  wrapper sobre a grande variedade de modelos dispon\xEDveis na biblioteca. \xC9 um wrapper inteligente, pois pode automaticamente \u201Cadivinhar\u201D a arquitetura apropriada do modelo para seu checkpoint, e ent\xE3o instancia um modelo com esta arquitetura."),P.forEach(a)},m(p,v){c(p,r,v),t(r,l),t(r,o),t(o,f),t(r,w),c(p,E,v),c(p,k,v),t(k,z),t(k,y),t(y,q),t(k,C)},d(p){p&&a(r),p&&a(E),p&&a(k)}}}function ts(g){let r,l,o,f,w,E,k,z,y,q,C;return{c(){r=d("p"),l=i("Nesta se\xE7\xE3o, vamos analisar mais de perto a cria\xE7\xE3o e a utiliza\xE7\xE3o de um modelo. Vamos utilizar a classe "),o=d("code"),f=i("AutoModel"),w=i(", que \xE9 \xFAtil quando voc\xEA quer instanciar qualquer modelo a partir de um checkpoint."),E=_(),k=d("p"),z=i("A classe "),y=d("code"),q=i("AutoModel"),C=i(" e todas as classes filhas s\xE3o na verdade simples wrapper sobre a grande variedade de modelos dispon\xEDveis na biblioteca. \xC9 um wrapper inteligente, pois pode automaticamente \u201Cadivinhar\u201D a arquitetura apropriada do modelo para seu checkpoint, e ent\xE3o instancia um modelo com esta arquitetura.")},l(p){r=m(p,"P",{});var v=u(r);l=n(v,"Nesta se\xE7\xE3o, vamos analisar mais de perto a cria\xE7\xE3o e a utiliza\xE7\xE3o de um modelo. Vamos utilizar a classe "),o=m(v,"CODE",{});var O=u(o);f=n(O,"AutoModel"),O.forEach(a),w=n(v,", que \xE9 \xFAtil quando voc\xEA quer instanciar qualquer modelo a partir de um checkpoint."),v.forEach(a),E=h(p),k=m(p,"P",{});var P=u(k);z=n(P,"A classe "),y=m(P,"CODE",{});var N=u(y);q=n(N,"AutoModel"),N.forEach(a),C=n(P," e todas as classes filhas s\xE3o na verdade simples wrapper sobre a grande variedade de modelos dispon\xEDveis na biblioteca. \xC9 um wrapper inteligente, pois pode automaticamente \u201Cadivinhar\u201D a arquitetura apropriada do modelo para seu checkpoint, e ent\xE3o instancia um modelo com esta arquitetura."),P.forEach(a)},m(p,v){c(p,r,v),t(r,l),t(r,o),t(o,f),t(r,w),c(p,E,v),c(p,k,v),t(k,z),t(k,y),t(y,q),t(k,C)},d(p){p&&a(r),p&&a(E),p&&a(k)}}}function ss(g){let r,l;return r=new F({props:{code:`from transformers import BertConfig, TFBertModel

# Construindo a configura\xE7\xE3o
config = BertConfig()

# Construindo o modelo a partir da configura\xE7\xE3o
model = TFBertModel(config)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertConfig, TFBertModel

<span class="hljs-comment"># Construindo a configura\xE7\xE3o</span>
config = BertConfig()

<span class="hljs-comment"># Construindo o modelo a partir da configura\xE7\xE3o</span>
model = TFBertModel(config)`}}),{c(){M(r.$$.fragment)},l(o){B(r.$$.fragment,o)},m(o,f){A(r,o,f),l=!0},i(o){l||($(r.$$.fragment,o),l=!0)},o(o){b(r.$$.fragment,o),l=!1},d(o){T(r,o)}}}function is(g){let r,l;return r=new F({props:{code:`from transformers import BertConfig, BertModel

# Construindo a configura\xE7\xE3o
config = BertConfig()

# Construindo o modelo a partir da configura\xE7\xE3o
model = BertModel(config)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertConfig, BertModel

<span class="hljs-comment"># Construindo a configura\xE7\xE3o</span>
config = BertConfig()

<span class="hljs-comment"># Construindo o modelo a partir da configura\xE7\xE3o</span>
model = BertModel(config)`}}),{c(){M(r.$$.fragment)},l(o){B(r.$$.fragment,o)},m(o,f){A(r,o,f),l=!0},i(o){l||($(r.$$.fragment,o),l=!0)},o(o){b(r.$$.fragment,o),l=!1},d(o){T(r,o)}}}function ns(g){let r,l;return r=new F({props:{code:`from transformers import BertConfig, TFBertModel

config = BertConfig()
model = TFBertModel(config)

# O modelo \xE9 inicializado aleatoriamente!`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertConfig, TFBertModel

config = BertConfig()
model = TFBertModel(config)

<span class="hljs-comment"># O modelo \xE9 inicializado aleatoriamente!</span>`}}),{c(){M(r.$$.fragment)},l(o){B(r.$$.fragment,o)},m(o,f){A(r,o,f),l=!0},i(o){l||($(r.$$.fragment,o),l=!0)},o(o){b(r.$$.fragment,o),l=!1},d(o){T(r,o)}}}function ls(g){let r,l;return r=new F({props:{code:`from transformers import BertConfig, BertModel

config = BertConfig()
model = BertModel(config)

# O modelo \xE9 inicializado aleatoriamente!`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertConfig, BertModel

config = BertConfig()
model = BertModel(config)

<span class="hljs-comment"># O modelo \xE9 inicializado aleatoriamente!</span>`}}),{c(){M(r.$$.fragment)},l(o){B(r.$$.fragment,o)},m(o,f){A(r,o,f),l=!0},i(o){l||($(r.$$.fragment,o),l=!0)},o(o){b(r.$$.fragment,o),l=!1},d(o){T(r,o)}}}function ds(g){let r,l,o,f,w,E,k,z,y,q,C;return r=new F({props:{code:`from transformers import TFBertModel

model = TFBertModel.from_pretrained("bert-base-cased")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFBertModel

model = TFBertModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)`}}),{c(){M(r.$$.fragment),l=_(),o=d("p"),f=i("Como voc\xEA viu anteriormente, poder\xEDamos substituir o "),w=d("code"),E=i("TFBertModel"),k=i(" pela classe equivalente ao "),z=d("code"),y=i("TFAutoModel"),q=i(". Faremos isto de agora em diante, pois isto produz um c\xF3digo generalista a partir de um checkpoint; se seu c\xF3digo funciona para checkpoint, ele deve funcionar perfeitamente com outro. Isto se aplica mesmo que a arquitetura seja diferente, desde que o checkpoint tenha sido treinado para uma tarefa semelhante (por exemplo, uma tarefa de an\xE1lise de sentimento).")},l(p){B(r.$$.fragment,p),l=h(p),o=m(p,"P",{});var v=u(o);f=n(v,"Como voc\xEA viu anteriormente, poder\xEDamos substituir o "),w=m(v,"CODE",{});var O=u(w);E=n(O,"TFBertModel"),O.forEach(a),k=n(v," pela classe equivalente ao "),z=m(v,"CODE",{});var P=u(z);y=n(P,"TFAutoModel"),P.forEach(a),q=n(v,". Faremos isto de agora em diante, pois isto produz um c\xF3digo generalista a partir de um checkpoint; se seu c\xF3digo funciona para checkpoint, ele deve funcionar perfeitamente com outro. Isto se aplica mesmo que a arquitetura seja diferente, desde que o checkpoint tenha sido treinado para uma tarefa semelhante (por exemplo, uma tarefa de an\xE1lise de sentimento)."),v.forEach(a)},m(p,v){A(r,p,v),c(p,l,v),c(p,o,v),t(o,f),t(o,w),t(w,E),t(o,k),t(o,z),t(z,y),t(o,q),C=!0},i(p){C||($(r.$$.fragment,p),C=!0)},o(p){b(r.$$.fragment,p),C=!1},d(p){T(r,p),p&&a(l),p&&a(o)}}}function ms(g){let r,l,o,f,w,E,k,z,y,q,C;return r=new F({props:{code:`from transformers import BertModel

model = BertModel.from_pretrained("bert-base-cased")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertModel

model = BertModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)`}}),{c(){M(r.$$.fragment),l=_(),o=d("p"),f=i("Como voc\xEA viu anteriormente, poder\xEDamos substituir o "),w=d("code"),E=i("BertModel"),k=i(" pela classe equivalente ao "),z=d("code"),y=i("AutoModel"),q=i(". Faremos isto de agora em diante, pois isto produz um c\xF3digo generalista a partir de um checkpoint; se seu c\xF3digo funciona para checkpoint, ele deve funcionar perfeitamente com outro. Isto se aplica mesmo que a arquitetura seja diferente, desde que o checkpoint tenha sido treinado para uma tarefa semelhante (por exemplo, uma tarefa de an\xE1lise de sentimento).")},l(p){B(r.$$.fragment,p),l=h(p),o=m(p,"P",{});var v=u(o);f=n(v,"Como voc\xEA viu anteriormente, poder\xEDamos substituir o "),w=m(v,"CODE",{});var O=u(w);E=n(O,"BertModel"),O.forEach(a),k=n(v," pela classe equivalente ao "),z=m(v,"CODE",{});var P=u(z);y=n(P,"AutoModel"),P.forEach(a),q=n(v,". Faremos isto de agora em diante, pois isto produz um c\xF3digo generalista a partir de um checkpoint; se seu c\xF3digo funciona para checkpoint, ele deve funcionar perfeitamente com outro. Isto se aplica mesmo que a arquitetura seja diferente, desde que o checkpoint tenha sido treinado para uma tarefa semelhante (por exemplo, uma tarefa de an\xE1lise de sentimento)."),v.forEach(a)},m(p,v){A(r,p,v),c(p,l,v),c(p,o,v),t(o,f),t(o,w),t(w,E),t(o,k),t(o,z),t(z,y),t(o,q),C=!0},i(p){C||($(r.$$.fragment,p),C=!0)},o(p){b(r.$$.fragment,p),C=!1},d(p){T(r,p),p&&a(l),p&&a(o)}}}function cs(g){let r,l;return r=new F({props:{code:`ls path_no_seu_computador

config.json tf_model.h5`,highlighted:`ls path_no_seu_computador

<span class="hljs-built_in">config</span>.<span class="hljs-keyword">json </span>tf_model.h5`}}),{c(){M(r.$$.fragment)},l(o){B(r.$$.fragment,o)},m(o,f){A(r,o,f),l=!0},i(o){l||($(r.$$.fragment,o),l=!0)},o(o){b(r.$$.fragment,o),l=!1},d(o){T(r,o)}}}function us(g){let r,l;return r=new F({props:{code:`ls path_no_seu_computador

config.json pytorch_model.bin`,highlighted:`ls path_no_seu_computador

<span class="hljs-built_in">config</span>.<span class="hljs-keyword">json </span>pytorch_model.<span class="hljs-keyword">bin</span>`}}),{c(){M(r.$$.fragment)},l(o){B(r.$$.fragment,o)},m(o,f){A(r,o,f),l=!0},i(o){l||($(r.$$.fragment,o),l=!0)},o(o){b(r.$$.fragment,o),l=!1},d(o){T(r,o)}}}function ps(g){let r,l,o,f,w,E,k,z;return{c(){r=d("p"),l=i("O arquivo "),o=d("em"),f=i("tf_model.h5"),w=i(" \xE9 conhecido como o "),E=d("em"),k=i("dicion\xE1rio de estado"),z=i("; ele cont\xE9m todos os pesos do seu modelo. Os dois arquivos andam de m\xE3os dadas; a configura\xE7\xE3o \xE9 necess\xE1ria para conhecer a arquitetura de seu modelo, enquanto os pesos do modelo s\xE3o os par\xE2metros de seu modelo.")},l(y){r=m(y,"P",{});var q=u(r);l=n(q,"O arquivo "),o=m(q,"EM",{});var C=u(o);f=n(C,"tf_model.h5"),C.forEach(a),w=n(q," \xE9 conhecido como o "),E=m(q,"EM",{});var p=u(E);k=n(p,"dicion\xE1rio de estado"),p.forEach(a),z=n(q,"; ele cont\xE9m todos os pesos do seu modelo. Os dois arquivos andam de m\xE3os dadas; a configura\xE7\xE3o \xE9 necess\xE1ria para conhecer a arquitetura de seu modelo, enquanto os pesos do modelo s\xE3o os par\xE2metros de seu modelo."),q.forEach(a)},m(y,q){c(y,r,q),t(r,l),t(r,o),t(o,f),t(r,w),t(r,E),t(E,k),t(r,z)},d(y){y&&a(r)}}}function fs(g){let r,l,o,f,w,E,k,z;return{c(){r=d("p"),l=i("O arquivo "),o=d("em"),f=i("pytorch_model.bin"),w=i(" \xE9 conhecido como o "),E=d("em"),k=i("dicion\xE1rio de estado"),z=i("; ele cont\xE9m todos os pesos do seu modelo. Os dois arquivos andam de m\xE3os dadas; a configura\xE7\xE3o \xE9 necess\xE1ria para conhecer a arquitetura de seu modelo, enquanto os pesos do modelo s\xE3o os par\xE2metros de seu modelo.")},l(y){r=m(y,"P",{});var q=u(r);l=n(q,"O arquivo "),o=m(q,"EM",{});var C=u(o);f=n(C,"pytorch_model.bin"),C.forEach(a),w=n(q," \xE9 conhecido como o "),E=m(q,"EM",{});var p=u(E);k=n(p,"dicion\xE1rio de estado"),p.forEach(a),z=n(q,"; ele cont\xE9m todos os pesos do seu modelo. Os dois arquivos andam de m\xE3os dadas; a configura\xE7\xE3o \xE9 necess\xE1ria para conhecer a arquitetura de seu modelo, enquanto os pesos do modelo s\xE3o os par\xE2metros de seu modelo."),q.forEach(a)},m(y,q){c(y,r,q),t(r,l),t(r,o),t(o,f),t(r,w),t(r,E),t(E,k),t(r,z)},d(y){y&&a(r)}}}function _s(g){let r,l;return r=new F({props:{code:`import tensorflow as tf

model_inputs = tf.constant(encoded_sequences)`,highlighted:`<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

model_inputs = tf.constant(encoded_sequences)`}}),{c(){M(r.$$.fragment)},l(o){B(r.$$.fragment,o)},m(o,f){A(r,o,f),l=!0},i(o){l||($(r.$$.fragment,o),l=!0)},o(o){b(r.$$.fragment,o),l=!1},d(o){T(r,o)}}}function hs(g){let r,l;return r=new F({props:{code:`import torch

model_inputs = torch.tensor(encoded_sequences)`,highlighted:`<span class="hljs-keyword">import</span> torch

model_inputs = torch.tensor(encoded_sequences)`}}),{c(){M(r.$$.fragment)},l(o){B(r.$$.fragment,o)},m(o,f){A(r,o,f),l=!0},i(o){l||($(r.$$.fragment,o),l=!0)},o(o){b(r.$$.fragment,o),l=!1},d(o){T(r,o)}}}function vs(g){let r,l,o,f,w,E,k,z,y,q,C,p,v,O,P,N,H,Ve,Ue,Ge,Ta,Ro,X,se,bo,ge,Oa,$o,Pa,Vo,Je,Na,Uo,I,R,Le,Ye,Fa,Go,ke,Jo,qe,Lo,D,Da,go,xa,Sa,ko,Ha,Ia,qo,Ra,Va,Yo,Z,ie,Eo,Ee,Ua,wo,Ga,Ko,Ke,Ja,Qo,V,U,Qe,ne,La,We,Ya,Ka,Wo,le,Qa,zo,Wa,Xa,Xo,G,J,Xe,x,Za,yo,er,or,jo,ar,rr,we,tr,sr,Zo,de,ir,Co,nr,lr,ea,S,dr,Mo,mr,cr,Bo,ur,pr,Ao,fr,_r,oa,me,hr,ze,vr,br,aa,ee,ce,To,ye,$r,Oo,gr,ra,W,kr,Po,qr,Er,No,wr,zr,ta,je,sa,Ze,yr,ia,L,Y,eo,ue,jr,Fo,Cr,Mr,na,oo,oe,pe,Do,Ce,Br,xo,Ar,la,ao,Tr,da,ro,Or,ma,to,Pr,ca,Me,ua,fe,Nr,So,Fr,Dr,pa,Be,fa,so,xr,_a,K,Q,io,ae,_e,Ho,Ae,Sr,Io,Hr,ha,no,Ir,va,Te,ba,lo,Rr,$a;o=new Xt({props:{fw:g[0]}}),z=new vo({});const Vr=[es,Zt],Oe=[];function Ur(e,s){return e[0]==="pt"?0:1}v=Ur(g),O=Oe[v]=Vr[v](g);const Gr=[as,os],Pe=[];function Jr(e,s){return e[0]==="pt"?0:1}N=Jr(g),H=Pe[N]=Gr[N](g);function Lr(e,s){return e[0]==="pt"?ts:rs}let ga=Lr(g),re=ga(g);ge=new vo({});const Yr=[is,ss],Ne=[];function Kr(e,s){return e[0]==="pt"?0:1}I=Kr(g),R=Ne[I]=Yr[I](g),ke=new F({props:{code:"print(config)",highlighted:'<span class="hljs-built_in">print</span>(config)'}}),qe=new F({props:{code:`BertConfig {
  [...]
  "hidden_size": 768,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  [...]
}`,highlighted:`BertConfig {
  [...]
  <span class="hljs-string">&quot;hidden_size&quot;</span>: <span class="hljs-number">768</span>,
  <span class="hljs-string">&quot;intermediate_size&quot;</span>: <span class="hljs-number">3072</span>,
  <span class="hljs-string">&quot;max_position_embeddings&quot;</span>: <span class="hljs-number">512</span>,
  <span class="hljs-string">&quot;num_attention_heads&quot;</span>: <span class="hljs-number">12</span>,
  <span class="hljs-string">&quot;num_hidden_layers&quot;</span>: <span class="hljs-number">12</span>,
  [...]
}`}}),Ee=new vo({});const Qr=[ls,ns],Fe=[];function Wr(e,s){return e[0]==="pt"?0:1}V=Wr(g),U=Fe[V]=Qr[V](g);const Xr=[ms,ds],De=[];function Zr(e,s){return e[0]==="pt"?0:1}G=Zr(g),J=De[G]=Xr[G](g),ye=new vo({}),je=new F({props:{code:'model.save_pretrained("path_no_seu_computador")',highlighted:'model.save_pretrained(<span class="hljs-string">&quot;path_no_seu_computador&quot;</span>)'}});const et=[us,cs],xe=[];function ot(e,s){return e[0]==="pt"?0:1}L=ot(g),Y=xe[L]=et[L](g);function at(e,s){return e[0]==="pt"?fs:ps}let ka=at(g),te=ka(g);Ce=new vo({}),Me=new F({props:{code:'sequences = ["Hello!", "Cool.", "Nice!"]',highlighted:'sequences = [<span class="hljs-string">&quot;Hello!&quot;</span>, <span class="hljs-string">&quot;Cool.&quot;</span>, <span class="hljs-string">&quot;Nice!&quot;</span>]'}}),Be=new F({props:{code:`encoded_sequences = [
    [101, 7592, 999, 102],
    [101, 4658, 1012, 102],
    [101, 3835, 999, 102],
]`,highlighted:`encoded_sequences = [
    [<span class="hljs-number">101</span>, <span class="hljs-number">7592</span>, <span class="hljs-number">999</span>, <span class="hljs-number">102</span>],
    [<span class="hljs-number">101</span>, <span class="hljs-number">4658</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>],
    [<span class="hljs-number">101</span>, <span class="hljs-number">3835</span>, <span class="hljs-number">999</span>, <span class="hljs-number">102</span>],
]`}});const rt=[hs,_s],Se=[];function tt(e,s){return e[0]==="pt"?0:1}return K=tt(g),Q=Se[K]=rt[K](g),Ae=new vo({}),Te=new F({props:{code:"output = model(model_inputs)",highlighted:"output = model(model_inputs)"}}),{c(){r=d("meta"),l=_(),M(o.$$.fragment),f=_(),w=d("h1"),E=d("a"),k=d("span"),M(z.$$.fragment),y=_(),q=d("span"),C=i("Modelos"),p=_(),O.c(),P=_(),H.c(),Ve=_(),re.c(),Ue=_(),Ge=d("p"),Ta=i("Entretanto, se voc\xEA conhece o tipo de modelo que deseja usar, pode usar diretamente a classe que define sua arquitetura. Vamos dar uma olhada em como isto funciona com um modelo BERT."),Ro=_(),X=d("h2"),se=d("a"),bo=d("span"),M(ge.$$.fragment),Oa=_(),$o=d("span"),Pa=i("Criando um Transformer"),Vo=_(),Je=d("p"),Na=i("A primeira coisa que precisamos fazer para inicializar um modelo BERT \xE9 carregar um objeto de configura\xE7\xE3o:"),Uo=_(),R.c(),Le=_(),Ye=d("p"),Fa=i("A configura\xE7\xE3o cont\xE9m muitos atributos que s\xE3o usados para construir o modelo:"),Go=_(),M(ke.$$.fragment),Jo=_(),M(qe.$$.fragment),Lo=_(),D=d("p"),Da=i("Embora voc\xEA ainda n\xE3o tenha visto o que todos esses atributos fazem, voc\xEA deve reconhecer alguns deles: o atributo "),go=d("code"),xa=i("hidden_size"),Sa=i(" define o tamanho do vetor "),ko=d("code"),Ha=i("hidden_states"),Ia=i(", e o "),qo=d("code"),Ra=i("num_hidden_layers"),Va=i("  define o n\xFAmero de camadas que o Transformer possui."),Yo=_(),Z=d("h3"),ie=d("a"),Eo=d("span"),M(Ee.$$.fragment),Ua=_(),wo=d("span"),Ga=i("Diferentes m\xE9todos de inicializar o modelo"),Ko=_(),Ke=d("p"),Ja=i("A cria\xE7\xE3o de um modelo a partir da configura\xE7\xE3o padr\xE3o o inicializa com valores aleat\xF3rios:"),Qo=_(),U.c(),Qe=_(),ne=d("p"),La=i("O modelo pode ser utilizado neste estado, mas produzir\xE1 sa\xEDdas err\xF4neas; ele precisa ser treinado primeiro. Poder\xEDamos treinar o modelo a partir do zero na tarefa em m\xE3os, mas como voc\xEA viu em "),We=d("a"),Ya=i("Cap\xEDtulo 1"),Ka=i(", isto exigiria muito tempo e muitos dados, e teria um impacto ambiental n\xE3o negligenci\xE1vel. Para evitar esfor\xE7os desnecess\xE1rios e duplicados, normalmente \xE9 poss\xEDvel compartilhar e reutilizar modelos que j\xE1 foram treinados."),Wo=_(),le=d("p"),Qa=i("Carregar um Transformer j\xE1 treinado \xE9 simples - podemos fazer isso utilizando o m\xE9todo "),zo=d("code"),Wa=i("from_pretrained()"),Xa=i(":"),Xo=_(),J.c(),Xe=_(),x=d("p"),Za=i("No exemplo de c\xF3digo acima n\xE3o utilizamos "),yo=d("code"),er=i("BertConfig"),or=i(", e em vez disso carregamos um modelo pr\xE9-treinado atrav\xE9s do identificador "),jo=d("code"),ar=i("bert-base-cased"),rr=i(". Este \xE9 um checkpoint do modelo que foi treinado pelos pr\xF3prios autores do BERT; voc\xEA pode encontrar mais detalhes sobre ele em seu "),we=d("a"),tr=i("model card"),sr=i("."),Zo=_(),de=d("p"),ir=i("Este modelo agora \xE9 inicializado com todos os pesos do checkpoint. Ele pode ser usado diretamente para infer\xEAncia sobre as tarefas nas quais foi treinado, e tamb\xE9m pode ser "),Co=d("em"),nr=i("fine-tuned"),lr=i(" (aperfei\xE7oado) em uma nova tarefa. Treinando com pesos pr\xE9-treinados e n\xE3o do zero, podemos rapidamente alcan\xE7ar bons resultados."),ea=_(),S=d("p"),dr=i("Os pesos foram baixados e armazenados em cache (logo, para as futuras chamadas do m\xE9todo "),Mo=d("code"),mr=i("from_pretrained()"),cr=i(" n\xE3o ser\xE1 realizado o download novamente) em sua respectiva pasta, que tem como padr\xE3o o path "),Bo=d("em"),ur=i("~/.cache/huggingface/transformers"),pr=i(". Voc\xEA pode personalizar sua pasta de cache definindo a vari\xE1vel de ambiente "),Ao=d("code"),fr=i("HF_HOME"),_r=i("."),oa=_(),me=d("p"),hr=i("O identificador usado para carregar o modelo pode ser o identificador de qualquer modelo no Model Hub, desde que seja compat\xEDvel com a arquitetura BERT. A lista completa dos checkpoints BERT dispon\xEDveis podem ser encontrada [aqui]."),ze=d("a"),vr=i("https://huggingface.co/models?filter=bert"),br=i(")."),aa=_(),ee=d("h3"),ce=d("a"),To=d("span"),M(ye.$$.fragment),$r=_(),Oo=d("span"),gr=i("M\xE9todos para salvar/armazenar o modelo"),ra=_(),W=d("p"),kr=i("Salvar um modelo \xE9 t\xE3o f\xE1cil quanto carregar um - utilizamos o m\xE9todo "),Po=d("code"),qr=i("save_pretrained()"),Er=i(", que \xE9 an\xE1logo ao m\xE9todo "),No=d("code"),wr=i("from_pretrained()"),zr=i(":"),ta=_(),M(je.$$.fragment),sa=_(),Ze=d("p"),yr=i("Isto salva dois arquivos em seu disco:"),ia=_(),Y.c(),eo=_(),ue=d("p"),jr=i("Se voc\xEA der uma olhada no arquivo "),Fo=d("em"),Cr=i("config.json"),Mr=i(", voc\xEA reconhecer\xE1 os atributos necess\xE1rios para construir a arquitetura modelo. Este arquivo tamb\xE9m cont\xE9m alguns metadados, como a origem do checkpoint e a vers\xE3o \u{1F917} Transformers que voc\xEA estava usando quando salvou o checkpoint pela \xFAltima vez."),na=_(),te.c(),oo=_(),oe=d("h2"),pe=d("a"),Do=d("span"),M(Ce.$$.fragment),Br=_(),xo=d("span"),Ar=i("Usando um modelo de Transformer para infer\xEAncia"),la=_(),ao=d("p"),Tr=i("Agora que voc\xEA sabe como carregar e salvar um modelo, vamos tentar us\xE1-lo para fazer algumas predi\xE7\xF5es. Os Transformers s\xF3 podem processar n\xFAmeros - n\xFAmeros que o tokenizer gera. Mas antes de discutirmos os tokenizers, vamos explorar quais entradas o modelo aceita."),da=_(),ro=d("p"),Or=i("Os Tokenizers podem se encarregar de lan\xE7ar as entradas nos tensores da estrutura apropriada, mas para ajud\xE1-lo a entender o que est\xE1 acontecendo, vamos dar uma r\xE1pida olhada no que deve ser feito antes de enviar as entradas para o modelo."),ma=_(),to=d("p"),Pr=i("Digamos que temos um par de sequ\xEAncias:"),ca=_(),M(Me.$$.fragment),ua=_(),fe=d("p"),Nr=i("O tokenizer os converte em \xEDndices de vocabul\xE1rio que s\xE3o normalmente chamados de "),So=d("em"),Fr=i("IDs de entrada"),Dr=i(". Cada sequ\xEAncia \xE9 agora uma lista de n\xFAmeros! A sa\xEDda resultante \xE9:"),pa=_(),M(Be.$$.fragment),fa=_(),so=d("p"),xr=i("Esta \xE9 uma lista de sequ\xEAncias codificadas: uma lista de listas. Os tensores s\xF3 aceitam shapes (tamanhos) retangulares (pense em matrizes). Esta \u201Cmatriz\u201D j\xE1 \xE9 de forma retangular, portanto, convert\xEA-la em um tensor \xE9 f\xE1cil:"),_a=_(),Q.c(),io=_(),ae=d("h3"),_e=d("a"),Ho=d("span"),M(Ae.$$.fragment),Sr=_(),Io=d("span"),Hr=i("Usando os tensores como entradas para o modelo"),ha=_(),no=d("p"),Ir=i("Fazer uso dos tensores com o modelo \xE9 extremamente simples - chamamos apenas o modelo com os inputs:"),va=_(),M(Te.$$.fragment),ba=_(),lo=d("p"),Rr=i("Embora o modelo aceite muitos argumentos diferentes, apenas os IDs de entrada s\xE3o necess\xE1rios. Explicaremos o que os outros argumentos fazem e quando eles s\xE3o necess\xE1rios mais tarde, mas primeiro precisamos olhar mais de perto os tokenizers que constroem as entradas que um Transformer pode compreender."),this.h()},l(e){const s=Qt('[data-svelte="svelte-1phssyn"]',document.head);r=m(s,"META",{name:!0,content:!0}),s.forEach(a),l=h(e),B(o.$$.fragment,e),f=h(e),w=m(e,"H1",{class:!0});var He=u(w);E=m(He,"A",{id:!0,class:!0,href:!0});var mo=u(E);k=m(mo,"SPAN",{});var co=u(k);B(z.$$.fragment,co),co.forEach(a),mo.forEach(a),y=h(He),q=m(He,"SPAN",{});var uo=u(q);C=n(uo,"Modelos"),uo.forEach(a),He.forEach(a),p=h(e),O.l(e),P=h(e),H.l(e),Ve=h(e),re.l(e),Ue=h(e),Ge=m(e,"P",{});var po=u(Ge);Ta=n(po,"Entretanto, se voc\xEA conhece o tipo de modelo que deseja usar, pode usar diretamente a classe que define sua arquitetura. Vamos dar uma olhada em como isto funciona com um modelo BERT."),po.forEach(a),Ro=h(e),X=m(e,"H2",{class:!0});var he=u(X);se=m(he,"A",{id:!0,class:!0,href:!0});var fo=u(se);bo=m(fo,"SPAN",{});var _o=u(bo);B(ge.$$.fragment,_o),_o.forEach(a),fo.forEach(a),Oa=h(he),$o=m(he,"SPAN",{});var st=u($o);Pa=n(st,"Criando um Transformer"),st.forEach(a),he.forEach(a),Vo=h(e),Je=m(e,"P",{});var it=u(Je);Na=n(it,"A primeira coisa que precisamos fazer para inicializar um modelo BERT \xE9 carregar um objeto de configura\xE7\xE3o:"),it.forEach(a),Uo=h(e),R.l(e),Le=h(e),Ye=m(e,"P",{});var nt=u(Ye);Fa=n(nt,"A configura\xE7\xE3o cont\xE9m muitos atributos que s\xE3o usados para construir o modelo:"),nt.forEach(a),Go=h(e),B(ke.$$.fragment,e),Jo=h(e),B(qe.$$.fragment,e),Lo=h(e),D=m(e,"P",{});var ve=u(D);Da=n(ve,"Embora voc\xEA ainda n\xE3o tenha visto o que todos esses atributos fazem, voc\xEA deve reconhecer alguns deles: o atributo "),go=m(ve,"CODE",{});var lt=u(go);xa=n(lt,"hidden_size"),lt.forEach(a),Sa=n(ve," define o tamanho do vetor "),ko=m(ve,"CODE",{});var dt=u(ko);Ha=n(dt,"hidden_states"),dt.forEach(a),Ia=n(ve,", e o "),qo=m(ve,"CODE",{});var mt=u(qo);Ra=n(mt,"num_hidden_layers"),mt.forEach(a),Va=n(ve,"  define o n\xFAmero de camadas que o Transformer possui."),ve.forEach(a),Yo=h(e),Z=m(e,"H3",{class:!0});var qa=u(Z);ie=m(qa,"A",{id:!0,class:!0,href:!0});var ct=u(ie);Eo=m(ct,"SPAN",{});var ut=u(Eo);B(Ee.$$.fragment,ut),ut.forEach(a),ct.forEach(a),Ua=h(qa),wo=m(qa,"SPAN",{});var pt=u(wo);Ga=n(pt,"Diferentes m\xE9todos de inicializar o modelo"),pt.forEach(a),qa.forEach(a),Ko=h(e),Ke=m(e,"P",{});var ft=u(Ke);Ja=n(ft,"A cria\xE7\xE3o de um modelo a partir da configura\xE7\xE3o padr\xE3o o inicializa com valores aleat\xF3rios:"),ft.forEach(a),Qo=h(e),U.l(e),Qe=h(e),ne=m(e,"P",{});var Ea=u(ne);La=n(Ea,"O modelo pode ser utilizado neste estado, mas produzir\xE1 sa\xEDdas err\xF4neas; ele precisa ser treinado primeiro. Poder\xEDamos treinar o modelo a partir do zero na tarefa em m\xE3os, mas como voc\xEA viu em "),We=m(Ea,"A",{href:!0});var _t=u(We);Ya=n(_t,"Cap\xEDtulo 1"),_t.forEach(a),Ka=n(Ea,", isto exigiria muito tempo e muitos dados, e teria um impacto ambiental n\xE3o negligenci\xE1vel. Para evitar esfor\xE7os desnecess\xE1rios e duplicados, normalmente \xE9 poss\xEDvel compartilhar e reutilizar modelos que j\xE1 foram treinados."),Ea.forEach(a),Wo=h(e),le=m(e,"P",{});var wa=u(le);Qa=n(wa,"Carregar um Transformer j\xE1 treinado \xE9 simples - podemos fazer isso utilizando o m\xE9todo "),zo=m(wa,"CODE",{});var ht=u(zo);Wa=n(ht,"from_pretrained()"),ht.forEach(a),Xa=n(wa,":"),wa.forEach(a),Xo=h(e),J.l(e),Xe=h(e),x=m(e,"P",{});var be=u(x);Za=n(be,"No exemplo de c\xF3digo acima n\xE3o utilizamos "),yo=m(be,"CODE",{});var vt=u(yo);er=n(vt,"BertConfig"),vt.forEach(a),or=n(be,", e em vez disso carregamos um modelo pr\xE9-treinado atrav\xE9s do identificador "),jo=m(be,"CODE",{});var bt=u(jo);ar=n(bt,"bert-base-cased"),bt.forEach(a),rr=n(be,". Este \xE9 um checkpoint do modelo que foi treinado pelos pr\xF3prios autores do BERT; voc\xEA pode encontrar mais detalhes sobre ele em seu "),we=m(be,"A",{href:!0,rel:!0});var $t=u(we);tr=n($t,"model card"),$t.forEach(a),sr=n(be,"."),be.forEach(a),Zo=h(e),de=m(e,"P",{});var za=u(de);ir=n(za,"Este modelo agora \xE9 inicializado com todos os pesos do checkpoint. Ele pode ser usado diretamente para infer\xEAncia sobre as tarefas nas quais foi treinado, e tamb\xE9m pode ser "),Co=m(za,"EM",{});var gt=u(Co);nr=n(gt,"fine-tuned"),gt.forEach(a),lr=n(za," (aperfei\xE7oado) em uma nova tarefa. Treinando com pesos pr\xE9-treinados e n\xE3o do zero, podemos rapidamente alcan\xE7ar bons resultados."),za.forEach(a),ea=h(e),S=m(e,"P",{});var $e=u(S);dr=n($e,"Os pesos foram baixados e armazenados em cache (logo, para as futuras chamadas do m\xE9todo "),Mo=m($e,"CODE",{});var kt=u(Mo);mr=n(kt,"from_pretrained()"),kt.forEach(a),cr=n($e," n\xE3o ser\xE1 realizado o download novamente) em sua respectiva pasta, que tem como padr\xE3o o path "),Bo=m($e,"EM",{});var qt=u(Bo);ur=n(qt,"~/.cache/huggingface/transformers"),qt.forEach(a),pr=n($e,". Voc\xEA pode personalizar sua pasta de cache definindo a vari\xE1vel de ambiente "),Ao=m($e,"CODE",{});var Et=u(Ao);fr=n(Et,"HF_HOME"),Et.forEach(a),_r=n($e,"."),$e.forEach(a),oa=h(e),me=m(e,"P",{});var ya=u(me);hr=n(ya,"O identificador usado para carregar o modelo pode ser o identificador de qualquer modelo no Model Hub, desde que seja compat\xEDvel com a arquitetura BERT. A lista completa dos checkpoints BERT dispon\xEDveis podem ser encontrada [aqui]."),ze=m(ya,"A",{href:!0,rel:!0});var wt=u(ze);vr=n(wt,"https://huggingface.co/models?filter=bert"),wt.forEach(a),br=n(ya,")."),ya.forEach(a),aa=h(e),ee=m(e,"H3",{class:!0});var ja=u(ee);ce=m(ja,"A",{id:!0,class:!0,href:!0});var zt=u(ce);To=m(zt,"SPAN",{});var yt=u(To);B(ye.$$.fragment,yt),yt.forEach(a),zt.forEach(a),$r=h(ja),Oo=m(ja,"SPAN",{});var jt=u(Oo);gr=n(jt,"M\xE9todos para salvar/armazenar o modelo"),jt.forEach(a),ja.forEach(a),ra=h(e),W=m(e,"P",{});var ho=u(W);kr=n(ho,"Salvar um modelo \xE9 t\xE3o f\xE1cil quanto carregar um - utilizamos o m\xE9todo "),Po=m(ho,"CODE",{});var Ct=u(Po);qr=n(Ct,"save_pretrained()"),Ct.forEach(a),Er=n(ho,", que \xE9 an\xE1logo ao m\xE9todo "),No=m(ho,"CODE",{});var Mt=u(No);wr=n(Mt,"from_pretrained()"),Mt.forEach(a),zr=n(ho,":"),ho.forEach(a),ta=h(e),B(je.$$.fragment,e),sa=h(e),Ze=m(e,"P",{});var Bt=u(Ze);yr=n(Bt,"Isto salva dois arquivos em seu disco:"),Bt.forEach(a),ia=h(e),Y.l(e),eo=h(e),ue=m(e,"P",{});var Ca=u(ue);jr=n(Ca,"Se voc\xEA der uma olhada no arquivo "),Fo=m(Ca,"EM",{});var At=u(Fo);Cr=n(At,"config.json"),At.forEach(a),Mr=n(Ca,", voc\xEA reconhecer\xE1 os atributos necess\xE1rios para construir a arquitetura modelo. Este arquivo tamb\xE9m cont\xE9m alguns metadados, como a origem do checkpoint e a vers\xE3o \u{1F917} Transformers que voc\xEA estava usando quando salvou o checkpoint pela \xFAltima vez."),Ca.forEach(a),na=h(e),te.l(e),oo=h(e),oe=m(e,"H2",{class:!0});var Ma=u(oe);pe=m(Ma,"A",{id:!0,class:!0,href:!0});var Tt=u(pe);Do=m(Tt,"SPAN",{});var Ot=u(Do);B(Ce.$$.fragment,Ot),Ot.forEach(a),Tt.forEach(a),Br=h(Ma),xo=m(Ma,"SPAN",{});var Pt=u(xo);Ar=n(Pt,"Usando um modelo de Transformer para infer\xEAncia"),Pt.forEach(a),Ma.forEach(a),la=h(e),ao=m(e,"P",{});var Nt=u(ao);Tr=n(Nt,"Agora que voc\xEA sabe como carregar e salvar um modelo, vamos tentar us\xE1-lo para fazer algumas predi\xE7\xF5es. Os Transformers s\xF3 podem processar n\xFAmeros - n\xFAmeros que o tokenizer gera. Mas antes de discutirmos os tokenizers, vamos explorar quais entradas o modelo aceita."),Nt.forEach(a),da=h(e),ro=m(e,"P",{});var Ft=u(ro);Or=n(Ft,"Os Tokenizers podem se encarregar de lan\xE7ar as entradas nos tensores da estrutura apropriada, mas para ajud\xE1-lo a entender o que est\xE1 acontecendo, vamos dar uma r\xE1pida olhada no que deve ser feito antes de enviar as entradas para o modelo."),Ft.forEach(a),ma=h(e),to=m(e,"P",{});var Dt=u(to);Pr=n(Dt,"Digamos que temos um par de sequ\xEAncias:"),Dt.forEach(a),ca=h(e),B(Me.$$.fragment,e),ua=h(e),fe=m(e,"P",{});var Ba=u(fe);Nr=n(Ba,"O tokenizer os converte em \xEDndices de vocabul\xE1rio que s\xE3o normalmente chamados de "),So=m(Ba,"EM",{});var xt=u(So);Fr=n(xt,"IDs de entrada"),xt.forEach(a),Dr=n(Ba,". Cada sequ\xEAncia \xE9 agora uma lista de n\xFAmeros! A sa\xEDda resultante \xE9:"),Ba.forEach(a),pa=h(e),B(Be.$$.fragment,e),fa=h(e),so=m(e,"P",{});var St=u(so);xr=n(St,"Esta \xE9 uma lista de sequ\xEAncias codificadas: uma lista de listas. Os tensores s\xF3 aceitam shapes (tamanhos) retangulares (pense em matrizes). Esta \u201Cmatriz\u201D j\xE1 \xE9 de forma retangular, portanto, convert\xEA-la em um tensor \xE9 f\xE1cil:"),St.forEach(a),_a=h(e),Q.l(e),io=h(e),ae=m(e,"H3",{class:!0});var Aa=u(ae);_e=m(Aa,"A",{id:!0,class:!0,href:!0});var Ht=u(_e);Ho=m(Ht,"SPAN",{});var It=u(Ho);B(Ae.$$.fragment,It),It.forEach(a),Ht.forEach(a),Sr=h(Aa),Io=m(Aa,"SPAN",{});var Rt=u(Io);Hr=n(Rt,"Usando os tensores como entradas para o modelo"),Rt.forEach(a),Aa.forEach(a),ha=h(e),no=m(e,"P",{});var Vt=u(no);Ir=n(Vt,"Fazer uso dos tensores com o modelo \xE9 extremamente simples - chamamos apenas o modelo com os inputs:"),Vt.forEach(a),va=h(e),B(Te.$$.fragment,e),ba=h(e),lo=m(e,"P",{});var Ut=u(lo);Rr=n(Ut,"Embora o modelo aceite muitos argumentos diferentes, apenas os IDs de entrada s\xE3o necess\xE1rios. Explicaremos o que os outros argumentos fazem e quando eles s\xE3o necess\xE1rios mais tarde, mas primeiro precisamos olhar mais de perto os tokenizers que constroem as entradas que um Transformer pode compreender."),Ut.forEach(a),this.h()},h(){j(r,"name","hf:doc:metadata"),j(r,"content",JSON.stringify(bs)),j(E,"id","modelos"),j(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),j(E,"href","#modelos"),j(w,"class","relative group"),j(se,"id","criando-um-transformer"),j(se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),j(se,"href","#criando-um-transformer"),j(X,"class","relative group"),j(ie,"id","diferentes-mtodos-de-inicializar-o-modelo"),j(ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),j(ie,"href","#diferentes-mtodos-de-inicializar-o-modelo"),j(Z,"class","relative group"),j(We,"href","/course/pt/chapter1"),j(we,"href","https://huggingface.co/bert-base-cased"),j(we,"rel","nofollow"),j(ze,"href","https://huggingface.co/models?filter=bert"),j(ze,"rel","nofollow"),j(ce,"id","mtodos-para-salvararmazenar-o-modelo"),j(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),j(ce,"href","#mtodos-para-salvararmazenar-o-modelo"),j(ee,"class","relative group"),j(pe,"id","usando-um-modelo-de-transformer-para-inferncia"),j(pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),j(pe,"href","#usando-um-modelo-de-transformer-para-inferncia"),j(oe,"class","relative group"),j(_e,"id","usando-os-tensores-como-entradas-para-o-modelo"),j(_e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),j(_e,"href","#usando-os-tensores-como-entradas-para-o-modelo"),j(ae,"class","relative group")},m(e,s){t(document.head,r),c(e,l,s),A(o,e,s),c(e,f,s),c(e,w,s),t(w,E),t(E,k),A(z,k,null),t(w,y),t(w,q),t(q,C),c(e,p,s),Oe[v].m(e,s),c(e,P,s),Pe[N].m(e,s),c(e,Ve,s),re.m(e,s),c(e,Ue,s),c(e,Ge,s),t(Ge,Ta),c(e,Ro,s),c(e,X,s),t(X,se),t(se,bo),A(ge,bo,null),t(X,Oa),t(X,$o),t($o,Pa),c(e,Vo,s),c(e,Je,s),t(Je,Na),c(e,Uo,s),Ne[I].m(e,s),c(e,Le,s),c(e,Ye,s),t(Ye,Fa),c(e,Go,s),A(ke,e,s),c(e,Jo,s),A(qe,e,s),c(e,Lo,s),c(e,D,s),t(D,Da),t(D,go),t(go,xa),t(D,Sa),t(D,ko),t(ko,Ha),t(D,Ia),t(D,qo),t(qo,Ra),t(D,Va),c(e,Yo,s),c(e,Z,s),t(Z,ie),t(ie,Eo),A(Ee,Eo,null),t(Z,Ua),t(Z,wo),t(wo,Ga),c(e,Ko,s),c(e,Ke,s),t(Ke,Ja),c(e,Qo,s),Fe[V].m(e,s),c(e,Qe,s),c(e,ne,s),t(ne,La),t(ne,We),t(We,Ya),t(ne,Ka),c(e,Wo,s),c(e,le,s),t(le,Qa),t(le,zo),t(zo,Wa),t(le,Xa),c(e,Xo,s),De[G].m(e,s),c(e,Xe,s),c(e,x,s),t(x,Za),t(x,yo),t(yo,er),t(x,or),t(x,jo),t(jo,ar),t(x,rr),t(x,we),t(we,tr),t(x,sr),c(e,Zo,s),c(e,de,s),t(de,ir),t(de,Co),t(Co,nr),t(de,lr),c(e,ea,s),c(e,S,s),t(S,dr),t(S,Mo),t(Mo,mr),t(S,cr),t(S,Bo),t(Bo,ur),t(S,pr),t(S,Ao),t(Ao,fr),t(S,_r),c(e,oa,s),c(e,me,s),t(me,hr),t(me,ze),t(ze,vr),t(me,br),c(e,aa,s),c(e,ee,s),t(ee,ce),t(ce,To),A(ye,To,null),t(ee,$r),t(ee,Oo),t(Oo,gr),c(e,ra,s),c(e,W,s),t(W,kr),t(W,Po),t(Po,qr),t(W,Er),t(W,No),t(No,wr),t(W,zr),c(e,ta,s),A(je,e,s),c(e,sa,s),c(e,Ze,s),t(Ze,yr),c(e,ia,s),xe[L].m(e,s),c(e,eo,s),c(e,ue,s),t(ue,jr),t(ue,Fo),t(Fo,Cr),t(ue,Mr),c(e,na,s),te.m(e,s),c(e,oo,s),c(e,oe,s),t(oe,pe),t(pe,Do),A(Ce,Do,null),t(oe,Br),t(oe,xo),t(xo,Ar),c(e,la,s),c(e,ao,s),t(ao,Tr),c(e,da,s),c(e,ro,s),t(ro,Or),c(e,ma,s),c(e,to,s),t(to,Pr),c(e,ca,s),A(Me,e,s),c(e,ua,s),c(e,fe,s),t(fe,Nr),t(fe,So),t(So,Fr),t(fe,Dr),c(e,pa,s),A(Be,e,s),c(e,fa,s),c(e,so,s),t(so,xr),c(e,_a,s),Se[K].m(e,s),c(e,io,s),c(e,ae,s),t(ae,_e),t(_e,Ho),A(Ae,Ho,null),t(ae,Sr),t(ae,Io),t(Io,Hr),c(e,ha,s),c(e,no,s),t(no,Ir),c(e,va,s),A(Te,e,s),c(e,ba,s),c(e,lo,s),t(lo,Rr),$a=!0},p(e,[s]){const He={};s&1&&(He.fw=e[0]),o.$set(He);let mo=v;v=Ur(e),v!==mo&&(Re(),b(Oe[mo],1,1,()=>{Oe[mo]=null}),Ie(),O=Oe[v],O||(O=Oe[v]=Vr[v](e),O.c()),$(O,1),O.m(P.parentNode,P));let co=N;N=Jr(e),N!==co&&(Re(),b(Pe[co],1,1,()=>{Pe[co]=null}),Ie(),H=Pe[N],H||(H=Pe[N]=Gr[N](e),H.c()),$(H,1),H.m(Ve.parentNode,Ve)),ga!==(ga=Lr(e))&&(re.d(1),re=ga(e),re&&(re.c(),re.m(Ue.parentNode,Ue)));let uo=I;I=Kr(e),I!==uo&&(Re(),b(Ne[uo],1,1,()=>{Ne[uo]=null}),Ie(),R=Ne[I],R||(R=Ne[I]=Yr[I](e),R.c()),$(R,1),R.m(Le.parentNode,Le));let po=V;V=Wr(e),V!==po&&(Re(),b(Fe[po],1,1,()=>{Fe[po]=null}),Ie(),U=Fe[V],U||(U=Fe[V]=Qr[V](e),U.c()),$(U,1),U.m(Qe.parentNode,Qe));let he=G;G=Zr(e),G!==he&&(Re(),b(De[he],1,1,()=>{De[he]=null}),Ie(),J=De[G],J||(J=De[G]=Xr[G](e),J.c()),$(J,1),J.m(Xe.parentNode,Xe));let fo=L;L=ot(e),L!==fo&&(Re(),b(xe[fo],1,1,()=>{xe[fo]=null}),Ie(),Y=xe[L],Y||(Y=xe[L]=et[L](e),Y.c()),$(Y,1),Y.m(eo.parentNode,eo)),ka!==(ka=at(e))&&(te.d(1),te=ka(e),te&&(te.c(),te.m(oo.parentNode,oo)));let _o=K;K=tt(e),K!==_o&&(Re(),b(Se[_o],1,1,()=>{Se[_o]=null}),Ie(),Q=Se[K],Q||(Q=Se[K]=rt[K](e),Q.c()),$(Q,1),Q.m(io.parentNode,io))},i(e){$a||($(o.$$.fragment,e),$(z.$$.fragment,e),$(O),$(H),$(ge.$$.fragment,e),$(R),$(ke.$$.fragment,e),$(qe.$$.fragment,e),$(Ee.$$.fragment,e),$(U),$(J),$(ye.$$.fragment,e),$(je.$$.fragment,e),$(Y),$(Ce.$$.fragment,e),$(Me.$$.fragment,e),$(Be.$$.fragment,e),$(Q),$(Ae.$$.fragment,e),$(Te.$$.fragment,e),$a=!0)},o(e){b(o.$$.fragment,e),b(z.$$.fragment,e),b(O),b(H),b(ge.$$.fragment,e),b(R),b(ke.$$.fragment,e),b(qe.$$.fragment,e),b(Ee.$$.fragment,e),b(U),b(J),b(ye.$$.fragment,e),b(je.$$.fragment,e),b(Y),b(Ce.$$.fragment,e),b(Me.$$.fragment,e),b(Be.$$.fragment,e),b(Q),b(Ae.$$.fragment,e),b(Te.$$.fragment,e),$a=!1},d(e){a(r),e&&a(l),T(o,e),e&&a(f),e&&a(w),T(z),e&&a(p),Oe[v].d(e),e&&a(P),Pe[N].d(e),e&&a(Ve),re.d(e),e&&a(Ue),e&&a(Ge),e&&a(Ro),e&&a(X),T(ge),e&&a(Vo),e&&a(Je),e&&a(Uo),Ne[I].d(e),e&&a(Le),e&&a(Ye),e&&a(Go),T(ke,e),e&&a(Jo),T(qe,e),e&&a(Lo),e&&a(D),e&&a(Yo),e&&a(Z),T(Ee),e&&a(Ko),e&&a(Ke),e&&a(Qo),Fe[V].d(e),e&&a(Qe),e&&a(ne),e&&a(Wo),e&&a(le),e&&a(Xo),De[G].d(e),e&&a(Xe),e&&a(x),e&&a(Zo),e&&a(de),e&&a(ea),e&&a(S),e&&a(oa),e&&a(me),e&&a(aa),e&&a(ee),T(ye),e&&a(ra),e&&a(W),e&&a(ta),T(je,e),e&&a(sa),e&&a(Ze),e&&a(ia),xe[L].d(e),e&&a(eo),e&&a(ue),e&&a(na),te.d(e),e&&a(oo),e&&a(oe),T(Ce),e&&a(la),e&&a(ao),e&&a(da),e&&a(ro),e&&a(ma),e&&a(to),e&&a(ca),T(Me,e),e&&a(ua),e&&a(fe),e&&a(pa),T(Be,e),e&&a(fa),e&&a(so),e&&a(_a),Se[K].d(e),e&&a(io),e&&a(ae),T(Ae),e&&a(ha),e&&a(no),e&&a(va),T(Te,e),e&&a(ba),e&&a(lo)}}}const bs={local:"modelos",sections:[{local:"criando-um-transformer",sections:[{local:"diferentes-mtodos-de-inicializar-o-modelo",title:"Diferentes m\xE9todos de inicializar o modelo"},{local:"mtodos-para-salvararmazenar-o-modelo",title:"M\xE9todos para salvar/armazenar o modelo"}],title:"Criando um Transformer"},{local:"usando-um-modelo-de-transformer-para-inferncia",sections:[{local:"usando-os-tensores-como-entradas-para-o-modelo",title:"Usando os tensores como entradas para o modelo"}],title:"Usando um modelo de Transformer para infer\xEAncia"}],title:"Modelos"};function $s(g,r,l){let o="pt";return Wt(()=>{const f=new URLSearchParams(window.location.search);l(0,o=f.get("fw")||"pt")}),[o]}class ys extends Lt{constructor(r){super();Yt(this,r,$s,vs,Kt,{})}}export{ys as default,bs as metadata};
