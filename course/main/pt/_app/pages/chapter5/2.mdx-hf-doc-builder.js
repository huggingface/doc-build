import{S as un,i as cn,s as pn,e as r,k as m,w as _,t,M as fn,c as n,d as o,m as u,a as d,x as v,h as s,b as c,G as a,g as l,y as h,q as g,o as q,B as $,v as _n}from"../../chunks/vendor-hf-doc-builder.js";import{T as Zs}from"../../chunks/Tip-hf-doc-builder.js";import{Y as vn}from"../../chunks/Youtube-hf-doc-builder.js";import{I as Zo}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as y}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as hn}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";function gn(ee){let p,E,f,b,z;return{c(){p=r("p"),E=t("\u270E Se voc\xEA est\xE1 se perguntando por que h\xE1 um "),f=r("code"),b=t("!"),z=t(" nos comandos shell acima, \xE9 porque estamos executando-os dentro de um Jupyter notebook. Basta remover o prefixo se voc\xEA quiser baixar e descompactar o conjunto de dados dentro de um terminal.")},l(j){p=n(j,"P",{});var x=d(p);E=s(x,"\u270E Se voc\xEA est\xE1 se perguntando por que h\xE1 um "),f=n(x,"CODE",{});var C=d(f);b=s(C,"!"),C.forEach(o),z=s(x," nos comandos shell acima, \xE9 porque estamos executando-os dentro de um Jupyter notebook. Basta remover o prefixo se voc\xEA quiser baixar e descompactar o conjunto de dados dentro de um terminal."),x.forEach(o)},m(j,x){l(j,p,x),a(p,E),a(p,f),a(f,b),a(p,z)},d(j){j&&o(p)}}}function qn(ee){let p,E,f,b,z,j,x,C,V,ae,N,P,w,ve;return{c(){p=r("p"),E=t("O argumento "),f=r("code"),b=t("data_files"),z=t(" da fun\xE7\xE3o "),j=r("code"),x=t("load_dataset()"),C=t(" \xE9 bastante flex\xEDvel e pode ser um \xFAnico caminho de arquivo ou uma lista de caminhos de arquivo, ou um dicion\xE1rio que mapeia nomes divididos para caminhos de arquivo. Voc\xEA tamb\xE9m pode incluir arquivos que correspondam a um padr\xE3o especificado de acordo com as regras utilizadas pela Unix shell (por exemplo, voc\xEA pode adicionar todos os arquivos JSON em um diret\xF3rio como uma \xFAnica divis\xE3o, definindo "),V=r("code"),ae=t('data_files="*.json"'),N=t("). Consulte a "),P=r("a"),w=t("documenta\xE7\xE3o"),ve=t(" do \u{1F917} Datasets para obter mais detalhes."),this.h()},l(O){p=n(O,"P",{});var D=d(p);E=s(D,"O argumento "),f=n(D,"CODE",{});var Te=d(f);b=s(Te,"data_files"),Te.forEach(o),z=s(D," da fun\xE7\xE3o "),j=n(D,"CODE",{});var oe=d(j);x=s(oe,"load_dataset()"),oe.forEach(o),C=s(D," \xE9 bastante flex\xEDvel e pode ser um \xFAnico caminho de arquivo ou uma lista de caminhos de arquivo, ou um dicion\xE1rio que mapeia nomes divididos para caminhos de arquivo. Voc\xEA tamb\xE9m pode incluir arquivos que correspondam a um padr\xE3o especificado de acordo com as regras utilizadas pela Unix shell (por exemplo, voc\xEA pode adicionar todos os arquivos JSON em um diret\xF3rio como uma \xFAnica divis\xE3o, definindo "),V=n(D,"CODE",{});var ye=d(V);ae=s(ye,'data_files="*.json"'),ye.forEach(o),N=s(D,"). Consulte a "),P=n(D,"A",{href:!0,rel:!0});var Ne=d(P);w=s(Ne,"documenta\xE7\xE3o"),Ne.forEach(o),ve=s(D," do \u{1F917} Datasets para obter mais detalhes."),D.forEach(o),this.h()},h(){c(P,"href","https://huggingface.co/docs/datasets/loading.html#local-and-remote-files"),c(P,"rel","nofollow")},m(O,D){l(O,p,D),a(p,E),a(p,f),a(f,b),a(p,z),a(p,j),a(j,x),a(p,C),a(p,V),a(V,ae),a(p,N),a(p,P),a(P,w),a(p,ve)},d(O){O&&o(p)}}}function $n(ee){let p;return{c(){p=t("\u270F\uFE0F **Tente fazer isso!** Escolha outro conjunto de dados hospedado no GitHub ou no [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php) e tente carreg\xE1-lo tanto local como remotamente usando as t\xE9cnicas introduzidas acima. Para pontos b\xF4nus, tente carregar um conjunto de dados que esteja armazenado em formato CSV ou texto (veja a [documenta\xE7\xE3o](https://huggingface.co/docs/datasets/loading.html#local-and-remote-files) para mais informa\xE7\xF5es sobre estes formatos).")},l(E){p=s(E,"\u270F\uFE0F **Tente fazer isso!** Escolha outro conjunto de dados hospedado no GitHub ou no [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php) e tente carreg\xE1-lo tanto local como remotamente usando as t\xE9cnicas introduzidas acima. Para pontos b\xF4nus, tente carregar um conjunto de dados que esteja armazenado em formato CSV ou texto (veja a [documenta\xE7\xE3o](https://huggingface.co/docs/datasets/loading.html#local-and-remote-files) para mais informa\xE7\xF5es sobre estes formatos).")},m(E,f){l(E,p,f)},d(E){E&&o(p)}}}function jn(ee){let p,E,f,b,z,j,x,C,V,ae,N,P,w,ve,O,D,Te,oe,ye,Ne,so,he,ro,G,te,fa,ge,Yo,_a,Ko,no,He,Wo,io,se,va,U,Ie,Xo,et,Je,at,ot,Re,tt,st,H,B,Le,rt,nt,Me,ha,dt,it,Fe,ga,lt,mt,Z,Ve,ut,ct,Ge,qa,pt,ft,Ue,$a,_t,vt,Y,Be,ht,gt,Ze,ja,qt,$t,Ye,Ea,jt,Et,K,Ke,bt,Dt,We,ba,St,xt,Xe,Da,wt,lo,I,At,Sa,zt,Ot,xa,Ct,Pt,mo,W,re,wa,qe,Qt,Aa,kt,uo,ne,Tt,$e,yt,Nt,co,de,Ht,za,It,Jt,po,je,fo,Q,Rt,Oa,Lt,Mt,Ca,Ft,Vt,Pa,Gt,Ut,_o,Ee,vo,be,ho,J,Bt,Qa,Zt,Yt,ka,Kt,Wt,go,ie,qo,k,Xt,Ta,es,as,ya,os,ts,Na,ss,rs,$o,De,jo,R,ns,Ha,ds,is,Ia,ls,ms,Eo,Se,bo,xe,Do,ea,us,So,we,xo,Ae,wo,S,cs,Ja,ps,fs,Ra,_s,vs,La,hs,gs,Ma,qs,$s,Fa,js,Es,Ao,ze,zo,Oe,Oo,aa,bs,Co,le,Po,L,Ds,Va,Ss,xs,Ga,ws,As,Qo,Ce,ko,me,zs,Ua,Os,Cs,To,oa,Ps,yo,X,ue,Ba,Pe,Qs,Za,ks,No,A,Ts,Ya,ys,Ns,Ka,Hs,Is,Wa,Js,Rs,Xa,Ls,Ms,Ho,Qe,Io,M,Fs,eo,Vs,Gs,ao,Us,Bs,Jo,ce,Ro;return j=new Zo({}),N=new hn({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter5/section2.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter5/section2.ipynb"}]}}),he=new vn({props:{id:"HyQgpJTkRdE"}}),ge=new Zo({}),qe=new Zo({}),je=new y({props:{code:`!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-train.json.gz
!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-test.json.gz`,highlighted:`!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-train.json.gz
!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-test.json.gz`}}),Ee=new y({props:{code:"!gzip -dkv SQuAD_it-*.json.gz",highlighted:"!gzip -dkv SQuAD_it-*.json.gz"}}),be=new y({props:{code:`SQuAD_it-test.json.gz:	   87.4% -- replaced with SQuAD_it-test.json
SQuAD_it-train.json.gz:	   82.2% -- replaced with SQuAD_it-train.json`,highlighted:`SQuAD_it-test.json.gz:	   87.4% -- replaced with SQuAD_it-test.json
SQuAD_it-train.json.gz:	   82.2% -- replaced with SQuAD_it-train.json`}}),ie=new Zs({props:{$$slots:{default:[gn]},$$scope:{ctx:ee}}}),De=new y({props:{code:`from datasets import load_dataset

squad_it_dataset = load_dataset("json", data_files="SQuAD_it-train.json", field="data")`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

squad_it_dataset = load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=<span class="hljs-string">&quot;SQuAD_it-train.json&quot;</span>, field=<span class="hljs-string">&quot;data&quot;</span>)`}}),Se=new y({props:{code:"squad_it_dataset",highlighted:"squad_it_dataset"}}),xe=new y({props:{code:`DatasetDict({
    train: Dataset({
        features: ['title', 'paragraphs'],
        num_rows: 442
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;paragraphs&#x27;</span>],
        num_rows: <span class="hljs-number">442</span>
    })
})`}}),we=new y({props:{code:'squad_it_dataset["train"][0]',highlighted:'squad_it_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]'}}),Ae=new y({props:{code:`{
    "title": "Terremoto del Sichuan del 2008",
    "paragraphs": [
        {
            "context": "Il terremoto del Sichuan del 2008 o il terremoto...",
            "qas": [
                {
                    "answers": [{"answer_start": 29, "text": "2008"}],
                    "id": "56cdca7862d2951400fa6826",
                    "question": "In quale anno si \xE8 verificato il terremoto nel Sichuan?",
                },
                ...
            ],
        },
        ...
    ],
}`,highlighted:`{
    <span class="hljs-string">&quot;title&quot;</span>: <span class="hljs-string">&quot;Terremoto del Sichuan del 2008&quot;</span>,
    <span class="hljs-string">&quot;paragraphs&quot;</span>: [
        {
            <span class="hljs-string">&quot;context&quot;</span>: <span class="hljs-string">&quot;Il terremoto del Sichuan del 2008 o il terremoto...&quot;</span>,
            <span class="hljs-string">&quot;qas&quot;</span>: [
                {
                    <span class="hljs-string">&quot;answers&quot;</span>: [{<span class="hljs-string">&quot;answer_start&quot;</span>: <span class="hljs-number">29</span>, <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;2008&quot;</span>}],
                    <span class="hljs-string">&quot;id&quot;</span>: <span class="hljs-string">&quot;56cdca7862d2951400fa6826&quot;</span>,
                    <span class="hljs-string">&quot;question&quot;</span>: <span class="hljs-string">&quot;In quale anno si \xE8 verificato il terremoto nel Sichuan?&quot;</span>,
                },
                ...
            ],
        },
        ...
    ],
}`}}),ze=new y({props:{code:`data_files = {"train": "SQuAD_it-train.json", "test": "SQuAD_it-test.json"}
squad_it_dataset = load_dataset("json", data_files=data_files, field="data")
squad_it_dataset`,highlighted:`data_files = {<span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;SQuAD_it-train.json&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;SQuAD_it-test.json&quot;</span>}
squad_it_dataset = load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=data_files, field=<span class="hljs-string">&quot;data&quot;</span>)
squad_it_dataset`}}),Oe=new y({props:{code:`DatasetDict({
    train: Dataset({
        features: ['title', 'paragraphs'],
        num_rows: 442
    })
    test: Dataset({
        features: ['title', 'paragraphs'],
        num_rows: 48
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;paragraphs&#x27;</span>],
        num_rows: <span class="hljs-number">442</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;paragraphs&#x27;</span>],
        num_rows: <span class="hljs-number">48</span>
    })
})`}}),le=new Zs({props:{$$slots:{default:[qn]},$$scope:{ctx:ee}}}),Ce=new y({props:{code:`data_files = {"train": "SQuAD_it-train.json.gz", "test": "SQuAD_it-test.json.gz"}
squad_it_dataset = load_dataset("json", data_files=data_files, field="data")`,highlighted:`data_files = {<span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;SQuAD_it-train.json.gz&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;SQuAD_it-test.json.gz&quot;</span>}
squad_it_dataset = load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=data_files, field=<span class="hljs-string">&quot;data&quot;</span>)`}}),Pe=new Zo({}),Qe=new y({props:{code:`url = "https://github.com/crux82/squad-it/raw/master/"
data_files = {
    "train": url + "SQuAD_it-train.json.gz",
    "test": url + "SQuAD_it-test.json.gz",
}
squad_it_dataset = load_dataset("json", data_files=data_files, field="data")`,highlighted:`url = <span class="hljs-string">&quot;https://github.com/crux82/squad-it/raw/master/&quot;</span>
data_files = {
    <span class="hljs-string">&quot;train&quot;</span>: url + <span class="hljs-string">&quot;SQuAD_it-train.json.gz&quot;</span>,
    <span class="hljs-string">&quot;test&quot;</span>: url + <span class="hljs-string">&quot;SQuAD_it-test.json.gz&quot;</span>,
}
squad_it_dataset = load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=data_files, field=<span class="hljs-string">&quot;data&quot;</span>)`}}),ce=new Zs({props:{$$slots:{default:[$n]},$$scope:{ctx:ee}}}),{c(){p=r("meta"),E=m(),f=r("h1"),b=r("a"),z=r("span"),_(j.$$.fragment),x=m(),C=r("span"),V=t("E se o meu dataset n\xE3o estiver no Hub?"),ae=m(),_(N.$$.fragment),P=m(),w=r("p"),ve=t("Voc\xEA sabe como usar o "),O=r("a"),D=t("Hugging Face Hub"),Te=t(" para baixar conjuntos de dados ("),oe=r("strong"),ye=t("datasets"),Ne=t("), mas muitas vezes voc\xEA se encontrar\xE1 trabalhando com dados que s\xE3o armazenados em seu laptop ou em um servidor remoto. Nesta se\xE7\xE3o mostraremos como \u{1F917} Datasets podem ser usados para carregar conjuntos de dados que n\xE3o est\xE3o dispon\xEDveis no Hugging Face Hub."),so=m(),_(he.$$.fragment),ro=m(),G=r("h2"),te=r("a"),fa=r("span"),_(ge.$$.fragment),Yo=m(),_a=r("span"),Ko=t("Trabalhando com datasets locais e remotos"),no=m(),He=r("p"),Wo=t("\u{1F917} Datasets fornece scripts de carregamento para lidar com o carregamento de conjuntos de dados locais e remotos. Ele suporta v\xE1rios formatos de dados comuns, como por exemplo:"),io=m(),se=r("table"),va=r("thead"),U=r("tr"),Ie=r("th"),Xo=t("Formato do dato"),et=m(),Je=r("th"),at=t("script de carregamento"),ot=m(),Re=r("th"),tt=t("Exemplo"),st=m(),H=r("tbody"),B=r("tr"),Le=r("td"),rt=t("CSV & TSV"),nt=m(),Me=r("td"),ha=r("code"),dt=t("csv"),it=m(),Fe=r("td"),ga=r("code"),lt=t('load_dataset("csv", data_files="my_file.csv")'),mt=m(),Z=r("tr"),Ve=r("td"),ut=t("Text files"),ct=m(),Ge=r("td"),qa=r("code"),pt=t("text"),ft=m(),Ue=r("td"),$a=r("code"),_t=t('load_dataset("text", data_files="my_file.txt")'),vt=m(),Y=r("tr"),Be=r("td"),ht=t("JSON & JSON Lines"),gt=m(),Ze=r("td"),ja=r("code"),qt=t("json"),$t=m(),Ye=r("td"),Ea=r("code"),jt=t('load_dataset("json", data_files="my_file.jsonl")'),Et=m(),K=r("tr"),Ke=r("td"),bt=t("Pickled DataFrames"),Dt=m(),We=r("td"),ba=r("code"),St=t("pandas"),xt=m(),Xe=r("td"),Da=r("code"),wt=t('load_dataset("pandas", data_files="my_dataframe.pkl")'),lo=m(),I=r("p"),At=t("Como mostrado na tabela, para cada formato de dados s\xF3 precisamos especificar o tipo de script de carregamento na fun\xE7\xE3o "),Sa=r("code"),zt=t("load_dataset()"),Ot=t(", junto com um argumento "),xa=r("code"),Ct=t("data_files"),Pt=t(" que especifica o caminho para um ou mais arquivos. Vamos come\xE7ar carregando um conjunto de dados de arquivos locais; mais tarde veremos como fazer o mesmo com arquivos remotos."),mo=m(),W=r("h2"),re=r("a"),wa=r("span"),_(qe.$$.fragment),Qt=m(),Aa=r("span"),kt=t("Carregando um conjunto de dados local"),uo=m(),ne=r("p"),Tt=t("Para este exemplo usaremos o [SQuAD-it dataset] ("),$e=r("a"),yt=t("https://github.com/crux82/squad-it/"),Nt=t("), que \xE9 um conjunto de dados em grande escala para resposta a perguntas em italiano."),co=m(),de=r("p"),Ht=t("As divis\xF5es de treinamento e testes s\xE3o hospedadas no GitHub, para que possamos baix\xE1-las com um simples comando "),za=r("code"),It=t("wget"),Jt=t(":"),po=m(),_(je.$$.fragment),fo=m(),Q=r("p"),Rt=t("Isto ir\xE1 baixar dois arquivos compactados chamados "),Oa=r("em"),Lt=t("SQuAD_it-train.json.gz"),Mt=t(" e "),Ca=r("em"),Ft=t("SQuAD_it-test.json.gz"),Vt=t(", que podemos descomprimir com o comando Linux "),Pa=r("code"),Gt=t("gzip"),Ut=t(":"),_o=m(),_(Ee.$$.fragment),vo=m(),_(be.$$.fragment),ho=m(),J=r("p"),Bt=t("Podemos ver que os arquivos compactados foram substitu\xEDdos por "),Qa=r("em"),Zt=t("SQuAD_it-train.json"),Yt=t(" e "),ka=r("em"),Kt=t("SQuAD_it-text.json"),Wt=t(", e que os dados s\xE3o armazenados no formato JSON."),go=m(),_(ie.$$.fragment),qo=m(),k=r("p"),Xt=t("Para carregar um arquivo JSON com a fun\xE7\xE3o "),Ta=r("code"),es=t("load_dataset()"),as=t(", s\xF3 precisamos saber se estamos lidando com o JSON comum (semelhante a um dicion\xE1rio aninhado) ou Linhas JSON (JSON line-separated JSON). Como muitos conjuntos de dados que respondem a perguntas, o SQuAD utiliza o formato aninhado, com todo o texto armazenado em um campo "),ya=r("code"),os=t("data"),ts=t(". Isto significa que podemos carregar o conjunto de dados especificando o argumento  "),Na=r("code"),ss=t("field"),rs=t(" da seguinte forma:"),$o=m(),_(De.$$.fragment),jo=m(),R=r("p"),ns=t("Por padr\xE3o, o carregamento de arquivos locais cria um objeto "),Ha=r("code"),ds=t("DatasetDict"),is=t(" com uma divis\xE3o de treino (train). Podemos ver isso inspecionando o objeto "),Ia=r("code"),ls=t("squad_it_dataset"),ms=t(":"),Eo=m(),_(Se.$$.fragment),bo=m(),_(xe.$$.fragment),Do=m(),ea=r("p"),us=t("Isto nos mostra o n\xFAmero de linhas e os nomes das colunas associadas ao conjunto de treinamento. Podemos ver um dos exemplos, indexando na divis\xE3o de treino da seguinte forma:"),So=m(),_(we.$$.fragment),xo=m(),_(Ae.$$.fragment),wo=m(),S=r("p"),cs=t("\xD3timo, n\xF3s carregamos nosso primeiro conjunto de dados local! Mas enquanto isso funcionou para o conjunto de treinamento, o que realmente queremos \xE9 incluir tanto o conjunto de "),Ja=r("code"),ps=t("treino"),fs=t(" quanto o de "),Ra=r("code"),_s=t("teste"),vs=t(" divididos em um \xFAnico objeto "),La=r("code"),hs=t("DatasetDict"),gs=t(" para que possamos aplicar as fun\xE7\xF5es "),Ma=r("code"),qs=t("Dataset.map()"),$s=t(" em ambas as divis\xF5es de uma s\xF3 vez. Para fazer isso, podemos fornecer um dicion\xE1rio para o argumento "),Fa=r("code"),js=t("data_files"),Es=t(" que mapeia cada nome de divis\xE3o para um arquivo associado a essa divis\xE3o:"),Ao=m(),_(ze.$$.fragment),zo=m(),_(Oe.$$.fragment),Oo=m(),aa=r("p"),bs=t("Isto \xE9 exatamente o que quer\xEDamos. Agora, podemos aplicar v\xE1rias t\xE9cnicas de pr\xE9-processamento para limpar os dados, assinalar as revis\xF5es, e assim por diante."),Co=m(),_(le.$$.fragment),Po=m(),L=r("p"),Ds=t("Os scripts de carregamento em \u{1F917} Datasets realmente suportam a descompress\xE3o autom\xE1tica dos arquivos de entrada, ent\xE3o poder\xEDamos ter pulado o uso do "),Va=r("code"),Ss=t("gzip"),xs=t(" ao apontar o argumento "),Ga=r("code"),ws=t("data_files"),As=t(" diretamente para os arquivos compactados:"),Qo=m(),_(Ce.$$.fragment),ko=m(),me=r("p"),zs=t("Isto pode ser \xFAtil se voc\xEA n\xE3o quiser descomprimir manualmente muitos arquivos GZIP. A descompress\xE3o autom\xE1tica tamb\xE9m se aplica a outros formatos comuns como ZIP e TAR, ent\xE3o voc\xEA s\xF3 precisa apontar "),Ua=r("code"),Os=t("data_files"),Cs=t(" para os arquivos compactados e est\xE1 pronto para seguir em frente!"),To=m(),oa=r("p"),Ps=t("Agora que voc\xEA sabe como carregar arquivos locais em seu laptop ou desktop, vamos dar uma olhada no carregamento de arquivos remotos."),yo=m(),X=r("h2"),ue=r("a"),Ba=r("span"),_(Pe.$$.fragment),Qs=m(),Za=r("span"),ks=t("Carregando um dataset remoto"),No=m(),A=r("p"),Ts=t("Se voc\xEA estiver trabalhando como cientista de dados ou programador em uma empresa, h\xE1 uma boa chance de que os conjuntos de dados que voc\xEA deseja analisar estejam armazenados em algum servidor remoto. Felizmente, o carregamento de arquivos remotos \xE9 t\xE3o simples quanto o carregamento de arquivos locais! Em vez de fornecer um caminho para arquivos locais, apontamos o argumento "),Ya=r("code"),ys=t("data_files"),Ns=t(" de "),Ka=r("code"),Hs=t("load_dataset()"),Is=t(" para uma ou mais URLs onde os arquivos remotos s\xE3o armazenados. Por exemplo, para o conjunto de dados SQuAD-it hospedado no GitHub, podemos apenas apontar "),Wa=r("code"),Js=t("data_files"),Rs=t(" para as URLs "),Xa=r("em"),Ls=t("SQuAD_it-*.json.gz"),Ms=t(" da seguinte maneira:"),Ho=m(),_(Qe.$$.fragment),Io=m(),M=r("p"),Fs=t("Isto retorna o mesmo objeto "),eo=r("code"),Vs=t("DatasetDict"),Gs=t(" obtido anteriormente, mas nos poupa o passo de baixar e descomprimir manualmente os arquivos "),ao=r("em"),Us=t("SQuAD_it-*.json.gz"),Bs=t(". Isto envolve nas v\xE1rias formas de carregar conjuntos de dados que n\xE3o est\xE3o hospedados no Hugging Face Hub. Agora que temos um conjunto de dados para brincar, vamos sujar as m\xE3os com v\xE1rias t\xE9cnicas de manipula\xE7\xE3o de dados!"),Jo=m(),_(ce.$$.fragment),this.h()},l(e){const i=fn('[data-svelte="svelte-1phssyn"]',document.head);p=n(i,"META",{name:!0,content:!0}),i.forEach(o),E=u(e),f=n(e,"H1",{class:!0});var ke=d(f);b=n(ke,"A",{id:!0,class:!0,href:!0});var oo=d(b);z=n(oo,"SPAN",{});var to=d(z);v(j.$$.fragment,to),to.forEach(o),oo.forEach(o),x=u(ke),C=n(ke,"SPAN",{});var Ys=d(C);V=s(Ys,"E se o meu dataset n\xE3o estiver no Hub?"),Ys.forEach(o),ke.forEach(o),ae=u(e),v(N.$$.fragment,e),P=u(e),w=n(e,"P",{});var ta=d(w);ve=s(ta,"Voc\xEA sabe como usar o "),O=n(ta,"A",{href:!0,rel:!0});var Ks=d(O);D=s(Ks,"Hugging Face Hub"),Ks.forEach(o),Te=s(ta," para baixar conjuntos de dados ("),oe=n(ta,"STRONG",{});var Ws=d(oe);ye=s(Ws,"datasets"),Ws.forEach(o),Ne=s(ta,"), mas muitas vezes voc\xEA se encontrar\xE1 trabalhando com dados que s\xE3o armazenados em seu laptop ou em um servidor remoto. Nesta se\xE7\xE3o mostraremos como \u{1F917} Datasets podem ser usados para carregar conjuntos de dados que n\xE3o est\xE3o dispon\xEDveis no Hugging Face Hub."),ta.forEach(o),so=u(e),v(he.$$.fragment,e),ro=u(e),G=n(e,"H2",{class:!0});var Lo=d(G);te=n(Lo,"A",{id:!0,class:!0,href:!0});var Xs=d(te);fa=n(Xs,"SPAN",{});var er=d(fa);v(ge.$$.fragment,er),er.forEach(o),Xs.forEach(o),Yo=u(Lo),_a=n(Lo,"SPAN",{});var ar=d(_a);Ko=s(ar,"Trabalhando com datasets locais e remotos"),ar.forEach(o),Lo.forEach(o),no=u(e),He=n(e,"P",{});var or=d(He);Wo=s(or,"\u{1F917} Datasets fornece scripts de carregamento para lidar com o carregamento de conjuntos de dados locais e remotos. Ele suporta v\xE1rios formatos de dados comuns, como por exemplo:"),or.forEach(o),io=u(e),se=n(e,"TABLE",{});var Mo=d(se);va=n(Mo,"THEAD",{});var tr=d(va);U=n(tr,"TR",{});var sa=d(U);Ie=n(sa,"TH",{align:!0});var sr=d(Ie);Xo=s(sr,"Formato do dato"),sr.forEach(o),et=u(sa),Je=n(sa,"TH",{align:!0});var rr=d(Je);at=s(rr,"script de carregamento"),rr.forEach(o),ot=u(sa),Re=n(sa,"TH",{align:!0});var nr=d(Re);tt=s(nr,"Exemplo"),nr.forEach(o),sa.forEach(o),tr.forEach(o),st=u(Mo),H=n(Mo,"TBODY",{});var pe=d(H);B=n(pe,"TR",{});var ra=d(B);Le=n(ra,"TD",{align:!0});var dr=d(Le);rt=s(dr,"CSV & TSV"),dr.forEach(o),nt=u(ra),Me=n(ra,"TD",{align:!0});var ir=d(Me);ha=n(ir,"CODE",{});var lr=d(ha);dt=s(lr,"csv"),lr.forEach(o),ir.forEach(o),it=u(ra),Fe=n(ra,"TD",{align:!0});var mr=d(Fe);ga=n(mr,"CODE",{});var ur=d(ga);lt=s(ur,'load_dataset("csv", data_files="my_file.csv")'),ur.forEach(o),mr.forEach(o),ra.forEach(o),mt=u(pe),Z=n(pe,"TR",{});var na=d(Z);Ve=n(na,"TD",{align:!0});var cr=d(Ve);ut=s(cr,"Text files"),cr.forEach(o),ct=u(na),Ge=n(na,"TD",{align:!0});var pr=d(Ge);qa=n(pr,"CODE",{});var fr=d(qa);pt=s(fr,"text"),fr.forEach(o),pr.forEach(o),ft=u(na),Ue=n(na,"TD",{align:!0});var _r=d(Ue);$a=n(_r,"CODE",{});var vr=d($a);_t=s(vr,'load_dataset("text", data_files="my_file.txt")'),vr.forEach(o),_r.forEach(o),na.forEach(o),vt=u(pe),Y=n(pe,"TR",{});var da=d(Y);Be=n(da,"TD",{align:!0});var hr=d(Be);ht=s(hr,"JSON & JSON Lines"),hr.forEach(o),gt=u(da),Ze=n(da,"TD",{align:!0});var gr=d(Ze);ja=n(gr,"CODE",{});var qr=d(ja);qt=s(qr,"json"),qr.forEach(o),gr.forEach(o),$t=u(da),Ye=n(da,"TD",{align:!0});var $r=d(Ye);Ea=n($r,"CODE",{});var jr=d(Ea);jt=s(jr,'load_dataset("json", data_files="my_file.jsonl")'),jr.forEach(o),$r.forEach(o),da.forEach(o),Et=u(pe),K=n(pe,"TR",{});var ia=d(K);Ke=n(ia,"TD",{align:!0});var Er=d(Ke);bt=s(Er,"Pickled DataFrames"),Er.forEach(o),Dt=u(ia),We=n(ia,"TD",{align:!0});var br=d(We);ba=n(br,"CODE",{});var Dr=d(ba);St=s(Dr,"pandas"),Dr.forEach(o),br.forEach(o),xt=u(ia),Xe=n(ia,"TD",{align:!0});var Sr=d(Xe);Da=n(Sr,"CODE",{});var xr=d(Da);wt=s(xr,'load_dataset("pandas", data_files="my_dataframe.pkl")'),xr.forEach(o),Sr.forEach(o),ia.forEach(o),pe.forEach(o),Mo.forEach(o),lo=u(e),I=n(e,"P",{});var la=d(I);At=s(la,"Como mostrado na tabela, para cada formato de dados s\xF3 precisamos especificar o tipo de script de carregamento na fun\xE7\xE3o "),Sa=n(la,"CODE",{});var wr=d(Sa);zt=s(wr,"load_dataset()"),wr.forEach(o),Ot=s(la,", junto com um argumento "),xa=n(la,"CODE",{});var Ar=d(xa);Ct=s(Ar,"data_files"),Ar.forEach(o),Pt=s(la," que especifica o caminho para um ou mais arquivos. Vamos come\xE7ar carregando um conjunto de dados de arquivos locais; mais tarde veremos como fazer o mesmo com arquivos remotos."),la.forEach(o),mo=u(e),W=n(e,"H2",{class:!0});var Fo=d(W);re=n(Fo,"A",{id:!0,class:!0,href:!0});var zr=d(re);wa=n(zr,"SPAN",{});var Or=d(wa);v(qe.$$.fragment,Or),Or.forEach(o),zr.forEach(o),Qt=u(Fo),Aa=n(Fo,"SPAN",{});var Cr=d(Aa);kt=s(Cr,"Carregando um conjunto de dados local"),Cr.forEach(o),Fo.forEach(o),uo=u(e),ne=n(e,"P",{});var Vo=d(ne);Tt=s(Vo,"Para este exemplo usaremos o [SQuAD-it dataset] ("),$e=n(Vo,"A",{href:!0,rel:!0});var Pr=d($e);yt=s(Pr,"https://github.com/crux82/squad-it/"),Pr.forEach(o),Nt=s(Vo,"), que \xE9 um conjunto de dados em grande escala para resposta a perguntas em italiano."),Vo.forEach(o),co=u(e),de=n(e,"P",{});var Go=d(de);Ht=s(Go,"As divis\xF5es de treinamento e testes s\xE3o hospedadas no GitHub, para que possamos baix\xE1-las com um simples comando "),za=n(Go,"CODE",{});var Qr=d(za);It=s(Qr,"wget"),Qr.forEach(o),Jt=s(Go,":"),Go.forEach(o),po=u(e),v(je.$$.fragment,e),fo=u(e),Q=n(e,"P",{});var fe=d(Q);Rt=s(fe,"Isto ir\xE1 baixar dois arquivos compactados chamados "),Oa=n(fe,"EM",{});var kr=d(Oa);Lt=s(kr,"SQuAD_it-train.json.gz"),kr.forEach(o),Mt=s(fe," e "),Ca=n(fe,"EM",{});var Tr=d(Ca);Ft=s(Tr,"SQuAD_it-test.json.gz"),Tr.forEach(o),Vt=s(fe,", que podemos descomprimir com o comando Linux "),Pa=n(fe,"CODE",{});var yr=d(Pa);Gt=s(yr,"gzip"),yr.forEach(o),Ut=s(fe,":"),fe.forEach(o),_o=u(e),v(Ee.$$.fragment,e),vo=u(e),v(be.$$.fragment,e),ho=u(e),J=n(e,"P",{});var ma=d(J);Bt=s(ma,"Podemos ver que os arquivos compactados foram substitu\xEDdos por "),Qa=n(ma,"EM",{});var Nr=d(Qa);Zt=s(Nr,"SQuAD_it-train.json"),Nr.forEach(o),Yt=s(ma," e "),ka=n(ma,"EM",{});var Hr=d(ka);Kt=s(Hr,"SQuAD_it-text.json"),Hr.forEach(o),Wt=s(ma,", e que os dados s\xE3o armazenados no formato JSON."),ma.forEach(o),go=u(e),v(ie.$$.fragment,e),qo=u(e),k=n(e,"P",{});var _e=d(k);Xt=s(_e,"Para carregar um arquivo JSON com a fun\xE7\xE3o "),Ta=n(_e,"CODE",{});var Ir=d(Ta);es=s(Ir,"load_dataset()"),Ir.forEach(o),as=s(_e,", s\xF3 precisamos saber se estamos lidando com o JSON comum (semelhante a um dicion\xE1rio aninhado) ou Linhas JSON (JSON line-separated JSON). Como muitos conjuntos de dados que respondem a perguntas, o SQuAD utiliza o formato aninhado, com todo o texto armazenado em um campo "),ya=n(_e,"CODE",{});var Jr=d(ya);os=s(Jr,"data"),Jr.forEach(o),ts=s(_e,". Isto significa que podemos carregar o conjunto de dados especificando o argumento  "),Na=n(_e,"CODE",{});var Rr=d(Na);ss=s(Rr,"field"),Rr.forEach(o),rs=s(_e," da seguinte forma:"),_e.forEach(o),$o=u(e),v(De.$$.fragment,e),jo=u(e),R=n(e,"P",{});var ua=d(R);ns=s(ua,"Por padr\xE3o, o carregamento de arquivos locais cria um objeto "),Ha=n(ua,"CODE",{});var Lr=d(Ha);ds=s(Lr,"DatasetDict"),Lr.forEach(o),is=s(ua," com uma divis\xE3o de treino (train). Podemos ver isso inspecionando o objeto "),Ia=n(ua,"CODE",{});var Mr=d(Ia);ls=s(Mr,"squad_it_dataset"),Mr.forEach(o),ms=s(ua,":"),ua.forEach(o),Eo=u(e),v(Se.$$.fragment,e),bo=u(e),v(xe.$$.fragment,e),Do=u(e),ea=n(e,"P",{});var Fr=d(ea);us=s(Fr,"Isto nos mostra o n\xFAmero de linhas e os nomes das colunas associadas ao conjunto de treinamento. Podemos ver um dos exemplos, indexando na divis\xE3o de treino da seguinte forma:"),Fr.forEach(o),So=u(e),v(we.$$.fragment,e),xo=u(e),v(Ae.$$.fragment,e),wo=u(e),S=n(e,"P",{});var T=d(S);cs=s(T,"\xD3timo, n\xF3s carregamos nosso primeiro conjunto de dados local! Mas enquanto isso funcionou para o conjunto de treinamento, o que realmente queremos \xE9 incluir tanto o conjunto de "),Ja=n(T,"CODE",{});var Vr=d(Ja);ps=s(Vr,"treino"),Vr.forEach(o),fs=s(T," quanto o de "),Ra=n(T,"CODE",{});var Gr=d(Ra);_s=s(Gr,"teste"),Gr.forEach(o),vs=s(T," divididos em um \xFAnico objeto "),La=n(T,"CODE",{});var Ur=d(La);hs=s(Ur,"DatasetDict"),Ur.forEach(o),gs=s(T," para que possamos aplicar as fun\xE7\xF5es "),Ma=n(T,"CODE",{});var Br=d(Ma);qs=s(Br,"Dataset.map()"),Br.forEach(o),$s=s(T," em ambas as divis\xF5es de uma s\xF3 vez. Para fazer isso, podemos fornecer um dicion\xE1rio para o argumento "),Fa=n(T,"CODE",{});var Zr=d(Fa);js=s(Zr,"data_files"),Zr.forEach(o),Es=s(T," que mapeia cada nome de divis\xE3o para um arquivo associado a essa divis\xE3o:"),T.forEach(o),Ao=u(e),v(ze.$$.fragment,e),zo=u(e),v(Oe.$$.fragment,e),Oo=u(e),aa=n(e,"P",{});var Yr=d(aa);bs=s(Yr,"Isto \xE9 exatamente o que quer\xEDamos. Agora, podemos aplicar v\xE1rias t\xE9cnicas de pr\xE9-processamento para limpar os dados, assinalar as revis\xF5es, e assim por diante."),Yr.forEach(o),Co=u(e),v(le.$$.fragment,e),Po=u(e),L=n(e,"P",{});var ca=d(L);Ds=s(ca,"Os scripts de carregamento em \u{1F917} Datasets realmente suportam a descompress\xE3o autom\xE1tica dos arquivos de entrada, ent\xE3o poder\xEDamos ter pulado o uso do "),Va=n(ca,"CODE",{});var Kr=d(Va);Ss=s(Kr,"gzip"),Kr.forEach(o),xs=s(ca," ao apontar o argumento "),Ga=n(ca,"CODE",{});var Wr=d(Ga);ws=s(Wr,"data_files"),Wr.forEach(o),As=s(ca," diretamente para os arquivos compactados:"),ca.forEach(o),Qo=u(e),v(Ce.$$.fragment,e),ko=u(e),me=n(e,"P",{});var Uo=d(me);zs=s(Uo,"Isto pode ser \xFAtil se voc\xEA n\xE3o quiser descomprimir manualmente muitos arquivos GZIP. A descompress\xE3o autom\xE1tica tamb\xE9m se aplica a outros formatos comuns como ZIP e TAR, ent\xE3o voc\xEA s\xF3 precisa apontar "),Ua=n(Uo,"CODE",{});var Xr=d(Ua);Os=s(Xr,"data_files"),Xr.forEach(o),Cs=s(Uo," para os arquivos compactados e est\xE1 pronto para seguir em frente!"),Uo.forEach(o),To=u(e),oa=n(e,"P",{});var en=d(oa);Ps=s(en,"Agora que voc\xEA sabe como carregar arquivos locais em seu laptop ou desktop, vamos dar uma olhada no carregamento de arquivos remotos."),en.forEach(o),yo=u(e),X=n(e,"H2",{class:!0});var Bo=d(X);ue=n(Bo,"A",{id:!0,class:!0,href:!0});var an=d(ue);Ba=n(an,"SPAN",{});var on=d(Ba);v(Pe.$$.fragment,on),on.forEach(o),an.forEach(o),Qs=u(Bo),Za=n(Bo,"SPAN",{});var tn=d(Za);ks=s(tn,"Carregando um dataset remoto"),tn.forEach(o),Bo.forEach(o),No=u(e),A=n(e,"P",{});var F=d(A);Ts=s(F,"Se voc\xEA estiver trabalhando como cientista de dados ou programador em uma empresa, h\xE1 uma boa chance de que os conjuntos de dados que voc\xEA deseja analisar estejam armazenados em algum servidor remoto. Felizmente, o carregamento de arquivos remotos \xE9 t\xE3o simples quanto o carregamento de arquivos locais! Em vez de fornecer um caminho para arquivos locais, apontamos o argumento "),Ya=n(F,"CODE",{});var sn=d(Ya);ys=s(sn,"data_files"),sn.forEach(o),Ns=s(F," de "),Ka=n(F,"CODE",{});var rn=d(Ka);Hs=s(rn,"load_dataset()"),rn.forEach(o),Is=s(F," para uma ou mais URLs onde os arquivos remotos s\xE3o armazenados. Por exemplo, para o conjunto de dados SQuAD-it hospedado no GitHub, podemos apenas apontar "),Wa=n(F,"CODE",{});var nn=d(Wa);Js=s(nn,"data_files"),nn.forEach(o),Rs=s(F," para as URLs "),Xa=n(F,"EM",{});var dn=d(Xa);Ls=s(dn,"SQuAD_it-*.json.gz"),dn.forEach(o),Ms=s(F," da seguinte maneira:"),F.forEach(o),Ho=u(e),v(Qe.$$.fragment,e),Io=u(e),M=n(e,"P",{});var pa=d(M);Fs=s(pa,"Isto retorna o mesmo objeto "),eo=n(pa,"CODE",{});var ln=d(eo);Vs=s(ln,"DatasetDict"),ln.forEach(o),Gs=s(pa," obtido anteriormente, mas nos poupa o passo de baixar e descomprimir manualmente os arquivos "),ao=n(pa,"EM",{});var mn=d(ao);Us=s(mn,"SQuAD_it-*.json.gz"),mn.forEach(o),Bs=s(pa,". Isto envolve nas v\xE1rias formas de carregar conjuntos de dados que n\xE3o est\xE3o hospedados no Hugging Face Hub. Agora que temos um conjunto de dados para brincar, vamos sujar as m\xE3os com v\xE1rias t\xE9cnicas de manipula\xE7\xE3o de dados!"),pa.forEach(o),Jo=u(e),v(ce.$$.fragment,e),this.h()},h(){c(p,"name","hf:doc:metadata"),c(p,"content",JSON.stringify(En)),c(b,"id","e-se-o-meu-dataset-no-estiver-no-hub"),c(b,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(b,"href","#e-se-o-meu-dataset-no-estiver-no-hub"),c(f,"class","relative group"),c(O,"href","https://huggingface.co/datasets"),c(O,"rel","nofollow"),c(te,"id","trabalhando-com-datasets-locais-e-remotos"),c(te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(te,"href","#trabalhando-com-datasets-locais-e-remotos"),c(G,"class","relative group"),c(Ie,"align","center"),c(Je,"align","center"),c(Re,"align","center"),c(Le,"align","center"),c(Me,"align","center"),c(Fe,"align","center"),c(Ve,"align","center"),c(Ge,"align","center"),c(Ue,"align","center"),c(Be,"align","center"),c(Ze,"align","center"),c(Ye,"align","center"),c(Ke,"align","center"),c(We,"align","center"),c(Xe,"align","center"),c(re,"id","carregando-um-conjunto-de-dados-local"),c(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(re,"href","#carregando-um-conjunto-de-dados-local"),c(W,"class","relative group"),c($e,"href","https://github.com/crux82/squad-it/"),c($e,"rel","nofollow"),c(ue,"id","carregando-um-dataset-remoto"),c(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ue,"href","#carregando-um-dataset-remoto"),c(X,"class","relative group")},m(e,i){a(document.head,p),l(e,E,i),l(e,f,i),a(f,b),a(b,z),h(j,z,null),a(f,x),a(f,C),a(C,V),l(e,ae,i),h(N,e,i),l(e,P,i),l(e,w,i),a(w,ve),a(w,O),a(O,D),a(w,Te),a(w,oe),a(oe,ye),a(w,Ne),l(e,so,i),h(he,e,i),l(e,ro,i),l(e,G,i),a(G,te),a(te,fa),h(ge,fa,null),a(G,Yo),a(G,_a),a(_a,Ko),l(e,no,i),l(e,He,i),a(He,Wo),l(e,io,i),l(e,se,i),a(se,va),a(va,U),a(U,Ie),a(Ie,Xo),a(U,et),a(U,Je),a(Je,at),a(U,ot),a(U,Re),a(Re,tt),a(se,st),a(se,H),a(H,B),a(B,Le),a(Le,rt),a(B,nt),a(B,Me),a(Me,ha),a(ha,dt),a(B,it),a(B,Fe),a(Fe,ga),a(ga,lt),a(H,mt),a(H,Z),a(Z,Ve),a(Ve,ut),a(Z,ct),a(Z,Ge),a(Ge,qa),a(qa,pt),a(Z,ft),a(Z,Ue),a(Ue,$a),a($a,_t),a(H,vt),a(H,Y),a(Y,Be),a(Be,ht),a(Y,gt),a(Y,Ze),a(Ze,ja),a(ja,qt),a(Y,$t),a(Y,Ye),a(Ye,Ea),a(Ea,jt),a(H,Et),a(H,K),a(K,Ke),a(Ke,bt),a(K,Dt),a(K,We),a(We,ba),a(ba,St),a(K,xt),a(K,Xe),a(Xe,Da),a(Da,wt),l(e,lo,i),l(e,I,i),a(I,At),a(I,Sa),a(Sa,zt),a(I,Ot),a(I,xa),a(xa,Ct),a(I,Pt),l(e,mo,i),l(e,W,i),a(W,re),a(re,wa),h(qe,wa,null),a(W,Qt),a(W,Aa),a(Aa,kt),l(e,uo,i),l(e,ne,i),a(ne,Tt),a(ne,$e),a($e,yt),a(ne,Nt),l(e,co,i),l(e,de,i),a(de,Ht),a(de,za),a(za,It),a(de,Jt),l(e,po,i),h(je,e,i),l(e,fo,i),l(e,Q,i),a(Q,Rt),a(Q,Oa),a(Oa,Lt),a(Q,Mt),a(Q,Ca),a(Ca,Ft),a(Q,Vt),a(Q,Pa),a(Pa,Gt),a(Q,Ut),l(e,_o,i),h(Ee,e,i),l(e,vo,i),h(be,e,i),l(e,ho,i),l(e,J,i),a(J,Bt),a(J,Qa),a(Qa,Zt),a(J,Yt),a(J,ka),a(ka,Kt),a(J,Wt),l(e,go,i),h(ie,e,i),l(e,qo,i),l(e,k,i),a(k,Xt),a(k,Ta),a(Ta,es),a(k,as),a(k,ya),a(ya,os),a(k,ts),a(k,Na),a(Na,ss),a(k,rs),l(e,$o,i),h(De,e,i),l(e,jo,i),l(e,R,i),a(R,ns),a(R,Ha),a(Ha,ds),a(R,is),a(R,Ia),a(Ia,ls),a(R,ms),l(e,Eo,i),h(Se,e,i),l(e,bo,i),h(xe,e,i),l(e,Do,i),l(e,ea,i),a(ea,us),l(e,So,i),h(we,e,i),l(e,xo,i),h(Ae,e,i),l(e,wo,i),l(e,S,i),a(S,cs),a(S,Ja),a(Ja,ps),a(S,fs),a(S,Ra),a(Ra,_s),a(S,vs),a(S,La),a(La,hs),a(S,gs),a(S,Ma),a(Ma,qs),a(S,$s),a(S,Fa),a(Fa,js),a(S,Es),l(e,Ao,i),h(ze,e,i),l(e,zo,i),h(Oe,e,i),l(e,Oo,i),l(e,aa,i),a(aa,bs),l(e,Co,i),h(le,e,i),l(e,Po,i),l(e,L,i),a(L,Ds),a(L,Va),a(Va,Ss),a(L,xs),a(L,Ga),a(Ga,ws),a(L,As),l(e,Qo,i),h(Ce,e,i),l(e,ko,i),l(e,me,i),a(me,zs),a(me,Ua),a(Ua,Os),a(me,Cs),l(e,To,i),l(e,oa,i),a(oa,Ps),l(e,yo,i),l(e,X,i),a(X,ue),a(ue,Ba),h(Pe,Ba,null),a(X,Qs),a(X,Za),a(Za,ks),l(e,No,i),l(e,A,i),a(A,Ts),a(A,Ya),a(Ya,ys),a(A,Ns),a(A,Ka),a(Ka,Hs),a(A,Is),a(A,Wa),a(Wa,Js),a(A,Rs),a(A,Xa),a(Xa,Ls),a(A,Ms),l(e,Ho,i),h(Qe,e,i),l(e,Io,i),l(e,M,i),a(M,Fs),a(M,eo),a(eo,Vs),a(M,Gs),a(M,ao),a(ao,Us),a(M,Bs),l(e,Jo,i),h(ce,e,i),Ro=!0},p(e,[i]){const ke={};i&2&&(ke.$$scope={dirty:i,ctx:e}),ie.$set(ke);const oo={};i&2&&(oo.$$scope={dirty:i,ctx:e}),le.$set(oo);const to={};i&2&&(to.$$scope={dirty:i,ctx:e}),ce.$set(to)},i(e){Ro||(g(j.$$.fragment,e),g(N.$$.fragment,e),g(he.$$.fragment,e),g(ge.$$.fragment,e),g(qe.$$.fragment,e),g(je.$$.fragment,e),g(Ee.$$.fragment,e),g(be.$$.fragment,e),g(ie.$$.fragment,e),g(De.$$.fragment,e),g(Se.$$.fragment,e),g(xe.$$.fragment,e),g(we.$$.fragment,e),g(Ae.$$.fragment,e),g(ze.$$.fragment,e),g(Oe.$$.fragment,e),g(le.$$.fragment,e),g(Ce.$$.fragment,e),g(Pe.$$.fragment,e),g(Qe.$$.fragment,e),g(ce.$$.fragment,e),Ro=!0)},o(e){q(j.$$.fragment,e),q(N.$$.fragment,e),q(he.$$.fragment,e),q(ge.$$.fragment,e),q(qe.$$.fragment,e),q(je.$$.fragment,e),q(Ee.$$.fragment,e),q(be.$$.fragment,e),q(ie.$$.fragment,e),q(De.$$.fragment,e),q(Se.$$.fragment,e),q(xe.$$.fragment,e),q(we.$$.fragment,e),q(Ae.$$.fragment,e),q(ze.$$.fragment,e),q(Oe.$$.fragment,e),q(le.$$.fragment,e),q(Ce.$$.fragment,e),q(Pe.$$.fragment,e),q(Qe.$$.fragment,e),q(ce.$$.fragment,e),Ro=!1},d(e){o(p),e&&o(E),e&&o(f),$(j),e&&o(ae),$(N,e),e&&o(P),e&&o(w),e&&o(so),$(he,e),e&&o(ro),e&&o(G),$(ge),e&&o(no),e&&o(He),e&&o(io),e&&o(se),e&&o(lo),e&&o(I),e&&o(mo),e&&o(W),$(qe),e&&o(uo),e&&o(ne),e&&o(co),e&&o(de),e&&o(po),$(je,e),e&&o(fo),e&&o(Q),e&&o(_o),$(Ee,e),e&&o(vo),$(be,e),e&&o(ho),e&&o(J),e&&o(go),$(ie,e),e&&o(qo),e&&o(k),e&&o($o),$(De,e),e&&o(jo),e&&o(R),e&&o(Eo),$(Se,e),e&&o(bo),$(xe,e),e&&o(Do),e&&o(ea),e&&o(So),$(we,e),e&&o(xo),$(Ae,e),e&&o(wo),e&&o(S),e&&o(Ao),$(ze,e),e&&o(zo),$(Oe,e),e&&o(Oo),e&&o(aa),e&&o(Co),$(le,e),e&&o(Po),e&&o(L),e&&o(Qo),$(Ce,e),e&&o(ko),e&&o(me),e&&o(To),e&&o(oa),e&&o(yo),e&&o(X),$(Pe),e&&o(No),e&&o(A),e&&o(Ho),$(Qe,e),e&&o(Io),e&&o(M),e&&o(Jo),$(ce,e)}}}const En={local:"e-se-o-meu-dataset-no-estiver-no-hub",sections:[{local:"trabalhando-com-datasets-locais-e-remotos",title:"Trabalhando com datasets locais e remotos"},{local:"carregando-um-conjunto-de-dados-local",title:"Carregando um conjunto de dados local"},{local:"carregando-um-dataset-remoto",title:"Carregando um dataset remoto"}],title:"E se o meu dataset n\xE3o estiver no Hub?"};function bn(ee){return _n(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class On extends un{constructor(p){super();cn(this,p,bn,jn,pn,{})}}export{On as default,En as metadata};
