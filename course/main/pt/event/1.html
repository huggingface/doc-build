<meta charset="utf-8" /><meta http-equiv="content-security-policy" content=""><meta name="hf:doc:metadata" content="{&quot;local&quot;:&quot;evento-de-lanamento-da-parte-2&quot;,&quot;sections&quot;:[{&quot;local&quot;:&quot;dia-1-uma-viso-de-alto-nvel-dos-transformers-e-como-treinlos&quot;,&quot;title&quot;:&quot;Dia 1: Uma vis√£o de alto n√≠vel dos Transformers e como trein√°-los&quot;},{&quot;local&quot;:&quot;dia-2-as-ferramentas-a-serem-usadas&quot;,&quot;title&quot;:&quot;Dia 2: As ferramentas a serem usadas&quot;}],&quot;title&quot;:&quot;Evento de lan√ßamento da Parte 2&quot;}" data-svelte="svelte-1phssyn">
	<link rel="modulepreload" href="/docs/course/main/pt/_app/assets/pages/__layout.svelte-hf-doc-builder.css">
	<link rel="modulepreload" href="/docs/course/main/pt/_app/start-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/pt/_app/chunks/vendor-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/pt/_app/chunks/paths-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/pt/_app/pages/__layout.svelte-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/pt/_app/pages/event/1.mdx-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/pt/_app/chunks/Youtube-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/pt/_app/chunks/IconCopyLink-hf-doc-builder.js"> 





<h1 class="relative group"><a id="evento-de-lanamento-da-parte-2" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#evento-de-lanamento-da-parte-2"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Evento de lan√ßamento da Parte 2
	</span></h1>

<p>Para o lan√ßamento da parte 2 do curso, organizamos um evento ao vivo com dois dias de palestras antes de um sprint de ajuste. Se voc√™ perdeu, pode acompanhar as palestras que est√£o listadas abaixo!</p>
<h2 class="relative group"><a id="dia-1-uma-viso-de-alto-nvel-dos-transformers-e-como-treinlos" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#dia-1-uma-viso-de-alto-nvel-dos-transformers-e-como-treinlos"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Dia 1: Uma vis√£o de alto n√≠vel dos Transformers e como trein√°-los
	</span></h2>

<p><strong>Thomas Wolf:</strong> <em>Transfer Learning and the birth of the Transformers library</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/wCYVeahJES0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/9eq8oUi.png" alt="A visual summary of Thom's talk" width="80%"></p>
<p>Thomas Wolf √© cofundador e Chief Science Officer da Hugging Face. As ferramentas criadas por Thomas Wolf e a equipe Hugging Face s√£o usadas em mais de 5.000 organiza√ß√µes de pesquisa, incluindo Facebook Artificial Intelligence Research, Google Research, DeepMind, Amazon Research, Apple, Allen Institute for Artificial Intelligence e na maioria dos departamentos universit√°rios. Thomas Wolf √© o iniciador e presidente s√™nior da maior colabora√ß√£o de pesquisa que j√° existiu em Intelig√™ncia Artificial: <a href="https://bigscience.huggingface.co" rel="nofollow">‚ÄúBigScience‚Äù</a>, bem como um conjunto de <a href="https://github.com/huggingface/" rel="nofollow">bibliotecas e ferramentas amplamente utilizadas </a>. Thomas Wolf tamb√©m √© um educador prol√≠fico, um l√≠der de pensamento no campo de Intelig√™ncia Artificial e Processamento de Linguagem Natural e um orador convidado regular para confer√™ncias em todo o mundo <a href="https://thomwolf.io" rel="nofollow">https://thomwolf.io</a>.</p>
<p><strong>Jay Alammar:</strong> <em>A gentle visual intro to Transformers models</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/VzvG23gmcYU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/rOZAuE9.png" alt="A visual summary of Jay's talk" width="80%"></p>
<p>Por meio de seu popular blog de ML, Jay ajudou milh√µes de pesquisadores e engenheiros a entender visualmente ferramentas e conceitos de aprendizado de m√°quina desde o b√°sico (terminando em NumPy, Pandas docs) at√© o de ponta (Transformers, BERT, GPT-3).</p>
<p><strong>Margaret Mitchell:</strong> <em>On Values in ML Development</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/8j9HRMjh_s8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/NuIsnY3.png" alt="A visual summary of Margaret's talk" width="80%"></p>
<p>Margaret Mitchell √© uma pesquisadora que trabalha em IA √©tica, atualmente focada nos meandros do desenvolvimento de IA informada pela √©tica em tecnologia. Ela publicou mais de 50 artigos sobre gera√ß√£o de linguagem natural, tecnologia assistiva, vis√£o computacional e √©tica em IA, e possui v√°rias patentes nas √°reas de gera√ß√£o de conversas e classifica√ß√£o de sentimentos. Ela trabalhou anteriormente no Google AI como Staff Research Scientist, onde fundou e co-liderou o grupo Ethical AI do Google, focado na pesquisa b√°sica de √©tica em IA e na operacionaliza√ß√£o da √©tica de IA internamente no Google. Antes de ingressar no Google, ela foi pesquisadora da Microsoft Research, focada na gera√ß√£o de vis√£o computacional para linguagem; e fez p√≥s-doutorado na Johns Hopkins, com foco em modelagem bayesiana e extra√ß√£o de informa√ß√µes. Ela possui doutorado em Ci√™ncia da Computa√ß√£o pela Universidade de Aberdeen e mestrado em lingu√≠stica computacional pela Universidade de Washington. Enquanto se formava, ela tamb√©m trabalhou de 2005 a 2012 em aprendizado de m√°quina, dist√∫rbios neurol√≥gicos e tecnologia assistiva na Oregon Health and Science University. Ela liderou uma s√©rie de workshops e iniciativas nas interse√ß√µes de diversidade, inclus√£o, ci√™ncia da computa√ß√£o e √©tica. Seu trabalho recebeu pr√™mios do Secret√°rio de Defesa Ash Carter e da Funda√ß√£o Americana para Cegos e foi implementado por v√°rias empresas de tecnologia. Ela gosta de jardinagem, c√£es e gatos.</p>
<p><strong>Matthew Watson and Chen Qian:</strong> <em>NLP workflows with Keras</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/gZIP-_2XYMM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/1vD2az8.png" alt="A visual summary of Matt and Chen's talk" width="80%"></p>
<p>Matthew Watson √© engenheiro de aprendizado de m√°quina na equipe Keras, com foco em APIs de modelagem de alto n√≠vel. Ele estudou Computa√ß√£o Gr√°fica durante a gradua√ß√£o e mestrado na Universidade de Stanford. Um quase graduado em ingl√™s que se voltou para a ci√™ncia da computa√ß√£o, ele √© apaixonado por trabalhar em v√°rias disciplinas e tornar a PNL acess√≠vel a um p√∫blico mais amplo.</p>
<p>Chen Qian √© engenheiro de software da equipe Keras, com foco em APIs de modelagem de alto n√≠vel. Chen obteve um mestrado em Engenharia El√©trica pela Universidade de Stanford e est√° especialmente interessado em simplificar as implementa√ß√µes de c√≥digo de tarefas de ML e ML em larga escala.</p>
<p><strong>Mark Saroufim:</strong> <em>How to Train a Model with Pytorch</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/KmvPlW2cbIo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/TPmlkm8.png" alt="A visual summary of Mark's talk" width="80%"></p>
<p>Mark Saroufim √© um engenheiro parceiro do Pytorch trabalhando em ferramentas de produ√ß√£o OSS, incluindo TorchServe e Pytorch Enterprise. Em suas vidas passadas, Mark foi Cientista Aplicado e Gerente de Produto na Graphcore, <a href="http://yuri.ai/" rel="nofollow">yuri.ai</a>, Microsoft e JPL da NASA. Sua principal paix√£o √© tornar a programa√ß√£o mais divertida.</p>
<p><strong>Jakob Uszkoreit:</strong> <em>It Ain‚Äôt Broke So <del>Don‚Äôt Fix</del> Let‚Äôs Break It</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/C6jweXYFHSA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/5dWQeNB.png" alt="A visual summary of Jakob's talk" width="80%"></p>
<p>Jakob Uszkoreit √© o cofundador da Inceptive. A Inceptive projeta mol√©culas de RNA para vacinas e terapias usando aprendizado profundo em larga escala em um circuito fechado com experimentos de alto rendimento com o objetivo de tornar os medicamentos baseados em RNA mais acess√≠veis, mais eficazes e mais amplamente aplic√°veis. Anteriormente, Jakob trabalhou no Google por mais de uma d√©cada, liderando equipes de pesquisa e desenvolvimento no Google Brain, Research and Search trabalhando em fundamentos de aprendizado profundo, vis√£o computacional, compreens√£o de idiomas e tradu√ß√£o autom√°tica.</p>
<h2 class="relative group"><a id="dia-2-as-ferramentas-a-serem-usadas" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#dia-2-as-ferramentas-a-serem-usadas"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Dia 2: As ferramentas a serem usadas
	</span></h2>

<p><strong>Lewis Tunstall:</strong> <em>Simple Training with the ü§ó Transformers Trainer</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/u--UVvH-LIQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p>Lewis √© machine learning engineer no Hugging Face, focado em desenvolver ferramentas de c√≥digo aberto e torn√°-las acess√≠veis para a comunidade em geral. Ele tamb√©m √© coautor do livro de O‚ÄôReilly <a href="https://www.oreilly.com/library/view/natural-language-processing/9781098136789/" rel="nofollow">Natural Language Processing with Transformers</a>. Voc√™ pode segui-lo no Twitter (@_lewtun) para dicas e truques de PNL!</p>
<p><strong>Matthew Carrigan:</strong> <em>New TensorFlow Features for ü§ó Transformers and ü§ó Datasets</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/gQUlXp1691w" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p>Matt √© respons√°vel pela manuten√ß√£o do TensorFlow em Transformers e, eventualmente, liderar√° um golpe contra a fac√ß√£o PyTorch, que provavelmente ser√° coordenada por meio de sua conta no Twitter @carrigmat.</p>
<p><strong>Lysandre Debut:</strong> <em>The Hugging Face Hub as a means to collaborate on and share Machine Learning projects</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/RBw1TmdEZp0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/TarIPCz.png" alt="A visual summary of Lysandre's talk" width="80%"></p>
<p>Lysandre √© machine learning engineer no Hugging Face, onde est√° envolvido em muitos projetos de c√≥digo aberto. Seu objetivo √© tornar o Machine Learning acess√≠vel a todos, desenvolvendo ferramentas poderosas com uma API muito simples.</p>
<p><strong>Lucile Saulnier:</strong> <em>Get your own tokenizer with ü§ó Transformers &amp; ü§ó Tokenizers</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/UkNmyTFKriI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p>Lucile √© engenheira de aprendizado de m√°quina na Hugging Face, desenvolvendo e dando suporte ao uso de ferramentas de c√≥digo aberto. Ela tamb√©m est√° ativamente envolvida em muitos projetos de pesquisa na √°rea de Processamento de Linguagem Natural, como treinamento colaborativo e BigScience.</p>
<p><strong>Sylvain Gugger:</strong> <em>Supercharge your PyTorch training loop with ü§ó Accelerate</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/t8Krzu-nSeY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p>Sylvain √© um Research Engineer no Hugging Face e um dos principais mantenedores do ü§ó Transformers e o desenvolvedor por tr√°s do ü§ó Accelerate. Ele gosta de tornar o treinamento de modelo mais acess√≠vel.</p>
<p><strong>Merve Noyan:</strong> <em>Showcase your model demos with ü§ó Spaces</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/vbaKOa4UXoM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p>Merve √© um desenvolvedor defensor da Hugging Face, trabalhando no desenvolvimento de ferramentas e na cria√ß√£o de conte√∫do em torno delas para democratizar o aprendizado de m√°quina para todos.</p>
<p><strong>Abubakar Abid:</strong> <em>Building Machine Learning Applications Fast</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/c7mle2yYpwQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/qWIFeiF.png" alt="A visual summary of Abubakar's talk" width="80%"></p>
<p>Abubakar Abid √© o CEO da <a href="www.gradio.app">Gradio</a>. Ele recebeu seu bacharelado em Engenharia El√©trica e Ci√™ncia da Computa√ß√£o do MIT em 2015 e seu PhD em Aprendizado de M√°quina Aplicado de Stanford em 2021. Em seu papel como CEO da Gradio, Abubakar trabalha para tornar os modelos de aprendizado de m√°quina mais f√°ceis de demonstrar, debugar, e implantar.</p>
<p><strong>Mathieu Desv√©:</strong> <em>AWS ML Vision: Making Machine Learning Accessible to all Customers</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/O2e3pXO4aRE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/oLdZTKy.png" alt="A visual summary of Mathieu's talk" width="80%"></p>
<p>Entusiasta da tecnologia, maker nas horas vagas. Gosto de desafios e resolu√ß√£o de problemas de clientes e usu√°rios, e trabalho com pessoas talentosas para aprender todos os dias. Desde 2004, atuo em v√°rias posi√ß√µes alternando entre frontend, backend, infraestrutura, opera√ß√µes e gerenciamentos. Tente resolver problemas t√©cnicos e gerenciais comuns de maneira √°gil.</p>
<p><strong>Philipp Schmid:</strong> <em>Managed Training with Amazon SageMaker and ü§ó Transformers</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/yG6J2Zfo8iw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p>Philipp Schmid √© Machine Learning Engineer and Tech Lead no Hugging Face, onde lidera a colabora√ß√£o com a equipe do Amazon SageMaker. Ele √© apaixonado por democratizar e produzir modelos de PNL de ponta e melhorar a facilidade de uso do Deep Learning.</p>


		<script type="module" data-hydrate="lvph0s">
		import { start } from "/docs/course/main/pt/_app/start-hf-doc-builder.js";
		start({
			target: document.querySelector('[data-hydrate="lvph0s"]').parentNode,
			paths: {"base":"/docs/course/main/pt","assets":"/docs/course/main/pt"},
			session: {},
			route: false,
			spa: false,
			trailing_slash: "never",
			hydrate: {
				status: 200,
				error: null,
				nodes: [
					import("/docs/course/main/pt/_app/pages/__layout.svelte-hf-doc-builder.js"),
						import("/docs/course/main/pt/_app/pages/event/1.mdx-hf-doc-builder.js")
				],
				params: {}
			}
		});
	</script>
