import{S as Do,i as Fo,s as Oo,e as n,k as l,w as p,t as u,M as xo,c as o,d as t,m as f,a as s,x as h,h as c,b as m,N as A,G as a,g as r,y as d,L as Co,q as g,o as v,B as w,v as jo}from"../../chunks/vendor-hf-doc-builder.js";import{Y as y}from"../../chunks/Youtube-hf-doc-builder.js";import{I as Yr}from"../../chunks/IconCopyLink-hf-doc-builder.js";function zo(Qr){let _,Jt,$,M,ut,K,_i,ct,$i,Kt,qe,bi,Yt,b,S,pt,Y,ki,ht,Ai,Qt,P,dt,Mi,Si,gt,Pi,qt,Q,q,Xt,X,Z,qr,Zt,E,Ti,ee,Ii,Li,te,Gi,Ni,ae,Hi,Ri,ea,T,vt,Di,Fi,wt,Oi,ta,ie,re,aa,ne,oe,Xr,ia,Xe,xi,ra,I,yt,Ci,ji,Et,zi,na,se,le,oa,fe,me,Zr,sa,Ze,Bi,la,L,_t,Wi,Vi,$t,Ui,fa,ue,ce,ma,pe,he,en,ua,et,Ji,ca,tt,Ki,pa,G,bt,Yi,Qi,kt,qi,ha,de,ge,da,ve,we,tn,ga,N,Xi,ye,Zi,er,va,H,At,tr,ar,Ee,ir,Mt,rr,nr,wa,_e,$e,ya,be,ke,an,Ea,at,or,_a,k,R,St,Ae,sr,Pt,lr,$a,D,Tt,fr,mr,It,ur,ba,Me,Se,ka,F,cr,Pe,pr,hr,Aa,O,Lt,dr,gr,Gt,vr,Ma,Te,Ie,Sa,it,wr,Pa,x,Nt,yr,Er,Ht,_r,Ta,Le,Ge,Ia,Ne,He,rn,La,rt,$r,Ga,C,Rt,br,kr,Dt,Ar,Na,Re,De,Ha,nt,Mr,Ra,j,Ft,Sr,Pr,Ot,Tr,Da,Fe,Oe,Fa,ot,Ir,Oa,z,xt,Lr,Gr,Ct,Nr,xa,xe,Ce,Ca,st,Hr,ja,B,jt,Rr,Dr,zt,Fr,za,je,ze,Ba,Be,We,nn,Wa,W,Or,lt,xr,Cr,Va,V,Bt,jr,zr,Wt,Br,Ua,Ve,Ue,Ja,Je,Ke,on,Ka,ft,Wr,Ya,U,Vt,Vr,Ur,Ut,Jr,Qa,Ye,Qe,qa,mt,Kr,Xa;return K=new Yr({}),Y=new Yr({}),q=new y({props:{id:"wCYVeahJES0"}}),re=new y({props:{id:"VzvG23gmcYU"}}),le=new y({props:{id:"8j9HRMjh_s8"}}),ce=new y({props:{id:"gZIP-_2XYMM"}}),ge=new y({props:{id:"KmvPlW2cbIo"}}),$e=new y({props:{id:"C6jweXYFHSA"}}),Ae=new Yr({}),Se=new y({props:{id:"u--UVvH-LIQ"}}),Ie=new y({props:{id:"gQUlXp1691w"}}),Ge=new y({props:{id:"RBw1TmdEZp0"}}),De=new y({props:{id:"UkNmyTFKriI"}}),Oe=new y({props:{id:"t8Krzu-nSeY"}}),Ce=new y({props:{id:"vbaKOa4UXoM"}}),ze=new y({props:{id:"c7mle2yYpwQ"}}),Ue=new y({props:{id:"O2e3pXO4aRE"}}),Qe=new y({props:{id:"yG6J2Zfo8iw"}}),{c(){_=n("meta"),Jt=l(),$=n("h1"),M=n("a"),ut=n("span"),p(K.$$.fragment),_i=l(),ct=n("span"),$i=u("Part 2 Release Event"),Kt=l(),qe=n("p"),bi=u("For the release of part 2 of the course, we organized a live event with two days of talks before a fine-tuning sprint. If you missed it, you can catch up with the talks which are all listed below!"),Yt=l(),b=n("h2"),S=n("a"),pt=n("span"),p(Y.$$.fragment),ki=l(),ht=n("span"),Ai=u("Day 1: A high-level view of Transformers and how to train them"),Qt=l(),P=n("p"),dt=n("strong"),Mi=u("Thomas Wolf:"),Si=l(),gt=n("em"),Pi=u("Transfer Learning and the birth of the Transformers library"),qt=l(),Q=n("div"),p(q.$$.fragment),Xt=l(),X=n("p"),Z=n("img"),Zt=l(),E=n("p"),Ti=u("Thomas Wolf is co-founder and Chief Science Officer of Hugging Face. The tools created by Thomas Wolf and the Hugging Face team are used across more than 5,000 research organisations including Facebook Artificial Intelligence Research, Google Research, DeepMind, Amazon Research, Apple, the Allen Institute for Artificial Intelligence as well as most university departments. Thomas Wolf is the initiator and senior chair of the largest research collaboration that has ever existed in Artificial Intelligence: "),ee=n("a"),Ii=u("\u201CBigScience\u201D"),Li=u(", as well as a set of widely used "),te=n("a"),Gi=u("libraries and tools"),Ni=u(". Thomas Wolf is also a prolific educator, a thought leader in the field of Artificial Intelligence and Natural Language Processing, and a regular invited speaker to conferences all around the world "),ae=n("a"),Hi=u("https://thomwolf.io"),Ri=u("."),ea=l(),T=n("p"),vt=n("strong"),Di=u("Jay Alammar:"),Fi=l(),wt=n("em"),Oi=u("A gentle visual intro to Transformers models"),ta=l(),ie=n("div"),p(re.$$.fragment),aa=l(),ne=n("p"),oe=n("img"),ia=l(),Xe=n("p"),xi=u("Through his popular ML blog, Jay has helped millions of researchers and engineers visually understand machine learning tools and concepts from the basic (ending up in NumPy, Pandas docs) to the cutting-edge (Transformers, BERT, GPT-3)."),ra=l(),I=n("p"),yt=n("strong"),Ci=u("Margaret Mitchell:"),ji=l(),Et=n("em"),zi=u("On Values in ML Development"),na=l(),se=n("div"),p(le.$$.fragment),oa=l(),fe=n("p"),me=n("img"),sa=l(),Ze=n("p"),Bi=u("Margaret Mitchell is a researcher working on Ethical AI, currently focused on the ins and outs of ethics-informed AI development in tech. She has published over 50 papers on natural language generation, assistive technology, computer vision, and AI ethics, and holds multiple patents in the areas of conversation generation and sentiment classification. She previously worked at Google AI as a Staff Research Scientist, where she founded and co-led Google\u2019s Ethical AI group, focused on foundational AI ethics research and operationalizing AI ethics Google-internally. Before joining Google, she was a researcher at Microsoft Research, focused on computer vision-to-language generation; and was a postdoc at Johns Hopkins, focused on Bayesian modeling and information extraction. She holds a PhD in Computer Science from the University of Aberdeen and a Master\u2019s in computational linguistics from the University of Washington. While earning her degrees, she also worked from 2005-2012 on machine learning, neurological disorders, and assistive technology at Oregon Health and Science University. She has spearheaded a number of workshops and initiatives at the intersections of diversity, inclusion, computer science, and ethics. Her work has received awards from Secretary of Defense Ash Carter and the American Foundation for the Blind, and has been implemented by multiple technology companies. She likes gardening, dogs, and cats."),la=l(),L=n("p"),_t=n("strong"),Wi=u("Matthew Watson and Chen Qian:"),Vi=l(),$t=n("em"),Ui=u("NLP workflows with Keras"),fa=l(),ue=n("div"),p(ce.$$.fragment),ma=l(),pe=n("p"),he=n("img"),ua=l(),et=n("p"),Ji=u("Matthew Watson is a machine learning engineer on the Keras team, with a focus on high-level modeling APIs. He studied Computer Graphics during undergrad and a Masters at Stanford University. An almost English major who turned towards computer science, he is passionate about working across disciplines and making NLP accessible to a wider audience."),ca=l(),tt=n("p"),Ki=u("Chen Qian is a software engineer from Keras team, with a focus on high-level modeling APIs. Chen got a Master degree of Electrical Engineering from Stanford University, and he is especially interested in simplifying code implementations of ML tasks and large-scale ML."),pa=l(),G=n("p"),bt=n("strong"),Yi=u("Mark Saroufim:"),Qi=l(),kt=n("em"),qi=u("How to Train a Model with Pytorch"),ha=l(),de=n("div"),p(ge.$$.fragment),da=l(),ve=n("p"),we=n("img"),ga=l(),N=n("p"),Xi=u("Mark Saroufim is a Partner Engineer at Pytorch working on OSS production tools including TorchServe and Pytorch Enterprise. In his past lives, Mark was an Applied Scientist and Product Manager at Graphcore, "),ye=n("a"),Zi=u("yuri.ai"),er=u(", Microsoft and NASA\u2019s JPL. His primary passion is to make programming more fun."),va=l(),H=n("p"),At=n("strong"),tr=u("Jakob Uszkoreit:"),ar=l(),Ee=n("em"),ir=u("It Ain\u2019t Broke So "),Mt=n("del"),rr=u("Don\u2019t Fix"),nr=u(" Let\u2019s Break It"),wa=l(),_e=n("div"),p($e.$$.fragment),ya=l(),be=n("p"),ke=n("img"),Ea=l(),at=n("p"),or=u("Jakob Uszkoreit is the co-founder of Inceptive. Inceptive designs RNA molecules for vaccines and therapeutics using large-scale deep learning in a tight loop with high throughput experiments with the goal of making RNA-based medicines more accessible, more effective and more broadly applicable. Previously, Jakob worked at Google for more than a decade, leading research and development teams in Google Brain, Research and Search working on deep learning fundamentals, computer vision, language understanding and machine translation."),_a=l(),k=n("h2"),R=n("a"),St=n("span"),p(Ae.$$.fragment),sr=l(),Pt=n("span"),lr=u("Day 2: The tools to use"),$a=l(),D=n("p"),Tt=n("strong"),fr=u("Lewis Tunstall:"),mr=l(),It=n("em"),ur=u("Simple Training with the \u{1F917} Transformers Trainer"),ba=l(),Me=n("div"),p(Se.$$.fragment),ka=l(),F=n("p"),cr=u("Lewis is a machine learning engineer at Hugging Face, focused on developing open-source tools and making them accessible to the wider community. He is also a co-author of the O\u2019Reilly book "),Pe=n("a"),pr=u("Natural Language Processing with Transformers"),hr=u(". You can follow him on Twitter (@_lewtun) for NLP tips and tricks!"),Aa=l(),O=n("p"),Lt=n("strong"),dr=u("Matthew Carrigan:"),gr=l(),Gt=n("em"),vr=u("New TensorFlow Features for \u{1F917} Transformers and \u{1F917} Datasets"),Ma=l(),Te=n("div"),p(Ie.$$.fragment),Sa=l(),it=n("p"),wr=u("Matt is responsible for TensorFlow maintenance at Transformers, and will eventually lead a coup against the incumbent PyTorch faction which will likely be co-ordinated via his Twitter account @carrigmat."),Pa=l(),x=n("p"),Nt=n("strong"),yr=u("Lysandre Debut:"),Er=l(),Ht=n("em"),_r=u("The Hugging Face Hub as a means to collaborate on and share Machine Learning projects"),Ta=l(),Le=n("div"),p(Ge.$$.fragment),Ia=l(),Ne=n("p"),He=n("img"),La=l(),rt=n("p"),$r=u("Lysandre is a Machine Learning Engineer at Hugging Face where he is involved in many open source projects. His aim is to make Machine Learning accessible to everyone by developing powerful tools with a very simple API."),Ga=l(),C=n("p"),Rt=n("strong"),br=u("Lucile Saulnier:"),kr=l(),Dt=n("em"),Ar=u("Get your own tokenizer with \u{1F917} Transformers & \u{1F917} Tokenizers"),Na=l(),Re=n("div"),p(De.$$.fragment),Ha=l(),nt=n("p"),Mr=u("Lucile is a machine learning engineer at Hugging Face, developing and supporting the use of open source tools. She is also actively involved in many research projects in the field of Natural Language Processing such as collaborative training and BigScience."),Ra=l(),j=n("p"),Ft=n("strong"),Sr=u("Sylvain Gugger:"),Pr=l(),Ot=n("em"),Tr=u("Supercharge your PyTorch training loop with \u{1F917} Accelerate"),Da=l(),Fe=n("div"),p(Oe.$$.fragment),Fa=l(),ot=n("p"),Ir=u("Sylvain is a Research Engineer at Hugging Face and one of the core maintainers of \u{1F917} Transformers and the developer behind \u{1F917} Accelerate. He likes making model training more accessible."),Oa=l(),z=n("p"),xt=n("strong"),Lr=u("Merve Noyan:"),Gr=l(),Ct=n("em"),Nr=u("Showcase your model demos with \u{1F917} Spaces"),xa=l(),xe=n("div"),p(Ce.$$.fragment),Ca=l(),st=n("p"),Hr=u("Merve is a developer advocate at Hugging Face, working on developing tools and building content around them to democratize machine learning for everyone."),ja=l(),B=n("p"),jt=n("strong"),Rr=u("Abubakar Abid:"),Dr=l(),zt=n("em"),Fr=u("Building Machine Learning Applications Fast"),za=l(),je=n("div"),p(ze.$$.fragment),Ba=l(),Be=n("p"),We=n("img"),Wa=l(),W=n("p"),Or=u("Abubakar Abid is the CEO of "),lt=n("a"),xr=u("Gradio"),Cr=u(". He received his Bachelor\u2019s of Science in Electrical Engineering and Computer Science from MIT in 2015, and his PhD in Applied Machine Learning from Stanford in 2021. In his role as the CEO of Gradio, Abubakar works on making machine learning models easier to demo, debug, and deploy."),Va=l(),V=n("p"),Bt=n("strong"),jr=u("Mathieu Desv\xE9:"),zr=l(),Wt=n("em"),Br=u("AWS ML Vision: Making Machine Learning Accessible to all Customers"),Ua=l(),Ve=n("div"),p(Ue.$$.fragment),Ja=l(),Je=n("p"),Ke=n("img"),Ka=l(),ft=n("p"),Wr=u("Technology enthusiast, maker on my free time. I like challenges and solving problem of clients and users, and work with talented people to learn every day. Since 2004, I work in multiple positions switching from frontend, backend, infrastructure, operations and managements. Try to solve commons technical and managerial issues in agile manner."),Ya=l(),U=n("p"),Vt=n("strong"),Vr=u("Philipp Schmid:"),Ur=l(),Ut=n("em"),Jr=u("Managed Training with Amazon SageMaker and \u{1F917} Transformers"),Qa=l(),Ye=n("div"),p(Qe.$$.fragment),qa=l(),mt=n("p"),Kr=u("Philipp Schmid is a Machine Learning Engineer and Tech Lead at Hugging Face, where he leads the collaboration with the Amazon SageMaker team. He is passionate about democratizing and productionizing cutting-edge NLP models and improving the ease of use for Deep Learning."),this.h()},l(e){const i=xo('[data-svelte="svelte-1phssyn"]',document.head);_=o(i,"META",{name:!0,content:!0}),i.forEach(t),Jt=f(e),$=o(e,"H1",{class:!0});var Za=s($);M=o(Za,"A",{id:!0,class:!0,href:!0});var sn=s(M);ut=o(sn,"SPAN",{});var ln=s(ut);h(K.$$.fragment,ln),ln.forEach(t),sn.forEach(t),_i=f(Za),ct=o(Za,"SPAN",{});var fn=s(ct);$i=c(fn,"Part 2 Release Event"),fn.forEach(t),Za.forEach(t),Kt=f(e),qe=o(e,"P",{});var mn=s(qe);bi=c(mn,"For the release of part 2 of the course, we organized a live event with two days of talks before a fine-tuning sprint. If you missed it, you can catch up with the talks which are all listed below!"),mn.forEach(t),Yt=f(e),b=o(e,"H2",{class:!0});var ei=s(b);S=o(ei,"A",{id:!0,class:!0,href:!0});var un=s(S);pt=o(un,"SPAN",{});var cn=s(pt);h(Y.$$.fragment,cn),cn.forEach(t),un.forEach(t),ki=f(ei),ht=o(ei,"SPAN",{});var pn=s(ht);Ai=c(pn,"Day 1: A high-level view of Transformers and how to train them"),pn.forEach(t),ei.forEach(t),Qt=f(e),P=o(e,"P",{});var ti=s(P);dt=o(ti,"STRONG",{});var hn=s(dt);Mi=c(hn,"Thomas Wolf:"),hn.forEach(t),Si=f(ti),gt=o(ti,"EM",{});var dn=s(gt);Pi=c(dn,"Transfer Learning and the birth of the Transformers library"),dn.forEach(t),ti.forEach(t),qt=f(e),Q=o(e,"DIV",{class:!0});var gn=s(Q);h(q.$$.fragment,gn),gn.forEach(t),Xt=f(e),X=o(e,"P",{align:!0});var vn=s(X);Z=o(vn,"IMG",{src:!0,alt:!0,width:!0}),vn.forEach(t),Zt=f(e),E=o(e,"P",{});var J=s(E);Ti=c(J,"Thomas Wolf is co-founder and Chief Science Officer of Hugging Face. The tools created by Thomas Wolf and the Hugging Face team are used across more than 5,000 research organisations including Facebook Artificial Intelligence Research, Google Research, DeepMind, Amazon Research, Apple, the Allen Institute for Artificial Intelligence as well as most university departments. Thomas Wolf is the initiator and senior chair of the largest research collaboration that has ever existed in Artificial Intelligence: "),ee=o(J,"A",{href:!0,rel:!0});var wn=s(ee);Ii=c(wn,"\u201CBigScience\u201D"),wn.forEach(t),Li=c(J,", as well as a set of widely used "),te=o(J,"A",{href:!0,rel:!0});var yn=s(te);Gi=c(yn,"libraries and tools"),yn.forEach(t),Ni=c(J,". Thomas Wolf is also a prolific educator, a thought leader in the field of Artificial Intelligence and Natural Language Processing, and a regular invited speaker to conferences all around the world "),ae=o(J,"A",{href:!0,rel:!0});var En=s(ae);Hi=c(En,"https://thomwolf.io"),En.forEach(t),Ri=c(J,"."),J.forEach(t),ea=f(e),T=o(e,"P",{});var ai=s(T);vt=o(ai,"STRONG",{});var _n=s(vt);Di=c(_n,"Jay Alammar:"),_n.forEach(t),Fi=f(ai),wt=o(ai,"EM",{});var $n=s(wt);Oi=c($n,"A gentle visual intro to Transformers models"),$n.forEach(t),ai.forEach(t),ta=f(e),ie=o(e,"DIV",{class:!0});var bn=s(ie);h(re.$$.fragment,bn),bn.forEach(t),aa=f(e),ne=o(e,"P",{align:!0});var kn=s(ne);oe=o(kn,"IMG",{src:!0,alt:!0,width:!0}),kn.forEach(t),ia=f(e),Xe=o(e,"P",{});var An=s(Xe);xi=c(An,"Through his popular ML blog, Jay has helped millions of researchers and engineers visually understand machine learning tools and concepts from the basic (ending up in NumPy, Pandas docs) to the cutting-edge (Transformers, BERT, GPT-3)."),An.forEach(t),ra=f(e),I=o(e,"P",{});var ii=s(I);yt=o(ii,"STRONG",{});var Mn=s(yt);Ci=c(Mn,"Margaret Mitchell:"),Mn.forEach(t),ji=f(ii),Et=o(ii,"EM",{});var Sn=s(Et);zi=c(Sn,"On Values in ML Development"),Sn.forEach(t),ii.forEach(t),na=f(e),se=o(e,"DIV",{class:!0});var Pn=s(se);h(le.$$.fragment,Pn),Pn.forEach(t),oa=f(e),fe=o(e,"P",{align:!0});var Tn=s(fe);me=o(Tn,"IMG",{src:!0,alt:!0,width:!0}),Tn.forEach(t),sa=f(e),Ze=o(e,"P",{});var In=s(Ze);Bi=c(In,"Margaret Mitchell is a researcher working on Ethical AI, currently focused on the ins and outs of ethics-informed AI development in tech. She has published over 50 papers on natural language generation, assistive technology, computer vision, and AI ethics, and holds multiple patents in the areas of conversation generation and sentiment classification. She previously worked at Google AI as a Staff Research Scientist, where she founded and co-led Google\u2019s Ethical AI group, focused on foundational AI ethics research and operationalizing AI ethics Google-internally. Before joining Google, she was a researcher at Microsoft Research, focused on computer vision-to-language generation; and was a postdoc at Johns Hopkins, focused on Bayesian modeling and information extraction. She holds a PhD in Computer Science from the University of Aberdeen and a Master\u2019s in computational linguistics from the University of Washington. While earning her degrees, she also worked from 2005-2012 on machine learning, neurological disorders, and assistive technology at Oregon Health and Science University. She has spearheaded a number of workshops and initiatives at the intersections of diversity, inclusion, computer science, and ethics. Her work has received awards from Secretary of Defense Ash Carter and the American Foundation for the Blind, and has been implemented by multiple technology companies. She likes gardening, dogs, and cats."),In.forEach(t),la=f(e),L=o(e,"P",{});var ri=s(L);_t=o(ri,"STRONG",{});var Ln=s(_t);Wi=c(Ln,"Matthew Watson and Chen Qian:"),Ln.forEach(t),Vi=f(ri),$t=o(ri,"EM",{});var Gn=s($t);Ui=c(Gn,"NLP workflows with Keras"),Gn.forEach(t),ri.forEach(t),fa=f(e),ue=o(e,"DIV",{class:!0});var Nn=s(ue);h(ce.$$.fragment,Nn),Nn.forEach(t),ma=f(e),pe=o(e,"P",{align:!0});var Hn=s(pe);he=o(Hn,"IMG",{src:!0,alt:!0,width:!0}),Hn.forEach(t),ua=f(e),et=o(e,"P",{});var Rn=s(et);Ji=c(Rn,"Matthew Watson is a machine learning engineer on the Keras team, with a focus on high-level modeling APIs. He studied Computer Graphics during undergrad and a Masters at Stanford University. An almost English major who turned towards computer science, he is passionate about working across disciplines and making NLP accessible to a wider audience."),Rn.forEach(t),ca=f(e),tt=o(e,"P",{});var Dn=s(tt);Ki=c(Dn,"Chen Qian is a software engineer from Keras team, with a focus on high-level modeling APIs. Chen got a Master degree of Electrical Engineering from Stanford University, and he is especially interested in simplifying code implementations of ML tasks and large-scale ML."),Dn.forEach(t),pa=f(e),G=o(e,"P",{});var ni=s(G);bt=o(ni,"STRONG",{});var Fn=s(bt);Yi=c(Fn,"Mark Saroufim:"),Fn.forEach(t),Qi=f(ni),kt=o(ni,"EM",{});var On=s(kt);qi=c(On,"How to Train a Model with Pytorch"),On.forEach(t),ni.forEach(t),ha=f(e),de=o(e,"DIV",{class:!0});var xn=s(de);h(ge.$$.fragment,xn),xn.forEach(t),da=f(e),ve=o(e,"P",{align:!0});var Cn=s(ve);we=o(Cn,"IMG",{src:!0,alt:!0,width:!0}),Cn.forEach(t),ga=f(e),N=o(e,"P",{});var oi=s(N);Xi=c(oi,"Mark Saroufim is a Partner Engineer at Pytorch working on OSS production tools including TorchServe and Pytorch Enterprise. In his past lives, Mark was an Applied Scientist and Product Manager at Graphcore, "),ye=o(oi,"A",{href:!0,rel:!0});var jn=s(ye);Zi=c(jn,"yuri.ai"),jn.forEach(t),er=c(oi,", Microsoft and NASA\u2019s JPL. His primary passion is to make programming more fun."),oi.forEach(t),va=f(e),H=o(e,"P",{});var si=s(H);At=o(si,"STRONG",{});var zn=s(At);tr=c(zn,"Jakob Uszkoreit:"),zn.forEach(t),ar=f(si),Ee=o(si,"EM",{});var li=s(Ee);ir=c(li,"It Ain\u2019t Broke So "),Mt=o(li,"DEL",{});var Bn=s(Mt);rr=c(Bn,"Don\u2019t Fix"),Bn.forEach(t),nr=c(li," Let\u2019s Break It"),li.forEach(t),si.forEach(t),wa=f(e),_e=o(e,"DIV",{class:!0});var Wn=s(_e);h($e.$$.fragment,Wn),Wn.forEach(t),ya=f(e),be=o(e,"P",{align:!0});var Vn=s(be);ke=o(Vn,"IMG",{src:!0,alt:!0,width:!0}),Vn.forEach(t),Ea=f(e),at=o(e,"P",{});var Un=s(at);or=c(Un,"Jakob Uszkoreit is the co-founder of Inceptive. Inceptive designs RNA molecules for vaccines and therapeutics using large-scale deep learning in a tight loop with high throughput experiments with the goal of making RNA-based medicines more accessible, more effective and more broadly applicable. Previously, Jakob worked at Google for more than a decade, leading research and development teams in Google Brain, Research and Search working on deep learning fundamentals, computer vision, language understanding and machine translation."),Un.forEach(t),_a=f(e),k=o(e,"H2",{class:!0});var fi=s(k);R=o(fi,"A",{id:!0,class:!0,href:!0});var Jn=s(R);St=o(Jn,"SPAN",{});var Kn=s(St);h(Ae.$$.fragment,Kn),Kn.forEach(t),Jn.forEach(t),sr=f(fi),Pt=o(fi,"SPAN",{});var Yn=s(Pt);lr=c(Yn,"Day 2: The tools to use"),Yn.forEach(t),fi.forEach(t),$a=f(e),D=o(e,"P",{});var mi=s(D);Tt=o(mi,"STRONG",{});var Qn=s(Tt);fr=c(Qn,"Lewis Tunstall:"),Qn.forEach(t),mr=f(mi),It=o(mi,"EM",{});var qn=s(It);ur=c(qn,"Simple Training with the \u{1F917} Transformers Trainer"),qn.forEach(t),mi.forEach(t),ba=f(e),Me=o(e,"DIV",{class:!0});var Xn=s(Me);h(Se.$$.fragment,Xn),Xn.forEach(t),ka=f(e),F=o(e,"P",{});var ui=s(F);cr=c(ui,"Lewis is a machine learning engineer at Hugging Face, focused on developing open-source tools and making them accessible to the wider community. He is also a co-author of the O\u2019Reilly book "),Pe=o(ui,"A",{href:!0,rel:!0});var Zn=s(Pe);pr=c(Zn,"Natural Language Processing with Transformers"),Zn.forEach(t),hr=c(ui,". You can follow him on Twitter (@_lewtun) for NLP tips and tricks!"),ui.forEach(t),Aa=f(e),O=o(e,"P",{});var ci=s(O);Lt=o(ci,"STRONG",{});var eo=s(Lt);dr=c(eo,"Matthew Carrigan:"),eo.forEach(t),gr=f(ci),Gt=o(ci,"EM",{});var to=s(Gt);vr=c(to,"New TensorFlow Features for \u{1F917} Transformers and \u{1F917} Datasets"),to.forEach(t),ci.forEach(t),Ma=f(e),Te=o(e,"DIV",{class:!0});var ao=s(Te);h(Ie.$$.fragment,ao),ao.forEach(t),Sa=f(e),it=o(e,"P",{});var io=s(it);wr=c(io,"Matt is responsible for TensorFlow maintenance at Transformers, and will eventually lead a coup against the incumbent PyTorch faction which will likely be co-ordinated via his Twitter account @carrigmat."),io.forEach(t),Pa=f(e),x=o(e,"P",{});var pi=s(x);Nt=o(pi,"STRONG",{});var ro=s(Nt);yr=c(ro,"Lysandre Debut:"),ro.forEach(t),Er=f(pi),Ht=o(pi,"EM",{});var no=s(Ht);_r=c(no,"The Hugging Face Hub as a means to collaborate on and share Machine Learning projects"),no.forEach(t),pi.forEach(t),Ta=f(e),Le=o(e,"DIV",{class:!0});var oo=s(Le);h(Ge.$$.fragment,oo),oo.forEach(t),Ia=f(e),Ne=o(e,"P",{align:!0});var so=s(Ne);He=o(so,"IMG",{src:!0,alt:!0,width:!0}),so.forEach(t),La=f(e),rt=o(e,"P",{});var lo=s(rt);$r=c(lo,"Lysandre is a Machine Learning Engineer at Hugging Face where he is involved in many open source projects. His aim is to make Machine Learning accessible to everyone by developing powerful tools with a very simple API."),lo.forEach(t),Ga=f(e),C=o(e,"P",{});var hi=s(C);Rt=o(hi,"STRONG",{});var fo=s(Rt);br=c(fo,"Lucile Saulnier:"),fo.forEach(t),kr=f(hi),Dt=o(hi,"EM",{});var mo=s(Dt);Ar=c(mo,"Get your own tokenizer with \u{1F917} Transformers & \u{1F917} Tokenizers"),mo.forEach(t),hi.forEach(t),Na=f(e),Re=o(e,"DIV",{class:!0});var uo=s(Re);h(De.$$.fragment,uo),uo.forEach(t),Ha=f(e),nt=o(e,"P",{});var co=s(nt);Mr=c(co,"Lucile is a machine learning engineer at Hugging Face, developing and supporting the use of open source tools. She is also actively involved in many research projects in the field of Natural Language Processing such as collaborative training and BigScience."),co.forEach(t),Ra=f(e),j=o(e,"P",{});var di=s(j);Ft=o(di,"STRONG",{});var po=s(Ft);Sr=c(po,"Sylvain Gugger:"),po.forEach(t),Pr=f(di),Ot=o(di,"EM",{});var ho=s(Ot);Tr=c(ho,"Supercharge your PyTorch training loop with \u{1F917} Accelerate"),ho.forEach(t),di.forEach(t),Da=f(e),Fe=o(e,"DIV",{class:!0});var go=s(Fe);h(Oe.$$.fragment,go),go.forEach(t),Fa=f(e),ot=o(e,"P",{});var vo=s(ot);Ir=c(vo,"Sylvain is a Research Engineer at Hugging Face and one of the core maintainers of \u{1F917} Transformers and the developer behind \u{1F917} Accelerate. He likes making model training more accessible."),vo.forEach(t),Oa=f(e),z=o(e,"P",{});var gi=s(z);xt=o(gi,"STRONG",{});var wo=s(xt);Lr=c(wo,"Merve Noyan:"),wo.forEach(t),Gr=f(gi),Ct=o(gi,"EM",{});var yo=s(Ct);Nr=c(yo,"Showcase your model demos with \u{1F917} Spaces"),yo.forEach(t),gi.forEach(t),xa=f(e),xe=o(e,"DIV",{class:!0});var Eo=s(xe);h(Ce.$$.fragment,Eo),Eo.forEach(t),Ca=f(e),st=o(e,"P",{});var _o=s(st);Hr=c(_o,"Merve is a developer advocate at Hugging Face, working on developing tools and building content around them to democratize machine learning for everyone."),_o.forEach(t),ja=f(e),B=o(e,"P",{});var vi=s(B);jt=o(vi,"STRONG",{});var $o=s(jt);Rr=c($o,"Abubakar Abid:"),$o.forEach(t),Dr=f(vi),zt=o(vi,"EM",{});var bo=s(zt);Fr=c(bo,"Building Machine Learning Applications Fast"),bo.forEach(t),vi.forEach(t),za=f(e),je=o(e,"DIV",{class:!0});var ko=s(je);h(ze.$$.fragment,ko),ko.forEach(t),Ba=f(e),Be=o(e,"P",{align:!0});var Ao=s(Be);We=o(Ao,"IMG",{src:!0,alt:!0,width:!0}),Ao.forEach(t),Wa=f(e),W=o(e,"P",{});var wi=s(W);Or=c(wi,"Abubakar Abid is the CEO of "),lt=o(wi,"A",{href:!0});var Mo=s(lt);xr=c(Mo,"Gradio"),Mo.forEach(t),Cr=c(wi,". He received his Bachelor\u2019s of Science in Electrical Engineering and Computer Science from MIT in 2015, and his PhD in Applied Machine Learning from Stanford in 2021. In his role as the CEO of Gradio, Abubakar works on making machine learning models easier to demo, debug, and deploy."),wi.forEach(t),Va=f(e),V=o(e,"P",{});var yi=s(V);Bt=o(yi,"STRONG",{});var So=s(Bt);jr=c(So,"Mathieu Desv\xE9:"),So.forEach(t),zr=f(yi),Wt=o(yi,"EM",{});var Po=s(Wt);Br=c(Po,"AWS ML Vision: Making Machine Learning Accessible to all Customers"),Po.forEach(t),yi.forEach(t),Ua=f(e),Ve=o(e,"DIV",{class:!0});var To=s(Ve);h(Ue.$$.fragment,To),To.forEach(t),Ja=f(e),Je=o(e,"P",{align:!0});var Io=s(Je);Ke=o(Io,"IMG",{src:!0,alt:!0,width:!0}),Io.forEach(t),Ka=f(e),ft=o(e,"P",{});var Lo=s(ft);Wr=c(Lo,"Technology enthusiast, maker on my free time. I like challenges and solving problem of clients and users, and work with talented people to learn every day. Since 2004, I work in multiple positions switching from frontend, backend, infrastructure, operations and managements. Try to solve commons technical and managerial issues in agile manner."),Lo.forEach(t),Ya=f(e),U=o(e,"P",{});var Ei=s(U);Vt=o(Ei,"STRONG",{});var Go=s(Vt);Vr=c(Go,"Philipp Schmid:"),Go.forEach(t),Ur=f(Ei),Ut=o(Ei,"EM",{});var No=s(Ut);Jr=c(No,"Managed Training with Amazon SageMaker and \u{1F917} Transformers"),No.forEach(t),Ei.forEach(t),Qa=f(e),Ye=o(e,"DIV",{class:!0});var Ho=s(Ye);h(Qe.$$.fragment,Ho),Ho.forEach(t),qa=f(e),mt=o(e,"P",{});var Ro=s(mt);Kr=c(Ro,"Philipp Schmid is a Machine Learning Engineer and Tech Lead at Hugging Face, where he leads the collaboration with the Amazon SageMaker team. He is passionate about democratizing and productionizing cutting-edge NLP models and improving the ease of use for Deep Learning."),Ro.forEach(t),this.h()},h(){m(_,"name","hf:doc:metadata"),m(_,"content",JSON.stringify(Bo)),m(M,"id","part-2-release-event"),m(M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(M,"href","#part-2-release-event"),m($,"class","relative group"),m(S,"id","day-1-a-highlevel-view-of-transformers-and-how-to-train-them"),m(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(S,"href","#day-1-a-highlevel-view-of-transformers-and-how-to-train-them"),m(b,"class","relative group"),m(Q,"class","flex justify-center"),A(Z.src,qr="https://i.imgur.com/9eq8oUi.png")||m(Z,"src",qr),m(Z,"alt","A visual summary of Thom's talk"),m(Z,"width","80%"),m(X,"align","center"),m(ee,"href","https://bigscience.huggingface.co"),m(ee,"rel","nofollow"),m(te,"href","https://github.com/huggingface/"),m(te,"rel","nofollow"),m(ae,"href","https://thomwolf.io"),m(ae,"rel","nofollow"),m(ie,"class","flex justify-center"),A(oe.src,Xr="https://i.imgur.com/rOZAuE9.png")||m(oe,"src",Xr),m(oe,"alt","A visual summary of Jay's talk"),m(oe,"width","80%"),m(ne,"align","center"),m(se,"class","flex justify-center"),A(me.src,Zr="https://i.imgur.com/NuIsnY3.png")||m(me,"src",Zr),m(me,"alt","A visual summary of Margaret's talk"),m(me,"width","80%"),m(fe,"align","center"),m(ue,"class","flex justify-center"),A(he.src,en="https://i.imgur.com/1vD2az8.png")||m(he,"src",en),m(he,"alt","A visual summary of Matt and Chen's talk"),m(he,"width","80%"),m(pe,"align","center"),m(de,"class","flex justify-center"),A(we.src,tn="https://i.imgur.com/TPmlkm8.png")||m(we,"src",tn),m(we,"alt","A visual summary of Mark's talk"),m(we,"width","80%"),m(ve,"align","center"),m(ye,"href","http://yuri.ai/"),m(ye,"rel","nofollow"),m(_e,"class","flex justify-center"),A(ke.src,an="https://i.imgur.com/5dWQeNB.png")||m(ke,"src",an),m(ke,"alt","A visual summary of Jakob's talk"),m(ke,"width","80%"),m(be,"align","center"),m(R,"id","day-2-the-tools-to-use"),m(R,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(R,"href","#day-2-the-tools-to-use"),m(k,"class","relative group"),m(Me,"class","flex justify-center"),m(Pe,"href","https://www.oreilly.com/library/view/natural-language-processing/9781098103231/"),m(Pe,"rel","nofollow"),m(Te,"class","flex justify-center"),m(Le,"class","flex justify-center"),A(He.src,rn="https://i.imgur.com/TarIPCz.png")||m(He,"src",rn),m(He,"alt","A visual summary of Lysandre's talk"),m(He,"width","80%"),m(Ne,"align","center"),m(Re,"class","flex justify-center"),m(Fe,"class","flex justify-center"),m(xe,"class","flex justify-center"),m(je,"class","flex justify-center"),A(We.src,nn="https://i.imgur.com/qWIFeiF.png")||m(We,"src",nn),m(We,"alt","A visual summary of Abubakar's talk"),m(We,"width","80%"),m(Be,"align","center"),m(lt,"href","www.gradio.app"),m(Ve,"class","flex justify-center"),A(Ke.src,on="https://i.imgur.com/oLdZTKy.png")||m(Ke,"src",on),m(Ke,"alt","A visual summary of Mathieu's talk"),m(Ke,"width","80%"),m(Je,"align","center"),m(Ye,"class","flex justify-center")},m(e,i){a(document.head,_),r(e,Jt,i),r(e,$,i),a($,M),a(M,ut),d(K,ut,null),a($,_i),a($,ct),a(ct,$i),r(e,Kt,i),r(e,qe,i),a(qe,bi),r(e,Yt,i),r(e,b,i),a(b,S),a(S,pt),d(Y,pt,null),a(b,ki),a(b,ht),a(ht,Ai),r(e,Qt,i),r(e,P,i),a(P,dt),a(dt,Mi),a(P,Si),a(P,gt),a(gt,Pi),r(e,qt,i),r(e,Q,i),d(q,Q,null),r(e,Xt,i),r(e,X,i),a(X,Z),r(e,Zt,i),r(e,E,i),a(E,Ti),a(E,ee),a(ee,Ii),a(E,Li),a(E,te),a(te,Gi),a(E,Ni),a(E,ae),a(ae,Hi),a(E,Ri),r(e,ea,i),r(e,T,i),a(T,vt),a(vt,Di),a(T,Fi),a(T,wt),a(wt,Oi),r(e,ta,i),r(e,ie,i),d(re,ie,null),r(e,aa,i),r(e,ne,i),a(ne,oe),r(e,ia,i),r(e,Xe,i),a(Xe,xi),r(e,ra,i),r(e,I,i),a(I,yt),a(yt,Ci),a(I,ji),a(I,Et),a(Et,zi),r(e,na,i),r(e,se,i),d(le,se,null),r(e,oa,i),r(e,fe,i),a(fe,me),r(e,sa,i),r(e,Ze,i),a(Ze,Bi),r(e,la,i),r(e,L,i),a(L,_t),a(_t,Wi),a(L,Vi),a(L,$t),a($t,Ui),r(e,fa,i),r(e,ue,i),d(ce,ue,null),r(e,ma,i),r(e,pe,i),a(pe,he),r(e,ua,i),r(e,et,i),a(et,Ji),r(e,ca,i),r(e,tt,i),a(tt,Ki),r(e,pa,i),r(e,G,i),a(G,bt),a(bt,Yi),a(G,Qi),a(G,kt),a(kt,qi),r(e,ha,i),r(e,de,i),d(ge,de,null),r(e,da,i),r(e,ve,i),a(ve,we),r(e,ga,i),r(e,N,i),a(N,Xi),a(N,ye),a(ye,Zi),a(N,er),r(e,va,i),r(e,H,i),a(H,At),a(At,tr),a(H,ar),a(H,Ee),a(Ee,ir),a(Ee,Mt),a(Mt,rr),a(Ee,nr),r(e,wa,i),r(e,_e,i),d($e,_e,null),r(e,ya,i),r(e,be,i),a(be,ke),r(e,Ea,i),r(e,at,i),a(at,or),r(e,_a,i),r(e,k,i),a(k,R),a(R,St),d(Ae,St,null),a(k,sr),a(k,Pt),a(Pt,lr),r(e,$a,i),r(e,D,i),a(D,Tt),a(Tt,fr),a(D,mr),a(D,It),a(It,ur),r(e,ba,i),r(e,Me,i),d(Se,Me,null),r(e,ka,i),r(e,F,i),a(F,cr),a(F,Pe),a(Pe,pr),a(F,hr),r(e,Aa,i),r(e,O,i),a(O,Lt),a(Lt,dr),a(O,gr),a(O,Gt),a(Gt,vr),r(e,Ma,i),r(e,Te,i),d(Ie,Te,null),r(e,Sa,i),r(e,it,i),a(it,wr),r(e,Pa,i),r(e,x,i),a(x,Nt),a(Nt,yr),a(x,Er),a(x,Ht),a(Ht,_r),r(e,Ta,i),r(e,Le,i),d(Ge,Le,null),r(e,Ia,i),r(e,Ne,i),a(Ne,He),r(e,La,i),r(e,rt,i),a(rt,$r),r(e,Ga,i),r(e,C,i),a(C,Rt),a(Rt,br),a(C,kr),a(C,Dt),a(Dt,Ar),r(e,Na,i),r(e,Re,i),d(De,Re,null),r(e,Ha,i),r(e,nt,i),a(nt,Mr),r(e,Ra,i),r(e,j,i),a(j,Ft),a(Ft,Sr),a(j,Pr),a(j,Ot),a(Ot,Tr),r(e,Da,i),r(e,Fe,i),d(Oe,Fe,null),r(e,Fa,i),r(e,ot,i),a(ot,Ir),r(e,Oa,i),r(e,z,i),a(z,xt),a(xt,Lr),a(z,Gr),a(z,Ct),a(Ct,Nr),r(e,xa,i),r(e,xe,i),d(Ce,xe,null),r(e,Ca,i),r(e,st,i),a(st,Hr),r(e,ja,i),r(e,B,i),a(B,jt),a(jt,Rr),a(B,Dr),a(B,zt),a(zt,Fr),r(e,za,i),r(e,je,i),d(ze,je,null),r(e,Ba,i),r(e,Be,i),a(Be,We),r(e,Wa,i),r(e,W,i),a(W,Or),a(W,lt),a(lt,xr),a(W,Cr),r(e,Va,i),r(e,V,i),a(V,Bt),a(Bt,jr),a(V,zr),a(V,Wt),a(Wt,Br),r(e,Ua,i),r(e,Ve,i),d(Ue,Ve,null),r(e,Ja,i),r(e,Je,i),a(Je,Ke),r(e,Ka,i),r(e,ft,i),a(ft,Wr),r(e,Ya,i),r(e,U,i),a(U,Vt),a(Vt,Vr),a(U,Ur),a(U,Ut),a(Ut,Jr),r(e,Qa,i),r(e,Ye,i),d(Qe,Ye,null),r(e,qa,i),r(e,mt,i),a(mt,Kr),Xa=!0},p:Co,i(e){Xa||(g(K.$$.fragment,e),g(Y.$$.fragment,e),g(q.$$.fragment,e),g(re.$$.fragment,e),g(le.$$.fragment,e),g(ce.$$.fragment,e),g(ge.$$.fragment,e),g($e.$$.fragment,e),g(Ae.$$.fragment,e),g(Se.$$.fragment,e),g(Ie.$$.fragment,e),g(Ge.$$.fragment,e),g(De.$$.fragment,e),g(Oe.$$.fragment,e),g(Ce.$$.fragment,e),g(ze.$$.fragment,e),g(Ue.$$.fragment,e),g(Qe.$$.fragment,e),Xa=!0)},o(e){v(K.$$.fragment,e),v(Y.$$.fragment,e),v(q.$$.fragment,e),v(re.$$.fragment,e),v(le.$$.fragment,e),v(ce.$$.fragment,e),v(ge.$$.fragment,e),v($e.$$.fragment,e),v(Ae.$$.fragment,e),v(Se.$$.fragment,e),v(Ie.$$.fragment,e),v(Ge.$$.fragment,e),v(De.$$.fragment,e),v(Oe.$$.fragment,e),v(Ce.$$.fragment,e),v(ze.$$.fragment,e),v(Ue.$$.fragment,e),v(Qe.$$.fragment,e),Xa=!1},d(e){t(_),e&&t(Jt),e&&t($),w(K),e&&t(Kt),e&&t(qe),e&&t(Yt),e&&t(b),w(Y),e&&t(Qt),e&&t(P),e&&t(qt),e&&t(Q),w(q),e&&t(Xt),e&&t(X),e&&t(Zt),e&&t(E),e&&t(ea),e&&t(T),e&&t(ta),e&&t(ie),w(re),e&&t(aa),e&&t(ne),e&&t(ia),e&&t(Xe),e&&t(ra),e&&t(I),e&&t(na),e&&t(se),w(le),e&&t(oa),e&&t(fe),e&&t(sa),e&&t(Ze),e&&t(la),e&&t(L),e&&t(fa),e&&t(ue),w(ce),e&&t(ma),e&&t(pe),e&&t(ua),e&&t(et),e&&t(ca),e&&t(tt),e&&t(pa),e&&t(G),e&&t(ha),e&&t(de),w(ge),e&&t(da),e&&t(ve),e&&t(ga),e&&t(N),e&&t(va),e&&t(H),e&&t(wa),e&&t(_e),w($e),e&&t(ya),e&&t(be),e&&t(Ea),e&&t(at),e&&t(_a),e&&t(k),w(Ae),e&&t($a),e&&t(D),e&&t(ba),e&&t(Me),w(Se),e&&t(ka),e&&t(F),e&&t(Aa),e&&t(O),e&&t(Ma),e&&t(Te),w(Ie),e&&t(Sa),e&&t(it),e&&t(Pa),e&&t(x),e&&t(Ta),e&&t(Le),w(Ge),e&&t(Ia),e&&t(Ne),e&&t(La),e&&t(rt),e&&t(Ga),e&&t(C),e&&t(Na),e&&t(Re),w(De),e&&t(Ha),e&&t(nt),e&&t(Ra),e&&t(j),e&&t(Da),e&&t(Fe),w(Oe),e&&t(Fa),e&&t(ot),e&&t(Oa),e&&t(z),e&&t(xa),e&&t(xe),w(Ce),e&&t(Ca),e&&t(st),e&&t(ja),e&&t(B),e&&t(za),e&&t(je),w(ze),e&&t(Ba),e&&t(Be),e&&t(Wa),e&&t(W),e&&t(Va),e&&t(V),e&&t(Ua),e&&t(Ve),w(Ue),e&&t(Ja),e&&t(Je),e&&t(Ka),e&&t(ft),e&&t(Ya),e&&t(U),e&&t(Qa),e&&t(Ye),w(Qe),e&&t(qa),e&&t(mt)}}}const Bo={local:"part-2-release-event",sections:[{local:"day-1-a-highlevel-view-of-transformers-and-how-to-train-them",title:"Day 1: A high-level view of Transformers and how to train them"},{local:"day-2-the-tools-to-use",title:"Day 2: The tools to use"}],title:"Part 2 Release Event"};function Wo(Qr){return jo(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ko extends Do{constructor(_){super();Fo(this,_,Wo,zo,Oo,{})}}export{Ko as default,Bo as metadata};
