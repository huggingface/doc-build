import{S as ut,i as mt,s as wt,e as r,k as c,w as x,t as f,l as pt,M as $t,c as s,d as t,m as d,x as _,a as n,h as p,b as h,G as a,g as l,y as b,o as v,p as vt,q as g,B as k,v as gt,n as yt}from"../../chunks/vendor-hf-doc-builder.js";import{I as xe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{Q as _e}from"../../chunks/Question-hf-doc-builder.js";import{F as xt}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function _t(Fe){let $,E,T,S,j,y,ue,O,be,me,de,Z,ne,K,C,q,I,G,ie,he,ee,L,ve,F,D,fe,P,z,te,W,J,A,ae,Y,X,we,M,le,Q;return S=new xe({}),C=new _e({props:{choices:[{text:"Nothing, but you get a warning.",explain:"You do get a warning, but that's not all!"},{text:"The head of the pretrained model is discarded and a new head suitable for the task is inserted instead.",explain:"Correct. For example, when we used <code>TFAutoModelForSequenceClassification</code> with <code>bert-base-uncased</code>, we got warnings when instantiating the model. The pretrained head is not used for the sequence classification task, so it's discarded and a new head is instantiated with random weights.",correct:!0},{text:"The head of the pretrained model is discarded.",explain:"Something else needs to happen. Try again!"},{text:"Nothing, since the model can still be fine-tuned for the different task.",explain:"The head of the pretrained model was not trained to solve this task, so we should discard the head!"}]}}),he=new xe({}),z=new _e({props:{choices:[{text:"The models work on a TPU out of the box.",explain:"Almost! There are some small additional changes required. For example, you need to run everything in a <code>TPUStrategy</code> scope, including the initialization of the model."},{text:"You can leverage existing methods such as <code>compile()</code>, <code>fit()</code>, and <code>predict()</code>.",explain:"Correct! Once you have the data, training on it requires very little work.",correct:!0},{text:"You get to learn Keras as well as transformers.",explain:"Correct, but we're looking for something else :)",correct:!0},{text:"You can easily compute metrics related to the dataset.",explain:"Keras helps us with training and evaluating the model, not computing dataset-related metrics."}]}}),ae=new xe({}),le=new _e({props:{choices:[{text:"By subclassing <code>tf.keras.metrics.Metric</code>.",explain:"Great!",correct:!0},{text:"Using the Keras functional API.",explain:"Try again!"},{text:"By using a callable with signature <code>metric_fn(y_true, y_pred)</code>.",explain:"Correct!",correct:!0},{text:"By Googling it.",explain:"That's not the answer we're looking for, but it should help you find it.",correct:!0}]}}),{c(){$=r("h3"),E=r("a"),T=r("span"),x(S.$$.fragment),j=c(),y=r("span"),ue=f("4. What happens when you instantiate one of the "),O=r("code"),be=f("TFAutoModelForXxx"),me=f(" classes with a pretrained language model (such as "),de=r("code"),Z=f("bert-base-uncased"),ne=f(") that corresponds to a different task than the one for which it was trained?"),K=c(),x(C.$$.fragment),q=c(),I=r("h3"),G=r("a"),ie=r("span"),x(he.$$.fragment),ee=c(),L=r("span"),ve=f("5. The TensorFlow models from "),F=r("code"),D=f("transformers"),fe=f(" are already Keras models. What benefit does this offer?"),P=c(),x(z.$$.fragment),te=c(),W=r("h3"),J=r("a"),A=r("span"),x(ae.$$.fragment),Y=c(),X=r("span"),we=f("6. How can you define your own custom metric?"),M=c(),x(le.$$.fragment),this.h()},l(i){$=s(i,"H3",{class:!0});var w=n($);E=s(w,"A",{id:!0,class:!0,href:!0});var ke=n(E);T=s(ke,"SPAN",{});var oe=n(T);_(S.$$.fragment,oe),oe.forEach(t),ke.forEach(t),j=d(w),y=s(w,"SPAN",{});var H=n(y);ue=p(H,"4. What happens when you instantiate one of the "),O=s(H,"CODE",{});var ge=n(O);be=p(ge,"TFAutoModelForXxx"),ge.forEach(t),me=p(H," classes with a pretrained language model (such as "),de=s(H,"CODE",{});var pe=n(de);Z=p(pe,"bert-base-uncased"),pe.forEach(t),ne=p(H,") that corresponds to a different task than the one for which it was trained?"),H.forEach(t),w.forEach(t),K=d(i),_(C.$$.fragment,i),q=d(i),I=s(i,"H3",{class:!0});var $e=n(I);G=s($e,"A",{id:!0,class:!0,href:!0});var re=n(G);ie=s(re,"SPAN",{});var Ee=n(ie);_(he.$$.fragment,Ee),Ee.forEach(t),re.forEach(t),ee=d($e),L=s($e,"SPAN",{});var B=n(L);ve=p(B,"5. The TensorFlow models from "),F=s(B,"CODE",{});var U=n(F);D=p(U,"transformers"),U.forEach(t),fe=p(B," are already Keras models. What benefit does this offer?"),B.forEach(t),$e.forEach(t),P=d(i),_(z.$$.fragment,i),te=d(i),W=s(i,"H3",{class:!0});var ce=n(W);J=s(ce,"A",{id:!0,class:!0,href:!0});var N=n(J);A=s(N,"SPAN",{});var R=n(A);_(ae.$$.fragment,R),R.forEach(t),N.forEach(t),Y=d(ce),X=s(ce,"SPAN",{});var V=n(X);we=p(V,"6. How can you define your own custom metric?"),V.forEach(t),ce.forEach(t),M=d(i),_(le.$$.fragment,i),this.h()},h(){h(E,"id","4.-what-happens-when-you-instantiate-one-of-the-<code>tfautomodelforxxx</code>-classes-with-a-pretrained-language-model-(such-as-<code>bert-base-uncased</code>)-that-corresponds-to-a-different-task-than-the-one-for-which-it-was-trained?"),h(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(E,"href","#4.-what-happens-when-you-instantiate-one-of-the-<code>tfautomodelforxxx</code>-classes-with-a-pretrained-language-model-(such-as-<code>bert-base-uncased</code>)-that-corresponds-to-a-different-task-than-the-one-for-which-it-was-trained?"),h($,"class","relative group"),h(G,"id","5.-the-tensorflow-models-from-<code>transformers</code>-are-already-keras-models.-what-benefit-does-this-offer?"),h(G,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(G,"href","#5.-the-tensorflow-models-from-<code>transformers</code>-are-already-keras-models.-what-benefit-does-this-offer?"),h(I,"class","relative group"),h(J,"id","6.-how-can-you-define-your-own-custom-metric?"),h(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(J,"href","#6.-how-can-you-define-your-own-custom-metric?"),h(W,"class","relative group")},m(i,w){l(i,$,w),a($,E),a(E,T),b(S,T,null),a($,j),a($,y),a(y,ue),a(y,O),a(O,be),a(y,me),a(y,de),a(de,Z),a(y,ne),l(i,K,w),b(C,i,w),l(i,q,w),l(i,I,w),a(I,G),a(G,ie),b(he,ie,null),a(I,ee),a(I,L),a(L,ve),a(L,F),a(F,D),a(L,fe),l(i,P,w),b(z,i,w),l(i,te,w),l(i,W,w),a(W,J),a(J,A),b(ae,A,null),a(W,Y),a(W,X),a(X,we),l(i,M,w),b(le,i,w),Q=!0},i(i){Q||(g(S.$$.fragment,i),g(C.$$.fragment,i),g(he.$$.fragment,i),g(z.$$.fragment,i),g(ae.$$.fragment,i),g(le.$$.fragment,i),Q=!0)},o(i){v(S.$$.fragment,i),v(C.$$.fragment,i),v(he.$$.fragment,i),v(z.$$.fragment,i),v(ae.$$.fragment,i),v(le.$$.fragment,i),Q=!1},d(i){i&&t($),k(S),i&&t(K),k(C,i),i&&t(q),i&&t(I),k(he),i&&t(P),k(z,i),i&&t(te),i&&t(W),k(ae),i&&t(M),k(le,i)}}}function bt(Fe){let $,E,T,S,j,y,ue,O,be,me,de,Z,ne,K,C,q,I,G,ie,he,ee,L,ve,F,D,fe,P,z,te,W,J,A,ae,Y,X,we,M,le,Q,i,w,ke,oe,H,ge,pe,$e,re,Ee,B,U,ce,N,R,V,qe,Ie,Te,Le,o,u,ye,se,Ae,We,Se,Pe,He,Ye,Ce,Ne,De;return S=new xe({}),Z=new _e({props:{choices:[{text:"The results of the function are cached, so it won't take any time if we re-execute the code.",explain:"That is indeed one of the neat benefits of this method! It's not the only one, though...",correct:!0},{text:"It can apply multiprocessing to go faster than applying the function on each element of the dataset.",explain:"This is a neat feature of this method, but it's not the only one!",correct:!0},{text:"It does not load the whole dataset into memory, saving the results as soon as one element is processed.",explain:"That's one advantage of this method. There are others, though!",correct:!0}]}}),I=new xe({}),L=new _e({props:{choices:[{text:"It's when you pad the inputs for each batch to the maximum length in the whole dataset.",explain:"It does imply padding when creating the batch, but not to the maximum length in the whole dataset."},{text:"It's when you pad your inputs when the batch is created, to the maximum length of the sentences inside that batch.",explain:`That's correct! The "dynamic" part comes from the fact that the size of each batch is determined at the time of creation, and all your batches might have different shapes as a result.`,correct:!0},{text:"It's when you pad your inputs so that each sentence has the same number of tokens as the previous one in the dataset.",explain:"That's incorrect, plus it doesn't make sense to look at the order in the dataset since we shuffle it during training."}]}}),P=new xe({}),A=new _e({props:{choices:[{text:"It ensures all the sequences in the dataset have the same length.",explain:"A collate function is involved in handling individual batches, not the whole dataset. Additionally, we're talking about generic collate functions, not <code>DataCollatorWithPadding</code> specifically."},{text:"It puts together all the samples in a batch.",explain:"Correct! You can pass the collate function as an argument of a <code>DataLoader</code>. We used the <code>DataCollatorWithPadding</code> function, which pads all items in a batch so they have the same length.",correct:!0},{text:"It preprocesses the whole dataset.",explain:"That would be a preprocessing function, not a collate function."},{text:"It truncates the sequences in the dataset.",explain:"A collate function is involved in handling individual batches, not the whole dataset. If you're interested in truncating, you can use the <code>truncate</code> argument of <code>tokenizer</code>."}]}}),M=new xe({}),re=new _e({props:{choices:[{text:"Nothing, but you get a warning.",explain:"You do get a warning, but that's not all!"},{text:"The head of the pretrained model is discarded and a new head suitable for the task is inserted instead.",explain:"Correct. For example, when we used <code>AutoModelForSequenceClassification</code> with <code>bert-base-uncased</code>, we got warnings when instantiating the model. The pretrained head is not used for the sequence classification task, so it's discarded and a new head is instantiated with random weights.",correct:!0},{text:"The head of the pretrained model is discarded.",explain:"Something else needs to happen. Try again!"},{text:"Nothing, since the model can still be fine-tuned for the different task.",explain:"The head of the pretrained model was not trained to solve this task, so we should discard the head!"}]}}),N=new xe({}),u=new _e({props:{choices:[{text:"It contains all the hyperparameters used for training and evaluation with the <code>Trainer</code>.",explain:"Correct!",correct:!0},{text:"It specifies the size of the model.",explain:"The model size is defined by the model configuration, not the class <code>TrainingArguments</code>."},{text:"It just contains the hyperparameters used for evaluation.",explain:"In the example, we specified where the model and its checkpoints will be saved. Try again!"},{text:"It just contains the hyperparameters used for training.",explain:"In the example, we used an <code>evaluation_strategy</code> as well, so this impacts evaluation. Try again!"}]}}),Se=new xe({}),Ne=new _e({props:{choices:[{text:"It provides access to faster models.",explain:"No, the \u{1F917} Accelerate library does not provide any models."},{text:"It provides a high-level API so I don't have to implement my own training loop.",explain:"This is what we did with <code>Trainer</code>, not the \u{1F917} Accelerate library. Try again!"},{text:"It makes our training loops work on distributed strategies",explain:"Correct! With \u{1F917} Accelerate, your training loops will work for multiple GPUs and TPUs.",correct:!0},{text:"It provides more optimization functions.",explain:"No, the \u{1F917} Accelerate library does not provide any optimization functions."}]}}),{c(){$=r("h3"),E=r("a"),T=r("span"),x(S.$$.fragment),j=c(),y=r("span"),ue=f("4. What are the benefits of the "),O=r("code"),be=f("Dataset.map()"),me=f(" method?"),de=c(),x(Z.$$.fragment),ne=c(),K=r("h3"),C=r("a"),q=r("span"),x(I.$$.fragment),G=c(),ie=r("span"),he=f("5. What does dynamic padding mean?"),ee=c(),x(L.$$.fragment),ve=c(),F=r("h3"),D=r("a"),fe=r("span"),x(P.$$.fragment),z=c(),te=r("span"),W=f("6. What is the purpose of a collate function?"),J=c(),x(A.$$.fragment),ae=c(),Y=r("h3"),X=r("a"),we=r("span"),x(M.$$.fragment),le=c(),Q=r("span"),i=f("7. What happens when you instantiate one of the "),w=r("code"),ke=f("AutoModelForXxx"),oe=f(" classes with a pretrained language model (such as "),H=r("code"),ge=f("bert-base-uncased"),pe=f(") that corresponds to a different task than the one for which it was trained?"),$e=c(),x(re.$$.fragment),Ee=c(),B=r("h3"),U=r("a"),ce=r("span"),x(N.$$.fragment),R=c(),V=r("span"),qe=f("8. What\u2019s the purpose of "),Ie=r("code"),Te=f("TrainingArguments"),Le=f("?"),o=c(),x(u.$$.fragment),ye=c(),se=r("h3"),Ae=r("a"),We=r("span"),x(Se.$$.fragment),Pe=c(),He=r("span"),Ye=f("9. Why should you use the \u{1F917} Accelerate library?"),Ce=c(),x(Ne.$$.fragment),this.h()},l(e){$=s(e,"H3",{class:!0});var m=n($);E=s(m,"A",{id:!0,class:!0,href:!0});var Ue=n(E);T=s(Ue,"SPAN",{});var ze=n(T);_(S.$$.fragment,ze),ze.forEach(t),Ue.forEach(t),j=d(m),y=s(m,"SPAN",{});var Me=n(y);ue=p(Me,"4. What are the benefits of the "),O=s(Me,"CODE",{});var Ke=n(O);be=p(Ke,"Dataset.map()"),Ke.forEach(t),me=p(Me," method?"),Me.forEach(t),m.forEach(t),de=d(e),_(Z.$$.fragment,e),ne=d(e),K=s(e,"H3",{class:!0});var Oe=n(K);C=s(Oe,"A",{id:!0,class:!0,href:!0});var Je=n(C);q=s(Je,"SPAN",{});var Ve=n(q);_(I.$$.fragment,Ve),Ve.forEach(t),Je.forEach(t),G=d(Oe),ie=s(Oe,"SPAN",{});var Ze=n(ie);he=p(Ze,"5. What does dynamic padding mean?"),Ze.forEach(t),Oe.forEach(t),ee=d(e),_(L.$$.fragment,e),ve=d(e),F=s(e,"H3",{class:!0});var Ge=n(F);D=s(Ge,"A",{id:!0,class:!0,href:!0});var et=n(D);fe=s(et,"SPAN",{});var tt=n(fe);_(P.$$.fragment,tt),tt.forEach(t),et.forEach(t),z=d(Ge),te=s(Ge,"SPAN",{});var at=n(te);W=p(at,"6. What is the purpose of a collate function?"),at.forEach(t),Ge.forEach(t),J=d(e),_(A.$$.fragment,e),ae=d(e),Y=s(e,"H3",{class:!0});var Xe=n(Y);X=s(Xe,"A",{id:!0,class:!0,href:!0});var ot=n(X);we=s(ot,"SPAN",{});var rt=n(we);_(M.$$.fragment,rt),rt.forEach(t),ot.forEach(t),le=d(Xe),Q=s(Xe,"SPAN",{});var Be=n(Q);i=p(Be,"7. What happens when you instantiate one of the "),w=s(Be,"CODE",{});var st=n(w);ke=p(st,"AutoModelForXxx"),st.forEach(t),oe=p(Be," classes with a pretrained language model (such as "),H=s(Be,"CODE",{});var nt=n(H);ge=p(nt,"bert-base-uncased"),nt.forEach(t),pe=p(Be,") that corresponds to a different task than the one for which it was trained?"),Be.forEach(t),Xe.forEach(t),$e=d(e),_(re.$$.fragment,e),Ee=d(e),B=s(e,"H3",{class:!0});var Qe=n(B);U=s(Qe,"A",{id:!0,class:!0,href:!0});var it=n(U);ce=s(it,"SPAN",{});var ht=n(ce);_(N.$$.fragment,ht),ht.forEach(t),it.forEach(t),R=d(Qe),V=s(Qe,"SPAN",{});var Re=n(V);qe=p(Re,"8. What\u2019s the purpose of "),Ie=s(Re,"CODE",{});var lt=n(Ie);Te=p(lt,"TrainingArguments"),lt.forEach(t),Le=p(Re,"?"),Re.forEach(t),Qe.forEach(t),o=d(e),_(u.$$.fragment,e),ye=d(e),se=s(e,"H3",{class:!0});var je=n(se);Ae=s(je,"A",{id:!0,class:!0,href:!0});var ct=n(Ae);We=s(ct,"SPAN",{});var dt=n(We);_(Se.$$.fragment,dt),dt.forEach(t),ct.forEach(t),Pe=d(je),He=s(je,"SPAN",{});var ft=n(He);Ye=p(ft,"9. Why should you use the \u{1F917} Accelerate library?"),ft.forEach(t),je.forEach(t),Ce=d(e),_(Ne.$$.fragment,e),this.h()},h(){h(E,"id","4.-what-are-the-benefits-of-the-<code>dataset.map()</code>-method?"),h(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(E,"href","#4.-what-are-the-benefits-of-the-<code>dataset.map()</code>-method?"),h($,"class","relative group"),h(C,"id","5.-what-does-dynamic-padding-mean?"),h(C,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(C,"href","#5.-what-does-dynamic-padding-mean?"),h(K,"class","relative group"),h(D,"id","6.-what-is-the-purpose-of-a-collate-function?"),h(D,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(D,"href","#6.-what-is-the-purpose-of-a-collate-function?"),h(F,"class","relative group"),h(X,"id","7.-what-happens-when-you-instantiate-one-of-the-<code>automodelforxxx</code>-classes-with-a-pretrained-language-model-(such-as-<code>bert-base-uncased</code>)-that-corresponds-to-a-different-task-than-the-one-for-which-it-was-trained?"),h(X,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(X,"href","#7.-what-happens-when-you-instantiate-one-of-the-<code>automodelforxxx</code>-classes-with-a-pretrained-language-model-(such-as-<code>bert-base-uncased</code>)-that-corresponds-to-a-different-task-than-the-one-for-which-it-was-trained?"),h(Y,"class","relative group"),h(U,"id","8.-what\u2019s-the-purpose-of-<code>trainingarguments</code>?"),h(U,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(U,"href","#8.-what\u2019s-the-purpose-of-<code>trainingarguments</code>?"),h(B,"class","relative group"),h(Ae,"id","9.-why-should-you-use-the-\u{1F917}-accelerate-library?"),h(Ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ae,"href","#9.-why-should-you-use-the-\u{1F917}-accelerate-library?"),h(se,"class","relative group")},m(e,m){l(e,$,m),a($,E),a(E,T),b(S,T,null),a($,j),a($,y),a(y,ue),a(y,O),a(O,be),a(y,me),l(e,de,m),b(Z,e,m),l(e,ne,m),l(e,K,m),a(K,C),a(C,q),b(I,q,null),a(K,G),a(K,ie),a(ie,he),l(e,ee,m),b(L,e,m),l(e,ve,m),l(e,F,m),a(F,D),a(D,fe),b(P,fe,null),a(F,z),a(F,te),a(te,W),l(e,J,m),b(A,e,m),l(e,ae,m),l(e,Y,m),a(Y,X),a(X,we),b(M,we,null),a(Y,le),a(Y,Q),a(Q,i),a(Q,w),a(w,ke),a(Q,oe),a(Q,H),a(H,ge),a(Q,pe),l(e,$e,m),b(re,e,m),l(e,Ee,m),l(e,B,m),a(B,U),a(U,ce),b(N,ce,null),a(B,R),a(B,V),a(V,qe),a(V,Ie),a(Ie,Te),a(V,Le),l(e,o,m),b(u,e,m),l(e,ye,m),l(e,se,m),a(se,Ae),a(Ae,We),b(Se,We,null),a(se,Pe),a(se,He),a(He,Ye),l(e,Ce,m),b(Ne,e,m),De=!0},i(e){De||(g(S.$$.fragment,e),g(Z.$$.fragment,e),g(I.$$.fragment,e),g(L.$$.fragment,e),g(P.$$.fragment,e),g(A.$$.fragment,e),g(M.$$.fragment,e),g(re.$$.fragment,e),g(N.$$.fragment,e),g(u.$$.fragment,e),g(Se.$$.fragment,e),g(Ne.$$.fragment,e),De=!0)},o(e){v(S.$$.fragment,e),v(Z.$$.fragment,e),v(I.$$.fragment,e),v(L.$$.fragment,e),v(P.$$.fragment,e),v(A.$$.fragment,e),v(M.$$.fragment,e),v(re.$$.fragment,e),v(N.$$.fragment,e),v(u.$$.fragment,e),v(Se.$$.fragment,e),v(Ne.$$.fragment,e),De=!1},d(e){e&&t($),k(S),e&&t(de),k(Z,e),e&&t(ne),e&&t(K),k(I),e&&t(ee),k(L,e),e&&t(ve),e&&t(F),k(P),e&&t(J),k(A,e),e&&t(ae),e&&t(Y),k(M),e&&t($e),k(re,e),e&&t(Ee),e&&t(B),k(N),e&&t(o),k(u,e),e&&t(ye),e&&t(se),k(Se),e&&t(Ce),k(Ne,e)}}}function kt(Fe){let $,E,T,S,j,y,ue,O,be,me,de,Z,ne,K,C,q,I,G,ie,he,ee,L,ve,F,D,fe,P,z,te,W,J,A,ae,Y,X,we,M,le,Q,i,w,ke,oe,H,ge,pe,$e,re,Ee,B,U,ce,N,R,V,qe;T=new xt({props:{fw:Fe[0]}}),O=new xe({}),D=new _e({props:{choices:[{text:"Joy",explain:"Try again \u2014 this emotion is present in that dataset!"},{text:"Love",explain:"Try again \u2014 this emotion is present in that dataset!"},{text:"Confusion",explain:"Correct! Confusion is not one of the six basic emotions.",correct:!0},{text:"Surprise",explain:"Surprise! Try another one!"}]}}),W=new xe({}),w=new _e({props:{choices:[{text:"Sentiment classification",explain:"That's right! You can tell thanks to the tags.",correct:!0},{text:"Machine translation",explain:"That's not it \u2014 take another look at the <a href='https://huggingface.co/datasets/ar_sarcasm'>dataset card</a>!"},{text:"Named entity recognition",explain:"That's not it \u2014 take another look at the <a href='https://huggingface.co/datasets/ar_sarcasm'>dataset card</a>!"},{text:"Question answering",explain:"Alas, this question was not answered correctly. Try again!"}]}}),pe=new xe({}),U=new _e({props:{choices:[{text:"Tokens_of_sentence_1 [SEP] Tokens_of_sentence_2",explain:"A <code>[SEP]</code> special token is needed to separate the two sentences, but that's not the only thing!"},{text:"[CLS] Tokens_of_sentence_1 Tokens_of_sentence_2",explain:"A <code>[CLS]</code> special token is required at the beginning, but that's not the only thing!"},{text:"[CLS] Tokens_of_sentence_1 [SEP] Tokens_of_sentence_2 [SEP]",explain:"That's correct!",correct:!0},{text:"[CLS] Tokens_of_sentence_1 [SEP] Tokens_of_sentence_2",explain:"A <code>[CLS]</code> special token is needed at the beginning as well as a <code>[SEP]</code> special token to separate the two sentences, but that's not all!"}]}});const Ie=[bt,_t],Te=[];function Le(o,u){return o[0]==="pt"?0:1}return N=Le(Fe),R=Te[N]=Ie[N](Fe),{c(){$=r("meta"),E=c(),x(T.$$.fragment),S=c(),j=r("h1"),y=r("a"),ue=r("span"),x(O.$$.fragment),be=c(),me=r("span"),de=f("End-of-chapter quiz"),Z=c(),ne=r("p"),K=f("Test what you learned in this chapter!"),C=c(),q=r("h3"),I=f("1. The "),G=r("code"),ie=f("emotion"),he=f(" dataset contains Twitter messages labeled with emotions. Search for it in the "),ee=r("a"),L=f("Hub"),ve=f(", and read the dataset card. Which of these is not one of its basic emotions?"),F=c(),x(D.$$.fragment),fe=c(),P=r("h3"),z=r("a"),te=r("span"),x(W.$$.fragment),J=c(),A=r("span"),ae=f("2. Search for the "),Y=r("code"),X=f("ar_sarcasm"),we=f(" dataset in the "),M=r("a"),le=f("Hub"),Q=f(". Which task does it support?"),i=c(),x(w.$$.fragment),ke=c(),oe=r("h3"),H=r("a"),ge=r("span"),x(pe.$$.fragment),$e=c(),re=r("span"),Ee=f("3. How does the BERT model expect a pair of sentences to be processed?"),B=c(),x(U.$$.fragment),ce=c(),R.c(),V=pt(),this.h()},l(o){const u=$t('[data-svelte="svelte-1phssyn"]',document.head);$=s(u,"META",{name:!0,content:!0}),u.forEach(t),E=d(o),_(T.$$.fragment,o),S=d(o),j=s(o,"H1",{class:!0});var ye=n(j);y=s(ye,"A",{id:!0,class:!0,href:!0});var se=n(y);ue=s(se,"SPAN",{});var Ae=n(ue);_(O.$$.fragment,Ae),Ae.forEach(t),se.forEach(t),be=d(ye),me=s(ye,"SPAN",{});var We=n(me);de=p(We,"End-of-chapter quiz"),We.forEach(t),ye.forEach(t),Z=d(o),ne=s(o,"P",{});var Se=n(ne);K=p(Se,"Test what you learned in this chapter!"),Se.forEach(t),C=d(o),q=s(o,"H3",{});var Pe=n(q);I=p(Pe,"1. The "),G=s(Pe,"CODE",{});var He=n(G);ie=p(He,"emotion"),He.forEach(t),he=p(Pe," dataset contains Twitter messages labeled with emotions. Search for it in the "),ee=s(Pe,"A",{href:!0,rel:!0});var Ye=n(ee);L=p(Ye,"Hub"),Ye.forEach(t),ve=p(Pe,", and read the dataset card. Which of these is not one of its basic emotions?"),Pe.forEach(t),F=d(o),_(D.$$.fragment,o),fe=d(o),P=s(o,"H3",{class:!0});var Ce=n(P);z=s(Ce,"A",{id:!0,class:!0,href:!0});var Ne=n(z);te=s(Ne,"SPAN",{});var De=n(te);_(W.$$.fragment,De),De.forEach(t),Ne.forEach(t),J=d(Ce),A=s(Ce,"SPAN",{});var e=n(A);ae=p(e,"2. Search for the "),Y=s(e,"CODE",{});var m=n(Y);X=p(m,"ar_sarcasm"),m.forEach(t),we=p(e," dataset in the "),M=s(e,"A",{href:!0,rel:!0});var Ue=n(M);le=p(Ue,"Hub"),Ue.forEach(t),Q=p(e,". Which task does it support?"),e.forEach(t),Ce.forEach(t),i=d(o),_(w.$$.fragment,o),ke=d(o),oe=s(o,"H3",{class:!0});var ze=n(oe);H=s(ze,"A",{id:!0,class:!0,href:!0});var Me=n(H);ge=s(Me,"SPAN",{});var Ke=n(ge);_(pe.$$.fragment,Ke),Ke.forEach(t),Me.forEach(t),$e=d(ze),re=s(ze,"SPAN",{});var Oe=n(re);Ee=p(Oe,"3. How does the BERT model expect a pair of sentences to be processed?"),Oe.forEach(t),ze.forEach(t),B=d(o),_(U.$$.fragment,o),ce=d(o),R.l(o),V=pt(),this.h()},h(){h($,"name","hf:doc:metadata"),h($,"content",JSON.stringify(Et)),h(y,"id","endofchapter-quiz"),h(y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(y,"href","#endofchapter-quiz"),h(j,"class","relative group"),h(ee,"href","https://huggingface.co/datasets"),h(ee,"rel","nofollow"),h(z,"id","2.-search-for-the-<code>ar_sarcasm</code>-dataset-in-the-hub.-which-task-does-it-support?"),h(z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(z,"href","#2.-search-for-the-<code>ar_sarcasm</code>-dataset-in-the-hub.-which-task-does-it-support?"),h(M,"href","https://huggingface.co/datasets"),h(M,"rel","nofollow"),h(P,"class","relative group"),h(H,"id","3.-how-does-the-bert-model-expect-a-pair-of-sentences-to-be-processed?"),h(H,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(H,"href","#3.-how-does-the-bert-model-expect-a-pair-of-sentences-to-be-processed?"),h(oe,"class","relative group")},m(o,u){a(document.head,$),l(o,E,u),b(T,o,u),l(o,S,u),l(o,j,u),a(j,y),a(y,ue),b(O,ue,null),a(j,be),a(j,me),a(me,de),l(o,Z,u),l(o,ne,u),a(ne,K),l(o,C,u),l(o,q,u),a(q,I),a(q,G),a(G,ie),a(q,he),a(q,ee),a(ee,L),a(q,ve),l(o,F,u),b(D,o,u),l(o,fe,u),l(o,P,u),a(P,z),a(z,te),b(W,te,null),a(P,J),a(P,A),a(A,ae),a(A,Y),a(Y,X),a(A,we),a(A,M),a(M,le),a(A,Q),l(o,i,u),b(w,o,u),l(o,ke,u),l(o,oe,u),a(oe,H),a(H,ge),b(pe,ge,null),a(oe,$e),a(oe,re),a(re,Ee),l(o,B,u),b(U,o,u),l(o,ce,u),Te[N].m(o,u),l(o,V,u),qe=!0},p(o,[u]){const ye={};u&1&&(ye.fw=o[0]),T.$set(ye);let se=N;N=Le(o),N!==se&&(yt(),v(Te[se],1,1,()=>{Te[se]=null}),vt(),R=Te[N],R||(R=Te[N]=Ie[N](o),R.c()),g(R,1),R.m(V.parentNode,V))},i(o){qe||(g(T.$$.fragment,o),g(O.$$.fragment,o),g(D.$$.fragment,o),g(W.$$.fragment,o),g(w.$$.fragment,o),g(pe.$$.fragment,o),g(U.$$.fragment,o),g(R),qe=!0)},o(o){v(T.$$.fragment,o),v(O.$$.fragment,o),v(D.$$.fragment,o),v(W.$$.fragment,o),v(w.$$.fragment,o),v(pe.$$.fragment,o),v(U.$$.fragment,o),v(R),qe=!1},d(o){t($),o&&t(E),k(T,o),o&&t(S),o&&t(j),k(O),o&&t(Z),o&&t(ne),o&&t(C),o&&t(q),o&&t(F),k(D,o),o&&t(fe),o&&t(P),k(W),o&&t(i),k(w,o),o&&t(ke),o&&t(oe),k(pe),o&&t(B),k(U,o),o&&t(ce),Te[N].d(o),o&&t(V)}}}const Et={local:"endofchapter-quiz",title:"End-of-chapter quiz"};function Tt(Fe,$,E){let T="pt";return gt(()=>{const S=new URLSearchParams(window.location.search);E(0,T=S.get("fw")||"pt")}),[T]}class Ct extends ut{constructor($){super();mt(this,$,Tt,kt,wt,{})}}export{Ct as default,Et as metadata};
