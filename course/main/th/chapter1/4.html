<meta charset="utf-8" /><meta http-equiv="content-security-policy" content=""><meta name="hf:doc:metadata" content="{&quot;local&quot;:&quot;transformer&quot;,&quot;sections&quot;:[{&quot;local&quot;:&quot;transformer&quot;,&quot;title&quot;:&quot;ประวัติของ Transformer เบื้องต้น&quot;},{&quot;local&quot;:&quot;transformers&quot;,&quot;title&quot;:&quot;Transformers ก็คือโมเดลบริบททางภาษาแบบหนึ่งนั่นแหละ&quot;},{&quot;local&quot;:&quot;transformers&quot;,&quot;title&quot;:&quot;Transformers มัน ใหญ่ มาก&quot;},{&quot;local&quot;:&quot;transfer-learning&quot;,&quot;title&quot;:&quot;Transfer Learning&quot;},{&quot;local&quot;:&quot;&quot;,&quot;title&quot;:&quot;สถาปัตยกรรมทั่วไป&quot;},{&quot;local&quot;:&quot;&quot;,&quot;title&quot;:&quot;เริ่มต้น&quot;},{&quot;local&quot;:&quot;attention-layers&quot;,&quot;title&quot;:&quot;Attention layers&quot;},{&quot;local&quot;:&quot;&quot;,&quot;title&quot;:&quot;สถาปัตยกรรมต้นฉบับ&quot;},{&quot;local&quot;:&quot;architecture-vs-checkpoints&quot;,&quot;title&quot;:&quot;สถาปัตยกรรม(หรือเรียกว่า Architecture) vs. จุดเซฟ(หรือเรียกว่า checkpoints)&quot;}],&quot;title&quot;:&quot;Transformer ทำงานยังไง?&quot;}" data-svelte="svelte-1phssyn">
	<link rel="modulepreload" href="/docs/course/main/th/_app/assets/pages/__layout.svelte-hf-doc-builder.css">
	<link rel="modulepreload" href="/docs/course/main/th/_app/start-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/th/_app/chunks/vendor-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/th/_app/chunks/paths-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/th/_app/pages/__layout.svelte-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/th/_app/pages/chapter1/4.mdx-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/th/_app/chunks/Youtube-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/th/_app/chunks/IconCopyLink-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/th/_app/chunks/CourseFloatingBanner-hf-doc-builder.js"> 





<h1 class="relative group"><a id="transformer" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#transformer"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Transformer ทำงานยังไง?
	</span></h1>



<div class="flex space-x-1 absolute z-10 right-0 top-0"><a href="https://discuss.huggingface.co/t/chapter-1-questions" target="_blank"><img alt="Ask a Question" class="!m-0" src="https://img.shields.io/badge/Ask%20a%20question-ffcb4c.svg?logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgLTEgMTA0IDEwNiI+PGRlZnM+PHN0eWxlPi5jbHMtMXtmaWxsOiMyMzFmMjA7fS5jbHMtMntmaWxsOiNmZmY5YWU7fS5jbHMtM3tmaWxsOiMwMGFlZWY7fS5jbHMtNHtmaWxsOiMwMGE5NGY7fS5jbHMtNXtmaWxsOiNmMTVkMjI7fS5jbHMtNntmaWxsOiNlMzFiMjM7fTwvc3R5bGU+PC9kZWZzPjx0aXRsZT5EaXNjb3Vyc2VfbG9nbzwvdGl0bGU+PGcgaWQ9IkxheWVyXzIiPjxnIGlkPSJMYXllcl8zIj48cGF0aCBjbGFzcz0iY2xzLTEiIGQ9Ik01MS44NywwQzIzLjcxLDAsMCwyMi44MywwLDUxYzAsLjkxLDAsNTIuODEsMCw1Mi44MWw1MS44Ni0uMDVjMjguMTYsMCw1MS0yMy43MSw1MS01MS44N1M4MCwwLDUxLjg3LDBaIi8+PHBhdGggY2xhc3M9ImNscy0yIiBkPSJNNTIuMzcsMTkuNzRBMzEuNjIsMzEuNjIsMCwwLDAsMjQuNTgsNjYuNDFsLTUuNzIsMTguNEwzOS40LDgwLjE3YTMxLjYxLDMxLjYxLDAsMSwwLDEzLTYwLjQzWiIvPjxwYXRoIGNsYXNzPSJjbHMtMyIgZD0iTTc3LjQ1LDMyLjEyYTMxLjYsMzEuNiwwLDAsMS0zOC4wNSw0OEwxOC44Niw4NC44MmwyMC45MS0yLjQ3QTMxLjYsMzEuNiwwLDAsMCw3Ny40NSwzMi4xMloiLz48cGF0aCBjbGFzcz0iY2xzLTQiIGQ9Ik03MS42MywyNi4yOUEzMS42LDMxLjYsMCwwLDEsMzguOCw3OEwxOC44Niw4NC44MiwzOS40LDgwLjE3QTMxLjYsMzEuNiwwLDAsMCw3MS42MywyNi4yOVoiLz48cGF0aCBjbGFzcz0iY2xzLTUiIGQ9Ik0yNi40Nyw2Ny4xMWEzMS42MSwzMS42MSwwLDAsMSw1MS0zNUEzMS42MSwzMS42MSwwLDAsMCwyNC41OCw2Ni40MWwtNS43MiwxOC40WiIvPjxwYXRoIGNsYXNzPSJjbHMtNiIgZD0iTTI0LjU4LDY2LjQxQTMxLjYxLDMxLjYxLDAsMCwxLDcxLjYzLDI2LjI5YTMxLjYxLDMxLjYxLDAsMCwwLTQ5LDM5LjYzbC0zLjc2LDE4LjlaIi8+PC9nPjwvZz48L3N2Zz4="></a>
	
	</div>
<p>ในส่วนนี้เราจะมาดูกันว่าสถาปัตยกรรมของโมเดล Transformer ทำงานกันยังไง</p>
<h2 class="relative group"><a id="transformer" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#transformer"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>ประวัติของ Transformer เบื้องต้น
	</span></h2>

<p>รูปด้านล่างแสดงรายชื่อของโมเดล Transformer ตามแต่ละช่วงเวลา:</p>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers_chrono.svg" alt="A brief chronology of Transformers models.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers_chrono-dark.svg" alt="A brief chronology of Transformers models."></div>
<p><a href="https://arxiv.org/abs/1706.03762" rel="nofollow">สถาปัตยกรรม Transformer</a> ถูกสร้างขึ้นเมื่อปี 2017 เป้าหมายในการสร้างโมเดลก็เพื่องานในการแปลภาษา หลังจากนั้นก็มีโมเดลที่ได้รับแรงบันดาลใจต่อ ๆ มา เช่น</p>
<ul><li><p><strong>มิถุนายน 2018</strong>: <a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf" rel="nofollow">GPT</a>, โมเดล Transformer ตัวแรก ที่มาพร้อมกับพร้อมกับโมเดลที่เทรนมาแล้ว ใช้ในการ fine-tune งานทางด้าน NLP ได้หลายงานและได้ผลลัพธ์ที่เทียบเท่างานวิจัยล่าสุด</p></li>
<li><p><strong>ตุลาคม 2018</strong>: <a href="https://arxiv.org/abs/1810.04805" rel="nofollow">BERT</a>, โมเดลขนาดใหญ่อีกตัวหนึ่งที่ผ่านการเทรนมาแล้ว ซึ่งออกแบบมาสำหรับงานในการสรุปความ (อ่านต่อได้ในบทถัดไป)</p></li>
<li><p><strong>กุมภาพันธ์ 2019</strong>: <a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" rel="nofollow">GPT-2</a>, โมเดล GPT รุ่นพัฒนาที่ดีขึ้น(และใหญ่ขึ้นด้วย) แต่ว่าไม่ได้เปิดให้ใช้สาธารณะในทันทีเนื่องจากอาจมีการนำไปใช้ในด้านไม่ดี</p></li>
<li><p><strong>ตุลาคม 2019</strong>: <a href="https://arxiv.org/abs/1910.01108" rel="nofollow">DistilBERT</a>, โมเดล BERT ขนาดย่อ ซึ่งเร็วกว่า 60% และใช้หน่วยความจำลดลง 40% แต่ยังคงประสิทธิภาพไว้ที่ 97% ของโมเดล BERT ปกติ</p></li>
<li><p><strong>ตุลาคม 2019</strong>: <a href="https://arxiv.org/abs/1910.13461" rel="nofollow">BART</a> และ <a href="https://arxiv.org/abs/1910.10683" rel="nofollow">T5</a>, โมเดลที่ผ่านการเทรนมาแล้วทั้งสองตัวที่ใช้สถาปัตยกรรมเดียวกันกับโมเดล Transformer ต้นฉบับ (โมเดลแรกที่ทำแบบนี้)</p></li>
<li><p><strong>พฤษภาคม 2020</strong>, <a href="https://arxiv.org/abs/2005.14165" rel="nofollow">GPT-3</a>, โมเดล GPT-2 ที่ใหญ่ขึ้นไปอีกซึ่งสามารถทำงานได้หลายอย่างโดยไม่ต้องการการ fine-tune (หรือเรียกว่า <em>zero-shot learning</em>)</p></li></ul>
<p>ที่จริงแล้วยังมีโมเดลอื่น ๆ อีกมากนอกเหนือจากรายชื่อที่กล่าวไป ในที่นี้ต้องการที่จะเน้นย้ำอีกครั้งในส่วนของประเภทของโมเดล Transformer ซึ่งสามารถแบ่งได้ดังนี้:</p>
<ul><li>กลุ่ม GPT (หรือเรียกว่า โมเดล Transformer แบบ <em>auto-regressive</em>)</li>
<li>กลุ่ม BERT (หรือเรียกว่า โมเดล Transformer แบบ <em>auto-encoding</em>)</li>
<li>กลุ่ม BART/T5 (หรือเรียกว่า โมเดล Transformer แบบ <em>sequence-to-sequence</em>)</li></ul>
<p>โดยเราจะกล่าวถึงแต่ละกลุ่มในรายละเอียดกันภายหลัง</p>
<h2 class="relative group"><a id="transformers" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#transformers"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Transformers ก็คือโมเดลบริบททางภาษาแบบหนึ่งนั่นแหละ
	</span></h2>

<p>โมเดล Transformer ที่กล่าวไปด้านบนทั้งหมด (GPT, BERT, BART, T5 เป็นต้น) ถูกเทรนให้เป็น<em>โมเดลบริบททางภาษา</em> (หรือเรียกว่า language model) นั่นคือโมเดลเหล่านี้ถูกเทรนผ่านข้อความดิบขนาดใหญ่เรียนรู้ด้วยตนเอง (หรือเรียกว่า self-supervised) การ self-supervised นั้นคือการเทรนแบบหนึ่งซึ่งเป้าหมายในการเทรนจะถูกคำนวณออกมาอัตโนมัติจาก input ที่ใส่เข้าไป ดังนั้นการเทรนแบบนี้จึงไม่จำเป็นต้อง label ข้อมูลเลย!</p>
<p>โมเดลประเภทนี้จะเข้าในภาษาที่ถูกเทรนมาในเชิงสถิติ แต่ในการใช้งานจริงอาจไม่มีประโยชน์เท่าไหร่ ดังนั้นโมเดลที่ผ่านการเทรนแบบนี้มาจึงถูกนำไปใช้ในกระบวนการ <em>transfer learning</em> ซึ่งก็คือโมเดลนี้จะถูกนำไป fine-tune ต่อในงานอื่นที่มี label จากมนุษย์</p>
<p>ตัวอย่างงานดังกล่าวได้แก่ การเดาคำต่อไปหลังจากอ่านคำในประโยค <em>n</em> คำ สิ่งนี้เรียกว่า <em>causal language model</em> เนื่องจาก output ขึ้นอยู่กับ input ในอดีตและปัจจุบันเท่านั้น</p>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/causal_modeling.svg" alt="Example of causal language modeling in which the next word from a sentence is predicted.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/causal_modeling-dark.svg" alt="Example of causal language modeling in which the next word from a sentence is predicted."></div>
<p>อีกตัวอย่างหนึ่งได้แก่ การเติมคำในช่องว่าง (หรือเรียกว่า <em>masked language modeling</em>) เป็นการเดาคำที่เว้นว่างไว้ในประโยค โดยในที่นี้จะใช้คำว่า <code>[MASK]</code> แทนการเว้นว่าง</p>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/masked_modeling.svg" alt="Example of masked language modeling in which a masked word from a sentence is predicted.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/masked_modeling-dark.svg" alt="Example of masked language modeling in which a masked word from a sentence is predicted."></div>
<h2 class="relative group"><a id="transformers" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#transformers"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Transformers มัน ใหญ่ มาก
	</span></h2>

<p>ถ้าไม่นับพวกโมเดลแปลก ๆ อย่าง DistilBERT การจะได้มาซึ่งผลลัพธ์ที่ดีขึ้นก็ต้องเพิ่มขนาดโมเดลและขนาดข้อมูลที่นำมาเทรนโมเดล</p>
<div class="flex justify-center"><img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/model_parameters.png" alt="Number of parameters of recent Transformers models" width="90%"></div>
<p>ซึ่งในการเทรนโมเดลโดยเฉพาะโมเดลขนาดใหญ่ต้องการข้อมูลในการเทรนจำนวนมาก ดังนั้นการเทรนแต่ละครั้งจึงกินทั้งทรัพยากรเวลาและทรัพยากรในการคำนวณมากขึ้นไปอีก ซึ่งหมายถึงผลกระทบต่อสิ่งแวดล้อมดังแสดงในภาพด้านล่าง</p>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/carbon_footprint.svg" alt="The carbon footprint of a large language model.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/carbon_footprint-dark.svg" alt="The carbon footprint of a large language model."></div>
<iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/ftWlj4FBHTg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p>รูปภาพทำขึ้นเพื่อจะสื่อสารไปยังทีมพัฒนาต่าง ๆ ให้เห็นถึงผลกระทบต่อสิ่งแวดล้อมในการเทรนโมเดลขนาดใหญ่(มาก ๆ) และหากต้องการจะทดลองเพื่อหา hyperparameter ที่ดีสุด ผลกระทบย่อมเพิ่มขึ้นอีกเป็นเงาตามตัว</p>
<p>ลองนึกสภาพว่าหากแต่ละทีมวิจัย, กลุ่มการศึกษา, หรือบริษัทเอกชนใด ๆ ต้องการเทรนโมเดลซักโมเดลหนึ่ง โดยเริ่มต้นมาจากศูนย์ทุกครั้ง จะก่อให้เกิดค่าใช้จ่ายที่ไม่จำเป็นอย่างใหญ่หลวงมาก</p>
<p>เพราะฉะนั้นการแบ่งปันโมเดลที่เทรนไว้แล้วจึงเป็นเรื่องสำคัญอย่างมาก การแบ่งปัน weight ของโมเดลและสร้างสิ่งต่าง ๆ ผ่าน weight ที่มีคนทำมาแล้วจะช่วยลดค่าใช้จ่ายและลดค่า carbon footprint โดยทั่วกัน</p>
<h2 class="relative group"><a id="transfer-learning" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#transfer-learning"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Transfer Learning
	</span></h2>

<iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/BqqfQnyjmgg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p><em>Pretraining</em> เป็นการเทรนโมเดลจากศูนย์ ซึ่งก็คือ weight ในโมเดลเริ่มต้นจากค่าสุ่ม และเริ่มเทรนโดยไม่มีความรู้อะไรเลย</p>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/pretraining.svg" alt="The pretraining of a language model is costly in both time and money.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/pretraining-dark.svg" alt="The pretraining of a language model is costly in both time and money."></div>
<p>โดยมากแล้วการ pretrain จะใช้ข้อมูลขนาดใหญ่มาก ๆ ดังนั้นจึงต้องการข้อมูลภาษาขนาดใหญ่และใช้เวลาเทรนหลายสัปดาห์</p>
<p><em>Fine-tuning</em> เป็นการเทรนโมเดล<strong>หลังจาก</strong>การ pretrain ซึ่งก็คือ นำ language model ที่ผ่านการ pretrain แล้ว มาเทรนเพิ่มเติมด้วยชุดข้อมูลที่เฉพาะเจาะจงในงานที่ต้องการ ว่าแต่ ทำไมไม่เทรนโมเดลสำหรับงานสุดท้ายไปทีเดียวเลยล่ะ? มันมีเหตุผลอยู่ ดังนี้:</p>
<ul><li>โมเดลที่ผ่านการ pretrain มาแล้วมีความเข้าใจความเหมือนบางอย่างในชุดข้อมูลที่นำมา fine-tune ดังนั้น การ fine-tune จึงสามารถนำความรู้ที่ได้จากการ pretrain มาใช้ประโยชน์ได้ทันที (เช่น โมเดลที่ pretrain มาแล้วทางด้าน NLP พอจะมีเข้าใจเบื้องต้นเกี่ยวกับภาษาที่เรากำลังใช้อยู่ในเชิงสถิติ)</li>
<li>เนื่องจากโมเดลที่ผ่านการ pretrain มาแล้วนั้นถูกเทรนด้วยข้อมูลขนาดใหญ่มาก การใช้ข้อมูลเพียงเล็กน้อยในการ fine-tune ก็สามารถให้ผลเป็นที่พึงพอใจได้</li>
<li>และด้วยเหตุผลเดียวกันนี้ เวลาและทรัพยากรที่ใช้เพื่อให้ได้ผลลัพธ์ที่ดีก็น้อยกว่าเช่นกัน</li></ul>
<p>ตัวอย่างเช่น เราสามารถใช้โมเดล pretrain ในภาษาอังกฤษและ fine-tune ด้วยข้อมูลภาษาจากใน arXiv (แหล่งข้อมูลค้นคว้าวิจัยทางด้านวิทยาศาสตร์) ทำให้ได้โมเดลที่เก่งทางด้านวิทยาศาสตร์และการวิจัย การ fine-tune นี้ต้องการข้อมูลเพียงเล็กน้อยเท่านั้น ความรู้ความเข้าใจทางภาษาของโมเดลถูกส่งต่อมาจากโมเดล pretrain ดังนั้นกระบวนการนี้จึงเรียกว่า <em>transfer learning</em></p>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/finetuning.svg" alt="The fine-tuning of a language model is cheaper than pretraining in both time and money.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/finetuning-dark.svg" alt="The fine-tuning of a language model is cheaper than pretraining in both time and money."></div>
<p>ด้วยเหตุนี้การ fine-tune จึงใช้เวลา ข้อมูล ค่าใช้จ่าย และผลกระทบต่อสิ่งแวดล้อมน้อยกว่า รวมถึงว่าเราสามารถทดลองรูปแบบการ fine-tune ต่าง ๆ ได้ง่ายกว่าและเร็วกว่าอีกด้วย เนื่องจากการเทรนแบบนี้มีเงื่อนไขต่ำกว่าการเทรนเต็มรูปแบบ</p>
<p>กระบวนการดังกล่าวนี้ยังให้ผลลัพธ์ที่ดีกว่าการเทรนทุกอย่างจากศูนย์อีกด้วย(เว้นแต่ว่าคุณจะมีข้อมูลเยอะมากจริง ๆ) และนี่ก็เป็นอีกสาเหตุหนึ่งที่คุณควรใช้โมเดล pretrain ที่ใกล้เคียงกับงานที่คุณต้องการทำที่สุดและแค่ fine-tune มันออกมา</p>
<h2 id="">สถาปัตยกรรมทั่วไป</h2>
<p>ในส่วนนี้เราจะพูดถึงสถาปัตยกรรมทั่วไปของโมเดล Transformer ไม่ต้องกังวลไปหากคุณไม่เข้าใจเนื้อหาบางส่วนตอนนี้ เนื้อหาในส่วนหลังจะอธิบานเรื่องเหล่านี้ในรายละเอียดเพิ่มเติมให้</p>
<iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/H39Z_720T5s" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<h2 id="">เริ่มต้น</h2>
<p>โมเดล Transformer ประกอบด้วยส่วนใหญ่ ๆ สองส่วน ได้แก่:</p>
<ul><li><strong>ส่วนเข้ารหัส (หรือเรียกว่า Encoder) (ซ้าย)</strong>: encoder รับ input เข้ามาและสร้างตัวแทน input เหล่านั้น โดยตัวแทนเหล่านี้เรียกว่า feature นั่นหมายความว่าโมเดลจะปรับแต่งตัวเองให้เข้าใจ input ได้ในส่วนนี้</li>
<li><strong>ส่วนถอดรหัส (หรือเรียกว่า Decoder) (ขวา)</strong>: decoder สร้าง output ออกมาเป็นข้อมูลลำดับ (หรือเรียกว่า sequence) โดยอาศัย feature และ input อื่น ๆ นั่นหมายถึงโมเดลปรับแต่งตัวเองให้สร้าง output ได้ในส่วนนี้</li></ul>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers_blocks.svg" alt="Architecture of a Transformers models">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers_blocks-dark.svg" alt="Architecture of a Transformers models"></div>
<p>แต่ละส่วนดังกล่าวสามารถแยกใช้อิสระต่อกันได้ ขึ้นอยู่กับว่าใช้ในงานอะไร เช่น:</p>
<ul><li><strong>โมเดลที่ใช้ encoder อย่างเดียว</strong>: สำหรับงานที่ต้องการให้เข้าใจ input เช่น การแยกหมวดหมู่ประโยคและการระบุชนิดของคำในประโยค</li>
<li><strong>โมเดลที่ใช้ decoder อย่างเดียว</strong>: สำหรับงานในการสร้าง output ออกมา เช่น การสร้างข้อความ</li>
<li><strong>โมเดลที่ใช้ทั้ง encoder และ decoder</strong> หรือ <strong>โมเดล sequence-to-sequence</strong> สำหรับงานในการสร้าง output ที่ต้องการ input เข้ามาด้วย เช่น การแปลภาษาหรือการสรุปความ</li></ul>
<p>ซึ่งเราจะเจาะลงไปในรายละเอียดของแต่ละสถาปัตยกรรมกันต่อในภายหลัง</p>
<h2 class="relative group"><a id="attention-layers" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#attention-layers"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Attention layers
	</span></h2>

<p>ฟีเจอร์สำคัญของโมเดล Transformer ก็คือโมเดลนี้ถูกสร้างขึ้นมาจาก layer พิเศษที่ชื่อว่า <em>attention layer</em> ซึ่งเป็นสาเหตุที่ชื่อของงานวิจัยที่พูดถึงสถาปัตยกรรม Transformer เป็นครั้งแรกถูกตั้งชื่อว่า <a href="https://arxiv.org/abs/1706.03762" rel="nofollow">“Attention Is All You Need”</a> (Attention เป็นทุกอย่างให้เธอแล้ว) เราจะมาอธิบายเกี่ยวกับ attention layer ในรายละเอียดกันในช่วงหลังของคอร์สนี้ แต่สำหรับตอนนี้ คุณแค่เข้าใจว่า attention layer ทำหน้าที่บอกให้โมเดลให้ความสนใจ(attend)กับคำที่ตำแหน่งใดเป็นพิเศษจากประโยคส่งให้(รวมถึงบอกให้มองข้ามคำที่ตำแหน่งอื่นด้วย)เมื่อต้องการอธิบายความหมายของคำใด ๆ</p>
<p>เพื่อให้เห็นภาพมากขึ้น ลองนึกถึงงานในการแปลข้อความจากภาษาอังกฤษเป็นภาษาฝรั่งเศส ตัวอย่างเช่นประโยค “You like this course” โมเดลแปลภาษาต้องสนใจไปที่คำว่า “You” เพื่อให้ได้คำแปลของคำว่า “like” ที่เหมาะสม เนื่องจากในภาษาฝรั่งเศสคำว่า “like” นั้นเปลี่ยนรูปไปตามประธานในประโยค คำอื่น ๆ ที่เหลือในประโยคไม่ได้ส่งผลต่อการแปลคำว่า “like” เลย ในลักษณะเดียวกัน การแปลคำว่า “this” โมเดลต้องสนใจไปที่คำว่า “course” เนื่องจากคำว่า “this” ในภาษาฝรั่งเศสจะแปลออกมาว่าอย่างไรขึ้นอยู่กับว่าคำนั้นเป็นเพศชายหรือหญิง(ในบางภาษาคำแต่ละคำจะมีเพศกำกับไว้แม้ว่าจะไม่ได้เป็นสิ่งมีชีวิตที่มีเพศจริง ๆ ก็ตาม โดยไวยากรณ์ของภาษานั้น ๆ จะผันตามเพศของคำ) และแน่นอนคำอื่น ๆ ในประโยคไม่ได้ส่งผลต่อการแปลว่าคำว่า “this” เลย และเมื่อประโยคซับซ้อนมากยิ่งขึ้น(ส่งผลให้กฎไวยากรณ์ซับซ้อนมากยิ่งขึ้น) โมเดลยิ่งต้องให้ความสนใจไปยังคำที่ไกลออกไปในประโยคเพื่อแปลคำแต่ละคำให้เหมาะสม</p>
<p>แนวคิดเดียวกันนี้ใช้ได้กับงาน NLP อื่น ๆ นั่นคือ คำแต่ละคำมีความหมายในตัวมันเอง โดยความหมายเหล่านี้ส่งผลมาจากบริบทของคำ ซึ่งก็คือคำอื่นที่อยู่รอบ ๆ คำนั้น ๆ</p>
<p>ตอนนี้คุณก็พอจะเข้าใจแล้วว่า attention layer คืออะไร ลองมาดูรายละเอียดของสถาปัตยกรรม Transformer กัน</p>
<h2 id="">สถาปัตยกรรมต้นฉบับ</h2>
<p>ในตอนแรก Transformer ออกแบบมาเพื่องานแปลภาษา ระหว่างการเทรน ตัว encoder รับ input เป็นประโยคในภาษาหนึ่ง ในขณะที่ decoder เองก็รับประโยคเดียวกันในภาษาเป้าหมาย โดย attention layer ใน encoder สามารถใช้คำทั้งหมดในประโยคได้(เนื่องจากการแปลคำใด ๆ ขึ้นอยู่กับคำที่อาจจะอยู่ข้างหน้าหรือข้างหลังคำนั้น ๆ ก็ได้) ในขณะที่ decoder ต้องสร้างคำเป็นลำดับออกมาทีละคำ นั่นคือ decoder สามารถสนใจคำที่แปลออกมาก่อนได้เท่านั้น ตัวอย่างเช่น เมื่อเราแปลคำในภาษาเป้าหมายไป 3 คำแรก เราก็จะเอา 3 คำนี้ส่งไปยัง decoder รวมกับ input อื่นจาก encoder เพื่อทำนายคำที่ 4 ออกมา</p>
<p>เพื่อให้กระบวนการเทรนเร็วมากขึ้น(เมื่อโมเดลเข้าถึงประโยคในภาษาเป้าหมายได้) decoder จะรับประโยคในภาษาเป้าหมายไปทั้งประโยค แต่แค่ไม่อนุญาตให้เข้าถึงคำที่กำลังจะแปลในอนาคต(ลองคิดดูว่าถ้ากำลังทำนายคำในประโยคเป้าหมายตำแหน่งที่ 2 แล้วโมเดลก็เข้าถึงคำในตำแหน่งที่ 2 ในประโยคเป้าหมายได้ ปัญหามันก็ดูจะแก้ได้ง่ายเกินไปแหละ) หรืออีกนัยหนึ่งคือ ขณะที่กำลังทำนายคำที่ 4 ในประโยค ตัว attention layer จะเข้าถึงได้แค่คำที่ตำแหน่ง 1 ถึง 3 เท่านั้น</p>
<p>รูปด้านล่างแสดงสถาปัตยกรรม Transformer โดย encoder อยู่ด้านซ้ายและ decoder อยู่ด้านขวา:</p>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers.svg" alt="Architecture of a Transformers models">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers-dark.svg" alt="Architecture of a Transformers models"></div>
<p>หมายเหตุไว้หน่อยว่า attention layer แรกใน decoder สนใจไปที่ input (ในอดีต)ทั้งหมดของ decoder แต่ attention layer ที่สองใช้ output ของ encoder ด้วย นั่นคือ มันสามารถเข้าถึงประโยค input ทั้งหมดเพื่อทำนายคำในปัจจุบันได้ ส่วนนี้มีประโยชน์มากเนื่องจากแต่ละภาษาก็มีหลักไวยากรณ์ในการวางตำแหน่งคำที่ต่างกัน หรือบริบทที่ถูกกล่าวถึงทีหลังในประโยคอาจส่งผลต่อการหาคำแปลที่เหมาะสมของคำในปัจจุบัน</p>
<p><em>attention mask</em> เป็นอีกส่วนประกอบที่ใช้ได้กับทั้ง encoder และ decoder เพื่อป้องกันไม่ให้โมเดลสนใจไปยังคำบางคำ ตัวอย่างเช่น คำพิเศษบางคำที่เอามาเติมในประโยคให้ประโยคใน input ที่ความยาวเท่ากับเวลาประมวลผลประโยคพร้อมกัน</p>
<h2 class="relative group"><a id="architecture-vs-checkpoints" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#architecture-vs-checkpoints"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>สถาปัตยกรรม(หรือเรียกว่า Architecture) vs. จุดเซฟ(หรือเรียกว่า checkpoints)
	</span></h2>

<p>ดังที่เราได้เรียนรู้โมเดล Transformer มาในคอร์สนี้ คุณจะเห็นคำที่ความหมายคล้าย ๆ กัน อย่างเช่น <em>architecture</em> และ <em>checkpoint</em> รวมถึง <em>model</em> อย่างไรก็ตาม คำแหล่านี้มีความหมายแตกต่างกันเล็กน้อย ดังนี้:</p>
<ul><li><strong>Architecture</strong>: เป็นโครงสร้างของโมเดล นั่นคือ เป็นการกำหนดนิยามของ layer (เช่น บอกว่า มีทั้งหมดกี่ layer และ layer แต่ละ layer เป็นประเภทใด) รวมถึงบอกว่า layer นั้น ๆ จะมีกระบวนการการทำอะไรบ้าง</li>
<li><strong>Checkpoints</strong>: เป็นเพียงการเซฟ weight หรือค่าคงที่ของ parameter ในแต่ละ layer ที่จะเอาไปใช้ใน architecture ที่กำหนดได้</li>
<li><strong>Model</strong>: เป็นคำกว้าง ๆ ไม่ได้ระบุความหมายเฉพาะเจาะจงเหมือนคำว่า “architecture” หรือ “checkpoint” ซึ่งจริง ๆ อาจจะหมายถึงคำใดก็ได้ แต่ในคอร์สนี้จะใช้คำว่า <em>architecture</em> หรือ <em>checkpoint</em> ไปเลยเพื่อหลีกเลี่ยงความสับสน</li></ul>
<p>ยกตัวอย่างง่าย ๆ เช่น BERT เป็น architecture ในขณะที่ <code>bert-base-cased</code> เป็น checkpoint ที่เซฟ weight จากการเทรน BERT ที่ทีม Google ปล่อยออกมาตอนเปิดให้ใช้งานครั้งแรก โดยเราสามารถเรียกสิ่งเหล่านี้ว่า”โมเดล BERT” หรือ “โมเดล <code>bert-base-cased</code>” ก็ถือว่าถูกต้องทั้งคู่</p>


		<script type="module" data-hydrate="b8igz2">
		import { start } from "/docs/course/main/th/_app/start-hf-doc-builder.js";
		start({
			target: document.querySelector('[data-hydrate="b8igz2"]').parentNode,
			paths: {"base":"/docs/course/main/th","assets":"/docs/course/main/th"},
			session: {},
			route: false,
			spa: false,
			trailing_slash: "never",
			hydrate: {
				status: 200,
				error: null,
				nodes: [
					import("/docs/course/main/th/_app/pages/__layout.svelte-hf-doc-builder.js"),
						import("/docs/course/main/th/_app/pages/chapter1/4.mdx-hf-doc-builder.js")
				],
				params: {}
			}
		});
	</script>
