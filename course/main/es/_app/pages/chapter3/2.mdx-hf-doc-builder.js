import{S as Gc,i as Vc,s as Yc,e as i,t as o,k as m,w as g,c,a as d,h as n,d as a,m as f,x as E,g as p,G as s,y,q as j,o as v,B as x,l as Wc,M as Jc,b as z,p as Cs,v as Kc,n as Ps}from"../../chunks/vendor-hf-doc-builder.js";import{T as si}from"../../chunks/Tip-hf-doc-builder.js";import{Y as go}from"../../chunks/Youtube-hf-doc-builder.js";import{I as Rn}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as D}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as Bc}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as Zc}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function Qc(w){let t,u;return t=new Bc({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter3/section2_tf.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter3/section2_tf.ipynb"}]}}),{c(){g(t.$$.fragment)},l(l){E(t.$$.fragment,l)},m(l,b){y(t,l,b),u=!0},i(l){u||(j(t.$$.fragment,l),u=!0)},o(l){v(t.$$.fragment,l),u=!1},d(l){x(t,l)}}}function Xc(w){let t,u;return t=new Bc({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter3/section2_pt.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter3/section2_pt.ipynb"}]}}),{c(){g(t.$$.fragment)},l(l){E(t.$$.fragment,l)},m(l,b){y(t,l,b),u=!0},i(l){u||(j(t.$$.fragment,l),u=!0)},o(l){v(t.$$.fragment,l),u=!1},d(l){x(t,l)}}}function ed(w){let t,u,l,b,k,h,_,C;return _=new D({props:{code:`import tensorflow as tf
import numpy as np
from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

# Same as before
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)
sequences = [
    "I've been waiting for a HuggingFace course my whole life.",
    "This course is amazing!",
]
batch = dict(tokenizer(sequences, padding=True, truncation=True, return_tensors="tf"))

# This is new
model.compile(optimizer="adam", loss="sparse_categorical_crossentropy")
labels = tf.convert_to_tensor([1, 1])
model.train_on_batch(batch, labels)`,highlighted:`<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

<span class="hljs-comment"># Same as before</span>
checkpoint = <span class="hljs-string">&quot;bert-base-uncased&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)
sequences = [
    <span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>,
    <span class="hljs-string">&quot;This course is amazing!&quot;</span>,
]
batch = <span class="hljs-built_in">dict</span>(tokenizer(sequences, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>))

<span class="hljs-comment"># This is new</span>
model.<span class="hljs-built_in">compile</span>(optimizer=<span class="hljs-string">&quot;adam&quot;</span>, loss=<span class="hljs-string">&quot;sparse_categorical_crossentropy&quot;</span>)
labels = tf.convert_to_tensor([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>])
model.train_on_batch(batch, labels)`}}),{c(){t=i("p"),u=o("Continuando con el ejemplo del "),l=i("a"),b=o("cap\xEDtulo anterior"),k=o(", aqu\xED mostraremos como podr\xEDamos entrenar un clasificador de oraciones/sentencias en TensorFlow:"),h=m(),g(_.$$.fragment),this.h()},l($){t=c($,"P",{});var q=d(t);u=n(q,"Continuando con el ejemplo del "),l=c(q,"A",{href:!0});var N=d(l);b=n(N,"cap\xEDtulo anterior"),N.forEach(a),k=n(q,", aqu\xED mostraremos como podr\xEDamos entrenar un clasificador de oraciones/sentencias en TensorFlow:"),q.forEach(a),h=f($),E(_.$$.fragment,$),this.h()},h(){z(l,"href","/course/chapter2")},m($,q){p($,t,q),s(t,u),s(t,l),s(l,b),s(t,k),p($,h,q),y(_,$,q),C=!0},i($){C||(j(_.$$.fragment,$),C=!0)},o($){v(_.$$.fragment,$),C=!1},d($){$&&a(t),$&&a(h),x(_,$)}}}function sd(w){let t,u,l,b,k,h,_,C;return _=new D({props:{code:`import torch
from transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification

# Same as before
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)
sequences = [
    "I've been waiting for a HuggingFace course my whole life.",
    "This course is amazing!",
]
batch = tokenizer(sequences, padding=True, truncation=True, return_tensors="pt")

# This is new
batch["labels"] = torch.tensor([1, 1])

optimizer = AdamW(model.parameters())
loss = model(**batch).loss
loss.backward()
optimizer.step()`,highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AdamW, AutoTokenizer, AutoModelForSequenceClassification

<span class="hljs-comment"># Same as before</span>
checkpoint = <span class="hljs-string">&quot;bert-base-uncased&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)
sequences = [
    <span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>,
    <span class="hljs-string">&quot;This course is amazing!&quot;</span>,
]
batch = tokenizer(sequences, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)

<span class="hljs-comment"># This is new</span>
batch[<span class="hljs-string">&quot;labels&quot;</span>] = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>])

optimizer = AdamW(model.parameters())
loss = model(**batch).loss
loss.backward()
optimizer.step()`}}),{c(){t=i("p"),u=o("Continuando con el ejemplo del "),l=i("a"),b=o("cap\xEDtulo anterior"),k=o(", aqu\xED mostraremos como podr\xEDamos entrenar un clasificador de oraciones/sentencias en PyTorch.:"),h=m(),g(_.$$.fragment),this.h()},l($){t=c($,"P",{});var q=d(t);u=n(q,"Continuando con el ejemplo del "),l=c(q,"A",{href:!0});var N=d(l);b=n(N,"cap\xEDtulo anterior"),N.forEach(a),k=n(q,", aqu\xED mostraremos como podr\xEDamos entrenar un clasificador de oraciones/sentencias en PyTorch.:"),q.forEach(a),h=f($),E(_.$$.fragment,$),this.h()},h(){z(l,"href","/course/chapter2")},m($,q){p($,t,q),s(t,u),s(t,l),s(l,b),s(t,k),p($,h,q),y(_,$,q),C=!0},i($){C||(j(_.$$.fragment,$),C=!0)},o($){v(_.$$.fragment,$),C=!1},d($){$&&a(t),$&&a(h),x(_,$)}}}function ad(w){let t,u;return t=new go({props:{id:"W_gMJF0xomE"}}),{c(){g(t.$$.fragment)},l(l){E(t.$$.fragment,l)},m(l,b){y(t,l,b),u=!0},i(l){u||(j(t.$$.fragment,l),u=!0)},o(l){v(t.$$.fragment,l),u=!1},d(l){x(t,l)}}}function od(w){let t,u;return t=new go({props:{id:"_BZearw7f0w"}}),{c(){g(t.$$.fragment)},l(l){E(t.$$.fragment,l)},m(l,b){y(t,l,b),u=!0},i(l){u||(j(t.$$.fragment,l),u=!0)},o(l){v(t.$$.fragment,l),u=!1},d(l){x(t,l)}}}function nd(w){let t,u,l,b,k;return{c(){t=i("p"),u=o("\u270F\uFE0F "),l=i("strong"),b=o("Int\xE9ntalo!"),k=o(" Mira el elemento 15 del conjunto de datos de entrenamiento y el elemento 87 del conjunto de datos de validaci\xF3n. Cu\xE1les son sus etiquetas?")},l(h){t=c(h,"P",{});var _=d(t);u=n(_,"\u270F\uFE0F "),l=c(_,"STRONG",{});var C=d(l);b=n(C,"Int\xE9ntalo!"),C.forEach(a),k=n(_," Mira el elemento 15 del conjunto de datos de entrenamiento y el elemento 87 del conjunto de datos de validaci\xF3n. Cu\xE1les son sus etiquetas?"),_.forEach(a)},m(h,_){p(h,t,_),s(t,u),s(t,l),s(l,b),s(t,k)},d(h){h&&a(t)}}}function td(w){let t,u;return t=new go({props:{id:"P-rZWqcB6CE"}}),{c(){g(t.$$.fragment)},l(l){E(t.$$.fragment,l)},m(l,b){y(t,l,b),u=!0},i(l){u||(j(t.$$.fragment,l),u=!0)},o(l){v(t.$$.fragment,l),u=!1},d(l){x(t,l)}}}function ld(w){let t,u;return t=new go({props:{id:"0u3ioSwev3s"}}),{c(){g(t.$$.fragment)},l(l){E(t.$$.fragment,l)},m(l,b){y(t,l,b),u=!0},i(l){u||(j(t.$$.fragment,l),u=!0)},o(l){v(t.$$.fragment,l),u=!1},d(l){x(t,l)}}}function rd(w){let t,u,l,b,k;return{c(){t=i("p"),u=o("\u270F\uFE0F "),l=i("strong"),b=o("Int\xE9ntalo!"),k=o(" Toma el elemento 15 del conjunto de datos de entrenamiento y tokeniza las dos oraciones independientemente y como un par. Cu\xE1l es la diferencia entre los dos resultados?")},l(h){t=c(h,"P",{});var _=d(t);u=n(_,"\u270F\uFE0F "),l=c(_,"STRONG",{});var C=d(l);b=n(C,"Int\xE9ntalo!"),C.forEach(a),k=n(_," Toma el elemento 15 del conjunto de datos de entrenamiento y tokeniza las dos oraciones independientemente y como un par. Cu\xE1l es la diferencia entre los dos resultados?"),_.forEach(a)},m(h,_){p(h,t,_),s(t,u),s(t,l),s(l,b),s(t,k)},d(h){h&&a(t)}}}function id(w){let t,u,l,b,k,h,_,C;return{c(){t=i("p"),u=o("La funci\xF3n responsable de juntar los elementos dentro de un lote es llamada "),l=i("em"),b=o("funci\xF3n de cotejo"),k=o(". Esta es un argumento que puedes pasar cuando construyes un "),h=i("code"),_=o("DataLoader"),C=o(", cuya funci\xF3n por defecto convierte tus elementos a un tf.Tensor y los concatena (recursivamente si los elementos son listas, tuplas o diccionarios). Esto no ser\xE1 posible en nuestro caso debido a que las entradas que tenemos no tienen el mismo tama\xF1o. Hemos pospuesto el relleno, para aplicarlo s\xF3lo cuando se necesita en cada lote y evitar tener entradas muy largas con mucho relleno. Esto va a acelerar el entrenamiento significativamente, pero n\xF3tese que esto puede causar problemas si est\xE1s entrenando en un TPU - Los TPUs prefieren tama\xF1os fijos, a\xFAn cuando requieran relleno adicional.")},l($){t=c($,"P",{});var q=d(t);u=n(q,"La funci\xF3n responsable de juntar los elementos dentro de un lote es llamada "),l=c(q,"EM",{});var N=d(l);b=n(N,"funci\xF3n de cotejo"),N.forEach(a),k=n(q,". Esta es un argumento que puedes pasar cuando construyes un "),h=c(q,"CODE",{});var F=d(h);_=n(F,"DataLoader"),F.forEach(a),C=n(q,", cuya funci\xF3n por defecto convierte tus elementos a un tf.Tensor y los concatena (recursivamente si los elementos son listas, tuplas o diccionarios). Esto no ser\xE1 posible en nuestro caso debido a que las entradas que tenemos no tienen el mismo tama\xF1o. Hemos pospuesto el relleno, para aplicarlo s\xF3lo cuando se necesita en cada lote y evitar tener entradas muy largas con mucho relleno. Esto va a acelerar el entrenamiento significativamente, pero n\xF3tese que esto puede causar problemas si est\xE1s entrenando en un TPU - Los TPUs prefieren tama\xF1os fijos, a\xFAn cuando requieran relleno adicional."),q.forEach(a)},m($,q){p($,t,q),s(t,u),s(t,l),s(l,b),s(t,k),s(t,h),s(h,_),s(t,C)},d($){$&&a(t)}}}function cd(w){let t,u,l,b,k,h,_,C;return{c(){t=i("p"),u=o("La funci\xF3n responsable de juntar los elementos dentro de un lote es llamada "),l=i("em"),b=o("funci\xF3n de cotejo"),k=o(". Esta es un argumento que puedes pasar cuando construyes un "),h=i("code"),_=o("DataLoader"),C=o(", cuya funci\xF3n por defecto convierte tus elementos a tensores PyTorch y los concatena (recursivamente si los elementos son listas, tuplas o diccionarios). Esto no ser\xE1 posible en nuestro caso debido a que las entradas que tenemos no tienen el mismo tama\xF1o. Hemos pospuesto el relleno, para aplicarlo s\xF3lo cuando se necesita en cada lote y evitar tener entradas muy largas con mucho relleno. Esto va a acelerar el entrenamiento significativamente, pero n\xF3tese que esto puede causar problemas si est\xE1s entrenando en un TPU - Los TPUs prefieren tama\xF1os fijos, a\xFAn cuando requieran relleno adicional.")},l($){t=c($,"P",{});var q=d(t);u=n(q,"La funci\xF3n responsable de juntar los elementos dentro de un lote es llamada "),l=c(q,"EM",{});var N=d(l);b=n(N,"funci\xF3n de cotejo"),N.forEach(a),k=n(q,". Esta es un argumento que puedes pasar cuando construyes un "),h=c(q,"CODE",{});var F=d(h);_=n(F,"DataLoader"),F.forEach(a),C=n(q,", cuya funci\xF3n por defecto convierte tus elementos a tensores PyTorch y los concatena (recursivamente si los elementos son listas, tuplas o diccionarios). Esto no ser\xE1 posible en nuestro caso debido a que las entradas que tenemos no tienen el mismo tama\xF1o. Hemos pospuesto el relleno, para aplicarlo s\xF3lo cuando se necesita en cada lote y evitar tener entradas muy largas con mucho relleno. Esto va a acelerar el entrenamiento significativamente, pero n\xF3tese que esto puede causar problemas si est\xE1s entrenando en un TPU - Los TPUs prefieren tama\xF1os fijos, a\xFAn cuando requieran relleno adicional."),q.forEach(a)},m($,q){p($,t,q),s(t,u),s(t,l),s(l,b),s(t,k),s(t,h),s(h,_),s(t,C)},d($){$&&a(t)}}}function dd(w){let t,u;return t=new D({props:{code:`from transformers import DataCollatorWithPadding

data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors="tf")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorWithPadding

data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`}}),{c(){g(t.$$.fragment)},l(l){E(t.$$.fragment,l)},m(l,b){y(t,l,b),u=!0},i(l){u||(j(t.$$.fragment,l),u=!0)},o(l){v(t.$$.fragment,l),u=!1},d(l){x(t,l)}}}function pd(w){let t,u;return t=new D({props:{code:`from transformers import DataCollatorWithPadding

data_collator = DataCollatorWithPadding(tokenizer=tokenizer)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorWithPadding

data_collator = DataCollatorWithPadding(tokenizer=tokenizer)`}}),{c(){g(t.$$.fragment)},l(l){E(t.$$.fragment,l)},m(l,b){y(t,l,b),u=!0},i(l){u||(j(t.$$.fragment,l),u=!0)},o(l){v(t.$$.fragment,l),u=!1},d(l){x(t,l)}}}function ud(w){let t,u,l,b,k;return t=new D({props:{code:`{'attention_mask': torch.Size([8, 67]),
 'input_ids': torch.Size([8, 67]),
 'token_type_ids': torch.Size([8, 67]),
 'labels': torch.Size([8])}`,highlighted:`{<span class="hljs-string">&#x27;attention_mask&#x27;</span>: torch.Size([<span class="hljs-number">8</span>, <span class="hljs-number">67</span>]),
 <span class="hljs-string">&#x27;input_ids&#x27;</span>: torch.Size([<span class="hljs-number">8</span>, <span class="hljs-number">67</span>]),
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: torch.Size([<span class="hljs-number">8</span>, <span class="hljs-number">67</span>]),
 <span class="hljs-string">&#x27;labels&#x27;</span>: torch.Size([<span class="hljs-number">8</span>])}`}}),{c(){g(t.$$.fragment),u=m(),l=i("p"),b=o("Luce bi\xE9n! Ahora que hemos convertido el texto crudo a lotes que nuestro modelo puede aceptar, estamos listos para ajustarlo!")},l(h){E(t.$$.fragment,h),u=f(h),l=c(h,"P",{});var _=d(l);b=n(_,"Luce bi\xE9n! Ahora que hemos convertido el texto crudo a lotes que nuestro modelo puede aceptar, estamos listos para ajustarlo!"),_.forEach(a)},m(h,_){y(t,h,_),p(h,u,_),p(h,l,_),s(l,b),k=!0},i(h){k||(j(t.$$.fragment,h),k=!0)},o(h){v(t.$$.fragment,h),k=!1},d(h){x(t,h),h&&a(u),h&&a(l)}}}function md(w){let t,u;return t=new D({props:{code:`{'attention_mask': TensorShape([8, 67]),
 'input_ids': TensorShape([8, 67]),
 'token_type_ids': TensorShape([8, 67]),
 'labels': TensorShape([8])}`,highlighted:`{<span class="hljs-string">&#x27;attention_mask&#x27;</span>: TensorShape([<span class="hljs-number">8</span>, <span class="hljs-number">67</span>]),
 <span class="hljs-string">&#x27;input_ids&#x27;</span>: TensorShape([<span class="hljs-number">8</span>, <span class="hljs-number">67</span>]),
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: TensorShape([<span class="hljs-number">8</span>, <span class="hljs-number">67</span>]),
 <span class="hljs-string">&#x27;labels&#x27;</span>: TensorShape([<span class="hljs-number">8</span>])}`}}),{c(){g(t.$$.fragment)},l(l){E(t.$$.fragment,l)},m(l,b){y(t,l,b),u=!0},i(l){u||(j(t.$$.fragment,l),u=!0)},o(l){v(t.$$.fragment,l),u=!1},d(l){x(t,l)}}}function fd(w){let t,u,l,b,k;return{c(){t=i("p"),u=o("\u270F\uFE0F "),l=i("strong"),b=o("Int\xE9ntalo!"),k=o(" Reproduce el preprocesamiento en el conjunto de datos GLUE SST-2. Es un poco diferente ya que esta compuesto de oraciones individuales en lugar de pares, pero el resto de lo que hicimos deberia ser igual. Para un reto mayor, intenta escribir una funci\xF3n de preprocesamiento que trabaje con cualquiera de las tareas GLUE.")},l(h){t=c(h,"P",{});var _=d(t);u=n(_,"\u270F\uFE0F "),l=c(_,"STRONG",{});var C=d(l);b=n(C,"Int\xE9ntalo!"),C.forEach(a),k=n(_," Reproduce el preprocesamiento en el conjunto de datos GLUE SST-2. Es un poco diferente ya que esta compuesto de oraciones individuales en lugar de pares, pero el resto de lo que hicimos deberia ser igual. Para un reto mayor, intenta escribir una funci\xF3n de preprocesamiento que trabaje con cualquiera de las tareas GLUE."),_.forEach(a)},m(h,_){p(h,t,_),s(t,u),s(t,l),s(l,b),s(t,k)},d(h){h&&a(t)}}}function Uc(w){let t,u,l,b,k,h,_,C,$,q,N,F,U,B,ee,L,H,J,ce,xe;return L=new D({props:{code:`tf_train_dataset = tokenized_datasets["train"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=8,
)

tf_validation_dataset = tokenized_datasets["validation"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=False,
    collate_fn=data_collator,
    batch_size=8,
)`,highlighted:`tf_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].to_tf_dataset(
    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
    label_cols=[<span class="hljs-string">&quot;labels&quot;</span>],
    shuffle=<span class="hljs-literal">True</span>,
    collate_fn=data_collator,
    batch_size=<span class="hljs-number">8</span>,
)

tf_validation_dataset = tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>].to_tf_dataset(
    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
    label_cols=[<span class="hljs-string">&quot;labels&quot;</span>],
    shuffle=<span class="hljs-literal">False</span>,
    collate_fn=data_collator,
    batch_size=<span class="hljs-number">8</span>,
)`}}),{c(){t=i("p"),u=o("Ahora que tenemos nuestro conjunto de datos y el cotejador de datos, necesitamos juntarlos. Nosotros podriamos cargar lotes de datos y cotejarlos, pero eso ser\xEDa mucho trabajo, y probablemente no muy eficiente. En cambio, existe un m\xE9todo que ofrece una soluci\xF3n eficiente para este problema: "),l=i("code"),b=o("to_tf_dataset()"),k=o(". Este envuelve un "),h=i("code"),_=o("tf.data.Dataset"),C=o(" alrededor de tu conjunto de datos, con una funci\xF3n opcional de cotejo. "),$=i("code"),q=o("tf.data.Dataset"),N=o(" es un formato nativo de TensorFlow que Keras puede usar con el "),F=i("code"),U=o("model.fit()"),B=o(", as\xED este m\xE9todo convierte inmediatamente un conjunto de datos \u{1F917} a un formato que viene listo para entrenamiento. Ve\xE1moslo en acci\xF3n con nuestro conjunto de datos."),ee=m(),g(L.$$.fragment),H=m(),J=i("p"),ce=o("Y eso es todo! Ahora podemos usar esos conjuntos de datos en nuestra pr\xF3xima clase, donde el entrenamiento ser\xE1 mas sencillo despu\xE9s de todo el trabajo de preprocesamiento de datos.")},l(P){t=c(P,"P",{});var T=d(t);u=n(T,"Ahora que tenemos nuestro conjunto de datos y el cotejador de datos, necesitamos juntarlos. Nosotros podriamos cargar lotes de datos y cotejarlos, pero eso ser\xEDa mucho trabajo, y probablemente no muy eficiente. En cambio, existe un m\xE9todo que ofrece una soluci\xF3n eficiente para este problema: "),l=c(T,"CODE",{});var Ds=d(l);b=n(Ds,"to_tf_dataset()"),Ds.forEach(a),k=n(T,". Este envuelve un "),h=c(T,"CODE",{});var de=d(h);_=n(de,"tf.data.Dataset"),de.forEach(a),C=n(T," alrededor de tu conjunto de datos, con una funci\xF3n opcional de cotejo. "),$=c(T,"CODE",{});var Ts=d($);q=n(Ts,"tf.data.Dataset"),Ts.forEach(a),N=n(T," es un formato nativo de TensorFlow que Keras puede usar con el "),F=c(T,"CODE",{});var As=d(F);U=n(As,"model.fit()"),As.forEach(a),B=n(T,", as\xED este m\xE9todo convierte inmediatamente un conjunto de datos \u{1F917} a un formato que viene listo para entrenamiento. Ve\xE1moslo en acci\xF3n con nuestro conjunto de datos."),T.forEach(a),ee=f(P),E(L.$$.fragment,P),H=f(P),J=c(P,"P",{});var Ge=d(J);ce=n(Ge,"Y eso es todo! Ahora podemos usar esos conjuntos de datos en nuestra pr\xF3xima clase, donde el entrenamiento ser\xE1 mas sencillo despu\xE9s de todo el trabajo de preprocesamiento de datos."),Ge.forEach(a)},m(P,T){p(P,t,T),s(t,u),s(t,l),s(l,b),s(t,k),s(t,h),s(h,_),s(t,C),s(t,$),s($,q),s(t,N),s(t,F),s(F,U),s(t,B),p(P,ee,T),y(L,P,T),p(P,H,T),p(P,J,T),s(J,ce),xe=!0},i(P){xe||(j(L.$$.fragment,P),xe=!0)},o(P){v(L.$$.fragment,P),xe=!1},d(P){P&&a(t),P&&a(ee),x(L,P),P&&a(H),P&&a(J)}}}function hd(w){let t,u,l,b,k,h,_,C,$,q,N,F,U,B,ee,L,H,J,ce,xe,P,T,Ds,de,Ts,As,Ge,qe,we,ia,Ve,In,ca,Wn,Eo,se,ae,Ss,K,Un,Ye,Bn,Gn,Je,Vn,Yn,Ke,Jn,Kn,yo,Os,Zn,xo,Ze,wo,Qe,zo,R,Qn,da,Xn,et,pa,st,at,ua,ot,nt,ma,tt,lt,fa,rt,it,Co,pe,ct,ha,dt,pt,_a,ut,mt,Po,ze,ft,ba,ht,_t,Do,Xe,To,es,Ao,ue,bt,ja,jt,vt,va,$t,kt,So,ss,Oo,as,No,S,qt,$a,gt,Et,ka,yt,xt,qa,wt,zt,ga,Ct,Pt,Ea,Dt,Tt,ya,At,St,xa,Ot,Nt,Lo,Ce,Mo,ge,Pe,wa,os,Lt,za,Mt,Fo,oe,ne,Ns,De,Ft,Ls,Ht,Rt,Ho,ns,Ro,Ms,It,Io,ts,Wo,ls,Uo,G,Wt,Ca,Ut,Bt,Pa,Gt,Vt,Fs,Yt,Jt,Da,Kt,Zt,Bo,Te,Go,Ae,Qt,Ta,Xt,el,Vo,rs,Yo,Hs,sl,Jo,is,Ko,me,al,Aa,ol,nl,Sa,tl,ll,Zo,cs,Qo,V,rl,Oa,il,cl,Na,dl,pl,La,ul,ml,Ma,fl,hl,Xo,Se,_l,Fa,bl,jl,en,fe,vl,Rs,$l,kl,Ha,ql,gl,sn,Is,El,an,Oe,yl,Ra,xl,wl,on,he,zl,Ws,Cl,Pl,Us,Dl,Tl,nn,ds,tn,Y,Al,Ia,Sl,Ol,Wa,Nl,Ll,Ua,Ml,Fl,ps,Hl,Rl,ln,_e,Il,us,Ba,Wl,Ul,Ga,Bl,Gl,rn,ms,cn,A,Vl,Va,Yl,Jl,Ya,Kl,Zl,Ja,Ql,Xl,Ka,er,sr,Za,ar,or,Qa,nr,tr,Xa,lr,rr,eo,ir,cr,fs,dr,pr,dn,Ne,ur,so,mr,fr,pn,be,hr,ao,_r,br,oo,jr,vr,un,hs,mn,Bs,$r,fn,_s,hn,je,kr,no,qr,gr,to,Er,yr,_n,I,xr,lo,wr,zr,ro,Cr,Pr,io,Dr,Tr,co,Ar,Sr,po,Or,Nr,bn,Le,Lr,uo,Mr,Fr,jn,Ee,Me,mo,bs,Hr,fo,Rr,vn,js,$n,Gs,Fe,Ir,ho,Wr,Ur,kn,te,le,Vs,Z,Br,_o,Gr,Vr,bo,Yr,Jr,jo,Kr,Zr,qn,vs,gn,$s,En,He,Qr,vo,Xr,ei,yn,ks,xn,re,ie,Ys,Re,wn,Js,zn;l=new Zc({props:{fw:w[0]}}),C=new Rn({});const ai=[Xc,Qc],qs=[];function oi(e,r){return e[0]==="pt"?0:1}U=oi(w),B=qs[U]=ai[U](w);const ni=[sd,ed],gs=[];function ti(e,r){return e[0]==="pt"?0:1}L=ti(w),H=gs[L]=ni[L](w),Ve=new Rn({});const li=[od,ad],Es=[];function ri(e,r){return e[0]==="pt"?0:1}se=ri(w),ae=Es[se]=li[se](w),Ze=new D({props:{code:`from datasets import load_dataset

raw_datasets = load_dataset("glue", "mrpc")
raw_datasets`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

raw_datasets = load_dataset(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mrpc&quot;</span>)
raw_datasets`}}),Qe=new D({props:{code:`DatasetDict({
    train: Dataset({
        features: ['sentence1', 'sentence2', 'label', 'idx'],
        num_rows: 3668
    })
    validation: Dataset({
        features: ['sentence1', 'sentence2', 'label', 'idx'],
        num_rows: 408
    })
    test: Dataset({
        features: ['sentence1', 'sentence2', 'label', 'idx'],
        num_rows: 1725
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;sentence1&#x27;</span>, <span class="hljs-string">&#x27;sentence2&#x27;</span>, <span class="hljs-string">&#x27;label&#x27;</span>, <span class="hljs-string">&#x27;idx&#x27;</span>],
        num_rows: <span class="hljs-number">3668</span>
    })
    validation: Dataset({
        features: [<span class="hljs-string">&#x27;sentence1&#x27;</span>, <span class="hljs-string">&#x27;sentence2&#x27;</span>, <span class="hljs-string">&#x27;label&#x27;</span>, <span class="hljs-string">&#x27;idx&#x27;</span>],
        num_rows: <span class="hljs-number">408</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;sentence1&#x27;</span>, <span class="hljs-string">&#x27;sentence2&#x27;</span>, <span class="hljs-string">&#x27;label&#x27;</span>, <span class="hljs-string">&#x27;idx&#x27;</span>],
        num_rows: <span class="hljs-number">1725</span>
    })
})`}}),Xe=new D({props:{code:`raw_train_dataset = raw_datasets["train"]
raw_train_dataset[0]`,highlighted:`raw_train_dataset = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>]
raw_train_dataset[<span class="hljs-number">0</span>]`}}),es=new D({props:{code:`{'idx': 0,
 'label': 1,
 'sentence1': 'Amrozi accused his brother , whom he called " the witness " , of deliberately distorting his evidence .',
 'sentence2': 'Referring to him as only " the witness " , Amrozi accused his brother of deliberately distorting his evidence .'}`,highlighted:`{<span class="hljs-string">&#x27;idx&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">1</span>,
 <span class="hljs-string">&#x27;sentence1&#x27;</span>: <span class="hljs-string">&#x27;Amrozi accused his brother , whom he called &quot; the witness &quot; , of deliberately distorting his evidence .&#x27;</span>,
 <span class="hljs-string">&#x27;sentence2&#x27;</span>: <span class="hljs-string">&#x27;Referring to him as only &quot; the witness &quot; , Amrozi accused his brother of deliberately distorting his evidence .&#x27;</span>}`}}),ss=new D({props:{code:"raw_train_dataset.features",highlighted:"raw_train_dataset.features"}}),as=new D({props:{code:`{'sentence1': Value(dtype='string', id=None),
 'sentence2': Value(dtype='string', id=None),
 'label': ClassLabel(num_classes=2, names=['not_equivalent', 'equivalent'], names_file=None, id=None),
 'idx': Value(dtype='int32', id=None)}`,highlighted:`{<span class="hljs-string">&#x27;sentence1&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
 <span class="hljs-string">&#x27;sentence2&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;string&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
 <span class="hljs-string">&#x27;label&#x27;</span>: ClassLabel(num_classes=<span class="hljs-number">2</span>, names=[<span class="hljs-string">&#x27;not_equivalent&#x27;</span>, <span class="hljs-string">&#x27;equivalent&#x27;</span>], names_file=<span class="hljs-literal">None</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>),
 <span class="hljs-string">&#x27;idx&#x27;</span>: Value(dtype=<span class="hljs-string">&#x27;int32&#x27;</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)}`}}),Ce=new si({props:{$$slots:{default:[nd]},$$scope:{ctx:w}}}),os=new Rn({});const ii=[ld,td],ys=[];function ci(e,r){return e[0]==="pt"?0:1}oe=ci(w),ne=ys[oe]=ii[oe](w),ns=new D({props:{code:`from transformers import AutoTokenizer

checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
tokenized_sentences_1 = tokenizer(raw_datasets["train"]["sentence1"])
tokenized_sentences_2 = tokenizer(raw_datasets["train"]["sentence2"])`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

checkpoint = <span class="hljs-string">&quot;bert-base-uncased&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
tokenized_sentences_1 = tokenizer(raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-string">&quot;sentence1&quot;</span>])
tokenized_sentences_2 = tokenizer(raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-string">&quot;sentence2&quot;</span>])`}}),ts=new D({props:{code:`inputs = tokenizer("This is the first sentence.", "This is the second one.")
inputs`,highlighted:`inputs = tokenizer(<span class="hljs-string">&quot;This is the first sentence.&quot;</span>, <span class="hljs-string">&quot;This is the second one.&quot;</span>)
inputs`}}),ls=new D({props:{code:`{ 
  'input_ids': [101, 2023, 2003, 1996, 2034, 6251, 1012, 102, 2023, 2003, 1996, 2117, 2028, 1012, 102],
  'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1],
  'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
}`,highlighted:`{ 
  <span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">2023</span>, <span class="hljs-number">2003</span>, <span class="hljs-number">1996</span>, <span class="hljs-number">2034</span>, <span class="hljs-number">6251</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>, <span class="hljs-number">2023</span>, <span class="hljs-number">2003</span>, <span class="hljs-number">1996</span>, <span class="hljs-number">2117</span>, <span class="hljs-number">2028</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>],
  <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
  <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]
}`}}),Te=new si({props:{$$slots:{default:[rd]},$$scope:{ctx:w}}}),rs=new D({props:{code:'tokenizer.convert_ids_to_tokens(inputs["input_ids"])',highlighted:'tokenizer.convert_ids_to_tokens(inputs[<span class="hljs-string">&quot;input_ids&quot;</span>])'}}),is=new D({props:{code:"['[CLS]', 'this', 'is', 'the', 'first', 'sentence', '.', '[SEP]', 'this', 'is', 'the', 'second', 'one', '.', '[SEP]']",highlighted:'[<span class="hljs-string">&#x27;[CLS]&#x27;</span>, <span class="hljs-string">&#x27;this&#x27;</span>, <span class="hljs-string">&#x27;is&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;first&#x27;</span>, <span class="hljs-string">&#x27;sentence&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>, <span class="hljs-string">&#x27;this&#x27;</span>, <span class="hljs-string">&#x27;is&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;second&#x27;</span>, <span class="hljs-string">&#x27;one&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>]'}}),cs=new D({props:{code:`['[CLS]', 'this', 'is', 'the', 'first', 'sentence', '.', '[SEP]', 'this', 'is', 'the', 'second', 'one', '.', '[SEP]']
[      0,      0,    0,     0,       0,          0,   0,       0,      1,    1,     1,        1,     1,   1,       1]`,highlighted:`[<span class="hljs-string">&#x27;[CLS]&#x27;</span>, <span class="hljs-string">&#x27;this&#x27;</span>, <span class="hljs-string">&#x27;is&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;first&#x27;</span>, <span class="hljs-string">&#x27;sentence&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>, <span class="hljs-string">&#x27;this&#x27;</span>, <span class="hljs-string">&#x27;is&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;second&#x27;</span>, <span class="hljs-string">&#x27;one&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>]
[      <span class="hljs-number">0</span>,      <span class="hljs-number">0</span>,    <span class="hljs-number">0</span>,     <span class="hljs-number">0</span>,       <span class="hljs-number">0</span>,          <span class="hljs-number">0</span>,   <span class="hljs-number">0</span>,       <span class="hljs-number">0</span>,      <span class="hljs-number">1</span>,    <span class="hljs-number">1</span>,     <span class="hljs-number">1</span>,        <span class="hljs-number">1</span>,     <span class="hljs-number">1</span>,   <span class="hljs-number">1</span>,       <span class="hljs-number">1</span>]`}}),ds=new D({props:{code:`tokenized_dataset = tokenizer(
    raw_datasets["train"]["sentence1"],
    raw_datasets["train"]["sentence2"],
    padding=True,
    truncation=True,
)`,highlighted:`tokenized_dataset = tokenizer(
    raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-string">&quot;sentence1&quot;</span>],
    raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-string">&quot;sentence2&quot;</span>],
    padding=<span class="hljs-literal">True</span>,
    truncation=<span class="hljs-literal">True</span>,
)`}}),ms=new D({props:{code:`def tokenize_function(example):
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">example</span>):
    <span class="hljs-keyword">return</span> tokenizer(example[<span class="hljs-string">&quot;sentence1&quot;</span>], example[<span class="hljs-string">&quot;sentence2&quot;</span>], truncation=<span class="hljs-literal">True</span>)`}}),hs=new D({props:{code:`tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)
tokenized_datasets`,highlighted:`tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)
tokenized_datasets`}}),_s=new D({props:{code:`DatasetDict({
    train: Dataset({
        features: ['attention_mask', 'idx', 'input_ids', 'label', 'sentence1', 'sentence2', 'token_type_ids'],
        num_rows: 3668
    })
    validation: Dataset({
        features: ['attention_mask', 'idx', 'input_ids', 'label', 'sentence1', 'sentence2', 'token_type_ids'],
        num_rows: 408
    })
    test: Dataset({
        features: ['attention_mask', 'idx', 'input_ids', 'label', 'sentence1', 'sentence2', 'token_type_ids'],
        num_rows: 1725
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;idx&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;label&#x27;</span>, <span class="hljs-string">&#x27;sentence1&#x27;</span>, <span class="hljs-string">&#x27;sentence2&#x27;</span>, <span class="hljs-string">&#x27;token_type_ids&#x27;</span>],
        num_rows: <span class="hljs-number">3668</span>
    })
    validation: Dataset({
        features: [<span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;idx&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;label&#x27;</span>, <span class="hljs-string">&#x27;sentence1&#x27;</span>, <span class="hljs-string">&#x27;sentence2&#x27;</span>, <span class="hljs-string">&#x27;token_type_ids&#x27;</span>],
        num_rows: <span class="hljs-number">408</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;idx&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;label&#x27;</span>, <span class="hljs-string">&#x27;sentence1&#x27;</span>, <span class="hljs-string">&#x27;sentence2&#x27;</span>, <span class="hljs-string">&#x27;token_type_ids&#x27;</span>],
        num_rows: <span class="hljs-number">1725</span>
    })
})`}}),bs=new Rn({}),js=new go({props:{id:"7q5NyFT8REg"}});function di(e,r){return e[0]==="pt"?cd:id}let Cn=di(w),ye=Cn(w);const pi=[pd,dd],xs=[];function ui(e,r){return e[0]==="pt"?0:1}te=ui(w),le=xs[te]=pi[te](w),vs=new D({props:{code:`samples = tokenized_datasets["train"][:8]
samples = {k: v for k, v in samples.items() if k not in ["idx", "sentence1", "sentence2"]}
[len(x) for x in samples["input_ids"]]`,highlighted:`samples = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>][:<span class="hljs-number">8</span>]
samples = {k: v <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> samples.items() <span class="hljs-keyword">if</span> k <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;idx&quot;</span>, <span class="hljs-string">&quot;sentence1&quot;</span>, <span class="hljs-string">&quot;sentence2&quot;</span>]}
[<span class="hljs-built_in">len</span>(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> samples[<span class="hljs-string">&quot;input_ids&quot;</span>]]`}}),$s=new D({props:{code:"[50, 59, 47, 67, 59, 50, 62, 32]",highlighted:'[<span class="hljs-number">50</span>, <span class="hljs-number">59</span>, <span class="hljs-number">47</span>, <span class="hljs-number">67</span>, <span class="hljs-number">59</span>, <span class="hljs-number">50</span>, <span class="hljs-number">62</span>, <span class="hljs-number">32</span>]'}}),ks=new D({props:{code:`batch = data_collator(samples)
{k: v.shape for k, v in batch.items()}`,highlighted:`batch = data_collator(samples)
{k: v.shape <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}`}});const mi=[md,ud],ws=[];function fi(e,r){return e[0]==="tf"?0:1}re=fi(w),ie=ws[re]=mi[re](w),Re=new si({props:{$$slots:{default:[fd]},$$scope:{ctx:w}}});let M=w[0]==="tf"&&Uc();return{c(){t=i("meta"),u=m(),g(l.$$.fragment),b=m(),k=i("h1"),h=i("a"),_=i("span"),g(C.$$.fragment),$=m(),q=i("span"),N=o("Procesando los datos"),F=m(),B.c(),ee=m(),H.c(),J=m(),ce=i("p"),xe=o("Por supuesto, entrenando el modelo con solo dos oraciones no va a producir muy buenos resultados. Para obtener mejores resultados, debes preparar un conjunto de datos m\xE1s grande."),P=m(),T=i("p"),Ds=o("En esta secci\xF3n usaremos como ejemplo el conjunto de datos MRPC (Cuerpo de par\xE1frasis de investigaciones de Microsoft), que fue presentado en el "),de=i("a"),Ts=o("art\xEDculo"),As=o(" de William B. Dolan and Chris Brockett. El conjunto de datos consiste en 5,801 pares of oraciones, con una etiqueta que indica si son par\xE1frasis o no. (es decir, si ambas oraciones significan lo mismo). Hemos seleccionado el mismo para este cap\xEDtulo porque es un conjunto de datos peque\xF1o que facilita la experimentaci\xF3n y entrenamiento sobre \xE9l."),Ge=m(),qe=i("h3"),we=i("a"),ia=i("span"),g(Ve.$$.fragment),In=m(),ca=i("span"),Wn=o("Cargando un conjunto de datos desde el Hub"),Eo=m(),ae.c(),Ss=m(),K=i("p"),Un=o("El Hub no solo contiene modelos; sino que tambi\xE9n tiene m\xFAltiples conjunto de datos en diferentes idiomas. Puedes explorar los conjuntos de datos "),Ye=i("a"),Bn=o("aqu\xED"),Gn=o(", y recomendamos que trates de cargar y procesar un nuevo conjunto de datos una vez que hayas revisado esta secci\xF3n (mira la documentaci\xF3n general "),Je=i("a"),Vn=o("aqu\xED"),Yn=o("). Por ahora, enfoqu\xE9monos en el conjunto de datos MRPC! Este es uno de los 10 conjuntos de datos que comprende el "),Ke=i("a"),Jn=o("punto de referencia GLUE"),Kn=o(", el cual es un punto de referencia acad\xE9mico que se usa para medir el desempe\xF1o de modelos ML sobre 10 tareas de clasificaci\xF3n de texto."),yo=m(),Os=i("p"),Zn=o("La Libreria Datasets \u{1F917} provee un comando muy simple para descargar y memorizar un conjunto de datos en el Hub. Podemos descargar el conjunto de datos de la siguiente manera:"),xo=m(),g(Ze.$$.fragment),wo=m(),g(Qe.$$.fragment),zo=m(),R=i("p"),Qn=o("Como puedes ver, obtenemos un objeto "),da=i("code"),Xn=o("DatasetDict"),et=o(" que contiene los conjuntos de datos de entrenamiento, de validaci\xF3n y de pruebas. Cada uno de estos contiene varias columnas ("),pa=i("code"),st=o("sentence1"),at=o(", "),ua=i("code"),ot=o("sentence2"),nt=o(", "),ma=i("code"),tt=o("label"),lt=o(", and "),fa=i("code"),rt=o("idx"),it=o(") y un n\xFAmero variable de filas, que son el n\xFAmero de elementos en cada conjunto (asi, que hay 3,668 pares de oraciones en el conjunto de entrenamiento, 408 en el de validaci\xF3n, y 1,725 en el pruebas)"),Co=m(),pe=i("p"),ct=o("Este comando descarga y almacena el conjunto de datos, por defecto en "),ha=i("em"),dt=o("~/.cache/huggingface/dataset"),pt=o(". Recuerda del Cap\xEDtulo 2 que puedes personalizar tu carpeta mediante la configuraci\xF3n de la variable de entorno "),_a=i("code"),ut=o("HF_HOME"),mt=o("."),Po=m(),ze=i("p"),ft=o("Podemos acceder a cada par de oraciones en nuestro objeto "),ba=i("code"),ht=o("raw_datasets"),_t=o(" usando indexaci\xF3n, como con un diccionario."),Do=m(),g(Xe.$$.fragment),To=m(),g(es.$$.fragment),Ao=m(),ue=i("p"),bt=o("Podemos ver que las etiquetas ya son n\xFAmeros enteros, as\xED que no es necesario hacer ning\xFAn preprocesamiento. Para saber cual valor corresponde con cual etiqueta, podemos inspeccionar el atributo "),ja=i("code"),jt=o("features"),vt=o(" de nuestro "),va=i("code"),$t=o("raw_train_dataset"),kt=o(". Esto indicara el tipo dato de cada columna:"),So=m(),g(ss.$$.fragment),Oo=m(),g(as.$$.fragment),No=m(),S=i("p"),qt=o("Internamente, "),$a=i("code"),gt=o("label"),Et=o(" es del tipo de dato "),ka=i("code"),yt=o("ClassLabel"),xt=o(", y la asociaci\xF3n de valores enteros y sus etiquetas esta almacenado en la carpeta "),qa=i("em"),wt=o("names"),zt=o(". "),ga=i("code"),Ct=o("0"),Pt=o(" corresponde con "),Ea=i("code"),Dt=o("not_equivalent"),Tt=o(", y "),ya=i("code"),At=o("1"),St=o(" corresponde con "),xa=i("code"),Ot=o("equivalent"),Nt=o("."),Lo=m(),g(Ce.$$.fragment),Mo=m(),ge=i("h3"),Pe=i("a"),wa=i("span"),g(os.$$.fragment),Lt=m(),za=i("span"),Mt=o("Preprocesando un conjunto de datos"),Fo=m(),ne.c(),Ns=m(),De=i("p"),Ft=o("Para preprocesar el conjunto de datos, necesitamos convertir el texto en n\xFAmeros que puedan ser entendidos por el modelo. Como viste en el "),Ls=i("a"),Ht=o("cap\xEDtulo anterior"),Rt=o(", esto se hace con el tokenizador. Podemos darle al tokenizador una oraci\xF3n o una lista de oraciones, as\xED podemos tokenizar directamente todas las primeras y las segundas oraciones de cada par de la siguiente manera:"),Ho=m(),g(ns.$$.fragment),Ro=m(),Ms=i("p"),It=o(`Sin embargo, no podemos simplemente pasar dos secuencias al modelo y obtener una predicci\xF3n indicando si estas son par\xE1frasis o no. Necesitamos manipular las dos secuencias como un par y aplicar el preprocesamiento apropiado.
Afortunadamente, el tokenizador puede recibir tambi\xE9n un par de oraciones y preparar las misma de una forma que nuestro modelo BERT espera:`),Io=m(),g(ts.$$.fragment),Wo=m(),g(ls.$$.fragment),Uo=m(),G=i("p"),Wt=o("Nosotros consideramos las llaves "),Ca=i("code"),Ut=o("input_ids"),Bt=o(" y "),Pa=i("code"),Gt=o("attention_mask"),Vt=o(" en el "),Fs=i("a"),Yt=o("Cap\xEDtulo 2"),Jt=o(", pero postergamos hablar sobre la llave "),Da=i("code"),Kt=o("token_type_ids"),Zt=o(". En este ejemplo, esta es la que le dice al modelo cual parte de la entrada es la primera oraci\xF3n y cual es la segunda."),Bo=m(),g(Te.$$.fragment),Go=m(),Ae=i("p"),Qt=o("Si convertimos los IDs dentro de "),Ta=i("code"),Xt=o("input_ids"),el=o(" en palabras:"),Vo=m(),g(rs.$$.fragment),Yo=m(),Hs=i("p"),sl=o("obtendremos:"),Jo=m(),g(is.$$.fragment),Ko=m(),me=i("p"),al=o("De esta manera vemos que el modelo espera las entradas de la siguiente forma "),Aa=i("code"),ol=o("[CLS] sentence1 [SEP] sentence2 [SEP]"),nl=o(" cuando hay dos oraciones. Alineando esto con los "),Sa=i("code"),tl=o("token_type_ids"),ll=o(" obtenemos:"),Zo=m(),g(cs.$$.fragment),Qo=m(),V=i("p"),rl=o("Como puedes observar, las partes de la entrada que corresponden a "),Oa=i("code"),il=o("[CLS] sentence1 [SEP]"),cl=o(" todas tienen un tipo de token ID "),Na=i("code"),dl=o("0"),pl=o(", mientras que las otras partes que corresponden a "),La=i("code"),ul=o("sentence2 [SEP]"),ml=o(", todas tienen tipo ID "),Ma=i("code"),fl=o("1"),hl=o("."),Xo=m(),Se=i("p"),_l=o("N\xF3tese que si seleccionas un punto de control diferente, no necesariamente tendr\xE1s el "),Fa=i("code"),bl=o("token_type_ids"),jl=o(" en tus entradas tonenizadas (por ejemplo, ellas no aparecen si usas un modelo DistilBERT). Estas aparecen cuando el modelo sabe que hacer con ellas, porque las ha visto durante su etapa de preentrenamiento."),en=m(),fe=i("p"),vl=o("Aqu\xED, BERT esta preentrenado con tokens de tipo ID, y adem\xE1s del objetivo de modelado de lenguaje oculto que mencionamos en el "),Rs=i("a"),$l=o("Cap\xEDtulo 1"),kl=o(", tambi\xE9n tiene el objetivo llamado "),Ha=i("em"),ql=o("predicci\xF3n de la siguiente oraci\xF3n"),gl=o(". El objectivo con esta tarea es modelar la relaci\xF3n entre pares de oraciones."),sn=m(),Is=i("p"),El=o("Para predecir la siguiente oraci\xF3n, el modelo recibe pares de oraciones (con tokens ocultados aleatoriamente) y se le pide que prediga si la segunda secuencia sigue a la primera. Para que la tarea no sea tan simple, la mitad de las veces las oraciones estan seguidas en el texto original de donde se obtuvieron, y la otra mitad las oraciones vienen de dos documentos distintos."),an=m(),Oe=i("p"),yl=o("En general, no debes preocuparte si los "),Ra=i("code"),xl=o("token_type_ids"),wl=o(" estan o no en las entradas tokenizadas: con tal que uses el mismo punto de control para el tokenizador y el modelo, todo estar\xE1 bien porque el tokenizador sabe que pasarle a su modelo."),on=m(),he=i("p"),zl=o("Ahora que hemos visto como nuestro tokenizador puede trabajar con un par de oraciones, podemos usarlo para tokenizar todo el conjunto de datos: como en el "),Ws=i("a"),Cl=o("cap\xEDtulo anterior"),Pl=o(", podemos darle al tokenizador una lista de pares de oraciones, d\xE1ndole la lista de las primeras oraciones, y luego la lista de las segundas oraciones. Esto tambi\xE9n es compatible con las opciones de relleno y truncamiento que vimos en el "),Us=i("a"),Dl=o("Cap\xEDtulo 2"),Tl=o(". Por lo tanto, una manera de preprocessar el conjunto de datos de entrenamiento ser\xEDa:"),nn=m(),g(ds.$$.fragment),tn=m(),Y=i("p"),Al=o("Esto funciona bien, pero tiene la desventaja de que devuelve un diccionario (con nuestras llaves, "),Ia=i("code"),Sl=o("input_ids"),Ol=o(", "),Wa=i("code"),Nl=o("attention_mask"),Ll=o(", and "),Ua=i("code"),Ml=o("token_type_ids"),Fl=o(", y valores que son listas de listas). Adem\xE1s va a trabajar solo si tienes suficiente memoria principal para almacenar todo el conjunto de datos durante la tokenizaci\xF3n (mientras que los conjuntos de datos de la librer\xEDa Datasets \u{1F917} son archivos "),ps=i("a"),Hl=o("Apache Arrow"),Rl=o(" almacenados en disco, y as\xED solo mantienes en memoria las muestras que necesitas)."),ln=m(),_e=i("p"),Il=o("Para mantener los datos como un conjunto de datos, usaremos el m\xE9todo "),us=i("a"),Ba=i("code"),Wl=o("Dataset.map()"),Ul=o(". Este tambi\xE9n nos ofrece una flexibilidad adicional en caso de que necesitemos preprocesamiento mas all\xE1 de la tokenizaci\xF3n. El m\xE9todo "),Ga=i("code"),Bl=o("map()"),Gl=o(" trabaja aplicando una funci\xF3n sobre cada elemento del conjunto de datos, as\xED que definamos una funci\xF3n para tokenizar nuestras entradas:"),rn=m(),g(ms.$$.fragment),cn=m(),A=i("p"),Vl=o("Esta funci\xF3n recibe un diccionario (como los elementos de nuestro conjunto de datos) y devuelve un nuevo diccionario con las llaves "),Va=i("code"),Yl=o("input_ids"),Jl=o(", "),Ya=i("code"),Kl=o("attention_mask"),Zl=o(", y "),Ja=i("code"),Ql=o("token_type_ids"),Xl=o(". N\xF3tese que tambi\xE9n funciona si el diccionario "),Ka=i("code"),er=o("example"),sr=o(" contiene m\xFAltiples elementos (cada llave con una lista de oraciones) debido a que el "),Za=i("code"),ar=o("tokenizador"),or=o(" funciona con listas de pares de oraciones, como se vio anteriormente. Esto nos va a permitir usar la opci\xF3n "),Qa=i("code"),nr=o("batched=True"),tr=o(" en nuestra llamada a "),Xa=i("code"),lr=o("map()"),rr=o(", lo que acelera la tokenizaci\xF3n significativamente. El "),eo=i("code"),ir=o("tokenizador"),cr=o(" es respaldado por un tokenizador escrito en Rust que viene de la libreria "),fs=i("a"),dr=o("Tokenizadores \u{1F917}"),pr=o(". Este tokenizador puede ser muy r\xE1pido, pero solo si le da muchas entradas al mismo tiempo."),dn=m(),Ne=i("p"),ur=o("N\xF3tese que por ahora hemos dejado el argumento "),so=i("code"),mr=o("padding"),fr=o(" fuera de nuestra funci\xF3n de tokenizaci\xF3n. Esto es porque rellenar todos los elementos hasta su m\xE1xima longitud no es eficiente: es mejor rellenar los elememtos cuando se esta construyendo el lote, debido a que solo debemos rellenar hasta la m\xE1xima longitud en el lote, pero no en todo el conjunto de datos. Esto puede ahorrar mucho tiempo y poder de processamiento cuando las entradas tienen longitudes variables."),pn=m(),be=i("p"),hr=o("Aqu\xED se muestra como se aplica la funci\xF3n de tokenizaci\xF3n a todo el conjunto de datos en un solo paso. Estamos usando "),ao=i("code"),_r=o("batched=True"),br=o(" en nuestra llamada a "),oo=i("code"),jr=o("map"),vr=o(" para que la funci\xF3n sea aplicada a m\xFAltiples elementos de nuestro conjunto de datos al mismo tiempo, y no a cada elemento por separado. Esto permite un preprocesamiento m\xE1s r\xE1pido."),un=m(),g(hs.$$.fragment),mn=m(),Bs=i("p"),$r=o("La manera en que la libreria \u{1F917} aplica este procesamiento es a trav\xE9s de campos a\xF1adidos al conjunto de datos, uno por cada diccionario devuelto por la funci\xF3n de preprocesamiento."),fn=m(),g(_s.$$.fragment),hn=m(),je=i("p"),kr=o("Hasta puedes usar multiprocesamiento cuando aplicas la funci\xF3n de preprocesamiento con "),no=i("code"),qr=o("map()"),gr=o(" pasando el argumento "),to=i("code"),Er=o("num_proc"),yr=o(". Nosotros no usamos esta opci\xF3n porque los Tokenizadores de la libreria \u{1F917} usa m\xFAltiples hilos de procesamiento para tokenizar r\xE1pidamente nuestros elementos, pero sino estas usando un tokenizador r\xE1pido respaldado por esta libreria, esta opci\xF3n puede acelerar tu preprocesamiento."),_n=m(),I=i("p"),xr=o("Nuestra funci\xF3n "),lo=i("code"),wr=o("tokenize_function"),zr=o(" devuelve un diccionario con las llaves "),ro=i("code"),Cr=o("input_ids"),Pr=o(", "),io=i("code"),Dr=o("attention_mask"),Tr=o(", y "),co=i("code"),Ar=o("token_type_ids"),Sr=o(", as\xED que esos tres campos son adicionados a todas las divisiones de nuestro conjunto de datos. N\xF3tese que pudimos haber cambiado los campos existentes si nuestra funci\xF3n de preprocesamiento hubiese devuelto un valor nuevo para cualquiera de las llaves en el conjunto de datos al que le aplicamos "),po=i("code"),Or=o("map()"),Nr=o("."),bn=m(),Le=i("p"),Lr=o("Lo \xFAltimo que necesitamos hacer es rellenar todos los elementos hasta la longitud del elemento m\xE1s largo al momento de agrupar los elementos - a esta t\xE9cnica la llamamos "),uo=i("em"),Mr=o("relleno din\xE1mico"),Fr=o("."),jn=m(),Ee=i("h3"),Me=i("a"),mo=i("span"),g(bs.$$.fragment),Hr=m(),fo=i("span"),Rr=o("Relleno Din\xE1mico"),vn=m(),g(js.$$.fragment),$n=m(),ye.c(),Gs=m(),Fe=i("p"),Ir=o("Para poner esto en pr\xE1ctica, tenemos que definir una funci\xF3n de cotejo que aplique la cantidad correcta de relleno a los elementos del conjunto de datos que queremos agrupar. Afortundamente, la libreria Transformers de \u{1F917} nos provee esta funci\xF3n mediante "),ho=i("code"),Wr=o("DataCollatorWithPadding"),Ur=o(". Esta recibe un tokenizador cuando la creas (para saber cual token de relleno se debe usar, y si el modelo espera el relleno a la izquierda o la derecha en las entradas) y hace todo lo que necesitas:"),kn=m(),le.c(),Vs=m(),Z=i("p"),Br=o("Para probar este nuevo juguete, tomemos algunos elementos de nuestro conjunto de datos de entrenamiento para agruparlos. Aqu\xED, removemos las columnas "),_o=i("code"),Gr=o("idx"),Vr=o(", "),bo=i("code"),Yr=o("sentence1"),Jr=o(", and "),jo=i("code"),Kr=o("sentence2"),Zr=o(" ya que \xE9stas no se necesitan y contienen cadenas (y no podemos crear tensores con cadenas), miremos las longitudes de cada elemento en el lote."),qn=m(),g(vs.$$.fragment),gn=m(),g($s.$$.fragment),En=m(),He=i("p"),Qr=o("Como era de esperarse, obtenemos elementos de longitud variable, desde 32 hasta 67. El relleno din\xE1mico significa que los elementos en este lote deben ser rellenos hasta una longitud de 67, que es la m\xE1xima longitud en el lote. Sin relleno din\xE1mico, todos los elementos tendr\xEDan que haber sido rellenos hasta el m\xE1ximo de todo el conjunto de datos, o el m\xE1ximo aceptado por el modelo. Verifiquemos que nuestro "),vo=i("code"),Xr=o("data_collator"),ei=o(" esta rellenando din\xE1micamente el lote de la manera apropiada:"),yn=m(),g(ks.$$.fragment),xn=m(),ie.c(),Ys=m(),g(Re.$$.fragment),wn=m(),M&&M.c(),Js=Wc(),this.h()},l(e){const r=Jc('[data-svelte="svelte-1phssyn"]',document.head);t=c(r,"META",{name:!0,content:!0}),r.forEach(a),u=f(e),E(l.$$.fragment,e),b=f(e),k=c(e,"H1",{class:!0});var zs=d(k);h=c(zs,"A",{id:!0,class:!0,href:!0});var Ks=d(h);_=c(Ks,"SPAN",{});var Zs=d(_);E(C.$$.fragment,Zs),Zs.forEach(a),Ks.forEach(a),$=f(zs),q=c(zs,"SPAN",{});var Qs=d(q);N=n(Qs,"Procesando los datos"),Qs.forEach(a),zs.forEach(a),F=f(e),B.l(e),ee=f(e),H.l(e),J=f(e),ce=c(e,"P",{});var $o=d(ce);xe=n($o,"Por supuesto, entrenando el modelo con solo dos oraciones no va a producir muy buenos resultados. Para obtener mejores resultados, debes preparar un conjunto de datos m\xE1s grande."),$o.forEach(a),P=f(e),T=c(e,"P",{});var Ie=d(T);Ds=n(Ie,"En esta secci\xF3n usaremos como ejemplo el conjunto de datos MRPC (Cuerpo de par\xE1frasis de investigaciones de Microsoft), que fue presentado en el "),de=c(Ie,"A",{href:!0,rel:!0});var ko=d(de);Ts=n(ko,"art\xEDculo"),ko.forEach(a),As=n(Ie," de William B. Dolan and Chris Brockett. El conjunto de datos consiste en 5,801 pares of oraciones, con una etiqueta que indica si son par\xE1frasis o no. (es decir, si ambas oraciones significan lo mismo). Hemos seleccionado el mismo para este cap\xEDtulo porque es un conjunto de datos peque\xF1o que facilita la experimentaci\xF3n y entrenamiento sobre \xE9l."),Ie.forEach(a),Ge=f(e),qe=c(e,"H3",{class:!0});var We=d(qe);we=c(We,"A",{id:!0,class:!0,href:!0});var Xs=d(we);ia=c(Xs,"SPAN",{});var qo=d(ia);E(Ve.$$.fragment,qo),qo.forEach(a),Xs.forEach(a),In=f(We),ca=c(We,"SPAN",{});var hi=d(ca);Wn=n(hi,"Cargando un conjunto de datos desde el Hub"),hi.forEach(a),We.forEach(a),Eo=f(e),ae.l(e),Ss=f(e),K=c(e,"P",{});var Ue=d(K);Un=n(Ue,"El Hub no solo contiene modelos; sino que tambi\xE9n tiene m\xFAltiples conjunto de datos en diferentes idiomas. Puedes explorar los conjuntos de datos "),Ye=c(Ue,"A",{href:!0,rel:!0});var _i=d(Ye);Bn=n(_i,"aqu\xED"),_i.forEach(a),Gn=n(Ue,", y recomendamos que trates de cargar y procesar un nuevo conjunto de datos una vez que hayas revisado esta secci\xF3n (mira la documentaci\xF3n general "),Je=c(Ue,"A",{href:!0,rel:!0});var bi=d(Je);Vn=n(bi,"aqu\xED"),bi.forEach(a),Yn=n(Ue,"). Por ahora, enfoqu\xE9monos en el conjunto de datos MRPC! Este es uno de los 10 conjuntos de datos que comprende el "),Ke=c(Ue,"A",{href:!0,rel:!0});var ji=d(Ke);Jn=n(ji,"punto de referencia GLUE"),ji.forEach(a),Kn=n(Ue,", el cual es un punto de referencia acad\xE9mico que se usa para medir el desempe\xF1o de modelos ML sobre 10 tareas de clasificaci\xF3n de texto."),Ue.forEach(a),yo=f(e),Os=c(e,"P",{});var vi=d(Os);Zn=n(vi,"La Libreria Datasets \u{1F917} provee un comando muy simple para descargar y memorizar un conjunto de datos en el Hub. Podemos descargar el conjunto de datos de la siguiente manera:"),vi.forEach(a),xo=f(e),E(Ze.$$.fragment,e),wo=f(e),E(Qe.$$.fragment,e),zo=f(e),R=c(e,"P",{});var Q=d(R);Qn=n(Q,"Como puedes ver, obtenemos un objeto "),da=c(Q,"CODE",{});var $i=d(da);Xn=n($i,"DatasetDict"),$i.forEach(a),et=n(Q," que contiene los conjuntos de datos de entrenamiento, de validaci\xF3n y de pruebas. Cada uno de estos contiene varias columnas ("),pa=c(Q,"CODE",{});var ki=d(pa);st=n(ki,"sentence1"),ki.forEach(a),at=n(Q,", "),ua=c(Q,"CODE",{});var qi=d(ua);ot=n(qi,"sentence2"),qi.forEach(a),nt=n(Q,", "),ma=c(Q,"CODE",{});var gi=d(ma);tt=n(gi,"label"),gi.forEach(a),lt=n(Q,", and "),fa=c(Q,"CODE",{});var Ei=d(fa);rt=n(Ei,"idx"),Ei.forEach(a),it=n(Q,") y un n\xFAmero variable de filas, que son el n\xFAmero de elementos en cada conjunto (asi, que hay 3,668 pares de oraciones en el conjunto de entrenamiento, 408 en el de validaci\xF3n, y 1,725 en el pruebas)"),Q.forEach(a),Co=f(e),pe=c(e,"P",{});var ea=d(pe);ct=n(ea,"Este comando descarga y almacena el conjunto de datos, por defecto en "),ha=c(ea,"EM",{});var yi=d(ha);dt=n(yi,"~/.cache/huggingface/dataset"),yi.forEach(a),pt=n(ea,". Recuerda del Cap\xEDtulo 2 que puedes personalizar tu carpeta mediante la configuraci\xF3n de la variable de entorno "),_a=c(ea,"CODE",{});var xi=d(_a);ut=n(xi,"HF_HOME"),xi.forEach(a),mt=n(ea,"."),ea.forEach(a),Po=f(e),ze=c(e,"P",{});var Pn=d(ze);ft=n(Pn,"Podemos acceder a cada par de oraciones en nuestro objeto "),ba=c(Pn,"CODE",{});var wi=d(ba);ht=n(wi,"raw_datasets"),wi.forEach(a),_t=n(Pn," usando indexaci\xF3n, como con un diccionario."),Pn.forEach(a),Do=f(e),E(Xe.$$.fragment,e),To=f(e),E(es.$$.fragment,e),Ao=f(e),ue=c(e,"P",{});var sa=d(ue);bt=n(sa,"Podemos ver que las etiquetas ya son n\xFAmeros enteros, as\xED que no es necesario hacer ning\xFAn preprocesamiento. Para saber cual valor corresponde con cual etiqueta, podemos inspeccionar el atributo "),ja=c(sa,"CODE",{});var zi=d(ja);jt=n(zi,"features"),zi.forEach(a),vt=n(sa," de nuestro "),va=c(sa,"CODE",{});var Ci=d(va);$t=n(Ci,"raw_train_dataset"),Ci.forEach(a),kt=n(sa,". Esto indicara el tipo dato de cada columna:"),sa.forEach(a),So=f(e),E(ss.$$.fragment,e),Oo=f(e),E(as.$$.fragment,e),No=f(e),S=c(e,"P",{});var W=d(S);qt=n(W,"Internamente, "),$a=c(W,"CODE",{});var Pi=d($a);gt=n(Pi,"label"),Pi.forEach(a),Et=n(W," es del tipo de dato "),ka=c(W,"CODE",{});var Di=d(ka);yt=n(Di,"ClassLabel"),Di.forEach(a),xt=n(W,", y la asociaci\xF3n de valores enteros y sus etiquetas esta almacenado en la carpeta "),qa=c(W,"EM",{});var Ti=d(qa);wt=n(Ti,"names"),Ti.forEach(a),zt=n(W,". "),ga=c(W,"CODE",{});var Ai=d(ga);Ct=n(Ai,"0"),Ai.forEach(a),Pt=n(W," corresponde con "),Ea=c(W,"CODE",{});var Si=d(Ea);Dt=n(Si,"not_equivalent"),Si.forEach(a),Tt=n(W,", y "),ya=c(W,"CODE",{});var Oi=d(ya);At=n(Oi,"1"),Oi.forEach(a),St=n(W," corresponde con "),xa=c(W,"CODE",{});var Ni=d(xa);Ot=n(Ni,"equivalent"),Ni.forEach(a),Nt=n(W,"."),W.forEach(a),Lo=f(e),E(Ce.$$.fragment,e),Mo=f(e),ge=c(e,"H3",{class:!0});var Dn=d(ge);Pe=c(Dn,"A",{id:!0,class:!0,href:!0});var Li=d(Pe);wa=c(Li,"SPAN",{});var Mi=d(wa);E(os.$$.fragment,Mi),Mi.forEach(a),Li.forEach(a),Lt=f(Dn),za=c(Dn,"SPAN",{});var Fi=d(za);Mt=n(Fi,"Preprocesando un conjunto de datos"),Fi.forEach(a),Dn.forEach(a),Fo=f(e),ne.l(e),Ns=f(e),De=c(e,"P",{});var Tn=d(De);Ft=n(Tn,"Para preprocesar el conjunto de datos, necesitamos convertir el texto en n\xFAmeros que puedan ser entendidos por el modelo. Como viste en el "),Ls=c(Tn,"A",{href:!0});var Hi=d(Ls);Ht=n(Hi,"cap\xEDtulo anterior"),Hi.forEach(a),Rt=n(Tn,", esto se hace con el tokenizador. Podemos darle al tokenizador una oraci\xF3n o una lista de oraciones, as\xED podemos tokenizar directamente todas las primeras y las segundas oraciones de cada par de la siguiente manera:"),Tn.forEach(a),Ho=f(e),E(ns.$$.fragment,e),Ro=f(e),Ms=c(e,"P",{});var Ri=d(Ms);It=n(Ri,`Sin embargo, no podemos simplemente pasar dos secuencias al modelo y obtener una predicci\xF3n indicando si estas son par\xE1frasis o no. Necesitamos manipular las dos secuencias como un par y aplicar el preprocesamiento apropiado.
Afortunadamente, el tokenizador puede recibir tambi\xE9n un par de oraciones y preparar las misma de una forma que nuestro modelo BERT espera:`),Ri.forEach(a),Io=f(e),E(ts.$$.fragment,e),Wo=f(e),E(ls.$$.fragment,e),Uo=f(e),G=c(e,"P",{});var ve=d(G);Wt=n(ve,"Nosotros consideramos las llaves "),Ca=c(ve,"CODE",{});var Ii=d(Ca);Ut=n(Ii,"input_ids"),Ii.forEach(a),Bt=n(ve," y "),Pa=c(ve,"CODE",{});var Wi=d(Pa);Gt=n(Wi,"attention_mask"),Wi.forEach(a),Vt=n(ve," en el "),Fs=c(ve,"A",{href:!0});var Ui=d(Fs);Yt=n(Ui,"Cap\xEDtulo 2"),Ui.forEach(a),Jt=n(ve,", pero postergamos hablar sobre la llave "),Da=c(ve,"CODE",{});var Bi=d(Da);Kt=n(Bi,"token_type_ids"),Bi.forEach(a),Zt=n(ve,". En este ejemplo, esta es la que le dice al modelo cual parte de la entrada es la primera oraci\xF3n y cual es la segunda."),ve.forEach(a),Bo=f(e),E(Te.$$.fragment,e),Go=f(e),Ae=c(e,"P",{});var An=d(Ae);Qt=n(An,"Si convertimos los IDs dentro de "),Ta=c(An,"CODE",{});var Gi=d(Ta);Xt=n(Gi,"input_ids"),Gi.forEach(a),el=n(An," en palabras:"),An.forEach(a),Vo=f(e),E(rs.$$.fragment,e),Yo=f(e),Hs=c(e,"P",{});var Vi=d(Hs);sl=n(Vi,"obtendremos:"),Vi.forEach(a),Jo=f(e),E(is.$$.fragment,e),Ko=f(e),me=c(e,"P",{});var aa=d(me);al=n(aa,"De esta manera vemos que el modelo espera las entradas de la siguiente forma "),Aa=c(aa,"CODE",{});var Yi=d(Aa);ol=n(Yi,"[CLS] sentence1 [SEP] sentence2 [SEP]"),Yi.forEach(a),nl=n(aa," cuando hay dos oraciones. Alineando esto con los "),Sa=c(aa,"CODE",{});var Ji=d(Sa);tl=n(Ji,"token_type_ids"),Ji.forEach(a),ll=n(aa," obtenemos:"),aa.forEach(a),Zo=f(e),E(cs.$$.fragment,e),Qo=f(e),V=c(e,"P",{});var $e=d(V);rl=n($e,"Como puedes observar, las partes de la entrada que corresponden a "),Oa=c($e,"CODE",{});var Ki=d(Oa);il=n(Ki,"[CLS] sentence1 [SEP]"),Ki.forEach(a),cl=n($e," todas tienen un tipo de token ID "),Na=c($e,"CODE",{});var Zi=d(Na);dl=n(Zi,"0"),Zi.forEach(a),pl=n($e,", mientras que las otras partes que corresponden a "),La=c($e,"CODE",{});var Qi=d(La);ul=n(Qi,"sentence2 [SEP]"),Qi.forEach(a),ml=n($e,", todas tienen tipo ID "),Ma=c($e,"CODE",{});var Xi=d(Ma);fl=n(Xi,"1"),Xi.forEach(a),hl=n($e,"."),$e.forEach(a),Xo=f(e),Se=c(e,"P",{});var Sn=d(Se);_l=n(Sn,"N\xF3tese que si seleccionas un punto de control diferente, no necesariamente tendr\xE1s el "),Fa=c(Sn,"CODE",{});var ec=d(Fa);bl=n(ec,"token_type_ids"),ec.forEach(a),jl=n(Sn," en tus entradas tonenizadas (por ejemplo, ellas no aparecen si usas un modelo DistilBERT). Estas aparecen cuando el modelo sabe que hacer con ellas, porque las ha visto durante su etapa de preentrenamiento."),Sn.forEach(a),en=f(e),fe=c(e,"P",{});var oa=d(fe);vl=n(oa,"Aqu\xED, BERT esta preentrenado con tokens de tipo ID, y adem\xE1s del objetivo de modelado de lenguaje oculto que mencionamos en el "),Rs=c(oa,"A",{href:!0});var sc=d(Rs);$l=n(sc,"Cap\xEDtulo 1"),sc.forEach(a),kl=n(oa,", tambi\xE9n tiene el objetivo llamado "),Ha=c(oa,"EM",{});var ac=d(Ha);ql=n(ac,"predicci\xF3n de la siguiente oraci\xF3n"),ac.forEach(a),gl=n(oa,". El objectivo con esta tarea es modelar la relaci\xF3n entre pares de oraciones."),oa.forEach(a),sn=f(e),Is=c(e,"P",{});var oc=d(Is);El=n(oc,"Para predecir la siguiente oraci\xF3n, el modelo recibe pares de oraciones (con tokens ocultados aleatoriamente) y se le pide que prediga si la segunda secuencia sigue a la primera. Para que la tarea no sea tan simple, la mitad de las veces las oraciones estan seguidas en el texto original de donde se obtuvieron, y la otra mitad las oraciones vienen de dos documentos distintos."),oc.forEach(a),an=f(e),Oe=c(e,"P",{});var On=d(Oe);yl=n(On,"En general, no debes preocuparte si los "),Ra=c(On,"CODE",{});var nc=d(Ra);xl=n(nc,"token_type_ids"),nc.forEach(a),wl=n(On," estan o no en las entradas tokenizadas: con tal que uses el mismo punto de control para el tokenizador y el modelo, todo estar\xE1 bien porque el tokenizador sabe que pasarle a su modelo."),On.forEach(a),on=f(e),he=c(e,"P",{});var na=d(he);zl=n(na,"Ahora que hemos visto como nuestro tokenizador puede trabajar con un par de oraciones, podemos usarlo para tokenizar todo el conjunto de datos: como en el "),Ws=c(na,"A",{href:!0});var tc=d(Ws);Cl=n(tc,"cap\xEDtulo anterior"),tc.forEach(a),Pl=n(na,", podemos darle al tokenizador una lista de pares de oraciones, d\xE1ndole la lista de las primeras oraciones, y luego la lista de las segundas oraciones. Esto tambi\xE9n es compatible con las opciones de relleno y truncamiento que vimos en el "),Us=c(na,"A",{href:!0});var lc=d(Us);Dl=n(lc,"Cap\xEDtulo 2"),lc.forEach(a),Tl=n(na,". Por lo tanto, una manera de preprocessar el conjunto de datos de entrenamiento ser\xEDa:"),na.forEach(a),nn=f(e),E(ds.$$.fragment,e),tn=f(e),Y=c(e,"P",{});var ke=d(Y);Al=n(ke,"Esto funciona bien, pero tiene la desventaja de que devuelve un diccionario (con nuestras llaves, "),Ia=c(ke,"CODE",{});var rc=d(Ia);Sl=n(rc,"input_ids"),rc.forEach(a),Ol=n(ke,", "),Wa=c(ke,"CODE",{});var ic=d(Wa);Nl=n(ic,"attention_mask"),ic.forEach(a),Ll=n(ke,", and "),Ua=c(ke,"CODE",{});var cc=d(Ua);Ml=n(cc,"token_type_ids"),cc.forEach(a),Fl=n(ke,", y valores que son listas de listas). Adem\xE1s va a trabajar solo si tienes suficiente memoria principal para almacenar todo el conjunto de datos durante la tokenizaci\xF3n (mientras que los conjuntos de datos de la librer\xEDa Datasets \u{1F917} son archivos "),ps=c(ke,"A",{href:!0,rel:!0});var dc=d(ps);Hl=n(dc,"Apache Arrow"),dc.forEach(a),Rl=n(ke," almacenados en disco, y as\xED solo mantienes en memoria las muestras que necesitas)."),ke.forEach(a),ln=f(e),_e=c(e,"P",{});var ta=d(_e);Il=n(ta,"Para mantener los datos como un conjunto de datos, usaremos el m\xE9todo "),us=c(ta,"A",{href:!0,rel:!0});var pc=d(us);Ba=c(pc,"CODE",{});var uc=d(Ba);Wl=n(uc,"Dataset.map()"),uc.forEach(a),pc.forEach(a),Ul=n(ta,". Este tambi\xE9n nos ofrece una flexibilidad adicional en caso de que necesitemos preprocesamiento mas all\xE1 de la tokenizaci\xF3n. El m\xE9todo "),Ga=c(ta,"CODE",{});var mc=d(Ga);Bl=n(mc,"map()"),mc.forEach(a),Gl=n(ta," trabaja aplicando una funci\xF3n sobre cada elemento del conjunto de datos, as\xED que definamos una funci\xF3n para tokenizar nuestras entradas:"),ta.forEach(a),rn=f(e),E(ms.$$.fragment,e),cn=f(e),A=c(e,"P",{});var O=d(A);Vl=n(O,"Esta funci\xF3n recibe un diccionario (como los elementos de nuestro conjunto de datos) y devuelve un nuevo diccionario con las llaves "),Va=c(O,"CODE",{});var fc=d(Va);Yl=n(fc,"input_ids"),fc.forEach(a),Jl=n(O,", "),Ya=c(O,"CODE",{});var hc=d(Ya);Kl=n(hc,"attention_mask"),hc.forEach(a),Zl=n(O,", y "),Ja=c(O,"CODE",{});var _c=d(Ja);Ql=n(_c,"token_type_ids"),_c.forEach(a),Xl=n(O,". N\xF3tese que tambi\xE9n funciona si el diccionario "),Ka=c(O,"CODE",{});var bc=d(Ka);er=n(bc,"example"),bc.forEach(a),sr=n(O," contiene m\xFAltiples elementos (cada llave con una lista de oraciones) debido a que el "),Za=c(O,"CODE",{});var jc=d(Za);ar=n(jc,"tokenizador"),jc.forEach(a),or=n(O," funciona con listas de pares de oraciones, como se vio anteriormente. Esto nos va a permitir usar la opci\xF3n "),Qa=c(O,"CODE",{});var vc=d(Qa);nr=n(vc,"batched=True"),vc.forEach(a),tr=n(O," en nuestra llamada a "),Xa=c(O,"CODE",{});var $c=d(Xa);lr=n($c,"map()"),$c.forEach(a),rr=n(O,", lo que acelera la tokenizaci\xF3n significativamente. El "),eo=c(O,"CODE",{});var kc=d(eo);ir=n(kc,"tokenizador"),kc.forEach(a),cr=n(O," es respaldado por un tokenizador escrito en Rust que viene de la libreria "),fs=c(O,"A",{href:!0,rel:!0});var qc=d(fs);dr=n(qc,"Tokenizadores \u{1F917}"),qc.forEach(a),pr=n(O,". Este tokenizador puede ser muy r\xE1pido, pero solo si le da muchas entradas al mismo tiempo."),O.forEach(a),dn=f(e),Ne=c(e,"P",{});var Nn=d(Ne);ur=n(Nn,"N\xF3tese que por ahora hemos dejado el argumento "),so=c(Nn,"CODE",{});var gc=d(so);mr=n(gc,"padding"),gc.forEach(a),fr=n(Nn," fuera de nuestra funci\xF3n de tokenizaci\xF3n. Esto es porque rellenar todos los elementos hasta su m\xE1xima longitud no es eficiente: es mejor rellenar los elememtos cuando se esta construyendo el lote, debido a que solo debemos rellenar hasta la m\xE1xima longitud en el lote, pero no en todo el conjunto de datos. Esto puede ahorrar mucho tiempo y poder de processamiento cuando las entradas tienen longitudes variables."),Nn.forEach(a),pn=f(e),be=c(e,"P",{});var la=d(be);hr=n(la,"Aqu\xED se muestra como se aplica la funci\xF3n de tokenizaci\xF3n a todo el conjunto de datos en un solo paso. Estamos usando "),ao=c(la,"CODE",{});var Ec=d(ao);_r=n(Ec,"batched=True"),Ec.forEach(a),br=n(la," en nuestra llamada a "),oo=c(la,"CODE",{});var yc=d(oo);jr=n(yc,"map"),yc.forEach(a),vr=n(la," para que la funci\xF3n sea aplicada a m\xFAltiples elementos de nuestro conjunto de datos al mismo tiempo, y no a cada elemento por separado. Esto permite un preprocesamiento m\xE1s r\xE1pido."),la.forEach(a),un=f(e),E(hs.$$.fragment,e),mn=f(e),Bs=c(e,"P",{});var xc=d(Bs);$r=n(xc,"La manera en que la libreria \u{1F917} aplica este procesamiento es a trav\xE9s de campos a\xF1adidos al conjunto de datos, uno por cada diccionario devuelto por la funci\xF3n de preprocesamiento."),xc.forEach(a),fn=f(e),E(_s.$$.fragment,e),hn=f(e),je=c(e,"P",{});var ra=d(je);kr=n(ra,"Hasta puedes usar multiprocesamiento cuando aplicas la funci\xF3n de preprocesamiento con "),no=c(ra,"CODE",{});var wc=d(no);qr=n(wc,"map()"),wc.forEach(a),gr=n(ra," pasando el argumento "),to=c(ra,"CODE",{});var zc=d(to);Er=n(zc,"num_proc"),zc.forEach(a),yr=n(ra,". Nosotros no usamos esta opci\xF3n porque los Tokenizadores de la libreria \u{1F917} usa m\xFAltiples hilos de procesamiento para tokenizar r\xE1pidamente nuestros elementos, pero sino estas usando un tokenizador r\xE1pido respaldado por esta libreria, esta opci\xF3n puede acelerar tu preprocesamiento."),ra.forEach(a),_n=f(e),I=c(e,"P",{});var X=d(I);xr=n(X,"Nuestra funci\xF3n "),lo=c(X,"CODE",{});var Cc=d(lo);wr=n(Cc,"tokenize_function"),Cc.forEach(a),zr=n(X," devuelve un diccionario con las llaves "),ro=c(X,"CODE",{});var Pc=d(ro);Cr=n(Pc,"input_ids"),Pc.forEach(a),Pr=n(X,", "),io=c(X,"CODE",{});var Dc=d(io);Dr=n(Dc,"attention_mask"),Dc.forEach(a),Tr=n(X,", y "),co=c(X,"CODE",{});var Tc=d(co);Ar=n(Tc,"token_type_ids"),Tc.forEach(a),Sr=n(X,", as\xED que esos tres campos son adicionados a todas las divisiones de nuestro conjunto de datos. N\xF3tese que pudimos haber cambiado los campos existentes si nuestra funci\xF3n de preprocesamiento hubiese devuelto un valor nuevo para cualquiera de las llaves en el conjunto de datos al que le aplicamos "),po=c(X,"CODE",{});var Ac=d(po);Or=n(Ac,"map()"),Ac.forEach(a),Nr=n(X,"."),X.forEach(a),bn=f(e),Le=c(e,"P",{});var Ln=d(Le);Lr=n(Ln,"Lo \xFAltimo que necesitamos hacer es rellenar todos los elementos hasta la longitud del elemento m\xE1s largo al momento de agrupar los elementos - a esta t\xE9cnica la llamamos "),uo=c(Ln,"EM",{});var Sc=d(uo);Mr=n(Sc,"relleno din\xE1mico"),Sc.forEach(a),Fr=n(Ln,"."),Ln.forEach(a),jn=f(e),Ee=c(e,"H3",{class:!0});var Mn=d(Ee);Me=c(Mn,"A",{id:!0,class:!0,href:!0});var Oc=d(Me);mo=c(Oc,"SPAN",{});var Nc=d(mo);E(bs.$$.fragment,Nc),Nc.forEach(a),Oc.forEach(a),Hr=f(Mn),fo=c(Mn,"SPAN",{});var Lc=d(fo);Rr=n(Lc,"Relleno Din\xE1mico"),Lc.forEach(a),Mn.forEach(a),vn=f(e),E(js.$$.fragment,e),$n=f(e),ye.l(e),Gs=f(e),Fe=c(e,"P",{});var Fn=d(Fe);Ir=n(Fn,"Para poner esto en pr\xE1ctica, tenemos que definir una funci\xF3n de cotejo que aplique la cantidad correcta de relleno a los elementos del conjunto de datos que queremos agrupar. Afortundamente, la libreria Transformers de \u{1F917} nos provee esta funci\xF3n mediante "),ho=c(Fn,"CODE",{});var Mc=d(ho);Wr=n(Mc,"DataCollatorWithPadding"),Mc.forEach(a),Ur=n(Fn,". Esta recibe un tokenizador cuando la creas (para saber cual token de relleno se debe usar, y si el modelo espera el relleno a la izquierda o la derecha en las entradas) y hace todo lo que necesitas:"),Fn.forEach(a),kn=f(e),le.l(e),Vs=f(e),Z=c(e,"P",{});var Be=d(Z);Br=n(Be,"Para probar este nuevo juguete, tomemos algunos elementos de nuestro conjunto de datos de entrenamiento para agruparlos. Aqu\xED, removemos las columnas "),_o=c(Be,"CODE",{});var Fc=d(_o);Gr=n(Fc,"idx"),Fc.forEach(a),Vr=n(Be,", "),bo=c(Be,"CODE",{});var Hc=d(bo);Yr=n(Hc,"sentence1"),Hc.forEach(a),Jr=n(Be,", and "),jo=c(Be,"CODE",{});var Rc=d(jo);Kr=n(Rc,"sentence2"),Rc.forEach(a),Zr=n(Be," ya que \xE9stas no se necesitan y contienen cadenas (y no podemos crear tensores con cadenas), miremos las longitudes de cada elemento en el lote."),Be.forEach(a),qn=f(e),E(vs.$$.fragment,e),gn=f(e),E($s.$$.fragment,e),En=f(e),He=c(e,"P",{});var Hn=d(He);Qr=n(Hn,"Como era de esperarse, obtenemos elementos de longitud variable, desde 32 hasta 67. El relleno din\xE1mico significa que los elementos en este lote deben ser rellenos hasta una longitud de 67, que es la m\xE1xima longitud en el lote. Sin relleno din\xE1mico, todos los elementos tendr\xEDan que haber sido rellenos hasta el m\xE1ximo de todo el conjunto de datos, o el m\xE1ximo aceptado por el modelo. Verifiquemos que nuestro "),vo=c(Hn,"CODE",{});var Ic=d(vo);Xr=n(Ic,"data_collator"),Ic.forEach(a),ei=n(Hn," esta rellenando din\xE1micamente el lote de la manera apropiada:"),Hn.forEach(a),yn=f(e),E(ks.$$.fragment,e),xn=f(e),ie.l(e),Ys=f(e),E(Re.$$.fragment,e),wn=f(e),M&&M.l(e),Js=Wc(),this.h()},h(){z(t,"name","hf:doc:metadata"),z(t,"content",JSON.stringify(_d)),z(h,"id","procesando-los-datos"),z(h,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),z(h,"href","#procesando-los-datos"),z(k,"class","relative group"),z(de,"href","https://www.aclweb.org/anthology/I05-5002.pdf"),z(de,"rel","nofollow"),z(we,"id","cargando-un-conjunto-de-datos-desde-el-hub"),z(we,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),z(we,"href","#cargando-un-conjunto-de-datos-desde-el-hub"),z(qe,"class","relative group"),z(Ye,"href","https://huggingface.co/datasets"),z(Ye,"rel","nofollow"),z(Je,"href","https://huggingface.co/docs/datasets/loading_datasets.html#from-the-huggingface-hub"),z(Je,"rel","nofollow"),z(Ke,"href","https://gluebenchmark.com/"),z(Ke,"rel","nofollow"),z(Pe,"id","preprocesando-un-conjunto-de-datos"),z(Pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),z(Pe,"href","#preprocesando-un-conjunto-de-datos"),z(ge,"class","relative group"),z(Ls,"href","/course/chapter2"),z(Fs,"href","/course/chapter2"),z(Rs,"href","/course/chapter1"),z(Ws,"href","/course/chapter2"),z(Us,"href","/course/chapter2"),z(ps,"href","https://arrow.apache.org/"),z(ps,"rel","nofollow"),z(us,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map"),z(us,"rel","nofollow"),z(fs,"href","https://github.com/huggingface/tokenizers"),z(fs,"rel","nofollow"),z(Me,"id","relleno-dinmico"),z(Me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),z(Me,"href","#relleno-dinmico"),z(Ee,"class","relative group")},m(e,r){s(document.head,t),p(e,u,r),y(l,e,r),p(e,b,r),p(e,k,r),s(k,h),s(h,_),y(C,_,null),s(k,$),s(k,q),s(q,N),p(e,F,r),qs[U].m(e,r),p(e,ee,r),gs[L].m(e,r),p(e,J,r),p(e,ce,r),s(ce,xe),p(e,P,r),p(e,T,r),s(T,Ds),s(T,de),s(de,Ts),s(T,As),p(e,Ge,r),p(e,qe,r),s(qe,we),s(we,ia),y(Ve,ia,null),s(qe,In),s(qe,ca),s(ca,Wn),p(e,Eo,r),Es[se].m(e,r),p(e,Ss,r),p(e,K,r),s(K,Un),s(K,Ye),s(Ye,Bn),s(K,Gn),s(K,Je),s(Je,Vn),s(K,Yn),s(K,Ke),s(Ke,Jn),s(K,Kn),p(e,yo,r),p(e,Os,r),s(Os,Zn),p(e,xo,r),y(Ze,e,r),p(e,wo,r),y(Qe,e,r),p(e,zo,r),p(e,R,r),s(R,Qn),s(R,da),s(da,Xn),s(R,et),s(R,pa),s(pa,st),s(R,at),s(R,ua),s(ua,ot),s(R,nt),s(R,ma),s(ma,tt),s(R,lt),s(R,fa),s(fa,rt),s(R,it),p(e,Co,r),p(e,pe,r),s(pe,ct),s(pe,ha),s(ha,dt),s(pe,pt),s(pe,_a),s(_a,ut),s(pe,mt),p(e,Po,r),p(e,ze,r),s(ze,ft),s(ze,ba),s(ba,ht),s(ze,_t),p(e,Do,r),y(Xe,e,r),p(e,To,r),y(es,e,r),p(e,Ao,r),p(e,ue,r),s(ue,bt),s(ue,ja),s(ja,jt),s(ue,vt),s(ue,va),s(va,$t),s(ue,kt),p(e,So,r),y(ss,e,r),p(e,Oo,r),y(as,e,r),p(e,No,r),p(e,S,r),s(S,qt),s(S,$a),s($a,gt),s(S,Et),s(S,ka),s(ka,yt),s(S,xt),s(S,qa),s(qa,wt),s(S,zt),s(S,ga),s(ga,Ct),s(S,Pt),s(S,Ea),s(Ea,Dt),s(S,Tt),s(S,ya),s(ya,At),s(S,St),s(S,xa),s(xa,Ot),s(S,Nt),p(e,Lo,r),y(Ce,e,r),p(e,Mo,r),p(e,ge,r),s(ge,Pe),s(Pe,wa),y(os,wa,null),s(ge,Lt),s(ge,za),s(za,Mt),p(e,Fo,r),ys[oe].m(e,r),p(e,Ns,r),p(e,De,r),s(De,Ft),s(De,Ls),s(Ls,Ht),s(De,Rt),p(e,Ho,r),y(ns,e,r),p(e,Ro,r),p(e,Ms,r),s(Ms,It),p(e,Io,r),y(ts,e,r),p(e,Wo,r),y(ls,e,r),p(e,Uo,r),p(e,G,r),s(G,Wt),s(G,Ca),s(Ca,Ut),s(G,Bt),s(G,Pa),s(Pa,Gt),s(G,Vt),s(G,Fs),s(Fs,Yt),s(G,Jt),s(G,Da),s(Da,Kt),s(G,Zt),p(e,Bo,r),y(Te,e,r),p(e,Go,r),p(e,Ae,r),s(Ae,Qt),s(Ae,Ta),s(Ta,Xt),s(Ae,el),p(e,Vo,r),y(rs,e,r),p(e,Yo,r),p(e,Hs,r),s(Hs,sl),p(e,Jo,r),y(is,e,r),p(e,Ko,r),p(e,me,r),s(me,al),s(me,Aa),s(Aa,ol),s(me,nl),s(me,Sa),s(Sa,tl),s(me,ll),p(e,Zo,r),y(cs,e,r),p(e,Qo,r),p(e,V,r),s(V,rl),s(V,Oa),s(Oa,il),s(V,cl),s(V,Na),s(Na,dl),s(V,pl),s(V,La),s(La,ul),s(V,ml),s(V,Ma),s(Ma,fl),s(V,hl),p(e,Xo,r),p(e,Se,r),s(Se,_l),s(Se,Fa),s(Fa,bl),s(Se,jl),p(e,en,r),p(e,fe,r),s(fe,vl),s(fe,Rs),s(Rs,$l),s(fe,kl),s(fe,Ha),s(Ha,ql),s(fe,gl),p(e,sn,r),p(e,Is,r),s(Is,El),p(e,an,r),p(e,Oe,r),s(Oe,yl),s(Oe,Ra),s(Ra,xl),s(Oe,wl),p(e,on,r),p(e,he,r),s(he,zl),s(he,Ws),s(Ws,Cl),s(he,Pl),s(he,Us),s(Us,Dl),s(he,Tl),p(e,nn,r),y(ds,e,r),p(e,tn,r),p(e,Y,r),s(Y,Al),s(Y,Ia),s(Ia,Sl),s(Y,Ol),s(Y,Wa),s(Wa,Nl),s(Y,Ll),s(Y,Ua),s(Ua,Ml),s(Y,Fl),s(Y,ps),s(ps,Hl),s(Y,Rl),p(e,ln,r),p(e,_e,r),s(_e,Il),s(_e,us),s(us,Ba),s(Ba,Wl),s(_e,Ul),s(_e,Ga),s(Ga,Bl),s(_e,Gl),p(e,rn,r),y(ms,e,r),p(e,cn,r),p(e,A,r),s(A,Vl),s(A,Va),s(Va,Yl),s(A,Jl),s(A,Ya),s(Ya,Kl),s(A,Zl),s(A,Ja),s(Ja,Ql),s(A,Xl),s(A,Ka),s(Ka,er),s(A,sr),s(A,Za),s(Za,ar),s(A,or),s(A,Qa),s(Qa,nr),s(A,tr),s(A,Xa),s(Xa,lr),s(A,rr),s(A,eo),s(eo,ir),s(A,cr),s(A,fs),s(fs,dr),s(A,pr),p(e,dn,r),p(e,Ne,r),s(Ne,ur),s(Ne,so),s(so,mr),s(Ne,fr),p(e,pn,r),p(e,be,r),s(be,hr),s(be,ao),s(ao,_r),s(be,br),s(be,oo),s(oo,jr),s(be,vr),p(e,un,r),y(hs,e,r),p(e,mn,r),p(e,Bs,r),s(Bs,$r),p(e,fn,r),y(_s,e,r),p(e,hn,r),p(e,je,r),s(je,kr),s(je,no),s(no,qr),s(je,gr),s(je,to),s(to,Er),s(je,yr),p(e,_n,r),p(e,I,r),s(I,xr),s(I,lo),s(lo,wr),s(I,zr),s(I,ro),s(ro,Cr),s(I,Pr),s(I,io),s(io,Dr),s(I,Tr),s(I,co),s(co,Ar),s(I,Sr),s(I,po),s(po,Or),s(I,Nr),p(e,bn,r),p(e,Le,r),s(Le,Lr),s(Le,uo),s(uo,Mr),s(Le,Fr),p(e,jn,r),p(e,Ee,r),s(Ee,Me),s(Me,mo),y(bs,mo,null),s(Ee,Hr),s(Ee,fo),s(fo,Rr),p(e,vn,r),y(js,e,r),p(e,$n,r),ye.m(e,r),p(e,Gs,r),p(e,Fe,r),s(Fe,Ir),s(Fe,ho),s(ho,Wr),s(Fe,Ur),p(e,kn,r),xs[te].m(e,r),p(e,Vs,r),p(e,Z,r),s(Z,Br),s(Z,_o),s(_o,Gr),s(Z,Vr),s(Z,bo),s(bo,Yr),s(Z,Jr),s(Z,jo),s(jo,Kr),s(Z,Zr),p(e,qn,r),y(vs,e,r),p(e,gn,r),y($s,e,r),p(e,En,r),p(e,He,r),s(He,Qr),s(He,vo),s(vo,Xr),s(He,ei),p(e,yn,r),y(ks,e,r),p(e,xn,r),ws[re].m(e,r),p(e,Ys,r),y(Re,e,r),p(e,wn,r),M&&M.m(e,r),p(e,Js,r),zn=!0},p(e,[r]){const zs={};r&1&&(zs.fw=e[0]),l.$set(zs);let Ks=U;U=oi(e),U!==Ks&&(Ps(),v(qs[Ks],1,1,()=>{qs[Ks]=null}),Cs(),B=qs[U],B||(B=qs[U]=ai[U](e),B.c()),j(B,1),B.m(ee.parentNode,ee));let Zs=L;L=ti(e),L!==Zs&&(Ps(),v(gs[Zs],1,1,()=>{gs[Zs]=null}),Cs(),H=gs[L],H||(H=gs[L]=ni[L](e),H.c()),j(H,1),H.m(J.parentNode,J));let Qs=se;se=ri(e),se!==Qs&&(Ps(),v(Es[Qs],1,1,()=>{Es[Qs]=null}),Cs(),ae=Es[se],ae||(ae=Es[se]=li[se](e),ae.c()),j(ae,1),ae.m(Ss.parentNode,Ss));const $o={};r&2&&($o.$$scope={dirty:r,ctx:e}),Ce.$set($o);let Ie=oe;oe=ci(e),oe!==Ie&&(Ps(),v(ys[Ie],1,1,()=>{ys[Ie]=null}),Cs(),ne=ys[oe],ne||(ne=ys[oe]=ii[oe](e),ne.c()),j(ne,1),ne.m(Ns.parentNode,Ns));const ko={};r&2&&(ko.$$scope={dirty:r,ctx:e}),Te.$set(ko),Cn!==(Cn=di(e))&&(ye.d(1),ye=Cn(e),ye&&(ye.c(),ye.m(Gs.parentNode,Gs)));let We=te;te=ui(e),te!==We&&(Ps(),v(xs[We],1,1,()=>{xs[We]=null}),Cs(),le=xs[te],le||(le=xs[te]=pi[te](e),le.c()),j(le,1),le.m(Vs.parentNode,Vs));let Xs=re;re=fi(e),re!==Xs&&(Ps(),v(ws[Xs],1,1,()=>{ws[Xs]=null}),Cs(),ie=ws[re],ie||(ie=ws[re]=mi[re](e),ie.c()),j(ie,1),ie.m(Ys.parentNode,Ys));const qo={};r&2&&(qo.$$scope={dirty:r,ctx:e}),Re.$set(qo),e[0]==="tf"?M?r&1&&j(M,1):(M=Uc(),M.c(),j(M,1),M.m(Js.parentNode,Js)):M&&(Ps(),v(M,1,1,()=>{M=null}),Cs())},i(e){zn||(j(l.$$.fragment,e),j(C.$$.fragment,e),j(B),j(H),j(Ve.$$.fragment,e),j(ae),j(Ze.$$.fragment,e),j(Qe.$$.fragment,e),j(Xe.$$.fragment,e),j(es.$$.fragment,e),j(ss.$$.fragment,e),j(as.$$.fragment,e),j(Ce.$$.fragment,e),j(os.$$.fragment,e),j(ne),j(ns.$$.fragment,e),j(ts.$$.fragment,e),j(ls.$$.fragment,e),j(Te.$$.fragment,e),j(rs.$$.fragment,e),j(is.$$.fragment,e),j(cs.$$.fragment,e),j(ds.$$.fragment,e),j(ms.$$.fragment,e),j(hs.$$.fragment,e),j(_s.$$.fragment,e),j(bs.$$.fragment,e),j(js.$$.fragment,e),j(le),j(vs.$$.fragment,e),j($s.$$.fragment,e),j(ks.$$.fragment,e),j(ie),j(Re.$$.fragment,e),j(M),zn=!0)},o(e){v(l.$$.fragment,e),v(C.$$.fragment,e),v(B),v(H),v(Ve.$$.fragment,e),v(ae),v(Ze.$$.fragment,e),v(Qe.$$.fragment,e),v(Xe.$$.fragment,e),v(es.$$.fragment,e),v(ss.$$.fragment,e),v(as.$$.fragment,e),v(Ce.$$.fragment,e),v(os.$$.fragment,e),v(ne),v(ns.$$.fragment,e),v(ts.$$.fragment,e),v(ls.$$.fragment,e),v(Te.$$.fragment,e),v(rs.$$.fragment,e),v(is.$$.fragment,e),v(cs.$$.fragment,e),v(ds.$$.fragment,e),v(ms.$$.fragment,e),v(hs.$$.fragment,e),v(_s.$$.fragment,e),v(bs.$$.fragment,e),v(js.$$.fragment,e),v(le),v(vs.$$.fragment,e),v($s.$$.fragment,e),v(ks.$$.fragment,e),v(ie),v(Re.$$.fragment,e),v(M),zn=!1},d(e){a(t),e&&a(u),x(l,e),e&&a(b),e&&a(k),x(C),e&&a(F),qs[U].d(e),e&&a(ee),gs[L].d(e),e&&a(J),e&&a(ce),e&&a(P),e&&a(T),e&&a(Ge),e&&a(qe),x(Ve),e&&a(Eo),Es[se].d(e),e&&a(Ss),e&&a(K),e&&a(yo),e&&a(Os),e&&a(xo),x(Ze,e),e&&a(wo),x(Qe,e),e&&a(zo),e&&a(R),e&&a(Co),e&&a(pe),e&&a(Po),e&&a(ze),e&&a(Do),x(Xe,e),e&&a(To),x(es,e),e&&a(Ao),e&&a(ue),e&&a(So),x(ss,e),e&&a(Oo),x(as,e),e&&a(No),e&&a(S),e&&a(Lo),x(Ce,e),e&&a(Mo),e&&a(ge),x(os),e&&a(Fo),ys[oe].d(e),e&&a(Ns),e&&a(De),e&&a(Ho),x(ns,e),e&&a(Ro),e&&a(Ms),e&&a(Io),x(ts,e),e&&a(Wo),x(ls,e),e&&a(Uo),e&&a(G),e&&a(Bo),x(Te,e),e&&a(Go),e&&a(Ae),e&&a(Vo),x(rs,e),e&&a(Yo),e&&a(Hs),e&&a(Jo),x(is,e),e&&a(Ko),e&&a(me),e&&a(Zo),x(cs,e),e&&a(Qo),e&&a(V),e&&a(Xo),e&&a(Se),e&&a(en),e&&a(fe),e&&a(sn),e&&a(Is),e&&a(an),e&&a(Oe),e&&a(on),e&&a(he),e&&a(nn),x(ds,e),e&&a(tn),e&&a(Y),e&&a(ln),e&&a(_e),e&&a(rn),x(ms,e),e&&a(cn),e&&a(A),e&&a(dn),e&&a(Ne),e&&a(pn),e&&a(be),e&&a(un),x(hs,e),e&&a(mn),e&&a(Bs),e&&a(fn),x(_s,e),e&&a(hn),e&&a(je),e&&a(_n),e&&a(I),e&&a(bn),e&&a(Le),e&&a(jn),e&&a(Ee),x(bs),e&&a(vn),x(js,e),e&&a($n),ye.d(e),e&&a(Gs),e&&a(Fe),e&&a(kn),xs[te].d(e),e&&a(Vs),e&&a(Z),e&&a(qn),x(vs,e),e&&a(gn),x($s,e),e&&a(En),e&&a(He),e&&a(yn),x(ks,e),e&&a(xn),ws[re].d(e),e&&a(Ys),x(Re,e),e&&a(wn),M&&M.d(e),e&&a(Js)}}}const _d={local:"procesando-los-datos",sections:[{local:"cargando-un-conjunto-de-datos-desde-el-hub",title:"Cargando un conjunto de datos desde el Hub"},{local:"preprocesando-un-conjunto-de-datos",title:"Preprocesando un conjunto de datos"},{local:"relleno-dinmico",title:"Relleno Din\xE1mico"}],title:"Procesando los datos"};function bd(w,t,u){let l="pt";return Kc(()=>{const b=new URLSearchParams(window.location.search);u(0,l=b.get("fw")||"pt")}),[l]}class yd extends Gc{constructor(t){super();Vc(this,t,bd,hd,Yc,{})}}export{yd as default,_d as metadata};
