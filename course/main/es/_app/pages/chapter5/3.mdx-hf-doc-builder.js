import{S as d3,i as p3,s as u3,e as o,k as d,w as f,t,M as c3,c as r,d as s,m as p,a as l,x as h,h as n,b as m,f as i3,G as a,g as u,y as v,q as _,o as g,B as $,v as m3}from"../../chunks/vendor-hf-doc-builder.js";import{T as gs}from"../../chunks/Tip-hf-doc-builder.js";import{Y as gE}from"../../chunks/Youtube-hf-doc-builder.js";import{I as Kt}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as E}from"../../chunks/CodeBlock-hf-doc-builder.js";import{C as f3}from"../../chunks/CourseFloatingBanner-hf-doc-builder.js";function h3(M){let c,T,j,x,y,b,D,C;return{c(){c=o("p"),T=t("\u270F\uFE0F "),j=o("strong"),x=t("\xA1Int\xE9ntalo!"),y=t(" Usa la funci\xF3n "),b=o("code"),D=t("Dataset.unique()"),C=t(" para encontrar el n\xFAmero de medicamentos y condiciones \xFAnicas en los conjuntos de entrenamiento y de prueba.")},l(q){c=r(q,"P",{});var w=l(c);T=n(w,"\u270F\uFE0F "),j=r(w,"STRONG",{});var z=l(j);x=n(z,"\xA1Int\xE9ntalo!"),z.forEach(s),y=n(w," Usa la funci\xF3n "),b=r(w,"CODE",{});var k=l(b);D=n(k,"Dataset.unique()"),k.forEach(s),C=n(w," para encontrar el n\xFAmero de medicamentos y condiciones \xFAnicas en los conjuntos de entrenamiento y de prueba."),w.forEach(s)},m(q,w){u(q,c,w),a(c,T),a(c,j),a(j,x),a(c,y),a(c,b),a(b,D),a(c,C)},d(q){q&&s(c)}}}function v3(M){let c,T,j,x,y,b,D,C;return{c(){c=o("p"),T=t("\u{1F64B} Una forma alternativa de a\xF1adir nuevas columnas al dataset es a trav\xE9s de la funci\xF3n "),j=o("code"),x=t("Dataset.add_column()"),y=t(". Esta te permite incluir la columna como una lista de Python o un array de NumPy y puede ser \xFAtil en situaciones en las que "),b=o("code"),D=t("Dataset.map()"),C=t(" no se ajusta a tu caso de uso.")},l(q){c=r(q,"P",{});var w=l(c);T=n(w,"\u{1F64B} Una forma alternativa de a\xF1adir nuevas columnas al dataset es a trav\xE9s de la funci\xF3n "),j=r(w,"CODE",{});var z=l(j);x=n(z,"Dataset.add_column()"),z.forEach(s),y=n(w,". Esta te permite incluir la columna como una lista de Python o un array de NumPy y puede ser \xFAtil en situaciones en las que "),b=r(w,"CODE",{});var k=l(b);D=n(k,"Dataset.map()"),k.forEach(s),C=n(w," no se ajusta a tu caso de uso."),w.forEach(s)},m(q,w){u(q,c,w),a(c,T),a(c,j),a(j,x),a(c,y),a(c,b),a(b,D),a(c,C)},d(q){q&&s(c)}}}function _3(M){let c,T,j,x,y,b,D,C,q,w,z;return{c(){c=o("p"),T=t("\u270F\uFE0F "),j=o("strong"),x=t("\xA1Int\xE9ntalo!"),y=t(" Usa la funci\xF3n "),b=o("code"),D=t("Dataset.sort()"),C=t(" para inspeccionar las rese\xF1as con el mayor n\xFAmero de palabras. Revisa la "),q=o("a"),w=t("documentaci\xF3n"),z=t(" para ver cu\xE1l argumento necesitas para ordenar las rese\xF1as de mayor a menor."),this.h()},l(k){c=r(k,"P",{});var P=l(c);T=n(P,"\u270F\uFE0F "),j=r(P,"STRONG",{});var J=l(j);x=n(J,"\xA1Int\xE9ntalo!"),J.forEach(s),y=n(P," Usa la funci\xF3n "),b=r(P,"CODE",{});var N=l(b);D=n(N,"Dataset.sort()"),N.forEach(s),C=n(P," para inspeccionar las rese\xF1as con el mayor n\xFAmero de palabras. Revisa la "),q=r(P,"A",{href:!0,rel:!0});var O=l(q);w=n(O,"documentaci\xF3n"),O.forEach(s),z=n(P," para ver cu\xE1l argumento necesitas para ordenar las rese\xF1as de mayor a menor."),P.forEach(s),this.h()},h(){m(q,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.sort"),m(q,"rel","nofollow")},m(k,P){u(k,c,P),a(c,T),a(c,j),a(j,x),a(c,y),a(c,b),a(b,D),a(c,C),a(c,q),a(q,w),a(c,z)},d(k){k&&s(c)}}}function g3(M){let c,T,j,x,y,b,D,C,q,w,z,k,P,J;return{c(){c=o("p"),T=t("\u270F\uFE0F "),j=o("strong"),x=t("\xA1Int\xE9ntalo!"),y=t(" Ejecuta la misma instrucci\xF3n con y sin "),b=o("code"),D=t("batched=True"),C=t(" y luego usa un tokenizador \u201Clento\u201D (a\xF1ade "),q=o("code"),w=t("use_fast=False"),z=t(" en el m\xE9todo "),k=o("code"),P=t("AutoTokenizer.from_pretrained()"),J=t(") para ver cu\xE1nto tiempo se toman en tu computador.")},l(N){c=r(N,"P",{});var O=l(c);T=n(O,"\u270F\uFE0F "),j=r(O,"STRONG",{});var ge=l(j);x=n(ge,"\xA1Int\xE9ntalo!"),ge.forEach(s),y=n(O," Ejecuta la misma instrucci\xF3n con y sin "),b=r(O,"CODE",{});var R=l(b);D=n(R,"batched=True"),R.forEach(s),C=n(O," y luego usa un tokenizador \u201Clento\u201D (a\xF1ade "),q=r(O,"CODE",{});var W=l(q);w=n(W,"use_fast=False"),W.forEach(s),z=n(O," en el m\xE9todo "),k=r(O,"CODE",{});var re=l(k);P=n(re,"AutoTokenizer.from_pretrained()"),re.forEach(s),J=n(O,") para ver cu\xE1nto tiempo se toman en tu computador."),O.forEach(s)},m(N,O){u(N,c,O),a(c,T),a(c,j),a(j,x),a(c,y),a(c,b),a(b,D),a(c,C),a(c,q),a(q,w),a(c,z),a(c,k),a(k,P),a(c,J)},d(N){N&&s(c)}}}function $3(M){let c,T,j,x,y;return{c(){c=o("p"),T=t("Usar "),j=o("code"),x=t("num_proc"),y=t(" para acelerar tu procesamiento suele ser una buena idea, siempre y cuando la funci\xF3n que uses no est\xE9 usando multiples procesos por si misma.")},l(b){c=r(b,"P",{});var D=l(c);T=n(D,"Usar "),j=r(D,"CODE",{});var C=l(j);x=n(C,"num_proc"),C.forEach(s),y=n(D," para acelerar tu procesamiento suele ser una buena idea, siempre y cuando la funci\xF3n que uses no est\xE9 usando multiples procesos por si misma."),D.forEach(s)},m(b,D){u(b,c,D),a(c,T),a(c,j),a(j,x),a(c,y)},d(b){b&&s(c)}}}function E3(M){let c,T,j,x,y,b,D,C,q,w,z;return{c(){c=o("p"),T=t("\u{1F4A1} Un "),j=o("em"),x=t("ejemplo"),y=t(" en Machine Learning se suele definir como el conjunto de "),b=o("em"),D=t("features"),C=t(" que le damos al modelo. En algunos contextos estos features ser\xE1n el conjuto de columnas en un "),q=o("code"),w=t("Dataset"),z=t(", mientras que en otros se pueden extraer m\xFAtiples features de un solo ejemplo que pertenecen a una columna \u2013como aqu\xED y en tareas de responder preguntas-.")},l(k){c=r(k,"P",{});var P=l(c);T=n(P,"\u{1F4A1} Un "),j=r(P,"EM",{});var J=l(j);x=n(J,"ejemplo"),J.forEach(s),y=n(P," en Machine Learning se suele definir como el conjunto de "),b=r(P,"EM",{});var N=l(b);D=n(N,"features"),N.forEach(s),C=n(P," que le damos al modelo. En algunos contextos estos features ser\xE1n el conjuto de columnas en un "),q=r(P,"CODE",{});var O=l(q);w=n(O,"Dataset"),O.forEach(s),z=n(P,", mientras que en otros se pueden extraer m\xFAtiples features de un solo ejemplo que pertenecen a una columna \u2013como aqu\xED y en tareas de responder preguntas-."),P.forEach(s)},m(k,P){u(k,c,P),a(c,T),a(c,j),a(j,x),a(c,y),a(c,b),a(b,D),a(c,C),a(c,q),a(q,w),a(c,z)},d(k){k&&s(c)}}}function j3(M){let c,T,j,x,y,b,D,C,q,w,z,k,P,J,N,O,ge,R,W,re,ne,$s,We,Xe,xa,U,Ke,Ze,Es;return{c(){c=o("p"),T=t("\u{1F6A8} Internamente, "),j=o("code"),x=t("Dataset.set_format()"),y=t(" cambia el formato de devoluci\xF3n del m\xE9todo "),b=o("em"),D=t("dunder"),C=d(),q=o("code"),w=t("__getitem()__"),z=t(". Esto significa que cuando queremos crear un objeto nuevo como "),k=o("code"),P=t("train_df"),J=t(" de un "),N=o("code"),O=t("Dataset"),ge=t(" en formato "),R=o("code"),W=t('"pandas"'),re=t(", tenemos que seleccionar el dataset completo para obtener un "),ne=o("code"),$s=t("pandas.DataFrame"),We=t(". Puedes verificar por ti mismo que el tipo de "),Xe=o("code"),xa=t('drug_dataset["train"]'),U=t(" es "),Ke=o("code"),Ze=t("Dataset"),Es=t(" sin importar el formato de salida.")},l(ea){c=r(ea,"P",{});var A=l(c);T=n(A,"\u{1F6A8} Internamente, "),j=r(A,"CODE",{});var Zt=l(j);x=n(Zt,"Dataset.set_format()"),Zt.forEach(s),y=n(A," cambia el formato de devoluci\xF3n del m\xE9todo "),b=r(A,"EM",{});var en=l(b);D=n(en,"dunder"),en.forEach(s),C=p(A),q=r(A,"CODE",{});var Da=l(q);w=n(Da,"__getitem()__"),Da.forEach(s),z=n(A,". Esto significa que cuando queremos crear un objeto nuevo como "),k=r(A,"CODE",{});var an=l(k);P=n(an,"train_df"),an.forEach(s),J=n(A," de un "),N=r(A,"CODE",{});var sn=l(N);O=n(sn,"Dataset"),sn.forEach(s),ge=n(A," en formato "),R=r(A,"CODE",{});var aa=l(R);W=n(aa,'"pandas"'),aa.forEach(s),re=n(A,", tenemos que seleccionar el dataset completo para obtener un "),ne=r(A,"CODE",{});var tn=l(ne);$s=n(tn,"pandas.DataFrame"),tn.forEach(s),We=n(A,". Puedes verificar por ti mismo que el tipo de "),Xe=r(A,"CODE",{});var nn=l(Xe);xa=n(nn,'drug_dataset["train"]'),nn.forEach(s),U=n(A," es "),Ke=r(A,"CODE",{});var js=l(Ke);Ze=n(js,"Dataset"),js.forEach(s),Es=n(A," sin importar el formato de salida."),A.forEach(s)},m(ea,A){u(ea,c,A),a(c,T),a(c,j),a(j,x),a(c,y),a(c,b),a(b,D),a(c,C),a(c,q),a(q,w),a(c,z),a(c,k),a(k,P),a(c,J),a(c,N),a(N,O),a(c,ge),a(c,R),a(R,W),a(c,re),a(c,ne),a(ne,$s),a(c,We),a(c,Xe),a(Xe,xa),a(c,U),a(c,Ke),a(Ke,Ze),a(c,Es)},d(ea){ea&&s(c)}}}function b3(M){let c,T,j,x,y,b,D,C;return{c(){c=o("p"),T=t("\u270F\uFE0F "),j=o("strong"),x=t("\xA1Int\xE9ntalo!"),y=t(" Calcula la calificaci\xF3n promedio por medicamento y guarda el resultado en un nuevo "),b=o("code"),D=t("Dataset"),C=t(".")},l(q){c=r(q,"P",{});var w=l(c);T=n(w,"\u270F\uFE0F "),j=r(w,"STRONG",{});var z=l(j);x=n(z,"\xA1Int\xE9ntalo!"),z.forEach(s),y=n(w," Calcula la calificaci\xF3n promedio por medicamento y guarda el resultado en un nuevo "),b=r(w,"CODE",{});var k=l(b);D=n(k,"Dataset"),k.forEach(s),C=n(w,"."),w.forEach(s)},m(q,w){u(q,c,w),a(c,T),a(c,j),a(j,x),a(c,y),a(c,b),a(b,D),a(c,C)},d(q){q&&s(c)}}}function q3(M){let c,T,j,x,y,b,D,C,q,w,z,k,P,J,N,O,ge,R,W,re,ne,$s,We,Xe,xa,U,Ke,Ze,Es,ea,A,Zt,en,Da,an,sn,aa,tn,nn,js,je,Xc,bs,Kc,Zc,qs,em,am,wd,be,sm,Vo,tm,nm,Jo,om,rm,xd,ws,Dd,le,lm,Go,im,dm,Qo,pm,um,Wo,cm,mm,yd,xs,kd,qe,fm,Xo,hm,vm,Ko,_m,gm,Td,Ds,Cd,ys,Pd,ie,$m,Zo,Em,jm,er,bm,qm,ar,wm,xm,zd,we,ks,Dm,sr,ym,km,Tm,Ts,Cm,tr,Pm,zm,Om,sa,Am,nr,Nm,Im,or,Sm,Hm,Od,xe,Lm,rr,Mm,Rm,lr,Um,Fm,Ad,Cs,Nd,De,Bm,ir,Ym,Vm,dr,Jm,Gm,Id,Ps,Sd,zs,Hd,ya,Ld,X,Qm,pr,Wm,Xm,ur,Km,Zm,on,ef,af,cr,sf,tf,Md,Os,Rd,As,Ud,K,nf,mr,of,rf,fr,lf,df,hr,pf,uf,vr,cf,mf,Fd,Ns,Bd,ye,ff,_r,hf,vf,gr,_f,gf,Yd,Is,Vd,Z,$f,$r,Ef,jf,Ss,bf,qf,Er,wf,xf,jr,Df,yf,Jd,Hs,Gd,ke,kf,br,Tf,Cf,qr,Pf,zf,Qd,Ls,Wd,Ms,Xd,rn,Of,Kd,Rs,Zd,Us,ep,Te,Af,Fs,Nf,If,wr,Sf,Hf,ap,Bs,sp,Ce,Lf,xr,Mf,Rf,Dr,Uf,Ff,tp,Ys,np,Vs,op,ln,Bf,rp,ta,ka,yr,Js,Yf,kr,Vf,lp,dn,Jf,ip,pn,Gf,dp,Gs,pp,G,Qf,Tr,Wf,Xf,Cr,Kf,Zf,Pr,eh,ah,zr,sh,th,Or,nh,oh,up,Qs,cp,Ws,mp,Pe,rh,Ar,lh,ih,Nr,dh,ph,fp,Xs,hp,Ks,vp,un,uh,_p,Ta,gp,ze,ch,Ir,mh,fh,Sr,hh,vh,$p,Zs,Ep,et,jp,cn,_h,bp,Ca,qp,Pa,gh,Hr,$h,Eh,wp,at,xp,st,Dp,za,jh,Lr,bh,qh,yp,tt,kp,Oa,wh,Mr,xh,Dh,Tp,na,Aa,Rr,nt,yh,mn,kh,Ur,Th,Cp,ee,Ch,Fr,Ph,zh,Br,Oh,Ah,Yr,Nh,Ih,Vr,Sh,Hh,Pp,ae,Lh,Jr,Mh,Rh,Gr,Uh,Fh,Qr,Bh,Yh,Wr,Vh,Jh,zp,ot,Op,de,Gh,Xr,Qh,Wh,Kr,Xh,Kh,Zr,Zh,ev,Ap,pe,av,el,sv,tv,al,nv,ov,fn,rv,lv,Np,rt,Ip,ue,iv,hn,dv,pv,sl,uv,cv,tl,mv,fv,Sp,lt,Hp,Na,hv,nl,vv,_v,Lp,Ia,Mp,vn,gv,Rp,Sa,ol,oa,_n,$v,Ev,gn,jv,bv,$n,qv,wv,it,ra,En,rl,xv,Dv,jn,yv,kv,bn,Tv,Cv,la,qn,ll,Pv,zv,wn,Ov,Av,xn,Nv,Up,Oe,Iv,il,Sv,Hv,dl,Lv,Mv,Fp,Dn,Rv,Bp,$e,pl,Uv,Fv,ul,Bv,Yv,cl,Vv,Jv,Yp,dt,Vp,yn,Gv,Jp,Ha,ml,ia,kn,Qv,Wv,Tn,Xv,Kv,Cn,Zv,e_,Ee,da,Pn,fl,a_,s_,zn,t_,n_,On,o_,r_,pa,An,hl,l_,i_,Nn,d_,p_,In,u_,c_,ua,La,vl,m_,f_,_l,h_,v_,Sn,__,g_,Hn,$_,E_,ca,Ma,gl,j_,b_,$l,q_,w_,Ln,x_,D_,Mn,y_,Gp,ce,k_,El,T_,C_,jl,P_,z_,bl,O_,A_,Qp,Ra,Wp,me,N_,ql,I_,S_,wl,H_,L_,Rn,M_,R_,Xp,Ua,Kp,Ae,U_,xl,F_,B_,Dl,Y_,V_,Zp,pt,eu,Fa,J_,yl,G_,Q_,au,ut,su,ct,tu,Un,W_,nu,mt,ou,ft,ru,Ba,X_,Ya,K_,kl,Z_,e2,lu,se,a2,Tl,s2,t2,Cl,n2,o2,Pl,r2,l2,zl,i2,d2,iu,ht,du,Fn,p2,pu,vt,uu,_t,cu,Ne,u2,Ol,c2,m2,Al,f2,h2,mu,gt,fu,Va,v2,Nl,_2,g2,hu,$t,vu,Et,_u,Bn,$2,gu,Ja,E2,Il,j2,b2,$u,ma,Ga,Sl,jt,q2,fa,w2,Hl,x2,D2,Ll,y2,k2,Eu,bt,ju,te,T2,Ml,C2,P2,Rl,z2,O2,Ul,A2,N2,Fl,I2,S2,bu,qt,qu,Qa,H2,Bl,L2,M2,wu,wt,xu,Ie,Yl,I,Du,R2,Vl,U2,F2,Jl,B2,Y2,Gl,V2,J2,Ql,G2,Q2,Wl,W2,X2,Xl,K2,Z2,Kl,eg,ag,Zl,sg,tg,ha,S,ei,ng,og,ai,rg,lg,si,ig,dg,ti,pg,ug,ni,cg,mg,oi,fg,hg,ri,vg,_g,li,gg,$g,ii,Eg,jg,H,di,bg,qg,pi,wg,xg,ui,Dg,yg,ci,kg,Tg,mi,Cg,Pg,fi,zg,Og,hi,Ag,Ng,vi,Ig,Sg,_i,Hg,Lg,L,gi,Mg,Rg,$i,Ug,Fg,Ei,Bg,Yg,ji,Vg,Jg,bi,Gg,Qg,qi,Wg,Xg,wi,Kg,Zg,xi,e1,a1,Di,s1,yu,Se,t1,yi,n1,o1,ki,r1,l1,ku,xt,Tu,Wa,Cu,Xa,i1,Ti,d1,p1,Pu,Dt,zu,He,Ci,Le,Ou,u1,Pi,c1,m1,zi,f1,h1,oe,va,Oi,v1,_1,Ai,g1,$1,Ni,E1,j1,_a,Ii,b1,q1,Si,w1,x1,Hi,D1,y1,ga,Li,k1,T1,Mi,C1,P1,Ri,z1,O1,$a,Ui,A1,N1,Fi,I1,S1,Bi,H1,L1,Ea,Yi,M1,R1,Vi,U1,F1,Ji,B1,Au,Me,Y1,Gi,V1,J1,Qi,G1,Q1,Nu,yt,Iu,kt,Su,Ka,Hu,fe,W1,Wi,X1,K1,Xi,Z1,e$,Ki,a$,s$,Lu,Tt,Mu,ja,Za,Zi,Ct,t$,ed,n$,Ru,Yn,o$,Uu,Q,r$,ad,l$,i$,sd,d$,p$,td,u$,c$,nd,m$,f$,od,h$,v$,Fu,Pt,Bu,zt,Yu,es,_$,Vn,g$,$$,Vu,ba,as,rd,Ot,E$,ld,j$,Ju,At,Gu,Jn,b$,Qu,ss,id,Nt,Gn,q$,w$,Qn,x$,D$,qa,It,Wn,y$,k$,Xn,dd,T$,C$,St,Kn,P$,z$,Zn,pd,O$,A$,Ht,eo,N$,I$,ao,ud,S$,Wu,so,H$,Xu,Lt,Ku,to,L$,Zu,Mt,ec,he,M$,cd,R$,U$,md,F$,B$,fd,Y$,V$,ac,ts,J$,hd,G$,Q$,sc,Rt,tc,Ut,nc,ns,W$,vd,X$,K$,oc,Ft,rc,os,Z$,Bt,eE,aE,lc,Yt,ic,Vt,dc,rs,sE,no,tE,nE,pc,Jt,uc,oo,oE,cc,ls,Gt,rE,ro,lE,iE,dE,wa,pE,_d,uE,cE,lo,mE,fE,mc,io,hE,fc;return b=new Kt({}),z=new f3({props:{chapter:5,classNames:"absolute z-10 right-0 top-0",notebooks:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter5/section3.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter5/section3.ipynb"}]}}),O=new gE({props:{id:"tqfSFcPMgOI"}}),ne=new Kt({}),ws=new E({props:{code:`!wget "https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip"
!unzip drugsCom_raw.zip`,highlighted:`!wget <span class="hljs-string">&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip&quot;</span>
!unzip drugsCom_raw.<span class="hljs-built_in">zip</span>`}}),xs=new E({props:{code:`from datasets import load_dataset

data_files = {"train": "drugsComTrain_raw.tsv", "test": "drugsComTest_raw.tsv"}
# \\t es el caracter para tabulaciones en Python
drug_dataset = load_dataset("csv", data_files=data_files, delimiter="\\t")`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

data_files = {<span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;drugsComTrain_raw.tsv&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;drugsComTest_raw.tsv&quot;</span>}
<span class="hljs-comment"># \\t es el caracter para tabulaciones en Python</span>
drug_dataset = load_dataset(<span class="hljs-string">&quot;csv&quot;</span>, data_files=data_files, delimiter=<span class="hljs-string">&quot;\\t&quot;</span>)`}}),Ds=new E({props:{code:`drug_sample = drug_dataset["train"].shuffle(seed=42).select(range(1000))
# Mirar los primeros ejemplos
drug_sample[:3]`,highlighted:`drug_sample = drug_dataset[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))
<span class="hljs-comment"># Mirar los primeros ejemplos</span>
drug_sample[:<span class="hljs-number">3</span>]`}}),ys=new E({props:{code:`{'Unnamed: 0': [87571, 178045, 80482],
 'drugName': ['Naproxen', 'Duloxetine', 'Mobic'],
 'condition': ['Gout, Acute', 'ibromyalgia', 'Inflammatory Conditions'],
 'review': ['"like the previous person mention, I&#039;m a strong believer of aleve, it works faster for my gout than the prescription meds I take. No more going to the doctor for refills.....Aleve works!"',
  '"I have taken Cymbalta for about a year and a half for fibromyalgia pain. It is great\\r\\nas a pain reducer and an anti-depressant, however, the side effects outweighed \\r\\nany benefit I got from it. I had trouble with restlessness, being tired constantly,\\r\\ndizziness, dry mouth, numbness and tingling in my feet, and horrible sweating. I am\\r\\nbeing weaned off of it now. Went from 60 mg to 30mg and now to 15 mg. I will be\\r\\noff completely in about a week. The fibro pain is coming back, but I would rather deal with it than the side effects."',
  '"I have been taking Mobic for over a year with no side effects other than an elevated blood pressure.  I had severe knee and ankle pain which completely went away after taking Mobic.  I attempted to stop the medication however pain returned after a few days."'],
 'rating': [9.0, 3.0, 10.0],
 'date': ['September 2, 2015', 'November 7, 2011', 'June 5, 2013'],
 'usefulCount': [36, 13, 128]}`,highlighted:`{<span class="hljs-string">&#x27;Unnamed: 0&#x27;</span>: [<span class="hljs-number">87571</span>, <span class="hljs-number">178045</span>, <span class="hljs-number">80482</span>],
 <span class="hljs-string">&#x27;drugName&#x27;</span>: [<span class="hljs-string">&#x27;Naproxen&#x27;</span>, <span class="hljs-string">&#x27;Duloxetine&#x27;</span>, <span class="hljs-string">&#x27;Mobic&#x27;</span>],
 <span class="hljs-string">&#x27;condition&#x27;</span>: [<span class="hljs-string">&#x27;Gout, Acute&#x27;</span>, <span class="hljs-string">&#x27;ibromyalgia&#x27;</span>, <span class="hljs-string">&#x27;Inflammatory Conditions&#x27;</span>],
 <span class="hljs-string">&#x27;review&#x27;</span>: [<span class="hljs-string">&#x27;&quot;like the previous person mention, I&amp;#039;m a strong believer of aleve, it works faster for my gout than the prescription meds I take. No more going to the doctor for refills.....Aleve works!&quot;&#x27;</span>,
  <span class="hljs-string">&#x27;&quot;I have taken Cymbalta for about a year and a half for fibromyalgia pain. It is great\\r\\nas a pain reducer and an anti-depressant, however, the side effects outweighed \\r\\nany benefit I got from it. I had trouble with restlessness, being tired constantly,\\r\\ndizziness, dry mouth, numbness and tingling in my feet, and horrible sweating. I am\\r\\nbeing weaned off of it now. Went from 60 mg to 30mg and now to 15 mg. I will be\\r\\noff completely in about a week. The fibro pain is coming back, but I would rather deal with it than the side effects.&quot;&#x27;</span>,
  <span class="hljs-string">&#x27;&quot;I have been taking Mobic for over a year with no side effects other than an elevated blood pressure.  I had severe knee and ankle pain which completely went away after taking Mobic.  I attempted to stop the medication however pain returned after a few days.&quot;&#x27;</span>],
 <span class="hljs-string">&#x27;rating&#x27;</span>: [<span class="hljs-number">9.0</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">10.0</span>],
 <span class="hljs-string">&#x27;date&#x27;</span>: [<span class="hljs-string">&#x27;September 2, 2015&#x27;</span>, <span class="hljs-string">&#x27;November 7, 2011&#x27;</span>, <span class="hljs-string">&#x27;June 5, 2013&#x27;</span>],
 <span class="hljs-string">&#x27;usefulCount&#x27;</span>: [<span class="hljs-number">36</span>, <span class="hljs-number">13</span>, <span class="hljs-number">128</span>]}`}}),Cs=new E({props:{code:`for split in drug_dataset.keys():
    assert len(drug_dataset[split]) == len(drug_dataset[split].unique("Unnamed: 0"))`,highlighted:`<span class="hljs-keyword">for</span> split <span class="hljs-keyword">in</span> drug_dataset.keys():
    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(drug_dataset[split]) == <span class="hljs-built_in">len</span>(drug_dataset[split].unique(<span class="hljs-string">&quot;Unnamed: 0&quot;</span>))`}}),Ps=new E({props:{code:`drug_dataset = drug_dataset.rename_column(
    original_column_name="Unnamed: 0", new_column_name="patient_id"
)
drug_dataset`,highlighted:`drug_dataset = drug_dataset.rename_column(
    original_column_name=<span class="hljs-string">&quot;Unnamed: 0&quot;</span>, new_column_name=<span class="hljs-string">&quot;patient_id&quot;</span>
)
drug_dataset`}}),zs=new E({props:{code:`DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],
        num_rows: 161297
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],
        num_rows: 53766
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>],
        num_rows: <span class="hljs-number">161297</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>],
        num_rows: <span class="hljs-number">53766</span>
    })
})`}}),ya=new gs({props:{$$slots:{default:[h3]},$$scope:{ctx:M}}}),Os=new E({props:{code:`def lowercase_condition(example):
    return {"condition": example["condition"].lower()}


drug_dataset.map(lowercase_condition)`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">lowercase_condition</span>(<span class="hljs-params">example</span>):
    <span class="hljs-keyword">return</span> {<span class="hljs-string">&quot;condition&quot;</span>: example[<span class="hljs-string">&quot;condition&quot;</span>].lower()}


drug_dataset.<span class="hljs-built_in">map</span>(lowercase_condition)`}}),As=new E({props:{code:"AttributeError: 'NoneType' object has no attribute 'lower'",highlighted:'AttributeError: <span class="hljs-string">&#x27;NoneType&#x27;</span> <span class="hljs-built_in">object</span> has no attribute <span class="hljs-string">&#x27;lower&#x27;</span>'}}),Ns=new E({props:{code:`def filter_nones(x):
    return x["condition"] is not None`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">filter_nones</span>(<span class="hljs-params">x</span>):
    <span class="hljs-keyword">return</span> x[<span class="hljs-string">&quot;condition&quot;</span>] <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>`}}),Is=new E({props:{code:"lambda <arguments> : <expression>",highlighted:'lambda <span class="hljs-tag">&lt;<span class="hljs-name">arguments</span>&gt;</span> : <span class="hljs-tag">&lt;<span class="hljs-name">expression</span>&gt;</span>'}}),Hs=new E({props:{code:"lambda x : x * x",highlighted:'lambda <span class="hljs-keyword">x</span> : <span class="hljs-keyword">x</span> * <span class="hljs-keyword">x</span>'}}),Ls=new E({props:{code:"(lambda x: x * x)(3)",highlighted:'(<span class="hljs-keyword">lambda</span> x: x * x)(<span class="hljs-number">3</span>)'}}),Ms=new E({props:{code:"9",highlighted:'<span class="hljs-number">9</span>'}}),Rs=new E({props:{code:"(lambda base, height: 0.5 * base * height)(4, 8)",highlighted:'(<span class="hljs-keyword">lambda</span> base, height: <span class="hljs-number">0.5</span> * base * height)(<span class="hljs-number">4</span>, <span class="hljs-number">8</span>)'}}),Us=new E({props:{code:"16.0",highlighted:'<span class="hljs-number">16.0</span>'}}),Bs=new E({props:{code:'drug_dataset = drug_dataset.filter(lambda x: x["condition"] is not None)',highlighted:'drug_dataset = drug_dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-string">&quot;condition&quot;</span>] <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>)'}}),Ys=new E({props:{code:`drug_dataset = drug_dataset.map(lowercase_condition)
# Revisar que se pasaron a min\xFAscula
drug_dataset["train"]["condition"][:3]`,highlighted:`drug_dataset = drug_dataset.<span class="hljs-built_in">map</span>(lowercase_condition)
<span class="hljs-comment"># Revisar que se pasaron a min\xFAscula</span>
drug_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-string">&quot;condition&quot;</span>][:<span class="hljs-number">3</span>]`}}),Vs=new E({props:{code:"['left ventricular dysfunction', 'adhd', 'birth control']",highlighted:'[<span class="hljs-string">&#x27;left ventricular dysfunction&#x27;</span>, <span class="hljs-string">&#x27;adhd&#x27;</span>, <span class="hljs-string">&#x27;birth control&#x27;</span>]'}}),Js=new Kt({}),Gs=new E({props:{code:`def compute_review_length(example):
    return {"review_length": len(example["review"].split())}`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_review_length</span>(<span class="hljs-params">example</span>):
    <span class="hljs-keyword">return</span> {<span class="hljs-string">&quot;review_length&quot;</span>: <span class="hljs-built_in">len</span>(example[<span class="hljs-string">&quot;review&quot;</span>].split())}`}}),Qs=new E({props:{code:`drug_dataset = drug_dataset.map(compute_review_length)
# Inspeccionar el primer ejemplo de entrenamiento
drug_dataset["train"][0]`,highlighted:`drug_dataset = drug_dataset.<span class="hljs-built_in">map</span>(compute_review_length)
<span class="hljs-comment"># Inspeccionar el primer ejemplo de entrenamiento</span>
drug_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]`}}),Ws=new E({props:{code:`{'patient_id': 206461,
 'drugName': 'Valsartan',
 'condition': 'left ventricular dysfunction',
 'review': '"It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil"',
 'rating': 9.0,
 'date': 'May 20, 2012',
 'usefulCount': 27,
 'review_length': 17}`,highlighted:`{<span class="hljs-string">&#x27;patient_id&#x27;</span>: <span class="hljs-number">206461</span>,
 <span class="hljs-string">&#x27;drugName&#x27;</span>: <span class="hljs-string">&#x27;Valsartan&#x27;</span>,
 <span class="hljs-string">&#x27;condition&#x27;</span>: <span class="hljs-string">&#x27;left ventricular dysfunction&#x27;</span>,
 <span class="hljs-string">&#x27;review&#x27;</span>: <span class="hljs-string">&#x27;&quot;It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil&quot;&#x27;</span>,
 <span class="hljs-string">&#x27;rating&#x27;</span>: <span class="hljs-number">9.0</span>,
 <span class="hljs-string">&#x27;date&#x27;</span>: <span class="hljs-string">&#x27;May 20, 2012&#x27;</span>,
 <span class="hljs-string">&#x27;usefulCount&#x27;</span>: <span class="hljs-number">27</span>,
 <span class="hljs-string">&#x27;review_length&#x27;</span>: <span class="hljs-number">17</span>}`}}),Xs=new E({props:{code:'drug_dataset["train"].sort("review_length")[:3]',highlighted:'drug_dataset[<span class="hljs-string">&quot;train&quot;</span>].sort(<span class="hljs-string">&quot;review_length&quot;</span>)[:<span class="hljs-number">3</span>]'}}),Ks=new E({props:{code:`{'patient_id': [103488, 23627, 20558],
 'drugName': ['Loestrin 21 1 / 20', 'Chlorzoxazone', 'Nucynta'],
 'condition': ['birth control', 'muscle spasm', 'pain'],
 'review': ['"Excellent."', '"useless"', '"ok"'],
 'rating': [10.0, 1.0, 6.0],
 'date': ['November 4, 2008', 'March 24, 2017', 'August 20, 2016'],
 'usefulCount': [5, 2, 10],
 'review_length': [1, 1, 1]}`,highlighted:`{<span class="hljs-string">&#x27;patient_id&#x27;</span>: [<span class="hljs-number">103488</span>, <span class="hljs-number">23627</span>, <span class="hljs-number">20558</span>],
 <span class="hljs-string">&#x27;drugName&#x27;</span>: [<span class="hljs-string">&#x27;Loestrin 21 1 / 20&#x27;</span>, <span class="hljs-string">&#x27;Chlorzoxazone&#x27;</span>, <span class="hljs-string">&#x27;Nucynta&#x27;</span>],
 <span class="hljs-string">&#x27;condition&#x27;</span>: [<span class="hljs-string">&#x27;birth control&#x27;</span>, <span class="hljs-string">&#x27;muscle spasm&#x27;</span>, <span class="hljs-string">&#x27;pain&#x27;</span>],
 <span class="hljs-string">&#x27;review&#x27;</span>: [<span class="hljs-string">&#x27;&quot;Excellent.&quot;&#x27;</span>, <span class="hljs-string">&#x27;&quot;useless&quot;&#x27;</span>, <span class="hljs-string">&#x27;&quot;ok&quot;&#x27;</span>],
 <span class="hljs-string">&#x27;rating&#x27;</span>: [<span class="hljs-number">10.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">6.0</span>],
 <span class="hljs-string">&#x27;date&#x27;</span>: [<span class="hljs-string">&#x27;November 4, 2008&#x27;</span>, <span class="hljs-string">&#x27;March 24, 2017&#x27;</span>, <span class="hljs-string">&#x27;August 20, 2016&#x27;</span>],
 <span class="hljs-string">&#x27;usefulCount&#x27;</span>: [<span class="hljs-number">5</span>, <span class="hljs-number">2</span>, <span class="hljs-number">10</span>],
 <span class="hljs-string">&#x27;review_length&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),Ta=new gs({props:{$$slots:{default:[v3]},$$scope:{ctx:M}}}),Zs=new E({props:{code:`drug_dataset = drug_dataset.filter(lambda x: x["review_length"] > 30)
print(drug_dataset.num_rows)`,highlighted:`drug_dataset = drug_dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-string">&quot;review_length&quot;</span>] &gt; <span class="hljs-number">30</span>)
<span class="hljs-built_in">print</span>(drug_dataset.num_rows)`}}),et=new E({props:{code:"{'train': 138514, 'test': 46108}",highlighted:'{<span class="hljs-string">&#x27;train&#x27;</span>: <span class="hljs-number">138514</span>, <span class="hljs-string">&#x27;test&#x27;</span>: <span class="hljs-number">46108</span>}'}}),Ca=new gs({props:{$$slots:{default:[_3]},$$scope:{ctx:M}}}),at=new E({props:{code:`import html

text = "I&#039;m a transformer called BERT"
html.unescape(text)`,highlighted:`<span class="hljs-keyword">import</span> html

text = <span class="hljs-string">&quot;I&amp;#039;m a transformer called BERT&quot;</span>
html.unescape(text)`}}),st=new E({props:{code:`"I'm a transformer called BERT"`,highlighted:'<span class="hljs-string">&quot;I&#x27;m a transformer called BERT&quot;</span>'}}),tt=new E({props:{code:'drug_dataset = drug_dataset.map(lambda x: {"review": html.unescape(x["review"])})',highlighted:'drug_dataset = drug_dataset.<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: {<span class="hljs-string">&quot;review&quot;</span>: html.unescape(x[<span class="hljs-string">&quot;review&quot;</span>])})'}}),nt=new Kt({}),ot=new E({props:{code:`new_drug_dataset = drug_dataset.map(
    lambda x: {"review": [html.unescape(o) for o in x["review"]]}, batched=True
)`,highlighted:`new_drug_dataset = drug_dataset.<span class="hljs-built_in">map</span>(
    <span class="hljs-keyword">lambda</span> x: {<span class="hljs-string">&quot;review&quot;</span>: [html.unescape(o) <span class="hljs-keyword">for</span> o <span class="hljs-keyword">in</span> x[<span class="hljs-string">&quot;review&quot;</span>]]}, batched=<span class="hljs-literal">True</span>
)`}}),rt=new E({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")


def tokenize_function(examples):
    return tokenizer(examples["review"], truncation=True)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">examples</span>):
    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&quot;review&quot;</span>], truncation=<span class="hljs-literal">True</span>)`}}),lt=new E({props:{code:"%time tokenized_dataset = drug_dataset.map(tokenize_function, batched=True)",highlighted:'%time tokenized_dataset = drug_dataset.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)'}}),Ia=new gs({props:{$$slots:{default:[g3]},$$scope:{ctx:M}}}),dt=new E({props:{code:`slow_tokenizer = AutoTokenizer.from_pretrained("bert-base-cased", use_fast=False)


def slow_tokenize_function(examples):
    return slow_tokenizer(examples["review"], truncation=True)


tokenized_dataset = drug_dataset.map(slow_tokenize_function, batched=True, num_proc=8)`,highlighted:`slow_tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, use_fast=<span class="hljs-literal">False</span>)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">slow_tokenize_function</span>(<span class="hljs-params">examples</span>):
    <span class="hljs-keyword">return</span> slow_tokenizer(examples[<span class="hljs-string">&quot;review&quot;</span>], truncation=<span class="hljs-literal">True</span>)


tokenized_dataset = drug_dataset.<span class="hljs-built_in">map</span>(slow_tokenize_function, batched=<span class="hljs-literal">True</span>, num_proc=<span class="hljs-number">8</span>)`}}),Ra=new gs({props:{$$slots:{default:[$3]},$$scope:{ctx:M}}}),Ua=new gs({props:{$$slots:{default:[E3]},$$scope:{ctx:M}}}),pt=new E({props:{code:`def tokenize_and_split(examples):
    return tokenizer(
        examples["review"],
        truncation=True,
        max_length=128,
        return_overflowing_tokens=True,
    )`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_and_split</span>(<span class="hljs-params">examples</span>):
    <span class="hljs-keyword">return</span> tokenizer(
        examples[<span class="hljs-string">&quot;review&quot;</span>],
        truncation=<span class="hljs-literal">True</span>,
        max_length=<span class="hljs-number">128</span>,
        return_overflowing_tokens=<span class="hljs-literal">True</span>,
    )`}}),ut=new E({props:{code:`result = tokenize_and_split(drug_dataset["train"][0])
[len(inp) for inp in result["input_ids"]]`,highlighted:`result = tokenize_and_split(drug_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>])
[<span class="hljs-built_in">len</span>(inp) <span class="hljs-keyword">for</span> inp <span class="hljs-keyword">in</span> result[<span class="hljs-string">&quot;input_ids&quot;</span>]]`}}),ct=new E({props:{code:"[128, 49]",highlighted:'[<span class="hljs-number">128</span>, <span class="hljs-number">49</span>]'}}),mt=new E({props:{code:"tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)",highlighted:'tokenized_dataset = drug_dataset.<span class="hljs-built_in">map</span>(tokenize_and_split, batched=<span class="hljs-literal">True</span>)'}}),ft=new E({props:{code:"ArrowInvalid: Column 1 named condition expected length 1463 but got length 1000",highlighted:'ArrowInvalid: Column <span class="hljs-number">1</span> named condition expected length <span class="hljs-number">1463</span> but got length <span class="hljs-number">1000</span>'}}),ht=new E({props:{code:`tokenized_dataset = drug_dataset.map(
    tokenize_and_split, batched=True, remove_columns=drug_dataset["train"].column_names
)`,highlighted:`tokenized_dataset = drug_dataset.<span class="hljs-built_in">map</span>(
    tokenize_and_split, batched=<span class="hljs-literal">True</span>, remove_columns=drug_dataset[<span class="hljs-string">&quot;train&quot;</span>].column_names
)`}}),vt=new E({props:{code:'len(tokenized_dataset["train"]), len(drug_dataset["train"])',highlighted:'<span class="hljs-built_in">len</span>(tokenized_dataset[<span class="hljs-string">&quot;train&quot;</span>]), <span class="hljs-built_in">len</span>(drug_dataset[<span class="hljs-string">&quot;train&quot;</span>])'}}),_t=new E({props:{code:"(206772, 138514)",highlighted:'(<span class="hljs-number">206772</span>, <span class="hljs-number">138514</span>)'}}),gt=new E({props:{code:`def tokenize_and_split(examples):
    result = tokenizer(
        examples["review"],
        truncation=True,
        max_length=128,
        return_overflowing_tokens=True,
    )
    # Extraer el mapeo entre los \xEDndices nuevos y viejos
    sample_map = result.pop("overflow_to_sample_mapping")
    for key, values in examples.items():
        result[key] = [values[i] for i in sample_map]
    return result`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_and_split</span>(<span class="hljs-params">examples</span>):
    result = tokenizer(
        examples[<span class="hljs-string">&quot;review&quot;</span>],
        truncation=<span class="hljs-literal">True</span>,
        max_length=<span class="hljs-number">128</span>,
        return_overflowing_tokens=<span class="hljs-literal">True</span>,
    )
    <span class="hljs-comment"># Extraer el mapeo entre los \xEDndices nuevos y viejos</span>
    sample_map = result.pop(<span class="hljs-string">&quot;overflow_to_sample_mapping&quot;</span>)
    <span class="hljs-keyword">for</span> key, values <span class="hljs-keyword">in</span> examples.items():
        result[key] = [values[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> sample_map]
    <span class="hljs-keyword">return</span> result`}}),$t=new E({props:{code:`tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)
tokenized_dataset`,highlighted:`tokenized_dataset = drug_dataset.<span class="hljs-built_in">map</span>(tokenize_and_split, batched=<span class="hljs-literal">True</span>)
tokenized_dataset`}}),Et=new E({props:{code:`DatasetDict({
    train: Dataset({
        features: ['attention_mask', 'condition', 'date', 'drugName', 'input_ids', 'patient_id', 'rating', 'review', 'review_length', 'token_type_ids', 'usefulCount'],
        num_rows: 206772
    })
    test: Dataset({
        features: ['attention_mask', 'condition', 'date', 'drugName', 'input_ids', 'patient_id', 'rating', 'review', 'review_length', 'token_type_ids', 'usefulCount'],
        num_rows: 68876
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>, <span class="hljs-string">&#x27;token_type_ids&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>],
        num_rows: <span class="hljs-number">206772</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>, <span class="hljs-string">&#x27;token_type_ids&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>],
        num_rows: <span class="hljs-number">68876</span>
    })
})`}}),jt=new Kt({}),bt=new gE({props:{id:"tfcY1067A5Q"}}),qt=new E({props:{code:'drug_dataset.set_format("pandas")',highlighted:'drug_dataset.set_format(<span class="hljs-string">&quot;pandas&quot;</span>)'}}),wt=new E({props:{code:'drug_dataset["train"][:3]',highlighted:'drug_dataset[<span class="hljs-string">&quot;train&quot;</span>][:<span class="hljs-number">3</span>]'}}),xt=new E({props:{code:'train_df = drug_dataset["train"][:]',highlighted:'train_df = drug_dataset[<span class="hljs-string">&quot;train&quot;</span>][:]'}}),Wa=new gs({props:{$$slots:{default:[j3]},$$scope:{ctx:M}}}),Dt=new E({props:{code:`frequencies = (
    train_df["condition"]
    .value_counts()
    .to_frame()
    .reset_index()
    .rename(columns={"index": "condition", "condition": "frequency"})
)
frequencies.head()`,highlighted:`frequencies = (
    train_df[<span class="hljs-string">&quot;condition&quot;</span>]
    .value_counts()
    .to_frame()
    .reset_index()
    .rename(columns={<span class="hljs-string">&quot;index&quot;</span>: <span class="hljs-string">&quot;condition&quot;</span>, <span class="hljs-string">&quot;condition&quot;</span>: <span class="hljs-string">&quot;frequency&quot;</span>})
)
frequencies.head()`}}),yt=new E({props:{code:`from datasets import Dataset

freq_dataset = Dataset.from_pandas(frequencies)
freq_dataset`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset

freq_dataset = Dataset.from_pandas(frequencies)
freq_dataset`}}),kt=new E({props:{code:`Dataset({
    features: ['condition', 'frequency'],
    num_rows: 819
})`,highlighted:`Dataset({
    features: [<span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;frequency&#x27;</span>],
    num_rows: <span class="hljs-number">819</span>
})`}}),Ka=new gs({props:{$$slots:{default:[b3]},$$scope:{ctx:M}}}),Tt=new E({props:{code:"drug_dataset.reset_format()",highlighted:"drug_dataset.reset_format()"}}),Ct=new Kt({}),Pt=new E({props:{code:`drug_dataset_clean = drug_dataset["train"].train_test_split(train_size=0.8, seed=42)
# Renombrar el conjunto "test" a "validation"
drug_dataset_clean["validation"] = drug_dataset_clean.pop("test")
# A\xF1adir el conjunto "test" al \`DatasetDict\`
drug_dataset_clean["test"] = drug_dataset["test"]
drug_dataset_clean`,highlighted:`drug_dataset_clean = drug_dataset[<span class="hljs-string">&quot;train&quot;</span>].train_test_split(train_size=<span class="hljs-number">0.8</span>, seed=<span class="hljs-number">42</span>)
<span class="hljs-comment"># Renombrar el conjunto &quot;test&quot; a &quot;validation&quot;</span>
drug_dataset_clean[<span class="hljs-string">&quot;validation&quot;</span>] = drug_dataset_clean.pop(<span class="hljs-string">&quot;test&quot;</span>)
<span class="hljs-comment"># A\xF1adir el conjunto &quot;test&quot; al \`DatasetDict\`</span>
drug_dataset_clean[<span class="hljs-string">&quot;test&quot;</span>] = drug_dataset[<span class="hljs-string">&quot;test&quot;</span>]
drug_dataset_clean`}}),zt=new E({props:{code:`DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 110811
    })
    validation: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 27703
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 46108
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>, <span class="hljs-string">&#x27;review_clean&#x27;</span>],
        num_rows: <span class="hljs-number">110811</span>
    })
    validation: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>, <span class="hljs-string">&#x27;review_clean&#x27;</span>],
        num_rows: <span class="hljs-number">27703</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>, <span class="hljs-string">&#x27;review_clean&#x27;</span>],
        num_rows: <span class="hljs-number">46108</span>
    })
})`}}),Ot=new Kt({}),At=new gE({props:{id:"blF9uxYcKHo"}}),Lt=new E({props:{code:'drug_dataset_clean.save_to_disk("drug-reviews")',highlighted:'drug_dataset_clean.save_to_disk(<span class="hljs-string">&quot;drug-reviews&quot;</span>)'}}),Mt=new E({props:{code:`drug-reviews/
\u251C\u2500\u2500 dataset_dict.json
\u251C\u2500\u2500 test
\u2502   \u251C\u2500\u2500 dataset.arrow
\u2502   \u251C\u2500\u2500 dataset_info.json
\u2502   \u2514\u2500\u2500 state.json
\u251C\u2500\u2500 train
\u2502   \u251C\u2500\u2500 dataset.arrow
\u2502   \u251C\u2500\u2500 dataset_info.json
\u2502   \u251C\u2500\u2500 indices.arrow
\u2502   \u2514\u2500\u2500 state.json
\u2514\u2500\u2500 validation
    \u251C\u2500\u2500 dataset.arrow
    \u251C\u2500\u2500 dataset_info.json
    \u251C\u2500\u2500 indices.arrow
    \u2514\u2500\u2500 state.json`,highlighted:`drug-reviews/
\u251C\u2500\u2500 dataset_dict.json
\u251C\u2500\u2500 test
\u2502   \u251C\u2500\u2500 dataset.arrow
\u2502   \u251C\u2500\u2500 dataset_info.json
\u2502   \u2514\u2500\u2500 <span class="hljs-keyword">state</span>.json
\u251C\u2500\u2500 train
\u2502   \u251C\u2500\u2500 dataset.arrow
\u2502   \u251C\u2500\u2500 dataset_info.json
\u2502   \u251C\u2500\u2500 indices.arrow
\u2502   \u2514\u2500\u2500 <span class="hljs-keyword">state</span>.json
\u2514\u2500\u2500 validation
    \u251C\u2500\u2500 dataset.arrow
    \u251C\u2500\u2500 dataset_info.json
    \u251C\u2500\u2500 indices.arrow
    \u2514\u2500\u2500 <span class="hljs-keyword">state</span>.json`}}),Rt=new E({props:{code:`from datasets import load_from_disk

drug_dataset_reloaded = load_from_disk("drug-reviews")
drug_dataset_reloaded`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_from_disk

drug_dataset_reloaded = load_from_disk(<span class="hljs-string">&quot;drug-reviews&quot;</span>)
drug_dataset_reloaded`}}),Ut=new E({props:{code:`DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 110811
    })
    validation: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 27703
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 46108
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>],
        num_rows: <span class="hljs-number">110811</span>
    })
    validation: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>],
        num_rows: <span class="hljs-number">27703</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>],
        num_rows: <span class="hljs-number">46108</span>
    })
})`}}),Ft=new E({props:{code:`for split, dataset in drug_dataset_clean.items():
    dataset.to_json(f"drug-reviews-{split}.jsonl")`,highlighted:`<span class="hljs-keyword">for</span> split, dataset <span class="hljs-keyword">in</span> drug_dataset_clean.items():
    dataset.to_json(<span class="hljs-string">f&quot;drug-reviews-<span class="hljs-subst">{split}</span>.jsonl&quot;</span>)`}}),Yt=new E({props:{code:"!head -n 1 drug-reviews-train.jsonl",highlighted:'!head -n <span class="hljs-number">1</span> drug-reviews-train.jsonl'}}),Vt=new E({props:{code:`{"patient_id":141780,"drugName":"Escitalopram","condition":"depression","review":"\\"I seemed to experience the regular side effects of LEXAPRO, insomnia, low sex drive, sleepiness during the day. I am taking it at night because my doctor said if it made me tired to take it at night. I assumed it would and started out taking it at night. Strange dreams, some pleasant. I was diagnosed with fibromyalgia. Seems to be helping with the pain. Have had anxiety and depression in my family, and have tried quite a few other medications that haven't worked. Only have been on it for two weeks but feel more positive in my mind, want to accomplish more in my life. Hopefully the side effects will dwindle away, worth it to stick with it from hearing others responses. Great medication.\\"","rating":9.0,"date":"May 29, 2011","usefulCount":10,"review_length":125}`,highlighted:'{<span class="hljs-string">&quot;patient_id&quot;</span>:<span class="hljs-number">141780</span>,<span class="hljs-string">&quot;drugName&quot;</span>:<span class="hljs-string">&quot;Escitalopram&quot;</span>,<span class="hljs-string">&quot;condition&quot;</span>:<span class="hljs-string">&quot;depression&quot;</span>,<span class="hljs-string">&quot;review&quot;</span>:<span class="hljs-string">&quot;\\&quot;I seemed to experience the regular side effects of LEXAPRO, insomnia, low sex drive, sleepiness during the day. I am taking it at night because my doctor said if it made me tired to take it at night. I assumed it would and started out taking it at night. Strange dreams, some pleasant. I was diagnosed with fibromyalgia. Seems to be helping with the pain. Have had anxiety and depression in my family, and have tried quite a few other medications that haven&#x27;t worked. Only have been on it for two weeks but feel more positive in my mind, want to accomplish more in my life. Hopefully the side effects will dwindle away, worth it to stick with it from hearing others responses. Great medication.\\&quot;&quot;</span>,<span class="hljs-string">&quot;rating&quot;</span>:<span class="hljs-number">9.0</span>,<span class="hljs-string">&quot;date&quot;</span>:<span class="hljs-string">&quot;May 29, 2011&quot;</span>,<span class="hljs-string">&quot;usefulCount&quot;</span>:<span class="hljs-number">10</span>,<span class="hljs-string">&quot;review_length&quot;</span>:<span class="hljs-number">125</span>}'}}),Jt=new E({props:{code:`data_files = {
    "train": "drug-reviews-train.jsonl",
    "validation": "drug-reviews-validation.jsonl",
    "test": "drug-reviews-test.jsonl",
}
drug_dataset_reloaded = load_dataset("json", data_files=data_files)`,highlighted:`data_files = {
    <span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;drug-reviews-train.jsonl&quot;</span>,
    <span class="hljs-string">&quot;validation&quot;</span>: <span class="hljs-string">&quot;drug-reviews-validation.jsonl&quot;</span>,
    <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;drug-reviews-test.jsonl&quot;</span>,
}
drug_dataset_reloaded = load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=data_files)`}}),{c(){c=o("meta"),T=d(),j=o("h1"),x=o("a"),y=o("span"),f(b.$$.fragment),D=d(),C=o("span"),q=t("Es momento de subdividir"),w=d(),f(z.$$.fragment),k=d(),P=o("p"),J=t("La mayor parte del tiempo tus datos no estar\xE1n perfectamente listos para entrenar modelos. En esta secci\xF3n vamos a explorar distintas funciones que tiene \u{1F917} Datasets para limpiar tus conjuntos de datos."),N=d(),f(O.$$.fragment),ge=d(),R=o("h2"),W=o("a"),re=o("span"),f(ne.$$.fragment),$s=d(),We=o("span"),Xe=t("Subdivdiendo nuestros datos"),xa=d(),U=o("p"),Ke=t("De manera similar a Pandas, \u{1F917} Datasets incluye varias funciones para manipular el contenido de los objetos "),Ze=o("code"),Es=t("Dataset"),ea=t(" y "),A=o("code"),Zt=t("DatasetDict"),en=t(". Ya vimos el m\xE9todo "),Da=o("code"),an=t("Dataset.map()"),sn=t(" en el "),aa=o("a"),tn=t("Cap\xEDtulo 3"),nn=t(" y en esta secci\xF3n vamos a explorar otras funciones que tenemos a nuestra disposici\xF3n."),js=d(),je=o("p"),Xc=t("Para este ejemplo, vamos a usar el "),bs=o("a"),Kc=t("Dataset de rese\xF1as de medicamentos"),Zc=t(" alojado en el "),qs=o("a"),em=t("Repositorio de Machine Learning de UC Irvine"),am=t(", que contiene la evaluaci\xF3n de varios medicamentos por parte de pacientes, junto con la condici\xF3n por la que los estaban tratando y una calificaci\xF3n en una escala de 10 estrellas sobre su satisfacci\xF3n."),wd=d(),be=o("p"),sm=t("Primero, tenemos que descargar y extraer los datos, que se puede hacer con los comandos "),Vo=o("code"),tm=t("wget"),nm=t(" y "),Jo=o("code"),om=t("unzip"),rm=t(":"),xd=d(),f(ws.$$.fragment),Dd=d(),le=o("p"),lm=t("Dado que TSV es una variaci\xF3n de CSV en la que se usan tabulaciones en vez de comas como separadores, podemos cargar estos archivos usando el script de carga "),Go=o("code"),im=t("csv"),dm=t(" y especificando el argumento "),Qo=o("code"),pm=t("delimiter"),um=t(" en la funci\xF3n "),Wo=o("code"),cm=t("load_dataset"),mm=t(" de la siguiente manera:"),yd=d(),f(xs.$$.fragment),kd=d(),qe=o("p"),fm=t("Una buena pr\xE1ctica al hacer cualquier tipo de an\xE1lisis de datos es tomar una muestra aleatoria del dataset para tener una vista r\xE1pida del tipo de datos con los que est\xE1s trabajando. En \u{1F917} Datasets, podemos crear una muestra aleatoria al encadenar las funciones "),Xo=o("code"),hm=t("Dataset.shuffle()"),vm=t(" y "),Ko=o("code"),_m=t("Dataset.select()"),gm=t(":"),Td=d(),f(Ds.$$.fragment),Cd=d(),f(ys.$$.fragment),Pd=d(),ie=o("p"),$m=t("Puedes ver que hemos fijado la semilla en "),Zo=o("code"),Em=t("Dataset.shuffle()"),jm=t(" por motivos de reproducibilidad. "),er=o("code"),bm=t("Dataset.select()"),qm=t(" espera un interable de \xEDndices, as\xED que incluimos "),ar=o("code"),wm=t("range(1000)"),xm=t(" para tomar los primeros 1.000 ejemplos del conjunto de datos aleatorizado. Ya podemos ver algunos detalles para esta muestra:"),zd=d(),we=o("ul"),ks=o("li"),Dm=t("La columna "),sr=o("code"),ym=t("Unnamed: 0"),km=t(" se ve sospechosamente como un ID anonimizado para cada paciente."),Tm=d(),Ts=o("li"),Cm=t("La columna "),tr=o("code"),Pm=t("condition"),zm=t(" incluye una mezcla de niveles en may\xFAscula y min\xFAscula."),Om=d(),sa=o("li"),Am=t("Las rese\xF1as tienen longitud variable y contienen una mezcla de separadores de l\xEDnea de Python ("),nr=o("code"),Nm=t("\\r\\n"),Im=t("), as\xED como caracteres de HTML como "),or=o("code"),Sm=t("&\\#039;"),Hm=t("."),Od=d(),xe=o("p"),Lm=t("Veamos c\xF3mo podemos usar \u{1F917} Datasets para lidiar con cada uno de estos asuntos. Para probar la hip\xF3tesis de que la columna "),rr=o("code"),Mm=t("Unnamed: 0"),Rm=t(" es un ID de los pacientes, podemos usar la funci\xF3n "),lr=o("code"),Um=t("Dataset.unique()"),Fm=t(" para verificar que el n\xFAmero de los ID corresponda con el n\xFAmero de filas de cada conjunto:"),Ad=d(),f(Cs.$$.fragment),Nd=d(),De=o("p"),Bm=t("Esto parece confirmar nuestra hip\xF3tesis, as\xED que limpiemos el dataset un poco al cambiar el nombre de la columna "),ir=o("code"),Ym=t("Unnamed: 0"),Vm=t(" a algo m\xE1s legible. Podemos usar la funci\xF3n "),dr=o("code"),Jm=t("DatasetDict.rename_column()"),Gm=t(" para renombrar la columna en ambos conjuntos en una sola operaci\xF3n:"),Id=d(),f(Ps.$$.fragment),Sd=d(),f(zs.$$.fragment),Hd=d(),f(ya.$$.fragment),Ld=d(),X=o("p"),Qm=t("Ahora normalicemos todas las etiquetas de "),pr=o("code"),Wm=t("condition"),Xm=t(" usando "),ur=o("code"),Km=t("Dataset.map()"),Zm=t(". Tal como lo hicimos con la tokenizaci\xF3n en el "),on=o("a"),ef=t("Cap\xEDtulo 3"),af=t(", podemos definir una funci\xF3n simple que pueda ser aplicada en todas las filas de cada conjunto en el "),cr=o("code"),sf=t("drug_dataset"),tf=t(":"),Md=d(),f(Os.$$.fragment),Rd=d(),f(As.$$.fragment),Ud=d(),K=o("p"),nf=t("\xA1Tenemos un problema en nuestra funci\xF3n de mapeo! Del error podemos inferir que algunas de las entradas de la columna "),mr=o("code"),of=t("condici\xF3n"),rf=t(" son "),fr=o("code"),lf=t("None"),df=t(", que no puede transformarse en min\xFAscula al no ser un string. Filtremos estas filas usando "),hr=o("code"),pf=t("Dataset.filter()"),uf=t(", que funciona de una forma similar "),vr=o("code"),cf=t("Dataset.map()"),mf=t(" y recibe como argumento una funci\xF3n que toma un ejemplo particular del dataset. En vez de escribir una funci\xF3n expl\xEDcita como:"),Fd=d(),f(Ns.$$.fragment),Bd=d(),ye=o("p"),ff=t("y luego ejecutar "),_r=o("code"),hf=t("drug_dataset.filter(filter_nones)"),vf=t(", podemos hacerlo en una l\xEDnea usando una "),gr=o("em"),_f=t("funci\xF3n lambda"),gf=t(". En Python, las funciones lambda son funciones peque\xF1as que puedes definir sin nombrarlas expl\xEDcitamente. Estas toman la forma general:"),Yd=d(),f(Is.$$.fragment),Vd=d(),Z=o("p"),$f=t("en la que "),$r=o("code"),Ef=t("lambda"),jf=t(" es una de las "),Ss=o("a"),bf=t("palabras especiales"),qf=t(" de Python, "),Er=o("code"),wf=t("<arguments>"),xf=t(" es una lista o conjunto de valores separados con coma que definen los argumentos de la funci\xF3n y "),jr=o("code"),Df=t("<expression>"),yf=t(" representa las operaciones que quieres ejecutar. Por ejemplo, podemos definir una funci\xF3n lambda simple que eleve un n\xFAmero al cuadrado de la siguiente manera:"),Jd=d(),f(Hs.$$.fragment),Gd=d(),ke=o("p"),kf=t("Para aplicar esta funci\xF3n a un "),br=o("em"),Tf=t("input"),Cf=t(", tenemos que envolverla a ella y al "),qr=o("em"),Pf=t("input"),zf=t(" en par\xE9ntesis:"),Qd=d(),f(Ls.$$.fragment),Wd=d(),f(Ms.$$.fragment),Xd=d(),rn=o("p"),Of=t("De manera similar, podemos definir funciones lambda con m\xFAltiples argumentos separ\xE1ndolos con comas. Por ejemplo, podemos calcular el \xE1rea de un tri\xE1ngulo as\xED:"),Kd=d(),f(Rs.$$.fragment),Zd=d(),f(Us.$$.fragment),ep=d(),Te=o("p"),Af=t("Las funciones lambda son \xFAtiles cuando quieres definir funciones peque\xF1as de un \xFAnico uso (para m\xE1s informaci\xF3n sobre ellas, te recomendamos leer este excelente "),Fs=o("a"),Nf=t("tutorial de Real Python"),If=t(" escrito por Andre Burgaud). En el contexto de \u{1F917} Datasets, podemos usar las funciones lambda para definir operaciones simples de mapeo y filtrado, as\xED que usemos este truco para eliminar las entradas "),wr=o("code"),Sf=t("None"),Hf=t(" de nuestro dataset:"),ap=d(),f(Bs.$$.fragment),sp=d(),Ce=o("p"),Lf=t("Ahora que eliminamos los "),xr=o("code"),Mf=t("None"),Rf=t(", podemos normalizar nuestra columna "),Dr=o("code"),Uf=t("condition"),Ff=t(":"),tp=d(),f(Ys.$$.fragment),np=d(),f(Vs.$$.fragment),op=d(),ln=o("p"),Bf=t("\xA1Funcion\xF3! Como ya limpiamos las etiquetas, veamos c\xF3mo podemos limpiar las rese\xF1as."),rp=d(),ta=o("h2"),ka=o("a"),yr=o("span"),f(Js.$$.fragment),Yf=d(),kr=o("span"),Vf=t("Creando nuevas columnas"),lp=d(),dn=o("p"),Jf=t("Cuando est\xE1s lidiando con rese\xF1as de clientes, es una buena pr\xE1ctica revisar el n\xFAmero de palabras de cada rese\xF1a. Una rese\xF1a puede ser una \xFAnica palabra como \u201C\xA1Genial!\u201D o un ensayo completo con miles de palabras y, seg\xFAn el caso de uso, tendr\xE1s que abordar estos extremos de forma diferente. Para calcular el n\xFAmero de palabras en cada rese\xF1a, usaremos una heur\xEDstica aproximada basada en dividir cada texto por los espacios en blanco."),ip=d(),pn=o("p"),Gf=t("Definamos una funci\xF3n simple que cuente el n\xFAmero de palabras en cada rese\xF1a:"),dp=d(),f(Gs.$$.fragment),pp=d(),G=o("p"),Qf=t("Contrario a la funci\xF3n "),Tr=o("code"),Wf=t("lowercase_condition()"),Xf=t(", "),Cr=o("code"),Kf=t("compute_review_length()"),Zf=t(" devuelve un diccionario cuya llave no corresponde a uno de los nombres de las columnas en el conjunto de datos. En este caso, cuando se pasa "),Pr=o("code"),eh=t("compute_review_length()"),ah=t(" a "),zr=o("code"),sh=t("Dataset.map()"),th=t(",  la funci\xF3n se aplicar\xE1 a todas las filas en el dataset para crear una nueva columna "),Or=o("code"),nh=t("review_length()"),oh=t(":"),up=d(),f(Qs.$$.fragment),cp=d(),f(Ws.$$.fragment),mp=d(),Pe=o("p"),rh=t("Tal como lo esper\xE1bamos, podemos ver que se a\xF1adi\xF3 la columna "),Ar=o("code"),lh=t("review_length"),ih=t(" al conjunto de entrenamiento. Podemos ordenar esta columna nueva con "),Nr=o("code"),dh=t("Dataset.sort()"),ph=t(" para ver c\xF3mo son los valores extremos:"),fp=d(),f(Xs.$$.fragment),hp=d(),f(Ks.$$.fragment),vp=d(),un=o("p"),uh=t("Como lo discutimos anteriormente, algunas rese\xF1as incluyen una sola palabra, que si bien puede ser \xFAtil para el an\xE1lisis de sentimientos, no ser\xEDa tan informativa si quisieramos predecir la condici\xF3n."),_p=d(),f(Ta.$$.fragment),gp=d(),ze=o("p"),ch=t("Usemos la funci\xF3n "),Ir=o("code"),mh=t("Dataset.filter()"),fh=t(" para quitar las rese\xF1as que contienen menos de 30 palabras. Similar a lo que hicimos con la columna "),Sr=o("code"),hh=t("condition"),vh=t(", podemos filtrar las rese\xF1as cortas al incluir una condici\xF3n de que su longitud est\xE9 por encima de este umbral:"),$p=d(),f(Zs.$$.fragment),Ep=d(),f(et.$$.fragment),jp=d(),cn=o("p"),_h=t("Como puedes ver, esto ha eliminado alrededor del 15% de las rese\xF1as de nuestros conjuntos originales de entrenamiento y prueba."),bp=d(),f(Ca.$$.fragment),qp=d(),Pa=o("p"),gh=t("Por \xFAltimo, tenemos que lidiar con la presencia de c\xF3digos de caracteres HTML en las rese\xF1as. Podemos usar el m\xF3dulo "),Hr=o("code"),$h=t("html"),Eh=t(" de Python para transformar estos c\xF3digos as\xED:"),wp=d(),f(at.$$.fragment),xp=d(),f(st.$$.fragment),Dp=d(),za=o("p"),jh=t("Usaremos "),Lr=o("code"),bh=t("Dataset.map()"),qh=t(" para transformar todos los caracteres HTML en el corpus:"),yp=d(),f(tt.$$.fragment),kp=d(),Oa=o("p"),wh=t("Como puedes ver, el m\xE9todo "),Mr=o("code"),xh=t("Dataset.map()"),Dh=t(" es muy \xFAtil para procesar datos y esta es apenas la punta del iceberg de lo que puede hacer."),Tp=d(),na=o("h2"),Aa=o("a"),Rr=o("span"),f(nt.$$.fragment),yh=d(),mn=o("span"),kh=t("Los superpoderes del m\xE9todo "),Ur=o("code"),Th=t("map()"),Cp=d(),ee=o("p"),Ch=t("El m\xE9todo "),Fr=o("code"),Ph=t("Dataset.map()"),zh=t(" recibe un argumento "),Br=o("code"),Oh=t("matched"),Ah=t(" que, al definirse como "),Yr=o("code"),Nh=t("True"),Ih=t(", env\xEDa un lote de ejemplos a la funci\xF3n de mapeo a la vez (el tama\xF1o del lote se puede configurar, pero tiene un valor por defecto de 1.000). Por ejemplo, la funci\xF3n anterior de mapeo que transform\xF3 todos los HTML se demor\xF3 un poco en su ejecuci\xF3n (puedes leer el tiempo en las barras de progreso). Podemos reducir el tiempo al procesar varios elementos a la vez usando un "),Vr=o("em"),Sh=t("list comprehension"),Hh=t("."),Pp=d(),ae=o("p"),Lh=t("Cuando especificas "),Jr=o("code"),Mh=t("batched=True"),Rh=t(", la funci\xF3n recibe un diccionario con los campos del dataset, pero cada valor es ahora una "),Gr=o("em"),Uh=t("lista de valores"),Fh=t(" y no un valor individual. La salida de "),Qr=o("code"),Bh=t("Dataset.map()"),Yh=t(" deber\xEDa ser igual: un diccionario con los campos que queremos actualizar o a\xF1adir a nuestro dataset y una lista de valores. Por ejemplo, aqu\xED puedes ver otra forma de transformar todos los caracteres HTML usando "),Wr=o("code"),Vh=t("batched=True"),Jh=t(":"),zp=d(),f(ot.$$.fragment),Op=d(),de=o("p"),Gh=t("Si est\xE1s ejecutando este c\xF3digo en un cuaderno, ver\xE1s que este comando se ejecuta mucho m\xE1s r\xE1pido que el anterior. Y no es porque los caracteres HTML de las rese\xF1as ya se hubieran procesado; si vuelves a ejecutar la instrucci\xF3n de la secci\xF3n anterior (sin "),Xr=o("code"),Qh=t("batched=True"),Wh=t("), se tomar\xE1 el mismo tiempo de ejecuci\xF3n que antes. Esto es porque las "),Kr=o("em"),Xh=t("list comprehensions"),Kh=t(" suelen ser m\xE1s r\xE1pidas que ejecutar el mismo c\xF3digo en un ciclo "),Zr=o("code"),Zh=t("for"),ev=t(" y porque tambi\xE9n ganamos rendimiento al acceder a muchos elementos a la vez en vez de uno por uno."),Ap=d(),pe=o("p"),av=t("Usar "),el=o("code"),sv=t("Dataset.map()"),tv=t(" con "),al=o("code"),nv=t("batched=True"),ov=t(" ser\xE1 fundamental para desbloquear la velocidad de los tokenizadores \u201Cr\xE1pidos\u201D que nos vamos a encontrar en el "),fn=o("a"),rv=t("Cap\xEDtulo 6"),lv=t(", que pueden tokenizar velozmente grandes listas de textos. Por ejemplo, para tokenizar todas las rese\xF1as de medicamentos con un tokenizador r\xE1pido, podr\xEDamos usar una funci\xF3n como la siguiente:"),Np=d(),f(rt.$$.fragment),Ip=d(),ue=o("p"),iv=t("Como viste en el "),hn=o("a"),dv=t("Cap\xEDtulo 3"),pv=t(", podemos pasar uno o varios ejemplos al tokenizador, as\xED que podemos usar esta funci\xF3n con o sin "),sl=o("code"),uv=t("batched=True"),cv=t(". Aprovechemos esta oportunidad para comparar el desempe\xF1o de las distintas opciones. En un cuaderno, puedes medir el tiempo de ejecuci\xF3n de una instrucci\xF3n de una l\xEDnea a\xF1adiendo "),tl=o("code"),mv=t("%time"),fv=t(" antes de la l\xEDnea de c\xF3digo de tu inter\xE9s:"),Sp=d(),f(lt.$$.fragment),Hp=d(),Na=o("p"),hv=t("Tambi\xE9n puedes medir el tiempo de una celda completa a\xF1adiendo "),nl=o("code"),vv=t("%%time"),_v=t(" al inicio de la celda. En el hardware en el que lo ejecutamos, nos arroj\xF3 10.8s para esta instrucci\xF3n (es el n\xFAmero que aparece despu\xE9s de \u201CWall time\u201D)."),Lp=d(),f(Ia.$$.fragment),Mp=d(),vn=o("p"),gv=t("Estos son los resultados que obtuvimos con y sin la ejecuci\xF3n por lotes, con un tokenizador r\xE1pido y lento:"),Rp=d(),Sa=o("table"),ol=o("thead"),oa=o("tr"),_n=o("th"),$v=t("Opciones"),Ev=d(),gn=o("th"),jv=t("Tokenizador r\xE1pido"),bv=d(),$n=o("th"),qv=t("Tokenizador lento"),wv=d(),it=o("tbody"),ra=o("tr"),En=o("td"),rl=o("code"),xv=t("batched=True"),Dv=d(),jn=o("td"),yv=t("10.8s"),kv=d(),bn=o("td"),Tv=t("4min41s"),Cv=d(),la=o("tr"),qn=o("td"),ll=o("code"),Pv=t("batched=False"),zv=d(),wn=o("td"),Ov=t("59.2s"),Av=d(),xn=o("td"),Nv=t("5min3s"),Up=d(),Oe=o("p"),Iv=t("Esto significa que usar un tokenizador r\xE1pido con la opci\xF3n "),il=o("code"),Sv=t("batched=True"),Hv=t(" es 30 veces m\xE1s r\xE1pido que su contraparte lenta sin usar lotes. \xA1Realmente impresionante! Esta es la raz\xF3n principal por la que los tokenizadores r\xE1pidos son la opci\xF3n por defecto al usar "),dl=o("code"),Lv=t("AutoTokenizer"),Mv=t(" (y por qu\xE9 se denominan \u201Cr\xE1pidos\u201D). Estos logran tal rapidez gracias a que el c\xF3digo de los tokenizadores corre en Rust, que es un lenguaje que facilita la ejecuci\xF3n del c\xF3digo en paralelo."),Fp=d(),Dn=o("p"),Rv=t("La paralelizaci\xF3n tambi\xE9n es la raz\xF3n para el incremento de 6x en la velocidad del tokenizador al ejecutarse por lotes: No puedes ejecutar una \xFAnica operac\xF3n de tokenizaci\xF3n en paralelo, pero cuando quieres tokenizar muchos textos al mismo tiempo puedes dividir la ejecuci\xF3n en diferentes procesos, cada uno responsable de sus propios textos."),Bp=d(),$e=o("p"),pl=o("code"),Uv=t("Dataset.map()"),Fv=t(" tambi\xE9n tiene algunas capacidades de paralelizaci\xF3n. Dado que no funcionan con Rust, no van a hacer que un tokenizador lento alcance el rendimiento de uno r\xE1pido, pero a\xFAn as\xED pueden ser \xFAtiles (especialmente si est\xE1s usando un tokenizador que no tiene una versi\xF3n r\xE1pida). Para habilitar el multiprocesamiento, usa el argumento "),ul=o("code"),Bv=t("num_proc"),Yv=t(" y especifica el n\xFAmero de procesos para usar en "),cl=o("code"),Vv=t("Dataset.map()"),Jv=t(":"),Yp=d(),f(dt.$$.fragment),Vp=d(),yn=o("p"),Gv=t("Tambi\xE9n puedes medir el tiempo para determinar el n\xFAmero de procesos que vas a usar. En nuestro caso, usar 8 procesos produjo la mayor ganancia de velocidad. Aqu\xED est\xE1n algunos de los n\xFAmeros que obtuvimos con y sin multiprocesamiento:"),Jp=d(),Ha=o("table"),ml=o("thead"),ia=o("tr"),kn=o("th"),Qv=t("Opciones"),Wv=d(),Tn=o("th"),Xv=t("Tokenizador r\xE1pido"),Kv=d(),Cn=o("th"),Zv=t("Rokenizador lento"),e_=d(),Ee=o("tbody"),da=o("tr"),Pn=o("td"),fl=o("code"),a_=t("batched=True"),s_=d(),zn=o("td"),t_=t("10.8s"),n_=d(),On=o("td"),o_=t("4min41s"),r_=d(),pa=o("tr"),An=o("td"),hl=o("code"),l_=t("batched=False"),i_=d(),Nn=o("td"),d_=t("59.2s"),p_=d(),In=o("td"),u_=t("5min3s"),c_=d(),ua=o("tr"),La=o("td"),vl=o("code"),m_=t("batched=True"),f_=t(", "),_l=o("code"),h_=t("num_proc=8"),v_=d(),Sn=o("td"),__=t("6.52s"),g_=d(),Hn=o("td"),$_=t("41.3s"),E_=d(),ca=o("tr"),Ma=o("td"),gl=o("code"),j_=t("batched=False"),b_=t(", "),$l=o("code"),q_=t("num_proc=8"),w_=d(),Ln=o("td"),x_=t("9.49s"),D_=d(),Mn=o("td"),y_=t("45.2s"),Gp=d(),ce=o("p"),k_=t("Estos son resultados mucho m\xE1s razonables para el tokenizador lento, aunque el desempe\xF1o del r\xE1pido tambi\xE9n mejor\xF3 sustancialmente. Sin embargo, este no siempre ser\xE1 el caso: para valores de "),El=o("code"),T_=t("num_proc"),C_=t(" diferentes a 8, nuestras pruebas mostraron que era m\xE1s r\xE1pido usar "),jl=o("code"),P_=t("batched=true"),z_=t(" sin esta opci\xF3n. En general, no recomendamos usar el multiprocesamiento de Python para tokenizadores r\xE1pidos con "),bl=o("code"),O_=t("batched=True"),A_=t("."),Qp=d(),f(Ra.$$.fragment),Wp=d(),me=o("p"),N_=t("Que toda esta funcionalidad est\xE1 incluida en un m\xE9todo es algo impresionante en si mismo, \xA1pero hay m\xE1s!. Con "),ql=o("code"),I_=t("Dataset.map()"),S_=t(" y "),wl=o("code"),H_=t("batched=True"),L_=t(" puedes cambiar el n\xFAmero de elementos en tu dataset. Esto es s\xFAper \xFAtil en situaciones en las que quieres crear varias caracter\xEDsticas de entrenamiento de un ejemplo, algo que haremos en el preprocesamiento para varias de las tareas de PLN que abordaremos en el "),Rn=o("a"),M_=t("Cap\xEDtulo 7"),R_=t("."),Xp=d(),f(Ua.$$.fragment),Kp=d(),Ae=o("p"),U_=t("\xA1Veamos c\xF3mo funciona! En este ejemplo vamos a tokenizar nuestros ejemplos y limitarlos a una longitud m\xE1xima de 128, pero le pediremos al tokenizador que devuelva "),xl=o("em"),F_=t("todos"),B_=t(" los fragmentos de texto en vez de unicamente el primero. Esto se puede lograr con el argumento "),Dl=o("code"),Y_=t("return_overflowing_tokens=True"),V_=t(":"),Zp=d(),f(pt.$$.fragment),eu=d(),Fa=o("p"),J_=t("Prob\xE9moslo en un ejemplo puntual antes de usar "),yl=o("code"),G_=t("Dataset.map()"),Q_=t(" en todo el dataset:"),au=d(),f(ut.$$.fragment),su=d(),f(ct.$$.fragment),tu=d(),Un=o("p"),W_=t("El primer ejemplo en el conjunto de entrenamiento se convirti\xF3 en dos features porque fue tokenizado en un n\xFAmero superior de tokens al que especificamos: el primero de longitud 128 y el segundo de longitud 49. \xA1Vamos a aplicarlo a todo el dataset!"),nu=d(),f(mt.$$.fragment),ou=d(),f(ft.$$.fragment),ru=d(),Ba=o("p"),X_=t("\xBFPor qu\xE9 no funcion\xF3? El mensaje de error nos da una pista: hay un desajuste en las longitudes de una de las columnas, siendo una de logitud 1.463 y otra de longitud 1.000. Si has revisado la "),Ya=o("a"),K_=t("documentaci\xF3n de "),kl=o("code"),Z_=t("Dataset.map()"),e2=t(", te habr\xE1s dado cuenta que estamos mapeando el n\xFAmero de muestras que le pasamos a la funci\xF3n: en este caso los 1.000 ejemplos nos devuelven 1.463 features, arrojando un error."),lu=d(),se=o("p"),a2=t("El problema es que estamos tratando de mezclar dos datasets de tama\xF1os diferentes: las columnas de "),Tl=o("code"),s2=t("drug_dataset"),t2=t(" tendr\xE1n un cierto n\xFAmero de ejemplos (los 1.000 en el error), pero el "),Cl=o("code"),n2=t("tokenized_dataset"),o2=t(" que estamos construyendo tendr\xE1 m\xE1s (los 1.463 en el mensaje de error). Esto no funciona para un "),Pl=o("code"),r2=t("Dataset"),l2=t(", as\xED que tenemos que eliminar las columnas del anterior dataset o volverlas del mismo tama\xF1o del nuevo. Podemos hacer la primera operaci\xF3n con el argumento "),zl=o("code"),i2=t("remove_columns"),d2=t(":"),iu=d(),f(ht.$$.fragment),du=d(),Fn=o("p"),p2=t("Ahora funciona sin errores. Podemos revisar que nuestro dataset nuevo tiene m\xE1s elementos que el original al comparar sus longitudes:"),pu=d(),f(vt.$$.fragment),uu=d(),f(_t.$$.fragment),cu=d(),Ne=o("p"),u2=t("Tambi\xE9n mencionamos que podemos trabajar con el problema de longitudes que no coinciden al convertir las columnas viejas en el mismo tama\xF1o de las nuevas. Para eso, vamos a necesitar el campo "),Ol=o("code"),c2=t("overflow_to_sample_mapping"),m2=t(" que devuelve el tokenizer cuando definimos "),Al=o("code"),f2=t("return_overflowing_tokens=True"),h2=t(". Esto devuelve un mapeo del \xEDndice de un nuevo feature al \xEDndice de la muestra de la que se origin\xF3. Usando lo anterior, podemos asociar cada llave presente en el dataset original con una lista de valores del tama\xF1o correcto al repetir los valores de cada ejemplo tantas veces como genere nuevos features:"),mu=d(),f(gt.$$.fragment),fu=d(),Va=o("p"),v2=t("De esta forma, podemos ver que funciona con "),Nl=o("code"),_2=t("Dataset.map()"),g2=t(" sin necesidad de eliminar las columnas viejas."),hu=d(),f($t.$$.fragment),vu=d(),f(Et.$$.fragment),_u=d(),Bn=o("p"),$2=t("Como resultado, tenemos el mismo n\xFAmero de features de entrenamiento que antes, pero conservando todos los campos anteriores. Quiz\xE1s prefieras usar esta opci\xF3n si necesitas conservarlos para algunas tareas de post-procesamiento despu\xE9s de aplicar tu modelo."),gu=d(),Ja=o("p"),E2=t("Ya has visto como usar \u{1F917} Datasets para preprocesar un dataset de varias formas. Si bien las funciones de procesamiento de \u{1F917} Datasets van a suplir la mayor parte de tus necesidades de entrenamiento de modelos, hay ocasiones en las que puedes necesitar Pandas para tener acceso a herramientas m\xE1s poderosas, como "),Il=o("code"),j2=t("DataFrame.groupby()"),b2=t(" o alg\xFAn API de alto nivel para visualizaci\xF3n. Afortunadamente, \u{1F917} Datasets est\xE1 dise\xF1ado para ser interoperable con librer\xEDas como Pandas, NumPy, PyTorch, TensoFlow y JAX. Veamos c\xF3mo funciona."),$u=d(),ma=o("h2"),Ga=o("a"),Sl=o("span"),f(jt.$$.fragment),q2=d(),fa=o("span"),w2=t("De "),Hl=o("code"),x2=t("Dataset"),D2=t("s a "),Ll=o("code"),y2=t("DataFrame"),k2=t("s y viceversa"),Eu=d(),f(bt.$$.fragment),ju=d(),te=o("p"),T2=t("Para habilitar la conversi\xF3n entre varias librer\xEDas de terceros, \u{1F917} Datasets provee la funci\xF3n "),Ml=o("code"),C2=t("Dataset.set_format()"),P2=t(". Esta funci\xF3n s\xF3lo cambia el "),Rl=o("em"),z2=t("formato de salida"),O2=t(" del dataset, de tal manera que puedas cambiar a otro formato sin cambiar el "),Ul=o("em"),A2=t("formato de datos subyacente"),N2=t(", que es Apache Arrow. Este cambio de formato se hace "),Fl=o("em"),I2=t("in place"),S2=t(". Para verlo en acci\xF3n, convirtamos el dataset a Pandas:"),bu=d(),f(qt.$$.fragment),qu=d(),Qa=o("p"),H2=t("Ahora, cuando accedemos a los elementos del dataset obtenemos un "),Bl=o("code"),L2=t("pandas.DataFrame"),M2=t(" en vez de un diccionario:"),wu=d(),f(wt.$$.fragment),xu=d(),Ie=o("table"),Yl=o("thead"),I=o("tr"),Du=o("th"),R2=d(),Vl=o("th"),U2=t("patient_id"),F2=d(),Jl=o("th"),B2=t("drugName"),Y2=d(),Gl=o("th"),V2=t("condition"),J2=d(),Ql=o("th"),G2=t("review"),Q2=d(),Wl=o("th"),W2=t("rating"),X2=d(),Xl=o("th"),K2=t("date"),Z2=d(),Kl=o("th"),eg=t("usefulCount"),ag=d(),Zl=o("th"),sg=t("review_length"),tg=d(),ha=o("tbody"),S=o("tr"),ei=o("th"),ng=t("0"),og=d(),ai=o("td"),rg=t("95260"),lg=d(),si=o("td"),ig=t("Guanfacine"),dg=d(),ti=o("td"),pg=t("adhd"),ug=d(),ni=o("td"),cg=t('"My son is halfway through his fourth week of Intuniv..."'),mg=d(),oi=o("td"),fg=t("8.0"),hg=d(),ri=o("td"),vg=t("April 27, 2010"),_g=d(),li=o("td"),gg=t("192"),$g=d(),ii=o("td"),Eg=t("141"),jg=d(),H=o("tr"),di=o("th"),bg=t("1"),qg=d(),pi=o("td"),wg=t("92703"),xg=d(),ui=o("td"),Dg=t("Lybrel"),yg=d(),ci=o("td"),kg=t("birth control"),Tg=d(),mi=o("td"),Cg=t('"I used to take another oral contraceptive, which had 21 pill cycle, and was very happy- very light periods, max 5 days, no other side effects..."'),Pg=d(),fi=o("td"),zg=t("5.0"),Og=d(),hi=o("td"),Ag=t("December 14, 2009"),Ng=d(),vi=o("td"),Ig=t("17"),Sg=d(),_i=o("td"),Hg=t("134"),Lg=d(),L=o("tr"),gi=o("th"),Mg=t("2"),Rg=d(),$i=o("td"),Ug=t("138000"),Fg=d(),Ei=o("td"),Bg=t("Ortho Evra"),Yg=d(),ji=o("td"),Vg=t("birth control"),Jg=d(),bi=o("td"),Gg=t('"This is my first time using any form of birth control..."'),Qg=d(),qi=o("td"),Wg=t("8.0"),Xg=d(),wi=o("td"),Kg=t("November 3, 2015"),Zg=d(),xi=o("td"),e1=t("10"),a1=d(),Di=o("td"),s1=t("89"),yu=d(),Se=o("p"),t1=t("Creemos un "),yi=o("code"),n1=t("pandas.DataFrame"),o1=t(" para el conjunto de entrenamiento entero al seleccionar los elementos de "),ki=o("code"),r1=t('drug_dataset["train"]'),l1=t(":"),ku=d(),f(xt.$$.fragment),Tu=d(),f(Wa.$$.fragment),Cu=d(),Xa=o("p"),i1=t("De aqu\xED en adelante podemos usar toda la funcionalidad de pandas cuando queramos. Por ejemplo, podemos hacer un encadenamiento sofisticado para calcular la distribuci\xF3n de clase entre las entradas de "),Ti=o("code"),d1=t("condition"),p1=t(":"),Pu=d(),f(Dt.$$.fragment),zu=d(),He=o("table"),Ci=o("thead"),Le=o("tr"),Ou=o("th"),u1=d(),Pi=o("th"),c1=t("condition"),m1=d(),zi=o("th"),f1=t("frequency"),h1=d(),oe=o("tbody"),va=o("tr"),Oi=o("th"),v1=t("0"),_1=d(),Ai=o("td"),g1=t("birth control"),$1=d(),Ni=o("td"),E1=t("27655"),j1=d(),_a=o("tr"),Ii=o("th"),b1=t("1"),q1=d(),Si=o("td"),w1=t("depression"),x1=d(),Hi=o("td"),D1=t("8023"),y1=d(),ga=o("tr"),Li=o("th"),k1=t("2"),T1=d(),Mi=o("td"),C1=t("acne"),P1=d(),Ri=o("td"),z1=t("5209"),O1=d(),$a=o("tr"),Ui=o("th"),A1=t("3"),N1=d(),Fi=o("td"),I1=t("anxiety"),S1=d(),Bi=o("td"),H1=t("4991"),L1=d(),Ea=o("tr"),Yi=o("th"),M1=t("4"),R1=d(),Vi=o("td"),U1=t("pain"),F1=d(),Ji=o("td"),B1=t("4744"),Au=d(),Me=o("p"),Y1=t("Y una vez hemos concluido el an\xE1lisis con Pandas, tenemos la posibilidad de crear un nuevo objeto "),Gi=o("code"),V1=t("Dataset"),J1=t(" usando la funci\xF3n "),Qi=o("code"),G1=t("Dataset.from_pandas()"),Q1=t(" de la siguiente manera:"),Nu=d(),f(yt.$$.fragment),Iu=d(),f(kt.$$.fragment),Su=d(),f(Ka.$$.fragment),Hu=d(),fe=o("p"),W1=t("Con esto terminamos nuestro tour de las m\xFAltiples t\xE9cnicas de preprocesamiento disponibles en \u{1F917} Datasets. Para concluir, creemos un set de validaci\xF3n para preparar el conjunto de datos y entrenar el clasificador. Antes de hacerlo, vamos a reiniciar el formato de salida de "),Wi=o("code"),X1=t("drug_dataset"),K1=t(" de "),Xi=o("code"),Z1=t('"pandas"'),e$=t(" a "),Ki=o("code"),a$=t('"arrow"'),s$=t(":"),Lu=d(),f(Tt.$$.fragment),Mu=d(),ja=o("h2"),Za=o("a"),Zi=o("span"),f(Ct.$$.fragment),t$=d(),ed=o("span"),n$=t("Creando un conjunto de validaci\xF3n"),Ru=d(),Yn=o("p"),o$=t("Si bien tenemos un conjunto de prueba que podr\xEDamos usar para la evaluaci\xF3n, es una buena pr\xE1ctica dejar el conjunto de prueba intacto y crear un conjunto de validaci\xF3n aparte durante el desarrollo. Una vez est\xE9s satisfecho con el desempe\xF1o de tus modelos en el conjunto de validaci\xF3n, puedes hacer un \xFAltimo chequeo con el conjunto de prueba. Este proceso ayuda a reducir el riesgo de sobreajustar al conjunto de prueba y desplegar un modelo que falle en datos reales."),Uu=d(),Q=o("p"),r$=t("\u{1F917} Datasets provee la funci\xF3n "),ad=o("code"),l$=t("Dataset.train_test_split()"),i$=t(" que est\xE1 basada en la famosa funcionalidad de "),sd=o("code"),d$=t("scikit-learn"),p$=t(". Us\xE9mosla para separar nuestro conjunto de entrenamiento en dos partes "),td=o("code"),u$=t("train"),c$=t(" y "),nd=o("code"),m$=t("validation"),f$=t(" (definiendo el argumento "),od=o("code"),h$=t("seed"),v$=t(" por motivos de reproducibilidad):"),Fu=d(),f(Pt.$$.fragment),Bu=d(),f(zt.$$.fragment),Yu=d(),es=o("p"),_$=t("S\xFAper, ya preparamos un dataset que est\xE1 listo para entrenar modelos. En la "),Vn=o("a"),g$=t("secci\xF3n 5"),$$=t(" veremos c\xF3mo subir datasets al Hub de Hugging Face, pero por ahora terminemos el an\xE1lisis estudiando algunas formas de guardarlos en tu m\xE1quina local."),Vu=d(),ba=o("h2"),as=o("a"),rd=o("span"),f(Ot.$$.fragment),E$=d(),ld=o("span"),j$=t("Saving a dataset"),Ju=d(),f(At.$$.fragment),Gu=d(),Jn=o("p"),b$=t("A pesar de que \u{1F917} Datasets va a guardar en cach\xE9 todo dataset que descargues, as\xED como las operaciones que se ejecutan en \xE9l, hay ocasiones en las que querr\xE1s guardar un dataset en memoria (e.g., en caso que el cach\xE9 se elimine). Como se muestra en la siguiente tabla, \u{1F917} Datasets tiene 3 funciones para guardar tu dataset en distintos formatos:"),Qu=d(),ss=o("table"),id=o("thead"),Nt=o("tr"),Gn=o("th"),q$=t("Formato"),w$=d(),Qn=o("th"),x$=t("Funci\xF3n"),D$=d(),qa=o("tbody"),It=o("tr"),Wn=o("td"),y$=t("Arrow"),k$=d(),Xn=o("td"),dd=o("code"),T$=t("Dataset.save_to_disk()"),C$=d(),St=o("tr"),Kn=o("td"),P$=t("CSV"),z$=d(),Zn=o("td"),pd=o("code"),O$=t("Dataset.to_csv()"),A$=d(),Ht=o("tr"),eo=o("td"),N$=t("JSON"),I$=d(),ao=o("td"),ud=o("code"),S$=t("Dataset.to_json()"),Wu=d(),so=o("p"),H$=t("Por ejemplo, guardemos el dataset limpio en formato Arrow:"),Xu=d(),f(Lt.$$.fragment),Ku=d(),to=o("p"),L$=t("Esto crear\xE1 una carpeta con la siguiente estructura:"),Zu=d(),f(Mt.$$.fragment),ec=d(),he=o("p"),M$=t("en las que podemos ver que cada parte del dataset est\xE1 asociada con una tabla "),cd=o("em"),R$=t("dataset.arrow"),U$=t(" y algunos metadatos en "),md=o("em"),F$=t("dataset_info.json"),B$=t(" y "),fd=o("em"),Y$=t("state.json"),V$=t(". Puedes pensar en el formato Arrow como una tabla sofisticada de columnas y filas que est\xE1 optimizada para construir aplicaciones de alto rendimiento que procesan y transportan datasets grandes."),ac=d(),ts=o("p"),J$=t("Una vez el dataset est\xE1 guardado, podemos cargarlo usando la funci\xF3n "),hd=o("code"),G$=t("load_from_disk()"),Q$=t(" as\xED:"),sc=d(),f(Rt.$$.fragment),tc=d(),f(Ut.$$.fragment),nc=d(),ns=o("p"),W$=t("Para los formatos CSV y JSON, tenemos que guardar cada parte en un archivo separado. Una forma de hacerlo es iterando sobre las llaves y valores del objeto "),vd=o("code"),X$=t("DatasetDict"),K$=t(":"),oc=d(),f(Ft.$$.fragment),rc=d(),os=o("p"),Z$=t("Esto guarda cada parte en formato "),Bt=o("a"),eE=t("JSON Lines"),aE=t(", donde cada fila del dataset est\xE1 almacenada como una \xFAnica l\xEDnea de JSON. As\xED se ve el primer ejemplo:"),lc=d(),f(Yt.$$.fragment),ic=d(),f(Vt.$$.fragment),dc=d(),rs=o("p"),sE=t("Podemos usar las t\xE9cnicas de la "),no=o("a"),tE=t("secci\xF3n 2"),nE=t(" para cargar los archivos JSON de la siguiente manera:"),pc=d(),f(Jt.$$.fragment),uc=d(),oo=o("p"),oE=t("Esto es todo lo que vamos a ver en nuestra revisi\xF3n del manejo de datos con \u{1F917} Datasets. Ahora que tenemos un dataset limpio para entrenar un modelo, aqu\xED van algunas ideas que podr\xEDas intentar:"),cc=d(),ls=o("ol"),Gt=o("li"),rE=t("Usa las t\xE9cnicas del "),ro=o("a"),lE=t("Cap\xEDtulo 3"),iE=t(" para entrenar un clasificador que pueda predecir la condici\xF3n del paciente con base en las rese\xF1as de los medicamentos."),dE=d(),wa=o("li"),pE=t("Usa el pipeline de "),_d=o("code"),uE=t("summarization"),cE=t(" del "),lo=o("a"),mE=t("Cap\xEDtulo 1"),fE=t(" para generar res\xFAmenes de las rese\xF1as."),mc=d(),io=o("p"),hE=t("En la siguiente secci\xF3n veremos c\xF3mo \u{1F917} Datasets te puede ayudar a trabajar con datasets enormes \xA1sin explotar tu computador!"),this.h()},l(e){const i=c3('[data-svelte="svelte-1phssyn"]',document.head);c=r(i,"META",{name:!0,content:!0}),i.forEach(s),T=p(e),j=r(e,"H1",{class:!0});var Qt=l(j);x=r(Qt,"A",{id:!0,class:!0,href:!0});var gd=l(x);y=r(gd,"SPAN",{});var $d=l(y);h(b.$$.fragment,$d),$d.forEach(s),gd.forEach(s),D=p(Qt),C=r(Qt,"SPAN",{});var Ed=l(C);q=n(Ed,"Es momento de subdividir"),Ed.forEach(s),Qt.forEach(s),w=p(e),h(z.$$.fragment,e),k=p(e),P=r(e,"P",{});var jd=l(P);J=n(jd,"La mayor parte del tiempo tus datos no estar\xE1n perfectamente listos para entrenar modelos. En esta secci\xF3n vamos a explorar distintas funciones que tiene \u{1F917} Datasets para limpiar tus conjuntos de datos."),jd.forEach(s),N=p(e),h(O.$$.fragment,e),ge=p(e),R=r(e,"H2",{class:!0});var Wt=l(R);W=r(Wt,"A",{id:!0,class:!0,href:!0});var bd=l(W);re=r(bd,"SPAN",{});var qd=l(re);h(ne.$$.fragment,qd),qd.forEach(s),bd.forEach(s),$s=p(Wt),We=r(Wt,"SPAN",{});var $E=l(We);Xe=n($E,"Subdivdiendo nuestros datos"),$E.forEach(s),Wt.forEach(s),xa=p(e),U=r(e,"P",{});var Re=l(U);Ke=n(Re,"De manera similar a Pandas, \u{1F917} Datasets incluye varias funciones para manipular el contenido de los objetos "),Ze=r(Re,"CODE",{});var EE=l(Ze);Es=n(EE,"Dataset"),EE.forEach(s),ea=n(Re," y "),A=r(Re,"CODE",{});var jE=l(A);Zt=n(jE,"DatasetDict"),jE.forEach(s),en=n(Re,". Ya vimos el m\xE9todo "),Da=r(Re,"CODE",{});var bE=l(Da);an=n(bE,"Dataset.map()"),bE.forEach(s),sn=n(Re," en el "),aa=r(Re,"A",{href:!0});var qE=l(aa);tn=n(qE,"Cap\xEDtulo 3"),qE.forEach(s),nn=n(Re," y en esta secci\xF3n vamos a explorar otras funciones que tenemos a nuestra disposici\xF3n."),Re.forEach(s),js=p(e),je=r(e,"P",{});var po=l(je);Xc=n(po,"Para este ejemplo, vamos a usar el "),bs=r(po,"A",{href:!0,rel:!0});var wE=l(bs);Kc=n(wE,"Dataset de rese\xF1as de medicamentos"),wE.forEach(s),Zc=n(po," alojado en el "),qs=r(po,"A",{href:!0,rel:!0});var xE=l(qs);em=n(xE,"Repositorio de Machine Learning de UC Irvine"),xE.forEach(s),am=n(po,", que contiene la evaluaci\xF3n de varios medicamentos por parte de pacientes, junto con la condici\xF3n por la que los estaban tratando y una calificaci\xF3n en una escala de 10 estrellas sobre su satisfacci\xF3n."),po.forEach(s),wd=p(e),be=r(e,"P",{});var uo=l(be);sm=n(uo,"Primero, tenemos que descargar y extraer los datos, que se puede hacer con los comandos "),Vo=r(uo,"CODE",{});var DE=l(Vo);tm=n(DE,"wget"),DE.forEach(s),nm=n(uo," y "),Jo=r(uo,"CODE",{});var yE=l(Jo);om=n(yE,"unzip"),yE.forEach(s),rm=n(uo,":"),uo.forEach(s),xd=p(e),h(ws.$$.fragment,e),Dd=p(e),le=r(e,"P",{});var is=l(le);lm=n(is,"Dado que TSV es una variaci\xF3n de CSV en la que se usan tabulaciones en vez de comas como separadores, podemos cargar estos archivos usando el script de carga "),Go=r(is,"CODE",{});var kE=l(Go);im=n(kE,"csv"),kE.forEach(s),dm=n(is," y especificando el argumento "),Qo=r(is,"CODE",{});var TE=l(Qo);pm=n(TE,"delimiter"),TE.forEach(s),um=n(is," en la funci\xF3n "),Wo=r(is,"CODE",{});var CE=l(Wo);cm=n(CE,"load_dataset"),CE.forEach(s),mm=n(is," de la siguiente manera:"),is.forEach(s),yd=p(e),h(xs.$$.fragment,e),kd=p(e),qe=r(e,"P",{});var co=l(qe);fm=n(co,"Una buena pr\xE1ctica al hacer cualquier tipo de an\xE1lisis de datos es tomar una muestra aleatoria del dataset para tener una vista r\xE1pida del tipo de datos con los que est\xE1s trabajando. En \u{1F917} Datasets, podemos crear una muestra aleatoria al encadenar las funciones "),Xo=r(co,"CODE",{});var PE=l(Xo);hm=n(PE,"Dataset.shuffle()"),PE.forEach(s),vm=n(co," y "),Ko=r(co,"CODE",{});var zE=l(Ko);_m=n(zE,"Dataset.select()"),zE.forEach(s),gm=n(co,":"),co.forEach(s),Td=p(e),h(Ds.$$.fragment,e),Cd=p(e),h(ys.$$.fragment,e),Pd=p(e),ie=r(e,"P",{});var ds=l(ie);$m=n(ds,"Puedes ver que hemos fijado la semilla en "),Zo=r(ds,"CODE",{});var OE=l(Zo);Em=n(OE,"Dataset.shuffle()"),OE.forEach(s),jm=n(ds," por motivos de reproducibilidad. "),er=r(ds,"CODE",{});var AE=l(er);bm=n(AE,"Dataset.select()"),AE.forEach(s),qm=n(ds," espera un interable de \xEDndices, as\xED que incluimos "),ar=r(ds,"CODE",{});var NE=l(ar);wm=n(NE,"range(1000)"),NE.forEach(s),xm=n(ds," para tomar los primeros 1.000 ejemplos del conjunto de datos aleatorizado. Ya podemos ver algunos detalles para esta muestra:"),ds.forEach(s),zd=p(e),we=r(e,"UL",{});var mo=l(we);ks=r(mo,"LI",{});var hc=l(ks);Dm=n(hc,"La columna "),sr=r(hc,"CODE",{});var IE=l(sr);ym=n(IE,"Unnamed: 0"),IE.forEach(s),km=n(hc," se ve sospechosamente como un ID anonimizado para cada paciente."),hc.forEach(s),Tm=p(mo),Ts=r(mo,"LI",{});var vc=l(Ts);Cm=n(vc,"La columna "),tr=r(vc,"CODE",{});var SE=l(tr);Pm=n(SE,"condition"),SE.forEach(s),zm=n(vc," incluye una mezcla de niveles en may\xFAscula y min\xFAscula."),vc.forEach(s),Om=p(mo),sa=r(mo,"LI",{});var fo=l(sa);Am=n(fo,"Las rese\xF1as tienen longitud variable y contienen una mezcla de separadores de l\xEDnea de Python ("),nr=r(fo,"CODE",{});var HE=l(nr);Nm=n(HE,"\\r\\n"),HE.forEach(s),Im=n(fo,"), as\xED como caracteres de HTML como "),or=r(fo,"CODE",{});var LE=l(or);Sm=n(LE,"&\\#039;"),LE.forEach(s),Hm=n(fo,"."),fo.forEach(s),mo.forEach(s),Od=p(e),xe=r(e,"P",{});var ho=l(xe);Lm=n(ho,"Veamos c\xF3mo podemos usar \u{1F917} Datasets para lidiar con cada uno de estos asuntos. Para probar la hip\xF3tesis de que la columna "),rr=r(ho,"CODE",{});var ME=l(rr);Mm=n(ME,"Unnamed: 0"),ME.forEach(s),Rm=n(ho," es un ID de los pacientes, podemos usar la funci\xF3n "),lr=r(ho,"CODE",{});var RE=l(lr);Um=n(RE,"Dataset.unique()"),RE.forEach(s),Fm=n(ho," para verificar que el n\xFAmero de los ID corresponda con el n\xFAmero de filas de cada conjunto:"),ho.forEach(s),Ad=p(e),h(Cs.$$.fragment,e),Nd=p(e),De=r(e,"P",{});var vo=l(De);Bm=n(vo,"Esto parece confirmar nuestra hip\xF3tesis, as\xED que limpiemos el dataset un poco al cambiar el nombre de la columna "),ir=r(vo,"CODE",{});var UE=l(ir);Ym=n(UE,"Unnamed: 0"),UE.forEach(s),Vm=n(vo," a algo m\xE1s legible. Podemos usar la funci\xF3n "),dr=r(vo,"CODE",{});var FE=l(dr);Jm=n(FE,"DatasetDict.rename_column()"),FE.forEach(s),Gm=n(vo," para renombrar la columna en ambos conjuntos en una sola operaci\xF3n:"),vo.forEach(s),Id=p(e),h(Ps.$$.fragment,e),Sd=p(e),h(zs.$$.fragment,e),Hd=p(e),h(ya.$$.fragment,e),Ld=p(e),X=r(e,"P",{});var Ue=l(X);Qm=n(Ue,"Ahora normalicemos todas las etiquetas de "),pr=r(Ue,"CODE",{});var BE=l(pr);Wm=n(BE,"condition"),BE.forEach(s),Xm=n(Ue," usando "),ur=r(Ue,"CODE",{});var YE=l(ur);Km=n(YE,"Dataset.map()"),YE.forEach(s),Zm=n(Ue,". Tal como lo hicimos con la tokenizaci\xF3n en el "),on=r(Ue,"A",{href:!0});var VE=l(on);ef=n(VE,"Cap\xEDtulo 3"),VE.forEach(s),af=n(Ue,", podemos definir una funci\xF3n simple que pueda ser aplicada en todas las filas de cada conjunto en el "),cr=r(Ue,"CODE",{});var JE=l(cr);sf=n(JE,"drug_dataset"),JE.forEach(s),tf=n(Ue,":"),Ue.forEach(s),Md=p(e),h(Os.$$.fragment,e),Rd=p(e),h(As.$$.fragment,e),Ud=p(e),K=r(e,"P",{});var Fe=l(K);nf=n(Fe,"\xA1Tenemos un problema en nuestra funci\xF3n de mapeo! Del error podemos inferir que algunas de las entradas de la columna "),mr=r(Fe,"CODE",{});var GE=l(mr);of=n(GE,"condici\xF3n"),GE.forEach(s),rf=n(Fe," son "),fr=r(Fe,"CODE",{});var QE=l(fr);lf=n(QE,"None"),QE.forEach(s),df=n(Fe,", que no puede transformarse en min\xFAscula al no ser un string. Filtremos estas filas usando "),hr=r(Fe,"CODE",{});var WE=l(hr);pf=n(WE,"Dataset.filter()"),WE.forEach(s),uf=n(Fe,", que funciona de una forma similar "),vr=r(Fe,"CODE",{});var XE=l(vr);cf=n(XE,"Dataset.map()"),XE.forEach(s),mf=n(Fe," y recibe como argumento una funci\xF3n que toma un ejemplo particular del dataset. En vez de escribir una funci\xF3n expl\xEDcita como:"),Fe.forEach(s),Fd=p(e),h(Ns.$$.fragment,e),Bd=p(e),ye=r(e,"P",{});var _o=l(ye);ff=n(_o,"y luego ejecutar "),_r=r(_o,"CODE",{});var KE=l(_r);hf=n(KE,"drug_dataset.filter(filter_nones)"),KE.forEach(s),vf=n(_o,", podemos hacerlo en una l\xEDnea usando una "),gr=r(_o,"EM",{});var ZE=l(gr);_f=n(ZE,"funci\xF3n lambda"),ZE.forEach(s),gf=n(_o,". En Python, las funciones lambda son funciones peque\xF1as que puedes definir sin nombrarlas expl\xEDcitamente. Estas toman la forma general:"),_o.forEach(s),Yd=p(e),h(Is.$$.fragment,e),Vd=p(e),Z=r(e,"P",{});var Be=l(Z);$f=n(Be,"en la que "),$r=r(Be,"CODE",{});var ej=l($r);Ef=n(ej,"lambda"),ej.forEach(s),jf=n(Be," es una de las "),Ss=r(Be,"A",{href:!0,rel:!0});var aj=l(Ss);bf=n(aj,"palabras especiales"),aj.forEach(s),qf=n(Be," de Python, "),Er=r(Be,"CODE",{});var sj=l(Er);wf=n(sj,"<arguments>"),sj.forEach(s),xf=n(Be," es una lista o conjunto de valores separados con coma que definen los argumentos de la funci\xF3n y "),jr=r(Be,"CODE",{});var tj=l(jr);Df=n(tj,"<expression>"),tj.forEach(s),yf=n(Be," representa las operaciones que quieres ejecutar. Por ejemplo, podemos definir una funci\xF3n lambda simple que eleve un n\xFAmero al cuadrado de la siguiente manera:"),Be.forEach(s),Jd=p(e),h(Hs.$$.fragment,e),Gd=p(e),ke=r(e,"P",{});var go=l(ke);kf=n(go,"Para aplicar esta funci\xF3n a un "),br=r(go,"EM",{});var nj=l(br);Tf=n(nj,"input"),nj.forEach(s),Cf=n(go,", tenemos que envolverla a ella y al "),qr=r(go,"EM",{});var oj=l(qr);Pf=n(oj,"input"),oj.forEach(s),zf=n(go," en par\xE9ntesis:"),go.forEach(s),Qd=p(e),h(Ls.$$.fragment,e),Wd=p(e),h(Ms.$$.fragment,e),Xd=p(e),rn=r(e,"P",{});var rj=l(rn);Of=n(rj,"De manera similar, podemos definir funciones lambda con m\xFAltiples argumentos separ\xE1ndolos con comas. Por ejemplo, podemos calcular el \xE1rea de un tri\xE1ngulo as\xED:"),rj.forEach(s),Kd=p(e),h(Rs.$$.fragment,e),Zd=p(e),h(Us.$$.fragment,e),ep=p(e),Te=r(e,"P",{});var $o=l(Te);Af=n($o,"Las funciones lambda son \xFAtiles cuando quieres definir funciones peque\xF1as de un \xFAnico uso (para m\xE1s informaci\xF3n sobre ellas, te recomendamos leer este excelente "),Fs=r($o,"A",{href:!0,rel:!0});var lj=l(Fs);Nf=n(lj,"tutorial de Real Python"),lj.forEach(s),If=n($o," escrito por Andre Burgaud). En el contexto de \u{1F917} Datasets, podemos usar las funciones lambda para definir operaciones simples de mapeo y filtrado, as\xED que usemos este truco para eliminar las entradas "),wr=r($o,"CODE",{});var ij=l(wr);Sf=n(ij,"None"),ij.forEach(s),Hf=n($o," de nuestro dataset:"),$o.forEach(s),ap=p(e),h(Bs.$$.fragment,e),sp=p(e),Ce=r(e,"P",{});var Eo=l(Ce);Lf=n(Eo,"Ahora que eliminamos los "),xr=r(Eo,"CODE",{});var dj=l(xr);Mf=n(dj,"None"),dj.forEach(s),Rf=n(Eo,", podemos normalizar nuestra columna "),Dr=r(Eo,"CODE",{});var pj=l(Dr);Uf=n(pj,"condition"),pj.forEach(s),Ff=n(Eo,":"),Eo.forEach(s),tp=p(e),h(Ys.$$.fragment,e),np=p(e),h(Vs.$$.fragment,e),op=p(e),ln=r(e,"P",{});var uj=l(ln);Bf=n(uj,"\xA1Funcion\xF3! Como ya limpiamos las etiquetas, veamos c\xF3mo podemos limpiar las rese\xF1as."),uj.forEach(s),rp=p(e),ta=r(e,"H2",{class:!0});var _c=l(ta);ka=r(_c,"A",{id:!0,class:!0,href:!0});var cj=l(ka);yr=r(cj,"SPAN",{});var mj=l(yr);h(Js.$$.fragment,mj),mj.forEach(s),cj.forEach(s),Yf=p(_c),kr=r(_c,"SPAN",{});var fj=l(kr);Vf=n(fj,"Creando nuevas columnas"),fj.forEach(s),_c.forEach(s),lp=p(e),dn=r(e,"P",{});var hj=l(dn);Jf=n(hj,"Cuando est\xE1s lidiando con rese\xF1as de clientes, es una buena pr\xE1ctica revisar el n\xFAmero de palabras de cada rese\xF1a. Una rese\xF1a puede ser una \xFAnica palabra como \u201C\xA1Genial!\u201D o un ensayo completo con miles de palabras y, seg\xFAn el caso de uso, tendr\xE1s que abordar estos extremos de forma diferente. Para calcular el n\xFAmero de palabras en cada rese\xF1a, usaremos una heur\xEDstica aproximada basada en dividir cada texto por los espacios en blanco."),hj.forEach(s),ip=p(e),pn=r(e,"P",{});var vj=l(pn);Gf=n(vj,"Definamos una funci\xF3n simple que cuente el n\xFAmero de palabras en cada rese\xF1a:"),vj.forEach(s),dp=p(e),h(Gs.$$.fragment,e),pp=p(e),G=r(e,"P",{});var ve=l(G);Qf=n(ve,"Contrario a la funci\xF3n "),Tr=r(ve,"CODE",{});var _j=l(Tr);Wf=n(_j,"lowercase_condition()"),_j.forEach(s),Xf=n(ve,", "),Cr=r(ve,"CODE",{});var gj=l(Cr);Kf=n(gj,"compute_review_length()"),gj.forEach(s),Zf=n(ve," devuelve un diccionario cuya llave no corresponde a uno de los nombres de las columnas en el conjunto de datos. En este caso, cuando se pasa "),Pr=r(ve,"CODE",{});var $j=l(Pr);eh=n($j,"compute_review_length()"),$j.forEach(s),ah=n(ve," a "),zr=r(ve,"CODE",{});var Ej=l(zr);sh=n(Ej,"Dataset.map()"),Ej.forEach(s),th=n(ve,",  la funci\xF3n se aplicar\xE1 a todas las filas en el dataset para crear una nueva columna "),Or=r(ve,"CODE",{});var jj=l(Or);nh=n(jj,"review_length()"),jj.forEach(s),oh=n(ve,":"),ve.forEach(s),up=p(e),h(Qs.$$.fragment,e),cp=p(e),h(Ws.$$.fragment,e),mp=p(e),Pe=r(e,"P",{});var jo=l(Pe);rh=n(jo,"Tal como lo esper\xE1bamos, podemos ver que se a\xF1adi\xF3 la columna "),Ar=r(jo,"CODE",{});var bj=l(Ar);lh=n(bj,"review_length"),bj.forEach(s),ih=n(jo," al conjunto de entrenamiento. Podemos ordenar esta columna nueva con "),Nr=r(jo,"CODE",{});var qj=l(Nr);dh=n(qj,"Dataset.sort()"),qj.forEach(s),ph=n(jo," para ver c\xF3mo son los valores extremos:"),jo.forEach(s),fp=p(e),h(Xs.$$.fragment,e),hp=p(e),h(Ks.$$.fragment,e),vp=p(e),un=r(e,"P",{});var wj=l(un);uh=n(wj,"Como lo discutimos anteriormente, algunas rese\xF1as incluyen una sola palabra, que si bien puede ser \xFAtil para el an\xE1lisis de sentimientos, no ser\xEDa tan informativa si quisieramos predecir la condici\xF3n."),wj.forEach(s),_p=p(e),h(Ta.$$.fragment,e),gp=p(e),ze=r(e,"P",{});var bo=l(ze);ch=n(bo,"Usemos la funci\xF3n "),Ir=r(bo,"CODE",{});var xj=l(Ir);mh=n(xj,"Dataset.filter()"),xj.forEach(s),fh=n(bo," para quitar las rese\xF1as que contienen menos de 30 palabras. Similar a lo que hicimos con la columna "),Sr=r(bo,"CODE",{});var Dj=l(Sr);hh=n(Dj,"condition"),Dj.forEach(s),vh=n(bo,", podemos filtrar las rese\xF1as cortas al incluir una condici\xF3n de que su longitud est\xE9 por encima de este umbral:"),bo.forEach(s),$p=p(e),h(Zs.$$.fragment,e),Ep=p(e),h(et.$$.fragment,e),jp=p(e),cn=r(e,"P",{});var yj=l(cn);_h=n(yj,"Como puedes ver, esto ha eliminado alrededor del 15% de las rese\xF1as de nuestros conjuntos originales de entrenamiento y prueba."),yj.forEach(s),bp=p(e),h(Ca.$$.fragment,e),qp=p(e),Pa=r(e,"P",{});var gc=l(Pa);gh=n(gc,"Por \xFAltimo, tenemos que lidiar con la presencia de c\xF3digos de caracteres HTML en las rese\xF1as. Podemos usar el m\xF3dulo "),Hr=r(gc,"CODE",{});var kj=l(Hr);$h=n(kj,"html"),kj.forEach(s),Eh=n(gc," de Python para transformar estos c\xF3digos as\xED:"),gc.forEach(s),wp=p(e),h(at.$$.fragment,e),xp=p(e),h(st.$$.fragment,e),Dp=p(e),za=r(e,"P",{});var $c=l(za);jh=n($c,"Usaremos "),Lr=r($c,"CODE",{});var Tj=l(Lr);bh=n(Tj,"Dataset.map()"),Tj.forEach(s),qh=n($c," para transformar todos los caracteres HTML en el corpus:"),$c.forEach(s),yp=p(e),h(tt.$$.fragment,e),kp=p(e),Oa=r(e,"P",{});var Ec=l(Oa);wh=n(Ec,"Como puedes ver, el m\xE9todo "),Mr=r(Ec,"CODE",{});var Cj=l(Mr);xh=n(Cj,"Dataset.map()"),Cj.forEach(s),Dh=n(Ec," es muy \xFAtil para procesar datos y esta es apenas la punta del iceberg de lo que puede hacer."),Ec.forEach(s),Tp=p(e),na=r(e,"H2",{class:!0});var jc=l(na);Aa=r(jc,"A",{id:!0,class:!0,href:!0});var Pj=l(Aa);Rr=r(Pj,"SPAN",{});var zj=l(Rr);h(nt.$$.fragment,zj),zj.forEach(s),Pj.forEach(s),yh=p(jc),mn=r(jc,"SPAN",{});var vE=l(mn);kh=n(vE,"Los superpoderes del m\xE9todo "),Ur=r(vE,"CODE",{});var Oj=l(Ur);Th=n(Oj,"map()"),Oj.forEach(s),vE.forEach(s),jc.forEach(s),Cp=p(e),ee=r(e,"P",{});var Ye=l(ee);Ch=n(Ye,"El m\xE9todo "),Fr=r(Ye,"CODE",{});var Aj=l(Fr);Ph=n(Aj,"Dataset.map()"),Aj.forEach(s),zh=n(Ye," recibe un argumento "),Br=r(Ye,"CODE",{});var Nj=l(Br);Oh=n(Nj,"matched"),Nj.forEach(s),Ah=n(Ye," que, al definirse como "),Yr=r(Ye,"CODE",{});var Ij=l(Yr);Nh=n(Ij,"True"),Ij.forEach(s),Ih=n(Ye,", env\xEDa un lote de ejemplos a la funci\xF3n de mapeo a la vez (el tama\xF1o del lote se puede configurar, pero tiene un valor por defecto de 1.000). Por ejemplo, la funci\xF3n anterior de mapeo que transform\xF3 todos los HTML se demor\xF3 un poco en su ejecuci\xF3n (puedes leer el tiempo en las barras de progreso). Podemos reducir el tiempo al procesar varios elementos a la vez usando un "),Vr=r(Ye,"EM",{});var Sj=l(Vr);Sh=n(Sj,"list comprehension"),Sj.forEach(s),Hh=n(Ye,"."),Ye.forEach(s),Pp=p(e),ae=r(e,"P",{});var Ve=l(ae);Lh=n(Ve,"Cuando especificas "),Jr=r(Ve,"CODE",{});var Hj=l(Jr);Mh=n(Hj,"batched=True"),Hj.forEach(s),Rh=n(Ve,", la funci\xF3n recibe un diccionario con los campos del dataset, pero cada valor es ahora una "),Gr=r(Ve,"EM",{});var Lj=l(Gr);Uh=n(Lj,"lista de valores"),Lj.forEach(s),Fh=n(Ve," y no un valor individual. La salida de "),Qr=r(Ve,"CODE",{});var Mj=l(Qr);Bh=n(Mj,"Dataset.map()"),Mj.forEach(s),Yh=n(Ve," deber\xEDa ser igual: un diccionario con los campos que queremos actualizar o a\xF1adir a nuestro dataset y una lista de valores. Por ejemplo, aqu\xED puedes ver otra forma de transformar todos los caracteres HTML usando "),Wr=r(Ve,"CODE",{});var Rj=l(Wr);Vh=n(Rj,"batched=True"),Rj.forEach(s),Jh=n(Ve,":"),Ve.forEach(s),zp=p(e),h(ot.$$.fragment,e),Op=p(e),de=r(e,"P",{});var ps=l(de);Gh=n(ps,"Si est\xE1s ejecutando este c\xF3digo en un cuaderno, ver\xE1s que este comando se ejecuta mucho m\xE1s r\xE1pido que el anterior. Y no es porque los caracteres HTML de las rese\xF1as ya se hubieran procesado; si vuelves a ejecutar la instrucci\xF3n de la secci\xF3n anterior (sin "),Xr=r(ps,"CODE",{});var Uj=l(Xr);Qh=n(Uj,"batched=True"),Uj.forEach(s),Wh=n(ps,"), se tomar\xE1 el mismo tiempo de ejecuci\xF3n que antes. Esto es porque las "),Kr=r(ps,"EM",{});var Fj=l(Kr);Xh=n(Fj,"list comprehensions"),Fj.forEach(s),Kh=n(ps," suelen ser m\xE1s r\xE1pidas que ejecutar el mismo c\xF3digo en un ciclo "),Zr=r(ps,"CODE",{});var Bj=l(Zr);Zh=n(Bj,"for"),Bj.forEach(s),ev=n(ps," y porque tambi\xE9n ganamos rendimiento al acceder a muchos elementos a la vez en vez de uno por uno."),ps.forEach(s),Ap=p(e),pe=r(e,"P",{});var us=l(pe);av=n(us,"Usar "),el=r(us,"CODE",{});var Yj=l(el);sv=n(Yj,"Dataset.map()"),Yj.forEach(s),tv=n(us," con "),al=r(us,"CODE",{});var Vj=l(al);nv=n(Vj,"batched=True"),Vj.forEach(s),ov=n(us," ser\xE1 fundamental para desbloquear la velocidad de los tokenizadores \u201Cr\xE1pidos\u201D que nos vamos a encontrar en el "),fn=r(us,"A",{href:!0});var Jj=l(fn);rv=n(Jj,"Cap\xEDtulo 6"),Jj.forEach(s),lv=n(us,", que pueden tokenizar velozmente grandes listas de textos. Por ejemplo, para tokenizar todas las rese\xF1as de medicamentos con un tokenizador r\xE1pido, podr\xEDamos usar una funci\xF3n como la siguiente:"),us.forEach(s),Np=p(e),h(rt.$$.fragment,e),Ip=p(e),ue=r(e,"P",{});var cs=l(ue);iv=n(cs,"Como viste en el "),hn=r(cs,"A",{href:!0});var Gj=l(hn);dv=n(Gj,"Cap\xEDtulo 3"),Gj.forEach(s),pv=n(cs,", podemos pasar uno o varios ejemplos al tokenizador, as\xED que podemos usar esta funci\xF3n con o sin "),sl=r(cs,"CODE",{});var Qj=l(sl);uv=n(Qj,"batched=True"),Qj.forEach(s),cv=n(cs,". Aprovechemos esta oportunidad para comparar el desempe\xF1o de las distintas opciones. En un cuaderno, puedes medir el tiempo de ejecuci\xF3n de una instrucci\xF3n de una l\xEDnea a\xF1adiendo "),tl=r(cs,"CODE",{});var Wj=l(tl);mv=n(Wj,"%time"),Wj.forEach(s),fv=n(cs," antes de la l\xEDnea de c\xF3digo de tu inter\xE9s:"),cs.forEach(s),Sp=p(e),h(lt.$$.fragment,e),Hp=p(e),Na=r(e,"P",{});var bc=l(Na);hv=n(bc,"Tambi\xE9n puedes medir el tiempo de una celda completa a\xF1adiendo "),nl=r(bc,"CODE",{});var Xj=l(nl);vv=n(Xj,"%%time"),Xj.forEach(s),_v=n(bc," al inicio de la celda. En el hardware en el que lo ejecutamos, nos arroj\xF3 10.8s para esta instrucci\xF3n (es el n\xFAmero que aparece despu\xE9s de \u201CWall time\u201D)."),bc.forEach(s),Lp=p(e),h(Ia.$$.fragment,e),Mp=p(e),vn=r(e,"P",{});var Kj=l(vn);gv=n(Kj,"Estos son los resultados que obtuvimos con y sin la ejecuci\xF3n por lotes, con un tokenizador r\xE1pido y lento:"),Kj.forEach(s),Rp=p(e),Sa=r(e,"TABLE",{});var qc=l(Sa);ol=r(qc,"THEAD",{});var Zj=l(ol);oa=r(Zj,"TR",{});var qo=l(oa);_n=r(qo,"TH",{align:!0});var eb=l(_n);$v=n(eb,"Opciones"),eb.forEach(s),Ev=p(qo),gn=r(qo,"TH",{align:!0});var ab=l(gn);jv=n(ab,"Tokenizador r\xE1pido"),ab.forEach(s),bv=p(qo),$n=r(qo,"TH",{align:!0});var sb=l($n);qv=n(sb,"Tokenizador lento"),sb.forEach(s),qo.forEach(s),Zj.forEach(s),wv=p(qc),it=r(qc,"TBODY",{});var wc=l(it);ra=r(wc,"TR",{});var wo=l(ra);En=r(wo,"TD",{align:!0});var tb=l(En);rl=r(tb,"CODE",{});var nb=l(rl);xv=n(nb,"batched=True"),nb.forEach(s),tb.forEach(s),Dv=p(wo),jn=r(wo,"TD",{align:!0});var ob=l(jn);yv=n(ob,"10.8s"),ob.forEach(s),kv=p(wo),bn=r(wo,"TD",{align:!0});var rb=l(bn);Tv=n(rb,"4min41s"),rb.forEach(s),wo.forEach(s),Cv=p(wc),la=r(wc,"TR",{});var xo=l(la);qn=r(xo,"TD",{align:!0});var lb=l(qn);ll=r(lb,"CODE",{});var ib=l(ll);Pv=n(ib,"batched=False"),ib.forEach(s),lb.forEach(s),zv=p(xo),wn=r(xo,"TD",{align:!0});var db=l(wn);Ov=n(db,"59.2s"),db.forEach(s),Av=p(xo),xn=r(xo,"TD",{align:!0});var pb=l(xn);Nv=n(pb,"5min3s"),pb.forEach(s),xo.forEach(s),wc.forEach(s),qc.forEach(s),Up=p(e),Oe=r(e,"P",{});var Do=l(Oe);Iv=n(Do,"Esto significa que usar un tokenizador r\xE1pido con la opci\xF3n "),il=r(Do,"CODE",{});var ub=l(il);Sv=n(ub,"batched=True"),ub.forEach(s),Hv=n(Do," es 30 veces m\xE1s r\xE1pido que su contraparte lenta sin usar lotes. \xA1Realmente impresionante! Esta es la raz\xF3n principal por la que los tokenizadores r\xE1pidos son la opci\xF3n por defecto al usar "),dl=r(Do,"CODE",{});var cb=l(dl);Lv=n(cb,"AutoTokenizer"),cb.forEach(s),Mv=n(Do," (y por qu\xE9 se denominan \u201Cr\xE1pidos\u201D). Estos logran tal rapidez gracias a que el c\xF3digo de los tokenizadores corre en Rust, que es un lenguaje que facilita la ejecuci\xF3n del c\xF3digo en paralelo."),Do.forEach(s),Fp=p(e),Dn=r(e,"P",{});var mb=l(Dn);Rv=n(mb,"La paralelizaci\xF3n tambi\xE9n es la raz\xF3n para el incremento de 6x en la velocidad del tokenizador al ejecutarse por lotes: No puedes ejecutar una \xFAnica operac\xF3n de tokenizaci\xF3n en paralelo, pero cuando quieres tokenizar muchos textos al mismo tiempo puedes dividir la ejecuci\xF3n en diferentes procesos, cada uno responsable de sus propios textos."),mb.forEach(s),Bp=p(e),$e=r(e,"P",{});var Xt=l($e);pl=r(Xt,"CODE",{});var fb=l(pl);Uv=n(fb,"Dataset.map()"),fb.forEach(s),Fv=n(Xt," tambi\xE9n tiene algunas capacidades de paralelizaci\xF3n. Dado que no funcionan con Rust, no van a hacer que un tokenizador lento alcance el rendimiento de uno r\xE1pido, pero a\xFAn as\xED pueden ser \xFAtiles (especialmente si est\xE1s usando un tokenizador que no tiene una versi\xF3n r\xE1pida). Para habilitar el multiprocesamiento, usa el argumento "),ul=r(Xt,"CODE",{});var hb=l(ul);Bv=n(hb,"num_proc"),hb.forEach(s),Yv=n(Xt," y especifica el n\xFAmero de procesos para usar en "),cl=r(Xt,"CODE",{});var vb=l(cl);Vv=n(vb,"Dataset.map()"),vb.forEach(s),Jv=n(Xt,":"),Xt.forEach(s),Yp=p(e),h(dt.$$.fragment,e),Vp=p(e),yn=r(e,"P",{});var _b=l(yn);Gv=n(_b,"Tambi\xE9n puedes medir el tiempo para determinar el n\xFAmero de procesos que vas a usar. En nuestro caso, usar 8 procesos produjo la mayor ganancia de velocidad. Aqu\xED est\xE1n algunos de los n\xFAmeros que obtuvimos con y sin multiprocesamiento:"),_b.forEach(s),Jp=p(e),Ha=r(e,"TABLE",{});var xc=l(Ha);ml=r(xc,"THEAD",{});var gb=l(ml);ia=r(gb,"TR",{});var yo=l(ia);kn=r(yo,"TH",{align:!0});var $b=l(kn);Qv=n($b,"Opciones"),$b.forEach(s),Wv=p(yo),Tn=r(yo,"TH",{align:!0});var Eb=l(Tn);Xv=n(Eb,"Tokenizador r\xE1pido"),Eb.forEach(s),Kv=p(yo),Cn=r(yo,"TH",{align:!0});var jb=l(Cn);Zv=n(jb,"Rokenizador lento"),jb.forEach(s),yo.forEach(s),gb.forEach(s),e_=p(xc),Ee=r(xc,"TBODY",{});var ms=l(Ee);da=r(ms,"TR",{});var ko=l(da);Pn=r(ko,"TD",{align:!0});var bb=l(Pn);fl=r(bb,"CODE",{});var qb=l(fl);a_=n(qb,"batched=True"),qb.forEach(s),bb.forEach(s),s_=p(ko),zn=r(ko,"TD",{align:!0});var wb=l(zn);t_=n(wb,"10.8s"),wb.forEach(s),n_=p(ko),On=r(ko,"TD",{align:!0});var xb=l(On);o_=n(xb,"4min41s"),xb.forEach(s),ko.forEach(s),r_=p(ms),pa=r(ms,"TR",{});var To=l(pa);An=r(To,"TD",{align:!0});var Db=l(An);hl=r(Db,"CODE",{});var yb=l(hl);l_=n(yb,"batched=False"),yb.forEach(s),Db.forEach(s),i_=p(To),Nn=r(To,"TD",{align:!0});var kb=l(Nn);d_=n(kb,"59.2s"),kb.forEach(s),p_=p(To),In=r(To,"TD",{align:!0});var Tb=l(In);u_=n(Tb,"5min3s"),Tb.forEach(s),To.forEach(s),c_=p(ms),ua=r(ms,"TR",{});var Co=l(ua);La=r(Co,"TD",{align:!0});var Dc=l(La);vl=r(Dc,"CODE",{});var Cb=l(vl);m_=n(Cb,"batched=True"),Cb.forEach(s),f_=n(Dc,", "),_l=r(Dc,"CODE",{});var Pb=l(_l);h_=n(Pb,"num_proc=8"),Pb.forEach(s),Dc.forEach(s),v_=p(Co),Sn=r(Co,"TD",{align:!0});var zb=l(Sn);__=n(zb,"6.52s"),zb.forEach(s),g_=p(Co),Hn=r(Co,"TD",{align:!0});var Ob=l(Hn);$_=n(Ob,"41.3s"),Ob.forEach(s),Co.forEach(s),E_=p(ms),ca=r(ms,"TR",{});var Po=l(ca);Ma=r(Po,"TD",{align:!0});var yc=l(Ma);gl=r(yc,"CODE",{});var Ab=l(gl);j_=n(Ab,"batched=False"),Ab.forEach(s),b_=n(yc,", "),$l=r(yc,"CODE",{});var Nb=l($l);q_=n(Nb,"num_proc=8"),Nb.forEach(s),yc.forEach(s),w_=p(Po),Ln=r(Po,"TD",{align:!0});var Ib=l(Ln);x_=n(Ib,"9.49s"),Ib.forEach(s),D_=p(Po),Mn=r(Po,"TD",{align:!0});var Sb=l(Mn);y_=n(Sb,"45.2s"),Sb.forEach(s),Po.forEach(s),ms.forEach(s),xc.forEach(s),Gp=p(e),ce=r(e,"P",{});var fs=l(ce);k_=n(fs,"Estos son resultados mucho m\xE1s razonables para el tokenizador lento, aunque el desempe\xF1o del r\xE1pido tambi\xE9n mejor\xF3 sustancialmente. Sin embargo, este no siempre ser\xE1 el caso: para valores de "),El=r(fs,"CODE",{});var Hb=l(El);T_=n(Hb,"num_proc"),Hb.forEach(s),C_=n(fs," diferentes a 8, nuestras pruebas mostraron que era m\xE1s r\xE1pido usar "),jl=r(fs,"CODE",{});var Lb=l(jl);P_=n(Lb,"batched=true"),Lb.forEach(s),z_=n(fs," sin esta opci\xF3n. En general, no recomendamos usar el multiprocesamiento de Python para tokenizadores r\xE1pidos con "),bl=r(fs,"CODE",{});var Mb=l(bl);O_=n(Mb,"batched=True"),Mb.forEach(s),A_=n(fs,"."),fs.forEach(s),Qp=p(e),h(Ra.$$.fragment,e),Wp=p(e),me=r(e,"P",{});var hs=l(me);N_=n(hs,"Que toda esta funcionalidad est\xE1 incluida en un m\xE9todo es algo impresionante en si mismo, \xA1pero hay m\xE1s!. Con "),ql=r(hs,"CODE",{});var Rb=l(ql);I_=n(Rb,"Dataset.map()"),Rb.forEach(s),S_=n(hs," y "),wl=r(hs,"CODE",{});var Ub=l(wl);H_=n(Ub,"batched=True"),Ub.forEach(s),L_=n(hs," puedes cambiar el n\xFAmero de elementos en tu dataset. Esto es s\xFAper \xFAtil en situaciones en las que quieres crear varias caracter\xEDsticas de entrenamiento de un ejemplo, algo que haremos en el preprocesamiento para varias de las tareas de PLN que abordaremos en el "),Rn=r(hs,"A",{href:!0});var Fb=l(Rn);M_=n(Fb,"Cap\xEDtulo 7"),Fb.forEach(s),R_=n(hs,"."),hs.forEach(s),Xp=p(e),h(Ua.$$.fragment,e),Kp=p(e),Ae=r(e,"P",{});var zo=l(Ae);U_=n(zo,"\xA1Veamos c\xF3mo funciona! En este ejemplo vamos a tokenizar nuestros ejemplos y limitarlos a una longitud m\xE1xima de 128, pero le pediremos al tokenizador que devuelva "),xl=r(zo,"EM",{});var Bb=l(xl);F_=n(Bb,"todos"),Bb.forEach(s),B_=n(zo," los fragmentos de texto en vez de unicamente el primero. Esto se puede lograr con el argumento "),Dl=r(zo,"CODE",{});var Yb=l(Dl);Y_=n(Yb,"return_overflowing_tokens=True"),Yb.forEach(s),V_=n(zo,":"),zo.forEach(s),Zp=p(e),h(pt.$$.fragment,e),eu=p(e),Fa=r(e,"P",{});var kc=l(Fa);J_=n(kc,"Prob\xE9moslo en un ejemplo puntual antes de usar "),yl=r(kc,"CODE",{});var Vb=l(yl);G_=n(Vb,"Dataset.map()"),Vb.forEach(s),Q_=n(kc," en todo el dataset:"),kc.forEach(s),au=p(e),h(ut.$$.fragment,e),su=p(e),h(ct.$$.fragment,e),tu=p(e),Un=r(e,"P",{});var Jb=l(Un);W_=n(Jb,"El primer ejemplo en el conjunto de entrenamiento se convirti\xF3 en dos features porque fue tokenizado en un n\xFAmero superior de tokens al que especificamos: el primero de longitud 128 y el segundo de longitud 49. \xA1Vamos a aplicarlo a todo el dataset!"),Jb.forEach(s),nu=p(e),h(mt.$$.fragment,e),ou=p(e),h(ft.$$.fragment,e),ru=p(e),Ba=r(e,"P",{});var Tc=l(Ba);X_=n(Tc,"\xBFPor qu\xE9 no funcion\xF3? El mensaje de error nos da una pista: hay un desajuste en las longitudes de una de las columnas, siendo una de logitud 1.463 y otra de longitud 1.000. Si has revisado la "),Ya=r(Tc,"A",{href:!0,rel:!0});var _E=l(Ya);K_=n(_E,"documentaci\xF3n de "),kl=r(_E,"CODE",{});var Gb=l(kl);Z_=n(Gb,"Dataset.map()"),Gb.forEach(s),_E.forEach(s),e2=n(Tc,", te habr\xE1s dado cuenta que estamos mapeando el n\xFAmero de muestras que le pasamos a la funci\xF3n: en este caso los 1.000 ejemplos nos devuelven 1.463 features, arrojando un error."),Tc.forEach(s),lu=p(e),se=r(e,"P",{});var Je=l(se);a2=n(Je,"El problema es que estamos tratando de mezclar dos datasets de tama\xF1os diferentes: las columnas de "),Tl=r(Je,"CODE",{});var Qb=l(Tl);s2=n(Qb,"drug_dataset"),Qb.forEach(s),t2=n(Je," tendr\xE1n un cierto n\xFAmero de ejemplos (los 1.000 en el error), pero el "),Cl=r(Je,"CODE",{});var Wb=l(Cl);n2=n(Wb,"tokenized_dataset"),Wb.forEach(s),o2=n(Je," que estamos construyendo tendr\xE1 m\xE1s (los 1.463 en el mensaje de error). Esto no funciona para un "),Pl=r(Je,"CODE",{});var Xb=l(Pl);r2=n(Xb,"Dataset"),Xb.forEach(s),l2=n(Je,", as\xED que tenemos que eliminar las columnas del anterior dataset o volverlas del mismo tama\xF1o del nuevo. Podemos hacer la primera operaci\xF3n con el argumento "),zl=r(Je,"CODE",{});var Kb=l(zl);i2=n(Kb,"remove_columns"),Kb.forEach(s),d2=n(Je,":"),Je.forEach(s),iu=p(e),h(ht.$$.fragment,e),du=p(e),Fn=r(e,"P",{});var Zb=l(Fn);p2=n(Zb,"Ahora funciona sin errores. Podemos revisar que nuestro dataset nuevo tiene m\xE1s elementos que el original al comparar sus longitudes:"),Zb.forEach(s),pu=p(e),h(vt.$$.fragment,e),uu=p(e),h(_t.$$.fragment,e),cu=p(e),Ne=r(e,"P",{});var Oo=l(Ne);u2=n(Oo,"Tambi\xE9n mencionamos que podemos trabajar con el problema de longitudes que no coinciden al convertir las columnas viejas en el mismo tama\xF1o de las nuevas. Para eso, vamos a necesitar el campo "),Ol=r(Oo,"CODE",{});var e7=l(Ol);c2=n(e7,"overflow_to_sample_mapping"),e7.forEach(s),m2=n(Oo," que devuelve el tokenizer cuando definimos "),Al=r(Oo,"CODE",{});var a7=l(Al);f2=n(a7,"return_overflowing_tokens=True"),a7.forEach(s),h2=n(Oo,". Esto devuelve un mapeo del \xEDndice de un nuevo feature al \xEDndice de la muestra de la que se origin\xF3. Usando lo anterior, podemos asociar cada llave presente en el dataset original con una lista de valores del tama\xF1o correcto al repetir los valores de cada ejemplo tantas veces como genere nuevos features:"),Oo.forEach(s),mu=p(e),h(gt.$$.fragment,e),fu=p(e),Va=r(e,"P",{});var Cc=l(Va);v2=n(Cc,"De esta forma, podemos ver que funciona con "),Nl=r(Cc,"CODE",{});var s7=l(Nl);_2=n(s7,"Dataset.map()"),s7.forEach(s),g2=n(Cc," sin necesidad de eliminar las columnas viejas."),Cc.forEach(s),hu=p(e),h($t.$$.fragment,e),vu=p(e),h(Et.$$.fragment,e),_u=p(e),Bn=r(e,"P",{});var t7=l(Bn);$2=n(t7,"Como resultado, tenemos el mismo n\xFAmero de features de entrenamiento que antes, pero conservando todos los campos anteriores. Quiz\xE1s prefieras usar esta opci\xF3n si necesitas conservarlos para algunas tareas de post-procesamiento despu\xE9s de aplicar tu modelo."),t7.forEach(s),gu=p(e),Ja=r(e,"P",{});var Pc=l(Ja);E2=n(Pc,"Ya has visto como usar \u{1F917} Datasets para preprocesar un dataset de varias formas. Si bien las funciones de procesamiento de \u{1F917} Datasets van a suplir la mayor parte de tus necesidades de entrenamiento de modelos, hay ocasiones en las que puedes necesitar Pandas para tener acceso a herramientas m\xE1s poderosas, como "),Il=r(Pc,"CODE",{});var n7=l(Il);j2=n(n7,"DataFrame.groupby()"),n7.forEach(s),b2=n(Pc," o alg\xFAn API de alto nivel para visualizaci\xF3n. Afortunadamente, \u{1F917} Datasets est\xE1 dise\xF1ado para ser interoperable con librer\xEDas como Pandas, NumPy, PyTorch, TensoFlow y JAX. Veamos c\xF3mo funciona."),Pc.forEach(s),$u=p(e),ma=r(e,"H2",{class:!0});var zc=l(ma);Ga=r(zc,"A",{id:!0,class:!0,href:!0});var o7=l(Ga);Sl=r(o7,"SPAN",{});var r7=l(Sl);h(jt.$$.fragment,r7),r7.forEach(s),o7.forEach(s),q2=p(zc),fa=r(zc,"SPAN",{});var Ao=l(fa);w2=n(Ao,"De "),Hl=r(Ao,"CODE",{});var l7=l(Hl);x2=n(l7,"Dataset"),l7.forEach(s),D2=n(Ao,"s a "),Ll=r(Ao,"CODE",{});var i7=l(Ll);y2=n(i7,"DataFrame"),i7.forEach(s),k2=n(Ao,"s y viceversa"),Ao.forEach(s),zc.forEach(s),Eu=p(e),h(bt.$$.fragment,e),ju=p(e),te=r(e,"P",{});var Ge=l(te);T2=n(Ge,"Para habilitar la conversi\xF3n entre varias librer\xEDas de terceros, \u{1F917} Datasets provee la funci\xF3n "),Ml=r(Ge,"CODE",{});var d7=l(Ml);C2=n(d7,"Dataset.set_format()"),d7.forEach(s),P2=n(Ge,". Esta funci\xF3n s\xF3lo cambia el "),Rl=r(Ge,"EM",{});var p7=l(Rl);z2=n(p7,"formato de salida"),p7.forEach(s),O2=n(Ge," del dataset, de tal manera que puedas cambiar a otro formato sin cambiar el "),Ul=r(Ge,"EM",{});var u7=l(Ul);A2=n(u7,"formato de datos subyacente"),u7.forEach(s),N2=n(Ge,", que es Apache Arrow. Este cambio de formato se hace "),Fl=r(Ge,"EM",{});var c7=l(Fl);I2=n(c7,"in place"),c7.forEach(s),S2=n(Ge,". Para verlo en acci\xF3n, convirtamos el dataset a Pandas:"),Ge.forEach(s),bu=p(e),h(qt.$$.fragment,e),qu=p(e),Qa=r(e,"P",{});var Oc=l(Qa);H2=n(Oc,"Ahora, cuando accedemos a los elementos del dataset obtenemos un "),Bl=r(Oc,"CODE",{});var m7=l(Bl);L2=n(m7,"pandas.DataFrame"),m7.forEach(s),M2=n(Oc," en vez de un diccionario:"),Oc.forEach(s),wu=p(e),h(wt.$$.fragment,e),xu=p(e),Ie=r(e,"TABLE",{border:!0,class:!0});var Ac=l(Ie);Yl=r(Ac,"THEAD",{});var f7=l(Yl);I=r(f7,"TR",{style:!0});var F=l(I);Du=r(F,"TH",{}),l(Du).forEach(s),R2=p(F),Vl=r(F,"TH",{});var h7=l(Vl);U2=n(h7,"patient_id"),h7.forEach(s),F2=p(F),Jl=r(F,"TH",{});var v7=l(Jl);B2=n(v7,"drugName"),v7.forEach(s),Y2=p(F),Gl=r(F,"TH",{});var _7=l(Gl);V2=n(_7,"condition"),_7.forEach(s),J2=p(F),Ql=r(F,"TH",{});var g7=l(Ql);G2=n(g7,"review"),g7.forEach(s),Q2=p(F),Wl=r(F,"TH",{});var $7=l(Wl);W2=n($7,"rating"),$7.forEach(s),X2=p(F),Xl=r(F,"TH",{});var E7=l(Xl);K2=n(E7,"date"),E7.forEach(s),Z2=p(F),Kl=r(F,"TH",{});var j7=l(Kl);eg=n(j7,"usefulCount"),j7.forEach(s),ag=p(F),Zl=r(F,"TH",{});var b7=l(Zl);sg=n(b7,"review_length"),b7.forEach(s),F.forEach(s),f7.forEach(s),tg=p(Ac),ha=r(Ac,"TBODY",{});var No=l(ha);S=r(No,"TR",{});var B=l(S);ei=r(B,"TH",{});var q7=l(ei);ng=n(q7,"0"),q7.forEach(s),og=p(B),ai=r(B,"TD",{});var w7=l(ai);rg=n(w7,"95260"),w7.forEach(s),lg=p(B),si=r(B,"TD",{});var x7=l(si);ig=n(x7,"Guanfacine"),x7.forEach(s),dg=p(B),ti=r(B,"TD",{});var D7=l(ti);pg=n(D7,"adhd"),D7.forEach(s),ug=p(B),ni=r(B,"TD",{});var y7=l(ni);cg=n(y7,'"My son is halfway through his fourth week of Intuniv..."'),y7.forEach(s),mg=p(B),oi=r(B,"TD",{});var k7=l(oi);fg=n(k7,"8.0"),k7.forEach(s),hg=p(B),ri=r(B,"TD",{});var T7=l(ri);vg=n(T7,"April 27, 2010"),T7.forEach(s),_g=p(B),li=r(B,"TD",{});var C7=l(li);gg=n(C7,"192"),C7.forEach(s),$g=p(B),ii=r(B,"TD",{});var P7=l(ii);Eg=n(P7,"141"),P7.forEach(s),B.forEach(s),jg=p(No),H=r(No,"TR",{});var Y=l(H);di=r(Y,"TH",{});var z7=l(di);bg=n(z7,"1"),z7.forEach(s),qg=p(Y),pi=r(Y,"TD",{});var O7=l(pi);wg=n(O7,"92703"),O7.forEach(s),xg=p(Y),ui=r(Y,"TD",{});var A7=l(ui);Dg=n(A7,"Lybrel"),A7.forEach(s),yg=p(Y),ci=r(Y,"TD",{});var N7=l(ci);kg=n(N7,"birth control"),N7.forEach(s),Tg=p(Y),mi=r(Y,"TD",{});var I7=l(mi);Cg=n(I7,'"I used to take another oral contraceptive, which had 21 pill cycle, and was very happy- very light periods, max 5 days, no other side effects..."'),I7.forEach(s),Pg=p(Y),fi=r(Y,"TD",{});var S7=l(fi);zg=n(S7,"5.0"),S7.forEach(s),Og=p(Y),hi=r(Y,"TD",{});var H7=l(hi);Ag=n(H7,"December 14, 2009"),H7.forEach(s),Ng=p(Y),vi=r(Y,"TD",{});var L7=l(vi);Ig=n(L7,"17"),L7.forEach(s),Sg=p(Y),_i=r(Y,"TD",{});var M7=l(_i);Hg=n(M7,"134"),M7.forEach(s),Y.forEach(s),Lg=p(No),L=r(No,"TR",{});var V=l(L);gi=r(V,"TH",{});var R7=l(gi);Mg=n(R7,"2"),R7.forEach(s),Rg=p(V),$i=r(V,"TD",{});var U7=l($i);Ug=n(U7,"138000"),U7.forEach(s),Fg=p(V),Ei=r(V,"TD",{});var F7=l(Ei);Bg=n(F7,"Ortho Evra"),F7.forEach(s),Yg=p(V),ji=r(V,"TD",{});var B7=l(ji);Vg=n(B7,"birth control"),B7.forEach(s),Jg=p(V),bi=r(V,"TD",{});var Y7=l(bi);Gg=n(Y7,'"This is my first time using any form of birth control..."'),Y7.forEach(s),Qg=p(V),qi=r(V,"TD",{});var V7=l(qi);Wg=n(V7,"8.0"),V7.forEach(s),Xg=p(V),wi=r(V,"TD",{});var J7=l(wi);Kg=n(J7,"November 3, 2015"),J7.forEach(s),Zg=p(V),xi=r(V,"TD",{});var G7=l(xi);e1=n(G7,"10"),G7.forEach(s),a1=p(V),Di=r(V,"TD",{});var Q7=l(Di);s1=n(Q7,"89"),Q7.forEach(s),V.forEach(s),No.forEach(s),Ac.forEach(s),yu=p(e),Se=r(e,"P",{});var Io=l(Se);t1=n(Io,"Creemos un "),yi=r(Io,"CODE",{});var W7=l(yi);n1=n(W7,"pandas.DataFrame"),W7.forEach(s),o1=n(Io," para el conjunto de entrenamiento entero al seleccionar los elementos de "),ki=r(Io,"CODE",{});var X7=l(ki);r1=n(X7,'drug_dataset["train"]'),X7.forEach(s),l1=n(Io,":"),Io.forEach(s),ku=p(e),h(xt.$$.fragment,e),Tu=p(e),h(Wa.$$.fragment,e),Cu=p(e),Xa=r(e,"P",{});var Nc=l(Xa);i1=n(Nc,"De aqu\xED en adelante podemos usar toda la funcionalidad de pandas cuando queramos. Por ejemplo, podemos hacer un encadenamiento sofisticado para calcular la distribuci\xF3n de clase entre las entradas de "),Ti=r(Nc,"CODE",{});var K7=l(Ti);d1=n(K7,"condition"),K7.forEach(s),p1=n(Nc,":"),Nc.forEach(s),Pu=p(e),h(Dt.$$.fragment,e),zu=p(e),He=r(e,"TABLE",{border:!0,class:!0});var Ic=l(He);Ci=r(Ic,"THEAD",{});var Z7=l(Ci);Le=r(Z7,"TR",{style:!0});var So=l(Le);Ou=r(So,"TH",{}),l(Ou).forEach(s),u1=p(So),Pi=r(So,"TH",{});var e0=l(Pi);c1=n(e0,"condition"),e0.forEach(s),m1=p(So),zi=r(So,"TH",{});var a0=l(zi);f1=n(a0,"frequency"),a0.forEach(s),So.forEach(s),Z7.forEach(s),h1=p(Ic),oe=r(Ic,"TBODY",{});var Qe=l(oe);va=r(Qe,"TR",{});var Ho=l(va);Oi=r(Ho,"TH",{});var s0=l(Oi);v1=n(s0,"0"),s0.forEach(s),_1=p(Ho),Ai=r(Ho,"TD",{});var t0=l(Ai);g1=n(t0,"birth control"),t0.forEach(s),$1=p(Ho),Ni=r(Ho,"TD",{});var n0=l(Ni);E1=n(n0,"27655"),n0.forEach(s),Ho.forEach(s),j1=p(Qe),_a=r(Qe,"TR",{});var Lo=l(_a);Ii=r(Lo,"TH",{});var o0=l(Ii);b1=n(o0,"1"),o0.forEach(s),q1=p(Lo),Si=r(Lo,"TD",{});var r0=l(Si);w1=n(r0,"depression"),r0.forEach(s),x1=p(Lo),Hi=r(Lo,"TD",{});var l0=l(Hi);D1=n(l0,"8023"),l0.forEach(s),Lo.forEach(s),y1=p(Qe),ga=r(Qe,"TR",{});var Mo=l(ga);Li=r(Mo,"TH",{});var i0=l(Li);k1=n(i0,"2"),i0.forEach(s),T1=p(Mo),Mi=r(Mo,"TD",{});var d0=l(Mi);C1=n(d0,"acne"),d0.forEach(s),P1=p(Mo),Ri=r(Mo,"TD",{});var p0=l(Ri);z1=n(p0,"5209"),p0.forEach(s),Mo.forEach(s),O1=p(Qe),$a=r(Qe,"TR",{});var Ro=l($a);Ui=r(Ro,"TH",{});var u0=l(Ui);A1=n(u0,"3"),u0.forEach(s),N1=p(Ro),Fi=r(Ro,"TD",{});var c0=l(Fi);I1=n(c0,"anxiety"),c0.forEach(s),S1=p(Ro),Bi=r(Ro,"TD",{});var m0=l(Bi);H1=n(m0,"4991"),m0.forEach(s),Ro.forEach(s),L1=p(Qe),Ea=r(Qe,"TR",{});var Uo=l(Ea);Yi=r(Uo,"TH",{});var f0=l(Yi);M1=n(f0,"4"),f0.forEach(s),R1=p(Uo),Vi=r(Uo,"TD",{});var h0=l(Vi);U1=n(h0,"pain"),h0.forEach(s),F1=p(Uo),Ji=r(Uo,"TD",{});var v0=l(Ji);B1=n(v0,"4744"),v0.forEach(s),Uo.forEach(s),Qe.forEach(s),Ic.forEach(s),Au=p(e),Me=r(e,"P",{});var Fo=l(Me);Y1=n(Fo,"Y una vez hemos concluido el an\xE1lisis con Pandas, tenemos la posibilidad de crear un nuevo objeto "),Gi=r(Fo,"CODE",{});var _0=l(Gi);V1=n(_0,"Dataset"),_0.forEach(s),J1=n(Fo," usando la funci\xF3n "),Qi=r(Fo,"CODE",{});var g0=l(Qi);G1=n(g0,"Dataset.from_pandas()"),g0.forEach(s),Q1=n(Fo," de la siguiente manera:"),Fo.forEach(s),Nu=p(e),h(yt.$$.fragment,e),Iu=p(e),h(kt.$$.fragment,e),Su=p(e),h(Ka.$$.fragment,e),Hu=p(e),fe=r(e,"P",{});var vs=l(fe);W1=n(vs,"Con esto terminamos nuestro tour de las m\xFAltiples t\xE9cnicas de preprocesamiento disponibles en \u{1F917} Datasets. Para concluir, creemos un set de validaci\xF3n para preparar el conjunto de datos y entrenar el clasificador. Antes de hacerlo, vamos a reiniciar el formato de salida de "),Wi=r(vs,"CODE",{});var $0=l(Wi);X1=n($0,"drug_dataset"),$0.forEach(s),K1=n(vs," de "),Xi=r(vs,"CODE",{});var E0=l(Xi);Z1=n(E0,'"pandas"'),E0.forEach(s),e$=n(vs," a "),Ki=r(vs,"CODE",{});var j0=l(Ki);a$=n(j0,'"arrow"'),j0.forEach(s),s$=n(vs,":"),vs.forEach(s),Lu=p(e),h(Tt.$$.fragment,e),Mu=p(e),ja=r(e,"H2",{class:!0});var Sc=l(ja);Za=r(Sc,"A",{id:!0,class:!0,href:!0});var b0=l(Za);Zi=r(b0,"SPAN",{});var q0=l(Zi);h(Ct.$$.fragment,q0),q0.forEach(s),b0.forEach(s),t$=p(Sc),ed=r(Sc,"SPAN",{});var w0=l(ed);n$=n(w0,"Creando un conjunto de validaci\xF3n"),w0.forEach(s),Sc.forEach(s),Ru=p(e),Yn=r(e,"P",{});var x0=l(Yn);o$=n(x0,"Si bien tenemos un conjunto de prueba que podr\xEDamos usar para la evaluaci\xF3n, es una buena pr\xE1ctica dejar el conjunto de prueba intacto y crear un conjunto de validaci\xF3n aparte durante el desarrollo. Una vez est\xE9s satisfecho con el desempe\xF1o de tus modelos en el conjunto de validaci\xF3n, puedes hacer un \xFAltimo chequeo con el conjunto de prueba. Este proceso ayuda a reducir el riesgo de sobreajustar al conjunto de prueba y desplegar un modelo que falle en datos reales."),x0.forEach(s),Uu=p(e),Q=r(e,"P",{});var _e=l(Q);r$=n(_e,"\u{1F917} Datasets provee la funci\xF3n "),ad=r(_e,"CODE",{});var D0=l(ad);l$=n(D0,"Dataset.train_test_split()"),D0.forEach(s),i$=n(_e," que est\xE1 basada en la famosa funcionalidad de "),sd=r(_e,"CODE",{});var y0=l(sd);d$=n(y0,"scikit-learn"),y0.forEach(s),p$=n(_e,". Us\xE9mosla para separar nuestro conjunto de entrenamiento en dos partes "),td=r(_e,"CODE",{});var k0=l(td);u$=n(k0,"train"),k0.forEach(s),c$=n(_e," y "),nd=r(_e,"CODE",{});var T0=l(nd);m$=n(T0,"validation"),T0.forEach(s),f$=n(_e," (definiendo el argumento "),od=r(_e,"CODE",{});var C0=l(od);h$=n(C0,"seed"),C0.forEach(s),v$=n(_e," por motivos de reproducibilidad):"),_e.forEach(s),Fu=p(e),h(Pt.$$.fragment,e),Bu=p(e),h(zt.$$.fragment,e),Yu=p(e),es=r(e,"P",{});var Hc=l(es);_$=n(Hc,"S\xFAper, ya preparamos un dataset que est\xE1 listo para entrenar modelos. En la "),Vn=r(Hc,"A",{href:!0});var P0=l(Vn);g$=n(P0,"secci\xF3n 5"),P0.forEach(s),$$=n(Hc," veremos c\xF3mo subir datasets al Hub de Hugging Face, pero por ahora terminemos el an\xE1lisis estudiando algunas formas de guardarlos en tu m\xE1quina local."),Hc.forEach(s),Vu=p(e),ba=r(e,"H2",{class:!0});var Lc=l(ba);as=r(Lc,"A",{id:!0,class:!0,href:!0});var z0=l(as);rd=r(z0,"SPAN",{});var O0=l(rd);h(Ot.$$.fragment,O0),O0.forEach(s),z0.forEach(s),E$=p(Lc),ld=r(Lc,"SPAN",{});var A0=l(ld);j$=n(A0,"Saving a dataset"),A0.forEach(s),Lc.forEach(s),Ju=p(e),h(At.$$.fragment,e),Gu=p(e),Jn=r(e,"P",{});var N0=l(Jn);b$=n(N0,"A pesar de que \u{1F917} Datasets va a guardar en cach\xE9 todo dataset que descargues, as\xED como las operaciones que se ejecutan en \xE9l, hay ocasiones en las que querr\xE1s guardar un dataset en memoria (e.g., en caso que el cach\xE9 se elimine). Como se muestra en la siguiente tabla, \u{1F917} Datasets tiene 3 funciones para guardar tu dataset en distintos formatos:"),N0.forEach(s),Qu=p(e),ss=r(e,"TABLE",{});var Mc=l(ss);id=r(Mc,"THEAD",{});var I0=l(id);Nt=r(I0,"TR",{});var Rc=l(Nt);Gn=r(Rc,"TH",{align:!0});var S0=l(Gn);q$=n(S0,"Formato"),S0.forEach(s),w$=p(Rc),Qn=r(Rc,"TH",{align:!0});var H0=l(Qn);x$=n(H0,"Funci\xF3n"),H0.forEach(s),Rc.forEach(s),I0.forEach(s),D$=p(Mc),qa=r(Mc,"TBODY",{});var Bo=l(qa);It=r(Bo,"TR",{});var Uc=l(It);Wn=r(Uc,"TD",{align:!0});var L0=l(Wn);y$=n(L0,"Arrow"),L0.forEach(s),k$=p(Uc),Xn=r(Uc,"TD",{align:!0});var M0=l(Xn);dd=r(M0,"CODE",{});var R0=l(dd);T$=n(R0,"Dataset.save_to_disk()"),R0.forEach(s),M0.forEach(s),Uc.forEach(s),C$=p(Bo),St=r(Bo,"TR",{});var Fc=l(St);Kn=r(Fc,"TD",{align:!0});var U0=l(Kn);P$=n(U0,"CSV"),U0.forEach(s),z$=p(Fc),Zn=r(Fc,"TD",{align:!0});var F0=l(Zn);pd=r(F0,"CODE",{});var B0=l(pd);O$=n(B0,"Dataset.to_csv()"),B0.forEach(s),F0.forEach(s),Fc.forEach(s),A$=p(Bo),Ht=r(Bo,"TR",{});var Bc=l(Ht);eo=r(Bc,"TD",{align:!0});var Y0=l(eo);N$=n(Y0,"JSON"),Y0.forEach(s),I$=p(Bc),ao=r(Bc,"TD",{align:!0});var V0=l(ao);ud=r(V0,"CODE",{});var J0=l(ud);S$=n(J0,"Dataset.to_json()"),J0.forEach(s),V0.forEach(s),Bc.forEach(s),Bo.forEach(s),Mc.forEach(s),Wu=p(e),so=r(e,"P",{});var G0=l(so);H$=n(G0,"Por ejemplo, guardemos el dataset limpio en formato Arrow:"),G0.forEach(s),Xu=p(e),h(Lt.$$.fragment,e),Ku=p(e),to=r(e,"P",{});var Q0=l(to);L$=n(Q0,"Esto crear\xE1 una carpeta con la siguiente estructura:"),Q0.forEach(s),Zu=p(e),h(Mt.$$.fragment,e),ec=p(e),he=r(e,"P",{});var _s=l(he);M$=n(_s,"en las que podemos ver que cada parte del dataset est\xE1 asociada con una tabla "),cd=r(_s,"EM",{});var W0=l(cd);R$=n(W0,"dataset.arrow"),W0.forEach(s),U$=n(_s," y algunos metadatos en "),md=r(_s,"EM",{});var X0=l(md);F$=n(X0,"dataset_info.json"),X0.forEach(s),B$=n(_s," y "),fd=r(_s,"EM",{});var K0=l(fd);Y$=n(K0,"state.json"),K0.forEach(s),V$=n(_s,". Puedes pensar en el formato Arrow como una tabla sofisticada de columnas y filas que est\xE1 optimizada para construir aplicaciones de alto rendimiento que procesan y transportan datasets grandes."),_s.forEach(s),ac=p(e),ts=r(e,"P",{});var Yc=l(ts);J$=n(Yc,"Una vez el dataset est\xE1 guardado, podemos cargarlo usando la funci\xF3n "),hd=r(Yc,"CODE",{});var Z0=l(hd);G$=n(Z0,"load_from_disk()"),Z0.forEach(s),Q$=n(Yc," as\xED:"),Yc.forEach(s),sc=p(e),h(Rt.$$.fragment,e),tc=p(e),h(Ut.$$.fragment,e),nc=p(e),ns=r(e,"P",{});var Vc=l(ns);W$=n(Vc,"Para los formatos CSV y JSON, tenemos que guardar cada parte en un archivo separado. Una forma de hacerlo es iterando sobre las llaves y valores del objeto "),vd=r(Vc,"CODE",{});var e3=l(vd);X$=n(e3,"DatasetDict"),e3.forEach(s),K$=n(Vc,":"),Vc.forEach(s),oc=p(e),h(Ft.$$.fragment,e),rc=p(e),os=r(e,"P",{});var Jc=l(os);Z$=n(Jc,"Esto guarda cada parte en formato "),Bt=r(Jc,"A",{href:!0,rel:!0});var a3=l(Bt);eE=n(a3,"JSON Lines"),a3.forEach(s),aE=n(Jc,", donde cada fila del dataset est\xE1 almacenada como una \xFAnica l\xEDnea de JSON. As\xED se ve el primer ejemplo:"),Jc.forEach(s),lc=p(e),h(Yt.$$.fragment,e),ic=p(e),h(Vt.$$.fragment,e),dc=p(e),rs=r(e,"P",{});var Gc=l(rs);sE=n(Gc,"Podemos usar las t\xE9cnicas de la "),no=r(Gc,"A",{href:!0});var s3=l(no);tE=n(s3,"secci\xF3n 2"),s3.forEach(s),nE=n(Gc," para cargar los archivos JSON de la siguiente manera:"),Gc.forEach(s),pc=p(e),h(Jt.$$.fragment,e),uc=p(e),oo=r(e,"P",{});var t3=l(oo);oE=n(t3,"Esto es todo lo que vamos a ver en nuestra revisi\xF3n del manejo de datos con \u{1F917} Datasets. Ahora que tenemos un dataset limpio para entrenar un modelo, aqu\xED van algunas ideas que podr\xEDas intentar:"),t3.forEach(s),cc=p(e),ls=r(e,"OL",{});var Qc=l(ls);Gt=r(Qc,"LI",{});var Wc=l(Gt);rE=n(Wc,"Usa las t\xE9cnicas del "),ro=r(Wc,"A",{href:!0});var n3=l(ro);lE=n(n3,"Cap\xEDtulo 3"),n3.forEach(s),iE=n(Wc," para entrenar un clasificador que pueda predecir la condici\xF3n del paciente con base en las rese\xF1as de los medicamentos."),Wc.forEach(s),dE=p(Qc),wa=r(Qc,"LI",{});var Yo=l(wa);pE=n(Yo,"Usa el pipeline de "),_d=r(Yo,"CODE",{});var o3=l(_d);uE=n(o3,"summarization"),o3.forEach(s),cE=n(Yo," del "),lo=r(Yo,"A",{href:!0});var r3=l(lo);mE=n(r3,"Cap\xEDtulo 1"),r3.forEach(s),fE=n(Yo," para generar res\xFAmenes de las rese\xF1as."),Yo.forEach(s),Qc.forEach(s),mc=p(e),io=r(e,"P",{});var l3=l(io);hE=n(l3,"En la siguiente secci\xF3n veremos c\xF3mo \u{1F917} Datasets te puede ayudar a trabajar con datasets enormes \xA1sin explotar tu computador!"),l3.forEach(s),this.h()},h(){m(c,"name","hf:doc:metadata"),m(c,"content",JSON.stringify(w3)),m(x,"id","es-momento-de-subdividir"),m(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(x,"href","#es-momento-de-subdividir"),m(j,"class","relative group"),m(W,"id","subdivdiendo-nuestros-datos"),m(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(W,"href","#subdivdiendo-nuestros-datos"),m(R,"class","relative group"),m(aa,"href","/course/chapter3"),m(bs,"href","https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29"),m(bs,"rel","nofollow"),m(qs,"href","https://archive.ics.uci.edu/ml/index.php"),m(qs,"rel","nofollow"),m(on,"href","/course/chapter3"),m(Ss,"href","https://docs.python.org/3/reference/lexical_analysis.html#keywords"),m(Ss,"rel","nofollow"),m(Fs,"href","https://realpython.com/python-lambda/"),m(Fs,"rel","nofollow"),m(ka,"id","creando-nuevas-columnas"),m(ka,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ka,"href","#creando-nuevas-columnas"),m(ta,"class","relative group"),m(Aa,"id","los-superpoderes-del-mtodo-map"),m(Aa,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Aa,"href","#los-superpoderes-del-mtodo-map"),m(na,"class","relative group"),m(fn,"href","/course/chapter6"),m(hn,"href","/course/chapter3"),m(_n,"align","center"),m(gn,"align","center"),m($n,"align","center"),m(En,"align","center"),m(jn,"align","center"),m(bn,"align","center"),m(qn,"align","center"),m(wn,"align","center"),m(xn,"align","center"),m(kn,"align","center"),m(Tn,"align","center"),m(Cn,"align","center"),m(Pn,"align","center"),m(zn,"align","center"),m(On,"align","center"),m(An,"align","center"),m(Nn,"align","center"),m(In,"align","center"),m(La,"align","center"),m(Sn,"align","center"),m(Hn,"align","center"),m(Ma,"align","center"),m(Ln,"align","center"),m(Mn,"align","center"),m(Rn,"href","/course/chapter7"),m(Ya,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map"),m(Ya,"rel","nofollow"),m(Ga,"id","de-datasets-a-dataframes-y-viceversa"),m(Ga,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Ga,"href","#de-datasets-a-dataframes-y-viceversa"),m(ma,"class","relative group"),i3(I,"text-align","right"),m(Ie,"border","1"),m(Ie,"class","dataframe"),i3(Le,"text-align","right"),m(He,"border","1"),m(He,"class","dataframe"),m(Za,"id","creando-un-conjunto-de-validacin"),m(Za,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Za,"href","#creando-un-conjunto-de-validacin"),m(ja,"class","relative group"),m(Vn,"href","/course/chapter5/5"),m(as,"id","saving-a-dataset"),m(as,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(as,"href","#saving-a-dataset"),m(ba,"class","relative group"),m(Gn,"align","center"),m(Qn,"align","center"),m(Wn,"align","center"),m(Xn,"align","center"),m(Kn,"align","center"),m(Zn,"align","center"),m(eo,"align","center"),m(ao,"align","center"),m(Bt,"href","https://jsonlines.org"),m(Bt,"rel","nofollow"),m(no,"href","/course/chapter5/2"),m(ro,"href","/course/chapter3"),m(lo,"href","/course/chapter1")},m(e,i){a(document.head,c),u(e,T,i),u(e,j,i),a(j,x),a(x,y),v(b,y,null),a(j,D),a(j,C),a(C,q),u(e,w,i),v(z,e,i),u(e,k,i),u(e,P,i),a(P,J),u(e,N,i),v(O,e,i),u(e,ge,i),u(e,R,i),a(R,W),a(W,re),v(ne,re,null),a(R,$s),a(R,We),a(We,Xe),u(e,xa,i),u(e,U,i),a(U,Ke),a(U,Ze),a(Ze,Es),a(U,ea),a(U,A),a(A,Zt),a(U,en),a(U,Da),a(Da,an),a(U,sn),a(U,aa),a(aa,tn),a(U,nn),u(e,js,i),u(e,je,i),a(je,Xc),a(je,bs),a(bs,Kc),a(je,Zc),a(je,qs),a(qs,em),a(je,am),u(e,wd,i),u(e,be,i),a(be,sm),a(be,Vo),a(Vo,tm),a(be,nm),a(be,Jo),a(Jo,om),a(be,rm),u(e,xd,i),v(ws,e,i),u(e,Dd,i),u(e,le,i),a(le,lm),a(le,Go),a(Go,im),a(le,dm),a(le,Qo),a(Qo,pm),a(le,um),a(le,Wo),a(Wo,cm),a(le,mm),u(e,yd,i),v(xs,e,i),u(e,kd,i),u(e,qe,i),a(qe,fm),a(qe,Xo),a(Xo,hm),a(qe,vm),a(qe,Ko),a(Ko,_m),a(qe,gm),u(e,Td,i),v(Ds,e,i),u(e,Cd,i),v(ys,e,i),u(e,Pd,i),u(e,ie,i),a(ie,$m),a(ie,Zo),a(Zo,Em),a(ie,jm),a(ie,er),a(er,bm),a(ie,qm),a(ie,ar),a(ar,wm),a(ie,xm),u(e,zd,i),u(e,we,i),a(we,ks),a(ks,Dm),a(ks,sr),a(sr,ym),a(ks,km),a(we,Tm),a(we,Ts),a(Ts,Cm),a(Ts,tr),a(tr,Pm),a(Ts,zm),a(we,Om),a(we,sa),a(sa,Am),a(sa,nr),a(nr,Nm),a(sa,Im),a(sa,or),a(or,Sm),a(sa,Hm),u(e,Od,i),u(e,xe,i),a(xe,Lm),a(xe,rr),a(rr,Mm),a(xe,Rm),a(xe,lr),a(lr,Um),a(xe,Fm),u(e,Ad,i),v(Cs,e,i),u(e,Nd,i),u(e,De,i),a(De,Bm),a(De,ir),a(ir,Ym),a(De,Vm),a(De,dr),a(dr,Jm),a(De,Gm),u(e,Id,i),v(Ps,e,i),u(e,Sd,i),v(zs,e,i),u(e,Hd,i),v(ya,e,i),u(e,Ld,i),u(e,X,i),a(X,Qm),a(X,pr),a(pr,Wm),a(X,Xm),a(X,ur),a(ur,Km),a(X,Zm),a(X,on),a(on,ef),a(X,af),a(X,cr),a(cr,sf),a(X,tf),u(e,Md,i),v(Os,e,i),u(e,Rd,i),v(As,e,i),u(e,Ud,i),u(e,K,i),a(K,nf),a(K,mr),a(mr,of),a(K,rf),a(K,fr),a(fr,lf),a(K,df),a(K,hr),a(hr,pf),a(K,uf),a(K,vr),a(vr,cf),a(K,mf),u(e,Fd,i),v(Ns,e,i),u(e,Bd,i),u(e,ye,i),a(ye,ff),a(ye,_r),a(_r,hf),a(ye,vf),a(ye,gr),a(gr,_f),a(ye,gf),u(e,Yd,i),v(Is,e,i),u(e,Vd,i),u(e,Z,i),a(Z,$f),a(Z,$r),a($r,Ef),a(Z,jf),a(Z,Ss),a(Ss,bf),a(Z,qf),a(Z,Er),a(Er,wf),a(Z,xf),a(Z,jr),a(jr,Df),a(Z,yf),u(e,Jd,i),v(Hs,e,i),u(e,Gd,i),u(e,ke,i),a(ke,kf),a(ke,br),a(br,Tf),a(ke,Cf),a(ke,qr),a(qr,Pf),a(ke,zf),u(e,Qd,i),v(Ls,e,i),u(e,Wd,i),v(Ms,e,i),u(e,Xd,i),u(e,rn,i),a(rn,Of),u(e,Kd,i),v(Rs,e,i),u(e,Zd,i),v(Us,e,i),u(e,ep,i),u(e,Te,i),a(Te,Af),a(Te,Fs),a(Fs,Nf),a(Te,If),a(Te,wr),a(wr,Sf),a(Te,Hf),u(e,ap,i),v(Bs,e,i),u(e,sp,i),u(e,Ce,i),a(Ce,Lf),a(Ce,xr),a(xr,Mf),a(Ce,Rf),a(Ce,Dr),a(Dr,Uf),a(Ce,Ff),u(e,tp,i),v(Ys,e,i),u(e,np,i),v(Vs,e,i),u(e,op,i),u(e,ln,i),a(ln,Bf),u(e,rp,i),u(e,ta,i),a(ta,ka),a(ka,yr),v(Js,yr,null),a(ta,Yf),a(ta,kr),a(kr,Vf),u(e,lp,i),u(e,dn,i),a(dn,Jf),u(e,ip,i),u(e,pn,i),a(pn,Gf),u(e,dp,i),v(Gs,e,i),u(e,pp,i),u(e,G,i),a(G,Qf),a(G,Tr),a(Tr,Wf),a(G,Xf),a(G,Cr),a(Cr,Kf),a(G,Zf),a(G,Pr),a(Pr,eh),a(G,ah),a(G,zr),a(zr,sh),a(G,th),a(G,Or),a(Or,nh),a(G,oh),u(e,up,i),v(Qs,e,i),u(e,cp,i),v(Ws,e,i),u(e,mp,i),u(e,Pe,i),a(Pe,rh),a(Pe,Ar),a(Ar,lh),a(Pe,ih),a(Pe,Nr),a(Nr,dh),a(Pe,ph),u(e,fp,i),v(Xs,e,i),u(e,hp,i),v(Ks,e,i),u(e,vp,i),u(e,un,i),a(un,uh),u(e,_p,i),v(Ta,e,i),u(e,gp,i),u(e,ze,i),a(ze,ch),a(ze,Ir),a(Ir,mh),a(ze,fh),a(ze,Sr),a(Sr,hh),a(ze,vh),u(e,$p,i),v(Zs,e,i),u(e,Ep,i),v(et,e,i),u(e,jp,i),u(e,cn,i),a(cn,_h),u(e,bp,i),v(Ca,e,i),u(e,qp,i),u(e,Pa,i),a(Pa,gh),a(Pa,Hr),a(Hr,$h),a(Pa,Eh),u(e,wp,i),v(at,e,i),u(e,xp,i),v(st,e,i),u(e,Dp,i),u(e,za,i),a(za,jh),a(za,Lr),a(Lr,bh),a(za,qh),u(e,yp,i),v(tt,e,i),u(e,kp,i),u(e,Oa,i),a(Oa,wh),a(Oa,Mr),a(Mr,xh),a(Oa,Dh),u(e,Tp,i),u(e,na,i),a(na,Aa),a(Aa,Rr),v(nt,Rr,null),a(na,yh),a(na,mn),a(mn,kh),a(mn,Ur),a(Ur,Th),u(e,Cp,i),u(e,ee,i),a(ee,Ch),a(ee,Fr),a(Fr,Ph),a(ee,zh),a(ee,Br),a(Br,Oh),a(ee,Ah),a(ee,Yr),a(Yr,Nh),a(ee,Ih),a(ee,Vr),a(Vr,Sh),a(ee,Hh),u(e,Pp,i),u(e,ae,i),a(ae,Lh),a(ae,Jr),a(Jr,Mh),a(ae,Rh),a(ae,Gr),a(Gr,Uh),a(ae,Fh),a(ae,Qr),a(Qr,Bh),a(ae,Yh),a(ae,Wr),a(Wr,Vh),a(ae,Jh),u(e,zp,i),v(ot,e,i),u(e,Op,i),u(e,de,i),a(de,Gh),a(de,Xr),a(Xr,Qh),a(de,Wh),a(de,Kr),a(Kr,Xh),a(de,Kh),a(de,Zr),a(Zr,Zh),a(de,ev),u(e,Ap,i),u(e,pe,i),a(pe,av),a(pe,el),a(el,sv),a(pe,tv),a(pe,al),a(al,nv),a(pe,ov),a(pe,fn),a(fn,rv),a(pe,lv),u(e,Np,i),v(rt,e,i),u(e,Ip,i),u(e,ue,i),a(ue,iv),a(ue,hn),a(hn,dv),a(ue,pv),a(ue,sl),a(sl,uv),a(ue,cv),a(ue,tl),a(tl,mv),a(ue,fv),u(e,Sp,i),v(lt,e,i),u(e,Hp,i),u(e,Na,i),a(Na,hv),a(Na,nl),a(nl,vv),a(Na,_v),u(e,Lp,i),v(Ia,e,i),u(e,Mp,i),u(e,vn,i),a(vn,gv),u(e,Rp,i),u(e,Sa,i),a(Sa,ol),a(ol,oa),a(oa,_n),a(_n,$v),a(oa,Ev),a(oa,gn),a(gn,jv),a(oa,bv),a(oa,$n),a($n,qv),a(Sa,wv),a(Sa,it),a(it,ra),a(ra,En),a(En,rl),a(rl,xv),a(ra,Dv),a(ra,jn),a(jn,yv),a(ra,kv),a(ra,bn),a(bn,Tv),a(it,Cv),a(it,la),a(la,qn),a(qn,ll),a(ll,Pv),a(la,zv),a(la,wn),a(wn,Ov),a(la,Av),a(la,xn),a(xn,Nv),u(e,Up,i),u(e,Oe,i),a(Oe,Iv),a(Oe,il),a(il,Sv),a(Oe,Hv),a(Oe,dl),a(dl,Lv),a(Oe,Mv),u(e,Fp,i),u(e,Dn,i),a(Dn,Rv),u(e,Bp,i),u(e,$e,i),a($e,pl),a(pl,Uv),a($e,Fv),a($e,ul),a(ul,Bv),a($e,Yv),a($e,cl),a(cl,Vv),a($e,Jv),u(e,Yp,i),v(dt,e,i),u(e,Vp,i),u(e,yn,i),a(yn,Gv),u(e,Jp,i),u(e,Ha,i),a(Ha,ml),a(ml,ia),a(ia,kn),a(kn,Qv),a(ia,Wv),a(ia,Tn),a(Tn,Xv),a(ia,Kv),a(ia,Cn),a(Cn,Zv),a(Ha,e_),a(Ha,Ee),a(Ee,da),a(da,Pn),a(Pn,fl),a(fl,a_),a(da,s_),a(da,zn),a(zn,t_),a(da,n_),a(da,On),a(On,o_),a(Ee,r_),a(Ee,pa),a(pa,An),a(An,hl),a(hl,l_),a(pa,i_),a(pa,Nn),a(Nn,d_),a(pa,p_),a(pa,In),a(In,u_),a(Ee,c_),a(Ee,ua),a(ua,La),a(La,vl),a(vl,m_),a(La,f_),a(La,_l),a(_l,h_),a(ua,v_),a(ua,Sn),a(Sn,__),a(ua,g_),a(ua,Hn),a(Hn,$_),a(Ee,E_),a(Ee,ca),a(ca,Ma),a(Ma,gl),a(gl,j_),a(Ma,b_),a(Ma,$l),a($l,q_),a(ca,w_),a(ca,Ln),a(Ln,x_),a(ca,D_),a(ca,Mn),a(Mn,y_),u(e,Gp,i),u(e,ce,i),a(ce,k_),a(ce,El),a(El,T_),a(ce,C_),a(ce,jl),a(jl,P_),a(ce,z_),a(ce,bl),a(bl,O_),a(ce,A_),u(e,Qp,i),v(Ra,e,i),u(e,Wp,i),u(e,me,i),a(me,N_),a(me,ql),a(ql,I_),a(me,S_),a(me,wl),a(wl,H_),a(me,L_),a(me,Rn),a(Rn,M_),a(me,R_),u(e,Xp,i),v(Ua,e,i),u(e,Kp,i),u(e,Ae,i),a(Ae,U_),a(Ae,xl),a(xl,F_),a(Ae,B_),a(Ae,Dl),a(Dl,Y_),a(Ae,V_),u(e,Zp,i),v(pt,e,i),u(e,eu,i),u(e,Fa,i),a(Fa,J_),a(Fa,yl),a(yl,G_),a(Fa,Q_),u(e,au,i),v(ut,e,i),u(e,su,i),v(ct,e,i),u(e,tu,i),u(e,Un,i),a(Un,W_),u(e,nu,i),v(mt,e,i),u(e,ou,i),v(ft,e,i),u(e,ru,i),u(e,Ba,i),a(Ba,X_),a(Ba,Ya),a(Ya,K_),a(Ya,kl),a(kl,Z_),a(Ba,e2),u(e,lu,i),u(e,se,i),a(se,a2),a(se,Tl),a(Tl,s2),a(se,t2),a(se,Cl),a(Cl,n2),a(se,o2),a(se,Pl),a(Pl,r2),a(se,l2),a(se,zl),a(zl,i2),a(se,d2),u(e,iu,i),v(ht,e,i),u(e,du,i),u(e,Fn,i),a(Fn,p2),u(e,pu,i),v(vt,e,i),u(e,uu,i),v(_t,e,i),u(e,cu,i),u(e,Ne,i),a(Ne,u2),a(Ne,Ol),a(Ol,c2),a(Ne,m2),a(Ne,Al),a(Al,f2),a(Ne,h2),u(e,mu,i),v(gt,e,i),u(e,fu,i),u(e,Va,i),a(Va,v2),a(Va,Nl),a(Nl,_2),a(Va,g2),u(e,hu,i),v($t,e,i),u(e,vu,i),v(Et,e,i),u(e,_u,i),u(e,Bn,i),a(Bn,$2),u(e,gu,i),u(e,Ja,i),a(Ja,E2),a(Ja,Il),a(Il,j2),a(Ja,b2),u(e,$u,i),u(e,ma,i),a(ma,Ga),a(Ga,Sl),v(jt,Sl,null),a(ma,q2),a(ma,fa),a(fa,w2),a(fa,Hl),a(Hl,x2),a(fa,D2),a(fa,Ll),a(Ll,y2),a(fa,k2),u(e,Eu,i),v(bt,e,i),u(e,ju,i),u(e,te,i),a(te,T2),a(te,Ml),a(Ml,C2),a(te,P2),a(te,Rl),a(Rl,z2),a(te,O2),a(te,Ul),a(Ul,A2),a(te,N2),a(te,Fl),a(Fl,I2),a(te,S2),u(e,bu,i),v(qt,e,i),u(e,qu,i),u(e,Qa,i),a(Qa,H2),a(Qa,Bl),a(Bl,L2),a(Qa,M2),u(e,wu,i),v(wt,e,i),u(e,xu,i),u(e,Ie,i),a(Ie,Yl),a(Yl,I),a(I,Du),a(I,R2),a(I,Vl),a(Vl,U2),a(I,F2),a(I,Jl),a(Jl,B2),a(I,Y2),a(I,Gl),a(Gl,V2),a(I,J2),a(I,Ql),a(Ql,G2),a(I,Q2),a(I,Wl),a(Wl,W2),a(I,X2),a(I,Xl),a(Xl,K2),a(I,Z2),a(I,Kl),a(Kl,eg),a(I,ag),a(I,Zl),a(Zl,sg),a(Ie,tg),a(Ie,ha),a(ha,S),a(S,ei),a(ei,ng),a(S,og),a(S,ai),a(ai,rg),a(S,lg),a(S,si),a(si,ig),a(S,dg),a(S,ti),a(ti,pg),a(S,ug),a(S,ni),a(ni,cg),a(S,mg),a(S,oi),a(oi,fg),a(S,hg),a(S,ri),a(ri,vg),a(S,_g),a(S,li),a(li,gg),a(S,$g),a(S,ii),a(ii,Eg),a(ha,jg),a(ha,H),a(H,di),a(di,bg),a(H,qg),a(H,pi),a(pi,wg),a(H,xg),a(H,ui),a(ui,Dg),a(H,yg),a(H,ci),a(ci,kg),a(H,Tg),a(H,mi),a(mi,Cg),a(H,Pg),a(H,fi),a(fi,zg),a(H,Og),a(H,hi),a(hi,Ag),a(H,Ng),a(H,vi),a(vi,Ig),a(H,Sg),a(H,_i),a(_i,Hg),a(ha,Lg),a(ha,L),a(L,gi),a(gi,Mg),a(L,Rg),a(L,$i),a($i,Ug),a(L,Fg),a(L,Ei),a(Ei,Bg),a(L,Yg),a(L,ji),a(ji,Vg),a(L,Jg),a(L,bi),a(bi,Gg),a(L,Qg),a(L,qi),a(qi,Wg),a(L,Xg),a(L,wi),a(wi,Kg),a(L,Zg),a(L,xi),a(xi,e1),a(L,a1),a(L,Di),a(Di,s1),u(e,yu,i),u(e,Se,i),a(Se,t1),a(Se,yi),a(yi,n1),a(Se,o1),a(Se,ki),a(ki,r1),a(Se,l1),u(e,ku,i),v(xt,e,i),u(e,Tu,i),v(Wa,e,i),u(e,Cu,i),u(e,Xa,i),a(Xa,i1),a(Xa,Ti),a(Ti,d1),a(Xa,p1),u(e,Pu,i),v(Dt,e,i),u(e,zu,i),u(e,He,i),a(He,Ci),a(Ci,Le),a(Le,Ou),a(Le,u1),a(Le,Pi),a(Pi,c1),a(Le,m1),a(Le,zi),a(zi,f1),a(He,h1),a(He,oe),a(oe,va),a(va,Oi),a(Oi,v1),a(va,_1),a(va,Ai),a(Ai,g1),a(va,$1),a(va,Ni),a(Ni,E1),a(oe,j1),a(oe,_a),a(_a,Ii),a(Ii,b1),a(_a,q1),a(_a,Si),a(Si,w1),a(_a,x1),a(_a,Hi),a(Hi,D1),a(oe,y1),a(oe,ga),a(ga,Li),a(Li,k1),a(ga,T1),a(ga,Mi),a(Mi,C1),a(ga,P1),a(ga,Ri),a(Ri,z1),a(oe,O1),a(oe,$a),a($a,Ui),a(Ui,A1),a($a,N1),a($a,Fi),a(Fi,I1),a($a,S1),a($a,Bi),a(Bi,H1),a(oe,L1),a(oe,Ea),a(Ea,Yi),a(Yi,M1),a(Ea,R1),a(Ea,Vi),a(Vi,U1),a(Ea,F1),a(Ea,Ji),a(Ji,B1),u(e,Au,i),u(e,Me,i),a(Me,Y1),a(Me,Gi),a(Gi,V1),a(Me,J1),a(Me,Qi),a(Qi,G1),a(Me,Q1),u(e,Nu,i),v(yt,e,i),u(e,Iu,i),v(kt,e,i),u(e,Su,i),v(Ka,e,i),u(e,Hu,i),u(e,fe,i),a(fe,W1),a(fe,Wi),a(Wi,X1),a(fe,K1),a(fe,Xi),a(Xi,Z1),a(fe,e$),a(fe,Ki),a(Ki,a$),a(fe,s$),u(e,Lu,i),v(Tt,e,i),u(e,Mu,i),u(e,ja,i),a(ja,Za),a(Za,Zi),v(Ct,Zi,null),a(ja,t$),a(ja,ed),a(ed,n$),u(e,Ru,i),u(e,Yn,i),a(Yn,o$),u(e,Uu,i),u(e,Q,i),a(Q,r$),a(Q,ad),a(ad,l$),a(Q,i$),a(Q,sd),a(sd,d$),a(Q,p$),a(Q,td),a(td,u$),a(Q,c$),a(Q,nd),a(nd,m$),a(Q,f$),a(Q,od),a(od,h$),a(Q,v$),u(e,Fu,i),v(Pt,e,i),u(e,Bu,i),v(zt,e,i),u(e,Yu,i),u(e,es,i),a(es,_$),a(es,Vn),a(Vn,g$),a(es,$$),u(e,Vu,i),u(e,ba,i),a(ba,as),a(as,rd),v(Ot,rd,null),a(ba,E$),a(ba,ld),a(ld,j$),u(e,Ju,i),v(At,e,i),u(e,Gu,i),u(e,Jn,i),a(Jn,b$),u(e,Qu,i),u(e,ss,i),a(ss,id),a(id,Nt),a(Nt,Gn),a(Gn,q$),a(Nt,w$),a(Nt,Qn),a(Qn,x$),a(ss,D$),a(ss,qa),a(qa,It),a(It,Wn),a(Wn,y$),a(It,k$),a(It,Xn),a(Xn,dd),a(dd,T$),a(qa,C$),a(qa,St),a(St,Kn),a(Kn,P$),a(St,z$),a(St,Zn),a(Zn,pd),a(pd,O$),a(qa,A$),a(qa,Ht),a(Ht,eo),a(eo,N$),a(Ht,I$),a(Ht,ao),a(ao,ud),a(ud,S$),u(e,Wu,i),u(e,so,i),a(so,H$),u(e,Xu,i),v(Lt,e,i),u(e,Ku,i),u(e,to,i),a(to,L$),u(e,Zu,i),v(Mt,e,i),u(e,ec,i),u(e,he,i),a(he,M$),a(he,cd),a(cd,R$),a(he,U$),a(he,md),a(md,F$),a(he,B$),a(he,fd),a(fd,Y$),a(he,V$),u(e,ac,i),u(e,ts,i),a(ts,J$),a(ts,hd),a(hd,G$),a(ts,Q$),u(e,sc,i),v(Rt,e,i),u(e,tc,i),v(Ut,e,i),u(e,nc,i),u(e,ns,i),a(ns,W$),a(ns,vd),a(vd,X$),a(ns,K$),u(e,oc,i),v(Ft,e,i),u(e,rc,i),u(e,os,i),a(os,Z$),a(os,Bt),a(Bt,eE),a(os,aE),u(e,lc,i),v(Yt,e,i),u(e,ic,i),v(Vt,e,i),u(e,dc,i),u(e,rs,i),a(rs,sE),a(rs,no),a(no,tE),a(rs,nE),u(e,pc,i),v(Jt,e,i),u(e,uc,i),u(e,oo,i),a(oo,oE),u(e,cc,i),u(e,ls,i),a(ls,Gt),a(Gt,rE),a(Gt,ro),a(ro,lE),a(Gt,iE),a(ls,dE),a(ls,wa),a(wa,pE),a(wa,_d),a(_d,uE),a(wa,cE),a(wa,lo),a(lo,mE),a(wa,fE),u(e,mc,i),u(e,io,i),a(io,hE),fc=!0},p(e,[i]){const Qt={};i&2&&(Qt.$$scope={dirty:i,ctx:e}),ya.$set(Qt);const gd={};i&2&&(gd.$$scope={dirty:i,ctx:e}),Ta.$set(gd);const $d={};i&2&&($d.$$scope={dirty:i,ctx:e}),Ca.$set($d);const Ed={};i&2&&(Ed.$$scope={dirty:i,ctx:e}),Ia.$set(Ed);const jd={};i&2&&(jd.$$scope={dirty:i,ctx:e}),Ra.$set(jd);const Wt={};i&2&&(Wt.$$scope={dirty:i,ctx:e}),Ua.$set(Wt);const bd={};i&2&&(bd.$$scope={dirty:i,ctx:e}),Wa.$set(bd);const qd={};i&2&&(qd.$$scope={dirty:i,ctx:e}),Ka.$set(qd)},i(e){fc||(_(b.$$.fragment,e),_(z.$$.fragment,e),_(O.$$.fragment,e),_(ne.$$.fragment,e),_(ws.$$.fragment,e),_(xs.$$.fragment,e),_(Ds.$$.fragment,e),_(ys.$$.fragment,e),_(Cs.$$.fragment,e),_(Ps.$$.fragment,e),_(zs.$$.fragment,e),_(ya.$$.fragment,e),_(Os.$$.fragment,e),_(As.$$.fragment,e),_(Ns.$$.fragment,e),_(Is.$$.fragment,e),_(Hs.$$.fragment,e),_(Ls.$$.fragment,e),_(Ms.$$.fragment,e),_(Rs.$$.fragment,e),_(Us.$$.fragment,e),_(Bs.$$.fragment,e),_(Ys.$$.fragment,e),_(Vs.$$.fragment,e),_(Js.$$.fragment,e),_(Gs.$$.fragment,e),_(Qs.$$.fragment,e),_(Ws.$$.fragment,e),_(Xs.$$.fragment,e),_(Ks.$$.fragment,e),_(Ta.$$.fragment,e),_(Zs.$$.fragment,e),_(et.$$.fragment,e),_(Ca.$$.fragment,e),_(at.$$.fragment,e),_(st.$$.fragment,e),_(tt.$$.fragment,e),_(nt.$$.fragment,e),_(ot.$$.fragment,e),_(rt.$$.fragment,e),_(lt.$$.fragment,e),_(Ia.$$.fragment,e),_(dt.$$.fragment,e),_(Ra.$$.fragment,e),_(Ua.$$.fragment,e),_(pt.$$.fragment,e),_(ut.$$.fragment,e),_(ct.$$.fragment,e),_(mt.$$.fragment,e),_(ft.$$.fragment,e),_(ht.$$.fragment,e),_(vt.$$.fragment,e),_(_t.$$.fragment,e),_(gt.$$.fragment,e),_($t.$$.fragment,e),_(Et.$$.fragment,e),_(jt.$$.fragment,e),_(bt.$$.fragment,e),_(qt.$$.fragment,e),_(wt.$$.fragment,e),_(xt.$$.fragment,e),_(Wa.$$.fragment,e),_(Dt.$$.fragment,e),_(yt.$$.fragment,e),_(kt.$$.fragment,e),_(Ka.$$.fragment,e),_(Tt.$$.fragment,e),_(Ct.$$.fragment,e),_(Pt.$$.fragment,e),_(zt.$$.fragment,e),_(Ot.$$.fragment,e),_(At.$$.fragment,e),_(Lt.$$.fragment,e),_(Mt.$$.fragment,e),_(Rt.$$.fragment,e),_(Ut.$$.fragment,e),_(Ft.$$.fragment,e),_(Yt.$$.fragment,e),_(Vt.$$.fragment,e),_(Jt.$$.fragment,e),fc=!0)},o(e){g(b.$$.fragment,e),g(z.$$.fragment,e),g(O.$$.fragment,e),g(ne.$$.fragment,e),g(ws.$$.fragment,e),g(xs.$$.fragment,e),g(Ds.$$.fragment,e),g(ys.$$.fragment,e),g(Cs.$$.fragment,e),g(Ps.$$.fragment,e),g(zs.$$.fragment,e),g(ya.$$.fragment,e),g(Os.$$.fragment,e),g(As.$$.fragment,e),g(Ns.$$.fragment,e),g(Is.$$.fragment,e),g(Hs.$$.fragment,e),g(Ls.$$.fragment,e),g(Ms.$$.fragment,e),g(Rs.$$.fragment,e),g(Us.$$.fragment,e),g(Bs.$$.fragment,e),g(Ys.$$.fragment,e),g(Vs.$$.fragment,e),g(Js.$$.fragment,e),g(Gs.$$.fragment,e),g(Qs.$$.fragment,e),g(Ws.$$.fragment,e),g(Xs.$$.fragment,e),g(Ks.$$.fragment,e),g(Ta.$$.fragment,e),g(Zs.$$.fragment,e),g(et.$$.fragment,e),g(Ca.$$.fragment,e),g(at.$$.fragment,e),g(st.$$.fragment,e),g(tt.$$.fragment,e),g(nt.$$.fragment,e),g(ot.$$.fragment,e),g(rt.$$.fragment,e),g(lt.$$.fragment,e),g(Ia.$$.fragment,e),g(dt.$$.fragment,e),g(Ra.$$.fragment,e),g(Ua.$$.fragment,e),g(pt.$$.fragment,e),g(ut.$$.fragment,e),g(ct.$$.fragment,e),g(mt.$$.fragment,e),g(ft.$$.fragment,e),g(ht.$$.fragment,e),g(vt.$$.fragment,e),g(_t.$$.fragment,e),g(gt.$$.fragment,e),g($t.$$.fragment,e),g(Et.$$.fragment,e),g(jt.$$.fragment,e),g(bt.$$.fragment,e),g(qt.$$.fragment,e),g(wt.$$.fragment,e),g(xt.$$.fragment,e),g(Wa.$$.fragment,e),g(Dt.$$.fragment,e),g(yt.$$.fragment,e),g(kt.$$.fragment,e),g(Ka.$$.fragment,e),g(Tt.$$.fragment,e),g(Ct.$$.fragment,e),g(Pt.$$.fragment,e),g(zt.$$.fragment,e),g(Ot.$$.fragment,e),g(At.$$.fragment,e),g(Lt.$$.fragment,e),g(Mt.$$.fragment,e),g(Rt.$$.fragment,e),g(Ut.$$.fragment,e),g(Ft.$$.fragment,e),g(Yt.$$.fragment,e),g(Vt.$$.fragment,e),g(Jt.$$.fragment,e),fc=!1},d(e){s(c),e&&s(T),e&&s(j),$(b),e&&s(w),$(z,e),e&&s(k),e&&s(P),e&&s(N),$(O,e),e&&s(ge),e&&s(R),$(ne),e&&s(xa),e&&s(U),e&&s(js),e&&s(je),e&&s(wd),e&&s(be),e&&s(xd),$(ws,e),e&&s(Dd),e&&s(le),e&&s(yd),$(xs,e),e&&s(kd),e&&s(qe),e&&s(Td),$(Ds,e),e&&s(Cd),$(ys,e),e&&s(Pd),e&&s(ie),e&&s(zd),e&&s(we),e&&s(Od),e&&s(xe),e&&s(Ad),$(Cs,e),e&&s(Nd),e&&s(De),e&&s(Id),$(Ps,e),e&&s(Sd),$(zs,e),e&&s(Hd),$(ya,e),e&&s(Ld),e&&s(X),e&&s(Md),$(Os,e),e&&s(Rd),$(As,e),e&&s(Ud),e&&s(K),e&&s(Fd),$(Ns,e),e&&s(Bd),e&&s(ye),e&&s(Yd),$(Is,e),e&&s(Vd),e&&s(Z),e&&s(Jd),$(Hs,e),e&&s(Gd),e&&s(ke),e&&s(Qd),$(Ls,e),e&&s(Wd),$(Ms,e),e&&s(Xd),e&&s(rn),e&&s(Kd),$(Rs,e),e&&s(Zd),$(Us,e),e&&s(ep),e&&s(Te),e&&s(ap),$(Bs,e),e&&s(sp),e&&s(Ce),e&&s(tp),$(Ys,e),e&&s(np),$(Vs,e),e&&s(op),e&&s(ln),e&&s(rp),e&&s(ta),$(Js),e&&s(lp),e&&s(dn),e&&s(ip),e&&s(pn),e&&s(dp),$(Gs,e),e&&s(pp),e&&s(G),e&&s(up),$(Qs,e),e&&s(cp),$(Ws,e),e&&s(mp),e&&s(Pe),e&&s(fp),$(Xs,e),e&&s(hp),$(Ks,e),e&&s(vp),e&&s(un),e&&s(_p),$(Ta,e),e&&s(gp),e&&s(ze),e&&s($p),$(Zs,e),e&&s(Ep),$(et,e),e&&s(jp),e&&s(cn),e&&s(bp),$(Ca,e),e&&s(qp),e&&s(Pa),e&&s(wp),$(at,e),e&&s(xp),$(st,e),e&&s(Dp),e&&s(za),e&&s(yp),$(tt,e),e&&s(kp),e&&s(Oa),e&&s(Tp),e&&s(na),$(nt),e&&s(Cp),e&&s(ee),e&&s(Pp),e&&s(ae),e&&s(zp),$(ot,e),e&&s(Op),e&&s(de),e&&s(Ap),e&&s(pe),e&&s(Np),$(rt,e),e&&s(Ip),e&&s(ue),e&&s(Sp),$(lt,e),e&&s(Hp),e&&s(Na),e&&s(Lp),$(Ia,e),e&&s(Mp),e&&s(vn),e&&s(Rp),e&&s(Sa),e&&s(Up),e&&s(Oe),e&&s(Fp),e&&s(Dn),e&&s(Bp),e&&s($e),e&&s(Yp),$(dt,e),e&&s(Vp),e&&s(yn),e&&s(Jp),e&&s(Ha),e&&s(Gp),e&&s(ce),e&&s(Qp),$(Ra,e),e&&s(Wp),e&&s(me),e&&s(Xp),$(Ua,e),e&&s(Kp),e&&s(Ae),e&&s(Zp),$(pt,e),e&&s(eu),e&&s(Fa),e&&s(au),$(ut,e),e&&s(su),$(ct,e),e&&s(tu),e&&s(Un),e&&s(nu),$(mt,e),e&&s(ou),$(ft,e),e&&s(ru),e&&s(Ba),e&&s(lu),e&&s(se),e&&s(iu),$(ht,e),e&&s(du),e&&s(Fn),e&&s(pu),$(vt,e),e&&s(uu),$(_t,e),e&&s(cu),e&&s(Ne),e&&s(mu),$(gt,e),e&&s(fu),e&&s(Va),e&&s(hu),$($t,e),e&&s(vu),$(Et,e),e&&s(_u),e&&s(Bn),e&&s(gu),e&&s(Ja),e&&s($u),e&&s(ma),$(jt),e&&s(Eu),$(bt,e),e&&s(ju),e&&s(te),e&&s(bu),$(qt,e),e&&s(qu),e&&s(Qa),e&&s(wu),$(wt,e),e&&s(xu),e&&s(Ie),e&&s(yu),e&&s(Se),e&&s(ku),$(xt,e),e&&s(Tu),$(Wa,e),e&&s(Cu),e&&s(Xa),e&&s(Pu),$(Dt,e),e&&s(zu),e&&s(He),e&&s(Au),e&&s(Me),e&&s(Nu),$(yt,e),e&&s(Iu),$(kt,e),e&&s(Su),$(Ka,e),e&&s(Hu),e&&s(fe),e&&s(Lu),$(Tt,e),e&&s(Mu),e&&s(ja),$(Ct),e&&s(Ru),e&&s(Yn),e&&s(Uu),e&&s(Q),e&&s(Fu),$(Pt,e),e&&s(Bu),$(zt,e),e&&s(Yu),e&&s(es),e&&s(Vu),e&&s(ba),$(Ot),e&&s(Ju),$(At,e),e&&s(Gu),e&&s(Jn),e&&s(Qu),e&&s(ss),e&&s(Wu),e&&s(so),e&&s(Xu),$(Lt,e),e&&s(Ku),e&&s(to),e&&s(Zu),$(Mt,e),e&&s(ec),e&&s(he),e&&s(ac),e&&s(ts),e&&s(sc),$(Rt,e),e&&s(tc),$(Ut,e),e&&s(nc),e&&s(ns),e&&s(oc),$(Ft,e),e&&s(rc),e&&s(os),e&&s(lc),$(Yt,e),e&&s(ic),$(Vt,e),e&&s(dc),e&&s(rs),e&&s(pc),$(Jt,e),e&&s(uc),e&&s(oo),e&&s(cc),e&&s(ls),e&&s(mc),e&&s(io)}}}const w3={local:"es-momento-de-subdividir",sections:[{local:"subdivdiendo-nuestros-datos",title:"Subdivdiendo nuestros datos"},{local:"creando-nuevas-columnas",title:"Creando nuevas columnas"},{local:"los-superpoderes-del-mtodo-map",title:"Los superpoderes del m\xE9todo `map()`"},{local:"de-datasets-a-dataframes-y-viceversa",title:"De `Dataset`s a `DataFrame`s y viceversa"},{local:"creando-un-conjunto-de-validacin",title:"Creando un conjunto de validaci\xF3n"},{local:"saving-a-dataset",title:"Saving a dataset"}],title:"Es momento de subdividir"};function x3(M){return m3(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class z3 extends d3{constructor(c){super();p3(this,c,x3,q3,u3,{})}}export{z3 as default,w3 as metadata};
