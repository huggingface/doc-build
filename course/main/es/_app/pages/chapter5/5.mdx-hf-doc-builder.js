import{S as Sc,i as Uc,s as zc,e as n,k as p,w as b,t,M as Lc,c as o,d as a,m as c,a as i,x as v,h as l,b as m,N as Ga,G as e,g as u,y as x,q as j,o as $,B as q,v as Mc}from"../../chunks/vendor-hf-doc-builder.js";import{T as ra}from"../../chunks/Tip-hf-doc-builder.js";import{Y as Fc}from"../../chunks/Youtube-hf-doc-builder.js";import{I as Ia}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as A}from"../../chunks/CodeBlock-hf-doc-builder.js";import{C as Bc}from"../../chunks/CourseFloatingBanner-hf-doc-builder.js";function Vc(S){let d,D,h,E,w,f,O,k;return{c(){d=n("p"),D=t("\u270F\uFE0F "),h=n("strong"),E=t("\xA1Int\xE9ntalo!"),w=t(" Haz clic en algunas de las URL en el "),f=n("em"),O=t("payload"),k=t(" JSON de arriba para explorar la informaci\xF3n que est\xE1 enlazada al issue de GitHub.")},l(g){d=o(g,"P",{});var _=i(d);D=l(_,"\u270F\uFE0F "),h=o(_,"STRONG",{});var H=i(h);E=l(H,"\xA1Int\xE9ntalo!"),H.forEach(a),w=l(_," Haz clic en algunas de las URL en el "),f=o(_,"EM",{});var y=i(f);O=l(y,"payload"),y.forEach(a),k=l(_," JSON de arriba para explorar la informaci\xF3n que est\xE1 enlazada al issue de GitHub."),_.forEach(a)},m(g,_){u(g,d,_),e(d,D),e(d,h),e(h,E),e(d,w),e(d,f),e(f,O),e(d,k)},d(g){g&&a(d)}}}function Qc(S){let d,D,h,E,w,f,O,k,g,_,H,y;return{c(){d=n("p"),D=t("\u26A0\uFE0F No compartas un cuaderno que contenga tu "),h=n("code"),E=t("GITHUB_TOKEN"),w=t(". Te recomendamos eliminar la \xFAltima celda una vez la has ejecutado para evitar filtrar accidentalmente esta informaci\xF3n. A\xFAn mejor, guarda el token en un archivo "),f=n("em"),O=t(".env"),k=t(" y usa la librer\xEDa "),g=n("a"),_=n("code"),H=t("python-dotenv"),y=t(" para cargarla autom\xE1ticamente como una variable de ambiente."),this.h()},l(P){d=o(P,"P",{});var T=i(d);D=l(T,"\u26A0\uFE0F No compartas un cuaderno que contenga tu "),h=o(T,"CODE",{});var N=i(h);E=l(N,"GITHUB_TOKEN"),N.forEach(a),w=l(T,". Te recomendamos eliminar la \xFAltima celda una vez la has ejecutado para evitar filtrar accidentalmente esta informaci\xF3n. A\xFAn mejor, guarda el token en un archivo "),f=o(T,"EM",{});var C=i(f);O=l(C,".env"),C.forEach(a),k=l(T," y usa la librer\xEDa "),g=o(T,"A",{href:!0,rel:!0});var V=i(g);_=o(V,"CODE",{});var U=i(_);H=l(U,"python-dotenv"),U.forEach(a),V.forEach(a),y=l(T," para cargarla autom\xE1ticamente como una variable de ambiente."),T.forEach(a),this.h()},h(){m(g,"href","https://github.com/theskumar/python-dotenv"),m(g,"rel","nofollow")},m(P,T){u(P,d,T),e(d,D),e(d,h),e(h,E),e(d,w),e(d,f),e(f,O),e(d,k),e(d,g),e(g,_),e(_,H),e(d,y)},d(P){P&&a(d)}}}function Jc(S){let d,D,h,E,w,f,O,k,g,_,H,y,P,T,N,C,V,U,R,Q;return{c(){d=n("p"),D=t("\u270F\uFE0F "),h=n("strong"),E=t("\xA1Int\xE9ntalo!"),w=t(" Calcula el tiempo promedio que toma cerrar issues en \u{1F917} Datasets. La funci\xF3n "),f=n("code"),O=t("Dataset.filter()"),k=t(" te ser\xE1 \xFAtil para filtrar los pull requests y los issues abiertos, y puedes usar la funci\xF3n "),g=n("code"),_=t("Dataset.set_format()"),H=t(" para convertir el dataset a un "),y=n("code"),P=t("DataFrame"),T=t(" para poder manipular f\xE1cilmente los timestamps de "),N=n("code"),C=t("created_at"),V=t(" y "),U=n("code"),R=t("closed_at"),Q=t(". Para puntos extra, calcula el tiempo promedio que toma cerrar pull requests.")},l(cs){d=o(cs,"P",{});var G=i(d);D=l(G,"\u270F\uFE0F "),h=o(G,"STRONG",{});var K=i(h);E=l(K,"\xA1Int\xE9ntalo!"),K.forEach(a),w=l(G," Calcula el tiempo promedio que toma cerrar issues en \u{1F917} Datasets. La funci\xF3n "),f=o(G,"CODE",{});var na=i(f);O=l(na,"Dataset.filter()"),na.forEach(a),k=l(G," te ser\xE1 \xFAtil para filtrar los pull requests y los issues abiertos, y puedes usar la funci\xF3n "),g=o(G,"CODE",{});var xs=i(g);_=l(xs,"Dataset.set_format()"),xs.forEach(a),H=l(G," para convertir el dataset a un "),y=o(G,"CODE",{});var oa=i(y);P=l(oa,"DataFrame"),oa.forEach(a),T=l(G," para poder manipular f\xE1cilmente los timestamps de "),N=o(G,"CODE",{});var ia=i(N);C=l(ia,"created_at"),ia.forEach(a),V=l(G," y "),U=o(G,"CODE",{});var ua=i(U);R=l(ua,"closed_at"),ua.forEach(a),Q=l(G,". Para puntos extra, calcula el tiempo promedio que toma cerrar pull requests."),G.forEach(a)},m(cs,G){u(cs,d,G),e(d,D),e(d,h),e(h,E),e(d,w),e(d,f),e(f,O),e(d,k),e(d,g),e(g,_),e(d,H),e(d,y),e(y,P),e(d,T),e(d,N),e(N,C),e(d,V),e(d,U),e(U,R),e(d,Q)},d(cs){cs&&a(d)}}}function Zc(S){let d,D,h,E,w,f,O,k,g,_,H;return{c(){d=n("p"),D=t("\u270F\uFE0F "),h=n("strong"),E=t("\xA1Int\xE9ntalo!"),w=t(" Usa tu nombre de usuario de Hugging Face Hub para obtener un token y crear un repositorio vac\xEDo llamado "),f=n("code"),O=t("girhub-issues"),k=t(". Recuerda "),g=n("strong"),_=t("nunca guardar tus credenciales"),H=t(" en Colab o cualquier otro repositorio, ya que esta informaci\xF3n puede ser aprovechada por terceros.")},l(y){d=o(y,"P",{});var P=i(d);D=l(P,"\u270F\uFE0F "),h=o(P,"STRONG",{});var T=i(h);E=l(T,"\xA1Int\xE9ntalo!"),T.forEach(a),w=l(P," Usa tu nombre de usuario de Hugging Face Hub para obtener un token y crear un repositorio vac\xEDo llamado "),f=o(P,"CODE",{});var N=i(f);O=l(N,"girhub-issues"),N.forEach(a),k=l(P,". Recuerda "),g=o(P,"STRONG",{});var C=i(g);_=l(C,"nunca guardar tus credenciales"),C.forEach(a),H=l(P," en Colab o cualquier otro repositorio, ya que esta informaci\xF3n puede ser aprovechada por terceros."),P.forEach(a)},m(y,P){u(y,d,P),e(d,D),e(d,h),e(h,E),e(d,w),e(d,f),e(f,O),e(d,k),e(d,g),e(g,_),e(d,H)},d(y){y&&a(d)}}}function Kc(S){let d,D,h,E,w,f,O,k;return{c(){d=n("p"),D=t("\u{1F4A1} Tambi\xE9n puedes subir un dataset al Hub de Hugging Face directamente desde la terminal usando "),h=n("code"),E=t("huggingface-cli"),w=t(" y un poco de Git. Revisa la "),f=n("a"),O=t("gu\xEDa de \u{1F917} Datasets"),k=t(" para m\xE1s detalles sobre c\xF3mo hacerlo."),this.h()},l(g){d=o(g,"P",{});var _=i(d);D=l(_,"\u{1F4A1} Tambi\xE9n puedes subir un dataset al Hub de Hugging Face directamente desde la terminal usando "),h=o(_,"CODE",{});var H=i(h);E=l(H,"huggingface-cli"),H.forEach(a),w=l(_," y un poco de Git. Revisa la "),f=o(_,"A",{href:!0,rel:!0});var y=i(f);O=l(y,"gu\xEDa de \u{1F917} Datasets"),y.forEach(a),k=l(_," para m\xE1s detalles sobre c\xF3mo hacerlo."),_.forEach(a),this.h()},h(){m(f,"href","https://huggingface.co/docs/datasets/share.html#add-a-community-dataset"),m(f,"rel","nofollow")},m(g,_){u(g,d,_),e(d,D),e(d,h),e(h,E),e(d,w),e(d,f),e(f,O),e(d,k)},d(g){g&&a(d)}}}function Xc(S){let d,D,h,E,w,f,O,k,g,_,H,y,P,T;return{c(){d=n("p"),D=t("\u270F\uFE0F "),h=n("strong"),E=t("\xA1Int\xE9ntalo!"),w=t(" Usa la aplicaci\xF3n "),f=n("code"),O=t("dataset-tagging"),k=t(" y la "),g=n("a"),_=t("gu\xEDa de \u{1F917} Datasets"),H=t(" para completar el archivo "),y=n("em"),P=t("README.md"),T=t(" para tu dataset de issues de GitHub."),this.h()},l(N){d=o(N,"P",{});var C=i(d);D=l(C,"\u270F\uFE0F "),h=o(C,"STRONG",{});var V=i(h);E=l(V,"\xA1Int\xE9ntalo!"),V.forEach(a),w=l(C," Usa la aplicaci\xF3n "),f=o(C,"CODE",{});var U=i(f);O=l(U,"dataset-tagging"),U.forEach(a),k=l(C," y la "),g=o(C,"A",{href:!0,rel:!0});var R=i(g);_=l(R,"gu\xEDa de \u{1F917} Datasets"),R.forEach(a),H=l(C," para completar el archivo "),y=o(C,"EM",{});var Q=i(y);P=l(Q,"README.md"),Q.forEach(a),T=l(C," para tu dataset de issues de GitHub."),C.forEach(a),this.h()},h(){m(g,"href","https://github.com/huggingface/datasets/blob/master/templates/README_guide.md"),m(g,"rel","nofollow")},m(N,C){u(N,d,C),e(d,D),e(d,h),e(h,E),e(d,w),e(d,f),e(f,O),e(d,k),e(d,g),e(g,_),e(d,H),e(d,y),e(y,P),e(d,T)},d(N){N&&a(d)}}}function Wc(S){let d,D,h,E,w,f,O,k;return{c(){d=n("p"),D=t("\u270F\uFE0F "),h=n("strong"),E=t("\xA1Int\xE9ntalo!"),w=t(" Sigue los pasos descritos en esta secci\xF3n para crear un dataset de issues de GitHub de tu librer\xEDa de c\xF3digo abierto favorita (\xA1por supuesto, escoge algo distinto a \u{1F917} Datasets!). Para puntos extra, ajusta un clasificador de etiquetas m\xFAltiples para predecir las etiquetas presentes en el campo "),f=n("code"),O=t("labels"),k=t(".")},l(g){d=o(g,"P",{});var _=i(d);D=l(_,"\u270F\uFE0F "),h=o(_,"STRONG",{});var H=i(h);E=l(H,"\xA1Int\xE9ntalo!"),H.forEach(a),w=l(_," Sigue los pasos descritos en esta secci\xF3n para crear un dataset de issues de GitHub de tu librer\xEDa de c\xF3digo abierto favorita (\xA1por supuesto, escoge algo distinto a \u{1F917} Datasets!). Para puntos extra, ajusta un clasificador de etiquetas m\xFAltiples para predecir las etiquetas presentes en el campo "),f=o(_,"CODE",{});var y=i(f);O=l(y,"labels"),y.forEach(a),k=l(_,"."),_.forEach(a)},m(g,_){u(g,d,_),e(d,D),e(d,h),e(h,E),e(d,w),e(d,f),e(f,O),e(d,k)},d(g){g&&a(d)}}}function Yc(S){let d,D,h,E,w,f,O,k,g,_,H,y,P,T,N,C,V,U,R,Q,cs,G,K,na,xs,oa,ia,ua,Ra,nn,sl,pa,on,el,ds,js,Sa,Xs,un,Ua,pn,al,$s,cn,Ws,dn,mn,tl,Ys,se,Ru,ll,ca,hn,rl,ee,ae,Su,nl,X,fn,te,gn,_n,qs,bn,za,vn,xn,ol,Es,jn,La,$n,qn,il,le,ul,W,En,Ma,yn,wn,Fa,kn,Pn,pl,re,cl,ys,Dn,Ba,Hn,On,dl,ne,ml,oe,hl,z,An,Va,Cn,Tn,ie,Nn,Gn,Qa,In,Rn,Ja,Sn,Un,fl,ue,gl,pe,_l,J,zn,Za,Ln,Mn,Ka,Fn,Bn,Xa,Vn,Qn,bl,ws,vl,L,Jn,ce,Zn,Kn,Wa,Xn,Wn,de,Yn,so,Ya,eo,ao,xl,me,jl,ks,$l,da,to,ql,he,El,Y,lo,st,ro,no,et,oo,io,yl,fe,wl,Ps,uo,ma,po,co,kl,ge,Pl,_e,Dl,ss,mo,be,ho,fo,ve,go,_o,Hl,ha,ms,bo,at,vo,xo,tt,jo,$o,Ol,fa,qo,Al,hs,Ds,lt,xe,Eo,rt,yo,Cl,I,wo,nt,ko,Po,ga,Do,Ho,ot,Oo,Ao,it,Co,To,ut,No,Go,pt,Io,Ro,Tl,je,Nl,$e,Gl,M,So,ct,Uo,zo,dt,Lo,Mo,mt,Fo,Bo,ht,Vo,Qo,Il,qe,Rl,Hs,Sl,_a,Jo,Ul,ba,Zo,zl,fs,Os,ft,Ee,Ko,gt,Xo,Ll,va,Wo,Ml,ye,we,Uu,Fl,As,Yo,Cs,si,_t,ei,ai,Bl,ke,Vl,Pe,Ql,Z,ti,bt,li,ri,vt,ni,oi,xt,ii,ui,Jl,De,Zl,He,Kl,es,pi,jt,ci,di,$t,mi,hi,Xl,Oe,Wl,xa,fi,Yl,Ae,sr,gs,Ts,qt,Ce,gi,Et,_i,er,Te,ar,as,bi,Ne,vi,xi,yt,ji,$i,tr,Ge,lr,Ie,rr,Ns,qi,wt,Ei,yi,nr,Gs,wi,kt,ki,Pi,or,Re,ir,Is,Di,Pt,Hi,Oi,ur,Se,pr,Rs,Ai,Dt,Ci,Ti,cr,Ue,dr,ze,mr,ts,Ni,Ht,Gi,Ii,Ot,Ri,Si,hr,Ss,fr,Us,Ui,At,zi,Li,gr,Le,_r,F,Mi,Ct,Fi,Bi,Tt,Vi,Qi,Nt,Ji,Zi,Gt,Ki,Xi,br,Me,vr,zs,Wi,It,Yi,su,xr,Fe,jr,Ls,eu,Rt,au,tu,$r,Be,Ve,zu,qr,ls,lu,St,ru,nu,Ut,ou,iu,Er,Qe,yr,Je,wr,rs,uu,zt,pu,cu,Lt,du,mu,kr,Ms,Pr,_s,Fs,Mt,Ze,hu,Ft,fu,Dr,ja,gu,Hr,Bs,_u,Bt,bu,vu,Or,$a,bs,xu,Vs,ju,Vt,$u,qu,Qt,Eu,yu,Ar,Ke,Xe,Lu,Cr,We,Ye,wu,sa,ku,Pu,Tr,ns,Du,Jt,Hu,Ou,Zt,Au,Cu,Nr,ea,aa,Mu,Gr,Qs,Ir,qa,Tu,Rr,Js,Sr;return f=new Ia({}),H=new Bc({props:{chapter:5,classNames:"absolute z-10 right-0 top-0",notebooks:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter5/section5.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter5/section5.ipynb"}]}}),Xs=new Ia({}),le=new A({props:{code:"!pip install requests",highlighted:"!pip install requests"}}),re=new A({props:{code:`import requests

url = "https://api.github.com/repos/huggingface/datasets/issues?page=1&per_page=1"
response = requests.get(url)`,highlighted:`<span class="hljs-keyword">import</span> requests

url = <span class="hljs-string">&quot;https://api.github.com/repos/huggingface/datasets/issues?page=1&amp;per_page=1&quot;</span>
response = requests.get(url)`}}),ne=new A({props:{code:"response.status_code",highlighted:"response.status_code"}}),oe=new A({props:{code:"200",highlighted:'<span class="hljs-number">200</span>'}}),ue=new A({props:{code:"response.json()",highlighted:"response.json()"}}),pe=new A({props:{code:`[{'url': 'https://api.github.com/repos/huggingface/datasets/issues/2792',
  'repository_url': 'https://api.github.com/repos/huggingface/datasets',
  'labels_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792/labels{/name}',
  'comments_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792/comments',
  'events_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792/events',
  'html_url': 'https://github.com/huggingface/datasets/pull/2792',
  'id': 968650274,
  'node_id': 'MDExOlB1bGxSZXF1ZXN0NzEwNzUyMjc0',
  'number': 2792,
  'title': 'Update GooAQ',
  'user': {'login': 'bhavitvyamalik',
   'id': 19718818,
   'node_id': 'MDQ6VXNlcjE5NzE4ODE4',
   'avatar_url': 'https://avatars.githubusercontent.com/u/19718818?v=4',
   'gravatar_id': '',
   'url': 'https://api.github.com/users/bhavitvyamalik',
   'html_url': 'https://github.com/bhavitvyamalik',
   'followers_url': 'https://api.github.com/users/bhavitvyamalik/followers',
   'following_url': 'https://api.github.com/users/bhavitvyamalik/following{/other_user}',
   'gists_url': 'https://api.github.com/users/bhavitvyamalik/gists{/gist_id}',
   'starred_url': 'https://api.github.com/users/bhavitvyamalik/starred{/owner}{/repo}',
   'subscriptions_url': 'https://api.github.com/users/bhavitvyamalik/subscriptions',
   'organizations_url': 'https://api.github.com/users/bhavitvyamalik/orgs',
   'repos_url': 'https://api.github.com/users/bhavitvyamalik/repos',
   'events_url': 'https://api.github.com/users/bhavitvyamalik/events{/privacy}',
   'received_events_url': 'https://api.github.com/users/bhavitvyamalik/received_events',
   'type': 'User',
   'site_admin': False},
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2021-08-12T11:40:18Z',
  'updated_at': '2021-08-12T12:31:17Z',
  'closed_at': None,
  'author_association': 'CONTRIBUTOR',
  'active_lock_reason': None,
  'pull_request': {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/2792',
   'html_url': 'https://github.com/huggingface/datasets/pull/2792',
   'diff_url': 'https://github.com/huggingface/datasets/pull/2792.diff',
   'patch_url': 'https://github.com/huggingface/datasets/pull/2792.patch'},
  'body': '[GooAQ](https://github.com/allenai/gooaq) dataset was recently updated after splits were added for the same. This PR contains new updated GooAQ with train/val/test splits and updated README as well.',
  'performed_via_github_app': None}]`,highlighted:`[{<span class="hljs-string">&#x27;url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/repos/huggingface/datasets/issues/2792&#x27;</span>,
  <span class="hljs-string">&#x27;repository_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/repos/huggingface/datasets&#x27;</span>,
  <span class="hljs-string">&#x27;labels_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/repos/huggingface/datasets/issues/2792/labels{/name}&#x27;</span>,
  <span class="hljs-string">&#x27;comments_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/repos/huggingface/datasets/issues/2792/comments&#x27;</span>,
  <span class="hljs-string">&#x27;events_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/repos/huggingface/datasets/issues/2792/events&#x27;</span>,
  <span class="hljs-string">&#x27;html_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/datasets/pull/2792&#x27;</span>,
  <span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">968650274</span>,
  <span class="hljs-string">&#x27;node_id&#x27;</span>: <span class="hljs-string">&#x27;MDExOlB1bGxSZXF1ZXN0NzEwNzUyMjc0&#x27;</span>,
  <span class="hljs-string">&#x27;number&#x27;</span>: <span class="hljs-number">2792</span>,
  <span class="hljs-string">&#x27;title&#x27;</span>: <span class="hljs-string">&#x27;Update GooAQ&#x27;</span>,
  <span class="hljs-string">&#x27;user&#x27;</span>: {<span class="hljs-string">&#x27;login&#x27;</span>: <span class="hljs-string">&#x27;bhavitvyamalik&#x27;</span>,
   <span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">19718818</span>,
   <span class="hljs-string">&#x27;node_id&#x27;</span>: <span class="hljs-string">&#x27;MDQ6VXNlcjE5NzE4ODE4&#x27;</span>,
   <span class="hljs-string">&#x27;avatar_url&#x27;</span>: <span class="hljs-string">&#x27;https://avatars.githubusercontent.com/u/19718818?v=4&#x27;</span>,
   <span class="hljs-string">&#x27;gravatar_id&#x27;</span>: <span class="hljs-string">&#x27;&#x27;</span>,
   <span class="hljs-string">&#x27;url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik&#x27;</span>,
   <span class="hljs-string">&#x27;html_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/bhavitvyamalik&#x27;</span>,
   <span class="hljs-string">&#x27;followers_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/followers&#x27;</span>,
   <span class="hljs-string">&#x27;following_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/following{/other_user}&#x27;</span>,
   <span class="hljs-string">&#x27;gists_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/gists{/gist_id}&#x27;</span>,
   <span class="hljs-string">&#x27;starred_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/starred{/owner}{/repo}&#x27;</span>,
   <span class="hljs-string">&#x27;subscriptions_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/subscriptions&#x27;</span>,
   <span class="hljs-string">&#x27;organizations_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/orgs&#x27;</span>,
   <span class="hljs-string">&#x27;repos_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/repos&#x27;</span>,
   <span class="hljs-string">&#x27;events_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/events{/privacy}&#x27;</span>,
   <span class="hljs-string">&#x27;received_events_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/received_events&#x27;</span>,
   <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;User&#x27;</span>,
   <span class="hljs-string">&#x27;site_admin&#x27;</span>: <span class="hljs-literal">False</span>},
  <span class="hljs-string">&#x27;labels&#x27;</span>: [],
  <span class="hljs-string">&#x27;state&#x27;</span>: <span class="hljs-string">&#x27;open&#x27;</span>,
  <span class="hljs-string">&#x27;locked&#x27;</span>: <span class="hljs-literal">False</span>,
  <span class="hljs-string">&#x27;assignee&#x27;</span>: <span class="hljs-literal">None</span>,
  <span class="hljs-string">&#x27;assignees&#x27;</span>: [],
  <span class="hljs-string">&#x27;milestone&#x27;</span>: <span class="hljs-literal">None</span>,
  <span class="hljs-string">&#x27;comments&#x27;</span>: <span class="hljs-number">1</span>,
  <span class="hljs-string">&#x27;created_at&#x27;</span>: <span class="hljs-string">&#x27;2021-08-12T11:40:18Z&#x27;</span>,
  <span class="hljs-string">&#x27;updated_at&#x27;</span>: <span class="hljs-string">&#x27;2021-08-12T12:31:17Z&#x27;</span>,
  <span class="hljs-string">&#x27;closed_at&#x27;</span>: <span class="hljs-literal">None</span>,
  <span class="hljs-string">&#x27;author_association&#x27;</span>: <span class="hljs-string">&#x27;CONTRIBUTOR&#x27;</span>,
  <span class="hljs-string">&#x27;active_lock_reason&#x27;</span>: <span class="hljs-literal">None</span>,
  <span class="hljs-string">&#x27;pull_request&#x27;</span>: {<span class="hljs-string">&#x27;url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/repos/huggingface/datasets/pulls/2792&#x27;</span>,
   <span class="hljs-string">&#x27;html_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/datasets/pull/2792&#x27;</span>,
   <span class="hljs-string">&#x27;diff_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/datasets/pull/2792.diff&#x27;</span>,
   <span class="hljs-string">&#x27;patch_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/datasets/pull/2792.patch&#x27;</span>},
  <span class="hljs-string">&#x27;body&#x27;</span>: <span class="hljs-string">&#x27;[GooAQ](https://github.com/allenai/gooaq) dataset was recently updated after splits were added for the same. This PR contains new updated GooAQ with train/val/test splits and updated README as well.&#x27;</span>,
  <span class="hljs-string">&#x27;performed_via_github_app&#x27;</span>: <span class="hljs-literal">None</span>}]`}}),ws=new ra({props:{$$slots:{default:[Vc]},$$scope:{ctx:S}}}),me=new A({props:{code:`GITHUB_TOKEN = xxx  # Copy your GitHub token here
headers = {"Authorization": f"token {GITHUB_TOKEN}"}`,highlighted:`GITHUB_TOKEN = xxx  <span class="hljs-comment"># Copy your GitHub token here</span>
headers = {<span class="hljs-string">&quot;Authorization&quot;</span>: <span class="hljs-string">f&quot;token <span class="hljs-subst">{GITHUB_TOKEN}</span>&quot;</span>}`}}),ks=new ra({props:{warning:!0,$$slots:{default:[Qc]},$$scope:{ctx:S}}}),he=new A({props:{code:`import time
import math
from pathlib import Path
import pandas as pd
from tqdm.notebook import tqdm


def fetch_issues(
    owner="huggingface",
    repo="datasets",
    num_issues=10_000,
    rate_limit=5_000,
    issues_path=Path("."),
):
    if not issues_path.is_dir():
        issues_path.mkdir(exist_ok=True)

    batch = []
    all_issues = []
    per_page = 100  # N\xFAmero de issues por p\xE1gina
    num_pages = math.ceil(num_issues / per_page)
    base_url = "https://api.github.com/repos"

    for page in tqdm(range(num_pages)):
        # Query con state=all para obtener tanto issues abiertos como cerrados
        query = f"issues?page={page}&per_page={per_page}&state=all"
        issues = requests.get(f"{base_url}/{owner}/{repo}/{query}", headers=headers)
        batch.extend(issues.json())

        if len(batch) > rate_limit and len(all_issues) < num_issues:
            all_issues.extend(batch)
            batch = []  # Vac\xEDa el batch para el siguiente periodo de tiempo
            print(f"Reached GitHub rate limit. Sleeping for one hour ...")
            time.sleep(60 * 60 + 1)

    all_issues.extend(batch)
    df = pd.DataFrame.from_records(all_issues)
    df.to_json(f"{issues_path}/{repo}-issues.jsonl", orient="records", lines=True)
    print(
        f"Downloaded all the issues for {repo}! Dataset stored at {issues_path}/{repo}-issues.jsonl"
    )`,highlighted:`<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">import</span> math
<span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> tqdm.notebook <span class="hljs-keyword">import</span> tqdm


<span class="hljs-keyword">def</span> <span class="hljs-title function_">fetch_issues</span>(<span class="hljs-params">
    owner=<span class="hljs-string">&quot;huggingface&quot;</span>,
    repo=<span class="hljs-string">&quot;datasets&quot;</span>,
    num_issues=<span class="hljs-number">10_000</span>,
    rate_limit=<span class="hljs-number">5_000</span>,
    issues_path=Path(<span class="hljs-params"><span class="hljs-string">&quot;.&quot;</span></span>),
</span>):
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> issues_path.is_dir():
        issues_path.mkdir(exist_ok=<span class="hljs-literal">True</span>)

    batch = []
    all_issues = []
    per_page = <span class="hljs-number">100</span>  <span class="hljs-comment"># N\xFAmero de issues por p\xE1gina</span>
    num_pages = math.ceil(num_issues / per_page)
    base_url = <span class="hljs-string">&quot;https://api.github.com/repos&quot;</span>

    <span class="hljs-keyword">for</span> page <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(num_pages)):
        <span class="hljs-comment"># Query con state=all para obtener tanto issues abiertos como cerrados</span>
        query = <span class="hljs-string">f&quot;issues?page=<span class="hljs-subst">{page}</span>&amp;per_page=<span class="hljs-subst">{per_page}</span>&amp;state=all&quot;</span>
        issues = requests.get(<span class="hljs-string">f&quot;<span class="hljs-subst">{base_url}</span>/<span class="hljs-subst">{owner}</span>/<span class="hljs-subst">{repo}</span>/<span class="hljs-subst">{query}</span>&quot;</span>, headers=headers)
        batch.extend(issues.json())

        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(batch) &gt; rate_limit <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(all_issues) &lt; num_issues:
            all_issues.extend(batch)
            batch = []  <span class="hljs-comment"># Vac\xEDa el batch para el siguiente periodo de tiempo</span>
            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Reached GitHub rate limit. Sleeping for one hour ...&quot;</span>)
            time.sleep(<span class="hljs-number">60</span> * <span class="hljs-number">60</span> + <span class="hljs-number">1</span>)

    all_issues.extend(batch)
    df = pd.DataFrame.from_records(all_issues)
    df.to_json(<span class="hljs-string">f&quot;<span class="hljs-subst">{issues_path}</span>/<span class="hljs-subst">{repo}</span>-issues.jsonl&quot;</span>, orient=<span class="hljs-string">&quot;records&quot;</span>, lines=<span class="hljs-literal">True</span>)
    <span class="hljs-built_in">print</span>(
        <span class="hljs-string">f&quot;Downloaded all the issues for <span class="hljs-subst">{repo}</span>! Dataset stored at <span class="hljs-subst">{issues_path}</span>/<span class="hljs-subst">{repo}</span>-issues.jsonl&quot;</span>
    )`}}),fe=new A({props:{code:`# Dependiendo de tu conexi\xF3n a internet, esto puede tomar varios minutos para ejecutarse...
fetch_issues()`,highlighted:`<span class="hljs-comment"># Dependiendo de tu conexi\xF3n a internet, esto puede tomar varios minutos para ejecutarse...</span>
fetch_issues()`}}),ge=new A({props:{code:`issues_dataset = load_dataset("json", data_files="datasets-issues.jsonl", split="train")
issues_dataset`,highlighted:`issues_dataset = load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=<span class="hljs-string">&quot;datasets-issues.jsonl&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)
issues_dataset`}}),_e=new A({props:{code:`Dataset({
    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'pull_request', 'body', 'timeline_url', 'performed_via_github_app'],
    num_rows: 3019
})`,highlighted:`Dataset({
    features: [<span class="hljs-string">&#x27;url&#x27;</span>, <span class="hljs-string">&#x27;repository_url&#x27;</span>, <span class="hljs-string">&#x27;labels_url&#x27;</span>, <span class="hljs-string">&#x27;comments_url&#x27;</span>, <span class="hljs-string">&#x27;events_url&#x27;</span>, <span class="hljs-string">&#x27;html_url&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;node_id&#x27;</span>, <span class="hljs-string">&#x27;number&#x27;</span>, <span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;user&#x27;</span>, <span class="hljs-string">&#x27;labels&#x27;</span>, <span class="hljs-string">&#x27;state&#x27;</span>, <span class="hljs-string">&#x27;locked&#x27;</span>, <span class="hljs-string">&#x27;assignee&#x27;</span>, <span class="hljs-string">&#x27;assignees&#x27;</span>, <span class="hljs-string">&#x27;milestone&#x27;</span>, <span class="hljs-string">&#x27;comments&#x27;</span>, <span class="hljs-string">&#x27;created_at&#x27;</span>, <span class="hljs-string">&#x27;updated_at&#x27;</span>, <span class="hljs-string">&#x27;closed_at&#x27;</span>, <span class="hljs-string">&#x27;author_association&#x27;</span>, <span class="hljs-string">&#x27;active_lock_reason&#x27;</span>, <span class="hljs-string">&#x27;pull_request&#x27;</span>, <span class="hljs-string">&#x27;body&#x27;</span>, <span class="hljs-string">&#x27;timeline_url&#x27;</span>, <span class="hljs-string">&#x27;performed_via_github_app&#x27;</span>],
    num_rows: <span class="hljs-number">3019</span>
})`}}),xe=new Ia({}),je=new A({props:{code:`sample = issues_dataset.shuffle(seed=666).select(range(3))

# Imprime la URL y las entradas de pull_request
for url, pr in zip(sample["html_url"], sample["pull_request"]):
    print(f">> URL: {url}")
    print(f">> Pull request: {pr}\\n")`,highlighted:`sample = issues_dataset.shuffle(seed=<span class="hljs-number">666</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>))

<span class="hljs-comment"># Imprime la URL y las entradas de pull_request</span>
<span class="hljs-keyword">for</span> url, pr <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(sample[<span class="hljs-string">&quot;html_url&quot;</span>], sample[<span class="hljs-string">&quot;pull_request&quot;</span>]):
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;&gt;&gt; URL: <span class="hljs-subst">{url}</span>&quot;</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;&gt;&gt; Pull request: <span class="hljs-subst">{pr}</span>\\n&quot;</span>)`}}),$e=new A({props:{code:`>> URL: https://github.com/huggingface/datasets/pull/850
>> Pull request: {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/850', 'html_url': 'https://github.com/huggingface/datasets/pull/850', 'diff_url': 'https://github.com/huggingface/datasets/pull/850.diff', 'patch_url': 'https://github.com/huggingface/datasets/pull/850.patch'}

>> URL: https://github.com/huggingface/datasets/issues/2773
>> Pull request: None

>> URL: https://github.com/huggingface/datasets/pull/783
>> Pull request: {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/783', 'html_url': 'https://github.com/huggingface/datasets/pull/783', 'diff_url': 'https://github.com/huggingface/datasets/pull/783.diff', 'patch_url': 'https://github.com/huggingface/datasets/pull/783.patch'}`,highlighted:`&gt;&gt; URL: https://github.com/huggingface/datasets/pull/<span class="hljs-number">850</span>
&gt;&gt; Pull request: {<span class="hljs-string">&#x27;url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/repos/huggingface/datasets/pulls/850&#x27;</span>, <span class="hljs-string">&#x27;html_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/datasets/pull/850&#x27;</span>, <span class="hljs-string">&#x27;diff_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/datasets/pull/850.diff&#x27;</span>, <span class="hljs-string">&#x27;patch_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/datasets/pull/850.patch&#x27;</span>}

&gt;&gt; URL: https://github.com/huggingface/datasets/issues/<span class="hljs-number">2773</span>
&gt;&gt; Pull request: <span class="hljs-literal">None</span>

&gt;&gt; URL: https://github.com/huggingface/datasets/pull/<span class="hljs-number">783</span>
&gt;&gt; Pull request: {<span class="hljs-string">&#x27;url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/repos/huggingface/datasets/pulls/783&#x27;</span>, <span class="hljs-string">&#x27;html_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/datasets/pull/783&#x27;</span>, <span class="hljs-string">&#x27;diff_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/datasets/pull/783.diff&#x27;</span>, <span class="hljs-string">&#x27;patch_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/datasets/pull/783.patch&#x27;</span>}`}}),qe=new A({props:{code:`issues_dataset = issues_dataset.map(
    lambda x: {"is_pull_request": False if x["pull_request"] is None else True}
)`,highlighted:`issues_dataset = issues_dataset.<span class="hljs-built_in">map</span>(
    <span class="hljs-keyword">lambda</span> x: {<span class="hljs-string">&quot;is_pull_request&quot;</span>: <span class="hljs-literal">False</span> <span class="hljs-keyword">if</span> x[<span class="hljs-string">&quot;pull_request&quot;</span>] <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">True</span>}
)`}}),Hs=new ra({props:{$$slots:{default:[Jc]},$$scope:{ctx:S}}}),Ee=new Ia({}),ke=new A({props:{code:`issue_number = 2792
url = f"https://api.github.com/repos/huggingface/datasets/issues/{issue_number}/comments"
response = requests.get(url, headers=headers)
response.json()`,highlighted:`issue_number = <span class="hljs-number">2792</span>
url = <span class="hljs-string">f&quot;https://api.github.com/repos/huggingface/datasets/issues/<span class="hljs-subst">{issue_number}</span>/comments&quot;</span>
response = requests.get(url, headers=headers)
response.json()`}}),Pe=new A({props:{code:`[{'url': 'https://api.github.com/repos/huggingface/datasets/issues/comments/897594128',
  'html_url': 'https://github.com/huggingface/datasets/pull/2792#issuecomment-897594128',
  'issue_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792',
  'id': 897594128,
  'node_id': 'IC_kwDODunzps41gDMQ',
  'user': {'login': 'bhavitvyamalik',
   'id': 19718818,
   'node_id': 'MDQ6VXNlcjE5NzE4ODE4',
   'avatar_url': 'https://avatars.githubusercontent.com/u/19718818?v=4',
   'gravatar_id': '',
   'url': 'https://api.github.com/users/bhavitvyamalik',
   'html_url': 'https://github.com/bhavitvyamalik',
   'followers_url': 'https://api.github.com/users/bhavitvyamalik/followers',
   'following_url': 'https://api.github.com/users/bhavitvyamalik/following{/other_user}',
   'gists_url': 'https://api.github.com/users/bhavitvyamalik/gists{/gist_id}',
   'starred_url': 'https://api.github.com/users/bhavitvyamalik/starred{/owner}{/repo}',
   'subscriptions_url': 'https://api.github.com/users/bhavitvyamalik/subscriptions',
   'organizations_url': 'https://api.github.com/users/bhavitvyamalik/orgs',
   'repos_url': 'https://api.github.com/users/bhavitvyamalik/repos',
   'events_url': 'https://api.github.com/users/bhavitvyamalik/events{/privacy}',
   'received_events_url': 'https://api.github.com/users/bhavitvyamalik/received_events',
   'type': 'User',
   'site_admin': False},
  'created_at': '2021-08-12T12:21:52Z',
  'updated_at': '2021-08-12T12:31:17Z',
  'author_association': 'CONTRIBUTOR',
  'body': "@albertvillanova my tests are failing here:\\r\\n\`\`\`\\r\\ndataset_name = 'gooaq'\\r\\n\\r\\n    def test_load_dataset(self, dataset_name):\\r\\n        configs = self.dataset_tester.load_all_configs(dataset_name, is_local=True)[:1]\\r\\n>       self.dataset_tester.check_load_dataset(dataset_name, configs, is_local=True, use_local_dummy_data=True)\\r\\n\\r\\ntests/test_dataset_common.py:234: \\r\\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\r\\ntests/test_dataset_common.py:187: in check_load_dataset\\r\\n    self.parent.assertTrue(len(dataset[split]) > 0)\\r\\nE   AssertionError: False is not true\\r\\n\`\`\`\\r\\nWhen I try loading dataset on local machine it works fine. Any suggestions on how can I avoid this error?",
  'performed_via_github_app': None}]`,highlighted:`[{<span class="hljs-string">&#x27;url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/repos/huggingface/datasets/issues/comments/897594128&#x27;</span>,
  <span class="hljs-string">&#x27;html_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/datasets/pull/2792#issuecomment-897594128&#x27;</span>,
  <span class="hljs-string">&#x27;issue_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/repos/huggingface/datasets/issues/2792&#x27;</span>,
  <span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">897594128</span>,
  <span class="hljs-string">&#x27;node_id&#x27;</span>: <span class="hljs-string">&#x27;IC_kwDODunzps41gDMQ&#x27;</span>,
  <span class="hljs-string">&#x27;user&#x27;</span>: {<span class="hljs-string">&#x27;login&#x27;</span>: <span class="hljs-string">&#x27;bhavitvyamalik&#x27;</span>,
   <span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">19718818</span>,
   <span class="hljs-string">&#x27;node_id&#x27;</span>: <span class="hljs-string">&#x27;MDQ6VXNlcjE5NzE4ODE4&#x27;</span>,
   <span class="hljs-string">&#x27;avatar_url&#x27;</span>: <span class="hljs-string">&#x27;https://avatars.githubusercontent.com/u/19718818?v=4&#x27;</span>,
   <span class="hljs-string">&#x27;gravatar_id&#x27;</span>: <span class="hljs-string">&#x27;&#x27;</span>,
   <span class="hljs-string">&#x27;url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik&#x27;</span>,
   <span class="hljs-string">&#x27;html_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/bhavitvyamalik&#x27;</span>,
   <span class="hljs-string">&#x27;followers_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/followers&#x27;</span>,
   <span class="hljs-string">&#x27;following_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/following{/other_user}&#x27;</span>,
   <span class="hljs-string">&#x27;gists_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/gists{/gist_id}&#x27;</span>,
   <span class="hljs-string">&#x27;starred_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/starred{/owner}{/repo}&#x27;</span>,
   <span class="hljs-string">&#x27;subscriptions_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/subscriptions&#x27;</span>,
   <span class="hljs-string">&#x27;organizations_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/orgs&#x27;</span>,
   <span class="hljs-string">&#x27;repos_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/repos&#x27;</span>,
   <span class="hljs-string">&#x27;events_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/events{/privacy}&#x27;</span>,
   <span class="hljs-string">&#x27;received_events_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/received_events&#x27;</span>,
   <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;User&#x27;</span>,
   <span class="hljs-string">&#x27;site_admin&#x27;</span>: <span class="hljs-literal">False</span>},
  <span class="hljs-string">&#x27;created_at&#x27;</span>: <span class="hljs-string">&#x27;2021-08-12T12:21:52Z&#x27;</span>,
  <span class="hljs-string">&#x27;updated_at&#x27;</span>: <span class="hljs-string">&#x27;2021-08-12T12:31:17Z&#x27;</span>,
  <span class="hljs-string">&#x27;author_association&#x27;</span>: <span class="hljs-string">&#x27;CONTRIBUTOR&#x27;</span>,
  <span class="hljs-string">&#x27;body&#x27;</span>: <span class="hljs-string">&quot;@albertvillanova my tests are failing here:\\r\\n\`\`\`\\r\\ndataset_name = &#x27;gooaq&#x27;\\r\\n\\r\\n    def test_load_dataset(self, dataset_name):\\r\\n        configs = self.dataset_tester.load_all_configs(dataset_name, is_local=True)[:1]\\r\\n&gt;       self.dataset_tester.check_load_dataset(dataset_name, configs, is_local=True, use_local_dummy_data=True)\\r\\n\\r\\ntests/test_dataset_common.py:234: \\r\\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\r\\ntests/test_dataset_common.py:187: in check_load_dataset\\r\\n    self.parent.assertTrue(len(dataset[split]) &gt; 0)\\r\\nE   AssertionError: False is not true\\r\\n\`\`\`\\r\\nWhen I try loading dataset on local machine it works fine. Any suggestions on how can I avoid this error?&quot;</span>,
  <span class="hljs-string">&#x27;performed_via_github_app&#x27;</span>: <span class="hljs-literal">None</span>}]`}}),De=new A({props:{code:`def get_comments(issue_number):
    url = f"https://api.github.com/repos/huggingface/datasets/issues/{issue_number}/comments"
    response = requests.get(url, headers=headers)
    return [r["body"] for r in response.json()]


# Revisar que el comportamiento de nuestra funci\xF3n es el esperado
get_comments(2792)`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">get_comments</span>(<span class="hljs-params">issue_number</span>):
    url = <span class="hljs-string">f&quot;https://api.github.com/repos/huggingface/datasets/issues/<span class="hljs-subst">{issue_number}</span>/comments&quot;</span>
    response = requests.get(url, headers=headers)
    <span class="hljs-keyword">return</span> [r[<span class="hljs-string">&quot;body&quot;</span>] <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> response.json()]


<span class="hljs-comment"># Revisar que el comportamiento de nuestra funci\xF3n es el esperado</span>
get_comments(<span class="hljs-number">2792</span>)`}}),He=new A({props:{code:"[\"@albertvillanova my tests are failing here:\\r\\n```\\r\\ndataset_name = 'gooaq'\\r\\n\\r\\n    def test_load_dataset(self, dataset_name):\\r\\n        configs = self.dataset_tester.load_all_configs(dataset_name, is_local=True)[:1]\\r\\n>       self.dataset_tester.check_load_dataset(dataset_name, configs, is_local=True, use_local_dummy_data=True)\\r\\n\\r\\ntests/test_dataset_common.py:234: \\r\\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\r\\ntests/test_dataset_common.py:187: in check_load_dataset\\r\\n    self.parent.assertTrue(len(dataset[split]) > 0)\\r\\nE   AssertionError: False is not true\\r\\n```\\r\\nWhen I try loading dataset on local machine it works fine. Any suggestions on how can I avoid this error?\"]",highlighted:'[<span class="hljs-string">&quot;@albertvillanova my tests are failing here:\\r\\n```\\r\\ndataset_name = &#x27;gooaq&#x27;\\r\\n\\r\\n    def test_load_dataset(self, dataset_name):\\r\\n        configs = self.dataset_tester.load_all_configs(dataset_name, is_local=True)[:1]\\r\\n&gt;       self.dataset_tester.check_load_dataset(dataset_name, configs, is_local=True, use_local_dummy_data=True)\\r\\n\\r\\ntests/test_dataset_common.py:234: \\r\\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\r\\ntests/test_dataset_common.py:187: in check_load_dataset\\r\\n    self.parent.assertTrue(len(dataset[split]) &gt; 0)\\r\\nE   AssertionError: False is not true\\r\\n```\\r\\nWhen I try loading dataset on local machine it works fine. Any suggestions on how can I avoid this error?&quot;</span>]'}}),Oe=new A({props:{code:`# Dependiendo de tu conexi\xF3n a internet, esto puede tomar varios minutos...
issues_with_comments_dataset = issues_dataset.map(
    lambda x: {"comments": get_comments(x["number"])}
)`,highlighted:`<span class="hljs-comment"># Dependiendo de tu conexi\xF3n a internet, esto puede tomar varios minutos...</span>
issues_with_comments_dataset = issues_dataset.<span class="hljs-built_in">map</span>(
    <span class="hljs-keyword">lambda</span> x: {<span class="hljs-string">&quot;comments&quot;</span>: get_comments(x[<span class="hljs-string">&quot;number&quot;</span>])}
)`}}),Ae=new A({props:{code:'issues_with_comments_dataset.to_json("issues-datasets-with-hf-doc-builder.jsonl")',highlighted:'issues_with_comments_dataset.to_json(<span class="hljs-string">&quot;issues-datasets-with-hf-doc-builder.jsonl&quot;</span>)'}}),Ce=new Ia({}),Te=new Fc({props:{id:"HaN6qCr_Afc"}}),Ge=new A({props:{code:`from huggingface_hub import list_datasets

all_datasets = list_datasets()
print(f"Number of datasets on Hub: {len(all_datasets)}")
print(all_datasets[0])`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> list_datasets

all_datasets = list_datasets()
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Number of datasets on Hub: <span class="hljs-subst">{<span class="hljs-built_in">len</span>(all_datasets)}</span>&quot;</span>)
<span class="hljs-built_in">print</span>(all_datasets[<span class="hljs-number">0</span>])`}}),Ie=new A({props:{code:`Number of datasets on Hub: 1487
Dataset Name: acronym_identification, Tags: ['annotations_creators:expert-generated', 'language_creators:found', 'languages:en', 'licenses:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:structure-prediction', 'task_ids:structure-prediction-other-acronym-identification']`,highlighted:`Number of datasets on Hub: <span class="hljs-number">1487</span>
Dataset Name: acronym_identification, Tags: [<span class="hljs-string">&#x27;annotations_creators:expert-generated&#x27;</span>, <span class="hljs-string">&#x27;language_creators:found&#x27;</span>, <span class="hljs-string">&#x27;languages:en&#x27;</span>, <span class="hljs-string">&#x27;licenses:mit&#x27;</span>, <span class="hljs-string">&#x27;multilinguality:monolingual&#x27;</span>, <span class="hljs-string">&#x27;size_categories:10K&lt;n&lt;100K&#x27;</span>, <span class="hljs-string">&#x27;source_datasets:original&#x27;</span>, <span class="hljs-string">&#x27;task_categories:structure-prediction&#x27;</span>, <span class="hljs-string">&#x27;task_ids:structure-prediction-other-acronym-identification&#x27;</span>]`}}),Re=new A({props:{code:`from huggingface_hub import notebook_login

notebook_login()`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

notebook_login()`}}),Se=new A({props:{code:"huggingface-cli login",highlighted:"huggingface-cli login"}}),Ue=new A({props:{code:`from huggingface_hub import create_repo

repo_url = create_repo(name="github-issues", repo_type="dataset")
repo_url`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> create_repo

repo_url = create_repo(name=<span class="hljs-string">&quot;github-issues&quot;</span>, repo_type=<span class="hljs-string">&quot;dataset&quot;</span>)
repo_url`}}),ze=new A({props:{code:"'https://huggingface.co/datasets/lewtun/github-issues'",highlighted:'<span class="hljs-string">&#x27;https://huggingface.co/datasets/lewtun/github-issues&#x27;</span>'}}),Ss=new ra({props:{$$slots:{default:[Zc]},$$scope:{ctx:S}}}),Le=new A({props:{code:`from huggingface_hub import Repository

repo = Repository(local_dir="github-issues", clone_from=repo_url)
!cp issues-datasets-with-hf-doc-builder.jsonl github-issues/`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> Repository

repo = Repository(local_dir=<span class="hljs-string">&quot;github-issues&quot;</span>, clone_from=repo_url)
!cp issues-datasets-<span class="hljs-keyword">with</span>-hf-doc-builder.jsonl github-issues/`}}),Me=new A({props:{code:'repo.lfs_track("*.jsonl")',highlighted:'repo.lfs_track(<span class="hljs-string">&quot;*.jsonl&quot;</span>)'}}),Fe=new A({props:{code:"repo.push_to_hub()",highlighted:"repo.push_to_hub()"}}),Qe=new A({props:{code:`remote_dataset = load_dataset("lewtun/github-issues", split="train")
remote_dataset`,highlighted:`remote_dataset = load_dataset(<span class="hljs-string">&quot;lewtun/github-issues&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)
remote_dataset`}}),Je=new A({props:{code:`Dataset({
    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'pull_request', 'body', 'performed_via_github_app', 'is_pull_request'],
    num_rows: 2855
})`,highlighted:`Dataset({
    features: [<span class="hljs-string">&#x27;url&#x27;</span>, <span class="hljs-string">&#x27;repository_url&#x27;</span>, <span class="hljs-string">&#x27;labels_url&#x27;</span>, <span class="hljs-string">&#x27;comments_url&#x27;</span>, <span class="hljs-string">&#x27;events_url&#x27;</span>, <span class="hljs-string">&#x27;html_url&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;node_id&#x27;</span>, <span class="hljs-string">&#x27;number&#x27;</span>, <span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;user&#x27;</span>, <span class="hljs-string">&#x27;labels&#x27;</span>, <span class="hljs-string">&#x27;state&#x27;</span>, <span class="hljs-string">&#x27;locked&#x27;</span>, <span class="hljs-string">&#x27;assignee&#x27;</span>, <span class="hljs-string">&#x27;assignees&#x27;</span>, <span class="hljs-string">&#x27;milestone&#x27;</span>, <span class="hljs-string">&#x27;comments&#x27;</span>, <span class="hljs-string">&#x27;created_at&#x27;</span>, <span class="hljs-string">&#x27;updated_at&#x27;</span>, <span class="hljs-string">&#x27;closed_at&#x27;</span>, <span class="hljs-string">&#x27;author_association&#x27;</span>, <span class="hljs-string">&#x27;active_lock_reason&#x27;</span>, <span class="hljs-string">&#x27;pull_request&#x27;</span>, <span class="hljs-string">&#x27;body&#x27;</span>, <span class="hljs-string">&#x27;performed_via_github_app&#x27;</span>, <span class="hljs-string">&#x27;is_pull_request&#x27;</span>],
    num_rows: <span class="hljs-number">2855</span>
})`}}),Ms=new ra({props:{$$slots:{default:[Kc]},$$scope:{ctx:S}}}),Ze=new Ia({}),Qs=new ra({props:{$$slots:{default:[Xc]},$$scope:{ctx:S}}}),Js=new ra({props:{$$slots:{default:[Wc]},$$scope:{ctx:S}}}),{c(){d=n("meta"),D=p(),h=n("h1"),E=n("a"),w=n("span"),b(f.$$.fragment),O=p(),k=n("span"),g=t("Crea tu propio dataset"),_=p(),b(H.$$.fragment),y=p(),P=n("p"),T=t("Algunas veces el dataset que necesitas para crear una aplicaci\xF3n de procesamiento de lenguaje natural no existe, as\xED que necesitas crearla. En esta secci\xF3n vamos a mostrarte c\xF3mo crear un corpus de "),N=n("a"),C=t("issues de GitHub"),V=t(", que se usan com\xFAnmente para rastrear bugs o features en repositorios de GitHub. Este corpus podr\xEDa ser usado para varios prop\xF3sitos como:"),U=p(),R=n("ul"),Q=n("li"),cs=t("Explorar qu\xE9 tanto se demora el cierre un issue abierto o un pull request"),G=p(),K=n("li"),na=t("Entrenar un "),xs=n("em"),oa=t("clasificador de etiquetas m\xFAltiples"),ia=t(" que pueda etiquetar issues con metadados basado en la descripci\xF3n del issue (e.g., \u201Cbug\u201D, \u201Cmejora\u201D o \u201Cpregunta\u201D)"),ua=p(),Ra=n("li"),nn=t("Crear un motor de b\xFAsqueda sem\xE1ntica para encontrar qu\xE9 issues coinciden con la pregunta del usuario"),sl=p(),pa=n("p"),on=t("En esta secci\xF3n nos vamos a enfocar en la creaci\xF3n del corpus y en la siguiente vamos a abordar la aplicaci\xF3n de b\xFAsqueda sem\xE1ntica. Para que esto sea un meta-proyecto, vamos a usar los issues de Github asociados con un proyecto popular de c\xF3digo abierto: \u{1F917} Datasets! Veamos c\xF3mo obtener los datos y explorar la informaci\xF3n contenida en estos issues."),el=p(),ds=n("h2"),js=n("a"),Sa=n("span"),b(Xs.$$.fragment),un=p(),Ua=n("span"),pn=t("Obteniendo los datos"),al=p(),$s=n("p"),cn=t("Puedes encontrar todos los issues de \u{1F917} Datasets yendo a la "),Ws=n("a"),dn=t("pesta\xF1a de issues"),mn=t(" del repositorio. Como se puede ver en la siguiente captura de pantalla, al momento de escribir esta secci\xF3n hab\xEDan 331 issues abiertos y 668 cerrados."),tl=p(),Ys=n("div"),se=n("img"),ll=p(),ca=n("p"),hn=t("Si haces clic en alguno de estos issues te encontrar\xE1s con que incluyen un t\xEDtulo, una descripci\xF3n y un conjunto de etiquetas que lo caracterizan. Un ejemplo de esto se muestra en la siguiente captura de pantalla."),rl=p(),ee=n("div"),ae=n("img"),nl=p(),X=n("p"),fn=t("Para descargar todos los issues del repositorio, usaremos el "),te=n("a"),gn=t("API REST de GitHub"),_n=t(" para obtener el "),qs=n("a"),bn=t("endpoint "),za=n("code"),vn=t("Issues"),xn=t(". Este endpoint devuelve una lista de objetos JSON, en la que cada objeto contiene un gran n\xFAmero de campos que incluyen el t\xEDtulo y la descripci\xF3n, as\xED como metadatos sobre el estado del issue, entre otros."),ol=p(),Es=n("p"),jn=t("Una forma conveniente de descargar los issues es a trav\xE9s de la librer\xEDa "),La=n("code"),$n=t("requests"),qn=t(", que es la manera est\xE1ndar para hacer pedidos HTTP en Python. Puedes instalar esta librer\xEDa instalando:"),il=p(),b(le.$$.fragment),ul=p(),W=n("p"),En=t("Una vez la librer\xEDa est\xE1 instalada, puedes hacer pedidos GET al endpoint "),Ma=n("code"),yn=t("Issues"),wn=t(" ejecutando la funci\xF3n "),Fa=n("code"),kn=t("requests.get()"),Pn=t(". Por ejemplo, puedes correr el siguiente comando para obtener el primer issue de la primera p\xE1gina:"),pl=p(),b(re.$$.fragment),cl=p(),ys=n("p"),Dn=t("El objeto "),Ba=n("code"),Hn=t("response"),On=t(" contiene una gran cantidad de informaci\xF3n \xFAtil sobre el pedido, incluyendo el c\xF3digo de status de HTTP:"),dl=p(),b(ne.$$.fragment),ml=p(),b(oe.$$.fragment),hl=p(),z=n("p"),An=t("en el que un c\xF3digo de "),Va=n("code"),Cn=t("200"),Tn=t(" significa que el pedido fue exitoso (puedes ver una lista de posibles c\xF3digos de status de HTTP "),ie=n("a"),Nn=t("aqu\xED"),Gn=t("). No obstante, en lo que estamos interesados realmente es el "),Qa=n("em"),In=t("payload"),Rn=t(", que se puede acceder en varios formatos como bytes, strings o JSON. Como ya sabemos que los issues est\xE1n en formato JSON, inspeccionemos el "),Ja=n("em"),Sn=t("payload"),Un=t(" de la siguiente manera:"),fl=p(),b(ue.$$.fragment),gl=p(),b(pe.$$.fragment),_l=p(),J=n("p"),zn=t("Wow, \xA1es mucha informaci\xF3n! Podemos ver campos \xFAtiles como "),Za=n("code"),Ln=t("title"),Mn=t(", "),Ka=n("code"),Fn=t("body"),Bn=t(" y "),Xa=n("code"),Vn=t("number"),Qn=t(", que describen el issue, as\xED como informaci\xF3n del usuario de GitHub que lo abri\xF3."),bl=p(),b(ws.$$.fragment),vl=p(),L=n("p"),Jn=t("Tal como se describe en la "),ce=n("a"),Zn=t("documentaci\xF3n"),Kn=t(" de GitHub, los pedidos sin autenticaci\xF3n est\xE1n limitados a 60 por hora. Si bien puedes incrementar el par\xE1metro de b\xFAsqueda "),Wa=n("code"),Xn=t("per_page"),Wn=t(" para reducir el n\xFAmero de pedidos que haces, igual puedes alcanzar el l\xEDmite de pedidos en cualquier repositorio que tenga m\xE1s que un par de miles de issues. En vez de hacer eso, puedes seguir las "),de=n("a"),Yn=t("instrucciones"),so=t(" de GitHub para crear un "),Ya=n("em"),eo=t("token de acceso personal"),ao=t(" y que puedas incrementar el l\xEDmite de pedidos a 5.000 por hora. Una vez tengas tu token, puedes incluirlo como parte del encabezado del pedido:"),xl=p(),b(me.$$.fragment),jl=p(),b(ks.$$.fragment),$l=p(),da=n("p"),to=t("Ahora que tenemos nuestro token de acceso, creemos una funci\xF3n que descargue todos los issues de un repositorio de GitHub:"),ql=p(),b(he.$$.fragment),El=p(),Y=n("p"),lo=t("Cuando ejecutemos "),st=n("code"),ro=t("fetch_issues()"),no=t(", se descargar\xE1n todos los issues en lotes para evitar exceder el l\xEDmite de GitHub sobre el n\xFAmero de pedidos por hora. El resultado se guardar\xE1 en un archivo "),et=n("em"),oo=t("repository_name-issues.jsonl"),io=t(", donde cada l\xEDnea es un objeto JSON que representa un issue. Usemos esta funci\xF3n para cargar todos los issues de \u{1F917} Datasets:"),yl=p(),b(fe.$$.fragment),wl=p(),Ps=n("p"),uo=t("Una vez los issues est\xE9n descargados, los podemos cargar localmente usando las habilidades aprendidas en la "),ma=n("a"),po=t("secci\xF3n 2"),co=t(":"),kl=p(),b(ge.$$.fragment),Pl=p(),b(_e.$$.fragment),Dl=p(),ss=n("p"),mo=t("\xA1Genial! Hemos creado nuestro primer dataset desde cero. Pero, \xBFpor qu\xE9 hay varios miles de issues cuando la "),be=n("a"),ho=t("pesta\xF1a de Issues"),fo=t(" del repositorio de \u{1F917} Datasets s\xF3lo muestra alrededor de 1.000 en total? Como se describe en la "),ve=n("a"),go=t("documentaci\xF3n"),_o=t(", esto sucede porque tambi\xE9n descargamos todos los pull requests:"),Hl=p(),ha=n("blockquote"),ms=n("p"),bo=t("GitHub\u2019s REST API v3 considers every pull request an issue, but not every issue is a pull request. For this reason, \u201CIssues\u201D endpoints may return both issues and pull requests in the response. You can identify pull requests by the "),at=n("code"),vo=t("pull_request"),xo=t(" key. Be aware that the "),tt=n("code"),jo=t("id"),$o=t(" of a pull request returned from \u201CIssues\u201D endpoints will be an issue id."),Ol=p(),fa=n("p"),qo=t("Como el contenido de los issues y pull requests son diferentes, hagamos un preprocesamiento simple para distinguirlos entre s\xED."),Al=p(),hs=n("h2"),Ds=n("a"),lt=n("span"),b(xe.$$.fragment),Eo=p(),rt=n("span"),yo=t("Limpiando los datos"),Cl=p(),I=n("p"),wo=t("El fragmento anterior de la documentaci\xF3n de GitHub nos dice que la columna "),nt=n("code"),ko=t("pull_request"),Po=t(" puede usarse para diferenciar los issues de los pull requests. Veamos una muestra aleatoria para ver la diferencia. Como hicimos en la "),ga=n("a"),Do=t("secci\xF3n 3"),Ho=t(", vamos a encadenar "),ot=n("code"),Oo=t("Dataset.shuffle()"),Ao=t(" y "),it=n("code"),Co=t("Dataset.select()"),To=t(" para crear una muestra aleatoria y luego unir las columnas de "),ut=n("code"),No=t("html_url"),Go=t(" y "),pt=n("code"),Io=t("pull_request"),Ro=t(" para comparar las distintas URL:"),Tl=p(),b(je.$$.fragment),Nl=p(),b($e.$$.fragment),Gl=p(),M=n("p"),So=t("Podemos ver que cada pull request est\xE1 asociado con varias URL, mientras que los issues ordinarios tienen una entrada "),ct=n("code"),Uo=t("None"),zo=t(". Podemos usar esta distinci\xF3n para crear una nueva columna "),dt=n("code"),Lo=t("is_pull_request"),Mo=t(" que revisa si el campo "),mt=n("code"),Fo=t("pull_request"),Bo=t(" es "),ht=n("code"),Vo=t("None"),Qo=t(" o no:"),Il=p(),b(qe.$$.fragment),Rl=p(),b(Hs.$$.fragment),Sl=p(),_a=n("p"),Jo=t("Si bien podemos limpiar a\xFAn m\xE1s el dataset eliminando o renombrando algunas columnas, es una buena pr\xE1ctica mantener un dataset lo m\xE1s parecido al original en esta etapa, para que se pueda usar f\xE1cilmente en varias aplicaciones."),Ul=p(),ba=n("p"),Zo=t("Antes de subir el dataset el Hub de Hugging Face, nos hace falta a\xF1adirle algo m\xE1s: los comentarios asociados con cada issue y pull request. Los vamos a a\xF1adir con el API REST de GitHub."),zl=p(),fs=n("h2"),Os=n("a"),ft=n("span"),b(Ee.$$.fragment),Ko=p(),gt=n("span"),Xo=t("Ampliando el dataset"),Ll=p(),va=n("p"),Wo=t("Como se muestra en la siguiente captura de pantalla, los comentarios asociados con un issue o un pull request son una fuente rica de informaci\xF3n, especialmente si estamos interesados en construir un motor de b\xFAsqueda para responder preguntas de usuarios sobre la librer\xEDa."),Ml=p(),ye=n("div"),we=n("img"),Fl=p(),As=n("p"),Yo=t("El API REST de GitHub tiene un "),Cs=n("a"),si=t("endpoint "),_t=n("code"),ei=t("Comments"),ai=t(" que devuelve todos los comentarios asociados con un n\xFAmero de issue. Prob\xE9mos este endpoint para ver qu\xE9 devuelve:"),Bl=p(),b(ke.$$.fragment),Vl=p(),b(Pe.$$.fragment),Ql=p(),Z=n("p"),ti=t("Podemos ver que el comentario est\xE1 almacenado en el campo "),bt=n("code"),li=t("body"),ri=t(", as\xED que escribamos una funci\xF3n simple que devuelva todos los comentarios asociados con un issue al extraer el contenido de "),vt=n("code"),ni=t("body"),oi=t(" para cada elemento en el "),xt=n("code"),ii=t("response.json()"),ui=t(":"),Jl=p(),b(De.$$.fragment),Zl=p(),b(He.$$.fragment),Kl=p(),es=n("p"),pi=t("Esto luce bien, as\xED que usemos "),jt=n("code"),ci=t("Dataset.map()"),di=t(" para a\xF1adir una nueva columna "),$t=n("code"),mi=t("comments"),hi=t(" a cada issue en el dataset:"),Xl=p(),b(Oe.$$.fragment),Wl=p(),xa=n("p"),fi=t("El \xFAltimo paso es guardar el dataset ampliado en el mismo lugar que los datos originales para poderlos subir al Hub:"),Yl=p(),b(Ae.$$.fragment),sr=p(),gs=n("h2"),Ts=n("a"),qt=n("span"),b(Ce.$$.fragment),gi=p(),Et=n("span"),_i=t("Subiendo un dataset al Hub de Hugging Face"),er=p(),b(Te.$$.fragment),ar=p(),as=n("p"),bi=t("Ahora que tenemos nuestro dataset ampliado, es momento de subirlo al Hub para poder compartirlo con la comunidad. Para subir el dataset tenemos que usar la "),Ne=n("a"),vi=t("librer\xEDa \u{1F917} Hub"),xi=t(", que nos permite interactuar con el Hub de Hugging Face usando una API de Python. \u{1F917} Hub viene instalada con \u{1F917} Transformers, as\xED que podemos usarla directamente. Por ejemplo, podemos usar la funci\xF3n "),yt=n("code"),ji=t("list_datasets()"),$i=t(" para obtener informaci\xF3n sobre todos los datasets p\xFAblicos que est\xE1n almacenados en el Hub:"),tr=p(),b(Ge.$$.fragment),lr=p(),b(Ie.$$.fragment),rr=p(),Ns=n("p"),qi=t("Podemos ver que hay alrededor de 1.500 datasets en el Hub y que la funci\xF3n "),wt=n("code"),Ei=t("list_datasets()"),yi=t(" tambi\xE9n provee algunos metadatos sobre el repositorio de cada uno."),nr=p(),Gs=n("p"),wi=t("Para lo que queremos hacer, lo primero que necesitamos es crear un nuevo repositorio de dataset en el Hub. Para ello, necesitamos un token de autenticaci\xF3n, que se obtiene al acceder al Hub de Hugging Face con la funci\xF3n "),kt=n("code"),ki=t("notebook_login()"),Pi=t(":"),or=p(),b(Re.$$.fragment),ir=p(),Is=n("p"),Di=t("Esto crea un widget en el que ingresas tu nombre de usuario y contrase\xF1a, y guarda un token API en "),Pt=n("em"),Hi=t("~/.huggingface/token"),Oi=t(". Si est\xE1s ejecutando el c\xF3digo en la terminal, puedes acceder a trav\xE9s de la l\xEDnea de comandos as\xED:"),ur=p(),b(Se.$$.fragment),pr=p(),Rs=n("p"),Ai=t("Una vez hecho esto, podemos crear un nuevo repositorio para el dataset con la funci\xF3n "),Dt=n("code"),Ci=t("create_repo()"),Ti=t(":"),cr=p(),b(Ue.$$.fragment),dr=p(),b(ze.$$.fragment),mr=p(),ts=n("p"),Ni=t("En este ejemplo, hemos creado un repositorio vac\xEDo para el dataset llamado "),Ht=n("code"),Gi=t("github-issues"),Ii=t(" bajo el nombre de usuario "),Ot=n("code"),Ri=t("lewtun"),Si=t(" (\xA1el nombre de usuario deber\xEDa ser tu nombre de usuario del Hub cuando est\xE9s ejecutando este c\xF3digo!)."),hr=p(),b(Ss.$$.fragment),fr=p(),Us=n("p"),Ui=t("Ahora clonemos el repositorio del Hub a nuestra m\xE1quina local y copiemos nuestro dataset ah\xED. \u{1F917} Hub incluye una clase "),At=n("code"),zi=t("Repositorio"),Li=t(" que envuelve muchos de los comandos comunes de Git, as\xED que para clonar el repositorio remoto solamente necesitamos dar la URL y la ruta local en la que lo queremos clonar:"),gr=p(),b(Le.$$.fragment),_r=p(),F=n("p"),Mi=t("Por defecto, varias extensiones de archivo (como "),Ct=n("em"),Fi=t(".bin"),Bi=t(", "),Tt=n("em"),Vi=t(".gz"),Qi=t(", and "),Nt=n("em"),Ji=t(".zip"),Zi=t(") se siguen con Git LFS de tal manera que los archivos grandes se pueden versionar dentro del mismo flujo de trabajo de Git. Puedes encontrar una lista de extensiones que se van a seguir en el archivo "),Gt=n("em"),Ki=t(".gitattributes"),Xi=t(". Para incluir el formato JSON Lines en la lista, puedes ejecutar el siguiente comando:"),br=p(),b(Me.$$.fragment),vr=p(),zs=n("p"),Wi=t("Luego, podemos usar "),It=n("code"),Yi=t("$$Repository.push_to_hub()"),su=t(" para subir el dataset al Hub:"),xr=p(),b(Fe.$$.fragment),jr=p(),Ls=n("p"),eu=t("Si navegamos a la URL que aparece en "),Rt=n("code"),au=t("repo_url"),tu=t(", deber\xEDamos ver que el archivo del dataset se ha subido."),$r=p(),Be=n("div"),Ve=n("img"),qr=p(),ls=n("p"),lu=t("Desde aqui, cualquier persona podr\xE1 descargar el dataset incluyendo el ID del repositorio en el argumento "),St=n("code"),ru=t("path"),nu=t(" de la funci\xF3n "),Ut=n("code"),ou=t("load_dataset()"),iu=t(":"),Er=p(),b(Qe.$$.fragment),yr=p(),b(Je.$$.fragment),wr=p(),rs=n("p"),uu=t("\xA1Genial, hemos subido el dataset al Hub y ya est\xE1 disponible para que otras personas lo usen! S\xF3lo hay una cosa restante por hacer: a\xF1adir una "),zt=n("em"),pu=t("tarjeta del dataset"),cu=t(" ("),Lt=n("em"),du=t("dataset card"),mu=t(") que explique c\xF3mo se cre\xF3 el corpus y provea informaci\xF3n \xFAtil para la comunidad."),kr=p(),b(Ms.$$.fragment),Pr=p(),_s=n("h2"),Fs=n("a"),Mt=n("span"),b(Ze.$$.fragment),hu=p(),Ft=n("span"),fu=t("Creando una tarjeta del dataset"),Dr=p(),ja=n("p"),gu=t("Los datasets bien documentados tienen m\xE1s probabilidades de ser \xFAtiles para otros (incluy\xE9ndote a ti en el futuro), dado que brindan la informaci\xF3n necesaria para que los usuarios decidan si el dataset es \xFAtil para su tarea, as\xED como para evaluar cualquier sesgo o riesgo potencial asociado a su uso."),Hr=p(),Bs=n("p"),_u=t("En el Hub de Hugging Face, esta informaci\xF3n se almacena en el archivo "),Bt=n("em"),bu=t("README.md"),vu=t(" del repositorio del dataset. Hay dos pasos que deber\xEDas hacer antes de crear este archivo:"),Or=p(),$a=n("ol"),bs=n("li"),xu=t("Usa la "),Vs=n("a"),ju=t("aplicaci\xF3n "),Vt=n("code"),$u=t("datasets-tagging"),qu=t(" para crear etiquetas de metadatos en el formato YAML. Estas etiquetas se usan para una variedad de funciones de b\xFAsqueda en el Hub de Hugging Face y aseguran que otros miembros de la comunidad puedan encontrar tu dataset. Dado que creamos un dataset personalizado en esta secci\xF3n, tendremos que clonar el repositorio "),Qt=n("code"),Eu=t("datasets-tagging"),yu=t(" y correr la aplicaci\xF3n localmente. As\xED se ve la interfaz de la aplicaci\xF3n:"),Ar=p(),Ke=n("div"),Xe=n("img"),Cr=p(),We=n("ol"),Ye=n("li"),wu=t("Lee la "),sa=n("a"),ku=t("gu\xEDa de \u{1F917} Datasets"),Pu=t(" sobre c\xF3mo crear tarjetas informativas y usarlas como plantilla."),Tr=p(),ns=n("p"),Du=t("Puedes crear el archivo "),Jt=n("em"),Hu=t("README.md"),Ou=t(" drectamente desde el Hub y puedes encontrar una plantilla de tarjeta en el repositorio "),Zt=n("code"),Au=t("lewtun/github-issues"),Cu=t(". As\xED se ve una tarjeta de dataset diligenciada:"),Nr=p(),ea=n("div"),aa=n("img"),Gr=p(),b(Qs.$$.fragment),Ir=p(),qa=n("p"),Tu=t("\xA1Eso es todo! Hemos visto que crear un buen dataset requiere de mucho esfuerzo de tu parte, pero afortunadamente subirlo y compartirlo con la comunidad no. En la siguiente secci\xF3n usaremos nuestro nuevo dataset para crear un motor de b\xFAsqueda sem\xE1ntica con \u{1F917} Datasets que pueda emparejar pregunras con los issues y comentarios m\xE1s relevantes."),Rr=p(),b(Js.$$.fragment),this.h()},l(s){const r=Lc('[data-svelte="svelte-1phssyn"]',document.head);d=o(r,"META",{name:!0,content:!0}),r.forEach(a),D=c(s),h=o(s,"H1",{class:!0});var ta=i(h);E=o(ta,"A",{id:!0,class:!0,href:!0});var Kt=i(E);w=o(Kt,"SPAN",{});var Xt=i(w);v(f.$$.fragment,Xt),Xt.forEach(a),Kt.forEach(a),O=c(ta),k=o(ta,"SPAN",{});var Wt=i(k);g=l(Wt,"Crea tu propio dataset"),Wt.forEach(a),ta.forEach(a),_=c(s),v(H.$$.fragment,s),y=c(s),P=o(s,"P",{});var la=i(P);T=l(la,"Algunas veces el dataset que necesitas para crear una aplicaci\xF3n de procesamiento de lenguaje natural no existe, as\xED que necesitas crearla. En esta secci\xF3n vamos a mostrarte c\xF3mo crear un corpus de "),N=o(la,"A",{href:!0,rel:!0});var Yt=i(N);C=l(Yt,"issues de GitHub"),Yt.forEach(a),V=l(la,", que se usan com\xFAnmente para rastrear bugs o features en repositorios de GitHub. Este corpus podr\xEDa ser usado para varios prop\xF3sitos como:"),la.forEach(a),U=c(s),R=o(s,"UL",{});var vs=i(R);Q=o(vs,"LI",{});var Fu=i(Q);cs=l(Fu,"Explorar qu\xE9 tanto se demora el cierre un issue abierto o un pull request"),Fu.forEach(a),G=c(vs),K=o(vs,"LI",{});var Ur=i(K);na=l(Ur,"Entrenar un "),xs=o(Ur,"EM",{});var Bu=i(xs);oa=l(Bu,"clasificador de etiquetas m\xFAltiples"),Bu.forEach(a),ia=l(Ur," que pueda etiquetar issues con metadados basado en la descripci\xF3n del issue (e.g., \u201Cbug\u201D, \u201Cmejora\u201D o \u201Cpregunta\u201D)"),Ur.forEach(a),ua=c(vs),Ra=o(vs,"LI",{});var Vu=i(Ra);nn=l(Vu,"Crear un motor de b\xFAsqueda sem\xE1ntica para encontrar qu\xE9 issues coinciden con la pregunta del usuario"),Vu.forEach(a),vs.forEach(a),sl=c(s),pa=o(s,"P",{});var Qu=i(pa);on=l(Qu,"En esta secci\xF3n nos vamos a enfocar en la creaci\xF3n del corpus y en la siguiente vamos a abordar la aplicaci\xF3n de b\xFAsqueda sem\xE1ntica. Para que esto sea un meta-proyecto, vamos a usar los issues de Github asociados con un proyecto popular de c\xF3digo abierto: \u{1F917} Datasets! Veamos c\xF3mo obtener los datos y explorar la informaci\xF3n contenida en estos issues."),Qu.forEach(a),el=c(s),ds=o(s,"H2",{class:!0});var zr=i(ds);js=o(zr,"A",{id:!0,class:!0,href:!0});var Ju=i(js);Sa=o(Ju,"SPAN",{});var Zu=i(Sa);v(Xs.$$.fragment,Zu),Zu.forEach(a),Ju.forEach(a),un=c(zr),Ua=o(zr,"SPAN",{});var Ku=i(Ua);pn=l(Ku,"Obteniendo los datos"),Ku.forEach(a),zr.forEach(a),al=c(s),$s=o(s,"P",{});var Lr=i($s);cn=l(Lr,"Puedes encontrar todos los issues de \u{1F917} Datasets yendo a la "),Ws=o(Lr,"A",{href:!0,rel:!0});var Xu=i(Ws);dn=l(Xu,"pesta\xF1a de issues"),Xu.forEach(a),mn=l(Lr," del repositorio. Como se puede ver en la siguiente captura de pantalla, al momento de escribir esta secci\xF3n hab\xEDan 331 issues abiertos y 668 cerrados."),Lr.forEach(a),tl=c(s),Ys=o(s,"DIV",{class:!0});var Wu=i(Ys);se=o(Wu,"IMG",{src:!0,alt:!0,width:!0}),Wu.forEach(a),ll=c(s),ca=o(s,"P",{});var Yu=i(ca);hn=l(Yu,"Si haces clic en alguno de estos issues te encontrar\xE1s con que incluyen un t\xEDtulo, una descripci\xF3n y un conjunto de etiquetas que lo caracterizan. Un ejemplo de esto se muestra en la siguiente captura de pantalla."),Yu.forEach(a),rl=c(s),ee=o(s,"DIV",{class:!0});var sp=i(ee);ae=o(sp,"IMG",{src:!0,alt:!0,width:!0}),sp.forEach(a),nl=c(s),X=o(s,"P",{});var Ea=i(X);fn=l(Ea,"Para descargar todos los issues del repositorio, usaremos el "),te=o(Ea,"A",{href:!0,rel:!0});var ep=i(te);gn=l(ep,"API REST de GitHub"),ep.forEach(a),_n=l(Ea," para obtener el "),qs=o(Ea,"A",{href:!0,rel:!0});var Nu=i(qs);bn=l(Nu,"endpoint "),za=o(Nu,"CODE",{});var ap=i(za);vn=l(ap,"Issues"),ap.forEach(a),Nu.forEach(a),xn=l(Ea,". Este endpoint devuelve una lista de objetos JSON, en la que cada objeto contiene un gran n\xFAmero de campos que incluyen el t\xEDtulo y la descripci\xF3n, as\xED como metadatos sobre el estado del issue, entre otros."),Ea.forEach(a),ol=c(s),Es=o(s,"P",{});var Mr=i(Es);jn=l(Mr,"Una forma conveniente de descargar los issues es a trav\xE9s de la librer\xEDa "),La=o(Mr,"CODE",{});var tp=i(La);$n=l(tp,"requests"),tp.forEach(a),qn=l(Mr,", que es la manera est\xE1ndar para hacer pedidos HTTP en Python. Puedes instalar esta librer\xEDa instalando:"),Mr.forEach(a),il=c(s),v(le.$$.fragment,s),ul=c(s),W=o(s,"P",{});var ya=i(W);En=l(ya,"Una vez la librer\xEDa est\xE1 instalada, puedes hacer pedidos GET al endpoint "),Ma=o(ya,"CODE",{});var lp=i(Ma);yn=l(lp,"Issues"),lp.forEach(a),wn=l(ya," ejecutando la funci\xF3n "),Fa=o(ya,"CODE",{});var rp=i(Fa);kn=l(rp,"requests.get()"),rp.forEach(a),Pn=l(ya,". Por ejemplo, puedes correr el siguiente comando para obtener el primer issue de la primera p\xE1gina:"),ya.forEach(a),pl=c(s),v(re.$$.fragment,s),cl=c(s),ys=o(s,"P",{});var Fr=i(ys);Dn=l(Fr,"El objeto "),Ba=o(Fr,"CODE",{});var np=i(Ba);Hn=l(np,"response"),np.forEach(a),On=l(Fr," contiene una gran cantidad de informaci\xF3n \xFAtil sobre el pedido, incluyendo el c\xF3digo de status de HTTP:"),Fr.forEach(a),dl=c(s),v(ne.$$.fragment,s),ml=c(s),v(oe.$$.fragment,s),hl=c(s),z=o(s,"P",{});var os=i(z);An=l(os,"en el que un c\xF3digo de "),Va=o(os,"CODE",{});var op=i(Va);Cn=l(op,"200"),op.forEach(a),Tn=l(os," significa que el pedido fue exitoso (puedes ver una lista de posibles c\xF3digos de status de HTTP "),ie=o(os,"A",{href:!0,rel:!0});var ip=i(ie);Nn=l(ip,"aqu\xED"),ip.forEach(a),Gn=l(os,"). No obstante, en lo que estamos interesados realmente es el "),Qa=o(os,"EM",{});var up=i(Qa);In=l(up,"payload"),up.forEach(a),Rn=l(os,", que se puede acceder en varios formatos como bytes, strings o JSON. Como ya sabemos que los issues est\xE1n en formato JSON, inspeccionemos el "),Ja=o(os,"EM",{});var pp=i(Ja);Sn=l(pp,"payload"),pp.forEach(a),Un=l(os," de la siguiente manera:"),os.forEach(a),fl=c(s),v(ue.$$.fragment,s),gl=c(s),v(pe.$$.fragment,s),_l=c(s),J=o(s,"P",{});var Zs=i(J);zn=l(Zs,"Wow, \xA1es mucha informaci\xF3n! Podemos ver campos \xFAtiles como "),Za=o(Zs,"CODE",{});var cp=i(Za);Ln=l(cp,"title"),cp.forEach(a),Mn=l(Zs,", "),Ka=o(Zs,"CODE",{});var dp=i(Ka);Fn=l(dp,"body"),dp.forEach(a),Bn=l(Zs," y "),Xa=o(Zs,"CODE",{});var mp=i(Xa);Vn=l(mp,"number"),mp.forEach(a),Qn=l(Zs,", que describen el issue, as\xED como informaci\xF3n del usuario de GitHub que lo abri\xF3."),Zs.forEach(a),bl=c(s),v(ws.$$.fragment,s),vl=c(s),L=o(s,"P",{});var is=i(L);Jn=l(is,"Tal como se describe en la "),ce=o(is,"A",{href:!0,rel:!0});var hp=i(ce);Zn=l(hp,"documentaci\xF3n"),hp.forEach(a),Kn=l(is," de GitHub, los pedidos sin autenticaci\xF3n est\xE1n limitados a 60 por hora. Si bien puedes incrementar el par\xE1metro de b\xFAsqueda "),Wa=o(is,"CODE",{});var fp=i(Wa);Xn=l(fp,"per_page"),fp.forEach(a),Wn=l(is," para reducir el n\xFAmero de pedidos que haces, igual puedes alcanzar el l\xEDmite de pedidos en cualquier repositorio que tenga m\xE1s que un par de miles de issues. En vez de hacer eso, puedes seguir las "),de=o(is,"A",{href:!0,rel:!0});var gp=i(de);Yn=l(gp,"instrucciones"),gp.forEach(a),so=l(is," de GitHub para crear un "),Ya=o(is,"EM",{});var _p=i(Ya);eo=l(_p,"token de acceso personal"),_p.forEach(a),ao=l(is," y que puedas incrementar el l\xEDmite de pedidos a 5.000 por hora. Una vez tengas tu token, puedes incluirlo como parte del encabezado del pedido:"),is.forEach(a),xl=c(s),v(me.$$.fragment,s),jl=c(s),v(ks.$$.fragment,s),$l=c(s),da=o(s,"P",{});var bp=i(da);to=l(bp,"Ahora que tenemos nuestro token de acceso, creemos una funci\xF3n que descargue todos los issues de un repositorio de GitHub:"),bp.forEach(a),ql=c(s),v(he.$$.fragment,s),El=c(s),Y=o(s,"P",{});var wa=i(Y);lo=l(wa,"Cuando ejecutemos "),st=o(wa,"CODE",{});var vp=i(st);ro=l(vp,"fetch_issues()"),vp.forEach(a),no=l(wa,", se descargar\xE1n todos los issues en lotes para evitar exceder el l\xEDmite de GitHub sobre el n\xFAmero de pedidos por hora. El resultado se guardar\xE1 en un archivo "),et=o(wa,"EM",{});var xp=i(et);oo=l(xp,"repository_name-issues.jsonl"),xp.forEach(a),io=l(wa,", donde cada l\xEDnea es un objeto JSON que representa un issue. Usemos esta funci\xF3n para cargar todos los issues de \u{1F917} Datasets:"),wa.forEach(a),yl=c(s),v(fe.$$.fragment,s),wl=c(s),Ps=o(s,"P",{});var Br=i(Ps);uo=l(Br,"Una vez los issues est\xE9n descargados, los podemos cargar localmente usando las habilidades aprendidas en la "),ma=o(Br,"A",{href:!0});var jp=i(ma);po=l(jp,"secci\xF3n 2"),jp.forEach(a),co=l(Br,":"),Br.forEach(a),kl=c(s),v(ge.$$.fragment,s),Pl=c(s),v(_e.$$.fragment,s),Dl=c(s),ss=o(s,"P",{});var ka=i(ss);mo=l(ka,"\xA1Genial! Hemos creado nuestro primer dataset desde cero. Pero, \xBFpor qu\xE9 hay varios miles de issues cuando la "),be=o(ka,"A",{href:!0,rel:!0});var $p=i(be);ho=l($p,"pesta\xF1a de Issues"),$p.forEach(a),fo=l(ka," del repositorio de \u{1F917} Datasets s\xF3lo muestra alrededor de 1.000 en total? Como se describe en la "),ve=o(ka,"A",{href:!0,rel:!0});var qp=i(ve);go=l(qp,"documentaci\xF3n"),qp.forEach(a),_o=l(ka,", esto sucede porque tambi\xE9n descargamos todos los pull requests:"),ka.forEach(a),Hl=c(s),ha=o(s,"BLOCKQUOTE",{});var Ep=i(ha);ms=o(Ep,"P",{});var Pa=i(ms);bo=l(Pa,"GitHub\u2019s REST API v3 considers every pull request an issue, but not every issue is a pull request. For this reason, \u201CIssues\u201D endpoints may return both issues and pull requests in the response. You can identify pull requests by the "),at=o(Pa,"CODE",{});var yp=i(at);vo=l(yp,"pull_request"),yp.forEach(a),xo=l(Pa," key. Be aware that the "),tt=o(Pa,"CODE",{});var wp=i(tt);jo=l(wp,"id"),wp.forEach(a),$o=l(Pa," of a pull request returned from \u201CIssues\u201D endpoints will be an issue id."),Pa.forEach(a),Ep.forEach(a),Ol=c(s),fa=o(s,"P",{});var kp=i(fa);qo=l(kp,"Como el contenido de los issues y pull requests son diferentes, hagamos un preprocesamiento simple para distinguirlos entre s\xED."),kp.forEach(a),Al=c(s),hs=o(s,"H2",{class:!0});var Vr=i(hs);Ds=o(Vr,"A",{id:!0,class:!0,href:!0});var Pp=i(Ds);lt=o(Pp,"SPAN",{});var Dp=i(lt);v(xe.$$.fragment,Dp),Dp.forEach(a),Pp.forEach(a),Eo=c(Vr),rt=o(Vr,"SPAN",{});var Hp=i(rt);yo=l(Hp,"Limpiando los datos"),Hp.forEach(a),Vr.forEach(a),Cl=c(s),I=o(s,"P",{});var B=i(I);wo=l(B,"El fragmento anterior de la documentaci\xF3n de GitHub nos dice que la columna "),nt=o(B,"CODE",{});var Op=i(nt);ko=l(Op,"pull_request"),Op.forEach(a),Po=l(B," puede usarse para diferenciar los issues de los pull requests. Veamos una muestra aleatoria para ver la diferencia. Como hicimos en la "),ga=o(B,"A",{href:!0});var Ap=i(ga);Do=l(Ap,"secci\xF3n 3"),Ap.forEach(a),Ho=l(B,", vamos a encadenar "),ot=o(B,"CODE",{});var Cp=i(ot);Oo=l(Cp,"Dataset.shuffle()"),Cp.forEach(a),Ao=l(B," y "),it=o(B,"CODE",{});var Tp=i(it);Co=l(Tp,"Dataset.select()"),Tp.forEach(a),To=l(B," para crear una muestra aleatoria y luego unir las columnas de "),ut=o(B,"CODE",{});var Np=i(ut);No=l(Np,"html_url"),Np.forEach(a),Go=l(B," y "),pt=o(B,"CODE",{});var Gp=i(pt);Io=l(Gp,"pull_request"),Gp.forEach(a),Ro=l(B," para comparar las distintas URL:"),B.forEach(a),Tl=c(s),v(je.$$.fragment,s),Nl=c(s),v($e.$$.fragment,s),Gl=c(s),M=o(s,"P",{});var us=i(M);So=l(us,"Podemos ver que cada pull request est\xE1 asociado con varias URL, mientras que los issues ordinarios tienen una entrada "),ct=o(us,"CODE",{});var Ip=i(ct);Uo=l(Ip,"None"),Ip.forEach(a),zo=l(us,". Podemos usar esta distinci\xF3n para crear una nueva columna "),dt=o(us,"CODE",{});var Rp=i(dt);Lo=l(Rp,"is_pull_request"),Rp.forEach(a),Mo=l(us," que revisa si el campo "),mt=o(us,"CODE",{});var Sp=i(mt);Fo=l(Sp,"pull_request"),Sp.forEach(a),Bo=l(us," es "),ht=o(us,"CODE",{});var Up=i(ht);Vo=l(Up,"None"),Up.forEach(a),Qo=l(us," o no:"),us.forEach(a),Il=c(s),v(qe.$$.fragment,s),Rl=c(s),v(Hs.$$.fragment,s),Sl=c(s),_a=o(s,"P",{});var zp=i(_a);Jo=l(zp,"Si bien podemos limpiar a\xFAn m\xE1s el dataset eliminando o renombrando algunas columnas, es una buena pr\xE1ctica mantener un dataset lo m\xE1s parecido al original en esta etapa, para que se pueda usar f\xE1cilmente en varias aplicaciones."),zp.forEach(a),Ul=c(s),ba=o(s,"P",{});var Lp=i(ba);Zo=l(Lp,"Antes de subir el dataset el Hub de Hugging Face, nos hace falta a\xF1adirle algo m\xE1s: los comentarios asociados con cada issue y pull request. Los vamos a a\xF1adir con el API REST de GitHub."),Lp.forEach(a),zl=c(s),fs=o(s,"H2",{class:!0});var Qr=i(fs);Os=o(Qr,"A",{id:!0,class:!0,href:!0});var Mp=i(Os);ft=o(Mp,"SPAN",{});var Fp=i(ft);v(Ee.$$.fragment,Fp),Fp.forEach(a),Mp.forEach(a),Ko=c(Qr),gt=o(Qr,"SPAN",{});var Bp=i(gt);Xo=l(Bp,"Ampliando el dataset"),Bp.forEach(a),Qr.forEach(a),Ll=c(s),va=o(s,"P",{});var Vp=i(va);Wo=l(Vp,"Como se muestra en la siguiente captura de pantalla, los comentarios asociados con un issue o un pull request son una fuente rica de informaci\xF3n, especialmente si estamos interesados en construir un motor de b\xFAsqueda para responder preguntas de usuarios sobre la librer\xEDa."),Vp.forEach(a),Ml=c(s),ye=o(s,"DIV",{class:!0});var Qp=i(ye);we=o(Qp,"IMG",{src:!0,alt:!0,width:!0}),Qp.forEach(a),Fl=c(s),As=o(s,"P",{});var Jr=i(As);Yo=l(Jr,"El API REST de GitHub tiene un "),Cs=o(Jr,"A",{href:!0,rel:!0});var Gu=i(Cs);si=l(Gu,"endpoint "),_t=o(Gu,"CODE",{});var Jp=i(_t);ei=l(Jp,"Comments"),Jp.forEach(a),Gu.forEach(a),ai=l(Jr," que devuelve todos los comentarios asociados con un n\xFAmero de issue. Prob\xE9mos este endpoint para ver qu\xE9 devuelve:"),Jr.forEach(a),Bl=c(s),v(ke.$$.fragment,s),Vl=c(s),v(Pe.$$.fragment,s),Ql=c(s),Z=o(s,"P",{});var Ks=i(Z);ti=l(Ks,"Podemos ver que el comentario est\xE1 almacenado en el campo "),bt=o(Ks,"CODE",{});var Zp=i(bt);li=l(Zp,"body"),Zp.forEach(a),ri=l(Ks,", as\xED que escribamos una funci\xF3n simple que devuelva todos los comentarios asociados con un issue al extraer el contenido de "),vt=o(Ks,"CODE",{});var Kp=i(vt);ni=l(Kp,"body"),Kp.forEach(a),oi=l(Ks," para cada elemento en el "),xt=o(Ks,"CODE",{});var Xp=i(xt);ii=l(Xp,"response.json()"),Xp.forEach(a),ui=l(Ks,":"),Ks.forEach(a),Jl=c(s),v(De.$$.fragment,s),Zl=c(s),v(He.$$.fragment,s),Kl=c(s),es=o(s,"P",{});var Da=i(es);pi=l(Da,"Esto luce bien, as\xED que usemos "),jt=o(Da,"CODE",{});var Wp=i(jt);ci=l(Wp,"Dataset.map()"),Wp.forEach(a),di=l(Da," para a\xF1adir una nueva columna "),$t=o(Da,"CODE",{});var Yp=i($t);mi=l(Yp,"comments"),Yp.forEach(a),hi=l(Da," a cada issue en el dataset:"),Da.forEach(a),Xl=c(s),v(Oe.$$.fragment,s),Wl=c(s),xa=o(s,"P",{});var sc=i(xa);fi=l(sc,"El \xFAltimo paso es guardar el dataset ampliado en el mismo lugar que los datos originales para poderlos subir al Hub:"),sc.forEach(a),Yl=c(s),v(Ae.$$.fragment,s),sr=c(s),gs=o(s,"H2",{class:!0});var Zr=i(gs);Ts=o(Zr,"A",{id:!0,class:!0,href:!0});var ec=i(Ts);qt=o(ec,"SPAN",{});var ac=i(qt);v(Ce.$$.fragment,ac),ac.forEach(a),ec.forEach(a),gi=c(Zr),Et=o(Zr,"SPAN",{});var tc=i(Et);_i=l(tc,"Subiendo un dataset al Hub de Hugging Face"),tc.forEach(a),Zr.forEach(a),er=c(s),v(Te.$$.fragment,s),ar=c(s),as=o(s,"P",{});var Ha=i(as);bi=l(Ha,"Ahora que tenemos nuestro dataset ampliado, es momento de subirlo al Hub para poder compartirlo con la comunidad. Para subir el dataset tenemos que usar la "),Ne=o(Ha,"A",{href:!0,rel:!0});var lc=i(Ne);vi=l(lc,"librer\xEDa \u{1F917} Hub"),lc.forEach(a),xi=l(Ha,", que nos permite interactuar con el Hub de Hugging Face usando una API de Python. \u{1F917} Hub viene instalada con \u{1F917} Transformers, as\xED que podemos usarla directamente. Por ejemplo, podemos usar la funci\xF3n "),yt=o(Ha,"CODE",{});var rc=i(yt);ji=l(rc,"list_datasets()"),rc.forEach(a),$i=l(Ha," para obtener informaci\xF3n sobre todos los datasets p\xFAblicos que est\xE1n almacenados en el Hub:"),Ha.forEach(a),tr=c(s),v(Ge.$$.fragment,s),lr=c(s),v(Ie.$$.fragment,s),rr=c(s),Ns=o(s,"P",{});var Kr=i(Ns);qi=l(Kr,"Podemos ver que hay alrededor de 1.500 datasets en el Hub y que la funci\xF3n "),wt=o(Kr,"CODE",{});var nc=i(wt);Ei=l(nc,"list_datasets()"),nc.forEach(a),yi=l(Kr," tambi\xE9n provee algunos metadatos sobre el repositorio de cada uno."),Kr.forEach(a),nr=c(s),Gs=o(s,"P",{});var Xr=i(Gs);wi=l(Xr,"Para lo que queremos hacer, lo primero que necesitamos es crear un nuevo repositorio de dataset en el Hub. Para ello, necesitamos un token de autenticaci\xF3n, que se obtiene al acceder al Hub de Hugging Face con la funci\xF3n "),kt=o(Xr,"CODE",{});var oc=i(kt);ki=l(oc,"notebook_login()"),oc.forEach(a),Pi=l(Xr,":"),Xr.forEach(a),or=c(s),v(Re.$$.fragment,s),ir=c(s),Is=o(s,"P",{});var Wr=i(Is);Di=l(Wr,"Esto crea un widget en el que ingresas tu nombre de usuario y contrase\xF1a, y guarda un token API en "),Pt=o(Wr,"EM",{});var ic=i(Pt);Hi=l(ic,"~/.huggingface/token"),ic.forEach(a),Oi=l(Wr,". Si est\xE1s ejecutando el c\xF3digo en la terminal, puedes acceder a trav\xE9s de la l\xEDnea de comandos as\xED:"),Wr.forEach(a),ur=c(s),v(Se.$$.fragment,s),pr=c(s),Rs=o(s,"P",{});var Yr=i(Rs);Ai=l(Yr,"Una vez hecho esto, podemos crear un nuevo repositorio para el dataset con la funci\xF3n "),Dt=o(Yr,"CODE",{});var uc=i(Dt);Ci=l(uc,"create_repo()"),uc.forEach(a),Ti=l(Yr,":"),Yr.forEach(a),cr=c(s),v(Ue.$$.fragment,s),dr=c(s),v(ze.$$.fragment,s),mr=c(s),ts=o(s,"P",{});var Oa=i(ts);Ni=l(Oa,"En este ejemplo, hemos creado un repositorio vac\xEDo para el dataset llamado "),Ht=o(Oa,"CODE",{});var pc=i(Ht);Gi=l(pc,"github-issues"),pc.forEach(a),Ii=l(Oa," bajo el nombre de usuario "),Ot=o(Oa,"CODE",{});var cc=i(Ot);Ri=l(cc,"lewtun"),cc.forEach(a),Si=l(Oa," (\xA1el nombre de usuario deber\xEDa ser tu nombre de usuario del Hub cuando est\xE9s ejecutando este c\xF3digo!)."),Oa.forEach(a),hr=c(s),v(Ss.$$.fragment,s),fr=c(s),Us=o(s,"P",{});var sn=i(Us);Ui=l(sn,"Ahora clonemos el repositorio del Hub a nuestra m\xE1quina local y copiemos nuestro dataset ah\xED. \u{1F917} Hub incluye una clase "),At=o(sn,"CODE",{});var dc=i(At);zi=l(dc,"Repositorio"),dc.forEach(a),Li=l(sn," que envuelve muchos de los comandos comunes de Git, as\xED que para clonar el repositorio remoto solamente necesitamos dar la URL y la ruta local en la que lo queremos clonar:"),sn.forEach(a),gr=c(s),v(Le.$$.fragment,s),_r=c(s),F=o(s,"P",{});var ps=i(F);Mi=l(ps,"Por defecto, varias extensiones de archivo (como "),Ct=o(ps,"EM",{});var mc=i(Ct);Fi=l(mc,".bin"),mc.forEach(a),Bi=l(ps,", "),Tt=o(ps,"EM",{});var hc=i(Tt);Vi=l(hc,".gz"),hc.forEach(a),Qi=l(ps,", and "),Nt=o(ps,"EM",{});var fc=i(Nt);Ji=l(fc,".zip"),fc.forEach(a),Zi=l(ps,") se siguen con Git LFS de tal manera que los archivos grandes se pueden versionar dentro del mismo flujo de trabajo de Git. Puedes encontrar una lista de extensiones que se van a seguir en el archivo "),Gt=o(ps,"EM",{});var gc=i(Gt);Ki=l(gc,".gitattributes"),gc.forEach(a),Xi=l(ps,". Para incluir el formato JSON Lines en la lista, puedes ejecutar el siguiente comando:"),ps.forEach(a),br=c(s),v(Me.$$.fragment,s),vr=c(s),zs=o(s,"P",{});var en=i(zs);Wi=l(en,"Luego, podemos usar "),It=o(en,"CODE",{});var _c=i(It);Yi=l(_c,"$$Repository.push_to_hub()"),_c.forEach(a),su=l(en," para subir el dataset al Hub:"),en.forEach(a),xr=c(s),v(Fe.$$.fragment,s),jr=c(s),Ls=o(s,"P",{});var an=i(Ls);eu=l(an,"Si navegamos a la URL que aparece en "),Rt=o(an,"CODE",{});var bc=i(Rt);au=l(bc,"repo_url"),bc.forEach(a),tu=l(an,", deber\xEDamos ver que el archivo del dataset se ha subido."),an.forEach(a),$r=c(s),Be=o(s,"DIV",{class:!0});var vc=i(Be);Ve=o(vc,"IMG",{src:!0,alt:!0,width:!0}),vc.forEach(a),qr=c(s),ls=o(s,"P",{});var Aa=i(ls);lu=l(Aa,"Desde aqui, cualquier persona podr\xE1 descargar el dataset incluyendo el ID del repositorio en el argumento "),St=o(Aa,"CODE",{});var xc=i(St);ru=l(xc,"path"),xc.forEach(a),nu=l(Aa," de la funci\xF3n "),Ut=o(Aa,"CODE",{});var jc=i(Ut);ou=l(jc,"load_dataset()"),jc.forEach(a),iu=l(Aa,":"),Aa.forEach(a),Er=c(s),v(Qe.$$.fragment,s),yr=c(s),v(Je.$$.fragment,s),wr=c(s),rs=o(s,"P",{});var Ca=i(rs);uu=l(Ca,"\xA1Genial, hemos subido el dataset al Hub y ya est\xE1 disponible para que otras personas lo usen! S\xF3lo hay una cosa restante por hacer: a\xF1adir una "),zt=o(Ca,"EM",{});var $c=i(zt);pu=l($c,"tarjeta del dataset"),$c.forEach(a),cu=l(Ca," ("),Lt=o(Ca,"EM",{});var qc=i(Lt);du=l(qc,"dataset card"),qc.forEach(a),mu=l(Ca,") que explique c\xF3mo se cre\xF3 el corpus y provea informaci\xF3n \xFAtil para la comunidad."),Ca.forEach(a),kr=c(s),v(Ms.$$.fragment,s),Pr=c(s),_s=o(s,"H2",{class:!0});var tn=i(_s);Fs=o(tn,"A",{id:!0,class:!0,href:!0});var Ec=i(Fs);Mt=o(Ec,"SPAN",{});var yc=i(Mt);v(Ze.$$.fragment,yc),yc.forEach(a),Ec.forEach(a),hu=c(tn),Ft=o(tn,"SPAN",{});var wc=i(Ft);fu=l(wc,"Creando una tarjeta del dataset"),wc.forEach(a),tn.forEach(a),Dr=c(s),ja=o(s,"P",{});var kc=i(ja);gu=l(kc,"Los datasets bien documentados tienen m\xE1s probabilidades de ser \xFAtiles para otros (incluy\xE9ndote a ti en el futuro), dado que brindan la informaci\xF3n necesaria para que los usuarios decidan si el dataset es \xFAtil para su tarea, as\xED como para evaluar cualquier sesgo o riesgo potencial asociado a su uso."),kc.forEach(a),Hr=c(s),Bs=o(s,"P",{});var ln=i(Bs);_u=l(ln,"En el Hub de Hugging Face, esta informaci\xF3n se almacena en el archivo "),Bt=o(ln,"EM",{});var Pc=i(Bt);bu=l(Pc,"README.md"),Pc.forEach(a),vu=l(ln," del repositorio del dataset. Hay dos pasos que deber\xEDas hacer antes de crear este archivo:"),ln.forEach(a),Or=c(s),$a=o(s,"OL",{});var Dc=i($a);bs=o(Dc,"LI",{});var Ta=i(bs);xu=l(Ta,"Usa la "),Vs=o(Ta,"A",{href:!0,rel:!0});var Iu=i(Vs);ju=l(Iu,"aplicaci\xF3n "),Vt=o(Iu,"CODE",{});var Hc=i(Vt);$u=l(Hc,"datasets-tagging"),Hc.forEach(a),Iu.forEach(a),qu=l(Ta," para crear etiquetas de metadatos en el formato YAML. Estas etiquetas se usan para una variedad de funciones de b\xFAsqueda en el Hub de Hugging Face y aseguran que otros miembros de la comunidad puedan encontrar tu dataset. Dado que creamos un dataset personalizado en esta secci\xF3n, tendremos que clonar el repositorio "),Qt=o(Ta,"CODE",{});var Oc=i(Qt);Eu=l(Oc,"datasets-tagging"),Oc.forEach(a),yu=l(Ta," y correr la aplicaci\xF3n localmente. As\xED se ve la interfaz de la aplicaci\xF3n:"),Ta.forEach(a),Dc.forEach(a),Ar=c(s),Ke=o(s,"DIV",{class:!0});var Ac=i(Ke);Xe=o(Ac,"IMG",{src:!0,alt:!0,width:!0}),Ac.forEach(a),Cr=c(s),We=o(s,"OL",{start:!0});var Cc=i(We);Ye=o(Cc,"LI",{});var rn=i(Ye);wu=l(rn,"Lee la "),sa=o(rn,"A",{href:!0,rel:!0});var Tc=i(sa);ku=l(Tc,"gu\xEDa de \u{1F917} Datasets"),Tc.forEach(a),Pu=l(rn," sobre c\xF3mo crear tarjetas informativas y usarlas como plantilla."),rn.forEach(a),Cc.forEach(a),Tr=c(s),ns=o(s,"P",{});var Na=i(ns);Du=l(Na,"Puedes crear el archivo "),Jt=o(Na,"EM",{});var Nc=i(Jt);Hu=l(Nc,"README.md"),Nc.forEach(a),Ou=l(Na," drectamente desde el Hub y puedes encontrar una plantilla de tarjeta en el repositorio "),Zt=o(Na,"CODE",{});var Gc=i(Zt);Au=l(Gc,"lewtun/github-issues"),Gc.forEach(a),Cu=l(Na,". As\xED se ve una tarjeta de dataset diligenciada:"),Na.forEach(a),Nr=c(s),ea=o(s,"DIV",{class:!0});var Ic=i(ea);aa=o(Ic,"IMG",{src:!0,alt:!0,width:!0}),Ic.forEach(a),Gr=c(s),v(Qs.$$.fragment,s),Ir=c(s),qa=o(s,"P",{});var Rc=i(qa);Tu=l(Rc,"\xA1Eso es todo! Hemos visto que crear un buen dataset requiere de mucho esfuerzo de tu parte, pero afortunadamente subirlo y compartirlo con la comunidad no. En la siguiente secci\xF3n usaremos nuestro nuevo dataset para crear un motor de b\xFAsqueda sem\xE1ntica con \u{1F917} Datasets que pueda emparejar pregunras con los issues y comentarios m\xE1s relevantes."),Rc.forEach(a),Rr=c(s),v(Js.$$.fragment,s),this.h()},h(){m(d,"name","hf:doc:metadata"),m(d,"content",JSON.stringify(sd)),m(E,"id","crea-tu-propio-dataset"),m(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(E,"href","#crea-tu-propio-dataset"),m(h,"class","relative group"),m(N,"href","https://github.com/features/issues/"),m(N,"rel","nofollow"),m(js,"id","obteniendo-los-datos"),m(js,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(js,"href","#obteniendo-los-datos"),m(ds,"class","relative group"),m(Ws,"href","https://github.com/huggingface/datasets/issues"),m(Ws,"rel","nofollow"),Ga(se.src,Ru="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-issues.png")||m(se,"src",Ru),m(se,"alt","The GitHub issues associated with \u{1F917} Datasets."),m(se,"width","80%"),m(Ys,"class","flex justify-center"),Ga(ae.src,Su="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-issues-single.png")||m(ae,"src",Su),m(ae,"alt","A typical GitHub issue in the \u{1F917} Datasets repository."),m(ae,"width","80%"),m(ee,"class","flex justify-center"),m(te,"href","https://docs.github.com/en/rest"),m(te,"rel","nofollow"),m(qs,"href","https://docs.github.com/en/rest/reference/issues#list-repository-issues"),m(qs,"rel","nofollow"),m(ie,"href","https://en.wikipedia.org/wiki/List_of_HTTP_status_codes"),m(ie,"rel","nofollow"),m(ce,"href","https://docs.github.com/en/rest/overview/resources-in-the-rest-api#rate-limiting"),m(ce,"rel","nofollow"),m(de,"href","https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token"),m(de,"rel","nofollow"),m(ma,"href","/course/chaper5/2"),m(be,"href","https://github.com/huggingface/datasets/issues"),m(be,"rel","nofollow"),m(ve,"href","https://docs.github.com/en/rest/reference/issues#list-issues-assigned-to-the-authenticated-user"),m(ve,"rel","nofollow"),m(Ds,"id","limpiando-los-datos"),m(Ds,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Ds,"href","#limpiando-los-datos"),m(hs,"class","relative group"),m(ga,"href","/course/chapter5/3"),m(Os,"id","ampliando-el-dataset"),m(Os,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Os,"href","#ampliando-el-dataset"),m(fs,"class","relative group"),Ga(we.src,Uu="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-issues-comment.png")||m(we,"src",Uu),m(we,"alt","Comments associated with an issue about \u{1F917} Datasets."),m(we,"width","80%"),m(ye,"class","flex justify-center"),m(Cs,"href","https://docs.github.com/en/rest/reference/issues#list-issue-comments"),m(Cs,"rel","nofollow"),m(Ts,"id","subiendo-un-dataset-al-hub-de-hugging-face"),m(Ts,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Ts,"href","#subiendo-un-dataset-al-hub-de-hugging-face"),m(gs,"class","relative group"),m(Ne,"href","https://github.com/huggingface/huggingface_hub"),m(Ne,"rel","nofollow"),Ga(Ve.src,zu="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/hub-repo.png")||m(Ve,"src",zu),m(Ve,"alt","Our dataset repository on the Hugging Face Hub."),m(Ve,"width","80%"),m(Be,"class","flex justify-center"),m(Fs,"id","creando-una-tarjeta-del-dataset"),m(Fs,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Fs,"href","#creando-una-tarjeta-del-dataset"),m(_s,"class","relative group"),m(Vs,"href","https://huggingface.co/datasets/tagging/"),m(Vs,"rel","nofollow"),Ga(Xe.src,Lu="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-tagger.png")||m(Xe,"src",Lu),m(Xe,"alt","The `datasets-tagging` interface."),m(Xe,"width","80%"),m(Ke,"class","flex justify-center"),m(sa,"href","https://github.com/huggingface/datasets/blob/master/templates/README_guide.md"),m(sa,"rel","nofollow"),m(We,"start","2"),Ga(aa.src,Mu="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/dataset-card.png")||m(aa,"src",Mu),m(aa,"alt","A dataset card."),m(aa,"width","80%"),m(ea,"class","flex justify-center")},m(s,r){e(document.head,d),u(s,D,r),u(s,h,r),e(h,E),e(E,w),x(f,w,null),e(h,O),e(h,k),e(k,g),u(s,_,r),x(H,s,r),u(s,y,r),u(s,P,r),e(P,T),e(P,N),e(N,C),e(P,V),u(s,U,r),u(s,R,r),e(R,Q),e(Q,cs),e(R,G),e(R,K),e(K,na),e(K,xs),e(xs,oa),e(K,ia),e(R,ua),e(R,Ra),e(Ra,nn),u(s,sl,r),u(s,pa,r),e(pa,on),u(s,el,r),u(s,ds,r),e(ds,js),e(js,Sa),x(Xs,Sa,null),e(ds,un),e(ds,Ua),e(Ua,pn),u(s,al,r),u(s,$s,r),e($s,cn),e($s,Ws),e(Ws,dn),e($s,mn),u(s,tl,r),u(s,Ys,r),e(Ys,se),u(s,ll,r),u(s,ca,r),e(ca,hn),u(s,rl,r),u(s,ee,r),e(ee,ae),u(s,nl,r),u(s,X,r),e(X,fn),e(X,te),e(te,gn),e(X,_n),e(X,qs),e(qs,bn),e(qs,za),e(za,vn),e(X,xn),u(s,ol,r),u(s,Es,r),e(Es,jn),e(Es,La),e(La,$n),e(Es,qn),u(s,il,r),x(le,s,r),u(s,ul,r),u(s,W,r),e(W,En),e(W,Ma),e(Ma,yn),e(W,wn),e(W,Fa),e(Fa,kn),e(W,Pn),u(s,pl,r),x(re,s,r),u(s,cl,r),u(s,ys,r),e(ys,Dn),e(ys,Ba),e(Ba,Hn),e(ys,On),u(s,dl,r),x(ne,s,r),u(s,ml,r),x(oe,s,r),u(s,hl,r),u(s,z,r),e(z,An),e(z,Va),e(Va,Cn),e(z,Tn),e(z,ie),e(ie,Nn),e(z,Gn),e(z,Qa),e(Qa,In),e(z,Rn),e(z,Ja),e(Ja,Sn),e(z,Un),u(s,fl,r),x(ue,s,r),u(s,gl,r),x(pe,s,r),u(s,_l,r),u(s,J,r),e(J,zn),e(J,Za),e(Za,Ln),e(J,Mn),e(J,Ka),e(Ka,Fn),e(J,Bn),e(J,Xa),e(Xa,Vn),e(J,Qn),u(s,bl,r),x(ws,s,r),u(s,vl,r),u(s,L,r),e(L,Jn),e(L,ce),e(ce,Zn),e(L,Kn),e(L,Wa),e(Wa,Xn),e(L,Wn),e(L,de),e(de,Yn),e(L,so),e(L,Ya),e(Ya,eo),e(L,ao),u(s,xl,r),x(me,s,r),u(s,jl,r),x(ks,s,r),u(s,$l,r),u(s,da,r),e(da,to),u(s,ql,r),x(he,s,r),u(s,El,r),u(s,Y,r),e(Y,lo),e(Y,st),e(st,ro),e(Y,no),e(Y,et),e(et,oo),e(Y,io),u(s,yl,r),x(fe,s,r),u(s,wl,r),u(s,Ps,r),e(Ps,uo),e(Ps,ma),e(ma,po),e(Ps,co),u(s,kl,r),x(ge,s,r),u(s,Pl,r),x(_e,s,r),u(s,Dl,r),u(s,ss,r),e(ss,mo),e(ss,be),e(be,ho),e(ss,fo),e(ss,ve),e(ve,go),e(ss,_o),u(s,Hl,r),u(s,ha,r),e(ha,ms),e(ms,bo),e(ms,at),e(at,vo),e(ms,xo),e(ms,tt),e(tt,jo),e(ms,$o),u(s,Ol,r),u(s,fa,r),e(fa,qo),u(s,Al,r),u(s,hs,r),e(hs,Ds),e(Ds,lt),x(xe,lt,null),e(hs,Eo),e(hs,rt),e(rt,yo),u(s,Cl,r),u(s,I,r),e(I,wo),e(I,nt),e(nt,ko),e(I,Po),e(I,ga),e(ga,Do),e(I,Ho),e(I,ot),e(ot,Oo),e(I,Ao),e(I,it),e(it,Co),e(I,To),e(I,ut),e(ut,No),e(I,Go),e(I,pt),e(pt,Io),e(I,Ro),u(s,Tl,r),x(je,s,r),u(s,Nl,r),x($e,s,r),u(s,Gl,r),u(s,M,r),e(M,So),e(M,ct),e(ct,Uo),e(M,zo),e(M,dt),e(dt,Lo),e(M,Mo),e(M,mt),e(mt,Fo),e(M,Bo),e(M,ht),e(ht,Vo),e(M,Qo),u(s,Il,r),x(qe,s,r),u(s,Rl,r),x(Hs,s,r),u(s,Sl,r),u(s,_a,r),e(_a,Jo),u(s,Ul,r),u(s,ba,r),e(ba,Zo),u(s,zl,r),u(s,fs,r),e(fs,Os),e(Os,ft),x(Ee,ft,null),e(fs,Ko),e(fs,gt),e(gt,Xo),u(s,Ll,r),u(s,va,r),e(va,Wo),u(s,Ml,r),u(s,ye,r),e(ye,we),u(s,Fl,r),u(s,As,r),e(As,Yo),e(As,Cs),e(Cs,si),e(Cs,_t),e(_t,ei),e(As,ai),u(s,Bl,r),x(ke,s,r),u(s,Vl,r),x(Pe,s,r),u(s,Ql,r),u(s,Z,r),e(Z,ti),e(Z,bt),e(bt,li),e(Z,ri),e(Z,vt),e(vt,ni),e(Z,oi),e(Z,xt),e(xt,ii),e(Z,ui),u(s,Jl,r),x(De,s,r),u(s,Zl,r),x(He,s,r),u(s,Kl,r),u(s,es,r),e(es,pi),e(es,jt),e(jt,ci),e(es,di),e(es,$t),e($t,mi),e(es,hi),u(s,Xl,r),x(Oe,s,r),u(s,Wl,r),u(s,xa,r),e(xa,fi),u(s,Yl,r),x(Ae,s,r),u(s,sr,r),u(s,gs,r),e(gs,Ts),e(Ts,qt),x(Ce,qt,null),e(gs,gi),e(gs,Et),e(Et,_i),u(s,er,r),x(Te,s,r),u(s,ar,r),u(s,as,r),e(as,bi),e(as,Ne),e(Ne,vi),e(as,xi),e(as,yt),e(yt,ji),e(as,$i),u(s,tr,r),x(Ge,s,r),u(s,lr,r),x(Ie,s,r),u(s,rr,r),u(s,Ns,r),e(Ns,qi),e(Ns,wt),e(wt,Ei),e(Ns,yi),u(s,nr,r),u(s,Gs,r),e(Gs,wi),e(Gs,kt),e(kt,ki),e(Gs,Pi),u(s,or,r),x(Re,s,r),u(s,ir,r),u(s,Is,r),e(Is,Di),e(Is,Pt),e(Pt,Hi),e(Is,Oi),u(s,ur,r),x(Se,s,r),u(s,pr,r),u(s,Rs,r),e(Rs,Ai),e(Rs,Dt),e(Dt,Ci),e(Rs,Ti),u(s,cr,r),x(Ue,s,r),u(s,dr,r),x(ze,s,r),u(s,mr,r),u(s,ts,r),e(ts,Ni),e(ts,Ht),e(Ht,Gi),e(ts,Ii),e(ts,Ot),e(Ot,Ri),e(ts,Si),u(s,hr,r),x(Ss,s,r),u(s,fr,r),u(s,Us,r),e(Us,Ui),e(Us,At),e(At,zi),e(Us,Li),u(s,gr,r),x(Le,s,r),u(s,_r,r),u(s,F,r),e(F,Mi),e(F,Ct),e(Ct,Fi),e(F,Bi),e(F,Tt),e(Tt,Vi),e(F,Qi),e(F,Nt),e(Nt,Ji),e(F,Zi),e(F,Gt),e(Gt,Ki),e(F,Xi),u(s,br,r),x(Me,s,r),u(s,vr,r),u(s,zs,r),e(zs,Wi),e(zs,It),e(It,Yi),e(zs,su),u(s,xr,r),x(Fe,s,r),u(s,jr,r),u(s,Ls,r),e(Ls,eu),e(Ls,Rt),e(Rt,au),e(Ls,tu),u(s,$r,r),u(s,Be,r),e(Be,Ve),u(s,qr,r),u(s,ls,r),e(ls,lu),e(ls,St),e(St,ru),e(ls,nu),e(ls,Ut),e(Ut,ou),e(ls,iu),u(s,Er,r),x(Qe,s,r),u(s,yr,r),x(Je,s,r),u(s,wr,r),u(s,rs,r),e(rs,uu),e(rs,zt),e(zt,pu),e(rs,cu),e(rs,Lt),e(Lt,du),e(rs,mu),u(s,kr,r),x(Ms,s,r),u(s,Pr,r),u(s,_s,r),e(_s,Fs),e(Fs,Mt),x(Ze,Mt,null),e(_s,hu),e(_s,Ft),e(Ft,fu),u(s,Dr,r),u(s,ja,r),e(ja,gu),u(s,Hr,r),u(s,Bs,r),e(Bs,_u),e(Bs,Bt),e(Bt,bu),e(Bs,vu),u(s,Or,r),u(s,$a,r),e($a,bs),e(bs,xu),e(bs,Vs),e(Vs,ju),e(Vs,Vt),e(Vt,$u),e(bs,qu),e(bs,Qt),e(Qt,Eu),e(bs,yu),u(s,Ar,r),u(s,Ke,r),e(Ke,Xe),u(s,Cr,r),u(s,We,r),e(We,Ye),e(Ye,wu),e(Ye,sa),e(sa,ku),e(Ye,Pu),u(s,Tr,r),u(s,ns,r),e(ns,Du),e(ns,Jt),e(Jt,Hu),e(ns,Ou),e(ns,Zt),e(Zt,Au),e(ns,Cu),u(s,Nr,r),u(s,ea,r),e(ea,aa),u(s,Gr,r),x(Qs,s,r),u(s,Ir,r),u(s,qa,r),e(qa,Tu),u(s,Rr,r),x(Js,s,r),Sr=!0},p(s,[r]){const ta={};r&2&&(ta.$$scope={dirty:r,ctx:s}),ws.$set(ta);const Kt={};r&2&&(Kt.$$scope={dirty:r,ctx:s}),ks.$set(Kt);const Xt={};r&2&&(Xt.$$scope={dirty:r,ctx:s}),Hs.$set(Xt);const Wt={};r&2&&(Wt.$$scope={dirty:r,ctx:s}),Ss.$set(Wt);const la={};r&2&&(la.$$scope={dirty:r,ctx:s}),Ms.$set(la);const Yt={};r&2&&(Yt.$$scope={dirty:r,ctx:s}),Qs.$set(Yt);const vs={};r&2&&(vs.$$scope={dirty:r,ctx:s}),Js.$set(vs)},i(s){Sr||(j(f.$$.fragment,s),j(H.$$.fragment,s),j(Xs.$$.fragment,s),j(le.$$.fragment,s),j(re.$$.fragment,s),j(ne.$$.fragment,s),j(oe.$$.fragment,s),j(ue.$$.fragment,s),j(pe.$$.fragment,s),j(ws.$$.fragment,s),j(me.$$.fragment,s),j(ks.$$.fragment,s),j(he.$$.fragment,s),j(fe.$$.fragment,s),j(ge.$$.fragment,s),j(_e.$$.fragment,s),j(xe.$$.fragment,s),j(je.$$.fragment,s),j($e.$$.fragment,s),j(qe.$$.fragment,s),j(Hs.$$.fragment,s),j(Ee.$$.fragment,s),j(ke.$$.fragment,s),j(Pe.$$.fragment,s),j(De.$$.fragment,s),j(He.$$.fragment,s),j(Oe.$$.fragment,s),j(Ae.$$.fragment,s),j(Ce.$$.fragment,s),j(Te.$$.fragment,s),j(Ge.$$.fragment,s),j(Ie.$$.fragment,s),j(Re.$$.fragment,s),j(Se.$$.fragment,s),j(Ue.$$.fragment,s),j(ze.$$.fragment,s),j(Ss.$$.fragment,s),j(Le.$$.fragment,s),j(Me.$$.fragment,s),j(Fe.$$.fragment,s),j(Qe.$$.fragment,s),j(Je.$$.fragment,s),j(Ms.$$.fragment,s),j(Ze.$$.fragment,s),j(Qs.$$.fragment,s),j(Js.$$.fragment,s),Sr=!0)},o(s){$(f.$$.fragment,s),$(H.$$.fragment,s),$(Xs.$$.fragment,s),$(le.$$.fragment,s),$(re.$$.fragment,s),$(ne.$$.fragment,s),$(oe.$$.fragment,s),$(ue.$$.fragment,s),$(pe.$$.fragment,s),$(ws.$$.fragment,s),$(me.$$.fragment,s),$(ks.$$.fragment,s),$(he.$$.fragment,s),$(fe.$$.fragment,s),$(ge.$$.fragment,s),$(_e.$$.fragment,s),$(xe.$$.fragment,s),$(je.$$.fragment,s),$($e.$$.fragment,s),$(qe.$$.fragment,s),$(Hs.$$.fragment,s),$(Ee.$$.fragment,s),$(ke.$$.fragment,s),$(Pe.$$.fragment,s),$(De.$$.fragment,s),$(He.$$.fragment,s),$(Oe.$$.fragment,s),$(Ae.$$.fragment,s),$(Ce.$$.fragment,s),$(Te.$$.fragment,s),$(Ge.$$.fragment,s),$(Ie.$$.fragment,s),$(Re.$$.fragment,s),$(Se.$$.fragment,s),$(Ue.$$.fragment,s),$(ze.$$.fragment,s),$(Ss.$$.fragment,s),$(Le.$$.fragment,s),$(Me.$$.fragment,s),$(Fe.$$.fragment,s),$(Qe.$$.fragment,s),$(Je.$$.fragment,s),$(Ms.$$.fragment,s),$(Ze.$$.fragment,s),$(Qs.$$.fragment,s),$(Js.$$.fragment,s),Sr=!1},d(s){a(d),s&&a(D),s&&a(h),q(f),s&&a(_),q(H,s),s&&a(y),s&&a(P),s&&a(U),s&&a(R),s&&a(sl),s&&a(pa),s&&a(el),s&&a(ds),q(Xs),s&&a(al),s&&a($s),s&&a(tl),s&&a(Ys),s&&a(ll),s&&a(ca),s&&a(rl),s&&a(ee),s&&a(nl),s&&a(X),s&&a(ol),s&&a(Es),s&&a(il),q(le,s),s&&a(ul),s&&a(W),s&&a(pl),q(re,s),s&&a(cl),s&&a(ys),s&&a(dl),q(ne,s),s&&a(ml),q(oe,s),s&&a(hl),s&&a(z),s&&a(fl),q(ue,s),s&&a(gl),q(pe,s),s&&a(_l),s&&a(J),s&&a(bl),q(ws,s),s&&a(vl),s&&a(L),s&&a(xl),q(me,s),s&&a(jl),q(ks,s),s&&a($l),s&&a(da),s&&a(ql),q(he,s),s&&a(El),s&&a(Y),s&&a(yl),q(fe,s),s&&a(wl),s&&a(Ps),s&&a(kl),q(ge,s),s&&a(Pl),q(_e,s),s&&a(Dl),s&&a(ss),s&&a(Hl),s&&a(ha),s&&a(Ol),s&&a(fa),s&&a(Al),s&&a(hs),q(xe),s&&a(Cl),s&&a(I),s&&a(Tl),q(je,s),s&&a(Nl),q($e,s),s&&a(Gl),s&&a(M),s&&a(Il),q(qe,s),s&&a(Rl),q(Hs,s),s&&a(Sl),s&&a(_a),s&&a(Ul),s&&a(ba),s&&a(zl),s&&a(fs),q(Ee),s&&a(Ll),s&&a(va),s&&a(Ml),s&&a(ye),s&&a(Fl),s&&a(As),s&&a(Bl),q(ke,s),s&&a(Vl),q(Pe,s),s&&a(Ql),s&&a(Z),s&&a(Jl),q(De,s),s&&a(Zl),q(He,s),s&&a(Kl),s&&a(es),s&&a(Xl),q(Oe,s),s&&a(Wl),s&&a(xa),s&&a(Yl),q(Ae,s),s&&a(sr),s&&a(gs),q(Ce),s&&a(er),q(Te,s),s&&a(ar),s&&a(as),s&&a(tr),q(Ge,s),s&&a(lr),q(Ie,s),s&&a(rr),s&&a(Ns),s&&a(nr),s&&a(Gs),s&&a(or),q(Re,s),s&&a(ir),s&&a(Is),s&&a(ur),q(Se,s),s&&a(pr),s&&a(Rs),s&&a(cr),q(Ue,s),s&&a(dr),q(ze,s),s&&a(mr),s&&a(ts),s&&a(hr),q(Ss,s),s&&a(fr),s&&a(Us),s&&a(gr),q(Le,s),s&&a(_r),s&&a(F),s&&a(br),q(Me,s),s&&a(vr),s&&a(zs),s&&a(xr),q(Fe,s),s&&a(jr),s&&a(Ls),s&&a($r),s&&a(Be),s&&a(qr),s&&a(ls),s&&a(Er),q(Qe,s),s&&a(yr),q(Je,s),s&&a(wr),s&&a(rs),s&&a(kr),q(Ms,s),s&&a(Pr),s&&a(_s),q(Ze),s&&a(Dr),s&&a(ja),s&&a(Hr),s&&a(Bs),s&&a(Or),s&&a($a),s&&a(Ar),s&&a(Ke),s&&a(Cr),s&&a(We),s&&a(Tr),s&&a(ns),s&&a(Nr),s&&a(ea),s&&a(Gr),q(Qs,s),s&&a(Ir),s&&a(qa),s&&a(Rr),q(Js,s)}}}const sd={local:"crea-tu-propio-dataset",sections:[{local:"obteniendo-los-datos",title:"Obteniendo los datos"},{local:"limpiando-los-datos",title:"Limpiando los datos"},{local:"ampliando-el-dataset",title:"Ampliando el dataset"},{local:"subiendo-un-dataset-al-hub-de-hugging-face",title:"Subiendo un dataset al Hub de Hugging Face"},{local:"creando-una-tarjeta-del-dataset",title:"Creando una tarjeta del dataset"}],title:"Crea tu propio dataset"};function ed(S){return Mc(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class id extends Sc{constructor(d){super();Uc(this,d,ed,Yc,zc,{})}}export{id as default,sd as metadata};
