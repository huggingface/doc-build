import{S as un,i as mn,s as pn,e as r,k as c,w as g,t as s,M as fn,c as n,d as t,m as u,a as l,x as v,h as o,b as p,G as a,g as d,y as $,q,o as E,B as j,v as hn}from"../../chunks/vendor-hf-doc-builder.js";import{T as Bo}from"../../chunks/Tip-hf-doc-builder.js";import{Y as _n}from"../../chunks/Youtube-hf-doc-builder.js";import{I as Ut}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as J}from"../../chunks/CodeBlock-hf-doc-builder.js";import{C as gn}from"../../chunks/CourseFloatingBanner-hf-doc-builder.js";function vn(se){let m,C,f,b,A;return{c(){m=r("p"),C=s("\u270E Si te preguntas por qu\xE9 hay un caracter de signo de admiraci\xF3n ("),f=r("code"),b=s("!"),A=s(") en los comandos de shell, esto es porque los estamos ejecutando desde un cuaderno de Jupyter. Si quieres descargar y descomprimir el archivo directamente desde la terminal, elimina el signo de admiraci\xF3n.")},l(h){m=n(h,"P",{});var S=l(m);C=o(S,"\u270E Si te preguntas por qu\xE9 hay un caracter de signo de admiraci\xF3n ("),f=n(S,"CODE",{});var x=l(f);b=o(x,"!"),x.forEach(t),A=o(S,") en los comandos de shell, esto es porque los estamos ejecutando desde un cuaderno de Jupyter. Si quieres descargar y descomprimir el archivo directamente desde la terminal, elimina el signo de admiraci\xF3n."),S.forEach(t)},m(h,S){d(h,m,S),a(m,C),a(m,f),a(f,b),a(m,A)},d(h){h&&t(m)}}}function $n(se){let m,C,f,b,A,h,S,x,y,z,Q,w,_,I;return{c(){m=r("p"),C=s("El argumento "),f=r("code"),b=s("data_files"),A=s(" de la funci\xF3n "),h=r("code"),S=s("load_dataset()"),x=s(" es muy flexible. Puede ser una \xFAnica ruta de archivo, una lista de rutas o un diccionario que mapee los nombres de los conjuntos a las rutas de archivo. Tambi\xE9n puedes buscar archivos que cumplan con cierto patr\xF3n espec\xEDfico de acuerdo con las reglas usadas por el shell de Unix (e.g., puedes buscar todos los archivos JSON en una carpeta al definir "),y=r("code"),z=s('datafiles="*.json"'),Q=s("). Revisa la "),w=r("a"),_=s("documentaci\xF3n"),I=s(" para m\xE1s detalles."),this.h()},l(P){m=n(P,"P",{});var D=l(m);C=o(D,"El argumento "),f=n(D,"CODE",{});var Te=l(f);b=o(Te,"data_files"),Te.forEach(t),A=o(D," de la funci\xF3n "),h=n(D,"CODE",{});var ve=l(h);S=o(ve,"load_dataset()"),ve.forEach(t),x=o(D," es muy flexible. Puede ser una \xFAnica ruta de archivo, una lista de rutas o un diccionario que mapee los nombres de los conjuntos a las rutas de archivo. Tambi\xE9n puedes buscar archivos que cumplan con cierto patr\xF3n espec\xEDfico de acuerdo con las reglas usadas por el shell de Unix (e.g., puedes buscar todos los archivos JSON en una carpeta al definir "),y=n(D,"CODE",{});var G=l(y);z=o(G,'datafiles="*.json"'),G.forEach(t),Q=o(D,"). Revisa la "),w=n(D,"A",{href:!0,rel:!0});var $e=l(w);_=o($e,"documentaci\xF3n"),$e.forEach(t),I=o(D," para m\xE1s detalles."),D.forEach(t),this.h()},h(){p(w,"href","https://huggingface.co/docs/datasets/loading.html#local-and-remote-files"),p(w,"rel","nofollow")},m(P,D){d(P,m,D),a(m,C),a(m,f),a(f,b),a(m,A),a(m,h),a(h,S),a(m,x),a(m,y),a(y,z),a(m,Q),a(m,w),a(w,_),a(m,I)},d(P){P&&t(m)}}}function qn(se){let m,C,f,b,A,h,S,x,y,z,Q;return{c(){m=r("p"),C=s("\u270F\uFE0F "),f=r("strong"),b=s("\xA1Int\xE9ntalo!"),A=s(" Escoge otro dataset alojado en GitHub o en el "),h=r("a"),S=s("Repositorio de Machine Learning de UCI"),x=s(" e intenta cargarlo local y remotamente usando las t\xE9cnicas descritas con anterioridad. Para puntos extra, intenta cargar un dataset que est\xE9 guardado en un formato CSV o de texto (revisa la "),y=r("a"),z=s("documentaci\xF3n"),Q=s(" pata tener m\xE1s informaci\xF3n sobre estos formatos)."),this.h()},l(w){m=n(w,"P",{});var _=l(m);C=o(_,"\u270F\uFE0F "),f=n(_,"STRONG",{});var I=l(f);b=o(I,"\xA1Int\xE9ntalo!"),I.forEach(t),A=o(_," Escoge otro dataset alojado en GitHub o en el "),h=n(_,"A",{href:!0,rel:!0});var P=l(h);S=o(P,"Repositorio de Machine Learning de UCI"),P.forEach(t),x=o(_," e intenta cargarlo local y remotamente usando las t\xE9cnicas descritas con anterioridad. Para puntos extra, intenta cargar un dataset que est\xE9 guardado en un formato CSV o de texto (revisa la "),y=n(_,"A",{href:!0,rel:!0});var D=l(y);z=o(D,"documentaci\xF3n"),D.forEach(t),Q=o(_," pata tener m\xE1s informaci\xF3n sobre estos formatos)."),_.forEach(t),this.h()},h(){p(h,"href","https://archive.ics.uci.edu/ml/index.php"),p(h,"rel","nofollow"),p(y,"href","https://huggingface.co/docs/datasets/loading.html#local-and-remote-files"),p(y,"rel","nofollow")},m(w,_){d(w,m,_),a(m,C),a(m,f),a(f,b),a(m,A),a(m,h),a(h,S),a(m,x),a(m,y),a(y,z),a(m,Q)},d(w){w&&t(m)}}}function En(se){let m,C,f,b,A,h,S,x,y,z,Q,w,_,I,P,D,Te,ve,G,$e,B,oe,ua,qe,Yt,ma,Vt,st,He,Bt,ot,re,pa,Z,Ne,Zt,Kt,Le,Wt,Xt,Je,es,as,R,K,Re,ts,ss,Ie,fa,os,rs,Ge,ha,ns,ls,W,Me,is,ds,Fe,_a,cs,us,Ue,ga,ms,ps,X,Ye,fs,hs,Ve,va,_s,gs,Be,$a,vs,$s,ee,Ze,qs,Es,Ke,qa,js,bs,We,Ea,Ds,rt,M,Ss,ja,ws,As,ba,ys,Cs,nt,ae,ne,Da,Ee,xs,Sa,Ps,lt,Xe,Os,it,le,Qs,wa,ks,zs,dt,je,ct,T,Ts,Aa,Hs,Ns,ya,Ls,Js,Ca,Rs,Is,ut,be,mt,De,pt,F,Gs,xa,Ms,Fs,Pa,Us,Ys,ft,ie,ht,H,Vs,Oa,Bs,Zs,Qa,Ks,Ws,ka,Xs,eo,_t,Se,gt,N,ao,za,to,so,Ta,oo,ro,Ha,no,lo,vt,we,$t,Ae,qt,ea,io,Et,ye,jt,Ce,bt,O,co,Na,uo,mo,La,po,fo,Ja,ho,_o,Ra,go,vo,Ia,$o,qo,Dt,xe,St,Pe,wt,de,Eo,Ga,jo,bo,At,ce,yt,U,Do,Ma,So,wo,Fa,Ao,yo,Ct,Oe,xt,ue,Co,Ua,xo,Po,Pt,aa,Oo,Ot,te,me,Ya,Qe,Qo,Va,ko,Qt,k,zo,Ba,To,Ho,Za,No,Lo,Ka,Jo,Ro,Wa,Io,Go,kt,ke,zt,Y,Mo,Xa,Fo,Uo,et,Yo,Vo,Tt,pe,Ht;return h=new Ut({}),Q=new gn({props:{chapter:5,classNames:"absolute z-10 right-0 top-0",notebooks:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter5/section2.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter5/section2.ipynb"}]}}),G=new _n({props:{id:"HyQgpJTkRdE"}}),qe=new Ut({}),Ee=new Ut({}),je=new J({props:{code:`!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-train.json.gz
!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-test.json.gz`,highlighted:`!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-train.json.gz
!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-test.json.gz`}}),be=new J({props:{code:"!gzip -dkv SQuAD_it-*.json.gz",highlighted:"!gzip -dkv SQuAD_it-*.json.gz"}}),De=new J({props:{code:`SQuAD_it-test.json.gz:	   87.4% -- replaced with SQuAD_it-test.json
SQuAD_it-train.json.gz:	   82.2% -- replaced with SQuAD_it-train.json`,highlighted:`SQuAD_it-test.json.gz:	   87.4% -- replaced with SQuAD_it-test.json
SQuAD_it-train.json.gz:	   82.2% -- replaced with SQuAD_it-train.json`}}),ie=new Bo({props:{$$slots:{default:[vn]},$$scope:{ctx:se}}}),Se=new J({props:{code:`from datasets import load_dataset

squad_it_dataset = load_dataset("json", data_files="SQuAD_it-train.json", field="data")`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

squad_it_dataset = load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=<span class="hljs-string">&quot;SQuAD_it-train.json&quot;</span>, field=<span class="hljs-string">&quot;data&quot;</span>)`}}),we=new J({props:{code:"squad_it_dataset",highlighted:"squad_it_dataset"}}),Ae=new J({props:{code:`DatasetDict({
    train: Dataset({
        features: ['title', 'paragraphs'],
        num_rows: 442
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;paragraphs&#x27;</span>],
        num_rows: <span class="hljs-number">442</span>
    })
})`}}),ye=new J({props:{code:'squad_it_dataset["train"][0]',highlighted:'squad_it_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]'}}),Ce=new J({props:{code:`{
    "title": "Terremoto del Sichuan del 2008",
    "paragraphs": [
        {
            "context": "Il terremoto del Sichuan del 2008 o il terremoto...",
            "qas": [
                {
                    "answers": [{"answer_start": 29, "text": "2008"}],
                    "id": "56cdca7862d2951400fa6826",
                    "question": "In quale anno si \xE8 verificato il terremoto nel Sichuan?",
                },
                ...
            ],
        },
        ...
    ],
}`,highlighted:`{
    <span class="hljs-string">&quot;title&quot;</span>: <span class="hljs-string">&quot;Terremoto del Sichuan del 2008&quot;</span>,
    <span class="hljs-string">&quot;paragraphs&quot;</span>: [
        {
            <span class="hljs-string">&quot;context&quot;</span>: <span class="hljs-string">&quot;Il terremoto del Sichuan del 2008 o il terremoto...&quot;</span>,
            <span class="hljs-string">&quot;qas&quot;</span>: [
                {
                    <span class="hljs-string">&quot;answers&quot;</span>: [{<span class="hljs-string">&quot;answer_start&quot;</span>: <span class="hljs-number">29</span>, <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;2008&quot;</span>}],
                    <span class="hljs-string">&quot;id&quot;</span>: <span class="hljs-string">&quot;56cdca7862d2951400fa6826&quot;</span>,
                    <span class="hljs-string">&quot;question&quot;</span>: <span class="hljs-string">&quot;In quale anno si \xE8 verificato il terremoto nel Sichuan?&quot;</span>,
                },
                ...
            ],
        },
        ...
    ],
}`}}),xe=new J({props:{code:`data_files = {"train": "SQuAD_it-train.json", "test": "SQuAD_it-test.json"}
squad_it_dataset = load_dataset("json", data_files=data_files, field="data")
squad_it_dataset`,highlighted:`data_files = {<span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;SQuAD_it-train.json&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;SQuAD_it-test.json&quot;</span>}
squad_it_dataset = load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=data_files, field=<span class="hljs-string">&quot;data&quot;</span>)
squad_it_dataset`}}),Pe=new J({props:{code:`DatasetDict({
    train: Dataset({
        features: ['title', 'paragraphs'],
        num_rows: 442
    })
    test: Dataset({
        features: ['title', 'paragraphs'],
        num_rows: 48
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;paragraphs&#x27;</span>],
        num_rows: <span class="hljs-number">442</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;paragraphs&#x27;</span>],
        num_rows: <span class="hljs-number">48</span>
    })
})`}}),ce=new Bo({props:{$$slots:{default:[$n]},$$scope:{ctx:se}}}),Oe=new J({props:{code:`data_files = {"train": "SQuAD_it-train.json.gz", "test": "SQuAD_it-test.json.gz"}
squad_it_dataset = load_dataset("json", data_files=data_files, field="data")`,highlighted:`data_files = {<span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;SQuAD_it-train.json.gz&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;SQuAD_it-test.json.gz&quot;</span>}
squad_it_dataset = load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=data_files, field=<span class="hljs-string">&quot;data&quot;</span>)`}}),Qe=new Ut({}),ke=new J({props:{code:`url = "https://github.com/crux82/squad-it/raw/master/"
data_files = {
    "train": url + "SQuAD_it-train.json.gz",
    "test": url + "SQuAD_it-test.json.gz",
}
squad_it_dataset = load_dataset("json", data_files=data_files, field="data")`,highlighted:`url = <span class="hljs-string">&quot;https://github.com/crux82/squad-it/raw/master/&quot;</span>
data_files = {
    <span class="hljs-string">&quot;train&quot;</span>: url + <span class="hljs-string">&quot;SQuAD_it-train.json.gz&quot;</span>,
    <span class="hljs-string">&quot;test&quot;</span>: url + <span class="hljs-string">&quot;SQuAD_it-test.json.gz&quot;</span>,
}
squad_it_dataset = load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=data_files, field=<span class="hljs-string">&quot;data&quot;</span>)`}}),pe=new Bo({props:{$$slots:{default:[qn]},$$scope:{ctx:se}}}),{c(){m=r("meta"),C=c(),f=r("h1"),b=r("a"),A=r("span"),g(h.$$.fragment),S=c(),x=r("span"),y=s("\xBFY si mi dataset no est\xE1 en el Hub?"),z=c(),g(Q.$$.fragment),w=c(),_=r("p"),I=s("Ya sabes c\xF3mo usar el "),P=r("a"),D=s("Hub de Hugging Face"),Te=s(" para descargar datasets, pero usualmente vas a tener que trabajar con datos que est\xE1n guardados en tu computador o en un servidor remoto. En esta secci\xF3n te mostraremos c\xF3mo usar \u{1F917} Datasets para cargar conjuntos de datos que no est\xE1n disponibles en el Hub de Hugging Face."),ve=c(),g(G.$$.fragment),$e=c(),B=r("h2"),oe=r("a"),ua=r("span"),g(qe.$$.fragment),Yt=c(),ma=r("span"),Vt=s("Trabajando con datos locales y remotos"),st=c(),He=r("p"),Bt=s("\u{1F917} Datasets contiene scripts para cargar datasets locales y remotos que soportan formatos comunes de datos como:"),ot=c(),re=r("table"),pa=r("thead"),Z=r("tr"),Ne=r("th"),Zt=s("Formato de datos"),Kt=c(),Le=r("th"),Wt=s("Script de carga"),Xt=c(),Je=r("th"),es=s("Ejemplo"),as=c(),R=r("tbody"),K=r("tr"),Re=r("td"),ts=s("CSV y TSV"),ss=c(),Ie=r("td"),fa=r("code"),os=s("csv"),rs=c(),Ge=r("td"),ha=r("code"),ns=s('load_dataset("csv", data_files="my_file.csv")'),ls=c(),W=r("tr"),Me=r("td"),is=s("Archivos de texto"),ds=c(),Fe=r("td"),_a=r("code"),cs=s("text"),us=c(),Ue=r("td"),ga=r("code"),ms=s('load_dataset("text", data_files="my_file.txt")'),ps=c(),X=r("tr"),Ye=r("td"),fs=s("JSON y JSON Lines"),hs=c(),Ve=r("td"),va=r("code"),_s=s("json"),gs=c(),Be=r("td"),$a=r("code"),vs=s('load_dataset("json", data_files="my_file.jsonl")'),$s=c(),ee=r("tr"),Ze=r("td"),qs=s("Pickled DataFrames"),Es=c(),Ke=r("td"),qa=r("code"),js=s("pandas"),bs=c(),We=r("td"),Ea=r("code"),Ds=s('load_dataset("pandas", data_files="my_dataframe.pkl")'),rt=c(),M=r("p"),Ss=s("Como ves en la tabla, para cada formato de datos solo tenemos que especificar el tipo de script de carga en la funci\xF3n "),ja=r("code"),ws=s("load_dataset()"),As=s(", as\xED como el argumento "),ba=r("code"),ys=s("data_files"),Cs=s(" que contiene la ruta a uno o m\xE1s archivos. Comencemos por cargar un dataset desde archivos locales y luego veremos c\xF3mo hacer lo propio para archivos remotos."),nt=c(),ae=r("h2"),ne=r("a"),Da=r("span"),g(Ee.$$.fragment),xs=c(),Sa=r("span"),Ps=s("Cargando un dataset local"),lt=c(),Xe=r("p"),Os=s("Para este ejemplo, vamos a usar el [dataset SQuAD-it], que es un dataset de gran escala para responder preguntas en italiano."),it=c(),le=r("p"),Qs=s("Los conjuntos de entrenamiento y de prueba est\xE1n alojados en GitHub, as\xED que podemos descargarlos f\xE1cilmente con el comando "),wa=r("code"),ks=s("wget"),zs=s(":"),dt=c(),g(je.$$.fragment),ct=c(),T=r("p"),Ts=s("Esto va a descargar dos archivos comprimidos llamados "),Aa=r("em"),Hs=s("SQuAD_it-train.json.gz"),Ns=s(" y "),ya=r("em"),Ls=s("SQuAD_it-test.json.gz"),Js=s(", que podemos descomprimir con el comando  "),Ca=r("code"),Rs=s("gzip"),Is=s(" de Linux:"),ut=c(),g(be.$$.fragment),mt=c(),g(De.$$.fragment),pt=c(),F=r("p"),Gs=s("De este modo, podemos ver que los archivos comprimidos son reemplazados por los archuvos en formato JSON "),xa=r("em"),Ms=s("SQuAD_it-train.json"),Fs=s(" y "),Pa=r("em"),Us=s("SQuAD_it-test.json"),Ys=s("."),ft=c(),g(ie.$$.fragment),ht=c(),H=r("p"),Vs=s("Para cargar un archivo JSON con la funci\xF3n "),Oa=r("code"),Bs=s("load_dataset()"),Zs=s(", necesitamos saber si estamos trabajando con un archivo JSON ordinario (parecido a un diccionario anidado) o con JSON Lines (JSON separado por l\xEDneas). Como muchos de los datasets de respuesta a preguntas que te vas a encontrar, SQuAD-it usa el formato anidado, en el que el texto est\xE1 almacenado en un campo "),Qa=r("code"),Ks=s("data"),Ws=s(". Esto significa que podemos cargar el dataset especificando el argumento "),ka=r("code"),Xs=s("field"),eo=s(" de la siguiente manera:"),_t=c(),g(Se.$$.fragment),gt=c(),N=r("p"),ao=s("Por defecto, cuando cargas archivos locales se crea un objeto "),za=r("code"),to=s("DatasetDict"),so=s(" con un conjunto de entrenamiento \u2013"),Ta=r("code"),oo=s("train"),ro=s("\u2013. Podemos verlo al inspeccionar el objeto "),Ha=r("code"),no=s("squad_it_dataset"),lo=s(":"),vt=c(),g(we.$$.fragment),$t=c(),g(Ae.$$.fragment),qt=c(),ea=r("p"),io=s("Esto nos muestra el n\xFAmero de filas y los nombres de las columnas asociadas al conjunto de entrenamiento. Podemos ver uno de los ejemplos al poner un \xEDndice en el conjunto de entrenamiento as\xED:"),Et=c(),g(ye.$$.fragment),jt=c(),g(Ce.$$.fragment),bt=c(),O=r("p"),co=s("\xA1Genial, ya cargamos nuestro primer dataset local! Sin embargo, esto funcion\xF3 \xFAnicamente para el conjunto de entrenamiento. Realmente, queremos incluir tanto el conjunto "),Na=r("code"),uo=s("train"),mo=s(" como el conjunto "),La=r("code"),po=s("test"),fo=s(" en un \xFAnico objeto "),Ja=r("code"),ho=s("DatasetDict"),_o=s(" para poder aplicar las funciones "),Ra=r("code"),go=s("Dataset.map()"),vo=s(" en ambos conjuntos al mismo tiempo. Para hacerlo, podemos incluir un diccionario en el argumento "),Ia=r("code"),$o=s("datafiles"),qo=s(" que mapea cada nombre de conjunto a su archivo asociado:"),Dt=c(),g(xe.$$.fragment),St=c(),g(Pe.$$.fragment),wt=c(),de=r("p"),Eo=s("Esto es exactamente lo que quer\xEDamos. Ahora podemos aplicar varias t\xE9cnicas de preprocesamiento para limpiar los datos, "),Ga=r("em"),jo=s("tokenizar"),bo=s(" las rese\xF1as, entre otras tareas."),At=c(),g(ce.$$.fragment),yt=c(),U=r("p"),Do=s("Los scripts de carga en \u{1F917} Datasets tambi\xE9n pueden descomprimir los archivos de entrada autom\xE1ticamente, as\xED que podemos saltarnos el uso de "),Ma=r("code"),So=s("gzip"),wo=s(" especificando el argumento "),Fa=r("code"),Ao=s("data_files"),yo=s(" directamente a la ruta de los archivos comprimidos."),Ct=c(),g(Oe.$$.fragment),xt=c(),ue=r("p"),Co=s("Esto puede ser \xFAtil si no quieres descomprimir manualmente muchos archivos GZIP. La descompresi\xF3n autom\xE1tica tambi\xE9n aplica para otros formatos de archivo comunes como TAR y ZIP, as\xED que solo necesitas dirigir el argumento "),Ua=r("code"),xo=s("data_files"),Po=s(" a los archivos comprimidos y \xA1listo!."),Pt=c(),aa=r("p"),Oo=s("Ahora que sabes c\xF3mo cargar archivos locales en tu computador port\xE1til o de escritorio, veamos c\xF3mo cargar archivos remotos."),Ot=c(),te=r("h2"),me=r("a"),Ya=r("span"),g(Qe.$$.fragment),Qo=c(),Va=r("span"),ko=s("Cargando un dataset remoto"),Qt=c(),k=r("p"),zo=s("Si est\xE1s trabajando como cient\xEDfico de datos o desarrollador en una compa\xF1\xEDa, hay una alta probabilidad de que los datasets que quieres analizar est\xE9n almacenados en un servidor remoto. Afortunadamente, \xA1la carga de archivos remotos es tan f\xE1cil como cargar archivos locales! En vez de incluir una ruta de archivo, dirigimos el argumento "),Ba=r("code"),To=s("data_files"),Ho=s(" de la funci\xF3n "),Za=r("code"),No=s("load_datasets()"),Lo=s(" a una o m\xE1s URL en las que est\xE9n almacenados los archivos. Por ejemplo, para el dataset SQuAD-it alojado en GitHub, podemos apuntar "),Ka=r("code"),Jo=s("data_files"),Ro=s(" a las URL de "),Wa=r("em"),Io=s("SQuAD_it-*.json.gz"),Go=s(" as\xED:"),kt=c(),g(ke.$$.fragment),zt=c(),Y=r("p"),Mo=s("Esto devuelve el mismo objeto "),Xa=r("code"),Fo=s("DatasetDict"),Uo=s(" que obtuvimos antes, pero nos ahorra el paso de descargar y descomprimir manualmente los archivos "),et=r("em"),Yo=s("SQuAD_it-*.json.gz"),Vo=s(". Con esto concluimos nuestra exploraci\xF3n de las diferentes maneras de cargar datasets que no est\xE1n alojados en el Hub de Hugging Face. Ahora que tenemos un dataset para experimentar, \xA1pong\xE1monos manos a la obra con diferentes t\xE9cnicas de procesamiento de datos!"),Tt=c(),g(pe.$$.fragment),this.h()},l(e){const i=fn('[data-svelte="svelte-1phssyn"]',document.head);m=n(i,"META",{name:!0,content:!0}),i.forEach(t),C=u(e),f=n(e,"H1",{class:!0});var ze=l(f);b=n(ze,"A",{id:!0,class:!0,href:!0});var at=l(b);A=n(at,"SPAN",{});var tt=l(A);v(h.$$.fragment,tt),tt.forEach(t),at.forEach(t),S=u(ze),x=n(ze,"SPAN",{});var Zo=l(x);y=o(Zo,"\xBFY si mi dataset no est\xE1 en el Hub?"),Zo.forEach(t),ze.forEach(t),z=u(e),v(Q.$$.fragment,e),w=u(e),_=n(e,"P",{});var Nt=l(_);I=o(Nt,"Ya sabes c\xF3mo usar el "),P=n(Nt,"A",{href:!0,rel:!0});var Ko=l(P);D=o(Ko,"Hub de Hugging Face"),Ko.forEach(t),Te=o(Nt," para descargar datasets, pero usualmente vas a tener que trabajar con datos que est\xE1n guardados en tu computador o en un servidor remoto. En esta secci\xF3n te mostraremos c\xF3mo usar \u{1F917} Datasets para cargar conjuntos de datos que no est\xE1n disponibles en el Hub de Hugging Face."),Nt.forEach(t),ve=u(e),v(G.$$.fragment,e),$e=u(e),B=n(e,"H2",{class:!0});var Lt=l(B);oe=n(Lt,"A",{id:!0,class:!0,href:!0});var Wo=l(oe);ua=n(Wo,"SPAN",{});var Xo=l(ua);v(qe.$$.fragment,Xo),Xo.forEach(t),Wo.forEach(t),Yt=u(Lt),ma=n(Lt,"SPAN",{});var er=l(ma);Vt=o(er,"Trabajando con datos locales y remotos"),er.forEach(t),Lt.forEach(t),st=u(e),He=n(e,"P",{});var ar=l(He);Bt=o(ar,"\u{1F917} Datasets contiene scripts para cargar datasets locales y remotos que soportan formatos comunes de datos como:"),ar.forEach(t),ot=u(e),re=n(e,"TABLE",{});var Jt=l(re);pa=n(Jt,"THEAD",{});var tr=l(pa);Z=n(tr,"TR",{});var ta=l(Z);Ne=n(ta,"TH",{align:!0});var sr=l(Ne);Zt=o(sr,"Formato de datos"),sr.forEach(t),Kt=u(ta),Le=n(ta,"TH",{align:!0});var or=l(Le);Wt=o(or,"Script de carga"),or.forEach(t),Xt=u(ta),Je=n(ta,"TH",{align:!0});var rr=l(Je);es=o(rr,"Ejemplo"),rr.forEach(t),ta.forEach(t),tr.forEach(t),as=u(Jt),R=n(Jt,"TBODY",{});var fe=l(R);K=n(fe,"TR",{});var sa=l(K);Re=n(sa,"TD",{align:!0});var nr=l(Re);ts=o(nr,"CSV y TSV"),nr.forEach(t),ss=u(sa),Ie=n(sa,"TD",{align:!0});var lr=l(Ie);fa=n(lr,"CODE",{});var ir=l(fa);os=o(ir,"csv"),ir.forEach(t),lr.forEach(t),rs=u(sa),Ge=n(sa,"TD",{align:!0});var dr=l(Ge);ha=n(dr,"CODE",{});var cr=l(ha);ns=o(cr,'load_dataset("csv", data_files="my_file.csv")'),cr.forEach(t),dr.forEach(t),sa.forEach(t),ls=u(fe),W=n(fe,"TR",{});var oa=l(W);Me=n(oa,"TD",{align:!0});var ur=l(Me);is=o(ur,"Archivos de texto"),ur.forEach(t),ds=u(oa),Fe=n(oa,"TD",{align:!0});var mr=l(Fe);_a=n(mr,"CODE",{});var pr=l(_a);cs=o(pr,"text"),pr.forEach(t),mr.forEach(t),us=u(oa),Ue=n(oa,"TD",{align:!0});var fr=l(Ue);ga=n(fr,"CODE",{});var hr=l(ga);ms=o(hr,'load_dataset("text", data_files="my_file.txt")'),hr.forEach(t),fr.forEach(t),oa.forEach(t),ps=u(fe),X=n(fe,"TR",{});var ra=l(X);Ye=n(ra,"TD",{align:!0});var _r=l(Ye);fs=o(_r,"JSON y JSON Lines"),_r.forEach(t),hs=u(ra),Ve=n(ra,"TD",{align:!0});var gr=l(Ve);va=n(gr,"CODE",{});var vr=l(va);_s=o(vr,"json"),vr.forEach(t),gr.forEach(t),gs=u(ra),Be=n(ra,"TD",{align:!0});var $r=l(Be);$a=n($r,"CODE",{});var qr=l($a);vs=o(qr,'load_dataset("json", data_files="my_file.jsonl")'),qr.forEach(t),$r.forEach(t),ra.forEach(t),$s=u(fe),ee=n(fe,"TR",{});var na=l(ee);Ze=n(na,"TD",{align:!0});var Er=l(Ze);qs=o(Er,"Pickled DataFrames"),Er.forEach(t),Es=u(na),Ke=n(na,"TD",{align:!0});var jr=l(Ke);qa=n(jr,"CODE",{});var br=l(qa);js=o(br,"pandas"),br.forEach(t),jr.forEach(t),bs=u(na),We=n(na,"TD",{align:!0});var Dr=l(We);Ea=n(Dr,"CODE",{});var Sr=l(Ea);Ds=o(Sr,'load_dataset("pandas", data_files="my_dataframe.pkl")'),Sr.forEach(t),Dr.forEach(t),na.forEach(t),fe.forEach(t),Jt.forEach(t),rt=u(e),M=n(e,"P",{});var la=l(M);Ss=o(la,"Como ves en la tabla, para cada formato de datos solo tenemos que especificar el tipo de script de carga en la funci\xF3n "),ja=n(la,"CODE",{});var wr=l(ja);ws=o(wr,"load_dataset()"),wr.forEach(t),As=o(la,", as\xED como el argumento "),ba=n(la,"CODE",{});var Ar=l(ba);ys=o(Ar,"data_files"),Ar.forEach(t),Cs=o(la," que contiene la ruta a uno o m\xE1s archivos. Comencemos por cargar un dataset desde archivos locales y luego veremos c\xF3mo hacer lo propio para archivos remotos."),la.forEach(t),nt=u(e),ae=n(e,"H2",{class:!0});var Rt=l(ae);ne=n(Rt,"A",{id:!0,class:!0,href:!0});var yr=l(ne);Da=n(yr,"SPAN",{});var Cr=l(Da);v(Ee.$$.fragment,Cr),Cr.forEach(t),yr.forEach(t),xs=u(Rt),Sa=n(Rt,"SPAN",{});var xr=l(Sa);Ps=o(xr,"Cargando un dataset local"),xr.forEach(t),Rt.forEach(t),lt=u(e),Xe=n(e,"P",{});var Pr=l(Xe);Os=o(Pr,"Para este ejemplo, vamos a usar el [dataset SQuAD-it], que es un dataset de gran escala para responder preguntas en italiano."),Pr.forEach(t),it=u(e),le=n(e,"P",{});var It=l(le);Qs=o(It,"Los conjuntos de entrenamiento y de prueba est\xE1n alojados en GitHub, as\xED que podemos descargarlos f\xE1cilmente con el comando "),wa=n(It,"CODE",{});var Or=l(wa);ks=o(Or,"wget"),Or.forEach(t),zs=o(It,":"),It.forEach(t),dt=u(e),v(je.$$.fragment,e),ct=u(e),T=n(e,"P",{});var he=l(T);Ts=o(he,"Esto va a descargar dos archivos comprimidos llamados "),Aa=n(he,"EM",{});var Qr=l(Aa);Hs=o(Qr,"SQuAD_it-train.json.gz"),Qr.forEach(t),Ns=o(he," y "),ya=n(he,"EM",{});var kr=l(ya);Ls=o(kr,"SQuAD_it-test.json.gz"),kr.forEach(t),Js=o(he,", que podemos descomprimir con el comando  "),Ca=n(he,"CODE",{});var zr=l(Ca);Rs=o(zr,"gzip"),zr.forEach(t),Is=o(he," de Linux:"),he.forEach(t),ut=u(e),v(be.$$.fragment,e),mt=u(e),v(De.$$.fragment,e),pt=u(e),F=n(e,"P",{});var ia=l(F);Gs=o(ia,"De este modo, podemos ver que los archivos comprimidos son reemplazados por los archuvos en formato JSON "),xa=n(ia,"EM",{});var Tr=l(xa);Ms=o(Tr,"SQuAD_it-train.json"),Tr.forEach(t),Fs=o(ia," y "),Pa=n(ia,"EM",{});var Hr=l(Pa);Us=o(Hr,"SQuAD_it-test.json"),Hr.forEach(t),Ys=o(ia,"."),ia.forEach(t),ft=u(e),v(ie.$$.fragment,e),ht=u(e),H=n(e,"P",{});var _e=l(H);Vs=o(_e,"Para cargar un archivo JSON con la funci\xF3n "),Oa=n(_e,"CODE",{});var Nr=l(Oa);Bs=o(Nr,"load_dataset()"),Nr.forEach(t),Zs=o(_e,", necesitamos saber si estamos trabajando con un archivo JSON ordinario (parecido a un diccionario anidado) o con JSON Lines (JSON separado por l\xEDneas). Como muchos de los datasets de respuesta a preguntas que te vas a encontrar, SQuAD-it usa el formato anidado, en el que el texto est\xE1 almacenado en un campo "),Qa=n(_e,"CODE",{});var Lr=l(Qa);Ks=o(Lr,"data"),Lr.forEach(t),Ws=o(_e,". Esto significa que podemos cargar el dataset especificando el argumento "),ka=n(_e,"CODE",{});var Jr=l(ka);Xs=o(Jr,"field"),Jr.forEach(t),eo=o(_e," de la siguiente manera:"),_e.forEach(t),_t=u(e),v(Se.$$.fragment,e),gt=u(e),N=n(e,"P",{});var ge=l(N);ao=o(ge,"Por defecto, cuando cargas archivos locales se crea un objeto "),za=n(ge,"CODE",{});var Rr=l(za);to=o(Rr,"DatasetDict"),Rr.forEach(t),so=o(ge," con un conjunto de entrenamiento \u2013"),Ta=n(ge,"CODE",{});var Ir=l(Ta);oo=o(Ir,"train"),Ir.forEach(t),ro=o(ge,"\u2013. Podemos verlo al inspeccionar el objeto "),Ha=n(ge,"CODE",{});var Gr=l(Ha);no=o(Gr,"squad_it_dataset"),Gr.forEach(t),lo=o(ge,":"),ge.forEach(t),vt=u(e),v(we.$$.fragment,e),$t=u(e),v(Ae.$$.fragment,e),qt=u(e),ea=n(e,"P",{});var Mr=l(ea);io=o(Mr,"Esto nos muestra el n\xFAmero de filas y los nombres de las columnas asociadas al conjunto de entrenamiento. Podemos ver uno de los ejemplos al poner un \xEDndice en el conjunto de entrenamiento as\xED:"),Mr.forEach(t),Et=u(e),v(ye.$$.fragment,e),jt=u(e),v(Ce.$$.fragment,e),bt=u(e),O=n(e,"P",{});var L=l(O);co=o(L,"\xA1Genial, ya cargamos nuestro primer dataset local! Sin embargo, esto funcion\xF3 \xFAnicamente para el conjunto de entrenamiento. Realmente, queremos incluir tanto el conjunto "),Na=n(L,"CODE",{});var Fr=l(Na);uo=o(Fr,"train"),Fr.forEach(t),mo=o(L," como el conjunto "),La=n(L,"CODE",{});var Ur=l(La);po=o(Ur,"test"),Ur.forEach(t),fo=o(L," en un \xFAnico objeto "),Ja=n(L,"CODE",{});var Yr=l(Ja);ho=o(Yr,"DatasetDict"),Yr.forEach(t),_o=o(L," para poder aplicar las funciones "),Ra=n(L,"CODE",{});var Vr=l(Ra);go=o(Vr,"Dataset.map()"),Vr.forEach(t),vo=o(L," en ambos conjuntos al mismo tiempo. Para hacerlo, podemos incluir un diccionario en el argumento "),Ia=n(L,"CODE",{});var Br=l(Ia);$o=o(Br,"datafiles"),Br.forEach(t),qo=o(L," que mapea cada nombre de conjunto a su archivo asociado:"),L.forEach(t),Dt=u(e),v(xe.$$.fragment,e),St=u(e),v(Pe.$$.fragment,e),wt=u(e),de=n(e,"P",{});var Gt=l(de);Eo=o(Gt,"Esto es exactamente lo que quer\xEDamos. Ahora podemos aplicar varias t\xE9cnicas de preprocesamiento para limpiar los datos, "),Ga=n(Gt,"EM",{});var Zr=l(Ga);jo=o(Zr,"tokenizar"),Zr.forEach(t),bo=o(Gt," las rese\xF1as, entre otras tareas."),Gt.forEach(t),At=u(e),v(ce.$$.fragment,e),yt=u(e),U=n(e,"P",{});var da=l(U);Do=o(da,"Los scripts de carga en \u{1F917} Datasets tambi\xE9n pueden descomprimir los archivos de entrada autom\xE1ticamente, as\xED que podemos saltarnos el uso de "),Ma=n(da,"CODE",{});var Kr=l(Ma);So=o(Kr,"gzip"),Kr.forEach(t),wo=o(da," especificando el argumento "),Fa=n(da,"CODE",{});var Wr=l(Fa);Ao=o(Wr,"data_files"),Wr.forEach(t),yo=o(da," directamente a la ruta de los archivos comprimidos."),da.forEach(t),Ct=u(e),v(Oe.$$.fragment,e),xt=u(e),ue=n(e,"P",{});var Mt=l(ue);Co=o(Mt,"Esto puede ser \xFAtil si no quieres descomprimir manualmente muchos archivos GZIP. La descompresi\xF3n autom\xE1tica tambi\xE9n aplica para otros formatos de archivo comunes como TAR y ZIP, as\xED que solo necesitas dirigir el argumento "),Ua=n(Mt,"CODE",{});var Xr=l(Ua);xo=o(Xr,"data_files"),Xr.forEach(t),Po=o(Mt," a los archivos comprimidos y \xA1listo!."),Mt.forEach(t),Pt=u(e),aa=n(e,"P",{});var en=l(aa);Oo=o(en,"Ahora que sabes c\xF3mo cargar archivos locales en tu computador port\xE1til o de escritorio, veamos c\xF3mo cargar archivos remotos."),en.forEach(t),Ot=u(e),te=n(e,"H2",{class:!0});var Ft=l(te);me=n(Ft,"A",{id:!0,class:!0,href:!0});var an=l(me);Ya=n(an,"SPAN",{});var tn=l(Ya);v(Qe.$$.fragment,tn),tn.forEach(t),an.forEach(t),Qo=u(Ft),Va=n(Ft,"SPAN",{});var sn=l(Va);ko=o(sn,"Cargando un dataset remoto"),sn.forEach(t),Ft.forEach(t),Qt=u(e),k=n(e,"P",{});var V=l(k);zo=o(V,"Si est\xE1s trabajando como cient\xEDfico de datos o desarrollador en una compa\xF1\xEDa, hay una alta probabilidad de que los datasets que quieres analizar est\xE9n almacenados en un servidor remoto. Afortunadamente, \xA1la carga de archivos remotos es tan f\xE1cil como cargar archivos locales! En vez de incluir una ruta de archivo, dirigimos el argumento "),Ba=n(V,"CODE",{});var on=l(Ba);To=o(on,"data_files"),on.forEach(t),Ho=o(V," de la funci\xF3n "),Za=n(V,"CODE",{});var rn=l(Za);No=o(rn,"load_datasets()"),rn.forEach(t),Lo=o(V," a una o m\xE1s URL en las que est\xE9n almacenados los archivos. Por ejemplo, para el dataset SQuAD-it alojado en GitHub, podemos apuntar "),Ka=n(V,"CODE",{});var nn=l(Ka);Jo=o(nn,"data_files"),nn.forEach(t),Ro=o(V," a las URL de "),Wa=n(V,"EM",{});var ln=l(Wa);Io=o(ln,"SQuAD_it-*.json.gz"),ln.forEach(t),Go=o(V," as\xED:"),V.forEach(t),kt=u(e),v(ke.$$.fragment,e),zt=u(e),Y=n(e,"P",{});var ca=l(Y);Mo=o(ca,"Esto devuelve el mismo objeto "),Xa=n(ca,"CODE",{});var dn=l(Xa);Fo=o(dn,"DatasetDict"),dn.forEach(t),Uo=o(ca," que obtuvimos antes, pero nos ahorra el paso de descargar y descomprimir manualmente los archivos "),et=n(ca,"EM",{});var cn=l(et);Yo=o(cn,"SQuAD_it-*.json.gz"),cn.forEach(t),Vo=o(ca,". Con esto concluimos nuestra exploraci\xF3n de las diferentes maneras de cargar datasets que no est\xE1n alojados en el Hub de Hugging Face. Ahora que tenemos un dataset para experimentar, \xA1pong\xE1monos manos a la obra con diferentes t\xE9cnicas de procesamiento de datos!"),ca.forEach(t),Tt=u(e),v(pe.$$.fragment,e),this.h()},h(){p(m,"name","hf:doc:metadata"),p(m,"content",JSON.stringify(jn)),p(b,"id","y-si-mi-dataset-no-est-en-el-hub"),p(b,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(b,"href","#y-si-mi-dataset-no-est-en-el-hub"),p(f,"class","relative group"),p(P,"href","https://huggingface.co/datasets"),p(P,"rel","nofollow"),p(oe,"id","trabajando-con-datos-locales-y-remotos"),p(oe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(oe,"href","#trabajando-con-datos-locales-y-remotos"),p(B,"class","relative group"),p(Ne,"align","center"),p(Le,"align","center"),p(Je,"align","center"),p(Re,"align","center"),p(Ie,"align","center"),p(Ge,"align","center"),p(Me,"align","center"),p(Fe,"align","center"),p(Ue,"align","center"),p(Ye,"align","center"),p(Ve,"align","center"),p(Be,"align","center"),p(Ze,"align","center"),p(Ke,"align","center"),p(We,"align","center"),p(ne,"id","cargando-un-dataset-local"),p(ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ne,"href","#cargando-un-dataset-local"),p(ae,"class","relative group"),p(me,"id","cargando-un-dataset-remoto"),p(me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(me,"href","#cargando-un-dataset-remoto"),p(te,"class","relative group")},m(e,i){a(document.head,m),d(e,C,i),d(e,f,i),a(f,b),a(b,A),$(h,A,null),a(f,S),a(f,x),a(x,y),d(e,z,i),$(Q,e,i),d(e,w,i),d(e,_,i),a(_,I),a(_,P),a(P,D),a(_,Te),d(e,ve,i),$(G,e,i),d(e,$e,i),d(e,B,i),a(B,oe),a(oe,ua),$(qe,ua,null),a(B,Yt),a(B,ma),a(ma,Vt),d(e,st,i),d(e,He,i),a(He,Bt),d(e,ot,i),d(e,re,i),a(re,pa),a(pa,Z),a(Z,Ne),a(Ne,Zt),a(Z,Kt),a(Z,Le),a(Le,Wt),a(Z,Xt),a(Z,Je),a(Je,es),a(re,as),a(re,R),a(R,K),a(K,Re),a(Re,ts),a(K,ss),a(K,Ie),a(Ie,fa),a(fa,os),a(K,rs),a(K,Ge),a(Ge,ha),a(ha,ns),a(R,ls),a(R,W),a(W,Me),a(Me,is),a(W,ds),a(W,Fe),a(Fe,_a),a(_a,cs),a(W,us),a(W,Ue),a(Ue,ga),a(ga,ms),a(R,ps),a(R,X),a(X,Ye),a(Ye,fs),a(X,hs),a(X,Ve),a(Ve,va),a(va,_s),a(X,gs),a(X,Be),a(Be,$a),a($a,vs),a(R,$s),a(R,ee),a(ee,Ze),a(Ze,qs),a(ee,Es),a(ee,Ke),a(Ke,qa),a(qa,js),a(ee,bs),a(ee,We),a(We,Ea),a(Ea,Ds),d(e,rt,i),d(e,M,i),a(M,Ss),a(M,ja),a(ja,ws),a(M,As),a(M,ba),a(ba,ys),a(M,Cs),d(e,nt,i),d(e,ae,i),a(ae,ne),a(ne,Da),$(Ee,Da,null),a(ae,xs),a(ae,Sa),a(Sa,Ps),d(e,lt,i),d(e,Xe,i),a(Xe,Os),d(e,it,i),d(e,le,i),a(le,Qs),a(le,wa),a(wa,ks),a(le,zs),d(e,dt,i),$(je,e,i),d(e,ct,i),d(e,T,i),a(T,Ts),a(T,Aa),a(Aa,Hs),a(T,Ns),a(T,ya),a(ya,Ls),a(T,Js),a(T,Ca),a(Ca,Rs),a(T,Is),d(e,ut,i),$(be,e,i),d(e,mt,i),$(De,e,i),d(e,pt,i),d(e,F,i),a(F,Gs),a(F,xa),a(xa,Ms),a(F,Fs),a(F,Pa),a(Pa,Us),a(F,Ys),d(e,ft,i),$(ie,e,i),d(e,ht,i),d(e,H,i),a(H,Vs),a(H,Oa),a(Oa,Bs),a(H,Zs),a(H,Qa),a(Qa,Ks),a(H,Ws),a(H,ka),a(ka,Xs),a(H,eo),d(e,_t,i),$(Se,e,i),d(e,gt,i),d(e,N,i),a(N,ao),a(N,za),a(za,to),a(N,so),a(N,Ta),a(Ta,oo),a(N,ro),a(N,Ha),a(Ha,no),a(N,lo),d(e,vt,i),$(we,e,i),d(e,$t,i),$(Ae,e,i),d(e,qt,i),d(e,ea,i),a(ea,io),d(e,Et,i),$(ye,e,i),d(e,jt,i),$(Ce,e,i),d(e,bt,i),d(e,O,i),a(O,co),a(O,Na),a(Na,uo),a(O,mo),a(O,La),a(La,po),a(O,fo),a(O,Ja),a(Ja,ho),a(O,_o),a(O,Ra),a(Ra,go),a(O,vo),a(O,Ia),a(Ia,$o),a(O,qo),d(e,Dt,i),$(xe,e,i),d(e,St,i),$(Pe,e,i),d(e,wt,i),d(e,de,i),a(de,Eo),a(de,Ga),a(Ga,jo),a(de,bo),d(e,At,i),$(ce,e,i),d(e,yt,i),d(e,U,i),a(U,Do),a(U,Ma),a(Ma,So),a(U,wo),a(U,Fa),a(Fa,Ao),a(U,yo),d(e,Ct,i),$(Oe,e,i),d(e,xt,i),d(e,ue,i),a(ue,Co),a(ue,Ua),a(Ua,xo),a(ue,Po),d(e,Pt,i),d(e,aa,i),a(aa,Oo),d(e,Ot,i),d(e,te,i),a(te,me),a(me,Ya),$(Qe,Ya,null),a(te,Qo),a(te,Va),a(Va,ko),d(e,Qt,i),d(e,k,i),a(k,zo),a(k,Ba),a(Ba,To),a(k,Ho),a(k,Za),a(Za,No),a(k,Lo),a(k,Ka),a(Ka,Jo),a(k,Ro),a(k,Wa),a(Wa,Io),a(k,Go),d(e,kt,i),$(ke,e,i),d(e,zt,i),d(e,Y,i),a(Y,Mo),a(Y,Xa),a(Xa,Fo),a(Y,Uo),a(Y,et),a(et,Yo),a(Y,Vo),d(e,Tt,i),$(pe,e,i),Ht=!0},p(e,[i]){const ze={};i&2&&(ze.$$scope={dirty:i,ctx:e}),ie.$set(ze);const at={};i&2&&(at.$$scope={dirty:i,ctx:e}),ce.$set(at);const tt={};i&2&&(tt.$$scope={dirty:i,ctx:e}),pe.$set(tt)},i(e){Ht||(q(h.$$.fragment,e),q(Q.$$.fragment,e),q(G.$$.fragment,e),q(qe.$$.fragment,e),q(Ee.$$.fragment,e),q(je.$$.fragment,e),q(be.$$.fragment,e),q(De.$$.fragment,e),q(ie.$$.fragment,e),q(Se.$$.fragment,e),q(we.$$.fragment,e),q(Ae.$$.fragment,e),q(ye.$$.fragment,e),q(Ce.$$.fragment,e),q(xe.$$.fragment,e),q(Pe.$$.fragment,e),q(ce.$$.fragment,e),q(Oe.$$.fragment,e),q(Qe.$$.fragment,e),q(ke.$$.fragment,e),q(pe.$$.fragment,e),Ht=!0)},o(e){E(h.$$.fragment,e),E(Q.$$.fragment,e),E(G.$$.fragment,e),E(qe.$$.fragment,e),E(Ee.$$.fragment,e),E(je.$$.fragment,e),E(be.$$.fragment,e),E(De.$$.fragment,e),E(ie.$$.fragment,e),E(Se.$$.fragment,e),E(we.$$.fragment,e),E(Ae.$$.fragment,e),E(ye.$$.fragment,e),E(Ce.$$.fragment,e),E(xe.$$.fragment,e),E(Pe.$$.fragment,e),E(ce.$$.fragment,e),E(Oe.$$.fragment,e),E(Qe.$$.fragment,e),E(ke.$$.fragment,e),E(pe.$$.fragment,e),Ht=!1},d(e){t(m),e&&t(C),e&&t(f),j(h),e&&t(z),j(Q,e),e&&t(w),e&&t(_),e&&t(ve),j(G,e),e&&t($e),e&&t(B),j(qe),e&&t(st),e&&t(He),e&&t(ot),e&&t(re),e&&t(rt),e&&t(M),e&&t(nt),e&&t(ae),j(Ee),e&&t(lt),e&&t(Xe),e&&t(it),e&&t(le),e&&t(dt),j(je,e),e&&t(ct),e&&t(T),e&&t(ut),j(be,e),e&&t(mt),j(De,e),e&&t(pt),e&&t(F),e&&t(ft),j(ie,e),e&&t(ht),e&&t(H),e&&t(_t),j(Se,e),e&&t(gt),e&&t(N),e&&t(vt),j(we,e),e&&t($t),j(Ae,e),e&&t(qt),e&&t(ea),e&&t(Et),j(ye,e),e&&t(jt),j(Ce,e),e&&t(bt),e&&t(O),e&&t(Dt),j(xe,e),e&&t(St),j(Pe,e),e&&t(wt),e&&t(de),e&&t(At),j(ce,e),e&&t(yt),e&&t(U),e&&t(Ct),j(Oe,e),e&&t(xt),e&&t(ue),e&&t(Pt),e&&t(aa),e&&t(Ot),e&&t(te),j(Qe),e&&t(Qt),e&&t(k),e&&t(kt),j(ke,e),e&&t(zt),e&&t(Y),e&&t(Tt),j(pe,e)}}}const jn={local:"y-si-mi-dataset-no-est-en-el-hub",sections:[{local:"trabajando-con-datos-locales-y-remotos",title:"Trabajando con datos locales y remotos"},{local:"cargando-un-dataset-local",title:"Cargando un dataset local"},{local:"cargando-un-dataset-remoto",title:"Cargando un dataset remoto"}],title:"\xBFY si mi dataset no est\xE1 en el Hub?"};function bn(se){return hn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class xn extends un{constructor(m){super();mn(this,m,bn,En,pn,{})}}export{xn as default,jn as metadata};
