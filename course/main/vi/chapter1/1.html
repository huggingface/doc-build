<meta charset="utf-8" /><meta http-equiv="content-security-policy" content=""><meta name="hf:doc:metadata" content="{&quot;local&quot;:&quot;gii-thiu&quot;,&quot;sections&quot;:[{&quot;local&quot;:&quot;cho-mng-ti-kho-hc&quot;,&quot;title&quot;:&quot;ChÃ o má»«ng tá»›i ğŸ¤— KhoÃ¡ há»c!&quot;},{&quot;local&quot;:&quot;kha-hc-c-g&quot;,&quot;title&quot;:&quot;KhÃ³a há»c cÃ³ gÃ¬?&quot;},{&quot;local&quot;:&quot;chng-ta-l-ai&quot;,&quot;title&quot;:&quot;ChÃºng ta lÃ  ai?&quot;}],&quot;title&quot;:&quot;Giá»›i thiá»‡u&quot;}" data-svelte="svelte-1phssyn">
	<link rel="modulepreload" href="/docs/course/main/vi/_app/assets/pages/__layout.svelte-hf-doc-builder.css">
	<link rel="modulepreload" href="/docs/course/main/vi/_app/start-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/vi/_app/chunks/vendor-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/vi/_app/chunks/paths-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/vi/_app/pages/__layout.svelte-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/vi/_app/pages/chapter1/1.mdx-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/vi/_app/chunks/Youtube-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/vi/_app/chunks/IconCopyLink-hf-doc-builder.js"> 





<h1 class="relative group"><a id="gii-thiu" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#gii-thiu"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Giá»›i thiá»‡u
	</span></h1>

<h2 class="relative group"><a id="cho-mng-ti-kho-hc" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#cho-mng-ti-kho-hc"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>ChÃ o má»«ng tá»›i ğŸ¤— KhoÃ¡ há»c!
	</span></h2>

<iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/00GKzGyWFEs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p>KhÃ³a há»c nÃ y sáº½ dáº¡y báº¡n vá» Xá»­ lÃ½ NgÃ´n ngá»¯ Tá»± nhiÃªn (NLP) sá»­ dá»¥ng cÃ¡c thÆ° viá»‡n tá»« há»‡ sinh thÃ¡i <a href="https://huggingface.co/" rel="nofollow">Hugging Face</a> â€” <a href="https://github.com/huggingface/transformers" rel="nofollow">ğŸ¤— Transformers</a>, <a href="https://github.com/huggingface/datasets" rel="nofollow">ğŸ¤— Datasets</a>, <a href="https://github.com/huggingface/tokenizers" rel="nofollow">ğŸ¤— Tokenizers</a>, vÃ  <a href="https://github.com/huggingface/accelerate" rel="nofollow">ğŸ¤— Accelerate</a> â€” cÅ©ng nhÆ° <a href="https://huggingface.co/models" rel="nofollow">Hugging Face Hub</a>. KhoÃ¡ há»c hoÃ n toÃ n miá»…n phÃ­ vÃ  khÃ´ng cÃ³ quáº£ng cÃ¡o.</p>
<h2 class="relative group"><a id="kha-hc-c-g" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#kha-hc-c-g"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>KhÃ³a há»c cÃ³ gÃ¬?
	</span></h2>

<p>DÆ°á»›i Ä‘Ã¢y lÃ  tá»•ng quan ngáº¯n gá»n vá» khÃ³a há»c:</p>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary.svg" alt="Brief overview of the chapters of the course.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary-dark.svg" alt="Brief overview of the chapters of the course."></div>
<ul><li>CÃ¡c chÆ°Æ¡ng tá»« 1 Ä‘áº¿n 4 giá»›i thiá»‡u cÃ¡c khÃ¡i niá»‡m chÃ­nh cá»§a thÆ° viá»‡n ğŸ¤— Transformers. Äáº¿n cuá»‘i há»c pháº§n nÃ y, báº¡n sáº½ quen thuá»™c vá»›i cÃ¡ch hoáº¡t Ä‘á»™ng cá»§a cÃ¡c mÃ´ hÃ¬nh Transformer vÃ  sáº½ biáº¿t cÃ¡ch sá»­ dá»¥ng mÃ´ hÃ¬nh tá»« <a href="https://huggingface.co/models" rel="nofollow">Hugging Face Hub</a>, tinh chá»‰nh nÃ³ trÃªn má»™t táº­p dá»¯ liá»‡u cá»¥ thá»ƒ, vÃ  chia sáº» káº¿t quáº£ cá»§a báº¡n lÃªn Hub!</li>
<li>CÃ¡c chÆ°Æ¡ng tá»« 5 Ä‘áº¿n 8 dáº¡y cÃ¡c kiáº¿n thá»©c cÆ¡ báº£n vá» ğŸ¤— Datasets vÃ  ğŸ¤— Tokenizers trÆ°á»›c khi Ä‘i sÃ¢u vÃ o cÃ¡c tÃ¡c vá»¥ NLP kinh Ä‘iá»ƒn. Äáº¿n cuá»‘i há»c pháº§n nÃ y, báº¡n sáº½ cÃ³ thá»ƒ tá»± mÃ¬nh giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» NLP phá»• biáº¿n nháº¥t.</li>
<li>CÃ¡c chÆ°Æ¡ng tá»« 9 Ä‘áº¿n 12 vÆ°á»£t ra ngoÃ i pháº¡m vi NLP vÃ  khÃ¡m phÃ¡ cÃ¡ch sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh Transformer Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c tÃ¡c vá»¥ trong xá»­ lÃ½ giá»ng nÃ³i vÃ  thá»‹ giÃ¡c mÃ¡y tÃ­nh. Trong quÃ¡ trÃ¬nh nÃ y, báº¡n sáº½ há»c cÃ¡ch xÃ¢y dá»±ng vÃ  chia sáº» cÃ¡c báº£n demo vá» mÃ´ hÃ¬nh cá»§a mÃ¬nh cÅ©ng nhÆ° cÃ¡ch tá»‘i Æ°u hÃ³a chÃºng cho mÃ´i trÆ°á»ng sáº£n xuáº¥t. Äáº¿n cuá»‘i há»c pháº§n nÃ y, báº¡n sáº½ sáºµn sÃ ng Ã¡p dá»¥ng ğŸ¤— Transformers cho (háº§u háº¿t) báº¥t ká»³ váº¥n Ä‘á» há»c mÃ¡y nÃ o!</li></ul>
<p>KhoÃ¡ há»c:</p>
<ul><li>YÃªu cáº§u cÃ³ kiáº¿n thá»©c tá»‘t vá» Python.</li>
<li>NÃªn tÃ¬m hiá»ƒu sau khi Ä‘Ã£ hoÃ n thÃ nh má»™t khÃ³a nháº­p mÃ´n vá» Há»c sÃ¢u, cháº³ng háº¡n nhÆ° <a href="https://course.fast.ai/" rel="nofollow">Practical Deep Learning for Coders</a> cá»§a <a href="https://www.fast.ai/" rel="nofollow">fast.ai</a> hoáº·c má»™t trong nhá»¯ng chÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi <a href="https://www.deeplearning.ai/" rel="nofollow">DeepLearning.AI</a>.</li>
<li>KhÃ´ng yÃªu cáº§u biáº¿t trÆ°á»›c cÃ¡c kiáº¿n thá»©c vá» <a href="https://pytorch.org/" rel="nofollow">PyTorch</a> hoáº·c <a href="https://www.tensorflow.org/" rel="nofollow">TensorFlow</a>, máº·c dÃ¹ quen thuá»™c vá»›i má»™t sá»‘ kiáº¿n thá»©c nÃ y sáº½ há»¯u Ã­ch.</li></ul>
<p>Sau khi báº¡n hoÃ n thÃ nh khÃ³a há»c nÃ y, chÃºng tÃ´i khuyáº¿n khÃ­ch báº¡n xem thÃªm khoÃ¡ <a href="https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearning-ai&utm_medium=institutions&utm_campaign=20211011-nlp-2-hugging_face-page-nlp-refresh" rel="nofollow">Natural Language Processing Specialization</a> cá»§a DeepLearning.AI vá»›i ná»™i dung bao gá»“m má»™t loáº¡t cÃ¡c mÃ´ hÃ¬nh NLP truyá»n thá»‘ng Ä‘Ã¡ng Ä‘á»ƒ biáº¿t nhÆ° Naive Bayes vÃ  LSTM!</p>
<h2 class="relative group"><a id="chng-ta-l-ai" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#chng-ta-l-ai"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>ChÃºng ta lÃ  ai?
	</span></h2>

<p>Giá»›i thiá»‡u vá» tÃ¡c giáº£:</p>
<p><strong>Abubakar Abid</strong> Ä‘Ã£ hoÃ n thÃ nh chÆ°Æ¡ng trÃ¬nh Tiáº¿n sÄ© vá» há»c mÃ¡y á»©ng dá»¥ng táº¡i Stanford. Trong thá»i gian há»c tiáº¿n sÄ©, anh áº¥y Ä‘Ã£ táº¡o ra <a href="https://github.com/gradio-app/gradio" rel="nofollow">Gradio</a>, má»™t thÆ° viá»‡n Python mÃ£ nguá»“n má»Ÿ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ xÃ¢y dá»±ng hÆ¡n 600,000 báº£n demo há»c mÃ¡y. Gradio Ä‘Æ°á»£c mua láº¡i bá»Ÿi Hugging Face, nÆ¡i Abubakar hiá»‡n Ä‘Ã³ng vai trÃ² lÃ  trÆ°á»Ÿng nhÃ³m há»c mÃ¡y.</p>
<p><strong>Matthew Carrigan</strong> lÃ  má»™t Ká»¹ sÆ° Há»c mÃ¡y táº¡i Hugging Face. Anh áº¥y sá»‘ng á»Ÿ Dublin, Ireland, trÆ°á»›c Ä‘Ã¢y lÃ  ká»¹ sÆ° Há»c mÃ¡y táº¡i Parse.ly vÃ  trÆ°á»›c Ä‘Ã³ lÃ  nhÃ  nghiÃªn cá»©u sau tiáº¿n sÄ© táº¡i Trinity College Dublin. Anh áº¥y khÃ´ng tin ráº±ng chÃºng ta sáº½ Ä‘áº¡t Ä‘Æ°á»£c AGI báº±ng cÃ¡ch má»Ÿ rá»™ng cÃ¡c kiáº¿n â€‹â€‹trÃºc hiá»‡n cÃ³, nhÆ°ng cÃ³ niá»m tin vÃ o sá»± báº¥t tá»­ cá»§a robot.</p>
<p><strong>Lysandre Debut</strong> lÃ  má»™t Ká»¹ sÆ° Há»c mÃ¡y táº¡i Hugging Face vÃ  Ä‘Ã£ lÃ m viá»‡c vá»›i thÆ° viá»‡n ğŸ¤— Transformers tá»« nhá»¯ng giai Ä‘oáº¡n Ä‘áº§u phÃ¡t triá»ƒn. Má»¥c tiÃªu cá»§a anh áº¥y lÃ  lÃ m cho NLP cÃ³ thá»ƒ dá»… dÃ ng truy cáº­p Ä‘Æ°á»£c tá»« táº¥t cáº£ má»i ngÆ°á»i báº±ng cÃ¡ch phÃ¡t triá»ƒn cÃ¡c cÃ´ng cá»¥ vá»›i má»™t API ráº¥t Ä‘Æ¡n giáº£n.</p>
<p><strong>Sylvain Gugger</strong> lÃ  Ká»¹ sÆ° nghiÃªn cá»©u táº¡i Hugging Face vÃ  lÃ  má»™t trong nhá»¯ng thÃ nh viÃªn cá»‘t lÃµi cá»§a thÆ° viá»‡n ğŸ¤— Transformers. TrÆ°á»›c Ä‘Ã¢y, anh áº¥y lÃ  NhÃ  nghiÃªn cá»©u khoa há»c táº¡i fast.ai vÃ  anh áº¥y lÃ  Ä‘á»“ng sÃ¡ng tÃ¡c Ä‘áº§u sÃ¡ch <em><a href="https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/" rel="nofollow">Deep Learning for Coders with fastai and PyTorch</a></em> cÃ¹ng vá»›i Jeremy Howard. HÆ°á»›ng nghiÃªn cá»©u chÃ­nh cá»§a anh áº¥y lÃ  lÃ m cho viá»‡c há»c sÃ¢u trá»Ÿ nÃªn dá»… tiáº¿p cáº­n hÆ¡n, báº±ng cÃ¡ch thiáº¿t káº¿ vÃ  cáº£i tiáº¿n cÃ¡c ká»¹ thuáº­t cho phÃ©p cÃ¡c mÃ´ hÃ¬nh huáº¥n luyá»‡n nhanh trÃªn cÃ¡c tÃ i nguyÃªn háº¡n cháº¿.</p>
<p><strong>Dawood Khan</strong> lÃ  má»™t Ká»¹ sÆ° Há»c mÃ¡y táº¡i Hugging Face. Anh áº¥y Ä‘áº¿n tá»« New York vÃ  tá»‘t nghiá»‡p Äáº¡i há»c New York chuyÃªn ngÃ nh Khoa há»c mÃ¡y tÃ­nh. Sau khi lÃ m viá»‡c vá»›i tÆ° cÃ¡ch lÃ  Ká»¹ sÆ° iOS trong má»™t vÃ i nÄƒm, Dawood Ä‘Ã£ nghá»‰ viá»‡c Ä‘á»ƒ báº¯t Ä‘áº§u phÃ¡t triá»ƒn Gradio cÃ¹ng vá»›i nhá»¯ng ngÆ°á»i Ä‘á»“ng sÃ¡ng láº­p cá»§a mÃ¬nh. Gradio cuá»‘i cÃ¹ng Ä‘Ã£ Ä‘Æ°á»£c mua láº¡i bá»Ÿi Hugging Face.</p>
<p><strong>Merve Noyan</strong> lÃ  ChuyÃªn gia vá» Quan há»‡ láº­p trÃ¬nh viÃªn táº¡i Hugging Face, hiá»‡n Ä‘ang phÃ¡t triá»ƒn cÃ¡c cÃ´ng cá»¥ vÃ  xÃ¢y dá»±ng ná»™i dung xung quanh chÃºng Ä‘á»ƒ táº¥t cáº£ má»i ngÆ°á»i cÃ³ thá»ƒ tiáº¿p cáº­n há»c mÃ¡y dá»… dÃ ng hÆ¡n.</p>
<p><strong>Lucile Saulnier</strong> lÃ  má»™t Ká»¹ sÆ° Há»c mÃ¡y táº¡i Hugging Face, phÃ¡t triá»ƒn vÃ  há»— trá»£ viá»‡c sá»­ dá»¥ng cÃ¡c cÃ´ng cá»¥ mÃ£ nguá»“n má»Ÿ. CÃ´ cÅ©ng tÃ­ch cá»±c tham gia vÃ o nhiá»u dá»± Ã¡n nghiÃªn cá»©u trong lÄ©nh vá»±c Xá»­ lÃ½ NgÃ´n ngá»¯ Tá»± nhiÃªn nhÆ° huáº¥n luyá»‡n cá»™ng tÃ¡c vÃ  BigScience.</p>
<p><strong>Lewis Tunstall</strong> lÃ  má»™t Ká»¹ sÆ° Há»c mÃ¡y táº¡i Hugging Face, táº­p trung vÃ o viá»‡c phÃ¡t triá»ƒn cÃ¡c cÃ´ng cá»¥ mÃ£ nguá»“n má»Ÿ vÃ  giÃºp chÃºng cÃ³ thá»ƒ tiáº¿p cáº­n Ä‘Æ°á»£c vá»›i cá»™ng Ä‘á»“ng rá»™ng lá»›n hÆ¡n. Anh cÅ©ng lÃ  Ä‘á»“ng tÃ¡c giáº£ cá»§a cuá»‘n sÃ¡ch Oâ€™Reilly <a href="https://www.oreilly.com/library/view/natural-language-processing/9781098103231/" rel="nofollow">Natural Language Processing with Transformers</a>.</p>
<p><strong>Leandro von Werra</strong> lÃ  má»™t Ká»¹ sÆ° Há»c mÃ¡y trong nhÃ³m mÃ£ nguá»“n má»Ÿ táº¡i Hugging Face vÃ  cÅ©ng lÃ  Ä‘á»“ng tÃ¡c giáº£ cá»§a cuá»‘n sÃ¡ch Oâ€™Reilly <a href="https://www.oreilly.com/library/view/natural-language-processing/9781098103231/" rel="nofollow">Natural Language Processing with Transformers</a>. Anh áº¥y cÃ³ nhiá»u nÄƒm kinh nghiá»‡m thá»±c táº¿ triá»ƒn khai cÃ¡c dá»± Ã¡n NLP vÃ o sáº£n xuáº¥t báº±ng cÃ¡ch lÃ m viá»‡c trÃªn toÃ n bá»™ há»‡ thá»‘ng há»c mÃ¡y.</p>
<p>Báº¡n Ä‘Ã£ sáºµn sÃ ng chÆ°a? Trong chÆ°Æ¡ng nÃ y, báº¡n sáº½ há»c:</p>
<ul><li>CÃ¡ch sá»­ dá»¥ng hÃ m <code>pipeline()</code> Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c tÃ¡c vá»¥ NLP nhÆ° táº¡o vÃ  phÃ¢n loáº¡i vÄƒn báº£n.</li>
<li>Vá» cáº¥u trÃºc cá»§a máº¡ng Transformer.</li>
<li>LÃ m tháº¿ nÃ o Ä‘á»ƒ phÃ¢n biá»‡t giá»¯a cÃ¡c kiáº¿n trÃºc encoder, decoder, vÃ  encoder-decoder cÅ©ng nhÆ° cÃ¡c trÆ°á»ng há»£p sá»­ dá»¥ng.</li></ul>


		<script type="module" data-hydrate="19jzjvs">
		import { start } from "/docs/course/main/vi/_app/start-hf-doc-builder.js";
		start({
			target: document.querySelector('[data-hydrate="19jzjvs"]').parentNode,
			paths: {"base":"/docs/course/main/vi","assets":"/docs/course/main/vi"},
			session: {},
			route: false,
			spa: false,
			trailing_slash: "never",
			hydrate: {
				status: 200,
				error: null,
				nodes: [
					import("/docs/course/main/vi/_app/pages/__layout.svelte-hf-doc-builder.js"),
						import("/docs/course/main/vi/_app/pages/chapter1/1.mdx-hf-doc-builder.js")
				],
				params: {}
			}
		});
	</script>
