<meta charset="utf-8" /><meta http-equiv="content-security-policy" content=""><meta name="hf:doc:metadata" content="{&quot;local&quot;:&quot;einfhrung&quot;,&quot;sections&quot;:[{&quot;local&quot;:&quot;willkommen-zum-kurs&quot;,&quot;title&quot;:&quot;Willkommen zum ü§ó Kurs!&quot;},{&quot;local&quot;:&quot;was-erwartet-dich&quot;,&quot;title&quot;:&quot;Was erwartet dich?&quot;},{&quot;local&quot;:&quot;wer-sind-wir&quot;,&quot;title&quot;:&quot;Wer sind wir?&quot;},{&quot;local&quot;:&quot;hufig-gestellte-fragen-faq&quot;,&quot;title&quot;:&quot;H√§ufig gestellte Fragen (FAQ)&quot;}],&quot;title&quot;:&quot;Einf√ºhrung&quot;}" data-svelte="svelte-1phssyn">
	<link rel="modulepreload" href="/docs/course/main/de/_app/assets/pages/__layout.svelte-hf-doc-builder.css">
	<link rel="modulepreload" href="/docs/course/main/de/_app/start-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/de/_app/chunks/vendor-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/de/_app/chunks/paths-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/de/_app/pages/__layout.svelte-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/de/_app/pages/chapter1/1.mdx-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/de/_app/chunks/Youtube-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/de/_app/chunks/IconCopyLink-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/de/_app/chunks/CodeBlock-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/de/_app/chunks/CourseFloatingBanner-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/de/_app/chunks/DocNotebookDropdown-hf-doc-builder.js"> 





<h1 class="relative group"><a id="einfhrung" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#einfhrung"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Einf√ºhrung
	</span></h1>



<div class="flex space-x-1 absolute z-10 right-0 top-0"><a href="https://discuss.huggingface.co/t/chapter-1-questions" target="_blank"><img alt="Ask a Question" class="!m-0" src="https://img.shields.io/badge/Ask%20a%20question-ffcb4c.svg?logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgLTEgMTA0IDEwNiI+PGRlZnM+PHN0eWxlPi5jbHMtMXtmaWxsOiMyMzFmMjA7fS5jbHMtMntmaWxsOiNmZmY5YWU7fS5jbHMtM3tmaWxsOiMwMGFlZWY7fS5jbHMtNHtmaWxsOiMwMGE5NGY7fS5jbHMtNXtmaWxsOiNmMTVkMjI7fS5jbHMtNntmaWxsOiNlMzFiMjM7fTwvc3R5bGU+PC9kZWZzPjx0aXRsZT5EaXNjb3Vyc2VfbG9nbzwvdGl0bGU+PGcgaWQ9IkxheWVyXzIiPjxnIGlkPSJMYXllcl8zIj48cGF0aCBjbGFzcz0iY2xzLTEiIGQ9Ik01MS44NywwQzIzLjcxLDAsMCwyMi44MywwLDUxYzAsLjkxLDAsNTIuODEsMCw1Mi44MWw1MS44Ni0uMDVjMjguMTYsMCw1MS0yMy43MSw1MS01MS44N1M4MCwwLDUxLjg3LDBaIi8+PHBhdGggY2xhc3M9ImNscy0yIiBkPSJNNTIuMzcsMTkuNzRBMzEuNjIsMzEuNjIsMCwwLDAsMjQuNTgsNjYuNDFsLTUuNzIsMTguNEwzOS40LDgwLjE3YTMxLjYxLDMxLjYxLDAsMSwwLDEzLTYwLjQzWiIvPjxwYXRoIGNsYXNzPSJjbHMtMyIgZD0iTTc3LjQ1LDMyLjEyYTMxLjYsMzEuNiwwLDAsMS0zOC4wNSw0OEwxOC44Niw4NC44MmwyMC45MS0yLjQ3QTMxLjYsMzEuNiwwLDAsMCw3Ny40NSwzMi4xMloiLz48cGF0aCBjbGFzcz0iY2xzLTQiIGQ9Ik03MS42MywyNi4yOUEzMS42LDMxLjYsMCwwLDEsMzguOCw3OEwxOC44Niw4NC44MiwzOS40LDgwLjE3QTMxLjYsMzEuNiwwLDAsMCw3MS42MywyNi4yOVoiLz48cGF0aCBjbGFzcz0iY2xzLTUiIGQ9Ik0yNi40Nyw2Ny4xMWEzMS42MSwzMS42MSwwLDAsMSw1MS0zNUEzMS42MSwzMS42MSwwLDAsMCwyNC41OCw2Ni40MWwtNS43MiwxOC40WiIvPjxwYXRoIGNsYXNzPSJjbHMtNiIgZD0iTTI0LjU4LDY2LjQxQTMxLjYxLDMxLjYxLDAsMCwxLDcxLjYzLDI2LjI5YTMxLjYxLDMxLjYxLDAsMCwwLTQ5LDM5LjYzbC0zLjc2LDE4LjlaIi8+PC9nPjwvZz48L3N2Zz4="></a>
	
	</div>
<h2 class="relative group"><a id="willkommen-zum-kurs" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#willkommen-zum-kurs"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Willkommen zum ü§ó Kurs!
	</span></h2>

<iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/00GKzGyWFEs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p>In diesem Kurs lernst du verschiedene Teilbereiche der maschinellen Verarbeitung nat√ºrlicher Sprache (engl. Natural Language Processing, NLP) - im Deutschen auch als Maschinelle Sprachverarbeitung oder Computerlinguistik (CL) bezeichnet - unter Verwendung der Bibliotheken des √ñkosystems von <a href="https://huggingface.co/" rel="nofollow">Hugging Face</a> kennen: die <a href="https://github.com/huggingface/transformers" rel="nofollow">ü§ó Transformers-</a>, die <a href="https://github.com/huggingface/datasets" rel="nofollow">ü§ó Datasets-</a>, die <a href="https://github.com/huggingface/tokenizers" rel="nofollow">ü§ó Tokenizers-</a> sowie die <a href="https://github.com/huggingface/accelerate" rel="nofollow">ü§ó Accelerate-Bibliotheken</a> als auch der <a href="https://huggingface.co/models" rel="nofollow">Hugging Face Hub</a>. Der Kurs ist komplett kostenlos und frei von Werbung.</p>
<h2 class="relative group"><a id="was-erwartet-dich" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#was-erwartet-dich"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Was erwartet dich?
	</span></h2>

<p>Hier ein kurzer √úberblick √ºber den Kurs:</p>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary.svg" alt="Brief overview of the chapters of the course.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary-dark.svg" alt="Brief overview of the chapters of the course."></div>
<ul><li>Die Kapitel 1 bis 4 geben eine Einf√ºhrung in die wichtigsten Konzepte der ü§ó Transformers-Bibliothek. Am Ende dieses Teils des Kurses wirst du mit der Funktionsweise von Transformer-Modellen vertraut sein und wissen, wie du ein Modell aus dem <a href="https://huggingface.co/models" rel="nofollow">Hugging Face Hub</a> verwendest, es auf einem Datensatz feintunst und deine Ergebnisse mit anderen auf dem Hub teilst!</li>
<li>In den Kapiteln 5 bis 8 lernst du die Grundlagen der ü§ó Datasets- und ü§ó Tokenizers-Bibliotheken kennen, bevor du in die typischen Problemstellungen des NLP eintauchst. Am Ende dieses Teils wirst du in der Lage sein, die g√§ngisten Problemstellungen im NLP selbstst√§ndig zu l√∂sen.</li>
<li>Die Kapitel 9 bis 12 gehen √ºber den Bereich des NLP hinaus und zeigen, wie Transformer-Modelle f√ºr Aufgaben bei der Verarbeitung gesprochener Sprache (engl. Speech Processing) und im Bereich Computer Vision (im Deutschen ungef√§hr mit computerbasiertem Sehen zu √ºbersetzen) eingesetzt werden k√∂nnen. Nebenbei lernst du, wie du eigene Versionen deiner Modelle zu Demonstrationszwecken erstellen und sie mit anderen teilen kannst, und wie du sie f√ºr Produktionsumgebungen optimierst. Am Ende dieses Teils wirst du in der Lage sein, die ü§ó Transformers-Bibliothek auf (fast) jede Problemstellung, die dir im Bereich des Maschinellen Lernens begegnen, anzuwenden!</li></ul>
<p>Dieser Kurs:</p>
<ul><li>Erfordert gute Kenntnisse in Python</li>
<li>Sollte am besten nach einem Einf√ºhrungskurs in Deep Learning gemacht werden, wie z. B. <a href="https://www.fast.ai/" rel="nofollow">fast.ai‚Äôs Kurs</a> <a href="https://course.fast.ai/" rel="nofollow">Practical Deep Learning for Coders</a> oder eines der von <a href="https://www.deeplearning.ai/" rel="nofollow">DeepLearning.AI</a> entwickelten Kursprogramme</li>
<li>Setzt keine Vorkenntnisse in <a href="https://pytorch.org/" rel="nofollow">PyTorch</a> oder <a href="https://www.tensorflow.org/" rel="nofollow">TensorFlow</a> voraus, obwohl es hilfreich ist, wenn du bereits mit ihnen vertraut sein solltest.</li></ul>
<p>Nachdem du diesen Kurs abgeschlossen hast, empfehlen wir dir den <a href="https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearning-ai&utm_medium=institutions&utm_campaign=20211011-nlp-2-hugging_face-page-nlp-refresh" rel="nofollow">Spezialisierungskurs Natural Language Processing von DeepLearning.AI</a>, der eine breite Palette traditioneller NLP-Modelle wie Naive Bayes und LSTMs abdeckt, bei denen es sich lohnt, sich mit ihnen vertraut zu machen!</p>
<h2 class="relative group"><a id="wer-sind-wir" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#wer-sind-wir"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Wer sind wir?
	</span></h2>

<p>√úber die Autorinnen und Autoren:</p>
<p><strong>Matthew Carrigan</strong> ist Machine Learning Engineer bei Hugging Face. Er lebt in der irischen Hauptstadt Dublin und hat zuvor als Machine Learning Engineer bei Parse.ly und als Post-Doktorand am Trinity College Dublin gearbeitet. Er glaubt nicht, dass wir eine k√ºnstliche allgemeine Intelligenz (engl. Artificial General Intelligence, AGI) durch eine zunehmende Skalierung bestehender Architekturen erreichen werden, hat aber dennoch die Hoffnung, dass Roboter auf dem Weg zur Unsterblichkeit sind.</p>
<p><strong>Lysandre Debut</strong> ist Machine Learning Engineer bei Hugging Face und arbeitet bereits seit Entstehung an der ü§ó Transformers-Bibliothek mit. Sein Ziel ist es, NLP f√ºr alle zug√§nglich zu machen, indem er Tools entwickelt, die eine sehr einfache API bieten.</p>
<p><strong>Sylvain Gugger</strong> ist Research Engineer bei Hugging Face und einer der Hauptverantwortlichen f√ºr die Pflege der ü§ó Transformers-Bibliothek. Zuvor war er Research Scientist bei fast.ai und hat zusammen mit Jeremy Howard das Buch <em><a href="https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/" rel="nofollow">Deep Learning for Coders with fastai and PyTorch</a></em> verfasst. Seine Forschung ist darauf ausgerichtet, Deep Learning zug√§nglicher zu machen. Hierf√ºr entwickelt und verbessert er Techniken, mit denen Modelle auch bei begrenzter Ressourcenausstattung auf schnelle Weise trainiert werden k√∂nnen.</p>
<p><strong>Merve Noyan</strong> ist Developer Advocate bei Hugging Face und arbeitet daran, Tools zu entwickeln und Inhalte zu erstellen, die Maschinelles Lernen f√ºr jeden zug√§nglich machen.</p>
<p><strong>Lucile Saulnier</strong> ist Machine Learning Engineer bei Hugging Face und entwickelt und unterst√ºtzt die Nutzung von Open-Source-Tools. Au√üerdem ist sie aktiv an vielen Forschungsprojekten im Bereich des NLP beteiligt, z. B. an kollaborativem Training und BigScience.</p>
<p><strong>Lewis Tunstall</strong> ist Machine Learning Engineer bei Hugging Face, und konzentriert sich darauf, Open-Source-Tools zu entwickeln und sie der breiten Community zug√§nglich zu machen. Zudem ist er Mitverfasser des O‚ÄôReilly-Buches <a href="https://www.oreilly.com/library/view/natural-language-processing/9781098136789/" rel="nofollow">Natural Language Processing with Transformers</a>.</p>
<p><strong>Leandro von Werra</strong> ist Machine Learning Engineer im Open-Source-Team von Hugging Face und ebenfalls einer der Autoren des O‚ÄôReilly-Buches <a href="https://www.oreilly.com/library/view/natural-language-processing/9781098136789/" rel="nofollow">Natural Language Processing with Transformers</a>. Er hat mehrere Jahre praktische Erfahrung darin gesammelt, NLP-Projekte in die Produktion zu bringen, und dabei den gesamten ML-Stack beackert.</p>
<h2 class="relative group"><a id="hufig-gestellte-fragen-faq" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#hufig-gestellte-fragen-faq"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>H√§ufig gestellte Fragen (FAQ)
	</span></h2>

<p>Hier findest du einige Antworten auf h√§ufig gestellte Fragen:</p>
<ul><li><p>**Erhalte ich f√ºr die Teilnahme an diesem Kurs ein Zertifikat?
Derzeit gibt es f√ºr diesen Kurs noch kein Zertifikat. Wir arbeiten jedoch an einem Programm zur Erlangung eines Zertifikats f√ºr das Hugging-Face-√ñkosystem - bleib‚Äô auf dem Laufenden!</p></li>
<li><p>**Wie viel Zeit sollte ich f√ºr diesen Kurs einplanen?
Jedes Kapitel dieses Kurses ist so konzipiert, dass es innerhalb einer Woche abgeschlossen werden kann, wenn du circa 6 bis 8 Stunden Arbeit einplanst. Du kannst dir jedoch so viel Zeit nehmen wie n√∂tig.</p></li>
<li><p><strong>Wo kann ich Fragen stellen, wenn ich welche habe?</strong>
Wenn du eine Frage zu einem Kursabschnitt hast, klicke einfach auf das sich oben auf der Seite befindende Banner ‚Äù<em>Ask a question</em>‚Äù und du wirst automatisch zum entsprechenden Bereich des <a href="https://discuss.huggingface.co/" rel="nofollow">Hugging-Face-Forums</a> weitergeleitet:</p></li></ul>
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/forum-button.png" alt="Link to the Hugging Face forums" width="75%">
<p>Wenn du nach dem Kurs noch weiter √ºben m√∂chtest, steht dir in den Foren eine Liste mit <a href="https://discuss.huggingface.co/c/course/course-event/25" rel="nofollow">Projektideen</a> zur Verf√ºgung.</p>
<ul><li><strong>Wo finde ich den Code f√ºr den Kurs?</strong>
In jedem Abschnitt kannst du auf das oben auf der Seite befindliche Banner klicken, um den Code entweder in Google Colab oder in Amazon SageMaker Studio Lab auszuf√ºhren:</li></ul>
<img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/notebook-buttons.png" alt="Link to the Hugging Face course notebooks" width="75%">
<p>Die Jupyter-Notebooks, die den gesamten Code des Kurses enthalten, befinden sich im <a href="https://github.com/huggingface/notebooks" rel="nofollow"><code>huggingface/notebooks</code>-Repo</a>. Wenn du sie lokal aufsetzen m√∂chtest, schau dir die Anweisungen im <a href="https://github.com/huggingface/course#-jupyter-notebooks" rel="nofollow"><code>course</code>-Repository</a> auf GitHub an.</p>
<ul><li><p><strong>Wie kann ich etwas zum Kurs beitragen?</strong>
Es gibt mehrere M√∂glichkeiten, zum Kurs beizutragen! Wenn du einen Tippfehler oder einen Fehler entdeckst, er√∂ffne bitte ein Issue in dem <a href="https://github.com/huggingface/course" rel="nofollow"><code>course</code>-Repository</a>. Wenn du uns dabei unterst√ºtzen m√∂chtest, den Kurs in deine Muttersprache zu √ºbersetzen, sieh dir bitte die <a href="https://github.com/huggingface/course#translating-the-course-into-your-language" rel="nofollow">Anleitung</a> an.</p></li>
<li><p><strong>Welche Entscheidungen wurden bei den einzelnen √úbersetzungen getroffen?</strong>
F√ºr jede √úbersetzung gibt es ein Glossar und die Datei <code>TRANSLATING.txt</code>, in der die gew√§hlten Fachtermini usw. festgehalten sind. Ein Beispiel f√ºr die deutsche Fassung findest du <a href="https://github.com/huggingface/course/blob/main/chapters/de/TRANSLATING.txt" rel="nofollow">hier</a>.</p></li></ul>
<ul><li><strong>Kann ich diesen Kurs auch an anderer Stelle verwenden?</strong>
Ja, nat√ºrlich! Der Kurs ist unter der permissiven <a href="https://www.apache.org/licenses/LICENSE-2.0.html" rel="nofollow">Apache-2-Lizenz</a> ver√∂ffentlicht. Das bedeutet, dass du den Kurs in angemessener Weise erw√§hnen, einen Verweis zur Lizenz angeben und darauf hinweisen musst, wenn du √Ñnderungen vorgenommen hast. Du kannst dies in jeder angemessenen Weise tun, allerdings nicht in einer Weise, die den Eindruck erweckt, dass der Lizenzgeber dich oder deine Nutzung unterst√ºtzt. Wenn du den Kurs zitieren m√∂chtest, verwende bitte den folgenden BibTeX-Eintrag:</li></ul>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START -->@misc{huggingfacecourse,
  <span class="hljs-attr">author</span> = {Hugging Face},
  <span class="hljs-attr">title</span> = {The Hugging Face Course, <span class="hljs-number">2022</span>},
  <span class="hljs-attr">howpublished</span> = <span class="hljs-string">&quot;\url{https://huggingface.co/course}&quot;</span>,
  <span class="hljs-attr">year</span> = {<span class="hljs-number">2022</span>},
  <span class="hljs-attr">note</span> = <span class="hljs-string">&quot;[Online; accessed &lt;today&gt;]&quot;</span>
}<!-- HTML_TAG_END --></pre></div>
<p>Bist du bereit, loszulegen? In diesem Kapitel lernst du</p>
<ul><li>wie man die Funktion <code>pipeline()</code> benutzt, um computerlinguistische Aufgaben wie Textgenerierung und Klassifizierung zu l√∂sen,</li>
<li>mehr √ºber die Transformer-Architektur und</li>
<li>wie zwischen Encoder-, Decoder- und Encoder-Decoder-basierten Architekturen und -Anwendungsf√§llen unterschieden werden kann.</li></ul>


		<script type="module" data-hydrate="cnftac">
		import { start } from "/docs/course/main/de/_app/start-hf-doc-builder.js";
		start({
			target: document.querySelector('[data-hydrate="cnftac"]').parentNode,
			paths: {"base":"/docs/course/main/de","assets":"/docs/course/main/de"},
			session: {},
			route: false,
			spa: false,
			trailing_slash: "never",
			hydrate: {
				status: 200,
				error: null,
				nodes: [
					import("/docs/course/main/de/_app/pages/__layout.svelte-hf-doc-builder.js"),
						import("/docs/course/main/de/_app/pages/chapter1/1.mdx-hf-doc-builder.js")
				],
				params: {}
			}
		});
	</script>
