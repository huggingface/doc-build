import{S as Od,i as Hd,s as Cd,e as a,k as u,w as $,t as i,M as Fd,c as l,d as n,m as p,a as o,x as k,h as r,b as f,N as Wd,G as s,g as d,y as _,q as x,o as E,B as z,v as Bd}from"../../chunks/vendor-hf-doc-builder.js";import{T as Fe}from"../../chunks/Tip-hf-doc-builder.js";import{Y as Nd}from"../../chunks/Youtube-hf-doc-builder.js";import{I as W}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as T}from"../../chunks/CodeBlock-hf-doc-builder.js";import{C as Ld}from"../../chunks/CourseFloatingBanner-hf-doc-builder.js";import"../../chunks/DocNotebookDropdown-hf-doc-builder.js";function Rd(I){let h,b,g,v,m,c,w,j,S;return{c(){h=i("\u{1F440} Siehst du rechts oben die Schaltfl\xE4che "),b=a("em"),g=i("Open in Colab"),v=i(`? Klicke darauf, um ein Google Colab Notebook, das alle Codebeispiele dieses Abschnitts enth\xE4lt, zu \xF6ffnen. Diese Schaltfl\xE4che ist in jedem Abschnitt, der Codebeispiele enth\xE4lt, zu finden.
`),m=a("p"),c=i("Wenn du die Beispiele lieber lokal ausf\xFChren m\xF6chtest, empfehlen wir dir, einen Blick auf das Kapitel "),w=a("a"),j=i("Einrichtung"),S=i(" zu werfen."),this.h()},l(y){h=r(y,"\u{1F440} Siehst du rechts oben die Schaltfl\xE4che "),b=l(y,"EM",{});var P=o(b);g=r(P,"Open in Colab"),P.forEach(n),v=r(y,`? Klicke darauf, um ein Google Colab Notebook, das alle Codebeispiele dieses Abschnitts enth\xE4lt, zu \xF6ffnen. Diese Schaltfl\xE4che ist in jedem Abschnitt, der Codebeispiele enth\xE4lt, zu finden.
`),m=l(y,"P",{});var D=o(m);c=r(D,"Wenn du die Beispiele lieber lokal ausf\xFChren m\xF6chtest, empfehlen wir dir, einen Blick auf das Kapitel "),w=l(D,"A",{href:!0});var M=o(w);j=r(M,"Einrichtung"),M.forEach(n),S=r(D," zu werfen."),D.forEach(n),this.h()},h(){f(w,"href","/course/chapter0")},m(y,P){d(y,h,P),d(y,b,P),s(b,g),d(y,v,P),d(y,m,P),s(m,c),s(m,w),s(w,j),s(m,S)},d(y){y&&n(h),y&&n(b),y&&n(v),y&&n(m)}}}function Vd(I){let h,b,g,v;return{c(){h=i("\u26A0\uFE0F Der Hugging Face Hub ist nicht auf Transformer-Modelle beschr\xE4nkt. Jede bzw. jeder kann die von ihr bzw. ihm gew\xFCnschten Arten von Modellen oder Datens\xE4tzen teilen! "),b=a("a"),g=i("Erstelle ein Konto auf huggingface.co"),v=i(", um alle verf\xFCgbaren Features nutzen zu k\xF6nnen!"),this.h()},l(m){h=r(m,"\u26A0\uFE0F Der Hugging Face Hub ist nicht auf Transformer-Modelle beschr\xE4nkt. Jede bzw. jeder kann die von ihr bzw. ihm gew\xFCnschten Arten von Modellen oder Datens\xE4tzen teilen! "),b=l(m,"A",{href:!0});var c=o(b);g=r(c,"Erstelle ein Konto auf huggingface.co"),c.forEach(n),v=r(m,", um alle verf\xFCgbaren Features nutzen zu k\xF6nnen!"),this.h()},h(){f(b,"href","https://huggingface.co/join")},m(m,c){d(m,h,c),d(m,b,c),s(b,g),d(m,v,c)},d(m){m&&n(h),m&&n(b),m&&n(v)}}}function Gd(I){let h,b,g,v,m;return{c(){h=a("p"),b=i("\u270F\uFE0F "),g=a("strong"),v=i("Probiere es aus!"),m=i(" Spiel mit deinen eigenen Sequenzen und Labels herum und beobachte, wie sich das Modell verh\xE4lt.")},l(c){h=l(c,"P",{});var w=o(h);b=r(w,"\u270F\uFE0F "),g=l(w,"STRONG",{});var j=o(g);v=r(j,"Probiere es aus!"),j.forEach(n),m=r(w," Spiel mit deinen eigenen Sequenzen und Labels herum und beobachte, wie sich das Modell verh\xE4lt."),w.forEach(n)},m(c,w){d(c,h,w),s(h,b),s(h,g),s(g,v),s(h,m)},d(c){c&&n(h)}}}function Kd(I){let h,b,g,v,m,c,w,j,S,y,P;return{c(){h=a("p"),b=i("\u270F\uFE0F "),g=a("strong"),v=i("Probiere es aus!"),m=i(" W\xE4hle die Argumente "),c=a("code"),w=i("num_return_sequences"),j=i(" und "),S=a("code"),y=i("max_length"),P=i(" so, dass zwei S\xE4tze mit jeweils 15 W\xF6rtern erzeugt werden.")},l(D){h=l(D,"P",{});var M=o(h);b=r(M,"\u270F\uFE0F "),g=l(M,"STRONG",{});var Tn=o(g);v=r(Tn,"Probiere es aus!"),Tn.forEach(n),m=r(M," W\xE4hle die Argumente "),c=l(M,"CODE",{});var ie=o(c);w=r(ie,"num_return_sequences"),ie.forEach(n),j=r(M," und "),S=l(M,"CODE",{});var Sn=o(S);y=r(Sn,"max_length"),Sn.forEach(n),P=r(M," so, dass zwei S\xE4tze mit jeweils 15 W\xF6rtern erzeugt werden."),M.forEach(n)},m(D,M){d(D,h,M),s(h,b),s(h,g),s(g,v),s(h,m),s(h,c),s(c,w),s(h,j),s(h,S),s(S,y),s(h,P)},d(D){D&&n(h)}}}function Zd(I){let h,b,g,v,m;return{c(){h=a("p"),b=i("\u270F\uFE0F "),g=a("strong"),v=i("Probiere es aus!"),m=i(" Verwende die Filter, um ein Textgenerierungsmodell f\xFCr eine andere Sprache zu finden. Experimentiere ruhig ein wenig mit dem Widget und verwende das Modell in einer Pipeline!")},l(c){h=l(c,"P",{});var w=o(h);b=r(w,"\u270F\uFE0F "),g=l(w,"STRONG",{});var j=o(g);v=r(j,"Probiere es aus!"),j.forEach(n),m=r(w," Verwende die Filter, um ein Textgenerierungsmodell f\xFCr eine andere Sprache zu finden. Experimentiere ruhig ein wenig mit dem Widget und verwende das Modell in einer Pipeline!"),w.forEach(n)},m(c,w){d(c,h,w),s(h,b),s(h,g),s(g,v),s(h,m)},d(c){c&&n(h)}}}function Ud(I){let h,b,g,v,m,c,w,j;return{c(){h=a("p"),b=i("\u270F\uFE0F "),g=a("strong"),v=i("Probiere es aus!"),m=i(" Suche im Hub nach dem Modell "),c=a("code"),w=i("bert-base-cased"),j=i(" und finde sein Mask Token im Widget, das auf der Inference API basiert, heraus. Was sagt dieses Modell f\xFCr den oben in der Pipeline verwendeten Satz vorher?")},l(S){h=l(S,"P",{});var y=o(h);b=r(y,"\u270F\uFE0F "),g=l(y,"STRONG",{});var P=o(g);v=r(P,"Probiere es aus!"),P.forEach(n),m=r(y," Suche im Hub nach dem Modell "),c=l(y,"CODE",{});var D=o(c);w=r(D,"bert-base-cased"),D.forEach(n),j=r(y," und finde sein Mask Token im Widget, das auf der Inference API basiert, heraus. Was sagt dieses Modell f\xFCr den oben in der Pipeline verwendeten Satz vorher?"),y.forEach(n)},m(S,y){d(S,h,y),s(h,b),s(h,g),s(g,v),s(h,m),s(h,c),s(c,w),s(h,j)},d(S){S&&n(h)}}}function Jd(I){let h,b,g,v,m;return{c(){h=a("p"),b=i("\u270F\uFE0F "),g=a("strong"),v=i("Probiere es aus!"),m=i(" Suche im Model Hub nach einem Modell, das in der Lage ist, Part-of-Speech-Tagging (in der Regel als POS abgek\xFCrzt) im Englischen durchzuf\xFChren (Anm.: d. h. Wortarten zuzuordnen). Was sagt dieses Modell f\xFCr den Satz im obigen Beispiel vorher?")},l(c){h=l(c,"P",{});var w=o(h);b=r(w,"\u270F\uFE0F "),g=l(w,"STRONG",{});var j=o(g);v=r(j,"Probiere es aus!"),j.forEach(n),m=r(w," Suche im Model Hub nach einem Modell, das in der Lage ist, Part-of-Speech-Tagging (in der Regel als POS abgek\xFCrzt) im Englischen durchzuf\xFChren (Anm.: d. h. Wortarten zuzuordnen). Was sagt dieses Modell f\xFCr den Satz im obigen Beispiel vorher?"),w.forEach(n)},m(c,w){d(c,h,w),s(h,b),s(h,g),s(g,v),s(h,m)},d(c){c&&n(h)}}}function Qd(I){let h,b,g,v,m;return{c(){h=a("p"),b=i("\u270F\uFE0F "),g=a("strong"),v=i("Probiere es aus!"),m=i(" Suche nach \xDCbersetzungsmodellen in anderen Sprachen und versuche, den vorangegangenen Satz in mehrere verschiedene Sprachen zu \xFCbersetzen.")},l(c){h=l(c,"P",{});var w=o(h);b=r(w,"\u270F\uFE0F "),g=l(w,"STRONG",{});var j=o(g);v=r(j,"Probiere es aus!"),j.forEach(n),m=r(w," Suche nach \xDCbersetzungsmodellen in anderen Sprachen und versuche, den vorangegangenen Satz in mehrere verschiedene Sprachen zu \xFCbersetzen."),w.forEach(n)},m(c,w){d(c,h,w),s(h,b),s(h,g),s(g,v),s(h,m)},d(c){c&&n(h)}}}function Yd(I){let h,b,g,v,m,c,w,j,S,y,P,D,M,Tn,ie,Sn,rr,mt,re,wt,K,ae,Yn,We,ar,Xn,lr,bt,In,or,vt,le,Vl,$t,B,dr,Be,ur,pr,Ne,hr,fr,kt,oe,_t,Dn,cr,xt,Z,de,es,Le,gr,ns,mr,Et,Re,zt,ue,wr,ss,br,vr,yt,Ve,jt,Ge,Pt,qn,$r,Mt,Ke,At,Ze,Tt,pe,kr,ts,_r,xr,St,On,Er,It,N,is,zr,yr,rs,jr,Pr,as,Mr,Dt,he,Ar,Ue,Tr,Sr,qt,A,Hn,ls,Ir,Dr,qr,os,ds,Or,Hr,Cn,us,Cr,Fr,Wr,ps,hs,Br,Nr,fs,cs,Lr,Rr,gs,ms,Vr,Gr,ws,bs,Kr,Zr,vs,$s,Ur,Jr,ks,_s,Qr,Ot,Fn,Yr,Ht,U,fe,xs,Je,Xr,Es,ea,Ct,ce,na,zs,sa,ta,Ft,Qe,Wt,Ye,Bt,ge,ia,ys,ra,aa,Nt,me,Lt,J,we,js,Xe,la,Ps,oa,Rt,Wn,da,Vt,en,Gt,nn,Kt,L,ua,Ms,pa,ha,As,fa,ca,Zt,be,Ut,Q,ve,Ts,sn,ga,Ss,ma,Jt,C,wa,tn,ba,va,Is,$a,ka,rn,_a,xa,Qt,$e,Ea,an,Ds,za,ya,Yt,ln,Xt,on,ei,ke,ja,qs,Pa,Ma,ni,Bn,Aa,si,_e,ti,Y,xe,Os,dn,Ta,Hs,Sa,ii,Ee,Ia,un,Da,qa,ri,ze,Oa,pn,Ha,Ca,ai,X,ye,Cs,hn,Fa,Fs,Wa,li,je,Ba,Ws,Na,La,oi,fn,di,cn,ui,F,Ra,Bs,Va,Ga,Ns,Ka,Za,Ls,Ua,Ja,pi,Pe,hi,ee,Me,Rs,gn,Qa,Vs,Ya,fi,Nn,Xa,ci,mn,gi,wn,mi,Ln,el,wi,q,nl,Gs,sl,tl,Ks,il,rl,Zs,al,ll,Us,ol,dl,Js,ul,pl,Qs,hl,fl,bi,Ae,vi,ne,Te,Ys,bn,cl,Xs,gl,$i,Se,ml,et,wl,bl,ki,vn,_i,$n,xi,Rn,vl,Ei,se,Ie,nt,kn,$l,st,kl,zi,Vn,_l,yi,_n,ji,xn,Pi,R,xl,tt,El,zl,it,yl,jl,Mi,te,De,rt,En,Pl,at,Ml,Ai,V,Al,lt,Tl,Sl,zn,Il,Dl,Ti,yn,Si,jn,Ii,G,ql,ot,Ol,Hl,dt,Cl,Fl,Di,qe,qi,Oe,Wl,ut,Bl,Nl,Oi;return c=new W({}),P=new Ld({props:{chapter:1,classNames:"absolute z-10 right-0 top-0",notebooks:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/de/chapter1/section3.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/de/chapter1/section3.ipynb"}]}}),re=new Fe({props:{$$slots:{default:[Rd]},$$scope:{ctx:I}}}),We=new W({}),oe=new Fe({props:{$$slots:{default:[Vd]},$$scope:{ctx:I}}}),Le=new W({}),Re=new Nd({props:{id:"tiZFewofSLM"}}),Ve=new T({props:{code:`from transformers import pipeline

classifier = pipeline("sentiment-analysis")
classifier("I've been waiting for a HuggingFace course my whole life.")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>)
classifier(<span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>)`}}),Ge=new T({props:{code:"[{'label': 'POSITIVE', 'score': 0.9598047137260437}]",highlighted:'[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;POSITIVE&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9598047137260437</span>}]'}}),Ke=new T({props:{code:`classifier(
    ["I've been waiting for a HuggingFace course my whole life.", "I hate this so much!"]
)`,highlighted:`classifier(
    [<span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>, <span class="hljs-string">&quot;I hate this so much!&quot;</span>]
)`}}),Ze=new T({props:{code:`[{'label': 'POSITIVE', 'score': 0.9598047137260437},
 {'label': 'NEGATIVE', 'score': 0.9994558095932007}]`,highlighted:`[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;POSITIVE&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9598047137260437</span>},
 {<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;NEGATIVE&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9994558095932007</span>}]`}}),Je=new W({}),Qe=new T({props:{code:`from transformers import pipeline

classifier = pipeline("zero-shot-classification")
classifier(
    "This is a course about the Transformers library",
    candidate_labels=["education", "politics", "business"],
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

classifier = pipeline(<span class="hljs-string">&quot;zero-shot-classification&quot;</span>)
classifier(
    <span class="hljs-string">&quot;This is a course about the Transformers library&quot;</span>,
    candidate_labels=[<span class="hljs-string">&quot;education&quot;</span>, <span class="hljs-string">&quot;politics&quot;</span>, <span class="hljs-string">&quot;business&quot;</span>],
)`}}),Ye=new T({props:{code:`{'sequence': 'This is a course about the Transformers library',
 'labels': ['education', 'business', 'politics'],
 'scores': [0.8445963859558105, 0.111976258456707, 0.043427448719739914]}`,highlighted:`{<span class="hljs-string">&#x27;sequence&#x27;</span>: <span class="hljs-string">&#x27;This is a course about the Transformers library&#x27;</span>,
 <span class="hljs-string">&#x27;labels&#x27;</span>: [<span class="hljs-string">&#x27;education&#x27;</span>, <span class="hljs-string">&#x27;business&#x27;</span>, <span class="hljs-string">&#x27;politics&#x27;</span>],
 <span class="hljs-string">&#x27;scores&#x27;</span>: [<span class="hljs-number">0.8445963859558105</span>, <span class="hljs-number">0.111976258456707</span>, <span class="hljs-number">0.043427448719739914</span>]}`}}),me=new Fe({props:{$$slots:{default:[Gd]},$$scope:{ctx:I}}}),Xe=new W({}),en=new T({props:{code:`from transformers import pipeline

generator = pipeline("text-generation")
generator("In this course, we will teach you how to")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

generator = pipeline(<span class="hljs-string">&quot;text-generation&quot;</span>)
generator(<span class="hljs-string">&quot;In this course, we will teach you how to&quot;</span>)`}}),nn=new T({props:{code:`[{'generated_text': 'In this course, we will teach you how to understand and use '
                    'data flow and data interchange when handling user data. We '
                    'will be working with one or more of the most commonly used '
                    'data flows \u2014 data flows of various types, as seen by the '
                    'HTTP'}]`,highlighted:`[{<span class="hljs-string">&#x27;generated_text&#x27;</span>: <span class="hljs-string">&#x27;In this course, we will teach you how to understand and use &#x27;</span>
                    <span class="hljs-string">&#x27;data flow and data interchange when handling user data. We &#x27;</span>
                    <span class="hljs-string">&#x27;will be working with one or more of the most commonly used &#x27;</span>
                    <span class="hljs-string">&#x27;data flows \u2014 data flows of various types, as seen by the &#x27;</span>
                    <span class="hljs-string">&#x27;HTTP&#x27;</span>}]`}}),be=new Fe({props:{$$slots:{default:[Kd]},$$scope:{ctx:I}}}),sn=new W({}),ln=new T({props:{code:`from transformers import pipeline

generator = pipeline("text-generation", model="distilgpt2")
generator(
    "In this course, we will teach you how to",
    max_length=30,
    num_return_sequences=2,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

generator = pipeline(<span class="hljs-string">&quot;text-generation&quot;</span>, model=<span class="hljs-string">&quot;distilgpt2&quot;</span>)
generator(
    <span class="hljs-string">&quot;In this course, we will teach you how to&quot;</span>,
    max_length=<span class="hljs-number">30</span>,
    num_return_sequences=<span class="hljs-number">2</span>,
)`}}),on=new T({props:{code:`[{'generated_text': 'In this course, we will teach you how to manipulate the world and '
                    'move your mental and physical capabilities to your advantage.'},
 {'generated_text': 'In this course, we will teach you how to become an expert and '
                    'practice realtime, and with a hands on experience on both real '
                    'time and real'}]`,highlighted:`[{<span class="hljs-string">&#x27;generated_text&#x27;</span>: <span class="hljs-string">&#x27;In this course, we will teach you how to manipulate the world and &#x27;</span>
                    <span class="hljs-string">&#x27;move your mental and physical capabilities to your advantage.&#x27;</span>},
 {<span class="hljs-string">&#x27;generated_text&#x27;</span>: <span class="hljs-string">&#x27;In this course, we will teach you how to become an expert and &#x27;</span>
                    <span class="hljs-string">&#x27;practice realtime, and with a hands on experience on both real &#x27;</span>
                    <span class="hljs-string">&#x27;time and real&#x27;</span>}]`}}),_e=new Fe({props:{$$slots:{default:[Zd]},$$scope:{ctx:I}}}),dn=new W({}),hn=new W({}),fn=new T({props:{code:`from transformers import pipeline

unmasker = pipeline("fill-mask")
unmasker("This course will teach you all about <mask> models.", top_k=2)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

unmasker = pipeline(<span class="hljs-string">&quot;fill-mask&quot;</span>)
unmasker(<span class="hljs-string">&quot;This course will teach you all about &lt;mask&gt; models.&quot;</span>, top_k=<span class="hljs-number">2</span>)`}}),cn=new T({props:{code:`[{'sequence': 'This course will teach you all about mathematical models.',
  'score': 0.19619831442832947,
  'token': 30412,
  'token_str': ' mathematical'},
 {'sequence': 'This course will teach you all about computational models.',
  'score': 0.04052725434303284,
  'token': 38163,
  'token_str': ' computational'}]`,highlighted:`[{<span class="hljs-string">&#x27;sequence&#x27;</span>: <span class="hljs-string">&#x27;This course will teach you all about mathematical models.&#x27;</span>,
  <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.19619831442832947</span>,
  <span class="hljs-string">&#x27;token&#x27;</span>: <span class="hljs-number">30412</span>,
  <span class="hljs-string">&#x27;token_str&#x27;</span>: <span class="hljs-string">&#x27; mathematical&#x27;</span>},
 {<span class="hljs-string">&#x27;sequence&#x27;</span>: <span class="hljs-string">&#x27;This course will teach you all about computational models.&#x27;</span>,
  <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.04052725434303284</span>,
  <span class="hljs-string">&#x27;token&#x27;</span>: <span class="hljs-number">38163</span>,
  <span class="hljs-string">&#x27;token_str&#x27;</span>: <span class="hljs-string">&#x27; computational&#x27;</span>}]`}}),Pe=new Fe({props:{$$slots:{default:[Ud]},$$scope:{ctx:I}}}),gn=new W({}),mn=new T({props:{code:`from transformers import pipeline

ner = pipeline("ner", grouped_entities=True)
ner("My name is Sylvain and I work at Hugging Face in Brooklyn.")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

ner = pipeline(<span class="hljs-string">&quot;ner&quot;</span>, grouped_entities=<span class="hljs-literal">True</span>)
ner(<span class="hljs-string">&quot;My name is Sylvain and I work at Hugging Face in Brooklyn.&quot;</span>)`}}),wn=new T({props:{code:`[{'entity_group': 'PER', 'score': 0.99816, 'word': 'Sylvain', 'start': 11, 'end': 18}, 
 {'entity_group': 'ORG', 'score': 0.97960, 'word': 'Hugging Face', 'start': 33, 'end': 45}, 
 {'entity_group': 'LOC', 'score': 0.99321, 'word': 'Brooklyn', 'start': 49, 'end': 57}
]`,highlighted:`[{<span class="hljs-string">&#x27;entity_group&#x27;</span>: <span class="hljs-string">&#x27;PER&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.99816</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;Sylvain&#x27;</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">11</span>, <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">18</span>}, 
 {<span class="hljs-string">&#x27;entity_group&#x27;</span>: <span class="hljs-string">&#x27;ORG&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.97960</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;Hugging Face&#x27;</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">33</span>, <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">45</span>}, 
 {<span class="hljs-string">&#x27;entity_group&#x27;</span>: <span class="hljs-string">&#x27;LOC&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.99321</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;Brooklyn&#x27;</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">49</span>, <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">57</span>}
]`}}),Ae=new Fe({props:{$$slots:{default:[Jd]},$$scope:{ctx:I}}}),bn=new W({}),vn=new T({props:{code:`from transformers import pipeline

question_answerer = pipeline("question-answering")
question_answerer(
    question="Where do I work?",
    context="My name is Sylvain and I work at Hugging Face in Brooklyn",
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

question_answerer = pipeline(<span class="hljs-string">&quot;question-answering&quot;</span>)
question_answerer(
    question=<span class="hljs-string">&quot;Where do I work?&quot;</span>,
    context=<span class="hljs-string">&quot;My name is Sylvain and I work at Hugging Face in Brooklyn&quot;</span>,
)`}}),$n=new T({props:{code:"{'score': 0.6385916471481323, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}",highlighted:'{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.6385916471481323</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">33</span>, <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">45</span>, <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;Hugging Face&#x27;</span>}'}}),kn=new W({}),_n=new T({props:{code:`from transformers import pipeline

summarizer = pipeline("summarization")
summarizer(
    """
    America has changed dramatically during recent years. Not only has the number of 
    graduates in traditional engineering disciplines such as mechanical, civil, 
    electrical, chemical, and aeronautical engineering declined, but in most of 
    the premier American universities engineering curricula now concentrate on 
    and encourage largely the study of engineering science. As a result, there 
    are declining offerings in engineering subjects dealing with infrastructure, 
    the environment, and related issues, and greater concentration on high 
    technology subjects, largely supporting increasingly complex scientific 
    developments. While the latter is important, it should not be at the expense 
    of more traditional engineering.

    Rapidly developing economies such as China and India, as well as other 
    industrial countries in Europe and Asia, continue to encourage and advance 
    the teaching of engineering. Both China and India, respectively, graduate 
    six and eight times as many traditional engineers as does the United States. 
    Other industrial countries at minimum maintain their output, while America 
    suffers an increasingly serious decline in the number of engineering graduates 
    and a lack of well-educated engineers.
"""
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

summarizer = pipeline(<span class="hljs-string">&quot;summarization&quot;</span>)
summarizer(
    <span class="hljs-string">&quot;&quot;&quot;
    America has changed dramatically during recent years. Not only has the number of 
    graduates in traditional engineering disciplines such as mechanical, civil, 
    electrical, chemical, and aeronautical engineering declined, but in most of 
    the premier American universities engineering curricula now concentrate on 
    and encourage largely the study of engineering science. As a result, there 
    are declining offerings in engineering subjects dealing with infrastructure, 
    the environment, and related issues, and greater concentration on high 
    technology subjects, largely supporting increasingly complex scientific 
    developments. While the latter is important, it should not be at the expense 
    of more traditional engineering.

    Rapidly developing economies such as China and India, as well as other 
    industrial countries in Europe and Asia, continue to encourage and advance 
    the teaching of engineering. Both China and India, respectively, graduate 
    six and eight times as many traditional engineers as does the United States. 
    Other industrial countries at minimum maintain their output, while America 
    suffers an increasingly serious decline in the number of engineering graduates 
    and a lack of well-educated engineers.
&quot;&quot;&quot;</span>
)`}}),xn=new T({props:{code:`[{'summary_text': ' America has changed dramatically during recent years . The '
                  'number of engineering graduates in the U.S. has declined in '
                  'traditional engineering disciplines such as mechanical, civil '
                  ', electrical, chemical, and aeronautical engineering . Rapidly '
                  'developing economies such as China and India, as well as other '
                  'industrial countries in Europe and Asia, continue to encourage '
                  'and advance engineering .'}]`,highlighted:`[{<span class="hljs-string">&#x27;summary_text&#x27;</span>: <span class="hljs-string">&#x27; America has changed dramatically during recent years . The &#x27;</span>
                  <span class="hljs-string">&#x27;number of engineering graduates in the U.S. has declined in &#x27;</span>
                  <span class="hljs-string">&#x27;traditional engineering disciplines such as mechanical, civil &#x27;</span>
                  <span class="hljs-string">&#x27;, electrical, chemical, and aeronautical engineering . Rapidly &#x27;</span>
                  <span class="hljs-string">&#x27;developing economies such as China and India, as well as other &#x27;</span>
                  <span class="hljs-string">&#x27;industrial countries in Europe and Asia, continue to encourage &#x27;</span>
                  <span class="hljs-string">&#x27;and advance engineering .&#x27;</span>}]`}}),En=new W({}),yn=new T({props:{code:`from transformers import pipeline

translator = pipeline("translation", model="Helsinki-NLP/opus-mt-fr-en")
translator("Ce cours est produit par Hugging Face.")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

translator = pipeline(<span class="hljs-string">&quot;translation&quot;</span>, model=<span class="hljs-string">&quot;Helsinki-NLP/opus-mt-fr-en&quot;</span>)
translator(<span class="hljs-string">&quot;Ce cours est produit par Hugging Face.&quot;</span>)`}}),jn=new T({props:{code:"[{'translation_text': 'This course is produced by Hugging Face.'}]",highlighted:'[{<span class="hljs-string">&#x27;translation_text&#x27;</span>: <span class="hljs-string">&#x27;This course is produced by Hugging Face.&#x27;</span>}]'}}),qe=new Fe({props:{$$slots:{default:[Qd]},$$scope:{ctx:I}}}),{c(){h=a("meta"),b=u(),g=a("h1"),v=a("a"),m=a("span"),$(c.$$.fragment),w=u(),j=a("span"),S=i("Transformer-Modelle - wozu sind sie imstande?"),y=u(),$(P.$$.fragment),D=u(),M=a("p"),Tn=i("In diesem Abschnitt schauen wir uns an, was Transformer-Modelle zu leisten imstande sind. Zudem verwenden wir unser erstes Werkzeug aus der \u{1F917} Transformers-Bibliothek: die Funktion "),ie=a("code"),Sn=i("pipeline()"),rr=i("."),mt=u(),$(re.$$.fragment),wt=u(),K=a("h2"),ae=a("a"),Yn=a("span"),$(We.$$.fragment),ar=u(),Xn=a("span"),lr=i("Transformer-Modelle sind \xFCberall anzutreffen!"),bt=u(),In=a("p"),or=i("Transformer-Modelle werden verwendet, um alle Arten von CL-Aufgaben (engl. Tasks) zu l\xF6sen, u. a. die im vorherigen Abschnitt genannten. Hier sind einige der Unternehmen und Organisationen, die Hugging-Face- und Transformer-Modelle verwenden und ihre Modelle mit der Community teilen:"),vt=u(),le=a("img"),$t=u(),B=a("p"),dr=i("Die "),Be=a("a"),ur=i("\u{1F917} Transformers-Bibliothek"),pr=i(" bietet die Funktionalit\xE4t, um diese geteilten Modelle zu erstellen und zu nutzen. Der "),Ne=a("a"),hr=i("Model Hub"),fr=i(" enth\xE4lt Tausende von vortrainierten Modellen, die jeder herunterladen und nutzen kann. Auch du kannst dort deine eigenen Modelle hochladen!"),kt=u(),$(oe.$$.fragment),_t=u(),Dn=a("p"),cr=i("Bevor wir uns ansehen, wie Transformer-Modelle im Einzelnen funktionieren, widmen wir uns ein paar Beispielen, die veranschaulichen, wie sie zur L\xF6sung interessanter CL-Problemstellungen eingesetzt werden k\xF6nnen."),xt=u(),Z=a("h2"),de=a("a"),es=a("span"),$(Le.$$.fragment),gr=u(),ns=a("span"),mr=i("Mit Pipelines arbeiten"),Et=u(),$(Re.$$.fragment),zt=u(),ue=a("p"),wr=i("Das grundlegendste Objekt in der \u{1F917} Transformers-Bibliothek ist die "),ss=a("code"),br=i("pipeline()"),vr=i("-Funktion. Sie verbindet ein Modell mit den notwendigen Vor- und Nachverarbeitungsschritten (engl. Preprocessing/Postprocessing) und erm\xF6glicht es uns, direkt einen beliebigen Text eingeben zu k\xF6nnen und eine Antwort zu erhalten, die verst\xE4ndlich ist:"),yt=u(),$(Ve.$$.fragment),jt=u(),$(Ge.$$.fragment),Pt=u(),qn=a("p"),$r=i("Wir k\xF6nnen sogar mehrere S\xE4tze auf einmal \xFCbergeben!"),Mt=u(),$(Ke.$$.fragment),At=u(),$(Ze.$$.fragment),Tt=u(),pe=a("p"),kr=i("In der Voreinstellung w\xE4hlt diese Pipeline ein bestimmtes vortrainiertes Modell aus, das bereits f\xFCr die Sentiment-Analyse in englischer Sprache feingetunt wurde. Wenn du das "),ts=a("code"),_r=i("classifier"),xr=i("-Objekt erstellst, wird das Modell heruntergeladen und zwischengespeichert. Wenn du den Befehl erneut ausf\xFChrst, wird stattdessen das zwischengespeicherte Modell verwendet und das Modell muss nicht erneut heruntergeladen werden."),St=u(),On=a("p"),Er=i("Wenn du einen Text an eine Pipeline \xFCbergibst, gibt es drei wichtige Schritte:"),It=u(),N=a("ol"),is=a("li"),zr=i("Der Text wird im Rahmen der Vorverarbeitung in ein Format \xFCberf\xFChrt, das das Modell verstehen kann."),yr=u(),rs=a("li"),jr=i("Die vorverarbeiteten Inputs bzw. Eingaben werden an das Modell \xFCbergeben."),Pr=u(),as=a("li"),Mr=i("Die Vorhersagen des Modells werden so nachverarbeitet, sodass du sie nutzen kannst."),Dt=u(),he=a("p"),Ar=i("Einige der derzeit "),Ue=a("a"),Tr=i("verf\xFCgbaren Pipelines"),Sr=i(" sind:"),qt=u(),A=a("ul"),Hn=a("li"),ls=a("code"),Ir=i("feature-extraction"),Dr=i(" (Vektordarstellung eines Textes erhalten)"),qr=u(),os=a("li"),ds=a("code"),Or=i("fill-mask"),Hr=u(),Cn=a("li"),us=a("code"),Cr=i("ner"),Fr=i(" (Named Entity Recognition)"),Wr=u(),ps=a("li"),hs=a("code"),Br=i("question-answering"),Nr=u(),fs=a("li"),cs=a("code"),Lr=i("sentiment-analysis"),Rr=u(),gs=a("li"),ms=a("code"),Vr=i("summarization"),Gr=u(),ws=a("li"),bs=a("code"),Kr=i("text-generation"),Zr=u(),vs=a("li"),$s=a("code"),Ur=i("translation"),Jr=u(),ks=a("li"),_s=a("code"),Qr=i("zero-shot-classification"),Ot=u(),Fn=a("p"),Yr=i("Werfen wir doch gleich mal einen Blick auf ein paar von ihnen!"),Ht=u(),U=a("h2"),fe=a("a"),xs=a("span"),$(Je.$$.fragment),Xr=u(),Es=a("span"),ea=i("Zero-Shot-Klassifizierung"),Ct=u(),ce=a("p"),na=i("Beginnen wir mit der recht anspruchsvollen Aufgabe, Texte zu klassifizieren, die noch nicht gelabelt wurden. Dieses Problem tritt h\xE4ufig in realen Projekten auf, da das Labeln von Texten in der Regel zeitaufwendig ist und Fachwissen erfordert. F\xFCr diesen Anwendungsfall ist die Pipeline "),zs=a("code"),sa=i("zero-shot-classification"),ta=i(" sehr vielversprechend: Mit ihr kannst du festlegen, welche Labels f\xFCr die Klassifizierung verwendet werden sollen, und musst nicht auf die Labels des vortrainierten Modells zur\xFCckgreifen. Wie du bereits gesehen hast, kann das Modell einen Satz - entsprechend der beiden Labels - als positiv oder negativ klassifizieren. Es kann den Text aber auch auf der Grundlage einer beliebigen anderen Auswahl an Labels klassifizieren."),Ft=u(),$(Qe.$$.fragment),Wt=u(),$(Ye.$$.fragment),Bt=u(),ge=a("p"),ia=i("Diese Pipeline hei\xDFt "),ys=a("em"),ra=i("zero-shot"),aa=i(", weil du das Modell nicht erst auf deine Daten feintunen musst, ehe du es verwenden kannst. Sie kann direkt die Wahrscheinlichkeiten f\xFCr jede beliebige von dir vorgegebene Liste von Labels liefern!"),Nt=u(),$(me.$$.fragment),Lt=u(),J=a("h2"),we=a("a"),js=a("span"),$(Xe.$$.fragment),la=u(),Ps=a("span"),oa=i("Textgenerierung"),Rt=u(),Wn=a("p"),da=i("Sehen wir uns nun an, wie du eine Pipeline verwenden kannst, wenn du einen Text generieren m\xF6chtest. Der Grundgedanke dabei ist, dass du einen bestimmten Input (einen sog. Prompt) vorgibst und das Modell diesen automatisch vervollst\xE4ndigt, indem es den restlichen Text generiert. Das ist \xE4hnlich wie die Textvorhersagefunktion, die auf vielen Handys zu finden ist. Die Textgenerierung erfolgt nach dem Zufallsprinzip - daher ist es normal, wenn du nicht die gleichen Ergebnisse wie die unten gezeigten erh\xE4ltst."),Vt=u(),$(en.$$.fragment),Gt=u(),$(nn.$$.fragment),Kt=u(),L=a("p"),ua=i("Mit dem Argument "),Ms=a("code"),pa=i("num_return_sequences"),ha=i(" kannst du steuern, wie viele verschiedene Sequenzen erzeugt werden und mit dem Argument "),As=a("code"),fa=i("max_length"),ca=i(", wie lang der Ausgabetext insgesamt sein soll."),Zt=u(),$(be.$$.fragment),Ut=u(),Q=a("h2"),ve=a("a"),Ts=a("span"),$(sn.$$.fragment),ga=u(),Ss=a("span"),ma=i("Verwendung eines beliebigen Modells vom Hub in einer Pipeline"),Jt=u(),C=a("p"),wa=i("In den vorherigen Beispielen wurde f\xFCr die jeweilige Aufgabe das voreingestellte Standardmodell verwendet. Du kannst aber auch ein bestimmtes Modell aus dem Hub ausw\xE4hlen und es in einer Pipeline f\xFCr eine konkrete Aufgabe verwenden - zum Beispiel f\xFCr die Textgenerierung. Gehe zum "),tn=a("a"),ba=i("Model Hub"),va=i(" und klicke auf der linken Seite unter "),Is=a("code"),$a=i("Tasks"),ka=i(" auf das entsprechende Tag, um dir lediglich die f\xFCr diese Aufgabenstellung unterst\xFCtzten Modelle anzeigen zu lassen. Du solltest anschlie\xDFend auf eine Seite wie "),rn=a("a"),_a=i("diese"),xa=i(" gelangen."),Qt=u(),$e=a("p"),Ea=i("Probieren wir nun das Modell "),an=a("a"),Ds=a("code"),za=i("distilgpt2"),ya=i(" aus! So kannst du es mit der gleichen Pipeline wie zuvor laden:"),Yt=u(),$(ln.$$.fragment),Xt=u(),$(on.$$.fragment),ei=u(),ke=a("p"),ja=i("Du kannst deine Suche nach einem Modell verfeinern, indem du auf eines der "),qs=a("code"),Pa=i("Languages"),Ma=i("-Tags klickst und ein Modell ausw\xE4hlst, das Text in einer anderen Sprache generiert. Der Model Hub enth\xE4lt sogar Checkpoints f\xFCr mehrsprachige Modelle, die mehrere verschiedene Sprachen unterst\xFCtzen."),ni=u(),Bn=a("p"),Aa=i("Nachdem du auf ein Modell geklickt und es ausgew\xE4hlt hast, siehst du, dass es ein Widget gibt, mit dem du es direkt online ausprobieren kannst. Dementsprechend kannst du die F\xE4higkeiten eines Modells erst schnell testen, bevor du dich dazu entschlie\xDFt, es herunterzuladen."),si=u(),$(_e.$$.fragment),ti=u(),Y=a("h3"),xe=a("a"),Os=a("span"),$(dn.$$.fragment),Ta=u(),Hs=a("span"),Sa=i("Die Inference API"),ii=u(),Ee=a("p"),Ia=i("Alle Modelle k\xF6nnen direkt \xFCber deinen Browser getestet werden, indem du die Inference API verwendest, die auf der "),un=a("a"),Da=i("Webseite von Hugging Face"),qa=i(" verf\xFCgbar ist. Auf dieser Seite kannst du direkt mit dem Modell experimentieren, indem du einen eigenen Text eingibst und beobachtest, wie das Modell die Input-Daten verarbeitet."),ri=u(),ze=a("p"),Oa=i("Die Inference API, die dem Widget zugrunde liegt, ist auch als kostenpflichtiges Produkt erh\xE4ltlich, was recht praktisch ist, wenn du sie f\xFCr deine Workflows ben\xF6tigst. Weitere Informationen findest du auf der "),pn=a("a"),Ha=i("Preisseite"),Ca=i("."),ai=u(),X=a("h2"),ye=a("a"),Cs=a("span"),$(hn.$$.fragment),Fa=u(),Fs=a("span"),Wa=i("Mask Filling"),li=u(),je=a("p"),Ba=i("Die n\xE4chste Pipeline, die du ausprobieren wirst, ist "),Ws=a("code"),Na=i("fill-mask"),La=i(". Bei dieser Aufgabe geht es darum, L\xFCcken in einem vorgegebenen Text zu f\xFCllen:"),oi=u(),$(fn.$$.fragment),di=u(),$(cn.$$.fragment),ui=u(),F=a("p"),Ra=i("Mit dem Argument "),Bs=a("code"),Va=i("top_k"),Ga=i(" kannst du bestimmen, wie viele M\xF6glichkeiten dir ausgegeben werden sollen. Beachte, dass das Modell hier das spezielle Wort "),Ns=a("code"),Ka=i("<mask>"),Za=i(" auff\xFCllt, das oft als "),Ls=a("em"),Ua=i("Mask-Token"),Ja=i(" bezeichnet wird. Andere Modelle, die dazu dienen, Maskierungen aufzuf\xFCllen, k\xF6nnen andere Mask Tokens haben. Deshalb ist es immer gut, erst das verwendete Mask Token zu ermitteln, wenn du andere Modelle nutzen m\xF6chtest. Eine M\xF6glichkeit, zu \xFCberpr\xFCfen, welches Mask Token verwendet wird, ist das Widget."),pi=u(),$(Pe.$$.fragment),hi=u(),ee=a("h2"),Me=a("a"),Rs=a("span"),$(gn.$$.fragment),Qa=u(),Vs=a("span"),Ya=i("Named Entity Recognition"),fi=u(),Nn=a("p"),Xa=i("Bei der Eigennamenerkennung (engl. Named Entity Recognition, NER) handelt es sich um eine Aufgabenstellung, bei der das Modell herausfinden muss, welche Teile des Input-Textes Entit\xE4ten wie Personen, Orte oder Organisationen darstellen. Nehmen wir uns ein konkretes Beispiel zur Hand:"),ci=u(),$(mn.$$.fragment),gi=u(),$(wn.$$.fragment),mi=u(),Ln=a("p"),el=i("Hier hat das Modell richtig erkannt, dass Sylvain eine Person (PER), Hugging Face eine Organisation (ORG) und Brooklyn ein Ort (LOC) ist."),wi=u(),q=a("p"),nl=i("In der Funktion zur Erstellung der Pipeline \xFCbergeben wir die Option "),Gs=a("code"),sl=i("grouped_entities=True"),tl=i(", um die Pipeline anzuweisen, die Teile des Satzes, die der gleichen Entit\xE4t entsprechen, zu gruppieren: Hier hat das Modell \u201CHugging\u201D und \u201CFace\u201D richtigerweise als eine einzelne Organisation gruppiert, auch wenn der Name aus mehreren W\xF6rtern besteht. Wie wir im n\xE4chsten Kapitel sehen werden, werden bei der Vorverarbeitung (engl. Preprocessing) sogar einige W\xF6rter in kleinere Teile zerlegt. Zum Beispiel wird "),Ks=a("code"),il=i("Sylvain"),rl=i(" in vier Teile zerlegt: "),Zs=a("code"),al=i("S"),ll=i(", "),Us=a("code"),ol=i("##yl"),dl=i(", "),Js=a("code"),ul=i("##va"),pl=i(" und "),Qs=a("code"),hl=i("##in"),fl=i(". Im Nachverarbeitungsschritt (engl. Post-Processing) hat die Pipeline diese Teile erfolgreich neu gruppiert."),bi=u(),$(Ae.$$.fragment),vi=u(),ne=a("h2"),Te=a("a"),Ys=a("span"),$(bn.$$.fragment),cl=u(),Xs=a("span"),gl=i("Frage-Antwort-Systeme (Question Answering)"),$i=u(),Se=a("p"),ml=i("Die Pipeline "),et=a("code"),wl=i("question-answering"),bl=i(" beantwortet Fragen anhand von Informationen, die aus einem bestimmten Kontext stammen:"),ki=u(),$(vn.$$.fragment),_i=u(),$($n.$$.fragment),xi=u(),Rn=a("p"),vl=i("Beachte, dass diese Pipeline Informationen aus dem gegebenen Kontext extrahiert; sie generiert nicht die Antwort."),Ei=u(),se=a("h2"),Ie=a("a"),nt=a("span"),$(kn.$$.fragment),$l=u(),st=a("span"),kl=i("Automatische Textzusammenfassung"),zi=u(),Vn=a("p"),_l=i("Bei der automatischen Textzusammenfassung (engl. Summarization) geht es darum, einen Text zu k\xFCrzen und dabei alle (oder die meisten) wichtigen Aspekte, auf die im Text verwiesen wird, beizubehalten. Hier ist ein Beispiel:"),yi=u(),$(_n.$$.fragment),ji=u(),$(xn.$$.fragment),Pi=u(),R=a("p"),xl=i("Wie bei der Textgenerierung kannst du eine maximale ("),tt=a("code"),El=i("max_length"),zl=i(") oder minimale ("),it=a("code"),yl=i("min_length"),jl=i(") L\xE4nge f\xFCr das Ergebnis angeben."),Mi=u(),te=a("h2"),De=a("a"),rt=a("span"),$(En.$$.fragment),Pl=u(),at=a("span"),Ml=i("Maschinelle \xDCbersetzung"),Ai=u(),V=a("p"),Al=i("F\xFCr die Maschinelle \xDCbersetzung (engl. Translation) kannst du ein vorgegebenes Standardmodell verwenden, indem du ein Sprachpaar im Aufgabennamen angibst (z. B. "),lt=a("code"),Tl=i('"translation_en_to_fr"'),Sl=i("). Am einfachsten ist es jedoch, das Modell, das du verwenden m\xF6chtest, im "),zn=a("a"),Il=i("Model Hub"),Dl=i(" auszuw\xE4hlen. Im folgenden Beispiel probieren wir die \xDCbersetzung vom Franz\xF6sischen ins Englische aus:"),Ti=u(),$(yn.$$.fragment),Si=u(),$(jn.$$.fragment),Ii=u(),G=a("p"),ql=i("Wie bei der Textgenerierung und -zusammenfassung kannst du auch hier "),ot=a("code"),Ol=i("max_length"),Hl=i(" oder "),dt=a("code"),Cl=i("min_length"),Fl=i(" als Argumente f\xFCr das Ergebnis angeben."),Di=u(),$(qe.$$.fragment),qi=u(),Oe=a("p"),Wl=i("Die bisher gezeigten Pipelines dienen haupts\xE4chlich zu Demonstrationszwecken. Sie wurden f\xFCr bestimmte Aufgabenstellungen programmiert und sind nicht f\xFCr Abwandlungen geeignet. Im n\xE4chsten Kapitel erf\xE4hrst du, was sich hinter einer "),ut=a("code"),Bl=i("pipeline()"),Nl=i("-Funktion verbirgt und wie du ihr Verhalten anpassen kannst."),this.h()},l(e){const t=Fd('[data-svelte="svelte-1phssyn"]',document.head);h=l(t,"META",{name:!0,content:!0}),t.forEach(n),b=p(e),g=l(e,"H1",{class:!0});var Pn=o(g);v=l(Pn,"A",{id:!0,class:!0,href:!0});var pt=o(v);m=l(pt,"SPAN",{});var ht=o(m);k(c.$$.fragment,ht),ht.forEach(n),pt.forEach(n),w=p(Pn),j=l(Pn,"SPAN",{});var ft=o(j);S=r(ft,"Transformer-Modelle - wozu sind sie imstande?"),ft.forEach(n),Pn.forEach(n),y=p(e),k(P.$$.fragment,e),D=p(e),M=l(e,"P",{});var Mn=o(M);Tn=r(Mn,"In diesem Abschnitt schauen wir uns an, was Transformer-Modelle zu leisten imstande sind. Zudem verwenden wir unser erstes Werkzeug aus der \u{1F917} Transformers-Bibliothek: die Funktion "),ie=l(Mn,"CODE",{});var ct=o(ie);Sn=r(ct,"pipeline()"),ct.forEach(n),rr=r(Mn,"."),Mn.forEach(n),mt=p(e),k(re.$$.fragment,e),wt=p(e),K=l(e,"H2",{class:!0});var An=o(K);ae=l(An,"A",{id:!0,class:!0,href:!0});var gt=o(ae);Yn=l(gt,"SPAN",{});var Gl=o(Yn);k(We.$$.fragment,Gl),Gl.forEach(n),gt.forEach(n),ar=p(An),Xn=l(An,"SPAN",{});var Kl=o(Xn);lr=r(Kl,"Transformer-Modelle sind \xFCberall anzutreffen!"),Kl.forEach(n),An.forEach(n),bt=p(e),In=l(e,"P",{});var Zl=o(In);or=r(Zl,"Transformer-Modelle werden verwendet, um alle Arten von CL-Aufgaben (engl. Tasks) zu l\xF6sen, u. a. die im vorherigen Abschnitt genannten. Hier sind einige der Unternehmen und Organisationen, die Hugging-Face- und Transformer-Modelle verwenden und ihre Modelle mit der Community teilen:"),Zl.forEach(n),vt=p(e),le=l(e,"IMG",{src:!0,alt:!0,width:!0}),$t=p(e),B=l(e,"P",{});var Gn=o(B);dr=r(Gn,"Die "),Be=l(Gn,"A",{href:!0,rel:!0});var Ul=o(Be);ur=r(Ul,"\u{1F917} Transformers-Bibliothek"),Ul.forEach(n),pr=r(Gn," bietet die Funktionalit\xE4t, um diese geteilten Modelle zu erstellen und zu nutzen. Der "),Ne=l(Gn,"A",{href:!0,rel:!0});var Jl=o(Ne);hr=r(Jl,"Model Hub"),Jl.forEach(n),fr=r(Gn," enth\xE4lt Tausende von vortrainierten Modellen, die jeder herunterladen und nutzen kann. Auch du kannst dort deine eigenen Modelle hochladen!"),Gn.forEach(n),kt=p(e),k(oe.$$.fragment,e),_t=p(e),Dn=l(e,"P",{});var Ql=o(Dn);cr=r(Ql,"Bevor wir uns ansehen, wie Transformer-Modelle im Einzelnen funktionieren, widmen wir uns ein paar Beispielen, die veranschaulichen, wie sie zur L\xF6sung interessanter CL-Problemstellungen eingesetzt werden k\xF6nnen."),Ql.forEach(n),xt=p(e),Z=l(e,"H2",{class:!0});var Hi=o(Z);de=l(Hi,"A",{id:!0,class:!0,href:!0});var Yl=o(de);es=l(Yl,"SPAN",{});var Xl=o(es);k(Le.$$.fragment,Xl),Xl.forEach(n),Yl.forEach(n),gr=p(Hi),ns=l(Hi,"SPAN",{});var eo=o(ns);mr=r(eo,"Mit Pipelines arbeiten"),eo.forEach(n),Hi.forEach(n),Et=p(e),k(Re.$$.fragment,e),zt=p(e),ue=l(e,"P",{});var Ci=o(ue);wr=r(Ci,"Das grundlegendste Objekt in der \u{1F917} Transformers-Bibliothek ist die "),ss=l(Ci,"CODE",{});var no=o(ss);br=r(no,"pipeline()"),no.forEach(n),vr=r(Ci,"-Funktion. Sie verbindet ein Modell mit den notwendigen Vor- und Nachverarbeitungsschritten (engl. Preprocessing/Postprocessing) und erm\xF6glicht es uns, direkt einen beliebigen Text eingeben zu k\xF6nnen und eine Antwort zu erhalten, die verst\xE4ndlich ist:"),Ci.forEach(n),yt=p(e),k(Ve.$$.fragment,e),jt=p(e),k(Ge.$$.fragment,e),Pt=p(e),qn=l(e,"P",{});var so=o(qn);$r=r(so,"Wir k\xF6nnen sogar mehrere S\xE4tze auf einmal \xFCbergeben!"),so.forEach(n),Mt=p(e),k(Ke.$$.fragment,e),At=p(e),k(Ze.$$.fragment,e),Tt=p(e),pe=l(e,"P",{});var Fi=o(pe);kr=r(Fi,"In der Voreinstellung w\xE4hlt diese Pipeline ein bestimmtes vortrainiertes Modell aus, das bereits f\xFCr die Sentiment-Analyse in englischer Sprache feingetunt wurde. Wenn du das "),ts=l(Fi,"CODE",{});var to=o(ts);_r=r(to,"classifier"),to.forEach(n),xr=r(Fi,"-Objekt erstellst, wird das Modell heruntergeladen und zwischengespeichert. Wenn du den Befehl erneut ausf\xFChrst, wird stattdessen das zwischengespeicherte Modell verwendet und das Modell muss nicht erneut heruntergeladen werden."),Fi.forEach(n),St=p(e),On=l(e,"P",{});var io=o(On);Er=r(io,"Wenn du einen Text an eine Pipeline \xFCbergibst, gibt es drei wichtige Schritte:"),io.forEach(n),It=p(e),N=l(e,"OL",{});var Kn=o(N);is=l(Kn,"LI",{});var ro=o(is);zr=r(ro,"Der Text wird im Rahmen der Vorverarbeitung in ein Format \xFCberf\xFChrt, das das Modell verstehen kann."),ro.forEach(n),yr=p(Kn),rs=l(Kn,"LI",{});var ao=o(rs);jr=r(ao,"Die vorverarbeiteten Inputs bzw. Eingaben werden an das Modell \xFCbergeben."),ao.forEach(n),Pr=p(Kn),as=l(Kn,"LI",{});var lo=o(as);Mr=r(lo,"Die Vorhersagen des Modells werden so nachverarbeitet, sodass du sie nutzen kannst."),lo.forEach(n),Kn.forEach(n),Dt=p(e),he=l(e,"P",{});var Wi=o(he);Ar=r(Wi,"Einige der derzeit "),Ue=l(Wi,"A",{href:!0,rel:!0});var oo=o(Ue);Tr=r(oo,"verf\xFCgbaren Pipelines"),oo.forEach(n),Sr=r(Wi," sind:"),Wi.forEach(n),qt=p(e),A=l(e,"UL",{});var O=o(A);Hn=l(O,"LI",{});var Ll=o(Hn);ls=l(Ll,"CODE",{});var uo=o(ls);Ir=r(uo,"feature-extraction"),uo.forEach(n),Dr=r(Ll," (Vektordarstellung eines Textes erhalten)"),Ll.forEach(n),qr=p(O),os=l(O,"LI",{});var po=o(os);ds=l(po,"CODE",{});var ho=o(ds);Or=r(ho,"fill-mask"),ho.forEach(n),po.forEach(n),Hr=p(O),Cn=l(O,"LI",{});var Rl=o(Cn);us=l(Rl,"CODE",{});var fo=o(us);Cr=r(fo,"ner"),fo.forEach(n),Fr=r(Rl," (Named Entity Recognition)"),Rl.forEach(n),Wr=p(O),ps=l(O,"LI",{});var co=o(ps);hs=l(co,"CODE",{});var go=o(hs);Br=r(go,"question-answering"),go.forEach(n),co.forEach(n),Nr=p(O),fs=l(O,"LI",{});var mo=o(fs);cs=l(mo,"CODE",{});var wo=o(cs);Lr=r(wo,"sentiment-analysis"),wo.forEach(n),mo.forEach(n),Rr=p(O),gs=l(O,"LI",{});var bo=o(gs);ms=l(bo,"CODE",{});var vo=o(ms);Vr=r(vo,"summarization"),vo.forEach(n),bo.forEach(n),Gr=p(O),ws=l(O,"LI",{});var $o=o(ws);bs=l($o,"CODE",{});var ko=o(bs);Kr=r(ko,"text-generation"),ko.forEach(n),$o.forEach(n),Zr=p(O),vs=l(O,"LI",{});var _o=o(vs);$s=l(_o,"CODE",{});var xo=o($s);Ur=r(xo,"translation"),xo.forEach(n),_o.forEach(n),Jr=p(O),ks=l(O,"LI",{});var Eo=o(ks);_s=l(Eo,"CODE",{});var zo=o(_s);Qr=r(zo,"zero-shot-classification"),zo.forEach(n),Eo.forEach(n),O.forEach(n),Ot=p(e),Fn=l(e,"P",{});var yo=o(Fn);Yr=r(yo,"Werfen wir doch gleich mal einen Blick auf ein paar von ihnen!"),yo.forEach(n),Ht=p(e),U=l(e,"H2",{class:!0});var Bi=o(U);fe=l(Bi,"A",{id:!0,class:!0,href:!0});var jo=o(fe);xs=l(jo,"SPAN",{});var Po=o(xs);k(Je.$$.fragment,Po),Po.forEach(n),jo.forEach(n),Xr=p(Bi),Es=l(Bi,"SPAN",{});var Mo=o(Es);ea=r(Mo,"Zero-Shot-Klassifizierung"),Mo.forEach(n),Bi.forEach(n),Ct=p(e),ce=l(e,"P",{});var Ni=o(ce);na=r(Ni,"Beginnen wir mit der recht anspruchsvollen Aufgabe, Texte zu klassifizieren, die noch nicht gelabelt wurden. Dieses Problem tritt h\xE4ufig in realen Projekten auf, da das Labeln von Texten in der Regel zeitaufwendig ist und Fachwissen erfordert. F\xFCr diesen Anwendungsfall ist die Pipeline "),zs=l(Ni,"CODE",{});var Ao=o(zs);sa=r(Ao,"zero-shot-classification"),Ao.forEach(n),ta=r(Ni," sehr vielversprechend: Mit ihr kannst du festlegen, welche Labels f\xFCr die Klassifizierung verwendet werden sollen, und musst nicht auf die Labels des vortrainierten Modells zur\xFCckgreifen. Wie du bereits gesehen hast, kann das Modell einen Satz - entsprechend der beiden Labels - als positiv oder negativ klassifizieren. Es kann den Text aber auch auf der Grundlage einer beliebigen anderen Auswahl an Labels klassifizieren."),Ni.forEach(n),Ft=p(e),k(Qe.$$.fragment,e),Wt=p(e),k(Ye.$$.fragment,e),Bt=p(e),ge=l(e,"P",{});var Li=o(ge);ia=r(Li,"Diese Pipeline hei\xDFt "),ys=l(Li,"EM",{});var To=o(ys);ra=r(To,"zero-shot"),To.forEach(n),aa=r(Li,", weil du das Modell nicht erst auf deine Daten feintunen musst, ehe du es verwenden kannst. Sie kann direkt die Wahrscheinlichkeiten f\xFCr jede beliebige von dir vorgegebene Liste von Labels liefern!"),Li.forEach(n),Nt=p(e),k(me.$$.fragment,e),Lt=p(e),J=l(e,"H2",{class:!0});var Ri=o(J);we=l(Ri,"A",{id:!0,class:!0,href:!0});var So=o(we);js=l(So,"SPAN",{});var Io=o(js);k(Xe.$$.fragment,Io),Io.forEach(n),So.forEach(n),la=p(Ri),Ps=l(Ri,"SPAN",{});var Do=o(Ps);oa=r(Do,"Textgenerierung"),Do.forEach(n),Ri.forEach(n),Rt=p(e),Wn=l(e,"P",{});var qo=o(Wn);da=r(qo,"Sehen wir uns nun an, wie du eine Pipeline verwenden kannst, wenn du einen Text generieren m\xF6chtest. Der Grundgedanke dabei ist, dass du einen bestimmten Input (einen sog. Prompt) vorgibst und das Modell diesen automatisch vervollst\xE4ndigt, indem es den restlichen Text generiert. Das ist \xE4hnlich wie die Textvorhersagefunktion, die auf vielen Handys zu finden ist. Die Textgenerierung erfolgt nach dem Zufallsprinzip - daher ist es normal, wenn du nicht die gleichen Ergebnisse wie die unten gezeigten erh\xE4ltst."),qo.forEach(n),Vt=p(e),k(en.$$.fragment,e),Gt=p(e),k(nn.$$.fragment,e),Kt=p(e),L=l(e,"P",{});var Zn=o(L);ua=r(Zn,"Mit dem Argument "),Ms=l(Zn,"CODE",{});var Oo=o(Ms);pa=r(Oo,"num_return_sequences"),Oo.forEach(n),ha=r(Zn," kannst du steuern, wie viele verschiedene Sequenzen erzeugt werden und mit dem Argument "),As=l(Zn,"CODE",{});var Ho=o(As);fa=r(Ho,"max_length"),Ho.forEach(n),ca=r(Zn,", wie lang der Ausgabetext insgesamt sein soll."),Zn.forEach(n),Zt=p(e),k(be.$$.fragment,e),Ut=p(e),Q=l(e,"H2",{class:!0});var Vi=o(Q);ve=l(Vi,"A",{id:!0,class:!0,href:!0});var Co=o(ve);Ts=l(Co,"SPAN",{});var Fo=o(Ts);k(sn.$$.fragment,Fo),Fo.forEach(n),Co.forEach(n),ga=p(Vi),Ss=l(Vi,"SPAN",{});var Wo=o(Ss);ma=r(Wo,"Verwendung eines beliebigen Modells vom Hub in einer Pipeline"),Wo.forEach(n),Vi.forEach(n),Jt=p(e),C=l(e,"P",{});var He=o(C);wa=r(He,"In den vorherigen Beispielen wurde f\xFCr die jeweilige Aufgabe das voreingestellte Standardmodell verwendet. Du kannst aber auch ein bestimmtes Modell aus dem Hub ausw\xE4hlen und es in einer Pipeline f\xFCr eine konkrete Aufgabe verwenden - zum Beispiel f\xFCr die Textgenerierung. Gehe zum "),tn=l(He,"A",{href:!0,rel:!0});var Bo=o(tn);ba=r(Bo,"Model Hub"),Bo.forEach(n),va=r(He," und klicke auf der linken Seite unter "),Is=l(He,"CODE",{});var No=o(Is);$a=r(No,"Tasks"),No.forEach(n),ka=r(He," auf das entsprechende Tag, um dir lediglich die f\xFCr diese Aufgabenstellung unterst\xFCtzten Modelle anzeigen zu lassen. Du solltest anschlie\xDFend auf eine Seite wie "),rn=l(He,"A",{href:!0,rel:!0});var Lo=o(rn);_a=r(Lo,"diese"),Lo.forEach(n),xa=r(He," gelangen."),He.forEach(n),Qt=p(e),$e=l(e,"P",{});var Gi=o($e);Ea=r(Gi,"Probieren wir nun das Modell "),an=l(Gi,"A",{href:!0,rel:!0});var Ro=o(an);Ds=l(Ro,"CODE",{});var Vo=o(Ds);za=r(Vo,"distilgpt2"),Vo.forEach(n),Ro.forEach(n),ya=r(Gi," aus! So kannst du es mit der gleichen Pipeline wie zuvor laden:"),Gi.forEach(n),Yt=p(e),k(ln.$$.fragment,e),Xt=p(e),k(on.$$.fragment,e),ei=p(e),ke=l(e,"P",{});var Ki=o(ke);ja=r(Ki,"Du kannst deine Suche nach einem Modell verfeinern, indem du auf eines der "),qs=l(Ki,"CODE",{});var Go=o(qs);Pa=r(Go,"Languages"),Go.forEach(n),Ma=r(Ki,"-Tags klickst und ein Modell ausw\xE4hlst, das Text in einer anderen Sprache generiert. Der Model Hub enth\xE4lt sogar Checkpoints f\xFCr mehrsprachige Modelle, die mehrere verschiedene Sprachen unterst\xFCtzen."),Ki.forEach(n),ni=p(e),Bn=l(e,"P",{});var Ko=o(Bn);Aa=r(Ko,"Nachdem du auf ein Modell geklickt und es ausgew\xE4hlt hast, siehst du, dass es ein Widget gibt, mit dem du es direkt online ausprobieren kannst. Dementsprechend kannst du die F\xE4higkeiten eines Modells erst schnell testen, bevor du dich dazu entschlie\xDFt, es herunterzuladen."),Ko.forEach(n),si=p(e),k(_e.$$.fragment,e),ti=p(e),Y=l(e,"H3",{class:!0});var Zi=o(Y);xe=l(Zi,"A",{id:!0,class:!0,href:!0});var Zo=o(xe);Os=l(Zo,"SPAN",{});var Uo=o(Os);k(dn.$$.fragment,Uo),Uo.forEach(n),Zo.forEach(n),Ta=p(Zi),Hs=l(Zi,"SPAN",{});var Jo=o(Hs);Sa=r(Jo,"Die Inference API"),Jo.forEach(n),Zi.forEach(n),ii=p(e),Ee=l(e,"P",{});var Ui=o(Ee);Ia=r(Ui,"Alle Modelle k\xF6nnen direkt \xFCber deinen Browser getestet werden, indem du die Inference API verwendest, die auf der "),un=l(Ui,"A",{href:!0,rel:!0});var Qo=o(un);Da=r(Qo,"Webseite von Hugging Face"),Qo.forEach(n),qa=r(Ui," verf\xFCgbar ist. Auf dieser Seite kannst du direkt mit dem Modell experimentieren, indem du einen eigenen Text eingibst und beobachtest, wie das Modell die Input-Daten verarbeitet."),Ui.forEach(n),ri=p(e),ze=l(e,"P",{});var Ji=o(ze);Oa=r(Ji,"Die Inference API, die dem Widget zugrunde liegt, ist auch als kostenpflichtiges Produkt erh\xE4ltlich, was recht praktisch ist, wenn du sie f\xFCr deine Workflows ben\xF6tigst. Weitere Informationen findest du auf der "),pn=l(Ji,"A",{href:!0,rel:!0});var Yo=o(pn);Ha=r(Yo,"Preisseite"),Yo.forEach(n),Ca=r(Ji,"."),Ji.forEach(n),ai=p(e),X=l(e,"H2",{class:!0});var Qi=o(X);ye=l(Qi,"A",{id:!0,class:!0,href:!0});var Xo=o(ye);Cs=l(Xo,"SPAN",{});var ed=o(Cs);k(hn.$$.fragment,ed),ed.forEach(n),Xo.forEach(n),Fa=p(Qi),Fs=l(Qi,"SPAN",{});var nd=o(Fs);Wa=r(nd,"Mask Filling"),nd.forEach(n),Qi.forEach(n),li=p(e),je=l(e,"P",{});var Yi=o(je);Ba=r(Yi,"Die n\xE4chste Pipeline, die du ausprobieren wirst, ist "),Ws=l(Yi,"CODE",{});var sd=o(Ws);Na=r(sd,"fill-mask"),sd.forEach(n),La=r(Yi,". Bei dieser Aufgabe geht es darum, L\xFCcken in einem vorgegebenen Text zu f\xFCllen:"),Yi.forEach(n),oi=p(e),k(fn.$$.fragment,e),di=p(e),k(cn.$$.fragment,e),ui=p(e),F=l(e,"P",{});var Ce=o(F);Ra=r(Ce,"Mit dem Argument "),Bs=l(Ce,"CODE",{});var td=o(Bs);Va=r(td,"top_k"),td.forEach(n),Ga=r(Ce," kannst du bestimmen, wie viele M\xF6glichkeiten dir ausgegeben werden sollen. Beachte, dass das Modell hier das spezielle Wort "),Ns=l(Ce,"CODE",{});var id=o(Ns);Ka=r(id,"<mask>"),id.forEach(n),Za=r(Ce," auff\xFCllt, das oft als "),Ls=l(Ce,"EM",{});var rd=o(Ls);Ua=r(rd,"Mask-Token"),rd.forEach(n),Ja=r(Ce," bezeichnet wird. Andere Modelle, die dazu dienen, Maskierungen aufzuf\xFCllen, k\xF6nnen andere Mask Tokens haben. Deshalb ist es immer gut, erst das verwendete Mask Token zu ermitteln, wenn du andere Modelle nutzen m\xF6chtest. Eine M\xF6glichkeit, zu \xFCberpr\xFCfen, welches Mask Token verwendet wird, ist das Widget."),Ce.forEach(n),pi=p(e),k(Pe.$$.fragment,e),hi=p(e),ee=l(e,"H2",{class:!0});var Xi=o(ee);Me=l(Xi,"A",{id:!0,class:!0,href:!0});var ad=o(Me);Rs=l(ad,"SPAN",{});var ld=o(Rs);k(gn.$$.fragment,ld),ld.forEach(n),ad.forEach(n),Qa=p(Xi),Vs=l(Xi,"SPAN",{});var od=o(Vs);Ya=r(od,"Named Entity Recognition"),od.forEach(n),Xi.forEach(n),fi=p(e),Nn=l(e,"P",{});var dd=o(Nn);Xa=r(dd,"Bei der Eigennamenerkennung (engl. Named Entity Recognition, NER) handelt es sich um eine Aufgabenstellung, bei der das Modell herausfinden muss, welche Teile des Input-Textes Entit\xE4ten wie Personen, Orte oder Organisationen darstellen. Nehmen wir uns ein konkretes Beispiel zur Hand:"),dd.forEach(n),ci=p(e),k(mn.$$.fragment,e),gi=p(e),k(wn.$$.fragment,e),mi=p(e),Ln=l(e,"P",{});var ud=o(Ln);el=r(ud,"Hier hat das Modell richtig erkannt, dass Sylvain eine Person (PER), Hugging Face eine Organisation (ORG) und Brooklyn ein Ort (LOC) ist."),ud.forEach(n),wi=p(e),q=l(e,"P",{});var H=o(q);nl=r(H,"In der Funktion zur Erstellung der Pipeline \xFCbergeben wir die Option "),Gs=l(H,"CODE",{});var pd=o(Gs);sl=r(pd,"grouped_entities=True"),pd.forEach(n),tl=r(H,", um die Pipeline anzuweisen, die Teile des Satzes, die der gleichen Entit\xE4t entsprechen, zu gruppieren: Hier hat das Modell \u201CHugging\u201D und \u201CFace\u201D richtigerweise als eine einzelne Organisation gruppiert, auch wenn der Name aus mehreren W\xF6rtern besteht. Wie wir im n\xE4chsten Kapitel sehen werden, werden bei der Vorverarbeitung (engl. Preprocessing) sogar einige W\xF6rter in kleinere Teile zerlegt. Zum Beispiel wird "),Ks=l(H,"CODE",{});var hd=o(Ks);il=r(hd,"Sylvain"),hd.forEach(n),rl=r(H," in vier Teile zerlegt: "),Zs=l(H,"CODE",{});var fd=o(Zs);al=r(fd,"S"),fd.forEach(n),ll=r(H,", "),Us=l(H,"CODE",{});var cd=o(Us);ol=r(cd,"##yl"),cd.forEach(n),dl=r(H,", "),Js=l(H,"CODE",{});var gd=o(Js);ul=r(gd,"##va"),gd.forEach(n),pl=r(H," und "),Qs=l(H,"CODE",{});var md=o(Qs);hl=r(md,"##in"),md.forEach(n),fl=r(H,". Im Nachverarbeitungsschritt (engl. Post-Processing) hat die Pipeline diese Teile erfolgreich neu gruppiert."),H.forEach(n),bi=p(e),k(Ae.$$.fragment,e),vi=p(e),ne=l(e,"H2",{class:!0});var er=o(ne);Te=l(er,"A",{id:!0,class:!0,href:!0});var wd=o(Te);Ys=l(wd,"SPAN",{});var bd=o(Ys);k(bn.$$.fragment,bd),bd.forEach(n),wd.forEach(n),cl=p(er),Xs=l(er,"SPAN",{});var vd=o(Xs);gl=r(vd,"Frage-Antwort-Systeme (Question Answering)"),vd.forEach(n),er.forEach(n),$i=p(e),Se=l(e,"P",{});var nr=o(Se);ml=r(nr,"Die Pipeline "),et=l(nr,"CODE",{});var $d=o(et);wl=r($d,"question-answering"),$d.forEach(n),bl=r(nr," beantwortet Fragen anhand von Informationen, die aus einem bestimmten Kontext stammen:"),nr.forEach(n),ki=p(e),k(vn.$$.fragment,e),_i=p(e),k($n.$$.fragment,e),xi=p(e),Rn=l(e,"P",{});var kd=o(Rn);vl=r(kd,"Beachte, dass diese Pipeline Informationen aus dem gegebenen Kontext extrahiert; sie generiert nicht die Antwort."),kd.forEach(n),Ei=p(e),se=l(e,"H2",{class:!0});var sr=o(se);Ie=l(sr,"A",{id:!0,class:!0,href:!0});var _d=o(Ie);nt=l(_d,"SPAN",{});var xd=o(nt);k(kn.$$.fragment,xd),xd.forEach(n),_d.forEach(n),$l=p(sr),st=l(sr,"SPAN",{});var Ed=o(st);kl=r(Ed,"Automatische Textzusammenfassung"),Ed.forEach(n),sr.forEach(n),zi=p(e),Vn=l(e,"P",{});var zd=o(Vn);_l=r(zd,"Bei der automatischen Textzusammenfassung (engl. Summarization) geht es darum, einen Text zu k\xFCrzen und dabei alle (oder die meisten) wichtigen Aspekte, auf die im Text verwiesen wird, beizubehalten. Hier ist ein Beispiel:"),zd.forEach(n),yi=p(e),k(_n.$$.fragment,e),ji=p(e),k(xn.$$.fragment,e),Pi=p(e),R=l(e,"P",{});var Un=o(R);xl=r(Un,"Wie bei der Textgenerierung kannst du eine maximale ("),tt=l(Un,"CODE",{});var yd=o(tt);El=r(yd,"max_length"),yd.forEach(n),zl=r(Un,") oder minimale ("),it=l(Un,"CODE",{});var jd=o(it);yl=r(jd,"min_length"),jd.forEach(n),jl=r(Un,") L\xE4nge f\xFCr das Ergebnis angeben."),Un.forEach(n),Mi=p(e),te=l(e,"H2",{class:!0});var tr=o(te);De=l(tr,"A",{id:!0,class:!0,href:!0});var Pd=o(De);rt=l(Pd,"SPAN",{});var Md=o(rt);k(En.$$.fragment,Md),Md.forEach(n),Pd.forEach(n),Pl=p(tr),at=l(tr,"SPAN",{});var Ad=o(at);Ml=r(Ad,"Maschinelle \xDCbersetzung"),Ad.forEach(n),tr.forEach(n),Ai=p(e),V=l(e,"P",{});var Jn=o(V);Al=r(Jn,"F\xFCr die Maschinelle \xDCbersetzung (engl. Translation) kannst du ein vorgegebenes Standardmodell verwenden, indem du ein Sprachpaar im Aufgabennamen angibst (z. B. "),lt=l(Jn,"CODE",{});var Td=o(lt);Tl=r(Td,'"translation_en_to_fr"'),Td.forEach(n),Sl=r(Jn,"). Am einfachsten ist es jedoch, das Modell, das du verwenden m\xF6chtest, im "),zn=l(Jn,"A",{href:!0,rel:!0});var Sd=o(zn);Il=r(Sd,"Model Hub"),Sd.forEach(n),Dl=r(Jn," auszuw\xE4hlen. Im folgenden Beispiel probieren wir die \xDCbersetzung vom Franz\xF6sischen ins Englische aus:"),Jn.forEach(n),Ti=p(e),k(yn.$$.fragment,e),Si=p(e),k(jn.$$.fragment,e),Ii=p(e),G=l(e,"P",{});var Qn=o(G);ql=r(Qn,"Wie bei der Textgenerierung und -zusammenfassung kannst du auch hier "),ot=l(Qn,"CODE",{});var Id=o(ot);Ol=r(Id,"max_length"),Id.forEach(n),Hl=r(Qn," oder "),dt=l(Qn,"CODE",{});var Dd=o(dt);Cl=r(Dd,"min_length"),Dd.forEach(n),Fl=r(Qn," als Argumente f\xFCr das Ergebnis angeben."),Qn.forEach(n),Di=p(e),k(qe.$$.fragment,e),qi=p(e),Oe=l(e,"P",{});var ir=o(Oe);Wl=r(ir,"Die bisher gezeigten Pipelines dienen haupts\xE4chlich zu Demonstrationszwecken. Sie wurden f\xFCr bestimmte Aufgabenstellungen programmiert und sind nicht f\xFCr Abwandlungen geeignet. Im n\xE4chsten Kapitel erf\xE4hrst du, was sich hinter einer "),ut=l(ir,"CODE",{});var qd=o(ut);Bl=r(qd,"pipeline()"),qd.forEach(n),Nl=r(ir,"-Funktion verbirgt und wie du ihr Verhalten anpassen kannst."),ir.forEach(n),this.h()},h(){f(h,"name","hf:doc:metadata"),f(h,"content",JSON.stringify(Xd)),f(v,"id","transformermodelle-wozu-sind-sie-imstande"),f(v,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(v,"href","#transformermodelle-wozu-sind-sie-imstande"),f(g,"class","relative group"),f(ae,"id","transformermodelle-sind-berall-anzutreffen"),f(ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(ae,"href","#transformermodelle-sind-berall-anzutreffen"),f(K,"class","relative group"),Wd(le.src,Vl="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/companies.PNG")||f(le,"src",Vl),f(le,"alt","Companies using Hugging Face"),f(le,"width","100%"),f(Be,"href","https://github.com/huggingface/transformers"),f(Be,"rel","nofollow"),f(Ne,"href","https://huggingface.co/models"),f(Ne,"rel","nofollow"),f(de,"id","mit-pipelines-arbeiten"),f(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(de,"href","#mit-pipelines-arbeiten"),f(Z,"class","relative group"),f(Ue,"href","https://huggingface.co/transformers/main_classes/pipelines.html"),f(Ue,"rel","nofollow"),f(fe,"id","zeroshotklassifizierung"),f(fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(fe,"href","#zeroshotklassifizierung"),f(U,"class","relative group"),f(we,"id","textgenerierung"),f(we,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(we,"href","#textgenerierung"),f(J,"class","relative group"),f(ve,"id","verwendung-eines-beliebigen-modells-vom-hub-in-einer-pipeline"),f(ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(ve,"href","#verwendung-eines-beliebigen-modells-vom-hub-in-einer-pipeline"),f(Q,"class","relative group"),f(tn,"href","https://huggingface.co/models"),f(tn,"rel","nofollow"),f(rn,"href","https://huggingface.co/models?pipeline_tag=text-generation"),f(rn,"rel","nofollow"),f(an,"href","https://huggingface.co/distilgpt2"),f(an,"rel","nofollow"),f(xe,"id","die-inference-api"),f(xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(xe,"href","#die-inference-api"),f(Y,"class","relative group"),f(un,"href","https://huggingface.co/"),f(un,"rel","nofollow"),f(pn,"href","https://huggingface.co/pricing"),f(pn,"rel","nofollow"),f(ye,"id","mask-filling"),f(ye,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(ye,"href","#mask-filling"),f(X,"class","relative group"),f(Me,"id","named-entity-recognition"),f(Me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(Me,"href","#named-entity-recognition"),f(ee,"class","relative group"),f(Te,"id","frageantwortsysteme-question-answering"),f(Te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(Te,"href","#frageantwortsysteme-question-answering"),f(ne,"class","relative group"),f(Ie,"id","automatische-textzusammenfassung"),f(Ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(Ie,"href","#automatische-textzusammenfassung"),f(se,"class","relative group"),f(De,"id","maschinelle-bersetzung"),f(De,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(De,"href","#maschinelle-bersetzung"),f(te,"class","relative group"),f(zn,"href","https://huggingface.co/models"),f(zn,"rel","nofollow")},m(e,t){s(document.head,h),d(e,b,t),d(e,g,t),s(g,v),s(v,m),_(c,m,null),s(g,w),s(g,j),s(j,S),d(e,y,t),_(P,e,t),d(e,D,t),d(e,M,t),s(M,Tn),s(M,ie),s(ie,Sn),s(M,rr),d(e,mt,t),_(re,e,t),d(e,wt,t),d(e,K,t),s(K,ae),s(ae,Yn),_(We,Yn,null),s(K,ar),s(K,Xn),s(Xn,lr),d(e,bt,t),d(e,In,t),s(In,or),d(e,vt,t),d(e,le,t),d(e,$t,t),d(e,B,t),s(B,dr),s(B,Be),s(Be,ur),s(B,pr),s(B,Ne),s(Ne,hr),s(B,fr),d(e,kt,t),_(oe,e,t),d(e,_t,t),d(e,Dn,t),s(Dn,cr),d(e,xt,t),d(e,Z,t),s(Z,de),s(de,es),_(Le,es,null),s(Z,gr),s(Z,ns),s(ns,mr),d(e,Et,t),_(Re,e,t),d(e,zt,t),d(e,ue,t),s(ue,wr),s(ue,ss),s(ss,br),s(ue,vr),d(e,yt,t),_(Ve,e,t),d(e,jt,t),_(Ge,e,t),d(e,Pt,t),d(e,qn,t),s(qn,$r),d(e,Mt,t),_(Ke,e,t),d(e,At,t),_(Ze,e,t),d(e,Tt,t),d(e,pe,t),s(pe,kr),s(pe,ts),s(ts,_r),s(pe,xr),d(e,St,t),d(e,On,t),s(On,Er),d(e,It,t),d(e,N,t),s(N,is),s(is,zr),s(N,yr),s(N,rs),s(rs,jr),s(N,Pr),s(N,as),s(as,Mr),d(e,Dt,t),d(e,he,t),s(he,Ar),s(he,Ue),s(Ue,Tr),s(he,Sr),d(e,qt,t),d(e,A,t),s(A,Hn),s(Hn,ls),s(ls,Ir),s(Hn,Dr),s(A,qr),s(A,os),s(os,ds),s(ds,Or),s(A,Hr),s(A,Cn),s(Cn,us),s(us,Cr),s(Cn,Fr),s(A,Wr),s(A,ps),s(ps,hs),s(hs,Br),s(A,Nr),s(A,fs),s(fs,cs),s(cs,Lr),s(A,Rr),s(A,gs),s(gs,ms),s(ms,Vr),s(A,Gr),s(A,ws),s(ws,bs),s(bs,Kr),s(A,Zr),s(A,vs),s(vs,$s),s($s,Ur),s(A,Jr),s(A,ks),s(ks,_s),s(_s,Qr),d(e,Ot,t),d(e,Fn,t),s(Fn,Yr),d(e,Ht,t),d(e,U,t),s(U,fe),s(fe,xs),_(Je,xs,null),s(U,Xr),s(U,Es),s(Es,ea),d(e,Ct,t),d(e,ce,t),s(ce,na),s(ce,zs),s(zs,sa),s(ce,ta),d(e,Ft,t),_(Qe,e,t),d(e,Wt,t),_(Ye,e,t),d(e,Bt,t),d(e,ge,t),s(ge,ia),s(ge,ys),s(ys,ra),s(ge,aa),d(e,Nt,t),_(me,e,t),d(e,Lt,t),d(e,J,t),s(J,we),s(we,js),_(Xe,js,null),s(J,la),s(J,Ps),s(Ps,oa),d(e,Rt,t),d(e,Wn,t),s(Wn,da),d(e,Vt,t),_(en,e,t),d(e,Gt,t),_(nn,e,t),d(e,Kt,t),d(e,L,t),s(L,ua),s(L,Ms),s(Ms,pa),s(L,ha),s(L,As),s(As,fa),s(L,ca),d(e,Zt,t),_(be,e,t),d(e,Ut,t),d(e,Q,t),s(Q,ve),s(ve,Ts),_(sn,Ts,null),s(Q,ga),s(Q,Ss),s(Ss,ma),d(e,Jt,t),d(e,C,t),s(C,wa),s(C,tn),s(tn,ba),s(C,va),s(C,Is),s(Is,$a),s(C,ka),s(C,rn),s(rn,_a),s(C,xa),d(e,Qt,t),d(e,$e,t),s($e,Ea),s($e,an),s(an,Ds),s(Ds,za),s($e,ya),d(e,Yt,t),_(ln,e,t),d(e,Xt,t),_(on,e,t),d(e,ei,t),d(e,ke,t),s(ke,ja),s(ke,qs),s(qs,Pa),s(ke,Ma),d(e,ni,t),d(e,Bn,t),s(Bn,Aa),d(e,si,t),_(_e,e,t),d(e,ti,t),d(e,Y,t),s(Y,xe),s(xe,Os),_(dn,Os,null),s(Y,Ta),s(Y,Hs),s(Hs,Sa),d(e,ii,t),d(e,Ee,t),s(Ee,Ia),s(Ee,un),s(un,Da),s(Ee,qa),d(e,ri,t),d(e,ze,t),s(ze,Oa),s(ze,pn),s(pn,Ha),s(ze,Ca),d(e,ai,t),d(e,X,t),s(X,ye),s(ye,Cs),_(hn,Cs,null),s(X,Fa),s(X,Fs),s(Fs,Wa),d(e,li,t),d(e,je,t),s(je,Ba),s(je,Ws),s(Ws,Na),s(je,La),d(e,oi,t),_(fn,e,t),d(e,di,t),_(cn,e,t),d(e,ui,t),d(e,F,t),s(F,Ra),s(F,Bs),s(Bs,Va),s(F,Ga),s(F,Ns),s(Ns,Ka),s(F,Za),s(F,Ls),s(Ls,Ua),s(F,Ja),d(e,pi,t),_(Pe,e,t),d(e,hi,t),d(e,ee,t),s(ee,Me),s(Me,Rs),_(gn,Rs,null),s(ee,Qa),s(ee,Vs),s(Vs,Ya),d(e,fi,t),d(e,Nn,t),s(Nn,Xa),d(e,ci,t),_(mn,e,t),d(e,gi,t),_(wn,e,t),d(e,mi,t),d(e,Ln,t),s(Ln,el),d(e,wi,t),d(e,q,t),s(q,nl),s(q,Gs),s(Gs,sl),s(q,tl),s(q,Ks),s(Ks,il),s(q,rl),s(q,Zs),s(Zs,al),s(q,ll),s(q,Us),s(Us,ol),s(q,dl),s(q,Js),s(Js,ul),s(q,pl),s(q,Qs),s(Qs,hl),s(q,fl),d(e,bi,t),_(Ae,e,t),d(e,vi,t),d(e,ne,t),s(ne,Te),s(Te,Ys),_(bn,Ys,null),s(ne,cl),s(ne,Xs),s(Xs,gl),d(e,$i,t),d(e,Se,t),s(Se,ml),s(Se,et),s(et,wl),s(Se,bl),d(e,ki,t),_(vn,e,t),d(e,_i,t),_($n,e,t),d(e,xi,t),d(e,Rn,t),s(Rn,vl),d(e,Ei,t),d(e,se,t),s(se,Ie),s(Ie,nt),_(kn,nt,null),s(se,$l),s(se,st),s(st,kl),d(e,zi,t),d(e,Vn,t),s(Vn,_l),d(e,yi,t),_(_n,e,t),d(e,ji,t),_(xn,e,t),d(e,Pi,t),d(e,R,t),s(R,xl),s(R,tt),s(tt,El),s(R,zl),s(R,it),s(it,yl),s(R,jl),d(e,Mi,t),d(e,te,t),s(te,De),s(De,rt),_(En,rt,null),s(te,Pl),s(te,at),s(at,Ml),d(e,Ai,t),d(e,V,t),s(V,Al),s(V,lt),s(lt,Tl),s(V,Sl),s(V,zn),s(zn,Il),s(V,Dl),d(e,Ti,t),_(yn,e,t),d(e,Si,t),_(jn,e,t),d(e,Ii,t),d(e,G,t),s(G,ql),s(G,ot),s(ot,Ol),s(G,Hl),s(G,dt),s(dt,Cl),s(G,Fl),d(e,Di,t),_(qe,e,t),d(e,qi,t),d(e,Oe,t),s(Oe,Wl),s(Oe,ut),s(ut,Bl),s(Oe,Nl),Oi=!0},p(e,[t]){const Pn={};t&2&&(Pn.$$scope={dirty:t,ctx:e}),re.$set(Pn);const pt={};t&2&&(pt.$$scope={dirty:t,ctx:e}),oe.$set(pt);const ht={};t&2&&(ht.$$scope={dirty:t,ctx:e}),me.$set(ht);const ft={};t&2&&(ft.$$scope={dirty:t,ctx:e}),be.$set(ft);const Mn={};t&2&&(Mn.$$scope={dirty:t,ctx:e}),_e.$set(Mn);const ct={};t&2&&(ct.$$scope={dirty:t,ctx:e}),Pe.$set(ct);const An={};t&2&&(An.$$scope={dirty:t,ctx:e}),Ae.$set(An);const gt={};t&2&&(gt.$$scope={dirty:t,ctx:e}),qe.$set(gt)},i(e){Oi||(x(c.$$.fragment,e),x(P.$$.fragment,e),x(re.$$.fragment,e),x(We.$$.fragment,e),x(oe.$$.fragment,e),x(Le.$$.fragment,e),x(Re.$$.fragment,e),x(Ve.$$.fragment,e),x(Ge.$$.fragment,e),x(Ke.$$.fragment,e),x(Ze.$$.fragment,e),x(Je.$$.fragment,e),x(Qe.$$.fragment,e),x(Ye.$$.fragment,e),x(me.$$.fragment,e),x(Xe.$$.fragment,e),x(en.$$.fragment,e),x(nn.$$.fragment,e),x(be.$$.fragment,e),x(sn.$$.fragment,e),x(ln.$$.fragment,e),x(on.$$.fragment,e),x(_e.$$.fragment,e),x(dn.$$.fragment,e),x(hn.$$.fragment,e),x(fn.$$.fragment,e),x(cn.$$.fragment,e),x(Pe.$$.fragment,e),x(gn.$$.fragment,e),x(mn.$$.fragment,e),x(wn.$$.fragment,e),x(Ae.$$.fragment,e),x(bn.$$.fragment,e),x(vn.$$.fragment,e),x($n.$$.fragment,e),x(kn.$$.fragment,e),x(_n.$$.fragment,e),x(xn.$$.fragment,e),x(En.$$.fragment,e),x(yn.$$.fragment,e),x(jn.$$.fragment,e),x(qe.$$.fragment,e),Oi=!0)},o(e){E(c.$$.fragment,e),E(P.$$.fragment,e),E(re.$$.fragment,e),E(We.$$.fragment,e),E(oe.$$.fragment,e),E(Le.$$.fragment,e),E(Re.$$.fragment,e),E(Ve.$$.fragment,e),E(Ge.$$.fragment,e),E(Ke.$$.fragment,e),E(Ze.$$.fragment,e),E(Je.$$.fragment,e),E(Qe.$$.fragment,e),E(Ye.$$.fragment,e),E(me.$$.fragment,e),E(Xe.$$.fragment,e),E(en.$$.fragment,e),E(nn.$$.fragment,e),E(be.$$.fragment,e),E(sn.$$.fragment,e),E(ln.$$.fragment,e),E(on.$$.fragment,e),E(_e.$$.fragment,e),E(dn.$$.fragment,e),E(hn.$$.fragment,e),E(fn.$$.fragment,e),E(cn.$$.fragment,e),E(Pe.$$.fragment,e),E(gn.$$.fragment,e),E(mn.$$.fragment,e),E(wn.$$.fragment,e),E(Ae.$$.fragment,e),E(bn.$$.fragment,e),E(vn.$$.fragment,e),E($n.$$.fragment,e),E(kn.$$.fragment,e),E(_n.$$.fragment,e),E(xn.$$.fragment,e),E(En.$$.fragment,e),E(yn.$$.fragment,e),E(jn.$$.fragment,e),E(qe.$$.fragment,e),Oi=!1},d(e){n(h),e&&n(b),e&&n(g),z(c),e&&n(y),z(P,e),e&&n(D),e&&n(M),e&&n(mt),z(re,e),e&&n(wt),e&&n(K),z(We),e&&n(bt),e&&n(In),e&&n(vt),e&&n(le),e&&n($t),e&&n(B),e&&n(kt),z(oe,e),e&&n(_t),e&&n(Dn),e&&n(xt),e&&n(Z),z(Le),e&&n(Et),z(Re,e),e&&n(zt),e&&n(ue),e&&n(yt),z(Ve,e),e&&n(jt),z(Ge,e),e&&n(Pt),e&&n(qn),e&&n(Mt),z(Ke,e),e&&n(At),z(Ze,e),e&&n(Tt),e&&n(pe),e&&n(St),e&&n(On),e&&n(It),e&&n(N),e&&n(Dt),e&&n(he),e&&n(qt),e&&n(A),e&&n(Ot),e&&n(Fn),e&&n(Ht),e&&n(U),z(Je),e&&n(Ct),e&&n(ce),e&&n(Ft),z(Qe,e),e&&n(Wt),z(Ye,e),e&&n(Bt),e&&n(ge),e&&n(Nt),z(me,e),e&&n(Lt),e&&n(J),z(Xe),e&&n(Rt),e&&n(Wn),e&&n(Vt),z(en,e),e&&n(Gt),z(nn,e),e&&n(Kt),e&&n(L),e&&n(Zt),z(be,e),e&&n(Ut),e&&n(Q),z(sn),e&&n(Jt),e&&n(C),e&&n(Qt),e&&n($e),e&&n(Yt),z(ln,e),e&&n(Xt),z(on,e),e&&n(ei),e&&n(ke),e&&n(ni),e&&n(Bn),e&&n(si),z(_e,e),e&&n(ti),e&&n(Y),z(dn),e&&n(ii),e&&n(Ee),e&&n(ri),e&&n(ze),e&&n(ai),e&&n(X),z(hn),e&&n(li),e&&n(je),e&&n(oi),z(fn,e),e&&n(di),z(cn,e),e&&n(ui),e&&n(F),e&&n(pi),z(Pe,e),e&&n(hi),e&&n(ee),z(gn),e&&n(fi),e&&n(Nn),e&&n(ci),z(mn,e),e&&n(gi),z(wn,e),e&&n(mi),e&&n(Ln),e&&n(wi),e&&n(q),e&&n(bi),z(Ae,e),e&&n(vi),e&&n(ne),z(bn),e&&n($i),e&&n(Se),e&&n(ki),z(vn,e),e&&n(_i),z($n,e),e&&n(xi),e&&n(Rn),e&&n(Ei),e&&n(se),z(kn),e&&n(zi),e&&n(Vn),e&&n(yi),z(_n,e),e&&n(ji),z(xn,e),e&&n(Pi),e&&n(R),e&&n(Mi),e&&n(te),z(En),e&&n(Ai),e&&n(V),e&&n(Ti),z(yn,e),e&&n(Si),z(jn,e),e&&n(Ii),e&&n(G),e&&n(Di),z(qe,e),e&&n(qi),e&&n(Oe)}}}const Xd={local:"transformermodelle-wozu-sind-sie-imstande",sections:[{local:"transformermodelle-sind-berall-anzutreffen",title:"Transformer-Modelle sind \xFCberall anzutreffen!"},{local:"mit-pipelines-arbeiten",title:"Mit Pipelines arbeiten"},{local:"zeroshotklassifizierung",title:"Zero-Shot-Klassifizierung"},{local:"textgenerierung",title:"Textgenerierung"},{local:"verwendung-eines-beliebigen-modells-vom-hub-in-einer-pipeline",sections:[{local:"die-inference-api",title:"Die Inference API"}],title:"Verwendung eines beliebigen Modells vom Hub in einer Pipeline"},{local:"mask-filling",title:"Mask Filling"},{local:"named-entity-recognition",title:"Named Entity Recognition"},{local:"frageantwortsysteme-question-answering",title:"Frage-Antwort-Systeme (Question Answering)"},{local:"automatische-textzusammenfassung",title:"Automatische Textzusammenfassung"},{local:"maschinelle-bersetzung",title:"Maschinelle \xDCbersetzung"}],title:"Transformer-Modelle - wozu sind sie imstande?"};function eu(I){return Bd(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ou extends Od{constructor(h){super();Hd(this,h,eu,Yd,Cd,{})}}export{ou as default,Xd as metadata};
