import{S as Ut,i as Jt,s as Xt,e as i,k as d,w as h,t as w,M as Yt,c as s,d as n,m as u,x as f,a,h as $,b as l,G as t,g as o,y as p,L as er,q as c,o as m,B as g,v as nr}from"../../chunks/vendor-hf-doc-builder.js";import{I as v}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as ut}from"../../chunks/CodeBlock-hf-doc-builder.js";import{C as tr}from"../../chunks/CourseFloatingBanner-hf-doc-builder.js";import{Q as b}from"../../chunks/Question-hf-doc-builder.js";import"../../chunks/DocNotebookDropdown-hf-doc-builder.js";function rr(ht){let k,Ve,V,Oe,z,W,ze,O,Bn,xe,Gn,Ze,be,Kn,Qe,ke,In,Ue,x,N,Ee,Z,Ln,Q,Cn,_e,jn,Hn,Je,U,Xe,E,B,Me,J,Rn,Ae,Fn,Ye,X,en,Y,nn,_,G,Se,ee,Vn,ye,On,tn,ne,rn,te,sn,M,K,Pe,re,Zn,qe,Qn,an,ie,ln,se,on,A,I,Te,ae,Un,De,Jn,dn,le,un,S,L,We,oe,Xn,Ne,Yn,hn,de,fn,y,C,Be,ue,et,Ge,nt,pn,he,cn,P,j,Ke,fe,tt,Ie,rt,mn,pe,gn,q,H,Le,ce,it,Ce,st,wn,me,$n,T,R,je,ge,at,He,lt,vn,we,bn,D,F,Re,$e,ot,Fe,dt,kn,ve,zn;return V=new tr({props:{chapter:1,classNames:"absolute z-10 right-0 top-0"}}),O=new v({}),Z=new v({}),U=new b({props:{choices:[{text:"Summarization (Textzusammenfassung)",explain:'Sieh nochmal auf der Seite des Modells<a href="https://huggingface.co/roberta-large-mnli">roberta-large-mnli</a> nach.'},{text:"Text Classification (Textklassifizierung)",explain:"Genauer gesagt, wird klassifiziert, ob zwei S\xE4tze hinsichtlich dreier Labels (Widerspruch (engl. Contradiction), Neutral, Konsequenz (engl. Entailment)) logisch miteinander verbunden sind - eine Aufgabe, die auch als <em>Natural Language Inference</em> bezeichnet wird.",correct:!0},{text:"Text Generation (Textgenerierung)",explain:'Sieh nochmal auf der Seite des Modells <a href="https://huggingface.co/roberta-large-mnli">roberta-large-mnli</a> nach.'}]}}),J=new v({}),X=new ut({props:{code:`from transformers import pipeline

ner = pipeline("ner", grouped_entities=True)
ner("My name is Sylvain and I work at Hugging Face in Brooklyn.")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

ner = pipeline(<span class="hljs-string">&quot;ner&quot;</span>, grouped_entities=<span class="hljs-literal">True</span>)
ner(<span class="hljs-string">&quot;My name is Sylvain and I work at Hugging Face in Brooklyn.&quot;</span>)`}}),Y=new b({props:{choices:[{text:'Er gibt die Ergebnisse der Klassifizierung f\xFCr diesen Satz f\xFCr die Labels "positive" oder "negative" zur\xFCck.',explain:"Das ist nicht richtig - daf\xFCr m\xFCsstest du eine <code>sentiment-analysis</code>-Pipeline verwenden."},{text:"Er wird einen generierten Text zur\xFCckgeben, der diesen Satz vervollst\xE4ndigt.",explain:"Das ist nicht richtig - daf\xFCr m\xFCsstest du eine <code>text-generation</code>-Pipeline verwenden."},{text:"Er gibt Begriffe zur\xFCck, die f\xFCr Personen, Organisationen oder Orte stehen.",explain:'Au\xDFerdem werden mit <code>grouped_entities=True</code> die W\xF6rter, die zur selben Entit\xE4t geh\xF6ren, gruppiert, wie z. B. "Hugging Face".',correct:!0}]}}),ee=new v({}),ne=new ut({props:{code:`from transformers import pipeline

filler = pipeline("fill-mask", model="bert-base-cased")
result = filler("...")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

filler = pipeline(<span class="hljs-string">&quot;fill-mask&quot;</span>, model=<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
result = filler(<span class="hljs-string">&quot;...&quot;</span>)`}}),te=new b({props:{choices:[{text:"This &#60;mask> has been waiting for you.",explain:"Das stimmt nicht. Schau dir die <code>bert-base-cased</code>-\xDCbersichtsseite des Modells an und versuche, deinen Fehler zu entdecken."},{text:"This [MASK] has been waiting for you.",explain:"Richtig! Der Mask Token dieses Modells ist [MASK].",correct:!0},{text:"This man has been waiting for you.",explain:"Leider falsch. Diese Pipeline f\xFCllt maskierte W\xF6rter auf, also braucht sie irgendwo einen Mask Token."}]}}),re=new v({}),ie=new ut({props:{code:`from transformers import pipeline

classifier = pipeline("zero-shot-classification")
result = classifier("This is a course about the Transformers library")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

classifier = pipeline(<span class="hljs-string">&quot;zero-shot-classification&quot;</span>)
result = classifier(<span class="hljs-string">&quot;This is a course about the Transformers library&quot;</span>)`}}),se=new b({props:{choices:[{text:"Diese Pipeline erfordert, dass Labels angegeben werden, damit der Text klassifiziert werden kann.",explain:"Richtig \u2014 der korrekte Code muss <code>candidate_labels=[...]</code> enthalten.",correct:!0},{text:"Diese Pipeline erfordert mehrere S\xE4tze, nicht nur einen.",explain:"Das ist falsch - obwohl diese Pipeline, wenn sie korrekt verwendet wird, eine Liste von S\xE4tzen verarbeiten kann (wie alle anderen Pipelines)."},{text:"Die \u{1F917} Transformers-Bibliothek funktioniert wie immer nicht.",explain:"Zu dieser Antwort er\xFCbrigt sich jeder Kommentar!"},{text:"Diese Pipeline erfordert l\xE4ngere Inputs; diese hier sind zu kurz.",explain:"Das ist falsch. \xDCbrigens wird ein sehr langer Text bei der Verarbeitung durch diese Pipeline gestutzt (engl. truncated) bzw. gek\xFCrzt."}]}}),ae=new v({}),le=new b({props:{choices:[{text:"\xDCbertragen des im Pretraining erlangten Wissens auf ein neues Modell, indem es auf demselben Datensatz trainiert wird.",explain:"Nein, das w\xE4ren dann zwei Versionen desselben Modells."},{text:"\xDCbertragen des im Pretraining erlangten Wissens auf ein neues Modell durch Initialisierung des zweiten Modells mit der Gewichtung des ersten Modells.",explain:"Richtig: Wenn das zweite Modell f\xFCr eine neue Aufgabe trainiert wird, *\xFCbertr\xE4gt* (engl. transfer) es das Wissen des ersten Modells.",correct:!0},{text:"\xDCbertragen des im Pretraining erlangten Wissens auf ein neues Modell, indem das zweite Modell mit der gleichen Architektur wie das erste Modell aufgebaut wird.",explain:"Die Architektur ist nur die Art und Weise, wie das Modell aufgebaut ist. Es wird in diesem Fall kein Wissen geteilt oder \xFCbertragen."}]}}),oe=new v({}),de=new b({props:{choices:[{text:"Richtig",explain:"Das Pretraining ist in der Regel <em>selbst\xFCberwacht</em> (engl. self-supervised), d. h. die Labels werden automatisch aus den Inputs erstellt (wie z. B. die Vorhersage des n\xE4chsten Wortes oder das Auff\xFCllen einiger maskierter W\xF6rter).",correct:!0},{text:"Falsch",explain:"Das ist nicht die richtige Antwort."}]}}),ue=new v({}),he=new b({props:{choices:[{text:"Wenn ein Modell ein Geb\xE4ude ist, ist seine Architektur der Bauplan und die Gewichte sind die Menschen, die darin leben.",explain:"In Anlehnung an diese Metapher w\xE4ren die Gewichte die Ziegel (und weitere Materialien), die zum Bau des Geb\xE4udes verwendet werden."},{text:"Eine Architektur ist eine Karte zum Aufbau eines Modells und ihre Gewichte sind die St\xE4dte, die auf der Karte dargestellt sind.",explain:"Das Problem bei dieser Metapher ist, dass eine Karte in der Regel nur eine Realit\xE4t abbildet (es gibt nur eine Stadt in Frankreich namens Paris). F\xFCr eine bestimmte Architektur sind jedoch verschiedene Gewichtungen m\xF6glich."},{text:"Eine Architektur ist eine Abfolge von mathematischen Funktionen zum Aufbau eines Modells und ihre Gewichte sind die Parameter dieser Funktionen.",explain:"Dieselben mathematischen Funktionen (Architektur) k\xF6nnen verwendet werden, um verschiedene Modelle zu erstellen, indem unterschiedliche Parameter (Gewichte) verwendet werden.",correct:!0}]}}),fe=new v({}),pe=new b({props:{choices:[{text:"Ein Encoder-Modell",explain:"Ein Encoder-Modell erzeugt eine Repr\xE4sentation f\xFCr den gesamten Satz. Diese ist f\xFCr Aufgaben wie die Klassifizierung besser geeignet."},{text:"Ein Decoder-Modell",explain:"Decoder-Modelle eignen sich perfekt f\xFCr die Generierung von Text auf Basis eines Prompts bzw. Input-Textes.",correct:!0},{text:"Ein Sequence-to-Sequence-Modell",explain:"Sequence-to-Sequence-Modelle eignen sich besser f\xFCr Aufgaben, bei denen du S\xE4tze generieren m\xF6chtest, die jeweils einen Bezug zu den Input-S\xE4tzen haben, und nicht auf einen bestimmten Prompt zur\xFCckzuf\xFChren sind."}]}}),ce=new v({}),me=new b({props:{choices:[{text:"Ein Encoder-Modell",explain:"Ein Encoder-Modell erzeugt eine Repr\xE4sentation f\xFCr den gesamten Satz. Diese ist f\xFCr Aufgaben wie die Klassifizierung besser geeignet."},{text:"Ein Decoder-Modell",explain:"Decoder-Modelle sind gut f\xFCr die Erstellung von Text-Outputs (wie Zusammenfassungen), aber sie haben nicht die F\xE4higkeit, einen Gesamtkontext wie den kompletten Text f\xFCr die Zusammenfassung zu nutzen."},{text:"Ein Sequence-to-Sequence-Modell",explain:"Sequence-to-Sequence-Modelle eignen sich perfekt f\xFCr eine Textzusammenfassungsaufgabe.",correct:!0}]}}),ge=new v({}),we=new b({props:{choices:[{text:"Ein Encoder-Modell",explain:"Ein Encoder-Modell erzeugt eine Repr\xE4sentation f\xFCr den gesamten Satz. Diese eignet sich perfekt f\xFCr eine Aufgabe wie die Klassifizierung.",correct:!0},{text:"Ein Decoder-Modell",explain:"Decoder-Modelle eignen sich f\xFCr die Generierung von Output-Texten, aber nicht daf\xFCr, ein Label f\xFCr einen bestimmten Satz zu ermitteln."},{text:"Ein Sequence-to-Sequence-Modell",explain:"Sequence-to-Sequence-Modelle eignen sich besser f\xFCr Aufgaben, bei denen du Text auf der Grundlage eines vorgegebenen Satzes und nicht eines Labels generieren m\xF6chtest."}]}}),$e=new v({}),ve=new b({props:{choices:[{text:"Das Modell ist eine feingetunte Version eines vortrainierten Modells, das den Bias aus dem Pretraining \xFCbernommen hat.",explain:"Bei der Anwendung von Transfer Learning wird ein Bias, der dem vortrainierten Modell zugrunde lag, auch beim feingetunten Modell durchsickern.",correct:!0},{text:"Die Daten, mit denen das Modell trainiert wurde, spiegeln Voreingenommenheiten wider bzw. sind mit einem Bias versehen.",explain:"Dies ist die offensichtlichste Ursache f\xFCr eine Voreingenommenheit (Bias), aber nicht die einzige.",correct:!0},{text:"Das Ma\xDF, auf dessen Grundlage das Modell optimiert wurde, f\xFChrt zu einem Bias.",explain:"Eine weniger offensichtliche Ursache f\xFCr Voreingenommenheiten (Bias) ist die Art und Weise, wie das Modell trainiert wird. Bspw. wenn du dein Modell einfach blindlings in Bezug auf das von dir gew\xE4hlte Ma\xDF optimierst.",correct:!0}]}}),{c(){k=i("meta"),Ve=d(),h(V.$$.fragment),Oe=d(),z=i("h1"),W=i("a"),ze=i("span"),h(O.$$.fragment),Bn=d(),xe=i("span"),Gn=w("Quiz am Ende des Kapitels"),Ze=d(),be=i("p"),Kn=w("In diesem Kapitel hast du viel gelernt! Mach dir keine Sorgen, wenn du noch nicht alle Einzelheiten verstanden hast. In den n\xE4chsten Kapiteln wirst du mehr dar\xFCber erfahren, wie die Dinge im Einzelnen funktionieren."),Qe=d(),ke=i("p"),In=w("Doch zuerst wollen wir noch testen, was du in diesem Kapitel gelernt hast!"),Ue=d(),x=i("h3"),N=i("a"),Ee=i("span"),h(Z.$$.fragment),Ln=d(),Q=i("span"),Cn=w("1. Erkunde den Hub und suche nach dem Checkpoint "),_e=i("code"),jn=w("roberta-large-mnli"),Hn=w(". Welche Aufgabe unterst\xFCtzt er?"),Je=d(),h(U.$$.fragment),Xe=d(),E=i("h3"),B=i("a"),Me=i("span"),h(J.$$.fragment),Rn=d(),Ae=i("span"),Fn=w("2. Was gibt der folgende Code zur\xFCck?"),Ye=d(),h(X.$$.fragment),en=d(),h(Y.$$.fragment),nn=d(),_=i("h3"),G=i("a"),Se=i("span"),h(ee.$$.fragment),Vn=d(),ye=i("span"),On=w("3. Wodurch m\xFCsste \u2026 in diesem Codebeispiel ersetzt werden?"),tn=d(),h(ne.$$.fragment),rn=d(),h(te.$$.fragment),sn=d(),M=i("h3"),K=i("a"),Pe=i("span"),h(re.$$.fragment),Zn=d(),qe=i("span"),Qn=w("4. Warum wird dieser Code nicht funktionieren?"),an=d(),h(ie.$$.fragment),ln=d(),h(se.$$.fragment),on=d(),A=i("h3"),I=i("a"),Te=i("span"),h(ae.$$.fragment),Un=d(),De=i("span"),Jn=w("5. Was bedeutet der Begriff \u201CTransfer Learning\u201D?"),dn=d(),h(le.$$.fragment),un=d(),S=i("h3"),L=i("a"),We=i("span"),h(oe.$$.fragment),Xn=d(),Ne=i("span"),Yn=w("6. Richtig oder falsch? Ein Sprachmodell ben\xF6tigt im Rahmen des Pretraining in der Regel keine Labels."),hn=d(),h(de.$$.fragment),fn=d(),y=i("h3"),C=i("a"),Be=i("span"),h(ue.$$.fragment),et=d(),Ge=i("span"),nt=w("7. W\xE4hle den Satz aus, der die Begriffe \u201CModell\u201D, \u201CArchitektur\u201D und \u201CGewichte\u201D bzw. \u201CGewichtung\u201D am besten beschreibt."),pn=d(),h(he.$$.fragment),cn=d(),P=i("h3"),j=i("a"),Ke=i("span"),h(fe.$$.fragment),tt=d(),Ie=i("span"),rt=w("8. Welche dieser Modelle w\xFCrdest du nutzen, um einen Prompt bzw. Text-Input durch einen generierten Text vervollst\xE4ndigen zu lassen?"),mn=d(),h(pe.$$.fragment),gn=d(),q=i("h3"),H=i("a"),Le=i("span"),h(ce.$$.fragment),it=d(),Ce=i("span"),st=w("9. Welche dieser Modelle w\xFCrdest du f\xFCr die Zusammenfassung von Texten verwenden?"),wn=d(),h(me.$$.fragment),$n=d(),T=i("h3"),R=i("a"),je=i("span"),h(ge.$$.fragment),at=d(),He=i("span"),lt=w("10. Welche Art von Modellen w\xFCrdest du verwenden, um Text-Inputs entsprechend bestimmter Labels zu klassifizieren?"),vn=d(),h(we.$$.fragment),bn=d(),D=i("h3"),F=i("a"),Re=i("span"),h($e.$$.fragment),ot=d(),Fe=i("span"),dt=w("11. Welche m\xF6gliche Ursache kann eine vom Modell zu beobachtende Voreingenommenheit (Bias) haben?"),kn=d(),h(ve.$$.fragment),this.h()},l(e){const r=Yt('[data-svelte="svelte-1phssyn"]',document.head);k=s(r,"META",{name:!0,content:!0}),r.forEach(n),Ve=u(e),f(V.$$.fragment,e),Oe=u(e),z=s(e,"H1",{class:!0});var xn=a(z);W=s(xn,"A",{id:!0,class:!0,href:!0});var ft=a(W);ze=s(ft,"SPAN",{});var pt=a(ze);f(O.$$.fragment,pt),pt.forEach(n),ft.forEach(n),Bn=u(xn),xe=s(xn,"SPAN",{});var ct=a(xe);Gn=$(ct,"Quiz am Ende des Kapitels"),ct.forEach(n),xn.forEach(n),Ze=u(e),be=s(e,"P",{});var mt=a(be);Kn=$(mt,"In diesem Kapitel hast du viel gelernt! Mach dir keine Sorgen, wenn du noch nicht alle Einzelheiten verstanden hast. In den n\xE4chsten Kapiteln wirst du mehr dar\xFCber erfahren, wie die Dinge im Einzelnen funktionieren."),mt.forEach(n),Qe=u(e),ke=s(e,"P",{});var gt=a(ke);In=$(gt,"Doch zuerst wollen wir noch testen, was du in diesem Kapitel gelernt hast!"),gt.forEach(n),Ue=u(e),x=s(e,"H3",{class:!0});var En=a(x);N=s(En,"A",{id:!0,class:!0,href:!0});var wt=a(N);Ee=s(wt,"SPAN",{});var $t=a(Ee);f(Z.$$.fragment,$t),$t.forEach(n),wt.forEach(n),Ln=u(En),Q=s(En,"SPAN",{});var _n=a(Q);Cn=$(_n,"1. Erkunde den Hub und suche nach dem Checkpoint "),_e=s(_n,"CODE",{});var vt=a(_e);jn=$(vt,"roberta-large-mnli"),vt.forEach(n),Hn=$(_n,". Welche Aufgabe unterst\xFCtzt er?"),_n.forEach(n),En.forEach(n),Je=u(e),f(U.$$.fragment,e),Xe=u(e),E=s(e,"H3",{class:!0});var Mn=a(E);B=s(Mn,"A",{id:!0,class:!0,href:!0});var bt=a(B);Me=s(bt,"SPAN",{});var kt=a(Me);f(J.$$.fragment,kt),kt.forEach(n),bt.forEach(n),Rn=u(Mn),Ae=s(Mn,"SPAN",{});var zt=a(Ae);Fn=$(zt,"2. Was gibt der folgende Code zur\xFCck?"),zt.forEach(n),Mn.forEach(n),Ye=u(e),f(X.$$.fragment,e),en=u(e),f(Y.$$.fragment,e),nn=u(e),_=s(e,"H3",{class:!0});var An=a(_);G=s(An,"A",{id:!0,class:!0,href:!0});var xt=a(G);Se=s(xt,"SPAN",{});var Et=a(Se);f(ee.$$.fragment,Et),Et.forEach(n),xt.forEach(n),Vn=u(An),ye=s(An,"SPAN",{});var _t=a(ye);On=$(_t,"3. Wodurch m\xFCsste \u2026 in diesem Codebeispiel ersetzt werden?"),_t.forEach(n),An.forEach(n),tn=u(e),f(ne.$$.fragment,e),rn=u(e),f(te.$$.fragment,e),sn=u(e),M=s(e,"H3",{class:!0});var Sn=a(M);K=s(Sn,"A",{id:!0,class:!0,href:!0});var Mt=a(K);Pe=s(Mt,"SPAN",{});var At=a(Pe);f(re.$$.fragment,At),At.forEach(n),Mt.forEach(n),Zn=u(Sn),qe=s(Sn,"SPAN",{});var St=a(qe);Qn=$(St,"4. Warum wird dieser Code nicht funktionieren?"),St.forEach(n),Sn.forEach(n),an=u(e),f(ie.$$.fragment,e),ln=u(e),f(se.$$.fragment,e),on=u(e),A=s(e,"H3",{class:!0});var yn=a(A);I=s(yn,"A",{id:!0,class:!0,href:!0});var yt=a(I);Te=s(yt,"SPAN",{});var Pt=a(Te);f(ae.$$.fragment,Pt),Pt.forEach(n),yt.forEach(n),Un=u(yn),De=s(yn,"SPAN",{});var qt=a(De);Jn=$(qt,"5. Was bedeutet der Begriff \u201CTransfer Learning\u201D?"),qt.forEach(n),yn.forEach(n),dn=u(e),f(le.$$.fragment,e),un=u(e),S=s(e,"H3",{class:!0});var Pn=a(S);L=s(Pn,"A",{id:!0,class:!0,href:!0});var Tt=a(L);We=s(Tt,"SPAN",{});var Dt=a(We);f(oe.$$.fragment,Dt),Dt.forEach(n),Tt.forEach(n),Xn=u(Pn),Ne=s(Pn,"SPAN",{});var Wt=a(Ne);Yn=$(Wt,"6. Richtig oder falsch? Ein Sprachmodell ben\xF6tigt im Rahmen des Pretraining in der Regel keine Labels."),Wt.forEach(n),Pn.forEach(n),hn=u(e),f(de.$$.fragment,e),fn=u(e),y=s(e,"H3",{class:!0});var qn=a(y);C=s(qn,"A",{id:!0,class:!0,href:!0});var Nt=a(C);Be=s(Nt,"SPAN",{});var Bt=a(Be);f(ue.$$.fragment,Bt),Bt.forEach(n),Nt.forEach(n),et=u(qn),Ge=s(qn,"SPAN",{});var Gt=a(Ge);nt=$(Gt,"7. W\xE4hle den Satz aus, der die Begriffe \u201CModell\u201D, \u201CArchitektur\u201D und \u201CGewichte\u201D bzw. \u201CGewichtung\u201D am besten beschreibt."),Gt.forEach(n),qn.forEach(n),pn=u(e),f(he.$$.fragment,e),cn=u(e),P=s(e,"H3",{class:!0});var Tn=a(P);j=s(Tn,"A",{id:!0,class:!0,href:!0});var Kt=a(j);Ke=s(Kt,"SPAN",{});var It=a(Ke);f(fe.$$.fragment,It),It.forEach(n),Kt.forEach(n),tt=u(Tn),Ie=s(Tn,"SPAN",{});var Lt=a(Ie);rt=$(Lt,"8. Welche dieser Modelle w\xFCrdest du nutzen, um einen Prompt bzw. Text-Input durch einen generierten Text vervollst\xE4ndigen zu lassen?"),Lt.forEach(n),Tn.forEach(n),mn=u(e),f(pe.$$.fragment,e),gn=u(e),q=s(e,"H3",{class:!0});var Dn=a(q);H=s(Dn,"A",{id:!0,class:!0,href:!0});var Ct=a(H);Le=s(Ct,"SPAN",{});var jt=a(Le);f(ce.$$.fragment,jt),jt.forEach(n),Ct.forEach(n),it=u(Dn),Ce=s(Dn,"SPAN",{});var Ht=a(Ce);st=$(Ht,"9. Welche dieser Modelle w\xFCrdest du f\xFCr die Zusammenfassung von Texten verwenden?"),Ht.forEach(n),Dn.forEach(n),wn=u(e),f(me.$$.fragment,e),$n=u(e),T=s(e,"H3",{class:!0});var Wn=a(T);R=s(Wn,"A",{id:!0,class:!0,href:!0});var Rt=a(R);je=s(Rt,"SPAN",{});var Ft=a(je);f(ge.$$.fragment,Ft),Ft.forEach(n),Rt.forEach(n),at=u(Wn),He=s(Wn,"SPAN",{});var Vt=a(He);lt=$(Vt,"10. Welche Art von Modellen w\xFCrdest du verwenden, um Text-Inputs entsprechend bestimmter Labels zu klassifizieren?"),Vt.forEach(n),Wn.forEach(n),vn=u(e),f(we.$$.fragment,e),bn=u(e),D=s(e,"H3",{class:!0});var Nn=a(D);F=s(Nn,"A",{id:!0,class:!0,href:!0});var Ot=a(F);Re=s(Ot,"SPAN",{});var Zt=a(Re);f($e.$$.fragment,Zt),Zt.forEach(n),Ot.forEach(n),ot=u(Nn),Fe=s(Nn,"SPAN",{});var Qt=a(Fe);dt=$(Qt,"11. Welche m\xF6gliche Ursache kann eine vom Modell zu beobachtende Voreingenommenheit (Bias) haben?"),Qt.forEach(n),Nn.forEach(n),kn=u(e),f(ve.$$.fragment,e),this.h()},h(){l(k,"name","hf:doc:metadata"),l(k,"content",JSON.stringify(ir)),l(W,"id","quiz-am-ende-des-kapitels"),l(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(W,"href","#quiz-am-ende-des-kapitels"),l(z,"class","relative group"),l(N,"id","1.-erkunde-den-hub-und-suche-nach-dem-checkpoint-<code>roberta-large-mnli</code>.-welche-aufgabe-unterst\xFCtzt-er?"),l(N,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(N,"href","#1.-erkunde-den-hub-und-suche-nach-dem-checkpoint-<code>roberta-large-mnli</code>.-welche-aufgabe-unterst\xFCtzt-er?"),l(x,"class","relative group"),l(B,"id","2.-was-gibt-der-folgende-code-zur\xFCck?"),l(B,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(B,"href","#2.-was-gibt-der-folgende-code-zur\xFCck?"),l(E,"class","relative group"),l(G,"id","3.-wodurch-m\xFCsste-\u2026-in-diesem-codebeispiel-ersetzt-werden?"),l(G,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(G,"href","#3.-wodurch-m\xFCsste-\u2026-in-diesem-codebeispiel-ersetzt-werden?"),l(_,"class","relative group"),l(K,"id","4.-warum-wird-dieser-code-nicht-funktionieren?"),l(K,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(K,"href","#4.-warum-wird-dieser-code-nicht-funktionieren?"),l(M,"class","relative group"),l(I,"id","5.-was-bedeutet-der-begriff-\u201Ctransfer-learning\u201D?"),l(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(I,"href","#5.-was-bedeutet-der-begriff-\u201Ctransfer-learning\u201D?"),l(A,"class","relative group"),l(L,"id","6.-richtig-oder-falsch?-ein-sprachmodell-ben\xF6tigt-im-rahmen-des-pretraining-in-der-regel-keine-labels."),l(L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(L,"href","#6.-richtig-oder-falsch?-ein-sprachmodell-ben\xF6tigt-im-rahmen-des-pretraining-in-der-regel-keine-labels."),l(S,"class","relative group"),l(C,"id","7.-w\xE4hle-den-satz-aus,-der-die-begriffe-\u201Cmodell\u201D,-\u201Carchitektur\u201D-und-\u201Cgewichte\u201D-bzw.-\u201Cgewichtung\u201D-am-besten-beschreibt."),l(C,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(C,"href","#7.-w\xE4hle-den-satz-aus,-der-die-begriffe-\u201Cmodell\u201D,-\u201Carchitektur\u201D-und-\u201Cgewichte\u201D-bzw.-\u201Cgewichtung\u201D-am-besten-beschreibt."),l(y,"class","relative group"),l(j,"id","8.-welche-dieser-modelle-w\xFCrdest-du-nutzen,-um-einen-prompt-bzw.-text-input-durch-einen-generierten-text-vervollst\xE4ndigen-zu-lassen?"),l(j,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(j,"href","#8.-welche-dieser-modelle-w\xFCrdest-du-nutzen,-um-einen-prompt-bzw.-text-input-durch-einen-generierten-text-vervollst\xE4ndigen-zu-lassen?"),l(P,"class","relative group"),l(H,"id","9.-welche-dieser-modelle-w\xFCrdest-du-f\xFCr-die-zusammenfassung-von-texten-verwenden?"),l(H,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(H,"href","#9.-welche-dieser-modelle-w\xFCrdest-du-f\xFCr-die-zusammenfassung-von-texten-verwenden?"),l(q,"class","relative group"),l(R,"id","10.-welche-art-von-modellen-w\xFCrdest-du-verwenden,-um-text-inputs-entsprechend-bestimmter-labels-zu-klassifizieren?"),l(R,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(R,"href","#10.-welche-art-von-modellen-w\xFCrdest-du-verwenden,-um-text-inputs-entsprechend-bestimmter-labels-zu-klassifizieren?"),l(T,"class","relative group"),l(F,"id","11.-welche-m\xF6gliche-ursache-kann-eine-vom-modell-zu-beobachtende-voreingenommenheit-(bias)-haben?"),l(F,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(F,"href","#11.-welche-m\xF6gliche-ursache-kann-eine-vom-modell-zu-beobachtende-voreingenommenheit-(bias)-haben?"),l(D,"class","relative group")},m(e,r){t(document.head,k),o(e,Ve,r),p(V,e,r),o(e,Oe,r),o(e,z,r),t(z,W),t(W,ze),p(O,ze,null),t(z,Bn),t(z,xe),t(xe,Gn),o(e,Ze,r),o(e,be,r),t(be,Kn),o(e,Qe,r),o(e,ke,r),t(ke,In),o(e,Ue,r),o(e,x,r),t(x,N),t(N,Ee),p(Z,Ee,null),t(x,Ln),t(x,Q),t(Q,Cn),t(Q,_e),t(_e,jn),t(Q,Hn),o(e,Je,r),p(U,e,r),o(e,Xe,r),o(e,E,r),t(E,B),t(B,Me),p(J,Me,null),t(E,Rn),t(E,Ae),t(Ae,Fn),o(e,Ye,r),p(X,e,r),o(e,en,r),p(Y,e,r),o(e,nn,r),o(e,_,r),t(_,G),t(G,Se),p(ee,Se,null),t(_,Vn),t(_,ye),t(ye,On),o(e,tn,r),p(ne,e,r),o(e,rn,r),p(te,e,r),o(e,sn,r),o(e,M,r),t(M,K),t(K,Pe),p(re,Pe,null),t(M,Zn),t(M,qe),t(qe,Qn),o(e,an,r),p(ie,e,r),o(e,ln,r),p(se,e,r),o(e,on,r),o(e,A,r),t(A,I),t(I,Te),p(ae,Te,null),t(A,Un),t(A,De),t(De,Jn),o(e,dn,r),p(le,e,r),o(e,un,r),o(e,S,r),t(S,L),t(L,We),p(oe,We,null),t(S,Xn),t(S,Ne),t(Ne,Yn),o(e,hn,r),p(de,e,r),o(e,fn,r),o(e,y,r),t(y,C),t(C,Be),p(ue,Be,null),t(y,et),t(y,Ge),t(Ge,nt),o(e,pn,r),p(he,e,r),o(e,cn,r),o(e,P,r),t(P,j),t(j,Ke),p(fe,Ke,null),t(P,tt),t(P,Ie),t(Ie,rt),o(e,mn,r),p(pe,e,r),o(e,gn,r),o(e,q,r),t(q,H),t(H,Le),p(ce,Le,null),t(q,it),t(q,Ce),t(Ce,st),o(e,wn,r),p(me,e,r),o(e,$n,r),o(e,T,r),t(T,R),t(R,je),p(ge,je,null),t(T,at),t(T,He),t(He,lt),o(e,vn,r),p(we,e,r),o(e,bn,r),o(e,D,r),t(D,F),t(F,Re),p($e,Re,null),t(D,ot),t(D,Fe),t(Fe,dt),o(e,kn,r),p(ve,e,r),zn=!0},p:er,i(e){zn||(c(V.$$.fragment,e),c(O.$$.fragment,e),c(Z.$$.fragment,e),c(U.$$.fragment,e),c(J.$$.fragment,e),c(X.$$.fragment,e),c(Y.$$.fragment,e),c(ee.$$.fragment,e),c(ne.$$.fragment,e),c(te.$$.fragment,e),c(re.$$.fragment,e),c(ie.$$.fragment,e),c(se.$$.fragment,e),c(ae.$$.fragment,e),c(le.$$.fragment,e),c(oe.$$.fragment,e),c(de.$$.fragment,e),c(ue.$$.fragment,e),c(he.$$.fragment,e),c(fe.$$.fragment,e),c(pe.$$.fragment,e),c(ce.$$.fragment,e),c(me.$$.fragment,e),c(ge.$$.fragment,e),c(we.$$.fragment,e),c($e.$$.fragment,e),c(ve.$$.fragment,e),zn=!0)},o(e){m(V.$$.fragment,e),m(O.$$.fragment,e),m(Z.$$.fragment,e),m(U.$$.fragment,e),m(J.$$.fragment,e),m(X.$$.fragment,e),m(Y.$$.fragment,e),m(ee.$$.fragment,e),m(ne.$$.fragment,e),m(te.$$.fragment,e),m(re.$$.fragment,e),m(ie.$$.fragment,e),m(se.$$.fragment,e),m(ae.$$.fragment,e),m(le.$$.fragment,e),m(oe.$$.fragment,e),m(de.$$.fragment,e),m(ue.$$.fragment,e),m(he.$$.fragment,e),m(fe.$$.fragment,e),m(pe.$$.fragment,e),m(ce.$$.fragment,e),m(me.$$.fragment,e),m(ge.$$.fragment,e),m(we.$$.fragment,e),m($e.$$.fragment,e),m(ve.$$.fragment,e),zn=!1},d(e){n(k),e&&n(Ve),g(V,e),e&&n(Oe),e&&n(z),g(O),e&&n(Ze),e&&n(be),e&&n(Qe),e&&n(ke),e&&n(Ue),e&&n(x),g(Z),e&&n(Je),g(U,e),e&&n(Xe),e&&n(E),g(J),e&&n(Ye),g(X,e),e&&n(en),g(Y,e),e&&n(nn),e&&n(_),g(ee),e&&n(tn),g(ne,e),e&&n(rn),g(te,e),e&&n(sn),e&&n(M),g(re),e&&n(an),g(ie,e),e&&n(ln),g(se,e),e&&n(on),e&&n(A),g(ae),e&&n(dn),g(le,e),e&&n(un),e&&n(S),g(oe),e&&n(hn),g(de,e),e&&n(fn),e&&n(y),g(ue),e&&n(pn),g(he,e),e&&n(cn),e&&n(P),g(fe),e&&n(mn),g(pe,e),e&&n(gn),e&&n(q),g(ce),e&&n(wn),g(me,e),e&&n($n),e&&n(T),g(ge),e&&n(vn),g(we,e),e&&n(bn),e&&n(D),g($e),e&&n(kn),g(ve,e)}}}const ir={local:"quiz-am-ende-des-kapitels",title:"Quiz am Ende des Kapitels"};function sr(ht){return nr(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class fr extends Ut{constructor(k){super();Jt(this,k,sr,rr,Xt,{})}}export{fr as default,ir as metadata};
