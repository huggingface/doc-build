import{S as z_,i as O_,s as F_,e as r,k as d,w as f,t as a,M as S_,c as n,d as o,m as l,a as s,x as h,h as i,b as c,F as t,g as u,y as m,L as q_,q as g,o as _,B as v}from"../../chunks/vendor-ab4e3193.js";import{D as b}from"../../chunks/Docstring-91f1beab.js";import{C as D_}from"../../chunks/CodeBlock-516df0c5.js";import{I as $e}from"../../chunks/IconCopyLink-d992940d.js";import"../../chunks/CopyButton-204b56db.js";function B_(wc){let ge,Wo,S,N,Wn,ft,Ec,Vn,Lc,Ba,T,Pc,Vo,Dc,zc,Mo,Oc,Fc,Co,Sc,qc,Go,Bc,Ic,Ho,Ac,Nc,jo,Wc,Vc,Ia,Ro,Mc,Aa,ke,Ce,Mn,ht,Cc,Cn,Gc,Na,q,Hc,Ko,jc,Rc,Uo,Kc,Uc,Yo,Yc,Xc,Wa,Xo,Jc,Va,mt,Ma,_e,Qc,Gn,Zc,ed,Jo,td,od,Ca,B,Qo,Hn,rd,nd,sd,Zo,jn,ad,id,cd,er,Rn,dd,ld,pd,tr,Kn,ud,fd,Ga,y,hd,Un,md,gd,Yn,_d,vd,Xn,bd,Td,Jn,yd,$d,Qn,kd,xd,Zn,wd,Ed,Ha,w,Ld,es,Pd,Dd,ts,zd,Od,os,Fd,Sd,rs,qd,Bd,ja,E,Id,ns,Ad,Nd,ss,Wd,Vd,as,Md,Cd,is,Gd,Hd,Ra,gt,Ka,Ge,jd,cs,Rd,Kd,Ua,L,Ud,ds,Yd,Xd,ls,Jd,Qd,ps,Zd,el,us,tl,ol,Ya,or,rl,Xa,xe,He,fs,_t,nl,hs,sl,Ja,we,vt,al,ms,il,Qa,Ee,bt,cl,gs,dl,Za,W,Tt,ll,_s,pl,ul,je,yt,fl,vs,hl,ei,Le,Re,bs,$t,ml,Ts,gl,ti,Pe,kt,_l,ys,vl,oi,De,xt,bl,$s,Tl,ri,V,wt,yl,ks,$l,kl,Ke,Et,xl,xs,wl,ni,ze,Ue,ws,Lt,El,Es,Ll,si,Oe,Pt,Pl,Ls,Dl,ai,Fe,Dt,zl,Ps,Ol,ii,Se,Ye,Ds,zt,Fl,zs,Sl,ci,qe,Ot,ql,Os,Bl,di,Be,Ft,Il,Fs,Al,li,Ie,Xe,Ss,St,Nl,qs,Wl,pi,Je,Vl,rr,Ml,Cl,ui,M,qt,Gl,Bs,Hl,jl,Qe,Bt,Rl,Is,Kl,fi,C,It,Ul,$,Yl,nr,Xl,Jl,sr,Ql,Zl,As,ep,tp,Ns,Ws,op,rp,ar,np,sp,ir,ap,ip,cp,cr,At,hi,G,Nt,dp,Vs,lp,pp,Ze,Wt,up,Ms,fp,mi,H,Vt,hp,dr,lr,mp,gp,_p,Cs,gi,j,Mt,vp,pr,ur,bp,Tp,yp,Gs,_i,R,Ct,$p,fr,hr,kp,xp,wp,Hs,vi,K,Gt,Ep,mr,gr,Lp,Pp,Dp,js,bi,U,Ht,zp,_r,vr,Op,Fp,Sp,Rs,Ti,Y,jt,qp,et,br,Bp,Ip,Rt,Ap,Np,Wp,Ks,yi,X,Kt,Vp,Tr,yr,Mp,Cp,Gp,Us,$i,J,Ut,Hp,tt,$r,jp,Rp,Yt,Kp,Up,Yp,Ys,ki,Q,Xt,Xp,ve,kr,Jp,Qp,xr,Zp,eu,Jt,tu,ou,ru,Xs,xi,Z,Qt,nu,wr,Er,su,au,iu,Js,wi,ee,Zt,cu,ot,Lr,du,lu,Qs,pu,uu,fu,Zs,Ei,te,eo,hu,I,Pr,mu,gu,ea,_u,vu,ta,bu,Tu,oa,yu,$u,ku,ra,Li,oe,to,xu,na,wu,Eu,rt,oo,Lu,sa,Pu,Pi,re,ro,Du,k,zu,Dr,Ou,Fu,zr,Su,qu,aa,Bu,Iu,ia,ca,Au,Nu,Or,Wu,Vu,Fr,Mu,Cu,Gu,Sr,no,Di,ne,so,Hu,da,ju,Ru,nt,ao,Ku,la,Uu,zi,se,io,Yu,qr,Br,Xu,Ju,Qu,pa,Oi,ae,co,Zu,Ir,Ar,ef,tf,of,ua,Fi,ie,lo,rf,Nr,Wr,nf,sf,af,fa,Si,ce,po,cf,Vr,Mr,df,lf,pf,ha,qi,de,uo,uf,st,Cr,ff,hf,ma,mf,gf,_f,ga,Bi,le,fo,vf,Gr,Hr,bf,Tf,yf,_a,Ii,Ae,at,va,ho,$f,ba,kf,Ai,it,xf,jr,wf,Ef,Ni,pe,mo,Lf,Ta,Pf,Df,Rr,go,Wi,_o,Kr,vo,Vi,ue,bo,zf,To,Of,ya,Ff,Sf,qf,Ur,yo,Mi,fe,$o,Bf,ko,If,$a,Af,Nf,Wf,Yr,xo,Ci,Ne,ct,ka,wo,Vf,xa,Mf,Gi,F,Eo,Cf,We,Gf,Xr,Hf,jf,Jr,Rf,Kf,Uf,Qr,Lo,Yf,Zr,Po,Hi,x,Do,Xf,en,tn,Jf,Qf,Zf,zo,eh,Oo,th,oh,rh,on,nh,Fo,sh,ah,wa,ih,Ea,ji,Ve,dt,La,So,ch,Pa,dh,Ri,he,qo,lh,Da,ph,uh,rn,fh,Bo,hh,Ki,me,Io,mh,za,gh,_h,nn,vh,Ao,bh,Ui;return ft=new $e({}),ht=new $e({}),mt=new D_({props:{code:`from transformers import GPT2Tokenizer, GPT2LMHeadModel

tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
model = GPT2LMHeadModel.from_pretrained("gpt2")

inputs = tokenizer("Hello, my dog is cute and ", return_tensors="pt")
generation_output = model.generate(**inputs, return_dict_in_generate=True, output_scores=True),`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> GPT2Tokenizer, GPT2LMHeadModel

tokenizer = GPT2Tokenizer.from_pretrained(<span class="hljs-string">&quot;gpt2&quot;</span>)
model = GPT2LMHeadModel.from_pretrained(<span class="hljs-string">&quot;gpt2&quot;</span>)

inputs = tokenizer(<span class="hljs-string">&quot;Hello, my dog is cute and &quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
generation_output = model.generate(**inputs, return_dict_in_generate=<span class="hljs-literal">True</span>, output_scores=<span class="hljs-literal">True</span>)`}}),gt=new D_({props:{code:"generation_output[:2],",highlighted:'generation_output[:<span class="hljs-number">2</span>]'}}),_t=new $e({}),vt=new b({props:{name:"class transformers.generation_utils.GreedySearchDecoderOnlyOutput",anchor:"transformers.generation_utils.GreedySearchDecoderOnlyOutput",parameters:[{name:"sequences",val:": LongTensor = None"},{name:"scores",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"hidden_states",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_utils.py#L58",parametersDescription:[{anchor:"transformers.generation_utils.GreedySearchDecoderOnlyOutput.sequences",description:`<strong>sequences</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
The generated sequences. The second dimension (sequence_length) is either equal to <code>max_length</code> or shorter
if all batches finished early due to the <code>eos_token_id</code>.`,name:"sequences"},{anchor:"transformers.generation_utils.GreedySearchDecoderOnlyOutput.scores",description:`<strong>scores</strong> (<code>tuple(torch.FloatTensor)</code> <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Processed prediction scores of the language modeling head (scores for each vocabulary token before SoftMax)
at each generation step. <code>(max_length-input_ids.shape[-1],)</code>-shaped tuple of <code>torch.FloatTensor</code> with each
tensor of shape <code>(batch_size, config.vocab_size)</code>).`,name:"scores"},{anchor:"transformers.generation_utils.GreedySearchDecoderOnlyOutput.attentions",description:`<strong>attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size, num_heads, generated_length, sequence_length)</code>.`,name:"attentions"},{anchor:"transformers.generation_utils.GreedySearchDecoderOnlyOutput.hidden_states",description:`<strong>hidden_states</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size, generated_length, hidden_size)</code>.`,name:"hidden_states"}]}}),bt=new b({props:{name:"class transformers.generation_utils.GreedySearchEncoderDecoderOutput",anchor:"transformers.generation_utils.GreedySearchEncoderDecoderOutput",parameters:[{name:"sequences",val:": LongTensor = None"},{name:"scores",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"encoder_attentions",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"encoder_hidden_states",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"decoder_attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"cross_attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"decoder_hidden_states",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_utils.py#L86",parametersDescription:[{anchor:"transformers.generation_utils.GreedySearchEncoderDecoderOutput.sequences",description:`<strong>sequences</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
The generated sequences. The second dimension (sequence_length) is either equal to <code>max_length</code> or shorter
if all batches finished early due to the <code>eos_token_id</code>.`,name:"sequences"},{anchor:"transformers.generation_utils.GreedySearchEncoderDecoderOutput.scores",description:`<strong>scores</strong> (<code>tuple(torch.FloatTensor)</code> <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Processed prediction scores of the language modeling head (scores for each vocabulary token before SoftMax)
at each generation step. <code>(max_length-1,)</code>-shaped tuple of <code>torch.FloatTensor</code> with each tensor of shape
<code>(batch_size, config.vocab_size)</code>).`,name:"scores"},{anchor:"transformers.generation_utils.GreedySearchEncoderDecoderOutput.encoder_attentions",description:`<strong>encoder_attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple of <code>torch.FloatTensor</code> (one for each layer of the decoder) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.`,name:"encoder_attentions"},{anchor:"transformers.generation_utils.GreedySearchEncoderDecoderOutput.encoder_hidden_states",description:`<strong>encoder_hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings + one for the output of each layer) of
shape <code>(batch_size, sequence_length, hidden_size)</code>.`,name:"encoder_hidden_states"},{anchor:"transformers.generation_utils.GreedySearchEncoderDecoderOutput.decoder_attentions",description:`<strong>decoder_attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size, num_heads, generated_length, sequence_length)</code>.`,name:"decoder_attentions"},{anchor:"transformers.generation_utils.GreedySearchEncoderDecoderOutput.cross_attentions",description:`<strong>cross_attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size, num_heads, generated_length, sequence_length)</code>.`,name:"cross_attentions"},{anchor:"transformers.generation_utils.GreedySearchEncoderDecoderOutput.decoder_hidden_states",description:`<strong>decoder_hidden_states</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size, generated_length, hidden_size)</code>.`,name:"decoder_hidden_states"}]}}),Tt=new b({props:{name:"class transformers.generation_flax_utils.FlaxGreedySearchOutput",anchor:"transformers.generation_flax_utils.FlaxGreedySearchOutput",parameters:[{name:"sequences",val:": ndarray = None"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_flax_utils.py#L45",parametersDescription:[{anchor:"transformers.generation_flax_utils.FlaxGreedySearchOutput.sequences",description:`<strong>sequences</strong> (<code>jnp.ndarray</code> of shape <code>(batch_size, max_length)</code>) &#x2014;
The generated sequences.`,name:"sequences"}]}}),yt=new b({props:{name:"replace",anchor:"None",parameters:[{name:"**updates",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/flax/struct.py#L120"}}),$t=new $e({}),kt=new b({props:{name:"class transformers.generation_utils.SampleDecoderOnlyOutput",anchor:"transformers.generation_utils.SampleDecoderOnlyOutput",parameters:[{name:"sequences",val:": LongTensor = None"},{name:"scores",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"hidden_states",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_utils.py#L128",parametersDescription:[{anchor:"transformers.generation_utils.SampleDecoderOnlyOutput.sequences",description:`<strong>sequences</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size*num_return_sequences, sequence_length)</code>) &#x2014;
The generated sequences. The second dimension (sequence_length) is either equal to <code>max_length</code> or shorter
if all batches finished early due to the <code>eos_token_id</code>.`,name:"sequences"},{anchor:"transformers.generation_utils.SampleDecoderOnlyOutput.scores",description:`<strong>scores</strong> (<code>tuple(torch.FloatTensor)</code> <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Processed prediction scores of the language modeling head (scores for each vocabulary token before SoftMax)
at each generation step. <code>(max_length-input_ids.shape[-1],)</code>-shaped tuple of <code>torch.FloatTensor</code> with each
tensor of shape <code>(batch_size*num_return_sequences, config.vocab_size)</code>).`,name:"scores"},{anchor:"transformers.generation_utils.SampleDecoderOnlyOutput.attentions",description:`<strong>attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(num_return_sequences*batch_size, num_heads, generated_length, sequence_length)</code>.`,name:"attentions"},{anchor:"transformers.generation_utils.SampleDecoderOnlyOutput.hidden_states",description:`<strong>hidden_states</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(num_return_sequences*batch_size, generated_length, hidden_size)</code>.`,name:"hidden_states"}]}}),xt=new b({props:{name:"class transformers.generation_utils.SampleEncoderDecoderOutput",anchor:"transformers.generation_utils.SampleEncoderDecoderOutput",parameters:[{name:"sequences",val:": LongTensor = None"},{name:"scores",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"encoder_attentions",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"encoder_hidden_states",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"decoder_attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"cross_attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"decoder_hidden_states",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_utils.py#L157",parametersDescription:[{anchor:"transformers.generation_utils.SampleEncoderDecoderOutput.sequences",description:`<strong>sequences</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size*num_return_sequences, sequence_length)</code>) &#x2014;
The generated sequences. The second dimension (sequence_length) is either equal to <code>max_length</code> or shorter
if all batches finished early due to the <code>eos_token_id</code>.`,name:"sequences"},{anchor:"transformers.generation_utils.SampleEncoderDecoderOutput.scores",description:`<strong>scores</strong> (<code>tuple(torch.FloatTensor)</code> <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Processed prediction scores of the language modeling head (scores for each vocabulary token before SoftMax)
at each generation step. <code>(max_length-1,)</code>-shaped tuple of <code>torch.FloatTensor</code> with each tensor of shape
<code>(batch_size*num_return_sequences, config.vocab_size)</code>).`,name:"scores"},{anchor:"transformers.generation_utils.SampleEncoderDecoderOutput.encoder_attentions",description:`<strong>encoder_attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple of <code>torch.FloatTensor</code> (one for each layer of the decoder) of shape
<code>(batch_size*num_return_sequences, num_heads, sequence_length, sequence_length)</code>.`,name:"encoder_attentions"},{anchor:"transformers.generation_utils.SampleEncoderDecoderOutput.encoder_hidden_states",description:`<strong>encoder_hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings + one for the output of each layer) of
shape <code>(batch_size*num_return_sequences, sequence_length, hidden_size)</code>.`,name:"encoder_hidden_states"},{anchor:"transformers.generation_utils.SampleEncoderDecoderOutput.decoder_attentions",description:`<strong>decoder_attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size*num_return_sequences, num_heads, generated_length, sequence_length)</code>.`,name:"decoder_attentions"},{anchor:"transformers.generation_utils.SampleEncoderDecoderOutput.cross_attentions",description:`<strong>cross_attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size, num_heads, generated_length, sequence_length)</code>.`,name:"cross_attentions"},{anchor:"transformers.generation_utils.SampleEncoderDecoderOutput.decoder_hidden_states",description:`<strong>decoder_hidden_states</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size*num_return_sequences, generated_length, hidden_size)</code>.`,name:"decoder_hidden_states"}]}}),wt=new b({props:{name:"class transformers.generation_flax_utils.FlaxSampleOutput",anchor:"transformers.generation_flax_utils.FlaxSampleOutput",parameters:[{name:"sequences",val:": ndarray = None"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_flax_utils.py#L59",parametersDescription:[{anchor:"transformers.generation_flax_utils.FlaxSampleOutput.sequences",description:`<strong>sequences</strong> (<code>jnp.ndarray</code> of shape <code>(batch_size, max_length)</code>) &#x2014;
The generated sequences.`,name:"sequences"}]}}),Et=new b({props:{name:"replace",anchor:"None",parameters:[{name:"**updates",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/flax/struct.py#L120"}}),Lt=new $e({}),Pt=new b({props:{name:"class transformers.generation_utils.BeamSearchDecoderOnlyOutput",anchor:"transformers.generation_utils.BeamSearchDecoderOnlyOutput",parameters:[{name:"sequences",val:": LongTensor = None"},{name:"sequences_scores",val:": typing.Optional[torch.FloatTensor] = None"},{name:"scores",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"beam_indices",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.LongTensor]]] = None"},{name:"attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"hidden_states",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_utils.py#L200",parametersDescription:[{anchor:"transformers.generation_utils.BeamSearchDecoderOnlyOutput.sequences",description:`<strong>sequences</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size*num_return_sequences, sequence_length)</code>) &#x2014;
The generated sequences. The second dimension (sequence_length) is either equal to <code>max_length</code> or shorter
if all batches finished early due to the <code>eos_token_id</code>.`,name:"sequences"},{anchor:"transformers.generation_utils.BeamSearchDecoderOnlyOutput.sequences_scores",description:`<strong>sequences_scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size*num_return_sequences)</code>, <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Final beam scores of the generated <code>sequences</code>.`,name:"sequences_scores"},{anchor:"transformers.generation_utils.BeamSearchDecoderOnlyOutput.scores",description:`<strong>scores</strong> (<code>tuple(torch.FloatTensor)</code> <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Beam transition scores for each vocabulary token at each generation step. Beam transition scores consisting
of log probabilities of tokens conditioned on log softmax of previously generated tokens in this beam.
<code>(max_length-input_ids.shape[-1],)</code>-shaped tuple of <code>torch.FloatTensor</code> with each tensor of shape
<code>(batch_size*num_beams*num_return_sequences, config.vocab_size)</code>).`,name:"scores"},{anchor:"transformers.generation_utils.BeamSearchDecoderOnlyOutput.beam_indices",description:`<strong>beam_indices</strong> (<code>tuple(tuple(torch.LongTensor))</code>, <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Beam indices of generated token id at each generation step. <code>(batch_size*num_return_sequences)</code>-shaped
tuple of <code>(max_length-input_ids.shape[-1],)</code>-shaped tuples of scalar <code>torch.LongTensor</code> tensors.`,name:"beam_indices"},{anchor:"transformers.generation_utils.BeamSearchDecoderOnlyOutput.attentions",description:`<strong>attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size*num_beams, num_heads, generated_length, sequence_length)</code>.`,name:"attentions"},{anchor:"transformers.generation_utils.BeamSearchDecoderOnlyOutput.hidden_states",description:`<strong>hidden_states</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size*num_beams*num_return_sequences, generated_length, hidden_size)</code>.`,name:"hidden_states"}]}}),Dt=new b({props:{name:"class transformers.generation_utils.BeamSearchEncoderDecoderOutput",anchor:"transformers.generation_utils.BeamSearchEncoderDecoderOutput",parameters:[{name:"sequences",val:": LongTensor = None"},{name:"sequences_scores",val:": typing.Optional[torch.FloatTensor] = None"},{name:"scores",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"beam_indices",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.LongTensor]]] = None"},{name:"encoder_attentions",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"encoder_hidden_states",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"decoder_attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"cross_attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"decoder_hidden_states",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_utils.py#L235",parametersDescription:[{anchor:"transformers.generation_utils.BeamSearchEncoderDecoderOutput.sequences",description:`<strong>sequences</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size*num_return_sequences, sequence_length)</code>) &#x2014;
The generated sequences. The second dimension (sequence_length) is either equal to <code>max_length</code> or shorter
if all batches finished early due to the <code>eos_token_id</code>.`,name:"sequences"},{anchor:"transformers.generation_utils.BeamSearchEncoderDecoderOutput.sequences_scores",description:`<strong>sequences_scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size*num_return_sequences)</code>, <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Final beam scores of the generated <code>sequences</code>.`,name:"sequences_scores"},{anchor:"transformers.generation_utils.BeamSearchEncoderDecoderOutput.scores",description:`<strong>scores</strong> (<code>tuple(torch.FloatTensor)</code> <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Beam transition scores for each vocabulary token at each generation step. Beam transition scores consisting
of log probabilities of tokens conditioned on log softmax of previously generated tokens in this beam.
<code>(max_length-1,)</code>-shaped tuple of <code>torch.FloatTensor</code> with each tensor of shape <code>(batch_size*num_beams, config.vocab_size)</code>).`,name:"scores"},{anchor:"transformers.generation_utils.BeamSearchEncoderDecoderOutput.beam_indices",description:`<strong>beam_indices</strong> (<code>tuple(tuple(torch.LongTensor))</code>, <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Beam indices of generated token id at each generation step. <code>(batch_size*num_return_sequences)</code>-shaped
tuple of <code>(max_length-1,)</code>-shaped tuples of scalar <code>torch.LongTensor</code> tensors.`,name:"beam_indices"},{anchor:"transformers.generation_utils.BeamSearchEncoderDecoderOutput.attentions",description:"<strong>attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;",name:"attentions"},{anchor:"transformers.generation_utils.BeamSearchEncoderDecoderOutput.encoder_attentions",description:`<strong>encoder_attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple of <code>torch.FloatTensor</code> (one for each layer of the decoder) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.`,name:"encoder_attentions"},{anchor:"transformers.generation_utils.BeamSearchEncoderDecoderOutput.encoder_hidden_states",description:`<strong>encoder_hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings + one for the output of each layer) of
shape <code>(batch_size*num_beams*num_return_sequences, sequence_length, hidden_size)</code>.`,name:"encoder_hidden_states"},{anchor:"transformers.generation_utils.BeamSearchEncoderDecoderOutput.decoder_attentions",description:`<strong>decoder_attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size*num_beams*num_return_sequences, num_heads, generated_length, sequence_length)</code>.`,name:"decoder_attentions"},{anchor:"transformers.generation_utils.BeamSearchEncoderDecoderOutput.cross_attentions",description:`<strong>cross_attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size, num_heads, generated_length, sequence_length)</code>.`,name:"cross_attentions"},{anchor:"transformers.generation_utils.BeamSearchEncoderDecoderOutput.decoder_hidden_states",description:`<strong>decoder_hidden_states</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size*num_beams*num_return_sequences, generated_length, hidden_size)</code>.`,name:"decoder_hidden_states"}]}}),zt=new $e({}),Ot=new b({props:{name:"class transformers.generation_utils.BeamSampleDecoderOnlyOutput",anchor:"transformers.generation_utils.BeamSampleDecoderOnlyOutput",parameters:[{name:"sequences",val:": LongTensor = None"},{name:"sequences_scores",val:": typing.Optional[torch.FloatTensor] = None"},{name:"scores",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"beam_indices",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.LongTensor]]] = None"},{name:"attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"hidden_states",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_utils.py#L286",parametersDescription:[{anchor:"transformers.generation_utils.BeamSampleDecoderOnlyOutput.sequences",description:`<strong>sequences</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size*num_return_sequences, sequence_length)</code>) &#x2014;
The generated sequences. The second dimension (sequence_length) is either equal to <code>max_length</code> or shorter
if all batches finished early due to the <code>eos_token_id</code>.`,name:"sequences"},{anchor:"transformers.generation_utils.BeamSampleDecoderOnlyOutput.sequences_scores",description:`<strong>sequences_scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size * num_return_sequence)</code>, <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Final beam scores of the generated <code>sequences</code>.`,name:"sequences_scores"},{anchor:"transformers.generation_utils.BeamSampleDecoderOnlyOutput.scores",description:`<strong>scores</strong> (<code>tuple(torch.FloatTensor)</code> <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Beam transition scores for each vocabulary token at each generation step. Beam transition scores consisting
of log probabilities of tokens conditioned on log softmax of previously generated tokens in this beam.
<code>(max_length-input_ids.shape[-1],)</code>-shaped tuple of <code>torch.FloatTensor</code> with each tensor of shape
<code>(batch_size*num_beams*num_return_sequences, config.vocab_size)</code>).`,name:"scores"},{anchor:"transformers.generation_utils.BeamSampleDecoderOnlyOutput.beam_indices",description:`<strong>beam_indices</strong> (<code>tuple(tuple(torch.LongTensor))</code>, <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Beam indices of generated token id at each generation step. <code>(batch_size*num_return_sequences)</code>-shaped
tuple of <code>(max_length-input_ids.shape[-1],)</code>-shaped tuples of scalar <code>torch.LongTensor</code> tensors.`,name:"beam_indices"},{anchor:"transformers.generation_utils.BeamSampleDecoderOnlyOutput.attentions",description:`<strong>attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size*num_beams, num_heads, generated_length, sequence_length)</code>.`,name:"attentions"},{anchor:"transformers.generation_utils.BeamSampleDecoderOnlyOutput.hidden_states",description:`<strong>hidden_states</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size*num_beams, generated_length, hidden_size)</code>.`,name:"hidden_states"}]}}),Ft=new b({props:{name:"class transformers.generation_utils.BeamSampleEncoderDecoderOutput",anchor:"transformers.generation_utils.BeamSampleEncoderDecoderOutput",parameters:[{name:"sequences",val:": LongTensor = None"},{name:"sequences_scores",val:": typing.Optional[torch.FloatTensor] = None"},{name:"scores",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"beam_indices",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.LongTensor]]] = None"},{name:"encoder_attentions",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"encoder_hidden_states",val:": typing.Optional[typing.Tuple[torch.FloatTensor]] = None"},{name:"decoder_attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"cross_attentions",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"},{name:"decoder_hidden_states",val:": typing.Optional[typing.Tuple[typing.Tuple[torch.FloatTensor]]] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_utils.py#L321",parametersDescription:[{anchor:"transformers.generation_utils.BeamSampleEncoderDecoderOutput.sequences",description:`<strong>sequences</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size*num_beams, sequence_length)</code>) &#x2014;
The generated sequences. The second dimension (sequence_length) is either equal to <code>max_length</code> or shorter
if all batches finished early due to the <code>eos_token_id</code>.`,name:"sequences"},{anchor:"transformers.generation_utils.BeamSampleEncoderDecoderOutput.sequences_scores",description:`<strong>sequences_scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size * num_return_sequence)</code>, <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Final beam scores of the generated <code>sequences</code>.`,name:"sequences_scores"},{anchor:"transformers.generation_utils.BeamSampleEncoderDecoderOutput.scores",description:`<strong>scores</strong> (<code>tuple(torch.FloatTensor)</code> <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Beam transition scores for each vocabulary token at each generation step. Beam transition scores consisting
of log probabilities of tokens conditioned on log softmax of previously generated tokens in this beam.
<code>(max_length-1,)</code>-shaped tuple of <code>torch.FloatTensor</code> with each tensor of shape <code>(batch_size*num_beams, config.vocab_size)</code>).`,name:"scores"},{anchor:"transformers.generation_utils.BeamSampleEncoderDecoderOutput.beam_indices",description:`<strong>beam_indices</strong> (<code>tuple(tuple(torch.LongTensor))</code>, <em>optional</em>, returned when <code>output_scores=True</code> is passed or when <code>config.output_scores=True</code>) &#x2014;
Beam indices of generated token id at each generation step. <code>(batch_size*num_return_sequences)</code>-shaped
tuple of <code>(max_length-1,)</code>-shaped tuples of scalar <code>torch.LongTensor</code> tensors.`,name:"beam_indices"},{anchor:"transformers.generation_utils.BeamSampleEncoderDecoderOutput.encoder_attentions",description:`<strong>encoder_attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple of <code>torch.FloatTensor</code> (one for each layer of the decoder) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.`,name:"encoder_attentions"},{anchor:"transformers.generation_utils.BeamSampleEncoderDecoderOutput.encoder_hidden_states",description:`<strong>encoder_hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings + one for the output of each layer) of
shape <code>(batch_size*num_beams, sequence_length, hidden_size)</code>.`,name:"encoder_hidden_states"},{anchor:"transformers.generation_utils.BeamSampleEncoderDecoderOutput.decoder_attentions",description:`<strong>decoder_attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size*num_beams, num_heads, generated_length, sequence_length)</code>.`,name:"decoder_attentions"},{anchor:"transformers.generation_utils.BeamSampleEncoderDecoderOutput.cross_attentions",description:`<strong>cross_attentions</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or <code>config.output_attentions=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size, num_heads, generated_length, sequence_length)</code>.`,name:"cross_attentions"},{anchor:"transformers.generation_utils.BeamSampleEncoderDecoderOutput.decoder_hidden_states",description:`<strong>decoder_hidden_states</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) &#x2014;
Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of
<code>torch.FloatTensor</code> of shape <code>(batch_size*num_beams, generated_length, hidden_size)</code>.`,name:"decoder_hidden_states"}]}}),St=new $e({}),qt=new b({props:{name:"class transformers.LogitsProcessor",anchor:"transformers.LogitsProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_logits_process.py#L52"}}),Bt=new b({props:{name:"__call__",anchor:"transformers.LogitsProcessor.__call__",parameters:[{name:"input_ids",val:": LongTensor"},{name:"scores",val:": FloatTensor"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_logits_process.py#L55",parametersDescription:[{anchor:"transformers.LogitsProcessor.__call__.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertTokenizer">BertTokenizer</a>. See <a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">PreTrainedTokenizer.encode()</a> and
<a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.LogitsProcessor.__call__.scores",description:`<strong>scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, config.vocab_size)</code>) &#x2014;
Prediction scores of a language modeling head. These can be logits for each vocabulary when not using beam
search or log softmax for each vocabulary token when using beam search
kwargs &#x2014;
Additional logits processor specific kwargs.`,name:"scores"}],returnDescription:`
<p>The processed prediction scores.</p>
`,returnType:`
<p><code>torch.FloatTensor</code> of shape <code>(batch_size, config.vocab_size)</code></p>
`}}),It=new b({props:{name:"class transformers.LogitsProcessorList",anchor:"transformers.LogitsProcessorList",parameters:[{name:"iterable",val:" = ()"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_logits_process.py#L74"}}),At=new b({props:{name:"__call__",anchor:"transformers.LogitsProcessorList.__call__",parameters:[{name:"input_ids",val:": LongTensor"},{name:"scores",val:": FloatTensor"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_logits_process.py#L81",parametersDescription:[{anchor:"transformers.LogitsProcessorList.__call__.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertTokenizer">BertTokenizer</a>. See <a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">PreTrainedTokenizer.encode()</a> and
<a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.LogitsProcessorList.__call__.scores",description:`<strong>scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, config.vocab_size)</code>) &#x2014;
Prediction scores of a language modeling head. These can be logits for each vocabulary when not using beam
search or log softmax for each vocabulary token when using beam search
kwargs &#x2014;
Additional logits processor specific kwargs.`,name:"scores"}],returnDescription:`
<p>The processed prediction scores.</p>
`,returnType:`
<p><code>torch.FloatTensor</code> of shape <code>(batch_size, config.vocab_size)</code></p>
`}}),Nt=new b({props:{name:"class transformers.LogitsWarper",anchor:"transformers.LogitsWarper",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_logits_process.py#L63"}}),Wt=new b({props:{name:"__call__",anchor:"transformers.LogitsWarper.__call__",parameters:[{name:"input_ids",val:": LongTensor"},{name:"scores",val:": FloatTensor"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_logits_process.py#L66",parametersDescription:[{anchor:"transformers.LogitsWarper.__call__.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertTokenizer">BertTokenizer</a>. See <a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">PreTrainedTokenizer.encode()</a> and
<a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.LogitsWarper.__call__.scores",description:`<strong>scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, config.vocab_size)</code>) &#x2014;
Prediction scores of a language modeling head. These can be logits for each vocabulary when not using beam
search or log softmax for each vocabulary token when using beam search
kwargs &#x2014;
Additional logits processor specific kwargs.`,name:"scores"}],returnDescription:`
<p>The processed prediction scores.</p>
`,returnType:`
<p><code>torch.FloatTensor</code> of shape <code>(batch_size, config.vocab_size)</code></p>
`}}),Vt=new b({props:{name:"class transformers.MinLengthLogitsProcessor",anchor:"transformers.MinLengthLogitsProcessor",parameters:[{name:"min_length",val:": int"},{name:"eos_token_id",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_logits_process.py#L97",parametersDescription:[{anchor:"transformers.MinLengthLogitsProcessor.min_length",description:`<strong>min_length</strong> (<code>int</code>) &#x2014;
The minimum length below which the score of <code>eos_token_id</code> is set to <code>-float(&quot;Inf&quot;)</code>.`,name:"min_length"},{anchor:"transformers.MinLengthLogitsProcessor.eos_token_id",description:`<strong>eos_token_id</strong> (<code>int</code>) &#x2014;
The id of the <em>end-of-sequence</em> token.`,name:"eos_token_id"}]}}),Mt=new b({props:{name:"class transformers.TemperatureLogitsWarper",anchor:"transformers.TemperatureLogitsWarper",parameters:[{name:"temperature",val:": float"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_logits_process.py#L125",parametersDescription:[{anchor:"transformers.TemperatureLogitsWarper.temperature",description:`<strong>temperature</strong> (<code>float</code>) &#x2014;
The value used to module the logits distribution.`,name:"temperature"}]}}),Ct=new b({props:{name:"class transformers.RepetitionPenaltyLogitsProcessor",anchor:"transformers.RepetitionPenaltyLogitsProcessor",parameters:[{name:"penalty",val:": float"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_logits_process.py#L145",parametersDescription:[{anchor:"transformers.RepetitionPenaltyLogitsProcessor.repetition_penalty",description:`<strong>repetition_penalty</strong> (<code>float</code>) &#x2014;
The parameter for repetition penalty. 1.0 means no penalty. See <a href="https://arxiv.org/pdf/1909.05858.pdf" rel="nofollow">this
paper</a> for more details.`,name:"repetition_penalty"}]}}),Gt=new b({props:{name:"class transformers.TopPLogitsWarper",anchor:"transformers.TopPLogitsWarper",parameters:[{name:"top_p",val:": float"},{name:"filter_value",val:": float = -inf"},{name:"min_tokens_to_keep",val:": int = 1"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_logits_process.py#L171",parametersDescription:[{anchor:"transformers.TopPLogitsWarper.top_p",description:`<strong>top_p</strong> (<code>float</code>) &#x2014;
If set to &lt; 1, only the most probable tokens with probabilities that add up to <code>top_p</code> or higher are kept
for generation.`,name:"top_p"},{anchor:"transformers.TopPLogitsWarper.filter_value",description:`<strong>filter_value</strong> (<code>float</code>, <em>optional</em>, defaults to <code>-float(&quot;Inf&quot;)</code>) &#x2014;
All filtered values will be set to this float value.`,name:"filter_value"},{anchor:"transformers.TopPLogitsWarper.min_tokens_to_keep",description:`<strong>min_tokens_to_keep</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
Minimum number of tokens that cannot be filtered.`,name:"min_tokens_to_keep"}]}}),Ht=new b({props:{name:"class transformers.TopKLogitsWarper",anchor:"transformers.TopKLogitsWarper",parameters:[{name:"top_k",val:": int"},{name:"filter_value",val:": float = -inf"},{name:"min_tokens_to_keep",val:": int = 1"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_logits_process.py#L213",parametersDescription:[{anchor:"transformers.TopKLogitsWarper.top_k",description:`<strong>top_k</strong> (<code>int</code>) &#x2014;
The number of highest probability vocabulary tokens to keep for top-k-filtering.`,name:"top_k"},{anchor:"transformers.TopKLogitsWarper.filter_value",description:`<strong>filter_value</strong> (<code>float</code>, <em>optional</em>, defaults to <code>-float(&quot;Inf&quot;)</code>) &#x2014;
All filtered values will be set to this float value.`,name:"filter_value"},{anchor:"transformers.TopKLogitsWarper.min_tokens_to_keep",description:`<strong>min_tokens_to_keep</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
Minimum number of tokens that cannot be filtered.`,name:"min_tokens_to_keep"}]}}),jt=new b({props:{name:"class transformers.NoRepeatNGramLogitsProcessor",anchor:"transformers.NoRepeatNGramLogitsProcessor",parameters:[{name:"ngram_size",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_logits_process.py#L277",parametersDescription:[{anchor:"transformers.NoRepeatNGramLogitsProcessor.ngram_size",description:`<strong>ngram_size</strong> (<code>int</code>) &#x2014;
All ngrams of size <code>ngram_size</code> can only occur once.`,name:"ngram_size"}]}}),Kt=new b({props:{name:"class transformers.NoBadWordsLogitsProcessor",anchor:"transformers.NoBadWordsLogitsProcessor",parameters:[{name:"bad_words_ids",val:": typing.List[typing.List[int]]"},{name:"eos_token_id",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_logits_process.py#L344",parametersDescription:[{anchor:"transformers.NoBadWordsLogitsProcessor.bad_words_ids",description:`<strong>bad_words_ids</strong> (<code>List[List[int]]</code>) &#x2014;
List of list of token ids that are not allowed to be generated. In order to get the tokens of the words
that should not appear in the generated text, use <code>tokenizer(bad_word, add_prefix_space=True).input_ids</code>.`,name:"bad_words_ids"},{anchor:"transformers.NoBadWordsLogitsProcessor.eos_token_id",description:`<strong>eos_token_id</strong> (<code>int</code>) &#x2014;
The id of the <em>end-of-sequence</em> token.`,name:"eos_token_id"}]}}),Ut=new b({props:{name:"class transformers.PrefixConstrainedLogitsProcessor",anchor:"transformers.PrefixConstrainedLogitsProcessor",parameters:[{name:"prefix_allowed_tokens_fn",val:": typing.Callable[[int, torch.Tensor], typing.List[int]]"},{name:"num_beams",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_logits_process.py#L471"}}),Xt=new b({props:{name:"class transformers.HammingDiversityLogitsProcessor",anchor:"transformers.HammingDiversityLogitsProcessor",parameters:[{name:"diversity_penalty",val:": float"},{name:"num_beams",val:": int"},{name:"num_beam_groups",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_logits_process.py#L497",parametersDescription:[{anchor:"transformers.HammingDiversityLogitsProcessor.diversity_penalty",description:`<strong>diversity_penalty</strong> (<code>float</code>) &#x2014;
This value is subtracted from a beam&#x2019;s score if it generates a token same as any beam from other group at a
particular time. Note that <code>diversity_penalty</code> is only effective if <code>group beam search</code> is enabled.`,name:"diversity_penalty"},{anchor:"transformers.HammingDiversityLogitsProcessor.num_beams",description:`<strong>num_beams</strong> (<code>int</code>) &#x2014;
Number of beams used for group beam search. See <a href="https://arxiv.org/pdf/1610.02424.pdf" rel="nofollow">this paper</a> for more
details.`,name:"num_beams"},{anchor:"transformers.HammingDiversityLogitsProcessor.num_beam_groups",description:`<strong>num_beam_groups</strong> (<code>int</code>) &#x2014;
Number of groups to divide <code>num_beams</code> into in order to ensure diversity among different groups of beams.
See <a href="https://arxiv.org/pdf/1610.02424.pdf" rel="nofollow">this paper</a> for more details.`,name:"num_beam_groups"}]}}),Qt=new b({props:{name:"class transformers.ForcedBOSTokenLogitsProcessor",anchor:"transformers.ForcedBOSTokenLogitsProcessor",parameters:[{name:"bos_token_id",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_logits_process.py#L557",parametersDescription:[{anchor:"transformers.ForcedBOSTokenLogitsProcessor.bos_token_id",description:`<strong>bos_token_id</strong> (<code>int</code>) &#x2014;
The id of the token to force as the first generated token.`,name:"bos_token_id"}]}}),Zt=new b({props:{name:"class transformers.ForcedEOSTokenLogitsProcessor",anchor:"transformers.ForcedEOSTokenLogitsProcessor",parameters:[{name:"max_length",val:": int"},{name:"eos_token_id",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_logits_process.py#L578",parametersDescription:[{anchor:"transformers.ForcedEOSTokenLogitsProcessor.max_length",description:`<strong>max_length</strong> (<code>int</code>) &#x2014;
The maximum length of the sequence to be generated.`,name:"max_length"},{anchor:"transformers.ForcedEOSTokenLogitsProcessor.eos_token_id",description:`<strong>eos_token_id</strong> (<code>int</code>) &#x2014;
The id of the token to force as the last generated token when <code>max_length</code> is reached.`,name:"eos_token_id"}]}}),eo=new b({props:{name:"class transformers.InfNanRemoveLogitsProcessor",anchor:"transformers.InfNanRemoveLogitsProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_logits_process.py#L602"}}),to=new b({props:{name:"class transformers.FlaxLogitsProcessor",anchor:"transformers.FlaxLogitsProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_flax_logits_process.py#L51"}}),oo=new b({props:{name:"__call__",anchor:"transformers.FlaxLogitsProcessor.__call__",parameters:[{name:"input_ids",val:": ndarray"},{name:"scores",val:": ndarray"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_flax_logits_process.py#L54",parametersDescription:[{anchor:"transformers.FlaxLogitsProcessor.__call__.input_ids",description:`<strong>input_ids</strong> (<code>jnp.ndarray</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.16.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer">PreTrainedTokenizer</a>. See <a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">PreTrainedTokenizer.encode()</a> and
<a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.FlaxLogitsProcessor.__call__.scores",description:`<strong>scores</strong> (<code>jnp.ndarray</code> of shape <code>(batch_size, config.vocab_size)</code>) &#x2014;
Prediction scores of a language modeling head. These can be logits for each vocabulary when not using beam
search or log softmax for each vocabulary token when using beam search
kwargs &#x2014;
Additional logits processor specific kwargs.`,name:"scores"}],returnDescription:`
<p>The processed prediction scores.</p>
`,returnType:`
<p><code>jnp.ndarray</code> of shape <code>(batch_size, config.vocab_size)</code></p>
`}}),ro=new b({props:{name:"class transformers.FlaxLogitsProcessorList",anchor:"transformers.FlaxLogitsProcessorList",parameters:[{name:"iterable",val:" = ()"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_flax_logits_process.py#L73"}}),no=new b({props:{name:"__call__",anchor:"transformers.FlaxLogitsProcessorList.__call__",parameters:[{name:"input_ids",val:": ndarray"},{name:"scores",val:": ndarray"},{name:"cur_len",val:": int"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_flax_logits_process.py#L80",parametersDescription:[{anchor:"transformers.FlaxLogitsProcessorList.__call__.input_ids",description:`<strong>input_ids</strong> (<code>jnp.ndarray</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.16.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer">PreTrainedTokenizer</a>. See <a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">PreTrainedTokenizer.encode()</a> and
<a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.FlaxLogitsProcessorList.__call__.scores",description:`<strong>scores</strong> (<code>jnp.ndarray</code> of shape <code>(batch_size, config.vocab_size)</code>) &#x2014;
Prediction scores of a language modeling head. These can be logits for each vocabulary when not using beam
search or log softmax for each vocabulary token when using beam search
kwargs &#x2014;
Additional logits processor specific kwargs.`,name:"scores"}],returnDescription:`
<p>The processed prediction scores.</p>
`,returnType:`
<p><code>jnp.ndarray</code> of shape <code>(batch_size, config.vocab_size)</code></p>
`}}),so=new b({props:{name:"class transformers.FlaxLogitsWarper",anchor:"transformers.FlaxLogitsWarper",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_flax_logits_process.py#L62"}}),ao=new b({props:{name:"__call__",anchor:"transformers.FlaxLogitsWarper.__call__",parameters:[{name:"input_ids",val:": ndarray"},{name:"scores",val:": ndarray"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_flax_logits_process.py#L65",parametersDescription:[{anchor:"transformers.FlaxLogitsWarper.__call__.input_ids",description:`<strong>input_ids</strong> (<code>jnp.ndarray</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.16.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer">PreTrainedTokenizer</a>. See <a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">PreTrainedTokenizer.encode()</a> and
<a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.FlaxLogitsWarper.__call__.scores",description:`<strong>scores</strong> (<code>jnp.ndarray</code> of shape <code>(batch_size, config.vocab_size)</code>) &#x2014;
Prediction scores of a language modeling head. These can be logits for each vocabulary when not using beam
search or log softmax for each vocabulary token when using beam search
kwargs &#x2014;
Additional logits processor specific kwargs.`,name:"scores"}],returnDescription:`
<p>The processed prediction scores.</p>
`,returnType:`
<p><code>jnp.ndarray</code> of shape <code>(batch_size, config.vocab_size)</code></p>
`}}),io=new b({props:{name:"class transformers.FlaxTemperatureLogitsWarper",anchor:"transformers.FlaxTemperatureLogitsWarper",parameters:[{name:"temperature",val:": float"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_flax_logits_process.py#L96",parametersDescription:[{anchor:"transformers.FlaxTemperatureLogitsWarper.temperature",description:`<strong>temperature</strong> (<code>float</code>) &#x2014;
The value used to module the logits distribution.`,name:"temperature"}]}}),co=new b({props:{name:"class transformers.FlaxTopPLogitsWarper",anchor:"transformers.FlaxTopPLogitsWarper",parameters:[{name:"top_p",val:": float"},{name:"filter_value",val:": float = -inf"},{name:"min_tokens_to_keep",val:": int = 1"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_flax_logits_process.py#L116",parametersDescription:[{anchor:"transformers.FlaxTopPLogitsWarper.top_p",description:`<strong>top_p</strong> (<code>float</code>) &#x2014;
If set to &lt; 1, only the most probable tokens with probabilities that add up to <code>top_p</code> or higher are kept
for generation.`,name:"top_p"},{anchor:"transformers.FlaxTopPLogitsWarper.filter_value",description:`<strong>filter_value</strong> (<code>float</code>, <em>optional</em>, defaults to <code>-float(&quot;Inf&quot;)</code>) &#x2014;
All filtered values will be set to this float value.`,name:"filter_value"},{anchor:"transformers.FlaxTopPLogitsWarper.min_tokens_to_keep",description:`<strong>min_tokens_to_keep</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
Minimum number of tokens that cannot be filtered.`,name:"min_tokens_to_keep"}]}}),lo=new b({props:{name:"class transformers.FlaxTopKLogitsWarper",anchor:"transformers.FlaxTopKLogitsWarper",parameters:[{name:"top_k",val:": int"},{name:"filter_value",val:": float = -inf"},{name:"min_tokens_to_keep",val:": int = 1"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_flax_logits_process.py#L157",parametersDescription:[{anchor:"transformers.FlaxTopKLogitsWarper.top_k",description:`<strong>top_k</strong> (<code>int</code>) &#x2014;
The number of highest probability vocabulary tokens to keep for top-k-filtering.`,name:"top_k"},{anchor:"transformers.FlaxTopKLogitsWarper.filter_value",description:`<strong>filter_value</strong> (<code>float</code>, <em>optional</em>, defaults to <code>-float(&quot;Inf&quot;)</code>) &#x2014;
All filtered values will be set to this float value.`,name:"filter_value"},{anchor:"transformers.FlaxTopKLogitsWarper.min_tokens_to_keep",description:`<strong>min_tokens_to_keep</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
Minimum number of tokens that cannot be filtered.`,name:"min_tokens_to_keep"}]}}),po=new b({props:{name:"class transformers.FlaxForcedBOSTokenLogitsProcessor",anchor:"transformers.FlaxForcedBOSTokenLogitsProcessor",parameters:[{name:"bos_token_id",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_flax_logits_process.py#L193",parametersDescription:[{anchor:"transformers.FlaxForcedBOSTokenLogitsProcessor.bos_token_id",description:`<strong>bos_token_id</strong> (<code>int</code>) &#x2014;
The id of the token to force as the first generated token.`,name:"bos_token_id"}]}}),uo=new b({props:{name:"class transformers.FlaxForcedEOSTokenLogitsProcessor",anchor:"transformers.FlaxForcedEOSTokenLogitsProcessor",parameters:[{name:"max_length",val:": int"},{name:"eos_token_id",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_flax_logits_process.py#L217",parametersDescription:[{anchor:"transformers.FlaxForcedEOSTokenLogitsProcessor.max_length",description:`<strong>max_length</strong> (<code>int</code>) &#x2014;
The maximum length of the sequence to be generated.`,name:"max_length"},{anchor:"transformers.FlaxForcedEOSTokenLogitsProcessor.eos_token_id",description:`<strong>eos_token_id</strong> (<code>int</code>) &#x2014;
The id of the token to force as the last generated token when <code>max_length</code> is reached.`,name:"eos_token_id"}]}}),fo=new b({props:{name:"class transformers.FlaxMinLengthLogitsProcessor",anchor:"transformers.FlaxMinLengthLogitsProcessor",parameters:[{name:"min_length",val:": int"},{name:"eos_token_id",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_flax_logits_process.py#L244",parametersDescription:[{anchor:"transformers.FlaxMinLengthLogitsProcessor.min_length",description:`<strong>min_length</strong> (<code>int</code>) &#x2014;
The minimum length below which the score of <code>eos_token_id</code> is set to <code>-float(&quot;Inf&quot;)</code>.`,name:"min_length"},{anchor:"transformers.FlaxMinLengthLogitsProcessor.eos_token_id",description:`<strong>eos_token_id</strong> (<code>int</code>) &#x2014;
The id of the <em>end-of-sequence</em> token.`,name:"eos_token_id"}]}}),ho=new $e({}),mo=new b({props:{name:"class transformers.StoppingCriteria",anchor:"transformers.StoppingCriteria",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_stopping_criteria.py#L33"}}),go=new b({props:{name:"__call__",anchor:"transformers.StoppingCriteria.__call__",parameters:[{name:"input_ids",val:": LongTensor"},{name:"scores",val:": FloatTensor"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_stopping_criteria.py#L36",parametersDescription:[{anchor:"transformers.StoppingCriteria.__call__.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertTokenizer">BertTokenizer</a>. See <a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">PreTrainedTokenizer.encode()</a> and
<a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.StoppingCriteria.__call__.scores",description:`<strong>scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, config.vocab_size)</code>) &#x2014;
Prediction scores of a language modeling head. These can be scores for each vocabulary token before SoftMax
or scores for each vocabulary token after SoftMax.
kwargs &#x2014;
Additional stopping criteria specific kwargs.`,name:"scores"}],returnDescription:`
<p><code>bool</code>. <code>False</code> indicates we should continue, <code>True</code> indicates we should stop.</p>
`}}),vo=new b({props:{name:"__call__",anchor:"transformers.StoppingCriteriaList.__call__",parameters:[{name:"input_ids",val:": LongTensor"},{name:"scores",val:": FloatTensor"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_stopping_criteria.py#L111",parametersDescription:[{anchor:"transformers.StoppingCriteriaList.__call__.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertTokenizer">BertTokenizer</a>. See <a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">PreTrainedTokenizer.encode()</a> and
<a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.StoppingCriteriaList.__call__.scores",description:`<strong>scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, config.vocab_size)</code>) &#x2014;
Prediction scores of a language modeling head. These can be scores for each vocabulary token before SoftMax
or scores for each vocabulary token after SoftMax.
kwargs &#x2014;
Additional stopping criteria specific kwargs.`,name:"scores"}],returnDescription:`
<p><code>bool</code>. <code>False</code> indicates we should continue, <code>True</code> indicates we should stop.</p>
`}}),bo=new b({props:{name:"class transformers.MaxLengthCriteria",anchor:"transformers.MaxLengthCriteria",parameters:[{name:"max_length",val:": int"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_stopping_criteria.py#L41",parametersDescription:[{anchor:"transformers.MaxLengthCriteria.max_length",description:`<strong>max_length</strong> (<code>int</code>) &#x2014;
The maximum length that the output sequence can have in number of tokens.`,name:"max_length"}]}}),yo=new b({props:{name:"__call__",anchor:"transformers.MaxLengthCriteria.__call__",parameters:[{name:"input_ids",val:": LongTensor"},{name:"scores",val:": FloatTensor"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_stopping_criteria.py#L54",parametersDescription:[{anchor:"transformers.MaxLengthCriteria.__call__.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertTokenizer">BertTokenizer</a>. See <a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">PreTrainedTokenizer.encode()</a> and
<a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.MaxLengthCriteria.__call__.scores",description:`<strong>scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, config.vocab_size)</code>) &#x2014;
Prediction scores of a language modeling head. These can be scores for each vocabulary token before SoftMax
or scores for each vocabulary token after SoftMax.
kwargs &#x2014;
Additional stopping criteria specific kwargs.`,name:"scores"}],returnDescription:`
<p><code>bool</code>. <code>False</code> indicates we should continue, <code>True</code> indicates we should stop.</p>
`}}),$o=new b({props:{name:"class transformers.MaxTimeCriteria",anchor:"transformers.MaxTimeCriteria",parameters:[{name:"max_time",val:": float"},{name:"initial_timestamp",val:": typing.Optional[float] = None"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_stopping_criteria.py#L88",parametersDescription:[{anchor:"transformers.MaxTimeCriteria.max_time",description:`<strong>max_time</strong> (<code>float</code>) &#x2014;
The maximum allowed time in seconds for the generation.`,name:"max_time"},{anchor:"transformers.MaxTimeCriteria.initial_time",description:`<strong>initial_time</strong> (<code>float</code>, <em>optional</em>, defaults to <code>time.time()</code>) &#x2014;
The start of the generation allowed time.`,name:"initial_time"}]}}),xo=new b({props:{name:"__call__",anchor:"transformers.MaxTimeCriteria.__call__",parameters:[{name:"input_ids",val:": LongTensor"},{name:"scores",val:": FloatTensor"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_stopping_criteria.py#L105",parametersDescription:[{anchor:"transformers.MaxTimeCriteria.__call__.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <a href="/docs/transformers/v4.16.2/en/model_doc/bert#transformers.BertTokenizer">BertTokenizer</a>. See <a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">PreTrainedTokenizer.encode()</a> and
<a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.MaxTimeCriteria.__call__.scores",description:`<strong>scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, config.vocab_size)</code>) &#x2014;
Prediction scores of a language modeling head. These can be scores for each vocabulary token before SoftMax
or scores for each vocabulary token after SoftMax.
kwargs &#x2014;
Additional stopping criteria specific kwargs.`,name:"scores"}],returnDescription:`
<p><code>bool</code>. <code>False</code> indicates we should continue, <code>True</code> indicates we should stop.</p>
`}}),wo=new $e({}),Eo=new b({props:{name:"class transformers.BeamScorer",anchor:"transformers.BeamScorer",parameters:[],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_beam_search.py#L86"}}),Lo=new b({props:{name:"process",anchor:"transformers.BeamScorer.process",parameters:[{name:"input_ids",val:": LongTensor"},{name:"next_scores",val:": FloatTensor"},{name:"next_tokens",val:": LongTensor"},{name:"next_indices",val:": LongTensor"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_beam_search.py#L92",parametersDescription:[{anchor:"transformers.BeamScorer.process.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size * num_beams, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using any class inheriting from <a href="/docs/transformers/v4.16.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer">PreTrainedTokenizer</a>. See
<a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">PreTrainedTokenizer.encode()</a> and <a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.BeamScorer.process.next_scores",description:`<strong>next_scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, 2 * num_beams)</code>) &#x2014;
Current scores of the top <code>2 * num_beams</code> non-finished beam hypotheses.`,name:"next_scores"},{anchor:"transformers.BeamScorer.process.next_tokens",description:`<strong>next_tokens</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, 2 * num_beams)</code>) &#x2014;
<code>input_ids</code> of the tokens corresponding to the top <code>2 * num_beams</code> non-finished beam hypotheses.`,name:"next_tokens"},{anchor:"transformers.BeamScorer.process.next_indices",description:`<strong>next_indices</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, 2 * num_beams)</code>) &#x2014;
Beam indices indicating to which beam hypothesis the <code>next_tokens</code> correspond.`,name:"next_indices"},{anchor:"transformers.BeamScorer.process.pad_token_id",description:`<strong>pad_token_id</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The id of the <em>padding</em> token.`,name:"pad_token_id"},{anchor:"transformers.BeamScorer.process.eos_token_id",description:`<strong>eos_token_id</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The id of the <em>end-of-sequence</em> token.`,name:"eos_token_id"}],returnDescription:`
<p>A dictionary composed of the fields as defined above:</p>
<ul>
<li><strong>next_beam_scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size * num_beams)</code>) \u2014 Updated scores of all
non-finished beams.</li>
<li><strong>next_beam_tokens</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size * num_beams)</code>) \u2014 Next tokens to be added
to the non-finished beam_hypotheses.</li>
<li><strong>next_beam_indices</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size * num_beams)</code>) \u2014 Beam indices
indicating to which beam the next tokens shall be added.</li>
</ul>
`,returnType:`
<p><code>UserDict</code></p>
`}}),Po=new b({props:{name:"finalize",anchor:"transformers.BeamScorer.finalize",parameters:[{name:"input_ids",val:": LongTensor"},{name:"next_scores",val:": FloatTensor"},{name:"next_tokens",val:": LongTensor"},{name:"next_indices",val:": LongTensor"},{name:"max_length",val:": int"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_beam_search.py#L104",parametersDescription:[{anchor:"transformers.BeamScorer.finalize.input_ids",description:`<strong>input_ids</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size * num_beams, sequence_length)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using any class inheriting from <a href="/docs/transformers/v4.16.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer">PreTrainedTokenizer</a>. See
<a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.encode">PreTrainedTokenizer.encode()</a> and <a href="/docs/transformers/v4.16.2/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.BeamScorer.finalize.final_beam_scores",description:`<strong>final_beam_scores</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size * num_beams)</code>) &#x2014;
The final scores of all non-finished beams.`,name:"final_beam_scores"},{anchor:"transformers.BeamScorer.finalize.final_beam_tokens",description:`<strong>final_beam_tokens</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size * num_beams)</code>) &#x2014;
The last tokens to be added to the non-finished beam_hypotheses.`,name:"final_beam_tokens"},{anchor:"transformers.BeamScorer.finalize.final_beam_indices",description:`<strong>final_beam_indices</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size * num_beams)</code>) &#x2014;
The beam indices indicating to which beam the <code>final_beam_tokens</code> shall be added.`,name:"final_beam_indices"},{anchor:"transformers.BeamScorer.finalize.pad_token_id",description:`<strong>pad_token_id</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The id of the <em>padding</em> token.`,name:"pad_token_id"},{anchor:"transformers.BeamScorer.finalize.eos_token_id",description:`<strong>eos_token_id</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The id of the <em>end-of-sequence</em> token.`,name:"eos_token_id"}],returnDescription:`
<p>The generated sequences.
The second dimension (sequence_length) is either equal to <code>max_length</code> or shorter if all batches finished early
due to the <code>eos_token_id</code>.</p>
`,returnType:`
<p><code>torch.LongTensor</code> of shape <code>(batch_size * num_return_sequences, sequence_length)</code></p>
`}}),Do=new b({props:{name:"class transformers.BeamSearchScorer",anchor:"transformers.BeamSearchScorer",parameters:[{name:"batch_size",val:": int"},{name:"num_beams",val:": int"},{name:"device",val:": device"},{name:"length_penalty",val:": typing.Optional[float] = 1.0"},{name:"do_early_stopping",val:": typing.Optional[bool] = False"},{name:"num_beam_hyps_to_keep",val:": typing.Optional[int] = 1"},{name:"num_beam_groups",val:": typing.Optional[int] = 1"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_beam_search.py#L118",parametersDescription:[{anchor:"transformers.BeamSearchScorer.batch_size",description:`<strong>batch_size</strong> (<code>int</code>) &#x2014;
Batch Size of <code>input_ids</code> for which standard beam search decoding is run in parallel.`,name:"batch_size"},{anchor:"transformers.BeamSearchScorer.max_length",description:`<strong>max_length</strong> (<code>int</code>) &#x2014;
The maximum length of the sequence to be generated.`,name:"max_length"},{anchor:"transformers.BeamSearchScorer.num_beams",description:`<strong>num_beams</strong> (<code>int</code>) &#x2014;
Number of beams for beam search.`,name:"num_beams"},{anchor:"transformers.BeamSearchScorer.device",description:`<strong>device</strong> (<code>torch.device</code>) &#x2014;
Defines the device type (<em>e.g.</em>, <code>&quot;cpu&quot;</code> or <code>&quot;cuda&quot;</code>) on which this instance of <code>BeamSearchScorer</code> will be
allocated.`,name:"device"},{anchor:"transformers.BeamSearchScorer.length_penalty",description:`<strong>length_penalty</strong> (<code>float</code>, <em>optional</em>, defaults to 1.0) &#x2014;
Exponential penalty to the length. 1.0 means no penalty. Set to values &lt; 1.0 in order to encourage the
model to generate shorter sequences, to a value &gt; 1.0 in order to encourage the model to produce longer
sequences.`,name:"length_penalty"},{anchor:"transformers.BeamSearchScorer.do_early_stopping",description:`<strong>do_early_stopping</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to stop the beam search when at least <code>num_beams</code> sentences are finished per batch or not.`,name:"do_early_stopping"},{anchor:"transformers.BeamSearchScorer.num_beam_hyps_to_keep",description:`<strong>num_beam_hyps_to_keep</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
The number of beam hypotheses that shall be returned upon calling
<code>finalize</code>.`,name:"num_beam_hyps_to_keep"},{anchor:"transformers.BeamSearchScorer.num_beam_groups",description:`<strong>num_beam_groups</strong> (<code>int</code>) &#x2014;
Number of groups to divide <code>num_beams</code> into in order to ensure diversity among different groups of beams.
See <a href="https://arxiv.org/pdf/1610.02424.pdf" rel="nofollow">this paper</a> for more details.`,name:"num_beam_groups"}]}}),So=new $e({}),qo=new b({props:{name:"transformers.top_k_top_p_filtering",anchor:"transformers.top_k_top_p_filtering",parameters:[{name:"logits",val:": FloatTensor"},{name:"top_k",val:": int = 0"},{name:"top_p",val:": float = 1.0"},{name:"filter_value",val:": float = -inf"},{name:"min_tokens_to_keep",val:": int = 1"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_utils.py#L2788",parametersDescription:[{anchor:"transformers.top_k_top_p_filtering.top_k",description:`<strong>top_k</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
If &gt; 0, only keep the top k tokens with highest probability (top-k filtering)`,name:"top_k"},{anchor:"transformers.top_k_top_p_filtering.top_p",description:`<strong>top_p</strong> (<code>float</code>, <em>optional</em>, defaults to 1.0) &#x2014;
If &lt; 1.0, only keep the top tokens with cumulative probability &gt;= top_p (nucleus filtering). Nucleus
filtering is described in Holtzman et al. (<a href="http://arxiv.org/abs/1904.09751" rel="nofollow">http://arxiv.org/abs/1904.09751</a>)`,name:"top_p"},{anchor:"transformers.top_k_top_p_filtering.min_tokens_to_keep",description:`<strong>min_tokens_to_keep</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
Minimumber of tokens we keep per batch example in the output.`,name:"min_tokens_to_keep"}]}}),Io=new b({props:{name:"transformers.tf_top_k_top_p_filtering",anchor:"transformers.tf_top_k_top_p_filtering",parameters:[{name:"logits",val:""},{name:"top_k",val:" = 0"},{name:"top_p",val:" = 1.0"},{name:"filter_value",val:" = -inf"},{name:"min_tokens_to_keep",val:" = 1"}],source:"https://github.com/huggingface/transformers/blob/v4.16.2/src/transformers/generation_tf_utils.py#L1569",parametersDescription:[{anchor:"transformers.tf_top_k_top_p_filtering.top_k",description:`<strong>top_k</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
If &gt; 0, only keep the top k tokens with highest probability (top-k filtering)`,name:"top_k"},{anchor:"transformers.tf_top_k_top_p_filtering.top_p",description:`<strong>top_p</strong> (<code>float</code>, <em>optional</em>, defaults to 1.0) &#x2014;
If &lt; 1.0, only keep the top tokens with cumulative probability &gt;= top_p (nucleus filtering). Nucleus
filtering is described in Holtzman et al. (<a href="http://arxiv.org/abs/1904.09751" rel="nofollow">http://arxiv.org/abs/1904.09751</a>)`,name:"top_p"},{anchor:"transformers.tf_top_k_top_p_filtering.min_tokens_to_keep",description:`<strong>min_tokens_to_keep</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014;
Minimumber of tokens we keep per batch example in the output.`,name:"min_tokens_to_keep"}]}}),{c(){ge=r("meta"),Wo=d(),S=r("h1"),N=r("a"),Wn=r("span"),f(ft.$$.fragment),Ec=d(),Vn=r("span"),Lc=a("Utilities for Generation"),Ba=d(),T=r("p"),Pc=a("This page lists all the utility functions used by "),Vo=r("a"),Dc=a("generate()"),zc=a(`,
`),Mo=r("a"),Oc=a("greedy_search()"),Fc=a(`,
`),Co=r("a"),Sc=a("sample()"),qc=a(`,
`),Go=r("a"),Bc=a("beam_search()"),Ic=a(`,
`),Ho=r("a"),Ac=a("beam_sample()"),Nc=a(`, and
`),jo=r("a"),Wc=a("group_beam_search()"),Vc=a("."),Ia=d(),Ro=r("p"),Mc=a("Most of those are only useful if you are studying the code of the generate methods in the library."),Aa=d(),ke=r("h2"),Ce=r("a"),Mn=r("span"),f(ht.$$.fragment),Cc=d(),Cn=r("span"),Gc=a("Generate Outputs"),Na=d(),q=r("p"),Hc=a("The output of "),Ko=r("a"),jc=a("generate()"),Rc=a(` is an instance of a subclass of
`),Uo=r("a"),Kc=a("ModelOutput"),Uc=a(`. This output is a data structure containing all the information returned
by `),Yo=r("a"),Yc=a("generate()"),Xc=a(", but that can also be used as tuple or dictionary."),Wa=d(),Xo=r("p"),Jc=a("Here\u2019s an example:"),Va=d(),f(mt.$$.fragment),Ma=d(),_e=r("p"),Qc=a("The "),Gn=r("code"),Zc=a("generation_output"),ed=a(" object is a "),Jo=r("a"),td=a("GreedySearchDecoderOnlyOutput"),od=a(`, as we can
see in the documentation of that class below, it means it has the following attributes:`),Ca=d(),B=r("ul"),Qo=r("li"),Hn=r("code"),rd=a("sequences"),nd=a(": the generated sequences of tokens"),sd=d(),Zo=r("li"),jn=r("code"),ad=a("scores"),id=a(" (optional): the prediction scores of the language modelling head, for each generation step"),cd=d(),er=r("li"),Rn=r("code"),dd=a("hidden_states"),ld=a(" (optional): the hidden states of the model, for each generation step"),pd=d(),tr=r("li"),Kn=r("code"),ud=a("attentions"),fd=a(" (optional): the attention weights of the model, for each generation step"),Ga=d(),y=r("p"),hd=a("Here we have the "),Un=r("code"),md=a("scores"),gd=a(" since we passed along "),Yn=r("code"),_d=a("output_scores=True"),vd=a(", but we don\u2019t have "),Xn=r("code"),bd=a("hidden_states"),Td=a(` and
`),Jn=r("code"),yd=a("attentions"),$d=a(" because we didn\u2019t pass "),Qn=r("code"),kd=a("output_hidden_states=True"),xd=a(" or "),Zn=r("code"),wd=a("output_attentions=True"),Ed=a("."),Ha=d(),w=r("p"),Ld=a(`You can access each attribute as you would usually do, and if that attribute has not been returned by the model, you
will get `),es=r("code"),Pd=a("None"),Dd=a(". Here for instance "),ts=r("code"),zd=a("generation_output.scores"),Od=a(` are all the generated prediction scores of the
language modeling head, and `),os=r("code"),Fd=a("generation_output.attentions"),Sd=a(" is "),rs=r("code"),qd=a("None"),Bd=a("."),ja=d(),E=r("p"),Id=a("When using our "),ns=r("code"),Ad=a("generation_output"),Nd=a(" object as a tuple, it only keeps the attributes that don\u2019t have "),ss=r("code"),Wd=a("None"),Vd=a(` values.
Here, for instance, it has two elements, `),as=r("code"),Md=a("loss"),Cd=a(" then "),is=r("code"),Gd=a("logits"),Hd=a(", so"),Ra=d(),f(gt.$$.fragment),Ka=d(),Ge=r("p"),jd=a("will return the tuple "),cs=r("code"),Rd=a("(generation_output.sequences, generation_output.scores)"),Kd=a(" for instance."),Ua=d(),L=r("p"),Ud=a("When using our "),ds=r("code"),Yd=a("generation_output"),Xd=a(" object as a dictionary, it only keeps the attributes that don\u2019t have "),ls=r("code"),Jd=a("None"),Qd=a(`
values. Here, for instance, it has two keys that are `),ps=r("code"),Zd=a("sequences"),el=a(" and "),us=r("code"),tl=a("scores"),ol=a("."),Ya=d(),or=r("p"),rl=a("We document here all output types."),Xa=d(),xe=r("h3"),He=r("a"),fs=r("span"),f(_t.$$.fragment),nl=d(),hs=r("span"),sl=a("GreedySearchOutput"),Ja=d(),we=r("div"),f(vt.$$.fragment),al=d(),ms=r("p"),il=a("Base class for outputs of decoder-only generation models using greedy search."),Qa=d(),Ee=r("div"),f(bt.$$.fragment),cl=d(),gs=r("p"),dl=a(`Base class for outputs of encoder-decoder generation models using greedy search. Hidden states and attention
weights of the decoder (respectively the encoder) can be accessed via the encoder_attentions and the
encoder_hidden_states attributes (respectively the decoder_attentions and the decoder_hidden_states attributes)`),Za=d(),W=r("div"),f(Tt.$$.fragment),ll=d(),_s=r("p"),pl=a("Flax Base class for outputs of decoder-only generation models using greedy search."),ul=d(),je=r("div"),f(yt.$$.fragment),fl=d(),vs=r("p"),hl=a("\u201CReturns a new object replacing the specified fields with new values."),ei=d(),Le=r("h3"),Re=r("a"),bs=r("span"),f($t.$$.fragment),ml=d(),Ts=r("span"),gl=a("SampleOutput"),ti=d(),Pe=r("div"),f(kt.$$.fragment),_l=d(),ys=r("p"),vl=a("Base class for outputs of decoder-only generation models using sampling."),oi=d(),De=r("div"),f(xt.$$.fragment),bl=d(),$s=r("p"),Tl=a(`Base class for outputs of encoder-decoder generation models using sampling. Hidden states and attention weights of
the decoder (respectively the encoder) can be accessed via the encoder_attentions and the encoder_hidden_states
attributes (respectively the decoder_attentions and the decoder_hidden_states attributes)`),ri=d(),V=r("div"),f(wt.$$.fragment),yl=d(),ks=r("p"),$l=a("Flax Base class for outputs of decoder-only generation models using sampling."),kl=d(),Ke=r("div"),f(Et.$$.fragment),xl=d(),xs=r("p"),wl=a("\u201CReturns a new object replacing the specified fields with new values."),ni=d(),ze=r("h3"),Ue=r("a"),ws=r("span"),f(Lt.$$.fragment),El=d(),Es=r("span"),Ll=a("BeamSearchOutput"),si=d(),Oe=r("div"),f(Pt.$$.fragment),Pl=d(),Ls=r("p"),Dl=a("Base class for outputs of decoder-only generation models using beam search."),ai=d(),Fe=r("div"),f(Dt.$$.fragment),zl=d(),Ps=r("p"),Ol=a(`Base class for outputs of encoder-decoder generation models using beam search. Hidden states and attention weights
of the decoder (respectively the encoder) can be accessed via the encoder_attentions and the encoder_hidden_states
attributes (respectively the decoder_attentions and the decoder_hidden_states attributes)`),ii=d(),Se=r("h3"),Ye=r("a"),Ds=r("span"),f(zt.$$.fragment),Fl=d(),zs=r("span"),Sl=a("BeamSampleOutput"),ci=d(),qe=r("div"),f(Ot.$$.fragment),ql=d(),Os=r("p"),Bl=a("Base class for outputs of decoder-only generation models using beam sample."),di=d(),Be=r("div"),f(Ft.$$.fragment),Il=d(),Fs=r("p"),Al=a(`Base class for outputs of encoder-decoder generation models using beam sampling. Hidden states and attention
weights of the decoder (respectively the encoder) can be accessed via the encoder_attentions and the
encoder_hidden_states attributes (respectively the decoder_attentions and the decoder_hidden_states attributes)`),li=d(),Ie=r("h2"),Xe=r("a"),Ss=r("span"),f(St.$$.fragment),Nl=d(),qs=r("span"),Wl=a("LogitsProcessor"),pi=d(),Je=r("p"),Vl=a("A "),rr=r("a"),Ml=a("LogitsProcessor"),Cl=a(` can be used to modify the prediction scores of a language model head for
generation.`),ui=d(),M=r("div"),f(qt.$$.fragment),Gl=d(),Bs=r("p"),Hl=a("Abstract base class for all logit processors that can be applied during generation."),jl=d(),Qe=r("div"),f(Bt.$$.fragment),Rl=d(),Is=r("p"),Kl=a("Torch method for processing logits."),fi=d(),C=r("div"),f(It.$$.fragment),Ul=d(),$=r("p"),Yl=a("This class can be used to create a list of "),nr=r("a"),Xl=a("LogitsProcessor"),Jl=a(" or "),sr=r("a"),Ql=a("LogitsWarper"),Zl=a(` to subsequently process a
`),As=r("code"),ep=a("scores"),tp=a(" input tensor. This class inherits from list and adds a specific "),Ns=r("em"),Ws=r("strong"),op=a("call"),rp=a(` method to apply each
`),ar=r("a"),np=a("LogitsProcessor"),sp=a(" or "),ir=r("a"),ap=a("LogitsWarper"),ip=a(" to the inputs."),cp=d(),cr=r("div"),f(At.$$.fragment),hi=d(),G=r("div"),f(Nt.$$.fragment),dp=d(),Vs=r("p"),lp=a("Abstract base class for all logit warpers that can be applied during generation with multinomial sampling."),pp=d(),Ze=r("div"),f(Wt.$$.fragment),up=d(),Ms=r("p"),fp=a("Torch method for warping logits."),mi=d(),H=r("div"),f(Vt.$$.fragment),hp=d(),dr=r("p"),lr=r("a"),mp=a("LogitsProcessor"),gp=a(" enforcing a min-length by setting EOS probability to 0."),_p=d(),Cs=r("div"),gi=d(),j=r("div"),f(Mt.$$.fragment),vp=d(),pr=r("p"),ur=r("a"),bp=a("LogitsWarper"),Tp=a(" for temperature (exponential scaling output probability distribution)."),yp=d(),Gs=r("div"),_i=d(),R=r("div"),f(Ct.$$.fragment),$p=d(),fr=r("p"),hr=r("a"),kp=a("LogitsProcessor"),xp=a(" enforcing an exponential penalty on repeated sequences."),wp=d(),Hs=r("div"),vi=d(),K=r("div"),f(Gt.$$.fragment),Ep=d(),mr=r("p"),gr=r("a"),Lp=a("LogitsWarper"),Pp=a(" that performs top-p, i.e. restricting to top tokens summing to prob_cut_off <= prob_cut_off."),Dp=d(),js=r("div"),bi=d(),U=r("div"),f(Ht.$$.fragment),zp=d(),_r=r("p"),vr=r("a"),Op=a("LogitsWarper"),Fp=a(" that performs top-k, i.e. restricting to the k highest probability elements."),Sp=d(),Rs=r("div"),Ti=d(),Y=r("div"),f(jt.$$.fragment),qp=d(),et=r("p"),br=r("a"),Bp=a("LogitsProcessor"),Ip=a(` that enforces no repetition of n-grams. See
`),Rt=r("a"),Ap=a("Fairseq"),Np=a("."),Wp=d(),Ks=r("div"),yi=d(),X=r("div"),f(Kt.$$.fragment),Vp=d(),Tr=r("p"),yr=r("a"),Mp=a("LogitsProcessor"),Cp=a(" that enforces that specified sequences will never be sampled."),Gp=d(),Us=r("div"),$i=d(),J=r("div"),f(Ut.$$.fragment),Hp=d(),tt=r("p"),$r=r("a"),jp=a("LogitsProcessor"),Rp=a(` that enforces constrained generation and is useful for prefix-conditioned constrained
generation. See `),Yt=r("a"),Kp=a("Autoregressive Entity Retrieval"),Up=a(" for more information."),Yp=d(),Ys=r("div"),ki=d(),Q=r("div"),f(Xt.$$.fragment),Xp=d(),ve=r("p"),kr=r("a"),Jp=a("LogitsProcessor"),Qp=a(` that enforces diverse beam search. Note that this logits processor is only effective for
`),xr=r("a"),Zp=a("PreTrainedModel.group_beam_search()"),eu=a(". See "),Jt=r("a"),tu=a(`Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence
Models`),ou=a(" for more details."),ru=d(),Xs=r("div"),xi=d(),Z=r("div"),f(Qt.$$.fragment),nu=d(),wr=r("p"),Er=r("a"),su=a("LogitsProcessor"),au=a(" that enforces the specified token as the first generated token."),iu=d(),Js=r("div"),wi=d(),ee=r("div"),f(Zt.$$.fragment),cu=d(),ot=r("p"),Lr=r("a"),du=a("LogitsProcessor"),lu=a(" that enforces the specified token as the last generated token when "),Qs=r("code"),pu=a("max_length"),uu=a(" is reached."),fu=d(),Zs=r("div"),Ei=d(),te=r("div"),f(eo.$$.fragment),hu=d(),I=r("p"),Pr=r("a"),mu=a("LogitsProcessor"),gu=a(" that removes all "),ea=r("code"),_u=a("nan"),vu=a(" and "),ta=r("code"),bu=a("inf"),Tu=a(` values to avoid the generation method to fail. Note that using
the logits processor should only be used if necessary since it can slow down the generation method. `),oa=r("code"),yu=a("max_length"),$u=a(` is
reached.`),ku=d(),ra=r("div"),Li=d(),oe=r("div"),f(to.$$.fragment),xu=d(),na=r("p"),wu=a("Abstract base class for all logit processors that can be applied during generation."),Eu=d(),rt=r("div"),f(oo.$$.fragment),Lu=d(),sa=r("p"),Pu=a("Flax method for processing logits."),Pi=d(),re=r("div"),f(ro.$$.fragment),Du=d(),k=r("p"),zu=a("This class can be used to create a list of "),Dr=r("a"),Ou=a("FlaxLogitsProcessor"),Fu=a(" or "),zr=r("a"),Su=a("FlaxLogitsWarper"),qu=a(` to subsequently process
a `),aa=r("code"),Bu=a("scores"),Iu=a(" input tensor. This class inherits from list and adds a specific "),ia=r("em"),ca=r("strong"),Au=a("call"),Nu=a(` method to apply each
`),Or=r("a"),Wu=a("FlaxLogitsProcessor"),Vu=a(" or "),Fr=r("a"),Mu=a("FlaxLogitsWarper"),Cu=a(" to the inputs."),Gu=d(),Sr=r("div"),f(no.$$.fragment),Di=d(),ne=r("div"),f(so.$$.fragment),Hu=d(),da=r("p"),ju=a("Abstract base class for all logit warpers that can be applied during generation with multinomial sampling."),Ru=d(),nt=r("div"),f(ao.$$.fragment),Ku=d(),la=r("p"),Uu=a("Flax method for warping logits."),zi=d(),se=r("div"),f(io.$$.fragment),Yu=d(),qr=r("p"),Br=r("a"),Xu=a("LogitsWarper"),Ju=a(" for temperature (exponential scaling output probability distribution)."),Qu=d(),pa=r("div"),Oi=d(),ae=r("div"),f(co.$$.fragment),Zu=d(),Ir=r("p"),Ar=r("a"),ef=a("LogitsWarper"),tf=a(" that performs top-p, i.e. restricting to top tokens summing to prob_cut_off <= prob_cut_off."),of=d(),ua=r("div"),Fi=d(),ie=r("div"),f(lo.$$.fragment),rf=d(),Nr=r("p"),Wr=r("a"),nf=a("LogitsWarper"),sf=a(" that performs top-k, i.e. restricting to the k highest probability elements."),af=d(),fa=r("div"),Si=d(),ce=r("div"),f(po.$$.fragment),cf=d(),Vr=r("p"),Mr=r("a"),df=a("FlaxLogitsProcessor"),lf=a(" that enforces the specified token as the first generated token."),pf=d(),ha=r("div"),qi=d(),de=r("div"),f(uo.$$.fragment),uf=d(),st=r("p"),Cr=r("a"),ff=a("FlaxLogitsProcessor"),hf=a(" that enforces the specified token as the last generated token when "),ma=r("code"),mf=a("max_length"),gf=a(" is reached."),_f=d(),ga=r("div"),Bi=d(),le=r("div"),f(fo.$$.fragment),vf=d(),Gr=r("p"),Hr=r("a"),bf=a("FlaxLogitsProcessor"),Tf=a(" enforcing a min-length by setting EOS probability to 0."),yf=d(),_a=r("div"),Ii=d(),Ae=r("h2"),at=r("a"),va=r("span"),f(ho.$$.fragment),$f=d(),ba=r("span"),kf=a("StoppingCriteria"),Ai=d(),it=r("p"),xf=a("A "),jr=r("a"),wf=a("StoppingCriteria"),Ef=a(" can be used to change when to stop generation (other than EOS token)."),Ni=d(),pe=r("div"),f(mo.$$.fragment),Lf=d(),Ta=r("p"),Pf=a("Abstract base class for all stopping criteria that can be applied during generation."),Df=d(),Rr=r("div"),f(go.$$.fragment),Wi=d(),_o=r("div"),Kr=r("div"),f(vo.$$.fragment),Vi=d(),ue=r("div"),f(bo.$$.fragment),zf=d(),To=r("p"),Of=a("This class can be used to stop generation whenever the full generated number of tokens exceeds "),ya=r("code"),Ff=a("max_length"),Sf=a(`. Keep
in mind for decoder-only type of transformers, this will include the initial prompted tokens.`),qf=d(),Ur=r("div"),f(yo.$$.fragment),Mi=d(),fe=r("div"),f($o.$$.fragment),Bf=d(),ko=r("p"),If=a(`This class can be used to stop generation whenever the full generation exceeds some amount of time. By default, the
time will start being counted when you initialize this function. You can override this by passing an
`),$a=r("code"),Af=a("initial_time"),Nf=a("."),Wf=d(),Yr=r("div"),f(xo.$$.fragment),Ci=d(),Ne=r("h2"),ct=r("a"),ka=r("span"),f(wo.$$.fragment),Vf=d(),xa=r("span"),Mf=a("BeamSearch"),Gi=d(),F=r("div"),f(Eo.$$.fragment),Cf=d(),We=r("p"),Gf=a("Abstract base class for all beam scorers that are used for "),Xr=r("a"),Hf=a("beam_search()"),jf=a(` and
`),Jr=r("a"),Rf=a("beam_sample()"),Kf=a("."),Uf=d(),Qr=r("div"),f(Lo.$$.fragment),Yf=d(),Zr=r("div"),f(Po.$$.fragment),Hi=d(),x=r("div"),f(Do.$$.fragment),Xf=d(),en=r("p"),tn=r("a"),Jf=a("BeamScorer"),Qf=a(" implementing standard beam search decoding."),Zf=d(),zo=r("p"),eh=a("Adapted in part from "),Oo=r("a"),th=a(`Facebook\u2019s XLM beam search
code`),oh=a("."),rh=d(),on=r("p"),nh=a("Reference for the diverse beam search algorithm and implementation "),Fo=r("a"),sh=a(`Ashwin Kalyan\u2019s DBS
implementation`),ah=d(),wa=r("div"),ih=d(),Ea=r("div"),ji=d(),Ve=r("h2"),dt=r("a"),La=r("span"),f(So.$$.fragment),ch=d(),Pa=r("span"),dh=a("Utilities"),Ri=d(),he=r("div"),f(qo.$$.fragment),lh=d(),Da=r("p"),ph=a("Filter a distribution of logits using top-k and/or nucleus (top-p) filtering"),uh=d(),rn=r("p"),fh=a("From: "),Bo=r("a"),hh=a("https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317"),Ki=d(),me=r("div"),f(Io.$$.fragment),mh=d(),za=r("p"),gh=a("Filter a distribution of logits using top-k and/or nucleus (top-p) filtering"),_h=d(),nn=r("p"),vh=a("From: "),Ao=r("a"),bh=a("https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317"),this.h()},l(e){const p=S_('[data-svelte="svelte-1phssyn"]',document.head);ge=n(p,"META",{name:!0,content:!0}),p.forEach(o),Wo=l(e),S=n(e,"H1",{class:!0});var Yi=s(S);N=n(Yi,"A",{id:!0,class:!0,href:!0});var Vh=s(N);Wn=n(Vh,"SPAN",{});var Mh=s(Wn);h(ft.$$.fragment,Mh),Mh.forEach(o),Vh.forEach(o),Ec=l(Yi),Vn=n(Yi,"SPAN",{});var Ch=s(Vn);Lc=i(Ch,"Utilities for Generation"),Ch.forEach(o),Yi.forEach(o),Ba=l(e),T=n(e,"P",{});var P=s(T);Pc=i(P,"This page lists all the utility functions used by "),Vo=n(P,"A",{href:!0});var Gh=s(Vo);Dc=i(Gh,"generate()"),Gh.forEach(o),zc=i(P,`,
`),Mo=n(P,"A",{href:!0});var Hh=s(Mo);Oc=i(Hh,"greedy_search()"),Hh.forEach(o),Fc=i(P,`,
`),Co=n(P,"A",{href:!0});var jh=s(Co);Sc=i(jh,"sample()"),jh.forEach(o),qc=i(P,`,
`),Go=n(P,"A",{href:!0});var Rh=s(Go);Bc=i(Rh,"beam_search()"),Rh.forEach(o),Ic=i(P,`,
`),Ho=n(P,"A",{href:!0});var Kh=s(Ho);Ac=i(Kh,"beam_sample()"),Kh.forEach(o),Nc=i(P,`, and
`),jo=n(P,"A",{href:!0});var Uh=s(jo);Wc=i(Uh,"group_beam_search()"),Uh.forEach(o),Vc=i(P,"."),P.forEach(o),Ia=l(e),Ro=n(e,"P",{});var Yh=s(Ro);Mc=i(Yh,"Most of those are only useful if you are studying the code of the generate methods in the library."),Yh.forEach(o),Aa=l(e),ke=n(e,"H2",{class:!0});var Xi=s(ke);Ce=n(Xi,"A",{id:!0,class:!0,href:!0});var Xh=s(Ce);Mn=n(Xh,"SPAN",{});var Jh=s(Mn);h(ht.$$.fragment,Jh),Jh.forEach(o),Xh.forEach(o),Cc=l(Xi),Cn=n(Xi,"SPAN",{});var Qh=s(Cn);Gc=i(Qh,"Generate Outputs"),Qh.forEach(o),Xi.forEach(o),Na=l(e),q=n(e,"P",{});var lt=s(q);Hc=i(lt,"The output of "),Ko=n(lt,"A",{href:!0});var Zh=s(Ko);jc=i(Zh,"generate()"),Zh.forEach(o),Rc=i(lt,` is an instance of a subclass of
`),Uo=n(lt,"A",{href:!0});var em=s(Uo);Kc=i(em,"ModelOutput"),em.forEach(o),Uc=i(lt,`. This output is a data structure containing all the information returned
by `),Yo=n(lt,"A",{href:!0});var tm=s(Yo);Yc=i(tm,"generate()"),tm.forEach(o),Xc=i(lt,", but that can also be used as tuple or dictionary."),lt.forEach(o),Wa=l(e),Xo=n(e,"P",{});var om=s(Xo);Jc=i(om,"Here\u2019s an example:"),om.forEach(o),Va=l(e),h(mt.$$.fragment,e),Ma=l(e),_e=n(e,"P",{});var sn=s(_e);Qc=i(sn,"The "),Gn=n(sn,"CODE",{});var rm=s(Gn);Zc=i(rm,"generation_output"),rm.forEach(o),ed=i(sn," object is a "),Jo=n(sn,"A",{href:!0});var nm=s(Jo);td=i(nm,"GreedySearchDecoderOnlyOutput"),nm.forEach(o),od=i(sn,`, as we can
see in the documentation of that class below, it means it has the following attributes:`),sn.forEach(o),Ca=l(e),B=n(e,"UL",{});var pt=s(B);Qo=n(pt,"LI",{});var Th=s(Qo);Hn=n(Th,"CODE",{});var sm=s(Hn);rd=i(sm,"sequences"),sm.forEach(o),nd=i(Th,": the generated sequences of tokens"),Th.forEach(o),sd=l(pt),Zo=n(pt,"LI",{});var yh=s(Zo);jn=n(yh,"CODE",{});var am=s(jn);ad=i(am,"scores"),am.forEach(o),id=i(yh," (optional): the prediction scores of the language modelling head, for each generation step"),yh.forEach(o),cd=l(pt),er=n(pt,"LI",{});var $h=s(er);Rn=n($h,"CODE",{});var im=s(Rn);dd=i(im,"hidden_states"),im.forEach(o),ld=i($h," (optional): the hidden states of the model, for each generation step"),$h.forEach(o),pd=l(pt),tr=n(pt,"LI",{});var kh=s(tr);Kn=n(kh,"CODE",{});var cm=s(Kn);ud=i(cm,"attentions"),cm.forEach(o),fd=i(kh," (optional): the attention weights of the model, for each generation step"),kh.forEach(o),pt.forEach(o),Ga=l(e),y=n(e,"P",{});var D=s(y);hd=i(D,"Here we have the "),Un=n(D,"CODE",{});var dm=s(Un);md=i(dm,"scores"),dm.forEach(o),gd=i(D," since we passed along "),Yn=n(D,"CODE",{});var lm=s(Yn);_d=i(lm,"output_scores=True"),lm.forEach(o),vd=i(D,", but we don\u2019t have "),Xn=n(D,"CODE",{});var pm=s(Xn);bd=i(pm,"hidden_states"),pm.forEach(o),Td=i(D,` and
`),Jn=n(D,"CODE",{});var um=s(Jn);yd=i(um,"attentions"),um.forEach(o),$d=i(D," because we didn\u2019t pass "),Qn=n(D,"CODE",{});var fm=s(Qn);kd=i(fm,"output_hidden_states=True"),fm.forEach(o),xd=i(D," or "),Zn=n(D,"CODE",{});var hm=s(Zn);wd=i(hm,"output_attentions=True"),hm.forEach(o),Ed=i(D,"."),D.forEach(o),Ha=l(e),w=n(e,"P",{});var be=s(w);Ld=i(be,`You can access each attribute as you would usually do, and if that attribute has not been returned by the model, you
will get `),es=n(be,"CODE",{});var mm=s(es);Pd=i(mm,"None"),mm.forEach(o),Dd=i(be,". Here for instance "),ts=n(be,"CODE",{});var gm=s(ts);zd=i(gm,"generation_output.scores"),gm.forEach(o),Od=i(be,` are all the generated prediction scores of the
language modeling head, and `),os=n(be,"CODE",{});var _m=s(os);Fd=i(_m,"generation_output.attentions"),_m.forEach(o),Sd=i(be," is "),rs=n(be,"CODE",{});var vm=s(rs);qd=i(vm,"None"),vm.forEach(o),Bd=i(be,"."),be.forEach(o),ja=l(e),E=n(e,"P",{});var Te=s(E);Id=i(Te,"When using our "),ns=n(Te,"CODE",{});var bm=s(ns);Ad=i(bm,"generation_output"),bm.forEach(o),Nd=i(Te," object as a tuple, it only keeps the attributes that don\u2019t have "),ss=n(Te,"CODE",{});var Tm=s(ss);Wd=i(Tm,"None"),Tm.forEach(o),Vd=i(Te,` values.
Here, for instance, it has two elements, `),as=n(Te,"CODE",{});var ym=s(as);Md=i(ym,"loss"),ym.forEach(o),Cd=i(Te," then "),is=n(Te,"CODE",{});var $m=s(is);Gd=i($m,"logits"),$m.forEach(o),Hd=i(Te,", so"),Te.forEach(o),Ra=l(e),h(gt.$$.fragment,e),Ka=l(e),Ge=n(e,"P",{});var Ji=s(Ge);jd=i(Ji,"will return the tuple "),cs=n(Ji,"CODE",{});var km=s(cs);Rd=i(km,"(generation_output.sequences, generation_output.scores)"),km.forEach(o),Kd=i(Ji," for instance."),Ji.forEach(o),Ua=l(e),L=n(e,"P",{});var ye=s(L);Ud=i(ye,"When using our "),ds=n(ye,"CODE",{});var xm=s(ds);Yd=i(xm,"generation_output"),xm.forEach(o),Xd=i(ye," object as a dictionary, it only keeps the attributes that don\u2019t have "),ls=n(ye,"CODE",{});var wm=s(ls);Jd=i(wm,"None"),wm.forEach(o),Qd=i(ye,`
values. Here, for instance, it has two keys that are `),ps=n(ye,"CODE",{});var Em=s(ps);Zd=i(Em,"sequences"),Em.forEach(o),el=i(ye," and "),us=n(ye,"CODE",{});var Lm=s(us);tl=i(Lm,"scores"),Lm.forEach(o),ol=i(ye,"."),ye.forEach(o),Ya=l(e),or=n(e,"P",{});var Pm=s(or);rl=i(Pm,"We document here all output types."),Pm.forEach(o),Xa=l(e),xe=n(e,"H3",{class:!0});var Qi=s(xe);He=n(Qi,"A",{id:!0,class:!0,href:!0});var Dm=s(He);fs=n(Dm,"SPAN",{});var zm=s(fs);h(_t.$$.fragment,zm),zm.forEach(o),Dm.forEach(o),nl=l(Qi),hs=n(Qi,"SPAN",{});var Om=s(hs);sl=i(Om,"GreedySearchOutput"),Om.forEach(o),Qi.forEach(o),Ja=l(e),we=n(e,"DIV",{class:!0});var Zi=s(we);h(vt.$$.fragment,Zi),al=l(Zi),ms=n(Zi,"P",{});var Fm=s(ms);il=i(Fm,"Base class for outputs of decoder-only generation models using greedy search."),Fm.forEach(o),Zi.forEach(o),Qa=l(e),Ee=n(e,"DIV",{class:!0});var ec=s(Ee);h(bt.$$.fragment,ec),cl=l(ec),gs=n(ec,"P",{});var Sm=s(gs);dl=i(Sm,`Base class for outputs of encoder-decoder generation models using greedy search. Hidden states and attention
weights of the decoder (respectively the encoder) can be accessed via the encoder_attentions and the
encoder_hidden_states attributes (respectively the decoder_attentions and the decoder_hidden_states attributes)`),Sm.forEach(o),ec.forEach(o),Za=l(e),W=n(e,"DIV",{class:!0});var an=s(W);h(Tt.$$.fragment,an),ll=l(an),_s=n(an,"P",{});var qm=s(_s);pl=i(qm,"Flax Base class for outputs of decoder-only generation models using greedy search."),qm.forEach(o),ul=l(an),je=n(an,"DIV",{class:!0});var tc=s(je);h(yt.$$.fragment,tc),fl=l(tc),vs=n(tc,"P",{});var Bm=s(vs);hl=i(Bm,"\u201CReturns a new object replacing the specified fields with new values."),Bm.forEach(o),tc.forEach(o),an.forEach(o),ei=l(e),Le=n(e,"H3",{class:!0});var oc=s(Le);Re=n(oc,"A",{id:!0,class:!0,href:!0});var Im=s(Re);bs=n(Im,"SPAN",{});var Am=s(bs);h($t.$$.fragment,Am),Am.forEach(o),Im.forEach(o),ml=l(oc),Ts=n(oc,"SPAN",{});var Nm=s(Ts);gl=i(Nm,"SampleOutput"),Nm.forEach(o),oc.forEach(o),ti=l(e),Pe=n(e,"DIV",{class:!0});var rc=s(Pe);h(kt.$$.fragment,rc),_l=l(rc),ys=n(rc,"P",{});var Wm=s(ys);vl=i(Wm,"Base class for outputs of decoder-only generation models using sampling."),Wm.forEach(o),rc.forEach(o),oi=l(e),De=n(e,"DIV",{class:!0});var nc=s(De);h(xt.$$.fragment,nc),bl=l(nc),$s=n(nc,"P",{});var Vm=s($s);Tl=i(Vm,`Base class for outputs of encoder-decoder generation models using sampling. Hidden states and attention weights of
the decoder (respectively the encoder) can be accessed via the encoder_attentions and the encoder_hidden_states
attributes (respectively the decoder_attentions and the decoder_hidden_states attributes)`),Vm.forEach(o),nc.forEach(o),ri=l(e),V=n(e,"DIV",{class:!0});var cn=s(V);h(wt.$$.fragment,cn),yl=l(cn),ks=n(cn,"P",{});var Mm=s(ks);$l=i(Mm,"Flax Base class for outputs of decoder-only generation models using sampling."),Mm.forEach(o),kl=l(cn),Ke=n(cn,"DIV",{class:!0});var sc=s(Ke);h(Et.$$.fragment,sc),xl=l(sc),xs=n(sc,"P",{});var Cm=s(xs);wl=i(Cm,"\u201CReturns a new object replacing the specified fields with new values."),Cm.forEach(o),sc.forEach(o),cn.forEach(o),ni=l(e),ze=n(e,"H3",{class:!0});var ac=s(ze);Ue=n(ac,"A",{id:!0,class:!0,href:!0});var Gm=s(Ue);ws=n(Gm,"SPAN",{});var Hm=s(ws);h(Lt.$$.fragment,Hm),Hm.forEach(o),Gm.forEach(o),El=l(ac),Es=n(ac,"SPAN",{});var jm=s(Es);Ll=i(jm,"BeamSearchOutput"),jm.forEach(o),ac.forEach(o),si=l(e),Oe=n(e,"DIV",{class:!0});var ic=s(Oe);h(Pt.$$.fragment,ic),Pl=l(ic),Ls=n(ic,"P",{});var Rm=s(Ls);Dl=i(Rm,"Base class for outputs of decoder-only generation models using beam search."),Rm.forEach(o),ic.forEach(o),ai=l(e),Fe=n(e,"DIV",{class:!0});var cc=s(Fe);h(Dt.$$.fragment,cc),zl=l(cc),Ps=n(cc,"P",{});var Km=s(Ps);Ol=i(Km,`Base class for outputs of encoder-decoder generation models using beam search. Hidden states and attention weights
of the decoder (respectively the encoder) can be accessed via the encoder_attentions and the encoder_hidden_states
attributes (respectively the decoder_attentions and the decoder_hidden_states attributes)`),Km.forEach(o),cc.forEach(o),ii=l(e),Se=n(e,"H3",{class:!0});var dc=s(Se);Ye=n(dc,"A",{id:!0,class:!0,href:!0});var Um=s(Ye);Ds=n(Um,"SPAN",{});var Ym=s(Ds);h(zt.$$.fragment,Ym),Ym.forEach(o),Um.forEach(o),Fl=l(dc),zs=n(dc,"SPAN",{});var Xm=s(zs);Sl=i(Xm,"BeamSampleOutput"),Xm.forEach(o),dc.forEach(o),ci=l(e),qe=n(e,"DIV",{class:!0});var lc=s(qe);h(Ot.$$.fragment,lc),ql=l(lc),Os=n(lc,"P",{});var Jm=s(Os);Bl=i(Jm,"Base class for outputs of decoder-only generation models using beam sample."),Jm.forEach(o),lc.forEach(o),di=l(e),Be=n(e,"DIV",{class:!0});var pc=s(Be);h(Ft.$$.fragment,pc),Il=l(pc),Fs=n(pc,"P",{});var Qm=s(Fs);Al=i(Qm,`Base class for outputs of encoder-decoder generation models using beam sampling. Hidden states and attention
weights of the decoder (respectively the encoder) can be accessed via the encoder_attentions and the
encoder_hidden_states attributes (respectively the decoder_attentions and the decoder_hidden_states attributes)`),Qm.forEach(o),pc.forEach(o),li=l(e),Ie=n(e,"H2",{class:!0});var uc=s(Ie);Xe=n(uc,"A",{id:!0,class:!0,href:!0});var Zm=s(Xe);Ss=n(Zm,"SPAN",{});var eg=s(Ss);h(St.$$.fragment,eg),eg.forEach(o),Zm.forEach(o),Nl=l(uc),qs=n(uc,"SPAN",{});var tg=s(qs);Wl=i(tg,"LogitsProcessor"),tg.forEach(o),uc.forEach(o),pi=l(e),Je=n(e,"P",{});var fc=s(Je);Vl=i(fc,"A "),rr=n(fc,"A",{href:!0});var og=s(rr);Ml=i(og,"LogitsProcessor"),og.forEach(o),Cl=i(fc,` can be used to modify the prediction scores of a language model head for
generation.`),fc.forEach(o),ui=l(e),M=n(e,"DIV",{class:!0});var dn=s(M);h(qt.$$.fragment,dn),Gl=l(dn),Bs=n(dn,"P",{});var rg=s(Bs);Hl=i(rg,"Abstract base class for all logit processors that can be applied during generation."),rg.forEach(o),jl=l(dn),Qe=n(dn,"DIV",{class:!0});var hc=s(Qe);h(Bt.$$.fragment,hc),Rl=l(hc),Is=n(hc,"P",{});var ng=s(Is);Kl=i(ng,"Torch method for processing logits."),ng.forEach(o),hc.forEach(o),dn.forEach(o),fi=l(e),C=n(e,"DIV",{class:!0});var ln=s(C);h(It.$$.fragment,ln),Ul=l(ln),$=n(ln,"P",{});var z=s($);Yl=i(z,"This class can be used to create a list of "),nr=n(z,"A",{href:!0});var sg=s(nr);Xl=i(sg,"LogitsProcessor"),sg.forEach(o),Jl=i(z," or "),sr=n(z,"A",{href:!0});var ag=s(sr);Ql=i(ag,"LogitsWarper"),ag.forEach(o),Zl=i(z,` to subsequently process a
`),As=n(z,"CODE",{});var ig=s(As);ep=i(ig,"scores"),ig.forEach(o),tp=i(z," input tensor. This class inherits from list and adds a specific "),Ns=n(z,"EM",{});var cg=s(Ns);Ws=n(cg,"STRONG",{});var dg=s(Ws);op=i(dg,"call"),dg.forEach(o),cg.forEach(o),rp=i(z,` method to apply each
`),ar=n(z,"A",{href:!0});var lg=s(ar);np=i(lg,"LogitsProcessor"),lg.forEach(o),sp=i(z," or "),ir=n(z,"A",{href:!0});var pg=s(ir);ap=i(pg,"LogitsWarper"),pg.forEach(o),ip=i(z," to the inputs."),z.forEach(o),cp=l(ln),cr=n(ln,"DIV",{class:!0});var ug=s(cr);h(At.$$.fragment,ug),ug.forEach(o),ln.forEach(o),hi=l(e),G=n(e,"DIV",{class:!0});var pn=s(G);h(Nt.$$.fragment,pn),dp=l(pn),Vs=n(pn,"P",{});var fg=s(Vs);lp=i(fg,"Abstract base class for all logit warpers that can be applied during generation with multinomial sampling."),fg.forEach(o),pp=l(pn),Ze=n(pn,"DIV",{class:!0});var mc=s(Ze);h(Wt.$$.fragment,mc),up=l(mc),Ms=n(mc,"P",{});var hg=s(Ms);fp=i(hg,"Torch method for warping logits."),hg.forEach(o),mc.forEach(o),pn.forEach(o),mi=l(e),H=n(e,"DIV",{class:!0});var un=s(H);h(Vt.$$.fragment,un),hp=l(un),dr=n(un,"P",{});var xh=s(dr);lr=n(xh,"A",{href:!0});var mg=s(lr);mp=i(mg,"LogitsProcessor"),mg.forEach(o),gp=i(xh," enforcing a min-length by setting EOS probability to 0."),xh.forEach(o),_p=l(un),Cs=n(un,"DIV",{class:!0}),s(Cs).forEach(o),un.forEach(o),gi=l(e),j=n(e,"DIV",{class:!0});var fn=s(j);h(Mt.$$.fragment,fn),vp=l(fn),pr=n(fn,"P",{});var wh=s(pr);ur=n(wh,"A",{href:!0});var gg=s(ur);bp=i(gg,"LogitsWarper"),gg.forEach(o),Tp=i(wh," for temperature (exponential scaling output probability distribution)."),wh.forEach(o),yp=l(fn),Gs=n(fn,"DIV",{class:!0}),s(Gs).forEach(o),fn.forEach(o),_i=l(e),R=n(e,"DIV",{class:!0});var hn=s(R);h(Ct.$$.fragment,hn),$p=l(hn),fr=n(hn,"P",{});var Eh=s(fr);hr=n(Eh,"A",{href:!0});var _g=s(hr);kp=i(_g,"LogitsProcessor"),_g.forEach(o),xp=i(Eh," enforcing an exponential penalty on repeated sequences."),Eh.forEach(o),wp=l(hn),Hs=n(hn,"DIV",{class:!0}),s(Hs).forEach(o),hn.forEach(o),vi=l(e),K=n(e,"DIV",{class:!0});var mn=s(K);h(Gt.$$.fragment,mn),Ep=l(mn),mr=n(mn,"P",{});var Lh=s(mr);gr=n(Lh,"A",{href:!0});var vg=s(gr);Lp=i(vg,"LogitsWarper"),vg.forEach(o),Pp=i(Lh," that performs top-p, i.e. restricting to top tokens summing to prob_cut_off <= prob_cut_off."),Lh.forEach(o),Dp=l(mn),js=n(mn,"DIV",{class:!0}),s(js).forEach(o),mn.forEach(o),bi=l(e),U=n(e,"DIV",{class:!0});var gn=s(U);h(Ht.$$.fragment,gn),zp=l(gn),_r=n(gn,"P",{});var Ph=s(_r);vr=n(Ph,"A",{href:!0});var bg=s(vr);Op=i(bg,"LogitsWarper"),bg.forEach(o),Fp=i(Ph," that performs top-k, i.e. restricting to the k highest probability elements."),Ph.forEach(o),Sp=l(gn),Rs=n(gn,"DIV",{class:!0}),s(Rs).forEach(o),gn.forEach(o),Ti=l(e),Y=n(e,"DIV",{class:!0});var _n=s(Y);h(jt.$$.fragment,_n),qp=l(_n),et=n(_n,"P",{});var Oa=s(et);br=n(Oa,"A",{href:!0});var Tg=s(br);Bp=i(Tg,"LogitsProcessor"),Tg.forEach(o),Ip=i(Oa,` that enforces no repetition of n-grams. See
`),Rt=n(Oa,"A",{href:!0,rel:!0});var yg=s(Rt);Ap=i(yg,"Fairseq"),yg.forEach(o),Np=i(Oa,"."),Oa.forEach(o),Wp=l(_n),Ks=n(_n,"DIV",{class:!0}),s(Ks).forEach(o),_n.forEach(o),yi=l(e),X=n(e,"DIV",{class:!0});var vn=s(X);h(Kt.$$.fragment,vn),Vp=l(vn),Tr=n(vn,"P",{});var Dh=s(Tr);yr=n(Dh,"A",{href:!0});var $g=s(yr);Mp=i($g,"LogitsProcessor"),$g.forEach(o),Cp=i(Dh," that enforces that specified sequences will never be sampled."),Dh.forEach(o),Gp=l(vn),Us=n(vn,"DIV",{class:!0}),s(Us).forEach(o),vn.forEach(o),$i=l(e),J=n(e,"DIV",{class:!0});var bn=s(J);h(Ut.$$.fragment,bn),Hp=l(bn),tt=n(bn,"P",{});var Fa=s(tt);$r=n(Fa,"A",{href:!0});var kg=s($r);jp=i(kg,"LogitsProcessor"),kg.forEach(o),Rp=i(Fa,` that enforces constrained generation and is useful for prefix-conditioned constrained
generation. See `),Yt=n(Fa,"A",{href:!0,rel:!0});var xg=s(Yt);Kp=i(xg,"Autoregressive Entity Retrieval"),xg.forEach(o),Up=i(Fa," for more information."),Fa.forEach(o),Yp=l(bn),Ys=n(bn,"DIV",{class:!0}),s(Ys).forEach(o),bn.forEach(o),ki=l(e),Q=n(e,"DIV",{class:!0});var Tn=s(Q);h(Xt.$$.fragment,Tn),Xp=l(Tn),ve=n(Tn,"P",{});var No=s(ve);kr=n(No,"A",{href:!0});var wg=s(kr);Jp=i(wg,"LogitsProcessor"),wg.forEach(o),Qp=i(No,` that enforces diverse beam search. Note that this logits processor is only effective for
`),xr=n(No,"A",{href:!0});var Eg=s(xr);Zp=i(Eg,"PreTrainedModel.group_beam_search()"),Eg.forEach(o),eu=i(No,". See "),Jt=n(No,"A",{href:!0,rel:!0});var Lg=s(Jt);tu=i(Lg,`Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence
Models`),Lg.forEach(o),ou=i(No," for more details."),No.forEach(o),ru=l(Tn),Xs=n(Tn,"DIV",{class:!0}),s(Xs).forEach(o),Tn.forEach(o),xi=l(e),Z=n(e,"DIV",{class:!0});var yn=s(Z);h(Qt.$$.fragment,yn),nu=l(yn),wr=n(yn,"P",{});var zh=s(wr);Er=n(zh,"A",{href:!0});var Pg=s(Er);su=i(Pg,"LogitsProcessor"),Pg.forEach(o),au=i(zh," that enforces the specified token as the first generated token."),zh.forEach(o),iu=l(yn),Js=n(yn,"DIV",{class:!0}),s(Js).forEach(o),yn.forEach(o),wi=l(e),ee=n(e,"DIV",{class:!0});var $n=s(ee);h(Zt.$$.fragment,$n),cu=l($n),ot=n($n,"P",{});var Sa=s(ot);Lr=n(Sa,"A",{href:!0});var Dg=s(Lr);du=i(Dg,"LogitsProcessor"),Dg.forEach(o),lu=i(Sa," that enforces the specified token as the last generated token when "),Qs=n(Sa,"CODE",{});var zg=s(Qs);pu=i(zg,"max_length"),zg.forEach(o),uu=i(Sa," is reached."),Sa.forEach(o),fu=l($n),Zs=n($n,"DIV",{class:!0}),s(Zs).forEach(o),$n.forEach(o),Ei=l(e),te=n(e,"DIV",{class:!0});var kn=s(te);h(eo.$$.fragment,kn),hu=l(kn),I=n(kn,"P",{});var Me=s(I);Pr=n(Me,"A",{href:!0});var Og=s(Pr);mu=i(Og,"LogitsProcessor"),Og.forEach(o),gu=i(Me," that removes all "),ea=n(Me,"CODE",{});var Fg=s(ea);_u=i(Fg,"nan"),Fg.forEach(o),vu=i(Me," and "),ta=n(Me,"CODE",{});var Sg=s(ta);bu=i(Sg,"inf"),Sg.forEach(o),Tu=i(Me,` values to avoid the generation method to fail. Note that using
the logits processor should only be used if necessary since it can slow down the generation method. `),oa=n(Me,"CODE",{});var qg=s(oa);yu=i(qg,"max_length"),qg.forEach(o),$u=i(Me,` is
reached.`),Me.forEach(o),ku=l(kn),ra=n(kn,"DIV",{class:!0}),s(ra).forEach(o),kn.forEach(o),Li=l(e),oe=n(e,"DIV",{class:!0});var xn=s(oe);h(to.$$.fragment,xn),xu=l(xn),na=n(xn,"P",{});var Bg=s(na);wu=i(Bg,"Abstract base class for all logit processors that can be applied during generation."),Bg.forEach(o),Eu=l(xn),rt=n(xn,"DIV",{class:!0});var gc=s(rt);h(oo.$$.fragment,gc),Lu=l(gc),sa=n(gc,"P",{});var Ig=s(sa);Pu=i(Ig,"Flax method for processing logits."),Ig.forEach(o),gc.forEach(o),xn.forEach(o),Pi=l(e),re=n(e,"DIV",{class:!0});var wn=s(re);h(ro.$$.fragment,wn),Du=l(wn),k=n(wn,"P",{});var O=s(k);zu=i(O,"This class can be used to create a list of "),Dr=n(O,"A",{href:!0});var Ag=s(Dr);Ou=i(Ag,"FlaxLogitsProcessor"),Ag.forEach(o),Fu=i(O," or "),zr=n(O,"A",{href:!0});var Ng=s(zr);Su=i(Ng,"FlaxLogitsWarper"),Ng.forEach(o),qu=i(O,` to subsequently process
a `),aa=n(O,"CODE",{});var Wg=s(aa);Bu=i(Wg,"scores"),Wg.forEach(o),Iu=i(O," input tensor. This class inherits from list and adds a specific "),ia=n(O,"EM",{});var Vg=s(ia);ca=n(Vg,"STRONG",{});var Mg=s(ca);Au=i(Mg,"call"),Mg.forEach(o),Vg.forEach(o),Nu=i(O,` method to apply each
`),Or=n(O,"A",{href:!0});var Cg=s(Or);Wu=i(Cg,"FlaxLogitsProcessor"),Cg.forEach(o),Vu=i(O," or "),Fr=n(O,"A",{href:!0});var Gg=s(Fr);Mu=i(Gg,"FlaxLogitsWarper"),Gg.forEach(o),Cu=i(O," to the inputs."),O.forEach(o),Gu=l(wn),Sr=n(wn,"DIV",{class:!0});var Hg=s(Sr);h(no.$$.fragment,Hg),Hg.forEach(o),wn.forEach(o),Di=l(e),ne=n(e,"DIV",{class:!0});var En=s(ne);h(so.$$.fragment,En),Hu=l(En),da=n(En,"P",{});var jg=s(da);ju=i(jg,"Abstract base class for all logit warpers that can be applied during generation with multinomial sampling."),jg.forEach(o),Ru=l(En),nt=n(En,"DIV",{class:!0});var _c=s(nt);h(ao.$$.fragment,_c),Ku=l(_c),la=n(_c,"P",{});var Rg=s(la);Uu=i(Rg,"Flax method for warping logits."),Rg.forEach(o),_c.forEach(o),En.forEach(o),zi=l(e),se=n(e,"DIV",{class:!0});var Ln=s(se);h(io.$$.fragment,Ln),Yu=l(Ln),qr=n(Ln,"P",{});var Oh=s(qr);Br=n(Oh,"A",{href:!0});var Kg=s(Br);Xu=i(Kg,"LogitsWarper"),Kg.forEach(o),Ju=i(Oh," for temperature (exponential scaling output probability distribution)."),Oh.forEach(o),Qu=l(Ln),pa=n(Ln,"DIV",{class:!0}),s(pa).forEach(o),Ln.forEach(o),Oi=l(e),ae=n(e,"DIV",{class:!0});var Pn=s(ae);h(co.$$.fragment,Pn),Zu=l(Pn),Ir=n(Pn,"P",{});var Fh=s(Ir);Ar=n(Fh,"A",{href:!0});var Ug=s(Ar);ef=i(Ug,"LogitsWarper"),Ug.forEach(o),tf=i(Fh," that performs top-p, i.e. restricting to top tokens summing to prob_cut_off <= prob_cut_off."),Fh.forEach(o),of=l(Pn),ua=n(Pn,"DIV",{class:!0}),s(ua).forEach(o),Pn.forEach(o),Fi=l(e),ie=n(e,"DIV",{class:!0});var Dn=s(ie);h(lo.$$.fragment,Dn),rf=l(Dn),Nr=n(Dn,"P",{});var Sh=s(Nr);Wr=n(Sh,"A",{href:!0});var Yg=s(Wr);nf=i(Yg,"LogitsWarper"),Yg.forEach(o),sf=i(Sh," that performs top-k, i.e. restricting to the k highest probability elements."),Sh.forEach(o),af=l(Dn),fa=n(Dn,"DIV",{class:!0}),s(fa).forEach(o),Dn.forEach(o),Si=l(e),ce=n(e,"DIV",{class:!0});var zn=s(ce);h(po.$$.fragment,zn),cf=l(zn),Vr=n(zn,"P",{});var qh=s(Vr);Mr=n(qh,"A",{href:!0});var Xg=s(Mr);df=i(Xg,"FlaxLogitsProcessor"),Xg.forEach(o),lf=i(qh," that enforces the specified token as the first generated token."),qh.forEach(o),pf=l(zn),ha=n(zn,"DIV",{class:!0}),s(ha).forEach(o),zn.forEach(o),qi=l(e),de=n(e,"DIV",{class:!0});var On=s(de);h(uo.$$.fragment,On),uf=l(On),st=n(On,"P",{});var qa=s(st);Cr=n(qa,"A",{href:!0});var Jg=s(Cr);ff=i(Jg,"FlaxLogitsProcessor"),Jg.forEach(o),hf=i(qa," that enforces the specified token as the last generated token when "),ma=n(qa,"CODE",{});var Qg=s(ma);mf=i(Qg,"max_length"),Qg.forEach(o),gf=i(qa," is reached."),qa.forEach(o),_f=l(On),ga=n(On,"DIV",{class:!0}),s(ga).forEach(o),On.forEach(o),Bi=l(e),le=n(e,"DIV",{class:!0});var Fn=s(le);h(fo.$$.fragment,Fn),vf=l(Fn),Gr=n(Fn,"P",{});var Bh=s(Gr);Hr=n(Bh,"A",{href:!0});var Zg=s(Hr);bf=i(Zg,"FlaxLogitsProcessor"),Zg.forEach(o),Tf=i(Bh," enforcing a min-length by setting EOS probability to 0."),Bh.forEach(o),yf=l(Fn),_a=n(Fn,"DIV",{class:!0}),s(_a).forEach(o),Fn.forEach(o),Ii=l(e),Ae=n(e,"H2",{class:!0});var vc=s(Ae);at=n(vc,"A",{id:!0,class:!0,href:!0});var e_=s(at);va=n(e_,"SPAN",{});var t_=s(va);h(ho.$$.fragment,t_),t_.forEach(o),e_.forEach(o),$f=l(vc),ba=n(vc,"SPAN",{});var o_=s(ba);kf=i(o_,"StoppingCriteria"),o_.forEach(o),vc.forEach(o),Ai=l(e),it=n(e,"P",{});var bc=s(it);xf=i(bc,"A "),jr=n(bc,"A",{href:!0});var r_=s(jr);wf=i(r_,"StoppingCriteria"),r_.forEach(o),Ef=i(bc," can be used to change when to stop generation (other than EOS token)."),bc.forEach(o),Ni=l(e),pe=n(e,"DIV",{class:!0});var Sn=s(pe);h(mo.$$.fragment,Sn),Lf=l(Sn),Ta=n(Sn,"P",{});var n_=s(Ta);Pf=i(n_,"Abstract base class for all stopping criteria that can be applied during generation."),n_.forEach(o),Df=l(Sn),Rr=n(Sn,"DIV",{class:!0});var s_=s(Rr);h(go.$$.fragment,s_),s_.forEach(o),Sn.forEach(o),Wi=l(e),_o=n(e,"DIV",{class:!0});var a_=s(_o);Kr=n(a_,"DIV",{class:!0});var i_=s(Kr);h(vo.$$.fragment,i_),i_.forEach(o),a_.forEach(o),Vi=l(e),ue=n(e,"DIV",{class:!0});var qn=s(ue);h(bo.$$.fragment,qn),zf=l(qn),To=n(qn,"P",{});var Tc=s(To);Of=i(Tc,"This class can be used to stop generation whenever the full generated number of tokens exceeds "),ya=n(Tc,"CODE",{});var c_=s(ya);Ff=i(c_,"max_length"),c_.forEach(o),Sf=i(Tc,`. Keep
in mind for decoder-only type of transformers, this will include the initial prompted tokens.`),Tc.forEach(o),qf=l(qn),Ur=n(qn,"DIV",{class:!0});var d_=s(Ur);h(yo.$$.fragment,d_),d_.forEach(o),qn.forEach(o),Mi=l(e),fe=n(e,"DIV",{class:!0});var Bn=s(fe);h($o.$$.fragment,Bn),Bf=l(Bn),ko=n(Bn,"P",{});var yc=s(ko);If=i(yc,`This class can be used to stop generation whenever the full generation exceeds some amount of time. By default, the
time will start being counted when you initialize this function. You can override this by passing an
`),$a=n(yc,"CODE",{});var l_=s($a);Af=i(l_,"initial_time"),l_.forEach(o),Nf=i(yc,"."),yc.forEach(o),Wf=l(Bn),Yr=n(Bn,"DIV",{class:!0});var p_=s(Yr);h(xo.$$.fragment,p_),p_.forEach(o),Bn.forEach(o),Ci=l(e),Ne=n(e,"H2",{class:!0});var $c=s(Ne);ct=n($c,"A",{id:!0,class:!0,href:!0});var u_=s(ct);ka=n(u_,"SPAN",{});var f_=s(ka);h(wo.$$.fragment,f_),f_.forEach(o),u_.forEach(o),Vf=l($c),xa=n($c,"SPAN",{});var h_=s(xa);Mf=i(h_,"BeamSearch"),h_.forEach(o),$c.forEach(o),Gi=l(e),F=n(e,"DIV",{class:!0});var ut=s(F);h(Eo.$$.fragment,ut),Cf=l(ut),We=n(ut,"P",{});var In=s(We);Gf=i(In,"Abstract base class for all beam scorers that are used for "),Xr=n(In,"A",{href:!0});var m_=s(Xr);Hf=i(m_,"beam_search()"),m_.forEach(o),jf=i(In,` and
`),Jr=n(In,"A",{href:!0});var g_=s(Jr);Rf=i(g_,"beam_sample()"),g_.forEach(o),Kf=i(In,"."),In.forEach(o),Uf=l(ut),Qr=n(ut,"DIV",{class:!0});var __=s(Qr);h(Lo.$$.fragment,__),__.forEach(o),Yf=l(ut),Zr=n(ut,"DIV",{class:!0});var v_=s(Zr);h(Po.$$.fragment,v_),v_.forEach(o),ut.forEach(o),Hi=l(e),x=n(e,"DIV",{class:!0});var A=s(x);h(Do.$$.fragment,A),Xf=l(A),en=n(A,"P",{});var Ih=s(en);tn=n(Ih,"A",{href:!0});var b_=s(tn);Jf=i(b_,"BeamScorer"),b_.forEach(o),Qf=i(Ih," implementing standard beam search decoding."),Ih.forEach(o),Zf=l(A),zo=n(A,"P",{});var kc=s(zo);eh=i(kc,"Adapted in part from "),Oo=n(kc,"A",{href:!0,rel:!0});var T_=s(Oo);th=i(T_,`Facebook\u2019s XLM beam search
code`),T_.forEach(o),oh=i(kc,"."),kc.forEach(o),rh=l(A),on=n(A,"P",{});var Ah=s(on);nh=i(Ah,"Reference for the diverse beam search algorithm and implementation "),Fo=n(Ah,"A",{href:!0,rel:!0});var y_=s(Fo);sh=i(y_,`Ashwin Kalyan\u2019s DBS
implementation`),y_.forEach(o),Ah.forEach(o),ah=l(A),wa=n(A,"DIV",{class:!0}),s(wa).forEach(o),ih=l(A),Ea=n(A,"DIV",{class:!0}),s(Ea).forEach(o),A.forEach(o),ji=l(e),Ve=n(e,"H2",{class:!0});var xc=s(Ve);dt=n(xc,"A",{id:!0,class:!0,href:!0});var $_=s(dt);La=n($_,"SPAN",{});var k_=s(La);h(So.$$.fragment,k_),k_.forEach(o),$_.forEach(o),ch=l(xc),Pa=n(xc,"SPAN",{});var x_=s(Pa);dh=i(x_,"Utilities"),x_.forEach(o),xc.forEach(o),Ri=l(e),he=n(e,"DIV",{class:!0});var An=s(he);h(qo.$$.fragment,An),lh=l(An),Da=n(An,"P",{});var w_=s(Da);ph=i(w_,"Filter a distribution of logits using top-k and/or nucleus (top-p) filtering"),w_.forEach(o),uh=l(An),rn=n(An,"P",{});var Nh=s(rn);fh=i(Nh,"From: "),Bo=n(Nh,"A",{href:!0,rel:!0});var E_=s(Bo);hh=i(E_,"https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317"),E_.forEach(o),Nh.forEach(o),An.forEach(o),Ki=l(e),me=n(e,"DIV",{class:!0});var Nn=s(me);h(Io.$$.fragment,Nn),mh=l(Nn),za=n(Nn,"P",{});var L_=s(za);gh=i(L_,"Filter a distribution of logits using top-k and/or nucleus (top-p) filtering"),L_.forEach(o),_h=l(Nn),nn=n(Nn,"P",{});var Wh=s(nn);vh=i(Wh,"From: "),Ao=n(Wh,"A",{href:!0,rel:!0});var P_=s(Ao);bh=i(P_,"https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317"),P_.forEach(o),Wh.forEach(o),Nn.forEach(o),this.h()},h(){c(ge,"name","hf:doc:metadata"),c(ge,"content",JSON.stringify(I_)),c(N,"id","utilities-for-generation"),c(N,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(N,"href","#utilities-for-generation"),c(S,"class","relative group"),c(Vo,"href","/docs/transformers/v4.16.2/en/main_classes/model#transformers.generation_utils.GenerationMixin.generate"),c(Mo,"href","/docs/transformers/v4.16.2/en/main_classes/model#transformers.generation_utils.GenerationMixin.greedy_search"),c(Co,"href","/docs/transformers/v4.16.2/en/main_classes/model#transformers.generation_utils.GenerationMixin.sample"),c(Go,"href","/docs/transformers/v4.16.2/en/main_classes/model#transformers.generation_utils.GenerationMixin.beam_search"),c(Ho,"href","/docs/transformers/v4.16.2/en/main_classes/model#transformers.generation_utils.GenerationMixin.beam_sample"),c(jo,"href","/docs/transformers/v4.16.2/en/main_classes/model#transformers.generation_utils.GenerationMixin.group_beam_search"),c(Ce,"id","generate-outputs"),c(Ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ce,"href","#generate-outputs"),c(ke,"class","relative group"),c(Ko,"href","/docs/transformers/v4.16.2/en/main_classes/model#transformers.generation_utils.GenerationMixin.generate"),c(Uo,"href","/docs/transformers/v4.16.2/en/main_classes/output#transformers.file_utils.ModelOutput"),c(Yo,"href","/docs/transformers/v4.16.2/en/main_classes/model#transformers.generation_utils.GenerationMixin.generate"),c(Jo,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.generation_utils.GreedySearchDecoderOnlyOutput"),c(He,"id","transformers.generation_utils.GreedySearchDecoderOnlyOutput"),c(He,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(He,"href","#transformers.generation_utils.GreedySearchDecoderOnlyOutput"),c(xe,"class","relative group"),c(we,"class","docstring"),c(Ee,"class","docstring"),c(je,"class","docstring"),c(W,"class","docstring"),c(Re,"id","transformers.generation_utils.SampleDecoderOnlyOutput"),c(Re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Re,"href","#transformers.generation_utils.SampleDecoderOnlyOutput"),c(Le,"class","relative group"),c(Pe,"class","docstring"),c(De,"class","docstring"),c(Ke,"class","docstring"),c(V,"class","docstring"),c(Ue,"id","transformers.generation_utils.BeamSearchDecoderOnlyOutput"),c(Ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ue,"href","#transformers.generation_utils.BeamSearchDecoderOnlyOutput"),c(ze,"class","relative group"),c(Oe,"class","docstring"),c(Fe,"class","docstring"),c(Ye,"id","transformers.generation_utils.BeamSampleDecoderOnlyOutput"),c(Ye,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ye,"href","#transformers.generation_utils.BeamSampleDecoderOnlyOutput"),c(Se,"class","relative group"),c(qe,"class","docstring"),c(Be,"class","docstring"),c(Xe,"id","transformers.LogitsProcessor"),c(Xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Xe,"href","#transformers.LogitsProcessor"),c(Ie,"class","relative group"),c(rr,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.LogitsProcessor"),c(Qe,"class","docstring"),c(M,"class","docstring"),c(nr,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.LogitsProcessor"),c(sr,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.LogitsWarper"),c(ar,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.LogitsProcessor"),c(ir,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.LogitsWarper"),c(cr,"class","docstring"),c(C,"class","docstring"),c(Ze,"class","docstring"),c(G,"class","docstring"),c(lr,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.LogitsProcessor"),c(Cs,"class","docstring"),c(H,"class","docstring"),c(ur,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.LogitsWarper"),c(Gs,"class","docstring"),c(j,"class","docstring"),c(hr,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.LogitsProcessor"),c(Hs,"class","docstring"),c(R,"class","docstring"),c(gr,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.LogitsWarper"),c(js,"class","docstring"),c(K,"class","docstring"),c(vr,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.LogitsWarper"),c(Rs,"class","docstring"),c(U,"class","docstring"),c(br,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.LogitsProcessor"),c(Rt,"href","https://github.com/pytorch/fairseq/blob/a07cb6f40480928c9e0548b737aadd36ee66ac76/fairseq/sequence_generator.py#L345"),c(Rt,"rel","nofollow"),c(Ks,"class","docstring"),c(Y,"class","docstring"),c(yr,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.LogitsProcessor"),c(Us,"class","docstring"),c(X,"class","docstring"),c($r,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.LogitsProcessor"),c(Yt,"href","https://arxiv.org/abs/2010.00904"),c(Yt,"rel","nofollow"),c(Ys,"class","docstring"),c(J,"class","docstring"),c(kr,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.LogitsProcessor"),c(xr,"href","/docs/transformers/v4.16.2/en/main_classes/model#transformers.generation_utils.GenerationMixin.group_beam_search"),c(Jt,"href","https://arxiv.org/pdf/1610.02424.pdf"),c(Jt,"rel","nofollow"),c(Xs,"class","docstring"),c(Q,"class","docstring"),c(Er,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.LogitsProcessor"),c(Js,"class","docstring"),c(Z,"class","docstring"),c(Lr,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.LogitsProcessor"),c(Zs,"class","docstring"),c(ee,"class","docstring"),c(Pr,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.LogitsProcessor"),c(ra,"class","docstring"),c(te,"class","docstring"),c(rt,"class","docstring"),c(oe,"class","docstring"),c(Dr,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.FlaxLogitsProcessor"),c(zr,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.FlaxLogitsWarper"),c(Or,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.FlaxLogitsProcessor"),c(Fr,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.FlaxLogitsWarper"),c(Sr,"class","docstring"),c(re,"class","docstring"),c(nt,"class","docstring"),c(ne,"class","docstring"),c(Br,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.LogitsWarper"),c(pa,"class","docstring"),c(se,"class","docstring"),c(Ar,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.LogitsWarper"),c(ua,"class","docstring"),c(ae,"class","docstring"),c(Wr,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.LogitsWarper"),c(fa,"class","docstring"),c(ie,"class","docstring"),c(Mr,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.FlaxLogitsProcessor"),c(ha,"class","docstring"),c(ce,"class","docstring"),c(Cr,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.FlaxLogitsProcessor"),c(ga,"class","docstring"),c(de,"class","docstring"),c(Hr,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.FlaxLogitsProcessor"),c(_a,"class","docstring"),c(le,"class","docstring"),c(at,"id","transformers.StoppingCriteria"),c(at,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(at,"href","#transformers.StoppingCriteria"),c(Ae,"class","relative group"),c(jr,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.StoppingCriteria"),c(Rr,"class","docstring"),c(pe,"class","docstring"),c(Kr,"class","docstring"),c(_o,"class","docstring"),c(Ur,"class","docstring"),c(ue,"class","docstring"),c(Yr,"class","docstring"),c(fe,"class","docstring"),c(ct,"id","transformers.BeamScorer"),c(ct,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ct,"href","#transformers.BeamScorer"),c(Ne,"class","relative group"),c(Xr,"href","/docs/transformers/v4.16.2/en/main_classes/model#transformers.generation_utils.GenerationMixin.beam_search"),c(Jr,"href","/docs/transformers/v4.16.2/en/main_classes/model#transformers.generation_utils.GenerationMixin.beam_sample"),c(Qr,"class","docstring"),c(Zr,"class","docstring"),c(F,"class","docstring"),c(tn,"href","/docs/transformers/v4.16.2/en/internal/generation_utils#transformers.BeamScorer"),c(Oo,"href","https://github.com/facebookresearch/XLM/blob/9e6f6814d17be4fe5b15f2e6c43eb2b2d76daeb4/src/model/transformer.py#L529"),c(Oo,"rel","nofollow"),c(Fo,"href","https://github.com/ashwinkalyan/dbs/blob/master/dbs/beam_utils.lua"),c(Fo,"rel","nofollow"),c(wa,"class","docstring"),c(Ea,"class","docstring"),c(x,"class","docstring"),c(dt,"id","transformers.top_k_top_p_filtering"),c(dt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dt,"href","#transformers.top_k_top_p_filtering"),c(Ve,"class","relative group"),c(Bo,"href","https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317"),c(Bo,"rel","nofollow"),c(he,"class","docstring"),c(Ao,"href","https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317"),c(Ao,"rel","nofollow"),c(me,"class","docstring")},m(e,p){t(document.head,ge),u(e,Wo,p),u(e,S,p),t(S,N),t(N,Wn),m(ft,Wn,null),t(S,Ec),t(S,Vn),t(Vn,Lc),u(e,Ba,p),u(e,T,p),t(T,Pc),t(T,Vo),t(Vo,Dc),t(T,zc),t(T,Mo),t(Mo,Oc),t(T,Fc),t(T,Co),t(Co,Sc),t(T,qc),t(T,Go),t(Go,Bc),t(T,Ic),t(T,Ho),t(Ho,Ac),t(T,Nc),t(T,jo),t(jo,Wc),t(T,Vc),u(e,Ia,p),u(e,Ro,p),t(Ro,Mc),u(e,Aa,p),u(e,ke,p),t(ke,Ce),t(Ce,Mn),m(ht,Mn,null),t(ke,Cc),t(ke,Cn),t(Cn,Gc),u(e,Na,p),u(e,q,p),t(q,Hc),t(q,Ko),t(Ko,jc),t(q,Rc),t(q,Uo),t(Uo,Kc),t(q,Uc),t(q,Yo),t(Yo,Yc),t(q,Xc),u(e,Wa,p),u(e,Xo,p),t(Xo,Jc),u(e,Va,p),m(mt,e,p),u(e,Ma,p),u(e,_e,p),t(_e,Qc),t(_e,Gn),t(Gn,Zc),t(_e,ed),t(_e,Jo),t(Jo,td),t(_e,od),u(e,Ca,p),u(e,B,p),t(B,Qo),t(Qo,Hn),t(Hn,rd),t(Qo,nd),t(B,sd),t(B,Zo),t(Zo,jn),t(jn,ad),t(Zo,id),t(B,cd),t(B,er),t(er,Rn),t(Rn,dd),t(er,ld),t(B,pd),t(B,tr),t(tr,Kn),t(Kn,ud),t(tr,fd),u(e,Ga,p),u(e,y,p),t(y,hd),t(y,Un),t(Un,md),t(y,gd),t(y,Yn),t(Yn,_d),t(y,vd),t(y,Xn),t(Xn,bd),t(y,Td),t(y,Jn),t(Jn,yd),t(y,$d),t(y,Qn),t(Qn,kd),t(y,xd),t(y,Zn),t(Zn,wd),t(y,Ed),u(e,Ha,p),u(e,w,p),t(w,Ld),t(w,es),t(es,Pd),t(w,Dd),t(w,ts),t(ts,zd),t(w,Od),t(w,os),t(os,Fd),t(w,Sd),t(w,rs),t(rs,qd),t(w,Bd),u(e,ja,p),u(e,E,p),t(E,Id),t(E,ns),t(ns,Ad),t(E,Nd),t(E,ss),t(ss,Wd),t(E,Vd),t(E,as),t(as,Md),t(E,Cd),t(E,is),t(is,Gd),t(E,Hd),u(e,Ra,p),m(gt,e,p),u(e,Ka,p),u(e,Ge,p),t(Ge,jd),t(Ge,cs),t(cs,Rd),t(Ge,Kd),u(e,Ua,p),u(e,L,p),t(L,Ud),t(L,ds),t(ds,Yd),t(L,Xd),t(L,ls),t(ls,Jd),t(L,Qd),t(L,ps),t(ps,Zd),t(L,el),t(L,us),t(us,tl),t(L,ol),u(e,Ya,p),u(e,or,p),t(or,rl),u(e,Xa,p),u(e,xe,p),t(xe,He),t(He,fs),m(_t,fs,null),t(xe,nl),t(xe,hs),t(hs,sl),u(e,Ja,p),u(e,we,p),m(vt,we,null),t(we,al),t(we,ms),t(ms,il),u(e,Qa,p),u(e,Ee,p),m(bt,Ee,null),t(Ee,cl),t(Ee,gs),t(gs,dl),u(e,Za,p),u(e,W,p),m(Tt,W,null),t(W,ll),t(W,_s),t(_s,pl),t(W,ul),t(W,je),m(yt,je,null),t(je,fl),t(je,vs),t(vs,hl),u(e,ei,p),u(e,Le,p),t(Le,Re),t(Re,bs),m($t,bs,null),t(Le,ml),t(Le,Ts),t(Ts,gl),u(e,ti,p),u(e,Pe,p),m(kt,Pe,null),t(Pe,_l),t(Pe,ys),t(ys,vl),u(e,oi,p),u(e,De,p),m(xt,De,null),t(De,bl),t(De,$s),t($s,Tl),u(e,ri,p),u(e,V,p),m(wt,V,null),t(V,yl),t(V,ks),t(ks,$l),t(V,kl),t(V,Ke),m(Et,Ke,null),t(Ke,xl),t(Ke,xs),t(xs,wl),u(e,ni,p),u(e,ze,p),t(ze,Ue),t(Ue,ws),m(Lt,ws,null),t(ze,El),t(ze,Es),t(Es,Ll),u(e,si,p),u(e,Oe,p),m(Pt,Oe,null),t(Oe,Pl),t(Oe,Ls),t(Ls,Dl),u(e,ai,p),u(e,Fe,p),m(Dt,Fe,null),t(Fe,zl),t(Fe,Ps),t(Ps,Ol),u(e,ii,p),u(e,Se,p),t(Se,Ye),t(Ye,Ds),m(zt,Ds,null),t(Se,Fl),t(Se,zs),t(zs,Sl),u(e,ci,p),u(e,qe,p),m(Ot,qe,null),t(qe,ql),t(qe,Os),t(Os,Bl),u(e,di,p),u(e,Be,p),m(Ft,Be,null),t(Be,Il),t(Be,Fs),t(Fs,Al),u(e,li,p),u(e,Ie,p),t(Ie,Xe),t(Xe,Ss),m(St,Ss,null),t(Ie,Nl),t(Ie,qs),t(qs,Wl),u(e,pi,p),u(e,Je,p),t(Je,Vl),t(Je,rr),t(rr,Ml),t(Je,Cl),u(e,ui,p),u(e,M,p),m(qt,M,null),t(M,Gl),t(M,Bs),t(Bs,Hl),t(M,jl),t(M,Qe),m(Bt,Qe,null),t(Qe,Rl),t(Qe,Is),t(Is,Kl),u(e,fi,p),u(e,C,p),m(It,C,null),t(C,Ul),t(C,$),t($,Yl),t($,nr),t(nr,Xl),t($,Jl),t($,sr),t(sr,Ql),t($,Zl),t($,As),t(As,ep),t($,tp),t($,Ns),t(Ns,Ws),t(Ws,op),t($,rp),t($,ar),t(ar,np),t($,sp),t($,ir),t(ir,ap),t($,ip),t(C,cp),t(C,cr),m(At,cr,null),u(e,hi,p),u(e,G,p),m(Nt,G,null),t(G,dp),t(G,Vs),t(Vs,lp),t(G,pp),t(G,Ze),m(Wt,Ze,null),t(Ze,up),t(Ze,Ms),t(Ms,fp),u(e,mi,p),u(e,H,p),m(Vt,H,null),t(H,hp),t(H,dr),t(dr,lr),t(lr,mp),t(dr,gp),t(H,_p),t(H,Cs),u(e,gi,p),u(e,j,p),m(Mt,j,null),t(j,vp),t(j,pr),t(pr,ur),t(ur,bp),t(pr,Tp),t(j,yp),t(j,Gs),u(e,_i,p),u(e,R,p),m(Ct,R,null),t(R,$p),t(R,fr),t(fr,hr),t(hr,kp),t(fr,xp),t(R,wp),t(R,Hs),u(e,vi,p),u(e,K,p),m(Gt,K,null),t(K,Ep),t(K,mr),t(mr,gr),t(gr,Lp),t(mr,Pp),t(K,Dp),t(K,js),u(e,bi,p),u(e,U,p),m(Ht,U,null),t(U,zp),t(U,_r),t(_r,vr),t(vr,Op),t(_r,Fp),t(U,Sp),t(U,Rs),u(e,Ti,p),u(e,Y,p),m(jt,Y,null),t(Y,qp),t(Y,et),t(et,br),t(br,Bp),t(et,Ip),t(et,Rt),t(Rt,Ap),t(et,Np),t(Y,Wp),t(Y,Ks),u(e,yi,p),u(e,X,p),m(Kt,X,null),t(X,Vp),t(X,Tr),t(Tr,yr),t(yr,Mp),t(Tr,Cp),t(X,Gp),t(X,Us),u(e,$i,p),u(e,J,p),m(Ut,J,null),t(J,Hp),t(J,tt),t(tt,$r),t($r,jp),t(tt,Rp),t(tt,Yt),t(Yt,Kp),t(tt,Up),t(J,Yp),t(J,Ys),u(e,ki,p),u(e,Q,p),m(Xt,Q,null),t(Q,Xp),t(Q,ve),t(ve,kr),t(kr,Jp),t(ve,Qp),t(ve,xr),t(xr,Zp),t(ve,eu),t(ve,Jt),t(Jt,tu),t(ve,ou),t(Q,ru),t(Q,Xs),u(e,xi,p),u(e,Z,p),m(Qt,Z,null),t(Z,nu),t(Z,wr),t(wr,Er),t(Er,su),t(wr,au),t(Z,iu),t(Z,Js),u(e,wi,p),u(e,ee,p),m(Zt,ee,null),t(ee,cu),t(ee,ot),t(ot,Lr),t(Lr,du),t(ot,lu),t(ot,Qs),t(Qs,pu),t(ot,uu),t(ee,fu),t(ee,Zs),u(e,Ei,p),u(e,te,p),m(eo,te,null),t(te,hu),t(te,I),t(I,Pr),t(Pr,mu),t(I,gu),t(I,ea),t(ea,_u),t(I,vu),t(I,ta),t(ta,bu),t(I,Tu),t(I,oa),t(oa,yu),t(I,$u),t(te,ku),t(te,ra),u(e,Li,p),u(e,oe,p),m(to,oe,null),t(oe,xu),t(oe,na),t(na,wu),t(oe,Eu),t(oe,rt),m(oo,rt,null),t(rt,Lu),t(rt,sa),t(sa,Pu),u(e,Pi,p),u(e,re,p),m(ro,re,null),t(re,Du),t(re,k),t(k,zu),t(k,Dr),t(Dr,Ou),t(k,Fu),t(k,zr),t(zr,Su),t(k,qu),t(k,aa),t(aa,Bu),t(k,Iu),t(k,ia),t(ia,ca),t(ca,Au),t(k,Nu),t(k,Or),t(Or,Wu),t(k,Vu),t(k,Fr),t(Fr,Mu),t(k,Cu),t(re,Gu),t(re,Sr),m(no,Sr,null),u(e,Di,p),u(e,ne,p),m(so,ne,null),t(ne,Hu),t(ne,da),t(da,ju),t(ne,Ru),t(ne,nt),m(ao,nt,null),t(nt,Ku),t(nt,la),t(la,Uu),u(e,zi,p),u(e,se,p),m(io,se,null),t(se,Yu),t(se,qr),t(qr,Br),t(Br,Xu),t(qr,Ju),t(se,Qu),t(se,pa),u(e,Oi,p),u(e,ae,p),m(co,ae,null),t(ae,Zu),t(ae,Ir),t(Ir,Ar),t(Ar,ef),t(Ir,tf),t(ae,of),t(ae,ua),u(e,Fi,p),u(e,ie,p),m(lo,ie,null),t(ie,rf),t(ie,Nr),t(Nr,Wr),t(Wr,nf),t(Nr,sf),t(ie,af),t(ie,fa),u(e,Si,p),u(e,ce,p),m(po,ce,null),t(ce,cf),t(ce,Vr),t(Vr,Mr),t(Mr,df),t(Vr,lf),t(ce,pf),t(ce,ha),u(e,qi,p),u(e,de,p),m(uo,de,null),t(de,uf),t(de,st),t(st,Cr),t(Cr,ff),t(st,hf),t(st,ma),t(ma,mf),t(st,gf),t(de,_f),t(de,ga),u(e,Bi,p),u(e,le,p),m(fo,le,null),t(le,vf),t(le,Gr),t(Gr,Hr),t(Hr,bf),t(Gr,Tf),t(le,yf),t(le,_a),u(e,Ii,p),u(e,Ae,p),t(Ae,at),t(at,va),m(ho,va,null),t(Ae,$f),t(Ae,ba),t(ba,kf),u(e,Ai,p),u(e,it,p),t(it,xf),t(it,jr),t(jr,wf),t(it,Ef),u(e,Ni,p),u(e,pe,p),m(mo,pe,null),t(pe,Lf),t(pe,Ta),t(Ta,Pf),t(pe,Df),t(pe,Rr),m(go,Rr,null),u(e,Wi,p),u(e,_o,p),t(_o,Kr),m(vo,Kr,null),u(e,Vi,p),u(e,ue,p),m(bo,ue,null),t(ue,zf),t(ue,To),t(To,Of),t(To,ya),t(ya,Ff),t(To,Sf),t(ue,qf),t(ue,Ur),m(yo,Ur,null),u(e,Mi,p),u(e,fe,p),m($o,fe,null),t(fe,Bf),t(fe,ko),t(ko,If),t(ko,$a),t($a,Af),t(ko,Nf),t(fe,Wf),t(fe,Yr),m(xo,Yr,null),u(e,Ci,p),u(e,Ne,p),t(Ne,ct),t(ct,ka),m(wo,ka,null),t(Ne,Vf),t(Ne,xa),t(xa,Mf),u(e,Gi,p),u(e,F,p),m(Eo,F,null),t(F,Cf),t(F,We),t(We,Gf),t(We,Xr),t(Xr,Hf),t(We,jf),t(We,Jr),t(Jr,Rf),t(We,Kf),t(F,Uf),t(F,Qr),m(Lo,Qr,null),t(F,Yf),t(F,Zr),m(Po,Zr,null),u(e,Hi,p),u(e,x,p),m(Do,x,null),t(x,Xf),t(x,en),t(en,tn),t(tn,Jf),t(en,Qf),t(x,Zf),t(x,zo),t(zo,eh),t(zo,Oo),t(Oo,th),t(zo,oh),t(x,rh),t(x,on),t(on,nh),t(on,Fo),t(Fo,sh),t(x,ah),t(x,wa),t(x,ih),t(x,Ea),u(e,ji,p),u(e,Ve,p),t(Ve,dt),t(dt,La),m(So,La,null),t(Ve,ch),t(Ve,Pa),t(Pa,dh),u(e,Ri,p),u(e,he,p),m(qo,he,null),t(he,lh),t(he,Da),t(Da,ph),t(he,uh),t(he,rn),t(rn,fh),t(rn,Bo),t(Bo,hh),u(e,Ki,p),u(e,me,p),m(Io,me,null),t(me,mh),t(me,za),t(za,gh),t(me,_h),t(me,nn),t(nn,vh),t(nn,Ao),t(Ao,bh),Ui=!0},p:q_,i(e){Ui||(g(ft.$$.fragment,e),g(ht.$$.fragment,e),g(mt.$$.fragment,e),g(gt.$$.fragment,e),g(_t.$$.fragment,e),g(vt.$$.fragment,e),g(bt.$$.fragment,e),g(Tt.$$.fragment,e),g(yt.$$.fragment,e),g($t.$$.fragment,e),g(kt.$$.fragment,e),g(xt.$$.fragment,e),g(wt.$$.fragment,e),g(Et.$$.fragment,e),g(Lt.$$.fragment,e),g(Pt.$$.fragment,e),g(Dt.$$.fragment,e),g(zt.$$.fragment,e),g(Ot.$$.fragment,e),g(Ft.$$.fragment,e),g(St.$$.fragment,e),g(qt.$$.fragment,e),g(Bt.$$.fragment,e),g(It.$$.fragment,e),g(At.$$.fragment,e),g(Nt.$$.fragment,e),g(Wt.$$.fragment,e),g(Vt.$$.fragment,e),g(Mt.$$.fragment,e),g(Ct.$$.fragment,e),g(Gt.$$.fragment,e),g(Ht.$$.fragment,e),g(jt.$$.fragment,e),g(Kt.$$.fragment,e),g(Ut.$$.fragment,e),g(Xt.$$.fragment,e),g(Qt.$$.fragment,e),g(Zt.$$.fragment,e),g(eo.$$.fragment,e),g(to.$$.fragment,e),g(oo.$$.fragment,e),g(ro.$$.fragment,e),g(no.$$.fragment,e),g(so.$$.fragment,e),g(ao.$$.fragment,e),g(io.$$.fragment,e),g(co.$$.fragment,e),g(lo.$$.fragment,e),g(po.$$.fragment,e),g(uo.$$.fragment,e),g(fo.$$.fragment,e),g(ho.$$.fragment,e),g(mo.$$.fragment,e),g(go.$$.fragment,e),g(vo.$$.fragment,e),g(bo.$$.fragment,e),g(yo.$$.fragment,e),g($o.$$.fragment,e),g(xo.$$.fragment,e),g(wo.$$.fragment,e),g(Eo.$$.fragment,e),g(Lo.$$.fragment,e),g(Po.$$.fragment,e),g(Do.$$.fragment,e),g(So.$$.fragment,e),g(qo.$$.fragment,e),g(Io.$$.fragment,e),Ui=!0)},o(e){_(ft.$$.fragment,e),_(ht.$$.fragment,e),_(mt.$$.fragment,e),_(gt.$$.fragment,e),_(_t.$$.fragment,e),_(vt.$$.fragment,e),_(bt.$$.fragment,e),_(Tt.$$.fragment,e),_(yt.$$.fragment,e),_($t.$$.fragment,e),_(kt.$$.fragment,e),_(xt.$$.fragment,e),_(wt.$$.fragment,e),_(Et.$$.fragment,e),_(Lt.$$.fragment,e),_(Pt.$$.fragment,e),_(Dt.$$.fragment,e),_(zt.$$.fragment,e),_(Ot.$$.fragment,e),_(Ft.$$.fragment,e),_(St.$$.fragment,e),_(qt.$$.fragment,e),_(Bt.$$.fragment,e),_(It.$$.fragment,e),_(At.$$.fragment,e),_(Nt.$$.fragment,e),_(Wt.$$.fragment,e),_(Vt.$$.fragment,e),_(Mt.$$.fragment,e),_(Ct.$$.fragment,e),_(Gt.$$.fragment,e),_(Ht.$$.fragment,e),_(jt.$$.fragment,e),_(Kt.$$.fragment,e),_(Ut.$$.fragment,e),_(Xt.$$.fragment,e),_(Qt.$$.fragment,e),_(Zt.$$.fragment,e),_(eo.$$.fragment,e),_(to.$$.fragment,e),_(oo.$$.fragment,e),_(ro.$$.fragment,e),_(no.$$.fragment,e),_(so.$$.fragment,e),_(ao.$$.fragment,e),_(io.$$.fragment,e),_(co.$$.fragment,e),_(lo.$$.fragment,e),_(po.$$.fragment,e),_(uo.$$.fragment,e),_(fo.$$.fragment,e),_(ho.$$.fragment,e),_(mo.$$.fragment,e),_(go.$$.fragment,e),_(vo.$$.fragment,e),_(bo.$$.fragment,e),_(yo.$$.fragment,e),_($o.$$.fragment,e),_(xo.$$.fragment,e),_(wo.$$.fragment,e),_(Eo.$$.fragment,e),_(Lo.$$.fragment,e),_(Po.$$.fragment,e),_(Do.$$.fragment,e),_(So.$$.fragment,e),_(qo.$$.fragment,e),_(Io.$$.fragment,e),Ui=!1},d(e){o(ge),e&&o(Wo),e&&o(S),v(ft),e&&o(Ba),e&&o(T),e&&o(Ia),e&&o(Ro),e&&o(Aa),e&&o(ke),v(ht),e&&o(Na),e&&o(q),e&&o(Wa),e&&o(Xo),e&&o(Va),v(mt,e),e&&o(Ma),e&&o(_e),e&&o(Ca),e&&o(B),e&&o(Ga),e&&o(y),e&&o(Ha),e&&o(w),e&&o(ja),e&&o(E),e&&o(Ra),v(gt,e),e&&o(Ka),e&&o(Ge),e&&o(Ua),e&&o(L),e&&o(Ya),e&&o(or),e&&o(Xa),e&&o(xe),v(_t),e&&o(Ja),e&&o(we),v(vt),e&&o(Qa),e&&o(Ee),v(bt),e&&o(Za),e&&o(W),v(Tt),v(yt),e&&o(ei),e&&o(Le),v($t),e&&o(ti),e&&o(Pe),v(kt),e&&o(oi),e&&o(De),v(xt),e&&o(ri),e&&o(V),v(wt),v(Et),e&&o(ni),e&&o(ze),v(Lt),e&&o(si),e&&o(Oe),v(Pt),e&&o(ai),e&&o(Fe),v(Dt),e&&o(ii),e&&o(Se),v(zt),e&&o(ci),e&&o(qe),v(Ot),e&&o(di),e&&o(Be),v(Ft),e&&o(li),e&&o(Ie),v(St),e&&o(pi),e&&o(Je),e&&o(ui),e&&o(M),v(qt),v(Bt),e&&o(fi),e&&o(C),v(It),v(At),e&&o(hi),e&&o(G),v(Nt),v(Wt),e&&o(mi),e&&o(H),v(Vt),e&&o(gi),e&&o(j),v(Mt),e&&o(_i),e&&o(R),v(Ct),e&&o(vi),e&&o(K),v(Gt),e&&o(bi),e&&o(U),v(Ht),e&&o(Ti),e&&o(Y),v(jt),e&&o(yi),e&&o(X),v(Kt),e&&o($i),e&&o(J),v(Ut),e&&o(ki),e&&o(Q),v(Xt),e&&o(xi),e&&o(Z),v(Qt),e&&o(wi),e&&o(ee),v(Zt),e&&o(Ei),e&&o(te),v(eo),e&&o(Li),e&&o(oe),v(to),v(oo),e&&o(Pi),e&&o(re),v(ro),v(no),e&&o(Di),e&&o(ne),v(so),v(ao),e&&o(zi),e&&o(se),v(io),e&&o(Oi),e&&o(ae),v(co),e&&o(Fi),e&&o(ie),v(lo),e&&o(Si),e&&o(ce),v(po),e&&o(qi),e&&o(de),v(uo),e&&o(Bi),e&&o(le),v(fo),e&&o(Ii),e&&o(Ae),v(ho),e&&o(Ai),e&&o(it),e&&o(Ni),e&&o(pe),v(mo),v(go),e&&o(Wi),e&&o(_o),v(vo),e&&o(Vi),e&&o(ue),v(bo),v(yo),e&&o(Mi),e&&o(fe),v($o),v(xo),e&&o(Ci),e&&o(Ne),v(wo),e&&o(Gi),e&&o(F),v(Eo),v(Lo),v(Po),e&&o(Hi),e&&o(x),v(Do),e&&o(ji),e&&o(Ve),v(So),e&&o(Ri),e&&o(he),v(qo),e&&o(Ki),e&&o(me),v(Io)}}}const I_={local:"utilities-for-generation",sections:[{local:"generate-outputs",sections:[{local:"transformers.generation_utils.GreedySearchDecoderOnlyOutput",title:"GreedySearchOutput"},{local:"transformers.generation_utils.SampleDecoderOnlyOutput",title:"SampleOutput"},{local:"transformers.generation_utils.BeamSearchDecoderOnlyOutput",title:"BeamSearchOutput"},{local:"transformers.generation_utils.BeamSampleDecoderOnlyOutput",title:"BeamSampleOutput"}],title:"Generate Outputs"},{local:"transformers.LogitsProcessor",title:"LogitsProcessor"},{local:"transformers.StoppingCriteria",title:"StoppingCriteria"},{local:"transformers.BeamScorer",title:"BeamSearch"},{local:"transformers.top_k_top_p_filtering",title:"Utilities"}],title:"Utilities for Generation"};function A_(wc,ge,Wo){let{fw:S}=ge;return wc.$$set=N=>{"fw"in N&&Wo(0,S=N.fw)},[S]}class G_ extends z_{constructor(ge){super();O_(this,ge,A_,B_,F_,{fw:0})}}export{G_ as default,I_ as metadata};
