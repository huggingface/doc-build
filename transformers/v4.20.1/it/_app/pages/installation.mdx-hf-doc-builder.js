import{S as As,i as Cs,s as Ss,e as l,k as p,w as h,t as r,M as Os,c as i,d as a,m as c,a as o,x as v,h as n,b as m,N as ks,G as t,g as f,y as _,q as g,o as $,B as E,v as Is}from"../chunks/vendor-hf-doc-builder.js";import{C as P,T as Ei}from"../chunks/CodeBlock-hf-doc-builder.js";import{I as ge}from"../chunks/IconCopyLink-hf-doc-builder.js";function qs(M){let u,y,d,w,T;return{c(){u=l("p"),y=r("Devi tenere la cartella "),d=l("code"),w=r("transformers"),T=r(" se vuoi continuare ad utilizzare la libreria.")},l(b){u=i(b,"P",{});var z=o(u);y=n(z,"Devi tenere la cartella "),d=i(z,"CODE",{});var A=o(d);w=n(A,"transformers"),A.forEach(a),T=n(z," se vuoi continuare ad utilizzare la libreria."),z.forEach(a)},m(b,z){f(b,u,z),t(u,y),t(u,d),t(d,w),t(u,T)},d(b){b&&a(u)}}}function Fs(M){let u,y,d,w,T,b,z,A,S,C,I;return{c(){u=l("p"),y=r("\u{1F917} Transformers utilizzer\xE0 le variabili d\u2019ambiente della shell "),d=l("code"),w=r("PYTORCH_TRANSFORMERS_CACHE"),T=r(" o "),b=l("code"),z=r("PYTORCH_PRETRAINED_BERT_CACHE"),A=r(" se si proviene da un\u2019iterazione precedente di questa libreria e sono state impostate queste variabili d\u2019ambiente, a meno che non si specifichi la variabile d\u2019ambiente della shell "),S=l("code"),C=r("TRANSFORMERS_CACHE"),I=r(".")},l(q){u=i(q,"P",{});var O=o(u);y=n(O,"\u{1F917} Transformers utilizzer\xE0 le variabili d\u2019ambiente della shell "),d=i(O,"CODE",{});var U=o(d);w=n(U,"PYTORCH_TRANSFORMERS_CACHE"),U.forEach(a),T=n(O," o "),b=i(O,"CODE",{});var zt=o(b);z=n(zt,"PYTORCH_PRETRAINED_BERT_CACHE"),zt.forEach(a),A=n(O," se si proviene da un\u2019iterazione precedente di questa libreria e sono state impostate queste variabili d\u2019ambiente, a meno che non si specifichi la variabile d\u2019ambiente della shell "),S=i(O,"CODE",{});var $e=o(S);C=n($e,"TRANSFORMERS_CACHE"),$e.forEach(a),I=n(O,"."),O.forEach(a)},m(q,O){f(q,u,O),t(u,y),t(u,d),t(d,w),t(u,T),t(u,b),t(b,z),t(u,A),t(u,S),t(S,C),t(u,I)},d(q){q&&a(u)}}}function Rs(M){let u,y,d,w,T,b,z,A;return{c(){u=l("p"),y=r("Aggiungi "),d=l("a"),w=r("\u{1F917} Datasets"),T=r(" al tuo flusso di lavoro offline di training impostando la variabile d\u2019ambiente "),b=l("code"),z=r("HF_DATASETS_OFFLINE=1"),A=r("."),this.h()},l(S){u=i(S,"P",{});var C=o(u);y=n(C,"Aggiungi "),d=i(C,"A",{href:!0,rel:!0});var I=o(d);w=n(I,"\u{1F917} Datasets"),I.forEach(a),T=n(C," al tuo flusso di lavoro offline di training impostando la variabile d\u2019ambiente "),b=i(C,"CODE",{});var q=o(b);z=n(q,"HF_DATASETS_OFFLINE=1"),q.forEach(a),A=n(C,"."),C.forEach(a),this.h()},h(){m(d,"href","https://huggingface.co/docs/datasets/"),m(d,"rel","nofollow")},m(S,C){f(S,u,C),t(u,y),t(u,d),t(d,w),t(u,T),t(u,b),t(b,z),t(u,A)},d(S){S&&a(u)}}}function Ms(M){let u,y,d,w,T;return{c(){u=l("p"),y=r("Fai riferimento alla sezione "),d=l("a"),w=r("How to download files from the Hub"),T=r(" per avere maggiori dettagli su come scaricare modelli presenti sull Hub."),this.h()},l(b){u=i(b,"P",{});var z=o(u);y=n(z,"Fai riferimento alla sezione "),d=i(z,"A",{href:!0,rel:!0});var A=o(d);w=n(A,"How to download files from the Hub"),A.forEach(a),T=n(z," per avere maggiori dettagli su come scaricare modelli presenti sull Hub."),z.forEach(a),this.h()},h(){m(d,"href","https://huggingface.co/docs/hub/how-to-downstream"),m(d,"rel","nofollow")},m(b,z){f(b,u,z),t(u,y),t(u,d),t(d,w),t(u,T)},d(b){b&&a(u)}}}function js(M){let u,y,d,w,T,b,z,A,S,C,I,q,O,U,zt,$e,j,wt,Ee,bi,zi,wi,Tt,be,Ti,Pi,yi,Pt,ze,Ai,Ci,Ba,B,te,ea,we,Si,ta,Oi,Qa,D,ki,Te,Ii,qi,Pe,Fi,Ri,Va,yt,Mi,Ga,ye,Ya,At,ji,Wa,Ae,Xa,Ct,Di,Ja,Ce,Ka,St,Hi,Za,Se,el,Ot,Ni,tl,Oe,al,kt,xi,ll,ke,il,It,Li,ol,Ie,rl,qt,Ui,nl,qe,sl,Q,ae,aa,Fe,Bi,la,Qi,fl,Ft,Vi,pl,Re,cl,k,Gi,ia,Yi,Wi,oa,Xi,Ji,ra,Ki,Zi,Me,eo,to,ml,Rt,ao,ul,je,dl,V,le,na,De,lo,sa,io,hl,Mt,oo,vl,ie,He,ro,fa,no,so,fo,pa,po,_l,jt,co,gl,Ne,$l,H,mo,ca,uo,ho,ma,vo,_o,El,oe,bl,Dt,go,zl,xe,wl,re,$o,ua,Eo,bo,Tl,G,ne,da,Le,zo,ha,wo,Pl,se,To,va,Po,yo,yl,Ue,Al,Y,fe,_a,Be,Ao,ga,Co,Cl,F,So,$a,Oo,ko,Ea,Io,qo,ba,Fo,Ro,Sl,N,Qe,Mo,za,jo,Do,Ho,W,No,wa,xo,Lo,Ta,Uo,Bo,Qo,X,Vo,Pa,Go,Yo,ya,Wo,Xo,Ol,pe,kl,J,ce,Aa,Ve,Jo,Ca,Ko,Il,me,Zo,Sa,er,tr,ql,ue,Fl,Ht,ar,Rl,Ge,Ml,Nt,lr,jl,Ye,Dl,xt,ir,Hl,K,de,Oa,We,or,ka,rr,Nl,Lt,nr,xl,x,Xe,Je,sr,Ke,fr,pr,cr,Ia,Ut,tn,mr,Ze,Z,ur,qa,dr,hr,Fa,vr,_r,gr,ee,et,tt,$r,Ra,Er,br,zr,at,wr,lt,it,Tr,Ma,Pr,yr,Ar,ot,Cr,rt,nt,Sr,ja,Or,kr,Ir,st,qr,ft,pt,Fr,ct,Rr,Mr,jr,mt,ut,dt,Dr,Da,Hr,Nr,xr,ht,Lr,vt,R,Ur,_t,Ha,Br,Qr,Na,Vr,Gr,gt,Yr,Wr,Xr,$t,Ll,Bt,Jr,Ul,Et,Bl,he,Ql;return b=new ge({}),we=new ge({}),ye=new P({props:{code:"python -m venv .env",highlighted:'python -m venv .<span class="hljs-built_in">env</span>'}}),Ae=new P({props:{code:"source .env/bin/activate",highlighted:'<span class="hljs-built_in">source</span> .<span class="hljs-built_in">env</span>/bin/activate'}}),Ce=new P({props:{code:"pip install transformers",highlighted:"pip install transformers"}}),Se=new P({props:{code:"pip install transformers[torch]",highlighted:"pip install transformers[torch]"}}),Oe=new P({props:{code:"pip install transformers[tf-cpu]",highlighted:"pip install transformers[tf-cpu]"}}),ke=new P({props:{code:"pip install transformers[flax]",highlighted:"pip install transformers[flax]"}}),Ie=new P({props:{code:`python -c "from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))"`,highlighted:'python -c <span class="hljs-string">&quot;from transformers import pipeline; print(pipeline(&#x27;sentiment-analysis&#x27;)(&#x27;we love you&#x27;))&quot;</span>'}}),qe=new P({props:{code:"[{'label': 'POSITIVE', 'score': 0.9998704791069031}]",highlighted:'[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;POSITIVE&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: 0.9998704791069031}]'}}),Fe=new ge({}),Re=new P({props:{code:"pip install git+https://github.com/huggingface/transformers",highlighted:"pip install git+https://github.com/huggingface/transformers"}}),je=new P({props:{code:`python -c "from transformers import pipeline; print(pipeline('sentiment-analysis')('I love you'))"`,highlighted:'python -c <span class="hljs-string">&quot;from transformers import pipeline; print(pipeline(&#x27;sentiment-analysis&#x27;)(&#x27;I love you&#x27;))&quot;</span>'}}),De=new ge({}),Ne=new P({props:{code:`git clone https://github.com/huggingface/transformers.git
cd transformers
pip install -e .`,highlighted:`git <span class="hljs-built_in">clone</span> https://github.com/huggingface/transformers.git
<span class="hljs-built_in">cd</span> transformers
pip install -e .`}}),oe=new Ei({props:{warning:!0,$$slots:{default:[qs]},$$scope:{ctx:M}}}),xe=new P({props:{code:`cd ~/transformers/
git pull`,highlighted:`<span class="hljs-built_in">cd</span> ~/transformers/
git pull`}}),Le=new ge({}),Ue=new P({props:{code:"conda install -c huggingface transformers",highlighted:"conda install -c huggingface transformers"}}),Be=new ge({}),pe=new Ei({props:{$$slots:{default:[Fs]},$$scope:{ctx:M}}}),Ve=new ge({}),ue=new Ei({props:{$$slots:{default:[Rs]},$$scope:{ctx:M}}}),Ge=new P({props:{code:"python examples/pytorch/translation/run_translation.py --model_name_or_path t5-small --dataset_name wmt16 --dataset_config ro-en ...",highlighted:"python examples/pytorch/translation/run_translation.py --model_name_or_path t5-small --dataset_name wmt16 --dataset_config ro-en ..."}}),Ye=new P({props:{code:`HF_DATASETS_OFFLINE=1 TRANSFORMERS_OFFLINE=1 \\
python examples/pytorch/translation/run_translation.py --model_name_or_path t5-small --dataset_name wmt16 --dataset_config ro-en ...`,highlighted:`HF_DATASETS_OFFLINE=1 TRANSFORMERS_OFFLINE=1 \\
python examples/pytorch/translation/run_translation.py --model_name_or_path t5-small --dataset_name wmt16 --dataset_config ro-en ...`}}),We=new ge({}),at=new P({props:{code:`from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

tokenizer = AutoTokenizer.from_pretrained("bigscience/T0_3B")
model = AutoModelForSeq2SeqLM.from_pretrained("bigscience/T0_3B")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bigscience/T0_3B&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;bigscience/T0_3B&quot;</span>)`}}),ot=new P({props:{code:`tokenizer.save_pretrained("./il/tuo/path/bigscience_t0")
model.save_pretrained("./il/tuo/path/bigscience_t0")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(<span class="hljs-string">&quot;./il/tuo/path/bigscience_t0&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.save_pretrained(<span class="hljs-string">&quot;./il/tuo/path/bigscience_t0&quot;</span>)`}}),st=new P({props:{code:`tokenizer = AutoTokenizer.from_pretrained("./il/tuo/path/bigscience_t0")
model = AutoModel.from_pretrained("./il/tuo/path/bigscience_t0")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./il/tuo/path/bigscience_t0&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;./il/tuo/path/bigscience_t0&quot;</span>)`}}),ht=new P({props:{code:"python -m pip install huggingface_hub",highlighted:"python -m pip install huggingface_hub"}}),$t=new P({props:{code:`from huggingface_hub import hf_hub_download

hf_hub_download(repo_id="bigscience/T0_3B", filename="config.json", cache_dir="./il/tuo/path/bigscience_t0")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> hf_hub_download

<span class="hljs-meta">&gt;&gt;&gt; </span>hf_hub_download(repo_id=<span class="hljs-string">&quot;bigscience/T0_3B&quot;</span>, filename=<span class="hljs-string">&quot;config.json&quot;</span>, cache_dir=<span class="hljs-string">&quot;./il/tuo/path/bigscience_t0&quot;</span>)`}}),Et=new P({props:{code:`from transformers import AutoConfig

config = AutoConfig.from_pretrained("./il/tuo/path/bigscience_t0/config.json")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./il/tuo/path/bigscience_t0/config.json&quot;</span>)`}}),he=new Ei({props:{$$slots:{default:[Ms]},$$scope:{ctx:M}}}),{c(){u=l("meta"),y=p(),d=l("h1"),w=l("a"),T=l("span"),h(b.$$.fragment),z=p(),A=l("span"),S=r("Installazione"),C=p(),I=l("p"),q=r("Installa \u{1F917} Transformers per qualsiasi libreria di deep learning con cui stai lavorando, imposta la tua cache, e opzionalmente configura \u{1F917} Transformers per l\u2019esecuzione offline."),O=p(),U=l("p"),zt=r("\u{1F917} Transformers \xE8 testato su Python 3.6+, PyTorch 1.1.0+, TensorFlow 2.0+, e Flax. Segui le istruzioni di installazione seguenti per la libreria di deep learning che stai utilizzando:"),$e=p(),j=l("ul"),wt=l("li"),Ee=l("a"),bi=r("PyTorch"),zi=r(" istruzioni di installazione."),wi=p(),Tt=l("li"),be=l("a"),Ti=r("TensorFlow 2.0"),Pi=r(" istruzioni di installazione."),yi=p(),Pt=l("li"),ze=l("a"),Ai=r("Flax"),Ci=r(" istruzioni di installazione."),Ba=p(),B=l("h2"),te=l("a"),ea=l("span"),h(we.$$.fragment),Si=p(),ta=l("span"),Oi=r("Installazione con pip"),Qa=p(),D=l("p"),ki=r("Puoi installare \u{1F917} Transformers in un "),Te=l("a"),Ii=r("ambiente virtuale"),qi=r(". Se non sei familiare con gli ambienti virtuali in Python, dai un\u2019occhiata a questa "),Pe=l("a"),Fi=r("guida"),Ri=r(". Un ambiente virtuale rende pi\xF9 semplice la gestione di progetti differenti, evitando problemi di compatibilit\xE0 tra dipendenze."),Va=p(),yt=l("p"),Mi=r("Inizia creando un ambiente virtuale nella directory del tuo progetto:"),Ga=p(),h(ye.$$.fragment),Ya=p(),At=l("p"),ji=r("Attiva l\u2019ambiente virtuale:"),Wa=p(),h(Ae.$$.fragment),Xa=p(),Ct=l("p"),Di=r("Ora puoi procedere con l\u2019installazione di \u{1F917} Transformers eseguendo il comando seguente:"),Ja=p(),h(Ce.$$.fragment),Ka=p(),St=l("p"),Hi=r("Per il solo supporto della CPU, puoi installare facilmente \u{1F917} Transformers e una libreria di deep learning in solo una riga. Ad esempio, installiamo \u{1F917} Transformers e PyTorch con:"),Za=p(),h(Se.$$.fragment),el=p(),Ot=l("p"),Ni=r("\u{1F917} Transformers e TensorFlow 2.0:"),tl=p(),h(Oe.$$.fragment),al=p(),kt=l("p"),xi=r("\u{1F917} Transformers e Flax:"),ll=p(),h(ke.$$.fragment),il=p(),It=l("p"),Li=r("Infine, verifica se \u{1F917} Transformers \xE8 stato installato in modo appropriato eseguendo il seguente comando. Questo scaricher\xE0 un modello pre-allenato:"),ol=p(),h(Ie.$$.fragment),rl=p(),qt=l("p"),Ui=r("Dopodich\xE9 stampa l\u2019etichetta e il punteggio:"),nl=p(),h(qe.$$.fragment),sl=p(),Q=l("h2"),ae=l("a"),aa=l("span"),h(Fe.$$.fragment),Bi=p(),la=l("span"),Qi=r("Installazione dalla fonte"),fl=p(),Ft=l("p"),Vi=r("Installa \u{1F917} Transformers dalla fonte con il seguente comando:"),pl=p(),h(Re.$$.fragment),cl=p(),k=l("p"),Gi=r("Questo comando installa la versione "),ia=l("code"),Yi=r("main"),Wi=r(" pi\xF9 attuale invece dell\u2019ultima versione stabile. Questo \xE8 utile per stare al passo con gli ultimi sviluppi. Ad esempio, se un bug \xE8 stato sistemato da quando \xE8 uscita l\u2019ultima versione ufficiale ma non \xE8 stata ancora rilasciata una nuova versione. Tuttavia, questo significa che questa versione "),oa=l("code"),Xi=r("main"),Ji=r(" pu\xF2 non essere sempre stabile. Ci sforziamo per mantenere la versione "),ra=l("code"),Ki=r("main"),Zi=r(" operativa, e la maggior parte dei problemi viene risolta in poche ore o in un giorno. Se riscontri un problema, per favore apri una "),Me=l("a"),eo=r("Issue"),to=r(" cos\xEC possiamo sistemarlo ancora pi\xF9 velocemente!"),ml=p(),Rt=l("p"),ao=r("Controlla se \u{1F917} Transformers \xE8 stata installata in modo appropriato con il seguente comando:"),ul=p(),h(je.$$.fragment),dl=p(),V=l("h2"),le=l("a"),na=l("span"),h(De.$$.fragment),lo=p(),sa=l("span"),io=r("Installazione modificabile"),hl=p(),Mt=l("p"),oo=r("Hai bisogno di un\u2019installazione modificabile se vuoi:"),vl=p(),ie=l("ul"),He=l("li"),ro=r("Usare la versione "),fa=l("code"),no=r("main"),so=r(" del codice dalla fonte."),fo=p(),pa=l("li"),po=r("Contribuire a \u{1F917} Transformers e hai bisogno di testare i cambiamenti nel codice."),_l=p(),jt=l("p"),co=r("Clona il repository e installa \u{1F917} Transformers con i seguenti comandi:"),gl=p(),h(Ne.$$.fragment),$l=p(),H=l("p"),mo=r("Questi comandi collegheranno la cartella in cui \xE8 stato clonato il repository e i path delle librerie Python. Python guarder\xE0 ora all\u2019interno della cartella clonata, oltre ai normali path delle librerie. Per esempio, se i tuoi pacchetti Python sono installati tipicamente in "),ca=l("code"),uo=r("~/anaconda3/envs/main/lib/python3.7/site-packages/"),ho=r(", Python cercher\xE0 anche nella cartella clonata: "),ma=l("code"),vo=r("~/transformers/"),_o=r("."),El=p(),h(oe.$$.fragment),bl=p(),Dt=l("p"),go=r("Ora puoi facilmente aggiornare il tuo clone all\u2019ultima versione di \u{1F917} Transformers con il seguente comando:"),zl=p(),h(xe.$$.fragment),wl=p(),re=l("p"),$o=r("Il tuo ambiente Python trover\xE0 la versione "),ua=l("code"),Eo=r("main"),bo=r(" di \u{1F917} Transformers alla prossima esecuzione."),Tl=p(),G=l("h2"),ne=l("a"),da=l("span"),h(Le.$$.fragment),zo=p(),ha=l("span"),wo=r("Installazione con conda"),Pl=p(),se=l("p"),To=r("Installazione dal canale conda "),va=l("code"),Po=r("huggingface"),yo=r(":"),yl=p(),h(Ue.$$.fragment),Al=p(),Y=l("h2"),fe=l("a"),_a=l("span"),h(Be.$$.fragment),Ao=p(),ga=l("span"),Co=r("Impostazione della cache"),Cl=p(),F=l("p"),So=r("I modelli pre-allenati sono scaricati e memorizzati localmente nella cache in: "),$a=l("code"),Oo=r("~/.cache/huggingface/transformers/"),ko=r(". Questa \xE8 la directory di default data dalla variabile d\u2019ambiente della shell "),Ea=l("code"),Io=r("TRANSFORMERS_CACHE"),qo=r(". Su Windows, la directory di default \xE8 data da "),ba=l("code"),Fo=r("C:\\Users\\username\\.cache\\huggingface\\transformers"),Ro=r(". Puoi cambiare le variabili d\u2019ambiente della shell indicate in seguito, in ordine di priorit\xE0, per specificare una directory differente per la cache:"),Sl=p(),N=l("ol"),Qe=l("li"),Mo=r("Variabile d\u2019ambiente della shell (default): "),za=l("code"),jo=r("TRANSFORMERS_CACHE"),Do=r("."),Ho=p(),W=l("li"),No=r("Variabile d\u2019ambiente della shell: "),wa=l("code"),xo=r("HF_HOME"),Lo=r(" + "),Ta=l("code"),Uo=r("transformers/"),Bo=r("."),Qo=p(),X=l("li"),Vo=r("Variabile d\u2019ambiente della shell: "),Pa=l("code"),Go=r("XDG_CACHE_HOME"),Yo=r(" + "),ya=l("code"),Wo=r("/huggingface/transformers"),Xo=r("."),Ol=p(),h(pe.$$.fragment),kl=p(),J=l("h2"),ce=l("a"),Aa=l("span"),h(Ve.$$.fragment),Jo=p(),Ca=l("span"),Ko=r("Modalit\xE0 Offline"),Il=p(),me=l("p"),Zo=r("\u{1F917} Transformers pu\xF2 essere eseguita in un ambiente firewalled o offline utilizzando solo file locali. Imposta la variabile d\u2019ambiente "),Sa=l("code"),er=r("TRANSFORMERS_OFFLINE=1"),tr=r(" per abilitare questo comportamento."),ql=p(),h(ue.$$.fragment),Fl=p(),Ht=l("p"),ar=r("Ad esempio, in genere si esegue un programma su una rete normale, protetta da firewall per le istanze esterne, con il seguente comando:"),Rl=p(),h(Ge.$$.fragment),Ml=p(),Nt=l("p"),lr=r("Esegui lo stesso programma in un\u2019istanza offline con:"),jl=p(),h(Ye.$$.fragment),Dl=p(),xt=l("p"),ir=r("Lo script viene ora eseguito senza bloccarsi o attendere il timeout, perch\xE9 sa di dover cercare solo file locali."),Hl=p(),K=l("h3"),de=l("a"),Oa=l("span"),h(We.$$.fragment),or=p(),ka=l("span"),rr=r("Ottenere modelli e tokenizer per l'uso offline"),Nl=p(),Lt=l("p"),nr=r("Un\u2019altra opzione per utilizzare offline \u{1F917} Transformers \xE8 scaricare i file in anticipo, e poi puntare al loro path locale quando hai la necessit\xE0 di utilizzarli offline. Ci sono tre modi per fare questo:"),xl=p(),x=l("ul"),Xe=l("li"),Je=l("p"),sr=r("Scarica un file tramite l\u2019interfaccia utente sul "),Ke=l("a"),fr=r("Model Hub"),pr=r(" premendo sull\u2019icona \u2193."),cr=p(),Ia=l("p"),Ut=l("img"),mr=p(),Ze=l("li"),Z=l("p"),ur=r("Utilizza il flusso "),qa=l("code"),dr=r("PreTrainedModel.from_pretrained()"),hr=r(" e "),Fa=l("code"),vr=r("PreTrainedModel.save_pretrained()"),_r=r(":"),gr=p(),ee=l("ol"),et=l("li"),tt=l("p"),$r=r("Scarica i tuoi file in anticipo con "),Ra=l("code"),Er=r("PreTrainedModel.from_pretrained()"),br=r(":"),zr=p(),h(at.$$.fragment),wr=p(),lt=l("li"),it=l("p"),Tr=r("Salva i tuoi file in una directory specificata con "),Ma=l("code"),Pr=r("PreTrainedModel.save_pretrained()"),yr=r(":"),Ar=p(),h(ot.$$.fragment),Cr=p(),rt=l("li"),nt=l("p"),Sr=r("Ora quando sei offline, carica i tuoi file con "),ja=l("code"),Or=r("PreTrainedModel.from_pretrained()"),kr=r(" dalla directory specificata:"),Ir=p(),h(st.$$.fragment),qr=p(),ft=l("li"),pt=l("p"),Fr=r("Scarica in maniera programmatica i file con la libreria "),ct=l("a"),Rr=r("huggingface_hub"),Mr=r(":"),jr=p(),mt=l("ol"),ut=l("li"),dt=l("p"),Dr=r("Installa la libreria "),Da=l("code"),Hr=r("huggingface_hub"),Nr=r(" nel tuo ambiente virtuale:"),xr=p(),h(ht.$$.fragment),Lr=p(),vt=l("li"),R=l("p"),Ur=r("Utilizza la funzione "),_t=l("a"),Ha=l("code"),Br=r("hf_hub_download"),Qr=r(" per scaricare un file in un path specifico. Per esempio, il seguente comando scarica il file "),Na=l("code"),Vr=r("config.json"),Gr=r(" dal modello "),gt=l("a"),Yr=r("T0"),Wr=r(" nel path che desideri:"),Xr=p(),h($t.$$.fragment),Ll=p(),Bt=l("p"),Jr=r("Una volta che il tuo file \xE8 scaricato e salvato in cache localmente, specifica il suo path locale per caricarlo e utilizzarlo:"),Ul=p(),h(Et.$$.fragment),Bl=p(),h(he.$$.fragment),this.h()},l(e){const s=Os('[data-svelte="svelte-1phssyn"]',document.head);u=i(s,"META",{name:!0,content:!0}),s.forEach(a),y=c(e),d=i(e,"H1",{class:!0});var bt=o(d);w=i(bt,"A",{id:!0,class:!0,href:!0});var xa=o(w);T=i(xa,"SPAN",{});var La=o(T);v(b.$$.fragment,La),La.forEach(a),xa.forEach(a),z=c(bt),A=i(bt,"SPAN",{});var Ua=o(A);S=n(Ua,"Installazione"),Ua.forEach(a),bt.forEach(a),C=c(e),I=i(e,"P",{});var an=o(I);q=n(an,"Installa \u{1F917} Transformers per qualsiasi libreria di deep learning con cui stai lavorando, imposta la tua cache, e opzionalmente configura \u{1F917} Transformers per l\u2019esecuzione offline."),an.forEach(a),O=c(e),U=i(e,"P",{});var ln=o(U);zt=n(ln,"\u{1F917} Transformers \xE8 testato su Python 3.6+, PyTorch 1.1.0+, TensorFlow 2.0+, e Flax. Segui le istruzioni di installazione seguenti per la libreria di deep learning che stai utilizzando:"),ln.forEach(a),$e=c(e),j=i(e,"UL",{});var Qt=o(j);wt=i(Qt,"LI",{});var Kr=o(wt);Ee=i(Kr,"A",{href:!0,rel:!0});var on=o(Ee);bi=n(on,"PyTorch"),on.forEach(a),zi=n(Kr," istruzioni di installazione."),Kr.forEach(a),wi=c(Qt),Tt=i(Qt,"LI",{});var Zr=o(Tt);be=i(Zr,"A",{href:!0,rel:!0});var rn=o(be);Ti=n(rn,"TensorFlow 2.0"),rn.forEach(a),Pi=n(Zr," istruzioni di installazione."),Zr.forEach(a),yi=c(Qt),Pt=i(Qt,"LI",{});var en=o(Pt);ze=i(en,"A",{href:!0,rel:!0});var nn=o(ze);Ai=n(nn,"Flax"),nn.forEach(a),Ci=n(en," istruzioni di installazione."),en.forEach(a),Qt.forEach(a),Ba=c(e),B=i(e,"H2",{class:!0});var Vl=o(B);te=i(Vl,"A",{id:!0,class:!0,href:!0});var sn=o(te);ea=i(sn,"SPAN",{});var fn=o(ea);v(we.$$.fragment,fn),fn.forEach(a),sn.forEach(a),Si=c(Vl),ta=i(Vl,"SPAN",{});var pn=o(ta);Oi=n(pn,"Installazione con pip"),pn.forEach(a),Vl.forEach(a),Qa=c(e),D=i(e,"P",{});var Vt=o(D);ki=n(Vt,"Puoi installare \u{1F917} Transformers in un "),Te=i(Vt,"A",{href:!0,rel:!0});var cn=o(Te);Ii=n(cn,"ambiente virtuale"),cn.forEach(a),qi=n(Vt,". Se non sei familiare con gli ambienti virtuali in Python, dai un\u2019occhiata a questa "),Pe=i(Vt,"A",{href:!0,rel:!0});var mn=o(Pe);Fi=n(mn,"guida"),mn.forEach(a),Ri=n(Vt,". Un ambiente virtuale rende pi\xF9 semplice la gestione di progetti differenti, evitando problemi di compatibilit\xE0 tra dipendenze."),Vt.forEach(a),Va=c(e),yt=i(e,"P",{});var un=o(yt);Mi=n(un,"Inizia creando un ambiente virtuale nella directory del tuo progetto:"),un.forEach(a),Ga=c(e),v(ye.$$.fragment,e),Ya=c(e),At=i(e,"P",{});var dn=o(At);ji=n(dn,"Attiva l\u2019ambiente virtuale:"),dn.forEach(a),Wa=c(e),v(Ae.$$.fragment,e),Xa=c(e),Ct=i(e,"P",{});var hn=o(Ct);Di=n(hn,"Ora puoi procedere con l\u2019installazione di \u{1F917} Transformers eseguendo il comando seguente:"),hn.forEach(a),Ja=c(e),v(Ce.$$.fragment,e),Ka=c(e),St=i(e,"P",{});var vn=o(St);Hi=n(vn,"Per il solo supporto della CPU, puoi installare facilmente \u{1F917} Transformers e una libreria di deep learning in solo una riga. Ad esempio, installiamo \u{1F917} Transformers e PyTorch con:"),vn.forEach(a),Za=c(e),v(Se.$$.fragment,e),el=c(e),Ot=i(e,"P",{});var _n=o(Ot);Ni=n(_n,"\u{1F917} Transformers e TensorFlow 2.0:"),_n.forEach(a),tl=c(e),v(Oe.$$.fragment,e),al=c(e),kt=i(e,"P",{});var gn=o(kt);xi=n(gn,"\u{1F917} Transformers e Flax:"),gn.forEach(a),ll=c(e),v(ke.$$.fragment,e),il=c(e),It=i(e,"P",{});var $n=o(It);Li=n($n,"Infine, verifica se \u{1F917} Transformers \xE8 stato installato in modo appropriato eseguendo il seguente comando. Questo scaricher\xE0 un modello pre-allenato:"),$n.forEach(a),ol=c(e),v(Ie.$$.fragment,e),rl=c(e),qt=i(e,"P",{});var En=o(qt);Ui=n(En,"Dopodich\xE9 stampa l\u2019etichetta e il punteggio:"),En.forEach(a),nl=c(e),v(qe.$$.fragment,e),sl=c(e),Q=i(e,"H2",{class:!0});var Gl=o(Q);ae=i(Gl,"A",{id:!0,class:!0,href:!0});var bn=o(ae);aa=i(bn,"SPAN",{});var zn=o(aa);v(Fe.$$.fragment,zn),zn.forEach(a),bn.forEach(a),Bi=c(Gl),la=i(Gl,"SPAN",{});var wn=o(la);Qi=n(wn,"Installazione dalla fonte"),wn.forEach(a),Gl.forEach(a),fl=c(e),Ft=i(e,"P",{});var Tn=o(Ft);Vi=n(Tn,"Installa \u{1F917} Transformers dalla fonte con il seguente comando:"),Tn.forEach(a),pl=c(e),v(Re.$$.fragment,e),cl=c(e),k=i(e,"P",{});var L=o(k);Gi=n(L,"Questo comando installa la versione "),ia=i(L,"CODE",{});var Pn=o(ia);Yi=n(Pn,"main"),Pn.forEach(a),Wi=n(L," pi\xF9 attuale invece dell\u2019ultima versione stabile. Questo \xE8 utile per stare al passo con gli ultimi sviluppi. Ad esempio, se un bug \xE8 stato sistemato da quando \xE8 uscita l\u2019ultima versione ufficiale ma non \xE8 stata ancora rilasciata una nuova versione. Tuttavia, questo significa che questa versione "),oa=i(L,"CODE",{});var yn=o(oa);Xi=n(yn,"main"),yn.forEach(a),Ji=n(L," pu\xF2 non essere sempre stabile. Ci sforziamo per mantenere la versione "),ra=i(L,"CODE",{});var An=o(ra);Ki=n(An,"main"),An.forEach(a),Zi=n(L," operativa, e la maggior parte dei problemi viene risolta in poche ore o in un giorno. Se riscontri un problema, per favore apri una "),Me=i(L,"A",{href:!0,rel:!0});var Cn=o(Me);eo=n(Cn,"Issue"),Cn.forEach(a),to=n(L," cos\xEC possiamo sistemarlo ancora pi\xF9 velocemente!"),L.forEach(a),ml=c(e),Rt=i(e,"P",{});var Sn=o(Rt);ao=n(Sn,"Controlla se \u{1F917} Transformers \xE8 stata installata in modo appropriato con il seguente comando:"),Sn.forEach(a),ul=c(e),v(je.$$.fragment,e),dl=c(e),V=i(e,"H2",{class:!0});var Yl=o(V);le=i(Yl,"A",{id:!0,class:!0,href:!0});var On=o(le);na=i(On,"SPAN",{});var kn=o(na);v(De.$$.fragment,kn),kn.forEach(a),On.forEach(a),lo=c(Yl),sa=i(Yl,"SPAN",{});var In=o(sa);io=n(In,"Installazione modificabile"),In.forEach(a),Yl.forEach(a),hl=c(e),Mt=i(e,"P",{});var qn=o(Mt);oo=n(qn,"Hai bisogno di un\u2019installazione modificabile se vuoi:"),qn.forEach(a),vl=c(e),ie=i(e,"UL",{});var Wl=o(ie);He=i(Wl,"LI",{});var Xl=o(He);ro=n(Xl,"Usare la versione "),fa=i(Xl,"CODE",{});var Fn=o(fa);no=n(Fn,"main"),Fn.forEach(a),so=n(Xl," del codice dalla fonte."),Xl.forEach(a),fo=c(Wl),pa=i(Wl,"LI",{});var Rn=o(pa);po=n(Rn,"Contribuire a \u{1F917} Transformers e hai bisogno di testare i cambiamenti nel codice."),Rn.forEach(a),Wl.forEach(a),_l=c(e),jt=i(e,"P",{});var Mn=o(jt);co=n(Mn,"Clona il repository e installa \u{1F917} Transformers con i seguenti comandi:"),Mn.forEach(a),gl=c(e),v(Ne.$$.fragment,e),$l=c(e),H=i(e,"P",{});var Gt=o(H);mo=n(Gt,"Questi comandi collegheranno la cartella in cui \xE8 stato clonato il repository e i path delle librerie Python. Python guarder\xE0 ora all\u2019interno della cartella clonata, oltre ai normali path delle librerie. Per esempio, se i tuoi pacchetti Python sono installati tipicamente in "),ca=i(Gt,"CODE",{});var jn=o(ca);uo=n(jn,"~/anaconda3/envs/main/lib/python3.7/site-packages/"),jn.forEach(a),ho=n(Gt,", Python cercher\xE0 anche nella cartella clonata: "),ma=i(Gt,"CODE",{});var Dn=o(ma);vo=n(Dn,"~/transformers/"),Dn.forEach(a),_o=n(Gt,"."),Gt.forEach(a),El=c(e),v(oe.$$.fragment,e),bl=c(e),Dt=i(e,"P",{});var Hn=o(Dt);go=n(Hn,"Ora puoi facilmente aggiornare il tuo clone all\u2019ultima versione di \u{1F917} Transformers con il seguente comando:"),Hn.forEach(a),zl=c(e),v(xe.$$.fragment,e),wl=c(e),re=i(e,"P",{});var Jl=o(re);$o=n(Jl,"Il tuo ambiente Python trover\xE0 la versione "),ua=i(Jl,"CODE",{});var Nn=o(ua);Eo=n(Nn,"main"),Nn.forEach(a),bo=n(Jl," di \u{1F917} Transformers alla prossima esecuzione."),Jl.forEach(a),Tl=c(e),G=i(e,"H2",{class:!0});var Kl=o(G);ne=i(Kl,"A",{id:!0,class:!0,href:!0});var xn=o(ne);da=i(xn,"SPAN",{});var Ln=o(da);v(Le.$$.fragment,Ln),Ln.forEach(a),xn.forEach(a),zo=c(Kl),ha=i(Kl,"SPAN",{});var Un=o(ha);wo=n(Un,"Installazione con conda"),Un.forEach(a),Kl.forEach(a),Pl=c(e),se=i(e,"P",{});var Zl=o(se);To=n(Zl,"Installazione dal canale conda "),va=i(Zl,"CODE",{});var Bn=o(va);Po=n(Bn,"huggingface"),Bn.forEach(a),yo=n(Zl,":"),Zl.forEach(a),yl=c(e),v(Ue.$$.fragment,e),Al=c(e),Y=i(e,"H2",{class:!0});var ei=o(Y);fe=i(ei,"A",{id:!0,class:!0,href:!0});var Qn=o(fe);_a=i(Qn,"SPAN",{});var Vn=o(_a);v(Be.$$.fragment,Vn),Vn.forEach(a),Qn.forEach(a),Ao=c(ei),ga=i(ei,"SPAN",{});var Gn=o(ga);Co=n(Gn,"Impostazione della cache"),Gn.forEach(a),ei.forEach(a),Cl=c(e),F=i(e,"P",{});var ve=o(F);So=n(ve,"I modelli pre-allenati sono scaricati e memorizzati localmente nella cache in: "),$a=i(ve,"CODE",{});var Yn=o($a);Oo=n(Yn,"~/.cache/huggingface/transformers/"),Yn.forEach(a),ko=n(ve,". Questa \xE8 la directory di default data dalla variabile d\u2019ambiente della shell "),Ea=i(ve,"CODE",{});var Wn=o(Ea);Io=n(Wn,"TRANSFORMERS_CACHE"),Wn.forEach(a),qo=n(ve,". Su Windows, la directory di default \xE8 data da "),ba=i(ve,"CODE",{});var Xn=o(ba);Fo=n(Xn,"C:\\Users\\username\\.cache\\huggingface\\transformers"),Xn.forEach(a),Ro=n(ve,". Puoi cambiare le variabili d\u2019ambiente della shell indicate in seguito, in ordine di priorit\xE0, per specificare una directory differente per la cache:"),ve.forEach(a),Sl=c(e),N=i(e,"OL",{});var Yt=o(N);Qe=i(Yt,"LI",{});var ti=o(Qe);Mo=n(ti,"Variabile d\u2019ambiente della shell (default): "),za=i(ti,"CODE",{});var Jn=o(za);jo=n(Jn,"TRANSFORMERS_CACHE"),Jn.forEach(a),Do=n(ti,"."),ti.forEach(a),Ho=c(Yt),W=i(Yt,"LI",{});var Wt=o(W);No=n(Wt,"Variabile d\u2019ambiente della shell: "),wa=i(Wt,"CODE",{});var Kn=o(wa);xo=n(Kn,"HF_HOME"),Kn.forEach(a),Lo=n(Wt," + "),Ta=i(Wt,"CODE",{});var Zn=o(Ta);Uo=n(Zn,"transformers/"),Zn.forEach(a),Bo=n(Wt,"."),Wt.forEach(a),Qo=c(Yt),X=i(Yt,"LI",{});var Xt=o(X);Vo=n(Xt,"Variabile d\u2019ambiente della shell: "),Pa=i(Xt,"CODE",{});var es=o(Pa);Go=n(es,"XDG_CACHE_HOME"),es.forEach(a),Yo=n(Xt," + "),ya=i(Xt,"CODE",{});var ts=o(ya);Wo=n(ts,"/huggingface/transformers"),ts.forEach(a),Xo=n(Xt,"."),Xt.forEach(a),Yt.forEach(a),Ol=c(e),v(pe.$$.fragment,e),kl=c(e),J=i(e,"H2",{class:!0});var ai=o(J);ce=i(ai,"A",{id:!0,class:!0,href:!0});var as=o(ce);Aa=i(as,"SPAN",{});var ls=o(Aa);v(Ve.$$.fragment,ls),ls.forEach(a),as.forEach(a),Jo=c(ai),Ca=i(ai,"SPAN",{});var is=o(Ca);Ko=n(is,"Modalit\xE0 Offline"),is.forEach(a),ai.forEach(a),Il=c(e),me=i(e,"P",{});var li=o(me);Zo=n(li,"\u{1F917} Transformers pu\xF2 essere eseguita in un ambiente firewalled o offline utilizzando solo file locali. Imposta la variabile d\u2019ambiente "),Sa=i(li,"CODE",{});var os=o(Sa);er=n(os,"TRANSFORMERS_OFFLINE=1"),os.forEach(a),tr=n(li," per abilitare questo comportamento."),li.forEach(a),ql=c(e),v(ue.$$.fragment,e),Fl=c(e),Ht=i(e,"P",{});var rs=o(Ht);ar=n(rs,"Ad esempio, in genere si esegue un programma su una rete normale, protetta da firewall per le istanze esterne, con il seguente comando:"),rs.forEach(a),Rl=c(e),v(Ge.$$.fragment,e),Ml=c(e),Nt=i(e,"P",{});var ns=o(Nt);lr=n(ns,"Esegui lo stesso programma in un\u2019istanza offline con:"),ns.forEach(a),jl=c(e),v(Ye.$$.fragment,e),Dl=c(e),xt=i(e,"P",{});var ss=o(xt);ir=n(ss,"Lo script viene ora eseguito senza bloccarsi o attendere il timeout, perch\xE9 sa di dover cercare solo file locali."),ss.forEach(a),Hl=c(e),K=i(e,"H3",{class:!0});var ii=o(K);de=i(ii,"A",{id:!0,class:!0,href:!0});var fs=o(de);Oa=i(fs,"SPAN",{});var ps=o(Oa);v(We.$$.fragment,ps),ps.forEach(a),fs.forEach(a),or=c(ii),ka=i(ii,"SPAN",{});var cs=o(ka);rr=n(cs,"Ottenere modelli e tokenizer per l'uso offline"),cs.forEach(a),ii.forEach(a),Nl=c(e),Lt=i(e,"P",{});var ms=o(Lt);nr=n(ms,"Un\u2019altra opzione per utilizzare offline \u{1F917} Transformers \xE8 scaricare i file in anticipo, e poi puntare al loro path locale quando hai la necessit\xE0 di utilizzarli offline. Ci sono tre modi per fare questo:"),ms.forEach(a),xl=c(e),x=i(e,"UL",{});var Jt=o(x);Xe=i(Jt,"LI",{});var oi=o(Xe);Je=i(oi,"P",{});var ri=o(Je);sr=n(ri,"Scarica un file tramite l\u2019interfaccia utente sul "),Ke=i(ri,"A",{href:!0,rel:!0});var us=o(Ke);fr=n(us,"Model Hub"),us.forEach(a),pr=n(ri," premendo sull\u2019icona \u2193."),ri.forEach(a),cr=c(oi),Ia=i(oi,"P",{});var ds=o(Ia);Ut=i(ds,"IMG",{src:!0,alt:!0}),ds.forEach(a),oi.forEach(a),mr=c(Jt),Ze=i(Jt,"LI",{});var ni=o(Ze);Z=i(ni,"P",{});var Kt=o(Z);ur=n(Kt,"Utilizza il flusso "),qa=i(Kt,"CODE",{});var hs=o(qa);dr=n(hs,"PreTrainedModel.from_pretrained()"),hs.forEach(a),hr=n(Kt," e "),Fa=i(Kt,"CODE",{});var vs=o(Fa);vr=n(vs,"PreTrainedModel.save_pretrained()"),vs.forEach(a),_r=n(Kt,":"),Kt.forEach(a),gr=c(ni),ee=i(ni,"OL",{});var Zt=o(ee);et=i(Zt,"LI",{});var si=o(et);tt=i(si,"P",{});var fi=o(tt);$r=n(fi,"Scarica i tuoi file in anticipo con "),Ra=i(fi,"CODE",{});var _s=o(Ra);Er=n(_s,"PreTrainedModel.from_pretrained()"),_s.forEach(a),br=n(fi,":"),fi.forEach(a),zr=c(si),v(at.$$.fragment,si),si.forEach(a),wr=c(Zt),lt=i(Zt,"LI",{});var pi=o(lt);it=i(pi,"P",{});var ci=o(it);Tr=n(ci,"Salva i tuoi file in una directory specificata con "),Ma=i(ci,"CODE",{});var gs=o(Ma);Pr=n(gs,"PreTrainedModel.save_pretrained()"),gs.forEach(a),yr=n(ci,":"),ci.forEach(a),Ar=c(pi),v(ot.$$.fragment,pi),pi.forEach(a),Cr=c(Zt),rt=i(Zt,"LI",{});var mi=o(rt);nt=i(mi,"P",{});var ui=o(nt);Sr=n(ui,"Ora quando sei offline, carica i tuoi file con "),ja=i(ui,"CODE",{});var $s=o(ja);Or=n($s,"PreTrainedModel.from_pretrained()"),$s.forEach(a),kr=n(ui," dalla directory specificata:"),ui.forEach(a),Ir=c(mi),v(st.$$.fragment,mi),mi.forEach(a),Zt.forEach(a),ni.forEach(a),qr=c(Jt),ft=i(Jt,"LI",{});var di=o(ft);pt=i(di,"P",{});var hi=o(pt);Fr=n(hi,"Scarica in maniera programmatica i file con la libreria "),ct=i(hi,"A",{href:!0,rel:!0});var Es=o(ct);Rr=n(Es,"huggingface_hub"),Es.forEach(a),Mr=n(hi,":"),hi.forEach(a),jr=c(di),mt=i(di,"OL",{});var vi=o(mt);ut=i(vi,"LI",{});var _i=o(ut);dt=i(_i,"P",{});var gi=o(dt);Dr=n(gi,"Installa la libreria "),Da=i(gi,"CODE",{});var bs=o(Da);Hr=n(bs,"huggingface_hub"),bs.forEach(a),Nr=n(gi," nel tuo ambiente virtuale:"),gi.forEach(a),xr=c(_i),v(ht.$$.fragment,_i),_i.forEach(a),Lr=c(vi),vt=i(vi,"LI",{});var $i=o(vt);R=i($i,"P",{});var _e=o(R);Ur=n(_e,"Utilizza la funzione "),_t=i(_e,"A",{href:!0,rel:!0});var zs=o(_t);Ha=i(zs,"CODE",{});var ws=o(Ha);Br=n(ws,"hf_hub_download"),ws.forEach(a),zs.forEach(a),Qr=n(_e," per scaricare un file in un path specifico. Per esempio, il seguente comando scarica il file "),Na=i(_e,"CODE",{});var Ts=o(Na);Vr=n(Ts,"config.json"),Ts.forEach(a),Gr=n(_e," dal modello "),gt=i(_e,"A",{href:!0,rel:!0});var Ps=o(gt);Yr=n(Ps,"T0"),Ps.forEach(a),Wr=n(_e," nel path che desideri:"),_e.forEach(a),Xr=c($i),v($t.$$.fragment,$i),$i.forEach(a),vi.forEach(a),di.forEach(a),Jt.forEach(a),Ll=c(e),Bt=i(e,"P",{});var ys=o(Bt);Jr=n(ys,"Una volta che il tuo file \xE8 scaricato e salvato in cache localmente, specifica il suo path locale per caricarlo e utilizzarlo:"),ys.forEach(a),Ul=c(e),v(Et.$$.fragment,e),Bl=c(e),v(he.$$.fragment,e),this.h()},h(){m(u,"name","hf:doc:metadata"),m(u,"content",JSON.stringify(Ds)),m(w,"id","installazione"),m(w,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(w,"href","#installazione"),m(d,"class","relative group"),m(Ee,"href","https://pytorch.org/get-started/locally/"),m(Ee,"rel","nofollow"),m(be,"href","https://www.tensorflow.org/install/pip"),m(be,"rel","nofollow"),m(ze,"href","https://flax.readthedocs.io/en/latest/"),m(ze,"rel","nofollow"),m(te,"id","installazione-con-pip"),m(te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(te,"href","#installazione-con-pip"),m(B,"class","relative group"),m(Te,"href","https://docs.python.org/3/library/venv.html"),m(Te,"rel","nofollow"),m(Pe,"href","https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/"),m(Pe,"rel","nofollow"),m(ae,"id","installazione-dalla-fonte"),m(ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ae,"href","#installazione-dalla-fonte"),m(Q,"class","relative group"),m(Me,"href","https://github.com/huggingface/transformers/issues"),m(Me,"rel","nofollow"),m(le,"id","installazione-modificabile"),m(le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(le,"href","#installazione-modificabile"),m(V,"class","relative group"),m(ne,"id","installazione-con-conda"),m(ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ne,"href","#installazione-con-conda"),m(G,"class","relative group"),m(fe,"id","impostazione-della-cache"),m(fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(fe,"href","#impostazione-della-cache"),m(Y,"class","relative group"),m(ce,"id","modalit-offline"),m(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ce,"href","#modalit-offline"),m(J,"class","relative group"),m(de,"id","ottenere-modelli-e-tokenizer-per-luso-offline"),m(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(de,"href","#ottenere-modelli-e-tokenizer-per-luso-offline"),m(K,"class","relative group"),m(Ke,"href","https://huggingface.co/models"),m(Ke,"rel","nofollow"),ks(Ut.src,tn="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/download-icon.png")||m(Ut,"src",tn),m(Ut,"alt","download-icon"),m(ct,"href","https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub"),m(ct,"rel","nofollow"),m(_t,"href","https://huggingface.co/docs/hub/adding-a-library#download-files-from-the-hub"),m(_t,"rel","nofollow"),m(gt,"href","https://huggingface.co/bigscience/T0_3B"),m(gt,"rel","nofollow")},m(e,s){t(document.head,u),f(e,y,s),f(e,d,s),t(d,w),t(w,T),_(b,T,null),t(d,z),t(d,A),t(A,S),f(e,C,s),f(e,I,s),t(I,q),f(e,O,s),f(e,U,s),t(U,zt),f(e,$e,s),f(e,j,s),t(j,wt),t(wt,Ee),t(Ee,bi),t(wt,zi),t(j,wi),t(j,Tt),t(Tt,be),t(be,Ti),t(Tt,Pi),t(j,yi),t(j,Pt),t(Pt,ze),t(ze,Ai),t(Pt,Ci),f(e,Ba,s),f(e,B,s),t(B,te),t(te,ea),_(we,ea,null),t(B,Si),t(B,ta),t(ta,Oi),f(e,Qa,s),f(e,D,s),t(D,ki),t(D,Te),t(Te,Ii),t(D,qi),t(D,Pe),t(Pe,Fi),t(D,Ri),f(e,Va,s),f(e,yt,s),t(yt,Mi),f(e,Ga,s),_(ye,e,s),f(e,Ya,s),f(e,At,s),t(At,ji),f(e,Wa,s),_(Ae,e,s),f(e,Xa,s),f(e,Ct,s),t(Ct,Di),f(e,Ja,s),_(Ce,e,s),f(e,Ka,s),f(e,St,s),t(St,Hi),f(e,Za,s),_(Se,e,s),f(e,el,s),f(e,Ot,s),t(Ot,Ni),f(e,tl,s),_(Oe,e,s),f(e,al,s),f(e,kt,s),t(kt,xi),f(e,ll,s),_(ke,e,s),f(e,il,s),f(e,It,s),t(It,Li),f(e,ol,s),_(Ie,e,s),f(e,rl,s),f(e,qt,s),t(qt,Ui),f(e,nl,s),_(qe,e,s),f(e,sl,s),f(e,Q,s),t(Q,ae),t(ae,aa),_(Fe,aa,null),t(Q,Bi),t(Q,la),t(la,Qi),f(e,fl,s),f(e,Ft,s),t(Ft,Vi),f(e,pl,s),_(Re,e,s),f(e,cl,s),f(e,k,s),t(k,Gi),t(k,ia),t(ia,Yi),t(k,Wi),t(k,oa),t(oa,Xi),t(k,Ji),t(k,ra),t(ra,Ki),t(k,Zi),t(k,Me),t(Me,eo),t(k,to),f(e,ml,s),f(e,Rt,s),t(Rt,ao),f(e,ul,s),_(je,e,s),f(e,dl,s),f(e,V,s),t(V,le),t(le,na),_(De,na,null),t(V,lo),t(V,sa),t(sa,io),f(e,hl,s),f(e,Mt,s),t(Mt,oo),f(e,vl,s),f(e,ie,s),t(ie,He),t(He,ro),t(He,fa),t(fa,no),t(He,so),t(ie,fo),t(ie,pa),t(pa,po),f(e,_l,s),f(e,jt,s),t(jt,co),f(e,gl,s),_(Ne,e,s),f(e,$l,s),f(e,H,s),t(H,mo),t(H,ca),t(ca,uo),t(H,ho),t(H,ma),t(ma,vo),t(H,_o),f(e,El,s),_(oe,e,s),f(e,bl,s),f(e,Dt,s),t(Dt,go),f(e,zl,s),_(xe,e,s),f(e,wl,s),f(e,re,s),t(re,$o),t(re,ua),t(ua,Eo),t(re,bo),f(e,Tl,s),f(e,G,s),t(G,ne),t(ne,da),_(Le,da,null),t(G,zo),t(G,ha),t(ha,wo),f(e,Pl,s),f(e,se,s),t(se,To),t(se,va),t(va,Po),t(se,yo),f(e,yl,s),_(Ue,e,s),f(e,Al,s),f(e,Y,s),t(Y,fe),t(fe,_a),_(Be,_a,null),t(Y,Ao),t(Y,ga),t(ga,Co),f(e,Cl,s),f(e,F,s),t(F,So),t(F,$a),t($a,Oo),t(F,ko),t(F,Ea),t(Ea,Io),t(F,qo),t(F,ba),t(ba,Fo),t(F,Ro),f(e,Sl,s),f(e,N,s),t(N,Qe),t(Qe,Mo),t(Qe,za),t(za,jo),t(Qe,Do),t(N,Ho),t(N,W),t(W,No),t(W,wa),t(wa,xo),t(W,Lo),t(W,Ta),t(Ta,Uo),t(W,Bo),t(N,Qo),t(N,X),t(X,Vo),t(X,Pa),t(Pa,Go),t(X,Yo),t(X,ya),t(ya,Wo),t(X,Xo),f(e,Ol,s),_(pe,e,s),f(e,kl,s),f(e,J,s),t(J,ce),t(ce,Aa),_(Ve,Aa,null),t(J,Jo),t(J,Ca),t(Ca,Ko),f(e,Il,s),f(e,me,s),t(me,Zo),t(me,Sa),t(Sa,er),t(me,tr),f(e,ql,s),_(ue,e,s),f(e,Fl,s),f(e,Ht,s),t(Ht,ar),f(e,Rl,s),_(Ge,e,s),f(e,Ml,s),f(e,Nt,s),t(Nt,lr),f(e,jl,s),_(Ye,e,s),f(e,Dl,s),f(e,xt,s),t(xt,ir),f(e,Hl,s),f(e,K,s),t(K,de),t(de,Oa),_(We,Oa,null),t(K,or),t(K,ka),t(ka,rr),f(e,Nl,s),f(e,Lt,s),t(Lt,nr),f(e,xl,s),f(e,x,s),t(x,Xe),t(Xe,Je),t(Je,sr),t(Je,Ke),t(Ke,fr),t(Je,pr),t(Xe,cr),t(Xe,Ia),t(Ia,Ut),t(x,mr),t(x,Ze),t(Ze,Z),t(Z,ur),t(Z,qa),t(qa,dr),t(Z,hr),t(Z,Fa),t(Fa,vr),t(Z,_r),t(Ze,gr),t(Ze,ee),t(ee,et),t(et,tt),t(tt,$r),t(tt,Ra),t(Ra,Er),t(tt,br),t(et,zr),_(at,et,null),t(ee,wr),t(ee,lt),t(lt,it),t(it,Tr),t(it,Ma),t(Ma,Pr),t(it,yr),t(lt,Ar),_(ot,lt,null),t(ee,Cr),t(ee,rt),t(rt,nt),t(nt,Sr),t(nt,ja),t(ja,Or),t(nt,kr),t(rt,Ir),_(st,rt,null),t(x,qr),t(x,ft),t(ft,pt),t(pt,Fr),t(pt,ct),t(ct,Rr),t(pt,Mr),t(ft,jr),t(ft,mt),t(mt,ut),t(ut,dt),t(dt,Dr),t(dt,Da),t(Da,Hr),t(dt,Nr),t(ut,xr),_(ht,ut,null),t(mt,Lr),t(mt,vt),t(vt,R),t(R,Ur),t(R,_t),t(_t,Ha),t(Ha,Br),t(R,Qr),t(R,Na),t(Na,Vr),t(R,Gr),t(R,gt),t(gt,Yr),t(R,Wr),t(vt,Xr),_($t,vt,null),f(e,Ll,s),f(e,Bt,s),t(Bt,Jr),f(e,Ul,s),_(Et,e,s),f(e,Bl,s),_(he,e,s),Ql=!0},p(e,[s]){const bt={};s&2&&(bt.$$scope={dirty:s,ctx:e}),oe.$set(bt);const xa={};s&2&&(xa.$$scope={dirty:s,ctx:e}),pe.$set(xa);const La={};s&2&&(La.$$scope={dirty:s,ctx:e}),ue.$set(La);const Ua={};s&2&&(Ua.$$scope={dirty:s,ctx:e}),he.$set(Ua)},i(e){Ql||(g(b.$$.fragment,e),g(we.$$.fragment,e),g(ye.$$.fragment,e),g(Ae.$$.fragment,e),g(Ce.$$.fragment,e),g(Se.$$.fragment,e),g(Oe.$$.fragment,e),g(ke.$$.fragment,e),g(Ie.$$.fragment,e),g(qe.$$.fragment,e),g(Fe.$$.fragment,e),g(Re.$$.fragment,e),g(je.$$.fragment,e),g(De.$$.fragment,e),g(Ne.$$.fragment,e),g(oe.$$.fragment,e),g(xe.$$.fragment,e),g(Le.$$.fragment,e),g(Ue.$$.fragment,e),g(Be.$$.fragment,e),g(pe.$$.fragment,e),g(Ve.$$.fragment,e),g(ue.$$.fragment,e),g(Ge.$$.fragment,e),g(Ye.$$.fragment,e),g(We.$$.fragment,e),g(at.$$.fragment,e),g(ot.$$.fragment,e),g(st.$$.fragment,e),g(ht.$$.fragment,e),g($t.$$.fragment,e),g(Et.$$.fragment,e),g(he.$$.fragment,e),Ql=!0)},o(e){$(b.$$.fragment,e),$(we.$$.fragment,e),$(ye.$$.fragment,e),$(Ae.$$.fragment,e),$(Ce.$$.fragment,e),$(Se.$$.fragment,e),$(Oe.$$.fragment,e),$(ke.$$.fragment,e),$(Ie.$$.fragment,e),$(qe.$$.fragment,e),$(Fe.$$.fragment,e),$(Re.$$.fragment,e),$(je.$$.fragment,e),$(De.$$.fragment,e),$(Ne.$$.fragment,e),$(oe.$$.fragment,e),$(xe.$$.fragment,e),$(Le.$$.fragment,e),$(Ue.$$.fragment,e),$(Be.$$.fragment,e),$(pe.$$.fragment,e),$(Ve.$$.fragment,e),$(ue.$$.fragment,e),$(Ge.$$.fragment,e),$(Ye.$$.fragment,e),$(We.$$.fragment,e),$(at.$$.fragment,e),$(ot.$$.fragment,e),$(st.$$.fragment,e),$(ht.$$.fragment,e),$($t.$$.fragment,e),$(Et.$$.fragment,e),$(he.$$.fragment,e),Ql=!1},d(e){a(u),e&&a(y),e&&a(d),E(b),e&&a(C),e&&a(I),e&&a(O),e&&a(U),e&&a($e),e&&a(j),e&&a(Ba),e&&a(B),E(we),e&&a(Qa),e&&a(D),e&&a(Va),e&&a(yt),e&&a(Ga),E(ye,e),e&&a(Ya),e&&a(At),e&&a(Wa),E(Ae,e),e&&a(Xa),e&&a(Ct),e&&a(Ja),E(Ce,e),e&&a(Ka),e&&a(St),e&&a(Za),E(Se,e),e&&a(el),e&&a(Ot),e&&a(tl),E(Oe,e),e&&a(al),e&&a(kt),e&&a(ll),E(ke,e),e&&a(il),e&&a(It),e&&a(ol),E(Ie,e),e&&a(rl),e&&a(qt),e&&a(nl),E(qe,e),e&&a(sl),e&&a(Q),E(Fe),e&&a(fl),e&&a(Ft),e&&a(pl),E(Re,e),e&&a(cl),e&&a(k),e&&a(ml),e&&a(Rt),e&&a(ul),E(je,e),e&&a(dl),e&&a(V),E(De),e&&a(hl),e&&a(Mt),e&&a(vl),e&&a(ie),e&&a(_l),e&&a(jt),e&&a(gl),E(Ne,e),e&&a($l),e&&a(H),e&&a(El),E(oe,e),e&&a(bl),e&&a(Dt),e&&a(zl),E(xe,e),e&&a(wl),e&&a(re),e&&a(Tl),e&&a(G),E(Le),e&&a(Pl),e&&a(se),e&&a(yl),E(Ue,e),e&&a(Al),e&&a(Y),E(Be),e&&a(Cl),e&&a(F),e&&a(Sl),e&&a(N),e&&a(Ol),E(pe,e),e&&a(kl),e&&a(J),E(Ve),e&&a(Il),e&&a(me),e&&a(ql),E(ue,e),e&&a(Fl),e&&a(Ht),e&&a(Rl),E(Ge,e),e&&a(Ml),e&&a(Nt),e&&a(jl),E(Ye,e),e&&a(Dl),e&&a(xt),e&&a(Hl),e&&a(K),E(We),e&&a(Nl),e&&a(Lt),e&&a(xl),e&&a(x),E(at),E(ot),E(st),E(ht),E($t),e&&a(Ll),e&&a(Bt),e&&a(Ul),E(Et,e),e&&a(Bl),E(he,e)}}}const Ds={local:"installazione",sections:[{local:"installazione-con-pip",title:"Installazione con pip"},{local:"installazione-dalla-fonte",title:"Installazione dalla fonte"},{local:"installazione-modificabile",title:"Installazione modificabile"},{local:"installazione-con-conda",title:"Installazione con conda"},{local:"impostazione-della-cache",title:"Impostazione della cache"},{local:"modalit-offline",sections:[{local:"ottenere-modelli-e-tokenizer-per-luso-offline",title:"Ottenere modelli e tokenizer per l'uso offline"}],title:"Modalit\xE0 Offline"}],title:"Installazione"};function Hs(M){return Is(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Us extends As{constructor(u){super();Cs(this,u,Hs,js,Ss,{})}}export{Us as default,Ds as metadata};
