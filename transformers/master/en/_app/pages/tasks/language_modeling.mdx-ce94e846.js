import{S as Sp,i as Op,s as Np,e as r,k as h,w,t as a,M as Rp,c as o,d as t,m,a as i,x as k,h as l,b as u,F as s,g as p,y as j,q as v,o as y,B as b,L as Pp}from"../../chunks/vendor-6b77c823.js";import{T as ks}from"../../chunks/Tip-39098574.js";import{Y as dn}from"../../chunks/Youtube-5c6e11e6.js";import{I as ue}from"../../chunks/IconCopyLink-7a11ce68.js";import{C as D}from"../../chunks/CodeBlock-3a8b25a8.js";import{F as Gp,M as Ip}from"../../chunks/Markdown-4489c441.js";function Bp(S){let f,x,c,_,A,g,E,F,$,q,M,z,L,P,G,B,H,C,N,d;return{c(){f=r("p"),x=a("You can fine-tune other architectures for language modeling such as "),c=r("a"),_=a("GPT-Neo"),A=a(", "),g=r("a"),E=a("GPT-J"),F=a(", and "),$=r("a"),q=a("BERT"),M=a(", following the same steps presented in this guide!"),z=h(),L=r("p"),P=a("See the text generation "),G=r("a"),B=a("task page"),H=a(" and fill mask "),C=r("a"),N=a("task page"),d=a(" for more information about their associated models, datasets, and metrics."),this.h()},l(T){f=o(T,"P",{});var O=i(f);x=l(O,"You can fine-tune other architectures for language modeling such as "),c=o(O,"A",{href:!0,rel:!0});var R=i(c);_=l(R,"GPT-Neo"),R.forEach(t),A=l(O,", "),g=o(O,"A",{href:!0,rel:!0});var I=i(g);E=l(I,"GPT-J"),I.forEach(t),F=l(O,", and "),$=o(O,"A",{href:!0,rel:!0});var J=i($);q=l(J,"BERT"),J.forEach(t),M=l(O,", following the same steps presented in this guide!"),O.forEach(t),z=m(T),L=o(T,"P",{});var W=i(L);P=l(W,"See the text generation "),G=o(W,"A",{href:!0,rel:!0});var Yt=i(G);B=l(Yt,"task page"),Yt.forEach(t),H=l(W," and fill mask "),C=o(W,"A",{href:!0,rel:!0});var Ut=i(C);N=l(Ut,"task page"),Ut.forEach(t),d=l(W," for more information about their associated models, datasets, and metrics."),W.forEach(t),this.h()},h(){u(c,"href","https://huggingface.co/EleutherAI/gpt-neo-125M"),u(c,"rel","nofollow"),u(g,"href","https://huggingface.co/EleutherAI/gpt-j-6B"),u(g,"rel","nofollow"),u($,"href","https://huggingface.co/bert-base-uncased"),u($,"rel","nofollow"),u(G,"href","https://huggingface.co/tasks/text-generation"),u(G,"rel","nofollow"),u(C,"href","https://huggingface.co/tasks/fill-mask"),u(C,"rel","nofollow")},m(T,O){p(T,f,O),s(f,x),s(f,c),s(c,_),s(f,A),s(f,g),s(g,E),s(f,F),s(f,$),s($,q),s(f,M),p(T,z,O),p(T,L,O),s(L,P),s(L,G),s(G,B),s(L,H),s(L,C),s(C,N),s(L,d)},d(T){T&&t(f),T&&t(z),T&&t(L)}}}function Hp(S){let f,x,c,_,A,g,E,F,$,q,M,z,L,P,G,B,H,C,N;return E=new D({props:{code:`from transformers import DataCollatorForLanguageModeling

tokenizer.pad_token = tokenizer.eos_token
data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForLanguageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.pad_token = tokenizer.eos_token
<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=<span class="hljs-literal">False</span>)`}}),C=new D({props:{code:`from transformers import DataCollatorForLanguageModeling

tokenizer.pad_token = tokenizer.eos_token
data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForLanguageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.pad_token = tokenizer.eos_token
<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=<span class="hljs-number">0.15</span>)`}}),{c(){f=r("p"),x=a("You can use the end of sequence token as the padding token, and set "),c=r("code"),_=a("mlm=False"),A=a(". This will use the inputs as labels shifted to the right by one element:"),g=h(),w(E.$$.fragment),F=h(),$=r("p"),q=a("For masked language modeling, use the same "),M=r("a"),z=a("DataCollatorForLanguageModeling"),L=a(" except you should specify "),P=r("code"),G=a("mlm_probability"),B=a(" to randomly mask tokens each time you iterate over the data."),H=h(),w(C.$$.fragment),this.h()},l(d){f=o(d,"P",{});var T=i(f);x=l(T,"You can use the end of sequence token as the padding token, and set "),c=o(T,"CODE",{});var O=i(c);_=l(O,"mlm=False"),O.forEach(t),A=l(T,". This will use the inputs as labels shifted to the right by one element:"),T.forEach(t),g=m(d),k(E.$$.fragment,d),F=m(d),$=o(d,"P",{});var R=i($);q=l(R,"For masked language modeling, use the same "),M=o(R,"A",{href:!0});var I=i(M);z=l(I,"DataCollatorForLanguageModeling"),I.forEach(t),L=l(R," except you should specify "),P=o(R,"CODE",{});var J=i(P);G=l(J,"mlm_probability"),J.forEach(t),B=l(R," to randomly mask tokens each time you iterate over the data."),R.forEach(t),H=m(d),k(C.$$.fragment,d),this.h()},h(){u(M,"href","/docs/transformers/master/en/main_classes/data_collator#transformers.DataCollatorForLanguageModeling")},m(d,T){p(d,f,T),s(f,x),s(f,c),s(c,_),s(f,A),p(d,g,T),j(E,d,T),p(d,F,T),p(d,$,T),s($,q),s($,M),s(M,z),s($,L),s($,P),s(P,G),s($,B),p(d,H,T),j(C,d,T),N=!0},p:Pp,i(d){N||(v(E.$$.fragment,d),v(C.$$.fragment,d),N=!0)},o(d){y(E.$$.fragment,d),y(C.$$.fragment,d),N=!1},d(d){d&&t(f),d&&t(g),b(E,d),d&&t(F),d&&t($),d&&t(H),b(C,d)}}}function Wp(S){let f,x;return f=new Ip({props:{$$slots:{default:[Hp]},$$scope:{ctx:S}}}),{c(){w(f.$$.fragment)},l(c){k(f.$$.fragment,c)},m(c,_){j(f,c,_),x=!0},p(c,_){const A={};_&2&&(A.$$scope={dirty:_,ctx:c}),f.$set(A)},i(c){x||(v(f.$$.fragment,c),x=!0)},o(c){y(f.$$.fragment,c),x=!1},d(c){b(f,c)}}}function Yp(S){let f,x,c,_,A,g,E,F,$,q,M,z,L,P,G,B,H,C,N;return E=new D({props:{code:`from transformers import DataCollatorForLanguageModeling

data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False, return_tensors="tf")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForLanguageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=<span class="hljs-literal">False</span>, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`}}),C=new D({props:{code:`from transformers import DataCollatorForLanguageModeling

data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False, return_tensors="tf")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForLanguageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=<span class="hljs-literal">False</span>, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`}}),{c(){f=r("p"),x=a("You can use the end of sequence token as the padding token, and set "),c=r("code"),_=a("mlm=False"),A=a(". This will use the inputs as labels shifted to the right by one element:"),g=h(),w(E.$$.fragment),F=h(),$=r("p"),q=a("For masked language modeling, use the same "),M=r("a"),z=a("DataCollatorForLanguageModeling"),L=a(" except you should specify "),P=r("code"),G=a("mlm_probability"),B=a(" to randomly mask tokens each time you iterate over the data."),H=h(),w(C.$$.fragment),this.h()},l(d){f=o(d,"P",{});var T=i(f);x=l(T,"You can use the end of sequence token as the padding token, and set "),c=o(T,"CODE",{});var O=i(c);_=l(O,"mlm=False"),O.forEach(t),A=l(T,". This will use the inputs as labels shifted to the right by one element:"),T.forEach(t),g=m(d),k(E.$$.fragment,d),F=m(d),$=o(d,"P",{});var R=i($);q=l(R,"For masked language modeling, use the same "),M=o(R,"A",{href:!0});var I=i(M);z=l(I,"DataCollatorForLanguageModeling"),I.forEach(t),L=l(R," except you should specify "),P=o(R,"CODE",{});var J=i(P);G=l(J,"mlm_probability"),J.forEach(t),B=l(R," to randomly mask tokens each time you iterate over the data."),R.forEach(t),H=m(d),k(C.$$.fragment,d),this.h()},h(){u(M,"href","/docs/transformers/master/en/main_classes/data_collator#transformers.DataCollatorForLanguageModeling")},m(d,T){p(d,f,T),s(f,x),s(f,c),s(c,_),s(f,A),p(d,g,T),j(E,d,T),p(d,F,T),p(d,$,T),s($,q),s($,M),s(M,z),s($,L),s($,P),s(P,G),s($,B),p(d,H,T),j(C,d,T),N=!0},p:Pp,i(d){N||(v(E.$$.fragment,d),v(C.$$.fragment,d),N=!0)},o(d){y(E.$$.fragment,d),y(C.$$.fragment,d),N=!1},d(d){d&&t(f),d&&t(g),b(E,d),d&&t(F),d&&t($),d&&t(H),b(C,d)}}}function Up(S){let f,x;return f=new Ip({props:{$$slots:{default:[Yp]},$$scope:{ctx:S}}}),{c(){w(f.$$.fragment)},l(c){k(f.$$.fragment,c)},m(c,_){j(f,c,_),x=!0},p(c,_){const A={};_&2&&(A.$$scope={dirty:_,ctx:c}),f.$set(A)},i(c){x||(v(f.$$.fragment,c),x=!0)},o(c){y(f.$$.fragment,c),x=!1},d(c){b(f,c)}}}function Jp(S){let f,x,c,_,A,g,E,F;return{c(){f=r("p"),x=a("If you aren\u2019t familiar with fine-tuning a model with the "),c=r("a"),_=a("Trainer"),A=a(", take a look at the basic tutorial "),g=r("a"),E=a("here"),F=a("!"),this.h()},l($){f=o($,"P",{});var q=i(f);x=l(q,"If you aren\u2019t familiar with fine-tuning a model with the "),c=o(q,"A",{href:!0});var M=i(c);_=l(M,"Trainer"),M.forEach(t),A=l(q,", take a look at the basic tutorial "),g=o(q,"A",{href:!0});var z=i(g);E=l(z,"here"),z.forEach(t),F=l(q,"!"),q.forEach(t),this.h()},h(){u(c,"href","/docs/transformers/master/en/main_classes/trainer#transformers.Trainer"),u(g,"href","training#finetune-with-trainer")},m($,q){p($,f,q),s(f,x),s(f,c),s(c,_),s(f,A),s(f,g),s(g,E),s(f,F)},d($){$&&t(f)}}}function Kp(S){let f,x,c,_,A;return{c(){f=r("p"),x=a("If you aren\u2019t familiar with fine-tuning a model with Keras, take a look at the basic tutorial "),c=r("a"),_=a("here"),A=a("!"),this.h()},l(g){f=o(g,"P",{});var E=i(f);x=l(E,"If you aren\u2019t familiar with fine-tuning a model with Keras, take a look at the basic tutorial "),c=o(E,"A",{href:!0});var F=i(c);_=l(F,"here"),F.forEach(t),A=l(E,"!"),E.forEach(t),this.h()},h(){u(c,"href","training#finetune-with-keras")},m(g,E){p(g,f,E),s(f,x),s(f,c),s(c,_),s(f,A)},d(g){g&&t(f)}}}function Qp(S){let f,x,c,_,A,g,E,F;return{c(){f=r("p"),x=a("If you aren\u2019t familiar with fine-tuning a model with the "),c=r("a"),_=a("Trainer"),A=a(", take a look at the basic tutorial "),g=r("a"),E=a("here"),F=a("!"),this.h()},l($){f=o($,"P",{});var q=i(f);x=l(q,"If you aren\u2019t familiar with fine-tuning a model with the "),c=o(q,"A",{href:!0});var M=i(c);_=l(M,"Trainer"),M.forEach(t),A=l(q,", take a look at the basic tutorial "),g=o(q,"A",{href:!0});var z=i(g);E=l(z,"here"),z.forEach(t),F=l(q,"!"),q.forEach(t),this.h()},h(){u(c,"href","/docs/transformers/master/en/main_classes/trainer#transformers.Trainer"),u(g,"href","training#finetune-with-trainer")},m($,q){p($,f,q),s(f,x),s(f,c),s(c,_),s(f,A),s(f,g),s(g,E),s(f,F)},d($){$&&t(f)}}}function Vp(S){let f,x,c,_,A;return{c(){f=r("p"),x=a("If you aren\u2019t familiar with fine-tuning a model with Keras, take a look at the basic tutorial "),c=r("a"),_=a("here"),A=a("!"),this.h()},l(g){f=o(g,"P",{});var E=i(f);x=l(E,"If you aren\u2019t familiar with fine-tuning a model with Keras, take a look at the basic tutorial "),c=o(E,"A",{href:!0});var F=i(c);_=l(F,"here"),F.forEach(t),A=l(E,"!"),E.forEach(t),this.h()},h(){u(c,"href","training#finetune-with-keras")},m(g,E){p(g,f,E),s(f,x),s(f,c),s(c,_),s(f,A)},d(g){g&&t(f)}}}function Xp(S){let f,x,c,_,A,g,E,F;return{c(){f=r("p"),x=a(`For a more in-depth example of how to fine-tune a model for causal language modeling, take a look at the corresponding
`),c=r("a"),_=a("PyTorch notebook"),A=a(`
or `),g=r("a"),E=a("TensorFlow notebook"),F=a("."),this.h()},l($){f=o($,"P",{});var q=i(f);x=l(q,`For a more in-depth example of how to fine-tune a model for causal language modeling, take a look at the corresponding
`),c=o(q,"A",{href:!0,rel:!0});var M=i(c);_=l(M,"PyTorch notebook"),M.forEach(t),A=l(q,`
or `),g=o(q,"A",{href:!0,rel:!0});var z=i(g);E=l(z,"TensorFlow notebook"),z.forEach(t),F=l(q,"."),q.forEach(t),this.h()},h(){u(c,"href","https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/language_modeling.ipynb"),u(c,"rel","nofollow"),u(g,"href","https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/language_modeling-tf.ipynb"),u(g,"rel","nofollow")},m($,q){p($,f,q),s(f,x),s(f,c),s(c,_),s(f,A),s(f,g),s(g,E),s(f,F)},d($){$&&t(f)}}}function Zp(S){let f,x,c,_,A,g,E,F,$,q,M,z,L,P,G,B,H,C,N,d,T,O,R,I,J,W,Yt,Ut,We,gn,_n,Ye,$n,wn,Ue,kn,jn,$a,ce,wa,ne,de,js,Je,vn,vs,yn,ka,Jt,bn,ja,Ke,va,Kt,En,ya,Qe,ba,Qt,xn,Ea,Ve,xa,K,Tn,ys,An,qn,bs,Fn,Mn,Es,Cn,Dn,Ta,re,ge,xs,Xe,zn,Ts,Ln,Aa,Ze,qa,_e,Pn,As,In,Sn,Fa,et,Ma,tt,Ca,Vt,On,Da,st,za,X,Nn,qs,Rn,Gn,at,Fs,Bn,Hn,La,lt,Pa,Z,Wn,Ms,Yn,Un,Cs,Jn,Kn,Ia,Xt,Qn,Sa,nt,Oa,Y,Vn,rt,Ds,Xn,Zn,zs,er,tr,Ls,sr,ar,Ps,lr,nr,Na,ot,Ra,Zt,rr,Ga,$e,Is,or,ir,it,pr,Ss,fr,hr,Ba,pt,Ha,we,mr,Os,ur,cr,Wa,ft,Ya,U,dr,es,gr,_r,Ns,$r,wr,Rs,kr,jr,Gs,vr,yr,Ua,ke,Ja,oe,je,Bs,ht,br,Hs,Er,Ka,ve,xr,mt,Tr,Ar,Qa,ie,ye,Ws,ut,qr,Ys,Fr,Va,be,Mr,ts,Cr,Dr,Xa,ct,Za,Ee,el,ss,zr,tl,ee,dt,Lr,as,Pr,Ir,Sr,gt,Or,ls,Nr,Rr,Gr,_t,Br,ns,Hr,Wr,sl,$t,al,pe,xe,Us,wt,Yr,Js,Ur,ll,rs,Jr,nl,Te,rl,Q,Kr,Ks,Qr,Vr,kt,Qs,Xr,Zr,Vs,eo,to,ol,jt,il,os,so,pl,vt,fl,Ae,ao,is,lo,no,hl,yt,ml,qe,ro,bt,Xs,oo,io,ul,Et,cl,Fe,po,xt,Zs,fo,ho,dl,Tt,gl,fe,Me,ea,At,mo,ta,uo,_l,Ce,co,qt,go,_o,$l,he,De,sa,Ft,$o,aa,wo,wl,ze,ko,la,jo,vo,kl,Mt,jl,Le,vl,ps,yo,yl,te,Ct,bo,fs,Eo,xo,To,Dt,Ao,hs,qo,Fo,Mo,zt,Co,ms,Do,zo,bl,Lt,El,me,Pe,na,Pt,Lo,ra,Po,xl,us,Io,Tl,Ie,Al,V,So,oa,Oo,No,It,ia,Ro,Go,pa,Bo,Ho,ql,St,Fl,cs,Wo,Ml,Ot,Cl,Se,Yo,ds,Uo,Jo,Dl,Nt,zl,Oe,Ko,Rt,fa,Qo,Vo,Ll,Gt,Pl,Ne,Xo,Bt,ha,Zo,ei,Il,Ht,Sl,Re,Ol;return g=new ue({}),P=new dn({props:{id:"Vpjb1lu0MDk"}}),N=new dn({props:{id:"mqElG5QJWUg"}}),ce=new ks({props:{$$slots:{default:[Bp]},$$scope:{ctx:S}}}),Je=new ue({}),Ke=new D({props:{code:`from datasets import load_dataset

eli5 = load_dataset("eli5", split="train_asks[:5000]")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>eli5 = load_dataset(<span class="hljs-string">&quot;eli5&quot;</span>, split=<span class="hljs-string">&quot;train_asks[:5000]&quot;</span>)`}}),Qe=new D({props:{code:"eli5 = eli5.train_test_split(test_size=0.2)",highlighted:'eli5 = eli5.train_test_split(test_size=<span class="hljs-number">0.2</span>)'}}),Ve=new D({props:{code:'eli5["train"][0]',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>eli5[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;answers&#x27;</span>: {<span class="hljs-string">&#x27;a_id&#x27;</span>: [<span class="hljs-string">&#x27;c3d1aib&#x27;</span>, <span class="hljs-string">&#x27;c3d4lya&#x27;</span>],
  <span class="hljs-string">&#x27;score&#x27;</span>: [<span class="hljs-number">6</span>, <span class="hljs-number">3</span>],
  <span class="hljs-string">&#x27;text&#x27;</span>: [<span class="hljs-string">&quot;The velocity needed to remain in orbit is equal to the square root of Newton&#x27;s constant times the mass of earth divided by the distance from the center of the earth. I don&#x27;t know the altitude of that specific mission, but they&#x27;re usually around 300 km. That means he&#x27;s going 7-8 km/s.\\n\\nIn space there are no other forces acting on either the shuttle or the guy, so they stay in the same position relative to each other. If he were to become unable to return to the ship, he would presumably run out of oxygen, or slowly fall into the atmosphere and burn up.&quot;</span>,
   <span class="hljs-string">&quot;Hope you don&#x27;t mind me asking another question, but why aren&#x27;t there any stars visible in this photo?&quot;</span>]},
 <span class="hljs-string">&#x27;answers_urls&#x27;</span>: {<span class="hljs-string">&#x27;url&#x27;</span>: []},
 <span class="hljs-string">&#x27;document&#x27;</span>: <span class="hljs-string">&#x27;&#x27;</span>,
 <span class="hljs-string">&#x27;q_id&#x27;</span>: <span class="hljs-string">&#x27;nyxfp&#x27;</span>,
 <span class="hljs-string">&#x27;selftext&#x27;</span>: <span class="hljs-string">&#x27;_URL_0_\\n\\nThis was on the front page earlier and I have a few questions about it. Is it possible to calculate how fast the astronaut would be orbiting the earth? Also how does he stay close to the shuttle so that he can return safely, i.e is he orbiting at the same speed and can therefore stay next to it? And finally if his propulsion system failed, would he eventually re-enter the atmosphere and presumably die?&#x27;</span>,
 <span class="hljs-string">&#x27;selftext_urls&#x27;</span>: {<span class="hljs-string">&#x27;url&#x27;</span>: [<span class="hljs-string">&#x27;http://apod.nasa.gov/apod/image/1201/freeflyer_nasa_3000.jpg&#x27;</span>]},
 <span class="hljs-string">&#x27;subreddit&#x27;</span>: <span class="hljs-string">&#x27;askscience&#x27;</span>,
 <span class="hljs-string">&#x27;title&#x27;</span>: <span class="hljs-string">&#x27;Few questions about this space walk photograph.&#x27;</span>,
 <span class="hljs-string">&#x27;title_urls&#x27;</span>: {<span class="hljs-string">&#x27;url&#x27;</span>: []}}`}}),Xe=new ue({}),Ze=new dn({props:{id:"ma1TrR7gE7I"}}),et=new D({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("distilgpt2")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilgpt2&quot;</span>)`}}),tt=new dn({props:{id:"8PmhEIXhBvI"}}),st=new D({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("distilroberta-base")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilroberta-base&quot;</span>)`}}),lt=new D({props:{code:`eli5 = eli5.flatten()
eli5["train"][0]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>eli5 = eli5.flatten()
<span class="hljs-meta">&gt;&gt;&gt; </span>eli5[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;answers.a_id&#x27;</span>: [<span class="hljs-string">&#x27;c3d1aib&#x27;</span>, <span class="hljs-string">&#x27;c3d4lya&#x27;</span>],
 <span class="hljs-string">&#x27;answers.score&#x27;</span>: [<span class="hljs-number">6</span>, <span class="hljs-number">3</span>],
 <span class="hljs-string">&#x27;answers.text&#x27;</span>: [<span class="hljs-string">&quot;The velocity needed to remain in orbit is equal to the square root of Newton&#x27;s constant times the mass of earth divided by the distance from the center of the earth. I don&#x27;t know the altitude of that specific mission, but they&#x27;re usually around 300 km. That means he&#x27;s going 7-8 km/s.\\n\\nIn space there are no other forces acting on either the shuttle or the guy, so they stay in the same position relative to each other. If he were to become unable to return to the ship, he would presumably run out of oxygen, or slowly fall into the atmosphere and burn up.&quot;</span>,
  <span class="hljs-string">&quot;Hope you don&#x27;t mind me asking another question, but why aren&#x27;t there any stars visible in this photo?&quot;</span>],
 <span class="hljs-string">&#x27;answers_urls.url&#x27;</span>: [],
 <span class="hljs-string">&#x27;document&#x27;</span>: <span class="hljs-string">&#x27;&#x27;</span>,
 <span class="hljs-string">&#x27;q_id&#x27;</span>: <span class="hljs-string">&#x27;nyxfp&#x27;</span>,
 <span class="hljs-string">&#x27;selftext&#x27;</span>: <span class="hljs-string">&#x27;_URL_0_\\n\\nThis was on the front page earlier and I have a few questions about it. Is it possible to calculate how fast the astronaut would be orbiting the earth? Also how does he stay close to the shuttle so that he can return safely, i.e is he orbiting at the same speed and can therefore stay next to it? And finally if his propulsion system failed, would he eventually re-enter the atmosphere and presumably die?&#x27;</span>,
 <span class="hljs-string">&#x27;selftext_urls.url&#x27;</span>: [<span class="hljs-string">&#x27;http://apod.nasa.gov/apod/image/1201/freeflyer_nasa_3000.jpg&#x27;</span>],
 <span class="hljs-string">&#x27;subreddit&#x27;</span>: <span class="hljs-string">&#x27;askscience&#x27;</span>,
 <span class="hljs-string">&#x27;title&#x27;</span>: <span class="hljs-string">&#x27;Few questions about this space walk photograph.&#x27;</span>,
 <span class="hljs-string">&#x27;title_urls.url&#x27;</span>: []}`}}),nt=new D({props:{code:`def preprocess_function(examples):
    return tokenizer([" ".join(x) for x in examples["answers.text"]], truncation=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> tokenizer([<span class="hljs-string">&quot; &quot;</span>.join(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;answers.text&quot;</span>]], truncation=<span class="hljs-literal">True</span>)`}}),ot=new D({props:{code:`tokenized_eli5 = eli5.map(
    preprocess_function,
    batched=True,
    num_proc=4,
    remove_columns=eli5["train"].column_names,
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_eli5 = eli5.<span class="hljs-built_in">map</span>(
<span class="hljs-meta">... </span>    preprocess_function,
<span class="hljs-meta">... </span>    batched=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    num_proc=<span class="hljs-number">4</span>,
<span class="hljs-meta">... </span>    remove_columns=eli5[<span class="hljs-string">&quot;train&quot;</span>].column_names,
<span class="hljs-meta">... </span>)`}}),pt=new D({props:{code:`block_size = 128


def group_texts(examples):
    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}
    total_length = len(concatenated_examples[list(examples.keys())[0]])
    result = {
        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]
        for k, t in concatenated_examples.items()
    }
    result["labels"] = result["input_ids"].copy()
    return result`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>block_size = <span class="hljs-number">128</span>


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">group_texts</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    concatenated_examples = {k: <span class="hljs-built_in">sum</span>(examples[k], []) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> examples.keys()}
<span class="hljs-meta">... </span>    total_length = <span class="hljs-built_in">len</span>(concatenated_examples[<span class="hljs-built_in">list</span>(examples.keys())[<span class="hljs-number">0</span>]])
<span class="hljs-meta">... </span>    result = {
<span class="hljs-meta">... </span>        k: [t[i : i + block_size] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, total_length, block_size)]
<span class="hljs-meta">... </span>        <span class="hljs-keyword">for</span> k, t <span class="hljs-keyword">in</span> concatenated_examples.items()
<span class="hljs-meta">... </span>    }
<span class="hljs-meta">... </span>    result[<span class="hljs-string">&quot;labels&quot;</span>] = result[<span class="hljs-string">&quot;input_ids&quot;</span>].copy()
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> result`}}),ft=new D({props:{code:"lm_dataset = tokenized_eli5.map(group_texts, batched=True, num_proc=4)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>lm_dataset = tokenized_eli5.<span class="hljs-built_in">map</span>(group_texts, batched=<span class="hljs-literal">True</span>, num_proc=<span class="hljs-number">4</span>)'}}),ke=new Gp({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Up],pytorch:[Wp]},$$scope:{ctx:S}}}),ht=new ue({}),ut=new ue({}),ct=new D({props:{code:`from transformers import AutoModelForCausalLM, TrainingArguments, Trainer

model = AutoModelForCausalLM.from_pretrained("distilgpt2")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, TrainingArguments, Trainer

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;distilgpt2&quot;</span>)`}}),Ee=new ks({props:{$$slots:{default:[Jp]},$$scope:{ctx:S}}}),$t=new D({props:{code:`training_args = TrainingArguments(
    output_dir="./results",
    evaluation_strategy="epoch",
    learning_rate=2e-5,
    weight_decay=0.01,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=lm_dataset["train"],
    eval_dataset=lm_dataset["test"],
    data_collator=data_collator,
)

trainer.train()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;./results&quot;</span>,
<span class="hljs-meta">... </span>    evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
<span class="hljs-meta">... </span>    learning_rate=<span class="hljs-number">2e-5</span>,
<span class="hljs-meta">... </span>    weight_decay=<span class="hljs-number">0.01</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=lm_dataset[<span class="hljs-string">&quot;train&quot;</span>],
<span class="hljs-meta">... </span>    eval_dataset=lm_dataset[<span class="hljs-string">&quot;test&quot;</span>],
<span class="hljs-meta">... </span>    data_collator=data_collator,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()`}}),wt=new ue({}),Te=new ks({props:{$$slots:{default:[Kp]},$$scope:{ctx:S}}}),jt=new D({props:{code:`tf_train_set = lm_dataset["train"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "labels"],
    dummy_labels=True,
    shuffle=True,
    batch_size=16,
    collate_fn=data_collator,
)

tf_test_set = lm_dataset["test"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "labels"],
    dummy_labels=True,
    shuffle=False,
    batch_size=16,
    collate_fn=data_collator,
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_train_set = lm_dataset[<span class="hljs-string">&quot;train&quot;</span>].to_tf_dataset(
<span class="hljs-meta">... </span>    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>],
<span class="hljs-meta">... </span>    dummy_labels=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_test_set = lm_dataset[<span class="hljs-string">&quot;test&quot;</span>].to_tf_dataset(
<span class="hljs-meta">... </span>    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>],
<span class="hljs-meta">... </span>    dummy_labels=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">False</span>,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>)`}}),vt=new D({props:{code:`from transformers import create_optimizer, AdamWeightDecay

optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> create_optimizer, AdamWeightDecay

<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer = AdamWeightDecay(learning_rate=<span class="hljs-number">2e-5</span>, weight_decay_rate=<span class="hljs-number">0.01</span>)`}}),yt=new D({props:{code:`from transformers import TFAutoModelForCausalLM

model = TFAutoModelForCausalLM.from_pretrained("distilgpt2")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;distilgpt2&quot;</span>)`}}),Et=new D({props:{code:`import tensorflow as tf

model.compile(optimizer=optimizer)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">compile</span>(optimizer=optimizer)`}}),Tt=new D({props:{code:"model.fit(x=tf_train_set, validation_data=tf_test_set, epochs=3)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model.fit(x=tf_train_set, validation_data=tf_test_set, epochs=<span class="hljs-number">3</span>)'}}),At=new ue({}),Ft=new ue({}),Mt=new D({props:{code:`from transformers import AutoModelForMaskedLM

model = AutoModelForMaskedLM.from_pretrained("distilroberta-base")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;distilroberta-base&quot;</span>)`}}),Le=new ks({props:{$$slots:{default:[Qp]},$$scope:{ctx:S}}}),Lt=new D({props:{code:`training_args = TrainingArguments(
    output_dir="./results",
    evaluation_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=lm_dataset["train"],
    eval_dataset=lm_dataset["test"],
    data_collator=data_collator,
)

trainer.train()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;./results&quot;</span>,
<span class="hljs-meta">... </span>    evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
<span class="hljs-meta">... </span>    learning_rate=<span class="hljs-number">2e-5</span>,
<span class="hljs-meta">... </span>    num_train_epochs=<span class="hljs-number">3</span>,
<span class="hljs-meta">... </span>    weight_decay=<span class="hljs-number">0.01</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=lm_dataset[<span class="hljs-string">&quot;train&quot;</span>],
<span class="hljs-meta">... </span>    eval_dataset=lm_dataset[<span class="hljs-string">&quot;test&quot;</span>],
<span class="hljs-meta">... </span>    data_collator=data_collator,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()`}}),Pt=new ue({}),Ie=new ks({props:{$$slots:{default:[Vp]},$$scope:{ctx:S}}}),St=new D({props:{code:`tf_train_set = lm_dataset["train"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "labels"],
    dummy_labels=True,
    shuffle=True,
    batch_size=16,
    collate_fn=data_collator,
)

tf_test_set = lm_dataset["test"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "labels"],
    dummy_labels=True,
    shuffle=False,
    batch_size=16,
    collate_fn=data_collator,
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_train_set = lm_dataset[<span class="hljs-string">&quot;train&quot;</span>].to_tf_dataset(
<span class="hljs-meta">... </span>    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>],
<span class="hljs-meta">... </span>    dummy_labels=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_test_set = lm_dataset[<span class="hljs-string">&quot;test&quot;</span>].to_tf_dataset(
<span class="hljs-meta">... </span>    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>],
<span class="hljs-meta">... </span>    dummy_labels=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">False</span>,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>)`}}),Ot=new D({props:{code:`from transformers import create_optimizer, AdamWeightDecay

optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> create_optimizer, AdamWeightDecay

<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer = AdamWeightDecay(learning_rate=<span class="hljs-number">2e-5</span>, weight_decay_rate=<span class="hljs-number">0.01</span>)`}}),Nt=new D({props:{code:`from transformers import TFAutoModelForMaskedLM

model = TFAutoModelForCausalLM.from_pretrained("distilroberta-base")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;distilroberta-base&quot;</span>)`}}),Gt=new D({props:{code:`import tensorflow as tf

model.compile(optimizer=optimizer)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">compile</span>(optimizer=optimizer)`}}),Ht=new D({props:{code:"model.fit(x=tf_train_set, validation_data=tf_test_set, epochs=3)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model.fit(x=tf_train_set, validation_data=tf_test_set, epochs=<span class="hljs-number">3</span>)'}}),Re=new ks({props:{$$slots:{default:[Xp]},$$scope:{ctx:S}}}),{c(){f=r("meta"),x=h(),c=r("h1"),_=r("a"),A=r("span"),w(g.$$.fragment),E=h(),F=r("span"),$=a("Language modeling"),q=h(),M=r("p"),z=a("Language modeling predicts words in a sentence. There are two forms of language modeling."),L=h(),w(P.$$.fragment),G=h(),B=r("p"),H=a("Causal language modeling predicts the next token in a sequence of tokens, and the model can only attend to tokens on the left."),C=h(),w(N.$$.fragment),d=h(),T=r("p"),O=a("Masked language modeling predicts a masked token in a sequence, and the model can attend to tokens bidirectionally."),R=h(),I=r("p"),J=a("This guide will show you how to fine-tune "),W=r("a"),Yt=a("DistilGPT2"),Ut=a(" for causal language modeling and "),We=r("a"),gn=a("DistilRoBERTa"),_n=a(" for masked language modeling on the "),Ye=r("a"),$n=a("r/askscience"),wn=a(" subset of the "),Ue=r("a"),kn=a("ELI5"),jn=a(" dataset."),$a=h(),w(ce.$$.fragment),wa=h(),ne=r("h2"),de=r("a"),js=r("span"),w(Je.$$.fragment),vn=h(),vs=r("span"),yn=a("Load ELI5 dataset"),ka=h(),Jt=r("p"),bn=a("Load only the first 5000 rows of the ELI5 dataset from the \u{1F917} Datasets library since it is pretty large:"),ja=h(),w(Ke.$$.fragment),va=h(),Kt=r("p"),En=a("Split this dataset into a train and test set:"),ya=h(),w(Qe.$$.fragment),ba=h(),Qt=r("p"),xn=a("Then take a look at an example:"),Ea=h(),w(Ve.$$.fragment),xa=h(),K=r("p"),Tn=a("Notice "),ys=r("code"),An=a("text"),qn=a(" is a subfield nested inside the "),bs=r("code"),Fn=a("answers"),Mn=a(" dictionary. When you preprocess the dataset, you will need to extract the "),Es=r("code"),Cn=a("text"),Dn=a(" subfield into a separate column."),Ta=h(),re=r("h2"),ge=r("a"),xs=r("span"),w(Xe.$$.fragment),zn=h(),Ts=r("span"),Ln=a("Preprocess"),Aa=h(),w(Ze.$$.fragment),qa=h(),_e=r("p"),Pn=a("For causal language modeling, load the DistilGPT2 tokenizer to process the "),As=r("code"),In=a("text"),Sn=a(" subfield:"),Fa=h(),w(et.$$.fragment),Ma=h(),w(tt.$$.fragment),Ca=h(),Vt=r("p"),On=a("For masked language modeling, load the DistilRoBERTa tokenizer instead:"),Da=h(),w(st.$$.fragment),za=h(),X=r("p"),Nn=a("Extract the "),qs=r("code"),Rn=a("text"),Gn=a(" subfield from its nested structure with the "),at=r("a"),Fs=r("code"),Bn=a("flatten"),Hn=a(" method:"),La=h(),w(lt.$$.fragment),Pa=h(),Z=r("p"),Wn=a("Each subfield is now a separate column as indicated by the "),Ms=r("code"),Yn=a("answers"),Un=a(" prefix. Notice that "),Cs=r("code"),Jn=a("answers.text"),Kn=a(" is a list. Instead of tokenizing each sentence separately, convert the list to a string to jointly tokenize them."),Ia=h(),Xt=r("p"),Qn=a("Here is how you can create a preprocessing function to convert the list to a string and truncate sequences to be no longer than DistilGPT2\u2019s maximum input length:"),Sa=h(),w(nt.$$.fragment),Oa=h(),Y=r("p"),Vn=a("Use \u{1F917} Datasets "),rt=r("a"),Ds=r("code"),Xn=a("map"),Zn=a(" function to apply the preprocessing function over the entire dataset. You can speed up the "),zs=r("code"),er=a("map"),tr=a(" function by setting "),Ls=r("code"),sr=a("batched=True"),ar=a(" to process multiple elements of the dataset at once and increasing the number of processes with "),Ps=r("code"),lr=a("num_proc"),nr=a(". Remove the columns you don\u2019t need:"),Na=h(),w(ot.$$.fragment),Ra=h(),Zt=r("p"),rr=a("Now you need a second preprocessing function to capture text truncated from any lengthy examples to prevent loss of information. This preprocessing function should:"),Ga=h(),$e=r("ul"),Is=r("li"),or=a("Concatenate all the text."),ir=h(),it=r("li"),pr=a("Split the concatenated text into smaller chunks defined by "),Ss=r("code"),fr=a("block_size"),hr=a("."),Ba=h(),w(pt.$$.fragment),Ha=h(),we=r("p"),mr=a("Apply the "),Os=r("code"),ur=a("group_texts"),cr=a(" function over the entire dataset:"),Wa=h(),w(ft.$$.fragment),Ya=h(),U=r("p"),dr=a("For causal language modeling, use "),es=r("a"),gr=a("DataCollatorForLanguageModeling"),_r=a(" to create a batch of examples. It will also "),Ns=r("em"),$r=a("dynamically pad"),wr=a(" your text to the length of the longest element in its batch, so they are a uniform length. While it is possible to pad your text in the "),Rs=r("code"),kr=a("tokenizer"),jr=a(" function by setting "),Gs=r("code"),vr=a("padding=True"),yr=a(", dynamic padding is more efficient."),Ua=h(),w(ke.$$.fragment),Ja=h(),oe=r("h2"),je=r("a"),Bs=r("span"),w(ht.$$.fragment),br=h(),Hs=r("span"),Er=a("Causal language modeling"),Ka=h(),ve=r("p"),xr=a("Causal language modeling is frequently used for text generation. This section shows you how to fine-tune "),mt=r("a"),Tr=a("DistilGPT2"),Ar=a(" to generate new text."),Qa=h(),ie=r("h3"),ye=r("a"),Ws=r("span"),w(ut.$$.fragment),qr=h(),Ys=r("span"),Fr=a("Fine-tune with Trainer"),Va=h(),be=r("p"),Mr=a("Load DistilGPT2 with "),ts=r("a"),Cr=a("AutoModelForCausalLM"),Dr=a(":"),Xa=h(),w(ct.$$.fragment),Za=h(),w(Ee.$$.fragment),el=h(),ss=r("p"),zr=a("At this point, only three steps remain:"),tl=h(),ee=r("ol"),dt=r("li"),Lr=a("Define your training hyperparameters in "),as=r("a"),Pr=a("TrainingArguments"),Ir=a("."),Sr=h(),gt=r("li"),Or=a("Pass the training arguments to "),ls=r("a"),Nr=a("Trainer"),Rr=a(" along with the model, datasets, and data collator."),Gr=h(),_t=r("li"),Br=a("Call "),ns=r("a"),Hr=a("train()"),Wr=a(" to fine-tune your model."),sl=h(),w($t.$$.fragment),al=h(),pe=r("h3"),xe=r("a"),Us=r("span"),w(wt.$$.fragment),Yr=h(),Js=r("span"),Ur=a("Fine-tune with TensorFlow"),ll=h(),rs=r("p"),Jr=a("To fine-tune a model in TensorFlow is just as easy, with only a few differences."),nl=h(),w(Te.$$.fragment),rl=h(),Q=r("p"),Kr=a("Convert your datasets to the "),Ks=r("code"),Qr=a("tf.data.Dataset"),Vr=a(" format with "),kt=r("a"),Qs=r("code"),Xr=a("to_tf_dataset"),Zr=a(". Specify inputs and labels in "),Vs=r("code"),eo=a("columns"),to=a(", whether to shuffle the dataset order, batch size, and the data collator:"),ol=h(),w(jt.$$.fragment),il=h(),os=r("p"),so=a("Set up an optimizer function, learning rate, and some training hyperparameters:"),pl=h(),w(vt.$$.fragment),fl=h(),Ae=r("p"),ao=a("Load DistilGPT2 with "),is=r("a"),lo=a("TFAutoModelForCausalLM"),no=a(":"),hl=h(),w(yt.$$.fragment),ml=h(),qe=r("p"),ro=a("Configure the model for training with "),bt=r("a"),Xs=r("code"),oo=a("compile"),io=a(":"),ul=h(),w(Et.$$.fragment),cl=h(),Fe=r("p"),po=a("Call "),xt=r("a"),Zs=r("code"),fo=a("fit"),ho=a(" to fine-tune the model:"),dl=h(),w(Tt.$$.fragment),gl=h(),fe=r("h2"),Me=r("a"),ea=r("span"),w(At.$$.fragment),mo=h(),ta=r("span"),uo=a("Masked language modeling"),_l=h(),Ce=r("p"),co=a("Masked language modeling is also known as a fill-mask task because it predicts a masked token in a sequence. Models for masked language modeling require a good contextual understanding of an entire sequence instead of only the left context. This section shows you how to fine-tune "),qt=r("a"),go=a("DistilRoBERTa"),_o=a(" to predict a masked word."),$l=h(),he=r("h3"),De=r("a"),sa=r("span"),w(Ft.$$.fragment),$o=h(),aa=r("span"),wo=a("Fine-tune with Trainer"),wl=h(),ze=r("p"),ko=a("Load DistilRoBERTa with "),la=r("code"),jo=a("AutoModelForMaskedlM"),vo=a(":"),kl=h(),w(Mt.$$.fragment),jl=h(),w(Le.$$.fragment),vl=h(),ps=r("p"),yo=a("At this point, only three steps remain:"),yl=h(),te=r("ol"),Ct=r("li"),bo=a("Define your training hyperparameters in "),fs=r("a"),Eo=a("TrainingArguments"),xo=a("."),To=h(),Dt=r("li"),Ao=a("Pass the training arguments to "),hs=r("a"),qo=a("Trainer"),Fo=a(" along with the model, datasets, and data collator."),Mo=h(),zt=r("li"),Co=a("Call "),ms=r("a"),Do=a("train()"),zo=a(" to fine-tune your model."),bl=h(),w(Lt.$$.fragment),El=h(),me=r("h3"),Pe=r("a"),na=r("span"),w(Pt.$$.fragment),Lo=h(),ra=r("span"),Po=a("Fine-tune with TensorFlow"),xl=h(),us=r("p"),Io=a("To fine-tune a model in TensorFlow is just as easy, with only a few differences."),Tl=h(),w(Ie.$$.fragment),Al=h(),V=r("p"),So=a("Convert your datasets to the "),oa=r("code"),Oo=a("tf.data.Dataset"),No=a(" format with "),It=r("a"),ia=r("code"),Ro=a("to_tf_dataset"),Go=a(". Specify inputs and labels in "),pa=r("code"),Bo=a("columns"),Ho=a(", whether to shuffle the dataset order, batch size, and the data collator:"),ql=h(),w(St.$$.fragment),Fl=h(),cs=r("p"),Wo=a("Set up an optimizer function, learning rate, and some training hyperparameters:"),Ml=h(),w(Ot.$$.fragment),Cl=h(),Se=r("p"),Yo=a("Load DistilRoBERTa with "),ds=r("a"),Uo=a("TFAutoModelForMaskedLM"),Jo=a(":"),Dl=h(),w(Nt.$$.fragment),zl=h(),Oe=r("p"),Ko=a("Configure the model for training with "),Rt=r("a"),fa=r("code"),Qo=a("compile"),Vo=a(":"),Ll=h(),w(Gt.$$.fragment),Pl=h(),Ne=r("p"),Xo=a("Call "),Bt=r("a"),ha=r("code"),Zo=a("fit"),ei=a(" to fine-tune the model:"),Il=h(),w(Ht.$$.fragment),Sl=h(),w(Re.$$.fragment),this.h()},l(e){const n=Rp('[data-svelte="svelte-1phssyn"]',document.head);f=o(n,"META",{name:!0,content:!0}),n.forEach(t),x=m(e),c=o(e,"H1",{class:!0});var Wt=i(c);_=o(Wt,"A",{id:!0,class:!0,href:!0});var ma=i(_);A=o(ma,"SPAN",{});var ua=i(A);k(g.$$.fragment,ua),ua.forEach(t),ma.forEach(t),E=m(Wt),F=o(Wt,"SPAN",{});var ca=i(F);$=l(ca,"Language modeling"),ca.forEach(t),Wt.forEach(t),q=m(e),M=o(e,"P",{});var da=i(M);z=l(da,"Language modeling predicts words in a sentence. There are two forms of language modeling."),da.forEach(t),L=m(e),k(P.$$.fragment,e),G=m(e),B=o(e,"P",{});var ga=i(B);H=l(ga,"Causal language modeling predicts the next token in a sequence of tokens, and the model can only attend to tokens on the left."),ga.forEach(t),C=m(e),k(N.$$.fragment,e),d=m(e),T=o(e,"P",{});var _a=i(T);O=l(_a,"Masked language modeling predicts a masked token in a sequence, and the model can attend to tokens bidirectionally."),_a.forEach(t),R=m(e),I=o(e,"P",{});var se=i(I);J=l(se,"This guide will show you how to fine-tune "),W=o(se,"A",{href:!0,rel:!0});var ti=i(W);Yt=l(ti,"DistilGPT2"),ti.forEach(t),Ut=l(se," for causal language modeling and "),We=o(se,"A",{href:!0,rel:!0});var si=i(We);gn=l(si,"DistilRoBERTa"),si.forEach(t),_n=l(se," for masked language modeling on the "),Ye=o(se,"A",{href:!0,rel:!0});var ai=i(Ye);$n=l(ai,"r/askscience"),ai.forEach(t),wn=l(se," subset of the "),Ue=o(se,"A",{href:!0,rel:!0});var li=i(Ue);kn=l(li,"ELI5"),li.forEach(t),jn=l(se," dataset."),se.forEach(t),$a=m(e),k(ce.$$.fragment,e),wa=m(e),ne=o(e,"H2",{class:!0});var Nl=i(ne);de=o(Nl,"A",{id:!0,class:!0,href:!0});var ni=i(de);js=o(ni,"SPAN",{});var ri=i(js);k(Je.$$.fragment,ri),ri.forEach(t),ni.forEach(t),vn=m(Nl),vs=o(Nl,"SPAN",{});var oi=i(vs);yn=l(oi,"Load ELI5 dataset"),oi.forEach(t),Nl.forEach(t),ka=m(e),Jt=o(e,"P",{});var ii=i(Jt);bn=l(ii,"Load only the first 5000 rows of the ELI5 dataset from the \u{1F917} Datasets library since it is pretty large:"),ii.forEach(t),ja=m(e),k(Ke.$$.fragment,e),va=m(e),Kt=o(e,"P",{});var pi=i(Kt);En=l(pi,"Split this dataset into a train and test set:"),pi.forEach(t),ya=m(e),k(Qe.$$.fragment,e),ba=m(e),Qt=o(e,"P",{});var fi=i(Qt);xn=l(fi,"Then take a look at an example:"),fi.forEach(t),Ea=m(e),k(Ve.$$.fragment,e),xa=m(e),K=o(e,"P",{});var Ge=i(K);Tn=l(Ge,"Notice "),ys=o(Ge,"CODE",{});var hi=i(ys);An=l(hi,"text"),hi.forEach(t),qn=l(Ge," is a subfield nested inside the "),bs=o(Ge,"CODE",{});var mi=i(bs);Fn=l(mi,"answers"),mi.forEach(t),Mn=l(Ge," dictionary. When you preprocess the dataset, you will need to extract the "),Es=o(Ge,"CODE",{});var ui=i(Es);Cn=l(ui,"text"),ui.forEach(t),Dn=l(Ge," subfield into a separate column."),Ge.forEach(t),Ta=m(e),re=o(e,"H2",{class:!0});var Rl=i(re);ge=o(Rl,"A",{id:!0,class:!0,href:!0});var ci=i(ge);xs=o(ci,"SPAN",{});var di=i(xs);k(Xe.$$.fragment,di),di.forEach(t),ci.forEach(t),zn=m(Rl),Ts=o(Rl,"SPAN",{});var gi=i(Ts);Ln=l(gi,"Preprocess"),gi.forEach(t),Rl.forEach(t),Aa=m(e),k(Ze.$$.fragment,e),qa=m(e),_e=o(e,"P",{});var Gl=i(_e);Pn=l(Gl,"For causal language modeling, load the DistilGPT2 tokenizer to process the "),As=o(Gl,"CODE",{});var _i=i(As);In=l(_i,"text"),_i.forEach(t),Sn=l(Gl," subfield:"),Gl.forEach(t),Fa=m(e),k(et.$$.fragment,e),Ma=m(e),k(tt.$$.fragment,e),Ca=m(e),Vt=o(e,"P",{});var $i=i(Vt);On=l($i,"For masked language modeling, load the DistilRoBERTa tokenizer instead:"),$i.forEach(t),Da=m(e),k(st.$$.fragment,e),za=m(e),X=o(e,"P",{});var gs=i(X);Nn=l(gs,"Extract the "),qs=o(gs,"CODE",{});var wi=i(qs);Rn=l(wi,"text"),wi.forEach(t),Gn=l(gs," subfield from its nested structure with the "),at=o(gs,"A",{href:!0,rel:!0});var ki=i(at);Fs=o(ki,"CODE",{});var ji=i(Fs);Bn=l(ji,"flatten"),ji.forEach(t),ki.forEach(t),Hn=l(gs," method:"),gs.forEach(t),La=m(e),k(lt.$$.fragment,e),Pa=m(e),Z=o(e,"P",{});var _s=i(Z);Wn=l(_s,"Each subfield is now a separate column as indicated by the "),Ms=o(_s,"CODE",{});var vi=i(Ms);Yn=l(vi,"answers"),vi.forEach(t),Un=l(_s," prefix. Notice that "),Cs=o(_s,"CODE",{});var yi=i(Cs);Jn=l(yi,"answers.text"),yi.forEach(t),Kn=l(_s," is a list. Instead of tokenizing each sentence separately, convert the list to a string to jointly tokenize them."),_s.forEach(t),Ia=m(e),Xt=o(e,"P",{});var bi=i(Xt);Qn=l(bi,"Here is how you can create a preprocessing function to convert the list to a string and truncate sequences to be no longer than DistilGPT2\u2019s maximum input length:"),bi.forEach(t),Sa=m(e),k(nt.$$.fragment,e),Oa=m(e),Y=o(e,"P",{});var ae=i(Y);Vn=l(ae,"Use \u{1F917} Datasets "),rt=o(ae,"A",{href:!0,rel:!0});var Ei=i(rt);Ds=o(Ei,"CODE",{});var xi=i(Ds);Xn=l(xi,"map"),xi.forEach(t),Ei.forEach(t),Zn=l(ae," function to apply the preprocessing function over the entire dataset. You can speed up the "),zs=o(ae,"CODE",{});var Ti=i(zs);er=l(Ti,"map"),Ti.forEach(t),tr=l(ae," function by setting "),Ls=o(ae,"CODE",{});var Ai=i(Ls);sr=l(Ai,"batched=True"),Ai.forEach(t),ar=l(ae," to process multiple elements of the dataset at once and increasing the number of processes with "),Ps=o(ae,"CODE",{});var qi=i(Ps);lr=l(qi,"num_proc"),qi.forEach(t),nr=l(ae,". Remove the columns you don\u2019t need:"),ae.forEach(t),Na=m(e),k(ot.$$.fragment,e),Ra=m(e),Zt=o(e,"P",{});var Fi=i(Zt);rr=l(Fi,"Now you need a second preprocessing function to capture text truncated from any lengthy examples to prevent loss of information. This preprocessing function should:"),Fi.forEach(t),Ga=m(e),$e=o(e,"UL",{});var Bl=i($e);Is=o(Bl,"LI",{});var Mi=i(Is);or=l(Mi,"Concatenate all the text."),Mi.forEach(t),ir=m(Bl),it=o(Bl,"LI",{});var Hl=i(it);pr=l(Hl,"Split the concatenated text into smaller chunks defined by "),Ss=o(Hl,"CODE",{});var Ci=i(Ss);fr=l(Ci,"block_size"),Ci.forEach(t),hr=l(Hl,"."),Hl.forEach(t),Bl.forEach(t),Ba=m(e),k(pt.$$.fragment,e),Ha=m(e),we=o(e,"P",{});var Wl=i(we);mr=l(Wl,"Apply the "),Os=o(Wl,"CODE",{});var Di=i(Os);ur=l(Di,"group_texts"),Di.forEach(t),cr=l(Wl," function over the entire dataset:"),Wl.forEach(t),Wa=m(e),k(ft.$$.fragment,e),Ya=m(e),U=o(e,"P",{});var le=i(U);dr=l(le,"For causal language modeling, use "),es=o(le,"A",{href:!0});var zi=i(es);gr=l(zi,"DataCollatorForLanguageModeling"),zi.forEach(t),_r=l(le," to create a batch of examples. It will also "),Ns=o(le,"EM",{});var Li=i(Ns);$r=l(Li,"dynamically pad"),Li.forEach(t),wr=l(le," your text to the length of the longest element in its batch, so they are a uniform length. While it is possible to pad your text in the "),Rs=o(le,"CODE",{});var Pi=i(Rs);kr=l(Pi,"tokenizer"),Pi.forEach(t),jr=l(le," function by setting "),Gs=o(le,"CODE",{});var Ii=i(Gs);vr=l(Ii,"padding=True"),Ii.forEach(t),yr=l(le,", dynamic padding is more efficient."),le.forEach(t),Ua=m(e),k(ke.$$.fragment,e),Ja=m(e),oe=o(e,"H2",{class:!0});var Yl=i(oe);je=o(Yl,"A",{id:!0,class:!0,href:!0});var Si=i(je);Bs=o(Si,"SPAN",{});var Oi=i(Bs);k(ht.$$.fragment,Oi),Oi.forEach(t),Si.forEach(t),br=m(Yl),Hs=o(Yl,"SPAN",{});var Ni=i(Hs);Er=l(Ni,"Causal language modeling"),Ni.forEach(t),Yl.forEach(t),Ka=m(e),ve=o(e,"P",{});var Ul=i(ve);xr=l(Ul,"Causal language modeling is frequently used for text generation. This section shows you how to fine-tune "),mt=o(Ul,"A",{href:!0,rel:!0});var Ri=i(mt);Tr=l(Ri,"DistilGPT2"),Ri.forEach(t),Ar=l(Ul," to generate new text."),Ul.forEach(t),Qa=m(e),ie=o(e,"H3",{class:!0});var Jl=i(ie);ye=o(Jl,"A",{id:!0,class:!0,href:!0});var Gi=i(ye);Ws=o(Gi,"SPAN",{});var Bi=i(Ws);k(ut.$$.fragment,Bi),Bi.forEach(t),Gi.forEach(t),qr=m(Jl),Ys=o(Jl,"SPAN",{});var Hi=i(Ys);Fr=l(Hi,"Fine-tune with Trainer"),Hi.forEach(t),Jl.forEach(t),Va=m(e),be=o(e,"P",{});var Kl=i(be);Mr=l(Kl,"Load DistilGPT2 with "),ts=o(Kl,"A",{href:!0});var Wi=i(ts);Cr=l(Wi,"AutoModelForCausalLM"),Wi.forEach(t),Dr=l(Kl,":"),Kl.forEach(t),Xa=m(e),k(ct.$$.fragment,e),Za=m(e),k(Ee.$$.fragment,e),el=m(e),ss=o(e,"P",{});var Yi=i(ss);zr=l(Yi,"At this point, only three steps remain:"),Yi.forEach(t),tl=m(e),ee=o(e,"OL",{});var $s=i(ee);dt=o($s,"LI",{});var Ql=i(dt);Lr=l(Ql,"Define your training hyperparameters in "),as=o(Ql,"A",{href:!0});var Ui=i(as);Pr=l(Ui,"TrainingArguments"),Ui.forEach(t),Ir=l(Ql,"."),Ql.forEach(t),Sr=m($s),gt=o($s,"LI",{});var Vl=i(gt);Or=l(Vl,"Pass the training arguments to "),ls=o(Vl,"A",{href:!0});var Ji=i(ls);Nr=l(Ji,"Trainer"),Ji.forEach(t),Rr=l(Vl," along with the model, datasets, and data collator."),Vl.forEach(t),Gr=m($s),_t=o($s,"LI",{});var Xl=i(_t);Br=l(Xl,"Call "),ns=o(Xl,"A",{href:!0});var Ki=i(ns);Hr=l(Ki,"train()"),Ki.forEach(t),Wr=l(Xl," to fine-tune your model."),Xl.forEach(t),$s.forEach(t),sl=m(e),k($t.$$.fragment,e),al=m(e),pe=o(e,"H3",{class:!0});var Zl=i(pe);xe=o(Zl,"A",{id:!0,class:!0,href:!0});var Qi=i(xe);Us=o(Qi,"SPAN",{});var Vi=i(Us);k(wt.$$.fragment,Vi),Vi.forEach(t),Qi.forEach(t),Yr=m(Zl),Js=o(Zl,"SPAN",{});var Xi=i(Js);Ur=l(Xi,"Fine-tune with TensorFlow"),Xi.forEach(t),Zl.forEach(t),ll=m(e),rs=o(e,"P",{});var Zi=i(rs);Jr=l(Zi,"To fine-tune a model in TensorFlow is just as easy, with only a few differences."),Zi.forEach(t),nl=m(e),k(Te.$$.fragment,e),rl=m(e),Q=o(e,"P",{});var Be=i(Q);Kr=l(Be,"Convert your datasets to the "),Ks=o(Be,"CODE",{});var ep=i(Ks);Qr=l(ep,"tf.data.Dataset"),ep.forEach(t),Vr=l(Be," format with "),kt=o(Be,"A",{href:!0,rel:!0});var tp=i(kt);Qs=o(tp,"CODE",{});var sp=i(Qs);Xr=l(sp,"to_tf_dataset"),sp.forEach(t),tp.forEach(t),Zr=l(Be,". Specify inputs and labels in "),Vs=o(Be,"CODE",{});var ap=i(Vs);eo=l(ap,"columns"),ap.forEach(t),to=l(Be,", whether to shuffle the dataset order, batch size, and the data collator:"),Be.forEach(t),ol=m(e),k(jt.$$.fragment,e),il=m(e),os=o(e,"P",{});var lp=i(os);so=l(lp,"Set up an optimizer function, learning rate, and some training hyperparameters:"),lp.forEach(t),pl=m(e),k(vt.$$.fragment,e),fl=m(e),Ae=o(e,"P",{});var en=i(Ae);ao=l(en,"Load DistilGPT2 with "),is=o(en,"A",{href:!0});var np=i(is);lo=l(np,"TFAutoModelForCausalLM"),np.forEach(t),no=l(en,":"),en.forEach(t),hl=m(e),k(yt.$$.fragment,e),ml=m(e),qe=o(e,"P",{});var tn=i(qe);ro=l(tn,"Configure the model for training with "),bt=o(tn,"A",{href:!0,rel:!0});var rp=i(bt);Xs=o(rp,"CODE",{});var op=i(Xs);oo=l(op,"compile"),op.forEach(t),rp.forEach(t),io=l(tn,":"),tn.forEach(t),ul=m(e),k(Et.$$.fragment,e),cl=m(e),Fe=o(e,"P",{});var sn=i(Fe);po=l(sn,"Call "),xt=o(sn,"A",{href:!0,rel:!0});var ip=i(xt);Zs=o(ip,"CODE",{});var pp=i(Zs);fo=l(pp,"fit"),pp.forEach(t),ip.forEach(t),ho=l(sn," to fine-tune the model:"),sn.forEach(t),dl=m(e),k(Tt.$$.fragment,e),gl=m(e),fe=o(e,"H2",{class:!0});var an=i(fe);Me=o(an,"A",{id:!0,class:!0,href:!0});var fp=i(Me);ea=o(fp,"SPAN",{});var hp=i(ea);k(At.$$.fragment,hp),hp.forEach(t),fp.forEach(t),mo=m(an),ta=o(an,"SPAN",{});var mp=i(ta);uo=l(mp,"Masked language modeling"),mp.forEach(t),an.forEach(t),_l=m(e),Ce=o(e,"P",{});var ln=i(Ce);co=l(ln,"Masked language modeling is also known as a fill-mask task because it predicts a masked token in a sequence. Models for masked language modeling require a good contextual understanding of an entire sequence instead of only the left context. This section shows you how to fine-tune "),qt=o(ln,"A",{href:!0,rel:!0});var up=i(qt);go=l(up,"DistilRoBERTa"),up.forEach(t),_o=l(ln," to predict a masked word."),ln.forEach(t),$l=m(e),he=o(e,"H3",{class:!0});var nn=i(he);De=o(nn,"A",{id:!0,class:!0,href:!0});var cp=i(De);sa=o(cp,"SPAN",{});var dp=i(sa);k(Ft.$$.fragment,dp),dp.forEach(t),cp.forEach(t),$o=m(nn),aa=o(nn,"SPAN",{});var gp=i(aa);wo=l(gp,"Fine-tune with Trainer"),gp.forEach(t),nn.forEach(t),wl=m(e),ze=o(e,"P",{});var rn=i(ze);ko=l(rn,"Load DistilRoBERTa with "),la=o(rn,"CODE",{});var _p=i(la);jo=l(_p,"AutoModelForMaskedlM"),_p.forEach(t),vo=l(rn,":"),rn.forEach(t),kl=m(e),k(Mt.$$.fragment,e),jl=m(e),k(Le.$$.fragment,e),vl=m(e),ps=o(e,"P",{});var $p=i(ps);yo=l($p,"At this point, only three steps remain:"),$p.forEach(t),yl=m(e),te=o(e,"OL",{});var ws=i(te);Ct=o(ws,"LI",{});var on=i(Ct);bo=l(on,"Define your training hyperparameters in "),fs=o(on,"A",{href:!0});var wp=i(fs);Eo=l(wp,"TrainingArguments"),wp.forEach(t),xo=l(on,"."),on.forEach(t),To=m(ws),Dt=o(ws,"LI",{});var pn=i(Dt);Ao=l(pn,"Pass the training arguments to "),hs=o(pn,"A",{href:!0});var kp=i(hs);qo=l(kp,"Trainer"),kp.forEach(t),Fo=l(pn," along with the model, datasets, and data collator."),pn.forEach(t),Mo=m(ws),zt=o(ws,"LI",{});var fn=i(zt);Co=l(fn,"Call "),ms=o(fn,"A",{href:!0});var jp=i(ms);Do=l(jp,"train()"),jp.forEach(t),zo=l(fn," to fine-tune your model."),fn.forEach(t),ws.forEach(t),bl=m(e),k(Lt.$$.fragment,e),El=m(e),me=o(e,"H3",{class:!0});var hn=i(me);Pe=o(hn,"A",{id:!0,class:!0,href:!0});var vp=i(Pe);na=o(vp,"SPAN",{});var yp=i(na);k(Pt.$$.fragment,yp),yp.forEach(t),vp.forEach(t),Lo=m(hn),ra=o(hn,"SPAN",{});var bp=i(ra);Po=l(bp,"Fine-tune with TensorFlow"),bp.forEach(t),hn.forEach(t),xl=m(e),us=o(e,"P",{});var Ep=i(us);Io=l(Ep,"To fine-tune a model in TensorFlow is just as easy, with only a few differences."),Ep.forEach(t),Tl=m(e),k(Ie.$$.fragment,e),Al=m(e),V=o(e,"P",{});var He=i(V);So=l(He,"Convert your datasets to the "),oa=o(He,"CODE",{});var xp=i(oa);Oo=l(xp,"tf.data.Dataset"),xp.forEach(t),No=l(He," format with "),It=o(He,"A",{href:!0,rel:!0});var Tp=i(It);ia=o(Tp,"CODE",{});var Ap=i(ia);Ro=l(Ap,"to_tf_dataset"),Ap.forEach(t),Tp.forEach(t),Go=l(He,". Specify inputs and labels in "),pa=o(He,"CODE",{});var qp=i(pa);Bo=l(qp,"columns"),qp.forEach(t),Ho=l(He,", whether to shuffle the dataset order, batch size, and the data collator:"),He.forEach(t),ql=m(e),k(St.$$.fragment,e),Fl=m(e),cs=o(e,"P",{});var Fp=i(cs);Wo=l(Fp,"Set up an optimizer function, learning rate, and some training hyperparameters:"),Fp.forEach(t),Ml=m(e),k(Ot.$$.fragment,e),Cl=m(e),Se=o(e,"P",{});var mn=i(Se);Yo=l(mn,"Load DistilRoBERTa with "),ds=o(mn,"A",{href:!0});var Mp=i(ds);Uo=l(Mp,"TFAutoModelForMaskedLM"),Mp.forEach(t),Jo=l(mn,":"),mn.forEach(t),Dl=m(e),k(Nt.$$.fragment,e),zl=m(e),Oe=o(e,"P",{});var un=i(Oe);Ko=l(un,"Configure the model for training with "),Rt=o(un,"A",{href:!0,rel:!0});var Cp=i(Rt);fa=o(Cp,"CODE",{});var Dp=i(fa);Qo=l(Dp,"compile"),Dp.forEach(t),Cp.forEach(t),Vo=l(un,":"),un.forEach(t),Ll=m(e),k(Gt.$$.fragment,e),Pl=m(e),Ne=o(e,"P",{});var cn=i(Ne);Xo=l(cn,"Call "),Bt=o(cn,"A",{href:!0,rel:!0});var zp=i(Bt);ha=o(zp,"CODE",{});var Lp=i(ha);Zo=l(Lp,"fit"),Lp.forEach(t),zp.forEach(t),ei=l(cn," to fine-tune the model:"),cn.forEach(t),Il=m(e),k(Ht.$$.fragment,e),Sl=m(e),k(Re.$$.fragment,e),this.h()},h(){u(f,"name","hf:doc:metadata"),u(f,"content",JSON.stringify(ef)),u(_,"id","language-modeling"),u(_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(_,"href","#language-modeling"),u(c,"class","relative group"),u(W,"href","https://huggingface.co/distilgpt2"),u(W,"rel","nofollow"),u(We,"href","https://huggingface.co/distilroberta-base"),u(We,"rel","nofollow"),u(Ye,"href","https://www.reddit.com/r/askscience/"),u(Ye,"rel","nofollow"),u(Ue,"href","https://huggingface.co/datasets/eli5"),u(Ue,"rel","nofollow"),u(de,"id","load-eli5-dataset"),u(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(de,"href","#load-eli5-dataset"),u(ne,"class","relative group"),u(ge,"id","preprocess"),u(ge,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ge,"href","#preprocess"),u(re,"class","relative group"),u(at,"href","https://huggingface.co/docs/datasets/process.html#flatten"),u(at,"rel","nofollow"),u(rt,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map"),u(rt,"rel","nofollow"),u(es,"href","/docs/transformers/master/en/main_classes/data_collator#transformers.DataCollatorForLanguageModeling"),u(je,"id","causal-language-modeling"),u(je,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(je,"href","#causal-language-modeling"),u(oe,"class","relative group"),u(mt,"href","https://huggingface.co/distilgpt2"),u(mt,"rel","nofollow"),u(ye,"id","finetune-with-trainer"),u(ye,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ye,"href","#finetune-with-trainer"),u(ie,"class","relative group"),u(ts,"href","/docs/transformers/master/en/model_doc/auto#transformers.AutoModelForCausalLM"),u(as,"href","/docs/transformers/master/en/main_classes/trainer#transformers.TrainingArguments"),u(ls,"href","/docs/transformers/master/en/main_classes/trainer#transformers.Trainer"),u(ns,"href","/docs/transformers/master/en/main_classes/trainer#transformers.Trainer.train"),u(xe,"id","finetune-with-tensorflow"),u(xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(xe,"href","#finetune-with-tensorflow"),u(pe,"class","relative group"),u(kt,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.to_tf_dataset"),u(kt,"rel","nofollow"),u(is,"href","/docs/transformers/master/en/model_doc/auto#transformers.TFAutoModelForCausalLM"),u(bt,"href","https://keras.io/api/models/model_training_apis/#compile-method"),u(bt,"rel","nofollow"),u(xt,"href","https://keras.io/api/models/model_training_apis/#fit-method"),u(xt,"rel","nofollow"),u(Me,"id","masked-language-modeling"),u(Me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(Me,"href","#masked-language-modeling"),u(fe,"class","relative group"),u(qt,"href","https://huggingface.co/distilroberta-base"),u(qt,"rel","nofollow"),u(De,"id","finetune-with-trainer"),u(De,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(De,"href","#finetune-with-trainer"),u(he,"class","relative group"),u(fs,"href","/docs/transformers/master/en/main_classes/trainer#transformers.TrainingArguments"),u(hs,"href","/docs/transformers/master/en/main_classes/trainer#transformers.Trainer"),u(ms,"href","/docs/transformers/master/en/main_classes/trainer#transformers.Trainer.train"),u(Pe,"id","finetune-with-tensorflow"),u(Pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(Pe,"href","#finetune-with-tensorflow"),u(me,"class","relative group"),u(It,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.to_tf_dataset"),u(It,"rel","nofollow"),u(ds,"href","/docs/transformers/master/en/model_doc/auto#transformers.TFAutoModelForMaskedLM"),u(Rt,"href","https://keras.io/api/models/model_training_apis/#compile-method"),u(Rt,"rel","nofollow"),u(Bt,"href","https://keras.io/api/models/model_training_apis/#fit-method"),u(Bt,"rel","nofollow")},m(e,n){s(document.head,f),p(e,x,n),p(e,c,n),s(c,_),s(_,A),j(g,A,null),s(c,E),s(c,F),s(F,$),p(e,q,n),p(e,M,n),s(M,z),p(e,L,n),j(P,e,n),p(e,G,n),p(e,B,n),s(B,H),p(e,C,n),j(N,e,n),p(e,d,n),p(e,T,n),s(T,O),p(e,R,n),p(e,I,n),s(I,J),s(I,W),s(W,Yt),s(I,Ut),s(I,We),s(We,gn),s(I,_n),s(I,Ye),s(Ye,$n),s(I,wn),s(I,Ue),s(Ue,kn),s(I,jn),p(e,$a,n),j(ce,e,n),p(e,wa,n),p(e,ne,n),s(ne,de),s(de,js),j(Je,js,null),s(ne,vn),s(ne,vs),s(vs,yn),p(e,ka,n),p(e,Jt,n),s(Jt,bn),p(e,ja,n),j(Ke,e,n),p(e,va,n),p(e,Kt,n),s(Kt,En),p(e,ya,n),j(Qe,e,n),p(e,ba,n),p(e,Qt,n),s(Qt,xn),p(e,Ea,n),j(Ve,e,n),p(e,xa,n),p(e,K,n),s(K,Tn),s(K,ys),s(ys,An),s(K,qn),s(K,bs),s(bs,Fn),s(K,Mn),s(K,Es),s(Es,Cn),s(K,Dn),p(e,Ta,n),p(e,re,n),s(re,ge),s(ge,xs),j(Xe,xs,null),s(re,zn),s(re,Ts),s(Ts,Ln),p(e,Aa,n),j(Ze,e,n),p(e,qa,n),p(e,_e,n),s(_e,Pn),s(_e,As),s(As,In),s(_e,Sn),p(e,Fa,n),j(et,e,n),p(e,Ma,n),j(tt,e,n),p(e,Ca,n),p(e,Vt,n),s(Vt,On),p(e,Da,n),j(st,e,n),p(e,za,n),p(e,X,n),s(X,Nn),s(X,qs),s(qs,Rn),s(X,Gn),s(X,at),s(at,Fs),s(Fs,Bn),s(X,Hn),p(e,La,n),j(lt,e,n),p(e,Pa,n),p(e,Z,n),s(Z,Wn),s(Z,Ms),s(Ms,Yn),s(Z,Un),s(Z,Cs),s(Cs,Jn),s(Z,Kn),p(e,Ia,n),p(e,Xt,n),s(Xt,Qn),p(e,Sa,n),j(nt,e,n),p(e,Oa,n),p(e,Y,n),s(Y,Vn),s(Y,rt),s(rt,Ds),s(Ds,Xn),s(Y,Zn),s(Y,zs),s(zs,er),s(Y,tr),s(Y,Ls),s(Ls,sr),s(Y,ar),s(Y,Ps),s(Ps,lr),s(Y,nr),p(e,Na,n),j(ot,e,n),p(e,Ra,n),p(e,Zt,n),s(Zt,rr),p(e,Ga,n),p(e,$e,n),s($e,Is),s(Is,or),s($e,ir),s($e,it),s(it,pr),s(it,Ss),s(Ss,fr),s(it,hr),p(e,Ba,n),j(pt,e,n),p(e,Ha,n),p(e,we,n),s(we,mr),s(we,Os),s(Os,ur),s(we,cr),p(e,Wa,n),j(ft,e,n),p(e,Ya,n),p(e,U,n),s(U,dr),s(U,es),s(es,gr),s(U,_r),s(U,Ns),s(Ns,$r),s(U,wr),s(U,Rs),s(Rs,kr),s(U,jr),s(U,Gs),s(Gs,vr),s(U,yr),p(e,Ua,n),j(ke,e,n),p(e,Ja,n),p(e,oe,n),s(oe,je),s(je,Bs),j(ht,Bs,null),s(oe,br),s(oe,Hs),s(Hs,Er),p(e,Ka,n),p(e,ve,n),s(ve,xr),s(ve,mt),s(mt,Tr),s(ve,Ar),p(e,Qa,n),p(e,ie,n),s(ie,ye),s(ye,Ws),j(ut,Ws,null),s(ie,qr),s(ie,Ys),s(Ys,Fr),p(e,Va,n),p(e,be,n),s(be,Mr),s(be,ts),s(ts,Cr),s(be,Dr),p(e,Xa,n),j(ct,e,n),p(e,Za,n),j(Ee,e,n),p(e,el,n),p(e,ss,n),s(ss,zr),p(e,tl,n),p(e,ee,n),s(ee,dt),s(dt,Lr),s(dt,as),s(as,Pr),s(dt,Ir),s(ee,Sr),s(ee,gt),s(gt,Or),s(gt,ls),s(ls,Nr),s(gt,Rr),s(ee,Gr),s(ee,_t),s(_t,Br),s(_t,ns),s(ns,Hr),s(_t,Wr),p(e,sl,n),j($t,e,n),p(e,al,n),p(e,pe,n),s(pe,xe),s(xe,Us),j(wt,Us,null),s(pe,Yr),s(pe,Js),s(Js,Ur),p(e,ll,n),p(e,rs,n),s(rs,Jr),p(e,nl,n),j(Te,e,n),p(e,rl,n),p(e,Q,n),s(Q,Kr),s(Q,Ks),s(Ks,Qr),s(Q,Vr),s(Q,kt),s(kt,Qs),s(Qs,Xr),s(Q,Zr),s(Q,Vs),s(Vs,eo),s(Q,to),p(e,ol,n),j(jt,e,n),p(e,il,n),p(e,os,n),s(os,so),p(e,pl,n),j(vt,e,n),p(e,fl,n),p(e,Ae,n),s(Ae,ao),s(Ae,is),s(is,lo),s(Ae,no),p(e,hl,n),j(yt,e,n),p(e,ml,n),p(e,qe,n),s(qe,ro),s(qe,bt),s(bt,Xs),s(Xs,oo),s(qe,io),p(e,ul,n),j(Et,e,n),p(e,cl,n),p(e,Fe,n),s(Fe,po),s(Fe,xt),s(xt,Zs),s(Zs,fo),s(Fe,ho),p(e,dl,n),j(Tt,e,n),p(e,gl,n),p(e,fe,n),s(fe,Me),s(Me,ea),j(At,ea,null),s(fe,mo),s(fe,ta),s(ta,uo),p(e,_l,n),p(e,Ce,n),s(Ce,co),s(Ce,qt),s(qt,go),s(Ce,_o),p(e,$l,n),p(e,he,n),s(he,De),s(De,sa),j(Ft,sa,null),s(he,$o),s(he,aa),s(aa,wo),p(e,wl,n),p(e,ze,n),s(ze,ko),s(ze,la),s(la,jo),s(ze,vo),p(e,kl,n),j(Mt,e,n),p(e,jl,n),j(Le,e,n),p(e,vl,n),p(e,ps,n),s(ps,yo),p(e,yl,n),p(e,te,n),s(te,Ct),s(Ct,bo),s(Ct,fs),s(fs,Eo),s(Ct,xo),s(te,To),s(te,Dt),s(Dt,Ao),s(Dt,hs),s(hs,qo),s(Dt,Fo),s(te,Mo),s(te,zt),s(zt,Co),s(zt,ms),s(ms,Do),s(zt,zo),p(e,bl,n),j(Lt,e,n),p(e,El,n),p(e,me,n),s(me,Pe),s(Pe,na),j(Pt,na,null),s(me,Lo),s(me,ra),s(ra,Po),p(e,xl,n),p(e,us,n),s(us,Io),p(e,Tl,n),j(Ie,e,n),p(e,Al,n),p(e,V,n),s(V,So),s(V,oa),s(oa,Oo),s(V,No),s(V,It),s(It,ia),s(ia,Ro),s(V,Go),s(V,pa),s(pa,Bo),s(V,Ho),p(e,ql,n),j(St,e,n),p(e,Fl,n),p(e,cs,n),s(cs,Wo),p(e,Ml,n),j(Ot,e,n),p(e,Cl,n),p(e,Se,n),s(Se,Yo),s(Se,ds),s(ds,Uo),s(Se,Jo),p(e,Dl,n),j(Nt,e,n),p(e,zl,n),p(e,Oe,n),s(Oe,Ko),s(Oe,Rt),s(Rt,fa),s(fa,Qo),s(Oe,Vo),p(e,Ll,n),j(Gt,e,n),p(e,Pl,n),p(e,Ne,n),s(Ne,Xo),s(Ne,Bt),s(Bt,ha),s(ha,Zo),s(Ne,ei),p(e,Il,n),j(Ht,e,n),p(e,Sl,n),j(Re,e,n),Ol=!0},p(e,[n]){const Wt={};n&2&&(Wt.$$scope={dirty:n,ctx:e}),ce.$set(Wt);const ma={};n&2&&(ma.$$scope={dirty:n,ctx:e}),ke.$set(ma);const ua={};n&2&&(ua.$$scope={dirty:n,ctx:e}),Ee.$set(ua);const ca={};n&2&&(ca.$$scope={dirty:n,ctx:e}),Te.$set(ca);const da={};n&2&&(da.$$scope={dirty:n,ctx:e}),Le.$set(da);const ga={};n&2&&(ga.$$scope={dirty:n,ctx:e}),Ie.$set(ga);const _a={};n&2&&(_a.$$scope={dirty:n,ctx:e}),Re.$set(_a)},i(e){Ol||(v(g.$$.fragment,e),v(P.$$.fragment,e),v(N.$$.fragment,e),v(ce.$$.fragment,e),v(Je.$$.fragment,e),v(Ke.$$.fragment,e),v(Qe.$$.fragment,e),v(Ve.$$.fragment,e),v(Xe.$$.fragment,e),v(Ze.$$.fragment,e),v(et.$$.fragment,e),v(tt.$$.fragment,e),v(st.$$.fragment,e),v(lt.$$.fragment,e),v(nt.$$.fragment,e),v(ot.$$.fragment,e),v(pt.$$.fragment,e),v(ft.$$.fragment,e),v(ke.$$.fragment,e),v(ht.$$.fragment,e),v(ut.$$.fragment,e),v(ct.$$.fragment,e),v(Ee.$$.fragment,e),v($t.$$.fragment,e),v(wt.$$.fragment,e),v(Te.$$.fragment,e),v(jt.$$.fragment,e),v(vt.$$.fragment,e),v(yt.$$.fragment,e),v(Et.$$.fragment,e),v(Tt.$$.fragment,e),v(At.$$.fragment,e),v(Ft.$$.fragment,e),v(Mt.$$.fragment,e),v(Le.$$.fragment,e),v(Lt.$$.fragment,e),v(Pt.$$.fragment,e),v(Ie.$$.fragment,e),v(St.$$.fragment,e),v(Ot.$$.fragment,e),v(Nt.$$.fragment,e),v(Gt.$$.fragment,e),v(Ht.$$.fragment,e),v(Re.$$.fragment,e),Ol=!0)},o(e){y(g.$$.fragment,e),y(P.$$.fragment,e),y(N.$$.fragment,e),y(ce.$$.fragment,e),y(Je.$$.fragment,e),y(Ke.$$.fragment,e),y(Qe.$$.fragment,e),y(Ve.$$.fragment,e),y(Xe.$$.fragment,e),y(Ze.$$.fragment,e),y(et.$$.fragment,e),y(tt.$$.fragment,e),y(st.$$.fragment,e),y(lt.$$.fragment,e),y(nt.$$.fragment,e),y(ot.$$.fragment,e),y(pt.$$.fragment,e),y(ft.$$.fragment,e),y(ke.$$.fragment,e),y(ht.$$.fragment,e),y(ut.$$.fragment,e),y(ct.$$.fragment,e),y(Ee.$$.fragment,e),y($t.$$.fragment,e),y(wt.$$.fragment,e),y(Te.$$.fragment,e),y(jt.$$.fragment,e),y(vt.$$.fragment,e),y(yt.$$.fragment,e),y(Et.$$.fragment,e),y(Tt.$$.fragment,e),y(At.$$.fragment,e),y(Ft.$$.fragment,e),y(Mt.$$.fragment,e),y(Le.$$.fragment,e),y(Lt.$$.fragment,e),y(Pt.$$.fragment,e),y(Ie.$$.fragment,e),y(St.$$.fragment,e),y(Ot.$$.fragment,e),y(Nt.$$.fragment,e),y(Gt.$$.fragment,e),y(Ht.$$.fragment,e),y(Re.$$.fragment,e),Ol=!1},d(e){t(f),e&&t(x),e&&t(c),b(g),e&&t(q),e&&t(M),e&&t(L),b(P,e),e&&t(G),e&&t(B),e&&t(C),b(N,e),e&&t(d),e&&t(T),e&&t(R),e&&t(I),e&&t($a),b(ce,e),e&&t(wa),e&&t(ne),b(Je),e&&t(ka),e&&t(Jt),e&&t(ja),b(Ke,e),e&&t(va),e&&t(Kt),e&&t(ya),b(Qe,e),e&&t(ba),e&&t(Qt),e&&t(Ea),b(Ve,e),e&&t(xa),e&&t(K),e&&t(Ta),e&&t(re),b(Xe),e&&t(Aa),b(Ze,e),e&&t(qa),e&&t(_e),e&&t(Fa),b(et,e),e&&t(Ma),b(tt,e),e&&t(Ca),e&&t(Vt),e&&t(Da),b(st,e),e&&t(za),e&&t(X),e&&t(La),b(lt,e),e&&t(Pa),e&&t(Z),e&&t(Ia),e&&t(Xt),e&&t(Sa),b(nt,e),e&&t(Oa),e&&t(Y),e&&t(Na),b(ot,e),e&&t(Ra),e&&t(Zt),e&&t(Ga),e&&t($e),e&&t(Ba),b(pt,e),e&&t(Ha),e&&t(we),e&&t(Wa),b(ft,e),e&&t(Ya),e&&t(U),e&&t(Ua),b(ke,e),e&&t(Ja),e&&t(oe),b(ht),e&&t(Ka),e&&t(ve),e&&t(Qa),e&&t(ie),b(ut),e&&t(Va),e&&t(be),e&&t(Xa),b(ct,e),e&&t(Za),b(Ee,e),e&&t(el),e&&t(ss),e&&t(tl),e&&t(ee),e&&t(sl),b($t,e),e&&t(al),e&&t(pe),b(wt),e&&t(ll),e&&t(rs),e&&t(nl),b(Te,e),e&&t(rl),e&&t(Q),e&&t(ol),b(jt,e),e&&t(il),e&&t(os),e&&t(pl),b(vt,e),e&&t(fl),e&&t(Ae),e&&t(hl),b(yt,e),e&&t(ml),e&&t(qe),e&&t(ul),b(Et,e),e&&t(cl),e&&t(Fe),e&&t(dl),b(Tt,e),e&&t(gl),e&&t(fe),b(At),e&&t(_l),e&&t(Ce),e&&t($l),e&&t(he),b(Ft),e&&t(wl),e&&t(ze),e&&t(kl),b(Mt,e),e&&t(jl),b(Le,e),e&&t(vl),e&&t(ps),e&&t(yl),e&&t(te),e&&t(bl),b(Lt,e),e&&t(El),e&&t(me),b(Pt),e&&t(xl),e&&t(us),e&&t(Tl),b(Ie,e),e&&t(Al),e&&t(V),e&&t(ql),b(St,e),e&&t(Fl),e&&t(cs),e&&t(Ml),b(Ot,e),e&&t(Cl),e&&t(Se),e&&t(Dl),b(Nt,e),e&&t(zl),e&&t(Oe),e&&t(Ll),b(Gt,e),e&&t(Pl),e&&t(Ne),e&&t(Il),b(Ht,e),e&&t(Sl),b(Re,e)}}}const ef={local:"language-modeling",sections:[{local:"load-eli5-dataset",title:"Load ELI5 dataset"},{local:"preprocess",title:"Preprocess"},{local:"causal-language-modeling",sections:[{local:"finetune-with-trainer",title:"Fine-tune with Trainer"},{local:"finetune-with-tensorflow",title:"Fine-tune with TensorFlow"}],title:"Causal language modeling"},{local:"masked-language-modeling",sections:[{local:"finetune-with-trainer",title:"Fine-tune with Trainer"},{local:"finetune-with-tensorflow",title:"Fine-tune with TensorFlow"}],title:"Masked language modeling"}],title:"Language modeling"};function tf(S,f,x){let{fw:c}=f;return S.$$set=_=>{"fw"in _&&x(0,c=_.fw)},[c]}class pf extends Sp{constructor(f){super();Op(this,f,tf,Zp,Np,{fw:0})}}export{pf as default,ef as metadata};
