import{S as tl,i as ll,s as il,e as i,k as d,w as f,t,M as rl,c as r,d as s,m as u,a as p,x as c,h as l,b as h,N as pl,G as n,g as o,y as g,q as m,o as v,B as b,v as ol}from"../chunks/vendor-hf-doc-builder.js";import{T as dl,C as _}from"../chunks/CodeBlock-hf-doc-builder.js";import{I as Oe}from"../chunks/IconCopyLink-hf-doc-builder.js";function ul($s){let j,L,k,x,M;return{c(){j=i("p"),L=t("Eine vollst\xE4ndige Liste der unterst\xFCtzten Aufgaben und verf\xFCgbaren Parameter finden Sie in der "),k=i("code"),x=t("pipeline()"),M=t("-Dokumentation.")},l(E){j=r(E,"P",{});var A=p(j);L=l(A,"Eine vollst\xE4ndige Liste der unterst\xFCtzten Aufgaben und verf\xFCgbaren Parameter finden Sie in der "),k=r(A,"CODE",{});var F=p(k);x=l(F,"pipeline()"),F.forEach(s),M=l(A,"-Dokumentation."),A.forEach(s)},m(E,A){o(E,j,A),n(j,L),n(j,k),n(k,x),n(j,M)},d(E){E&&s(j)}}}function hl($s){let j,L,k,x,M,E,A,F,En,ks,S,_n,Le,xn,Sn,se,zn,qn,Fe,An,Pn,ws,P,ne,yn,Ke,Dn,Mn,In,Ve,Bn,Cn,ae,Tn,Ne,On,Ln,Es,K,_s,I,V,He,te,Fn,Re,Kn,xs,z,Vn,We,Nn,Hn,Ge,Rn,Wn,Ue,Gn,Un,Ss,qe,le,Qn,Qe,Zn,Jn,zs,ie,qs,re,pe,Xn,Ze,Yn,ea,As,oe,Ps,Ae,sa,ys,de,Ds,w,na,Je,aa,ta,Xe,la,ia,Ye,ra,pa,es,oa,da,Ms,ue,Is,B,N,ss,he,ua,ns,ha,Bs,$,fa,as,ca,ga,fe,ma,va,ts,ba,ja,ls,$a,ka,is,wa,Ea,Cs,ce,Ts,H,_a,rs,xa,Sa,Os,ge,Ls,R,za,ps,qa,Aa,Fs,me,Ks,C,W,os,ve,Pa,ds,ya,Vs,G,Da,us,Ma,Ia,Ns,Pe,Ba,Hs,be,Rs,y,Ca,je,Ta,Oa,hs,La,Fa,Ws,$e,Gs,U,Ka,fs,Va,Na,Us,ke,Qs,T,Q,cs,we,Ha,gs,Ra,Zs,Z,Wa,ms,Ga,Ua,Js,ye,Qa,Xs,De,Me,at,Ys,Ee,en,O,J,vs,_e,Za,bs,Ja,sn,X,Xa,js,Ya,et,nn,Ie,st,an,xe,tn,Be,nt,ln,Se,rn;return E=new Oe({}),K=new dl({props:{$$slots:{default:[ul]},$$scope:{ctx:$s}}}),te=new Oe({}),ie=new _({props:{code:`from transformers import pipeline

generator = pipeline(task="text-generation")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>generator = pipeline(task=<span class="hljs-string">&quot;text-generation&quot;</span>)`}}),oe=new _({props:{code:`generator(
    "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone"
)  # doctest: +SKIP`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>
<span class="hljs-meta">... </span>)  <span class="hljs-comment"># doctest: +SKIP</span>
[{<span class="hljs-string">&#x27;generated_text&#x27;</span>: <span class="hljs-string">&#x27;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone, Seven for the Iron-priests at the door to the east, and thirteen for the Lord Kings at the end of the mountain&#x27;</span>}]`}}),de=new _({props:{code:`generator(
    [
        "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone",
        "Nine for Mortal Men, doomed to die, One for the Dark Lord on his dark throne",
    ]
)  # doctest: +SKIP`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(
<span class="hljs-meta">... </span>    [
<span class="hljs-meta">... </span>        <span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>,
<span class="hljs-meta">... </span>        <span class="hljs-string">&quot;Nine for Mortal Men, doomed to die, One for the Dark Lord on his dark throne&quot;</span>,
<span class="hljs-meta">... </span>    ]
<span class="hljs-meta">... </span>)  <span class="hljs-comment"># doctest: +SKIP</span>`}}),ue=new _({props:{code:`generator(
    "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone",
    num_return_sequences=2,
)  # doctest: +SKIP`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>,
<span class="hljs-meta">... </span>    num_return_sequences=<span class="hljs-number">2</span>,
<span class="hljs-meta">... </span>)  <span class="hljs-comment"># doctest: +SKIP</span>`}}),he=new Oe({}),ce=new _({props:{code:`from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained("distilgpt2")
model = AutoModelForCausalLM.from_pretrained("distilgpt2")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilgpt2&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;distilgpt2&quot;</span>)`}}),ge=new _({props:{code:`from transformers import pipeline

generator = pipeline(task="text-generation", model=model, tokenizer=tokenizer)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>generator = pipeline(task=<span class="hljs-string">&quot;text-generation&quot;</span>, model=model, tokenizer=tokenizer)`}}),me=new _({props:{code:`generator(
    "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone"
)  # doctest: +SKIP`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>
<span class="hljs-meta">... </span>)  <span class="hljs-comment"># doctest: +SKIP</span>
[{<span class="hljs-string">&#x27;generated_text&#x27;</span>: <span class="hljs-string">&#x27;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone, Seven for the Dragon-lords (for them to rule in a world ruled by their rulers, and all who live within the realm&#x27;</span>}]`}}),ve=new Oe({}),be=new _({props:{code:`from datasets import load_dataset
import torch

torch.manual_seed(42)
ds = load_dataset("hf-internal-testing/librispeech_asr_demo", "clean", split="validation")
audio_file = ds[0]["audio"]["path"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>torch.manual_seed(<span class="hljs-number">42</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_dataset(<span class="hljs-string">&quot;hf-internal-testing/librispeech_asr_demo&quot;</span>, <span class="hljs-string">&quot;clean&quot;</span>, split=<span class="hljs-string">&quot;validation&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>audio_file = ds[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>][<span class="hljs-string">&quot;path&quot;</span>]`}}),$e=new _({props:{code:`from transformers import pipeline

audio_classifier = pipeline(
    task="audio-classification", model="ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>audio_classifier = pipeline(
<span class="hljs-meta">... </span>    task=<span class="hljs-string">&quot;audio-classification&quot;</span>, model=<span class="hljs-string">&quot;ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition&quot;</span>
<span class="hljs-meta">... </span>)`}}),ke=new _({props:{code:`preds = audio_classifier(audio_file)
preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
preds`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>preds = audio_classifier(audio_file)
<span class="hljs-meta">&gt;&gt;&gt; </span>preds = [{<span class="hljs-string">&quot;score&quot;</span>: <span class="hljs-built_in">round</span>(pred[<span class="hljs-string">&quot;score&quot;</span>], <span class="hljs-number">4</span>), <span class="hljs-string">&quot;label&quot;</span>: pred[<span class="hljs-string">&quot;label&quot;</span>]} <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> preds]
<span class="hljs-meta">&gt;&gt;&gt; </span>preds
[{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1315</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;calm&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1307</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;neutral&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1274</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;sad&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1261</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;fearful&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1242</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;happy&#x27;</span>}]`}}),we=new Oe({}),Ee=new _({props:{code:`from transformers import pipeline

vision_classifier = pipeline(task="image-classification")
preds = vision_classifier(
    images="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
)
preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
preds`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>vision_classifier = pipeline(task=<span class="hljs-string">&quot;image-classification&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>preds = vision_classifier(
<span class="hljs-meta">... </span>    images=<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg&quot;</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>preds = [{<span class="hljs-string">&quot;score&quot;</span>: <span class="hljs-built_in">round</span>(pred[<span class="hljs-string">&quot;score&quot;</span>], <span class="hljs-number">4</span>), <span class="hljs-string">&quot;label&quot;</span>: pred[<span class="hljs-string">&quot;label&quot;</span>]} <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> preds]
<span class="hljs-meta">&gt;&gt;&gt; </span>preds
[{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.4335</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;lynx, catamount&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0348</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;cougar, puma, catamount, mountain lion, painter, panther, Felis concolor&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0324</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;snow leopard, ounce, Panthera uncia&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0239</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;Egyptian cat&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0229</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;tiger cat&#x27;</span>}]`}}),_e=new Oe({}),xe=new _({props:{code:`image = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
question = "Where is the cat?"`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>image = <span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>question = <span class="hljs-string">&quot;Where is the cat?&quot;</span>`}}),Se=new _({props:{code:`from transformers import pipeline

vqa = pipeline(task="vqa")
preds = vqa(image=image, question=question)
preds = [{"score": round(pred["score"], 4), "answer": pred["answer"]} for pred in preds]
preds`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>vqa = pipeline(task=<span class="hljs-string">&quot;vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>preds = vqa(image=image, question=question)
<span class="hljs-meta">&gt;&gt;&gt; </span>preds = [{<span class="hljs-string">&quot;score&quot;</span>: <span class="hljs-built_in">round</span>(pred[<span class="hljs-string">&quot;score&quot;</span>], <span class="hljs-number">4</span>), <span class="hljs-string">&quot;answer&quot;</span>: pred[<span class="hljs-string">&quot;answer&quot;</span>]} <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> preds]
<span class="hljs-meta">&gt;&gt;&gt; </span>preds
[{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9112</span>, <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;snow&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.8796</span>, <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;in snow&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.6717</span>, <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;outside&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0291</span>, <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;on ground&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.027</span>, <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;ground&#x27;</span>}]`}}),{c(){j=i("meta"),L=d(),k=i("h1"),x=i("a"),M=i("span"),f(E.$$.fragment),A=d(),F=i("span"),En=t("Pipelines f\xFCr Inferenzen"),ks=d(),S=i("p"),_n=t("Die "),Le=i("code"),xn=t("pipeline()"),Sn=t(" macht es einfach, jedes beliebige Modell aus dem "),se=i("a"),zn=t("Hub"),qn=t(" f\xFCr die Inferenz auf jede Sprache, Computer Vision, Sprache und multimodale Aufgaben zu verwenden. Selbst wenn Sie keine Erfahrung mit einer bestimmten Modalit\xE4t haben oder nicht mit dem zugrundeliegenden Code hinter den Modellen vertraut sind, k\xF6nnen Sie sie mit der "),Fe=i("code"),An=t("pipeline()"),Pn=t(" f\xFCr Inferenzen verwenden! In diesem Beispiel lernen Sie, wie:"),ws=d(),P=i("ul"),ne=i("li"),yn=t("Eine "),Ke=i("code"),Dn=t("pipeline()"),Mn=t(" f\xFCr Inferenz zu verwenden."),In=d(),Ve=i("li"),Bn=t("Einen bestimmten Tokenizer oder ein bestimmtes Modell zu verwenden."),Cn=d(),ae=i("li"),Tn=t("Eine "),Ne=i("code"),On=t("pipeline()"),Ln=t(" f\xFCr Audio-, Vision- und multimodale Aufgaben zu verwenden."),Es=d(),f(K.$$.fragment),_s=d(),I=i("h2"),V=i("a"),He=i("span"),f(te.$$.fragment),Fn=d(),Re=i("span"),Kn=t("Verwendung von Pipelines"),xs=d(),z=i("p"),Vn=t("Obwohl jede Aufgabe eine zugeh\xF6rige "),We=i("code"),Nn=t("pipeline()"),Hn=t(" hat, ist es einfacher, die allgemeine "),Ge=i("code"),Rn=t("pipeline()"),Wn=t("-Abstraktion zu verwenden, die alle aufgabenspezifischen Pipelines enth\xE4lt. Die "),Ue=i("code"),Gn=t("pipeline()"),Un=t(" l\xE4dt automatisch ein Standardmodell und eine Vorverarbeitungsklasse, die f\xFCr Ihre Aufgabe inferenzf\xE4hig ist."),Ss=d(),qe=i("ol"),le=i("li"),Qn=t("Beginnen Sie mit der Erstellung einer "),Qe=i("code"),Zn=t("pipeline()"),Jn=t(" und geben Sie eine Inferenzaufgabe an:"),zs=d(),f(ie.$$.fragment),qs=d(),re=i("ol"),pe=i("li"),Xn=t("\xDCbergeben Sie Ihren Eingabetext an die "),Ze=i("code"),Yn=t("pipeline()"),ea=t(":"),As=d(),f(oe.$$.fragment),Ps=d(),Ae=i("p"),sa=t("Wenn Sie mehr als eine Eingabe haben, \xFCbergeben Sie die Eingabe als Liste:"),ys=d(),f(de.$$.fragment),Ds=d(),w=i("p"),na=t("Alle zus\xE4tzlichen Parameter f\xFCr Ihre Aufgabe k\xF6nnen auch in die "),Je=i("code"),aa=t("pipeline()"),ta=t(" aufgenommen werden. Die Aufgabe "),Xe=i("code"),la=t("Text-Generierung"),ia=t(" hat eine "),Ye=i("code"),ra=t("generate()"),pa=t("-Methode mit mehreren Parametern zur Steuerung der Ausgabe. Wenn Sie zum Beispiel mehr als eine Ausgabe erzeugen wollen, setzen Sie den Parameter "),es=i("code"),oa=t("num_return_sequences"),da=t(":"),Ms=d(),f(ue.$$.fragment),Is=d(),B=i("h3"),N=i("a"),ss=i("span"),f(he.$$.fragment),ua=d(),ns=i("span"),ha=t("W\xE4hlen Sie ein Modell und einen Tokenizer"),Bs=d(),$=i("p"),fa=t("Die "),as=i("code"),ca=t("pipeline()"),ga=t(" akzeptiert jedes Modell aus dem [Hub] ("),fe=i("a"),ma=t("https://huggingface.co/models"),va=t("). Auf dem Hub gibt es Tags, mit denen Sie nach einem Modell filtern k\xF6nnen, das Sie f\xFCr Ihre Aufgabe verwenden m\xF6chten. Sobald Sie ein passendes Modell ausgew\xE4hlt haben, laden Sie es mit der entsprechenden "),ts=i("code"),ba=t("AutoModelFor"),ja=t(" und "),ls=i("code"),$a=t("AutoTokenizer"),ka=t(" Klasse. Laden Sie zum Beispiel die Klasse "),is=i("code"),wa=t("AutoModelForCausalLM"),Ea=t(" f\xFCr eine kausale Sprachmodellierungsaufgabe:"),Cs=d(),f(ce.$$.fragment),Ts=d(),H=i("p"),_a=t("Erstellen Sie eine "),rs=i("code"),xa=t("pipeline()"),Sa=t(" f\xFCr Ihre Aufgabe, und geben Sie das Modell und den Tokenizer an, die Sie geladen haben:"),Os=d(),f(ge.$$.fragment),Ls=d(),R=i("p"),za=t("\xDCbergeben Sie Ihren Eingabetext an die "),ps=i("code"),qa=t("pipeline()"),Aa=t(" , um einen Text zu erzeugen:"),Fs=d(),f(me.$$.fragment),Ks=d(),C=i("h2"),W=i("a"),os=i("span"),f(ve.$$.fragment),Pa=d(),ds=i("span"),ya=t("Audio-Pipeline"),Vs=d(),G=i("p"),Da=t("Die "),us=i("code"),Ma=t("pipeline()"),Ia=t(" unterst\xFCtzt auch Audioaufgaben wie Audioklassifizierung und automatische Spracherkennung."),Ns=d(),Pe=i("p"),Ba=t("Lassen Sie uns zum Beispiel die Emotion in diesem Audioclip klassifizieren:"),Hs=d(),f(be.$$.fragment),Rs=d(),y=i("p"),Ca=t("Finden Sie ein "),je=i("a"),Ta=t("Audioklassifikation"),Oa=t(" Modell auf dem Model Hub f\xFCr Emotionserkennung und laden Sie es in die "),hs=i("code"),La=t("pipeline()"),Fa=t(":"),Ws=d(),f($e.$$.fragment),Gs=d(),U=i("p"),Ka=t("\xDCbergeben Sie die Audiodatei an die "),fs=i("code"),Va=t("pipeline()"),Na=t(":"),Us=d(),f(ke.$$.fragment),Qs=d(),T=i("h2"),Q=i("a"),cs=i("span"),f(we.$$.fragment),Ha=d(),gs=i("span"),Ra=t("Bildverarbeitungs-Pipeline"),Zs=d(),Z=i("p"),Wa=t("Die Verwendung einer "),ms=i("code"),Ga=t("pipeline()"),Ua=t(" f\xFCr Bildverarbeitungsaufgaben ist praktisch identisch."),Js=d(),ye=i("p"),Qa=t("Geben Sie Ihre Aufgabe an und \xFCbergeben Sie Ihr Bild an den Klassifikator. Das Bild kann ein Link oder ein lokaler Pfad zu dem Bild sein. Zum Beispiel: Welche Katzenart ist unten abgebildet?"),Xs=d(),De=i("p"),Me=i("img"),Ys=d(),f(Ee.$$.fragment),en=d(),O=i("h2"),J=i("a"),vs=i("span"),f(_e.$$.fragment),Za=d(),bs=i("span"),Ja=t("Multimodale Pipeline"),sn=d(),X=i("p"),Xa=t("Die "),js=i("code"),Ya=t("pipeline()"),et=t(" unterst\xFCtzt mehr als eine Modalit\xE4t. Eine Aufgabe zur Beantwortung visueller Fragen (VQA) kombiniert zum Beispiel Text und Bild. Verwenden Sie einen beliebigen Bildlink und eine Frage, die Sie zu dem Bild stellen m\xF6chten. Das Bild kann eine URL oder ein lokaler Pfad zu dem Bild sein."),nn=d(),Ie=i("p"),st=t("Wenn Sie zum Beispiel das gleiche Bild wie in der obigen Vision-Pipeline verwenden:"),an=d(),f(xe.$$.fragment),tn=d(),Be=i("p"),nt=t("Erstellen Sie eine Pipeline f\xFCr \u201Cvqa\u201D und \xFCbergeben Sie ihr das Bild und die Frage:"),ln=d(),f(Se.$$.fragment),this.h()},l(e){const a=rl('[data-svelte="svelte-1phssyn"]',document.head);j=r(a,"META",{name:!0,content:!0}),a.forEach(s),L=u(e),k=r(e,"H1",{class:!0});var ze=p(k);x=r(ze,"A",{id:!0,class:!0,href:!0});var tt=p(x);M=r(tt,"SPAN",{});var lt=p(M);c(E.$$.fragment,lt),lt.forEach(s),tt.forEach(s),A=u(ze),F=r(ze,"SPAN",{});var it=p(F);En=l(it,"Pipelines f\xFCr Inferenzen"),it.forEach(s),ze.forEach(s),ks=u(e),S=r(e,"P",{});var Y=p(S);_n=l(Y,"Die "),Le=r(Y,"CODE",{});var rt=p(Le);xn=l(rt,"pipeline()"),rt.forEach(s),Sn=l(Y," macht es einfach, jedes beliebige Modell aus dem "),se=r(Y,"A",{href:!0,rel:!0});var pt=p(se);zn=l(pt,"Hub"),pt.forEach(s),qn=l(Y," f\xFCr die Inferenz auf jede Sprache, Computer Vision, Sprache und multimodale Aufgaben zu verwenden. Selbst wenn Sie keine Erfahrung mit einer bestimmten Modalit\xE4t haben oder nicht mit dem zugrundeliegenden Code hinter den Modellen vertraut sind, k\xF6nnen Sie sie mit der "),Fe=r(Y,"CODE",{});var ot=p(Fe);An=l(ot,"pipeline()"),ot.forEach(s),Pn=l(Y," f\xFCr Inferenzen verwenden! In diesem Beispiel lernen Sie, wie:"),Y.forEach(s),ws=u(e),P=r(e,"UL",{});var Ce=p(P);ne=r(Ce,"LI",{});var pn=p(ne);yn=l(pn,"Eine "),Ke=r(pn,"CODE",{});var dt=p(Ke);Dn=l(dt,"pipeline()"),dt.forEach(s),Mn=l(pn," f\xFCr Inferenz zu verwenden."),pn.forEach(s),In=u(Ce),Ve=r(Ce,"LI",{});var ut=p(Ve);Bn=l(ut,"Einen bestimmten Tokenizer oder ein bestimmtes Modell zu verwenden."),ut.forEach(s),Cn=u(Ce),ae=r(Ce,"LI",{});var on=p(ae);Tn=l(on,"Eine "),Ne=r(on,"CODE",{});var ht=p(Ne);On=l(ht,"pipeline()"),ht.forEach(s),Ln=l(on," f\xFCr Audio-, Vision- und multimodale Aufgaben zu verwenden."),on.forEach(s),Ce.forEach(s),Es=u(e),c(K.$$.fragment,e),_s=u(e),I=r(e,"H2",{class:!0});var dn=p(I);V=r(dn,"A",{id:!0,class:!0,href:!0});var ft=p(V);He=r(ft,"SPAN",{});var ct=p(He);c(te.$$.fragment,ct),ct.forEach(s),ft.forEach(s),Fn=u(dn),Re=r(dn,"SPAN",{});var gt=p(Re);Kn=l(gt,"Verwendung von Pipelines"),gt.forEach(s),dn.forEach(s),xs=u(e),z=r(e,"P",{});var ee=p(z);Vn=l(ee,"Obwohl jede Aufgabe eine zugeh\xF6rige "),We=r(ee,"CODE",{});var mt=p(We);Nn=l(mt,"pipeline()"),mt.forEach(s),Hn=l(ee," hat, ist es einfacher, die allgemeine "),Ge=r(ee,"CODE",{});var vt=p(Ge);Rn=l(vt,"pipeline()"),vt.forEach(s),Wn=l(ee,"-Abstraktion zu verwenden, die alle aufgabenspezifischen Pipelines enth\xE4lt. Die "),Ue=r(ee,"CODE",{});var bt=p(Ue);Gn=l(bt,"pipeline()"),bt.forEach(s),Un=l(ee," l\xE4dt automatisch ein Standardmodell und eine Vorverarbeitungsklasse, die f\xFCr Ihre Aufgabe inferenzf\xE4hig ist."),ee.forEach(s),Ss=u(e),qe=r(e,"OL",{});var jt=p(qe);le=r(jt,"LI",{});var un=p(le);Qn=l(un,"Beginnen Sie mit der Erstellung einer "),Qe=r(un,"CODE",{});var $t=p(Qe);Zn=l($t,"pipeline()"),$t.forEach(s),Jn=l(un," und geben Sie eine Inferenzaufgabe an:"),un.forEach(s),jt.forEach(s),zs=u(e),c(ie.$$.fragment,e),qs=u(e),re=r(e,"OL",{start:!0});var kt=p(re);pe=r(kt,"LI",{});var hn=p(pe);Xn=l(hn,"\xDCbergeben Sie Ihren Eingabetext an die "),Ze=r(hn,"CODE",{});var wt=p(Ze);Yn=l(wt,"pipeline()"),wt.forEach(s),ea=l(hn,":"),hn.forEach(s),kt.forEach(s),As=u(e),c(oe.$$.fragment,e),Ps=u(e),Ae=r(e,"P",{});var Et=p(Ae);sa=l(Et,"Wenn Sie mehr als eine Eingabe haben, \xFCbergeben Sie die Eingabe als Liste:"),Et.forEach(s),ys=u(e),c(de.$$.fragment,e),Ds=u(e),w=r(e,"P",{});var D=p(w);na=l(D,"Alle zus\xE4tzlichen Parameter f\xFCr Ihre Aufgabe k\xF6nnen auch in die "),Je=r(D,"CODE",{});var _t=p(Je);aa=l(_t,"pipeline()"),_t.forEach(s),ta=l(D," aufgenommen werden. Die Aufgabe "),Xe=r(D,"CODE",{});var xt=p(Xe);la=l(xt,"Text-Generierung"),xt.forEach(s),ia=l(D," hat eine "),Ye=r(D,"CODE",{});var St=p(Ye);ra=l(St,"generate()"),St.forEach(s),pa=l(D,"-Methode mit mehreren Parametern zur Steuerung der Ausgabe. Wenn Sie zum Beispiel mehr als eine Ausgabe erzeugen wollen, setzen Sie den Parameter "),es=r(D,"CODE",{});var zt=p(es);oa=l(zt,"num_return_sequences"),zt.forEach(s),da=l(D,":"),D.forEach(s),Ms=u(e),c(ue.$$.fragment,e),Is=u(e),B=r(e,"H3",{class:!0});var fn=p(B);N=r(fn,"A",{id:!0,class:!0,href:!0});var qt=p(N);ss=r(qt,"SPAN",{});var At=p(ss);c(he.$$.fragment,At),At.forEach(s),qt.forEach(s),ua=u(fn),ns=r(fn,"SPAN",{});var Pt=p(ns);ha=l(Pt,"W\xE4hlen Sie ein Modell und einen Tokenizer"),Pt.forEach(s),fn.forEach(s),Bs=u(e),$=r(e,"P",{});var q=p($);fa=l(q,"Die "),as=r(q,"CODE",{});var yt=p(as);ca=l(yt,"pipeline()"),yt.forEach(s),ga=l(q," akzeptiert jedes Modell aus dem [Hub] ("),fe=r(q,"A",{href:!0,rel:!0});var Dt=p(fe);ma=l(Dt,"https://huggingface.co/models"),Dt.forEach(s),va=l(q,"). Auf dem Hub gibt es Tags, mit denen Sie nach einem Modell filtern k\xF6nnen, das Sie f\xFCr Ihre Aufgabe verwenden m\xF6chten. Sobald Sie ein passendes Modell ausgew\xE4hlt haben, laden Sie es mit der entsprechenden "),ts=r(q,"CODE",{});var Mt=p(ts);ba=l(Mt,"AutoModelFor"),Mt.forEach(s),ja=l(q," und "),ls=r(q,"CODE",{});var It=p(ls);$a=l(It,"AutoTokenizer"),It.forEach(s),ka=l(q," Klasse. Laden Sie zum Beispiel die Klasse "),is=r(q,"CODE",{});var Bt=p(is);wa=l(Bt,"AutoModelForCausalLM"),Bt.forEach(s),Ea=l(q," f\xFCr eine kausale Sprachmodellierungsaufgabe:"),q.forEach(s),Cs=u(e),c(ce.$$.fragment,e),Ts=u(e),H=r(e,"P",{});var cn=p(H);_a=l(cn,"Erstellen Sie eine "),rs=r(cn,"CODE",{});var Ct=p(rs);xa=l(Ct,"pipeline()"),Ct.forEach(s),Sa=l(cn," f\xFCr Ihre Aufgabe, und geben Sie das Modell und den Tokenizer an, die Sie geladen haben:"),cn.forEach(s),Os=u(e),c(ge.$$.fragment,e),Ls=u(e),R=r(e,"P",{});var gn=p(R);za=l(gn,"\xDCbergeben Sie Ihren Eingabetext an die "),ps=r(gn,"CODE",{});var Tt=p(ps);qa=l(Tt,"pipeline()"),Tt.forEach(s),Aa=l(gn," , um einen Text zu erzeugen:"),gn.forEach(s),Fs=u(e),c(me.$$.fragment,e),Ks=u(e),C=r(e,"H2",{class:!0});var mn=p(C);W=r(mn,"A",{id:!0,class:!0,href:!0});var Ot=p(W);os=r(Ot,"SPAN",{});var Lt=p(os);c(ve.$$.fragment,Lt),Lt.forEach(s),Ot.forEach(s),Pa=u(mn),ds=r(mn,"SPAN",{});var Ft=p(ds);ya=l(Ft,"Audio-Pipeline"),Ft.forEach(s),mn.forEach(s),Vs=u(e),G=r(e,"P",{});var vn=p(G);Da=l(vn,"Die "),us=r(vn,"CODE",{});var Kt=p(us);Ma=l(Kt,"pipeline()"),Kt.forEach(s),Ia=l(vn," unterst\xFCtzt auch Audioaufgaben wie Audioklassifizierung und automatische Spracherkennung."),vn.forEach(s),Ns=u(e),Pe=r(e,"P",{});var Vt=p(Pe);Ba=l(Vt,"Lassen Sie uns zum Beispiel die Emotion in diesem Audioclip klassifizieren:"),Vt.forEach(s),Hs=u(e),c(be.$$.fragment,e),Rs=u(e),y=r(e,"P",{});var Te=p(y);Ca=l(Te,"Finden Sie ein "),je=r(Te,"A",{href:!0,rel:!0});var Nt=p(je);Ta=l(Nt,"Audioklassifikation"),Nt.forEach(s),Oa=l(Te," Modell auf dem Model Hub f\xFCr Emotionserkennung und laden Sie es in die "),hs=r(Te,"CODE",{});var Ht=p(hs);La=l(Ht,"pipeline()"),Ht.forEach(s),Fa=l(Te,":"),Te.forEach(s),Ws=u(e),c($e.$$.fragment,e),Gs=u(e),U=r(e,"P",{});var bn=p(U);Ka=l(bn,"\xDCbergeben Sie die Audiodatei an die "),fs=r(bn,"CODE",{});var Rt=p(fs);Va=l(Rt,"pipeline()"),Rt.forEach(s),Na=l(bn,":"),bn.forEach(s),Us=u(e),c(ke.$$.fragment,e),Qs=u(e),T=r(e,"H2",{class:!0});var jn=p(T);Q=r(jn,"A",{id:!0,class:!0,href:!0});var Wt=p(Q);cs=r(Wt,"SPAN",{});var Gt=p(cs);c(we.$$.fragment,Gt),Gt.forEach(s),Wt.forEach(s),Ha=u(jn),gs=r(jn,"SPAN",{});var Ut=p(gs);Ra=l(Ut,"Bildverarbeitungs-Pipeline"),Ut.forEach(s),jn.forEach(s),Zs=u(e),Z=r(e,"P",{});var $n=p(Z);Wa=l($n,"Die Verwendung einer "),ms=r($n,"CODE",{});var Qt=p(ms);Ga=l(Qt,"pipeline()"),Qt.forEach(s),Ua=l($n," f\xFCr Bildverarbeitungsaufgaben ist praktisch identisch."),$n.forEach(s),Js=u(e),ye=r(e,"P",{});var Zt=p(ye);Qa=l(Zt,"Geben Sie Ihre Aufgabe an und \xFCbergeben Sie Ihr Bild an den Klassifikator. Das Bild kann ein Link oder ein lokaler Pfad zu dem Bild sein. Zum Beispiel: Welche Katzenart ist unten abgebildet?"),Zt.forEach(s),Xs=u(e),De=r(e,"P",{});var Jt=p(De);Me=r(Jt,"IMG",{src:!0,alt:!0}),Jt.forEach(s),Ys=u(e),c(Ee.$$.fragment,e),en=u(e),O=r(e,"H2",{class:!0});var kn=p(O);J=r(kn,"A",{id:!0,class:!0,href:!0});var Xt=p(J);vs=r(Xt,"SPAN",{});var Yt=p(vs);c(_e.$$.fragment,Yt),Yt.forEach(s),Xt.forEach(s),Za=u(kn),bs=r(kn,"SPAN",{});var el=p(bs);Ja=l(el,"Multimodale Pipeline"),el.forEach(s),kn.forEach(s),sn=u(e),X=r(e,"P",{});var wn=p(X);Xa=l(wn,"Die "),js=r(wn,"CODE",{});var sl=p(js);Ya=l(sl,"pipeline()"),sl.forEach(s),et=l(wn," unterst\xFCtzt mehr als eine Modalit\xE4t. Eine Aufgabe zur Beantwortung visueller Fragen (VQA) kombiniert zum Beispiel Text und Bild. Verwenden Sie einen beliebigen Bildlink und eine Frage, die Sie zu dem Bild stellen m\xF6chten. Das Bild kann eine URL oder ein lokaler Pfad zu dem Bild sein."),wn.forEach(s),nn=u(e),Ie=r(e,"P",{});var nl=p(Ie);st=l(nl,"Wenn Sie zum Beispiel das gleiche Bild wie in der obigen Vision-Pipeline verwenden:"),nl.forEach(s),an=u(e),c(xe.$$.fragment,e),tn=u(e),Be=r(e,"P",{});var al=p(Be);nt=l(al,"Erstellen Sie eine Pipeline f\xFCr \u201Cvqa\u201D und \xFCbergeben Sie ihr das Bild und die Frage:"),al.forEach(s),ln=u(e),c(Se.$$.fragment,e),this.h()},h(){h(j,"name","hf:doc:metadata"),h(j,"content",JSON.stringify(fl)),h(x,"id","pipelines-fr-inferenzen"),h(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(x,"href","#pipelines-fr-inferenzen"),h(k,"class","relative group"),h(se,"href","https://huggingface.co/models"),h(se,"rel","nofollow"),h(V,"id","verwendung-von-pipelines"),h(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(V,"href","#verwendung-von-pipelines"),h(I,"class","relative group"),h(re,"start","2"),h(N,"id","whlen-sie-ein-modell-und-einen-tokenizer"),h(N,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(N,"href","#whlen-sie-ein-modell-und-einen-tokenizer"),h(B,"class","relative group"),h(fe,"href","https://huggingface.co/models"),h(fe,"rel","nofollow"),h(W,"id","audiopipeline"),h(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(W,"href","#audiopipeline"),h(C,"class","relative group"),h(je,"href","https://huggingface.co/models?pipeline_tag=audio-classification"),h(je,"rel","nofollow"),h(Q,"id","bildverarbeitungspipeline"),h(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Q,"href","#bildverarbeitungspipeline"),h(T,"class","relative group"),pl(Me.src,at="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg")||h(Me,"src",at),h(Me,"alt","pipeline-cat-chonk"),h(J,"id","multimodale-pipeline"),h(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(J,"href","#multimodale-pipeline"),h(O,"class","relative group")},m(e,a){n(document.head,j),o(e,L,a),o(e,k,a),n(k,x),n(x,M),g(E,M,null),n(k,A),n(k,F),n(F,En),o(e,ks,a),o(e,S,a),n(S,_n),n(S,Le),n(Le,xn),n(S,Sn),n(S,se),n(se,zn),n(S,qn),n(S,Fe),n(Fe,An),n(S,Pn),o(e,ws,a),o(e,P,a),n(P,ne),n(ne,yn),n(ne,Ke),n(Ke,Dn),n(ne,Mn),n(P,In),n(P,Ve),n(Ve,Bn),n(P,Cn),n(P,ae),n(ae,Tn),n(ae,Ne),n(Ne,On),n(ae,Ln),o(e,Es,a),g(K,e,a),o(e,_s,a),o(e,I,a),n(I,V),n(V,He),g(te,He,null),n(I,Fn),n(I,Re),n(Re,Kn),o(e,xs,a),o(e,z,a),n(z,Vn),n(z,We),n(We,Nn),n(z,Hn),n(z,Ge),n(Ge,Rn),n(z,Wn),n(z,Ue),n(Ue,Gn),n(z,Un),o(e,Ss,a),o(e,qe,a),n(qe,le),n(le,Qn),n(le,Qe),n(Qe,Zn),n(le,Jn),o(e,zs,a),g(ie,e,a),o(e,qs,a),o(e,re,a),n(re,pe),n(pe,Xn),n(pe,Ze),n(Ze,Yn),n(pe,ea),o(e,As,a),g(oe,e,a),o(e,Ps,a),o(e,Ae,a),n(Ae,sa),o(e,ys,a),g(de,e,a),o(e,Ds,a),o(e,w,a),n(w,na),n(w,Je),n(Je,aa),n(w,ta),n(w,Xe),n(Xe,la),n(w,ia),n(w,Ye),n(Ye,ra),n(w,pa),n(w,es),n(es,oa),n(w,da),o(e,Ms,a),g(ue,e,a),o(e,Is,a),o(e,B,a),n(B,N),n(N,ss),g(he,ss,null),n(B,ua),n(B,ns),n(ns,ha),o(e,Bs,a),o(e,$,a),n($,fa),n($,as),n(as,ca),n($,ga),n($,fe),n(fe,ma),n($,va),n($,ts),n(ts,ba),n($,ja),n($,ls),n(ls,$a),n($,ka),n($,is),n(is,wa),n($,Ea),o(e,Cs,a),g(ce,e,a),o(e,Ts,a),o(e,H,a),n(H,_a),n(H,rs),n(rs,xa),n(H,Sa),o(e,Os,a),g(ge,e,a),o(e,Ls,a),o(e,R,a),n(R,za),n(R,ps),n(ps,qa),n(R,Aa),o(e,Fs,a),g(me,e,a),o(e,Ks,a),o(e,C,a),n(C,W),n(W,os),g(ve,os,null),n(C,Pa),n(C,ds),n(ds,ya),o(e,Vs,a),o(e,G,a),n(G,Da),n(G,us),n(us,Ma),n(G,Ia),o(e,Ns,a),o(e,Pe,a),n(Pe,Ba),o(e,Hs,a),g(be,e,a),o(e,Rs,a),o(e,y,a),n(y,Ca),n(y,je),n(je,Ta),n(y,Oa),n(y,hs),n(hs,La),n(y,Fa),o(e,Ws,a),g($e,e,a),o(e,Gs,a),o(e,U,a),n(U,Ka),n(U,fs),n(fs,Va),n(U,Na),o(e,Us,a),g(ke,e,a),o(e,Qs,a),o(e,T,a),n(T,Q),n(Q,cs),g(we,cs,null),n(T,Ha),n(T,gs),n(gs,Ra),o(e,Zs,a),o(e,Z,a),n(Z,Wa),n(Z,ms),n(ms,Ga),n(Z,Ua),o(e,Js,a),o(e,ye,a),n(ye,Qa),o(e,Xs,a),o(e,De,a),n(De,Me),o(e,Ys,a),g(Ee,e,a),o(e,en,a),o(e,O,a),n(O,J),n(J,vs),g(_e,vs,null),n(O,Za),n(O,bs),n(bs,Ja),o(e,sn,a),o(e,X,a),n(X,Xa),n(X,js),n(js,Ya),n(X,et),o(e,nn,a),o(e,Ie,a),n(Ie,st),o(e,an,a),g(xe,e,a),o(e,tn,a),o(e,Be,a),n(Be,nt),o(e,ln,a),g(Se,e,a),rn=!0},p(e,[a]){const ze={};a&2&&(ze.$$scope={dirty:a,ctx:e}),K.$set(ze)},i(e){rn||(m(E.$$.fragment,e),m(K.$$.fragment,e),m(te.$$.fragment,e),m(ie.$$.fragment,e),m(oe.$$.fragment,e),m(de.$$.fragment,e),m(ue.$$.fragment,e),m(he.$$.fragment,e),m(ce.$$.fragment,e),m(ge.$$.fragment,e),m(me.$$.fragment,e),m(ve.$$.fragment,e),m(be.$$.fragment,e),m($e.$$.fragment,e),m(ke.$$.fragment,e),m(we.$$.fragment,e),m(Ee.$$.fragment,e),m(_e.$$.fragment,e),m(xe.$$.fragment,e),m(Se.$$.fragment,e),rn=!0)},o(e){v(E.$$.fragment,e),v(K.$$.fragment,e),v(te.$$.fragment,e),v(ie.$$.fragment,e),v(oe.$$.fragment,e),v(de.$$.fragment,e),v(ue.$$.fragment,e),v(he.$$.fragment,e),v(ce.$$.fragment,e),v(ge.$$.fragment,e),v(me.$$.fragment,e),v(ve.$$.fragment,e),v(be.$$.fragment,e),v($e.$$.fragment,e),v(ke.$$.fragment,e),v(we.$$.fragment,e),v(Ee.$$.fragment,e),v(_e.$$.fragment,e),v(xe.$$.fragment,e),v(Se.$$.fragment,e),rn=!1},d(e){s(j),e&&s(L),e&&s(k),b(E),e&&s(ks),e&&s(S),e&&s(ws),e&&s(P),e&&s(Es),b(K,e),e&&s(_s),e&&s(I),b(te),e&&s(xs),e&&s(z),e&&s(Ss),e&&s(qe),e&&s(zs),b(ie,e),e&&s(qs),e&&s(re),e&&s(As),b(oe,e),e&&s(Ps),e&&s(Ae),e&&s(ys),b(de,e),e&&s(Ds),e&&s(w),e&&s(Ms),b(ue,e),e&&s(Is),e&&s(B),b(he),e&&s(Bs),e&&s($),e&&s(Cs),b(ce,e),e&&s(Ts),e&&s(H),e&&s(Os),b(ge,e),e&&s(Ls),e&&s(R),e&&s(Fs),b(me,e),e&&s(Ks),e&&s(C),b(ve),e&&s(Vs),e&&s(G),e&&s(Ns),e&&s(Pe),e&&s(Hs),b(be,e),e&&s(Rs),e&&s(y),e&&s(Ws),b($e,e),e&&s(Gs),e&&s(U),e&&s(Us),b(ke,e),e&&s(Qs),e&&s(T),b(we),e&&s(Zs),e&&s(Z),e&&s(Js),e&&s(ye),e&&s(Xs),e&&s(De),e&&s(Ys),b(Ee,e),e&&s(en),e&&s(O),b(_e),e&&s(sn),e&&s(X),e&&s(nn),e&&s(Ie),e&&s(an),b(xe,e),e&&s(tn),e&&s(Be),e&&s(ln),b(Se,e)}}}const fl={local:"pipelines-fr-inferenzen",sections:[{local:"verwendung-von-pipelines",sections:[{local:"whlen-sie-ein-modell-und-einen-tokenizer",title:"W\xE4hlen Sie ein Modell und einen Tokenizer"}],title:"Verwendung von Pipelines"},{local:"audiopipeline",title:"Audio-Pipeline"},{local:"bildverarbeitungspipeline",title:"Bildverarbeitungs-Pipeline"},{local:"multimodale-pipeline",title:"Multimodale Pipeline"}],title:"Pipelines f\xFCr Inferenzen"};function cl($s){return ol(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class bl extends tl{constructor(j){super();ll(this,j,cl,hl,il,{})}}export{bl as default,fl as metadata};
