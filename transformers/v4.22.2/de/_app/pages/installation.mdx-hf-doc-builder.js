import{S as oo,i as fo,s as uo,e as i,k as u,w as c,t as s,M as ho,c as l,d as n,m as d,a,x as g,h as o,b as h,N as po,G as t,g as f,y as v,q as b,o as _,B as $,v as mo}from"../chunks/vendor-hf-doc-builder.js";import{C as k,T as gi}from"../chunks/CodeBlock-hf-doc-builder.js";import{I as ce}from"../chunks/IconCopyLink-hf-doc-builder.js";function co(B){let p,z,m,S,P;return{c(){p=i("p"),z=s("Sie m\xFCssen den Ordner "),m=i("code"),S=s("transformers"),P=s(" behalten, wenn Sie die Bibliothek weiter verwenden wollen.")},l(w){p=l(w,"P",{});var E=a(p);z=o(E,"Sie m\xFCssen den Ordner "),m=l(E,"CODE",{});var T=a(m);S=o(T,"transformers"),T.forEach(n),P=o(E," behalten, wenn Sie die Bibliothek weiter verwenden wollen."),E.forEach(n)},m(w,E){f(w,p,E),t(p,z),t(p,m),t(m,S),t(p,P)},d(w){w&&n(p)}}}function go(B){let p,z,m,S,P,w,E,T,y,A,D;return{c(){p=i("p"),z=s("Transformers verwendet die Shell-Umgebungsvariablen "),m=i("code"),S=s("PYTORCH_TRANSFORMERS_CACHE"),P=s(" oder "),w=i("code"),E=s("PYTORCH_PRETRAINED_BERT_CACHE"),T=s(", wenn Sie von einer fr\xFCheren Iteration dieser Bibliothek kommen und diese Umgebungsvariablen gesetzt haben, sofern Sie nicht die Shell-Umgebungsvariable "),y=i("code"),A=s("TRANSFORMERS_CACHE"),D=s(" angeben.")},l(O){p=l(O,"P",{});var I=a(p);z=o(I,"Transformers verwendet die Shell-Umgebungsvariablen "),m=l(I,"CODE",{});var N=a(m);S=o(N,"PYTORCH_TRANSFORMERS_CACHE"),N.forEach(n),P=o(I," oder "),w=l(I,"CODE",{});var _n=a(w);E=o(_n,"PYTORCH_PRETRAINED_BERT_CACHE"),_n.forEach(n),T=o(I,", wenn Sie von einer fr\xFCheren Iteration dieser Bibliothek kommen und diese Umgebungsvariablen gesetzt haben, sofern Sie nicht die Shell-Umgebungsvariable "),y=l(I,"CODE",{});var ge=a(y);A=o(ge,"TRANSFORMERS_CACHE"),ge.forEach(n),D=o(I," angeben."),I.forEach(n)},m(O,I){f(O,p,I),t(p,z),t(p,m),t(m,S),t(p,P),t(p,w),t(w,E),t(p,T),t(p,y),t(y,A),t(p,D)},d(O){O&&n(p)}}}function vo(B){let p,z,m,S,P,w,E,T;return{c(){p=i("p"),z=s("F\xFCgen sie "),m=i("a"),S=s("\u{1F917} Datasets"),P=s(" zu Ihrem Offline-Trainingsworkflow hinzuf\xFCgen, indem Sie die Umgebungsvariable "),w=i("code"),E=s("HF_DATASETS_OFFLINE=1"),T=s(" setzen."),this.h()},l(y){p=l(y,"P",{});var A=a(p);z=o(A,"F\xFCgen sie "),m=l(A,"A",{href:!0,rel:!0});var D=a(m);S=o(D,"\u{1F917} Datasets"),D.forEach(n),P=o(A," zu Ihrem Offline-Trainingsworkflow hinzuf\xFCgen, indem Sie die Umgebungsvariable "),w=l(A,"CODE",{});var O=a(w);E=o(O,"HF_DATASETS_OFFLINE=1"),O.forEach(n),T=o(A," setzen."),A.forEach(n),this.h()},h(){h(m,"href","https://huggingface.co/docs/datasets/"),h(m,"rel","nofollow")},m(y,A){f(y,p,A),t(p,z),t(p,m),t(m,S),t(p,P),t(p,w),t(w,E),t(p,T)},d(y){y&&n(p)}}}function bo(B){let p,z,m,S,P;return{c(){p=i("p"),z=s("Weitere Informationen zum Herunterladen von Dateien, die auf dem Hub gespeichert sind, finden Sie im Abschnitt [Wie man Dateien vom Hub herunterl\xE4dt] ("),m=i("a"),S=s("https://huggingface.co/docs/hub/how-to-downstream"),P=s(")."),this.h()},l(w){p=l(w,"P",{});var E=a(p);z=o(E,"Weitere Informationen zum Herunterladen von Dateien, die auf dem Hub gespeichert sind, finden Sie im Abschnitt [Wie man Dateien vom Hub herunterl\xE4dt] ("),m=l(E,"A",{href:!0,rel:!0});var T=a(m);S=o(T,"https://huggingface.co/docs/hub/how-to-downstream"),T.forEach(n),P=o(E,")."),E.forEach(n),this.h()},h(){h(m,"href","https://huggingface.co/docs/hub/how-to-downstream"),h(m,"rel","nofollow")},m(w,E){f(w,p,E),t(p,z),t(p,m),t(m,S),t(p,P)},d(w){w&&n(p)}}}function _o(B){let p,z,m,S,P,w,E,T,y,A,D,O,I,N,_n,ge,F,$n,ve,vi,bi,_i,wn,be,$i,wi,Ei,En,_e,Si,ki,jt,x,ee,Xn,$e,Pi,et,zi,Lt,M,Ti,we,Ai,yi,Ee,Ii,Ci,Nt,Sn,Di,xt,Se,Vt,kn,Oi,qt,ke,Wt,Pn,Bi,Gt,Pe,Kt,zn,Fi,Zt,ze,Jt,Tn,Mi,Qt,Te,Yt,An,Hi,Xt,Ae,er,yn,Ui,nr,ye,tr,In,Ri,rr,Ie,ir,Cn,ji,lr,Ce,ar,V,ne,nt,De,Li,tt,Ni,sr,Dn,xi,or,Oe,fr,C,Vi,rt,qi,Wi,it,Gi,Ki,lt,Zi,Ji,Be,Qi,Yi,ur,On,Xi,dr,Fe,hr,q,te,at,Me,el,st,nl,pr,Bn,tl,mr,re,ot,rl,il,ft,ll,cr,Fn,al,gr,He,vr,H,sl,ut,ol,fl,dt,ul,dl,br,ie,_r,Mn,hl,$r,Ue,wr,le,pl,ht,ml,cl,Er,W,ae,pt,Re,gl,mt,vl,Sr,se,bl,ct,_l,$l,kr,je,Pr,G,oe,gt,Le,wl,vt,El,zr,U,Sl,bt,kl,Pl,_t,zl,Tl,Tr,R,K,Al,$t,yl,Il,wt,Cl,Dl,Ol,Ne,Bl,Et,Fl,Ml,Hl,Z,Ul,St,Rl,jl,kt,Ll,Nl,Ar,fe,yr,J,ue,Pt,xe,xl,zt,Vl,Ir,de,ql,Tt,Wl,Gl,Cr,he,Dr,Hn,Kl,Or,Ve,Br,Un,Zl,Fr,qe,Mr,Rn,Jl,Hr,Q,pe,At,We,Ql,yt,Yl,Ur,jn,Xl,Rr,j,Ge,Ke,ea,Ze,na,ta,ra,It,Ln,Ra,ia,Je,Ct,la,aa,Y,Qe,Ye,sa,Dt,oa,fa,ua,Xe,da,en,nn,ha,Ot,pa,ma,ca,tn,ga,rn,ln,va,Bt,ba,_a,$a,an,wa,sn,on,Ea,fn,Sa,ka,Pa,un,dn,Ft,za,Ta,hn,Aa,pn,X,ya,mn,Mt,Ia,Ca,cn,Da,Oa,Ba,gn,jr,Nn,Fa,Lr,vn,Nr,me,xr;return w=new ce({}),$e=new ce({}),Se=new k({props:{code:"python -m venv .env",highlighted:'python -m venv .<span class="hljs-built_in">env</span>'}}),ke=new k({props:{code:"source .env/bin/activate",highlighted:'<span class="hljs-built_in">source</span> .<span class="hljs-built_in">env</span>/bin/activate'}}),Pe=new k({props:{code:".env/Scripts/activate",highlighted:'.<span class="hljs-built_in">env</span>/Scripts/activate'}}),ze=new k({props:{code:"pip install transformers",highlighted:"pip install transformers"}}),Te=new k({props:{code:"pip install transformers[torch]",highlighted:"pip install transformers[torch]"}}),Ae=new k({props:{code:"pip install transformers[tf-cpu]",highlighted:"pip install transformers[tf-cpu]"}}),ye=new k({props:{code:"pip install transformers[flax]",highlighted:"pip install transformers[flax]"}}),Ie=new k({props:{code:`python -c "from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))"`,highlighted:'python -c <span class="hljs-string">&quot;from transformers import pipeline; print(pipeline(&#x27;sentiment-analysis&#x27;)(&#x27;we love you&#x27;))&quot;</span>'}}),Ce=new k({props:{code:"[{'label': 'POSITIVE', 'score': 0.9998704791069031}]",highlighted:'[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;POSITIVE&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: 0.9998704791069031}]'}}),De=new ce({}),Oe=new k({props:{code:"pip install git+https://github.com/huggingface/transformers",highlighted:"pip install git+https://github.com/huggingface/transformers"}}),Fe=new k({props:{code:`python -c "from transformers import pipeline; print(pipeline('sentiment-analysis')('I love you'))"`,highlighted:'python -c <span class="hljs-string">&quot;from transformers import pipeline; print(pipeline(&#x27;sentiment-analysis&#x27;)(&#x27;I love you&#x27;))&quot;</span>'}}),Me=new ce({}),He=new k({props:{code:`git clone https://github.com/huggingface/transformers.git
cd transformers
pip install -e .`,highlighted:`git <span class="hljs-built_in">clone</span> https://github.com/huggingface/transformers.git
<span class="hljs-built_in">cd</span> transformers
pip install -e .`}}),ie=new gi({props:{warning:!0,$$slots:{default:[co]},$$scope:{ctx:B}}}),Ue=new k({props:{code:`cd ~/transformers/
git pull`,highlighted:`<span class="hljs-built_in">cd</span> ~/transformers/
git pull`}}),Re=new ce({}),je=new k({props:{code:"conda install -c huggingface transformers",highlighted:"conda install -c huggingface transformers"}}),Le=new ce({}),fe=new gi({props:{$$slots:{default:[go]},$$scope:{ctx:B}}}),xe=new ce({}),he=new gi({props:{$$slots:{default:[vo]},$$scope:{ctx:B}}}),Ve=new k({props:{code:"python examples/pytorch/translation/run_translation.py --model_name_or_path t5-small --dataset_name wmt16 --dataset_config ro-en ...",highlighted:"python examples/pytorch/translation/run_translation.py --model_name_or_path t5-small --dataset_name wmt16 --dataset_config ro-en ..."}}),qe=new k({props:{code:`HF_DATASETS_OFFLINE=1 TRANSFORMERS_OFFLINE=1 \\
python examples/pytorch/translation/run_translation.py --model_name_or_path t5-small --dataset_name wmt16 --dataset_config ro-en ...`,highlighted:`HF_DATASETS_OFFLINE=1 TRANSFORMERS_OFFLINE=1 \\
python examples/pytorch/translation/run_translation.py --model_name_or_path t5-small --dataset_name wmt16 --dataset_config ro-en ...`}}),We=new ce({}),Xe=new k({props:{code:`from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

tokenizer = AutoTokenizer.from_pretrained("bigscience/T0_3B")
model = AutoModelForSeq2SeqLM.from_pretrained("bigscience/T0_3B")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bigscience/T0_3B&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;bigscience/T0_3B&quot;</span>)`}}),tn=new k({props:{code:`tokenizer.save_pretrained("./your/path/bigscience_t0")
model.save_pretrained("./your/path/bigscience_t0")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(<span class="hljs-string">&quot;./your/path/bigscience_t0&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.save_pretrained(<span class="hljs-string">&quot;./your/path/bigscience_t0&quot;</span>)`}}),an=new k({props:{code:`tokenizer = AutoTokenizer.from_pretrained("./your/path/bigscience_t0")
model = AutoModel.from_pretrained("./your/path/bigscience_t0")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./your/path/bigscience_t0&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;./your/path/bigscience_t0&quot;</span>)`}}),hn=new k({props:{code:"python -m pip install huggingface_hub",highlighted:"python -m pip install huggingface_hub"}}),gn=new k({props:{code:`from huggingface_hub import hf_hub_download

hf_hub_download(repo_id="bigscience/T0_3B", filename="config.json", cache_dir="./your/path/bigscience_t0")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> hf_hub_download

<span class="hljs-meta">&gt;&gt;&gt; </span>hf_hub_download(repo_id=<span class="hljs-string">&quot;bigscience/T0_3B&quot;</span>, filename=<span class="hljs-string">&quot;config.json&quot;</span>, cache_dir=<span class="hljs-string">&quot;./your/path/bigscience_t0&quot;</span>)`}}),vn=new k({props:{code:`from transformers import AutoConfig

config = AutoConfig.from_pretrained("./your/path/bigscience_t0/config.json")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./your/path/bigscience_t0/config.json&quot;</span>)`}}),me=new gi({props:{$$slots:{default:[bo]},$$scope:{ctx:B}}}),{c(){p=i("meta"),z=u(),m=i("h1"),S=i("a"),P=i("span"),c(w.$$.fragment),E=u(),T=i("span"),y=s("Installation"),A=u(),D=i("p"),O=s("Installieren Sie \u{1F917} Transformers f\xFCr die Deep-Learning-Bibliothek, mit der Sie arbeiten, richten Sie Ihren Cache ein und konfigurieren Sie \u{1F917} Transformers optional f\xFCr den Offline-Betrieb."),I=u(),N=i("p"),_n=s("\u{1F917} Transformers wurde unter Python 3.6+, PyTorch 1.1.0+, TensorFlow 2.0+, und Flax getestet. Folgen Sie den Installationsanweisungen unten f\xFCr die von Ihnen verwendete Deep-Learning-Bibliothek:"),ge=u(),F=i("ul"),$n=i("li"),ve=i("a"),vi=s("PyTorch"),bi=s(" installation instructions."),_i=u(),wn=i("li"),be=i("a"),$i=s("TensorFlow 2.0"),wi=s(" installation instructions."),Ei=u(),En=i("li"),_e=i("a"),Si=s("Flax"),ki=s(" installation instructions."),jt=u(),x=i("h2"),ee=i("a"),Xn=i("span"),c($e.$$.fragment),Pi=u(),et=i("span"),zi=s("Installation mit pip"),Lt=u(),M=i("p"),Ti=s("Sie sollten \u{1F917} Transformers in einer "),we=i("a"),Ai=s("virtuellen Umgebung"),yi=s(" installieren. Wenn Sie mit virtuellen Python-Umgebungen nicht vertraut sind, werfen Sie einen Blick auf diese "),Ee=i("a"),Ii=s("Anleitung"),Ci=s(". Eine virtuelle Umgebung macht es einfacher, verschiedene Projekte zu verwalten und Kompatibilit\xE4tsprobleme zwischen Abh\xE4ngigkeiten zu vermeiden."),Nt=u(),Sn=i("p"),Di=s("Beginnen wir mit der Erstellung einer virtuellen Umgebung in Ihrem Projektverzeichnis:"),xt=u(),c(Se.$$.fragment),Vt=u(),kn=i("p"),Oi=s("Aktivieren wir die virtuelle Umgebung. Unter Linux und MacOs:"),qt=u(),c(ke.$$.fragment),Wt=u(),Pn=i("p"),Bi=s("Aktivieren wir die virtuelle Umgebung unter Windows"),Gt=u(),c(Pe.$$.fragment),Kt=u(),zn=i("p"),Fi=s("Jetzt k\xF6nnen wir die \u{1F917} Transformers mit dem folgenden Befehl installieren:"),Zt=u(),c(ze.$$.fragment),Jt=u(),Tn=i("p"),Mi=s("Bei reiner CPU-Unterst\xFCtzung k\xF6nnen wir \u{1F917} Transformers und eine Deep-Learning-Bibliothek bequem in einer Zeile installieren. Installieren wir zum Beispiel \u{1F917} Transformers und PyTorch mit:"),Qt=u(),c(Te.$$.fragment),Yt=u(),An=i("p"),Hi=s("\u{1F917} Transformers und TensorFlow 2.0:"),Xt=u(),c(Ae.$$.fragment),er=u(),yn=i("p"),Ui=s("\u{1F917} Transformers und Flax:"),nr=u(),c(ye.$$.fragment),tr=u(),In=i("p"),Ri=s("\xDCberpr\xFCfen wir abschlie\xDFend, ob \u{1F917} Transformers ordnungsgem\xE4\xDF installiert wurde, indem wir den folgenden Befehl ausf\xFChren. Es wird ein vortrainiertes Modell heruntergeladen:"),rr=u(),c(Ie.$$.fragment),ir=u(),Cn=i("p"),ji=s("Dann wird die Kategorie und die Wahrscheinlichkeit ausgegeben:"),lr=u(),c(Ce.$$.fragment),ar=u(),V=i("h2"),ne=i("a"),nt=i("span"),c(De.$$.fragment),Li=u(),tt=i("span"),Ni=s("Installation aus dem Code"),sr=u(),Dn=i("p"),xi=s("Installieren wir \u{1F917} Transformers aus dem Quellcode mit dem folgenden Befehl:"),or=u(),c(Oe.$$.fragment),fr=u(),C=i("p"),Vi=s("Dieser Befehl installiert die aktuelle "),rt=i("code"),qi=s("main"),Wi=s(" Version und nicht die neueste "),it=i("code"),Gi=s("stable"),Ki=s(" Version. Die "),lt=i("code"),Zi=s("main"),Ji=s("-Version ist n\xFCtzlich, um mit den neuesten Entwicklungen Schritt zu halten. Zum Beispiel, wenn ein Fehler seit der letzten offiziellen Version behoben wurde, aber eine neue Version noch nicht ver\xF6ffentlicht wurde. Das bedeutet jedoch, dass die \u201CHauptversion\u201D nicht immer stabil ist. Wir bem\xFChen uns, die Hauptversion einsatzbereit zu halten, und die meisten Probleme werden normalerweise innerhalb weniger Stunden oder eines Tages behoben. Wenn Sie auf ein Problem sto\xDFen, \xF6ffnen Sie bitte ein [Issue] ("),Be=i("a"),Qi=s("https://github.com/huggingface/transformers/issues"),Yi=s("), damit wir es noch schneller beheben k\xF6nnen!"),ur=u(),On=i("p"),Xi=s("\xDCberpr\xFCfen wir, ob \u{1F917} Transformers richtig installiert wurde, indem Sie den folgenden Befehl ausf\xFChren:"),dr=u(),c(Fe.$$.fragment),hr=u(),q=i("h2"),te=i("a"),at=i("span"),c(Me.$$.fragment),el=u(),st=i("span"),nl=s("Editierbare Installation"),pr=u(),Bn=i("p"),tl=s("Sie ben\xF6tigen eine bearbeitbare Installation, wenn Sie:"),mr=u(),re=i("ul"),ot=i("li"),rl=s("die \u201CHaupt\u201D-Version des Quellcodes verwenden m\xF6chten."),il=u(),ft=i("li"),ll=s("Zu \u{1F917} Transformers beitragen und \xC4nderungen am Code testen wollen."),cr=u(),Fn=i("p"),al=s("Klonen Sie das Repository und installieren \u{1F917} Transformers mit den folgenden Befehlen:"),gr=u(),c(He.$$.fragment),vr=u(),H=i("p"),sl=s("Diese Befehle verkn\xFCpfen den Ordner, in den Sie das Repository geklont haben, mit den Pfaden Ihrer Python-Bibliotheken. Python wird nun in dem Ordner suchen, in den Sie geklont haben, zus\xE4tzlich zu den normalen Bibliothekspfaden. Wenn zum Beispiel Ihre Python-Pakete normalerweise in "),ut=i("code"),ol=s("~/anaconda3/envs/main/lib/python3.7/site-packages/"),fl=s(" installiert sind, wird Python auch den Ordner durchsuchen, in den Sie geklont haben: "),dt=i("code"),ul=s("~/transformers/"),dl=s("."),br=u(),c(ie.$$.fragment),_r=u(),Mn=i("p"),hl=s("Jetzt k\xF6nnen Sie Ihren Klon mit dem folgenden Befehl ganz einfach auf die neueste Version von \u{1F917} Transformers aktualisieren:"),$r=u(),c(Ue.$$.fragment),wr=u(),le=i("p"),pl=s("Ihre Python-Umgebung wird beim n\xE4chsten Ausf\xFChren die "),ht=i("code"),ml=s("main"),cl=s("-Version von \u{1F917} Transformers finden."),Er=u(),W=i("h2"),ae=i("a"),pt=i("span"),c(Re.$$.fragment),gl=u(),mt=i("span"),vl=s("Installation mit conda"),Sr=u(),se=i("p"),bl=s("Installation von dem conda Kanal "),ct=i("code"),_l=s("huggingface"),$l=s(":"),kr=u(),c(je.$$.fragment),Pr=u(),G=i("h2"),oe=i("a"),gt=i("span"),c(Le.$$.fragment),wl=u(),vt=i("span"),El=s("Cache Einrichtung"),zr=u(),U=i("p"),Sl=s("Vorgefertigte Modelle werden heruntergeladen und lokal zwischengespeichert unter: "),bt=i("code"),kl=s("~/.cache/huggingface/hub"),Pl=s(". Dies ist das Standardverzeichnis, das durch die Shell-Umgebungsvariable \u201CTRANSFORMERS_CACHE\u201D vorgegeben ist. Unter Windows wird das Standardverzeichnis durch "),_t=i("code"),zl=s("C:\\Benutzer\\Benutzername\\.cache\\huggingface\\hub"),Tl=s(" angegeben. Sie k\xF6nnen die unten aufgef\xFChrten Shell-Umgebungsvariablen - in der Reihenfolge ihrer Priorit\xE4t - \xE4ndern, um ein anderes Cache-Verzeichnis anzugeben:"),Tr=u(),R=i("ol"),K=i("li"),Al=s("Shell-Umgebungsvariable (Standard): "),$t=i("code"),yl=s("HUGGINGFACE_HUB_CACHE"),Il=s(" oder "),wt=i("code"),Cl=s("TRANSFORMERS_CACHE"),Dl=s("."),Ol=u(),Ne=i("li"),Bl=s("Shell-Umgebungsvariable: "),Et=i("code"),Fl=s("HF_HOME"),Ml=s("."),Hl=u(),Z=i("li"),Ul=s("Shell-Umgebungsvariable: "),St=i("code"),Rl=s("XDG_CACHE_HOME"),jl=s(" + "),kt=i("code"),Ll=s("/huggingface"),Nl=s("."),Ar=u(),c(fe.$$.fragment),yr=u(),J=i("h2"),ue=i("a"),Pt=i("span"),c(xe.$$.fragment),xl=u(),zt=i("span"),Vl=s("Offline Modus"),Ir=u(),de=i("p"),ql=s("Transformers ist in der Lage, in einer Firewall- oder Offline-Umgebung zu laufen, indem es nur lokale Dateien verwendet. Setzen Sie die Umgebungsvariable "),Tt=i("code"),Wl=s("TRANSFORMERS_OFFLINE=1"),Gl=s(", um dieses Verhalten zu aktivieren."),Cr=u(),c(he.$$.fragment),Dr=u(),Hn=i("p"),Kl=s("So w\xFCrden Sie beispielsweise ein Programm in einem normalen Netzwerk mit einer Firewall f\xFCr externe Instanzen mit dem folgenden Befehl ausf\xFChren:"),Or=u(),c(Ve.$$.fragment),Br=u(),Un=i("p"),Zl=s("F\xFChren Sie das gleiche Programm in einer Offline-Instanz mit aus:"),Fr=u(),c(qe.$$.fragment),Mr=u(),Rn=i("p"),Jl=s("Das Skript sollte nun laufen, ohne sich aufzuh\xE4ngen oder eine Zeit\xFCberschreitung abzuwarten, da es wei\xDF, dass es nur nach lokalen Dateien suchen soll."),Hr=u(),Q=i("h3"),pe=i("a"),At=i("span"),c(We.$$.fragment),Ql=u(),yt=i("span"),Yl=s("Abrufen von Modellen und Tokenizern zur Offline-Verwendung"),Ur=u(),jn=i("p"),Xl=s("Eine andere M\xF6glichkeit, \u{1F917} Transformers offline zu verwenden, besteht darin, die Dateien im Voraus herunterzuladen und dann auf ihren lokalen Pfad zu verweisen, wenn Sie sie offline verwenden m\xFCssen. Es gibt drei M\xF6glichkeiten, dies zu tun:"),Rr=u(),j=i("ul"),Ge=i("li"),Ke=i("p"),ea=s("Laden Sie eine Datei \xFCber die Benutzeroberfl\xE4che des "),Ze=i("a"),na=s("Model Hub"),ta=s(" herunter, indem Sie auf das \u2193-Symbol klicken."),ra=u(),It=i("p"),Ln=i("img"),ia=u(),Je=i("li"),Ct=i("p"),la=s("Verwenden Sie den [PreTrainedModel.from_pretrained] und [PreTrainedModel.save_pretrained] Workflow:"),aa=u(),Y=i("ol"),Qe=i("li"),Ye=i("p"),sa=s("Laden Sie Ihre Dateien im Voraus mit "),Dt=i("code"),oa=s("PreTrainedModel.from_pretrained()"),fa=s(" herunter:"),ua=u(),c(Xe.$$.fragment),da=u(),en=i("li"),nn=i("p"),ha=s("Speichern Sie Ihre Dateien in einem bestimmten Verzeichnis mit "),Ot=i("code"),pa=s("PreTrainedModel.save_pretrained()"),ma=s(":"),ca=u(),c(tn.$$.fragment),ga=u(),rn=i("li"),ln=i("p"),va=s("Wenn Sie nun offline sind, laden Sie Ihre Dateien mit "),Bt=i("code"),ba=s("PreTrainedModel.from_pretrained()"),_a=s(" aus dem bestimmten Verzeichnis:"),$a=u(),c(an.$$.fragment),wa=u(),sn=i("li"),on=i("p"),Ea=s("Programmatisches Herunterladen von Dateien mit der "),fn=i("a"),Sa=s("huggingface_hub"),ka=s(" Bibliothek:"),Pa=u(),un=i("ol"),dn=i("li"),Ft=i("p"),za=s("Installieren Sie die \u201Chuggingface_hub\u201D-Bibliothek in Ihrer virtuellen Umgebung:"),Ta=u(),c(hn.$$.fragment),Aa=u(),pn=i("li"),X=i("p"),ya=s("Verwenden Sie die Funktion "),mn=i("a"),Mt=i("code"),Ia=s("hf_hub_download"),Ca=s(", um eine Datei in einen bestimmten Pfad herunterzuladen. Der folgende Befehl l\xE4dt zum Beispiel die Datei \u201Cconfig.json\u201D aus dem Modell "),cn=i("a"),Da=s("T0"),Oa=s(" in den gew\xFCnschten Pfad herunter:"),Ba=u(),c(gn.$$.fragment),jr=u(),Nn=i("p"),Fa=s("Sobald Ihre Datei heruntergeladen und lokal zwischengespeichert ist, geben Sie den lokalen Pfad an, um sie zu laden und zu verwenden:"),Lr=u(),c(vn.$$.fragment),Nr=u(),c(me.$$.fragment),this.h()},l(e){const r=ho('[data-svelte="svelte-1phssyn"]',document.head);p=l(r,"META",{name:!0,content:!0}),r.forEach(n),z=d(e),m=l(e,"H1",{class:!0});var bn=a(m);S=l(bn,"A",{id:!0,class:!0,href:!0});var Ht=a(S);P=l(Ht,"SPAN",{});var Ut=a(P);g(w.$$.fragment,Ut),Ut.forEach(n),Ht.forEach(n),E=d(bn),T=l(bn,"SPAN",{});var Rt=a(T);y=o(Rt,"Installation"),Rt.forEach(n),bn.forEach(n),A=d(e),D=l(e,"P",{});var ja=a(D);O=o(ja,"Installieren Sie \u{1F917} Transformers f\xFCr die Deep-Learning-Bibliothek, mit der Sie arbeiten, richten Sie Ihren Cache ein und konfigurieren Sie \u{1F917} Transformers optional f\xFCr den Offline-Betrieb."),ja.forEach(n),I=d(e),N=l(e,"P",{});var La=a(N);_n=o(La,"\u{1F917} Transformers wurde unter Python 3.6+, PyTorch 1.1.0+, TensorFlow 2.0+, und Flax getestet. Folgen Sie den Installationsanweisungen unten f\xFCr die von Ihnen verwendete Deep-Learning-Bibliothek:"),La.forEach(n),ge=d(e),F=l(e,"UL",{});var xn=a(F);$n=l(xn,"LI",{});var Ma=a($n);ve=l(Ma,"A",{href:!0,rel:!0});var Na=a(ve);vi=o(Na,"PyTorch"),Na.forEach(n),bi=o(Ma," installation instructions."),Ma.forEach(n),_i=d(xn),wn=l(xn,"LI",{});var Ha=a(wn);be=l(Ha,"A",{href:!0,rel:!0});var xa=a(be);$i=o(xa,"TensorFlow 2.0"),xa.forEach(n),wi=o(Ha," installation instructions."),Ha.forEach(n),Ei=d(xn),En=l(xn,"LI",{});var Ua=a(En);_e=l(Ua,"A",{href:!0,rel:!0});var Va=a(_e);Si=o(Va,"Flax"),Va.forEach(n),ki=o(Ua," installation instructions."),Ua.forEach(n),xn.forEach(n),jt=d(e),x=l(e,"H2",{class:!0});var Vr=a(x);ee=l(Vr,"A",{id:!0,class:!0,href:!0});var qa=a(ee);Xn=l(qa,"SPAN",{});var Wa=a(Xn);g($e.$$.fragment,Wa),Wa.forEach(n),qa.forEach(n),Pi=d(Vr),et=l(Vr,"SPAN",{});var Ga=a(et);zi=o(Ga,"Installation mit pip"),Ga.forEach(n),Vr.forEach(n),Lt=d(e),M=l(e,"P",{});var Vn=a(M);Ti=o(Vn,"Sie sollten \u{1F917} Transformers in einer "),we=l(Vn,"A",{href:!0,rel:!0});var Ka=a(we);Ai=o(Ka,"virtuellen Umgebung"),Ka.forEach(n),yi=o(Vn," installieren. Wenn Sie mit virtuellen Python-Umgebungen nicht vertraut sind, werfen Sie einen Blick auf diese "),Ee=l(Vn,"A",{href:!0,rel:!0});var Za=a(Ee);Ii=o(Za,"Anleitung"),Za.forEach(n),Ci=o(Vn,". Eine virtuelle Umgebung macht es einfacher, verschiedene Projekte zu verwalten und Kompatibilit\xE4tsprobleme zwischen Abh\xE4ngigkeiten zu vermeiden."),Vn.forEach(n),Nt=d(e),Sn=l(e,"P",{});var Ja=a(Sn);Di=o(Ja,"Beginnen wir mit der Erstellung einer virtuellen Umgebung in Ihrem Projektverzeichnis:"),Ja.forEach(n),xt=d(e),g(Se.$$.fragment,e),Vt=d(e),kn=l(e,"P",{});var Qa=a(kn);Oi=o(Qa,"Aktivieren wir die virtuelle Umgebung. Unter Linux und MacOs:"),Qa.forEach(n),qt=d(e),g(ke.$$.fragment,e),Wt=d(e),Pn=l(e,"P",{});var Ya=a(Pn);Bi=o(Ya,"Aktivieren wir die virtuelle Umgebung unter Windows"),Ya.forEach(n),Gt=d(e),g(Pe.$$.fragment,e),Kt=d(e),zn=l(e,"P",{});var Xa=a(zn);Fi=o(Xa,"Jetzt k\xF6nnen wir die \u{1F917} Transformers mit dem folgenden Befehl installieren:"),Xa.forEach(n),Zt=d(e),g(ze.$$.fragment,e),Jt=d(e),Tn=l(e,"P",{});var es=a(Tn);Mi=o(es,"Bei reiner CPU-Unterst\xFCtzung k\xF6nnen wir \u{1F917} Transformers und eine Deep-Learning-Bibliothek bequem in einer Zeile installieren. Installieren wir zum Beispiel \u{1F917} Transformers und PyTorch mit:"),es.forEach(n),Qt=d(e),g(Te.$$.fragment,e),Yt=d(e),An=l(e,"P",{});var ns=a(An);Hi=o(ns,"\u{1F917} Transformers und TensorFlow 2.0:"),ns.forEach(n),Xt=d(e),g(Ae.$$.fragment,e),er=d(e),yn=l(e,"P",{});var ts=a(yn);Ui=o(ts,"\u{1F917} Transformers und Flax:"),ts.forEach(n),nr=d(e),g(ye.$$.fragment,e),tr=d(e),In=l(e,"P",{});var rs=a(In);Ri=o(rs,"\xDCberpr\xFCfen wir abschlie\xDFend, ob \u{1F917} Transformers ordnungsgem\xE4\xDF installiert wurde, indem wir den folgenden Befehl ausf\xFChren. Es wird ein vortrainiertes Modell heruntergeladen:"),rs.forEach(n),rr=d(e),g(Ie.$$.fragment,e),ir=d(e),Cn=l(e,"P",{});var is=a(Cn);ji=o(is,"Dann wird die Kategorie und die Wahrscheinlichkeit ausgegeben:"),is.forEach(n),lr=d(e),g(Ce.$$.fragment,e),ar=d(e),V=l(e,"H2",{class:!0});var qr=a(V);ne=l(qr,"A",{id:!0,class:!0,href:!0});var ls=a(ne);nt=l(ls,"SPAN",{});var as=a(nt);g(De.$$.fragment,as),as.forEach(n),ls.forEach(n),Li=d(qr),tt=l(qr,"SPAN",{});var ss=a(tt);Ni=o(ss,"Installation aus dem Code"),ss.forEach(n),qr.forEach(n),sr=d(e),Dn=l(e,"P",{});var os=a(Dn);xi=o(os,"Installieren wir \u{1F917} Transformers aus dem Quellcode mit dem folgenden Befehl:"),os.forEach(n),or=d(e),g(Oe.$$.fragment,e),fr=d(e),C=l(e,"P",{});var L=a(C);Vi=o(L,"Dieser Befehl installiert die aktuelle "),rt=l(L,"CODE",{});var fs=a(rt);qi=o(fs,"main"),fs.forEach(n),Wi=o(L," Version und nicht die neueste "),it=l(L,"CODE",{});var us=a(it);Gi=o(us,"stable"),us.forEach(n),Ki=o(L," Version. Die "),lt=l(L,"CODE",{});var ds=a(lt);Zi=o(ds,"main"),ds.forEach(n),Ji=o(L,"-Version ist n\xFCtzlich, um mit den neuesten Entwicklungen Schritt zu halten. Zum Beispiel, wenn ein Fehler seit der letzten offiziellen Version behoben wurde, aber eine neue Version noch nicht ver\xF6ffentlicht wurde. Das bedeutet jedoch, dass die \u201CHauptversion\u201D nicht immer stabil ist. Wir bem\xFChen uns, die Hauptversion einsatzbereit zu halten, und die meisten Probleme werden normalerweise innerhalb weniger Stunden oder eines Tages behoben. Wenn Sie auf ein Problem sto\xDFen, \xF6ffnen Sie bitte ein [Issue] ("),Be=l(L,"A",{href:!0,rel:!0});var hs=a(Be);Qi=o(hs,"https://github.com/huggingface/transformers/issues"),hs.forEach(n),Yi=o(L,"), damit wir es noch schneller beheben k\xF6nnen!"),L.forEach(n),ur=d(e),On=l(e,"P",{});var ps=a(On);Xi=o(ps,"\xDCberpr\xFCfen wir, ob \u{1F917} Transformers richtig installiert wurde, indem Sie den folgenden Befehl ausf\xFChren:"),ps.forEach(n),dr=d(e),g(Fe.$$.fragment,e),hr=d(e),q=l(e,"H2",{class:!0});var Wr=a(q);te=l(Wr,"A",{id:!0,class:!0,href:!0});var ms=a(te);at=l(ms,"SPAN",{});var cs=a(at);g(Me.$$.fragment,cs),cs.forEach(n),ms.forEach(n),el=d(Wr),st=l(Wr,"SPAN",{});var gs=a(st);nl=o(gs,"Editierbare Installation"),gs.forEach(n),Wr.forEach(n),pr=d(e),Bn=l(e,"P",{});var vs=a(Bn);tl=o(vs,"Sie ben\xF6tigen eine bearbeitbare Installation, wenn Sie:"),vs.forEach(n),mr=d(e),re=l(e,"UL",{});var Gr=a(re);ot=l(Gr,"LI",{});var bs=a(ot);rl=o(bs,"die \u201CHaupt\u201D-Version des Quellcodes verwenden m\xF6chten."),bs.forEach(n),il=d(Gr),ft=l(Gr,"LI",{});var _s=a(ft);ll=o(_s,"Zu \u{1F917} Transformers beitragen und \xC4nderungen am Code testen wollen."),_s.forEach(n),Gr.forEach(n),cr=d(e),Fn=l(e,"P",{});var $s=a(Fn);al=o($s,"Klonen Sie das Repository und installieren \u{1F917} Transformers mit den folgenden Befehlen:"),$s.forEach(n),gr=d(e),g(He.$$.fragment,e),vr=d(e),H=l(e,"P",{});var qn=a(H);sl=o(qn,"Diese Befehle verkn\xFCpfen den Ordner, in den Sie das Repository geklont haben, mit den Pfaden Ihrer Python-Bibliotheken. Python wird nun in dem Ordner suchen, in den Sie geklont haben, zus\xE4tzlich zu den normalen Bibliothekspfaden. Wenn zum Beispiel Ihre Python-Pakete normalerweise in "),ut=l(qn,"CODE",{});var ws=a(ut);ol=o(ws,"~/anaconda3/envs/main/lib/python3.7/site-packages/"),ws.forEach(n),fl=o(qn," installiert sind, wird Python auch den Ordner durchsuchen, in den Sie geklont haben: "),dt=l(qn,"CODE",{});var Es=a(dt);ul=o(Es,"~/transformers/"),Es.forEach(n),dl=o(qn,"."),qn.forEach(n),br=d(e),g(ie.$$.fragment,e),_r=d(e),Mn=l(e,"P",{});var Ss=a(Mn);hl=o(Ss,"Jetzt k\xF6nnen Sie Ihren Klon mit dem folgenden Befehl ganz einfach auf die neueste Version von \u{1F917} Transformers aktualisieren:"),Ss.forEach(n),$r=d(e),g(Ue.$$.fragment,e),wr=d(e),le=l(e,"P",{});var Kr=a(le);pl=o(Kr,"Ihre Python-Umgebung wird beim n\xE4chsten Ausf\xFChren die "),ht=l(Kr,"CODE",{});var ks=a(ht);ml=o(ks,"main"),ks.forEach(n),cl=o(Kr,"-Version von \u{1F917} Transformers finden."),Kr.forEach(n),Er=d(e),W=l(e,"H2",{class:!0});var Zr=a(W);ae=l(Zr,"A",{id:!0,class:!0,href:!0});var Ps=a(ae);pt=l(Ps,"SPAN",{});var zs=a(pt);g(Re.$$.fragment,zs),zs.forEach(n),Ps.forEach(n),gl=d(Zr),mt=l(Zr,"SPAN",{});var Ts=a(mt);vl=o(Ts,"Installation mit conda"),Ts.forEach(n),Zr.forEach(n),Sr=d(e),se=l(e,"P",{});var Jr=a(se);bl=o(Jr,"Installation von dem conda Kanal "),ct=l(Jr,"CODE",{});var As=a(ct);_l=o(As,"huggingface"),As.forEach(n),$l=o(Jr,":"),Jr.forEach(n),kr=d(e),g(je.$$.fragment,e),Pr=d(e),G=l(e,"H2",{class:!0});var Qr=a(G);oe=l(Qr,"A",{id:!0,class:!0,href:!0});var ys=a(oe);gt=l(ys,"SPAN",{});var Is=a(gt);g(Le.$$.fragment,Is),Is.forEach(n),ys.forEach(n),wl=d(Qr),vt=l(Qr,"SPAN",{});var Cs=a(vt);El=o(Cs,"Cache Einrichtung"),Cs.forEach(n),Qr.forEach(n),zr=d(e),U=l(e,"P",{});var Wn=a(U);Sl=o(Wn,"Vorgefertigte Modelle werden heruntergeladen und lokal zwischengespeichert unter: "),bt=l(Wn,"CODE",{});var Ds=a(bt);kl=o(Ds,"~/.cache/huggingface/hub"),Ds.forEach(n),Pl=o(Wn,". Dies ist das Standardverzeichnis, das durch die Shell-Umgebungsvariable \u201CTRANSFORMERS_CACHE\u201D vorgegeben ist. Unter Windows wird das Standardverzeichnis durch "),_t=l(Wn,"CODE",{});var Os=a(_t);zl=o(Os,"C:\\Benutzer\\Benutzername\\.cache\\huggingface\\hub"),Os.forEach(n),Tl=o(Wn," angegeben. Sie k\xF6nnen die unten aufgef\xFChrten Shell-Umgebungsvariablen - in der Reihenfolge ihrer Priorit\xE4t - \xE4ndern, um ein anderes Cache-Verzeichnis anzugeben:"),Wn.forEach(n),Tr=d(e),R=l(e,"OL",{});var Gn=a(R);K=l(Gn,"LI",{});var Kn=a(K);Al=o(Kn,"Shell-Umgebungsvariable (Standard): "),$t=l(Kn,"CODE",{});var Bs=a($t);yl=o(Bs,"HUGGINGFACE_HUB_CACHE"),Bs.forEach(n),Il=o(Kn," oder "),wt=l(Kn,"CODE",{});var Fs=a(wt);Cl=o(Fs,"TRANSFORMERS_CACHE"),Fs.forEach(n),Dl=o(Kn,"."),Kn.forEach(n),Ol=d(Gn),Ne=l(Gn,"LI",{});var Yr=a(Ne);Bl=o(Yr,"Shell-Umgebungsvariable: "),Et=l(Yr,"CODE",{});var Ms=a(Et);Fl=o(Ms,"HF_HOME"),Ms.forEach(n),Ml=o(Yr,"."),Yr.forEach(n),Hl=d(Gn),Z=l(Gn,"LI",{});var Zn=a(Z);Ul=o(Zn,"Shell-Umgebungsvariable: "),St=l(Zn,"CODE",{});var Hs=a(St);Rl=o(Hs,"XDG_CACHE_HOME"),Hs.forEach(n),jl=o(Zn," + "),kt=l(Zn,"CODE",{});var Us=a(kt);Ll=o(Us,"/huggingface"),Us.forEach(n),Nl=o(Zn,"."),Zn.forEach(n),Gn.forEach(n),Ar=d(e),g(fe.$$.fragment,e),yr=d(e),J=l(e,"H2",{class:!0});var Xr=a(J);ue=l(Xr,"A",{id:!0,class:!0,href:!0});var Rs=a(ue);Pt=l(Rs,"SPAN",{});var js=a(Pt);g(xe.$$.fragment,js),js.forEach(n),Rs.forEach(n),xl=d(Xr),zt=l(Xr,"SPAN",{});var Ls=a(zt);Vl=o(Ls,"Offline Modus"),Ls.forEach(n),Xr.forEach(n),Ir=d(e),de=l(e,"P",{});var ei=a(de);ql=o(ei,"Transformers ist in der Lage, in einer Firewall- oder Offline-Umgebung zu laufen, indem es nur lokale Dateien verwendet. Setzen Sie die Umgebungsvariable "),Tt=l(ei,"CODE",{});var Ns=a(Tt);Wl=o(Ns,"TRANSFORMERS_OFFLINE=1"),Ns.forEach(n),Gl=o(ei,", um dieses Verhalten zu aktivieren."),ei.forEach(n),Cr=d(e),g(he.$$.fragment,e),Dr=d(e),Hn=l(e,"P",{});var xs=a(Hn);Kl=o(xs,"So w\xFCrden Sie beispielsweise ein Programm in einem normalen Netzwerk mit einer Firewall f\xFCr externe Instanzen mit dem folgenden Befehl ausf\xFChren:"),xs.forEach(n),Or=d(e),g(Ve.$$.fragment,e),Br=d(e),Un=l(e,"P",{});var Vs=a(Un);Zl=o(Vs,"F\xFChren Sie das gleiche Programm in einer Offline-Instanz mit aus:"),Vs.forEach(n),Fr=d(e),g(qe.$$.fragment,e),Mr=d(e),Rn=l(e,"P",{});var qs=a(Rn);Jl=o(qs,"Das Skript sollte nun laufen, ohne sich aufzuh\xE4ngen oder eine Zeit\xFCberschreitung abzuwarten, da es wei\xDF, dass es nur nach lokalen Dateien suchen soll."),qs.forEach(n),Hr=d(e),Q=l(e,"H3",{class:!0});var ni=a(Q);pe=l(ni,"A",{id:!0,class:!0,href:!0});var Ws=a(pe);At=l(Ws,"SPAN",{});var Gs=a(At);g(We.$$.fragment,Gs),Gs.forEach(n),Ws.forEach(n),Ql=d(ni),yt=l(ni,"SPAN",{});var Ks=a(yt);Yl=o(Ks,"Abrufen von Modellen und Tokenizern zur Offline-Verwendung"),Ks.forEach(n),ni.forEach(n),Ur=d(e),jn=l(e,"P",{});var Zs=a(jn);Xl=o(Zs,"Eine andere M\xF6glichkeit, \u{1F917} Transformers offline zu verwenden, besteht darin, die Dateien im Voraus herunterzuladen und dann auf ihren lokalen Pfad zu verweisen, wenn Sie sie offline verwenden m\xFCssen. Es gibt drei M\xF6glichkeiten, dies zu tun:"),Zs.forEach(n),Rr=d(e),j=l(e,"UL",{});var Jn=a(j);Ge=l(Jn,"LI",{});var ti=a(Ge);Ke=l(ti,"P",{});var ri=a(Ke);ea=o(ri,"Laden Sie eine Datei \xFCber die Benutzeroberfl\xE4che des "),Ze=l(ri,"A",{href:!0,rel:!0});var Js=a(Ze);na=o(Js,"Model Hub"),Js.forEach(n),ta=o(ri," herunter, indem Sie auf das \u2193-Symbol klicken."),ri.forEach(n),ra=d(ti),It=l(ti,"P",{});var Qs=a(It);Ln=l(Qs,"IMG",{src:!0,alt:!0}),Qs.forEach(n),ti.forEach(n),ia=d(Jn),Je=l(Jn,"LI",{});var ii=a(Je);Ct=l(ii,"P",{});var Ys=a(Ct);la=o(Ys,"Verwenden Sie den [PreTrainedModel.from_pretrained] und [PreTrainedModel.save_pretrained] Workflow:"),Ys.forEach(n),aa=d(ii),Y=l(ii,"OL",{});var Qn=a(Y);Qe=l(Qn,"LI",{});var li=a(Qe);Ye=l(li,"P",{});var ai=a(Ye);sa=o(ai,"Laden Sie Ihre Dateien im Voraus mit "),Dt=l(ai,"CODE",{});var Xs=a(Dt);oa=o(Xs,"PreTrainedModel.from_pretrained()"),Xs.forEach(n),fa=o(ai," herunter:"),ai.forEach(n),ua=d(li),g(Xe.$$.fragment,li),li.forEach(n),da=d(Qn),en=l(Qn,"LI",{});var si=a(en);nn=l(si,"P",{});var oi=a(nn);ha=o(oi,"Speichern Sie Ihre Dateien in einem bestimmten Verzeichnis mit "),Ot=l(oi,"CODE",{});var eo=a(Ot);pa=o(eo,"PreTrainedModel.save_pretrained()"),eo.forEach(n),ma=o(oi,":"),oi.forEach(n),ca=d(si),g(tn.$$.fragment,si),si.forEach(n),ga=d(Qn),rn=l(Qn,"LI",{});var fi=a(rn);ln=l(fi,"P",{});var ui=a(ln);va=o(ui,"Wenn Sie nun offline sind, laden Sie Ihre Dateien mit "),Bt=l(ui,"CODE",{});var no=a(Bt);ba=o(no,"PreTrainedModel.from_pretrained()"),no.forEach(n),_a=o(ui," aus dem bestimmten Verzeichnis:"),ui.forEach(n),$a=d(fi),g(an.$$.fragment,fi),fi.forEach(n),Qn.forEach(n),ii.forEach(n),wa=d(Jn),sn=l(Jn,"LI",{});var di=a(sn);on=l(di,"P",{});var hi=a(on);Ea=o(hi,"Programmatisches Herunterladen von Dateien mit der "),fn=l(hi,"A",{href:!0,rel:!0});var to=a(fn);Sa=o(to,"huggingface_hub"),to.forEach(n),ka=o(hi," Bibliothek:"),hi.forEach(n),Pa=d(di),un=l(di,"OL",{});var pi=a(un);dn=l(pi,"LI",{});var mi=a(dn);Ft=l(mi,"P",{});var ro=a(Ft);za=o(ro,"Installieren Sie die \u201Chuggingface_hub\u201D-Bibliothek in Ihrer virtuellen Umgebung:"),ro.forEach(n),Ta=d(mi),g(hn.$$.fragment,mi),mi.forEach(n),Aa=d(pi),pn=l(pi,"LI",{});var ci=a(pn);X=l(ci,"P",{});var Yn=a(X);ya=o(Yn,"Verwenden Sie die Funktion "),mn=l(Yn,"A",{href:!0,rel:!0});var io=a(mn);Mt=l(io,"CODE",{});var lo=a(Mt);Ia=o(lo,"hf_hub_download"),lo.forEach(n),io.forEach(n),Ca=o(Yn,", um eine Datei in einen bestimmten Pfad herunterzuladen. Der folgende Befehl l\xE4dt zum Beispiel die Datei \u201Cconfig.json\u201D aus dem Modell "),cn=l(Yn,"A",{href:!0,rel:!0});var ao=a(cn);Da=o(ao,"T0"),ao.forEach(n),Oa=o(Yn," in den gew\xFCnschten Pfad herunter:"),Yn.forEach(n),Ba=d(ci),g(gn.$$.fragment,ci),ci.forEach(n),pi.forEach(n),di.forEach(n),Jn.forEach(n),jr=d(e),Nn=l(e,"P",{});var so=a(Nn);Fa=o(so,"Sobald Ihre Datei heruntergeladen und lokal zwischengespeichert ist, geben Sie den lokalen Pfad an, um sie zu laden und zu verwenden:"),so.forEach(n),Lr=d(e),g(vn.$$.fragment,e),Nr=d(e),g(me.$$.fragment,e),this.h()},h(){h(p,"name","hf:doc:metadata"),h(p,"content",JSON.stringify($o)),h(S,"id","installation"),h(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(S,"href","#installation"),h(m,"class","relative group"),h(ve,"href","https://pytorch.org/get-started/locally/"),h(ve,"rel","nofollow"),h(be,"href","https://www.tensorflow.org/install/pip"),h(be,"rel","nofollow"),h(_e,"href","https://flax.readthedocs.io/en/latest/"),h(_e,"rel","nofollow"),h(ee,"id","installation-mit-pip"),h(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ee,"href","#installation-mit-pip"),h(x,"class","relative group"),h(we,"href","https://docs.python.org/3/library/venv.html"),h(we,"rel","nofollow"),h(Ee,"href","https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/"),h(Ee,"rel","nofollow"),h(ne,"id","installation-aus-dem-code"),h(ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ne,"href","#installation-aus-dem-code"),h(V,"class","relative group"),h(Be,"href","https://github.com/huggingface/transformers/issues"),h(Be,"rel","nofollow"),h(te,"id","editierbare-installation"),h(te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(te,"href","#editierbare-installation"),h(q,"class","relative group"),h(ae,"id","installation-mit-conda"),h(ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ae,"href","#installation-mit-conda"),h(W,"class","relative group"),h(oe,"id","cache-einrichtung"),h(oe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(oe,"href","#cache-einrichtung"),h(G,"class","relative group"),h(ue,"id","offline-modus"),h(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ue,"href","#offline-modus"),h(J,"class","relative group"),h(pe,"id","abrufen-von-modellen-und-tokenizern-zur-offlineverwendung"),h(pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(pe,"href","#abrufen-von-modellen-und-tokenizern-zur-offlineverwendung"),h(Q,"class","relative group"),h(Ze,"href","https://huggingface.co/models"),h(Ze,"rel","nofollow"),po(Ln.src,Ra="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/download-icon.png")||h(Ln,"src",Ra),h(Ln,"alt","download-icon"),h(fn,"href","https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub"),h(fn,"rel","nofollow"),h(mn,"href","https://huggingface.co/docs/hub/adding-a-library#download-files-from-the-hub"),h(mn,"rel","nofollow"),h(cn,"href","https://huggingface.co/bigscience/T0_3B"),h(cn,"rel","nofollow")},m(e,r){t(document.head,p),f(e,z,r),f(e,m,r),t(m,S),t(S,P),v(w,P,null),t(m,E),t(m,T),t(T,y),f(e,A,r),f(e,D,r),t(D,O),f(e,I,r),f(e,N,r),t(N,_n),f(e,ge,r),f(e,F,r),t(F,$n),t($n,ve),t(ve,vi),t($n,bi),t(F,_i),t(F,wn),t(wn,be),t(be,$i),t(wn,wi),t(F,Ei),t(F,En),t(En,_e),t(_e,Si),t(En,ki),f(e,jt,r),f(e,x,r),t(x,ee),t(ee,Xn),v($e,Xn,null),t(x,Pi),t(x,et),t(et,zi),f(e,Lt,r),f(e,M,r),t(M,Ti),t(M,we),t(we,Ai),t(M,yi),t(M,Ee),t(Ee,Ii),t(M,Ci),f(e,Nt,r),f(e,Sn,r),t(Sn,Di),f(e,xt,r),v(Se,e,r),f(e,Vt,r),f(e,kn,r),t(kn,Oi),f(e,qt,r),v(ke,e,r),f(e,Wt,r),f(e,Pn,r),t(Pn,Bi),f(e,Gt,r),v(Pe,e,r),f(e,Kt,r),f(e,zn,r),t(zn,Fi),f(e,Zt,r),v(ze,e,r),f(e,Jt,r),f(e,Tn,r),t(Tn,Mi),f(e,Qt,r),v(Te,e,r),f(e,Yt,r),f(e,An,r),t(An,Hi),f(e,Xt,r),v(Ae,e,r),f(e,er,r),f(e,yn,r),t(yn,Ui),f(e,nr,r),v(ye,e,r),f(e,tr,r),f(e,In,r),t(In,Ri),f(e,rr,r),v(Ie,e,r),f(e,ir,r),f(e,Cn,r),t(Cn,ji),f(e,lr,r),v(Ce,e,r),f(e,ar,r),f(e,V,r),t(V,ne),t(ne,nt),v(De,nt,null),t(V,Li),t(V,tt),t(tt,Ni),f(e,sr,r),f(e,Dn,r),t(Dn,xi),f(e,or,r),v(Oe,e,r),f(e,fr,r),f(e,C,r),t(C,Vi),t(C,rt),t(rt,qi),t(C,Wi),t(C,it),t(it,Gi),t(C,Ki),t(C,lt),t(lt,Zi),t(C,Ji),t(C,Be),t(Be,Qi),t(C,Yi),f(e,ur,r),f(e,On,r),t(On,Xi),f(e,dr,r),v(Fe,e,r),f(e,hr,r),f(e,q,r),t(q,te),t(te,at),v(Me,at,null),t(q,el),t(q,st),t(st,nl),f(e,pr,r),f(e,Bn,r),t(Bn,tl),f(e,mr,r),f(e,re,r),t(re,ot),t(ot,rl),t(re,il),t(re,ft),t(ft,ll),f(e,cr,r),f(e,Fn,r),t(Fn,al),f(e,gr,r),v(He,e,r),f(e,vr,r),f(e,H,r),t(H,sl),t(H,ut),t(ut,ol),t(H,fl),t(H,dt),t(dt,ul),t(H,dl),f(e,br,r),v(ie,e,r),f(e,_r,r),f(e,Mn,r),t(Mn,hl),f(e,$r,r),v(Ue,e,r),f(e,wr,r),f(e,le,r),t(le,pl),t(le,ht),t(ht,ml),t(le,cl),f(e,Er,r),f(e,W,r),t(W,ae),t(ae,pt),v(Re,pt,null),t(W,gl),t(W,mt),t(mt,vl),f(e,Sr,r),f(e,se,r),t(se,bl),t(se,ct),t(ct,_l),t(se,$l),f(e,kr,r),v(je,e,r),f(e,Pr,r),f(e,G,r),t(G,oe),t(oe,gt),v(Le,gt,null),t(G,wl),t(G,vt),t(vt,El),f(e,zr,r),f(e,U,r),t(U,Sl),t(U,bt),t(bt,kl),t(U,Pl),t(U,_t),t(_t,zl),t(U,Tl),f(e,Tr,r),f(e,R,r),t(R,K),t(K,Al),t(K,$t),t($t,yl),t(K,Il),t(K,wt),t(wt,Cl),t(K,Dl),t(R,Ol),t(R,Ne),t(Ne,Bl),t(Ne,Et),t(Et,Fl),t(Ne,Ml),t(R,Hl),t(R,Z),t(Z,Ul),t(Z,St),t(St,Rl),t(Z,jl),t(Z,kt),t(kt,Ll),t(Z,Nl),f(e,Ar,r),v(fe,e,r),f(e,yr,r),f(e,J,r),t(J,ue),t(ue,Pt),v(xe,Pt,null),t(J,xl),t(J,zt),t(zt,Vl),f(e,Ir,r),f(e,de,r),t(de,ql),t(de,Tt),t(Tt,Wl),t(de,Gl),f(e,Cr,r),v(he,e,r),f(e,Dr,r),f(e,Hn,r),t(Hn,Kl),f(e,Or,r),v(Ve,e,r),f(e,Br,r),f(e,Un,r),t(Un,Zl),f(e,Fr,r),v(qe,e,r),f(e,Mr,r),f(e,Rn,r),t(Rn,Jl),f(e,Hr,r),f(e,Q,r),t(Q,pe),t(pe,At),v(We,At,null),t(Q,Ql),t(Q,yt),t(yt,Yl),f(e,Ur,r),f(e,jn,r),t(jn,Xl),f(e,Rr,r),f(e,j,r),t(j,Ge),t(Ge,Ke),t(Ke,ea),t(Ke,Ze),t(Ze,na),t(Ke,ta),t(Ge,ra),t(Ge,It),t(It,Ln),t(j,ia),t(j,Je),t(Je,Ct),t(Ct,la),t(Je,aa),t(Je,Y),t(Y,Qe),t(Qe,Ye),t(Ye,sa),t(Ye,Dt),t(Dt,oa),t(Ye,fa),t(Qe,ua),v(Xe,Qe,null),t(Y,da),t(Y,en),t(en,nn),t(nn,ha),t(nn,Ot),t(Ot,pa),t(nn,ma),t(en,ca),v(tn,en,null),t(Y,ga),t(Y,rn),t(rn,ln),t(ln,va),t(ln,Bt),t(Bt,ba),t(ln,_a),t(rn,$a),v(an,rn,null),t(j,wa),t(j,sn),t(sn,on),t(on,Ea),t(on,fn),t(fn,Sa),t(on,ka),t(sn,Pa),t(sn,un),t(un,dn),t(dn,Ft),t(Ft,za),t(dn,Ta),v(hn,dn,null),t(un,Aa),t(un,pn),t(pn,X),t(X,ya),t(X,mn),t(mn,Mt),t(Mt,Ia),t(X,Ca),t(X,cn),t(cn,Da),t(X,Oa),t(pn,Ba),v(gn,pn,null),f(e,jr,r),f(e,Nn,r),t(Nn,Fa),f(e,Lr,r),v(vn,e,r),f(e,Nr,r),v(me,e,r),xr=!0},p(e,[r]){const bn={};r&2&&(bn.$$scope={dirty:r,ctx:e}),ie.$set(bn);const Ht={};r&2&&(Ht.$$scope={dirty:r,ctx:e}),fe.$set(Ht);const Ut={};r&2&&(Ut.$$scope={dirty:r,ctx:e}),he.$set(Ut);const Rt={};r&2&&(Rt.$$scope={dirty:r,ctx:e}),me.$set(Rt)},i(e){xr||(b(w.$$.fragment,e),b($e.$$.fragment,e),b(Se.$$.fragment,e),b(ke.$$.fragment,e),b(Pe.$$.fragment,e),b(ze.$$.fragment,e),b(Te.$$.fragment,e),b(Ae.$$.fragment,e),b(ye.$$.fragment,e),b(Ie.$$.fragment,e),b(Ce.$$.fragment,e),b(De.$$.fragment,e),b(Oe.$$.fragment,e),b(Fe.$$.fragment,e),b(Me.$$.fragment,e),b(He.$$.fragment,e),b(ie.$$.fragment,e),b(Ue.$$.fragment,e),b(Re.$$.fragment,e),b(je.$$.fragment,e),b(Le.$$.fragment,e),b(fe.$$.fragment,e),b(xe.$$.fragment,e),b(he.$$.fragment,e),b(Ve.$$.fragment,e),b(qe.$$.fragment,e),b(We.$$.fragment,e),b(Xe.$$.fragment,e),b(tn.$$.fragment,e),b(an.$$.fragment,e),b(hn.$$.fragment,e),b(gn.$$.fragment,e),b(vn.$$.fragment,e),b(me.$$.fragment,e),xr=!0)},o(e){_(w.$$.fragment,e),_($e.$$.fragment,e),_(Se.$$.fragment,e),_(ke.$$.fragment,e),_(Pe.$$.fragment,e),_(ze.$$.fragment,e),_(Te.$$.fragment,e),_(Ae.$$.fragment,e),_(ye.$$.fragment,e),_(Ie.$$.fragment,e),_(Ce.$$.fragment,e),_(De.$$.fragment,e),_(Oe.$$.fragment,e),_(Fe.$$.fragment,e),_(Me.$$.fragment,e),_(He.$$.fragment,e),_(ie.$$.fragment,e),_(Ue.$$.fragment,e),_(Re.$$.fragment,e),_(je.$$.fragment,e),_(Le.$$.fragment,e),_(fe.$$.fragment,e),_(xe.$$.fragment,e),_(he.$$.fragment,e),_(Ve.$$.fragment,e),_(qe.$$.fragment,e),_(We.$$.fragment,e),_(Xe.$$.fragment,e),_(tn.$$.fragment,e),_(an.$$.fragment,e),_(hn.$$.fragment,e),_(gn.$$.fragment,e),_(vn.$$.fragment,e),_(me.$$.fragment,e),xr=!1},d(e){n(p),e&&n(z),e&&n(m),$(w),e&&n(A),e&&n(D),e&&n(I),e&&n(N),e&&n(ge),e&&n(F),e&&n(jt),e&&n(x),$($e),e&&n(Lt),e&&n(M),e&&n(Nt),e&&n(Sn),e&&n(xt),$(Se,e),e&&n(Vt),e&&n(kn),e&&n(qt),$(ke,e),e&&n(Wt),e&&n(Pn),e&&n(Gt),$(Pe,e),e&&n(Kt),e&&n(zn),e&&n(Zt),$(ze,e),e&&n(Jt),e&&n(Tn),e&&n(Qt),$(Te,e),e&&n(Yt),e&&n(An),e&&n(Xt),$(Ae,e),e&&n(er),e&&n(yn),e&&n(nr),$(ye,e),e&&n(tr),e&&n(In),e&&n(rr),$(Ie,e),e&&n(ir),e&&n(Cn),e&&n(lr),$(Ce,e),e&&n(ar),e&&n(V),$(De),e&&n(sr),e&&n(Dn),e&&n(or),$(Oe,e),e&&n(fr),e&&n(C),e&&n(ur),e&&n(On),e&&n(dr),$(Fe,e),e&&n(hr),e&&n(q),$(Me),e&&n(pr),e&&n(Bn),e&&n(mr),e&&n(re),e&&n(cr),e&&n(Fn),e&&n(gr),$(He,e),e&&n(vr),e&&n(H),e&&n(br),$(ie,e),e&&n(_r),e&&n(Mn),e&&n($r),$(Ue,e),e&&n(wr),e&&n(le),e&&n(Er),e&&n(W),$(Re),e&&n(Sr),e&&n(se),e&&n(kr),$(je,e),e&&n(Pr),e&&n(G),$(Le),e&&n(zr),e&&n(U),e&&n(Tr),e&&n(R),e&&n(Ar),$(fe,e),e&&n(yr),e&&n(J),$(xe),e&&n(Ir),e&&n(de),e&&n(Cr),$(he,e),e&&n(Dr),e&&n(Hn),e&&n(Or),$(Ve,e),e&&n(Br),e&&n(Un),e&&n(Fr),$(qe,e),e&&n(Mr),e&&n(Rn),e&&n(Hr),e&&n(Q),$(We),e&&n(Ur),e&&n(jn),e&&n(Rr),e&&n(j),$(Xe),$(tn),$(an),$(hn),$(gn),e&&n(jr),e&&n(Nn),e&&n(Lr),$(vn,e),e&&n(Nr),$(me,e)}}}const $o={local:"installation",sections:[{local:"installation-mit-pip",title:"Installation mit pip"},{local:"installation-aus-dem-code",title:"Installation aus dem Code"},{local:"editierbare-installation",title:"Editierbare Installation"},{local:"installation-mit-conda",title:"Installation mit conda"},{local:"cache-einrichtung",title:"Cache Einrichtung"},{local:"offline-modus",sections:[{local:"abrufen-von-modellen-und-tokenizern-zur-offlineverwendung",title:"Abrufen von Modellen und Tokenizern zur Offline-Verwendung"}],title:"Offline Modus"}],title:"Installation"};function wo(B){return mo(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Po extends oo{constructor(p){super();fo(this,p,wo,_o,uo,{})}}export{Po as default,$o as metadata};
