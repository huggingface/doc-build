import{S as ol,i as pl,s as hl,e as r,k as f,w as m,t as n,M as fl,c as i,d as s,m as c,a as o,x as u,h as l,b as h,N as cl,G as a,g as p,y as d,q as g,o as v,B as j,v as ml}from"../chunks/vendor-hf-doc-builder.js";import{T as ul}from"../chunks/Tip-hf-doc-builder.js";import{I as ls}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as y}from"../chunks/CodeBlock-hf-doc-builder.js";function dl(_s){let k,N,$,b,F;return{c(){k=r("p"),N=n("Take a look at the "),$=r("a"),b=n("pipeline()"),F=n(" documentation for a complete list of supported tasks and available parameters."),this.h()},l(w){k=i(w,"P",{});var P=o(k);N=l(P,"Take a look at the "),$=i(P,"A",{href:!0});var H=o($);b=l(H,"pipeline()"),H.forEach(s),F=l(P," documentation for a complete list of supported tasks and available parameters."),P.forEach(s),this.h()},h(){h($,"href","/docs/transformers/v4.22.2/en/main_classes/pipelines#transformers.pipeline")},m(w,P){p(w,k,P),a(k,N),a(k,$),a($,b),a(k,F)},d(w){w&&s(k)}}}function gl(_s){let k,N,$,b,F,w,P,H,ya,xs,E,ba,Pe,Ea,qa,ae,Aa,Pa,Te,Ta,Sa,ws,T,te,Ma,Se,Fa,za,Ca,rs,La,Ia,ne,Da,Me,Na,Ha,ys,R,bs,z,U,is,le,Ra,os,Ua,Es,q,Oa,Fe,Ka,Va,ze,Wa,Ga,Ce,Ba,Qa,qs,Le,re,Ja,Ie,Xa,Ya,As,ie,Ps,oe,pe,Za,De,et,st,Ts,he,Ss,Ne,at,Ms,fe,Fs,x,tt,He,nt,lt,ps,rt,it,Re,ot,pt,hs,ht,ft,zs,ce,Cs,C,O,fs,me,ct,cs,mt,Ls,_,ut,Ue,dt,gt,ue,vt,jt,ms,kt,$t,Oe,_t,xt,Ke,wt,yt,Is,de,Ds,K,bt,Ve,Et,qt,Ns,ge,Hs,V,At,We,Pt,Tt,Rs,ve,Us,L,W,us,je,St,ds,Mt,Os,G,Ft,Ge,zt,Ct,Ks,Be,Lt,Vs,ke,Ws,S,It,$e,Dt,Nt,Qe,Ht,Rt,Gs,_e,Bs,B,Ut,Je,Ot,Kt,Qs,xe,Js,I,Q,gs,we,Vt,vs,Wt,Xs,J,Gt,Xe,Bt,Qt,Ys,Ye,Jt,Zs,Ze,es,rn,ea,ye,sa,D,X,js,be,Xt,ks,Yt,aa,Y,Zt,ss,en,sn,ta,as,an,na,Ee,la,Z,tn,$s,nn,ln,ra,qe,ia;return w=new ls({}),R=new ul({props:{$$slots:{default:[dl]},$$scope:{ctx:_s}}}),le=new ls({}),ie=new y({props:{code:`from transformers import pipeline

generator = pipeline(task="text-generation")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>generator = pipeline(task=<span class="hljs-string">&quot;text-generation&quot;</span>)`}}),he=new y({props:{code:`generator(
    "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone"
)  # doctest: +SKIP`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>
<span class="hljs-meta">... </span>)  <span class="hljs-comment"># doctest: +SKIP</span>
[{<span class="hljs-string">&#x27;generated_text&#x27;</span>: <span class="hljs-string">&#x27;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone, Seven for the Iron-priests at the door to the east, and thirteen for the Lord Kings at the end of the mountain&#x27;</span>}]`}}),fe=new y({props:{code:`generator(
    [
        "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone",
        "Nine for Mortal Men, doomed to die, One for the Dark Lord on his dark throne",
    ]
)  # doctest: +SKIP`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(
<span class="hljs-meta">... </span>    [
<span class="hljs-meta">... </span>        <span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>,
<span class="hljs-meta">... </span>        <span class="hljs-string">&quot;Nine for Mortal Men, doomed to die, One for the Dark Lord on his dark throne&quot;</span>,
<span class="hljs-meta">... </span>    ]
<span class="hljs-meta">... </span>)  <span class="hljs-comment"># doctest: +SKIP</span>`}}),ce=new y({props:{code:`generator(
    "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone",
    num_return_sequences=2,
)  # doctest: +SKIP`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>,
<span class="hljs-meta">... </span>    num_return_sequences=<span class="hljs-number">2</span>,
<span class="hljs-meta">... </span>)  <span class="hljs-comment"># doctest: +SKIP</span>`}}),me=new ls({}),de=new y({props:{code:`from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained("distilgpt2")
model = AutoModelForCausalLM.from_pretrained("distilgpt2")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilgpt2&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;distilgpt2&quot;</span>)`}}),ge=new y({props:{code:`from transformers import pipeline

generator = pipeline(task="text-generation", model=model, tokenizer=tokenizer)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>generator = pipeline(task=<span class="hljs-string">&quot;text-generation&quot;</span>, model=model, tokenizer=tokenizer)`}}),ve=new y({props:{code:`generator(
    "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone"
)  # doctest: +SKIP`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>
<span class="hljs-meta">... </span>)  <span class="hljs-comment"># doctest: +SKIP</span>
[{<span class="hljs-string">&#x27;generated_text&#x27;</span>: <span class="hljs-string">&#x27;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone, Seven for the Dragon-lords (for them to rule in a world ruled by their rulers, and all who live within the realm&#x27;</span>}]`}}),je=new ls({}),ke=new y({props:{code:`from datasets import load_dataset
import torch

torch.manual_seed(42)
ds = load_dataset("hf-internal-testing/librispeech_asr_demo", "clean", split="validation")
audio_file = ds[0]["audio"]["path"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>torch.manual_seed(<span class="hljs-number">42</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_dataset(<span class="hljs-string">&quot;hf-internal-testing/librispeech_asr_demo&quot;</span>, <span class="hljs-string">&quot;clean&quot;</span>, split=<span class="hljs-string">&quot;validation&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>audio_file = ds[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>][<span class="hljs-string">&quot;path&quot;</span>]`}}),_e=new y({props:{code:`from transformers import pipeline

audio_classifier = pipeline(
    task="audio-classification", model="ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>audio_classifier = pipeline(
<span class="hljs-meta">... </span>    task=<span class="hljs-string">&quot;audio-classification&quot;</span>, model=<span class="hljs-string">&quot;ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition&quot;</span>
<span class="hljs-meta">... </span>)`}}),xe=new y({props:{code:`preds = audio_classifier(audio_file)
preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
preds`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>preds = audio_classifier(audio_file)
<span class="hljs-meta">&gt;&gt;&gt; </span>preds = [{<span class="hljs-string">&quot;score&quot;</span>: <span class="hljs-built_in">round</span>(pred[<span class="hljs-string">&quot;score&quot;</span>], <span class="hljs-number">4</span>), <span class="hljs-string">&quot;label&quot;</span>: pred[<span class="hljs-string">&quot;label&quot;</span>]} <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> preds]
<span class="hljs-meta">&gt;&gt;&gt; </span>preds
[{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1315</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;calm&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1307</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;neutral&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1274</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;sad&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1261</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;fearful&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1242</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;happy&#x27;</span>}]`}}),we=new ls({}),ye=new y({props:{code:`from transformers import pipeline

vision_classifier = pipeline(task="image-classification")
preds = vision_classifier(
    images="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
)
preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
preds`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>vision_classifier = pipeline(task=<span class="hljs-string">&quot;image-classification&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>preds = vision_classifier(
<span class="hljs-meta">... </span>    images=<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg&quot;</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>preds = [{<span class="hljs-string">&quot;score&quot;</span>: <span class="hljs-built_in">round</span>(pred[<span class="hljs-string">&quot;score&quot;</span>], <span class="hljs-number">4</span>), <span class="hljs-string">&quot;label&quot;</span>: pred[<span class="hljs-string">&quot;label&quot;</span>]} <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> preds]
<span class="hljs-meta">&gt;&gt;&gt; </span>preds
[{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.4335</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;lynx, catamount&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0348</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;cougar, puma, catamount, mountain lion, painter, panther, Felis concolor&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0324</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;snow leopard, ounce, Panthera uncia&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0239</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;Egyptian cat&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0229</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;tiger cat&#x27;</span>}]`}}),be=new ls({}),Ee=new y({props:{code:`image = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
question = "Where is the cat?"`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>image = <span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>question = <span class="hljs-string">&quot;Where is the cat?&quot;</span>`}}),qe=new y({props:{code:`from transformers import pipeline

vqa = pipeline(task="vqa")
preds = vqa(image=image, question=question)
preds = [{"score": round(pred["score"], 4), "answer": pred["answer"]} for pred in preds]
preds`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>vqa = pipeline(task=<span class="hljs-string">&quot;vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>preds = vqa(image=image, question=question)
<span class="hljs-meta">&gt;&gt;&gt; </span>preds = [{<span class="hljs-string">&quot;score&quot;</span>: <span class="hljs-built_in">round</span>(pred[<span class="hljs-string">&quot;score&quot;</span>], <span class="hljs-number">4</span>), <span class="hljs-string">&quot;answer&quot;</span>: pred[<span class="hljs-string">&quot;answer&quot;</span>]} <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> preds]
<span class="hljs-meta">&gt;&gt;&gt; </span>preds
[{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.911</span>, <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;snow&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.8786</span>, <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;in snow&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.6714</span>, <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;outside&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0293</span>, <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;on ground&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0272</span>, <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;ground&#x27;</span>}]`}}),{c(){k=r("meta"),N=f(),$=r("h1"),b=r("a"),F=r("span"),m(w.$$.fragment),P=f(),H=r("span"),ya=n("Pipelines for inference"),xs=f(),E=r("p"),ba=n("The "),Pe=r("a"),Ea=n("pipeline()"),qa=n(" makes it simple to use any model from the "),ae=r("a"),Aa=n("Hub"),Pa=n(" for inference on any language, computer vision, speech, and multimodal tasks. Even if you don\u2019t have experience with a specific modality or aren\u2019t familiar with the underlying code behind the models, you can still use them for inference with the "),Te=r("a"),Ta=n("pipeline()"),Sa=n("! This tutorial will teach you to:"),ws=f(),T=r("ul"),te=r("li"),Ma=n("Use a "),Se=r("a"),Fa=n("pipeline()"),za=n(" for inference."),Ca=f(),rs=r("li"),La=n("Use a specific tokenizer or model."),Ia=f(),ne=r("li"),Da=n("Use a "),Me=r("a"),Na=n("pipeline()"),Ha=n(" for audio, vision, and multimodal tasks."),ys=f(),m(R.$$.fragment),bs=f(),z=r("h2"),U=r("a"),is=r("span"),m(le.$$.fragment),Ra=f(),os=r("span"),Ua=n("Pipeline usage"),Es=f(),q=r("p"),Oa=n("While each task has an associated "),Fe=r("a"),Ka=n("pipeline()"),Va=n(", it is simpler to use the general "),ze=r("a"),Wa=n("pipeline()"),Ga=n(" abstraction which contains all the task-specific pipelines. The "),Ce=r("a"),Ba=n("pipeline()"),Qa=n(" automatically loads a default model and a preprocessing class capable of inference for your task."),qs=f(),Le=r("ol"),re=r("li"),Ja=n("Start by creating a "),Ie=r("a"),Xa=n("pipeline()"),Ya=n(" and specify an inference task:"),As=f(),m(ie.$$.fragment),Ps=f(),oe=r("ol"),pe=r("li"),Za=n("Pass your input text to the "),De=r("a"),et=n("pipeline()"),st=n(":"),Ts=f(),m(he.$$.fragment),Ss=f(),Ne=r("p"),at=n("If you have more than one input, pass your input as a list:"),Ms=f(),m(fe.$$.fragment),Fs=f(),x=r("p"),tt=n("Any additional parameters for your task can also be included in the "),He=r("a"),nt=n("pipeline()"),lt=n(". The "),ps=r("code"),rt=n("text-generation"),it=n(" task has a "),Re=r("a"),ot=n("generate()"),pt=n(" method with several parameters for controlling the output. For example, if you want to generate more than one output, set the "),hs=r("code"),ht=n("num_return_sequences"),ft=n(" parameter:"),zs=f(),m(ce.$$.fragment),Cs=f(),C=r("h3"),O=r("a"),fs=r("span"),m(me.$$.fragment),ct=f(),cs=r("span"),mt=n("Choose a model and tokenizer"),Ls=f(),_=r("p"),ut=n("The "),Ue=r("a"),dt=n("pipeline()"),gt=n(" accepts any model from the "),ue=r("a"),vt=n("Hub"),jt=n(". There are tags on the Hub that allow you to filter for a model you\u2019d like to use for your task. Once you\u2019ve picked an appropriate model, load it with the corresponding "),ms=r("code"),kt=n("AutoModelFor"),$t=n(" and "),Oe=r("a"),_t=n("AutoTokenizer"),xt=n(" class. For example, load the "),Ke=r("a"),wt=n("AutoModelForCausalLM"),yt=n(" class for a causal language modeling task:"),Is=f(),m(de.$$.fragment),Ds=f(),K=r("p"),bt=n("Create a "),Ve=r("a"),Et=n("pipeline()"),qt=n(" for your task, and specify the model and tokenizer you\u2019ve loaded:"),Ns=f(),m(ge.$$.fragment),Hs=f(),V=r("p"),At=n("Pass your input text to the "),We=r("a"),Pt=n("pipeline()"),Tt=n(" to generate some text:"),Rs=f(),m(ve.$$.fragment),Us=f(),L=r("h2"),W=r("a"),us=r("span"),m(je.$$.fragment),St=f(),ds=r("span"),Mt=n("Audio pipeline"),Os=f(),G=r("p"),Ft=n("The "),Ge=r("a"),zt=n("pipeline()"),Ct=n(" also supports audio tasks like audio classification and automatic speech recognition."),Ks=f(),Be=r("p"),Lt=n("For example, let\u2019s classify the emotion in this audio clip:"),Vs=f(),m(ke.$$.fragment),Ws=f(),S=r("p"),It=n("Find an "),$e=r("a"),Dt=n("audio classification"),Nt=n(" model on the Model Hub for emotion recognition and load it in the "),Qe=r("a"),Ht=n("pipeline()"),Rt=n(":"),Gs=f(),m(_e.$$.fragment),Bs=f(),B=r("p"),Ut=n("Pass the audio file to the "),Je=r("a"),Ot=n("pipeline()"),Kt=n(":"),Qs=f(),m(xe.$$.fragment),Js=f(),I=r("h2"),Q=r("a"),gs=r("span"),m(we.$$.fragment),Vt=f(),vs=r("span"),Wt=n("Vision pipeline"),Xs=f(),J=r("p"),Gt=n("Using a "),Xe=r("a"),Bt=n("pipeline()"),Qt=n(" for vision tasks is practically identical."),Ys=f(),Ye=r("p"),Jt=n("Specify your task and pass your image to the classifier. The image can be a link or a local path to the image. For example, what species of cat is shown below?"),Zs=f(),Ze=r("p"),es=r("img"),ea=f(),m(ye.$$.fragment),sa=f(),D=r("h2"),X=r("a"),js=r("span"),m(be.$$.fragment),Xt=f(),ks=r("span"),Yt=n("Multimodal pipeline"),aa=f(),Y=r("p"),Zt=n("The "),ss=r("a"),en=n("pipeline()"),sn=n(" supports more than one modality. For example, a visual question answering (VQA) task combines text and image. Feel free to use any image link you like and a question you want to ask about the image. The image can be a URL or a local path to the image."),ta=f(),as=r("p"),an=n("For example, if you use the same image from the vision pipeline above:"),na=f(),m(Ee.$$.fragment),la=f(),Z=r("p"),tn=n("Create a pipeline for "),$s=r("code"),nn=n("vqa"),ln=n(" and pass it the image and question:"),ra=f(),m(qe.$$.fragment),this.h()},l(e){const t=fl('[data-svelte="svelte-1phssyn"]',document.head);k=i(t,"META",{name:!0,content:!0}),t.forEach(s),N=c(e),$=i(e,"H1",{class:!0});var Ae=o($);b=i(Ae,"A",{id:!0,class:!0,href:!0});var on=o(b);F=i(on,"SPAN",{});var pn=o(F);u(w.$$.fragment,pn),pn.forEach(s),on.forEach(s),P=c(Ae),H=i(Ae,"SPAN",{});var hn=o(H);ya=l(hn,"Pipelines for inference"),hn.forEach(s),Ae.forEach(s),xs=c(e),E=i(e,"P",{});var ee=o(E);ba=l(ee,"The "),Pe=i(ee,"A",{href:!0});var fn=o(Pe);Ea=l(fn,"pipeline()"),fn.forEach(s),qa=l(ee," makes it simple to use any model from the "),ae=i(ee,"A",{href:!0,rel:!0});var cn=o(ae);Aa=l(cn,"Hub"),cn.forEach(s),Pa=l(ee," for inference on any language, computer vision, speech, and multimodal tasks. Even if you don\u2019t have experience with a specific modality or aren\u2019t familiar with the underlying code behind the models, you can still use them for inference with the "),Te=i(ee,"A",{href:!0});var mn=o(Te);Ta=l(mn,"pipeline()"),mn.forEach(s),Sa=l(ee,"! This tutorial will teach you to:"),ee.forEach(s),ws=c(e),T=i(e,"UL",{});var ts=o(T);te=i(ts,"LI",{});var oa=o(te);Ma=l(oa,"Use a "),Se=i(oa,"A",{href:!0});var un=o(Se);Fa=l(un,"pipeline()"),un.forEach(s),za=l(oa," for inference."),oa.forEach(s),Ca=c(ts),rs=i(ts,"LI",{});var dn=o(rs);La=l(dn,"Use a specific tokenizer or model."),dn.forEach(s),Ia=c(ts),ne=i(ts,"LI",{});var pa=o(ne);Da=l(pa,"Use a "),Me=i(pa,"A",{href:!0});var gn=o(Me);Na=l(gn,"pipeline()"),gn.forEach(s),Ha=l(pa," for audio, vision, and multimodal tasks."),pa.forEach(s),ts.forEach(s),ys=c(e),u(R.$$.fragment,e),bs=c(e),z=i(e,"H2",{class:!0});var ha=o(z);U=i(ha,"A",{id:!0,class:!0,href:!0});var vn=o(U);is=i(vn,"SPAN",{});var jn=o(is);u(le.$$.fragment,jn),jn.forEach(s),vn.forEach(s),Ra=c(ha),os=i(ha,"SPAN",{});var kn=o(os);Ua=l(kn,"Pipeline usage"),kn.forEach(s),ha.forEach(s),Es=c(e),q=i(e,"P",{});var se=o(q);Oa=l(se,"While each task has an associated "),Fe=i(se,"A",{href:!0});var $n=o(Fe);Ka=l($n,"pipeline()"),$n.forEach(s),Va=l(se,", it is simpler to use the general "),ze=i(se,"A",{href:!0});var _n=o(ze);Wa=l(_n,"pipeline()"),_n.forEach(s),Ga=l(se," abstraction which contains all the task-specific pipelines. The "),Ce=i(se,"A",{href:!0});var xn=o(Ce);Ba=l(xn,"pipeline()"),xn.forEach(s),Qa=l(se," automatically loads a default model and a preprocessing class capable of inference for your task."),se.forEach(s),qs=c(e),Le=i(e,"OL",{});var wn=o(Le);re=i(wn,"LI",{});var fa=o(re);Ja=l(fa,"Start by creating a "),Ie=i(fa,"A",{href:!0});var yn=o(Ie);Xa=l(yn,"pipeline()"),yn.forEach(s),Ya=l(fa," and specify an inference task:"),fa.forEach(s),wn.forEach(s),As=c(e),u(ie.$$.fragment,e),Ps=c(e),oe=i(e,"OL",{start:!0});var bn=o(oe);pe=i(bn,"LI",{});var ca=o(pe);Za=l(ca,"Pass your input text to the "),De=i(ca,"A",{href:!0});var En=o(De);et=l(En,"pipeline()"),En.forEach(s),st=l(ca,":"),ca.forEach(s),bn.forEach(s),Ts=c(e),u(he.$$.fragment,e),Ss=c(e),Ne=i(e,"P",{});var qn=o(Ne);at=l(qn,"If you have more than one input, pass your input as a list:"),qn.forEach(s),Ms=c(e),u(fe.$$.fragment,e),Fs=c(e),x=i(e,"P",{});var M=o(x);tt=l(M,"Any additional parameters for your task can also be included in the "),He=i(M,"A",{href:!0});var An=o(He);nt=l(An,"pipeline()"),An.forEach(s),lt=l(M,". The "),ps=i(M,"CODE",{});var Pn=o(ps);rt=l(Pn,"text-generation"),Pn.forEach(s),it=l(M," task has a "),Re=i(M,"A",{href:!0});var Tn=o(Re);ot=l(Tn,"generate()"),Tn.forEach(s),pt=l(M," method with several parameters for controlling the output. For example, if you want to generate more than one output, set the "),hs=i(M,"CODE",{});var Sn=o(hs);ht=l(Sn,"num_return_sequences"),Sn.forEach(s),ft=l(M," parameter:"),M.forEach(s),zs=c(e),u(ce.$$.fragment,e),Cs=c(e),C=i(e,"H3",{class:!0});var ma=o(C);O=i(ma,"A",{id:!0,class:!0,href:!0});var Mn=o(O);fs=i(Mn,"SPAN",{});var Fn=o(fs);u(me.$$.fragment,Fn),Fn.forEach(s),Mn.forEach(s),ct=c(ma),cs=i(ma,"SPAN",{});var zn=o(cs);mt=l(zn,"Choose a model and tokenizer"),zn.forEach(s),ma.forEach(s),Ls=c(e),_=i(e,"P",{});var A=o(_);ut=l(A,"The "),Ue=i(A,"A",{href:!0});var Cn=o(Ue);dt=l(Cn,"pipeline()"),Cn.forEach(s),gt=l(A," accepts any model from the "),ue=i(A,"A",{href:!0,rel:!0});var Ln=o(ue);vt=l(Ln,"Hub"),Ln.forEach(s),jt=l(A,". There are tags on the Hub that allow you to filter for a model you\u2019d like to use for your task. Once you\u2019ve picked an appropriate model, load it with the corresponding "),ms=i(A,"CODE",{});var In=o(ms);kt=l(In,"AutoModelFor"),In.forEach(s),$t=l(A," and "),Oe=i(A,"A",{href:!0});var Dn=o(Oe);_t=l(Dn,"AutoTokenizer"),Dn.forEach(s),xt=l(A," class. For example, load the "),Ke=i(A,"A",{href:!0});var Nn=o(Ke);wt=l(Nn,"AutoModelForCausalLM"),Nn.forEach(s),yt=l(A," class for a causal language modeling task:"),A.forEach(s),Is=c(e),u(de.$$.fragment,e),Ds=c(e),K=i(e,"P",{});var ua=o(K);bt=l(ua,"Create a "),Ve=i(ua,"A",{href:!0});var Hn=o(Ve);Et=l(Hn,"pipeline()"),Hn.forEach(s),qt=l(ua," for your task, and specify the model and tokenizer you\u2019ve loaded:"),ua.forEach(s),Ns=c(e),u(ge.$$.fragment,e),Hs=c(e),V=i(e,"P",{});var da=o(V);At=l(da,"Pass your input text to the "),We=i(da,"A",{href:!0});var Rn=o(We);Pt=l(Rn,"pipeline()"),Rn.forEach(s),Tt=l(da," to generate some text:"),da.forEach(s),Rs=c(e),u(ve.$$.fragment,e),Us=c(e),L=i(e,"H2",{class:!0});var ga=o(L);W=i(ga,"A",{id:!0,class:!0,href:!0});var Un=o(W);us=i(Un,"SPAN",{});var On=o(us);u(je.$$.fragment,On),On.forEach(s),Un.forEach(s),St=c(ga),ds=i(ga,"SPAN",{});var Kn=o(ds);Mt=l(Kn,"Audio pipeline"),Kn.forEach(s),ga.forEach(s),Os=c(e),G=i(e,"P",{});var va=o(G);Ft=l(va,"The "),Ge=i(va,"A",{href:!0});var Vn=o(Ge);zt=l(Vn,"pipeline()"),Vn.forEach(s),Ct=l(va," also supports audio tasks like audio classification and automatic speech recognition."),va.forEach(s),Ks=c(e),Be=i(e,"P",{});var Wn=o(Be);Lt=l(Wn,"For example, let\u2019s classify the emotion in this audio clip:"),Wn.forEach(s),Vs=c(e),u(ke.$$.fragment,e),Ws=c(e),S=i(e,"P",{});var ns=o(S);It=l(ns,"Find an "),$e=i(ns,"A",{href:!0,rel:!0});var Gn=o($e);Dt=l(Gn,"audio classification"),Gn.forEach(s),Nt=l(ns," model on the Model Hub for emotion recognition and load it in the "),Qe=i(ns,"A",{href:!0});var Bn=o(Qe);Ht=l(Bn,"pipeline()"),Bn.forEach(s),Rt=l(ns,":"),ns.forEach(s),Gs=c(e),u(_e.$$.fragment,e),Bs=c(e),B=i(e,"P",{});var ja=o(B);Ut=l(ja,"Pass the audio file to the "),Je=i(ja,"A",{href:!0});var Qn=o(Je);Ot=l(Qn,"pipeline()"),Qn.forEach(s),Kt=l(ja,":"),ja.forEach(s),Qs=c(e),u(xe.$$.fragment,e),Js=c(e),I=i(e,"H2",{class:!0});var ka=o(I);Q=i(ka,"A",{id:!0,class:!0,href:!0});var Jn=o(Q);gs=i(Jn,"SPAN",{});var Xn=o(gs);u(we.$$.fragment,Xn),Xn.forEach(s),Jn.forEach(s),Vt=c(ka),vs=i(ka,"SPAN",{});var Yn=o(vs);Wt=l(Yn,"Vision pipeline"),Yn.forEach(s),ka.forEach(s),Xs=c(e),J=i(e,"P",{});var $a=o(J);Gt=l($a,"Using a "),Xe=i($a,"A",{href:!0});var Zn=o(Xe);Bt=l(Zn,"pipeline()"),Zn.forEach(s),Qt=l($a," for vision tasks is practically identical."),$a.forEach(s),Ys=c(e),Ye=i(e,"P",{});var el=o(Ye);Jt=l(el,"Specify your task and pass your image to the classifier. The image can be a link or a local path to the image. For example, what species of cat is shown below?"),el.forEach(s),Zs=c(e),Ze=i(e,"P",{});var sl=o(Ze);es=i(sl,"IMG",{src:!0,alt:!0}),sl.forEach(s),ea=c(e),u(ye.$$.fragment,e),sa=c(e),D=i(e,"H2",{class:!0});var _a=o(D);X=i(_a,"A",{id:!0,class:!0,href:!0});var al=o(X);js=i(al,"SPAN",{});var tl=o(js);u(be.$$.fragment,tl),tl.forEach(s),al.forEach(s),Xt=c(_a),ks=i(_a,"SPAN",{});var nl=o(ks);Yt=l(nl,"Multimodal pipeline"),nl.forEach(s),_a.forEach(s),aa=c(e),Y=i(e,"P",{});var xa=o(Y);Zt=l(xa,"The "),ss=i(xa,"A",{href:!0});var ll=o(ss);en=l(ll,"pipeline()"),ll.forEach(s),sn=l(xa," supports more than one modality. For example, a visual question answering (VQA) task combines text and image. Feel free to use any image link you like and a question you want to ask about the image. The image can be a URL or a local path to the image."),xa.forEach(s),ta=c(e),as=i(e,"P",{});var rl=o(as);an=l(rl,"For example, if you use the same image from the vision pipeline above:"),rl.forEach(s),na=c(e),u(Ee.$$.fragment,e),la=c(e),Z=i(e,"P",{});var wa=o(Z);tn=l(wa,"Create a pipeline for "),$s=i(wa,"CODE",{});var il=o($s);nn=l(il,"vqa"),il.forEach(s),ln=l(wa," and pass it the image and question:"),wa.forEach(s),ra=c(e),u(qe.$$.fragment,e),this.h()},h(){h(k,"name","hf:doc:metadata"),h(k,"content",JSON.stringify(vl)),h(b,"id","pipelines-for-inference"),h(b,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(b,"href","#pipelines-for-inference"),h($,"class","relative group"),h(Pe,"href","/docs/transformers/v4.22.2/en/main_classes/pipelines#transformers.pipeline"),h(ae,"href","https://huggingface.co/models"),h(ae,"rel","nofollow"),h(Te,"href","/docs/transformers/v4.22.2/en/main_classes/pipelines#transformers.pipeline"),h(Se,"href","/docs/transformers/v4.22.2/en/main_classes/pipelines#transformers.pipeline"),h(Me,"href","/docs/transformers/v4.22.2/en/main_classes/pipelines#transformers.pipeline"),h(U,"id","pipeline-usage"),h(U,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(U,"href","#pipeline-usage"),h(z,"class","relative group"),h(Fe,"href","/docs/transformers/v4.22.2/en/main_classes/pipelines#transformers.pipeline"),h(ze,"href","/docs/transformers/v4.22.2/en/main_classes/pipelines#transformers.pipeline"),h(Ce,"href","/docs/transformers/v4.22.2/en/main_classes/pipelines#transformers.pipeline"),h(Ie,"href","/docs/transformers/v4.22.2/en/main_classes/pipelines#transformers.pipeline"),h(De,"href","/docs/transformers/v4.22.2/en/main_classes/pipelines#transformers.pipeline"),h(oe,"start","2"),h(He,"href","/docs/transformers/v4.22.2/en/main_classes/pipelines#transformers.pipeline"),h(Re,"href","/docs/transformers/v4.22.2/en/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate"),h(O,"id","choose-a-model-and-tokenizer"),h(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(O,"href","#choose-a-model-and-tokenizer"),h(C,"class","relative group"),h(Ue,"href","/docs/transformers/v4.22.2/en/main_classes/pipelines#transformers.pipeline"),h(ue,"href","https://huggingface.co/models"),h(ue,"rel","nofollow"),h(Oe,"href","/docs/transformers/v4.22.2/en/model_doc/auto#transformers.AutoTokenizer"),h(Ke,"href","/docs/transformers/v4.22.2/en/model_doc/auto#transformers.AutoModelForCausalLM"),h(Ve,"href","/docs/transformers/v4.22.2/en/main_classes/pipelines#transformers.pipeline"),h(We,"href","/docs/transformers/v4.22.2/en/main_classes/pipelines#transformers.pipeline"),h(W,"id","audio-pipeline"),h(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(W,"href","#audio-pipeline"),h(L,"class","relative group"),h(Ge,"href","/docs/transformers/v4.22.2/en/main_classes/pipelines#transformers.pipeline"),h($e,"href","https://huggingface.co/models?pipeline_tag=audio-classification"),h($e,"rel","nofollow"),h(Qe,"href","/docs/transformers/v4.22.2/en/main_classes/pipelines#transformers.pipeline"),h(Je,"href","/docs/transformers/v4.22.2/en/main_classes/pipelines#transformers.pipeline"),h(Q,"id","vision-pipeline"),h(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Q,"href","#vision-pipeline"),h(I,"class","relative group"),h(Xe,"href","/docs/transformers/v4.22.2/en/main_classes/pipelines#transformers.pipeline"),cl(es.src,rn="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg")||h(es,"src",rn),h(es,"alt","pipeline-cat-chonk"),h(X,"id","multimodal-pipeline"),h(X,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(X,"href","#multimodal-pipeline"),h(D,"class","relative group"),h(ss,"href","/docs/transformers/v4.22.2/en/main_classes/pipelines#transformers.pipeline")},m(e,t){a(document.head,k),p(e,N,t),p(e,$,t),a($,b),a(b,F),d(w,F,null),a($,P),a($,H),a(H,ya),p(e,xs,t),p(e,E,t),a(E,ba),a(E,Pe),a(Pe,Ea),a(E,qa),a(E,ae),a(ae,Aa),a(E,Pa),a(E,Te),a(Te,Ta),a(E,Sa),p(e,ws,t),p(e,T,t),a(T,te),a(te,Ma),a(te,Se),a(Se,Fa),a(te,za),a(T,Ca),a(T,rs),a(rs,La),a(T,Ia),a(T,ne),a(ne,Da),a(ne,Me),a(Me,Na),a(ne,Ha),p(e,ys,t),d(R,e,t),p(e,bs,t),p(e,z,t),a(z,U),a(U,is),d(le,is,null),a(z,Ra),a(z,os),a(os,Ua),p(e,Es,t),p(e,q,t),a(q,Oa),a(q,Fe),a(Fe,Ka),a(q,Va),a(q,ze),a(ze,Wa),a(q,Ga),a(q,Ce),a(Ce,Ba),a(q,Qa),p(e,qs,t),p(e,Le,t),a(Le,re),a(re,Ja),a(re,Ie),a(Ie,Xa),a(re,Ya),p(e,As,t),d(ie,e,t),p(e,Ps,t),p(e,oe,t),a(oe,pe),a(pe,Za),a(pe,De),a(De,et),a(pe,st),p(e,Ts,t),d(he,e,t),p(e,Ss,t),p(e,Ne,t),a(Ne,at),p(e,Ms,t),d(fe,e,t),p(e,Fs,t),p(e,x,t),a(x,tt),a(x,He),a(He,nt),a(x,lt),a(x,ps),a(ps,rt),a(x,it),a(x,Re),a(Re,ot),a(x,pt),a(x,hs),a(hs,ht),a(x,ft),p(e,zs,t),d(ce,e,t),p(e,Cs,t),p(e,C,t),a(C,O),a(O,fs),d(me,fs,null),a(C,ct),a(C,cs),a(cs,mt),p(e,Ls,t),p(e,_,t),a(_,ut),a(_,Ue),a(Ue,dt),a(_,gt),a(_,ue),a(ue,vt),a(_,jt),a(_,ms),a(ms,kt),a(_,$t),a(_,Oe),a(Oe,_t),a(_,xt),a(_,Ke),a(Ke,wt),a(_,yt),p(e,Is,t),d(de,e,t),p(e,Ds,t),p(e,K,t),a(K,bt),a(K,Ve),a(Ve,Et),a(K,qt),p(e,Ns,t),d(ge,e,t),p(e,Hs,t),p(e,V,t),a(V,At),a(V,We),a(We,Pt),a(V,Tt),p(e,Rs,t),d(ve,e,t),p(e,Us,t),p(e,L,t),a(L,W),a(W,us),d(je,us,null),a(L,St),a(L,ds),a(ds,Mt),p(e,Os,t),p(e,G,t),a(G,Ft),a(G,Ge),a(Ge,zt),a(G,Ct),p(e,Ks,t),p(e,Be,t),a(Be,Lt),p(e,Vs,t),d(ke,e,t),p(e,Ws,t),p(e,S,t),a(S,It),a(S,$e),a($e,Dt),a(S,Nt),a(S,Qe),a(Qe,Ht),a(S,Rt),p(e,Gs,t),d(_e,e,t),p(e,Bs,t),p(e,B,t),a(B,Ut),a(B,Je),a(Je,Ot),a(B,Kt),p(e,Qs,t),d(xe,e,t),p(e,Js,t),p(e,I,t),a(I,Q),a(Q,gs),d(we,gs,null),a(I,Vt),a(I,vs),a(vs,Wt),p(e,Xs,t),p(e,J,t),a(J,Gt),a(J,Xe),a(Xe,Bt),a(J,Qt),p(e,Ys,t),p(e,Ye,t),a(Ye,Jt),p(e,Zs,t),p(e,Ze,t),a(Ze,es),p(e,ea,t),d(ye,e,t),p(e,sa,t),p(e,D,t),a(D,X),a(X,js),d(be,js,null),a(D,Xt),a(D,ks),a(ks,Yt),p(e,aa,t),p(e,Y,t),a(Y,Zt),a(Y,ss),a(ss,en),a(Y,sn),p(e,ta,t),p(e,as,t),a(as,an),p(e,na,t),d(Ee,e,t),p(e,la,t),p(e,Z,t),a(Z,tn),a(Z,$s),a($s,nn),a(Z,ln),p(e,ra,t),d(qe,e,t),ia=!0},p(e,[t]){const Ae={};t&2&&(Ae.$$scope={dirty:t,ctx:e}),R.$set(Ae)},i(e){ia||(g(w.$$.fragment,e),g(R.$$.fragment,e),g(le.$$.fragment,e),g(ie.$$.fragment,e),g(he.$$.fragment,e),g(fe.$$.fragment,e),g(ce.$$.fragment,e),g(me.$$.fragment,e),g(de.$$.fragment,e),g(ge.$$.fragment,e),g(ve.$$.fragment,e),g(je.$$.fragment,e),g(ke.$$.fragment,e),g(_e.$$.fragment,e),g(xe.$$.fragment,e),g(we.$$.fragment,e),g(ye.$$.fragment,e),g(be.$$.fragment,e),g(Ee.$$.fragment,e),g(qe.$$.fragment,e),ia=!0)},o(e){v(w.$$.fragment,e),v(R.$$.fragment,e),v(le.$$.fragment,e),v(ie.$$.fragment,e),v(he.$$.fragment,e),v(fe.$$.fragment,e),v(ce.$$.fragment,e),v(me.$$.fragment,e),v(de.$$.fragment,e),v(ge.$$.fragment,e),v(ve.$$.fragment,e),v(je.$$.fragment,e),v(ke.$$.fragment,e),v(_e.$$.fragment,e),v(xe.$$.fragment,e),v(we.$$.fragment,e),v(ye.$$.fragment,e),v(be.$$.fragment,e),v(Ee.$$.fragment,e),v(qe.$$.fragment,e),ia=!1},d(e){s(k),e&&s(N),e&&s($),j(w),e&&s(xs),e&&s(E),e&&s(ws),e&&s(T),e&&s(ys),j(R,e),e&&s(bs),e&&s(z),j(le),e&&s(Es),e&&s(q),e&&s(qs),e&&s(Le),e&&s(As),j(ie,e),e&&s(Ps),e&&s(oe),e&&s(Ts),j(he,e),e&&s(Ss),e&&s(Ne),e&&s(Ms),j(fe,e),e&&s(Fs),e&&s(x),e&&s(zs),j(ce,e),e&&s(Cs),e&&s(C),j(me),e&&s(Ls),e&&s(_),e&&s(Is),j(de,e),e&&s(Ds),e&&s(K),e&&s(Ns),j(ge,e),e&&s(Hs),e&&s(V),e&&s(Rs),j(ve,e),e&&s(Us),e&&s(L),j(je),e&&s(Os),e&&s(G),e&&s(Ks),e&&s(Be),e&&s(Vs),j(ke,e),e&&s(Ws),e&&s(S),e&&s(Gs),j(_e,e),e&&s(Bs),e&&s(B),e&&s(Qs),j(xe,e),e&&s(Js),e&&s(I),j(we),e&&s(Xs),e&&s(J),e&&s(Ys),e&&s(Ye),e&&s(Zs),e&&s(Ze),e&&s(ea),j(ye,e),e&&s(sa),e&&s(D),j(be),e&&s(aa),e&&s(Y),e&&s(ta),e&&s(as),e&&s(na),j(Ee,e),e&&s(la),e&&s(Z),e&&s(ra),j(qe,e)}}}const vl={local:"pipelines-for-inference",sections:[{local:"pipeline-usage",sections:[{local:"choose-a-model-and-tokenizer",title:"Choose a model and tokenizer"}],title:"Pipeline usage"},{local:"audio-pipeline",title:"Audio pipeline"},{local:"vision-pipeline",title:"Vision pipeline"},{local:"multimodal-pipeline",title:"Multimodal pipeline"}],title:"Pipelines for inference"};function jl(_s){return ml(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class wl extends ol{constructor(k){super();pl(this,k,jl,gl,hl,{})}}export{wl as default,vl as metadata};
