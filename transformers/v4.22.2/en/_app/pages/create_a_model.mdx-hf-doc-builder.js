import{S as qi,i as Ei,s as Ti,e as o,k as m,w as j,t as a,M as xi,c as n,d as s,m as d,a as i,x as q,h as r,b as g,G as t,g as f,y as E,q as T,o as x,B as z,v as zi,L as Ra}from"../chunks/vendor-hf-doc-builder.js";import{T as Na}from"../chunks/Tip-hf-doc-builder.js";import{I as ct}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as L}from"../chunks/CodeBlock-hf-doc-builder.js";import{F as ji,M as Qa}from"../chunks/Markdown-hf-doc-builder.js";function Fi(I){let p,$,u,_,y;return{c(){p=o("p"),$=a("You can also save your configuration file as a dictionary or even just the difference between your custom configuration attributes and the default configuration attributes! See the "),u=o("a"),_=a("configuration"),y=a(" documentation for more details."),this.h()},l(v){p=n(v,"P",{});var w=i(p);$=r(w,"You can also save your configuration file as a dictionary or even just the difference between your custom configuration attributes and the default configuration attributes! See the "),u=n(w,"A",{href:!0});var F=i(u);_=r(F,"configuration"),F.forEach(s),y=r(w," documentation for more details."),w.forEach(s),this.h()},h(){g(u,"href","main_classes/configuration")},m(v,w){f(v,p,w),t(p,$),t(p,u),t(u,_),t(p,y)},d(v){v&&s(p)}}}function Di(I){let p,$,u,_,y,v,w,F,b,W,k,S,A,M,D,V,h,C,N,P,R;return _=new L({props:{code:`from transformers import DistilBertModel

my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")
model = DistilBertModel(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;./your_model_save_path/my_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertModel(my_config)`}}),D=new L({props:{code:'model = DistilBertModel.from_pretrained("distilbert-base-uncased")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)'}}),P=new L({props:{code:'model = DistilBertModel.from_pretrained("distilbert-base-uncased", config=my_config)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, config=my_config)'}}),{c(){p=o("p"),$=a("Load your custom configuration attributes into the model:"),u=m(),j(_.$$.fragment),y=m(),v=o("p"),w=a("This creates a model with random values instead of pretrained weights. You won\u2019t be able to use this model for anything useful yet until you train it. Training is a costly and time-consuming process. It is generally better to use a pretrained model to obtain better results faster, while using only a fraction of the resources required for training."),F=m(),b=o("p"),W=a("Create a pretrained model with "),k=o("a"),S=a("from_pretrained()"),A=a(":"),M=m(),j(D.$$.fragment),V=m(),h=o("p"),C=a("When you load pretrained weights, the default model configuration is automatically loaded if the model is provided by \u{1F917} Transformers. However, you can still replace - some or all of - the default model configuration attributes with your own if you\u2019d like:"),N=m(),j(P.$$.fragment),this.h()},l(c){p=n(c,"P",{});var B=i(p);$=r(B,"Load your custom configuration attributes into the model:"),B.forEach(s),u=d(c),q(_.$$.fragment,c),y=d(c),v=n(c,"P",{});var O=i(v);w=r(O,"This creates a model with random values instead of pretrained weights. You won\u2019t be able to use this model for anything useful yet until you train it. Training is a costly and time-consuming process. It is generally better to use a pretrained model to obtain better results faster, while using only a fraction of the resources required for training."),O.forEach(s),F=d(c),b=n(c,"P",{});var H=i(b);W=r(H,"Create a pretrained model with "),k=n(H,"A",{href:!0});var se=i(k);S=r(se,"from_pretrained()"),se.forEach(s),A=r(H,":"),H.forEach(s),M=d(c),q(D.$$.fragment,c),V=d(c),h=n(c,"P",{});var ae=i(h);C=r(ae,"When you load pretrained weights, the default model configuration is automatically loaded if the model is provided by \u{1F917} Transformers. However, you can still replace - some or all of - the default model configuration attributes with your own if you\u2019d like:"),ae.forEach(s),N=d(c),q(P.$$.fragment,c),this.h()},h(){g(k,"href","/docs/transformers/v4.22.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained")},m(c,B){f(c,p,B),t(p,$),f(c,u,B),E(_,c,B),f(c,y,B),f(c,v,B),t(v,w),f(c,F,B),f(c,b,B),t(b,W),t(b,k),t(k,S),t(b,A),f(c,M,B),E(D,c,B),f(c,V,B),f(c,h,B),t(h,C),f(c,N,B),E(P,c,B),R=!0},p:Ra,i(c){R||(T(_.$$.fragment,c),T(D.$$.fragment,c),T(P.$$.fragment,c),R=!0)},o(c){x(_.$$.fragment,c),x(D.$$.fragment,c),x(P.$$.fragment,c),R=!1},d(c){c&&s(p),c&&s(u),z(_,c),c&&s(y),c&&s(v),c&&s(F),c&&s(b),c&&s(M),z(D,c),c&&s(V),c&&s(h),c&&s(N),z(P,c)}}}function Bi(I){let p,$;return p=new Qa({props:{$$slots:{default:[Di]},$$scope:{ctx:I}}}),{c(){j(p.$$.fragment)},l(u){q(p.$$.fragment,u)},m(u,_){E(p,u,_),$=!0},p(u,_){const y={};_&2&&(y.$$scope={dirty:_,ctx:u}),p.$set(y)},i(u){$||(T(p.$$.fragment,u),$=!0)},o(u){x(p.$$.fragment,u),$=!1},d(u){z(p,u)}}}function Ci(I){let p,$,u,_,y,v,w,F,b,W,k,S,A,M,D,V,h,C,N,P,R;return _=new L({props:{code:`from transformers import TFDistilBertModel

my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")
tf_model = TFDistilBertModel(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFDistilBertModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;./your_model_save_path/my_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertModel(my_config)`}}),D=new L({props:{code:'tf_model = TFDistilBertModel.from_pretrained("distilbert-base-uncased")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)'}}),P=new L({props:{code:'tf_model = TFDistilBertModel.from_pretrained("distilbert-base-uncased", config=my_config)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, config=my_config)'}}),{c(){p=o("p"),$=a("Load your custom configuration attributes into the model:"),u=m(),j(_.$$.fragment),y=m(),v=o("p"),w=a("This creates a model with random values instead of pretrained weights. You won\u2019t be able to use this model for anything useful yet until you train it. Training is a costly and time-consuming process. It is generally better to use a pretrained model to obtain better results faster, while using only a fraction of the resources required for training."),F=m(),b=o("p"),W=a("Create a pretrained model with "),k=o("a"),S=a("from_pretrained()"),A=a(":"),M=m(),j(D.$$.fragment),V=m(),h=o("p"),C=a("When you load pretrained weights, the default model configuration is automatically loaded if the model is provided by \u{1F917} Transformers. However, you can still replace - some or all of - the default model configuration attributes with your own if you\u2019d like:"),N=m(),j(P.$$.fragment),this.h()},l(c){p=n(c,"P",{});var B=i(p);$=r(B,"Load your custom configuration attributes into the model:"),B.forEach(s),u=d(c),q(_.$$.fragment,c),y=d(c),v=n(c,"P",{});var O=i(v);w=r(O,"This creates a model with random values instead of pretrained weights. You won\u2019t be able to use this model for anything useful yet until you train it. Training is a costly and time-consuming process. It is generally better to use a pretrained model to obtain better results faster, while using only a fraction of the resources required for training."),O.forEach(s),F=d(c),b=n(c,"P",{});var H=i(b);W=r(H,"Create a pretrained model with "),k=n(H,"A",{href:!0});var se=i(k);S=r(se,"from_pretrained()"),se.forEach(s),A=r(H,":"),H.forEach(s),M=d(c),q(D.$$.fragment,c),V=d(c),h=n(c,"P",{});var ae=i(h);C=r(ae,"When you load pretrained weights, the default model configuration is automatically loaded if the model is provided by \u{1F917} Transformers. However, you can still replace - some or all of - the default model configuration attributes with your own if you\u2019d like:"),ae.forEach(s),N=d(c),q(P.$$.fragment,c),this.h()},h(){g(k,"href","/docs/transformers/v4.22.2/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained")},m(c,B){f(c,p,B),t(p,$),f(c,u,B),E(_,c,B),f(c,y,B),f(c,v,B),t(v,w),f(c,F,B),f(c,b,B),t(b,W),t(b,k),t(k,S),t(b,A),f(c,M,B),E(D,c,B),f(c,V,B),f(c,h,B),t(h,C),f(c,N,B),E(P,c,B),R=!0},p:Ra,i(c){R||(T(_.$$.fragment,c),T(D.$$.fragment,c),T(P.$$.fragment,c),R=!0)},o(c){x(_.$$.fragment,c),x(D.$$.fragment,c),x(P.$$.fragment,c),R=!1},d(c){c&&s(p),c&&s(u),z(_,c),c&&s(y),c&&s(v),c&&s(F),c&&s(b),c&&s(M),z(D,c),c&&s(V),c&&s(h),c&&s(N),z(P,c)}}}function Ai(I){let p,$;return p=new Qa({props:{$$slots:{default:[Ci]},$$scope:{ctx:I}}}),{c(){j(p.$$.fragment)},l(u){q(p.$$.fragment,u)},m(u,_){E(p,u,_),$=!0},p(u,_){const y={};_&2&&(y.$$scope={dirty:_,ctx:u}),p.$set(y)},i(u){$||(T(p.$$.fragment,u),$=!0)},o(u){x(p.$$.fragment,u),$=!1},d(u){z(p,u)}}}function Pi(I){let p,$,u,_,y,v,w,F,b,W,k,S,A,M,D,V;return w=new L({props:{code:`from transformers import DistilBertForSequenceClassification

model = DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),D=new L({props:{code:`from transformers import DistilBertForQuestionAnswering

model = DistilBertForQuestionAnswering.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),{c(){p=o("p"),$=a("For example, "),u=o("a"),_=a("DistilBertForSequenceClassification"),y=a(" is a base DistilBERT model with a sequence classification head. The sequence classification head is a linear layer on top of the pooled outputs."),v=m(),j(w.$$.fragment),F=m(),b=o("p"),W=a("Easily reuse this checkpoint for another task by switching to a different model head. For a question answering task, you would use the "),k=o("a"),S=a("DistilBertForQuestionAnswering"),A=a(" model head. The question answering head is similar to the sequence classification head except it is a linear layer on top of the hidden states output."),M=m(),j(D.$$.fragment),this.h()},l(h){p=n(h,"P",{});var C=i(p);$=r(C,"For example, "),u=n(C,"A",{href:!0});var N=i(u);_=r(N,"DistilBertForSequenceClassification"),N.forEach(s),y=r(C," is a base DistilBERT model with a sequence classification head. The sequence classification head is a linear layer on top of the pooled outputs."),C.forEach(s),v=d(h),q(w.$$.fragment,h),F=d(h),b=n(h,"P",{});var P=i(b);W=r(P,"Easily reuse this checkpoint for another task by switching to a different model head. For a question answering task, you would use the "),k=n(P,"A",{href:!0});var R=i(k);S=r(R,"DistilBertForQuestionAnswering"),R.forEach(s),A=r(P," model head. The question answering head is similar to the sequence classification head except it is a linear layer on top of the hidden states output."),P.forEach(s),M=d(h),q(D.$$.fragment,h),this.h()},h(){g(u,"href","/docs/transformers/v4.22.2/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),g(k,"href","/docs/transformers/v4.22.2/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering")},m(h,C){f(h,p,C),t(p,$),t(p,u),t(u,_),t(p,y),f(h,v,C),E(w,h,C),f(h,F,C),f(h,b,C),t(b,W),t(b,k),t(k,S),t(b,A),f(h,M,C),E(D,h,C),V=!0},p:Ra,i(h){V||(T(w.$$.fragment,h),T(D.$$.fragment,h),V=!0)},o(h){x(w.$$.fragment,h),x(D.$$.fragment,h),V=!1},d(h){h&&s(p),h&&s(v),z(w,h),h&&s(F),h&&s(b),h&&s(M),z(D,h)}}}function Mi(I){let p,$;return p=new Qa({props:{$$slots:{default:[Pi]},$$scope:{ctx:I}}}),{c(){j(p.$$.fragment)},l(u){q(p.$$.fragment,u)},m(u,_){E(p,u,_),$=!0},p(u,_){const y={};_&2&&(y.$$scope={dirty:_,ctx:u}),p.$set(y)},i(u){$||(T(p.$$.fragment,u),$=!0)},o(u){x(p.$$.fragment,u),$=!1},d(u){z(p,u)}}}function Vi(I){let p,$,u,_,y,v,w,F,b,W,k,S,A,M,D,V;return w=new L({props:{code:`from transformers import TFDistilBertForSequenceClassification

tf_model = TFDistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFDistilBertForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),D=new L({props:{code:`from transformers import TFDistilBertForQuestionAnswering

tf_model = TFDistilBertForQuestionAnswering.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFDistilBertForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),{c(){p=o("p"),$=a("For example, "),u=o("a"),_=a("TFDistilBertForSequenceClassification"),y=a(" is a base DistilBERT model with a sequence classification head. The sequence classification head is a linear layer on top of the pooled outputs."),v=m(),j(w.$$.fragment),F=m(),b=o("p"),W=a("Easily reuse this checkpoint for another task by switching to a different model head. For a question answering task, you would use the "),k=o("a"),S=a("TFDistilBertForQuestionAnswering"),A=a(" model head. The question answering head is similar to the sequence classification head except it is a linear layer on top of the hidden states output."),M=m(),j(D.$$.fragment),this.h()},l(h){p=n(h,"P",{});var C=i(p);$=r(C,"For example, "),u=n(C,"A",{href:!0});var N=i(u);_=r(N,"TFDistilBertForSequenceClassification"),N.forEach(s),y=r(C," is a base DistilBERT model with a sequence classification head. The sequence classification head is a linear layer on top of the pooled outputs."),C.forEach(s),v=d(h),q(w.$$.fragment,h),F=d(h),b=n(h,"P",{});var P=i(b);W=r(P,"Easily reuse this checkpoint for another task by switching to a different model head. For a question answering task, you would use the "),k=n(P,"A",{href:!0});var R=i(k);S=r(R,"TFDistilBertForQuestionAnswering"),R.forEach(s),A=r(P," model head. The question answering head is similar to the sequence classification head except it is a linear layer on top of the hidden states output."),P.forEach(s),M=d(h),q(D.$$.fragment,h),this.h()},h(){g(u,"href","/docs/transformers/v4.22.2/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),g(k,"href","/docs/transformers/v4.22.2/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering")},m(h,C){f(h,p,C),t(p,$),t(p,u),t(u,_),t(p,y),f(h,v,C),E(w,h,C),f(h,F,C),f(h,b,C),t(b,W),t(b,k),t(k,S),t(b,A),f(h,M,C),E(D,h,C),V=!0},p:Ra,i(h){V||(T(w.$$.fragment,h),T(D.$$.fragment,h),V=!0)},o(h){x(w.$$.fragment,h),x(D.$$.fragment,h),V=!1},d(h){h&&s(p),h&&s(v),z(w,h),h&&s(F),h&&s(b),h&&s(M),z(D,h)}}}function Si(I){let p,$;return p=new Qa({props:{$$slots:{default:[Vi]},$$scope:{ctx:I}}}),{c(){j(p.$$.fragment)},l(u){q(p.$$.fragment,u)},m(u,_){E(p,u,_),$=!0},p(u,_){const y={};_&2&&(y.$$scope={dirty:_,ctx:u}),p.$set(y)},i(u){$||(T(p.$$.fragment,u),$=!0)},o(u){x(p.$$.fragment,u),$=!1},d(u){z(p,u)}}}function Ii(I){let p,$,u,_,y;return{c(){p=o("p"),$=a("Not every model supports a fast tokenizer. Take a look at this "),u=o("a"),_=a("table"),y=a(" to check if a model has fast tokenizer support."),this.h()},l(v){p=n(v,"P",{});var w=i(p);$=r(w,"Not every model supports a fast tokenizer. Take a look at this "),u=n(w,"A",{href:!0});var F=i(u);_=r(F,"table"),F.forEach(s),y=r(w," to check if a model has fast tokenizer support."),w.forEach(s),this.h()},h(){g(u,"href","index#supported-frameworks")},m(v,w){f(v,p,w),t(p,$),t(p,u),t(u,_),t(p,y)},d(v){v&&s(p)}}}function Wi(I){let p,$,u,_,y,v,w,F,b,W,k;return{c(){p=o("p"),$=a("By default, "),u=o("a"),_=a("AutoTokenizer"),y=a(" will try to load a fast tokenizer. You can disable this behavior by setting "),v=o("code"),w=a("use_fast=False"),F=a(" in "),b=o("code"),W=a("from_pretrained"),k=a("."),this.h()},l(S){p=n(S,"P",{});var A=i(p);$=r(A,"By default, "),u=n(A,"A",{href:!0});var M=i(u);_=r(M,"AutoTokenizer"),M.forEach(s),y=r(A," will try to load a fast tokenizer. You can disable this behavior by setting "),v=n(A,"CODE",{});var D=i(v);w=r(D,"use_fast=False"),D.forEach(s),F=r(A," in "),b=n(A,"CODE",{});var V=i(b);W=r(V,"from_pretrained"),V.forEach(s),k=r(A,"."),A.forEach(s),this.h()},h(){g(u,"href","/docs/transformers/v4.22.2/en/model_doc/auto#transformers.AutoTokenizer")},m(S,A){f(S,p,A),t(p,$),t(p,u),t(u,_),t(p,y),t(p,v),t(v,w),t(p,F),t(p,b),t(b,W),t(p,k)},d(S){S&&s(p)}}}function Li(I){let p,$,u,_,y;return{c(){p=o("p"),$=a("If you aren\u2019t looking for any customization, just use the "),u=o("code"),_=a("from_pretrained"),y=a(" method to load a model\u2019s default feature extractor parameters.")},l(v){p=n(v,"P",{});var w=i(p);$=r(w,"If you aren\u2019t looking for any customization, just use the "),u=n(w,"CODE",{});var F=i(u);_=r(F,"from_pretrained"),F.forEach(s),y=r(w," method to load a model\u2019s default feature extractor parameters."),w.forEach(s)},m(v,w){f(v,p,w),t(p,$),t(p,u),t(u,_),t(p,y)},d(v){v&&s(p)}}}function Oi(I){let p,$,u,_,y,v,w,F,b,W,k,S,A,M,D,V,h,C,N,P,R,c,B,O,H,se,ae,Rt,Ya,Ha,Qt,Ua,Ga,Yt,Ja,Xa,Ht,Ka,js,re,ue,Ut,Se,Za,Gt,er,qs,Y,tr,mt,sr,ar,Jt,rr,or,Xt,nr,ir,Kt,lr,fr,Zt,pr,ur,Es,K,cr,dt,mr,dr,ht,hr,gr,Ts,Ie,xs,oe,gt,_r,$r,_t,vr,wr,zs,ce,We,yr,es,br,kr,jr,Le,qr,ts,Er,Tr,Fs,Oe,Ds,me,xr,$t,zr,Fr,Bs,Ne,Cs,de,Dr,vt,Br,Cr,As,Re,Ps,he,Ar,wt,Pr,Mr,Ms,Qe,Vs,ge,Ss,ne,_e,ss,Ye,Vr,as,Sr,Is,Q,Ir,yt,Wr,Lr,rs,Or,Nr,bt,Rr,Qr,He,os,Yr,Hr,Ue,ns,Ur,Gr,Ge,is,Jr,Xr,Ws,$e,Ls,ie,ve,ls,Je,Kr,fs,Zr,Os,we,eo,ps,to,so,Ns,ye,Rs,le,be,us,Xe,ao,cs,ro,Qs,ke,oo,kt,no,io,Ys,je,jt,qt,lo,fo,po,Z,Et,uo,co,Ke,mo,ho,ms,go,_o,Hs,Tt,$o,Us,qe,Gs,Ee,vo,ds,wo,yo,Js,Ze,Xs,Te,bo,xt,ko,jo,Ks,et,Zs,xe,qo,zt,Eo,To,ea,tt,ta,ze,sa,fe,Fe,hs,st,xo,gs,zo,aa,G,Fo,Ft,Do,Bo,Dt,Co,Ao,Bt,Po,Mo,ra,ee,Vo,Ct,So,Io,At,Wo,Lo,oa,at,na,De,ia,Be,Oo,Pt,No,Ro,la,rt,fa,Ce,Qo,Mt,Yo,Ho,pa,ot,ua,pe,Ae,_s,nt,Uo,$s,Go,ca,Pe,Jo,Vt,Xo,Ko,ma,St,Zo,da,it,ha,It,en,ga,lt,_a,Me,tn,Wt,sn,an,$a,ft,va,Lt,rn,wa;return v=new ct({}),Se=new ct({}),Ie=new L({props:{code:`from transformers import DistilBertConfig

config = DistilBertConfig()
print(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = DistilBertConfig()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(config)
DistilBertConfig {
  <span class="hljs-string">&quot;activation&quot;</span>: <span class="hljs-string">&quot;gelu&quot;</span>,
  <span class="hljs-string">&quot;attention_dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;dim&quot;</span>: <span class="hljs-number">768</span>,
  <span class="hljs-string">&quot;dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;hidden_dim&quot;</span>: <span class="hljs-number">3072</span>,
  <span class="hljs-string">&quot;initializer_range&quot;</span>: <span class="hljs-number">0.02</span>,
  <span class="hljs-string">&quot;max_position_embeddings&quot;</span>: <span class="hljs-number">512</span>,
  <span class="hljs-string">&quot;model_type&quot;</span>: <span class="hljs-string">&quot;distilbert&quot;</span>,
  <span class="hljs-string">&quot;n_heads&quot;</span>: <span class="hljs-number">12</span>,
  <span class="hljs-string">&quot;n_layers&quot;</span>: <span class="hljs-number">6</span>,
  <span class="hljs-string">&quot;pad_token_id&quot;</span>: <span class="hljs-number">0</span>,
  <span class="hljs-string">&quot;qa_dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;seq_classif_dropout&quot;</span>: <span class="hljs-number">0.2</span>,
  <span class="hljs-string">&quot;sinusoidal_pos_embds&quot;</span>: false,
  <span class="hljs-string">&quot;transformers_version&quot;</span>: <span class="hljs-string">&quot;4.16.2&quot;</span>,
  <span class="hljs-string">&quot;vocab_size&quot;</span>: <span class="hljs-number">30522</span>
}`}}),Oe=new L({props:{code:`my_config = DistilBertConfig(activation="relu", attention_dropout=0.4)
print(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig(activation=<span class="hljs-string">&quot;relu&quot;</span>, attention_dropout=<span class="hljs-number">0.4</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(my_config)
DistilBertConfig {
  <span class="hljs-string">&quot;activation&quot;</span>: <span class="hljs-string">&quot;relu&quot;</span>,
  <span class="hljs-string">&quot;attention_dropout&quot;</span>: <span class="hljs-number">0.4</span>,
  <span class="hljs-string">&quot;dim&quot;</span>: <span class="hljs-number">768</span>,
  <span class="hljs-string">&quot;dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;hidden_dim&quot;</span>: <span class="hljs-number">3072</span>,
  <span class="hljs-string">&quot;initializer_range&quot;</span>: <span class="hljs-number">0.02</span>,
  <span class="hljs-string">&quot;max_position_embeddings&quot;</span>: <span class="hljs-number">512</span>,
  <span class="hljs-string">&quot;model_type&quot;</span>: <span class="hljs-string">&quot;distilbert&quot;</span>,
  <span class="hljs-string">&quot;n_heads&quot;</span>: <span class="hljs-number">12</span>,
  <span class="hljs-string">&quot;n_layers&quot;</span>: <span class="hljs-number">6</span>,
  <span class="hljs-string">&quot;pad_token_id&quot;</span>: <span class="hljs-number">0</span>,
  <span class="hljs-string">&quot;qa_dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;seq_classif_dropout&quot;</span>: <span class="hljs-number">0.2</span>,
  <span class="hljs-string">&quot;sinusoidal_pos_embds&quot;</span>: false,
  <span class="hljs-string">&quot;transformers_version&quot;</span>: <span class="hljs-string">&quot;4.16.2&quot;</span>,
  <span class="hljs-string">&quot;vocab_size&quot;</span>: <span class="hljs-number">30522</span>
}`}}),Ne=new L({props:{code:'my_config = DistilBertConfig.from_pretrained("distilbert-base-uncased", activation="relu", attention_dropout=0.4)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, activation=<span class="hljs-string">&quot;relu&quot;</span>, attention_dropout=<span class="hljs-number">0.4</span>)'}}),Re=new L({props:{code:'my_config.save_pretrained(save_directory="./your_model_save_path")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>my_config.save_pretrained(save_directory=<span class="hljs-string">&quot;./your_model_save_path&quot;</span>)'}}),Qe=new L({props:{code:'my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;./your_model_save_path/my_config.json&quot;</span>)'}}),ge=new Na({props:{$$slots:{default:[Fi]},$$scope:{ctx:I}}}),Ye=new ct({}),$e=new ji({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Ai],pytorch:[Bi]},$$scope:{ctx:I}}}),Je=new ct({}),ye=new ji({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Si],pytorch:[Mi]},$$scope:{ctx:I}}}),Xe=new ct({}),qe=new Na({props:{warning:!0,$$slots:{default:[Ii]},$$scope:{ctx:I}}}),Ze=new L({props:{code:`from transformers import DistilBertTokenizer

my_tokenizer = DistilBertTokenizer(vocab_file="my_vocab_file.txt", do_lower_case=False, padding_side="left")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>my_tokenizer = DistilBertTokenizer(vocab_file=<span class="hljs-string">&quot;my_vocab_file.txt&quot;</span>, do_lower_case=<span class="hljs-literal">False</span>, padding_side=<span class="hljs-string">&quot;left&quot;</span>)`}}),et=new L({props:{code:`from transformers import DistilBertTokenizer

slow_tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>slow_tokenizer = DistilBertTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),tt=new L({props:{code:`from transformers import DistilBertTokenizerFast

fast_tokenizer = DistilBertTokenizerFast.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertTokenizerFast

<span class="hljs-meta">&gt;&gt;&gt; </span>fast_tokenizer = DistilBertTokenizerFast.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),ze=new Na({props:{$$slots:{default:[Wi]},$$scope:{ctx:I}}}),st=new ct({}),at=new L({props:{code:`from transformers import ViTFeatureExtractor

vit_extractor = ViTFeatureExtractor()
print(vit_extractor)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> ViTFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>vit_extractor = ViTFeatureExtractor()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(vit_extractor)
ViTFeatureExtractor {
  <span class="hljs-string">&quot;do_normalize&quot;</span>: true,
  <span class="hljs-string">&quot;do_resize&quot;</span>: true,
  <span class="hljs-string">&quot;feature_extractor_type&quot;</span>: <span class="hljs-string">&quot;ViTFeatureExtractor&quot;</span>,
  <span class="hljs-string">&quot;image_mean&quot;</span>: [
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>
  ],
  <span class="hljs-string">&quot;image_std&quot;</span>: [
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>
  ],
  <span class="hljs-string">&quot;resample&quot;</span>: <span class="hljs-number">2</span>,
  <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">224</span>
}`}}),De=new Na({props:{$$slots:{default:[Li]},$$scope:{ctx:I}}}),rt=new L({props:{code:`from transformers import ViTFeatureExtractor

my_vit_extractor = ViTFeatureExtractor(resample="PIL.Image.BOX", do_normalize=False, image_mean=[0.3, 0.3, 0.3])
print(my_vit_extractor)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> ViTFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>my_vit_extractor = ViTFeatureExtractor(resample=<span class="hljs-string">&quot;PIL.Image.BOX&quot;</span>, do_normalize=<span class="hljs-literal">False</span>, image_mean=[<span class="hljs-number">0.3</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.3</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(my_vit_extractor)
ViTFeatureExtractor {
  <span class="hljs-string">&quot;do_normalize&quot;</span>: false,
  <span class="hljs-string">&quot;do_resize&quot;</span>: true,
  <span class="hljs-string">&quot;feature_extractor_type&quot;</span>: <span class="hljs-string">&quot;ViTFeatureExtractor&quot;</span>,
  <span class="hljs-string">&quot;image_mean&quot;</span>: [
    <span class="hljs-number">0.3</span>,
    <span class="hljs-number">0.3</span>,
    <span class="hljs-number">0.3</span>
  ],
  <span class="hljs-string">&quot;image_std&quot;</span>: [
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>
  ],
  <span class="hljs-string">&quot;resample&quot;</span>: <span class="hljs-string">&quot;PIL.Image.BOX&quot;</span>,
  <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">224</span>
}`}}),ot=new L({props:{code:`from transformers import Wav2Vec2FeatureExtractor

w2v2_extractor = Wav2Vec2FeatureExtractor()
print(w2v2_extractor)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2FeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>w2v2_extractor = Wav2Vec2FeatureExtractor()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(w2v2_extractor)
Wav2Vec2FeatureExtractor {
  <span class="hljs-string">&quot;do_normalize&quot;</span>: true,
  <span class="hljs-string">&quot;feature_extractor_type&quot;</span>: <span class="hljs-string">&quot;Wav2Vec2FeatureExtractor&quot;</span>,
  <span class="hljs-string">&quot;feature_size&quot;</span>: <span class="hljs-number">1</span>,
  <span class="hljs-string">&quot;padding_side&quot;</span>: <span class="hljs-string">&quot;right&quot;</span>,
  <span class="hljs-string">&quot;padding_value&quot;</span>: <span class="hljs-number">0.0</span>,
  <span class="hljs-string">&quot;return_attention_mask&quot;</span>: false,
  <span class="hljs-string">&quot;sampling_rate&quot;</span>: <span class="hljs-number">16000</span>
}`}}),nt=new ct({}),it=new L({props:{code:`from transformers import Wav2Vec2FeatureExtractor

feature_extractor = Wav2Vec2FeatureExtractor(padding_value=1.0, do_normalize=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2FeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = Wav2Vec2FeatureExtractor(padding_value=<span class="hljs-number">1.0</span>, do_normalize=<span class="hljs-literal">True</span>)`}}),lt=new L({props:{code:`from transformers import Wav2Vec2CTCTokenizer

tokenizer = Wav2Vec2CTCTokenizer(vocab_file="my_vocab_file.txt")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2CTCTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = Wav2Vec2CTCTokenizer(vocab_file=<span class="hljs-string">&quot;my_vocab_file.txt&quot;</span>)`}}),ft=new L({props:{code:`from transformers import Wav2Vec2Processor

processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2Processor

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)`}}),{c(){p=o("meta"),$=m(),u=o("h1"),_=o("a"),y=o("span"),j(v.$$.fragment),w=m(),F=o("span"),b=a("Create a custom architecture"),W=m(),k=o("p"),S=a("An "),A=o("a"),M=o("code"),D=a("AutoClass"),V=a(" automatically infers the model architecture and downloads pretrained configuration and weights. Generally, we recommend using an "),h=o("code"),C=a("AutoClass"),N=a(" to produce checkpoint-agnostic code. But users who want more control over specific model parameters can create a custom \u{1F917} Transformers model from just a few base classes. This could be particularly useful for anyone who is interested in studying, training or experimenting with a \u{1F917} Transformers model. In this guide, dive deeper into creating a custom model without an "),P=o("code"),R=a("AutoClass"),c=a(". Learn how to:"),B=m(),O=o("ul"),H=o("li"),se=a("Load and customize a model configuration."),ae=m(),Rt=o("li"),Ya=a("Create a model architecture."),Ha=m(),Qt=o("li"),Ua=a("Create a slow and fast tokenizer for text."),Ga=m(),Yt=o("li"),Ja=a("Create a feature extractor for audio or image tasks."),Xa=m(),Ht=o("li"),Ka=a("Create a processor for multimodal tasks."),js=m(),re=o("h2"),ue=o("a"),Ut=o("span"),j(Se.$$.fragment),Za=m(),Gt=o("span"),er=a("Configuration"),qs=m(),Y=o("p"),tr=a("A "),mt=o("a"),sr=a("configuration"),ar=a(" refers to a model\u2019s specific attributes. Each model configuration has different attributes; for instance, all NLP models have the "),Jt=o("code"),rr=a("hidden_size"),or=a(", "),Xt=o("code"),nr=a("num_attention_heads"),ir=a(", "),Kt=o("code"),lr=a("num_hidden_layers"),fr=a(" and "),Zt=o("code"),pr=a("vocab_size"),ur=a(" attributes in common. These attributes specify the number of attention heads or hidden layers to construct a model with."),Es=m(),K=o("p"),cr=a("Get a closer look at "),dt=o("a"),mr=a("DistilBERT"),dr=a(" by accessing "),ht=o("a"),hr=a("DistilBertConfig"),gr=a(" to inspect it\u2019s attributes:"),Ts=m(),j(Ie.$$.fragment),xs=m(),oe=o("p"),gt=o("a"),_r=a("DistilBertConfig"),$r=a(" displays all the default attributes used to build a base "),_t=o("a"),vr=a("DistilBertModel"),wr=a(". All attributes are customizable, creating space for experimentation. For example, you can customize a default model to:"),zs=m(),ce=o("ul"),We=o("li"),yr=a("Try a different activation function with the "),es=o("code"),br=a("activation"),kr=a(" parameter."),jr=m(),Le=o("li"),qr=a("Use a higher dropout ratio for the attention probabilities with the "),ts=o("code"),Er=a("attention_dropout"),Tr=a(" parameter."),Fs=m(),j(Oe.$$.fragment),Ds=m(),me=o("p"),xr=a("Pretrained model attributes can be modified in the "),$t=o("a"),zr=a("from_pretrained()"),Fr=a(" function:"),Bs=m(),j(Ne.$$.fragment),Cs=m(),de=o("p"),Dr=a("Once you are satisfied with your model configuration, you can save it with "),vt=o("a"),Br=a("save_pretrained()"),Cr=a(". Your configuration file is stored as a JSON file in the specified save directory:"),As=m(),j(Re.$$.fragment),Ps=m(),he=o("p"),Ar=a("To reuse the configuration file, load it with "),wt=o("a"),Pr=a("from_pretrained()"),Mr=a(":"),Ms=m(),j(Qe.$$.fragment),Vs=m(),j(ge.$$.fragment),Ss=m(),ne=o("h2"),_e=o("a"),ss=o("span"),j(Ye.$$.fragment),Vr=m(),as=o("span"),Sr=a("Model"),Is=m(),Q=o("p"),Ir=a("The next step is to create a "),yt=o("a"),Wr=a("model"),Lr=a(". The model - also loosely referred to as the architecture - defines what each layer is doing and what operations are happening. Attributes like "),rs=o("code"),Or=a("num_hidden_layers"),Nr=a(" from the configuration are used to define the architecture. Every model shares the base class "),bt=o("a"),Rr=a("PreTrainedModel"),Qr=a(" and a few common methods like resizing input embeddings and pruning self-attention heads. In addition, all models are also either a "),He=o("a"),os=o("code"),Yr=a("torch.nn.Module"),Hr=a(", "),Ue=o("a"),ns=o("code"),Ur=a("tf.keras.Model"),Gr=a(" or "),Ge=o("a"),is=o("code"),Jr=a("flax.linen.Module"),Xr=a(" subclass. This means models are compatible with each of their respective framework\u2019s usage."),Ws=m(),j($e.$$.fragment),Ls=m(),ie=o("h3"),ve=o("a"),ls=o("span"),j(Je.$$.fragment),Kr=m(),fs=o("span"),Zr=a("Model heads"),Os=m(),we=o("p"),eo=a("At this point, you have a base DistilBERT model which outputs the "),ps=o("em"),to=a("hidden states"),so=a(". The hidden states are passed as inputs to a model head to produce the final output. \u{1F917} Transformers provides a different model head for each task as long as a model supports the task (i.e., you can\u2019t use DistilBERT for a sequence-to-sequence task like translation)."),Ns=m(),j(ye.$$.fragment),Rs=m(),le=o("h2"),be=o("a"),us=o("span"),j(Xe.$$.fragment),ao=m(),cs=o("span"),ro=a("Tokenizer"),Qs=m(),ke=o("p"),oo=a("The last base class you need before using a model for textual data is a "),kt=o("a"),no=a("tokenizer"),io=a(" to convert raw text to tensors. There are two types of tokenizers you can use with \u{1F917} Transformers:"),Ys=m(),je=o("ul"),jt=o("li"),qt=o("a"),lo=a("PreTrainedTokenizer"),fo=a(": a Python implementation of a tokenizer."),po=m(),Z=o("li"),Et=o("a"),uo=a("PreTrainedTokenizerFast"),co=a(": a tokenizer from our Rust-based "),Ke=o("a"),mo=a("\u{1F917} Tokenizer"),ho=a(" library. This tokenizer type is significantly faster - especially during batch tokenization - due to it\u2019s Rust implementation. The fast tokenizer also offers additional methods like "),ms=o("em"),go=a("offset mapping"),_o=a(" which maps tokens to their original words or characters."),Hs=m(),Tt=o("p"),$o=a("Both tokenizers support common methods such as encoding and decoding, adding new tokens, and managing special tokens."),Us=m(),j(qe.$$.fragment),Gs=m(),Ee=o("p"),vo=a("If you trained your own tokenizer, you can create one from your "),ds=o("em"),wo=a("vocabulary"),yo=a(" file:"),Js=m(),j(Ze.$$.fragment),Xs=m(),Te=o("p"),bo=a("It is important to remember the vocabulary from a custom tokenizer will be different from the vocabulary generated by a pretrained model\u2019s tokenizer. You need to use a pretrained model\u2019s vocabulary if you are using a pretrained model, otherwise the inputs won\u2019t make sense. Create a tokenizer with a pretrained model\u2019s vocabulary with the "),xt=o("a"),ko=a("DistilBertTokenizer"),jo=a(" class:"),Ks=m(),j(et.$$.fragment),Zs=m(),xe=o("p"),qo=a("Create a fast tokenizer with the "),zt=o("a"),Eo=a("DistilBertTokenizerFast"),To=a(" class:"),ea=m(),j(tt.$$.fragment),ta=m(),j(ze.$$.fragment),sa=m(),fe=o("h2"),Fe=o("a"),hs=o("span"),j(st.$$.fragment),xo=m(),gs=o("span"),zo=a("Feature Extractor"),aa=m(),G=o("p"),Fo=a("A feature extractor processes audio or image inputs. It inherits from the base "),Ft=o("a"),Do=a("FeatureExtractionMixin"),Bo=a(" class, and may also inherit from the "),Dt=o("a"),Co=a("ImageFeatureExtractionMixin"),Ao=a(" class for processing image features or the "),Bt=o("a"),Po=a("SequenceFeatureExtractor"),Mo=a(" class for processing audio inputs."),ra=m(),ee=o("p"),Vo=a("Depending on whether you are working on an audio or vision task, create a feature extractor associated with the model you\u2019re using. For example, create a default "),Ct=o("a"),So=a("ViTFeatureExtractor"),Io=a(" if you are using "),At=o("a"),Wo=a("ViT"),Lo=a(" for image classification:"),oa=m(),j(at.$$.fragment),na=m(),j(De.$$.fragment),ia=m(),Be=o("p"),Oo=a("Modify any of the "),Pt=o("a"),No=a("ViTFeatureExtractor"),Ro=a(" parameters to create your custom feature extractor:"),la=m(),j(rt.$$.fragment),fa=m(),Ce=o("p"),Qo=a("For audio inputs, you can create a "),Mt=o("a"),Yo=a("Wav2Vec2FeatureExtractor"),Ho=a(" and customize the parameters in a similar way:"),pa=m(),j(ot.$$.fragment),ua=m(),pe=o("h2"),Ae=o("a"),_s=o("span"),j(nt.$$.fragment),Uo=m(),$s=o("span"),Go=a("Processor"),ca=m(),Pe=o("p"),Jo=a("For models that support multimodal tasks, \u{1F917} Transformers offers a processor class that conveniently wraps a feature extractor and tokenizer into a single object. For example, let\u2019s use the "),Vt=o("a"),Xo=a("Wav2Vec2Processor"),Ko=a(" for an automatic speech recognition task (ASR). ASR transcribes audio to text, so you will need a feature extractor and a tokenizer."),ma=m(),St=o("p"),Zo=a("Create a feature extractor to handle the audio inputs:"),da=m(),j(it.$$.fragment),ha=m(),It=o("p"),en=a("Create a tokenizer to handle the text inputs:"),ga=m(),j(lt.$$.fragment),_a=m(),Me=o("p"),tn=a("Combine the feature extractor and tokenizer in "),Wt=o("a"),sn=a("Wav2Vec2Processor"),an=a(":"),$a=m(),j(ft.$$.fragment),va=m(),Lt=o("p"),rn=a("With two basic classes - configuration and model - and an additional preprocessing class (tokenizer, feature extractor, or processor), you can create any of the models supported by \u{1F917} Transformers. Each of these base classes are configurable, allowing you to use the specific attributes you want. You can easily setup a model for training or modify an existing pretrained model to fine-tune."),this.h()},l(e){const l=xi('[data-svelte="svelte-1phssyn"]',document.head);p=n(l,"META",{name:!0,content:!0}),l.forEach(s),$=d(e),u=n(e,"H1",{class:!0});var pt=i(u);_=n(pt,"A",{id:!0,class:!0,href:!0});var vs=i(_);y=n(vs,"SPAN",{});var ws=i(y);q(v.$$.fragment,ws),ws.forEach(s),vs.forEach(s),w=d(pt),F=n(pt,"SPAN",{});var ys=i(F);b=r(ys,"Create a custom architecture"),ys.forEach(s),pt.forEach(s),W=d(e),k=n(e,"P",{});var X=i(k);S=r(X,"An "),A=n(X,"A",{href:!0});var bs=i(A);M=n(bs,"CODE",{});var nn=i(M);D=r(nn,"AutoClass"),nn.forEach(s),bs.forEach(s),V=r(X," automatically infers the model architecture and downloads pretrained configuration and weights. Generally, we recommend using an "),h=n(X,"CODE",{});var ln=i(h);C=r(ln,"AutoClass"),ln.forEach(s),N=r(X," to produce checkpoint-agnostic code. But users who want more control over specific model parameters can create a custom \u{1F917} Transformers model from just a few base classes. This could be particularly useful for anyone who is interested in studying, training or experimenting with a \u{1F917} Transformers model. In this guide, dive deeper into creating a custom model without an "),P=n(X,"CODE",{});var fn=i(P);R=r(fn,"AutoClass"),fn.forEach(s),c=r(X,". Learn how to:"),X.forEach(s),B=d(e),O=n(e,"UL",{});var te=i(O);H=n(te,"LI",{});var pn=i(H);se=r(pn,"Load and customize a model configuration."),pn.forEach(s),ae=d(te),Rt=n(te,"LI",{});var un=i(Rt);Ya=r(un,"Create a model architecture."),un.forEach(s),Ha=d(te),Qt=n(te,"LI",{});var cn=i(Qt);Ua=r(cn,"Create a slow and fast tokenizer for text."),cn.forEach(s),Ga=d(te),Yt=n(te,"LI",{});var mn=i(Yt);Ja=r(mn,"Create a feature extractor for audio or image tasks."),mn.forEach(s),Xa=d(te),Ht=n(te,"LI",{});var dn=i(Ht);Ka=r(dn,"Create a processor for multimodal tasks."),dn.forEach(s),te.forEach(s),js=d(e),re=n(e,"H2",{class:!0});var ya=i(re);ue=n(ya,"A",{id:!0,class:!0,href:!0});var hn=i(ue);Ut=n(hn,"SPAN",{});var gn=i(Ut);q(Se.$$.fragment,gn),gn.forEach(s),hn.forEach(s),Za=d(ya),Gt=n(ya,"SPAN",{});var _n=i(Gt);er=r(_n,"Configuration"),_n.forEach(s),ya.forEach(s),qs=d(e),Y=n(e,"P",{});var J=i(Y);tr=r(J,"A "),mt=n(J,"A",{href:!0});var $n=i(mt);sr=r($n,"configuration"),$n.forEach(s),ar=r(J," refers to a model\u2019s specific attributes. Each model configuration has different attributes; for instance, all NLP models have the "),Jt=n(J,"CODE",{});var vn=i(Jt);rr=r(vn,"hidden_size"),vn.forEach(s),or=r(J,", "),Xt=n(J,"CODE",{});var wn=i(Xt);nr=r(wn,"num_attention_heads"),wn.forEach(s),ir=r(J,", "),Kt=n(J,"CODE",{});var yn=i(Kt);lr=r(yn,"num_hidden_layers"),yn.forEach(s),fr=r(J," and "),Zt=n(J,"CODE",{});var bn=i(Zt);pr=r(bn,"vocab_size"),bn.forEach(s),ur=r(J," attributes in common. These attributes specify the number of attention heads or hidden layers to construct a model with."),J.forEach(s),Es=d(e),K=n(e,"P",{});var Ot=i(K);cr=r(Ot,"Get a closer look at "),dt=n(Ot,"A",{href:!0});var kn=i(dt);mr=r(kn,"DistilBERT"),kn.forEach(s),dr=r(Ot," by accessing "),ht=n(Ot,"A",{href:!0});var jn=i(ht);hr=r(jn,"DistilBertConfig"),jn.forEach(s),gr=r(Ot," to inspect it\u2019s attributes:"),Ot.forEach(s),Ts=d(e),q(Ie.$$.fragment,e),xs=d(e),oe=n(e,"P",{});var ks=i(oe);gt=n(ks,"A",{href:!0});var qn=i(gt);_r=r(qn,"DistilBertConfig"),qn.forEach(s),$r=r(ks," displays all the default attributes used to build a base "),_t=n(ks,"A",{href:!0});var En=i(_t);vr=r(En,"DistilBertModel"),En.forEach(s),wr=r(ks,". All attributes are customizable, creating space for experimentation. For example, you can customize a default model to:"),ks.forEach(s),zs=d(e),ce=n(e,"UL",{});var ba=i(ce);We=n(ba,"LI",{});var ka=i(We);yr=r(ka,"Try a different activation function with the "),es=n(ka,"CODE",{});var Tn=i(es);br=r(Tn,"activation"),Tn.forEach(s),kr=r(ka," parameter."),ka.forEach(s),jr=d(ba),Le=n(ba,"LI",{});var ja=i(Le);qr=r(ja,"Use a higher dropout ratio for the attention probabilities with the "),ts=n(ja,"CODE",{});var xn=i(ts);Er=r(xn,"attention_dropout"),xn.forEach(s),Tr=r(ja," parameter."),ja.forEach(s),ba.forEach(s),Fs=d(e),q(Oe.$$.fragment,e),Ds=d(e),me=n(e,"P",{});var qa=i(me);xr=r(qa,"Pretrained model attributes can be modified in the "),$t=n(qa,"A",{href:!0});var zn=i($t);zr=r(zn,"from_pretrained()"),zn.forEach(s),Fr=r(qa," function:"),qa.forEach(s),Bs=d(e),q(Ne.$$.fragment,e),Cs=d(e),de=n(e,"P",{});var Ea=i(de);Dr=r(Ea,"Once you are satisfied with your model configuration, you can save it with "),vt=n(Ea,"A",{href:!0});var Fn=i(vt);Br=r(Fn,"save_pretrained()"),Fn.forEach(s),Cr=r(Ea,". Your configuration file is stored as a JSON file in the specified save directory:"),Ea.forEach(s),As=d(e),q(Re.$$.fragment,e),Ps=d(e),he=n(e,"P",{});var Ta=i(he);Ar=r(Ta,"To reuse the configuration file, load it with "),wt=n(Ta,"A",{href:!0});var Dn=i(wt);Pr=r(Dn,"from_pretrained()"),Dn.forEach(s),Mr=r(Ta,":"),Ta.forEach(s),Ms=d(e),q(Qe.$$.fragment,e),Vs=d(e),q(ge.$$.fragment,e),Ss=d(e),ne=n(e,"H2",{class:!0});var xa=i(ne);_e=n(xa,"A",{id:!0,class:!0,href:!0});var Bn=i(_e);ss=n(Bn,"SPAN",{});var Cn=i(ss);q(Ye.$$.fragment,Cn),Cn.forEach(s),Bn.forEach(s),Vr=d(xa),as=n(xa,"SPAN",{});var An=i(as);Sr=r(An,"Model"),An.forEach(s),xa.forEach(s),Is=d(e),Q=n(e,"P",{});var U=i(Q);Ir=r(U,"The next step is to create a "),yt=n(U,"A",{href:!0});var Pn=i(yt);Wr=r(Pn,"model"),Pn.forEach(s),Lr=r(U,". The model - also loosely referred to as the architecture - defines what each layer is doing and what operations are happening. Attributes like "),rs=n(U,"CODE",{});var Mn=i(rs);Or=r(Mn,"num_hidden_layers"),Mn.forEach(s),Nr=r(U," from the configuration are used to define the architecture. Every model shares the base class "),bt=n(U,"A",{href:!0});var Vn=i(bt);Rr=r(Vn,"PreTrainedModel"),Vn.forEach(s),Qr=r(U," and a few common methods like resizing input embeddings and pruning self-attention heads. In addition, all models are also either a "),He=n(U,"A",{href:!0,rel:!0});var Sn=i(He);os=n(Sn,"CODE",{});var In=i(os);Yr=r(In,"torch.nn.Module"),In.forEach(s),Sn.forEach(s),Hr=r(U,", "),Ue=n(U,"A",{href:!0,rel:!0});var Wn=i(Ue);ns=n(Wn,"CODE",{});var Ln=i(ns);Ur=r(Ln,"tf.keras.Model"),Ln.forEach(s),Wn.forEach(s),Gr=r(U," or "),Ge=n(U,"A",{href:!0,rel:!0});var On=i(Ge);is=n(On,"CODE",{});var Nn=i(is);Jr=r(Nn,"flax.linen.Module"),Nn.forEach(s),On.forEach(s),Xr=r(U," subclass. This means models are compatible with each of their respective framework\u2019s usage."),U.forEach(s),Ws=d(e),q($e.$$.fragment,e),Ls=d(e),ie=n(e,"H3",{class:!0});var za=i(ie);ve=n(za,"A",{id:!0,class:!0,href:!0});var Rn=i(ve);ls=n(Rn,"SPAN",{});var Qn=i(ls);q(Je.$$.fragment,Qn),Qn.forEach(s),Rn.forEach(s),Kr=d(za),fs=n(za,"SPAN",{});var Yn=i(fs);Zr=r(Yn,"Model heads"),Yn.forEach(s),za.forEach(s),Os=d(e),we=n(e,"P",{});var Fa=i(we);eo=r(Fa,"At this point, you have a base DistilBERT model which outputs the "),ps=n(Fa,"EM",{});var Hn=i(ps);to=r(Hn,"hidden states"),Hn.forEach(s),so=r(Fa,". The hidden states are passed as inputs to a model head to produce the final output. \u{1F917} Transformers provides a different model head for each task as long as a model supports the task (i.e., you can\u2019t use DistilBERT for a sequence-to-sequence task like translation)."),Fa.forEach(s),Ns=d(e),q(ye.$$.fragment,e),Rs=d(e),le=n(e,"H2",{class:!0});var Da=i(le);be=n(Da,"A",{id:!0,class:!0,href:!0});var Un=i(be);us=n(Un,"SPAN",{});var Gn=i(us);q(Xe.$$.fragment,Gn),Gn.forEach(s),Un.forEach(s),ao=d(Da),cs=n(Da,"SPAN",{});var Jn=i(cs);ro=r(Jn,"Tokenizer"),Jn.forEach(s),Da.forEach(s),Qs=d(e),ke=n(e,"P",{});var Ba=i(ke);oo=r(Ba,"The last base class you need before using a model for textual data is a "),kt=n(Ba,"A",{href:!0});var Xn=i(kt);no=r(Xn,"tokenizer"),Xn.forEach(s),io=r(Ba," to convert raw text to tensors. There are two types of tokenizers you can use with \u{1F917} Transformers:"),Ba.forEach(s),Ys=d(e),je=n(e,"UL",{});var Ca=i(je);jt=n(Ca,"LI",{});var on=i(jt);qt=n(on,"A",{href:!0});var Kn=i(qt);lo=r(Kn,"PreTrainedTokenizer"),Kn.forEach(s),fo=r(on,": a Python implementation of a tokenizer."),on.forEach(s),po=d(Ca),Z=n(Ca,"LI",{});var ut=i(Z);Et=n(ut,"A",{href:!0});var Zn=i(Et);uo=r(Zn,"PreTrainedTokenizerFast"),Zn.forEach(s),co=r(ut,": a tokenizer from our Rust-based "),Ke=n(ut,"A",{href:!0,rel:!0});var ei=i(Ke);mo=r(ei,"\u{1F917} Tokenizer"),ei.forEach(s),ho=r(ut," library. This tokenizer type is significantly faster - especially during batch tokenization - due to it\u2019s Rust implementation. The fast tokenizer also offers additional methods like "),ms=n(ut,"EM",{});var ti=i(ms);go=r(ti,"offset mapping"),ti.forEach(s),_o=r(ut," which maps tokens to their original words or characters."),ut.forEach(s),Ca.forEach(s),Hs=d(e),Tt=n(e,"P",{});var si=i(Tt);$o=r(si,"Both tokenizers support common methods such as encoding and decoding, adding new tokens, and managing special tokens."),si.forEach(s),Us=d(e),q(qe.$$.fragment,e),Gs=d(e),Ee=n(e,"P",{});var Aa=i(Ee);vo=r(Aa,"If you trained your own tokenizer, you can create one from your "),ds=n(Aa,"EM",{});var ai=i(ds);wo=r(ai,"vocabulary"),ai.forEach(s),yo=r(Aa," file:"),Aa.forEach(s),Js=d(e),q(Ze.$$.fragment,e),Xs=d(e),Te=n(e,"P",{});var Pa=i(Te);bo=r(Pa,"It is important to remember the vocabulary from a custom tokenizer will be different from the vocabulary generated by a pretrained model\u2019s tokenizer. You need to use a pretrained model\u2019s vocabulary if you are using a pretrained model, otherwise the inputs won\u2019t make sense. Create a tokenizer with a pretrained model\u2019s vocabulary with the "),xt=n(Pa,"A",{href:!0});var ri=i(xt);ko=r(ri,"DistilBertTokenizer"),ri.forEach(s),jo=r(Pa," class:"),Pa.forEach(s),Ks=d(e),q(et.$$.fragment,e),Zs=d(e),xe=n(e,"P",{});var Ma=i(xe);qo=r(Ma,"Create a fast tokenizer with the "),zt=n(Ma,"A",{href:!0});var oi=i(zt);Eo=r(oi,"DistilBertTokenizerFast"),oi.forEach(s),To=r(Ma," class:"),Ma.forEach(s),ea=d(e),q(tt.$$.fragment,e),ta=d(e),q(ze.$$.fragment,e),sa=d(e),fe=n(e,"H2",{class:!0});var Va=i(fe);Fe=n(Va,"A",{id:!0,class:!0,href:!0});var ni=i(Fe);hs=n(ni,"SPAN",{});var ii=i(hs);q(st.$$.fragment,ii),ii.forEach(s),ni.forEach(s),xo=d(Va),gs=n(Va,"SPAN",{});var li=i(gs);zo=r(li,"Feature Extractor"),li.forEach(s),Va.forEach(s),aa=d(e),G=n(e,"P",{});var Ve=i(G);Fo=r(Ve,"A feature extractor processes audio or image inputs. It inherits from the base "),Ft=n(Ve,"A",{href:!0});var fi=i(Ft);Do=r(fi,"FeatureExtractionMixin"),fi.forEach(s),Bo=r(Ve," class, and may also inherit from the "),Dt=n(Ve,"A",{href:!0});var pi=i(Dt);Co=r(pi,"ImageFeatureExtractionMixin"),pi.forEach(s),Ao=r(Ve," class for processing image features or the "),Bt=n(Ve,"A",{href:!0});var ui=i(Bt);Po=r(ui,"SequenceFeatureExtractor"),ui.forEach(s),Mo=r(Ve," class for processing audio inputs."),Ve.forEach(s),ra=d(e),ee=n(e,"P",{});var Nt=i(ee);Vo=r(Nt,"Depending on whether you are working on an audio or vision task, create a feature extractor associated with the model you\u2019re using. For example, create a default "),Ct=n(Nt,"A",{href:!0});var ci=i(Ct);So=r(ci,"ViTFeatureExtractor"),ci.forEach(s),Io=r(Nt," if you are using "),At=n(Nt,"A",{href:!0});var mi=i(At);Wo=r(mi,"ViT"),mi.forEach(s),Lo=r(Nt," for image classification:"),Nt.forEach(s),oa=d(e),q(at.$$.fragment,e),na=d(e),q(De.$$.fragment,e),ia=d(e),Be=n(e,"P",{});var Sa=i(Be);Oo=r(Sa,"Modify any of the "),Pt=n(Sa,"A",{href:!0});var di=i(Pt);No=r(di,"ViTFeatureExtractor"),di.forEach(s),Ro=r(Sa," parameters to create your custom feature extractor:"),Sa.forEach(s),la=d(e),q(rt.$$.fragment,e),fa=d(e),Ce=n(e,"P",{});var Ia=i(Ce);Qo=r(Ia,"For audio inputs, you can create a "),Mt=n(Ia,"A",{href:!0});var hi=i(Mt);Yo=r(hi,"Wav2Vec2FeatureExtractor"),hi.forEach(s),Ho=r(Ia," and customize the parameters in a similar way:"),Ia.forEach(s),pa=d(e),q(ot.$$.fragment,e),ua=d(e),pe=n(e,"H2",{class:!0});var Wa=i(pe);Ae=n(Wa,"A",{id:!0,class:!0,href:!0});var gi=i(Ae);_s=n(gi,"SPAN",{});var _i=i(_s);q(nt.$$.fragment,_i),_i.forEach(s),gi.forEach(s),Uo=d(Wa),$s=n(Wa,"SPAN",{});var $i=i($s);Go=r($i,"Processor"),$i.forEach(s),Wa.forEach(s),ca=d(e),Pe=n(e,"P",{});var La=i(Pe);Jo=r(La,"For models that support multimodal tasks, \u{1F917} Transformers offers a processor class that conveniently wraps a feature extractor and tokenizer into a single object. For example, let\u2019s use the "),Vt=n(La,"A",{href:!0});var vi=i(Vt);Xo=r(vi,"Wav2Vec2Processor"),vi.forEach(s),Ko=r(La," for an automatic speech recognition task (ASR). ASR transcribes audio to text, so you will need a feature extractor and a tokenizer."),La.forEach(s),ma=d(e),St=n(e,"P",{});var wi=i(St);Zo=r(wi,"Create a feature extractor to handle the audio inputs:"),wi.forEach(s),da=d(e),q(it.$$.fragment,e),ha=d(e),It=n(e,"P",{});var yi=i(It);en=r(yi,"Create a tokenizer to handle the text inputs:"),yi.forEach(s),ga=d(e),q(lt.$$.fragment,e),_a=d(e),Me=n(e,"P",{});var Oa=i(Me);tn=r(Oa,"Combine the feature extractor and tokenizer in "),Wt=n(Oa,"A",{href:!0});var bi=i(Wt);sn=r(bi,"Wav2Vec2Processor"),bi.forEach(s),an=r(Oa,":"),Oa.forEach(s),$a=d(e),q(ft.$$.fragment,e),va=d(e),Lt=n(e,"P",{});var ki=i(Lt);rn=r(ki,"With two basic classes - configuration and model - and an additional preprocessing class (tokenizer, feature extractor, or processor), you can create any of the models supported by \u{1F917} Transformers. Each of these base classes are configurable, allowing you to use the specific attributes you want. You can easily setup a model for training or modify an existing pretrained model to fine-tune."),ki.forEach(s),this.h()},h(){g(p,"name","hf:doc:metadata"),g(p,"content",JSON.stringify(Ni)),g(_,"id","create-a-custom-architecture"),g(_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(_,"href","#create-a-custom-architecture"),g(u,"class","relative group"),g(A,"href","model_doc/auto"),g(ue,"id","configuration"),g(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(ue,"href","#configuration"),g(re,"class","relative group"),g(mt,"href","main_classes/configuration"),g(dt,"href","model_doc/distilbert"),g(ht,"href","/docs/transformers/v4.22.2/en/model_doc/distilbert#transformers.DistilBertConfig"),g(gt,"href","/docs/transformers/v4.22.2/en/model_doc/distilbert#transformers.DistilBertConfig"),g(_t,"href","/docs/transformers/v4.22.2/en/model_doc/distilbert#transformers.DistilBertModel"),g($t,"href","/docs/transformers/v4.22.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained"),g(vt,"href","/docs/transformers/v4.22.2/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained"),g(wt,"href","/docs/transformers/v4.22.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained"),g(_e,"id","model"),g(_e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(_e,"href","#model"),g(ne,"class","relative group"),g(yt,"href","main_classes/models"),g(bt,"href","/docs/transformers/v4.22.2/en/main_classes/model#transformers.PreTrainedModel"),g(He,"href","https://pytorch.org/docs/stable/generated/torch.nn.Module.html"),g(He,"rel","nofollow"),g(Ue,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),g(Ue,"rel","nofollow"),g(Ge,"href","https://flax.readthedocs.io/en/latest/flax.linen.html#module"),g(Ge,"rel","nofollow"),g(ve,"id","model-heads"),g(ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(ve,"href","#model-heads"),g(ie,"class","relative group"),g(be,"id","tokenizer"),g(be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(be,"href","#tokenizer"),g(le,"class","relative group"),g(kt,"href","main_classes/tokenizer"),g(qt,"href","/docs/transformers/v4.22.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer"),g(Et,"href","/docs/transformers/v4.22.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast"),g(Ke,"href","https://huggingface.co/docs/tokenizers/python/latest/"),g(Ke,"rel","nofollow"),g(xt,"href","/docs/transformers/v4.22.2/en/model_doc/distilbert#transformers.DistilBertTokenizer"),g(zt,"href","/docs/transformers/v4.22.2/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),g(Fe,"id","feature-extractor"),g(Fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(Fe,"href","#feature-extractor"),g(fe,"class","relative group"),g(Ft,"href","/docs/transformers/v4.22.2/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin"),g(Dt,"href","/docs/transformers/v4.22.2/en/main_classes/feature_extractor#transformers.ImageFeatureExtractionMixin"),g(Bt,"href","/docs/transformers/v4.22.2/en/main_classes/feature_extractor#transformers.SequenceFeatureExtractor"),g(Ct,"href","/docs/transformers/v4.22.2/en/model_doc/vit#transformers.ViTFeatureExtractor"),g(At,"href","model_doc/vit"),g(Pt,"href","/docs/transformers/v4.22.2/en/model_doc/vit#transformers.ViTFeatureExtractor"),g(Mt,"href","/docs/transformers/v4.22.2/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),g(Ae,"id","processor"),g(Ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(Ae,"href","#processor"),g(pe,"class","relative group"),g(Vt,"href","/docs/transformers/v4.22.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),g(Wt,"href","/docs/transformers/v4.22.2/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor")},m(e,l){t(document.head,p),f(e,$,l),f(e,u,l),t(u,_),t(_,y),E(v,y,null),t(u,w),t(u,F),t(F,b),f(e,W,l),f(e,k,l),t(k,S),t(k,A),t(A,M),t(M,D),t(k,V),t(k,h),t(h,C),t(k,N),t(k,P),t(P,R),t(k,c),f(e,B,l),f(e,O,l),t(O,H),t(H,se),t(O,ae),t(O,Rt),t(Rt,Ya),t(O,Ha),t(O,Qt),t(Qt,Ua),t(O,Ga),t(O,Yt),t(Yt,Ja),t(O,Xa),t(O,Ht),t(Ht,Ka),f(e,js,l),f(e,re,l),t(re,ue),t(ue,Ut),E(Se,Ut,null),t(re,Za),t(re,Gt),t(Gt,er),f(e,qs,l),f(e,Y,l),t(Y,tr),t(Y,mt),t(mt,sr),t(Y,ar),t(Y,Jt),t(Jt,rr),t(Y,or),t(Y,Xt),t(Xt,nr),t(Y,ir),t(Y,Kt),t(Kt,lr),t(Y,fr),t(Y,Zt),t(Zt,pr),t(Y,ur),f(e,Es,l),f(e,K,l),t(K,cr),t(K,dt),t(dt,mr),t(K,dr),t(K,ht),t(ht,hr),t(K,gr),f(e,Ts,l),E(Ie,e,l),f(e,xs,l),f(e,oe,l),t(oe,gt),t(gt,_r),t(oe,$r),t(oe,_t),t(_t,vr),t(oe,wr),f(e,zs,l),f(e,ce,l),t(ce,We),t(We,yr),t(We,es),t(es,br),t(We,kr),t(ce,jr),t(ce,Le),t(Le,qr),t(Le,ts),t(ts,Er),t(Le,Tr),f(e,Fs,l),E(Oe,e,l),f(e,Ds,l),f(e,me,l),t(me,xr),t(me,$t),t($t,zr),t(me,Fr),f(e,Bs,l),E(Ne,e,l),f(e,Cs,l),f(e,de,l),t(de,Dr),t(de,vt),t(vt,Br),t(de,Cr),f(e,As,l),E(Re,e,l),f(e,Ps,l),f(e,he,l),t(he,Ar),t(he,wt),t(wt,Pr),t(he,Mr),f(e,Ms,l),E(Qe,e,l),f(e,Vs,l),E(ge,e,l),f(e,Ss,l),f(e,ne,l),t(ne,_e),t(_e,ss),E(Ye,ss,null),t(ne,Vr),t(ne,as),t(as,Sr),f(e,Is,l),f(e,Q,l),t(Q,Ir),t(Q,yt),t(yt,Wr),t(Q,Lr),t(Q,rs),t(rs,Or),t(Q,Nr),t(Q,bt),t(bt,Rr),t(Q,Qr),t(Q,He),t(He,os),t(os,Yr),t(Q,Hr),t(Q,Ue),t(Ue,ns),t(ns,Ur),t(Q,Gr),t(Q,Ge),t(Ge,is),t(is,Jr),t(Q,Xr),f(e,Ws,l),E($e,e,l),f(e,Ls,l),f(e,ie,l),t(ie,ve),t(ve,ls),E(Je,ls,null),t(ie,Kr),t(ie,fs),t(fs,Zr),f(e,Os,l),f(e,we,l),t(we,eo),t(we,ps),t(ps,to),t(we,so),f(e,Ns,l),E(ye,e,l),f(e,Rs,l),f(e,le,l),t(le,be),t(be,us),E(Xe,us,null),t(le,ao),t(le,cs),t(cs,ro),f(e,Qs,l),f(e,ke,l),t(ke,oo),t(ke,kt),t(kt,no),t(ke,io),f(e,Ys,l),f(e,je,l),t(je,jt),t(jt,qt),t(qt,lo),t(jt,fo),t(je,po),t(je,Z),t(Z,Et),t(Et,uo),t(Z,co),t(Z,Ke),t(Ke,mo),t(Z,ho),t(Z,ms),t(ms,go),t(Z,_o),f(e,Hs,l),f(e,Tt,l),t(Tt,$o),f(e,Us,l),E(qe,e,l),f(e,Gs,l),f(e,Ee,l),t(Ee,vo),t(Ee,ds),t(ds,wo),t(Ee,yo),f(e,Js,l),E(Ze,e,l),f(e,Xs,l),f(e,Te,l),t(Te,bo),t(Te,xt),t(xt,ko),t(Te,jo),f(e,Ks,l),E(et,e,l),f(e,Zs,l),f(e,xe,l),t(xe,qo),t(xe,zt),t(zt,Eo),t(xe,To),f(e,ea,l),E(tt,e,l),f(e,ta,l),E(ze,e,l),f(e,sa,l),f(e,fe,l),t(fe,Fe),t(Fe,hs),E(st,hs,null),t(fe,xo),t(fe,gs),t(gs,zo),f(e,aa,l),f(e,G,l),t(G,Fo),t(G,Ft),t(Ft,Do),t(G,Bo),t(G,Dt),t(Dt,Co),t(G,Ao),t(G,Bt),t(Bt,Po),t(G,Mo),f(e,ra,l),f(e,ee,l),t(ee,Vo),t(ee,Ct),t(Ct,So),t(ee,Io),t(ee,At),t(At,Wo),t(ee,Lo),f(e,oa,l),E(at,e,l),f(e,na,l),E(De,e,l),f(e,ia,l),f(e,Be,l),t(Be,Oo),t(Be,Pt),t(Pt,No),t(Be,Ro),f(e,la,l),E(rt,e,l),f(e,fa,l),f(e,Ce,l),t(Ce,Qo),t(Ce,Mt),t(Mt,Yo),t(Ce,Ho),f(e,pa,l),E(ot,e,l),f(e,ua,l),f(e,pe,l),t(pe,Ae),t(Ae,_s),E(nt,_s,null),t(pe,Uo),t(pe,$s),t($s,Go),f(e,ca,l),f(e,Pe,l),t(Pe,Jo),t(Pe,Vt),t(Vt,Xo),t(Pe,Ko),f(e,ma,l),f(e,St,l),t(St,Zo),f(e,da,l),E(it,e,l),f(e,ha,l),f(e,It,l),t(It,en),f(e,ga,l),E(lt,e,l),f(e,_a,l),f(e,Me,l),t(Me,tn),t(Me,Wt),t(Wt,sn),t(Me,an),f(e,$a,l),E(ft,e,l),f(e,va,l),f(e,Lt,l),t(Lt,rn),wa=!0},p(e,[l]){const pt={};l&2&&(pt.$$scope={dirty:l,ctx:e}),ge.$set(pt);const vs={};l&2&&(vs.$$scope={dirty:l,ctx:e}),$e.$set(vs);const ws={};l&2&&(ws.$$scope={dirty:l,ctx:e}),ye.$set(ws);const ys={};l&2&&(ys.$$scope={dirty:l,ctx:e}),qe.$set(ys);const X={};l&2&&(X.$$scope={dirty:l,ctx:e}),ze.$set(X);const bs={};l&2&&(bs.$$scope={dirty:l,ctx:e}),De.$set(bs)},i(e){wa||(T(v.$$.fragment,e),T(Se.$$.fragment,e),T(Ie.$$.fragment,e),T(Oe.$$.fragment,e),T(Ne.$$.fragment,e),T(Re.$$.fragment,e),T(Qe.$$.fragment,e),T(ge.$$.fragment,e),T(Ye.$$.fragment,e),T($e.$$.fragment,e),T(Je.$$.fragment,e),T(ye.$$.fragment,e),T(Xe.$$.fragment,e),T(qe.$$.fragment,e),T(Ze.$$.fragment,e),T(et.$$.fragment,e),T(tt.$$.fragment,e),T(ze.$$.fragment,e),T(st.$$.fragment,e),T(at.$$.fragment,e),T(De.$$.fragment,e),T(rt.$$.fragment,e),T(ot.$$.fragment,e),T(nt.$$.fragment,e),T(it.$$.fragment,e),T(lt.$$.fragment,e),T(ft.$$.fragment,e),wa=!0)},o(e){x(v.$$.fragment,e),x(Se.$$.fragment,e),x(Ie.$$.fragment,e),x(Oe.$$.fragment,e),x(Ne.$$.fragment,e),x(Re.$$.fragment,e),x(Qe.$$.fragment,e),x(ge.$$.fragment,e),x(Ye.$$.fragment,e),x($e.$$.fragment,e),x(Je.$$.fragment,e),x(ye.$$.fragment,e),x(Xe.$$.fragment,e),x(qe.$$.fragment,e),x(Ze.$$.fragment,e),x(et.$$.fragment,e),x(tt.$$.fragment,e),x(ze.$$.fragment,e),x(st.$$.fragment,e),x(at.$$.fragment,e),x(De.$$.fragment,e),x(rt.$$.fragment,e),x(ot.$$.fragment,e),x(nt.$$.fragment,e),x(it.$$.fragment,e),x(lt.$$.fragment,e),x(ft.$$.fragment,e),wa=!1},d(e){s(p),e&&s($),e&&s(u),z(v),e&&s(W),e&&s(k),e&&s(B),e&&s(O),e&&s(js),e&&s(re),z(Se),e&&s(qs),e&&s(Y),e&&s(Es),e&&s(K),e&&s(Ts),z(Ie,e),e&&s(xs),e&&s(oe),e&&s(zs),e&&s(ce),e&&s(Fs),z(Oe,e),e&&s(Ds),e&&s(me),e&&s(Bs),z(Ne,e),e&&s(Cs),e&&s(de),e&&s(As),z(Re,e),e&&s(Ps),e&&s(he),e&&s(Ms),z(Qe,e),e&&s(Vs),z(ge,e),e&&s(Ss),e&&s(ne),z(Ye),e&&s(Is),e&&s(Q),e&&s(Ws),z($e,e),e&&s(Ls),e&&s(ie),z(Je),e&&s(Os),e&&s(we),e&&s(Ns),z(ye,e),e&&s(Rs),e&&s(le),z(Xe),e&&s(Qs),e&&s(ke),e&&s(Ys),e&&s(je),e&&s(Hs),e&&s(Tt),e&&s(Us),z(qe,e),e&&s(Gs),e&&s(Ee),e&&s(Js),z(Ze,e),e&&s(Xs),e&&s(Te),e&&s(Ks),z(et,e),e&&s(Zs),e&&s(xe),e&&s(ea),z(tt,e),e&&s(ta),z(ze,e),e&&s(sa),e&&s(fe),z(st),e&&s(aa),e&&s(G),e&&s(ra),e&&s(ee),e&&s(oa),z(at,e),e&&s(na),z(De,e),e&&s(ia),e&&s(Be),e&&s(la),z(rt,e),e&&s(fa),e&&s(Ce),e&&s(pa),z(ot,e),e&&s(ua),e&&s(pe),z(nt),e&&s(ca),e&&s(Pe),e&&s(ma),e&&s(St),e&&s(da),z(it,e),e&&s(ha),e&&s(It),e&&s(ga),z(lt,e),e&&s(_a),e&&s(Me),e&&s($a),z(ft,e),e&&s(va),e&&s(Lt)}}}const Ni={local:"create-a-custom-architecture",sections:[{local:"configuration",title:"Configuration"},{local:"model",sections:[{local:"model-heads",title:"Model heads"}],title:"Model"},{local:"tokenizer",title:"Tokenizer"},{local:"feature-extractor",title:"Feature Extractor"},{local:"processor",title:"Processor"}],title:"Create a custom architecture"};function Ri(I){return zi(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ji extends qi{constructor(p){super();Ei(this,p,Ri,Oi,Ti,{})}}export{Ji as default,Ni as metadata};
