import{S as Lm,i as Mm,s as Hm,e as o,c as r,a as n,d as a,b as d,N as Nm,g as l,L as Im,k as m,w as f,t as i,M as Rm,m as c,x as h,h as p,G as s,y as g,q as _,o as v,B as $,v as Bm}from"../chunks/vendor-hf-doc-builder.js";import{T as Mi}from"../chunks/Tip-hf-doc-builder.js";import{I as T,C as j}from"../chunks/CodeBlock-hf-doc-builder.js";import{D as Gm}from"../chunks/DocNotebookDropdown-hf-doc-builder.js";function Km(P){let u,k;return{c(){u=o("iframe"),this.h()},l(b){u=r(b,"IFRAME",{class:!0,src:!0,title:!0,frameborder:!0,allow:!0}),n(u).forEach(a),this.h()},h(){d(u,"class","w-full xl:w-4/6 h-80"),Nm(u.src,k="https://www.youtube-nocookie.com/embed/"+P[0])||d(u,"src",k),d(u,"title","YouTube video player"),d(u,"frameborder","0"),d(u,"allow","accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"),u.allowFullscreen=!0},m(b,w){l(b,u,w)},p(b,[w]){w&1&&!Nm(u.src,k="https://www.youtube-nocookie.com/embed/"+b[0])&&d(u,"src",k)},i:Im,o:Im,d(b){b&&a(u)}}}function Um(P,u,k){let{id:b}=u;return P.$$set=w=>{"id"in w&&k(0,b=w.id)},[b]}class Gr extends Lm{constructor(u){super();Mm(this,u,Um,Km,Hm,{id:0})}}function Wm(P){let u,k;return{c(){u=o("p"),k=i(`Voc\xEA ver\xE1 um alerta sobre alguns pesos pr\xE9-treinados que n\xE3o est\xE3o sendo utilizados e que alguns pesos est\xE3o
sendo inicializados aleatoriamente. N\xE3o se preocupe, essa mensagem \xE9 completamente normal.
O header/cabe\xE7\xE1rio pr\xE9-treinado do modelo BERT \xE9 descartado e substitui-se por um header de classifica\xE7\xE3o
inicializado aleatoriamente. Assim, pode aplicar o fine-tuning a este novo header do modelo em sua tarefa
de classifica\xE7\xE3o de sequ\xEAncias fazendo um transfer learning do modelo pr\xE9-treinado.`)},l(b){u=r(b,"P",{});var w=n(u);k=p(w,`Voc\xEA ver\xE1 um alerta sobre alguns pesos pr\xE9-treinados que n\xE3o est\xE3o sendo utilizados e que alguns pesos est\xE3o
sendo inicializados aleatoriamente. N\xE3o se preocupe, essa mensagem \xE9 completamente normal.
O header/cabe\xE7\xE1rio pr\xE9-treinado do modelo BERT \xE9 descartado e substitui-se por um header de classifica\xE7\xE3o
inicializado aleatoriamente. Assim, pode aplicar o fine-tuning a este novo header do modelo em sua tarefa
de classifica\xE7\xE3o de sequ\xEAncias fazendo um transfer learning do modelo pr\xE9-treinado.`),w.forEach(a)},m(b,w){l(b,u,w),s(u,k)},d(b){b&&a(u)}}}function Ym(P){let u,k,b,w,z,y,F,C;return{c(){u=o("p"),k=i("O "),b=o("code"),w=i("Trainer"),z=i(" utiliza "),y=o("code"),F=i("DataCollatorWithPadding"),C=i(` por padr\xE3o, ent\xE3o voc\xEA n\xE3o precisa especificar explicitamente um
colador de dados (data collator).`)},l(A){u=r(A,"P",{});var E=n(u);k=p(E,"O "),b=r(E,"CODE",{});var D=n(b);w=p(D,"Trainer"),D.forEach(a),z=p(E," utiliza "),y=r(E,"CODE",{});var N=n(y);F=p(N,"DataCollatorWithPadding"),N.forEach(a),C=p(E,` por padr\xE3o, ent\xE3o voc\xEA n\xE3o precisa especificar explicitamente um
colador de dados (data collator).`),E.forEach(a)},m(A,E){l(A,u,E),s(u,k),s(u,b),s(b,w),s(u,z),s(u,y),s(y,F),s(u,C)},d(A){A&&a(u)}}}function Qm(P){let u,k,b,w,z,y,F,C;return{c(){u=o("p"),k=i(`Se necess\xE1rio, voc\xEA pode obter o acesso gratuito a uma GPU na n\xFAvem por meio de um notebook no
`),b=o("a"),w=i("Colaboratory"),z=i(" ou "),y=o("a"),F=i("SageMaker StudioLab"),C=i(`
se n\xE3o tiver esse recurso de forma local.`),this.h()},l(A){u=r(A,"P",{});var E=n(u);k=p(E,`Se necess\xE1rio, voc\xEA pode obter o acesso gratuito a uma GPU na n\xFAvem por meio de um notebook no
`),b=r(E,"A",{href:!0,rel:!0});var D=n(b);w=p(D,"Colaboratory"),D.forEach(a),z=p(E," ou "),y=r(E,"A",{href:!0,rel:!0});var N=n(y);F=p(N,"SageMaker StudioLab"),N.forEach(a),C=p(E,`
se n\xE3o tiver esse recurso de forma local.`),E.forEach(a),this.h()},h(){d(b,"href","https://colab.research.google.com/"),d(b,"rel","nofollow"),d(y,"href","https://studiolab.sagemaker.aws/"),d(y,"rel","nofollow")},m(A,E){l(A,u,E),s(u,k),s(u,b),s(b,w),s(u,z),s(u,y),s(y,F),s(u,C)},d(A){A&&a(u)}}}function Vm(P){let u,k,b,w,z,y,F,C,A,E,D,N,Wa,Kr,xt,I,Le,Ur,bs,Wr,Yr,Qr,ws,Vr,Jr,js,Xr,St,Ya,Ot,G,re,ks,Me,Zr,Es,en,Ft,He,Nt,Qa,an,It,ne,sn,Re,tn,on,Lt,Be,Mt,le,rn,Ge,ys,nn,ln,Ht,Ke,Rt,Va,pn,Bt,Ue,Gt,Ja,Kt,K,ie,qs,We,mn,Xa,cn,As,dn,Ut,Ye,Wt,L,un,Ts,fn,hn,Ps,gn,_n,Yt,pe,vn,Qe,$n,bn,Qt,Ve,Vt,me,Jt,U,ce,zs,Je,wn,Cs,jn,Xt,M,kn,Ds,En,yn,Xe,qn,An,Zt,Za,Tn,eo,Ze,ao,W,de,xs,ea,Pn,Ss,zn,so,q,Cn,Os,Dn,xn,Fs,Sn,On,aa,Ns,Fn,Nn,Is,In,Ln,sa,Mn,Hn,to,ta,oo,x,Rn,Ls,Bn,Gn,Ms,Kn,Un,Hs,Wn,Yn,ro,oa,no,ue,Qn,Rs,Vn,Jn,lo,ra,io,Y,fe,Bs,na,Xn,Gs,Zn,po,he,el,Ks,al,sl,mo,la,co,ge,tl,Us,ol,rl,uo,ia,fo,es,ho,Q,_e,Ws,pa,nl,Ys,ll,go,ma,_o,as,il,vo,V,ve,Qs,ca,pl,Vs,ml,$o,H,cl,Js,dl,ul,Xs,fl,hl,bo,da,wo,$e,jo,S,gl,ua,Zs,_l,vl,et,$l,bl,at,wl,jl,ko,fa,Eo,J,be,st,ha,kl,tt,El,yo,ss,yl,qo,ga,Ao,we,ql,_a,ot,Al,Tl,To,va,Po,ts,zo,X,je,rt,$a,Pl,nt,zl,Co,ba,Do,ke,Cl,lt,Dl,xl,xo,os,Sl,So,wa,Oo,Ee,Ol,it,Fl,Nl,Fo,R,ja,ka,Il,pt,Ll,Ml,Hl,Ea,Rl,ya,Z,Bl,mt,Gl,Kl,ct,Ul,Wl,Yl,qa,Ql,Aa,dt,Vl,Jl,Ta,No,rs,Xl,Io,Pa,Lo,ee,ye,ut,za,Zl,ft,ei,Mo,qe,ai,ht,si,ti,Ho,Ca,Ro,ns,oi,Bo,Da,Go,ae,Ae,gt,xa,ri,_t,ni,Ko,Te,li,Sa,vt,ii,pi,Uo,Oa,Wo,Pe,mi,$t,ci,di,Yo,Fa,Qo,ze,ui,bt,fi,hi,Vo,Na,Jo,Ce,Xo,ls,gi,Zo,se,De,wt,Ia,_i,jt,vi,er,xe,$i,La,bi,wi,ar,Ma,sr,te,Se,kt,Ha,ji,Et,ki,tr,B,Ei,yt,yi,qi,Ra,qt,Ai,Ti,or,Ba,rr,is,nr,oe,Oe,At,Ga,Pi,Tt,zi,lr,ps,Ci,ir,Fe,Pt,ms,Ka,Di,xi,Si,zt,cs,ds,Oi,Fi,pr;return y=new T({}),D=new Gm({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/pt/training.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/pt/pytorch/training.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/pt/tensorflow/training.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/pt/training.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/pt/pytorch/training.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/pt/tensorflow/training.ipynb"}]}}),Me=new T({}),He=new Gr({props:{id:"_BZearw7f0w"}}),Be=new j({props:{code:`from datasets import load_dataset

dataset = load_dataset("yelp_review_full")
dataset[100]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;yelp_review_full&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">100</span>]
{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\&#x27;s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\&#x27;s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\&quot;serving off their orders\\\\&quot; when they didn\\&#x27;t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\&#x27;t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\&#x27;ve eaten at various McDonalds restaurants for over 30 years. I\\&#x27;ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!&#x27;</span>}`}}),Ke=new j({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")


def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)


tokenized_datasets = dataset.map(tokenize_function, batched=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&quot;text&quot;</span>], padding=<span class="hljs-string">&quot;max_length&quot;</span>, truncation=<span class="hljs-literal">True</span>)


<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets = dataset.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)`}}),Ue=new j({props:{code:`small_train_dataset = tokenized_datasets["train"].shuffle(seed=42).select(range(1000))
small_eval_dataset = tokenized_datasets["test"].shuffle(seed=42).select(range(1000))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>small_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>small_eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;test&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))`}}),We=new T({}),Ye=new Gr({props:{id:"nvBXf7s7vTI"}}),Ve=new j({props:{code:`from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, num_labels=<span class="hljs-number">5</span>)`}}),me=new Mi({props:{$$slots:{default:[Wm]},$$scope:{ctx:P}}}),Je=new T({}),Ze=new j({props:{code:`from transformers import TrainingArguments

training_args = TrainingArguments(output_dir="test_trainer")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(output_dir=<span class="hljs-string">&quot;test_trainer&quot;</span>)`}}),ea=new T({}),ta=new j({props:{code:`import numpy as np
from datasets import load_metric

metric = load_metric("accuracy")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_metric

<span class="hljs-meta">&gt;&gt;&gt; </span>metric = load_metric(<span class="hljs-string">&quot;accuracy&quot;</span>)`}}),oa=new j({props:{code:`def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):
<span class="hljs-meta">... </span>    logits, labels = eval_pred
<span class="hljs-meta">... </span>    predictions = np.argmax(logits, axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> metric.compute(predictions=predictions, references=labels)`}}),ra=new j({props:{code:`from transformers import TrainingArguments

training_args = TrainingArguments(output_dir="test_trainer", evaluation_strategy="epoch")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(output_dir=<span class="hljs-string">&quot;test_trainer&quot;</span>, evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>)`}}),na=new T({}),la=new j({props:{code:`trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=small_train_dataset,
    eval_dataset=small_eval_dataset,
    compute_metrics=compute_metrics,
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=small_train_dataset,
<span class="hljs-meta">... </span>    eval_dataset=small_eval_dataset,
<span class="hljs-meta">... </span>    compute_metrics=compute_metrics,
<span class="hljs-meta">... </span>)`}}),ia=new j({props:{code:"trainer.train()",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()'}}),pa=new T({}),ma=new Gr({props:{id:"rnTGBy2ax1c"}}),ca=new T({}),da=new j({props:{code:`from transformers import DefaultDataCollator

data_collator = DefaultDataCollator(return_tensors="tf")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DefaultDataCollator

<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DefaultDataCollator(return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`}}),$e=new Mi({props:{$$slots:{default:[Ym]},$$scope:{ctx:P}}}),fa=new j({props:{code:`tf_train_dataset = small_train_dataset.to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=8,
)

tf_validation_dataset = small_eval_dataset.to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=False,
    collate_fn=data_collator,
    batch_size=8,
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_train_dataset = small_train_dataset.to_tf_dataset(
<span class="hljs-meta">... </span>    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
<span class="hljs-meta">... </span>    label_cols=[<span class="hljs-string">&quot;labels&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">8</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_validation_dataset = small_eval_dataset.to_tf_dataset(
<span class="hljs-meta">... </span>    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
<span class="hljs-meta">... </span>    label_cols=[<span class="hljs-string">&quot;labels&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">False</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">8</span>,
<span class="hljs-meta">... </span>)`}}),ha=new T({}),ga=new j({props:{code:`import tensorflow as tf
from transformers import TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, num_labels=<span class="hljs-number">5</span>)`}}),va=new j({props:{code:`model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=tf.metrics.SparseCategoricalAccuracy(),
)

model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">compile</span>(
<span class="hljs-meta">... </span>    optimizer=tf.keras.optimizers.Adam(learning_rate=<span class="hljs-number">5e-5</span>),
<span class="hljs-meta">... </span>    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>),
<span class="hljs-meta">... </span>    metrics=tf.metrics.SparseCategoricalAccuracy(),
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=<span class="hljs-number">3</span>)`}}),$a=new T({}),ba=new Gr({props:{id:"Dh9CL8fyG80"}}),wa=new j({props:{code:`del model
del pytorch_model
del trainer
torch.cuda.empty_cache()`,highlighted:`<span class="hljs-keyword">del</span> model
<span class="hljs-keyword">del</span> pytorch_model
<span class="hljs-keyword">del</span> trainer
torch.cuda.empty_cache()`}}),Ea=new j({props:{code:'tokenized_datasets = tokenized_datasets.remove_columns(["text"])',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets = tokenized_datasets.remove_columns([<span class="hljs-string">&quot;text&quot;</span>])'}}),qa=new j({props:{code:'tokenized_datasets = tokenized_datasets.rename_column("label", "labels")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets = tokenized_datasets.rename_column(<span class="hljs-string">&quot;label&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>)'}}),Ta=new j({props:{code:'tokenized_datasets.set_format("torch")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets.set_format(<span class="hljs-string">&quot;torch&quot;</span>)'}}),Pa=new j({props:{code:`small_train_dataset = tokenized_datasets["train"].shuffle(seed=42).select(range(1000))
small_eval_dataset = tokenized_datasets["test"].shuffle(seed=42).select(range(1000))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>small_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>small_eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;test&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))`}}),za=new T({}),Ca=new j({props:{code:`from torch.utils.data import DataLoader

train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=8)
eval_dataloader = DataLoader(small_eval_dataset, batch_size=8)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader

<span class="hljs-meta">&gt;&gt;&gt; </span>train_dataloader = DataLoader(small_train_dataset, shuffle=<span class="hljs-literal">True</span>, batch_size=<span class="hljs-number">8</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>eval_dataloader = DataLoader(small_eval_dataset, batch_size=<span class="hljs-number">8</span>)`}}),Da=new j({props:{code:`from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, num_labels=<span class="hljs-number">5</span>)`}}),xa=new T({}),Oa=new j({props:{code:`from torch.optim import AdamW

optimizer = AdamW(model.parameters(), lr=5e-5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> AdamW

<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">5e-5</span>)`}}),Fa=new j({props:{code:`from transformers import get_scheduler

num_epochs = 3
num_training_steps = num_epochs * len(train_dataloader)
lr_scheduler = get_scheduler(
    name="linear", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> get_scheduler

<span class="hljs-meta">&gt;&gt;&gt; </span>num_epochs = <span class="hljs-number">3</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>num_training_steps = num_epochs * <span class="hljs-built_in">len</span>(train_dataloader)
<span class="hljs-meta">&gt;&gt;&gt; </span>lr_scheduler = get_scheduler(
<span class="hljs-meta">... </span>    name=<span class="hljs-string">&quot;linear&quot;</span>, optimizer=optimizer, num_warmup_steps=<span class="hljs-number">0</span>, num_training_steps=num_training_steps
<span class="hljs-meta">... </span>)`}}),Na=new j({props:{code:`import torch

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
model.to(device)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>) <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.to(device)`}}),Ce=new Mi({props:{$$slots:{default:[Qm]},$$scope:{ctx:P}}}),Ia=new T({}),Ma=new j({props:{code:`from tqdm.auto import tqdm

progress_bar = tqdm(range(num_training_steps))

model.train()
for epoch in range(num_epochs):
    for batch in train_dataloader:
        batch = {k: v.to(device) for k, v in batch.items()}
        outputs = model(**batch)
        loss = outputs.loss
        loss.backward()

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm

<span class="hljs-meta">&gt;&gt;&gt; </span>progress_bar = tqdm(<span class="hljs-built_in">range</span>(num_training_steps))

<span class="hljs-meta">&gt;&gt;&gt; </span>model.train()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:
<span class="hljs-meta">... </span>        batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}
<span class="hljs-meta">... </span>        outputs = model(**batch)
<span class="hljs-meta">... </span>        loss = outputs.loss
<span class="hljs-meta">... </span>        loss.backward()

<span class="hljs-meta">... </span>        optimizer.step()
<span class="hljs-meta">... </span>        lr_scheduler.step()
<span class="hljs-meta">... </span>        optimizer.zero_grad()
<span class="hljs-meta">... </span>        progress_bar.update(<span class="hljs-number">1</span>)`}}),Ha=new T({}),Ba=new j({props:{code:`metric = load_metric("accuracy")
model.eval()
for batch in eval_dataloader:
    batch = {k: v.to(device) for k, v in batch.items()}
    with torch.no_grad():
        outputs = model(**batch)

    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)
    metric.add_batch(predictions=predictions, references=batch["labels"])

metric.compute()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>metric = load_metric(<span class="hljs-string">&quot;accuracy&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">eval</span>()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> eval_dataloader:
<span class="hljs-meta">... </span>    batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}
<span class="hljs-meta">... </span>    <span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>        outputs = model(**batch)

<span class="hljs-meta">... </span>    logits = outputs.logits
<span class="hljs-meta">... </span>    predictions = torch.argmax(logits, dim=-<span class="hljs-number">1</span>)
<span class="hljs-meta">... </span>    metric.add_batch(predictions=predictions, references=batch[<span class="hljs-string">&quot;labels&quot;</span>])

<span class="hljs-meta">&gt;&gt;&gt; </span>metric.compute()`}}),Ga=new T({}),{c(){u=o("meta"),k=m(),b=o("h1"),w=o("a"),z=o("span"),f(y.$$.fragment),F=m(),C=o("span"),A=i("Fine-tuning de um modelo pr\xE9-treinado"),E=m(),f(D.$$.fragment),N=m(),Wa=o("p"),Kr=i(`O uso de um modelo pr\xE9-treinado tem importantes vantagens. Redu\xE7\xE3o do custo computacional, a pegada de carbono, e te
permite utilizar modelos de \xFAltima gera\xE7\xE3o sem ter que treinar um novo desde o in\xEDcio.
O \u{1F917} Transformers proporciona acesso a milhares de modelos pr\xE9-treinados numa ampla gama de tarefas.
Quando utilizar um modelo pr\xE9-treinado, treine-o com um dataset espec\xEDfico para a sua tarefa.
Isto \xE9 chamado de fine-tuning, uma t\xE9cnica de treinamento incrivelmente poderosa. Neste tutorial faremos o fine-tuning
a um modelo pr\xE9-treinado com um framework de Deep Learning de sua escolha:`),xt=m(),I=o("ul"),Le=o("li"),Ur=i("Fine-tuning de um modelo pr\xE9-treinado com o \u{1F917} Transformers "),bs=o("code"),Wr=i("Trainer"),Yr=i("."),Qr=m(),ws=o("li"),Vr=i("Fine-tuning de um modelo pr\xE9-treinado no TensorFlow com o Keras."),Jr=m(),js=o("li"),Xr=i("Fine-tuning de um modelo pr\xE9-treinado em PyTorch nativo."),St=m(),Ya=o("a"),Ot=m(),G=o("h2"),re=o("a"),ks=o("span"),f(Me.$$.fragment),Zr=m(),Es=o("span"),en=i("Preparando um dataset"),Ft=m(),f(He.$$.fragment),Nt=m(),Qa=o("p"),an=i(`Antes de aplicar o fine-tuning a um modelo pr\xE9-treinado, baixe um dataset e prepare-o para o treinamento.
O tutorial anterior ensinar\xE1 a processar os dados para o treinamento, e ent\xE3o poder\xE1 ter a oportunidade de testar
esse novo conhecimento em algo pr\xE1tico.`),It=m(),ne=o("p"),sn=i("Comece carregando o dataset "),Re=o("a"),tn=i("Yelp Reviews"),on=i(":"),Lt=m(),f(Be.$$.fragment),Mt=m(),le=o("p"),rn=i(`Como j\xE1 sabe, \xE9 necess\xE1rio ter um tokenizador para processar o texto e incluir uma estrat\xE9gia de padding e truncamento,
para manejar qualquer tamanho var\xEDavel de sequ\xEAncia. Para processar o seu dataset em apenas um passo, utilize o m\xE9todo de
\u{1F917} Datasets `),Ge=o("a"),ys=o("code"),nn=i("map"),ln=i(` para aplicar uma fun\xE7\xE3o de preprocessamento sobre
todo o dataset.`),Ht=m(),f(Ke.$$.fragment),Rt=m(),Va=o("p"),pn=i("Se desejar, \xE9 poss\xEDvel criar um subconjunto menor do dataset completo para aplicar o fine-tuning e assim reduzir o tempo necess\xE1rio."),Bt=m(),f(Ue.$$.fragment),Gt=m(),Ja=o("a"),Kt=m(),K=o("h2"),ie=o("a"),qs=o("span"),f(We.$$.fragment),mn=m(),Xa=o("span"),cn=i("Fine-tuning com o "),As=o("code"),dn=i("Trainer"),Ut=m(),f(Ye.$$.fragment),Wt=m(),L=o("p"),un=i("O \u{1F917} Transformers proporciona uma classe "),Ts=o("code"),fn=i("Trainer"),hn=i(` otimizada para o treinamento de modelos de \u{1F917} Transformers,
facilitando os primeiros passos do treinamento sem a necessidade de escrever manualmente seu pr\xF3prio ciclo.
A API do `),Ps=o("code"),gn=i("Trainer"),_n=i(` suporta um grande conjunto de op\xE7\xF5es de treinamento e funcionalidades, como o logging,
o gradient accumulation e o mixed precision.`),Yt=m(),pe=o("p"),vn=i(`Comece carregando seu modelo e especifique o n\xFAmero de labels de previs\xE3o.
A partir do `),Qe=o("a"),$n=i("Card Dataset"),bn=i(` do Yelp Reveiw, que ja
sabemos ter 5 labels usamos o seguinte c\xF3digo:`),Qt=m(),f(Ve.$$.fragment),Vt=m(),f(me.$$.fragment),Jt=m(),U=o("h3"),ce=o("a"),zs=o("span"),f(Je.$$.fragment),wn=m(),Cs=o("span"),jn=i("Hiperpar\xE2metros de treinamento"),Xt=m(),M=o("p"),kn=i("Em seguida, crie uma classe "),Ds=o("code"),En=i("TrainingArguments"),yn=i(` que contenha todos os hiperpar\xE2metros que possam ser ajustados, assim
como os indicadores para ativar as diferentes op\xE7\xF5es de treinamento. Para este tutorial, voc\xEA pode come\xE7ar o treinamento
usando os `),Xe=o("a"),qn=i("hiperpar\xE1metros"),An=i(` padr\xE3o,
por\xE9m, sinta-se livre para experimentar com eles e encontrar uma configura\xE7\xE3o \xF3tima.`),Zt=m(),Za=o("p"),Tn=i("Especifique onde salvar os checkpoints do treinamento:"),eo=m(),f(Ze.$$.fragment),ao=m(),W=o("h3"),de=o("a"),xs=o("span"),f(ea.$$.fragment),Pn=m(),Ss=o("span"),zn=i("M\xE9tricas"),so=m(),q=o("p"),Cn=i("O "),Os=o("code"),Dn=i("Trainer"),xn=i(` n\xE3o avalia automaticamente o rendimento do modelo durante o treinamento. Ser\xE1 necess\xE1rio passar ao
`),Fs=o("code"),Sn=i("Trainer"),On=i(` uma fun\xE7\xE3o para calcular e fazer um diagn\xF3stico sobre as m\xE9tricas. A biblioteca \u{1F917} Datasets proporciona
uma fun\xE7\xE3o de `),aa=o("a"),Ns=o("code"),Fn=i("accuracy"),Nn=i(` simples que pode ser carregada com a fun\xE7\xE3o
`),Is=o("code"),In=i("load_metric"),Ln=i(" (ver este "),sa=o("a"),Mn=i("tutorial"),Hn=i(" para mais informa\xE7\xF5es):"),to=m(),f(ta.$$.fragment),oo=m(),x=o("p"),Rn=i("Defina a fun\xE7\xE3o "),Ls=o("code"),Bn=i("compute"),Gn=i(" dentro de "),Ms=o("code"),Kn=i("metric"),Un=i(` para calcular a precis\xE3o de suas predi\xE7\xF5es.
Antes de passar suas predi\xE7\xF5es ao `),Hs=o("code"),Wn=i("compute"),Yn=i(`, \xE9 necess\xE1rio converter as predi\xE7\xF5es \xE0 logits (lembre-se que
todos os modelos de \u{1F917} Transformers retornam logits).`),ro=m(),f(oa.$$.fragment),no=m(),ue=o("p"),Qn=i("Se quiser controlar suas m\xE9tricas de avalia\xE7\xE3o durante o fine-tuning, especifique o par\xE2metro "),Rs=o("code"),Vn=i("evaluation_strategy"),Jn=i(`
em seus argumentos de treinamento para que o modelo leve em conta a m\xE9trica de avalia\xE7\xE3o ao final de cada \xE9poca:`),lo=m(),f(ra.$$.fragment),io=m(),Y=o("h3"),fe=o("a"),Bs=o("span"),f(na.$$.fragment),Xn=m(),Gs=o("span"),Zn=i("Trainer"),po=m(),he=o("p"),el=i("Crie um objeto "),Ks=o("code"),al=i("Trainer"),sl=i(" com seu modelo, argumentos de treinamento, conjuntos de dados de treinamento e de teste, e sua fun\xE7\xE3o de avalia\xE7\xE3o:"),mo=m(),f(la.$$.fragment),co=m(),ge=o("p"),tl=i("Em seguida, aplique o fine-tuning a seu modelo chamado "),Us=o("code"),ol=i("train()"),rl=i(":"),uo=m(),f(ia.$$.fragment),fo=m(),es=o("a"),ho=m(),Q=o("h2"),_e=o("a"),Ws=o("span"),f(pa.$$.fragment),nl=m(),Ys=o("span"),ll=i("Fine-tuning com Keras"),go=m(),f(ma.$$.fragment),_o=m(),as=o("p"),il=i(`Os modelos de \u{1F917} Transformers tamb\xE9m permitem realizar o treinamento com o TensorFlow com a API do Keras.
Contudo, ser\xE1 necess\xE1rio fazer algumas mudan\xE7as antes de realizar o fine-tuning.`),vo=m(),V=o("h3"),ve=o("a"),Qs=o("span"),f(ca.$$.fragment),pl=m(),Vs=o("span"),ml=i("Convers\xE3o do dataset ao formato do TensorFlow"),$o=m(),H=o("p"),cl=i("O "),Js=o("code"),dl=i("DefaultDataCollator"),ul=i(` junta os tensores em um batch para que o modelo possa ser treinado em cima deles.
Assegure-se de especificar os `),Xs=o("code"),fl=i("return_tensors"),hl=i(" para retornar os tensores do TensorFlow:"),bo=m(),f(da.$$.fragment),wo=m(),f($e.$$.fragment),jo=m(),S=o("p"),gl=i(`Em seguida, converta os datasets tokenizados em datasets do TensorFlow com o m\xE9todo
`),ua=o("a"),Zs=o("code"),_l=i("to_tf_dataset"),vl=i(`.
Especifique suas entradas em `),et=o("code"),$l=i("columns"),bl=i(" e seu r\xF3tulo em "),at=o("code"),wl=i("label_cols"),jl=i(":"),ko=m(),f(fa.$$.fragment),Eo=m(),J=o("h3"),be=o("a"),st=o("span"),f(ha.$$.fragment),kl=m(),tt=o("span"),El=i("Compila\xE7\xE3o e ajustes"),yo=m(),ss=o("p"),yl=i("Carregue um modelo do TensorFlow com o n\xFAmero esperado de r\xF3tulos:"),qo=m(),f(ga.$$.fragment),Ao=m(),we=o("p"),ql=i("A seguir, compile e ajuste o fine-tuning a seu modelo com "),_a=o("a"),ot=o("code"),Al=i("fit"),Tl=i(` como
faria com qualquer outro modelo do Keras:`),To=m(),f(va.$$.fragment),Po=m(),ts=o("a"),zo=m(),X=o("h2"),je=o("a"),rt=o("span"),f($a.$$.fragment),Pl=m(),nt=o("span"),zl=i("Fine-tune em PyTorch nativo"),Co=m(),f(ba.$$.fragment),Do=m(),ke=o("p"),Cl=i("O "),lt=o("code"),Dl=i("Trainer"),xl=i(` se encarrega do ciclo de treinamento e permite aplicar o fine-tuning a um modelo em uma linha de c\xF3digo apenas.
Para os usu\xE1rios que preferirem escrever seu pr\xF3prio ciclo de treinamento, tamb\xE9m \xE9 poss\xEDvel aplicar o fine-tuning a um
modelo de \u{1F917} Transformers em PyTorch nativo.`),xo=m(),os=o("p"),Sl=i(`Neste momento, talvez ocorra a necessidade de reinicar seu notebook ou executar a seguinte linha de c\xF3digo para liberar
mem\xF3ria:`),So=m(),f(wa.$$.fragment),Oo=m(),Ee=o("p"),Ol=i("Em sequ\xEAncia, faremos um post-processing manual do "),it=o("code"),Fl=i("tokenized_dataset"),Nl=i(" e assim prepar\xE1-lo para o treinamento."),Fo=m(),R=o("ol"),ja=o("li"),ka=o("p"),Il=i("Apague a coluna de "),pt=o("code"),Ll=i("text"),Ml=i(" porque o modelo n\xE3o aceita texto cru como entrada:"),Hl=m(),f(Ea.$$.fragment),Rl=m(),ya=o("li"),Z=o("p"),Bl=i("Troque o nome da coluna "),mt=o("code"),Gl=i("label"),Kl=i(" para "),ct=o("code"),Ul=i("labels"),Wl=i(", pois o modelo espera um argumento de mesmo nome:"),Yl=m(),f(qa.$$.fragment),Ql=m(),Aa=o("li"),dt=o("p"),Vl=i("Defina o formato do dataset para retornar tensores do PyTorch no lugar de listas:"),Jl=m(),f(Ta.$$.fragment),No=m(),rs=o("p"),Xl=i("Em sequ\xEAncia, crie um subconjunto menor do dataset, como foi mostrado anteriormente, para aceler\xE1-lo o fine-tuning."),Io=m(),f(Pa.$$.fragment),Lo=m(),ee=o("h3"),ye=o("a"),ut=o("span"),f(za.$$.fragment),Zl=m(),ft=o("span"),ei=i("DataLoader"),Mo=m(),qe=o("p"),ai=i("Crie um "),ht=o("code"),si=i("DataLoader"),ti=i(" para seus datasets de treinamento e de teste para poder iterar sobre batches de dados:"),Ho=m(),f(Ca.$$.fragment),Ro=m(),ns=o("p"),oi=i("Carregue seu modelo com o n\xFAmero de labels esperados:"),Bo=m(),f(Da.$$.fragment),Go=m(),ae=o("h3"),Ae=o("a"),gt=o("span"),f(xa.$$.fragment),ri=m(),_t=o("span"),ni=i("Otimiza\xE7\xE3o e configura\xE7\xE3o do Learning Rate"),Ko=m(),Te=o("p"),li=i(`Crie um otimizador e um learning rate para aplicar o fine-tuning ao modelo.
Iremos utilizar o otimizador `),Sa=o("a"),vt=o("code"),ii=i("AdamW"),pi=i(" do PyTorch:"),Uo=m(),f(Oa.$$.fragment),Wo=m(),Pe=o("p"),mi=i("Defina o learning rate do "),$t=o("code"),ci=i("Trainer"),di=i(":"),Yo=m(),f(Fa.$$.fragment),Qo=m(),ze=o("p"),ui=i("Por \xFAltimo, especifique o "),bt=o("code"),fi=i("device"),hi=i(` do ambiente para utilizar uma GPU se tiver acesso \xE0 alguma. Caso contr\xE1rio, o treinamento
em uma CPU pode acabar levando v\xE1rias horas em vez de minutos.`),Vo=m(),f(Na.$$.fragment),Jo=m(),f(Ce.$$.fragment),Xo=m(),ls=o("p"),gi=i(`Perfeito, agora estamos prontos para come\xE7ar o treinamento! \u{1F973}
Genial, \xA1ahora estamos listos entrenar! \u{1F973}`),Zo=m(),se=o("h3"),De=o("a"),wt=o("span"),f(Ia.$$.fragment),_i=m(),jt=o("span"),vi=i("Ciclo de treinamento"),er=m(),xe=o("p"),$i=i("Para visualizar melhor o processo de treinamento, utilize a biblioteca "),La=o("a"),bi=i("tqdm"),wi=i(` para adicionar
uma barra de progresso sobre o n\xFAmero de passos percorridos no treinamento atual:`),ar=m(),f(Ma.$$.fragment),sr=m(),te=o("h3"),Se=o("a"),kt=o("span"),f(Ha.$$.fragment),ji=m(),Et=o("span"),ki=i("M\xE9tricas"),tr=m(),B=o("p"),Ei=i("Da mesma forma que \xE9 necess\xE1rio adicionar uma fun\xE7\xE3o de avalia\xE7\xE3o ao "),yt=o("code"),yi=i("Trainer"),qi=i(`, \xE9 necess\xE1rio fazer o mesmo quando
escrevendo o pr\xF3prio ciclo de treinamento. Contudo, em vez de calcular e retornar a m\xE9trica final de cada \xE9poca,
voc\xEA dever\xE1 adicionar todos os batches com `),Ra=o("a"),qt=o("code"),Ai=i("add_batch"),Ti=i(`
e calcular a m\xE9trica apenas no final.`),or=m(),f(Ba.$$.fragment),rr=m(),is=o("a"),nr=m(),oe=o("h2"),Oe=o("a"),At=o("span"),f(Ga.$$.fragment),Pi=m(),Tt=o("span"),zi=i("Recursos adicionais"),lr=m(),ps=o("p"),Ci=i("Para mais exemplos de fine-tuning acesse:"),ir=m(),Fe=o("ul"),Pt=o("li"),ms=o("p"),Ka=o("a"),Di=i("\u{1F917} Transformers Examples"),xi=i(` inclui scripts
para treinas tarefas comuns de NLP em PyTorch e TensorFlow.`),Si=m(),zt=o("li"),cs=o("p"),ds=o("a"),Oi=i("\u{1F917} Transformers Notebooks"),Fi=i(` cont\xE9m v\xE1rios notebooks sobre como aplicar o fine-tuning a um modelo
para tarefas espec\xEDficas no PyTorch e TensorFlow.`),this.h()},l(e){const t=Rm('[data-svelte="svelte-1phssyn"]',document.head);u=r(t,"META",{name:!0,content:!0}),t.forEach(a),k=c(e),b=r(e,"H1",{class:!0});var Ua=n(b);w=r(Ua,"A",{id:!0,class:!0,href:!0});var Ct=n(w);z=r(Ct,"SPAN",{});var Dt=n(z);h(y.$$.fragment,Dt),Dt.forEach(a),Ct.forEach(a),F=c(Ua),C=r(Ua,"SPAN",{});var Hi=n(C);A=p(Hi,"Fine-tuning de um modelo pr\xE9-treinado"),Hi.forEach(a),Ua.forEach(a),E=c(e),h(D.$$.fragment,e),N=c(e),Wa=r(e,"P",{});var Ri=n(Wa);Kr=p(Ri,`O uso de um modelo pr\xE9-treinado tem importantes vantagens. Redu\xE7\xE3o do custo computacional, a pegada de carbono, e te
permite utilizar modelos de \xFAltima gera\xE7\xE3o sem ter que treinar um novo desde o in\xEDcio.
O \u{1F917} Transformers proporciona acesso a milhares de modelos pr\xE9-treinados numa ampla gama de tarefas.
Quando utilizar um modelo pr\xE9-treinado, treine-o com um dataset espec\xEDfico para a sua tarefa.
Isto \xE9 chamado de fine-tuning, uma t\xE9cnica de treinamento incrivelmente poderosa. Neste tutorial faremos o fine-tuning
a um modelo pr\xE9-treinado com um framework de Deep Learning de sua escolha:`),Ri.forEach(a),xt=c(e),I=r(e,"UL",{});var us=n(I);Le=r(us,"LI",{});var mr=n(Le);Ur=p(mr,"Fine-tuning de um modelo pr\xE9-treinado com o \u{1F917} Transformers "),bs=r(mr,"CODE",{});var Bi=n(bs);Wr=p(Bi,"Trainer"),Bi.forEach(a),Yr=p(mr,"."),mr.forEach(a),Qr=c(us),ws=r(us,"LI",{});var Gi=n(ws);Vr=p(Gi,"Fine-tuning de um modelo pr\xE9-treinado no TensorFlow com o Keras."),Gi.forEach(a),Jr=c(us),js=r(us,"LI",{});var Ki=n(js);Xr=p(Ki,"Fine-tuning de um modelo pr\xE9-treinado em PyTorch nativo."),Ki.forEach(a),us.forEach(a),St=c(e),Ya=r(e,"A",{id:!0}),n(Ya).forEach(a),Ot=c(e),G=r(e,"H2",{class:!0});var cr=n(G);re=r(cr,"A",{id:!0,class:!0,href:!0});var Ui=n(re);ks=r(Ui,"SPAN",{});var Wi=n(ks);h(Me.$$.fragment,Wi),Wi.forEach(a),Ui.forEach(a),Zr=c(cr),Es=r(cr,"SPAN",{});var Yi=n(Es);en=p(Yi,"Preparando um dataset"),Yi.forEach(a),cr.forEach(a),Ft=c(e),h(He.$$.fragment,e),Nt=c(e),Qa=r(e,"P",{});var Qi=n(Qa);an=p(Qi,`Antes de aplicar o fine-tuning a um modelo pr\xE9-treinado, baixe um dataset e prepare-o para o treinamento.
O tutorial anterior ensinar\xE1 a processar os dados para o treinamento, e ent\xE3o poder\xE1 ter a oportunidade de testar
esse novo conhecimento em algo pr\xE1tico.`),Qi.forEach(a),It=c(e),ne=r(e,"P",{});var dr=n(ne);sn=p(dr,"Comece carregando o dataset "),Re=r(dr,"A",{href:!0,rel:!0});var Vi=n(Re);tn=p(Vi,"Yelp Reviews"),Vi.forEach(a),on=p(dr,":"),dr.forEach(a),Lt=c(e),h(Be.$$.fragment,e),Mt=c(e),le=r(e,"P",{});var ur=n(le);rn=p(ur,`Como j\xE1 sabe, \xE9 necess\xE1rio ter um tokenizador para processar o texto e incluir uma estrat\xE9gia de padding e truncamento,
para manejar qualquer tamanho var\xEDavel de sequ\xEAncia. Para processar o seu dataset em apenas um passo, utilize o m\xE9todo de
\u{1F917} Datasets `),Ge=r(ur,"A",{href:!0,rel:!0});var Ji=n(Ge);ys=r(Ji,"CODE",{});var Xi=n(ys);nn=p(Xi,"map"),Xi.forEach(a),Ji.forEach(a),ln=p(ur,` para aplicar uma fun\xE7\xE3o de preprocessamento sobre
todo o dataset.`),ur.forEach(a),Ht=c(e),h(Ke.$$.fragment,e),Rt=c(e),Va=r(e,"P",{});var Zi=n(Va);pn=p(Zi,"Se desejar, \xE9 poss\xEDvel criar um subconjunto menor do dataset completo para aplicar o fine-tuning e assim reduzir o tempo necess\xE1rio."),Zi.forEach(a),Bt=c(e),h(Ue.$$.fragment,e),Gt=c(e),Ja=r(e,"A",{id:!0}),n(Ja).forEach(a),Kt=c(e),K=r(e,"H2",{class:!0});var fr=n(K);ie=r(fr,"A",{id:!0,class:!0,href:!0});var ep=n(ie);qs=r(ep,"SPAN",{});var ap=n(qs);h(We.$$.fragment,ap),ap.forEach(a),ep.forEach(a),mn=c(fr),Xa=r(fr,"SPAN",{});var Ni=n(Xa);cn=p(Ni,"Fine-tuning com o "),As=r(Ni,"CODE",{});var sp=n(As);dn=p(sp,"Trainer"),sp.forEach(a),Ni.forEach(a),fr.forEach(a),Ut=c(e),h(Ye.$$.fragment,e),Wt=c(e),L=r(e,"P",{});var fs=n(L);un=p(fs,"O \u{1F917} Transformers proporciona uma classe "),Ts=r(fs,"CODE",{});var tp=n(Ts);fn=p(tp,"Trainer"),tp.forEach(a),hn=p(fs,` otimizada para o treinamento de modelos de \u{1F917} Transformers,
facilitando os primeiros passos do treinamento sem a necessidade de escrever manualmente seu pr\xF3prio ciclo.
A API do `),Ps=r(fs,"CODE",{});var op=n(Ps);gn=p(op,"Trainer"),op.forEach(a),_n=p(fs,` suporta um grande conjunto de op\xE7\xF5es de treinamento e funcionalidades, como o logging,
o gradient accumulation e o mixed precision.`),fs.forEach(a),Yt=c(e),pe=r(e,"P",{});var hr=n(pe);vn=p(hr,`Comece carregando seu modelo e especifique o n\xFAmero de labels de previs\xE3o.
A partir do `),Qe=r(hr,"A",{href:!0,rel:!0});var rp=n(Qe);$n=p(rp,"Card Dataset"),rp.forEach(a),bn=p(hr,` do Yelp Reveiw, que ja
sabemos ter 5 labels usamos o seguinte c\xF3digo:`),hr.forEach(a),Qt=c(e),h(Ve.$$.fragment,e),Vt=c(e),h(me.$$.fragment,e),Jt=c(e),U=r(e,"H3",{class:!0});var gr=n(U);ce=r(gr,"A",{id:!0,class:!0,href:!0});var np=n(ce);zs=r(np,"SPAN",{});var lp=n(zs);h(Je.$$.fragment,lp),lp.forEach(a),np.forEach(a),wn=c(gr),Cs=r(gr,"SPAN",{});var ip=n(Cs);jn=p(ip,"Hiperpar\xE2metros de treinamento"),ip.forEach(a),gr.forEach(a),Xt=c(e),M=r(e,"P",{});var hs=n(M);kn=p(hs,"Em seguida, crie uma classe "),Ds=r(hs,"CODE",{});var pp=n(Ds);En=p(pp,"TrainingArguments"),pp.forEach(a),yn=p(hs,` que contenha todos os hiperpar\xE2metros que possam ser ajustados, assim
como os indicadores para ativar as diferentes op\xE7\xF5es de treinamento. Para este tutorial, voc\xEA pode come\xE7ar o treinamento
usando os `),Xe=r(hs,"A",{href:!0,rel:!0});var mp=n(Xe);qn=p(mp,"hiperpar\xE1metros"),mp.forEach(a),An=p(hs,` padr\xE3o,
por\xE9m, sinta-se livre para experimentar com eles e encontrar uma configura\xE7\xE3o \xF3tima.`),hs.forEach(a),Zt=c(e),Za=r(e,"P",{});var cp=n(Za);Tn=p(cp,"Especifique onde salvar os checkpoints do treinamento:"),cp.forEach(a),eo=c(e),h(Ze.$$.fragment,e),ao=c(e),W=r(e,"H3",{class:!0});var _r=n(W);de=r(_r,"A",{id:!0,class:!0,href:!0});var dp=n(de);xs=r(dp,"SPAN",{});var up=n(xs);h(ea.$$.fragment,up),up.forEach(a),dp.forEach(a),Pn=c(_r),Ss=r(_r,"SPAN",{});var fp=n(Ss);zn=p(fp,"M\xE9tricas"),fp.forEach(a),_r.forEach(a),so=c(e),q=r(e,"P",{});var O=n(q);Cn=p(O,"O "),Os=r(O,"CODE",{});var hp=n(Os);Dn=p(hp,"Trainer"),hp.forEach(a),xn=p(O,` n\xE3o avalia automaticamente o rendimento do modelo durante o treinamento. Ser\xE1 necess\xE1rio passar ao
`),Fs=r(O,"CODE",{});var gp=n(Fs);Sn=p(gp,"Trainer"),gp.forEach(a),On=p(O,` uma fun\xE7\xE3o para calcular e fazer um diagn\xF3stico sobre as m\xE9tricas. A biblioteca \u{1F917} Datasets proporciona
uma fun\xE7\xE3o de `),aa=r(O,"A",{href:!0,rel:!0});var _p=n(aa);Ns=r(_p,"CODE",{});var vp=n(Ns);Fn=p(vp,"accuracy"),vp.forEach(a),_p.forEach(a),Nn=p(O,` simples que pode ser carregada com a fun\xE7\xE3o
`),Is=r(O,"CODE",{});var $p=n(Is);In=p($p,"load_metric"),$p.forEach(a),Ln=p(O," (ver este "),sa=r(O,"A",{href:!0,rel:!0});var bp=n(sa);Mn=p(bp,"tutorial"),bp.forEach(a),Hn=p(O," para mais informa\xE7\xF5es):"),O.forEach(a),to=c(e),h(ta.$$.fragment,e),oo=c(e),x=r(e,"P",{});var Ne=n(x);Rn=p(Ne,"Defina a fun\xE7\xE3o "),Ls=r(Ne,"CODE",{});var wp=n(Ls);Bn=p(wp,"compute"),wp.forEach(a),Gn=p(Ne," dentro de "),Ms=r(Ne,"CODE",{});var jp=n(Ms);Kn=p(jp,"metric"),jp.forEach(a),Un=p(Ne,` para calcular a precis\xE3o de suas predi\xE7\xF5es.
Antes de passar suas predi\xE7\xF5es ao `),Hs=r(Ne,"CODE",{});var kp=n(Hs);Wn=p(kp,"compute"),kp.forEach(a),Yn=p(Ne,`, \xE9 necess\xE1rio converter as predi\xE7\xF5es \xE0 logits (lembre-se que
todos os modelos de \u{1F917} Transformers retornam logits).`),Ne.forEach(a),ro=c(e),h(oa.$$.fragment,e),no=c(e),ue=r(e,"P",{});var vr=n(ue);Qn=p(vr,"Se quiser controlar suas m\xE9tricas de avalia\xE7\xE3o durante o fine-tuning, especifique o par\xE2metro "),Rs=r(vr,"CODE",{});var Ep=n(Rs);Vn=p(Ep,"evaluation_strategy"),Ep.forEach(a),Jn=p(vr,`
em seus argumentos de treinamento para que o modelo leve em conta a m\xE9trica de avalia\xE7\xE3o ao final de cada \xE9poca:`),vr.forEach(a),lo=c(e),h(ra.$$.fragment,e),io=c(e),Y=r(e,"H3",{class:!0});var $r=n(Y);fe=r($r,"A",{id:!0,class:!0,href:!0});var yp=n(fe);Bs=r(yp,"SPAN",{});var qp=n(Bs);h(na.$$.fragment,qp),qp.forEach(a),yp.forEach(a),Xn=c($r),Gs=r($r,"SPAN",{});var Ap=n(Gs);Zn=p(Ap,"Trainer"),Ap.forEach(a),$r.forEach(a),po=c(e),he=r(e,"P",{});var br=n(he);el=p(br,"Crie um objeto "),Ks=r(br,"CODE",{});var Tp=n(Ks);al=p(Tp,"Trainer"),Tp.forEach(a),sl=p(br," com seu modelo, argumentos de treinamento, conjuntos de dados de treinamento e de teste, e sua fun\xE7\xE3o de avalia\xE7\xE3o:"),br.forEach(a),mo=c(e),h(la.$$.fragment,e),co=c(e),ge=r(e,"P",{});var wr=n(ge);tl=p(wr,"Em seguida, aplique o fine-tuning a seu modelo chamado "),Us=r(wr,"CODE",{});var Pp=n(Us);ol=p(Pp,"train()"),Pp.forEach(a),rl=p(wr,":"),wr.forEach(a),uo=c(e),h(ia.$$.fragment,e),fo=c(e),es=r(e,"A",{id:!0}),n(es).forEach(a),ho=c(e),Q=r(e,"H2",{class:!0});var jr=n(Q);_e=r(jr,"A",{id:!0,class:!0,href:!0});var zp=n(_e);Ws=r(zp,"SPAN",{});var Cp=n(Ws);h(pa.$$.fragment,Cp),Cp.forEach(a),zp.forEach(a),nl=c(jr),Ys=r(jr,"SPAN",{});var Dp=n(Ys);ll=p(Dp,"Fine-tuning com Keras"),Dp.forEach(a),jr.forEach(a),go=c(e),h(ma.$$.fragment,e),_o=c(e),as=r(e,"P",{});var xp=n(as);il=p(xp,`Os modelos de \u{1F917} Transformers tamb\xE9m permitem realizar o treinamento com o TensorFlow com a API do Keras.
Contudo, ser\xE1 necess\xE1rio fazer algumas mudan\xE7as antes de realizar o fine-tuning.`),xp.forEach(a),vo=c(e),V=r(e,"H3",{class:!0});var kr=n(V);ve=r(kr,"A",{id:!0,class:!0,href:!0});var Sp=n(ve);Qs=r(Sp,"SPAN",{});var Op=n(Qs);h(ca.$$.fragment,Op),Op.forEach(a),Sp.forEach(a),pl=c(kr),Vs=r(kr,"SPAN",{});var Fp=n(Vs);ml=p(Fp,"Convers\xE3o do dataset ao formato do TensorFlow"),Fp.forEach(a),kr.forEach(a),$o=c(e),H=r(e,"P",{});var gs=n(H);cl=p(gs,"O "),Js=r(gs,"CODE",{});var Np=n(Js);dl=p(Np,"DefaultDataCollator"),Np.forEach(a),ul=p(gs,` junta os tensores em um batch para que o modelo possa ser treinado em cima deles.
Assegure-se de especificar os `),Xs=r(gs,"CODE",{});var Ip=n(Xs);fl=p(Ip,"return_tensors"),Ip.forEach(a),hl=p(gs," para retornar os tensores do TensorFlow:"),gs.forEach(a),bo=c(e),h(da.$$.fragment,e),wo=c(e),h($e.$$.fragment,e),jo=c(e),S=r(e,"P",{});var Ie=n(S);gl=p(Ie,`Em seguida, converta os datasets tokenizados em datasets do TensorFlow com o m\xE9todo
`),ua=r(Ie,"A",{href:!0,rel:!0});var Lp=n(ua);Zs=r(Lp,"CODE",{});var Mp=n(Zs);_l=p(Mp,"to_tf_dataset"),Mp.forEach(a),Lp.forEach(a),vl=p(Ie,`.
Especifique suas entradas em `),et=r(Ie,"CODE",{});var Hp=n(et);$l=p(Hp,"columns"),Hp.forEach(a),bl=p(Ie," e seu r\xF3tulo em "),at=r(Ie,"CODE",{});var Rp=n(at);wl=p(Rp,"label_cols"),Rp.forEach(a),jl=p(Ie,":"),Ie.forEach(a),ko=c(e),h(fa.$$.fragment,e),Eo=c(e),J=r(e,"H3",{class:!0});var Er=n(J);be=r(Er,"A",{id:!0,class:!0,href:!0});var Bp=n(be);st=r(Bp,"SPAN",{});var Gp=n(st);h(ha.$$.fragment,Gp),Gp.forEach(a),Bp.forEach(a),kl=c(Er),tt=r(Er,"SPAN",{});var Kp=n(tt);El=p(Kp,"Compila\xE7\xE3o e ajustes"),Kp.forEach(a),Er.forEach(a),yo=c(e),ss=r(e,"P",{});var Up=n(ss);yl=p(Up,"Carregue um modelo do TensorFlow com o n\xFAmero esperado de r\xF3tulos:"),Up.forEach(a),qo=c(e),h(ga.$$.fragment,e),Ao=c(e),we=r(e,"P",{});var yr=n(we);ql=p(yr,"A seguir, compile e ajuste o fine-tuning a seu modelo com "),_a=r(yr,"A",{href:!0,rel:!0});var Wp=n(_a);ot=r(Wp,"CODE",{});var Yp=n(ot);Al=p(Yp,"fit"),Yp.forEach(a),Wp.forEach(a),Tl=p(yr,` como
faria com qualquer outro modelo do Keras:`),yr.forEach(a),To=c(e),h(va.$$.fragment,e),Po=c(e),ts=r(e,"A",{id:!0}),n(ts).forEach(a),zo=c(e),X=r(e,"H2",{class:!0});var qr=n(X);je=r(qr,"A",{id:!0,class:!0,href:!0});var Qp=n(je);rt=r(Qp,"SPAN",{});var Vp=n(rt);h($a.$$.fragment,Vp),Vp.forEach(a),Qp.forEach(a),Pl=c(qr),nt=r(qr,"SPAN",{});var Jp=n(nt);zl=p(Jp,"Fine-tune em PyTorch nativo"),Jp.forEach(a),qr.forEach(a),Co=c(e),h(ba.$$.fragment,e),Do=c(e),ke=r(e,"P",{});var Ar=n(ke);Cl=p(Ar,"O "),lt=r(Ar,"CODE",{});var Xp=n(lt);Dl=p(Xp,"Trainer"),Xp.forEach(a),xl=p(Ar,` se encarrega do ciclo de treinamento e permite aplicar o fine-tuning a um modelo em uma linha de c\xF3digo apenas.
Para os usu\xE1rios que preferirem escrever seu pr\xF3prio ciclo de treinamento, tamb\xE9m \xE9 poss\xEDvel aplicar o fine-tuning a um
modelo de \u{1F917} Transformers em PyTorch nativo.`),Ar.forEach(a),xo=c(e),os=r(e,"P",{});var Zp=n(os);Sl=p(Zp,`Neste momento, talvez ocorra a necessidade de reinicar seu notebook ou executar a seguinte linha de c\xF3digo para liberar
mem\xF3ria:`),Zp.forEach(a),So=c(e),h(wa.$$.fragment,e),Oo=c(e),Ee=r(e,"P",{});var Tr=n(Ee);Ol=p(Tr,"Em sequ\xEAncia, faremos um post-processing manual do "),it=r(Tr,"CODE",{});var em=n(it);Fl=p(em,"tokenized_dataset"),em.forEach(a),Nl=p(Tr," e assim prepar\xE1-lo para o treinamento."),Tr.forEach(a),Fo=c(e),R=r(e,"OL",{});var _s=n(R);ja=r(_s,"LI",{});var Pr=n(ja);ka=r(Pr,"P",{});var zr=n(ka);Il=p(zr,"Apague a coluna de "),pt=r(zr,"CODE",{});var am=n(pt);Ll=p(am,"text"),am.forEach(a),Ml=p(zr," porque o modelo n\xE3o aceita texto cru como entrada:"),zr.forEach(a),Hl=c(Pr),h(Ea.$$.fragment,Pr),Pr.forEach(a),Rl=c(_s),ya=r(_s,"LI",{});var Cr=n(ya);Z=r(Cr,"P",{});var vs=n(Z);Bl=p(vs,"Troque o nome da coluna "),mt=r(vs,"CODE",{});var sm=n(mt);Gl=p(sm,"label"),sm.forEach(a),Kl=p(vs," para "),ct=r(vs,"CODE",{});var tm=n(ct);Ul=p(tm,"labels"),tm.forEach(a),Wl=p(vs,", pois o modelo espera um argumento de mesmo nome:"),vs.forEach(a),Yl=c(Cr),h(qa.$$.fragment,Cr),Cr.forEach(a),Ql=c(_s),Aa=r(_s,"LI",{});var Dr=n(Aa);dt=r(Dr,"P",{});var om=n(dt);Vl=p(om,"Defina o formato do dataset para retornar tensores do PyTorch no lugar de listas:"),om.forEach(a),Jl=c(Dr),h(Ta.$$.fragment,Dr),Dr.forEach(a),_s.forEach(a),No=c(e),rs=r(e,"P",{});var rm=n(rs);Xl=p(rm,"Em sequ\xEAncia, crie um subconjunto menor do dataset, como foi mostrado anteriormente, para aceler\xE1-lo o fine-tuning."),rm.forEach(a),Io=c(e),h(Pa.$$.fragment,e),Lo=c(e),ee=r(e,"H3",{class:!0});var xr=n(ee);ye=r(xr,"A",{id:!0,class:!0,href:!0});var nm=n(ye);ut=r(nm,"SPAN",{});var lm=n(ut);h(za.$$.fragment,lm),lm.forEach(a),nm.forEach(a),Zl=c(xr),ft=r(xr,"SPAN",{});var im=n(ft);ei=p(im,"DataLoader"),im.forEach(a),xr.forEach(a),Mo=c(e),qe=r(e,"P",{});var Sr=n(qe);ai=p(Sr,"Crie um "),ht=r(Sr,"CODE",{});var pm=n(ht);si=p(pm,"DataLoader"),pm.forEach(a),ti=p(Sr," para seus datasets de treinamento e de teste para poder iterar sobre batches de dados:"),Sr.forEach(a),Ho=c(e),h(Ca.$$.fragment,e),Ro=c(e),ns=r(e,"P",{});var mm=n(ns);oi=p(mm,"Carregue seu modelo com o n\xFAmero de labels esperados:"),mm.forEach(a),Bo=c(e),h(Da.$$.fragment,e),Go=c(e),ae=r(e,"H3",{class:!0});var Or=n(ae);Ae=r(Or,"A",{id:!0,class:!0,href:!0});var cm=n(Ae);gt=r(cm,"SPAN",{});var dm=n(gt);h(xa.$$.fragment,dm),dm.forEach(a),cm.forEach(a),ri=c(Or),_t=r(Or,"SPAN",{});var um=n(_t);ni=p(um,"Otimiza\xE7\xE3o e configura\xE7\xE3o do Learning Rate"),um.forEach(a),Or.forEach(a),Ko=c(e),Te=r(e,"P",{});var Fr=n(Te);li=p(Fr,`Crie um otimizador e um learning rate para aplicar o fine-tuning ao modelo.
Iremos utilizar o otimizador `),Sa=r(Fr,"A",{href:!0,rel:!0});var fm=n(Sa);vt=r(fm,"CODE",{});var hm=n(vt);ii=p(hm,"AdamW"),hm.forEach(a),fm.forEach(a),pi=p(Fr," do PyTorch:"),Fr.forEach(a),Uo=c(e),h(Oa.$$.fragment,e),Wo=c(e),Pe=r(e,"P",{});var Nr=n(Pe);mi=p(Nr,"Defina o learning rate do "),$t=r(Nr,"CODE",{});var gm=n($t);ci=p(gm,"Trainer"),gm.forEach(a),di=p(Nr,":"),Nr.forEach(a),Yo=c(e),h(Fa.$$.fragment,e),Qo=c(e),ze=r(e,"P",{});var Ir=n(ze);ui=p(Ir,"Por \xFAltimo, especifique o "),bt=r(Ir,"CODE",{});var _m=n(bt);fi=p(_m,"device"),_m.forEach(a),hi=p(Ir,` do ambiente para utilizar uma GPU se tiver acesso \xE0 alguma. Caso contr\xE1rio, o treinamento
em uma CPU pode acabar levando v\xE1rias horas em vez de minutos.`),Ir.forEach(a),Vo=c(e),h(Na.$$.fragment,e),Jo=c(e),h(Ce.$$.fragment,e),Xo=c(e),ls=r(e,"P",{});var vm=n(ls);gi=p(vm,`Perfeito, agora estamos prontos para come\xE7ar o treinamento! \u{1F973}
Genial, \xA1ahora estamos listos entrenar! \u{1F973}`),vm.forEach(a),Zo=c(e),se=r(e,"H3",{class:!0});var Lr=n(se);De=r(Lr,"A",{id:!0,class:!0,href:!0});var $m=n(De);wt=r($m,"SPAN",{});var bm=n(wt);h(Ia.$$.fragment,bm),bm.forEach(a),$m.forEach(a),_i=c(Lr),jt=r(Lr,"SPAN",{});var wm=n(jt);vi=p(wm,"Ciclo de treinamento"),wm.forEach(a),Lr.forEach(a),er=c(e),xe=r(e,"P",{});var Mr=n(xe);$i=p(Mr,"Para visualizar melhor o processo de treinamento, utilize a biblioteca "),La=r(Mr,"A",{href:!0,rel:!0});var jm=n(La);bi=p(jm,"tqdm"),jm.forEach(a),wi=p(Mr,` para adicionar
uma barra de progresso sobre o n\xFAmero de passos percorridos no treinamento atual:`),Mr.forEach(a),ar=c(e),h(Ma.$$.fragment,e),sr=c(e),te=r(e,"H3",{class:!0});var Hr=n(te);Se=r(Hr,"A",{id:!0,class:!0,href:!0});var km=n(Se);kt=r(km,"SPAN",{});var Em=n(kt);h(Ha.$$.fragment,Em),Em.forEach(a),km.forEach(a),ji=c(Hr),Et=r(Hr,"SPAN",{});var ym=n(Et);ki=p(ym,"M\xE9tricas"),ym.forEach(a),Hr.forEach(a),tr=c(e),B=r(e,"P",{});var $s=n(B);Ei=p($s,"Da mesma forma que \xE9 necess\xE1rio adicionar uma fun\xE7\xE3o de avalia\xE7\xE3o ao "),yt=r($s,"CODE",{});var qm=n(yt);yi=p(qm,"Trainer"),qm.forEach(a),qi=p($s,`, \xE9 necess\xE1rio fazer o mesmo quando
escrevendo o pr\xF3prio ciclo de treinamento. Contudo, em vez de calcular e retornar a m\xE9trica final de cada \xE9poca,
voc\xEA dever\xE1 adicionar todos os batches com `),Ra=r($s,"A",{href:!0,rel:!0});var Am=n(Ra);qt=r(Am,"CODE",{});var Tm=n(qt);Ai=p(Tm,"add_batch"),Tm.forEach(a),Am.forEach(a),Ti=p($s,`
e calcular a m\xE9trica apenas no final.`),$s.forEach(a),or=c(e),h(Ba.$$.fragment,e),rr=c(e),is=r(e,"A",{id:!0}),n(is).forEach(a),nr=c(e),oe=r(e,"H2",{class:!0});var Rr=n(oe);Oe=r(Rr,"A",{id:!0,class:!0,href:!0});var Pm=n(Oe);At=r(Pm,"SPAN",{});var zm=n(At);h(Ga.$$.fragment,zm),zm.forEach(a),Pm.forEach(a),Pi=c(Rr),Tt=r(Rr,"SPAN",{});var Cm=n(Tt);zi=p(Cm,"Recursos adicionais"),Cm.forEach(a),Rr.forEach(a),lr=c(e),ps=r(e,"P",{});var Dm=n(ps);Ci=p(Dm,"Para mais exemplos de fine-tuning acesse:"),Dm.forEach(a),ir=c(e),Fe=r(e,"UL",{});var Br=n(Fe);Pt=r(Br,"LI",{});var xm=n(Pt);ms=r(xm,"P",{});var Ii=n(ms);Ka=r(Ii,"A",{href:!0,rel:!0});var Sm=n(Ka);Di=p(Sm,"\u{1F917} Transformers Examples"),Sm.forEach(a),xi=p(Ii,` inclui scripts
para treinas tarefas comuns de NLP em PyTorch e TensorFlow.`),Ii.forEach(a),xm.forEach(a),Si=c(Br),zt=r(Br,"LI",{});var Om=n(zt);cs=r(Om,"P",{});var Li=n(cs);ds=r(Li,"A",{href:!0});var Fm=n(ds);Oi=p(Fm,"\u{1F917} Transformers Notebooks"),Fm.forEach(a),Fi=p(Li,` cont\xE9m v\xE1rios notebooks sobre como aplicar o fine-tuning a um modelo
para tarefas espec\xEDficas no PyTorch e TensorFlow.`),Li.forEach(a),Om.forEach(a),Br.forEach(a),this.h()},h(){d(u,"name","hf:doc:metadata"),d(u,"content",JSON.stringify(Jm)),d(w,"id","finetuning-de-um-modelo-prtreinado"),d(w,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(w,"href","#finetuning-de-um-modelo-prtreinado"),d(b,"class","relative group"),d(Ya,"id","data-processing"),d(re,"id","preparando-um-dataset"),d(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(re,"href","#preparando-um-dataset"),d(G,"class","relative group"),d(Re,"href","https://huggingface.co/datasets/yelp_review_full"),d(Re,"rel","nofollow"),d(Ge,"href","https://huggingface.co/docs/datasets/process.html#map"),d(Ge,"rel","nofollow"),d(Ja,"id","trainer"),d(ie,"id","finetuning-com-o-trainer"),d(ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ie,"href","#finetuning-com-o-trainer"),d(K,"class","relative group"),d(Qe,"href","https://huggingface.co/datasets/yelp_review_full#data-fields"),d(Qe,"rel","nofollow"),d(ce,"id","hiperparmetros-de-treinamento"),d(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ce,"href","#hiperparmetros-de-treinamento"),d(U,"class","relative group"),d(Xe,"href","https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments"),d(Xe,"rel","nofollow"),d(de,"id","mtricas"),d(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(de,"href","#mtricas"),d(W,"class","relative group"),d(aa,"href","https://huggingface.co/metrics/accuracy"),d(aa,"rel","nofollow"),d(sa,"href","https://huggingface.co/docs/datasets/metrics.html"),d(sa,"rel","nofollow"),d(fe,"id","trainer"),d(fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(fe,"href","#trainer"),d(Y,"class","relative group"),d(es,"id","keras"),d(_e,"id","finetuning-com-keras"),d(_e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(_e,"href","#finetuning-com-keras"),d(Q,"class","relative group"),d(ve,"id","converso-do-dataset-ao-formato-do-tensorflow"),d(ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ve,"href","#converso-do-dataset-ao-formato-do-tensorflow"),d(V,"class","relative group"),d(ua,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.to_tf_dataset"),d(ua,"rel","nofollow"),d(be,"id","compilao-e-ajustes"),d(be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(be,"href","#compilao-e-ajustes"),d(J,"class","relative group"),d(_a,"href","https://keras.io/api/models/model_training_apis/"),d(_a,"rel","nofollow"),d(ts,"id","pytorch_native"),d(je,"id","finetune-em-pytorch-nativo"),d(je,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(je,"href","#finetune-em-pytorch-nativo"),d(X,"class","relative group"),d(ye,"id","dataloader"),d(ye,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ye,"href","#dataloader"),d(ee,"class","relative group"),d(Ae,"id","otimizao-e-configurao-do-learning-rate"),d(Ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ae,"href","#otimizao-e-configurao-do-learning-rate"),d(ae,"class","relative group"),d(Sa,"href","https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"),d(Sa,"rel","nofollow"),d(De,"id","ciclo-de-treinamento"),d(De,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(De,"href","#ciclo-de-treinamento"),d(se,"class","relative group"),d(La,"href","https://tqdm.github.io/"),d(La,"rel","nofollow"),d(Se,"id","mtricas"),d(Se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Se,"href","#mtricas"),d(te,"class","relative group"),d(Ra,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=add_batch#datasets.Metric.add_batch"),d(Ra,"rel","nofollow"),d(is,"id","additional-resources"),d(Oe,"id","recursos-adicionais"),d(Oe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Oe,"href","#recursos-adicionais"),d(oe,"class","relative group"),d(Ka,"href","https://github.com/huggingface/transformers/tree/main/examples"),d(Ka,"rel","nofollow"),d(ds,"href","notebooks")},m(e,t){s(document.head,u),l(e,k,t),l(e,b,t),s(b,w),s(w,z),g(y,z,null),s(b,F),s(b,C),s(C,A),l(e,E,t),g(D,e,t),l(e,N,t),l(e,Wa,t),s(Wa,Kr),l(e,xt,t),l(e,I,t),s(I,Le),s(Le,Ur),s(Le,bs),s(bs,Wr),s(Le,Yr),s(I,Qr),s(I,ws),s(ws,Vr),s(I,Jr),s(I,js),s(js,Xr),l(e,St,t),l(e,Ya,t),l(e,Ot,t),l(e,G,t),s(G,re),s(re,ks),g(Me,ks,null),s(G,Zr),s(G,Es),s(Es,en),l(e,Ft,t),g(He,e,t),l(e,Nt,t),l(e,Qa,t),s(Qa,an),l(e,It,t),l(e,ne,t),s(ne,sn),s(ne,Re),s(Re,tn),s(ne,on),l(e,Lt,t),g(Be,e,t),l(e,Mt,t),l(e,le,t),s(le,rn),s(le,Ge),s(Ge,ys),s(ys,nn),s(le,ln),l(e,Ht,t),g(Ke,e,t),l(e,Rt,t),l(e,Va,t),s(Va,pn),l(e,Bt,t),g(Ue,e,t),l(e,Gt,t),l(e,Ja,t),l(e,Kt,t),l(e,K,t),s(K,ie),s(ie,qs),g(We,qs,null),s(K,mn),s(K,Xa),s(Xa,cn),s(Xa,As),s(As,dn),l(e,Ut,t),g(Ye,e,t),l(e,Wt,t),l(e,L,t),s(L,un),s(L,Ts),s(Ts,fn),s(L,hn),s(L,Ps),s(Ps,gn),s(L,_n),l(e,Yt,t),l(e,pe,t),s(pe,vn),s(pe,Qe),s(Qe,$n),s(pe,bn),l(e,Qt,t),g(Ve,e,t),l(e,Vt,t),g(me,e,t),l(e,Jt,t),l(e,U,t),s(U,ce),s(ce,zs),g(Je,zs,null),s(U,wn),s(U,Cs),s(Cs,jn),l(e,Xt,t),l(e,M,t),s(M,kn),s(M,Ds),s(Ds,En),s(M,yn),s(M,Xe),s(Xe,qn),s(M,An),l(e,Zt,t),l(e,Za,t),s(Za,Tn),l(e,eo,t),g(Ze,e,t),l(e,ao,t),l(e,W,t),s(W,de),s(de,xs),g(ea,xs,null),s(W,Pn),s(W,Ss),s(Ss,zn),l(e,so,t),l(e,q,t),s(q,Cn),s(q,Os),s(Os,Dn),s(q,xn),s(q,Fs),s(Fs,Sn),s(q,On),s(q,aa),s(aa,Ns),s(Ns,Fn),s(q,Nn),s(q,Is),s(Is,In),s(q,Ln),s(q,sa),s(sa,Mn),s(q,Hn),l(e,to,t),g(ta,e,t),l(e,oo,t),l(e,x,t),s(x,Rn),s(x,Ls),s(Ls,Bn),s(x,Gn),s(x,Ms),s(Ms,Kn),s(x,Un),s(x,Hs),s(Hs,Wn),s(x,Yn),l(e,ro,t),g(oa,e,t),l(e,no,t),l(e,ue,t),s(ue,Qn),s(ue,Rs),s(Rs,Vn),s(ue,Jn),l(e,lo,t),g(ra,e,t),l(e,io,t),l(e,Y,t),s(Y,fe),s(fe,Bs),g(na,Bs,null),s(Y,Xn),s(Y,Gs),s(Gs,Zn),l(e,po,t),l(e,he,t),s(he,el),s(he,Ks),s(Ks,al),s(he,sl),l(e,mo,t),g(la,e,t),l(e,co,t),l(e,ge,t),s(ge,tl),s(ge,Us),s(Us,ol),s(ge,rl),l(e,uo,t),g(ia,e,t),l(e,fo,t),l(e,es,t),l(e,ho,t),l(e,Q,t),s(Q,_e),s(_e,Ws),g(pa,Ws,null),s(Q,nl),s(Q,Ys),s(Ys,ll),l(e,go,t),g(ma,e,t),l(e,_o,t),l(e,as,t),s(as,il),l(e,vo,t),l(e,V,t),s(V,ve),s(ve,Qs),g(ca,Qs,null),s(V,pl),s(V,Vs),s(Vs,ml),l(e,$o,t),l(e,H,t),s(H,cl),s(H,Js),s(Js,dl),s(H,ul),s(H,Xs),s(Xs,fl),s(H,hl),l(e,bo,t),g(da,e,t),l(e,wo,t),g($e,e,t),l(e,jo,t),l(e,S,t),s(S,gl),s(S,ua),s(ua,Zs),s(Zs,_l),s(S,vl),s(S,et),s(et,$l),s(S,bl),s(S,at),s(at,wl),s(S,jl),l(e,ko,t),g(fa,e,t),l(e,Eo,t),l(e,J,t),s(J,be),s(be,st),g(ha,st,null),s(J,kl),s(J,tt),s(tt,El),l(e,yo,t),l(e,ss,t),s(ss,yl),l(e,qo,t),g(ga,e,t),l(e,Ao,t),l(e,we,t),s(we,ql),s(we,_a),s(_a,ot),s(ot,Al),s(we,Tl),l(e,To,t),g(va,e,t),l(e,Po,t),l(e,ts,t),l(e,zo,t),l(e,X,t),s(X,je),s(je,rt),g($a,rt,null),s(X,Pl),s(X,nt),s(nt,zl),l(e,Co,t),g(ba,e,t),l(e,Do,t),l(e,ke,t),s(ke,Cl),s(ke,lt),s(lt,Dl),s(ke,xl),l(e,xo,t),l(e,os,t),s(os,Sl),l(e,So,t),g(wa,e,t),l(e,Oo,t),l(e,Ee,t),s(Ee,Ol),s(Ee,it),s(it,Fl),s(Ee,Nl),l(e,Fo,t),l(e,R,t),s(R,ja),s(ja,ka),s(ka,Il),s(ka,pt),s(pt,Ll),s(ka,Ml),s(ja,Hl),g(Ea,ja,null),s(R,Rl),s(R,ya),s(ya,Z),s(Z,Bl),s(Z,mt),s(mt,Gl),s(Z,Kl),s(Z,ct),s(ct,Ul),s(Z,Wl),s(ya,Yl),g(qa,ya,null),s(R,Ql),s(R,Aa),s(Aa,dt),s(dt,Vl),s(Aa,Jl),g(Ta,Aa,null),l(e,No,t),l(e,rs,t),s(rs,Xl),l(e,Io,t),g(Pa,e,t),l(e,Lo,t),l(e,ee,t),s(ee,ye),s(ye,ut),g(za,ut,null),s(ee,Zl),s(ee,ft),s(ft,ei),l(e,Mo,t),l(e,qe,t),s(qe,ai),s(qe,ht),s(ht,si),s(qe,ti),l(e,Ho,t),g(Ca,e,t),l(e,Ro,t),l(e,ns,t),s(ns,oi),l(e,Bo,t),g(Da,e,t),l(e,Go,t),l(e,ae,t),s(ae,Ae),s(Ae,gt),g(xa,gt,null),s(ae,ri),s(ae,_t),s(_t,ni),l(e,Ko,t),l(e,Te,t),s(Te,li),s(Te,Sa),s(Sa,vt),s(vt,ii),s(Te,pi),l(e,Uo,t),g(Oa,e,t),l(e,Wo,t),l(e,Pe,t),s(Pe,mi),s(Pe,$t),s($t,ci),s(Pe,di),l(e,Yo,t),g(Fa,e,t),l(e,Qo,t),l(e,ze,t),s(ze,ui),s(ze,bt),s(bt,fi),s(ze,hi),l(e,Vo,t),g(Na,e,t),l(e,Jo,t),g(Ce,e,t),l(e,Xo,t),l(e,ls,t),s(ls,gi),l(e,Zo,t),l(e,se,t),s(se,De),s(De,wt),g(Ia,wt,null),s(se,_i),s(se,jt),s(jt,vi),l(e,er,t),l(e,xe,t),s(xe,$i),s(xe,La),s(La,bi),s(xe,wi),l(e,ar,t),g(Ma,e,t),l(e,sr,t),l(e,te,t),s(te,Se),s(Se,kt),g(Ha,kt,null),s(te,ji),s(te,Et),s(Et,ki),l(e,tr,t),l(e,B,t),s(B,Ei),s(B,yt),s(yt,yi),s(B,qi),s(B,Ra),s(Ra,qt),s(qt,Ai),s(B,Ti),l(e,or,t),g(Ba,e,t),l(e,rr,t),l(e,is,t),l(e,nr,t),l(e,oe,t),s(oe,Oe),s(Oe,At),g(Ga,At,null),s(oe,Pi),s(oe,Tt),s(Tt,zi),l(e,lr,t),l(e,ps,t),s(ps,Ci),l(e,ir,t),l(e,Fe,t),s(Fe,Pt),s(Pt,ms),s(ms,Ka),s(Ka,Di),s(ms,xi),s(Fe,Si),s(Fe,zt),s(zt,cs),s(cs,ds),s(ds,Oi),s(cs,Fi),pr=!0},p(e,[t]){const Ua={};t&2&&(Ua.$$scope={dirty:t,ctx:e}),me.$set(Ua);const Ct={};t&2&&(Ct.$$scope={dirty:t,ctx:e}),$e.$set(Ct);const Dt={};t&2&&(Dt.$$scope={dirty:t,ctx:e}),Ce.$set(Dt)},i(e){pr||(_(y.$$.fragment,e),_(D.$$.fragment,e),_(Me.$$.fragment,e),_(He.$$.fragment,e),_(Be.$$.fragment,e),_(Ke.$$.fragment,e),_(Ue.$$.fragment,e),_(We.$$.fragment,e),_(Ye.$$.fragment,e),_(Ve.$$.fragment,e),_(me.$$.fragment,e),_(Je.$$.fragment,e),_(Ze.$$.fragment,e),_(ea.$$.fragment,e),_(ta.$$.fragment,e),_(oa.$$.fragment,e),_(ra.$$.fragment,e),_(na.$$.fragment,e),_(la.$$.fragment,e),_(ia.$$.fragment,e),_(pa.$$.fragment,e),_(ma.$$.fragment,e),_(ca.$$.fragment,e),_(da.$$.fragment,e),_($e.$$.fragment,e),_(fa.$$.fragment,e),_(ha.$$.fragment,e),_(ga.$$.fragment,e),_(va.$$.fragment,e),_($a.$$.fragment,e),_(ba.$$.fragment,e),_(wa.$$.fragment,e),_(Ea.$$.fragment,e),_(qa.$$.fragment,e),_(Ta.$$.fragment,e),_(Pa.$$.fragment,e),_(za.$$.fragment,e),_(Ca.$$.fragment,e),_(Da.$$.fragment,e),_(xa.$$.fragment,e),_(Oa.$$.fragment,e),_(Fa.$$.fragment,e),_(Na.$$.fragment,e),_(Ce.$$.fragment,e),_(Ia.$$.fragment,e),_(Ma.$$.fragment,e),_(Ha.$$.fragment,e),_(Ba.$$.fragment,e),_(Ga.$$.fragment,e),pr=!0)},o(e){v(y.$$.fragment,e),v(D.$$.fragment,e),v(Me.$$.fragment,e),v(He.$$.fragment,e),v(Be.$$.fragment,e),v(Ke.$$.fragment,e),v(Ue.$$.fragment,e),v(We.$$.fragment,e),v(Ye.$$.fragment,e),v(Ve.$$.fragment,e),v(me.$$.fragment,e),v(Je.$$.fragment,e),v(Ze.$$.fragment,e),v(ea.$$.fragment,e),v(ta.$$.fragment,e),v(oa.$$.fragment,e),v(ra.$$.fragment,e),v(na.$$.fragment,e),v(la.$$.fragment,e),v(ia.$$.fragment,e),v(pa.$$.fragment,e),v(ma.$$.fragment,e),v(ca.$$.fragment,e),v(da.$$.fragment,e),v($e.$$.fragment,e),v(fa.$$.fragment,e),v(ha.$$.fragment,e),v(ga.$$.fragment,e),v(va.$$.fragment,e),v($a.$$.fragment,e),v(ba.$$.fragment,e),v(wa.$$.fragment,e),v(Ea.$$.fragment,e),v(qa.$$.fragment,e),v(Ta.$$.fragment,e),v(Pa.$$.fragment,e),v(za.$$.fragment,e),v(Ca.$$.fragment,e),v(Da.$$.fragment,e),v(xa.$$.fragment,e),v(Oa.$$.fragment,e),v(Fa.$$.fragment,e),v(Na.$$.fragment,e),v(Ce.$$.fragment,e),v(Ia.$$.fragment,e),v(Ma.$$.fragment,e),v(Ha.$$.fragment,e),v(Ba.$$.fragment,e),v(Ga.$$.fragment,e),pr=!1},d(e){a(u),e&&a(k),e&&a(b),$(y),e&&a(E),$(D,e),e&&a(N),e&&a(Wa),e&&a(xt),e&&a(I),e&&a(St),e&&a(Ya),e&&a(Ot),e&&a(G),$(Me),e&&a(Ft),$(He,e),e&&a(Nt),e&&a(Qa),e&&a(It),e&&a(ne),e&&a(Lt),$(Be,e),e&&a(Mt),e&&a(le),e&&a(Ht),$(Ke,e),e&&a(Rt),e&&a(Va),e&&a(Bt),$(Ue,e),e&&a(Gt),e&&a(Ja),e&&a(Kt),e&&a(K),$(We),e&&a(Ut),$(Ye,e),e&&a(Wt),e&&a(L),e&&a(Yt),e&&a(pe),e&&a(Qt),$(Ve,e),e&&a(Vt),$(me,e),e&&a(Jt),e&&a(U),$(Je),e&&a(Xt),e&&a(M),e&&a(Zt),e&&a(Za),e&&a(eo),$(Ze,e),e&&a(ao),e&&a(W),$(ea),e&&a(so),e&&a(q),e&&a(to),$(ta,e),e&&a(oo),e&&a(x),e&&a(ro),$(oa,e),e&&a(no),e&&a(ue),e&&a(lo),$(ra,e),e&&a(io),e&&a(Y),$(na),e&&a(po),e&&a(he),e&&a(mo),$(la,e),e&&a(co),e&&a(ge),e&&a(uo),$(ia,e),e&&a(fo),e&&a(es),e&&a(ho),e&&a(Q),$(pa),e&&a(go),$(ma,e),e&&a(_o),e&&a(as),e&&a(vo),e&&a(V),$(ca),e&&a($o),e&&a(H),e&&a(bo),$(da,e),e&&a(wo),$($e,e),e&&a(jo),e&&a(S),e&&a(ko),$(fa,e),e&&a(Eo),e&&a(J),$(ha),e&&a(yo),e&&a(ss),e&&a(qo),$(ga,e),e&&a(Ao),e&&a(we),e&&a(To),$(va,e),e&&a(Po),e&&a(ts),e&&a(zo),e&&a(X),$($a),e&&a(Co),$(ba,e),e&&a(Do),e&&a(ke),e&&a(xo),e&&a(os),e&&a(So),$(wa,e),e&&a(Oo),e&&a(Ee),e&&a(Fo),e&&a(R),$(Ea),$(qa),$(Ta),e&&a(No),e&&a(rs),e&&a(Io),$(Pa,e),e&&a(Lo),e&&a(ee),$(za),e&&a(Mo),e&&a(qe),e&&a(Ho),$(Ca,e),e&&a(Ro),e&&a(ns),e&&a(Bo),$(Da,e),e&&a(Go),e&&a(ae),$(xa),e&&a(Ko),e&&a(Te),e&&a(Uo),$(Oa,e),e&&a(Wo),e&&a(Pe),e&&a(Yo),$(Fa,e),e&&a(Qo),e&&a(ze),e&&a(Vo),$(Na,e),e&&a(Jo),$(Ce,e),e&&a(Xo),e&&a(ls),e&&a(Zo),e&&a(se),$(Ia),e&&a(er),e&&a(xe),e&&a(ar),$(Ma,e),e&&a(sr),e&&a(te),$(Ha),e&&a(tr),e&&a(B),e&&a(or),$(Ba,e),e&&a(rr),e&&a(is),e&&a(nr),e&&a(oe),$(Ga),e&&a(lr),e&&a(ps),e&&a(ir),e&&a(Fe)}}}const Jm={local:"finetuning-de-um-modelo-prtreinado",sections:[{local:"preparando-um-dataset",title:"Preparando um dataset"},{local:"finetuning-com-o-trainer",sections:[{local:"hiperparmetros-de-treinamento",title:"Hiperpar\xE2metros de treinamento"},{local:"mtricas",title:"M\xE9tricas"},{local:"trainer",title:"Trainer"}],title:"Fine-tuning com o `Trainer`"},{local:"finetuning-com-keras",sections:[{local:"converso-do-dataset-ao-formato-do-tensorflow",title:"Convers\xE3o do dataset ao formato do TensorFlow"},{local:"compilao-e-ajustes",title:"Compila\xE7\xE3o e ajustes"}],title:"Fine-tuning com Keras"},{local:"finetune-em-pytorch-nativo",sections:[{local:"dataloader",title:"DataLoader"},{local:"otimizao-e-configurao-do-learning-rate",title:"Otimiza\xE7\xE3o e configura\xE7\xE3o do Learning Rate"},{local:"ciclo-de-treinamento",title:"Ciclo de treinamento"},{local:"mtricas",title:"M\xE9tricas"}],title:"Fine-tune em PyTorch nativo"},{local:"recursos-adicionais",title:"Recursos adicionais"}],title:"Fine-tuning de um modelo pr\xE9-treinado"};function Xm(P){return Bm(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class tc extends Lm{constructor(u){super();Mm(this,u,Xm,Vm,Hm,{})}}export{tc as default,Jm as metadata};
