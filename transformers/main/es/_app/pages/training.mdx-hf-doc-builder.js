import{S as Fc,i as Nc,s as Oc,e as r,k as c,w as u,t as i,M as Lc,c as n,d as a,m,a as l,x as f,h as p,b as d,G as t,g as o,y as h,q as g,o as _,B as v,v as Ic}from"../chunks/vendor-hf-doc-builder.js";import{T as Li}from"../chunks/Tip-hf-doc-builder.js";import{Y as Rn}from"../chunks/Youtube-hf-doc-builder.js";import{I as z}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as j}from"../chunks/CodeBlock-hf-doc-builder.js";import{D as Mc}from"../chunks/DocNotebookDropdown-hf-doc-builder.js";function Hc(se){let $,E;return{c(){$=r("p"),E=i(`Ver\xE1s una advertencia acerca de que algunos de los pesos pre-entrenados no est\xE1n siendo utilizados y que algunos pesos est\xE1n siendo inicializados al azar. No te preocupes, esto es completamente normal.
No te preocupes, esto es completamente normal. El head/cabezal pre-entrenado del modelo BERT se descarta y se sustituye por un head de clasificaci\xF3n inicializado aleatoriamente. Puedes aplicar fine-tuning a este nuevo head del modelo en tu tarea de clasificaci\xF3n de secuencias haciendo transfer learning del modelo pre-entrenado.`)},l(b){$=n(b,"P",{});var w=l($);E=p(w,`Ver\xE1s una advertencia acerca de que algunos de los pesos pre-entrenados no est\xE1n siendo utilizados y que algunos pesos est\xE1n siendo inicializados al azar. No te preocupes, esto es completamente normal.
No te preocupes, esto es completamente normal. El head/cabezal pre-entrenado del modelo BERT se descarta y se sustituye por un head de clasificaci\xF3n inicializado aleatoriamente. Puedes aplicar fine-tuning a este nuevo head del modelo en tu tarea de clasificaci\xF3n de secuencias haciendo transfer learning del modelo pre-entrenado.`),w.forEach(a)},m(b,w){o(b,$,w),t($,E)},d(b){b&&a($)}}}function Rc(se){let $,E,b,w,P,y,F;return{c(){$=r("p"),E=r("code"),b=i("Trainer"),w=i(" utiliza "),P=r("code"),y=i("DataCollatorWithPadding"),F=i(" por defecto por lo que no es necesario especificar expl\xEDcitamente un intercalador de datos (data collator, en ingl\xE9s).")},l(T){$=n(T,"P",{});var k=l($);E=n(k,"CODE",{});var q=l(E);b=p(q,"Trainer"),q.forEach(a),w=p(k," utiliza "),P=n(k,"CODE",{});var C=l(P);y=p(C,"DataCollatorWithPadding"),C.forEach(a),F=p(k," por defecto por lo que no es necesario especificar expl\xEDcitamente un intercalador de datos (data collator, en ingl\xE9s)."),k.forEach(a)},m(T,k){o(T,$,k),t($,E),t(E,b),t($,w),t($,P),t(P,y),t($,F)},d(T){T&&a($)}}}function Bc(se){let $,E,b,w,P,y,F,T;return{c(){$=r("p"),E=i("Consigue acceso gratuito a una GPU en la nube si es que no tienes este recurso de forma local con un notebook alojado en "),b=r("a"),w=i("Colaboratory"),P=i(" o "),y=r("a"),F=i("SageMaker StudioLab"),T=i("."),this.h()},l(k){$=n(k,"P",{});var q=l($);E=p(q,"Consigue acceso gratuito a una GPU en la nube si es que no tienes este recurso de forma local con un notebook alojado en "),b=n(q,"A",{href:!0,rel:!0});var C=l(b);w=p(C,"Colaboratory"),C.forEach(a),P=p(q," o "),y=n(q,"A",{href:!0,rel:!0});var Le=l(y);F=p(Le,"SageMaker StudioLab"),Le.forEach(a),T=p(q,"."),q.forEach(a),this.h()},h(){d(b,"href","https://colab.research.google.com/"),d(b,"rel","nofollow"),d(y,"href","https://studiolab.sagemaker.aws/"),d(y,"rel","nofollow")},m(k,q){o(k,$,q),t($,E),t($,b),t(b,w),t($,P),t($,y),t(y,F),t($,T)},d(k){k&&a($)}}}function Gc(se){let $,E,b,w,P,y,F,T,k,q,C,Le,Ua,Bn,Ds,O,Ie,Gn,$t,Kn,Un,Wn,bt,Yn,Vn,jt,Jn,xs,Wa,Ss,B,re,wt,Me,Xn,yt,Zn,Fs,He,Ns,Ya,Qn,Os,ne,el,Re,al,tl,Ls,Be,Is,Va,sl,Ms,Ge,Hs,Ja,rl,Rs,Ke,Bs,Xa,Gs,G,le,Et,Ue,nl,Za,ll,kt,ol,Ks,We,Us,L,il,qt,pl,cl,At,ml,dl,Ws,oe,ul,Ye,fl,hl,Ys,Ve,Vs,ie,Js,K,pe,Pt,Je,gl,Tt,_l,Xs,I,vl,zt,$l,bl,Xe,jl,wl,Zs,Qa,yl,Qs,Ze,er,U,ce,Ct,Qe,El,Dt,kl,ar,A,ql,xt,Al,Pl,St,Tl,zl,ea,Ft,Cl,Dl,Nt,xl,Sl,aa,Fl,Nl,tr,ta,sr,D,Ol,Ot,Ll,Il,Lt,Ml,Hl,It,Rl,Bl,rr,sa,nr,me,Gl,Mt,Kl,Ul,lr,ra,or,W,de,Ht,na,Wl,Rt,Yl,ir,ue,Vl,Bt,Jl,Xl,pr,la,cr,fe,Zl,Gt,Ql,eo,mr,oa,dr,et,ur,Y,he,Kt,ia,ao,Ut,to,fr,pa,hr,at,so,gr,V,ge,Wt,ca,ro,Yt,no,_r,M,lo,Vt,oo,io,Jt,po,co,vr,ma,$r,_e,br,x,mo,da,Xt,uo,fo,Zt,ho,go,Qt,_o,vo,jr,ua,wr,J,ve,es,fa,$o,as,bo,yr,tt,jo,Er,ha,kr,$e,wo,ga,ts,yo,Eo,qr,_a,Ar,st,Pr,X,be,ss,va,ko,rs,qo,Tr,$a,zr,je,Ao,ns,Po,To,Cr,rt,zo,Dr,ba,xr,we,Co,ls,Do,xo,Sr,H,ja,wa,So,os,Fo,No,Oo,ya,Lo,Ea,N,Io,is,Mo,Ho,ps,Ro,Bo,cs,Go,Ko,Uo,ka,Wo,qa,ms,Yo,Vo,Aa,Fr,nt,Jo,Nr,Pa,Or,Z,ye,ds,Ta,Xo,us,Zo,Lr,Ee,Qo,fs,ei,ai,Ir,za,Mr,lt,ti,Hr,Ca,Rr,Q,ke,hs,Da,si,gs,ri,Br,qe,ni,xa,_s,li,oi,Gr,Sa,Kr,Ae,ii,vs,pi,ci,Ur,Fa,Wr,Pe,mi,$s,di,ui,Yr,Na,Vr,Te,Jr,ot,fi,Xr,ee,ze,bs,Oa,hi,js,gi,Zr,Ce,_i,La,vi,$i,Qr,Ia,en,ae,De,ws,Ma,bi,ys,ji,an,R,wi,Es,yi,Ei,Ha,ks,ki,qi,tn,Ra,sn,it,rn,te,xe,qs,Ba,Ai,As,Pi,nn,pt,Ti,ln,Se,Ps,ct,Ga,zi,Ci,Di,Ts,mt,dt,xi,Si,on;return y=new z({}),C=new Mc({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/es/training.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/es/pytorch/training.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/es/tensorflow/training.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/es/training.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/es/pytorch/training.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/es/tensorflow/training.ipynb"}]}}),Me=new z({}),He=new Rn({props:{id:"_BZearw7f0w"}}),Be=new j({props:{code:`from datasets import load_dataset

dataset = load_dataset("yelp_review_full")
dataset[100]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;yelp_review_full&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">100</span>]
{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\&#x27;s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\&#x27;s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\&quot;serving off their orders\\\\&quot; when they didn\\&#x27;t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\&#x27;t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\&#x27;ve eaten at various McDonalds restaurants for over 30 years. I\\&#x27;ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!&#x27;</span>}`}}),Ge=new j({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")


def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)


tokenized_datasets = dataset.map(tokenize_function, batched=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&quot;text&quot;</span>], padding=<span class="hljs-string">&quot;max_length&quot;</span>, truncation=<span class="hljs-literal">True</span>)


<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets = dataset.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)`}}),Ke=new j({props:{code:`small_train_dataset = tokenized_datasets["train"].shuffle(seed=42).select(range(1000))
small_eval_dataset = tokenized_datasets["test"].shuffle(seed=42).select(range(1000))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>small_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>small_eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;test&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))`}}),Ue=new z({}),We=new Rn({props:{id:"nvBXf7s7vTI"}}),Ve=new j({props:{code:`from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, num_labels=<span class="hljs-number">5</span>)`}}),ie=new Li({props:{$$slots:{default:[Hc]},$$scope:{ctx:se}}}),Je=new z({}),Ze=new j({props:{code:`from transformers import TrainingArguments

training_args = TrainingArguments(output_dir="test_trainer")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(output_dir=<span class="hljs-string">&quot;test_trainer&quot;</span>)`}}),Qe=new z({}),ta=new j({props:{code:`import numpy as np
from datasets import load_metric

metric = load_metric("accuracy")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_metric

<span class="hljs-meta">&gt;&gt;&gt; </span>metric = load_metric(<span class="hljs-string">&quot;accuracy&quot;</span>)`}}),sa=new j({props:{code:`def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):
<span class="hljs-meta">... </span>    logits, labels = eval_pred
<span class="hljs-meta">... </span>    predictions = np.argmax(logits, axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> metric.compute(predictions=predictions, references=labels)`}}),ra=new j({props:{code:`from transformers import TrainingArguments

training_args = TrainingArguments(output_dir="test_trainer", evaluation_strategy="epoch")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(output_dir=<span class="hljs-string">&quot;test_trainer&quot;</span>, evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>)`}}),na=new z({}),la=new j({props:{code:`trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=small_train_dataset,
    eval_dataset=small_eval_dataset,
    compute_metrics=compute_metrics,
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=small_train_dataset,
<span class="hljs-meta">... </span>    eval_dataset=small_eval_dataset,
<span class="hljs-meta">... </span>    compute_metrics=compute_metrics,
<span class="hljs-meta">... </span>)`}}),oa=new j({props:{code:"trainer.train()",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()'}}),ia=new z({}),pa=new Rn({props:{id:"rnTGBy2ax1c"}}),ca=new z({}),ma=new j({props:{code:`from transformers import DefaultDataCollator

data_collator = DefaultDataCollator(return_tensors="tf")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DefaultDataCollator

<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DefaultDataCollator(return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`}}),_e=new Li({props:{$$slots:{default:[Rc]},$$scope:{ctx:se}}}),ua=new j({props:{code:`tf_train_dataset = small_train_dataset.to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=8,
)

tf_validation_dataset = small_eval_dataset.to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=False,
    collate_fn=data_collator,
    batch_size=8,
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_train_dataset = small_train_dataset.to_tf_dataset(
<span class="hljs-meta">... </span>    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
<span class="hljs-meta">... </span>    label_cols=[<span class="hljs-string">&quot;labels&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">8</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_validation_dataset = small_eval_dataset.to_tf_dataset(
<span class="hljs-meta">... </span>    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
<span class="hljs-meta">... </span>    label_cols=[<span class="hljs-string">&quot;labels&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">False</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">8</span>,
<span class="hljs-meta">... </span>)`}}),fa=new z({}),ha=new j({props:{code:`import tensorflow as tf
from transformers import TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, num_labels=<span class="hljs-number">5</span>)`}}),_a=new j({props:{code:`model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=tf.metrics.SparseCategoricalAccuracy(),
)

model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">compile</span>(
<span class="hljs-meta">... </span>    optimizer=tf.keras.optimizers.Adam(learning_rate=<span class="hljs-number">5e-5</span>),
<span class="hljs-meta">... </span>    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>),
<span class="hljs-meta">... </span>    metrics=tf.metrics.SparseCategoricalAccuracy(),
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=<span class="hljs-number">3</span>)`}}),va=new z({}),$a=new Rn({props:{id:"Dh9CL8fyG80"}}),ba=new j({props:{code:`del model
del pytorch_model
del trainer
torch.cuda.empty_cache()`,highlighted:`<span class="hljs-keyword">del</span> model
<span class="hljs-keyword">del</span> pytorch_model
<span class="hljs-keyword">del</span> trainer
torch.cuda.empty_cache()`}}),ya=new j({props:{code:'tokenized_datasets = tokenized_datasets.remove_columns(["text"])',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets = tokenized_datasets.remove_columns([<span class="hljs-string">&quot;text&quot;</span>])'}}),ka=new j({props:{code:'tokenized_datasets = tokenized_datasets.rename_column("label", "labels")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets = tokenized_datasets.rename_column(<span class="hljs-string">&quot;label&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>)'}}),Aa=new j({props:{code:'tokenized_datasets.set_format("torch")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets.set_format(<span class="hljs-string">&quot;torch&quot;</span>)'}}),Pa=new j({props:{code:`small_train_dataset = tokenized_datasets["train"].shuffle(seed=42).select(range(1000))
small_eval_dataset = tokenized_datasets["test"].shuffle(seed=42).select(range(1000))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>small_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>small_eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;test&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))`}}),Ta=new z({}),za=new j({props:{code:`from torch.utils.data import DataLoader

train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=8)
eval_dataloader = DataLoader(small_eval_dataset, batch_size=8)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader

<span class="hljs-meta">&gt;&gt;&gt; </span>train_dataloader = DataLoader(small_train_dataset, shuffle=<span class="hljs-literal">True</span>, batch_size=<span class="hljs-number">8</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>eval_dataloader = DataLoader(small_eval_dataset, batch_size=<span class="hljs-number">8</span>)`}}),Ca=new j({props:{code:`from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, num_labels=<span class="hljs-number">5</span>)`}}),Da=new z({}),Sa=new j({props:{code:`from torch.optim import AdamW

optimizer = AdamW(model.parameters(), lr=5e-5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> AdamW

<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">5e-5</span>)`}}),Fa=new j({props:{code:`from transformers import get_scheduler

num_epochs = 3
num_training_steps = num_epochs * len(train_dataloader)
lr_scheduler = get_scheduler(
    name="linear", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> get_scheduler

<span class="hljs-meta">&gt;&gt;&gt; </span>num_epochs = <span class="hljs-number">3</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>num_training_steps = num_epochs * <span class="hljs-built_in">len</span>(train_dataloader)
<span class="hljs-meta">&gt;&gt;&gt; </span>lr_scheduler = get_scheduler(
<span class="hljs-meta">... </span>    name=<span class="hljs-string">&quot;linear&quot;</span>, optimizer=optimizer, num_warmup_steps=<span class="hljs-number">0</span>, num_training_steps=num_training_steps
<span class="hljs-meta">... </span>)`}}),Na=new j({props:{code:`import torch

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
model.to(device)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>) <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.to(device)`}}),Te=new Li({props:{$$slots:{default:[Bc]},$$scope:{ctx:se}}}),Oa=new z({}),Ia=new j({props:{code:`from tqdm.auto import tqdm

progress_bar = tqdm(range(num_training_steps))

model.train()
for epoch in range(num_epochs):
    for batch in train_dataloader:
        batch = {k: v.to(device) for k, v in batch.items()}
        outputs = model(**batch)
        loss = outputs.loss
        loss.backward()

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm

<span class="hljs-meta">&gt;&gt;&gt; </span>progress_bar = tqdm(<span class="hljs-built_in">range</span>(num_training_steps))

<span class="hljs-meta">&gt;&gt;&gt; </span>model.train()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:
<span class="hljs-meta">... </span>        batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}
<span class="hljs-meta">... </span>        outputs = model(**batch)
<span class="hljs-meta">... </span>        loss = outputs.loss
<span class="hljs-meta">... </span>        loss.backward()

<span class="hljs-meta">... </span>        optimizer.step()
<span class="hljs-meta">... </span>        lr_scheduler.step()
<span class="hljs-meta">... </span>        optimizer.zero_grad()
<span class="hljs-meta">... </span>        progress_bar.update(<span class="hljs-number">1</span>)`}}),Ma=new z({}),Ra=new j({props:{code:`metric = load_metric("accuracy")
model.eval()
for batch in eval_dataloader:
    batch = {k: v.to(device) for k, v in batch.items()}
    with torch.no_grad():
        outputs = model(**batch)

    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)
    metric.add_batch(predictions=predictions, references=batch["labels"])

metric.compute()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>metric = load_metric(<span class="hljs-string">&quot;accuracy&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">eval</span>()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> eval_dataloader:
<span class="hljs-meta">... </span>    batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}
<span class="hljs-meta">... </span>    <span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>        outputs = model(**batch)

<span class="hljs-meta">... </span>    logits = outputs.logits
<span class="hljs-meta">... </span>    predictions = torch.argmax(logits, dim=-<span class="hljs-number">1</span>)
<span class="hljs-meta">... </span>    metric.add_batch(predictions=predictions, references=batch[<span class="hljs-string">&quot;labels&quot;</span>])

<span class="hljs-meta">&gt;&gt;&gt; </span>metric.compute()`}}),Ba=new z({}),{c(){$=r("meta"),E=c(),b=r("h1"),w=r("a"),P=r("span"),u(y.$$.fragment),F=c(),T=r("span"),k=i("Fine-tuning a un modelo pre-entrenado"),q=c(),u(C.$$.fragment),Le=c(),Ua=r("p"),Bn=i("El uso de un modelo pre-entrenado tiene importantes ventajas. Reduce los costos de computaci\xF3n, la huella de carbono y te permite utilizar modelos de \xFAltima generaci\xF3n sin tener que entrenar uno desde cero."),Ds=c(),O=r("ul"),Ie=r("li"),Gn=i("Fine-tuning a un modelo pre-entrenado con \u{1F917} Transformers "),$t=r("code"),Kn=i("Trainer"),Un=i("."),Wn=c(),bt=r("li"),Yn=i("Fine-tuning a un modelo pre-entrenado en TensorFlow con Keras."),Vn=c(),jt=r("li"),Jn=i("Fine-tuning a un modelo pre-entrenado en PyTorch nativo."),xs=c(),Wa=r("a"),Ss=c(),B=r("h2"),re=r("a"),wt=r("span"),u(Me.$$.fragment),Xn=c(),yt=r("span"),Zn=i("Prepara un dataset"),Fs=c(),u(He.$$.fragment),Ns=c(),Ya=r("p"),Qn=i("Antes de aplicar fine-tuning a un modelo pre-entrenado, descarga un dataset y prep\xE1ralo para el entrenamiento. El tutorial anterior nos ense\xF1\xF3 c\xF3mo procesar los datos para el entrenamiento, y ahora es la oportunidad de poner a prueba estas habilidades."),Os=c(),ne=r("p"),el=i("Comienza cargando el dataset de "),Re=r("a"),al=i("Yelp Reviews"),tl=i(":"),Ls=c(),u(Be.$$.fragment),Is=c(),Va=r("p"),sl=i("Como ya sabes, necesitas un tokenizador para procesar el texto e incluir una estrategia para el padding y el truncamiento para manejar cualquier longitud de secuencia variable. Para procesar tu dataset en un solo paso, utiliza el m\xE9todo de \u{1F917} Datasets\xA0mappara aplicar una funci\xF3n de preprocesamiento sobre todo el dataset:"),Ms=c(),u(Ge.$$.fragment),Hs=c(),Ja=r("p"),rl=i("Si lo deseas, puedes crear un subconjunto m\xE1s peque\xF1o del dataset completo para aplicarle fine-tuning y as\xED reducir el tiempo."),Rs=c(),u(Ke.$$.fragment),Bs=c(),Xa=r("a"),Gs=c(),G=r("h2"),le=r("a"),Et=r("span"),u(Ue.$$.fragment),nl=c(),Za=r("span"),ll=i("Fine-tuning con "),kt=r("code"),ol=i("Trainer"),Ks=c(),u(We.$$.fragment),Us=c(),L=r("p"),il=i("\u{1F917} Transformers proporciona una clase "),qt=r("code"),pl=i("Trainer"),cl=i(" optimizada para el entrenamiento de modelos de \u{1F917} Transformers, haciendo m\xE1s f\xE1cil el inicio del entrenamiento sin necesidad de escribir manualmente tu propio ciclo. La API del "),At=r("code"),ml=i("Trainer"),dl=i(" soporta una amplia gama de opciones de entrenamiento y caracter\xEDsticas como el logging, el gradient accumulation y el mixed precision."),Ws=c(),oe=r("p"),ul=i("Comienza cargando tu modelo y especifica el n\xFAmero de labels previstas. A partir del "),Ye=r("a"),fl=i("Card Dataset"),hl=i(" de Yelp Review, que como ya sabemos tiene 5 labels:"),Ys=c(),u(Ve.$$.fragment),Vs=c(),u(ie.$$.fragment),Js=c(),K=r("h3"),pe=r("a"),Pt=r("span"),u(Je.$$.fragment),gl=c(),Tt=r("span"),_l=i("Hiperpar\xE1metros de entrenamiento"),Xs=c(),I=r("p"),vl=i("A continuaci\xF3n, crea una clase "),zt=r("code"),$l=i("TrainingArguments"),bl=i(" que contenga todos los hiperpar\xE1metros que puedes ajustar as\xED como los indicadores para activar las diferentes opciones de entrenamiento. Para este tutorial puedes empezar con los "),Xe=r("a"),jl=i("hiperpar\xE1metros"),wl=i(" de entrenamiento por defecto, pero si\xE9ntete libre de experimentar con ellos para encontrar tu configuraci\xF3n \xF3ptima."),Zs=c(),Qa=r("p"),yl=i("Especifica d\xF3nde vas a guardar los checkpoints de tu entrenamiento:"),Qs=c(),u(Ze.$$.fragment),er=c(),U=r("h3"),ce=r("a"),Ct=r("span"),u(Qe.$$.fragment),El=c(),Dt=r("span"),kl=i("M\xE9tricas"),ar=c(),A=r("p"),ql=i("El "),xt=r("code"),Al=i("Trainer"),Pl=i(" no eval\xFAa autom\xE1ticamente el rendimiento del modelo durante el entrenamiento. Tendr\xE1s que pasarle a "),St=r("code"),Tl=i("Trainer"),zl=i(" una funci\xF3n para calcular y hacer un reporte de las m\xE9tricas. La biblioteca de \u{1F917} Datasets proporciona una funci\xF3n de "),ea=r("a"),Ft=r("code"),Cl=i("accuracy"),Dl=i(" simple que puedes cargar con la funci\xF3n "),Nt=r("code"),xl=i("load_metric"),Sl=i(" (ver este "),aa=r("a"),Fl=i("tutorial"),Nl=i(" para m\xE1s informaci\xF3n):"),tr=c(),u(ta.$$.fragment),sr=c(),D=r("p"),Ol=i("Define la funci\xF3n "),Ot=r("code"),Ll=i("compute"),Il=i(" en "),Lt=r("code"),Ml=i("metric"),Hl=i(" para calcular el accuracy de tus predicciones. Antes de pasar tus predicciones a "),It=r("code"),Rl=i("compute"),Bl=i(", necesitas convertir las predicciones a logits (recuerda que todos los modelos de \u{1F917} Transformers devuelven logits)."),rr=c(),u(sa.$$.fragment),nr=c(),me=r("p"),Gl=i("Si quieres controlar tus m\xE9tricas de evaluaci\xF3n durante el fine-tuning, especifica el par\xE1metro "),Mt=r("code"),Kl=i("evaluation_strategy"),Ul=i(" en tus argumentos de entrenamiento para que el modelo tenga en cuenta la m\xE9trica de evaluaci\xF3n al final de cada \xE9poca:"),lr=c(),u(ra.$$.fragment),or=c(),W=r("h3"),de=r("a"),Ht=r("span"),u(na.$$.fragment),Wl=c(),Rt=r("span"),Yl=i("Trainer"),ir=c(),ue=r("p"),Vl=i("Crea un objeto "),Bt=r("code"),Jl=i("Trainer"),Xl=i(" con tu modelo, argumentos de entrenamiento, datasets de entrenamiento y de prueba, y tu funci\xF3n de evaluaci\xF3n:"),pr=c(),u(la.$$.fragment),cr=c(),fe=r("p"),Zl=i("A continuaci\xF3n, aplica fine-tuning a tu modelo llamando "),Gt=r("code"),Ql=i("train()"),eo=i(":"),mr=c(),u(oa.$$.fragment),dr=c(),et=r("a"),ur=c(),Y=r("h2"),he=r("a"),Kt=r("span"),u(ia.$$.fragment),ao=c(),Ut=r("span"),to=i("Fine-tuning con Keras"),fr=c(),u(pa.$$.fragment),hr=c(),at=r("p"),so=i("Los modelos de \u{1F917} Transformers tambi\xE9n permiten realizar el entrenamiento en TensorFlow con la API de Keras. Solo es necesario hacer algunos cambios antes de hacer fine-tuning."),gr=c(),V=r("h3"),ge=r("a"),Wt=r("span"),u(ca.$$.fragment),ro=c(),Yt=r("span"),no=i("Convierte el dataset al formato de TensorFlow"),_r=c(),M=r("p"),lo=i("El "),Vt=r("code"),oo=i("DefaultDataCollator"),io=i(" junta los tensores en un batch para que el modelo se entrene en \xE9l. Aseg\xFArate de especificar "),Jt=r("code"),po=i("return_tensors"),co=i(" para devolver los tensores de TensorFlow:"),vr=c(),u(ma.$$.fragment),$r=c(),u(_e.$$.fragment),br=c(),x=r("p"),mo=i("A continuaci\xF3n, convierte los datasets tokenizados en datasets de TensorFlow con el m\xE9todo "),da=r("a"),Xt=r("code"),uo=i("to_tf_dataset"),fo=i(". Especifica tus entradas en "),Zt=r("code"),ho=i("columns"),go=i(" y tu etiqueta en "),Qt=r("code"),_o=i("label_cols"),vo=i(":"),jr=c(),u(ua.$$.fragment),wr=c(),J=r("h3"),ve=r("a"),es=r("span"),u(fa.$$.fragment),$o=c(),as=r("span"),bo=i("Compila y ajusta"),yr=c(),tt=r("p"),jo=i("Carguemos un modelo TensorFlow con el n\xFAmero esperado de labels:"),Er=c(),u(ha.$$.fragment),kr=c(),$e=r("p"),wo=i("A continuaci\xF3n, compila y aplica fine-tuning a tu modelo con "),ga=r("a"),ts=r("code"),yo=i("fit"),Eo=i(" como lo har\xEDas con cualquier otro modelo de Keras:"),qr=c(),u(_a.$$.fragment),Ar=c(),st=r("a"),Pr=c(),X=r("h2"),be=r("a"),ss=r("span"),u(va.$$.fragment),ko=c(),rs=r("span"),qo=i("Fine-tune en PyTorch nativo"),Tr=c(),u($a.$$.fragment),zr=c(),je=r("p"),Ao=i("El "),ns=r("code"),Po=i("Trainer"),To=i(" se encarga del ciclo de entrenamiento y permite aplicar fine-tuning a un modelo en una sola l\xEDnea de c\xF3digo. Para los que prefieran escribir su propio ciclo de entrenamiento, tambi\xE9n pueden aplicar fine-tuning a un modelo de \u{1F917} Transformers en PyTorch nativo."),Cr=c(),rt=r("p"),zo=i("En este punto, es posible que necesites reiniciar tu notebook o ejecutar el siguiente c\xF3digo para liberar algo de memoria:"),Dr=c(),u(ba.$$.fragment),xr=c(),we=r("p"),Co=i("A continuaci\xF3n, haremos un post-procesamiento manual al "),ls=r("code"),Do=i("tokenized_dataset"),xo=i(" y as\xED prepararlo para el entrenamiento."),Sr=c(),H=r("ol"),ja=r("li"),wa=r("p"),So=i("Elimina la columna de "),os=r("code"),Fo=i("text"),No=i(" porque el modelo no acepta texto en crudo como entrada:"),Oo=c(),u(ya.$$.fragment),Lo=c(),Ea=r("li"),N=r("p"),Io=i("Cambia el nombre de la columna de "),is=r("code"),Mo=i("label"),Ho=i(" a "),ps=r("code"),Ro=i("labels"),Bo=i(" porque el modelo espera que el argumento se llame "),cs=r("code"),Go=i("labels"),Ko=i(":"),Uo=c(),u(ka.$$.fragment),Wo=c(),qa=r("li"),ms=r("p"),Yo=i("Establece el formato del dataset para devolver tensores PyTorch en lugar de listas:"),Vo=c(),u(Aa.$$.fragment),Fr=c(),nt=r("p"),Jo=i("A continuaci\xF3n, crea un subconjunto m\xE1s peque\xF1o del dataset como se ha mostrado anteriormente para acelerar el fine-tuning:"),Nr=c(),u(Pa.$$.fragment),Or=c(),Z=r("h3"),ye=r("a"),ds=r("span"),u(Ta.$$.fragment),Xo=c(),us=r("span"),Zo=i("DataLoader"),Lr=c(),Ee=r("p"),Qo=i("Crea un "),fs=r("code"),ei=i("DataLoader"),ai=i(" para tus datasets de entrenamiento y de prueba para poder iterar sobre batches de datos:"),Ir=c(),u(za.$$.fragment),Mr=c(),lt=r("p"),ti=i("Carga tu modelo con el n\xFAmero de labels previstas:"),Hr=c(),u(Ca.$$.fragment),Rr=c(),Q=r("h3"),ke=r("a"),hs=r("span"),u(Da.$$.fragment),si=c(),gs=r("span"),ri=i("Optimiza y programa el learning rate"),Br=c(),qe=r("p"),ni=i("Crea un optimizador y el learning rate para aplicar fine-tuning al modelo. Vamos a utilizar el optimizador "),xa=r("a"),_s=r("code"),li=i("AdamW"),oi=i(" de PyTorch:"),Gr=c(),u(Sa.$$.fragment),Kr=c(),Ae=r("p"),ii=i("Crea el learning rate desde el "),vs=r("code"),pi=i("Trainer"),ci=i(":"),Ur=c(),u(Fa.$$.fragment),Wr=c(),Pe=r("p"),mi=i("Por \xFAltimo, especifica el "),$s=r("code"),di=i("device"),ui=i(" o entorno de ejecuci\xF3n para utilizar una GPU si tienes acceso a una. De lo contrario, el entrenamiento en una CPU puede llevarte varias horas en lugar de un par de minutos."),Yr=c(),u(Na.$$.fragment),Vr=c(),u(Te.$$.fragment),Jr=c(),ot=r("p"),fi=i("Genial, \xA1ahora podemos entrenar! \u{1F973}"),Xr=c(),ee=r("h3"),ze=r("a"),bs=r("span"),u(Oa.$$.fragment),hi=c(),js=r("span"),gi=i("Ciclo de entrenamiento"),Zr=c(),Ce=r("p"),_i=i("Para hacer un seguimiento al progreso del entrenamiento, utiliza la biblioteca "),La=r("a"),vi=i("tqdm"),$i=i(" para a\xF1adir una barra de progreso sobre el n\xFAmero de pasos de entrenamiento:"),Qr=c(),u(Ia.$$.fragment),en=c(),ae=r("h3"),De=r("a"),ws=r("span"),u(Ma.$$.fragment),bi=c(),ys=r("span"),ji=i("M\xE9tricas"),an=c(),R=r("p"),wi=i("De la misma manera que necesitas a\xF1adir una funci\xF3n de evaluaci\xF3n al "),Es=r("code"),yi=i("Trainer"),Ei=i(", necesitas hacer lo mismo cuando escribas tu propio ciclo de entrenamiento. Pero en lugar de calcular y reportar la m\xE9trica al final de cada \xE9poca, esta vez acumular\xE1s todos los batches con "),Ha=r("a"),ks=r("code"),ki=i("add_batch"),qi=i(" y calcular\xE1s la m\xE9trica al final."),tn=c(),u(Ra.$$.fragment),sn=c(),it=r("a"),rn=c(),te=r("h2"),xe=r("a"),qs=r("span"),u(Ba.$$.fragment),Ai=c(),As=r("span"),Pi=i("Recursos adicionales"),nn=c(),pt=r("p"),Ti=i("Para m\xE1s ejemplos de fine-tuning consulta:"),ln=c(),Se=r("ul"),Ps=r("li"),ct=r("p"),Ga=r("a"),zi=i("\u{1F917} Transformers Examples"),Ci=i(` incluye scripts
para entrenar tareas comunes de NLP en PyTorch y TensorFlow.`),Di=c(),Ts=r("li"),mt=r("p"),dt=r("a"),xi=i("\u{1F917} Transformers Notebooks"),Si=i(" contiene varios notebooks sobre c\xF3mo aplicar fine-tuning a un modelo para tareas espec\xEDficas en PyTorch y TensorFlow."),this.h()},l(e){const s=Lc('[data-svelte="svelte-1phssyn"]',document.head);$=n(s,"META",{name:!0,content:!0}),s.forEach(a),E=m(e),b=n(e,"H1",{class:!0});var Ka=l(b);w=n(Ka,"A",{id:!0,class:!0,href:!0});var zs=l(w);P=n(zs,"SPAN",{});var Cs=l(P);f(y.$$.fragment,Cs),Cs.forEach(a),zs.forEach(a),F=m(Ka),T=n(Ka,"SPAN",{});var Ii=l(T);k=p(Ii,"Fine-tuning a un modelo pre-entrenado"),Ii.forEach(a),Ka.forEach(a),q=m(e),f(C.$$.fragment,e),Le=m(e),Ua=n(e,"P",{});var Mi=l(Ua);Bn=p(Mi,"El uso de un modelo pre-entrenado tiene importantes ventajas. Reduce los costos de computaci\xF3n, la huella de carbono y te permite utilizar modelos de \xFAltima generaci\xF3n sin tener que entrenar uno desde cero."),Mi.forEach(a),Ds=m(e),O=n(e,"UL",{});var ut=l(O);Ie=n(ut,"LI",{});var pn=l(Ie);Gn=p(pn,"Fine-tuning a un modelo pre-entrenado con \u{1F917} Transformers "),$t=n(pn,"CODE",{});var Hi=l($t);Kn=p(Hi,"Trainer"),Hi.forEach(a),Un=p(pn,"."),pn.forEach(a),Wn=m(ut),bt=n(ut,"LI",{});var Ri=l(bt);Yn=p(Ri,"Fine-tuning a un modelo pre-entrenado en TensorFlow con Keras."),Ri.forEach(a),Vn=m(ut),jt=n(ut,"LI",{});var Bi=l(jt);Jn=p(Bi,"Fine-tuning a un modelo pre-entrenado en PyTorch nativo."),Bi.forEach(a),ut.forEach(a),xs=m(e),Wa=n(e,"A",{id:!0}),l(Wa).forEach(a),Ss=m(e),B=n(e,"H2",{class:!0});var cn=l(B);re=n(cn,"A",{id:!0,class:!0,href:!0});var Gi=l(re);wt=n(Gi,"SPAN",{});var Ki=l(wt);f(Me.$$.fragment,Ki),Ki.forEach(a),Gi.forEach(a),Xn=m(cn),yt=n(cn,"SPAN",{});var Ui=l(yt);Zn=p(Ui,"Prepara un dataset"),Ui.forEach(a),cn.forEach(a),Fs=m(e),f(He.$$.fragment,e),Ns=m(e),Ya=n(e,"P",{});var Wi=l(Ya);Qn=p(Wi,"Antes de aplicar fine-tuning a un modelo pre-entrenado, descarga un dataset y prep\xE1ralo para el entrenamiento. El tutorial anterior nos ense\xF1\xF3 c\xF3mo procesar los datos para el entrenamiento, y ahora es la oportunidad de poner a prueba estas habilidades."),Wi.forEach(a),Os=m(e),ne=n(e,"P",{});var mn=l(ne);el=p(mn,"Comienza cargando el dataset de "),Re=n(mn,"A",{href:!0,rel:!0});var Yi=l(Re);al=p(Yi,"Yelp Reviews"),Yi.forEach(a),tl=p(mn,":"),mn.forEach(a),Ls=m(e),f(Be.$$.fragment,e),Is=m(e),Va=n(e,"P",{});var Vi=l(Va);sl=p(Vi,"Como ya sabes, necesitas un tokenizador para procesar el texto e incluir una estrategia para el padding y el truncamiento para manejar cualquier longitud de secuencia variable. Para procesar tu dataset en un solo paso, utiliza el m\xE9todo de \u{1F917} Datasets\xA0mappara aplicar una funci\xF3n de preprocesamiento sobre todo el dataset:"),Vi.forEach(a),Ms=m(e),f(Ge.$$.fragment,e),Hs=m(e),Ja=n(e,"P",{});var Ji=l(Ja);rl=p(Ji,"Si lo deseas, puedes crear un subconjunto m\xE1s peque\xF1o del dataset completo para aplicarle fine-tuning y as\xED reducir el tiempo."),Ji.forEach(a),Rs=m(e),f(Ke.$$.fragment,e),Bs=m(e),Xa=n(e,"A",{id:!0}),l(Xa).forEach(a),Gs=m(e),G=n(e,"H2",{class:!0});var dn=l(G);le=n(dn,"A",{id:!0,class:!0,href:!0});var Xi=l(le);Et=n(Xi,"SPAN",{});var Zi=l(Et);f(Ue.$$.fragment,Zi),Zi.forEach(a),Xi.forEach(a),nl=m(dn),Za=n(dn,"SPAN",{});var Fi=l(Za);ll=p(Fi,"Fine-tuning con "),kt=n(Fi,"CODE",{});var Qi=l(kt);ol=p(Qi,"Trainer"),Qi.forEach(a),Fi.forEach(a),dn.forEach(a),Ks=m(e),f(We.$$.fragment,e),Us=m(e),L=n(e,"P",{});var ft=l(L);il=p(ft,"\u{1F917} Transformers proporciona una clase "),qt=n(ft,"CODE",{});var ep=l(qt);pl=p(ep,"Trainer"),ep.forEach(a),cl=p(ft," optimizada para el entrenamiento de modelos de \u{1F917} Transformers, haciendo m\xE1s f\xE1cil el inicio del entrenamiento sin necesidad de escribir manualmente tu propio ciclo. La API del "),At=n(ft,"CODE",{});var ap=l(At);ml=p(ap,"Trainer"),ap.forEach(a),dl=p(ft," soporta una amplia gama de opciones de entrenamiento y caracter\xEDsticas como el logging, el gradient accumulation y el mixed precision."),ft.forEach(a),Ws=m(e),oe=n(e,"P",{});var un=l(oe);ul=p(un,"Comienza cargando tu modelo y especifica el n\xFAmero de labels previstas. A partir del "),Ye=n(un,"A",{href:!0,rel:!0});var tp=l(Ye);fl=p(tp,"Card Dataset"),tp.forEach(a),hl=p(un," de Yelp Review, que como ya sabemos tiene 5 labels:"),un.forEach(a),Ys=m(e),f(Ve.$$.fragment,e),Vs=m(e),f(ie.$$.fragment,e),Js=m(e),K=n(e,"H3",{class:!0});var fn=l(K);pe=n(fn,"A",{id:!0,class:!0,href:!0});var sp=l(pe);Pt=n(sp,"SPAN",{});var rp=l(Pt);f(Je.$$.fragment,rp),rp.forEach(a),sp.forEach(a),gl=m(fn),Tt=n(fn,"SPAN",{});var np=l(Tt);_l=p(np,"Hiperpar\xE1metros de entrenamiento"),np.forEach(a),fn.forEach(a),Xs=m(e),I=n(e,"P",{});var ht=l(I);vl=p(ht,"A continuaci\xF3n, crea una clase "),zt=n(ht,"CODE",{});var lp=l(zt);$l=p(lp,"TrainingArguments"),lp.forEach(a),bl=p(ht," que contenga todos los hiperpar\xE1metros que puedes ajustar as\xED como los indicadores para activar las diferentes opciones de entrenamiento. Para este tutorial puedes empezar con los "),Xe=n(ht,"A",{href:!0,rel:!0});var op=l(Xe);jl=p(op,"hiperpar\xE1metros"),op.forEach(a),wl=p(ht," de entrenamiento por defecto, pero si\xE9ntete libre de experimentar con ellos para encontrar tu configuraci\xF3n \xF3ptima."),ht.forEach(a),Zs=m(e),Qa=n(e,"P",{});var ip=l(Qa);yl=p(ip,"Especifica d\xF3nde vas a guardar los checkpoints de tu entrenamiento:"),ip.forEach(a),Qs=m(e),f(Ze.$$.fragment,e),er=m(e),U=n(e,"H3",{class:!0});var hn=l(U);ce=n(hn,"A",{id:!0,class:!0,href:!0});var pp=l(ce);Ct=n(pp,"SPAN",{});var cp=l(Ct);f(Qe.$$.fragment,cp),cp.forEach(a),pp.forEach(a),El=m(hn),Dt=n(hn,"SPAN",{});var mp=l(Dt);kl=p(mp,"M\xE9tricas"),mp.forEach(a),hn.forEach(a),ar=m(e),A=n(e,"P",{});var S=l(A);ql=p(S,"El "),xt=n(S,"CODE",{});var dp=l(xt);Al=p(dp,"Trainer"),dp.forEach(a),Pl=p(S," no eval\xFAa autom\xE1ticamente el rendimiento del modelo durante el entrenamiento. Tendr\xE1s que pasarle a "),St=n(S,"CODE",{});var up=l(St);Tl=p(up,"Trainer"),up.forEach(a),zl=p(S," una funci\xF3n para calcular y hacer un reporte de las m\xE9tricas. La biblioteca de \u{1F917} Datasets proporciona una funci\xF3n de "),ea=n(S,"A",{href:!0,rel:!0});var fp=l(ea);Ft=n(fp,"CODE",{});var hp=l(Ft);Cl=p(hp,"accuracy"),hp.forEach(a),fp.forEach(a),Dl=p(S," simple que puedes cargar con la funci\xF3n "),Nt=n(S,"CODE",{});var gp=l(Nt);xl=p(gp,"load_metric"),gp.forEach(a),Sl=p(S," (ver este "),aa=n(S,"A",{href:!0,rel:!0});var _p=l(aa);Fl=p(_p,"tutorial"),_p.forEach(a),Nl=p(S," para m\xE1s informaci\xF3n):"),S.forEach(a),tr=m(e),f(ta.$$.fragment,e),sr=m(e),D=n(e,"P",{});var Fe=l(D);Ol=p(Fe,"Define la funci\xF3n "),Ot=n(Fe,"CODE",{});var vp=l(Ot);Ll=p(vp,"compute"),vp.forEach(a),Il=p(Fe," en "),Lt=n(Fe,"CODE",{});var $p=l(Lt);Ml=p($p,"metric"),$p.forEach(a),Hl=p(Fe," para calcular el accuracy de tus predicciones. Antes de pasar tus predicciones a "),It=n(Fe,"CODE",{});var bp=l(It);Rl=p(bp,"compute"),bp.forEach(a),Bl=p(Fe,", necesitas convertir las predicciones a logits (recuerda que todos los modelos de \u{1F917} Transformers devuelven logits)."),Fe.forEach(a),rr=m(e),f(sa.$$.fragment,e),nr=m(e),me=n(e,"P",{});var gn=l(me);Gl=p(gn,"Si quieres controlar tus m\xE9tricas de evaluaci\xF3n durante el fine-tuning, especifica el par\xE1metro "),Mt=n(gn,"CODE",{});var jp=l(Mt);Kl=p(jp,"evaluation_strategy"),jp.forEach(a),Ul=p(gn," en tus argumentos de entrenamiento para que el modelo tenga en cuenta la m\xE9trica de evaluaci\xF3n al final de cada \xE9poca:"),gn.forEach(a),lr=m(e),f(ra.$$.fragment,e),or=m(e),W=n(e,"H3",{class:!0});var _n=l(W);de=n(_n,"A",{id:!0,class:!0,href:!0});var wp=l(de);Ht=n(wp,"SPAN",{});var yp=l(Ht);f(na.$$.fragment,yp),yp.forEach(a),wp.forEach(a),Wl=m(_n),Rt=n(_n,"SPAN",{});var Ep=l(Rt);Yl=p(Ep,"Trainer"),Ep.forEach(a),_n.forEach(a),ir=m(e),ue=n(e,"P",{});var vn=l(ue);Vl=p(vn,"Crea un objeto "),Bt=n(vn,"CODE",{});var kp=l(Bt);Jl=p(kp,"Trainer"),kp.forEach(a),Xl=p(vn," con tu modelo, argumentos de entrenamiento, datasets de entrenamiento y de prueba, y tu funci\xF3n de evaluaci\xF3n:"),vn.forEach(a),pr=m(e),f(la.$$.fragment,e),cr=m(e),fe=n(e,"P",{});var $n=l(fe);Zl=p($n,"A continuaci\xF3n, aplica fine-tuning a tu modelo llamando "),Gt=n($n,"CODE",{});var qp=l(Gt);Ql=p(qp,"train()"),qp.forEach(a),eo=p($n,":"),$n.forEach(a),mr=m(e),f(oa.$$.fragment,e),dr=m(e),et=n(e,"A",{id:!0}),l(et).forEach(a),ur=m(e),Y=n(e,"H2",{class:!0});var bn=l(Y);he=n(bn,"A",{id:!0,class:!0,href:!0});var Ap=l(he);Kt=n(Ap,"SPAN",{});var Pp=l(Kt);f(ia.$$.fragment,Pp),Pp.forEach(a),Ap.forEach(a),ao=m(bn),Ut=n(bn,"SPAN",{});var Tp=l(Ut);to=p(Tp,"Fine-tuning con Keras"),Tp.forEach(a),bn.forEach(a),fr=m(e),f(pa.$$.fragment,e),hr=m(e),at=n(e,"P",{});var zp=l(at);so=p(zp,"Los modelos de \u{1F917} Transformers tambi\xE9n permiten realizar el entrenamiento en TensorFlow con la API de Keras. Solo es necesario hacer algunos cambios antes de hacer fine-tuning."),zp.forEach(a),gr=m(e),V=n(e,"H3",{class:!0});var jn=l(V);ge=n(jn,"A",{id:!0,class:!0,href:!0});var Cp=l(ge);Wt=n(Cp,"SPAN",{});var Dp=l(Wt);f(ca.$$.fragment,Dp),Dp.forEach(a),Cp.forEach(a),ro=m(jn),Yt=n(jn,"SPAN",{});var xp=l(Yt);no=p(xp,"Convierte el dataset al formato de TensorFlow"),xp.forEach(a),jn.forEach(a),_r=m(e),M=n(e,"P",{});var gt=l(M);lo=p(gt,"El "),Vt=n(gt,"CODE",{});var Sp=l(Vt);oo=p(Sp,"DefaultDataCollator"),Sp.forEach(a),io=p(gt," junta los tensores en un batch para que el modelo se entrene en \xE9l. Aseg\xFArate de especificar "),Jt=n(gt,"CODE",{});var Fp=l(Jt);po=p(Fp,"return_tensors"),Fp.forEach(a),co=p(gt," para devolver los tensores de TensorFlow:"),gt.forEach(a),vr=m(e),f(ma.$$.fragment,e),$r=m(e),f(_e.$$.fragment,e),br=m(e),x=n(e,"P",{});var Ne=l(x);mo=p(Ne,"A continuaci\xF3n, convierte los datasets tokenizados en datasets de TensorFlow con el m\xE9todo "),da=n(Ne,"A",{href:!0,rel:!0});var Np=l(da);Xt=n(Np,"CODE",{});var Op=l(Xt);uo=p(Op,"to_tf_dataset"),Op.forEach(a),Np.forEach(a),fo=p(Ne,". Especifica tus entradas en "),Zt=n(Ne,"CODE",{});var Lp=l(Zt);ho=p(Lp,"columns"),Lp.forEach(a),go=p(Ne," y tu etiqueta en "),Qt=n(Ne,"CODE",{});var Ip=l(Qt);_o=p(Ip,"label_cols"),Ip.forEach(a),vo=p(Ne,":"),Ne.forEach(a),jr=m(e),f(ua.$$.fragment,e),wr=m(e),J=n(e,"H3",{class:!0});var wn=l(J);ve=n(wn,"A",{id:!0,class:!0,href:!0});var Mp=l(ve);es=n(Mp,"SPAN",{});var Hp=l(es);f(fa.$$.fragment,Hp),Hp.forEach(a),Mp.forEach(a),$o=m(wn),as=n(wn,"SPAN",{});var Rp=l(as);bo=p(Rp,"Compila y ajusta"),Rp.forEach(a),wn.forEach(a),yr=m(e),tt=n(e,"P",{});var Bp=l(tt);jo=p(Bp,"Carguemos un modelo TensorFlow con el n\xFAmero esperado de labels:"),Bp.forEach(a),Er=m(e),f(ha.$$.fragment,e),kr=m(e),$e=n(e,"P",{});var yn=l($e);wo=p(yn,"A continuaci\xF3n, compila y aplica fine-tuning a tu modelo con "),ga=n(yn,"A",{href:!0,rel:!0});var Gp=l(ga);ts=n(Gp,"CODE",{});var Kp=l(ts);yo=p(Kp,"fit"),Kp.forEach(a),Gp.forEach(a),Eo=p(yn," como lo har\xEDas con cualquier otro modelo de Keras:"),yn.forEach(a),qr=m(e),f(_a.$$.fragment,e),Ar=m(e),st=n(e,"A",{id:!0}),l(st).forEach(a),Pr=m(e),X=n(e,"H2",{class:!0});var En=l(X);be=n(En,"A",{id:!0,class:!0,href:!0});var Up=l(be);ss=n(Up,"SPAN",{});var Wp=l(ss);f(va.$$.fragment,Wp),Wp.forEach(a),Up.forEach(a),ko=m(En),rs=n(En,"SPAN",{});var Yp=l(rs);qo=p(Yp,"Fine-tune en PyTorch nativo"),Yp.forEach(a),En.forEach(a),Tr=m(e),f($a.$$.fragment,e),zr=m(e),je=n(e,"P",{});var kn=l(je);Ao=p(kn,"El "),ns=n(kn,"CODE",{});var Vp=l(ns);Po=p(Vp,"Trainer"),Vp.forEach(a),To=p(kn," se encarga del ciclo de entrenamiento y permite aplicar fine-tuning a un modelo en una sola l\xEDnea de c\xF3digo. Para los que prefieran escribir su propio ciclo de entrenamiento, tambi\xE9n pueden aplicar fine-tuning a un modelo de \u{1F917} Transformers en PyTorch nativo."),kn.forEach(a),Cr=m(e),rt=n(e,"P",{});var Jp=l(rt);zo=p(Jp,"En este punto, es posible que necesites reiniciar tu notebook o ejecutar el siguiente c\xF3digo para liberar algo de memoria:"),Jp.forEach(a),Dr=m(e),f(ba.$$.fragment,e),xr=m(e),we=n(e,"P",{});var qn=l(we);Co=p(qn,"A continuaci\xF3n, haremos un post-procesamiento manual al "),ls=n(qn,"CODE",{});var Xp=l(ls);Do=p(Xp,"tokenized_dataset"),Xp.forEach(a),xo=p(qn," y as\xED prepararlo para el entrenamiento."),qn.forEach(a),Sr=m(e),H=n(e,"OL",{});var _t=l(H);ja=n(_t,"LI",{});var An=l(ja);wa=n(An,"P",{});var Pn=l(wa);So=p(Pn,"Elimina la columna de "),os=n(Pn,"CODE",{});var Zp=l(os);Fo=p(Zp,"text"),Zp.forEach(a),No=p(Pn," porque el modelo no acepta texto en crudo como entrada:"),Pn.forEach(a),Oo=m(An),f(ya.$$.fragment,An),An.forEach(a),Lo=m(_t),Ea=n(_t,"LI",{});var Tn=l(Ea);N=n(Tn,"P",{});var Oe=l(N);Io=p(Oe,"Cambia el nombre de la columna de "),is=n(Oe,"CODE",{});var Qp=l(is);Mo=p(Qp,"label"),Qp.forEach(a),Ho=p(Oe," a "),ps=n(Oe,"CODE",{});var ec=l(ps);Ro=p(ec,"labels"),ec.forEach(a),Bo=p(Oe," porque el modelo espera que el argumento se llame "),cs=n(Oe,"CODE",{});var ac=l(cs);Go=p(ac,"labels"),ac.forEach(a),Ko=p(Oe,":"),Oe.forEach(a),Uo=m(Tn),f(ka.$$.fragment,Tn),Tn.forEach(a),Wo=m(_t),qa=n(_t,"LI",{});var zn=l(qa);ms=n(zn,"P",{});var tc=l(ms);Yo=p(tc,"Establece el formato del dataset para devolver tensores PyTorch en lugar de listas:"),tc.forEach(a),Vo=m(zn),f(Aa.$$.fragment,zn),zn.forEach(a),_t.forEach(a),Fr=m(e),nt=n(e,"P",{});var sc=l(nt);Jo=p(sc,"A continuaci\xF3n, crea un subconjunto m\xE1s peque\xF1o del dataset como se ha mostrado anteriormente para acelerar el fine-tuning:"),sc.forEach(a),Nr=m(e),f(Pa.$$.fragment,e),Or=m(e),Z=n(e,"H3",{class:!0});var Cn=l(Z);ye=n(Cn,"A",{id:!0,class:!0,href:!0});var rc=l(ye);ds=n(rc,"SPAN",{});var nc=l(ds);f(Ta.$$.fragment,nc),nc.forEach(a),rc.forEach(a),Xo=m(Cn),us=n(Cn,"SPAN",{});var lc=l(us);Zo=p(lc,"DataLoader"),lc.forEach(a),Cn.forEach(a),Lr=m(e),Ee=n(e,"P",{});var Dn=l(Ee);Qo=p(Dn,"Crea un "),fs=n(Dn,"CODE",{});var oc=l(fs);ei=p(oc,"DataLoader"),oc.forEach(a),ai=p(Dn," para tus datasets de entrenamiento y de prueba para poder iterar sobre batches de datos:"),Dn.forEach(a),Ir=m(e),f(za.$$.fragment,e),Mr=m(e),lt=n(e,"P",{});var ic=l(lt);ti=p(ic,"Carga tu modelo con el n\xFAmero de labels previstas:"),ic.forEach(a),Hr=m(e),f(Ca.$$.fragment,e),Rr=m(e),Q=n(e,"H3",{class:!0});var xn=l(Q);ke=n(xn,"A",{id:!0,class:!0,href:!0});var pc=l(ke);hs=n(pc,"SPAN",{});var cc=l(hs);f(Da.$$.fragment,cc),cc.forEach(a),pc.forEach(a),si=m(xn),gs=n(xn,"SPAN",{});var mc=l(gs);ri=p(mc,"Optimiza y programa el learning rate"),mc.forEach(a),xn.forEach(a),Br=m(e),qe=n(e,"P",{});var Sn=l(qe);ni=p(Sn,"Crea un optimizador y el learning rate para aplicar fine-tuning al modelo. Vamos a utilizar el optimizador "),xa=n(Sn,"A",{href:!0,rel:!0});var dc=l(xa);_s=n(dc,"CODE",{});var uc=l(_s);li=p(uc,"AdamW"),uc.forEach(a),dc.forEach(a),oi=p(Sn," de PyTorch:"),Sn.forEach(a),Gr=m(e),f(Sa.$$.fragment,e),Kr=m(e),Ae=n(e,"P",{});var Fn=l(Ae);ii=p(Fn,"Crea el learning rate desde el "),vs=n(Fn,"CODE",{});var fc=l(vs);pi=p(fc,"Trainer"),fc.forEach(a),ci=p(Fn,":"),Fn.forEach(a),Ur=m(e),f(Fa.$$.fragment,e),Wr=m(e),Pe=n(e,"P",{});var Nn=l(Pe);mi=p(Nn,"Por \xFAltimo, especifica el "),$s=n(Nn,"CODE",{});var hc=l($s);di=p(hc,"device"),hc.forEach(a),ui=p(Nn," o entorno de ejecuci\xF3n para utilizar una GPU si tienes acceso a una. De lo contrario, el entrenamiento en una CPU puede llevarte varias horas en lugar de un par de minutos."),Nn.forEach(a),Yr=m(e),f(Na.$$.fragment,e),Vr=m(e),f(Te.$$.fragment,e),Jr=m(e),ot=n(e,"P",{});var gc=l(ot);fi=p(gc,"Genial, \xA1ahora podemos entrenar! \u{1F973}"),gc.forEach(a),Xr=m(e),ee=n(e,"H3",{class:!0});var On=l(ee);ze=n(On,"A",{id:!0,class:!0,href:!0});var _c=l(ze);bs=n(_c,"SPAN",{});var vc=l(bs);f(Oa.$$.fragment,vc),vc.forEach(a),_c.forEach(a),hi=m(On),js=n(On,"SPAN",{});var $c=l(js);gi=p($c,"Ciclo de entrenamiento"),$c.forEach(a),On.forEach(a),Zr=m(e),Ce=n(e,"P",{});var Ln=l(Ce);_i=p(Ln,"Para hacer un seguimiento al progreso del entrenamiento, utiliza la biblioteca "),La=n(Ln,"A",{href:!0,rel:!0});var bc=l(La);vi=p(bc,"tqdm"),bc.forEach(a),$i=p(Ln," para a\xF1adir una barra de progreso sobre el n\xFAmero de pasos de entrenamiento:"),Ln.forEach(a),Qr=m(e),f(Ia.$$.fragment,e),en=m(e),ae=n(e,"H3",{class:!0});var In=l(ae);De=n(In,"A",{id:!0,class:!0,href:!0});var jc=l(De);ws=n(jc,"SPAN",{});var wc=l(ws);f(Ma.$$.fragment,wc),wc.forEach(a),jc.forEach(a),bi=m(In),ys=n(In,"SPAN",{});var yc=l(ys);ji=p(yc,"M\xE9tricas"),yc.forEach(a),In.forEach(a),an=m(e),R=n(e,"P",{});var vt=l(R);wi=p(vt,"De la misma manera que necesitas a\xF1adir una funci\xF3n de evaluaci\xF3n al "),Es=n(vt,"CODE",{});var Ec=l(Es);yi=p(Ec,"Trainer"),Ec.forEach(a),Ei=p(vt,", necesitas hacer lo mismo cuando escribas tu propio ciclo de entrenamiento. Pero en lugar de calcular y reportar la m\xE9trica al final de cada \xE9poca, esta vez acumular\xE1s todos los batches con "),Ha=n(vt,"A",{href:!0,rel:!0});var kc=l(Ha);ks=n(kc,"CODE",{});var qc=l(ks);ki=p(qc,"add_batch"),qc.forEach(a),kc.forEach(a),qi=p(vt," y calcular\xE1s la m\xE9trica al final."),vt.forEach(a),tn=m(e),f(Ra.$$.fragment,e),sn=m(e),it=n(e,"A",{id:!0}),l(it).forEach(a),rn=m(e),te=n(e,"H2",{class:!0});var Mn=l(te);xe=n(Mn,"A",{id:!0,class:!0,href:!0});var Ac=l(xe);qs=n(Ac,"SPAN",{});var Pc=l(qs);f(Ba.$$.fragment,Pc),Pc.forEach(a),Ac.forEach(a),Ai=m(Mn),As=n(Mn,"SPAN",{});var Tc=l(As);Pi=p(Tc,"Recursos adicionales"),Tc.forEach(a),Mn.forEach(a),nn=m(e),pt=n(e,"P",{});var zc=l(pt);Ti=p(zc,"Para m\xE1s ejemplos de fine-tuning consulta:"),zc.forEach(a),ln=m(e),Se=n(e,"UL",{});var Hn=l(Se);Ps=n(Hn,"LI",{});var Cc=l(Ps);ct=n(Cc,"P",{});var Ni=l(ct);Ga=n(Ni,"A",{href:!0,rel:!0});var Dc=l(Ga);zi=p(Dc,"\u{1F917} Transformers Examples"),Dc.forEach(a),Ci=p(Ni,` incluye scripts
para entrenar tareas comunes de NLP en PyTorch y TensorFlow.`),Ni.forEach(a),Cc.forEach(a),Di=m(Hn),Ts=n(Hn,"LI",{});var xc=l(Ts);mt=n(xc,"P",{});var Oi=l(mt);dt=n(Oi,"A",{href:!0});var Sc=l(dt);xi=p(Sc,"\u{1F917} Transformers Notebooks"),Sc.forEach(a),Si=p(Oi," contiene varios notebooks sobre c\xF3mo aplicar fine-tuning a un modelo para tareas espec\xEDficas en PyTorch y TensorFlow."),Oi.forEach(a),xc.forEach(a),Hn.forEach(a),this.h()},h(){d($,"name","hf:doc:metadata"),d($,"content",JSON.stringify(Kc)),d(w,"id","finetuning-a-un-modelo-preentrenado"),d(w,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(w,"href","#finetuning-a-un-modelo-preentrenado"),d(b,"class","relative group"),d(Wa,"id","data-processing"),d(re,"id","prepara-un-dataset"),d(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(re,"href","#prepara-un-dataset"),d(B,"class","relative group"),d(Re,"href","https://huggingface.co/datasets/yelp_review_full"),d(Re,"rel","nofollow"),d(Xa,"id","trainer"),d(le,"id","finetuning-con-trainer"),d(le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(le,"href","#finetuning-con-trainer"),d(G,"class","relative group"),d(Ye,"href","https://huggingface.co/datasets/yelp_review_full#data-fields"),d(Ye,"rel","nofollow"),d(pe,"id","hiperparmetros-de-entrenamiento"),d(pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(pe,"href","#hiperparmetros-de-entrenamiento"),d(K,"class","relative group"),d(Xe,"href","https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments"),d(Xe,"rel","nofollow"),d(ce,"id","mtricas"),d(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ce,"href","#mtricas"),d(U,"class","relative group"),d(ea,"href","https://huggingface.co/metrics/accuracy"),d(ea,"rel","nofollow"),d(aa,"href","https://huggingface.co/docs/datasets/metrics.html"),d(aa,"rel","nofollow"),d(de,"id","trainer"),d(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(de,"href","#trainer"),d(W,"class","relative group"),d(et,"id","keras"),d(he,"id","finetuning-con-keras"),d(he,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(he,"href","#finetuning-con-keras"),d(Y,"class","relative group"),d(ge,"id","convierte-el-dataset-al-formato-de-tensorflow"),d(ge,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ge,"href","#convierte-el-dataset-al-formato-de-tensorflow"),d(V,"class","relative group"),d(da,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.to_tf_dataset"),d(da,"rel","nofollow"),d(ve,"id","compila-y-ajusta"),d(ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ve,"href","#compila-y-ajusta"),d(J,"class","relative group"),d(ga,"href","https://keras.io/api/models/model_training_apis/"),d(ga,"rel","nofollow"),d(st,"id","pytorch_native"),d(be,"id","finetune-en-pytorch-nativo"),d(be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(be,"href","#finetune-en-pytorch-nativo"),d(X,"class","relative group"),d(ye,"id","dataloader"),d(ye,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ye,"href","#dataloader"),d(Z,"class","relative group"),d(ke,"id","optimiza-y-programa-el-learning-rate"),d(ke,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ke,"href","#optimiza-y-programa-el-learning-rate"),d(Q,"class","relative group"),d(xa,"href","https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"),d(xa,"rel","nofollow"),d(ze,"id","ciclo-de-entrenamiento"),d(ze,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ze,"href","#ciclo-de-entrenamiento"),d(ee,"class","relative group"),d(La,"href","https://tqdm.github.io/"),d(La,"rel","nofollow"),d(De,"id","mtricas"),d(De,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(De,"href","#mtricas"),d(ae,"class","relative group"),d(Ha,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=add_batch#datasets.Metric.add_batch"),d(Ha,"rel","nofollow"),d(it,"id","additional-resources"),d(xe,"id","recursos-adicionales"),d(xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(xe,"href","#recursos-adicionales"),d(te,"class","relative group"),d(Ga,"href","https://github.com/huggingface/transformers/tree/main/examples"),d(Ga,"rel","nofollow"),d(dt,"href","notebooks")},m(e,s){t(document.head,$),o(e,E,s),o(e,b,s),t(b,w),t(w,P),h(y,P,null),t(b,F),t(b,T),t(T,k),o(e,q,s),h(C,e,s),o(e,Le,s),o(e,Ua,s),t(Ua,Bn),o(e,Ds,s),o(e,O,s),t(O,Ie),t(Ie,Gn),t(Ie,$t),t($t,Kn),t(Ie,Un),t(O,Wn),t(O,bt),t(bt,Yn),t(O,Vn),t(O,jt),t(jt,Jn),o(e,xs,s),o(e,Wa,s),o(e,Ss,s),o(e,B,s),t(B,re),t(re,wt),h(Me,wt,null),t(B,Xn),t(B,yt),t(yt,Zn),o(e,Fs,s),h(He,e,s),o(e,Ns,s),o(e,Ya,s),t(Ya,Qn),o(e,Os,s),o(e,ne,s),t(ne,el),t(ne,Re),t(Re,al),t(ne,tl),o(e,Ls,s),h(Be,e,s),o(e,Is,s),o(e,Va,s),t(Va,sl),o(e,Ms,s),h(Ge,e,s),o(e,Hs,s),o(e,Ja,s),t(Ja,rl),o(e,Rs,s),h(Ke,e,s),o(e,Bs,s),o(e,Xa,s),o(e,Gs,s),o(e,G,s),t(G,le),t(le,Et),h(Ue,Et,null),t(G,nl),t(G,Za),t(Za,ll),t(Za,kt),t(kt,ol),o(e,Ks,s),h(We,e,s),o(e,Us,s),o(e,L,s),t(L,il),t(L,qt),t(qt,pl),t(L,cl),t(L,At),t(At,ml),t(L,dl),o(e,Ws,s),o(e,oe,s),t(oe,ul),t(oe,Ye),t(Ye,fl),t(oe,hl),o(e,Ys,s),h(Ve,e,s),o(e,Vs,s),h(ie,e,s),o(e,Js,s),o(e,K,s),t(K,pe),t(pe,Pt),h(Je,Pt,null),t(K,gl),t(K,Tt),t(Tt,_l),o(e,Xs,s),o(e,I,s),t(I,vl),t(I,zt),t(zt,$l),t(I,bl),t(I,Xe),t(Xe,jl),t(I,wl),o(e,Zs,s),o(e,Qa,s),t(Qa,yl),o(e,Qs,s),h(Ze,e,s),o(e,er,s),o(e,U,s),t(U,ce),t(ce,Ct),h(Qe,Ct,null),t(U,El),t(U,Dt),t(Dt,kl),o(e,ar,s),o(e,A,s),t(A,ql),t(A,xt),t(xt,Al),t(A,Pl),t(A,St),t(St,Tl),t(A,zl),t(A,ea),t(ea,Ft),t(Ft,Cl),t(A,Dl),t(A,Nt),t(Nt,xl),t(A,Sl),t(A,aa),t(aa,Fl),t(A,Nl),o(e,tr,s),h(ta,e,s),o(e,sr,s),o(e,D,s),t(D,Ol),t(D,Ot),t(Ot,Ll),t(D,Il),t(D,Lt),t(Lt,Ml),t(D,Hl),t(D,It),t(It,Rl),t(D,Bl),o(e,rr,s),h(sa,e,s),o(e,nr,s),o(e,me,s),t(me,Gl),t(me,Mt),t(Mt,Kl),t(me,Ul),o(e,lr,s),h(ra,e,s),o(e,or,s),o(e,W,s),t(W,de),t(de,Ht),h(na,Ht,null),t(W,Wl),t(W,Rt),t(Rt,Yl),o(e,ir,s),o(e,ue,s),t(ue,Vl),t(ue,Bt),t(Bt,Jl),t(ue,Xl),o(e,pr,s),h(la,e,s),o(e,cr,s),o(e,fe,s),t(fe,Zl),t(fe,Gt),t(Gt,Ql),t(fe,eo),o(e,mr,s),h(oa,e,s),o(e,dr,s),o(e,et,s),o(e,ur,s),o(e,Y,s),t(Y,he),t(he,Kt),h(ia,Kt,null),t(Y,ao),t(Y,Ut),t(Ut,to),o(e,fr,s),h(pa,e,s),o(e,hr,s),o(e,at,s),t(at,so),o(e,gr,s),o(e,V,s),t(V,ge),t(ge,Wt),h(ca,Wt,null),t(V,ro),t(V,Yt),t(Yt,no),o(e,_r,s),o(e,M,s),t(M,lo),t(M,Vt),t(Vt,oo),t(M,io),t(M,Jt),t(Jt,po),t(M,co),o(e,vr,s),h(ma,e,s),o(e,$r,s),h(_e,e,s),o(e,br,s),o(e,x,s),t(x,mo),t(x,da),t(da,Xt),t(Xt,uo),t(x,fo),t(x,Zt),t(Zt,ho),t(x,go),t(x,Qt),t(Qt,_o),t(x,vo),o(e,jr,s),h(ua,e,s),o(e,wr,s),o(e,J,s),t(J,ve),t(ve,es),h(fa,es,null),t(J,$o),t(J,as),t(as,bo),o(e,yr,s),o(e,tt,s),t(tt,jo),o(e,Er,s),h(ha,e,s),o(e,kr,s),o(e,$e,s),t($e,wo),t($e,ga),t(ga,ts),t(ts,yo),t($e,Eo),o(e,qr,s),h(_a,e,s),o(e,Ar,s),o(e,st,s),o(e,Pr,s),o(e,X,s),t(X,be),t(be,ss),h(va,ss,null),t(X,ko),t(X,rs),t(rs,qo),o(e,Tr,s),h($a,e,s),o(e,zr,s),o(e,je,s),t(je,Ao),t(je,ns),t(ns,Po),t(je,To),o(e,Cr,s),o(e,rt,s),t(rt,zo),o(e,Dr,s),h(ba,e,s),o(e,xr,s),o(e,we,s),t(we,Co),t(we,ls),t(ls,Do),t(we,xo),o(e,Sr,s),o(e,H,s),t(H,ja),t(ja,wa),t(wa,So),t(wa,os),t(os,Fo),t(wa,No),t(ja,Oo),h(ya,ja,null),t(H,Lo),t(H,Ea),t(Ea,N),t(N,Io),t(N,is),t(is,Mo),t(N,Ho),t(N,ps),t(ps,Ro),t(N,Bo),t(N,cs),t(cs,Go),t(N,Ko),t(Ea,Uo),h(ka,Ea,null),t(H,Wo),t(H,qa),t(qa,ms),t(ms,Yo),t(qa,Vo),h(Aa,qa,null),o(e,Fr,s),o(e,nt,s),t(nt,Jo),o(e,Nr,s),h(Pa,e,s),o(e,Or,s),o(e,Z,s),t(Z,ye),t(ye,ds),h(Ta,ds,null),t(Z,Xo),t(Z,us),t(us,Zo),o(e,Lr,s),o(e,Ee,s),t(Ee,Qo),t(Ee,fs),t(fs,ei),t(Ee,ai),o(e,Ir,s),h(za,e,s),o(e,Mr,s),o(e,lt,s),t(lt,ti),o(e,Hr,s),h(Ca,e,s),o(e,Rr,s),o(e,Q,s),t(Q,ke),t(ke,hs),h(Da,hs,null),t(Q,si),t(Q,gs),t(gs,ri),o(e,Br,s),o(e,qe,s),t(qe,ni),t(qe,xa),t(xa,_s),t(_s,li),t(qe,oi),o(e,Gr,s),h(Sa,e,s),o(e,Kr,s),o(e,Ae,s),t(Ae,ii),t(Ae,vs),t(vs,pi),t(Ae,ci),o(e,Ur,s),h(Fa,e,s),o(e,Wr,s),o(e,Pe,s),t(Pe,mi),t(Pe,$s),t($s,di),t(Pe,ui),o(e,Yr,s),h(Na,e,s),o(e,Vr,s),h(Te,e,s),o(e,Jr,s),o(e,ot,s),t(ot,fi),o(e,Xr,s),o(e,ee,s),t(ee,ze),t(ze,bs),h(Oa,bs,null),t(ee,hi),t(ee,js),t(js,gi),o(e,Zr,s),o(e,Ce,s),t(Ce,_i),t(Ce,La),t(La,vi),t(Ce,$i),o(e,Qr,s),h(Ia,e,s),o(e,en,s),o(e,ae,s),t(ae,De),t(De,ws),h(Ma,ws,null),t(ae,bi),t(ae,ys),t(ys,ji),o(e,an,s),o(e,R,s),t(R,wi),t(R,Es),t(Es,yi),t(R,Ei),t(R,Ha),t(Ha,ks),t(ks,ki),t(R,qi),o(e,tn,s),h(Ra,e,s),o(e,sn,s),o(e,it,s),o(e,rn,s),o(e,te,s),t(te,xe),t(xe,qs),h(Ba,qs,null),t(te,Ai),t(te,As),t(As,Pi),o(e,nn,s),o(e,pt,s),t(pt,Ti),o(e,ln,s),o(e,Se,s),t(Se,Ps),t(Ps,ct),t(ct,Ga),t(Ga,zi),t(ct,Ci),t(Se,Di),t(Se,Ts),t(Ts,mt),t(mt,dt),t(dt,xi),t(mt,Si),on=!0},p(e,[s]){const Ka={};s&2&&(Ka.$$scope={dirty:s,ctx:e}),ie.$set(Ka);const zs={};s&2&&(zs.$$scope={dirty:s,ctx:e}),_e.$set(zs);const Cs={};s&2&&(Cs.$$scope={dirty:s,ctx:e}),Te.$set(Cs)},i(e){on||(g(y.$$.fragment,e),g(C.$$.fragment,e),g(Me.$$.fragment,e),g(He.$$.fragment,e),g(Be.$$.fragment,e),g(Ge.$$.fragment,e),g(Ke.$$.fragment,e),g(Ue.$$.fragment,e),g(We.$$.fragment,e),g(Ve.$$.fragment,e),g(ie.$$.fragment,e),g(Je.$$.fragment,e),g(Ze.$$.fragment,e),g(Qe.$$.fragment,e),g(ta.$$.fragment,e),g(sa.$$.fragment,e),g(ra.$$.fragment,e),g(na.$$.fragment,e),g(la.$$.fragment,e),g(oa.$$.fragment,e),g(ia.$$.fragment,e),g(pa.$$.fragment,e),g(ca.$$.fragment,e),g(ma.$$.fragment,e),g(_e.$$.fragment,e),g(ua.$$.fragment,e),g(fa.$$.fragment,e),g(ha.$$.fragment,e),g(_a.$$.fragment,e),g(va.$$.fragment,e),g($a.$$.fragment,e),g(ba.$$.fragment,e),g(ya.$$.fragment,e),g(ka.$$.fragment,e),g(Aa.$$.fragment,e),g(Pa.$$.fragment,e),g(Ta.$$.fragment,e),g(za.$$.fragment,e),g(Ca.$$.fragment,e),g(Da.$$.fragment,e),g(Sa.$$.fragment,e),g(Fa.$$.fragment,e),g(Na.$$.fragment,e),g(Te.$$.fragment,e),g(Oa.$$.fragment,e),g(Ia.$$.fragment,e),g(Ma.$$.fragment,e),g(Ra.$$.fragment,e),g(Ba.$$.fragment,e),on=!0)},o(e){_(y.$$.fragment,e),_(C.$$.fragment,e),_(Me.$$.fragment,e),_(He.$$.fragment,e),_(Be.$$.fragment,e),_(Ge.$$.fragment,e),_(Ke.$$.fragment,e),_(Ue.$$.fragment,e),_(We.$$.fragment,e),_(Ve.$$.fragment,e),_(ie.$$.fragment,e),_(Je.$$.fragment,e),_(Ze.$$.fragment,e),_(Qe.$$.fragment,e),_(ta.$$.fragment,e),_(sa.$$.fragment,e),_(ra.$$.fragment,e),_(na.$$.fragment,e),_(la.$$.fragment,e),_(oa.$$.fragment,e),_(ia.$$.fragment,e),_(pa.$$.fragment,e),_(ca.$$.fragment,e),_(ma.$$.fragment,e),_(_e.$$.fragment,e),_(ua.$$.fragment,e),_(fa.$$.fragment,e),_(ha.$$.fragment,e),_(_a.$$.fragment,e),_(va.$$.fragment,e),_($a.$$.fragment,e),_(ba.$$.fragment,e),_(ya.$$.fragment,e),_(ka.$$.fragment,e),_(Aa.$$.fragment,e),_(Pa.$$.fragment,e),_(Ta.$$.fragment,e),_(za.$$.fragment,e),_(Ca.$$.fragment,e),_(Da.$$.fragment,e),_(Sa.$$.fragment,e),_(Fa.$$.fragment,e),_(Na.$$.fragment,e),_(Te.$$.fragment,e),_(Oa.$$.fragment,e),_(Ia.$$.fragment,e),_(Ma.$$.fragment,e),_(Ra.$$.fragment,e),_(Ba.$$.fragment,e),on=!1},d(e){a($),e&&a(E),e&&a(b),v(y),e&&a(q),v(C,e),e&&a(Le),e&&a(Ua),e&&a(Ds),e&&a(O),e&&a(xs),e&&a(Wa),e&&a(Ss),e&&a(B),v(Me),e&&a(Fs),v(He,e),e&&a(Ns),e&&a(Ya),e&&a(Os),e&&a(ne),e&&a(Ls),v(Be,e),e&&a(Is),e&&a(Va),e&&a(Ms),v(Ge,e),e&&a(Hs),e&&a(Ja),e&&a(Rs),v(Ke,e),e&&a(Bs),e&&a(Xa),e&&a(Gs),e&&a(G),v(Ue),e&&a(Ks),v(We,e),e&&a(Us),e&&a(L),e&&a(Ws),e&&a(oe),e&&a(Ys),v(Ve,e),e&&a(Vs),v(ie,e),e&&a(Js),e&&a(K),v(Je),e&&a(Xs),e&&a(I),e&&a(Zs),e&&a(Qa),e&&a(Qs),v(Ze,e),e&&a(er),e&&a(U),v(Qe),e&&a(ar),e&&a(A),e&&a(tr),v(ta,e),e&&a(sr),e&&a(D),e&&a(rr),v(sa,e),e&&a(nr),e&&a(me),e&&a(lr),v(ra,e),e&&a(or),e&&a(W),v(na),e&&a(ir),e&&a(ue),e&&a(pr),v(la,e),e&&a(cr),e&&a(fe),e&&a(mr),v(oa,e),e&&a(dr),e&&a(et),e&&a(ur),e&&a(Y),v(ia),e&&a(fr),v(pa,e),e&&a(hr),e&&a(at),e&&a(gr),e&&a(V),v(ca),e&&a(_r),e&&a(M),e&&a(vr),v(ma,e),e&&a($r),v(_e,e),e&&a(br),e&&a(x),e&&a(jr),v(ua,e),e&&a(wr),e&&a(J),v(fa),e&&a(yr),e&&a(tt),e&&a(Er),v(ha,e),e&&a(kr),e&&a($e),e&&a(qr),v(_a,e),e&&a(Ar),e&&a(st),e&&a(Pr),e&&a(X),v(va),e&&a(Tr),v($a,e),e&&a(zr),e&&a(je),e&&a(Cr),e&&a(rt),e&&a(Dr),v(ba,e),e&&a(xr),e&&a(we),e&&a(Sr),e&&a(H),v(ya),v(ka),v(Aa),e&&a(Fr),e&&a(nt),e&&a(Nr),v(Pa,e),e&&a(Or),e&&a(Z),v(Ta),e&&a(Lr),e&&a(Ee),e&&a(Ir),v(za,e),e&&a(Mr),e&&a(lt),e&&a(Hr),v(Ca,e),e&&a(Rr),e&&a(Q),v(Da),e&&a(Br),e&&a(qe),e&&a(Gr),v(Sa,e),e&&a(Kr),e&&a(Ae),e&&a(Ur),v(Fa,e),e&&a(Wr),e&&a(Pe),e&&a(Yr),v(Na,e),e&&a(Vr),v(Te,e),e&&a(Jr),e&&a(ot),e&&a(Xr),e&&a(ee),v(Oa),e&&a(Zr),e&&a(Ce),e&&a(Qr),v(Ia,e),e&&a(en),e&&a(ae),v(Ma),e&&a(an),e&&a(R),e&&a(tn),v(Ra,e),e&&a(sn),e&&a(it),e&&a(rn),e&&a(te),v(Ba),e&&a(nn),e&&a(pt),e&&a(ln),e&&a(Se)}}}const Kc={local:"finetuning-a-un-modelo-preentrenado",sections:[{local:"prepara-un-dataset",title:"Prepara un dataset"},{local:"finetuning-con-trainer",sections:[{local:"hiperparmetros-de-entrenamiento",title:"Hiperpar\xE1metros de entrenamiento"},{local:"mtricas",title:"M\xE9tricas"},{local:"trainer",title:"Trainer"}],title:"Fine-tuning con `Trainer`"},{local:"finetuning-con-keras",sections:[{local:"convierte-el-dataset-al-formato-de-tensorflow",title:"Convierte el dataset al formato de TensorFlow"},{local:"compila-y-ajusta",title:"Compila y ajusta"}],title:"Fine-tuning con Keras"},{local:"finetune-en-pytorch-nativo",sections:[{local:"dataloader",title:"DataLoader"},{local:"optimiza-y-programa-el-learning-rate",title:"Optimiza y programa el learning rate"},{local:"ciclo-de-entrenamiento",title:"Ciclo de entrenamiento"},{local:"mtricas",title:"M\xE9tricas"}],title:"Fine-tune en PyTorch nativo"},{local:"recursos-adicionales",title:"Recursos adicionales"}],title:"Fine-tuning a un modelo pre-entrenado"};function Uc(se){return Ic(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Qc extends Fc{constructor($){super();Nc(this,$,Uc,Gc,Oc,{})}}export{Qc as default,Kc as metadata};
