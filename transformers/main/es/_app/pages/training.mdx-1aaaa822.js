import{S as Hc,i as Rc,s as Bc,e as r,k as c,w as u,t as i,M as Kc,c as n,d as a,m as d,a as o,x as f,h as p,b as m,F as t,g as l,y as h,q as g,o as _,B as v,v as Uc}from"../chunks/vendor-a50a4eac.js";import{T as Bi}from"../chunks/Tip-52f026d5.js";import{Y as Un}from"../chunks/Youtube-9f2aaf44.js";import{I as z}from"../chunks/IconCopyLink-8e6a6cd7.js";import{C as j}from"../chunks/CodeBlock-468bc730.js";import{D as Wc}from"../chunks/DocNotebookDropdown-46484535.js";function Gc(se){let $,E;return{c(){$=r("p"),E=i(`Ver\xE1s una advertencia acerca de que algunos de los pesos pre-entrenados que no est\xE1n siendo utilizados y que algunos pesos est\xE1n siendo inicializados al azar.
No te preocupes, esto es completamente normal. El head/cabezal pre-entrenado del modelo BERT se descarta y se sustituye por un head de clasificaci\xF3n inicializado aleatoriamente. Puedes aplicar fine-tuning a este nuevo head del modelo en tu tarea de clasificaci\xF3n de secuencias haciendo transfer learning del modelo pre-entrenado.`)},l(b){$=n(b,"P",{});var w=o($);E=p(w,`Ver\xE1s una advertencia acerca de que algunos de los pesos pre-entrenados que no est\xE1n siendo utilizados y que algunos pesos est\xE1n siendo inicializados al azar.
No te preocupes, esto es completamente normal. El head/cabezal pre-entrenado del modelo BERT se descarta y se sustituye por un head de clasificaci\xF3n inicializado aleatoriamente. Puedes aplicar fine-tuning a este nuevo head del modelo en tu tarea de clasificaci\xF3n de secuencias haciendo transfer learning del modelo pre-entrenado.`),w.forEach(a)},m(b,w){l(b,$,w),t($,E)},d(b){b&&a($)}}}function Yc(se){let $,E,b,w,P,y,F;return{c(){$=r("p"),E=r("code"),b=i("Trainer"),w=i(" utiliza "),P=r("code"),y=i("DataCollatorWithPadding"),F=i(" por defecto por lo que no es necesario especificar expl\xEDcitamente un intercalador de datos (data collator, en ingl\xE9s).")},l(T){$=n(T,"P",{});var k=o($);E=n(k,"CODE",{});var q=o(E);b=p(q,"Trainer"),q.forEach(a),w=p(k," utiliza "),P=n(k,"CODE",{});var C=o(P);y=p(C,"DataCollatorWithPadding"),C.forEach(a),F=p(k," por defecto por lo que no es necesario especificar expl\xEDcitamente un intercalador de datos (data collator, en ingl\xE9s)."),k.forEach(a)},m(T,k){l(T,$,k),t($,E),t(E,b),t($,w),t($,P),t(P,y),t($,F)},d(T){T&&a($)}}}function Vc(se){let $,E,b,w,P,y,F,T;return{c(){$=r("p"),E=i("Consigue acceso gratuito a una GPU en la nube si es que no tienes este recurso de forma local con un notebook alojado en "),b=r("a"),w=i("Colaboratory"),P=i(" o "),y=r("a"),F=i("SageMaker StudioLab"),T=i("."),this.h()},l(k){$=n(k,"P",{});var q=o($);E=p(q,"Consigue acceso gratuito a una GPU en la nube si es que no tienes este recurso de forma local con un notebook alojado en "),b=n(q,"A",{href:!0,rel:!0});var C=o(b);w=p(C,"Colaboratory"),C.forEach(a),P=p(q," o "),y=n(q,"A",{href:!0,rel:!0});var Ie=o(y);F=p(Ie,"SageMaker StudioLab"),Ie.forEach(a),T=p(q,"."),q.forEach(a),this.h()},h(){m(b,"href","https://colab.research.google.com/"),m(b,"rel","nofollow"),m(y,"href","https://studiolab.sagemaker.aws/"),m(y,"rel","nofollow")},m(k,q){l(k,$,q),t($,E),t($,b),t(b,w),t($,P),t($,y),t(y,F),t($,T)},d(k){k&&a($)}}}function Jc(se){let $,E,b,w,P,y,F,T,k,q,C,Ie,Ya,Wn,Ss,N,Me,Gn,bt,Yn,Vn,Jn,jt,Xn,Zn,wt,Qn,Fs,Va,Os,B,re,yt,He,eo,Et,ao,Ns,Re,Ls,Ja,to,Is,ne,so,Be,ro,no,Ms,Ke,Hs,oe,oo,Ue,kt,lo,io,Rs,We,Bs,Xa,po,Ks,Ge,Us,Za,Ws,K,le,qt,Ye,co,Qa,mo,At,uo,Gs,Ve,Ys,L,fo,Pt,ho,go,Tt,_o,vo,Vs,ie,$o,Je,bo,jo,Js,Xe,Xs,pe,Zs,U,ce,zt,Ze,wo,Ct,yo,Qs,I,Eo,Dt,ko,qo,Qe,Ao,Po,er,et,To,ar,ea,tr,W,de,xt,aa,zo,St,Co,sr,A,Do,Ft,xo,So,Ot,Fo,Oo,ta,Nt,No,Lo,Lt,Io,Mo,sa,Ho,Ro,rr,ra,nr,D,Bo,It,Ko,Uo,Mt,Wo,Go,Ht,Yo,Vo,or,na,lr,me,Jo,Rt,Xo,Zo,ir,oa,pr,G,ue,Bt,la,Qo,Kt,el,cr,fe,al,Ut,tl,sl,dr,ia,mr,he,rl,Wt,nl,ol,ur,pa,fr,at,hr,Y,ge,Gt,ca,ll,Yt,il,gr,da,_r,tt,pl,vr,V,_e,Vt,ma,cl,Jt,dl,$r,M,ml,Xt,ul,fl,Zt,hl,gl,br,ua,jr,ve,wr,x,_l,fa,Qt,vl,$l,es,bl,jl,as,wl,yl,yr,ha,Er,J,$e,ts,ga,El,ss,kl,kr,st,ql,qr,_a,Ar,be,Al,va,rs,Pl,Tl,Pr,$a,Tr,rt,zr,X,je,ns,ba,zl,os,Cl,Cr,ja,Dr,we,Dl,ls,xl,Sl,xr,nt,Fl,Sr,wa,Fr,ye,Ol,is,Nl,Ll,Or,H,ya,Ea,Il,ps,Ml,Hl,Rl,ka,Bl,qa,O,Kl,cs,Ul,Wl,ds,Gl,Yl,ms,Vl,Jl,Xl,Aa,Zl,Pa,us,Ql,ei,Ta,Nr,ot,ai,Lr,za,Ir,Z,Ee,fs,Ca,ti,hs,si,Mr,ke,ri,gs,ni,oi,Hr,Da,Rr,lt,li,Br,xa,Kr,Q,qe,_s,Sa,ii,vs,pi,Ur,Ae,ci,Fa,$s,di,mi,Wr,Oa,Gr,Pe,ui,bs,fi,hi,Yr,Na,Vr,Te,gi,js,_i,vi,Jr,La,Xr,ze,Zr,it,$i,Qr,ee,Ce,ws,Ia,bi,ys,ji,en,De,wi,Ma,yi,Ei,an,Ha,tn,ae,xe,Es,Ra,ki,ks,qi,sn,R,Ai,qs,Pi,Ti,Ba,As,zi,Ci,rn,Ka,nn,pt,on,te,Se,Ps,Ua,Di,Ts,xi,ln,ct,Si,pn,Fe,zs,dt,Wa,Fi,Oi,Ni,Cs,mt,ut,Li,Ii,cn;return y=new z({}),C=new Wc({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/es/training.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/es/pytorch/training.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/es/tensorflow/training.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/es/training.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/es/pytorch/training.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/es/tensorflow/training.ipynb"}]}}),He=new z({}),Re=new Un({props:{id:"_BZearw7f0w"}}),Ke=new j({props:{code:`from datasets import load_dataset

dataset = load_dataset("yelp_review_full")
dataset[100]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;yelp_review_full&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">100</span>]
{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\&#x27;s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\&#x27;s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\&quot;serving off their orders\\\\&quot; when they didn\\&#x27;t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\&#x27;t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\&#x27;ve eaten at various McDonalds restaurants for over 30 years. I\\&#x27;ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!&#x27;</span>}`}}),We=new j({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")


def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)


tokenized_datasets = dataset.map(tokenize_function, batched=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&quot;text&quot;</span>], padding=<span class="hljs-string">&quot;max_length&quot;</span>, truncation=<span class="hljs-literal">True</span>)


<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets = dataset.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)`}}),Ge=new j({props:{code:`small_train_dataset = tokenized_datasets["train"].shuffle(seed=42).select(range(1000))
small_eval_dataset = tokenized_datasets["test"].shuffle(seed=42).select(range(1000))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>small_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>small_eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;test&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))`}}),Ye=new z({}),Ve=new Un({props:{id:"nvBXf7s7vTI"}}),Xe=new j({props:{code:`from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, num_labels=<span class="hljs-number">5</span>)`}}),pe=new Bi({props:{$$slots:{default:[Gc]},$$scope:{ctx:se}}}),Ze=new z({}),ea=new j({props:{code:`from transformers import TrainingArguments

training_args = TrainingArguments(output_dir="test_trainer")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(output_dir=<span class="hljs-string">&quot;test_trainer&quot;</span>)`}}),aa=new z({}),ra=new j({props:{code:`import numpy as np
from datasets import load_metric

metric = load_metric("accuracy")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_metric

<span class="hljs-meta">&gt;&gt;&gt; </span>metric = load_metric(<span class="hljs-string">&quot;accuracy&quot;</span>)`}}),na=new j({props:{code:`def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):
<span class="hljs-meta">... </span>    logits, labels = eval_pred
<span class="hljs-meta">... </span>    predictions = np.argmax(logits, axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> metric.compute(predictions=predictions, references=labels)`}}),oa=new j({props:{code:`from transformers import TrainingArguments

training_args = TrainingArguments(output_dir="test_trainer", evaluation_strategy="epoch")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(output_dir=<span class="hljs-string">&quot;test_trainer&quot;</span>, evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>)`}}),la=new z({}),ia=new j({props:{code:`trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=small_train_dataset,
    eval_dataset=small_eval_dataset,
    compute_metrics=compute_metrics,
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=small_train_dataset,
<span class="hljs-meta">... </span>    eval_dataset=small_eval_dataset,
<span class="hljs-meta">... </span>    compute_metrics=compute_metrics,
<span class="hljs-meta">... </span>)`}}),pa=new j({props:{code:"trainer.train()",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()'}}),ca=new z({}),da=new Un({props:{id:"rnTGBy2ax1c"}}),ma=new z({}),ua=new j({props:{code:`from transformers import DefaultDataCollator

data_collator = DefaultDataCollator(return_tensors="tf")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DefaultDataCollator

<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DefaultDataCollator(return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`}}),ve=new Bi({props:{$$slots:{default:[Yc]},$$scope:{ctx:se}}}),ha=new j({props:{code:`tf_train_dataset = small_train_dataset.to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=8,
)

tf_validation_dataset = small_eval_dataset.to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["labels"],
    shuffle=False,
    collate_fn=data_collator,
    batch_size=8,
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_train_dataset = small_train_dataset.to_tf_dataset(
<span class="hljs-meta">... </span>    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
<span class="hljs-meta">... </span>    label_cols=[<span class="hljs-string">&quot;labels&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">8</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_validation_dataset = small_eval_dataset.to_tf_dataset(
<span class="hljs-meta">... </span>    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
<span class="hljs-meta">... </span>    label_cols=[<span class="hljs-string">&quot;labels&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">False</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">8</span>,
<span class="hljs-meta">... </span>)`}}),ga=new z({}),_a=new j({props:{code:`import tensorflow as tf
from transformers import TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, num_labels=<span class="hljs-number">5</span>)`}}),$a=new j({props:{code:`model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=tf.metrics.SparseCategoricalAccuracy(),
)

model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">compile</span>(
<span class="hljs-meta">... </span>    optimizer=tf.keras.optimizers.Adam(learning_rate=<span class="hljs-number">5e-5</span>),
<span class="hljs-meta">... </span>    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>),
<span class="hljs-meta">... </span>    metrics=tf.metrics.SparseCategoricalAccuracy(),
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=<span class="hljs-number">3</span>)`}}),ba=new z({}),ja=new Un({props:{id:"Dh9CL8fyG80"}}),wa=new j({props:{code:`del model
del pytorch_model
del trainer
torch.cuda.empty_cache()`,highlighted:`<span class="hljs-keyword">del</span> model
<span class="hljs-keyword">del</span> pytorch_model
<span class="hljs-keyword">del</span> trainer
torch.cuda.empty_cache()`}}),ka=new j({props:{code:'tokenized_datasets = tokenized_datasets.remove_columns(["text"])',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets = tokenized_datasets.remove_columns([<span class="hljs-string">&quot;text&quot;</span>])'}}),Aa=new j({props:{code:'tokenized_datasets = tokenized_datasets.rename_column("label", "labels")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets = tokenized_datasets.rename_column(<span class="hljs-string">&quot;label&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>)'}}),Ta=new j({props:{code:'tokenized_datasets.set_format("torch")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_datasets.set_format(<span class="hljs-string">&quot;torch&quot;</span>)'}}),za=new j({props:{code:`small_train_dataset = tokenized_datasets["train"].shuffle(seed=42).select(range(1000))
small_eval_dataset = tokenized_datasets["test"].shuffle(seed=42).select(range(1000))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>small_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>small_eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;test&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))`}}),Ca=new z({}),Da=new j({props:{code:`from torch.utils.data import DataLoader

train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=8)
eval_dataloader = DataLoader(small_eval_dataset, batch_size=8)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader

<span class="hljs-meta">&gt;&gt;&gt; </span>train_dataloader = DataLoader(small_train_dataset, shuffle=<span class="hljs-literal">True</span>, batch_size=<span class="hljs-number">8</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>eval_dataloader = DataLoader(small_eval_dataset, batch_size=<span class="hljs-number">8</span>)`}}),xa=new j({props:{code:`from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, num_labels=<span class="hljs-number">5</span>)`}}),Sa=new z({}),Oa=new j({props:{code:`from torch.optim import AdamW

optimizer = AdamW(model.parameters(), lr=5e-5)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> AdamW

<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">5e-5</span>)`}}),Na=new j({props:{code:`from transformers import get_scheduler

num_epochs = 3
num_training_steps = num_epochs * len(train_dataloader)
lr_scheduler = get_scheduler(
    name="linear", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> get_scheduler

<span class="hljs-meta">&gt;&gt;&gt; </span>num_epochs = <span class="hljs-number">3</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>num_training_steps = num_epochs * <span class="hljs-built_in">len</span>(train_dataloader)
<span class="hljs-meta">&gt;&gt;&gt; </span>lr_scheduler = get_scheduler(
<span class="hljs-meta">... </span>    name=<span class="hljs-string">&quot;linear&quot;</span>, optimizer=optimizer, num_warmup_steps=<span class="hljs-number">0</span>, num_training_steps=num_training_steps
<span class="hljs-meta">... </span>)`}}),La=new j({props:{code:`import torch

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
model.to(device)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>) <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.to(device)`}}),ze=new Bi({props:{$$slots:{default:[Vc]},$$scope:{ctx:se}}}),Ia=new z({}),Ha=new j({props:{code:`from tqdm.auto import tqdm

progress_bar = tqdm(range(num_training_steps))

model.train()
for epoch in range(num_epochs):
    for batch in train_dataloader:
        batch = {k: v.to(device) for k, v in batch.items()}
        outputs = model(**batch)
        loss = outputs.loss
        loss.backward()

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm

<span class="hljs-meta">&gt;&gt;&gt; </span>progress_bar = tqdm(<span class="hljs-built_in">range</span>(num_training_steps))

<span class="hljs-meta">&gt;&gt;&gt; </span>model.train()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:
<span class="hljs-meta">... </span>        batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}
<span class="hljs-meta">... </span>        outputs = model(**batch)
<span class="hljs-meta">... </span>        loss = outputs.loss
<span class="hljs-meta">... </span>        loss.backward()

<span class="hljs-meta">... </span>        optimizer.step()
<span class="hljs-meta">... </span>        lr_scheduler.step()
<span class="hljs-meta">... </span>        optimizer.zero_grad()
<span class="hljs-meta">... </span>        progress_bar.update(<span class="hljs-number">1</span>)`}}),Ra=new z({}),Ka=new j({props:{code:`metric = load_metric("accuracy")
model.eval()
for batch in eval_dataloader:
    batch = {k: v.to(device) for k, v in batch.items()}
    with torch.no_grad():
        outputs = model(**batch)

    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-1)
    metric.add_batch(predictions=predictions, references=batch["labels"])

metric.compute()`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>metric = load_metric(<span class="hljs-string">&quot;accuracy&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">eval</span>()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> eval_dataloader:
<span class="hljs-meta">... </span>    batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}
<span class="hljs-meta">... </span>    <span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>        outputs = model(**batch)

<span class="hljs-meta">... </span>    logits = outputs.logits
<span class="hljs-meta">... </span>    predictions = torch.argmax(logits, dim=-<span class="hljs-number">1</span>)
<span class="hljs-meta">... </span>    metric.add_batch(predictions=predictions, references=batch[<span class="hljs-string">&quot;labels&quot;</span>])

<span class="hljs-meta">&gt;&gt;&gt; </span>metric.compute()`}}),Ua=new z({}),{c(){$=r("meta"),E=c(),b=r("h1"),w=r("a"),P=r("span"),u(y.$$.fragment),F=c(),T=r("span"),k=i("Fine-tuning a un modelo pre-entrenado"),q=c(),u(C.$$.fragment),Ie=c(),Ya=r("p"),Wn=i("El uso de un modelo pre-entrenado tiene importantes ventajas. Reduce los costos de computaci\xF3n, la huella de carbono, y te permite utilizar modelos de \xFAltima generaci\xF3n sin tener que entrenar uno desde cero. \u{1F917} Transformers proporciona acceso a miles de modelos pre-entrenados en una amplia gama de tareas. Cuando utilizas un modelo pre-entrenado, lo entrenas con un dataset espec\xEDfico para tu tarea. Esto se conoce como fine-tuning, una t\xE9cnica de entrenamiento incre\xEDblemente poderosa. En este tutorial haremos fine-tuning a un modelo pre-entrenado con un framework de Deep Learning de tu elecci\xF3n:"),Ss=c(),N=r("ul"),Me=r("li"),Gn=i("Fine-tuning a un modelo pre-entrenado con \u{1F917} Transformers "),bt=r("code"),Yn=i("Trainer"),Vn=i("."),Jn=c(),jt=r("li"),Xn=i("Fine-tuning a un modelo pre-entrenado en TensorFlow con Keras."),Zn=c(),wt=r("li"),Qn=i("Fine-tuning a un modelo pre-entrenado en PyTorch nativo."),Fs=c(),Va=r("a"),Os=c(),B=r("h2"),re=r("a"),yt=r("span"),u(He.$$.fragment),eo=c(),Et=r("span"),ao=i("Prepara un dataset"),Ns=c(),u(Re.$$.fragment),Ls=c(),Ja=r("p"),to=i("Antes de aplicar fine-tuning a un modelo pre-entrenado, descarga un dataset y prep\xE1ralo para el entrenamiento. El tutorial anterior nos ense\xF1\xF3 c\xF3mo procesar los datos para el entrenamiento, y ahora es la oportunidad de poner a prueba estas habilidades."),Is=c(),ne=r("p"),so=i("Comienza cargando el dataset de "),Be=r("a"),ro=i("Yelp Reviews"),no=i(":"),Ms=c(),u(Ke.$$.fragment),Hs=c(),oe=r("p"),oo=i("Como ya sabes, necesitas un tokenizador para procesar el texto e incluir una estrategia para el padding y el truncamiento, para manejar cualquier longitud de secuencia variable. Para procesar tu dataset en un solo paso, utiliza el m\xE9todo de \u{1F917} Datasets "),Ue=r("a"),kt=r("code"),lo=i("map"),io=i(" para aplicar una funci\xF3n de preprocesamiento sobre todo el dataset:"),Rs=c(),u(We.$$.fragment),Bs=c(),Xa=r("p"),po=i("Si lo deseas, puedes crear un subconjunto m\xE1s peque\xF1o del dataset completo para aplicarle fine-tuning y as\xED reducir el tiempo."),Ks=c(),u(Ge.$$.fragment),Us=c(),Za=r("a"),Ws=c(),K=r("h2"),le=r("a"),qt=r("span"),u(Ye.$$.fragment),co=c(),Qa=r("span"),mo=i("Fine-tuning con "),At=r("code"),uo=i("Trainer"),Gs=c(),u(Ve.$$.fragment),Ys=c(),L=r("p"),fo=i("\u{1F917} Transformers proporciona una clase "),Pt=r("code"),ho=i("Trainer"),go=i(" optimizada para el entrenamiento de modelos de \u{1F917} Transformers, haciendo m\xE1s f\xE1cil el inicio del entrenamiento sin necesidad de escribir manualmente tu propio ciclo. La API del "),Tt=r("code"),_o=i("Trainer"),vo=i(" soporta una amplia gama de opciones de entrenamiento y caracter\xEDsticas como el logging, el gradient accumulation y el mixed precision."),Vs=c(),ie=r("p"),$o=i("Comienza cargando tu modelo y especifica el n\xFAmero de labels previstas. A partir del "),Je=r("a"),bo=i("Card Dataset"),jo=i(" de Yelp Review, que como ya sabemos tiene 5 labels:"),Js=c(),u(Xe.$$.fragment),Xs=c(),u(pe.$$.fragment),Zs=c(),U=r("h3"),ce=r("a"),zt=r("span"),u(Ze.$$.fragment),wo=c(),Ct=r("span"),yo=i("Hiperpar\xE1metros de entrenamiento"),Qs=c(),I=r("p"),Eo=i("A continuaci\xF3n, crea una clase "),Dt=r("code"),ko=i("TrainingArguments"),qo=i(" que contenga todos los hiperpar\xE1metros que puedes ajustar as\xED como los indicadores para activar las diferentes opciones de entrenamiento. Para este tutorial puedes empezar con los "),Qe=r("a"),Ao=i("hiperpar\xE1metros"),Po=i(" de entrenamiento por defecto, pero si\xE9ntete libre de experimentar con ellos para encontrar tu configuraci\xF3n \xF3ptima."),er=c(),et=r("p"),To=i("Especifica d\xF3nde vas a guardar los checkpoints de tu entrenamiento:"),ar=c(),u(ea.$$.fragment),tr=c(),W=r("h3"),de=r("a"),xt=r("span"),u(aa.$$.fragment),zo=c(),St=r("span"),Co=i("M\xE9tricas"),sr=c(),A=r("p"),Do=i("El "),Ft=r("code"),xo=i("Trainer"),So=i(" no eval\xFAa autom\xE1ticamente el rendimiento del modelo durante el entrenamiento. Tendr\xE1s que pasarle a "),Ot=r("code"),Fo=i("Trainer"),Oo=i(" una funci\xF3n para calcular y hacer un reporte de las m\xE9tricas. La librer\xEDa de \u{1F917} Datasets proporciona una funci\xF3n de "),ta=r("a"),Nt=r("code"),No=i("accuracy"),Lo=i(" simple que puedes cargar con la funci\xF3n "),Lt=r("code"),Io=i("load_metric"),Mo=i(" (ver este "),sa=r("a"),Ho=i("tutorial"),Ro=i(" para m\xE1s informaci\xF3n):"),rr=c(),u(ra.$$.fragment),nr=c(),D=r("p"),Bo=i("Define la funci\xF3n "),It=r("code"),Ko=i("compute"),Uo=i(" en "),Mt=r("code"),Wo=i("metric"),Go=i(" para calcular el accuracy de tus predicciones. Antes de pasar tus predicciones a "),Ht=r("code"),Yo=i("compute"),Vo=i(", necesitas convertir las predicciones a logits (recuerda que todos los modelos de \u{1F917} Transformers devuelven logits)."),or=c(),u(na.$$.fragment),lr=c(),me=r("p"),Jo=i("Si quieres controlar tus m\xE9tricas de evaluaci\xF3n durante el fine-tuning, especifica el par\xE1metro "),Rt=r("code"),Xo=i("evaluation_strategy"),Zo=i(" en tus argumentos de entrenamiento para que el modelo tenga en cuenta la m\xE9trica de evaluaci\xF3n al final de cada \xE9poca:"),ir=c(),u(oa.$$.fragment),pr=c(),G=r("h3"),ue=r("a"),Bt=r("span"),u(la.$$.fragment),Qo=c(),Kt=r("span"),el=i("Trainer"),cr=c(),fe=r("p"),al=i("Crea un objeto "),Ut=r("code"),tl=i("Trainer"),sl=i(" con tu modelo, argumentos de entrenamiento, conjuntos de datos de entrenamiento y de prueba, y tu funci\xF3n de evaluaci\xF3n:"),dr=c(),u(ia.$$.fragment),mr=c(),he=r("p"),rl=i("A continuaci\xF3n, aplica fine-tuning a tu modelo llamando "),Wt=r("code"),nl=i("train()"),ol=i(":"),ur=c(),u(pa.$$.fragment),fr=c(),at=r("a"),hr=c(),Y=r("h2"),ge=r("a"),Gt=r("span"),u(ca.$$.fragment),ll=c(),Yt=r("span"),il=i("Fine-tuning con Keras"),gr=c(),u(da.$$.fragment),_r=c(),tt=r("p"),pl=i("Los modelos de \u{1F917} Transformers tambi\xE9n permiten realizar el entrenamiento en TensorFlow con la API de Keras. S\xF3lo es necesario hacer algunos cambios antes de hacer fine-tuning."),vr=c(),V=r("h3"),_e=r("a"),Vt=r("span"),u(ma.$$.fragment),cl=c(),Jt=r("span"),dl=i("Convierte el dataset al formato de TensorFlow"),$r=c(),M=r("p"),ml=i("El "),Xt=r("code"),ul=i("DefaultDataCollator"),fl=i(" junta los tensores en un batch para que el modelo se entrene en \xE9l. Aseg\xFArate de especificar "),Zt=r("code"),hl=i("return_tensors"),gl=i(" para devolver los tensores de TensorFlow:"),br=c(),u(ua.$$.fragment),jr=c(),u(ve.$$.fragment),wr=c(),x=r("p"),_l=i("A continuaci\xF3n, convierte los datasets tokenizados en datasets de TensorFlow con el m\xE9todo "),fa=r("a"),Qt=r("code"),vl=i("to_tf_dataset"),$l=i(". Especifica tus entradas en "),es=r("code"),bl=i("columns"),jl=i(" y tu etiqueta en "),as=r("code"),wl=i("label_cols"),yl=i(":"),yr=c(),u(ha.$$.fragment),Er=c(),J=r("h3"),$e=r("a"),ts=r("span"),u(ga.$$.fragment),El=c(),ss=r("span"),kl=i("Compila y ajusta"),kr=c(),st=r("p"),ql=i("Carguemos un modelo TensorFlow con el n\xFAmero esperado de labels:"),qr=c(),u(_a.$$.fragment),Ar=c(),be=r("p"),Al=i("A continuaci\xF3n, compila y aplica fine-tuning a tu modelo con "),va=r("a"),rs=r("code"),Pl=i("fit"),Tl=i(" como lo har\xEDas con cualquier otro modelo de Keras:"),Pr=c(),u($a.$$.fragment),Tr=c(),rt=r("a"),zr=c(),X=r("h2"),je=r("a"),ns=r("span"),u(ba.$$.fragment),zl=c(),os=r("span"),Cl=i("Fine-tune en PyTorch nativo"),Cr=c(),u(ja.$$.fragment),Dr=c(),we=r("p"),Dl=i("El "),ls=r("code"),xl=i("Trainer"),Sl=i(" se encarga del ciclo de entrenamiento y permite aplicar fine-tuning a un modelo en una sola l\xEDnea de c\xF3digo. Para los usuarios que prefieren escribir tu propio ciclo de entrenamiento, tambi\xE9n puedes aplicar fine-tuning a un modelo de \u{1F917} Transformers en PyTorch nativo."),xr=c(),nt=r("p"),Fl=i("En este punto, es posible que necesites reiniciar tu notebook o ejecutar el siguiente c\xF3digo para liberar algo de memoria:"),Sr=c(),u(wa.$$.fragment),Fr=c(),ye=r("p"),Ol=i("A continuaci\xF3n, haremos un post-procesamiento manual al "),is=r("code"),Nl=i("tokenized_dataset"),Ll=i(" y as\xED prepararlo para el entrenamiento."),Or=c(),H=r("ol"),ya=r("li"),Ea=r("p"),Il=i("Elimina la columna de "),ps=r("code"),Ml=i("text"),Hl=i(" porque el modelo no acepta texto en crudo como entrada:"),Rl=c(),u(ka.$$.fragment),Bl=c(),qa=r("li"),O=r("p"),Kl=i("Cambia el nombre de la columna de "),cs=r("code"),Ul=i("label"),Wl=i(" a "),ds=r("code"),Gl=i("labels"),Yl=i(" porque el modelo espera que el argumento se llame "),ms=r("code"),Vl=i("labels"),Jl=i(":"),Xl=c(),u(Aa.$$.fragment),Zl=c(),Pa=r("li"),us=r("p"),Ql=i("Establece el formato del dataset para devolver tensores PyTorch en lugar de listas:"),ei=c(),u(Ta.$$.fragment),Nr=c(),ot=r("p"),ai=i("A continuaci\xF3n, crea un subconjunto m\xE1s peque\xF1o del dataset, como se ha mostrado anteriormente, para acelerar el fine-tuning:"),Lr=c(),u(za.$$.fragment),Ir=c(),Z=r("h3"),Ee=r("a"),fs=r("span"),u(Ca.$$.fragment),ti=c(),hs=r("span"),si=i("DataLoader"),Mr=c(),ke=r("p"),ri=i("Crea un "),gs=r("code"),ni=i("DataLoader"),oi=i(" para tus datasets de entrenamiento y de prueba para poder iterar sobre batches de datos:"),Hr=c(),u(Da.$$.fragment),Rr=c(),lt=r("p"),li=i("Carga tu modelo con el n\xFAmero de labels previstas:"),Br=c(),u(xa.$$.fragment),Kr=c(),Q=r("h3"),qe=r("a"),_s=r("span"),u(Sa.$$.fragment),ii=c(),vs=r("span"),pi=i("Optimiza y progrma el learning rate"),Ur=c(),Ae=r("p"),ci=i("Crea un optimizador y el learning rate para aplicar fine-tuning al modelo. Vamos a utilizar el optimizador "),Fa=r("a"),$s=r("code"),di=i("AdamW"),mi=i(" de PyTorch:"),Wr=c(),u(Oa.$$.fragment),Gr=c(),Pe=r("p"),ui=i("Crea el learning rate desde el "),bs=r("code"),fi=i("Trainer"),hi=i(":"),Yr=c(),u(Na.$$.fragment),Vr=c(),Te=r("p"),gi=i("Por \xFAltimo, especifica el "),js=r("code"),_i=i("device"),vi=i(" o entorno de ejecuci\xF3n para utilizar una GPU si tienes acceso a una. De lo contrario, el entrenamiento en una CPU puede llevarte varias horas en lugar de un par de minutos."),Jr=c(),u(La.$$.fragment),Xr=c(),u(ze.$$.fragment),Zr=c(),it=r("p"),$i=i("Genial, \xA1ahora estamos listos entrenar! \u{1F973}"),Qr=c(),ee=r("h3"),Ce=r("a"),ws=r("span"),u(Ia.$$.fragment),bi=c(),ys=r("span"),ji=i("Ciclo de entrenamiento"),en=c(),De=r("p"),wi=i("Para hacer un seguimiento al progreso del entrenamiento, utiliza la librer\xEDa "),Ma=r("a"),yi=i("tqdm"),Ei=i(" para a\xF1adir una barra de progreso sobre el n\xFAmero de pasos de entrenamiento:"),an=c(),u(Ha.$$.fragment),tn=c(),ae=r("h3"),xe=r("a"),Es=r("span"),u(Ra.$$.fragment),ki=c(),ks=r("span"),qi=i("M\xE9tricas"),sn=c(),R=r("p"),Ai=i("De la misma manera que necesitas a\xF1adir una funci\xF3n de evaluaci\xF3n al "),qs=r("code"),Pi=i("Trainer"),Ti=i(", necesitas hacer lo mismo cuando escribas tu propio ciclo de entrenamiento. Pero en lugar de calcular y reportar la m\xE9trica al final de cada \xE9poca, esta vez acumular\xE1s todos los batches con "),Ba=r("a"),As=r("code"),zi=i("add_batch"),Ci=i(" y calcular\xE1s la m\xE9trica al final."),rn=c(),u(Ka.$$.fragment),nn=c(),pt=r("a"),on=c(),te=r("h2"),Se=r("a"),Ps=r("span"),u(Ua.$$.fragment),Di=c(),Ts=r("span"),xi=i("Recursos adicionales"),ln=c(),ct=r("p"),Si=i("Para m\xE1s ejemplos de fine-tuning consulta:"),pn=c(),Fe=r("ul"),zs=r("li"),dt=r("p"),Wa=r("a"),Fi=i("\u{1F917} Transformers Examples"),Oi=i(` incluye scripts
para entrenar tareas comunes de NLP en PyTorch y TensorFlow.`),Ni=c(),Cs=r("li"),mt=r("p"),ut=r("a"),Li=i("\u{1F917} Transformers Notebooks"),Ii=i(" contiene varios notebooks sobre c\xF3mo aplicar fine-tuning a un modelo para tareas espec\xEDficas en PyTorch y TensorFlow."),this.h()},l(e){const s=Kc('[data-svelte="svelte-1phssyn"]',document.head);$=n(s,"META",{name:!0,content:!0}),s.forEach(a),E=d(e),b=n(e,"H1",{class:!0});var Ga=o(b);w=n(Ga,"A",{id:!0,class:!0,href:!0});var Ds=o(w);P=n(Ds,"SPAN",{});var xs=o(P);f(y.$$.fragment,xs),xs.forEach(a),Ds.forEach(a),F=d(Ga),T=n(Ga,"SPAN",{});var Ki=o(T);k=p(Ki,"Fine-tuning a un modelo pre-entrenado"),Ki.forEach(a),Ga.forEach(a),q=d(e),f(C.$$.fragment,e),Ie=d(e),Ya=n(e,"P",{});var Ui=o(Ya);Wn=p(Ui,"El uso de un modelo pre-entrenado tiene importantes ventajas. Reduce los costos de computaci\xF3n, la huella de carbono, y te permite utilizar modelos de \xFAltima generaci\xF3n sin tener que entrenar uno desde cero. \u{1F917} Transformers proporciona acceso a miles de modelos pre-entrenados en una amplia gama de tareas. Cuando utilizas un modelo pre-entrenado, lo entrenas con un dataset espec\xEDfico para tu tarea. Esto se conoce como fine-tuning, una t\xE9cnica de entrenamiento incre\xEDblemente poderosa. En este tutorial haremos fine-tuning a un modelo pre-entrenado con un framework de Deep Learning de tu elecci\xF3n:"),Ui.forEach(a),Ss=d(e),N=n(e,"UL",{});var ft=o(N);Me=n(ft,"LI",{});var dn=o(Me);Gn=p(dn,"Fine-tuning a un modelo pre-entrenado con \u{1F917} Transformers "),bt=n(dn,"CODE",{});var Wi=o(bt);Yn=p(Wi,"Trainer"),Wi.forEach(a),Vn=p(dn,"."),dn.forEach(a),Jn=d(ft),jt=n(ft,"LI",{});var Gi=o(jt);Xn=p(Gi,"Fine-tuning a un modelo pre-entrenado en TensorFlow con Keras."),Gi.forEach(a),Zn=d(ft),wt=n(ft,"LI",{});var Yi=o(wt);Qn=p(Yi,"Fine-tuning a un modelo pre-entrenado en PyTorch nativo."),Yi.forEach(a),ft.forEach(a),Fs=d(e),Va=n(e,"A",{id:!0}),o(Va).forEach(a),Os=d(e),B=n(e,"H2",{class:!0});var mn=o(B);re=n(mn,"A",{id:!0,class:!0,href:!0});var Vi=o(re);yt=n(Vi,"SPAN",{});var Ji=o(yt);f(He.$$.fragment,Ji),Ji.forEach(a),Vi.forEach(a),eo=d(mn),Et=n(mn,"SPAN",{});var Xi=o(Et);ao=p(Xi,"Prepara un dataset"),Xi.forEach(a),mn.forEach(a),Ns=d(e),f(Re.$$.fragment,e),Ls=d(e),Ja=n(e,"P",{});var Zi=o(Ja);to=p(Zi,"Antes de aplicar fine-tuning a un modelo pre-entrenado, descarga un dataset y prep\xE1ralo para el entrenamiento. El tutorial anterior nos ense\xF1\xF3 c\xF3mo procesar los datos para el entrenamiento, y ahora es la oportunidad de poner a prueba estas habilidades."),Zi.forEach(a),Is=d(e),ne=n(e,"P",{});var un=o(ne);so=p(un,"Comienza cargando el dataset de "),Be=n(un,"A",{href:!0,rel:!0});var Qi=o(Be);ro=p(Qi,"Yelp Reviews"),Qi.forEach(a),no=p(un,":"),un.forEach(a),Ms=d(e),f(Ke.$$.fragment,e),Hs=d(e),oe=n(e,"P",{});var fn=o(oe);oo=p(fn,"Como ya sabes, necesitas un tokenizador para procesar el texto e incluir una estrategia para el padding y el truncamiento, para manejar cualquier longitud de secuencia variable. Para procesar tu dataset en un solo paso, utiliza el m\xE9todo de \u{1F917} Datasets "),Ue=n(fn,"A",{href:!0,rel:!0});var ep=o(Ue);kt=n(ep,"CODE",{});var ap=o(kt);lo=p(ap,"map"),ap.forEach(a),ep.forEach(a),io=p(fn," para aplicar una funci\xF3n de preprocesamiento sobre todo el dataset:"),fn.forEach(a),Rs=d(e),f(We.$$.fragment,e),Bs=d(e),Xa=n(e,"P",{});var tp=o(Xa);po=p(tp,"Si lo deseas, puedes crear un subconjunto m\xE1s peque\xF1o del dataset completo para aplicarle fine-tuning y as\xED reducir el tiempo."),tp.forEach(a),Ks=d(e),f(Ge.$$.fragment,e),Us=d(e),Za=n(e,"A",{id:!0}),o(Za).forEach(a),Ws=d(e),K=n(e,"H2",{class:!0});var hn=o(K);le=n(hn,"A",{id:!0,class:!0,href:!0});var sp=o(le);qt=n(sp,"SPAN",{});var rp=o(qt);f(Ye.$$.fragment,rp),rp.forEach(a),sp.forEach(a),co=d(hn),Qa=n(hn,"SPAN",{});var Mi=o(Qa);mo=p(Mi,"Fine-tuning con "),At=n(Mi,"CODE",{});var np=o(At);uo=p(np,"Trainer"),np.forEach(a),Mi.forEach(a),hn.forEach(a),Gs=d(e),f(Ve.$$.fragment,e),Ys=d(e),L=n(e,"P",{});var ht=o(L);fo=p(ht,"\u{1F917} Transformers proporciona una clase "),Pt=n(ht,"CODE",{});var op=o(Pt);ho=p(op,"Trainer"),op.forEach(a),go=p(ht," optimizada para el entrenamiento de modelos de \u{1F917} Transformers, haciendo m\xE1s f\xE1cil el inicio del entrenamiento sin necesidad de escribir manualmente tu propio ciclo. La API del "),Tt=n(ht,"CODE",{});var lp=o(Tt);_o=p(lp,"Trainer"),lp.forEach(a),vo=p(ht," soporta una amplia gama de opciones de entrenamiento y caracter\xEDsticas como el logging, el gradient accumulation y el mixed precision."),ht.forEach(a),Vs=d(e),ie=n(e,"P",{});var gn=o(ie);$o=p(gn,"Comienza cargando tu modelo y especifica el n\xFAmero de labels previstas. A partir del "),Je=n(gn,"A",{href:!0,rel:!0});var ip=o(Je);bo=p(ip,"Card Dataset"),ip.forEach(a),jo=p(gn," de Yelp Review, que como ya sabemos tiene 5 labels:"),gn.forEach(a),Js=d(e),f(Xe.$$.fragment,e),Xs=d(e),f(pe.$$.fragment,e),Zs=d(e),U=n(e,"H3",{class:!0});var _n=o(U);ce=n(_n,"A",{id:!0,class:!0,href:!0});var pp=o(ce);zt=n(pp,"SPAN",{});var cp=o(zt);f(Ze.$$.fragment,cp),cp.forEach(a),pp.forEach(a),wo=d(_n),Ct=n(_n,"SPAN",{});var dp=o(Ct);yo=p(dp,"Hiperpar\xE1metros de entrenamiento"),dp.forEach(a),_n.forEach(a),Qs=d(e),I=n(e,"P",{});var gt=o(I);Eo=p(gt,"A continuaci\xF3n, crea una clase "),Dt=n(gt,"CODE",{});var mp=o(Dt);ko=p(mp,"TrainingArguments"),mp.forEach(a),qo=p(gt," que contenga todos los hiperpar\xE1metros que puedes ajustar as\xED como los indicadores para activar las diferentes opciones de entrenamiento. Para este tutorial puedes empezar con los "),Qe=n(gt,"A",{href:!0,rel:!0});var up=o(Qe);Ao=p(up,"hiperpar\xE1metros"),up.forEach(a),Po=p(gt," de entrenamiento por defecto, pero si\xE9ntete libre de experimentar con ellos para encontrar tu configuraci\xF3n \xF3ptima."),gt.forEach(a),er=d(e),et=n(e,"P",{});var fp=o(et);To=p(fp,"Especifica d\xF3nde vas a guardar los checkpoints de tu entrenamiento:"),fp.forEach(a),ar=d(e),f(ea.$$.fragment,e),tr=d(e),W=n(e,"H3",{class:!0});var vn=o(W);de=n(vn,"A",{id:!0,class:!0,href:!0});var hp=o(de);xt=n(hp,"SPAN",{});var gp=o(xt);f(aa.$$.fragment,gp),gp.forEach(a),hp.forEach(a),zo=d(vn),St=n(vn,"SPAN",{});var _p=o(St);Co=p(_p,"M\xE9tricas"),_p.forEach(a),vn.forEach(a),sr=d(e),A=n(e,"P",{});var S=o(A);Do=p(S,"El "),Ft=n(S,"CODE",{});var vp=o(Ft);xo=p(vp,"Trainer"),vp.forEach(a),So=p(S," no eval\xFAa autom\xE1ticamente el rendimiento del modelo durante el entrenamiento. Tendr\xE1s que pasarle a "),Ot=n(S,"CODE",{});var $p=o(Ot);Fo=p($p,"Trainer"),$p.forEach(a),Oo=p(S," una funci\xF3n para calcular y hacer un reporte de las m\xE9tricas. La librer\xEDa de \u{1F917} Datasets proporciona una funci\xF3n de "),ta=n(S,"A",{href:!0,rel:!0});var bp=o(ta);Nt=n(bp,"CODE",{});var jp=o(Nt);No=p(jp,"accuracy"),jp.forEach(a),bp.forEach(a),Lo=p(S," simple que puedes cargar con la funci\xF3n "),Lt=n(S,"CODE",{});var wp=o(Lt);Io=p(wp,"load_metric"),wp.forEach(a),Mo=p(S," (ver este "),sa=n(S,"A",{href:!0,rel:!0});var yp=o(sa);Ho=p(yp,"tutorial"),yp.forEach(a),Ro=p(S," para m\xE1s informaci\xF3n):"),S.forEach(a),rr=d(e),f(ra.$$.fragment,e),nr=d(e),D=n(e,"P",{});var Oe=o(D);Bo=p(Oe,"Define la funci\xF3n "),It=n(Oe,"CODE",{});var Ep=o(It);Ko=p(Ep,"compute"),Ep.forEach(a),Uo=p(Oe," en "),Mt=n(Oe,"CODE",{});var kp=o(Mt);Wo=p(kp,"metric"),kp.forEach(a),Go=p(Oe," para calcular el accuracy de tus predicciones. Antes de pasar tus predicciones a "),Ht=n(Oe,"CODE",{});var qp=o(Ht);Yo=p(qp,"compute"),qp.forEach(a),Vo=p(Oe,", necesitas convertir las predicciones a logits (recuerda que todos los modelos de \u{1F917} Transformers devuelven logits)."),Oe.forEach(a),or=d(e),f(na.$$.fragment,e),lr=d(e),me=n(e,"P",{});var $n=o(me);Jo=p($n,"Si quieres controlar tus m\xE9tricas de evaluaci\xF3n durante el fine-tuning, especifica el par\xE1metro "),Rt=n($n,"CODE",{});var Ap=o(Rt);Xo=p(Ap,"evaluation_strategy"),Ap.forEach(a),Zo=p($n," en tus argumentos de entrenamiento para que el modelo tenga en cuenta la m\xE9trica de evaluaci\xF3n al final de cada \xE9poca:"),$n.forEach(a),ir=d(e),f(oa.$$.fragment,e),pr=d(e),G=n(e,"H3",{class:!0});var bn=o(G);ue=n(bn,"A",{id:!0,class:!0,href:!0});var Pp=o(ue);Bt=n(Pp,"SPAN",{});var Tp=o(Bt);f(la.$$.fragment,Tp),Tp.forEach(a),Pp.forEach(a),Qo=d(bn),Kt=n(bn,"SPAN",{});var zp=o(Kt);el=p(zp,"Trainer"),zp.forEach(a),bn.forEach(a),cr=d(e),fe=n(e,"P",{});var jn=o(fe);al=p(jn,"Crea un objeto "),Ut=n(jn,"CODE",{});var Cp=o(Ut);tl=p(Cp,"Trainer"),Cp.forEach(a),sl=p(jn," con tu modelo, argumentos de entrenamiento, conjuntos de datos de entrenamiento y de prueba, y tu funci\xF3n de evaluaci\xF3n:"),jn.forEach(a),dr=d(e),f(ia.$$.fragment,e),mr=d(e),he=n(e,"P",{});var wn=o(he);rl=p(wn,"A continuaci\xF3n, aplica fine-tuning a tu modelo llamando "),Wt=n(wn,"CODE",{});var Dp=o(Wt);nl=p(Dp,"train()"),Dp.forEach(a),ol=p(wn,":"),wn.forEach(a),ur=d(e),f(pa.$$.fragment,e),fr=d(e),at=n(e,"A",{id:!0}),o(at).forEach(a),hr=d(e),Y=n(e,"H2",{class:!0});var yn=o(Y);ge=n(yn,"A",{id:!0,class:!0,href:!0});var xp=o(ge);Gt=n(xp,"SPAN",{});var Sp=o(Gt);f(ca.$$.fragment,Sp),Sp.forEach(a),xp.forEach(a),ll=d(yn),Yt=n(yn,"SPAN",{});var Fp=o(Yt);il=p(Fp,"Fine-tuning con Keras"),Fp.forEach(a),yn.forEach(a),gr=d(e),f(da.$$.fragment,e),_r=d(e),tt=n(e,"P",{});var Op=o(tt);pl=p(Op,"Los modelos de \u{1F917} Transformers tambi\xE9n permiten realizar el entrenamiento en TensorFlow con la API de Keras. S\xF3lo es necesario hacer algunos cambios antes de hacer fine-tuning."),Op.forEach(a),vr=d(e),V=n(e,"H3",{class:!0});var En=o(V);_e=n(En,"A",{id:!0,class:!0,href:!0});var Np=o(_e);Vt=n(Np,"SPAN",{});var Lp=o(Vt);f(ma.$$.fragment,Lp),Lp.forEach(a),Np.forEach(a),cl=d(En),Jt=n(En,"SPAN",{});var Ip=o(Jt);dl=p(Ip,"Convierte el dataset al formato de TensorFlow"),Ip.forEach(a),En.forEach(a),$r=d(e),M=n(e,"P",{});var _t=o(M);ml=p(_t,"El "),Xt=n(_t,"CODE",{});var Mp=o(Xt);ul=p(Mp,"DefaultDataCollator"),Mp.forEach(a),fl=p(_t," junta los tensores en un batch para que el modelo se entrene en \xE9l. Aseg\xFArate de especificar "),Zt=n(_t,"CODE",{});var Hp=o(Zt);hl=p(Hp,"return_tensors"),Hp.forEach(a),gl=p(_t," para devolver los tensores de TensorFlow:"),_t.forEach(a),br=d(e),f(ua.$$.fragment,e),jr=d(e),f(ve.$$.fragment,e),wr=d(e),x=n(e,"P",{});var Ne=o(x);_l=p(Ne,"A continuaci\xF3n, convierte los datasets tokenizados en datasets de TensorFlow con el m\xE9todo "),fa=n(Ne,"A",{href:!0,rel:!0});var Rp=o(fa);Qt=n(Rp,"CODE",{});var Bp=o(Qt);vl=p(Bp,"to_tf_dataset"),Bp.forEach(a),Rp.forEach(a),$l=p(Ne,". Especifica tus entradas en "),es=n(Ne,"CODE",{});var Kp=o(es);bl=p(Kp,"columns"),Kp.forEach(a),jl=p(Ne," y tu etiqueta en "),as=n(Ne,"CODE",{});var Up=o(as);wl=p(Up,"label_cols"),Up.forEach(a),yl=p(Ne,":"),Ne.forEach(a),yr=d(e),f(ha.$$.fragment,e),Er=d(e),J=n(e,"H3",{class:!0});var kn=o(J);$e=n(kn,"A",{id:!0,class:!0,href:!0});var Wp=o($e);ts=n(Wp,"SPAN",{});var Gp=o(ts);f(ga.$$.fragment,Gp),Gp.forEach(a),Wp.forEach(a),El=d(kn),ss=n(kn,"SPAN",{});var Yp=o(ss);kl=p(Yp,"Compila y ajusta"),Yp.forEach(a),kn.forEach(a),kr=d(e),st=n(e,"P",{});var Vp=o(st);ql=p(Vp,"Carguemos un modelo TensorFlow con el n\xFAmero esperado de labels:"),Vp.forEach(a),qr=d(e),f(_a.$$.fragment,e),Ar=d(e),be=n(e,"P",{});var qn=o(be);Al=p(qn,"A continuaci\xF3n, compila y aplica fine-tuning a tu modelo con "),va=n(qn,"A",{href:!0,rel:!0});var Jp=o(va);rs=n(Jp,"CODE",{});var Xp=o(rs);Pl=p(Xp,"fit"),Xp.forEach(a),Jp.forEach(a),Tl=p(qn," como lo har\xEDas con cualquier otro modelo de Keras:"),qn.forEach(a),Pr=d(e),f($a.$$.fragment,e),Tr=d(e),rt=n(e,"A",{id:!0}),o(rt).forEach(a),zr=d(e),X=n(e,"H2",{class:!0});var An=o(X);je=n(An,"A",{id:!0,class:!0,href:!0});var Zp=o(je);ns=n(Zp,"SPAN",{});var Qp=o(ns);f(ba.$$.fragment,Qp),Qp.forEach(a),Zp.forEach(a),zl=d(An),os=n(An,"SPAN",{});var ec=o(os);Cl=p(ec,"Fine-tune en PyTorch nativo"),ec.forEach(a),An.forEach(a),Cr=d(e),f(ja.$$.fragment,e),Dr=d(e),we=n(e,"P",{});var Pn=o(we);Dl=p(Pn,"El "),ls=n(Pn,"CODE",{});var ac=o(ls);xl=p(ac,"Trainer"),ac.forEach(a),Sl=p(Pn," se encarga del ciclo de entrenamiento y permite aplicar fine-tuning a un modelo en una sola l\xEDnea de c\xF3digo. Para los usuarios que prefieren escribir tu propio ciclo de entrenamiento, tambi\xE9n puedes aplicar fine-tuning a un modelo de \u{1F917} Transformers en PyTorch nativo."),Pn.forEach(a),xr=d(e),nt=n(e,"P",{});var tc=o(nt);Fl=p(tc,"En este punto, es posible que necesites reiniciar tu notebook o ejecutar el siguiente c\xF3digo para liberar algo de memoria:"),tc.forEach(a),Sr=d(e),f(wa.$$.fragment,e),Fr=d(e),ye=n(e,"P",{});var Tn=o(ye);Ol=p(Tn,"A continuaci\xF3n, haremos un post-procesamiento manual al "),is=n(Tn,"CODE",{});var sc=o(is);Nl=p(sc,"tokenized_dataset"),sc.forEach(a),Ll=p(Tn," y as\xED prepararlo para el entrenamiento."),Tn.forEach(a),Or=d(e),H=n(e,"OL",{});var vt=o(H);ya=n(vt,"LI",{});var zn=o(ya);Ea=n(zn,"P",{});var Cn=o(Ea);Il=p(Cn,"Elimina la columna de "),ps=n(Cn,"CODE",{});var rc=o(ps);Ml=p(rc,"text"),rc.forEach(a),Hl=p(Cn," porque el modelo no acepta texto en crudo como entrada:"),Cn.forEach(a),Rl=d(zn),f(ka.$$.fragment,zn),zn.forEach(a),Bl=d(vt),qa=n(vt,"LI",{});var Dn=o(qa);O=n(Dn,"P",{});var Le=o(O);Kl=p(Le,"Cambia el nombre de la columna de "),cs=n(Le,"CODE",{});var nc=o(cs);Ul=p(nc,"label"),nc.forEach(a),Wl=p(Le," a "),ds=n(Le,"CODE",{});var oc=o(ds);Gl=p(oc,"labels"),oc.forEach(a),Yl=p(Le," porque el modelo espera que el argumento se llame "),ms=n(Le,"CODE",{});var lc=o(ms);Vl=p(lc,"labels"),lc.forEach(a),Jl=p(Le,":"),Le.forEach(a),Xl=d(Dn),f(Aa.$$.fragment,Dn),Dn.forEach(a),Zl=d(vt),Pa=n(vt,"LI",{});var xn=o(Pa);us=n(xn,"P",{});var ic=o(us);Ql=p(ic,"Establece el formato del dataset para devolver tensores PyTorch en lugar de listas:"),ic.forEach(a),ei=d(xn),f(Ta.$$.fragment,xn),xn.forEach(a),vt.forEach(a),Nr=d(e),ot=n(e,"P",{});var pc=o(ot);ai=p(pc,"A continuaci\xF3n, crea un subconjunto m\xE1s peque\xF1o del dataset, como se ha mostrado anteriormente, para acelerar el fine-tuning:"),pc.forEach(a),Lr=d(e),f(za.$$.fragment,e),Ir=d(e),Z=n(e,"H3",{class:!0});var Sn=o(Z);Ee=n(Sn,"A",{id:!0,class:!0,href:!0});var cc=o(Ee);fs=n(cc,"SPAN",{});var dc=o(fs);f(Ca.$$.fragment,dc),dc.forEach(a),cc.forEach(a),ti=d(Sn),hs=n(Sn,"SPAN",{});var mc=o(hs);si=p(mc,"DataLoader"),mc.forEach(a),Sn.forEach(a),Mr=d(e),ke=n(e,"P",{});var Fn=o(ke);ri=p(Fn,"Crea un "),gs=n(Fn,"CODE",{});var uc=o(gs);ni=p(uc,"DataLoader"),uc.forEach(a),oi=p(Fn," para tus datasets de entrenamiento y de prueba para poder iterar sobre batches de datos:"),Fn.forEach(a),Hr=d(e),f(Da.$$.fragment,e),Rr=d(e),lt=n(e,"P",{});var fc=o(lt);li=p(fc,"Carga tu modelo con el n\xFAmero de labels previstas:"),fc.forEach(a),Br=d(e),f(xa.$$.fragment,e),Kr=d(e),Q=n(e,"H3",{class:!0});var On=o(Q);qe=n(On,"A",{id:!0,class:!0,href:!0});var hc=o(qe);_s=n(hc,"SPAN",{});var gc=o(_s);f(Sa.$$.fragment,gc),gc.forEach(a),hc.forEach(a),ii=d(On),vs=n(On,"SPAN",{});var _c=o(vs);pi=p(_c,"Optimiza y progrma el learning rate"),_c.forEach(a),On.forEach(a),Ur=d(e),Ae=n(e,"P",{});var Nn=o(Ae);ci=p(Nn,"Crea un optimizador y el learning rate para aplicar fine-tuning al modelo. Vamos a utilizar el optimizador "),Fa=n(Nn,"A",{href:!0,rel:!0});var vc=o(Fa);$s=n(vc,"CODE",{});var $c=o($s);di=p($c,"AdamW"),$c.forEach(a),vc.forEach(a),mi=p(Nn," de PyTorch:"),Nn.forEach(a),Wr=d(e),f(Oa.$$.fragment,e),Gr=d(e),Pe=n(e,"P",{});var Ln=o(Pe);ui=p(Ln,"Crea el learning rate desde el "),bs=n(Ln,"CODE",{});var bc=o(bs);fi=p(bc,"Trainer"),bc.forEach(a),hi=p(Ln,":"),Ln.forEach(a),Yr=d(e),f(Na.$$.fragment,e),Vr=d(e),Te=n(e,"P",{});var In=o(Te);gi=p(In,"Por \xFAltimo, especifica el "),js=n(In,"CODE",{});var jc=o(js);_i=p(jc,"device"),jc.forEach(a),vi=p(In," o entorno de ejecuci\xF3n para utilizar una GPU si tienes acceso a una. De lo contrario, el entrenamiento en una CPU puede llevarte varias horas en lugar de un par de minutos."),In.forEach(a),Jr=d(e),f(La.$$.fragment,e),Xr=d(e),f(ze.$$.fragment,e),Zr=d(e),it=n(e,"P",{});var wc=o(it);$i=p(wc,"Genial, \xA1ahora estamos listos entrenar! \u{1F973}"),wc.forEach(a),Qr=d(e),ee=n(e,"H3",{class:!0});var Mn=o(ee);Ce=n(Mn,"A",{id:!0,class:!0,href:!0});var yc=o(Ce);ws=n(yc,"SPAN",{});var Ec=o(ws);f(Ia.$$.fragment,Ec),Ec.forEach(a),yc.forEach(a),bi=d(Mn),ys=n(Mn,"SPAN",{});var kc=o(ys);ji=p(kc,"Ciclo de entrenamiento"),kc.forEach(a),Mn.forEach(a),en=d(e),De=n(e,"P",{});var Hn=o(De);wi=p(Hn,"Para hacer un seguimiento al progreso del entrenamiento, utiliza la librer\xEDa "),Ma=n(Hn,"A",{href:!0,rel:!0});var qc=o(Ma);yi=p(qc,"tqdm"),qc.forEach(a),Ei=p(Hn," para a\xF1adir una barra de progreso sobre el n\xFAmero de pasos de entrenamiento:"),Hn.forEach(a),an=d(e),f(Ha.$$.fragment,e),tn=d(e),ae=n(e,"H3",{class:!0});var Rn=o(ae);xe=n(Rn,"A",{id:!0,class:!0,href:!0});var Ac=o(xe);Es=n(Ac,"SPAN",{});var Pc=o(Es);f(Ra.$$.fragment,Pc),Pc.forEach(a),Ac.forEach(a),ki=d(Rn),ks=n(Rn,"SPAN",{});var Tc=o(ks);qi=p(Tc,"M\xE9tricas"),Tc.forEach(a),Rn.forEach(a),sn=d(e),R=n(e,"P",{});var $t=o(R);Ai=p($t,"De la misma manera que necesitas a\xF1adir una funci\xF3n de evaluaci\xF3n al "),qs=n($t,"CODE",{});var zc=o(qs);Pi=p(zc,"Trainer"),zc.forEach(a),Ti=p($t,", necesitas hacer lo mismo cuando escribas tu propio ciclo de entrenamiento. Pero en lugar de calcular y reportar la m\xE9trica al final de cada \xE9poca, esta vez acumular\xE1s todos los batches con "),Ba=n($t,"A",{href:!0,rel:!0});var Cc=o(Ba);As=n(Cc,"CODE",{});var Dc=o(As);zi=p(Dc,"add_batch"),Dc.forEach(a),Cc.forEach(a),Ci=p($t," y calcular\xE1s la m\xE9trica al final."),$t.forEach(a),rn=d(e),f(Ka.$$.fragment,e),nn=d(e),pt=n(e,"A",{id:!0}),o(pt).forEach(a),on=d(e),te=n(e,"H2",{class:!0});var Bn=o(te);Se=n(Bn,"A",{id:!0,class:!0,href:!0});var xc=o(Se);Ps=n(xc,"SPAN",{});var Sc=o(Ps);f(Ua.$$.fragment,Sc),Sc.forEach(a),xc.forEach(a),Di=d(Bn),Ts=n(Bn,"SPAN",{});var Fc=o(Ts);xi=p(Fc,"Recursos adicionales"),Fc.forEach(a),Bn.forEach(a),ln=d(e),ct=n(e,"P",{});var Oc=o(ct);Si=p(Oc,"Para m\xE1s ejemplos de fine-tuning consulta:"),Oc.forEach(a),pn=d(e),Fe=n(e,"UL",{});var Kn=o(Fe);zs=n(Kn,"LI",{});var Nc=o(zs);dt=n(Nc,"P",{});var Hi=o(dt);Wa=n(Hi,"A",{href:!0,rel:!0});var Lc=o(Wa);Fi=p(Lc,"\u{1F917} Transformers Examples"),Lc.forEach(a),Oi=p(Hi,` incluye scripts
para entrenar tareas comunes de NLP en PyTorch y TensorFlow.`),Hi.forEach(a),Nc.forEach(a),Ni=d(Kn),Cs=n(Kn,"LI",{});var Ic=o(Cs);mt=n(Ic,"P",{});var Ri=o(mt);ut=n(Ri,"A",{href:!0});var Mc=o(ut);Li=p(Mc,"\u{1F917} Transformers Notebooks"),Mc.forEach(a),Ii=p(Ri," contiene varios notebooks sobre c\xF3mo aplicar fine-tuning a un modelo para tareas espec\xEDficas en PyTorch y TensorFlow."),Ri.forEach(a),Ic.forEach(a),Kn.forEach(a),this.h()},h(){m($,"name","hf:doc:metadata"),m($,"content",JSON.stringify(Xc)),m(w,"id","finetuning-a-un-modelo-preentrenado"),m(w,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(w,"href","#finetuning-a-un-modelo-preentrenado"),m(b,"class","relative group"),m(Va,"id","data-processing"),m(re,"id","prepara-un-dataset"),m(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(re,"href","#prepara-un-dataset"),m(B,"class","relative group"),m(Be,"href","https://huggingface.co/datasets/yelp_review_full"),m(Be,"rel","nofollow"),m(Ue,"href","https://huggingface.co/docs/datasets/process.html#map"),m(Ue,"rel","nofollow"),m(Za,"id","trainer"),m(le,"id","finetuning-con-trainer"),m(le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(le,"href","#finetuning-con-trainer"),m(K,"class","relative group"),m(Je,"href","https://huggingface.co/datasets/yelp_review_full#data-fields"),m(Je,"rel","nofollow"),m(ce,"id","hiperparmetros-de-entrenamiento"),m(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ce,"href","#hiperparmetros-de-entrenamiento"),m(U,"class","relative group"),m(Qe,"href","https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments"),m(Qe,"rel","nofollow"),m(de,"id","mtricas"),m(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(de,"href","#mtricas"),m(W,"class","relative group"),m(ta,"href","https://huggingface.co/metrics/accuracy"),m(ta,"rel","nofollow"),m(sa,"href","https://huggingface.co/docs/datasets/metrics.html"),m(sa,"rel","nofollow"),m(ue,"id","trainer"),m(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ue,"href","#trainer"),m(G,"class","relative group"),m(at,"id","keras"),m(ge,"id","finetuning-con-keras"),m(ge,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ge,"href","#finetuning-con-keras"),m(Y,"class","relative group"),m(_e,"id","convierte-el-dataset-al-formato-de-tensorflow"),m(_e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(_e,"href","#convierte-el-dataset-al-formato-de-tensorflow"),m(V,"class","relative group"),m(fa,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.to_tf_dataset"),m(fa,"rel","nofollow"),m($e,"id","compila-y-ajusta"),m($e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m($e,"href","#compila-y-ajusta"),m(J,"class","relative group"),m(va,"href","https://keras.io/api/models/model_training_apis/"),m(va,"rel","nofollow"),m(rt,"id","pytorch_native"),m(je,"id","finetune-en-pytorch-nativo"),m(je,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(je,"href","#finetune-en-pytorch-nativo"),m(X,"class","relative group"),m(Ee,"id","dataloader"),m(Ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Ee,"href","#dataloader"),m(Z,"class","relative group"),m(qe,"id","optimiza-y-progrma-el-learning-rate"),m(qe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(qe,"href","#optimiza-y-progrma-el-learning-rate"),m(Q,"class","relative group"),m(Fa,"href","https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html"),m(Fa,"rel","nofollow"),m(Ce,"id","ciclo-de-entrenamiento"),m(Ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Ce,"href","#ciclo-de-entrenamiento"),m(ee,"class","relative group"),m(Ma,"href","https://tqdm.github.io/"),m(Ma,"rel","nofollow"),m(xe,"id","mtricas"),m(xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(xe,"href","#mtricas"),m(ae,"class","relative group"),m(Ba,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=add_batch#datasets.Metric.add_batch"),m(Ba,"rel","nofollow"),m(pt,"id","additional-resources"),m(Se,"id","recursos-adicionales"),m(Se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Se,"href","#recursos-adicionales"),m(te,"class","relative group"),m(Wa,"href","https://github.com/huggingface/transformers/tree/main/examples"),m(Wa,"rel","nofollow"),m(ut,"href","notebooks")},m(e,s){t(document.head,$),l(e,E,s),l(e,b,s),t(b,w),t(w,P),h(y,P,null),t(b,F),t(b,T),t(T,k),l(e,q,s),h(C,e,s),l(e,Ie,s),l(e,Ya,s),t(Ya,Wn),l(e,Ss,s),l(e,N,s),t(N,Me),t(Me,Gn),t(Me,bt),t(bt,Yn),t(Me,Vn),t(N,Jn),t(N,jt),t(jt,Xn),t(N,Zn),t(N,wt),t(wt,Qn),l(e,Fs,s),l(e,Va,s),l(e,Os,s),l(e,B,s),t(B,re),t(re,yt),h(He,yt,null),t(B,eo),t(B,Et),t(Et,ao),l(e,Ns,s),h(Re,e,s),l(e,Ls,s),l(e,Ja,s),t(Ja,to),l(e,Is,s),l(e,ne,s),t(ne,so),t(ne,Be),t(Be,ro),t(ne,no),l(e,Ms,s),h(Ke,e,s),l(e,Hs,s),l(e,oe,s),t(oe,oo),t(oe,Ue),t(Ue,kt),t(kt,lo),t(oe,io),l(e,Rs,s),h(We,e,s),l(e,Bs,s),l(e,Xa,s),t(Xa,po),l(e,Ks,s),h(Ge,e,s),l(e,Us,s),l(e,Za,s),l(e,Ws,s),l(e,K,s),t(K,le),t(le,qt),h(Ye,qt,null),t(K,co),t(K,Qa),t(Qa,mo),t(Qa,At),t(At,uo),l(e,Gs,s),h(Ve,e,s),l(e,Ys,s),l(e,L,s),t(L,fo),t(L,Pt),t(Pt,ho),t(L,go),t(L,Tt),t(Tt,_o),t(L,vo),l(e,Vs,s),l(e,ie,s),t(ie,$o),t(ie,Je),t(Je,bo),t(ie,jo),l(e,Js,s),h(Xe,e,s),l(e,Xs,s),h(pe,e,s),l(e,Zs,s),l(e,U,s),t(U,ce),t(ce,zt),h(Ze,zt,null),t(U,wo),t(U,Ct),t(Ct,yo),l(e,Qs,s),l(e,I,s),t(I,Eo),t(I,Dt),t(Dt,ko),t(I,qo),t(I,Qe),t(Qe,Ao),t(I,Po),l(e,er,s),l(e,et,s),t(et,To),l(e,ar,s),h(ea,e,s),l(e,tr,s),l(e,W,s),t(W,de),t(de,xt),h(aa,xt,null),t(W,zo),t(W,St),t(St,Co),l(e,sr,s),l(e,A,s),t(A,Do),t(A,Ft),t(Ft,xo),t(A,So),t(A,Ot),t(Ot,Fo),t(A,Oo),t(A,ta),t(ta,Nt),t(Nt,No),t(A,Lo),t(A,Lt),t(Lt,Io),t(A,Mo),t(A,sa),t(sa,Ho),t(A,Ro),l(e,rr,s),h(ra,e,s),l(e,nr,s),l(e,D,s),t(D,Bo),t(D,It),t(It,Ko),t(D,Uo),t(D,Mt),t(Mt,Wo),t(D,Go),t(D,Ht),t(Ht,Yo),t(D,Vo),l(e,or,s),h(na,e,s),l(e,lr,s),l(e,me,s),t(me,Jo),t(me,Rt),t(Rt,Xo),t(me,Zo),l(e,ir,s),h(oa,e,s),l(e,pr,s),l(e,G,s),t(G,ue),t(ue,Bt),h(la,Bt,null),t(G,Qo),t(G,Kt),t(Kt,el),l(e,cr,s),l(e,fe,s),t(fe,al),t(fe,Ut),t(Ut,tl),t(fe,sl),l(e,dr,s),h(ia,e,s),l(e,mr,s),l(e,he,s),t(he,rl),t(he,Wt),t(Wt,nl),t(he,ol),l(e,ur,s),h(pa,e,s),l(e,fr,s),l(e,at,s),l(e,hr,s),l(e,Y,s),t(Y,ge),t(ge,Gt),h(ca,Gt,null),t(Y,ll),t(Y,Yt),t(Yt,il),l(e,gr,s),h(da,e,s),l(e,_r,s),l(e,tt,s),t(tt,pl),l(e,vr,s),l(e,V,s),t(V,_e),t(_e,Vt),h(ma,Vt,null),t(V,cl),t(V,Jt),t(Jt,dl),l(e,$r,s),l(e,M,s),t(M,ml),t(M,Xt),t(Xt,ul),t(M,fl),t(M,Zt),t(Zt,hl),t(M,gl),l(e,br,s),h(ua,e,s),l(e,jr,s),h(ve,e,s),l(e,wr,s),l(e,x,s),t(x,_l),t(x,fa),t(fa,Qt),t(Qt,vl),t(x,$l),t(x,es),t(es,bl),t(x,jl),t(x,as),t(as,wl),t(x,yl),l(e,yr,s),h(ha,e,s),l(e,Er,s),l(e,J,s),t(J,$e),t($e,ts),h(ga,ts,null),t(J,El),t(J,ss),t(ss,kl),l(e,kr,s),l(e,st,s),t(st,ql),l(e,qr,s),h(_a,e,s),l(e,Ar,s),l(e,be,s),t(be,Al),t(be,va),t(va,rs),t(rs,Pl),t(be,Tl),l(e,Pr,s),h($a,e,s),l(e,Tr,s),l(e,rt,s),l(e,zr,s),l(e,X,s),t(X,je),t(je,ns),h(ba,ns,null),t(X,zl),t(X,os),t(os,Cl),l(e,Cr,s),h(ja,e,s),l(e,Dr,s),l(e,we,s),t(we,Dl),t(we,ls),t(ls,xl),t(we,Sl),l(e,xr,s),l(e,nt,s),t(nt,Fl),l(e,Sr,s),h(wa,e,s),l(e,Fr,s),l(e,ye,s),t(ye,Ol),t(ye,is),t(is,Nl),t(ye,Ll),l(e,Or,s),l(e,H,s),t(H,ya),t(ya,Ea),t(Ea,Il),t(Ea,ps),t(ps,Ml),t(Ea,Hl),t(ya,Rl),h(ka,ya,null),t(H,Bl),t(H,qa),t(qa,O),t(O,Kl),t(O,cs),t(cs,Ul),t(O,Wl),t(O,ds),t(ds,Gl),t(O,Yl),t(O,ms),t(ms,Vl),t(O,Jl),t(qa,Xl),h(Aa,qa,null),t(H,Zl),t(H,Pa),t(Pa,us),t(us,Ql),t(Pa,ei),h(Ta,Pa,null),l(e,Nr,s),l(e,ot,s),t(ot,ai),l(e,Lr,s),h(za,e,s),l(e,Ir,s),l(e,Z,s),t(Z,Ee),t(Ee,fs),h(Ca,fs,null),t(Z,ti),t(Z,hs),t(hs,si),l(e,Mr,s),l(e,ke,s),t(ke,ri),t(ke,gs),t(gs,ni),t(ke,oi),l(e,Hr,s),h(Da,e,s),l(e,Rr,s),l(e,lt,s),t(lt,li),l(e,Br,s),h(xa,e,s),l(e,Kr,s),l(e,Q,s),t(Q,qe),t(qe,_s),h(Sa,_s,null),t(Q,ii),t(Q,vs),t(vs,pi),l(e,Ur,s),l(e,Ae,s),t(Ae,ci),t(Ae,Fa),t(Fa,$s),t($s,di),t(Ae,mi),l(e,Wr,s),h(Oa,e,s),l(e,Gr,s),l(e,Pe,s),t(Pe,ui),t(Pe,bs),t(bs,fi),t(Pe,hi),l(e,Yr,s),h(Na,e,s),l(e,Vr,s),l(e,Te,s),t(Te,gi),t(Te,js),t(js,_i),t(Te,vi),l(e,Jr,s),h(La,e,s),l(e,Xr,s),h(ze,e,s),l(e,Zr,s),l(e,it,s),t(it,$i),l(e,Qr,s),l(e,ee,s),t(ee,Ce),t(Ce,ws),h(Ia,ws,null),t(ee,bi),t(ee,ys),t(ys,ji),l(e,en,s),l(e,De,s),t(De,wi),t(De,Ma),t(Ma,yi),t(De,Ei),l(e,an,s),h(Ha,e,s),l(e,tn,s),l(e,ae,s),t(ae,xe),t(xe,Es),h(Ra,Es,null),t(ae,ki),t(ae,ks),t(ks,qi),l(e,sn,s),l(e,R,s),t(R,Ai),t(R,qs),t(qs,Pi),t(R,Ti),t(R,Ba),t(Ba,As),t(As,zi),t(R,Ci),l(e,rn,s),h(Ka,e,s),l(e,nn,s),l(e,pt,s),l(e,on,s),l(e,te,s),t(te,Se),t(Se,Ps),h(Ua,Ps,null),t(te,Di),t(te,Ts),t(Ts,xi),l(e,ln,s),l(e,ct,s),t(ct,Si),l(e,pn,s),l(e,Fe,s),t(Fe,zs),t(zs,dt),t(dt,Wa),t(Wa,Fi),t(dt,Oi),t(Fe,Ni),t(Fe,Cs),t(Cs,mt),t(mt,ut),t(ut,Li),t(mt,Ii),cn=!0},p(e,[s]){const Ga={};s&2&&(Ga.$$scope={dirty:s,ctx:e}),pe.$set(Ga);const Ds={};s&2&&(Ds.$$scope={dirty:s,ctx:e}),ve.$set(Ds);const xs={};s&2&&(xs.$$scope={dirty:s,ctx:e}),ze.$set(xs)},i(e){cn||(g(y.$$.fragment,e),g(C.$$.fragment,e),g(He.$$.fragment,e),g(Re.$$.fragment,e),g(Ke.$$.fragment,e),g(We.$$.fragment,e),g(Ge.$$.fragment,e),g(Ye.$$.fragment,e),g(Ve.$$.fragment,e),g(Xe.$$.fragment,e),g(pe.$$.fragment,e),g(Ze.$$.fragment,e),g(ea.$$.fragment,e),g(aa.$$.fragment,e),g(ra.$$.fragment,e),g(na.$$.fragment,e),g(oa.$$.fragment,e),g(la.$$.fragment,e),g(ia.$$.fragment,e),g(pa.$$.fragment,e),g(ca.$$.fragment,e),g(da.$$.fragment,e),g(ma.$$.fragment,e),g(ua.$$.fragment,e),g(ve.$$.fragment,e),g(ha.$$.fragment,e),g(ga.$$.fragment,e),g(_a.$$.fragment,e),g($a.$$.fragment,e),g(ba.$$.fragment,e),g(ja.$$.fragment,e),g(wa.$$.fragment,e),g(ka.$$.fragment,e),g(Aa.$$.fragment,e),g(Ta.$$.fragment,e),g(za.$$.fragment,e),g(Ca.$$.fragment,e),g(Da.$$.fragment,e),g(xa.$$.fragment,e),g(Sa.$$.fragment,e),g(Oa.$$.fragment,e),g(Na.$$.fragment,e),g(La.$$.fragment,e),g(ze.$$.fragment,e),g(Ia.$$.fragment,e),g(Ha.$$.fragment,e),g(Ra.$$.fragment,e),g(Ka.$$.fragment,e),g(Ua.$$.fragment,e),cn=!0)},o(e){_(y.$$.fragment,e),_(C.$$.fragment,e),_(He.$$.fragment,e),_(Re.$$.fragment,e),_(Ke.$$.fragment,e),_(We.$$.fragment,e),_(Ge.$$.fragment,e),_(Ye.$$.fragment,e),_(Ve.$$.fragment,e),_(Xe.$$.fragment,e),_(pe.$$.fragment,e),_(Ze.$$.fragment,e),_(ea.$$.fragment,e),_(aa.$$.fragment,e),_(ra.$$.fragment,e),_(na.$$.fragment,e),_(oa.$$.fragment,e),_(la.$$.fragment,e),_(ia.$$.fragment,e),_(pa.$$.fragment,e),_(ca.$$.fragment,e),_(da.$$.fragment,e),_(ma.$$.fragment,e),_(ua.$$.fragment,e),_(ve.$$.fragment,e),_(ha.$$.fragment,e),_(ga.$$.fragment,e),_(_a.$$.fragment,e),_($a.$$.fragment,e),_(ba.$$.fragment,e),_(ja.$$.fragment,e),_(wa.$$.fragment,e),_(ka.$$.fragment,e),_(Aa.$$.fragment,e),_(Ta.$$.fragment,e),_(za.$$.fragment,e),_(Ca.$$.fragment,e),_(Da.$$.fragment,e),_(xa.$$.fragment,e),_(Sa.$$.fragment,e),_(Oa.$$.fragment,e),_(Na.$$.fragment,e),_(La.$$.fragment,e),_(ze.$$.fragment,e),_(Ia.$$.fragment,e),_(Ha.$$.fragment,e),_(Ra.$$.fragment,e),_(Ka.$$.fragment,e),_(Ua.$$.fragment,e),cn=!1},d(e){a($),e&&a(E),e&&a(b),v(y),e&&a(q),v(C,e),e&&a(Ie),e&&a(Ya),e&&a(Ss),e&&a(N),e&&a(Fs),e&&a(Va),e&&a(Os),e&&a(B),v(He),e&&a(Ns),v(Re,e),e&&a(Ls),e&&a(Ja),e&&a(Is),e&&a(ne),e&&a(Ms),v(Ke,e),e&&a(Hs),e&&a(oe),e&&a(Rs),v(We,e),e&&a(Bs),e&&a(Xa),e&&a(Ks),v(Ge,e),e&&a(Us),e&&a(Za),e&&a(Ws),e&&a(K),v(Ye),e&&a(Gs),v(Ve,e),e&&a(Ys),e&&a(L),e&&a(Vs),e&&a(ie),e&&a(Js),v(Xe,e),e&&a(Xs),v(pe,e),e&&a(Zs),e&&a(U),v(Ze),e&&a(Qs),e&&a(I),e&&a(er),e&&a(et),e&&a(ar),v(ea,e),e&&a(tr),e&&a(W),v(aa),e&&a(sr),e&&a(A),e&&a(rr),v(ra,e),e&&a(nr),e&&a(D),e&&a(or),v(na,e),e&&a(lr),e&&a(me),e&&a(ir),v(oa,e),e&&a(pr),e&&a(G),v(la),e&&a(cr),e&&a(fe),e&&a(dr),v(ia,e),e&&a(mr),e&&a(he),e&&a(ur),v(pa,e),e&&a(fr),e&&a(at),e&&a(hr),e&&a(Y),v(ca),e&&a(gr),v(da,e),e&&a(_r),e&&a(tt),e&&a(vr),e&&a(V),v(ma),e&&a($r),e&&a(M),e&&a(br),v(ua,e),e&&a(jr),v(ve,e),e&&a(wr),e&&a(x),e&&a(yr),v(ha,e),e&&a(Er),e&&a(J),v(ga),e&&a(kr),e&&a(st),e&&a(qr),v(_a,e),e&&a(Ar),e&&a(be),e&&a(Pr),v($a,e),e&&a(Tr),e&&a(rt),e&&a(zr),e&&a(X),v(ba),e&&a(Cr),v(ja,e),e&&a(Dr),e&&a(we),e&&a(xr),e&&a(nt),e&&a(Sr),v(wa,e),e&&a(Fr),e&&a(ye),e&&a(Or),e&&a(H),v(ka),v(Aa),v(Ta),e&&a(Nr),e&&a(ot),e&&a(Lr),v(za,e),e&&a(Ir),e&&a(Z),v(Ca),e&&a(Mr),e&&a(ke),e&&a(Hr),v(Da,e),e&&a(Rr),e&&a(lt),e&&a(Br),v(xa,e),e&&a(Kr),e&&a(Q),v(Sa),e&&a(Ur),e&&a(Ae),e&&a(Wr),v(Oa,e),e&&a(Gr),e&&a(Pe),e&&a(Yr),v(Na,e),e&&a(Vr),e&&a(Te),e&&a(Jr),v(La,e),e&&a(Xr),v(ze,e),e&&a(Zr),e&&a(it),e&&a(Qr),e&&a(ee),v(Ia),e&&a(en),e&&a(De),e&&a(an),v(Ha,e),e&&a(tn),e&&a(ae),v(Ra),e&&a(sn),e&&a(R),e&&a(rn),v(Ka,e),e&&a(nn),e&&a(pt),e&&a(on),e&&a(te),v(Ua),e&&a(ln),e&&a(ct),e&&a(pn),e&&a(Fe)}}}const Xc={local:"finetuning-a-un-modelo-preentrenado",sections:[{local:"prepara-un-dataset",title:"Prepara un dataset"},{local:"finetuning-con-trainer",sections:[{local:"hiperparmetros-de-entrenamiento",title:"Hiperpar\xE1metros de entrenamiento"},{local:"mtricas",title:"M\xE9tricas"},{local:"trainer",title:"Trainer"}],title:"Fine-tuning con `Trainer`"},{local:"finetuning-con-keras",sections:[{local:"convierte-el-dataset-al-formato-de-tensorflow",title:"Convierte el dataset al formato de TensorFlow"},{local:"compila-y-ajusta",title:"Compila y ajusta"}],title:"Fine-tuning con Keras"},{local:"finetune-en-pytorch-nativo",sections:[{local:"dataloader",title:"DataLoader"},{local:"optimiza-y-progrma-el-learning-rate",title:"Optimiza y progrma el learning rate"},{local:"ciclo-de-entrenamiento",title:"Ciclo de entrenamiento"},{local:"mtricas",title:"M\xE9tricas"}],title:"Fine-tune en PyTorch nativo"},{local:"recursos-adicionales",title:"Recursos adicionales"}],title:"Fine-tuning a un modelo pre-entrenado"};function Zc(se){return Uc(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class nd extends Hc{constructor($){super();Rc(this,$,Zc,Jc,Bc,{})}}export{nd as default,Xc as metadata};
