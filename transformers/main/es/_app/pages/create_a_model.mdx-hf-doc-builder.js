import{S as Ki,i as Yi,s as Zi,e as r,k as f,w as z,t,M as ec,c as n,d as s,m as _,a as l,x as w,h as o,b as q,G as a,g as c,y,q as C,o as D,B as x,v as ac,L as ho}from"../chunks/vendor-hf-doc-builder.js";import{T as _o}from"../chunks/Tip-hf-doc-builder.js";import{I as ba}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as R}from"../chunks/CodeBlock-hf-doc-builder.js";import{F as Gi,M as go}from"../chunks/Markdown-hf-doc-builder.js";import"../chunks/IconTensorflow-hf-doc-builder.js";function sc(N){let p;return{c(){p=t("Tambi\xE9n puedes guardar los archivos de configuraci\xF3n como un diccionario; o incluso guardar solo la diferencia entre tu archivo personalizado y la configuraci\xF3n por defecto. Consulta la [documentaci\xF3n sobre configuraci\xF3n](main_classes/configuration) para ver m\xE1s detalles.")},l($){p=o($,"Tambi\xE9n puedes guardar los archivos de configuraci\xF3n como un diccionario; o incluso guardar solo la diferencia entre tu archivo personalizado y la configuraci\xF3n por defecto. Consulta la [documentaci\xF3n sobre configuraci\xF3n](main_classes/configuration) para ver m\xE1s detalles.")},m($,u){c($,p,u)},d($){$&&s(p)}}}function tc(N){let p,$,u,h,b,v,k,F,g,L,j,S,P,M,B,T,A,U,I,O,V;return h=new R({props:{code:`from transformers import DistilBertModel

my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")
model = DistilBertModel(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;./your_model_save_path/my_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertModel(my_config)`}}),B=new R({props:{code:'model = DistilBertModel.from_pretrained("distilbert-base-uncased")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)'}}),O=new R({props:{code:'model = DistilBertModel.from_pretrained("distilbert-base-uncased", config=my_config)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, config=my_config)'}}),{c(){p=r("p"),$=t("Carga los atributos de tu configuraci\xF3n personalizada en el modelo de la siguiente forma:"),u=f(),z(h.$$.fragment),b=f(),v=r("p"),k=t("Esto crea un modelo con valores aleatorios, en lugar de crearlo con los pesos del preentramiento, por lo que no ser\xE1s capaz de usar este modelo para nada \xFAtil hasta que no lo entrenes. El entrenamiento es un proceso costoso, tanto en cuesti\xF3n de recursos como de tiempo, por lo que generalmente es mejor usar un modelo preentrenado para obtener mejores resultados m\xE1s r\xE1pido, consumiendo una fracci\xF3n de los recursos que un entrenamiento completo hubiera requerido."),F=f(),g=r("p"),L=t("Puedes crear un modelo preentrenado con "),j=r("code"),S=t("from_pretrained()"),P=t(":"),M=f(),z(B.$$.fragment),T=f(),A=r("p"),U=t("Cuando cargues tus pesos del preentramiento, el modelo por defecto se carga autom\xE1ticamente si nos lo proporciona \u{1F917} Transformers. Sin embargo, siempre puedes reemplazar (todos o algunos de) los atributos del modelo por defecto por los tuyos:"),I=f(),z(O.$$.fragment)},l(d){p=n(d,"P",{});var m=l(p);$=o(m,"Carga los atributos de tu configuraci\xF3n personalizada en el modelo de la siguiente forma:"),m.forEach(s),u=_(d),w(h.$$.fragment,d),b=_(d),v=n(d,"P",{});var E=l(v);k=o(E,"Esto crea un modelo con valores aleatorios, en lugar de crearlo con los pesos del preentramiento, por lo que no ser\xE1s capaz de usar este modelo para nada \xFAtil hasta que no lo entrenes. El entrenamiento es un proceso costoso, tanto en cuesti\xF3n de recursos como de tiempo, por lo que generalmente es mejor usar un modelo preentrenado para obtener mejores resultados m\xE1s r\xE1pido, consumiendo una fracci\xF3n de los recursos que un entrenamiento completo hubiera requerido."),E.forEach(s),F=_(d),g=n(d,"P",{});var H=l(g);L=o(H,"Puedes crear un modelo preentrenado con "),j=n(H,"CODE",{});var W=l(j);S=o(W,"from_pretrained()"),W.forEach(s),P=o(H,":"),H.forEach(s),M=_(d),w(B.$$.fragment,d),T=_(d),A=n(d,"P",{});var K=l(A);U=o(K,"Cuando cargues tus pesos del preentramiento, el modelo por defecto se carga autom\xE1ticamente si nos lo proporciona \u{1F917} Transformers. Sin embargo, siempre puedes reemplazar (todos o algunos de) los atributos del modelo por defecto por los tuyos:"),K.forEach(s),I=_(d),w(O.$$.fragment,d)},m(d,m){c(d,p,m),a(p,$),c(d,u,m),y(h,d,m),c(d,b,m),c(d,v,m),a(v,k),c(d,F,m),c(d,g,m),a(g,L),a(g,j),a(j,S),a(g,P),c(d,M,m),y(B,d,m),c(d,T,m),c(d,A,m),a(A,U),c(d,I,m),y(O,d,m),V=!0},p:ho,i(d){V||(C(h.$$.fragment,d),C(B.$$.fragment,d),C(O.$$.fragment,d),V=!0)},o(d){D(h.$$.fragment,d),D(B.$$.fragment,d),D(O.$$.fragment,d),V=!1},d(d){d&&s(p),d&&s(u),x(h,d),d&&s(b),d&&s(v),d&&s(F),d&&s(g),d&&s(M),x(B,d),d&&s(T),d&&s(A),d&&s(I),x(O,d)}}}function oc(N){let p,$;return p=new go({props:{$$slots:{default:[tc]},$$scope:{ctx:N}}}),{c(){z(p.$$.fragment)},l(u){w(p.$$.fragment,u)},m(u,h){y(p,u,h),$=!0},p(u,h){const b={};h&2&&(b.$$scope={dirty:h,ctx:u}),p.$set(b)},i(u){$||(C(p.$$.fragment,u),$=!0)},o(u){D(p.$$.fragment,u),$=!1},d(u){x(p,u)}}}function rc(N){let p,$,u,h,b,v,k,F,g,L,j,S,P,M,B,T,A,U,I,O,V;return h=new R({props:{code:`from transformers import TFDistilBertModel

my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")
tf_model = TFDistilBertModel(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFDistilBertModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;./your_model_save_path/my_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertModel(my_config)`}}),B=new R({props:{code:'tf_model = TFDistilBertModel.from_pretrained("distilbert-base-uncased")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)'}}),O=new R({props:{code:'tf_model = TFDistilBertModel.from_pretrained("distilbert-base-uncased", config=my_config)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertModel.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, config=my_config)'}}),{c(){p=r("p"),$=t("Carga los atributos de tu configuraci\xF3n personalizada en el modelo de la siguiente forma:"),u=f(),z(h.$$.fragment),b=f(),v=r("p"),k=t("Esto crea un modelo con valores aleatorios, en lugar de crearlo con los pesos del preentramiento, por lo que no ser\xE1s capaz de usar este modelo para nada \xFAtil hasta que no lo entrenes. El entrenamiento es un proceso costoso, tanto en cuesti\xF3n de recursos como de tiempo, por lo que generalmente es mejor usar un modelo preentrenado para obtener mejores resultados m\xE1s r\xE1pido, consumiendo solo una fracci\xF3n de los recursos que un entrenamiento completo hubiera requerido."),F=f(),g=r("p"),L=t("Puedes crear un modelo preentrenado con "),j=r("code"),S=t("from_pretrained()"),P=t(":"),M=f(),z(B.$$.fragment),T=f(),A=r("p"),U=t("Cuando cargues tus pesos del preentramiento, el modelo por defecto se carga autom\xE1ticamente si este nos lo proporciona \u{1F917} Transformers. Sin embargo, siempre puedes reemplazar (todos o algunos de) los atributos del modelo por defecto por los tuyos:"),I=f(),z(O.$$.fragment)},l(d){p=n(d,"P",{});var m=l(p);$=o(m,"Carga los atributos de tu configuraci\xF3n personalizada en el modelo de la siguiente forma:"),m.forEach(s),u=_(d),w(h.$$.fragment,d),b=_(d),v=n(d,"P",{});var E=l(v);k=o(E,"Esto crea un modelo con valores aleatorios, en lugar de crearlo con los pesos del preentramiento, por lo que no ser\xE1s capaz de usar este modelo para nada \xFAtil hasta que no lo entrenes. El entrenamiento es un proceso costoso, tanto en cuesti\xF3n de recursos como de tiempo, por lo que generalmente es mejor usar un modelo preentrenado para obtener mejores resultados m\xE1s r\xE1pido, consumiendo solo una fracci\xF3n de los recursos que un entrenamiento completo hubiera requerido."),E.forEach(s),F=_(d),g=n(d,"P",{});var H=l(g);L=o(H,"Puedes crear un modelo preentrenado con "),j=n(H,"CODE",{});var W=l(j);S=o(W,"from_pretrained()"),W.forEach(s),P=o(H,":"),H.forEach(s),M=_(d),w(B.$$.fragment,d),T=_(d),A=n(d,"P",{});var K=l(A);U=o(K,"Cuando cargues tus pesos del preentramiento, el modelo por defecto se carga autom\xE1ticamente si este nos lo proporciona \u{1F917} Transformers. Sin embargo, siempre puedes reemplazar (todos o algunos de) los atributos del modelo por defecto por los tuyos:"),K.forEach(s),I=_(d),w(O.$$.fragment,d)},m(d,m){c(d,p,m),a(p,$),c(d,u,m),y(h,d,m),c(d,b,m),c(d,v,m),a(v,k),c(d,F,m),c(d,g,m),a(g,L),a(g,j),a(j,S),a(g,P),c(d,M,m),y(B,d,m),c(d,T,m),c(d,A,m),a(A,U),c(d,I,m),y(O,d,m),V=!0},p:ho,i(d){V||(C(h.$$.fragment,d),C(B.$$.fragment,d),C(O.$$.fragment,d),V=!0)},o(d){D(h.$$.fragment,d),D(B.$$.fragment,d),D(O.$$.fragment,d),V=!1},d(d){d&&s(p),d&&s(u),x(h,d),d&&s(b),d&&s(v),d&&s(F),d&&s(g),d&&s(M),x(B,d),d&&s(T),d&&s(A),d&&s(I),x(O,d)}}}function nc(N){let p,$;return p=new go({props:{$$slots:{default:[rc]},$$scope:{ctx:N}}}),{c(){z(p.$$.fragment)},l(u){w(p.$$.fragment,u)},m(u,h){y(p,u,h),$=!0},p(u,h){const b={};h&2&&(b.$$scope={dirty:h,ctx:u}),p.$set(b)},i(u){$||(C(p.$$.fragment,u),$=!0)},o(u){D(p.$$.fragment,u),$=!1},d(u){x(p,u)}}}function lc(N){let p,$,u,h,b,v,k,F,g,L,j,S,P,M,B,T,A,U,I,O,V,d;return k=new R({props:{code:`from transformers import DistilBertForSequenceClassification

model = DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),V=new R({props:{code:`from transformers import DistilBertForQuestionAnswering

model = DistilBertForQuestionAnswering.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span>model = DistilBertForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),{c(){p=r("p"),$=t("Por ejemplo,  "),u=r("code"),h=t("DistilBertForSequenceClassification"),b=t(" es un modelo DistilBERT base con una cabeza de clasificaci\xF3n de secuencias. La cabeza de clasificaci\xF3n de secuencias es una capa superior que precede a la recolecci\xF3n de las salidas."),v=f(),z(k.$$.fragment),F=f(),g=r("p"),L=t("Puedes reutilizar este punto de guardado o "),j=r("em"),S=t("checkpoint"),P=t(" para otra tarea f\xE1cilmente cambiando a una cabeza de un modelo diferente. Para una tarea de respuesta a preguntas, puedes usar la cabeza del modelo "),M=r("code"),B=t("DistilBertForQuestionAnswering"),T=t(". La cabeza de respuesta a preguntas es similar a la de clasificaci\xF3n de secuencias, excepto porque consta de una capa lineal delante de la salida de los "),A=r("em"),U=t("hidden states"),I=t("."),O=f(),z(V.$$.fragment)},l(m){p=n(m,"P",{});var E=l(p);$=o(E,"Por ejemplo,  "),u=n(E,"CODE",{});var H=l(u);h=o(H,"DistilBertForSequenceClassification"),H.forEach(s),b=o(E," es un modelo DistilBERT base con una cabeza de clasificaci\xF3n de secuencias. La cabeza de clasificaci\xF3n de secuencias es una capa superior que precede a la recolecci\xF3n de las salidas."),E.forEach(s),v=_(m),w(k.$$.fragment,m),F=_(m),g=n(m,"P",{});var W=l(g);L=o(W,"Puedes reutilizar este punto de guardado o "),j=n(W,"EM",{});var K=l(j);S=o(K,"checkpoint"),K.forEach(s),P=o(W," para otra tarea f\xE1cilmente cambiando a una cabeza de un modelo diferente. Para una tarea de respuesta a preguntas, puedes usar la cabeza del modelo "),M=n(W,"CODE",{});var te=l(M);B=o(te,"DistilBertForQuestionAnswering"),te.forEach(s),T=o(W,". La cabeza de respuesta a preguntas es similar a la de clasificaci\xF3n de secuencias, excepto porque consta de una capa lineal delante de la salida de los "),A=n(W,"EM",{});var fe=l(A);U=o(fe,"hidden states"),fe.forEach(s),I=o(W,"."),W.forEach(s),O=_(m),w(V.$$.fragment,m)},m(m,E){c(m,p,E),a(p,$),a(p,u),a(u,h),a(p,b),c(m,v,E),y(k,m,E),c(m,F,E),c(m,g,E),a(g,L),a(g,j),a(j,S),a(g,P),a(g,M),a(M,B),a(g,T),a(g,A),a(A,U),a(g,I),c(m,O,E),y(V,m,E),d=!0},p:ho,i(m){d||(C(k.$$.fragment,m),C(V.$$.fragment,m),d=!0)},o(m){D(k.$$.fragment,m),D(V.$$.fragment,m),d=!1},d(m){m&&s(p),m&&s(v),x(k,m),m&&s(F),m&&s(g),m&&s(O),x(V,m)}}}function ic(N){let p,$;return p=new go({props:{$$slots:{default:[lc]},$$scope:{ctx:N}}}),{c(){z(p.$$.fragment)},l(u){w(p.$$.fragment,u)},m(u,h){y(p,u,h),$=!0},p(u,h){const b={};h&2&&(b.$$scope={dirty:h,ctx:u}),p.$set(b)},i(u){$||(C(p.$$.fragment,u),$=!0)},o(u){D(p.$$.fragment,u),$=!1},d(u){x(p,u)}}}function cc(N){let p,$,u,h,b,v,k,F,g,L,j,S,P,M,B,T,A,U,I,O,V,d;return k=new R({props:{code:`from transformers import TFDistilBertForSequenceClassification

tf_model = TFDistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFDistilBertForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),V=new R({props:{code:`from transformers import TFDistilBertForQuestionAnswering

tf_model = TFDistilBertForQuestionAnswering.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFDistilBertForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),{c(){p=r("p"),$=t("Por ejemplo,  "),u=r("code"),h=t("TFDistilBertForSequenceClassification"),b=t(" es un modelo DistilBERT base con una cabeza de clasificaci\xF3n de secuencias. La cabeza de clasificaci\xF3n de secuencias es una capa superior que precede a la recolecci\xF3n de las salidas."),v=f(),z(k.$$.fragment),F=f(),g=r("p"),L=t("Puedes reutilizar este punto de guardado o "),j=r("em"),S=t("checkpoint"),P=t(" para otra tarea f\xE1cilmente cambiando a una cabeza de un modelo diferente. Para una tarea de respuesta a preguntas, puedes usar la cabeza del modelo "),M=r("code"),B=t("TFDistilBertForQuestionAnswering"),T=t(". La cabeza de respuesta a preguntas es similar a la de clasificaci\xF3n de secuencias, excepto porque consta de una capa lineal delante de la salida de los "),A=r("em"),U=t("hidden states"),I=t("."),O=f(),z(V.$$.fragment)},l(m){p=n(m,"P",{});var E=l(p);$=o(E,"Por ejemplo,  "),u=n(E,"CODE",{});var H=l(u);h=o(H,"TFDistilBertForSequenceClassification"),H.forEach(s),b=o(E," es un modelo DistilBERT base con una cabeza de clasificaci\xF3n de secuencias. La cabeza de clasificaci\xF3n de secuencias es una capa superior que precede a la recolecci\xF3n de las salidas."),E.forEach(s),v=_(m),w(k.$$.fragment,m),F=_(m),g=n(m,"P",{});var W=l(g);L=o(W,"Puedes reutilizar este punto de guardado o "),j=n(W,"EM",{});var K=l(j);S=o(K,"checkpoint"),K.forEach(s),P=o(W," para otra tarea f\xE1cilmente cambiando a una cabeza de un modelo diferente. Para una tarea de respuesta a preguntas, puedes usar la cabeza del modelo "),M=n(W,"CODE",{});var te=l(M);B=o(te,"TFDistilBertForQuestionAnswering"),te.forEach(s),T=o(W,". La cabeza de respuesta a preguntas es similar a la de clasificaci\xF3n de secuencias, excepto porque consta de una capa lineal delante de la salida de los "),A=n(W,"EM",{});var fe=l(A);U=o(fe,"hidden states"),fe.forEach(s),I=o(W,"."),W.forEach(s),O=_(m),w(V.$$.fragment,m)},m(m,E){c(m,p,E),a(p,$),a(p,u),a(u,h),a(p,b),c(m,v,E),y(k,m,E),c(m,F,E),c(m,g,E),a(g,L),a(g,j),a(j,S),a(g,P),a(g,M),a(M,B),a(g,T),a(g,A),a(A,U),a(g,I),c(m,O,E),y(V,m,E),d=!0},p:ho,i(m){d||(C(k.$$.fragment,m),C(V.$$.fragment,m),d=!0)},o(m){D(k.$$.fragment,m),D(V.$$.fragment,m),d=!1},d(m){m&&s(p),m&&s(v),x(k,m),m&&s(F),m&&s(g),m&&s(O),x(V,m)}}}function pc(N){let p,$;return p=new go({props:{$$slots:{default:[cc]},$$scope:{ctx:N}}}),{c(){z(p.$$.fragment)},l(u){w(p.$$.fragment,u)},m(u,h){y(p,u,h),$=!0},p(u,h){const b={};h&2&&(b.$$scope={dirty:h,ctx:u}),p.$set(b)},i(u){$||(C(p.$$.fragment,u),$=!0)},o(u){D(p.$$.fragment,u),$=!1},d(u){x(p,u)}}}function dc(N){let p,$,u,h,b,v,k,F,g,L,j;return{c(){p=r("p"),$=t("No todos los modelos son compatibles con un "),u=r("em"),h=t("tokenizer"),b=t(" r\xE1pido. \xC9chale un vistazo a esta "),v=r("a"),k=t("tabla"),F=t(" para comprobar si un modelo en espec\xEDfico es compatible con un "),g=r("em"),L=t("tokenizer"),j=t(" r\xE1pido."),this.h()},l(S){p=n(S,"P",{});var P=l(p);$=o(P,"No todos los modelos son compatibles con un "),u=n(P,"EM",{});var M=l(u);h=o(M,"tokenizer"),M.forEach(s),b=o(P," r\xE1pido. \xC9chale un vistazo a esta "),v=n(P,"A",{href:!0});var B=l(v);k=o(B,"tabla"),B.forEach(s),F=o(P," para comprobar si un modelo en espec\xEDfico es compatible con un "),g=n(P,"EM",{});var T=l(g);L=o(T,"tokenizer"),T.forEach(s),j=o(P," r\xE1pido."),P.forEach(s),this.h()},h(){q(v,"href","index#supported-frameworks")},m(S,P){c(S,p,P),a(p,$),a(p,u),a(u,h),a(p,b),a(p,v),a(v,k),a(p,F),a(p,g),a(g,L),a(p,j)},d(S){S&&s(p)}}}function uc(N){let p,$,u,h,b,v,k,F,g,L,j,S,P,M;return{c(){p=r("p"),$=t("Por defecto, el "),u=r("code"),h=t("AutoTokenizer"),b=t(" intentar\xE1 cargar un "),v=r("em"),k=t("tokenizer"),F=t(" r\xE1pido. Puedes desactivar este compartimiento cambiando el par\xE1metro "),g=r("code"),L=t("use_fast=False"),j=t(" de "),S=r("code"),P=t("from_pretrained"),M=t(".")},l(B){p=n(B,"P",{});var T=l(p);$=o(T,"Por defecto, el "),u=n(T,"CODE",{});var A=l(u);h=o(A,"AutoTokenizer"),A.forEach(s),b=o(T," intentar\xE1 cargar un "),v=n(T,"EM",{});var U=l(v);k=o(U,"tokenizer"),U.forEach(s),F=o(T," r\xE1pido. Puedes desactivar este compartimiento cambiando el par\xE1metro "),g=n(T,"CODE",{});var I=l(g);L=o(I,"use_fast=False"),I.forEach(s),j=o(T," de "),S=n(T,"CODE",{});var O=l(S);P=o(O,"from_pretrained"),O.forEach(s),M=o(T,"."),T.forEach(s)},m(B,T){c(B,p,T),a(p,$),a(p,u),a(u,h),a(p,b),a(p,v),a(v,k),a(p,F),a(p,g),a(g,L),a(p,j),a(p,S),a(S,P),a(p,M)},d(B){B&&s(p)}}}function mc(N){let p,$,u,h,b;return{c(){p=r("p"),$=t("Si no est\xE1s buscando ninguna personalizaci\xF3n en espec\xEDfico, usa el m\xE9todo "),u=r("code"),h=t("from_pretrained"),b=t(" para cargar los par\xE1metros del extractor de caracter\xEDsticas por defecto del modelo.")},l(v){p=n(v,"P",{});var k=l(p);$=o(k,"Si no est\xE1s buscando ninguna personalizaci\xF3n en espec\xEDfico, usa el m\xE9todo "),u=n(k,"CODE",{});var F=l(u);h=o(F,"from_pretrained"),F.forEach(s),b=o(k," para cargar los par\xE1metros del extractor de caracter\xEDsticas por defecto del modelo."),k.forEach(s)},m(v,k){c(v,p,k),a(p,$),a(p,u),a(u,h),a(p,b)},d(v){v&&s(p)}}}function fc(N){let p,$,u,h,b,v,k,F,g,L,j,S,P,M,B,T,A,U,I,O,V,d,m,E,H,W,K,te,fe,$o,Ba,vo,bo,Ma,Eo,qo,Aa,jo,Zs,_e,je,Oa,Je,ko,Sa,zo,et,X,wo,Ea,yo,Co,Va,Do,xo,La,Po,To,Wa,Fo,Bo,Na,Mo,Ao,at,ne,Oo,qa,So,Vo,Ia,Lo,Wo,st,Xe,tt,he,Ra,No,Io,Ua,Ro,Uo,ot,ke,Ge,Qo,Qa,Ho,Jo,Xo,ge,Go,Ha,Ko,Yo,Ja,Zo,er,rt,Ke,nt,ze,ar,Xa,sr,tr,lt,Ye,it,we,or,Ga,rr,nr,ct,Ze,pt,ye,lr,Ka,ir,cr,dt,ea,ut,Ce,mt,$e,De,Ya,aa,pr,Za,dr,ft,Q,ur,ja,mr,fr,es,_r,hr,as,gr,$r,ss,vr,br,ts,Er,qr,sa,os,jr,kr,ta,rs,zr,wr,oa,ns,yr,Cr,_t,xe,ht,ve,Pe,ls,ra,Dr,is,xr,gt,le,Pr,cs,Tr,Fr,ps,Br,Mr,$t,Te,vt,be,Fe,ds,na,Ar,us,Or,bt,ie,Sr,ka,Vr,Lr,ms,Wr,Nr,Et,Be,Me,fs,Ir,Rr,_s,Ur,Qr,Hr,Y,hs,Jr,Xr,gs,Gr,Kr,la,Yr,Zr,$s,en,an,vs,sn,tn,qt,Ae,on,bs,rn,nn,jt,Oe,kt,Se,ln,Es,cn,pn,zt,ia,wt,G,dn,qs,un,mn,js,fn,_n,ks,hn,gn,zs,$n,vn,ws,bn,En,yt,ca,Ct,ce,qn,ys,jn,kn,Cs,zn,wn,Dt,pa,xt,Ve,Pt,Ee,Le,Ds,da,yn,xs,Cn,Tt,ee,Dn,Ps,xn,Pn,Ts,Tn,Fn,Fs,Bn,Mn,Ft,pe,An,Bs,On,Sn,za,Vn,Ln,Bt,ua,Mt,We,At,Ne,Wn,Ms,Nn,In,Ot,ma,St,Ie,Rn,As,Un,Qn,Vt,fa,Lt,qe,Re,Os,_a,Hn,Ss,Jn,Wt,Z,Xn,Vs,Gn,Kn,Ls,Yn,Zn,Ws,el,al,Ns,sl,tl,Nt,wa,ol,It,ha,Rt,Ue,rl,Is,nl,ll,Ut,ga,Qt,de,il,Rs,cl,pl,Us,dl,ul,Ht,$a,Jt,Qe,ml,Qs,fl,_l,Xt;return v=new ba({}),Je=new ba({}),Xe=new R({props:{code:`from transformers import DistilBertConfig

config = DistilBertConfig()
print(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = DistilBertConfig()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(config)
DistilBertConfig {
  <span class="hljs-string">&quot;activation&quot;</span>: <span class="hljs-string">&quot;gelu&quot;</span>,
  <span class="hljs-string">&quot;attention_dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;dim&quot;</span>: <span class="hljs-number">768</span>,
  <span class="hljs-string">&quot;dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;hidden_dim&quot;</span>: <span class="hljs-number">3072</span>,
  <span class="hljs-string">&quot;initializer_range&quot;</span>: <span class="hljs-number">0.02</span>,
  <span class="hljs-string">&quot;max_position_embeddings&quot;</span>: <span class="hljs-number">512</span>,
  <span class="hljs-string">&quot;model_type&quot;</span>: <span class="hljs-string">&quot;distilbert&quot;</span>,
  <span class="hljs-string">&quot;n_heads&quot;</span>: <span class="hljs-number">12</span>,
  <span class="hljs-string">&quot;n_layers&quot;</span>: <span class="hljs-number">6</span>,
  <span class="hljs-string">&quot;pad_token_id&quot;</span>: <span class="hljs-number">0</span>,
  <span class="hljs-string">&quot;qa_dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;seq_classif_dropout&quot;</span>: <span class="hljs-number">0.2</span>,
  <span class="hljs-string">&quot;sinusoidal_pos_embds&quot;</span>: false,
  <span class="hljs-string">&quot;transformers_version&quot;</span>: <span class="hljs-string">&quot;4.16.2&quot;</span>,
  <span class="hljs-string">&quot;vocab_size&quot;</span>: <span class="hljs-number">30522</span>
}`}}),Ke=new R({props:{code:`my_config = DistilBertConfig(activation="relu", attention_dropout=0.4)
print(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig(activation=<span class="hljs-string">&quot;relu&quot;</span>, attention_dropout=<span class="hljs-number">0.4</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(my_config)
DistilBertConfig {
  <span class="hljs-string">&quot;activation&quot;</span>: <span class="hljs-string">&quot;relu&quot;</span>,
  <span class="hljs-string">&quot;attention_dropout&quot;</span>: <span class="hljs-number">0.4</span>,
  <span class="hljs-string">&quot;dim&quot;</span>: <span class="hljs-number">768</span>,
  <span class="hljs-string">&quot;dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;hidden_dim&quot;</span>: <span class="hljs-number">3072</span>,
  <span class="hljs-string">&quot;initializer_range&quot;</span>: <span class="hljs-number">0.02</span>,
  <span class="hljs-string">&quot;max_position_embeddings&quot;</span>: <span class="hljs-number">512</span>,
  <span class="hljs-string">&quot;model_type&quot;</span>: <span class="hljs-string">&quot;distilbert&quot;</span>,
  <span class="hljs-string">&quot;n_heads&quot;</span>: <span class="hljs-number">12</span>,
  <span class="hljs-string">&quot;n_layers&quot;</span>: <span class="hljs-number">6</span>,
  <span class="hljs-string">&quot;pad_token_id&quot;</span>: <span class="hljs-number">0</span>,
  <span class="hljs-string">&quot;qa_dropout&quot;</span>: <span class="hljs-number">0.1</span>,
  <span class="hljs-string">&quot;seq_classif_dropout&quot;</span>: <span class="hljs-number">0.2</span>,
  <span class="hljs-string">&quot;sinusoidal_pos_embds&quot;</span>: false,
  <span class="hljs-string">&quot;transformers_version&quot;</span>: <span class="hljs-string">&quot;4.16.2&quot;</span>,
  <span class="hljs-string">&quot;vocab_size&quot;</span>: <span class="hljs-number">30522</span>
}`}}),Ye=new R({props:{code:'my_config = DistilBertConfig.from_pretrained("distilbert-base-uncased", activation="relu", attention_dropout=0.4)',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, activation=<span class="hljs-string">&quot;relu&quot;</span>, attention_dropout=<span class="hljs-number">0.4</span>)'}}),Ze=new R({props:{code:'my_config.save_pretrained(save_directory="./your_model_save_path")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>my_config.save_pretrained(save_directory=<span class="hljs-string">&quot;./your_model_save_path&quot;</span>)'}}),ea=new R({props:{code:'my_config = DistilBertConfig.from_pretrained("./your_model_save_path/my_config.json")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = DistilBertConfig.from_pretrained(<span class="hljs-string">&quot;./your_model_save_path/my_config.json&quot;</span>)'}}),Ce=new _o({props:{$$slots:{default:[sc]},$$scope:{ctx:N}}}),aa=new ba({}),xe=new Gi({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[nc],pytorch:[oc]},$$scope:{ctx:N}}}),ra=new ba({}),Te=new Gi({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[pc],pytorch:[ic]},$$scope:{ctx:N}}}),na=new ba({}),Oe=new _o({props:{warning:!0,$$slots:{default:[dc]},$$scope:{ctx:N}}}),ia=new R({props:{code:`from transformers import DistilBertTokenizer

my_tokenizer = DistilBertTokenizer(vocab_file="my_vocab_file.txt", do_lower_case=False, padding_side="left")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>my_tokenizer = DistilBertTokenizer(vocab_file=<span class="hljs-string">&quot;my_vocab_file.txt&quot;</span>, do_lower_case=<span class="hljs-literal">False</span>, padding_side=<span class="hljs-string">&quot;left&quot;</span>)`}}),ca=new R({props:{code:`from transformers import DistilBertTokenizer

slow_tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>slow_tokenizer = DistilBertTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),pa=new R({props:{code:`from transformers import DistilBertTokenizerFast

fast_tokenizer = DistilBertTokenizerFast.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DistilBertTokenizerFast

<span class="hljs-meta">&gt;&gt;&gt; </span>fast_tokenizer = DistilBertTokenizerFast.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),Ve=new _o({props:{$$slots:{default:[uc]},$$scope:{ctx:N}}}),da=new ba({}),ua=new R({props:{code:`from transformers import ViTFeatureExtractor

vit_extractor = ViTFeatureExtractor()
print(vit_extractor)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> ViTFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>vit_extractor = ViTFeatureExtractor()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(vit_extractor)
ViTFeatureExtractor {
  <span class="hljs-string">&quot;do_normalize&quot;</span>: true,
  <span class="hljs-string">&quot;do_resize&quot;</span>: true,
  <span class="hljs-string">&quot;feature_extractor_type&quot;</span>: <span class="hljs-string">&quot;ViTFeatureExtractor&quot;</span>,
  <span class="hljs-string">&quot;image_mean&quot;</span>: [
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>
  ],
  <span class="hljs-string">&quot;image_std&quot;</span>: [
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>
  ],
  <span class="hljs-string">&quot;resample&quot;</span>: <span class="hljs-number">2</span>,
  <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">224</span>
}`}}),We=new _o({props:{$$slots:{default:[mc]},$$scope:{ctx:N}}}),ma=new R({props:{code:`from transformers import ViTFeatureExtractor

my_vit_extractor = ViTFeatureExtractor(resample="PIL.Image.BOX", do_normalize=False, image_mean=[0.3, 0.3, 0.3])
print(my_vit_extractor)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> ViTFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>my_vit_extractor = ViTFeatureExtractor(resample=<span class="hljs-string">&quot;PIL.Image.BOX&quot;</span>, do_normalize=<span class="hljs-literal">False</span>, image_mean=[<span class="hljs-number">0.3</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.3</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(my_vit_extractor)
ViTFeatureExtractor {
  <span class="hljs-string">&quot;do_normalize&quot;</span>: false,
  <span class="hljs-string">&quot;do_resize&quot;</span>: true,
  <span class="hljs-string">&quot;feature_extractor_type&quot;</span>: <span class="hljs-string">&quot;ViTFeatureExtractor&quot;</span>,
  <span class="hljs-string">&quot;image_mean&quot;</span>: [
    <span class="hljs-number">0.3</span>,
    <span class="hljs-number">0.3</span>,
    <span class="hljs-number">0.3</span>
  ],
  <span class="hljs-string">&quot;image_std&quot;</span>: [
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>,
    <span class="hljs-number">0.5</span>
  ],
  <span class="hljs-string">&quot;resample&quot;</span>: <span class="hljs-string">&quot;PIL.Image.BOX&quot;</span>,
  <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-number">224</span>
}`}}),fa=new R({props:{code:`from transformers import Wav2Vec2FeatureExtractor

w2v2_extractor = Wav2Vec2FeatureExtractor()
print(w2v2_extractor)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2FeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>w2v2_extractor = Wav2Vec2FeatureExtractor()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(w2v2_extractor)
Wav2Vec2FeatureExtractor {
  <span class="hljs-string">&quot;do_normalize&quot;</span>: true,
  <span class="hljs-string">&quot;feature_extractor_type&quot;</span>: <span class="hljs-string">&quot;Wav2Vec2FeatureExtractor&quot;</span>,
  <span class="hljs-string">&quot;feature_size&quot;</span>: <span class="hljs-number">1</span>,
  <span class="hljs-string">&quot;padding_side&quot;</span>: <span class="hljs-string">&quot;right&quot;</span>,
  <span class="hljs-string">&quot;padding_value&quot;</span>: <span class="hljs-number">0.0</span>,
  <span class="hljs-string">&quot;return_attention_mask&quot;</span>: false,
  <span class="hljs-string">&quot;sampling_rate&quot;</span>: <span class="hljs-number">16000</span>
}`}}),_a=new ba({}),ha=new R({props:{code:`from transformers import Wav2Vec2FeatureExtractor

feature_extractor = Wav2Vec2FeatureExtractor(padding_value=1.0, do_normalize=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2FeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = Wav2Vec2FeatureExtractor(padding_value=<span class="hljs-number">1.0</span>, do_normalize=<span class="hljs-literal">True</span>)`}}),ga=new R({props:{code:`from transformers import Wav2Vec2CTCTokenizer

tokenizer = Wav2Vec2CTCTokenizer(vocab_file="my_vocab_file.txt")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2CTCTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = Wav2Vec2CTCTokenizer(vocab_file=<span class="hljs-string">&quot;my_vocab_file.txt&quot;</span>)`}}),$a=new R({props:{code:`from transformers import Wav2Vec2Processor

processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Wav2Vec2Processor

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)`}}),{c(){p=r("meta"),$=f(),u=r("h1"),h=r("a"),b=r("span"),z(v.$$.fragment),k=f(),F=r("span"),g=t("Crea una arquitectura personalizada"),L=f(),j=r("p"),S=t("Una "),P=r("a"),M=r("code"),B=t("AutoClass"),T=t(" infiere, autom\xE1ticamente, la arquitectura del modelo y descarga la configuraci\xF3n y los pesos del modelo preentrenado. Normalmente, recomendamos usar una "),A=r("code"),U=t("AutoClass"),I=t(" para producir un c\xF3digo agn\xF3stico a puntos de guardado o checkpoints. Sin embargo, los usuarios que quieran m\xE1s control sobre los par\xE1metros espec\xEDficos de los modelos pueden crear su propio modelo \u{1F917} Transformers personalizado a partir de varias clases base. Esto puede ser particularmente \xFAtil para alguien que est\xE9 interesado en estudiar, entrenar o experimentar con modelos \u{1F917} Transformers. En esta gu\xEDa vamos a profundizar en la creaci\xF3n de modelos personalizados sin usar "),O=r("code"),V=t("AutoClass"),d=t(". Aprenderemos a:"),m=f(),E=r("ul"),H=r("li"),W=t("Cargar y personalizar una configuraci\xF3n para un modelo."),K=f(),te=r("li"),fe=t("Crear una arquitectura para un modelo."),$o=f(),Ba=r("li"),vo=t("Crear tokenizadores r\xE1pidos y lentos para textos."),bo=f(),Ma=r("li"),Eo=t("Crear un extractor de propiedades para tareas de audio o im\xE1genes."),qo=f(),Aa=r("li"),jo=t("Crear un procesador para tareas multimodales."),Zs=f(),_e=r("h2"),je=r("a"),Oa=r("span"),z(Je.$$.fragment),ko=f(),Sa=r("span"),zo=t("Configuraci\xF3n"),et=f(),X=r("p"),wo=t("Una "),Ea=r("a"),yo=t("configuraci\xF3n"),Co=t(" es un conjunto de atributos espec\xEDficos de un modelo. Cada configuraci\xF3n de modelo tiene atributos diferentes. Por ejemplo, todos los modelos de PLN tienen los atributos "),Va=r("code"),Do=t("hidden_size"),xo=t(", "),La=r("code"),Po=t("num_attention_heads"),To=t(", "),Wa=r("code"),Fo=t("num_hidden_layers"),Bo=t(" y "),Na=r("code"),Mo=t("vocab_size"),Ao=t(" en com\xFAn. Estos atributos especifican el n\xFAmero de cabezas de atenci\xF3n o de capas ocultas con las que se construyen los modelos."),at=f(),ne=r("p"),Oo=t("Puedes echarle un vistazo a "),qa=r("a"),So=t("DistilBERT"),Vo=t(" y sus atributos accediendo a "),Ia=r("code"),Lo=t("DistilBertConfig"),Wo=t(":"),st=f(),z(Xe.$$.fragment),tt=f(),he=r("p"),Ra=r("code"),No=t("DistilBertConfig"),Io=t(" muestra todos los atributos por defecto que se han usado para construir un modelo "),Ua=r("code"),Ro=t("DistilBertModel"),Uo=t(" base. Todos ellos son personalizables, lo que deja espacio para poder experimentar. Por ejemplo, puedes personalizar un modelo predeterminado para:"),ot=f(),ke=r("ul"),Ge=r("li"),Qo=t("Probar una funci\xF3n de activaci\xF3n diferente, usando el par\xE1metro "),Qa=r("code"),Ho=t("activation"),Jo=t("."),Xo=f(),ge=r("li"),Go=t("Usar un valor de abandono (tambi\xE9n conocido como "),Ha=r("em"),Ko=t("dropout"),Yo=t(") m\xE1s alto para las probabilidades de las capas de atenci\xF3n, usando el par\xE1metro "),Ja=r("code"),Zo=t("attention_dropout"),er=t("."),rt=f(),z(Ke.$$.fragment),nt=f(),ze=r("p"),ar=t("Los atributos de los modelos preentrenados pueden ser modificados con la funci\xF3n "),Xa=r("code"),sr=t("from_pretrained()"),tr=t(":"),lt=f(),z(Ye.$$.fragment),it=f(),we=r("p"),or=t("Cuando est\xE9s satisfecho con la configuraci\xF3n de tu modelo, puedes guardarlo con la funci\xF3n "),Ga=r("code"),rr=t("save_pretrained()"),nr=t(". Tu configuraci\xF3n se guardar\xE1 en un archivo JSON dentro del directorio que le especifiques como par\xE1metro."),ct=f(),z(Ze.$$.fragment),pt=f(),ye=r("p"),lr=t("Para volver a usar el archivo de configuraci\xF3n, puedes cargarlo usando "),Ka=r("code"),ir=t("from_pretrained()"),cr=t(":"),dt=f(),z(ea.$$.fragment),ut=f(),z(Ce.$$.fragment),mt=f(),$e=r("h2"),De=r("a"),Ya=r("span"),z(aa.$$.fragment),pr=f(),Za=r("span"),dr=t("Modelo"),ft=f(),Q=r("p"),ur=t("El siguiente paso ser\xE1 crear un "),ja=r("a"),mr=t("modelo"),fr=t(". El modelo, al que a veces tambi\xE9n nos referimos como arquitectura, es el encargado de definir cada capa y qu\xE9 operaciones se realizan. Los atributos como "),es=r("code"),_r=t("num_hidden_layers"),hr=t(" de la configuraci\xF3n se usan para definir la arquitectura. Todos los modelos comparten una clase base, "),as=r("code"),gr=t("PreTrainedModel"),$r=t(", y algunos m\xE9todos comunes que se pueden usar para redimensionar los "),ss=r("em"),vr=t("embeddings"),br=t(" o para recortar cabezas de auto-atenci\xF3n (tambi\xE9n llamadas "),ts=r("em"),Er=t("self-attention heads"),qr=t("). Adem\xE1s, todos los modelos son subclases de "),sa=r("a"),os=r("code"),jr=t("torch.nn.Module"),kr=t(", "),ta=r("a"),rs=r("code"),zr=t("tf.keras.Model"),wr=t(" o "),oa=r("a"),ns=r("code"),yr=t("flax.linen.Module"),Cr=t(", lo que significa que son compatibles con su respectivo framework."),_t=f(),z(xe.$$.fragment),ht=f(),ve=r("h3"),Pe=r("a"),ls=r("span"),z(ra.$$.fragment),Dr=f(),is=r("span"),xr=t("Cabezas de modelo"),gt=f(),le=r("p"),Pr=t("En este punto del tutorial, tenemos un modelo DistilBERT base que devuelve los "),cs=r("em"),Tr=t("hidden states"),Fr=t(" o estados ocultos. Los "),ps=r("em"),Br=t("hidden states"),Mr=t(" se pasan como par\xE1metros de entrada a la cabeza del modelo para producir la salida. \u{1F917} Transformers ofrece una cabeza de modelo diferente para cada tarea, siempre y cuando el modelo sea compatible para la tarea (por ejemplo, no puedes usar DistilBERT para una tarea secuencia a secuencia como la traducci\xF3n)."),$t=f(),z(Te.$$.fragment),vt=f(),be=r("h2"),Fe=r("a"),ds=r("span"),z(na.$$.fragment),Ar=f(),us=r("span"),Or=t("Tokenizer"),bt=f(),ie=r("p"),Sr=t("La ultima clase base que debes conocer antes de usar un modelo con datos textuales es la clase "),ka=r("a"),Vr=t("tokenizer"),Lr=t(", que convierte el texto bruto en tensores. Hay dos tipos de "),ms=r("em"),Wr=t("tokenizers"),Nr=t(" que puedes usar con \u{1F917} Transformers:"),Et=f(),Be=r("ul"),Me=r("li"),fs=r("code"),Ir=t("PreTrainedTokenizer"),Rr=t(":  una implementaci\xF3n de un "),_s=r("em"),Ur=t("tokenizer"),Qr=t(" hecha en Python."),Hr=f(),Y=r("li"),hs=r("code"),Jr=t("PreTrainedTokenizerFast"),Xr=t(": un "),gs=r("em"),Gr=t("tokenizer"),Kr=t(" de nuestra librer\xEDa "),la=r("a"),Yr=t("\u{1F917} Tokenizer"),Zr=t(", basada en Rust. Este tipo de "),$s=r("em"),en=t("tokenizer"),an=t(" es bastante m\xE1s r\xE1pido, especialmente durante la tokenizaci\xF3n por lotes, gracias a estar implementado en Rust. Esta r\xE1pida tokenizaci\xF3n tambi\xE9n ofrece m\xE9todos adicionales como el "),vs=r("em"),sn=t("offset mapping"),tn=t(", que relaciona los tokens con sus palabras o caracteres originales."),qt=f(),Ae=r("p"),on=t("Ambos "),bs=r("em"),rn=t("tokenizers"),nn=t(" son compatibles con los m\xE9todos comunes, como los de encodificaci\xF3n y decodificaci\xF3n, los m\xE9todos para a\xF1adir tokens y aquellos que manejan tokens especiales."),jt=f(),z(Oe.$$.fragment),kt=f(),Se=r("p"),ln=t("Si has entrenado tu propio "),Es=r("em"),cn=t("tokenizer"),pn=t(", puedes crear uno desde tu archivo de \u201Cvocabulario\u201D:"),zt=f(),z(ia.$$.fragment),wt=f(),G=r("p"),dn=t("Es importante recordar que los vocabularios que provienen de un "),qs=r("em"),un=t("tokenizer"),mn=t(" personalizado ser\xE1n diferentes a los vocabularios generados por el "),js=r("em"),fn=t("tokenizer"),_n=t(" de un modelo preentrenado. Debes usar el vocabulario de un "),ks=r("em"),hn=t("tokenizer"),gn=t(" preentrenado si vas a usar un modelo preentrenado, de lo contrario las entradas no tendr\xE1n sentido. Crea un "),zs=r("em"),$n=t("tokenizer"),vn=t(" con el vocabulario de un modelo preentrenado usado la clase "),ws=r("code"),bn=t("DistilBertTokenizer"),En=t(":"),yt=f(),z(ca.$$.fragment),Ct=f(),ce=r("p"),qn=t("Crea un "),ys=r("em"),jn=t("tokenizer"),kn=t(" r\xE1pido con la clase "),Cs=r("code"),zn=t("DistilBertTokenizerFast"),wn=t(":"),Dt=f(),z(pa.$$.fragment),xt=f(),z(Ve.$$.fragment),Pt=f(),Ee=r("h2"),Le=r("a"),Ds=r("span"),z(da.$$.fragment),yn=f(),xs=r("span"),Cn=t("Extractor de Caracter\xEDsticas"),Tt=f(),ee=r("p"),Dn=t("Un extractor de caracter\xEDsticas procesa entradas de audio e imagen. Hereda de la clase base "),Ps=r("code"),xn=t("FeatureExtractionMixin"),Pn=t(" y tambi\xE9n puede heredar de la clase "),Ts=r("code"),Tn=t("ImageFeatureExtractionMixin"),Fn=t(" para el procesamiento de caracter\xEDsticas de las im\xE1genes o de la clase "),Fs=r("code"),Bn=t("SequenceFeatureExtractor"),Mn=t(" para el procesamiento de entradas de audio."),Ft=f(),pe=r("p"),An=t("Dependiendo de si trabajas en una tarea de audio o de video, puedes crear un extractor de caracter\xEDsticas asociado al modelo que estes usando. Por ejemplo, podr\xEDas crear un "),Bs=r("code"),On=t("ViTFeatureExtractor"),Sn=t(" por defecto si estas usando "),za=r("a"),Vn=t("ViT"),Ln=t(" para clasificaci\xF3n de im\xE1genes:"),Bt=f(),z(ua.$$.fragment),Mt=f(),z(We.$$.fragment),At=f(),Ne=r("p"),Wn=t("Puedes modificar cualquier par\xE1metro de "),Ms=r("code"),Nn=t("ViTFeatureExtractor"),In=t(" para crear tu extractor de caracter\xEDsticas personalizado:"),Ot=f(),z(ma.$$.fragment),St=f(),Ie=r("p"),Rn=t("Para las entradas de audio, puedes crear un "),As=r("code"),Un=t("Wav2Vec2FeatureExtractor"),Qn=t(" y personalizar los par\xE1metros de una forma similar:"),Vt=f(),z(fa.$$.fragment),Lt=f(),qe=r("h2"),Re=r("a"),Os=r("span"),z(_a.$$.fragment),Hn=f(),Ss=r("span"),Jn=t("Procesador"),Wt=f(),Z=r("p"),Xn=t("Para modelos que son compatibles con tareas multimodales, \u{1F917} Transformers ofrece una clase "),Vs=r("em"),Gn=t("procesador"),Kn=t(" que agrupa un extractor de caracter\xEDsticas y un "),Ls=r("em"),Yn=t("tokenizer"),Zn=t(" en el mismo objeto. Por ejemplo, probemos a usar el procesador "),Ws=r("code"),el=t("Wav2Vec2Processor"),al=t(" para una tarea de reconocimiento de voz (ASR). Un ASR transcribe el audio a texto, por lo que necesitaremos un extractor de caracter\xEDsticas y un "),Ns=r("em"),sl=t("tokenizer"),tl=t("."),Nt=f(),wa=r("p"),ol=t("Crea un extractor de caracter\xEDsticas para manejar la entrada de audio:"),It=f(),z(ha.$$.fragment),Rt=f(),Ue=r("p"),rl=t("Crea un "),Is=r("em"),nl=t("tokenizer"),ll=t(" para manejar la entrada de texto:"),Ut=f(),z(ga.$$.fragment),Qt=f(),de=r("p"),il=t("Puedes combinar el extractor de caracter\xEDsticas y el "),Rs=r("em"),cl=t("tokenizer"),pl=t(" en el "),Us=r("code"),dl=t("Wav2Vec2Processor"),ul=t(":"),Ht=f(),z($a.$$.fragment),Jt=f(),Qe=r("p"),ml=t("Con dos clases base (la configuraci\xF3n y el modelo) y una clase de preprocesamiento adicional ("),Qs=r("em"),fl=t("tokenizer"),_l=t(", extractor de caracter\xEDsticas o procesador), puedes crear cualquiera de los modelos compatibles con \u{1F917} Transformers. Cada una de estas clases son configurables, permiti\xE9ndote usar sus atributos espec\xEDficos. Puedes crear un modelo para entrenarlo de una forma f\xE1cil, o modificar un modelo preentrenado disponible para especializarlo."),this.h()},l(e){const i=ec('[data-svelte="svelte-1phssyn"]',document.head);p=n(i,"META",{name:!0,content:!0}),i.forEach(s),$=_(e),u=n(e,"H1",{class:!0});var va=l(u);h=n(va,"A",{id:!0,class:!0,href:!0});var Hs=l(h);b=n(Hs,"SPAN",{});var Js=l(b);w(v.$$.fragment,Js),Js.forEach(s),Hs.forEach(s),k=_(va),F=n(va,"SPAN",{});var Xs=l(F);g=o(Xs,"Crea una arquitectura personalizada"),Xs.forEach(s),va.forEach(s),L=_(e),j=n(e,"P",{});var oe=l(j);S=o(oe,"Una "),P=n(oe,"A",{href:!0});var Gs=l(P);M=n(Gs,"CODE",{});var hl=l(M);B=o(hl,"AutoClass"),hl.forEach(s),Gs.forEach(s),T=o(oe," infiere, autom\xE1ticamente, la arquitectura del modelo y descarga la configuraci\xF3n y los pesos del modelo preentrenado. Normalmente, recomendamos usar una "),A=n(oe,"CODE",{});var gl=l(A);U=o(gl,"AutoClass"),gl.forEach(s),I=o(oe," para producir un c\xF3digo agn\xF3stico a puntos de guardado o checkpoints. Sin embargo, los usuarios que quieran m\xE1s control sobre los par\xE1metros espec\xEDficos de los modelos pueden crear su propio modelo \u{1F917} Transformers personalizado a partir de varias clases base. Esto puede ser particularmente \xFAtil para alguien que est\xE9 interesado en estudiar, entrenar o experimentar con modelos \u{1F917} Transformers. En esta gu\xEDa vamos a profundizar en la creaci\xF3n de modelos personalizados sin usar "),O=n(oe,"CODE",{});var $l=l(O);V=o($l,"AutoClass"),$l.forEach(s),d=o(oe,". Aprenderemos a:"),oe.forEach(s),m=_(e),E=n(e,"UL",{});var ue=l(E);H=n(ue,"LI",{});var vl=l(H);W=o(vl,"Cargar y personalizar una configuraci\xF3n para un modelo."),vl.forEach(s),K=_(ue),te=n(ue,"LI",{});var bl=l(te);fe=o(bl,"Crear una arquitectura para un modelo."),bl.forEach(s),$o=_(ue),Ba=n(ue,"LI",{});var El=l(Ba);vo=o(El,"Crear tokenizadores r\xE1pidos y lentos para textos."),El.forEach(s),bo=_(ue),Ma=n(ue,"LI",{});var ql=l(Ma);Eo=o(ql,"Crear un extractor de propiedades para tareas de audio o im\xE1genes."),ql.forEach(s),qo=_(ue),Aa=n(ue,"LI",{});var jl=l(Aa);jo=o(jl,"Crear un procesador para tareas multimodales."),jl.forEach(s),ue.forEach(s),Zs=_(e),_e=n(e,"H2",{class:!0});var Gt=l(_e);je=n(Gt,"A",{id:!0,class:!0,href:!0});var kl=l(je);Oa=n(kl,"SPAN",{});var zl=l(Oa);w(Je.$$.fragment,zl),zl.forEach(s),kl.forEach(s),ko=_(Gt),Sa=n(Gt,"SPAN",{});var wl=l(Sa);zo=o(wl,"Configuraci\xF3n"),wl.forEach(s),Gt.forEach(s),et=_(e),X=n(e,"P",{});var ae=l(X);wo=o(ae,"Una "),Ea=n(ae,"A",{href:!0});var yl=l(Ea);yo=o(yl,"configuraci\xF3n"),yl.forEach(s),Co=o(ae," es un conjunto de atributos espec\xEDficos de un modelo. Cada configuraci\xF3n de modelo tiene atributos diferentes. Por ejemplo, todos los modelos de PLN tienen los atributos "),Va=n(ae,"CODE",{});var Cl=l(Va);Do=o(Cl,"hidden_size"),Cl.forEach(s),xo=o(ae,", "),La=n(ae,"CODE",{});var Dl=l(La);Po=o(Dl,"num_attention_heads"),Dl.forEach(s),To=o(ae,", "),Wa=n(ae,"CODE",{});var xl=l(Wa);Fo=o(xl,"num_hidden_layers"),xl.forEach(s),Bo=o(ae," y "),Na=n(ae,"CODE",{});var Pl=l(Na);Mo=o(Pl,"vocab_size"),Pl.forEach(s),Ao=o(ae," en com\xFAn. Estos atributos especifican el n\xFAmero de cabezas de atenci\xF3n o de capas ocultas con las que se construyen los modelos."),ae.forEach(s),at=_(e),ne=n(e,"P",{});var ya=l(ne);Oo=o(ya,"Puedes echarle un vistazo a "),qa=n(ya,"A",{href:!0});var Tl=l(qa);So=o(Tl,"DistilBERT"),Tl.forEach(s),Vo=o(ya," y sus atributos accediendo a "),Ia=n(ya,"CODE",{});var Fl=l(Ia);Lo=o(Fl,"DistilBertConfig"),Fl.forEach(s),Wo=o(ya,":"),ya.forEach(s),st=_(e),w(Xe.$$.fragment,e),tt=_(e),he=n(e,"P",{});var Ks=l(he);Ra=n(Ks,"CODE",{});var Bl=l(Ra);No=o(Bl,"DistilBertConfig"),Bl.forEach(s),Io=o(Ks," muestra todos los atributos por defecto que se han usado para construir un modelo "),Ua=n(Ks,"CODE",{});var Ml=l(Ua);Ro=o(Ml,"DistilBertModel"),Ml.forEach(s),Uo=o(Ks," base. Todos ellos son personalizables, lo que deja espacio para poder experimentar. Por ejemplo, puedes personalizar un modelo predeterminado para:"),Ks.forEach(s),ot=_(e),ke=n(e,"UL",{});var Kt=l(ke);Ge=n(Kt,"LI",{});var Yt=l(Ge);Qo=o(Yt,"Probar una funci\xF3n de activaci\xF3n diferente, usando el par\xE1metro "),Qa=n(Yt,"CODE",{});var Al=l(Qa);Ho=o(Al,"activation"),Al.forEach(s),Jo=o(Yt,"."),Yt.forEach(s),Xo=_(Kt),ge=n(Kt,"LI",{});var Ca=l(ge);Go=o(Ca,"Usar un valor de abandono (tambi\xE9n conocido como "),Ha=n(Ca,"EM",{});var Ol=l(Ha);Ko=o(Ol,"dropout"),Ol.forEach(s),Yo=o(Ca,") m\xE1s alto para las probabilidades de las capas de atenci\xF3n, usando el par\xE1metro "),Ja=n(Ca,"CODE",{});var Sl=l(Ja);Zo=o(Sl,"attention_dropout"),Sl.forEach(s),er=o(Ca,"."),Ca.forEach(s),Kt.forEach(s),rt=_(e),w(Ke.$$.fragment,e),nt=_(e),ze=n(e,"P",{});var Zt=l(ze);ar=o(Zt,"Los atributos de los modelos preentrenados pueden ser modificados con la funci\xF3n "),Xa=n(Zt,"CODE",{});var Vl=l(Xa);sr=o(Vl,"from_pretrained()"),Vl.forEach(s),tr=o(Zt,":"),Zt.forEach(s),lt=_(e),w(Ye.$$.fragment,e),it=_(e),we=n(e,"P",{});var eo=l(we);or=o(eo,"Cuando est\xE9s satisfecho con la configuraci\xF3n de tu modelo, puedes guardarlo con la funci\xF3n "),Ga=n(eo,"CODE",{});var Ll=l(Ga);rr=o(Ll,"save_pretrained()"),Ll.forEach(s),nr=o(eo,". Tu configuraci\xF3n se guardar\xE1 en un archivo JSON dentro del directorio que le especifiques como par\xE1metro."),eo.forEach(s),ct=_(e),w(Ze.$$.fragment,e),pt=_(e),ye=n(e,"P",{});var ao=l(ye);lr=o(ao,"Para volver a usar el archivo de configuraci\xF3n, puedes cargarlo usando "),Ka=n(ao,"CODE",{});var Wl=l(Ka);ir=o(Wl,"from_pretrained()"),Wl.forEach(s),cr=o(ao,":"),ao.forEach(s),dt=_(e),w(ea.$$.fragment,e),ut=_(e),w(Ce.$$.fragment,e),mt=_(e),$e=n(e,"H2",{class:!0});var so=l($e);De=n(so,"A",{id:!0,class:!0,href:!0});var Nl=l(De);Ya=n(Nl,"SPAN",{});var Il=l(Ya);w(aa.$$.fragment,Il),Il.forEach(s),Nl.forEach(s),pr=_(so),Za=n(so,"SPAN",{});var Rl=l(Za);dr=o(Rl,"Modelo"),Rl.forEach(s),so.forEach(s),ft=_(e),Q=n(e,"P",{});var J=l(Q);ur=o(J,"El siguiente paso ser\xE1 crear un "),ja=n(J,"A",{href:!0});var Ul=l(ja);mr=o(Ul,"modelo"),Ul.forEach(s),fr=o(J,". El modelo, al que a veces tambi\xE9n nos referimos como arquitectura, es el encargado de definir cada capa y qu\xE9 operaciones se realizan. Los atributos como "),es=n(J,"CODE",{});var Ql=l(es);_r=o(Ql,"num_hidden_layers"),Ql.forEach(s),hr=o(J," de la configuraci\xF3n se usan para definir la arquitectura. Todos los modelos comparten una clase base, "),as=n(J,"CODE",{});var Hl=l(as);gr=o(Hl,"PreTrainedModel"),Hl.forEach(s),$r=o(J,", y algunos m\xE9todos comunes que se pueden usar para redimensionar los "),ss=n(J,"EM",{});var Jl=l(ss);vr=o(Jl,"embeddings"),Jl.forEach(s),br=o(J," o para recortar cabezas de auto-atenci\xF3n (tambi\xE9n llamadas "),ts=n(J,"EM",{});var Xl=l(ts);Er=o(Xl,"self-attention heads"),Xl.forEach(s),qr=o(J,"). Adem\xE1s, todos los modelos son subclases de "),sa=n(J,"A",{href:!0,rel:!0});var Gl=l(sa);os=n(Gl,"CODE",{});var Kl=l(os);jr=o(Kl,"torch.nn.Module"),Kl.forEach(s),Gl.forEach(s),kr=o(J,", "),ta=n(J,"A",{href:!0,rel:!0});var Yl=l(ta);rs=n(Yl,"CODE",{});var Zl=l(rs);zr=o(Zl,"tf.keras.Model"),Zl.forEach(s),Yl.forEach(s),wr=o(J," o "),oa=n(J,"A",{href:!0,rel:!0});var ei=l(oa);ns=n(ei,"CODE",{});var ai=l(ns);yr=o(ai,"flax.linen.Module"),ai.forEach(s),ei.forEach(s),Cr=o(J,", lo que significa que son compatibles con su respectivo framework."),J.forEach(s),_t=_(e),w(xe.$$.fragment,e),ht=_(e),ve=n(e,"H3",{class:!0});var to=l(ve);Pe=n(to,"A",{id:!0,class:!0,href:!0});var si=l(Pe);ls=n(si,"SPAN",{});var ti=l(ls);w(ra.$$.fragment,ti),ti.forEach(s),si.forEach(s),Dr=_(to),is=n(to,"SPAN",{});var oi=l(is);xr=o(oi,"Cabezas de modelo"),oi.forEach(s),to.forEach(s),gt=_(e),le=n(e,"P",{});var Da=l(le);Pr=o(Da,"En este punto del tutorial, tenemos un modelo DistilBERT base que devuelve los "),cs=n(Da,"EM",{});var ri=l(cs);Tr=o(ri,"hidden states"),ri.forEach(s),Fr=o(Da," o estados ocultos. Los "),ps=n(Da,"EM",{});var ni=l(ps);Br=o(ni,"hidden states"),ni.forEach(s),Mr=o(Da," se pasan como par\xE1metros de entrada a la cabeza del modelo para producir la salida. \u{1F917} Transformers ofrece una cabeza de modelo diferente para cada tarea, siempre y cuando el modelo sea compatible para la tarea (por ejemplo, no puedes usar DistilBERT para una tarea secuencia a secuencia como la traducci\xF3n)."),Da.forEach(s),$t=_(e),w(Te.$$.fragment,e),vt=_(e),be=n(e,"H2",{class:!0});var oo=l(be);Fe=n(oo,"A",{id:!0,class:!0,href:!0});var li=l(Fe);ds=n(li,"SPAN",{});var ii=l(ds);w(na.$$.fragment,ii),ii.forEach(s),li.forEach(s),Ar=_(oo),us=n(oo,"SPAN",{});var ci=l(us);Or=o(ci,"Tokenizer"),ci.forEach(s),oo.forEach(s),bt=_(e),ie=n(e,"P",{});var xa=l(ie);Sr=o(xa,"La ultima clase base que debes conocer antes de usar un modelo con datos textuales es la clase "),ka=n(xa,"A",{href:!0});var pi=l(ka);Vr=o(pi,"tokenizer"),pi.forEach(s),Lr=o(xa,", que convierte el texto bruto en tensores. Hay dos tipos de "),ms=n(xa,"EM",{});var di=l(ms);Wr=o(di,"tokenizers"),di.forEach(s),Nr=o(xa," que puedes usar con \u{1F917} Transformers:"),xa.forEach(s),Et=_(e),Be=n(e,"UL",{});var ro=l(Be);Me=n(ro,"LI",{});var Ys=l(Me);fs=n(Ys,"CODE",{});var ui=l(fs);Ir=o(ui,"PreTrainedTokenizer"),ui.forEach(s),Rr=o(Ys,":  una implementaci\xF3n de un "),_s=n(Ys,"EM",{});var mi=l(_s);Ur=o(mi,"tokenizer"),mi.forEach(s),Qr=o(Ys," hecha en Python."),Ys.forEach(s),Hr=_(ro),Y=n(ro,"LI",{});var re=l(Y);hs=n(re,"CODE",{});var fi=l(hs);Jr=o(fi,"PreTrainedTokenizerFast"),fi.forEach(s),Xr=o(re,": un "),gs=n(re,"EM",{});var _i=l(gs);Gr=o(_i,"tokenizer"),_i.forEach(s),Kr=o(re," de nuestra librer\xEDa "),la=n(re,"A",{href:!0,rel:!0});var hi=l(la);Yr=o(hi,"\u{1F917} Tokenizer"),hi.forEach(s),Zr=o(re,", basada en Rust. Este tipo de "),$s=n(re,"EM",{});var gi=l($s);en=o(gi,"tokenizer"),gi.forEach(s),an=o(re," es bastante m\xE1s r\xE1pido, especialmente durante la tokenizaci\xF3n por lotes, gracias a estar implementado en Rust. Esta r\xE1pida tokenizaci\xF3n tambi\xE9n ofrece m\xE9todos adicionales como el "),vs=n(re,"EM",{});var $i=l(vs);sn=o($i,"offset mapping"),$i.forEach(s),tn=o(re,", que relaciona los tokens con sus palabras o caracteres originales."),re.forEach(s),ro.forEach(s),qt=_(e),Ae=n(e,"P",{});var no=l(Ae);on=o(no,"Ambos "),bs=n(no,"EM",{});var vi=l(bs);rn=o(vi,"tokenizers"),vi.forEach(s),nn=o(no," son compatibles con los m\xE9todos comunes, como los de encodificaci\xF3n y decodificaci\xF3n, los m\xE9todos para a\xF1adir tokens y aquellos que manejan tokens especiales."),no.forEach(s),jt=_(e),w(Oe.$$.fragment,e),kt=_(e),Se=n(e,"P",{});var lo=l(Se);ln=o(lo,"Si has entrenado tu propio "),Es=n(lo,"EM",{});var bi=l(Es);cn=o(bi,"tokenizer"),bi.forEach(s),pn=o(lo,", puedes crear uno desde tu archivo de \u201Cvocabulario\u201D:"),lo.forEach(s),zt=_(e),w(ia.$$.fragment,e),wt=_(e),G=n(e,"P",{});var se=l(G);dn=o(se,"Es importante recordar que los vocabularios que provienen de un "),qs=n(se,"EM",{});var Ei=l(qs);un=o(Ei,"tokenizer"),Ei.forEach(s),mn=o(se," personalizado ser\xE1n diferentes a los vocabularios generados por el "),js=n(se,"EM",{});var qi=l(js);fn=o(qi,"tokenizer"),qi.forEach(s),_n=o(se," de un modelo preentrenado. Debes usar el vocabulario de un "),ks=n(se,"EM",{});var ji=l(ks);hn=o(ji,"tokenizer"),ji.forEach(s),gn=o(se," preentrenado si vas a usar un modelo preentrenado, de lo contrario las entradas no tendr\xE1n sentido. Crea un "),zs=n(se,"EM",{});var ki=l(zs);$n=o(ki,"tokenizer"),ki.forEach(s),vn=o(se," con el vocabulario de un modelo preentrenado usado la clase "),ws=n(se,"CODE",{});var zi=l(ws);bn=o(zi,"DistilBertTokenizer"),zi.forEach(s),En=o(se,":"),se.forEach(s),yt=_(e),w(ca.$$.fragment,e),Ct=_(e),ce=n(e,"P",{});var Pa=l(ce);qn=o(Pa,"Crea un "),ys=n(Pa,"EM",{});var wi=l(ys);jn=o(wi,"tokenizer"),wi.forEach(s),kn=o(Pa," r\xE1pido con la clase "),Cs=n(Pa,"CODE",{});var yi=l(Cs);zn=o(yi,"DistilBertTokenizerFast"),yi.forEach(s),wn=o(Pa,":"),Pa.forEach(s),Dt=_(e),w(pa.$$.fragment,e),xt=_(e),w(Ve.$$.fragment,e),Pt=_(e),Ee=n(e,"H2",{class:!0});var io=l(Ee);Le=n(io,"A",{id:!0,class:!0,href:!0});var Ci=l(Le);Ds=n(Ci,"SPAN",{});var Di=l(Ds);w(da.$$.fragment,Di),Di.forEach(s),Ci.forEach(s),yn=_(io),xs=n(io,"SPAN",{});var xi=l(xs);Cn=o(xi,"Extractor de Caracter\xEDsticas"),xi.forEach(s),io.forEach(s),Tt=_(e),ee=n(e,"P",{});var He=l(ee);Dn=o(He,"Un extractor de caracter\xEDsticas procesa entradas de audio e imagen. Hereda de la clase base "),Ps=n(He,"CODE",{});var Pi=l(Ps);xn=o(Pi,"FeatureExtractionMixin"),Pi.forEach(s),Pn=o(He," y tambi\xE9n puede heredar de la clase "),Ts=n(He,"CODE",{});var Ti=l(Ts);Tn=o(Ti,"ImageFeatureExtractionMixin"),Ti.forEach(s),Fn=o(He," para el procesamiento de caracter\xEDsticas de las im\xE1genes o de la clase "),Fs=n(He,"CODE",{});var Fi=l(Fs);Bn=o(Fi,"SequenceFeatureExtractor"),Fi.forEach(s),Mn=o(He," para el procesamiento de entradas de audio."),He.forEach(s),Ft=_(e),pe=n(e,"P",{});var Ta=l(pe);An=o(Ta,"Dependiendo de si trabajas en una tarea de audio o de video, puedes crear un extractor de caracter\xEDsticas asociado al modelo que estes usando. Por ejemplo, podr\xEDas crear un "),Bs=n(Ta,"CODE",{});var Bi=l(Bs);On=o(Bi,"ViTFeatureExtractor"),Bi.forEach(s),Sn=o(Ta," por defecto si estas usando "),za=n(Ta,"A",{href:!0});var Mi=l(za);Vn=o(Mi,"ViT"),Mi.forEach(s),Ln=o(Ta," para clasificaci\xF3n de im\xE1genes:"),Ta.forEach(s),Bt=_(e),w(ua.$$.fragment,e),Mt=_(e),w(We.$$.fragment,e),At=_(e),Ne=n(e,"P",{});var co=l(Ne);Wn=o(co,"Puedes modificar cualquier par\xE1metro de "),Ms=n(co,"CODE",{});var Ai=l(Ms);Nn=o(Ai,"ViTFeatureExtractor"),Ai.forEach(s),In=o(co," para crear tu extractor de caracter\xEDsticas personalizado:"),co.forEach(s),Ot=_(e),w(ma.$$.fragment,e),St=_(e),Ie=n(e,"P",{});var po=l(Ie);Rn=o(po,"Para las entradas de audio, puedes crear un "),As=n(po,"CODE",{});var Oi=l(As);Un=o(Oi,"Wav2Vec2FeatureExtractor"),Oi.forEach(s),Qn=o(po," y personalizar los par\xE1metros de una forma similar:"),po.forEach(s),Vt=_(e),w(fa.$$.fragment,e),Lt=_(e),qe=n(e,"H2",{class:!0});var uo=l(qe);Re=n(uo,"A",{id:!0,class:!0,href:!0});var Si=l(Re);Os=n(Si,"SPAN",{});var Vi=l(Os);w(_a.$$.fragment,Vi),Vi.forEach(s),Si.forEach(s),Hn=_(uo),Ss=n(uo,"SPAN",{});var Li=l(Ss);Jn=o(Li,"Procesador"),Li.forEach(s),uo.forEach(s),Wt=_(e),Z=n(e,"P",{});var me=l(Z);Xn=o(me,"Para modelos que son compatibles con tareas multimodales, \u{1F917} Transformers ofrece una clase "),Vs=n(me,"EM",{});var Wi=l(Vs);Gn=o(Wi,"procesador"),Wi.forEach(s),Kn=o(me," que agrupa un extractor de caracter\xEDsticas y un "),Ls=n(me,"EM",{});var Ni=l(Ls);Yn=o(Ni,"tokenizer"),Ni.forEach(s),Zn=o(me," en el mismo objeto. Por ejemplo, probemos a usar el procesador "),Ws=n(me,"CODE",{});var Ii=l(Ws);el=o(Ii,"Wav2Vec2Processor"),Ii.forEach(s),al=o(me," para una tarea de reconocimiento de voz (ASR). Un ASR transcribe el audio a texto, por lo que necesitaremos un extractor de caracter\xEDsticas y un "),Ns=n(me,"EM",{});var Ri=l(Ns);sl=o(Ri,"tokenizer"),Ri.forEach(s),tl=o(me,"."),me.forEach(s),Nt=_(e),wa=n(e,"P",{});var Ui=l(wa);ol=o(Ui,"Crea un extractor de caracter\xEDsticas para manejar la entrada de audio:"),Ui.forEach(s),It=_(e),w(ha.$$.fragment,e),Rt=_(e),Ue=n(e,"P",{});var mo=l(Ue);rl=o(mo,"Crea un "),Is=n(mo,"EM",{});var Qi=l(Is);nl=o(Qi,"tokenizer"),Qi.forEach(s),ll=o(mo," para manejar la entrada de texto:"),mo.forEach(s),Ut=_(e),w(ga.$$.fragment,e),Qt=_(e),de=n(e,"P",{});var Fa=l(de);il=o(Fa,"Puedes combinar el extractor de caracter\xEDsticas y el "),Rs=n(Fa,"EM",{});var Hi=l(Rs);cl=o(Hi,"tokenizer"),Hi.forEach(s),pl=o(Fa," en el "),Us=n(Fa,"CODE",{});var Ji=l(Us);dl=o(Ji,"Wav2Vec2Processor"),Ji.forEach(s),ul=o(Fa,":"),Fa.forEach(s),Ht=_(e),w($a.$$.fragment,e),Jt=_(e),Qe=n(e,"P",{});var fo=l(Qe);ml=o(fo,"Con dos clases base (la configuraci\xF3n y el modelo) y una clase de preprocesamiento adicional ("),Qs=n(fo,"EM",{});var Xi=l(Qs);fl=o(Xi,"tokenizer"),Xi.forEach(s),_l=o(fo,", extractor de caracter\xEDsticas o procesador), puedes crear cualquiera de los modelos compatibles con \u{1F917} Transformers. Cada una de estas clases son configurables, permiti\xE9ndote usar sus atributos espec\xEDficos. Puedes crear un modelo para entrenarlo de una forma f\xE1cil, o modificar un modelo preentrenado disponible para especializarlo."),fo.forEach(s),this.h()},h(){q(p,"name","hf:doc:metadata"),q(p,"content",JSON.stringify(_c)),q(h,"id","crea-una-arquitectura-personalizada"),q(h,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(h,"href","#crea-una-arquitectura-personalizada"),q(u,"class","relative group"),q(P,"href","model_doc/auto"),q(je,"id","configuracin"),q(je,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(je,"href","#configuracin"),q(_e,"class","relative group"),q(Ea,"href","main_classes/configuration"),q(qa,"href","model_doc/distilbert"),q(De,"id","modelo"),q(De,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(De,"href","#modelo"),q($e,"class","relative group"),q(ja,"href","main_classes/models"),q(sa,"href","https://pytorch.org/docs/stable/generated/torch.nn.Module.html"),q(sa,"rel","nofollow"),q(ta,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),q(ta,"rel","nofollow"),q(oa,"href","https://flax.readthedocs.io/en/latest/flax.linen.html#module"),q(oa,"rel","nofollow"),q(Pe,"id","cabezas-de-modelo"),q(Pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(Pe,"href","#cabezas-de-modelo"),q(ve,"class","relative group"),q(Fe,"id","tokenizer"),q(Fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(Fe,"href","#tokenizer"),q(be,"class","relative group"),q(ka,"href","main_classes/tokenizer"),q(la,"href","https://huggingface.co/docs/tokenizers/python/latest/"),q(la,"rel","nofollow"),q(Le,"id","extractor-de-caractersticas"),q(Le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(Le,"href","#extractor-de-caractersticas"),q(Ee,"class","relative group"),q(za,"href","model_doc/vit"),q(Re,"id","procesador"),q(Re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(Re,"href","#procesador"),q(qe,"class","relative group")},m(e,i){a(document.head,p),c(e,$,i),c(e,u,i),a(u,h),a(h,b),y(v,b,null),a(u,k),a(u,F),a(F,g),c(e,L,i),c(e,j,i),a(j,S),a(j,P),a(P,M),a(M,B),a(j,T),a(j,A),a(A,U),a(j,I),a(j,O),a(O,V),a(j,d),c(e,m,i),c(e,E,i),a(E,H),a(H,W),a(E,K),a(E,te),a(te,fe),a(E,$o),a(E,Ba),a(Ba,vo),a(E,bo),a(E,Ma),a(Ma,Eo),a(E,qo),a(E,Aa),a(Aa,jo),c(e,Zs,i),c(e,_e,i),a(_e,je),a(je,Oa),y(Je,Oa,null),a(_e,ko),a(_e,Sa),a(Sa,zo),c(e,et,i),c(e,X,i),a(X,wo),a(X,Ea),a(Ea,yo),a(X,Co),a(X,Va),a(Va,Do),a(X,xo),a(X,La),a(La,Po),a(X,To),a(X,Wa),a(Wa,Fo),a(X,Bo),a(X,Na),a(Na,Mo),a(X,Ao),c(e,at,i),c(e,ne,i),a(ne,Oo),a(ne,qa),a(qa,So),a(ne,Vo),a(ne,Ia),a(Ia,Lo),a(ne,Wo),c(e,st,i),y(Xe,e,i),c(e,tt,i),c(e,he,i),a(he,Ra),a(Ra,No),a(he,Io),a(he,Ua),a(Ua,Ro),a(he,Uo),c(e,ot,i),c(e,ke,i),a(ke,Ge),a(Ge,Qo),a(Ge,Qa),a(Qa,Ho),a(Ge,Jo),a(ke,Xo),a(ke,ge),a(ge,Go),a(ge,Ha),a(Ha,Ko),a(ge,Yo),a(ge,Ja),a(Ja,Zo),a(ge,er),c(e,rt,i),y(Ke,e,i),c(e,nt,i),c(e,ze,i),a(ze,ar),a(ze,Xa),a(Xa,sr),a(ze,tr),c(e,lt,i),y(Ye,e,i),c(e,it,i),c(e,we,i),a(we,or),a(we,Ga),a(Ga,rr),a(we,nr),c(e,ct,i),y(Ze,e,i),c(e,pt,i),c(e,ye,i),a(ye,lr),a(ye,Ka),a(Ka,ir),a(ye,cr),c(e,dt,i),y(ea,e,i),c(e,ut,i),y(Ce,e,i),c(e,mt,i),c(e,$e,i),a($e,De),a(De,Ya),y(aa,Ya,null),a($e,pr),a($e,Za),a(Za,dr),c(e,ft,i),c(e,Q,i),a(Q,ur),a(Q,ja),a(ja,mr),a(Q,fr),a(Q,es),a(es,_r),a(Q,hr),a(Q,as),a(as,gr),a(Q,$r),a(Q,ss),a(ss,vr),a(Q,br),a(Q,ts),a(ts,Er),a(Q,qr),a(Q,sa),a(sa,os),a(os,jr),a(Q,kr),a(Q,ta),a(ta,rs),a(rs,zr),a(Q,wr),a(Q,oa),a(oa,ns),a(ns,yr),a(Q,Cr),c(e,_t,i),y(xe,e,i),c(e,ht,i),c(e,ve,i),a(ve,Pe),a(Pe,ls),y(ra,ls,null),a(ve,Dr),a(ve,is),a(is,xr),c(e,gt,i),c(e,le,i),a(le,Pr),a(le,cs),a(cs,Tr),a(le,Fr),a(le,ps),a(ps,Br),a(le,Mr),c(e,$t,i),y(Te,e,i),c(e,vt,i),c(e,be,i),a(be,Fe),a(Fe,ds),y(na,ds,null),a(be,Ar),a(be,us),a(us,Or),c(e,bt,i),c(e,ie,i),a(ie,Sr),a(ie,ka),a(ka,Vr),a(ie,Lr),a(ie,ms),a(ms,Wr),a(ie,Nr),c(e,Et,i),c(e,Be,i),a(Be,Me),a(Me,fs),a(fs,Ir),a(Me,Rr),a(Me,_s),a(_s,Ur),a(Me,Qr),a(Be,Hr),a(Be,Y),a(Y,hs),a(hs,Jr),a(Y,Xr),a(Y,gs),a(gs,Gr),a(Y,Kr),a(Y,la),a(la,Yr),a(Y,Zr),a(Y,$s),a($s,en),a(Y,an),a(Y,vs),a(vs,sn),a(Y,tn),c(e,qt,i),c(e,Ae,i),a(Ae,on),a(Ae,bs),a(bs,rn),a(Ae,nn),c(e,jt,i),y(Oe,e,i),c(e,kt,i),c(e,Se,i),a(Se,ln),a(Se,Es),a(Es,cn),a(Se,pn),c(e,zt,i),y(ia,e,i),c(e,wt,i),c(e,G,i),a(G,dn),a(G,qs),a(qs,un),a(G,mn),a(G,js),a(js,fn),a(G,_n),a(G,ks),a(ks,hn),a(G,gn),a(G,zs),a(zs,$n),a(G,vn),a(G,ws),a(ws,bn),a(G,En),c(e,yt,i),y(ca,e,i),c(e,Ct,i),c(e,ce,i),a(ce,qn),a(ce,ys),a(ys,jn),a(ce,kn),a(ce,Cs),a(Cs,zn),a(ce,wn),c(e,Dt,i),y(pa,e,i),c(e,xt,i),y(Ve,e,i),c(e,Pt,i),c(e,Ee,i),a(Ee,Le),a(Le,Ds),y(da,Ds,null),a(Ee,yn),a(Ee,xs),a(xs,Cn),c(e,Tt,i),c(e,ee,i),a(ee,Dn),a(ee,Ps),a(Ps,xn),a(ee,Pn),a(ee,Ts),a(Ts,Tn),a(ee,Fn),a(ee,Fs),a(Fs,Bn),a(ee,Mn),c(e,Ft,i),c(e,pe,i),a(pe,An),a(pe,Bs),a(Bs,On),a(pe,Sn),a(pe,za),a(za,Vn),a(pe,Ln),c(e,Bt,i),y(ua,e,i),c(e,Mt,i),y(We,e,i),c(e,At,i),c(e,Ne,i),a(Ne,Wn),a(Ne,Ms),a(Ms,Nn),a(Ne,In),c(e,Ot,i),y(ma,e,i),c(e,St,i),c(e,Ie,i),a(Ie,Rn),a(Ie,As),a(As,Un),a(Ie,Qn),c(e,Vt,i),y(fa,e,i),c(e,Lt,i),c(e,qe,i),a(qe,Re),a(Re,Os),y(_a,Os,null),a(qe,Hn),a(qe,Ss),a(Ss,Jn),c(e,Wt,i),c(e,Z,i),a(Z,Xn),a(Z,Vs),a(Vs,Gn),a(Z,Kn),a(Z,Ls),a(Ls,Yn),a(Z,Zn),a(Z,Ws),a(Ws,el),a(Z,al),a(Z,Ns),a(Ns,sl),a(Z,tl),c(e,Nt,i),c(e,wa,i),a(wa,ol),c(e,It,i),y(ha,e,i),c(e,Rt,i),c(e,Ue,i),a(Ue,rl),a(Ue,Is),a(Is,nl),a(Ue,ll),c(e,Ut,i),y(ga,e,i),c(e,Qt,i),c(e,de,i),a(de,il),a(de,Rs),a(Rs,cl),a(de,pl),a(de,Us),a(Us,dl),a(de,ul),c(e,Ht,i),y($a,e,i),c(e,Jt,i),c(e,Qe,i),a(Qe,ml),a(Qe,Qs),a(Qs,fl),a(Qe,_l),Xt=!0},p(e,[i]){const va={};i&2&&(va.$$scope={dirty:i,ctx:e}),Ce.$set(va);const Hs={};i&2&&(Hs.$$scope={dirty:i,ctx:e}),xe.$set(Hs);const Js={};i&2&&(Js.$$scope={dirty:i,ctx:e}),Te.$set(Js);const Xs={};i&2&&(Xs.$$scope={dirty:i,ctx:e}),Oe.$set(Xs);const oe={};i&2&&(oe.$$scope={dirty:i,ctx:e}),Ve.$set(oe);const Gs={};i&2&&(Gs.$$scope={dirty:i,ctx:e}),We.$set(Gs)},i(e){Xt||(C(v.$$.fragment,e),C(Je.$$.fragment,e),C(Xe.$$.fragment,e),C(Ke.$$.fragment,e),C(Ye.$$.fragment,e),C(Ze.$$.fragment,e),C(ea.$$.fragment,e),C(Ce.$$.fragment,e),C(aa.$$.fragment,e),C(xe.$$.fragment,e),C(ra.$$.fragment,e),C(Te.$$.fragment,e),C(na.$$.fragment,e),C(Oe.$$.fragment,e),C(ia.$$.fragment,e),C(ca.$$.fragment,e),C(pa.$$.fragment,e),C(Ve.$$.fragment,e),C(da.$$.fragment,e),C(ua.$$.fragment,e),C(We.$$.fragment,e),C(ma.$$.fragment,e),C(fa.$$.fragment,e),C(_a.$$.fragment,e),C(ha.$$.fragment,e),C(ga.$$.fragment,e),C($a.$$.fragment,e),Xt=!0)},o(e){D(v.$$.fragment,e),D(Je.$$.fragment,e),D(Xe.$$.fragment,e),D(Ke.$$.fragment,e),D(Ye.$$.fragment,e),D(Ze.$$.fragment,e),D(ea.$$.fragment,e),D(Ce.$$.fragment,e),D(aa.$$.fragment,e),D(xe.$$.fragment,e),D(ra.$$.fragment,e),D(Te.$$.fragment,e),D(na.$$.fragment,e),D(Oe.$$.fragment,e),D(ia.$$.fragment,e),D(ca.$$.fragment,e),D(pa.$$.fragment,e),D(Ve.$$.fragment,e),D(da.$$.fragment,e),D(ua.$$.fragment,e),D(We.$$.fragment,e),D(ma.$$.fragment,e),D(fa.$$.fragment,e),D(_a.$$.fragment,e),D(ha.$$.fragment,e),D(ga.$$.fragment,e),D($a.$$.fragment,e),Xt=!1},d(e){s(p),e&&s($),e&&s(u),x(v),e&&s(L),e&&s(j),e&&s(m),e&&s(E),e&&s(Zs),e&&s(_e),x(Je),e&&s(et),e&&s(X),e&&s(at),e&&s(ne),e&&s(st),x(Xe,e),e&&s(tt),e&&s(he),e&&s(ot),e&&s(ke),e&&s(rt),x(Ke,e),e&&s(nt),e&&s(ze),e&&s(lt),x(Ye,e),e&&s(it),e&&s(we),e&&s(ct),x(Ze,e),e&&s(pt),e&&s(ye),e&&s(dt),x(ea,e),e&&s(ut),x(Ce,e),e&&s(mt),e&&s($e),x(aa),e&&s(ft),e&&s(Q),e&&s(_t),x(xe,e),e&&s(ht),e&&s(ve),x(ra),e&&s(gt),e&&s(le),e&&s($t),x(Te,e),e&&s(vt),e&&s(be),x(na),e&&s(bt),e&&s(ie),e&&s(Et),e&&s(Be),e&&s(qt),e&&s(Ae),e&&s(jt),x(Oe,e),e&&s(kt),e&&s(Se),e&&s(zt),x(ia,e),e&&s(wt),e&&s(G),e&&s(yt),x(ca,e),e&&s(Ct),e&&s(ce),e&&s(Dt),x(pa,e),e&&s(xt),x(Ve,e),e&&s(Pt),e&&s(Ee),x(da),e&&s(Tt),e&&s(ee),e&&s(Ft),e&&s(pe),e&&s(Bt),x(ua,e),e&&s(Mt),x(We,e),e&&s(At),e&&s(Ne),e&&s(Ot),x(ma,e),e&&s(St),e&&s(Ie),e&&s(Vt),x(fa,e),e&&s(Lt),e&&s(qe),x(_a),e&&s(Wt),e&&s(Z),e&&s(Nt),e&&s(wa),e&&s(It),x(ha,e),e&&s(Rt),e&&s(Ue),e&&s(Ut),x(ga,e),e&&s(Qt),e&&s(de),e&&s(Ht),x($a,e),e&&s(Jt),e&&s(Qe)}}}const _c={local:"crea-una-arquitectura-personalizada",sections:[{local:"configuracin",title:"Configuraci\xF3n"},{local:"modelo",sections:[{local:"cabezas-de-modelo",title:"Cabezas de modelo "}],title:"Modelo"},{local:"tokenizer",title:"Tokenizer"},{local:"extractor-de-caractersticas",title:"Extractor de Caracter\xEDsticas "},{local:"procesador",title:"Procesador"}],title:"Crea una arquitectura personalizada"};function hc(N){return ac(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class jc extends Ki{constructor(p){super();Yi(this,p,hc,fc,Zi,{})}}export{jc as default,_c as metadata};
