import{S as Ya,i as Ja,s as Ka,e as r,k as m,w as d,t as l,M as Wa,c as a,d as t,m as f,a as n,x as c,h as i,b as u,G as s,g as p,y as v,q as g,o as _,B as w,v as Qa}from"../chunks/vendor-hf-doc-builder.js";import{T as Ra}from"../chunks/Tip-hf-doc-builder.js";import{Y as Va}from"../chunks/Youtube-hf-doc-builder.js";import{I as xe}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as T}from"../chunks/CodeBlock-hf-doc-builder.js";function Xa(Be){let h,A,$,k,j;return{c(){h=r("p"),A=l("Refer to the Performance "),$=r("a"),k=l("guide"),j=l(" for more details about memory-saving techniques."),this.h()},l(b){h=a(b,"P",{});var y=n(h);A=i(y,"Refer to the Performance "),$=a(y,"A",{href:!0});var C=n($);k=i(C,"guide"),C.forEach(t),j=i(y," for more details about memory-saving techniques."),y.forEach(t),this.h()},h(){u($,"href","performance")},m(b,y){p(b,h,y),s(h,A),s(h,$),s($,k),s(h,j)},d(b){b&&t(h)}}}function Za(Be){let h,A,$,k,j;return{c(){h=r("p"),A=l("By default, the tokenizer creates an "),$=r("code"),k=l("attention_mask"),j=l(" for you based on your specific tokenizer\u2019s defaults.")},l(b){h=a(b,"P",{});var y=n(h);A=i(y,"By default, the tokenizer creates an "),$=a(y,"CODE",{});var C=n($);k=i(C,"attention_mask"),C.forEach(t),j=i(y," for you based on your specific tokenizer\u2019s defaults."),y.forEach(t)},m(b,y){p(b,h,y),s(h,A),s(h,$),s($,k),s(h,j)},d(b){b&&t(h)}}}function en(Be){let h,A,$,k,j,b,y,C,Ks,Lt,Le,Ws,Nt,ne,Gt,Ne,F,Qs,le,Xs,Zs,ie,eo,to,pe,so,oo,Ht,me,Ot,S,pt,fe,ro,ue,ao,no,lo,mt,he,io,Ge,po,mo,zt,H,fo,de,uo,ho,Rt,U,O,ft,ce,co,ut,vo,Vt,He,go,Yt,ve,Jt,z,_o,Oe,wo,$o,Kt,q,R,ht,ge,bo,dt,yo,Wt,ze,ko,Qt,_e,Xt,Re,Eo,Zt,V,D,jo,Ve,ct,To,Ao,Ye,Po,Co,Fo,M,Io,Je,vt,So,Uo,Ke,qo,Do,es,Y,ts,x,J,gt,we,Mo,_t,xo,ss,K,Bo,$e,Lo,No,os,We,I,Go,wt,Ho,Oo,be,$t,zo,Ro,Qe,Vo,Yo,rs,ye,as,Xe,B,Jo,bt,Ko,Wo,Ze,Qo,Xo,ns,ke,ls,L,W,yt,Ee,Zo,kt,er,is,Q,tr,Et,sr,or,ps,je,ms,et,rr,fs,Te,us,N,X,jt,Ae,ar,Tt,nr,hs,tt,lr,ds,Pe,cs,st,ir,vs,Ce,gs,ot,pr,_s,Fe,ws,G,Z,At,Ie,mr,Pt,fr,$s,E,ur,Ct,hr,dr,Ft,cr,vr,It,gr,_r,St,wr,$r,Ut,br,yr,bs,Se,ys,rt,kr,ks,Ue,Es,at,Er,js,qe,Ts,ee,jr,qt,Tr,Ar,As,te,Ps,De,Cs,se,Pr,Dt,Cr,Fr,Fs,oe,Mt,Ir,Sr,xt,Ur,Is;return b=new xe({}),ne=new Va({props:{id:"S2EEG3JIt2A"}}),me=new Va({props:{id:"_PAli-V4wj0"}}),ce=new xe({}),ve=new T({props:{code:`ValueError: Connection error, and we cannot find the requested files in the cached path.
Please try again or make sure your Internet connection is on.`,highlighted:`ValueError: Connection error, <span class="hljs-built_in">and</span> we cannot <span class="hljs-keyword">find</span> the requested <span class="hljs-keyword">files</span> in the cached path.
Please <span class="hljs-keyword">try</span> again <span class="hljs-built_in">or</span> <span class="hljs-keyword">make</span> sure your Internet connection <span class="hljs-keyword">is</span> <span class="hljs-keyword">on</span>.`}}),ge=new xe({}),_e=new T({props:{code:"CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 11.17 GiB total capacity; 9.70 GiB already allocated; 179.81 MiB free; 9.85 GiB reserved in total by PyTorch)",highlighted:'<span class="hljs-attribute">CUDA</span> out of memory. Tried to allocate <span class="hljs-number">256</span>.<span class="hljs-number">00</span> MiB (GPU <span class="hljs-number">0</span>; <span class="hljs-number">11</span>.<span class="hljs-number">17</span> GiB total capacity; <span class="hljs-number">9</span>.<span class="hljs-number">70</span> GiB already allocated; <span class="hljs-number">179</span>.<span class="hljs-number">81</span> MiB free; <span class="hljs-number">9</span>.<span class="hljs-number">85</span> GiB reserved in total by PyTorch)'}}),Y=new Ra({props:{$$slots:{default:[Xa]},$$scope:{ctx:Be}}}),we=new xe({}),ye=new T({props:{code:`from transformers import TFPreTrainedModel
from tensorflow import keras

model.save_weights("some_folder/tf_model.h5")
model = TFPreTrainedModel.from_pretrained("some_folder")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFPreTrainedModel
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> tensorflow <span class="hljs-keyword">import</span> keras

<span class="hljs-meta">&gt;&gt;&gt; </span>model.save_weights(<span class="hljs-string">&quot;some_folder/tf_model.h5&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFPreTrainedModel.from_pretrained(<span class="hljs-string">&quot;some_folder&quot;</span>)`}}),ke=new T({props:{code:`from transformers import TFPreTrainedModel

model.save_pretrained("path_to/model")
model = TFPreTrainedModel.from_pretrained("path_to/model")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFPreTrainedModel

<span class="hljs-meta">&gt;&gt;&gt; </span>model.save_pretrained(<span class="hljs-string">&quot;path_to/model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFPreTrainedModel.from_pretrained(<span class="hljs-string">&quot;path_to/model&quot;</span>)`}}),Ee=new xe({}),je=new T({props:{code:"ImportError: cannot import name 'ImageGPTFeatureExtractor' from 'transformers' (unknown location)",highlighted:'ImportError: cannot <span class="hljs-keyword">import</span> <span class="hljs-type">name</span> <span class="hljs-string">&#x27;ImageGPTFeatureExtractor&#x27;</span> <span class="hljs-keyword">from</span> <span class="hljs-string">&#x27;transformers&#x27;</span> (<span class="hljs-type">unknown</span> <span class="hljs-keyword">location</span>)'}}),Te=new T({props:{code:"pip install transformers --upgrade",highlighted:"pip install transformers --upgrade"}}),Ae=new xe({}),Pe=new T({props:{code:"RuntimeError: CUDA error: device-side assert triggered",highlighted:'RuntimeError: CUDA <span class="hljs-literal">error</span>: device-<span class="hljs-literal">side</span> <span class="hljs-keyword">assert</span> triggered'}}),Ce=new T({props:{code:`import os

os.environ["CUDA_VISIBLE_DEVICES"] = ""`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> os

<span class="hljs-meta">&gt;&gt;&gt; </span>os.environ[<span class="hljs-string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="hljs-string">&quot;&quot;</span>`}}),Fe=new T({props:{code:`import os

os.environ["CUDA_LAUNCH_BLOCKING"] = "1"`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> os

<span class="hljs-meta">&gt;&gt;&gt; </span>os.environ[<span class="hljs-string">&quot;CUDA_LAUNCH_BLOCKING&quot;</span>] = <span class="hljs-string">&quot;1&quot;</span>`}}),Ie=new xe({}),Se=new T({props:{code:`from transformers import AutoModelForSequenceClassification
import torch

model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased")
model.config.pad_token_id`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.pad_token_id
<span class="hljs-number">0</span>`}}),Ue=new T({props:{code:`input_ids = torch.tensor([[7592, 2057, 2097, 2393, 9611, 2115], [7592, 0, 0, 0, 0, 0]])
output = model(input_ids)
print(output.logits)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>input_ids = torch.tensor([[<span class="hljs-number">7592</span>, <span class="hljs-number">2057</span>, <span class="hljs-number">2097</span>, <span class="hljs-number">2393</span>, <span class="hljs-number">9611</span>, <span class="hljs-number">2115</span>], [<span class="hljs-number">7592</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]])
<span class="hljs-meta">&gt;&gt;&gt; </span>output = model(input_ids)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(output.logits)
tensor([[ <span class="hljs-number">0.0082</span>, -<span class="hljs-number">0.2307</span>],
        [ <span class="hljs-number">0.1317</span>, -<span class="hljs-number">0.1683</span>]], grad_fn=&lt;AddmmBackward0&gt;)`}}),qe=new T({props:{code:`input_ids = torch.tensor([[7592]])
output = model(input_ids)
print(output.logits)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>input_ids = torch.tensor([[<span class="hljs-number">7592</span>]])
<span class="hljs-meta">&gt;&gt;&gt; </span>output = model(input_ids)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(output.logits)
tensor([[-<span class="hljs-number">0.1008</span>, -<span class="hljs-number">0.4061</span>]], grad_fn=&lt;AddmmBackward0&gt;)`}}),te=new Ra({props:{$$slots:{default:[Za]},$$scope:{ctx:Be}}}),De=new T({props:{code:`attention_mask = torch.tensor([[1, 1, 1, 1, 1, 1], [1, 0, 0, 0, 0, 0]])
output = model(input_ids, attention_mask=attention_mask)
print(output.logits)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>attention_mask = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]])
<span class="hljs-meta">&gt;&gt;&gt; </span>output = model(input_ids, attention_mask=attention_mask)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(output.logits)
tensor([[ <span class="hljs-number">0.0082</span>, -<span class="hljs-number">0.2307</span>],
        [-<span class="hljs-number">0.1008</span>, -<span class="hljs-number">0.4061</span>]], grad_fn=&lt;AddmmBackward0&gt;)`}}),{c(){h=r("meta"),A=m(),$=r("h1"),k=r("a"),j=r("span"),d(b.$$.fragment),y=m(),C=r("span"),Ks=l("Troubleshoot"),Lt=m(),Le=r("p"),Ws=l("Sometimes errors occur, but we are here to help! This guide covers some of the most common issues we\u2019ve seen and how you can resolve them. However, this guide isn\u2019t meant to be a comprehensive collection of every \u{1F917} Transformers issue. For more help with troubleshooting your issue, try:"),Nt=m(),d(ne.$$.fragment),Gt=m(),Ne=r("ol"),F=r("li"),Qs=l("Asking for help on the "),le=r("a"),Xs=l("forums"),Zs=l(". There are specific categories you can post your question to, like "),ie=r("a"),eo=l("Beginners"),to=l(" or "),pe=r("a"),so=l("\u{1F917} Transformers"),oo=l(". Make sure you write a good descriptive forum post with some reproducible code to maximize the likelihood that your problem is solved!"),Ht=m(),d(me.$$.fragment),Ot=m(),S=r("ol"),pt=r("li"),fe=r("p"),ro=l("Create an "),ue=r("a"),ao=l("Issue"),no=l(" on the \u{1F917} Transformers repository if it is a bug related to the library. Try to include as much information describing the bug as possible to help us better figure out what\u2019s wrong and how we can fix it."),lo=m(),mt=r("li"),he=r("p"),io=l("Check the "),Ge=r("a"),po=l("Migration"),mo=l(" guide if you use an older version of \u{1F917} Transformers since some important changes have been introduced between versions."),zt=m(),H=r("p"),fo=l("For more details about troubleshooting and getting help, take a look at "),de=r("a"),uo=l("Chapter 8"),ho=l(" of the Hugging Face course."),Rt=m(),U=r("h2"),O=r("a"),ft=r("span"),d(ce.$$.fragment),co=m(),ut=r("span"),vo=l("Firewalled environments"),Vt=m(),He=r("p"),go=l("Some GPU instances on cloud and intranet setups are firewalled to external connections, resulting in a connection error. When your script attempts to download model weights or datasets, the download will hang and then timeout with the following message:"),Yt=m(),d(ve.$$.fragment),Jt=m(),z=r("p"),_o=l("In this case, you should try to run \u{1F917} Transformers on "),Oe=r("a"),wo=l("offline mode"),$o=l(" to avoid the connection error."),Kt=m(),q=r("h2"),R=r("a"),ht=r("span"),d(ge.$$.fragment),bo=m(),dt=r("span"),yo=l("CUDA out of memory"),Wt=m(),ze=r("p"),ko=l("Training large models with millions of parameters can be challenging without the appropriate hardware. A common error you may encounter when the GPU runs out of memory is:"),Qt=m(),d(_e.$$.fragment),Xt=m(),Re=r("p"),Eo=l("Here are some potential solutions you can try to lessen memory use:"),Zt=m(),V=r("ul"),D=r("li"),jo=l("Reduce the "),Ve=r("a"),ct=r("code"),To=l("per_device_train_batch_size"),Ao=l(" value in "),Ye=r("a"),Po=l("TrainingArguments"),Co=l("."),Fo=m(),M=r("li"),Io=l("Try using "),Je=r("a"),vt=r("code"),So=l("gradient_accumulation_steps"),Uo=l(" in "),Ke=r("a"),qo=l("TrainingArguments"),Do=l(" to effectively increase overall batch size."),es=m(),d(Y.$$.fragment),ts=m(),x=r("h2"),J=r("a"),gt=r("span"),d(we.$$.fragment),Mo=m(),_t=r("span"),xo=l("Unable to load a saved TensorFlow model"),ss=m(),K=r("p"),Bo=l("TensorFlow\u2019s "),$e=r("a"),Lo=l("model.save"),No=l(" method will save the entire model - architecture, weights, training configuration - in a single file. However, when you load the model file again, you may run into an error because \u{1F917} Transformers may not load all the TensorFlow-related objects in the model file. To avoid issues with saving and loading TensorFlow models, we recommend you:"),os=m(),We=r("ul"),I=r("li"),Go=l("Save the model weights as a "),wt=r("code"),Ho=l("h5"),Oo=l(" file extension with "),be=r("a"),$t=r("code"),zo=l("model.save_weights"),Ro=l(" and then reload the model with "),Qe=r("a"),Vo=l("from_pretrained()"),Yo=l(":"),rs=m(),d(ye.$$.fragment),as=m(),Xe=r("ul"),B=r("li"),Jo=l("Save the model with "),bt=r("code"),Ko=l("~TFPretrainedModel.save_pretrained"),Wo=l(" and load it again with "),Ze=r("a"),Qo=l("from_pretrained()"),Xo=l(":"),ns=m(),d(ke.$$.fragment),ls=m(),L=r("h2"),W=r("a"),yt=r("span"),d(Ee.$$.fragment),Zo=m(),kt=r("span"),er=l("ImportError"),is=m(),Q=r("p"),tr=l("Another common error you may encounter, especially if it is a newly released model, is "),Et=r("code"),sr=l("ImportError"),or=l(":"),ps=m(),d(je.$$.fragment),ms=m(),et=r("p"),rr=l("For these error types, check to make sure you have the latest version of \u{1F917} Transformers installed to access the most recent models:"),fs=m(),d(Te.$$.fragment),us=m(),N=r("h2"),X=r("a"),jt=r("span"),d(Ae.$$.fragment),ar=m(),Tt=r("span"),nr=l("CUDA error: device-side assert triggered"),hs=m(),tt=r("p"),lr=l("Sometimes you may run into a generic CUDA error about an error in the device code."),ds=m(),d(Pe.$$.fragment),cs=m(),st=r("p"),ir=l("You should try to run the code on a CPU first to get a more descriptive error message. Add the following environment variable to the beginning of your code to switch to a CPU:"),vs=m(),d(Ce.$$.fragment),gs=m(),ot=r("p"),pr=l("Another option is to get a better traceback from the GPU. Add the following environment variable to the beginning of your code to get the traceback to point to the source of the error:"),_s=m(),d(Fe.$$.fragment),ws=m(),G=r("h2"),Z=r("a"),At=r("span"),d(Ie.$$.fragment),mr=m(),Pt=r("span"),fr=l("Incorrect output when padding tokens aren't masked"),$s=m(),E=r("p"),ur=l("In some cases, the output "),Ct=r("code"),hr=l("hidden_state"),dr=l(" may be incorrect if the "),Ft=r("code"),cr=l("input_ids"),vr=l(" include padding tokens. To demonstrate, load a model and tokenizer. You can access a model\u2019s "),It=r("code"),gr=l("pad_token_id"),_r=l(" to see its value. The "),St=r("code"),wr=l("pad_token_id"),$r=l(" may be "),Ut=r("code"),br=l("None"),yr=l(" for some models, but you can always manually set it."),bs=m(),d(Se.$$.fragment),ys=m(),rt=r("p"),kr=l("The following example shows the output without masking the padding tokens:"),ks=m(),d(Ue.$$.fragment),Es=m(),at=r("p"),Er=l("Here is the actual output of the second sequence:"),js=m(),d(qe.$$.fragment),Ts=m(),ee=r("p"),jr=l("Most of the time, you should provide an "),qt=r("code"),Tr=l("attention_mask"),Ar=l(" to your model to ignore the padding tokens to avoid this silent error. Now the output of the second sequence matches its actual output:"),As=m(),d(te.$$.fragment),Ps=m(),d(De.$$.fragment),Cs=m(),se=r("p"),Pr=l("\u{1F917} Transformers doesn\u2019t automatically create an "),Dt=r("code"),Cr=l("attention_mask"),Fr=l(" to mask a padding token if it is provided because:"),Fs=m(),oe=r("ul"),Mt=r("li"),Ir=l("Some models don\u2019t have a padding token."),Sr=m(),xt=r("li"),Ur=l("For some use-cases, users want a model to attend to a padding token."),this.h()},l(e){const o=Wa('[data-svelte="svelte-1phssyn"]',document.head);h=a(o,"META",{name:!0,content:!0}),o.forEach(t),A=f(e),$=a(e,"H1",{class:!0});var Me=n($);k=a(Me,"A",{id:!0,class:!0,href:!0});var Bt=n(k);j=a(Bt,"SPAN",{});var qr=n(j);c(b.$$.fragment,qr),qr.forEach(t),Bt.forEach(t),y=f(Me),C=a(Me,"SPAN",{});var Dr=n(C);Ks=i(Dr,"Troubleshoot"),Dr.forEach(t),Me.forEach(t),Lt=f(e),Le=a(e,"P",{});var Mr=n(Le);Ws=i(Mr,"Sometimes errors occur, but we are here to help! This guide covers some of the most common issues we\u2019ve seen and how you can resolve them. However, this guide isn\u2019t meant to be a comprehensive collection of every \u{1F917} Transformers issue. For more help with troubleshooting your issue, try:"),Mr.forEach(t),Nt=f(e),c(ne.$$.fragment,e),Gt=f(e),Ne=a(e,"OL",{});var xr=n(Ne);F=a(xr,"LI",{});var re=n(F);Qs=i(re,"Asking for help on the "),le=a(re,"A",{href:!0,rel:!0});var Br=n(le);Xs=i(Br,"forums"),Br.forEach(t),Zs=i(re,". There are specific categories you can post your question to, like "),ie=a(re,"A",{href:!0,rel:!0});var Lr=n(ie);eo=i(Lr,"Beginners"),Lr.forEach(t),to=i(re," or "),pe=a(re,"A",{href:!0,rel:!0});var Nr=n(pe);so=i(Nr,"\u{1F917} Transformers"),Nr.forEach(t),oo=i(re,". Make sure you write a good descriptive forum post with some reproducible code to maximize the likelihood that your problem is solved!"),re.forEach(t),xr.forEach(t),Ht=f(e),c(me.$$.fragment,e),Ot=f(e),S=a(e,"OL",{start:!0});var Ss=n(S);pt=a(Ss,"LI",{});var Gr=n(pt);fe=a(Gr,"P",{});var Us=n(fe);ro=i(Us,"Create an "),ue=a(Us,"A",{href:!0,rel:!0});var Hr=n(ue);ao=i(Hr,"Issue"),Hr.forEach(t),no=i(Us," on the \u{1F917} Transformers repository if it is a bug related to the library. Try to include as much information describing the bug as possible to help us better figure out what\u2019s wrong and how we can fix it."),Us.forEach(t),Gr.forEach(t),lo=f(Ss),mt=a(Ss,"LI",{});var Or=n(mt);he=a(Or,"P",{});var qs=n(he);io=i(qs,"Check the "),Ge=a(qs,"A",{href:!0});var zr=n(Ge);po=i(zr,"Migration"),zr.forEach(t),mo=i(qs," guide if you use an older version of \u{1F917} Transformers since some important changes have been introduced between versions."),qs.forEach(t),Or.forEach(t),Ss.forEach(t),zt=f(e),H=a(e,"P",{});var Ds=n(H);fo=i(Ds,"For more details about troubleshooting and getting help, take a look at "),de=a(Ds,"A",{href:!0,rel:!0});var Rr=n(de);uo=i(Rr,"Chapter 8"),Rr.forEach(t),ho=i(Ds," of the Hugging Face course."),Ds.forEach(t),Rt=f(e),U=a(e,"H2",{class:!0});var Ms=n(U);O=a(Ms,"A",{id:!0,class:!0,href:!0});var Vr=n(O);ft=a(Vr,"SPAN",{});var Yr=n(ft);c(ce.$$.fragment,Yr),Yr.forEach(t),Vr.forEach(t),co=f(Ms),ut=a(Ms,"SPAN",{});var Jr=n(ut);vo=i(Jr,"Firewalled environments"),Jr.forEach(t),Ms.forEach(t),Vt=f(e),He=a(e,"P",{});var Kr=n(He);go=i(Kr,"Some GPU instances on cloud and intranet setups are firewalled to external connections, resulting in a connection error. When your script attempts to download model weights or datasets, the download will hang and then timeout with the following message:"),Kr.forEach(t),Yt=f(e),c(ve.$$.fragment,e),Jt=f(e),z=a(e,"P",{});var xs=n(z);_o=i(xs,"In this case, you should try to run \u{1F917} Transformers on "),Oe=a(xs,"A",{href:!0});var Wr=n(Oe);wo=i(Wr,"offline mode"),Wr.forEach(t),$o=i(xs," to avoid the connection error."),xs.forEach(t),Kt=f(e),q=a(e,"H2",{class:!0});var Bs=n(q);R=a(Bs,"A",{id:!0,class:!0,href:!0});var Qr=n(R);ht=a(Qr,"SPAN",{});var Xr=n(ht);c(ge.$$.fragment,Xr),Xr.forEach(t),Qr.forEach(t),bo=f(Bs),dt=a(Bs,"SPAN",{});var Zr=n(dt);yo=i(Zr,"CUDA out of memory"),Zr.forEach(t),Bs.forEach(t),Wt=f(e),ze=a(e,"P",{});var ea=n(ze);ko=i(ea,"Training large models with millions of parameters can be challenging without the appropriate hardware. A common error you may encounter when the GPU runs out of memory is:"),ea.forEach(t),Qt=f(e),c(_e.$$.fragment,e),Xt=f(e),Re=a(e,"P",{});var ta=n(Re);Eo=i(ta,"Here are some potential solutions you can try to lessen memory use:"),ta.forEach(t),Zt=f(e),V=a(e,"UL",{});var Ls=n(V);D=a(Ls,"LI",{});var nt=n(D);jo=i(nt,"Reduce the "),Ve=a(nt,"A",{href:!0});var sa=n(Ve);ct=a(sa,"CODE",{});var oa=n(ct);To=i(oa,"per_device_train_batch_size"),oa.forEach(t),sa.forEach(t),Ao=i(nt," value in "),Ye=a(nt,"A",{href:!0});var ra=n(Ye);Po=i(ra,"TrainingArguments"),ra.forEach(t),Co=i(nt,"."),nt.forEach(t),Fo=f(Ls),M=a(Ls,"LI",{});var lt=n(M);Io=i(lt,"Try using "),Je=a(lt,"A",{href:!0});var aa=n(Je);vt=a(aa,"CODE",{});var na=n(vt);So=i(na,"gradient_accumulation_steps"),na.forEach(t),aa.forEach(t),Uo=i(lt," in "),Ke=a(lt,"A",{href:!0});var la=n(Ke);qo=i(la,"TrainingArguments"),la.forEach(t),Do=i(lt," to effectively increase overall batch size."),lt.forEach(t),Ls.forEach(t),es=f(e),c(Y.$$.fragment,e),ts=f(e),x=a(e,"H2",{class:!0});var Ns=n(x);J=a(Ns,"A",{id:!0,class:!0,href:!0});var ia=n(J);gt=a(ia,"SPAN",{});var pa=n(gt);c(we.$$.fragment,pa),pa.forEach(t),ia.forEach(t),Mo=f(Ns),_t=a(Ns,"SPAN",{});var ma=n(_t);xo=i(ma,"Unable to load a saved TensorFlow model"),ma.forEach(t),Ns.forEach(t),ss=f(e),K=a(e,"P",{});var Gs=n(K);Bo=i(Gs,"TensorFlow\u2019s "),$e=a(Gs,"A",{href:!0,rel:!0});var fa=n($e);Lo=i(fa,"model.save"),fa.forEach(t),No=i(Gs," method will save the entire model - architecture, weights, training configuration - in a single file. However, when you load the model file again, you may run into an error because \u{1F917} Transformers may not load all the TensorFlow-related objects in the model file. To avoid issues with saving and loading TensorFlow models, we recommend you:"),Gs.forEach(t),os=f(e),We=a(e,"UL",{});var ua=n(We);I=a(ua,"LI",{});var ae=n(I);Go=i(ae,"Save the model weights as a "),wt=a(ae,"CODE",{});var ha=n(wt);Ho=i(ha,"h5"),ha.forEach(t),Oo=i(ae," file extension with "),be=a(ae,"A",{href:!0,rel:!0});var da=n(be);$t=a(da,"CODE",{});var ca=n($t);zo=i(ca,"model.save_weights"),ca.forEach(t),da.forEach(t),Ro=i(ae," and then reload the model with "),Qe=a(ae,"A",{href:!0});var va=n(Qe);Vo=i(va,"from_pretrained()"),va.forEach(t),Yo=i(ae,":"),ae.forEach(t),ua.forEach(t),rs=f(e),c(ye.$$.fragment,e),as=f(e),Xe=a(e,"UL",{});var ga=n(Xe);B=a(ga,"LI",{});var it=n(B);Jo=i(it,"Save the model with "),bt=a(it,"CODE",{});var _a=n(bt);Ko=i(_a,"~TFPretrainedModel.save_pretrained"),_a.forEach(t),Wo=i(it," and load it again with "),Ze=a(it,"A",{href:!0});var wa=n(Ze);Qo=i(wa,"from_pretrained()"),wa.forEach(t),Xo=i(it,":"),it.forEach(t),ga.forEach(t),ns=f(e),c(ke.$$.fragment,e),ls=f(e),L=a(e,"H2",{class:!0});var Hs=n(L);W=a(Hs,"A",{id:!0,class:!0,href:!0});var $a=n(W);yt=a($a,"SPAN",{});var ba=n(yt);c(Ee.$$.fragment,ba),ba.forEach(t),$a.forEach(t),Zo=f(Hs),kt=a(Hs,"SPAN",{});var ya=n(kt);er=i(ya,"ImportError"),ya.forEach(t),Hs.forEach(t),is=f(e),Q=a(e,"P",{});var Os=n(Q);tr=i(Os,"Another common error you may encounter, especially if it is a newly released model, is "),Et=a(Os,"CODE",{});var ka=n(Et);sr=i(ka,"ImportError"),ka.forEach(t),or=i(Os,":"),Os.forEach(t),ps=f(e),c(je.$$.fragment,e),ms=f(e),et=a(e,"P",{});var Ea=n(et);rr=i(Ea,"For these error types, check to make sure you have the latest version of \u{1F917} Transformers installed to access the most recent models:"),Ea.forEach(t),fs=f(e),c(Te.$$.fragment,e),us=f(e),N=a(e,"H2",{class:!0});var zs=n(N);X=a(zs,"A",{id:!0,class:!0,href:!0});var ja=n(X);jt=a(ja,"SPAN",{});var Ta=n(jt);c(Ae.$$.fragment,Ta),Ta.forEach(t),ja.forEach(t),ar=f(zs),Tt=a(zs,"SPAN",{});var Aa=n(Tt);nr=i(Aa,"CUDA error: device-side assert triggered"),Aa.forEach(t),zs.forEach(t),hs=f(e),tt=a(e,"P",{});var Pa=n(tt);lr=i(Pa,"Sometimes you may run into a generic CUDA error about an error in the device code."),Pa.forEach(t),ds=f(e),c(Pe.$$.fragment,e),cs=f(e),st=a(e,"P",{});var Ca=n(st);ir=i(Ca,"You should try to run the code on a CPU first to get a more descriptive error message. Add the following environment variable to the beginning of your code to switch to a CPU:"),Ca.forEach(t),vs=f(e),c(Ce.$$.fragment,e),gs=f(e),ot=a(e,"P",{});var Fa=n(ot);pr=i(Fa,"Another option is to get a better traceback from the GPU. Add the following environment variable to the beginning of your code to get the traceback to point to the source of the error:"),Fa.forEach(t),_s=f(e),c(Fe.$$.fragment,e),ws=f(e),G=a(e,"H2",{class:!0});var Rs=n(G);Z=a(Rs,"A",{id:!0,class:!0,href:!0});var Ia=n(Z);At=a(Ia,"SPAN",{});var Sa=n(At);c(Ie.$$.fragment,Sa),Sa.forEach(t),Ia.forEach(t),mr=f(Rs),Pt=a(Rs,"SPAN",{});var Ua=n(Pt);fr=i(Ua,"Incorrect output when padding tokens aren't masked"),Ua.forEach(t),Rs.forEach(t),$s=f(e),E=a(e,"P",{});var P=n(E);ur=i(P,"In some cases, the output "),Ct=a(P,"CODE",{});var qa=n(Ct);hr=i(qa,"hidden_state"),qa.forEach(t),dr=i(P," may be incorrect if the "),Ft=a(P,"CODE",{});var Da=n(Ft);cr=i(Da,"input_ids"),Da.forEach(t),vr=i(P," include padding tokens. To demonstrate, load a model and tokenizer. You can access a model\u2019s "),It=a(P,"CODE",{});var Ma=n(It);gr=i(Ma,"pad_token_id"),Ma.forEach(t),_r=i(P," to see its value. The "),St=a(P,"CODE",{});var xa=n(St);wr=i(xa,"pad_token_id"),xa.forEach(t),$r=i(P," may be "),Ut=a(P,"CODE",{});var Ba=n(Ut);br=i(Ba,"None"),Ba.forEach(t),yr=i(P," for some models, but you can always manually set it."),P.forEach(t),bs=f(e),c(Se.$$.fragment,e),ys=f(e),rt=a(e,"P",{});var La=n(rt);kr=i(La,"The following example shows the output without masking the padding tokens:"),La.forEach(t),ks=f(e),c(Ue.$$.fragment,e),Es=f(e),at=a(e,"P",{});var Na=n(at);Er=i(Na,"Here is the actual output of the second sequence:"),Na.forEach(t),js=f(e),c(qe.$$.fragment,e),Ts=f(e),ee=a(e,"P",{});var Vs=n(ee);jr=i(Vs,"Most of the time, you should provide an "),qt=a(Vs,"CODE",{});var Ga=n(qt);Tr=i(Ga,"attention_mask"),Ga.forEach(t),Ar=i(Vs," to your model to ignore the padding tokens to avoid this silent error. Now the output of the second sequence matches its actual output:"),Vs.forEach(t),As=f(e),c(te.$$.fragment,e),Ps=f(e),c(De.$$.fragment,e),Cs=f(e),se=a(e,"P",{});var Ys=n(se);Pr=i(Ys,"\u{1F917} Transformers doesn\u2019t automatically create an "),Dt=a(Ys,"CODE",{});var Ha=n(Dt);Cr=i(Ha,"attention_mask"),Ha.forEach(t),Fr=i(Ys," to mask a padding token if it is provided because:"),Ys.forEach(t),Fs=f(e),oe=a(e,"UL",{});var Js=n(oe);Mt=a(Js,"LI",{});var Oa=n(Mt);Ir=i(Oa,"Some models don\u2019t have a padding token."),Oa.forEach(t),Sr=f(Js),xt=a(Js,"LI",{});var za=n(xt);Ur=i(za,"For some use-cases, users want a model to attend to a padding token."),za.forEach(t),Js.forEach(t),this.h()},h(){u(h,"name","hf:doc:metadata"),u(h,"content",JSON.stringify(tn)),u(k,"id","troubleshoot"),u(k,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(k,"href","#troubleshoot"),u($,"class","relative group"),u(le,"href","https://discuss.huggingface.co/"),u(le,"rel","nofollow"),u(ie,"href","https://discuss.huggingface.co/c/beginners/5"),u(ie,"rel","nofollow"),u(pe,"href","https://discuss.huggingface.co/c/transformers/9"),u(pe,"rel","nofollow"),u(ue,"href","https://github.com/huggingface/transformers/issues/new/choose"),u(ue,"rel","nofollow"),u(Ge,"href","migration"),u(S,"start","2"),u(de,"href","https://huggingface.co/course/chapter8/1?fw=pt"),u(de,"rel","nofollow"),u(O,"id","firewalled-environments"),u(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(O,"href","#firewalled-environments"),u(U,"class","relative group"),u(Oe,"href","installation#offline-mode"),u(R,"id","cuda-out-of-memory"),u(R,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(R,"href","#cuda-out-of-memory"),u(q,"class","relative group"),u(Ve,"href","main_classes/trainer#transformers.TrainingArguments.per_device_train_batch_size"),u(Ye,"href","/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments"),u(Je,"href","main_classes/trainer#transformers.TrainingArguments.gradient_accumulation_steps"),u(Ke,"href","/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments"),u(J,"id","unable-to-load-a-saved-tensorflow-model"),u(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(J,"href","#unable-to-load-a-saved-tensorflow-model"),u(x,"class","relative group"),u($e,"href","https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model"),u($e,"rel","nofollow"),u(be,"href","https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model"),u(be,"rel","nofollow"),u(Qe,"href","/docs/transformers/main/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained"),u(Ze,"href","/docs/transformers/main/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained"),u(W,"id","importerror"),u(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(W,"href","#importerror"),u(L,"class","relative group"),u(X,"id","cuda-error-deviceside-assert-triggered"),u(X,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(X,"href","#cuda-error-deviceside-assert-triggered"),u(N,"class","relative group"),u(Z,"id","incorrect-output-when-padding-tokens-arent-masked"),u(Z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(Z,"href","#incorrect-output-when-padding-tokens-arent-masked"),u(G,"class","relative group")},m(e,o){s(document.head,h),p(e,A,o),p(e,$,o),s($,k),s(k,j),v(b,j,null),s($,y),s($,C),s(C,Ks),p(e,Lt,o),p(e,Le,o),s(Le,Ws),p(e,Nt,o),v(ne,e,o),p(e,Gt,o),p(e,Ne,o),s(Ne,F),s(F,Qs),s(F,le),s(le,Xs),s(F,Zs),s(F,ie),s(ie,eo),s(F,to),s(F,pe),s(pe,so),s(F,oo),p(e,Ht,o),v(me,e,o),p(e,Ot,o),p(e,S,o),s(S,pt),s(pt,fe),s(fe,ro),s(fe,ue),s(ue,ao),s(fe,no),s(S,lo),s(S,mt),s(mt,he),s(he,io),s(he,Ge),s(Ge,po),s(he,mo),p(e,zt,o),p(e,H,o),s(H,fo),s(H,de),s(de,uo),s(H,ho),p(e,Rt,o),p(e,U,o),s(U,O),s(O,ft),v(ce,ft,null),s(U,co),s(U,ut),s(ut,vo),p(e,Vt,o),p(e,He,o),s(He,go),p(e,Yt,o),v(ve,e,o),p(e,Jt,o),p(e,z,o),s(z,_o),s(z,Oe),s(Oe,wo),s(z,$o),p(e,Kt,o),p(e,q,o),s(q,R),s(R,ht),v(ge,ht,null),s(q,bo),s(q,dt),s(dt,yo),p(e,Wt,o),p(e,ze,o),s(ze,ko),p(e,Qt,o),v(_e,e,o),p(e,Xt,o),p(e,Re,o),s(Re,Eo),p(e,Zt,o),p(e,V,o),s(V,D),s(D,jo),s(D,Ve),s(Ve,ct),s(ct,To),s(D,Ao),s(D,Ye),s(Ye,Po),s(D,Co),s(V,Fo),s(V,M),s(M,Io),s(M,Je),s(Je,vt),s(vt,So),s(M,Uo),s(M,Ke),s(Ke,qo),s(M,Do),p(e,es,o),v(Y,e,o),p(e,ts,o),p(e,x,o),s(x,J),s(J,gt),v(we,gt,null),s(x,Mo),s(x,_t),s(_t,xo),p(e,ss,o),p(e,K,o),s(K,Bo),s(K,$e),s($e,Lo),s(K,No),p(e,os,o),p(e,We,o),s(We,I),s(I,Go),s(I,wt),s(wt,Ho),s(I,Oo),s(I,be),s(be,$t),s($t,zo),s(I,Ro),s(I,Qe),s(Qe,Vo),s(I,Yo),p(e,rs,o),v(ye,e,o),p(e,as,o),p(e,Xe,o),s(Xe,B),s(B,Jo),s(B,bt),s(bt,Ko),s(B,Wo),s(B,Ze),s(Ze,Qo),s(B,Xo),p(e,ns,o),v(ke,e,o),p(e,ls,o),p(e,L,o),s(L,W),s(W,yt),v(Ee,yt,null),s(L,Zo),s(L,kt),s(kt,er),p(e,is,o),p(e,Q,o),s(Q,tr),s(Q,Et),s(Et,sr),s(Q,or),p(e,ps,o),v(je,e,o),p(e,ms,o),p(e,et,o),s(et,rr),p(e,fs,o),v(Te,e,o),p(e,us,o),p(e,N,o),s(N,X),s(X,jt),v(Ae,jt,null),s(N,ar),s(N,Tt),s(Tt,nr),p(e,hs,o),p(e,tt,o),s(tt,lr),p(e,ds,o),v(Pe,e,o),p(e,cs,o),p(e,st,o),s(st,ir),p(e,vs,o),v(Ce,e,o),p(e,gs,o),p(e,ot,o),s(ot,pr),p(e,_s,o),v(Fe,e,o),p(e,ws,o),p(e,G,o),s(G,Z),s(Z,At),v(Ie,At,null),s(G,mr),s(G,Pt),s(Pt,fr),p(e,$s,o),p(e,E,o),s(E,ur),s(E,Ct),s(Ct,hr),s(E,dr),s(E,Ft),s(Ft,cr),s(E,vr),s(E,It),s(It,gr),s(E,_r),s(E,St),s(St,wr),s(E,$r),s(E,Ut),s(Ut,br),s(E,yr),p(e,bs,o),v(Se,e,o),p(e,ys,o),p(e,rt,o),s(rt,kr),p(e,ks,o),v(Ue,e,o),p(e,Es,o),p(e,at,o),s(at,Er),p(e,js,o),v(qe,e,o),p(e,Ts,o),p(e,ee,o),s(ee,jr),s(ee,qt),s(qt,Tr),s(ee,Ar),p(e,As,o),v(te,e,o),p(e,Ps,o),v(De,e,o),p(e,Cs,o),p(e,se,o),s(se,Pr),s(se,Dt),s(Dt,Cr),s(se,Fr),p(e,Fs,o),p(e,oe,o),s(oe,Mt),s(Mt,Ir),s(oe,Sr),s(oe,xt),s(xt,Ur),Is=!0},p(e,[o]){const Me={};o&2&&(Me.$$scope={dirty:o,ctx:e}),Y.$set(Me);const Bt={};o&2&&(Bt.$$scope={dirty:o,ctx:e}),te.$set(Bt)},i(e){Is||(g(b.$$.fragment,e),g(ne.$$.fragment,e),g(me.$$.fragment,e),g(ce.$$.fragment,e),g(ve.$$.fragment,e),g(ge.$$.fragment,e),g(_e.$$.fragment,e),g(Y.$$.fragment,e),g(we.$$.fragment,e),g(ye.$$.fragment,e),g(ke.$$.fragment,e),g(Ee.$$.fragment,e),g(je.$$.fragment,e),g(Te.$$.fragment,e),g(Ae.$$.fragment,e),g(Pe.$$.fragment,e),g(Ce.$$.fragment,e),g(Fe.$$.fragment,e),g(Ie.$$.fragment,e),g(Se.$$.fragment,e),g(Ue.$$.fragment,e),g(qe.$$.fragment,e),g(te.$$.fragment,e),g(De.$$.fragment,e),Is=!0)},o(e){_(b.$$.fragment,e),_(ne.$$.fragment,e),_(me.$$.fragment,e),_(ce.$$.fragment,e),_(ve.$$.fragment,e),_(ge.$$.fragment,e),_(_e.$$.fragment,e),_(Y.$$.fragment,e),_(we.$$.fragment,e),_(ye.$$.fragment,e),_(ke.$$.fragment,e),_(Ee.$$.fragment,e),_(je.$$.fragment,e),_(Te.$$.fragment,e),_(Ae.$$.fragment,e),_(Pe.$$.fragment,e),_(Ce.$$.fragment,e),_(Fe.$$.fragment,e),_(Ie.$$.fragment,e),_(Se.$$.fragment,e),_(Ue.$$.fragment,e),_(qe.$$.fragment,e),_(te.$$.fragment,e),_(De.$$.fragment,e),Is=!1},d(e){t(h),e&&t(A),e&&t($),w(b),e&&t(Lt),e&&t(Le),e&&t(Nt),w(ne,e),e&&t(Gt),e&&t(Ne),e&&t(Ht),w(me,e),e&&t(Ot),e&&t(S),e&&t(zt),e&&t(H),e&&t(Rt),e&&t(U),w(ce),e&&t(Vt),e&&t(He),e&&t(Yt),w(ve,e),e&&t(Jt),e&&t(z),e&&t(Kt),e&&t(q),w(ge),e&&t(Wt),e&&t(ze),e&&t(Qt),w(_e,e),e&&t(Xt),e&&t(Re),e&&t(Zt),e&&t(V),e&&t(es),w(Y,e),e&&t(ts),e&&t(x),w(we),e&&t(ss),e&&t(K),e&&t(os),e&&t(We),e&&t(rs),w(ye,e),e&&t(as),e&&t(Xe),e&&t(ns),w(ke,e),e&&t(ls),e&&t(L),w(Ee),e&&t(is),e&&t(Q),e&&t(ps),w(je,e),e&&t(ms),e&&t(et),e&&t(fs),w(Te,e),e&&t(us),e&&t(N),w(Ae),e&&t(hs),e&&t(tt),e&&t(ds),w(Pe,e),e&&t(cs),e&&t(st),e&&t(vs),w(Ce,e),e&&t(gs),e&&t(ot),e&&t(_s),w(Fe,e),e&&t(ws),e&&t(G),w(Ie),e&&t($s),e&&t(E),e&&t(bs),w(Se,e),e&&t(ys),e&&t(rt),e&&t(ks),w(Ue,e),e&&t(Es),e&&t(at),e&&t(js),w(qe,e),e&&t(Ts),e&&t(ee),e&&t(As),w(te,e),e&&t(Ps),w(De,e),e&&t(Cs),e&&t(se),e&&t(Fs),e&&t(oe)}}}const tn={local:"troubleshoot",sections:[{local:"firewalled-environments",title:"Firewalled environments"},{local:"cuda-out-of-memory",title:"CUDA out of memory"},{local:"unable-to-load-a-saved-tensorflow-model",title:"Unable to load a saved TensorFlow model"},{local:"importerror",title:"ImportError"},{local:"cuda-error-deviceside-assert-triggered",title:"CUDA error: device-side assert triggered"},{local:"incorrect-output-when-padding-tokens-arent-masked",title:"Incorrect output when padding tokens aren't masked"}],title:"Troubleshoot"};function sn(Be){return Qa(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class pn extends Ya{constructor(h){super();Ja(this,h,sn,en,Ka,{})}}export{pn as default,tn as metadata};
