import{S as X$,i as e_,s as t_,e as l,k as f,w as k,t as s,M as a_,c as i,d as a,m as c,a as p,x as w,h as r,b as h,G as e,g as d,y,q as b,o as T,B as E,v as s_,L as ye}from"../chunks/vendor-hf-doc-builder.js";import{T as Dn}from"../chunks/Tip-hf-doc-builder.js";import{Y as Z$}from"../chunks/Youtube-hf-doc-builder.js";import{I as Ne}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as N}from"../chunks/CodeBlock-hf-doc-builder.js";import{D as r_}from"../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as vs,M as ue}from"../chunks/Markdown-hf-doc-builder.js";function o_(x){let o,u;return o=new N({props:{code:"pip install torch",highlighted:"pip install torch"}}),{c(){k(o.$$.fragment)},l(n){w(o.$$.fragment,n)},m(n,g){y(o,n,g),u=!0},p:ye,i(n){u||(b(o.$$.fragment,n),u=!0)},o(n){T(o.$$.fragment,n),u=!1},d(n){E(o,n)}}}function n_(x){let o,u;return o=new ue({props:{$$slots:{default:[o_]},$$scope:{ctx:x}}}),{c(){k(o.$$.fragment)},l(n){w(o.$$.fragment,n)},m(n,g){y(o,n,g),u=!0},p(n,g){const _={};g&2&&(_.$$scope={dirty:g,ctx:n}),o.$set(_)},i(n){u||(b(o.$$.fragment,n),u=!0)},o(n){T(o.$$.fragment,n),u=!1},d(n){E(o,n)}}}function l_(x){let o,u;return o=new N({props:{code:"pip install tensorflow",highlighted:"pip install tensorflow"}}),{c(){k(o.$$.fragment)},l(n){w(o.$$.fragment,n)},m(n,g){y(o,n,g),u=!0},p:ye,i(n){u||(b(o.$$.fragment,n),u=!0)},o(n){T(o.$$.fragment,n),u=!1},d(n){E(o,n)}}}function i_(x){let o,u;return o=new ue({props:{$$slots:{default:[l_]},$$scope:{ctx:x}}}),{c(){k(o.$$.fragment)},l(n){w(o.$$.fragment,n)},m(n,g){y(o,n,g),u=!0},p(n,g){const _={};g&2&&(_.$$scope={dirty:g,ctx:n}),o.$set(_)},i(n){u||(b(o.$$.fragment,n),u=!0)},o(n){T(o.$$.fragment,n),u=!1},d(n){E(o,n)}}}function p_(x){let o,u,n,g,_,v,q,F,$,j,S,O,I,H;return I=new N({props:{code:`from transformers import AutoTokenizer, AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),{c(){o=l("p"),u=s("Use "),n=l("a"),g=s("AutoModelForSequenceClassification"),_=s(" and "),v=l("a"),q=s("AutoTokenizer"),F=s(" to load the pretrained model and it\u2019s associated tokenizer (more on an "),$=l("code"),j=s("AutoClass"),S=s(" in the next section):"),O=f(),k(I.$$.fragment),this.h()},l(z){o=i(z,"P",{});var M=p(o);u=r(M,"Use "),n=i(M,"A",{href:!0});var A=p(n);g=r(A,"AutoModelForSequenceClassification"),A.forEach(a),_=r(M," and "),v=i(M,"A",{href:!0});var D=p(v);q=r(D,"AutoTokenizer"),D.forEach(a),F=r(M," to load the pretrained model and it\u2019s associated tokenizer (more on an "),$=i(M,"CODE",{});var G=p($);j=r(G,"AutoClass"),G.forEach(a),S=r(M," in the next section):"),M.forEach(a),O=c(z),w(I.$$.fragment,z),this.h()},h(){h(n,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForSequenceClassification"),h(v,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer")},m(z,M){d(z,o,M),e(o,u),e(o,n),e(n,g),e(o,_),e(o,v),e(v,q),e(o,F),e(o,$),e($,j),e(o,S),d(z,O,M),y(I,z,M),H=!0},p:ye,i(z){H||(b(I.$$.fragment,z),H=!0)},o(z){T(I.$$.fragment,z),H=!1},d(z){z&&a(o),z&&a(O),E(I,z)}}}function f_(x){let o,u;return o=new ue({props:{$$slots:{default:[p_]},$$scope:{ctx:x}}}),{c(){k(o.$$.fragment)},l(n){w(o.$$.fragment,n)},m(n,g){y(o,n,g),u=!0},p(n,g){const _={};g&2&&(_.$$scope={dirty:g,ctx:n}),o.$set(_)},i(n){u||(b(o.$$.fragment,n),u=!0)},o(n){T(o.$$.fragment,n),u=!1},d(n){E(o,n)}}}function c_(x){let o,u,n,g,_,v,q,F,$,j,S,O,I,H;return I=new N({props:{code:`from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),{c(){o=l("p"),u=s("Use "),n=l("a"),g=s("TFAutoModelForSequenceClassification"),_=s(" and "),v=l("a"),q=s("AutoTokenizer"),F=s(" to load the pretrained model and it\u2019s associated tokenizer (more on an "),$=l("code"),j=s("TFAutoClass"),S=s(" in the next section):"),O=f(),k(I.$$.fragment),this.h()},l(z){o=i(z,"P",{});var M=p(o);u=r(M,"Use "),n=i(M,"A",{href:!0});var A=p(n);g=r(A,"TFAutoModelForSequenceClassification"),A.forEach(a),_=r(M," and "),v=i(M,"A",{href:!0});var D=p(v);q=r(D,"AutoTokenizer"),D.forEach(a),F=r(M," to load the pretrained model and it\u2019s associated tokenizer (more on an "),$=i(M,"CODE",{});var G=p($);j=r(G,"TFAutoClass"),G.forEach(a),S=r(M," in the next section):"),M.forEach(a),O=c(z),w(I.$$.fragment,z),this.h()},h(){h(n,"href","/docs/transformers/main/en/model_doc/auto#transformers.TFAutoModelForSequenceClassification"),h(v,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer")},m(z,M){d(z,o,M),e(o,u),e(o,n),e(n,g),e(o,_),e(o,v),e(v,q),e(o,F),e(o,$),e($,j),e(o,S),d(z,O,M),y(I,z,M),H=!0},p:ye,i(z){H||(b(I.$$.fragment,z),H=!0)},o(z){T(I.$$.fragment,z),H=!1},d(z){z&&a(o),z&&a(O),E(I,z)}}}function m_(x){let o,u;return o=new ue({props:{$$slots:{default:[c_]},$$scope:{ctx:x}}}),{c(){k(o.$$.fragment)},l(n){w(o.$$.fragment,n)},m(n,g){y(o,n,g),u=!0},p(n,g){const _={};g&2&&(_.$$scope={dirty:g,ctx:n}),o.$set(_)},i(n){u||(b(o.$$.fragment,n),u=!0)},o(n){T(o.$$.fragment,n),u=!1},d(n){E(o,n)}}}function d_(x){let o,u;return o=new N({props:{code:`pt_batch = tokenizer(
    ["We are very happy to show you the \u{1F917} Transformers library.", "We hope you don't hate it."],
    padding=True,
    truncation=True,
    max_length=512,
    return_tensors="pt",
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;pt&quot;</span>,
<span class="hljs-meta">... </span>)`}}),{c(){k(o.$$.fragment)},l(n){w(o.$$.fragment,n)},m(n,g){y(o,n,g),u=!0},p:ye,i(n){u||(b(o.$$.fragment,n),u=!0)},o(n){T(o.$$.fragment,n),u=!1},d(n){E(o,n)}}}function u_(x){let o,u;return o=new ue({props:{$$slots:{default:[d_]},$$scope:{ctx:x}}}),{c(){k(o.$$.fragment)},l(n){w(o.$$.fragment,n)},m(n,g){y(o,n,g),u=!0},p(n,g){const _={};g&2&&(_.$$scope={dirty:g,ctx:n}),o.$set(_)},i(n){u||(b(o.$$.fragment,n),u=!0)},o(n){T(o.$$.fragment,n),u=!1},d(n){E(o,n)}}}function h_(x){let o,u;return o=new N({props:{code:`tf_batch = tokenizer(
    ["We are very happy to show you the \u{1F917} Transformers library.", "We hope you don't hate it."],
    padding=True,
    truncation=True,
    max_length=512,
    return_tensors="tf",
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;tf&quot;</span>,
<span class="hljs-meta">... </span>)`}}),{c(){k(o.$$.fragment)},l(n){w(o.$$.fragment,n)},m(n,g){y(o,n,g),u=!0},p:ye,i(n){u||(b(o.$$.fragment,n),u=!0)},o(n){T(o.$$.fragment,n),u=!1},d(n){E(o,n)}}}function g_(x){let o,u;return o=new ue({props:{$$slots:{default:[h_]},$$scope:{ctx:x}}}),{c(){k(o.$$.fragment)},l(n){w(o.$$.fragment,n)},m(n,g){y(o,n,g),u=!0},p(n,g){const _={};g&2&&(_.$$scope={dirty:g,ctx:n}),o.$set(_)},i(n){u||(b(o.$$.fragment,n),u=!0)},o(n){T(o.$$.fragment,n),u=!1},d(n){E(o,n)}}}function $_(x){let o,u,n,g,_,v,q,F,$,j,S;return{c(){o=l("p"),u=s("Check out the "),n=l("a"),g=s("preprocess"),_=s(" tutorial for more details about tokenization, and how to use an "),v=l("a"),q=s("AutoFeatureExtractor"),F=s(" and "),$=l("a"),j=s("AutoProcessor"),S=s(" to preprocess image, audio, and multimodal inputs."),this.h()},l(O){o=i(O,"P",{});var I=p(o);u=r(I,"Check out the "),n=i(I,"A",{href:!0});var H=p(n);g=r(H,"preprocess"),H.forEach(a),_=r(I," tutorial for more details about tokenization, and how to use an "),v=i(I,"A",{href:!0});var z=p(v);q=r(z,"AutoFeatureExtractor"),z.forEach(a),F=r(I," and "),$=i(I,"A",{href:!0});var M=p($);j=r(M,"AutoProcessor"),M.forEach(a),S=r(I," to preprocess image, audio, and multimodal inputs."),I.forEach(a),this.h()},h(){h(n,"href","./preprocessing"),h(v,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor"),h($,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor")},m(O,I){d(O,o,I),e(o,u),e(o,n),e(n,g),e(o,_),e(o,v),e(v,q),e(o,F),e(o,$),e($,j),e(o,S)},d(O){O&&a(o)}}}function __(x){let o,u,n,g,_,v,q,F;return{c(){o=l("p"),u=s("See the "),n=l("a"),g=s("task summary"),_=s(" for tasks supported by an "),v=l("a"),q=s("AutoModel"),F=s(" class."),this.h()},l($){o=i($,"P",{});var j=p(o);u=r(j,"See the "),n=i(j,"A",{href:!0});var S=p(n);g=r(S,"task summary"),S.forEach(a),_=r(j," for tasks supported by an "),v=i(j,"A",{href:!0});var O=p(v);q=r(O,"AutoModel"),O.forEach(a),F=r(j," class."),j.forEach(a),this.h()},h(){h(n,"href","./task_summary"),h(v,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel")},m($,j){d($,o,j),e(o,u),e(o,n),e(n,g),e(o,_),e(o,v),e(v,q),e(o,F)},d($){$&&a(o)}}}function v_(x){let o,u,n,g,_,v,q,F,$,j,S,O,I,H,z,M,A,D,G,R,Q,ie,oe,he,K,ne,le,B,$e,J,be,_e,V,se,Z,P,L,X;return M=new N({props:{code:`from transformers import AutoModelForSequenceClassification

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)`}}),D=new Dn({props:{$$slots:{default:[__]},$$scope:{ctx:x}}}),ne=new N({props:{code:"pt_outputs = pt_model(**pt_batch)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_outputs = pt_model(**pt_batch)'}}),L=new N({props:{code:`from torch import nn

pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)
print(pt_predictions)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn

<span class="hljs-meta">&gt;&gt;&gt; </span>pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(pt_predictions)
tensor([[<span class="hljs-number">0.0021</span>, <span class="hljs-number">0.0018</span>, <span class="hljs-number">0.0115</span>, <span class="hljs-number">0.2121</span>, <span class="hljs-number">0.7725</span>],
        [<span class="hljs-number">0.2084</span>, <span class="hljs-number">0.1826</span>, <span class="hljs-number">0.1969</span>, <span class="hljs-number">0.1755</span>, <span class="hljs-number">0.2365</span>]], grad_fn=&lt;SoftmaxBackward0&gt;)`}}),{c(){o=l("p"),u=s("\u{1F917} Transformers provides a simple and unified way to load pretrained instances. This means you can load an "),n=l("a"),g=s("AutoModel"),_=s(" like you would load an "),v=l("a"),q=s("AutoTokenizer"),F=s(". The only difference is selecting the correct "),$=l("a"),j=s("AutoModel"),S=s(" for the task. For text (or sequence) classification, you should load "),O=l("a"),I=s("AutoModelForSequenceClassification"),H=s(":"),z=f(),k(M.$$.fragment),A=f(),k(D.$$.fragment),G=f(),R=l("p"),Q=s("Now pass your preprocessed batch of inputs directly to the model. You just have to unpack the dictionary by adding "),ie=l("code"),oe=s("**"),he=s(":"),K=f(),k(ne.$$.fragment),le=f(),B=l("p"),$e=s("The model outputs the final activations in the "),J=l("code"),be=s("logits"),_e=s(" attribute. Apply the softmax function to the "),V=l("code"),se=s("logits"),Z=s(" to retrieve the probabilities:"),P=f(),k(L.$$.fragment),this.h()},l(C){o=i(C,"P",{});var W=p(o);u=r(W,"\u{1F917} Transformers provides a simple and unified way to load pretrained instances. This means you can load an "),n=i(W,"A",{href:!0});var ve=p(n);g=r(ve,"AutoModel"),ve.forEach(a),_=r(W," like you would load an "),v=i(W,"A",{href:!0});var Le=p(v);q=r(Le,"AutoTokenizer"),Le.forEach(a),F=r(W,". The only difference is selecting the correct "),$=i(W,"A",{href:!0});var ae=p($);j=r(ae,"AutoModel"),ae.forEach(a),S=r(W," for the task. For text (or sequence) classification, you should load "),O=i(W,"A",{href:!0});var We=p(O);I=r(We,"AutoModelForSequenceClassification"),We.forEach(a),H=r(W,":"),W.forEach(a),z=c(C),w(M.$$.fragment,C),A=c(C),w(D.$$.fragment,C),G=c(C),R=i(C,"P",{});var ee=p(R);Q=r(ee,"Now pass your preprocessed batch of inputs directly to the model. You just have to unpack the dictionary by adding "),ie=i(ee,"CODE",{});var ks=p(ie);oe=r(ks,"**"),ks.forEach(a),he=r(ee,":"),ee.forEach(a),K=c(C),w(ne.$$.fragment,C),le=c(C),B=i(C,"P",{});var ge=p(B);$e=r(ge,"The model outputs the final activations in the "),J=i(ge,"CODE",{});var ws=p(J);be=r(ws,"logits"),ws.forEach(a),_e=r(ge," attribute. Apply the softmax function to the "),V=i(ge,"CODE",{});var ys=p(V);se=r(ys,"logits"),ys.forEach(a),Z=r(ge," to retrieve the probabilities:"),ge.forEach(a),P=c(C),w(L.$$.fragment,C),this.h()},h(){h(n,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),h(v,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),h($,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),h(O,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForSequenceClassification")},m(C,W){d(C,o,W),e(o,u),e(o,n),e(n,g),e(o,_),e(o,v),e(v,q),e(o,F),e(o,$),e($,j),e(o,S),e(o,O),e(O,I),e(o,H),d(C,z,W),y(M,C,W),d(C,A,W),y(D,C,W),d(C,G,W),d(C,R,W),e(R,Q),e(R,ie),e(ie,oe),e(R,he),d(C,K,W),y(ne,C,W),d(C,le,W),d(C,B,W),e(B,$e),e(B,J),e(J,be),e(B,_e),e(B,V),e(V,se),e(B,Z),d(C,P,W),y(L,C,W),X=!0},p(C,W){const ve={};W&2&&(ve.$$scope={dirty:W,ctx:C}),D.$set(ve)},i(C){X||(b(M.$$.fragment,C),b(D.$$.fragment,C),b(ne.$$.fragment,C),b(L.$$.fragment,C),X=!0)},o(C){T(M.$$.fragment,C),T(D.$$.fragment,C),T(ne.$$.fragment,C),T(L.$$.fragment,C),X=!1},d(C){C&&a(o),C&&a(z),E(M,C),C&&a(A),E(D,C),C&&a(G),C&&a(R),C&&a(K),E(ne,C),C&&a(le),C&&a(B),C&&a(P),E(L,C)}}}function k_(x){let o,u;return o=new ue({props:{$$slots:{default:[v_]},$$scope:{ctx:x}}}),{c(){k(o.$$.fragment)},l(n){w(o.$$.fragment,n)},m(n,g){y(o,n,g),u=!0},p(n,g){const _={};g&2&&(_.$$scope={dirty:g,ctx:n}),o.$set(_)},i(n){u||(b(o.$$.fragment,n),u=!0)},o(n){T(o.$$.fragment,n),u=!1},d(n){E(o,n)}}}function w_(x){let o,u,n,g,_,v,q,F;return{c(){o=l("p"),u=s("See the "),n=l("a"),g=s("task summary"),_=s(" for tasks supported by an "),v=l("a"),q=s("AutoModel"),F=s(" class."),this.h()},l($){o=i($,"P",{});var j=p(o);u=r(j,"See the "),n=i(j,"A",{href:!0});var S=p(n);g=r(S,"task summary"),S.forEach(a),_=r(j," for tasks supported by an "),v=i(j,"A",{href:!0});var O=p(v);q=r(O,"AutoModel"),O.forEach(a),F=r(j," class."),j.forEach(a),this.h()},h(){h(n,"href","./task_summary"),h(v,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel")},m($,j){d($,o,j),e(o,u),e(o,n),e(n,g),e(o,_),e(o,v),e(v,q),e(o,F)},d($){$&&a(o)}}}function y_(x){let o,u,n,g,_,v,q,F,$,j,S,O,I,H,z,M,A,D,G,R,Q,ie,oe,he,K,ne,le,B,$e,J,be,_e,V,se,Z;return M=new N({props:{code:`from transformers import TFAutoModelForSequenceClassification

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)`}}),D=new Dn({props:{$$slots:{default:[w_]},$$scope:{ctx:x}}}),oe=new N({props:{code:"tf_outputs = tf_model(tf_batch)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_outputs = tf_model(tf_batch)'}}),se=new N({props:{code:`import tensorflow as tf

tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-1)
tf_predictions`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions`}}),{c(){o=l("p"),u=s("\u{1F917} Transformers provides a simple and unified way to load pretrained instances. This means you can load an "),n=l("a"),g=s("TFAutoModel"),_=s(" like you would load an "),v=l("a"),q=s("AutoTokenizer"),F=s(". The only difference is selecting the correct "),$=l("a"),j=s("TFAutoModel"),S=s(" for the task. For text (or sequence) classification, you should load "),O=l("a"),I=s("TFAutoModelForSequenceClassification"),H=s(":"),z=f(),k(M.$$.fragment),A=f(),k(D.$$.fragment),G=f(),R=l("p"),Q=s("Now pass your preprocessed batch of inputs directly to the model by passing the dictionary keys directly to the tensors:"),ie=f(),k(oe.$$.fragment),he=f(),K=l("p"),ne=s("The model outputs the final activations in the "),le=l("code"),B=s("logits"),$e=s(" attribute. Apply the softmax function to the "),J=l("code"),be=s("logits"),_e=s(" to retrieve the probabilities:"),V=f(),k(se.$$.fragment),this.h()},l(P){o=i(P,"P",{});var L=p(o);u=r(L,"\u{1F917} Transformers provides a simple and unified way to load pretrained instances. This means you can load an "),n=i(L,"A",{href:!0});var X=p(n);g=r(X,"TFAutoModel"),X.forEach(a),_=r(L," like you would load an "),v=i(L,"A",{href:!0});var C=p(v);q=r(C,"AutoTokenizer"),C.forEach(a),F=r(L,". The only difference is selecting the correct "),$=i(L,"A",{href:!0});var W=p($);j=r(W,"TFAutoModel"),W.forEach(a),S=r(L," for the task. For text (or sequence) classification, you should load "),O=i(L,"A",{href:!0});var ve=p(O);I=r(ve,"TFAutoModelForSequenceClassification"),ve.forEach(a),H=r(L,":"),L.forEach(a),z=c(P),w(M.$$.fragment,P),A=c(P),w(D.$$.fragment,P),G=c(P),R=i(P,"P",{});var Le=p(R);Q=r(Le,"Now pass your preprocessed batch of inputs directly to the model by passing the dictionary keys directly to the tensors:"),Le.forEach(a),ie=c(P),w(oe.$$.fragment,P),he=c(P),K=i(P,"P",{});var ae=p(K);ne=r(ae,"The model outputs the final activations in the "),le=i(ae,"CODE",{});var We=p(le);B=r(We,"logits"),We.forEach(a),$e=r(ae," attribute. Apply the softmax function to the "),J=i(ae,"CODE",{});var ee=p(J);be=r(ee,"logits"),ee.forEach(a),_e=r(ae," to retrieve the probabilities:"),ae.forEach(a),V=c(P),w(se.$$.fragment,P),this.h()},h(){h(n,"href","/docs/transformers/main/en/model_doc/auto#transformers.TFAutoModel"),h(v,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),h($,"href","/docs/transformers/main/en/model_doc/auto#transformers.TFAutoModel"),h(O,"href","/docs/transformers/main/en/model_doc/auto#transformers.TFAutoModelForSequenceClassification")},m(P,L){d(P,o,L),e(o,u),e(o,n),e(n,g),e(o,_),e(o,v),e(v,q),e(o,F),e(o,$),e($,j),e(o,S),e(o,O),e(O,I),e(o,H),d(P,z,L),y(M,P,L),d(P,A,L),y(D,P,L),d(P,G,L),d(P,R,L),e(R,Q),d(P,ie,L),y(oe,P,L),d(P,he,L),d(P,K,L),e(K,ne),e(K,le),e(le,B),e(K,$e),e(K,J),e(J,be),e(K,_e),d(P,V,L),y(se,P,L),Z=!0},p(P,L){const X={};L&2&&(X.$$scope={dirty:L,ctx:P}),D.$set(X)},i(P){Z||(b(M.$$.fragment,P),b(D.$$.fragment,P),b(oe.$$.fragment,P),b(se.$$.fragment,P),Z=!0)},o(P){T(M.$$.fragment,P),T(D.$$.fragment,P),T(oe.$$.fragment,P),T(se.$$.fragment,P),Z=!1},d(P){P&&a(o),P&&a(z),E(M,P),P&&a(A),E(D,P),P&&a(G),P&&a(R),P&&a(ie),E(oe,P),P&&a(he),P&&a(K),P&&a(V),E(se,P)}}}function b_(x){let o,u;return o=new ue({props:{$$slots:{default:[y_]},$$scope:{ctx:x}}}),{c(){k(o.$$.fragment)},l(n){w(o.$$.fragment,n)},m(n,g){y(o,n,g),u=!0},p(n,g){const _={};g&2&&(_.$$scope={dirty:g,ctx:n}),o.$set(_)},i(n){u||(b(o.$$.fragment,n),u=!0)},o(n){T(o.$$.fragment,n),u=!1},d(n){E(o,n)}}}function T_(x){let o,u,n,g,_;return{c(){o=l("p"),u=s("All \u{1F917} Transformers models (PyTorch or TensorFlow) output the tensors "),n=l("em"),g=s("before"),_=s(` the final activation
function (like softmax) because the final activation function is often fused with the loss. Model outputs are special dataclasses so their attributes are autocompleted in an IDE. The model outputs behave like a tuple or a dictionary (you can index with an integer, a slice or a string) in which case, attributes that are None are ignored.`)},l(v){o=i(v,"P",{});var q=p(o);u=r(q,"All \u{1F917} Transformers models (PyTorch or TensorFlow) output the tensors "),n=i(q,"EM",{});var F=p(n);g=r(F,"before"),F.forEach(a),_=r(q,` the final activation
function (like softmax) because the final activation function is often fused with the loss. Model outputs are special dataclasses so their attributes are autocompleted in an IDE. The model outputs behave like a tuple or a dictionary (you can index with an integer, a slice or a string) in which case, attributes that are None are ignored.`),q.forEach(a)},m(v,q){d(v,o,q),e(o,u),e(o,n),e(n,g),e(o,_)},d(v){v&&a(o)}}}function E_(x){let o,u,n,g,_,v,q,F,$,j,S,O,I,H,z,M;return q=new N({props:{code:`pt_save_directory = "./pt_save_pretrained"
tokenizer.save_pretrained(pt_save_directory)
pt_model.save_pretrained(pt_save_directory)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_save_directory = <span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.save_pretrained(pt_save_directory)`}}),z=new N({props:{code:'pt_model = AutoModelForSequenceClassification.from_pretrained("./pt_save_pretrained")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>)'}}),{c(){o=l("p"),u=s("Once your model is fine-tuned, you can save it with its tokenizer using "),n=l("a"),g=s("PreTrainedModel.save_pretrained()"),_=s(":"),v=f(),k(q.$$.fragment),F=f(),$=l("p"),j=s("When you are ready to use the model again, reload it with "),S=l("a"),O=s("PreTrainedModel.from_pretrained()"),I=s(":"),H=f(),k(z.$$.fragment),this.h()},l(A){o=i(A,"P",{});var D=p(o);u=r(D,"Once your model is fine-tuned, you can save it with its tokenizer using "),n=i(D,"A",{href:!0});var G=p(n);g=r(G,"PreTrainedModel.save_pretrained()"),G.forEach(a),_=r(D,":"),D.forEach(a),v=c(A),w(q.$$.fragment,A),F=c(A),$=i(A,"P",{});var R=p($);j=r(R,"When you are ready to use the model again, reload it with "),S=i(R,"A",{href:!0});var Q=p(S);O=r(Q,"PreTrainedModel.from_pretrained()"),Q.forEach(a),I=r(R,":"),R.forEach(a),H=c(A),w(z.$$.fragment,A),this.h()},h(){h(n,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained"),h(S,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained")},m(A,D){d(A,o,D),e(o,u),e(o,n),e(n,g),e(o,_),d(A,v,D),y(q,A,D),d(A,F,D),d(A,$,D),e($,j),e($,S),e(S,O),e($,I),d(A,H,D),y(z,A,D),M=!0},p:ye,i(A){M||(b(q.$$.fragment,A),b(z.$$.fragment,A),M=!0)},o(A){T(q.$$.fragment,A),T(z.$$.fragment,A),M=!1},d(A){A&&a(o),A&&a(v),E(q,A),A&&a(F),A&&a($),A&&a(H),E(z,A)}}}function A_(x){let o,u;return o=new ue({props:{$$slots:{default:[E_]},$$scope:{ctx:x}}}),{c(){k(o.$$.fragment)},l(n){w(o.$$.fragment,n)},m(n,g){y(o,n,g),u=!0},p(n,g){const _={};g&2&&(_.$$scope={dirty:g,ctx:n}),o.$set(_)},i(n){u||(b(o.$$.fragment,n),u=!0)},o(n){T(o.$$.fragment,n),u=!1},d(n){E(o,n)}}}function j_(x){let o,u,n,g,_,v,q,F,$,j,S,O,I,H,z,M;return q=new N({props:{code:`tf_save_directory = "./tf_save_pretrained"
tokenizer.save_pretrained(tf_save_directory)
tf_model.save_pretrained(tf_save_directory)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_save_directory = <span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model.save_pretrained(tf_save_directory)`}}),z=new N({props:{code:'tf_model = TFAutoModelForSequenceClassification.from_pretrained("./tf_save_pretrained")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>)'}}),{c(){o=l("p"),u=s("Once your model is fine-tuned, you can save it with its tokenizer using "),n=l("a"),g=s("TFPreTrainedModel.save_pretrained()"),_=s(":"),v=f(),k(q.$$.fragment),F=f(),$=l("p"),j=s("When you are ready to use the model again, reload it with "),S=l("a"),O=s("TFPreTrainedModel.from_pretrained()"),I=s(":"),H=f(),k(z.$$.fragment),this.h()},l(A){o=i(A,"P",{});var D=p(o);u=r(D,"Once your model is fine-tuned, you can save it with its tokenizer using "),n=i(D,"A",{href:!0});var G=p(n);g=r(G,"TFPreTrainedModel.save_pretrained()"),G.forEach(a),_=r(D,":"),D.forEach(a),v=c(A),w(q.$$.fragment,A),F=c(A),$=i(A,"P",{});var R=p($);j=r(R,"When you are ready to use the model again, reload it with "),S=i(R,"A",{href:!0});var Q=p(S);O=r(Q,"TFPreTrainedModel.from_pretrained()"),Q.forEach(a),I=r(R,":"),R.forEach(a),H=c(A),w(z.$$.fragment,A),this.h()},h(){h(n,"href","/docs/transformers/main/en/main_classes/model#transformers.TFPreTrainedModel.save_pretrained"),h(S,"href","/docs/transformers/main/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained")},m(A,D){d(A,o,D),e(o,u),e(o,n),e(n,g),e(o,_),d(A,v,D),y(q,A,D),d(A,F,D),d(A,$,D),e($,j),e($,S),e(S,O),e($,I),d(A,H,D),y(z,A,D),M=!0},p:ye,i(A){M||(b(q.$$.fragment,A),b(z.$$.fragment,A),M=!0)},o(A){T(q.$$.fragment,A),T(z.$$.fragment,A),M=!1},d(A){A&&a(o),A&&a(v),E(q,A),A&&a(F),A&&a($),A&&a(H),E(z,A)}}}function q_(x){let o,u;return o=new ue({props:{$$slots:{default:[j_]},$$scope:{ctx:x}}}),{c(){k(o.$$.fragment)},l(n){w(o.$$.fragment,n)},m(n,g){y(o,n,g),u=!0},p(n,g){const _={};g&2&&(_.$$scope={dirty:g,ctx:n}),o.$set(_)},i(n){u||(b(o.$$.fragment,n),u=!0)},o(n){T(o.$$.fragment,n),u=!1},d(n){E(o,n)}}}function z_(x){let o,u;return o=new N({props:{code:`from transformers import AutoModel

tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=<span class="hljs-literal">True</span>)`}}),{c(){k(o.$$.fragment)},l(n){w(o.$$.fragment,n)},m(n,g){y(o,n,g),u=!0},p:ye,i(n){u||(b(o.$$.fragment,n),u=!0)},o(n){T(o.$$.fragment,n),u=!1},d(n){E(o,n)}}}function P_(x){let o,u;return o=new ue({props:{$$slots:{default:[z_]},$$scope:{ctx:x}}}),{c(){k(o.$$.fragment)},l(n){w(o.$$.fragment,n)},m(n,g){y(o,n,g),u=!0},p(n,g){const _={};g&2&&(_.$$scope={dirty:g,ctx:n}),o.$set(_)},i(n){u||(b(o.$$.fragment,n),u=!0)},o(n){T(o.$$.fragment,n),u=!1},d(n){E(o,n)}}}function x_(x){let o,u;return o=new N({props:{code:`from transformers import TFAutoModel

tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=<span class="hljs-literal">True</span>)`}}),{c(){k(o.$$.fragment)},l(n){w(o.$$.fragment,n)},m(n,g){y(o,n,g),u=!0},p:ye,i(n){u||(b(o.$$.fragment,n),u=!0)},o(n){T(o.$$.fragment,n),u=!1},d(n){E(o,n)}}}function F_(x){let o,u;return o=new ue({props:{$$slots:{default:[x_]},$$scope:{ctx:x}}}),{c(){k(o.$$.fragment)},l(n){w(o.$$.fragment,n)},m(n,g){y(o,n,g),u=!0},p(n,g){const _={};g&2&&(_.$$scope={dirty:g,ctx:n}),o.$set(_)},i(n){u||(b(o.$$.fragment,n),u=!0)},o(n){T(o.$$.fragment,n),u=!1},d(n){E(o,n)}}}function C_(x){let o,u,n,g,_,v,q,F;return q=new N({props:{code:`from transformers import AutoModel

my_model = AutoModel.from_config(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_model = AutoModel.from_config(my_config)`}}),{c(){o=l("p"),u=s("Create a model from your custom configuration with "),n=l("a"),g=s("AutoModel.from_config()"),_=s(":"),v=f(),k(q.$$.fragment),this.h()},l($){o=i($,"P",{});var j=p(o);u=r(j,"Create a model from your custom configuration with "),n=i(j,"A",{href:!0});var S=p(n);g=r(S,"AutoModel.from_config()"),S.forEach(a),_=r(j,":"),j.forEach(a),v=c($),w(q.$$.fragment,$),this.h()},h(){h(n,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config")},m($,j){d($,o,j),e(o,u),e(o,n),e(n,g),e(o,_),d($,v,j),y(q,$,j),F=!0},p:ye,i($){F||(b(q.$$.fragment,$),F=!0)},o($){T(q.$$.fragment,$),F=!1},d($){$&&a(o),$&&a(v),E(q,$)}}}function M_(x){let o,u;return o=new ue({props:{$$slots:{default:[C_]},$$scope:{ctx:x}}}),{c(){k(o.$$.fragment)},l(n){w(o.$$.fragment,n)},m(n,g){y(o,n,g),u=!0},p(n,g){const _={};g&2&&(_.$$scope={dirty:g,ctx:n}),o.$set(_)},i(n){u||(b(o.$$.fragment,n),u=!0)},o(n){T(o.$$.fragment,n),u=!1},d(n){E(o,n)}}}function S_(x){let o,u,n,g,_,v,q,F;return q=new N({props:{code:`from transformers import TFAutoModel

my_model = TFAutoModel.from_config(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_model = TFAutoModel.from_config(my_config)`}}),{c(){o=l("p"),u=s("Create a model from your custom configuration with "),n=l("a"),g=s("TFAutoModel.from_config()"),_=s(":"),v=f(),k(q.$$.fragment),this.h()},l($){o=i($,"P",{});var j=p(o);u=r(j,"Create a model from your custom configuration with "),n=i(j,"A",{href:!0});var S=p(n);g=r(S,"TFAutoModel.from_config()"),S.forEach(a),_=r(j,":"),j.forEach(a),v=c($),w(q.$$.fragment,$),this.h()},h(){h(n,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config")},m($,j){d($,o,j),e(o,u),e(o,n),e(n,g),e(o,_),d($,v,j),y(q,$,j),F=!0},p:ye,i($){F||(b(q.$$.fragment,$),F=!0)},o($){T(q.$$.fragment,$),F=!1},d($){$&&a(o),$&&a(v),E(q,$)}}}function D_(x){let o,u;return o=new ue({props:{$$slots:{default:[S_]},$$scope:{ctx:x}}}),{c(){k(o.$$.fragment)},l(n){w(o.$$.fragment,n)},m(n,g){y(o,n,g),u=!0},p(n,g){const _={};g&2&&(_.$$scope={dirty:g,ctx:n}),o.$set(_)},i(n){u||(b(o.$$.fragment,n),u=!0)},o(n){T(o.$$.fragment,n),u=!1},d(n){E(o,n)}}}function I_(x){let o,u,n,g,_,v,q,F;return{c(){o=l("p"),u=s("For tasks - like translation or summarization - that use a sequence-to-sequence model, use the "),n=l("a"),g=s("Seq2SeqTrainer"),_=s(" and "),v=l("a"),q=s("Seq2SeqTrainingArguments"),F=s(" classes instead."),this.h()},l($){o=i($,"P",{});var j=p(o);u=r(j,"For tasks - like translation or summarization - that use a sequence-to-sequence model, use the "),n=i(j,"A",{href:!0});var S=p(n);g=r(S,"Seq2SeqTrainer"),S.forEach(a),_=r(j," and "),v=i(j,"A",{href:!0});var O=p(v);q=r(O,"Seq2SeqTrainingArguments"),O.forEach(a),F=r(j," classes instead."),j.forEach(a),this.h()},h(){h(n,"href","/docs/transformers/main/en/main_classes/trainer#transformers.Seq2SeqTrainer"),h(v,"href","/docs/transformers/main/en/main_classes/trainer#transformers.Seq2SeqTrainingArguments")},m($,j){d($,o,j),e(o,u),e(o,n),e(n,g),e(o,_),e(o,v),e(v,q),e(o,F)},d($){$&&a(o)}}}function O_(x){let o,u,n,g,_,v,q,F,$,j,S,O,I,H,z,M,A,D,G,R,Q,ie,oe,he,K,ne,le,B,$e,J,be,_e,V,se,Z,P,L,X,C,W,ve,Le,ae,We,ee,ks,ge,ws,ys,bs,Di,Ii,In,ut,Fr,Te,Cr,Mr,Oi,Ni,Sr,Dr,Li,Wi,Ir,Or,Hi,Ri,Nr,Lr,Yi,Ui,Y,Ee,Wr,Gi,Ki,Hr,Bi,Qi,Rr,Vi,Ji,Yr,Zi,Xi,Ae,Ur,ep,tp,Gr,ap,sp,Kr,rp,op,Br,np,lp,je,Qr,ip,pp,Vr,fp,cp,Jr,mp,dp,Zr,up,hp,qe,Xr,gp,$p,eo,_p,vp,to,kp,wp,ao,yp,bp,ze,so,Tp,Ep,ro,Ap,jp,oo,qp,zp,no,Pp,xp,Pe,lo,Fp,Cp,io,Mp,Sp,po,Dp,Ip,fo,Op,Np,xe,co,Lp,Wp,mo,Hp,Rp,uo,Yp,Up,ho,Gp,Kp,Fe,go,Bp,Qp,$o,Vp,Jp,_o,Zp,Xp,vo,ef,tf,Ce,ko,af,sf,wo,rf,of,yo,nf,lf,bo,pf,ff,Me,To,cf,mf,Eo,df,uf,Ao,hf,gf,jo,$f,_f,Se,qo,vf,kf,zo,wf,yf,Po,bf,Tf,xo,Ef,Af,De,Fo,jf,qf,Co,zf,Pf,Mo,xf,Ff,So,Cf,Mf,Ie,Do,Sf,Df,Io,If,Of,Oo,Nf,Lf,No,Wf,On,pe,Hf,Ts,Rf,Yf,Es,Uf,Gf,As,Kf,Bf,js,Qf,Vf,Nn,na,Ln,ke,Jf,qs,Zf,Xf,la,ec,tc,Lo,ac,sc,Wn,ia,Hn,ht,rc,zs,oc,nc,Rn,pa,Yn,gt,lc,Ps,ic,pc,Un,fa,Gn,He,fc,ca,cc,mc,ma,dc,uc,Kn,da,Bn,$t,hc,ua,Wo,gc,$c,Qn,ha,Vn,_t,_c,Ho,vc,kc,Jn,ga,Zn,vt,wc,xs,yc,bc,Xn,tt,kt,Ro,$a,Tc,Yo,Ec,el,fe,Ac,Fs,jc,qc,_a,zc,Pc,Cs,xc,Fc,va,Cc,Mc,tl,ka,al,wt,sl,Re,Sc,Ms,Dc,Ic,Uo,Oc,Nc,rl,wa,ol,Ye,Lc,Ss,Wc,Hc,Ds,Rc,Yc,nl,at,yt,Go,ya,Uc,Ko,Gc,ll,ba,il,re,Kc,Is,Bc,Qc,Os,Vc,Jc,Ns,Zc,Xc,Ls,em,tm,Bo,am,sm,pl,Ue,rm,Qo,om,nm,Ws,lm,im,fl,st,bt,Vo,Ta,pm,Jo,fm,cl,Tt,cm,Hs,mm,dm,ml,Et,um,Rs,hm,gm,dl,Ea,ul,Ys,$m,hl,Aa,gl,Us,_m,$l,At,Gs,Ks,vm,km,wm,Bs,Qs,ym,bm,_l,Vs,Tm,vl,jt,kl,qt,wl,rt,zt,Zo,ja,Em,Xo,Am,yl,Pt,bl,xt,Tl,ot,Ft,en,qa,jm,tn,qm,El,Ct,Al,Ge,zm,an,Pm,xm,sn,Fm,Cm,jl,Mt,ql,nt,St,rn,za,Mm,on,Sm,zl,Js,Dm,Pl,Ke,Im,Zs,Om,Nm,Xs,Lm,Wm,xl,Pa,Fl,Dt,Cl,It,Hm,er,Rm,Ym,Ml,lt,Ot,nn,xa,Um,ln,Gm,Sl,Be,Km,Fa,pn,Bm,Qm,tr,Vm,Jm,Dl,Nt,Zm,ar,Xm,ed,Il,ce,Ca,it,td,sr,ad,sd,Ma,fn,rd,od,nd,Sa,ld,Da,rr,or,id,pd,fd,Ia,cd,Oa,cn,md,dd,Na,ud,La,mn,hd,gd,Wa,$d,Ha,Ra,_d,Ya,vd,kd,wd,Ua,Ol,nr,dn,Ga,un,yd,bd,Ka,Nl,Ba,Qa,Va,Td,lr,Ed,Ad,jd,Ja,Ll,Lt,qd,ir,zd,Pd,Wl,Za,Hl,Wt,xd,pr,Fd,Cd,Rl,Xa,Yl,Ht,Ul,Qe,Md,fr,Sd,Dd,cr,Id,Od,Gl,Ve,Nd,mr,Ld,Wd,dr,Hd,Rd,Kl,pt,Rt,hn,es,Yd,gn,Ud,Bl,te,Gd,ts,$n,Kd,Bd,as,Qd,Vd,ur,Jd,Zd,_n,Xd,eu,ss,vn,tu,au,rs,kn,su,ru,Ql,me,os,ft,ou,hr,nu,lu,ns,wn,iu,pu,fu,ls,cu,is,yn,mu,du,ps,uu,fs,bn,hu,gu,cs,$u,ms,ct,_u,ds,vu,ku,gr,wu,yu,bu,us,Tu,hs,mt,Eu,Tn,Au,ju,En,qu,zu,Pu,gs,Vl,dt,Yt,An,$s,xu,jn,Fu,Jl,$r,Cu,Zl;return v=new Ne({}),S=new r_({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/tensorflow/quicktour.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/tensorflow/quicktour.ipynb"}]}}),B=new N({props:{code:"!pip install transformers datasets",highlighted:"!pip install transformers datasets"}}),V=new vs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[i_],pytorch:[n_]},$$scope:{ctx:x}}}),X=new Ne({}),ae=new Z$({props:{id:"tiZFewofSLM"}}),na=new N({props:{code:`from transformers import pipeline

classifier = pipeline("sentiment-analysis")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>)`}}),ia=new N({props:{code:'classifier("We are very happy to show you the \u{1F917} Transformers library.")',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;POSITIVE&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9998</span>}]`}}),pa=new N({props:{code:`results = classifier(["We are very happy to show you the \u{1F917} Transformers library.", "We hope you don't hate it."])
for result in results:
    print(f"label: {result['label']}, with score: {round(result['score'], 4)}")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>results = classifier([<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> result <span class="hljs-keyword">in</span> results:
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;label: <span class="hljs-subst">{result[<span class="hljs-string">&#x27;label&#x27;</span>]}</span>, with score: <span class="hljs-subst">{<span class="hljs-built_in">round</span>(result[<span class="hljs-string">&#x27;score&#x27;</span>], <span class="hljs-number">4</span>)}</span>&quot;</span>)
label: POSITIVE, <span class="hljs-keyword">with</span> score: <span class="hljs-number">0.9998</span>
label: NEGATIVE, <span class="hljs-keyword">with</span> score: <span class="hljs-number">0.5309</span>`}}),fa=new N({props:{code:`import torch
from transformers import pipeline

speech_recognizer = pipeline("automatic-speech-recognition", model="facebook/wav2vec2-base-960h")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>speech_recognizer = pipeline(<span class="hljs-string">&quot;automatic-speech-recognition&quot;</span>, model=<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)`}}),da=new N({props:{code:`from datasets import load_dataset, Audio

dataset = load_dataset("PolyAI/minds14", name="en-US", split="train")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, name=<span class="hljs-string">&quot;en-US&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`}}),ha=new N({props:{code:'dataset = dataset.cast_column("audio", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))'}}),ga=new N({props:{code:`result = speech_recognizer(dataset[:4]["audio"])
print([d["text"] for d in result])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>result = speech_recognizer(dataset[:<span class="hljs-number">4</span>][<span class="hljs-string">&quot;audio&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>([d[<span class="hljs-string">&quot;text&quot;</span>] <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> result])
[<span class="hljs-string">&#x27;I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT&#x27;</span>, <span class="hljs-string">&quot;FODING HOW I&#x27;D SET UP A JOIN TO HET WITH MY WIFE AND WHERE THE AP MIGHT BE&quot;</span>, <span class="hljs-string">&quot;I I&#x27;D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I&#x27;M NOT SEEING THE OPTION TO DO IT ON THE AP SO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AND I&#x27;M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS&quot;</span>, <span class="hljs-string">&#x27;HOW DO I THURN A JOIN A COUNT&#x27;</span>]`}}),$a=new Ne({}),ka=new N({props:{code:'model_name = "nlptown/bert-base-multilingual-uncased-sentiment"',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>'}}),wt=new vs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[m_],pytorch:[f_]},$$scope:{ctx:x}}}),wa=new N({props:{code:`classifier = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
classifier("Nous sommes tr\xE8s heureux de vous pr\xE9senter la biblioth\xE8que \u{1F917} Transformers.")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>, model=model, tokenizer=tokenizer)
<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(<span class="hljs-string">&quot;Nous sommes tr\xE8s heureux de vous pr\xE9senter la biblioth\xE8que \u{1F917} Transformers.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;5 stars&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.7273</span>}]`}}),ya=new Ne({}),ba=new Z$({props:{id:"AhChOFRegn4"}}),Ta=new Ne({}),Ea=new N({props:{code:`from transformers import AutoTokenizer

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),Aa=new N({props:{code:`encoding = tokenizer("We are very happy to show you the \u{1F917} Transformers library.")
print(encoding)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>encoding = tokenizer(<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoding)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">11312</span>, <span class="hljs-number">10320</span>, <span class="hljs-number">12495</span>, <span class="hljs-number">19308</span>, <span class="hljs-number">10114</span>, <span class="hljs-number">11391</span>, <span class="hljs-number">10855</span>, <span class="hljs-number">10103</span>, <span class="hljs-number">100</span>, <span class="hljs-number">58263</span>, <span class="hljs-number">13299</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>],
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),jt=new vs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[g_],pytorch:[u_]},$$scope:{ctx:x}}}),qt=new Dn({props:{$$slots:{default:[$_]},$$scope:{ctx:x}}}),ja=new Ne({}),Pt=new vs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[b_],pytorch:[k_]},$$scope:{ctx:x}}}),xt=new Dn({props:{$$slots:{default:[T_]},$$scope:{ctx:x}}}),qa=new Ne({}),Ct=new vs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[q_],pytorch:[A_]},$$scope:{ctx:x}}}),Mt=new vs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[F_],pytorch:[P_]},$$scope:{ctx:x}}}),za=new Ne({}),Pa=new N({props:{code:`from transformers import AutoConfig

my_config = AutoConfig.from_pretrained("distilbert-base-uncased", n_heads=12)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, n_heads=<span class="hljs-number">12</span>)`}}),Dt=new vs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[D_],pytorch:[M_]},$$scope:{ctx:x}}}),xa=new Ne({}),Sa=new N({props:{code:`from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),Ia=new N({props:{code:`from transformers import TrainingArguments

training_args = TrainingArguments(
    output_dir="path/to/save/folder/",
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=2,
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;path/to/save/folder/&quot;</span>,
<span class="hljs-meta">... </span>    learning_rate=<span class="hljs-number">2e-5</span>,
<span class="hljs-meta">... </span>    per_device_train_batch_size=<span class="hljs-number">8</span>,
<span class="hljs-meta">... </span>    per_device_eval_batch_size=<span class="hljs-number">8</span>,
<span class="hljs-meta">... </span>    num_train_epochs=<span class="hljs-number">2</span>,
<span class="hljs-meta">... </span>)`}}),Na=new N({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),Wa=new N({props:{code:`from datasets import load_dataset

dataset = load_dataset("rottten_tomatoes")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;rottten_tomatoes&quot;</span>)`}}),Ua=new N({props:{code:`def tokenize_dataset(dataset):
    return tokenizer(dataset["text"])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_dataset</span>(<span class="hljs-params">dataset</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> tokenizer(dataset[<span class="hljs-string">&quot;text&quot;</span>])`}}),Ka=new N({props:{code:"",highlighted:""}}),Ja=new N({props:{code:`from transformers import DataCollatorWithPadding

data_collator = DataCollatorWithPadding(tokenizer=tokenizer)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorWithPadding

<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DataCollatorWithPadding(tokenizer=tokenizer)`}}),Za=new N({props:{code:`from transformers import Trainer

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset["train"],
    eval_dataset=dataset["test"],
    tokenizer=tokenizer,
    data_collator=data_collator,
)  # doctest: +SKIP`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=dataset[<span class="hljs-string">&quot;train&quot;</span>],
<span class="hljs-meta">... </span>    eval_dataset=dataset[<span class="hljs-string">&quot;test&quot;</span>],
<span class="hljs-meta">... </span>    tokenizer=tokenizer,
<span class="hljs-meta">... </span>    data_collator=data_collator,
<span class="hljs-meta">... </span>)  <span class="hljs-comment"># doctest: +SKIP</span>`}}),Xa=new N({props:{code:"trainer.train()",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()'}}),Ht=new Dn({props:{$$slots:{default:[I_]},$$scope:{ctx:x}}}),es=new Ne({}),ls=new N({props:{code:`from transformers import TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),ps=new N({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)`}}),cs=new N({props:{code:`def tokenize_dataset(dataset):
    return tokenizer(dataset["text"])  # doctest: +SKIP`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_dataset</span>(<span class="hljs-params">dataset</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> tokenizer(dataset[<span class="hljs-string">&quot;text&quot;</span>])  <span class="hljs-comment"># doctest: +SKIP</span>`}}),us=new N({props:{code:`dataset = dataset.map(tokenize_dataset)  # doctest: +SKIP
tf_dataset = model.prepare_tf_dataset(
    dataset, batch_size=16, shuffle=True, tokenizer=tokenizer
)  # doctest: +SKIP`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.<span class="hljs-built_in">map</span>(tokenize_dataset)  <span class="hljs-comment"># doctest: +SKIP</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_dataset = model.prepare_tf_dataset(
<span class="hljs-meta">... </span>    dataset, batch_size=<span class="hljs-number">16</span>, shuffle=<span class="hljs-literal">True</span>, tokenizer=tokenizer
<span class="hljs-meta">... </span>)  <span class="hljs-comment"># doctest: +SKIP</span>`}}),gs=new N({props:{code:`from tensorflow.keras.optimizers import Adam

model.compile(optimizer=Adam(3e-5))
model.fit(dataset)  # doctest: +SKIP`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> tensorflow.keras.optimizers <span class="hljs-keyword">import</span> Adam

<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">compile</span>(optimizer=Adam(<span class="hljs-number">3e-5</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>model.fit(dataset)  <span class="hljs-comment"># doctest: +SKIP</span>`}}),$s=new Ne({}),{c(){o=l("meta"),u=f(),n=l("h1"),g=l("a"),_=l("span"),k(v.$$.fragment),q=f(),F=l("span"),$=s("Quick tour"),j=f(),k(S.$$.fragment),O=f(),I=l("p"),H=s("Get up and running with \u{1F917} Transformers! Whether you\u2019re a developer or an everyday user, this quick tour will help you get started and show you how to use the "),z=l("a"),M=s("pipeline()"),A=s(" for inference, load a pretrained model and preprocessor with an "),D=l("a"),G=s("AutoClass"),R=s(", and quickly train a model with PyTorch or TensorFlow. If you\u2019re a beginner, we recommend checking out our tutorials or "),Q=l("a"),ie=s("course"),oe=s(" next for more in-depth explanations of the concepts introduced here."),he=f(),K=l("p"),ne=s("Before you begin, make sure you have all the necessary libraries installed:"),le=f(),k(B.$$.fragment),$e=f(),J=l("p"),be=s("You\u2019ll also need to install your preferred machine learning framework:"),_e=f(),k(V.$$.fragment),se=f(),Z=l("h2"),P=l("a"),L=l("span"),k(X.$$.fragment),C=f(),W=l("span"),ve=s("Pipeline"),Le=f(),k(ae.$$.fragment),We=f(),ee=l("p"),ks=s("The "),ge=l("a"),ws=s("pipeline()"),ys=s(" is the easiest way to use a pretrained model for inference. You can use the "),bs=l("a"),Di=s("pipeline()"),Ii=s(" out-of-the-box for many tasks across different modalities. Take a look at the table below for some supported tasks:"),In=f(),ut=l("table"),Fr=l("thead"),Te=l("tr"),Cr=l("th"),Mr=l("strong"),Oi=s("Task"),Ni=f(),Sr=l("th"),Dr=l("strong"),Li=s("Description"),Wi=f(),Ir=l("th"),Or=l("strong"),Hi=s("Modality"),Ri=f(),Nr=l("th"),Lr=l("strong"),Yi=s("Pipeline identifier"),Ui=f(),Y=l("tbody"),Ee=l("tr"),Wr=l("td"),Gi=s("Text classification"),Ki=f(),Hr=l("td"),Bi=s("assign a label to a given sequence of text"),Qi=f(),Rr=l("td"),Vi=s("NLP"),Ji=f(),Yr=l("td"),Zi=s("pipeline(task=\u201Csentiment-analysis\u201D)"),Xi=f(),Ae=l("tr"),Ur=l("td"),ep=s("Text generation"),tp=f(),Gr=l("td"),ap=s("generate text that follows a given prompt"),sp=f(),Kr=l("td"),rp=s("NLP"),op=f(),Br=l("td"),np=s("pipeline(task=\u201Ctext-generation\u201D)"),lp=f(),je=l("tr"),Qr=l("td"),ip=s("Name entity recognition"),pp=f(),Vr=l("td"),fp=s("assign a label to each token in a sequence (people, organization, location, etc.)"),cp=f(),Jr=l("td"),mp=s("NLP"),dp=f(),Zr=l("td"),up=s("pipeline(task=\u201Cner\u201D)"),hp=f(),qe=l("tr"),Xr=l("td"),gp=s("Question answering"),$p=f(),eo=l("td"),_p=s("extract an answer from the text given some context and a question"),vp=f(),to=l("td"),kp=s("NLP"),wp=f(),ao=l("td"),yp=s("pipeline(task=\u201Cquestion-answering\u201D)"),bp=f(),ze=l("tr"),so=l("td"),Tp=s("Fill-mask"),Ep=f(),ro=l("td"),Ap=s("predict the correct masked token in a sequence"),jp=f(),oo=l("td"),qp=s("NLP"),zp=f(),no=l("td"),Pp=s("pipeline(task=\u201Cfill-mask\u201D)"),xp=f(),Pe=l("tr"),lo=l("td"),Fp=s("Summarization"),Cp=f(),io=l("td"),Mp=s("generate a summary of a sequence of text or document"),Sp=f(),po=l("td"),Dp=s("NLP"),Ip=f(),fo=l("td"),Op=s("pipeline(task=\u201Csummarization\u201D)"),Np=f(),xe=l("tr"),co=l("td"),Lp=s("Translation"),Wp=f(),mo=l("td"),Hp=s("translate text from one language into another"),Rp=f(),uo=l("td"),Yp=s("NLP"),Up=f(),ho=l("td"),Gp=s("pipeline(task=\u201Ctranslation\u201D)"),Kp=f(),Fe=l("tr"),go=l("td"),Bp=s("Image classification"),Qp=f(),$o=l("td"),Vp=s("assign a label to an image"),Jp=f(),_o=l("td"),Zp=s("Computer vision"),Xp=f(),vo=l("td"),ef=s("pipeline(task=\u201Cimage-classification\u201D)"),tf=f(),Ce=l("tr"),ko=l("td"),af=s("Image segmentation"),sf=f(),wo=l("td"),rf=s("assign a label to each individual pixel of an image (supports semantic, panoptic, and instance segmentation)"),of=f(),yo=l("td"),nf=s("Computer vision"),lf=f(),bo=l("td"),pf=s("pipeline(task=\u201Cimage-segmentation\u201D)"),ff=f(),Me=l("tr"),To=l("td"),cf=s("Object detection"),mf=f(),Eo=l("td"),df=s("predict the bounding boxes and classes of objects in an image"),uf=f(),Ao=l("td"),hf=s("Computer vision"),gf=f(),jo=l("td"),$f=s("pipeline(task=\u201Cobject-detection\u201D)"),_f=f(),Se=l("tr"),qo=l("td"),vf=s("Audio classification"),kf=f(),zo=l("td"),wf=s("assign a label to an audio file"),yf=f(),Po=l("td"),bf=s("Audio"),Tf=f(),xo=l("td"),Ef=s("pipeline(task=\u201Caudio-classification\u201D)"),Af=f(),De=l("tr"),Fo=l("td"),jf=s("Automatic speech recognition"),qf=f(),Co=l("td"),zf=s("extract speech from an audio file into text"),Pf=f(),Mo=l("td"),xf=s("Audio"),Ff=f(),So=l("td"),Cf=s("pipeline(task=\u201Cautomatic-speech-recognition\u201D)"),Mf=f(),Ie=l("tr"),Do=l("td"),Sf=s("Visual question answering"),Df=f(),Io=l("td"),If=s("given an image and a question, correctly answer a question about the image"),Of=f(),Oo=l("td"),Nf=s("Multimodal"),Lf=f(),No=l("td"),Wf=s("pipeline(task=\u201Cvqa\u201D)"),On=f(),pe=l("p"),Hf=s("Start by creating an instance of "),Ts=l("a"),Rf=s("pipeline()"),Yf=s(" and specifying a task you want to use it for. You can use the "),Es=l("a"),Uf=s("pipeline()"),Gf=s(" for any of the previously mentioned tasks, and for a complete list of supported tasks, take a look at the "),As=l("a"),Kf=s("pipeline API reference"),Bf=s(". In this guide though, you\u2019ll use the "),js=l("a"),Qf=s("pipeline()"),Vf=s(" for sentiment analysis as an example:"),Nn=f(),k(na.$$.fragment),Ln=f(),ke=l("p"),Jf=s("The "),qs=l("a"),Zf=s("pipeline()"),Xf=s(" downloads and caches a default "),la=l("a"),ec=s("pretrained model"),tc=s(" and tokenizer for sentiment analysis. Now you can use the "),Lo=l("code"),ac=s("classifier"),sc=s(" on your target text:"),Wn=f(),k(ia.$$.fragment),Hn=f(),ht=l("p"),rc=s("If you have more than one input, pass your inputs as a list to the "),zs=l("a"),oc=s("pipeline()"),nc=s(" to return a list of dictionaries:"),Rn=f(),k(pa.$$.fragment),Yn=f(),gt=l("p"),lc=s("The "),Ps=l("a"),ic=s("pipeline()"),pc=s(" can also iterate over an entire dataset for any task you like. For this example, let\u2019s choose automatic speech recognition as our task:"),Un=f(),k(fa.$$.fragment),Gn=f(),He=l("p"),fc=s("Load an audio dataset (see the \u{1F917} Datasets "),ca=l("a"),cc=s("Quick Start"),mc=s(" for more details) you\u2019d like to iterate over. For example, load the "),ma=l("a"),dc=s("MInDS-14"),uc=s(" dataset:"),Kn=f(),k(da.$$.fragment),Bn=f(),$t=l("p"),hc=s(`You need to make sure the sampling rate of the dataset matches the sampling
rate `),ua=l("a"),Wo=l("code"),gc=s("facebook/wav2vec2-base-960h"),$c=s(" was trained on:"),Qn=f(),k(ha.$$.fragment),Vn=f(),_t=l("p"),_c=s("The audio files are automatically loaded and resampled when calling the "),Ho=l("code"),vc=s('"audio"'),kc=s(` column.
Extract the raw waveform arrays from the first 4 samples and pass it as a list to the pipeline:`),Jn=f(),k(ga.$$.fragment),Zn=f(),vt=l("p"),wc=s("For larger datasets where the inputs are big (like in speech or vision), you\u2019ll want to pass a generator instead of a list to load all the inputs in memory. Take a look at the "),xs=l("a"),yc=s("pipeline API reference"),bc=s(" for more information."),Xn=f(),tt=l("h3"),kt=l("a"),Ro=l("span"),k($a.$$.fragment),Tc=f(),Yo=l("span"),Ec=s("Use another model and tokenizer in the pipeline"),el=f(),fe=l("p"),Ac=s("The "),Fs=l("a"),jc=s("pipeline()"),qc=s(" can accommodate any model from the "),_a=l("a"),zc=s("Hub"),Pc=s(", making it easy to adapt the "),Cs=l("a"),xc=s("pipeline()"),Fc=s(" for other use-cases. For example, if you\u2019d like a model capable of handling French text, use the tags on the Hub to filter for an appropriate model. The top filtered result returns a multilingual "),va=l("a"),Cc=s("BERT model"),Mc=s(" finetuned for sentiment analysis you can use for French text:"),tl=f(),k(ka.$$.fragment),al=f(),k(wt.$$.fragment),sl=f(),Re=l("p"),Sc=s("Specify the model and tokenizer in the "),Ms=l("a"),Dc=s("pipeline()"),Ic=s(", and now you can apply the "),Uo=l("code"),Oc=s("classifier"),Nc=s(" on French text:"),rl=f(),k(wa.$$.fragment),ol=f(),Ye=l("p"),Lc=s("If you can\u2019t find a model for your use-case, you\u2019ll need to finetune a pretrained model on your data. Take a look at our "),Ss=l("a"),Wc=s("finetuning tutorial"),Hc=s(" to learn how. Finally, after you\u2019ve finetuned your pretrained model, please consider "),Ds=l("a"),Rc=s("sharing"),Yc=s(" the model with the community on the Hub to democratize machine learning for everyone! \u{1F917}"),nl=f(),at=l("h2"),yt=l("a"),Go=l("span"),k(ya.$$.fragment),Uc=f(),Ko=l("span"),Gc=s("AutoClass"),ll=f(),k(ba.$$.fragment),il=f(),re=l("p"),Kc=s("Under the hood, the "),Is=l("a"),Bc=s("AutoModelForSequenceClassification"),Qc=s(" and "),Os=l("a"),Vc=s("AutoTokenizer"),Jc=s(" classes work together to power the "),Ns=l("a"),Zc=s("pipeline()"),Xc=s(" you used above. An "),Ls=l("a"),em=s("AutoClass"),tm=s(" is a shortcut that automatically retrieves the architecture of a pretrained model from it\u2019s name or path. You only need to select the appropriate "),Bo=l("code"),am=s("AutoClass"),sm=s(" for your task and it\u2019s associated preprocessing class."),pl=f(),Ue=l("p"),rm=s("Let\u2019s return to the example from the previous section and see how you can use the "),Qo=l("code"),om=s("AutoClass"),nm=s(" to replicate the results of the "),Ws=l("a"),lm=s("pipeline()"),im=s("."),fl=f(),st=l("h3"),bt=l("a"),Vo=l("span"),k(Ta.$$.fragment),pm=f(),Jo=l("span"),fm=s("AutoTokenizer"),cl=f(),Tt=l("p"),cm=s("A tokenizer is responsible for preprocessing text into an array of numbers as inputs to a model. There are multiple rules that govern the tokenization process, including how to split a word and at what level words should be split (learn more about tokenization in the "),Hs=l("a"),mm=s("tokenizer summary"),dm=s("). The most important thing to remember is you need to instantiate a tokenizer with the same model name to ensure you\u2019re using the same tokenization rules a model was pretrained with."),ml=f(),Et=l("p"),um=s("Load a tokenizer with "),Rs=l("a"),hm=s("AutoTokenizer"),gm=s(":"),dl=f(),k(Ea.$$.fragment),ul=f(),Ys=l("p"),$m=s("Pass your text to the tokenizer:"),hl=f(),k(Aa.$$.fragment),gl=f(),Us=l("p"),_m=s("The tokenizer returns a dictionary containing:"),$l=f(),At=l("ul"),Gs=l("li"),Ks=l("a"),vm=s("input_ids"),km=s(": numerical representations of your tokens."),wm=f(),Bs=l("li"),Qs=l("a"),ym=s("attention_mask"),bm=s(": indicates which tokens should be attended to."),_l=f(),Vs=l("p"),Tm=s("A tokenizer can also accept a list of inputs, and pad and truncate the text to return a batch with uniform length:"),vl=f(),k(jt.$$.fragment),kl=f(),k(qt.$$.fragment),wl=f(),rt=l("h3"),zt=l("a"),Zo=l("span"),k(ja.$$.fragment),Em=f(),Xo=l("span"),Am=s("AutoModel"),yl=f(),k(Pt.$$.fragment),bl=f(),k(xt.$$.fragment),Tl=f(),ot=l("h3"),Ft=l("a"),en=l("span"),k(qa.$$.fragment),jm=f(),tn=l("span"),qm=s("Save a model"),El=f(),k(Ct.$$.fragment),Al=f(),Ge=l("p"),zm=s("One particularly cool \u{1F917} Transformers feature is the ability to save a model and reload it as either a PyTorch or TensorFlow model. The "),an=l("code"),Pm=s("from_pt"),xm=s(" or "),sn=l("code"),Fm=s("from_tf"),Cm=s(" parameter can convert the model from one framework to the other:"),jl=f(),k(Mt.$$.fragment),ql=f(),nt=l("h2"),St=l("a"),rn=l("span"),k(za.$$.fragment),Mm=f(),on=l("span"),Sm=s("Custom model builds"),zl=f(),Js=l("p"),Dm=s("You can modify the model\u2019s configuration class to change how a model is built. The configuration specifies a model\u2019s attributes, such as the number of hidden layers or attention heads. You start from scratch when you initialize a model from a custom configuration class. The model attributes are randomly initialized, and you\u2019ll need to train the model before you can use it to get meaningful results."),Pl=f(),Ke=l("p"),Im=s("Start by importing "),Zs=l("a"),Om=s("AutoConfig"),Nm=s(", and then load the pretrained model you want to modify. Within "),Xs=l("a"),Lm=s("AutoConfig.from_pretrained()"),Wm=s(", you can specify the attribute you want to change, such as the number of attention heads:"),xl=f(),k(Pa.$$.fragment),Fl=f(),k(Dt.$$.fragment),Cl=f(),It=l("p"),Hm=s("Take a look at the "),er=l("a"),Rm=s("Create a custom architecture"),Ym=s(" guide for more information about building custom configurations."),Ml=f(),lt=l("h2"),Ot=l("a"),nn=l("span"),k(xa.$$.fragment),Um=f(),ln=l("span"),Gm=s("Trainer - a PyTorch optimized training loop"),Sl=f(),Be=l("p"),Km=s("All models are a standard "),Fa=l("a"),pn=l("code"),Bm=s("torch.nn.Module"),Qm=s(" so you can use them in any typical training loop. While you can write your own training loop, \u{1F917} Transformers provides a "),tr=l("a"),Vm=s("Trainer"),Jm=s(" class for PyTorch, which contains the basic training loop and adds additional functionality for features like distributed training, mixed precision, and more."),Dl=f(),Nt=l("p"),Zm=s("Depending on your task, you\u2019ll typically pass the following parameters to "),ar=l("a"),Xm=s("Trainer"),ed=s(":"),Il=f(),ce=l("ol"),Ca=l("li"),it=l("p"),td=s("A "),sr=l("a"),ad=s("PreTrainedModel"),sd=s(" or a "),Ma=l("a"),fn=l("code"),rd=s("torch.nn.Module"),od=s(":"),nd=f(),k(Sa.$$.fragment),ld=f(),Da=l("li"),rr=l("p"),or=l("a"),id=s("TrainingArguments"),pd=s(" contains the model hyperparameters you can change like learning rate, batch size, and the number of epochs to train for. The default values are used if you don\u2019t specify any training arguments:"),fd=f(),k(Ia.$$.fragment),cd=f(),Oa=l("li"),cn=l("p"),md=s("A preprocessing class like a tokenizer, feature extractor, or processor:"),dd=f(),k(Na.$$.fragment),ud=f(),La=l("li"),mn=l("p"),hd=s("Load a dataset:"),gd=f(),k(Wa.$$.fragment),$d=f(),Ha=l("li"),Ra=l("p"),_d=s("Create a function to tokenize the dataset, and apply it over the entire dataset with "),Ya=l("a"),vd=s("map"),kd=s(":"),wd=f(),k(Ua.$$.fragment),Ol=f(),nr=l("blockquote"),dn=l("blockquote"),Ga=l("blockquote"),un=l("p"),yd=s("dataset = dataset.map(tokenize_dataset, batched=True)"),bd=f(),k(Ka.$$.fragment),Nl=f(),Ba=l("ol"),Qa=l("li"),Va=l("p"),Td=s("A "),lr=l("a"),Ed=s("DataCollatorWithPadding"),Ad=s(" to create a batch of examples from your dataset:"),jd=f(),k(Ja.$$.fragment),Ll=f(),Lt=l("p"),qd=s("Now gather all these classes in "),ir=l("a"),zd=s("Trainer"),Pd=s(":"),Wl=f(),k(Za.$$.fragment),Hl=f(),Wt=l("p"),xd=s("When you\u2019re ready, call "),pr=l("a"),Fd=s("train()"),Cd=s(" to start training:"),Rl=f(),k(Xa.$$.fragment),Yl=f(),k(Ht.$$.fragment),Ul=f(),Qe=l("p"),Md=s("You can customize the training loop behavior by subclassing the methods inside "),fr=l("a"),Sd=s("Trainer"),Dd=s(". This allows you to customize features such as the loss function, optimizer, and scheduler. Take a look at the "),cr=l("a"),Id=s("Trainer"),Od=s(" reference for which methods can be subclassed."),Gl=f(),Ve=l("p"),Nd=s("The other way to customize the training loop is by using "),mr=l("a"),Ld=s("Callbacks"),Wd=s(". You can use callbacks to integrate with other libraries and inspect the training loop to report on progress or stop the training early. Callbacks do not modify anything in the training loop itself. To customize something like the loss function, you need to subclass the "),dr=l("a"),Hd=s("Trainer"),Rd=s(" instead."),Kl=f(),pt=l("h2"),Rt=l("a"),hn=l("span"),k(es.$$.fragment),Yd=f(),gn=l("span"),Ud=s("Train with TensorFlow"),Bl=f(),te=l("p"),Gd=s("All models are a standard "),ts=l("a"),$n=l("code"),Kd=s("tf.keras.Model"),Bd=s(" so they can be trained in TensorFlow with the "),as=l("a"),Qd=s("Keras"),Vd=s(" API. \u{1F917} Transformers provides the "),ur=l("a"),Jd=s("prepare_tf_dataset()"),Zd=s(" method to easily load your dataset as a "),_n=l("code"),Xd=s("tf.data.Dataset"),eu=s(" so you can start training right away with Keras\u2019 "),ss=l("a"),vn=l("code"),tu=s("compile"),au=s(" and "),rs=l("a"),kn=l("code"),su=s("fit"),ru=s(" methods."),Ql=f(),me=l("ol"),os=l("li"),ft=l("p"),ou=s("You\u2019ll start with a "),hr=l("a"),nu=s("TFPreTrainedModel"),lu=s(" or a "),ns=l("a"),wn=l("code"),iu=s("tf.keras.Model"),pu=s(":"),fu=f(),k(ls.$$.fragment),cu=f(),is=l("li"),yn=l("p"),mu=s("A preprocessing class like a tokenizer, feature extractor, or processor:"),du=f(),k(ps.$$.fragment),uu=f(),fs=l("li"),bn=l("p"),hu=s("Create a function to tokenize the dataset:"),gu=f(),k(cs.$$.fragment),$u=f(),ms=l("li"),ct=l("p"),_u=s("Apply the tokenizer over the entire dataset with "),ds=l("a"),vu=s("map"),ku=s(" and then pass the dataset and tokenizer to "),gr=l("a"),wu=s("prepare_tf_dataset()"),yu=s(". You can also change the batch size and shuffle the dataset here if you\u2019d like:"),bu=f(),k(us.$$.fragment),Tu=f(),hs=l("li"),mt=l("p"),Eu=s("When you\u2019re ready, you can call "),Tn=l("code"),Au=s("compile"),ju=s(" and "),En=l("code"),qu=s("fit"),zu=s(" to start training:"),Pu=f(),k(gs.$$.fragment),Vl=f(),dt=l("h2"),Yt=l("a"),An=l("span"),k($s.$$.fragment),xu=f(),jn=l("span"),Fu=s("What's next?"),Jl=f(),$r=l("p"),Cu=s("Now that you\u2019ve completed the \u{1F917} Transformers quick tour, check out our guides and learn how to do more specific things like writing a custom model, fine-tuning a model for a task, and how to train a model with a script. If you\u2019re interested in learning more about \u{1F917} Transformers core concepts, grab a cup of coffee and take a look at our Conceptual Guides!"),this.h()},l(t){const m=a_('[data-svelte="svelte-1phssyn"]',document.head);o=i(m,"META",{name:!0,content:!0}),m.forEach(a),u=c(t),n=i(t,"H1",{class:!0});var _s=p(n);g=i(_s,"A",{id:!0,class:!0,href:!0});var qn=p(g);_=i(qn,"SPAN",{});var zn=p(_);w(v.$$.fragment,zn),zn.forEach(a),qn.forEach(a),q=c(_s),F=i(_s,"SPAN",{});var Pn=p(F);$=r(Pn,"Quick tour"),Pn.forEach(a),_s.forEach(a),j=c(t),w(S.$$.fragment,t),O=c(t),I=i(t,"P",{});var Oe=p(I);H=r(Oe,"Get up and running with \u{1F917} Transformers! Whether you\u2019re a developer or an everyday user, this quick tour will help you get started and show you how to use the "),z=i(Oe,"A",{href:!0});var xn=p(z);M=r(xn,"pipeline()"),xn.forEach(a),A=r(Oe," for inference, load a pretrained model and preprocessor with an "),D=i(Oe,"A",{href:!0});var Fn=p(D);G=r(Fn,"AutoClass"),Fn.forEach(a),R=r(Oe,", and quickly train a model with PyTorch or TensorFlow. If you\u2019re a beginner, we recommend checking out our tutorials or "),Q=i(Oe,"A",{href:!0,rel:!0});var Cn=p(Q);ie=r(Cn,"course"),Cn.forEach(a),oe=r(Oe," next for more in-depth explanations of the concepts introduced here."),Oe.forEach(a),he=c(t),K=i(t,"P",{});var Mn=p(K);ne=r(Mn,"Before you begin, make sure you have all the necessary libraries installed:"),Mn.forEach(a),le=c(t),w(B.$$.fragment,t),$e=c(t),J=i(t,"P",{});var Sn=p(J);be=r(Sn,"You\u2019ll also need to install your preferred machine learning framework:"),Sn.forEach(a),_e=c(t),w(V.$$.fragment,t),se=c(t),Z=i(t,"H2",{class:!0});var Xl=p(Z);P=i(Xl,"A",{id:!0,class:!0,href:!0});var Iu=p(P);L=i(Iu,"SPAN",{});var Ou=p(L);w(X.$$.fragment,Ou),Ou.forEach(a),Iu.forEach(a),C=c(Xl),W=i(Xl,"SPAN",{});var Nu=p(W);ve=r(Nu,"Pipeline"),Nu.forEach(a),Xl.forEach(a),Le=c(t),w(ae.$$.fragment,t),We=c(t),ee=i(t,"P",{});var _r=p(ee);ks=r(_r,"The "),ge=i(_r,"A",{href:!0});var Lu=p(ge);ws=r(Lu,"pipeline()"),Lu.forEach(a),ys=r(_r," is the easiest way to use a pretrained model for inference. You can use the "),bs=i(_r,"A",{href:!0});var Wu=p(bs);Di=r(Wu,"pipeline()"),Wu.forEach(a),Ii=r(_r," out-of-the-box for many tasks across different modalities. Take a look at the table below for some supported tasks:"),_r.forEach(a),In=c(t),ut=i(t,"TABLE",{});var ei=p(ut);Fr=i(ei,"THEAD",{});var Hu=p(Fr);Te=i(Hu,"TR",{});var Ut=p(Te);Cr=i(Ut,"TH",{});var Ru=p(Cr);Mr=i(Ru,"STRONG",{});var Yu=p(Mr);Oi=r(Yu,"Task"),Yu.forEach(a),Ru.forEach(a),Ni=c(Ut),Sr=i(Ut,"TH",{});var Uu=p(Sr);Dr=i(Uu,"STRONG",{});var Gu=p(Dr);Li=r(Gu,"Description"),Gu.forEach(a),Uu.forEach(a),Wi=c(Ut),Ir=i(Ut,"TH",{});var Ku=p(Ir);Or=i(Ku,"STRONG",{});var Bu=p(Or);Hi=r(Bu,"Modality"),Bu.forEach(a),Ku.forEach(a),Ri=c(Ut),Nr=i(Ut,"TH",{});var Qu=p(Nr);Lr=i(Qu,"STRONG",{});var Vu=p(Lr);Yi=r(Vu,"Pipeline identifier"),Vu.forEach(a),Qu.forEach(a),Ut.forEach(a),Hu.forEach(a),Ui=c(ei),Y=i(ei,"TBODY",{});var U=p(Y);Ee=i(U,"TR",{});var Gt=p(Ee);Wr=i(Gt,"TD",{});var Ju=p(Wr);Gi=r(Ju,"Text classification"),Ju.forEach(a),Ki=c(Gt),Hr=i(Gt,"TD",{});var Zu=p(Hr);Bi=r(Zu,"assign a label to a given sequence of text"),Zu.forEach(a),Qi=c(Gt),Rr=i(Gt,"TD",{});var Xu=p(Rr);Vi=r(Xu,"NLP"),Xu.forEach(a),Ji=c(Gt),Yr=i(Gt,"TD",{});var eh=p(Yr);Zi=r(eh,"pipeline(task=\u201Csentiment-analysis\u201D)"),eh.forEach(a),Gt.forEach(a),Xi=c(U),Ae=i(U,"TR",{});var Kt=p(Ae);Ur=i(Kt,"TD",{});var th=p(Ur);ep=r(th,"Text generation"),th.forEach(a),tp=c(Kt),Gr=i(Kt,"TD",{});var ah=p(Gr);ap=r(ah,"generate text that follows a given prompt"),ah.forEach(a),sp=c(Kt),Kr=i(Kt,"TD",{});var sh=p(Kr);rp=r(sh,"NLP"),sh.forEach(a),op=c(Kt),Br=i(Kt,"TD",{});var rh=p(Br);np=r(rh,"pipeline(task=\u201Ctext-generation\u201D)"),rh.forEach(a),Kt.forEach(a),lp=c(U),je=i(U,"TR",{});var Bt=p(je);Qr=i(Bt,"TD",{});var oh=p(Qr);ip=r(oh,"Name entity recognition"),oh.forEach(a),pp=c(Bt),Vr=i(Bt,"TD",{});var nh=p(Vr);fp=r(nh,"assign a label to each token in a sequence (people, organization, location, etc.)"),nh.forEach(a),cp=c(Bt),Jr=i(Bt,"TD",{});var lh=p(Jr);mp=r(lh,"NLP"),lh.forEach(a),dp=c(Bt),Zr=i(Bt,"TD",{});var ih=p(Zr);up=r(ih,"pipeline(task=\u201Cner\u201D)"),ih.forEach(a),Bt.forEach(a),hp=c(U),qe=i(U,"TR",{});var Qt=p(qe);Xr=i(Qt,"TD",{});var ph=p(Xr);gp=r(ph,"Question answering"),ph.forEach(a),$p=c(Qt),eo=i(Qt,"TD",{});var fh=p(eo);_p=r(fh,"extract an answer from the text given some context and a question"),fh.forEach(a),vp=c(Qt),to=i(Qt,"TD",{});var ch=p(to);kp=r(ch,"NLP"),ch.forEach(a),wp=c(Qt),ao=i(Qt,"TD",{});var mh=p(ao);yp=r(mh,"pipeline(task=\u201Cquestion-answering\u201D)"),mh.forEach(a),Qt.forEach(a),bp=c(U),ze=i(U,"TR",{});var Vt=p(ze);so=i(Vt,"TD",{});var dh=p(so);Tp=r(dh,"Fill-mask"),dh.forEach(a),Ep=c(Vt),ro=i(Vt,"TD",{});var uh=p(ro);Ap=r(uh,"predict the correct masked token in a sequence"),uh.forEach(a),jp=c(Vt),oo=i(Vt,"TD",{});var hh=p(oo);qp=r(hh,"NLP"),hh.forEach(a),zp=c(Vt),no=i(Vt,"TD",{});var gh=p(no);Pp=r(gh,"pipeline(task=\u201Cfill-mask\u201D)"),gh.forEach(a),Vt.forEach(a),xp=c(U),Pe=i(U,"TR",{});var Jt=p(Pe);lo=i(Jt,"TD",{});var $h=p(lo);Fp=r($h,"Summarization"),$h.forEach(a),Cp=c(Jt),io=i(Jt,"TD",{});var _h=p(io);Mp=r(_h,"generate a summary of a sequence of text or document"),_h.forEach(a),Sp=c(Jt),po=i(Jt,"TD",{});var vh=p(po);Dp=r(vh,"NLP"),vh.forEach(a),Ip=c(Jt),fo=i(Jt,"TD",{});var kh=p(fo);Op=r(kh,"pipeline(task=\u201Csummarization\u201D)"),kh.forEach(a),Jt.forEach(a),Np=c(U),xe=i(U,"TR",{});var Zt=p(xe);co=i(Zt,"TD",{});var wh=p(co);Lp=r(wh,"Translation"),wh.forEach(a),Wp=c(Zt),mo=i(Zt,"TD",{});var yh=p(mo);Hp=r(yh,"translate text from one language into another"),yh.forEach(a),Rp=c(Zt),uo=i(Zt,"TD",{});var bh=p(uo);Yp=r(bh,"NLP"),bh.forEach(a),Up=c(Zt),ho=i(Zt,"TD",{});var Th=p(ho);Gp=r(Th,"pipeline(task=\u201Ctranslation\u201D)"),Th.forEach(a),Zt.forEach(a),Kp=c(U),Fe=i(U,"TR",{});var Xt=p(Fe);go=i(Xt,"TD",{});var Eh=p(go);Bp=r(Eh,"Image classification"),Eh.forEach(a),Qp=c(Xt),$o=i(Xt,"TD",{});var Ah=p($o);Vp=r(Ah,"assign a label to an image"),Ah.forEach(a),Jp=c(Xt),_o=i(Xt,"TD",{});var jh=p(_o);Zp=r(jh,"Computer vision"),jh.forEach(a),Xp=c(Xt),vo=i(Xt,"TD",{});var qh=p(vo);ef=r(qh,"pipeline(task=\u201Cimage-classification\u201D)"),qh.forEach(a),Xt.forEach(a),tf=c(U),Ce=i(U,"TR",{});var ea=p(Ce);ko=i(ea,"TD",{});var zh=p(ko);af=r(zh,"Image segmentation"),zh.forEach(a),sf=c(ea),wo=i(ea,"TD",{});var Ph=p(wo);rf=r(Ph,"assign a label to each individual pixel of an image (supports semantic, panoptic, and instance segmentation)"),Ph.forEach(a),of=c(ea),yo=i(ea,"TD",{});var xh=p(yo);nf=r(xh,"Computer vision"),xh.forEach(a),lf=c(ea),bo=i(ea,"TD",{});var Fh=p(bo);pf=r(Fh,"pipeline(task=\u201Cimage-segmentation\u201D)"),Fh.forEach(a),ea.forEach(a),ff=c(U),Me=i(U,"TR",{});var ta=p(Me);To=i(ta,"TD",{});var Ch=p(To);cf=r(Ch,"Object detection"),Ch.forEach(a),mf=c(ta),Eo=i(ta,"TD",{});var Mh=p(Eo);df=r(Mh,"predict the bounding boxes and classes of objects in an image"),Mh.forEach(a),uf=c(ta),Ao=i(ta,"TD",{});var Sh=p(Ao);hf=r(Sh,"Computer vision"),Sh.forEach(a),gf=c(ta),jo=i(ta,"TD",{});var Dh=p(jo);$f=r(Dh,"pipeline(task=\u201Cobject-detection\u201D)"),Dh.forEach(a),ta.forEach(a),_f=c(U),Se=i(U,"TR",{});var aa=p(Se);qo=i(aa,"TD",{});var Ih=p(qo);vf=r(Ih,"Audio classification"),Ih.forEach(a),kf=c(aa),zo=i(aa,"TD",{});var Oh=p(zo);wf=r(Oh,"assign a label to an audio file"),Oh.forEach(a),yf=c(aa),Po=i(aa,"TD",{});var Nh=p(Po);bf=r(Nh,"Audio"),Nh.forEach(a),Tf=c(aa),xo=i(aa,"TD",{});var Lh=p(xo);Ef=r(Lh,"pipeline(task=\u201Caudio-classification\u201D)"),Lh.forEach(a),aa.forEach(a),Af=c(U),De=i(U,"TR",{});var sa=p(De);Fo=i(sa,"TD",{});var Wh=p(Fo);jf=r(Wh,"Automatic speech recognition"),Wh.forEach(a),qf=c(sa),Co=i(sa,"TD",{});var Hh=p(Co);zf=r(Hh,"extract speech from an audio file into text"),Hh.forEach(a),Pf=c(sa),Mo=i(sa,"TD",{});var Rh=p(Mo);xf=r(Rh,"Audio"),Rh.forEach(a),Ff=c(sa),So=i(sa,"TD",{});var Yh=p(So);Cf=r(Yh,"pipeline(task=\u201Cautomatic-speech-recognition\u201D)"),Yh.forEach(a),sa.forEach(a),Mf=c(U),Ie=i(U,"TR",{});var ra=p(Ie);Do=i(ra,"TD",{});var Uh=p(Do);Sf=r(Uh,"Visual question answering"),Uh.forEach(a),Df=c(ra),Io=i(ra,"TD",{});var Gh=p(Io);If=r(Gh,"given an image and a question, correctly answer a question about the image"),Gh.forEach(a),Of=c(ra),Oo=i(ra,"TD",{});var Kh=p(Oo);Nf=r(Kh,"Multimodal"),Kh.forEach(a),Lf=c(ra),No=i(ra,"TD",{});var Bh=p(No);Wf=r(Bh,"pipeline(task=\u201Cvqa\u201D)"),Bh.forEach(a),ra.forEach(a),U.forEach(a),ei.forEach(a),On=c(t),pe=i(t,"P",{});var Je=p(pe);Hf=r(Je,"Start by creating an instance of "),Ts=i(Je,"A",{href:!0});var Qh=p(Ts);Rf=r(Qh,"pipeline()"),Qh.forEach(a),Yf=r(Je," and specifying a task you want to use it for. You can use the "),Es=i(Je,"A",{href:!0});var Vh=p(Es);Uf=r(Vh,"pipeline()"),Vh.forEach(a),Gf=r(Je," for any of the previously mentioned tasks, and for a complete list of supported tasks, take a look at the "),As=i(Je,"A",{href:!0});var Jh=p(As);Kf=r(Jh,"pipeline API reference"),Jh.forEach(a),Bf=r(Je,". In this guide though, you\u2019ll use the "),js=i(Je,"A",{href:!0});var Zh=p(js);Qf=r(Zh,"pipeline()"),Zh.forEach(a),Vf=r(Je," for sentiment analysis as an example:"),Je.forEach(a),Nn=c(t),w(na.$$.fragment,t),Ln=c(t),ke=i(t,"P",{});var oa=p(ke);Jf=r(oa,"The "),qs=i(oa,"A",{href:!0});var Xh=p(qs);Zf=r(Xh,"pipeline()"),Xh.forEach(a),Xf=r(oa," downloads and caches a default "),la=i(oa,"A",{href:!0,rel:!0});var eg=p(la);ec=r(eg,"pretrained model"),eg.forEach(a),tc=r(oa," and tokenizer for sentiment analysis. Now you can use the "),Lo=i(oa,"CODE",{});var tg=p(Lo);ac=r(tg,"classifier"),tg.forEach(a),sc=r(oa," on your target text:"),oa.forEach(a),Wn=c(t),w(ia.$$.fragment,t),Hn=c(t),ht=i(t,"P",{});var ti=p(ht);rc=r(ti,"If you have more than one input, pass your inputs as a list to the "),zs=i(ti,"A",{href:!0});var ag=p(zs);oc=r(ag,"pipeline()"),ag.forEach(a),nc=r(ti," to return a list of dictionaries:"),ti.forEach(a),Rn=c(t),w(pa.$$.fragment,t),Yn=c(t),gt=i(t,"P",{});var ai=p(gt);lc=r(ai,"The "),Ps=i(ai,"A",{href:!0});var sg=p(Ps);ic=r(sg,"pipeline()"),sg.forEach(a),pc=r(ai," can also iterate over an entire dataset for any task you like. For this example, let\u2019s choose automatic speech recognition as our task:"),ai.forEach(a),Un=c(t),w(fa.$$.fragment,t),Gn=c(t),He=i(t,"P",{});var vr=p(He);fc=r(vr,"Load an audio dataset (see the \u{1F917} Datasets "),ca=i(vr,"A",{href:!0,rel:!0});var rg=p(ca);cc=r(rg,"Quick Start"),rg.forEach(a),mc=r(vr," for more details) you\u2019d like to iterate over. For example, load the "),ma=i(vr,"A",{href:!0,rel:!0});var og=p(ma);dc=r(og,"MInDS-14"),og.forEach(a),uc=r(vr," dataset:"),vr.forEach(a),Kn=c(t),w(da.$$.fragment,t),Bn=c(t),$t=i(t,"P",{});var si=p($t);hc=r(si,`You need to make sure the sampling rate of the dataset matches the sampling
rate `),ua=i(si,"A",{href:!0,rel:!0});var ng=p(ua);Wo=i(ng,"CODE",{});var lg=p(Wo);gc=r(lg,"facebook/wav2vec2-base-960h"),lg.forEach(a),ng.forEach(a),$c=r(si," was trained on:"),si.forEach(a),Qn=c(t),w(ha.$$.fragment,t),Vn=c(t),_t=i(t,"P",{});var ri=p(_t);_c=r(ri,"The audio files are automatically loaded and resampled when calling the "),Ho=i(ri,"CODE",{});var ig=p(Ho);vc=r(ig,'"audio"'),ig.forEach(a),kc=r(ri,` column.
Extract the raw waveform arrays from the first 4 samples and pass it as a list to the pipeline:`),ri.forEach(a),Jn=c(t),w(ga.$$.fragment,t),Zn=c(t),vt=i(t,"P",{});var oi=p(vt);wc=r(oi,"For larger datasets where the inputs are big (like in speech or vision), you\u2019ll want to pass a generator instead of a list to load all the inputs in memory. Take a look at the "),xs=i(oi,"A",{href:!0});var pg=p(xs);yc=r(pg,"pipeline API reference"),pg.forEach(a),bc=r(oi," for more information."),oi.forEach(a),Xn=c(t),tt=i(t,"H3",{class:!0});var ni=p(tt);kt=i(ni,"A",{id:!0,class:!0,href:!0});var fg=p(kt);Ro=i(fg,"SPAN",{});var cg=p(Ro);w($a.$$.fragment,cg),cg.forEach(a),fg.forEach(a),Tc=c(ni),Yo=i(ni,"SPAN",{});var mg=p(Yo);Ec=r(mg,"Use another model and tokenizer in the pipeline"),mg.forEach(a),ni.forEach(a),el=c(t),fe=i(t,"P",{});var Ze=p(fe);Ac=r(Ze,"The "),Fs=i(Ze,"A",{href:!0});var dg=p(Fs);jc=r(dg,"pipeline()"),dg.forEach(a),qc=r(Ze," can accommodate any model from the "),_a=i(Ze,"A",{href:!0,rel:!0});var ug=p(_a);zc=r(ug,"Hub"),ug.forEach(a),Pc=r(Ze,", making it easy to adapt the "),Cs=i(Ze,"A",{href:!0});var hg=p(Cs);xc=r(hg,"pipeline()"),hg.forEach(a),Fc=r(Ze," for other use-cases. For example, if you\u2019d like a model capable of handling French text, use the tags on the Hub to filter for an appropriate model. The top filtered result returns a multilingual "),va=i(Ze,"A",{href:!0,rel:!0});var gg=p(va);Cc=r(gg,"BERT model"),gg.forEach(a),Mc=r(Ze," finetuned for sentiment analysis you can use for French text:"),Ze.forEach(a),tl=c(t),w(ka.$$.fragment,t),al=c(t),w(wt.$$.fragment,t),sl=c(t),Re=i(t,"P",{});var kr=p(Re);Sc=r(kr,"Specify the model and tokenizer in the "),Ms=i(kr,"A",{href:!0});var $g=p(Ms);Dc=r($g,"pipeline()"),$g.forEach(a),Ic=r(kr,", and now you can apply the "),Uo=i(kr,"CODE",{});var _g=p(Uo);Oc=r(_g,"classifier"),_g.forEach(a),Nc=r(kr," on French text:"),kr.forEach(a),rl=c(t),w(wa.$$.fragment,t),ol=c(t),Ye=i(t,"P",{});var wr=p(Ye);Lc=r(wr,"If you can\u2019t find a model for your use-case, you\u2019ll need to finetune a pretrained model on your data. Take a look at our "),Ss=i(wr,"A",{href:!0});var vg=p(Ss);Wc=r(vg,"finetuning tutorial"),vg.forEach(a),Hc=r(wr," to learn how. Finally, after you\u2019ve finetuned your pretrained model, please consider "),Ds=i(wr,"A",{href:!0});var kg=p(Ds);Rc=r(kg,"sharing"),kg.forEach(a),Yc=r(wr," the model with the community on the Hub to democratize machine learning for everyone! \u{1F917}"),wr.forEach(a),nl=c(t),at=i(t,"H2",{class:!0});var li=p(at);yt=i(li,"A",{id:!0,class:!0,href:!0});var wg=p(yt);Go=i(wg,"SPAN",{});var yg=p(Go);w(ya.$$.fragment,yg),yg.forEach(a),wg.forEach(a),Uc=c(li),Ko=i(li,"SPAN",{});var bg=p(Ko);Gc=r(bg,"AutoClass"),bg.forEach(a),li.forEach(a),ll=c(t),w(ba.$$.fragment,t),il=c(t),re=i(t,"P",{});var we=p(re);Kc=r(we,"Under the hood, the "),Is=i(we,"A",{href:!0});var Tg=p(Is);Bc=r(Tg,"AutoModelForSequenceClassification"),Tg.forEach(a),Qc=r(we," and "),Os=i(we,"A",{href:!0});var Eg=p(Os);Vc=r(Eg,"AutoTokenizer"),Eg.forEach(a),Jc=r(we," classes work together to power the "),Ns=i(we,"A",{href:!0});var Ag=p(Ns);Zc=r(Ag,"pipeline()"),Ag.forEach(a),Xc=r(we," you used above. An "),Ls=i(we,"A",{href:!0});var jg=p(Ls);em=r(jg,"AutoClass"),jg.forEach(a),tm=r(we," is a shortcut that automatically retrieves the architecture of a pretrained model from it\u2019s name or path. You only need to select the appropriate "),Bo=i(we,"CODE",{});var qg=p(Bo);am=r(qg,"AutoClass"),qg.forEach(a),sm=r(we," for your task and it\u2019s associated preprocessing class."),we.forEach(a),pl=c(t),Ue=i(t,"P",{});var yr=p(Ue);rm=r(yr,"Let\u2019s return to the example from the previous section and see how you can use the "),Qo=i(yr,"CODE",{});var zg=p(Qo);om=r(zg,"AutoClass"),zg.forEach(a),nm=r(yr," to replicate the results of the "),Ws=i(yr,"A",{href:!0});var Pg=p(Ws);lm=r(Pg,"pipeline()"),Pg.forEach(a),im=r(yr,"."),yr.forEach(a),fl=c(t),st=i(t,"H3",{class:!0});var ii=p(st);bt=i(ii,"A",{id:!0,class:!0,href:!0});var xg=p(bt);Vo=i(xg,"SPAN",{});var Fg=p(Vo);w(Ta.$$.fragment,Fg),Fg.forEach(a),xg.forEach(a),pm=c(ii),Jo=i(ii,"SPAN",{});var Cg=p(Jo);fm=r(Cg,"AutoTokenizer"),Cg.forEach(a),ii.forEach(a),cl=c(t),Tt=i(t,"P",{});var pi=p(Tt);cm=r(pi,"A tokenizer is responsible for preprocessing text into an array of numbers as inputs to a model. There are multiple rules that govern the tokenization process, including how to split a word and at what level words should be split (learn more about tokenization in the "),Hs=i(pi,"A",{href:!0});var Mg=p(Hs);mm=r(Mg,"tokenizer summary"),Mg.forEach(a),dm=r(pi,"). The most important thing to remember is you need to instantiate a tokenizer with the same model name to ensure you\u2019re using the same tokenization rules a model was pretrained with."),pi.forEach(a),ml=c(t),Et=i(t,"P",{});var fi=p(Et);um=r(fi,"Load a tokenizer with "),Rs=i(fi,"A",{href:!0});var Sg=p(Rs);hm=r(Sg,"AutoTokenizer"),Sg.forEach(a),gm=r(fi,":"),fi.forEach(a),dl=c(t),w(Ea.$$.fragment,t),ul=c(t),Ys=i(t,"P",{});var Dg=p(Ys);$m=r(Dg,"Pass your text to the tokenizer:"),Dg.forEach(a),hl=c(t),w(Aa.$$.fragment,t),gl=c(t),Us=i(t,"P",{});var Ig=p(Us);_m=r(Ig,"The tokenizer returns a dictionary containing:"),Ig.forEach(a),$l=c(t),At=i(t,"UL",{});var ci=p(At);Gs=i(ci,"LI",{});var Mu=p(Gs);Ks=i(Mu,"A",{href:!0});var Og=p(Ks);vm=r(Og,"input_ids"),Og.forEach(a),km=r(Mu,": numerical representations of your tokens."),Mu.forEach(a),wm=c(ci),Bs=i(ci,"LI",{});var Su=p(Bs);Qs=i(Su,"A",{href:!0});var Ng=p(Qs);ym=r(Ng,"attention_mask"),Ng.forEach(a),bm=r(Su,": indicates which tokens should be attended to."),Su.forEach(a),ci.forEach(a),_l=c(t),Vs=i(t,"P",{});var Lg=p(Vs);Tm=r(Lg,"A tokenizer can also accept a list of inputs, and pad and truncate the text to return a batch with uniform length:"),Lg.forEach(a),vl=c(t),w(jt.$$.fragment,t),kl=c(t),w(qt.$$.fragment,t),wl=c(t),rt=i(t,"H3",{class:!0});var mi=p(rt);zt=i(mi,"A",{id:!0,class:!0,href:!0});var Wg=p(zt);Zo=i(Wg,"SPAN",{});var Hg=p(Zo);w(ja.$$.fragment,Hg),Hg.forEach(a),Wg.forEach(a),Em=c(mi),Xo=i(mi,"SPAN",{});var Rg=p(Xo);Am=r(Rg,"AutoModel"),Rg.forEach(a),mi.forEach(a),yl=c(t),w(Pt.$$.fragment,t),bl=c(t),w(xt.$$.fragment,t),Tl=c(t),ot=i(t,"H3",{class:!0});var di=p(ot);Ft=i(di,"A",{id:!0,class:!0,href:!0});var Yg=p(Ft);en=i(Yg,"SPAN",{});var Ug=p(en);w(qa.$$.fragment,Ug),Ug.forEach(a),Yg.forEach(a),jm=c(di),tn=i(di,"SPAN",{});var Gg=p(tn);qm=r(Gg,"Save a model"),Gg.forEach(a),di.forEach(a),El=c(t),w(Ct.$$.fragment,t),Al=c(t),Ge=i(t,"P",{});var br=p(Ge);zm=r(br,"One particularly cool \u{1F917} Transformers feature is the ability to save a model and reload it as either a PyTorch or TensorFlow model. The "),an=i(br,"CODE",{});var Kg=p(an);Pm=r(Kg,"from_pt"),Kg.forEach(a),xm=r(br," or "),sn=i(br,"CODE",{});var Bg=p(sn);Fm=r(Bg,"from_tf"),Bg.forEach(a),Cm=r(br," parameter can convert the model from one framework to the other:"),br.forEach(a),jl=c(t),w(Mt.$$.fragment,t),ql=c(t),nt=i(t,"H2",{class:!0});var ui=p(nt);St=i(ui,"A",{id:!0,class:!0,href:!0});var Qg=p(St);rn=i(Qg,"SPAN",{});var Vg=p(rn);w(za.$$.fragment,Vg),Vg.forEach(a),Qg.forEach(a),Mm=c(ui),on=i(ui,"SPAN",{});var Jg=p(on);Sm=r(Jg,"Custom model builds"),Jg.forEach(a),ui.forEach(a),zl=c(t),Js=i(t,"P",{});var Zg=p(Js);Dm=r(Zg,"You can modify the model\u2019s configuration class to change how a model is built. The configuration specifies a model\u2019s attributes, such as the number of hidden layers or attention heads. You start from scratch when you initialize a model from a custom configuration class. The model attributes are randomly initialized, and you\u2019ll need to train the model before you can use it to get meaningful results."),Zg.forEach(a),Pl=c(t),Ke=i(t,"P",{});var Tr=p(Ke);Im=r(Tr,"Start by importing "),Zs=i(Tr,"A",{href:!0});var Xg=p(Zs);Om=r(Xg,"AutoConfig"),Xg.forEach(a),Nm=r(Tr,", and then load the pretrained model you want to modify. Within "),Xs=i(Tr,"A",{href:!0});var e$=p(Xs);Lm=r(e$,"AutoConfig.from_pretrained()"),e$.forEach(a),Wm=r(Tr,", you can specify the attribute you want to change, such as the number of attention heads:"),Tr.forEach(a),xl=c(t),w(Pa.$$.fragment,t),Fl=c(t),w(Dt.$$.fragment,t),Cl=c(t),It=i(t,"P",{});var hi=p(It);Hm=r(hi,"Take a look at the "),er=i(hi,"A",{href:!0});var t$=p(er);Rm=r(t$,"Create a custom architecture"),t$.forEach(a),Ym=r(hi," guide for more information about building custom configurations."),hi.forEach(a),Ml=c(t),lt=i(t,"H2",{class:!0});var gi=p(lt);Ot=i(gi,"A",{id:!0,class:!0,href:!0});var a$=p(Ot);nn=i(a$,"SPAN",{});var s$=p(nn);w(xa.$$.fragment,s$),s$.forEach(a),a$.forEach(a),Um=c(gi),ln=i(gi,"SPAN",{});var r$=p(ln);Gm=r(r$,"Trainer - a PyTorch optimized training loop"),r$.forEach(a),gi.forEach(a),Sl=c(t),Be=i(t,"P",{});var Er=p(Be);Km=r(Er,"All models are a standard "),Fa=i(Er,"A",{href:!0,rel:!0});var o$=p(Fa);pn=i(o$,"CODE",{});var n$=p(pn);Bm=r(n$,"torch.nn.Module"),n$.forEach(a),o$.forEach(a),Qm=r(Er," so you can use them in any typical training loop. While you can write your own training loop, \u{1F917} Transformers provides a "),tr=i(Er,"A",{href:!0});var l$=p(tr);Vm=r(l$,"Trainer"),l$.forEach(a),Jm=r(Er," class for PyTorch, which contains the basic training loop and adds additional functionality for features like distributed training, mixed precision, and more."),Er.forEach(a),Dl=c(t),Nt=i(t,"P",{});var $i=p(Nt);Zm=r($i,"Depending on your task, you\u2019ll typically pass the following parameters to "),ar=i($i,"A",{href:!0});var i$=p(ar);Xm=r(i$,"Trainer"),i$.forEach(a),ed=r($i,":"),$i.forEach(a),Il=c(t),ce=i(t,"OL",{});var Xe=p(ce);Ca=i(Xe,"LI",{});var _i=p(Ca);it=i(_i,"P",{});var Ar=p(it);td=r(Ar,"A "),sr=i(Ar,"A",{href:!0});var p$=p(sr);ad=r(p$,"PreTrainedModel"),p$.forEach(a),sd=r(Ar," or a "),Ma=i(Ar,"A",{href:!0,rel:!0});var f$=p(Ma);fn=i(f$,"CODE",{});var c$=p(fn);rd=r(c$,"torch.nn.Module"),c$.forEach(a),f$.forEach(a),od=r(Ar,":"),Ar.forEach(a),nd=c(_i),w(Sa.$$.fragment,_i),_i.forEach(a),ld=c(Xe),Da=i(Xe,"LI",{});var vi=p(Da);rr=i(vi,"P",{});var Du=p(rr);or=i(Du,"A",{href:!0});var m$=p(or);id=r(m$,"TrainingArguments"),m$.forEach(a),pd=r(Du," contains the model hyperparameters you can change like learning rate, batch size, and the number of epochs to train for. The default values are used if you don\u2019t specify any training arguments:"),Du.forEach(a),fd=c(vi),w(Ia.$$.fragment,vi),vi.forEach(a),cd=c(Xe),Oa=i(Xe,"LI",{});var ki=p(Oa);cn=i(ki,"P",{});var d$=p(cn);md=r(d$,"A preprocessing class like a tokenizer, feature extractor, or processor:"),d$.forEach(a),dd=c(ki),w(Na.$$.fragment,ki),ki.forEach(a),ud=c(Xe),La=i(Xe,"LI",{});var wi=p(La);mn=i(wi,"P",{});var u$=p(mn);hd=r(u$,"Load a dataset:"),u$.forEach(a),gd=c(wi),w(Wa.$$.fragment,wi),wi.forEach(a),$d=c(Xe),Ha=i(Xe,"LI",{});var yi=p(Ha);Ra=i(yi,"P",{});var bi=p(Ra);_d=r(bi,"Create a function to tokenize the dataset, and apply it over the entire dataset with "),Ya=i(bi,"A",{href:!0,rel:!0});var h$=p(Ya);vd=r(h$,"map"),h$.forEach(a),kd=r(bi,":"),bi.forEach(a),wd=c(yi),w(Ua.$$.fragment,yi),yi.forEach(a),Xe.forEach(a),Ol=c(t),nr=i(t,"BLOCKQUOTE",{});var g$=p(nr);dn=i(g$,"BLOCKQUOTE",{});var $$=p(dn);Ga=i($$,"BLOCKQUOTE",{});var Ti=p(Ga);un=i(Ti,"P",{});var _$=p(un);yd=r(_$,"dataset = dataset.map(tokenize_dataset, batched=True)"),_$.forEach(a),bd=c(Ti),w(Ka.$$.fragment,Ti),Ti.forEach(a),$$.forEach(a),g$.forEach(a),Nl=c(t),Ba=i(t,"OL",{start:!0});var v$=p(Ba);Qa=i(v$,"LI",{});var Ei=p(Qa);Va=i(Ei,"P",{});var Ai=p(Va);Td=r(Ai,"A "),lr=i(Ai,"A",{href:!0});var k$=p(lr);Ed=r(k$,"DataCollatorWithPadding"),k$.forEach(a),Ad=r(Ai," to create a batch of examples from your dataset:"),Ai.forEach(a),jd=c(Ei),w(Ja.$$.fragment,Ei),Ei.forEach(a),v$.forEach(a),Ll=c(t),Lt=i(t,"P",{});var ji=p(Lt);qd=r(ji,"Now gather all these classes in "),ir=i(ji,"A",{href:!0});var w$=p(ir);zd=r(w$,"Trainer"),w$.forEach(a),Pd=r(ji,":"),ji.forEach(a),Wl=c(t),w(Za.$$.fragment,t),Hl=c(t),Wt=i(t,"P",{});var qi=p(Wt);xd=r(qi,"When you\u2019re ready, call "),pr=i(qi,"A",{href:!0});var y$=p(pr);Fd=r(y$,"train()"),y$.forEach(a),Cd=r(qi," to start training:"),qi.forEach(a),Rl=c(t),w(Xa.$$.fragment,t),Yl=c(t),w(Ht.$$.fragment,t),Ul=c(t),Qe=i(t,"P",{});var jr=p(Qe);Md=r(jr,"You can customize the training loop behavior by subclassing the methods inside "),fr=i(jr,"A",{href:!0});var b$=p(fr);Sd=r(b$,"Trainer"),b$.forEach(a),Dd=r(jr,". This allows you to customize features such as the loss function, optimizer, and scheduler. Take a look at the "),cr=i(jr,"A",{href:!0});var T$=p(cr);Id=r(T$,"Trainer"),T$.forEach(a),Od=r(jr," reference for which methods can be subclassed."),jr.forEach(a),Gl=c(t),Ve=i(t,"P",{});var qr=p(Ve);Nd=r(qr,"The other way to customize the training loop is by using "),mr=i(qr,"A",{href:!0});var E$=p(mr);Ld=r(E$,"Callbacks"),E$.forEach(a),Wd=r(qr,". You can use callbacks to integrate with other libraries and inspect the training loop to report on progress or stop the training early. Callbacks do not modify anything in the training loop itself. To customize something like the loss function, you need to subclass the "),dr=i(qr,"A",{href:!0});var A$=p(dr);Hd=r(A$,"Trainer"),A$.forEach(a),Rd=r(qr," instead."),qr.forEach(a),Kl=c(t),pt=i(t,"H2",{class:!0});var zi=p(pt);Rt=i(zi,"A",{id:!0,class:!0,href:!0});var j$=p(Rt);hn=i(j$,"SPAN",{});var q$=p(hn);w(es.$$.fragment,q$),q$.forEach(a),j$.forEach(a),Yd=c(zi),gn=i(zi,"SPAN",{});var z$=p(gn);Ud=r(z$,"Train with TensorFlow"),z$.forEach(a),zi.forEach(a),Bl=c(t),te=i(t,"P",{});var de=p(te);Gd=r(de,"All models are a standard "),ts=i(de,"A",{href:!0,rel:!0});var P$=p(ts);$n=i(P$,"CODE",{});var x$=p($n);Kd=r(x$,"tf.keras.Model"),x$.forEach(a),P$.forEach(a),Bd=r(de," so they can be trained in TensorFlow with the "),as=i(de,"A",{href:!0,rel:!0});var F$=p(as);Qd=r(F$,"Keras"),F$.forEach(a),Vd=r(de," API. \u{1F917} Transformers provides the "),ur=i(de,"A",{href:!0});var C$=p(ur);Jd=r(C$,"prepare_tf_dataset()"),C$.forEach(a),Zd=r(de," method to easily load your dataset as a "),_n=i(de,"CODE",{});var M$=p(_n);Xd=r(M$,"tf.data.Dataset"),M$.forEach(a),eu=r(de," so you can start training right away with Keras\u2019 "),ss=i(de,"A",{href:!0,rel:!0});var S$=p(ss);vn=i(S$,"CODE",{});var D$=p(vn);tu=r(D$,"compile"),D$.forEach(a),S$.forEach(a),au=r(de," and "),rs=i(de,"A",{href:!0,rel:!0});var I$=p(rs);kn=i(I$,"CODE",{});var O$=p(kn);su=r(O$,"fit"),O$.forEach(a),I$.forEach(a),ru=r(de," methods."),de.forEach(a),Ql=c(t),me=i(t,"OL",{});var et=p(me);os=i(et,"LI",{});var Pi=p(os);ft=i(Pi,"P",{});var zr=p(ft);ou=r(zr,"You\u2019ll start with a "),hr=i(zr,"A",{href:!0});var N$=p(hr);nu=r(N$,"TFPreTrainedModel"),N$.forEach(a),lu=r(zr," or a "),ns=i(zr,"A",{href:!0,rel:!0});var L$=p(ns);wn=i(L$,"CODE",{});var W$=p(wn);iu=r(W$,"tf.keras.Model"),W$.forEach(a),L$.forEach(a),pu=r(zr,":"),zr.forEach(a),fu=c(Pi),w(ls.$$.fragment,Pi),Pi.forEach(a),cu=c(et),is=i(et,"LI",{});var xi=p(is);yn=i(xi,"P",{});var H$=p(yn);mu=r(H$,"A preprocessing class like a tokenizer, feature extractor, or processor:"),H$.forEach(a),du=c(xi),w(ps.$$.fragment,xi),xi.forEach(a),uu=c(et),fs=i(et,"LI",{});var Fi=p(fs);bn=i(Fi,"P",{});var R$=p(bn);hu=r(R$,"Create a function to tokenize the dataset:"),R$.forEach(a),gu=c(Fi),w(cs.$$.fragment,Fi),Fi.forEach(a),$u=c(et),ms=i(et,"LI",{});var Ci=p(ms);ct=i(Ci,"P",{});var Pr=p(ct);_u=r(Pr,"Apply the tokenizer over the entire dataset with "),ds=i(Pr,"A",{href:!0,rel:!0});var Y$=p(ds);vu=r(Y$,"map"),Y$.forEach(a),ku=r(Pr," and then pass the dataset and tokenizer to "),gr=i(Pr,"A",{href:!0});var U$=p(gr);wu=r(U$,"prepare_tf_dataset()"),U$.forEach(a),yu=r(Pr,". You can also change the batch size and shuffle the dataset here if you\u2019d like:"),Pr.forEach(a),bu=c(Ci),w(us.$$.fragment,Ci),Ci.forEach(a),Tu=c(et),hs=i(et,"LI",{});var Mi=p(hs);mt=i(Mi,"P",{});var xr=p(mt);Eu=r(xr,"When you\u2019re ready, you can call "),Tn=i(xr,"CODE",{});var G$=p(Tn);Au=r(G$,"compile"),G$.forEach(a),ju=r(xr," and "),En=i(xr,"CODE",{});var K$=p(En);qu=r(K$,"fit"),K$.forEach(a),zu=r(xr," to start training:"),xr.forEach(a),Pu=c(Mi),w(gs.$$.fragment,Mi),Mi.forEach(a),et.forEach(a),Vl=c(t),dt=i(t,"H2",{class:!0});var Si=p(dt);Yt=i(Si,"A",{id:!0,class:!0,href:!0});var B$=p(Yt);An=i(B$,"SPAN",{});var Q$=p(An);w($s.$$.fragment,Q$),Q$.forEach(a),B$.forEach(a),xu=c(Si),jn=i(Si,"SPAN",{});var V$=p(jn);Fu=r(V$,"What's next?"),V$.forEach(a),Si.forEach(a),Jl=c(t),$r=i(t,"P",{});var J$=p($r);Cu=r(J$,"Now that you\u2019ve completed the \u{1F917} Transformers quick tour, check out our guides and learn how to do more specific things like writing a custom model, fine-tuning a model for a task, and how to train a model with a script. If you\u2019re interested in learning more about \u{1F917} Transformers core concepts, grab a cup of coffee and take a look at our Conceptual Guides!"),J$.forEach(a),this.h()},h(){h(o,"name","hf:doc:metadata"),h(o,"content",JSON.stringify(N_)),h(g,"id","quick-tour"),h(g,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(g,"href","#quick-tour"),h(n,"class","relative group"),h(z,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),h(D,"href","./model_doc/auto"),h(Q,"href","https://huggingface.co/course/chapter1/1"),h(Q,"rel","nofollow"),h(P,"id","pipeline"),h(P,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(P,"href","#pipeline"),h(Z,"class","relative group"),h(ge,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),h(bs,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),h(Ts,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),h(Es,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),h(As,"href","./main_classes/pipelines"),h(js,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),h(qs,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),h(la,"href","https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english"),h(la,"rel","nofollow"),h(zs,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),h(Ps,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),h(ca,"href","https://huggingface.co/docs/datasets/quickstart#audio"),h(ca,"rel","nofollow"),h(ma,"href","https://huggingface.co/datasets/PolyAI/minds14"),h(ma,"rel","nofollow"),h(ua,"href","https://huggingface.co/facebook/wav2vec2-base-960h"),h(ua,"rel","nofollow"),h(xs,"href","./main_classes/pipelines"),h(kt,"id","use-another-model-and-tokenizer-in-the-pipeline"),h(kt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(kt,"href","#use-another-model-and-tokenizer-in-the-pipeline"),h(tt,"class","relative group"),h(Fs,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),h(_a,"href","https://huggingface.co/models"),h(_a,"rel","nofollow"),h(Cs,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),h(va,"href","https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment"),h(va,"rel","nofollow"),h(Ms,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),h(Ss,"href","./training"),h(Ds,"href","./model_sharing"),h(yt,"id","autoclass"),h(yt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(yt,"href","#autoclass"),h(at,"class","relative group"),h(Is,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForSequenceClassification"),h(Os,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),h(Ns,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),h(Ls,"href","./model_doc/auto"),h(Ws,"href","/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline"),h(bt,"id","autotokenizer"),h(bt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(bt,"href","#autotokenizer"),h(st,"class","relative group"),h(Hs,"href","./tokenizer_summary"),h(Rs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),h(Ks,"href","./glossary#input-ids"),h(Qs,"href",".glossary#attention-mask"),h(zt,"id","automodel"),h(zt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(zt,"href","#automodel"),h(rt,"class","relative group"),h(Ft,"id","save-a-model"),h(Ft,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ft,"href","#save-a-model"),h(ot,"class","relative group"),h(St,"id","custom-model-builds"),h(St,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(St,"href","#custom-model-builds"),h(nt,"class","relative group"),h(Zs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig"),h(Xs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),h(er,"href","./create_a_model"),h(Ot,"id","trainer-a-pytorch-optimized-training-loop"),h(Ot,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ot,"href","#trainer-a-pytorch-optimized-training-loop"),h(lt,"class","relative group"),h(Fa,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),h(Fa,"rel","nofollow"),h(tr,"href","/docs/transformers/main/en/main_classes/trainer#transformers.Trainer"),h(ar,"href","/docs/transformers/main/en/main_classes/trainer#transformers.Trainer"),h(sr,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel"),h(Ma,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),h(Ma,"rel","nofollow"),h(or,"href","/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments"),h(Ya,"href","https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map"),h(Ya,"rel","nofollow"),h(lr,"href","/docs/transformers/main/en/main_classes/data_collator#transformers.DataCollatorWithPadding"),h(Ba,"start","6"),h(ir,"href","/docs/transformers/main/en/main_classes/trainer#transformers.Trainer"),h(pr,"href","/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train"),h(fr,"href","/docs/transformers/main/en/main_classes/trainer#transformers.Trainer"),h(cr,"href","/docs/transformers/main/en/main_classes/trainer#transformers.Trainer"),h(mr,"href","./main_classes/callbacks"),h(dr,"href","/docs/transformers/main/en/main_classes/trainer#transformers.Trainer"),h(Rt,"id","train-with-tensorflow"),h(Rt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Rt,"href","#train-with-tensorflow"),h(pt,"class","relative group"),h(ts,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),h(ts,"rel","nofollow"),h(as,"href","https://keras.io/"),h(as,"rel","nofollow"),h(ur,"href","/docs/transformers/main/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset"),h(ss,"href","https://keras.io/api/models/model_training_apis/#compile-method"),h(ss,"rel","nofollow"),h(rs,"href","https://keras.io/api/models/model_training_apis/#fit-method"),h(rs,"rel","nofollow"),h(hr,"href","/docs/transformers/main/en/main_classes/model#transformers.TFPreTrainedModel"),h(ns,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),h(ns,"rel","nofollow"),h(ds,"href","https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map"),h(ds,"rel","nofollow"),h(gr,"href","/docs/transformers/main/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset"),h(Yt,"id","whats-next"),h(Yt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Yt,"href","#whats-next"),h(dt,"class","relative group")},m(t,m){e(document.head,o),d(t,u,m),d(t,n,m),e(n,g),e(g,_),y(v,_,null),e(n,q),e(n,F),e(F,$),d(t,j,m),y(S,t,m),d(t,O,m),d(t,I,m),e(I,H),e(I,z),e(z,M),e(I,A),e(I,D),e(D,G),e(I,R),e(I,Q),e(Q,ie),e(I,oe),d(t,he,m),d(t,K,m),e(K,ne),d(t,le,m),y(B,t,m),d(t,$e,m),d(t,J,m),e(J,be),d(t,_e,m),y(V,t,m),d(t,se,m),d(t,Z,m),e(Z,P),e(P,L),y(X,L,null),e(Z,C),e(Z,W),e(W,ve),d(t,Le,m),y(ae,t,m),d(t,We,m),d(t,ee,m),e(ee,ks),e(ee,ge),e(ge,ws),e(ee,ys),e(ee,bs),e(bs,Di),e(ee,Ii),d(t,In,m),d(t,ut,m),e(ut,Fr),e(Fr,Te),e(Te,Cr),e(Cr,Mr),e(Mr,Oi),e(Te,Ni),e(Te,Sr),e(Sr,Dr),e(Dr,Li),e(Te,Wi),e(Te,Ir),e(Ir,Or),e(Or,Hi),e(Te,Ri),e(Te,Nr),e(Nr,Lr),e(Lr,Yi),e(ut,Ui),e(ut,Y),e(Y,Ee),e(Ee,Wr),e(Wr,Gi),e(Ee,Ki),e(Ee,Hr),e(Hr,Bi),e(Ee,Qi),e(Ee,Rr),e(Rr,Vi),e(Ee,Ji),e(Ee,Yr),e(Yr,Zi),e(Y,Xi),e(Y,Ae),e(Ae,Ur),e(Ur,ep),e(Ae,tp),e(Ae,Gr),e(Gr,ap),e(Ae,sp),e(Ae,Kr),e(Kr,rp),e(Ae,op),e(Ae,Br),e(Br,np),e(Y,lp),e(Y,je),e(je,Qr),e(Qr,ip),e(je,pp),e(je,Vr),e(Vr,fp),e(je,cp),e(je,Jr),e(Jr,mp),e(je,dp),e(je,Zr),e(Zr,up),e(Y,hp),e(Y,qe),e(qe,Xr),e(Xr,gp),e(qe,$p),e(qe,eo),e(eo,_p),e(qe,vp),e(qe,to),e(to,kp),e(qe,wp),e(qe,ao),e(ao,yp),e(Y,bp),e(Y,ze),e(ze,so),e(so,Tp),e(ze,Ep),e(ze,ro),e(ro,Ap),e(ze,jp),e(ze,oo),e(oo,qp),e(ze,zp),e(ze,no),e(no,Pp),e(Y,xp),e(Y,Pe),e(Pe,lo),e(lo,Fp),e(Pe,Cp),e(Pe,io),e(io,Mp),e(Pe,Sp),e(Pe,po),e(po,Dp),e(Pe,Ip),e(Pe,fo),e(fo,Op),e(Y,Np),e(Y,xe),e(xe,co),e(co,Lp),e(xe,Wp),e(xe,mo),e(mo,Hp),e(xe,Rp),e(xe,uo),e(uo,Yp),e(xe,Up),e(xe,ho),e(ho,Gp),e(Y,Kp),e(Y,Fe),e(Fe,go),e(go,Bp),e(Fe,Qp),e(Fe,$o),e($o,Vp),e(Fe,Jp),e(Fe,_o),e(_o,Zp),e(Fe,Xp),e(Fe,vo),e(vo,ef),e(Y,tf),e(Y,Ce),e(Ce,ko),e(ko,af),e(Ce,sf),e(Ce,wo),e(wo,rf),e(Ce,of),e(Ce,yo),e(yo,nf),e(Ce,lf),e(Ce,bo),e(bo,pf),e(Y,ff),e(Y,Me),e(Me,To),e(To,cf),e(Me,mf),e(Me,Eo),e(Eo,df),e(Me,uf),e(Me,Ao),e(Ao,hf),e(Me,gf),e(Me,jo),e(jo,$f),e(Y,_f),e(Y,Se),e(Se,qo),e(qo,vf),e(Se,kf),e(Se,zo),e(zo,wf),e(Se,yf),e(Se,Po),e(Po,bf),e(Se,Tf),e(Se,xo),e(xo,Ef),e(Y,Af),e(Y,De),e(De,Fo),e(Fo,jf),e(De,qf),e(De,Co),e(Co,zf),e(De,Pf),e(De,Mo),e(Mo,xf),e(De,Ff),e(De,So),e(So,Cf),e(Y,Mf),e(Y,Ie),e(Ie,Do),e(Do,Sf),e(Ie,Df),e(Ie,Io),e(Io,If),e(Ie,Of),e(Ie,Oo),e(Oo,Nf),e(Ie,Lf),e(Ie,No),e(No,Wf),d(t,On,m),d(t,pe,m),e(pe,Hf),e(pe,Ts),e(Ts,Rf),e(pe,Yf),e(pe,Es),e(Es,Uf),e(pe,Gf),e(pe,As),e(As,Kf),e(pe,Bf),e(pe,js),e(js,Qf),e(pe,Vf),d(t,Nn,m),y(na,t,m),d(t,Ln,m),d(t,ke,m),e(ke,Jf),e(ke,qs),e(qs,Zf),e(ke,Xf),e(ke,la),e(la,ec),e(ke,tc),e(ke,Lo),e(Lo,ac),e(ke,sc),d(t,Wn,m),y(ia,t,m),d(t,Hn,m),d(t,ht,m),e(ht,rc),e(ht,zs),e(zs,oc),e(ht,nc),d(t,Rn,m),y(pa,t,m),d(t,Yn,m),d(t,gt,m),e(gt,lc),e(gt,Ps),e(Ps,ic),e(gt,pc),d(t,Un,m),y(fa,t,m),d(t,Gn,m),d(t,He,m),e(He,fc),e(He,ca),e(ca,cc),e(He,mc),e(He,ma),e(ma,dc),e(He,uc),d(t,Kn,m),y(da,t,m),d(t,Bn,m),d(t,$t,m),e($t,hc),e($t,ua),e(ua,Wo),e(Wo,gc),e($t,$c),d(t,Qn,m),y(ha,t,m),d(t,Vn,m),d(t,_t,m),e(_t,_c),e(_t,Ho),e(Ho,vc),e(_t,kc),d(t,Jn,m),y(ga,t,m),d(t,Zn,m),d(t,vt,m),e(vt,wc),e(vt,xs),e(xs,yc),e(vt,bc),d(t,Xn,m),d(t,tt,m),e(tt,kt),e(kt,Ro),y($a,Ro,null),e(tt,Tc),e(tt,Yo),e(Yo,Ec),d(t,el,m),d(t,fe,m),e(fe,Ac),e(fe,Fs),e(Fs,jc),e(fe,qc),e(fe,_a),e(_a,zc),e(fe,Pc),e(fe,Cs),e(Cs,xc),e(fe,Fc),e(fe,va),e(va,Cc),e(fe,Mc),d(t,tl,m),y(ka,t,m),d(t,al,m),y(wt,t,m),d(t,sl,m),d(t,Re,m),e(Re,Sc),e(Re,Ms),e(Ms,Dc),e(Re,Ic),e(Re,Uo),e(Uo,Oc),e(Re,Nc),d(t,rl,m),y(wa,t,m),d(t,ol,m),d(t,Ye,m),e(Ye,Lc),e(Ye,Ss),e(Ss,Wc),e(Ye,Hc),e(Ye,Ds),e(Ds,Rc),e(Ye,Yc),d(t,nl,m),d(t,at,m),e(at,yt),e(yt,Go),y(ya,Go,null),e(at,Uc),e(at,Ko),e(Ko,Gc),d(t,ll,m),y(ba,t,m),d(t,il,m),d(t,re,m),e(re,Kc),e(re,Is),e(Is,Bc),e(re,Qc),e(re,Os),e(Os,Vc),e(re,Jc),e(re,Ns),e(Ns,Zc),e(re,Xc),e(re,Ls),e(Ls,em),e(re,tm),e(re,Bo),e(Bo,am),e(re,sm),d(t,pl,m),d(t,Ue,m),e(Ue,rm),e(Ue,Qo),e(Qo,om),e(Ue,nm),e(Ue,Ws),e(Ws,lm),e(Ue,im),d(t,fl,m),d(t,st,m),e(st,bt),e(bt,Vo),y(Ta,Vo,null),e(st,pm),e(st,Jo),e(Jo,fm),d(t,cl,m),d(t,Tt,m),e(Tt,cm),e(Tt,Hs),e(Hs,mm),e(Tt,dm),d(t,ml,m),d(t,Et,m),e(Et,um),e(Et,Rs),e(Rs,hm),e(Et,gm),d(t,dl,m),y(Ea,t,m),d(t,ul,m),d(t,Ys,m),e(Ys,$m),d(t,hl,m),y(Aa,t,m),d(t,gl,m),d(t,Us,m),e(Us,_m),d(t,$l,m),d(t,At,m),e(At,Gs),e(Gs,Ks),e(Ks,vm),e(Gs,km),e(At,wm),e(At,Bs),e(Bs,Qs),e(Qs,ym),e(Bs,bm),d(t,_l,m),d(t,Vs,m),e(Vs,Tm),d(t,vl,m),y(jt,t,m),d(t,kl,m),y(qt,t,m),d(t,wl,m),d(t,rt,m),e(rt,zt),e(zt,Zo),y(ja,Zo,null),e(rt,Em),e(rt,Xo),e(Xo,Am),d(t,yl,m),y(Pt,t,m),d(t,bl,m),y(xt,t,m),d(t,Tl,m),d(t,ot,m),e(ot,Ft),e(Ft,en),y(qa,en,null),e(ot,jm),e(ot,tn),e(tn,qm),d(t,El,m),y(Ct,t,m),d(t,Al,m),d(t,Ge,m),e(Ge,zm),e(Ge,an),e(an,Pm),e(Ge,xm),e(Ge,sn),e(sn,Fm),e(Ge,Cm),d(t,jl,m),y(Mt,t,m),d(t,ql,m),d(t,nt,m),e(nt,St),e(St,rn),y(za,rn,null),e(nt,Mm),e(nt,on),e(on,Sm),d(t,zl,m),d(t,Js,m),e(Js,Dm),d(t,Pl,m),d(t,Ke,m),e(Ke,Im),e(Ke,Zs),e(Zs,Om),e(Ke,Nm),e(Ke,Xs),e(Xs,Lm),e(Ke,Wm),d(t,xl,m),y(Pa,t,m),d(t,Fl,m),y(Dt,t,m),d(t,Cl,m),d(t,It,m),e(It,Hm),e(It,er),e(er,Rm),e(It,Ym),d(t,Ml,m),d(t,lt,m),e(lt,Ot),e(Ot,nn),y(xa,nn,null),e(lt,Um),e(lt,ln),e(ln,Gm),d(t,Sl,m),d(t,Be,m),e(Be,Km),e(Be,Fa),e(Fa,pn),e(pn,Bm),e(Be,Qm),e(Be,tr),e(tr,Vm),e(Be,Jm),d(t,Dl,m),d(t,Nt,m),e(Nt,Zm),e(Nt,ar),e(ar,Xm),e(Nt,ed),d(t,Il,m),d(t,ce,m),e(ce,Ca),e(Ca,it),e(it,td),e(it,sr),e(sr,ad),e(it,sd),e(it,Ma),e(Ma,fn),e(fn,rd),e(it,od),e(Ca,nd),y(Sa,Ca,null),e(ce,ld),e(ce,Da),e(Da,rr),e(rr,or),e(or,id),e(rr,pd),e(Da,fd),y(Ia,Da,null),e(ce,cd),e(ce,Oa),e(Oa,cn),e(cn,md),e(Oa,dd),y(Na,Oa,null),e(ce,ud),e(ce,La),e(La,mn),e(mn,hd),e(La,gd),y(Wa,La,null),e(ce,$d),e(ce,Ha),e(Ha,Ra),e(Ra,_d),e(Ra,Ya),e(Ya,vd),e(Ra,kd),e(Ha,wd),y(Ua,Ha,null),d(t,Ol,m),d(t,nr,m),e(nr,dn),e(dn,Ga),e(Ga,un),e(un,yd),e(Ga,bd),y(Ka,Ga,null),d(t,Nl,m),d(t,Ba,m),e(Ba,Qa),e(Qa,Va),e(Va,Td),e(Va,lr),e(lr,Ed),e(Va,Ad),e(Qa,jd),y(Ja,Qa,null),d(t,Ll,m),d(t,Lt,m),e(Lt,qd),e(Lt,ir),e(ir,zd),e(Lt,Pd),d(t,Wl,m),y(Za,t,m),d(t,Hl,m),d(t,Wt,m),e(Wt,xd),e(Wt,pr),e(pr,Fd),e(Wt,Cd),d(t,Rl,m),y(Xa,t,m),d(t,Yl,m),y(Ht,t,m),d(t,Ul,m),d(t,Qe,m),e(Qe,Md),e(Qe,fr),e(fr,Sd),e(Qe,Dd),e(Qe,cr),e(cr,Id),e(Qe,Od),d(t,Gl,m),d(t,Ve,m),e(Ve,Nd),e(Ve,mr),e(mr,Ld),e(Ve,Wd),e(Ve,dr),e(dr,Hd),e(Ve,Rd),d(t,Kl,m),d(t,pt,m),e(pt,Rt),e(Rt,hn),y(es,hn,null),e(pt,Yd),e(pt,gn),e(gn,Ud),d(t,Bl,m),d(t,te,m),e(te,Gd),e(te,ts),e(ts,$n),e($n,Kd),e(te,Bd),e(te,as),e(as,Qd),e(te,Vd),e(te,ur),e(ur,Jd),e(te,Zd),e(te,_n),e(_n,Xd),e(te,eu),e(te,ss),e(ss,vn),e(vn,tu),e(te,au),e(te,rs),e(rs,kn),e(kn,su),e(te,ru),d(t,Ql,m),d(t,me,m),e(me,os),e(os,ft),e(ft,ou),e(ft,hr),e(hr,nu),e(ft,lu),e(ft,ns),e(ns,wn),e(wn,iu),e(ft,pu),e(os,fu),y(ls,os,null),e(me,cu),e(me,is),e(is,yn),e(yn,mu),e(is,du),y(ps,is,null),e(me,uu),e(me,fs),e(fs,bn),e(bn,hu),e(fs,gu),y(cs,fs,null),e(me,$u),e(me,ms),e(ms,ct),e(ct,_u),e(ct,ds),e(ds,vu),e(ct,ku),e(ct,gr),e(gr,wu),e(ct,yu),e(ms,bu),y(us,ms,null),e(me,Tu),e(me,hs),e(hs,mt),e(mt,Eu),e(mt,Tn),e(Tn,Au),e(mt,ju),e(mt,En),e(En,qu),e(mt,zu),e(hs,Pu),y(gs,hs,null),d(t,Vl,m),d(t,dt,m),e(dt,Yt),e(Yt,An),y($s,An,null),e(dt,xu),e(dt,jn),e(jn,Fu),d(t,Jl,m),d(t,$r,m),e($r,Cu),Zl=!0},p(t,[m]){const _s={};m&2&&(_s.$$scope={dirty:m,ctx:t}),V.$set(_s);const qn={};m&2&&(qn.$$scope={dirty:m,ctx:t}),wt.$set(qn);const zn={};m&2&&(zn.$$scope={dirty:m,ctx:t}),jt.$set(zn);const Pn={};m&2&&(Pn.$$scope={dirty:m,ctx:t}),qt.$set(Pn);const Oe={};m&2&&(Oe.$$scope={dirty:m,ctx:t}),Pt.$set(Oe);const xn={};m&2&&(xn.$$scope={dirty:m,ctx:t}),xt.$set(xn);const Fn={};m&2&&(Fn.$$scope={dirty:m,ctx:t}),Ct.$set(Fn);const Cn={};m&2&&(Cn.$$scope={dirty:m,ctx:t}),Mt.$set(Cn);const Mn={};m&2&&(Mn.$$scope={dirty:m,ctx:t}),Dt.$set(Mn);const Sn={};m&2&&(Sn.$$scope={dirty:m,ctx:t}),Ht.$set(Sn)},i(t){Zl||(b(v.$$.fragment,t),b(S.$$.fragment,t),b(B.$$.fragment,t),b(V.$$.fragment,t),b(X.$$.fragment,t),b(ae.$$.fragment,t),b(na.$$.fragment,t),b(ia.$$.fragment,t),b(pa.$$.fragment,t),b(fa.$$.fragment,t),b(da.$$.fragment,t),b(ha.$$.fragment,t),b(ga.$$.fragment,t),b($a.$$.fragment,t),b(ka.$$.fragment,t),b(wt.$$.fragment,t),b(wa.$$.fragment,t),b(ya.$$.fragment,t),b(ba.$$.fragment,t),b(Ta.$$.fragment,t),b(Ea.$$.fragment,t),b(Aa.$$.fragment,t),b(jt.$$.fragment,t),b(qt.$$.fragment,t),b(ja.$$.fragment,t),b(Pt.$$.fragment,t),b(xt.$$.fragment,t),b(qa.$$.fragment,t),b(Ct.$$.fragment,t),b(Mt.$$.fragment,t),b(za.$$.fragment,t),b(Pa.$$.fragment,t),b(Dt.$$.fragment,t),b(xa.$$.fragment,t),b(Sa.$$.fragment,t),b(Ia.$$.fragment,t),b(Na.$$.fragment,t),b(Wa.$$.fragment,t),b(Ua.$$.fragment,t),b(Ka.$$.fragment,t),b(Ja.$$.fragment,t),b(Za.$$.fragment,t),b(Xa.$$.fragment,t),b(Ht.$$.fragment,t),b(es.$$.fragment,t),b(ls.$$.fragment,t),b(ps.$$.fragment,t),b(cs.$$.fragment,t),b(us.$$.fragment,t),b(gs.$$.fragment,t),b($s.$$.fragment,t),Zl=!0)},o(t){T(v.$$.fragment,t),T(S.$$.fragment,t),T(B.$$.fragment,t),T(V.$$.fragment,t),T(X.$$.fragment,t),T(ae.$$.fragment,t),T(na.$$.fragment,t),T(ia.$$.fragment,t),T(pa.$$.fragment,t),T(fa.$$.fragment,t),T(da.$$.fragment,t),T(ha.$$.fragment,t),T(ga.$$.fragment,t),T($a.$$.fragment,t),T(ka.$$.fragment,t),T(wt.$$.fragment,t),T(wa.$$.fragment,t),T(ya.$$.fragment,t),T(ba.$$.fragment,t),T(Ta.$$.fragment,t),T(Ea.$$.fragment,t),T(Aa.$$.fragment,t),T(jt.$$.fragment,t),T(qt.$$.fragment,t),T(ja.$$.fragment,t),T(Pt.$$.fragment,t),T(xt.$$.fragment,t),T(qa.$$.fragment,t),T(Ct.$$.fragment,t),T(Mt.$$.fragment,t),T(za.$$.fragment,t),T(Pa.$$.fragment,t),T(Dt.$$.fragment,t),T(xa.$$.fragment,t),T(Sa.$$.fragment,t),T(Ia.$$.fragment,t),T(Na.$$.fragment,t),T(Wa.$$.fragment,t),T(Ua.$$.fragment,t),T(Ka.$$.fragment,t),T(Ja.$$.fragment,t),T(Za.$$.fragment,t),T(Xa.$$.fragment,t),T(Ht.$$.fragment,t),T(es.$$.fragment,t),T(ls.$$.fragment,t),T(ps.$$.fragment,t),T(cs.$$.fragment,t),T(us.$$.fragment,t),T(gs.$$.fragment,t),T($s.$$.fragment,t),Zl=!1},d(t){a(o),t&&a(u),t&&a(n),E(v),t&&a(j),E(S,t),t&&a(O),t&&a(I),t&&a(he),t&&a(K),t&&a(le),E(B,t),t&&a($e),t&&a(J),t&&a(_e),E(V,t),t&&a(se),t&&a(Z),E(X),t&&a(Le),E(ae,t),t&&a(We),t&&a(ee),t&&a(In),t&&a(ut),t&&a(On),t&&a(pe),t&&a(Nn),E(na,t),t&&a(Ln),t&&a(ke),t&&a(Wn),E(ia,t),t&&a(Hn),t&&a(ht),t&&a(Rn),E(pa,t),t&&a(Yn),t&&a(gt),t&&a(Un),E(fa,t),t&&a(Gn),t&&a(He),t&&a(Kn),E(da,t),t&&a(Bn),t&&a($t),t&&a(Qn),E(ha,t),t&&a(Vn),t&&a(_t),t&&a(Jn),E(ga,t),t&&a(Zn),t&&a(vt),t&&a(Xn),t&&a(tt),E($a),t&&a(el),t&&a(fe),t&&a(tl),E(ka,t),t&&a(al),E(wt,t),t&&a(sl),t&&a(Re),t&&a(rl),E(wa,t),t&&a(ol),t&&a(Ye),t&&a(nl),t&&a(at),E(ya),t&&a(ll),E(ba,t),t&&a(il),t&&a(re),t&&a(pl),t&&a(Ue),t&&a(fl),t&&a(st),E(Ta),t&&a(cl),t&&a(Tt),t&&a(ml),t&&a(Et),t&&a(dl),E(Ea,t),t&&a(ul),t&&a(Ys),t&&a(hl),E(Aa,t),t&&a(gl),t&&a(Us),t&&a($l),t&&a(At),t&&a(_l),t&&a(Vs),t&&a(vl),E(jt,t),t&&a(kl),E(qt,t),t&&a(wl),t&&a(rt),E(ja),t&&a(yl),E(Pt,t),t&&a(bl),E(xt,t),t&&a(Tl),t&&a(ot),E(qa),t&&a(El),E(Ct,t),t&&a(Al),t&&a(Ge),t&&a(jl),E(Mt,t),t&&a(ql),t&&a(nt),E(za),t&&a(zl),t&&a(Js),t&&a(Pl),t&&a(Ke),t&&a(xl),E(Pa,t),t&&a(Fl),E(Dt,t),t&&a(Cl),t&&a(It),t&&a(Ml),t&&a(lt),E(xa),t&&a(Sl),t&&a(Be),t&&a(Dl),t&&a(Nt),t&&a(Il),t&&a(ce),E(Sa),E(Ia),E(Na),E(Wa),E(Ua),t&&a(Ol),t&&a(nr),E(Ka),t&&a(Nl),t&&a(Ba),E(Ja),t&&a(Ll),t&&a(Lt),t&&a(Wl),E(Za,t),t&&a(Hl),t&&a(Wt),t&&a(Rl),E(Xa,t),t&&a(Yl),E(Ht,t),t&&a(Ul),t&&a(Qe),t&&a(Gl),t&&a(Ve),t&&a(Kl),t&&a(pt),E(es),t&&a(Bl),t&&a(te),t&&a(Ql),t&&a(me),E(ls),E(ps),E(cs),E(us),E(gs),t&&a(Vl),t&&a(dt),E($s),t&&a(Jl),t&&a($r)}}}const N_={local:"quick-tour",sections:[{local:"pipeline",sections:[{local:"use-another-model-and-tokenizer-in-the-pipeline",title:"Use another model and tokenizer in the pipeline"}],title:"Pipeline"},{local:"autoclass",sections:[{local:"autotokenizer",title:"AutoTokenizer"},{local:"automodel",title:"AutoModel"},{local:"save-a-model",title:"Save a model"}],title:"AutoClass"},{local:"custom-model-builds",title:"Custom model builds"},{local:"trainer-a-pytorch-optimized-training-loop",title:"Trainer - a PyTorch optimized training loop"},{local:"train-with-tensorflow",title:"Train with TensorFlow"},{local:"whats-next",title:"What's next?"}],title:"Quick tour"};function L_(x){return s_(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class B_ extends X${constructor(o){super();e_(this,o,L_,O_,t_,{})}}export{B_ as default,N_ as metadata};
