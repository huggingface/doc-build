import{S as Oi,i as Ai,s as Ci,e as s,k as i,w as b,t as o,M as Li,c as r,d as t,m as c,a as n,x as v,h as l,b as d,F as e,g as m,y as _,L as Ui,q as w,o as $,B as y,v as Ii}from"../../chunks/vendor-6b77c823.js";import{D as j}from"../../chunks/Docstring-af1d0ae0.js";import{C as Pa}from"../../chunks/CodeBlock-3a8b25a8.js";import{I as at}from"../../chunks/IconCopyLink-7a11ce68.js";function zi(Xo){let O,ka,A,K,st,ne,vs,rt,_s,Ta,Y,ws,Ve,$s,ys,xa,Me,Es,Oa,C,W,nt,oe,Ds,ot,js,Aa,L,le,Ps,lt,ks,Ca,U,ie,Ts,it,xs,La,I,ce,Os,D,As,ct,Cs,Ls,pt,Us,Is,ht,zs,Ss,dt,Ns,Hs,Ua,z,pe,Gs,ut,Vs,Ia,S,J,ft,he,Ms,mt,Rs,za,N,de,Fs,gt,qs,Sa,H,Q,bt,ue,Bs,vt,Ks,Na,u,fe,Ys,_t,Ws,Js,wt,Qs,Xs,$t,yt,Zs,er,Et,tr,ar,G,Re,sr,Dt,rr,nr,Fe,or,jt,lr,ir,qe,cr,Pt,pr,hr,kt,dr,ur,V,Be,fr,Tt,mr,gr,Ke,br,xt,vr,_r,Ye,wr,Ot,$r,yr,At,Er,Dr,Ct,Lt,jr,Pr,Ut,kr,Tr,It,zt,xr,Or,St,Ar,Cr,X,me,Lr,ge,Ur,Nt,Ir,zr,Sr,Z,be,Nr,Ht,Hr,Ha,M,ee,Gt,ve,Gr,Vt,Vr,Ga,E,_e,Mr,we,Rr,Mt,Fr,qr,Br,$e,Kr,Rt,Yr,Wr,Jr,T,ye,Qr,Ft,Xr,Zr,Ee,en,qt,tn,an,sn,te,De,rn,je,nn,Bt,on,ln,cn,ae,Pe,pn,ke,hn,Kt,dn,un,Va,R,se,Yt,Te,fn,Wt,mn,Ma,p,xe,gn,F,bn,Jt,vn,_n,Qt,wn,$n,yn,Xt,En,Dn,Oe,Zt,jn,Pn,ea,kn,Tn,ta,xn,On,aa,An,Cn,Ae,Ln,k,Un,sa,In,zn,ra,Sn,Nn,na,Hn,Gn,Vn,Ce,Le,Mn,oa,Rn,Fn,qn,la,Bn,Kn,Ue,Yn,ia,Wn,Jn,Qn,Ie,Xn,q,Zn,ca,eo,to,pa,ao,so,ro,ha,no,oo,ze,lo,da,io,co,po,ua,ho,uo,Se,fo,fa,mo,go,ma,bo,vo,ga,_o,wo,Ne,$o,ba,yo,Eo,Do,He,jo,va,Po,ko,_a,To,xo,wa,Oo,Ao,$a,Co,Lo,Ge,Uo,ya,Io,zo,We,Ea,So,No,Ho,B,Go,Da,Vo,Mo,ja,Ro,Fo,Ra;return ne=new at({}),oe=new at({}),le=new j({props:{name:"class transformers.EvalPrediction",anchor:"transformers.EvalPrediction",parameters:[{name:"predictions",val:": typing.Union[numpy.ndarray, typing.Tuple[numpy.ndarray]]"},{name:"label_ids",val:": typing.Union[numpy.ndarray, typing.Tuple[numpy.ndarray]]"},{name:"inputs",val:": typing.Union[numpy.ndarray, typing.Tuple[numpy.ndarray], NoneType] = None"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_utils.py#L66",parametersDescription:[{anchor:"transformers.EvalPrediction.predictions",description:"<strong>predictions</strong> (<code>np.ndarray</code>) &#x2014; Predictions of the model.",name:"predictions"},{anchor:"transformers.EvalPrediction.label_ids",description:"<strong>label_ids</strong> (<code>np.ndarray</code>) &#x2014; Targets to be matched.",name:"label_ids"},{anchor:"transformers.EvalPrediction.inputs",description:"<strong>inputs</strong> (<code>np.ndarray</code>, <em>optional</em>) &#x2014;",name:"inputs"}]}}),ie=new j({props:{name:"class transformers.IntervalStrategy",anchor:"transformers.IntervalStrategy",parameters:[{name:"value",val:""},{name:"names",val:" = None"},{name:"module",val:" = None"},{name:"qualname",val:" = None"},{name:"type",val:" = None"},{name:"start",val:" = 1"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_utils.py#L140"}}),ce=new j({props:{name:"transformers.set_seed",anchor:"transformers.set_seed",parameters:[{name:"seed",val:": int"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_utils.py#L49",parametersDescription:[{anchor:"transformers.set_seed.seed",description:"<strong>seed</strong> (<code>int</code>) &#x2014; The seed to set.",name:"seed"}]}}),pe=new j({props:{name:"transformers.torch_distributed_zero_first",anchor:"transformers.torch_distributed_zero_first",parameters:[{name:"local_rank",val:": int"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_pt_utils.py#L202",parametersDescription:[{anchor:"transformers.torch_distributed_zero_first.local_rank",description:"<strong>local_rank</strong> (<code>int</code>) &#x2014; The rank of the local process.",name:"local_rank"}]}}),he=new at({}),de=new j({props:{name:"class transformers.trainer_callback.CallbackHandler",anchor:"transformers.trainer_callback.CallbackHandler",parameters:[{name:"callbacks",val:""},{name:"model",val:""},{name:"tokenizer",val:""},{name:"optimizer",val:""},{name:"lr_scheduler",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_callback.py#L284"}}),ue=new at({}),fe=new j({props:{name:"class transformers.trainer_pt_utils.DistributedTensorGatherer",anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer",parameters:[{name:"world_size",val:""},{name:"num_samples",val:""},{name:"make_multiple_of",val:" = None"},{name:"padding_index",val:" = -100"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_pt_utils.py#L328",parametersDescription:[{anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.world_size",description:`<strong>world_size</strong> (<code>int</code>) &#x2014;
The number of processes used in the distributed training.`,name:"world_size"},{anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.num_samples",description:`<strong>num_samples</strong> (<code>int</code>) &#x2014;
The number of samples in our dataset.`,name:"num_samples"},{anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.make_multiple_of",description:`<strong>make_multiple_of</strong> (<code>int</code>, <em>optional</em>) &#x2014;
If passed, the class assumes the datasets passed to each process are made to be a multiple of this argument
(by adding samples).`,name:"make_multiple_of"},{anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.padding_index",description:`<strong>padding_index</strong> (<code>int</code>, <em>optional</em>, defaults to -100) &#x2014;
The padding index to use if the arrays don&#x2019;t all have the same sequence length.`,name:"padding_index"}]}}),me=new j({props:{name:"add_arrays",anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.add_arrays",parameters:[{name:"arrays",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_pt_utils.py#L389"}}),be=new j({props:{name:"finalize",anchor:"transformers.trainer_pt_utils.DistributedTensorGatherer.finalize",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/trainer_pt_utils.py#L425"}}),ve=new at({}),_e=new j({props:{name:"class transformers.HfArgumentParser",anchor:"transformers.HfArgumentParser",parameters:[{name:"dataclass_types",val:": typing.Union[DataClassType, typing.Iterable[DataClassType]]"},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/hf_argparser.py#L44"}}),ye=new j({props:{name:"parse_args_into_dataclasses",anchor:"transformers.HfArgumentParser.parse_args_into_dataclasses",parameters:[{name:"args",val:" = None"},{name:"return_remaining_strings",val:" = False"},{name:"look_for_args_file",val:" = True"},{name:"args_filename",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/hf_argparser.py#L168",returnDescription:`
<ul>
<li>the dataclass instances in the same order as they were passed to the initializer.abspath</li>
<li>if applicable, an additional namespace for more (non-dataclass backed) arguments added to the parser
after initialization.</li>
<li>The potential list of remaining argument strings. (same as argparse.ArgumentParser.parse_known_args)</li>
</ul>
`,returnType:`
<p>Tuple consisting of</p>
`}}),De=new j({props:{name:"parse_dict",anchor:"transformers.HfArgumentParser.parse_dict",parameters:[{name:"args",val:": dict"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/hf_argparser.py#L241"}}),Pe=new j({props:{name:"parse_json_file",anchor:"transformers.HfArgumentParser.parse_json_file",parameters:[{name:"json_file",val:": str"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/hf_argparser.py#L227"}}),Te=new at({}),xe=new j({props:{name:"class transformers.debug_utils.DebugUnderflowOverflow",anchor:"transformers.debug_utils.DebugUnderflowOverflow",parameters:[{name:"model",val:""},{name:"max_frames_to_save",val:" = 21"},{name:"trace_batch_nums",val:" = []"},{name:"abort_after_batch_num",val:" = None"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/debug_utils.py#L27",parametersDescription:[{anchor:"transformers.debug_utils.DebugUnderflowOverflow.model",description:`<strong>model</strong> (<code>nn.Module</code>) &#x2014;
The model to debug.`,name:"model"},{anchor:"transformers.debug_utils.DebugUnderflowOverflow.max_frames_to_save",description:`<strong>max_frames_to_save</strong> (<code>int</code>, <em>optional</em>, defaults to 21) &#x2014;
How many frames back to record`,name:"max_frames_to_save"},{anchor:"transformers.debug_utils.DebugUnderflowOverflow.trace_batch_nums(List[int],",description:`<strong>trace_batch_nums(<code>List[int]</code>,</strong> <em>optional</em>, defaults to <code>[]</code>) &#x2014;
Which batch numbers to trace (turns detection off)`,name:"trace_batch_nums(List[int],"},{anchor:"transformers.debug_utils.DebugUnderflowOverflow.abort_after_batch_num",description:"<strong>abort_after_batch_num</strong>  (`int&#x201C;, <em>optional</em>) &#x2014;\nWhether to abort after a certain batch number has finished",name:"abort_after_batch_num"}]}}),Ae=new Pa({props:{code:"debug_overflow = DebugUnderflowOverflow(model)",highlighted:"debug_overflow = DebugUnderflowOverflow(model)"}}),Ie=new Pa({props:{code:`Detected inf/nan during batch_number=0
Last 21 forward frames:
abs min  abs max  metadata
[...]
                  encoder.block.2.layer.1.DenseReluDense.wi_0 Linear
2.17e-07 4.50e+00 weight
1.79e-06 4.65e+00 input[0]
2.68e-06 3.70e+01 output
                  encoder.block.2.layer.1.DenseReluDense.wi_1 Linear
8.08e-07 2.66e+01 weight
1.79e-06 4.65e+00 input[0]
1.27e-04 2.37e+02 output
                  encoder.block.2.layer.1.DenseReluDense.wo Linear
1.01e-06 6.44e+00 weight
0.00e+00 9.74e+03 input[0]
3.18e-04 6.27e+04 output
                  encoder.block.2.layer.1.DenseReluDense T5DenseGatedGeluDense
1.79e-06 4.65e+00 input[0]
3.18e-04 6.27e+04 output
                  encoder.block.2.layer.1.dropout Dropout
3.18e-04 6.27e+04 input[0]
0.00e+00      inf output`,highlighted:`<span class="hljs-attribute">Detected</span> inf/nan during batch_number=<span class="hljs-number">0</span>
<span class="hljs-attribute">Last</span> <span class="hljs-number">21</span> forward frames:
<span class="hljs-attribute">abs</span> min  abs max  metadata<span class="hljs-meta">
[...]</span>
                  <span class="hljs-attribute">encoder</span>.block.<span class="hljs-number">2</span>.layer.<span class="hljs-number">1</span>.DenseReluDense.wi_0 Linear
<span class="hljs-attribute">2</span>.<span class="hljs-number">17</span>e-<span class="hljs-number">07</span> <span class="hljs-number">4</span>.<span class="hljs-number">50</span>e+<span class="hljs-number">00</span> weight
<span class="hljs-attribute">1</span>.<span class="hljs-number">79</span>e-<span class="hljs-number">06</span> <span class="hljs-number">4</span>.<span class="hljs-number">65</span>e+<span class="hljs-number">00</span> input[<span class="hljs-number">0</span>]
<span class="hljs-attribute">2</span>.<span class="hljs-number">68</span>e-<span class="hljs-number">06</span> <span class="hljs-number">3</span>.<span class="hljs-number">70</span>e+<span class="hljs-number">01</span> output
                  <span class="hljs-attribute">encoder</span>.block.<span class="hljs-number">2</span>.layer.<span class="hljs-number">1</span>.DenseReluDense.wi_1 Linear
<span class="hljs-attribute">8</span>.<span class="hljs-number">08</span>e-<span class="hljs-number">07</span> <span class="hljs-number">2</span>.<span class="hljs-number">66</span>e+<span class="hljs-number">01</span> weight
<span class="hljs-attribute">1</span>.<span class="hljs-number">79</span>e-<span class="hljs-number">06</span> <span class="hljs-number">4</span>.<span class="hljs-number">65</span>e+<span class="hljs-number">00</span> input[<span class="hljs-number">0</span>]
<span class="hljs-attribute">1</span>.<span class="hljs-number">27</span>e-<span class="hljs-number">04</span> <span class="hljs-number">2</span>.<span class="hljs-number">37</span>e+<span class="hljs-number">02</span> output
                  <span class="hljs-attribute">encoder</span>.block.<span class="hljs-number">2</span>.layer.<span class="hljs-number">1</span>.DenseReluDense.wo Linear
<span class="hljs-attribute">1</span>.<span class="hljs-number">01</span>e-<span class="hljs-number">06</span> <span class="hljs-number">6</span>.<span class="hljs-number">44</span>e+<span class="hljs-number">00</span> weight
<span class="hljs-attribute">0</span>.<span class="hljs-number">00</span>e+<span class="hljs-number">00</span> <span class="hljs-number">9</span>.<span class="hljs-number">74</span>e+<span class="hljs-number">03</span> input[<span class="hljs-number">0</span>]
<span class="hljs-attribute">3</span>.<span class="hljs-number">18</span>e-<span class="hljs-number">04</span> <span class="hljs-number">6</span>.<span class="hljs-number">27</span>e+<span class="hljs-number">04</span> output
                  <span class="hljs-attribute">encoder</span>.block.<span class="hljs-number">2</span>.layer.<span class="hljs-number">1</span>.DenseReluDense T5DenseGatedGeluDense
<span class="hljs-attribute">1</span>.<span class="hljs-number">79</span>e-<span class="hljs-number">06</span> <span class="hljs-number">4</span>.<span class="hljs-number">65</span>e+<span class="hljs-number">00</span> input[<span class="hljs-number">0</span>]
<span class="hljs-attribute">3</span>.<span class="hljs-number">18</span>e-<span class="hljs-number">04</span> <span class="hljs-number">6</span>.<span class="hljs-number">27</span>e+<span class="hljs-number">04</span> output
                  <span class="hljs-attribute">encoder</span>.block.<span class="hljs-number">2</span>.layer.<span class="hljs-number">1</span>.dropout Dropout
<span class="hljs-attribute">3</span>.<span class="hljs-number">18</span>e-<span class="hljs-number">04</span> <span class="hljs-number">6</span>.<span class="hljs-number">27</span>e+<span class="hljs-number">04</span> input[<span class="hljs-number">0</span>]
<span class="hljs-attribute">0</span>.<span class="hljs-number">00</span>e+<span class="hljs-number">00</span>      inf output`}}),Se=new Pa({props:{code:"debug_overflow = DebugUnderflowOverflow(model, max_frames_to_save=100)",highlighted:'debug_overflow = DebugUnderflowOverflow(model, max_frames_to_save=<span class="hljs-number">100</span>)'}}),He=new Pa({props:{code:"debug_overflow = DebugUnderflowOverflow(model, trace_batch_nums=[1, 3])",highlighted:'debug_overflow = DebugUnderflowOverflow(model, trace_batch_nums=[<span class="hljs-number">1</span>, <span class="hljs-number">3</span>])'}}),Ge=new Pa({props:{code:"debug_overflow = DebugUnderflowOverflow(model, trace_batch_nums=[1, 3], abort_after_batch_num=3)",highlighted:'debug_overflow = DebugUnderflowOverflow(model, trace_batch_nums=[<span class="hljs-number">1</span>, <span class="hljs-number">3</span>], abort_after_batch_num=<span class="hljs-number">3</span>)'}}),{c(){O=s("meta"),ka=i(),A=s("h1"),K=s("a"),st=s("span"),b(ne.$$.fragment),vs=i(),rt=s("span"),_s=o("Utilities for Trainer"),Ta=i(),Y=s("p"),ws=o("This page lists all the utility functions used by "),Ve=s("a"),$s=o("Trainer"),ys=o("."),xa=i(),Me=s("p"),Es=o("Most of those are only useful if you are studying the code of the Trainer in the library."),Oa=i(),C=s("h2"),W=s("a"),nt=s("span"),b(oe.$$.fragment),Ds=i(),ot=s("span"),js=o("Utilities"),Aa=i(),L=s("div"),b(le.$$.fragment),Ps=i(),lt=s("p"),ks=o("Evaluation output (always contains labels), to be used to compute metrics."),Ca=i(),U=s("div"),b(ie.$$.fragment),Ts=i(),it=s("p"),xs=o("An enumeration."),La=i(),I=s("div"),b(ce.$$.fragment),Os=i(),D=s("p"),As=o("Helper function for reproducible behavior to set the seed in "),ct=s("code"),Cs=o("random"),Ls=o(", "),pt=s("code"),Us=o("numpy"),Is=o(", "),ht=s("code"),zs=o("torch"),Ss=o(" and/or "),dt=s("code"),Ns=o("tf"),Hs=o(" (if installed)."),Ua=i(),z=s("div"),b(pe.$$.fragment),Gs=i(),ut=s("p"),Vs=o("Decorator to make all processes in distributed training wait for each local_master to do something."),Ia=i(),S=s("h2"),J=s("a"),ft=s("span"),b(he.$$.fragment),Ms=i(),mt=s("span"),Rs=o("Callbacks internals"),za=i(),N=s("div"),b(de.$$.fragment),Fs=i(),gt=s("p"),qs=o("Internal class that just calls the list of callbacks in order."),Sa=i(),H=s("h2"),Q=s("a"),bt=s("span"),b(ue.$$.fragment),Bs=i(),vt=s("span"),Ks=o("Distributed Evaluation"),Na=i(),u=s("div"),b(fe.$$.fragment),Ys=i(),_t=s("p"),Ws=o("A class responsible for properly gathering tensors (or nested list/tuple of tensors) on the CPU by chunks."),Js=i(),wt=s("p"),Qs=o(`If our dataset has 16 samples with a batch size of 2 on 3 processes and we gather then transfer on CPU at every
step, our sampler will generate the following indices:`),Xs=i(),$t=s("p"),yt=s("code"),Zs=o("[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 0, 1]"),er=i(),Et=s("p"),tr=o(`to get something of size a multiple of 3 (so that each process gets the same dataset length). Then process 0, 1 and
2 will be responsible of making predictions for the following samples:`),ar=i(),G=s("ul"),Re=s("li"),sr=o("P0: "),Dt=s("code"),rr=o("[0, 1, 2, 3, 4, 5]"),nr=i(),Fe=s("li"),or=o("P1: "),jt=s("code"),lr=o("[6, 7, 8, 9, 10, 11]"),ir=i(),qe=s("li"),cr=o("P2: "),Pt=s("code"),pr=o("[12, 13, 14, 15, 0, 1]"),hr=i(),kt=s("p"),dr=o("The first batch treated on each process will be"),ur=i(),V=s("ul"),Be=s("li"),fr=o("P0: "),Tt=s("code"),mr=o("[0, 1]"),gr=i(),Ke=s("li"),br=o("P1: "),xt=s("code"),vr=o("[6, 7]"),_r=i(),Ye=s("li"),wr=o("P2: "),Ot=s("code"),$r=o("[12, 13]"),yr=i(),At=s("p"),Er=o(`So if we gather at the end of the first batch, we will get a tensor (nested list/tuple of tensor) corresponding to
the following indices:`),Dr=i(),Ct=s("p"),Lt=s("code"),jr=o("[0, 1, 6, 7, 12, 13]"),Pr=i(),Ut=s("p"),kr=o(`If we directly concatenate our results without taking any precautions, the user will then get the predictions for
the indices in this order at the end of the prediction loop:`),Tr=i(),It=s("p"),zt=s("code"),xr=o("[0, 1, 6, 7, 12, 13, 2, 3, 8, 9, 14, 15, 4, 5, 10, 11, 0, 1]"),Or=i(),St=s("p"),Ar=o("For some reason, that\u2019s not going to roll their boat. This class is there to solve that problem."),Cr=i(),X=s("div"),b(me.$$.fragment),Lr=i(),ge=s("p"),Ur=o("Add "),Nt=s("code"),Ir=o("arrays"),zr=o(` to the internal storage, Will initialize the storage to the full size at the first arrays passed
so that if we\u2019re bound to get an OOM, it happens at the beginning.`),Sr=i(),Z=s("div"),b(be.$$.fragment),Nr=i(),Ht=s("p"),Hr=o(`Return the properly gathered arrays and truncate to the number of samples (since the sampler added some extras
to get each process a dataset of the same length).`),Ha=i(),M=s("h2"),ee=s("a"),Gt=s("span"),b(ve.$$.fragment),Gr=i(),Vt=s("span"),Vr=o("Distributed Evaluation"),Ga=i(),E=s("div"),b(_e.$$.fragment),Mr=i(),we=s("p"),Rr=o("This subclass of "),Mt=s("code"),Fr=o("argparse.ArgumentParser"),qr=o(" uses type hints on dataclasses to generate arguments."),Br=i(),$e=s("p"),Kr=o(`The class is designed to play well with the native argparse. In particular, you can add more (non-dataclass backed)
arguments to the parser after initialization and you\u2019ll get the output back after parsing as an additional
namespace. Optional: To create sub argument groups use the `),Rt=s("code"),Yr=o("_argument_group_name"),Wr=o(" attribute in the dataclass."),Jr=i(),T=s("div"),b(ye.$$.fragment),Qr=i(),Ft=s("p"),Xr=o("Parse command-line args into instances of the specified dataclass types."),Zr=i(),Ee=s("p"),en=o("This relies on argparse\u2019s "),qt=s("code"),tn=o("ArgumentParser.parse_known_args"),an=o(`. See the doc at:
docs.python.org/3.7/library/argparse.html#argparse.ArgumentParser.parse_args`),sn=i(),te=s("div"),b(De.$$.fragment),rn=i(),je=s("p"),nn=o("Alternative helper method that does not use "),Bt=s("code"),on=o("argparse"),ln=o(` at all, instead uses a dict and populating the dataclass
types.`),cn=i(),ae=s("div"),b(Pe.$$.fragment),pn=i(),ke=s("p"),hn=o("Alternative helper method that does not use "),Kt=s("code"),dn=o("argparse"),un=o(` at all, instead loading a json file and populating the
dataclass types.`),Va=i(),R=s("h2"),se=s("a"),Yt=s("span"),b(Te.$$.fragment),fn=i(),Wt=s("span"),mn=o("Debug Utilities"),Ma=i(),p=s("div"),b(xe.$$.fragment),gn=i(),F=s("p"),bn=o(`This debug class helps detect and understand where the model starts getting very large or very small, and more
importantly `),Jt=s("code"),vn=o("nan"),_n=o(" or "),Qt=s("code"),wn=o("inf"),$n=o(" weight and activation elements."),yn=i(),Xt=s("p"),En=o("There are 2 working modes:"),Dn=i(),Oe=s("ol"),Zt=s("li"),jn=o("Underflow/overflow detection (default)"),Pn=i(),ea=s("li"),kn=o("Specific batch absolute min/max tracing without detection"),Tn=i(),ta=s("p"),xn=o("Mode 1: Underflow/overflow detection"),On=i(),aa=s("p"),An=o("To activate the underflow/overflow detection, initialize the object with the model :"),Cn=i(),b(Ae.$$.fragment),Ln=i(),k=s("p"),Un=o("then run the training as normal and if "),sa=s("code"),In=o("nan"),zn=o(" or "),ra=s("code"),Sn=o("inf"),Nn=o(` gets detected in at least one of the weight, input or output
elements this module will throw an exception and will print `),na=s("code"),Hn=o("max_frames_to_save"),Gn=o(` frames that lead to this event,
each frame reporting`),Vn=i(),Ce=s("ol"),Le=s("li"),Mn=o("the fully qualified module name plus the class name whose "),oa=s("code"),Rn=o("forward"),Fn=o(" was run"),qn=i(),la=s("li"),Bn=o("the absolute min and max value of all elements for each module weights, and the inputs and output"),Kn=i(),Ue=s("p"),Yn=o("For example, here is the header and the last few frames in detection report for "),ia=s("code"),Wn=o("google/mt5-small"),Jn=o(` run in fp16
mixed precision :`),Qn=i(),b(Ie.$$.fragment),Xn=i(),q=s("p"),Zn=o("You can see here, that "),ca=s("code"),eo=o("T5DenseGatedGeluDense.forward"),to=o(` resulted in output activations, whose absolute max value was
around 62.7K, which is very close to fp16\u2019s top limit of 64K. In the next frame we have `),pa=s("code"),ao=o("Dropout"),so=o(` which
renormalizes the weights, after it zeroed some of the elements, which pushes the absolute max value to more than
64K, and we get an overlow.`),ro=i(),ha=s("p"),no=o(`As you can see it\u2019s the previous frames that we need to look into when the numbers start going into very large for
fp16 numbers.`),oo=i(),ze=s("p"),lo=o("The tracking is done in a forward hook, which gets invoked immediately after "),da=s("code"),io=o("forward"),co=o(" has completed."),po=i(),ua=s("p"),ho=o("By default the last 21 frames are printed. You can change the default to adjust for your needs. For example :"),uo=i(),b(Se.$$.fragment),fo=i(),fa=s("p"),mo=o(`To validate that you have set up this debugging feature correctly, and you intend to use it in a training that
may take hours to complete, first run it with normal tracing enabled for one of a few batches as explained in
the next section.`),go=i(),ma=s("p"),bo=o("Mode 2. Specific batch absolute min/max tracing without detection"),vo=i(),ga=s("p"),_o=o("The second work mode is per-batch tracing with the underflow/overflow detection feature turned off."),wo=i(),Ne=s("p"),$o=o("Let\u2019s say you want to watch the absolute min and max values for all the ingredients of each "),ba=s("code"),yo=o("forward"),Eo=o(` call of a
given batch, and only do that for batches 1 and 3. Then you instantiate this class as :`),Do=i(),b(He.$$.fragment),jo=i(),va=s("p"),Po=o("And now full batches 1 and 3 will be traced using the same format as explained above. Batches are 0-indexed."),ko=i(),_a=s("p"),To=o(`This is helpful if you know that the program starts misbehaving after a certain batch number, so you can
fast-forward right to that area.`),xo=i(),wa=s("p"),Oo=o("Early stopping:"),Ao=i(),$a=s("p"),Co=o("You can also specify the batch number after which to stop the training, with :"),Lo=i(),b(Ge.$$.fragment),Uo=i(),ya=s("p"),Io=o("This feature is mainly useful in the tracing mode, but you can use it for any mode."),zo=i(),We=s("p"),Ea=s("strong"),So=o("Performance"),No=o(":"),Ho=i(),B=s("p"),Go=o("As this module measures absolute "),Da=s("code"),Vo=o("min"),Mo=o("/`"),ja=s("code"),Ro=o("max"),Fo=o(` of each weight of the model on every forward it\u2019ll slow the training
down. Therefore remember to turn it off once the debugging needs have been met.`),this.h()},l(a){const f=Li('[data-svelte="svelte-1phssyn"]',document.head);O=r(f,"META",{name:!0,content:!0}),f.forEach(t),ka=c(a),A=r(a,"H1",{class:!0});var Fa=n(A);K=r(Fa,"A",{id:!0,class:!0,href:!0});var Zo=n(K);st=r(Zo,"SPAN",{});var el=n(st);v(ne.$$.fragment,el),el.forEach(t),Zo.forEach(t),vs=c(Fa),rt=r(Fa,"SPAN",{});var tl=n(rt);_s=l(tl,"Utilities for Trainer"),tl.forEach(t),Fa.forEach(t),Ta=c(a),Y=r(a,"P",{});var qa=n(Y);ws=l(qa,"This page lists all the utility functions used by "),Ve=r(qa,"A",{href:!0});var al=n(Ve);$s=l(al,"Trainer"),al.forEach(t),ys=l(qa,"."),qa.forEach(t),xa=c(a),Me=r(a,"P",{});var sl=n(Me);Es=l(sl,"Most of those are only useful if you are studying the code of the Trainer in the library."),sl.forEach(t),Oa=c(a),C=r(a,"H2",{class:!0});var Ba=n(C);W=r(Ba,"A",{id:!0,class:!0,href:!0});var rl=n(W);nt=r(rl,"SPAN",{});var nl=n(nt);v(oe.$$.fragment,nl),nl.forEach(t),rl.forEach(t),Ds=c(Ba),ot=r(Ba,"SPAN",{});var ol=n(ot);js=l(ol,"Utilities"),ol.forEach(t),Ba.forEach(t),Aa=c(a),L=r(a,"DIV",{class:!0});var Ka=n(L);v(le.$$.fragment,Ka),Ps=c(Ka),lt=r(Ka,"P",{});var ll=n(lt);ks=l(ll,"Evaluation output (always contains labels), to be used to compute metrics."),ll.forEach(t),Ka.forEach(t),Ca=c(a),U=r(a,"DIV",{class:!0});var Ya=n(U);v(ie.$$.fragment,Ya),Ts=c(Ya),it=r(Ya,"P",{});var il=n(it);xs=l(il,"An enumeration."),il.forEach(t),Ya.forEach(t),La=c(a),I=r(a,"DIV",{class:!0});var Wa=n(I);v(ce.$$.fragment,Wa),Os=c(Wa),D=r(Wa,"P",{});var x=n(D);As=l(x,"Helper function for reproducible behavior to set the seed in "),ct=r(x,"CODE",{});var cl=n(ct);Cs=l(cl,"random"),cl.forEach(t),Ls=l(x,", "),pt=r(x,"CODE",{});var pl=n(pt);Us=l(pl,"numpy"),pl.forEach(t),Is=l(x,", "),ht=r(x,"CODE",{});var hl=n(ht);zs=l(hl,"torch"),hl.forEach(t),Ss=l(x," and/or "),dt=r(x,"CODE",{});var dl=n(dt);Ns=l(dl,"tf"),dl.forEach(t),Hs=l(x," (if installed)."),x.forEach(t),Wa.forEach(t),Ua=c(a),z=r(a,"DIV",{class:!0});var Ja=n(z);v(pe.$$.fragment,Ja),Gs=c(Ja),ut=r(Ja,"P",{});var ul=n(ut);Vs=l(ul,"Decorator to make all processes in distributed training wait for each local_master to do something."),ul.forEach(t),Ja.forEach(t),Ia=c(a),S=r(a,"H2",{class:!0});var Qa=n(S);J=r(Qa,"A",{id:!0,class:!0,href:!0});var fl=n(J);ft=r(fl,"SPAN",{});var ml=n(ft);v(he.$$.fragment,ml),ml.forEach(t),fl.forEach(t),Ms=c(Qa),mt=r(Qa,"SPAN",{});var gl=n(mt);Rs=l(gl,"Callbacks internals"),gl.forEach(t),Qa.forEach(t),za=c(a),N=r(a,"DIV",{class:!0});var Xa=n(N);v(de.$$.fragment,Xa),Fs=c(Xa),gt=r(Xa,"P",{});var bl=n(gt);qs=l(bl,"Internal class that just calls the list of callbacks in order."),bl.forEach(t),Xa.forEach(t),Sa=c(a),H=r(a,"H2",{class:!0});var Za=n(H);Q=r(Za,"A",{id:!0,class:!0,href:!0});var vl=n(Q);bt=r(vl,"SPAN",{});var _l=n(bt);v(ue.$$.fragment,_l),_l.forEach(t),vl.forEach(t),Bs=c(Za),vt=r(Za,"SPAN",{});var wl=n(vt);Ks=l(wl,"Distributed Evaluation"),wl.forEach(t),Za.forEach(t),Na=c(a),u=r(a,"DIV",{class:!0});var g=n(u);v(fe.$$.fragment,g),Ys=c(g),_t=r(g,"P",{});var $l=n(_t);Ws=l($l,"A class responsible for properly gathering tensors (or nested list/tuple of tensors) on the CPU by chunks."),$l.forEach(t),Js=c(g),wt=r(g,"P",{});var yl=n(wt);Qs=l(yl,`If our dataset has 16 samples with a batch size of 2 on 3 processes and we gather then transfer on CPU at every
step, our sampler will generate the following indices:`),yl.forEach(t),Xs=c(g),$t=r(g,"P",{});var El=n($t);yt=r(El,"CODE",{});var Dl=n(yt);Zs=l(Dl,"[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 0, 1]"),Dl.forEach(t),El.forEach(t),er=c(g),Et=r(g,"P",{});var jl=n(Et);tr=l(jl,`to get something of size a multiple of 3 (so that each process gets the same dataset length). Then process 0, 1 and
2 will be responsible of making predictions for the following samples:`),jl.forEach(t),ar=c(g),G=r(g,"UL",{});var Je=n(G);Re=r(Je,"LI",{});var qo=n(Re);sr=l(qo,"P0: "),Dt=r(qo,"CODE",{});var Pl=n(Dt);rr=l(Pl,"[0, 1, 2, 3, 4, 5]"),Pl.forEach(t),qo.forEach(t),nr=c(Je),Fe=r(Je,"LI",{});var Bo=n(Fe);or=l(Bo,"P1: "),jt=r(Bo,"CODE",{});var kl=n(jt);lr=l(kl,"[6, 7, 8, 9, 10, 11]"),kl.forEach(t),Bo.forEach(t),ir=c(Je),qe=r(Je,"LI",{});var Ko=n(qe);cr=l(Ko,"P2: "),Pt=r(Ko,"CODE",{});var Tl=n(Pt);pr=l(Tl,"[12, 13, 14, 15, 0, 1]"),Tl.forEach(t),Ko.forEach(t),Je.forEach(t),hr=c(g),kt=r(g,"P",{});var xl=n(kt);dr=l(xl,"The first batch treated on each process will be"),xl.forEach(t),ur=c(g),V=r(g,"UL",{});var Qe=n(V);Be=r(Qe,"LI",{});var Yo=n(Be);fr=l(Yo,"P0: "),Tt=r(Yo,"CODE",{});var Ol=n(Tt);mr=l(Ol,"[0, 1]"),Ol.forEach(t),Yo.forEach(t),gr=c(Qe),Ke=r(Qe,"LI",{});var Wo=n(Ke);br=l(Wo,"P1: "),xt=r(Wo,"CODE",{});var Al=n(xt);vr=l(Al,"[6, 7]"),Al.forEach(t),Wo.forEach(t),_r=c(Qe),Ye=r(Qe,"LI",{});var Jo=n(Ye);wr=l(Jo,"P2: "),Ot=r(Jo,"CODE",{});var Cl=n(Ot);$r=l(Cl,"[12, 13]"),Cl.forEach(t),Jo.forEach(t),Qe.forEach(t),yr=c(g),At=r(g,"P",{});var Ll=n(At);Er=l(Ll,`So if we gather at the end of the first batch, we will get a tensor (nested list/tuple of tensor) corresponding to
the following indices:`),Ll.forEach(t),Dr=c(g),Ct=r(g,"P",{});var Ul=n(Ct);Lt=r(Ul,"CODE",{});var Il=n(Lt);jr=l(Il,"[0, 1, 6, 7, 12, 13]"),Il.forEach(t),Ul.forEach(t),Pr=c(g),Ut=r(g,"P",{});var zl=n(Ut);kr=l(zl,`If we directly concatenate our results without taking any precautions, the user will then get the predictions for
the indices in this order at the end of the prediction loop:`),zl.forEach(t),Tr=c(g),It=r(g,"P",{});var Sl=n(It);zt=r(Sl,"CODE",{});var Nl=n(zt);xr=l(Nl,"[0, 1, 6, 7, 12, 13, 2, 3, 8, 9, 14, 15, 4, 5, 10, 11, 0, 1]"),Nl.forEach(t),Sl.forEach(t),Or=c(g),St=r(g,"P",{});var Hl=n(St);Ar=l(Hl,"For some reason, that\u2019s not going to roll their boat. This class is there to solve that problem."),Hl.forEach(t),Cr=c(g),X=r(g,"DIV",{class:!0});var es=n(X);v(me.$$.fragment,es),Lr=c(es),ge=r(es,"P",{});var ts=n(ge);Ur=l(ts,"Add "),Nt=r(ts,"CODE",{});var Gl=n(Nt);Ir=l(Gl,"arrays"),Gl.forEach(t),zr=l(ts,` to the internal storage, Will initialize the storage to the full size at the first arrays passed
so that if we\u2019re bound to get an OOM, it happens at the beginning.`),ts.forEach(t),es.forEach(t),Sr=c(g),Z=r(g,"DIV",{class:!0});var as=n(Z);v(be.$$.fragment,as),Nr=c(as),Ht=r(as,"P",{});var Vl=n(Ht);Hr=l(Vl,`Return the properly gathered arrays and truncate to the number of samples (since the sampler added some extras
to get each process a dataset of the same length).`),Vl.forEach(t),as.forEach(t),g.forEach(t),Ha=c(a),M=r(a,"H2",{class:!0});var ss=n(M);ee=r(ss,"A",{id:!0,class:!0,href:!0});var Ml=n(ee);Gt=r(Ml,"SPAN",{});var Rl=n(Gt);v(ve.$$.fragment,Rl),Rl.forEach(t),Ml.forEach(t),Gr=c(ss),Vt=r(ss,"SPAN",{});var Fl=n(Vt);Vr=l(Fl,"Distributed Evaluation"),Fl.forEach(t),ss.forEach(t),Ga=c(a),E=r(a,"DIV",{class:!0});var P=n(E);v(_e.$$.fragment,P),Mr=c(P),we=r(P,"P",{});var rs=n(we);Rr=l(rs,"This subclass of "),Mt=r(rs,"CODE",{});var ql=n(Mt);Fr=l(ql,"argparse.ArgumentParser"),ql.forEach(t),qr=l(rs," uses type hints on dataclasses to generate arguments."),rs.forEach(t),Br=c(P),$e=r(P,"P",{});var ns=n($e);Kr=l(ns,`The class is designed to play well with the native argparse. In particular, you can add more (non-dataclass backed)
arguments to the parser after initialization and you\u2019ll get the output back after parsing as an additional
namespace. Optional: To create sub argument groups use the `),Rt=r(ns,"CODE",{});var Bl=n(Rt);Yr=l(Bl,"_argument_group_name"),Bl.forEach(t),Wr=l(ns," attribute in the dataclass."),ns.forEach(t),Jr=c(P),T=r(P,"DIV",{class:!0});var Xe=n(T);v(ye.$$.fragment,Xe),Qr=c(Xe),Ft=r(Xe,"P",{});var Kl=n(Ft);Xr=l(Kl,"Parse command-line args into instances of the specified dataclass types."),Kl.forEach(t),Zr=c(Xe),Ee=r(Xe,"P",{});var os=n(Ee);en=l(os,"This relies on argparse\u2019s "),qt=r(os,"CODE",{});var Yl=n(qt);tn=l(Yl,"ArgumentParser.parse_known_args"),Yl.forEach(t),an=l(os,`. See the doc at:
docs.python.org/3.7/library/argparse.html#argparse.ArgumentParser.parse_args`),os.forEach(t),Xe.forEach(t),sn=c(P),te=r(P,"DIV",{class:!0});var ls=n(te);v(De.$$.fragment,ls),rn=c(ls),je=r(ls,"P",{});var is=n(je);nn=l(is,"Alternative helper method that does not use "),Bt=r(is,"CODE",{});var Wl=n(Bt);on=l(Wl,"argparse"),Wl.forEach(t),ln=l(is,` at all, instead uses a dict and populating the dataclass
types.`),is.forEach(t),ls.forEach(t),cn=c(P),ae=r(P,"DIV",{class:!0});var cs=n(ae);v(Pe.$$.fragment,cs),pn=c(cs),ke=r(cs,"P",{});var ps=n(ke);hn=l(ps,"Alternative helper method that does not use "),Kt=r(ps,"CODE",{});var Jl=n(Kt);dn=l(Jl,"argparse"),Jl.forEach(t),un=l(ps,` at all, instead loading a json file and populating the
dataclass types.`),ps.forEach(t),cs.forEach(t),P.forEach(t),Va=c(a),R=r(a,"H2",{class:!0});var hs=n(R);se=r(hs,"A",{id:!0,class:!0,href:!0});var Ql=n(se);Yt=r(Ql,"SPAN",{});var Xl=n(Yt);v(Te.$$.fragment,Xl),Xl.forEach(t),Ql.forEach(t),fn=c(hs),Wt=r(hs,"SPAN",{});var Zl=n(Wt);mn=l(Zl,"Debug Utilities"),Zl.forEach(t),hs.forEach(t),Ma=c(a),p=r(a,"DIV",{class:!0});var h=n(p);v(xe.$$.fragment,h),gn=c(h),F=r(h,"P",{});var Ze=n(F);bn=l(Ze,`This debug class helps detect and understand where the model starts getting very large or very small, and more
importantly `),Jt=r(Ze,"CODE",{});var ei=n(Jt);vn=l(ei,"nan"),ei.forEach(t),_n=l(Ze," or "),Qt=r(Ze,"CODE",{});var ti=n(Qt);wn=l(ti,"inf"),ti.forEach(t),$n=l(Ze," weight and activation elements."),Ze.forEach(t),yn=c(h),Xt=r(h,"P",{});var ai=n(Xt);En=l(ai,"There are 2 working modes:"),ai.forEach(t),Dn=c(h),Oe=r(h,"OL",{});var ds=n(Oe);Zt=r(ds,"LI",{});var si=n(Zt);jn=l(si,"Underflow/overflow detection (default)"),si.forEach(t),Pn=c(ds),ea=r(ds,"LI",{});var ri=n(ea);kn=l(ri,"Specific batch absolute min/max tracing without detection"),ri.forEach(t),ds.forEach(t),Tn=c(h),ta=r(h,"P",{});var ni=n(ta);xn=l(ni,"Mode 1: Underflow/overflow detection"),ni.forEach(t),On=c(h),aa=r(h,"P",{});var oi=n(aa);An=l(oi,"To activate the underflow/overflow detection, initialize the object with the model :"),oi.forEach(t),Cn=c(h),v(Ae.$$.fragment,h),Ln=c(h),k=r(h,"P",{});var re=n(k);Un=l(re,"then run the training as normal and if "),sa=r(re,"CODE",{});var li=n(sa);In=l(li,"nan"),li.forEach(t),zn=l(re," or "),ra=r(re,"CODE",{});var ii=n(ra);Sn=l(ii,"inf"),ii.forEach(t),Nn=l(re,` gets detected in at least one of the weight, input or output
elements this module will throw an exception and will print `),na=r(re,"CODE",{});var ci=n(na);Hn=l(ci,"max_frames_to_save"),ci.forEach(t),Gn=l(re,` frames that lead to this event,
each frame reporting`),re.forEach(t),Vn=c(h),Ce=r(h,"OL",{});var us=n(Ce);Le=r(us,"LI",{});var fs=n(Le);Mn=l(fs,"the fully qualified module name plus the class name whose "),oa=r(fs,"CODE",{});var pi=n(oa);Rn=l(pi,"forward"),pi.forEach(t),Fn=l(fs," was run"),fs.forEach(t),qn=c(us),la=r(us,"LI",{});var hi=n(la);Bn=l(hi,"the absolute min and max value of all elements for each module weights, and the inputs and output"),hi.forEach(t),us.forEach(t),Kn=c(h),Ue=r(h,"P",{});var ms=n(Ue);Yn=l(ms,"For example, here is the header and the last few frames in detection report for "),ia=r(ms,"CODE",{});var di=n(ia);Wn=l(di,"google/mt5-small"),di.forEach(t),Jn=l(ms,` run in fp16
mixed precision :`),ms.forEach(t),Qn=c(h),v(Ie.$$.fragment,h),Xn=c(h),q=r(h,"P",{});var et=n(q);Zn=l(et,"You can see here, that "),ca=r(et,"CODE",{});var ui=n(ca);eo=l(ui,"T5DenseGatedGeluDense.forward"),ui.forEach(t),to=l(et,` resulted in output activations, whose absolute max value was
around 62.7K, which is very close to fp16\u2019s top limit of 64K. In the next frame we have `),pa=r(et,"CODE",{});var fi=n(pa);ao=l(fi,"Dropout"),fi.forEach(t),so=l(et,` which
renormalizes the weights, after it zeroed some of the elements, which pushes the absolute max value to more than
64K, and we get an overlow.`),et.forEach(t),ro=c(h),ha=r(h,"P",{});var mi=n(ha);no=l(mi,`As you can see it\u2019s the previous frames that we need to look into when the numbers start going into very large for
fp16 numbers.`),mi.forEach(t),oo=c(h),ze=r(h,"P",{});var gs=n(ze);lo=l(gs,"The tracking is done in a forward hook, which gets invoked immediately after "),da=r(gs,"CODE",{});var gi=n(da);io=l(gi,"forward"),gi.forEach(t),co=l(gs," has completed."),gs.forEach(t),po=c(h),ua=r(h,"P",{});var bi=n(ua);ho=l(bi,"By default the last 21 frames are printed. You can change the default to adjust for your needs. For example :"),bi.forEach(t),uo=c(h),v(Se.$$.fragment,h),fo=c(h),fa=r(h,"P",{});var vi=n(fa);mo=l(vi,`To validate that you have set up this debugging feature correctly, and you intend to use it in a training that
may take hours to complete, first run it with normal tracing enabled for one of a few batches as explained in
the next section.`),vi.forEach(t),go=c(h),ma=r(h,"P",{});var _i=n(ma);bo=l(_i,"Mode 2. Specific batch absolute min/max tracing without detection"),_i.forEach(t),vo=c(h),ga=r(h,"P",{});var wi=n(ga);_o=l(wi,"The second work mode is per-batch tracing with the underflow/overflow detection feature turned off."),wi.forEach(t),wo=c(h),Ne=r(h,"P",{});var bs=n(Ne);$o=l(bs,"Let\u2019s say you want to watch the absolute min and max values for all the ingredients of each "),ba=r(bs,"CODE",{});var $i=n(ba);yo=l($i,"forward"),$i.forEach(t),Eo=l(bs,` call of a
given batch, and only do that for batches 1 and 3. Then you instantiate this class as :`),bs.forEach(t),Do=c(h),v(He.$$.fragment,h),jo=c(h),va=r(h,"P",{});var yi=n(va);Po=l(yi,"And now full batches 1 and 3 will be traced using the same format as explained above. Batches are 0-indexed."),yi.forEach(t),ko=c(h),_a=r(h,"P",{});var Ei=n(_a);To=l(Ei,`This is helpful if you know that the program starts misbehaving after a certain batch number, so you can
fast-forward right to that area.`),Ei.forEach(t),xo=c(h),wa=r(h,"P",{});var Di=n(wa);Oo=l(Di,"Early stopping:"),Di.forEach(t),Ao=c(h),$a=r(h,"P",{});var ji=n($a);Co=l(ji,"You can also specify the batch number after which to stop the training, with :"),ji.forEach(t),Lo=c(h),v(Ge.$$.fragment,h),Uo=c(h),ya=r(h,"P",{});var Pi=n(ya);Io=l(Pi,"This feature is mainly useful in the tracing mode, but you can use it for any mode."),Pi.forEach(t),zo=c(h),We=r(h,"P",{});var Qo=n(We);Ea=r(Qo,"STRONG",{});var ki=n(Ea);So=l(ki,"Performance"),ki.forEach(t),No=l(Qo,":"),Qo.forEach(t),Ho=c(h),B=r(h,"P",{});var tt=n(B);Go=l(tt,"As this module measures absolute "),Da=r(tt,"CODE",{});var Ti=n(Da);Vo=l(Ti,"min"),Ti.forEach(t),Mo=l(tt,"/`"),ja=r(tt,"CODE",{});var xi=n(ja);Ro=l(xi,"max"),xi.forEach(t),Fo=l(tt,` of each weight of the model on every forward it\u2019ll slow the training
down. Therefore remember to turn it off once the debugging needs have been met.`),tt.forEach(t),h.forEach(t),this.h()},h(){d(O,"name","hf:doc:metadata"),d(O,"content",JSON.stringify(Si)),d(K,"id","utilities-for-trainer"),d(K,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(K,"href","#utilities-for-trainer"),d(A,"class","relative group"),d(Ve,"href","/docs/transformers/main/en/main_classes/trainer#transformers.Trainer"),d(W,"id","transformers.EvalPrediction"),d(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(W,"href","#transformers.EvalPrediction"),d(C,"class","relative group"),d(L,"class","docstring"),d(U,"class","docstring"),d(I,"class","docstring"),d(z,"class","docstring"),d(J,"id","transformers.trainer_callback.CallbackHandler"),d(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(J,"href","#transformers.trainer_callback.CallbackHandler"),d(S,"class","relative group"),d(N,"class","docstring"),d(Q,"id","transformers.trainer_pt_utils.DistributedTensorGatherer"),d(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Q,"href","#transformers.trainer_pt_utils.DistributedTensorGatherer"),d(H,"class","relative group"),d(X,"class","docstring"),d(Z,"class","docstring"),d(u,"class","docstring"),d(ee,"id","transformers.HfArgumentParser"),d(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ee,"href","#transformers.HfArgumentParser"),d(M,"class","relative group"),d(T,"class","docstring"),d(te,"class","docstring"),d(ae,"class","docstring"),d(E,"class","docstring"),d(se,"id","transformers.debug_utils.DebugUnderflowOverflow"),d(se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(se,"href","#transformers.debug_utils.DebugUnderflowOverflow"),d(R,"class","relative group"),d(p,"class","docstring")},m(a,f){e(document.head,O),m(a,ka,f),m(a,A,f),e(A,K),e(K,st),_(ne,st,null),e(A,vs),e(A,rt),e(rt,_s),m(a,Ta,f),m(a,Y,f),e(Y,ws),e(Y,Ve),e(Ve,$s),e(Y,ys),m(a,xa,f),m(a,Me,f),e(Me,Es),m(a,Oa,f),m(a,C,f),e(C,W),e(W,nt),_(oe,nt,null),e(C,Ds),e(C,ot),e(ot,js),m(a,Aa,f),m(a,L,f),_(le,L,null),e(L,Ps),e(L,lt),e(lt,ks),m(a,Ca,f),m(a,U,f),_(ie,U,null),e(U,Ts),e(U,it),e(it,xs),m(a,La,f),m(a,I,f),_(ce,I,null),e(I,Os),e(I,D),e(D,As),e(D,ct),e(ct,Cs),e(D,Ls),e(D,pt),e(pt,Us),e(D,Is),e(D,ht),e(ht,zs),e(D,Ss),e(D,dt),e(dt,Ns),e(D,Hs),m(a,Ua,f),m(a,z,f),_(pe,z,null),e(z,Gs),e(z,ut),e(ut,Vs),m(a,Ia,f),m(a,S,f),e(S,J),e(J,ft),_(he,ft,null),e(S,Ms),e(S,mt),e(mt,Rs),m(a,za,f),m(a,N,f),_(de,N,null),e(N,Fs),e(N,gt),e(gt,qs),m(a,Sa,f),m(a,H,f),e(H,Q),e(Q,bt),_(ue,bt,null),e(H,Bs),e(H,vt),e(vt,Ks),m(a,Na,f),m(a,u,f),_(fe,u,null),e(u,Ys),e(u,_t),e(_t,Ws),e(u,Js),e(u,wt),e(wt,Qs),e(u,Xs),e(u,$t),e($t,yt),e(yt,Zs),e(u,er),e(u,Et),e(Et,tr),e(u,ar),e(u,G),e(G,Re),e(Re,sr),e(Re,Dt),e(Dt,rr),e(G,nr),e(G,Fe),e(Fe,or),e(Fe,jt),e(jt,lr),e(G,ir),e(G,qe),e(qe,cr),e(qe,Pt),e(Pt,pr),e(u,hr),e(u,kt),e(kt,dr),e(u,ur),e(u,V),e(V,Be),e(Be,fr),e(Be,Tt),e(Tt,mr),e(V,gr),e(V,Ke),e(Ke,br),e(Ke,xt),e(xt,vr),e(V,_r),e(V,Ye),e(Ye,wr),e(Ye,Ot),e(Ot,$r),e(u,yr),e(u,At),e(At,Er),e(u,Dr),e(u,Ct),e(Ct,Lt),e(Lt,jr),e(u,Pr),e(u,Ut),e(Ut,kr),e(u,Tr),e(u,It),e(It,zt),e(zt,xr),e(u,Or),e(u,St),e(St,Ar),e(u,Cr),e(u,X),_(me,X,null),e(X,Lr),e(X,ge),e(ge,Ur),e(ge,Nt),e(Nt,Ir),e(ge,zr),e(u,Sr),e(u,Z),_(be,Z,null),e(Z,Nr),e(Z,Ht),e(Ht,Hr),m(a,Ha,f),m(a,M,f),e(M,ee),e(ee,Gt),_(ve,Gt,null),e(M,Gr),e(M,Vt),e(Vt,Vr),m(a,Ga,f),m(a,E,f),_(_e,E,null),e(E,Mr),e(E,we),e(we,Rr),e(we,Mt),e(Mt,Fr),e(we,qr),e(E,Br),e(E,$e),e($e,Kr),e($e,Rt),e(Rt,Yr),e($e,Wr),e(E,Jr),e(E,T),_(ye,T,null),e(T,Qr),e(T,Ft),e(Ft,Xr),e(T,Zr),e(T,Ee),e(Ee,en),e(Ee,qt),e(qt,tn),e(Ee,an),e(E,sn),e(E,te),_(De,te,null),e(te,rn),e(te,je),e(je,nn),e(je,Bt),e(Bt,on),e(je,ln),e(E,cn),e(E,ae),_(Pe,ae,null),e(ae,pn),e(ae,ke),e(ke,hn),e(ke,Kt),e(Kt,dn),e(ke,un),m(a,Va,f),m(a,R,f),e(R,se),e(se,Yt),_(Te,Yt,null),e(R,fn),e(R,Wt),e(Wt,mn),m(a,Ma,f),m(a,p,f),_(xe,p,null),e(p,gn),e(p,F),e(F,bn),e(F,Jt),e(Jt,vn),e(F,_n),e(F,Qt),e(Qt,wn),e(F,$n),e(p,yn),e(p,Xt),e(Xt,En),e(p,Dn),e(p,Oe),e(Oe,Zt),e(Zt,jn),e(Oe,Pn),e(Oe,ea),e(ea,kn),e(p,Tn),e(p,ta),e(ta,xn),e(p,On),e(p,aa),e(aa,An),e(p,Cn),_(Ae,p,null),e(p,Ln),e(p,k),e(k,Un),e(k,sa),e(sa,In),e(k,zn),e(k,ra),e(ra,Sn),e(k,Nn),e(k,na),e(na,Hn),e(k,Gn),e(p,Vn),e(p,Ce),e(Ce,Le),e(Le,Mn),e(Le,oa),e(oa,Rn),e(Le,Fn),e(Ce,qn),e(Ce,la),e(la,Bn),e(p,Kn),e(p,Ue),e(Ue,Yn),e(Ue,ia),e(ia,Wn),e(Ue,Jn),e(p,Qn),_(Ie,p,null),e(p,Xn),e(p,q),e(q,Zn),e(q,ca),e(ca,eo),e(q,to),e(q,pa),e(pa,ao),e(q,so),e(p,ro),e(p,ha),e(ha,no),e(p,oo),e(p,ze),e(ze,lo),e(ze,da),e(da,io),e(ze,co),e(p,po),e(p,ua),e(ua,ho),e(p,uo),_(Se,p,null),e(p,fo),e(p,fa),e(fa,mo),e(p,go),e(p,ma),e(ma,bo),e(p,vo),e(p,ga),e(ga,_o),e(p,wo),e(p,Ne),e(Ne,$o),e(Ne,ba),e(ba,yo),e(Ne,Eo),e(p,Do),_(He,p,null),e(p,jo),e(p,va),e(va,Po),e(p,ko),e(p,_a),e(_a,To),e(p,xo),e(p,wa),e(wa,Oo),e(p,Ao),e(p,$a),e($a,Co),e(p,Lo),_(Ge,p,null),e(p,Uo),e(p,ya),e(ya,Io),e(p,zo),e(p,We),e(We,Ea),e(Ea,So),e(We,No),e(p,Ho),e(p,B),e(B,Go),e(B,Da),e(Da,Vo),e(B,Mo),e(B,ja),e(ja,Ro),e(B,Fo),Ra=!0},p:Ui,i(a){Ra||(w(ne.$$.fragment,a),w(oe.$$.fragment,a),w(le.$$.fragment,a),w(ie.$$.fragment,a),w(ce.$$.fragment,a),w(pe.$$.fragment,a),w(he.$$.fragment,a),w(de.$$.fragment,a),w(ue.$$.fragment,a),w(fe.$$.fragment,a),w(me.$$.fragment,a),w(be.$$.fragment,a),w(ve.$$.fragment,a),w(_e.$$.fragment,a),w(ye.$$.fragment,a),w(De.$$.fragment,a),w(Pe.$$.fragment,a),w(Te.$$.fragment,a),w(xe.$$.fragment,a),w(Ae.$$.fragment,a),w(Ie.$$.fragment,a),w(Se.$$.fragment,a),w(He.$$.fragment,a),w(Ge.$$.fragment,a),Ra=!0)},o(a){$(ne.$$.fragment,a),$(oe.$$.fragment,a),$(le.$$.fragment,a),$(ie.$$.fragment,a),$(ce.$$.fragment,a),$(pe.$$.fragment,a),$(he.$$.fragment,a),$(de.$$.fragment,a),$(ue.$$.fragment,a),$(fe.$$.fragment,a),$(me.$$.fragment,a),$(be.$$.fragment,a),$(ve.$$.fragment,a),$(_e.$$.fragment,a),$(ye.$$.fragment,a),$(De.$$.fragment,a),$(Pe.$$.fragment,a),$(Te.$$.fragment,a),$(xe.$$.fragment,a),$(Ae.$$.fragment,a),$(Ie.$$.fragment,a),$(Se.$$.fragment,a),$(He.$$.fragment,a),$(Ge.$$.fragment,a),Ra=!1},d(a){t(O),a&&t(ka),a&&t(A),y(ne),a&&t(Ta),a&&t(Y),a&&t(xa),a&&t(Me),a&&t(Oa),a&&t(C),y(oe),a&&t(Aa),a&&t(L),y(le),a&&t(Ca),a&&t(U),y(ie),a&&t(La),a&&t(I),y(ce),a&&t(Ua),a&&t(z),y(pe),a&&t(Ia),a&&t(S),y(he),a&&t(za),a&&t(N),y(de),a&&t(Sa),a&&t(H),y(ue),a&&t(Na),a&&t(u),y(fe),y(me),y(be),a&&t(Ha),a&&t(M),y(ve),a&&t(Ga),a&&t(E),y(_e),y(ye),y(De),y(Pe),a&&t(Va),a&&t(R),y(Te),a&&t(Ma),a&&t(p),y(xe),y(Ae),y(Ie),y(Se),y(He),y(Ge)}}}const Si={local:"utilities-for-trainer",sections:[{local:"transformers.EvalPrediction",title:"Utilities"},{local:"transformers.trainer_callback.CallbackHandler",title:"Callbacks internals"},{local:"transformers.trainer_pt_utils.DistributedTensorGatherer",title:"Distributed Evaluation"},{local:"transformers.HfArgumentParser",title:"Distributed Evaluation"},{local:"transformers.debug_utils.DebugUnderflowOverflow",title:"Debug Utilities"}],title:"Utilities for Trainer"};function Ni(Xo){return Ii(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ri extends Oi{constructor(O){super();Ai(this,O,Ni,zi,Ci,{})}}export{Ri as default,Si as metadata};
