import{S as Ps,i as ws,s as Es,e as t,k as m,w as v,t as n,M as Ts,c as s,d as o,m as c,a,x as y,h as i,b as d,G as e,g as u,y as $,q as I,o as x,B as P,v as ks,L as Is}from"../../chunks/vendor-hf-doc-builder.js";import{T as Ds}from"../../chunks/Tip-hf-doc-builder.js";import{D as T}from"../../chunks/Docstring-hf-doc-builder.js";import{C as xs}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as St}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as $s}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function Ms(J){let g,E,_,f,k;return f=new xs({props:{code:`# We can't instantiate directly the base class *ImageProcessingMixin* so let's show the examples on a
# derived class: *CLIPImageProcessor*
image_processor = CLIPImageProcessor.from_pretrained(
    "openai/clip-vit-base-patch32"
)  # Download image_processing_config from huggingface.co and cache.
image_processor = CLIPImageProcessor.from_pretrained(
    "./test/saved_model/"
)  # E.g. image processor (or model) was saved using *save_pretrained('./test/saved_model/')*
image_processor = CLIPImageProcessor.from_pretrained("./test/saved_model/preprocessor_config.json")
image_processor = CLIPImageProcessor.from_pretrained(
    "openai/clip-vit-base-patch32", do_normalize=False, foo=False
)
assert image_processor.do_normalize is False
image_processor, unused_kwargs = CLIPImageProcessor.from_pretrained(
    "openai/clip-vit-base-patch32", do_normalize=False, foo=False, return_unused_kwargs=True
)
assert image_processor.do_normalize is False
assert unused_kwargs == {"foo": False}`,highlighted:`<span class="hljs-comment"># We can&#x27;t instantiate directly the base class *ImageProcessingMixin* so let&#x27;s show the examples on a</span>
<span class="hljs-comment"># derived class: *CLIPImageProcessor*</span>
image_processor = CLIPImageProcessor.from_pretrained(
    <span class="hljs-string">&quot;openai/clip-vit-base-patch32&quot;</span>
)  <span class="hljs-comment"># Download image_processing_config from huggingface.co and cache.</span>
image_processor = CLIPImageProcessor.from_pretrained(
    <span class="hljs-string">&quot;./test/saved_model/&quot;</span>
)  <span class="hljs-comment"># E.g. image processor (or model) was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*</span>
image_processor = CLIPImageProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/preprocessor_config.json&quot;</span>)
image_processor = CLIPImageProcessor.from_pretrained(
    <span class="hljs-string">&quot;openai/clip-vit-base-patch32&quot;</span>, do_normalize=<span class="hljs-literal">False</span>, foo=<span class="hljs-literal">False</span>
)
<span class="hljs-keyword">assert</span> image_processor.do_normalize <span class="hljs-keyword">is</span> <span class="hljs-literal">False</span>
image_processor, unused_kwargs = CLIPImageProcessor.from_pretrained(
    <span class="hljs-string">&quot;openai/clip-vit-base-patch32&quot;</span>, do_normalize=<span class="hljs-literal">False</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
)
<span class="hljs-keyword">assert</span> image_processor.do_normalize <span class="hljs-keyword">is</span> <span class="hljs-literal">False</span>
<span class="hljs-keyword">assert</span> unused_kwargs == {<span class="hljs-string">&quot;foo&quot;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=t("p"),E=n("Examples:"),_=m(),v(f.$$.fragment)},l(l){g=s(l,"P",{});var w=a(g);E=i(w,"Examples:"),w.forEach(o),_=c(l),y(f.$$.fragment,l)},m(l,w){u(l,g,w),e(g,E),u(l,_,w),$(f,l,w),k=!0},p:Is,i(l){k||(I(f.$$.fragment,l),k=!0)},o(l){x(f.$$.fragment,l),k=!1},d(l){l&&o(g),l&&o(_),P(f,l)}}}function zs(J){let g,E,_,f,k;return f=new xs({props:{code:`from transformers import AutoImageProcessor

image processor = AutoImageProcessor.from_pretrained("bert-base-cased")

# Push the image processor to your namespace with the name "my-finetuned-bert".
image processor.push_to_hub("my-finetuned-bert")

# Push the image processor to an organization with the name "my-finetuned-bert".
image processor.push_to_hub("huggingface/my-finetuned-bert")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoImageProcessor

image processor = AutoImageProcessor.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-comment"># Push the image processor to your namespace with the name &quot;my-finetuned-bert&quot;.</span>
image processor.push_to_hub(<span class="hljs-string">&quot;my-finetuned-bert&quot;</span>)

<span class="hljs-comment"># Push the image processor to an organization with the name &quot;my-finetuned-bert&quot;.</span>
image processor.push_to_hub(<span class="hljs-string">&quot;huggingface/my-finetuned-bert&quot;</span>)`}}),{c(){g=t("p"),E=n("Examples:"),_=m(),v(f.$$.fragment)},l(l){g=s(l,"P",{});var w=a(g);E=i(w,"Examples:"),w.forEach(o),_=c(l),y(f.$$.fragment,l)},m(l,w){u(l,g,w),e(g,E),u(l,_,w),$(f,l,w),k=!0},p:Is,i(l){k||(I(f.$$.fragment,l),k=!0)},o(l){x(f.$$.fragment,l),k=!1},d(l){l&&o(g),l&&o(_),P(f,l)}}}function js(J){let g,E;return{c(){g=t("p"),E=n("This API is experimental and may have some slight breaking changes in the next releases.")},l(_){g=s(_,"P",{});var f=a(g);E=i(f,"This API is experimental and may have some slight breaking changes in the next releases."),f.forEach(o)},m(_,f){u(_,g,f),e(g,E)},d(_){_&&o(g)}}}function Ls(J){let g,E,_,f,k,l,w,Je,Kr,yr,je,Qr,$r,Le,Xr,Ir,O,H,He,ie,Zr,Be,eo,xr,N,me,ro,D,oo,Ge,to,so,Ye,ao,no,Ke,io,mo,Pr,M,ce,co,z,lo,Qe,po,go,Xe,fo,ho,Ze,uo,_o,bo,er,vo,wr,A,le,yo,S,$o,rr,Io,xo,or,Po,wo,Er,F,de,Eo,U,To,tr,ko,Do,sr,Mo,zo,Tr,V,pe,jo,ge,Lo,ar,Co,qo,kr,R,B,nr,fe,Oo,ir,No,Dr,h,he,Ao,mr,So,Fo,G,ue,Uo,_e,Vo,Ce,Ro,Wo,Jo,Y,be,Ho,ve,Bo,qe,Go,Yo,Ko,L,ye,Qo,$e,Xo,Oe,Zo,et,rt,K,ot,Q,Ie,tt,j,st,cr,at,nt,lr,it,mt,dr,ct,lt,dt,C,xe,pt,Pe,gt,pr,ft,ht,ut,X,_t,q,we,bt,Ee,vt,gr,yt,$t,It,Z,xt,ee,Te,Pt,W,wt,fr,Et,Tt,Ne,kt,Dt,Mt,re,ke,zt,hr,jt,Lt,oe,De,Ct,ur,qt,Ot,te,Me,Nt,_r,At,Mr;return l=new St({}),ie=new St({}),me=new T({props:{name:"transformers.image_transforms.center_crop",anchor:"transformers.image_transforms.center_crop",parameters:[{name:"image",val:": ndarray"},{name:"size",val:": typing.Tuple[int, int]"},{name:"data_format",val:": typing.Union[str, transformers.image_utils.ChannelDimension, NoneType] = None"},{name:"return_numpy",val:": typing.Optional[bool] = None"}],parametersDescription:[{anchor:"transformers.image_transforms.center_crop.image",description:`<strong>image</strong> (<code>np.ndarray</code>) &#x2014;
The image to crop.`,name:"image"},{anchor:"transformers.image_transforms.center_crop.size",description:`<strong>size</strong> (<code>Tuple[int, int]</code>) &#x2014;
The target size for the cropped image.`,name:"size"},{anchor:"transformers.image_transforms.center_crop.data_format",description:`<strong>data_format</strong> (<code>str</code> or <code>ChannelDimension</code>, <em>optional</em>) &#x2014;
The channel dimension format for the output image. Can be one of:<ul>
<li><code>&quot;channels_first&quot;</code> or <code>ChannelDimension.FIRST</code>: image in (num_channels, height, width) format.</li>
<li><code>&quot;channels_last&quot;</code> or <code>ChannelDimension.LAST</code>: image in (height, width, num_channels) format.
If unset, will use the inferred format of the input image.</li>
</ul>`,name:"data_format"},{anchor:"transformers.image_transforms.center_crop.return_numpy",description:`<strong>return_numpy</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the cropped image as a numpy array. Used for backwards compatibility with the
previous ImageFeatureExtractionMixin method.<ul>
<li>Unset: will return the same type as the input image.</li>
<li><code>True</code>: will return a numpy array.</li>
<li><code>False</code>: will return a <code>PIL.Image.Image</code> object.</li>
</ul>`,name:"return_numpy"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/image_transforms.py#L330",returnDescription:`
<p>The cropped image.</p>
`,returnType:`
<p><code>np.ndarray</code></p>
`}}),ce=new T({props:{name:"transformers.image_transforms.normalize",anchor:"transformers.image_transforms.normalize",parameters:[{name:"image",val:": ndarray"},{name:"mean",val:": typing.Union[float, typing.Iterable[float]]"},{name:"std",val:": typing.Union[float, typing.Iterable[float]]"},{name:"data_format",val:": typing.Optional[transformers.image_utils.ChannelDimension] = None"}],parametersDescription:[{anchor:"transformers.image_transforms.normalize.image",description:`<strong>image</strong> (<code>np.ndarray</code>) &#x2014;
The image to normalize.`,name:"image"},{anchor:"transformers.image_transforms.normalize.mean",description:`<strong>mean</strong> (<code>float</code> or <code>Iterable[float]</code>) &#x2014;
The mean to use for normalization.`,name:"mean"},{anchor:"transformers.image_transforms.normalize.std",description:`<strong>std</strong> (<code>float</code> or <code>Iterable[float]</code>) &#x2014;
The standard deviation to use for normalization.`,name:"std"},{anchor:"transformers.image_transforms.normalize.data_format",description:`<strong>data_format</strong> (<code>ChannelDimension</code>, <em>optional</em>) &#x2014;
The channel dimension format of the output image. If <code>None</code>, will use the inferred format from the input.`,name:"data_format"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/image_transforms.py#L272"}}),le=new T({props:{name:"transformers.rescale",anchor:"transformers.rescale",parameters:[{name:"image",val:": ndarray"},{name:"scale",val:": float"},{name:"data_format",val:": typing.Optional[transformers.image_utils.ChannelDimension] = None"},{name:"dtype",val:" = <class 'numpy.float32'>"}],parametersDescription:[{anchor:"transformers.rescale.image",description:`<strong>image</strong> (<code>np.ndarray</code>) &#x2014;
The image to rescale.`,name:"image"},{anchor:"transformers.rescale.scale",description:`<strong>scale</strong> (<code>float</code>) &#x2014;
The scale to use for rescaling the image.`,name:"scale"},{anchor:"transformers.rescale.data_format",description:`<strong>data_format</strong> (<code>ChannelDimension</code>, <em>optional</em>) &#x2014;
The channel dimension format of the image. If not provided, it will be the same as the input image.`,name:"data_format"},{anchor:"transformers.rescale.dtype",description:`<strong>dtype</strong> (<code>np.dtype</code>, <em>optional</em>, defaults to <code>np.float32</code>) &#x2014;
The dtype of the output image. Defaults to <code>np.float32</code>. Used for backwards compatibility with feature
extractors.`,name:"dtype"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/image_transforms.py#L80",returnDescription:`
<p>The rescaled image.</p>
`,returnType:`
<p><code>np.ndarray</code></p>
`}}),de=new T({props:{name:"transformers.resize",anchor:"transformers.resize",parameters:[{name:"image",val:""},{name:"size",val:": typing.Tuple[int, int]"},{name:"resample",val:" = <Resampling.BILINEAR: 2>"},{name:"data_format",val:": typing.Optional[transformers.image_utils.ChannelDimension] = None"},{name:"return_numpy",val:": bool = True"}],parametersDescription:[{anchor:"transformers.resize.image",description:`<strong>image</strong> (<code>PIL.Image.Image</code> or <code>np.ndarray</code> or <code>torch.Tensor</code>) &#x2014;
The image to resize.`,name:"image"},{anchor:"transformers.resize.size",description:`<strong>size</strong> (<code>Tuple[int, int]</code>) &#x2014;
The size to use for resizing the image.`,name:"size"},{anchor:"transformers.resize.resample",description:`<strong>resample</strong> (<code>int</code>, <em>optional</em>, defaults to <code>PILImageResampling.BILINEAR</code>) &#x2014;
The filter to user for resampling.`,name:"resample"},{anchor:"transformers.resize.data_format",description:`<strong>data_format</strong> (<code>ChannelDimension</code>, <em>optional</em>) &#x2014;
The channel dimension format of the output image. If <code>None</code>, will use the inferred format from the input.`,name:"data_format"},{anchor:"transformers.resize.return_numpy",description:`<strong>return_numpy</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to return the resized image as a numpy array. If False a <code>PIL.Image.Image</code> object is
returned.`,name:"return_numpy"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/image_transforms.py#L220",returnDescription:`
<p>The resized image.</p>
`,returnType:`
<p><code>np.ndarray</code></p>
`}}),pe=new T({props:{name:"transformers.to_pil_image",anchor:"transformers.to_pil_image",parameters:[{name:"image",val:": typing.Union[numpy.ndarray, PIL.Image.Image, ForwardRef('torch.Tensor'), ForwardRef('tf.Tensor'), ForwardRef('jnp.Tensor')]"},{name:"do_rescale",val:": typing.Optional[bool] = None"}],parametersDescription:[{anchor:"transformers.to_pil_image.image",description:`<strong>image</strong> (<code>PIL.Image.Image</code> or <code>numpy.ndarray</code> or <code>torch.Tensor</code> or <code>tf.Tensor</code>) &#x2014;
The image to convert to the <code>PIL.Image</code> format.`,name:"image"},{anchor:"transformers.to_pil_image.do_rescale",description:`<strong>do_rescale</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to apply the scaling factor (to make pixel values integers between 0 and 255). Will default
to <code>True</code> if the image type is a floating type, <code>False</code> otherwise.`,name:"do_rescale"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/image_transforms.py#L110",returnDescription:`
<p>The converted image.</p>
`,returnType:`
<p><code>PIL.Image.Image</code></p>
`}}),fe=new St({}),he=new T({props:{name:"class transformers.ImageProcessingMixin",anchor:"transformers.ImageProcessingMixin",parameters:[{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/image_processing_utils.py#L58"}}),ue=new T({props:{name:"from_dict",anchor:"transformers.ImageProcessingMixin.from_dict",parameters:[{name:"image_processor_dict",val:": typing.Dict[str, typing.Any]"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.ImageProcessingMixin.from_dict.image_processor_dict",description:`<strong>image_processor_dict</strong> (<code>Dict[str, Any]</code>) &#x2014;
Dictionary that will be used to instantiate the image processor object. Such a dictionary can be
retrieved from a pretrained checkpoint by leveraging the
<a href="/docs/transformers/main/en/internal/image_processing_utils#transformers.ImageProcessingMixin.to_dict">to_dict()</a> method.`,name:"image_processor_dict"},{anchor:"transformers.ImageProcessingMixin.from_dict.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>) &#x2014;
Additional parameters from which to initialize the image processor object.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/image_processing_utils.py#L302",returnDescription:`
<p>The image processor object instantiated from those
parameters.</p>
`,returnType:`
<p><a
  href="/docs/transformers/main/en/internal/image_processing_utils#transformers.ImageProcessingMixin"
>ImageProcessingMixin</a></p>
`}}),be=new T({props:{name:"from_json_file",anchor:"transformers.ImageProcessingMixin.from_json_file",parameters:[{name:"json_file",val:": typing.Union[str, os.PathLike]"}],parametersDescription:[{anchor:"transformers.ImageProcessingMixin.from_json_file.json_file",description:`<strong>json_file</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Path to the JSON file containing the parameters.`,name:"json_file"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/image_processing_utils.py#L350",returnDescription:`
<p>The image_processor object
instantiated from that JSON file.</p>
`,returnType:`
<p>A image processor of type <a
  href="/docs/transformers/main/en/internal/image_processing_utils#transformers.ImageProcessingMixin"
>ImageProcessingMixin</a></p>
`}}),ye=new T({props:{name:"from_pretrained",anchor:"transformers.ImageProcessingMixin.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:": typing.Union[str, os.PathLike]"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.ImageProcessingMixin.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained image_processor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a image processor file saved using the
<a href="/docs/transformers/main/en/internal/image_processing_utils#transformers.ImageProcessingMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved image processor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.ImageProcessingMixin.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model image processor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.ImageProcessingMixin.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the image processor files and override the cached versions if
they exist.`,name:"force_download"},{anchor:"transformers.ImageProcessingMixin.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.ImageProcessingMixin.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.ImageProcessingMixin.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, or not specified, will use
the token generated when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.ImageProcessingMixin.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/image_processing_utils.py#L82",returnDescription:`
<p>A image processor of type <a
  href="/docs/transformers/main/en/internal/image_processing_utils#transformers.ImageProcessingMixin"
>ImageProcessingMixin</a>.</p>
`}}),K=new $s({props:{anchor:"transformers.ImageProcessingMixin.from_pretrained.example",$$slots:{default:[Ms]},$$scope:{ctx:J}}}),Ie=new T({props:{name:"get_image_processor_dict",anchor:"transformers.ImageProcessingMixin.get_image_processor_dict",parameters:[{name:"pretrained_model_name_or_path",val:": typing.Union[str, os.PathLike]"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.ImageProcessingMixin.get_image_processor_dict.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
The identifier of the pre-trained checkpoint from which we want the dictionary of parameters.`,name:"pretrained_model_name_or_path"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/image_processing_utils.py#L209",returnDescription:`
<p>The dictionary(ies) that will be used to instantiate the image processor object.</p>
`,returnType:`
<p><code>Tuple[Dict, Dict]</code></p>
`}}),xe=new T({props:{name:"push_to_hub",anchor:"transformers.ImageProcessingMixin.push_to_hub",parameters:[{name:"repo_id",val:": str"},{name:"use_temp_dir",val:": typing.Optional[bool] = None"},{name:"commit_message",val:": typing.Optional[str] = None"},{name:"private",val:": typing.Optional[bool] = None"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = None"},{name:"max_shard_size",val:": typing.Union[int, str, NoneType] = '10GB'"},{name:"create_pr",val:": bool = False"},{name:"**deprecated_kwargs",val:""}],parametersDescription:[{anchor:"transformers.ImageProcessingMixin.push_to_hub.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
The name of the repository you want to push your image processor to. It should contain your organization name
when pushing to a given organization.`,name:"repo_id"},{anchor:"transformers.ImageProcessingMixin.push_to_hub.use_temp_dir",description:`<strong>use_temp_dir</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to use a temporary directory to store the files saved before they are pushed to the Hub.
Will default to <code>True</code> if there is no directory named like <code>repo_id</code>, <code>False</code> otherwise.`,name:"use_temp_dir"},{anchor:"transformers.ImageProcessingMixin.push_to_hub.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Message to commit while pushing. Will default to <code>&quot;Upload image processor&quot;</code>.`,name:"commit_message"},{anchor:"transformers.ImageProcessingMixin.push_to_hub.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not the repository created should be private.`,name:"private"},{anchor:"transformers.ImageProcessingMixin.push_to_hub.use_auth_token",description:`<strong>use_auth_token</strong> (<code>bool</code> or <code>str</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>). Will default to <code>True</code> if <code>repo_url</code>
is not specified.`,name:"use_auth_token"},{anchor:"transformers.ImageProcessingMixin.push_to_hub.max_shard_size",description:`<strong>max_shard_size</strong> (<code>int</code> or <code>str</code>, <em>optional</em>, defaults to <code>&quot;10GB&quot;</code>) &#x2014;
Only applicable for models. The maximum size for a checkpoint before being sharded. Checkpoints shard
will then be each of size lower than this size. If expressed as a string, needs to be digits followed
by a unit (like <code>&quot;5MB&quot;</code>).`,name:"max_shard_size"},{anchor:"transformers.ImageProcessingMixin.push_to_hub.create_pr",description:`<strong>create_pr</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to create a PR with the uploaded files or directly commit.`,name:"create_pr"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/utils/hub.py#L712"}}),X=new $s({props:{anchor:"transformers.ImageProcessingMixin.push_to_hub.example",$$slots:{default:[zs]},$$scope:{ctx:J}}}),we=new T({props:{name:"register_for_auto_class",anchor:"transformers.ImageProcessingMixin.register_for_auto_class",parameters:[{name:"auto_class",val:" = 'AutoImageProcessor'"}],parametersDescription:[{anchor:"transformers.ImageProcessingMixin.register_for_auto_class.auto_class",description:`<strong>auto_class</strong> (<code>str</code> or <code>type</code>, <em>optional</em>, defaults to <code>&quot;AutoImageProcessor &quot;</code>) &#x2014;
The auto class to register this new image processor with.`,name:"auto_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/image_processing_utils.py#L404"}}),Z=new Ds({props:{warning:!0,$$slots:{default:[js]},$$scope:{ctx:J}}}),Te=new T({props:{name:"save_pretrained",anchor:"transformers.ImageProcessingMixin.save_pretrained",parameters:[{name:"save_directory",val:": typing.Union[str, os.PathLike]"},{name:"push_to_hub",val:": bool = False"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.ImageProcessingMixin.save_pretrained.save_directory",description:`<strong>save_directory</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Directory where the image processor JSON file will be saved (will be created if it does not exist).`,name:"save_directory"},{anchor:"transformers.ImageProcessingMixin.save_pretrained.push_to_hub",description:`<strong>push_to_hub</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to push your model to the Hugging Face model hub after saving it. You can specify the
repository you want to push to with <code>repo_id</code> (will default to the name of <code>save_directory</code> in your
namespace).
kwargs &#x2014;
Additional key word arguments passed along to the <a href="/docs/transformers/main/en/internal/image_processing_utils#transformers.ImageProcessingMixin.push_to_hub">push_to_hub()</a> method.`,name:"push_to_hub"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/image_processing_utils.py#L165"}}),ke=new T({props:{name:"to_dict",anchor:"transformers.ImageProcessingMixin.to_dict",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/image_processing_utils.py#L338",returnDescription:`
<p>Dictionary of all the attributes that make up this image processor instance.</p>
`,returnType:`
<p><code>Dict[str, Any]</code></p>
`}}),De=new T({props:{name:"to_json_file",anchor:"transformers.ImageProcessingMixin.to_json_file",parameters:[{name:"json_file_path",val:": typing.Union[str, os.PathLike]"}],parametersDescription:[{anchor:"transformers.ImageProcessingMixin.to_json_file.json_file_path",description:`<strong>json_file_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Path to the JSON file in which this image_processor instance&#x2019;s parameters will be saved.`,name:"json_file_path"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/image_processing_utils.py#L390"}}),Me=new T({props:{name:"to_json_string",anchor:"transformers.ImageProcessingMixin.to_json_string",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/image_processing_utils.py#L369",returnDescription:`
<p>String containing all the attributes that make up this feature_extractor instance in JSON format.</p>
`,returnType:`
<p><code>str</code></p>
`}}),{c(){g=t("meta"),E=m(),_=t("h1"),f=t("a"),k=t("span"),v(l.$$.fragment),w=m(),Je=t("span"),Kr=n("Utilities for Image Processors"),yr=m(),je=t("p"),Qr=n(`This page lists all the utility functions used by the image processors, mainly the functional
transformations used to process the images.`),$r=m(),Le=t("p"),Xr=n("Most of those are only useful if you are studying the code of the image processors in the library."),Ir=m(),O=t("h2"),H=t("a"),He=t("span"),v(ie.$$.fragment),Zr=m(),Be=t("span"),eo=n("Image Transformations"),xr=m(),N=t("div"),v(me.$$.fragment),ro=m(),D=t("p"),oo=n("Crops the "),Ge=t("code"),to=n("image"),so=n(" to the specified "),Ye=t("code"),ao=n("size"),no=n(` using a center crop. Note that if the image is too small to be cropped to
the size given, it will be padded (so the returned result will always be of size `),Ke=t("code"),io=n("size"),mo=n(")."),Pr=m(),M=t("div"),v(ce.$$.fragment),co=m(),z=t("p"),lo=n("Normalizes "),Qe=t("code"),po=n("image"),go=n(" using the mean and standard deviation specified by "),Xe=t("code"),fo=n("mean"),ho=n(" and "),Ze=t("code"),uo=n("std"),_o=n("."),bo=m(),er=t("p"),vo=n("image = (image - mean) / std"),wr=m(),A=t("div"),v(le.$$.fragment),yo=m(),S=t("p"),$o=n("Rescales "),rr=t("code"),Io=n("image"),xo=n(" by "),or=t("code"),Po=n("scale"),wo=n("."),Er=m(),F=t("div"),v(de.$$.fragment),Eo=m(),U=t("p"),To=n("Resizes "),tr=t("code"),ko=n("image"),Do=n(" to (h, w) specified by "),sr=t("code"),Mo=n("size"),zo=n(" using the PIL library."),Tr=m(),V=t("div"),v(pe.$$.fragment),jo=m(),ge=t("p"),Lo=n("Converts "),ar=t("code"),Co=n("image"),qo=n(` to a PIL Image. Optionally rescales it and puts the channel dimension back as the last axis if
needed.`),kr=m(),R=t("h2"),B=t("a"),nr=t("span"),v(fe.$$.fragment),Oo=m(),ir=t("span"),No=n("ImageProcessingMixin"),Dr=m(),h=t("div"),v(he.$$.fragment),Ao=m(),mr=t("p"),So=n(`This is an image processor mixin used to provide saving/loading functionality for sequential and image feature
extractors.`),Fo=m(),G=t("div"),v(ue.$$.fragment),Uo=m(),_e=t("p"),Vo=n("Instantiates a type of "),Ce=t("a"),Ro=n("ImageProcessingMixin"),Wo=n(" from a Python dictionary of parameters."),Jo=m(),Y=t("div"),v(be.$$.fragment),Ho=m(),ve=t("p"),Bo=n("Instantiates a image processor of type "),qe=t("a"),Go=n("ImageProcessingMixin"),Yo=n(` from the path to a JSON
file of parameters.`),Ko=m(),L=t("div"),v(ye.$$.fragment),Qo=m(),$e=t("p"),Xo=n("Instantiate a type of "),Oe=t("a"),Zo=n("ImageProcessingMixin"),et=n(" from an image processor."),rt=m(),v(K.$$.fragment),ot=m(),Q=t("div"),v(Ie.$$.fragment),tt=m(),j=t("p"),st=n("From a "),cr=t("code"),at=n("pretrained_model_name_or_path"),nt=n(`, resolve to a dictionary of parameters, to be used for instantiating a
image processor of type `),lr=t("code"),it=n("~image_processor_utils.ImageProcessingMixin"),mt=n(" using "),dr=t("code"),ct=n("from_dict"),lt=n("."),dt=m(),C=t("div"),v(xe.$$.fragment),pt=m(),Pe=t("p"),gt=n(`Upload the image processor file to the \u{1F917} Model Hub while synchronizing a local clone of the repo in
`),pr=t("code"),ft=n("repo_path_or_name"),ht=n("."),ut=m(),v(X.$$.fragment),_t=m(),q=t("div"),v(we.$$.fragment),bt=m(),Ee=t("p"),vt=n(`Register this class with a given auto class. This should only be used for custom image processors as the ones
in the library are already mapped with `),gr=t("code"),yt=n("AutoImageProcessor "),$t=n("."),It=m(),v(Z.$$.fragment),xt=m(),ee=t("div"),v(Te.$$.fragment),Pt=m(),W=t("p"),wt=n("Save an image processor object to the directory "),fr=t("code"),Et=n("save_directory"),Tt=n(`, so that it can be re-loaded using the
`),Ne=t("a"),kt=n("from_pretrained()"),Dt=n(" class method."),Mt=m(),re=t("div"),v(ke.$$.fragment),zt=m(),hr=t("p"),jt=n("Serializes this instance to a Python dictionary."),Lt=m(),oe=t("div"),v(De.$$.fragment),Ct=m(),ur=t("p"),qt=n("Save this instance to a JSON file."),Ot=m(),te=t("div"),v(Me.$$.fragment),Nt=m(),_r=t("p"),At=n("Serializes this instance to a JSON string."),this.h()},l(r){const p=Ts('[data-svelte="svelte-1phssyn"]',document.head);g=s(p,"META",{name:!0,content:!0}),p.forEach(o),E=c(r),_=s(r,"H1",{class:!0});var ze=a(_);f=s(ze,"A",{id:!0,class:!0,href:!0});var br=a(f);k=s(br,"SPAN",{});var vr=a(k);y(l.$$.fragment,vr),vr.forEach(o),br.forEach(o),w=c(ze),Je=s(ze,"SPAN",{});var Ft=a(Je);Kr=i(Ft,"Utilities for Image Processors"),Ft.forEach(o),ze.forEach(o),yr=c(r),je=s(r,"P",{});var Ut=a(je);Qr=i(Ut,`This page lists all the utility functions used by the image processors, mainly the functional
transformations used to process the images.`),Ut.forEach(o),$r=c(r),Le=s(r,"P",{});var Vt=a(Le);Xr=i(Vt,"Most of those are only useful if you are studying the code of the image processors in the library."),Vt.forEach(o),Ir=c(r),O=s(r,"H2",{class:!0});var zr=a(O);H=s(zr,"A",{id:!0,class:!0,href:!0});var Rt=a(H);He=s(Rt,"SPAN",{});var Wt=a(He);y(ie.$$.fragment,Wt),Wt.forEach(o),Rt.forEach(o),Zr=c(zr),Be=s(zr,"SPAN",{});var Jt=a(Be);eo=i(Jt,"Image Transformations"),Jt.forEach(o),zr.forEach(o),xr=c(r),N=s(r,"DIV",{class:!0});var jr=a(N);y(me.$$.fragment,jr),ro=c(jr),D=s(jr,"P",{});var se=a(D);oo=i(se,"Crops the "),Ge=s(se,"CODE",{});var Ht=a(Ge);to=i(Ht,"image"),Ht.forEach(o),so=i(se," to the specified "),Ye=s(se,"CODE",{});var Bt=a(Ye);ao=i(Bt,"size"),Bt.forEach(o),no=i(se,` using a center crop. Note that if the image is too small to be cropped to
the size given, it will be padded (so the returned result will always be of size `),Ke=s(se,"CODE",{});var Gt=a(Ke);io=i(Gt,"size"),Gt.forEach(o),mo=i(se,")."),se.forEach(o),jr.forEach(o),Pr=c(r),M=s(r,"DIV",{class:!0});var Ae=a(M);y(ce.$$.fragment,Ae),co=c(Ae),z=s(Ae,"P",{});var ae=a(z);lo=i(ae,"Normalizes "),Qe=s(ae,"CODE",{});var Yt=a(Qe);po=i(Yt,"image"),Yt.forEach(o),go=i(ae," using the mean and standard deviation specified by "),Xe=s(ae,"CODE",{});var Kt=a(Xe);fo=i(Kt,"mean"),Kt.forEach(o),ho=i(ae," and "),Ze=s(ae,"CODE",{});var Qt=a(Ze);uo=i(Qt,"std"),Qt.forEach(o),_o=i(ae,"."),ae.forEach(o),bo=c(Ae),er=s(Ae,"P",{});var Xt=a(er);vo=i(Xt,"image = (image - mean) / std"),Xt.forEach(o),Ae.forEach(o),wr=c(r),A=s(r,"DIV",{class:!0});var Lr=a(A);y(le.$$.fragment,Lr),yo=c(Lr),S=s(Lr,"P",{});var Se=a(S);$o=i(Se,"Rescales "),rr=s(Se,"CODE",{});var Zt=a(rr);Io=i(Zt,"image"),Zt.forEach(o),xo=i(Se," by "),or=s(Se,"CODE",{});var es=a(or);Po=i(es,"scale"),es.forEach(o),wo=i(Se,"."),Se.forEach(o),Lr.forEach(o),Er=c(r),F=s(r,"DIV",{class:!0});var Cr=a(F);y(de.$$.fragment,Cr),Eo=c(Cr),U=s(Cr,"P",{});var Fe=a(U);To=i(Fe,"Resizes "),tr=s(Fe,"CODE",{});var rs=a(tr);ko=i(rs,"image"),rs.forEach(o),Do=i(Fe," to (h, w) specified by "),sr=s(Fe,"CODE",{});var os=a(sr);Mo=i(os,"size"),os.forEach(o),zo=i(Fe," using the PIL library."),Fe.forEach(o),Cr.forEach(o),Tr=c(r),V=s(r,"DIV",{class:!0});var qr=a(V);y(pe.$$.fragment,qr),jo=c(qr),ge=s(qr,"P",{});var Or=a(ge);Lo=i(Or,"Converts "),ar=s(Or,"CODE",{});var ts=a(ar);Co=i(ts,"image"),ts.forEach(o),qo=i(Or,` to a PIL Image. Optionally rescales it and puts the channel dimension back as the last axis if
needed.`),Or.forEach(o),qr.forEach(o),kr=c(r),R=s(r,"H2",{class:!0});var Nr=a(R);B=s(Nr,"A",{id:!0,class:!0,href:!0});var ss=a(B);nr=s(ss,"SPAN",{});var as=a(nr);y(fe.$$.fragment,as),as.forEach(o),ss.forEach(o),Oo=c(Nr),ir=s(Nr,"SPAN",{});var ns=a(ir);No=i(ns,"ImageProcessingMixin"),ns.forEach(o),Nr.forEach(o),Dr=c(r),h=s(r,"DIV",{class:!0});var b=a(h);y(he.$$.fragment,b),Ao=c(b),mr=s(b,"P",{});var is=a(mr);So=i(is,`This is an image processor mixin used to provide saving/loading functionality for sequential and image feature
extractors.`),is.forEach(o),Fo=c(b),G=s(b,"DIV",{class:!0});var Ar=a(G);y(ue.$$.fragment,Ar),Uo=c(Ar),_e=s(Ar,"P",{});var Sr=a(_e);Vo=i(Sr,"Instantiates a type of "),Ce=s(Sr,"A",{href:!0});var ms=a(Ce);Ro=i(ms,"ImageProcessingMixin"),ms.forEach(o),Wo=i(Sr," from a Python dictionary of parameters."),Sr.forEach(o),Ar.forEach(o),Jo=c(b),Y=s(b,"DIV",{class:!0});var Fr=a(Y);y(be.$$.fragment,Fr),Ho=c(Fr),ve=s(Fr,"P",{});var Ur=a(ve);Bo=i(Ur,"Instantiates a image processor of type "),qe=s(Ur,"A",{href:!0});var cs=a(qe);Go=i(cs,"ImageProcessingMixin"),cs.forEach(o),Yo=i(Ur,` from the path to a JSON
file of parameters.`),Ur.forEach(o),Fr.forEach(o),Ko=c(b),L=s(b,"DIV",{class:!0});var Ue=a(L);y(ye.$$.fragment,Ue),Qo=c(Ue),$e=s(Ue,"P",{});var Vr=a($e);Xo=i(Vr,"Instantiate a type of "),Oe=s(Vr,"A",{href:!0});var ls=a(Oe);Zo=i(ls,"ImageProcessingMixin"),ls.forEach(o),et=i(Vr," from an image processor."),Vr.forEach(o),rt=c(Ue),y(K.$$.fragment,Ue),Ue.forEach(o),ot=c(b),Q=s(b,"DIV",{class:!0});var Rr=a(Q);y(Ie.$$.fragment,Rr),tt=c(Rr),j=s(Rr,"P",{});var ne=a(j);st=i(ne,"From a "),cr=s(ne,"CODE",{});var ds=a(cr);at=i(ds,"pretrained_model_name_or_path"),ds.forEach(o),nt=i(ne,`, resolve to a dictionary of parameters, to be used for instantiating a
image processor of type `),lr=s(ne,"CODE",{});var ps=a(lr);it=i(ps,"~image_processor_utils.ImageProcessingMixin"),ps.forEach(o),mt=i(ne," using "),dr=s(ne,"CODE",{});var gs=a(dr);ct=i(gs,"from_dict"),gs.forEach(o),lt=i(ne,"."),ne.forEach(o),Rr.forEach(o),dt=c(b),C=s(b,"DIV",{class:!0});var Ve=a(C);y(xe.$$.fragment,Ve),pt=c(Ve),Pe=s(Ve,"P",{});var Wr=a(Pe);gt=i(Wr,`Upload the image processor file to the \u{1F917} Model Hub while synchronizing a local clone of the repo in
`),pr=s(Wr,"CODE",{});var fs=a(pr);ft=i(fs,"repo_path_or_name"),fs.forEach(o),ht=i(Wr,"."),Wr.forEach(o),ut=c(Ve),y(X.$$.fragment,Ve),Ve.forEach(o),_t=c(b),q=s(b,"DIV",{class:!0});var Re=a(q);y(we.$$.fragment,Re),bt=c(Re),Ee=s(Re,"P",{});var Jr=a(Ee);vt=i(Jr,`Register this class with a given auto class. This should only be used for custom image processors as the ones
in the library are already mapped with `),gr=s(Jr,"CODE",{});var hs=a(gr);yt=i(hs,"AutoImageProcessor "),hs.forEach(o),$t=i(Jr,"."),Jr.forEach(o),It=c(Re),y(Z.$$.fragment,Re),Re.forEach(o),xt=c(b),ee=s(b,"DIV",{class:!0});var Hr=a(ee);y(Te.$$.fragment,Hr),Pt=c(Hr),W=s(Hr,"P",{});var We=a(W);wt=i(We,"Save an image processor object to the directory "),fr=s(We,"CODE",{});var us=a(fr);Et=i(us,"save_directory"),us.forEach(o),Tt=i(We,`, so that it can be re-loaded using the
`),Ne=s(We,"A",{href:!0});var _s=a(Ne);kt=i(_s,"from_pretrained()"),_s.forEach(o),Dt=i(We," class method."),We.forEach(o),Hr.forEach(o),Mt=c(b),re=s(b,"DIV",{class:!0});var Br=a(re);y(ke.$$.fragment,Br),zt=c(Br),hr=s(Br,"P",{});var bs=a(hr);jt=i(bs,"Serializes this instance to a Python dictionary."),bs.forEach(o),Br.forEach(o),Lt=c(b),oe=s(b,"DIV",{class:!0});var Gr=a(oe);y(De.$$.fragment,Gr),Ct=c(Gr),ur=s(Gr,"P",{});var vs=a(ur);qt=i(vs,"Save this instance to a JSON file."),vs.forEach(o),Gr.forEach(o),Ot=c(b),te=s(b,"DIV",{class:!0});var Yr=a(te);y(Me.$$.fragment,Yr),Nt=c(Yr),_r=s(Yr,"P",{});var ys=a(_r);At=i(ys,"Serializes this instance to a JSON string."),ys.forEach(o),Yr.forEach(o),b.forEach(o),this.h()},h(){d(g,"name","hf:doc:metadata"),d(g,"content",JSON.stringify(Cs)),d(f,"id","utilities-for-image-processors"),d(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(f,"href","#utilities-for-image-processors"),d(_,"class","relative group"),d(H,"id","transformers.image_transforms.center_crop"),d(H,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(H,"href","#transformers.image_transforms.center_crop"),d(O,"class","relative group"),d(N,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(A,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(V,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(B,"id","transformers.ImageProcessingMixin"),d(B,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(B,"href","#transformers.ImageProcessingMixin"),d(R,"class","relative group"),d(Ce,"href","/docs/transformers/main/en/internal/image_processing_utils#transformers.ImageProcessingMixin"),d(G,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qe,"href","/docs/transformers/main/en/internal/image_processing_utils#transformers.ImageProcessingMixin"),d(Y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Oe,"href","/docs/transformers/main/en/internal/image_processing_utils#transformers.ImageProcessingMixin"),d(L,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(C,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ne,"href","/docs/transformers/main/en/internal/image_processing_utils#transformers.ImageProcessingMixin.from_pretrained"),d(ee,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(re,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(oe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(te,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(h,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(r,p){e(document.head,g),u(r,E,p),u(r,_,p),e(_,f),e(f,k),$(l,k,null),e(_,w),e(_,Je),e(Je,Kr),u(r,yr,p),u(r,je,p),e(je,Qr),u(r,$r,p),u(r,Le,p),e(Le,Xr),u(r,Ir,p),u(r,O,p),e(O,H),e(H,He),$(ie,He,null),e(O,Zr),e(O,Be),e(Be,eo),u(r,xr,p),u(r,N,p),$(me,N,null),e(N,ro),e(N,D),e(D,oo),e(D,Ge),e(Ge,to),e(D,so),e(D,Ye),e(Ye,ao),e(D,no),e(D,Ke),e(Ke,io),e(D,mo),u(r,Pr,p),u(r,M,p),$(ce,M,null),e(M,co),e(M,z),e(z,lo),e(z,Qe),e(Qe,po),e(z,go),e(z,Xe),e(Xe,fo),e(z,ho),e(z,Ze),e(Ze,uo),e(z,_o),e(M,bo),e(M,er),e(er,vo),u(r,wr,p),u(r,A,p),$(le,A,null),e(A,yo),e(A,S),e(S,$o),e(S,rr),e(rr,Io),e(S,xo),e(S,or),e(or,Po),e(S,wo),u(r,Er,p),u(r,F,p),$(de,F,null),e(F,Eo),e(F,U),e(U,To),e(U,tr),e(tr,ko),e(U,Do),e(U,sr),e(sr,Mo),e(U,zo),u(r,Tr,p),u(r,V,p),$(pe,V,null),e(V,jo),e(V,ge),e(ge,Lo),e(ge,ar),e(ar,Co),e(ge,qo),u(r,kr,p),u(r,R,p),e(R,B),e(B,nr),$(fe,nr,null),e(R,Oo),e(R,ir),e(ir,No),u(r,Dr,p),u(r,h,p),$(he,h,null),e(h,Ao),e(h,mr),e(mr,So),e(h,Fo),e(h,G),$(ue,G,null),e(G,Uo),e(G,_e),e(_e,Vo),e(_e,Ce),e(Ce,Ro),e(_e,Wo),e(h,Jo),e(h,Y),$(be,Y,null),e(Y,Ho),e(Y,ve),e(ve,Bo),e(ve,qe),e(qe,Go),e(ve,Yo),e(h,Ko),e(h,L),$(ye,L,null),e(L,Qo),e(L,$e),e($e,Xo),e($e,Oe),e(Oe,Zo),e($e,et),e(L,rt),$(K,L,null),e(h,ot),e(h,Q),$(Ie,Q,null),e(Q,tt),e(Q,j),e(j,st),e(j,cr),e(cr,at),e(j,nt),e(j,lr),e(lr,it),e(j,mt),e(j,dr),e(dr,ct),e(j,lt),e(h,dt),e(h,C),$(xe,C,null),e(C,pt),e(C,Pe),e(Pe,gt),e(Pe,pr),e(pr,ft),e(Pe,ht),e(C,ut),$(X,C,null),e(h,_t),e(h,q),$(we,q,null),e(q,bt),e(q,Ee),e(Ee,vt),e(Ee,gr),e(gr,yt),e(Ee,$t),e(q,It),$(Z,q,null),e(h,xt),e(h,ee),$(Te,ee,null),e(ee,Pt),e(ee,W),e(W,wt),e(W,fr),e(fr,Et),e(W,Tt),e(W,Ne),e(Ne,kt),e(W,Dt),e(h,Mt),e(h,re),$(ke,re,null),e(re,zt),e(re,hr),e(hr,jt),e(h,Lt),e(h,oe),$(De,oe,null),e(oe,Ct),e(oe,ur),e(ur,qt),e(h,Ot),e(h,te),$(Me,te,null),e(te,Nt),e(te,_r),e(_r,At),Mr=!0},p(r,[p]){const ze={};p&2&&(ze.$$scope={dirty:p,ctx:r}),K.$set(ze);const br={};p&2&&(br.$$scope={dirty:p,ctx:r}),X.$set(br);const vr={};p&2&&(vr.$$scope={dirty:p,ctx:r}),Z.$set(vr)},i(r){Mr||(I(l.$$.fragment,r),I(ie.$$.fragment,r),I(me.$$.fragment,r),I(ce.$$.fragment,r),I(le.$$.fragment,r),I(de.$$.fragment,r),I(pe.$$.fragment,r),I(fe.$$.fragment,r),I(he.$$.fragment,r),I(ue.$$.fragment,r),I(be.$$.fragment,r),I(ye.$$.fragment,r),I(K.$$.fragment,r),I(Ie.$$.fragment,r),I(xe.$$.fragment,r),I(X.$$.fragment,r),I(we.$$.fragment,r),I(Z.$$.fragment,r),I(Te.$$.fragment,r),I(ke.$$.fragment,r),I(De.$$.fragment,r),I(Me.$$.fragment,r),Mr=!0)},o(r){x(l.$$.fragment,r),x(ie.$$.fragment,r),x(me.$$.fragment,r),x(ce.$$.fragment,r),x(le.$$.fragment,r),x(de.$$.fragment,r),x(pe.$$.fragment,r),x(fe.$$.fragment,r),x(he.$$.fragment,r),x(ue.$$.fragment,r),x(be.$$.fragment,r),x(ye.$$.fragment,r),x(K.$$.fragment,r),x(Ie.$$.fragment,r),x(xe.$$.fragment,r),x(X.$$.fragment,r),x(we.$$.fragment,r),x(Z.$$.fragment,r),x(Te.$$.fragment,r),x(ke.$$.fragment,r),x(De.$$.fragment,r),x(Me.$$.fragment,r),Mr=!1},d(r){o(g),r&&o(E),r&&o(_),P(l),r&&o(yr),r&&o(je),r&&o($r),r&&o(Le),r&&o(Ir),r&&o(O),P(ie),r&&o(xr),r&&o(N),P(me),r&&o(Pr),r&&o(M),P(ce),r&&o(wr),r&&o(A),P(le),r&&o(Er),r&&o(F),P(de),r&&o(Tr),r&&o(V),P(pe),r&&o(kr),r&&o(R),P(fe),r&&o(Dr),r&&o(h),P(he),P(ue),P(be),P(ye),P(K),P(Ie),P(xe),P(X),P(we),P(Z),P(Te),P(ke),P(De),P(Me)}}}const Cs={local:"utilities-for-image-processors",sections:[{local:"transformers.image_transforms.center_crop",title:"Image Transformations"},{local:"transformers.ImageProcessingMixin",title:"ImageProcessingMixin"}],title:"Utilities for Image Processors"};function qs(J){return ks(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Vs extends Ps{constructor(g){super();ws(this,g,qs,Ls,Es,{})}}export{Vs as default,Cs as metadata};
