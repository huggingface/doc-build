import{S as Qm,i as Jm,s as Km,e as a,k as f,w as c,t as i,M as Zm,c as n,d as t,m as d,a as r,x as u,h,b as p,G as s,g as l,y as m,L as ev,q as v,o as b,B as _,v as tv}from"../chunks/vendor-hf-doc-builder.js";import{Y as kd}from"../chunks/Youtube-hf-doc-builder.js";import{I as w}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as y}from"../chunks/CodeBlock-hf-doc-builder.js";function sv(yd){let S,ur,C,_e,wa,ct,ii,$a,hi,mr,_s,pi,vr,D,we,ga,ut,fi,ka,di,br,M,$e,ya,mt,ci,Ea,ui,_r,ws,mi,wr,vt,$r,$s,vi,gr,gs,bi,kr,bt,yr,ks,_i,Er,_t,qr,ys,wi,jr,Es,$i,Ar,wt,Pr,qs,gi,Tr,$t,xr,q,ki,js,yi,Ei,qa,qi,ji,ja,Ai,Pi,zr,gt,Nr,I,ge,Aa,kt,Ti,Pa,xi,Sr,yt,zi,As,Ni,Cr,B,ke,Ta,Et,Si,xa,Ci,Dr,qt,Di,Ps,Mi,Mr,F,ye,za,jt,Ii,Na,Bi,Ir,L,Ee,Sa,At,Fi,Ca,Li,Br,Ts,Hi,Fr,H,qe,Da,Pt,Ri,Ma,Oi,Lr,R,je,Ia,Tt,Gi,Ba,Wi,Hr,xs,Ui,Rr,j,Vi,Fa,Xi,Yi,La,Qi,Ji,Ha,Ki,Zi,Or,zs,eh,Gr,O,Ae,Ra,xt,th,Oa,sh,Wr,Ns,ah,Ur,G,Pe,Ga,zt,nh,Wa,rh,Vr,W,Te,Ua,Nt,oh,Va,lh,Xr,xe,ih,Xa,hh,ph,Yr,$,fh,Ya,dh,ch,Qa,uh,mh,St,vh,bh,Ja,_h,wh,Ka,$h,gh,Za,kh,yh,en,Eh,qh,tn,jh,Ah,Qr,A,Ph,Ss,Th,xh,sn,zh,Nh,an,Sh,Ch,Jr,U,ze,nn,Ct,Dh,rn,Mh,Kr,V,Ne,on,Dt,Ih,ln,Bh,Zr,Se,Fh,hn,Lh,Hh,eo,Mt,to,Ce,Rh,It,Oh,Gh,so,Bt,ao,Cs,Wh,no,Ft,ro,Ds,Uh,oo,Lt,lo,De,Vh,Ht,Xh,Yh,io,Rt,ho,Ms,Qh,po,Ot,fo,Is,Jh,co,Bs,Kh,uo,Gt,mo,Fs,Zh,vo,Wt,bo,Me,ep,Ls,tp,sp,_o,X,Ie,pn,Ut,ap,fn,np,wo,Y,Be,dn,Vt,rp,cn,op,$o,Hs,lp,go,Rs,ip,ko,P,Q,hp,Os,pp,fp,un,dp,cp,up,J,mp,Gs,vp,bp,mn,_p,wp,$p,K,gp,Ws,kp,yp,vn,Ep,qp,jp,k,Ap,Us,Pp,Tp,Vs,xp,zp,bn,Np,Sp,_n,Cp,Dp,wn,Mp,Ip,$n,Bp,Fp,yo,Fe,Lp,Xs,Hp,Rp,Eo,Z,Le,gn,Xt,Op,kn,Gp,qo,ee,He,yn,Yt,Wp,En,Up,jo,Ys,Vp,Ao,te,Re,qn,Qt,Xp,jn,Yp,Po,Qs,Qp,To,se,Oe,An,Jt,Jp,Pn,Kp,xo,ae,Ge,Tn,Kt,Zp,xn,ef,zo,Js,tf,No,ne,We,zn,Zt,sf,Nn,af,So,Ks,nf,Co,re,Ue,Sn,es,rf,Cn,of,Do,Zs,lf,Mo,oe,Ve,Dn,ts,hf,Mn,pf,Io,le,Xe,In,ss,ff,Bn,df,Bo,Ye,cf,Fn,uf,mf,Fo,Qe,vf,Ln,bf,_f,Lo,Je,wf,Hn,$f,gf,Ho,ie,Ke,Rn,as,kf,On,yf,Ro,ea,Ef,Oo,he,Ze,Gn,ns,qf,Wn,jf,Go,pe,et,Un,rs,Af,Vn,Pf,Wo,ta,Tf,Uo,fe,tt,Xn,os,xf,Yn,zf,Vo,de,st,Qn,ls,Nf,Jn,Sf,Xo,sa,Cf,Yo,ce,at,Kn,is,Df,Zn,Mf,Qo,T,If,aa,Bf,Ff,na,Lf,Hf,Jo,ue,nt,er,hs,Rf,tr,Of,Ko,me,rt,sr,ps,Gf,ar,Wf,Zo,ra,Uf,el,ve,ot,nr,fs,Vf,rr,Xf,tl,oa,Yf,sl,ds,al,x,Qf,or,Jf,Kf,lr,Zf,ed,nl,cs,rl,lt,td,ir,sd,ad,ol,us,ll,la,nd,il,ms,hl,ia,rd,pl,ha,od,fl,vs,dl,z,ld,hr,id,hd,pr,pd,fd,cl,N,dd,pa,cd,ud,fr,md,vd,ul,be,it,dr,bs,bd,cr,_d,ml,fa,wd,vl;return ct=new w({}),ut=new w({}),mt=new w({}),vt=new kd({props:{id:"M6adb1j2jPI"}}),bt=new y({props:{code:`from transformers import BertTokenizer

tokenizer = BertTokenizer.from_pretrained("bert-base-cased")

sequence_a = "This is a short sequence."
sequence_b = "This is a rather long sequence. It is at least longer than the sequence A."

encoded_sequence_a = tokenizer(sequence_a)["input_ids"]
encoded_sequence_b = tokenizer(sequence_b)["input_ids"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>sequence_a = <span class="hljs-string">&quot;This is a short sequence.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>sequence_b = <span class="hljs-string">&quot;This is a rather long sequence. It is at least longer than the sequence A.&quot;</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_sequence_a = tokenizer(sequence_a)[<span class="hljs-string">&quot;input_ids&quot;</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_sequence_b = tokenizer(sequence_b)[<span class="hljs-string">&quot;input_ids&quot;</span>]`}}),_t=new y({props:{code:"len(encoded_sequence_a), len(encoded_sequence_b)",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">len</span>(encoded_sequence_a), <span class="hljs-built_in">len</span>(encoded_sequence_b)
(<span class="hljs-number">8</span>, <span class="hljs-number">19</span>)`}}),wt=new y({props:{code:"padded_sequences = tokenizer([sequence_a, sequence_b], padding=True)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>padded_sequences = tokenizer([sequence_a, sequence_b], padding=<span class="hljs-literal">True</span>)'}}),$t=new y({props:{code:'padded_sequences["input_ids"]',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>padded_sequences[<span class="hljs-string">&quot;input_ids&quot;</span>]
[[<span class="hljs-number">101</span>, <span class="hljs-number">1188</span>, <span class="hljs-number">1110</span>, <span class="hljs-number">170</span>, <span class="hljs-number">1603</span>, <span class="hljs-number">4954</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">101</span>, <span class="hljs-number">1188</span>, <span class="hljs-number">1110</span>, <span class="hljs-number">170</span>, <span class="hljs-number">1897</span>, <span class="hljs-number">1263</span>, <span class="hljs-number">4954</span>, <span class="hljs-number">119</span>, <span class="hljs-number">1135</span>, <span class="hljs-number">1110</span>, <span class="hljs-number">1120</span>, <span class="hljs-number">1655</span>, <span class="hljs-number">2039</span>, <span class="hljs-number">1190</span>, <span class="hljs-number">1103</span>, <span class="hljs-number">4954</span>, <span class="hljs-number">138</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>]]`}}),gt=new y({props:{code:'padded_sequences["attention_mask"]',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>padded_sequences[<span class="hljs-string">&quot;attention_mask&quot;</span>]
[[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]]`}}),kt=new w({}),Et=new w({}),jt=new w({}),At=new w({}),Pt=new w({}),Tt=new w({}),xt=new w({}),zt=new w({}),Nt=new w({}),Ct=new w({}),Dt=new w({}),Mt=new kd({props:{id:"VFp38yj8h3A"}}),Bt=new y({props:{code:`from transformers import BertTokenizer

tokenizer = BertTokenizer.from_pretrained("bert-base-cased")

sequence = "A Titan RTX has 24GB of VRAM"`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>sequence = <span class="hljs-string">&quot;A Titan RTX has 24GB of VRAM&quot;</span>`}}),Ft=new y({props:{code:"tokenized_sequence = tokenizer.tokenize(sequence)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_sequence = tokenizer.tokenize(sequence)'}}),Lt=new y({props:{code:"print(tokenized_sequence)",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(tokenized_sequence)
[<span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;Titan&#x27;</span>, <span class="hljs-string">&#x27;R&#x27;</span>, <span class="hljs-string">&#x27;##T&#x27;</span>, <span class="hljs-string">&#x27;##X&#x27;</span>, <span class="hljs-string">&#x27;has&#x27;</span>, <span class="hljs-string">&#x27;24&#x27;</span>, <span class="hljs-string">&#x27;##GB&#x27;</span>, <span class="hljs-string">&#x27;of&#x27;</span>, <span class="hljs-string">&#x27;V&#x27;</span>, <span class="hljs-string">&#x27;##RA&#x27;</span>, <span class="hljs-string">&#x27;##M&#x27;</span>]`}}),Rt=new y({props:{code:"inputs = tokenizer(sequence)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(sequence)'}}),Ot=new y({props:{code:`encoded_sequence = inputs["input_ids"]
print(encoded_sequence)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_sequence = inputs[<span class="hljs-string">&quot;input_ids&quot;</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoded_sequence)
[<span class="hljs-number">101</span>, <span class="hljs-number">138</span>, <span class="hljs-number">18696</span>, <span class="hljs-number">155</span>, <span class="hljs-number">1942</span>, <span class="hljs-number">3190</span>, <span class="hljs-number">1144</span>, <span class="hljs-number">1572</span>, <span class="hljs-number">13745</span>, <span class="hljs-number">1104</span>, <span class="hljs-number">159</span>, <span class="hljs-number">9664</span>, <span class="hljs-number">2107</span>, <span class="hljs-number">102</span>]`}}),Gt=new y({props:{code:"decoded_sequence = tokenizer.decode(encoded_sequence)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>decoded_sequence = tokenizer.decode(encoded_sequence)'}}),Wt=new y({props:{code:"print(decoded_sequence)",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(decoded_sequence)
[CLS] A Titan RTX has 24GB of VRAM [SEP]`}}),Ut=new w({}),Vt=new w({}),Xt=new w({}),Yt=new w({}),Qt=new w({}),Jt=new w({}),Kt=new w({}),Zt=new w({}),es=new w({}),ts=new w({}),ss=new w({}),as=new w({}),ns=new w({}),rs=new w({}),os=new w({}),ls=new w({}),is=new w({}),hs=new w({}),ps=new w({}),fs=new w({}),ds=new kd({props:{id:"0u3ioSwev3s"}}),cs=new y({props:{code:"# [CLS] SEQUENCE_A [SEP] SEQUENCE_B [SEP]",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># [CLS] SEQUENCE_A [SEP] SEQUENCE_B [SEP]</span>'}}),us=new y({props:{code:`from transformers import BertTokenizer

tokenizer = BertTokenizer.from_pretrained("bert-base-cased")
sequence_a = "HuggingFace is based in NYC"
sequence_b = "Where is HuggingFace based?"

encoded_dict = tokenizer(sequence_a, sequence_b)
decoded = tokenizer.decode(encoded_dict["input_ids"])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>sequence_a = <span class="hljs-string">&quot;HuggingFace is based in NYC&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>sequence_b = <span class="hljs-string">&quot;Where is HuggingFace based?&quot;</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_dict = tokenizer(sequence_a, sequence_b)
<span class="hljs-meta">&gt;&gt;&gt; </span>decoded = tokenizer.decode(encoded_dict[<span class="hljs-string">&quot;input_ids&quot;</span>])`}}),ms=new y({props:{code:"print(decoded)",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(decoded)
[CLS] HuggingFace <span class="hljs-keyword">is</span> based <span class="hljs-keyword">in</span> NYC [SEP] Where <span class="hljs-keyword">is</span> HuggingFace based? [SEP]`}}),vs=new y({props:{code:'encoded_dict["token_type_ids"]',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_dict[<span class="hljs-string">&quot;token_type_ids&quot;</span>]
[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]`}}),bs=new w({}),{c(){S=a("meta"),ur=f(),C=a("h1"),_e=a("a"),wa=a("span"),c(ct.$$.fragment),ii=f(),$a=a("span"),hi=i("Glossary"),mr=f(),_s=a("p"),pi=i(`This glossary defines general machine learning and \u{1F917} Transformers terms to help you better understand the
documentation.`),vr=f(),D=a("h2"),we=a("a"),ga=a("span"),c(ut.$$.fragment),fi=f(),ka=a("span"),di=i("A"),br=f(),M=a("h3"),$e=a("a"),ya=a("span"),c(mt.$$.fragment),ci=f(),Ea=a("span"),ui=i("Attention mask"),_r=f(),ws=a("p"),mi=i("The attention mask is an optional argument used when batching sequences together."),wr=f(),c(vt.$$.fragment),$r=f(),$s=a("p"),vi=i("This argument indicates to the model which tokens should be attended to, and which should not."),gr=f(),gs=a("p"),bi=i("For example, consider these two sequences:"),kr=f(),c(bt.$$.fragment),yr=f(),ks=a("p"),_i=i("The encoded versions have different lengths:"),Er=f(),c(_t.$$.fragment),qr=f(),ys=a("p"),wi=i(`Therefore, we can\u2019t put them together in the same tensor as-is. The first sequence needs to be padded up to the length
of the second one, or the second one needs to be truncated down to the length of the first one.`),jr=f(),Es=a("p"),$i=i(`In the first case, the list of IDs will be extended by the padding indices. We can pass a list to the tokenizer and ask
it to pad like this:`),Ar=f(),c(wt.$$.fragment),Pr=f(),qs=a("p"),gi=i("We can see that 0s have been added on the right of the first sentence to make it the same length as the second one:"),Tr=f(),c($t.$$.fragment),xr=f(),q=a("p"),ki=i(`This can then be converted into a tensor in PyTorch or TensorFlow. The attention mask is a binary tensor indicating the
position of the padded indices so that the model does not attend to them. For the `),js=a("a"),yi=i("BertTokenizer"),Ei=i(", "),qa=a("code"),qi=i("1"),ji=i(` indicates a
value that should be attended to, while `),ja=a("code"),Ai=i("0"),Pi=i(` indicates a padded value. This attention mask is in the dictionary returned
by the tokenizer under the key \u201Cattention_mask\u201D:`),zr=f(),c(gt.$$.fragment),Nr=f(),I=a("h3"),ge=a("a"),Aa=a("span"),c(kt.$$.fragment),Ti=f(),Pa=a("span"),xi=i("autoencoding models"),Sr=f(),yt=a("p"),zi=i("see "),As=a("a"),Ni=i("MLM"),Cr=f(),B=a("h3"),ke=a("a"),Ta=a("span"),c(Et.$$.fragment),Si=f(),xa=a("span"),Ci=i("autoregressive models"),Dr=f(),qt=a("p"),Di=i("see "),Ps=a("a"),Mi=i("CLM"),Mr=f(),F=a("h2"),ye=a("a"),za=a("span"),c(jt.$$.fragment),Ii=f(),Na=a("span"),Bi=i("C"),Ir=f(),L=a("h3"),Ee=a("a"),Sa=a("span"),c(At.$$.fragment),Fi=f(),Ca=a("span"),Li=i("CLM"),Br=f(),Ts=a("p"),Hi=i(`Causal language modeling, a pretraining task where the model reads the texts in order and has to predict the next word.
It\u2019s usually done by reading the whole sentence but using a mask inside the model to hide the future tokens at a
certain timestep.`),Fr=f(),H=a("h2"),qe=a("a"),Da=a("span"),c(Pt.$$.fragment),Ri=f(),Ma=a("span"),Oi=i("D"),Lr=f(),R=a("h3"),je=a("a"),Ia=a("span"),c(Tt.$$.fragment),Gi=f(),Ba=a("span"),Wi=i("Decoder input IDs"),Hr=f(),xs=a("p"),Ui=i(`This input is specific to encoder-decoder models, and contains the input IDs that will be fed to the decoder. These
inputs should be used for sequence to sequence tasks, such as translation or summarization, and are usually built in a
way specific to each model.`),Rr=f(),j=a("p"),Vi=i("Most encoder-decoder models (BART, T5) create their "),Fa=a("code"),Xi=i("decoder_input_ids"),Yi=i(" on their own from the "),La=a("code"),Qi=i("labels"),Ji=i(`. In such models,
passing the `),Ha=a("code"),Ki=i("labels"),Zi=i(" is the preferred way to handle training."),Or=f(),zs=a("p"),eh=i("Please check each model\u2019s docs to see how they handle these input IDs for sequence to sequence training."),Gr=f(),O=a("h3"),Ae=a("a"),Ra=a("span"),c(xt.$$.fragment),th=f(),Oa=a("span"),sh=i("deep learning"),Wr=f(),Ns=a("p"),ah=i("Machine learning algorithms which uses neural networks with several layers."),Ur=f(),G=a("h2"),Pe=a("a"),Ga=a("span"),c(zt.$$.fragment),nh=f(),Wa=a("span"),rh=i("F"),Vr=f(),W=a("h3"),Te=a("a"),Ua=a("span"),c(Nt.$$.fragment),oh=f(),Va=a("span"),lh=i("Feed Forward Chunking"),Xr=f(),xe=a("p"),ih=i(`In each residual attention block in transformers the self-attention layer is usually followed by 2 feed forward layers.
The intermediate embedding size of the feed forward layers is often bigger than the hidden size of the model (e.g., for
`),Xa=a("code"),hh=i("bert-base-uncased"),ph=i(")."),Yr=f(),$=a("p"),fh=i("For an input of size "),Ya=a("code"),dh=i("[batch_size, sequence_length]"),ch=i(`, the memory required to store the intermediate feed forward
embeddings `),Qa=a("code"),uh=i("[batch_size, sequence_length, config.intermediate_size]"),mh=i(` can account for a large fraction of the memory
use. The authors of `),St=a("a"),vh=i("Reformer: The Efficient Transformer"),bh=i(` noticed that since the
computation is independent of the `),Ja=a("code"),_h=i("sequence_length"),wh=i(` dimension, it is mathematically equivalent to compute the output
embeddings of both feed forward layers `),Ka=a("code"),$h=i("[batch_size, config.hidden_size]_0, ..., [batch_size, config.hidden_size]_n"),gh=i(`
individually and concat them afterward to `),Za=a("code"),kh=i("[batch_size, sequence_length, config.hidden_size]"),yh=i(" with "),en=a("code"),Eh=i("n = sequence_length"),qh=i(`, which trades increased computation time against reduced memory use, but yields a mathematically
`),tn=a("strong"),jh=i("equivalent"),Ah=i(" result."),Qr=f(),A=a("p"),Ph=i("For models employing the function "),Ss=a("a"),Th=i("apply_chunking_to_forward()"),xh=i(", the "),sn=a("code"),zh=i("chunk_size"),Nh=i(` defines the number of output
embeddings that are computed in parallel and thus defines the trade-off between memory and time complexity. If
`),an=a("code"),Sh=i("chunk_size"),Ch=i(" is set to 0, no feed forward chunking is done."),Jr=f(),U=a("h2"),ze=a("a"),nn=a("span"),c(Ct.$$.fragment),Dh=f(),rn=a("span"),Mh=i("I"),Kr=f(),V=a("h3"),Ne=a("a"),on=a("span"),c(Dt.$$.fragment),Ih=f(),ln=a("span"),Bh=i("Input IDs"),Zr=f(),Se=a("p"),Fh=i("The input ids are often the only required parameters to be passed to the model as input. "),hn=a("em"),Lh=i(`They are token indices,
numerical representations of tokens building the sequences that will be used as input by the model`),Hh=i("."),eo=f(),c(Mt.$$.fragment),to=f(),Ce=a("p"),Rh=i(`Each tokenizer works differently but the underlying mechanism remains the same. Here\u2019s an example using the BERT
tokenizer, which is a `),It=a("a"),Oh=i("WordPiece"),Gh=i(" tokenizer:"),so=f(),c(Bt.$$.fragment),ao=f(),Cs=a("p"),Wh=i("The tokenizer takes care of splitting the sequence into tokens available in the tokenizer vocabulary."),no=f(),c(Ft.$$.fragment),ro=f(),Ds=a("p"),Uh=i(`The tokens are either words or subwords. Here for instance, \u201CVRAM\u201D wasn\u2019t in the model vocabulary, so it\u2019s been split
in \u201CV\u201D, \u201CRA\u201D and \u201CM\u201D. To indicate those tokens are not separate words but parts of the same word, a double-hash prefix
is added for \u201CRA\u201D and \u201CM\u201D:`),oo=f(),c(Lt.$$.fragment),lo=f(),De=a("p"),Vh=i(`These tokens can then be converted into IDs which are understandable by the model. This can be done by directly feeding
the sentence to the tokenizer, which leverages the Rust implementation of `),Ht=a("a"),Xh=i(`\u{1F917}
Tokenizers`),Yh=i(" for peak performance."),io=f(),c(Rt.$$.fragment),ho=f(),Ms=a("p"),Qh=i(`The tokenizer returns a dictionary with all the arguments necessary for its corresponding model to work properly. The
token indices are under the key \u201Cinput_ids\u201D:`),po=f(),c(Ot.$$.fragment),fo=f(),Is=a("p"),Jh=i(`Note that the tokenizer automatically adds \u201Cspecial tokens\u201D (if the associated model relies on them) which are special
IDs the model sometimes uses.`),co=f(),Bs=a("p"),Kh=i("If we decode the previous sequence of ids,"),uo=f(),c(Gt.$$.fragment),mo=f(),Fs=a("p"),Zh=i("we will see"),vo=f(),c(Wt.$$.fragment),bo=f(),Me=a("p"),ep=i("because this is the way a "),Ls=a("a"),tp=i("BertModel"),sp=i(" is going to expect its inputs."),_o=f(),X=a("h2"),Ie=a("a"),pn=a("span"),c(Ut.$$.fragment),ap=f(),fn=a("span"),np=i("L"),wo=f(),Y=a("h3"),Be=a("a"),dn=a("span"),c(Vt.$$.fragment),rp=f(),cn=a("span"),op=i("Labels"),$o=f(),Hs=a("p"),lp=i(`The labels are an optional argument which can be passed in order for the model to compute the loss itself. These labels
should be the expected prediction of the model: it will use the standard loss in order to compute the loss between its
predictions and the expected value (the label).`),go=f(),Rs=a("p"),ip=i("These labels are different according to the model head, for example:"),ko=f(),P=a("ul"),Q=a("li"),hp=i("For sequence classification models (e.g., "),Os=a("a"),pp=i("BertForSequenceClassification"),fp=i(`), the model expects a tensor of dimension
`),un=a("code"),dp=i("(batch_size)"),cp=i(" with each value of the batch corresponding to the expected label of the entire sequence."),up=f(),J=a("li"),mp=i("For token classification models (e.g., "),Gs=a("a"),vp=i("BertForTokenClassification"),bp=i(`), the model expects a tensor of dimension
`),mn=a("code"),_p=i("(batch_size, seq_length)"),wp=i(" with each value corresponding to the expected label of each individual token."),$p=f(),K=a("li"),gp=i("For masked language modeling (e.g., "),Ws=a("a"),kp=i("BertForMaskedLM"),yp=i("), the model expects a tensor of dimension "),vn=a("code"),Ep=i("(batch_size, seq_length)"),qp=i(` with each value corresponding to the expected label of each individual token: the labels being the token
ID for the masked token, and values to be ignored for the rest (usually -100).`),jp=f(),k=a("li"),Ap=i("For sequence to sequence tasks,(e.g., "),Us=a("a"),Pp=i("BartForConditionalGeneration"),Tp=i(", "),Vs=a("a"),xp=i("MBartForConditionalGeneration"),zp=i(`), the model
expects a tensor of dimension `),bn=a("code"),Np=i("(batch_size, tgt_seq_length)"),Sp=i(` with each value corresponding to the target sequences
associated with each input sequence. During training, both `),_n=a("em"),Cp=i("BART"),Dp=i(" and "),wn=a("em"),Mp=i("T5"),Ip=i(` will make the appropriate
`),$n=a("em"),Bp=i("decoder_input_ids"),Fp=i(` and decoder attention masks internally. They usually do not need to be supplied. This does not
apply to models leveraging the Encoder-Decoder framework. See the documentation of each model for more information on
each specific model\u2019s labels.`),yo=f(),Fe=a("p"),Lp=i("The base models (e.g., "),Xs=a("a"),Hp=i("BertModel"),Rp=i(`) do not accept labels, as these are the base transformer models, simply outputting
features.`),Eo=f(),Z=a("h2"),Le=a("a"),gn=a("span"),c(Xt.$$.fragment),Op=f(),kn=a("span"),Gp=i("M"),qo=f(),ee=a("h3"),He=a("a"),yn=a("span"),c(Yt.$$.fragment),Wp=f(),En=a("span"),Up=i("MLM"),jo=f(),Ys=a("p"),Vp=i(`Masked language modeling, a pretraining task where the model sees a corrupted version of the texts, usually done by
masking some tokens randomly, and has to predict the original text.`),Ao=f(),te=a("h3"),Re=a("a"),qn=a("span"),c(Qt.$$.fragment),Xp=f(),jn=a("span"),Yp=i("multimodal"),Po=f(),Qs=a("p"),Qp=i("A task that combines texts with another kind of inputs (for instance images)."),To=f(),se=a("h2"),Oe=a("a"),An=a("span"),c(Jt.$$.fragment),Jp=f(),Pn=a("span"),Kp=i("N"),xo=f(),ae=a("h3"),Ge=a("a"),Tn=a("span"),c(Kt.$$.fragment),Zp=f(),xn=a("span"),ef=i("NLG"),zo=f(),Js=a("p"),tf=i("Natural language generation, all tasks related to generating text (for instance talk with transformers, translation)."),No=f(),ne=a("h3"),We=a("a"),zn=a("span"),c(Zt.$$.fragment),sf=f(),Nn=a("span"),af=i("NLP"),So=f(),Ks=a("p"),nf=i("Natural language processing, a generic way to say \u201Cdeal with texts\u201D."),Co=f(),re=a("h3"),Ue=a("a"),Sn=a("span"),c(es.$$.fragment),rf=f(),Cn=a("span"),of=i("NLU"),Do=f(),Zs=a("p"),lf=i(`Natural language understanding, all tasks related to understanding what is in a text (for instance classifying the
whole text, individual words).`),Mo=f(),oe=a("h2"),Ve=a("a"),Dn=a("span"),c(ts.$$.fragment),hf=f(),Mn=a("span"),pf=i("P"),Io=f(),le=a("h3"),Xe=a("a"),In=a("span"),c(ss.$$.fragment),ff=f(),Bn=a("span"),df=i("Position IDs"),Bo=f(),Ye=a("p"),cf=i(`Contrary to RNNs that have the position of each token embedded within them, transformers are unaware of the position of
each token. Therefore, the position IDs (`),Fn=a("code"),uf=i("position_ids"),mf=i(`) are used by the model to identify each token\u2019s position in the
list of tokens.`),Fo=f(),Qe=a("p"),vf=i("They are an optional parameter. If no "),Ln=a("code"),bf=i("position_ids"),_f=i(` are passed to the model, the IDs are automatically created as
absolute positional embeddings.`),Lo=f(),Je=a("p"),wf=i("Absolute positional embeddings are selected in the range "),Hn=a("code"),$f=i("[0, config.max_position_embeddings - 1]"),gf=i(`. Some models use
other types of positional embeddings, such as sinusoidal position embeddings or relative position embeddings.`),Ho=f(),ie=a("h3"),Ke=a("a"),Rn=a("span"),c(as.$$.fragment),kf=f(),On=a("span"),yf=i("pretrained model"),Ro=f(),ea=a("p"),Ef=i(`A model that has been pretrained on some data (for instance all of Wikipedia). Pretraining methods involve a
self-supervised objective, which can be reading the text and trying to predict the next word (see CLM) or masking some
words and trying to predict them (see MLM).`),Oo=f(),he=a("h2"),Ze=a("a"),Gn=a("span"),c(ns.$$.fragment),qf=f(),Wn=a("span"),jf=i("R"),Go=f(),pe=a("h3"),et=a("a"),Un=a("span"),c(rs.$$.fragment),Af=f(),Vn=a("span"),Pf=i("RNN"),Wo=f(),ta=a("p"),Tf=i("Recurrent neural network, a type of model that uses a loop over a layer to process texts."),Uo=f(),fe=a("h2"),tt=a("a"),Xn=a("span"),c(os.$$.fragment),xf=f(),Yn=a("span"),zf=i("S"),Vo=f(),de=a("h3"),st=a("a"),Qn=a("span"),c(ls.$$.fragment),Nf=f(),Jn=a("span"),Sf=i("self-attention"),Xo=f(),sa=a("p"),Cf=i("Each element of the input finds out which other elements of the input they should attend to."),Yo=f(),ce=a("h3"),at=a("a"),Kn=a("span"),c(is.$$.fragment),Df=f(),Zn=a("span"),Mf=i("seq2seq or sequence-to-sequence"),Qo=f(),T=a("p"),If=i(`Models that generate a new sequence from an input, like translation models, or summarization models (such as
`),aa=a("a"),Bf=i("Bart"),Ff=i(" or "),na=a("a"),Lf=i("T5"),Hf=i(")."),Jo=f(),ue=a("h2"),nt=a("a"),er=a("span"),c(hs.$$.fragment),Rf=f(),tr=a("span"),Of=i("T"),Ko=f(),me=a("h3"),rt=a("a"),sr=a("span"),c(ps.$$.fragment),Gf=f(),ar=a("span"),Wf=i("token"),Zo=f(),ra=a("p"),Uf=i(`A part of a sentence, usually a word, but can also be a subword (non-common words are often split in subwords) or a
punctuation symbol.`),el=f(),ve=a("h3"),ot=a("a"),nr=a("span"),c(fs.$$.fragment),Vf=f(),rr=a("span"),Xf=i("Token Type IDs"),tl=f(),oa=a("p"),Yf=i("Some models\u2019 purpose is to do classification on pairs of sentences or question answering."),sl=f(),c(ds.$$.fragment),al=f(),x=a("p"),Qf=i(`These require two different sequences to be joined in a single \u201Cinput_ids\u201D entry, which usually is performed with the
help of special tokens, such as the classifier (`),or=a("code"),Jf=i("[CLS]"),Kf=i(") and separator ("),lr=a("code"),Zf=i("[SEP]"),ed=i(`) tokens. For example, the BERT model
builds its two sequence input as such:`),nl=f(),c(cs.$$.fragment),rl=f(),lt=a("p"),td=i("We can use our tokenizer to automatically generate such a sentence by passing the two sequences to "),ir=a("code"),sd=i("tokenizer"),ad=i(` as two
arguments (and not a list, like before) like this:`),ol=f(),c(us.$$.fragment),ll=f(),la=a("p"),nd=i("which will return:"),il=f(),c(ms.$$.fragment),hl=f(),ia=a("p"),rd=i(`This is enough for some models to understand where one sequence ends and where another begins. However, other models,
such as BERT, also deploy token type IDs (also called segment IDs). They are represented as a binary mask identifying
the two types of sequence in the model.`),pl=f(),ha=a("p"),od=i("The tokenizer returns this mask as the \u201Ctoken_type_ids\u201D entry:"),fl=f(),c(vs.$$.fragment),dl=f(),z=a("p"),ld=i("The first sequence, the \u201Ccontext\u201D used for the question, has all its tokens represented by a "),hr=a("code"),id=i("0"),hd=i(`, whereas the second
sequence, corresponding to the \u201Cquestion\u201D, has all its tokens represented by a `),pr=a("code"),pd=i("1"),fd=i("."),cl=f(),N=a("p"),dd=i("Some models, like "),pa=a("a"),cd=i("XLNetModel"),ud=i(" use an additional token represented by a "),fr=a("code"),md=i("2"),vd=i("."),ul=f(),be=a("h3"),it=a("a"),dr=a("span"),c(bs.$$.fragment),bd=f(),cr=a("span"),_d=i("transformer"),ml=f(),fa=a("p"),wd=i("Self-attention based deep learning model architecture."),this.h()},l(e){const o=Zm('[data-svelte="svelte-1phssyn"]',document.head);S=n(o,"META",{name:!0,content:!0}),o.forEach(t),ur=d(e),C=n(e,"H1",{class:!0});var bl=r(C);_e=n(bl,"A",{id:!0,class:!0,href:!0});var Ed=r(_e);wa=n(Ed,"SPAN",{});var qd=r(wa);u(ct.$$.fragment,qd),qd.forEach(t),Ed.forEach(t),ii=d(bl),$a=n(bl,"SPAN",{});var jd=r($a);hi=h(jd,"Glossary"),jd.forEach(t),bl.forEach(t),mr=d(e),_s=n(e,"P",{});var Ad=r(_s);pi=h(Ad,`This glossary defines general machine learning and \u{1F917} Transformers terms to help you better understand the
documentation.`),Ad.forEach(t),vr=d(e),D=n(e,"H2",{class:!0});var _l=r(D);we=n(_l,"A",{id:!0,class:!0,href:!0});var Pd=r(we);ga=n(Pd,"SPAN",{});var Td=r(ga);u(ut.$$.fragment,Td),Td.forEach(t),Pd.forEach(t),fi=d(_l),ka=n(_l,"SPAN",{});var xd=r(ka);di=h(xd,"A"),xd.forEach(t),_l.forEach(t),br=d(e),M=n(e,"H3",{class:!0});var wl=r(M);$e=n(wl,"A",{id:!0,class:!0,href:!0});var zd=r($e);ya=n(zd,"SPAN",{});var Nd=r(ya);u(mt.$$.fragment,Nd),Nd.forEach(t),zd.forEach(t),ci=d(wl),Ea=n(wl,"SPAN",{});var Sd=r(Ea);ui=h(Sd,"Attention mask"),Sd.forEach(t),wl.forEach(t),_r=d(e),ws=n(e,"P",{});var Cd=r(ws);mi=h(Cd,"The attention mask is an optional argument used when batching sequences together."),Cd.forEach(t),wr=d(e),u(vt.$$.fragment,e),$r=d(e),$s=n(e,"P",{});var Dd=r($s);vi=h(Dd,"This argument indicates to the model which tokens should be attended to, and which should not."),Dd.forEach(t),gr=d(e),gs=n(e,"P",{});var Md=r(gs);bi=h(Md,"For example, consider these two sequences:"),Md.forEach(t),kr=d(e),u(bt.$$.fragment,e),yr=d(e),ks=n(e,"P",{});var Id=r(ks);_i=h(Id,"The encoded versions have different lengths:"),Id.forEach(t),Er=d(e),u(_t.$$.fragment,e),qr=d(e),ys=n(e,"P",{});var Bd=r(ys);wi=h(Bd,`Therefore, we can\u2019t put them together in the same tensor as-is. The first sequence needs to be padded up to the length
of the second one, or the second one needs to be truncated down to the length of the first one.`),Bd.forEach(t),jr=d(e),Es=n(e,"P",{});var Fd=r(Es);$i=h(Fd,`In the first case, the list of IDs will be extended by the padding indices. We can pass a list to the tokenizer and ask
it to pad like this:`),Fd.forEach(t),Ar=d(e),u(wt.$$.fragment,e),Pr=d(e),qs=n(e,"P",{});var Ld=r(qs);gi=h(Ld,"We can see that 0s have been added on the right of the first sentence to make it the same length as the second one:"),Ld.forEach(t),Tr=d(e),u($t.$$.fragment,e),xr=d(e),q=n(e,"P",{});var ht=r(q);ki=h(ht,`This can then be converted into a tensor in PyTorch or TensorFlow. The attention mask is a binary tensor indicating the
position of the padded indices so that the model does not attend to them. For the `),js=n(ht,"A",{href:!0});var Hd=r(js);yi=h(Hd,"BertTokenizer"),Hd.forEach(t),Ei=h(ht,", "),qa=n(ht,"CODE",{});var Rd=r(qa);qi=h(Rd,"1"),Rd.forEach(t),ji=h(ht,` indicates a
value that should be attended to, while `),ja=n(ht,"CODE",{});var Od=r(ja);Ai=h(Od,"0"),Od.forEach(t),Pi=h(ht,` indicates a padded value. This attention mask is in the dictionary returned
by the tokenizer under the key \u201Cattention_mask\u201D:`),ht.forEach(t),zr=d(e),u(gt.$$.fragment,e),Nr=d(e),I=n(e,"H3",{class:!0});var $l=r(I);ge=n($l,"A",{id:!0,class:!0,href:!0});var Gd=r(ge);Aa=n(Gd,"SPAN",{});var Wd=r(Aa);u(kt.$$.fragment,Wd),Wd.forEach(t),Gd.forEach(t),Ti=d($l),Pa=n($l,"SPAN",{});var Ud=r(Pa);xi=h(Ud,"autoencoding models"),Ud.forEach(t),$l.forEach(t),Sr=d(e),yt=n(e,"P",{});var $d=r(yt);zi=h($d,"see "),As=n($d,"A",{href:!0});var Vd=r(As);Ni=h(Vd,"MLM"),Vd.forEach(t),$d.forEach(t),Cr=d(e),B=n(e,"H3",{class:!0});var gl=r(B);ke=n(gl,"A",{id:!0,class:!0,href:!0});var Xd=r(ke);Ta=n(Xd,"SPAN",{});var Yd=r(Ta);u(Et.$$.fragment,Yd),Yd.forEach(t),Xd.forEach(t),Si=d(gl),xa=n(gl,"SPAN",{});var Qd=r(xa);Ci=h(Qd,"autoregressive models"),Qd.forEach(t),gl.forEach(t),Dr=d(e),qt=n(e,"P",{});var gd=r(qt);Di=h(gd,"see "),Ps=n(gd,"A",{href:!0});var Jd=r(Ps);Mi=h(Jd,"CLM"),Jd.forEach(t),gd.forEach(t),Mr=d(e),F=n(e,"H2",{class:!0});var kl=r(F);ye=n(kl,"A",{id:!0,class:!0,href:!0});var Kd=r(ye);za=n(Kd,"SPAN",{});var Zd=r(za);u(jt.$$.fragment,Zd),Zd.forEach(t),Kd.forEach(t),Ii=d(kl),Na=n(kl,"SPAN",{});var ec=r(Na);Bi=h(ec,"C"),ec.forEach(t),kl.forEach(t),Ir=d(e),L=n(e,"H3",{class:!0});var yl=r(L);Ee=n(yl,"A",{id:!0,class:!0,href:!0});var tc=r(Ee);Sa=n(tc,"SPAN",{});var sc=r(Sa);u(At.$$.fragment,sc),sc.forEach(t),tc.forEach(t),Fi=d(yl),Ca=n(yl,"SPAN",{});var ac=r(Ca);Li=h(ac,"CLM"),ac.forEach(t),yl.forEach(t),Br=d(e),Ts=n(e,"P",{});var nc=r(Ts);Hi=h(nc,`Causal language modeling, a pretraining task where the model reads the texts in order and has to predict the next word.
It\u2019s usually done by reading the whole sentence but using a mask inside the model to hide the future tokens at a
certain timestep.`),nc.forEach(t),Fr=d(e),H=n(e,"H2",{class:!0});var El=r(H);qe=n(El,"A",{id:!0,class:!0,href:!0});var rc=r(qe);Da=n(rc,"SPAN",{});var oc=r(Da);u(Pt.$$.fragment,oc),oc.forEach(t),rc.forEach(t),Ri=d(El),Ma=n(El,"SPAN",{});var lc=r(Ma);Oi=h(lc,"D"),lc.forEach(t),El.forEach(t),Lr=d(e),R=n(e,"H3",{class:!0});var ql=r(R);je=n(ql,"A",{id:!0,class:!0,href:!0});var ic=r(je);Ia=n(ic,"SPAN",{});var hc=r(Ia);u(Tt.$$.fragment,hc),hc.forEach(t),ic.forEach(t),Gi=d(ql),Ba=n(ql,"SPAN",{});var pc=r(Ba);Wi=h(pc,"Decoder input IDs"),pc.forEach(t),ql.forEach(t),Hr=d(e),xs=n(e,"P",{});var fc=r(xs);Ui=h(fc,`This input is specific to encoder-decoder models, and contains the input IDs that will be fed to the decoder. These
inputs should be used for sequence to sequence tasks, such as translation or summarization, and are usually built in a
way specific to each model.`),fc.forEach(t),Rr=d(e),j=n(e,"P",{});var pt=r(j);Vi=h(pt,"Most encoder-decoder models (BART, T5) create their "),Fa=n(pt,"CODE",{});var dc=r(Fa);Xi=h(dc,"decoder_input_ids"),dc.forEach(t),Yi=h(pt," on their own from the "),La=n(pt,"CODE",{});var cc=r(La);Qi=h(cc,"labels"),cc.forEach(t),Ji=h(pt,`. In such models,
passing the `),Ha=n(pt,"CODE",{});var uc=r(Ha);Ki=h(uc,"labels"),uc.forEach(t),Zi=h(pt," is the preferred way to handle training."),pt.forEach(t),Or=d(e),zs=n(e,"P",{});var mc=r(zs);eh=h(mc,"Please check each model\u2019s docs to see how they handle these input IDs for sequence to sequence training."),mc.forEach(t),Gr=d(e),O=n(e,"H3",{class:!0});var jl=r(O);Ae=n(jl,"A",{id:!0,class:!0,href:!0});var vc=r(Ae);Ra=n(vc,"SPAN",{});var bc=r(Ra);u(xt.$$.fragment,bc),bc.forEach(t),vc.forEach(t),th=d(jl),Oa=n(jl,"SPAN",{});var _c=r(Oa);sh=h(_c,"deep learning"),_c.forEach(t),jl.forEach(t),Wr=d(e),Ns=n(e,"P",{});var wc=r(Ns);ah=h(wc,"Machine learning algorithms which uses neural networks with several layers."),wc.forEach(t),Ur=d(e),G=n(e,"H2",{class:!0});var Al=r(G);Pe=n(Al,"A",{id:!0,class:!0,href:!0});var $c=r(Pe);Ga=n($c,"SPAN",{});var gc=r(Ga);u(zt.$$.fragment,gc),gc.forEach(t),$c.forEach(t),nh=d(Al),Wa=n(Al,"SPAN",{});var kc=r(Wa);rh=h(kc,"F"),kc.forEach(t),Al.forEach(t),Vr=d(e),W=n(e,"H3",{class:!0});var Pl=r(W);Te=n(Pl,"A",{id:!0,class:!0,href:!0});var yc=r(Te);Ua=n(yc,"SPAN",{});var Ec=r(Ua);u(Nt.$$.fragment,Ec),Ec.forEach(t),yc.forEach(t),oh=d(Pl),Va=n(Pl,"SPAN",{});var qc=r(Va);lh=h(qc,"Feed Forward Chunking"),qc.forEach(t),Pl.forEach(t),Xr=d(e),xe=n(e,"P",{});var Tl=r(xe);ih=h(Tl,`In each residual attention block in transformers the self-attention layer is usually followed by 2 feed forward layers.
The intermediate embedding size of the feed forward layers is often bigger than the hidden size of the model (e.g., for
`),Xa=n(Tl,"CODE",{});var jc=r(Xa);hh=h(jc,"bert-base-uncased"),jc.forEach(t),ph=h(Tl,")."),Tl.forEach(t),Yr=d(e),$=n(e,"P",{});var g=r($);fh=h(g,"For an input of size "),Ya=n(g,"CODE",{});var Ac=r(Ya);dh=h(Ac,"[batch_size, sequence_length]"),Ac.forEach(t),ch=h(g,`, the memory required to store the intermediate feed forward
embeddings `),Qa=n(g,"CODE",{});var Pc=r(Qa);uh=h(Pc,"[batch_size, sequence_length, config.intermediate_size]"),Pc.forEach(t),mh=h(g,` can account for a large fraction of the memory
use. The authors of `),St=n(g,"A",{href:!0,rel:!0});var Tc=r(St);vh=h(Tc,"Reformer: The Efficient Transformer"),Tc.forEach(t),bh=h(g,` noticed that since the
computation is independent of the `),Ja=n(g,"CODE",{});var xc=r(Ja);_h=h(xc,"sequence_length"),xc.forEach(t),wh=h(g,` dimension, it is mathematically equivalent to compute the output
embeddings of both feed forward layers `),Ka=n(g,"CODE",{});var zc=r(Ka);$h=h(zc,"[batch_size, config.hidden_size]_0, ..., [batch_size, config.hidden_size]_n"),zc.forEach(t),gh=h(g,`
individually and concat them afterward to `),Za=n(g,"CODE",{});var Nc=r(Za);kh=h(Nc,"[batch_size, sequence_length, config.hidden_size]"),Nc.forEach(t),yh=h(g," with "),en=n(g,"CODE",{});var Sc=r(en);Eh=h(Sc,"n = sequence_length"),Sc.forEach(t),qh=h(g,`, which trades increased computation time against reduced memory use, but yields a mathematically
`),tn=n(g,"STRONG",{});var Cc=r(tn);jh=h(Cc,"equivalent"),Cc.forEach(t),Ah=h(g," result."),g.forEach(t),Qr=d(e),A=n(e,"P",{});var ft=r(A);Ph=h(ft,"For models employing the function "),Ss=n(ft,"A",{href:!0});var Dc=r(Ss);Th=h(Dc,"apply_chunking_to_forward()"),Dc.forEach(t),xh=h(ft,", the "),sn=n(ft,"CODE",{});var Mc=r(sn);zh=h(Mc,"chunk_size"),Mc.forEach(t),Nh=h(ft,` defines the number of output
embeddings that are computed in parallel and thus defines the trade-off between memory and time complexity. If
`),an=n(ft,"CODE",{});var Ic=r(an);Sh=h(Ic,"chunk_size"),Ic.forEach(t),Ch=h(ft," is set to 0, no feed forward chunking is done."),ft.forEach(t),Jr=d(e),U=n(e,"H2",{class:!0});var xl=r(U);ze=n(xl,"A",{id:!0,class:!0,href:!0});var Bc=r(ze);nn=n(Bc,"SPAN",{});var Fc=r(nn);u(Ct.$$.fragment,Fc),Fc.forEach(t),Bc.forEach(t),Dh=d(xl),rn=n(xl,"SPAN",{});var Lc=r(rn);Mh=h(Lc,"I"),Lc.forEach(t),xl.forEach(t),Kr=d(e),V=n(e,"H3",{class:!0});var zl=r(V);Ne=n(zl,"A",{id:!0,class:!0,href:!0});var Hc=r(Ne);on=n(Hc,"SPAN",{});var Rc=r(on);u(Dt.$$.fragment,Rc),Rc.forEach(t),Hc.forEach(t),Ih=d(zl),ln=n(zl,"SPAN",{});var Oc=r(ln);Bh=h(Oc,"Input IDs"),Oc.forEach(t),zl.forEach(t),Zr=d(e),Se=n(e,"P",{});var Nl=r(Se);Fh=h(Nl,"The input ids are often the only required parameters to be passed to the model as input. "),hn=n(Nl,"EM",{});var Gc=r(hn);Lh=h(Gc,`They are token indices,
numerical representations of tokens building the sequences that will be used as input by the model`),Gc.forEach(t),Hh=h(Nl,"."),Nl.forEach(t),eo=d(e),u(Mt.$$.fragment,e),to=d(e),Ce=n(e,"P",{});var Sl=r(Ce);Rh=h(Sl,`Each tokenizer works differently but the underlying mechanism remains the same. Here\u2019s an example using the BERT
tokenizer, which is a `),It=n(Sl,"A",{href:!0,rel:!0});var Wc=r(It);Oh=h(Wc,"WordPiece"),Wc.forEach(t),Gh=h(Sl," tokenizer:"),Sl.forEach(t),so=d(e),u(Bt.$$.fragment,e),ao=d(e),Cs=n(e,"P",{});var Uc=r(Cs);Wh=h(Uc,"The tokenizer takes care of splitting the sequence into tokens available in the tokenizer vocabulary."),Uc.forEach(t),no=d(e),u(Ft.$$.fragment,e),ro=d(e),Ds=n(e,"P",{});var Vc=r(Ds);Uh=h(Vc,`The tokens are either words or subwords. Here for instance, \u201CVRAM\u201D wasn\u2019t in the model vocabulary, so it\u2019s been split
in \u201CV\u201D, \u201CRA\u201D and \u201CM\u201D. To indicate those tokens are not separate words but parts of the same word, a double-hash prefix
is added for \u201CRA\u201D and \u201CM\u201D:`),Vc.forEach(t),oo=d(e),u(Lt.$$.fragment,e),lo=d(e),De=n(e,"P",{});var Cl=r(De);Vh=h(Cl,`These tokens can then be converted into IDs which are understandable by the model. This can be done by directly feeding
the sentence to the tokenizer, which leverages the Rust implementation of `),Ht=n(Cl,"A",{href:!0,rel:!0});var Xc=r(Ht);Xh=h(Xc,`\u{1F917}
Tokenizers`),Xc.forEach(t),Yh=h(Cl," for peak performance."),Cl.forEach(t),io=d(e),u(Rt.$$.fragment,e),ho=d(e),Ms=n(e,"P",{});var Yc=r(Ms);Qh=h(Yc,`The tokenizer returns a dictionary with all the arguments necessary for its corresponding model to work properly. The
token indices are under the key \u201Cinput_ids\u201D:`),Yc.forEach(t),po=d(e),u(Ot.$$.fragment,e),fo=d(e),Is=n(e,"P",{});var Qc=r(Is);Jh=h(Qc,`Note that the tokenizer automatically adds \u201Cspecial tokens\u201D (if the associated model relies on them) which are special
IDs the model sometimes uses.`),Qc.forEach(t),co=d(e),Bs=n(e,"P",{});var Jc=r(Bs);Kh=h(Jc,"If we decode the previous sequence of ids,"),Jc.forEach(t),uo=d(e),u(Gt.$$.fragment,e),mo=d(e),Fs=n(e,"P",{});var Kc=r(Fs);Zh=h(Kc,"we will see"),Kc.forEach(t),vo=d(e),u(Wt.$$.fragment,e),bo=d(e),Me=n(e,"P",{});var Dl=r(Me);ep=h(Dl,"because this is the way a "),Ls=n(Dl,"A",{href:!0});var Zc=r(Ls);tp=h(Zc,"BertModel"),Zc.forEach(t),sp=h(Dl," is going to expect its inputs."),Dl.forEach(t),_o=d(e),X=n(e,"H2",{class:!0});var Ml=r(X);Ie=n(Ml,"A",{id:!0,class:!0,href:!0});var eu=r(Ie);pn=n(eu,"SPAN",{});var tu=r(pn);u(Ut.$$.fragment,tu),tu.forEach(t),eu.forEach(t),ap=d(Ml),fn=n(Ml,"SPAN",{});var su=r(fn);np=h(su,"L"),su.forEach(t),Ml.forEach(t),wo=d(e),Y=n(e,"H3",{class:!0});var Il=r(Y);Be=n(Il,"A",{id:!0,class:!0,href:!0});var au=r(Be);dn=n(au,"SPAN",{});var nu=r(dn);u(Vt.$$.fragment,nu),nu.forEach(t),au.forEach(t),rp=d(Il),cn=n(Il,"SPAN",{});var ru=r(cn);op=h(ru,"Labels"),ru.forEach(t),Il.forEach(t),$o=d(e),Hs=n(e,"P",{});var ou=r(Hs);lp=h(ou,`The labels are an optional argument which can be passed in order for the model to compute the loss itself. These labels
should be the expected prediction of the model: it will use the standard loss in order to compute the loss between its
predictions and the expected value (the label).`),ou.forEach(t),go=d(e),Rs=n(e,"P",{});var lu=r(Rs);ip=h(lu,"These labels are different according to the model head, for example:"),lu.forEach(t),ko=d(e),P=n(e,"UL",{});var dt=r(P);Q=n(dt,"LI",{});var da=r(Q);hp=h(da,"For sequence classification models (e.g., "),Os=n(da,"A",{href:!0});var iu=r(Os);pp=h(iu,"BertForSequenceClassification"),iu.forEach(t),fp=h(da,`), the model expects a tensor of dimension
`),un=n(da,"CODE",{});var hu=r(un);dp=h(hu,"(batch_size)"),hu.forEach(t),cp=h(da," with each value of the batch corresponding to the expected label of the entire sequence."),da.forEach(t),up=d(dt),J=n(dt,"LI",{});var ca=r(J);mp=h(ca,"For token classification models (e.g., "),Gs=n(ca,"A",{href:!0});var pu=r(Gs);vp=h(pu,"BertForTokenClassification"),pu.forEach(t),bp=h(ca,`), the model expects a tensor of dimension
`),mn=n(ca,"CODE",{});var fu=r(mn);_p=h(fu,"(batch_size, seq_length)"),fu.forEach(t),wp=h(ca," with each value corresponding to the expected label of each individual token."),ca.forEach(t),$p=d(dt),K=n(dt,"LI",{});var ua=r(K);gp=h(ua,"For masked language modeling (e.g., "),Ws=n(ua,"A",{href:!0});var du=r(Ws);kp=h(du,"BertForMaskedLM"),du.forEach(t),yp=h(ua,"), the model expects a tensor of dimension "),vn=n(ua,"CODE",{});var cu=r(vn);Ep=h(cu,"(batch_size, seq_length)"),cu.forEach(t),qp=h(ua,` with each value corresponding to the expected label of each individual token: the labels being the token
ID for the masked token, and values to be ignored for the rest (usually -100).`),ua.forEach(t),jp=d(dt),k=n(dt,"LI",{});var E=r(k);Ap=h(E,"For sequence to sequence tasks,(e.g., "),Us=n(E,"A",{href:!0});var uu=r(Us);Pp=h(uu,"BartForConditionalGeneration"),uu.forEach(t),Tp=h(E,", "),Vs=n(E,"A",{href:!0});var mu=r(Vs);xp=h(mu,"MBartForConditionalGeneration"),mu.forEach(t),zp=h(E,`), the model
expects a tensor of dimension `),bn=n(E,"CODE",{});var vu=r(bn);Np=h(vu,"(batch_size, tgt_seq_length)"),vu.forEach(t),Sp=h(E,` with each value corresponding to the target sequences
associated with each input sequence. During training, both `),_n=n(E,"EM",{});var bu=r(_n);Cp=h(bu,"BART"),bu.forEach(t),Dp=h(E," and "),wn=n(E,"EM",{});var _u=r(wn);Mp=h(_u,"T5"),_u.forEach(t),Ip=h(E,` will make the appropriate
`),$n=n(E,"EM",{});var wu=r($n);Bp=h(wu,"decoder_input_ids"),wu.forEach(t),Fp=h(E,` and decoder attention masks internally. They usually do not need to be supplied. This does not
apply to models leveraging the Encoder-Decoder framework. See the documentation of each model for more information on
each specific model\u2019s labels.`),E.forEach(t),dt.forEach(t),yo=d(e),Fe=n(e,"P",{});var Bl=r(Fe);Lp=h(Bl,"The base models (e.g., "),Xs=n(Bl,"A",{href:!0});var $u=r(Xs);Hp=h($u,"BertModel"),$u.forEach(t),Rp=h(Bl,`) do not accept labels, as these are the base transformer models, simply outputting
features.`),Bl.forEach(t),Eo=d(e),Z=n(e,"H2",{class:!0});var Fl=r(Z);Le=n(Fl,"A",{id:!0,class:!0,href:!0});var gu=r(Le);gn=n(gu,"SPAN",{});var ku=r(gn);u(Xt.$$.fragment,ku),ku.forEach(t),gu.forEach(t),Op=d(Fl),kn=n(Fl,"SPAN",{});var yu=r(kn);Gp=h(yu,"M"),yu.forEach(t),Fl.forEach(t),qo=d(e),ee=n(e,"H3",{class:!0});var Ll=r(ee);He=n(Ll,"A",{id:!0,class:!0,href:!0});var Eu=r(He);yn=n(Eu,"SPAN",{});var qu=r(yn);u(Yt.$$.fragment,qu),qu.forEach(t),Eu.forEach(t),Wp=d(Ll),En=n(Ll,"SPAN",{});var ju=r(En);Up=h(ju,"MLM"),ju.forEach(t),Ll.forEach(t),jo=d(e),Ys=n(e,"P",{});var Au=r(Ys);Vp=h(Au,`Masked language modeling, a pretraining task where the model sees a corrupted version of the texts, usually done by
masking some tokens randomly, and has to predict the original text.`),Au.forEach(t),Ao=d(e),te=n(e,"H3",{class:!0});var Hl=r(te);Re=n(Hl,"A",{id:!0,class:!0,href:!0});var Pu=r(Re);qn=n(Pu,"SPAN",{});var Tu=r(qn);u(Qt.$$.fragment,Tu),Tu.forEach(t),Pu.forEach(t),Xp=d(Hl),jn=n(Hl,"SPAN",{});var xu=r(jn);Yp=h(xu,"multimodal"),xu.forEach(t),Hl.forEach(t),Po=d(e),Qs=n(e,"P",{});var zu=r(Qs);Qp=h(zu,"A task that combines texts with another kind of inputs (for instance images)."),zu.forEach(t),To=d(e),se=n(e,"H2",{class:!0});var Rl=r(se);Oe=n(Rl,"A",{id:!0,class:!0,href:!0});var Nu=r(Oe);An=n(Nu,"SPAN",{});var Su=r(An);u(Jt.$$.fragment,Su),Su.forEach(t),Nu.forEach(t),Jp=d(Rl),Pn=n(Rl,"SPAN",{});var Cu=r(Pn);Kp=h(Cu,"N"),Cu.forEach(t),Rl.forEach(t),xo=d(e),ae=n(e,"H3",{class:!0});var Ol=r(ae);Ge=n(Ol,"A",{id:!0,class:!0,href:!0});var Du=r(Ge);Tn=n(Du,"SPAN",{});var Mu=r(Tn);u(Kt.$$.fragment,Mu),Mu.forEach(t),Du.forEach(t),Zp=d(Ol),xn=n(Ol,"SPAN",{});var Iu=r(xn);ef=h(Iu,"NLG"),Iu.forEach(t),Ol.forEach(t),zo=d(e),Js=n(e,"P",{});var Bu=r(Js);tf=h(Bu,"Natural language generation, all tasks related to generating text (for instance talk with transformers, translation)."),Bu.forEach(t),No=d(e),ne=n(e,"H3",{class:!0});var Gl=r(ne);We=n(Gl,"A",{id:!0,class:!0,href:!0});var Fu=r(We);zn=n(Fu,"SPAN",{});var Lu=r(zn);u(Zt.$$.fragment,Lu),Lu.forEach(t),Fu.forEach(t),sf=d(Gl),Nn=n(Gl,"SPAN",{});var Hu=r(Nn);af=h(Hu,"NLP"),Hu.forEach(t),Gl.forEach(t),So=d(e),Ks=n(e,"P",{});var Ru=r(Ks);nf=h(Ru,"Natural language processing, a generic way to say \u201Cdeal with texts\u201D."),Ru.forEach(t),Co=d(e),re=n(e,"H3",{class:!0});var Wl=r(re);Ue=n(Wl,"A",{id:!0,class:!0,href:!0});var Ou=r(Ue);Sn=n(Ou,"SPAN",{});var Gu=r(Sn);u(es.$$.fragment,Gu),Gu.forEach(t),Ou.forEach(t),rf=d(Wl),Cn=n(Wl,"SPAN",{});var Wu=r(Cn);of=h(Wu,"NLU"),Wu.forEach(t),Wl.forEach(t),Do=d(e),Zs=n(e,"P",{});var Uu=r(Zs);lf=h(Uu,`Natural language understanding, all tasks related to understanding what is in a text (for instance classifying the
whole text, individual words).`),Uu.forEach(t),Mo=d(e),oe=n(e,"H2",{class:!0});var Ul=r(oe);Ve=n(Ul,"A",{id:!0,class:!0,href:!0});var Vu=r(Ve);Dn=n(Vu,"SPAN",{});var Xu=r(Dn);u(ts.$$.fragment,Xu),Xu.forEach(t),Vu.forEach(t),hf=d(Ul),Mn=n(Ul,"SPAN",{});var Yu=r(Mn);pf=h(Yu,"P"),Yu.forEach(t),Ul.forEach(t),Io=d(e),le=n(e,"H3",{class:!0});var Vl=r(le);Xe=n(Vl,"A",{id:!0,class:!0,href:!0});var Qu=r(Xe);In=n(Qu,"SPAN",{});var Ju=r(In);u(ss.$$.fragment,Ju),Ju.forEach(t),Qu.forEach(t),ff=d(Vl),Bn=n(Vl,"SPAN",{});var Ku=r(Bn);df=h(Ku,"Position IDs"),Ku.forEach(t),Vl.forEach(t),Bo=d(e),Ye=n(e,"P",{});var Xl=r(Ye);cf=h(Xl,`Contrary to RNNs that have the position of each token embedded within them, transformers are unaware of the position of
each token. Therefore, the position IDs (`),Fn=n(Xl,"CODE",{});var Zu=r(Fn);uf=h(Zu,"position_ids"),Zu.forEach(t),mf=h(Xl,`) are used by the model to identify each token\u2019s position in the
list of tokens.`),Xl.forEach(t),Fo=d(e),Qe=n(e,"P",{});var Yl=r(Qe);vf=h(Yl,"They are an optional parameter. If no "),Ln=n(Yl,"CODE",{});var em=r(Ln);bf=h(em,"position_ids"),em.forEach(t),_f=h(Yl,` are passed to the model, the IDs are automatically created as
absolute positional embeddings.`),Yl.forEach(t),Lo=d(e),Je=n(e,"P",{});var Ql=r(Je);wf=h(Ql,"Absolute positional embeddings are selected in the range "),Hn=n(Ql,"CODE",{});var tm=r(Hn);$f=h(tm,"[0, config.max_position_embeddings - 1]"),tm.forEach(t),gf=h(Ql,`. Some models use
other types of positional embeddings, such as sinusoidal position embeddings or relative position embeddings.`),Ql.forEach(t),Ho=d(e),ie=n(e,"H3",{class:!0});var Jl=r(ie);Ke=n(Jl,"A",{id:!0,class:!0,href:!0});var sm=r(Ke);Rn=n(sm,"SPAN",{});var am=r(Rn);u(as.$$.fragment,am),am.forEach(t),sm.forEach(t),kf=d(Jl),On=n(Jl,"SPAN",{});var nm=r(On);yf=h(nm,"pretrained model"),nm.forEach(t),Jl.forEach(t),Ro=d(e),ea=n(e,"P",{});var rm=r(ea);Ef=h(rm,`A model that has been pretrained on some data (for instance all of Wikipedia). Pretraining methods involve a
self-supervised objective, which can be reading the text and trying to predict the next word (see CLM) or masking some
words and trying to predict them (see MLM).`),rm.forEach(t),Oo=d(e),he=n(e,"H2",{class:!0});var Kl=r(he);Ze=n(Kl,"A",{id:!0,class:!0,href:!0});var om=r(Ze);Gn=n(om,"SPAN",{});var lm=r(Gn);u(ns.$$.fragment,lm),lm.forEach(t),om.forEach(t),qf=d(Kl),Wn=n(Kl,"SPAN",{});var im=r(Wn);jf=h(im,"R"),im.forEach(t),Kl.forEach(t),Go=d(e),pe=n(e,"H3",{class:!0});var Zl=r(pe);et=n(Zl,"A",{id:!0,class:!0,href:!0});var hm=r(et);Un=n(hm,"SPAN",{});var pm=r(Un);u(rs.$$.fragment,pm),pm.forEach(t),hm.forEach(t),Af=d(Zl),Vn=n(Zl,"SPAN",{});var fm=r(Vn);Pf=h(fm,"RNN"),fm.forEach(t),Zl.forEach(t),Wo=d(e),ta=n(e,"P",{});var dm=r(ta);Tf=h(dm,"Recurrent neural network, a type of model that uses a loop over a layer to process texts."),dm.forEach(t),Uo=d(e),fe=n(e,"H2",{class:!0});var ei=r(fe);tt=n(ei,"A",{id:!0,class:!0,href:!0});var cm=r(tt);Xn=n(cm,"SPAN",{});var um=r(Xn);u(os.$$.fragment,um),um.forEach(t),cm.forEach(t),xf=d(ei),Yn=n(ei,"SPAN",{});var mm=r(Yn);zf=h(mm,"S"),mm.forEach(t),ei.forEach(t),Vo=d(e),de=n(e,"H3",{class:!0});var ti=r(de);st=n(ti,"A",{id:!0,class:!0,href:!0});var vm=r(st);Qn=n(vm,"SPAN",{});var bm=r(Qn);u(ls.$$.fragment,bm),bm.forEach(t),vm.forEach(t),Nf=d(ti),Jn=n(ti,"SPAN",{});var _m=r(Jn);Sf=h(_m,"self-attention"),_m.forEach(t),ti.forEach(t),Xo=d(e),sa=n(e,"P",{});var wm=r(sa);Cf=h(wm,"Each element of the input finds out which other elements of the input they should attend to."),wm.forEach(t),Yo=d(e),ce=n(e,"H3",{class:!0});var si=r(ce);at=n(si,"A",{id:!0,class:!0,href:!0});var $m=r(at);Kn=n($m,"SPAN",{});var gm=r(Kn);u(is.$$.fragment,gm),gm.forEach(t),$m.forEach(t),Df=d(si),Zn=n(si,"SPAN",{});var km=r(Zn);Mf=h(km,"seq2seq or sequence-to-sequence"),km.forEach(t),si.forEach(t),Qo=d(e),T=n(e,"P",{});var ma=r(T);If=h(ma,`Models that generate a new sequence from an input, like translation models, or summarization models (such as
`),aa=n(ma,"A",{href:!0});var ym=r(aa);Bf=h(ym,"Bart"),ym.forEach(t),Ff=h(ma," or "),na=n(ma,"A",{href:!0});var Em=r(na);Lf=h(Em,"T5"),Em.forEach(t),Hf=h(ma,")."),ma.forEach(t),Jo=d(e),ue=n(e,"H2",{class:!0});var ai=r(ue);nt=n(ai,"A",{id:!0,class:!0,href:!0});var qm=r(nt);er=n(qm,"SPAN",{});var jm=r(er);u(hs.$$.fragment,jm),jm.forEach(t),qm.forEach(t),Rf=d(ai),tr=n(ai,"SPAN",{});var Am=r(tr);Of=h(Am,"T"),Am.forEach(t),ai.forEach(t),Ko=d(e),me=n(e,"H3",{class:!0});var ni=r(me);rt=n(ni,"A",{id:!0,class:!0,href:!0});var Pm=r(rt);sr=n(Pm,"SPAN",{});var Tm=r(sr);u(ps.$$.fragment,Tm),Tm.forEach(t),Pm.forEach(t),Gf=d(ni),ar=n(ni,"SPAN",{});var xm=r(ar);Wf=h(xm,"token"),xm.forEach(t),ni.forEach(t),Zo=d(e),ra=n(e,"P",{});var zm=r(ra);Uf=h(zm,`A part of a sentence, usually a word, but can also be a subword (non-common words are often split in subwords) or a
punctuation symbol.`),zm.forEach(t),el=d(e),ve=n(e,"H3",{class:!0});var ri=r(ve);ot=n(ri,"A",{id:!0,class:!0,href:!0});var Nm=r(ot);nr=n(Nm,"SPAN",{});var Sm=r(nr);u(fs.$$.fragment,Sm),Sm.forEach(t),Nm.forEach(t),Vf=d(ri),rr=n(ri,"SPAN",{});var Cm=r(rr);Xf=h(Cm,"Token Type IDs"),Cm.forEach(t),ri.forEach(t),tl=d(e),oa=n(e,"P",{});var Dm=r(oa);Yf=h(Dm,"Some models\u2019 purpose is to do classification on pairs of sentences or question answering."),Dm.forEach(t),sl=d(e),u(ds.$$.fragment,e),al=d(e),x=n(e,"P",{});var va=r(x);Qf=h(va,`These require two different sequences to be joined in a single \u201Cinput_ids\u201D entry, which usually is performed with the
help of special tokens, such as the classifier (`),or=n(va,"CODE",{});var Mm=r(or);Jf=h(Mm,"[CLS]"),Mm.forEach(t),Kf=h(va,") and separator ("),lr=n(va,"CODE",{});var Im=r(lr);Zf=h(Im,"[SEP]"),Im.forEach(t),ed=h(va,`) tokens. For example, the BERT model
builds its two sequence input as such:`),va.forEach(t),nl=d(e),u(cs.$$.fragment,e),rl=d(e),lt=n(e,"P",{});var oi=r(lt);td=h(oi,"We can use our tokenizer to automatically generate such a sentence by passing the two sequences to "),ir=n(oi,"CODE",{});var Bm=r(ir);sd=h(Bm,"tokenizer"),Bm.forEach(t),ad=h(oi,` as two
arguments (and not a list, like before) like this:`),oi.forEach(t),ol=d(e),u(us.$$.fragment,e),ll=d(e),la=n(e,"P",{});var Fm=r(la);nd=h(Fm,"which will return:"),Fm.forEach(t),il=d(e),u(ms.$$.fragment,e),hl=d(e),ia=n(e,"P",{});var Lm=r(ia);rd=h(Lm,`This is enough for some models to understand where one sequence ends and where another begins. However, other models,
such as BERT, also deploy token type IDs (also called segment IDs). They are represented as a binary mask identifying
the two types of sequence in the model.`),Lm.forEach(t),pl=d(e),ha=n(e,"P",{});var Hm=r(ha);od=h(Hm,"The tokenizer returns this mask as the \u201Ctoken_type_ids\u201D entry:"),Hm.forEach(t),fl=d(e),u(vs.$$.fragment,e),dl=d(e),z=n(e,"P",{});var ba=r(z);ld=h(ba,"The first sequence, the \u201Ccontext\u201D used for the question, has all its tokens represented by a "),hr=n(ba,"CODE",{});var Rm=r(hr);id=h(Rm,"0"),Rm.forEach(t),hd=h(ba,`, whereas the second
sequence, corresponding to the \u201Cquestion\u201D, has all its tokens represented by a `),pr=n(ba,"CODE",{});var Om=r(pr);pd=h(Om,"1"),Om.forEach(t),fd=h(ba,"."),ba.forEach(t),cl=d(e),N=n(e,"P",{});var _a=r(N);dd=h(_a,"Some models, like "),pa=n(_a,"A",{href:!0});var Gm=r(pa);cd=h(Gm,"XLNetModel"),Gm.forEach(t),ud=h(_a," use an additional token represented by a "),fr=n(_a,"CODE",{});var Wm=r(fr);md=h(Wm,"2"),Wm.forEach(t),vd=h(_a,"."),_a.forEach(t),ul=d(e),be=n(e,"H3",{class:!0});var li=r(be);it=n(li,"A",{id:!0,class:!0,href:!0});var Um=r(it);dr=n(Um,"SPAN",{});var Vm=r(dr);u(bs.$$.fragment,Vm),Vm.forEach(t),Um.forEach(t),bd=d(li),cr=n(li,"SPAN",{});var Xm=r(cr);_d=h(Xm,"transformer"),Xm.forEach(t),li.forEach(t),ml=d(e),fa=n(e,"P",{});var Ym=r(fa);wd=h(Ym,"Self-attention based deep learning model architecture."),Ym.forEach(t),this.h()},h(){p(S,"name","hf:doc:metadata"),p(S,"content",JSON.stringify(av)),p(_e,"id","glossary"),p(_e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(_e,"href","#glossary"),p(C,"class","relative group"),p(we,"id","a"),p(we,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(we,"href","#a"),p(D,"class","relative group"),p($e,"id","attention-mask"),p($e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p($e,"href","#attention-mask"),p(M,"class","relative group"),p(js,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),p(ge,"id","autoencoding-models"),p(ge,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ge,"href","#autoencoding-models"),p(I,"class","relative group"),p(As,"href","#mlm"),p(ke,"id","autoregressive-models"),p(ke,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ke,"href","#autoregressive-models"),p(B,"class","relative group"),p(Ps,"href","#clm"),p(ye,"id","c"),p(ye,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ye,"href","#c"),p(F,"class","relative group"),p(Ee,"id","clm"),p(Ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Ee,"href","#clm"),p(L,"class","relative group"),p(qe,"id","d"),p(qe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(qe,"href","#d"),p(H,"class","relative group"),p(je,"id","decoder-input-ids"),p(je,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(je,"href","#decoder-input-ids"),p(R,"class","relative group"),p(Ae,"id","deep-learning"),p(Ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Ae,"href","#deep-learning"),p(O,"class","relative group"),p(Pe,"id","f"),p(Pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Pe,"href","#f"),p(G,"class","relative group"),p(Te,"id","feed-forward-chunking"),p(Te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Te,"href","#feed-forward-chunking"),p(W,"class","relative group"),p(St,"href","https://arxiv.org/abs/2001.04451"),p(St,"rel","nofollow"),p(Ss,"href","/docs/transformers/main/en/internal/modeling_utils#transformers.apply_chunking_to_forward"),p(ze,"id","i"),p(ze,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ze,"href","#i"),p(U,"class","relative group"),p(Ne,"id","input-ids"),p(Ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Ne,"href","#input-ids"),p(V,"class","relative group"),p(It,"href","https://arxiv.org/pdf/1609.08144.pdf"),p(It,"rel","nofollow"),p(Ht,"href","https://github.com/huggingface/tokenizers"),p(Ht,"rel","nofollow"),p(Ls,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),p(Ie,"id","l"),p(Ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Ie,"href","#l"),p(X,"class","relative group"),p(Be,"id","labels"),p(Be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Be,"href","#labels"),p(Y,"class","relative group"),p(Os,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification"),p(Gs,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification"),p(Ws,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM"),p(Us,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),p(Vs,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),p(Xs,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),p(Le,"id","m"),p(Le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Le,"href","#m"),p(Z,"class","relative group"),p(He,"id","mlm"),p(He,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(He,"href","#mlm"),p(ee,"class","relative group"),p(Re,"id","multimodal"),p(Re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Re,"href","#multimodal"),p(te,"class","relative group"),p(Oe,"id","n"),p(Oe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Oe,"href","#n"),p(se,"class","relative group"),p(Ge,"id","nlg"),p(Ge,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Ge,"href","#nlg"),p(ae,"class","relative group"),p(We,"id","nlp"),p(We,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(We,"href","#nlp"),p(ne,"class","relative group"),p(Ue,"id","nlu"),p(Ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Ue,"href","#nlu"),p(re,"class","relative group"),p(Ve,"id","p"),p(Ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Ve,"href","#p"),p(oe,"class","relative group"),p(Xe,"id","position-ids"),p(Xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Xe,"href","#position-ids"),p(le,"class","relative group"),p(Ke,"id","pretrained-model"),p(Ke,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Ke,"href","#pretrained-model"),p(ie,"class","relative group"),p(Ze,"id","r"),p(Ze,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Ze,"href","#r"),p(he,"class","relative group"),p(et,"id","rnn"),p(et,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(et,"href","#rnn"),p(pe,"class","relative group"),p(tt,"id","s"),p(tt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(tt,"href","#s"),p(fe,"class","relative group"),p(st,"id","selfattention"),p(st,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(st,"href","#selfattention"),p(de,"class","relative group"),p(at,"id","seq2seq-or-sequencetosequence"),p(at,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(at,"href","#seq2seq-or-sequencetosequence"),p(ce,"class","relative group"),p(aa,"href","model_doc/bart"),p(na,"href","model_doc/t5"),p(nt,"id","t"),p(nt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(nt,"href","#t"),p(ue,"class","relative group"),p(rt,"id","token"),p(rt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(rt,"href","#token"),p(me,"class","relative group"),p(ot,"id","token-type-ids"),p(ot,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(ot,"href","#token-type-ids"),p(ve,"class","relative group"),p(pa,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel"),p(it,"id","transformer"),p(it,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(it,"href","#transformer"),p(be,"class","relative group")},m(e,o){s(document.head,S),l(e,ur,o),l(e,C,o),s(C,_e),s(_e,wa),m(ct,wa,null),s(C,ii),s(C,$a),s($a,hi),l(e,mr,o),l(e,_s,o),s(_s,pi),l(e,vr,o),l(e,D,o),s(D,we),s(we,ga),m(ut,ga,null),s(D,fi),s(D,ka),s(ka,di),l(e,br,o),l(e,M,o),s(M,$e),s($e,ya),m(mt,ya,null),s(M,ci),s(M,Ea),s(Ea,ui),l(e,_r,o),l(e,ws,o),s(ws,mi),l(e,wr,o),m(vt,e,o),l(e,$r,o),l(e,$s,o),s($s,vi),l(e,gr,o),l(e,gs,o),s(gs,bi),l(e,kr,o),m(bt,e,o),l(e,yr,o),l(e,ks,o),s(ks,_i),l(e,Er,o),m(_t,e,o),l(e,qr,o),l(e,ys,o),s(ys,wi),l(e,jr,o),l(e,Es,o),s(Es,$i),l(e,Ar,o),m(wt,e,o),l(e,Pr,o),l(e,qs,o),s(qs,gi),l(e,Tr,o),m($t,e,o),l(e,xr,o),l(e,q,o),s(q,ki),s(q,js),s(js,yi),s(q,Ei),s(q,qa),s(qa,qi),s(q,ji),s(q,ja),s(ja,Ai),s(q,Pi),l(e,zr,o),m(gt,e,o),l(e,Nr,o),l(e,I,o),s(I,ge),s(ge,Aa),m(kt,Aa,null),s(I,Ti),s(I,Pa),s(Pa,xi),l(e,Sr,o),l(e,yt,o),s(yt,zi),s(yt,As),s(As,Ni),l(e,Cr,o),l(e,B,o),s(B,ke),s(ke,Ta),m(Et,Ta,null),s(B,Si),s(B,xa),s(xa,Ci),l(e,Dr,o),l(e,qt,o),s(qt,Di),s(qt,Ps),s(Ps,Mi),l(e,Mr,o),l(e,F,o),s(F,ye),s(ye,za),m(jt,za,null),s(F,Ii),s(F,Na),s(Na,Bi),l(e,Ir,o),l(e,L,o),s(L,Ee),s(Ee,Sa),m(At,Sa,null),s(L,Fi),s(L,Ca),s(Ca,Li),l(e,Br,o),l(e,Ts,o),s(Ts,Hi),l(e,Fr,o),l(e,H,o),s(H,qe),s(qe,Da),m(Pt,Da,null),s(H,Ri),s(H,Ma),s(Ma,Oi),l(e,Lr,o),l(e,R,o),s(R,je),s(je,Ia),m(Tt,Ia,null),s(R,Gi),s(R,Ba),s(Ba,Wi),l(e,Hr,o),l(e,xs,o),s(xs,Ui),l(e,Rr,o),l(e,j,o),s(j,Vi),s(j,Fa),s(Fa,Xi),s(j,Yi),s(j,La),s(La,Qi),s(j,Ji),s(j,Ha),s(Ha,Ki),s(j,Zi),l(e,Or,o),l(e,zs,o),s(zs,eh),l(e,Gr,o),l(e,O,o),s(O,Ae),s(Ae,Ra),m(xt,Ra,null),s(O,th),s(O,Oa),s(Oa,sh),l(e,Wr,o),l(e,Ns,o),s(Ns,ah),l(e,Ur,o),l(e,G,o),s(G,Pe),s(Pe,Ga),m(zt,Ga,null),s(G,nh),s(G,Wa),s(Wa,rh),l(e,Vr,o),l(e,W,o),s(W,Te),s(Te,Ua),m(Nt,Ua,null),s(W,oh),s(W,Va),s(Va,lh),l(e,Xr,o),l(e,xe,o),s(xe,ih),s(xe,Xa),s(Xa,hh),s(xe,ph),l(e,Yr,o),l(e,$,o),s($,fh),s($,Ya),s(Ya,dh),s($,ch),s($,Qa),s(Qa,uh),s($,mh),s($,St),s(St,vh),s($,bh),s($,Ja),s(Ja,_h),s($,wh),s($,Ka),s(Ka,$h),s($,gh),s($,Za),s(Za,kh),s($,yh),s($,en),s(en,Eh),s($,qh),s($,tn),s(tn,jh),s($,Ah),l(e,Qr,o),l(e,A,o),s(A,Ph),s(A,Ss),s(Ss,Th),s(A,xh),s(A,sn),s(sn,zh),s(A,Nh),s(A,an),s(an,Sh),s(A,Ch),l(e,Jr,o),l(e,U,o),s(U,ze),s(ze,nn),m(Ct,nn,null),s(U,Dh),s(U,rn),s(rn,Mh),l(e,Kr,o),l(e,V,o),s(V,Ne),s(Ne,on),m(Dt,on,null),s(V,Ih),s(V,ln),s(ln,Bh),l(e,Zr,o),l(e,Se,o),s(Se,Fh),s(Se,hn),s(hn,Lh),s(Se,Hh),l(e,eo,o),m(Mt,e,o),l(e,to,o),l(e,Ce,o),s(Ce,Rh),s(Ce,It),s(It,Oh),s(Ce,Gh),l(e,so,o),m(Bt,e,o),l(e,ao,o),l(e,Cs,o),s(Cs,Wh),l(e,no,o),m(Ft,e,o),l(e,ro,o),l(e,Ds,o),s(Ds,Uh),l(e,oo,o),m(Lt,e,o),l(e,lo,o),l(e,De,o),s(De,Vh),s(De,Ht),s(Ht,Xh),s(De,Yh),l(e,io,o),m(Rt,e,o),l(e,ho,o),l(e,Ms,o),s(Ms,Qh),l(e,po,o),m(Ot,e,o),l(e,fo,o),l(e,Is,o),s(Is,Jh),l(e,co,o),l(e,Bs,o),s(Bs,Kh),l(e,uo,o),m(Gt,e,o),l(e,mo,o),l(e,Fs,o),s(Fs,Zh),l(e,vo,o),m(Wt,e,o),l(e,bo,o),l(e,Me,o),s(Me,ep),s(Me,Ls),s(Ls,tp),s(Me,sp),l(e,_o,o),l(e,X,o),s(X,Ie),s(Ie,pn),m(Ut,pn,null),s(X,ap),s(X,fn),s(fn,np),l(e,wo,o),l(e,Y,o),s(Y,Be),s(Be,dn),m(Vt,dn,null),s(Y,rp),s(Y,cn),s(cn,op),l(e,$o,o),l(e,Hs,o),s(Hs,lp),l(e,go,o),l(e,Rs,o),s(Rs,ip),l(e,ko,o),l(e,P,o),s(P,Q),s(Q,hp),s(Q,Os),s(Os,pp),s(Q,fp),s(Q,un),s(un,dp),s(Q,cp),s(P,up),s(P,J),s(J,mp),s(J,Gs),s(Gs,vp),s(J,bp),s(J,mn),s(mn,_p),s(J,wp),s(P,$p),s(P,K),s(K,gp),s(K,Ws),s(Ws,kp),s(K,yp),s(K,vn),s(vn,Ep),s(K,qp),s(P,jp),s(P,k),s(k,Ap),s(k,Us),s(Us,Pp),s(k,Tp),s(k,Vs),s(Vs,xp),s(k,zp),s(k,bn),s(bn,Np),s(k,Sp),s(k,_n),s(_n,Cp),s(k,Dp),s(k,wn),s(wn,Mp),s(k,Ip),s(k,$n),s($n,Bp),s(k,Fp),l(e,yo,o),l(e,Fe,o),s(Fe,Lp),s(Fe,Xs),s(Xs,Hp),s(Fe,Rp),l(e,Eo,o),l(e,Z,o),s(Z,Le),s(Le,gn),m(Xt,gn,null),s(Z,Op),s(Z,kn),s(kn,Gp),l(e,qo,o),l(e,ee,o),s(ee,He),s(He,yn),m(Yt,yn,null),s(ee,Wp),s(ee,En),s(En,Up),l(e,jo,o),l(e,Ys,o),s(Ys,Vp),l(e,Ao,o),l(e,te,o),s(te,Re),s(Re,qn),m(Qt,qn,null),s(te,Xp),s(te,jn),s(jn,Yp),l(e,Po,o),l(e,Qs,o),s(Qs,Qp),l(e,To,o),l(e,se,o),s(se,Oe),s(Oe,An),m(Jt,An,null),s(se,Jp),s(se,Pn),s(Pn,Kp),l(e,xo,o),l(e,ae,o),s(ae,Ge),s(Ge,Tn),m(Kt,Tn,null),s(ae,Zp),s(ae,xn),s(xn,ef),l(e,zo,o),l(e,Js,o),s(Js,tf),l(e,No,o),l(e,ne,o),s(ne,We),s(We,zn),m(Zt,zn,null),s(ne,sf),s(ne,Nn),s(Nn,af),l(e,So,o),l(e,Ks,o),s(Ks,nf),l(e,Co,o),l(e,re,o),s(re,Ue),s(Ue,Sn),m(es,Sn,null),s(re,rf),s(re,Cn),s(Cn,of),l(e,Do,o),l(e,Zs,o),s(Zs,lf),l(e,Mo,o),l(e,oe,o),s(oe,Ve),s(Ve,Dn),m(ts,Dn,null),s(oe,hf),s(oe,Mn),s(Mn,pf),l(e,Io,o),l(e,le,o),s(le,Xe),s(Xe,In),m(ss,In,null),s(le,ff),s(le,Bn),s(Bn,df),l(e,Bo,o),l(e,Ye,o),s(Ye,cf),s(Ye,Fn),s(Fn,uf),s(Ye,mf),l(e,Fo,o),l(e,Qe,o),s(Qe,vf),s(Qe,Ln),s(Ln,bf),s(Qe,_f),l(e,Lo,o),l(e,Je,o),s(Je,wf),s(Je,Hn),s(Hn,$f),s(Je,gf),l(e,Ho,o),l(e,ie,o),s(ie,Ke),s(Ke,Rn),m(as,Rn,null),s(ie,kf),s(ie,On),s(On,yf),l(e,Ro,o),l(e,ea,o),s(ea,Ef),l(e,Oo,o),l(e,he,o),s(he,Ze),s(Ze,Gn),m(ns,Gn,null),s(he,qf),s(he,Wn),s(Wn,jf),l(e,Go,o),l(e,pe,o),s(pe,et),s(et,Un),m(rs,Un,null),s(pe,Af),s(pe,Vn),s(Vn,Pf),l(e,Wo,o),l(e,ta,o),s(ta,Tf),l(e,Uo,o),l(e,fe,o),s(fe,tt),s(tt,Xn),m(os,Xn,null),s(fe,xf),s(fe,Yn),s(Yn,zf),l(e,Vo,o),l(e,de,o),s(de,st),s(st,Qn),m(ls,Qn,null),s(de,Nf),s(de,Jn),s(Jn,Sf),l(e,Xo,o),l(e,sa,o),s(sa,Cf),l(e,Yo,o),l(e,ce,o),s(ce,at),s(at,Kn),m(is,Kn,null),s(ce,Df),s(ce,Zn),s(Zn,Mf),l(e,Qo,o),l(e,T,o),s(T,If),s(T,aa),s(aa,Bf),s(T,Ff),s(T,na),s(na,Lf),s(T,Hf),l(e,Jo,o),l(e,ue,o),s(ue,nt),s(nt,er),m(hs,er,null),s(ue,Rf),s(ue,tr),s(tr,Of),l(e,Ko,o),l(e,me,o),s(me,rt),s(rt,sr),m(ps,sr,null),s(me,Gf),s(me,ar),s(ar,Wf),l(e,Zo,o),l(e,ra,o),s(ra,Uf),l(e,el,o),l(e,ve,o),s(ve,ot),s(ot,nr),m(fs,nr,null),s(ve,Vf),s(ve,rr),s(rr,Xf),l(e,tl,o),l(e,oa,o),s(oa,Yf),l(e,sl,o),m(ds,e,o),l(e,al,o),l(e,x,o),s(x,Qf),s(x,or),s(or,Jf),s(x,Kf),s(x,lr),s(lr,Zf),s(x,ed),l(e,nl,o),m(cs,e,o),l(e,rl,o),l(e,lt,o),s(lt,td),s(lt,ir),s(ir,sd),s(lt,ad),l(e,ol,o),m(us,e,o),l(e,ll,o),l(e,la,o),s(la,nd),l(e,il,o),m(ms,e,o),l(e,hl,o),l(e,ia,o),s(ia,rd),l(e,pl,o),l(e,ha,o),s(ha,od),l(e,fl,o),m(vs,e,o),l(e,dl,o),l(e,z,o),s(z,ld),s(z,hr),s(hr,id),s(z,hd),s(z,pr),s(pr,pd),s(z,fd),l(e,cl,o),l(e,N,o),s(N,dd),s(N,pa),s(pa,cd),s(N,ud),s(N,fr),s(fr,md),s(N,vd),l(e,ul,o),l(e,be,o),s(be,it),s(it,dr),m(bs,dr,null),s(be,bd),s(be,cr),s(cr,_d),l(e,ml,o),l(e,fa,o),s(fa,wd),vl=!0},p:ev,i(e){vl||(v(ct.$$.fragment,e),v(ut.$$.fragment,e),v(mt.$$.fragment,e),v(vt.$$.fragment,e),v(bt.$$.fragment,e),v(_t.$$.fragment,e),v(wt.$$.fragment,e),v($t.$$.fragment,e),v(gt.$$.fragment,e),v(kt.$$.fragment,e),v(Et.$$.fragment,e),v(jt.$$.fragment,e),v(At.$$.fragment,e),v(Pt.$$.fragment,e),v(Tt.$$.fragment,e),v(xt.$$.fragment,e),v(zt.$$.fragment,e),v(Nt.$$.fragment,e),v(Ct.$$.fragment,e),v(Dt.$$.fragment,e),v(Mt.$$.fragment,e),v(Bt.$$.fragment,e),v(Ft.$$.fragment,e),v(Lt.$$.fragment,e),v(Rt.$$.fragment,e),v(Ot.$$.fragment,e),v(Gt.$$.fragment,e),v(Wt.$$.fragment,e),v(Ut.$$.fragment,e),v(Vt.$$.fragment,e),v(Xt.$$.fragment,e),v(Yt.$$.fragment,e),v(Qt.$$.fragment,e),v(Jt.$$.fragment,e),v(Kt.$$.fragment,e),v(Zt.$$.fragment,e),v(es.$$.fragment,e),v(ts.$$.fragment,e),v(ss.$$.fragment,e),v(as.$$.fragment,e),v(ns.$$.fragment,e),v(rs.$$.fragment,e),v(os.$$.fragment,e),v(ls.$$.fragment,e),v(is.$$.fragment,e),v(hs.$$.fragment,e),v(ps.$$.fragment,e),v(fs.$$.fragment,e),v(ds.$$.fragment,e),v(cs.$$.fragment,e),v(us.$$.fragment,e),v(ms.$$.fragment,e),v(vs.$$.fragment,e),v(bs.$$.fragment,e),vl=!0)},o(e){b(ct.$$.fragment,e),b(ut.$$.fragment,e),b(mt.$$.fragment,e),b(vt.$$.fragment,e),b(bt.$$.fragment,e),b(_t.$$.fragment,e),b(wt.$$.fragment,e),b($t.$$.fragment,e),b(gt.$$.fragment,e),b(kt.$$.fragment,e),b(Et.$$.fragment,e),b(jt.$$.fragment,e),b(At.$$.fragment,e),b(Pt.$$.fragment,e),b(Tt.$$.fragment,e),b(xt.$$.fragment,e),b(zt.$$.fragment,e),b(Nt.$$.fragment,e),b(Ct.$$.fragment,e),b(Dt.$$.fragment,e),b(Mt.$$.fragment,e),b(Bt.$$.fragment,e),b(Ft.$$.fragment,e),b(Lt.$$.fragment,e),b(Rt.$$.fragment,e),b(Ot.$$.fragment,e),b(Gt.$$.fragment,e),b(Wt.$$.fragment,e),b(Ut.$$.fragment,e),b(Vt.$$.fragment,e),b(Xt.$$.fragment,e),b(Yt.$$.fragment,e),b(Qt.$$.fragment,e),b(Jt.$$.fragment,e),b(Kt.$$.fragment,e),b(Zt.$$.fragment,e),b(es.$$.fragment,e),b(ts.$$.fragment,e),b(ss.$$.fragment,e),b(as.$$.fragment,e),b(ns.$$.fragment,e),b(rs.$$.fragment,e),b(os.$$.fragment,e),b(ls.$$.fragment,e),b(is.$$.fragment,e),b(hs.$$.fragment,e),b(ps.$$.fragment,e),b(fs.$$.fragment,e),b(ds.$$.fragment,e),b(cs.$$.fragment,e),b(us.$$.fragment,e),b(ms.$$.fragment,e),b(vs.$$.fragment,e),b(bs.$$.fragment,e),vl=!1},d(e){t(S),e&&t(ur),e&&t(C),_(ct),e&&t(mr),e&&t(_s),e&&t(vr),e&&t(D),_(ut),e&&t(br),e&&t(M),_(mt),e&&t(_r),e&&t(ws),e&&t(wr),_(vt,e),e&&t($r),e&&t($s),e&&t(gr),e&&t(gs),e&&t(kr),_(bt,e),e&&t(yr),e&&t(ks),e&&t(Er),_(_t,e),e&&t(qr),e&&t(ys),e&&t(jr),e&&t(Es),e&&t(Ar),_(wt,e),e&&t(Pr),e&&t(qs),e&&t(Tr),_($t,e),e&&t(xr),e&&t(q),e&&t(zr),_(gt,e),e&&t(Nr),e&&t(I),_(kt),e&&t(Sr),e&&t(yt),e&&t(Cr),e&&t(B),_(Et),e&&t(Dr),e&&t(qt),e&&t(Mr),e&&t(F),_(jt),e&&t(Ir),e&&t(L),_(At),e&&t(Br),e&&t(Ts),e&&t(Fr),e&&t(H),_(Pt),e&&t(Lr),e&&t(R),_(Tt),e&&t(Hr),e&&t(xs),e&&t(Rr),e&&t(j),e&&t(Or),e&&t(zs),e&&t(Gr),e&&t(O),_(xt),e&&t(Wr),e&&t(Ns),e&&t(Ur),e&&t(G),_(zt),e&&t(Vr),e&&t(W),_(Nt),e&&t(Xr),e&&t(xe),e&&t(Yr),e&&t($),e&&t(Qr),e&&t(A),e&&t(Jr),e&&t(U),_(Ct),e&&t(Kr),e&&t(V),_(Dt),e&&t(Zr),e&&t(Se),e&&t(eo),_(Mt,e),e&&t(to),e&&t(Ce),e&&t(so),_(Bt,e),e&&t(ao),e&&t(Cs),e&&t(no),_(Ft,e),e&&t(ro),e&&t(Ds),e&&t(oo),_(Lt,e),e&&t(lo),e&&t(De),e&&t(io),_(Rt,e),e&&t(ho),e&&t(Ms),e&&t(po),_(Ot,e),e&&t(fo),e&&t(Is),e&&t(co),e&&t(Bs),e&&t(uo),_(Gt,e),e&&t(mo),e&&t(Fs),e&&t(vo),_(Wt,e),e&&t(bo),e&&t(Me),e&&t(_o),e&&t(X),_(Ut),e&&t(wo),e&&t(Y),_(Vt),e&&t($o),e&&t(Hs),e&&t(go),e&&t(Rs),e&&t(ko),e&&t(P),e&&t(yo),e&&t(Fe),e&&t(Eo),e&&t(Z),_(Xt),e&&t(qo),e&&t(ee),_(Yt),e&&t(jo),e&&t(Ys),e&&t(Ao),e&&t(te),_(Qt),e&&t(Po),e&&t(Qs),e&&t(To),e&&t(se),_(Jt),e&&t(xo),e&&t(ae),_(Kt),e&&t(zo),e&&t(Js),e&&t(No),e&&t(ne),_(Zt),e&&t(So),e&&t(Ks),e&&t(Co),e&&t(re),_(es),e&&t(Do),e&&t(Zs),e&&t(Mo),e&&t(oe),_(ts),e&&t(Io),e&&t(le),_(ss),e&&t(Bo),e&&t(Ye),e&&t(Fo),e&&t(Qe),e&&t(Lo),e&&t(Je),e&&t(Ho),e&&t(ie),_(as),e&&t(Ro),e&&t(ea),e&&t(Oo),e&&t(he),_(ns),e&&t(Go),e&&t(pe),_(rs),e&&t(Wo),e&&t(ta),e&&t(Uo),e&&t(fe),_(os),e&&t(Vo),e&&t(de),_(ls),e&&t(Xo),e&&t(sa),e&&t(Yo),e&&t(ce),_(is),e&&t(Qo),e&&t(T),e&&t(Jo),e&&t(ue),_(hs),e&&t(Ko),e&&t(me),_(ps),e&&t(Zo),e&&t(ra),e&&t(el),e&&t(ve),_(fs),e&&t(tl),e&&t(oa),e&&t(sl),_(ds,e),e&&t(al),e&&t(x),e&&t(nl),_(cs,e),e&&t(rl),e&&t(lt),e&&t(ol),_(us,e),e&&t(ll),e&&t(la),e&&t(il),_(ms,e),e&&t(hl),e&&t(ia),e&&t(pl),e&&t(ha),e&&t(fl),_(vs,e),e&&t(dl),e&&t(z),e&&t(cl),e&&t(N),e&&t(ul),e&&t(be),_(bs),e&&t(ml),e&&t(fa)}}}const av={local:"glossary",sections:[{local:"a",sections:[{local:"attention-mask",title:"Attention mask"},{local:"autoencoding-models",title:"autoencoding models "},{local:"autoregressive-models",title:"autoregressive models"}],title:"A"},{local:"c",sections:[{local:"clm",title:"CLM"}],title:"C"},{local:"d",sections:[{local:"decoder-input-ids",title:"Decoder input IDs"},{local:"deep-learning",title:"deep learning"}],title:"D"},{local:"f",sections:[{local:"feed-forward-chunking",title:"Feed Forward Chunking"}],title:"F"},{local:"i",sections:[{local:"input-ids",title:"Input IDs"}],title:"I"},{local:"l",sections:[{local:"labels",title:"Labels"}],title:"L"},{local:"m",sections:[{local:"mlm",title:"MLM"},{local:"multimodal",title:"multimodal"}],title:"M"},{local:"n",sections:[{local:"nlg",title:"NLG"},{local:"nlp",title:"NLP"},{local:"nlu",title:"NLU"}],title:"N"},{local:"p",sections:[{local:"position-ids",title:"Position IDs"},{local:"pretrained-model",title:"pretrained model"}],title:"P"},{local:"r",sections:[{local:"rnn",title:"RNN"}],title:"R"},{local:"s",sections:[{local:"selfattention",title:"self-attention"},{local:"seq2seq-or-sequencetosequence",title:"seq2seq or sequence-to-sequence"}],title:"S"},{local:"t",sections:[{local:"token",title:"token"},{local:"token-type-ids",title:"Token Type IDs"},{local:"transformer",title:"transformer"}],title:"T"}],title:"Glossary"};function nv(yd){return tv(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class hv extends Qm{constructor(S){super();Jm(this,S,nv,sv,Km,{})}}export{hv as default,av as metadata};
