import{S as ag,i as lg,s as rg,e as a,k as p,w as j,t as s,M as ig,c as l,d as o,m as f,a as r,x as C,h as n,b as v,G as e,g as d,y as D,q,o as L,B as A,v as pg,L as sg}from"../chunks/vendor-hf-doc-builder.js";import{T as Rt}from"../chunks/Tip-hf-doc-builder.js";import{I as Ve}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as X}from"../chunks/CodeBlock-hf-doc-builder.js";import{F as fg,M as ng}from"../chunks/Markdown-hf-doc-builder.js";function dg(M){let c,$,m,E,w;return{c(){c=a("p"),$=s(`Once exported, a model can be optimized for inference via techniques such as
quantization and pruning. If you are interested in optimizing your models to run with
maximum efficiency, check out the `),m=a("a"),E=s(`\u{1F917} Optimum
library`),w=s("."),this.h()},l(_){c=l(_,"P",{});var x=r(c);$=n(x,`Once exported, a model can be optimized for inference via techniques such as
quantization and pruning. If you are interested in optimizing your models to run with
maximum efficiency, check out the `),m=l(x,"A",{href:!0,rel:!0});var b=r(m);E=n(b,`\u{1F917} Optimum
library`),b.forEach(o),w=n(x,"."),x.forEach(o),this.h()},h(){v(m,"href","https://github.com/huggingface/optimum"),v(m,"rel","nofollow")},m(_,x){d(_,c,x),e(c,$),e(c,m),e(m,E),e(c,w)},d(_){_&&o(c)}}}function cg(M){let c,$,m,E,w,_,x,b,k,T,I,y,O;return c=new X({props:{code:`from transformers import AutoTokenizer, AutoModelForSequenceClassification

# Load tokenizer and PyTorch weights form the Hub
tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
pt_model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")
# Save to disk
tokenizer.save_pretrained("local-pt-checkpoint")
pt_model.save_pretrained("local-pt-checkpoint")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load tokenizer and PyTorch weights form the Hub</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Save to disk</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(<span class="hljs-string">&quot;local-pt-checkpoint&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.save_pretrained(<span class="hljs-string">&quot;local-pt-checkpoint&quot;</span>)`}}),y=new X({props:{code:"python -m transformers.onnx --model=local-pt-checkpoint onnx/",highlighted:"python -m transformers.onnx --model=local-pt-checkpoint onnx/"}}),{c(){j(c.$$.fragment),$=p(),m=a("p"),E=s("Once the checkpoint is saved, we can export it to ONNX by pointing the "),w=a("code"),_=s("--model"),x=s(`
argument of the `),b=a("code"),k=s("transformers.onnx"),T=s(" package to the desired directory:"),I=p(),j(y.$$.fragment)},l(g){C(c.$$.fragment,g),$=f(g),m=l(g,"P",{});var N=r(m);E=n(N,"Once the checkpoint is saved, we can export it to ONNX by pointing the "),w=l(N,"CODE",{});var B=r(w);_=n(B,"--model"),B.forEach(o),x=n(N,`
argument of the `),b=l(N,"CODE",{});var R=r(b);k=n(R,"transformers.onnx"),R.forEach(o),T=n(N," package to the desired directory:"),N.forEach(o),I=f(g),C(y.$$.fragment,g)},m(g,N){D(c,g,N),d(g,$,N),d(g,m,N),e(m,E),e(m,w),e(w,_),e(m,x),e(m,b),e(b,k),e(m,T),d(g,I,N),D(y,g,N),O=!0},p:sg,i(g){O||(q(c.$$.fragment,g),q(y.$$.fragment,g),O=!0)},o(g){L(c.$$.fragment,g),L(y.$$.fragment,g),O=!1},d(g){A(c,g),g&&o($),g&&o(m),g&&o(I),A(y,g)}}}function hg(M){let c,$;return c=new ng({props:{$$slots:{default:[cg]},$$scope:{ctx:M}}}),{c(){j(c.$$.fragment)},l(m){C(c.$$.fragment,m)},m(m,E){D(c,m,E),$=!0},p(m,E){const w={};E&2&&(w.$$scope={dirty:E,ctx:m}),c.$set(w)},i(m){$||(q(c.$$.fragment,m),$=!0)},o(m){L(c.$$.fragment,m),$=!1},d(m){A(c,m)}}}function ug(M){let c,$,m,E,w,_,x,b,k,T,I,y,O;return c=new X({props:{code:`from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

# Load tokenizer and TensorFlow weights from the Hub
tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
tf_model = TFAutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased")
# Save to disk
tokenizer.save_pretrained("local-tf-checkpoint")
tf_model.save_pretrained("local-tf-checkpoint")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load tokenizer and TensorFlow weights from the Hub</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Save to disk</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(<span class="hljs-string">&quot;local-tf-checkpoint&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model.save_pretrained(<span class="hljs-string">&quot;local-tf-checkpoint&quot;</span>)`}}),y=new X({props:{code:"python -m transformers.onnx --model=local-tf-checkpoint onnx/",highlighted:"python -m transformers.onnx --model=local-tf-checkpoint onnx/"}}),{c(){j(c.$$.fragment),$=p(),m=a("p"),E=s("Once the checkpoint is saved, we can export it to ONNX by pointing the "),w=a("code"),_=s("--model"),x=s(`
argument of the `),b=a("code"),k=s("transformers.onnx"),T=s(" package to the desired directory:"),I=p(),j(y.$$.fragment)},l(g){C(c.$$.fragment,g),$=f(g),m=l(g,"P",{});var N=r(m);E=n(N,"Once the checkpoint is saved, we can export it to ONNX by pointing the "),w=l(N,"CODE",{});var B=r(w);_=n(B,"--model"),B.forEach(o),x=n(N,`
argument of the `),b=l(N,"CODE",{});var R=r(b);k=n(R,"transformers.onnx"),R.forEach(o),T=n(N," package to the desired directory:"),N.forEach(o),I=f(g),C(y.$$.fragment,g)},m(g,N){D(c,g,N),d(g,$,N),d(g,m,N),e(m,E),e(m,w),e(w,_),e(m,x),e(m,b),e(b,k),e(m,T),d(g,I,N),D(y,g,N),O=!0},p:sg,i(g){O||(q(c.$$.fragment,g),q(y.$$.fragment,g),O=!0)},o(g){L(c.$$.fragment,g),L(y.$$.fragment,g),O=!1},d(g){A(c,g),g&&o($),g&&o(m),g&&o(I),A(y,g)}}}function mg(M){let c,$;return c=new ng({props:{$$slots:{default:[ug]},$$scope:{ctx:M}}}),{c(){j(c.$$.fragment)},l(m){C(c.$$.fragment,m)},m(m,E){D(c,m,E),$=!0},p(m,E){const w={};E&2&&(w.$$scope={dirty:E,ctx:m}),c.$set(w)},i(m){$||(q(c.$$.fragment,m),$=!0)},o(m){L(c.$$.fragment,m),$=!1},d(m){A(c,m)}}}function gg(M){let c,$,m,E,w,_,x,b;return{c(){c=a("p"),$=s("The features that have a "),m=a("code"),E=s("with-past"),w=s(" suffix (like "),_=a("code"),x=s("causal-lm-with-past"),b=s(`) correspond to
model classes with precomputed hidden states (key and values in the attention blocks)
that can be used for fast autoregressive decoding.`)},l(k){c=l(k,"P",{});var T=r(c);$=n(T,"The features that have a "),m=l(T,"CODE",{});var I=r(m);E=n(I,"with-past"),I.forEach(o),w=n(T," suffix (like "),_=l(T,"CODE",{});var y=r(_);x=n(y,"causal-lm-with-past"),y.forEach(o),b=n(T,`) correspond to
model classes with precomputed hidden states (key and values in the attention blocks)
that can be used for fast autoregressive decoding.`),T.forEach(o)},m(k,T){d(k,c,T),e(c,$),e(c,m),e(m,E),e(c,w),e(c,_),e(_,x),e(c,b)},d(k){k&&o(c)}}}function _g(M){let c,$,m,E,w,_,x,b,k,T,I;return{c(){c=a("p"),$=s("For "),m=a("code"),E=s("VisionEncoderDecoder"),w=s(` type models, the encoder and decoder parts are
exported separately as two ONNX files named `),_=a("code"),x=s("encoder_model.onnx"),b=s(" and "),k=a("code"),T=s("decoder_model.onnx"),I=s(" respectively.")},l(y){c=l(y,"P",{});var O=r(c);$=n(O,"For "),m=l(O,"CODE",{});var g=r(m);E=n(g,"VisionEncoderDecoder"),g.forEach(o),w=n(O,` type models, the encoder and decoder parts are
exported separately as two ONNX files named `),_=l(O,"CODE",{});var N=r(_);x=n(N,"encoder_model.onnx"),N.forEach(o),b=n(O," and "),k=l(O,"CODE",{});var B=r(k);T=n(B,"decoder_model.onnx"),B.forEach(o),I=n(O," respectively."),O.forEach(o)},m(y,O){d(y,c,O),e(c,$),e(c,m),e(m,E),e(c,w),e(c,_),e(_,x),e(c,b),e(c,k),e(k,T),e(c,I)},d(y){y&&o(c)}}}function vg(M){let c,$,m,E,w;return{c(){c=a("p"),$=s(`A good way to implement a custom ONNX configuration is to look at the existing
implementation in the `),m=a("code"),E=s("configuration_<model_name>.py"),w=s(" file of a similar architecture.")},l(_){c=l(_,"P",{});var x=r(c);$=n(x,`A good way to implement a custom ONNX configuration is to look at the existing
implementation in the `),m=l(x,"CODE",{});var b=r(m);E=n(b,"configuration_<model_name>.py"),b.forEach(o),w=n(x," file of a similar architecture."),x.forEach(o)},m(_,x){d(_,c,x),e(c,$),e(c,m),e(m,E),e(c,w)},d(_){_&&o(c)}}}function Eg(M){let c,$,m,E,w,_,x,b,k,T,I,y,O,g,N,B,R,Q,W,He,K,We,Ge;return{c(){c=a("p"),$=s("Notice that "),m=a("code"),E=s("inputs"),w=s(" property for "),_=a("code"),x=s("DistilBertOnnxConfig"),b=s(" returns an "),k=a("code"),T=s("OrderedDict"),I=s(`. This
ensures that the inputs are matched with their relative position within the
`),y=a("code"),O=s("PreTrainedModel.forward()"),g=s(` method when tracing the graph. We recommend using an
`),N=a("code"),B=s("OrderedDict"),R=s(" for the "),Q=a("code"),W=s("inputs"),He=s(" and "),K=a("code"),We=s("outputs"),Ge=s(` properties when implementing custom ONNX
configurations.`)},l(Z){c=l(Z,"P",{});var P=r(c);$=n(P,"Notice that "),m=l(P,"CODE",{});var Ft=r(m);E=n(Ft,"inputs"),Ft.forEach(o),w=n(P," property for "),_=l(P,"CODE",{});var Ye=r(_);x=n(Ye,"DistilBertOnnxConfig"),Ye.forEach(o),b=n(P," returns an "),k=l(P,"CODE",{});var J=r(k);T=n(J,"OrderedDict"),J.forEach(o),I=n(P,`. This
ensures that the inputs are matched with their relative position within the
`),y=l(P,"CODE",{});var St=r(y);O=n(St,"PreTrainedModel.forward()"),St.forEach(o),g=n(P,` method when tracing the graph. We recommend using an
`),N=l(P,"CODE",{});var fe=r(N);B=n(fe,"OrderedDict"),fe.forEach(o),R=n(P," for the "),Q=l(P,"CODE",{});var ve=r(Q);W=n(ve,"inputs"),ve.forEach(o),He=n(P," and "),K=l(P,"CODE",{});var zt=r(K);We=n(zt,"outputs"),zt.forEach(o),Ge=n(P,` properties when implementing custom ONNX
configurations.`),P.forEach(o)},m(Z,P){d(Z,c,P),e(c,$),e(c,m),e(m,E),e(c,w),e(c,_),e(_,x),e(c,b),e(c,k),e(k,T),e(c,I),e(c,y),e(y,O),e(c,g),e(c,N),e(N,B),e(c,R),e(c,Q),e(Q,W),e(c,He),e(c,K),e(K,We),e(c,Ge)},d(Z){Z&&o(c)}}}function $g(M){let c,$,m,E,w,_,x,b;return{c(){c=a("p"),$=s("All of the base properties and methods associated with "),m=a("a"),E=s("OnnxConfig"),w=s(` and
the other configuration classes can be overridden if needed. Check out `),_=a("code"),x=s("BartOnnxConfig"),b=s(`
for an advanced example.`),this.h()},l(k){c=l(k,"P",{});var T=r(c);$=n(T,"All of the base properties and methods associated with "),m=l(T,"A",{href:!0});var I=r(m);E=n(I,"OnnxConfig"),I.forEach(o),w=n(T,` and
the other configuration classes can be overridden if needed. Check out `),_=l(T,"CODE",{});var y=r(_);x=n(y,"BartOnnxConfig"),y.forEach(o),b=n(T,`
for an advanced example.`),T.forEach(o),this.h()},h(){v(m,"href","/docs/transformers/main/en/main_classes/onnx#transformers.onnx.OnnxConfig")},m(k,T){d(k,c,T),e(c,$),e(c,m),e(m,E),e(c,w),e(c,_),e(_,x),e(c,b)},d(k){k&&o(c)}}}function wg(M){let c,$,m,E,w,_,x,b,k,T,I;return{c(){c=a("p"),$=s(`If your model is larger than 2GB, you will see that many additional files are created
during the export. This is `),m=a("em"),E=s("expected"),w=s(" because ONNX uses "),_=a("a"),x=s(`Protocol
Buffers`),b=s(` to store the model and these
have a size limit of 2GB. See the `),k=a("a"),T=s(`ONNX
documentation`),I=s(` for
instructions on how to load models with external data.`),this.h()},l(y){c=l(y,"P",{});var O=r(c);$=n(O,`If your model is larger than 2GB, you will see that many additional files are created
during the export. This is `),m=l(O,"EM",{});var g=r(m);E=n(g,"expected"),g.forEach(o),w=n(O," because ONNX uses "),_=l(O,"A",{href:!0,rel:!0});var N=r(_);x=n(N,`Protocol
Buffers`),N.forEach(o),b=n(O,` to store the model and these
have a size limit of 2GB. See the `),k=l(O,"A",{href:!0,rel:!0});var B=r(k);T=n(B,`ONNX
documentation`),B.forEach(o),I=n(O,` for
instructions on how to load models with external data.`),O.forEach(o),this.h()},h(){v(_,"href","https://developers.google.com/protocol-buffers/"),v(_,"rel","nofollow"),v(k,"href","https://github.com/onnx/onnx/blob/master/docs/ExternalData.md"),v(k,"rel","nofollow")},m(y,O){d(y,c,O),e(c,$),e(c,m),e(m,E),e(c,w),e(c,_),e(_,x),e(c,b),e(c,k),e(k,T),e(c,I)},d(y){y&&o(c)}}}function xg(M){let c,$,m,E,w,_,x,b,k,T,I,y,O,g,N,B,R,Q,W,He,K,We,Ge,Z,P,Ft,Ye,J,St,fe,ve,zt,sr,da,Vt,nr,ca,h,bo,ar,lr,ko,rr,ir,yo,pr,fr,Oo,dr,cr,To,hr,ur,No,mr,gr,jo,_r,vr,Co,Er,$r,Do,wr,xr,qo,br,kr,Lo,yr,Or,Ao,Tr,Nr,Io,jr,Cr,Po,Dr,qr,Mo,Lr,Ar,Xo,Ir,Pr,Bo,Mr,Xr,Ro,Br,Rr,Fo,Fr,Sr,So,zr,Vr,zo,Hr,Wr,Vo,Gr,Yr,Ho,Ur,Kr,Wo,Jr,Qr,Go,Zr,ei,Yo,ti,oi,Uo,si,ni,Ko,ai,li,Jo,ri,ii,Qo,pi,fi,Zo,di,ci,es,hi,ui,ts,mi,gi,os,_i,vi,ss,Ei,$i,ns,wi,xi,as,bi,ki,ls,yi,Oi,rs,Ti,Ni,is,ji,Ci,ps,Di,qi,fs,Li,Ai,ds,Ii,Pi,cs,Mi,Xi,hs,Bi,Ri,us,Fi,Si,ms,zi,Vi,gs,Hi,Wi,_s,Gi,Yi,vs,Ui,Ki,Es,Ji,Qi,$s,Zi,ep,ws,tp,op,xs,sp,np,bs,ap,lp,ks,rp,ip,ys,pp,fp,Os,dp,cp,Ts,hp,up,Ns,mp,gp,js,_p,ha,Ht,vp,ua,Ee,Ue,Ep,Cs,$p,wp,xp,Ds,bp,ma,de,$e,qs,Ke,kp,Ls,yp,ga,Wt,Op,_a,Je,va,we,Tp,As,Np,jp,Ea,Qe,$a,Gt,Cp,wa,Ze,xa,Yt,Dp,ba,et,ka,ee,qp,Is,Lp,Ap,Ps,Ip,Pp,ya,G,Mp,Ms,Xp,Bp,tt,Rp,Fp,ot,Sp,zp,Oa,st,Ta,xe,Vp,Xs,Hp,Wp,Na,nt,ja,be,Gp,at,Yp,Up,Ca,lt,Da,Ut,Kp,qa,ke,La,ce,ye,Bs,rt,Jp,Rs,Qp,Aa,te,Zp,Fs,ef,tf,Ss,of,sf,Ia,Oe,zs,it,Vs,nf,af,Hs,lf,rf,F,pt,ft,Ws,pf,ff,Gs,df,cf,Ys,Us,hf,uf,dt,ct,Ks,mf,gf,Js,_f,vf,Qs,Zs,Ef,$f,ht,en,tn,wf,xf,on,sn,bf,kf,ut,nn,an,yf,Of,ln,rn,Tf,Nf,mt,gt,pn,jf,Cf,fn,Df,qf,dn,cn,Lf,Af,_t,hn,un,If,Pf,mn,gn,Mf,Xf,vt,_n,vn,Bf,Rf,En,$n,Ff,Pa,Te,Sf,Kt,zf,Vf,Ma,Et,Xa,oe,Hf,wn,Wf,Gf,xn,Yf,Uf,Ba,$t,Ra,Jt,Kf,Fa,wt,Sa,Y,Jf,bn,Qf,Zf,kn,ed,td,yn,od,sd,za,Ne,Va,je,Ha,he,Ce,On,xt,nd,Tn,ad,Wa,Qt,ld,Ga,se,Nn,rd,id,jn,pd,fd,Cn,dd,Ya,Zt,cd,Ua,ue,De,Dn,bt,hd,qn,ud,Ka,eo,md,Ja,ne,to,gd,oo,_d,vd,so,Ed,no,$d,wd,ao,xd,lo,bd,Qa,qe,Za,Le,kd,Ln,yd,Od,el,kt,tl,z,Td,An,Nd,jd,In,Cd,Dd,Pn,qd,Ld,Mn,Ad,Id,ol,Ae,sl,ro,Pd,nl,yt,al,io,Md,ll,Ot,rl,po,Xd,il,Tt,pl,V,Bd,Xn,Rd,Fd,Bn,Sd,zd,Rn,Vd,Hd,Fn,Wd,Gd,fl,Nt,dl,Ie,cl,me,Pe,Sn,jt,Yd,zn,Ud,hl,ae,Kd,Vn,Jd,Qd,Hn,Zd,ec,ul,Ct,ml,S,tc,Wn,oc,sc,Gn,nc,ac,Yn,lc,rc,Un,ic,pc,Kn,fc,dc,gl,Dt,_l,Me,vl,ge,Xe,Jn,qt,cc,Qn,hc,El,le,uc,Zn,mc,gc,ea,_c,vc,$l,Lt,wl,Be,Ec,fo,$c,wc,xl,_e,Re,ta,At,xc,oa,bc,bl,co,kc,kl,re,It,yc,sa,Oc,Tc,Nc,ho,jc,na,Cc,Dc,uo,qc,aa,Lc,yl,Fe,Ac,Pt,Ic,Pc,Ol;return _=new Ve({}),R=new Rt({props:{$$slots:{default:[dg]},$$scope:{ctx:M}}}),Ke=new Ve({}),Je=new X({props:{code:"pip install transformers[onnx]",highlighted:"pip install transformers[onnx]"}}),Qe=new X({props:{code:`python -m transformers.onnx --help

usage: Hugging Face Transformers ONNX exporter [-h] -m MODEL [--feature {causal-lm, ...}] [--opset OPSET] [--atol ATOL] output

positional arguments:
  output                Path indicating where to store generated ONNX model.

optional arguments:
  -h, --help            show this help message and exit
  -m MODEL, --model MODEL
                        Model ID on huggingface.co or path on disk to load model from.
  --feature {causal-lm, ...}
                        The type of features to export the model with.
  --opset OPSET         ONNX opset version to export the model with.
  --atol ATOL           Absolute difference tolerance when validating the model.`,highlighted:`python -m transformers.onnx --<span class="hljs-built_in">help</span>

usage: Hugging Face Transformers ONNX exporter [-h] -m MODEL [--feature {causal-lm, ...}] [--opset OPSET] [--atol ATOL] output

positional arguments:
  output                Path indicating <span class="hljs-built_in">where</span> to store generated ONNX model.

optional arguments:
  -h, --<span class="hljs-built_in">help</span>            show this <span class="hljs-built_in">help</span> message and <span class="hljs-built_in">exit</span>
  -m MODEL, --model MODEL
                        Model ID on huggingface.co or path on disk to load model from.
  --feature {causal-lm, ...}
                        The <span class="hljs-built_in">type</span> of features to <span class="hljs-built_in">export</span> the model with.
  --opset OPSET         ONNX opset version to <span class="hljs-built_in">export</span> the model with.
  --atol ATOL           Absolute difference tolerance when validating the model.`}}),Ze=new X({props:{code:"python -m transformers.onnx --model=distilbert-base-uncased onnx/",highlighted:"python -m transformers.onnx --model=distilbert-base-uncased onnx/"}}),et=new X({props:{code:`Validating ONNX model...
        -[\u2713] ONNX model output names match reference model ({'last_hidden_state'})
        - Validating ONNX Model output "last_hidden_state":
                -[\u2713] (2, 8, 768) matches (2, 8, 768)
                -[\u2713] all values close (atol: 1e-05)
All good, model saved at: onnx/model.onnx`,highlighted:`Validating ONNX model...
        -[\u2713] ONNX model output names match reference model ({<span class="hljs-string">&#x27;last_hidden_state&#x27;</span>})
        - Validating ONNX Model output <span class="hljs-string">&quot;last_hidden_state&quot;</span>:
                -[\u2713] (2, 8, 768) matches (2, 8, 768)
                -[\u2713] all values close (atol: 1e-05)
All good, model saved at: onnx/model.onnx`}}),st=new X({props:{code:`from transformers import AutoTokenizer
from onnxruntime import InferenceSession

tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
session = InferenceSession("onnx/model.onnx")
# ONNX Runtime expects NumPy arrays as input
inputs = tokenizer("Using DistilBERT with ONNX Runtime!", return_tensors="np")
outputs = session.run(output_names=["last_hidden_state"], input_feed=dict(inputs))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> onnxruntime <span class="hljs-keyword">import</span> InferenceSession

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>session = InferenceSession(<span class="hljs-string">&quot;onnx/model.onnx&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># ONNX Runtime expects NumPy arrays as input</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Using DistilBERT with ONNX Runtime!&quot;</span>, return_tensors=<span class="hljs-string">&quot;np&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = session.run(output_names=[<span class="hljs-string">&quot;last_hidden_state&quot;</span>], input_feed=<span class="hljs-built_in">dict</span>(inputs))`}}),nt=new X({props:{code:`from transformers.models.distilbert import DistilBertConfig, DistilBertOnnxConfig

config = DistilBertConfig()
onnx_config = DistilBertOnnxConfig(config)
print(list(onnx_config.outputs.keys()))`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.models.distilbert <span class="hljs-keyword">import</span> DistilBertConfig, DistilBertOnnxConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = DistilBertConfig()
<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_config = DistilBertOnnxConfig(config)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-built_in">list</span>(onnx_config.outputs.keys()))
[<span class="hljs-string">&quot;last_hidden_state&quot;</span>]`}}),lt=new X({props:{code:"python -m transformers.onnx --model=keras-io/transformers-qa onnx/",highlighted:"python -m transformers.onnx --model=keras-io/transformers-qa onnx/"}}),ke=new fg({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[mg],pytorch:[hg]},$$scope:{ctx:M}}}),rt=new Ve({}),Et=new X({props:{code:`from transformers.onnx.features import FeaturesManager

distilbert_features = list(FeaturesManager.get_supported_features_for_model_type("distilbert").keys())
print(distilbert_features)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.onnx.features <span class="hljs-keyword">import</span> FeaturesManager

<span class="hljs-meta">&gt;&gt;&gt; </span>distilbert_features = <span class="hljs-built_in">list</span>(FeaturesManager.get_supported_features_for_model_type(<span class="hljs-string">&quot;distilbert&quot;</span>).keys())
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(distilbert_features)
[<span class="hljs-string">&quot;default&quot;</span>, <span class="hljs-string">&quot;masked-lm&quot;</span>, <span class="hljs-string">&quot;causal-lm&quot;</span>, <span class="hljs-string">&quot;sequence-classification&quot;</span>, <span class="hljs-string">&quot;token-classification&quot;</span>, <span class="hljs-string">&quot;question-answering&quot;</span>]`}}),$t=new X({props:{code:`python -m transformers.onnx --model=distilbert-base-uncased-finetuned-sst-2-english \\
                            --feature=sequence-classification onnx/`,highlighted:`python -m transformers.onnx --model=distilbert-base-uncased-finetuned-sst-2-english \\
                            --feature=sequence-classification onnx/`}}),wt=new X({props:{code:`Validating ONNX model...
        -[\u2713] ONNX model output names match reference model ({'logits'})
        - Validating ONNX Model output "logits":
                -[\u2713] (2, 2) matches (2, 2)
                -[\u2713] all values close (atol: 1e-05)
All good, model saved at: onnx/model.onnx`,highlighted:`Validating ONNX model...
        -[\u2713] ONNX model output names match reference model ({<span class="hljs-string">&#x27;logits&#x27;</span>})
        - Validating ONNX Model output <span class="hljs-string">&quot;logits&quot;</span>:
                -[\u2713] (2, 2) matches (2, 2)
                -[\u2713] all values close (atol: 1e-05)
All good, model saved at: onnx/model.onnx`}}),Ne=new Rt({props:{$$slots:{default:[gg]},$$scope:{ctx:M}}}),je=new Rt({props:{$$slots:{default:[_g]},$$scope:{ctx:M}}}),xt=new Ve({}),bt=new Ve({}),qe=new Rt({props:{$$slots:{default:[vg]},$$scope:{ctx:M}}}),kt=new X({props:{code:`from typing import Mapping, OrderedDict
from transformers.onnx import OnnxConfig


class DistilBertOnnxConfig(OnnxConfig):
    @property
    def inputs(self) -> Mapping[str, Mapping[int, str]]:
        return OrderedDict(
            [
                ("input_ids", {0: "batch", 1: "sequence"}),
                ("attention_mask", {0: "batch", 1: "sequence"}),
            ]
        )`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> Mapping, OrderedDict
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.onnx <span class="hljs-keyword">import</span> OnnxConfig


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">class</span> <span class="hljs-title class_">DistilBertOnnxConfig</span>(<span class="hljs-title class_ inherited__">OnnxConfig</span>):
<span class="hljs-meta">... </span>    @<span class="hljs-built_in">property</span>
<span class="hljs-meta">... </span>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">inputs</span>(<span class="hljs-params">self</span>) -&gt; Mapping[<span class="hljs-built_in">str</span>, Mapping[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">str</span>]]:
<span class="hljs-meta">... </span>        <span class="hljs-keyword">return</span> OrderedDict(
<span class="hljs-meta">... </span>            [
<span class="hljs-meta">... </span>                (<span class="hljs-string">&quot;input_ids&quot;</span>, {<span class="hljs-number">0</span>: <span class="hljs-string">&quot;batch&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;sequence&quot;</span>}),
<span class="hljs-meta">... </span>                (<span class="hljs-string">&quot;attention_mask&quot;</span>, {<span class="hljs-number">0</span>: <span class="hljs-string">&quot;batch&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;sequence&quot;</span>}),
<span class="hljs-meta">... </span>            ]
<span class="hljs-meta">... </span>        )`}}),Ae=new Rt({props:{$$slots:{default:[Eg]},$$scope:{ctx:M}}}),yt=new X({props:{code:`from transformers import AutoConfig

config = AutoConfig.from_pretrained("distilbert-base-uncased")
onnx_config = DistilBertOnnxConfig(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_config = DistilBertOnnxConfig(config)`}}),Ot=new X({props:{code:"print(onnx_config.default_onnx_opset)",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(onnx_config.default_onnx_opset)
<span class="hljs-number">11</span>`}}),Tt=new X({props:{code:"print(onnx_config.outputs)",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(onnx_config.outputs)
OrderedDict([(<span class="hljs-string">&quot;last_hidden_state&quot;</span>, {<span class="hljs-number">0</span>: <span class="hljs-string">&quot;batch&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;sequence&quot;</span>})])`}}),Nt=new X({props:{code:`from transformers import AutoConfig

config = AutoConfig.from_pretrained("distilbert-base-uncased")
onnx_config_for_seq_clf = DistilBertOnnxConfig(config, task="sequence-classification")
print(onnx_config_for_seq_clf.outputs)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_config_for_seq_clf = DistilBertOnnxConfig(config, task=<span class="hljs-string">&quot;sequence-classification&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(onnx_config_for_seq_clf.outputs)
OrderedDict([(<span class="hljs-string">&#x27;logits&#x27;</span>, {<span class="hljs-number">0</span>: <span class="hljs-string">&#x27;batch&#x27;</span>})])`}}),Ie=new Rt({props:{$$slots:{default:[$g]},$$scope:{ctx:M}}}),jt=new Ve({}),Ct=new X({props:{code:`from pathlib import Path
from transformers.onnx import export
from transformers import AutoTokenizer, AutoModel

onnx_path = Path("model.onnx")
model_ckpt = "distilbert-base-uncased"
base_model = AutoModel.from_pretrained(model_ckpt)
tokenizer = AutoTokenizer.from_pretrained(model_ckpt)

onnx_inputs, onnx_outputs = export(tokenizer, base_model, onnx_config, onnx_config.default_onnx_opset, onnx_path)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.onnx <span class="hljs-keyword">import</span> export
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_path = Path(<span class="hljs-string">&quot;model.onnx&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model_ckpt = <span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>base_model = AutoModel.from_pretrained(model_ckpt)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_ckpt)

<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_inputs, onnx_outputs = export(tokenizer, base_model, onnx_config, onnx_config.default_onnx_opset, onnx_path)`}}),Dt=new X({props:{code:`import onnx

onnx_model = onnx.load("model.onnx")
onnx.checker.check_model(onnx_model)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> onnx

<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_model = onnx.load(<span class="hljs-string">&quot;model.onnx&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>onnx.checker.check_model(onnx_model)`}}),Me=new Rt({props:{$$slots:{default:[wg]},$$scope:{ctx:M}}}),qt=new Ve({}),Lt=new X({props:{code:`from transformers.onnx import validate_model_outputs

validate_model_outputs(
    onnx_config, tokenizer, base_model, onnx_path, onnx_outputs, onnx_config.atol_for_validation
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.onnx <span class="hljs-keyword">import</span> validate_model_outputs

<span class="hljs-meta">&gt;&gt;&gt; </span>validate_model_outputs(
<span class="hljs-meta">... </span>    onnx_config, tokenizer, base_model, onnx_path, onnx_outputs, onnx_config.atol_for_validation
<span class="hljs-meta">... </span>)`}}),At=new Ve({}),{c(){c=a("meta"),$=p(),m=a("h1"),E=a("a"),w=a("span"),j(_.$$.fragment),x=p(),b=a("span"),k=s("Export to ONNX"),T=p(),I=a("p"),y=s(`If you need to deploy \u{1F917} Transformers models in production environments, we recommend
exporting them to a serialized format that can be loaded and executed on specialized
runtimes and hardware. In this guide, we\u2019ll show you how to export \u{1F917} Transformers
models to `),O=a("a"),g=s("ONNX (Open Neural Network eXchange)"),N=s("."),B=p(),j(R.$$.fragment),Q=p(),W=a("p"),He=s(`ONNX is an open standard that defines a common set of operators and a common file format
to represent deep learning models in a wide variety of frameworks, including PyTorch and
TensorFlow. When a model is exported to the ONNX format, these operators are used to
construct a computational graph (often called an `),K=a("em"),We=s("intermediate representation"),Ge=s(`) which
represents the flow of data through the neural network.`),Z=p(),P=a("p"),Ft=s(`By exposing a graph with standardized operators and data types, ONNX makes it easy to
switch between frameworks. For example, a model trained in PyTorch can be exported to
ONNX format and then imported in TensorFlow (and vice versa).`),Ye=p(),J=a("p"),St=s("\u{1F917} Transformers provides a "),fe=a("a"),ve=a("code"),zt=s("transformers.onnx"),sr=s(` package that enables
you to convert model checkpoints to an ONNX graph by leveraging configuration objects.
These configuration objects come ready made for a number of model architectures, and are
designed to be easily extendable to other architectures.`),da=p(),Vt=a("p"),nr=s("Ready-made configurations include the following architectures:"),ca=p(),h=a("ul"),bo=a("li"),ar=s("ALBERT"),lr=p(),ko=a("li"),rr=s("BART"),ir=p(),yo=a("li"),pr=s("BEiT"),fr=p(),Oo=a("li"),dr=s("BERT"),cr=p(),To=a("li"),hr=s("BigBird"),ur=p(),No=a("li"),mr=s("BigBird-Pegasus"),gr=p(),jo=a("li"),_r=s("Blenderbot"),vr=p(),Co=a("li"),Er=s("BlenderbotSmall"),$r=p(),Do=a("li"),wr=s("BLOOM"),xr=p(),qo=a("li"),br=s("CamemBERT"),kr=p(),Lo=a("li"),yr=s("CLIP"),Or=p(),Ao=a("li"),Tr=s("CodeGen"),Nr=p(),Io=a("li"),jr=s("Conditional DETR"),Cr=p(),Po=a("li"),Dr=s("ConvBERT"),qr=p(),Mo=a("li"),Lr=s("ConvNeXT"),Ar=p(),Xo=a("li"),Ir=s("Data2VecText"),Pr=p(),Bo=a("li"),Mr=s("Data2VecVision"),Xr=p(),Ro=a("li"),Br=s("DeBERTa"),Rr=p(),Fo=a("li"),Fr=s("DeBERTa-v2"),Sr=p(),So=a("li"),zr=s("DeiT"),Vr=p(),zo=a("li"),Hr=s("DETR"),Wr=p(),Vo=a("li"),Gr=s("DistilBERT"),Yr=p(),Ho=a("li"),Ur=s("ELECTRA"),Kr=p(),Wo=a("li"),Jr=s("ERNIE"),Qr=p(),Go=a("li"),Zr=s("FlauBERT"),ei=p(),Yo=a("li"),ti=s("GPT Neo"),oi=p(),Uo=a("li"),si=s("GPT-J"),ni=p(),Ko=a("li"),ai=s("GroupViT"),li=p(),Jo=a("li"),ri=s("I-BERT"),ii=p(),Qo=a("li"),pi=s("ImageGPT"),fi=p(),Zo=a("li"),di=s("LayoutLM"),ci=p(),es=a("li"),hi=s("LayoutLMv3"),ui=p(),ts=a("li"),mi=s("LeViT"),gi=p(),os=a("li"),_i=s("Longformer"),vi=p(),ss=a("li"),Ei=s("LongT5"),$i=p(),ns=a("li"),wi=s("M2M100"),xi=p(),as=a("li"),bi=s("Marian"),ki=p(),ls=a("li"),yi=s("mBART"),Oi=p(),rs=a("li"),Ti=s("MobileBERT"),Ni=p(),is=a("li"),ji=s("MobileNetV2"),Ci=p(),ps=a("li"),Di=s("MobileViT"),qi=p(),fs=a("li"),Li=s("MT5"),Ai=p(),ds=a("li"),Ii=s("OpenAI GPT-2"),Pi=p(),cs=a("li"),Mi=s("OWL-ViT"),Xi=p(),hs=a("li"),Bi=s("Perceiver"),Ri=p(),us=a("li"),Fi=s("PLBart"),Si=p(),ms=a("li"),zi=s("ResNet"),Vi=p(),gs=a("li"),Hi=s("RoBERTa"),Wi=p(),_s=a("li"),Gi=s("RoFormer"),Yi=p(),vs=a("li"),Ui=s("SegFormer"),Ki=p(),Es=a("li"),Ji=s("SqueezeBERT"),Qi=p(),$s=a("li"),Zi=s("Swin Transformer"),ep=p(),ws=a("li"),tp=s("T5"),op=p(),xs=a("li"),sp=s("Table Transformer"),np=p(),bs=a("li"),ap=s("Vision Encoder decoder"),lp=p(),ks=a("li"),rp=s("ViT"),ip=p(),ys=a("li"),pp=s("Whisper"),fp=p(),Os=a("li"),dp=s("XLM"),cp=p(),Ts=a("li"),hp=s("XLM-RoBERTa"),up=p(),Ns=a("li"),mp=s("XLM-RoBERTa-XL"),gp=p(),js=a("li"),_p=s("YOLOS"),ha=p(),Ht=a("p"),vp=s("In the next two sections, we\u2019ll show you how to:"),ua=p(),Ee=a("ul"),Ue=a("li"),Ep=s("Export a supported model using the "),Cs=a("code"),$p=s("transformers.onnx"),wp=s(" package."),xp=p(),Ds=a("li"),bp=s("Export a custom model for an unsupported architecture."),ma=p(),de=a("h2"),$e=a("a"),qs=a("span"),j(Ke.$$.fragment),kp=p(),Ls=a("span"),yp=s("Exporting a model to ONNX"),ga=p(),Wt=a("p"),Op=s(`To export a \u{1F917} Transformers model to ONNX, you\u2019ll first need to install some extra
dependencies:`),_a=p(),j(Je.$$.fragment),va=p(),we=a("p"),Tp=s("The "),As=a("code"),Np=s("transformers.onnx"),jp=s(" package can then be used as a Python module:"),Ea=p(),j(Qe.$$.fragment),$a=p(),Gt=a("p"),Cp=s("Exporting a checkpoint using a ready-made configuration can be done as follows:"),wa=p(),j(Ze.$$.fragment),xa=p(),Yt=a("p"),Dp=s("You should see the following logs:"),ba=p(),j(et.$$.fragment),ka=p(),ee=a("p"),qp=s("This exports an ONNX graph of the checkpoint defined by the "),Is=a("code"),Lp=s("--model"),Ap=s(` argument. In this
example, it is `),Ps=a("code"),Ip=s("distilbert-base-uncased"),Pp=s(`, but it can be any checkpoint on the Hugging
Face Hub or one that\u2019s stored locally.`),ya=p(),G=a("p"),Mp=s("The resulting "),Ms=a("code"),Xp=s("model.onnx"),Bp=s(" file can then be run on one of the "),tt=a("a"),Rp=s(`many
accelerators`),Fp=s(` that support the ONNX
standard. For example, we can load and run the model with `),ot=a("a"),Sp=s(`ONNX
Runtime`),zp=s(" as follows:"),Oa=p(),j(st.$$.fragment),Ta=p(),xe=a("p"),Vp=s("The required output names (like "),Xs=a("code"),Hp=s('["last_hidden_state"]'),Wp=s(`) can be obtained by taking a
look at the ONNX configuration of each model. For example, for DistilBERT we have:`),Na=p(),j(nt.$$.fragment),ja=p(),be=a("p"),Gp=s(`The process is identical for TensorFlow checkpoints on the Hub. For example, we can
export a pure TensorFlow checkpoint from the `),at=a("a"),Yp=s(`Keras
organization`),Up=s(" as follows:"),Ca=p(),j(lt.$$.fragment),Da=p(),Ut=a("p"),Kp=s(`To export a model that\u2019s stored locally, you\u2019ll need to have the model\u2019s weights and
tokenizer files stored in a directory. For example, we can load and save a checkpoint as
follows:`),qa=p(),j(ke.$$.fragment),La=p(),ce=a("h2"),ye=a("a"),Bs=a("span"),j(rt.$$.fragment),Jp=p(),Rs=a("span"),Qp=s("Selecting features for different model tasks"),Aa=p(),te=a("p"),Zp=s("Each ready-made configuration comes with a set of "),Fs=a("em"),ef=s("features"),tf=s(` that enable you to export
models for different types of tasks. As shown in the table below, each feature is
associated with a different `),Ss=a("code"),of=s("AutoClass"),sf=s(":"),Ia=p(),Oe=a("table"),zs=a("thead"),it=a("tr"),Vs=a("th"),nf=s("Feature"),af=p(),Hs=a("th"),lf=s("Auto Class"),rf=p(),F=a("tbody"),pt=a("tr"),ft=a("td"),Ws=a("code"),pf=s("causal-lm"),ff=s(", "),Gs=a("code"),df=s("causal-lm-with-past"),cf=p(),Ys=a("td"),Us=a("code"),hf=s("AutoModelForCausalLM"),uf=p(),dt=a("tr"),ct=a("td"),Ks=a("code"),mf=s("default"),gf=s(", "),Js=a("code"),_f=s("default-with-past"),vf=p(),Qs=a("td"),Zs=a("code"),Ef=s("AutoModel"),$f=p(),ht=a("tr"),en=a("td"),tn=a("code"),wf=s("masked-lm"),xf=p(),on=a("td"),sn=a("code"),bf=s("AutoModelForMaskedLM"),kf=p(),ut=a("tr"),nn=a("td"),an=a("code"),yf=s("question-answering"),Of=p(),ln=a("td"),rn=a("code"),Tf=s("AutoModelForQuestionAnswering"),Nf=p(),mt=a("tr"),gt=a("td"),pn=a("code"),jf=s("seq2seq-lm"),Cf=s(", "),fn=a("code"),Df=s("seq2seq-lm-with-past"),qf=p(),dn=a("td"),cn=a("code"),Lf=s("AutoModelForSeq2SeqLM"),Af=p(),_t=a("tr"),hn=a("td"),un=a("code"),If=s("sequence-classification"),Pf=p(),mn=a("td"),gn=a("code"),Mf=s("AutoModelForSequenceClassification"),Xf=p(),vt=a("tr"),_n=a("td"),vn=a("code"),Bf=s("token-classification"),Rf=p(),En=a("td"),$n=a("code"),Ff=s("AutoModelForTokenClassification"),Pa=p(),Te=a("p"),Sf=s(`For each configuration, you can find the list of supported features via the
`),Kt=a("a"),zf=s("FeaturesManager"),Vf=s(". For example, for DistilBERT we have:"),Ma=p(),j(Et.$$.fragment),Xa=p(),oe=a("p"),Hf=s("You can then pass one of these features to the "),wn=a("code"),Wf=s("--feature"),Gf=s(` argument in the
`),xn=a("code"),Yf=s("transformers.onnx"),Uf=s(` package. For example, to export a text-classification model we can
pick a fine-tuned model from the Hub and run:`),Ba=p(),j($t.$$.fragment),Ra=p(),Jt=a("p"),Kf=s("This displays the following logs:"),Fa=p(),j(wt.$$.fragment),Sa=p(),Y=a("p"),Jf=s("Notice that in this case, the output names from the fine-tuned model are "),bn=a("code"),Qf=s("logits"),Zf=s(`
instead of the `),kn=a("code"),ed=s("last_hidden_state"),td=s(" we saw with the "),yn=a("code"),od=s("distilbert-base-uncased"),sd=s(` checkpoint
earlier. This is expected since the fine-tuned model has a sequence classification head.`),za=p(),j(Ne.$$.fragment),Va=p(),j(je.$$.fragment),Ha=p(),he=a("h2"),Ce=a("a"),On=a("span"),j(xt.$$.fragment),nd=p(),Tn=a("span"),ad=s("Exporting a model for an unsupported architecture"),Wa=p(),Qt=a("p"),ld=s(`If you wish to export a model whose architecture is not natively supported by the
library, there are three main steps to follow:`),Ga=p(),se=a("ol"),Nn=a("li"),rd=s("Implement a custom ONNX configuration."),id=p(),jn=a("li"),pd=s("Export the model to ONNX."),fd=p(),Cn=a("li"),dd=s("Validate the outputs of the PyTorch and exported models."),Ya=p(),Zt=a("p"),cd=s(`In this section, we\u2019ll look at how DistilBERT was implemented to show what\u2019s involved
with each step.`),Ua=p(),ue=a("h3"),De=a("a"),Dn=a("span"),j(bt.$$.fragment),hd=p(),qn=a("span"),ud=s("Implementing a custom ONNX configuration"),Ka=p(),eo=a("p"),md=s(`Let\u2019s start with the ONNX configuration object. We provide three abstract classes that
you should inherit from, depending on the type of model architecture you wish to export:`),Ja=p(),ne=a("ul"),to=a("li"),gd=s("Encoder-based models inherit from "),oo=a("a"),_d=s("OnnxConfig"),vd=p(),so=a("li"),Ed=s("Decoder-based models inherit from "),no=a("a"),$d=s("OnnxConfigWithPast"),wd=p(),ao=a("li"),xd=s("Encoder-decoder models inherit from "),lo=a("a"),bd=s("OnnxSeq2SeqConfigWithPast"),Qa=p(),j(qe.$$.fragment),Za=p(),Le=a("p"),kd=s(`Since DistilBERT is an encoder-based model, its configuration inherits from
`),Ln=a("code"),yd=s("OnnxConfig"),Od=s(":"),el=p(),j(kt.$$.fragment),tl=p(),z=a("p"),Td=s("Every configuration object must implement the "),An=a("code"),Nd=s("inputs"),jd=s(` property and return a mapping,
where each key corresponds to an expected input, and each value indicates the axis of
that input. For DistilBERT, we can see that two inputs are required: `),In=a("code"),Cd=s("input_ids"),Dd=s(` and
`),Pn=a("code"),qd=s("attention_mask"),Ld=s(". These inputs have the same shape of "),Mn=a("code"),Ad=s("(batch_size, sequence_length)"),Id=s(`
which is why we see the same axes used in the configuration.`),ol=p(),j(Ae.$$.fragment),sl=p(),ro=a("p"),Pd=s(`Once you have implemented an ONNX configuration, you can instantiate it by providing the
base model\u2019s configuration as follows:`),nl=p(),j(yt.$$.fragment),al=p(),io=a("p"),Md=s(`The resulting object has several useful properties. For example, you can view the ONNX
operator set that will be used during the export:`),ll=p(),j(Ot.$$.fragment),rl=p(),po=a("p"),Xd=s("You can also view the outputs associated with the model as follows:"),il=p(),j(Tt.$$.fragment),pl=p(),V=a("p"),Bd=s(`Notice that the outputs property follows the same structure as the inputs; it returns an
`),Xn=a("code"),Rd=s("OrderedDict"),Fd=s(` of named outputs and their shapes. The output structure is linked to the
choice of feature that the configuration is initialised with. By default, the ONNX
configuration is initialized with the `),Bn=a("code"),Sd=s("default"),zd=s(` feature that corresponds to exporting a
model loaded with the `),Rn=a("code"),Vd=s("AutoModel"),Hd=s(` class. If you want to export a model for another task,
just provide a different feature to the `),Fn=a("code"),Wd=s("task"),Gd=s(` argument when you initialize the ONNX
configuration. For example, if we wished to export DistilBERT with a sequence
classification head, we could use:`),fl=p(),j(Nt.$$.fragment),dl=p(),j(Ie.$$.fragment),cl=p(),me=a("h3"),Pe=a("a"),Sn=a("span"),j(jt.$$.fragment),Yd=p(),zn=a("span"),Ud=s("Exporting the model"),hl=p(),ae=a("p"),Kd=s(`Once you have implemented the ONNX configuration, the next step is to export the model.
Here we can use the `),Vn=a("code"),Jd=s("export()"),Qd=s(" function provided by the "),Hn=a("code"),Zd=s("transformers.onnx"),ec=s(` package.
This function expects the ONNX configuration, along with the base model and tokenizer,
and the path to save the exported file:`),ul=p(),j(Ct.$$.fragment),ml=p(),S=a("p"),tc=s("The "),Wn=a("code"),oc=s("onnx_inputs"),sc=s(" and "),Gn=a("code"),nc=s("onnx_outputs"),ac=s(" returned by the "),Yn=a("code"),lc=s("export()"),rc=s(` function are lists of
the keys defined in the `),Un=a("code"),ic=s("inputs"),pc=s(" and "),Kn=a("code"),fc=s("outputs"),dc=s(` properties of the configuration. Once the
model is exported, you can test that the model is well formed as follows:`),gl=p(),j(Dt.$$.fragment),_l=p(),j(Me.$$.fragment),vl=p(),ge=a("h3"),Xe=a("a"),Jn=a("span"),j(qt.$$.fragment),cc=p(),Qn=a("span"),hc=s("Validating the model outputs"),El=p(),le=a("p"),uc=s(`The final step is to validate that the outputs from the base and exported model agree
within some absolute tolerance. Here we can use the `),Zn=a("code"),mc=s("validate_model_outputs()"),gc=s(` function
provided by the `),ea=a("code"),_c=s("transformers.onnx"),vc=s(" package as follows:"),$l=p(),j(Lt.$$.fragment),wl=p(),Be=a("p"),Ec=s("This function uses the "),fo=a("a"),$c=s("generate_dummy_inputs()"),wc=s(` method to
generate inputs for the base and exported model, and the absolute tolerance can be
defined in the configuration. We generally find numerical agreement in the 1e-6 to 1e-4
range, although anything smaller than 1e-3 is likely to be OK.`),xl=p(),_e=a("h2"),Re=a("a"),ta=a("span"),j(At.$$.fragment),xc=p(),oa=a("span"),bc=s("Contributing a new configuration to \u{1F917} Transformers"),bl=p(),co=a("p"),kc=s(`We are looking to expand the set of ready-made configurations and welcome contributions
from the community! If you would like to contribute your addition to the library, you
will need to:`),kl=p(),re=a("ul"),It=a("li"),yc=s("Implement the ONNX configuration in the corresponding "),sa=a("code"),Oc=s("configuration_<model_name>.py"),Tc=s(`
file`),Nc=p(),ho=a("li"),jc=s(`Include the model architecture and corresponding features in
`),na=a("code"),Cc=s("~onnx.features.FeatureManager"),Dc=p(),uo=a("li"),qc=s("Add your model architecture to the tests in "),aa=a("code"),Lc=s("test_onnx_v2.py"),yl=p(),Fe=a("p"),Ac=s("Check out how the configuration for "),Pt=a("a"),Ic=s(`IBERT was
contributed`),Pc=s(` to get an
idea of what\u2019s involved.`),this.h()},l(t){const i=ig('[data-svelte="svelte-1phssyn"]',document.head);c=l(i,"META",{name:!0,content:!0}),i.forEach(o),$=f(t),m=l(t,"H1",{class:!0});var Mt=r(m);E=l(Mt,"A",{id:!0,class:!0,href:!0});var la=r(E);w=l(la,"SPAN",{});var ra=r(w);C(_.$$.fragment,ra),ra.forEach(o),la.forEach(o),x=f(Mt),b=l(Mt,"SPAN",{});var ia=r(b);k=n(ia,"Export to ONNX"),ia.forEach(o),Mt.forEach(o),T=f(t),I=l(t,"P",{});var Xt=r(I);y=n(Xt,`If you need to deploy \u{1F917} Transformers models in production environments, we recommend
exporting them to a serialized format that can be loaded and executed on specialized
runtimes and hardware. In this guide, we\u2019ll show you how to export \u{1F917} Transformers
models to `),O=l(Xt,"A",{href:!0,rel:!0});var pa=r(O);g=n(pa,"ONNX (Open Neural Network eXchange)"),pa.forEach(o),N=n(Xt,"."),Xt.forEach(o),B=f(t),C(R.$$.fragment,t),Q=f(t),W=l(t,"P",{});var Bt=r(W);He=n(Bt,`ONNX is an open standard that defines a common set of operators and a common file format
to represent deep learning models in a wide variety of frameworks, including PyTorch and
TensorFlow. When a model is exported to the ONNX format, these operators are used to
construct a computational graph (often called an `),K=l(Bt,"EM",{});var fa=r(K);We=n(fa,"intermediate representation"),fa.forEach(o),Ge=n(Bt,`) which
represents the flow of data through the neural network.`),Bt.forEach(o),Z=f(t),P=l(t,"P",{});var Sc=r(P);Ft=n(Sc,`By exposing a graph with standardized operators and data types, ONNX makes it easy to
switch between frameworks. For example, a model trained in PyTorch can be exported to
ONNX format and then imported in TensorFlow (and vice versa).`),Sc.forEach(o),Ye=f(t),J=l(t,"P",{});var Tl=r(J);St=n(Tl,"\u{1F917} Transformers provides a "),fe=l(Tl,"A",{href:!0});var zc=r(fe);ve=l(zc,"CODE",{});var Vc=r(ve);zt=n(Vc,"transformers.onnx"),Vc.forEach(o),zc.forEach(o),sr=n(Tl,` package that enables
you to convert model checkpoints to an ONNX graph by leveraging configuration objects.
These configuration objects come ready made for a number of model architectures, and are
designed to be easily extendable to other architectures.`),Tl.forEach(o),da=f(t),Vt=l(t,"P",{});var Hc=r(Vt);nr=n(Hc,"Ready-made configurations include the following architectures:"),Hc.forEach(o),ca=f(t),h=l(t,"UL",{});var u=r(h);bo=l(u,"LI",{});var Wc=r(bo);ar=n(Wc,"ALBERT"),Wc.forEach(o),lr=f(u),ko=l(u,"LI",{});var Gc=r(ko);rr=n(Gc,"BART"),Gc.forEach(o),ir=f(u),yo=l(u,"LI",{});var Yc=r(yo);pr=n(Yc,"BEiT"),Yc.forEach(o),fr=f(u),Oo=l(u,"LI",{});var Uc=r(Oo);dr=n(Uc,"BERT"),Uc.forEach(o),cr=f(u),To=l(u,"LI",{});var Kc=r(To);hr=n(Kc,"BigBird"),Kc.forEach(o),ur=f(u),No=l(u,"LI",{});var Jc=r(No);mr=n(Jc,"BigBird-Pegasus"),Jc.forEach(o),gr=f(u),jo=l(u,"LI",{});var Qc=r(jo);_r=n(Qc,"Blenderbot"),Qc.forEach(o),vr=f(u),Co=l(u,"LI",{});var Zc=r(Co);Er=n(Zc,"BlenderbotSmall"),Zc.forEach(o),$r=f(u),Do=l(u,"LI",{});var eh=r(Do);wr=n(eh,"BLOOM"),eh.forEach(o),xr=f(u),qo=l(u,"LI",{});var th=r(qo);br=n(th,"CamemBERT"),th.forEach(o),kr=f(u),Lo=l(u,"LI",{});var oh=r(Lo);yr=n(oh,"CLIP"),oh.forEach(o),Or=f(u),Ao=l(u,"LI",{});var sh=r(Ao);Tr=n(sh,"CodeGen"),sh.forEach(o),Nr=f(u),Io=l(u,"LI",{});var nh=r(Io);jr=n(nh,"Conditional DETR"),nh.forEach(o),Cr=f(u),Po=l(u,"LI",{});var ah=r(Po);Dr=n(ah,"ConvBERT"),ah.forEach(o),qr=f(u),Mo=l(u,"LI",{});var lh=r(Mo);Lr=n(lh,"ConvNeXT"),lh.forEach(o),Ar=f(u),Xo=l(u,"LI",{});var rh=r(Xo);Ir=n(rh,"Data2VecText"),rh.forEach(o),Pr=f(u),Bo=l(u,"LI",{});var ih=r(Bo);Mr=n(ih,"Data2VecVision"),ih.forEach(o),Xr=f(u),Ro=l(u,"LI",{});var ph=r(Ro);Br=n(ph,"DeBERTa"),ph.forEach(o),Rr=f(u),Fo=l(u,"LI",{});var fh=r(Fo);Fr=n(fh,"DeBERTa-v2"),fh.forEach(o),Sr=f(u),So=l(u,"LI",{});var dh=r(So);zr=n(dh,"DeiT"),dh.forEach(o),Vr=f(u),zo=l(u,"LI",{});var ch=r(zo);Hr=n(ch,"DETR"),ch.forEach(o),Wr=f(u),Vo=l(u,"LI",{});var hh=r(Vo);Gr=n(hh,"DistilBERT"),hh.forEach(o),Yr=f(u),Ho=l(u,"LI",{});var uh=r(Ho);Ur=n(uh,"ELECTRA"),uh.forEach(o),Kr=f(u),Wo=l(u,"LI",{});var mh=r(Wo);Jr=n(mh,"ERNIE"),mh.forEach(o),Qr=f(u),Go=l(u,"LI",{});var gh=r(Go);Zr=n(gh,"FlauBERT"),gh.forEach(o),ei=f(u),Yo=l(u,"LI",{});var _h=r(Yo);ti=n(_h,"GPT Neo"),_h.forEach(o),oi=f(u),Uo=l(u,"LI",{});var vh=r(Uo);si=n(vh,"GPT-J"),vh.forEach(o),ni=f(u),Ko=l(u,"LI",{});var Eh=r(Ko);ai=n(Eh,"GroupViT"),Eh.forEach(o),li=f(u),Jo=l(u,"LI",{});var $h=r(Jo);ri=n($h,"I-BERT"),$h.forEach(o),ii=f(u),Qo=l(u,"LI",{});var wh=r(Qo);pi=n(wh,"ImageGPT"),wh.forEach(o),fi=f(u),Zo=l(u,"LI",{});var xh=r(Zo);di=n(xh,"LayoutLM"),xh.forEach(o),ci=f(u),es=l(u,"LI",{});var bh=r(es);hi=n(bh,"LayoutLMv3"),bh.forEach(o),ui=f(u),ts=l(u,"LI",{});var kh=r(ts);mi=n(kh,"LeViT"),kh.forEach(o),gi=f(u),os=l(u,"LI",{});var yh=r(os);_i=n(yh,"Longformer"),yh.forEach(o),vi=f(u),ss=l(u,"LI",{});var Oh=r(ss);Ei=n(Oh,"LongT5"),Oh.forEach(o),$i=f(u),ns=l(u,"LI",{});var Th=r(ns);wi=n(Th,"M2M100"),Th.forEach(o),xi=f(u),as=l(u,"LI",{});var Nh=r(as);bi=n(Nh,"Marian"),Nh.forEach(o),ki=f(u),ls=l(u,"LI",{});var jh=r(ls);yi=n(jh,"mBART"),jh.forEach(o),Oi=f(u),rs=l(u,"LI",{});var Ch=r(rs);Ti=n(Ch,"MobileBERT"),Ch.forEach(o),Ni=f(u),is=l(u,"LI",{});var Dh=r(is);ji=n(Dh,"MobileNetV2"),Dh.forEach(o),Ci=f(u),ps=l(u,"LI",{});var qh=r(ps);Di=n(qh,"MobileViT"),qh.forEach(o),qi=f(u),fs=l(u,"LI",{});var Lh=r(fs);Li=n(Lh,"MT5"),Lh.forEach(o),Ai=f(u),ds=l(u,"LI",{});var Ah=r(ds);Ii=n(Ah,"OpenAI GPT-2"),Ah.forEach(o),Pi=f(u),cs=l(u,"LI",{});var Ih=r(cs);Mi=n(Ih,"OWL-ViT"),Ih.forEach(o),Xi=f(u),hs=l(u,"LI",{});var Ph=r(hs);Bi=n(Ph,"Perceiver"),Ph.forEach(o),Ri=f(u),us=l(u,"LI",{});var Mh=r(us);Fi=n(Mh,"PLBart"),Mh.forEach(o),Si=f(u),ms=l(u,"LI",{});var Xh=r(ms);zi=n(Xh,"ResNet"),Xh.forEach(o),Vi=f(u),gs=l(u,"LI",{});var Bh=r(gs);Hi=n(Bh,"RoBERTa"),Bh.forEach(o),Wi=f(u),_s=l(u,"LI",{});var Rh=r(_s);Gi=n(Rh,"RoFormer"),Rh.forEach(o),Yi=f(u),vs=l(u,"LI",{});var Fh=r(vs);Ui=n(Fh,"SegFormer"),Fh.forEach(o),Ki=f(u),Es=l(u,"LI",{});var Sh=r(Es);Ji=n(Sh,"SqueezeBERT"),Sh.forEach(o),Qi=f(u),$s=l(u,"LI",{});var zh=r($s);Zi=n(zh,"Swin Transformer"),zh.forEach(o),ep=f(u),ws=l(u,"LI",{});var Vh=r(ws);tp=n(Vh,"T5"),Vh.forEach(o),op=f(u),xs=l(u,"LI",{});var Hh=r(xs);sp=n(Hh,"Table Transformer"),Hh.forEach(o),np=f(u),bs=l(u,"LI",{});var Wh=r(bs);ap=n(Wh,"Vision Encoder decoder"),Wh.forEach(o),lp=f(u),ks=l(u,"LI",{});var Gh=r(ks);rp=n(Gh,"ViT"),Gh.forEach(o),ip=f(u),ys=l(u,"LI",{});var Yh=r(ys);pp=n(Yh,"Whisper"),Yh.forEach(o),fp=f(u),Os=l(u,"LI",{});var Uh=r(Os);dp=n(Uh,"XLM"),Uh.forEach(o),cp=f(u),Ts=l(u,"LI",{});var Kh=r(Ts);hp=n(Kh,"XLM-RoBERTa"),Kh.forEach(o),up=f(u),Ns=l(u,"LI",{});var Jh=r(Ns);mp=n(Jh,"XLM-RoBERTa-XL"),Jh.forEach(o),gp=f(u),js=l(u,"LI",{});var Qh=r(js);_p=n(Qh,"YOLOS"),Qh.forEach(o),u.forEach(o),ha=f(t),Ht=l(t,"P",{});var Zh=r(Ht);vp=n(Zh,"In the next two sections, we\u2019ll show you how to:"),Zh.forEach(o),ua=f(t),Ee=l(t,"UL",{});var Nl=r(Ee);Ue=l(Nl,"LI",{});var jl=r(Ue);Ep=n(jl,"Export a supported model using the "),Cs=l(jl,"CODE",{});var eu=r(Cs);$p=n(eu,"transformers.onnx"),eu.forEach(o),wp=n(jl," package."),jl.forEach(o),xp=f(Nl),Ds=l(Nl,"LI",{});var tu=r(Ds);bp=n(tu,"Export a custom model for an unsupported architecture."),tu.forEach(o),Nl.forEach(o),ma=f(t),de=l(t,"H2",{class:!0});var Cl=r(de);$e=l(Cl,"A",{id:!0,class:!0,href:!0});var ou=r($e);qs=l(ou,"SPAN",{});var su=r(qs);C(Ke.$$.fragment,su),su.forEach(o),ou.forEach(o),kp=f(Cl),Ls=l(Cl,"SPAN",{});var nu=r(Ls);yp=n(nu,"Exporting a model to ONNX"),nu.forEach(o),Cl.forEach(o),ga=f(t),Wt=l(t,"P",{});var au=r(Wt);Op=n(au,`To export a \u{1F917} Transformers model to ONNX, you\u2019ll first need to install some extra
dependencies:`),au.forEach(o),_a=f(t),C(Je.$$.fragment,t),va=f(t),we=l(t,"P",{});var Dl=r(we);Tp=n(Dl,"The "),As=l(Dl,"CODE",{});var lu=r(As);Np=n(lu,"transformers.onnx"),lu.forEach(o),jp=n(Dl," package can then be used as a Python module:"),Dl.forEach(o),Ea=f(t),C(Qe.$$.fragment,t),$a=f(t),Gt=l(t,"P",{});var ru=r(Gt);Cp=n(ru,"Exporting a checkpoint using a ready-made configuration can be done as follows:"),ru.forEach(o),wa=f(t),C(Ze.$$.fragment,t),xa=f(t),Yt=l(t,"P",{});var iu=r(Yt);Dp=n(iu,"You should see the following logs:"),iu.forEach(o),ba=f(t),C(et.$$.fragment,t),ka=f(t),ee=l(t,"P",{});var mo=r(ee);qp=n(mo,"This exports an ONNX graph of the checkpoint defined by the "),Is=l(mo,"CODE",{});var pu=r(Is);Lp=n(pu,"--model"),pu.forEach(o),Ap=n(mo,` argument. In this
example, it is `),Ps=l(mo,"CODE",{});var fu=r(Ps);Ip=n(fu,"distilbert-base-uncased"),fu.forEach(o),Pp=n(mo,`, but it can be any checkpoint on the Hugging
Face Hub or one that\u2019s stored locally.`),mo.forEach(o),ya=f(t),G=l(t,"P",{});var Se=r(G);Mp=n(Se,"The resulting "),Ms=l(Se,"CODE",{});var du=r(Ms);Xp=n(du,"model.onnx"),du.forEach(o),Bp=n(Se," file can then be run on one of the "),tt=l(Se,"A",{href:!0,rel:!0});var cu=r(tt);Rp=n(cu,`many
accelerators`),cu.forEach(o),Fp=n(Se,` that support the ONNX
standard. For example, we can load and run the model with `),ot=l(Se,"A",{href:!0,rel:!0});var hu=r(ot);Sp=n(hu,`ONNX
Runtime`),hu.forEach(o),zp=n(Se," as follows:"),Se.forEach(o),Oa=f(t),C(st.$$.fragment,t),Ta=f(t),xe=l(t,"P",{});var ql=r(xe);Vp=n(ql,"The required output names (like "),Xs=l(ql,"CODE",{});var uu=r(Xs);Hp=n(uu,'["last_hidden_state"]'),uu.forEach(o),Wp=n(ql,`) can be obtained by taking a
look at the ONNX configuration of each model. For example, for DistilBERT we have:`),ql.forEach(o),Na=f(t),C(nt.$$.fragment,t),ja=f(t),be=l(t,"P",{});var Ll=r(be);Gp=n(Ll,`The process is identical for TensorFlow checkpoints on the Hub. For example, we can
export a pure TensorFlow checkpoint from the `),at=l(Ll,"A",{href:!0,rel:!0});var mu=r(at);Yp=n(mu,`Keras
organization`),mu.forEach(o),Up=n(Ll," as follows:"),Ll.forEach(o),Ca=f(t),C(lt.$$.fragment,t),Da=f(t),Ut=l(t,"P",{});var gu=r(Ut);Kp=n(gu,`To export a model that\u2019s stored locally, you\u2019ll need to have the model\u2019s weights and
tokenizer files stored in a directory. For example, we can load and save a checkpoint as
follows:`),gu.forEach(o),qa=f(t),C(ke.$$.fragment,t),La=f(t),ce=l(t,"H2",{class:!0});var Al=r(ce);ye=l(Al,"A",{id:!0,class:!0,href:!0});var _u=r(ye);Bs=l(_u,"SPAN",{});var vu=r(Bs);C(rt.$$.fragment,vu),vu.forEach(o),_u.forEach(o),Jp=f(Al),Rs=l(Al,"SPAN",{});var Eu=r(Rs);Qp=n(Eu,"Selecting features for different model tasks"),Eu.forEach(o),Al.forEach(o),Aa=f(t),te=l(t,"P",{});var go=r(te);Zp=n(go,"Each ready-made configuration comes with a set of "),Fs=l(go,"EM",{});var $u=r(Fs);ef=n($u,"features"),$u.forEach(o),tf=n(go,` that enable you to export
models for different types of tasks. As shown in the table below, each feature is
associated with a different `),Ss=l(go,"CODE",{});var wu=r(Ss);of=n(wu,"AutoClass"),wu.forEach(o),sf=n(go,":"),go.forEach(o),Ia=f(t),Oe=l(t,"TABLE",{});var Il=r(Oe);zs=l(Il,"THEAD",{});var xu=r(zs);it=l(xu,"TR",{});var Pl=r(it);Vs=l(Pl,"TH",{});var bu=r(Vs);nf=n(bu,"Feature"),bu.forEach(o),af=f(Pl),Hs=l(Pl,"TH",{});var ku=r(Hs);lf=n(ku,"Auto Class"),ku.forEach(o),Pl.forEach(o),xu.forEach(o),rf=f(Il),F=l(Il,"TBODY",{});var H=r(F);pt=l(H,"TR",{});var Ml=r(pt);ft=l(Ml,"TD",{});var Xl=r(ft);Ws=l(Xl,"CODE",{});var yu=r(Ws);pf=n(yu,"causal-lm"),yu.forEach(o),ff=n(Xl,", "),Gs=l(Xl,"CODE",{});var Ou=r(Gs);df=n(Ou,"causal-lm-with-past"),Ou.forEach(o),Xl.forEach(o),cf=f(Ml),Ys=l(Ml,"TD",{});var Tu=r(Ys);Us=l(Tu,"CODE",{});var Nu=r(Us);hf=n(Nu,"AutoModelForCausalLM"),Nu.forEach(o),Tu.forEach(o),Ml.forEach(o),uf=f(H),dt=l(H,"TR",{});var Bl=r(dt);ct=l(Bl,"TD",{});var Rl=r(ct);Ks=l(Rl,"CODE",{});var ju=r(Ks);mf=n(ju,"default"),ju.forEach(o),gf=n(Rl,", "),Js=l(Rl,"CODE",{});var Cu=r(Js);_f=n(Cu,"default-with-past"),Cu.forEach(o),Rl.forEach(o),vf=f(Bl),Qs=l(Bl,"TD",{});var Du=r(Qs);Zs=l(Du,"CODE",{});var qu=r(Zs);Ef=n(qu,"AutoModel"),qu.forEach(o),Du.forEach(o),Bl.forEach(o),$f=f(H),ht=l(H,"TR",{});var Fl=r(ht);en=l(Fl,"TD",{});var Lu=r(en);tn=l(Lu,"CODE",{});var Au=r(tn);wf=n(Au,"masked-lm"),Au.forEach(o),Lu.forEach(o),xf=f(Fl),on=l(Fl,"TD",{});var Iu=r(on);sn=l(Iu,"CODE",{});var Pu=r(sn);bf=n(Pu,"AutoModelForMaskedLM"),Pu.forEach(o),Iu.forEach(o),Fl.forEach(o),kf=f(H),ut=l(H,"TR",{});var Sl=r(ut);nn=l(Sl,"TD",{});var Mu=r(nn);an=l(Mu,"CODE",{});var Xu=r(an);yf=n(Xu,"question-answering"),Xu.forEach(o),Mu.forEach(o),Of=f(Sl),ln=l(Sl,"TD",{});var Bu=r(ln);rn=l(Bu,"CODE",{});var Ru=r(rn);Tf=n(Ru,"AutoModelForQuestionAnswering"),Ru.forEach(o),Bu.forEach(o),Sl.forEach(o),Nf=f(H),mt=l(H,"TR",{});var zl=r(mt);gt=l(zl,"TD",{});var Vl=r(gt);pn=l(Vl,"CODE",{});var Fu=r(pn);jf=n(Fu,"seq2seq-lm"),Fu.forEach(o),Cf=n(Vl,", "),fn=l(Vl,"CODE",{});var Su=r(fn);Df=n(Su,"seq2seq-lm-with-past"),Su.forEach(o),Vl.forEach(o),qf=f(zl),dn=l(zl,"TD",{});var zu=r(dn);cn=l(zu,"CODE",{});var Vu=r(cn);Lf=n(Vu,"AutoModelForSeq2SeqLM"),Vu.forEach(o),zu.forEach(o),zl.forEach(o),Af=f(H),_t=l(H,"TR",{});var Hl=r(_t);hn=l(Hl,"TD",{});var Hu=r(hn);un=l(Hu,"CODE",{});var Wu=r(un);If=n(Wu,"sequence-classification"),Wu.forEach(o),Hu.forEach(o),Pf=f(Hl),mn=l(Hl,"TD",{});var Gu=r(mn);gn=l(Gu,"CODE",{});var Yu=r(gn);Mf=n(Yu,"AutoModelForSequenceClassification"),Yu.forEach(o),Gu.forEach(o),Hl.forEach(o),Xf=f(H),vt=l(H,"TR",{});var Wl=r(vt);_n=l(Wl,"TD",{});var Uu=r(_n);vn=l(Uu,"CODE",{});var Ku=r(vn);Bf=n(Ku,"token-classification"),Ku.forEach(o),Uu.forEach(o),Rf=f(Wl),En=l(Wl,"TD",{});var Ju=r(En);$n=l(Ju,"CODE",{});var Qu=r($n);Ff=n(Qu,"AutoModelForTokenClassification"),Qu.forEach(o),Ju.forEach(o),Wl.forEach(o),H.forEach(o),Il.forEach(o),Pa=f(t),Te=l(t,"P",{});var Gl=r(Te);Sf=n(Gl,`For each configuration, you can find the list of supported features via the
`),Kt=l(Gl,"A",{href:!0});var Zu=r(Kt);zf=n(Zu,"FeaturesManager"),Zu.forEach(o),Vf=n(Gl,". For example, for DistilBERT we have:"),Gl.forEach(o),Ma=f(t),C(Et.$$.fragment,t),Xa=f(t),oe=l(t,"P",{});var _o=r(oe);Hf=n(_o,"You can then pass one of these features to the "),wn=l(_o,"CODE",{});var em=r(wn);Wf=n(em,"--feature"),em.forEach(o),Gf=n(_o,` argument in the
`),xn=l(_o,"CODE",{});var tm=r(xn);Yf=n(tm,"transformers.onnx"),tm.forEach(o),Uf=n(_o,` package. For example, to export a text-classification model we can
pick a fine-tuned model from the Hub and run:`),_o.forEach(o),Ba=f(t),C($t.$$.fragment,t),Ra=f(t),Jt=l(t,"P",{});var om=r(Jt);Kf=n(om,"This displays the following logs:"),om.forEach(o),Fa=f(t),C(wt.$$.fragment,t),Sa=f(t),Y=l(t,"P",{});var ze=r(Y);Jf=n(ze,"Notice that in this case, the output names from the fine-tuned model are "),bn=l(ze,"CODE",{});var sm=r(bn);Qf=n(sm,"logits"),sm.forEach(o),Zf=n(ze,`
instead of the `),kn=l(ze,"CODE",{});var nm=r(kn);ed=n(nm,"last_hidden_state"),nm.forEach(o),td=n(ze," we saw with the "),yn=l(ze,"CODE",{});var am=r(yn);od=n(am,"distilbert-base-uncased"),am.forEach(o),sd=n(ze,` checkpoint
earlier. This is expected since the fine-tuned model has a sequence classification head.`),ze.forEach(o),za=f(t),C(Ne.$$.fragment,t),Va=f(t),C(je.$$.fragment,t),Ha=f(t),he=l(t,"H2",{class:!0});var Yl=r(he);Ce=l(Yl,"A",{id:!0,class:!0,href:!0});var lm=r(Ce);On=l(lm,"SPAN",{});var rm=r(On);C(xt.$$.fragment,rm),rm.forEach(o),lm.forEach(o),nd=f(Yl),Tn=l(Yl,"SPAN",{});var im=r(Tn);ad=n(im,"Exporting a model for an unsupported architecture"),im.forEach(o),Yl.forEach(o),Wa=f(t),Qt=l(t,"P",{});var pm=r(Qt);ld=n(pm,`If you wish to export a model whose architecture is not natively supported by the
library, there are three main steps to follow:`),pm.forEach(o),Ga=f(t),se=l(t,"OL",{});var vo=r(se);Nn=l(vo,"LI",{});var fm=r(Nn);rd=n(fm,"Implement a custom ONNX configuration."),fm.forEach(o),id=f(vo),jn=l(vo,"LI",{});var dm=r(jn);pd=n(dm,"Export the model to ONNX."),dm.forEach(o),fd=f(vo),Cn=l(vo,"LI",{});var cm=r(Cn);dd=n(cm,"Validate the outputs of the PyTorch and exported models."),cm.forEach(o),vo.forEach(o),Ya=f(t),Zt=l(t,"P",{});var hm=r(Zt);cd=n(hm,`In this section, we\u2019ll look at how DistilBERT was implemented to show what\u2019s involved
with each step.`),hm.forEach(o),Ua=f(t),ue=l(t,"H3",{class:!0});var Ul=r(ue);De=l(Ul,"A",{id:!0,class:!0,href:!0});var um=r(De);Dn=l(um,"SPAN",{});var mm=r(Dn);C(bt.$$.fragment,mm),mm.forEach(o),um.forEach(o),hd=f(Ul),qn=l(Ul,"SPAN",{});var gm=r(qn);ud=n(gm,"Implementing a custom ONNX configuration"),gm.forEach(o),Ul.forEach(o),Ka=f(t),eo=l(t,"P",{});var _m=r(eo);md=n(_m,`Let\u2019s start with the ONNX configuration object. We provide three abstract classes that
you should inherit from, depending on the type of model architecture you wish to export:`),_m.forEach(o),Ja=f(t),ne=l(t,"UL",{});var Eo=r(ne);to=l(Eo,"LI",{});var Mc=r(to);gd=n(Mc,"Encoder-based models inherit from "),oo=l(Mc,"A",{href:!0});var vm=r(oo);_d=n(vm,"OnnxConfig"),vm.forEach(o),Mc.forEach(o),vd=f(Eo),so=l(Eo,"LI",{});var Xc=r(so);Ed=n(Xc,"Decoder-based models inherit from "),no=l(Xc,"A",{href:!0});var Em=r(no);$d=n(Em,"OnnxConfigWithPast"),Em.forEach(o),Xc.forEach(o),wd=f(Eo),ao=l(Eo,"LI",{});var Bc=r(ao);xd=n(Bc,"Encoder-decoder models inherit from "),lo=l(Bc,"A",{href:!0});var $m=r(lo);bd=n($m,"OnnxSeq2SeqConfigWithPast"),$m.forEach(o),Bc.forEach(o),Eo.forEach(o),Qa=f(t),C(qe.$$.fragment,t),Za=f(t),Le=l(t,"P",{});var Kl=r(Le);kd=n(Kl,`Since DistilBERT is an encoder-based model, its configuration inherits from
`),Ln=l(Kl,"CODE",{});var wm=r(Ln);yd=n(wm,"OnnxConfig"),wm.forEach(o),Od=n(Kl,":"),Kl.forEach(o),el=f(t),C(kt.$$.fragment,t),tl=f(t),z=l(t,"P",{});var ie=r(z);Td=n(ie,"Every configuration object must implement the "),An=l(ie,"CODE",{});var xm=r(An);Nd=n(xm,"inputs"),xm.forEach(o),jd=n(ie,` property and return a mapping,
where each key corresponds to an expected input, and each value indicates the axis of
that input. For DistilBERT, we can see that two inputs are required: `),In=l(ie,"CODE",{});var bm=r(In);Cd=n(bm,"input_ids"),bm.forEach(o),Dd=n(ie,` and
`),Pn=l(ie,"CODE",{});var km=r(Pn);qd=n(km,"attention_mask"),km.forEach(o),Ld=n(ie,". These inputs have the same shape of "),Mn=l(ie,"CODE",{});var ym=r(Mn);Ad=n(ym,"(batch_size, sequence_length)"),ym.forEach(o),Id=n(ie,`
which is why we see the same axes used in the configuration.`),ie.forEach(o),ol=f(t),C(Ae.$$.fragment,t),sl=f(t),ro=l(t,"P",{});var Om=r(ro);Pd=n(Om,`Once you have implemented an ONNX configuration, you can instantiate it by providing the
base model\u2019s configuration as follows:`),Om.forEach(o),nl=f(t),C(yt.$$.fragment,t),al=f(t),io=l(t,"P",{});var Tm=r(io);Md=n(Tm,`The resulting object has several useful properties. For example, you can view the ONNX
operator set that will be used during the export:`),Tm.forEach(o),ll=f(t),C(Ot.$$.fragment,t),rl=f(t),po=l(t,"P",{});var Nm=r(po);Xd=n(Nm,"You can also view the outputs associated with the model as follows:"),Nm.forEach(o),il=f(t),C(Tt.$$.fragment,t),pl=f(t),V=l(t,"P",{});var pe=r(V);Bd=n(pe,`Notice that the outputs property follows the same structure as the inputs; it returns an
`),Xn=l(pe,"CODE",{});var jm=r(Xn);Rd=n(jm,"OrderedDict"),jm.forEach(o),Fd=n(pe,` of named outputs and their shapes. The output structure is linked to the
choice of feature that the configuration is initialised with. By default, the ONNX
configuration is initialized with the `),Bn=l(pe,"CODE",{});var Cm=r(Bn);Sd=n(Cm,"default"),Cm.forEach(o),zd=n(pe,` feature that corresponds to exporting a
model loaded with the `),Rn=l(pe,"CODE",{});var Dm=r(Rn);Vd=n(Dm,"AutoModel"),Dm.forEach(o),Hd=n(pe,` class. If you want to export a model for another task,
just provide a different feature to the `),Fn=l(pe,"CODE",{});var qm=r(Fn);Wd=n(qm,"task"),qm.forEach(o),Gd=n(pe,` argument when you initialize the ONNX
configuration. For example, if we wished to export DistilBERT with a sequence
classification head, we could use:`),pe.forEach(o),fl=f(t),C(Nt.$$.fragment,t),dl=f(t),C(Ie.$$.fragment,t),cl=f(t),me=l(t,"H3",{class:!0});var Jl=r(me);Pe=l(Jl,"A",{id:!0,class:!0,href:!0});var Lm=r(Pe);Sn=l(Lm,"SPAN",{});var Am=r(Sn);C(jt.$$.fragment,Am),Am.forEach(o),Lm.forEach(o),Yd=f(Jl),zn=l(Jl,"SPAN",{});var Im=r(zn);Ud=n(Im,"Exporting the model"),Im.forEach(o),Jl.forEach(o),hl=f(t),ae=l(t,"P",{});var $o=r(ae);Kd=n($o,`Once you have implemented the ONNX configuration, the next step is to export the model.
Here we can use the `),Vn=l($o,"CODE",{});var Pm=r(Vn);Jd=n(Pm,"export()"),Pm.forEach(o),Qd=n($o," function provided by the "),Hn=l($o,"CODE",{});var Mm=r(Hn);Zd=n(Mm,"transformers.onnx"),Mm.forEach(o),ec=n($o,` package.
This function expects the ONNX configuration, along with the base model and tokenizer,
and the path to save the exported file:`),$o.forEach(o),ul=f(t),C(Ct.$$.fragment,t),ml=f(t),S=l(t,"P",{});var U=r(S);tc=n(U,"The "),Wn=l(U,"CODE",{});var Xm=r(Wn);oc=n(Xm,"onnx_inputs"),Xm.forEach(o),sc=n(U," and "),Gn=l(U,"CODE",{});var Bm=r(Gn);nc=n(Bm,"onnx_outputs"),Bm.forEach(o),ac=n(U," returned by the "),Yn=l(U,"CODE",{});var Rm=r(Yn);lc=n(Rm,"export()"),Rm.forEach(o),rc=n(U,` function are lists of
the keys defined in the `),Un=l(U,"CODE",{});var Fm=r(Un);ic=n(Fm,"inputs"),Fm.forEach(o),pc=n(U," and "),Kn=l(U,"CODE",{});var Sm=r(Kn);fc=n(Sm,"outputs"),Sm.forEach(o),dc=n(U,` properties of the configuration. Once the
model is exported, you can test that the model is well formed as follows:`),U.forEach(o),gl=f(t),C(Dt.$$.fragment,t),_l=f(t),C(Me.$$.fragment,t),vl=f(t),ge=l(t,"H3",{class:!0});var Ql=r(ge);Xe=l(Ql,"A",{id:!0,class:!0,href:!0});var zm=r(Xe);Jn=l(zm,"SPAN",{});var Vm=r(Jn);C(qt.$$.fragment,Vm),Vm.forEach(o),zm.forEach(o),cc=f(Ql),Qn=l(Ql,"SPAN",{});var Hm=r(Qn);hc=n(Hm,"Validating the model outputs"),Hm.forEach(o),Ql.forEach(o),El=f(t),le=l(t,"P",{});var wo=r(le);uc=n(wo,`The final step is to validate that the outputs from the base and exported model agree
within some absolute tolerance. Here we can use the `),Zn=l(wo,"CODE",{});var Wm=r(Zn);mc=n(Wm,"validate_model_outputs()"),Wm.forEach(o),gc=n(wo,` function
provided by the `),ea=l(wo,"CODE",{});var Gm=r(ea);_c=n(Gm,"transformers.onnx"),Gm.forEach(o),vc=n(wo," package as follows:"),wo.forEach(o),$l=f(t),C(Lt.$$.fragment,t),wl=f(t),Be=l(t,"P",{});var Zl=r(Be);Ec=n(Zl,"This function uses the "),fo=l(Zl,"A",{href:!0});var Ym=r(fo);$c=n(Ym,"generate_dummy_inputs()"),Ym.forEach(o),wc=n(Zl,` method to
generate inputs for the base and exported model, and the absolute tolerance can be
defined in the configuration. We generally find numerical agreement in the 1e-6 to 1e-4
range, although anything smaller than 1e-3 is likely to be OK.`),Zl.forEach(o),xl=f(t),_e=l(t,"H2",{class:!0});var er=r(_e);Re=l(er,"A",{id:!0,class:!0,href:!0});var Um=r(Re);ta=l(Um,"SPAN",{});var Km=r(ta);C(At.$$.fragment,Km),Km.forEach(o),Um.forEach(o),xc=f(er),oa=l(er,"SPAN",{});var Jm=r(oa);bc=n(Jm,"Contributing a new configuration to \u{1F917} Transformers"),Jm.forEach(o),er.forEach(o),bl=f(t),co=l(t,"P",{});var Qm=r(co);kc=n(Qm,`We are looking to expand the set of ready-made configurations and welcome contributions
from the community! If you would like to contribute your addition to the library, you
will need to:`),Qm.forEach(o),kl=f(t),re=l(t,"UL",{});var xo=r(re);It=l(xo,"LI",{});var tr=r(It);yc=n(tr,"Implement the ONNX configuration in the corresponding "),sa=l(tr,"CODE",{});var Zm=r(sa);Oc=n(Zm,"configuration_<model_name>.py"),Zm.forEach(o),Tc=n(tr,`
file`),tr.forEach(o),Nc=f(xo),ho=l(xo,"LI",{});var Rc=r(ho);jc=n(Rc,`Include the model architecture and corresponding features in
`),na=l(Rc,"CODE",{});var eg=r(na);Cc=n(eg,"~onnx.features.FeatureManager"),eg.forEach(o),Rc.forEach(o),Dc=f(xo),uo=l(xo,"LI",{});var Fc=r(uo);qc=n(Fc,"Add your model architecture to the tests in "),aa=l(Fc,"CODE",{});var tg=r(aa);Lc=n(tg,"test_onnx_v2.py"),tg.forEach(o),Fc.forEach(o),xo.forEach(o),yl=f(t),Fe=l(t,"P",{});var or=r(Fe);Ac=n(or,"Check out how the configuration for "),Pt=l(or,"A",{href:!0,rel:!0});var og=r(Pt);Ic=n(og,`IBERT was
contributed`),og.forEach(o),Pc=n(or,` to get an
idea of what\u2019s involved.`),or.forEach(o),this.h()},h(){v(c,"name","hf:doc:metadata"),v(c,"content",JSON.stringify(bg)),v(E,"id","export-to-onnx"),v(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),v(E,"href","#export-to-onnx"),v(m,"class","relative group"),v(O,"href","http://onnx.ai"),v(O,"rel","nofollow"),v(fe,"href","main_classes/onnx"),v($e,"id","exporting-a-model-to-onnx"),v($e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),v($e,"href","#exporting-a-model-to-onnx"),v(de,"class","relative group"),v(tt,"href","https://onnx.ai/supported-tools.html#deployModel"),v(tt,"rel","nofollow"),v(ot,"href","https://onnxruntime.ai/"),v(ot,"rel","nofollow"),v(at,"href","https://huggingface.co/keras-io"),v(at,"rel","nofollow"),v(ye,"id","selecting-features-for-different-model-tasks"),v(ye,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),v(ye,"href","#selecting-features-for-different-model-tasks"),v(ce,"class","relative group"),v(Kt,"href","/docs/transformers/main/en/main_classes/onnx#transformers.onnx.FeaturesManager"),v(Ce,"id","exporting-a-model-for-an-unsupported-architecture"),v(Ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),v(Ce,"href","#exporting-a-model-for-an-unsupported-architecture"),v(he,"class","relative group"),v(De,"id","implementing-a-custom-onnx-configuration"),v(De,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),v(De,"href","#implementing-a-custom-onnx-configuration"),v(ue,"class","relative group"),v(oo,"href","/docs/transformers/main/en/main_classes/onnx#transformers.onnx.OnnxConfig"),v(no,"href","/docs/transformers/main/en/main_classes/onnx#transformers.onnx.OnnxConfigWithPast"),v(lo,"href","/docs/transformers/main/en/main_classes/onnx#transformers.onnx.OnnxSeq2SeqConfigWithPast"),v(Pe,"id","exporting-the-model"),v(Pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),v(Pe,"href","#exporting-the-model"),v(me,"class","relative group"),v(Xe,"id","validating-the-model-outputs"),v(Xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),v(Xe,"href","#validating-the-model-outputs"),v(ge,"class","relative group"),v(fo,"href","/docs/transformers/main/en/main_classes/onnx#transformers.onnx.OnnxConfig.generate_dummy_inputs"),v(Re,"id","contributing-a-new-configuration-to-transformers"),v(Re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),v(Re,"href","#contributing-a-new-configuration-to-transformers"),v(_e,"class","relative group"),v(Pt,"href","https://github.com/huggingface/transformers/pull/14868/files"),v(Pt,"rel","nofollow")},m(t,i){e(document.head,c),d(t,$,i),d(t,m,i),e(m,E),e(E,w),D(_,w,null),e(m,x),e(m,b),e(b,k),d(t,T,i),d(t,I,i),e(I,y),e(I,O),e(O,g),e(I,N),d(t,B,i),D(R,t,i),d(t,Q,i),d(t,W,i),e(W,He),e(W,K),e(K,We),e(W,Ge),d(t,Z,i),d(t,P,i),e(P,Ft),d(t,Ye,i),d(t,J,i),e(J,St),e(J,fe),e(fe,ve),e(ve,zt),e(J,sr),d(t,da,i),d(t,Vt,i),e(Vt,nr),d(t,ca,i),d(t,h,i),e(h,bo),e(bo,ar),e(h,lr),e(h,ko),e(ko,rr),e(h,ir),e(h,yo),e(yo,pr),e(h,fr),e(h,Oo),e(Oo,dr),e(h,cr),e(h,To),e(To,hr),e(h,ur),e(h,No),e(No,mr),e(h,gr),e(h,jo),e(jo,_r),e(h,vr),e(h,Co),e(Co,Er),e(h,$r),e(h,Do),e(Do,wr),e(h,xr),e(h,qo),e(qo,br),e(h,kr),e(h,Lo),e(Lo,yr),e(h,Or),e(h,Ao),e(Ao,Tr),e(h,Nr),e(h,Io),e(Io,jr),e(h,Cr),e(h,Po),e(Po,Dr),e(h,qr),e(h,Mo),e(Mo,Lr),e(h,Ar),e(h,Xo),e(Xo,Ir),e(h,Pr),e(h,Bo),e(Bo,Mr),e(h,Xr),e(h,Ro),e(Ro,Br),e(h,Rr),e(h,Fo),e(Fo,Fr),e(h,Sr),e(h,So),e(So,zr),e(h,Vr),e(h,zo),e(zo,Hr),e(h,Wr),e(h,Vo),e(Vo,Gr),e(h,Yr),e(h,Ho),e(Ho,Ur),e(h,Kr),e(h,Wo),e(Wo,Jr),e(h,Qr),e(h,Go),e(Go,Zr),e(h,ei),e(h,Yo),e(Yo,ti),e(h,oi),e(h,Uo),e(Uo,si),e(h,ni),e(h,Ko),e(Ko,ai),e(h,li),e(h,Jo),e(Jo,ri),e(h,ii),e(h,Qo),e(Qo,pi),e(h,fi),e(h,Zo),e(Zo,di),e(h,ci),e(h,es),e(es,hi),e(h,ui),e(h,ts),e(ts,mi),e(h,gi),e(h,os),e(os,_i),e(h,vi),e(h,ss),e(ss,Ei),e(h,$i),e(h,ns),e(ns,wi),e(h,xi),e(h,as),e(as,bi),e(h,ki),e(h,ls),e(ls,yi),e(h,Oi),e(h,rs),e(rs,Ti),e(h,Ni),e(h,is),e(is,ji),e(h,Ci),e(h,ps),e(ps,Di),e(h,qi),e(h,fs),e(fs,Li),e(h,Ai),e(h,ds),e(ds,Ii),e(h,Pi),e(h,cs),e(cs,Mi),e(h,Xi),e(h,hs),e(hs,Bi),e(h,Ri),e(h,us),e(us,Fi),e(h,Si),e(h,ms),e(ms,zi),e(h,Vi),e(h,gs),e(gs,Hi),e(h,Wi),e(h,_s),e(_s,Gi),e(h,Yi),e(h,vs),e(vs,Ui),e(h,Ki),e(h,Es),e(Es,Ji),e(h,Qi),e(h,$s),e($s,Zi),e(h,ep),e(h,ws),e(ws,tp),e(h,op),e(h,xs),e(xs,sp),e(h,np),e(h,bs),e(bs,ap),e(h,lp),e(h,ks),e(ks,rp),e(h,ip),e(h,ys),e(ys,pp),e(h,fp),e(h,Os),e(Os,dp),e(h,cp),e(h,Ts),e(Ts,hp),e(h,up),e(h,Ns),e(Ns,mp),e(h,gp),e(h,js),e(js,_p),d(t,ha,i),d(t,Ht,i),e(Ht,vp),d(t,ua,i),d(t,Ee,i),e(Ee,Ue),e(Ue,Ep),e(Ue,Cs),e(Cs,$p),e(Ue,wp),e(Ee,xp),e(Ee,Ds),e(Ds,bp),d(t,ma,i),d(t,de,i),e(de,$e),e($e,qs),D(Ke,qs,null),e(de,kp),e(de,Ls),e(Ls,yp),d(t,ga,i),d(t,Wt,i),e(Wt,Op),d(t,_a,i),D(Je,t,i),d(t,va,i),d(t,we,i),e(we,Tp),e(we,As),e(As,Np),e(we,jp),d(t,Ea,i),D(Qe,t,i),d(t,$a,i),d(t,Gt,i),e(Gt,Cp),d(t,wa,i),D(Ze,t,i),d(t,xa,i),d(t,Yt,i),e(Yt,Dp),d(t,ba,i),D(et,t,i),d(t,ka,i),d(t,ee,i),e(ee,qp),e(ee,Is),e(Is,Lp),e(ee,Ap),e(ee,Ps),e(Ps,Ip),e(ee,Pp),d(t,ya,i),d(t,G,i),e(G,Mp),e(G,Ms),e(Ms,Xp),e(G,Bp),e(G,tt),e(tt,Rp),e(G,Fp),e(G,ot),e(ot,Sp),e(G,zp),d(t,Oa,i),D(st,t,i),d(t,Ta,i),d(t,xe,i),e(xe,Vp),e(xe,Xs),e(Xs,Hp),e(xe,Wp),d(t,Na,i),D(nt,t,i),d(t,ja,i),d(t,be,i),e(be,Gp),e(be,at),e(at,Yp),e(be,Up),d(t,Ca,i),D(lt,t,i),d(t,Da,i),d(t,Ut,i),e(Ut,Kp),d(t,qa,i),D(ke,t,i),d(t,La,i),d(t,ce,i),e(ce,ye),e(ye,Bs),D(rt,Bs,null),e(ce,Jp),e(ce,Rs),e(Rs,Qp),d(t,Aa,i),d(t,te,i),e(te,Zp),e(te,Fs),e(Fs,ef),e(te,tf),e(te,Ss),e(Ss,of),e(te,sf),d(t,Ia,i),d(t,Oe,i),e(Oe,zs),e(zs,it),e(it,Vs),e(Vs,nf),e(it,af),e(it,Hs),e(Hs,lf),e(Oe,rf),e(Oe,F),e(F,pt),e(pt,ft),e(ft,Ws),e(Ws,pf),e(ft,ff),e(ft,Gs),e(Gs,df),e(pt,cf),e(pt,Ys),e(Ys,Us),e(Us,hf),e(F,uf),e(F,dt),e(dt,ct),e(ct,Ks),e(Ks,mf),e(ct,gf),e(ct,Js),e(Js,_f),e(dt,vf),e(dt,Qs),e(Qs,Zs),e(Zs,Ef),e(F,$f),e(F,ht),e(ht,en),e(en,tn),e(tn,wf),e(ht,xf),e(ht,on),e(on,sn),e(sn,bf),e(F,kf),e(F,ut),e(ut,nn),e(nn,an),e(an,yf),e(ut,Of),e(ut,ln),e(ln,rn),e(rn,Tf),e(F,Nf),e(F,mt),e(mt,gt),e(gt,pn),e(pn,jf),e(gt,Cf),e(gt,fn),e(fn,Df),e(mt,qf),e(mt,dn),e(dn,cn),e(cn,Lf),e(F,Af),e(F,_t),e(_t,hn),e(hn,un),e(un,If),e(_t,Pf),e(_t,mn),e(mn,gn),e(gn,Mf),e(F,Xf),e(F,vt),e(vt,_n),e(_n,vn),e(vn,Bf),e(vt,Rf),e(vt,En),e(En,$n),e($n,Ff),d(t,Pa,i),d(t,Te,i),e(Te,Sf),e(Te,Kt),e(Kt,zf),e(Te,Vf),d(t,Ma,i),D(Et,t,i),d(t,Xa,i),d(t,oe,i),e(oe,Hf),e(oe,wn),e(wn,Wf),e(oe,Gf),e(oe,xn),e(xn,Yf),e(oe,Uf),d(t,Ba,i),D($t,t,i),d(t,Ra,i),d(t,Jt,i),e(Jt,Kf),d(t,Fa,i),D(wt,t,i),d(t,Sa,i),d(t,Y,i),e(Y,Jf),e(Y,bn),e(bn,Qf),e(Y,Zf),e(Y,kn),e(kn,ed),e(Y,td),e(Y,yn),e(yn,od),e(Y,sd),d(t,za,i),D(Ne,t,i),d(t,Va,i),D(je,t,i),d(t,Ha,i),d(t,he,i),e(he,Ce),e(Ce,On),D(xt,On,null),e(he,nd),e(he,Tn),e(Tn,ad),d(t,Wa,i),d(t,Qt,i),e(Qt,ld),d(t,Ga,i),d(t,se,i),e(se,Nn),e(Nn,rd),e(se,id),e(se,jn),e(jn,pd),e(se,fd),e(se,Cn),e(Cn,dd),d(t,Ya,i),d(t,Zt,i),e(Zt,cd),d(t,Ua,i),d(t,ue,i),e(ue,De),e(De,Dn),D(bt,Dn,null),e(ue,hd),e(ue,qn),e(qn,ud),d(t,Ka,i),d(t,eo,i),e(eo,md),d(t,Ja,i),d(t,ne,i),e(ne,to),e(to,gd),e(to,oo),e(oo,_d),e(ne,vd),e(ne,so),e(so,Ed),e(so,no),e(no,$d),e(ne,wd),e(ne,ao),e(ao,xd),e(ao,lo),e(lo,bd),d(t,Qa,i),D(qe,t,i),d(t,Za,i),d(t,Le,i),e(Le,kd),e(Le,Ln),e(Ln,yd),e(Le,Od),d(t,el,i),D(kt,t,i),d(t,tl,i),d(t,z,i),e(z,Td),e(z,An),e(An,Nd),e(z,jd),e(z,In),e(In,Cd),e(z,Dd),e(z,Pn),e(Pn,qd),e(z,Ld),e(z,Mn),e(Mn,Ad),e(z,Id),d(t,ol,i),D(Ae,t,i),d(t,sl,i),d(t,ro,i),e(ro,Pd),d(t,nl,i),D(yt,t,i),d(t,al,i),d(t,io,i),e(io,Md),d(t,ll,i),D(Ot,t,i),d(t,rl,i),d(t,po,i),e(po,Xd),d(t,il,i),D(Tt,t,i),d(t,pl,i),d(t,V,i),e(V,Bd),e(V,Xn),e(Xn,Rd),e(V,Fd),e(V,Bn),e(Bn,Sd),e(V,zd),e(V,Rn),e(Rn,Vd),e(V,Hd),e(V,Fn),e(Fn,Wd),e(V,Gd),d(t,fl,i),D(Nt,t,i),d(t,dl,i),D(Ie,t,i),d(t,cl,i),d(t,me,i),e(me,Pe),e(Pe,Sn),D(jt,Sn,null),e(me,Yd),e(me,zn),e(zn,Ud),d(t,hl,i),d(t,ae,i),e(ae,Kd),e(ae,Vn),e(Vn,Jd),e(ae,Qd),e(ae,Hn),e(Hn,Zd),e(ae,ec),d(t,ul,i),D(Ct,t,i),d(t,ml,i),d(t,S,i),e(S,tc),e(S,Wn),e(Wn,oc),e(S,sc),e(S,Gn),e(Gn,nc),e(S,ac),e(S,Yn),e(Yn,lc),e(S,rc),e(S,Un),e(Un,ic),e(S,pc),e(S,Kn),e(Kn,fc),e(S,dc),d(t,gl,i),D(Dt,t,i),d(t,_l,i),D(Me,t,i),d(t,vl,i),d(t,ge,i),e(ge,Xe),e(Xe,Jn),D(qt,Jn,null),e(ge,cc),e(ge,Qn),e(Qn,hc),d(t,El,i),d(t,le,i),e(le,uc),e(le,Zn),e(Zn,mc),e(le,gc),e(le,ea),e(ea,_c),e(le,vc),d(t,$l,i),D(Lt,t,i),d(t,wl,i),d(t,Be,i),e(Be,Ec),e(Be,fo),e(fo,$c),e(Be,wc),d(t,xl,i),d(t,_e,i),e(_e,Re),e(Re,ta),D(At,ta,null),e(_e,xc),e(_e,oa),e(oa,bc),d(t,bl,i),d(t,co,i),e(co,kc),d(t,kl,i),d(t,re,i),e(re,It),e(It,yc),e(It,sa),e(sa,Oc),e(It,Tc),e(re,Nc),e(re,ho),e(ho,jc),e(ho,na),e(na,Cc),e(re,Dc),e(re,uo),e(uo,qc),e(uo,aa),e(aa,Lc),d(t,yl,i),d(t,Fe,i),e(Fe,Ac),e(Fe,Pt),e(Pt,Ic),e(Fe,Pc),Ol=!0},p(t,[i]){const Mt={};i&2&&(Mt.$$scope={dirty:i,ctx:t}),R.$set(Mt);const la={};i&2&&(la.$$scope={dirty:i,ctx:t}),ke.$set(la);const ra={};i&2&&(ra.$$scope={dirty:i,ctx:t}),Ne.$set(ra);const ia={};i&2&&(ia.$$scope={dirty:i,ctx:t}),je.$set(ia);const Xt={};i&2&&(Xt.$$scope={dirty:i,ctx:t}),qe.$set(Xt);const pa={};i&2&&(pa.$$scope={dirty:i,ctx:t}),Ae.$set(pa);const Bt={};i&2&&(Bt.$$scope={dirty:i,ctx:t}),Ie.$set(Bt);const fa={};i&2&&(fa.$$scope={dirty:i,ctx:t}),Me.$set(fa)},i(t){Ol||(q(_.$$.fragment,t),q(R.$$.fragment,t),q(Ke.$$.fragment,t),q(Je.$$.fragment,t),q(Qe.$$.fragment,t),q(Ze.$$.fragment,t),q(et.$$.fragment,t),q(st.$$.fragment,t),q(nt.$$.fragment,t),q(lt.$$.fragment,t),q(ke.$$.fragment,t),q(rt.$$.fragment,t),q(Et.$$.fragment,t),q($t.$$.fragment,t),q(wt.$$.fragment,t),q(Ne.$$.fragment,t),q(je.$$.fragment,t),q(xt.$$.fragment,t),q(bt.$$.fragment,t),q(qe.$$.fragment,t),q(kt.$$.fragment,t),q(Ae.$$.fragment,t),q(yt.$$.fragment,t),q(Ot.$$.fragment,t),q(Tt.$$.fragment,t),q(Nt.$$.fragment,t),q(Ie.$$.fragment,t),q(jt.$$.fragment,t),q(Ct.$$.fragment,t),q(Dt.$$.fragment,t),q(Me.$$.fragment,t),q(qt.$$.fragment,t),q(Lt.$$.fragment,t),q(At.$$.fragment,t),Ol=!0)},o(t){L(_.$$.fragment,t),L(R.$$.fragment,t),L(Ke.$$.fragment,t),L(Je.$$.fragment,t),L(Qe.$$.fragment,t),L(Ze.$$.fragment,t),L(et.$$.fragment,t),L(st.$$.fragment,t),L(nt.$$.fragment,t),L(lt.$$.fragment,t),L(ke.$$.fragment,t),L(rt.$$.fragment,t),L(Et.$$.fragment,t),L($t.$$.fragment,t),L(wt.$$.fragment,t),L(Ne.$$.fragment,t),L(je.$$.fragment,t),L(xt.$$.fragment,t),L(bt.$$.fragment,t),L(qe.$$.fragment,t),L(kt.$$.fragment,t),L(Ae.$$.fragment,t),L(yt.$$.fragment,t),L(Ot.$$.fragment,t),L(Tt.$$.fragment,t),L(Nt.$$.fragment,t),L(Ie.$$.fragment,t),L(jt.$$.fragment,t),L(Ct.$$.fragment,t),L(Dt.$$.fragment,t),L(Me.$$.fragment,t),L(qt.$$.fragment,t),L(Lt.$$.fragment,t),L(At.$$.fragment,t),Ol=!1},d(t){o(c),t&&o($),t&&o(m),A(_),t&&o(T),t&&o(I),t&&o(B),A(R,t),t&&o(Q),t&&o(W),t&&o(Z),t&&o(P),t&&o(Ye),t&&o(J),t&&o(da),t&&o(Vt),t&&o(ca),t&&o(h),t&&o(ha),t&&o(Ht),t&&o(ua),t&&o(Ee),t&&o(ma),t&&o(de),A(Ke),t&&o(ga),t&&o(Wt),t&&o(_a),A(Je,t),t&&o(va),t&&o(we),t&&o(Ea),A(Qe,t),t&&o($a),t&&o(Gt),t&&o(wa),A(Ze,t),t&&o(xa),t&&o(Yt),t&&o(ba),A(et,t),t&&o(ka),t&&o(ee),t&&o(ya),t&&o(G),t&&o(Oa),A(st,t),t&&o(Ta),t&&o(xe),t&&o(Na),A(nt,t),t&&o(ja),t&&o(be),t&&o(Ca),A(lt,t),t&&o(Da),t&&o(Ut),t&&o(qa),A(ke,t),t&&o(La),t&&o(ce),A(rt),t&&o(Aa),t&&o(te),t&&o(Ia),t&&o(Oe),t&&o(Pa),t&&o(Te),t&&o(Ma),A(Et,t),t&&o(Xa),t&&o(oe),t&&o(Ba),A($t,t),t&&o(Ra),t&&o(Jt),t&&o(Fa),A(wt,t),t&&o(Sa),t&&o(Y),t&&o(za),A(Ne,t),t&&o(Va),A(je,t),t&&o(Ha),t&&o(he),A(xt),t&&o(Wa),t&&o(Qt),t&&o(Ga),t&&o(se),t&&o(Ya),t&&o(Zt),t&&o(Ua),t&&o(ue),A(bt),t&&o(Ka),t&&o(eo),t&&o(Ja),t&&o(ne),t&&o(Qa),A(qe,t),t&&o(Za),t&&o(Le),t&&o(el),A(kt,t),t&&o(tl),t&&o(z),t&&o(ol),A(Ae,t),t&&o(sl),t&&o(ro),t&&o(nl),A(yt,t),t&&o(al),t&&o(io),t&&o(ll),A(Ot,t),t&&o(rl),t&&o(po),t&&o(il),A(Tt,t),t&&o(pl),t&&o(V),t&&o(fl),A(Nt,t),t&&o(dl),A(Ie,t),t&&o(cl),t&&o(me),A(jt),t&&o(hl),t&&o(ae),t&&o(ul),A(Ct,t),t&&o(ml),t&&o(S),t&&o(gl),A(Dt,t),t&&o(_l),A(Me,t),t&&o(vl),t&&o(ge),A(qt),t&&o(El),t&&o(le),t&&o($l),A(Lt,t),t&&o(wl),t&&o(Be),t&&o(xl),t&&o(_e),A(At),t&&o(bl),t&&o(co),t&&o(kl),t&&o(re),t&&o(yl),t&&o(Fe)}}}const bg={local:"export-to-onnx",sections:[{local:"exporting-a-model-to-onnx",title:"Exporting a model to ONNX"},{local:"selecting-features-for-different-model-tasks",title:"Selecting features for different model tasks"},{local:"exporting-a-model-for-an-unsupported-architecture",sections:[{local:"implementing-a-custom-onnx-configuration",title:"Implementing a custom ONNX configuration"},{local:"exporting-the-model",title:"Exporting the model"},{local:"validating-the-model-outputs",title:"Validating the model outputs"}],title:"Exporting a model for an unsupported architecture"},{local:"contributing-a-new-configuration-to-transformers",title:"Contributing a new configuration to \u{1F917} Transformers"}],title:"Export to ONNX"};function kg(M){return pg(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Cg extends ag{constructor(c){super();lg(this,c,kg,xg,rg,{})}}export{Cg as default,bg as metadata};
