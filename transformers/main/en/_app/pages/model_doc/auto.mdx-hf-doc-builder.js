import{S as y5a,i as x5a,s as $5a,e as a,k as l,w as F,t as o,M as k5a,c as n,d as t,m as i,a as s,x as T,h as r,b as m,G as e,g as b,y as M,q as E,o as C,B as w,v as S5a,L as q}from"../../chunks/vendor-hf-doc-builder.js";import{T as B6t}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as B}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as oe}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as N}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function R5a($){let g,v,u,f,p,d,h,$o,vd,Qf,Tt,Fd,Td,m$,Wf,Xe,He,Md,ms,c$,cs,fs,f$,Ed,gs,g$,Cd,Uf,on;return{c(){g=a("p"),v=o("If your "),u=a("code"),f=o("NewModelConfig"),p=o(" is a subclass of "),d=a("code"),h=o("~transformer.PretrainedConfig"),$o=o(`, make sure its
`),vd=a("code"),Qf=o("model_type"),Tt=o(" attribute is set to the same key you use when registering the config (here "),Fd=a("code"),Td=o('"new-model"'),m$=o(")."),Wf=l(),Xe=a("p"),He=o("Likewise, if your "),Md=a("code"),ms=o("NewModel"),c$=o(" is a subclass of "),cs=a("a"),fs=o("PreTrainedModel"),f$=o(`, make sure its
`),Ed=a("code"),gs=o("config_class"),g$=o(` attribute is set to the same class you use when registering the model (here
`),Cd=a("code"),Uf=o("NewModelConfig"),on=o(")."),this.h()},l(Je){g=n(Je,"P",{});var Ae=s(g);v=r(Ae,"If your "),u=n(Ae,"CODE",{});var yN=s(u);f=r(yN,"NewModelConfig"),yN.forEach(t),p=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var wd=s(d);h=r(wd,"~transformer.PretrainedConfig"),wd.forEach(t),$o=r(Ae,`, make sure its
`),vd=n(Ae,"CODE",{});var xN=s(vd);Qf=r(xN,"model_type"),xN.forEach(t),Tt=r(Ae," attribute is set to the same key you use when registering the config (here "),Fd=n(Ae,"CODE",{});var $N=s(Fd);Td=r($N,'"new-model"'),$N.forEach(t),m$=r(Ae,")."),Ae.forEach(t),Wf=i(Je),Xe=n(Je,"P",{});var ko=s(Xe);He=r(ko,"Likewise, if your "),Md=n(ko,"CODE",{});var rn=s(Md);ms=r(rn,"NewModel"),rn.forEach(t),c$=r(ko," is a subclass of "),cs=n(ko,"A",{href:!0});var kN=s(cs);fs=r(kN,"PreTrainedModel"),kN.forEach(t),f$=r(ko,`, make sure its
`),Ed=n(ko,"CODE",{});var Hf=s(Ed);gs=r(Hf,"config_class"),Hf.forEach(t),g$=r(ko,` attribute is set to the same class you use when registering the model (here
`),Cd=n(ko,"CODE",{});var SN=s(Cd);Uf=r(SN,"NewModelConfig"),SN.forEach(t),on=r(ko,")."),ko.forEach(t),this.h()},h(){m(cs,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel")},m(Je,Ae){b(Je,g,Ae),e(g,v),e(g,u),e(u,f),e(g,p),e(g,d),e(d,h),e(g,$o),e(g,vd),e(vd,Qf),e(g,Tt),e(g,Fd),e(Fd,Td),e(g,m$),b(Je,Wf,Ae),b(Je,Xe,Ae),e(Xe,He),e(Xe,Md),e(Md,ms),e(Xe,c$),e(Xe,cs),e(cs,fs),e(Xe,f$),e(Xe,Ed),e(Ed,gs),e(Xe,g$),e(Xe,Cd),e(Cd,Uf),e(Xe,on)},d(Je){Je&&t(g),Je&&t(Wf),Je&&t(Xe)}}}function P5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function B5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function I5a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var $o=s(u);f=r($o,"use_auth_token=True"),$o.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function N5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function q5a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var $o=s(u);f=r($o,"use_auth_token=True"),$o.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(d){d&&t(g)}}}function j5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function D5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function G5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function O5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function V5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function X5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function z5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Q5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForDepthEstimation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function W5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForDepthEstimation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function U5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function H5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function J5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Y5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Z5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function K5a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function e0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function o0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function r0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function t0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function a0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function n0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function s0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function l0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function i0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function d0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function m0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = AutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function c0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/layoutlm_tf_model_config.json")
model = AutoModelForDocumentQuestionAnswering.from_pretrained(
    "./tf_model/layoutlm_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/layoutlm_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/layoutlm_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function f0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function g0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function h0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function u0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function p0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function b0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function v0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function F0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function T0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function M0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function E0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function C0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function w0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function A0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function L0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function y0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function x0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function k0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function S0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function R0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function P0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function B0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function I0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function N0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function q0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function j0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function D0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForZeroShotObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function G0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForZeroShotObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function O0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function V0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function X0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function z0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Q0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function W0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function U0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function H0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function J0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Y0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSemanticSegmentation.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Z0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function K0a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ewa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function owa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function rwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function twa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function awa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function nwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function swa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function lwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function iwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function dwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function mwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function cwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/layoutlm_pt_model_config.json")
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
    "./pt_model/layoutlm_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/layoutlm_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/layoutlm_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function fwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function gwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function hwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function uwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function pwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function _wa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function bwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function vwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Fwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Twa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Mwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Ewa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Cwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function wwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Awa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Lwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function ywa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function xwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function $wa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function kwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Swa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Rwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Pwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Bwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Iwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Nwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function qwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function jwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Dwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Gwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Owa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Vwa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(d),T(f.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,u,h),M(f,d,h),p=!0},p:q,i(d){p||(E(f.$$.fragment,d),p=!0)},o(d){C(f.$$.fragment,d),p=!1},d(d){d&&t(g),d&&t(u),w(f,d)}}}function Xwa($){let g,v,u,f,p,d,h,$o,vd,Qf,Tt,Fd,Td,m$,Wf,Xe,He,Md,ms,c$,cs,fs,f$,Ed,gs,g$,Cd,Uf,on,Je,Ae,yN,wd,xN,$N,ko,rn,kN,Hf,SN,kio,Qto,Ad,Jf,Efe,h$,Sio,Cfe,Rio,Wto,hs,Pio,wfe,Bio,Iio,Afe,Nio,qio,Uto,u$,Hto,RN,jio,Jto,Yf,Yto,Ld,Zf,Lfe,p$,Dio,yfe,Gio,Zto,So,_$,Oio,b$,Vio,PN,Xio,zio,Qio,v$,Wio,xfe,Uio,Hio,Jio,qr,F$,Yio,$fe,Zio,Kio,yd,edo,kfe,odo,rdo,Sfe,tdo,ado,ndo,A,Kf,Rfe,sdo,ldo,BN,ido,ddo,mdo,eg,Pfe,cdo,fdo,IN,gdo,hdo,udo,og,Bfe,pdo,_do,NN,bdo,vdo,Fdo,rg,Ife,Tdo,Mdo,qN,Edo,Cdo,wdo,tg,Nfe,Ado,Ldo,jN,ydo,xdo,$do,ag,qfe,kdo,Sdo,DN,Rdo,Pdo,Bdo,ng,jfe,Ido,Ndo,GN,qdo,jdo,Ddo,sg,Dfe,Gdo,Odo,ON,Vdo,Xdo,zdo,lg,Gfe,Qdo,Wdo,VN,Udo,Hdo,Jdo,ig,Ofe,Ydo,Zdo,XN,Kdo,emo,omo,dg,Vfe,rmo,tmo,zN,amo,nmo,smo,mg,Xfe,lmo,imo,QN,dmo,mmo,cmo,cg,zfe,fmo,gmo,WN,hmo,umo,pmo,fg,Qfe,_mo,bmo,UN,vmo,Fmo,Tmo,gg,Wfe,Mmo,Emo,HN,Cmo,wmo,Amo,hg,Ufe,Lmo,ymo,JN,xmo,$mo,kmo,ug,Hfe,Smo,Rmo,YN,Pmo,Bmo,Imo,pg,Jfe,Nmo,qmo,ZN,jmo,Dmo,Gmo,_g,Yfe,Omo,Vmo,KN,Xmo,zmo,Qmo,bg,Zfe,Wmo,Umo,eq,Hmo,Jmo,Ymo,vg,Kfe,Zmo,Kmo,oq,eco,oco,rco,Fg,ege,tco,aco,rq,nco,sco,lco,Tg,oge,ico,dco,tq,mco,cco,fco,Mg,rge,gco,hco,aq,uco,pco,_co,Eg,tge,bco,vco,nq,Fco,Tco,Mco,Cg,age,Eco,Cco,sq,wco,Aco,Lco,wg,nge,yco,xco,lq,$co,kco,Sco,Ag,sge,Rco,Pco,iq,Bco,Ico,Nco,Lg,lge,qco,jco,dq,Dco,Gco,Oco,yg,ige,Vco,Xco,mq,zco,Qco,Wco,xg,dge,Uco,Hco,cq,Jco,Yco,Zco,$g,mge,Kco,efo,fq,ofo,rfo,tfo,kg,cge,afo,nfo,gq,sfo,lfo,ifo,Sg,fge,dfo,mfo,hq,cfo,ffo,gfo,Rg,gge,hfo,ufo,uq,pfo,_fo,bfo,Pg,hge,vfo,Ffo,pq,Tfo,Mfo,Efo,Bg,uge,Cfo,wfo,_q,Afo,Lfo,yfo,Ig,pge,xfo,$fo,bq,kfo,Sfo,Rfo,Ng,_ge,Pfo,Bfo,vq,Ifo,Nfo,qfo,qg,bge,jfo,Dfo,Fq,Gfo,Ofo,Vfo,jg,vge,Xfo,zfo,Tq,Qfo,Wfo,Ufo,Dg,Fge,Hfo,Jfo,Mq,Yfo,Zfo,Kfo,Gg,Tge,ego,ogo,Eq,rgo,tgo,ago,Og,Mge,ngo,sgo,Cq,lgo,igo,dgo,Vg,Ege,mgo,cgo,wq,fgo,ggo,hgo,Xg,Cge,ugo,pgo,Aq,_go,bgo,vgo,zg,wge,Fgo,Tgo,Lq,Mgo,Ego,Cgo,Qg,Age,wgo,Ago,yq,Lgo,ygo,xgo,Wg,Lge,$go,kgo,xq,Sgo,Rgo,Pgo,Ug,yge,Bgo,Igo,$q,Ngo,qgo,jgo,Hg,xge,Dgo,Ggo,kq,Ogo,Vgo,Xgo,Jg,$ge,zgo,Qgo,Sq,Wgo,Ugo,Hgo,Yg,kge,Jgo,Ygo,Rq,Zgo,Kgo,eho,Zg,Sge,oho,rho,Pq,tho,aho,nho,Kg,Rge,sho,lho,Bq,iho,dho,mho,eh,Pge,cho,fho,Iq,gho,hho,uho,oh,Bge,pho,_ho,Nq,bho,vho,Fho,rh,Ige,Tho,Mho,qq,Eho,Cho,who,th,Nge,Aho,Lho,jq,yho,xho,$ho,ah,qge,kho,Sho,Dq,Rho,Pho,Bho,nh,jge,Iho,Nho,Gq,qho,jho,Dho,sh,Dge,Gho,Oho,Oq,Vho,Xho,zho,lh,Gge,Qho,Who,Vq,Uho,Hho,Jho,ih,Oge,Yho,Zho,Xq,Kho,euo,ouo,dh,Vge,ruo,tuo,zq,auo,nuo,suo,mh,Xge,luo,iuo,Qq,duo,muo,cuo,ch,zge,fuo,guo,Wq,huo,uuo,puo,fh,Qge,_uo,buo,Uq,vuo,Fuo,Tuo,gh,Wge,Muo,Euo,Hq,Cuo,wuo,Auo,hh,Uge,Luo,yuo,Jq,xuo,$uo,kuo,uh,Hge,Suo,Ruo,Yq,Puo,Buo,Iuo,ph,Jge,Nuo,quo,Zq,juo,Duo,Guo,_h,Yge,Ouo,Vuo,Kq,Xuo,zuo,Quo,bh,Zge,Wuo,Uuo,ej,Huo,Juo,Yuo,vh,Kge,Zuo,Kuo,oj,epo,opo,rpo,Fh,ehe,tpo,apo,rj,npo,spo,lpo,Th,ohe,ipo,dpo,tj,mpo,cpo,fpo,Mh,rhe,gpo,hpo,aj,upo,ppo,_po,Eh,the,bpo,vpo,nj,Fpo,Tpo,Mpo,Ch,ahe,Epo,Cpo,sj,wpo,Apo,Lpo,wh,nhe,ypo,xpo,lj,$po,kpo,Spo,Ah,she,Rpo,Ppo,ij,Bpo,Ipo,Npo,Lh,lhe,qpo,jpo,dj,Dpo,Gpo,Opo,yh,ihe,Vpo,Xpo,mj,zpo,Qpo,Wpo,xh,dhe,Upo,Hpo,cj,Jpo,Ypo,Zpo,$h,mhe,Kpo,e_o,fj,o_o,r_o,t_o,kh,che,a_o,n_o,gj,s_o,l_o,i_o,Sh,fhe,d_o,m_o,hj,c_o,f_o,g_o,Rh,ghe,h_o,u_o,uj,p_o,__o,b_o,Ph,hhe,v_o,F_o,pj,T_o,M_o,E_o,Bh,uhe,C_o,w_o,_j,A_o,L_o,y_o,Ih,phe,x_o,$_o,bj,k_o,S_o,R_o,Nh,_he,P_o,B_o,vj,I_o,N_o,q_o,qh,bhe,j_o,D_o,Fj,G_o,O_o,V_o,jh,vhe,X_o,z_o,Tj,Q_o,W_o,U_o,Dh,Fhe,H_o,J_o,Mj,Y_o,Z_o,K_o,Gh,The,e1o,o1o,Ej,r1o,t1o,a1o,Oh,Mhe,n1o,s1o,Cj,l1o,i1o,d1o,Vh,Ehe,m1o,c1o,wj,f1o,g1o,h1o,Xh,Che,u1o,p1o,Aj,_1o,b1o,v1o,zh,whe,F1o,T1o,Lj,M1o,E1o,C1o,Qh,Ahe,w1o,A1o,yj,L1o,y1o,x1o,Wh,Lhe,$1o,k1o,xj,S1o,R1o,P1o,Uh,yhe,B1o,I1o,$j,N1o,q1o,j1o,Hh,xhe,D1o,G1o,kj,O1o,V1o,X1o,Jh,$he,z1o,Q1o,Sj,W1o,U1o,H1o,Yh,khe,J1o,Y1o,Rj,Z1o,K1o,e2o,Zh,She,o2o,r2o,Pj,t2o,a2o,n2o,Kh,Rhe,s2o,l2o,Bj,i2o,d2o,m2o,eu,Phe,c2o,f2o,Ij,g2o,h2o,u2o,ou,Bhe,p2o,_2o,Nj,b2o,v2o,F2o,ru,Ihe,T2o,M2o,qj,E2o,C2o,w2o,tu,Nhe,A2o,L2o,jj,y2o,x2o,$2o,au,qhe,k2o,S2o,Dj,R2o,P2o,B2o,nu,jhe,I2o,N2o,Gj,q2o,j2o,D2o,su,Dhe,G2o,O2o,Oj,V2o,X2o,z2o,lu,Ghe,Q2o,W2o,Vj,U2o,H2o,J2o,iu,Ohe,Y2o,Z2o,Xj,K2o,ebo,obo,du,Vhe,rbo,tbo,zj,abo,nbo,sbo,mu,Xhe,lbo,ibo,Qj,dbo,mbo,cbo,cu,zhe,fbo,gbo,Wj,hbo,ubo,pbo,fu,Qhe,_bo,bbo,Uj,vbo,Fbo,Tbo,gu,Whe,Mbo,Ebo,Hj,Cbo,wbo,Abo,hu,Uhe,Lbo,ybo,Jj,xbo,$bo,kbo,uu,Hhe,Sbo,Rbo,Yj,Pbo,Bbo,Ibo,pu,Jhe,Nbo,qbo,Zj,jbo,Dbo,Gbo,_u,Yhe,Obo,Vbo,Kj,Xbo,zbo,Qbo,bu,Zhe,Wbo,Ubo,eD,Hbo,Jbo,Ybo,vu,Khe,Zbo,Kbo,oD,evo,ovo,rvo,Fu,eue,tvo,avo,rD,nvo,svo,lvo,Tu,oue,ivo,dvo,tD,mvo,cvo,fvo,Mu,rue,gvo,hvo,aD,uvo,pvo,_vo,Eu,tue,bvo,vvo,nD,Fvo,Tvo,Mvo,Cu,aue,Evo,Cvo,sD,wvo,Avo,Lvo,wu,nue,yvo,xvo,lD,$vo,kvo,Svo,Au,sue,Rvo,Pvo,iD,Bvo,Ivo,Nvo,Lu,qvo,yu,T$,jvo,lue,Dvo,Kto,xd,xu,iue,M$,Gvo,due,Ovo,eao,Ro,E$,Vvo,C$,Xvo,dD,zvo,Qvo,Wvo,w$,Uvo,mue,Hvo,Jvo,Yvo,jr,A$,Zvo,cue,Kvo,eFo,tn,oFo,fue,rFo,tFo,gue,aFo,nFo,hue,sFo,lFo,iFo,k,us,uue,dFo,mFo,mD,cFo,fFo,cD,gFo,hFo,uFo,ps,pue,pFo,_Fo,fD,bFo,vFo,gD,FFo,TFo,MFo,_s,_ue,EFo,CFo,hD,wFo,AFo,uD,LFo,yFo,xFo,$u,bue,$Fo,kFo,pD,SFo,RFo,PFo,bs,vue,BFo,IFo,_D,NFo,qFo,bD,jFo,DFo,GFo,ku,Fue,OFo,VFo,vD,XFo,zFo,QFo,Su,Tue,WFo,UFo,FD,HFo,JFo,YFo,Ru,Mue,ZFo,KFo,TD,eTo,oTo,rTo,vs,Eue,tTo,aTo,MD,nTo,sTo,ED,lTo,iTo,dTo,Fs,Cue,mTo,cTo,CD,fTo,gTo,wD,hTo,uTo,pTo,Ts,wue,_To,bTo,AD,vTo,FTo,LD,TTo,MTo,ETo,Pu,Aue,CTo,wTo,yD,ATo,LTo,yTo,Bu,Lue,xTo,$To,xD,kTo,STo,RTo,Iu,yue,PTo,BTo,$D,ITo,NTo,qTo,Ms,xue,jTo,DTo,kD,GTo,OTo,SD,VTo,XTo,zTo,Nu,$ue,QTo,WTo,RD,UTo,HTo,JTo,Es,kue,YTo,ZTo,PD,KTo,eMo,BD,oMo,rMo,tMo,Cs,Sue,aMo,nMo,ID,sMo,lMo,ND,iMo,dMo,mMo,ws,Rue,cMo,fMo,qD,gMo,hMo,jD,uMo,pMo,_Mo,As,Pue,bMo,vMo,DD,FMo,TMo,GD,MMo,EMo,CMo,Ls,Bue,wMo,AMo,OD,LMo,yMo,VD,xMo,$Mo,kMo,qu,Iue,SMo,RMo,XD,PMo,BMo,IMo,ys,Nue,NMo,qMo,zD,jMo,DMo,QD,GMo,OMo,VMo,xs,que,XMo,zMo,WD,QMo,WMo,UD,UMo,HMo,JMo,$s,jue,YMo,ZMo,HD,KMo,eEo,JD,oEo,rEo,tEo,ks,Due,aEo,nEo,YD,sEo,lEo,ZD,iEo,dEo,mEo,Ss,Gue,cEo,fEo,KD,gEo,hEo,eG,uEo,pEo,_Eo,Rs,Oue,bEo,vEo,oG,FEo,TEo,rG,MEo,EEo,CEo,Ps,Vue,wEo,AEo,tG,LEo,yEo,aG,xEo,$Eo,kEo,ju,Xue,SEo,REo,nG,PEo,BEo,IEo,Du,zue,NEo,qEo,sG,jEo,DEo,GEo,Bs,Que,OEo,VEo,lG,XEo,zEo,iG,QEo,WEo,UEo,Gu,Wue,HEo,JEo,dG,YEo,ZEo,KEo,Is,Uue,e4o,o4o,mG,r4o,t4o,cG,a4o,n4o,s4o,Ns,Hue,l4o,i4o,fG,d4o,m4o,gG,c4o,f4o,g4o,qs,Jue,h4o,u4o,hG,p4o,_4o,uG,b4o,v4o,F4o,Ou,Yue,T4o,M4o,pG,E4o,C4o,w4o,Vu,Zue,A4o,L4o,_G,y4o,x4o,$4o,js,Kue,k4o,S4o,bG,R4o,P4o,vG,B4o,I4o,N4o,Ds,epe,q4o,j4o,FG,D4o,G4o,TG,O4o,V4o,X4o,Gs,ope,z4o,Q4o,MG,W4o,U4o,EG,H4o,J4o,Y4o,Xu,rpe,Z4o,K4o,CG,eCo,oCo,rCo,Os,tpe,tCo,aCo,wG,nCo,sCo,AG,lCo,iCo,dCo,Vs,ape,mCo,cCo,LG,fCo,gCo,yG,hCo,uCo,pCo,Xs,npe,_Co,bCo,xG,vCo,FCo,$G,TCo,MCo,ECo,zs,spe,CCo,wCo,kG,ACo,LCo,SG,yCo,xCo,$Co,Qs,lpe,kCo,SCo,RG,RCo,PCo,PG,BCo,ICo,NCo,Ws,ipe,qCo,jCo,BG,DCo,GCo,IG,OCo,VCo,XCo,Us,dpe,zCo,QCo,NG,WCo,UCo,qG,HCo,JCo,YCo,Hs,mpe,ZCo,KCo,jG,e3o,o3o,DG,r3o,t3o,a3o,Js,cpe,n3o,s3o,GG,l3o,i3o,OG,d3o,m3o,c3o,zu,fpe,f3o,g3o,VG,h3o,u3o,p3o,Ys,gpe,_3o,b3o,XG,v3o,F3o,zG,T3o,M3o,E3o,Qu,hpe,C3o,w3o,QG,A3o,L3o,y3o,Wu,upe,x3o,$3o,WG,k3o,S3o,R3o,Zs,ppe,P3o,B3o,UG,I3o,N3o,HG,q3o,j3o,D3o,Ks,_pe,G3o,O3o,JG,V3o,X3o,YG,z3o,Q3o,W3o,el,bpe,U3o,H3o,ZG,J3o,Y3o,KG,Z3o,K3o,e5o,Uu,vpe,o5o,r5o,eO,t5o,a5o,n5o,ol,Fpe,s5o,l5o,oO,i5o,d5o,rO,m5o,c5o,f5o,rl,Tpe,g5o,h5o,tO,u5o,p5o,aO,_5o,b5o,v5o,tl,Mpe,F5o,T5o,nO,M5o,E5o,sO,C5o,w5o,A5o,al,Epe,L5o,y5o,lO,x5o,$5o,iO,k5o,S5o,R5o,nl,Cpe,P5o,B5o,dO,I5o,N5o,mO,q5o,j5o,D5o,sl,wpe,G5o,O5o,cO,V5o,X5o,fO,z5o,Q5o,W5o,ll,Ape,U5o,H5o,gO,J5o,Y5o,hO,Z5o,K5o,e0o,il,Lpe,o0o,r0o,uO,t0o,a0o,pO,n0o,s0o,l0o,Hu,ype,i0o,d0o,_O,m0o,c0o,f0o,dl,xpe,g0o,h0o,bO,u0o,p0o,vO,_0o,b0o,v0o,ml,$pe,F0o,T0o,FO,M0o,E0o,TO,C0o,w0o,A0o,cl,kpe,L0o,y0o,MO,x0o,$0o,EO,k0o,S0o,R0o,Ju,Spe,P0o,B0o,CO,I0o,N0o,q0o,Yu,Rpe,j0o,D0o,wO,G0o,O0o,V0o,Zu,Ppe,X0o,z0o,AO,Q0o,W0o,U0o,Ku,Bpe,H0o,J0o,LO,Y0o,Z0o,K0o,fl,Ipe,ewo,owo,yO,rwo,two,xO,awo,nwo,swo,ep,Npe,lwo,iwo,$O,dwo,mwo,cwo,gl,qpe,fwo,gwo,kO,hwo,uwo,SO,pwo,_wo,bwo,hl,jpe,vwo,Fwo,RO,Two,Mwo,PO,Ewo,Cwo,wwo,ul,Dpe,Awo,Lwo,BO,ywo,xwo,IO,$wo,kwo,Swo,pl,Gpe,Rwo,Pwo,NO,Bwo,Iwo,qO,Nwo,qwo,jwo,_l,Ope,Dwo,Gwo,jO,Owo,Vwo,DO,Xwo,zwo,Qwo,bl,Vpe,Wwo,Uwo,GO,Hwo,Jwo,OO,Ywo,Zwo,Kwo,op,Xpe,eAo,oAo,VO,rAo,tAo,aAo,rp,zpe,nAo,sAo,XO,lAo,iAo,dAo,vl,Qpe,mAo,cAo,zO,fAo,gAo,QO,hAo,uAo,pAo,Fl,Wpe,_Ao,bAo,WO,vAo,FAo,UO,TAo,MAo,EAo,Tl,Upe,CAo,wAo,HO,AAo,LAo,JO,yAo,xAo,$Ao,tp,Hpe,kAo,SAo,YO,RAo,PAo,BAo,ap,Jpe,IAo,NAo,ZO,qAo,jAo,DAo,np,Ype,GAo,OAo,KO,VAo,XAo,zAo,Ml,Zpe,QAo,WAo,eV,UAo,HAo,oV,JAo,YAo,ZAo,El,Kpe,KAo,e6o,rV,o6o,r6o,tV,t6o,a6o,n6o,sp,e_e,s6o,l6o,aV,i6o,d6o,m6o,lp,o_e,c6o,f6o,nV,g6o,h6o,u6o,ip,r_e,p6o,_6o,sV,b6o,v6o,F6o,dp,t_e,T6o,M6o,lV,E6o,C6o,w6o,Cl,a_e,A6o,L6o,iV,y6o,x6o,dV,$6o,k6o,S6o,wl,n_e,R6o,P6o,mV,B6o,I6o,cV,N6o,q6o,j6o,mp,s_e,D6o,G6o,fV,O6o,V6o,X6o,cp,l_e,z6o,Q6o,gV,W6o,U6o,H6o,Al,i_e,J6o,Y6o,hV,Z6o,K6o,uV,e7o,o7o,r7o,Ll,d_e,t7o,a7o,pV,n7o,s7o,_V,l7o,i7o,d7o,yl,m_e,m7o,c7o,bV,f7o,g7o,vV,h7o,u7o,p7o,xl,c_e,_7o,b7o,FV,v7o,F7o,TV,T7o,M7o,E7o,fp,C7o,gp,L$,w7o,f_e,A7o,oao,$d,hp,g_e,y$,L7o,h_e,y7o,rao,Po,x$,x7o,$$,$7o,MV,k7o,S7o,R7o,k$,P7o,u_e,B7o,I7o,N7o,Ye,S$,q7o,p_e,j7o,D7o,an,G7o,__e,O7o,V7o,b_e,X7o,z7o,v_e,Q7o,W7o,U7o,z,up,F_e,H7o,J7o,EV,Y7o,Z7o,K7o,pp,T_e,e8o,o8o,CV,r8o,t8o,a8o,_p,M_e,n8o,s8o,wV,l8o,i8o,d8o,bp,E_e,m8o,c8o,AV,f8o,g8o,h8o,vp,C_e,u8o,p8o,LV,_8o,b8o,v8o,Fp,w_e,F8o,T8o,yV,M8o,E8o,C8o,Tp,A_e,w8o,A8o,xV,L8o,y8o,x8o,Mp,L_e,$8o,k8o,$V,S8o,R8o,P8o,Ep,y_e,B8o,I8o,kV,N8o,q8o,j8o,Cp,x_e,D8o,G8o,SV,O8o,V8o,X8o,wp,$_e,z8o,Q8o,RV,W8o,U8o,H8o,Ap,k_e,J8o,Y8o,PV,Z8o,K8o,eLo,Lp,S_e,oLo,rLo,BV,tLo,aLo,nLo,yp,R_e,sLo,lLo,IV,iLo,dLo,mLo,xp,P_e,cLo,fLo,NV,gLo,hLo,uLo,$p,B_e,pLo,_Lo,qV,bLo,vLo,FLo,kp,I_e,TLo,MLo,jV,ELo,CLo,wLo,Sp,N_e,ALo,LLo,DV,yLo,xLo,$Lo,Rp,q_e,kLo,SLo,GV,RLo,PLo,BLo,Pp,j_e,ILo,NLo,OV,qLo,jLo,DLo,Bp,D_e,GLo,OLo,VV,VLo,XLo,zLo,Ip,G_e,QLo,WLo,XV,ULo,HLo,JLo,Np,O_e,YLo,ZLo,zV,KLo,eyo,oyo,qp,V_e,ryo,tyo,QV,ayo,nyo,syo,jp,X_e,lyo,iyo,WV,dyo,myo,cyo,Dp,z_e,fyo,gyo,UV,hyo,uyo,pyo,Gp,Q_e,_yo,byo,HV,vyo,Fyo,Tyo,Op,W_e,Myo,Eyo,JV,Cyo,wyo,Ayo,Vp,U_e,Lyo,yyo,YV,xyo,$yo,kyo,Xp,H_e,Syo,Ryo,ZV,Pyo,Byo,Iyo,zp,J_e,Nyo,qyo,KV,jyo,Dyo,Gyo,Qp,Y_e,Oyo,Vyo,eX,Xyo,zyo,Qyo,Wp,Z_e,Wyo,Uyo,oX,Hyo,Jyo,Yyo,Up,K_e,Zyo,Kyo,rX,e9o,o9o,r9o,Hp,e1e,t9o,a9o,tX,n9o,s9o,l9o,Jp,o1e,i9o,d9o,aX,m9o,c9o,f9o,Yp,r1e,g9o,h9o,nX,u9o,p9o,_9o,Zp,t1e,b9o,v9o,sX,F9o,T9o,M9o,Kp,a1e,E9o,C9o,lX,w9o,A9o,L9o,e_,n1e,y9o,x9o,iX,$9o,k9o,S9o,o_,s1e,R9o,P9o,dX,B9o,I9o,N9o,r_,l1e,q9o,j9o,mX,D9o,G9o,O9o,t_,i1e,V9o,X9o,cX,z9o,Q9o,W9o,a_,d1e,U9o,H9o,fX,J9o,Y9o,Z9o,n_,m1e,K9o,exo,gX,oxo,rxo,txo,s_,axo,l_,nxo,i_,R$,sxo,c1e,lxo,tao,kd,d_,f1e,P$,ixo,g1e,dxo,aao,Bo,B$,mxo,I$,cxo,hX,fxo,gxo,hxo,N$,uxo,h1e,pxo,_xo,bxo,Ze,q$,vxo,u1e,Fxo,Txo,Sd,Mxo,p1e,Exo,Cxo,_1e,wxo,Axo,Lxo,se,m_,b1e,yxo,xxo,uX,$xo,kxo,Sxo,c_,v1e,Rxo,Pxo,pX,Bxo,Ixo,Nxo,f_,F1e,qxo,jxo,_X,Dxo,Gxo,Oxo,g_,T1e,Vxo,Xxo,bX,zxo,Qxo,Wxo,h_,M1e,Uxo,Hxo,vX,Jxo,Yxo,Zxo,u_,E1e,Kxo,e$o,FX,o$o,r$o,t$o,p_,C1e,a$o,n$o,TX,s$o,l$o,i$o,__,w1e,d$o,m$o,MX,c$o,f$o,g$o,b_,A1e,h$o,u$o,EX,p$o,_$o,b$o,v_,L1e,v$o,F$o,CX,T$o,M$o,E$o,F_,y1e,C$o,w$o,wX,A$o,L$o,y$o,T_,x1e,x$o,$$o,AX,k$o,S$o,R$o,M_,$1e,P$o,B$o,LX,I$o,N$o,q$o,E_,k1e,j$o,D$o,yX,G$o,O$o,V$o,C_,S1e,X$o,z$o,xX,Q$o,W$o,U$o,w_,R1e,H$o,J$o,$X,Y$o,Z$o,K$o,A_,P1e,eko,oko,kX,rko,tko,ako,L_,B1e,nko,sko,SX,lko,iko,dko,y_,I1e,mko,cko,RX,fko,gko,hko,x_,N1e,uko,pko,PX,_ko,bko,vko,$_,q1e,Fko,Tko,BX,Mko,Eko,Cko,k_,j1e,wko,Ako,IX,Lko,yko,xko,S_,D1e,$ko,kko,NX,Sko,Rko,Pko,R_,Bko,P_,Iko,B_,j$,Nko,G1e,qko,nao,Rd,I_,O1e,D$,jko,V1e,Dko,sao,Io,G$,Gko,Pd,Oko,qX,Vko,Xko,jX,zko,Qko,Wko,O$,Uko,X1e,Hko,Jko,Yko,Mt,V$,Zko,z1e,Kko,eSo,Bd,oSo,Q1e,rSo,tSo,DX,aSo,nSo,sSo,N_,lSo,Ke,X$,iSo,W1e,dSo,mSo,nn,cSo,U1e,fSo,gSo,H1e,hSo,uSo,J1e,pSo,_So,bSo,y,q_,Y1e,vSo,FSo,GX,TSo,MSo,ESo,j_,Z1e,CSo,wSo,OX,ASo,LSo,ySo,D_,K1e,xSo,$So,VX,kSo,SSo,RSo,G_,e2e,PSo,BSo,XX,ISo,NSo,qSo,O_,o2e,jSo,DSo,zX,GSo,OSo,VSo,V_,r2e,XSo,zSo,QX,QSo,WSo,USo,X_,t2e,HSo,JSo,WX,YSo,ZSo,KSo,z_,a2e,eRo,oRo,UX,rRo,tRo,aRo,Q_,n2e,nRo,sRo,HX,lRo,iRo,dRo,W_,s2e,mRo,cRo,JX,fRo,gRo,hRo,U_,l2e,uRo,pRo,YX,_Ro,bRo,vRo,H_,i2e,FRo,TRo,ZX,MRo,ERo,CRo,J_,d2e,wRo,ARo,KX,LRo,yRo,xRo,Y_,m2e,$Ro,kRo,ez,SRo,RRo,PRo,Z_,c2e,BRo,IRo,oz,NRo,qRo,jRo,K_,f2e,DRo,GRo,rz,ORo,VRo,XRo,e1,g2e,zRo,QRo,tz,WRo,URo,HRo,o1,h2e,JRo,YRo,az,ZRo,KRo,ePo,r1,u2e,oPo,rPo,nz,tPo,aPo,nPo,t1,p2e,sPo,lPo,sz,iPo,dPo,mPo,a1,_2e,cPo,fPo,lz,gPo,hPo,uPo,n1,b2e,pPo,_Po,iz,bPo,vPo,FPo,s1,v2e,TPo,MPo,dz,EPo,CPo,wPo,l1,F2e,APo,LPo,mz,yPo,xPo,$Po,i1,T2e,kPo,SPo,cz,RPo,PPo,BPo,d1,M2e,IPo,NPo,fz,qPo,jPo,DPo,m1,E2e,GPo,OPo,gz,VPo,XPo,zPo,c1,C2e,QPo,WPo,hz,UPo,HPo,JPo,f1,w2e,YPo,ZPo,uz,KPo,eBo,oBo,g1,A2e,rBo,tBo,pz,aBo,nBo,sBo,h1,L2e,lBo,iBo,_z,dBo,mBo,cBo,u1,y2e,fBo,gBo,bz,hBo,uBo,pBo,p1,x2e,_Bo,bBo,vz,vBo,FBo,TBo,_1,$2e,MBo,EBo,Fz,CBo,wBo,ABo,b1,k2e,LBo,yBo,Tz,xBo,$Bo,kBo,v1,S2e,SBo,RBo,Mz,PBo,BBo,IBo,F1,R2e,NBo,qBo,Ez,jBo,DBo,GBo,T1,P2e,OBo,VBo,Cz,XBo,zBo,QBo,M1,B2e,WBo,UBo,wz,HBo,JBo,YBo,E1,I2e,ZBo,KBo,Az,eIo,oIo,rIo,$l,N2e,tIo,aIo,Lz,nIo,sIo,yz,lIo,iIo,dIo,C1,q2e,mIo,cIo,xz,fIo,gIo,hIo,w1,j2e,uIo,pIo,$z,_Io,bIo,vIo,A1,D2e,FIo,TIo,kz,MIo,EIo,CIo,L1,G2e,wIo,AIo,Sz,LIo,yIo,xIo,y1,O2e,$Io,kIo,Rz,SIo,RIo,PIo,x1,V2e,BIo,IIo,Pz,NIo,qIo,jIo,$1,X2e,DIo,GIo,Bz,OIo,VIo,XIo,k1,z2e,zIo,QIo,Iz,WIo,UIo,HIo,S1,Q2e,JIo,YIo,Nz,ZIo,KIo,eNo,R1,W2e,oNo,rNo,qz,tNo,aNo,nNo,P1,U2e,sNo,lNo,jz,iNo,dNo,mNo,B1,H2e,cNo,fNo,Dz,gNo,hNo,uNo,I1,J2e,pNo,_No,Gz,bNo,vNo,FNo,N1,Y2e,TNo,MNo,Oz,ENo,CNo,wNo,q1,Z2e,ANo,LNo,Vz,yNo,xNo,$No,j1,K2e,kNo,SNo,Xz,RNo,PNo,BNo,D1,ebe,INo,NNo,zz,qNo,jNo,DNo,G1,obe,GNo,ONo,Qz,VNo,XNo,zNo,O1,rbe,QNo,WNo,Wz,UNo,HNo,JNo,V1,tbe,YNo,ZNo,Uz,KNo,eqo,oqo,X1,abe,rqo,tqo,Hz,aqo,nqo,sqo,z1,nbe,lqo,iqo,Jz,dqo,mqo,cqo,Q1,sbe,fqo,gqo,Yz,hqo,uqo,pqo,W1,lbe,_qo,bqo,Zz,vqo,Fqo,Tqo,U1,ibe,Mqo,Eqo,Kz,Cqo,wqo,Aqo,H1,dbe,Lqo,yqo,eQ,xqo,$qo,kqo,J1,mbe,Sqo,Rqo,oQ,Pqo,Bqo,Iqo,Y1,cbe,Nqo,qqo,rQ,jqo,Dqo,Gqo,Z1,fbe,Oqo,Vqo,tQ,Xqo,zqo,Qqo,K1,gbe,Wqo,Uqo,aQ,Hqo,Jqo,Yqo,e2,hbe,Zqo,Kqo,nQ,ejo,ojo,rjo,o2,ube,tjo,ajo,sQ,njo,sjo,ljo,r2,pbe,ijo,djo,lQ,mjo,cjo,fjo,t2,_be,gjo,hjo,iQ,ujo,pjo,_jo,a2,bbe,bjo,vjo,dQ,Fjo,Tjo,Mjo,n2,vbe,Ejo,Cjo,mQ,wjo,Ajo,Ljo,s2,Fbe,yjo,xjo,cQ,$jo,kjo,Sjo,l2,Tbe,Rjo,Pjo,fQ,Bjo,Ijo,Njo,i2,Mbe,qjo,jjo,gQ,Djo,Gjo,Ojo,d2,Ebe,Vjo,Xjo,hQ,zjo,Qjo,Wjo,m2,Cbe,Ujo,Hjo,uQ,Jjo,Yjo,Zjo,c2,wbe,Kjo,eDo,pQ,oDo,rDo,tDo,f2,Abe,aDo,nDo,_Q,sDo,lDo,iDo,g2,Lbe,dDo,mDo,bQ,cDo,fDo,gDo,h2,ybe,hDo,uDo,vQ,pDo,_Do,bDo,u2,xbe,vDo,FDo,FQ,TDo,MDo,EDo,p2,$be,CDo,wDo,TQ,ADo,LDo,yDo,_2,kbe,xDo,$Do,MQ,kDo,SDo,RDo,b2,Sbe,PDo,BDo,EQ,IDo,NDo,qDo,v2,Rbe,jDo,DDo,CQ,GDo,ODo,VDo,F2,Pbe,XDo,zDo,wQ,QDo,WDo,UDo,T2,Bbe,HDo,JDo,AQ,YDo,ZDo,KDo,M2,Ibe,eGo,oGo,LQ,rGo,tGo,aGo,E2,Nbe,nGo,sGo,yQ,lGo,iGo,dGo,C2,qbe,mGo,cGo,xQ,fGo,gGo,hGo,w2,jbe,uGo,pGo,$Q,_Go,bGo,vGo,A2,Dbe,FGo,TGo,kQ,MGo,EGo,CGo,L2,Gbe,wGo,AGo,SQ,LGo,yGo,xGo,y2,Obe,$Go,kGo,RQ,SGo,RGo,PGo,x2,Vbe,BGo,IGo,PQ,NGo,qGo,jGo,$2,Xbe,DGo,GGo,BQ,OGo,VGo,XGo,k2,zbe,zGo,QGo,IQ,WGo,UGo,HGo,S2,Qbe,JGo,YGo,NQ,ZGo,KGo,eOo,R2,Wbe,oOo,rOo,qQ,tOo,aOo,nOo,P2,Ube,sOo,lOo,jQ,iOo,dOo,mOo,B2,Hbe,cOo,fOo,DQ,gOo,hOo,uOo,I2,Jbe,pOo,_Oo,GQ,bOo,vOo,FOo,N2,Ybe,TOo,MOo,OQ,EOo,COo,wOo,q2,Zbe,AOo,LOo,VQ,yOo,xOo,$Oo,j2,Kbe,kOo,SOo,XQ,ROo,POo,BOo,D2,eve,IOo,NOo,zQ,qOo,jOo,DOo,G2,ove,GOo,OOo,QQ,VOo,XOo,zOo,O2,rve,QOo,WOo,WQ,UOo,HOo,JOo,V2,tve,YOo,ZOo,UQ,KOo,eVo,oVo,X2,ave,rVo,tVo,HQ,aVo,nVo,sVo,z2,nve,lVo,iVo,JQ,dVo,mVo,cVo,Q2,sve,fVo,gVo,YQ,hVo,uVo,pVo,W2,lve,_Vo,bVo,ZQ,vVo,FVo,TVo,U2,ive,MVo,EVo,KQ,CVo,wVo,AVo,H2,dve,LVo,yVo,eW,xVo,$Vo,kVo,J2,mve,SVo,RVo,oW,PVo,BVo,IVo,Y2,cve,NVo,qVo,rW,jVo,DVo,GVo,Z2,fve,OVo,VVo,tW,XVo,zVo,QVo,K2,gve,WVo,UVo,aW,HVo,JVo,YVo,eb,hve,ZVo,KVo,nW,eXo,oXo,rXo,ob,uve,tXo,aXo,sW,nXo,sXo,lXo,rb,pve,iXo,dXo,lW,mXo,cXo,fXo,tb,_ve,gXo,hXo,iW,uXo,pXo,_Xo,ab,bve,bXo,vXo,dW,FXo,TXo,MXo,nb,EXo,vve,CXo,wXo,Fve,AXo,LXo,sb,lao,Id,lb,Tve,z$,yXo,Mve,xXo,iao,No,Q$,$Xo,Nd,kXo,mW,SXo,RXo,cW,PXo,BXo,IXo,W$,NXo,Eve,qXo,jXo,DXo,Et,U$,GXo,Cve,OXo,VXo,qd,XXo,wve,zXo,QXo,fW,WXo,UXo,HXo,ib,JXo,eo,H$,YXo,Ave,ZXo,KXo,sn,ezo,Lve,ozo,rzo,yve,tzo,azo,xve,nzo,szo,lzo,G,db,$ve,izo,dzo,gW,mzo,czo,fzo,mb,kve,gzo,hzo,hW,uzo,pzo,_zo,cb,Sve,bzo,vzo,uW,Fzo,Tzo,Mzo,fb,Rve,Ezo,Czo,pW,wzo,Azo,Lzo,gb,Pve,yzo,xzo,_W,$zo,kzo,Szo,hb,Bve,Rzo,Pzo,bW,Bzo,Izo,Nzo,ub,Ive,qzo,jzo,vW,Dzo,Gzo,Ozo,pb,Nve,Vzo,Xzo,FW,zzo,Qzo,Wzo,_b,qve,Uzo,Hzo,TW,Jzo,Yzo,Zzo,bb,jve,Kzo,eQo,MW,oQo,rQo,tQo,vb,Dve,aQo,nQo,EW,sQo,lQo,iQo,Fb,Gve,dQo,mQo,CW,cQo,fQo,gQo,Tb,Ove,hQo,uQo,wW,pQo,_Qo,bQo,Mb,Vve,vQo,FQo,AW,TQo,MQo,EQo,Eb,Xve,CQo,wQo,LW,AQo,LQo,yQo,Cb,zve,xQo,$Qo,yW,kQo,SQo,RQo,wb,Qve,PQo,BQo,xW,IQo,NQo,qQo,Ab,Wve,jQo,DQo,$W,GQo,OQo,VQo,Lb,Uve,XQo,zQo,kW,QQo,WQo,UQo,yb,Hve,HQo,JQo,SW,YQo,ZQo,KQo,xb,Jve,eWo,oWo,RW,rWo,tWo,aWo,$b,Yve,nWo,sWo,PW,lWo,iWo,dWo,kb,Zve,mWo,cWo,BW,fWo,gWo,hWo,Sb,Kve,uWo,pWo,IW,_Wo,bWo,vWo,Rb,eFe,FWo,TWo,NW,MWo,EWo,CWo,Pb,oFe,wWo,AWo,qW,LWo,yWo,xWo,Bb,rFe,$Wo,kWo,jW,SWo,RWo,PWo,Ib,tFe,BWo,IWo,DW,NWo,qWo,jWo,Nb,aFe,DWo,GWo,GW,OWo,VWo,XWo,qb,nFe,zWo,QWo,OW,WWo,UWo,HWo,jb,sFe,JWo,YWo,VW,ZWo,KWo,eUo,Db,lFe,oUo,rUo,XW,tUo,aUo,nUo,Gb,iFe,sUo,lUo,zW,iUo,dUo,mUo,Ob,dFe,cUo,fUo,QW,gUo,hUo,uUo,Vb,mFe,pUo,_Uo,WW,bUo,vUo,FUo,Xb,cFe,TUo,MUo,UW,EUo,CUo,wUo,zb,fFe,AUo,LUo,HW,yUo,xUo,$Uo,Qb,gFe,kUo,SUo,JW,RUo,PUo,BUo,Wb,hFe,IUo,NUo,YW,qUo,jUo,DUo,Ub,uFe,GUo,OUo,ZW,VUo,XUo,zUo,Hb,pFe,QUo,WUo,KW,UUo,HUo,JUo,Jb,_Fe,YUo,ZUo,eU,KUo,eHo,oHo,Yb,bFe,rHo,tHo,oU,aHo,nHo,sHo,Zb,vFe,lHo,iHo,rU,dHo,mHo,cHo,Kb,FFe,fHo,gHo,tU,hHo,uHo,pHo,ev,TFe,_Ho,bHo,aU,vHo,FHo,THo,ov,MFe,MHo,EHo,nU,CHo,wHo,AHo,rv,EFe,LHo,yHo,sU,xHo,$Ho,kHo,tv,SHo,CFe,RHo,PHo,wFe,BHo,IHo,av,dao,jd,nv,AFe,J$,NHo,LFe,qHo,mao,qo,Y$,jHo,Dd,DHo,lU,GHo,OHo,iU,VHo,XHo,zHo,Z$,QHo,yFe,WHo,UHo,HHo,Ct,K$,JHo,xFe,YHo,ZHo,Gd,KHo,$Fe,eJo,oJo,dU,rJo,tJo,aJo,sv,nJo,oo,ek,sJo,kFe,lJo,iJo,ln,dJo,SFe,mJo,cJo,RFe,fJo,gJo,PFe,hJo,uJo,pJo,W,lv,BFe,_Jo,bJo,mU,vJo,FJo,TJo,iv,IFe,MJo,EJo,cU,CJo,wJo,AJo,dv,NFe,LJo,yJo,fU,xJo,$Jo,kJo,mv,qFe,SJo,RJo,gU,PJo,BJo,IJo,cv,jFe,NJo,qJo,hU,jJo,DJo,GJo,fv,DFe,OJo,VJo,uU,XJo,zJo,QJo,gv,GFe,WJo,UJo,pU,HJo,JJo,YJo,hv,OFe,ZJo,KJo,_U,eYo,oYo,rYo,uv,VFe,tYo,aYo,bU,nYo,sYo,lYo,pv,XFe,iYo,dYo,vU,mYo,cYo,fYo,_v,zFe,gYo,hYo,FU,uYo,pYo,_Yo,bv,QFe,bYo,vYo,TU,FYo,TYo,MYo,vv,WFe,EYo,CYo,MU,wYo,AYo,LYo,Fv,UFe,yYo,xYo,EU,$Yo,kYo,SYo,Tv,HFe,RYo,PYo,CU,BYo,IYo,NYo,Mv,JFe,qYo,jYo,wU,DYo,GYo,OYo,Ev,YFe,VYo,XYo,AU,zYo,QYo,WYo,Cv,ZFe,UYo,HYo,LU,JYo,YYo,ZYo,wv,KFe,KYo,eZo,yU,oZo,rZo,tZo,Av,eTe,aZo,nZo,xU,sZo,lZo,iZo,Lv,oTe,dZo,mZo,$U,cZo,fZo,gZo,yv,rTe,hZo,uZo,kU,pZo,_Zo,bZo,xv,tTe,vZo,FZo,SU,TZo,MZo,EZo,$v,aTe,CZo,wZo,RU,AZo,LZo,yZo,kv,nTe,xZo,$Zo,PU,kZo,SZo,RZo,Sv,sTe,PZo,BZo,BU,IZo,NZo,qZo,Rv,lTe,jZo,DZo,IU,GZo,OZo,VZo,Pv,iTe,XZo,zZo,NU,QZo,WZo,UZo,Bv,dTe,HZo,JZo,qU,YZo,ZZo,KZo,Iv,mTe,eKo,oKo,jU,rKo,tKo,aKo,Nv,cTe,nKo,sKo,DU,lKo,iKo,dKo,qv,fTe,mKo,cKo,GU,fKo,gKo,hKo,jv,gTe,uKo,pKo,OU,_Ko,bKo,vKo,Dv,hTe,FKo,TKo,VU,MKo,EKo,CKo,Gv,uTe,wKo,AKo,XU,LKo,yKo,xKo,Ov,pTe,$Ko,kKo,zU,SKo,RKo,PKo,Vv,_Te,BKo,IKo,QU,NKo,qKo,jKo,Xv,bTe,DKo,GKo,WU,OKo,VKo,XKo,zv,vTe,zKo,QKo,UU,WKo,UKo,HKo,Qv,FTe,JKo,YKo,HU,ZKo,KKo,eer,Wv,TTe,oer,rer,JU,ter,aer,ner,Uv,MTe,ser,ler,YU,ier,der,mer,Hv,cer,ETe,fer,ger,CTe,her,uer,Jv,cao,Od,Yv,wTe,ok,per,ATe,_er,fao,jo,rk,ber,Vd,ver,ZU,Fer,Ter,KU,Mer,Eer,Cer,tk,wer,LTe,Aer,Ler,yer,wt,ak,xer,yTe,$er,ker,Xd,Ser,xTe,Rer,Per,eH,Ber,Ier,Ner,Zv,qer,ro,nk,jer,$Te,Der,Ger,dn,Oer,kTe,Ver,Xer,STe,zer,Qer,RTe,Wer,Uer,Her,sk,Kv,PTe,Jer,Yer,oH,Zer,Ker,eor,eF,BTe,oor,ror,rH,tor,aor,nor,oF,sor,ITe,lor,ior,NTe,dor,mor,rF,gao,zd,tF,qTe,lk,cor,jTe,gor,hao,Do,ik,hor,Qd,uor,tH,por,_or,aH,bor,vor,For,dk,Tor,DTe,Mor,Eor,Cor,At,mk,wor,GTe,Aor,Lor,Wd,yor,OTe,xor,$or,nH,kor,Sor,Ror,aF,Por,to,ck,Bor,VTe,Ior,Nor,mn,qor,XTe,jor,Dor,zTe,Gor,Oor,QTe,Vor,Xor,zor,Y,nF,WTe,Qor,Wor,sH,Uor,Hor,Jor,sF,UTe,Yor,Zor,lH,Kor,err,orr,lF,HTe,rrr,trr,iH,arr,nrr,srr,iF,JTe,lrr,irr,dH,drr,mrr,crr,dF,YTe,frr,grr,mH,hrr,urr,prr,mF,ZTe,_rr,brr,cH,vrr,Frr,Trr,cF,KTe,Mrr,Err,fH,Crr,wrr,Arr,fF,eMe,Lrr,yrr,gH,xrr,$rr,krr,gF,oMe,Srr,Rrr,hH,Prr,Brr,Irr,hF,rMe,Nrr,qrr,uH,jrr,Drr,Grr,uF,tMe,Orr,Vrr,pH,Xrr,zrr,Qrr,pF,aMe,Wrr,Urr,_H,Hrr,Jrr,Yrr,_F,nMe,Zrr,Krr,bH,etr,otr,rtr,bF,sMe,ttr,atr,vH,ntr,str,ltr,vF,lMe,itr,dtr,FH,mtr,ctr,ftr,FF,iMe,gtr,htr,TH,utr,ptr,_tr,TF,dMe,btr,vtr,MH,Ftr,Ttr,Mtr,MF,mMe,Etr,Ctr,EH,wtr,Atr,Ltr,EF,cMe,ytr,xtr,CH,$tr,ktr,Str,CF,fMe,Rtr,Ptr,wH,Btr,Itr,Ntr,wF,gMe,qtr,jtr,AH,Dtr,Gtr,Otr,AF,hMe,Vtr,Xtr,LH,ztr,Qtr,Wtr,LF,uMe,Utr,Htr,yH,Jtr,Ytr,Ztr,yF,pMe,Ktr,ear,xH,oar,rar,tar,xF,_Me,aar,nar,$H,sar,lar,iar,$F,bMe,dar,mar,kH,car,far,gar,kF,vMe,har,uar,SH,par,_ar,bar,SF,FMe,Far,Tar,RH,Mar,Ear,Car,RF,TMe,war,Aar,PH,Lar,yar,xar,PF,MMe,$ar,kar,BH,Sar,Rar,Par,BF,EMe,Bar,Iar,IH,Nar,qar,jar,IF,CMe,Dar,Gar,NH,Oar,Var,Xar,NF,wMe,zar,Qar,qH,War,Uar,Har,qF,AMe,Jar,Yar,jH,Zar,Kar,enr,jF,LMe,onr,rnr,yMe,tnr,anr,nnr,DF,xMe,snr,lnr,DH,inr,dnr,mnr,GF,$Me,cnr,fnr,GH,gnr,hnr,unr,OF,kMe,pnr,_nr,OH,bnr,vnr,Fnr,VF,SMe,Tnr,Mnr,VH,Enr,Cnr,wnr,XF,Anr,RMe,Lnr,ynr,PMe,xnr,$nr,zF,uao,Ud,QF,BMe,fk,knr,IMe,Snr,pao,Go,gk,Rnr,Hd,Pnr,XH,Bnr,Inr,zH,Nnr,qnr,jnr,hk,Dnr,NMe,Gnr,Onr,Vnr,Lt,uk,Xnr,qMe,znr,Qnr,Jd,Wnr,jMe,Unr,Hnr,QH,Jnr,Ynr,Znr,WF,Knr,ao,pk,esr,DMe,osr,rsr,cn,tsr,GMe,asr,nsr,OMe,ssr,lsr,VMe,isr,dsr,msr,he,UF,XMe,csr,fsr,WH,gsr,hsr,usr,HF,zMe,psr,_sr,UH,bsr,vsr,Fsr,JF,QMe,Tsr,Msr,HH,Esr,Csr,wsr,YF,WMe,Asr,Lsr,JH,ysr,xsr,$sr,ZF,UMe,ksr,Ssr,YH,Rsr,Psr,Bsr,KF,HMe,Isr,Nsr,ZH,qsr,jsr,Dsr,eT,JMe,Gsr,Osr,KH,Vsr,Xsr,zsr,oT,YMe,Qsr,Wsr,eJ,Usr,Hsr,Jsr,rT,ZMe,Ysr,Zsr,oJ,Ksr,elr,olr,tT,KMe,rlr,tlr,rJ,alr,nlr,slr,aT,eEe,llr,ilr,tJ,dlr,mlr,clr,nT,oEe,flr,glr,aJ,hlr,ulr,plr,sT,rEe,_lr,blr,nJ,vlr,Flr,Tlr,lT,tEe,Mlr,Elr,sJ,Clr,wlr,Alr,iT,aEe,Llr,ylr,lJ,xlr,$lr,klr,dT,nEe,Slr,Rlr,iJ,Plr,Blr,Ilr,mT,sEe,Nlr,qlr,dJ,jlr,Dlr,Glr,cT,lEe,Olr,Vlr,mJ,Xlr,zlr,Qlr,fT,iEe,Wlr,Ulr,cJ,Hlr,Jlr,Ylr,gT,dEe,Zlr,Klr,fJ,eir,oir,rir,hT,tir,mEe,air,nir,cEe,sir,lir,uT,_ao,Yd,pT,fEe,_k,iir,gEe,dir,bao,Oo,bk,mir,Zd,cir,gJ,fir,gir,hJ,hir,uir,pir,vk,_ir,hEe,bir,vir,Fir,yt,Fk,Tir,uEe,Mir,Eir,Kd,Cir,pEe,wir,Air,uJ,Lir,yir,xir,_T,$ir,no,Tk,kir,_Ee,Sir,Rir,fn,Pir,bEe,Bir,Iir,vEe,Nir,qir,FEe,jir,Dir,Gir,j,bT,TEe,Oir,Vir,pJ,Xir,zir,Qir,vT,MEe,Wir,Uir,_J,Hir,Jir,Yir,FT,EEe,Zir,Kir,bJ,edr,odr,rdr,TT,CEe,tdr,adr,vJ,ndr,sdr,ldr,MT,wEe,idr,ddr,FJ,mdr,cdr,fdr,ET,AEe,gdr,hdr,TJ,udr,pdr,_dr,CT,LEe,bdr,vdr,MJ,Fdr,Tdr,Mdr,wT,yEe,Edr,Cdr,EJ,wdr,Adr,Ldr,AT,xEe,ydr,xdr,CJ,$dr,kdr,Sdr,LT,$Ee,Rdr,Pdr,wJ,Bdr,Idr,Ndr,yT,kEe,qdr,jdr,AJ,Ddr,Gdr,Odr,xT,SEe,Vdr,Xdr,LJ,zdr,Qdr,Wdr,$T,REe,Udr,Hdr,yJ,Jdr,Ydr,Zdr,kT,PEe,Kdr,emr,xJ,omr,rmr,tmr,ST,BEe,amr,nmr,$J,smr,lmr,imr,RT,IEe,dmr,mmr,kJ,cmr,fmr,gmr,PT,NEe,hmr,umr,SJ,pmr,_mr,bmr,BT,qEe,vmr,Fmr,RJ,Tmr,Mmr,Emr,IT,jEe,Cmr,wmr,PJ,Amr,Lmr,ymr,NT,DEe,xmr,$mr,BJ,kmr,Smr,Rmr,qT,GEe,Pmr,Bmr,IJ,Imr,Nmr,qmr,jT,OEe,jmr,Dmr,NJ,Gmr,Omr,Vmr,DT,VEe,Xmr,zmr,qJ,Qmr,Wmr,Umr,GT,XEe,Hmr,Jmr,jJ,Ymr,Zmr,Kmr,OT,zEe,ecr,ocr,DJ,rcr,tcr,acr,VT,QEe,ncr,scr,GJ,lcr,icr,dcr,XT,WEe,mcr,ccr,OJ,fcr,gcr,hcr,zT,UEe,ucr,pcr,VJ,_cr,bcr,vcr,QT,HEe,Fcr,Tcr,XJ,Mcr,Ecr,Ccr,WT,JEe,wcr,Acr,zJ,Lcr,ycr,xcr,UT,YEe,$cr,kcr,QJ,Scr,Rcr,Pcr,HT,ZEe,Bcr,Icr,WJ,Ncr,qcr,jcr,JT,KEe,Dcr,Gcr,UJ,Ocr,Vcr,Xcr,YT,e4e,zcr,Qcr,HJ,Wcr,Ucr,Hcr,ZT,o4e,Jcr,Ycr,JJ,Zcr,Kcr,efr,KT,r4e,ofr,rfr,YJ,tfr,afr,nfr,eM,t4e,sfr,lfr,ZJ,ifr,dfr,mfr,oM,a4e,cfr,ffr,KJ,gfr,hfr,ufr,rM,n4e,pfr,_fr,eY,bfr,vfr,Ffr,tM,s4e,Tfr,Mfr,oY,Efr,Cfr,wfr,aM,l4e,Afr,Lfr,rY,yfr,xfr,$fr,nM,i4e,kfr,Sfr,tY,Rfr,Pfr,Bfr,sM,d4e,Ifr,Nfr,aY,qfr,jfr,Dfr,lM,m4e,Gfr,Ofr,nY,Vfr,Xfr,zfr,iM,c4e,Qfr,Wfr,sY,Ufr,Hfr,Jfr,dM,f4e,Yfr,Zfr,lY,Kfr,egr,ogr,mM,g4e,rgr,tgr,iY,agr,ngr,sgr,cM,h4e,lgr,igr,dY,dgr,mgr,cgr,fM,u4e,fgr,ggr,mY,hgr,ugr,pgr,gM,p4e,_gr,bgr,cY,vgr,Fgr,Tgr,hM,_4e,Mgr,Egr,fY,Cgr,wgr,Agr,uM,b4e,Lgr,ygr,gY,xgr,$gr,kgr,pM,v4e,Sgr,Rgr,hY,Pgr,Bgr,Igr,_M,F4e,Ngr,qgr,uY,jgr,Dgr,Ggr,bM,T4e,Ogr,Vgr,pY,Xgr,zgr,Qgr,vM,M4e,Wgr,Ugr,_Y,Hgr,Jgr,Ygr,FM,Zgr,E4e,Kgr,ehr,C4e,ohr,rhr,TM,vao,em,MM,w4e,Mk,thr,A4e,ahr,Fao,Vo,Ek,nhr,om,shr,bY,lhr,ihr,vY,dhr,mhr,chr,Ck,fhr,L4e,ghr,hhr,uhr,xt,wk,phr,y4e,_hr,bhr,rm,vhr,x4e,Fhr,Thr,FY,Mhr,Ehr,Chr,EM,whr,so,Ak,Ahr,$4e,Lhr,yhr,gn,xhr,k4e,$hr,khr,S4e,Shr,Rhr,R4e,Phr,Bhr,Ihr,K,CM,P4e,Nhr,qhr,TY,jhr,Dhr,Ghr,wM,B4e,Ohr,Vhr,MY,Xhr,zhr,Qhr,AM,I4e,Whr,Uhr,EY,Hhr,Jhr,Yhr,LM,N4e,Zhr,Khr,CY,eur,our,rur,yM,q4e,tur,aur,wY,nur,sur,lur,xM,j4e,iur,dur,AY,mur,cur,fur,$M,D4e,gur,hur,LY,uur,pur,_ur,kM,G4e,bur,vur,yY,Fur,Tur,Mur,SM,O4e,Eur,Cur,xY,wur,Aur,Lur,RM,V4e,yur,xur,$Y,$ur,kur,Sur,PM,X4e,Rur,Pur,kY,Bur,Iur,Nur,BM,z4e,qur,jur,SY,Dur,Gur,Our,IM,Q4e,Vur,Xur,RY,zur,Qur,Wur,NM,W4e,Uur,Hur,PY,Jur,Yur,Zur,qM,U4e,Kur,epr,BY,opr,rpr,tpr,jM,H4e,apr,npr,IY,spr,lpr,ipr,DM,J4e,dpr,mpr,NY,cpr,fpr,gpr,GM,Y4e,hpr,upr,qY,ppr,_pr,bpr,OM,Z4e,vpr,Fpr,jY,Tpr,Mpr,Epr,VM,K4e,Cpr,wpr,DY,Apr,Lpr,ypr,XM,eCe,xpr,$pr,GY,kpr,Spr,Rpr,zM,oCe,Ppr,Bpr,OY,Ipr,Npr,qpr,QM,rCe,jpr,Dpr,VY,Gpr,Opr,Vpr,WM,tCe,Xpr,zpr,XY,Qpr,Wpr,Upr,UM,aCe,Hpr,Jpr,zY,Ypr,Zpr,Kpr,HM,nCe,e_r,o_r,QY,r_r,t_r,a_r,JM,sCe,n_r,s_r,WY,l_r,i_r,d_r,YM,lCe,m_r,c_r,UY,f_r,g_r,h_r,ZM,iCe,u_r,p_r,HY,__r,b_r,v_r,KM,dCe,F_r,T_r,JY,M_r,E_r,C_r,eE,mCe,w_r,A_r,YY,L_r,y_r,x_r,oE,cCe,$_r,k_r,ZY,S_r,R_r,P_r,rE,B_r,fCe,I_r,N_r,gCe,q_r,j_r,tE,Tao,tm,aE,hCe,Lk,D_r,uCe,G_r,Mao,Xo,yk,O_r,am,V_r,KY,X_r,z_r,eZ,Q_r,W_r,U_r,xk,H_r,pCe,J_r,Y_r,Z_r,$t,$k,K_r,_Ce,e1r,o1r,nm,r1r,bCe,t1r,a1r,oZ,n1r,s1r,l1r,nE,i1r,lo,kk,d1r,vCe,m1r,c1r,hn,f1r,FCe,g1r,h1r,TCe,u1r,p1r,MCe,_1r,b1r,v1r,Ue,sE,ECe,F1r,T1r,rZ,M1r,E1r,C1r,lE,CCe,w1r,A1r,tZ,L1r,y1r,x1r,iE,wCe,$1r,k1r,aZ,S1r,R1r,P1r,dE,ACe,B1r,I1r,nZ,N1r,q1r,j1r,mE,LCe,D1r,G1r,sZ,O1r,V1r,X1r,cE,yCe,z1r,Q1r,lZ,W1r,U1r,H1r,fE,xCe,J1r,Y1r,iZ,Z1r,K1r,e2r,gE,o2r,$Ce,r2r,t2r,kCe,a2r,n2r,hE,Eao,sm,uE,SCe,Sk,s2r,RCe,l2r,Cao,zo,Rk,i2r,lm,d2r,dZ,m2r,c2r,mZ,f2r,g2r,h2r,Pk,u2r,PCe,p2r,_2r,b2r,kt,Bk,v2r,BCe,F2r,T2r,im,M2r,ICe,E2r,C2r,cZ,w2r,A2r,L2r,pE,y2r,io,Ik,x2r,NCe,$2r,k2r,un,S2r,qCe,R2r,P2r,jCe,B2r,I2r,DCe,N2r,q2r,j2r,U,_E,GCe,D2r,G2r,fZ,O2r,V2r,X2r,bE,OCe,z2r,Q2r,gZ,W2r,U2r,H2r,vE,VCe,J2r,Y2r,hZ,Z2r,K2r,ebr,FE,XCe,obr,rbr,uZ,tbr,abr,nbr,TE,zCe,sbr,lbr,pZ,ibr,dbr,mbr,ME,QCe,cbr,fbr,_Z,gbr,hbr,ubr,EE,WCe,pbr,_br,bZ,bbr,vbr,Fbr,CE,UCe,Tbr,Mbr,vZ,Ebr,Cbr,wbr,wE,HCe,Abr,Lbr,FZ,ybr,xbr,$br,AE,JCe,kbr,Sbr,TZ,Rbr,Pbr,Bbr,LE,YCe,Ibr,Nbr,MZ,qbr,jbr,Dbr,yE,ZCe,Gbr,Obr,EZ,Vbr,Xbr,zbr,xE,KCe,Qbr,Wbr,CZ,Ubr,Hbr,Jbr,$E,e3e,Ybr,Zbr,wZ,Kbr,evr,ovr,kE,o3e,rvr,tvr,AZ,avr,nvr,svr,SE,r3e,lvr,ivr,LZ,dvr,mvr,cvr,RE,t3e,fvr,gvr,yZ,hvr,uvr,pvr,PE,a3e,_vr,bvr,xZ,vvr,Fvr,Tvr,BE,n3e,Mvr,Evr,$Z,Cvr,wvr,Avr,IE,s3e,Lvr,yvr,kZ,xvr,$vr,kvr,NE,l3e,Svr,Rvr,SZ,Pvr,Bvr,Ivr,qE,i3e,Nvr,qvr,RZ,jvr,Dvr,Gvr,jE,d3e,Ovr,Vvr,PZ,Xvr,zvr,Qvr,DE,m3e,Wvr,Uvr,BZ,Hvr,Jvr,Yvr,GE,c3e,Zvr,Kvr,IZ,eFr,oFr,rFr,OE,f3e,tFr,aFr,NZ,nFr,sFr,lFr,VE,g3e,iFr,dFr,qZ,mFr,cFr,fFr,XE,h3e,gFr,hFr,jZ,uFr,pFr,_Fr,zE,u3e,bFr,vFr,DZ,FFr,TFr,MFr,QE,p3e,EFr,CFr,GZ,wFr,AFr,LFr,WE,_3e,yFr,xFr,OZ,$Fr,kFr,SFr,UE,b3e,RFr,PFr,VZ,BFr,IFr,NFr,HE,v3e,qFr,jFr,XZ,DFr,GFr,OFr,JE,F3e,VFr,XFr,zZ,zFr,QFr,WFr,YE,T3e,UFr,HFr,QZ,JFr,YFr,ZFr,ZE,M3e,KFr,eTr,WZ,oTr,rTr,tTr,KE,E3e,aTr,nTr,UZ,sTr,lTr,iTr,e4,C3e,dTr,mTr,HZ,cTr,fTr,gTr,o4,w3e,hTr,uTr,JZ,pTr,_Tr,bTr,r4,A3e,vTr,FTr,YZ,TTr,MTr,ETr,t4,L3e,CTr,wTr,ZZ,ATr,LTr,yTr,a4,xTr,y3e,$Tr,kTr,x3e,STr,RTr,n4,wao,dm,s4,$3e,Nk,PTr,k3e,BTr,Aao,Qo,qk,ITr,mm,NTr,KZ,qTr,jTr,eK,DTr,GTr,OTr,jk,VTr,S3e,XTr,zTr,QTr,St,Dk,WTr,R3e,UTr,HTr,cm,JTr,P3e,YTr,ZTr,oK,KTr,eMr,oMr,l4,rMr,mo,Gk,tMr,B3e,aMr,nMr,pn,sMr,I3e,lMr,iMr,N3e,dMr,mMr,q3e,cMr,fMr,gMr,O,i4,j3e,hMr,uMr,rK,pMr,_Mr,bMr,d4,D3e,vMr,FMr,tK,TMr,MMr,EMr,m4,G3e,CMr,wMr,aK,AMr,LMr,yMr,c4,O3e,xMr,$Mr,nK,kMr,SMr,RMr,f4,V3e,PMr,BMr,sK,IMr,NMr,qMr,g4,X3e,jMr,DMr,lK,GMr,OMr,VMr,h4,z3e,XMr,zMr,iK,QMr,WMr,UMr,u4,Q3e,HMr,JMr,dK,YMr,ZMr,KMr,p4,W3e,eEr,oEr,mK,rEr,tEr,aEr,_4,U3e,nEr,sEr,cK,lEr,iEr,dEr,b4,H3e,mEr,cEr,fK,fEr,gEr,hEr,v4,J3e,uEr,pEr,gK,_Er,bEr,vEr,F4,Y3e,FEr,TEr,hK,MEr,EEr,CEr,T4,Z3e,wEr,AEr,uK,LEr,yEr,xEr,M4,K3e,$Er,kEr,pK,SEr,REr,PEr,E4,e5e,BEr,IEr,_K,NEr,qEr,jEr,C4,o5e,DEr,GEr,bK,OEr,VEr,XEr,w4,r5e,zEr,QEr,vK,WEr,UEr,HEr,A4,t5e,JEr,YEr,FK,ZEr,KEr,e4r,L4,a5e,o4r,r4r,TK,t4r,a4r,n4r,y4,n5e,s4r,l4r,MK,i4r,d4r,m4r,x4,s5e,c4r,f4r,EK,g4r,h4r,u4r,$4,l5e,p4r,_4r,CK,b4r,v4r,F4r,k4,i5e,T4r,M4r,wK,E4r,C4r,w4r,S4,d5e,A4r,L4r,AK,y4r,x4r,$4r,R4,m5e,k4r,S4r,LK,R4r,P4r,B4r,P4,c5e,I4r,N4r,yK,q4r,j4r,D4r,B4,f5e,G4r,O4r,xK,V4r,X4r,z4r,I4,g5e,Q4r,W4r,$K,U4r,H4r,J4r,N4,h5e,Y4r,Z4r,kK,K4r,eCr,oCr,q4,u5e,rCr,tCr,SK,aCr,nCr,sCr,j4,p5e,lCr,iCr,RK,dCr,mCr,cCr,D4,_5e,fCr,gCr,PK,hCr,uCr,pCr,G4,b5e,_Cr,bCr,BK,vCr,FCr,TCr,O4,v5e,MCr,ECr,IK,CCr,wCr,ACr,V4,F5e,LCr,yCr,NK,xCr,$Cr,kCr,X4,T5e,SCr,RCr,qK,PCr,BCr,ICr,z4,M5e,NCr,qCr,jK,jCr,DCr,GCr,Q4,E5e,OCr,VCr,DK,XCr,zCr,QCr,W4,C5e,WCr,UCr,GK,HCr,JCr,YCr,U4,w5e,ZCr,KCr,OK,e3r,o3r,r3r,H4,A5e,t3r,a3r,VK,n3r,s3r,l3r,J4,L5e,i3r,d3r,XK,m3r,c3r,f3r,Y4,y5e,g3r,h3r,zK,u3r,p3r,_3r,Z4,x5e,b3r,v3r,QK,F3r,T3r,M3r,K4,$5e,E3r,C3r,WK,w3r,A3r,L3r,eC,k5e,y3r,x3r,UK,$3r,k3r,S3r,oC,S5e,R3r,P3r,HK,B3r,I3r,N3r,rC,q3r,R5e,j3r,D3r,P5e,G3r,O3r,tC,Lao,fm,aC,B5e,Ok,V3r,I5e,X3r,yao,Wo,Vk,z3r,gm,Q3r,JK,W3r,U3r,YK,H3r,J3r,Y3r,Xk,Z3r,N5e,K3r,e5r,o5r,Rt,zk,r5r,q5e,t5r,a5r,hm,n5r,j5e,s5r,l5r,ZK,i5r,d5r,m5r,nC,c5r,co,Qk,f5r,D5e,g5r,h5r,_n,u5r,G5e,p5r,_5r,O5e,b5r,v5r,V5e,F5r,T5r,M5r,X5e,sC,z5e,E5r,C5r,KK,w5r,A5r,L5r,lC,y5r,Q5e,x5r,$5r,W5e,k5r,S5r,iC,xao,um,dC,U5e,Wk,R5r,H5e,P5r,$ao,Uo,Uk,B5r,pm,I5r,eee,N5r,q5r,oee,j5r,D5r,G5r,Hk,O5r,J5e,V5r,X5r,z5r,Pt,Jk,Q5r,Y5e,W5r,U5r,_m,H5r,Z5e,J5r,Y5r,ree,Z5r,K5r,e0r,mC,o0r,fo,Yk,r0r,K5e,t0r,a0r,bn,n0r,e0e,s0r,l0r,o0e,i0r,d0r,r0e,m0r,c0r,f0r,bm,cC,t0e,g0r,h0r,tee,u0r,p0r,_0r,fC,a0e,b0r,v0r,aee,F0r,T0r,M0r,gC,n0e,E0r,C0r,nee,w0r,A0r,L0r,hC,y0r,s0e,x0r,$0r,l0e,k0r,S0r,uC,kao,vm,pC,i0e,Zk,R0r,d0e,P0r,Sao,Ho,Kk,B0r,Fm,I0r,see,N0r,q0r,lee,j0r,D0r,G0r,eS,O0r,m0e,V0r,X0r,z0r,Bt,oS,Q0r,c0e,W0r,U0r,Tm,H0r,f0e,J0r,Y0r,iee,Z0r,K0r,ewr,_C,owr,go,rS,rwr,g0e,twr,awr,vn,nwr,h0e,swr,lwr,u0e,iwr,dwr,p0e,mwr,cwr,fwr,be,bC,_0e,gwr,hwr,dee,uwr,pwr,_wr,vC,b0e,bwr,vwr,mee,Fwr,Twr,Mwr,FC,v0e,Ewr,Cwr,cee,wwr,Awr,Lwr,TC,F0e,ywr,xwr,fee,$wr,kwr,Swr,kl,T0e,Rwr,Pwr,gee,Bwr,Iwr,hee,Nwr,qwr,jwr,MC,M0e,Dwr,Gwr,uee,Owr,Vwr,Xwr,Sl,E0e,zwr,Qwr,pee,Wwr,Uwr,_ee,Hwr,Jwr,Ywr,EC,C0e,Zwr,Kwr,bee,eAr,oAr,rAr,It,w0e,tAr,aAr,vee,nAr,sAr,Fee,lAr,iAr,Tee,dAr,mAr,cAr,CC,A0e,fAr,gAr,Mee,hAr,uAr,pAr,wC,L0e,_Ar,bAr,Eee,vAr,FAr,TAr,AC,y0e,MAr,EAr,Cee,CAr,wAr,AAr,LC,x0e,LAr,yAr,wee,xAr,$Ar,kAr,yC,$0e,SAr,RAr,Aee,PAr,BAr,IAr,xC,k0e,NAr,qAr,Lee,jAr,DAr,GAr,$C,S0e,OAr,VAr,yee,XAr,zAr,QAr,kC,R0e,WAr,UAr,xee,HAr,JAr,YAr,SC,P0e,ZAr,KAr,$ee,e6r,o6r,r6r,RC,t6r,B0e,a6r,n6r,I0e,s6r,l6r,PC,Rao,Mm,BC,N0e,tS,i6r,q0e,d6r,Pao,Jo,aS,m6r,Em,c6r,kee,f6r,g6r,See,h6r,u6r,p6r,nS,_6r,j0e,b6r,v6r,F6r,Nt,sS,T6r,D0e,M6r,E6r,Cm,C6r,G0e,w6r,A6r,Ree,L6r,y6r,x6r,IC,$6r,ho,lS,k6r,O0e,S6r,R6r,Fn,P6r,V0e,B6r,I6r,X0e,N6r,q6r,z0e,j6r,D6r,G6r,Q0e,NC,W0e,O6r,V6r,Pee,X6r,z6r,Q6r,qC,W6r,U0e,U6r,H6r,H0e,J6r,Y6r,jC,Bao,wm,DC,J0e,iS,Z6r,Y0e,K6r,Iao,Yo,dS,e7r,Am,o7r,Bee,r7r,t7r,Iee,a7r,n7r,s7r,mS,l7r,Z0e,i7r,d7r,m7r,qt,cS,c7r,K0e,f7r,g7r,Lm,h7r,ewe,u7r,p7r,Nee,_7r,b7r,v7r,GC,F7r,uo,fS,T7r,owe,M7r,E7r,Tn,C7r,rwe,w7r,A7r,twe,L7r,y7r,awe,x7r,$7r,k7r,nwe,OC,swe,S7r,R7r,qee,P7r,B7r,I7r,VC,N7r,lwe,q7r,j7r,iwe,D7r,G7r,XC,Nao,ym,zC,dwe,gS,O7r,mwe,V7r,qao,Zo,hS,X7r,xm,z7r,jee,Q7r,W7r,Dee,U7r,H7r,J7r,uS,Y7r,cwe,Z7r,K7r,e8r,jt,pS,o8r,fwe,r8r,t8r,$m,a8r,gwe,n8r,s8r,Gee,l8r,i8r,d8r,QC,m8r,po,_S,c8r,hwe,f8r,g8r,Mn,h8r,uwe,u8r,p8r,pwe,_8r,b8r,_we,v8r,F8r,T8r,bwe,WC,vwe,M8r,E8r,Oee,C8r,w8r,A8r,UC,L8r,Fwe,y8r,x8r,Twe,$8r,k8r,HC,jao,km,JC,Mwe,bS,S8r,Ewe,R8r,Dao,Ko,vS,P8r,Sm,B8r,Vee,I8r,N8r,Xee,q8r,j8r,D8r,FS,G8r,Cwe,O8r,V8r,X8r,Dt,TS,z8r,wwe,Q8r,W8r,Rm,U8r,Awe,H8r,J8r,zee,Y8r,Z8r,K8r,YC,eLr,_o,MS,oLr,Lwe,rLr,tLr,En,aLr,ywe,nLr,sLr,xwe,lLr,iLr,$we,dLr,mLr,cLr,Be,ZC,kwe,fLr,gLr,Qee,hLr,uLr,pLr,KC,Swe,_Lr,bLr,Wee,vLr,FLr,TLr,e3,Rwe,MLr,ELr,Uee,CLr,wLr,ALr,o3,Pwe,LLr,yLr,Hee,xLr,$Lr,kLr,r3,Bwe,SLr,RLr,Jee,PLr,BLr,ILr,t3,Iwe,NLr,qLr,Yee,jLr,DLr,GLr,a3,Nwe,OLr,VLr,Zee,XLr,zLr,QLr,n3,qwe,WLr,ULr,Kee,HLr,JLr,YLr,s3,jwe,ZLr,KLr,eoe,eyr,oyr,ryr,l3,tyr,Dwe,ayr,nyr,Gwe,syr,lyr,i3,Gao,Pm,d3,Owe,ES,iyr,Vwe,dyr,Oao,er,CS,myr,Bm,cyr,ooe,fyr,gyr,roe,hyr,uyr,pyr,wS,_yr,Xwe,byr,vyr,Fyr,Gt,AS,Tyr,zwe,Myr,Eyr,Im,Cyr,Qwe,wyr,Ayr,toe,Lyr,yyr,xyr,m3,$yr,bo,LS,kyr,Wwe,Syr,Ryr,Cn,Pyr,Uwe,Byr,Iyr,Hwe,Nyr,qyr,Jwe,jyr,Dyr,Gyr,ut,c3,Ywe,Oyr,Vyr,aoe,Xyr,zyr,Qyr,f3,Zwe,Wyr,Uyr,noe,Hyr,Jyr,Yyr,g3,Kwe,Zyr,Kyr,soe,e9r,o9r,r9r,h3,eAe,t9r,a9r,loe,n9r,s9r,l9r,u3,oAe,i9r,d9r,ioe,m9r,c9r,f9r,p3,g9r,rAe,h9r,u9r,tAe,p9r,_9r,_3,Vao,Nm,b3,aAe,yS,b9r,nAe,v9r,Xao,or,xS,F9r,qm,T9r,doe,M9r,E9r,moe,C9r,w9r,A9r,$S,L9r,sAe,y9r,x9r,$9r,Ot,kS,k9r,lAe,S9r,R9r,jm,P9r,iAe,B9r,I9r,coe,N9r,q9r,j9r,v3,D9r,vo,SS,G9r,dAe,O9r,V9r,wn,X9r,mAe,z9r,Q9r,cAe,W9r,U9r,fAe,H9r,J9r,Y9r,Le,F3,gAe,Z9r,K9r,foe,exr,oxr,rxr,T3,hAe,txr,axr,goe,nxr,sxr,lxr,M3,uAe,ixr,dxr,hoe,mxr,cxr,fxr,E3,pAe,gxr,hxr,uoe,uxr,pxr,_xr,C3,_Ae,bxr,vxr,poe,Fxr,Txr,Mxr,w3,bAe,Exr,Cxr,_oe,wxr,Axr,Lxr,A3,vAe,yxr,xxr,boe,$xr,kxr,Sxr,L3,FAe,Rxr,Pxr,voe,Bxr,Ixr,Nxr,y3,TAe,qxr,jxr,Foe,Dxr,Gxr,Oxr,x3,MAe,Vxr,Xxr,Toe,zxr,Qxr,Wxr,$3,Uxr,EAe,Hxr,Jxr,CAe,Yxr,Zxr,k3,zao,Dm,S3,wAe,RS,Kxr,AAe,e$r,Qao,rr,PS,o$r,Gm,r$r,Moe,t$r,a$r,Eoe,n$r,s$r,l$r,BS,i$r,LAe,d$r,m$r,c$r,Vt,IS,f$r,yAe,g$r,h$r,Om,u$r,xAe,p$r,_$r,Coe,b$r,v$r,F$r,R3,T$r,Fo,NS,M$r,$Ae,E$r,C$r,An,w$r,kAe,A$r,L$r,SAe,y$r,x$r,RAe,$$r,k$r,S$r,Vm,P3,PAe,R$r,P$r,woe,B$r,I$r,N$r,B3,BAe,q$r,j$r,Aoe,D$r,G$r,O$r,I3,IAe,V$r,X$r,Loe,z$r,Q$r,W$r,N3,U$r,NAe,H$r,J$r,qAe,Y$r,Z$r,q3,Wao,Xm,j3,jAe,qS,K$r,DAe,ekr,Uao,tr,jS,okr,zm,rkr,yoe,tkr,akr,xoe,nkr,skr,lkr,DS,ikr,GAe,dkr,mkr,ckr,Xt,GS,fkr,OAe,gkr,hkr,Qm,ukr,VAe,pkr,_kr,$oe,bkr,vkr,Fkr,D3,Tkr,To,OS,Mkr,XAe,Ekr,Ckr,Ln,wkr,zAe,Akr,Lkr,QAe,ykr,xkr,WAe,$kr,kkr,Skr,pt,G3,UAe,Rkr,Pkr,koe,Bkr,Ikr,Nkr,O3,HAe,qkr,jkr,Soe,Dkr,Gkr,Okr,V3,JAe,Vkr,Xkr,Roe,zkr,Qkr,Wkr,X3,YAe,Ukr,Hkr,Poe,Jkr,Ykr,Zkr,z3,ZAe,Kkr,eSr,Boe,oSr,rSr,tSr,Q3,aSr,KAe,nSr,sSr,e6e,lSr,iSr,W3,Hao,Wm,U3,o6e,VS,dSr,r6e,mSr,Jao,ar,XS,cSr,Um,fSr,Ioe,gSr,hSr,Noe,uSr,pSr,_Sr,zS,bSr,t6e,vSr,FSr,TSr,zt,QS,MSr,a6e,ESr,CSr,Hm,wSr,n6e,ASr,LSr,qoe,ySr,xSr,$Sr,H3,kSr,Mo,WS,SSr,s6e,RSr,PSr,yn,BSr,l6e,ISr,NSr,i6e,qSr,jSr,d6e,DSr,GSr,OSr,xn,J3,m6e,VSr,XSr,joe,zSr,QSr,WSr,Y3,c6e,USr,HSr,Doe,JSr,YSr,ZSr,Z3,f6e,KSr,eRr,Goe,oRr,rRr,tRr,K3,g6e,aRr,nRr,Ooe,sRr,lRr,iRr,e5,dRr,h6e,mRr,cRr,u6e,fRr,gRr,o5,Yao,Jm,r5,p6e,US,hRr,_6e,uRr,Zao,nr,HS,pRr,Ym,_Rr,Voe,bRr,vRr,Xoe,FRr,TRr,MRr,JS,ERr,b6e,CRr,wRr,ARr,Qt,YS,LRr,v6e,yRr,xRr,Zm,$Rr,F6e,kRr,SRr,zoe,RRr,PRr,BRr,t5,IRr,Eo,ZS,NRr,T6e,qRr,jRr,$n,DRr,M6e,GRr,ORr,E6e,VRr,XRr,C6e,zRr,QRr,WRr,_t,a5,w6e,URr,HRr,Qoe,JRr,YRr,ZRr,n5,A6e,KRr,ePr,Woe,oPr,rPr,tPr,s5,L6e,aPr,nPr,Uoe,sPr,lPr,iPr,l5,y6e,dPr,mPr,Hoe,cPr,fPr,gPr,i5,x6e,hPr,uPr,Joe,pPr,_Pr,bPr,d5,vPr,$6e,FPr,TPr,k6e,MPr,EPr,m5,Kao,Km,c5,S6e,KS,CPr,R6e,wPr,eno,sr,eR,APr,ec,LPr,Yoe,yPr,xPr,Zoe,$Pr,kPr,SPr,oR,RPr,P6e,PPr,BPr,IPr,Wt,rR,NPr,B6e,qPr,jPr,oc,DPr,I6e,GPr,OPr,Koe,VPr,XPr,zPr,f5,QPr,Co,tR,WPr,N6e,UPr,HPr,kn,JPr,q6e,YPr,ZPr,j6e,KPr,eBr,D6e,oBr,rBr,tBr,G6e,g5,O6e,aBr,nBr,ere,sBr,lBr,iBr,h5,dBr,V6e,mBr,cBr,X6e,fBr,gBr,u5,ono,rc,p5,z6e,aR,hBr,Q6e,uBr,rno,lr,nR,pBr,tc,_Br,ore,bBr,vBr,rre,FBr,TBr,MBr,sR,EBr,W6e,CBr,wBr,ABr,Ut,lR,LBr,U6e,yBr,xBr,ac,$Br,H6e,kBr,SBr,tre,RBr,PBr,BBr,_5,IBr,wo,iR,NBr,J6e,qBr,jBr,Sn,DBr,Y6e,GBr,OBr,Z6e,VBr,XBr,K6e,zBr,QBr,WBr,bt,b5,e7e,UBr,HBr,are,JBr,YBr,ZBr,v5,o7e,KBr,eIr,nre,oIr,rIr,tIr,F5,r7e,aIr,nIr,sre,sIr,lIr,iIr,T5,t7e,dIr,mIr,lre,cIr,fIr,gIr,M5,a7e,hIr,uIr,ire,pIr,_Ir,bIr,E5,vIr,n7e,FIr,TIr,s7e,MIr,EIr,C5,tno,nc,w5,l7e,dR,CIr,i7e,wIr,ano,ir,mR,AIr,sc,LIr,dre,yIr,xIr,mre,$Ir,kIr,SIr,cR,RIr,d7e,PIr,BIr,IIr,Ht,fR,NIr,m7e,qIr,jIr,lc,DIr,c7e,GIr,OIr,cre,VIr,XIr,zIr,A5,QIr,Ao,gR,WIr,f7e,UIr,HIr,Rn,JIr,g7e,YIr,ZIr,h7e,KIr,eNr,u7e,oNr,rNr,tNr,p7e,L5,_7e,aNr,nNr,fre,sNr,lNr,iNr,y5,dNr,b7e,mNr,cNr,v7e,fNr,gNr,x5,nno,ic,$5,F7e,hR,hNr,T7e,uNr,sno,dr,uR,pNr,dc,_Nr,gre,bNr,vNr,hre,FNr,TNr,MNr,pR,ENr,M7e,CNr,wNr,ANr,Jt,_R,LNr,E7e,yNr,xNr,mc,$Nr,C7e,kNr,SNr,ure,RNr,PNr,BNr,k5,INr,Lo,bR,NNr,w7e,qNr,jNr,Pn,DNr,A7e,GNr,ONr,L7e,VNr,XNr,y7e,zNr,QNr,WNr,x7e,S5,$7e,UNr,HNr,pre,JNr,YNr,ZNr,R5,KNr,k7e,eqr,oqr,S7e,rqr,tqr,P5,lno,cc,B5,R7e,vR,aqr,P7e,nqr,ino,mr,FR,sqr,fc,lqr,_re,iqr,dqr,bre,mqr,cqr,fqr,TR,gqr,B7e,hqr,uqr,pqr,Yt,MR,_qr,I7e,bqr,vqr,gc,Fqr,N7e,Tqr,Mqr,vre,Eqr,Cqr,wqr,I5,Aqr,Dr,ER,Lqr,q7e,yqr,xqr,Bn,$qr,j7e,kqr,Sqr,D7e,Rqr,Pqr,G7e,Bqr,Iqr,Nqr,P,N5,O7e,qqr,jqr,Fre,Dqr,Gqr,Oqr,q5,V7e,Vqr,Xqr,Tre,zqr,Qqr,Wqr,j5,X7e,Uqr,Hqr,Mre,Jqr,Yqr,Zqr,D5,z7e,Kqr,ejr,Ere,ojr,rjr,tjr,G5,Q7e,ajr,njr,Cre,sjr,ljr,ijr,O5,W7e,djr,mjr,wre,cjr,fjr,gjr,V5,U7e,hjr,ujr,Are,pjr,_jr,bjr,X5,H7e,vjr,Fjr,Lre,Tjr,Mjr,Ejr,z5,J7e,Cjr,wjr,yre,Ajr,Ljr,yjr,Q5,Y7e,xjr,$jr,xre,kjr,Sjr,Rjr,W5,Z7e,Pjr,Bjr,$re,Ijr,Njr,qjr,U5,K7e,jjr,Djr,kre,Gjr,Ojr,Vjr,H5,e8e,Xjr,zjr,Sre,Qjr,Wjr,Ujr,J5,o8e,Hjr,Jjr,Rre,Yjr,Zjr,Kjr,Y5,r8e,eDr,oDr,Pre,rDr,tDr,aDr,Z5,t8e,nDr,sDr,Bre,lDr,iDr,dDr,K5,a8e,mDr,cDr,Ire,fDr,gDr,hDr,e0,n8e,uDr,pDr,Nre,_Dr,bDr,vDr,o0,s8e,FDr,TDr,qre,MDr,EDr,CDr,r0,l8e,wDr,ADr,jre,LDr,yDr,xDr,Rl,i8e,$Dr,kDr,Dre,SDr,RDr,Gre,PDr,BDr,IDr,t0,d8e,NDr,qDr,Ore,jDr,DDr,GDr,a0,m8e,ODr,VDr,Vre,XDr,zDr,QDr,n0,c8e,WDr,UDr,Xre,HDr,JDr,YDr,s0,f8e,ZDr,KDr,zre,eGr,oGr,rGr,l0,g8e,tGr,aGr,Qre,nGr,sGr,lGr,i0,h8e,iGr,dGr,Wre,mGr,cGr,fGr,d0,u8e,gGr,hGr,Ure,uGr,pGr,_Gr,m0,p8e,bGr,vGr,Hre,FGr,TGr,MGr,c0,_8e,EGr,CGr,Jre,wGr,AGr,LGr,f0,b8e,yGr,xGr,Yre,$Gr,kGr,SGr,g0,v8e,RGr,PGr,Zre,BGr,IGr,NGr,h0,F8e,qGr,jGr,Kre,DGr,GGr,OGr,u0,T8e,VGr,XGr,ete,zGr,QGr,WGr,p0,M8e,UGr,HGr,ote,JGr,YGr,ZGr,_0,E8e,KGr,eOr,rte,oOr,rOr,tOr,b0,C8e,aOr,nOr,tte,sOr,lOr,iOr,v0,w8e,dOr,mOr,ate,cOr,fOr,gOr,F0,A8e,hOr,uOr,nte,pOr,_Or,bOr,T0,L8e,vOr,FOr,ste,TOr,MOr,EOr,M0,y8e,COr,wOr,lte,AOr,LOr,yOr,E0,x8e,xOr,$Or,ite,kOr,SOr,ROr,C0,$8e,POr,BOr,dte,IOr,NOr,qOr,w0,k8e,jOr,DOr,mte,GOr,OOr,VOr,A0,S8e,XOr,zOr,cte,QOr,WOr,UOr,L0,R8e,HOr,JOr,fte,YOr,ZOr,KOr,y0,P8e,eVr,oVr,gte,rVr,tVr,aVr,x0,B8e,nVr,sVr,hte,lVr,iVr,dVr,$0,I8e,mVr,cVr,ute,fVr,gVr,hVr,k0,N8e,uVr,pVr,pte,_Vr,bVr,vVr,S0,q8e,FVr,TVr,_te,MVr,EVr,CVr,R0,j8e,wVr,AVr,bte,LVr,yVr,xVr,P0,D8e,$Vr,kVr,vte,SVr,RVr,PVr,B0,G8e,BVr,IVr,Fte,NVr,qVr,jVr,I0,O8e,DVr,GVr,Tte,OVr,VVr,XVr,N0,V8e,zVr,QVr,Mte,WVr,UVr,HVr,q0,X8e,JVr,YVr,Ete,ZVr,KVr,eXr,j0,z8e,oXr,rXr,Cte,tXr,aXr,nXr,D0,dno,hc,G0,Q8e,CR,sXr,W8e,lXr,mno,cr,wR,iXr,uc,dXr,wte,mXr,cXr,Ate,fXr,gXr,hXr,AR,uXr,U8e,pXr,_Xr,bXr,Zt,LR,vXr,H8e,FXr,TXr,pc,MXr,J8e,EXr,CXr,Lte,wXr,AXr,LXr,O0,yXr,Gr,yR,xXr,Y8e,$Xr,kXr,In,SXr,Z8e,RXr,PXr,K8e,BXr,IXr,eLe,NXr,qXr,jXr,le,V0,oLe,DXr,GXr,yte,OXr,VXr,XXr,X0,rLe,zXr,QXr,xte,WXr,UXr,HXr,z0,tLe,JXr,YXr,$te,ZXr,KXr,ezr,Q0,aLe,ozr,rzr,kte,tzr,azr,nzr,W0,nLe,szr,lzr,Ste,izr,dzr,mzr,U0,sLe,czr,fzr,Rte,gzr,hzr,uzr,H0,lLe,pzr,_zr,Pte,bzr,vzr,Fzr,J0,iLe,Tzr,Mzr,Bte,Ezr,Czr,wzr,Y0,dLe,Azr,Lzr,Ite,yzr,xzr,$zr,Z0,mLe,kzr,Szr,Nte,Rzr,Pzr,Bzr,K0,cLe,Izr,Nzr,qte,qzr,jzr,Dzr,ew,fLe,Gzr,Ozr,jte,Vzr,Xzr,zzr,ow,gLe,Qzr,Wzr,Dte,Uzr,Hzr,Jzr,rw,hLe,Yzr,Zzr,Gte,Kzr,eQr,oQr,tw,uLe,rQr,tQr,Ote,aQr,nQr,sQr,aw,pLe,lQr,iQr,Vte,dQr,mQr,cQr,nw,_Le,fQr,gQr,Xte,hQr,uQr,pQr,sw,bLe,_Qr,bQr,zte,vQr,FQr,TQr,lw,vLe,MQr,EQr,Qte,CQr,wQr,AQr,iw,FLe,LQr,yQr,Wte,xQr,$Qr,kQr,dw,TLe,SQr,RQr,Ute,PQr,BQr,IQr,mw,MLe,NQr,qQr,Hte,jQr,DQr,GQr,cw,ELe,OQr,VQr,Jte,XQr,zQr,QQr,fw,cno,_c,gw,CLe,xR,WQr,wLe,UQr,fno,fr,$R,HQr,bc,JQr,Yte,YQr,ZQr,Zte,KQr,eWr,oWr,kR,rWr,ALe,tWr,aWr,nWr,Kt,SR,sWr,LLe,lWr,iWr,vc,dWr,yLe,mWr,cWr,Kte,fWr,gWr,hWr,hw,uWr,Or,RR,pWr,xLe,_Wr,bWr,Nn,vWr,$Le,FWr,TWr,kLe,MWr,EWr,SLe,CWr,wWr,AWr,Me,uw,RLe,LWr,yWr,eae,xWr,$Wr,kWr,pw,PLe,SWr,RWr,oae,PWr,BWr,IWr,_w,BLe,NWr,qWr,rae,jWr,DWr,GWr,bw,ILe,OWr,VWr,tae,XWr,zWr,QWr,vw,NLe,WWr,UWr,aae,HWr,JWr,YWr,Fw,qLe,ZWr,KWr,nae,eUr,oUr,rUr,Tw,jLe,tUr,aUr,sae,nUr,sUr,lUr,Mw,DLe,iUr,dUr,lae,mUr,cUr,fUr,Ew,GLe,gUr,hUr,iae,uUr,pUr,_Ur,Cw,OLe,bUr,vUr,dae,FUr,TUr,MUr,ww,VLe,EUr,CUr,mae,wUr,AUr,LUr,Aw,XLe,yUr,xUr,cae,$Ur,kUr,SUr,Lw,zLe,RUr,PUr,fae,BUr,IUr,NUr,yw,QLe,qUr,jUr,gae,DUr,GUr,OUr,xw,gno,Fc,$w,WLe,PR,VUr,ULe,XUr,hno,gr,BR,zUr,Tc,QUr,hae,WUr,UUr,uae,HUr,JUr,YUr,IR,ZUr,HLe,KUr,eHr,oHr,ea,NR,rHr,JLe,tHr,aHr,Mc,nHr,YLe,sHr,lHr,pae,iHr,dHr,mHr,kw,cHr,Vr,qR,fHr,ZLe,gHr,hHr,qn,uHr,KLe,pHr,_Hr,eye,bHr,vHr,oye,FHr,THr,MHr,ye,Sw,rye,EHr,CHr,_ae,wHr,AHr,LHr,Rw,tye,yHr,xHr,bae,$Hr,kHr,SHr,Pw,aye,RHr,PHr,vae,BHr,IHr,NHr,Pl,nye,qHr,jHr,Fae,DHr,GHr,Tae,OHr,VHr,XHr,Bw,sye,zHr,QHr,Mae,WHr,UHr,HHr,Iw,lye,JHr,YHr,Eae,ZHr,KHr,eJr,Nw,iye,oJr,rJr,Cae,tJr,aJr,nJr,qw,dye,sJr,lJr,wae,iJr,dJr,mJr,jw,mye,cJr,fJr,Aae,gJr,hJr,uJr,Dw,cye,pJr,_Jr,Lae,bJr,vJr,FJr,Gw,uno,Ec,Ow,fye,jR,TJr,gye,MJr,pno,hr,DR,EJr,Cc,CJr,yae,wJr,AJr,xae,LJr,yJr,xJr,GR,$Jr,hye,kJr,SJr,RJr,oa,OR,PJr,uye,BJr,IJr,wc,NJr,pye,qJr,jJr,$ae,DJr,GJr,OJr,Vw,VJr,Xr,VR,XJr,_ye,zJr,QJr,jn,WJr,bye,UJr,HJr,vye,JJr,YJr,Fye,ZJr,KJr,eYr,Ac,Xw,Tye,oYr,rYr,kae,tYr,aYr,nYr,zw,Mye,sYr,lYr,Sae,iYr,dYr,mYr,Qw,Eye,cYr,fYr,Rae,gYr,hYr,uYr,Ww,_no,Lc,Uw,Cye,XR,pYr,wye,_Yr,bno,ur,zR,bYr,yc,vYr,Pae,FYr,TYr,Bae,MYr,EYr,CYr,QR,wYr,Aye,AYr,LYr,yYr,ra,WR,xYr,Lye,$Yr,kYr,xc,SYr,yye,RYr,PYr,Iae,BYr,IYr,NYr,Hw,qYr,zr,UR,jYr,xye,DYr,GYr,Dn,OYr,$ye,VYr,XYr,kye,zYr,QYr,Sye,WYr,UYr,HYr,ce,Jw,Rye,JYr,YYr,Nae,ZYr,KYr,eZr,Yw,Pye,oZr,rZr,qae,tZr,aZr,nZr,Zw,Bye,sZr,lZr,jae,iZr,dZr,mZr,Kw,Iye,cZr,fZr,Dae,gZr,hZr,uZr,eA,Nye,pZr,_Zr,Gae,bZr,vZr,FZr,oA,qye,TZr,MZr,Oae,EZr,CZr,wZr,rA,jye,AZr,LZr,Vae,yZr,xZr,$Zr,tA,Dye,kZr,SZr,Xae,RZr,PZr,BZr,aA,Gye,IZr,NZr,zae,qZr,jZr,DZr,nA,Oye,GZr,OZr,Qae,VZr,XZr,zZr,sA,Vye,QZr,WZr,Wae,UZr,HZr,JZr,lA,Xye,YZr,ZZr,Uae,KZr,eKr,oKr,iA,zye,rKr,tKr,Hae,aKr,nKr,sKr,dA,Qye,lKr,iKr,Jae,dKr,mKr,cKr,mA,Wye,fKr,gKr,Yae,hKr,uKr,pKr,cA,Uye,_Kr,bKr,Zae,vKr,FKr,TKr,fA,Hye,MKr,EKr,Kae,CKr,wKr,AKr,gA,Jye,LKr,yKr,ene,xKr,$Kr,kKr,hA,Yye,SKr,RKr,one,PKr,BKr,IKr,uA,Zye,NKr,qKr,rne,jKr,DKr,GKr,pA,Kye,OKr,VKr,tne,XKr,zKr,QKr,_A,vno,$c,bA,e9e,HR,WKr,o9e,UKr,Fno,pr,JR,HKr,kc,JKr,ane,YKr,ZKr,nne,KKr,eet,oet,YR,ret,r9e,tet,aet,net,ta,ZR,set,t9e,iet,det,Sc,met,a9e,cet,fet,sne,get,het,uet,vA,pet,Qr,KR,_et,n9e,bet,vet,Gn,Fet,s9e,Tet,Met,l9e,Eet,Cet,i9e,wet,Aet,Let,xe,FA,d9e,yet,xet,lne,$et,ket,Set,TA,m9e,Ret,Pet,ine,Bet,Iet,Net,MA,c9e,qet,jet,dne,Det,Get,Oet,EA,f9e,Vet,Xet,mne,zet,Qet,Wet,CA,g9e,Uet,Het,cne,Jet,Yet,Zet,wA,h9e,Ket,eot,fne,oot,rot,tot,AA,u9e,aot,not,gne,sot,lot,iot,LA,p9e,dot,mot,hne,cot,fot,got,yA,_9e,hot,uot,une,pot,_ot,bot,xA,b9e,vot,Fot,pne,Tot,Mot,Eot,$A,Tno,Rc,kA,v9e,eP,Cot,F9e,wot,Mno,_r,oP,Aot,Pc,Lot,_ne,yot,xot,bne,$ot,kot,Sot,rP,Rot,T9e,Pot,Bot,Iot,aa,tP,Not,M9e,qot,jot,Bc,Dot,E9e,Got,Oot,vne,Vot,Xot,zot,SA,Qot,Wr,aP,Wot,C9e,Uot,Hot,On,Jot,w9e,Yot,Zot,A9e,Kot,ert,L9e,ort,rrt,trt,re,RA,y9e,art,nrt,Fne,srt,lrt,irt,PA,x9e,drt,mrt,Tne,crt,frt,grt,BA,$9e,hrt,urt,Mne,prt,_rt,brt,IA,k9e,vrt,Frt,Ene,Trt,Mrt,Ert,NA,S9e,Crt,wrt,Cne,Art,Lrt,yrt,qA,R9e,xrt,$rt,wne,krt,Srt,Rrt,jA,P9e,Prt,Brt,Ane,Irt,Nrt,qrt,DA,B9e,jrt,Drt,Lne,Grt,Ort,Vrt,GA,I9e,Xrt,zrt,yne,Qrt,Wrt,Urt,OA,N9e,Hrt,Jrt,xne,Yrt,Zrt,Krt,VA,q9e,ett,ott,$ne,rtt,ttt,att,XA,j9e,ntt,stt,kne,ltt,itt,dtt,zA,D9e,mtt,ctt,Sne,ftt,gtt,htt,QA,G9e,utt,ptt,Rne,_tt,btt,vtt,WA,O9e,Ftt,Ttt,Pne,Mtt,Ett,Ctt,UA,V9e,wtt,Att,Bne,Ltt,ytt,xtt,HA,X9e,$tt,ktt,Ine,Stt,Rtt,Ptt,JA,z9e,Btt,Itt,Nne,Ntt,qtt,jtt,YA,Q9e,Dtt,Gtt,qne,Ott,Vtt,Xtt,ZA,W9e,ztt,Qtt,jne,Wtt,Utt,Htt,KA,U9e,Jtt,Ytt,Dne,Ztt,Ktt,eat,e6,H9e,oat,rat,Gne,tat,aat,nat,o6,J9e,sat,lat,One,iat,dat,mat,r6,Y9e,cat,fat,Vne,gat,hat,uat,t6,Z9e,pat,_at,Xne,bat,vat,Fat,a6,K9e,Tat,Mat,zne,Eat,Cat,wat,n6,exe,Aat,Lat,Qne,yat,xat,$at,s6,oxe,kat,Sat,Wne,Rat,Pat,Bat,l6,Eno,Ic,i6,rxe,nP,Iat,txe,Nat,Cno,br,sP,qat,Nc,jat,Une,Dat,Gat,Hne,Oat,Vat,Xat,lP,zat,axe,Qat,Wat,Uat,na,iP,Hat,nxe,Jat,Yat,qc,Zat,sxe,Kat,ent,Jne,ont,rnt,tnt,d6,ant,Ur,dP,nnt,lxe,snt,lnt,Vn,int,ixe,dnt,mnt,dxe,cnt,fnt,mxe,gnt,hnt,unt,ve,m6,cxe,pnt,_nt,Yne,bnt,vnt,Fnt,c6,fxe,Tnt,Mnt,Zne,Ent,Cnt,wnt,f6,gxe,Ant,Lnt,Kne,ynt,xnt,$nt,g6,hxe,knt,Snt,ese,Rnt,Pnt,Bnt,h6,uxe,Int,Nnt,ose,qnt,jnt,Dnt,u6,pxe,Gnt,Ont,rse,Vnt,Xnt,znt,p6,_xe,Qnt,Wnt,tse,Unt,Hnt,Jnt,_6,bxe,Ynt,Znt,ase,Knt,est,ost,b6,vxe,rst,tst,nse,ast,nst,sst,v6,Fxe,lst,ist,sse,dst,mst,cst,F6,Txe,fst,gst,lse,hst,ust,pst,T6,Mxe,_st,bst,ise,vst,Fst,Tst,M6,Exe,Mst,Est,dse,Cst,wst,Ast,E6,Cxe,Lst,yst,mse,xst,$st,kst,C6,wxe,Sst,Rst,cse,Pst,Bst,Ist,w6,Axe,Nst,qst,fse,jst,Dst,Gst,A6,Lxe,Ost,Vst,gse,Xst,zst,Qst,L6,wno,jc,y6,yxe,mP,Wst,xxe,Ust,Ano,vr,cP,Hst,Dc,Jst,hse,Yst,Zst,use,Kst,elt,olt,fP,rlt,$xe,tlt,alt,nlt,sa,gP,slt,kxe,llt,ilt,Gc,dlt,Sxe,mlt,clt,pse,flt,glt,hlt,x6,ult,Hr,hP,plt,Rxe,_lt,blt,Xn,vlt,Pxe,Flt,Tlt,Bxe,Mlt,Elt,Ixe,Clt,wlt,Alt,uP,$6,Nxe,Llt,ylt,_se,xlt,$lt,klt,k6,qxe,Slt,Rlt,bse,Plt,Blt,Ilt,S6,Lno,Oc,R6,jxe,pP,Nlt,Dxe,qlt,yno,Fr,_P,jlt,Vc,Dlt,vse,Glt,Olt,Fse,Vlt,Xlt,zlt,bP,Qlt,Gxe,Wlt,Ult,Hlt,la,vP,Jlt,Oxe,Ylt,Zlt,Xc,Klt,Vxe,eit,oit,Tse,rit,tit,ait,P6,nit,Jr,FP,sit,Xxe,lit,iit,zn,dit,zxe,mit,cit,Qxe,fit,git,Wxe,hit,uit,pit,Uxe,B6,Hxe,_it,bit,Mse,vit,Fit,Tit,I6,xno,zc,N6,Jxe,TP,Mit,Yxe,Eit,$no,Tr,MP,Cit,Qc,wit,Ese,Ait,Lit,Cse,yit,xit,$it,EP,kit,Zxe,Sit,Rit,Pit,ia,CP,Bit,Kxe,Iit,Nit,Wc,qit,e$e,jit,Dit,wse,Git,Oit,Vit,q6,Xit,Yr,wP,zit,o$e,Qit,Wit,Qn,Uit,r$e,Hit,Jit,t$e,Yit,Zit,a$e,Kit,edt,odt,n$e,j6,s$e,rdt,tdt,Ase,adt,ndt,sdt,D6,kno,Uc,G6,l$e,AP,ldt,i$e,idt,Sno,Mr,LP,ddt,Hc,mdt,Lse,cdt,fdt,yse,gdt,hdt,udt,yP,pdt,d$e,_dt,bdt,vdt,da,xP,Fdt,m$e,Tdt,Mdt,Jc,Edt,c$e,Cdt,wdt,xse,Adt,Ldt,ydt,O6,xdt,Zr,$P,$dt,f$e,kdt,Sdt,Wn,Rdt,g$e,Pdt,Bdt,h$e,Idt,Ndt,u$e,qdt,jdt,Ddt,ie,V6,p$e,Gdt,Odt,$se,Vdt,Xdt,zdt,X6,_$e,Qdt,Wdt,kse,Udt,Hdt,Jdt,z6,b$e,Ydt,Zdt,Sse,Kdt,emt,omt,Q6,v$e,rmt,tmt,Rse,amt,nmt,smt,W6,F$e,lmt,imt,Pse,dmt,mmt,cmt,U6,T$e,fmt,gmt,Bse,hmt,umt,pmt,H6,M$e,_mt,bmt,Ise,vmt,Fmt,Tmt,J6,E$e,Mmt,Emt,Nse,Cmt,wmt,Amt,Y6,C$e,Lmt,ymt,qse,xmt,$mt,kmt,Z6,w$e,Smt,Rmt,jse,Pmt,Bmt,Imt,K6,A$e,Nmt,qmt,Dse,jmt,Dmt,Gmt,e7,L$e,Omt,Vmt,Gse,Xmt,zmt,Qmt,o7,y$e,Wmt,Umt,Ose,Hmt,Jmt,Ymt,r7,x$e,Zmt,Kmt,Vse,ect,oct,rct,t7,$$e,tct,act,Xse,nct,sct,lct,a7,k$e,ict,dct,zse,mct,cct,fct,n7,S$e,gct,hct,Qse,uct,pct,_ct,s7,R$e,bct,vct,Wse,Fct,Tct,Mct,l7,P$e,Ect,Cct,Use,wct,Act,Lct,i7,B$e,yct,xct,Hse,$ct,kct,Sct,d7,I$e,Rct,Pct,Jse,Bct,Ict,Nct,m7,N$e,qct,jct,Yse,Dct,Gct,Oct,c7,Rno,Yc,f7,q$e,kP,Vct,j$e,Xct,Pno,Er,SP,zct,Zc,Qct,Zse,Wct,Uct,Kse,Hct,Jct,Yct,RP,Zct,D$e,Kct,eft,oft,ma,PP,rft,G$e,tft,aft,Kc,nft,O$e,sft,lft,ele,ift,dft,mft,g7,cft,Kr,BP,fft,V$e,gft,hft,Un,uft,X$e,pft,_ft,z$e,bft,vft,Q$e,Fft,Tft,Mft,fe,h7,W$e,Eft,Cft,ole,wft,Aft,Lft,u7,U$e,yft,xft,rle,$ft,kft,Sft,p7,H$e,Rft,Pft,tle,Bft,Ift,Nft,_7,J$e,qft,jft,ale,Dft,Gft,Oft,b7,Y$e,Vft,Xft,nle,zft,Qft,Wft,v7,Z$e,Uft,Hft,sle,Jft,Yft,Zft,F7,K$e,Kft,egt,lle,ogt,rgt,tgt,T7,eke,agt,ngt,ile,sgt,lgt,igt,M7,oke,dgt,mgt,dle,cgt,fgt,ggt,E7,rke,hgt,ugt,mle,pgt,_gt,bgt,C7,tke,vgt,Fgt,cle,Tgt,Mgt,Egt,w7,ake,Cgt,wgt,fle,Agt,Lgt,ygt,A7,nke,xgt,$gt,gle,kgt,Sgt,Rgt,L7,ske,Pgt,Bgt,hle,Igt,Ngt,qgt,y7,lke,jgt,Dgt,ule,Ggt,Ogt,Vgt,x7,ike,Xgt,zgt,ple,Qgt,Wgt,Ugt,$7,dke,Hgt,Jgt,_le,Ygt,Zgt,Kgt,k7,mke,eht,oht,ble,rht,tht,aht,S7,cke,nht,sht,vle,lht,iht,dht,R7,fke,mht,cht,Fle,fht,ght,hht,P7,gke,uht,pht,Tle,_ht,bht,vht,B7,Bno,ef,I7,hke,IP,Fht,uke,Tht,Ino,Cr,NP,Mht,of,Eht,Mle,Cht,wht,Ele,Aht,Lht,yht,qP,xht,pke,$ht,kht,Sht,ca,jP,Rht,_ke,Pht,Bht,rf,Iht,bke,Nht,qht,Cle,jht,Dht,Ght,N7,Oht,et,DP,Vht,vke,Xht,zht,Hn,Qht,Fke,Wht,Uht,Tke,Hht,Jht,Mke,Yht,Zht,Kht,Eke,q7,Cke,eut,out,wle,rut,tut,aut,j7,Nno,tf,D7,wke,GP,nut,Ake,sut,qno,wr,OP,lut,af,iut,Ale,dut,mut,Lle,cut,fut,gut,VP,hut,Lke,uut,put,_ut,fa,XP,but,yke,vut,Fut,nf,Tut,xke,Mut,Eut,yle,Cut,wut,Aut,G7,Lut,ot,zP,yut,$ke,xut,$ut,Jn,kut,kke,Sut,Rut,Ske,Put,But,Rke,Iut,Nut,qut,QP,O7,Pke,jut,Dut,xle,Gut,Out,Vut,V7,Bke,Xut,zut,$le,Qut,Wut,Uut,X7,jno,sf,z7,Ike,WP,Hut,Nke,Jut,Dno,Ar,UP,Yut,lf,Zut,kle,Kut,ept,Sle,opt,rpt,tpt,HP,apt,qke,npt,spt,lpt,ga,JP,ipt,jke,dpt,mpt,df,cpt,Dke,fpt,gpt,Rle,hpt,upt,ppt,Q7,_pt,rt,YP,bpt,Gke,vpt,Fpt,Yn,Tpt,Oke,Mpt,Ept,Vke,Cpt,wpt,Xke,Apt,Lpt,ypt,te,W7,zke,xpt,$pt,Ple,kpt,Spt,Rpt,U7,Qke,Ppt,Bpt,Ble,Ipt,Npt,qpt,H7,Wke,jpt,Dpt,Ile,Gpt,Opt,Vpt,J7,Uke,Xpt,zpt,Nle,Qpt,Wpt,Upt,Y7,Hke,Hpt,Jpt,qle,Ypt,Zpt,Kpt,Z7,Jke,e_t,o_t,jle,r_t,t_t,a_t,K7,Yke,n_t,s_t,Dle,l_t,i_t,d_t,e8,Zke,m_t,c_t,Gle,f_t,g_t,h_t,o8,Kke,u_t,p_t,Ole,__t,b_t,v_t,r8,eSe,F_t,T_t,Vle,M_t,E_t,C_t,t8,oSe,w_t,A_t,Xle,L_t,y_t,x_t,a8,rSe,$_t,k_t,zle,S_t,R_t,P_t,n8,tSe,B_t,I_t,Qle,N_t,q_t,j_t,s8,aSe,D_t,G_t,Wle,O_t,V_t,X_t,l8,nSe,z_t,Q_t,Ule,W_t,U_t,H_t,i8,sSe,J_t,Y_t,Hle,Z_t,K_t,e1t,d8,lSe,o1t,r1t,Jle,t1t,a1t,n1t,m8,iSe,s1t,l1t,Yle,i1t,d1t,m1t,c8,dSe,c1t,f1t,Zle,g1t,h1t,u1t,f8,mSe,p1t,_1t,Kle,b1t,v1t,F1t,g8,cSe,T1t,M1t,eie,E1t,C1t,w1t,h8,fSe,A1t,L1t,oie,y1t,x1t,$1t,u8,gSe,k1t,S1t,rie,R1t,P1t,B1t,p8,hSe,I1t,N1t,tie,q1t,j1t,D1t,_8,uSe,G1t,O1t,aie,V1t,X1t,z1t,b8,pSe,Q1t,W1t,nie,U1t,H1t,J1t,v8,_Se,Y1t,Z1t,sie,K1t,e2t,o2t,F8,Gno,mf,T8,bSe,ZP,r2t,vSe,t2t,Ono,Lr,KP,a2t,cf,n2t,lie,s2t,l2t,iie,i2t,d2t,m2t,eB,c2t,FSe,f2t,g2t,h2t,ha,oB,u2t,TSe,p2t,_2t,ff,b2t,MSe,v2t,F2t,die,T2t,M2t,E2t,M8,C2t,tt,rB,w2t,ESe,A2t,L2t,Zn,y2t,CSe,x2t,$2t,wSe,k2t,S2t,ASe,R2t,P2t,B2t,$e,E8,LSe,I2t,N2t,mie,q2t,j2t,D2t,C8,ySe,G2t,O2t,cie,V2t,X2t,z2t,w8,xSe,Q2t,W2t,fie,U2t,H2t,J2t,A8,$Se,Y2t,Z2t,gie,K2t,ebt,obt,L8,kSe,rbt,tbt,hie,abt,nbt,sbt,y8,SSe,lbt,ibt,uie,dbt,mbt,cbt,x8,RSe,fbt,gbt,pie,hbt,ubt,pbt,$8,PSe,_bt,bbt,_ie,vbt,Fbt,Tbt,k8,BSe,Mbt,Ebt,bie,Cbt,wbt,Abt,S8,ISe,Lbt,ybt,vie,xbt,$bt,kbt,R8,Vno,gf,P8,NSe,tB,Sbt,qSe,Rbt,Xno,yr,aB,Pbt,hf,Bbt,Fie,Ibt,Nbt,Tie,qbt,jbt,Dbt,nB,Gbt,jSe,Obt,Vbt,Xbt,ua,sB,zbt,DSe,Qbt,Wbt,uf,Ubt,GSe,Hbt,Jbt,Mie,Ybt,Zbt,Kbt,B8,evt,at,lB,ovt,OSe,rvt,tvt,Kn,avt,VSe,nvt,svt,XSe,lvt,ivt,zSe,dvt,mvt,cvt,Ee,I8,QSe,fvt,gvt,Eie,hvt,uvt,pvt,N8,WSe,_vt,bvt,Cie,vvt,Fvt,Tvt,q8,USe,Mvt,Evt,wie,Cvt,wvt,Avt,j8,HSe,Lvt,yvt,Aie,xvt,$vt,kvt,D8,JSe,Svt,Rvt,Lie,Pvt,Bvt,Ivt,G8,YSe,Nvt,qvt,yie,jvt,Dvt,Gvt,O8,ZSe,Ovt,Vvt,xie,Xvt,zvt,Qvt,V8,KSe,Wvt,Uvt,$ie,Hvt,Jvt,Yvt,X8,eRe,Zvt,Kvt,kie,eFt,oFt,rFt,z8,oRe,tFt,aFt,Sie,nFt,sFt,lFt,Q8,rRe,iFt,dFt,Rie,mFt,cFt,fFt,W8,tRe,gFt,hFt,Pie,uFt,pFt,_Ft,U8,aRe,bFt,vFt,Bie,FFt,TFt,MFt,H8,zno,pf,J8,nRe,iB,EFt,sRe,CFt,Qno,xr,dB,wFt,_f,AFt,Iie,LFt,yFt,Nie,xFt,$Ft,kFt,mB,SFt,lRe,RFt,PFt,BFt,pa,cB,IFt,iRe,NFt,qFt,bf,jFt,dRe,DFt,GFt,qie,OFt,VFt,XFt,Y8,zFt,nt,fB,QFt,mRe,WFt,UFt,es,HFt,cRe,JFt,YFt,fRe,ZFt,KFt,gRe,eTt,oTt,rTt,ke,Z8,hRe,tTt,aTt,jie,nTt,sTt,lTt,K8,uRe,iTt,dTt,Die,mTt,cTt,fTt,eL,pRe,gTt,hTt,Gie,uTt,pTt,_Tt,oL,_Re,bTt,vTt,Oie,FTt,TTt,MTt,rL,bRe,ETt,CTt,Vie,wTt,ATt,LTt,tL,vRe,yTt,xTt,Xie,$Tt,kTt,STt,aL,FRe,RTt,PTt,zie,BTt,ITt,NTt,nL,TRe,qTt,jTt,Qie,DTt,GTt,OTt,sL,MRe,VTt,XTt,Wie,zTt,QTt,WTt,lL,ERe,UTt,HTt,Uie,JTt,YTt,ZTt,iL,Wno,vf,dL,CRe,gB,KTt,wRe,eMt,Uno,$r,hB,oMt,Ff,rMt,Hie,tMt,aMt,Jie,nMt,sMt,lMt,uB,iMt,ARe,dMt,mMt,cMt,_a,pB,fMt,LRe,gMt,hMt,Tf,uMt,yRe,pMt,_Mt,Yie,bMt,vMt,FMt,mL,TMt,st,_B,MMt,xRe,EMt,CMt,os,wMt,$Re,AMt,LMt,kRe,yMt,xMt,SRe,$Mt,kMt,SMt,Se,cL,RRe,RMt,PMt,Zie,BMt,IMt,NMt,fL,PRe,qMt,jMt,Kie,DMt,GMt,OMt,gL,BRe,VMt,XMt,ede,zMt,QMt,WMt,hL,IRe,UMt,HMt,ode,JMt,YMt,ZMt,uL,NRe,KMt,eEt,rde,oEt,rEt,tEt,pL,qRe,aEt,nEt,tde,sEt,lEt,iEt,_L,jRe,dEt,mEt,ade,cEt,fEt,gEt,bL,DRe,hEt,uEt,nde,pEt,_Et,bEt,vL,GRe,vEt,FEt,sde,TEt,MEt,EEt,FL,ORe,CEt,wEt,lde,AEt,LEt,yEt,TL,Hno,Mf,ML,VRe,bB,xEt,XRe,$Et,Jno,kr,vB,kEt,Ef,SEt,ide,REt,PEt,dde,BEt,IEt,NEt,FB,qEt,zRe,jEt,DEt,GEt,ba,TB,OEt,QRe,VEt,XEt,Cf,zEt,WRe,QEt,WEt,mde,UEt,HEt,JEt,EL,YEt,lt,MB,ZEt,URe,KEt,e4t,rs,o4t,HRe,r4t,t4t,JRe,a4t,n4t,YRe,s4t,l4t,i4t,Re,CL,ZRe,d4t,m4t,cde,c4t,f4t,g4t,wL,KRe,h4t,u4t,fde,p4t,_4t,b4t,AL,ePe,v4t,F4t,gde,T4t,M4t,E4t,LL,oPe,C4t,w4t,hde,A4t,L4t,y4t,yL,rPe,x4t,$4t,ude,k4t,S4t,R4t,xL,tPe,P4t,B4t,pde,I4t,N4t,q4t,$L,aPe,j4t,D4t,_de,G4t,O4t,V4t,kL,nPe,X4t,z4t,bde,Q4t,W4t,U4t,SL,sPe,H4t,J4t,vde,Y4t,Z4t,K4t,RL,lPe,eCt,oCt,Fde,rCt,tCt,aCt,PL,Yno,wf,BL,iPe,EB,nCt,dPe,sCt,Zno,Sr,CB,lCt,Af,iCt,Tde,dCt,mCt,Mde,cCt,fCt,gCt,wB,hCt,mPe,uCt,pCt,_Ct,va,AB,bCt,cPe,vCt,FCt,Lf,TCt,fPe,MCt,ECt,Ede,CCt,wCt,ACt,IL,LCt,it,LB,yCt,gPe,xCt,$Ct,ts,kCt,hPe,SCt,RCt,uPe,PCt,BCt,pPe,ICt,NCt,qCt,Pe,NL,_Pe,jCt,DCt,Cde,GCt,OCt,VCt,qL,bPe,XCt,zCt,wde,QCt,WCt,UCt,jL,vPe,HCt,JCt,Ade,YCt,ZCt,KCt,DL,FPe,e3t,o3t,Lde,r3t,t3t,a3t,GL,TPe,n3t,s3t,yde,l3t,i3t,d3t,OL,MPe,m3t,c3t,xde,f3t,g3t,h3t,VL,EPe,u3t,p3t,$de,_3t,b3t,v3t,XL,CPe,F3t,T3t,kde,M3t,E3t,C3t,zL,wPe,w3t,A3t,Sde,L3t,y3t,x3t,QL,APe,$3t,k3t,Rde,S3t,R3t,P3t,WL,Kno,yf,UL,LPe,yB,B3t,yPe,I3t,eso,Rr,xB,N3t,xf,q3t,Pde,j3t,D3t,Bde,G3t,O3t,V3t,$B,X3t,xPe,z3t,Q3t,W3t,Fa,kB,U3t,$Pe,H3t,J3t,$f,Y3t,kPe,Z3t,K3t,Ide,e5t,o5t,r5t,HL,t5t,dt,SB,a5t,SPe,n5t,s5t,as,l5t,RPe,i5t,d5t,PPe,m5t,c5t,BPe,f5t,g5t,h5t,ze,JL,IPe,u5t,p5t,Nde,_5t,b5t,v5t,YL,NPe,F5t,T5t,qde,M5t,E5t,C5t,ZL,qPe,w5t,A5t,jde,L5t,y5t,x5t,KL,jPe,$5t,k5t,Dde,S5t,R5t,P5t,ey,DPe,B5t,I5t,Gde,N5t,q5t,j5t,oy,GPe,D5t,G5t,Ode,O5t,V5t,X5t,ry,OPe,z5t,Q5t,Vde,W5t,U5t,H5t,ty,VPe,J5t,Y5t,Xde,Z5t,K5t,e0t,ay,oso,kf,ny,XPe,RB,o0t,zPe,r0t,rso,Pr,PB,t0t,Sf,a0t,zde,n0t,s0t,Qde,l0t,i0t,d0t,BB,m0t,QPe,c0t,f0t,g0t,Ta,IB,h0t,WPe,u0t,p0t,Rf,_0t,UPe,b0t,v0t,Wde,F0t,T0t,M0t,sy,E0t,mt,NB,C0t,HPe,w0t,A0t,ns,L0t,JPe,y0t,x0t,YPe,$0t,k0t,ZPe,S0t,R0t,P0t,Qe,ly,KPe,B0t,I0t,Ude,N0t,q0t,j0t,iy,eBe,D0t,G0t,Hde,O0t,V0t,X0t,dy,oBe,z0t,Q0t,Jde,W0t,U0t,H0t,my,rBe,J0t,Y0t,Yde,Z0t,K0t,ewt,cy,tBe,owt,rwt,Zde,twt,awt,nwt,fy,aBe,swt,lwt,Kde,iwt,dwt,mwt,gy,nBe,cwt,fwt,eme,gwt,hwt,uwt,hy,sBe,pwt,_wt,ome,bwt,vwt,Fwt,uy,tso,Pf,py,lBe,qB,Twt,iBe,Mwt,aso,Br,jB,Ewt,Bf,Cwt,rme,wwt,Awt,tme,Lwt,ywt,xwt,DB,$wt,dBe,kwt,Swt,Rwt,Ma,GB,Pwt,mBe,Bwt,Iwt,If,Nwt,cBe,qwt,jwt,ame,Dwt,Gwt,Owt,_y,Vwt,ct,OB,Xwt,fBe,zwt,Qwt,ss,Wwt,gBe,Uwt,Hwt,hBe,Jwt,Ywt,uBe,Zwt,Kwt,eAt,pBe,by,_Be,oAt,rAt,nme,tAt,aAt,nAt,vy,nso,Nf,Fy,bBe,VB,sAt,vBe,lAt,sso,Ir,XB,iAt,qf,dAt,sme,mAt,cAt,lme,fAt,gAt,hAt,zB,uAt,FBe,pAt,_At,bAt,Ea,QB,vAt,TBe,FAt,TAt,jf,MAt,MBe,EAt,CAt,ime,wAt,AAt,LAt,Ty,yAt,ft,WB,xAt,EBe,$At,kAt,ls,SAt,CBe,RAt,PAt,wBe,BAt,IAt,ABe,NAt,qAt,jAt,UB,My,LBe,DAt,GAt,dme,OAt,VAt,XAt,Ey,yBe,zAt,QAt,mme,WAt,UAt,HAt,Cy,lso,Df,wy,xBe,HB,JAt,$Be,YAt,iso,Nr,JB,ZAt,Gf,KAt,cme,e6t,o6t,fme,r6t,t6t,a6t,YB,n6t,kBe,s6t,l6t,i6t,Ca,ZB,d6t,SBe,m6t,c6t,Of,f6t,RBe,g6t,h6t,gme,u6t,p6t,_6t,Ay,b6t,gt,KB,v6t,PBe,F6t,T6t,is,M6t,BBe,E6t,C6t,IBe,w6t,A6t,NBe,L6t,y6t,x6t,qBe,Ly,jBe,$6t,k6t,hme,S6t,R6t,P6t,yy,dso;return d=new oe({}),on=new B({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),h$=new oe({}),u$=new B({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Yf=new B6t({props:{warning:!0,$$slots:{default:[R5a]},$$scope:{ctx:$}}}),p$=new oe({}),_$=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L668"}}),F$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L691"}}),Lu=new N({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[P5a]},$$scope:{ctx:$}}}),T$=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L814"}}),M$=new oe({}),E$=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L449"}}),A$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L463"}}),fp=new N({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[B5a]},$$scope:{ctx:$}}}),L$=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L664"}}),y$=new oe({}),x$=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L205"}}),S$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/main/en/internal/image_processing_utils#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L219"}}),s_=new B6t({props:{$$slots:{default:[I5a]},$$scope:{ctx:$}}}),l_=new N({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[N5a]},$$scope:{ctx:$}}}),R$=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L346"}}),P$=new oe({}),B$=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L96"}}),q$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L110"}}),R_=new B6t({props:{$$slots:{default:[q5a]},$$scope:{ctx:$}}}),P_=new N({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[j5a]},$$scope:{ctx:$}}}),j$=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L277"}}),D$=new oe({}),G$=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L889"}}),V$=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegConfig">CLIPSegConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegModel">CLIPSegModel</a> (CLIPSeg model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel">ConditionalDetrModel</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel">DeformableDetrModel</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig">DonutSwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel">DonutSwinModel</a> (DonutSwin model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel">ErnieModel</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmModel">EsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel">GPTNeoXJapaneseModel</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltModel">LiltModel</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel">MarkupLMModel</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel">PegasusXModel</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig">TableTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerModel">TableTransformerModel</a> (Table Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig">TimeSeriesTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel">TimeSeriesTransformerModel</a> (Time Series Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel">ViTMSNModel</a> (ViTMSN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel">WhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig">XCLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel">XCLIPModel</a> (X-CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),N_=new N({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[D5a]},$$scope:{ctx:$}}}),X$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),sb=new N({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[G5a]},$$scope:{ctx:$}}}),z$=new oe({}),Q$=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L896"}}),U$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining">ErnieForPreTraining</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ib=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[O5a]},$$scope:{ctx:$}}}),H$=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),av=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[V5a]},$$scope:{ctx:$}}}),J$=new oe({}),Y$=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L911"}}),K$=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM">ErnieForCausalLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM">GPTNeoXJapaneseForCausalLM</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),sv=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[X5a]},$$scope:{ctx:$}}}),ek=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Jv=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[z5a]},$$scope:{ctx:$}}}),ok=new oe({}),rk=new R({props:{name:"class transformers.AutoModelForDepthEstimation",anchor:"transformers.AutoModelForDepthEstimation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1054"}}),ak=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDepthEstimation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForDepthEstimation">DPTForDepthEstimation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNForDepthEstimation">GLPNForDepthEstimation</a> (GLPN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Zv=new N({props:{anchor:"transformers.AutoModelForDepthEstimation.from_config.example",$$slots:{default:[Q5a]},$$scope:{ctx:$}}}),nk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDepthEstimation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),rF=new N({props:{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.example",$$slots:{default:[W5a]},$$scope:{ctx:$}}}),lk=new oe({}),ik=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L918"}}),mk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM">ErnieForMaskedLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),aF=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[U5a]},$$scope:{ctx:$}}}),ck=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),zF=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[H5a]},$$scope:{ctx:$}}}),fk=new oe({}),gk=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L925"}}),uk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration">PegasusXForConditionalGeneration</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),WF=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[J5a]},$$scope:{ctx:$}}}),pk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),uT=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Y5a]},$$scope:{ctx:$}}}),_k=new oe({}),bk=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L934"}}),Fk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification">ErnieForSequenceClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification">EsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForSequenceClassification">LiltForSequenceClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification">MarkupLMForSequenceClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),_T=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[Z5a]},$$scope:{ctx:$}}}),Tk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),TM=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[K5a]},$$scope:{ctx:$}}}),Mk=new oe({}),Ek=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L990"}}),wk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice">ErnieForMultipleChoice</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),EM=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[e0a]},$$scope:{ctx:$}}}),Ak=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),tE=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[o0a]},$$scope:{ctx:$}}}),Lk=new oe({}),yk=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L997"}}),$k=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction">ErnieForNextSentencePrediction</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),nE=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[r0a]},$$scope:{ctx:$}}}),kk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),hE=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[t0a]},$$scope:{ctx:$}}}),Sk=new oe({}),Rk=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L983"}}),Bk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification">ErnieForTokenClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification">EsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForTokenClassification">LiltForTokenClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification">MarkupLMForTokenClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),pE=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[a0a]},$$scope:{ctx:$}}}),Ik=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),n4=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[n0a]},$$scope:{ctx:$}}}),Nk=new oe({}),qk=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L943"}}),Dk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering">BloomForQuestionAnswering</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering">ErnieForQuestionAnswering</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForQuestionAnswering">LiltForQuestionAnswering</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering">MarkupLMForQuestionAnswering</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering">OPTForQuestionAnswering</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),l4=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[s0a]},$$scope:{ctx:$}}}),Gk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),tC=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[l0a]},$$scope:{ctx:$}}}),Ok=new oe({}),Vk=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L950"}}),zk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),nC=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[i0a]},$$scope:{ctx:$}}}),Qk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),iC=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[d0a]},$$scope:{ctx:$}}}),Wk=new oe({}),Uk=new R({props:{name:"class transformers.AutoModelForDocumentQuestionAnswering",anchor:"transformers.AutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L972"}}),Jk=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering">LayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),mC=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[m0a]},$$scope:{ctx:$}}}),Yk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),uC=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[c0a]},$$scope:{ctx:$}}}),Zk=new oe({}),Kk=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1006"}}),oS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification">ViTMSNForImageClassification</a> (ViTMSN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),_C=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[f0a]},$$scope:{ctx:$}}}),rS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),PC=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[g0a]},$$scope:{ctx:$}}}),tS=new oe({}),aS=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1061"}}),sS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),IC=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[h0a]},$$scope:{ctx:$}}}),lS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),jC=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[u0a]},$$scope:{ctx:$}}}),iS=new oe({}),dS=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1068"}}),cS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),GC=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[p0a]},$$scope:{ctx:$}}}),fS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),XC=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[_0a]},$$scope:{ctx:$}}}),gS=new oe({}),hS=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L961"}}),pS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),QC=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[b0a]},$$scope:{ctx:$}}}),_S=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),HC=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[v0a]},$$scope:{ctx:$}}}),bS=new oe({}),vS=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1075"}}),TS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),YC=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[F0a]},$$scope:{ctx:$}}}),MS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),i3=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[T0a]},$$scope:{ctx:$}}}),ES=new oe({}),CS=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1098"}}),AS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),m3=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[M0a]},$$scope:{ctx:$}}}),LS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),_3=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[E0a]},$$scope:{ctx:$}}}),yS=new oe({}),xS=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1082"}}),kS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),v3=new N({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[C0a]},$$scope:{ctx:$}}}),SS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),k3=new N({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[w0a]},$$scope:{ctx:$}}}),RS=new oe({}),PS=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1089"}}),IS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration">WhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),R3=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[A0a]},$$scope:{ctx:$}}}),NS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),q3=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[L0a]},$$scope:{ctx:$}}}),qS=new oe({}),jS=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1107"}}),GS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),D3=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[y0a]},$$scope:{ctx:$}}}),OS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),W3=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[x0a]},$$scope:{ctx:$}}}),VS=new oe({}),XS=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1114"}}),QS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),H3=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[$0a]},$$scope:{ctx:$}}}),WS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),o5=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[k0a]},$$scope:{ctx:$}}}),US=new oe({}),HS=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1038"}}),YS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection">ConditionalDetrForObjectDetection</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection">DeformableDetrForObjectDetection</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig">TableTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection">TableTransformerForObjectDetection</a> (Table Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),t5=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[S0a]},$$scope:{ctx:$}}}),ZS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),m5=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[R0a]},$$scope:{ctx:$}}}),KS=new oe({}),eR=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1013"}}),rR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),f5=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[P0a]},$$scope:{ctx:$}}}),tR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),u5=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[B0a]},$$scope:{ctx:$}}}),aR=new oe({}),nR=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1020"}}),lR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),_5=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[I0a]},$$scope:{ctx:$}}}),iR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),C5=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[N0a]},$$scope:{ctx:$}}}),dR=new oe({}),mR=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1029"}}),fR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),A5=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[q0a]},$$scope:{ctx:$}}}),gR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),x5=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[j0a]},$$scope:{ctx:$}}}),hR=new oe({}),uR=new R({props:{name:"class transformers.AutoModelForZeroShotObjectDetection",anchor:"transformers.AutoModelForZeroShotObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1045"}}),_R=new R({props:{name:"from_config",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection">OwlViTForObjectDetection</a> (OWL-ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),k5=new N({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.example",$$slots:{default:[D0a]},$$scope:{ctx:$}}}),bR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),P5=new N({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.example",$$slots:{default:[G0a]},$$scope:{ctx:$}}}),vR=new oe({}),FR=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),MR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel">TFCvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmModel">TFEsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel">TFGroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model">TFLayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel">TFMobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel">TFWhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel">TFXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),I5=new N({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[O0a]},$$scope:{ctx:$}}}),ER=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),D0=new N({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[V0a]},$$scope:{ctx:$}}}),CR=new oe({}),wR=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L451"}}),LR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),O0=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[X0a]},$$scope:{ctx:$}}}),yR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),fw=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[z0a]},$$scope:{ctx:$}}}),xR=new oe({}),$R=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L466"}}),SR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM">TFXGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),hw=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[Q0a]},$$scope:{ctx:$}}}),RR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),xw=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[W0a]},$$scope:{ctx:$}}}),PR=new oe({}),BR=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L482"}}),NR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification">TFCvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification">TFMobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),kw=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[U0a]},$$scope:{ctx:$}}}),qR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Gw=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[H0a]},$$scope:{ctx:$}}}),jR=new oe({}),DR=new R({props:{name:"class transformers.TFAutoModelForSemanticSegmentation",anchor:"transformers.TFAutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L491"}}),OR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation">TFData2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation">TFMobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation">TFSegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Vw=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[J0a]},$$scope:{ctx:$}}}),VR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Ww=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[Y0a]},$$scope:{ctx:$}}}),XR=new oe({}),zR=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L507"}}),WR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForMaskedLM">TFEsmForMaskedLM</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Hw=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[Z0a]},$$scope:{ctx:$}}}),UR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),_A=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[K0a]},$$scope:{ctx:$}}}),HR=new oe({}),JR=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L514"}}),ZR=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),vA=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[ewa]},$$scope:{ctx:$}}}),KR=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),$A=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[owa]},$$scope:{ctx:$}}}),eP=new oe({}),oP=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L523"}}),tP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForSequenceClassification">TFEsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification">TFLayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),SA=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[rwa]},$$scope:{ctx:$}}}),aP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),l6=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[twa]},$$scope:{ctx:$}}}),nP=new oe({}),sP=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L570"}}),iP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),d6=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[awa]},$$scope:{ctx:$}}}),dP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),L6=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[nwa]},$$scope:{ctx:$}}}),mP=new oe({}),cP=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L577"}}),gP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),x6=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[swa]},$$scope:{ctx:$}}}),hP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),S6=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[lwa]},$$scope:{ctx:$}}}),pP=new oe({}),_P=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L550"}}),vP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),P6=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[iwa]},$$scope:{ctx:$}}}),FP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),I6=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[dwa]},$$scope:{ctx:$}}}),TP=new oe({}),MP=new R({props:{name:"class transformers.TFAutoModelForDocumentQuestionAnswering",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L539"}}),CP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering">TFLayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),q6=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[mwa]},$$scope:{ctx:$}}}),wP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),D6=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[cwa]},$$scope:{ctx:$}}}),AP=new oe({}),LP=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L561"}}),xP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForTokenClassification">TFEsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification">TFLayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),O6=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[fwa]},$$scope:{ctx:$}}}),$P=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),c7=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[gwa]},$$scope:{ctx:$}}}),kP=new oe({}),SP=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L532"}}),PP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering">TFLayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),g7=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[hwa]},$$scope:{ctx:$}}}),BP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),B7=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[uwa]},$$scope:{ctx:$}}}),IP=new oe({}),NP=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L500"}}),jP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),N7=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[pwa]},$$scope:{ctx:$}}}),DP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),j7=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[_wa]},$$scope:{ctx:$}}}),GP=new oe({}),OP=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L586"}}),XP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration">TFWhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),G7=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[bwa]},$$scope:{ctx:$}}}),zP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),X7=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[vwa]},$$scope:{ctx:$}}}),WP=new oe({}),UP=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),JP=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Q7=new N({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[Fwa]},$$scope:{ctx:$}}}),YP=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),F8=new N({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[Twa]},$$scope:{ctx:$}}}),ZP=new oe({}),KP=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),oB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),M8=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[Mwa]},$$scope:{ctx:$}}}),rB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),R8=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Ewa]},$$scope:{ctx:$}}}),tB=new oe({}),aB=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),sB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),B8=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[Cwa]},$$scope:{ctx:$}}}),lB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),H8=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[wwa]},$$scope:{ctx:$}}}),iB=new oe({}),dB=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),cB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Y8=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[Awa]},$$scope:{ctx:$}}}),fB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),iL=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[Lwa]},$$scope:{ctx:$}}}),gB=new oe({}),hB=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),pB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),mL=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[ywa]},$$scope:{ctx:$}}}),_B=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),TL=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[xwa]},$$scope:{ctx:$}}}),bB=new oe({}),vB=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),TB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),EL=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[$wa]},$$scope:{ctx:$}}}),MB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),PL=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[kwa]},$$scope:{ctx:$}}}),EB=new oe({}),CB=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),AB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),IL=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[Swa]},$$scope:{ctx:$}}}),LB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),WL=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[Rwa]},$$scope:{ctx:$}}}),yB=new oe({}),xB=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),kB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),HL=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[Pwa]},$$scope:{ctx:$}}}),SB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ay=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[Bwa]},$$scope:{ctx:$}}}),RB=new oe({}),PB=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),IB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),sy=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[Iwa]},$$scope:{ctx:$}}}),NB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),uy=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Nwa]},$$scope:{ctx:$}}}),qB=new oe({}),jB=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),GB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),_y=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[qwa]},$$scope:{ctx:$}}}),OB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),vy=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[jwa]},$$scope:{ctx:$}}}),VB=new oe({}),XB=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),QB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Ty=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[Dwa]},$$scope:{ctx:$}}}),WB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Cy=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[Gwa]},$$scope:{ctx:$}}}),HB=new oe({}),JB=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),ZB=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Ay=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[Owa]},$$scope:{ctx:$}}}),KB=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),yy=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Vwa]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),u=a("h1"),f=a("a"),p=a("span"),F(d.$$.fragment),h=l(),$o=a("span"),vd=o("Auto Classes"),Qf=l(),Tt=a("p"),Fd=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Td=a("code"),m$=o("from_pretrained()"),Wf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Xe=l(),He=a("p"),Md=o("Instantiating one of "),ms=a("a"),c$=o("AutoConfig"),cs=o(", "),fs=a("a"),f$=o("AutoModel"),Ed=o(`, and
`),gs=a("a"),g$=o("AutoTokenizer"),Cd=o(" will directly create a class of the relevant architecture. For instance"),Uf=l(),F(on.$$.fragment),Je=l(),Ae=a("p"),yN=o("will create a model that is an instance of "),wd=a("a"),xN=o("BertModel"),$N=o("."),ko=l(),rn=a("p"),kN=o("There is one class of "),Hf=a("code"),SN=o("AutoModel"),kio=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),Qto=l(),Ad=a("h2"),Jf=a("a"),Efe=a("span"),F(h$.$$.fragment),Sio=l(),Cfe=a("span"),Rio=o("Extending the Auto Classes"),Wto=l(),hs=a("p"),Pio=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),wfe=a("code"),Bio=o("NewModel"),Iio=o(", make sure you have a "),Afe=a("code"),Nio=o("NewModelConfig"),qio=o(` then you can add those to the auto
classes like this:`),Uto=l(),F(u$.$$.fragment),Hto=l(),RN=a("p"),jio=o("You will then be able to use the auto classes like you would usually do!"),Jto=l(),F(Yf.$$.fragment),Yto=l(),Ld=a("h2"),Zf=a("a"),Lfe=a("span"),F(p$.$$.fragment),Dio=l(),yfe=a("span"),Gio=o("AutoConfig"),Zto=l(),So=a("div"),F(_$.$$.fragment),Oio=l(),b$=a("p"),Vio=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),PN=a("a"),Xio=o("from_pretrained()"),zio=o(" class method."),Qio=l(),v$=a("p"),Wio=o("This class cannot be instantiated directly using "),xfe=a("code"),Uio=o("__init__()"),Hio=o(" (throws an error)."),Jio=l(),qr=a("div"),F(F$.$$.fragment),Yio=l(),$fe=a("p"),Zio=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),Kio=l(),yd=a("p"),edo=o("The configuration class to instantiate is selected based on the "),kfe=a("code"),odo=o("model_type"),rdo=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Sfe=a("code"),tdo=o("pretrained_model_name_or_path"),ado=o(":"),ndo=l(),A=a("ul"),Kf=a("li"),Rfe=a("strong"),sdo=o("albert"),ldo=o(" \u2014 "),BN=a("a"),ido=o("AlbertConfig"),ddo=o(" (ALBERT model)"),mdo=l(),eg=a("li"),Pfe=a("strong"),cdo=o("bart"),fdo=o(" \u2014 "),IN=a("a"),gdo=o("BartConfig"),hdo=o(" (BART model)"),udo=l(),og=a("li"),Bfe=a("strong"),pdo=o("beit"),_do=o(" \u2014 "),NN=a("a"),bdo=o("BeitConfig"),vdo=o(" (BEiT model)"),Fdo=l(),rg=a("li"),Ife=a("strong"),Tdo=o("bert"),Mdo=o(" \u2014 "),qN=a("a"),Edo=o("BertConfig"),Cdo=o(" (BERT model)"),wdo=l(),tg=a("li"),Nfe=a("strong"),Ado=o("bert-generation"),Ldo=o(" \u2014 "),jN=a("a"),ydo=o("BertGenerationConfig"),xdo=o(" (Bert Generation model)"),$do=l(),ag=a("li"),qfe=a("strong"),kdo=o("big_bird"),Sdo=o(" \u2014 "),DN=a("a"),Rdo=o("BigBirdConfig"),Pdo=o(" (BigBird model)"),Bdo=l(),ng=a("li"),jfe=a("strong"),Ido=o("bigbird_pegasus"),Ndo=o(" \u2014 "),GN=a("a"),qdo=o("BigBirdPegasusConfig"),jdo=o(" (BigBird-Pegasus model)"),Ddo=l(),sg=a("li"),Dfe=a("strong"),Gdo=o("blenderbot"),Odo=o(" \u2014 "),ON=a("a"),Vdo=o("BlenderbotConfig"),Xdo=o(" (Blenderbot model)"),zdo=l(),lg=a("li"),Gfe=a("strong"),Qdo=o("blenderbot-small"),Wdo=o(" \u2014 "),VN=a("a"),Udo=o("BlenderbotSmallConfig"),Hdo=o(" (BlenderbotSmall model)"),Jdo=l(),ig=a("li"),Ofe=a("strong"),Ydo=o("bloom"),Zdo=o(" \u2014 "),XN=a("a"),Kdo=o("BloomConfig"),emo=o(" (BLOOM model)"),omo=l(),dg=a("li"),Vfe=a("strong"),rmo=o("camembert"),tmo=o(" \u2014 "),zN=a("a"),amo=o("CamembertConfig"),nmo=o(" (CamemBERT model)"),smo=l(),mg=a("li"),Xfe=a("strong"),lmo=o("canine"),imo=o(" \u2014 "),QN=a("a"),dmo=o("CanineConfig"),mmo=o(" (CANINE model)"),cmo=l(),cg=a("li"),zfe=a("strong"),fmo=o("clip"),gmo=o(" \u2014 "),WN=a("a"),hmo=o("CLIPConfig"),umo=o(" (CLIP model)"),pmo=l(),fg=a("li"),Qfe=a("strong"),_mo=o("clipseg"),bmo=o(" \u2014 "),UN=a("a"),vmo=o("CLIPSegConfig"),Fmo=o(" (CLIPSeg model)"),Tmo=l(),gg=a("li"),Wfe=a("strong"),Mmo=o("codegen"),Emo=o(" \u2014 "),HN=a("a"),Cmo=o("CodeGenConfig"),wmo=o(" (CodeGen model)"),Amo=l(),hg=a("li"),Ufe=a("strong"),Lmo=o("conditional_detr"),ymo=o(" \u2014 "),JN=a("a"),xmo=o("ConditionalDetrConfig"),$mo=o(" (Conditional DETR model)"),kmo=l(),ug=a("li"),Hfe=a("strong"),Smo=o("convbert"),Rmo=o(" \u2014 "),YN=a("a"),Pmo=o("ConvBertConfig"),Bmo=o(" (ConvBERT model)"),Imo=l(),pg=a("li"),Jfe=a("strong"),Nmo=o("convnext"),qmo=o(" \u2014 "),ZN=a("a"),jmo=o("ConvNextConfig"),Dmo=o(" (ConvNeXT model)"),Gmo=l(),_g=a("li"),Yfe=a("strong"),Omo=o("ctrl"),Vmo=o(" \u2014 "),KN=a("a"),Xmo=o("CTRLConfig"),zmo=o(" (CTRL model)"),Qmo=l(),bg=a("li"),Zfe=a("strong"),Wmo=o("cvt"),Umo=o(" \u2014 "),eq=a("a"),Hmo=o("CvtConfig"),Jmo=o(" (CvT model)"),Ymo=l(),vg=a("li"),Kfe=a("strong"),Zmo=o("data2vec-audio"),Kmo=o(" \u2014 "),oq=a("a"),eco=o("Data2VecAudioConfig"),oco=o(" (Data2VecAudio model)"),rco=l(),Fg=a("li"),ege=a("strong"),tco=o("data2vec-text"),aco=o(" \u2014 "),rq=a("a"),nco=o("Data2VecTextConfig"),sco=o(" (Data2VecText model)"),lco=l(),Tg=a("li"),oge=a("strong"),ico=o("data2vec-vision"),dco=o(" \u2014 "),tq=a("a"),mco=o("Data2VecVisionConfig"),cco=o(" (Data2VecVision model)"),fco=l(),Mg=a("li"),rge=a("strong"),gco=o("deberta"),hco=o(" \u2014 "),aq=a("a"),uco=o("DebertaConfig"),pco=o(" (DeBERTa model)"),_co=l(),Eg=a("li"),tge=a("strong"),bco=o("deberta-v2"),vco=o(" \u2014 "),nq=a("a"),Fco=o("DebertaV2Config"),Tco=o(" (DeBERTa-v2 model)"),Mco=l(),Cg=a("li"),age=a("strong"),Eco=o("decision_transformer"),Cco=o(" \u2014 "),sq=a("a"),wco=o("DecisionTransformerConfig"),Aco=o(" (Decision Transformer model)"),Lco=l(),wg=a("li"),nge=a("strong"),yco=o("deformable_detr"),xco=o(" \u2014 "),lq=a("a"),$co=o("DeformableDetrConfig"),kco=o(" (Deformable DETR model)"),Sco=l(),Ag=a("li"),sge=a("strong"),Rco=o("deit"),Pco=o(" \u2014 "),iq=a("a"),Bco=o("DeiTConfig"),Ico=o(" (DeiT model)"),Nco=l(),Lg=a("li"),lge=a("strong"),qco=o("detr"),jco=o(" \u2014 "),dq=a("a"),Dco=o("DetrConfig"),Gco=o(" (DETR model)"),Oco=l(),yg=a("li"),ige=a("strong"),Vco=o("distilbert"),Xco=o(" \u2014 "),mq=a("a"),zco=o("DistilBertConfig"),Qco=o(" (DistilBERT model)"),Wco=l(),xg=a("li"),dge=a("strong"),Uco=o("donut-swin"),Hco=o(" \u2014 "),cq=a("a"),Jco=o("DonutSwinConfig"),Yco=o(" (DonutSwin model)"),Zco=l(),$g=a("li"),mge=a("strong"),Kco=o("dpr"),efo=o(" \u2014 "),fq=a("a"),ofo=o("DPRConfig"),rfo=o(" (DPR model)"),tfo=l(),kg=a("li"),cge=a("strong"),afo=o("dpt"),nfo=o(" \u2014 "),gq=a("a"),sfo=o("DPTConfig"),lfo=o(" (DPT model)"),ifo=l(),Sg=a("li"),fge=a("strong"),dfo=o("electra"),mfo=o(" \u2014 "),hq=a("a"),cfo=o("ElectraConfig"),ffo=o(" (ELECTRA model)"),gfo=l(),Rg=a("li"),gge=a("strong"),hfo=o("encoder-decoder"),ufo=o(" \u2014 "),uq=a("a"),pfo=o("EncoderDecoderConfig"),_fo=o(" (Encoder decoder model)"),bfo=l(),Pg=a("li"),hge=a("strong"),vfo=o("ernie"),Ffo=o(" \u2014 "),pq=a("a"),Tfo=o("ErnieConfig"),Mfo=o(" (ERNIE model)"),Efo=l(),Bg=a("li"),uge=a("strong"),Cfo=o("esm"),wfo=o(" \u2014 "),_q=a("a"),Afo=o("EsmConfig"),Lfo=o(" (ESM model)"),yfo=l(),Ig=a("li"),pge=a("strong"),xfo=o("flaubert"),$fo=o(" \u2014 "),bq=a("a"),kfo=o("FlaubertConfig"),Sfo=o(" (FlauBERT model)"),Rfo=l(),Ng=a("li"),_ge=a("strong"),Pfo=o("flava"),Bfo=o(" \u2014 "),vq=a("a"),Ifo=o("FlavaConfig"),Nfo=o(" (FLAVA model)"),qfo=l(),qg=a("li"),bge=a("strong"),jfo=o("fnet"),Dfo=o(" \u2014 "),Fq=a("a"),Gfo=o("FNetConfig"),Ofo=o(" (FNet model)"),Vfo=l(),jg=a("li"),vge=a("strong"),Xfo=o("fsmt"),zfo=o(" \u2014 "),Tq=a("a"),Qfo=o("FSMTConfig"),Wfo=o(" (FairSeq Machine-Translation model)"),Ufo=l(),Dg=a("li"),Fge=a("strong"),Hfo=o("funnel"),Jfo=o(" \u2014 "),Mq=a("a"),Yfo=o("FunnelConfig"),Zfo=o(" (Funnel Transformer model)"),Kfo=l(),Gg=a("li"),Tge=a("strong"),ego=o("glpn"),ogo=o(" \u2014 "),Eq=a("a"),rgo=o("GLPNConfig"),tgo=o(" (GLPN model)"),ago=l(),Og=a("li"),Mge=a("strong"),ngo=o("gpt2"),sgo=o(" \u2014 "),Cq=a("a"),lgo=o("GPT2Config"),igo=o(" (OpenAI GPT-2 model)"),dgo=l(),Vg=a("li"),Ege=a("strong"),mgo=o("gpt_neo"),cgo=o(" \u2014 "),wq=a("a"),fgo=o("GPTNeoConfig"),ggo=o(" (GPT Neo model)"),hgo=l(),Xg=a("li"),Cge=a("strong"),ugo=o("gpt_neox"),pgo=o(" \u2014 "),Aq=a("a"),_go=o("GPTNeoXConfig"),bgo=o(" (GPT NeoX model)"),vgo=l(),zg=a("li"),wge=a("strong"),Fgo=o("gpt_neox_japanese"),Tgo=o(" \u2014 "),Lq=a("a"),Mgo=o("GPTNeoXJapaneseConfig"),Ego=o(" (GPT NeoX Japanese model)"),Cgo=l(),Qg=a("li"),Age=a("strong"),wgo=o("gptj"),Ago=o(" \u2014 "),yq=a("a"),Lgo=o("GPTJConfig"),ygo=o(" (GPT-J model)"),xgo=l(),Wg=a("li"),Lge=a("strong"),$go=o("groupvit"),kgo=o(" \u2014 "),xq=a("a"),Sgo=o("GroupViTConfig"),Rgo=o(" (GroupViT model)"),Pgo=l(),Ug=a("li"),yge=a("strong"),Bgo=o("hubert"),Igo=o(" \u2014 "),$q=a("a"),Ngo=o("HubertConfig"),qgo=o(" (Hubert model)"),jgo=l(),Hg=a("li"),xge=a("strong"),Dgo=o("ibert"),Ggo=o(" \u2014 "),kq=a("a"),Ogo=o("IBertConfig"),Vgo=o(" (I-BERT model)"),Xgo=l(),Jg=a("li"),$ge=a("strong"),zgo=o("imagegpt"),Qgo=o(" \u2014 "),Sq=a("a"),Wgo=o("ImageGPTConfig"),Ugo=o(" (ImageGPT model)"),Hgo=l(),Yg=a("li"),kge=a("strong"),Jgo=o("layoutlm"),Ygo=o(" \u2014 "),Rq=a("a"),Zgo=o("LayoutLMConfig"),Kgo=o(" (LayoutLM model)"),eho=l(),Zg=a("li"),Sge=a("strong"),oho=o("layoutlmv2"),rho=o(" \u2014 "),Pq=a("a"),tho=o("LayoutLMv2Config"),aho=o(" (LayoutLMv2 model)"),nho=l(),Kg=a("li"),Rge=a("strong"),sho=o("layoutlmv3"),lho=o(" \u2014 "),Bq=a("a"),iho=o("LayoutLMv3Config"),dho=o(" (LayoutLMv3 model)"),mho=l(),eh=a("li"),Pge=a("strong"),cho=o("led"),fho=o(" \u2014 "),Iq=a("a"),gho=o("LEDConfig"),hho=o(" (LED model)"),uho=l(),oh=a("li"),Bge=a("strong"),pho=o("levit"),_ho=o(" \u2014 "),Nq=a("a"),bho=o("LevitConfig"),vho=o(" (LeViT model)"),Fho=l(),rh=a("li"),Ige=a("strong"),Tho=o("lilt"),Mho=o(" \u2014 "),qq=a("a"),Eho=o("LiltConfig"),Cho=o(" (LiLT model)"),who=l(),th=a("li"),Nge=a("strong"),Aho=o("longformer"),Lho=o(" \u2014 "),jq=a("a"),yho=o("LongformerConfig"),xho=o(" (Longformer model)"),$ho=l(),ah=a("li"),qge=a("strong"),kho=o("longt5"),Sho=o(" \u2014 "),Dq=a("a"),Rho=o("LongT5Config"),Pho=o(" (LongT5 model)"),Bho=l(),nh=a("li"),jge=a("strong"),Iho=o("luke"),Nho=o(" \u2014 "),Gq=a("a"),qho=o("LukeConfig"),jho=o(" (LUKE model)"),Dho=l(),sh=a("li"),Dge=a("strong"),Gho=o("lxmert"),Oho=o(" \u2014 "),Oq=a("a"),Vho=o("LxmertConfig"),Xho=o(" (LXMERT model)"),zho=l(),lh=a("li"),Gge=a("strong"),Qho=o("m2m_100"),Who=o(" \u2014 "),Vq=a("a"),Uho=o("M2M100Config"),Hho=o(" (M2M100 model)"),Jho=l(),ih=a("li"),Oge=a("strong"),Yho=o("marian"),Zho=o(" \u2014 "),Xq=a("a"),Kho=o("MarianConfig"),euo=o(" (Marian model)"),ouo=l(),dh=a("li"),Vge=a("strong"),ruo=o("markuplm"),tuo=o(" \u2014 "),zq=a("a"),auo=o("MarkupLMConfig"),nuo=o(" (MarkupLM model)"),suo=l(),mh=a("li"),Xge=a("strong"),luo=o("maskformer"),iuo=o(" \u2014 "),Qq=a("a"),duo=o("MaskFormerConfig"),muo=o(" (MaskFormer model)"),cuo=l(),ch=a("li"),zge=a("strong"),fuo=o("mbart"),guo=o(" \u2014 "),Wq=a("a"),huo=o("MBartConfig"),uuo=o(" (mBART model)"),puo=l(),fh=a("li"),Qge=a("strong"),_uo=o("mctct"),buo=o(" \u2014 "),Uq=a("a"),vuo=o("MCTCTConfig"),Fuo=o(" (M-CTC-T model)"),Tuo=l(),gh=a("li"),Wge=a("strong"),Muo=o("megatron-bert"),Euo=o(" \u2014 "),Hq=a("a"),Cuo=o("MegatronBertConfig"),wuo=o(" (Megatron-BERT model)"),Auo=l(),hh=a("li"),Uge=a("strong"),Luo=o("mobilebert"),yuo=o(" \u2014 "),Jq=a("a"),xuo=o("MobileBertConfig"),$uo=o(" (MobileBERT model)"),kuo=l(),uh=a("li"),Hge=a("strong"),Suo=o("mobilevit"),Ruo=o(" \u2014 "),Yq=a("a"),Puo=o("MobileViTConfig"),Buo=o(" (MobileViT model)"),Iuo=l(),ph=a("li"),Jge=a("strong"),Nuo=o("mpnet"),quo=o(" \u2014 "),Zq=a("a"),juo=o("MPNetConfig"),Duo=o(" (MPNet model)"),Guo=l(),_h=a("li"),Yge=a("strong"),Ouo=o("mt5"),Vuo=o(" \u2014 "),Kq=a("a"),Xuo=o("MT5Config"),zuo=o(" (MT5 model)"),Quo=l(),bh=a("li"),Zge=a("strong"),Wuo=o("mvp"),Uuo=o(" \u2014 "),ej=a("a"),Huo=o("MvpConfig"),Juo=o(" (MVP model)"),Yuo=l(),vh=a("li"),Kge=a("strong"),Zuo=o("nezha"),Kuo=o(" \u2014 "),oj=a("a"),epo=o("NezhaConfig"),opo=o(" (Nezha model)"),rpo=l(),Fh=a("li"),ehe=a("strong"),tpo=o("nystromformer"),apo=o(" \u2014 "),rj=a("a"),npo=o("NystromformerConfig"),spo=o(" (Nystr\xF6mformer model)"),lpo=l(),Th=a("li"),ohe=a("strong"),ipo=o("openai-gpt"),dpo=o(" \u2014 "),tj=a("a"),mpo=o("OpenAIGPTConfig"),cpo=o(" (OpenAI GPT model)"),fpo=l(),Mh=a("li"),rhe=a("strong"),gpo=o("opt"),hpo=o(" \u2014 "),aj=a("a"),upo=o("OPTConfig"),ppo=o(" (OPT model)"),_po=l(),Eh=a("li"),the=a("strong"),bpo=o("owlvit"),vpo=o(" \u2014 "),nj=a("a"),Fpo=o("OwlViTConfig"),Tpo=o(" (OWL-ViT model)"),Mpo=l(),Ch=a("li"),ahe=a("strong"),Epo=o("pegasus"),Cpo=o(" \u2014 "),sj=a("a"),wpo=o("PegasusConfig"),Apo=o(" (Pegasus model)"),Lpo=l(),wh=a("li"),nhe=a("strong"),ypo=o("pegasus_x"),xpo=o(" \u2014 "),lj=a("a"),$po=o("PegasusXConfig"),kpo=o(" (PEGASUS-X model)"),Spo=l(),Ah=a("li"),she=a("strong"),Rpo=o("perceiver"),Ppo=o(" \u2014 "),ij=a("a"),Bpo=o("PerceiverConfig"),Ipo=o(" (Perceiver model)"),Npo=l(),Lh=a("li"),lhe=a("strong"),qpo=o("plbart"),jpo=o(" \u2014 "),dj=a("a"),Dpo=o("PLBartConfig"),Gpo=o(" (PLBart model)"),Opo=l(),yh=a("li"),ihe=a("strong"),Vpo=o("poolformer"),Xpo=o(" \u2014 "),mj=a("a"),zpo=o("PoolFormerConfig"),Qpo=o(" (PoolFormer model)"),Wpo=l(),xh=a("li"),dhe=a("strong"),Upo=o("prophetnet"),Hpo=o(" \u2014 "),cj=a("a"),Jpo=o("ProphetNetConfig"),Ypo=o(" (ProphetNet model)"),Zpo=l(),$h=a("li"),mhe=a("strong"),Kpo=o("qdqbert"),e_o=o(" \u2014 "),fj=a("a"),o_o=o("QDQBertConfig"),r_o=o(" (QDQBert model)"),t_o=l(),kh=a("li"),che=a("strong"),a_o=o("rag"),n_o=o(" \u2014 "),gj=a("a"),s_o=o("RagConfig"),l_o=o(" (RAG model)"),i_o=l(),Sh=a("li"),fhe=a("strong"),d_o=o("realm"),m_o=o(" \u2014 "),hj=a("a"),c_o=o("RealmConfig"),f_o=o(" (REALM model)"),g_o=l(),Rh=a("li"),ghe=a("strong"),h_o=o("reformer"),u_o=o(" \u2014 "),uj=a("a"),p_o=o("ReformerConfig"),__o=o(" (Reformer model)"),b_o=l(),Ph=a("li"),hhe=a("strong"),v_o=o("regnet"),F_o=o(" \u2014 "),pj=a("a"),T_o=o("RegNetConfig"),M_o=o(" (RegNet model)"),E_o=l(),Bh=a("li"),uhe=a("strong"),C_o=o("rembert"),w_o=o(" \u2014 "),_j=a("a"),A_o=o("RemBertConfig"),L_o=o(" (RemBERT model)"),y_o=l(),Ih=a("li"),phe=a("strong"),x_o=o("resnet"),$_o=o(" \u2014 "),bj=a("a"),k_o=o("ResNetConfig"),S_o=o(" (ResNet model)"),R_o=l(),Nh=a("li"),_he=a("strong"),P_o=o("retribert"),B_o=o(" \u2014 "),vj=a("a"),I_o=o("RetriBertConfig"),N_o=o(" (RetriBERT model)"),q_o=l(),qh=a("li"),bhe=a("strong"),j_o=o("roberta"),D_o=o(" \u2014 "),Fj=a("a"),G_o=o("RobertaConfig"),O_o=o(" (RoBERTa model)"),V_o=l(),jh=a("li"),vhe=a("strong"),X_o=o("roformer"),z_o=o(" \u2014 "),Tj=a("a"),Q_o=o("RoFormerConfig"),W_o=o(" (RoFormer model)"),U_o=l(),Dh=a("li"),Fhe=a("strong"),H_o=o("segformer"),J_o=o(" \u2014 "),Mj=a("a"),Y_o=o("SegformerConfig"),Z_o=o(" (SegFormer model)"),K_o=l(),Gh=a("li"),The=a("strong"),e1o=o("sew"),o1o=o(" \u2014 "),Ej=a("a"),r1o=o("SEWConfig"),t1o=o(" (SEW model)"),a1o=l(),Oh=a("li"),Mhe=a("strong"),n1o=o("sew-d"),s1o=o(" \u2014 "),Cj=a("a"),l1o=o("SEWDConfig"),i1o=o(" (SEW-D model)"),d1o=l(),Vh=a("li"),Ehe=a("strong"),m1o=o("speech-encoder-decoder"),c1o=o(" \u2014 "),wj=a("a"),f1o=o("SpeechEncoderDecoderConfig"),g1o=o(" (Speech Encoder decoder model)"),h1o=l(),Xh=a("li"),Che=a("strong"),u1o=o("speech_to_text"),p1o=o(" \u2014 "),Aj=a("a"),_1o=o("Speech2TextConfig"),b1o=o(" (Speech2Text model)"),v1o=l(),zh=a("li"),whe=a("strong"),F1o=o("speech_to_text_2"),T1o=o(" \u2014 "),Lj=a("a"),M1o=o("Speech2Text2Config"),E1o=o(" (Speech2Text2 model)"),C1o=l(),Qh=a("li"),Ahe=a("strong"),w1o=o("splinter"),A1o=o(" \u2014 "),yj=a("a"),L1o=o("SplinterConfig"),y1o=o(" (Splinter model)"),x1o=l(),Wh=a("li"),Lhe=a("strong"),$1o=o("squeezebert"),k1o=o(" \u2014 "),xj=a("a"),S1o=o("SqueezeBertConfig"),R1o=o(" (SqueezeBERT model)"),P1o=l(),Uh=a("li"),yhe=a("strong"),B1o=o("swin"),I1o=o(" \u2014 "),$j=a("a"),N1o=o("SwinConfig"),q1o=o(" (Swin Transformer model)"),j1o=l(),Hh=a("li"),xhe=a("strong"),D1o=o("swinv2"),G1o=o(" \u2014 "),kj=a("a"),O1o=o("Swinv2Config"),V1o=o(" (Swin Transformer V2 model)"),X1o=l(),Jh=a("li"),$he=a("strong"),z1o=o("t5"),Q1o=o(" \u2014 "),Sj=a("a"),W1o=o("T5Config"),U1o=o(" (T5 model)"),H1o=l(),Yh=a("li"),khe=a("strong"),J1o=o("table-transformer"),Y1o=o(" \u2014 "),Rj=a("a"),Z1o=o("TableTransformerConfig"),K1o=o(" (Table Transformer model)"),e2o=l(),Zh=a("li"),She=a("strong"),o2o=o("tapas"),r2o=o(" \u2014 "),Pj=a("a"),t2o=o("TapasConfig"),a2o=o(" (TAPAS model)"),n2o=l(),Kh=a("li"),Rhe=a("strong"),s2o=o("time_series_transformer"),l2o=o(" \u2014 "),Bj=a("a"),i2o=o("TimeSeriesTransformerConfig"),d2o=o(" (Time Series Transformer model)"),m2o=l(),eu=a("li"),Phe=a("strong"),c2o=o("trajectory_transformer"),f2o=o(" \u2014 "),Ij=a("a"),g2o=o("TrajectoryTransformerConfig"),h2o=o(" (Trajectory Transformer model)"),u2o=l(),ou=a("li"),Bhe=a("strong"),p2o=o("transfo-xl"),_2o=o(" \u2014 "),Nj=a("a"),b2o=o("TransfoXLConfig"),v2o=o(" (Transformer-XL model)"),F2o=l(),ru=a("li"),Ihe=a("strong"),T2o=o("trocr"),M2o=o(" \u2014 "),qj=a("a"),E2o=o("TrOCRConfig"),C2o=o(" (TrOCR model)"),w2o=l(),tu=a("li"),Nhe=a("strong"),A2o=o("unispeech"),L2o=o(" \u2014 "),jj=a("a"),y2o=o("UniSpeechConfig"),x2o=o(" (UniSpeech model)"),$2o=l(),au=a("li"),qhe=a("strong"),k2o=o("unispeech-sat"),S2o=o(" \u2014 "),Dj=a("a"),R2o=o("UniSpeechSatConfig"),P2o=o(" (UniSpeechSat model)"),B2o=l(),nu=a("li"),jhe=a("strong"),I2o=o("van"),N2o=o(" \u2014 "),Gj=a("a"),q2o=o("VanConfig"),j2o=o(" (VAN model)"),D2o=l(),su=a("li"),Dhe=a("strong"),G2o=o("videomae"),O2o=o(" \u2014 "),Oj=a("a"),V2o=o("VideoMAEConfig"),X2o=o(" (VideoMAE model)"),z2o=l(),lu=a("li"),Ghe=a("strong"),Q2o=o("vilt"),W2o=o(" \u2014 "),Vj=a("a"),U2o=o("ViltConfig"),H2o=o(" (ViLT model)"),J2o=l(),iu=a("li"),Ohe=a("strong"),Y2o=o("vision-encoder-decoder"),Z2o=o(" \u2014 "),Xj=a("a"),K2o=o("VisionEncoderDecoderConfig"),ebo=o(" (Vision Encoder decoder model)"),obo=l(),du=a("li"),Vhe=a("strong"),rbo=o("vision-text-dual-encoder"),tbo=o(" \u2014 "),zj=a("a"),abo=o("VisionTextDualEncoderConfig"),nbo=o(" (VisionTextDualEncoder model)"),sbo=l(),mu=a("li"),Xhe=a("strong"),lbo=o("visual_bert"),ibo=o(" \u2014 "),Qj=a("a"),dbo=o("VisualBertConfig"),mbo=o(" (VisualBERT model)"),cbo=l(),cu=a("li"),zhe=a("strong"),fbo=o("vit"),gbo=o(" \u2014 "),Wj=a("a"),hbo=o("ViTConfig"),ubo=o(" (ViT model)"),pbo=l(),fu=a("li"),Qhe=a("strong"),_bo=o("vit_mae"),bbo=o(" \u2014 "),Uj=a("a"),vbo=o("ViTMAEConfig"),Fbo=o(" (ViTMAE model)"),Tbo=l(),gu=a("li"),Whe=a("strong"),Mbo=o("vit_msn"),Ebo=o(" \u2014 "),Hj=a("a"),Cbo=o("ViTMSNConfig"),wbo=o(" (ViTMSN model)"),Abo=l(),hu=a("li"),Uhe=a("strong"),Lbo=o("wav2vec2"),ybo=o(" \u2014 "),Jj=a("a"),xbo=o("Wav2Vec2Config"),$bo=o(" (Wav2Vec2 model)"),kbo=l(),uu=a("li"),Hhe=a("strong"),Sbo=o("wav2vec2-conformer"),Rbo=o(" \u2014 "),Yj=a("a"),Pbo=o("Wav2Vec2ConformerConfig"),Bbo=o(" (Wav2Vec2-Conformer model)"),Ibo=l(),pu=a("li"),Jhe=a("strong"),Nbo=o("wavlm"),qbo=o(" \u2014 "),Zj=a("a"),jbo=o("WavLMConfig"),Dbo=o(" (WavLM model)"),Gbo=l(),_u=a("li"),Yhe=a("strong"),Obo=o("whisper"),Vbo=o(" \u2014 "),Kj=a("a"),Xbo=o("WhisperConfig"),zbo=o(" (Whisper model)"),Qbo=l(),bu=a("li"),Zhe=a("strong"),Wbo=o("xclip"),Ubo=o(" \u2014 "),eD=a("a"),Hbo=o("XCLIPConfig"),Jbo=o(" (X-CLIP model)"),Ybo=l(),vu=a("li"),Khe=a("strong"),Zbo=o("xglm"),Kbo=o(" \u2014 "),oD=a("a"),evo=o("XGLMConfig"),ovo=o(" (XGLM model)"),rvo=l(),Fu=a("li"),eue=a("strong"),tvo=o("xlm"),avo=o(" \u2014 "),rD=a("a"),nvo=o("XLMConfig"),svo=o(" (XLM model)"),lvo=l(),Tu=a("li"),oue=a("strong"),ivo=o("xlm-prophetnet"),dvo=o(" \u2014 "),tD=a("a"),mvo=o("XLMProphetNetConfig"),cvo=o(" (XLM-ProphetNet model)"),fvo=l(),Mu=a("li"),rue=a("strong"),gvo=o("xlm-roberta"),hvo=o(" \u2014 "),aD=a("a"),uvo=o("XLMRobertaConfig"),pvo=o(" (XLM-RoBERTa model)"),_vo=l(),Eu=a("li"),tue=a("strong"),bvo=o("xlm-roberta-xl"),vvo=o(" \u2014 "),nD=a("a"),Fvo=o("XLMRobertaXLConfig"),Tvo=o(" (XLM-RoBERTa-XL model)"),Mvo=l(),Cu=a("li"),aue=a("strong"),Evo=o("xlnet"),Cvo=o(" \u2014 "),sD=a("a"),wvo=o("XLNetConfig"),Avo=o(" (XLNet model)"),Lvo=l(),wu=a("li"),nue=a("strong"),yvo=o("yolos"),xvo=o(" \u2014 "),lD=a("a"),$vo=o("YolosConfig"),kvo=o(" (YOLOS model)"),Svo=l(),Au=a("li"),sue=a("strong"),Rvo=o("yoso"),Pvo=o(" \u2014 "),iD=a("a"),Bvo=o("YosoConfig"),Ivo=o(" (YOSO model)"),Nvo=l(),F(Lu.$$.fragment),qvo=l(),yu=a("div"),F(T$.$$.fragment),jvo=l(),lue=a("p"),Dvo=o("Register a new configuration for this class."),Kto=l(),xd=a("h2"),xu=a("a"),iue=a("span"),F(M$.$$.fragment),Gvo=l(),due=a("span"),Ovo=o("AutoTokenizer"),eao=l(),Ro=a("div"),F(E$.$$.fragment),Vvo=l(),C$=a("p"),Xvo=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),dD=a("a"),zvo=o("AutoTokenizer.from_pretrained()"),Qvo=o(" class method."),Wvo=l(),w$=a("p"),Uvo=o("This class cannot be instantiated directly using "),mue=a("code"),Hvo=o("__init__()"),Jvo=o(" (throws an error)."),Yvo=l(),jr=a("div"),F(A$.$$.fragment),Zvo=l(),cue=a("p"),Kvo=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),eFo=l(),tn=a("p"),oFo=o("The tokenizer class to instantiate is selected based on the "),fue=a("code"),rFo=o("model_type"),tFo=o(` property of the config object (either
passed as an argument or loaded from `),gue=a("code"),aFo=o("pretrained_model_name_or_path"),nFo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hue=a("code"),sFo=o("pretrained_model_name_or_path"),lFo=o(":"),iFo=l(),k=a("ul"),us=a("li"),uue=a("strong"),dFo=o("albert"),mFo=o(" \u2014 "),mD=a("a"),cFo=o("AlbertTokenizer"),fFo=o(" or "),cD=a("a"),gFo=o("AlbertTokenizerFast"),hFo=o(" (ALBERT model)"),uFo=l(),ps=a("li"),pue=a("strong"),pFo=o("bart"),_Fo=o(" \u2014 "),fD=a("a"),bFo=o("BartTokenizer"),vFo=o(" or "),gD=a("a"),FFo=o("BartTokenizerFast"),TFo=o(" (BART model)"),MFo=l(),_s=a("li"),_ue=a("strong"),EFo=o("barthez"),CFo=o(" \u2014 "),hD=a("a"),wFo=o("BarthezTokenizer"),AFo=o(" or "),uD=a("a"),LFo=o("BarthezTokenizerFast"),yFo=o(" (BARThez model)"),xFo=l(),$u=a("li"),bue=a("strong"),$Fo=o("bartpho"),kFo=o(" \u2014 "),pD=a("a"),SFo=o("BartphoTokenizer"),RFo=o(" (BARTpho model)"),PFo=l(),bs=a("li"),vue=a("strong"),BFo=o("bert"),IFo=o(" \u2014 "),_D=a("a"),NFo=o("BertTokenizer"),qFo=o(" or "),bD=a("a"),jFo=o("BertTokenizerFast"),DFo=o(" (BERT model)"),GFo=l(),ku=a("li"),Fue=a("strong"),OFo=o("bert-generation"),VFo=o(" \u2014 "),vD=a("a"),XFo=o("BertGenerationTokenizer"),zFo=o(" (Bert Generation model)"),QFo=l(),Su=a("li"),Tue=a("strong"),WFo=o("bert-japanese"),UFo=o(" \u2014 "),FD=a("a"),HFo=o("BertJapaneseTokenizer"),JFo=o(" (BertJapanese model)"),YFo=l(),Ru=a("li"),Mue=a("strong"),ZFo=o("bertweet"),KFo=o(" \u2014 "),TD=a("a"),eTo=o("BertweetTokenizer"),oTo=o(" (BERTweet model)"),rTo=l(),vs=a("li"),Eue=a("strong"),tTo=o("big_bird"),aTo=o(" \u2014 "),MD=a("a"),nTo=o("BigBirdTokenizer"),sTo=o(" or "),ED=a("a"),lTo=o("BigBirdTokenizerFast"),iTo=o(" (BigBird model)"),dTo=l(),Fs=a("li"),Cue=a("strong"),mTo=o("bigbird_pegasus"),cTo=o(" \u2014 "),CD=a("a"),fTo=o("PegasusTokenizer"),gTo=o(" or "),wD=a("a"),hTo=o("PegasusTokenizerFast"),uTo=o(" (BigBird-Pegasus model)"),pTo=l(),Ts=a("li"),wue=a("strong"),_To=o("blenderbot"),bTo=o(" \u2014 "),AD=a("a"),vTo=o("BlenderbotTokenizer"),FTo=o(" or "),LD=a("a"),TTo=o("BlenderbotTokenizerFast"),MTo=o(" (Blenderbot model)"),ETo=l(),Pu=a("li"),Aue=a("strong"),CTo=o("blenderbot-small"),wTo=o(" \u2014 "),yD=a("a"),ATo=o("BlenderbotSmallTokenizer"),LTo=o(" (BlenderbotSmall model)"),yTo=l(),Bu=a("li"),Lue=a("strong"),xTo=o("bloom"),$To=o(" \u2014 "),xD=a("a"),kTo=o("BloomTokenizerFast"),STo=o(" (BLOOM model)"),RTo=l(),Iu=a("li"),yue=a("strong"),PTo=o("byt5"),BTo=o(" \u2014 "),$D=a("a"),ITo=o("ByT5Tokenizer"),NTo=o(" (ByT5 model)"),qTo=l(),Ms=a("li"),xue=a("strong"),jTo=o("camembert"),DTo=o(" \u2014 "),kD=a("a"),GTo=o("CamembertTokenizer"),OTo=o(" or "),SD=a("a"),VTo=o("CamembertTokenizerFast"),XTo=o(" (CamemBERT model)"),zTo=l(),Nu=a("li"),$ue=a("strong"),QTo=o("canine"),WTo=o(" \u2014 "),RD=a("a"),UTo=o("CanineTokenizer"),HTo=o(" (CANINE model)"),JTo=l(),Es=a("li"),kue=a("strong"),YTo=o("clip"),ZTo=o(" \u2014 "),PD=a("a"),KTo=o("CLIPTokenizer"),eMo=o(" or "),BD=a("a"),oMo=o("CLIPTokenizerFast"),rMo=o(" (CLIP model)"),tMo=l(),Cs=a("li"),Sue=a("strong"),aMo=o("clipseg"),nMo=o(" \u2014 "),ID=a("a"),sMo=o("CLIPTokenizer"),lMo=o(" or "),ND=a("a"),iMo=o("CLIPTokenizerFast"),dMo=o(" (CLIPSeg model)"),mMo=l(),ws=a("li"),Rue=a("strong"),cMo=o("codegen"),fMo=o(" \u2014 "),qD=a("a"),gMo=o("CodeGenTokenizer"),hMo=o(" or "),jD=a("a"),uMo=o("CodeGenTokenizerFast"),pMo=o(" (CodeGen model)"),_Mo=l(),As=a("li"),Pue=a("strong"),bMo=o("convbert"),vMo=o(" \u2014 "),DD=a("a"),FMo=o("ConvBertTokenizer"),TMo=o(" or "),GD=a("a"),MMo=o("ConvBertTokenizerFast"),EMo=o(" (ConvBERT model)"),CMo=l(),Ls=a("li"),Bue=a("strong"),wMo=o("cpm"),AMo=o(" \u2014 "),OD=a("a"),LMo=o("CpmTokenizer"),yMo=o(" or "),VD=a("a"),xMo=o("CpmTokenizerFast"),$Mo=o(" (CPM model)"),kMo=l(),qu=a("li"),Iue=a("strong"),SMo=o("ctrl"),RMo=o(" \u2014 "),XD=a("a"),PMo=o("CTRLTokenizer"),BMo=o(" (CTRL model)"),IMo=l(),ys=a("li"),Nue=a("strong"),NMo=o("data2vec-text"),qMo=o(" \u2014 "),zD=a("a"),jMo=o("RobertaTokenizer"),DMo=o(" or "),QD=a("a"),GMo=o("RobertaTokenizerFast"),OMo=o(" (Data2VecText model)"),VMo=l(),xs=a("li"),que=a("strong"),XMo=o("deberta"),zMo=o(" \u2014 "),WD=a("a"),QMo=o("DebertaTokenizer"),WMo=o(" or "),UD=a("a"),UMo=o("DebertaTokenizerFast"),HMo=o(" (DeBERTa model)"),JMo=l(),$s=a("li"),jue=a("strong"),YMo=o("deberta-v2"),ZMo=o(" \u2014 "),HD=a("a"),KMo=o("DebertaV2Tokenizer"),eEo=o(" or "),JD=a("a"),oEo=o("DebertaV2TokenizerFast"),rEo=o(" (DeBERTa-v2 model)"),tEo=l(),ks=a("li"),Due=a("strong"),aEo=o("distilbert"),nEo=o(" \u2014 "),YD=a("a"),sEo=o("DistilBertTokenizer"),lEo=o(" or "),ZD=a("a"),iEo=o("DistilBertTokenizerFast"),dEo=o(" (DistilBERT model)"),mEo=l(),Ss=a("li"),Gue=a("strong"),cEo=o("dpr"),fEo=o(" \u2014 "),KD=a("a"),gEo=o("DPRQuestionEncoderTokenizer"),hEo=o(" or "),eG=a("a"),uEo=o("DPRQuestionEncoderTokenizerFast"),pEo=o(" (DPR model)"),_Eo=l(),Rs=a("li"),Oue=a("strong"),bEo=o("electra"),vEo=o(" \u2014 "),oG=a("a"),FEo=o("ElectraTokenizer"),TEo=o(" or "),rG=a("a"),MEo=o("ElectraTokenizerFast"),EEo=o(" (ELECTRA model)"),CEo=l(),Ps=a("li"),Vue=a("strong"),wEo=o("ernie"),AEo=o(" \u2014 "),tG=a("a"),LEo=o("BertTokenizer"),yEo=o(" or "),aG=a("a"),xEo=o("BertTokenizerFast"),$Eo=o(" (ERNIE model)"),kEo=l(),ju=a("li"),Xue=a("strong"),SEo=o("esm"),REo=o(" \u2014 "),nG=a("a"),PEo=o("EsmTokenizer"),BEo=o(" (ESM model)"),IEo=l(),Du=a("li"),zue=a("strong"),NEo=o("flaubert"),qEo=o(" \u2014 "),sG=a("a"),jEo=o("FlaubertTokenizer"),DEo=o(" (FlauBERT model)"),GEo=l(),Bs=a("li"),Que=a("strong"),OEo=o("fnet"),VEo=o(" \u2014 "),lG=a("a"),XEo=o("FNetTokenizer"),zEo=o(" or "),iG=a("a"),QEo=o("FNetTokenizerFast"),WEo=o(" (FNet model)"),UEo=l(),Gu=a("li"),Wue=a("strong"),HEo=o("fsmt"),JEo=o(" \u2014 "),dG=a("a"),YEo=o("FSMTTokenizer"),ZEo=o(" (FairSeq Machine-Translation model)"),KEo=l(),Is=a("li"),Uue=a("strong"),e4o=o("funnel"),o4o=o(" \u2014 "),mG=a("a"),r4o=o("FunnelTokenizer"),t4o=o(" or "),cG=a("a"),a4o=o("FunnelTokenizerFast"),n4o=o(" (Funnel Transformer model)"),s4o=l(),Ns=a("li"),Hue=a("strong"),l4o=o("gpt2"),i4o=o(" \u2014 "),fG=a("a"),d4o=o("GPT2Tokenizer"),m4o=o(" or "),gG=a("a"),c4o=o("GPT2TokenizerFast"),f4o=o(" (OpenAI GPT-2 model)"),g4o=l(),qs=a("li"),Jue=a("strong"),h4o=o("gpt_neo"),u4o=o(" \u2014 "),hG=a("a"),p4o=o("GPT2Tokenizer"),_4o=o(" or "),uG=a("a"),b4o=o("GPT2TokenizerFast"),v4o=o(" (GPT Neo model)"),F4o=l(),Ou=a("li"),Yue=a("strong"),T4o=o("gpt_neox"),M4o=o(" \u2014 "),pG=a("a"),E4o=o("GPTNeoXTokenizerFast"),C4o=o(" (GPT NeoX model)"),w4o=l(),Vu=a("li"),Zue=a("strong"),A4o=o("gpt_neox_japanese"),L4o=o(" \u2014 "),_G=a("a"),y4o=o("GPTNeoXJapaneseTokenizer"),x4o=o(" (GPT NeoX Japanese model)"),$4o=l(),js=a("li"),Kue=a("strong"),k4o=o("gptj"),S4o=o(" \u2014 "),bG=a("a"),R4o=o("GPT2Tokenizer"),P4o=o(" or "),vG=a("a"),B4o=o("GPT2TokenizerFast"),I4o=o(" (GPT-J model)"),N4o=l(),Ds=a("li"),epe=a("strong"),q4o=o("groupvit"),j4o=o(" \u2014 "),FG=a("a"),D4o=o("CLIPTokenizer"),G4o=o(" or "),TG=a("a"),O4o=o("CLIPTokenizerFast"),V4o=o(" (GroupViT model)"),X4o=l(),Gs=a("li"),ope=a("strong"),z4o=o("herbert"),Q4o=o(" \u2014 "),MG=a("a"),W4o=o("HerbertTokenizer"),U4o=o(" or "),EG=a("a"),H4o=o("HerbertTokenizerFast"),J4o=o(" (HerBERT model)"),Y4o=l(),Xu=a("li"),rpe=a("strong"),Z4o=o("hubert"),K4o=o(" \u2014 "),CG=a("a"),eCo=o("Wav2Vec2CTCTokenizer"),oCo=o(" (Hubert model)"),rCo=l(),Os=a("li"),tpe=a("strong"),tCo=o("ibert"),aCo=o(" \u2014 "),wG=a("a"),nCo=o("RobertaTokenizer"),sCo=o(" or "),AG=a("a"),lCo=o("RobertaTokenizerFast"),iCo=o(" (I-BERT model)"),dCo=l(),Vs=a("li"),ape=a("strong"),mCo=o("layoutlm"),cCo=o(" \u2014 "),LG=a("a"),fCo=o("LayoutLMTokenizer"),gCo=o(" or "),yG=a("a"),hCo=o("LayoutLMTokenizerFast"),uCo=o(" (LayoutLM model)"),pCo=l(),Xs=a("li"),npe=a("strong"),_Co=o("layoutlmv2"),bCo=o(" \u2014 "),xG=a("a"),vCo=o("LayoutLMv2Tokenizer"),FCo=o(" or "),$G=a("a"),TCo=o("LayoutLMv2TokenizerFast"),MCo=o(" (LayoutLMv2 model)"),ECo=l(),zs=a("li"),spe=a("strong"),CCo=o("layoutlmv3"),wCo=o(" \u2014 "),kG=a("a"),ACo=o("LayoutLMv3Tokenizer"),LCo=o(" or "),SG=a("a"),yCo=o("LayoutLMv3TokenizerFast"),xCo=o(" (LayoutLMv3 model)"),$Co=l(),Qs=a("li"),lpe=a("strong"),kCo=o("layoutxlm"),SCo=o(" \u2014 "),RG=a("a"),RCo=o("LayoutXLMTokenizer"),PCo=o(" or "),PG=a("a"),BCo=o("LayoutXLMTokenizerFast"),ICo=o(" (LayoutXLM model)"),NCo=l(),Ws=a("li"),ipe=a("strong"),qCo=o("led"),jCo=o(" \u2014 "),BG=a("a"),DCo=o("LEDTokenizer"),GCo=o(" or "),IG=a("a"),OCo=o("LEDTokenizerFast"),VCo=o(" (LED model)"),XCo=l(),Us=a("li"),dpe=a("strong"),zCo=o("lilt"),QCo=o(" \u2014 "),NG=a("a"),WCo=o("LayoutLMv3Tokenizer"),UCo=o(" or "),qG=a("a"),HCo=o("LayoutLMv3TokenizerFast"),JCo=o(" (LiLT model)"),YCo=l(),Hs=a("li"),mpe=a("strong"),ZCo=o("longformer"),KCo=o(" \u2014 "),jG=a("a"),e3o=o("LongformerTokenizer"),o3o=o(" or "),DG=a("a"),r3o=o("LongformerTokenizerFast"),t3o=o(" (Longformer model)"),a3o=l(),Js=a("li"),cpe=a("strong"),n3o=o("longt5"),s3o=o(" \u2014 "),GG=a("a"),l3o=o("T5Tokenizer"),i3o=o(" or "),OG=a("a"),d3o=o("T5TokenizerFast"),m3o=o(" (LongT5 model)"),c3o=l(),zu=a("li"),fpe=a("strong"),f3o=o("luke"),g3o=o(" \u2014 "),VG=a("a"),h3o=o("LukeTokenizer"),u3o=o(" (LUKE model)"),p3o=l(),Ys=a("li"),gpe=a("strong"),_3o=o("lxmert"),b3o=o(" \u2014 "),XG=a("a"),v3o=o("LxmertTokenizer"),F3o=o(" or "),zG=a("a"),T3o=o("LxmertTokenizerFast"),M3o=o(" (LXMERT model)"),E3o=l(),Qu=a("li"),hpe=a("strong"),C3o=o("m2m_100"),w3o=o(" \u2014 "),QG=a("a"),A3o=o("M2M100Tokenizer"),L3o=o(" (M2M100 model)"),y3o=l(),Wu=a("li"),upe=a("strong"),x3o=o("marian"),$3o=o(" \u2014 "),WG=a("a"),k3o=o("MarianTokenizer"),S3o=o(" (Marian model)"),R3o=l(),Zs=a("li"),ppe=a("strong"),P3o=o("mbart"),B3o=o(" \u2014 "),UG=a("a"),I3o=o("MBartTokenizer"),N3o=o(" or "),HG=a("a"),q3o=o("MBartTokenizerFast"),j3o=o(" (mBART model)"),D3o=l(),Ks=a("li"),_pe=a("strong"),G3o=o("mbart50"),O3o=o(" \u2014 "),JG=a("a"),V3o=o("MBart50Tokenizer"),X3o=o(" or "),YG=a("a"),z3o=o("MBart50TokenizerFast"),Q3o=o(" (mBART-50 model)"),W3o=l(),el=a("li"),bpe=a("strong"),U3o=o("megatron-bert"),H3o=o(" \u2014 "),ZG=a("a"),J3o=o("BertTokenizer"),Y3o=o(" or "),KG=a("a"),Z3o=o("BertTokenizerFast"),K3o=o(" (Megatron-BERT model)"),e5o=l(),Uu=a("li"),vpe=a("strong"),o5o=o("mluke"),r5o=o(" \u2014 "),eO=a("a"),t5o=o("MLukeTokenizer"),a5o=o(" (mLUKE model)"),n5o=l(),ol=a("li"),Fpe=a("strong"),s5o=o("mobilebert"),l5o=o(" \u2014 "),oO=a("a"),i5o=o("MobileBertTokenizer"),d5o=o(" or "),rO=a("a"),m5o=o("MobileBertTokenizerFast"),c5o=o(" (MobileBERT model)"),f5o=l(),rl=a("li"),Tpe=a("strong"),g5o=o("mpnet"),h5o=o(" \u2014 "),tO=a("a"),u5o=o("MPNetTokenizer"),p5o=o(" or "),aO=a("a"),_5o=o("MPNetTokenizerFast"),b5o=o(" (MPNet model)"),v5o=l(),tl=a("li"),Mpe=a("strong"),F5o=o("mt5"),T5o=o(" \u2014 "),nO=a("a"),M5o=o("MT5Tokenizer"),E5o=o(" or "),sO=a("a"),C5o=o("MT5TokenizerFast"),w5o=o(" (MT5 model)"),A5o=l(),al=a("li"),Epe=a("strong"),L5o=o("mvp"),y5o=o(" \u2014 "),lO=a("a"),x5o=o("MvpTokenizer"),$5o=o(" or "),iO=a("a"),k5o=o("MvpTokenizerFast"),S5o=o(" (MVP model)"),R5o=l(),nl=a("li"),Cpe=a("strong"),P5o=o("nezha"),B5o=o(" \u2014 "),dO=a("a"),I5o=o("BertTokenizer"),N5o=o(" or "),mO=a("a"),q5o=o("BertTokenizerFast"),j5o=o(" (Nezha model)"),D5o=l(),sl=a("li"),wpe=a("strong"),G5o=o("nllb"),O5o=o(" \u2014 "),cO=a("a"),V5o=o("NllbTokenizer"),X5o=o(" or "),fO=a("a"),z5o=o("NllbTokenizerFast"),Q5o=o(" (NLLB model)"),W5o=l(),ll=a("li"),Ape=a("strong"),U5o=o("nystromformer"),H5o=o(" \u2014 "),gO=a("a"),J5o=o("AlbertTokenizer"),Y5o=o(" or "),hO=a("a"),Z5o=o("AlbertTokenizerFast"),K5o=o(" (Nystr\xF6mformer model)"),e0o=l(),il=a("li"),Lpe=a("strong"),o0o=o("openai-gpt"),r0o=o(" \u2014 "),uO=a("a"),t0o=o("OpenAIGPTTokenizer"),a0o=o(" or "),pO=a("a"),n0o=o("OpenAIGPTTokenizerFast"),s0o=o(" (OpenAI GPT model)"),l0o=l(),Hu=a("li"),ype=a("strong"),i0o=o("opt"),d0o=o(" \u2014 "),_O=a("a"),m0o=o("GPT2Tokenizer"),c0o=o(" (OPT model)"),f0o=l(),dl=a("li"),xpe=a("strong"),g0o=o("owlvit"),h0o=o(" \u2014 "),bO=a("a"),u0o=o("CLIPTokenizer"),p0o=o(" or "),vO=a("a"),_0o=o("CLIPTokenizerFast"),b0o=o(" (OWL-ViT model)"),v0o=l(),ml=a("li"),$pe=a("strong"),F0o=o("pegasus"),T0o=o(" \u2014 "),FO=a("a"),M0o=o("PegasusTokenizer"),E0o=o(" or "),TO=a("a"),C0o=o("PegasusTokenizerFast"),w0o=o(" (Pegasus model)"),A0o=l(),cl=a("li"),kpe=a("strong"),L0o=o("pegasus_x"),y0o=o(" \u2014 "),MO=a("a"),x0o=o("PegasusTokenizer"),$0o=o(" or "),EO=a("a"),k0o=o("PegasusTokenizerFast"),S0o=o(" (PEGASUS-X model)"),R0o=l(),Ju=a("li"),Spe=a("strong"),P0o=o("perceiver"),B0o=o(" \u2014 "),CO=a("a"),I0o=o("PerceiverTokenizer"),N0o=o(" (Perceiver model)"),q0o=l(),Yu=a("li"),Rpe=a("strong"),j0o=o("phobert"),D0o=o(" \u2014 "),wO=a("a"),G0o=o("PhobertTokenizer"),O0o=o(" (PhoBERT model)"),V0o=l(),Zu=a("li"),Ppe=a("strong"),X0o=o("plbart"),z0o=o(" \u2014 "),AO=a("a"),Q0o=o("PLBartTokenizer"),W0o=o(" (PLBart model)"),U0o=l(),Ku=a("li"),Bpe=a("strong"),H0o=o("prophetnet"),J0o=o(" \u2014 "),LO=a("a"),Y0o=o("ProphetNetTokenizer"),Z0o=o(" (ProphetNet model)"),K0o=l(),fl=a("li"),Ipe=a("strong"),ewo=o("qdqbert"),owo=o(" \u2014 "),yO=a("a"),rwo=o("BertTokenizer"),two=o(" or "),xO=a("a"),awo=o("BertTokenizerFast"),nwo=o(" (QDQBert model)"),swo=l(),ep=a("li"),Npe=a("strong"),lwo=o("rag"),iwo=o(" \u2014 "),$O=a("a"),dwo=o("RagTokenizer"),mwo=o(" (RAG model)"),cwo=l(),gl=a("li"),qpe=a("strong"),fwo=o("realm"),gwo=o(" \u2014 "),kO=a("a"),hwo=o("RealmTokenizer"),uwo=o(" or "),SO=a("a"),pwo=o("RealmTokenizerFast"),_wo=o(" (REALM model)"),bwo=l(),hl=a("li"),jpe=a("strong"),vwo=o("reformer"),Fwo=o(" \u2014 "),RO=a("a"),Two=o("ReformerTokenizer"),Mwo=o(" or "),PO=a("a"),Ewo=o("ReformerTokenizerFast"),Cwo=o(" (Reformer model)"),wwo=l(),ul=a("li"),Dpe=a("strong"),Awo=o("rembert"),Lwo=o(" \u2014 "),BO=a("a"),ywo=o("RemBertTokenizer"),xwo=o(" or "),IO=a("a"),$wo=o("RemBertTokenizerFast"),kwo=o(" (RemBERT model)"),Swo=l(),pl=a("li"),Gpe=a("strong"),Rwo=o("retribert"),Pwo=o(" \u2014 "),NO=a("a"),Bwo=o("RetriBertTokenizer"),Iwo=o(" or "),qO=a("a"),Nwo=o("RetriBertTokenizerFast"),qwo=o(" (RetriBERT model)"),jwo=l(),_l=a("li"),Ope=a("strong"),Dwo=o("roberta"),Gwo=o(" \u2014 "),jO=a("a"),Owo=o("RobertaTokenizer"),Vwo=o(" or "),DO=a("a"),Xwo=o("RobertaTokenizerFast"),zwo=o(" (RoBERTa model)"),Qwo=l(),bl=a("li"),Vpe=a("strong"),Wwo=o("roformer"),Uwo=o(" \u2014 "),GO=a("a"),Hwo=o("RoFormerTokenizer"),Jwo=o(" or "),OO=a("a"),Ywo=o("RoFormerTokenizerFast"),Zwo=o(" (RoFormer model)"),Kwo=l(),op=a("li"),Xpe=a("strong"),eAo=o("speech_to_text"),oAo=o(" \u2014 "),VO=a("a"),rAo=o("Speech2TextTokenizer"),tAo=o(" (Speech2Text model)"),aAo=l(),rp=a("li"),zpe=a("strong"),nAo=o("speech_to_text_2"),sAo=o(" \u2014 "),XO=a("a"),lAo=o("Speech2Text2Tokenizer"),iAo=o(" (Speech2Text2 model)"),dAo=l(),vl=a("li"),Qpe=a("strong"),mAo=o("splinter"),cAo=o(" \u2014 "),zO=a("a"),fAo=o("SplinterTokenizer"),gAo=o(" or "),QO=a("a"),hAo=o("SplinterTokenizerFast"),uAo=o(" (Splinter model)"),pAo=l(),Fl=a("li"),Wpe=a("strong"),_Ao=o("squeezebert"),bAo=o(" \u2014 "),WO=a("a"),vAo=o("SqueezeBertTokenizer"),FAo=o(" or "),UO=a("a"),TAo=o("SqueezeBertTokenizerFast"),MAo=o(" (SqueezeBERT model)"),EAo=l(),Tl=a("li"),Upe=a("strong"),CAo=o("t5"),wAo=o(" \u2014 "),HO=a("a"),AAo=o("T5Tokenizer"),LAo=o(" or "),JO=a("a"),yAo=o("T5TokenizerFast"),xAo=o(" (T5 model)"),$Ao=l(),tp=a("li"),Hpe=a("strong"),kAo=o("tapas"),SAo=o(" \u2014 "),YO=a("a"),RAo=o("TapasTokenizer"),PAo=o(" (TAPAS model)"),BAo=l(),ap=a("li"),Jpe=a("strong"),IAo=o("tapex"),NAo=o(" \u2014 "),ZO=a("a"),qAo=o("TapexTokenizer"),jAo=o(" (TAPEX model)"),DAo=l(),np=a("li"),Ype=a("strong"),GAo=o("transfo-xl"),OAo=o(" \u2014 "),KO=a("a"),VAo=o("TransfoXLTokenizer"),XAo=o(" (Transformer-XL model)"),zAo=l(),Ml=a("li"),Zpe=a("strong"),QAo=o("vilt"),WAo=o(" \u2014 "),eV=a("a"),UAo=o("BertTokenizer"),HAo=o(" or "),oV=a("a"),JAo=o("BertTokenizerFast"),YAo=o(" (ViLT model)"),ZAo=l(),El=a("li"),Kpe=a("strong"),KAo=o("visual_bert"),e6o=o(" \u2014 "),rV=a("a"),o6o=o("BertTokenizer"),r6o=o(" or "),tV=a("a"),t6o=o("BertTokenizerFast"),a6o=o(" (VisualBERT model)"),n6o=l(),sp=a("li"),e_e=a("strong"),s6o=o("wav2vec2"),l6o=o(" \u2014 "),aV=a("a"),i6o=o("Wav2Vec2CTCTokenizer"),d6o=o(" (Wav2Vec2 model)"),m6o=l(),lp=a("li"),o_e=a("strong"),c6o=o("wav2vec2-conformer"),f6o=o(" \u2014 "),nV=a("a"),g6o=o("Wav2Vec2CTCTokenizer"),h6o=o(" (Wav2Vec2-Conformer model)"),u6o=l(),ip=a("li"),r_e=a("strong"),p6o=o("wav2vec2_phoneme"),_6o=o(" \u2014 "),sV=a("a"),b6o=o("Wav2Vec2PhonemeCTCTokenizer"),v6o=o(" (Wav2Vec2Phoneme model)"),F6o=l(),dp=a("li"),t_e=a("strong"),T6o=o("whisper"),M6o=o(" \u2014 "),lV=a("a"),E6o=o("WhisperTokenizer"),C6o=o(" (Whisper model)"),w6o=l(),Cl=a("li"),a_e=a("strong"),A6o=o("xclip"),L6o=o(" \u2014 "),iV=a("a"),y6o=o("CLIPTokenizer"),x6o=o(" or "),dV=a("a"),$6o=o("CLIPTokenizerFast"),k6o=o(" (X-CLIP model)"),S6o=l(),wl=a("li"),n_e=a("strong"),R6o=o("xglm"),P6o=o(" \u2014 "),mV=a("a"),B6o=o("XGLMTokenizer"),I6o=o(" or "),cV=a("a"),N6o=o("XGLMTokenizerFast"),q6o=o(" (XGLM model)"),j6o=l(),mp=a("li"),s_e=a("strong"),D6o=o("xlm"),G6o=o(" \u2014 "),fV=a("a"),O6o=o("XLMTokenizer"),V6o=o(" (XLM model)"),X6o=l(),cp=a("li"),l_e=a("strong"),z6o=o("xlm-prophetnet"),Q6o=o(" \u2014 "),gV=a("a"),W6o=o("XLMProphetNetTokenizer"),U6o=o(" (XLM-ProphetNet model)"),H6o=l(),Al=a("li"),i_e=a("strong"),J6o=o("xlm-roberta"),Y6o=o(" \u2014 "),hV=a("a"),Z6o=o("XLMRobertaTokenizer"),K6o=o(" or "),uV=a("a"),e7o=o("XLMRobertaTokenizerFast"),o7o=o(" (XLM-RoBERTa model)"),r7o=l(),Ll=a("li"),d_e=a("strong"),t7o=o("xlm-roberta-xl"),a7o=o(" \u2014 "),pV=a("a"),n7o=o("XLMRobertaTokenizer"),s7o=o(" or "),_V=a("a"),l7o=o("XLMRobertaTokenizerFast"),i7o=o(" (XLM-RoBERTa-XL model)"),d7o=l(),yl=a("li"),m_e=a("strong"),m7o=o("xlnet"),c7o=o(" \u2014 "),bV=a("a"),f7o=o("XLNetTokenizer"),g7o=o(" or "),vV=a("a"),h7o=o("XLNetTokenizerFast"),u7o=o(" (XLNet model)"),p7o=l(),xl=a("li"),c_e=a("strong"),_7o=o("yoso"),b7o=o(" \u2014 "),FV=a("a"),v7o=o("AlbertTokenizer"),F7o=o(" or "),TV=a("a"),T7o=o("AlbertTokenizerFast"),M7o=o(" (YOSO model)"),E7o=l(),F(fp.$$.fragment),C7o=l(),gp=a("div"),F(L$.$$.fragment),w7o=l(),f_e=a("p"),A7o=o("Register a new tokenizer in this mapping."),oao=l(),$d=a("h2"),hp=a("a"),g_e=a("span"),F(y$.$$.fragment),L7o=l(),h_e=a("span"),y7o=o("AutoFeatureExtractor"),rao=l(),Po=a("div"),F(x$.$$.fragment),x7o=l(),$$=a("p"),$7o=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),MV=a("a"),k7o=o("AutoFeatureExtractor.from_pretrained()"),S7o=o(" class method."),R7o=l(),k$=a("p"),P7o=o("This class cannot be instantiated directly using "),u_e=a("code"),B7o=o("__init__()"),I7o=o(" (throws an error)."),N7o=l(),Ye=a("div"),F(S$.$$.fragment),q7o=l(),p_e=a("p"),j7o=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),D7o=l(),an=a("p"),G7o=o("The feature extractor class to instantiate is selected based on the "),__e=a("code"),O7o=o("model_type"),V7o=o(` property of the config object
(either passed as an argument or loaded from `),b_e=a("code"),X7o=o("pretrained_model_name_or_path"),z7o=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),v_e=a("code"),Q7o=o("pretrained_model_name_or_path"),W7o=o(":"),U7o=l(),z=a("ul"),up=a("li"),F_e=a("strong"),H7o=o("beit"),J7o=o(" \u2014 "),EV=a("a"),Y7o=o("BeitFeatureExtractor"),Z7o=o(" (BEiT model)"),K7o=l(),pp=a("li"),T_e=a("strong"),e8o=o("clip"),o8o=o(" \u2014 "),CV=a("a"),r8o=o("CLIPFeatureExtractor"),t8o=o(" (CLIP model)"),a8o=l(),_p=a("li"),M_e=a("strong"),n8o=o("clipseg"),s8o=o(" \u2014 "),wV=a("a"),l8o=o("ViTFeatureExtractor"),i8o=o(" (CLIPSeg model)"),d8o=l(),bp=a("li"),E_e=a("strong"),m8o=o("conditional_detr"),c8o=o(" \u2014 "),AV=a("a"),f8o=o("ConditionalDetrFeatureExtractor"),g8o=o(" (Conditional DETR model)"),h8o=l(),vp=a("li"),C_e=a("strong"),u8o=o("convnext"),p8o=o(" \u2014 "),LV=a("a"),_8o=o("ConvNextFeatureExtractor"),b8o=o(" (ConvNeXT model)"),v8o=l(),Fp=a("li"),w_e=a("strong"),F8o=o("cvt"),T8o=o(" \u2014 "),yV=a("a"),M8o=o("ConvNextFeatureExtractor"),E8o=o(" (CvT model)"),C8o=l(),Tp=a("li"),A_e=a("strong"),w8o=o("data2vec-audio"),A8o=o(" \u2014 "),xV=a("a"),L8o=o("Wav2Vec2FeatureExtractor"),y8o=o(" (Data2VecAudio model)"),x8o=l(),Mp=a("li"),L_e=a("strong"),$8o=o("data2vec-vision"),k8o=o(" \u2014 "),$V=a("a"),S8o=o("BeitFeatureExtractor"),R8o=o(" (Data2VecVision model)"),P8o=l(),Ep=a("li"),y_e=a("strong"),B8o=o("deformable_detr"),I8o=o(" \u2014 "),kV=a("a"),N8o=o("DeformableDetrFeatureExtractor"),q8o=o(" (Deformable DETR model)"),j8o=l(),Cp=a("li"),x_e=a("strong"),D8o=o("deit"),G8o=o(" \u2014 "),SV=a("a"),O8o=o("DeiTFeatureExtractor"),V8o=o(" (DeiT model)"),X8o=l(),wp=a("li"),$_e=a("strong"),z8o=o("detr"),Q8o=o(" \u2014 "),RV=a("a"),W8o=o("DetrFeatureExtractor"),U8o=o(" (DETR model)"),H8o=l(),Ap=a("li"),k_e=a("strong"),J8o=o("donut-swin"),Y8o=o(" \u2014 "),PV=a("a"),Z8o=o("DonutFeatureExtractor"),K8o=o(" (DonutSwin model)"),eLo=l(),Lp=a("li"),S_e=a("strong"),oLo=o("dpt"),rLo=o(" \u2014 "),BV=a("a"),tLo=o("DPTFeatureExtractor"),aLo=o(" (DPT model)"),nLo=l(),yp=a("li"),R_e=a("strong"),sLo=o("flava"),lLo=o(" \u2014 "),IV=a("a"),iLo=o("FlavaFeatureExtractor"),dLo=o(" (FLAVA model)"),mLo=l(),xp=a("li"),P_e=a("strong"),cLo=o("glpn"),fLo=o(" \u2014 "),NV=a("a"),gLo=o("GLPNFeatureExtractor"),hLo=o(" (GLPN model)"),uLo=l(),$p=a("li"),B_e=a("strong"),pLo=o("groupvit"),_Lo=o(" \u2014 "),qV=a("a"),bLo=o("CLIPFeatureExtractor"),vLo=o(" (GroupViT model)"),FLo=l(),kp=a("li"),I_e=a("strong"),TLo=o("hubert"),MLo=o(" \u2014 "),jV=a("a"),ELo=o("Wav2Vec2FeatureExtractor"),CLo=o(" (Hubert model)"),wLo=l(),Sp=a("li"),N_e=a("strong"),ALo=o("imagegpt"),LLo=o(" \u2014 "),DV=a("a"),yLo=o("ImageGPTFeatureExtractor"),xLo=o(" (ImageGPT model)"),$Lo=l(),Rp=a("li"),q_e=a("strong"),kLo=o("layoutlmv2"),SLo=o(" \u2014 "),GV=a("a"),RLo=o("LayoutLMv2FeatureExtractor"),PLo=o(" (LayoutLMv2 model)"),BLo=l(),Pp=a("li"),j_e=a("strong"),ILo=o("layoutlmv3"),NLo=o(" \u2014 "),OV=a("a"),qLo=o("LayoutLMv3FeatureExtractor"),jLo=o(" (LayoutLMv3 model)"),DLo=l(),Bp=a("li"),D_e=a("strong"),GLo=o("levit"),OLo=o(" \u2014 "),VV=a("a"),VLo=o("LevitFeatureExtractor"),XLo=o(" (LeViT model)"),zLo=l(),Ip=a("li"),G_e=a("strong"),QLo=o("maskformer"),WLo=o(" \u2014 "),XV=a("a"),ULo=o("MaskFormerFeatureExtractor"),HLo=o(" (MaskFormer model)"),JLo=l(),Np=a("li"),O_e=a("strong"),YLo=o("mctct"),ZLo=o(" \u2014 "),zV=a("a"),KLo=o("MCTCTFeatureExtractor"),eyo=o(" (M-CTC-T model)"),oyo=l(),qp=a("li"),V_e=a("strong"),ryo=o("mobilevit"),tyo=o(" \u2014 "),QV=a("a"),ayo=o("MobileViTFeatureExtractor"),nyo=o(" (MobileViT model)"),syo=l(),jp=a("li"),X_e=a("strong"),lyo=o("owlvit"),iyo=o(" \u2014 "),WV=a("a"),dyo=o("OwlViTFeatureExtractor"),myo=o(" (OWL-ViT model)"),cyo=l(),Dp=a("li"),z_e=a("strong"),fyo=o("perceiver"),gyo=o(" \u2014 "),UV=a("a"),hyo=o("PerceiverFeatureExtractor"),uyo=o(" (Perceiver model)"),pyo=l(),Gp=a("li"),Q_e=a("strong"),_yo=o("poolformer"),byo=o(" \u2014 "),HV=a("a"),vyo=o("PoolFormerFeatureExtractor"),Fyo=o(" (PoolFormer model)"),Tyo=l(),Op=a("li"),W_e=a("strong"),Myo=o("regnet"),Eyo=o(" \u2014 "),JV=a("a"),Cyo=o("ConvNextFeatureExtractor"),wyo=o(" (RegNet model)"),Ayo=l(),Vp=a("li"),U_e=a("strong"),Lyo=o("resnet"),yyo=o(" \u2014 "),YV=a("a"),xyo=o("ConvNextFeatureExtractor"),$yo=o(" (ResNet model)"),kyo=l(),Xp=a("li"),H_e=a("strong"),Syo=o("segformer"),Ryo=o(" \u2014 "),ZV=a("a"),Pyo=o("SegformerFeatureExtractor"),Byo=o(" (SegFormer model)"),Iyo=l(),zp=a("li"),J_e=a("strong"),Nyo=o("speech_to_text"),qyo=o(" \u2014 "),KV=a("a"),jyo=o("Speech2TextFeatureExtractor"),Dyo=o(" (Speech2Text model)"),Gyo=l(),Qp=a("li"),Y_e=a("strong"),Oyo=o("swin"),Vyo=o(" \u2014 "),eX=a("a"),Xyo=o("ViTFeatureExtractor"),zyo=o(" (Swin Transformer model)"),Qyo=l(),Wp=a("li"),Z_e=a("strong"),Wyo=o("swinv2"),Uyo=o(" \u2014 "),oX=a("a"),Hyo=o("ViTFeatureExtractor"),Jyo=o(" (Swin Transformer V2 model)"),Yyo=l(),Up=a("li"),K_e=a("strong"),Zyo=o("table-transformer"),Kyo=o(" \u2014 "),rX=a("a"),e9o=o("DetrFeatureExtractor"),o9o=o(" (Table Transformer model)"),r9o=l(),Hp=a("li"),e1e=a("strong"),t9o=o("van"),a9o=o(" \u2014 "),tX=a("a"),n9o=o("ConvNextFeatureExtractor"),s9o=o(" (VAN model)"),l9o=l(),Jp=a("li"),o1e=a("strong"),i9o=o("videomae"),d9o=o(" \u2014 "),aX=a("a"),m9o=o("VideoMAEFeatureExtractor"),c9o=o(" (VideoMAE model)"),f9o=l(),Yp=a("li"),r1e=a("strong"),g9o=o("vilt"),h9o=o(" \u2014 "),nX=a("a"),u9o=o("ViltFeatureExtractor"),p9o=o(" (ViLT model)"),_9o=l(),Zp=a("li"),t1e=a("strong"),b9o=o("vit"),v9o=o(" \u2014 "),sX=a("a"),F9o=o("ViTFeatureExtractor"),T9o=o(" (ViT model)"),M9o=l(),Kp=a("li"),a1e=a("strong"),E9o=o("vit_mae"),C9o=o(" \u2014 "),lX=a("a"),w9o=o("ViTFeatureExtractor"),A9o=o(" (ViTMAE model)"),L9o=l(),e_=a("li"),n1e=a("strong"),y9o=o("vit_msn"),x9o=o(" \u2014 "),iX=a("a"),$9o=o("ViTFeatureExtractor"),k9o=o(" (ViTMSN model)"),S9o=l(),o_=a("li"),s1e=a("strong"),R9o=o("wav2vec2"),P9o=o(" \u2014 "),dX=a("a"),B9o=o("Wav2Vec2FeatureExtractor"),I9o=o(" (Wav2Vec2 model)"),N9o=l(),r_=a("li"),l1e=a("strong"),q9o=o("wav2vec2-conformer"),j9o=o(" \u2014 "),mX=a("a"),D9o=o("Wav2Vec2FeatureExtractor"),G9o=o(" (Wav2Vec2-Conformer model)"),O9o=l(),t_=a("li"),i1e=a("strong"),V9o=o("whisper"),X9o=o(" \u2014 "),cX=a("a"),z9o=o("WhisperFeatureExtractor"),Q9o=o(" (Whisper model)"),W9o=l(),a_=a("li"),d1e=a("strong"),U9o=o("xclip"),H9o=o(" \u2014 "),fX=a("a"),J9o=o("CLIPFeatureExtractor"),Y9o=o(" (X-CLIP model)"),Z9o=l(),n_=a("li"),m1e=a("strong"),K9o=o("yolos"),exo=o(" \u2014 "),gX=a("a"),oxo=o("YolosFeatureExtractor"),rxo=o(" (YOLOS model)"),txo=l(),F(s_.$$.fragment),axo=l(),F(l_.$$.fragment),nxo=l(),i_=a("div"),F(R$.$$.fragment),sxo=l(),c1e=a("p"),lxo=o("Register a new feature extractor for this class."),tao=l(),kd=a("h2"),d_=a("a"),f1e=a("span"),F(P$.$$.fragment),ixo=l(),g1e=a("span"),dxo=o("AutoProcessor"),aao=l(),Bo=a("div"),F(B$.$$.fragment),mxo=l(),I$=a("p"),cxo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),hX=a("a"),fxo=o("AutoProcessor.from_pretrained()"),gxo=o(" class method."),hxo=l(),N$=a("p"),uxo=o("This class cannot be instantiated directly using "),h1e=a("code"),pxo=o("__init__()"),_xo=o(" (throws an error)."),bxo=l(),Ze=a("div"),F(q$.$$.fragment),vxo=l(),u1e=a("p"),Fxo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),Txo=l(),Sd=a("p"),Mxo=o("The processor class to instantiate is selected based on the "),p1e=a("code"),Exo=o("model_type"),Cxo=o(` property of the config object (either
passed as an argument or loaded from `),_1e=a("code"),wxo=o("pretrained_model_name_or_path"),Axo=o(" if possible):"),Lxo=l(),se=a("ul"),m_=a("li"),b1e=a("strong"),yxo=o("clip"),xxo=o(" \u2014 "),uX=a("a"),$xo=o("CLIPProcessor"),kxo=o(" (CLIP model)"),Sxo=l(),c_=a("li"),v1e=a("strong"),Rxo=o("clipseg"),Pxo=o(" \u2014 "),pX=a("a"),Bxo=o("CLIPSegProcessor"),Ixo=o(" (CLIPSeg model)"),Nxo=l(),f_=a("li"),F1e=a("strong"),qxo=o("flava"),jxo=o(" \u2014 "),_X=a("a"),Dxo=o("FlavaProcessor"),Gxo=o(" (FLAVA model)"),Oxo=l(),g_=a("li"),T1e=a("strong"),Vxo=o("groupvit"),Xxo=o(" \u2014 "),bX=a("a"),zxo=o("CLIPProcessor"),Qxo=o(" (GroupViT model)"),Wxo=l(),h_=a("li"),M1e=a("strong"),Uxo=o("layoutlmv2"),Hxo=o(" \u2014 "),vX=a("a"),Jxo=o("LayoutLMv2Processor"),Yxo=o(" (LayoutLMv2 model)"),Zxo=l(),u_=a("li"),E1e=a("strong"),Kxo=o("layoutlmv3"),e$o=o(" \u2014 "),FX=a("a"),o$o=o("LayoutLMv3Processor"),r$o=o(" (LayoutLMv3 model)"),t$o=l(),p_=a("li"),C1e=a("strong"),a$o=o("layoutxlm"),n$o=o(" \u2014 "),TX=a("a"),s$o=o("LayoutXLMProcessor"),l$o=o(" (LayoutXLM model)"),i$o=l(),__=a("li"),w1e=a("strong"),d$o=o("markuplm"),m$o=o(" \u2014 "),MX=a("a"),c$o=o("MarkupLMProcessor"),f$o=o(" (MarkupLM model)"),g$o=l(),b_=a("li"),A1e=a("strong"),h$o=o("owlvit"),u$o=o(" \u2014 "),EX=a("a"),p$o=o("OwlViTProcessor"),_$o=o(" (OWL-ViT model)"),b$o=l(),v_=a("li"),L1e=a("strong"),v$o=o("sew"),F$o=o(" \u2014 "),CX=a("a"),T$o=o("Wav2Vec2Processor"),M$o=o(" (SEW model)"),E$o=l(),F_=a("li"),y1e=a("strong"),C$o=o("sew-d"),w$o=o(" \u2014 "),wX=a("a"),A$o=o("Wav2Vec2Processor"),L$o=o(" (SEW-D model)"),y$o=l(),T_=a("li"),x1e=a("strong"),x$o=o("speech_to_text"),$$o=o(" \u2014 "),AX=a("a"),k$o=o("Speech2TextProcessor"),S$o=o(" (Speech2Text model)"),R$o=l(),M_=a("li"),$1e=a("strong"),P$o=o("speech_to_text_2"),B$o=o(" \u2014 "),LX=a("a"),I$o=o("Speech2Text2Processor"),N$o=o(" (Speech2Text2 model)"),q$o=l(),E_=a("li"),k1e=a("strong"),j$o=o("trocr"),D$o=o(" \u2014 "),yX=a("a"),G$o=o("TrOCRProcessor"),O$o=o(" (TrOCR model)"),V$o=l(),C_=a("li"),S1e=a("strong"),X$o=o("unispeech"),z$o=o(" \u2014 "),xX=a("a"),Q$o=o("Wav2Vec2Processor"),W$o=o(" (UniSpeech model)"),U$o=l(),w_=a("li"),R1e=a("strong"),H$o=o("unispeech-sat"),J$o=o(" \u2014 "),$X=a("a"),Y$o=o("Wav2Vec2Processor"),Z$o=o(" (UniSpeechSat model)"),K$o=l(),A_=a("li"),P1e=a("strong"),eko=o("vilt"),oko=o(" \u2014 "),kX=a("a"),rko=o("ViltProcessor"),tko=o(" (ViLT model)"),ako=l(),L_=a("li"),B1e=a("strong"),nko=o("vision-text-dual-encoder"),sko=o(" \u2014 "),SX=a("a"),lko=o("VisionTextDualEncoderProcessor"),iko=o(" (VisionTextDualEncoder model)"),dko=l(),y_=a("li"),I1e=a("strong"),mko=o("wav2vec2"),cko=o(" \u2014 "),RX=a("a"),fko=o("Wav2Vec2Processor"),gko=o(" (Wav2Vec2 model)"),hko=l(),x_=a("li"),N1e=a("strong"),uko=o("wav2vec2-conformer"),pko=o(" \u2014 "),PX=a("a"),_ko=o("Wav2Vec2Processor"),bko=o(" (Wav2Vec2-Conformer model)"),vko=l(),$_=a("li"),q1e=a("strong"),Fko=o("wavlm"),Tko=o(" \u2014 "),BX=a("a"),Mko=o("Wav2Vec2Processor"),Eko=o(" (WavLM model)"),Cko=l(),k_=a("li"),j1e=a("strong"),wko=o("whisper"),Ako=o(" \u2014 "),IX=a("a"),Lko=o("WhisperProcessor"),yko=o(" (Whisper model)"),xko=l(),S_=a("li"),D1e=a("strong"),$ko=o("xclip"),kko=o(" \u2014 "),NX=a("a"),Sko=o("XCLIPProcessor"),Rko=o(" (X-CLIP model)"),Pko=l(),F(R_.$$.fragment),Bko=l(),F(P_.$$.fragment),Iko=l(),B_=a("div"),F(j$.$$.fragment),Nko=l(),G1e=a("p"),qko=o("Register a new processor for this class."),nao=l(),Rd=a("h2"),I_=a("a"),O1e=a("span"),F(D$.$$.fragment),jko=l(),V1e=a("span"),Dko=o("AutoModel"),sao=l(),Io=a("div"),F(G$.$$.fragment),Gko=l(),Pd=a("p"),Oko=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),qX=a("a"),Vko=o("from_pretrained()"),Xko=o(" class method or the "),jX=a("a"),zko=o("from_config()"),Qko=o(` class
method.`),Wko=l(),O$=a("p"),Uko=o("This class cannot be instantiated directly using "),X1e=a("code"),Hko=o("__init__()"),Jko=o(" (throws an error)."),Yko=l(),Mt=a("div"),F(V$.$$.fragment),Zko=l(),z1e=a("p"),Kko=o("Instantiates one of the base model classes of the library from a configuration."),eSo=l(),Bd=a("p"),oSo=o(`Note:
Loading a model from its configuration file does `),Q1e=a("strong"),rSo=o("not"),tSo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DX=a("a"),aSo=o("from_pretrained()"),nSo=o(" to load the model weights."),sSo=l(),F(N_.$$.fragment),lSo=l(),Ke=a("div"),F(X$.$$.fragment),iSo=l(),W1e=a("p"),dSo=o("Instantiate one of the base model classes of the library from a pretrained model."),mSo=l(),nn=a("p"),cSo=o("The model class to instantiate is selected based on the "),U1e=a("code"),fSo=o("model_type"),gSo=o(` property of the config object (either
passed as an argument or loaded from `),H1e=a("code"),hSo=o("pretrained_model_name_or_path"),uSo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J1e=a("code"),pSo=o("pretrained_model_name_or_path"),_So=o(":"),bSo=l(),y=a("ul"),q_=a("li"),Y1e=a("strong"),vSo=o("albert"),FSo=o(" \u2014 "),GX=a("a"),TSo=o("AlbertModel"),MSo=o(" (ALBERT model)"),ESo=l(),j_=a("li"),Z1e=a("strong"),CSo=o("bart"),wSo=o(" \u2014 "),OX=a("a"),ASo=o("BartModel"),LSo=o(" (BART model)"),ySo=l(),D_=a("li"),K1e=a("strong"),xSo=o("beit"),$So=o(" \u2014 "),VX=a("a"),kSo=o("BeitModel"),SSo=o(" (BEiT model)"),RSo=l(),G_=a("li"),e2e=a("strong"),PSo=o("bert"),BSo=o(" \u2014 "),XX=a("a"),ISo=o("BertModel"),NSo=o(" (BERT model)"),qSo=l(),O_=a("li"),o2e=a("strong"),jSo=o("bert-generation"),DSo=o(" \u2014 "),zX=a("a"),GSo=o("BertGenerationEncoder"),OSo=o(" (Bert Generation model)"),VSo=l(),V_=a("li"),r2e=a("strong"),XSo=o("big_bird"),zSo=o(" \u2014 "),QX=a("a"),QSo=o("BigBirdModel"),WSo=o(" (BigBird model)"),USo=l(),X_=a("li"),t2e=a("strong"),HSo=o("bigbird_pegasus"),JSo=o(" \u2014 "),WX=a("a"),YSo=o("BigBirdPegasusModel"),ZSo=o(" (BigBird-Pegasus model)"),KSo=l(),z_=a("li"),a2e=a("strong"),eRo=o("blenderbot"),oRo=o(" \u2014 "),UX=a("a"),rRo=o("BlenderbotModel"),tRo=o(" (Blenderbot model)"),aRo=l(),Q_=a("li"),n2e=a("strong"),nRo=o("blenderbot-small"),sRo=o(" \u2014 "),HX=a("a"),lRo=o("BlenderbotSmallModel"),iRo=o(" (BlenderbotSmall model)"),dRo=l(),W_=a("li"),s2e=a("strong"),mRo=o("bloom"),cRo=o(" \u2014 "),JX=a("a"),fRo=o("BloomModel"),gRo=o(" (BLOOM model)"),hRo=l(),U_=a("li"),l2e=a("strong"),uRo=o("camembert"),pRo=o(" \u2014 "),YX=a("a"),_Ro=o("CamembertModel"),bRo=o(" (CamemBERT model)"),vRo=l(),H_=a("li"),i2e=a("strong"),FRo=o("canine"),TRo=o(" \u2014 "),ZX=a("a"),MRo=o("CanineModel"),ERo=o(" (CANINE model)"),CRo=l(),J_=a("li"),d2e=a("strong"),wRo=o("clip"),ARo=o(" \u2014 "),KX=a("a"),LRo=o("CLIPModel"),yRo=o(" (CLIP model)"),xRo=l(),Y_=a("li"),m2e=a("strong"),$Ro=o("clipseg"),kRo=o(" \u2014 "),ez=a("a"),SRo=o("CLIPSegModel"),RRo=o(" (CLIPSeg model)"),PRo=l(),Z_=a("li"),c2e=a("strong"),BRo=o("codegen"),IRo=o(" \u2014 "),oz=a("a"),NRo=o("CodeGenModel"),qRo=o(" (CodeGen model)"),jRo=l(),K_=a("li"),f2e=a("strong"),DRo=o("conditional_detr"),GRo=o(" \u2014 "),rz=a("a"),ORo=o("ConditionalDetrModel"),VRo=o(" (Conditional DETR model)"),XRo=l(),e1=a("li"),g2e=a("strong"),zRo=o("convbert"),QRo=o(" \u2014 "),tz=a("a"),WRo=o("ConvBertModel"),URo=o(" (ConvBERT model)"),HRo=l(),o1=a("li"),h2e=a("strong"),JRo=o("convnext"),YRo=o(" \u2014 "),az=a("a"),ZRo=o("ConvNextModel"),KRo=o(" (ConvNeXT model)"),ePo=l(),r1=a("li"),u2e=a("strong"),oPo=o("ctrl"),rPo=o(" \u2014 "),nz=a("a"),tPo=o("CTRLModel"),aPo=o(" (CTRL model)"),nPo=l(),t1=a("li"),p2e=a("strong"),sPo=o("cvt"),lPo=o(" \u2014 "),sz=a("a"),iPo=o("CvtModel"),dPo=o(" (CvT model)"),mPo=l(),a1=a("li"),_2e=a("strong"),cPo=o("data2vec-audio"),fPo=o(" \u2014 "),lz=a("a"),gPo=o("Data2VecAudioModel"),hPo=o(" (Data2VecAudio model)"),uPo=l(),n1=a("li"),b2e=a("strong"),pPo=o("data2vec-text"),_Po=o(" \u2014 "),iz=a("a"),bPo=o("Data2VecTextModel"),vPo=o(" (Data2VecText model)"),FPo=l(),s1=a("li"),v2e=a("strong"),TPo=o("data2vec-vision"),MPo=o(" \u2014 "),dz=a("a"),EPo=o("Data2VecVisionModel"),CPo=o(" (Data2VecVision model)"),wPo=l(),l1=a("li"),F2e=a("strong"),APo=o("deberta"),LPo=o(" \u2014 "),mz=a("a"),yPo=o("DebertaModel"),xPo=o(" (DeBERTa model)"),$Po=l(),i1=a("li"),T2e=a("strong"),kPo=o("deberta-v2"),SPo=o(" \u2014 "),cz=a("a"),RPo=o("DebertaV2Model"),PPo=o(" (DeBERTa-v2 model)"),BPo=l(),d1=a("li"),M2e=a("strong"),IPo=o("decision_transformer"),NPo=o(" \u2014 "),fz=a("a"),qPo=o("DecisionTransformerModel"),jPo=o(" (Decision Transformer model)"),DPo=l(),m1=a("li"),E2e=a("strong"),GPo=o("deformable_detr"),OPo=o(" \u2014 "),gz=a("a"),VPo=o("DeformableDetrModel"),XPo=o(" (Deformable DETR model)"),zPo=l(),c1=a("li"),C2e=a("strong"),QPo=o("deit"),WPo=o(" \u2014 "),hz=a("a"),UPo=o("DeiTModel"),HPo=o(" (DeiT model)"),JPo=l(),f1=a("li"),w2e=a("strong"),YPo=o("detr"),ZPo=o(" \u2014 "),uz=a("a"),KPo=o("DetrModel"),eBo=o(" (DETR model)"),oBo=l(),g1=a("li"),A2e=a("strong"),rBo=o("distilbert"),tBo=o(" \u2014 "),pz=a("a"),aBo=o("DistilBertModel"),nBo=o(" (DistilBERT model)"),sBo=l(),h1=a("li"),L2e=a("strong"),lBo=o("donut-swin"),iBo=o(" \u2014 "),_z=a("a"),dBo=o("DonutSwinModel"),mBo=o(" (DonutSwin model)"),cBo=l(),u1=a("li"),y2e=a("strong"),fBo=o("dpr"),gBo=o(" \u2014 "),bz=a("a"),hBo=o("DPRQuestionEncoder"),uBo=o(" (DPR model)"),pBo=l(),p1=a("li"),x2e=a("strong"),_Bo=o("dpt"),bBo=o(" \u2014 "),vz=a("a"),vBo=o("DPTModel"),FBo=o(" (DPT model)"),TBo=l(),_1=a("li"),$2e=a("strong"),MBo=o("electra"),EBo=o(" \u2014 "),Fz=a("a"),CBo=o("ElectraModel"),wBo=o(" (ELECTRA model)"),ABo=l(),b1=a("li"),k2e=a("strong"),LBo=o("ernie"),yBo=o(" \u2014 "),Tz=a("a"),xBo=o("ErnieModel"),$Bo=o(" (ERNIE model)"),kBo=l(),v1=a("li"),S2e=a("strong"),SBo=o("esm"),RBo=o(" \u2014 "),Mz=a("a"),PBo=o("EsmModel"),BBo=o(" (ESM model)"),IBo=l(),F1=a("li"),R2e=a("strong"),NBo=o("flaubert"),qBo=o(" \u2014 "),Ez=a("a"),jBo=o("FlaubertModel"),DBo=o(" (FlauBERT model)"),GBo=l(),T1=a("li"),P2e=a("strong"),OBo=o("flava"),VBo=o(" \u2014 "),Cz=a("a"),XBo=o("FlavaModel"),zBo=o(" (FLAVA model)"),QBo=l(),M1=a("li"),B2e=a("strong"),WBo=o("fnet"),UBo=o(" \u2014 "),wz=a("a"),HBo=o("FNetModel"),JBo=o(" (FNet model)"),YBo=l(),E1=a("li"),I2e=a("strong"),ZBo=o("fsmt"),KBo=o(" \u2014 "),Az=a("a"),eIo=o("FSMTModel"),oIo=o(" (FairSeq Machine-Translation model)"),rIo=l(),$l=a("li"),N2e=a("strong"),tIo=o("funnel"),aIo=o(" \u2014 "),Lz=a("a"),nIo=o("FunnelModel"),sIo=o(" or "),yz=a("a"),lIo=o("FunnelBaseModel"),iIo=o(" (Funnel Transformer model)"),dIo=l(),C1=a("li"),q2e=a("strong"),mIo=o("glpn"),cIo=o(" \u2014 "),xz=a("a"),fIo=o("GLPNModel"),gIo=o(" (GLPN model)"),hIo=l(),w1=a("li"),j2e=a("strong"),uIo=o("gpt2"),pIo=o(" \u2014 "),$z=a("a"),_Io=o("GPT2Model"),bIo=o(" (OpenAI GPT-2 model)"),vIo=l(),A1=a("li"),D2e=a("strong"),FIo=o("gpt_neo"),TIo=o(" \u2014 "),kz=a("a"),MIo=o("GPTNeoModel"),EIo=o(" (GPT Neo model)"),CIo=l(),L1=a("li"),G2e=a("strong"),wIo=o("gpt_neox"),AIo=o(" \u2014 "),Sz=a("a"),LIo=o("GPTNeoXModel"),yIo=o(" (GPT NeoX model)"),xIo=l(),y1=a("li"),O2e=a("strong"),$Io=o("gpt_neox_japanese"),kIo=o(" \u2014 "),Rz=a("a"),SIo=o("GPTNeoXJapaneseModel"),RIo=o(" (GPT NeoX Japanese model)"),PIo=l(),x1=a("li"),V2e=a("strong"),BIo=o("gptj"),IIo=o(" \u2014 "),Pz=a("a"),NIo=o("GPTJModel"),qIo=o(" (GPT-J model)"),jIo=l(),$1=a("li"),X2e=a("strong"),DIo=o("groupvit"),GIo=o(" \u2014 "),Bz=a("a"),OIo=o("GroupViTModel"),VIo=o(" (GroupViT model)"),XIo=l(),k1=a("li"),z2e=a("strong"),zIo=o("hubert"),QIo=o(" \u2014 "),Iz=a("a"),WIo=o("HubertModel"),UIo=o(" (Hubert model)"),HIo=l(),S1=a("li"),Q2e=a("strong"),JIo=o("ibert"),YIo=o(" \u2014 "),Nz=a("a"),ZIo=o("IBertModel"),KIo=o(" (I-BERT model)"),eNo=l(),R1=a("li"),W2e=a("strong"),oNo=o("imagegpt"),rNo=o(" \u2014 "),qz=a("a"),tNo=o("ImageGPTModel"),aNo=o(" (ImageGPT model)"),nNo=l(),P1=a("li"),U2e=a("strong"),sNo=o("layoutlm"),lNo=o(" \u2014 "),jz=a("a"),iNo=o("LayoutLMModel"),dNo=o(" (LayoutLM model)"),mNo=l(),B1=a("li"),H2e=a("strong"),cNo=o("layoutlmv2"),fNo=o(" \u2014 "),Dz=a("a"),gNo=o("LayoutLMv2Model"),hNo=o(" (LayoutLMv2 model)"),uNo=l(),I1=a("li"),J2e=a("strong"),pNo=o("layoutlmv3"),_No=o(" \u2014 "),Gz=a("a"),bNo=o("LayoutLMv3Model"),vNo=o(" (LayoutLMv3 model)"),FNo=l(),N1=a("li"),Y2e=a("strong"),TNo=o("led"),MNo=o(" \u2014 "),Oz=a("a"),ENo=o("LEDModel"),CNo=o(" (LED model)"),wNo=l(),q1=a("li"),Z2e=a("strong"),ANo=o("levit"),LNo=o(" \u2014 "),Vz=a("a"),yNo=o("LevitModel"),xNo=o(" (LeViT model)"),$No=l(),j1=a("li"),K2e=a("strong"),kNo=o("lilt"),SNo=o(" \u2014 "),Xz=a("a"),RNo=o("LiltModel"),PNo=o(" (LiLT model)"),BNo=l(),D1=a("li"),ebe=a("strong"),INo=o("longformer"),NNo=o(" \u2014 "),zz=a("a"),qNo=o("LongformerModel"),jNo=o(" (Longformer model)"),DNo=l(),G1=a("li"),obe=a("strong"),GNo=o("longt5"),ONo=o(" \u2014 "),Qz=a("a"),VNo=o("LongT5Model"),XNo=o(" (LongT5 model)"),zNo=l(),O1=a("li"),rbe=a("strong"),QNo=o("luke"),WNo=o(" \u2014 "),Wz=a("a"),UNo=o("LukeModel"),HNo=o(" (LUKE model)"),JNo=l(),V1=a("li"),tbe=a("strong"),YNo=o("lxmert"),ZNo=o(" \u2014 "),Uz=a("a"),KNo=o("LxmertModel"),eqo=o(" (LXMERT model)"),oqo=l(),X1=a("li"),abe=a("strong"),rqo=o("m2m_100"),tqo=o(" \u2014 "),Hz=a("a"),aqo=o("M2M100Model"),nqo=o(" (M2M100 model)"),sqo=l(),z1=a("li"),nbe=a("strong"),lqo=o("marian"),iqo=o(" \u2014 "),Jz=a("a"),dqo=o("MarianModel"),mqo=o(" (Marian model)"),cqo=l(),Q1=a("li"),sbe=a("strong"),fqo=o("markuplm"),gqo=o(" \u2014 "),Yz=a("a"),hqo=o("MarkupLMModel"),uqo=o(" (MarkupLM model)"),pqo=l(),W1=a("li"),lbe=a("strong"),_qo=o("maskformer"),bqo=o(" \u2014 "),Zz=a("a"),vqo=o("MaskFormerModel"),Fqo=o(" (MaskFormer model)"),Tqo=l(),U1=a("li"),ibe=a("strong"),Mqo=o("mbart"),Eqo=o(" \u2014 "),Kz=a("a"),Cqo=o("MBartModel"),wqo=o(" (mBART model)"),Aqo=l(),H1=a("li"),dbe=a("strong"),Lqo=o("mctct"),yqo=o(" \u2014 "),eQ=a("a"),xqo=o("MCTCTModel"),$qo=o(" (M-CTC-T model)"),kqo=l(),J1=a("li"),mbe=a("strong"),Sqo=o("megatron-bert"),Rqo=o(" \u2014 "),oQ=a("a"),Pqo=o("MegatronBertModel"),Bqo=o(" (Megatron-BERT model)"),Iqo=l(),Y1=a("li"),cbe=a("strong"),Nqo=o("mobilebert"),qqo=o(" \u2014 "),rQ=a("a"),jqo=o("MobileBertModel"),Dqo=o(" (MobileBERT model)"),Gqo=l(),Z1=a("li"),fbe=a("strong"),Oqo=o("mobilevit"),Vqo=o(" \u2014 "),tQ=a("a"),Xqo=o("MobileViTModel"),zqo=o(" (MobileViT model)"),Qqo=l(),K1=a("li"),gbe=a("strong"),Wqo=o("mpnet"),Uqo=o(" \u2014 "),aQ=a("a"),Hqo=o("MPNetModel"),Jqo=o(" (MPNet model)"),Yqo=l(),e2=a("li"),hbe=a("strong"),Zqo=o("mt5"),Kqo=o(" \u2014 "),nQ=a("a"),ejo=o("MT5Model"),ojo=o(" (MT5 model)"),rjo=l(),o2=a("li"),ube=a("strong"),tjo=o("mvp"),ajo=o(" \u2014 "),sQ=a("a"),njo=o("MvpModel"),sjo=o(" (MVP model)"),ljo=l(),r2=a("li"),pbe=a("strong"),ijo=o("nezha"),djo=o(" \u2014 "),lQ=a("a"),mjo=o("NezhaModel"),cjo=o(" (Nezha model)"),fjo=l(),t2=a("li"),_be=a("strong"),gjo=o("nllb"),hjo=o(" \u2014 "),iQ=a("a"),ujo=o("M2M100Model"),pjo=o(" (NLLB model)"),_jo=l(),a2=a("li"),bbe=a("strong"),bjo=o("nystromformer"),vjo=o(" \u2014 "),dQ=a("a"),Fjo=o("NystromformerModel"),Tjo=o(" (Nystr\xF6mformer model)"),Mjo=l(),n2=a("li"),vbe=a("strong"),Ejo=o("openai-gpt"),Cjo=o(" \u2014 "),mQ=a("a"),wjo=o("OpenAIGPTModel"),Ajo=o(" (OpenAI GPT model)"),Ljo=l(),s2=a("li"),Fbe=a("strong"),yjo=o("opt"),xjo=o(" \u2014 "),cQ=a("a"),$jo=o("OPTModel"),kjo=o(" (OPT model)"),Sjo=l(),l2=a("li"),Tbe=a("strong"),Rjo=o("owlvit"),Pjo=o(" \u2014 "),fQ=a("a"),Bjo=o("OwlViTModel"),Ijo=o(" (OWL-ViT model)"),Njo=l(),i2=a("li"),Mbe=a("strong"),qjo=o("pegasus"),jjo=o(" \u2014 "),gQ=a("a"),Djo=o("PegasusModel"),Gjo=o(" (Pegasus model)"),Ojo=l(),d2=a("li"),Ebe=a("strong"),Vjo=o("pegasus_x"),Xjo=o(" \u2014 "),hQ=a("a"),zjo=o("PegasusXModel"),Qjo=o(" (PEGASUS-X model)"),Wjo=l(),m2=a("li"),Cbe=a("strong"),Ujo=o("perceiver"),Hjo=o(" \u2014 "),uQ=a("a"),Jjo=o("PerceiverModel"),Yjo=o(" (Perceiver model)"),Zjo=l(),c2=a("li"),wbe=a("strong"),Kjo=o("plbart"),eDo=o(" \u2014 "),pQ=a("a"),oDo=o("PLBartModel"),rDo=o(" (PLBart model)"),tDo=l(),f2=a("li"),Abe=a("strong"),aDo=o("poolformer"),nDo=o(" \u2014 "),_Q=a("a"),sDo=o("PoolFormerModel"),lDo=o(" (PoolFormer model)"),iDo=l(),g2=a("li"),Lbe=a("strong"),dDo=o("prophetnet"),mDo=o(" \u2014 "),bQ=a("a"),cDo=o("ProphetNetModel"),fDo=o(" (ProphetNet model)"),gDo=l(),h2=a("li"),ybe=a("strong"),hDo=o("qdqbert"),uDo=o(" \u2014 "),vQ=a("a"),pDo=o("QDQBertModel"),_Do=o(" (QDQBert model)"),bDo=l(),u2=a("li"),xbe=a("strong"),vDo=o("reformer"),FDo=o(" \u2014 "),FQ=a("a"),TDo=o("ReformerModel"),MDo=o(" (Reformer model)"),EDo=l(),p2=a("li"),$be=a("strong"),CDo=o("regnet"),wDo=o(" \u2014 "),TQ=a("a"),ADo=o("RegNetModel"),LDo=o(" (RegNet model)"),yDo=l(),_2=a("li"),kbe=a("strong"),xDo=o("rembert"),$Do=o(" \u2014 "),MQ=a("a"),kDo=o("RemBertModel"),SDo=o(" (RemBERT model)"),RDo=l(),b2=a("li"),Sbe=a("strong"),PDo=o("resnet"),BDo=o(" \u2014 "),EQ=a("a"),IDo=o("ResNetModel"),NDo=o(" (ResNet model)"),qDo=l(),v2=a("li"),Rbe=a("strong"),jDo=o("retribert"),DDo=o(" \u2014 "),CQ=a("a"),GDo=o("RetriBertModel"),ODo=o(" (RetriBERT model)"),VDo=l(),F2=a("li"),Pbe=a("strong"),XDo=o("roberta"),zDo=o(" \u2014 "),wQ=a("a"),QDo=o("RobertaModel"),WDo=o(" (RoBERTa model)"),UDo=l(),T2=a("li"),Bbe=a("strong"),HDo=o("roformer"),JDo=o(" \u2014 "),AQ=a("a"),YDo=o("RoFormerModel"),ZDo=o(" (RoFormer model)"),KDo=l(),M2=a("li"),Ibe=a("strong"),eGo=o("segformer"),oGo=o(" \u2014 "),LQ=a("a"),rGo=o("SegformerModel"),tGo=o(" (SegFormer model)"),aGo=l(),E2=a("li"),Nbe=a("strong"),nGo=o("sew"),sGo=o(" \u2014 "),yQ=a("a"),lGo=o("SEWModel"),iGo=o(" (SEW model)"),dGo=l(),C2=a("li"),qbe=a("strong"),mGo=o("sew-d"),cGo=o(" \u2014 "),xQ=a("a"),fGo=o("SEWDModel"),gGo=o(" (SEW-D model)"),hGo=l(),w2=a("li"),jbe=a("strong"),uGo=o("speech_to_text"),pGo=o(" \u2014 "),$Q=a("a"),_Go=o("Speech2TextModel"),bGo=o(" (Speech2Text model)"),vGo=l(),A2=a("li"),Dbe=a("strong"),FGo=o("splinter"),TGo=o(" \u2014 "),kQ=a("a"),MGo=o("SplinterModel"),EGo=o(" (Splinter model)"),CGo=l(),L2=a("li"),Gbe=a("strong"),wGo=o("squeezebert"),AGo=o(" \u2014 "),SQ=a("a"),LGo=o("SqueezeBertModel"),yGo=o(" (SqueezeBERT model)"),xGo=l(),y2=a("li"),Obe=a("strong"),$Go=o("swin"),kGo=o(" \u2014 "),RQ=a("a"),SGo=o("SwinModel"),RGo=o(" (Swin Transformer model)"),PGo=l(),x2=a("li"),Vbe=a("strong"),BGo=o("swinv2"),IGo=o(" \u2014 "),PQ=a("a"),NGo=o("Swinv2Model"),qGo=o(" (Swin Transformer V2 model)"),jGo=l(),$2=a("li"),Xbe=a("strong"),DGo=o("t5"),GGo=o(" \u2014 "),BQ=a("a"),OGo=o("T5Model"),VGo=o(" (T5 model)"),XGo=l(),k2=a("li"),zbe=a("strong"),zGo=o("table-transformer"),QGo=o(" \u2014 "),IQ=a("a"),WGo=o("TableTransformerModel"),UGo=o(" (Table Transformer model)"),HGo=l(),S2=a("li"),Qbe=a("strong"),JGo=o("tapas"),YGo=o(" \u2014 "),NQ=a("a"),ZGo=o("TapasModel"),KGo=o(" (TAPAS model)"),eOo=l(),R2=a("li"),Wbe=a("strong"),oOo=o("time_series_transformer"),rOo=o(" \u2014 "),qQ=a("a"),tOo=o("TimeSeriesTransformerModel"),aOo=o(" (Time Series Transformer model)"),nOo=l(),P2=a("li"),Ube=a("strong"),sOo=o("trajectory_transformer"),lOo=o(" \u2014 "),jQ=a("a"),iOo=o("TrajectoryTransformerModel"),dOo=o(" (Trajectory Transformer model)"),mOo=l(),B2=a("li"),Hbe=a("strong"),cOo=o("transfo-xl"),fOo=o(" \u2014 "),DQ=a("a"),gOo=o("TransfoXLModel"),hOo=o(" (Transformer-XL model)"),uOo=l(),I2=a("li"),Jbe=a("strong"),pOo=o("unispeech"),_Oo=o(" \u2014 "),GQ=a("a"),bOo=o("UniSpeechModel"),vOo=o(" (UniSpeech model)"),FOo=l(),N2=a("li"),Ybe=a("strong"),TOo=o("unispeech-sat"),MOo=o(" \u2014 "),OQ=a("a"),EOo=o("UniSpeechSatModel"),COo=o(" (UniSpeechSat model)"),wOo=l(),q2=a("li"),Zbe=a("strong"),AOo=o("van"),LOo=o(" \u2014 "),VQ=a("a"),yOo=o("VanModel"),xOo=o(" (VAN model)"),$Oo=l(),j2=a("li"),Kbe=a("strong"),kOo=o("videomae"),SOo=o(" \u2014 "),XQ=a("a"),ROo=o("VideoMAEModel"),POo=o(" (VideoMAE model)"),BOo=l(),D2=a("li"),eve=a("strong"),IOo=o("vilt"),NOo=o(" \u2014 "),zQ=a("a"),qOo=o("ViltModel"),jOo=o(" (ViLT model)"),DOo=l(),G2=a("li"),ove=a("strong"),GOo=o("vision-text-dual-encoder"),OOo=o(" \u2014 "),QQ=a("a"),VOo=o("VisionTextDualEncoderModel"),XOo=o(" (VisionTextDualEncoder model)"),zOo=l(),O2=a("li"),rve=a("strong"),QOo=o("visual_bert"),WOo=o(" \u2014 "),WQ=a("a"),UOo=o("VisualBertModel"),HOo=o(" (VisualBERT model)"),JOo=l(),V2=a("li"),tve=a("strong"),YOo=o("vit"),ZOo=o(" \u2014 "),UQ=a("a"),KOo=o("ViTModel"),eVo=o(" (ViT model)"),oVo=l(),X2=a("li"),ave=a("strong"),rVo=o("vit_mae"),tVo=o(" \u2014 "),HQ=a("a"),aVo=o("ViTMAEModel"),nVo=o(" (ViTMAE model)"),sVo=l(),z2=a("li"),nve=a("strong"),lVo=o("vit_msn"),iVo=o(" \u2014 "),JQ=a("a"),dVo=o("ViTMSNModel"),mVo=o(" (ViTMSN model)"),cVo=l(),Q2=a("li"),sve=a("strong"),fVo=o("wav2vec2"),gVo=o(" \u2014 "),YQ=a("a"),hVo=o("Wav2Vec2Model"),uVo=o(" (Wav2Vec2 model)"),pVo=l(),W2=a("li"),lve=a("strong"),_Vo=o("wav2vec2-conformer"),bVo=o(" \u2014 "),ZQ=a("a"),vVo=o("Wav2Vec2ConformerModel"),FVo=o(" (Wav2Vec2-Conformer model)"),TVo=l(),U2=a("li"),ive=a("strong"),MVo=o("wavlm"),EVo=o(" \u2014 "),KQ=a("a"),CVo=o("WavLMModel"),wVo=o(" (WavLM model)"),AVo=l(),H2=a("li"),dve=a("strong"),LVo=o("whisper"),yVo=o(" \u2014 "),eW=a("a"),xVo=o("WhisperModel"),$Vo=o(" (Whisper model)"),kVo=l(),J2=a("li"),mve=a("strong"),SVo=o("xclip"),RVo=o(" \u2014 "),oW=a("a"),PVo=o("XCLIPModel"),BVo=o(" (X-CLIP model)"),IVo=l(),Y2=a("li"),cve=a("strong"),NVo=o("xglm"),qVo=o(" \u2014 "),rW=a("a"),jVo=o("XGLMModel"),DVo=o(" (XGLM model)"),GVo=l(),Z2=a("li"),fve=a("strong"),OVo=o("xlm"),VVo=o(" \u2014 "),tW=a("a"),XVo=o("XLMModel"),zVo=o(" (XLM model)"),QVo=l(),K2=a("li"),gve=a("strong"),WVo=o("xlm-prophetnet"),UVo=o(" \u2014 "),aW=a("a"),HVo=o("XLMProphetNetModel"),JVo=o(" (XLM-ProphetNet model)"),YVo=l(),eb=a("li"),hve=a("strong"),ZVo=o("xlm-roberta"),KVo=o(" \u2014 "),nW=a("a"),eXo=o("XLMRobertaModel"),oXo=o(" (XLM-RoBERTa model)"),rXo=l(),ob=a("li"),uve=a("strong"),tXo=o("xlm-roberta-xl"),aXo=o(" \u2014 "),sW=a("a"),nXo=o("XLMRobertaXLModel"),sXo=o(" (XLM-RoBERTa-XL model)"),lXo=l(),rb=a("li"),pve=a("strong"),iXo=o("xlnet"),dXo=o(" \u2014 "),lW=a("a"),mXo=o("XLNetModel"),cXo=o(" (XLNet model)"),fXo=l(),tb=a("li"),_ve=a("strong"),gXo=o("yolos"),hXo=o(" \u2014 "),iW=a("a"),uXo=o("YolosModel"),pXo=o(" (YOLOS model)"),_Xo=l(),ab=a("li"),bve=a("strong"),bXo=o("yoso"),vXo=o(" \u2014 "),dW=a("a"),FXo=o("YosoModel"),TXo=o(" (YOSO model)"),MXo=l(),nb=a("p"),EXo=o("The model is set in evaluation mode by default using "),vve=a("code"),CXo=o("model.eval()"),wXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Fve=a("code"),AXo=o("model.train()"),LXo=l(),F(sb.$$.fragment),lao=l(),Id=a("h2"),lb=a("a"),Tve=a("span"),F(z$.$$.fragment),yXo=l(),Mve=a("span"),xXo=o("AutoModelForPreTraining"),iao=l(),No=a("div"),F(Q$.$$.fragment),$Xo=l(),Nd=a("p"),kXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),mW=a("a"),SXo=o("from_pretrained()"),RXo=o(" class method or the "),cW=a("a"),PXo=o("from_config()"),BXo=o(` class
method.`),IXo=l(),W$=a("p"),NXo=o("This class cannot be instantiated directly using "),Eve=a("code"),qXo=o("__init__()"),jXo=o(" (throws an error)."),DXo=l(),Et=a("div"),F(U$.$$.fragment),GXo=l(),Cve=a("p"),OXo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),VXo=l(),qd=a("p"),XXo=o(`Note:
Loading a model from its configuration file does `),wve=a("strong"),zXo=o("not"),QXo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fW=a("a"),WXo=o("from_pretrained()"),UXo=o(" to load the model weights."),HXo=l(),F(ib.$$.fragment),JXo=l(),eo=a("div"),F(H$.$$.fragment),YXo=l(),Ave=a("p"),ZXo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),KXo=l(),sn=a("p"),ezo=o("The model class to instantiate is selected based on the "),Lve=a("code"),ozo=o("model_type"),rzo=o(` property of the config object (either
passed as an argument or loaded from `),yve=a("code"),tzo=o("pretrained_model_name_or_path"),azo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xve=a("code"),nzo=o("pretrained_model_name_or_path"),szo=o(":"),lzo=l(),G=a("ul"),db=a("li"),$ve=a("strong"),izo=o("albert"),dzo=o(" \u2014 "),gW=a("a"),mzo=o("AlbertForPreTraining"),czo=o(" (ALBERT model)"),fzo=l(),mb=a("li"),kve=a("strong"),gzo=o("bart"),hzo=o(" \u2014 "),hW=a("a"),uzo=o("BartForConditionalGeneration"),pzo=o(" (BART model)"),_zo=l(),cb=a("li"),Sve=a("strong"),bzo=o("bert"),vzo=o(" \u2014 "),uW=a("a"),Fzo=o("BertForPreTraining"),Tzo=o(" (BERT model)"),Mzo=l(),fb=a("li"),Rve=a("strong"),Ezo=o("big_bird"),Czo=o(" \u2014 "),pW=a("a"),wzo=o("BigBirdForPreTraining"),Azo=o(" (BigBird model)"),Lzo=l(),gb=a("li"),Pve=a("strong"),yzo=o("bloom"),xzo=o(" \u2014 "),_W=a("a"),$zo=o("BloomForCausalLM"),kzo=o(" (BLOOM model)"),Szo=l(),hb=a("li"),Bve=a("strong"),Rzo=o("camembert"),Pzo=o(" \u2014 "),bW=a("a"),Bzo=o("CamembertForMaskedLM"),Izo=o(" (CamemBERT model)"),Nzo=l(),ub=a("li"),Ive=a("strong"),qzo=o("ctrl"),jzo=o(" \u2014 "),vW=a("a"),Dzo=o("CTRLLMHeadModel"),Gzo=o(" (CTRL model)"),Ozo=l(),pb=a("li"),Nve=a("strong"),Vzo=o("data2vec-text"),Xzo=o(" \u2014 "),FW=a("a"),zzo=o("Data2VecTextForMaskedLM"),Qzo=o(" (Data2VecText model)"),Wzo=l(),_b=a("li"),qve=a("strong"),Uzo=o("deberta"),Hzo=o(" \u2014 "),TW=a("a"),Jzo=o("DebertaForMaskedLM"),Yzo=o(" (DeBERTa model)"),Zzo=l(),bb=a("li"),jve=a("strong"),Kzo=o("deberta-v2"),eQo=o(" \u2014 "),MW=a("a"),oQo=o("DebertaV2ForMaskedLM"),rQo=o(" (DeBERTa-v2 model)"),tQo=l(),vb=a("li"),Dve=a("strong"),aQo=o("distilbert"),nQo=o(" \u2014 "),EW=a("a"),sQo=o("DistilBertForMaskedLM"),lQo=o(" (DistilBERT model)"),iQo=l(),Fb=a("li"),Gve=a("strong"),dQo=o("electra"),mQo=o(" \u2014 "),CW=a("a"),cQo=o("ElectraForPreTraining"),fQo=o(" (ELECTRA model)"),gQo=l(),Tb=a("li"),Ove=a("strong"),hQo=o("ernie"),uQo=o(" \u2014 "),wW=a("a"),pQo=o("ErnieForPreTraining"),_Qo=o(" (ERNIE model)"),bQo=l(),Mb=a("li"),Vve=a("strong"),vQo=o("flaubert"),FQo=o(" \u2014 "),AW=a("a"),TQo=o("FlaubertWithLMHeadModel"),MQo=o(" (FlauBERT model)"),EQo=l(),Eb=a("li"),Xve=a("strong"),CQo=o("flava"),wQo=o(" \u2014 "),LW=a("a"),AQo=o("FlavaForPreTraining"),LQo=o(" (FLAVA model)"),yQo=l(),Cb=a("li"),zve=a("strong"),xQo=o("fnet"),$Qo=o(" \u2014 "),yW=a("a"),kQo=o("FNetForPreTraining"),SQo=o(" (FNet model)"),RQo=l(),wb=a("li"),Qve=a("strong"),PQo=o("fsmt"),BQo=o(" \u2014 "),xW=a("a"),IQo=o("FSMTForConditionalGeneration"),NQo=o(" (FairSeq Machine-Translation model)"),qQo=l(),Ab=a("li"),Wve=a("strong"),jQo=o("funnel"),DQo=o(" \u2014 "),$W=a("a"),GQo=o("FunnelForPreTraining"),OQo=o(" (Funnel Transformer model)"),VQo=l(),Lb=a("li"),Uve=a("strong"),XQo=o("gpt2"),zQo=o(" \u2014 "),kW=a("a"),QQo=o("GPT2LMHeadModel"),WQo=o(" (OpenAI GPT-2 model)"),UQo=l(),yb=a("li"),Hve=a("strong"),HQo=o("ibert"),JQo=o(" \u2014 "),SW=a("a"),YQo=o("IBertForMaskedLM"),ZQo=o(" (I-BERT model)"),KQo=l(),xb=a("li"),Jve=a("strong"),eWo=o("layoutlm"),oWo=o(" \u2014 "),RW=a("a"),rWo=o("LayoutLMForMaskedLM"),tWo=o(" (LayoutLM model)"),aWo=l(),$b=a("li"),Yve=a("strong"),nWo=o("longformer"),sWo=o(" \u2014 "),PW=a("a"),lWo=o("LongformerForMaskedLM"),iWo=o(" (Longformer model)"),dWo=l(),kb=a("li"),Zve=a("strong"),mWo=o("luke"),cWo=o(" \u2014 "),BW=a("a"),fWo=o("LukeForMaskedLM"),gWo=o(" (LUKE model)"),hWo=l(),Sb=a("li"),Kve=a("strong"),uWo=o("lxmert"),pWo=o(" \u2014 "),IW=a("a"),_Wo=o("LxmertForPreTraining"),bWo=o(" (LXMERT model)"),vWo=l(),Rb=a("li"),eFe=a("strong"),FWo=o("megatron-bert"),TWo=o(" \u2014 "),NW=a("a"),MWo=o("MegatronBertForPreTraining"),EWo=o(" (Megatron-BERT model)"),CWo=l(),Pb=a("li"),oFe=a("strong"),wWo=o("mobilebert"),AWo=o(" \u2014 "),qW=a("a"),LWo=o("MobileBertForPreTraining"),yWo=o(" (MobileBERT model)"),xWo=l(),Bb=a("li"),rFe=a("strong"),$Wo=o("mpnet"),kWo=o(" \u2014 "),jW=a("a"),SWo=o("MPNetForMaskedLM"),RWo=o(" (MPNet model)"),PWo=l(),Ib=a("li"),tFe=a("strong"),BWo=o("mvp"),IWo=o(" \u2014 "),DW=a("a"),NWo=o("MvpForConditionalGeneration"),qWo=o(" (MVP model)"),jWo=l(),Nb=a("li"),aFe=a("strong"),DWo=o("nezha"),GWo=o(" \u2014 "),GW=a("a"),OWo=o("NezhaForPreTraining"),VWo=o(" (Nezha model)"),XWo=l(),qb=a("li"),nFe=a("strong"),zWo=o("openai-gpt"),QWo=o(" \u2014 "),OW=a("a"),WWo=o("OpenAIGPTLMHeadModel"),UWo=o(" (OpenAI GPT model)"),HWo=l(),jb=a("li"),sFe=a("strong"),JWo=o("retribert"),YWo=o(" \u2014 "),VW=a("a"),ZWo=o("RetriBertModel"),KWo=o(" (RetriBERT model)"),eUo=l(),Db=a("li"),lFe=a("strong"),oUo=o("roberta"),rUo=o(" \u2014 "),XW=a("a"),tUo=o("RobertaForMaskedLM"),aUo=o(" (RoBERTa model)"),nUo=l(),Gb=a("li"),iFe=a("strong"),sUo=o("splinter"),lUo=o(" \u2014 "),zW=a("a"),iUo=o("SplinterForPreTraining"),dUo=o(" (Splinter model)"),mUo=l(),Ob=a("li"),dFe=a("strong"),cUo=o("squeezebert"),fUo=o(" \u2014 "),QW=a("a"),gUo=o("SqueezeBertForMaskedLM"),hUo=o(" (SqueezeBERT model)"),uUo=l(),Vb=a("li"),mFe=a("strong"),pUo=o("t5"),_Uo=o(" \u2014 "),WW=a("a"),bUo=o("T5ForConditionalGeneration"),vUo=o(" (T5 model)"),FUo=l(),Xb=a("li"),cFe=a("strong"),TUo=o("tapas"),MUo=o(" \u2014 "),UW=a("a"),EUo=o("TapasForMaskedLM"),CUo=o(" (TAPAS model)"),wUo=l(),zb=a("li"),fFe=a("strong"),AUo=o("transfo-xl"),LUo=o(" \u2014 "),HW=a("a"),yUo=o("TransfoXLLMHeadModel"),xUo=o(" (Transformer-XL model)"),$Uo=l(),Qb=a("li"),gFe=a("strong"),kUo=o("unispeech"),SUo=o(" \u2014 "),JW=a("a"),RUo=o("UniSpeechForPreTraining"),PUo=o(" (UniSpeech model)"),BUo=l(),Wb=a("li"),hFe=a("strong"),IUo=o("unispeech-sat"),NUo=o(" \u2014 "),YW=a("a"),qUo=o("UniSpeechSatForPreTraining"),jUo=o(" (UniSpeechSat model)"),DUo=l(),Ub=a("li"),uFe=a("strong"),GUo=o("videomae"),OUo=o(" \u2014 "),ZW=a("a"),VUo=o("VideoMAEForPreTraining"),XUo=o(" (VideoMAE model)"),zUo=l(),Hb=a("li"),pFe=a("strong"),QUo=o("visual_bert"),WUo=o(" \u2014 "),KW=a("a"),UUo=o("VisualBertForPreTraining"),HUo=o(" (VisualBERT model)"),JUo=l(),Jb=a("li"),_Fe=a("strong"),YUo=o("vit_mae"),ZUo=o(" \u2014 "),eU=a("a"),KUo=o("ViTMAEForPreTraining"),eHo=o(" (ViTMAE model)"),oHo=l(),Yb=a("li"),bFe=a("strong"),rHo=o("wav2vec2"),tHo=o(" \u2014 "),oU=a("a"),aHo=o("Wav2Vec2ForPreTraining"),nHo=o(" (Wav2Vec2 model)"),sHo=l(),Zb=a("li"),vFe=a("strong"),lHo=o("wav2vec2-conformer"),iHo=o(" \u2014 "),rU=a("a"),dHo=o("Wav2Vec2ConformerForPreTraining"),mHo=o(" (Wav2Vec2-Conformer model)"),cHo=l(),Kb=a("li"),FFe=a("strong"),fHo=o("xlm"),gHo=o(" \u2014 "),tU=a("a"),hHo=o("XLMWithLMHeadModel"),uHo=o(" (XLM model)"),pHo=l(),ev=a("li"),TFe=a("strong"),_Ho=o("xlm-roberta"),bHo=o(" \u2014 "),aU=a("a"),vHo=o("XLMRobertaForMaskedLM"),FHo=o(" (XLM-RoBERTa model)"),THo=l(),ov=a("li"),MFe=a("strong"),MHo=o("xlm-roberta-xl"),EHo=o(" \u2014 "),nU=a("a"),CHo=o("XLMRobertaXLForMaskedLM"),wHo=o(" (XLM-RoBERTa-XL model)"),AHo=l(),rv=a("li"),EFe=a("strong"),LHo=o("xlnet"),yHo=o(" \u2014 "),sU=a("a"),xHo=o("XLNetLMHeadModel"),$Ho=o(" (XLNet model)"),kHo=l(),tv=a("p"),SHo=o("The model is set in evaluation mode by default using "),CFe=a("code"),RHo=o("model.eval()"),PHo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),wFe=a("code"),BHo=o("model.train()"),IHo=l(),F(av.$$.fragment),dao=l(),jd=a("h2"),nv=a("a"),AFe=a("span"),F(J$.$$.fragment),NHo=l(),LFe=a("span"),qHo=o("AutoModelForCausalLM"),mao=l(),qo=a("div"),F(Y$.$$.fragment),jHo=l(),Dd=a("p"),DHo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),lU=a("a"),GHo=o("from_pretrained()"),OHo=o(" class method or the "),iU=a("a"),VHo=o("from_config()"),XHo=o(` class
method.`),zHo=l(),Z$=a("p"),QHo=o("This class cannot be instantiated directly using "),yFe=a("code"),WHo=o("__init__()"),UHo=o(" (throws an error)."),HHo=l(),Ct=a("div"),F(K$.$$.fragment),JHo=l(),xFe=a("p"),YHo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),ZHo=l(),Gd=a("p"),KHo=o(`Note:
Loading a model from its configuration file does `),$Fe=a("strong"),eJo=o("not"),oJo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dU=a("a"),rJo=o("from_pretrained()"),tJo=o(" to load the model weights."),aJo=l(),F(sv.$$.fragment),nJo=l(),oo=a("div"),F(ek.$$.fragment),sJo=l(),kFe=a("p"),lJo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),iJo=l(),ln=a("p"),dJo=o("The model class to instantiate is selected based on the "),SFe=a("code"),mJo=o("model_type"),cJo=o(` property of the config object (either
passed as an argument or loaded from `),RFe=a("code"),fJo=o("pretrained_model_name_or_path"),gJo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PFe=a("code"),hJo=o("pretrained_model_name_or_path"),uJo=o(":"),pJo=l(),W=a("ul"),lv=a("li"),BFe=a("strong"),_Jo=o("bart"),bJo=o(" \u2014 "),mU=a("a"),vJo=o("BartForCausalLM"),FJo=o(" (BART model)"),TJo=l(),iv=a("li"),IFe=a("strong"),MJo=o("bert"),EJo=o(" \u2014 "),cU=a("a"),CJo=o("BertLMHeadModel"),wJo=o(" (BERT model)"),AJo=l(),dv=a("li"),NFe=a("strong"),LJo=o("bert-generation"),yJo=o(" \u2014 "),fU=a("a"),xJo=o("BertGenerationDecoder"),$Jo=o(" (Bert Generation model)"),kJo=l(),mv=a("li"),qFe=a("strong"),SJo=o("big_bird"),RJo=o(" \u2014 "),gU=a("a"),PJo=o("BigBirdForCausalLM"),BJo=o(" (BigBird model)"),IJo=l(),cv=a("li"),jFe=a("strong"),NJo=o("bigbird_pegasus"),qJo=o(" \u2014 "),hU=a("a"),jJo=o("BigBirdPegasusForCausalLM"),DJo=o(" (BigBird-Pegasus model)"),GJo=l(),fv=a("li"),DFe=a("strong"),OJo=o("blenderbot"),VJo=o(" \u2014 "),uU=a("a"),XJo=o("BlenderbotForCausalLM"),zJo=o(" (Blenderbot model)"),QJo=l(),gv=a("li"),GFe=a("strong"),WJo=o("blenderbot-small"),UJo=o(" \u2014 "),pU=a("a"),HJo=o("BlenderbotSmallForCausalLM"),JJo=o(" (BlenderbotSmall model)"),YJo=l(),hv=a("li"),OFe=a("strong"),ZJo=o("bloom"),KJo=o(" \u2014 "),_U=a("a"),eYo=o("BloomForCausalLM"),oYo=o(" (BLOOM model)"),rYo=l(),uv=a("li"),VFe=a("strong"),tYo=o("camembert"),aYo=o(" \u2014 "),bU=a("a"),nYo=o("CamembertForCausalLM"),sYo=o(" (CamemBERT model)"),lYo=l(),pv=a("li"),XFe=a("strong"),iYo=o("codegen"),dYo=o(" \u2014 "),vU=a("a"),mYo=o("CodeGenForCausalLM"),cYo=o(" (CodeGen model)"),fYo=l(),_v=a("li"),zFe=a("strong"),gYo=o("ctrl"),hYo=o(" \u2014 "),FU=a("a"),uYo=o("CTRLLMHeadModel"),pYo=o(" (CTRL model)"),_Yo=l(),bv=a("li"),QFe=a("strong"),bYo=o("data2vec-text"),vYo=o(" \u2014 "),TU=a("a"),FYo=o("Data2VecTextForCausalLM"),TYo=o(" (Data2VecText model)"),MYo=l(),vv=a("li"),WFe=a("strong"),EYo=o("electra"),CYo=o(" \u2014 "),MU=a("a"),wYo=o("ElectraForCausalLM"),AYo=o(" (ELECTRA model)"),LYo=l(),Fv=a("li"),UFe=a("strong"),yYo=o("ernie"),xYo=o(" \u2014 "),EU=a("a"),$Yo=o("ErnieForCausalLM"),kYo=o(" (ERNIE model)"),SYo=l(),Tv=a("li"),HFe=a("strong"),RYo=o("gpt2"),PYo=o(" \u2014 "),CU=a("a"),BYo=o("GPT2LMHeadModel"),IYo=o(" (OpenAI GPT-2 model)"),NYo=l(),Mv=a("li"),JFe=a("strong"),qYo=o("gpt_neo"),jYo=o(" \u2014 "),wU=a("a"),DYo=o("GPTNeoForCausalLM"),GYo=o(" (GPT Neo model)"),OYo=l(),Ev=a("li"),YFe=a("strong"),VYo=o("gpt_neox"),XYo=o(" \u2014 "),AU=a("a"),zYo=o("GPTNeoXForCausalLM"),QYo=o(" (GPT NeoX model)"),WYo=l(),Cv=a("li"),ZFe=a("strong"),UYo=o("gpt_neox_japanese"),HYo=o(" \u2014 "),LU=a("a"),JYo=o("GPTNeoXJapaneseForCausalLM"),YYo=o(" (GPT NeoX Japanese model)"),ZYo=l(),wv=a("li"),KFe=a("strong"),KYo=o("gptj"),eZo=o(" \u2014 "),yU=a("a"),oZo=o("GPTJForCausalLM"),rZo=o(" (GPT-J model)"),tZo=l(),Av=a("li"),eTe=a("strong"),aZo=o("marian"),nZo=o(" \u2014 "),xU=a("a"),sZo=o("MarianForCausalLM"),lZo=o(" (Marian model)"),iZo=l(),Lv=a("li"),oTe=a("strong"),dZo=o("mbart"),mZo=o(" \u2014 "),$U=a("a"),cZo=o("MBartForCausalLM"),fZo=o(" (mBART model)"),gZo=l(),yv=a("li"),rTe=a("strong"),hZo=o("megatron-bert"),uZo=o(" \u2014 "),kU=a("a"),pZo=o("MegatronBertForCausalLM"),_Zo=o(" (Megatron-BERT model)"),bZo=l(),xv=a("li"),tTe=a("strong"),vZo=o("mvp"),FZo=o(" \u2014 "),SU=a("a"),TZo=o("MvpForCausalLM"),MZo=o(" (MVP model)"),EZo=l(),$v=a("li"),aTe=a("strong"),CZo=o("openai-gpt"),wZo=o(" \u2014 "),RU=a("a"),AZo=o("OpenAIGPTLMHeadModel"),LZo=o(" (OpenAI GPT model)"),yZo=l(),kv=a("li"),nTe=a("strong"),xZo=o("opt"),$Zo=o(" \u2014 "),PU=a("a"),kZo=o("OPTForCausalLM"),SZo=o(" (OPT model)"),RZo=l(),Sv=a("li"),sTe=a("strong"),PZo=o("pegasus"),BZo=o(" \u2014 "),BU=a("a"),IZo=o("PegasusForCausalLM"),NZo=o(" (Pegasus model)"),qZo=l(),Rv=a("li"),lTe=a("strong"),jZo=o("plbart"),DZo=o(" \u2014 "),IU=a("a"),GZo=o("PLBartForCausalLM"),OZo=o(" (PLBart model)"),VZo=l(),Pv=a("li"),iTe=a("strong"),XZo=o("prophetnet"),zZo=o(" \u2014 "),NU=a("a"),QZo=o("ProphetNetForCausalLM"),WZo=o(" (ProphetNet model)"),UZo=l(),Bv=a("li"),dTe=a("strong"),HZo=o("qdqbert"),JZo=o(" \u2014 "),qU=a("a"),YZo=o("QDQBertLMHeadModel"),ZZo=o(" (QDQBert model)"),KZo=l(),Iv=a("li"),mTe=a("strong"),eKo=o("reformer"),oKo=o(" \u2014 "),jU=a("a"),rKo=o("ReformerModelWithLMHead"),tKo=o(" (Reformer model)"),aKo=l(),Nv=a("li"),cTe=a("strong"),nKo=o("rembert"),sKo=o(" \u2014 "),DU=a("a"),lKo=o("RemBertForCausalLM"),iKo=o(" (RemBERT model)"),dKo=l(),qv=a("li"),fTe=a("strong"),mKo=o("roberta"),cKo=o(" \u2014 "),GU=a("a"),fKo=o("RobertaForCausalLM"),gKo=o(" (RoBERTa model)"),hKo=l(),jv=a("li"),gTe=a("strong"),uKo=o("roformer"),pKo=o(" \u2014 "),OU=a("a"),_Ko=o("RoFormerForCausalLM"),bKo=o(" (RoFormer model)"),vKo=l(),Dv=a("li"),hTe=a("strong"),FKo=o("speech_to_text_2"),TKo=o(" \u2014 "),VU=a("a"),MKo=o("Speech2Text2ForCausalLM"),EKo=o(" (Speech2Text2 model)"),CKo=l(),Gv=a("li"),uTe=a("strong"),wKo=o("transfo-xl"),AKo=o(" \u2014 "),XU=a("a"),LKo=o("TransfoXLLMHeadModel"),yKo=o(" (Transformer-XL model)"),xKo=l(),Ov=a("li"),pTe=a("strong"),$Ko=o("trocr"),kKo=o(" \u2014 "),zU=a("a"),SKo=o("TrOCRForCausalLM"),RKo=o(" (TrOCR model)"),PKo=l(),Vv=a("li"),_Te=a("strong"),BKo=o("xglm"),IKo=o(" \u2014 "),QU=a("a"),NKo=o("XGLMForCausalLM"),qKo=o(" (XGLM model)"),jKo=l(),Xv=a("li"),bTe=a("strong"),DKo=o("xlm"),GKo=o(" \u2014 "),WU=a("a"),OKo=o("XLMWithLMHeadModel"),VKo=o(" (XLM model)"),XKo=l(),zv=a("li"),vTe=a("strong"),zKo=o("xlm-prophetnet"),QKo=o(" \u2014 "),UU=a("a"),WKo=o("XLMProphetNetForCausalLM"),UKo=o(" (XLM-ProphetNet model)"),HKo=l(),Qv=a("li"),FTe=a("strong"),JKo=o("xlm-roberta"),YKo=o(" \u2014 "),HU=a("a"),ZKo=o("XLMRobertaForCausalLM"),KKo=o(" (XLM-RoBERTa model)"),eer=l(),Wv=a("li"),TTe=a("strong"),oer=o("xlm-roberta-xl"),rer=o(" \u2014 "),JU=a("a"),ter=o("XLMRobertaXLForCausalLM"),aer=o(" (XLM-RoBERTa-XL model)"),ner=l(),Uv=a("li"),MTe=a("strong"),ser=o("xlnet"),ler=o(" \u2014 "),YU=a("a"),ier=o("XLNetLMHeadModel"),der=o(" (XLNet model)"),mer=l(),Hv=a("p"),cer=o("The model is set in evaluation mode by default using "),ETe=a("code"),fer=o("model.eval()"),ger=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),CTe=a("code"),her=o("model.train()"),uer=l(),F(Jv.$$.fragment),cao=l(),Od=a("h2"),Yv=a("a"),wTe=a("span"),F(ok.$$.fragment),per=l(),ATe=a("span"),_er=o("AutoModelForDepthEstimation"),fao=l(),jo=a("div"),F(rk.$$.fragment),ber=l(),Vd=a("p"),ver=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),ZU=a("a"),Fer=o("from_pretrained()"),Ter=o(" class method or the "),KU=a("a"),Mer=o("from_config()"),Eer=o(` class
method.`),Cer=l(),tk=a("p"),wer=o("This class cannot be instantiated directly using "),LTe=a("code"),Aer=o("__init__()"),Ler=o(" (throws an error)."),yer=l(),wt=a("div"),F(ak.$$.fragment),xer=l(),yTe=a("p"),$er=o("Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),ker=l(),Xd=a("p"),Ser=o(`Note:
Loading a model from its configuration file does `),xTe=a("strong"),Rer=o("not"),Per=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eH=a("a"),Ber=o("from_pretrained()"),Ier=o(" to load the model weights."),Ner=l(),F(Zv.$$.fragment),qer=l(),ro=a("div"),F(nk.$$.fragment),jer=l(),$Te=a("p"),Der=o("Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),Ger=l(),dn=a("p"),Oer=o("The model class to instantiate is selected based on the "),kTe=a("code"),Ver=o("model_type"),Xer=o(` property of the config object (either
passed as an argument or loaded from `),STe=a("code"),zer=o("pretrained_model_name_or_path"),Qer=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RTe=a("code"),Wer=o("pretrained_model_name_or_path"),Uer=o(":"),Her=l(),sk=a("ul"),Kv=a("li"),PTe=a("strong"),Jer=o("dpt"),Yer=o(" \u2014 "),oH=a("a"),Zer=o("DPTForDepthEstimation"),Ker=o(" (DPT model)"),eor=l(),eF=a("li"),BTe=a("strong"),oor=o("glpn"),ror=o(" \u2014 "),rH=a("a"),tor=o("GLPNForDepthEstimation"),aor=o(" (GLPN model)"),nor=l(),oF=a("p"),sor=o("The model is set in evaluation mode by default using "),ITe=a("code"),lor=o("model.eval()"),ior=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),NTe=a("code"),dor=o("model.train()"),mor=l(),F(rF.$$.fragment),gao=l(),zd=a("h2"),tF=a("a"),qTe=a("span"),F(lk.$$.fragment),cor=l(),jTe=a("span"),gor=o("AutoModelForMaskedLM"),hao=l(),Do=a("div"),F(ik.$$.fragment),hor=l(),Qd=a("p"),uor=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),tH=a("a"),por=o("from_pretrained()"),_or=o(" class method or the "),aH=a("a"),bor=o("from_config()"),vor=o(` class
method.`),For=l(),dk=a("p"),Tor=o("This class cannot be instantiated directly using "),DTe=a("code"),Mor=o("__init__()"),Eor=o(" (throws an error)."),Cor=l(),At=a("div"),F(mk.$$.fragment),wor=l(),GTe=a("p"),Aor=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Lor=l(),Wd=a("p"),yor=o(`Note:
Loading a model from its configuration file does `),OTe=a("strong"),xor=o("not"),$or=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nH=a("a"),kor=o("from_pretrained()"),Sor=o(" to load the model weights."),Ror=l(),F(aF.$$.fragment),Por=l(),to=a("div"),F(ck.$$.fragment),Bor=l(),VTe=a("p"),Ior=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Nor=l(),mn=a("p"),qor=o("The model class to instantiate is selected based on the "),XTe=a("code"),jor=o("model_type"),Dor=o(` property of the config object (either
passed as an argument or loaded from `),zTe=a("code"),Gor=o("pretrained_model_name_or_path"),Oor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QTe=a("code"),Vor=o("pretrained_model_name_or_path"),Xor=o(":"),zor=l(),Y=a("ul"),nF=a("li"),WTe=a("strong"),Qor=o("albert"),Wor=o(" \u2014 "),sH=a("a"),Uor=o("AlbertForMaskedLM"),Hor=o(" (ALBERT model)"),Jor=l(),sF=a("li"),UTe=a("strong"),Yor=o("bart"),Zor=o(" \u2014 "),lH=a("a"),Kor=o("BartForConditionalGeneration"),err=o(" (BART model)"),orr=l(),lF=a("li"),HTe=a("strong"),rrr=o("bert"),trr=o(" \u2014 "),iH=a("a"),arr=o("BertForMaskedLM"),nrr=o(" (BERT model)"),srr=l(),iF=a("li"),JTe=a("strong"),lrr=o("big_bird"),irr=o(" \u2014 "),dH=a("a"),drr=o("BigBirdForMaskedLM"),mrr=o(" (BigBird model)"),crr=l(),dF=a("li"),YTe=a("strong"),frr=o("camembert"),grr=o(" \u2014 "),mH=a("a"),hrr=o("CamembertForMaskedLM"),urr=o(" (CamemBERT model)"),prr=l(),mF=a("li"),ZTe=a("strong"),_rr=o("convbert"),brr=o(" \u2014 "),cH=a("a"),vrr=o("ConvBertForMaskedLM"),Frr=o(" (ConvBERT model)"),Trr=l(),cF=a("li"),KTe=a("strong"),Mrr=o("data2vec-text"),Err=o(" \u2014 "),fH=a("a"),Crr=o("Data2VecTextForMaskedLM"),wrr=o(" (Data2VecText model)"),Arr=l(),fF=a("li"),eMe=a("strong"),Lrr=o("deberta"),yrr=o(" \u2014 "),gH=a("a"),xrr=o("DebertaForMaskedLM"),$rr=o(" (DeBERTa model)"),krr=l(),gF=a("li"),oMe=a("strong"),Srr=o("deberta-v2"),Rrr=o(" \u2014 "),hH=a("a"),Prr=o("DebertaV2ForMaskedLM"),Brr=o(" (DeBERTa-v2 model)"),Irr=l(),hF=a("li"),rMe=a("strong"),Nrr=o("distilbert"),qrr=o(" \u2014 "),uH=a("a"),jrr=o("DistilBertForMaskedLM"),Drr=o(" (DistilBERT model)"),Grr=l(),uF=a("li"),tMe=a("strong"),Orr=o("electra"),Vrr=o(" \u2014 "),pH=a("a"),Xrr=o("ElectraForMaskedLM"),zrr=o(" (ELECTRA model)"),Qrr=l(),pF=a("li"),aMe=a("strong"),Wrr=o("ernie"),Urr=o(" \u2014 "),_H=a("a"),Hrr=o("ErnieForMaskedLM"),Jrr=o(" (ERNIE model)"),Yrr=l(),_F=a("li"),nMe=a("strong"),Zrr=o("flaubert"),Krr=o(" \u2014 "),bH=a("a"),etr=o("FlaubertWithLMHeadModel"),otr=o(" (FlauBERT model)"),rtr=l(),bF=a("li"),sMe=a("strong"),ttr=o("fnet"),atr=o(" \u2014 "),vH=a("a"),ntr=o("FNetForMaskedLM"),str=o(" (FNet model)"),ltr=l(),vF=a("li"),lMe=a("strong"),itr=o("funnel"),dtr=o(" \u2014 "),FH=a("a"),mtr=o("FunnelForMaskedLM"),ctr=o(" (Funnel Transformer model)"),ftr=l(),FF=a("li"),iMe=a("strong"),gtr=o("ibert"),htr=o(" \u2014 "),TH=a("a"),utr=o("IBertForMaskedLM"),ptr=o(" (I-BERT model)"),_tr=l(),TF=a("li"),dMe=a("strong"),btr=o("layoutlm"),vtr=o(" \u2014 "),MH=a("a"),Ftr=o("LayoutLMForMaskedLM"),Ttr=o(" (LayoutLM model)"),Mtr=l(),MF=a("li"),mMe=a("strong"),Etr=o("longformer"),Ctr=o(" \u2014 "),EH=a("a"),wtr=o("LongformerForMaskedLM"),Atr=o(" (Longformer model)"),Ltr=l(),EF=a("li"),cMe=a("strong"),ytr=o("luke"),xtr=o(" \u2014 "),CH=a("a"),$tr=o("LukeForMaskedLM"),ktr=o(" (LUKE model)"),Str=l(),CF=a("li"),fMe=a("strong"),Rtr=o("mbart"),Ptr=o(" \u2014 "),wH=a("a"),Btr=o("MBartForConditionalGeneration"),Itr=o(" (mBART model)"),Ntr=l(),wF=a("li"),gMe=a("strong"),qtr=o("megatron-bert"),jtr=o(" \u2014 "),AH=a("a"),Dtr=o("MegatronBertForMaskedLM"),Gtr=o(" (Megatron-BERT model)"),Otr=l(),AF=a("li"),hMe=a("strong"),Vtr=o("mobilebert"),Xtr=o(" \u2014 "),LH=a("a"),ztr=o("MobileBertForMaskedLM"),Qtr=o(" (MobileBERT model)"),Wtr=l(),LF=a("li"),uMe=a("strong"),Utr=o("mpnet"),Htr=o(" \u2014 "),yH=a("a"),Jtr=o("MPNetForMaskedLM"),Ytr=o(" (MPNet model)"),Ztr=l(),yF=a("li"),pMe=a("strong"),Ktr=o("mvp"),ear=o(" \u2014 "),xH=a("a"),oar=o("MvpForConditionalGeneration"),rar=o(" (MVP model)"),tar=l(),xF=a("li"),_Me=a("strong"),aar=o("nezha"),nar=o(" \u2014 "),$H=a("a"),sar=o("NezhaForMaskedLM"),lar=o(" (Nezha model)"),iar=l(),$F=a("li"),bMe=a("strong"),dar=o("nystromformer"),mar=o(" \u2014 "),kH=a("a"),car=o("NystromformerForMaskedLM"),far=o(" (Nystr\xF6mformer model)"),gar=l(),kF=a("li"),vMe=a("strong"),har=o("perceiver"),uar=o(" \u2014 "),SH=a("a"),par=o("PerceiverForMaskedLM"),_ar=o(" (Perceiver model)"),bar=l(),SF=a("li"),FMe=a("strong"),Far=o("qdqbert"),Tar=o(" \u2014 "),RH=a("a"),Mar=o("QDQBertForMaskedLM"),Ear=o(" (QDQBert model)"),Car=l(),RF=a("li"),TMe=a("strong"),war=o("reformer"),Aar=o(" \u2014 "),PH=a("a"),Lar=o("ReformerForMaskedLM"),yar=o(" (Reformer model)"),xar=l(),PF=a("li"),MMe=a("strong"),$ar=o("rembert"),kar=o(" \u2014 "),BH=a("a"),Sar=o("RemBertForMaskedLM"),Rar=o(" (RemBERT model)"),Par=l(),BF=a("li"),EMe=a("strong"),Bar=o("roberta"),Iar=o(" \u2014 "),IH=a("a"),Nar=o("RobertaForMaskedLM"),qar=o(" (RoBERTa model)"),jar=l(),IF=a("li"),CMe=a("strong"),Dar=o("roformer"),Gar=o(" \u2014 "),NH=a("a"),Oar=o("RoFormerForMaskedLM"),Var=o(" (RoFormer model)"),Xar=l(),NF=a("li"),wMe=a("strong"),zar=o("squeezebert"),Qar=o(" \u2014 "),qH=a("a"),War=o("SqueezeBertForMaskedLM"),Uar=o(" (SqueezeBERT model)"),Har=l(),qF=a("li"),AMe=a("strong"),Jar=o("tapas"),Yar=o(" \u2014 "),jH=a("a"),Zar=o("TapasForMaskedLM"),Kar=o(" (TAPAS model)"),enr=l(),jF=a("li"),LMe=a("strong"),onr=o("wav2vec2"),rnr=o(" \u2014 "),yMe=a("code"),tnr=o("Wav2Vec2ForMaskedLM"),anr=o(" (Wav2Vec2 model)"),nnr=l(),DF=a("li"),xMe=a("strong"),snr=o("xlm"),lnr=o(" \u2014 "),DH=a("a"),inr=o("XLMWithLMHeadModel"),dnr=o(" (XLM model)"),mnr=l(),GF=a("li"),$Me=a("strong"),cnr=o("xlm-roberta"),fnr=o(" \u2014 "),GH=a("a"),gnr=o("XLMRobertaForMaskedLM"),hnr=o(" (XLM-RoBERTa model)"),unr=l(),OF=a("li"),kMe=a("strong"),pnr=o("xlm-roberta-xl"),_nr=o(" \u2014 "),OH=a("a"),bnr=o("XLMRobertaXLForMaskedLM"),vnr=o(" (XLM-RoBERTa-XL model)"),Fnr=l(),VF=a("li"),SMe=a("strong"),Tnr=o("yoso"),Mnr=o(" \u2014 "),VH=a("a"),Enr=o("YosoForMaskedLM"),Cnr=o(" (YOSO model)"),wnr=l(),XF=a("p"),Anr=o("The model is set in evaluation mode by default using "),RMe=a("code"),Lnr=o("model.eval()"),ynr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),PMe=a("code"),xnr=o("model.train()"),$nr=l(),F(zF.$$.fragment),uao=l(),Ud=a("h2"),QF=a("a"),BMe=a("span"),F(fk.$$.fragment),knr=l(),IMe=a("span"),Snr=o("AutoModelForSeq2SeqLM"),pao=l(),Go=a("div"),F(gk.$$.fragment),Rnr=l(),Hd=a("p"),Pnr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),XH=a("a"),Bnr=o("from_pretrained()"),Inr=o(" class method or the "),zH=a("a"),Nnr=o("from_config()"),qnr=o(` class
method.`),jnr=l(),hk=a("p"),Dnr=o("This class cannot be instantiated directly using "),NMe=a("code"),Gnr=o("__init__()"),Onr=o(" (throws an error)."),Vnr=l(),Lt=a("div"),F(uk.$$.fragment),Xnr=l(),qMe=a("p"),znr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Qnr=l(),Jd=a("p"),Wnr=o(`Note:
Loading a model from its configuration file does `),jMe=a("strong"),Unr=o("not"),Hnr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QH=a("a"),Jnr=o("from_pretrained()"),Ynr=o(" to load the model weights."),Znr=l(),F(WF.$$.fragment),Knr=l(),ao=a("div"),F(pk.$$.fragment),esr=l(),DMe=a("p"),osr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),rsr=l(),cn=a("p"),tsr=o("The model class to instantiate is selected based on the "),GMe=a("code"),asr=o("model_type"),nsr=o(` property of the config object (either
passed as an argument or loaded from `),OMe=a("code"),ssr=o("pretrained_model_name_or_path"),lsr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VMe=a("code"),isr=o("pretrained_model_name_or_path"),dsr=o(":"),msr=l(),he=a("ul"),UF=a("li"),XMe=a("strong"),csr=o("bart"),fsr=o(" \u2014 "),WH=a("a"),gsr=o("BartForConditionalGeneration"),hsr=o(" (BART model)"),usr=l(),HF=a("li"),zMe=a("strong"),psr=o("bigbird_pegasus"),_sr=o(" \u2014 "),UH=a("a"),bsr=o("BigBirdPegasusForConditionalGeneration"),vsr=o(" (BigBird-Pegasus model)"),Fsr=l(),JF=a("li"),QMe=a("strong"),Tsr=o("blenderbot"),Msr=o(" \u2014 "),HH=a("a"),Esr=o("BlenderbotForConditionalGeneration"),Csr=o(" (Blenderbot model)"),wsr=l(),YF=a("li"),WMe=a("strong"),Asr=o("blenderbot-small"),Lsr=o(" \u2014 "),JH=a("a"),ysr=o("BlenderbotSmallForConditionalGeneration"),xsr=o(" (BlenderbotSmall model)"),$sr=l(),ZF=a("li"),UMe=a("strong"),ksr=o("encoder-decoder"),Ssr=o(" \u2014 "),YH=a("a"),Rsr=o("EncoderDecoderModel"),Psr=o(" (Encoder decoder model)"),Bsr=l(),KF=a("li"),HMe=a("strong"),Isr=o("fsmt"),Nsr=o(" \u2014 "),ZH=a("a"),qsr=o("FSMTForConditionalGeneration"),jsr=o(" (FairSeq Machine-Translation model)"),Dsr=l(),eT=a("li"),JMe=a("strong"),Gsr=o("led"),Osr=o(" \u2014 "),KH=a("a"),Vsr=o("LEDForConditionalGeneration"),Xsr=o(" (LED model)"),zsr=l(),oT=a("li"),YMe=a("strong"),Qsr=o("longt5"),Wsr=o(" \u2014 "),eJ=a("a"),Usr=o("LongT5ForConditionalGeneration"),Hsr=o(" (LongT5 model)"),Jsr=l(),rT=a("li"),ZMe=a("strong"),Ysr=o("m2m_100"),Zsr=o(" \u2014 "),oJ=a("a"),Ksr=o("M2M100ForConditionalGeneration"),elr=o(" (M2M100 model)"),olr=l(),tT=a("li"),KMe=a("strong"),rlr=o("marian"),tlr=o(" \u2014 "),rJ=a("a"),alr=o("MarianMTModel"),nlr=o(" (Marian model)"),slr=l(),aT=a("li"),eEe=a("strong"),llr=o("mbart"),ilr=o(" \u2014 "),tJ=a("a"),dlr=o("MBartForConditionalGeneration"),mlr=o(" (mBART model)"),clr=l(),nT=a("li"),oEe=a("strong"),flr=o("mt5"),glr=o(" \u2014 "),aJ=a("a"),hlr=o("MT5ForConditionalGeneration"),ulr=o(" (MT5 model)"),plr=l(),sT=a("li"),rEe=a("strong"),_lr=o("mvp"),blr=o(" \u2014 "),nJ=a("a"),vlr=o("MvpForConditionalGeneration"),Flr=o(" (MVP model)"),Tlr=l(),lT=a("li"),tEe=a("strong"),Mlr=o("nllb"),Elr=o(" \u2014 "),sJ=a("a"),Clr=o("M2M100ForConditionalGeneration"),wlr=o(" (NLLB model)"),Alr=l(),iT=a("li"),aEe=a("strong"),Llr=o("pegasus"),ylr=o(" \u2014 "),lJ=a("a"),xlr=o("PegasusForConditionalGeneration"),$lr=o(" (Pegasus model)"),klr=l(),dT=a("li"),nEe=a("strong"),Slr=o("pegasus_x"),Rlr=o(" \u2014 "),iJ=a("a"),Plr=o("PegasusXForConditionalGeneration"),Blr=o(" (PEGASUS-X model)"),Ilr=l(),mT=a("li"),sEe=a("strong"),Nlr=o("plbart"),qlr=o(" \u2014 "),dJ=a("a"),jlr=o("PLBartForConditionalGeneration"),Dlr=o(" (PLBart model)"),Glr=l(),cT=a("li"),lEe=a("strong"),Olr=o("prophetnet"),Vlr=o(" \u2014 "),mJ=a("a"),Xlr=o("ProphetNetForConditionalGeneration"),zlr=o(" (ProphetNet model)"),Qlr=l(),fT=a("li"),iEe=a("strong"),Wlr=o("t5"),Ulr=o(" \u2014 "),cJ=a("a"),Hlr=o("T5ForConditionalGeneration"),Jlr=o(" (T5 model)"),Ylr=l(),gT=a("li"),dEe=a("strong"),Zlr=o("xlm-prophetnet"),Klr=o(" \u2014 "),fJ=a("a"),eir=o("XLMProphetNetForConditionalGeneration"),oir=o(" (XLM-ProphetNet model)"),rir=l(),hT=a("p"),tir=o("The model is set in evaluation mode by default using "),mEe=a("code"),air=o("model.eval()"),nir=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cEe=a("code"),sir=o("model.train()"),lir=l(),F(uT.$$.fragment),_ao=l(),Yd=a("h2"),pT=a("a"),fEe=a("span"),F(_k.$$.fragment),iir=l(),gEe=a("span"),dir=o("AutoModelForSequenceClassification"),bao=l(),Oo=a("div"),F(bk.$$.fragment),mir=l(),Zd=a("p"),cir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),gJ=a("a"),fir=o("from_pretrained()"),gir=o(" class method or the "),hJ=a("a"),hir=o("from_config()"),uir=o(` class
method.`),pir=l(),vk=a("p"),_ir=o("This class cannot be instantiated directly using "),hEe=a("code"),bir=o("__init__()"),vir=o(" (throws an error)."),Fir=l(),yt=a("div"),F(Fk.$$.fragment),Tir=l(),uEe=a("p"),Mir=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Eir=l(),Kd=a("p"),Cir=o(`Note:
Loading a model from its configuration file does `),pEe=a("strong"),wir=o("not"),Air=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uJ=a("a"),Lir=o("from_pretrained()"),yir=o(" to load the model weights."),xir=l(),F(_T.$$.fragment),$ir=l(),no=a("div"),F(Tk.$$.fragment),kir=l(),_Ee=a("p"),Sir=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Rir=l(),fn=a("p"),Pir=o("The model class to instantiate is selected based on the "),bEe=a("code"),Bir=o("model_type"),Iir=o(` property of the config object (either
passed as an argument or loaded from `),vEe=a("code"),Nir=o("pretrained_model_name_or_path"),qir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FEe=a("code"),jir=o("pretrained_model_name_or_path"),Dir=o(":"),Gir=l(),j=a("ul"),bT=a("li"),TEe=a("strong"),Oir=o("albert"),Vir=o(" \u2014 "),pJ=a("a"),Xir=o("AlbertForSequenceClassification"),zir=o(" (ALBERT model)"),Qir=l(),vT=a("li"),MEe=a("strong"),Wir=o("bart"),Uir=o(" \u2014 "),_J=a("a"),Hir=o("BartForSequenceClassification"),Jir=o(" (BART model)"),Yir=l(),FT=a("li"),EEe=a("strong"),Zir=o("bert"),Kir=o(" \u2014 "),bJ=a("a"),edr=o("BertForSequenceClassification"),odr=o(" (BERT model)"),rdr=l(),TT=a("li"),CEe=a("strong"),tdr=o("big_bird"),adr=o(" \u2014 "),vJ=a("a"),ndr=o("BigBirdForSequenceClassification"),sdr=o(" (BigBird model)"),ldr=l(),MT=a("li"),wEe=a("strong"),idr=o("bigbird_pegasus"),ddr=o(" \u2014 "),FJ=a("a"),mdr=o("BigBirdPegasusForSequenceClassification"),cdr=o(" (BigBird-Pegasus model)"),fdr=l(),ET=a("li"),AEe=a("strong"),gdr=o("bloom"),hdr=o(" \u2014 "),TJ=a("a"),udr=o("BloomForSequenceClassification"),pdr=o(" (BLOOM model)"),_dr=l(),CT=a("li"),LEe=a("strong"),bdr=o("camembert"),vdr=o(" \u2014 "),MJ=a("a"),Fdr=o("CamembertForSequenceClassification"),Tdr=o(" (CamemBERT model)"),Mdr=l(),wT=a("li"),yEe=a("strong"),Edr=o("canine"),Cdr=o(" \u2014 "),EJ=a("a"),wdr=o("CanineForSequenceClassification"),Adr=o(" (CANINE model)"),Ldr=l(),AT=a("li"),xEe=a("strong"),ydr=o("convbert"),xdr=o(" \u2014 "),CJ=a("a"),$dr=o("ConvBertForSequenceClassification"),kdr=o(" (ConvBERT model)"),Sdr=l(),LT=a("li"),$Ee=a("strong"),Rdr=o("ctrl"),Pdr=o(" \u2014 "),wJ=a("a"),Bdr=o("CTRLForSequenceClassification"),Idr=o(" (CTRL model)"),Ndr=l(),yT=a("li"),kEe=a("strong"),qdr=o("data2vec-text"),jdr=o(" \u2014 "),AJ=a("a"),Ddr=o("Data2VecTextForSequenceClassification"),Gdr=o(" (Data2VecText model)"),Odr=l(),xT=a("li"),SEe=a("strong"),Vdr=o("deberta"),Xdr=o(" \u2014 "),LJ=a("a"),zdr=o("DebertaForSequenceClassification"),Qdr=o(" (DeBERTa model)"),Wdr=l(),$T=a("li"),REe=a("strong"),Udr=o("deberta-v2"),Hdr=o(" \u2014 "),yJ=a("a"),Jdr=o("DebertaV2ForSequenceClassification"),Ydr=o(" (DeBERTa-v2 model)"),Zdr=l(),kT=a("li"),PEe=a("strong"),Kdr=o("distilbert"),emr=o(" \u2014 "),xJ=a("a"),omr=o("DistilBertForSequenceClassification"),rmr=o(" (DistilBERT model)"),tmr=l(),ST=a("li"),BEe=a("strong"),amr=o("electra"),nmr=o(" \u2014 "),$J=a("a"),smr=o("ElectraForSequenceClassification"),lmr=o(" (ELECTRA model)"),imr=l(),RT=a("li"),IEe=a("strong"),dmr=o("ernie"),mmr=o(" \u2014 "),kJ=a("a"),cmr=o("ErnieForSequenceClassification"),fmr=o(" (ERNIE model)"),gmr=l(),PT=a("li"),NEe=a("strong"),hmr=o("esm"),umr=o(" \u2014 "),SJ=a("a"),pmr=o("EsmForSequenceClassification"),_mr=o(" (ESM model)"),bmr=l(),BT=a("li"),qEe=a("strong"),vmr=o("flaubert"),Fmr=o(" \u2014 "),RJ=a("a"),Tmr=o("FlaubertForSequenceClassification"),Mmr=o(" (FlauBERT model)"),Emr=l(),IT=a("li"),jEe=a("strong"),Cmr=o("fnet"),wmr=o(" \u2014 "),PJ=a("a"),Amr=o("FNetForSequenceClassification"),Lmr=o(" (FNet model)"),ymr=l(),NT=a("li"),DEe=a("strong"),xmr=o("funnel"),$mr=o(" \u2014 "),BJ=a("a"),kmr=o("FunnelForSequenceClassification"),Smr=o(" (Funnel Transformer model)"),Rmr=l(),qT=a("li"),GEe=a("strong"),Pmr=o("gpt2"),Bmr=o(" \u2014 "),IJ=a("a"),Imr=o("GPT2ForSequenceClassification"),Nmr=o(" (OpenAI GPT-2 model)"),qmr=l(),jT=a("li"),OEe=a("strong"),jmr=o("gpt_neo"),Dmr=o(" \u2014 "),NJ=a("a"),Gmr=o("GPTNeoForSequenceClassification"),Omr=o(" (GPT Neo model)"),Vmr=l(),DT=a("li"),VEe=a("strong"),Xmr=o("gptj"),zmr=o(" \u2014 "),qJ=a("a"),Qmr=o("GPTJForSequenceClassification"),Wmr=o(" (GPT-J model)"),Umr=l(),GT=a("li"),XEe=a("strong"),Hmr=o("ibert"),Jmr=o(" \u2014 "),jJ=a("a"),Ymr=o("IBertForSequenceClassification"),Zmr=o(" (I-BERT model)"),Kmr=l(),OT=a("li"),zEe=a("strong"),ecr=o("layoutlm"),ocr=o(" \u2014 "),DJ=a("a"),rcr=o("LayoutLMForSequenceClassification"),tcr=o(" (LayoutLM model)"),acr=l(),VT=a("li"),QEe=a("strong"),ncr=o("layoutlmv2"),scr=o(" \u2014 "),GJ=a("a"),lcr=o("LayoutLMv2ForSequenceClassification"),icr=o(" (LayoutLMv2 model)"),dcr=l(),XT=a("li"),WEe=a("strong"),mcr=o("layoutlmv3"),ccr=o(" \u2014 "),OJ=a("a"),fcr=o("LayoutLMv3ForSequenceClassification"),gcr=o(" (LayoutLMv3 model)"),hcr=l(),zT=a("li"),UEe=a("strong"),ucr=o("led"),pcr=o(" \u2014 "),VJ=a("a"),_cr=o("LEDForSequenceClassification"),bcr=o(" (LED model)"),vcr=l(),QT=a("li"),HEe=a("strong"),Fcr=o("lilt"),Tcr=o(" \u2014 "),XJ=a("a"),Mcr=o("LiltForSequenceClassification"),Ecr=o(" (LiLT model)"),Ccr=l(),WT=a("li"),JEe=a("strong"),wcr=o("longformer"),Acr=o(" \u2014 "),zJ=a("a"),Lcr=o("LongformerForSequenceClassification"),ycr=o(" (Longformer model)"),xcr=l(),UT=a("li"),YEe=a("strong"),$cr=o("luke"),kcr=o(" \u2014 "),QJ=a("a"),Scr=o("LukeForSequenceClassification"),Rcr=o(" (LUKE model)"),Pcr=l(),HT=a("li"),ZEe=a("strong"),Bcr=o("markuplm"),Icr=o(" \u2014 "),WJ=a("a"),Ncr=o("MarkupLMForSequenceClassification"),qcr=o(" (MarkupLM model)"),jcr=l(),JT=a("li"),KEe=a("strong"),Dcr=o("mbart"),Gcr=o(" \u2014 "),UJ=a("a"),Ocr=o("MBartForSequenceClassification"),Vcr=o(" (mBART model)"),Xcr=l(),YT=a("li"),e4e=a("strong"),zcr=o("megatron-bert"),Qcr=o(" \u2014 "),HJ=a("a"),Wcr=o("MegatronBertForSequenceClassification"),Ucr=o(" (Megatron-BERT model)"),Hcr=l(),ZT=a("li"),o4e=a("strong"),Jcr=o("mobilebert"),Ycr=o(" \u2014 "),JJ=a("a"),Zcr=o("MobileBertForSequenceClassification"),Kcr=o(" (MobileBERT model)"),efr=l(),KT=a("li"),r4e=a("strong"),ofr=o("mpnet"),rfr=o(" \u2014 "),YJ=a("a"),tfr=o("MPNetForSequenceClassification"),afr=o(" (MPNet model)"),nfr=l(),eM=a("li"),t4e=a("strong"),sfr=o("mvp"),lfr=o(" \u2014 "),ZJ=a("a"),ifr=o("MvpForSequenceClassification"),dfr=o(" (MVP model)"),mfr=l(),oM=a("li"),a4e=a("strong"),cfr=o("nezha"),ffr=o(" \u2014 "),KJ=a("a"),gfr=o("NezhaForSequenceClassification"),hfr=o(" (Nezha model)"),ufr=l(),rM=a("li"),n4e=a("strong"),pfr=o("nystromformer"),_fr=o(" \u2014 "),eY=a("a"),bfr=o("NystromformerForSequenceClassification"),vfr=o(" (Nystr\xF6mformer model)"),Ffr=l(),tM=a("li"),s4e=a("strong"),Tfr=o("openai-gpt"),Mfr=o(" \u2014 "),oY=a("a"),Efr=o("OpenAIGPTForSequenceClassification"),Cfr=o(" (OpenAI GPT model)"),wfr=l(),aM=a("li"),l4e=a("strong"),Afr=o("opt"),Lfr=o(" \u2014 "),rY=a("a"),yfr=o("OPTForSequenceClassification"),xfr=o(" (OPT model)"),$fr=l(),nM=a("li"),i4e=a("strong"),kfr=o("perceiver"),Sfr=o(" \u2014 "),tY=a("a"),Rfr=o("PerceiverForSequenceClassification"),Pfr=o(" (Perceiver model)"),Bfr=l(),sM=a("li"),d4e=a("strong"),Ifr=o("plbart"),Nfr=o(" \u2014 "),aY=a("a"),qfr=o("PLBartForSequenceClassification"),jfr=o(" (PLBart model)"),Dfr=l(),lM=a("li"),m4e=a("strong"),Gfr=o("qdqbert"),Ofr=o(" \u2014 "),nY=a("a"),Vfr=o("QDQBertForSequenceClassification"),Xfr=o(" (QDQBert model)"),zfr=l(),iM=a("li"),c4e=a("strong"),Qfr=o("reformer"),Wfr=o(" \u2014 "),sY=a("a"),Ufr=o("ReformerForSequenceClassification"),Hfr=o(" (Reformer model)"),Jfr=l(),dM=a("li"),f4e=a("strong"),Yfr=o("rembert"),Zfr=o(" \u2014 "),lY=a("a"),Kfr=o("RemBertForSequenceClassification"),egr=o(" (RemBERT model)"),ogr=l(),mM=a("li"),g4e=a("strong"),rgr=o("roberta"),tgr=o(" \u2014 "),iY=a("a"),agr=o("RobertaForSequenceClassification"),ngr=o(" (RoBERTa model)"),sgr=l(),cM=a("li"),h4e=a("strong"),lgr=o("roformer"),igr=o(" \u2014 "),dY=a("a"),dgr=o("RoFormerForSequenceClassification"),mgr=o(" (RoFormer model)"),cgr=l(),fM=a("li"),u4e=a("strong"),fgr=o("squeezebert"),ggr=o(" \u2014 "),mY=a("a"),hgr=o("SqueezeBertForSequenceClassification"),ugr=o(" (SqueezeBERT model)"),pgr=l(),gM=a("li"),p4e=a("strong"),_gr=o("tapas"),bgr=o(" \u2014 "),cY=a("a"),vgr=o("TapasForSequenceClassification"),Fgr=o(" (TAPAS model)"),Tgr=l(),hM=a("li"),_4e=a("strong"),Mgr=o("transfo-xl"),Egr=o(" \u2014 "),fY=a("a"),Cgr=o("TransfoXLForSequenceClassification"),wgr=o(" (Transformer-XL model)"),Agr=l(),uM=a("li"),b4e=a("strong"),Lgr=o("xlm"),ygr=o(" \u2014 "),gY=a("a"),xgr=o("XLMForSequenceClassification"),$gr=o(" (XLM model)"),kgr=l(),pM=a("li"),v4e=a("strong"),Sgr=o("xlm-roberta"),Rgr=o(" \u2014 "),hY=a("a"),Pgr=o("XLMRobertaForSequenceClassification"),Bgr=o(" (XLM-RoBERTa model)"),Igr=l(),_M=a("li"),F4e=a("strong"),Ngr=o("xlm-roberta-xl"),qgr=o(" \u2014 "),uY=a("a"),jgr=o("XLMRobertaXLForSequenceClassification"),Dgr=o(" (XLM-RoBERTa-XL model)"),Ggr=l(),bM=a("li"),T4e=a("strong"),Ogr=o("xlnet"),Vgr=o(" \u2014 "),pY=a("a"),Xgr=o("XLNetForSequenceClassification"),zgr=o(" (XLNet model)"),Qgr=l(),vM=a("li"),M4e=a("strong"),Wgr=o("yoso"),Ugr=o(" \u2014 "),_Y=a("a"),Hgr=o("YosoForSequenceClassification"),Jgr=o(" (YOSO model)"),Ygr=l(),FM=a("p"),Zgr=o("The model is set in evaluation mode by default using "),E4e=a("code"),Kgr=o("model.eval()"),ehr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),C4e=a("code"),ohr=o("model.train()"),rhr=l(),F(TM.$$.fragment),vao=l(),em=a("h2"),MM=a("a"),w4e=a("span"),F(Mk.$$.fragment),thr=l(),A4e=a("span"),ahr=o("AutoModelForMultipleChoice"),Fao=l(),Vo=a("div"),F(Ek.$$.fragment),nhr=l(),om=a("p"),shr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),bY=a("a"),lhr=o("from_pretrained()"),ihr=o(" class method or the "),vY=a("a"),dhr=o("from_config()"),mhr=o(` class
method.`),chr=l(),Ck=a("p"),fhr=o("This class cannot be instantiated directly using "),L4e=a("code"),ghr=o("__init__()"),hhr=o(" (throws an error)."),uhr=l(),xt=a("div"),F(wk.$$.fragment),phr=l(),y4e=a("p"),_hr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),bhr=l(),rm=a("p"),vhr=o(`Note:
Loading a model from its configuration file does `),x4e=a("strong"),Fhr=o("not"),Thr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),FY=a("a"),Mhr=o("from_pretrained()"),Ehr=o(" to load the model weights."),Chr=l(),F(EM.$$.fragment),whr=l(),so=a("div"),F(Ak.$$.fragment),Ahr=l(),$4e=a("p"),Lhr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),yhr=l(),gn=a("p"),xhr=o("The model class to instantiate is selected based on the "),k4e=a("code"),$hr=o("model_type"),khr=o(` property of the config object (either
passed as an argument or loaded from `),S4e=a("code"),Shr=o("pretrained_model_name_or_path"),Rhr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R4e=a("code"),Phr=o("pretrained_model_name_or_path"),Bhr=o(":"),Ihr=l(),K=a("ul"),CM=a("li"),P4e=a("strong"),Nhr=o("albert"),qhr=o(" \u2014 "),TY=a("a"),jhr=o("AlbertForMultipleChoice"),Dhr=o(" (ALBERT model)"),Ghr=l(),wM=a("li"),B4e=a("strong"),Ohr=o("bert"),Vhr=o(" \u2014 "),MY=a("a"),Xhr=o("BertForMultipleChoice"),zhr=o(" (BERT model)"),Qhr=l(),AM=a("li"),I4e=a("strong"),Whr=o("big_bird"),Uhr=o(" \u2014 "),EY=a("a"),Hhr=o("BigBirdForMultipleChoice"),Jhr=o(" (BigBird model)"),Yhr=l(),LM=a("li"),N4e=a("strong"),Zhr=o("camembert"),Khr=o(" \u2014 "),CY=a("a"),eur=o("CamembertForMultipleChoice"),our=o(" (CamemBERT model)"),rur=l(),yM=a("li"),q4e=a("strong"),tur=o("canine"),aur=o(" \u2014 "),wY=a("a"),nur=o("CanineForMultipleChoice"),sur=o(" (CANINE model)"),lur=l(),xM=a("li"),j4e=a("strong"),iur=o("convbert"),dur=o(" \u2014 "),AY=a("a"),mur=o("ConvBertForMultipleChoice"),cur=o(" (ConvBERT model)"),fur=l(),$M=a("li"),D4e=a("strong"),gur=o("data2vec-text"),hur=o(" \u2014 "),LY=a("a"),uur=o("Data2VecTextForMultipleChoice"),pur=o(" (Data2VecText model)"),_ur=l(),kM=a("li"),G4e=a("strong"),bur=o("deberta-v2"),vur=o(" \u2014 "),yY=a("a"),Fur=o("DebertaV2ForMultipleChoice"),Tur=o(" (DeBERTa-v2 model)"),Mur=l(),SM=a("li"),O4e=a("strong"),Eur=o("distilbert"),Cur=o(" \u2014 "),xY=a("a"),wur=o("DistilBertForMultipleChoice"),Aur=o(" (DistilBERT model)"),Lur=l(),RM=a("li"),V4e=a("strong"),yur=o("electra"),xur=o(" \u2014 "),$Y=a("a"),$ur=o("ElectraForMultipleChoice"),kur=o(" (ELECTRA model)"),Sur=l(),PM=a("li"),X4e=a("strong"),Rur=o("ernie"),Pur=o(" \u2014 "),kY=a("a"),Bur=o("ErnieForMultipleChoice"),Iur=o(" (ERNIE model)"),Nur=l(),BM=a("li"),z4e=a("strong"),qur=o("flaubert"),jur=o(" \u2014 "),SY=a("a"),Dur=o("FlaubertForMultipleChoice"),Gur=o(" (FlauBERT model)"),Our=l(),IM=a("li"),Q4e=a("strong"),Vur=o("fnet"),Xur=o(" \u2014 "),RY=a("a"),zur=o("FNetForMultipleChoice"),Qur=o(" (FNet model)"),Wur=l(),NM=a("li"),W4e=a("strong"),Uur=o("funnel"),Hur=o(" \u2014 "),PY=a("a"),Jur=o("FunnelForMultipleChoice"),Yur=o(" (Funnel Transformer model)"),Zur=l(),qM=a("li"),U4e=a("strong"),Kur=o("ibert"),epr=o(" \u2014 "),BY=a("a"),opr=o("IBertForMultipleChoice"),rpr=o(" (I-BERT model)"),tpr=l(),jM=a("li"),H4e=a("strong"),apr=o("longformer"),npr=o(" \u2014 "),IY=a("a"),spr=o("LongformerForMultipleChoice"),lpr=o(" (Longformer model)"),ipr=l(),DM=a("li"),J4e=a("strong"),dpr=o("luke"),mpr=o(" \u2014 "),NY=a("a"),cpr=o("LukeForMultipleChoice"),fpr=o(" (LUKE model)"),gpr=l(),GM=a("li"),Y4e=a("strong"),hpr=o("megatron-bert"),upr=o(" \u2014 "),qY=a("a"),ppr=o("MegatronBertForMultipleChoice"),_pr=o(" (Megatron-BERT model)"),bpr=l(),OM=a("li"),Z4e=a("strong"),vpr=o("mobilebert"),Fpr=o(" \u2014 "),jY=a("a"),Tpr=o("MobileBertForMultipleChoice"),Mpr=o(" (MobileBERT model)"),Epr=l(),VM=a("li"),K4e=a("strong"),Cpr=o("mpnet"),wpr=o(" \u2014 "),DY=a("a"),Apr=o("MPNetForMultipleChoice"),Lpr=o(" (MPNet model)"),ypr=l(),XM=a("li"),eCe=a("strong"),xpr=o("nezha"),$pr=o(" \u2014 "),GY=a("a"),kpr=o("NezhaForMultipleChoice"),Spr=o(" (Nezha model)"),Rpr=l(),zM=a("li"),oCe=a("strong"),Ppr=o("nystromformer"),Bpr=o(" \u2014 "),OY=a("a"),Ipr=o("NystromformerForMultipleChoice"),Npr=o(" (Nystr\xF6mformer model)"),qpr=l(),QM=a("li"),rCe=a("strong"),jpr=o("qdqbert"),Dpr=o(" \u2014 "),VY=a("a"),Gpr=o("QDQBertForMultipleChoice"),Opr=o(" (QDQBert model)"),Vpr=l(),WM=a("li"),tCe=a("strong"),Xpr=o("rembert"),zpr=o(" \u2014 "),XY=a("a"),Qpr=o("RemBertForMultipleChoice"),Wpr=o(" (RemBERT model)"),Upr=l(),UM=a("li"),aCe=a("strong"),Hpr=o("roberta"),Jpr=o(" \u2014 "),zY=a("a"),Ypr=o("RobertaForMultipleChoice"),Zpr=o(" (RoBERTa model)"),Kpr=l(),HM=a("li"),nCe=a("strong"),e_r=o("roformer"),o_r=o(" \u2014 "),QY=a("a"),r_r=o("RoFormerForMultipleChoice"),t_r=o(" (RoFormer model)"),a_r=l(),JM=a("li"),sCe=a("strong"),n_r=o("squeezebert"),s_r=o(" \u2014 "),WY=a("a"),l_r=o("SqueezeBertForMultipleChoice"),i_r=o(" (SqueezeBERT model)"),d_r=l(),YM=a("li"),lCe=a("strong"),m_r=o("xlm"),c_r=o(" \u2014 "),UY=a("a"),f_r=o("XLMForMultipleChoice"),g_r=o(" (XLM model)"),h_r=l(),ZM=a("li"),iCe=a("strong"),u_r=o("xlm-roberta"),p_r=o(" \u2014 "),HY=a("a"),__r=o("XLMRobertaForMultipleChoice"),b_r=o(" (XLM-RoBERTa model)"),v_r=l(),KM=a("li"),dCe=a("strong"),F_r=o("xlm-roberta-xl"),T_r=o(" \u2014 "),JY=a("a"),M_r=o("XLMRobertaXLForMultipleChoice"),E_r=o(" (XLM-RoBERTa-XL model)"),C_r=l(),eE=a("li"),mCe=a("strong"),w_r=o("xlnet"),A_r=o(" \u2014 "),YY=a("a"),L_r=o("XLNetForMultipleChoice"),y_r=o(" (XLNet model)"),x_r=l(),oE=a("li"),cCe=a("strong"),$_r=o("yoso"),k_r=o(" \u2014 "),ZY=a("a"),S_r=o("YosoForMultipleChoice"),R_r=o(" (YOSO model)"),P_r=l(),rE=a("p"),B_r=o("The model is set in evaluation mode by default using "),fCe=a("code"),I_r=o("model.eval()"),N_r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gCe=a("code"),q_r=o("model.train()"),j_r=l(),F(tE.$$.fragment),Tao=l(),tm=a("h2"),aE=a("a"),hCe=a("span"),F(Lk.$$.fragment),D_r=l(),uCe=a("span"),G_r=o("AutoModelForNextSentencePrediction"),Mao=l(),Xo=a("div"),F(yk.$$.fragment),O_r=l(),am=a("p"),V_r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),KY=a("a"),X_r=o("from_pretrained()"),z_r=o(" class method or the "),eZ=a("a"),Q_r=o("from_config()"),W_r=o(` class
method.`),U_r=l(),xk=a("p"),H_r=o("This class cannot be instantiated directly using "),pCe=a("code"),J_r=o("__init__()"),Y_r=o(" (throws an error)."),Z_r=l(),$t=a("div"),F($k.$$.fragment),K_r=l(),_Ce=a("p"),e1r=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),o1r=l(),nm=a("p"),r1r=o(`Note:
Loading a model from its configuration file does `),bCe=a("strong"),t1r=o("not"),a1r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oZ=a("a"),n1r=o("from_pretrained()"),s1r=o(" to load the model weights."),l1r=l(),F(nE.$$.fragment),i1r=l(),lo=a("div"),F(kk.$$.fragment),d1r=l(),vCe=a("p"),m1r=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),c1r=l(),hn=a("p"),f1r=o("The model class to instantiate is selected based on the "),FCe=a("code"),g1r=o("model_type"),h1r=o(` property of the config object (either
passed as an argument or loaded from `),TCe=a("code"),u1r=o("pretrained_model_name_or_path"),p1r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MCe=a("code"),_1r=o("pretrained_model_name_or_path"),b1r=o(":"),v1r=l(),Ue=a("ul"),sE=a("li"),ECe=a("strong"),F1r=o("bert"),T1r=o(" \u2014 "),rZ=a("a"),M1r=o("BertForNextSentencePrediction"),E1r=o(" (BERT model)"),C1r=l(),lE=a("li"),CCe=a("strong"),w1r=o("ernie"),A1r=o(" \u2014 "),tZ=a("a"),L1r=o("ErnieForNextSentencePrediction"),y1r=o(" (ERNIE model)"),x1r=l(),iE=a("li"),wCe=a("strong"),$1r=o("fnet"),k1r=o(" \u2014 "),aZ=a("a"),S1r=o("FNetForNextSentencePrediction"),R1r=o(" (FNet model)"),P1r=l(),dE=a("li"),ACe=a("strong"),B1r=o("megatron-bert"),I1r=o(" \u2014 "),nZ=a("a"),N1r=o("MegatronBertForNextSentencePrediction"),q1r=o(" (Megatron-BERT model)"),j1r=l(),mE=a("li"),LCe=a("strong"),D1r=o("mobilebert"),G1r=o(" \u2014 "),sZ=a("a"),O1r=o("MobileBertForNextSentencePrediction"),V1r=o(" (MobileBERT model)"),X1r=l(),cE=a("li"),yCe=a("strong"),z1r=o("nezha"),Q1r=o(" \u2014 "),lZ=a("a"),W1r=o("NezhaForNextSentencePrediction"),U1r=o(" (Nezha model)"),H1r=l(),fE=a("li"),xCe=a("strong"),J1r=o("qdqbert"),Y1r=o(" \u2014 "),iZ=a("a"),Z1r=o("QDQBertForNextSentencePrediction"),K1r=o(" (QDQBert model)"),e2r=l(),gE=a("p"),o2r=o("The model is set in evaluation mode by default using "),$Ce=a("code"),r2r=o("model.eval()"),t2r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kCe=a("code"),a2r=o("model.train()"),n2r=l(),F(hE.$$.fragment),Eao=l(),sm=a("h2"),uE=a("a"),SCe=a("span"),F(Sk.$$.fragment),s2r=l(),RCe=a("span"),l2r=o("AutoModelForTokenClassification"),Cao=l(),zo=a("div"),F(Rk.$$.fragment),i2r=l(),lm=a("p"),d2r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),dZ=a("a"),m2r=o("from_pretrained()"),c2r=o(" class method or the "),mZ=a("a"),f2r=o("from_config()"),g2r=o(` class
method.`),h2r=l(),Pk=a("p"),u2r=o("This class cannot be instantiated directly using "),PCe=a("code"),p2r=o("__init__()"),_2r=o(" (throws an error)."),b2r=l(),kt=a("div"),F(Bk.$$.fragment),v2r=l(),BCe=a("p"),F2r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),T2r=l(),im=a("p"),M2r=o(`Note:
Loading a model from its configuration file does `),ICe=a("strong"),E2r=o("not"),C2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cZ=a("a"),w2r=o("from_pretrained()"),A2r=o(" to load the model weights."),L2r=l(),F(pE.$$.fragment),y2r=l(),io=a("div"),F(Ik.$$.fragment),x2r=l(),NCe=a("p"),$2r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),k2r=l(),un=a("p"),S2r=o("The model class to instantiate is selected based on the "),qCe=a("code"),R2r=o("model_type"),P2r=o(` property of the config object (either
passed as an argument or loaded from `),jCe=a("code"),B2r=o("pretrained_model_name_or_path"),I2r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DCe=a("code"),N2r=o("pretrained_model_name_or_path"),q2r=o(":"),j2r=l(),U=a("ul"),_E=a("li"),GCe=a("strong"),D2r=o("albert"),G2r=o(" \u2014 "),fZ=a("a"),O2r=o("AlbertForTokenClassification"),V2r=o(" (ALBERT model)"),X2r=l(),bE=a("li"),OCe=a("strong"),z2r=o("bert"),Q2r=o(" \u2014 "),gZ=a("a"),W2r=o("BertForTokenClassification"),U2r=o(" (BERT model)"),H2r=l(),vE=a("li"),VCe=a("strong"),J2r=o("big_bird"),Y2r=o(" \u2014 "),hZ=a("a"),Z2r=o("BigBirdForTokenClassification"),K2r=o(" (BigBird model)"),ebr=l(),FE=a("li"),XCe=a("strong"),obr=o("bloom"),rbr=o(" \u2014 "),uZ=a("a"),tbr=o("BloomForTokenClassification"),abr=o(" (BLOOM model)"),nbr=l(),TE=a("li"),zCe=a("strong"),sbr=o("camembert"),lbr=o(" \u2014 "),pZ=a("a"),ibr=o("CamembertForTokenClassification"),dbr=o(" (CamemBERT model)"),mbr=l(),ME=a("li"),QCe=a("strong"),cbr=o("canine"),fbr=o(" \u2014 "),_Z=a("a"),gbr=o("CanineForTokenClassification"),hbr=o(" (CANINE model)"),ubr=l(),EE=a("li"),WCe=a("strong"),pbr=o("convbert"),_br=o(" \u2014 "),bZ=a("a"),bbr=o("ConvBertForTokenClassification"),vbr=o(" (ConvBERT model)"),Fbr=l(),CE=a("li"),UCe=a("strong"),Tbr=o("data2vec-text"),Mbr=o(" \u2014 "),vZ=a("a"),Ebr=o("Data2VecTextForTokenClassification"),Cbr=o(" (Data2VecText model)"),wbr=l(),wE=a("li"),HCe=a("strong"),Abr=o("deberta"),Lbr=o(" \u2014 "),FZ=a("a"),ybr=o("DebertaForTokenClassification"),xbr=o(" (DeBERTa model)"),$br=l(),AE=a("li"),JCe=a("strong"),kbr=o("deberta-v2"),Sbr=o(" \u2014 "),TZ=a("a"),Rbr=o("DebertaV2ForTokenClassification"),Pbr=o(" (DeBERTa-v2 model)"),Bbr=l(),LE=a("li"),YCe=a("strong"),Ibr=o("distilbert"),Nbr=o(" \u2014 "),MZ=a("a"),qbr=o("DistilBertForTokenClassification"),jbr=o(" (DistilBERT model)"),Dbr=l(),yE=a("li"),ZCe=a("strong"),Gbr=o("electra"),Obr=o(" \u2014 "),EZ=a("a"),Vbr=o("ElectraForTokenClassification"),Xbr=o(" (ELECTRA model)"),zbr=l(),xE=a("li"),KCe=a("strong"),Qbr=o("ernie"),Wbr=o(" \u2014 "),CZ=a("a"),Ubr=o("ErnieForTokenClassification"),Hbr=o(" (ERNIE model)"),Jbr=l(),$E=a("li"),e3e=a("strong"),Ybr=o("esm"),Zbr=o(" \u2014 "),wZ=a("a"),Kbr=o("EsmForTokenClassification"),evr=o(" (ESM model)"),ovr=l(),kE=a("li"),o3e=a("strong"),rvr=o("flaubert"),tvr=o(" \u2014 "),AZ=a("a"),avr=o("FlaubertForTokenClassification"),nvr=o(" (FlauBERT model)"),svr=l(),SE=a("li"),r3e=a("strong"),lvr=o("fnet"),ivr=o(" \u2014 "),LZ=a("a"),dvr=o("FNetForTokenClassification"),mvr=o(" (FNet model)"),cvr=l(),RE=a("li"),t3e=a("strong"),fvr=o("funnel"),gvr=o(" \u2014 "),yZ=a("a"),hvr=o("FunnelForTokenClassification"),uvr=o(" (Funnel Transformer model)"),pvr=l(),PE=a("li"),a3e=a("strong"),_vr=o("gpt2"),bvr=o(" \u2014 "),xZ=a("a"),vvr=o("GPT2ForTokenClassification"),Fvr=o(" (OpenAI GPT-2 model)"),Tvr=l(),BE=a("li"),n3e=a("strong"),Mvr=o("ibert"),Evr=o(" \u2014 "),$Z=a("a"),Cvr=o("IBertForTokenClassification"),wvr=o(" (I-BERT model)"),Avr=l(),IE=a("li"),s3e=a("strong"),Lvr=o("layoutlm"),yvr=o(" \u2014 "),kZ=a("a"),xvr=o("LayoutLMForTokenClassification"),$vr=o(" (LayoutLM model)"),kvr=l(),NE=a("li"),l3e=a("strong"),Svr=o("layoutlmv2"),Rvr=o(" \u2014 "),SZ=a("a"),Pvr=o("LayoutLMv2ForTokenClassification"),Bvr=o(" (LayoutLMv2 model)"),Ivr=l(),qE=a("li"),i3e=a("strong"),Nvr=o("layoutlmv3"),qvr=o(" \u2014 "),RZ=a("a"),jvr=o("LayoutLMv3ForTokenClassification"),Dvr=o(" (LayoutLMv3 model)"),Gvr=l(),jE=a("li"),d3e=a("strong"),Ovr=o("lilt"),Vvr=o(" \u2014 "),PZ=a("a"),Xvr=o("LiltForTokenClassification"),zvr=o(" (LiLT model)"),Qvr=l(),DE=a("li"),m3e=a("strong"),Wvr=o("longformer"),Uvr=o(" \u2014 "),BZ=a("a"),Hvr=o("LongformerForTokenClassification"),Jvr=o(" (Longformer model)"),Yvr=l(),GE=a("li"),c3e=a("strong"),Zvr=o("luke"),Kvr=o(" \u2014 "),IZ=a("a"),eFr=o("LukeForTokenClassification"),oFr=o(" (LUKE model)"),rFr=l(),OE=a("li"),f3e=a("strong"),tFr=o("markuplm"),aFr=o(" \u2014 "),NZ=a("a"),nFr=o("MarkupLMForTokenClassification"),sFr=o(" (MarkupLM model)"),lFr=l(),VE=a("li"),g3e=a("strong"),iFr=o("megatron-bert"),dFr=o(" \u2014 "),qZ=a("a"),mFr=o("MegatronBertForTokenClassification"),cFr=o(" (Megatron-BERT model)"),fFr=l(),XE=a("li"),h3e=a("strong"),gFr=o("mobilebert"),hFr=o(" \u2014 "),jZ=a("a"),uFr=o("MobileBertForTokenClassification"),pFr=o(" (MobileBERT model)"),_Fr=l(),zE=a("li"),u3e=a("strong"),bFr=o("mpnet"),vFr=o(" \u2014 "),DZ=a("a"),FFr=o("MPNetForTokenClassification"),TFr=o(" (MPNet model)"),MFr=l(),QE=a("li"),p3e=a("strong"),EFr=o("nezha"),CFr=o(" \u2014 "),GZ=a("a"),wFr=o("NezhaForTokenClassification"),AFr=o(" (Nezha model)"),LFr=l(),WE=a("li"),_3e=a("strong"),yFr=o("nystromformer"),xFr=o(" \u2014 "),OZ=a("a"),$Fr=o("NystromformerForTokenClassification"),kFr=o(" (Nystr\xF6mformer model)"),SFr=l(),UE=a("li"),b3e=a("strong"),RFr=o("qdqbert"),PFr=o(" \u2014 "),VZ=a("a"),BFr=o("QDQBertForTokenClassification"),IFr=o(" (QDQBert model)"),NFr=l(),HE=a("li"),v3e=a("strong"),qFr=o("rembert"),jFr=o(" \u2014 "),XZ=a("a"),DFr=o("RemBertForTokenClassification"),GFr=o(" (RemBERT model)"),OFr=l(),JE=a("li"),F3e=a("strong"),VFr=o("roberta"),XFr=o(" \u2014 "),zZ=a("a"),zFr=o("RobertaForTokenClassification"),QFr=o(" (RoBERTa model)"),WFr=l(),YE=a("li"),T3e=a("strong"),UFr=o("roformer"),HFr=o(" \u2014 "),QZ=a("a"),JFr=o("RoFormerForTokenClassification"),YFr=o(" (RoFormer model)"),ZFr=l(),ZE=a("li"),M3e=a("strong"),KFr=o("squeezebert"),eTr=o(" \u2014 "),WZ=a("a"),oTr=o("SqueezeBertForTokenClassification"),rTr=o(" (SqueezeBERT model)"),tTr=l(),KE=a("li"),E3e=a("strong"),aTr=o("xlm"),nTr=o(" \u2014 "),UZ=a("a"),sTr=o("XLMForTokenClassification"),lTr=o(" (XLM model)"),iTr=l(),e4=a("li"),C3e=a("strong"),dTr=o("xlm-roberta"),mTr=o(" \u2014 "),HZ=a("a"),cTr=o("XLMRobertaForTokenClassification"),fTr=o(" (XLM-RoBERTa model)"),gTr=l(),o4=a("li"),w3e=a("strong"),hTr=o("xlm-roberta-xl"),uTr=o(" \u2014 "),JZ=a("a"),pTr=o("XLMRobertaXLForTokenClassification"),_Tr=o(" (XLM-RoBERTa-XL model)"),bTr=l(),r4=a("li"),A3e=a("strong"),vTr=o("xlnet"),FTr=o(" \u2014 "),YZ=a("a"),TTr=o("XLNetForTokenClassification"),MTr=o(" (XLNet model)"),ETr=l(),t4=a("li"),L3e=a("strong"),CTr=o("yoso"),wTr=o(" \u2014 "),ZZ=a("a"),ATr=o("YosoForTokenClassification"),LTr=o(" (YOSO model)"),yTr=l(),a4=a("p"),xTr=o("The model is set in evaluation mode by default using "),y3e=a("code"),$Tr=o("model.eval()"),kTr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),x3e=a("code"),STr=o("model.train()"),RTr=l(),F(n4.$$.fragment),wao=l(),dm=a("h2"),s4=a("a"),$3e=a("span"),F(Nk.$$.fragment),PTr=l(),k3e=a("span"),BTr=o("AutoModelForQuestionAnswering"),Aao=l(),Qo=a("div"),F(qk.$$.fragment),ITr=l(),mm=a("p"),NTr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),KZ=a("a"),qTr=o("from_pretrained()"),jTr=o(" class method or the "),eK=a("a"),DTr=o("from_config()"),GTr=o(` class
method.`),OTr=l(),jk=a("p"),VTr=o("This class cannot be instantiated directly using "),S3e=a("code"),XTr=o("__init__()"),zTr=o(" (throws an error)."),QTr=l(),St=a("div"),F(Dk.$$.fragment),WTr=l(),R3e=a("p"),UTr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),HTr=l(),cm=a("p"),JTr=o(`Note:
Loading a model from its configuration file does `),P3e=a("strong"),YTr=o("not"),ZTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oK=a("a"),KTr=o("from_pretrained()"),eMr=o(" to load the model weights."),oMr=l(),F(l4.$$.fragment),rMr=l(),mo=a("div"),F(Gk.$$.fragment),tMr=l(),B3e=a("p"),aMr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),nMr=l(),pn=a("p"),sMr=o("The model class to instantiate is selected based on the "),I3e=a("code"),lMr=o("model_type"),iMr=o(` property of the config object (either
passed as an argument or loaded from `),N3e=a("code"),dMr=o("pretrained_model_name_or_path"),mMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q3e=a("code"),cMr=o("pretrained_model_name_or_path"),fMr=o(":"),gMr=l(),O=a("ul"),i4=a("li"),j3e=a("strong"),hMr=o("albert"),uMr=o(" \u2014 "),rK=a("a"),pMr=o("AlbertForQuestionAnswering"),_Mr=o(" (ALBERT model)"),bMr=l(),d4=a("li"),D3e=a("strong"),vMr=o("bart"),FMr=o(" \u2014 "),tK=a("a"),TMr=o("BartForQuestionAnswering"),MMr=o(" (BART model)"),EMr=l(),m4=a("li"),G3e=a("strong"),CMr=o("bert"),wMr=o(" \u2014 "),aK=a("a"),AMr=o("BertForQuestionAnswering"),LMr=o(" (BERT model)"),yMr=l(),c4=a("li"),O3e=a("strong"),xMr=o("big_bird"),$Mr=o(" \u2014 "),nK=a("a"),kMr=o("BigBirdForQuestionAnswering"),SMr=o(" (BigBird model)"),RMr=l(),f4=a("li"),V3e=a("strong"),PMr=o("bigbird_pegasus"),BMr=o(" \u2014 "),sK=a("a"),IMr=o("BigBirdPegasusForQuestionAnswering"),NMr=o(" (BigBird-Pegasus model)"),qMr=l(),g4=a("li"),X3e=a("strong"),jMr=o("bloom"),DMr=o(" \u2014 "),lK=a("a"),GMr=o("BloomForQuestionAnswering"),OMr=o(" (BLOOM model)"),VMr=l(),h4=a("li"),z3e=a("strong"),XMr=o("camembert"),zMr=o(" \u2014 "),iK=a("a"),QMr=o("CamembertForQuestionAnswering"),WMr=o(" (CamemBERT model)"),UMr=l(),u4=a("li"),Q3e=a("strong"),HMr=o("canine"),JMr=o(" \u2014 "),dK=a("a"),YMr=o("CanineForQuestionAnswering"),ZMr=o(" (CANINE model)"),KMr=l(),p4=a("li"),W3e=a("strong"),eEr=o("convbert"),oEr=o(" \u2014 "),mK=a("a"),rEr=o("ConvBertForQuestionAnswering"),tEr=o(" (ConvBERT model)"),aEr=l(),_4=a("li"),U3e=a("strong"),nEr=o("data2vec-text"),sEr=o(" \u2014 "),cK=a("a"),lEr=o("Data2VecTextForQuestionAnswering"),iEr=o(" (Data2VecText model)"),dEr=l(),b4=a("li"),H3e=a("strong"),mEr=o("deberta"),cEr=o(" \u2014 "),fK=a("a"),fEr=o("DebertaForQuestionAnswering"),gEr=o(" (DeBERTa model)"),hEr=l(),v4=a("li"),J3e=a("strong"),uEr=o("deberta-v2"),pEr=o(" \u2014 "),gK=a("a"),_Er=o("DebertaV2ForQuestionAnswering"),bEr=o(" (DeBERTa-v2 model)"),vEr=l(),F4=a("li"),Y3e=a("strong"),FEr=o("distilbert"),TEr=o(" \u2014 "),hK=a("a"),MEr=o("DistilBertForQuestionAnswering"),EEr=o(" (DistilBERT model)"),CEr=l(),T4=a("li"),Z3e=a("strong"),wEr=o("electra"),AEr=o(" \u2014 "),uK=a("a"),LEr=o("ElectraForQuestionAnswering"),yEr=o(" (ELECTRA model)"),xEr=l(),M4=a("li"),K3e=a("strong"),$Er=o("ernie"),kEr=o(" \u2014 "),pK=a("a"),SEr=o("ErnieForQuestionAnswering"),REr=o(" (ERNIE model)"),PEr=l(),E4=a("li"),e5e=a("strong"),BEr=o("flaubert"),IEr=o(" \u2014 "),_K=a("a"),NEr=o("FlaubertForQuestionAnsweringSimple"),qEr=o(" (FlauBERT model)"),jEr=l(),C4=a("li"),o5e=a("strong"),DEr=o("fnet"),GEr=o(" \u2014 "),bK=a("a"),OEr=o("FNetForQuestionAnswering"),VEr=o(" (FNet model)"),XEr=l(),w4=a("li"),r5e=a("strong"),zEr=o("funnel"),QEr=o(" \u2014 "),vK=a("a"),WEr=o("FunnelForQuestionAnswering"),UEr=o(" (Funnel Transformer model)"),HEr=l(),A4=a("li"),t5e=a("strong"),JEr=o("gptj"),YEr=o(" \u2014 "),FK=a("a"),ZEr=o("GPTJForQuestionAnswering"),KEr=o(" (GPT-J model)"),e4r=l(),L4=a("li"),a5e=a("strong"),o4r=o("ibert"),r4r=o(" \u2014 "),TK=a("a"),t4r=o("IBertForQuestionAnswering"),a4r=o(" (I-BERT model)"),n4r=l(),y4=a("li"),n5e=a("strong"),s4r=o("layoutlmv2"),l4r=o(" \u2014 "),MK=a("a"),i4r=o("LayoutLMv2ForQuestionAnswering"),d4r=o(" (LayoutLMv2 model)"),m4r=l(),x4=a("li"),s5e=a("strong"),c4r=o("layoutlmv3"),f4r=o(" \u2014 "),EK=a("a"),g4r=o("LayoutLMv3ForQuestionAnswering"),h4r=o(" (LayoutLMv3 model)"),u4r=l(),$4=a("li"),l5e=a("strong"),p4r=o("led"),_4r=o(" \u2014 "),CK=a("a"),b4r=o("LEDForQuestionAnswering"),v4r=o(" (LED model)"),F4r=l(),k4=a("li"),i5e=a("strong"),T4r=o("lilt"),M4r=o(" \u2014 "),wK=a("a"),E4r=o("LiltForQuestionAnswering"),C4r=o(" (LiLT model)"),w4r=l(),S4=a("li"),d5e=a("strong"),A4r=o("longformer"),L4r=o(" \u2014 "),AK=a("a"),y4r=o("LongformerForQuestionAnswering"),x4r=o(" (Longformer model)"),$4r=l(),R4=a("li"),m5e=a("strong"),k4r=o("luke"),S4r=o(" \u2014 "),LK=a("a"),R4r=o("LukeForQuestionAnswering"),P4r=o(" (LUKE model)"),B4r=l(),P4=a("li"),c5e=a("strong"),I4r=o("lxmert"),N4r=o(" \u2014 "),yK=a("a"),q4r=o("LxmertForQuestionAnswering"),j4r=o(" (LXMERT model)"),D4r=l(),B4=a("li"),f5e=a("strong"),G4r=o("markuplm"),O4r=o(" \u2014 "),xK=a("a"),V4r=o("MarkupLMForQuestionAnswering"),X4r=o(" (MarkupLM model)"),z4r=l(),I4=a("li"),g5e=a("strong"),Q4r=o("mbart"),W4r=o(" \u2014 "),$K=a("a"),U4r=o("MBartForQuestionAnswering"),H4r=o(" (mBART model)"),J4r=l(),N4=a("li"),h5e=a("strong"),Y4r=o("megatron-bert"),Z4r=o(" \u2014 "),kK=a("a"),K4r=o("MegatronBertForQuestionAnswering"),eCr=o(" (Megatron-BERT model)"),oCr=l(),q4=a("li"),u5e=a("strong"),rCr=o("mobilebert"),tCr=o(" \u2014 "),SK=a("a"),aCr=o("MobileBertForQuestionAnswering"),nCr=o(" (MobileBERT model)"),sCr=l(),j4=a("li"),p5e=a("strong"),lCr=o("mpnet"),iCr=o(" \u2014 "),RK=a("a"),dCr=o("MPNetForQuestionAnswering"),mCr=o(" (MPNet model)"),cCr=l(),D4=a("li"),_5e=a("strong"),fCr=o("mvp"),gCr=o(" \u2014 "),PK=a("a"),hCr=o("MvpForQuestionAnswering"),uCr=o(" (MVP model)"),pCr=l(),G4=a("li"),b5e=a("strong"),_Cr=o("nezha"),bCr=o(" \u2014 "),BK=a("a"),vCr=o("NezhaForQuestionAnswering"),FCr=o(" (Nezha model)"),TCr=l(),O4=a("li"),v5e=a("strong"),MCr=o("nystromformer"),ECr=o(" \u2014 "),IK=a("a"),CCr=o("NystromformerForQuestionAnswering"),wCr=o(" (Nystr\xF6mformer model)"),ACr=l(),V4=a("li"),F5e=a("strong"),LCr=o("opt"),yCr=o(" \u2014 "),NK=a("a"),xCr=o("OPTForQuestionAnswering"),$Cr=o(" (OPT model)"),kCr=l(),X4=a("li"),T5e=a("strong"),SCr=o("qdqbert"),RCr=o(" \u2014 "),qK=a("a"),PCr=o("QDQBertForQuestionAnswering"),BCr=o(" (QDQBert model)"),ICr=l(),z4=a("li"),M5e=a("strong"),NCr=o("reformer"),qCr=o(" \u2014 "),jK=a("a"),jCr=o("ReformerForQuestionAnswering"),DCr=o(" (Reformer model)"),GCr=l(),Q4=a("li"),E5e=a("strong"),OCr=o("rembert"),VCr=o(" \u2014 "),DK=a("a"),XCr=o("RemBertForQuestionAnswering"),zCr=o(" (RemBERT model)"),QCr=l(),W4=a("li"),C5e=a("strong"),WCr=o("roberta"),UCr=o(" \u2014 "),GK=a("a"),HCr=o("RobertaForQuestionAnswering"),JCr=o(" (RoBERTa model)"),YCr=l(),U4=a("li"),w5e=a("strong"),ZCr=o("roformer"),KCr=o(" \u2014 "),OK=a("a"),e3r=o("RoFormerForQuestionAnswering"),o3r=o(" (RoFormer model)"),r3r=l(),H4=a("li"),A5e=a("strong"),t3r=o("splinter"),a3r=o(" \u2014 "),VK=a("a"),n3r=o("SplinterForQuestionAnswering"),s3r=o(" (Splinter model)"),l3r=l(),J4=a("li"),L5e=a("strong"),i3r=o("squeezebert"),d3r=o(" \u2014 "),XK=a("a"),m3r=o("SqueezeBertForQuestionAnswering"),c3r=o(" (SqueezeBERT model)"),f3r=l(),Y4=a("li"),y5e=a("strong"),g3r=o("xlm"),h3r=o(" \u2014 "),zK=a("a"),u3r=o("XLMForQuestionAnsweringSimple"),p3r=o(" (XLM model)"),_3r=l(),Z4=a("li"),x5e=a("strong"),b3r=o("xlm-roberta"),v3r=o(" \u2014 "),QK=a("a"),F3r=o("XLMRobertaForQuestionAnswering"),T3r=o(" (XLM-RoBERTa model)"),M3r=l(),K4=a("li"),$5e=a("strong"),E3r=o("xlm-roberta-xl"),C3r=o(" \u2014 "),WK=a("a"),w3r=o("XLMRobertaXLForQuestionAnswering"),A3r=o(" (XLM-RoBERTa-XL model)"),L3r=l(),eC=a("li"),k5e=a("strong"),y3r=o("xlnet"),x3r=o(" \u2014 "),UK=a("a"),$3r=o("XLNetForQuestionAnsweringSimple"),k3r=o(" (XLNet model)"),S3r=l(),oC=a("li"),S5e=a("strong"),R3r=o("yoso"),P3r=o(" \u2014 "),HK=a("a"),B3r=o("YosoForQuestionAnswering"),I3r=o(" (YOSO model)"),N3r=l(),rC=a("p"),q3r=o("The model is set in evaluation mode by default using "),R5e=a("code"),j3r=o("model.eval()"),D3r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P5e=a("code"),G3r=o("model.train()"),O3r=l(),F(tC.$$.fragment),Lao=l(),fm=a("h2"),aC=a("a"),B5e=a("span"),F(Ok.$$.fragment),V3r=l(),I5e=a("span"),X3r=o("AutoModelForTableQuestionAnswering"),yao=l(),Wo=a("div"),F(Vk.$$.fragment),z3r=l(),gm=a("p"),Q3r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),JK=a("a"),W3r=o("from_pretrained()"),U3r=o(" class method or the "),YK=a("a"),H3r=o("from_config()"),J3r=o(` class
method.`),Y3r=l(),Xk=a("p"),Z3r=o("This class cannot be instantiated directly using "),N5e=a("code"),K3r=o("__init__()"),e5r=o(" (throws an error)."),o5r=l(),Rt=a("div"),F(zk.$$.fragment),r5r=l(),q5e=a("p"),t5r=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),a5r=l(),hm=a("p"),n5r=o(`Note:
Loading a model from its configuration file does `),j5e=a("strong"),s5r=o("not"),l5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZK=a("a"),i5r=o("from_pretrained()"),d5r=o(" to load the model weights."),m5r=l(),F(nC.$$.fragment),c5r=l(),co=a("div"),F(Qk.$$.fragment),f5r=l(),D5e=a("p"),g5r=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),h5r=l(),_n=a("p"),u5r=o("The model class to instantiate is selected based on the "),G5e=a("code"),p5r=o("model_type"),_5r=o(` property of the config object (either
passed as an argument or loaded from `),O5e=a("code"),b5r=o("pretrained_model_name_or_path"),v5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V5e=a("code"),F5r=o("pretrained_model_name_or_path"),T5r=o(":"),M5r=l(),X5e=a("ul"),sC=a("li"),z5e=a("strong"),E5r=o("tapas"),C5r=o(" \u2014 "),KK=a("a"),w5r=o("TapasForQuestionAnswering"),A5r=o(" (TAPAS model)"),L5r=l(),lC=a("p"),y5r=o("The model is set in evaluation mode by default using "),Q5e=a("code"),x5r=o("model.eval()"),$5r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),W5e=a("code"),k5r=o("model.train()"),S5r=l(),F(iC.$$.fragment),xao=l(),um=a("h2"),dC=a("a"),U5e=a("span"),F(Wk.$$.fragment),R5r=l(),H5e=a("span"),P5r=o("AutoModelForDocumentQuestionAnswering"),$ao=l(),Uo=a("div"),F(Uk.$$.fragment),B5r=l(),pm=a("p"),I5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),eee=a("a"),N5r=o("from_pretrained()"),q5r=o(" class method or the "),oee=a("a"),j5r=o("from_config()"),D5r=o(` class
method.`),G5r=l(),Hk=a("p"),O5r=o("This class cannot be instantiated directly using "),J5e=a("code"),V5r=o("__init__()"),X5r=o(" (throws an error)."),z5r=l(),Pt=a("div"),F(Jk.$$.fragment),Q5r=l(),Y5e=a("p"),W5r=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),U5r=l(),_m=a("p"),H5r=o(`Note:
Loading a model from its configuration file does `),Z5e=a("strong"),J5r=o("not"),Y5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ree=a("a"),Z5r=o("from_pretrained()"),K5r=o(" to load the model weights."),e0r=l(),F(mC.$$.fragment),o0r=l(),fo=a("div"),F(Yk.$$.fragment),r0r=l(),K5e=a("p"),t0r=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),a0r=l(),bn=a("p"),n0r=o("The model class to instantiate is selected based on the "),e0e=a("code"),s0r=o("model_type"),l0r=o(` property of the config object (either
passed as an argument or loaded from `),o0e=a("code"),i0r=o("pretrained_model_name_or_path"),d0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r0e=a("code"),m0r=o("pretrained_model_name_or_path"),c0r=o(":"),f0r=l(),bm=a("ul"),cC=a("li"),t0e=a("strong"),g0r=o("layoutlm"),h0r=o(" \u2014 "),tee=a("a"),u0r=o("LayoutLMForQuestionAnswering"),p0r=o(" (LayoutLM model)"),_0r=l(),fC=a("li"),a0e=a("strong"),b0r=o("layoutlmv2"),v0r=o(" \u2014 "),aee=a("a"),F0r=o("LayoutLMv2ForQuestionAnswering"),T0r=o(" (LayoutLMv2 model)"),M0r=l(),gC=a("li"),n0e=a("strong"),E0r=o("layoutlmv3"),C0r=o(" \u2014 "),nee=a("a"),w0r=o("LayoutLMv3ForQuestionAnswering"),A0r=o(" (LayoutLMv3 model)"),L0r=l(),hC=a("p"),y0r=o("The model is set in evaluation mode by default using "),s0e=a("code"),x0r=o("model.eval()"),$0r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l0e=a("code"),k0r=o("model.train()"),S0r=l(),F(uC.$$.fragment),kao=l(),vm=a("h2"),pC=a("a"),i0e=a("span"),F(Zk.$$.fragment),R0r=l(),d0e=a("span"),P0r=o("AutoModelForImageClassification"),Sao=l(),Ho=a("div"),F(Kk.$$.fragment),B0r=l(),Fm=a("p"),I0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),see=a("a"),N0r=o("from_pretrained()"),q0r=o(" class method or the "),lee=a("a"),j0r=o("from_config()"),D0r=o(` class
method.`),G0r=l(),eS=a("p"),O0r=o("This class cannot be instantiated directly using "),m0e=a("code"),V0r=o("__init__()"),X0r=o(" (throws an error)."),z0r=l(),Bt=a("div"),F(oS.$$.fragment),Q0r=l(),c0e=a("p"),W0r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),U0r=l(),Tm=a("p"),H0r=o(`Note:
Loading a model from its configuration file does `),f0e=a("strong"),J0r=o("not"),Y0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iee=a("a"),Z0r=o("from_pretrained()"),K0r=o(" to load the model weights."),ewr=l(),F(_C.$$.fragment),owr=l(),go=a("div"),F(rS.$$.fragment),rwr=l(),g0e=a("p"),twr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),awr=l(),vn=a("p"),nwr=o("The model class to instantiate is selected based on the "),h0e=a("code"),swr=o("model_type"),lwr=o(` property of the config object (either
passed as an argument or loaded from `),u0e=a("code"),iwr=o("pretrained_model_name_or_path"),dwr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p0e=a("code"),mwr=o("pretrained_model_name_or_path"),cwr=o(":"),fwr=l(),be=a("ul"),bC=a("li"),_0e=a("strong"),gwr=o("beit"),hwr=o(" \u2014 "),dee=a("a"),uwr=o("BeitForImageClassification"),pwr=o(" (BEiT model)"),_wr=l(),vC=a("li"),b0e=a("strong"),bwr=o("convnext"),vwr=o(" \u2014 "),mee=a("a"),Fwr=o("ConvNextForImageClassification"),Twr=o(" (ConvNeXT model)"),Mwr=l(),FC=a("li"),v0e=a("strong"),Ewr=o("cvt"),Cwr=o(" \u2014 "),cee=a("a"),wwr=o("CvtForImageClassification"),Awr=o(" (CvT model)"),Lwr=l(),TC=a("li"),F0e=a("strong"),ywr=o("data2vec-vision"),xwr=o(" \u2014 "),fee=a("a"),$wr=o("Data2VecVisionForImageClassification"),kwr=o(" (Data2VecVision model)"),Swr=l(),kl=a("li"),T0e=a("strong"),Rwr=o("deit"),Pwr=o(" \u2014 "),gee=a("a"),Bwr=o("DeiTForImageClassification"),Iwr=o(" or "),hee=a("a"),Nwr=o("DeiTForImageClassificationWithTeacher"),qwr=o(" (DeiT model)"),jwr=l(),MC=a("li"),M0e=a("strong"),Dwr=o("imagegpt"),Gwr=o(" \u2014 "),uee=a("a"),Owr=o("ImageGPTForImageClassification"),Vwr=o(" (ImageGPT model)"),Xwr=l(),Sl=a("li"),E0e=a("strong"),zwr=o("levit"),Qwr=o(" \u2014 "),pee=a("a"),Wwr=o("LevitForImageClassification"),Uwr=o(" or "),_ee=a("a"),Hwr=o("LevitForImageClassificationWithTeacher"),Jwr=o(" (LeViT model)"),Ywr=l(),EC=a("li"),C0e=a("strong"),Zwr=o("mobilevit"),Kwr=o(" \u2014 "),bee=a("a"),eAr=o("MobileViTForImageClassification"),oAr=o(" (MobileViT model)"),rAr=l(),It=a("li"),w0e=a("strong"),tAr=o("perceiver"),aAr=o(" \u2014 "),vee=a("a"),nAr=o("PerceiverForImageClassificationLearned"),sAr=o(" or "),Fee=a("a"),lAr=o("PerceiverForImageClassificationFourier"),iAr=o(" or "),Tee=a("a"),dAr=o("PerceiverForImageClassificationConvProcessing"),mAr=o(" (Perceiver model)"),cAr=l(),CC=a("li"),A0e=a("strong"),fAr=o("poolformer"),gAr=o(" \u2014 "),Mee=a("a"),hAr=o("PoolFormerForImageClassification"),uAr=o(" (PoolFormer model)"),pAr=l(),wC=a("li"),L0e=a("strong"),_Ar=o("regnet"),bAr=o(" \u2014 "),Eee=a("a"),vAr=o("RegNetForImageClassification"),FAr=o(" (RegNet model)"),TAr=l(),AC=a("li"),y0e=a("strong"),MAr=o("resnet"),EAr=o(" \u2014 "),Cee=a("a"),CAr=o("ResNetForImageClassification"),wAr=o(" (ResNet model)"),AAr=l(),LC=a("li"),x0e=a("strong"),LAr=o("segformer"),yAr=o(" \u2014 "),wee=a("a"),xAr=o("SegformerForImageClassification"),$Ar=o(" (SegFormer model)"),kAr=l(),yC=a("li"),$0e=a("strong"),SAr=o("swin"),RAr=o(" \u2014 "),Aee=a("a"),PAr=o("SwinForImageClassification"),BAr=o(" (Swin Transformer model)"),IAr=l(),xC=a("li"),k0e=a("strong"),NAr=o("swinv2"),qAr=o(" \u2014 "),Lee=a("a"),jAr=o("Swinv2ForImageClassification"),DAr=o(" (Swin Transformer V2 model)"),GAr=l(),$C=a("li"),S0e=a("strong"),OAr=o("van"),VAr=o(" \u2014 "),yee=a("a"),XAr=o("VanForImageClassification"),zAr=o(" (VAN model)"),QAr=l(),kC=a("li"),R0e=a("strong"),WAr=o("vit"),UAr=o(" \u2014 "),xee=a("a"),HAr=o("ViTForImageClassification"),JAr=o(" (ViT model)"),YAr=l(),SC=a("li"),P0e=a("strong"),ZAr=o("vit_msn"),KAr=o(" \u2014 "),$ee=a("a"),e6r=o("ViTMSNForImageClassification"),o6r=o(" (ViTMSN model)"),r6r=l(),RC=a("p"),t6r=o("The model is set in evaluation mode by default using "),B0e=a("code"),a6r=o("model.eval()"),n6r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),I0e=a("code"),s6r=o("model.train()"),l6r=l(),F(PC.$$.fragment),Rao=l(),Mm=a("h2"),BC=a("a"),N0e=a("span"),F(tS.$$.fragment),i6r=l(),q0e=a("span"),d6r=o("AutoModelForVideoClassification"),Pao=l(),Jo=a("div"),F(aS.$$.fragment),m6r=l(),Em=a("p"),c6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),kee=a("a"),f6r=o("from_pretrained()"),g6r=o(" class method or the "),See=a("a"),h6r=o("from_config()"),u6r=o(` class
method.`),p6r=l(),nS=a("p"),_6r=o("This class cannot be instantiated directly using "),j0e=a("code"),b6r=o("__init__()"),v6r=o(" (throws an error)."),F6r=l(),Nt=a("div"),F(sS.$$.fragment),T6r=l(),D0e=a("p"),M6r=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),E6r=l(),Cm=a("p"),C6r=o(`Note:
Loading a model from its configuration file does `),G0e=a("strong"),w6r=o("not"),A6r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ree=a("a"),L6r=o("from_pretrained()"),y6r=o(" to load the model weights."),x6r=l(),F(IC.$$.fragment),$6r=l(),ho=a("div"),F(lS.$$.fragment),k6r=l(),O0e=a("p"),S6r=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),R6r=l(),Fn=a("p"),P6r=o("The model class to instantiate is selected based on the "),V0e=a("code"),B6r=o("model_type"),I6r=o(` property of the config object (either
passed as an argument or loaded from `),X0e=a("code"),N6r=o("pretrained_model_name_or_path"),q6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z0e=a("code"),j6r=o("pretrained_model_name_or_path"),D6r=o(":"),G6r=l(),Q0e=a("ul"),NC=a("li"),W0e=a("strong"),O6r=o("videomae"),V6r=o(" \u2014 "),Pee=a("a"),X6r=o("VideoMAEForVideoClassification"),z6r=o(" (VideoMAE model)"),Q6r=l(),qC=a("p"),W6r=o("The model is set in evaluation mode by default using "),U0e=a("code"),U6r=o("model.eval()"),H6r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),H0e=a("code"),J6r=o("model.train()"),Y6r=l(),F(jC.$$.fragment),Bao=l(),wm=a("h2"),DC=a("a"),J0e=a("span"),F(iS.$$.fragment),Z6r=l(),Y0e=a("span"),K6r=o("AutoModelForVision2Seq"),Iao=l(),Yo=a("div"),F(dS.$$.fragment),e7r=l(),Am=a("p"),o7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Bee=a("a"),r7r=o("from_pretrained()"),t7r=o(" class method or the "),Iee=a("a"),a7r=o("from_config()"),n7r=o(` class
method.`),s7r=l(),mS=a("p"),l7r=o("This class cannot be instantiated directly using "),Z0e=a("code"),i7r=o("__init__()"),d7r=o(" (throws an error)."),m7r=l(),qt=a("div"),F(cS.$$.fragment),c7r=l(),K0e=a("p"),f7r=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),g7r=l(),Lm=a("p"),h7r=o(`Note:
Loading a model from its configuration file does `),ewe=a("strong"),u7r=o("not"),p7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Nee=a("a"),_7r=o("from_pretrained()"),b7r=o(" to load the model weights."),v7r=l(),F(GC.$$.fragment),F7r=l(),uo=a("div"),F(fS.$$.fragment),T7r=l(),owe=a("p"),M7r=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),E7r=l(),Tn=a("p"),C7r=o("The model class to instantiate is selected based on the "),rwe=a("code"),w7r=o("model_type"),A7r=o(` property of the config object (either
passed as an argument or loaded from `),twe=a("code"),L7r=o("pretrained_model_name_or_path"),y7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),awe=a("code"),x7r=o("pretrained_model_name_or_path"),$7r=o(":"),k7r=l(),nwe=a("ul"),OC=a("li"),swe=a("strong"),S7r=o("vision-encoder-decoder"),R7r=o(" \u2014 "),qee=a("a"),P7r=o("VisionEncoderDecoderModel"),B7r=o(" (Vision Encoder decoder model)"),I7r=l(),VC=a("p"),N7r=o("The model is set in evaluation mode by default using "),lwe=a("code"),q7r=o("model.eval()"),j7r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),iwe=a("code"),D7r=o("model.train()"),G7r=l(),F(XC.$$.fragment),Nao=l(),ym=a("h2"),zC=a("a"),dwe=a("span"),F(gS.$$.fragment),O7r=l(),mwe=a("span"),V7r=o("AutoModelForVisualQuestionAnswering"),qao=l(),Zo=a("div"),F(hS.$$.fragment),X7r=l(),xm=a("p"),z7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),jee=a("a"),Q7r=o("from_pretrained()"),W7r=o(" class method or the "),Dee=a("a"),U7r=o("from_config()"),H7r=o(` class
method.`),J7r=l(),uS=a("p"),Y7r=o("This class cannot be instantiated directly using "),cwe=a("code"),Z7r=o("__init__()"),K7r=o(" (throws an error)."),e8r=l(),jt=a("div"),F(pS.$$.fragment),o8r=l(),fwe=a("p"),r8r=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),t8r=l(),$m=a("p"),a8r=o(`Note:
Loading a model from its configuration file does `),gwe=a("strong"),n8r=o("not"),s8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Gee=a("a"),l8r=o("from_pretrained()"),i8r=o(" to load the model weights."),d8r=l(),F(QC.$$.fragment),m8r=l(),po=a("div"),F(_S.$$.fragment),c8r=l(),hwe=a("p"),f8r=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),g8r=l(),Mn=a("p"),h8r=o("The model class to instantiate is selected based on the "),uwe=a("code"),u8r=o("model_type"),p8r=o(` property of the config object (either
passed as an argument or loaded from `),pwe=a("code"),_8r=o("pretrained_model_name_or_path"),b8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_we=a("code"),v8r=o("pretrained_model_name_or_path"),F8r=o(":"),T8r=l(),bwe=a("ul"),WC=a("li"),vwe=a("strong"),M8r=o("vilt"),E8r=o(" \u2014 "),Oee=a("a"),C8r=o("ViltForQuestionAnswering"),w8r=o(" (ViLT model)"),A8r=l(),UC=a("p"),L8r=o("The model is set in evaluation mode by default using "),Fwe=a("code"),y8r=o("model.eval()"),x8r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Twe=a("code"),$8r=o("model.train()"),k8r=l(),F(HC.$$.fragment),jao=l(),km=a("h2"),JC=a("a"),Mwe=a("span"),F(bS.$$.fragment),S8r=l(),Ewe=a("span"),R8r=o("AutoModelForAudioClassification"),Dao=l(),Ko=a("div"),F(vS.$$.fragment),P8r=l(),Sm=a("p"),B8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),Vee=a("a"),I8r=o("from_pretrained()"),N8r=o(" class method or the "),Xee=a("a"),q8r=o("from_config()"),j8r=o(` class
method.`),D8r=l(),FS=a("p"),G8r=o("This class cannot be instantiated directly using "),Cwe=a("code"),O8r=o("__init__()"),V8r=o(" (throws an error)."),X8r=l(),Dt=a("div"),F(TS.$$.fragment),z8r=l(),wwe=a("p"),Q8r=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),W8r=l(),Rm=a("p"),U8r=o(`Note:
Loading a model from its configuration file does `),Awe=a("strong"),H8r=o("not"),J8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zee=a("a"),Y8r=o("from_pretrained()"),Z8r=o(" to load the model weights."),K8r=l(),F(YC.$$.fragment),eLr=l(),_o=a("div"),F(MS.$$.fragment),oLr=l(),Lwe=a("p"),rLr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),tLr=l(),En=a("p"),aLr=o("The model class to instantiate is selected based on the "),ywe=a("code"),nLr=o("model_type"),sLr=o(` property of the config object (either
passed as an argument or loaded from `),xwe=a("code"),lLr=o("pretrained_model_name_or_path"),iLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$we=a("code"),dLr=o("pretrained_model_name_or_path"),mLr=o(":"),cLr=l(),Be=a("ul"),ZC=a("li"),kwe=a("strong"),fLr=o("data2vec-audio"),gLr=o(" \u2014 "),Qee=a("a"),hLr=o("Data2VecAudioForSequenceClassification"),uLr=o(" (Data2VecAudio model)"),pLr=l(),KC=a("li"),Swe=a("strong"),_Lr=o("hubert"),bLr=o(" \u2014 "),Wee=a("a"),vLr=o("HubertForSequenceClassification"),FLr=o(" (Hubert model)"),TLr=l(),e3=a("li"),Rwe=a("strong"),MLr=o("sew"),ELr=o(" \u2014 "),Uee=a("a"),CLr=o("SEWForSequenceClassification"),wLr=o(" (SEW model)"),ALr=l(),o3=a("li"),Pwe=a("strong"),LLr=o("sew-d"),yLr=o(" \u2014 "),Hee=a("a"),xLr=o("SEWDForSequenceClassification"),$Lr=o(" (SEW-D model)"),kLr=l(),r3=a("li"),Bwe=a("strong"),SLr=o("unispeech"),RLr=o(" \u2014 "),Jee=a("a"),PLr=o("UniSpeechForSequenceClassification"),BLr=o(" (UniSpeech model)"),ILr=l(),t3=a("li"),Iwe=a("strong"),NLr=o("unispeech-sat"),qLr=o(" \u2014 "),Yee=a("a"),jLr=o("UniSpeechSatForSequenceClassification"),DLr=o(" (UniSpeechSat model)"),GLr=l(),a3=a("li"),Nwe=a("strong"),OLr=o("wav2vec2"),VLr=o(" \u2014 "),Zee=a("a"),XLr=o("Wav2Vec2ForSequenceClassification"),zLr=o(" (Wav2Vec2 model)"),QLr=l(),n3=a("li"),qwe=a("strong"),WLr=o("wav2vec2-conformer"),ULr=o(" \u2014 "),Kee=a("a"),HLr=o("Wav2Vec2ConformerForSequenceClassification"),JLr=o(" (Wav2Vec2-Conformer model)"),YLr=l(),s3=a("li"),jwe=a("strong"),ZLr=o("wavlm"),KLr=o(" \u2014 "),eoe=a("a"),eyr=o("WavLMForSequenceClassification"),oyr=o(" (WavLM model)"),ryr=l(),l3=a("p"),tyr=o("The model is set in evaluation mode by default using "),Dwe=a("code"),ayr=o("model.eval()"),nyr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gwe=a("code"),syr=o("model.train()"),lyr=l(),F(i3.$$.fragment),Gao=l(),Pm=a("h2"),d3=a("a"),Owe=a("span"),F(ES.$$.fragment),iyr=l(),Vwe=a("span"),dyr=o("AutoModelForAudioFrameClassification"),Oao=l(),er=a("div"),F(CS.$$.fragment),myr=l(),Bm=a("p"),cyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),ooe=a("a"),fyr=o("from_pretrained()"),gyr=o(" class method or the "),roe=a("a"),hyr=o("from_config()"),uyr=o(` class
method.`),pyr=l(),wS=a("p"),_yr=o("This class cannot be instantiated directly using "),Xwe=a("code"),byr=o("__init__()"),vyr=o(" (throws an error)."),Fyr=l(),Gt=a("div"),F(AS.$$.fragment),Tyr=l(),zwe=a("p"),Myr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),Eyr=l(),Im=a("p"),Cyr=o(`Note:
Loading a model from its configuration file does `),Qwe=a("strong"),wyr=o("not"),Ayr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),toe=a("a"),Lyr=o("from_pretrained()"),yyr=o(" to load the model weights."),xyr=l(),F(m3.$$.fragment),$yr=l(),bo=a("div"),F(LS.$$.fragment),kyr=l(),Wwe=a("p"),Syr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Ryr=l(),Cn=a("p"),Pyr=o("The model class to instantiate is selected based on the "),Uwe=a("code"),Byr=o("model_type"),Iyr=o(` property of the config object (either
passed as an argument or loaded from `),Hwe=a("code"),Nyr=o("pretrained_model_name_or_path"),qyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jwe=a("code"),jyr=o("pretrained_model_name_or_path"),Dyr=o(":"),Gyr=l(),ut=a("ul"),c3=a("li"),Ywe=a("strong"),Oyr=o("data2vec-audio"),Vyr=o(" \u2014 "),aoe=a("a"),Xyr=o("Data2VecAudioForAudioFrameClassification"),zyr=o(" (Data2VecAudio model)"),Qyr=l(),f3=a("li"),Zwe=a("strong"),Wyr=o("unispeech-sat"),Uyr=o(" \u2014 "),noe=a("a"),Hyr=o("UniSpeechSatForAudioFrameClassification"),Jyr=o(" (UniSpeechSat model)"),Yyr=l(),g3=a("li"),Kwe=a("strong"),Zyr=o("wav2vec2"),Kyr=o(" \u2014 "),soe=a("a"),e9r=o("Wav2Vec2ForAudioFrameClassification"),o9r=o(" (Wav2Vec2 model)"),r9r=l(),h3=a("li"),eAe=a("strong"),t9r=o("wav2vec2-conformer"),a9r=o(" \u2014 "),loe=a("a"),n9r=o("Wav2Vec2ConformerForAudioFrameClassification"),s9r=o(" (Wav2Vec2-Conformer model)"),l9r=l(),u3=a("li"),oAe=a("strong"),i9r=o("wavlm"),d9r=o(" \u2014 "),ioe=a("a"),m9r=o("WavLMForAudioFrameClassification"),c9r=o(" (WavLM model)"),f9r=l(),p3=a("p"),g9r=o("The model is set in evaluation mode by default using "),rAe=a("code"),h9r=o("model.eval()"),u9r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tAe=a("code"),p9r=o("model.train()"),_9r=l(),F(_3.$$.fragment),Vao=l(),Nm=a("h2"),b3=a("a"),aAe=a("span"),F(yS.$$.fragment),b9r=l(),nAe=a("span"),v9r=o("AutoModelForCTC"),Xao=l(),or=a("div"),F(xS.$$.fragment),F9r=l(),qm=a("p"),T9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),doe=a("a"),M9r=o("from_pretrained()"),E9r=o(" class method or the "),moe=a("a"),C9r=o("from_config()"),w9r=o(` class
method.`),A9r=l(),$S=a("p"),L9r=o("This class cannot be instantiated directly using "),sAe=a("code"),y9r=o("__init__()"),x9r=o(" (throws an error)."),$9r=l(),Ot=a("div"),F(kS.$$.fragment),k9r=l(),lAe=a("p"),S9r=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),R9r=l(),jm=a("p"),P9r=o(`Note:
Loading a model from its configuration file does `),iAe=a("strong"),B9r=o("not"),I9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),coe=a("a"),N9r=o("from_pretrained()"),q9r=o(" to load the model weights."),j9r=l(),F(v3.$$.fragment),D9r=l(),vo=a("div"),F(SS.$$.fragment),G9r=l(),dAe=a("p"),O9r=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),V9r=l(),wn=a("p"),X9r=o("The model class to instantiate is selected based on the "),mAe=a("code"),z9r=o("model_type"),Q9r=o(` property of the config object (either
passed as an argument or loaded from `),cAe=a("code"),W9r=o("pretrained_model_name_or_path"),U9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fAe=a("code"),H9r=o("pretrained_model_name_or_path"),J9r=o(":"),Y9r=l(),Le=a("ul"),F3=a("li"),gAe=a("strong"),Z9r=o("data2vec-audio"),K9r=o(" \u2014 "),foe=a("a"),exr=o("Data2VecAudioForCTC"),oxr=o(" (Data2VecAudio model)"),rxr=l(),T3=a("li"),hAe=a("strong"),txr=o("hubert"),axr=o(" \u2014 "),goe=a("a"),nxr=o("HubertForCTC"),sxr=o(" (Hubert model)"),lxr=l(),M3=a("li"),uAe=a("strong"),ixr=o("mctct"),dxr=o(" \u2014 "),hoe=a("a"),mxr=o("MCTCTForCTC"),cxr=o(" (M-CTC-T model)"),fxr=l(),E3=a("li"),pAe=a("strong"),gxr=o("sew"),hxr=o(" \u2014 "),uoe=a("a"),uxr=o("SEWForCTC"),pxr=o(" (SEW model)"),_xr=l(),C3=a("li"),_Ae=a("strong"),bxr=o("sew-d"),vxr=o(" \u2014 "),poe=a("a"),Fxr=o("SEWDForCTC"),Txr=o(" (SEW-D model)"),Mxr=l(),w3=a("li"),bAe=a("strong"),Exr=o("unispeech"),Cxr=o(" \u2014 "),_oe=a("a"),wxr=o("UniSpeechForCTC"),Axr=o(" (UniSpeech model)"),Lxr=l(),A3=a("li"),vAe=a("strong"),yxr=o("unispeech-sat"),xxr=o(" \u2014 "),boe=a("a"),$xr=o("UniSpeechSatForCTC"),kxr=o(" (UniSpeechSat model)"),Sxr=l(),L3=a("li"),FAe=a("strong"),Rxr=o("wav2vec2"),Pxr=o(" \u2014 "),voe=a("a"),Bxr=o("Wav2Vec2ForCTC"),Ixr=o(" (Wav2Vec2 model)"),Nxr=l(),y3=a("li"),TAe=a("strong"),qxr=o("wav2vec2-conformer"),jxr=o(" \u2014 "),Foe=a("a"),Dxr=o("Wav2Vec2ConformerForCTC"),Gxr=o(" (Wav2Vec2-Conformer model)"),Oxr=l(),x3=a("li"),MAe=a("strong"),Vxr=o("wavlm"),Xxr=o(" \u2014 "),Toe=a("a"),zxr=o("WavLMForCTC"),Qxr=o(" (WavLM model)"),Wxr=l(),$3=a("p"),Uxr=o("The model is set in evaluation mode by default using "),EAe=a("code"),Hxr=o("model.eval()"),Jxr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),CAe=a("code"),Yxr=o("model.train()"),Zxr=l(),F(k3.$$.fragment),zao=l(),Dm=a("h2"),S3=a("a"),wAe=a("span"),F(RS.$$.fragment),Kxr=l(),AAe=a("span"),e$r=o("AutoModelForSpeechSeq2Seq"),Qao=l(),rr=a("div"),F(PS.$$.fragment),o$r=l(),Gm=a("p"),r$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Moe=a("a"),t$r=o("from_pretrained()"),a$r=o(" class method or the "),Eoe=a("a"),n$r=o("from_config()"),s$r=o(` class
method.`),l$r=l(),BS=a("p"),i$r=o("This class cannot be instantiated directly using "),LAe=a("code"),d$r=o("__init__()"),m$r=o(" (throws an error)."),c$r=l(),Vt=a("div"),F(IS.$$.fragment),f$r=l(),yAe=a("p"),g$r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),h$r=l(),Om=a("p"),u$r=o(`Note:
Loading a model from its configuration file does `),xAe=a("strong"),p$r=o("not"),_$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Coe=a("a"),b$r=o("from_pretrained()"),v$r=o(" to load the model weights."),F$r=l(),F(R3.$$.fragment),T$r=l(),Fo=a("div"),F(NS.$$.fragment),M$r=l(),$Ae=a("p"),E$r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),C$r=l(),An=a("p"),w$r=o("The model class to instantiate is selected based on the "),kAe=a("code"),A$r=o("model_type"),L$r=o(` property of the config object (either
passed as an argument or loaded from `),SAe=a("code"),y$r=o("pretrained_model_name_or_path"),x$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RAe=a("code"),$$r=o("pretrained_model_name_or_path"),k$r=o(":"),S$r=l(),Vm=a("ul"),P3=a("li"),PAe=a("strong"),R$r=o("speech-encoder-decoder"),P$r=o(" \u2014 "),woe=a("a"),B$r=o("SpeechEncoderDecoderModel"),I$r=o(" (Speech Encoder decoder model)"),N$r=l(),B3=a("li"),BAe=a("strong"),q$r=o("speech_to_text"),j$r=o(" \u2014 "),Aoe=a("a"),D$r=o("Speech2TextForConditionalGeneration"),G$r=o(" (Speech2Text model)"),O$r=l(),I3=a("li"),IAe=a("strong"),V$r=o("whisper"),X$r=o(" \u2014 "),Loe=a("a"),z$r=o("WhisperForConditionalGeneration"),Q$r=o(" (Whisper model)"),W$r=l(),N3=a("p"),U$r=o("The model is set in evaluation mode by default using "),NAe=a("code"),H$r=o("model.eval()"),J$r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qAe=a("code"),Y$r=o("model.train()"),Z$r=l(),F(q3.$$.fragment),Wao=l(),Xm=a("h2"),j3=a("a"),jAe=a("span"),F(qS.$$.fragment),K$r=l(),DAe=a("span"),ekr=o("AutoModelForAudioXVector"),Uao=l(),tr=a("div"),F(jS.$$.fragment),okr=l(),zm=a("p"),rkr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),yoe=a("a"),tkr=o("from_pretrained()"),akr=o(" class method or the "),xoe=a("a"),nkr=o("from_config()"),skr=o(` class
method.`),lkr=l(),DS=a("p"),ikr=o("This class cannot be instantiated directly using "),GAe=a("code"),dkr=o("__init__()"),mkr=o(" (throws an error)."),ckr=l(),Xt=a("div"),F(GS.$$.fragment),fkr=l(),OAe=a("p"),gkr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),hkr=l(),Qm=a("p"),ukr=o(`Note:
Loading a model from its configuration file does `),VAe=a("strong"),pkr=o("not"),_kr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$oe=a("a"),bkr=o("from_pretrained()"),vkr=o(" to load the model weights."),Fkr=l(),F(D3.$$.fragment),Tkr=l(),To=a("div"),F(OS.$$.fragment),Mkr=l(),XAe=a("p"),Ekr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),Ckr=l(),Ln=a("p"),wkr=o("The model class to instantiate is selected based on the "),zAe=a("code"),Akr=o("model_type"),Lkr=o(` property of the config object (either
passed as an argument or loaded from `),QAe=a("code"),ykr=o("pretrained_model_name_or_path"),xkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),WAe=a("code"),$kr=o("pretrained_model_name_or_path"),kkr=o(":"),Skr=l(),pt=a("ul"),G3=a("li"),UAe=a("strong"),Rkr=o("data2vec-audio"),Pkr=o(" \u2014 "),koe=a("a"),Bkr=o("Data2VecAudioForXVector"),Ikr=o(" (Data2VecAudio model)"),Nkr=l(),O3=a("li"),HAe=a("strong"),qkr=o("unispeech-sat"),jkr=o(" \u2014 "),Soe=a("a"),Dkr=o("UniSpeechSatForXVector"),Gkr=o(" (UniSpeechSat model)"),Okr=l(),V3=a("li"),JAe=a("strong"),Vkr=o("wav2vec2"),Xkr=o(" \u2014 "),Roe=a("a"),zkr=o("Wav2Vec2ForXVector"),Qkr=o(" (Wav2Vec2 model)"),Wkr=l(),X3=a("li"),YAe=a("strong"),Ukr=o("wav2vec2-conformer"),Hkr=o(" \u2014 "),Poe=a("a"),Jkr=o("Wav2Vec2ConformerForXVector"),Ykr=o(" (Wav2Vec2-Conformer model)"),Zkr=l(),z3=a("li"),ZAe=a("strong"),Kkr=o("wavlm"),eSr=o(" \u2014 "),Boe=a("a"),oSr=o("WavLMForXVector"),rSr=o(" (WavLM model)"),tSr=l(),Q3=a("p"),aSr=o("The model is set in evaluation mode by default using "),KAe=a("code"),nSr=o("model.eval()"),sSr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),e6e=a("code"),lSr=o("model.train()"),iSr=l(),F(W3.$$.fragment),Hao=l(),Wm=a("h2"),U3=a("a"),o6e=a("span"),F(VS.$$.fragment),dSr=l(),r6e=a("span"),mSr=o("AutoModelForMaskedImageModeling"),Jao=l(),ar=a("div"),F(XS.$$.fragment),cSr=l(),Um=a("p"),fSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Ioe=a("a"),gSr=o("from_pretrained()"),hSr=o(" class method or the "),Noe=a("a"),uSr=o("from_config()"),pSr=o(` class
method.`),_Sr=l(),zS=a("p"),bSr=o("This class cannot be instantiated directly using "),t6e=a("code"),vSr=o("__init__()"),FSr=o(" (throws an error)."),TSr=l(),zt=a("div"),F(QS.$$.fragment),MSr=l(),a6e=a("p"),ESr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),CSr=l(),Hm=a("p"),wSr=o(`Note:
Loading a model from its configuration file does `),n6e=a("strong"),ASr=o("not"),LSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qoe=a("a"),ySr=o("from_pretrained()"),xSr=o(" to load the model weights."),$Sr=l(),F(H3.$$.fragment),kSr=l(),Mo=a("div"),F(WS.$$.fragment),SSr=l(),s6e=a("p"),RSr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),PSr=l(),yn=a("p"),BSr=o("The model class to instantiate is selected based on the "),l6e=a("code"),ISr=o("model_type"),NSr=o(` property of the config object (either
passed as an argument or loaded from `),i6e=a("code"),qSr=o("pretrained_model_name_or_path"),jSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d6e=a("code"),DSr=o("pretrained_model_name_or_path"),GSr=o(":"),OSr=l(),xn=a("ul"),J3=a("li"),m6e=a("strong"),VSr=o("deit"),XSr=o(" \u2014 "),joe=a("a"),zSr=o("DeiTForMaskedImageModeling"),QSr=o(" (DeiT model)"),WSr=l(),Y3=a("li"),c6e=a("strong"),USr=o("swin"),HSr=o(" \u2014 "),Doe=a("a"),JSr=o("SwinForMaskedImageModeling"),YSr=o(" (Swin Transformer model)"),ZSr=l(),Z3=a("li"),f6e=a("strong"),KSr=o("swinv2"),eRr=o(" \u2014 "),Goe=a("a"),oRr=o("Swinv2ForMaskedImageModeling"),rRr=o(" (Swin Transformer V2 model)"),tRr=l(),K3=a("li"),g6e=a("strong"),aRr=o("vit"),nRr=o(" \u2014 "),Ooe=a("a"),sRr=o("ViTForMaskedImageModeling"),lRr=o(" (ViT model)"),iRr=l(),e5=a("p"),dRr=o("The model is set in evaluation mode by default using "),h6e=a("code"),mRr=o("model.eval()"),cRr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u6e=a("code"),fRr=o("model.train()"),gRr=l(),F(o5.$$.fragment),Yao=l(),Jm=a("h2"),r5=a("a"),p6e=a("span"),F(US.$$.fragment),hRr=l(),_6e=a("span"),uRr=o("AutoModelForObjectDetection"),Zao=l(),nr=a("div"),F(HS.$$.fragment),pRr=l(),Ym=a("p"),_Rr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Voe=a("a"),bRr=o("from_pretrained()"),vRr=o(" class method or the "),Xoe=a("a"),FRr=o("from_config()"),TRr=o(` class
method.`),MRr=l(),JS=a("p"),ERr=o("This class cannot be instantiated directly using "),b6e=a("code"),CRr=o("__init__()"),wRr=o(" (throws an error)."),ARr=l(),Qt=a("div"),F(YS.$$.fragment),LRr=l(),v6e=a("p"),yRr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),xRr=l(),Zm=a("p"),$Rr=o(`Note:
Loading a model from its configuration file does `),F6e=a("strong"),kRr=o("not"),SRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zoe=a("a"),RRr=o("from_pretrained()"),PRr=o(" to load the model weights."),BRr=l(),F(t5.$$.fragment),IRr=l(),Eo=a("div"),F(ZS.$$.fragment),NRr=l(),T6e=a("p"),qRr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),jRr=l(),$n=a("p"),DRr=o("The model class to instantiate is selected based on the "),M6e=a("code"),GRr=o("model_type"),ORr=o(` property of the config object (either
passed as an argument or loaded from `),E6e=a("code"),VRr=o("pretrained_model_name_or_path"),XRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C6e=a("code"),zRr=o("pretrained_model_name_or_path"),QRr=o(":"),WRr=l(),_t=a("ul"),a5=a("li"),w6e=a("strong"),URr=o("conditional_detr"),HRr=o(" \u2014 "),Qoe=a("a"),JRr=o("ConditionalDetrForObjectDetection"),YRr=o(" (Conditional DETR model)"),ZRr=l(),n5=a("li"),A6e=a("strong"),KRr=o("deformable_detr"),ePr=o(" \u2014 "),Woe=a("a"),oPr=o("DeformableDetrForObjectDetection"),rPr=o(" (Deformable DETR model)"),tPr=l(),s5=a("li"),L6e=a("strong"),aPr=o("detr"),nPr=o(" \u2014 "),Uoe=a("a"),sPr=o("DetrForObjectDetection"),lPr=o(" (DETR model)"),iPr=l(),l5=a("li"),y6e=a("strong"),dPr=o("table-transformer"),mPr=o(" \u2014 "),Hoe=a("a"),cPr=o("TableTransformerForObjectDetection"),fPr=o(" (Table Transformer model)"),gPr=l(),i5=a("li"),x6e=a("strong"),hPr=o("yolos"),uPr=o(" \u2014 "),Joe=a("a"),pPr=o("YolosForObjectDetection"),_Pr=o(" (YOLOS model)"),bPr=l(),d5=a("p"),vPr=o("The model is set in evaluation mode by default using "),$6e=a("code"),FPr=o("model.eval()"),TPr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),k6e=a("code"),MPr=o("model.train()"),EPr=l(),F(m5.$$.fragment),Kao=l(),Km=a("h2"),c5=a("a"),S6e=a("span"),F(KS.$$.fragment),CPr=l(),R6e=a("span"),wPr=o("AutoModelForImageSegmentation"),eno=l(),sr=a("div"),F(eR.$$.fragment),APr=l(),ec=a("p"),LPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),Yoe=a("a"),yPr=o("from_pretrained()"),xPr=o(" class method or the "),Zoe=a("a"),$Pr=o("from_config()"),kPr=o(` class
method.`),SPr=l(),oR=a("p"),RPr=o("This class cannot be instantiated directly using "),P6e=a("code"),PPr=o("__init__()"),BPr=o(" (throws an error)."),IPr=l(),Wt=a("div"),F(rR.$$.fragment),NPr=l(),B6e=a("p"),qPr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),jPr=l(),oc=a("p"),DPr=o(`Note:
Loading a model from its configuration file does `),I6e=a("strong"),GPr=o("not"),OPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Koe=a("a"),VPr=o("from_pretrained()"),XPr=o(" to load the model weights."),zPr=l(),F(f5.$$.fragment),QPr=l(),Co=a("div"),F(tR.$$.fragment),WPr=l(),N6e=a("p"),UPr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),HPr=l(),kn=a("p"),JPr=o("The model class to instantiate is selected based on the "),q6e=a("code"),YPr=o("model_type"),ZPr=o(` property of the config object (either
passed as an argument or loaded from `),j6e=a("code"),KPr=o("pretrained_model_name_or_path"),eBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D6e=a("code"),oBr=o("pretrained_model_name_or_path"),rBr=o(":"),tBr=l(),G6e=a("ul"),g5=a("li"),O6e=a("strong"),aBr=o("detr"),nBr=o(" \u2014 "),ere=a("a"),sBr=o("DetrForSegmentation"),lBr=o(" (DETR model)"),iBr=l(),h5=a("p"),dBr=o("The model is set in evaluation mode by default using "),V6e=a("code"),mBr=o("model.eval()"),cBr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X6e=a("code"),fBr=o("model.train()"),gBr=l(),F(u5.$$.fragment),ono=l(),rc=a("h2"),p5=a("a"),z6e=a("span"),F(aR.$$.fragment),hBr=l(),Q6e=a("span"),uBr=o("AutoModelForSemanticSegmentation"),rno=l(),lr=a("div"),F(nR.$$.fragment),pBr=l(),tc=a("p"),_Br=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),ore=a("a"),bBr=o("from_pretrained()"),vBr=o(" class method or the "),rre=a("a"),FBr=o("from_config()"),TBr=o(` class
method.`),MBr=l(),sR=a("p"),EBr=o("This class cannot be instantiated directly using "),W6e=a("code"),CBr=o("__init__()"),wBr=o(" (throws an error)."),ABr=l(),Ut=a("div"),F(lR.$$.fragment),LBr=l(),U6e=a("p"),yBr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),xBr=l(),ac=a("p"),$Br=o(`Note:
Loading a model from its configuration file does `),H6e=a("strong"),kBr=o("not"),SBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tre=a("a"),RBr=o("from_pretrained()"),PBr=o(" to load the model weights."),BBr=l(),F(_5.$$.fragment),IBr=l(),wo=a("div"),F(iR.$$.fragment),NBr=l(),J6e=a("p"),qBr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),jBr=l(),Sn=a("p"),DBr=o("The model class to instantiate is selected based on the "),Y6e=a("code"),GBr=o("model_type"),OBr=o(` property of the config object (either
passed as an argument or loaded from `),Z6e=a("code"),VBr=o("pretrained_model_name_or_path"),XBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K6e=a("code"),zBr=o("pretrained_model_name_or_path"),QBr=o(":"),WBr=l(),bt=a("ul"),b5=a("li"),e7e=a("strong"),UBr=o("beit"),HBr=o(" \u2014 "),are=a("a"),JBr=o("BeitForSemanticSegmentation"),YBr=o(" (BEiT model)"),ZBr=l(),v5=a("li"),o7e=a("strong"),KBr=o("data2vec-vision"),eIr=o(" \u2014 "),nre=a("a"),oIr=o("Data2VecVisionForSemanticSegmentation"),rIr=o(" (Data2VecVision model)"),tIr=l(),F5=a("li"),r7e=a("strong"),aIr=o("dpt"),nIr=o(" \u2014 "),sre=a("a"),sIr=o("DPTForSemanticSegmentation"),lIr=o(" (DPT model)"),iIr=l(),T5=a("li"),t7e=a("strong"),dIr=o("mobilevit"),mIr=o(" \u2014 "),lre=a("a"),cIr=o("MobileViTForSemanticSegmentation"),fIr=o(" (MobileViT model)"),gIr=l(),M5=a("li"),a7e=a("strong"),hIr=o("segformer"),uIr=o(" \u2014 "),ire=a("a"),pIr=o("SegformerForSemanticSegmentation"),_Ir=o(" (SegFormer model)"),bIr=l(),E5=a("p"),vIr=o("The model is set in evaluation mode by default using "),n7e=a("code"),FIr=o("model.eval()"),TIr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),s7e=a("code"),MIr=o("model.train()"),EIr=l(),F(C5.$$.fragment),tno=l(),nc=a("h2"),w5=a("a"),l7e=a("span"),F(dR.$$.fragment),CIr=l(),i7e=a("span"),wIr=o("AutoModelForInstanceSegmentation"),ano=l(),ir=a("div"),F(mR.$$.fragment),AIr=l(),sc=a("p"),LIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),dre=a("a"),yIr=o("from_pretrained()"),xIr=o(" class method or the "),mre=a("a"),$Ir=o("from_config()"),kIr=o(` class
method.`),SIr=l(),cR=a("p"),RIr=o("This class cannot be instantiated directly using "),d7e=a("code"),PIr=o("__init__()"),BIr=o(" (throws an error)."),IIr=l(),Ht=a("div"),F(fR.$$.fragment),NIr=l(),m7e=a("p"),qIr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),jIr=l(),lc=a("p"),DIr=o(`Note:
Loading a model from its configuration file does `),c7e=a("strong"),GIr=o("not"),OIr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cre=a("a"),VIr=o("from_pretrained()"),XIr=o(" to load the model weights."),zIr=l(),F(A5.$$.fragment),QIr=l(),Ao=a("div"),F(gR.$$.fragment),WIr=l(),f7e=a("p"),UIr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),HIr=l(),Rn=a("p"),JIr=o("The model class to instantiate is selected based on the "),g7e=a("code"),YIr=o("model_type"),ZIr=o(` property of the config object (either
passed as an argument or loaded from `),h7e=a("code"),KIr=o("pretrained_model_name_or_path"),eNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u7e=a("code"),oNr=o("pretrained_model_name_or_path"),rNr=o(":"),tNr=l(),p7e=a("ul"),L5=a("li"),_7e=a("strong"),aNr=o("maskformer"),nNr=o(" \u2014 "),fre=a("a"),sNr=o("MaskFormerForInstanceSegmentation"),lNr=o(" (MaskFormer model)"),iNr=l(),y5=a("p"),dNr=o("The model is set in evaluation mode by default using "),b7e=a("code"),mNr=o("model.eval()"),cNr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v7e=a("code"),fNr=o("model.train()"),gNr=l(),F(x5.$$.fragment),nno=l(),ic=a("h2"),$5=a("a"),F7e=a("span"),F(hR.$$.fragment),hNr=l(),T7e=a("span"),uNr=o("AutoModelForZeroShotObjectDetection"),sno=l(),dr=a("div"),F(uR.$$.fragment),pNr=l(),dc=a("p"),_Nr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),gre=a("a"),bNr=o("from_pretrained()"),vNr=o(" class method or the "),hre=a("a"),FNr=o("from_config()"),TNr=o(` class
method.`),MNr=l(),pR=a("p"),ENr=o("This class cannot be instantiated directly using "),M7e=a("code"),CNr=o("__init__()"),wNr=o(" (throws an error)."),ANr=l(),Jt=a("div"),F(_R.$$.fragment),LNr=l(),E7e=a("p"),yNr=o("Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),xNr=l(),mc=a("p"),$Nr=o(`Note:
Loading a model from its configuration file does `),C7e=a("strong"),kNr=o("not"),SNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ure=a("a"),RNr=o("from_pretrained()"),PNr=o(" to load the model weights."),BNr=l(),F(k5.$$.fragment),INr=l(),Lo=a("div"),F(bR.$$.fragment),NNr=l(),w7e=a("p"),qNr=o("Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),jNr=l(),Pn=a("p"),DNr=o("The model class to instantiate is selected based on the "),A7e=a("code"),GNr=o("model_type"),ONr=o(` property of the config object (either
passed as an argument or loaded from `),L7e=a("code"),VNr=o("pretrained_model_name_or_path"),XNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y7e=a("code"),zNr=o("pretrained_model_name_or_path"),QNr=o(":"),WNr=l(),x7e=a("ul"),S5=a("li"),$7e=a("strong"),UNr=o("owlvit"),HNr=o(" \u2014 "),pre=a("a"),JNr=o("OwlViTForObjectDetection"),YNr=o(" (OWL-ViT model)"),ZNr=l(),R5=a("p"),KNr=o("The model is set in evaluation mode by default using "),k7e=a("code"),eqr=o("model.eval()"),oqr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),S7e=a("code"),rqr=o("model.train()"),tqr=l(),F(P5.$$.fragment),lno=l(),cc=a("h2"),B5=a("a"),R7e=a("span"),F(vR.$$.fragment),aqr=l(),P7e=a("span"),nqr=o("TFAutoModel"),ino=l(),mr=a("div"),F(FR.$$.fragment),sqr=l(),fc=a("p"),lqr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),_re=a("a"),iqr=o("from_pretrained()"),dqr=o(" class method or the "),bre=a("a"),mqr=o("from_config()"),cqr=o(` class
method.`),fqr=l(),TR=a("p"),gqr=o("This class cannot be instantiated directly using "),B7e=a("code"),hqr=o("__init__()"),uqr=o(" (throws an error)."),pqr=l(),Yt=a("div"),F(MR.$$.fragment),_qr=l(),I7e=a("p"),bqr=o("Instantiates one of the base model classes of the library from a configuration."),vqr=l(),gc=a("p"),Fqr=o(`Note:
Loading a model from its configuration file does `),N7e=a("strong"),Tqr=o("not"),Mqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vre=a("a"),Eqr=o("from_pretrained()"),Cqr=o(" to load the model weights."),wqr=l(),F(I5.$$.fragment),Aqr=l(),Dr=a("div"),F(ER.$$.fragment),Lqr=l(),q7e=a("p"),yqr=o("Instantiate one of the base model classes of the library from a pretrained model."),xqr=l(),Bn=a("p"),$qr=o("The model class to instantiate is selected based on the "),j7e=a("code"),kqr=o("model_type"),Sqr=o(` property of the config object (either
passed as an argument or loaded from `),D7e=a("code"),Rqr=o("pretrained_model_name_or_path"),Pqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G7e=a("code"),Bqr=o("pretrained_model_name_or_path"),Iqr=o(":"),Nqr=l(),P=a("ul"),N5=a("li"),O7e=a("strong"),qqr=o("albert"),jqr=o(" \u2014 "),Fre=a("a"),Dqr=o("TFAlbertModel"),Gqr=o(" (ALBERT model)"),Oqr=l(),q5=a("li"),V7e=a("strong"),Vqr=o("bart"),Xqr=o(" \u2014 "),Tre=a("a"),zqr=o("TFBartModel"),Qqr=o(" (BART model)"),Wqr=l(),j5=a("li"),X7e=a("strong"),Uqr=o("bert"),Hqr=o(" \u2014 "),Mre=a("a"),Jqr=o("TFBertModel"),Yqr=o(" (BERT model)"),Zqr=l(),D5=a("li"),z7e=a("strong"),Kqr=o("blenderbot"),ejr=o(" \u2014 "),Ere=a("a"),ojr=o("TFBlenderbotModel"),rjr=o(" (Blenderbot model)"),tjr=l(),G5=a("li"),Q7e=a("strong"),ajr=o("blenderbot-small"),njr=o(" \u2014 "),Cre=a("a"),sjr=o("TFBlenderbotSmallModel"),ljr=o(" (BlenderbotSmall model)"),ijr=l(),O5=a("li"),W7e=a("strong"),djr=o("camembert"),mjr=o(" \u2014 "),wre=a("a"),cjr=o("TFCamembertModel"),fjr=o(" (CamemBERT model)"),gjr=l(),V5=a("li"),U7e=a("strong"),hjr=o("clip"),ujr=o(" \u2014 "),Are=a("a"),pjr=o("TFCLIPModel"),_jr=o(" (CLIP model)"),bjr=l(),X5=a("li"),H7e=a("strong"),vjr=o("convbert"),Fjr=o(" \u2014 "),Lre=a("a"),Tjr=o("TFConvBertModel"),Mjr=o(" (ConvBERT model)"),Ejr=l(),z5=a("li"),J7e=a("strong"),Cjr=o("convnext"),wjr=o(" \u2014 "),yre=a("a"),Ajr=o("TFConvNextModel"),Ljr=o(" (ConvNeXT model)"),yjr=l(),Q5=a("li"),Y7e=a("strong"),xjr=o("ctrl"),$jr=o(" \u2014 "),xre=a("a"),kjr=o("TFCTRLModel"),Sjr=o(" (CTRL model)"),Rjr=l(),W5=a("li"),Z7e=a("strong"),Pjr=o("cvt"),Bjr=o(" \u2014 "),$re=a("a"),Ijr=o("TFCvtModel"),Njr=o(" (CvT model)"),qjr=l(),U5=a("li"),K7e=a("strong"),jjr=o("data2vec-vision"),Djr=o(" \u2014 "),kre=a("a"),Gjr=o("TFData2VecVisionModel"),Ojr=o(" (Data2VecVision model)"),Vjr=l(),H5=a("li"),e8e=a("strong"),Xjr=o("deberta"),zjr=o(" \u2014 "),Sre=a("a"),Qjr=o("TFDebertaModel"),Wjr=o(" (DeBERTa model)"),Ujr=l(),J5=a("li"),o8e=a("strong"),Hjr=o("deberta-v2"),Jjr=o(" \u2014 "),Rre=a("a"),Yjr=o("TFDebertaV2Model"),Zjr=o(" (DeBERTa-v2 model)"),Kjr=l(),Y5=a("li"),r8e=a("strong"),eDr=o("deit"),oDr=o(" \u2014 "),Pre=a("a"),rDr=o("TFDeiTModel"),tDr=o(" (DeiT model)"),aDr=l(),Z5=a("li"),t8e=a("strong"),nDr=o("distilbert"),sDr=o(" \u2014 "),Bre=a("a"),lDr=o("TFDistilBertModel"),iDr=o(" (DistilBERT model)"),dDr=l(),K5=a("li"),a8e=a("strong"),mDr=o("dpr"),cDr=o(" \u2014 "),Ire=a("a"),fDr=o("TFDPRQuestionEncoder"),gDr=o(" (DPR model)"),hDr=l(),e0=a("li"),n8e=a("strong"),uDr=o("electra"),pDr=o(" \u2014 "),Nre=a("a"),_Dr=o("TFElectraModel"),bDr=o(" (ELECTRA model)"),vDr=l(),o0=a("li"),s8e=a("strong"),FDr=o("esm"),TDr=o(" \u2014 "),qre=a("a"),MDr=o("TFEsmModel"),EDr=o(" (ESM model)"),CDr=l(),r0=a("li"),l8e=a("strong"),wDr=o("flaubert"),ADr=o(" \u2014 "),jre=a("a"),LDr=o("TFFlaubertModel"),yDr=o(" (FlauBERT model)"),xDr=l(),Rl=a("li"),i8e=a("strong"),$Dr=o("funnel"),kDr=o(" \u2014 "),Dre=a("a"),SDr=o("TFFunnelModel"),RDr=o(" or "),Gre=a("a"),PDr=o("TFFunnelBaseModel"),BDr=o(" (Funnel Transformer model)"),IDr=l(),t0=a("li"),d8e=a("strong"),NDr=o("gpt2"),qDr=o(" \u2014 "),Ore=a("a"),jDr=o("TFGPT2Model"),DDr=o(" (OpenAI GPT-2 model)"),GDr=l(),a0=a("li"),m8e=a("strong"),ODr=o("gptj"),VDr=o(" \u2014 "),Vre=a("a"),XDr=o("TFGPTJModel"),zDr=o(" (GPT-J model)"),QDr=l(),n0=a("li"),c8e=a("strong"),WDr=o("groupvit"),UDr=o(" \u2014 "),Xre=a("a"),HDr=o("TFGroupViTModel"),JDr=o(" (GroupViT model)"),YDr=l(),s0=a("li"),f8e=a("strong"),ZDr=o("hubert"),KDr=o(" \u2014 "),zre=a("a"),eGr=o("TFHubertModel"),oGr=o(" (Hubert model)"),rGr=l(),l0=a("li"),g8e=a("strong"),tGr=o("layoutlm"),aGr=o(" \u2014 "),Qre=a("a"),nGr=o("TFLayoutLMModel"),sGr=o(" (LayoutLM model)"),lGr=l(),i0=a("li"),h8e=a("strong"),iGr=o("layoutlmv3"),dGr=o(" \u2014 "),Wre=a("a"),mGr=o("TFLayoutLMv3Model"),cGr=o(" (LayoutLMv3 model)"),fGr=l(),d0=a("li"),u8e=a("strong"),gGr=o("led"),hGr=o(" \u2014 "),Ure=a("a"),uGr=o("TFLEDModel"),pGr=o(" (LED model)"),_Gr=l(),m0=a("li"),p8e=a("strong"),bGr=o("longformer"),vGr=o(" \u2014 "),Hre=a("a"),FGr=o("TFLongformerModel"),TGr=o(" (Longformer model)"),MGr=l(),c0=a("li"),_8e=a("strong"),EGr=o("lxmert"),CGr=o(" \u2014 "),Jre=a("a"),wGr=o("TFLxmertModel"),AGr=o(" (LXMERT model)"),LGr=l(),f0=a("li"),b8e=a("strong"),yGr=o("marian"),xGr=o(" \u2014 "),Yre=a("a"),$Gr=o("TFMarianModel"),kGr=o(" (Marian model)"),SGr=l(),g0=a("li"),v8e=a("strong"),RGr=o("mbart"),PGr=o(" \u2014 "),Zre=a("a"),BGr=o("TFMBartModel"),IGr=o(" (mBART model)"),NGr=l(),h0=a("li"),F8e=a("strong"),qGr=o("mobilebert"),jGr=o(" \u2014 "),Kre=a("a"),DGr=o("TFMobileBertModel"),GGr=o(" (MobileBERT model)"),OGr=l(),u0=a("li"),T8e=a("strong"),VGr=o("mobilevit"),XGr=o(" \u2014 "),ete=a("a"),zGr=o("TFMobileViTModel"),QGr=o(" (MobileViT model)"),WGr=l(),p0=a("li"),M8e=a("strong"),UGr=o("mpnet"),HGr=o(" \u2014 "),ote=a("a"),JGr=o("TFMPNetModel"),YGr=o(" (MPNet model)"),ZGr=l(),_0=a("li"),E8e=a("strong"),KGr=o("mt5"),eOr=o(" \u2014 "),rte=a("a"),oOr=o("TFMT5Model"),rOr=o(" (MT5 model)"),tOr=l(),b0=a("li"),C8e=a("strong"),aOr=o("openai-gpt"),nOr=o(" \u2014 "),tte=a("a"),sOr=o("TFOpenAIGPTModel"),lOr=o(" (OpenAI GPT model)"),iOr=l(),v0=a("li"),w8e=a("strong"),dOr=o("opt"),mOr=o(" \u2014 "),ate=a("a"),cOr=o("TFOPTModel"),fOr=o(" (OPT model)"),gOr=l(),F0=a("li"),A8e=a("strong"),hOr=o("pegasus"),uOr=o(" \u2014 "),nte=a("a"),pOr=o("TFPegasusModel"),_Or=o(" (Pegasus model)"),bOr=l(),T0=a("li"),L8e=a("strong"),vOr=o("regnet"),FOr=o(" \u2014 "),ste=a("a"),TOr=o("TFRegNetModel"),MOr=o(" (RegNet model)"),EOr=l(),M0=a("li"),y8e=a("strong"),COr=o("rembert"),wOr=o(" \u2014 "),lte=a("a"),AOr=o("TFRemBertModel"),LOr=o(" (RemBERT model)"),yOr=l(),E0=a("li"),x8e=a("strong"),xOr=o("resnet"),$Or=o(" \u2014 "),ite=a("a"),kOr=o("TFResNetModel"),SOr=o(" (ResNet model)"),ROr=l(),C0=a("li"),$8e=a("strong"),POr=o("roberta"),BOr=o(" \u2014 "),dte=a("a"),IOr=o("TFRobertaModel"),NOr=o(" (RoBERTa model)"),qOr=l(),w0=a("li"),k8e=a("strong"),jOr=o("roformer"),DOr=o(" \u2014 "),mte=a("a"),GOr=o("TFRoFormerModel"),OOr=o(" (RoFormer model)"),VOr=l(),A0=a("li"),S8e=a("strong"),XOr=o("segformer"),zOr=o(" \u2014 "),cte=a("a"),QOr=o("TFSegformerModel"),WOr=o(" (SegFormer model)"),UOr=l(),L0=a("li"),R8e=a("strong"),HOr=o("speech_to_text"),JOr=o(" \u2014 "),fte=a("a"),YOr=o("TFSpeech2TextModel"),ZOr=o(" (Speech2Text model)"),KOr=l(),y0=a("li"),P8e=a("strong"),eVr=o("swin"),oVr=o(" \u2014 "),gte=a("a"),rVr=o("TFSwinModel"),tVr=o(" (Swin Transformer model)"),aVr=l(),x0=a("li"),B8e=a("strong"),nVr=o("t5"),sVr=o(" \u2014 "),hte=a("a"),lVr=o("TFT5Model"),iVr=o(" (T5 model)"),dVr=l(),$0=a("li"),I8e=a("strong"),mVr=o("tapas"),cVr=o(" \u2014 "),ute=a("a"),fVr=o("TFTapasModel"),gVr=o(" (TAPAS model)"),hVr=l(),k0=a("li"),N8e=a("strong"),uVr=o("transfo-xl"),pVr=o(" \u2014 "),pte=a("a"),_Vr=o("TFTransfoXLModel"),bVr=o(" (Transformer-XL model)"),vVr=l(),S0=a("li"),q8e=a("strong"),FVr=o("vit"),TVr=o(" \u2014 "),_te=a("a"),MVr=o("TFViTModel"),EVr=o(" (ViT model)"),CVr=l(),R0=a("li"),j8e=a("strong"),wVr=o("vit_mae"),AVr=o(" \u2014 "),bte=a("a"),LVr=o("TFViTMAEModel"),yVr=o(" (ViTMAE model)"),xVr=l(),P0=a("li"),D8e=a("strong"),$Vr=o("wav2vec2"),kVr=o(" \u2014 "),vte=a("a"),SVr=o("TFWav2Vec2Model"),RVr=o(" (Wav2Vec2 model)"),PVr=l(),B0=a("li"),G8e=a("strong"),BVr=o("whisper"),IVr=o(" \u2014 "),Fte=a("a"),NVr=o("TFWhisperModel"),qVr=o(" (Whisper model)"),jVr=l(),I0=a("li"),O8e=a("strong"),DVr=o("xglm"),GVr=o(" \u2014 "),Tte=a("a"),OVr=o("TFXGLMModel"),VVr=o(" (XGLM model)"),XVr=l(),N0=a("li"),V8e=a("strong"),zVr=o("xlm"),QVr=o(" \u2014 "),Mte=a("a"),WVr=o("TFXLMModel"),UVr=o(" (XLM model)"),HVr=l(),q0=a("li"),X8e=a("strong"),JVr=o("xlm-roberta"),YVr=o(" \u2014 "),Ete=a("a"),ZVr=o("TFXLMRobertaModel"),KVr=o(" (XLM-RoBERTa model)"),eXr=l(),j0=a("li"),z8e=a("strong"),oXr=o("xlnet"),rXr=o(" \u2014 "),Cte=a("a"),tXr=o("TFXLNetModel"),aXr=o(" (XLNet model)"),nXr=l(),F(D0.$$.fragment),dno=l(),hc=a("h2"),G0=a("a"),Q8e=a("span"),F(CR.$$.fragment),sXr=l(),W8e=a("span"),lXr=o("TFAutoModelForPreTraining"),mno=l(),cr=a("div"),F(wR.$$.fragment),iXr=l(),uc=a("p"),dXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),wte=a("a"),mXr=o("from_pretrained()"),cXr=o(" class method or the "),Ate=a("a"),fXr=o("from_config()"),gXr=o(` class
method.`),hXr=l(),AR=a("p"),uXr=o("This class cannot be instantiated directly using "),U8e=a("code"),pXr=o("__init__()"),_Xr=o(" (throws an error)."),bXr=l(),Zt=a("div"),F(LR.$$.fragment),vXr=l(),H8e=a("p"),FXr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),TXr=l(),pc=a("p"),MXr=o(`Note:
Loading a model from its configuration file does `),J8e=a("strong"),EXr=o("not"),CXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Lte=a("a"),wXr=o("from_pretrained()"),AXr=o(" to load the model weights."),LXr=l(),F(O0.$$.fragment),yXr=l(),Gr=a("div"),F(yR.$$.fragment),xXr=l(),Y8e=a("p"),$Xr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),kXr=l(),In=a("p"),SXr=o("The model class to instantiate is selected based on the "),Z8e=a("code"),RXr=o("model_type"),PXr=o(` property of the config object (either
passed as an argument or loaded from `),K8e=a("code"),BXr=o("pretrained_model_name_or_path"),IXr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eLe=a("code"),NXr=o("pretrained_model_name_or_path"),qXr=o(":"),jXr=l(),le=a("ul"),V0=a("li"),oLe=a("strong"),DXr=o("albert"),GXr=o(" \u2014 "),yte=a("a"),OXr=o("TFAlbertForPreTraining"),VXr=o(" (ALBERT model)"),XXr=l(),X0=a("li"),rLe=a("strong"),zXr=o("bart"),QXr=o(" \u2014 "),xte=a("a"),WXr=o("TFBartForConditionalGeneration"),UXr=o(" (BART model)"),HXr=l(),z0=a("li"),tLe=a("strong"),JXr=o("bert"),YXr=o(" \u2014 "),$te=a("a"),ZXr=o("TFBertForPreTraining"),KXr=o(" (BERT model)"),ezr=l(),Q0=a("li"),aLe=a("strong"),ozr=o("camembert"),rzr=o(" \u2014 "),kte=a("a"),tzr=o("TFCamembertForMaskedLM"),azr=o(" (CamemBERT model)"),nzr=l(),W0=a("li"),nLe=a("strong"),szr=o("ctrl"),lzr=o(" \u2014 "),Ste=a("a"),izr=o("TFCTRLLMHeadModel"),dzr=o(" (CTRL model)"),mzr=l(),U0=a("li"),sLe=a("strong"),czr=o("distilbert"),fzr=o(" \u2014 "),Rte=a("a"),gzr=o("TFDistilBertForMaskedLM"),hzr=o(" (DistilBERT model)"),uzr=l(),H0=a("li"),lLe=a("strong"),pzr=o("electra"),_zr=o(" \u2014 "),Pte=a("a"),bzr=o("TFElectraForPreTraining"),vzr=o(" (ELECTRA model)"),Fzr=l(),J0=a("li"),iLe=a("strong"),Tzr=o("flaubert"),Mzr=o(" \u2014 "),Bte=a("a"),Ezr=o("TFFlaubertWithLMHeadModel"),Czr=o(" (FlauBERT model)"),wzr=l(),Y0=a("li"),dLe=a("strong"),Azr=o("funnel"),Lzr=o(" \u2014 "),Ite=a("a"),yzr=o("TFFunnelForPreTraining"),xzr=o(" (Funnel Transformer model)"),$zr=l(),Z0=a("li"),mLe=a("strong"),kzr=o("gpt2"),Szr=o(" \u2014 "),Nte=a("a"),Rzr=o("TFGPT2LMHeadModel"),Pzr=o(" (OpenAI GPT-2 model)"),Bzr=l(),K0=a("li"),cLe=a("strong"),Izr=o("layoutlm"),Nzr=o(" \u2014 "),qte=a("a"),qzr=o("TFLayoutLMForMaskedLM"),jzr=o(" (LayoutLM model)"),Dzr=l(),ew=a("li"),fLe=a("strong"),Gzr=o("lxmert"),Ozr=o(" \u2014 "),jte=a("a"),Vzr=o("TFLxmertForPreTraining"),Xzr=o(" (LXMERT model)"),zzr=l(),ow=a("li"),gLe=a("strong"),Qzr=o("mobilebert"),Wzr=o(" \u2014 "),Dte=a("a"),Uzr=o("TFMobileBertForPreTraining"),Hzr=o(" (MobileBERT model)"),Jzr=l(),rw=a("li"),hLe=a("strong"),Yzr=o("mpnet"),Zzr=o(" \u2014 "),Gte=a("a"),Kzr=o("TFMPNetForMaskedLM"),eQr=o(" (MPNet model)"),oQr=l(),tw=a("li"),uLe=a("strong"),rQr=o("openai-gpt"),tQr=o(" \u2014 "),Ote=a("a"),aQr=o("TFOpenAIGPTLMHeadModel"),nQr=o(" (OpenAI GPT model)"),sQr=l(),aw=a("li"),pLe=a("strong"),lQr=o("roberta"),iQr=o(" \u2014 "),Vte=a("a"),dQr=o("TFRobertaForMaskedLM"),mQr=o(" (RoBERTa model)"),cQr=l(),nw=a("li"),_Le=a("strong"),fQr=o("t5"),gQr=o(" \u2014 "),Xte=a("a"),hQr=o("TFT5ForConditionalGeneration"),uQr=o(" (T5 model)"),pQr=l(),sw=a("li"),bLe=a("strong"),_Qr=o("tapas"),bQr=o(" \u2014 "),zte=a("a"),vQr=o("TFTapasForMaskedLM"),FQr=o(" (TAPAS model)"),TQr=l(),lw=a("li"),vLe=a("strong"),MQr=o("transfo-xl"),EQr=o(" \u2014 "),Qte=a("a"),CQr=o("TFTransfoXLLMHeadModel"),wQr=o(" (Transformer-XL model)"),AQr=l(),iw=a("li"),FLe=a("strong"),LQr=o("vit_mae"),yQr=o(" \u2014 "),Wte=a("a"),xQr=o("TFViTMAEForPreTraining"),$Qr=o(" (ViTMAE model)"),kQr=l(),dw=a("li"),TLe=a("strong"),SQr=o("xlm"),RQr=o(" \u2014 "),Ute=a("a"),PQr=o("TFXLMWithLMHeadModel"),BQr=o(" (XLM model)"),IQr=l(),mw=a("li"),MLe=a("strong"),NQr=o("xlm-roberta"),qQr=o(" \u2014 "),Hte=a("a"),jQr=o("TFXLMRobertaForMaskedLM"),DQr=o(" (XLM-RoBERTa model)"),GQr=l(),cw=a("li"),ELe=a("strong"),OQr=o("xlnet"),VQr=o(" \u2014 "),Jte=a("a"),XQr=o("TFXLNetLMHeadModel"),zQr=o(" (XLNet model)"),QQr=l(),F(fw.$$.fragment),cno=l(),_c=a("h2"),gw=a("a"),CLe=a("span"),F(xR.$$.fragment),WQr=l(),wLe=a("span"),UQr=o("TFAutoModelForCausalLM"),fno=l(),fr=a("div"),F($R.$$.fragment),HQr=l(),bc=a("p"),JQr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Yte=a("a"),YQr=o("from_pretrained()"),ZQr=o(" class method or the "),Zte=a("a"),KQr=o("from_config()"),eWr=o(` class
method.`),oWr=l(),kR=a("p"),rWr=o("This class cannot be instantiated directly using "),ALe=a("code"),tWr=o("__init__()"),aWr=o(" (throws an error)."),nWr=l(),Kt=a("div"),F(SR.$$.fragment),sWr=l(),LLe=a("p"),lWr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),iWr=l(),vc=a("p"),dWr=o(`Note:
Loading a model from its configuration file does `),yLe=a("strong"),mWr=o("not"),cWr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Kte=a("a"),fWr=o("from_pretrained()"),gWr=o(" to load the model weights."),hWr=l(),F(hw.$$.fragment),uWr=l(),Or=a("div"),F(RR.$$.fragment),pWr=l(),xLe=a("p"),_Wr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),bWr=l(),Nn=a("p"),vWr=o("The model class to instantiate is selected based on the "),$Le=a("code"),FWr=o("model_type"),TWr=o(` property of the config object (either
passed as an argument or loaded from `),kLe=a("code"),MWr=o("pretrained_model_name_or_path"),EWr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SLe=a("code"),CWr=o("pretrained_model_name_or_path"),wWr=o(":"),AWr=l(),Me=a("ul"),uw=a("li"),RLe=a("strong"),LWr=o("bert"),yWr=o(" \u2014 "),eae=a("a"),xWr=o("TFBertLMHeadModel"),$Wr=o(" (BERT model)"),kWr=l(),pw=a("li"),PLe=a("strong"),SWr=o("camembert"),RWr=o(" \u2014 "),oae=a("a"),PWr=o("TFCamembertForCausalLM"),BWr=o(" (CamemBERT model)"),IWr=l(),_w=a("li"),BLe=a("strong"),NWr=o("ctrl"),qWr=o(" \u2014 "),rae=a("a"),jWr=o("TFCTRLLMHeadModel"),DWr=o(" (CTRL model)"),GWr=l(),bw=a("li"),ILe=a("strong"),OWr=o("gpt2"),VWr=o(" \u2014 "),tae=a("a"),XWr=o("TFGPT2LMHeadModel"),zWr=o(" (OpenAI GPT-2 model)"),QWr=l(),vw=a("li"),NLe=a("strong"),WWr=o("gptj"),UWr=o(" \u2014 "),aae=a("a"),HWr=o("TFGPTJForCausalLM"),JWr=o(" (GPT-J model)"),YWr=l(),Fw=a("li"),qLe=a("strong"),ZWr=o("openai-gpt"),KWr=o(" \u2014 "),nae=a("a"),eUr=o("TFOpenAIGPTLMHeadModel"),oUr=o(" (OpenAI GPT model)"),rUr=l(),Tw=a("li"),jLe=a("strong"),tUr=o("opt"),aUr=o(" \u2014 "),sae=a("a"),nUr=o("TFOPTForCausalLM"),sUr=o(" (OPT model)"),lUr=l(),Mw=a("li"),DLe=a("strong"),iUr=o("rembert"),dUr=o(" \u2014 "),lae=a("a"),mUr=o("TFRemBertForCausalLM"),cUr=o(" (RemBERT model)"),fUr=l(),Ew=a("li"),GLe=a("strong"),gUr=o("roberta"),hUr=o(" \u2014 "),iae=a("a"),uUr=o("TFRobertaForCausalLM"),pUr=o(" (RoBERTa model)"),_Ur=l(),Cw=a("li"),OLe=a("strong"),bUr=o("roformer"),vUr=o(" \u2014 "),dae=a("a"),FUr=o("TFRoFormerForCausalLM"),TUr=o(" (RoFormer model)"),MUr=l(),ww=a("li"),VLe=a("strong"),EUr=o("transfo-xl"),CUr=o(" \u2014 "),mae=a("a"),wUr=o("TFTransfoXLLMHeadModel"),AUr=o(" (Transformer-XL model)"),LUr=l(),Aw=a("li"),XLe=a("strong"),yUr=o("xglm"),xUr=o(" \u2014 "),cae=a("a"),$Ur=o("TFXGLMForCausalLM"),kUr=o(" (XGLM model)"),SUr=l(),Lw=a("li"),zLe=a("strong"),RUr=o("xlm"),PUr=o(" \u2014 "),fae=a("a"),BUr=o("TFXLMWithLMHeadModel"),IUr=o(" (XLM model)"),NUr=l(),yw=a("li"),QLe=a("strong"),qUr=o("xlnet"),jUr=o(" \u2014 "),gae=a("a"),DUr=o("TFXLNetLMHeadModel"),GUr=o(" (XLNet model)"),OUr=l(),F(xw.$$.fragment),gno=l(),Fc=a("h2"),$w=a("a"),WLe=a("span"),F(PR.$$.fragment),VUr=l(),ULe=a("span"),XUr=o("TFAutoModelForImageClassification"),hno=l(),gr=a("div"),F(BR.$$.fragment),zUr=l(),Tc=a("p"),QUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),hae=a("a"),WUr=o("from_pretrained()"),UUr=o(" class method or the "),uae=a("a"),HUr=o("from_config()"),JUr=o(` class
method.`),YUr=l(),IR=a("p"),ZUr=o("This class cannot be instantiated directly using "),HLe=a("code"),KUr=o("__init__()"),eHr=o(" (throws an error)."),oHr=l(),ea=a("div"),F(NR.$$.fragment),rHr=l(),JLe=a("p"),tHr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),aHr=l(),Mc=a("p"),nHr=o(`Note:
Loading a model from its configuration file does `),YLe=a("strong"),sHr=o("not"),lHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pae=a("a"),iHr=o("from_pretrained()"),dHr=o(" to load the model weights."),mHr=l(),F(kw.$$.fragment),cHr=l(),Vr=a("div"),F(qR.$$.fragment),fHr=l(),ZLe=a("p"),gHr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),hHr=l(),qn=a("p"),uHr=o("The model class to instantiate is selected based on the "),KLe=a("code"),pHr=o("model_type"),_Hr=o(` property of the config object (either
passed as an argument or loaded from `),eye=a("code"),bHr=o("pretrained_model_name_or_path"),vHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oye=a("code"),FHr=o("pretrained_model_name_or_path"),THr=o(":"),MHr=l(),ye=a("ul"),Sw=a("li"),rye=a("strong"),EHr=o("convnext"),CHr=o(" \u2014 "),_ae=a("a"),wHr=o("TFConvNextForImageClassification"),AHr=o(" (ConvNeXT model)"),LHr=l(),Rw=a("li"),tye=a("strong"),yHr=o("cvt"),xHr=o(" \u2014 "),bae=a("a"),$Hr=o("TFCvtForImageClassification"),kHr=o(" (CvT model)"),SHr=l(),Pw=a("li"),aye=a("strong"),RHr=o("data2vec-vision"),PHr=o(" \u2014 "),vae=a("a"),BHr=o("TFData2VecVisionForImageClassification"),IHr=o(" (Data2VecVision model)"),NHr=l(),Pl=a("li"),nye=a("strong"),qHr=o("deit"),jHr=o(" \u2014 "),Fae=a("a"),DHr=o("TFDeiTForImageClassification"),GHr=o(" or "),Tae=a("a"),OHr=o("TFDeiTForImageClassificationWithTeacher"),VHr=o(" (DeiT model)"),XHr=l(),Bw=a("li"),sye=a("strong"),zHr=o("mobilevit"),QHr=o(" \u2014 "),Mae=a("a"),WHr=o("TFMobileViTForImageClassification"),UHr=o(" (MobileViT model)"),HHr=l(),Iw=a("li"),lye=a("strong"),JHr=o("regnet"),YHr=o(" \u2014 "),Eae=a("a"),ZHr=o("TFRegNetForImageClassification"),KHr=o(" (RegNet model)"),eJr=l(),Nw=a("li"),iye=a("strong"),oJr=o("resnet"),rJr=o(" \u2014 "),Cae=a("a"),tJr=o("TFResNetForImageClassification"),aJr=o(" (ResNet model)"),nJr=l(),qw=a("li"),dye=a("strong"),sJr=o("segformer"),lJr=o(" \u2014 "),wae=a("a"),iJr=o("TFSegformerForImageClassification"),dJr=o(" (SegFormer model)"),mJr=l(),jw=a("li"),mye=a("strong"),cJr=o("swin"),fJr=o(" \u2014 "),Aae=a("a"),gJr=o("TFSwinForImageClassification"),hJr=o(" (Swin Transformer model)"),uJr=l(),Dw=a("li"),cye=a("strong"),pJr=o("vit"),_Jr=o(" \u2014 "),Lae=a("a"),bJr=o("TFViTForImageClassification"),vJr=o(" (ViT model)"),FJr=l(),F(Gw.$$.fragment),uno=l(),Ec=a("h2"),Ow=a("a"),fye=a("span"),F(jR.$$.fragment),TJr=l(),gye=a("span"),MJr=o("TFAutoModelForSemanticSegmentation"),pno=l(),hr=a("div"),F(DR.$$.fragment),EJr=l(),Cc=a("p"),CJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),yae=a("a"),wJr=o("from_pretrained()"),AJr=o(" class method or the "),xae=a("a"),LJr=o("from_config()"),yJr=o(` class
method.`),xJr=l(),GR=a("p"),$Jr=o("This class cannot be instantiated directly using "),hye=a("code"),kJr=o("__init__()"),SJr=o(" (throws an error)."),RJr=l(),oa=a("div"),F(OR.$$.fragment),PJr=l(),uye=a("p"),BJr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),IJr=l(),wc=a("p"),NJr=o(`Note:
Loading a model from its configuration file does `),pye=a("strong"),qJr=o("not"),jJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$ae=a("a"),DJr=o("from_pretrained()"),GJr=o(" to load the model weights."),OJr=l(),F(Vw.$$.fragment),VJr=l(),Xr=a("div"),F(VR.$$.fragment),XJr=l(),_ye=a("p"),zJr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),QJr=l(),jn=a("p"),WJr=o("The model class to instantiate is selected based on the "),bye=a("code"),UJr=o("model_type"),HJr=o(` property of the config object (either
passed as an argument or loaded from `),vye=a("code"),JJr=o("pretrained_model_name_or_path"),YJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fye=a("code"),ZJr=o("pretrained_model_name_or_path"),KJr=o(":"),eYr=l(),Ac=a("ul"),Xw=a("li"),Tye=a("strong"),oYr=o("data2vec-vision"),rYr=o(" \u2014 "),kae=a("a"),tYr=o("TFData2VecVisionForSemanticSegmentation"),aYr=o(" (Data2VecVision model)"),nYr=l(),zw=a("li"),Mye=a("strong"),sYr=o("mobilevit"),lYr=o(" \u2014 "),Sae=a("a"),iYr=o("TFMobileViTForSemanticSegmentation"),dYr=o(" (MobileViT model)"),mYr=l(),Qw=a("li"),Eye=a("strong"),cYr=o("segformer"),fYr=o(" \u2014 "),Rae=a("a"),gYr=o("TFSegformerForSemanticSegmentation"),hYr=o(" (SegFormer model)"),uYr=l(),F(Ww.$$.fragment),_no=l(),Lc=a("h2"),Uw=a("a"),Cye=a("span"),F(XR.$$.fragment),pYr=l(),wye=a("span"),_Yr=o("TFAutoModelForMaskedLM"),bno=l(),ur=a("div"),F(zR.$$.fragment),bYr=l(),yc=a("p"),vYr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Pae=a("a"),FYr=o("from_pretrained()"),TYr=o(" class method or the "),Bae=a("a"),MYr=o("from_config()"),EYr=o(` class
method.`),CYr=l(),QR=a("p"),wYr=o("This class cannot be instantiated directly using "),Aye=a("code"),AYr=o("__init__()"),LYr=o(" (throws an error)."),yYr=l(),ra=a("div"),F(WR.$$.fragment),xYr=l(),Lye=a("p"),$Yr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),kYr=l(),xc=a("p"),SYr=o(`Note:
Loading a model from its configuration file does `),yye=a("strong"),RYr=o("not"),PYr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Iae=a("a"),BYr=o("from_pretrained()"),IYr=o(" to load the model weights."),NYr=l(),F(Hw.$$.fragment),qYr=l(),zr=a("div"),F(UR.$$.fragment),jYr=l(),xye=a("p"),DYr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),GYr=l(),Dn=a("p"),OYr=o("The model class to instantiate is selected based on the "),$ye=a("code"),VYr=o("model_type"),XYr=o(` property of the config object (either
passed as an argument or loaded from `),kye=a("code"),zYr=o("pretrained_model_name_or_path"),QYr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sye=a("code"),WYr=o("pretrained_model_name_or_path"),UYr=o(":"),HYr=l(),ce=a("ul"),Jw=a("li"),Rye=a("strong"),JYr=o("albert"),YYr=o(" \u2014 "),Nae=a("a"),ZYr=o("TFAlbertForMaskedLM"),KYr=o(" (ALBERT model)"),eZr=l(),Yw=a("li"),Pye=a("strong"),oZr=o("bert"),rZr=o(" \u2014 "),qae=a("a"),tZr=o("TFBertForMaskedLM"),aZr=o(" (BERT model)"),nZr=l(),Zw=a("li"),Bye=a("strong"),sZr=o("camembert"),lZr=o(" \u2014 "),jae=a("a"),iZr=o("TFCamembertForMaskedLM"),dZr=o(" (CamemBERT model)"),mZr=l(),Kw=a("li"),Iye=a("strong"),cZr=o("convbert"),fZr=o(" \u2014 "),Dae=a("a"),gZr=o("TFConvBertForMaskedLM"),hZr=o(" (ConvBERT model)"),uZr=l(),eA=a("li"),Nye=a("strong"),pZr=o("deberta"),_Zr=o(" \u2014 "),Gae=a("a"),bZr=o("TFDebertaForMaskedLM"),vZr=o(" (DeBERTa model)"),FZr=l(),oA=a("li"),qye=a("strong"),TZr=o("deberta-v2"),MZr=o(" \u2014 "),Oae=a("a"),EZr=o("TFDebertaV2ForMaskedLM"),CZr=o(" (DeBERTa-v2 model)"),wZr=l(),rA=a("li"),jye=a("strong"),AZr=o("distilbert"),LZr=o(" \u2014 "),Vae=a("a"),yZr=o("TFDistilBertForMaskedLM"),xZr=o(" (DistilBERT model)"),$Zr=l(),tA=a("li"),Dye=a("strong"),kZr=o("electra"),SZr=o(" \u2014 "),Xae=a("a"),RZr=o("TFElectraForMaskedLM"),PZr=o(" (ELECTRA model)"),BZr=l(),aA=a("li"),Gye=a("strong"),IZr=o("esm"),NZr=o(" \u2014 "),zae=a("a"),qZr=o("TFEsmForMaskedLM"),jZr=o(" (ESM model)"),DZr=l(),nA=a("li"),Oye=a("strong"),GZr=o("flaubert"),OZr=o(" \u2014 "),Qae=a("a"),VZr=o("TFFlaubertWithLMHeadModel"),XZr=o(" (FlauBERT model)"),zZr=l(),sA=a("li"),Vye=a("strong"),QZr=o("funnel"),WZr=o(" \u2014 "),Wae=a("a"),UZr=o("TFFunnelForMaskedLM"),HZr=o(" (Funnel Transformer model)"),JZr=l(),lA=a("li"),Xye=a("strong"),YZr=o("layoutlm"),ZZr=o(" \u2014 "),Uae=a("a"),KZr=o("TFLayoutLMForMaskedLM"),eKr=o(" (LayoutLM model)"),oKr=l(),iA=a("li"),zye=a("strong"),rKr=o("longformer"),tKr=o(" \u2014 "),Hae=a("a"),aKr=o("TFLongformerForMaskedLM"),nKr=o(" (Longformer model)"),sKr=l(),dA=a("li"),Qye=a("strong"),lKr=o("mobilebert"),iKr=o(" \u2014 "),Jae=a("a"),dKr=o("TFMobileBertForMaskedLM"),mKr=o(" (MobileBERT model)"),cKr=l(),mA=a("li"),Wye=a("strong"),fKr=o("mpnet"),gKr=o(" \u2014 "),Yae=a("a"),hKr=o("TFMPNetForMaskedLM"),uKr=o(" (MPNet model)"),pKr=l(),cA=a("li"),Uye=a("strong"),_Kr=o("rembert"),bKr=o(" \u2014 "),Zae=a("a"),vKr=o("TFRemBertForMaskedLM"),FKr=o(" (RemBERT model)"),TKr=l(),fA=a("li"),Hye=a("strong"),MKr=o("roberta"),EKr=o(" \u2014 "),Kae=a("a"),CKr=o("TFRobertaForMaskedLM"),wKr=o(" (RoBERTa model)"),AKr=l(),gA=a("li"),Jye=a("strong"),LKr=o("roformer"),yKr=o(" \u2014 "),ene=a("a"),xKr=o("TFRoFormerForMaskedLM"),$Kr=o(" (RoFormer model)"),kKr=l(),hA=a("li"),Yye=a("strong"),SKr=o("tapas"),RKr=o(" \u2014 "),one=a("a"),PKr=o("TFTapasForMaskedLM"),BKr=o(" (TAPAS model)"),IKr=l(),uA=a("li"),Zye=a("strong"),NKr=o("xlm"),qKr=o(" \u2014 "),rne=a("a"),jKr=o("TFXLMWithLMHeadModel"),DKr=o(" (XLM model)"),GKr=l(),pA=a("li"),Kye=a("strong"),OKr=o("xlm-roberta"),VKr=o(" \u2014 "),tne=a("a"),XKr=o("TFXLMRobertaForMaskedLM"),zKr=o(" (XLM-RoBERTa model)"),QKr=l(),F(_A.$$.fragment),vno=l(),$c=a("h2"),bA=a("a"),e9e=a("span"),F(HR.$$.fragment),WKr=l(),o9e=a("span"),UKr=o("TFAutoModelForSeq2SeqLM"),Fno=l(),pr=a("div"),F(JR.$$.fragment),HKr=l(),kc=a("p"),JKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),ane=a("a"),YKr=o("from_pretrained()"),ZKr=o(" class method or the "),nne=a("a"),KKr=o("from_config()"),eet=o(` class
method.`),oet=l(),YR=a("p"),ret=o("This class cannot be instantiated directly using "),r9e=a("code"),tet=o("__init__()"),aet=o(" (throws an error)."),net=l(),ta=a("div"),F(ZR.$$.fragment),set=l(),t9e=a("p"),iet=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),det=l(),Sc=a("p"),met=o(`Note:
Loading a model from its configuration file does `),a9e=a("strong"),cet=o("not"),fet=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sne=a("a"),get=o("from_pretrained()"),het=o(" to load the model weights."),uet=l(),F(vA.$$.fragment),pet=l(),Qr=a("div"),F(KR.$$.fragment),_et=l(),n9e=a("p"),bet=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),vet=l(),Gn=a("p"),Fet=o("The model class to instantiate is selected based on the "),s9e=a("code"),Tet=o("model_type"),Met=o(` property of the config object (either
passed as an argument or loaded from `),l9e=a("code"),Eet=o("pretrained_model_name_or_path"),Cet=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i9e=a("code"),wet=o("pretrained_model_name_or_path"),Aet=o(":"),Let=l(),xe=a("ul"),FA=a("li"),d9e=a("strong"),yet=o("bart"),xet=o(" \u2014 "),lne=a("a"),$et=o("TFBartForConditionalGeneration"),ket=o(" (BART model)"),Set=l(),TA=a("li"),m9e=a("strong"),Ret=o("blenderbot"),Pet=o(" \u2014 "),ine=a("a"),Bet=o("TFBlenderbotForConditionalGeneration"),Iet=o(" (Blenderbot model)"),Net=l(),MA=a("li"),c9e=a("strong"),qet=o("blenderbot-small"),jet=o(" \u2014 "),dne=a("a"),Det=o("TFBlenderbotSmallForConditionalGeneration"),Get=o(" (BlenderbotSmall model)"),Oet=l(),EA=a("li"),f9e=a("strong"),Vet=o("encoder-decoder"),Xet=o(" \u2014 "),mne=a("a"),zet=o("TFEncoderDecoderModel"),Qet=o(" (Encoder decoder model)"),Wet=l(),CA=a("li"),g9e=a("strong"),Uet=o("led"),Het=o(" \u2014 "),cne=a("a"),Jet=o("TFLEDForConditionalGeneration"),Yet=o(" (LED model)"),Zet=l(),wA=a("li"),h9e=a("strong"),Ket=o("marian"),eot=o(" \u2014 "),fne=a("a"),oot=o("TFMarianMTModel"),rot=o(" (Marian model)"),tot=l(),AA=a("li"),u9e=a("strong"),aot=o("mbart"),not=o(" \u2014 "),gne=a("a"),sot=o("TFMBartForConditionalGeneration"),lot=o(" (mBART model)"),iot=l(),LA=a("li"),p9e=a("strong"),dot=o("mt5"),mot=o(" \u2014 "),hne=a("a"),cot=o("TFMT5ForConditionalGeneration"),fot=o(" (MT5 model)"),got=l(),yA=a("li"),_9e=a("strong"),hot=o("pegasus"),uot=o(" \u2014 "),une=a("a"),pot=o("TFPegasusForConditionalGeneration"),_ot=o(" (Pegasus model)"),bot=l(),xA=a("li"),b9e=a("strong"),vot=o("t5"),Fot=o(" \u2014 "),pne=a("a"),Tot=o("TFT5ForConditionalGeneration"),Mot=o(" (T5 model)"),Eot=l(),F($A.$$.fragment),Tno=l(),Rc=a("h2"),kA=a("a"),v9e=a("span"),F(eP.$$.fragment),Cot=l(),F9e=a("span"),wot=o("TFAutoModelForSequenceClassification"),Mno=l(),_r=a("div"),F(oP.$$.fragment),Aot=l(),Pc=a("p"),Lot=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),_ne=a("a"),yot=o("from_pretrained()"),xot=o(" class method or the "),bne=a("a"),$ot=o("from_config()"),kot=o(` class
method.`),Sot=l(),rP=a("p"),Rot=o("This class cannot be instantiated directly using "),T9e=a("code"),Pot=o("__init__()"),Bot=o(" (throws an error)."),Iot=l(),aa=a("div"),F(tP.$$.fragment),Not=l(),M9e=a("p"),qot=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),jot=l(),Bc=a("p"),Dot=o(`Note:
Loading a model from its configuration file does `),E9e=a("strong"),Got=o("not"),Oot=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vne=a("a"),Vot=o("from_pretrained()"),Xot=o(" to load the model weights."),zot=l(),F(SA.$$.fragment),Qot=l(),Wr=a("div"),F(aP.$$.fragment),Wot=l(),C9e=a("p"),Uot=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Hot=l(),On=a("p"),Jot=o("The model class to instantiate is selected based on the "),w9e=a("code"),Yot=o("model_type"),Zot=o(` property of the config object (either
passed as an argument or loaded from `),A9e=a("code"),Kot=o("pretrained_model_name_or_path"),ert=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L9e=a("code"),ort=o("pretrained_model_name_or_path"),rrt=o(":"),trt=l(),re=a("ul"),RA=a("li"),y9e=a("strong"),art=o("albert"),nrt=o(" \u2014 "),Fne=a("a"),srt=o("TFAlbertForSequenceClassification"),lrt=o(" (ALBERT model)"),irt=l(),PA=a("li"),x9e=a("strong"),drt=o("bert"),mrt=o(" \u2014 "),Tne=a("a"),crt=o("TFBertForSequenceClassification"),frt=o(" (BERT model)"),grt=l(),BA=a("li"),$9e=a("strong"),hrt=o("camembert"),urt=o(" \u2014 "),Mne=a("a"),prt=o("TFCamembertForSequenceClassification"),_rt=o(" (CamemBERT model)"),brt=l(),IA=a("li"),k9e=a("strong"),vrt=o("convbert"),Frt=o(" \u2014 "),Ene=a("a"),Trt=o("TFConvBertForSequenceClassification"),Mrt=o(" (ConvBERT model)"),Ert=l(),NA=a("li"),S9e=a("strong"),Crt=o("ctrl"),wrt=o(" \u2014 "),Cne=a("a"),Art=o("TFCTRLForSequenceClassification"),Lrt=o(" (CTRL model)"),yrt=l(),qA=a("li"),R9e=a("strong"),xrt=o("deberta"),$rt=o(" \u2014 "),wne=a("a"),krt=o("TFDebertaForSequenceClassification"),Srt=o(" (DeBERTa model)"),Rrt=l(),jA=a("li"),P9e=a("strong"),Prt=o("deberta-v2"),Brt=o(" \u2014 "),Ane=a("a"),Irt=o("TFDebertaV2ForSequenceClassification"),Nrt=o(" (DeBERTa-v2 model)"),qrt=l(),DA=a("li"),B9e=a("strong"),jrt=o("distilbert"),Drt=o(" \u2014 "),Lne=a("a"),Grt=o("TFDistilBertForSequenceClassification"),Ort=o(" (DistilBERT model)"),Vrt=l(),GA=a("li"),I9e=a("strong"),Xrt=o("electra"),zrt=o(" \u2014 "),yne=a("a"),Qrt=o("TFElectraForSequenceClassification"),Wrt=o(" (ELECTRA model)"),Urt=l(),OA=a("li"),N9e=a("strong"),Hrt=o("esm"),Jrt=o(" \u2014 "),xne=a("a"),Yrt=o("TFEsmForSequenceClassification"),Zrt=o(" (ESM model)"),Krt=l(),VA=a("li"),q9e=a("strong"),ett=o("flaubert"),ott=o(" \u2014 "),$ne=a("a"),rtt=o("TFFlaubertForSequenceClassification"),ttt=o(" (FlauBERT model)"),att=l(),XA=a("li"),j9e=a("strong"),ntt=o("funnel"),stt=o(" \u2014 "),kne=a("a"),ltt=o("TFFunnelForSequenceClassification"),itt=o(" (Funnel Transformer model)"),dtt=l(),zA=a("li"),D9e=a("strong"),mtt=o("gpt2"),ctt=o(" \u2014 "),Sne=a("a"),ftt=o("TFGPT2ForSequenceClassification"),gtt=o(" (OpenAI GPT-2 model)"),htt=l(),QA=a("li"),G9e=a("strong"),utt=o("gptj"),ptt=o(" \u2014 "),Rne=a("a"),_tt=o("TFGPTJForSequenceClassification"),btt=o(" (GPT-J model)"),vtt=l(),WA=a("li"),O9e=a("strong"),Ftt=o("layoutlm"),Ttt=o(" \u2014 "),Pne=a("a"),Mtt=o("TFLayoutLMForSequenceClassification"),Ett=o(" (LayoutLM model)"),Ctt=l(),UA=a("li"),V9e=a("strong"),wtt=o("layoutlmv3"),Att=o(" \u2014 "),Bne=a("a"),Ltt=o("TFLayoutLMv3ForSequenceClassification"),ytt=o(" (LayoutLMv3 model)"),xtt=l(),HA=a("li"),X9e=a("strong"),$tt=o("longformer"),ktt=o(" \u2014 "),Ine=a("a"),Stt=o("TFLongformerForSequenceClassification"),Rtt=o(" (Longformer model)"),Ptt=l(),JA=a("li"),z9e=a("strong"),Btt=o("mobilebert"),Itt=o(" \u2014 "),Nne=a("a"),Ntt=o("TFMobileBertForSequenceClassification"),qtt=o(" (MobileBERT model)"),jtt=l(),YA=a("li"),Q9e=a("strong"),Dtt=o("mpnet"),Gtt=o(" \u2014 "),qne=a("a"),Ott=o("TFMPNetForSequenceClassification"),Vtt=o(" (MPNet model)"),Xtt=l(),ZA=a("li"),W9e=a("strong"),ztt=o("openai-gpt"),Qtt=o(" \u2014 "),jne=a("a"),Wtt=o("TFOpenAIGPTForSequenceClassification"),Utt=o(" (OpenAI GPT model)"),Htt=l(),KA=a("li"),U9e=a("strong"),Jtt=o("rembert"),Ytt=o(" \u2014 "),Dne=a("a"),Ztt=o("TFRemBertForSequenceClassification"),Ktt=o(" (RemBERT model)"),eat=l(),e6=a("li"),H9e=a("strong"),oat=o("roberta"),rat=o(" \u2014 "),Gne=a("a"),tat=o("TFRobertaForSequenceClassification"),aat=o(" (RoBERTa model)"),nat=l(),o6=a("li"),J9e=a("strong"),sat=o("roformer"),lat=o(" \u2014 "),One=a("a"),iat=o("TFRoFormerForSequenceClassification"),dat=o(" (RoFormer model)"),mat=l(),r6=a("li"),Y9e=a("strong"),cat=o("tapas"),fat=o(" \u2014 "),Vne=a("a"),gat=o("TFTapasForSequenceClassification"),hat=o(" (TAPAS model)"),uat=l(),t6=a("li"),Z9e=a("strong"),pat=o("transfo-xl"),_at=o(" \u2014 "),Xne=a("a"),bat=o("TFTransfoXLForSequenceClassification"),vat=o(" (Transformer-XL model)"),Fat=l(),a6=a("li"),K9e=a("strong"),Tat=o("xlm"),Mat=o(" \u2014 "),zne=a("a"),Eat=o("TFXLMForSequenceClassification"),Cat=o(" (XLM model)"),wat=l(),n6=a("li"),exe=a("strong"),Aat=o("xlm-roberta"),Lat=o(" \u2014 "),Qne=a("a"),yat=o("TFXLMRobertaForSequenceClassification"),xat=o(" (XLM-RoBERTa model)"),$at=l(),s6=a("li"),oxe=a("strong"),kat=o("xlnet"),Sat=o(" \u2014 "),Wne=a("a"),Rat=o("TFXLNetForSequenceClassification"),Pat=o(" (XLNet model)"),Bat=l(),F(l6.$$.fragment),Eno=l(),Ic=a("h2"),i6=a("a"),rxe=a("span"),F(nP.$$.fragment),Iat=l(),txe=a("span"),Nat=o("TFAutoModelForMultipleChoice"),Cno=l(),br=a("div"),F(sP.$$.fragment),qat=l(),Nc=a("p"),jat=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Une=a("a"),Dat=o("from_pretrained()"),Gat=o(" class method or the "),Hne=a("a"),Oat=o("from_config()"),Vat=o(` class
method.`),Xat=l(),lP=a("p"),zat=o("This class cannot be instantiated directly using "),axe=a("code"),Qat=o("__init__()"),Wat=o(" (throws an error)."),Uat=l(),na=a("div"),F(iP.$$.fragment),Hat=l(),nxe=a("p"),Jat=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Yat=l(),qc=a("p"),Zat=o(`Note:
Loading a model from its configuration file does `),sxe=a("strong"),Kat=o("not"),ent=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jne=a("a"),ont=o("from_pretrained()"),rnt=o(" to load the model weights."),tnt=l(),F(d6.$$.fragment),ant=l(),Ur=a("div"),F(dP.$$.fragment),nnt=l(),lxe=a("p"),snt=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),lnt=l(),Vn=a("p"),int=o("The model class to instantiate is selected based on the "),ixe=a("code"),dnt=o("model_type"),mnt=o(` property of the config object (either
passed as an argument or loaded from `),dxe=a("code"),cnt=o("pretrained_model_name_or_path"),fnt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mxe=a("code"),gnt=o("pretrained_model_name_or_path"),hnt=o(":"),unt=l(),ve=a("ul"),m6=a("li"),cxe=a("strong"),pnt=o("albert"),_nt=o(" \u2014 "),Yne=a("a"),bnt=o("TFAlbertForMultipleChoice"),vnt=o(" (ALBERT model)"),Fnt=l(),c6=a("li"),fxe=a("strong"),Tnt=o("bert"),Mnt=o(" \u2014 "),Zne=a("a"),Ent=o("TFBertForMultipleChoice"),Cnt=o(" (BERT model)"),wnt=l(),f6=a("li"),gxe=a("strong"),Ant=o("camembert"),Lnt=o(" \u2014 "),Kne=a("a"),ynt=o("TFCamembertForMultipleChoice"),xnt=o(" (CamemBERT model)"),$nt=l(),g6=a("li"),hxe=a("strong"),knt=o("convbert"),Snt=o(" \u2014 "),ese=a("a"),Rnt=o("TFConvBertForMultipleChoice"),Pnt=o(" (ConvBERT model)"),Bnt=l(),h6=a("li"),uxe=a("strong"),Int=o("distilbert"),Nnt=o(" \u2014 "),ose=a("a"),qnt=o("TFDistilBertForMultipleChoice"),jnt=o(" (DistilBERT model)"),Dnt=l(),u6=a("li"),pxe=a("strong"),Gnt=o("electra"),Ont=o(" \u2014 "),rse=a("a"),Vnt=o("TFElectraForMultipleChoice"),Xnt=o(" (ELECTRA model)"),znt=l(),p6=a("li"),_xe=a("strong"),Qnt=o("flaubert"),Wnt=o(" \u2014 "),tse=a("a"),Unt=o("TFFlaubertForMultipleChoice"),Hnt=o(" (FlauBERT model)"),Jnt=l(),_6=a("li"),bxe=a("strong"),Ynt=o("funnel"),Znt=o(" \u2014 "),ase=a("a"),Knt=o("TFFunnelForMultipleChoice"),est=o(" (Funnel Transformer model)"),ost=l(),b6=a("li"),vxe=a("strong"),rst=o("longformer"),tst=o(" \u2014 "),nse=a("a"),ast=o("TFLongformerForMultipleChoice"),nst=o(" (Longformer model)"),sst=l(),v6=a("li"),Fxe=a("strong"),lst=o("mobilebert"),ist=o(" \u2014 "),sse=a("a"),dst=o("TFMobileBertForMultipleChoice"),mst=o(" (MobileBERT model)"),cst=l(),F6=a("li"),Txe=a("strong"),fst=o("mpnet"),gst=o(" \u2014 "),lse=a("a"),hst=o("TFMPNetForMultipleChoice"),ust=o(" (MPNet model)"),pst=l(),T6=a("li"),Mxe=a("strong"),_st=o("rembert"),bst=o(" \u2014 "),ise=a("a"),vst=o("TFRemBertForMultipleChoice"),Fst=o(" (RemBERT model)"),Tst=l(),M6=a("li"),Exe=a("strong"),Mst=o("roberta"),Est=o(" \u2014 "),dse=a("a"),Cst=o("TFRobertaForMultipleChoice"),wst=o(" (RoBERTa model)"),Ast=l(),E6=a("li"),Cxe=a("strong"),Lst=o("roformer"),yst=o(" \u2014 "),mse=a("a"),xst=o("TFRoFormerForMultipleChoice"),$st=o(" (RoFormer model)"),kst=l(),C6=a("li"),wxe=a("strong"),Sst=o("xlm"),Rst=o(" \u2014 "),cse=a("a"),Pst=o("TFXLMForMultipleChoice"),Bst=o(" (XLM model)"),Ist=l(),w6=a("li"),Axe=a("strong"),Nst=o("xlm-roberta"),qst=o(" \u2014 "),fse=a("a"),jst=o("TFXLMRobertaForMultipleChoice"),Dst=o(" (XLM-RoBERTa model)"),Gst=l(),A6=a("li"),Lxe=a("strong"),Ost=o("xlnet"),Vst=o(" \u2014 "),gse=a("a"),Xst=o("TFXLNetForMultipleChoice"),zst=o(" (XLNet model)"),Qst=l(),F(L6.$$.fragment),wno=l(),jc=a("h2"),y6=a("a"),yxe=a("span"),F(mP.$$.fragment),Wst=l(),xxe=a("span"),Ust=o("TFAutoModelForNextSentencePrediction"),Ano=l(),vr=a("div"),F(cP.$$.fragment),Hst=l(),Dc=a("p"),Jst=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),hse=a("a"),Yst=o("from_pretrained()"),Zst=o(" class method or the "),use=a("a"),Kst=o("from_config()"),elt=o(` class
method.`),olt=l(),fP=a("p"),rlt=o("This class cannot be instantiated directly using "),$xe=a("code"),tlt=o("__init__()"),alt=o(" (throws an error)."),nlt=l(),sa=a("div"),F(gP.$$.fragment),slt=l(),kxe=a("p"),llt=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),ilt=l(),Gc=a("p"),dlt=o(`Note:
Loading a model from its configuration file does `),Sxe=a("strong"),mlt=o("not"),clt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pse=a("a"),flt=o("from_pretrained()"),glt=o(" to load the model weights."),hlt=l(),F(x6.$$.fragment),ult=l(),Hr=a("div"),F(hP.$$.fragment),plt=l(),Rxe=a("p"),_lt=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),blt=l(),Xn=a("p"),vlt=o("The model class to instantiate is selected based on the "),Pxe=a("code"),Flt=o("model_type"),Tlt=o(` property of the config object (either
passed as an argument or loaded from `),Bxe=a("code"),Mlt=o("pretrained_model_name_or_path"),Elt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ixe=a("code"),Clt=o("pretrained_model_name_or_path"),wlt=o(":"),Alt=l(),uP=a("ul"),$6=a("li"),Nxe=a("strong"),Llt=o("bert"),ylt=o(" \u2014 "),_se=a("a"),xlt=o("TFBertForNextSentencePrediction"),$lt=o(" (BERT model)"),klt=l(),k6=a("li"),qxe=a("strong"),Slt=o("mobilebert"),Rlt=o(" \u2014 "),bse=a("a"),Plt=o("TFMobileBertForNextSentencePrediction"),Blt=o(" (MobileBERT model)"),Ilt=l(),F(S6.$$.fragment),Lno=l(),Oc=a("h2"),R6=a("a"),jxe=a("span"),F(pP.$$.fragment),Nlt=l(),Dxe=a("span"),qlt=o("TFAutoModelForTableQuestionAnswering"),yno=l(),Fr=a("div"),F(_P.$$.fragment),jlt=l(),Vc=a("p"),Dlt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),vse=a("a"),Glt=o("from_pretrained()"),Olt=o(" class method or the "),Fse=a("a"),Vlt=o("from_config()"),Xlt=o(` class
method.`),zlt=l(),bP=a("p"),Qlt=o("This class cannot be instantiated directly using "),Gxe=a("code"),Wlt=o("__init__()"),Ult=o(" (throws an error)."),Hlt=l(),la=a("div"),F(vP.$$.fragment),Jlt=l(),Oxe=a("p"),Ylt=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Zlt=l(),Xc=a("p"),Klt=o(`Note:
Loading a model from its configuration file does `),Vxe=a("strong"),eit=o("not"),oit=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Tse=a("a"),rit=o("from_pretrained()"),tit=o(" to load the model weights."),ait=l(),F(P6.$$.fragment),nit=l(),Jr=a("div"),F(FP.$$.fragment),sit=l(),Xxe=a("p"),lit=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),iit=l(),zn=a("p"),dit=o("The model class to instantiate is selected based on the "),zxe=a("code"),mit=o("model_type"),cit=o(` property of the config object (either
passed as an argument or loaded from `),Qxe=a("code"),fit=o("pretrained_model_name_or_path"),git=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wxe=a("code"),hit=o("pretrained_model_name_or_path"),uit=o(":"),pit=l(),Uxe=a("ul"),B6=a("li"),Hxe=a("strong"),_it=o("tapas"),bit=o(" \u2014 "),Mse=a("a"),vit=o("TFTapasForQuestionAnswering"),Fit=o(" (TAPAS model)"),Tit=l(),F(I6.$$.fragment),xno=l(),zc=a("h2"),N6=a("a"),Jxe=a("span"),F(TP.$$.fragment),Mit=l(),Yxe=a("span"),Eit=o("TFAutoModelForDocumentQuestionAnswering"),$no=l(),Tr=a("div"),F(MP.$$.fragment),Cit=l(),Qc=a("p"),wit=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),Ese=a("a"),Ait=o("from_pretrained()"),Lit=o(" class method or the "),Cse=a("a"),yit=o("from_config()"),xit=o(` class
method.`),$it=l(),EP=a("p"),kit=o("This class cannot be instantiated directly using "),Zxe=a("code"),Sit=o("__init__()"),Rit=o(" (throws an error)."),Pit=l(),ia=a("div"),F(CP.$$.fragment),Bit=l(),Kxe=a("p"),Iit=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Nit=l(),Wc=a("p"),qit=o(`Note:
Loading a model from its configuration file does `),e$e=a("strong"),jit=o("not"),Dit=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wse=a("a"),Git=o("from_pretrained()"),Oit=o(" to load the model weights."),Vit=l(),F(q6.$$.fragment),Xit=l(),Yr=a("div"),F(wP.$$.fragment),zit=l(),o$e=a("p"),Qit=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Wit=l(),Qn=a("p"),Uit=o("The model class to instantiate is selected based on the "),r$e=a("code"),Hit=o("model_type"),Jit=o(` property of the config object (either
passed as an argument or loaded from `),t$e=a("code"),Yit=o("pretrained_model_name_or_path"),Zit=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a$e=a("code"),Kit=o("pretrained_model_name_or_path"),edt=o(":"),odt=l(),n$e=a("ul"),j6=a("li"),s$e=a("strong"),rdt=o("layoutlm"),tdt=o(" \u2014 "),Ase=a("a"),adt=o("TFLayoutLMForQuestionAnswering"),ndt=o(" (LayoutLM model)"),sdt=l(),F(D6.$$.fragment),kno=l(),Uc=a("h2"),G6=a("a"),l$e=a("span"),F(AP.$$.fragment),ldt=l(),i$e=a("span"),idt=o("TFAutoModelForTokenClassification"),Sno=l(),Mr=a("div"),F(LP.$$.fragment),ddt=l(),Hc=a("p"),mdt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Lse=a("a"),cdt=o("from_pretrained()"),fdt=o(" class method or the "),yse=a("a"),gdt=o("from_config()"),hdt=o(` class
method.`),udt=l(),yP=a("p"),pdt=o("This class cannot be instantiated directly using "),d$e=a("code"),_dt=o("__init__()"),bdt=o(" (throws an error)."),vdt=l(),da=a("div"),F(xP.$$.fragment),Fdt=l(),m$e=a("p"),Tdt=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Mdt=l(),Jc=a("p"),Edt=o(`Note:
Loading a model from its configuration file does `),c$e=a("strong"),Cdt=o("not"),wdt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xse=a("a"),Adt=o("from_pretrained()"),Ldt=o(" to load the model weights."),ydt=l(),F(O6.$$.fragment),xdt=l(),Zr=a("div"),F($P.$$.fragment),$dt=l(),f$e=a("p"),kdt=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Sdt=l(),Wn=a("p"),Rdt=o("The model class to instantiate is selected based on the "),g$e=a("code"),Pdt=o("model_type"),Bdt=o(` property of the config object (either
passed as an argument or loaded from `),h$e=a("code"),Idt=o("pretrained_model_name_or_path"),Ndt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u$e=a("code"),qdt=o("pretrained_model_name_or_path"),jdt=o(":"),Ddt=l(),ie=a("ul"),V6=a("li"),p$e=a("strong"),Gdt=o("albert"),Odt=o(" \u2014 "),$se=a("a"),Vdt=o("TFAlbertForTokenClassification"),Xdt=o(" (ALBERT model)"),zdt=l(),X6=a("li"),_$e=a("strong"),Qdt=o("bert"),Wdt=o(" \u2014 "),kse=a("a"),Udt=o("TFBertForTokenClassification"),Hdt=o(" (BERT model)"),Jdt=l(),z6=a("li"),b$e=a("strong"),Ydt=o("camembert"),Zdt=o(" \u2014 "),Sse=a("a"),Kdt=o("TFCamembertForTokenClassification"),emt=o(" (CamemBERT model)"),omt=l(),Q6=a("li"),v$e=a("strong"),rmt=o("convbert"),tmt=o(" \u2014 "),Rse=a("a"),amt=o("TFConvBertForTokenClassification"),nmt=o(" (ConvBERT model)"),smt=l(),W6=a("li"),F$e=a("strong"),lmt=o("deberta"),imt=o(" \u2014 "),Pse=a("a"),dmt=o("TFDebertaForTokenClassification"),mmt=o(" (DeBERTa model)"),cmt=l(),U6=a("li"),T$e=a("strong"),fmt=o("deberta-v2"),gmt=o(" \u2014 "),Bse=a("a"),hmt=o("TFDebertaV2ForTokenClassification"),umt=o(" (DeBERTa-v2 model)"),pmt=l(),H6=a("li"),M$e=a("strong"),_mt=o("distilbert"),bmt=o(" \u2014 "),Ise=a("a"),vmt=o("TFDistilBertForTokenClassification"),Fmt=o(" (DistilBERT model)"),Tmt=l(),J6=a("li"),E$e=a("strong"),Mmt=o("electra"),Emt=o(" \u2014 "),Nse=a("a"),Cmt=o("TFElectraForTokenClassification"),wmt=o(" (ELECTRA model)"),Amt=l(),Y6=a("li"),C$e=a("strong"),Lmt=o("esm"),ymt=o(" \u2014 "),qse=a("a"),xmt=o("TFEsmForTokenClassification"),$mt=o(" (ESM model)"),kmt=l(),Z6=a("li"),w$e=a("strong"),Smt=o("flaubert"),Rmt=o(" \u2014 "),jse=a("a"),Pmt=o("TFFlaubertForTokenClassification"),Bmt=o(" (FlauBERT model)"),Imt=l(),K6=a("li"),A$e=a("strong"),Nmt=o("funnel"),qmt=o(" \u2014 "),Dse=a("a"),jmt=o("TFFunnelForTokenClassification"),Dmt=o(" (Funnel Transformer model)"),Gmt=l(),e7=a("li"),L$e=a("strong"),Omt=o("layoutlm"),Vmt=o(" \u2014 "),Gse=a("a"),Xmt=o("TFLayoutLMForTokenClassification"),zmt=o(" (LayoutLM model)"),Qmt=l(),o7=a("li"),y$e=a("strong"),Wmt=o("layoutlmv3"),Umt=o(" \u2014 "),Ose=a("a"),Hmt=o("TFLayoutLMv3ForTokenClassification"),Jmt=o(" (LayoutLMv3 model)"),Ymt=l(),r7=a("li"),x$e=a("strong"),Zmt=o("longformer"),Kmt=o(" \u2014 "),Vse=a("a"),ect=o("TFLongformerForTokenClassification"),oct=o(" (Longformer model)"),rct=l(),t7=a("li"),$$e=a("strong"),tct=o("mobilebert"),act=o(" \u2014 "),Xse=a("a"),nct=o("TFMobileBertForTokenClassification"),sct=o(" (MobileBERT model)"),lct=l(),a7=a("li"),k$e=a("strong"),ict=o("mpnet"),dct=o(" \u2014 "),zse=a("a"),mct=o("TFMPNetForTokenClassification"),cct=o(" (MPNet model)"),fct=l(),n7=a("li"),S$e=a("strong"),gct=o("rembert"),hct=o(" \u2014 "),Qse=a("a"),uct=o("TFRemBertForTokenClassification"),pct=o(" (RemBERT model)"),_ct=l(),s7=a("li"),R$e=a("strong"),bct=o("roberta"),vct=o(" \u2014 "),Wse=a("a"),Fct=o("TFRobertaForTokenClassification"),Tct=o(" (RoBERTa model)"),Mct=l(),l7=a("li"),P$e=a("strong"),Ect=o("roformer"),Cct=o(" \u2014 "),Use=a("a"),wct=o("TFRoFormerForTokenClassification"),Act=o(" (RoFormer model)"),Lct=l(),i7=a("li"),B$e=a("strong"),yct=o("xlm"),xct=o(" \u2014 "),Hse=a("a"),$ct=o("TFXLMForTokenClassification"),kct=o(" (XLM model)"),Sct=l(),d7=a("li"),I$e=a("strong"),Rct=o("xlm-roberta"),Pct=o(" \u2014 "),Jse=a("a"),Bct=o("TFXLMRobertaForTokenClassification"),Ict=o(" (XLM-RoBERTa model)"),Nct=l(),m7=a("li"),N$e=a("strong"),qct=o("xlnet"),jct=o(" \u2014 "),Yse=a("a"),Dct=o("TFXLNetForTokenClassification"),Gct=o(" (XLNet model)"),Oct=l(),F(c7.$$.fragment),Rno=l(),Yc=a("h2"),f7=a("a"),q$e=a("span"),F(kP.$$.fragment),Vct=l(),j$e=a("span"),Xct=o("TFAutoModelForQuestionAnswering"),Pno=l(),Er=a("div"),F(SP.$$.fragment),zct=l(),Zc=a("p"),Qct=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Zse=a("a"),Wct=o("from_pretrained()"),Uct=o(" class method or the "),Kse=a("a"),Hct=o("from_config()"),Jct=o(` class
method.`),Yct=l(),RP=a("p"),Zct=o("This class cannot be instantiated directly using "),D$e=a("code"),Kct=o("__init__()"),eft=o(" (throws an error)."),oft=l(),ma=a("div"),F(PP.$$.fragment),rft=l(),G$e=a("p"),tft=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),aft=l(),Kc=a("p"),nft=o(`Note:
Loading a model from its configuration file does `),O$e=a("strong"),sft=o("not"),lft=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ele=a("a"),ift=o("from_pretrained()"),dft=o(" to load the model weights."),mft=l(),F(g7.$$.fragment),cft=l(),Kr=a("div"),F(BP.$$.fragment),fft=l(),V$e=a("p"),gft=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),hft=l(),Un=a("p"),uft=o("The model class to instantiate is selected based on the "),X$e=a("code"),pft=o("model_type"),_ft=o(` property of the config object (either
passed as an argument or loaded from `),z$e=a("code"),bft=o("pretrained_model_name_or_path"),vft=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q$e=a("code"),Fft=o("pretrained_model_name_or_path"),Tft=o(":"),Mft=l(),fe=a("ul"),h7=a("li"),W$e=a("strong"),Eft=o("albert"),Cft=o(" \u2014 "),ole=a("a"),wft=o("TFAlbertForQuestionAnswering"),Aft=o(" (ALBERT model)"),Lft=l(),u7=a("li"),U$e=a("strong"),yft=o("bert"),xft=o(" \u2014 "),rle=a("a"),$ft=o("TFBertForQuestionAnswering"),kft=o(" (BERT model)"),Sft=l(),p7=a("li"),H$e=a("strong"),Rft=o("camembert"),Pft=o(" \u2014 "),tle=a("a"),Bft=o("TFCamembertForQuestionAnswering"),Ift=o(" (CamemBERT model)"),Nft=l(),_7=a("li"),J$e=a("strong"),qft=o("convbert"),jft=o(" \u2014 "),ale=a("a"),Dft=o("TFConvBertForQuestionAnswering"),Gft=o(" (ConvBERT model)"),Oft=l(),b7=a("li"),Y$e=a("strong"),Vft=o("deberta"),Xft=o(" \u2014 "),nle=a("a"),zft=o("TFDebertaForQuestionAnswering"),Qft=o(" (DeBERTa model)"),Wft=l(),v7=a("li"),Z$e=a("strong"),Uft=o("deberta-v2"),Hft=o(" \u2014 "),sle=a("a"),Jft=o("TFDebertaV2ForQuestionAnswering"),Yft=o(" (DeBERTa-v2 model)"),Zft=l(),F7=a("li"),K$e=a("strong"),Kft=o("distilbert"),egt=o(" \u2014 "),lle=a("a"),ogt=o("TFDistilBertForQuestionAnswering"),rgt=o(" (DistilBERT model)"),tgt=l(),T7=a("li"),eke=a("strong"),agt=o("electra"),ngt=o(" \u2014 "),ile=a("a"),sgt=o("TFElectraForQuestionAnswering"),lgt=o(" (ELECTRA model)"),igt=l(),M7=a("li"),oke=a("strong"),dgt=o("flaubert"),mgt=o(" \u2014 "),dle=a("a"),cgt=o("TFFlaubertForQuestionAnsweringSimple"),fgt=o(" (FlauBERT model)"),ggt=l(),E7=a("li"),rke=a("strong"),hgt=o("funnel"),ugt=o(" \u2014 "),mle=a("a"),pgt=o("TFFunnelForQuestionAnswering"),_gt=o(" (Funnel Transformer model)"),bgt=l(),C7=a("li"),tke=a("strong"),vgt=o("gptj"),Fgt=o(" \u2014 "),cle=a("a"),Tgt=o("TFGPTJForQuestionAnswering"),Mgt=o(" (GPT-J model)"),Egt=l(),w7=a("li"),ake=a("strong"),Cgt=o("layoutlmv3"),wgt=o(" \u2014 "),fle=a("a"),Agt=o("TFLayoutLMv3ForQuestionAnswering"),Lgt=o(" (LayoutLMv3 model)"),ygt=l(),A7=a("li"),nke=a("strong"),xgt=o("longformer"),$gt=o(" \u2014 "),gle=a("a"),kgt=o("TFLongformerForQuestionAnswering"),Sgt=o(" (Longformer model)"),Rgt=l(),L7=a("li"),ske=a("strong"),Pgt=o("mobilebert"),Bgt=o(" \u2014 "),hle=a("a"),Igt=o("TFMobileBertForQuestionAnswering"),Ngt=o(" (MobileBERT model)"),qgt=l(),y7=a("li"),lke=a("strong"),jgt=o("mpnet"),Dgt=o(" \u2014 "),ule=a("a"),Ggt=o("TFMPNetForQuestionAnswering"),Ogt=o(" (MPNet model)"),Vgt=l(),x7=a("li"),ike=a("strong"),Xgt=o("rembert"),zgt=o(" \u2014 "),ple=a("a"),Qgt=o("TFRemBertForQuestionAnswering"),Wgt=o(" (RemBERT model)"),Ugt=l(),$7=a("li"),dke=a("strong"),Hgt=o("roberta"),Jgt=o(" \u2014 "),_le=a("a"),Ygt=o("TFRobertaForQuestionAnswering"),Zgt=o(" (RoBERTa model)"),Kgt=l(),k7=a("li"),mke=a("strong"),eht=o("roformer"),oht=o(" \u2014 "),ble=a("a"),rht=o("TFRoFormerForQuestionAnswering"),tht=o(" (RoFormer model)"),aht=l(),S7=a("li"),cke=a("strong"),nht=o("xlm"),sht=o(" \u2014 "),vle=a("a"),lht=o("TFXLMForQuestionAnsweringSimple"),iht=o(" (XLM model)"),dht=l(),R7=a("li"),fke=a("strong"),mht=o("xlm-roberta"),cht=o(" \u2014 "),Fle=a("a"),fht=o("TFXLMRobertaForQuestionAnswering"),ght=o(" (XLM-RoBERTa model)"),hht=l(),P7=a("li"),gke=a("strong"),uht=o("xlnet"),pht=o(" \u2014 "),Tle=a("a"),_ht=o("TFXLNetForQuestionAnsweringSimple"),bht=o(" (XLNet model)"),vht=l(),F(B7.$$.fragment),Bno=l(),ef=a("h2"),I7=a("a"),hke=a("span"),F(IP.$$.fragment),Fht=l(),uke=a("span"),Tht=o("TFAutoModelForVision2Seq"),Ino=l(),Cr=a("div"),F(NP.$$.fragment),Mht=l(),of=a("p"),Eht=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Mle=a("a"),Cht=o("from_pretrained()"),wht=o(" class method or the "),Ele=a("a"),Aht=o("from_config()"),Lht=o(` class
method.`),yht=l(),qP=a("p"),xht=o("This class cannot be instantiated directly using "),pke=a("code"),$ht=o("__init__()"),kht=o(" (throws an error)."),Sht=l(),ca=a("div"),F(jP.$$.fragment),Rht=l(),_ke=a("p"),Pht=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Bht=l(),rf=a("p"),Iht=o(`Note:
Loading a model from its configuration file does `),bke=a("strong"),Nht=o("not"),qht=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cle=a("a"),jht=o("from_pretrained()"),Dht=o(" to load the model weights."),Ght=l(),F(N7.$$.fragment),Oht=l(),et=a("div"),F(DP.$$.fragment),Vht=l(),vke=a("p"),Xht=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),zht=l(),Hn=a("p"),Qht=o("The model class to instantiate is selected based on the "),Fke=a("code"),Wht=o("model_type"),Uht=o(` property of the config object (either
passed as an argument or loaded from `),Tke=a("code"),Hht=o("pretrained_model_name_or_path"),Jht=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mke=a("code"),Yht=o("pretrained_model_name_or_path"),Zht=o(":"),Kht=l(),Eke=a("ul"),q7=a("li"),Cke=a("strong"),eut=o("vision-encoder-decoder"),out=o(" \u2014 "),wle=a("a"),rut=o("TFVisionEncoderDecoderModel"),tut=o(" (Vision Encoder decoder model)"),aut=l(),F(j7.$$.fragment),Nno=l(),tf=a("h2"),D7=a("a"),wke=a("span"),F(GP.$$.fragment),nut=l(),Ake=a("span"),sut=o("TFAutoModelForSpeechSeq2Seq"),qno=l(),wr=a("div"),F(OP.$$.fragment),lut=l(),af=a("p"),iut=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Ale=a("a"),dut=o("from_pretrained()"),mut=o(" class method or the "),Lle=a("a"),cut=o("from_config()"),fut=o(` class
method.`),gut=l(),VP=a("p"),hut=o("This class cannot be instantiated directly using "),Lke=a("code"),uut=o("__init__()"),put=o(" (throws an error)."),_ut=l(),fa=a("div"),F(XP.$$.fragment),but=l(),yke=a("p"),vut=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Fut=l(),nf=a("p"),Tut=o(`Note:
Loading a model from its configuration file does `),xke=a("strong"),Mut=o("not"),Eut=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yle=a("a"),Cut=o("from_pretrained()"),wut=o(" to load the model weights."),Aut=l(),F(G7.$$.fragment),Lut=l(),ot=a("div"),F(zP.$$.fragment),yut=l(),$ke=a("p"),xut=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),$ut=l(),Jn=a("p"),kut=o("The model class to instantiate is selected based on the "),kke=a("code"),Sut=o("model_type"),Rut=o(` property of the config object (either
passed as an argument or loaded from `),Ske=a("code"),Put=o("pretrained_model_name_or_path"),But=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rke=a("code"),Iut=o("pretrained_model_name_or_path"),Nut=o(":"),qut=l(),QP=a("ul"),O7=a("li"),Pke=a("strong"),jut=o("speech_to_text"),Dut=o(" \u2014 "),xle=a("a"),Gut=o("TFSpeech2TextForConditionalGeneration"),Out=o(" (Speech2Text model)"),Vut=l(),V7=a("li"),Bke=a("strong"),Xut=o("whisper"),zut=o(" \u2014 "),$le=a("a"),Qut=o("TFWhisperForConditionalGeneration"),Wut=o(" (Whisper model)"),Uut=l(),F(X7.$$.fragment),jno=l(),sf=a("h2"),z7=a("a"),Ike=a("span"),F(WP.$$.fragment),Hut=l(),Nke=a("span"),Jut=o("FlaxAutoModel"),Dno=l(),Ar=a("div"),F(UP.$$.fragment),Yut=l(),lf=a("p"),Zut=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),kle=a("a"),Kut=o("from_pretrained()"),ept=o(" class method or the "),Sle=a("a"),opt=o("from_config()"),rpt=o(` class
method.`),tpt=l(),HP=a("p"),apt=o("This class cannot be instantiated directly using "),qke=a("code"),npt=o("__init__()"),spt=o(" (throws an error)."),lpt=l(),ga=a("div"),F(JP.$$.fragment),ipt=l(),jke=a("p"),dpt=o("Instantiates one of the base model classes of the library from a configuration."),mpt=l(),df=a("p"),cpt=o(`Note:
Loading a model from its configuration file does `),Dke=a("strong"),fpt=o("not"),gpt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Rle=a("a"),hpt=o("from_pretrained()"),upt=o(" to load the model weights."),ppt=l(),F(Q7.$$.fragment),_pt=l(),rt=a("div"),F(YP.$$.fragment),bpt=l(),Gke=a("p"),vpt=o("Instantiate one of the base model classes of the library from a pretrained model."),Fpt=l(),Yn=a("p"),Tpt=o("The model class to instantiate is selected based on the "),Oke=a("code"),Mpt=o("model_type"),Ept=o(` property of the config object (either
passed as an argument or loaded from `),Vke=a("code"),Cpt=o("pretrained_model_name_or_path"),wpt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xke=a("code"),Apt=o("pretrained_model_name_or_path"),Lpt=o(":"),ypt=l(),te=a("ul"),W7=a("li"),zke=a("strong"),xpt=o("albert"),$pt=o(" \u2014 "),Ple=a("a"),kpt=o("FlaxAlbertModel"),Spt=o(" (ALBERT model)"),Rpt=l(),U7=a("li"),Qke=a("strong"),Ppt=o("bart"),Bpt=o(" \u2014 "),Ble=a("a"),Ipt=o("FlaxBartModel"),Npt=o(" (BART model)"),qpt=l(),H7=a("li"),Wke=a("strong"),jpt=o("beit"),Dpt=o(" \u2014 "),Ile=a("a"),Gpt=o("FlaxBeitModel"),Opt=o(" (BEiT model)"),Vpt=l(),J7=a("li"),Uke=a("strong"),Xpt=o("bert"),zpt=o(" \u2014 "),Nle=a("a"),Qpt=o("FlaxBertModel"),Wpt=o(" (BERT model)"),Upt=l(),Y7=a("li"),Hke=a("strong"),Hpt=o("big_bird"),Jpt=o(" \u2014 "),qle=a("a"),Ypt=o("FlaxBigBirdModel"),Zpt=o(" (BigBird model)"),Kpt=l(),Z7=a("li"),Jke=a("strong"),e_t=o("blenderbot"),o_t=o(" \u2014 "),jle=a("a"),r_t=o("FlaxBlenderbotModel"),t_t=o(" (Blenderbot model)"),a_t=l(),K7=a("li"),Yke=a("strong"),n_t=o("blenderbot-small"),s_t=o(" \u2014 "),Dle=a("a"),l_t=o("FlaxBlenderbotSmallModel"),i_t=o(" (BlenderbotSmall model)"),d_t=l(),e8=a("li"),Zke=a("strong"),m_t=o("clip"),c_t=o(" \u2014 "),Gle=a("a"),f_t=o("FlaxCLIPModel"),g_t=o(" (CLIP model)"),h_t=l(),o8=a("li"),Kke=a("strong"),u_t=o("distilbert"),p_t=o(" \u2014 "),Ole=a("a"),__t=o("FlaxDistilBertModel"),b_t=o(" (DistilBERT model)"),v_t=l(),r8=a("li"),eSe=a("strong"),F_t=o("electra"),T_t=o(" \u2014 "),Vle=a("a"),M_t=o("FlaxElectraModel"),E_t=o(" (ELECTRA model)"),C_t=l(),t8=a("li"),oSe=a("strong"),w_t=o("gpt2"),A_t=o(" \u2014 "),Xle=a("a"),L_t=o("FlaxGPT2Model"),y_t=o(" (OpenAI GPT-2 model)"),x_t=l(),a8=a("li"),rSe=a("strong"),$_t=o("gpt_neo"),k_t=o(" \u2014 "),zle=a("a"),S_t=o("FlaxGPTNeoModel"),R_t=o(" (GPT Neo model)"),P_t=l(),n8=a("li"),tSe=a("strong"),B_t=o("gptj"),I_t=o(" \u2014 "),Qle=a("a"),N_t=o("FlaxGPTJModel"),q_t=o(" (GPT-J model)"),j_t=l(),s8=a("li"),aSe=a("strong"),D_t=o("longt5"),G_t=o(" \u2014 "),Wle=a("a"),O_t=o("FlaxLongT5Model"),V_t=o(" (LongT5 model)"),X_t=l(),l8=a("li"),nSe=a("strong"),z_t=o("marian"),Q_t=o(" \u2014 "),Ule=a("a"),W_t=o("FlaxMarianModel"),U_t=o(" (Marian model)"),H_t=l(),i8=a("li"),sSe=a("strong"),J_t=o("mbart"),Y_t=o(" \u2014 "),Hle=a("a"),Z_t=o("FlaxMBartModel"),K_t=o(" (mBART model)"),e1t=l(),d8=a("li"),lSe=a("strong"),o1t=o("mt5"),r1t=o(" \u2014 "),Jle=a("a"),t1t=o("FlaxMT5Model"),a1t=o(" (MT5 model)"),n1t=l(),m8=a("li"),iSe=a("strong"),s1t=o("opt"),l1t=o(" \u2014 "),Yle=a("a"),i1t=o("FlaxOPTModel"),d1t=o(" (OPT model)"),m1t=l(),c8=a("li"),dSe=a("strong"),c1t=o("pegasus"),f1t=o(" \u2014 "),Zle=a("a"),g1t=o("FlaxPegasusModel"),h1t=o(" (Pegasus model)"),u1t=l(),f8=a("li"),mSe=a("strong"),p1t=o("roberta"),_1t=o(" \u2014 "),Kle=a("a"),b1t=o("FlaxRobertaModel"),v1t=o(" (RoBERTa model)"),F1t=l(),g8=a("li"),cSe=a("strong"),T1t=o("roformer"),M1t=o(" \u2014 "),eie=a("a"),E1t=o("FlaxRoFormerModel"),C1t=o(" (RoFormer model)"),w1t=l(),h8=a("li"),fSe=a("strong"),A1t=o("t5"),L1t=o(" \u2014 "),oie=a("a"),y1t=o("FlaxT5Model"),x1t=o(" (T5 model)"),$1t=l(),u8=a("li"),gSe=a("strong"),k1t=o("vision-text-dual-encoder"),S1t=o(" \u2014 "),rie=a("a"),R1t=o("FlaxVisionTextDualEncoderModel"),P1t=o(" (VisionTextDualEncoder model)"),B1t=l(),p8=a("li"),hSe=a("strong"),I1t=o("vit"),N1t=o(" \u2014 "),tie=a("a"),q1t=o("FlaxViTModel"),j1t=o(" (ViT model)"),D1t=l(),_8=a("li"),uSe=a("strong"),G1t=o("wav2vec2"),O1t=o(" \u2014 "),aie=a("a"),V1t=o("FlaxWav2Vec2Model"),X1t=o(" (Wav2Vec2 model)"),z1t=l(),b8=a("li"),pSe=a("strong"),Q1t=o("xglm"),W1t=o(" \u2014 "),nie=a("a"),U1t=o("FlaxXGLMModel"),H1t=o(" (XGLM model)"),J1t=l(),v8=a("li"),_Se=a("strong"),Y1t=o("xlm-roberta"),Z1t=o(" \u2014 "),sie=a("a"),K1t=o("FlaxXLMRobertaModel"),e2t=o(" (XLM-RoBERTa model)"),o2t=l(),F(F8.$$.fragment),Gno=l(),mf=a("h2"),T8=a("a"),bSe=a("span"),F(ZP.$$.fragment),r2t=l(),vSe=a("span"),t2t=o("FlaxAutoModelForCausalLM"),Ono=l(),Lr=a("div"),F(KP.$$.fragment),a2t=l(),cf=a("p"),n2t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),lie=a("a"),s2t=o("from_pretrained()"),l2t=o(" class method or the "),iie=a("a"),i2t=o("from_config()"),d2t=o(` class
method.`),m2t=l(),eB=a("p"),c2t=o("This class cannot be instantiated directly using "),FSe=a("code"),f2t=o("__init__()"),g2t=o(" (throws an error)."),h2t=l(),ha=a("div"),F(oB.$$.fragment),u2t=l(),TSe=a("p"),p2t=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),_2t=l(),ff=a("p"),b2t=o(`Note:
Loading a model from its configuration file does `),MSe=a("strong"),v2t=o("not"),F2t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),die=a("a"),T2t=o("from_pretrained()"),M2t=o(" to load the model weights."),E2t=l(),F(M8.$$.fragment),C2t=l(),tt=a("div"),F(rB.$$.fragment),w2t=l(),ESe=a("p"),A2t=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),L2t=l(),Zn=a("p"),y2t=o("The model class to instantiate is selected based on the "),CSe=a("code"),x2t=o("model_type"),$2t=o(` property of the config object (either
passed as an argument or loaded from `),wSe=a("code"),k2t=o("pretrained_model_name_or_path"),S2t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ASe=a("code"),R2t=o("pretrained_model_name_or_path"),P2t=o(":"),B2t=l(),$e=a("ul"),E8=a("li"),LSe=a("strong"),I2t=o("bart"),N2t=o(" \u2014 "),mie=a("a"),q2t=o("FlaxBartForCausalLM"),j2t=o(" (BART model)"),D2t=l(),C8=a("li"),ySe=a("strong"),G2t=o("bert"),O2t=o(" \u2014 "),cie=a("a"),V2t=o("FlaxBertForCausalLM"),X2t=o(" (BERT model)"),z2t=l(),w8=a("li"),xSe=a("strong"),Q2t=o("big_bird"),W2t=o(" \u2014 "),fie=a("a"),U2t=o("FlaxBigBirdForCausalLM"),H2t=o(" (BigBird model)"),J2t=l(),A8=a("li"),$Se=a("strong"),Y2t=o("electra"),Z2t=o(" \u2014 "),gie=a("a"),K2t=o("FlaxElectraForCausalLM"),ebt=o(" (ELECTRA model)"),obt=l(),L8=a("li"),kSe=a("strong"),rbt=o("gpt2"),tbt=o(" \u2014 "),hie=a("a"),abt=o("FlaxGPT2LMHeadModel"),nbt=o(" (OpenAI GPT-2 model)"),sbt=l(),y8=a("li"),SSe=a("strong"),lbt=o("gpt_neo"),ibt=o(" \u2014 "),uie=a("a"),dbt=o("FlaxGPTNeoForCausalLM"),mbt=o(" (GPT Neo model)"),cbt=l(),x8=a("li"),RSe=a("strong"),fbt=o("gptj"),gbt=o(" \u2014 "),pie=a("a"),hbt=o("FlaxGPTJForCausalLM"),ubt=o(" (GPT-J model)"),pbt=l(),$8=a("li"),PSe=a("strong"),_bt=o("opt"),bbt=o(" \u2014 "),_ie=a("a"),vbt=o("FlaxOPTForCausalLM"),Fbt=o(" (OPT model)"),Tbt=l(),k8=a("li"),BSe=a("strong"),Mbt=o("roberta"),Ebt=o(" \u2014 "),bie=a("a"),Cbt=o("FlaxRobertaForCausalLM"),wbt=o(" (RoBERTa model)"),Abt=l(),S8=a("li"),ISe=a("strong"),Lbt=o("xglm"),ybt=o(" \u2014 "),vie=a("a"),xbt=o("FlaxXGLMForCausalLM"),$bt=o(" (XGLM model)"),kbt=l(),F(R8.$$.fragment),Vno=l(),gf=a("h2"),P8=a("a"),NSe=a("span"),F(tB.$$.fragment),Sbt=l(),qSe=a("span"),Rbt=o("FlaxAutoModelForPreTraining"),Xno=l(),yr=a("div"),F(aB.$$.fragment),Pbt=l(),hf=a("p"),Bbt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Fie=a("a"),Ibt=o("from_pretrained()"),Nbt=o(" class method or the "),Tie=a("a"),qbt=o("from_config()"),jbt=o(` class
method.`),Dbt=l(),nB=a("p"),Gbt=o("This class cannot be instantiated directly using "),jSe=a("code"),Obt=o("__init__()"),Vbt=o(" (throws an error)."),Xbt=l(),ua=a("div"),F(sB.$$.fragment),zbt=l(),DSe=a("p"),Qbt=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Wbt=l(),uf=a("p"),Ubt=o(`Note:
Loading a model from its configuration file does `),GSe=a("strong"),Hbt=o("not"),Jbt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Mie=a("a"),Ybt=o("from_pretrained()"),Zbt=o(" to load the model weights."),Kbt=l(),F(B8.$$.fragment),evt=l(),at=a("div"),F(lB.$$.fragment),ovt=l(),OSe=a("p"),rvt=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),tvt=l(),Kn=a("p"),avt=o("The model class to instantiate is selected based on the "),VSe=a("code"),nvt=o("model_type"),svt=o(` property of the config object (either
passed as an argument or loaded from `),XSe=a("code"),lvt=o("pretrained_model_name_or_path"),ivt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zSe=a("code"),dvt=o("pretrained_model_name_or_path"),mvt=o(":"),cvt=l(),Ee=a("ul"),I8=a("li"),QSe=a("strong"),fvt=o("albert"),gvt=o(" \u2014 "),Eie=a("a"),hvt=o("FlaxAlbertForPreTraining"),uvt=o(" (ALBERT model)"),pvt=l(),N8=a("li"),WSe=a("strong"),_vt=o("bart"),bvt=o(" \u2014 "),Cie=a("a"),vvt=o("FlaxBartForConditionalGeneration"),Fvt=o(" (BART model)"),Tvt=l(),q8=a("li"),USe=a("strong"),Mvt=o("bert"),Evt=o(" \u2014 "),wie=a("a"),Cvt=o("FlaxBertForPreTraining"),wvt=o(" (BERT model)"),Avt=l(),j8=a("li"),HSe=a("strong"),Lvt=o("big_bird"),yvt=o(" \u2014 "),Aie=a("a"),xvt=o("FlaxBigBirdForPreTraining"),$vt=o(" (BigBird model)"),kvt=l(),D8=a("li"),JSe=a("strong"),Svt=o("electra"),Rvt=o(" \u2014 "),Lie=a("a"),Pvt=o("FlaxElectraForPreTraining"),Bvt=o(" (ELECTRA model)"),Ivt=l(),G8=a("li"),YSe=a("strong"),Nvt=o("longt5"),qvt=o(" \u2014 "),yie=a("a"),jvt=o("FlaxLongT5ForConditionalGeneration"),Dvt=o(" (LongT5 model)"),Gvt=l(),O8=a("li"),ZSe=a("strong"),Ovt=o("mbart"),Vvt=o(" \u2014 "),xie=a("a"),Xvt=o("FlaxMBartForConditionalGeneration"),zvt=o(" (mBART model)"),Qvt=l(),V8=a("li"),KSe=a("strong"),Wvt=o("mt5"),Uvt=o(" \u2014 "),$ie=a("a"),Hvt=o("FlaxMT5ForConditionalGeneration"),Jvt=o(" (MT5 model)"),Yvt=l(),X8=a("li"),eRe=a("strong"),Zvt=o("roberta"),Kvt=o(" \u2014 "),kie=a("a"),eFt=o("FlaxRobertaForMaskedLM"),oFt=o(" (RoBERTa model)"),rFt=l(),z8=a("li"),oRe=a("strong"),tFt=o("roformer"),aFt=o(" \u2014 "),Sie=a("a"),nFt=o("FlaxRoFormerForMaskedLM"),sFt=o(" (RoFormer model)"),lFt=l(),Q8=a("li"),rRe=a("strong"),iFt=o("t5"),dFt=o(" \u2014 "),Rie=a("a"),mFt=o("FlaxT5ForConditionalGeneration"),cFt=o(" (T5 model)"),fFt=l(),W8=a("li"),tRe=a("strong"),gFt=o("wav2vec2"),hFt=o(" \u2014 "),Pie=a("a"),uFt=o("FlaxWav2Vec2ForPreTraining"),pFt=o(" (Wav2Vec2 model)"),_Ft=l(),U8=a("li"),aRe=a("strong"),bFt=o("xlm-roberta"),vFt=o(" \u2014 "),Bie=a("a"),FFt=o("FlaxXLMRobertaForMaskedLM"),TFt=o(" (XLM-RoBERTa model)"),MFt=l(),F(H8.$$.fragment),zno=l(),pf=a("h2"),J8=a("a"),nRe=a("span"),F(iB.$$.fragment),EFt=l(),sRe=a("span"),CFt=o("FlaxAutoModelForMaskedLM"),Qno=l(),xr=a("div"),F(dB.$$.fragment),wFt=l(),_f=a("p"),AFt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Iie=a("a"),LFt=o("from_pretrained()"),yFt=o(" class method or the "),Nie=a("a"),xFt=o("from_config()"),$Ft=o(` class
method.`),kFt=l(),mB=a("p"),SFt=o("This class cannot be instantiated directly using "),lRe=a("code"),RFt=o("__init__()"),PFt=o(" (throws an error)."),BFt=l(),pa=a("div"),F(cB.$$.fragment),IFt=l(),iRe=a("p"),NFt=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),qFt=l(),bf=a("p"),jFt=o(`Note:
Loading a model from its configuration file does `),dRe=a("strong"),DFt=o("not"),GFt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qie=a("a"),OFt=o("from_pretrained()"),VFt=o(" to load the model weights."),XFt=l(),F(Y8.$$.fragment),zFt=l(),nt=a("div"),F(fB.$$.fragment),QFt=l(),mRe=a("p"),WFt=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),UFt=l(),es=a("p"),HFt=o("The model class to instantiate is selected based on the "),cRe=a("code"),JFt=o("model_type"),YFt=o(` property of the config object (either
passed as an argument or loaded from `),fRe=a("code"),ZFt=o("pretrained_model_name_or_path"),KFt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gRe=a("code"),eTt=o("pretrained_model_name_or_path"),oTt=o(":"),rTt=l(),ke=a("ul"),Z8=a("li"),hRe=a("strong"),tTt=o("albert"),aTt=o(" \u2014 "),jie=a("a"),nTt=o("FlaxAlbertForMaskedLM"),sTt=o(" (ALBERT model)"),lTt=l(),K8=a("li"),uRe=a("strong"),iTt=o("bart"),dTt=o(" \u2014 "),Die=a("a"),mTt=o("FlaxBartForConditionalGeneration"),cTt=o(" (BART model)"),fTt=l(),eL=a("li"),pRe=a("strong"),gTt=o("bert"),hTt=o(" \u2014 "),Gie=a("a"),uTt=o("FlaxBertForMaskedLM"),pTt=o(" (BERT model)"),_Tt=l(),oL=a("li"),_Re=a("strong"),bTt=o("big_bird"),vTt=o(" \u2014 "),Oie=a("a"),FTt=o("FlaxBigBirdForMaskedLM"),TTt=o(" (BigBird model)"),MTt=l(),rL=a("li"),bRe=a("strong"),ETt=o("distilbert"),CTt=o(" \u2014 "),Vie=a("a"),wTt=o("FlaxDistilBertForMaskedLM"),ATt=o(" (DistilBERT model)"),LTt=l(),tL=a("li"),vRe=a("strong"),yTt=o("electra"),xTt=o(" \u2014 "),Xie=a("a"),$Tt=o("FlaxElectraForMaskedLM"),kTt=o(" (ELECTRA model)"),STt=l(),aL=a("li"),FRe=a("strong"),RTt=o("mbart"),PTt=o(" \u2014 "),zie=a("a"),BTt=o("FlaxMBartForConditionalGeneration"),ITt=o(" (mBART model)"),NTt=l(),nL=a("li"),TRe=a("strong"),qTt=o("roberta"),jTt=o(" \u2014 "),Qie=a("a"),DTt=o("FlaxRobertaForMaskedLM"),GTt=o(" (RoBERTa model)"),OTt=l(),sL=a("li"),MRe=a("strong"),VTt=o("roformer"),XTt=o(" \u2014 "),Wie=a("a"),zTt=o("FlaxRoFormerForMaskedLM"),QTt=o(" (RoFormer model)"),WTt=l(),lL=a("li"),ERe=a("strong"),UTt=o("xlm-roberta"),HTt=o(" \u2014 "),Uie=a("a"),JTt=o("FlaxXLMRobertaForMaskedLM"),YTt=o(" (XLM-RoBERTa model)"),ZTt=l(),F(iL.$$.fragment),Wno=l(),vf=a("h2"),dL=a("a"),CRe=a("span"),F(gB.$$.fragment),KTt=l(),wRe=a("span"),eMt=o("FlaxAutoModelForSeq2SeqLM"),Uno=l(),$r=a("div"),F(hB.$$.fragment),oMt=l(),Ff=a("p"),rMt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Hie=a("a"),tMt=o("from_pretrained()"),aMt=o(" class method or the "),Jie=a("a"),nMt=o("from_config()"),sMt=o(` class
method.`),lMt=l(),uB=a("p"),iMt=o("This class cannot be instantiated directly using "),ARe=a("code"),dMt=o("__init__()"),mMt=o(" (throws an error)."),cMt=l(),_a=a("div"),F(pB.$$.fragment),fMt=l(),LRe=a("p"),gMt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),hMt=l(),Tf=a("p"),uMt=o(`Note:
Loading a model from its configuration file does `),yRe=a("strong"),pMt=o("not"),_Mt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yie=a("a"),bMt=o("from_pretrained()"),vMt=o(" to load the model weights."),FMt=l(),F(mL.$$.fragment),TMt=l(),st=a("div"),F(_B.$$.fragment),MMt=l(),xRe=a("p"),EMt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),CMt=l(),os=a("p"),wMt=o("The model class to instantiate is selected based on the "),$Re=a("code"),AMt=o("model_type"),LMt=o(` property of the config object (either
passed as an argument or loaded from `),kRe=a("code"),yMt=o("pretrained_model_name_or_path"),xMt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SRe=a("code"),$Mt=o("pretrained_model_name_or_path"),kMt=o(":"),SMt=l(),Se=a("ul"),cL=a("li"),RRe=a("strong"),RMt=o("bart"),PMt=o(" \u2014 "),Zie=a("a"),BMt=o("FlaxBartForConditionalGeneration"),IMt=o(" (BART model)"),NMt=l(),fL=a("li"),PRe=a("strong"),qMt=o("blenderbot"),jMt=o(" \u2014 "),Kie=a("a"),DMt=o("FlaxBlenderbotForConditionalGeneration"),GMt=o(" (Blenderbot model)"),OMt=l(),gL=a("li"),BRe=a("strong"),VMt=o("blenderbot-small"),XMt=o(" \u2014 "),ede=a("a"),zMt=o("FlaxBlenderbotSmallForConditionalGeneration"),QMt=o(" (BlenderbotSmall model)"),WMt=l(),hL=a("li"),IRe=a("strong"),UMt=o("encoder-decoder"),HMt=o(" \u2014 "),ode=a("a"),JMt=o("FlaxEncoderDecoderModel"),YMt=o(" (Encoder decoder model)"),ZMt=l(),uL=a("li"),NRe=a("strong"),KMt=o("longt5"),eEt=o(" \u2014 "),rde=a("a"),oEt=o("FlaxLongT5ForConditionalGeneration"),rEt=o(" (LongT5 model)"),tEt=l(),pL=a("li"),qRe=a("strong"),aEt=o("marian"),nEt=o(" \u2014 "),tde=a("a"),sEt=o("FlaxMarianMTModel"),lEt=o(" (Marian model)"),iEt=l(),_L=a("li"),jRe=a("strong"),dEt=o("mbart"),mEt=o(" \u2014 "),ade=a("a"),cEt=o("FlaxMBartForConditionalGeneration"),fEt=o(" (mBART model)"),gEt=l(),bL=a("li"),DRe=a("strong"),hEt=o("mt5"),uEt=o(" \u2014 "),nde=a("a"),pEt=o("FlaxMT5ForConditionalGeneration"),_Et=o(" (MT5 model)"),bEt=l(),vL=a("li"),GRe=a("strong"),vEt=o("pegasus"),FEt=o(" \u2014 "),sde=a("a"),TEt=o("FlaxPegasusForConditionalGeneration"),MEt=o(" (Pegasus model)"),EEt=l(),FL=a("li"),ORe=a("strong"),CEt=o("t5"),wEt=o(" \u2014 "),lde=a("a"),AEt=o("FlaxT5ForConditionalGeneration"),LEt=o(" (T5 model)"),yEt=l(),F(TL.$$.fragment),Hno=l(),Mf=a("h2"),ML=a("a"),VRe=a("span"),F(bB.$$.fragment),xEt=l(),XRe=a("span"),$Et=o("FlaxAutoModelForSequenceClassification"),Jno=l(),kr=a("div"),F(vB.$$.fragment),kEt=l(),Ef=a("p"),SEt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),ide=a("a"),REt=o("from_pretrained()"),PEt=o(" class method or the "),dde=a("a"),BEt=o("from_config()"),IEt=o(` class
method.`),NEt=l(),FB=a("p"),qEt=o("This class cannot be instantiated directly using "),zRe=a("code"),jEt=o("__init__()"),DEt=o(" (throws an error)."),GEt=l(),ba=a("div"),F(TB.$$.fragment),OEt=l(),QRe=a("p"),VEt=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),XEt=l(),Cf=a("p"),zEt=o(`Note:
Loading a model from its configuration file does `),WRe=a("strong"),QEt=o("not"),WEt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mde=a("a"),UEt=o("from_pretrained()"),HEt=o(" to load the model weights."),JEt=l(),F(EL.$$.fragment),YEt=l(),lt=a("div"),F(MB.$$.fragment),ZEt=l(),URe=a("p"),KEt=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),e4t=l(),rs=a("p"),o4t=o("The model class to instantiate is selected based on the "),HRe=a("code"),r4t=o("model_type"),t4t=o(` property of the config object (either
passed as an argument or loaded from `),JRe=a("code"),a4t=o("pretrained_model_name_or_path"),n4t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),YRe=a("code"),s4t=o("pretrained_model_name_or_path"),l4t=o(":"),i4t=l(),Re=a("ul"),CL=a("li"),ZRe=a("strong"),d4t=o("albert"),m4t=o(" \u2014 "),cde=a("a"),c4t=o("FlaxAlbertForSequenceClassification"),f4t=o(" (ALBERT model)"),g4t=l(),wL=a("li"),KRe=a("strong"),h4t=o("bart"),u4t=o(" \u2014 "),fde=a("a"),p4t=o("FlaxBartForSequenceClassification"),_4t=o(" (BART model)"),b4t=l(),AL=a("li"),ePe=a("strong"),v4t=o("bert"),F4t=o(" \u2014 "),gde=a("a"),T4t=o("FlaxBertForSequenceClassification"),M4t=o(" (BERT model)"),E4t=l(),LL=a("li"),oPe=a("strong"),C4t=o("big_bird"),w4t=o(" \u2014 "),hde=a("a"),A4t=o("FlaxBigBirdForSequenceClassification"),L4t=o(" (BigBird model)"),y4t=l(),yL=a("li"),rPe=a("strong"),x4t=o("distilbert"),$4t=o(" \u2014 "),ude=a("a"),k4t=o("FlaxDistilBertForSequenceClassification"),S4t=o(" (DistilBERT model)"),R4t=l(),xL=a("li"),tPe=a("strong"),P4t=o("electra"),B4t=o(" \u2014 "),pde=a("a"),I4t=o("FlaxElectraForSequenceClassification"),N4t=o(" (ELECTRA model)"),q4t=l(),$L=a("li"),aPe=a("strong"),j4t=o("mbart"),D4t=o(" \u2014 "),_de=a("a"),G4t=o("FlaxMBartForSequenceClassification"),O4t=o(" (mBART model)"),V4t=l(),kL=a("li"),nPe=a("strong"),X4t=o("roberta"),z4t=o(" \u2014 "),bde=a("a"),Q4t=o("FlaxRobertaForSequenceClassification"),W4t=o(" (RoBERTa model)"),U4t=l(),SL=a("li"),sPe=a("strong"),H4t=o("roformer"),J4t=o(" \u2014 "),vde=a("a"),Y4t=o("FlaxRoFormerForSequenceClassification"),Z4t=o(" (RoFormer model)"),K4t=l(),RL=a("li"),lPe=a("strong"),eCt=o("xlm-roberta"),oCt=o(" \u2014 "),Fde=a("a"),rCt=o("FlaxXLMRobertaForSequenceClassification"),tCt=o(" (XLM-RoBERTa model)"),aCt=l(),F(PL.$$.fragment),Yno=l(),wf=a("h2"),BL=a("a"),iPe=a("span"),F(EB.$$.fragment),nCt=l(),dPe=a("span"),sCt=o("FlaxAutoModelForQuestionAnswering"),Zno=l(),Sr=a("div"),F(CB.$$.fragment),lCt=l(),Af=a("p"),iCt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Tde=a("a"),dCt=o("from_pretrained()"),mCt=o(" class method or the "),Mde=a("a"),cCt=o("from_config()"),fCt=o(` class
method.`),gCt=l(),wB=a("p"),hCt=o("This class cannot be instantiated directly using "),mPe=a("code"),uCt=o("__init__()"),pCt=o(" (throws an error)."),_Ct=l(),va=a("div"),F(AB.$$.fragment),bCt=l(),cPe=a("p"),vCt=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),FCt=l(),Lf=a("p"),TCt=o(`Note:
Loading a model from its configuration file does `),fPe=a("strong"),MCt=o("not"),ECt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ede=a("a"),CCt=o("from_pretrained()"),wCt=o(" to load the model weights."),ACt=l(),F(IL.$$.fragment),LCt=l(),it=a("div"),F(LB.$$.fragment),yCt=l(),gPe=a("p"),xCt=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),$Ct=l(),ts=a("p"),kCt=o("The model class to instantiate is selected based on the "),hPe=a("code"),SCt=o("model_type"),RCt=o(` property of the config object (either
passed as an argument or loaded from `),uPe=a("code"),PCt=o("pretrained_model_name_or_path"),BCt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pPe=a("code"),ICt=o("pretrained_model_name_or_path"),NCt=o(":"),qCt=l(),Pe=a("ul"),NL=a("li"),_Pe=a("strong"),jCt=o("albert"),DCt=o(" \u2014 "),Cde=a("a"),GCt=o("FlaxAlbertForQuestionAnswering"),OCt=o(" (ALBERT model)"),VCt=l(),qL=a("li"),bPe=a("strong"),XCt=o("bart"),zCt=o(" \u2014 "),wde=a("a"),QCt=o("FlaxBartForQuestionAnswering"),WCt=o(" (BART model)"),UCt=l(),jL=a("li"),vPe=a("strong"),HCt=o("bert"),JCt=o(" \u2014 "),Ade=a("a"),YCt=o("FlaxBertForQuestionAnswering"),ZCt=o(" (BERT model)"),KCt=l(),DL=a("li"),FPe=a("strong"),e3t=o("big_bird"),o3t=o(" \u2014 "),Lde=a("a"),r3t=o("FlaxBigBirdForQuestionAnswering"),t3t=o(" (BigBird model)"),a3t=l(),GL=a("li"),TPe=a("strong"),n3t=o("distilbert"),s3t=o(" \u2014 "),yde=a("a"),l3t=o("FlaxDistilBertForQuestionAnswering"),i3t=o(" (DistilBERT model)"),d3t=l(),OL=a("li"),MPe=a("strong"),m3t=o("electra"),c3t=o(" \u2014 "),xde=a("a"),f3t=o("FlaxElectraForQuestionAnswering"),g3t=o(" (ELECTRA model)"),h3t=l(),VL=a("li"),EPe=a("strong"),u3t=o("mbart"),p3t=o(" \u2014 "),$de=a("a"),_3t=o("FlaxMBartForQuestionAnswering"),b3t=o(" (mBART model)"),v3t=l(),XL=a("li"),CPe=a("strong"),F3t=o("roberta"),T3t=o(" \u2014 "),kde=a("a"),M3t=o("FlaxRobertaForQuestionAnswering"),E3t=o(" (RoBERTa model)"),C3t=l(),zL=a("li"),wPe=a("strong"),w3t=o("roformer"),A3t=o(" \u2014 "),Sde=a("a"),L3t=o("FlaxRoFormerForQuestionAnswering"),y3t=o(" (RoFormer model)"),x3t=l(),QL=a("li"),APe=a("strong"),$3t=o("xlm-roberta"),k3t=o(" \u2014 "),Rde=a("a"),S3t=o("FlaxXLMRobertaForQuestionAnswering"),R3t=o(" (XLM-RoBERTa model)"),P3t=l(),F(WL.$$.fragment),Kno=l(),yf=a("h2"),UL=a("a"),LPe=a("span"),F(yB.$$.fragment),B3t=l(),yPe=a("span"),I3t=o("FlaxAutoModelForTokenClassification"),eso=l(),Rr=a("div"),F(xB.$$.fragment),N3t=l(),xf=a("p"),q3t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Pde=a("a"),j3t=o("from_pretrained()"),D3t=o(" class method or the "),Bde=a("a"),G3t=o("from_config()"),O3t=o(` class
method.`),V3t=l(),$B=a("p"),X3t=o("This class cannot be instantiated directly using "),xPe=a("code"),z3t=o("__init__()"),Q3t=o(" (throws an error)."),W3t=l(),Fa=a("div"),F(kB.$$.fragment),U3t=l(),$Pe=a("p"),H3t=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),J3t=l(),$f=a("p"),Y3t=o(`Note:
Loading a model from its configuration file does `),kPe=a("strong"),Z3t=o("not"),K3t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ide=a("a"),e5t=o("from_pretrained()"),o5t=o(" to load the model weights."),r5t=l(),F(HL.$$.fragment),t5t=l(),dt=a("div"),F(SB.$$.fragment),a5t=l(),SPe=a("p"),n5t=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),s5t=l(),as=a("p"),l5t=o("The model class to instantiate is selected based on the "),RPe=a("code"),i5t=o("model_type"),d5t=o(` property of the config object (either
passed as an argument or loaded from `),PPe=a("code"),m5t=o("pretrained_model_name_or_path"),c5t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),BPe=a("code"),f5t=o("pretrained_model_name_or_path"),g5t=o(":"),h5t=l(),ze=a("ul"),JL=a("li"),IPe=a("strong"),u5t=o("albert"),p5t=o(" \u2014 "),Nde=a("a"),_5t=o("FlaxAlbertForTokenClassification"),b5t=o(" (ALBERT model)"),v5t=l(),YL=a("li"),NPe=a("strong"),F5t=o("bert"),T5t=o(" \u2014 "),qde=a("a"),M5t=o("FlaxBertForTokenClassification"),E5t=o(" (BERT model)"),C5t=l(),ZL=a("li"),qPe=a("strong"),w5t=o("big_bird"),A5t=o(" \u2014 "),jde=a("a"),L5t=o("FlaxBigBirdForTokenClassification"),y5t=o(" (BigBird model)"),x5t=l(),KL=a("li"),jPe=a("strong"),$5t=o("distilbert"),k5t=o(" \u2014 "),Dde=a("a"),S5t=o("FlaxDistilBertForTokenClassification"),R5t=o(" (DistilBERT model)"),P5t=l(),ey=a("li"),DPe=a("strong"),B5t=o("electra"),I5t=o(" \u2014 "),Gde=a("a"),N5t=o("FlaxElectraForTokenClassification"),q5t=o(" (ELECTRA model)"),j5t=l(),oy=a("li"),GPe=a("strong"),D5t=o("roberta"),G5t=o(" \u2014 "),Ode=a("a"),O5t=o("FlaxRobertaForTokenClassification"),V5t=o(" (RoBERTa model)"),X5t=l(),ry=a("li"),OPe=a("strong"),z5t=o("roformer"),Q5t=o(" \u2014 "),Vde=a("a"),W5t=o("FlaxRoFormerForTokenClassification"),U5t=o(" (RoFormer model)"),H5t=l(),ty=a("li"),VPe=a("strong"),J5t=o("xlm-roberta"),Y5t=o(" \u2014 "),Xde=a("a"),Z5t=o("FlaxXLMRobertaForTokenClassification"),K5t=o(" (XLM-RoBERTa model)"),e0t=l(),F(ay.$$.fragment),oso=l(),kf=a("h2"),ny=a("a"),XPe=a("span"),F(RB.$$.fragment),o0t=l(),zPe=a("span"),r0t=o("FlaxAutoModelForMultipleChoice"),rso=l(),Pr=a("div"),F(PB.$$.fragment),t0t=l(),Sf=a("p"),a0t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),zde=a("a"),n0t=o("from_pretrained()"),s0t=o(" class method or the "),Qde=a("a"),l0t=o("from_config()"),i0t=o(` class
method.`),d0t=l(),BB=a("p"),m0t=o("This class cannot be instantiated directly using "),QPe=a("code"),c0t=o("__init__()"),f0t=o(" (throws an error)."),g0t=l(),Ta=a("div"),F(IB.$$.fragment),h0t=l(),WPe=a("p"),u0t=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),p0t=l(),Rf=a("p"),_0t=o(`Note:
Loading a model from its configuration file does `),UPe=a("strong"),b0t=o("not"),v0t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Wde=a("a"),F0t=o("from_pretrained()"),T0t=o(" to load the model weights."),M0t=l(),F(sy.$$.fragment),E0t=l(),mt=a("div"),F(NB.$$.fragment),C0t=l(),HPe=a("p"),w0t=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),A0t=l(),ns=a("p"),L0t=o("The model class to instantiate is selected based on the "),JPe=a("code"),y0t=o("model_type"),x0t=o(` property of the config object (either
passed as an argument or loaded from `),YPe=a("code"),$0t=o("pretrained_model_name_or_path"),k0t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZPe=a("code"),S0t=o("pretrained_model_name_or_path"),R0t=o(":"),P0t=l(),Qe=a("ul"),ly=a("li"),KPe=a("strong"),B0t=o("albert"),I0t=o(" \u2014 "),Ude=a("a"),N0t=o("FlaxAlbertForMultipleChoice"),q0t=o(" (ALBERT model)"),j0t=l(),iy=a("li"),eBe=a("strong"),D0t=o("bert"),G0t=o(" \u2014 "),Hde=a("a"),O0t=o("FlaxBertForMultipleChoice"),V0t=o(" (BERT model)"),X0t=l(),dy=a("li"),oBe=a("strong"),z0t=o("big_bird"),Q0t=o(" \u2014 "),Jde=a("a"),W0t=o("FlaxBigBirdForMultipleChoice"),U0t=o(" (BigBird model)"),H0t=l(),my=a("li"),rBe=a("strong"),J0t=o("distilbert"),Y0t=o(" \u2014 "),Yde=a("a"),Z0t=o("FlaxDistilBertForMultipleChoice"),K0t=o(" (DistilBERT model)"),ewt=l(),cy=a("li"),tBe=a("strong"),owt=o("electra"),rwt=o(" \u2014 "),Zde=a("a"),twt=o("FlaxElectraForMultipleChoice"),awt=o(" (ELECTRA model)"),nwt=l(),fy=a("li"),aBe=a("strong"),swt=o("roberta"),lwt=o(" \u2014 "),Kde=a("a"),iwt=o("FlaxRobertaForMultipleChoice"),dwt=o(" (RoBERTa model)"),mwt=l(),gy=a("li"),nBe=a("strong"),cwt=o("roformer"),fwt=o(" \u2014 "),eme=a("a"),gwt=o("FlaxRoFormerForMultipleChoice"),hwt=o(" (RoFormer model)"),uwt=l(),hy=a("li"),sBe=a("strong"),pwt=o("xlm-roberta"),_wt=o(" \u2014 "),ome=a("a"),bwt=o("FlaxXLMRobertaForMultipleChoice"),vwt=o(" (XLM-RoBERTa model)"),Fwt=l(),F(uy.$$.fragment),tso=l(),Pf=a("h2"),py=a("a"),lBe=a("span"),F(qB.$$.fragment),Twt=l(),iBe=a("span"),Mwt=o("FlaxAutoModelForNextSentencePrediction"),aso=l(),Br=a("div"),F(jB.$$.fragment),Ewt=l(),Bf=a("p"),Cwt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),rme=a("a"),wwt=o("from_pretrained()"),Awt=o(" class method or the "),tme=a("a"),Lwt=o("from_config()"),ywt=o(` class
method.`),xwt=l(),DB=a("p"),$wt=o("This class cannot be instantiated directly using "),dBe=a("code"),kwt=o("__init__()"),Swt=o(" (throws an error)."),Rwt=l(),Ma=a("div"),F(GB.$$.fragment),Pwt=l(),mBe=a("p"),Bwt=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Iwt=l(),If=a("p"),Nwt=o(`Note:
Loading a model from its configuration file does `),cBe=a("strong"),qwt=o("not"),jwt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ame=a("a"),Dwt=o("from_pretrained()"),Gwt=o(" to load the model weights."),Owt=l(),F(_y.$$.fragment),Vwt=l(),ct=a("div"),F(OB.$$.fragment),Xwt=l(),fBe=a("p"),zwt=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Qwt=l(),ss=a("p"),Wwt=o("The model class to instantiate is selected based on the "),gBe=a("code"),Uwt=o("model_type"),Hwt=o(` property of the config object (either
passed as an argument or loaded from `),hBe=a("code"),Jwt=o("pretrained_model_name_or_path"),Ywt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uBe=a("code"),Zwt=o("pretrained_model_name_or_path"),Kwt=o(":"),eAt=l(),pBe=a("ul"),by=a("li"),_Be=a("strong"),oAt=o("bert"),rAt=o(" \u2014 "),nme=a("a"),tAt=o("FlaxBertForNextSentencePrediction"),aAt=o(" (BERT model)"),nAt=l(),F(vy.$$.fragment),nso=l(),Nf=a("h2"),Fy=a("a"),bBe=a("span"),F(VB.$$.fragment),sAt=l(),vBe=a("span"),lAt=o("FlaxAutoModelForImageClassification"),sso=l(),Ir=a("div"),F(XB.$$.fragment),iAt=l(),qf=a("p"),dAt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),sme=a("a"),mAt=o("from_pretrained()"),cAt=o(" class method or the "),lme=a("a"),fAt=o("from_config()"),gAt=o(` class
method.`),hAt=l(),zB=a("p"),uAt=o("This class cannot be instantiated directly using "),FBe=a("code"),pAt=o("__init__()"),_At=o(" (throws an error)."),bAt=l(),Ea=a("div"),F(QB.$$.fragment),vAt=l(),TBe=a("p"),FAt=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),TAt=l(),jf=a("p"),MAt=o(`Note:
Loading a model from its configuration file does `),MBe=a("strong"),EAt=o("not"),CAt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ime=a("a"),wAt=o("from_pretrained()"),AAt=o(" to load the model weights."),LAt=l(),F(Ty.$$.fragment),yAt=l(),ft=a("div"),F(WB.$$.fragment),xAt=l(),EBe=a("p"),$At=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),kAt=l(),ls=a("p"),SAt=o("The model class to instantiate is selected based on the "),CBe=a("code"),RAt=o("model_type"),PAt=o(` property of the config object (either
passed as an argument or loaded from `),wBe=a("code"),BAt=o("pretrained_model_name_or_path"),IAt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ABe=a("code"),NAt=o("pretrained_model_name_or_path"),qAt=o(":"),jAt=l(),UB=a("ul"),My=a("li"),LBe=a("strong"),DAt=o("beit"),GAt=o(" \u2014 "),dme=a("a"),OAt=o("FlaxBeitForImageClassification"),VAt=o(" (BEiT model)"),XAt=l(),Ey=a("li"),yBe=a("strong"),zAt=o("vit"),QAt=o(" \u2014 "),mme=a("a"),WAt=o("FlaxViTForImageClassification"),UAt=o(" (ViT model)"),HAt=l(),F(Cy.$$.fragment),lso=l(),Df=a("h2"),wy=a("a"),xBe=a("span"),F(HB.$$.fragment),JAt=l(),$Be=a("span"),YAt=o("FlaxAutoModelForVision2Seq"),iso=l(),Nr=a("div"),F(JB.$$.fragment),ZAt=l(),Gf=a("p"),KAt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),cme=a("a"),e6t=o("from_pretrained()"),o6t=o(" class method or the "),fme=a("a"),r6t=o("from_config()"),t6t=o(` class
method.`),a6t=l(),YB=a("p"),n6t=o("This class cannot be instantiated directly using "),kBe=a("code"),s6t=o("__init__()"),l6t=o(" (throws an error)."),i6t=l(),Ca=a("div"),F(ZB.$$.fragment),d6t=l(),SBe=a("p"),m6t=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),c6t=l(),Of=a("p"),f6t=o(`Note:
Loading a model from its configuration file does `),RBe=a("strong"),g6t=o("not"),h6t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gme=a("a"),u6t=o("from_pretrained()"),p6t=o(" to load the model weights."),_6t=l(),F(Ay.$$.fragment),b6t=l(),gt=a("div"),F(KB.$$.fragment),v6t=l(),PBe=a("p"),F6t=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),T6t=l(),is=a("p"),M6t=o("The model class to instantiate is selected based on the "),BBe=a("code"),E6t=o("model_type"),C6t=o(` property of the config object (either
passed as an argument or loaded from `),IBe=a("code"),w6t=o("pretrained_model_name_or_path"),A6t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NBe=a("code"),L6t=o("pretrained_model_name_or_path"),y6t=o(":"),x6t=l(),qBe=a("ul"),Ly=a("li"),jBe=a("strong"),$6t=o("vision-encoder-decoder"),k6t=o(" \u2014 "),hme=a("a"),S6t=o("FlaxVisionEncoderDecoderModel"),R6t=o(" (Vision Encoder decoder model)"),P6t=l(),F(yy.$$.fragment),this.h()},l(c){const _=k5a('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(c),u=n(c,"H1",{class:!0});var eI=s(u);f=n(eI,"A",{id:!0,class:!0,href:!0});var DBe=s(f);p=n(DBe,"SPAN",{});var GBe=s(p);T(d.$$.fragment,GBe),GBe.forEach(t),DBe.forEach(t),h=i(eI),$o=n(eI,"SPAN",{});var OBe=s($o);vd=r(OBe,"Auto Classes"),OBe.forEach(t),eI.forEach(t),Qf=i(c),Tt=n(c,"P",{});var oI=s(Tt);Fd=r(oI,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Td=n(oI,"CODE",{});var VBe=s(Td);m$=r(VBe,"from_pretrained()"),VBe.forEach(t),Wf=r(oI,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),oI.forEach(t),Xe=i(c),He=n(c,"P",{});var ds=s(He);Md=r(ds,"Instantiating one of "),ms=n(ds,"A",{href:!0});var XBe=s(ms);c$=r(XBe,"AutoConfig"),XBe.forEach(t),cs=r(ds,", "),fs=n(ds,"A",{href:!0});var zBe=s(fs);f$=r(zBe,"AutoModel"),zBe.forEach(t),Ed=r(ds,`, and
`),gs=n(ds,"A",{href:!0});var QBe=s(gs);g$=r(QBe,"AutoTokenizer"),QBe.forEach(t),Cd=r(ds," will directly create a class of the relevant architecture. For instance"),ds.forEach(t),Uf=i(c),T(on.$$.fragment,c),Je=i(c),Ae=n(c,"P",{});var rI=s(Ae);yN=r(rI,"will create a model that is an instance of "),wd=n(rI,"A",{href:!0});var WBe=s(wd);xN=r(WBe,"BertModel"),WBe.forEach(t),$N=r(rI,"."),rI.forEach(t),ko=i(c),rn=n(c,"P",{});var tI=s(rn);kN=r(tI,"There is one class of "),Hf=n(tI,"CODE",{});var UBe=s(Hf);SN=r(UBe,"AutoModel"),UBe.forEach(t),kio=r(tI," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),tI.forEach(t),Qto=i(c),Ad=n(c,"H2",{class:!0});var aI=s(Ad);Jf=n(aI,"A",{id:!0,class:!0,href:!0});var HBe=s(Jf);Efe=n(HBe,"SPAN",{});var JBe=s(Efe);T(h$.$$.fragment,JBe),JBe.forEach(t),HBe.forEach(t),Sio=i(aI),Cfe=n(aI,"SPAN",{});var YBe=s(Cfe);Rio=r(YBe,"Extending the Auto Classes"),YBe.forEach(t),aI.forEach(t),Wto=i(c),hs=n(c,"P",{});var Vf=s(hs);Pio=r(Vf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),wfe=n(Vf,"CODE",{});var ZBe=s(wfe);Bio=r(ZBe,"NewModel"),ZBe.forEach(t),Iio=r(Vf,", make sure you have a "),Afe=n(Vf,"CODE",{});var KBe=s(Afe);Nio=r(KBe,"NewModelConfig"),KBe.forEach(t),qio=r(Vf,` then you can add those to the auto
classes like this:`),Vf.forEach(t),Uto=i(c),T(u$.$$.fragment,c),Hto=i(c),RN=n(c,"P",{});var eIe=s(RN);jio=r(eIe,"You will then be able to use the auto classes like you would usually do!"),eIe.forEach(t),Jto=i(c),T(Yf.$$.fragment,c),Yto=i(c),Ld=n(c,"H2",{class:!0});var nI=s(Ld);Zf=n(nI,"A",{id:!0,class:!0,href:!0});var oIe=s(Zf);Lfe=n(oIe,"SPAN",{});var rIe=s(Lfe);T(p$.$$.fragment,rIe),rIe.forEach(t),oIe.forEach(t),Dio=i(nI),yfe=n(nI,"SPAN",{});var tIe=s(yfe);Gio=r(tIe,"AutoConfig"),tIe.forEach(t),nI.forEach(t),Zto=i(c),So=n(c,"DIV",{class:!0});var vt=s(So);T(_$.$$.fragment,vt),Oio=i(vt),b$=n(vt,"P",{});var sI=s(b$);Vio=r(sI,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),PN=n(sI,"A",{href:!0});var aIe=s(PN);Xio=r(aIe,"from_pretrained()"),aIe.forEach(t),zio=r(sI," class method."),sI.forEach(t),Qio=i(vt),v$=n(vt,"P",{});var lI=s(v$);Wio=r(lI,"This class cannot be instantiated directly using "),xfe=n(lI,"CODE",{});var nIe=s(xfe);Uio=r(nIe,"__init__()"),nIe.forEach(t),Hio=r(lI," (throws an error)."),lI.forEach(t),Jio=i(vt),qr=n(vt,"DIV",{class:!0});var Ft=s(qr);T(F$.$$.fragment,Ft),Yio=i(Ft),$fe=n(Ft,"P",{});var sIe=s($fe);Zio=r(sIe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),sIe.forEach(t),Kio=i(Ft),yd=n(Ft,"P",{});var Xf=s(yd);edo=r(Xf,"The configuration class to instantiate is selected based on the "),kfe=n(Xf,"CODE",{});var lIe=s(kfe);odo=r(lIe,"model_type"),lIe.forEach(t),rdo=r(Xf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Sfe=n(Xf,"CODE",{});var iIe=s(Sfe);tdo=r(iIe,"pretrained_model_name_or_path"),iIe.forEach(t),ado=r(Xf,":"),Xf.forEach(t),ndo=i(Ft),A=n(Ft,"UL",{});var L=s(A);Kf=n(L,"LI",{});var xy=s(Kf);Rfe=n(xy,"STRONG",{});var dIe=s(Rfe);sdo=r(dIe,"albert"),dIe.forEach(t),ldo=r(xy," \u2014 "),BN=n(xy,"A",{href:!0});var mIe=s(BN);ido=r(mIe,"AlbertConfig"),mIe.forEach(t),ddo=r(xy," (ALBERT model)"),xy.forEach(t),mdo=i(L),eg=n(L,"LI",{});var $y=s(eg);Pfe=n($y,"STRONG",{});var cIe=s(Pfe);cdo=r(cIe,"bart"),cIe.forEach(t),fdo=r($y," \u2014 "),IN=n($y,"A",{href:!0});var fIe=s(IN);gdo=r(fIe,"BartConfig"),fIe.forEach(t),hdo=r($y," (BART model)"),$y.forEach(t),udo=i(L),og=n(L,"LI",{});var ky=s(og);Bfe=n(ky,"STRONG",{});var gIe=s(Bfe);pdo=r(gIe,"beit"),gIe.forEach(t),_do=r(ky," \u2014 "),NN=n(ky,"A",{href:!0});var hIe=s(NN);bdo=r(hIe,"BeitConfig"),hIe.forEach(t),vdo=r(ky," (BEiT model)"),ky.forEach(t),Fdo=i(L),rg=n(L,"LI",{});var Sy=s(rg);Ife=n(Sy,"STRONG",{});var uIe=s(Ife);Tdo=r(uIe,"bert"),uIe.forEach(t),Mdo=r(Sy," \u2014 "),qN=n(Sy,"A",{href:!0});var pIe=s(qN);Edo=r(pIe,"BertConfig"),pIe.forEach(t),Cdo=r(Sy," (BERT model)"),Sy.forEach(t),wdo=i(L),tg=n(L,"LI",{});var Ry=s(tg);Nfe=n(Ry,"STRONG",{});var _Ie=s(Nfe);Ado=r(_Ie,"bert-generation"),_Ie.forEach(t),Ldo=r(Ry," \u2014 "),jN=n(Ry,"A",{href:!0});var bIe=s(jN);ydo=r(bIe,"BertGenerationConfig"),bIe.forEach(t),xdo=r(Ry," (Bert Generation model)"),Ry.forEach(t),$do=i(L),ag=n(L,"LI",{});var Py=s(ag);qfe=n(Py,"STRONG",{});var vIe=s(qfe);kdo=r(vIe,"big_bird"),vIe.forEach(t),Sdo=r(Py," \u2014 "),DN=n(Py,"A",{href:!0});var FIe=s(DN);Rdo=r(FIe,"BigBirdConfig"),FIe.forEach(t),Pdo=r(Py," (BigBird model)"),Py.forEach(t),Bdo=i(L),ng=n(L,"LI",{});var By=s(ng);jfe=n(By,"STRONG",{});var TIe=s(jfe);Ido=r(TIe,"bigbird_pegasus"),TIe.forEach(t),Ndo=r(By," \u2014 "),GN=n(By,"A",{href:!0});var MIe=s(GN);qdo=r(MIe,"BigBirdPegasusConfig"),MIe.forEach(t),jdo=r(By," (BigBird-Pegasus model)"),By.forEach(t),Ddo=i(L),sg=n(L,"LI",{});var Iy=s(sg);Dfe=n(Iy,"STRONG",{});var EIe=s(Dfe);Gdo=r(EIe,"blenderbot"),EIe.forEach(t),Odo=r(Iy," \u2014 "),ON=n(Iy,"A",{href:!0});var CIe=s(ON);Vdo=r(CIe,"BlenderbotConfig"),CIe.forEach(t),Xdo=r(Iy," (Blenderbot model)"),Iy.forEach(t),zdo=i(L),lg=n(L,"LI",{});var Ny=s(lg);Gfe=n(Ny,"STRONG",{});var wIe=s(Gfe);Qdo=r(wIe,"blenderbot-small"),wIe.forEach(t),Wdo=r(Ny," \u2014 "),VN=n(Ny,"A",{href:!0});var AIe=s(VN);Udo=r(AIe,"BlenderbotSmallConfig"),AIe.forEach(t),Hdo=r(Ny," (BlenderbotSmall model)"),Ny.forEach(t),Jdo=i(L),ig=n(L,"LI",{});var qy=s(ig);Ofe=n(qy,"STRONG",{});var LIe=s(Ofe);Ydo=r(LIe,"bloom"),LIe.forEach(t),Zdo=r(qy," \u2014 "),XN=n(qy,"A",{href:!0});var yIe=s(XN);Kdo=r(yIe,"BloomConfig"),yIe.forEach(t),emo=r(qy," (BLOOM model)"),qy.forEach(t),omo=i(L),dg=n(L,"LI",{});var jy=s(dg);Vfe=n(jy,"STRONG",{});var xIe=s(Vfe);rmo=r(xIe,"camembert"),xIe.forEach(t),tmo=r(jy," \u2014 "),zN=n(jy,"A",{href:!0});var $Ie=s(zN);amo=r($Ie,"CamembertConfig"),$Ie.forEach(t),nmo=r(jy," (CamemBERT model)"),jy.forEach(t),smo=i(L),mg=n(L,"LI",{});var Dy=s(mg);Xfe=n(Dy,"STRONG",{});var kIe=s(Xfe);lmo=r(kIe,"canine"),kIe.forEach(t),imo=r(Dy," \u2014 "),QN=n(Dy,"A",{href:!0});var SIe=s(QN);dmo=r(SIe,"CanineConfig"),SIe.forEach(t),mmo=r(Dy," (CANINE model)"),Dy.forEach(t),cmo=i(L),cg=n(L,"LI",{});var Gy=s(cg);zfe=n(Gy,"STRONG",{});var RIe=s(zfe);fmo=r(RIe,"clip"),RIe.forEach(t),gmo=r(Gy," \u2014 "),WN=n(Gy,"A",{href:!0});var PIe=s(WN);hmo=r(PIe,"CLIPConfig"),PIe.forEach(t),umo=r(Gy," (CLIP model)"),Gy.forEach(t),pmo=i(L),fg=n(L,"LI",{});var Oy=s(fg);Qfe=n(Oy,"STRONG",{});var BIe=s(Qfe);_mo=r(BIe,"clipseg"),BIe.forEach(t),bmo=r(Oy," \u2014 "),UN=n(Oy,"A",{href:!0});var IIe=s(UN);vmo=r(IIe,"CLIPSegConfig"),IIe.forEach(t),Fmo=r(Oy," (CLIPSeg model)"),Oy.forEach(t),Tmo=i(L),gg=n(L,"LI",{});var Vy=s(gg);Wfe=n(Vy,"STRONG",{});var NIe=s(Wfe);Mmo=r(NIe,"codegen"),NIe.forEach(t),Emo=r(Vy," \u2014 "),HN=n(Vy,"A",{href:!0});var qIe=s(HN);Cmo=r(qIe,"CodeGenConfig"),qIe.forEach(t),wmo=r(Vy," (CodeGen model)"),Vy.forEach(t),Amo=i(L),hg=n(L,"LI",{});var Xy=s(hg);Ufe=n(Xy,"STRONG",{});var jIe=s(Ufe);Lmo=r(jIe,"conditional_detr"),jIe.forEach(t),ymo=r(Xy," \u2014 "),JN=n(Xy,"A",{href:!0});var DIe=s(JN);xmo=r(DIe,"ConditionalDetrConfig"),DIe.forEach(t),$mo=r(Xy," (Conditional DETR model)"),Xy.forEach(t),kmo=i(L),ug=n(L,"LI",{});var zy=s(ug);Hfe=n(zy,"STRONG",{});var GIe=s(Hfe);Smo=r(GIe,"convbert"),GIe.forEach(t),Rmo=r(zy," \u2014 "),YN=n(zy,"A",{href:!0});var OIe=s(YN);Pmo=r(OIe,"ConvBertConfig"),OIe.forEach(t),Bmo=r(zy," (ConvBERT model)"),zy.forEach(t),Imo=i(L),pg=n(L,"LI",{});var Qy=s(pg);Jfe=n(Qy,"STRONG",{});var VIe=s(Jfe);Nmo=r(VIe,"convnext"),VIe.forEach(t),qmo=r(Qy," \u2014 "),ZN=n(Qy,"A",{href:!0});var XIe=s(ZN);jmo=r(XIe,"ConvNextConfig"),XIe.forEach(t),Dmo=r(Qy," (ConvNeXT model)"),Qy.forEach(t),Gmo=i(L),_g=n(L,"LI",{});var Wy=s(_g);Yfe=n(Wy,"STRONG",{});var zIe=s(Yfe);Omo=r(zIe,"ctrl"),zIe.forEach(t),Vmo=r(Wy," \u2014 "),KN=n(Wy,"A",{href:!0});var QIe=s(KN);Xmo=r(QIe,"CTRLConfig"),QIe.forEach(t),zmo=r(Wy," (CTRL model)"),Wy.forEach(t),Qmo=i(L),bg=n(L,"LI",{});var Uy=s(bg);Zfe=n(Uy,"STRONG",{});var WIe=s(Zfe);Wmo=r(WIe,"cvt"),WIe.forEach(t),Umo=r(Uy," \u2014 "),eq=n(Uy,"A",{href:!0});var UIe=s(eq);Hmo=r(UIe,"CvtConfig"),UIe.forEach(t),Jmo=r(Uy," (CvT model)"),Uy.forEach(t),Ymo=i(L),vg=n(L,"LI",{});var Hy=s(vg);Kfe=n(Hy,"STRONG",{});var HIe=s(Kfe);Zmo=r(HIe,"data2vec-audio"),HIe.forEach(t),Kmo=r(Hy," \u2014 "),oq=n(Hy,"A",{href:!0});var JIe=s(oq);eco=r(JIe,"Data2VecAudioConfig"),JIe.forEach(t),oco=r(Hy," (Data2VecAudio model)"),Hy.forEach(t),rco=i(L),Fg=n(L,"LI",{});var Jy=s(Fg);ege=n(Jy,"STRONG",{});var YIe=s(ege);tco=r(YIe,"data2vec-text"),YIe.forEach(t),aco=r(Jy," \u2014 "),rq=n(Jy,"A",{href:!0});var ZIe=s(rq);nco=r(ZIe,"Data2VecTextConfig"),ZIe.forEach(t),sco=r(Jy," (Data2VecText model)"),Jy.forEach(t),lco=i(L),Tg=n(L,"LI",{});var Yy=s(Tg);oge=n(Yy,"STRONG",{});var KIe=s(oge);ico=r(KIe,"data2vec-vision"),KIe.forEach(t),dco=r(Yy," \u2014 "),tq=n(Yy,"A",{href:!0});var eNe=s(tq);mco=r(eNe,"Data2VecVisionConfig"),eNe.forEach(t),cco=r(Yy," (Data2VecVision model)"),Yy.forEach(t),fco=i(L),Mg=n(L,"LI",{});var Zy=s(Mg);rge=n(Zy,"STRONG",{});var oNe=s(rge);gco=r(oNe,"deberta"),oNe.forEach(t),hco=r(Zy," \u2014 "),aq=n(Zy,"A",{href:!0});var rNe=s(aq);uco=r(rNe,"DebertaConfig"),rNe.forEach(t),pco=r(Zy," (DeBERTa model)"),Zy.forEach(t),_co=i(L),Eg=n(L,"LI",{});var Ky=s(Eg);tge=n(Ky,"STRONG",{});var tNe=s(tge);bco=r(tNe,"deberta-v2"),tNe.forEach(t),vco=r(Ky," \u2014 "),nq=n(Ky,"A",{href:!0});var aNe=s(nq);Fco=r(aNe,"DebertaV2Config"),aNe.forEach(t),Tco=r(Ky," (DeBERTa-v2 model)"),Ky.forEach(t),Mco=i(L),Cg=n(L,"LI",{});var e9=s(Cg);age=n(e9,"STRONG",{});var nNe=s(age);Eco=r(nNe,"decision_transformer"),nNe.forEach(t),Cco=r(e9," \u2014 "),sq=n(e9,"A",{href:!0});var sNe=s(sq);wco=r(sNe,"DecisionTransformerConfig"),sNe.forEach(t),Aco=r(e9," (Decision Transformer model)"),e9.forEach(t),Lco=i(L),wg=n(L,"LI",{});var o9=s(wg);nge=n(o9,"STRONG",{});var lNe=s(nge);yco=r(lNe,"deformable_detr"),lNe.forEach(t),xco=r(o9," \u2014 "),lq=n(o9,"A",{href:!0});var iNe=s(lq);$co=r(iNe,"DeformableDetrConfig"),iNe.forEach(t),kco=r(o9," (Deformable DETR model)"),o9.forEach(t),Sco=i(L),Ag=n(L,"LI",{});var r9=s(Ag);sge=n(r9,"STRONG",{});var I6t=s(sge);Rco=r(I6t,"deit"),I6t.forEach(t),Pco=r(r9," \u2014 "),iq=n(r9,"A",{href:!0});var N6t=s(iq);Bco=r(N6t,"DeiTConfig"),N6t.forEach(t),Ico=r(r9," (DeiT model)"),r9.forEach(t),Nco=i(L),Lg=n(L,"LI",{});var dNe=s(Lg);lge=n(dNe,"STRONG",{});var q6t=s(lge);qco=r(q6t,"detr"),q6t.forEach(t),jco=r(dNe," \u2014 "),dq=n(dNe,"A",{href:!0});var j6t=s(dq);Dco=r(j6t,"DetrConfig"),j6t.forEach(t),Gco=r(dNe," (DETR model)"),dNe.forEach(t),Oco=i(L),yg=n(L,"LI",{});var mNe=s(yg);ige=n(mNe,"STRONG",{});var D6t=s(ige);Vco=r(D6t,"distilbert"),D6t.forEach(t),Xco=r(mNe," \u2014 "),mq=n(mNe,"A",{href:!0});var G6t=s(mq);zco=r(G6t,"DistilBertConfig"),G6t.forEach(t),Qco=r(mNe," (DistilBERT model)"),mNe.forEach(t),Wco=i(L),xg=n(L,"LI",{});var cNe=s(xg);dge=n(cNe,"STRONG",{});var O6t=s(dge);Uco=r(O6t,"donut-swin"),O6t.forEach(t),Hco=r(cNe," \u2014 "),cq=n(cNe,"A",{href:!0});var V6t=s(cq);Jco=r(V6t,"DonutSwinConfig"),V6t.forEach(t),Yco=r(cNe," (DonutSwin model)"),cNe.forEach(t),Zco=i(L),$g=n(L,"LI",{});var fNe=s($g);mge=n(fNe,"STRONG",{});var X6t=s(mge);Kco=r(X6t,"dpr"),X6t.forEach(t),efo=r(fNe," \u2014 "),fq=n(fNe,"A",{href:!0});var z6t=s(fq);ofo=r(z6t,"DPRConfig"),z6t.forEach(t),rfo=r(fNe," (DPR model)"),fNe.forEach(t),tfo=i(L),kg=n(L,"LI",{});var gNe=s(kg);cge=n(gNe,"STRONG",{});var Q6t=s(cge);afo=r(Q6t,"dpt"),Q6t.forEach(t),nfo=r(gNe," \u2014 "),gq=n(gNe,"A",{href:!0});var W6t=s(gq);sfo=r(W6t,"DPTConfig"),W6t.forEach(t),lfo=r(gNe," (DPT model)"),gNe.forEach(t),ifo=i(L),Sg=n(L,"LI",{});var hNe=s(Sg);fge=n(hNe,"STRONG",{});var U6t=s(fge);dfo=r(U6t,"electra"),U6t.forEach(t),mfo=r(hNe," \u2014 "),hq=n(hNe,"A",{href:!0});var H6t=s(hq);cfo=r(H6t,"ElectraConfig"),H6t.forEach(t),ffo=r(hNe," (ELECTRA model)"),hNe.forEach(t),gfo=i(L),Rg=n(L,"LI",{});var uNe=s(Rg);gge=n(uNe,"STRONG",{});var J6t=s(gge);hfo=r(J6t,"encoder-decoder"),J6t.forEach(t),ufo=r(uNe," \u2014 "),uq=n(uNe,"A",{href:!0});var Y6t=s(uq);pfo=r(Y6t,"EncoderDecoderConfig"),Y6t.forEach(t),_fo=r(uNe," (Encoder decoder model)"),uNe.forEach(t),bfo=i(L),Pg=n(L,"LI",{});var pNe=s(Pg);hge=n(pNe,"STRONG",{});var Z6t=s(hge);vfo=r(Z6t,"ernie"),Z6t.forEach(t),Ffo=r(pNe," \u2014 "),pq=n(pNe,"A",{href:!0});var K6t=s(pq);Tfo=r(K6t,"ErnieConfig"),K6t.forEach(t),Mfo=r(pNe," (ERNIE model)"),pNe.forEach(t),Efo=i(L),Bg=n(L,"LI",{});var _Ne=s(Bg);uge=n(_Ne,"STRONG",{});var e7t=s(uge);Cfo=r(e7t,"esm"),e7t.forEach(t),wfo=r(_Ne," \u2014 "),_q=n(_Ne,"A",{href:!0});var o7t=s(_q);Afo=r(o7t,"EsmConfig"),o7t.forEach(t),Lfo=r(_Ne," (ESM model)"),_Ne.forEach(t),yfo=i(L),Ig=n(L,"LI",{});var bNe=s(Ig);pge=n(bNe,"STRONG",{});var r7t=s(pge);xfo=r(r7t,"flaubert"),r7t.forEach(t),$fo=r(bNe," \u2014 "),bq=n(bNe,"A",{href:!0});var t7t=s(bq);kfo=r(t7t,"FlaubertConfig"),t7t.forEach(t),Sfo=r(bNe," (FlauBERT model)"),bNe.forEach(t),Rfo=i(L),Ng=n(L,"LI",{});var vNe=s(Ng);_ge=n(vNe,"STRONG",{});var a7t=s(_ge);Pfo=r(a7t,"flava"),a7t.forEach(t),Bfo=r(vNe," \u2014 "),vq=n(vNe,"A",{href:!0});var n7t=s(vq);Ifo=r(n7t,"FlavaConfig"),n7t.forEach(t),Nfo=r(vNe," (FLAVA model)"),vNe.forEach(t),qfo=i(L),qg=n(L,"LI",{});var FNe=s(qg);bge=n(FNe,"STRONG",{});var s7t=s(bge);jfo=r(s7t,"fnet"),s7t.forEach(t),Dfo=r(FNe," \u2014 "),Fq=n(FNe,"A",{href:!0});var l7t=s(Fq);Gfo=r(l7t,"FNetConfig"),l7t.forEach(t),Ofo=r(FNe," (FNet model)"),FNe.forEach(t),Vfo=i(L),jg=n(L,"LI",{});var TNe=s(jg);vge=n(TNe,"STRONG",{});var i7t=s(vge);Xfo=r(i7t,"fsmt"),i7t.forEach(t),zfo=r(TNe," \u2014 "),Tq=n(TNe,"A",{href:!0});var d7t=s(Tq);Qfo=r(d7t,"FSMTConfig"),d7t.forEach(t),Wfo=r(TNe," (FairSeq Machine-Translation model)"),TNe.forEach(t),Ufo=i(L),Dg=n(L,"LI",{});var MNe=s(Dg);Fge=n(MNe,"STRONG",{});var m7t=s(Fge);Hfo=r(m7t,"funnel"),m7t.forEach(t),Jfo=r(MNe," \u2014 "),Mq=n(MNe,"A",{href:!0});var c7t=s(Mq);Yfo=r(c7t,"FunnelConfig"),c7t.forEach(t),Zfo=r(MNe," (Funnel Transformer model)"),MNe.forEach(t),Kfo=i(L),Gg=n(L,"LI",{});var ENe=s(Gg);Tge=n(ENe,"STRONG",{});var f7t=s(Tge);ego=r(f7t,"glpn"),f7t.forEach(t),ogo=r(ENe," \u2014 "),Eq=n(ENe,"A",{href:!0});var g7t=s(Eq);rgo=r(g7t,"GLPNConfig"),g7t.forEach(t),tgo=r(ENe," (GLPN model)"),ENe.forEach(t),ago=i(L),Og=n(L,"LI",{});var CNe=s(Og);Mge=n(CNe,"STRONG",{});var h7t=s(Mge);ngo=r(h7t,"gpt2"),h7t.forEach(t),sgo=r(CNe," \u2014 "),Cq=n(CNe,"A",{href:!0});var u7t=s(Cq);lgo=r(u7t,"GPT2Config"),u7t.forEach(t),igo=r(CNe," (OpenAI GPT-2 model)"),CNe.forEach(t),dgo=i(L),Vg=n(L,"LI",{});var wNe=s(Vg);Ege=n(wNe,"STRONG",{});var p7t=s(Ege);mgo=r(p7t,"gpt_neo"),p7t.forEach(t),cgo=r(wNe," \u2014 "),wq=n(wNe,"A",{href:!0});var _7t=s(wq);fgo=r(_7t,"GPTNeoConfig"),_7t.forEach(t),ggo=r(wNe," (GPT Neo model)"),wNe.forEach(t),hgo=i(L),Xg=n(L,"LI",{});var ANe=s(Xg);Cge=n(ANe,"STRONG",{});var b7t=s(Cge);ugo=r(b7t,"gpt_neox"),b7t.forEach(t),pgo=r(ANe," \u2014 "),Aq=n(ANe,"A",{href:!0});var v7t=s(Aq);_go=r(v7t,"GPTNeoXConfig"),v7t.forEach(t),bgo=r(ANe," (GPT NeoX model)"),ANe.forEach(t),vgo=i(L),zg=n(L,"LI",{});var LNe=s(zg);wge=n(LNe,"STRONG",{});var F7t=s(wge);Fgo=r(F7t,"gpt_neox_japanese"),F7t.forEach(t),Tgo=r(LNe," \u2014 "),Lq=n(LNe,"A",{href:!0});var T7t=s(Lq);Mgo=r(T7t,"GPTNeoXJapaneseConfig"),T7t.forEach(t),Ego=r(LNe," (GPT NeoX Japanese model)"),LNe.forEach(t),Cgo=i(L),Qg=n(L,"LI",{});var yNe=s(Qg);Age=n(yNe,"STRONG",{});var M7t=s(Age);wgo=r(M7t,"gptj"),M7t.forEach(t),Ago=r(yNe," \u2014 "),yq=n(yNe,"A",{href:!0});var E7t=s(yq);Lgo=r(E7t,"GPTJConfig"),E7t.forEach(t),ygo=r(yNe," (GPT-J model)"),yNe.forEach(t),xgo=i(L),Wg=n(L,"LI",{});var xNe=s(Wg);Lge=n(xNe,"STRONG",{});var C7t=s(Lge);$go=r(C7t,"groupvit"),C7t.forEach(t),kgo=r(xNe," \u2014 "),xq=n(xNe,"A",{href:!0});var w7t=s(xq);Sgo=r(w7t,"GroupViTConfig"),w7t.forEach(t),Rgo=r(xNe," (GroupViT model)"),xNe.forEach(t),Pgo=i(L),Ug=n(L,"LI",{});var $Ne=s(Ug);yge=n($Ne,"STRONG",{});var A7t=s(yge);Bgo=r(A7t,"hubert"),A7t.forEach(t),Igo=r($Ne," \u2014 "),$q=n($Ne,"A",{href:!0});var L7t=s($q);Ngo=r(L7t,"HubertConfig"),L7t.forEach(t),qgo=r($Ne," (Hubert model)"),$Ne.forEach(t),jgo=i(L),Hg=n(L,"LI",{});var kNe=s(Hg);xge=n(kNe,"STRONG",{});var y7t=s(xge);Dgo=r(y7t,"ibert"),y7t.forEach(t),Ggo=r(kNe," \u2014 "),kq=n(kNe,"A",{href:!0});var x7t=s(kq);Ogo=r(x7t,"IBertConfig"),x7t.forEach(t),Vgo=r(kNe," (I-BERT model)"),kNe.forEach(t),Xgo=i(L),Jg=n(L,"LI",{});var SNe=s(Jg);$ge=n(SNe,"STRONG",{});var $7t=s($ge);zgo=r($7t,"imagegpt"),$7t.forEach(t),Qgo=r(SNe," \u2014 "),Sq=n(SNe,"A",{href:!0});var k7t=s(Sq);Wgo=r(k7t,"ImageGPTConfig"),k7t.forEach(t),Ugo=r(SNe," (ImageGPT model)"),SNe.forEach(t),Hgo=i(L),Yg=n(L,"LI",{});var RNe=s(Yg);kge=n(RNe,"STRONG",{});var S7t=s(kge);Jgo=r(S7t,"layoutlm"),S7t.forEach(t),Ygo=r(RNe," \u2014 "),Rq=n(RNe,"A",{href:!0});var R7t=s(Rq);Zgo=r(R7t,"LayoutLMConfig"),R7t.forEach(t),Kgo=r(RNe," (LayoutLM model)"),RNe.forEach(t),eho=i(L),Zg=n(L,"LI",{});var PNe=s(Zg);Sge=n(PNe,"STRONG",{});var P7t=s(Sge);oho=r(P7t,"layoutlmv2"),P7t.forEach(t),rho=r(PNe," \u2014 "),Pq=n(PNe,"A",{href:!0});var B7t=s(Pq);tho=r(B7t,"LayoutLMv2Config"),B7t.forEach(t),aho=r(PNe," (LayoutLMv2 model)"),PNe.forEach(t),nho=i(L),Kg=n(L,"LI",{});var BNe=s(Kg);Rge=n(BNe,"STRONG",{});var I7t=s(Rge);sho=r(I7t,"layoutlmv3"),I7t.forEach(t),lho=r(BNe," \u2014 "),Bq=n(BNe,"A",{href:!0});var N7t=s(Bq);iho=r(N7t,"LayoutLMv3Config"),N7t.forEach(t),dho=r(BNe," (LayoutLMv3 model)"),BNe.forEach(t),mho=i(L),eh=n(L,"LI",{});var INe=s(eh);Pge=n(INe,"STRONG",{});var q7t=s(Pge);cho=r(q7t,"led"),q7t.forEach(t),fho=r(INe," \u2014 "),Iq=n(INe,"A",{href:!0});var j7t=s(Iq);gho=r(j7t,"LEDConfig"),j7t.forEach(t),hho=r(INe," (LED model)"),INe.forEach(t),uho=i(L),oh=n(L,"LI",{});var NNe=s(oh);Bge=n(NNe,"STRONG",{});var D7t=s(Bge);pho=r(D7t,"levit"),D7t.forEach(t),_ho=r(NNe," \u2014 "),Nq=n(NNe,"A",{href:!0});var G7t=s(Nq);bho=r(G7t,"LevitConfig"),G7t.forEach(t),vho=r(NNe," (LeViT model)"),NNe.forEach(t),Fho=i(L),rh=n(L,"LI",{});var qNe=s(rh);Ige=n(qNe,"STRONG",{});var O7t=s(Ige);Tho=r(O7t,"lilt"),O7t.forEach(t),Mho=r(qNe," \u2014 "),qq=n(qNe,"A",{href:!0});var V7t=s(qq);Eho=r(V7t,"LiltConfig"),V7t.forEach(t),Cho=r(qNe," (LiLT model)"),qNe.forEach(t),who=i(L),th=n(L,"LI",{});var jNe=s(th);Nge=n(jNe,"STRONG",{});var X7t=s(Nge);Aho=r(X7t,"longformer"),X7t.forEach(t),Lho=r(jNe," \u2014 "),jq=n(jNe,"A",{href:!0});var z7t=s(jq);yho=r(z7t,"LongformerConfig"),z7t.forEach(t),xho=r(jNe," (Longformer model)"),jNe.forEach(t),$ho=i(L),ah=n(L,"LI",{});var DNe=s(ah);qge=n(DNe,"STRONG",{});var Q7t=s(qge);kho=r(Q7t,"longt5"),Q7t.forEach(t),Sho=r(DNe," \u2014 "),Dq=n(DNe,"A",{href:!0});var W7t=s(Dq);Rho=r(W7t,"LongT5Config"),W7t.forEach(t),Pho=r(DNe," (LongT5 model)"),DNe.forEach(t),Bho=i(L),nh=n(L,"LI",{});var GNe=s(nh);jge=n(GNe,"STRONG",{});var U7t=s(jge);Iho=r(U7t,"luke"),U7t.forEach(t),Nho=r(GNe," \u2014 "),Gq=n(GNe,"A",{href:!0});var H7t=s(Gq);qho=r(H7t,"LukeConfig"),H7t.forEach(t),jho=r(GNe," (LUKE model)"),GNe.forEach(t),Dho=i(L),sh=n(L,"LI",{});var ONe=s(sh);Dge=n(ONe,"STRONG",{});var J7t=s(Dge);Gho=r(J7t,"lxmert"),J7t.forEach(t),Oho=r(ONe," \u2014 "),Oq=n(ONe,"A",{href:!0});var Y7t=s(Oq);Vho=r(Y7t,"LxmertConfig"),Y7t.forEach(t),Xho=r(ONe," (LXMERT model)"),ONe.forEach(t),zho=i(L),lh=n(L,"LI",{});var VNe=s(lh);Gge=n(VNe,"STRONG",{});var Z7t=s(Gge);Qho=r(Z7t,"m2m_100"),Z7t.forEach(t),Who=r(VNe," \u2014 "),Vq=n(VNe,"A",{href:!0});var K7t=s(Vq);Uho=r(K7t,"M2M100Config"),K7t.forEach(t),Hho=r(VNe," (M2M100 model)"),VNe.forEach(t),Jho=i(L),ih=n(L,"LI",{});var XNe=s(ih);Oge=n(XNe,"STRONG",{});var e8t=s(Oge);Yho=r(e8t,"marian"),e8t.forEach(t),Zho=r(XNe," \u2014 "),Xq=n(XNe,"A",{href:!0});var o8t=s(Xq);Kho=r(o8t,"MarianConfig"),o8t.forEach(t),euo=r(XNe," (Marian model)"),XNe.forEach(t),ouo=i(L),dh=n(L,"LI",{});var zNe=s(dh);Vge=n(zNe,"STRONG",{});var r8t=s(Vge);ruo=r(r8t,"markuplm"),r8t.forEach(t),tuo=r(zNe," \u2014 "),zq=n(zNe,"A",{href:!0});var t8t=s(zq);auo=r(t8t,"MarkupLMConfig"),t8t.forEach(t),nuo=r(zNe," (MarkupLM model)"),zNe.forEach(t),suo=i(L),mh=n(L,"LI",{});var QNe=s(mh);Xge=n(QNe,"STRONG",{});var a8t=s(Xge);luo=r(a8t,"maskformer"),a8t.forEach(t),iuo=r(QNe," \u2014 "),Qq=n(QNe,"A",{href:!0});var n8t=s(Qq);duo=r(n8t,"MaskFormerConfig"),n8t.forEach(t),muo=r(QNe," (MaskFormer model)"),QNe.forEach(t),cuo=i(L),ch=n(L,"LI",{});var WNe=s(ch);zge=n(WNe,"STRONG",{});var s8t=s(zge);fuo=r(s8t,"mbart"),s8t.forEach(t),guo=r(WNe," \u2014 "),Wq=n(WNe,"A",{href:!0});var l8t=s(Wq);huo=r(l8t,"MBartConfig"),l8t.forEach(t),uuo=r(WNe," (mBART model)"),WNe.forEach(t),puo=i(L),fh=n(L,"LI",{});var UNe=s(fh);Qge=n(UNe,"STRONG",{});var i8t=s(Qge);_uo=r(i8t,"mctct"),i8t.forEach(t),buo=r(UNe," \u2014 "),Uq=n(UNe,"A",{href:!0});var d8t=s(Uq);vuo=r(d8t,"MCTCTConfig"),d8t.forEach(t),Fuo=r(UNe," (M-CTC-T model)"),UNe.forEach(t),Tuo=i(L),gh=n(L,"LI",{});var HNe=s(gh);Wge=n(HNe,"STRONG",{});var m8t=s(Wge);Muo=r(m8t,"megatron-bert"),m8t.forEach(t),Euo=r(HNe," \u2014 "),Hq=n(HNe,"A",{href:!0});var c8t=s(Hq);Cuo=r(c8t,"MegatronBertConfig"),c8t.forEach(t),wuo=r(HNe," (Megatron-BERT model)"),HNe.forEach(t),Auo=i(L),hh=n(L,"LI",{});var JNe=s(hh);Uge=n(JNe,"STRONG",{});var f8t=s(Uge);Luo=r(f8t,"mobilebert"),f8t.forEach(t),yuo=r(JNe," \u2014 "),Jq=n(JNe,"A",{href:!0});var g8t=s(Jq);xuo=r(g8t,"MobileBertConfig"),g8t.forEach(t),$uo=r(JNe," (MobileBERT model)"),JNe.forEach(t),kuo=i(L),uh=n(L,"LI",{});var YNe=s(uh);Hge=n(YNe,"STRONG",{});var h8t=s(Hge);Suo=r(h8t,"mobilevit"),h8t.forEach(t),Ruo=r(YNe," \u2014 "),Yq=n(YNe,"A",{href:!0});var u8t=s(Yq);Puo=r(u8t,"MobileViTConfig"),u8t.forEach(t),Buo=r(YNe," (MobileViT model)"),YNe.forEach(t),Iuo=i(L),ph=n(L,"LI",{});var ZNe=s(ph);Jge=n(ZNe,"STRONG",{});var p8t=s(Jge);Nuo=r(p8t,"mpnet"),p8t.forEach(t),quo=r(ZNe," \u2014 "),Zq=n(ZNe,"A",{href:!0});var _8t=s(Zq);juo=r(_8t,"MPNetConfig"),_8t.forEach(t),Duo=r(ZNe," (MPNet model)"),ZNe.forEach(t),Guo=i(L),_h=n(L,"LI",{});var KNe=s(_h);Yge=n(KNe,"STRONG",{});var b8t=s(Yge);Ouo=r(b8t,"mt5"),b8t.forEach(t),Vuo=r(KNe," \u2014 "),Kq=n(KNe,"A",{href:!0});var v8t=s(Kq);Xuo=r(v8t,"MT5Config"),v8t.forEach(t),zuo=r(KNe," (MT5 model)"),KNe.forEach(t),Quo=i(L),bh=n(L,"LI",{});var eqe=s(bh);Zge=n(eqe,"STRONG",{});var F8t=s(Zge);Wuo=r(F8t,"mvp"),F8t.forEach(t),Uuo=r(eqe," \u2014 "),ej=n(eqe,"A",{href:!0});var T8t=s(ej);Huo=r(T8t,"MvpConfig"),T8t.forEach(t),Juo=r(eqe," (MVP model)"),eqe.forEach(t),Yuo=i(L),vh=n(L,"LI",{});var oqe=s(vh);Kge=n(oqe,"STRONG",{});var M8t=s(Kge);Zuo=r(M8t,"nezha"),M8t.forEach(t),Kuo=r(oqe," \u2014 "),oj=n(oqe,"A",{href:!0});var E8t=s(oj);epo=r(E8t,"NezhaConfig"),E8t.forEach(t),opo=r(oqe," (Nezha model)"),oqe.forEach(t),rpo=i(L),Fh=n(L,"LI",{});var rqe=s(Fh);ehe=n(rqe,"STRONG",{});var C8t=s(ehe);tpo=r(C8t,"nystromformer"),C8t.forEach(t),apo=r(rqe," \u2014 "),rj=n(rqe,"A",{href:!0});var w8t=s(rj);npo=r(w8t,"NystromformerConfig"),w8t.forEach(t),spo=r(rqe," (Nystr\xF6mformer model)"),rqe.forEach(t),lpo=i(L),Th=n(L,"LI",{});var tqe=s(Th);ohe=n(tqe,"STRONG",{});var A8t=s(ohe);ipo=r(A8t,"openai-gpt"),A8t.forEach(t),dpo=r(tqe," \u2014 "),tj=n(tqe,"A",{href:!0});var L8t=s(tj);mpo=r(L8t,"OpenAIGPTConfig"),L8t.forEach(t),cpo=r(tqe," (OpenAI GPT model)"),tqe.forEach(t),fpo=i(L),Mh=n(L,"LI",{});var aqe=s(Mh);rhe=n(aqe,"STRONG",{});var y8t=s(rhe);gpo=r(y8t,"opt"),y8t.forEach(t),hpo=r(aqe," \u2014 "),aj=n(aqe,"A",{href:!0});var x8t=s(aj);upo=r(x8t,"OPTConfig"),x8t.forEach(t),ppo=r(aqe," (OPT model)"),aqe.forEach(t),_po=i(L),Eh=n(L,"LI",{});var nqe=s(Eh);the=n(nqe,"STRONG",{});var $8t=s(the);bpo=r($8t,"owlvit"),$8t.forEach(t),vpo=r(nqe," \u2014 "),nj=n(nqe,"A",{href:!0});var k8t=s(nj);Fpo=r(k8t,"OwlViTConfig"),k8t.forEach(t),Tpo=r(nqe," (OWL-ViT model)"),nqe.forEach(t),Mpo=i(L),Ch=n(L,"LI",{});var sqe=s(Ch);ahe=n(sqe,"STRONG",{});var S8t=s(ahe);Epo=r(S8t,"pegasus"),S8t.forEach(t),Cpo=r(sqe," \u2014 "),sj=n(sqe,"A",{href:!0});var R8t=s(sj);wpo=r(R8t,"PegasusConfig"),R8t.forEach(t),Apo=r(sqe," (Pegasus model)"),sqe.forEach(t),Lpo=i(L),wh=n(L,"LI",{});var lqe=s(wh);nhe=n(lqe,"STRONG",{});var P8t=s(nhe);ypo=r(P8t,"pegasus_x"),P8t.forEach(t),xpo=r(lqe," \u2014 "),lj=n(lqe,"A",{href:!0});var B8t=s(lj);$po=r(B8t,"PegasusXConfig"),B8t.forEach(t),kpo=r(lqe," (PEGASUS-X model)"),lqe.forEach(t),Spo=i(L),Ah=n(L,"LI",{});var iqe=s(Ah);she=n(iqe,"STRONG",{});var I8t=s(she);Rpo=r(I8t,"perceiver"),I8t.forEach(t),Ppo=r(iqe," \u2014 "),ij=n(iqe,"A",{href:!0});var N8t=s(ij);Bpo=r(N8t,"PerceiverConfig"),N8t.forEach(t),Ipo=r(iqe," (Perceiver model)"),iqe.forEach(t),Npo=i(L),Lh=n(L,"LI",{});var dqe=s(Lh);lhe=n(dqe,"STRONG",{});var q8t=s(lhe);qpo=r(q8t,"plbart"),q8t.forEach(t),jpo=r(dqe," \u2014 "),dj=n(dqe,"A",{href:!0});var j8t=s(dj);Dpo=r(j8t,"PLBartConfig"),j8t.forEach(t),Gpo=r(dqe," (PLBart model)"),dqe.forEach(t),Opo=i(L),yh=n(L,"LI",{});var mqe=s(yh);ihe=n(mqe,"STRONG",{});var D8t=s(ihe);Vpo=r(D8t,"poolformer"),D8t.forEach(t),Xpo=r(mqe," \u2014 "),mj=n(mqe,"A",{href:!0});var G8t=s(mj);zpo=r(G8t,"PoolFormerConfig"),G8t.forEach(t),Qpo=r(mqe," (PoolFormer model)"),mqe.forEach(t),Wpo=i(L),xh=n(L,"LI",{});var cqe=s(xh);dhe=n(cqe,"STRONG",{});var O8t=s(dhe);Upo=r(O8t,"prophetnet"),O8t.forEach(t),Hpo=r(cqe," \u2014 "),cj=n(cqe,"A",{href:!0});var V8t=s(cj);Jpo=r(V8t,"ProphetNetConfig"),V8t.forEach(t),Ypo=r(cqe," (ProphetNet model)"),cqe.forEach(t),Zpo=i(L),$h=n(L,"LI",{});var fqe=s($h);mhe=n(fqe,"STRONG",{});var X8t=s(mhe);Kpo=r(X8t,"qdqbert"),X8t.forEach(t),e_o=r(fqe," \u2014 "),fj=n(fqe,"A",{href:!0});var z8t=s(fj);o_o=r(z8t,"QDQBertConfig"),z8t.forEach(t),r_o=r(fqe," (QDQBert model)"),fqe.forEach(t),t_o=i(L),kh=n(L,"LI",{});var gqe=s(kh);che=n(gqe,"STRONG",{});var Q8t=s(che);a_o=r(Q8t,"rag"),Q8t.forEach(t),n_o=r(gqe," \u2014 "),gj=n(gqe,"A",{href:!0});var W8t=s(gj);s_o=r(W8t,"RagConfig"),W8t.forEach(t),l_o=r(gqe," (RAG model)"),gqe.forEach(t),i_o=i(L),Sh=n(L,"LI",{});var hqe=s(Sh);fhe=n(hqe,"STRONG",{});var U8t=s(fhe);d_o=r(U8t,"realm"),U8t.forEach(t),m_o=r(hqe," \u2014 "),hj=n(hqe,"A",{href:!0});var H8t=s(hj);c_o=r(H8t,"RealmConfig"),H8t.forEach(t),f_o=r(hqe," (REALM model)"),hqe.forEach(t),g_o=i(L),Rh=n(L,"LI",{});var uqe=s(Rh);ghe=n(uqe,"STRONG",{});var J8t=s(ghe);h_o=r(J8t,"reformer"),J8t.forEach(t),u_o=r(uqe," \u2014 "),uj=n(uqe,"A",{href:!0});var Y8t=s(uj);p_o=r(Y8t,"ReformerConfig"),Y8t.forEach(t),__o=r(uqe," (Reformer model)"),uqe.forEach(t),b_o=i(L),Ph=n(L,"LI",{});var pqe=s(Ph);hhe=n(pqe,"STRONG",{});var Z8t=s(hhe);v_o=r(Z8t,"regnet"),Z8t.forEach(t),F_o=r(pqe," \u2014 "),pj=n(pqe,"A",{href:!0});var K8t=s(pj);T_o=r(K8t,"RegNetConfig"),K8t.forEach(t),M_o=r(pqe," (RegNet model)"),pqe.forEach(t),E_o=i(L),Bh=n(L,"LI",{});var _qe=s(Bh);uhe=n(_qe,"STRONG",{});var eLt=s(uhe);C_o=r(eLt,"rembert"),eLt.forEach(t),w_o=r(_qe," \u2014 "),_j=n(_qe,"A",{href:!0});var oLt=s(_j);A_o=r(oLt,"RemBertConfig"),oLt.forEach(t),L_o=r(_qe," (RemBERT model)"),_qe.forEach(t),y_o=i(L),Ih=n(L,"LI",{});var bqe=s(Ih);phe=n(bqe,"STRONG",{});var rLt=s(phe);x_o=r(rLt,"resnet"),rLt.forEach(t),$_o=r(bqe," \u2014 "),bj=n(bqe,"A",{href:!0});var tLt=s(bj);k_o=r(tLt,"ResNetConfig"),tLt.forEach(t),S_o=r(bqe," (ResNet model)"),bqe.forEach(t),R_o=i(L),Nh=n(L,"LI",{});var vqe=s(Nh);_he=n(vqe,"STRONG",{});var aLt=s(_he);P_o=r(aLt,"retribert"),aLt.forEach(t),B_o=r(vqe," \u2014 "),vj=n(vqe,"A",{href:!0});var nLt=s(vj);I_o=r(nLt,"RetriBertConfig"),nLt.forEach(t),N_o=r(vqe," (RetriBERT model)"),vqe.forEach(t),q_o=i(L),qh=n(L,"LI",{});var Fqe=s(qh);bhe=n(Fqe,"STRONG",{});var sLt=s(bhe);j_o=r(sLt,"roberta"),sLt.forEach(t),D_o=r(Fqe," \u2014 "),Fj=n(Fqe,"A",{href:!0});var lLt=s(Fj);G_o=r(lLt,"RobertaConfig"),lLt.forEach(t),O_o=r(Fqe," (RoBERTa model)"),Fqe.forEach(t),V_o=i(L),jh=n(L,"LI",{});var Tqe=s(jh);vhe=n(Tqe,"STRONG",{});var iLt=s(vhe);X_o=r(iLt,"roformer"),iLt.forEach(t),z_o=r(Tqe," \u2014 "),Tj=n(Tqe,"A",{href:!0});var dLt=s(Tj);Q_o=r(dLt,"RoFormerConfig"),dLt.forEach(t),W_o=r(Tqe," (RoFormer model)"),Tqe.forEach(t),U_o=i(L),Dh=n(L,"LI",{});var Mqe=s(Dh);Fhe=n(Mqe,"STRONG",{});var mLt=s(Fhe);H_o=r(mLt,"segformer"),mLt.forEach(t),J_o=r(Mqe," \u2014 "),Mj=n(Mqe,"A",{href:!0});var cLt=s(Mj);Y_o=r(cLt,"SegformerConfig"),cLt.forEach(t),Z_o=r(Mqe," (SegFormer model)"),Mqe.forEach(t),K_o=i(L),Gh=n(L,"LI",{});var Eqe=s(Gh);The=n(Eqe,"STRONG",{});var fLt=s(The);e1o=r(fLt,"sew"),fLt.forEach(t),o1o=r(Eqe," \u2014 "),Ej=n(Eqe,"A",{href:!0});var gLt=s(Ej);r1o=r(gLt,"SEWConfig"),gLt.forEach(t),t1o=r(Eqe," (SEW model)"),Eqe.forEach(t),a1o=i(L),Oh=n(L,"LI",{});var Cqe=s(Oh);Mhe=n(Cqe,"STRONG",{});var hLt=s(Mhe);n1o=r(hLt,"sew-d"),hLt.forEach(t),s1o=r(Cqe," \u2014 "),Cj=n(Cqe,"A",{href:!0});var uLt=s(Cj);l1o=r(uLt,"SEWDConfig"),uLt.forEach(t),i1o=r(Cqe," (SEW-D model)"),Cqe.forEach(t),d1o=i(L),Vh=n(L,"LI",{});var wqe=s(Vh);Ehe=n(wqe,"STRONG",{});var pLt=s(Ehe);m1o=r(pLt,"speech-encoder-decoder"),pLt.forEach(t),c1o=r(wqe," \u2014 "),wj=n(wqe,"A",{href:!0});var _Lt=s(wj);f1o=r(_Lt,"SpeechEncoderDecoderConfig"),_Lt.forEach(t),g1o=r(wqe," (Speech Encoder decoder model)"),wqe.forEach(t),h1o=i(L),Xh=n(L,"LI",{});var Aqe=s(Xh);Che=n(Aqe,"STRONG",{});var bLt=s(Che);u1o=r(bLt,"speech_to_text"),bLt.forEach(t),p1o=r(Aqe," \u2014 "),Aj=n(Aqe,"A",{href:!0});var vLt=s(Aj);_1o=r(vLt,"Speech2TextConfig"),vLt.forEach(t),b1o=r(Aqe," (Speech2Text model)"),Aqe.forEach(t),v1o=i(L),zh=n(L,"LI",{});var Lqe=s(zh);whe=n(Lqe,"STRONG",{});var FLt=s(whe);F1o=r(FLt,"speech_to_text_2"),FLt.forEach(t),T1o=r(Lqe," \u2014 "),Lj=n(Lqe,"A",{href:!0});var TLt=s(Lj);M1o=r(TLt,"Speech2Text2Config"),TLt.forEach(t),E1o=r(Lqe," (Speech2Text2 model)"),Lqe.forEach(t),C1o=i(L),Qh=n(L,"LI",{});var yqe=s(Qh);Ahe=n(yqe,"STRONG",{});var MLt=s(Ahe);w1o=r(MLt,"splinter"),MLt.forEach(t),A1o=r(yqe," \u2014 "),yj=n(yqe,"A",{href:!0});var ELt=s(yj);L1o=r(ELt,"SplinterConfig"),ELt.forEach(t),y1o=r(yqe," (Splinter model)"),yqe.forEach(t),x1o=i(L),Wh=n(L,"LI",{});var xqe=s(Wh);Lhe=n(xqe,"STRONG",{});var CLt=s(Lhe);$1o=r(CLt,"squeezebert"),CLt.forEach(t),k1o=r(xqe," \u2014 "),xj=n(xqe,"A",{href:!0});var wLt=s(xj);S1o=r(wLt,"SqueezeBertConfig"),wLt.forEach(t),R1o=r(xqe," (SqueezeBERT model)"),xqe.forEach(t),P1o=i(L),Uh=n(L,"LI",{});var $qe=s(Uh);yhe=n($qe,"STRONG",{});var ALt=s(yhe);B1o=r(ALt,"swin"),ALt.forEach(t),I1o=r($qe," \u2014 "),$j=n($qe,"A",{href:!0});var LLt=s($j);N1o=r(LLt,"SwinConfig"),LLt.forEach(t),q1o=r($qe," (Swin Transformer model)"),$qe.forEach(t),j1o=i(L),Hh=n(L,"LI",{});var kqe=s(Hh);xhe=n(kqe,"STRONG",{});var yLt=s(xhe);D1o=r(yLt,"swinv2"),yLt.forEach(t),G1o=r(kqe," \u2014 "),kj=n(kqe,"A",{href:!0});var xLt=s(kj);O1o=r(xLt,"Swinv2Config"),xLt.forEach(t),V1o=r(kqe," (Swin Transformer V2 model)"),kqe.forEach(t),X1o=i(L),Jh=n(L,"LI",{});var Sqe=s(Jh);$he=n(Sqe,"STRONG",{});var $Lt=s($he);z1o=r($Lt,"t5"),$Lt.forEach(t),Q1o=r(Sqe," \u2014 "),Sj=n(Sqe,"A",{href:!0});var kLt=s(Sj);W1o=r(kLt,"T5Config"),kLt.forEach(t),U1o=r(Sqe," (T5 model)"),Sqe.forEach(t),H1o=i(L),Yh=n(L,"LI",{});var Rqe=s(Yh);khe=n(Rqe,"STRONG",{});var SLt=s(khe);J1o=r(SLt,"table-transformer"),SLt.forEach(t),Y1o=r(Rqe," \u2014 "),Rj=n(Rqe,"A",{href:!0});var RLt=s(Rj);Z1o=r(RLt,"TableTransformerConfig"),RLt.forEach(t),K1o=r(Rqe," (Table Transformer model)"),Rqe.forEach(t),e2o=i(L),Zh=n(L,"LI",{});var Pqe=s(Zh);She=n(Pqe,"STRONG",{});var PLt=s(She);o2o=r(PLt,"tapas"),PLt.forEach(t),r2o=r(Pqe," \u2014 "),Pj=n(Pqe,"A",{href:!0});var BLt=s(Pj);t2o=r(BLt,"TapasConfig"),BLt.forEach(t),a2o=r(Pqe," (TAPAS model)"),Pqe.forEach(t),n2o=i(L),Kh=n(L,"LI",{});var Bqe=s(Kh);Rhe=n(Bqe,"STRONG",{});var ILt=s(Rhe);s2o=r(ILt,"time_series_transformer"),ILt.forEach(t),l2o=r(Bqe," \u2014 "),Bj=n(Bqe,"A",{href:!0});var NLt=s(Bj);i2o=r(NLt,"TimeSeriesTransformerConfig"),NLt.forEach(t),d2o=r(Bqe," (Time Series Transformer model)"),Bqe.forEach(t),m2o=i(L),eu=n(L,"LI",{});var Iqe=s(eu);Phe=n(Iqe,"STRONG",{});var qLt=s(Phe);c2o=r(qLt,"trajectory_transformer"),qLt.forEach(t),f2o=r(Iqe," \u2014 "),Ij=n(Iqe,"A",{href:!0});var jLt=s(Ij);g2o=r(jLt,"TrajectoryTransformerConfig"),jLt.forEach(t),h2o=r(Iqe," (Trajectory Transformer model)"),Iqe.forEach(t),u2o=i(L),ou=n(L,"LI",{});var Nqe=s(ou);Bhe=n(Nqe,"STRONG",{});var DLt=s(Bhe);p2o=r(DLt,"transfo-xl"),DLt.forEach(t),_2o=r(Nqe," \u2014 "),Nj=n(Nqe,"A",{href:!0});var GLt=s(Nj);b2o=r(GLt,"TransfoXLConfig"),GLt.forEach(t),v2o=r(Nqe," (Transformer-XL model)"),Nqe.forEach(t),F2o=i(L),ru=n(L,"LI",{});var qqe=s(ru);Ihe=n(qqe,"STRONG",{});var OLt=s(Ihe);T2o=r(OLt,"trocr"),OLt.forEach(t),M2o=r(qqe," \u2014 "),qj=n(qqe,"A",{href:!0});var VLt=s(qj);E2o=r(VLt,"TrOCRConfig"),VLt.forEach(t),C2o=r(qqe," (TrOCR model)"),qqe.forEach(t),w2o=i(L),tu=n(L,"LI",{});var jqe=s(tu);Nhe=n(jqe,"STRONG",{});var XLt=s(Nhe);A2o=r(XLt,"unispeech"),XLt.forEach(t),L2o=r(jqe," \u2014 "),jj=n(jqe,"A",{href:!0});var zLt=s(jj);y2o=r(zLt,"UniSpeechConfig"),zLt.forEach(t),x2o=r(jqe," (UniSpeech model)"),jqe.forEach(t),$2o=i(L),au=n(L,"LI",{});var Dqe=s(au);qhe=n(Dqe,"STRONG",{});var QLt=s(qhe);k2o=r(QLt,"unispeech-sat"),QLt.forEach(t),S2o=r(Dqe," \u2014 "),Dj=n(Dqe,"A",{href:!0});var WLt=s(Dj);R2o=r(WLt,"UniSpeechSatConfig"),WLt.forEach(t),P2o=r(Dqe," (UniSpeechSat model)"),Dqe.forEach(t),B2o=i(L),nu=n(L,"LI",{});var Gqe=s(nu);jhe=n(Gqe,"STRONG",{});var ULt=s(jhe);I2o=r(ULt,"van"),ULt.forEach(t),N2o=r(Gqe," \u2014 "),Gj=n(Gqe,"A",{href:!0});var HLt=s(Gj);q2o=r(HLt,"VanConfig"),HLt.forEach(t),j2o=r(Gqe," (VAN model)"),Gqe.forEach(t),D2o=i(L),su=n(L,"LI",{});var Oqe=s(su);Dhe=n(Oqe,"STRONG",{});var JLt=s(Dhe);G2o=r(JLt,"videomae"),JLt.forEach(t),O2o=r(Oqe," \u2014 "),Oj=n(Oqe,"A",{href:!0});var YLt=s(Oj);V2o=r(YLt,"VideoMAEConfig"),YLt.forEach(t),X2o=r(Oqe," (VideoMAE model)"),Oqe.forEach(t),z2o=i(L),lu=n(L,"LI",{});var Vqe=s(lu);Ghe=n(Vqe,"STRONG",{});var ZLt=s(Ghe);Q2o=r(ZLt,"vilt"),ZLt.forEach(t),W2o=r(Vqe," \u2014 "),Vj=n(Vqe,"A",{href:!0});var KLt=s(Vj);U2o=r(KLt,"ViltConfig"),KLt.forEach(t),H2o=r(Vqe," (ViLT model)"),Vqe.forEach(t),J2o=i(L),iu=n(L,"LI",{});var Xqe=s(iu);Ohe=n(Xqe,"STRONG",{});var eyt=s(Ohe);Y2o=r(eyt,"vision-encoder-decoder"),eyt.forEach(t),Z2o=r(Xqe," \u2014 "),Xj=n(Xqe,"A",{href:!0});var oyt=s(Xj);K2o=r(oyt,"VisionEncoderDecoderConfig"),oyt.forEach(t),ebo=r(Xqe," (Vision Encoder decoder model)"),Xqe.forEach(t),obo=i(L),du=n(L,"LI",{});var zqe=s(du);Vhe=n(zqe,"STRONG",{});var ryt=s(Vhe);rbo=r(ryt,"vision-text-dual-encoder"),ryt.forEach(t),tbo=r(zqe," \u2014 "),zj=n(zqe,"A",{href:!0});var tyt=s(zj);abo=r(tyt,"VisionTextDualEncoderConfig"),tyt.forEach(t),nbo=r(zqe," (VisionTextDualEncoder model)"),zqe.forEach(t),sbo=i(L),mu=n(L,"LI",{});var Qqe=s(mu);Xhe=n(Qqe,"STRONG",{});var ayt=s(Xhe);lbo=r(ayt,"visual_bert"),ayt.forEach(t),ibo=r(Qqe," \u2014 "),Qj=n(Qqe,"A",{href:!0});var nyt=s(Qj);dbo=r(nyt,"VisualBertConfig"),nyt.forEach(t),mbo=r(Qqe," (VisualBERT model)"),Qqe.forEach(t),cbo=i(L),cu=n(L,"LI",{});var Wqe=s(cu);zhe=n(Wqe,"STRONG",{});var syt=s(zhe);fbo=r(syt,"vit"),syt.forEach(t),gbo=r(Wqe," \u2014 "),Wj=n(Wqe,"A",{href:!0});var lyt=s(Wj);hbo=r(lyt,"ViTConfig"),lyt.forEach(t),ubo=r(Wqe," (ViT model)"),Wqe.forEach(t),pbo=i(L),fu=n(L,"LI",{});var Uqe=s(fu);Qhe=n(Uqe,"STRONG",{});var iyt=s(Qhe);_bo=r(iyt,"vit_mae"),iyt.forEach(t),bbo=r(Uqe," \u2014 "),Uj=n(Uqe,"A",{href:!0});var dyt=s(Uj);vbo=r(dyt,"ViTMAEConfig"),dyt.forEach(t),Fbo=r(Uqe," (ViTMAE model)"),Uqe.forEach(t),Tbo=i(L),gu=n(L,"LI",{});var Hqe=s(gu);Whe=n(Hqe,"STRONG",{});var myt=s(Whe);Mbo=r(myt,"vit_msn"),myt.forEach(t),Ebo=r(Hqe," \u2014 "),Hj=n(Hqe,"A",{href:!0});var cyt=s(Hj);Cbo=r(cyt,"ViTMSNConfig"),cyt.forEach(t),wbo=r(Hqe," (ViTMSN model)"),Hqe.forEach(t),Abo=i(L),hu=n(L,"LI",{});var Jqe=s(hu);Uhe=n(Jqe,"STRONG",{});var fyt=s(Uhe);Lbo=r(fyt,"wav2vec2"),fyt.forEach(t),ybo=r(Jqe," \u2014 "),Jj=n(Jqe,"A",{href:!0});var gyt=s(Jj);xbo=r(gyt,"Wav2Vec2Config"),gyt.forEach(t),$bo=r(Jqe," (Wav2Vec2 model)"),Jqe.forEach(t),kbo=i(L),uu=n(L,"LI",{});var Yqe=s(uu);Hhe=n(Yqe,"STRONG",{});var hyt=s(Hhe);Sbo=r(hyt,"wav2vec2-conformer"),hyt.forEach(t),Rbo=r(Yqe," \u2014 "),Yj=n(Yqe,"A",{href:!0});var uyt=s(Yj);Pbo=r(uyt,"Wav2Vec2ConformerConfig"),uyt.forEach(t),Bbo=r(Yqe," (Wav2Vec2-Conformer model)"),Yqe.forEach(t),Ibo=i(L),pu=n(L,"LI",{});var Zqe=s(pu);Jhe=n(Zqe,"STRONG",{});var pyt=s(Jhe);Nbo=r(pyt,"wavlm"),pyt.forEach(t),qbo=r(Zqe," \u2014 "),Zj=n(Zqe,"A",{href:!0});var _yt=s(Zj);jbo=r(_yt,"WavLMConfig"),_yt.forEach(t),Dbo=r(Zqe," (WavLM model)"),Zqe.forEach(t),Gbo=i(L),_u=n(L,"LI",{});var Kqe=s(_u);Yhe=n(Kqe,"STRONG",{});var byt=s(Yhe);Obo=r(byt,"whisper"),byt.forEach(t),Vbo=r(Kqe," \u2014 "),Kj=n(Kqe,"A",{href:!0});var vyt=s(Kj);Xbo=r(vyt,"WhisperConfig"),vyt.forEach(t),zbo=r(Kqe," (Whisper model)"),Kqe.forEach(t),Qbo=i(L),bu=n(L,"LI",{});var eje=s(bu);Zhe=n(eje,"STRONG",{});var Fyt=s(Zhe);Wbo=r(Fyt,"xclip"),Fyt.forEach(t),Ubo=r(eje," \u2014 "),eD=n(eje,"A",{href:!0});var Tyt=s(eD);Hbo=r(Tyt,"XCLIPConfig"),Tyt.forEach(t),Jbo=r(eje," (X-CLIP model)"),eje.forEach(t),Ybo=i(L),vu=n(L,"LI",{});var oje=s(vu);Khe=n(oje,"STRONG",{});var Myt=s(Khe);Zbo=r(Myt,"xglm"),Myt.forEach(t),Kbo=r(oje," \u2014 "),oD=n(oje,"A",{href:!0});var Eyt=s(oD);evo=r(Eyt,"XGLMConfig"),Eyt.forEach(t),ovo=r(oje," (XGLM model)"),oje.forEach(t),rvo=i(L),Fu=n(L,"LI",{});var rje=s(Fu);eue=n(rje,"STRONG",{});var Cyt=s(eue);tvo=r(Cyt,"xlm"),Cyt.forEach(t),avo=r(rje," \u2014 "),rD=n(rje,"A",{href:!0});var wyt=s(rD);nvo=r(wyt,"XLMConfig"),wyt.forEach(t),svo=r(rje," (XLM model)"),rje.forEach(t),lvo=i(L),Tu=n(L,"LI",{});var tje=s(Tu);oue=n(tje,"STRONG",{});var Ayt=s(oue);ivo=r(Ayt,"xlm-prophetnet"),Ayt.forEach(t),dvo=r(tje," \u2014 "),tD=n(tje,"A",{href:!0});var Lyt=s(tD);mvo=r(Lyt,"XLMProphetNetConfig"),Lyt.forEach(t),cvo=r(tje," (XLM-ProphetNet model)"),tje.forEach(t),fvo=i(L),Mu=n(L,"LI",{});var aje=s(Mu);rue=n(aje,"STRONG",{});var yyt=s(rue);gvo=r(yyt,"xlm-roberta"),yyt.forEach(t),hvo=r(aje," \u2014 "),aD=n(aje,"A",{href:!0});var xyt=s(aD);uvo=r(xyt,"XLMRobertaConfig"),xyt.forEach(t),pvo=r(aje," (XLM-RoBERTa model)"),aje.forEach(t),_vo=i(L),Eu=n(L,"LI",{});var nje=s(Eu);tue=n(nje,"STRONG",{});var $yt=s(tue);bvo=r($yt,"xlm-roberta-xl"),$yt.forEach(t),vvo=r(nje," \u2014 "),nD=n(nje,"A",{href:!0});var kyt=s(nD);Fvo=r(kyt,"XLMRobertaXLConfig"),kyt.forEach(t),Tvo=r(nje," (XLM-RoBERTa-XL model)"),nje.forEach(t),Mvo=i(L),Cu=n(L,"LI",{});var sje=s(Cu);aue=n(sje,"STRONG",{});var Syt=s(aue);Evo=r(Syt,"xlnet"),Syt.forEach(t),Cvo=r(sje," \u2014 "),sD=n(sje,"A",{href:!0});var Ryt=s(sD);wvo=r(Ryt,"XLNetConfig"),Ryt.forEach(t),Avo=r(sje," (XLNet model)"),sje.forEach(t),Lvo=i(L),wu=n(L,"LI",{});var lje=s(wu);nue=n(lje,"STRONG",{});var Pyt=s(nue);yvo=r(Pyt,"yolos"),Pyt.forEach(t),xvo=r(lje," \u2014 "),lD=n(lje,"A",{href:!0});var Byt=s(lD);$vo=r(Byt,"YolosConfig"),Byt.forEach(t),kvo=r(lje," (YOLOS model)"),lje.forEach(t),Svo=i(L),Au=n(L,"LI",{});var ije=s(Au);sue=n(ije,"STRONG",{});var Iyt=s(sue);Rvo=r(Iyt,"yoso"),Iyt.forEach(t),Pvo=r(ije," \u2014 "),iD=n(ije,"A",{href:!0});var Nyt=s(iD);Bvo=r(Nyt,"YosoConfig"),Nyt.forEach(t),Ivo=r(ije," (YOSO model)"),ije.forEach(t),L.forEach(t),Nvo=i(Ft),T(Lu.$$.fragment,Ft),Ft.forEach(t),qvo=i(vt),yu=n(vt,"DIV",{class:!0});var mso=s(yu);T(T$.$$.fragment,mso),jvo=i(mso),lue=n(mso,"P",{});var qyt=s(lue);Dvo=r(qyt,"Register a new configuration for this class."),qyt.forEach(t),mso.forEach(t),vt.forEach(t),Kto=i(c),xd=n(c,"H2",{class:!0});var cso=s(xd);xu=n(cso,"A",{id:!0,class:!0,href:!0});var jyt=s(xu);iue=n(jyt,"SPAN",{});var Dyt=s(iue);T(M$.$$.fragment,Dyt),Dyt.forEach(t),jyt.forEach(t),Gvo=i(cso),due=n(cso,"SPAN",{});var Gyt=s(due);Ovo=r(Gyt,"AutoTokenizer"),Gyt.forEach(t),cso.forEach(t),eao=i(c),Ro=n(c,"DIV",{class:!0});var Bl=s(Ro);T(E$.$$.fragment,Bl),Vvo=i(Bl),C$=n(Bl,"P",{});var fso=s(C$);Xvo=r(fso,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),dD=n(fso,"A",{href:!0});var Oyt=s(dD);zvo=r(Oyt,"AutoTokenizer.from_pretrained()"),Oyt.forEach(t),Qvo=r(fso," class method."),fso.forEach(t),Wvo=i(Bl),w$=n(Bl,"P",{});var gso=s(w$);Uvo=r(gso,"This class cannot be instantiated directly using "),mue=n(gso,"CODE",{});var Vyt=s(mue);Hvo=r(Vyt,"__init__()"),Vyt.forEach(t),Jvo=r(gso," (throws an error)."),gso.forEach(t),Yvo=i(Bl),jr=n(Bl,"DIV",{class:!0});var Il=s(jr);T(A$.$$.fragment,Il),Zvo=i(Il),cue=n(Il,"P",{});var Xyt=s(cue);Kvo=r(Xyt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Xyt.forEach(t),eFo=i(Il),tn=n(Il,"P",{});var t9=s(tn);oFo=r(t9,"The tokenizer class to instantiate is selected based on the "),fue=n(t9,"CODE",{});var zyt=s(fue);rFo=r(zyt,"model_type"),zyt.forEach(t),tFo=r(t9,` property of the config object (either
passed as an argument or loaded from `),gue=n(t9,"CODE",{});var Qyt=s(gue);aFo=r(Qyt,"pretrained_model_name_or_path"),Qyt.forEach(t),nFo=r(t9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hue=n(t9,"CODE",{});var Wyt=s(hue);sFo=r(Wyt,"pretrained_model_name_or_path"),Wyt.forEach(t),lFo=r(t9,":"),t9.forEach(t),iFo=i(Il),k=n(Il,"UL",{});var S=s(k);us=n(S,"LI",{});var iI=s(us);uue=n(iI,"STRONG",{});var Uyt=s(uue);dFo=r(Uyt,"albert"),Uyt.forEach(t),mFo=r(iI," \u2014 "),mD=n(iI,"A",{href:!0});var Hyt=s(mD);cFo=r(Hyt,"AlbertTokenizer"),Hyt.forEach(t),fFo=r(iI," or "),cD=n(iI,"A",{href:!0});var Jyt=s(cD);gFo=r(Jyt,"AlbertTokenizerFast"),Jyt.forEach(t),hFo=r(iI," (ALBERT model)"),iI.forEach(t),uFo=i(S),ps=n(S,"LI",{});var dI=s(ps);pue=n(dI,"STRONG",{});var Yyt=s(pue);pFo=r(Yyt,"bart"),Yyt.forEach(t),_Fo=r(dI," \u2014 "),fD=n(dI,"A",{href:!0});var Zyt=s(fD);bFo=r(Zyt,"BartTokenizer"),Zyt.forEach(t),vFo=r(dI," or "),gD=n(dI,"A",{href:!0});var Kyt=s(gD);FFo=r(Kyt,"BartTokenizerFast"),Kyt.forEach(t),TFo=r(dI," (BART model)"),dI.forEach(t),MFo=i(S),_s=n(S,"LI",{});var mI=s(_s);_ue=n(mI,"STRONG",{});var e9t=s(_ue);EFo=r(e9t,"barthez"),e9t.forEach(t),CFo=r(mI," \u2014 "),hD=n(mI,"A",{href:!0});var o9t=s(hD);wFo=r(o9t,"BarthezTokenizer"),o9t.forEach(t),AFo=r(mI," or "),uD=n(mI,"A",{href:!0});var r9t=s(uD);LFo=r(r9t,"BarthezTokenizerFast"),r9t.forEach(t),yFo=r(mI," (BARThez model)"),mI.forEach(t),xFo=i(S),$u=n(S,"LI",{});var dje=s($u);bue=n(dje,"STRONG",{});var t9t=s(bue);$Fo=r(t9t,"bartpho"),t9t.forEach(t),kFo=r(dje," \u2014 "),pD=n(dje,"A",{href:!0});var a9t=s(pD);SFo=r(a9t,"BartphoTokenizer"),a9t.forEach(t),RFo=r(dje," (BARTpho model)"),dje.forEach(t),PFo=i(S),bs=n(S,"LI",{});var cI=s(bs);vue=n(cI,"STRONG",{});var n9t=s(vue);BFo=r(n9t,"bert"),n9t.forEach(t),IFo=r(cI," \u2014 "),_D=n(cI,"A",{href:!0});var s9t=s(_D);NFo=r(s9t,"BertTokenizer"),s9t.forEach(t),qFo=r(cI," or "),bD=n(cI,"A",{href:!0});var l9t=s(bD);jFo=r(l9t,"BertTokenizerFast"),l9t.forEach(t),DFo=r(cI," (BERT model)"),cI.forEach(t),GFo=i(S),ku=n(S,"LI",{});var mje=s(ku);Fue=n(mje,"STRONG",{});var i9t=s(Fue);OFo=r(i9t,"bert-generation"),i9t.forEach(t),VFo=r(mje," \u2014 "),vD=n(mje,"A",{href:!0});var d9t=s(vD);XFo=r(d9t,"BertGenerationTokenizer"),d9t.forEach(t),zFo=r(mje," (Bert Generation model)"),mje.forEach(t),QFo=i(S),Su=n(S,"LI",{});var cje=s(Su);Tue=n(cje,"STRONG",{});var m9t=s(Tue);WFo=r(m9t,"bert-japanese"),m9t.forEach(t),UFo=r(cje," \u2014 "),FD=n(cje,"A",{href:!0});var c9t=s(FD);HFo=r(c9t,"BertJapaneseTokenizer"),c9t.forEach(t),JFo=r(cje," (BertJapanese model)"),cje.forEach(t),YFo=i(S),Ru=n(S,"LI",{});var fje=s(Ru);Mue=n(fje,"STRONG",{});var f9t=s(Mue);ZFo=r(f9t,"bertweet"),f9t.forEach(t),KFo=r(fje," \u2014 "),TD=n(fje,"A",{href:!0});var g9t=s(TD);eTo=r(g9t,"BertweetTokenizer"),g9t.forEach(t),oTo=r(fje," (BERTweet model)"),fje.forEach(t),rTo=i(S),vs=n(S,"LI",{});var fI=s(vs);Eue=n(fI,"STRONG",{});var h9t=s(Eue);tTo=r(h9t,"big_bird"),h9t.forEach(t),aTo=r(fI," \u2014 "),MD=n(fI,"A",{href:!0});var u9t=s(MD);nTo=r(u9t,"BigBirdTokenizer"),u9t.forEach(t),sTo=r(fI," or "),ED=n(fI,"A",{href:!0});var p9t=s(ED);lTo=r(p9t,"BigBirdTokenizerFast"),p9t.forEach(t),iTo=r(fI," (BigBird model)"),fI.forEach(t),dTo=i(S),Fs=n(S,"LI",{});var gI=s(Fs);Cue=n(gI,"STRONG",{});var _9t=s(Cue);mTo=r(_9t,"bigbird_pegasus"),_9t.forEach(t),cTo=r(gI," \u2014 "),CD=n(gI,"A",{href:!0});var b9t=s(CD);fTo=r(b9t,"PegasusTokenizer"),b9t.forEach(t),gTo=r(gI," or "),wD=n(gI,"A",{href:!0});var v9t=s(wD);hTo=r(v9t,"PegasusTokenizerFast"),v9t.forEach(t),uTo=r(gI," (BigBird-Pegasus model)"),gI.forEach(t),pTo=i(S),Ts=n(S,"LI",{});var hI=s(Ts);wue=n(hI,"STRONG",{});var F9t=s(wue);_To=r(F9t,"blenderbot"),F9t.forEach(t),bTo=r(hI," \u2014 "),AD=n(hI,"A",{href:!0});var T9t=s(AD);vTo=r(T9t,"BlenderbotTokenizer"),T9t.forEach(t),FTo=r(hI," or "),LD=n(hI,"A",{href:!0});var M9t=s(LD);TTo=r(M9t,"BlenderbotTokenizerFast"),M9t.forEach(t),MTo=r(hI," (Blenderbot model)"),hI.forEach(t),ETo=i(S),Pu=n(S,"LI",{});var gje=s(Pu);Aue=n(gje,"STRONG",{});var E9t=s(Aue);CTo=r(E9t,"blenderbot-small"),E9t.forEach(t),wTo=r(gje," \u2014 "),yD=n(gje,"A",{href:!0});var C9t=s(yD);ATo=r(C9t,"BlenderbotSmallTokenizer"),C9t.forEach(t),LTo=r(gje," (BlenderbotSmall model)"),gje.forEach(t),yTo=i(S),Bu=n(S,"LI",{});var hje=s(Bu);Lue=n(hje,"STRONG",{});var w9t=s(Lue);xTo=r(w9t,"bloom"),w9t.forEach(t),$To=r(hje," \u2014 "),xD=n(hje,"A",{href:!0});var A9t=s(xD);kTo=r(A9t,"BloomTokenizerFast"),A9t.forEach(t),STo=r(hje," (BLOOM model)"),hje.forEach(t),RTo=i(S),Iu=n(S,"LI",{});var uje=s(Iu);yue=n(uje,"STRONG",{});var L9t=s(yue);PTo=r(L9t,"byt5"),L9t.forEach(t),BTo=r(uje," \u2014 "),$D=n(uje,"A",{href:!0});var y9t=s($D);ITo=r(y9t,"ByT5Tokenizer"),y9t.forEach(t),NTo=r(uje," (ByT5 model)"),uje.forEach(t),qTo=i(S),Ms=n(S,"LI",{});var uI=s(Ms);xue=n(uI,"STRONG",{});var x9t=s(xue);jTo=r(x9t,"camembert"),x9t.forEach(t),DTo=r(uI," \u2014 "),kD=n(uI,"A",{href:!0});var $9t=s(kD);GTo=r($9t,"CamembertTokenizer"),$9t.forEach(t),OTo=r(uI," or "),SD=n(uI,"A",{href:!0});var k9t=s(SD);VTo=r(k9t,"CamembertTokenizerFast"),k9t.forEach(t),XTo=r(uI," (CamemBERT model)"),uI.forEach(t),zTo=i(S),Nu=n(S,"LI",{});var pje=s(Nu);$ue=n(pje,"STRONG",{});var S9t=s($ue);QTo=r(S9t,"canine"),S9t.forEach(t),WTo=r(pje," \u2014 "),RD=n(pje,"A",{href:!0});var R9t=s(RD);UTo=r(R9t,"CanineTokenizer"),R9t.forEach(t),HTo=r(pje," (CANINE model)"),pje.forEach(t),JTo=i(S),Es=n(S,"LI",{});var pI=s(Es);kue=n(pI,"STRONG",{});var P9t=s(kue);YTo=r(P9t,"clip"),P9t.forEach(t),ZTo=r(pI," \u2014 "),PD=n(pI,"A",{href:!0});var B9t=s(PD);KTo=r(B9t,"CLIPTokenizer"),B9t.forEach(t),eMo=r(pI," or "),BD=n(pI,"A",{href:!0});var I9t=s(BD);oMo=r(I9t,"CLIPTokenizerFast"),I9t.forEach(t),rMo=r(pI," (CLIP model)"),pI.forEach(t),tMo=i(S),Cs=n(S,"LI",{});var _I=s(Cs);Sue=n(_I,"STRONG",{});var N9t=s(Sue);aMo=r(N9t,"clipseg"),N9t.forEach(t),nMo=r(_I," \u2014 "),ID=n(_I,"A",{href:!0});var q9t=s(ID);sMo=r(q9t,"CLIPTokenizer"),q9t.forEach(t),lMo=r(_I," or "),ND=n(_I,"A",{href:!0});var j9t=s(ND);iMo=r(j9t,"CLIPTokenizerFast"),j9t.forEach(t),dMo=r(_I," (CLIPSeg model)"),_I.forEach(t),mMo=i(S),ws=n(S,"LI",{});var bI=s(ws);Rue=n(bI,"STRONG",{});var D9t=s(Rue);cMo=r(D9t,"codegen"),D9t.forEach(t),fMo=r(bI," \u2014 "),qD=n(bI,"A",{href:!0});var G9t=s(qD);gMo=r(G9t,"CodeGenTokenizer"),G9t.forEach(t),hMo=r(bI," or "),jD=n(bI,"A",{href:!0});var O9t=s(jD);uMo=r(O9t,"CodeGenTokenizerFast"),O9t.forEach(t),pMo=r(bI," (CodeGen model)"),bI.forEach(t),_Mo=i(S),As=n(S,"LI",{});var vI=s(As);Pue=n(vI,"STRONG",{});var V9t=s(Pue);bMo=r(V9t,"convbert"),V9t.forEach(t),vMo=r(vI," \u2014 "),DD=n(vI,"A",{href:!0});var X9t=s(DD);FMo=r(X9t,"ConvBertTokenizer"),X9t.forEach(t),TMo=r(vI," or "),GD=n(vI,"A",{href:!0});var z9t=s(GD);MMo=r(z9t,"ConvBertTokenizerFast"),z9t.forEach(t),EMo=r(vI," (ConvBERT model)"),vI.forEach(t),CMo=i(S),Ls=n(S,"LI",{});var FI=s(Ls);Bue=n(FI,"STRONG",{});var Q9t=s(Bue);wMo=r(Q9t,"cpm"),Q9t.forEach(t),AMo=r(FI," \u2014 "),OD=n(FI,"A",{href:!0});var W9t=s(OD);LMo=r(W9t,"CpmTokenizer"),W9t.forEach(t),yMo=r(FI," or "),VD=n(FI,"A",{href:!0});var U9t=s(VD);xMo=r(U9t,"CpmTokenizerFast"),U9t.forEach(t),$Mo=r(FI," (CPM model)"),FI.forEach(t),kMo=i(S),qu=n(S,"LI",{});var _je=s(qu);Iue=n(_je,"STRONG",{});var H9t=s(Iue);SMo=r(H9t,"ctrl"),H9t.forEach(t),RMo=r(_je," \u2014 "),XD=n(_je,"A",{href:!0});var J9t=s(XD);PMo=r(J9t,"CTRLTokenizer"),J9t.forEach(t),BMo=r(_je," (CTRL model)"),_je.forEach(t),IMo=i(S),ys=n(S,"LI",{});var TI=s(ys);Nue=n(TI,"STRONG",{});var Y9t=s(Nue);NMo=r(Y9t,"data2vec-text"),Y9t.forEach(t),qMo=r(TI," \u2014 "),zD=n(TI,"A",{href:!0});var Z9t=s(zD);jMo=r(Z9t,"RobertaTokenizer"),Z9t.forEach(t),DMo=r(TI," or "),QD=n(TI,"A",{href:!0});var K9t=s(QD);GMo=r(K9t,"RobertaTokenizerFast"),K9t.forEach(t),OMo=r(TI," (Data2VecText model)"),TI.forEach(t),VMo=i(S),xs=n(S,"LI",{});var MI=s(xs);que=n(MI,"STRONG",{});var ext=s(que);XMo=r(ext,"deberta"),ext.forEach(t),zMo=r(MI," \u2014 "),WD=n(MI,"A",{href:!0});var oxt=s(WD);QMo=r(oxt,"DebertaTokenizer"),oxt.forEach(t),WMo=r(MI," or "),UD=n(MI,"A",{href:!0});var rxt=s(UD);UMo=r(rxt,"DebertaTokenizerFast"),rxt.forEach(t),HMo=r(MI," (DeBERTa model)"),MI.forEach(t),JMo=i(S),$s=n(S,"LI",{});var EI=s($s);jue=n(EI,"STRONG",{});var txt=s(jue);YMo=r(txt,"deberta-v2"),txt.forEach(t),ZMo=r(EI," \u2014 "),HD=n(EI,"A",{href:!0});var axt=s(HD);KMo=r(axt,"DebertaV2Tokenizer"),axt.forEach(t),eEo=r(EI," or "),JD=n(EI,"A",{href:!0});var nxt=s(JD);oEo=r(nxt,"DebertaV2TokenizerFast"),nxt.forEach(t),rEo=r(EI," (DeBERTa-v2 model)"),EI.forEach(t),tEo=i(S),ks=n(S,"LI",{});var CI=s(ks);Due=n(CI,"STRONG",{});var sxt=s(Due);aEo=r(sxt,"distilbert"),sxt.forEach(t),nEo=r(CI," \u2014 "),YD=n(CI,"A",{href:!0});var lxt=s(YD);sEo=r(lxt,"DistilBertTokenizer"),lxt.forEach(t),lEo=r(CI," or "),ZD=n(CI,"A",{href:!0});var ixt=s(ZD);iEo=r(ixt,"DistilBertTokenizerFast"),ixt.forEach(t),dEo=r(CI," (DistilBERT model)"),CI.forEach(t),mEo=i(S),Ss=n(S,"LI",{});var wI=s(Ss);Gue=n(wI,"STRONG",{});var dxt=s(Gue);cEo=r(dxt,"dpr"),dxt.forEach(t),fEo=r(wI," \u2014 "),KD=n(wI,"A",{href:!0});var mxt=s(KD);gEo=r(mxt,"DPRQuestionEncoderTokenizer"),mxt.forEach(t),hEo=r(wI," or "),eG=n(wI,"A",{href:!0});var cxt=s(eG);uEo=r(cxt,"DPRQuestionEncoderTokenizerFast"),cxt.forEach(t),pEo=r(wI," (DPR model)"),wI.forEach(t),_Eo=i(S),Rs=n(S,"LI",{});var AI=s(Rs);Oue=n(AI,"STRONG",{});var fxt=s(Oue);bEo=r(fxt,"electra"),fxt.forEach(t),vEo=r(AI," \u2014 "),oG=n(AI,"A",{href:!0});var gxt=s(oG);FEo=r(gxt,"ElectraTokenizer"),gxt.forEach(t),TEo=r(AI," or "),rG=n(AI,"A",{href:!0});var hxt=s(rG);MEo=r(hxt,"ElectraTokenizerFast"),hxt.forEach(t),EEo=r(AI," (ELECTRA model)"),AI.forEach(t),CEo=i(S),Ps=n(S,"LI",{});var LI=s(Ps);Vue=n(LI,"STRONG",{});var uxt=s(Vue);wEo=r(uxt,"ernie"),uxt.forEach(t),AEo=r(LI," \u2014 "),tG=n(LI,"A",{href:!0});var pxt=s(tG);LEo=r(pxt,"BertTokenizer"),pxt.forEach(t),yEo=r(LI," or "),aG=n(LI,"A",{href:!0});var _xt=s(aG);xEo=r(_xt,"BertTokenizerFast"),_xt.forEach(t),$Eo=r(LI," (ERNIE model)"),LI.forEach(t),kEo=i(S),ju=n(S,"LI",{});var bje=s(ju);Xue=n(bje,"STRONG",{});var bxt=s(Xue);SEo=r(bxt,"esm"),bxt.forEach(t),REo=r(bje," \u2014 "),nG=n(bje,"A",{href:!0});var vxt=s(nG);PEo=r(vxt,"EsmTokenizer"),vxt.forEach(t),BEo=r(bje," (ESM model)"),bje.forEach(t),IEo=i(S),Du=n(S,"LI",{});var vje=s(Du);zue=n(vje,"STRONG",{});var Fxt=s(zue);NEo=r(Fxt,"flaubert"),Fxt.forEach(t),qEo=r(vje," \u2014 "),sG=n(vje,"A",{href:!0});var Txt=s(sG);jEo=r(Txt,"FlaubertTokenizer"),Txt.forEach(t),DEo=r(vje," (FlauBERT model)"),vje.forEach(t),GEo=i(S),Bs=n(S,"LI",{});var yI=s(Bs);Que=n(yI,"STRONG",{});var Mxt=s(Que);OEo=r(Mxt,"fnet"),Mxt.forEach(t),VEo=r(yI," \u2014 "),lG=n(yI,"A",{href:!0});var Ext=s(lG);XEo=r(Ext,"FNetTokenizer"),Ext.forEach(t),zEo=r(yI," or "),iG=n(yI,"A",{href:!0});var Cxt=s(iG);QEo=r(Cxt,"FNetTokenizerFast"),Cxt.forEach(t),WEo=r(yI," (FNet model)"),yI.forEach(t),UEo=i(S),Gu=n(S,"LI",{});var Fje=s(Gu);Wue=n(Fje,"STRONG",{});var wxt=s(Wue);HEo=r(wxt,"fsmt"),wxt.forEach(t),JEo=r(Fje," \u2014 "),dG=n(Fje,"A",{href:!0});var Axt=s(dG);YEo=r(Axt,"FSMTTokenizer"),Axt.forEach(t),ZEo=r(Fje," (FairSeq Machine-Translation model)"),Fje.forEach(t),KEo=i(S),Is=n(S,"LI",{});var xI=s(Is);Uue=n(xI,"STRONG",{});var Lxt=s(Uue);e4o=r(Lxt,"funnel"),Lxt.forEach(t),o4o=r(xI," \u2014 "),mG=n(xI,"A",{href:!0});var yxt=s(mG);r4o=r(yxt,"FunnelTokenizer"),yxt.forEach(t),t4o=r(xI," or "),cG=n(xI,"A",{href:!0});var xxt=s(cG);a4o=r(xxt,"FunnelTokenizerFast"),xxt.forEach(t),n4o=r(xI," (Funnel Transformer model)"),xI.forEach(t),s4o=i(S),Ns=n(S,"LI",{});var $I=s(Ns);Hue=n($I,"STRONG",{});var $xt=s(Hue);l4o=r($xt,"gpt2"),$xt.forEach(t),i4o=r($I," \u2014 "),fG=n($I,"A",{href:!0});var kxt=s(fG);d4o=r(kxt,"GPT2Tokenizer"),kxt.forEach(t),m4o=r($I," or "),gG=n($I,"A",{href:!0});var Sxt=s(gG);c4o=r(Sxt,"GPT2TokenizerFast"),Sxt.forEach(t),f4o=r($I," (OpenAI GPT-2 model)"),$I.forEach(t),g4o=i(S),qs=n(S,"LI",{});var kI=s(qs);Jue=n(kI,"STRONG",{});var Rxt=s(Jue);h4o=r(Rxt,"gpt_neo"),Rxt.forEach(t),u4o=r(kI," \u2014 "),hG=n(kI,"A",{href:!0});var Pxt=s(hG);p4o=r(Pxt,"GPT2Tokenizer"),Pxt.forEach(t),_4o=r(kI," or "),uG=n(kI,"A",{href:!0});var Bxt=s(uG);b4o=r(Bxt,"GPT2TokenizerFast"),Bxt.forEach(t),v4o=r(kI," (GPT Neo model)"),kI.forEach(t),F4o=i(S),Ou=n(S,"LI",{});var Tje=s(Ou);Yue=n(Tje,"STRONG",{});var Ixt=s(Yue);T4o=r(Ixt,"gpt_neox"),Ixt.forEach(t),M4o=r(Tje," \u2014 "),pG=n(Tje,"A",{href:!0});var Nxt=s(pG);E4o=r(Nxt,"GPTNeoXTokenizerFast"),Nxt.forEach(t),C4o=r(Tje," (GPT NeoX model)"),Tje.forEach(t),w4o=i(S),Vu=n(S,"LI",{});var Mje=s(Vu);Zue=n(Mje,"STRONG",{});var qxt=s(Zue);A4o=r(qxt,"gpt_neox_japanese"),qxt.forEach(t),L4o=r(Mje," \u2014 "),_G=n(Mje,"A",{href:!0});var jxt=s(_G);y4o=r(jxt,"GPTNeoXJapaneseTokenizer"),jxt.forEach(t),x4o=r(Mje," (GPT NeoX Japanese model)"),Mje.forEach(t),$4o=i(S),js=n(S,"LI",{});var SI=s(js);Kue=n(SI,"STRONG",{});var Dxt=s(Kue);k4o=r(Dxt,"gptj"),Dxt.forEach(t),S4o=r(SI," \u2014 "),bG=n(SI,"A",{href:!0});var Gxt=s(bG);R4o=r(Gxt,"GPT2Tokenizer"),Gxt.forEach(t),P4o=r(SI," or "),vG=n(SI,"A",{href:!0});var Oxt=s(vG);B4o=r(Oxt,"GPT2TokenizerFast"),Oxt.forEach(t),I4o=r(SI," (GPT-J model)"),SI.forEach(t),N4o=i(S),Ds=n(S,"LI",{});var RI=s(Ds);epe=n(RI,"STRONG",{});var Vxt=s(epe);q4o=r(Vxt,"groupvit"),Vxt.forEach(t),j4o=r(RI," \u2014 "),FG=n(RI,"A",{href:!0});var Xxt=s(FG);D4o=r(Xxt,"CLIPTokenizer"),Xxt.forEach(t),G4o=r(RI," or "),TG=n(RI,"A",{href:!0});var zxt=s(TG);O4o=r(zxt,"CLIPTokenizerFast"),zxt.forEach(t),V4o=r(RI," (GroupViT model)"),RI.forEach(t),X4o=i(S),Gs=n(S,"LI",{});var PI=s(Gs);ope=n(PI,"STRONG",{});var Qxt=s(ope);z4o=r(Qxt,"herbert"),Qxt.forEach(t),Q4o=r(PI," \u2014 "),MG=n(PI,"A",{href:!0});var Wxt=s(MG);W4o=r(Wxt,"HerbertTokenizer"),Wxt.forEach(t),U4o=r(PI," or "),EG=n(PI,"A",{href:!0});var Uxt=s(EG);H4o=r(Uxt,"HerbertTokenizerFast"),Uxt.forEach(t),J4o=r(PI," (HerBERT model)"),PI.forEach(t),Y4o=i(S),Xu=n(S,"LI",{});var Eje=s(Xu);rpe=n(Eje,"STRONG",{});var Hxt=s(rpe);Z4o=r(Hxt,"hubert"),Hxt.forEach(t),K4o=r(Eje," \u2014 "),CG=n(Eje,"A",{href:!0});var Jxt=s(CG);eCo=r(Jxt,"Wav2Vec2CTCTokenizer"),Jxt.forEach(t),oCo=r(Eje," (Hubert model)"),Eje.forEach(t),rCo=i(S),Os=n(S,"LI",{});var BI=s(Os);tpe=n(BI,"STRONG",{});var Yxt=s(tpe);tCo=r(Yxt,"ibert"),Yxt.forEach(t),aCo=r(BI," \u2014 "),wG=n(BI,"A",{href:!0});var Zxt=s(wG);nCo=r(Zxt,"RobertaTokenizer"),Zxt.forEach(t),sCo=r(BI," or "),AG=n(BI,"A",{href:!0});var Kxt=s(AG);lCo=r(Kxt,"RobertaTokenizerFast"),Kxt.forEach(t),iCo=r(BI," (I-BERT model)"),BI.forEach(t),dCo=i(S),Vs=n(S,"LI",{});var II=s(Vs);ape=n(II,"STRONG",{});var e$t=s(ape);mCo=r(e$t,"layoutlm"),e$t.forEach(t),cCo=r(II," \u2014 "),LG=n(II,"A",{href:!0});var o$t=s(LG);fCo=r(o$t,"LayoutLMTokenizer"),o$t.forEach(t),gCo=r(II," or "),yG=n(II,"A",{href:!0});var r$t=s(yG);hCo=r(r$t,"LayoutLMTokenizerFast"),r$t.forEach(t),uCo=r(II," (LayoutLM model)"),II.forEach(t),pCo=i(S),Xs=n(S,"LI",{});var NI=s(Xs);npe=n(NI,"STRONG",{});var t$t=s(npe);_Co=r(t$t,"layoutlmv2"),t$t.forEach(t),bCo=r(NI," \u2014 "),xG=n(NI,"A",{href:!0});var a$t=s(xG);vCo=r(a$t,"LayoutLMv2Tokenizer"),a$t.forEach(t),FCo=r(NI," or "),$G=n(NI,"A",{href:!0});var n$t=s($G);TCo=r(n$t,"LayoutLMv2TokenizerFast"),n$t.forEach(t),MCo=r(NI," (LayoutLMv2 model)"),NI.forEach(t),ECo=i(S),zs=n(S,"LI",{});var qI=s(zs);spe=n(qI,"STRONG",{});var s$t=s(spe);CCo=r(s$t,"layoutlmv3"),s$t.forEach(t),wCo=r(qI," \u2014 "),kG=n(qI,"A",{href:!0});var l$t=s(kG);ACo=r(l$t,"LayoutLMv3Tokenizer"),l$t.forEach(t),LCo=r(qI," or "),SG=n(qI,"A",{href:!0});var i$t=s(SG);yCo=r(i$t,"LayoutLMv3TokenizerFast"),i$t.forEach(t),xCo=r(qI," (LayoutLMv3 model)"),qI.forEach(t),$Co=i(S),Qs=n(S,"LI",{});var jI=s(Qs);lpe=n(jI,"STRONG",{});var d$t=s(lpe);kCo=r(d$t,"layoutxlm"),d$t.forEach(t),SCo=r(jI," \u2014 "),RG=n(jI,"A",{href:!0});var m$t=s(RG);RCo=r(m$t,"LayoutXLMTokenizer"),m$t.forEach(t),PCo=r(jI," or "),PG=n(jI,"A",{href:!0});var c$t=s(PG);BCo=r(c$t,"LayoutXLMTokenizerFast"),c$t.forEach(t),ICo=r(jI," (LayoutXLM model)"),jI.forEach(t),NCo=i(S),Ws=n(S,"LI",{});var DI=s(Ws);ipe=n(DI,"STRONG",{});var f$t=s(ipe);qCo=r(f$t,"led"),f$t.forEach(t),jCo=r(DI," \u2014 "),BG=n(DI,"A",{href:!0});var g$t=s(BG);DCo=r(g$t,"LEDTokenizer"),g$t.forEach(t),GCo=r(DI," or "),IG=n(DI,"A",{href:!0});var h$t=s(IG);OCo=r(h$t,"LEDTokenizerFast"),h$t.forEach(t),VCo=r(DI," (LED model)"),DI.forEach(t),XCo=i(S),Us=n(S,"LI",{});var GI=s(Us);dpe=n(GI,"STRONG",{});var u$t=s(dpe);zCo=r(u$t,"lilt"),u$t.forEach(t),QCo=r(GI," \u2014 "),NG=n(GI,"A",{href:!0});var p$t=s(NG);WCo=r(p$t,"LayoutLMv3Tokenizer"),p$t.forEach(t),UCo=r(GI," or "),qG=n(GI,"A",{href:!0});var _$t=s(qG);HCo=r(_$t,"LayoutLMv3TokenizerFast"),_$t.forEach(t),JCo=r(GI," (LiLT model)"),GI.forEach(t),YCo=i(S),Hs=n(S,"LI",{});var OI=s(Hs);mpe=n(OI,"STRONG",{});var b$t=s(mpe);ZCo=r(b$t,"longformer"),b$t.forEach(t),KCo=r(OI," \u2014 "),jG=n(OI,"A",{href:!0});var v$t=s(jG);e3o=r(v$t,"LongformerTokenizer"),v$t.forEach(t),o3o=r(OI," or "),DG=n(OI,"A",{href:!0});var F$t=s(DG);r3o=r(F$t,"LongformerTokenizerFast"),F$t.forEach(t),t3o=r(OI," (Longformer model)"),OI.forEach(t),a3o=i(S),Js=n(S,"LI",{});var VI=s(Js);cpe=n(VI,"STRONG",{});var T$t=s(cpe);n3o=r(T$t,"longt5"),T$t.forEach(t),s3o=r(VI," \u2014 "),GG=n(VI,"A",{href:!0});var M$t=s(GG);l3o=r(M$t,"T5Tokenizer"),M$t.forEach(t),i3o=r(VI," or "),OG=n(VI,"A",{href:!0});var E$t=s(OG);d3o=r(E$t,"T5TokenizerFast"),E$t.forEach(t),m3o=r(VI," (LongT5 model)"),VI.forEach(t),c3o=i(S),zu=n(S,"LI",{});var Cje=s(zu);fpe=n(Cje,"STRONG",{});var C$t=s(fpe);f3o=r(C$t,"luke"),C$t.forEach(t),g3o=r(Cje," \u2014 "),VG=n(Cje,"A",{href:!0});var w$t=s(VG);h3o=r(w$t,"LukeTokenizer"),w$t.forEach(t),u3o=r(Cje," (LUKE model)"),Cje.forEach(t),p3o=i(S),Ys=n(S,"LI",{});var XI=s(Ys);gpe=n(XI,"STRONG",{});var A$t=s(gpe);_3o=r(A$t,"lxmert"),A$t.forEach(t),b3o=r(XI," \u2014 "),XG=n(XI,"A",{href:!0});var L$t=s(XG);v3o=r(L$t,"LxmertTokenizer"),L$t.forEach(t),F3o=r(XI," or "),zG=n(XI,"A",{href:!0});var y$t=s(zG);T3o=r(y$t,"LxmertTokenizerFast"),y$t.forEach(t),M3o=r(XI," (LXMERT model)"),XI.forEach(t),E3o=i(S),Qu=n(S,"LI",{});var wje=s(Qu);hpe=n(wje,"STRONG",{});var x$t=s(hpe);C3o=r(x$t,"m2m_100"),x$t.forEach(t),w3o=r(wje," \u2014 "),QG=n(wje,"A",{href:!0});var $$t=s(QG);A3o=r($$t,"M2M100Tokenizer"),$$t.forEach(t),L3o=r(wje," (M2M100 model)"),wje.forEach(t),y3o=i(S),Wu=n(S,"LI",{});var Aje=s(Wu);upe=n(Aje,"STRONG",{});var k$t=s(upe);x3o=r(k$t,"marian"),k$t.forEach(t),$3o=r(Aje," \u2014 "),WG=n(Aje,"A",{href:!0});var S$t=s(WG);k3o=r(S$t,"MarianTokenizer"),S$t.forEach(t),S3o=r(Aje," (Marian model)"),Aje.forEach(t),R3o=i(S),Zs=n(S,"LI",{});var zI=s(Zs);ppe=n(zI,"STRONG",{});var R$t=s(ppe);P3o=r(R$t,"mbart"),R$t.forEach(t),B3o=r(zI," \u2014 "),UG=n(zI,"A",{href:!0});var P$t=s(UG);I3o=r(P$t,"MBartTokenizer"),P$t.forEach(t),N3o=r(zI," or "),HG=n(zI,"A",{href:!0});var B$t=s(HG);q3o=r(B$t,"MBartTokenizerFast"),B$t.forEach(t),j3o=r(zI," (mBART model)"),zI.forEach(t),D3o=i(S),Ks=n(S,"LI",{});var QI=s(Ks);_pe=n(QI,"STRONG",{});var I$t=s(_pe);G3o=r(I$t,"mbart50"),I$t.forEach(t),O3o=r(QI," \u2014 "),JG=n(QI,"A",{href:!0});var N$t=s(JG);V3o=r(N$t,"MBart50Tokenizer"),N$t.forEach(t),X3o=r(QI," or "),YG=n(QI,"A",{href:!0});var q$t=s(YG);z3o=r(q$t,"MBart50TokenizerFast"),q$t.forEach(t),Q3o=r(QI," (mBART-50 model)"),QI.forEach(t),W3o=i(S),el=n(S,"LI",{});var WI=s(el);bpe=n(WI,"STRONG",{});var j$t=s(bpe);U3o=r(j$t,"megatron-bert"),j$t.forEach(t),H3o=r(WI," \u2014 "),ZG=n(WI,"A",{href:!0});var D$t=s(ZG);J3o=r(D$t,"BertTokenizer"),D$t.forEach(t),Y3o=r(WI," or "),KG=n(WI,"A",{href:!0});var G$t=s(KG);Z3o=r(G$t,"BertTokenizerFast"),G$t.forEach(t),K3o=r(WI," (Megatron-BERT model)"),WI.forEach(t),e5o=i(S),Uu=n(S,"LI",{});var Lje=s(Uu);vpe=n(Lje,"STRONG",{});var O$t=s(vpe);o5o=r(O$t,"mluke"),O$t.forEach(t),r5o=r(Lje," \u2014 "),eO=n(Lje,"A",{href:!0});var V$t=s(eO);t5o=r(V$t,"MLukeTokenizer"),V$t.forEach(t),a5o=r(Lje," (mLUKE model)"),Lje.forEach(t),n5o=i(S),ol=n(S,"LI",{});var UI=s(ol);Fpe=n(UI,"STRONG",{});var X$t=s(Fpe);s5o=r(X$t,"mobilebert"),X$t.forEach(t),l5o=r(UI," \u2014 "),oO=n(UI,"A",{href:!0});var z$t=s(oO);i5o=r(z$t,"MobileBertTokenizer"),z$t.forEach(t),d5o=r(UI," or "),rO=n(UI,"A",{href:!0});var Q$t=s(rO);m5o=r(Q$t,"MobileBertTokenizerFast"),Q$t.forEach(t),c5o=r(UI," (MobileBERT model)"),UI.forEach(t),f5o=i(S),rl=n(S,"LI",{});var HI=s(rl);Tpe=n(HI,"STRONG",{});var W$t=s(Tpe);g5o=r(W$t,"mpnet"),W$t.forEach(t),h5o=r(HI," \u2014 "),tO=n(HI,"A",{href:!0});var U$t=s(tO);u5o=r(U$t,"MPNetTokenizer"),U$t.forEach(t),p5o=r(HI," or "),aO=n(HI,"A",{href:!0});var H$t=s(aO);_5o=r(H$t,"MPNetTokenizerFast"),H$t.forEach(t),b5o=r(HI," (MPNet model)"),HI.forEach(t),v5o=i(S),tl=n(S,"LI",{});var JI=s(tl);Mpe=n(JI,"STRONG",{});var J$t=s(Mpe);F5o=r(J$t,"mt5"),J$t.forEach(t),T5o=r(JI," \u2014 "),nO=n(JI,"A",{href:!0});var Y$t=s(nO);M5o=r(Y$t,"MT5Tokenizer"),Y$t.forEach(t),E5o=r(JI," or "),sO=n(JI,"A",{href:!0});var Z$t=s(sO);C5o=r(Z$t,"MT5TokenizerFast"),Z$t.forEach(t),w5o=r(JI," (MT5 model)"),JI.forEach(t),A5o=i(S),al=n(S,"LI",{});var YI=s(al);Epe=n(YI,"STRONG",{});var K$t=s(Epe);L5o=r(K$t,"mvp"),K$t.forEach(t),y5o=r(YI," \u2014 "),lO=n(YI,"A",{href:!0});var ekt=s(lO);x5o=r(ekt,"MvpTokenizer"),ekt.forEach(t),$5o=r(YI," or "),iO=n(YI,"A",{href:!0});var okt=s(iO);k5o=r(okt,"MvpTokenizerFast"),okt.forEach(t),S5o=r(YI," (MVP model)"),YI.forEach(t),R5o=i(S),nl=n(S,"LI",{});var ZI=s(nl);Cpe=n(ZI,"STRONG",{});var rkt=s(Cpe);P5o=r(rkt,"nezha"),rkt.forEach(t),B5o=r(ZI," \u2014 "),dO=n(ZI,"A",{href:!0});var tkt=s(dO);I5o=r(tkt,"BertTokenizer"),tkt.forEach(t),N5o=r(ZI," or "),mO=n(ZI,"A",{href:!0});var akt=s(mO);q5o=r(akt,"BertTokenizerFast"),akt.forEach(t),j5o=r(ZI," (Nezha model)"),ZI.forEach(t),D5o=i(S),sl=n(S,"LI",{});var KI=s(sl);wpe=n(KI,"STRONG",{});var nkt=s(wpe);G5o=r(nkt,"nllb"),nkt.forEach(t),O5o=r(KI," \u2014 "),cO=n(KI,"A",{href:!0});var skt=s(cO);V5o=r(skt,"NllbTokenizer"),skt.forEach(t),X5o=r(KI," or "),fO=n(KI,"A",{href:!0});var lkt=s(fO);z5o=r(lkt,"NllbTokenizerFast"),lkt.forEach(t),Q5o=r(KI," (NLLB model)"),KI.forEach(t),W5o=i(S),ll=n(S,"LI",{});var eN=s(ll);Ape=n(eN,"STRONG",{});var ikt=s(Ape);U5o=r(ikt,"nystromformer"),ikt.forEach(t),H5o=r(eN," \u2014 "),gO=n(eN,"A",{href:!0});var dkt=s(gO);J5o=r(dkt,"AlbertTokenizer"),dkt.forEach(t),Y5o=r(eN," or "),hO=n(eN,"A",{href:!0});var mkt=s(hO);Z5o=r(mkt,"AlbertTokenizerFast"),mkt.forEach(t),K5o=r(eN," (Nystr\xF6mformer model)"),eN.forEach(t),e0o=i(S),il=n(S,"LI",{});var oN=s(il);Lpe=n(oN,"STRONG",{});var ckt=s(Lpe);o0o=r(ckt,"openai-gpt"),ckt.forEach(t),r0o=r(oN," \u2014 "),uO=n(oN,"A",{href:!0});var fkt=s(uO);t0o=r(fkt,"OpenAIGPTTokenizer"),fkt.forEach(t),a0o=r(oN," or "),pO=n(oN,"A",{href:!0});var gkt=s(pO);n0o=r(gkt,"OpenAIGPTTokenizerFast"),gkt.forEach(t),s0o=r(oN," (OpenAI GPT model)"),oN.forEach(t),l0o=i(S),Hu=n(S,"LI",{});var yje=s(Hu);ype=n(yje,"STRONG",{});var hkt=s(ype);i0o=r(hkt,"opt"),hkt.forEach(t),d0o=r(yje," \u2014 "),_O=n(yje,"A",{href:!0});var ukt=s(_O);m0o=r(ukt,"GPT2Tokenizer"),ukt.forEach(t),c0o=r(yje," (OPT model)"),yje.forEach(t),f0o=i(S),dl=n(S,"LI",{});var rN=s(dl);xpe=n(rN,"STRONG",{});var pkt=s(xpe);g0o=r(pkt,"owlvit"),pkt.forEach(t),h0o=r(rN," \u2014 "),bO=n(rN,"A",{href:!0});var _kt=s(bO);u0o=r(_kt,"CLIPTokenizer"),_kt.forEach(t),p0o=r(rN," or "),vO=n(rN,"A",{href:!0});var bkt=s(vO);_0o=r(bkt,"CLIPTokenizerFast"),bkt.forEach(t),b0o=r(rN," (OWL-ViT model)"),rN.forEach(t),v0o=i(S),ml=n(S,"LI",{});var tN=s(ml);$pe=n(tN,"STRONG",{});var vkt=s($pe);F0o=r(vkt,"pegasus"),vkt.forEach(t),T0o=r(tN," \u2014 "),FO=n(tN,"A",{href:!0});var Fkt=s(FO);M0o=r(Fkt,"PegasusTokenizer"),Fkt.forEach(t),E0o=r(tN," or "),TO=n(tN,"A",{href:!0});var Tkt=s(TO);C0o=r(Tkt,"PegasusTokenizerFast"),Tkt.forEach(t),w0o=r(tN," (Pegasus model)"),tN.forEach(t),A0o=i(S),cl=n(S,"LI",{});var aN=s(cl);kpe=n(aN,"STRONG",{});var Mkt=s(kpe);L0o=r(Mkt,"pegasus_x"),Mkt.forEach(t),y0o=r(aN," \u2014 "),MO=n(aN,"A",{href:!0});var Ekt=s(MO);x0o=r(Ekt,"PegasusTokenizer"),Ekt.forEach(t),$0o=r(aN," or "),EO=n(aN,"A",{href:!0});var Ckt=s(EO);k0o=r(Ckt,"PegasusTokenizerFast"),Ckt.forEach(t),S0o=r(aN," (PEGASUS-X model)"),aN.forEach(t),R0o=i(S),Ju=n(S,"LI",{});var xje=s(Ju);Spe=n(xje,"STRONG",{});var wkt=s(Spe);P0o=r(wkt,"perceiver"),wkt.forEach(t),B0o=r(xje," \u2014 "),CO=n(xje,"A",{href:!0});var Akt=s(CO);I0o=r(Akt,"PerceiverTokenizer"),Akt.forEach(t),N0o=r(xje," (Perceiver model)"),xje.forEach(t),q0o=i(S),Yu=n(S,"LI",{});var $je=s(Yu);Rpe=n($je,"STRONG",{});var Lkt=s(Rpe);j0o=r(Lkt,"phobert"),Lkt.forEach(t),D0o=r($je," \u2014 "),wO=n($je,"A",{href:!0});var ykt=s(wO);G0o=r(ykt,"PhobertTokenizer"),ykt.forEach(t),O0o=r($je," (PhoBERT model)"),$je.forEach(t),V0o=i(S),Zu=n(S,"LI",{});var kje=s(Zu);Ppe=n(kje,"STRONG",{});var xkt=s(Ppe);X0o=r(xkt,"plbart"),xkt.forEach(t),z0o=r(kje," \u2014 "),AO=n(kje,"A",{href:!0});var $kt=s(AO);Q0o=r($kt,"PLBartTokenizer"),$kt.forEach(t),W0o=r(kje," (PLBart model)"),kje.forEach(t),U0o=i(S),Ku=n(S,"LI",{});var Sje=s(Ku);Bpe=n(Sje,"STRONG",{});var kkt=s(Bpe);H0o=r(kkt,"prophetnet"),kkt.forEach(t),J0o=r(Sje," \u2014 "),LO=n(Sje,"A",{href:!0});var Skt=s(LO);Y0o=r(Skt,"ProphetNetTokenizer"),Skt.forEach(t),Z0o=r(Sje," (ProphetNet model)"),Sje.forEach(t),K0o=i(S),fl=n(S,"LI",{});var nN=s(fl);Ipe=n(nN,"STRONG",{});var Rkt=s(Ipe);ewo=r(Rkt,"qdqbert"),Rkt.forEach(t),owo=r(nN," \u2014 "),yO=n(nN,"A",{href:!0});var Pkt=s(yO);rwo=r(Pkt,"BertTokenizer"),Pkt.forEach(t),two=r(nN," or "),xO=n(nN,"A",{href:!0});var Bkt=s(xO);awo=r(Bkt,"BertTokenizerFast"),Bkt.forEach(t),nwo=r(nN," (QDQBert model)"),nN.forEach(t),swo=i(S),ep=n(S,"LI",{});var Rje=s(ep);Npe=n(Rje,"STRONG",{});var Ikt=s(Npe);lwo=r(Ikt,"rag"),Ikt.forEach(t),iwo=r(Rje," \u2014 "),$O=n(Rje,"A",{href:!0});var Nkt=s($O);dwo=r(Nkt,"RagTokenizer"),Nkt.forEach(t),mwo=r(Rje," (RAG model)"),Rje.forEach(t),cwo=i(S),gl=n(S,"LI",{});var sN=s(gl);qpe=n(sN,"STRONG",{});var qkt=s(qpe);fwo=r(qkt,"realm"),qkt.forEach(t),gwo=r(sN," \u2014 "),kO=n(sN,"A",{href:!0});var jkt=s(kO);hwo=r(jkt,"RealmTokenizer"),jkt.forEach(t),uwo=r(sN," or "),SO=n(sN,"A",{href:!0});var Dkt=s(SO);pwo=r(Dkt,"RealmTokenizerFast"),Dkt.forEach(t),_wo=r(sN," (REALM model)"),sN.forEach(t),bwo=i(S),hl=n(S,"LI",{});var lN=s(hl);jpe=n(lN,"STRONG",{});var Gkt=s(jpe);vwo=r(Gkt,"reformer"),Gkt.forEach(t),Fwo=r(lN," \u2014 "),RO=n(lN,"A",{href:!0});var Okt=s(RO);Two=r(Okt,"ReformerTokenizer"),Okt.forEach(t),Mwo=r(lN," or "),PO=n(lN,"A",{href:!0});var Vkt=s(PO);Ewo=r(Vkt,"ReformerTokenizerFast"),Vkt.forEach(t),Cwo=r(lN," (Reformer model)"),lN.forEach(t),wwo=i(S),ul=n(S,"LI",{});var iN=s(ul);Dpe=n(iN,"STRONG",{});var Xkt=s(Dpe);Awo=r(Xkt,"rembert"),Xkt.forEach(t),Lwo=r(iN," \u2014 "),BO=n(iN,"A",{href:!0});var zkt=s(BO);ywo=r(zkt,"RemBertTokenizer"),zkt.forEach(t),xwo=r(iN," or "),IO=n(iN,"A",{href:!0});var Qkt=s(IO);$wo=r(Qkt,"RemBertTokenizerFast"),Qkt.forEach(t),kwo=r(iN," (RemBERT model)"),iN.forEach(t),Swo=i(S),pl=n(S,"LI",{});var dN=s(pl);Gpe=n(dN,"STRONG",{});var Wkt=s(Gpe);Rwo=r(Wkt,"retribert"),Wkt.forEach(t),Pwo=r(dN," \u2014 "),NO=n(dN,"A",{href:!0});var Ukt=s(NO);Bwo=r(Ukt,"RetriBertTokenizer"),Ukt.forEach(t),Iwo=r(dN," or "),qO=n(dN,"A",{href:!0});var Hkt=s(qO);Nwo=r(Hkt,"RetriBertTokenizerFast"),Hkt.forEach(t),qwo=r(dN," (RetriBERT model)"),dN.forEach(t),jwo=i(S),_l=n(S,"LI",{});var mN=s(_l);Ope=n(mN,"STRONG",{});var Jkt=s(Ope);Dwo=r(Jkt,"roberta"),Jkt.forEach(t),Gwo=r(mN," \u2014 "),jO=n(mN,"A",{href:!0});var Ykt=s(jO);Owo=r(Ykt,"RobertaTokenizer"),Ykt.forEach(t),Vwo=r(mN," or "),DO=n(mN,"A",{href:!0});var Zkt=s(DO);Xwo=r(Zkt,"RobertaTokenizerFast"),Zkt.forEach(t),zwo=r(mN," (RoBERTa model)"),mN.forEach(t),Qwo=i(S),bl=n(S,"LI",{});var cN=s(bl);Vpe=n(cN,"STRONG",{});var Kkt=s(Vpe);Wwo=r(Kkt,"roformer"),Kkt.forEach(t),Uwo=r(cN," \u2014 "),GO=n(cN,"A",{href:!0});var eSt=s(GO);Hwo=r(eSt,"RoFormerTokenizer"),eSt.forEach(t),Jwo=r(cN," or "),OO=n(cN,"A",{href:!0});var oSt=s(OO);Ywo=r(oSt,"RoFormerTokenizerFast"),oSt.forEach(t),Zwo=r(cN," (RoFormer model)"),cN.forEach(t),Kwo=i(S),op=n(S,"LI",{});var Pje=s(op);Xpe=n(Pje,"STRONG",{});var rSt=s(Xpe);eAo=r(rSt,"speech_to_text"),rSt.forEach(t),oAo=r(Pje," \u2014 "),VO=n(Pje,"A",{href:!0});var tSt=s(VO);rAo=r(tSt,"Speech2TextTokenizer"),tSt.forEach(t),tAo=r(Pje," (Speech2Text model)"),Pje.forEach(t),aAo=i(S),rp=n(S,"LI",{});var Bje=s(rp);zpe=n(Bje,"STRONG",{});var aSt=s(zpe);nAo=r(aSt,"speech_to_text_2"),aSt.forEach(t),sAo=r(Bje," \u2014 "),XO=n(Bje,"A",{href:!0});var nSt=s(XO);lAo=r(nSt,"Speech2Text2Tokenizer"),nSt.forEach(t),iAo=r(Bje," (Speech2Text2 model)"),Bje.forEach(t),dAo=i(S),vl=n(S,"LI",{});var fN=s(vl);Qpe=n(fN,"STRONG",{});var sSt=s(Qpe);mAo=r(sSt,"splinter"),sSt.forEach(t),cAo=r(fN," \u2014 "),zO=n(fN,"A",{href:!0});var lSt=s(zO);fAo=r(lSt,"SplinterTokenizer"),lSt.forEach(t),gAo=r(fN," or "),QO=n(fN,"A",{href:!0});var iSt=s(QO);hAo=r(iSt,"SplinterTokenizerFast"),iSt.forEach(t),uAo=r(fN," (Splinter model)"),fN.forEach(t),pAo=i(S),Fl=n(S,"LI",{});var gN=s(Fl);Wpe=n(gN,"STRONG",{});var dSt=s(Wpe);_Ao=r(dSt,"squeezebert"),dSt.forEach(t),bAo=r(gN," \u2014 "),WO=n(gN,"A",{href:!0});var mSt=s(WO);vAo=r(mSt,"SqueezeBertTokenizer"),mSt.forEach(t),FAo=r(gN," or "),UO=n(gN,"A",{href:!0});var cSt=s(UO);TAo=r(cSt,"SqueezeBertTokenizerFast"),cSt.forEach(t),MAo=r(gN," (SqueezeBERT model)"),gN.forEach(t),EAo=i(S),Tl=n(S,"LI",{});var hN=s(Tl);Upe=n(hN,"STRONG",{});var fSt=s(Upe);CAo=r(fSt,"t5"),fSt.forEach(t),wAo=r(hN," \u2014 "),HO=n(hN,"A",{href:!0});var gSt=s(HO);AAo=r(gSt,"T5Tokenizer"),gSt.forEach(t),LAo=r(hN," or "),JO=n(hN,"A",{href:!0});var hSt=s(JO);yAo=r(hSt,"T5TokenizerFast"),hSt.forEach(t),xAo=r(hN," (T5 model)"),hN.forEach(t),$Ao=i(S),tp=n(S,"LI",{});var Ije=s(tp);Hpe=n(Ije,"STRONG",{});var uSt=s(Hpe);kAo=r(uSt,"tapas"),uSt.forEach(t),SAo=r(Ije," \u2014 "),YO=n(Ije,"A",{href:!0});var pSt=s(YO);RAo=r(pSt,"TapasTokenizer"),pSt.forEach(t),PAo=r(Ije," (TAPAS model)"),Ije.forEach(t),BAo=i(S),ap=n(S,"LI",{});var Nje=s(ap);Jpe=n(Nje,"STRONG",{});var _St=s(Jpe);IAo=r(_St,"tapex"),_St.forEach(t),NAo=r(Nje," \u2014 "),ZO=n(Nje,"A",{href:!0});var bSt=s(ZO);qAo=r(bSt,"TapexTokenizer"),bSt.forEach(t),jAo=r(Nje," (TAPEX model)"),Nje.forEach(t),DAo=i(S),np=n(S,"LI",{});var qje=s(np);Ype=n(qje,"STRONG",{});var vSt=s(Ype);GAo=r(vSt,"transfo-xl"),vSt.forEach(t),OAo=r(qje," \u2014 "),KO=n(qje,"A",{href:!0});var FSt=s(KO);VAo=r(FSt,"TransfoXLTokenizer"),FSt.forEach(t),XAo=r(qje," (Transformer-XL model)"),qje.forEach(t),zAo=i(S),Ml=n(S,"LI",{});var uN=s(Ml);Zpe=n(uN,"STRONG",{});var TSt=s(Zpe);QAo=r(TSt,"vilt"),TSt.forEach(t),WAo=r(uN," \u2014 "),eV=n(uN,"A",{href:!0});var MSt=s(eV);UAo=r(MSt,"BertTokenizer"),MSt.forEach(t),HAo=r(uN," or "),oV=n(uN,"A",{href:!0});var ESt=s(oV);JAo=r(ESt,"BertTokenizerFast"),ESt.forEach(t),YAo=r(uN," (ViLT model)"),uN.forEach(t),ZAo=i(S),El=n(S,"LI",{});var pN=s(El);Kpe=n(pN,"STRONG",{});var CSt=s(Kpe);KAo=r(CSt,"visual_bert"),CSt.forEach(t),e6o=r(pN," \u2014 "),rV=n(pN,"A",{href:!0});var wSt=s(rV);o6o=r(wSt,"BertTokenizer"),wSt.forEach(t),r6o=r(pN," or "),tV=n(pN,"A",{href:!0});var ASt=s(tV);t6o=r(ASt,"BertTokenizerFast"),ASt.forEach(t),a6o=r(pN," (VisualBERT model)"),pN.forEach(t),n6o=i(S),sp=n(S,"LI",{});var jje=s(sp);e_e=n(jje,"STRONG",{});var LSt=s(e_e);s6o=r(LSt,"wav2vec2"),LSt.forEach(t),l6o=r(jje," \u2014 "),aV=n(jje,"A",{href:!0});var ySt=s(aV);i6o=r(ySt,"Wav2Vec2CTCTokenizer"),ySt.forEach(t),d6o=r(jje," (Wav2Vec2 model)"),jje.forEach(t),m6o=i(S),lp=n(S,"LI",{});var Dje=s(lp);o_e=n(Dje,"STRONG",{});var xSt=s(o_e);c6o=r(xSt,"wav2vec2-conformer"),xSt.forEach(t),f6o=r(Dje," \u2014 "),nV=n(Dje,"A",{href:!0});var $St=s(nV);g6o=r($St,"Wav2Vec2CTCTokenizer"),$St.forEach(t),h6o=r(Dje," (Wav2Vec2-Conformer model)"),Dje.forEach(t),u6o=i(S),ip=n(S,"LI",{});var Gje=s(ip);r_e=n(Gje,"STRONG",{});var kSt=s(r_e);p6o=r(kSt,"wav2vec2_phoneme"),kSt.forEach(t),_6o=r(Gje," \u2014 "),sV=n(Gje,"A",{href:!0});var SSt=s(sV);b6o=r(SSt,"Wav2Vec2PhonemeCTCTokenizer"),SSt.forEach(t),v6o=r(Gje," (Wav2Vec2Phoneme model)"),Gje.forEach(t),F6o=i(S),dp=n(S,"LI",{});var Oje=s(dp);t_e=n(Oje,"STRONG",{});var RSt=s(t_e);T6o=r(RSt,"whisper"),RSt.forEach(t),M6o=r(Oje," \u2014 "),lV=n(Oje,"A",{href:!0});var PSt=s(lV);E6o=r(PSt,"WhisperTokenizer"),PSt.forEach(t),C6o=r(Oje," (Whisper model)"),Oje.forEach(t),w6o=i(S),Cl=n(S,"LI",{});var _N=s(Cl);a_e=n(_N,"STRONG",{});var BSt=s(a_e);A6o=r(BSt,"xclip"),BSt.forEach(t),L6o=r(_N," \u2014 "),iV=n(_N,"A",{href:!0});var ISt=s(iV);y6o=r(ISt,"CLIPTokenizer"),ISt.forEach(t),x6o=r(_N," or "),dV=n(_N,"A",{href:!0});var NSt=s(dV);$6o=r(NSt,"CLIPTokenizerFast"),NSt.forEach(t),k6o=r(_N," (X-CLIP model)"),_N.forEach(t),S6o=i(S),wl=n(S,"LI",{});var bN=s(wl);n_e=n(bN,"STRONG",{});var qSt=s(n_e);R6o=r(qSt,"xglm"),qSt.forEach(t),P6o=r(bN," \u2014 "),mV=n(bN,"A",{href:!0});var jSt=s(mV);B6o=r(jSt,"XGLMTokenizer"),jSt.forEach(t),I6o=r(bN," or "),cV=n(bN,"A",{href:!0});var DSt=s(cV);N6o=r(DSt,"XGLMTokenizerFast"),DSt.forEach(t),q6o=r(bN," (XGLM model)"),bN.forEach(t),j6o=i(S),mp=n(S,"LI",{});var Vje=s(mp);s_e=n(Vje,"STRONG",{});var GSt=s(s_e);D6o=r(GSt,"xlm"),GSt.forEach(t),G6o=r(Vje," \u2014 "),fV=n(Vje,"A",{href:!0});var OSt=s(fV);O6o=r(OSt,"XLMTokenizer"),OSt.forEach(t),V6o=r(Vje," (XLM model)"),Vje.forEach(t),X6o=i(S),cp=n(S,"LI",{});var Xje=s(cp);l_e=n(Xje,"STRONG",{});var VSt=s(l_e);z6o=r(VSt,"xlm-prophetnet"),VSt.forEach(t),Q6o=r(Xje," \u2014 "),gV=n(Xje,"A",{href:!0});var XSt=s(gV);W6o=r(XSt,"XLMProphetNetTokenizer"),XSt.forEach(t),U6o=r(Xje," (XLM-ProphetNet model)"),Xje.forEach(t),H6o=i(S),Al=n(S,"LI",{});var vN=s(Al);i_e=n(vN,"STRONG",{});var zSt=s(i_e);J6o=r(zSt,"xlm-roberta"),zSt.forEach(t),Y6o=r(vN," \u2014 "),hV=n(vN,"A",{href:!0});var QSt=s(hV);Z6o=r(QSt,"XLMRobertaTokenizer"),QSt.forEach(t),K6o=r(vN," or "),uV=n(vN,"A",{href:!0});var WSt=s(uV);e7o=r(WSt,"XLMRobertaTokenizerFast"),WSt.forEach(t),o7o=r(vN," (XLM-RoBERTa model)"),vN.forEach(t),r7o=i(S),Ll=n(S,"LI",{});var FN=s(Ll);d_e=n(FN,"STRONG",{});var USt=s(d_e);t7o=r(USt,"xlm-roberta-xl"),USt.forEach(t),a7o=r(FN," \u2014 "),pV=n(FN,"A",{href:!0});var HSt=s(pV);n7o=r(HSt,"XLMRobertaTokenizer"),HSt.forEach(t),s7o=r(FN," or "),_V=n(FN,"A",{href:!0});var JSt=s(_V);l7o=r(JSt,"XLMRobertaTokenizerFast"),JSt.forEach(t),i7o=r(FN," (XLM-RoBERTa-XL model)"),FN.forEach(t),d7o=i(S),yl=n(S,"LI",{});var TN=s(yl);m_e=n(TN,"STRONG",{});var YSt=s(m_e);m7o=r(YSt,"xlnet"),YSt.forEach(t),c7o=r(TN," \u2014 "),bV=n(TN,"A",{href:!0});var ZSt=s(bV);f7o=r(ZSt,"XLNetTokenizer"),ZSt.forEach(t),g7o=r(TN," or "),vV=n(TN,"A",{href:!0});var KSt=s(vV);h7o=r(KSt,"XLNetTokenizerFast"),KSt.forEach(t),u7o=r(TN," (XLNet model)"),TN.forEach(t),p7o=i(S),xl=n(S,"LI",{});var MN=s(xl);c_e=n(MN,"STRONG",{});var eRt=s(c_e);_7o=r(eRt,"yoso"),eRt.forEach(t),b7o=r(MN," \u2014 "),FV=n(MN,"A",{href:!0});var oRt=s(FV);v7o=r(oRt,"AlbertTokenizer"),oRt.forEach(t),F7o=r(MN," or "),TV=n(MN,"A",{href:!0});var rRt=s(TV);T7o=r(rRt,"AlbertTokenizerFast"),rRt.forEach(t),M7o=r(MN," (YOSO model)"),MN.forEach(t),S.forEach(t),E7o=i(Il),T(fp.$$.fragment,Il),Il.forEach(t),C7o=i(Bl),gp=n(Bl,"DIV",{class:!0});var hso=s(gp);T(L$.$$.fragment,hso),w7o=i(hso),f_e=n(hso,"P",{});var tRt=s(f_e);A7o=r(tRt,"Register a new tokenizer in this mapping."),tRt.forEach(t),hso.forEach(t),Bl.forEach(t),oao=i(c),$d=n(c,"H2",{class:!0});var uso=s($d);hp=n(uso,"A",{id:!0,class:!0,href:!0});var aRt=s(hp);g_e=n(aRt,"SPAN",{});var nRt=s(g_e);T(y$.$$.fragment,nRt),nRt.forEach(t),aRt.forEach(t),L7o=i(uso),h_e=n(uso,"SPAN",{});var sRt=s(h_e);y7o=r(sRt,"AutoFeatureExtractor"),sRt.forEach(t),uso.forEach(t),rao=i(c),Po=n(c,"DIV",{class:!0});var Nl=s(Po);T(x$.$$.fragment,Nl),x7o=i(Nl),$$=n(Nl,"P",{});var pso=s($$);$7o=r(pso,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),MV=n(pso,"A",{href:!0});var lRt=s(MV);k7o=r(lRt,"AutoFeatureExtractor.from_pretrained()"),lRt.forEach(t),S7o=r(pso," class method."),pso.forEach(t),R7o=i(Nl),k$=n(Nl,"P",{});var _so=s(k$);P7o=r(_so,"This class cannot be instantiated directly using "),u_e=n(_so,"CODE",{});var iRt=s(u_e);B7o=r(iRt,"__init__()"),iRt.forEach(t),I7o=r(_so," (throws an error)."),_so.forEach(t),N7o=i(Nl),Ye=n(Nl,"DIV",{class:!0});var wa=s(Ye);T(S$.$$.fragment,wa),q7o=i(wa),p_e=n(wa,"P",{});var dRt=s(p_e);j7o=r(dRt,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),dRt.forEach(t),D7o=i(wa),an=n(wa,"P",{});var a9=s(an);G7o=r(a9,"The feature extractor class to instantiate is selected based on the "),__e=n(a9,"CODE",{});var mRt=s(__e);O7o=r(mRt,"model_type"),mRt.forEach(t),V7o=r(a9,` property of the config object
(either passed as an argument or loaded from `),b_e=n(a9,"CODE",{});var cRt=s(b_e);X7o=r(cRt,"pretrained_model_name_or_path"),cRt.forEach(t),z7o=r(a9,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),v_e=n(a9,"CODE",{});var fRt=s(v_e);Q7o=r(fRt,"pretrained_model_name_or_path"),fRt.forEach(t),W7o=r(a9,":"),a9.forEach(t),U7o=i(wa),z=n(wa,"UL",{});var Q=s(z);up=n(Q,"LI",{});var zje=s(up);F_e=n(zje,"STRONG",{});var gRt=s(F_e);H7o=r(gRt,"beit"),gRt.forEach(t),J7o=r(zje," \u2014 "),EV=n(zje,"A",{href:!0});var hRt=s(EV);Y7o=r(hRt,"BeitFeatureExtractor"),hRt.forEach(t),Z7o=r(zje," (BEiT model)"),zje.forEach(t),K7o=i(Q),pp=n(Q,"LI",{});var Qje=s(pp);T_e=n(Qje,"STRONG",{});var uRt=s(T_e);e8o=r(uRt,"clip"),uRt.forEach(t),o8o=r(Qje," \u2014 "),CV=n(Qje,"A",{href:!0});var pRt=s(CV);r8o=r(pRt,"CLIPFeatureExtractor"),pRt.forEach(t),t8o=r(Qje," (CLIP model)"),Qje.forEach(t),a8o=i(Q),_p=n(Q,"LI",{});var Wje=s(_p);M_e=n(Wje,"STRONG",{});var _Rt=s(M_e);n8o=r(_Rt,"clipseg"),_Rt.forEach(t),s8o=r(Wje," \u2014 "),wV=n(Wje,"A",{href:!0});var bRt=s(wV);l8o=r(bRt,"ViTFeatureExtractor"),bRt.forEach(t),i8o=r(Wje," (CLIPSeg model)"),Wje.forEach(t),d8o=i(Q),bp=n(Q,"LI",{});var Uje=s(bp);E_e=n(Uje,"STRONG",{});var vRt=s(E_e);m8o=r(vRt,"conditional_detr"),vRt.forEach(t),c8o=r(Uje," \u2014 "),AV=n(Uje,"A",{href:!0});var FRt=s(AV);f8o=r(FRt,"ConditionalDetrFeatureExtractor"),FRt.forEach(t),g8o=r(Uje," (Conditional DETR model)"),Uje.forEach(t),h8o=i(Q),vp=n(Q,"LI",{});var Hje=s(vp);C_e=n(Hje,"STRONG",{});var TRt=s(C_e);u8o=r(TRt,"convnext"),TRt.forEach(t),p8o=r(Hje," \u2014 "),LV=n(Hje,"A",{href:!0});var MRt=s(LV);_8o=r(MRt,"ConvNextFeatureExtractor"),MRt.forEach(t),b8o=r(Hje," (ConvNeXT model)"),Hje.forEach(t),v8o=i(Q),Fp=n(Q,"LI",{});var Jje=s(Fp);w_e=n(Jje,"STRONG",{});var ERt=s(w_e);F8o=r(ERt,"cvt"),ERt.forEach(t),T8o=r(Jje," \u2014 "),yV=n(Jje,"A",{href:!0});var CRt=s(yV);M8o=r(CRt,"ConvNextFeatureExtractor"),CRt.forEach(t),E8o=r(Jje," (CvT model)"),Jje.forEach(t),C8o=i(Q),Tp=n(Q,"LI",{});var Yje=s(Tp);A_e=n(Yje,"STRONG",{});var wRt=s(A_e);w8o=r(wRt,"data2vec-audio"),wRt.forEach(t),A8o=r(Yje," \u2014 "),xV=n(Yje,"A",{href:!0});var ARt=s(xV);L8o=r(ARt,"Wav2Vec2FeatureExtractor"),ARt.forEach(t),y8o=r(Yje," (Data2VecAudio model)"),Yje.forEach(t),x8o=i(Q),Mp=n(Q,"LI",{});var Zje=s(Mp);L_e=n(Zje,"STRONG",{});var LRt=s(L_e);$8o=r(LRt,"data2vec-vision"),LRt.forEach(t),k8o=r(Zje," \u2014 "),$V=n(Zje,"A",{href:!0});var yRt=s($V);S8o=r(yRt,"BeitFeatureExtractor"),yRt.forEach(t),R8o=r(Zje," (Data2VecVision model)"),Zje.forEach(t),P8o=i(Q),Ep=n(Q,"LI",{});var Kje=s(Ep);y_e=n(Kje,"STRONG",{});var xRt=s(y_e);B8o=r(xRt,"deformable_detr"),xRt.forEach(t),I8o=r(Kje," \u2014 "),kV=n(Kje,"A",{href:!0});var $Rt=s(kV);N8o=r($Rt,"DeformableDetrFeatureExtractor"),$Rt.forEach(t),q8o=r(Kje," (Deformable DETR model)"),Kje.forEach(t),j8o=i(Q),Cp=n(Q,"LI",{});var eDe=s(Cp);x_e=n(eDe,"STRONG",{});var kRt=s(x_e);D8o=r(kRt,"deit"),kRt.forEach(t),G8o=r(eDe," \u2014 "),SV=n(eDe,"A",{href:!0});var SRt=s(SV);O8o=r(SRt,"DeiTFeatureExtractor"),SRt.forEach(t),V8o=r(eDe," (DeiT model)"),eDe.forEach(t),X8o=i(Q),wp=n(Q,"LI",{});var oDe=s(wp);$_e=n(oDe,"STRONG",{});var RRt=s($_e);z8o=r(RRt,"detr"),RRt.forEach(t),Q8o=r(oDe," \u2014 "),RV=n(oDe,"A",{href:!0});var PRt=s(RV);W8o=r(PRt,"DetrFeatureExtractor"),PRt.forEach(t),U8o=r(oDe," (DETR model)"),oDe.forEach(t),H8o=i(Q),Ap=n(Q,"LI",{});var rDe=s(Ap);k_e=n(rDe,"STRONG",{});var BRt=s(k_e);J8o=r(BRt,"donut-swin"),BRt.forEach(t),Y8o=r(rDe," \u2014 "),PV=n(rDe,"A",{href:!0});var IRt=s(PV);Z8o=r(IRt,"DonutFeatureExtractor"),IRt.forEach(t),K8o=r(rDe," (DonutSwin model)"),rDe.forEach(t),eLo=i(Q),Lp=n(Q,"LI",{});var tDe=s(Lp);S_e=n(tDe,"STRONG",{});var NRt=s(S_e);oLo=r(NRt,"dpt"),NRt.forEach(t),rLo=r(tDe," \u2014 "),BV=n(tDe,"A",{href:!0});var qRt=s(BV);tLo=r(qRt,"DPTFeatureExtractor"),qRt.forEach(t),aLo=r(tDe," (DPT model)"),tDe.forEach(t),nLo=i(Q),yp=n(Q,"LI",{});var aDe=s(yp);R_e=n(aDe,"STRONG",{});var jRt=s(R_e);sLo=r(jRt,"flava"),jRt.forEach(t),lLo=r(aDe," \u2014 "),IV=n(aDe,"A",{href:!0});var DRt=s(IV);iLo=r(DRt,"FlavaFeatureExtractor"),DRt.forEach(t),dLo=r(aDe," (FLAVA model)"),aDe.forEach(t),mLo=i(Q),xp=n(Q,"LI",{});var nDe=s(xp);P_e=n(nDe,"STRONG",{});var GRt=s(P_e);cLo=r(GRt,"glpn"),GRt.forEach(t),fLo=r(nDe," \u2014 "),NV=n(nDe,"A",{href:!0});var ORt=s(NV);gLo=r(ORt,"GLPNFeatureExtractor"),ORt.forEach(t),hLo=r(nDe," (GLPN model)"),nDe.forEach(t),uLo=i(Q),$p=n(Q,"LI",{});var sDe=s($p);B_e=n(sDe,"STRONG",{});var VRt=s(B_e);pLo=r(VRt,"groupvit"),VRt.forEach(t),_Lo=r(sDe," \u2014 "),qV=n(sDe,"A",{href:!0});var XRt=s(qV);bLo=r(XRt,"CLIPFeatureExtractor"),XRt.forEach(t),vLo=r(sDe," (GroupViT model)"),sDe.forEach(t),FLo=i(Q),kp=n(Q,"LI",{});var lDe=s(kp);I_e=n(lDe,"STRONG",{});var zRt=s(I_e);TLo=r(zRt,"hubert"),zRt.forEach(t),MLo=r(lDe," \u2014 "),jV=n(lDe,"A",{href:!0});var QRt=s(jV);ELo=r(QRt,"Wav2Vec2FeatureExtractor"),QRt.forEach(t),CLo=r(lDe," (Hubert model)"),lDe.forEach(t),wLo=i(Q),Sp=n(Q,"LI",{});var iDe=s(Sp);N_e=n(iDe,"STRONG",{});var WRt=s(N_e);ALo=r(WRt,"imagegpt"),WRt.forEach(t),LLo=r(iDe," \u2014 "),DV=n(iDe,"A",{href:!0});var URt=s(DV);yLo=r(URt,"ImageGPTFeatureExtractor"),URt.forEach(t),xLo=r(iDe," (ImageGPT model)"),iDe.forEach(t),$Lo=i(Q),Rp=n(Q,"LI",{});var dDe=s(Rp);q_e=n(dDe,"STRONG",{});var HRt=s(q_e);kLo=r(HRt,"layoutlmv2"),HRt.forEach(t),SLo=r(dDe," \u2014 "),GV=n(dDe,"A",{href:!0});var JRt=s(GV);RLo=r(JRt,"LayoutLMv2FeatureExtractor"),JRt.forEach(t),PLo=r(dDe," (LayoutLMv2 model)"),dDe.forEach(t),BLo=i(Q),Pp=n(Q,"LI",{});var mDe=s(Pp);j_e=n(mDe,"STRONG",{});var YRt=s(j_e);ILo=r(YRt,"layoutlmv3"),YRt.forEach(t),NLo=r(mDe," \u2014 "),OV=n(mDe,"A",{href:!0});var ZRt=s(OV);qLo=r(ZRt,"LayoutLMv3FeatureExtractor"),ZRt.forEach(t),jLo=r(mDe," (LayoutLMv3 model)"),mDe.forEach(t),DLo=i(Q),Bp=n(Q,"LI",{});var cDe=s(Bp);D_e=n(cDe,"STRONG",{});var KRt=s(D_e);GLo=r(KRt,"levit"),KRt.forEach(t),OLo=r(cDe," \u2014 "),VV=n(cDe,"A",{href:!0});var ePt=s(VV);VLo=r(ePt,"LevitFeatureExtractor"),ePt.forEach(t),XLo=r(cDe," (LeViT model)"),cDe.forEach(t),zLo=i(Q),Ip=n(Q,"LI",{});var fDe=s(Ip);G_e=n(fDe,"STRONG",{});var oPt=s(G_e);QLo=r(oPt,"maskformer"),oPt.forEach(t),WLo=r(fDe," \u2014 "),XV=n(fDe,"A",{href:!0});var rPt=s(XV);ULo=r(rPt,"MaskFormerFeatureExtractor"),rPt.forEach(t),HLo=r(fDe," (MaskFormer model)"),fDe.forEach(t),JLo=i(Q),Np=n(Q,"LI",{});var gDe=s(Np);O_e=n(gDe,"STRONG",{});var tPt=s(O_e);YLo=r(tPt,"mctct"),tPt.forEach(t),ZLo=r(gDe," \u2014 "),zV=n(gDe,"A",{href:!0});var aPt=s(zV);KLo=r(aPt,"MCTCTFeatureExtractor"),aPt.forEach(t),eyo=r(gDe," (M-CTC-T model)"),gDe.forEach(t),oyo=i(Q),qp=n(Q,"LI",{});var hDe=s(qp);V_e=n(hDe,"STRONG",{});var nPt=s(V_e);ryo=r(nPt,"mobilevit"),nPt.forEach(t),tyo=r(hDe," \u2014 "),QV=n(hDe,"A",{href:!0});var sPt=s(QV);ayo=r(sPt,"MobileViTFeatureExtractor"),sPt.forEach(t),nyo=r(hDe," (MobileViT model)"),hDe.forEach(t),syo=i(Q),jp=n(Q,"LI",{});var uDe=s(jp);X_e=n(uDe,"STRONG",{});var lPt=s(X_e);lyo=r(lPt,"owlvit"),lPt.forEach(t),iyo=r(uDe," \u2014 "),WV=n(uDe,"A",{href:!0});var iPt=s(WV);dyo=r(iPt,"OwlViTFeatureExtractor"),iPt.forEach(t),myo=r(uDe," (OWL-ViT model)"),uDe.forEach(t),cyo=i(Q),Dp=n(Q,"LI",{});var pDe=s(Dp);z_e=n(pDe,"STRONG",{});var dPt=s(z_e);fyo=r(dPt,"perceiver"),dPt.forEach(t),gyo=r(pDe," \u2014 "),UV=n(pDe,"A",{href:!0});var mPt=s(UV);hyo=r(mPt,"PerceiverFeatureExtractor"),mPt.forEach(t),uyo=r(pDe," (Perceiver model)"),pDe.forEach(t),pyo=i(Q),Gp=n(Q,"LI",{});var _De=s(Gp);Q_e=n(_De,"STRONG",{});var cPt=s(Q_e);_yo=r(cPt,"poolformer"),cPt.forEach(t),byo=r(_De," \u2014 "),HV=n(_De,"A",{href:!0});var fPt=s(HV);vyo=r(fPt,"PoolFormerFeatureExtractor"),fPt.forEach(t),Fyo=r(_De," (PoolFormer model)"),_De.forEach(t),Tyo=i(Q),Op=n(Q,"LI",{});var bDe=s(Op);W_e=n(bDe,"STRONG",{});var gPt=s(W_e);Myo=r(gPt,"regnet"),gPt.forEach(t),Eyo=r(bDe," \u2014 "),JV=n(bDe,"A",{href:!0});var hPt=s(JV);Cyo=r(hPt,"ConvNextFeatureExtractor"),hPt.forEach(t),wyo=r(bDe," (RegNet model)"),bDe.forEach(t),Ayo=i(Q),Vp=n(Q,"LI",{});var vDe=s(Vp);U_e=n(vDe,"STRONG",{});var uPt=s(U_e);Lyo=r(uPt,"resnet"),uPt.forEach(t),yyo=r(vDe," \u2014 "),YV=n(vDe,"A",{href:!0});var pPt=s(YV);xyo=r(pPt,"ConvNextFeatureExtractor"),pPt.forEach(t),$yo=r(vDe," (ResNet model)"),vDe.forEach(t),kyo=i(Q),Xp=n(Q,"LI",{});var FDe=s(Xp);H_e=n(FDe,"STRONG",{});var _Pt=s(H_e);Syo=r(_Pt,"segformer"),_Pt.forEach(t),Ryo=r(FDe," \u2014 "),ZV=n(FDe,"A",{href:!0});var bPt=s(ZV);Pyo=r(bPt,"SegformerFeatureExtractor"),bPt.forEach(t),Byo=r(FDe," (SegFormer model)"),FDe.forEach(t),Iyo=i(Q),zp=n(Q,"LI",{});var TDe=s(zp);J_e=n(TDe,"STRONG",{});var vPt=s(J_e);Nyo=r(vPt,"speech_to_text"),vPt.forEach(t),qyo=r(TDe," \u2014 "),KV=n(TDe,"A",{href:!0});var FPt=s(KV);jyo=r(FPt,"Speech2TextFeatureExtractor"),FPt.forEach(t),Dyo=r(TDe," (Speech2Text model)"),TDe.forEach(t),Gyo=i(Q),Qp=n(Q,"LI",{});var MDe=s(Qp);Y_e=n(MDe,"STRONG",{});var TPt=s(Y_e);Oyo=r(TPt,"swin"),TPt.forEach(t),Vyo=r(MDe," \u2014 "),eX=n(MDe,"A",{href:!0});var MPt=s(eX);Xyo=r(MPt,"ViTFeatureExtractor"),MPt.forEach(t),zyo=r(MDe," (Swin Transformer model)"),MDe.forEach(t),Qyo=i(Q),Wp=n(Q,"LI",{});var EDe=s(Wp);Z_e=n(EDe,"STRONG",{});var EPt=s(Z_e);Wyo=r(EPt,"swinv2"),EPt.forEach(t),Uyo=r(EDe," \u2014 "),oX=n(EDe,"A",{href:!0});var CPt=s(oX);Hyo=r(CPt,"ViTFeatureExtractor"),CPt.forEach(t),Jyo=r(EDe," (Swin Transformer V2 model)"),EDe.forEach(t),Yyo=i(Q),Up=n(Q,"LI",{});var CDe=s(Up);K_e=n(CDe,"STRONG",{});var wPt=s(K_e);Zyo=r(wPt,"table-transformer"),wPt.forEach(t),Kyo=r(CDe," \u2014 "),rX=n(CDe,"A",{href:!0});var APt=s(rX);e9o=r(APt,"DetrFeatureExtractor"),APt.forEach(t),o9o=r(CDe," (Table Transformer model)"),CDe.forEach(t),r9o=i(Q),Hp=n(Q,"LI",{});var wDe=s(Hp);e1e=n(wDe,"STRONG",{});var LPt=s(e1e);t9o=r(LPt,"van"),LPt.forEach(t),a9o=r(wDe," \u2014 "),tX=n(wDe,"A",{href:!0});var yPt=s(tX);n9o=r(yPt,"ConvNextFeatureExtractor"),yPt.forEach(t),s9o=r(wDe," (VAN model)"),wDe.forEach(t),l9o=i(Q),Jp=n(Q,"LI",{});var ADe=s(Jp);o1e=n(ADe,"STRONG",{});var xPt=s(o1e);i9o=r(xPt,"videomae"),xPt.forEach(t),d9o=r(ADe," \u2014 "),aX=n(ADe,"A",{href:!0});var $Pt=s(aX);m9o=r($Pt,"VideoMAEFeatureExtractor"),$Pt.forEach(t),c9o=r(ADe," (VideoMAE model)"),ADe.forEach(t),f9o=i(Q),Yp=n(Q,"LI",{});var LDe=s(Yp);r1e=n(LDe,"STRONG",{});var kPt=s(r1e);g9o=r(kPt,"vilt"),kPt.forEach(t),h9o=r(LDe," \u2014 "),nX=n(LDe,"A",{href:!0});var SPt=s(nX);u9o=r(SPt,"ViltFeatureExtractor"),SPt.forEach(t),p9o=r(LDe," (ViLT model)"),LDe.forEach(t),_9o=i(Q),Zp=n(Q,"LI",{});var yDe=s(Zp);t1e=n(yDe,"STRONG",{});var RPt=s(t1e);b9o=r(RPt,"vit"),RPt.forEach(t),v9o=r(yDe," \u2014 "),sX=n(yDe,"A",{href:!0});var PPt=s(sX);F9o=r(PPt,"ViTFeatureExtractor"),PPt.forEach(t),T9o=r(yDe," (ViT model)"),yDe.forEach(t),M9o=i(Q),Kp=n(Q,"LI",{});var xDe=s(Kp);a1e=n(xDe,"STRONG",{});var BPt=s(a1e);E9o=r(BPt,"vit_mae"),BPt.forEach(t),C9o=r(xDe," \u2014 "),lX=n(xDe,"A",{href:!0});var IPt=s(lX);w9o=r(IPt,"ViTFeatureExtractor"),IPt.forEach(t),A9o=r(xDe," (ViTMAE model)"),xDe.forEach(t),L9o=i(Q),e_=n(Q,"LI",{});var $De=s(e_);n1e=n($De,"STRONG",{});var NPt=s(n1e);y9o=r(NPt,"vit_msn"),NPt.forEach(t),x9o=r($De," \u2014 "),iX=n($De,"A",{href:!0});var qPt=s(iX);$9o=r(qPt,"ViTFeatureExtractor"),qPt.forEach(t),k9o=r($De," (ViTMSN model)"),$De.forEach(t),S9o=i(Q),o_=n(Q,"LI",{});var kDe=s(o_);s1e=n(kDe,"STRONG",{});var jPt=s(s1e);R9o=r(jPt,"wav2vec2"),jPt.forEach(t),P9o=r(kDe," \u2014 "),dX=n(kDe,"A",{href:!0});var DPt=s(dX);B9o=r(DPt,"Wav2Vec2FeatureExtractor"),DPt.forEach(t),I9o=r(kDe," (Wav2Vec2 model)"),kDe.forEach(t),N9o=i(Q),r_=n(Q,"LI",{});var SDe=s(r_);l1e=n(SDe,"STRONG",{});var GPt=s(l1e);q9o=r(GPt,"wav2vec2-conformer"),GPt.forEach(t),j9o=r(SDe," \u2014 "),mX=n(SDe,"A",{href:!0});var OPt=s(mX);D9o=r(OPt,"Wav2Vec2FeatureExtractor"),OPt.forEach(t),G9o=r(SDe," (Wav2Vec2-Conformer model)"),SDe.forEach(t),O9o=i(Q),t_=n(Q,"LI",{});var RDe=s(t_);i1e=n(RDe,"STRONG",{});var VPt=s(i1e);V9o=r(VPt,"whisper"),VPt.forEach(t),X9o=r(RDe," \u2014 "),cX=n(RDe,"A",{href:!0});var XPt=s(cX);z9o=r(XPt,"WhisperFeatureExtractor"),XPt.forEach(t),Q9o=r(RDe," (Whisper model)"),RDe.forEach(t),W9o=i(Q),a_=n(Q,"LI",{});var PDe=s(a_);d1e=n(PDe,"STRONG",{});var zPt=s(d1e);U9o=r(zPt,"xclip"),zPt.forEach(t),H9o=r(PDe," \u2014 "),fX=n(PDe,"A",{href:!0});var QPt=s(fX);J9o=r(QPt,"CLIPFeatureExtractor"),QPt.forEach(t),Y9o=r(PDe," (X-CLIP model)"),PDe.forEach(t),Z9o=i(Q),n_=n(Q,"LI",{});var BDe=s(n_);m1e=n(BDe,"STRONG",{});var WPt=s(m1e);K9o=r(WPt,"yolos"),WPt.forEach(t),exo=r(BDe," \u2014 "),gX=n(BDe,"A",{href:!0});var UPt=s(gX);oxo=r(UPt,"YolosFeatureExtractor"),UPt.forEach(t),rxo=r(BDe," (YOLOS model)"),BDe.forEach(t),Q.forEach(t),txo=i(wa),T(s_.$$.fragment,wa),axo=i(wa),T(l_.$$.fragment,wa),wa.forEach(t),nxo=i(Nl),i_=n(Nl,"DIV",{class:!0});var bso=s(i_);T(R$.$$.fragment,bso),sxo=i(bso),c1e=n(bso,"P",{});var HPt=s(c1e);lxo=r(HPt,"Register a new feature extractor for this class."),HPt.forEach(t),bso.forEach(t),Nl.forEach(t),tao=i(c),kd=n(c,"H2",{class:!0});var vso=s(kd);d_=n(vso,"A",{id:!0,class:!0,href:!0});var JPt=s(d_);f1e=n(JPt,"SPAN",{});var YPt=s(f1e);T(P$.$$.fragment,YPt),YPt.forEach(t),JPt.forEach(t),ixo=i(vso),g1e=n(vso,"SPAN",{});var ZPt=s(g1e);dxo=r(ZPt,"AutoProcessor"),ZPt.forEach(t),vso.forEach(t),aao=i(c),Bo=n(c,"DIV",{class:!0});var ql=s(Bo);T(B$.$$.fragment,ql),mxo=i(ql),I$=n(ql,"P",{});var Fso=s(I$);cxo=r(Fso,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),hX=n(Fso,"A",{href:!0});var KPt=s(hX);fxo=r(KPt,"AutoProcessor.from_pretrained()"),KPt.forEach(t),gxo=r(Fso," class method."),Fso.forEach(t),hxo=i(ql),N$=n(ql,"P",{});var Tso=s(N$);uxo=r(Tso,"This class cannot be instantiated directly using "),h1e=n(Tso,"CODE",{});var eBt=s(h1e);pxo=r(eBt,"__init__()"),eBt.forEach(t),_xo=r(Tso," (throws an error)."),Tso.forEach(t),bxo=i(ql),Ze=n(ql,"DIV",{class:!0});var Aa=s(Ze);T(q$.$$.fragment,Aa),vxo=i(Aa),u1e=n(Aa,"P",{});var oBt=s(u1e);Fxo=r(oBt,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),oBt.forEach(t),Txo=i(Aa),Sd=n(Aa,"P",{});var ume=s(Sd);Mxo=r(ume,"The processor class to instantiate is selected based on the "),p1e=n(ume,"CODE",{});var rBt=s(p1e);Exo=r(rBt,"model_type"),rBt.forEach(t),Cxo=r(ume,` property of the config object (either
passed as an argument or loaded from `),_1e=n(ume,"CODE",{});var tBt=s(_1e);wxo=r(tBt,"pretrained_model_name_or_path"),tBt.forEach(t),Axo=r(ume," if possible):"),ume.forEach(t),Lxo=i(Aa),se=n(Aa,"UL",{});var de=s(se);m_=n(de,"LI",{});var IDe=s(m_);b1e=n(IDe,"STRONG",{});var aBt=s(b1e);yxo=r(aBt,"clip"),aBt.forEach(t),xxo=r(IDe," \u2014 "),uX=n(IDe,"A",{href:!0});var nBt=s(uX);$xo=r(nBt,"CLIPProcessor"),nBt.forEach(t),kxo=r(IDe," (CLIP model)"),IDe.forEach(t),Sxo=i(de),c_=n(de,"LI",{});var NDe=s(c_);v1e=n(NDe,"STRONG",{});var sBt=s(v1e);Rxo=r(sBt,"clipseg"),sBt.forEach(t),Pxo=r(NDe," \u2014 "),pX=n(NDe,"A",{href:!0});var lBt=s(pX);Bxo=r(lBt,"CLIPSegProcessor"),lBt.forEach(t),Ixo=r(NDe," (CLIPSeg model)"),NDe.forEach(t),Nxo=i(de),f_=n(de,"LI",{});var qDe=s(f_);F1e=n(qDe,"STRONG",{});var iBt=s(F1e);qxo=r(iBt,"flava"),iBt.forEach(t),jxo=r(qDe," \u2014 "),_X=n(qDe,"A",{href:!0});var dBt=s(_X);Dxo=r(dBt,"FlavaProcessor"),dBt.forEach(t),Gxo=r(qDe," (FLAVA model)"),qDe.forEach(t),Oxo=i(de),g_=n(de,"LI",{});var jDe=s(g_);T1e=n(jDe,"STRONG",{});var mBt=s(T1e);Vxo=r(mBt,"groupvit"),mBt.forEach(t),Xxo=r(jDe," \u2014 "),bX=n(jDe,"A",{href:!0});var cBt=s(bX);zxo=r(cBt,"CLIPProcessor"),cBt.forEach(t),Qxo=r(jDe," (GroupViT model)"),jDe.forEach(t),Wxo=i(de),h_=n(de,"LI",{});var DDe=s(h_);M1e=n(DDe,"STRONG",{});var fBt=s(M1e);Uxo=r(fBt,"layoutlmv2"),fBt.forEach(t),Hxo=r(DDe," \u2014 "),vX=n(DDe,"A",{href:!0});var gBt=s(vX);Jxo=r(gBt,"LayoutLMv2Processor"),gBt.forEach(t),Yxo=r(DDe," (LayoutLMv2 model)"),DDe.forEach(t),Zxo=i(de),u_=n(de,"LI",{});var GDe=s(u_);E1e=n(GDe,"STRONG",{});var hBt=s(E1e);Kxo=r(hBt,"layoutlmv3"),hBt.forEach(t),e$o=r(GDe," \u2014 "),FX=n(GDe,"A",{href:!0});var uBt=s(FX);o$o=r(uBt,"LayoutLMv3Processor"),uBt.forEach(t),r$o=r(GDe," (LayoutLMv3 model)"),GDe.forEach(t),t$o=i(de),p_=n(de,"LI",{});var ODe=s(p_);C1e=n(ODe,"STRONG",{});var pBt=s(C1e);a$o=r(pBt,"layoutxlm"),pBt.forEach(t),n$o=r(ODe," \u2014 "),TX=n(ODe,"A",{href:!0});var _Bt=s(TX);s$o=r(_Bt,"LayoutXLMProcessor"),_Bt.forEach(t),l$o=r(ODe," (LayoutXLM model)"),ODe.forEach(t),i$o=i(de),__=n(de,"LI",{});var VDe=s(__);w1e=n(VDe,"STRONG",{});var bBt=s(w1e);d$o=r(bBt,"markuplm"),bBt.forEach(t),m$o=r(VDe," \u2014 "),MX=n(VDe,"A",{href:!0});var vBt=s(MX);c$o=r(vBt,"MarkupLMProcessor"),vBt.forEach(t),f$o=r(VDe," (MarkupLM model)"),VDe.forEach(t),g$o=i(de),b_=n(de,"LI",{});var XDe=s(b_);A1e=n(XDe,"STRONG",{});var FBt=s(A1e);h$o=r(FBt,"owlvit"),FBt.forEach(t),u$o=r(XDe," \u2014 "),EX=n(XDe,"A",{href:!0});var TBt=s(EX);p$o=r(TBt,"OwlViTProcessor"),TBt.forEach(t),_$o=r(XDe," (OWL-ViT model)"),XDe.forEach(t),b$o=i(de),v_=n(de,"LI",{});var zDe=s(v_);L1e=n(zDe,"STRONG",{});var MBt=s(L1e);v$o=r(MBt,"sew"),MBt.forEach(t),F$o=r(zDe," \u2014 "),CX=n(zDe,"A",{href:!0});var EBt=s(CX);T$o=r(EBt,"Wav2Vec2Processor"),EBt.forEach(t),M$o=r(zDe," (SEW model)"),zDe.forEach(t),E$o=i(de),F_=n(de,"LI",{});var QDe=s(F_);y1e=n(QDe,"STRONG",{});var CBt=s(y1e);C$o=r(CBt,"sew-d"),CBt.forEach(t),w$o=r(QDe," \u2014 "),wX=n(QDe,"A",{href:!0});var wBt=s(wX);A$o=r(wBt,"Wav2Vec2Processor"),wBt.forEach(t),L$o=r(QDe," (SEW-D model)"),QDe.forEach(t),y$o=i(de),T_=n(de,"LI",{});var WDe=s(T_);x1e=n(WDe,"STRONG",{});var ABt=s(x1e);x$o=r(ABt,"speech_to_text"),ABt.forEach(t),$$o=r(WDe," \u2014 "),AX=n(WDe,"A",{href:!0});var LBt=s(AX);k$o=r(LBt,"Speech2TextProcessor"),LBt.forEach(t),S$o=r(WDe," (Speech2Text model)"),WDe.forEach(t),R$o=i(de),M_=n(de,"LI",{});var UDe=s(M_);$1e=n(UDe,"STRONG",{});var yBt=s($1e);P$o=r(yBt,"speech_to_text_2"),yBt.forEach(t),B$o=r(UDe," \u2014 "),LX=n(UDe,"A",{href:!0});var xBt=s(LX);I$o=r(xBt,"Speech2Text2Processor"),xBt.forEach(t),N$o=r(UDe," (Speech2Text2 model)"),UDe.forEach(t),q$o=i(de),E_=n(de,"LI",{});var HDe=s(E_);k1e=n(HDe,"STRONG",{});var $Bt=s(k1e);j$o=r($Bt,"trocr"),$Bt.forEach(t),D$o=r(HDe," \u2014 "),yX=n(HDe,"A",{href:!0});var kBt=s(yX);G$o=r(kBt,"TrOCRProcessor"),kBt.forEach(t),O$o=r(HDe," (TrOCR model)"),HDe.forEach(t),V$o=i(de),C_=n(de,"LI",{});var JDe=s(C_);S1e=n(JDe,"STRONG",{});var SBt=s(S1e);X$o=r(SBt,"unispeech"),SBt.forEach(t),z$o=r(JDe," \u2014 "),xX=n(JDe,"A",{href:!0});var RBt=s(xX);Q$o=r(RBt,"Wav2Vec2Processor"),RBt.forEach(t),W$o=r(JDe," (UniSpeech model)"),JDe.forEach(t),U$o=i(de),w_=n(de,"LI",{});var YDe=s(w_);R1e=n(YDe,"STRONG",{});var PBt=s(R1e);H$o=r(PBt,"unispeech-sat"),PBt.forEach(t),J$o=r(YDe," \u2014 "),$X=n(YDe,"A",{href:!0});var BBt=s($X);Y$o=r(BBt,"Wav2Vec2Processor"),BBt.forEach(t),Z$o=r(YDe," (UniSpeechSat model)"),YDe.forEach(t),K$o=i(de),A_=n(de,"LI",{});var ZDe=s(A_);P1e=n(ZDe,"STRONG",{});var IBt=s(P1e);eko=r(IBt,"vilt"),IBt.forEach(t),oko=r(ZDe," \u2014 "),kX=n(ZDe,"A",{href:!0});var NBt=s(kX);rko=r(NBt,"ViltProcessor"),NBt.forEach(t),tko=r(ZDe," (ViLT model)"),ZDe.forEach(t),ako=i(de),L_=n(de,"LI",{});var KDe=s(L_);B1e=n(KDe,"STRONG",{});var qBt=s(B1e);nko=r(qBt,"vision-text-dual-encoder"),qBt.forEach(t),sko=r(KDe," \u2014 "),SX=n(KDe,"A",{href:!0});var jBt=s(SX);lko=r(jBt,"VisionTextDualEncoderProcessor"),jBt.forEach(t),iko=r(KDe," (VisionTextDualEncoder model)"),KDe.forEach(t),dko=i(de),y_=n(de,"LI",{});var eGe=s(y_);I1e=n(eGe,"STRONG",{});var DBt=s(I1e);mko=r(DBt,"wav2vec2"),DBt.forEach(t),cko=r(eGe," \u2014 "),RX=n(eGe,"A",{href:!0});var GBt=s(RX);fko=r(GBt,"Wav2Vec2Processor"),GBt.forEach(t),gko=r(eGe," (Wav2Vec2 model)"),eGe.forEach(t),hko=i(de),x_=n(de,"LI",{});var oGe=s(x_);N1e=n(oGe,"STRONG",{});var OBt=s(N1e);uko=r(OBt,"wav2vec2-conformer"),OBt.forEach(t),pko=r(oGe," \u2014 "),PX=n(oGe,"A",{href:!0});var VBt=s(PX);_ko=r(VBt,"Wav2Vec2Processor"),VBt.forEach(t),bko=r(oGe," (Wav2Vec2-Conformer model)"),oGe.forEach(t),vko=i(de),$_=n(de,"LI",{});var rGe=s($_);q1e=n(rGe,"STRONG",{});var XBt=s(q1e);Fko=r(XBt,"wavlm"),XBt.forEach(t),Tko=r(rGe," \u2014 "),BX=n(rGe,"A",{href:!0});var zBt=s(BX);Mko=r(zBt,"Wav2Vec2Processor"),zBt.forEach(t),Eko=r(rGe," (WavLM model)"),rGe.forEach(t),Cko=i(de),k_=n(de,"LI",{});var tGe=s(k_);j1e=n(tGe,"STRONG",{});var QBt=s(j1e);wko=r(QBt,"whisper"),QBt.forEach(t),Ako=r(tGe," \u2014 "),IX=n(tGe,"A",{href:!0});var WBt=s(IX);Lko=r(WBt,"WhisperProcessor"),WBt.forEach(t),yko=r(tGe," (Whisper model)"),tGe.forEach(t),xko=i(de),S_=n(de,"LI",{});var aGe=s(S_);D1e=n(aGe,"STRONG",{});var UBt=s(D1e);$ko=r(UBt,"xclip"),UBt.forEach(t),kko=r(aGe," \u2014 "),NX=n(aGe,"A",{href:!0});var HBt=s(NX);Sko=r(HBt,"XCLIPProcessor"),HBt.forEach(t),Rko=r(aGe," (X-CLIP model)"),aGe.forEach(t),de.forEach(t),Pko=i(Aa),T(R_.$$.fragment,Aa),Bko=i(Aa),T(P_.$$.fragment,Aa),Aa.forEach(t),Iko=i(ql),B_=n(ql,"DIV",{class:!0});var Mso=s(B_);T(j$.$$.fragment,Mso),Nko=i(Mso),G1e=n(Mso,"P",{});var JBt=s(G1e);qko=r(JBt,"Register a new processor for this class."),JBt.forEach(t),Mso.forEach(t),ql.forEach(t),nao=i(c),Rd=n(c,"H2",{class:!0});var Eso=s(Rd);I_=n(Eso,"A",{id:!0,class:!0,href:!0});var YBt=s(I_);O1e=n(YBt,"SPAN",{});var ZBt=s(O1e);T(D$.$$.fragment,ZBt),ZBt.forEach(t),YBt.forEach(t),jko=i(Eso),V1e=n(Eso,"SPAN",{});var KBt=s(V1e);Dko=r(KBt,"AutoModel"),KBt.forEach(t),Eso.forEach(t),sao=i(c),Io=n(c,"DIV",{class:!0});var jl=s(Io);T(G$.$$.fragment,jl),Gko=i(jl),Pd=n(jl,"P",{});var pme=s(Pd);Oko=r(pme,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),qX=n(pme,"A",{href:!0});var eIt=s(qX);Vko=r(eIt,"from_pretrained()"),eIt.forEach(t),Xko=r(pme," class method or the "),jX=n(pme,"A",{href:!0});var oIt=s(jX);zko=r(oIt,"from_config()"),oIt.forEach(t),Qko=r(pme,` class
method.`),pme.forEach(t),Wko=i(jl),O$=n(jl,"P",{});var Cso=s(O$);Uko=r(Cso,"This class cannot be instantiated directly using "),X1e=n(Cso,"CODE",{});var rIt=s(X1e);Hko=r(rIt,"__init__()"),rIt.forEach(t),Jko=r(Cso," (throws an error)."),Cso.forEach(t),Yko=i(jl),Mt=n(jl,"DIV",{class:!0});var n9=s(Mt);T(V$.$$.fragment,n9),Zko=i(n9),z1e=n(n9,"P",{});var tIt=s(z1e);Kko=r(tIt,"Instantiates one of the base model classes of the library from a configuration."),tIt.forEach(t),eSo=i(n9),Bd=n(n9,"P",{});var _me=s(Bd);oSo=r(_me,`Note:
Loading a model from its configuration file does `),Q1e=n(_me,"STRONG",{});var aIt=s(Q1e);rSo=r(aIt,"not"),aIt.forEach(t),tSo=r(_me,` load the model weights. It only affects the
model\u2019s configuration. Use `),DX=n(_me,"A",{href:!0});var nIt=s(DX);aSo=r(nIt,"from_pretrained()"),nIt.forEach(t),nSo=r(_me," to load the model weights."),_me.forEach(t),sSo=i(n9),T(N_.$$.fragment,n9),n9.forEach(t),lSo=i(jl),Ke=n(jl,"DIV",{class:!0});var La=s(Ke);T(X$.$$.fragment,La),iSo=i(La),W1e=n(La,"P",{});var sIt=s(W1e);dSo=r(sIt,"Instantiate one of the base model classes of the library from a pretrained model."),sIt.forEach(t),mSo=i(La),nn=n(La,"P",{});var s9=s(nn);cSo=r(s9,"The model class to instantiate is selected based on the "),U1e=n(s9,"CODE",{});var lIt=s(U1e);fSo=r(lIt,"model_type"),lIt.forEach(t),gSo=r(s9,` property of the config object (either
passed as an argument or loaded from `),H1e=n(s9,"CODE",{});var iIt=s(H1e);hSo=r(iIt,"pretrained_model_name_or_path"),iIt.forEach(t),uSo=r(s9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),J1e=n(s9,"CODE",{});var dIt=s(J1e);pSo=r(dIt,"pretrained_model_name_or_path"),dIt.forEach(t),_So=r(s9,":"),s9.forEach(t),bSo=i(La),y=n(La,"UL",{});var x=s(y);q_=n(x,"LI",{});var nGe=s(q_);Y1e=n(nGe,"STRONG",{});var mIt=s(Y1e);vSo=r(mIt,"albert"),mIt.forEach(t),FSo=r(nGe," \u2014 "),GX=n(nGe,"A",{href:!0});var cIt=s(GX);TSo=r(cIt,"AlbertModel"),cIt.forEach(t),MSo=r(nGe," (ALBERT model)"),nGe.forEach(t),ESo=i(x),j_=n(x,"LI",{});var sGe=s(j_);Z1e=n(sGe,"STRONG",{});var fIt=s(Z1e);CSo=r(fIt,"bart"),fIt.forEach(t),wSo=r(sGe," \u2014 "),OX=n(sGe,"A",{href:!0});var gIt=s(OX);ASo=r(gIt,"BartModel"),gIt.forEach(t),LSo=r(sGe," (BART model)"),sGe.forEach(t),ySo=i(x),D_=n(x,"LI",{});var lGe=s(D_);K1e=n(lGe,"STRONG",{});var hIt=s(K1e);xSo=r(hIt,"beit"),hIt.forEach(t),$So=r(lGe," \u2014 "),VX=n(lGe,"A",{href:!0});var uIt=s(VX);kSo=r(uIt,"BeitModel"),uIt.forEach(t),SSo=r(lGe," (BEiT model)"),lGe.forEach(t),RSo=i(x),G_=n(x,"LI",{});var iGe=s(G_);e2e=n(iGe,"STRONG",{});var pIt=s(e2e);PSo=r(pIt,"bert"),pIt.forEach(t),BSo=r(iGe," \u2014 "),XX=n(iGe,"A",{href:!0});var _It=s(XX);ISo=r(_It,"BertModel"),_It.forEach(t),NSo=r(iGe," (BERT model)"),iGe.forEach(t),qSo=i(x),O_=n(x,"LI",{});var dGe=s(O_);o2e=n(dGe,"STRONG",{});var bIt=s(o2e);jSo=r(bIt,"bert-generation"),bIt.forEach(t),DSo=r(dGe," \u2014 "),zX=n(dGe,"A",{href:!0});var vIt=s(zX);GSo=r(vIt,"BertGenerationEncoder"),vIt.forEach(t),OSo=r(dGe," (Bert Generation model)"),dGe.forEach(t),VSo=i(x),V_=n(x,"LI",{});var mGe=s(V_);r2e=n(mGe,"STRONG",{});var FIt=s(r2e);XSo=r(FIt,"big_bird"),FIt.forEach(t),zSo=r(mGe," \u2014 "),QX=n(mGe,"A",{href:!0});var TIt=s(QX);QSo=r(TIt,"BigBirdModel"),TIt.forEach(t),WSo=r(mGe," (BigBird model)"),mGe.forEach(t),USo=i(x),X_=n(x,"LI",{});var cGe=s(X_);t2e=n(cGe,"STRONG",{});var MIt=s(t2e);HSo=r(MIt,"bigbird_pegasus"),MIt.forEach(t),JSo=r(cGe," \u2014 "),WX=n(cGe,"A",{href:!0});var EIt=s(WX);YSo=r(EIt,"BigBirdPegasusModel"),EIt.forEach(t),ZSo=r(cGe," (BigBird-Pegasus model)"),cGe.forEach(t),KSo=i(x),z_=n(x,"LI",{});var fGe=s(z_);a2e=n(fGe,"STRONG",{});var CIt=s(a2e);eRo=r(CIt,"blenderbot"),CIt.forEach(t),oRo=r(fGe," \u2014 "),UX=n(fGe,"A",{href:!0});var wIt=s(UX);rRo=r(wIt,"BlenderbotModel"),wIt.forEach(t),tRo=r(fGe," (Blenderbot model)"),fGe.forEach(t),aRo=i(x),Q_=n(x,"LI",{});var gGe=s(Q_);n2e=n(gGe,"STRONG",{});var AIt=s(n2e);nRo=r(AIt,"blenderbot-small"),AIt.forEach(t),sRo=r(gGe," \u2014 "),HX=n(gGe,"A",{href:!0});var LIt=s(HX);lRo=r(LIt,"BlenderbotSmallModel"),LIt.forEach(t),iRo=r(gGe," (BlenderbotSmall model)"),gGe.forEach(t),dRo=i(x),W_=n(x,"LI",{});var hGe=s(W_);s2e=n(hGe,"STRONG",{});var yIt=s(s2e);mRo=r(yIt,"bloom"),yIt.forEach(t),cRo=r(hGe," \u2014 "),JX=n(hGe,"A",{href:!0});var xIt=s(JX);fRo=r(xIt,"BloomModel"),xIt.forEach(t),gRo=r(hGe," (BLOOM model)"),hGe.forEach(t),hRo=i(x),U_=n(x,"LI",{});var uGe=s(U_);l2e=n(uGe,"STRONG",{});var $It=s(l2e);uRo=r($It,"camembert"),$It.forEach(t),pRo=r(uGe," \u2014 "),YX=n(uGe,"A",{href:!0});var kIt=s(YX);_Ro=r(kIt,"CamembertModel"),kIt.forEach(t),bRo=r(uGe," (CamemBERT model)"),uGe.forEach(t),vRo=i(x),H_=n(x,"LI",{});var pGe=s(H_);i2e=n(pGe,"STRONG",{});var SIt=s(i2e);FRo=r(SIt,"canine"),SIt.forEach(t),TRo=r(pGe," \u2014 "),ZX=n(pGe,"A",{href:!0});var RIt=s(ZX);MRo=r(RIt,"CanineModel"),RIt.forEach(t),ERo=r(pGe," (CANINE model)"),pGe.forEach(t),CRo=i(x),J_=n(x,"LI",{});var _Ge=s(J_);d2e=n(_Ge,"STRONG",{});var PIt=s(d2e);wRo=r(PIt,"clip"),PIt.forEach(t),ARo=r(_Ge," \u2014 "),KX=n(_Ge,"A",{href:!0});var BIt=s(KX);LRo=r(BIt,"CLIPModel"),BIt.forEach(t),yRo=r(_Ge," (CLIP model)"),_Ge.forEach(t),xRo=i(x),Y_=n(x,"LI",{});var bGe=s(Y_);m2e=n(bGe,"STRONG",{});var IIt=s(m2e);$Ro=r(IIt,"clipseg"),IIt.forEach(t),kRo=r(bGe," \u2014 "),ez=n(bGe,"A",{href:!0});var NIt=s(ez);SRo=r(NIt,"CLIPSegModel"),NIt.forEach(t),RRo=r(bGe," (CLIPSeg model)"),bGe.forEach(t),PRo=i(x),Z_=n(x,"LI",{});var vGe=s(Z_);c2e=n(vGe,"STRONG",{});var qIt=s(c2e);BRo=r(qIt,"codegen"),qIt.forEach(t),IRo=r(vGe," \u2014 "),oz=n(vGe,"A",{href:!0});var jIt=s(oz);NRo=r(jIt,"CodeGenModel"),jIt.forEach(t),qRo=r(vGe," (CodeGen model)"),vGe.forEach(t),jRo=i(x),K_=n(x,"LI",{});var FGe=s(K_);f2e=n(FGe,"STRONG",{});var DIt=s(f2e);DRo=r(DIt,"conditional_detr"),DIt.forEach(t),GRo=r(FGe," \u2014 "),rz=n(FGe,"A",{href:!0});var GIt=s(rz);ORo=r(GIt,"ConditionalDetrModel"),GIt.forEach(t),VRo=r(FGe," (Conditional DETR model)"),FGe.forEach(t),XRo=i(x),e1=n(x,"LI",{});var TGe=s(e1);g2e=n(TGe,"STRONG",{});var OIt=s(g2e);zRo=r(OIt,"convbert"),OIt.forEach(t),QRo=r(TGe," \u2014 "),tz=n(TGe,"A",{href:!0});var VIt=s(tz);WRo=r(VIt,"ConvBertModel"),VIt.forEach(t),URo=r(TGe," (ConvBERT model)"),TGe.forEach(t),HRo=i(x),o1=n(x,"LI",{});var MGe=s(o1);h2e=n(MGe,"STRONG",{});var XIt=s(h2e);JRo=r(XIt,"convnext"),XIt.forEach(t),YRo=r(MGe," \u2014 "),az=n(MGe,"A",{href:!0});var zIt=s(az);ZRo=r(zIt,"ConvNextModel"),zIt.forEach(t),KRo=r(MGe," (ConvNeXT model)"),MGe.forEach(t),ePo=i(x),r1=n(x,"LI",{});var EGe=s(r1);u2e=n(EGe,"STRONG",{});var QIt=s(u2e);oPo=r(QIt,"ctrl"),QIt.forEach(t),rPo=r(EGe," \u2014 "),nz=n(EGe,"A",{href:!0});var WIt=s(nz);tPo=r(WIt,"CTRLModel"),WIt.forEach(t),aPo=r(EGe," (CTRL model)"),EGe.forEach(t),nPo=i(x),t1=n(x,"LI",{});var CGe=s(t1);p2e=n(CGe,"STRONG",{});var UIt=s(p2e);sPo=r(UIt,"cvt"),UIt.forEach(t),lPo=r(CGe," \u2014 "),sz=n(CGe,"A",{href:!0});var HIt=s(sz);iPo=r(HIt,"CvtModel"),HIt.forEach(t),dPo=r(CGe," (CvT model)"),CGe.forEach(t),mPo=i(x),a1=n(x,"LI",{});var wGe=s(a1);_2e=n(wGe,"STRONG",{});var JIt=s(_2e);cPo=r(JIt,"data2vec-audio"),JIt.forEach(t),fPo=r(wGe," \u2014 "),lz=n(wGe,"A",{href:!0});var YIt=s(lz);gPo=r(YIt,"Data2VecAudioModel"),YIt.forEach(t),hPo=r(wGe," (Data2VecAudio model)"),wGe.forEach(t),uPo=i(x),n1=n(x,"LI",{});var AGe=s(n1);b2e=n(AGe,"STRONG",{});var ZIt=s(b2e);pPo=r(ZIt,"data2vec-text"),ZIt.forEach(t),_Po=r(AGe," \u2014 "),iz=n(AGe,"A",{href:!0});var KIt=s(iz);bPo=r(KIt,"Data2VecTextModel"),KIt.forEach(t),vPo=r(AGe," (Data2VecText model)"),AGe.forEach(t),FPo=i(x),s1=n(x,"LI",{});var LGe=s(s1);v2e=n(LGe,"STRONG",{});var eNt=s(v2e);TPo=r(eNt,"data2vec-vision"),eNt.forEach(t),MPo=r(LGe," \u2014 "),dz=n(LGe,"A",{href:!0});var oNt=s(dz);EPo=r(oNt,"Data2VecVisionModel"),oNt.forEach(t),CPo=r(LGe," (Data2VecVision model)"),LGe.forEach(t),wPo=i(x),l1=n(x,"LI",{});var yGe=s(l1);F2e=n(yGe,"STRONG",{});var rNt=s(F2e);APo=r(rNt,"deberta"),rNt.forEach(t),LPo=r(yGe," \u2014 "),mz=n(yGe,"A",{href:!0});var tNt=s(mz);yPo=r(tNt,"DebertaModel"),tNt.forEach(t),xPo=r(yGe," (DeBERTa model)"),yGe.forEach(t),$Po=i(x),i1=n(x,"LI",{});var xGe=s(i1);T2e=n(xGe,"STRONG",{});var aNt=s(T2e);kPo=r(aNt,"deberta-v2"),aNt.forEach(t),SPo=r(xGe," \u2014 "),cz=n(xGe,"A",{href:!0});var nNt=s(cz);RPo=r(nNt,"DebertaV2Model"),nNt.forEach(t),PPo=r(xGe," (DeBERTa-v2 model)"),xGe.forEach(t),BPo=i(x),d1=n(x,"LI",{});var $Ge=s(d1);M2e=n($Ge,"STRONG",{});var sNt=s(M2e);IPo=r(sNt,"decision_transformer"),sNt.forEach(t),NPo=r($Ge," \u2014 "),fz=n($Ge,"A",{href:!0});var lNt=s(fz);qPo=r(lNt,"DecisionTransformerModel"),lNt.forEach(t),jPo=r($Ge," (Decision Transformer model)"),$Ge.forEach(t),DPo=i(x),m1=n(x,"LI",{});var kGe=s(m1);E2e=n(kGe,"STRONG",{});var iNt=s(E2e);GPo=r(iNt,"deformable_detr"),iNt.forEach(t),OPo=r(kGe," \u2014 "),gz=n(kGe,"A",{href:!0});var dNt=s(gz);VPo=r(dNt,"DeformableDetrModel"),dNt.forEach(t),XPo=r(kGe," (Deformable DETR model)"),kGe.forEach(t),zPo=i(x),c1=n(x,"LI",{});var SGe=s(c1);C2e=n(SGe,"STRONG",{});var mNt=s(C2e);QPo=r(mNt,"deit"),mNt.forEach(t),WPo=r(SGe," \u2014 "),hz=n(SGe,"A",{href:!0});var cNt=s(hz);UPo=r(cNt,"DeiTModel"),cNt.forEach(t),HPo=r(SGe," (DeiT model)"),SGe.forEach(t),JPo=i(x),f1=n(x,"LI",{});var RGe=s(f1);w2e=n(RGe,"STRONG",{});var fNt=s(w2e);YPo=r(fNt,"detr"),fNt.forEach(t),ZPo=r(RGe," \u2014 "),uz=n(RGe,"A",{href:!0});var gNt=s(uz);KPo=r(gNt,"DetrModel"),gNt.forEach(t),eBo=r(RGe," (DETR model)"),RGe.forEach(t),oBo=i(x),g1=n(x,"LI",{});var PGe=s(g1);A2e=n(PGe,"STRONG",{});var hNt=s(A2e);rBo=r(hNt,"distilbert"),hNt.forEach(t),tBo=r(PGe," \u2014 "),pz=n(PGe,"A",{href:!0});var uNt=s(pz);aBo=r(uNt,"DistilBertModel"),uNt.forEach(t),nBo=r(PGe," (DistilBERT model)"),PGe.forEach(t),sBo=i(x),h1=n(x,"LI",{});var BGe=s(h1);L2e=n(BGe,"STRONG",{});var pNt=s(L2e);lBo=r(pNt,"donut-swin"),pNt.forEach(t),iBo=r(BGe," \u2014 "),_z=n(BGe,"A",{href:!0});var _Nt=s(_z);dBo=r(_Nt,"DonutSwinModel"),_Nt.forEach(t),mBo=r(BGe," (DonutSwin model)"),BGe.forEach(t),cBo=i(x),u1=n(x,"LI",{});var IGe=s(u1);y2e=n(IGe,"STRONG",{});var bNt=s(y2e);fBo=r(bNt,"dpr"),bNt.forEach(t),gBo=r(IGe," \u2014 "),bz=n(IGe,"A",{href:!0});var vNt=s(bz);hBo=r(vNt,"DPRQuestionEncoder"),vNt.forEach(t),uBo=r(IGe," (DPR model)"),IGe.forEach(t),pBo=i(x),p1=n(x,"LI",{});var NGe=s(p1);x2e=n(NGe,"STRONG",{});var FNt=s(x2e);_Bo=r(FNt,"dpt"),FNt.forEach(t),bBo=r(NGe," \u2014 "),vz=n(NGe,"A",{href:!0});var TNt=s(vz);vBo=r(TNt,"DPTModel"),TNt.forEach(t),FBo=r(NGe," (DPT model)"),NGe.forEach(t),TBo=i(x),_1=n(x,"LI",{});var qGe=s(_1);$2e=n(qGe,"STRONG",{});var MNt=s($2e);MBo=r(MNt,"electra"),MNt.forEach(t),EBo=r(qGe," \u2014 "),Fz=n(qGe,"A",{href:!0});var ENt=s(Fz);CBo=r(ENt,"ElectraModel"),ENt.forEach(t),wBo=r(qGe," (ELECTRA model)"),qGe.forEach(t),ABo=i(x),b1=n(x,"LI",{});var jGe=s(b1);k2e=n(jGe,"STRONG",{});var CNt=s(k2e);LBo=r(CNt,"ernie"),CNt.forEach(t),yBo=r(jGe," \u2014 "),Tz=n(jGe,"A",{href:!0});var wNt=s(Tz);xBo=r(wNt,"ErnieModel"),wNt.forEach(t),$Bo=r(jGe," (ERNIE model)"),jGe.forEach(t),kBo=i(x),v1=n(x,"LI",{});var DGe=s(v1);S2e=n(DGe,"STRONG",{});var ANt=s(S2e);SBo=r(ANt,"esm"),ANt.forEach(t),RBo=r(DGe," \u2014 "),Mz=n(DGe,"A",{href:!0});var LNt=s(Mz);PBo=r(LNt,"EsmModel"),LNt.forEach(t),BBo=r(DGe," (ESM model)"),DGe.forEach(t),IBo=i(x),F1=n(x,"LI",{});var GGe=s(F1);R2e=n(GGe,"STRONG",{});var yNt=s(R2e);NBo=r(yNt,"flaubert"),yNt.forEach(t),qBo=r(GGe," \u2014 "),Ez=n(GGe,"A",{href:!0});var xNt=s(Ez);jBo=r(xNt,"FlaubertModel"),xNt.forEach(t),DBo=r(GGe," (FlauBERT model)"),GGe.forEach(t),GBo=i(x),T1=n(x,"LI",{});var OGe=s(T1);P2e=n(OGe,"STRONG",{});var $Nt=s(P2e);OBo=r($Nt,"flava"),$Nt.forEach(t),VBo=r(OGe," \u2014 "),Cz=n(OGe,"A",{href:!0});var kNt=s(Cz);XBo=r(kNt,"FlavaModel"),kNt.forEach(t),zBo=r(OGe," (FLAVA model)"),OGe.forEach(t),QBo=i(x),M1=n(x,"LI",{});var VGe=s(M1);B2e=n(VGe,"STRONG",{});var SNt=s(B2e);WBo=r(SNt,"fnet"),SNt.forEach(t),UBo=r(VGe," \u2014 "),wz=n(VGe,"A",{href:!0});var RNt=s(wz);HBo=r(RNt,"FNetModel"),RNt.forEach(t),JBo=r(VGe," (FNet model)"),VGe.forEach(t),YBo=i(x),E1=n(x,"LI",{});var XGe=s(E1);I2e=n(XGe,"STRONG",{});var PNt=s(I2e);ZBo=r(PNt,"fsmt"),PNt.forEach(t),KBo=r(XGe," \u2014 "),Az=n(XGe,"A",{href:!0});var BNt=s(Az);eIo=r(BNt,"FSMTModel"),BNt.forEach(t),oIo=r(XGe," (FairSeq Machine-Translation model)"),XGe.forEach(t),rIo=i(x),$l=n(x,"LI",{});var EN=s($l);N2e=n(EN,"STRONG",{});var INt=s(N2e);tIo=r(INt,"funnel"),INt.forEach(t),aIo=r(EN," \u2014 "),Lz=n(EN,"A",{href:!0});var NNt=s(Lz);nIo=r(NNt,"FunnelModel"),NNt.forEach(t),sIo=r(EN," or "),yz=n(EN,"A",{href:!0});var qNt=s(yz);lIo=r(qNt,"FunnelBaseModel"),qNt.forEach(t),iIo=r(EN," (Funnel Transformer model)"),EN.forEach(t),dIo=i(x),C1=n(x,"LI",{});var zGe=s(C1);q2e=n(zGe,"STRONG",{});var jNt=s(q2e);mIo=r(jNt,"glpn"),jNt.forEach(t),cIo=r(zGe," \u2014 "),xz=n(zGe,"A",{href:!0});var DNt=s(xz);fIo=r(DNt,"GLPNModel"),DNt.forEach(t),gIo=r(zGe," (GLPN model)"),zGe.forEach(t),hIo=i(x),w1=n(x,"LI",{});var QGe=s(w1);j2e=n(QGe,"STRONG",{});var GNt=s(j2e);uIo=r(GNt,"gpt2"),GNt.forEach(t),pIo=r(QGe," \u2014 "),$z=n(QGe,"A",{href:!0});var ONt=s($z);_Io=r(ONt,"GPT2Model"),ONt.forEach(t),bIo=r(QGe," (OpenAI GPT-2 model)"),QGe.forEach(t),vIo=i(x),A1=n(x,"LI",{});var WGe=s(A1);D2e=n(WGe,"STRONG",{});var VNt=s(D2e);FIo=r(VNt,"gpt_neo"),VNt.forEach(t),TIo=r(WGe," \u2014 "),kz=n(WGe,"A",{href:!0});var XNt=s(kz);MIo=r(XNt,"GPTNeoModel"),XNt.forEach(t),EIo=r(WGe," (GPT Neo model)"),WGe.forEach(t),CIo=i(x),L1=n(x,"LI",{});var UGe=s(L1);G2e=n(UGe,"STRONG",{});var zNt=s(G2e);wIo=r(zNt,"gpt_neox"),zNt.forEach(t),AIo=r(UGe," \u2014 "),Sz=n(UGe,"A",{href:!0});var QNt=s(Sz);LIo=r(QNt,"GPTNeoXModel"),QNt.forEach(t),yIo=r(UGe," (GPT NeoX model)"),UGe.forEach(t),xIo=i(x),y1=n(x,"LI",{});var HGe=s(y1);O2e=n(HGe,"STRONG",{});var WNt=s(O2e);$Io=r(WNt,"gpt_neox_japanese"),WNt.forEach(t),kIo=r(HGe," \u2014 "),Rz=n(HGe,"A",{href:!0});var UNt=s(Rz);SIo=r(UNt,"GPTNeoXJapaneseModel"),UNt.forEach(t),RIo=r(HGe," (GPT NeoX Japanese model)"),HGe.forEach(t),PIo=i(x),x1=n(x,"LI",{});var JGe=s(x1);V2e=n(JGe,"STRONG",{});var HNt=s(V2e);BIo=r(HNt,"gptj"),HNt.forEach(t),IIo=r(JGe," \u2014 "),Pz=n(JGe,"A",{href:!0});var JNt=s(Pz);NIo=r(JNt,"GPTJModel"),JNt.forEach(t),qIo=r(JGe," (GPT-J model)"),JGe.forEach(t),jIo=i(x),$1=n(x,"LI",{});var YGe=s($1);X2e=n(YGe,"STRONG",{});var YNt=s(X2e);DIo=r(YNt,"groupvit"),YNt.forEach(t),GIo=r(YGe," \u2014 "),Bz=n(YGe,"A",{href:!0});var ZNt=s(Bz);OIo=r(ZNt,"GroupViTModel"),ZNt.forEach(t),VIo=r(YGe," (GroupViT model)"),YGe.forEach(t),XIo=i(x),k1=n(x,"LI",{});var ZGe=s(k1);z2e=n(ZGe,"STRONG",{});var KNt=s(z2e);zIo=r(KNt,"hubert"),KNt.forEach(t),QIo=r(ZGe," \u2014 "),Iz=n(ZGe,"A",{href:!0});var eqt=s(Iz);WIo=r(eqt,"HubertModel"),eqt.forEach(t),UIo=r(ZGe," (Hubert model)"),ZGe.forEach(t),HIo=i(x),S1=n(x,"LI",{});var KGe=s(S1);Q2e=n(KGe,"STRONG",{});var oqt=s(Q2e);JIo=r(oqt,"ibert"),oqt.forEach(t),YIo=r(KGe," \u2014 "),Nz=n(KGe,"A",{href:!0});var rqt=s(Nz);ZIo=r(rqt,"IBertModel"),rqt.forEach(t),KIo=r(KGe," (I-BERT model)"),KGe.forEach(t),eNo=i(x),R1=n(x,"LI",{});var eOe=s(R1);W2e=n(eOe,"STRONG",{});var tqt=s(W2e);oNo=r(tqt,"imagegpt"),tqt.forEach(t),rNo=r(eOe," \u2014 "),qz=n(eOe,"A",{href:!0});var aqt=s(qz);tNo=r(aqt,"ImageGPTModel"),aqt.forEach(t),aNo=r(eOe," (ImageGPT model)"),eOe.forEach(t),nNo=i(x),P1=n(x,"LI",{});var oOe=s(P1);U2e=n(oOe,"STRONG",{});var nqt=s(U2e);sNo=r(nqt,"layoutlm"),nqt.forEach(t),lNo=r(oOe," \u2014 "),jz=n(oOe,"A",{href:!0});var sqt=s(jz);iNo=r(sqt,"LayoutLMModel"),sqt.forEach(t),dNo=r(oOe," (LayoutLM model)"),oOe.forEach(t),mNo=i(x),B1=n(x,"LI",{});var rOe=s(B1);H2e=n(rOe,"STRONG",{});var lqt=s(H2e);cNo=r(lqt,"layoutlmv2"),lqt.forEach(t),fNo=r(rOe," \u2014 "),Dz=n(rOe,"A",{href:!0});var iqt=s(Dz);gNo=r(iqt,"LayoutLMv2Model"),iqt.forEach(t),hNo=r(rOe," (LayoutLMv2 model)"),rOe.forEach(t),uNo=i(x),I1=n(x,"LI",{});var tOe=s(I1);J2e=n(tOe,"STRONG",{});var dqt=s(J2e);pNo=r(dqt,"layoutlmv3"),dqt.forEach(t),_No=r(tOe," \u2014 "),Gz=n(tOe,"A",{href:!0});var mqt=s(Gz);bNo=r(mqt,"LayoutLMv3Model"),mqt.forEach(t),vNo=r(tOe," (LayoutLMv3 model)"),tOe.forEach(t),FNo=i(x),N1=n(x,"LI",{});var aOe=s(N1);Y2e=n(aOe,"STRONG",{});var cqt=s(Y2e);TNo=r(cqt,"led"),cqt.forEach(t),MNo=r(aOe," \u2014 "),Oz=n(aOe,"A",{href:!0});var fqt=s(Oz);ENo=r(fqt,"LEDModel"),fqt.forEach(t),CNo=r(aOe," (LED model)"),aOe.forEach(t),wNo=i(x),q1=n(x,"LI",{});var nOe=s(q1);Z2e=n(nOe,"STRONG",{});var gqt=s(Z2e);ANo=r(gqt,"levit"),gqt.forEach(t),LNo=r(nOe," \u2014 "),Vz=n(nOe,"A",{href:!0});var hqt=s(Vz);yNo=r(hqt,"LevitModel"),hqt.forEach(t),xNo=r(nOe," (LeViT model)"),nOe.forEach(t),$No=i(x),j1=n(x,"LI",{});var sOe=s(j1);K2e=n(sOe,"STRONG",{});var uqt=s(K2e);kNo=r(uqt,"lilt"),uqt.forEach(t),SNo=r(sOe," \u2014 "),Xz=n(sOe,"A",{href:!0});var pqt=s(Xz);RNo=r(pqt,"LiltModel"),pqt.forEach(t),PNo=r(sOe," (LiLT model)"),sOe.forEach(t),BNo=i(x),D1=n(x,"LI",{});var lOe=s(D1);ebe=n(lOe,"STRONG",{});var _qt=s(ebe);INo=r(_qt,"longformer"),_qt.forEach(t),NNo=r(lOe," \u2014 "),zz=n(lOe,"A",{href:!0});var bqt=s(zz);qNo=r(bqt,"LongformerModel"),bqt.forEach(t),jNo=r(lOe," (Longformer model)"),lOe.forEach(t),DNo=i(x),G1=n(x,"LI",{});var iOe=s(G1);obe=n(iOe,"STRONG",{});var vqt=s(obe);GNo=r(vqt,"longt5"),vqt.forEach(t),ONo=r(iOe," \u2014 "),Qz=n(iOe,"A",{href:!0});var Fqt=s(Qz);VNo=r(Fqt,"LongT5Model"),Fqt.forEach(t),XNo=r(iOe," (LongT5 model)"),iOe.forEach(t),zNo=i(x),O1=n(x,"LI",{});var dOe=s(O1);rbe=n(dOe,"STRONG",{});var Tqt=s(rbe);QNo=r(Tqt,"luke"),Tqt.forEach(t),WNo=r(dOe," \u2014 "),Wz=n(dOe,"A",{href:!0});var Mqt=s(Wz);UNo=r(Mqt,"LukeModel"),Mqt.forEach(t),HNo=r(dOe," (LUKE model)"),dOe.forEach(t),JNo=i(x),V1=n(x,"LI",{});var mOe=s(V1);tbe=n(mOe,"STRONG",{});var Eqt=s(tbe);YNo=r(Eqt,"lxmert"),Eqt.forEach(t),ZNo=r(mOe," \u2014 "),Uz=n(mOe,"A",{href:!0});var Cqt=s(Uz);KNo=r(Cqt,"LxmertModel"),Cqt.forEach(t),eqo=r(mOe," (LXMERT model)"),mOe.forEach(t),oqo=i(x),X1=n(x,"LI",{});var cOe=s(X1);abe=n(cOe,"STRONG",{});var wqt=s(abe);rqo=r(wqt,"m2m_100"),wqt.forEach(t),tqo=r(cOe," \u2014 "),Hz=n(cOe,"A",{href:!0});var Aqt=s(Hz);aqo=r(Aqt,"M2M100Model"),Aqt.forEach(t),nqo=r(cOe," (M2M100 model)"),cOe.forEach(t),sqo=i(x),z1=n(x,"LI",{});var fOe=s(z1);nbe=n(fOe,"STRONG",{});var Lqt=s(nbe);lqo=r(Lqt,"marian"),Lqt.forEach(t),iqo=r(fOe," \u2014 "),Jz=n(fOe,"A",{href:!0});var yqt=s(Jz);dqo=r(yqt,"MarianModel"),yqt.forEach(t),mqo=r(fOe," (Marian model)"),fOe.forEach(t),cqo=i(x),Q1=n(x,"LI",{});var gOe=s(Q1);sbe=n(gOe,"STRONG",{});var xqt=s(sbe);fqo=r(xqt,"markuplm"),xqt.forEach(t),gqo=r(gOe," \u2014 "),Yz=n(gOe,"A",{href:!0});var $qt=s(Yz);hqo=r($qt,"MarkupLMModel"),$qt.forEach(t),uqo=r(gOe," (MarkupLM model)"),gOe.forEach(t),pqo=i(x),W1=n(x,"LI",{});var hOe=s(W1);lbe=n(hOe,"STRONG",{});var kqt=s(lbe);_qo=r(kqt,"maskformer"),kqt.forEach(t),bqo=r(hOe," \u2014 "),Zz=n(hOe,"A",{href:!0});var Sqt=s(Zz);vqo=r(Sqt,"MaskFormerModel"),Sqt.forEach(t),Fqo=r(hOe," (MaskFormer model)"),hOe.forEach(t),Tqo=i(x),U1=n(x,"LI",{});var uOe=s(U1);ibe=n(uOe,"STRONG",{});var Rqt=s(ibe);Mqo=r(Rqt,"mbart"),Rqt.forEach(t),Eqo=r(uOe," \u2014 "),Kz=n(uOe,"A",{href:!0});var Pqt=s(Kz);Cqo=r(Pqt,"MBartModel"),Pqt.forEach(t),wqo=r(uOe," (mBART model)"),uOe.forEach(t),Aqo=i(x),H1=n(x,"LI",{});var pOe=s(H1);dbe=n(pOe,"STRONG",{});var Bqt=s(dbe);Lqo=r(Bqt,"mctct"),Bqt.forEach(t),yqo=r(pOe," \u2014 "),eQ=n(pOe,"A",{href:!0});var Iqt=s(eQ);xqo=r(Iqt,"MCTCTModel"),Iqt.forEach(t),$qo=r(pOe," (M-CTC-T model)"),pOe.forEach(t),kqo=i(x),J1=n(x,"LI",{});var _Oe=s(J1);mbe=n(_Oe,"STRONG",{});var Nqt=s(mbe);Sqo=r(Nqt,"megatron-bert"),Nqt.forEach(t),Rqo=r(_Oe," \u2014 "),oQ=n(_Oe,"A",{href:!0});var qqt=s(oQ);Pqo=r(qqt,"MegatronBertModel"),qqt.forEach(t),Bqo=r(_Oe," (Megatron-BERT model)"),_Oe.forEach(t),Iqo=i(x),Y1=n(x,"LI",{});var bOe=s(Y1);cbe=n(bOe,"STRONG",{});var jqt=s(cbe);Nqo=r(jqt,"mobilebert"),jqt.forEach(t),qqo=r(bOe," \u2014 "),rQ=n(bOe,"A",{href:!0});var Dqt=s(rQ);jqo=r(Dqt,"MobileBertModel"),Dqt.forEach(t),Dqo=r(bOe," (MobileBERT model)"),bOe.forEach(t),Gqo=i(x),Z1=n(x,"LI",{});var vOe=s(Z1);fbe=n(vOe,"STRONG",{});var Gqt=s(fbe);Oqo=r(Gqt,"mobilevit"),Gqt.forEach(t),Vqo=r(vOe," \u2014 "),tQ=n(vOe,"A",{href:!0});var Oqt=s(tQ);Xqo=r(Oqt,"MobileViTModel"),Oqt.forEach(t),zqo=r(vOe," (MobileViT model)"),vOe.forEach(t),Qqo=i(x),K1=n(x,"LI",{});var FOe=s(K1);gbe=n(FOe,"STRONG",{});var Vqt=s(gbe);Wqo=r(Vqt,"mpnet"),Vqt.forEach(t),Uqo=r(FOe," \u2014 "),aQ=n(FOe,"A",{href:!0});var Xqt=s(aQ);Hqo=r(Xqt,"MPNetModel"),Xqt.forEach(t),Jqo=r(FOe," (MPNet model)"),FOe.forEach(t),Yqo=i(x),e2=n(x,"LI",{});var TOe=s(e2);hbe=n(TOe,"STRONG",{});var zqt=s(hbe);Zqo=r(zqt,"mt5"),zqt.forEach(t),Kqo=r(TOe," \u2014 "),nQ=n(TOe,"A",{href:!0});var Qqt=s(nQ);ejo=r(Qqt,"MT5Model"),Qqt.forEach(t),ojo=r(TOe," (MT5 model)"),TOe.forEach(t),rjo=i(x),o2=n(x,"LI",{});var MOe=s(o2);ube=n(MOe,"STRONG",{});var Wqt=s(ube);tjo=r(Wqt,"mvp"),Wqt.forEach(t),ajo=r(MOe," \u2014 "),sQ=n(MOe,"A",{href:!0});var Uqt=s(sQ);njo=r(Uqt,"MvpModel"),Uqt.forEach(t),sjo=r(MOe," (MVP model)"),MOe.forEach(t),ljo=i(x),r2=n(x,"LI",{});var EOe=s(r2);pbe=n(EOe,"STRONG",{});var Hqt=s(pbe);ijo=r(Hqt,"nezha"),Hqt.forEach(t),djo=r(EOe," \u2014 "),lQ=n(EOe,"A",{href:!0});var Jqt=s(lQ);mjo=r(Jqt,"NezhaModel"),Jqt.forEach(t),cjo=r(EOe," (Nezha model)"),EOe.forEach(t),fjo=i(x),t2=n(x,"LI",{});var COe=s(t2);_be=n(COe,"STRONG",{});var Yqt=s(_be);gjo=r(Yqt,"nllb"),Yqt.forEach(t),hjo=r(COe," \u2014 "),iQ=n(COe,"A",{href:!0});var Zqt=s(iQ);ujo=r(Zqt,"M2M100Model"),Zqt.forEach(t),pjo=r(COe," (NLLB model)"),COe.forEach(t),_jo=i(x),a2=n(x,"LI",{});var wOe=s(a2);bbe=n(wOe,"STRONG",{});var Kqt=s(bbe);bjo=r(Kqt,"nystromformer"),Kqt.forEach(t),vjo=r(wOe," \u2014 "),dQ=n(wOe,"A",{href:!0});var ejt=s(dQ);Fjo=r(ejt,"NystromformerModel"),ejt.forEach(t),Tjo=r(wOe," (Nystr\xF6mformer model)"),wOe.forEach(t),Mjo=i(x),n2=n(x,"LI",{});var AOe=s(n2);vbe=n(AOe,"STRONG",{});var ojt=s(vbe);Ejo=r(ojt,"openai-gpt"),ojt.forEach(t),Cjo=r(AOe," \u2014 "),mQ=n(AOe,"A",{href:!0});var rjt=s(mQ);wjo=r(rjt,"OpenAIGPTModel"),rjt.forEach(t),Ajo=r(AOe," (OpenAI GPT model)"),AOe.forEach(t),Ljo=i(x),s2=n(x,"LI",{});var LOe=s(s2);Fbe=n(LOe,"STRONG",{});var tjt=s(Fbe);yjo=r(tjt,"opt"),tjt.forEach(t),xjo=r(LOe," \u2014 "),cQ=n(LOe,"A",{href:!0});var ajt=s(cQ);$jo=r(ajt,"OPTModel"),ajt.forEach(t),kjo=r(LOe," (OPT model)"),LOe.forEach(t),Sjo=i(x),l2=n(x,"LI",{});var yOe=s(l2);Tbe=n(yOe,"STRONG",{});var njt=s(Tbe);Rjo=r(njt,"owlvit"),njt.forEach(t),Pjo=r(yOe," \u2014 "),fQ=n(yOe,"A",{href:!0});var sjt=s(fQ);Bjo=r(sjt,"OwlViTModel"),sjt.forEach(t),Ijo=r(yOe," (OWL-ViT model)"),yOe.forEach(t),Njo=i(x),i2=n(x,"LI",{});var xOe=s(i2);Mbe=n(xOe,"STRONG",{});var ljt=s(Mbe);qjo=r(ljt,"pegasus"),ljt.forEach(t),jjo=r(xOe," \u2014 "),gQ=n(xOe,"A",{href:!0});var ijt=s(gQ);Djo=r(ijt,"PegasusModel"),ijt.forEach(t),Gjo=r(xOe," (Pegasus model)"),xOe.forEach(t),Ojo=i(x),d2=n(x,"LI",{});var $Oe=s(d2);Ebe=n($Oe,"STRONG",{});var djt=s(Ebe);Vjo=r(djt,"pegasus_x"),djt.forEach(t),Xjo=r($Oe," \u2014 "),hQ=n($Oe,"A",{href:!0});var mjt=s(hQ);zjo=r(mjt,"PegasusXModel"),mjt.forEach(t),Qjo=r($Oe," (PEGASUS-X model)"),$Oe.forEach(t),Wjo=i(x),m2=n(x,"LI",{});var kOe=s(m2);Cbe=n(kOe,"STRONG",{});var cjt=s(Cbe);Ujo=r(cjt,"perceiver"),cjt.forEach(t),Hjo=r(kOe," \u2014 "),uQ=n(kOe,"A",{href:!0});var fjt=s(uQ);Jjo=r(fjt,"PerceiverModel"),fjt.forEach(t),Yjo=r(kOe," (Perceiver model)"),kOe.forEach(t),Zjo=i(x),c2=n(x,"LI",{});var SOe=s(c2);wbe=n(SOe,"STRONG",{});var gjt=s(wbe);Kjo=r(gjt,"plbart"),gjt.forEach(t),eDo=r(SOe," \u2014 "),pQ=n(SOe,"A",{href:!0});var hjt=s(pQ);oDo=r(hjt,"PLBartModel"),hjt.forEach(t),rDo=r(SOe," (PLBart model)"),SOe.forEach(t),tDo=i(x),f2=n(x,"LI",{});var ROe=s(f2);Abe=n(ROe,"STRONG",{});var ujt=s(Abe);aDo=r(ujt,"poolformer"),ujt.forEach(t),nDo=r(ROe," \u2014 "),_Q=n(ROe,"A",{href:!0});var pjt=s(_Q);sDo=r(pjt,"PoolFormerModel"),pjt.forEach(t),lDo=r(ROe," (PoolFormer model)"),ROe.forEach(t),iDo=i(x),g2=n(x,"LI",{});var POe=s(g2);Lbe=n(POe,"STRONG",{});var _jt=s(Lbe);dDo=r(_jt,"prophetnet"),_jt.forEach(t),mDo=r(POe," \u2014 "),bQ=n(POe,"A",{href:!0});var bjt=s(bQ);cDo=r(bjt,"ProphetNetModel"),bjt.forEach(t),fDo=r(POe," (ProphetNet model)"),POe.forEach(t),gDo=i(x),h2=n(x,"LI",{});var BOe=s(h2);ybe=n(BOe,"STRONG",{});var vjt=s(ybe);hDo=r(vjt,"qdqbert"),vjt.forEach(t),uDo=r(BOe," \u2014 "),vQ=n(BOe,"A",{href:!0});var Fjt=s(vQ);pDo=r(Fjt,"QDQBertModel"),Fjt.forEach(t),_Do=r(BOe," (QDQBert model)"),BOe.forEach(t),bDo=i(x),u2=n(x,"LI",{});var IOe=s(u2);xbe=n(IOe,"STRONG",{});var Tjt=s(xbe);vDo=r(Tjt,"reformer"),Tjt.forEach(t),FDo=r(IOe," \u2014 "),FQ=n(IOe,"A",{href:!0});var Mjt=s(FQ);TDo=r(Mjt,"ReformerModel"),Mjt.forEach(t),MDo=r(IOe," (Reformer model)"),IOe.forEach(t),EDo=i(x),p2=n(x,"LI",{});var NOe=s(p2);$be=n(NOe,"STRONG",{});var Ejt=s($be);CDo=r(Ejt,"regnet"),Ejt.forEach(t),wDo=r(NOe," \u2014 "),TQ=n(NOe,"A",{href:!0});var Cjt=s(TQ);ADo=r(Cjt,"RegNetModel"),Cjt.forEach(t),LDo=r(NOe," (RegNet model)"),NOe.forEach(t),yDo=i(x),_2=n(x,"LI",{});var qOe=s(_2);kbe=n(qOe,"STRONG",{});var wjt=s(kbe);xDo=r(wjt,"rembert"),wjt.forEach(t),$Do=r(qOe," \u2014 "),MQ=n(qOe,"A",{href:!0});var Ajt=s(MQ);kDo=r(Ajt,"RemBertModel"),Ajt.forEach(t),SDo=r(qOe," (RemBERT model)"),qOe.forEach(t),RDo=i(x),b2=n(x,"LI",{});var jOe=s(b2);Sbe=n(jOe,"STRONG",{});var Ljt=s(Sbe);PDo=r(Ljt,"resnet"),Ljt.forEach(t),BDo=r(jOe," \u2014 "),EQ=n(jOe,"A",{href:!0});var yjt=s(EQ);IDo=r(yjt,"ResNetModel"),yjt.forEach(t),NDo=r(jOe," (ResNet model)"),jOe.forEach(t),qDo=i(x),v2=n(x,"LI",{});var DOe=s(v2);Rbe=n(DOe,"STRONG",{});var xjt=s(Rbe);jDo=r(xjt,"retribert"),xjt.forEach(t),DDo=r(DOe," \u2014 "),CQ=n(DOe,"A",{href:!0});var $jt=s(CQ);GDo=r($jt,"RetriBertModel"),$jt.forEach(t),ODo=r(DOe," (RetriBERT model)"),DOe.forEach(t),VDo=i(x),F2=n(x,"LI",{});var GOe=s(F2);Pbe=n(GOe,"STRONG",{});var kjt=s(Pbe);XDo=r(kjt,"roberta"),kjt.forEach(t),zDo=r(GOe," \u2014 "),wQ=n(GOe,"A",{href:!0});var Sjt=s(wQ);QDo=r(Sjt,"RobertaModel"),Sjt.forEach(t),WDo=r(GOe," (RoBERTa model)"),GOe.forEach(t),UDo=i(x),T2=n(x,"LI",{});var OOe=s(T2);Bbe=n(OOe,"STRONG",{});var Rjt=s(Bbe);HDo=r(Rjt,"roformer"),Rjt.forEach(t),JDo=r(OOe," \u2014 "),AQ=n(OOe,"A",{href:!0});var Pjt=s(AQ);YDo=r(Pjt,"RoFormerModel"),Pjt.forEach(t),ZDo=r(OOe," (RoFormer model)"),OOe.forEach(t),KDo=i(x),M2=n(x,"LI",{});var VOe=s(M2);Ibe=n(VOe,"STRONG",{});var Bjt=s(Ibe);eGo=r(Bjt,"segformer"),Bjt.forEach(t),oGo=r(VOe," \u2014 "),LQ=n(VOe,"A",{href:!0});var Ijt=s(LQ);rGo=r(Ijt,"SegformerModel"),Ijt.forEach(t),tGo=r(VOe," (SegFormer model)"),VOe.forEach(t),aGo=i(x),E2=n(x,"LI",{});var XOe=s(E2);Nbe=n(XOe,"STRONG",{});var Njt=s(Nbe);nGo=r(Njt,"sew"),Njt.forEach(t),sGo=r(XOe," \u2014 "),yQ=n(XOe,"A",{href:!0});var qjt=s(yQ);lGo=r(qjt,"SEWModel"),qjt.forEach(t),iGo=r(XOe," (SEW model)"),XOe.forEach(t),dGo=i(x),C2=n(x,"LI",{});var zOe=s(C2);qbe=n(zOe,"STRONG",{});var jjt=s(qbe);mGo=r(jjt,"sew-d"),jjt.forEach(t),cGo=r(zOe," \u2014 "),xQ=n(zOe,"A",{href:!0});var Djt=s(xQ);fGo=r(Djt,"SEWDModel"),Djt.forEach(t),gGo=r(zOe," (SEW-D model)"),zOe.forEach(t),hGo=i(x),w2=n(x,"LI",{});var QOe=s(w2);jbe=n(QOe,"STRONG",{});var Gjt=s(jbe);uGo=r(Gjt,"speech_to_text"),Gjt.forEach(t),pGo=r(QOe," \u2014 "),$Q=n(QOe,"A",{href:!0});var Ojt=s($Q);_Go=r(Ojt,"Speech2TextModel"),Ojt.forEach(t),bGo=r(QOe," (Speech2Text model)"),QOe.forEach(t),vGo=i(x),A2=n(x,"LI",{});var WOe=s(A2);Dbe=n(WOe,"STRONG",{});var Vjt=s(Dbe);FGo=r(Vjt,"splinter"),Vjt.forEach(t),TGo=r(WOe," \u2014 "),kQ=n(WOe,"A",{href:!0});var Xjt=s(kQ);MGo=r(Xjt,"SplinterModel"),Xjt.forEach(t),EGo=r(WOe," (Splinter model)"),WOe.forEach(t),CGo=i(x),L2=n(x,"LI",{});var UOe=s(L2);Gbe=n(UOe,"STRONG",{});var zjt=s(Gbe);wGo=r(zjt,"squeezebert"),zjt.forEach(t),AGo=r(UOe," \u2014 "),SQ=n(UOe,"A",{href:!0});var Qjt=s(SQ);LGo=r(Qjt,"SqueezeBertModel"),Qjt.forEach(t),yGo=r(UOe," (SqueezeBERT model)"),UOe.forEach(t),xGo=i(x),y2=n(x,"LI",{});var HOe=s(y2);Obe=n(HOe,"STRONG",{});var Wjt=s(Obe);$Go=r(Wjt,"swin"),Wjt.forEach(t),kGo=r(HOe," \u2014 "),RQ=n(HOe,"A",{href:!0});var Ujt=s(RQ);SGo=r(Ujt,"SwinModel"),Ujt.forEach(t),RGo=r(HOe," (Swin Transformer model)"),HOe.forEach(t),PGo=i(x),x2=n(x,"LI",{});var JOe=s(x2);Vbe=n(JOe,"STRONG",{});var Hjt=s(Vbe);BGo=r(Hjt,"swinv2"),Hjt.forEach(t),IGo=r(JOe," \u2014 "),PQ=n(JOe,"A",{href:!0});var Jjt=s(PQ);NGo=r(Jjt,"Swinv2Model"),Jjt.forEach(t),qGo=r(JOe," (Swin Transformer V2 model)"),JOe.forEach(t),jGo=i(x),$2=n(x,"LI",{});var YOe=s($2);Xbe=n(YOe,"STRONG",{});var Yjt=s(Xbe);DGo=r(Yjt,"t5"),Yjt.forEach(t),GGo=r(YOe," \u2014 "),BQ=n(YOe,"A",{href:!0});var Zjt=s(BQ);OGo=r(Zjt,"T5Model"),Zjt.forEach(t),VGo=r(YOe," (T5 model)"),YOe.forEach(t),XGo=i(x),k2=n(x,"LI",{});var ZOe=s(k2);zbe=n(ZOe,"STRONG",{});var Kjt=s(zbe);zGo=r(Kjt,"table-transformer"),Kjt.forEach(t),QGo=r(ZOe," \u2014 "),IQ=n(ZOe,"A",{href:!0});var eDt=s(IQ);WGo=r(eDt,"TableTransformerModel"),eDt.forEach(t),UGo=r(ZOe," (Table Transformer model)"),ZOe.forEach(t),HGo=i(x),S2=n(x,"LI",{});var KOe=s(S2);Qbe=n(KOe,"STRONG",{});var oDt=s(Qbe);JGo=r(oDt,"tapas"),oDt.forEach(t),YGo=r(KOe," \u2014 "),NQ=n(KOe,"A",{href:!0});var rDt=s(NQ);ZGo=r(rDt,"TapasModel"),rDt.forEach(t),KGo=r(KOe," (TAPAS model)"),KOe.forEach(t),eOo=i(x),R2=n(x,"LI",{});var eVe=s(R2);Wbe=n(eVe,"STRONG",{});var tDt=s(Wbe);oOo=r(tDt,"time_series_transformer"),tDt.forEach(t),rOo=r(eVe," \u2014 "),qQ=n(eVe,"A",{href:!0});var aDt=s(qQ);tOo=r(aDt,"TimeSeriesTransformerModel"),aDt.forEach(t),aOo=r(eVe," (Time Series Transformer model)"),eVe.forEach(t),nOo=i(x),P2=n(x,"LI",{});var oVe=s(P2);Ube=n(oVe,"STRONG",{});var nDt=s(Ube);sOo=r(nDt,"trajectory_transformer"),nDt.forEach(t),lOo=r(oVe," \u2014 "),jQ=n(oVe,"A",{href:!0});var sDt=s(jQ);iOo=r(sDt,"TrajectoryTransformerModel"),sDt.forEach(t),dOo=r(oVe," (Trajectory Transformer model)"),oVe.forEach(t),mOo=i(x),B2=n(x,"LI",{});var rVe=s(B2);Hbe=n(rVe,"STRONG",{});var lDt=s(Hbe);cOo=r(lDt,"transfo-xl"),lDt.forEach(t),fOo=r(rVe," \u2014 "),DQ=n(rVe,"A",{href:!0});var iDt=s(DQ);gOo=r(iDt,"TransfoXLModel"),iDt.forEach(t),hOo=r(rVe," (Transformer-XL model)"),rVe.forEach(t),uOo=i(x),I2=n(x,"LI",{});var tVe=s(I2);Jbe=n(tVe,"STRONG",{});var dDt=s(Jbe);pOo=r(dDt,"unispeech"),dDt.forEach(t),_Oo=r(tVe," \u2014 "),GQ=n(tVe,"A",{href:!0});var mDt=s(GQ);bOo=r(mDt,"UniSpeechModel"),mDt.forEach(t),vOo=r(tVe," (UniSpeech model)"),tVe.forEach(t),FOo=i(x),N2=n(x,"LI",{});var aVe=s(N2);Ybe=n(aVe,"STRONG",{});var cDt=s(Ybe);TOo=r(cDt,"unispeech-sat"),cDt.forEach(t),MOo=r(aVe," \u2014 "),OQ=n(aVe,"A",{href:!0});var fDt=s(OQ);EOo=r(fDt,"UniSpeechSatModel"),fDt.forEach(t),COo=r(aVe," (UniSpeechSat model)"),aVe.forEach(t),wOo=i(x),q2=n(x,"LI",{});var nVe=s(q2);Zbe=n(nVe,"STRONG",{});var gDt=s(Zbe);AOo=r(gDt,"van"),gDt.forEach(t),LOo=r(nVe," \u2014 "),VQ=n(nVe,"A",{href:!0});var hDt=s(VQ);yOo=r(hDt,"VanModel"),hDt.forEach(t),xOo=r(nVe," (VAN model)"),nVe.forEach(t),$Oo=i(x),j2=n(x,"LI",{});var sVe=s(j2);Kbe=n(sVe,"STRONG",{});var uDt=s(Kbe);kOo=r(uDt,"videomae"),uDt.forEach(t),SOo=r(sVe," \u2014 "),XQ=n(sVe,"A",{href:!0});var pDt=s(XQ);ROo=r(pDt,"VideoMAEModel"),pDt.forEach(t),POo=r(sVe," (VideoMAE model)"),sVe.forEach(t),BOo=i(x),D2=n(x,"LI",{});var lVe=s(D2);eve=n(lVe,"STRONG",{});var _Dt=s(eve);IOo=r(_Dt,"vilt"),_Dt.forEach(t),NOo=r(lVe," \u2014 "),zQ=n(lVe,"A",{href:!0});var bDt=s(zQ);qOo=r(bDt,"ViltModel"),bDt.forEach(t),jOo=r(lVe," (ViLT model)"),lVe.forEach(t),DOo=i(x),G2=n(x,"LI",{});var iVe=s(G2);ove=n(iVe,"STRONG",{});var vDt=s(ove);GOo=r(vDt,"vision-text-dual-encoder"),vDt.forEach(t),OOo=r(iVe," \u2014 "),QQ=n(iVe,"A",{href:!0});var FDt=s(QQ);VOo=r(FDt,"VisionTextDualEncoderModel"),FDt.forEach(t),XOo=r(iVe," (VisionTextDualEncoder model)"),iVe.forEach(t),zOo=i(x),O2=n(x,"LI",{});var dVe=s(O2);rve=n(dVe,"STRONG",{});var TDt=s(rve);QOo=r(TDt,"visual_bert"),TDt.forEach(t),WOo=r(dVe," \u2014 "),WQ=n(dVe,"A",{href:!0});var MDt=s(WQ);UOo=r(MDt,"VisualBertModel"),MDt.forEach(t),HOo=r(dVe," (VisualBERT model)"),dVe.forEach(t),JOo=i(x),V2=n(x,"LI",{});var mVe=s(V2);tve=n(mVe,"STRONG",{});var EDt=s(tve);YOo=r(EDt,"vit"),EDt.forEach(t),ZOo=r(mVe," \u2014 "),UQ=n(mVe,"A",{href:!0});var CDt=s(UQ);KOo=r(CDt,"ViTModel"),CDt.forEach(t),eVo=r(mVe," (ViT model)"),mVe.forEach(t),oVo=i(x),X2=n(x,"LI",{});var cVe=s(X2);ave=n(cVe,"STRONG",{});var wDt=s(ave);rVo=r(wDt,"vit_mae"),wDt.forEach(t),tVo=r(cVe," \u2014 "),HQ=n(cVe,"A",{href:!0});var ADt=s(HQ);aVo=r(ADt,"ViTMAEModel"),ADt.forEach(t),nVo=r(cVe," (ViTMAE model)"),cVe.forEach(t),sVo=i(x),z2=n(x,"LI",{});var fVe=s(z2);nve=n(fVe,"STRONG",{});var LDt=s(nve);lVo=r(LDt,"vit_msn"),LDt.forEach(t),iVo=r(fVe," \u2014 "),JQ=n(fVe,"A",{href:!0});var yDt=s(JQ);dVo=r(yDt,"ViTMSNModel"),yDt.forEach(t),mVo=r(fVe," (ViTMSN model)"),fVe.forEach(t),cVo=i(x),Q2=n(x,"LI",{});var gVe=s(Q2);sve=n(gVe,"STRONG",{});var xDt=s(sve);fVo=r(xDt,"wav2vec2"),xDt.forEach(t),gVo=r(gVe," \u2014 "),YQ=n(gVe,"A",{href:!0});var $Dt=s(YQ);hVo=r($Dt,"Wav2Vec2Model"),$Dt.forEach(t),uVo=r(gVe," (Wav2Vec2 model)"),gVe.forEach(t),pVo=i(x),W2=n(x,"LI",{});var hVe=s(W2);lve=n(hVe,"STRONG",{});var kDt=s(lve);_Vo=r(kDt,"wav2vec2-conformer"),kDt.forEach(t),bVo=r(hVe," \u2014 "),ZQ=n(hVe,"A",{href:!0});var SDt=s(ZQ);vVo=r(SDt,"Wav2Vec2ConformerModel"),SDt.forEach(t),FVo=r(hVe," (Wav2Vec2-Conformer model)"),hVe.forEach(t),TVo=i(x),U2=n(x,"LI",{});var uVe=s(U2);ive=n(uVe,"STRONG",{});var RDt=s(ive);MVo=r(RDt,"wavlm"),RDt.forEach(t),EVo=r(uVe," \u2014 "),KQ=n(uVe,"A",{href:!0});var PDt=s(KQ);CVo=r(PDt,"WavLMModel"),PDt.forEach(t),wVo=r(uVe," (WavLM model)"),uVe.forEach(t),AVo=i(x),H2=n(x,"LI",{});var pVe=s(H2);dve=n(pVe,"STRONG",{});var BDt=s(dve);LVo=r(BDt,"whisper"),BDt.forEach(t),yVo=r(pVe," \u2014 "),eW=n(pVe,"A",{href:!0});var IDt=s(eW);xVo=r(IDt,"WhisperModel"),IDt.forEach(t),$Vo=r(pVe," (Whisper model)"),pVe.forEach(t),kVo=i(x),J2=n(x,"LI",{});var _Ve=s(J2);mve=n(_Ve,"STRONG",{});var NDt=s(mve);SVo=r(NDt,"xclip"),NDt.forEach(t),RVo=r(_Ve," \u2014 "),oW=n(_Ve,"A",{href:!0});var qDt=s(oW);PVo=r(qDt,"XCLIPModel"),qDt.forEach(t),BVo=r(_Ve," (X-CLIP model)"),_Ve.forEach(t),IVo=i(x),Y2=n(x,"LI",{});var bVe=s(Y2);cve=n(bVe,"STRONG",{});var jDt=s(cve);NVo=r(jDt,"xglm"),jDt.forEach(t),qVo=r(bVe," \u2014 "),rW=n(bVe,"A",{href:!0});var DDt=s(rW);jVo=r(DDt,"XGLMModel"),DDt.forEach(t),DVo=r(bVe," (XGLM model)"),bVe.forEach(t),GVo=i(x),Z2=n(x,"LI",{});var vVe=s(Z2);fve=n(vVe,"STRONG",{});var GDt=s(fve);OVo=r(GDt,"xlm"),GDt.forEach(t),VVo=r(vVe," \u2014 "),tW=n(vVe,"A",{href:!0});var ODt=s(tW);XVo=r(ODt,"XLMModel"),ODt.forEach(t),zVo=r(vVe," (XLM model)"),vVe.forEach(t),QVo=i(x),K2=n(x,"LI",{});var FVe=s(K2);gve=n(FVe,"STRONG",{});var VDt=s(gve);WVo=r(VDt,"xlm-prophetnet"),VDt.forEach(t),UVo=r(FVe," \u2014 "),aW=n(FVe,"A",{href:!0});var XDt=s(aW);HVo=r(XDt,"XLMProphetNetModel"),XDt.forEach(t),JVo=r(FVe," (XLM-ProphetNet model)"),FVe.forEach(t),YVo=i(x),eb=n(x,"LI",{});var TVe=s(eb);hve=n(TVe,"STRONG",{});var zDt=s(hve);ZVo=r(zDt,"xlm-roberta"),zDt.forEach(t),KVo=r(TVe," \u2014 "),nW=n(TVe,"A",{href:!0});var QDt=s(nW);eXo=r(QDt,"XLMRobertaModel"),QDt.forEach(t),oXo=r(TVe," (XLM-RoBERTa model)"),TVe.forEach(t),rXo=i(x),ob=n(x,"LI",{});var MVe=s(ob);uve=n(MVe,"STRONG",{});var WDt=s(uve);tXo=r(WDt,"xlm-roberta-xl"),WDt.forEach(t),aXo=r(MVe," \u2014 "),sW=n(MVe,"A",{href:!0});var UDt=s(sW);nXo=r(UDt,"XLMRobertaXLModel"),UDt.forEach(t),sXo=r(MVe," (XLM-RoBERTa-XL model)"),MVe.forEach(t),lXo=i(x),rb=n(x,"LI",{});var EVe=s(rb);pve=n(EVe,"STRONG",{});var HDt=s(pve);iXo=r(HDt,"xlnet"),HDt.forEach(t),dXo=r(EVe," \u2014 "),lW=n(EVe,"A",{href:!0});var JDt=s(lW);mXo=r(JDt,"XLNetModel"),JDt.forEach(t),cXo=r(EVe," (XLNet model)"),EVe.forEach(t),fXo=i(x),tb=n(x,"LI",{});var CVe=s(tb);_ve=n(CVe,"STRONG",{});var YDt=s(_ve);gXo=r(YDt,"yolos"),YDt.forEach(t),hXo=r(CVe," \u2014 "),iW=n(CVe,"A",{href:!0});var ZDt=s(iW);uXo=r(ZDt,"YolosModel"),ZDt.forEach(t),pXo=r(CVe," (YOLOS model)"),CVe.forEach(t),_Xo=i(x),ab=n(x,"LI",{});var wVe=s(ab);bve=n(wVe,"STRONG",{});var KDt=s(bve);bXo=r(KDt,"yoso"),KDt.forEach(t),vXo=r(wVe," \u2014 "),dW=n(wVe,"A",{href:!0});var eGt=s(dW);FXo=r(eGt,"YosoModel"),eGt.forEach(t),TXo=r(wVe," (YOSO model)"),wVe.forEach(t),x.forEach(t),MXo=i(La),nb=n(La,"P",{});var AVe=s(nb);EXo=r(AVe,"The model is set in evaluation mode by default using "),vve=n(AVe,"CODE",{});var oGt=s(vve);CXo=r(oGt,"model.eval()"),oGt.forEach(t),wXo=r(AVe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Fve=n(AVe,"CODE",{});var rGt=s(Fve);AXo=r(rGt,"model.train()"),rGt.forEach(t),AVe.forEach(t),LXo=i(La),T(sb.$$.fragment,La),La.forEach(t),jl.forEach(t),lao=i(c),Id=n(c,"H2",{class:!0});var wso=s(Id);lb=n(wso,"A",{id:!0,class:!0,href:!0});var tGt=s(lb);Tve=n(tGt,"SPAN",{});var aGt=s(Tve);T(z$.$$.fragment,aGt),aGt.forEach(t),tGt.forEach(t),yXo=i(wso),Mve=n(wso,"SPAN",{});var nGt=s(Mve);xXo=r(nGt,"AutoModelForPreTraining"),nGt.forEach(t),wso.forEach(t),iao=i(c),No=n(c,"DIV",{class:!0});var Dl=s(No);T(Q$.$$.fragment,Dl),$Xo=i(Dl),Nd=n(Dl,"P",{});var bme=s(Nd);kXo=r(bme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),mW=n(bme,"A",{href:!0});var sGt=s(mW);SXo=r(sGt,"from_pretrained()"),sGt.forEach(t),RXo=r(bme," class method or the "),cW=n(bme,"A",{href:!0});var lGt=s(cW);PXo=r(lGt,"from_config()"),lGt.forEach(t),BXo=r(bme,` class
method.`),bme.forEach(t),IXo=i(Dl),W$=n(Dl,"P",{});var Aso=s(W$);NXo=r(Aso,"This class cannot be instantiated directly using "),Eve=n(Aso,"CODE",{});var iGt=s(Eve);qXo=r(iGt,"__init__()"),iGt.forEach(t),jXo=r(Aso," (throws an error)."),Aso.forEach(t),DXo=i(Dl),Et=n(Dl,"DIV",{class:!0});var l9=s(Et);T(U$.$$.fragment,l9),GXo=i(l9),Cve=n(l9,"P",{});var dGt=s(Cve);OXo=r(dGt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),dGt.forEach(t),VXo=i(l9),qd=n(l9,"P",{});var vme=s(qd);XXo=r(vme,`Note:
Loading a model from its configuration file does `),wve=n(vme,"STRONG",{});var mGt=s(wve);zXo=r(mGt,"not"),mGt.forEach(t),QXo=r(vme,` load the model weights. It only affects the
model\u2019s configuration. Use `),fW=n(vme,"A",{href:!0});var cGt=s(fW);WXo=r(cGt,"from_pretrained()"),cGt.forEach(t),UXo=r(vme," to load the model weights."),vme.forEach(t),HXo=i(l9),T(ib.$$.fragment,l9),l9.forEach(t),JXo=i(Dl),eo=n(Dl,"DIV",{class:!0});var ya=s(eo);T(H$.$$.fragment,ya),YXo=i(ya),Ave=n(ya,"P",{});var fGt=s(Ave);ZXo=r(fGt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),fGt.forEach(t),KXo=i(ya),sn=n(ya,"P",{});var i9=s(sn);ezo=r(i9,"The model class to instantiate is selected based on the "),Lve=n(i9,"CODE",{});var gGt=s(Lve);ozo=r(gGt,"model_type"),gGt.forEach(t),rzo=r(i9,` property of the config object (either
passed as an argument or loaded from `),yve=n(i9,"CODE",{});var hGt=s(yve);tzo=r(hGt,"pretrained_model_name_or_path"),hGt.forEach(t),azo=r(i9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xve=n(i9,"CODE",{});var uGt=s(xve);nzo=r(uGt,"pretrained_model_name_or_path"),uGt.forEach(t),szo=r(i9,":"),i9.forEach(t),lzo=i(ya),G=n(ya,"UL",{});var V=s(G);db=n(V,"LI",{});var LVe=s(db);$ve=n(LVe,"STRONG",{});var pGt=s($ve);izo=r(pGt,"albert"),pGt.forEach(t),dzo=r(LVe," \u2014 "),gW=n(LVe,"A",{href:!0});var _Gt=s(gW);mzo=r(_Gt,"AlbertForPreTraining"),_Gt.forEach(t),czo=r(LVe," (ALBERT model)"),LVe.forEach(t),fzo=i(V),mb=n(V,"LI",{});var yVe=s(mb);kve=n(yVe,"STRONG",{});var bGt=s(kve);gzo=r(bGt,"bart"),bGt.forEach(t),hzo=r(yVe," \u2014 "),hW=n(yVe,"A",{href:!0});var vGt=s(hW);uzo=r(vGt,"BartForConditionalGeneration"),vGt.forEach(t),pzo=r(yVe," (BART model)"),yVe.forEach(t),_zo=i(V),cb=n(V,"LI",{});var xVe=s(cb);Sve=n(xVe,"STRONG",{});var FGt=s(Sve);bzo=r(FGt,"bert"),FGt.forEach(t),vzo=r(xVe," \u2014 "),uW=n(xVe,"A",{href:!0});var TGt=s(uW);Fzo=r(TGt,"BertForPreTraining"),TGt.forEach(t),Tzo=r(xVe," (BERT model)"),xVe.forEach(t),Mzo=i(V),fb=n(V,"LI",{});var $Ve=s(fb);Rve=n($Ve,"STRONG",{});var MGt=s(Rve);Ezo=r(MGt,"big_bird"),MGt.forEach(t),Czo=r($Ve," \u2014 "),pW=n($Ve,"A",{href:!0});var EGt=s(pW);wzo=r(EGt,"BigBirdForPreTraining"),EGt.forEach(t),Azo=r($Ve," (BigBird model)"),$Ve.forEach(t),Lzo=i(V),gb=n(V,"LI",{});var kVe=s(gb);Pve=n(kVe,"STRONG",{});var CGt=s(Pve);yzo=r(CGt,"bloom"),CGt.forEach(t),xzo=r(kVe," \u2014 "),_W=n(kVe,"A",{href:!0});var wGt=s(_W);$zo=r(wGt,"BloomForCausalLM"),wGt.forEach(t),kzo=r(kVe," (BLOOM model)"),kVe.forEach(t),Szo=i(V),hb=n(V,"LI",{});var SVe=s(hb);Bve=n(SVe,"STRONG",{});var AGt=s(Bve);Rzo=r(AGt,"camembert"),AGt.forEach(t),Pzo=r(SVe," \u2014 "),bW=n(SVe,"A",{href:!0});var LGt=s(bW);Bzo=r(LGt,"CamembertForMaskedLM"),LGt.forEach(t),Izo=r(SVe," (CamemBERT model)"),SVe.forEach(t),Nzo=i(V),ub=n(V,"LI",{});var RVe=s(ub);Ive=n(RVe,"STRONG",{});var yGt=s(Ive);qzo=r(yGt,"ctrl"),yGt.forEach(t),jzo=r(RVe," \u2014 "),vW=n(RVe,"A",{href:!0});var xGt=s(vW);Dzo=r(xGt,"CTRLLMHeadModel"),xGt.forEach(t),Gzo=r(RVe," (CTRL model)"),RVe.forEach(t),Ozo=i(V),pb=n(V,"LI",{});var PVe=s(pb);Nve=n(PVe,"STRONG",{});var $Gt=s(Nve);Vzo=r($Gt,"data2vec-text"),$Gt.forEach(t),Xzo=r(PVe," \u2014 "),FW=n(PVe,"A",{href:!0});var kGt=s(FW);zzo=r(kGt,"Data2VecTextForMaskedLM"),kGt.forEach(t),Qzo=r(PVe," (Data2VecText model)"),PVe.forEach(t),Wzo=i(V),_b=n(V,"LI",{});var BVe=s(_b);qve=n(BVe,"STRONG",{});var SGt=s(qve);Uzo=r(SGt,"deberta"),SGt.forEach(t),Hzo=r(BVe," \u2014 "),TW=n(BVe,"A",{href:!0});var RGt=s(TW);Jzo=r(RGt,"DebertaForMaskedLM"),RGt.forEach(t),Yzo=r(BVe," (DeBERTa model)"),BVe.forEach(t),Zzo=i(V),bb=n(V,"LI",{});var IVe=s(bb);jve=n(IVe,"STRONG",{});var PGt=s(jve);Kzo=r(PGt,"deberta-v2"),PGt.forEach(t),eQo=r(IVe," \u2014 "),MW=n(IVe,"A",{href:!0});var BGt=s(MW);oQo=r(BGt,"DebertaV2ForMaskedLM"),BGt.forEach(t),rQo=r(IVe," (DeBERTa-v2 model)"),IVe.forEach(t),tQo=i(V),vb=n(V,"LI",{});var NVe=s(vb);Dve=n(NVe,"STRONG",{});var IGt=s(Dve);aQo=r(IGt,"distilbert"),IGt.forEach(t),nQo=r(NVe," \u2014 "),EW=n(NVe,"A",{href:!0});var NGt=s(EW);sQo=r(NGt,"DistilBertForMaskedLM"),NGt.forEach(t),lQo=r(NVe," (DistilBERT model)"),NVe.forEach(t),iQo=i(V),Fb=n(V,"LI",{});var qVe=s(Fb);Gve=n(qVe,"STRONG",{});var qGt=s(Gve);dQo=r(qGt,"electra"),qGt.forEach(t),mQo=r(qVe," \u2014 "),CW=n(qVe,"A",{href:!0});var jGt=s(CW);cQo=r(jGt,"ElectraForPreTraining"),jGt.forEach(t),fQo=r(qVe," (ELECTRA model)"),qVe.forEach(t),gQo=i(V),Tb=n(V,"LI",{});var jVe=s(Tb);Ove=n(jVe,"STRONG",{});var DGt=s(Ove);hQo=r(DGt,"ernie"),DGt.forEach(t),uQo=r(jVe," \u2014 "),wW=n(jVe,"A",{href:!0});var GGt=s(wW);pQo=r(GGt,"ErnieForPreTraining"),GGt.forEach(t),_Qo=r(jVe," (ERNIE model)"),jVe.forEach(t),bQo=i(V),Mb=n(V,"LI",{});var DVe=s(Mb);Vve=n(DVe,"STRONG",{});var OGt=s(Vve);vQo=r(OGt,"flaubert"),OGt.forEach(t),FQo=r(DVe," \u2014 "),AW=n(DVe,"A",{href:!0});var VGt=s(AW);TQo=r(VGt,"FlaubertWithLMHeadModel"),VGt.forEach(t),MQo=r(DVe," (FlauBERT model)"),DVe.forEach(t),EQo=i(V),Eb=n(V,"LI",{});var GVe=s(Eb);Xve=n(GVe,"STRONG",{});var XGt=s(Xve);CQo=r(XGt,"flava"),XGt.forEach(t),wQo=r(GVe," \u2014 "),LW=n(GVe,"A",{href:!0});var zGt=s(LW);AQo=r(zGt,"FlavaForPreTraining"),zGt.forEach(t),LQo=r(GVe," (FLAVA model)"),GVe.forEach(t),yQo=i(V),Cb=n(V,"LI",{});var OVe=s(Cb);zve=n(OVe,"STRONG",{});var QGt=s(zve);xQo=r(QGt,"fnet"),QGt.forEach(t),$Qo=r(OVe," \u2014 "),yW=n(OVe,"A",{href:!0});var WGt=s(yW);kQo=r(WGt,"FNetForPreTraining"),WGt.forEach(t),SQo=r(OVe," (FNet model)"),OVe.forEach(t),RQo=i(V),wb=n(V,"LI",{});var VVe=s(wb);Qve=n(VVe,"STRONG",{});var UGt=s(Qve);PQo=r(UGt,"fsmt"),UGt.forEach(t),BQo=r(VVe," \u2014 "),xW=n(VVe,"A",{href:!0});var HGt=s(xW);IQo=r(HGt,"FSMTForConditionalGeneration"),HGt.forEach(t),NQo=r(VVe," (FairSeq Machine-Translation model)"),VVe.forEach(t),qQo=i(V),Ab=n(V,"LI",{});var XVe=s(Ab);Wve=n(XVe,"STRONG",{});var JGt=s(Wve);jQo=r(JGt,"funnel"),JGt.forEach(t),DQo=r(XVe," \u2014 "),$W=n(XVe,"A",{href:!0});var YGt=s($W);GQo=r(YGt,"FunnelForPreTraining"),YGt.forEach(t),OQo=r(XVe," (Funnel Transformer model)"),XVe.forEach(t),VQo=i(V),Lb=n(V,"LI",{});var zVe=s(Lb);Uve=n(zVe,"STRONG",{});var ZGt=s(Uve);XQo=r(ZGt,"gpt2"),ZGt.forEach(t),zQo=r(zVe," \u2014 "),kW=n(zVe,"A",{href:!0});var KGt=s(kW);QQo=r(KGt,"GPT2LMHeadModel"),KGt.forEach(t),WQo=r(zVe," (OpenAI GPT-2 model)"),zVe.forEach(t),UQo=i(V),yb=n(V,"LI",{});var QVe=s(yb);Hve=n(QVe,"STRONG",{});var eOt=s(Hve);HQo=r(eOt,"ibert"),eOt.forEach(t),JQo=r(QVe," \u2014 "),SW=n(QVe,"A",{href:!0});var oOt=s(SW);YQo=r(oOt,"IBertForMaskedLM"),oOt.forEach(t),ZQo=r(QVe," (I-BERT model)"),QVe.forEach(t),KQo=i(V),xb=n(V,"LI",{});var WVe=s(xb);Jve=n(WVe,"STRONG",{});var rOt=s(Jve);eWo=r(rOt,"layoutlm"),rOt.forEach(t),oWo=r(WVe," \u2014 "),RW=n(WVe,"A",{href:!0});var tOt=s(RW);rWo=r(tOt,"LayoutLMForMaskedLM"),tOt.forEach(t),tWo=r(WVe," (LayoutLM model)"),WVe.forEach(t),aWo=i(V),$b=n(V,"LI",{});var UVe=s($b);Yve=n(UVe,"STRONG",{});var aOt=s(Yve);nWo=r(aOt,"longformer"),aOt.forEach(t),sWo=r(UVe," \u2014 "),PW=n(UVe,"A",{href:!0});var nOt=s(PW);lWo=r(nOt,"LongformerForMaskedLM"),nOt.forEach(t),iWo=r(UVe," (Longformer model)"),UVe.forEach(t),dWo=i(V),kb=n(V,"LI",{});var HVe=s(kb);Zve=n(HVe,"STRONG",{});var sOt=s(Zve);mWo=r(sOt,"luke"),sOt.forEach(t),cWo=r(HVe," \u2014 "),BW=n(HVe,"A",{href:!0});var lOt=s(BW);fWo=r(lOt,"LukeForMaskedLM"),lOt.forEach(t),gWo=r(HVe," (LUKE model)"),HVe.forEach(t),hWo=i(V),Sb=n(V,"LI",{});var JVe=s(Sb);Kve=n(JVe,"STRONG",{});var iOt=s(Kve);uWo=r(iOt,"lxmert"),iOt.forEach(t),pWo=r(JVe," \u2014 "),IW=n(JVe,"A",{href:!0});var dOt=s(IW);_Wo=r(dOt,"LxmertForPreTraining"),dOt.forEach(t),bWo=r(JVe," (LXMERT model)"),JVe.forEach(t),vWo=i(V),Rb=n(V,"LI",{});var YVe=s(Rb);eFe=n(YVe,"STRONG",{});var mOt=s(eFe);FWo=r(mOt,"megatron-bert"),mOt.forEach(t),TWo=r(YVe," \u2014 "),NW=n(YVe,"A",{href:!0});var cOt=s(NW);MWo=r(cOt,"MegatronBertForPreTraining"),cOt.forEach(t),EWo=r(YVe," (Megatron-BERT model)"),YVe.forEach(t),CWo=i(V),Pb=n(V,"LI",{});var ZVe=s(Pb);oFe=n(ZVe,"STRONG",{});var fOt=s(oFe);wWo=r(fOt,"mobilebert"),fOt.forEach(t),AWo=r(ZVe," \u2014 "),qW=n(ZVe,"A",{href:!0});var gOt=s(qW);LWo=r(gOt,"MobileBertForPreTraining"),gOt.forEach(t),yWo=r(ZVe," (MobileBERT model)"),ZVe.forEach(t),xWo=i(V),Bb=n(V,"LI",{});var KVe=s(Bb);rFe=n(KVe,"STRONG",{});var hOt=s(rFe);$Wo=r(hOt,"mpnet"),hOt.forEach(t),kWo=r(KVe," \u2014 "),jW=n(KVe,"A",{href:!0});var uOt=s(jW);SWo=r(uOt,"MPNetForMaskedLM"),uOt.forEach(t),RWo=r(KVe," (MPNet model)"),KVe.forEach(t),PWo=i(V),Ib=n(V,"LI",{});var eXe=s(Ib);tFe=n(eXe,"STRONG",{});var pOt=s(tFe);BWo=r(pOt,"mvp"),pOt.forEach(t),IWo=r(eXe," \u2014 "),DW=n(eXe,"A",{href:!0});var _Ot=s(DW);NWo=r(_Ot,"MvpForConditionalGeneration"),_Ot.forEach(t),qWo=r(eXe," (MVP model)"),eXe.forEach(t),jWo=i(V),Nb=n(V,"LI",{});var oXe=s(Nb);aFe=n(oXe,"STRONG",{});var bOt=s(aFe);DWo=r(bOt,"nezha"),bOt.forEach(t),GWo=r(oXe," \u2014 "),GW=n(oXe,"A",{href:!0});var vOt=s(GW);OWo=r(vOt,"NezhaForPreTraining"),vOt.forEach(t),VWo=r(oXe," (Nezha model)"),oXe.forEach(t),XWo=i(V),qb=n(V,"LI",{});var rXe=s(qb);nFe=n(rXe,"STRONG",{});var FOt=s(nFe);zWo=r(FOt,"openai-gpt"),FOt.forEach(t),QWo=r(rXe," \u2014 "),OW=n(rXe,"A",{href:!0});var TOt=s(OW);WWo=r(TOt,"OpenAIGPTLMHeadModel"),TOt.forEach(t),UWo=r(rXe," (OpenAI GPT model)"),rXe.forEach(t),HWo=i(V),jb=n(V,"LI",{});var tXe=s(jb);sFe=n(tXe,"STRONG",{});var MOt=s(sFe);JWo=r(MOt,"retribert"),MOt.forEach(t),YWo=r(tXe," \u2014 "),VW=n(tXe,"A",{href:!0});var EOt=s(VW);ZWo=r(EOt,"RetriBertModel"),EOt.forEach(t),KWo=r(tXe," (RetriBERT model)"),tXe.forEach(t),eUo=i(V),Db=n(V,"LI",{});var aXe=s(Db);lFe=n(aXe,"STRONG",{});var COt=s(lFe);oUo=r(COt,"roberta"),COt.forEach(t),rUo=r(aXe," \u2014 "),XW=n(aXe,"A",{href:!0});var wOt=s(XW);tUo=r(wOt,"RobertaForMaskedLM"),wOt.forEach(t),aUo=r(aXe," (RoBERTa model)"),aXe.forEach(t),nUo=i(V),Gb=n(V,"LI",{});var nXe=s(Gb);iFe=n(nXe,"STRONG",{});var AOt=s(iFe);sUo=r(AOt,"splinter"),AOt.forEach(t),lUo=r(nXe," \u2014 "),zW=n(nXe,"A",{href:!0});var LOt=s(zW);iUo=r(LOt,"SplinterForPreTraining"),LOt.forEach(t),dUo=r(nXe," (Splinter model)"),nXe.forEach(t),mUo=i(V),Ob=n(V,"LI",{});var sXe=s(Ob);dFe=n(sXe,"STRONG",{});var yOt=s(dFe);cUo=r(yOt,"squeezebert"),yOt.forEach(t),fUo=r(sXe," \u2014 "),QW=n(sXe,"A",{href:!0});var xOt=s(QW);gUo=r(xOt,"SqueezeBertForMaskedLM"),xOt.forEach(t),hUo=r(sXe," (SqueezeBERT model)"),sXe.forEach(t),uUo=i(V),Vb=n(V,"LI",{});var lXe=s(Vb);mFe=n(lXe,"STRONG",{});var $Ot=s(mFe);pUo=r($Ot,"t5"),$Ot.forEach(t),_Uo=r(lXe," \u2014 "),WW=n(lXe,"A",{href:!0});var kOt=s(WW);bUo=r(kOt,"T5ForConditionalGeneration"),kOt.forEach(t),vUo=r(lXe," (T5 model)"),lXe.forEach(t),FUo=i(V),Xb=n(V,"LI",{});var iXe=s(Xb);cFe=n(iXe,"STRONG",{});var SOt=s(cFe);TUo=r(SOt,"tapas"),SOt.forEach(t),MUo=r(iXe," \u2014 "),UW=n(iXe,"A",{href:!0});var ROt=s(UW);EUo=r(ROt,"TapasForMaskedLM"),ROt.forEach(t),CUo=r(iXe," (TAPAS model)"),iXe.forEach(t),wUo=i(V),zb=n(V,"LI",{});var dXe=s(zb);fFe=n(dXe,"STRONG",{});var POt=s(fFe);AUo=r(POt,"transfo-xl"),POt.forEach(t),LUo=r(dXe," \u2014 "),HW=n(dXe,"A",{href:!0});var BOt=s(HW);yUo=r(BOt,"TransfoXLLMHeadModel"),BOt.forEach(t),xUo=r(dXe," (Transformer-XL model)"),dXe.forEach(t),$Uo=i(V),Qb=n(V,"LI",{});var mXe=s(Qb);gFe=n(mXe,"STRONG",{});var IOt=s(gFe);kUo=r(IOt,"unispeech"),IOt.forEach(t),SUo=r(mXe," \u2014 "),JW=n(mXe,"A",{href:!0});var NOt=s(JW);RUo=r(NOt,"UniSpeechForPreTraining"),NOt.forEach(t),PUo=r(mXe," (UniSpeech model)"),mXe.forEach(t),BUo=i(V),Wb=n(V,"LI",{});var cXe=s(Wb);hFe=n(cXe,"STRONG",{});var qOt=s(hFe);IUo=r(qOt,"unispeech-sat"),qOt.forEach(t),NUo=r(cXe," \u2014 "),YW=n(cXe,"A",{href:!0});var jOt=s(YW);qUo=r(jOt,"UniSpeechSatForPreTraining"),jOt.forEach(t),jUo=r(cXe," (UniSpeechSat model)"),cXe.forEach(t),DUo=i(V),Ub=n(V,"LI",{});var fXe=s(Ub);uFe=n(fXe,"STRONG",{});var DOt=s(uFe);GUo=r(DOt,"videomae"),DOt.forEach(t),OUo=r(fXe," \u2014 "),ZW=n(fXe,"A",{href:!0});var GOt=s(ZW);VUo=r(GOt,"VideoMAEForPreTraining"),GOt.forEach(t),XUo=r(fXe," (VideoMAE model)"),fXe.forEach(t),zUo=i(V),Hb=n(V,"LI",{});var gXe=s(Hb);pFe=n(gXe,"STRONG",{});var OOt=s(pFe);QUo=r(OOt,"visual_bert"),OOt.forEach(t),WUo=r(gXe," \u2014 "),KW=n(gXe,"A",{href:!0});var VOt=s(KW);UUo=r(VOt,"VisualBertForPreTraining"),VOt.forEach(t),HUo=r(gXe," (VisualBERT model)"),gXe.forEach(t),JUo=i(V),Jb=n(V,"LI",{});var hXe=s(Jb);_Fe=n(hXe,"STRONG",{});var XOt=s(_Fe);YUo=r(XOt,"vit_mae"),XOt.forEach(t),ZUo=r(hXe," \u2014 "),eU=n(hXe,"A",{href:!0});var zOt=s(eU);KUo=r(zOt,"ViTMAEForPreTraining"),zOt.forEach(t),eHo=r(hXe," (ViTMAE model)"),hXe.forEach(t),oHo=i(V),Yb=n(V,"LI",{});var uXe=s(Yb);bFe=n(uXe,"STRONG",{});var QOt=s(bFe);rHo=r(QOt,"wav2vec2"),QOt.forEach(t),tHo=r(uXe," \u2014 "),oU=n(uXe,"A",{href:!0});var WOt=s(oU);aHo=r(WOt,"Wav2Vec2ForPreTraining"),WOt.forEach(t),nHo=r(uXe," (Wav2Vec2 model)"),uXe.forEach(t),sHo=i(V),Zb=n(V,"LI",{});var pXe=s(Zb);vFe=n(pXe,"STRONG",{});var UOt=s(vFe);lHo=r(UOt,"wav2vec2-conformer"),UOt.forEach(t),iHo=r(pXe," \u2014 "),rU=n(pXe,"A",{href:!0});var HOt=s(rU);dHo=r(HOt,"Wav2Vec2ConformerForPreTraining"),HOt.forEach(t),mHo=r(pXe," (Wav2Vec2-Conformer model)"),pXe.forEach(t),cHo=i(V),Kb=n(V,"LI",{});var _Xe=s(Kb);FFe=n(_Xe,"STRONG",{});var JOt=s(FFe);fHo=r(JOt,"xlm"),JOt.forEach(t),gHo=r(_Xe," \u2014 "),tU=n(_Xe,"A",{href:!0});var YOt=s(tU);hHo=r(YOt,"XLMWithLMHeadModel"),YOt.forEach(t),uHo=r(_Xe," (XLM model)"),_Xe.forEach(t),pHo=i(V),ev=n(V,"LI",{});var bXe=s(ev);TFe=n(bXe,"STRONG",{});var ZOt=s(TFe);_Ho=r(ZOt,"xlm-roberta"),ZOt.forEach(t),bHo=r(bXe," \u2014 "),aU=n(bXe,"A",{href:!0});var KOt=s(aU);vHo=r(KOt,"XLMRobertaForMaskedLM"),KOt.forEach(t),FHo=r(bXe," (XLM-RoBERTa model)"),bXe.forEach(t),THo=i(V),ov=n(V,"LI",{});var vXe=s(ov);MFe=n(vXe,"STRONG",{});var eVt=s(MFe);MHo=r(eVt,"xlm-roberta-xl"),eVt.forEach(t),EHo=r(vXe," \u2014 "),nU=n(vXe,"A",{href:!0});var oVt=s(nU);CHo=r(oVt,"XLMRobertaXLForMaskedLM"),oVt.forEach(t),wHo=r(vXe," (XLM-RoBERTa-XL model)"),vXe.forEach(t),AHo=i(V),rv=n(V,"LI",{});var FXe=s(rv);EFe=n(FXe,"STRONG",{});var rVt=s(EFe);LHo=r(rVt,"xlnet"),rVt.forEach(t),yHo=r(FXe," \u2014 "),sU=n(FXe,"A",{href:!0});var tVt=s(sU);xHo=r(tVt,"XLNetLMHeadModel"),tVt.forEach(t),$Ho=r(FXe," (XLNet model)"),FXe.forEach(t),V.forEach(t),kHo=i(ya),tv=n(ya,"P",{});var TXe=s(tv);SHo=r(TXe,"The model is set in evaluation mode by default using "),CFe=n(TXe,"CODE",{});var aVt=s(CFe);RHo=r(aVt,"model.eval()"),aVt.forEach(t),PHo=r(TXe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),wFe=n(TXe,"CODE",{});var nVt=s(wFe);BHo=r(nVt,"model.train()"),nVt.forEach(t),TXe.forEach(t),IHo=i(ya),T(av.$$.fragment,ya),ya.forEach(t),Dl.forEach(t),dao=i(c),jd=n(c,"H2",{class:!0});var Lso=s(jd);nv=n(Lso,"A",{id:!0,class:!0,href:!0});var sVt=s(nv);AFe=n(sVt,"SPAN",{});var lVt=s(AFe);T(J$.$$.fragment,lVt),lVt.forEach(t),sVt.forEach(t),NHo=i(Lso),LFe=n(Lso,"SPAN",{});var iVt=s(LFe);qHo=r(iVt,"AutoModelForCausalLM"),iVt.forEach(t),Lso.forEach(t),mao=i(c),qo=n(c,"DIV",{class:!0});var Gl=s(qo);T(Y$.$$.fragment,Gl),jHo=i(Gl),Dd=n(Gl,"P",{});var Fme=s(Dd);DHo=r(Fme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),lU=n(Fme,"A",{href:!0});var dVt=s(lU);GHo=r(dVt,"from_pretrained()"),dVt.forEach(t),OHo=r(Fme," class method or the "),iU=n(Fme,"A",{href:!0});var mVt=s(iU);VHo=r(mVt,"from_config()"),mVt.forEach(t),XHo=r(Fme,` class
method.`),Fme.forEach(t),zHo=i(Gl),Z$=n(Gl,"P",{});var yso=s(Z$);QHo=r(yso,"This class cannot be instantiated directly using "),yFe=n(yso,"CODE",{});var cVt=s(yFe);WHo=r(cVt,"__init__()"),cVt.forEach(t),UHo=r(yso," (throws an error)."),yso.forEach(t),HHo=i(Gl),Ct=n(Gl,"DIV",{class:!0});var d9=s(Ct);T(K$.$$.fragment,d9),JHo=i(d9),xFe=n(d9,"P",{});var fVt=s(xFe);YHo=r(fVt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),fVt.forEach(t),ZHo=i(d9),Gd=n(d9,"P",{});var Tme=s(Gd);KHo=r(Tme,`Note:
Loading a model from its configuration file does `),$Fe=n(Tme,"STRONG",{});var gVt=s($Fe);eJo=r(gVt,"not"),gVt.forEach(t),oJo=r(Tme,` load the model weights. It only affects the
model\u2019s configuration. Use `),dU=n(Tme,"A",{href:!0});var hVt=s(dU);rJo=r(hVt,"from_pretrained()"),hVt.forEach(t),tJo=r(Tme," to load the model weights."),Tme.forEach(t),aJo=i(d9),T(sv.$$.fragment,d9),d9.forEach(t),nJo=i(Gl),oo=n(Gl,"DIV",{class:!0});var xa=s(oo);T(ek.$$.fragment,xa),sJo=i(xa),kFe=n(xa,"P",{});var uVt=s(kFe);lJo=r(uVt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),uVt.forEach(t),iJo=i(xa),ln=n(xa,"P",{});var m9=s(ln);dJo=r(m9,"The model class to instantiate is selected based on the "),SFe=n(m9,"CODE",{});var pVt=s(SFe);mJo=r(pVt,"model_type"),pVt.forEach(t),cJo=r(m9,` property of the config object (either
passed as an argument or loaded from `),RFe=n(m9,"CODE",{});var _Vt=s(RFe);fJo=r(_Vt,"pretrained_model_name_or_path"),_Vt.forEach(t),gJo=r(m9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PFe=n(m9,"CODE",{});var bVt=s(PFe);hJo=r(bVt,"pretrained_model_name_or_path"),bVt.forEach(t),uJo=r(m9,":"),m9.forEach(t),pJo=i(xa),W=n(xa,"UL",{});var H=s(W);lv=n(H,"LI",{});var MXe=s(lv);BFe=n(MXe,"STRONG",{});var vVt=s(BFe);_Jo=r(vVt,"bart"),vVt.forEach(t),bJo=r(MXe," \u2014 "),mU=n(MXe,"A",{href:!0});var FVt=s(mU);vJo=r(FVt,"BartForCausalLM"),FVt.forEach(t),FJo=r(MXe," (BART model)"),MXe.forEach(t),TJo=i(H),iv=n(H,"LI",{});var EXe=s(iv);IFe=n(EXe,"STRONG",{});var TVt=s(IFe);MJo=r(TVt,"bert"),TVt.forEach(t),EJo=r(EXe," \u2014 "),cU=n(EXe,"A",{href:!0});var MVt=s(cU);CJo=r(MVt,"BertLMHeadModel"),MVt.forEach(t),wJo=r(EXe," (BERT model)"),EXe.forEach(t),AJo=i(H),dv=n(H,"LI",{});var CXe=s(dv);NFe=n(CXe,"STRONG",{});var EVt=s(NFe);LJo=r(EVt,"bert-generation"),EVt.forEach(t),yJo=r(CXe," \u2014 "),fU=n(CXe,"A",{href:!0});var CVt=s(fU);xJo=r(CVt,"BertGenerationDecoder"),CVt.forEach(t),$Jo=r(CXe," (Bert Generation model)"),CXe.forEach(t),kJo=i(H),mv=n(H,"LI",{});var wXe=s(mv);qFe=n(wXe,"STRONG",{});var wVt=s(qFe);SJo=r(wVt,"big_bird"),wVt.forEach(t),RJo=r(wXe," \u2014 "),gU=n(wXe,"A",{href:!0});var AVt=s(gU);PJo=r(AVt,"BigBirdForCausalLM"),AVt.forEach(t),BJo=r(wXe," (BigBird model)"),wXe.forEach(t),IJo=i(H),cv=n(H,"LI",{});var AXe=s(cv);jFe=n(AXe,"STRONG",{});var LVt=s(jFe);NJo=r(LVt,"bigbird_pegasus"),LVt.forEach(t),qJo=r(AXe," \u2014 "),hU=n(AXe,"A",{href:!0});var yVt=s(hU);jJo=r(yVt,"BigBirdPegasusForCausalLM"),yVt.forEach(t),DJo=r(AXe," (BigBird-Pegasus model)"),AXe.forEach(t),GJo=i(H),fv=n(H,"LI",{});var LXe=s(fv);DFe=n(LXe,"STRONG",{});var xVt=s(DFe);OJo=r(xVt,"blenderbot"),xVt.forEach(t),VJo=r(LXe," \u2014 "),uU=n(LXe,"A",{href:!0});var $Vt=s(uU);XJo=r($Vt,"BlenderbotForCausalLM"),$Vt.forEach(t),zJo=r(LXe," (Blenderbot model)"),LXe.forEach(t),QJo=i(H),gv=n(H,"LI",{});var yXe=s(gv);GFe=n(yXe,"STRONG",{});var kVt=s(GFe);WJo=r(kVt,"blenderbot-small"),kVt.forEach(t),UJo=r(yXe," \u2014 "),pU=n(yXe,"A",{href:!0});var SVt=s(pU);HJo=r(SVt,"BlenderbotSmallForCausalLM"),SVt.forEach(t),JJo=r(yXe," (BlenderbotSmall model)"),yXe.forEach(t),YJo=i(H),hv=n(H,"LI",{});var xXe=s(hv);OFe=n(xXe,"STRONG",{});var RVt=s(OFe);ZJo=r(RVt,"bloom"),RVt.forEach(t),KJo=r(xXe," \u2014 "),_U=n(xXe,"A",{href:!0});var PVt=s(_U);eYo=r(PVt,"BloomForCausalLM"),PVt.forEach(t),oYo=r(xXe," (BLOOM model)"),xXe.forEach(t),rYo=i(H),uv=n(H,"LI",{});var $Xe=s(uv);VFe=n($Xe,"STRONG",{});var BVt=s(VFe);tYo=r(BVt,"camembert"),BVt.forEach(t),aYo=r($Xe," \u2014 "),bU=n($Xe,"A",{href:!0});var IVt=s(bU);nYo=r(IVt,"CamembertForCausalLM"),IVt.forEach(t),sYo=r($Xe," (CamemBERT model)"),$Xe.forEach(t),lYo=i(H),pv=n(H,"LI",{});var kXe=s(pv);XFe=n(kXe,"STRONG",{});var NVt=s(XFe);iYo=r(NVt,"codegen"),NVt.forEach(t),dYo=r(kXe," \u2014 "),vU=n(kXe,"A",{href:!0});var qVt=s(vU);mYo=r(qVt,"CodeGenForCausalLM"),qVt.forEach(t),cYo=r(kXe," (CodeGen model)"),kXe.forEach(t),fYo=i(H),_v=n(H,"LI",{});var SXe=s(_v);zFe=n(SXe,"STRONG",{});var jVt=s(zFe);gYo=r(jVt,"ctrl"),jVt.forEach(t),hYo=r(SXe," \u2014 "),FU=n(SXe,"A",{href:!0});var DVt=s(FU);uYo=r(DVt,"CTRLLMHeadModel"),DVt.forEach(t),pYo=r(SXe," (CTRL model)"),SXe.forEach(t),_Yo=i(H),bv=n(H,"LI",{});var RXe=s(bv);QFe=n(RXe,"STRONG",{});var GVt=s(QFe);bYo=r(GVt,"data2vec-text"),GVt.forEach(t),vYo=r(RXe," \u2014 "),TU=n(RXe,"A",{href:!0});var OVt=s(TU);FYo=r(OVt,"Data2VecTextForCausalLM"),OVt.forEach(t),TYo=r(RXe," (Data2VecText model)"),RXe.forEach(t),MYo=i(H),vv=n(H,"LI",{});var PXe=s(vv);WFe=n(PXe,"STRONG",{});var VVt=s(WFe);EYo=r(VVt,"electra"),VVt.forEach(t),CYo=r(PXe," \u2014 "),MU=n(PXe,"A",{href:!0});var XVt=s(MU);wYo=r(XVt,"ElectraForCausalLM"),XVt.forEach(t),AYo=r(PXe," (ELECTRA model)"),PXe.forEach(t),LYo=i(H),Fv=n(H,"LI",{});var BXe=s(Fv);UFe=n(BXe,"STRONG",{});var zVt=s(UFe);yYo=r(zVt,"ernie"),zVt.forEach(t),xYo=r(BXe," \u2014 "),EU=n(BXe,"A",{href:!0});var QVt=s(EU);$Yo=r(QVt,"ErnieForCausalLM"),QVt.forEach(t),kYo=r(BXe," (ERNIE model)"),BXe.forEach(t),SYo=i(H),Tv=n(H,"LI",{});var IXe=s(Tv);HFe=n(IXe,"STRONG",{});var WVt=s(HFe);RYo=r(WVt,"gpt2"),WVt.forEach(t),PYo=r(IXe," \u2014 "),CU=n(IXe,"A",{href:!0});var UVt=s(CU);BYo=r(UVt,"GPT2LMHeadModel"),UVt.forEach(t),IYo=r(IXe," (OpenAI GPT-2 model)"),IXe.forEach(t),NYo=i(H),Mv=n(H,"LI",{});var NXe=s(Mv);JFe=n(NXe,"STRONG",{});var HVt=s(JFe);qYo=r(HVt,"gpt_neo"),HVt.forEach(t),jYo=r(NXe," \u2014 "),wU=n(NXe,"A",{href:!0});var JVt=s(wU);DYo=r(JVt,"GPTNeoForCausalLM"),JVt.forEach(t),GYo=r(NXe," (GPT Neo model)"),NXe.forEach(t),OYo=i(H),Ev=n(H,"LI",{});var qXe=s(Ev);YFe=n(qXe,"STRONG",{});var YVt=s(YFe);VYo=r(YVt,"gpt_neox"),YVt.forEach(t),XYo=r(qXe," \u2014 "),AU=n(qXe,"A",{href:!0});var ZVt=s(AU);zYo=r(ZVt,"GPTNeoXForCausalLM"),ZVt.forEach(t),QYo=r(qXe," (GPT NeoX model)"),qXe.forEach(t),WYo=i(H),Cv=n(H,"LI",{});var jXe=s(Cv);ZFe=n(jXe,"STRONG",{});var KVt=s(ZFe);UYo=r(KVt,"gpt_neox_japanese"),KVt.forEach(t),HYo=r(jXe," \u2014 "),LU=n(jXe,"A",{href:!0});var eXt=s(LU);JYo=r(eXt,"GPTNeoXJapaneseForCausalLM"),eXt.forEach(t),YYo=r(jXe," (GPT NeoX Japanese model)"),jXe.forEach(t),ZYo=i(H),wv=n(H,"LI",{});var DXe=s(wv);KFe=n(DXe,"STRONG",{});var oXt=s(KFe);KYo=r(oXt,"gptj"),oXt.forEach(t),eZo=r(DXe," \u2014 "),yU=n(DXe,"A",{href:!0});var rXt=s(yU);oZo=r(rXt,"GPTJForCausalLM"),rXt.forEach(t),rZo=r(DXe," (GPT-J model)"),DXe.forEach(t),tZo=i(H),Av=n(H,"LI",{});var GXe=s(Av);eTe=n(GXe,"STRONG",{});var tXt=s(eTe);aZo=r(tXt,"marian"),tXt.forEach(t),nZo=r(GXe," \u2014 "),xU=n(GXe,"A",{href:!0});var aXt=s(xU);sZo=r(aXt,"MarianForCausalLM"),aXt.forEach(t),lZo=r(GXe," (Marian model)"),GXe.forEach(t),iZo=i(H),Lv=n(H,"LI",{});var OXe=s(Lv);oTe=n(OXe,"STRONG",{});var nXt=s(oTe);dZo=r(nXt,"mbart"),nXt.forEach(t),mZo=r(OXe," \u2014 "),$U=n(OXe,"A",{href:!0});var sXt=s($U);cZo=r(sXt,"MBartForCausalLM"),sXt.forEach(t),fZo=r(OXe," (mBART model)"),OXe.forEach(t),gZo=i(H),yv=n(H,"LI",{});var VXe=s(yv);rTe=n(VXe,"STRONG",{});var lXt=s(rTe);hZo=r(lXt,"megatron-bert"),lXt.forEach(t),uZo=r(VXe," \u2014 "),kU=n(VXe,"A",{href:!0});var iXt=s(kU);pZo=r(iXt,"MegatronBertForCausalLM"),iXt.forEach(t),_Zo=r(VXe," (Megatron-BERT model)"),VXe.forEach(t),bZo=i(H),xv=n(H,"LI",{});var XXe=s(xv);tTe=n(XXe,"STRONG",{});var dXt=s(tTe);vZo=r(dXt,"mvp"),dXt.forEach(t),FZo=r(XXe," \u2014 "),SU=n(XXe,"A",{href:!0});var mXt=s(SU);TZo=r(mXt,"MvpForCausalLM"),mXt.forEach(t),MZo=r(XXe," (MVP model)"),XXe.forEach(t),EZo=i(H),$v=n(H,"LI",{});var zXe=s($v);aTe=n(zXe,"STRONG",{});var cXt=s(aTe);CZo=r(cXt,"openai-gpt"),cXt.forEach(t),wZo=r(zXe," \u2014 "),RU=n(zXe,"A",{href:!0});var fXt=s(RU);AZo=r(fXt,"OpenAIGPTLMHeadModel"),fXt.forEach(t),LZo=r(zXe," (OpenAI GPT model)"),zXe.forEach(t),yZo=i(H),kv=n(H,"LI",{});var QXe=s(kv);nTe=n(QXe,"STRONG",{});var gXt=s(nTe);xZo=r(gXt,"opt"),gXt.forEach(t),$Zo=r(QXe," \u2014 "),PU=n(QXe,"A",{href:!0});var hXt=s(PU);kZo=r(hXt,"OPTForCausalLM"),hXt.forEach(t),SZo=r(QXe," (OPT model)"),QXe.forEach(t),RZo=i(H),Sv=n(H,"LI",{});var WXe=s(Sv);sTe=n(WXe,"STRONG",{});var uXt=s(sTe);PZo=r(uXt,"pegasus"),uXt.forEach(t),BZo=r(WXe," \u2014 "),BU=n(WXe,"A",{href:!0});var pXt=s(BU);IZo=r(pXt,"PegasusForCausalLM"),pXt.forEach(t),NZo=r(WXe," (Pegasus model)"),WXe.forEach(t),qZo=i(H),Rv=n(H,"LI",{});var UXe=s(Rv);lTe=n(UXe,"STRONG",{});var _Xt=s(lTe);jZo=r(_Xt,"plbart"),_Xt.forEach(t),DZo=r(UXe," \u2014 "),IU=n(UXe,"A",{href:!0});var bXt=s(IU);GZo=r(bXt,"PLBartForCausalLM"),bXt.forEach(t),OZo=r(UXe," (PLBart model)"),UXe.forEach(t),VZo=i(H),Pv=n(H,"LI",{});var HXe=s(Pv);iTe=n(HXe,"STRONG",{});var vXt=s(iTe);XZo=r(vXt,"prophetnet"),vXt.forEach(t),zZo=r(HXe," \u2014 "),NU=n(HXe,"A",{href:!0});var FXt=s(NU);QZo=r(FXt,"ProphetNetForCausalLM"),FXt.forEach(t),WZo=r(HXe," (ProphetNet model)"),HXe.forEach(t),UZo=i(H),Bv=n(H,"LI",{});var JXe=s(Bv);dTe=n(JXe,"STRONG",{});var TXt=s(dTe);HZo=r(TXt,"qdqbert"),TXt.forEach(t),JZo=r(JXe," \u2014 "),qU=n(JXe,"A",{href:!0});var MXt=s(qU);YZo=r(MXt,"QDQBertLMHeadModel"),MXt.forEach(t),ZZo=r(JXe," (QDQBert model)"),JXe.forEach(t),KZo=i(H),Iv=n(H,"LI",{});var YXe=s(Iv);mTe=n(YXe,"STRONG",{});var EXt=s(mTe);eKo=r(EXt,"reformer"),EXt.forEach(t),oKo=r(YXe," \u2014 "),jU=n(YXe,"A",{href:!0});var CXt=s(jU);rKo=r(CXt,"ReformerModelWithLMHead"),CXt.forEach(t),tKo=r(YXe," (Reformer model)"),YXe.forEach(t),aKo=i(H),Nv=n(H,"LI",{});var ZXe=s(Nv);cTe=n(ZXe,"STRONG",{});var wXt=s(cTe);nKo=r(wXt,"rembert"),wXt.forEach(t),sKo=r(ZXe," \u2014 "),DU=n(ZXe,"A",{href:!0});var AXt=s(DU);lKo=r(AXt,"RemBertForCausalLM"),AXt.forEach(t),iKo=r(ZXe," (RemBERT model)"),ZXe.forEach(t),dKo=i(H),qv=n(H,"LI",{});var KXe=s(qv);fTe=n(KXe,"STRONG",{});var LXt=s(fTe);mKo=r(LXt,"roberta"),LXt.forEach(t),cKo=r(KXe," \u2014 "),GU=n(KXe,"A",{href:!0});var yXt=s(GU);fKo=r(yXt,"RobertaForCausalLM"),yXt.forEach(t),gKo=r(KXe," (RoBERTa model)"),KXe.forEach(t),hKo=i(H),jv=n(H,"LI",{});var eze=s(jv);gTe=n(eze,"STRONG",{});var xXt=s(gTe);uKo=r(xXt,"roformer"),xXt.forEach(t),pKo=r(eze," \u2014 "),OU=n(eze,"A",{href:!0});var $Xt=s(OU);_Ko=r($Xt,"RoFormerForCausalLM"),$Xt.forEach(t),bKo=r(eze," (RoFormer model)"),eze.forEach(t),vKo=i(H),Dv=n(H,"LI",{});var oze=s(Dv);hTe=n(oze,"STRONG",{});var kXt=s(hTe);FKo=r(kXt,"speech_to_text_2"),kXt.forEach(t),TKo=r(oze," \u2014 "),VU=n(oze,"A",{href:!0});var SXt=s(VU);MKo=r(SXt,"Speech2Text2ForCausalLM"),SXt.forEach(t),EKo=r(oze," (Speech2Text2 model)"),oze.forEach(t),CKo=i(H),Gv=n(H,"LI",{});var rze=s(Gv);uTe=n(rze,"STRONG",{});var RXt=s(uTe);wKo=r(RXt,"transfo-xl"),RXt.forEach(t),AKo=r(rze," \u2014 "),XU=n(rze,"A",{href:!0});var PXt=s(XU);LKo=r(PXt,"TransfoXLLMHeadModel"),PXt.forEach(t),yKo=r(rze," (Transformer-XL model)"),rze.forEach(t),xKo=i(H),Ov=n(H,"LI",{});var tze=s(Ov);pTe=n(tze,"STRONG",{});var BXt=s(pTe);$Ko=r(BXt,"trocr"),BXt.forEach(t),kKo=r(tze," \u2014 "),zU=n(tze,"A",{href:!0});var IXt=s(zU);SKo=r(IXt,"TrOCRForCausalLM"),IXt.forEach(t),RKo=r(tze," (TrOCR model)"),tze.forEach(t),PKo=i(H),Vv=n(H,"LI",{});var aze=s(Vv);_Te=n(aze,"STRONG",{});var NXt=s(_Te);BKo=r(NXt,"xglm"),NXt.forEach(t),IKo=r(aze," \u2014 "),QU=n(aze,"A",{href:!0});var qXt=s(QU);NKo=r(qXt,"XGLMForCausalLM"),qXt.forEach(t),qKo=r(aze," (XGLM model)"),aze.forEach(t),jKo=i(H),Xv=n(H,"LI",{});var nze=s(Xv);bTe=n(nze,"STRONG",{});var jXt=s(bTe);DKo=r(jXt,"xlm"),jXt.forEach(t),GKo=r(nze," \u2014 "),WU=n(nze,"A",{href:!0});var DXt=s(WU);OKo=r(DXt,"XLMWithLMHeadModel"),DXt.forEach(t),VKo=r(nze," (XLM model)"),nze.forEach(t),XKo=i(H),zv=n(H,"LI",{});var sze=s(zv);vTe=n(sze,"STRONG",{});var GXt=s(vTe);zKo=r(GXt,"xlm-prophetnet"),GXt.forEach(t),QKo=r(sze," \u2014 "),UU=n(sze,"A",{href:!0});var OXt=s(UU);WKo=r(OXt,"XLMProphetNetForCausalLM"),OXt.forEach(t),UKo=r(sze," (XLM-ProphetNet model)"),sze.forEach(t),HKo=i(H),Qv=n(H,"LI",{});var lze=s(Qv);FTe=n(lze,"STRONG",{});var VXt=s(FTe);JKo=r(VXt,"xlm-roberta"),VXt.forEach(t),YKo=r(lze," \u2014 "),HU=n(lze,"A",{href:!0});var XXt=s(HU);ZKo=r(XXt,"XLMRobertaForCausalLM"),XXt.forEach(t),KKo=r(lze," (XLM-RoBERTa model)"),lze.forEach(t),eer=i(H),Wv=n(H,"LI",{});var ize=s(Wv);TTe=n(ize,"STRONG",{});var zXt=s(TTe);oer=r(zXt,"xlm-roberta-xl"),zXt.forEach(t),rer=r(ize," \u2014 "),JU=n(ize,"A",{href:!0});var QXt=s(JU);ter=r(QXt,"XLMRobertaXLForCausalLM"),QXt.forEach(t),aer=r(ize," (XLM-RoBERTa-XL model)"),ize.forEach(t),ner=i(H),Uv=n(H,"LI",{});var dze=s(Uv);MTe=n(dze,"STRONG",{});var WXt=s(MTe);ser=r(WXt,"xlnet"),WXt.forEach(t),ler=r(dze," \u2014 "),YU=n(dze,"A",{href:!0});var UXt=s(YU);ier=r(UXt,"XLNetLMHeadModel"),UXt.forEach(t),der=r(dze," (XLNet model)"),dze.forEach(t),H.forEach(t),mer=i(xa),Hv=n(xa,"P",{});var mze=s(Hv);cer=r(mze,"The model is set in evaluation mode by default using "),ETe=n(mze,"CODE",{});var HXt=s(ETe);fer=r(HXt,"model.eval()"),HXt.forEach(t),ger=r(mze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),CTe=n(mze,"CODE",{});var JXt=s(CTe);her=r(JXt,"model.train()"),JXt.forEach(t),mze.forEach(t),uer=i(xa),T(Jv.$$.fragment,xa),xa.forEach(t),Gl.forEach(t),cao=i(c),Od=n(c,"H2",{class:!0});var xso=s(Od);Yv=n(xso,"A",{id:!0,class:!0,href:!0});var YXt=s(Yv);wTe=n(YXt,"SPAN",{});var ZXt=s(wTe);T(ok.$$.fragment,ZXt),ZXt.forEach(t),YXt.forEach(t),per=i(xso),ATe=n(xso,"SPAN",{});var KXt=s(ATe);_er=r(KXt,"AutoModelForDepthEstimation"),KXt.forEach(t),xso.forEach(t),fao=i(c),jo=n(c,"DIV",{class:!0});var Ol=s(jo);T(rk.$$.fragment,Ol),ber=i(Ol),Vd=n(Ol,"P",{});var Mme=s(Vd);ver=r(Mme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),ZU=n(Mme,"A",{href:!0});var ezt=s(ZU);Fer=r(ezt,"from_pretrained()"),ezt.forEach(t),Ter=r(Mme," class method or the "),KU=n(Mme,"A",{href:!0});var ozt=s(KU);Mer=r(ozt,"from_config()"),ozt.forEach(t),Eer=r(Mme,` class
method.`),Mme.forEach(t),Cer=i(Ol),tk=n(Ol,"P",{});var $so=s(tk);wer=r($so,"This class cannot be instantiated directly using "),LTe=n($so,"CODE",{});var rzt=s(LTe);Aer=r(rzt,"__init__()"),rzt.forEach(t),Ler=r($so," (throws an error)."),$so.forEach(t),yer=i(Ol),wt=n(Ol,"DIV",{class:!0});var c9=s(wt);T(ak.$$.fragment,c9),xer=i(c9),yTe=n(c9,"P",{});var tzt=s(yTe);$er=r(tzt,"Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),tzt.forEach(t),ker=i(c9),Xd=n(c9,"P",{});var Eme=s(Xd);Ser=r(Eme,`Note:
Loading a model from its configuration file does `),xTe=n(Eme,"STRONG",{});var azt=s(xTe);Rer=r(azt,"not"),azt.forEach(t),Per=r(Eme,` load the model weights. It only affects the
model\u2019s configuration. Use `),eH=n(Eme,"A",{href:!0});var nzt=s(eH);Ber=r(nzt,"from_pretrained()"),nzt.forEach(t),Ier=r(Eme," to load the model weights."),Eme.forEach(t),Ner=i(c9),T(Zv.$$.fragment,c9),c9.forEach(t),qer=i(Ol),ro=n(Ol,"DIV",{class:!0});var $a=s(ro);T(nk.$$.fragment,$a),jer=i($a),$Te=n($a,"P",{});var szt=s($Te);Der=r(szt,"Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),szt.forEach(t),Ger=i($a),dn=n($a,"P",{});var f9=s(dn);Oer=r(f9,"The model class to instantiate is selected based on the "),kTe=n(f9,"CODE",{});var lzt=s(kTe);Ver=r(lzt,"model_type"),lzt.forEach(t),Xer=r(f9,` property of the config object (either
passed as an argument or loaded from `),STe=n(f9,"CODE",{});var izt=s(STe);zer=r(izt,"pretrained_model_name_or_path"),izt.forEach(t),Qer=r(f9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RTe=n(f9,"CODE",{});var dzt=s(RTe);Wer=r(dzt,"pretrained_model_name_or_path"),dzt.forEach(t),Uer=r(f9,":"),f9.forEach(t),Her=i($a),sk=n($a,"UL",{});var kso=s(sk);Kv=n(kso,"LI",{});var cze=s(Kv);PTe=n(cze,"STRONG",{});var mzt=s(PTe);Jer=r(mzt,"dpt"),mzt.forEach(t),Yer=r(cze," \u2014 "),oH=n(cze,"A",{href:!0});var czt=s(oH);Zer=r(czt,"DPTForDepthEstimation"),czt.forEach(t),Ker=r(cze," (DPT model)"),cze.forEach(t),eor=i(kso),eF=n(kso,"LI",{});var fze=s(eF);BTe=n(fze,"STRONG",{});var fzt=s(BTe);oor=r(fzt,"glpn"),fzt.forEach(t),ror=r(fze," \u2014 "),rH=n(fze,"A",{href:!0});var gzt=s(rH);tor=r(gzt,"GLPNForDepthEstimation"),gzt.forEach(t),aor=r(fze," (GLPN model)"),fze.forEach(t),kso.forEach(t),nor=i($a),oF=n($a,"P",{});var gze=s(oF);sor=r(gze,"The model is set in evaluation mode by default using "),ITe=n(gze,"CODE",{});var hzt=s(ITe);lor=r(hzt,"model.eval()"),hzt.forEach(t),ior=r(gze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),NTe=n(gze,"CODE",{});var uzt=s(NTe);dor=r(uzt,"model.train()"),uzt.forEach(t),gze.forEach(t),mor=i($a),T(rF.$$.fragment,$a),$a.forEach(t),Ol.forEach(t),gao=i(c),zd=n(c,"H2",{class:!0});var Sso=s(zd);tF=n(Sso,"A",{id:!0,class:!0,href:!0});var pzt=s(tF);qTe=n(pzt,"SPAN",{});var _zt=s(qTe);T(lk.$$.fragment,_zt),_zt.forEach(t),pzt.forEach(t),cor=i(Sso),jTe=n(Sso,"SPAN",{});var bzt=s(jTe);gor=r(bzt,"AutoModelForMaskedLM"),bzt.forEach(t),Sso.forEach(t),hao=i(c),Do=n(c,"DIV",{class:!0});var Vl=s(Do);T(ik.$$.fragment,Vl),hor=i(Vl),Qd=n(Vl,"P",{});var Cme=s(Qd);uor=r(Cme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),tH=n(Cme,"A",{href:!0});var vzt=s(tH);por=r(vzt,"from_pretrained()"),vzt.forEach(t),_or=r(Cme," class method or the "),aH=n(Cme,"A",{href:!0});var Fzt=s(aH);bor=r(Fzt,"from_config()"),Fzt.forEach(t),vor=r(Cme,` class
method.`),Cme.forEach(t),For=i(Vl),dk=n(Vl,"P",{});var Rso=s(dk);Tor=r(Rso,"This class cannot be instantiated directly using "),DTe=n(Rso,"CODE",{});var Tzt=s(DTe);Mor=r(Tzt,"__init__()"),Tzt.forEach(t),Eor=r(Rso," (throws an error)."),Rso.forEach(t),Cor=i(Vl),At=n(Vl,"DIV",{class:!0});var g9=s(At);T(mk.$$.fragment,g9),wor=i(g9),GTe=n(g9,"P",{});var Mzt=s(GTe);Aor=r(Mzt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Mzt.forEach(t),Lor=i(g9),Wd=n(g9,"P",{});var wme=s(Wd);yor=r(wme,`Note:
Loading a model from its configuration file does `),OTe=n(wme,"STRONG",{});var Ezt=s(OTe);xor=r(Ezt,"not"),Ezt.forEach(t),$or=r(wme,` load the model weights. It only affects the
model\u2019s configuration. Use `),nH=n(wme,"A",{href:!0});var Czt=s(nH);kor=r(Czt,"from_pretrained()"),Czt.forEach(t),Sor=r(wme," to load the model weights."),wme.forEach(t),Ror=i(g9),T(aF.$$.fragment,g9),g9.forEach(t),Por=i(Vl),to=n(Vl,"DIV",{class:!0});var ka=s(to);T(ck.$$.fragment,ka),Bor=i(ka),VTe=n(ka,"P",{});var wzt=s(VTe);Ior=r(wzt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),wzt.forEach(t),Nor=i(ka),mn=n(ka,"P",{});var h9=s(mn);qor=r(h9,"The model class to instantiate is selected based on the "),XTe=n(h9,"CODE",{});var Azt=s(XTe);jor=r(Azt,"model_type"),Azt.forEach(t),Dor=r(h9,` property of the config object (either
passed as an argument or loaded from `),zTe=n(h9,"CODE",{});var Lzt=s(zTe);Gor=r(Lzt,"pretrained_model_name_or_path"),Lzt.forEach(t),Oor=r(h9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QTe=n(h9,"CODE",{});var yzt=s(QTe);Vor=r(yzt,"pretrained_model_name_or_path"),yzt.forEach(t),Xor=r(h9,":"),h9.forEach(t),zor=i(ka),Y=n(ka,"UL",{});var Z=s(Y);nF=n(Z,"LI",{});var hze=s(nF);WTe=n(hze,"STRONG",{});var xzt=s(WTe);Qor=r(xzt,"albert"),xzt.forEach(t),Wor=r(hze," \u2014 "),sH=n(hze,"A",{href:!0});var $zt=s(sH);Uor=r($zt,"AlbertForMaskedLM"),$zt.forEach(t),Hor=r(hze," (ALBERT model)"),hze.forEach(t),Jor=i(Z),sF=n(Z,"LI",{});var uze=s(sF);UTe=n(uze,"STRONG",{});var kzt=s(UTe);Yor=r(kzt,"bart"),kzt.forEach(t),Zor=r(uze," \u2014 "),lH=n(uze,"A",{href:!0});var Szt=s(lH);Kor=r(Szt,"BartForConditionalGeneration"),Szt.forEach(t),err=r(uze," (BART model)"),uze.forEach(t),orr=i(Z),lF=n(Z,"LI",{});var pze=s(lF);HTe=n(pze,"STRONG",{});var Rzt=s(HTe);rrr=r(Rzt,"bert"),Rzt.forEach(t),trr=r(pze," \u2014 "),iH=n(pze,"A",{href:!0});var Pzt=s(iH);arr=r(Pzt,"BertForMaskedLM"),Pzt.forEach(t),nrr=r(pze," (BERT model)"),pze.forEach(t),srr=i(Z),iF=n(Z,"LI",{});var _ze=s(iF);JTe=n(_ze,"STRONG",{});var Bzt=s(JTe);lrr=r(Bzt,"big_bird"),Bzt.forEach(t),irr=r(_ze," \u2014 "),dH=n(_ze,"A",{href:!0});var Izt=s(dH);drr=r(Izt,"BigBirdForMaskedLM"),Izt.forEach(t),mrr=r(_ze," (BigBird model)"),_ze.forEach(t),crr=i(Z),dF=n(Z,"LI",{});var bze=s(dF);YTe=n(bze,"STRONG",{});var Nzt=s(YTe);frr=r(Nzt,"camembert"),Nzt.forEach(t),grr=r(bze," \u2014 "),mH=n(bze,"A",{href:!0});var qzt=s(mH);hrr=r(qzt,"CamembertForMaskedLM"),qzt.forEach(t),urr=r(bze," (CamemBERT model)"),bze.forEach(t),prr=i(Z),mF=n(Z,"LI",{});var vze=s(mF);ZTe=n(vze,"STRONG",{});var jzt=s(ZTe);_rr=r(jzt,"convbert"),jzt.forEach(t),brr=r(vze," \u2014 "),cH=n(vze,"A",{href:!0});var Dzt=s(cH);vrr=r(Dzt,"ConvBertForMaskedLM"),Dzt.forEach(t),Frr=r(vze," (ConvBERT model)"),vze.forEach(t),Trr=i(Z),cF=n(Z,"LI",{});var Fze=s(cF);KTe=n(Fze,"STRONG",{});var Gzt=s(KTe);Mrr=r(Gzt,"data2vec-text"),Gzt.forEach(t),Err=r(Fze," \u2014 "),fH=n(Fze,"A",{href:!0});var Ozt=s(fH);Crr=r(Ozt,"Data2VecTextForMaskedLM"),Ozt.forEach(t),wrr=r(Fze," (Data2VecText model)"),Fze.forEach(t),Arr=i(Z),fF=n(Z,"LI",{});var Tze=s(fF);eMe=n(Tze,"STRONG",{});var Vzt=s(eMe);Lrr=r(Vzt,"deberta"),Vzt.forEach(t),yrr=r(Tze," \u2014 "),gH=n(Tze,"A",{href:!0});var Xzt=s(gH);xrr=r(Xzt,"DebertaForMaskedLM"),Xzt.forEach(t),$rr=r(Tze," (DeBERTa model)"),Tze.forEach(t),krr=i(Z),gF=n(Z,"LI",{});var Mze=s(gF);oMe=n(Mze,"STRONG",{});var zzt=s(oMe);Srr=r(zzt,"deberta-v2"),zzt.forEach(t),Rrr=r(Mze," \u2014 "),hH=n(Mze,"A",{href:!0});var Qzt=s(hH);Prr=r(Qzt,"DebertaV2ForMaskedLM"),Qzt.forEach(t),Brr=r(Mze," (DeBERTa-v2 model)"),Mze.forEach(t),Irr=i(Z),hF=n(Z,"LI",{});var Eze=s(hF);rMe=n(Eze,"STRONG",{});var Wzt=s(rMe);Nrr=r(Wzt,"distilbert"),Wzt.forEach(t),qrr=r(Eze," \u2014 "),uH=n(Eze,"A",{href:!0});var Uzt=s(uH);jrr=r(Uzt,"DistilBertForMaskedLM"),Uzt.forEach(t),Drr=r(Eze," (DistilBERT model)"),Eze.forEach(t),Grr=i(Z),uF=n(Z,"LI",{});var Cze=s(uF);tMe=n(Cze,"STRONG",{});var Hzt=s(tMe);Orr=r(Hzt,"electra"),Hzt.forEach(t),Vrr=r(Cze," \u2014 "),pH=n(Cze,"A",{href:!0});var Jzt=s(pH);Xrr=r(Jzt,"ElectraForMaskedLM"),Jzt.forEach(t),zrr=r(Cze," (ELECTRA model)"),Cze.forEach(t),Qrr=i(Z),pF=n(Z,"LI",{});var wze=s(pF);aMe=n(wze,"STRONG",{});var Yzt=s(aMe);Wrr=r(Yzt,"ernie"),Yzt.forEach(t),Urr=r(wze," \u2014 "),_H=n(wze,"A",{href:!0});var Zzt=s(_H);Hrr=r(Zzt,"ErnieForMaskedLM"),Zzt.forEach(t),Jrr=r(wze," (ERNIE model)"),wze.forEach(t),Yrr=i(Z),_F=n(Z,"LI",{});var Aze=s(_F);nMe=n(Aze,"STRONG",{});var Kzt=s(nMe);Zrr=r(Kzt,"flaubert"),Kzt.forEach(t),Krr=r(Aze," \u2014 "),bH=n(Aze,"A",{href:!0});var eQt=s(bH);etr=r(eQt,"FlaubertWithLMHeadModel"),eQt.forEach(t),otr=r(Aze," (FlauBERT model)"),Aze.forEach(t),rtr=i(Z),bF=n(Z,"LI",{});var Lze=s(bF);sMe=n(Lze,"STRONG",{});var oQt=s(sMe);ttr=r(oQt,"fnet"),oQt.forEach(t),atr=r(Lze," \u2014 "),vH=n(Lze,"A",{href:!0});var rQt=s(vH);ntr=r(rQt,"FNetForMaskedLM"),rQt.forEach(t),str=r(Lze," (FNet model)"),Lze.forEach(t),ltr=i(Z),vF=n(Z,"LI",{});var yze=s(vF);lMe=n(yze,"STRONG",{});var tQt=s(lMe);itr=r(tQt,"funnel"),tQt.forEach(t),dtr=r(yze," \u2014 "),FH=n(yze,"A",{href:!0});var aQt=s(FH);mtr=r(aQt,"FunnelForMaskedLM"),aQt.forEach(t),ctr=r(yze," (Funnel Transformer model)"),yze.forEach(t),ftr=i(Z),FF=n(Z,"LI",{});var xze=s(FF);iMe=n(xze,"STRONG",{});var nQt=s(iMe);gtr=r(nQt,"ibert"),nQt.forEach(t),htr=r(xze," \u2014 "),TH=n(xze,"A",{href:!0});var sQt=s(TH);utr=r(sQt,"IBertForMaskedLM"),sQt.forEach(t),ptr=r(xze," (I-BERT model)"),xze.forEach(t),_tr=i(Z),TF=n(Z,"LI",{});var $ze=s(TF);dMe=n($ze,"STRONG",{});var lQt=s(dMe);btr=r(lQt,"layoutlm"),lQt.forEach(t),vtr=r($ze," \u2014 "),MH=n($ze,"A",{href:!0});var iQt=s(MH);Ftr=r(iQt,"LayoutLMForMaskedLM"),iQt.forEach(t),Ttr=r($ze," (LayoutLM model)"),$ze.forEach(t),Mtr=i(Z),MF=n(Z,"LI",{});var kze=s(MF);mMe=n(kze,"STRONG",{});var dQt=s(mMe);Etr=r(dQt,"longformer"),dQt.forEach(t),Ctr=r(kze," \u2014 "),EH=n(kze,"A",{href:!0});var mQt=s(EH);wtr=r(mQt,"LongformerForMaskedLM"),mQt.forEach(t),Atr=r(kze," (Longformer model)"),kze.forEach(t),Ltr=i(Z),EF=n(Z,"LI",{});var Sze=s(EF);cMe=n(Sze,"STRONG",{});var cQt=s(cMe);ytr=r(cQt,"luke"),cQt.forEach(t),xtr=r(Sze," \u2014 "),CH=n(Sze,"A",{href:!0});var fQt=s(CH);$tr=r(fQt,"LukeForMaskedLM"),fQt.forEach(t),ktr=r(Sze," (LUKE model)"),Sze.forEach(t),Str=i(Z),CF=n(Z,"LI",{});var Rze=s(CF);fMe=n(Rze,"STRONG",{});var gQt=s(fMe);Rtr=r(gQt,"mbart"),gQt.forEach(t),Ptr=r(Rze," \u2014 "),wH=n(Rze,"A",{href:!0});var hQt=s(wH);Btr=r(hQt,"MBartForConditionalGeneration"),hQt.forEach(t),Itr=r(Rze," (mBART model)"),Rze.forEach(t),Ntr=i(Z),wF=n(Z,"LI",{});var Pze=s(wF);gMe=n(Pze,"STRONG",{});var uQt=s(gMe);qtr=r(uQt,"megatron-bert"),uQt.forEach(t),jtr=r(Pze," \u2014 "),AH=n(Pze,"A",{href:!0});var pQt=s(AH);Dtr=r(pQt,"MegatronBertForMaskedLM"),pQt.forEach(t),Gtr=r(Pze," (Megatron-BERT model)"),Pze.forEach(t),Otr=i(Z),AF=n(Z,"LI",{});var Bze=s(AF);hMe=n(Bze,"STRONG",{});var _Qt=s(hMe);Vtr=r(_Qt,"mobilebert"),_Qt.forEach(t),Xtr=r(Bze," \u2014 "),LH=n(Bze,"A",{href:!0});var bQt=s(LH);ztr=r(bQt,"MobileBertForMaskedLM"),bQt.forEach(t),Qtr=r(Bze," (MobileBERT model)"),Bze.forEach(t),Wtr=i(Z),LF=n(Z,"LI",{});var Ize=s(LF);uMe=n(Ize,"STRONG",{});var vQt=s(uMe);Utr=r(vQt,"mpnet"),vQt.forEach(t),Htr=r(Ize," \u2014 "),yH=n(Ize,"A",{href:!0});var FQt=s(yH);Jtr=r(FQt,"MPNetForMaskedLM"),FQt.forEach(t),Ytr=r(Ize," (MPNet model)"),Ize.forEach(t),Ztr=i(Z),yF=n(Z,"LI",{});var Nze=s(yF);pMe=n(Nze,"STRONG",{});var TQt=s(pMe);Ktr=r(TQt,"mvp"),TQt.forEach(t),ear=r(Nze," \u2014 "),xH=n(Nze,"A",{href:!0});var MQt=s(xH);oar=r(MQt,"MvpForConditionalGeneration"),MQt.forEach(t),rar=r(Nze," (MVP model)"),Nze.forEach(t),tar=i(Z),xF=n(Z,"LI",{});var qze=s(xF);_Me=n(qze,"STRONG",{});var EQt=s(_Me);aar=r(EQt,"nezha"),EQt.forEach(t),nar=r(qze," \u2014 "),$H=n(qze,"A",{href:!0});var CQt=s($H);sar=r(CQt,"NezhaForMaskedLM"),CQt.forEach(t),lar=r(qze," (Nezha model)"),qze.forEach(t),iar=i(Z),$F=n(Z,"LI",{});var jze=s($F);bMe=n(jze,"STRONG",{});var wQt=s(bMe);dar=r(wQt,"nystromformer"),wQt.forEach(t),mar=r(jze," \u2014 "),kH=n(jze,"A",{href:!0});var AQt=s(kH);car=r(AQt,"NystromformerForMaskedLM"),AQt.forEach(t),far=r(jze," (Nystr\xF6mformer model)"),jze.forEach(t),gar=i(Z),kF=n(Z,"LI",{});var Dze=s(kF);vMe=n(Dze,"STRONG",{});var LQt=s(vMe);har=r(LQt,"perceiver"),LQt.forEach(t),uar=r(Dze," \u2014 "),SH=n(Dze,"A",{href:!0});var yQt=s(SH);par=r(yQt,"PerceiverForMaskedLM"),yQt.forEach(t),_ar=r(Dze," (Perceiver model)"),Dze.forEach(t),bar=i(Z),SF=n(Z,"LI",{});var Gze=s(SF);FMe=n(Gze,"STRONG",{});var xQt=s(FMe);Far=r(xQt,"qdqbert"),xQt.forEach(t),Tar=r(Gze," \u2014 "),RH=n(Gze,"A",{href:!0});var $Qt=s(RH);Mar=r($Qt,"QDQBertForMaskedLM"),$Qt.forEach(t),Ear=r(Gze," (QDQBert model)"),Gze.forEach(t),Car=i(Z),RF=n(Z,"LI",{});var Oze=s(RF);TMe=n(Oze,"STRONG",{});var kQt=s(TMe);war=r(kQt,"reformer"),kQt.forEach(t),Aar=r(Oze," \u2014 "),PH=n(Oze,"A",{href:!0});var SQt=s(PH);Lar=r(SQt,"ReformerForMaskedLM"),SQt.forEach(t),yar=r(Oze," (Reformer model)"),Oze.forEach(t),xar=i(Z),PF=n(Z,"LI",{});var Vze=s(PF);MMe=n(Vze,"STRONG",{});var RQt=s(MMe);$ar=r(RQt,"rembert"),RQt.forEach(t),kar=r(Vze," \u2014 "),BH=n(Vze,"A",{href:!0});var PQt=s(BH);Sar=r(PQt,"RemBertForMaskedLM"),PQt.forEach(t),Rar=r(Vze," (RemBERT model)"),Vze.forEach(t),Par=i(Z),BF=n(Z,"LI",{});var Xze=s(BF);EMe=n(Xze,"STRONG",{});var BQt=s(EMe);Bar=r(BQt,"roberta"),BQt.forEach(t),Iar=r(Xze," \u2014 "),IH=n(Xze,"A",{href:!0});var IQt=s(IH);Nar=r(IQt,"RobertaForMaskedLM"),IQt.forEach(t),qar=r(Xze," (RoBERTa model)"),Xze.forEach(t),jar=i(Z),IF=n(Z,"LI",{});var zze=s(IF);CMe=n(zze,"STRONG",{});var NQt=s(CMe);Dar=r(NQt,"roformer"),NQt.forEach(t),Gar=r(zze," \u2014 "),NH=n(zze,"A",{href:!0});var qQt=s(NH);Oar=r(qQt,"RoFormerForMaskedLM"),qQt.forEach(t),Var=r(zze," (RoFormer model)"),zze.forEach(t),Xar=i(Z),NF=n(Z,"LI",{});var Qze=s(NF);wMe=n(Qze,"STRONG",{});var jQt=s(wMe);zar=r(jQt,"squeezebert"),jQt.forEach(t),Qar=r(Qze," \u2014 "),qH=n(Qze,"A",{href:!0});var DQt=s(qH);War=r(DQt,"SqueezeBertForMaskedLM"),DQt.forEach(t),Uar=r(Qze," (SqueezeBERT model)"),Qze.forEach(t),Har=i(Z),qF=n(Z,"LI",{});var Wze=s(qF);AMe=n(Wze,"STRONG",{});var GQt=s(AMe);Jar=r(GQt,"tapas"),GQt.forEach(t),Yar=r(Wze," \u2014 "),jH=n(Wze,"A",{href:!0});var OQt=s(jH);Zar=r(OQt,"TapasForMaskedLM"),OQt.forEach(t),Kar=r(Wze," (TAPAS model)"),Wze.forEach(t),enr=i(Z),jF=n(Z,"LI",{});var Uze=s(jF);LMe=n(Uze,"STRONG",{});var VQt=s(LMe);onr=r(VQt,"wav2vec2"),VQt.forEach(t),rnr=r(Uze," \u2014 "),yMe=n(Uze,"CODE",{});var XQt=s(yMe);tnr=r(XQt,"Wav2Vec2ForMaskedLM"),XQt.forEach(t),anr=r(Uze," (Wav2Vec2 model)"),Uze.forEach(t),nnr=i(Z),DF=n(Z,"LI",{});var Hze=s(DF);xMe=n(Hze,"STRONG",{});var zQt=s(xMe);snr=r(zQt,"xlm"),zQt.forEach(t),lnr=r(Hze," \u2014 "),DH=n(Hze,"A",{href:!0});var QQt=s(DH);inr=r(QQt,"XLMWithLMHeadModel"),QQt.forEach(t),dnr=r(Hze," (XLM model)"),Hze.forEach(t),mnr=i(Z),GF=n(Z,"LI",{});var Jze=s(GF);$Me=n(Jze,"STRONG",{});var WQt=s($Me);cnr=r(WQt,"xlm-roberta"),WQt.forEach(t),fnr=r(Jze," \u2014 "),GH=n(Jze,"A",{href:!0});var UQt=s(GH);gnr=r(UQt,"XLMRobertaForMaskedLM"),UQt.forEach(t),hnr=r(Jze," (XLM-RoBERTa model)"),Jze.forEach(t),unr=i(Z),OF=n(Z,"LI",{});var Yze=s(OF);kMe=n(Yze,"STRONG",{});var HQt=s(kMe);pnr=r(HQt,"xlm-roberta-xl"),HQt.forEach(t),_nr=r(Yze," \u2014 "),OH=n(Yze,"A",{href:!0});var JQt=s(OH);bnr=r(JQt,"XLMRobertaXLForMaskedLM"),JQt.forEach(t),vnr=r(Yze," (XLM-RoBERTa-XL model)"),Yze.forEach(t),Fnr=i(Z),VF=n(Z,"LI",{});var Zze=s(VF);SMe=n(Zze,"STRONG",{});var YQt=s(SMe);Tnr=r(YQt,"yoso"),YQt.forEach(t),Mnr=r(Zze," \u2014 "),VH=n(Zze,"A",{href:!0});var ZQt=s(VH);Enr=r(ZQt,"YosoForMaskedLM"),ZQt.forEach(t),Cnr=r(Zze," (YOSO model)"),Zze.forEach(t),Z.forEach(t),wnr=i(ka),XF=n(ka,"P",{});var Kze=s(XF);Anr=r(Kze,"The model is set in evaluation mode by default using "),RMe=n(Kze,"CODE",{});var KQt=s(RMe);Lnr=r(KQt,"model.eval()"),KQt.forEach(t),ynr=r(Kze,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),PMe=n(Kze,"CODE",{});var eWt=s(PMe);xnr=r(eWt,"model.train()"),eWt.forEach(t),Kze.forEach(t),$nr=i(ka),T(zF.$$.fragment,ka),ka.forEach(t),Vl.forEach(t),uao=i(c),Ud=n(c,"H2",{class:!0});var Pso=s(Ud);QF=n(Pso,"A",{id:!0,class:!0,href:!0});var oWt=s(QF);BMe=n(oWt,"SPAN",{});var rWt=s(BMe);T(fk.$$.fragment,rWt),rWt.forEach(t),oWt.forEach(t),knr=i(Pso),IMe=n(Pso,"SPAN",{});var tWt=s(IMe);Snr=r(tWt,"AutoModelForSeq2SeqLM"),tWt.forEach(t),Pso.forEach(t),pao=i(c),Go=n(c,"DIV",{class:!0});var Xl=s(Go);T(gk.$$.fragment,Xl),Rnr=i(Xl),Hd=n(Xl,"P",{});var Ame=s(Hd);Pnr=r(Ame,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),XH=n(Ame,"A",{href:!0});var aWt=s(XH);Bnr=r(aWt,"from_pretrained()"),aWt.forEach(t),Inr=r(Ame," class method or the "),zH=n(Ame,"A",{href:!0});var nWt=s(zH);Nnr=r(nWt,"from_config()"),nWt.forEach(t),qnr=r(Ame,` class
method.`),Ame.forEach(t),jnr=i(Xl),hk=n(Xl,"P",{});var Bso=s(hk);Dnr=r(Bso,"This class cannot be instantiated directly using "),NMe=n(Bso,"CODE",{});var sWt=s(NMe);Gnr=r(sWt,"__init__()"),sWt.forEach(t),Onr=r(Bso," (throws an error)."),Bso.forEach(t),Vnr=i(Xl),Lt=n(Xl,"DIV",{class:!0});var u9=s(Lt);T(uk.$$.fragment,u9),Xnr=i(u9),qMe=n(u9,"P",{});var lWt=s(qMe);znr=r(lWt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),lWt.forEach(t),Qnr=i(u9),Jd=n(u9,"P",{});var Lme=s(Jd);Wnr=r(Lme,`Note:
Loading a model from its configuration file does `),jMe=n(Lme,"STRONG",{});var iWt=s(jMe);Unr=r(iWt,"not"),iWt.forEach(t),Hnr=r(Lme,` load the model weights. It only affects the
model\u2019s configuration. Use `),QH=n(Lme,"A",{href:!0});var dWt=s(QH);Jnr=r(dWt,"from_pretrained()"),dWt.forEach(t),Ynr=r(Lme," to load the model weights."),Lme.forEach(t),Znr=i(u9),T(WF.$$.fragment,u9),u9.forEach(t),Knr=i(Xl),ao=n(Xl,"DIV",{class:!0});var Sa=s(ao);T(pk.$$.fragment,Sa),esr=i(Sa),DMe=n(Sa,"P",{});var mWt=s(DMe);osr=r(mWt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),mWt.forEach(t),rsr=i(Sa),cn=n(Sa,"P",{});var p9=s(cn);tsr=r(p9,"The model class to instantiate is selected based on the "),GMe=n(p9,"CODE",{});var cWt=s(GMe);asr=r(cWt,"model_type"),cWt.forEach(t),nsr=r(p9,` property of the config object (either
passed as an argument or loaded from `),OMe=n(p9,"CODE",{});var fWt=s(OMe);ssr=r(fWt,"pretrained_model_name_or_path"),fWt.forEach(t),lsr=r(p9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VMe=n(p9,"CODE",{});var gWt=s(VMe);isr=r(gWt,"pretrained_model_name_or_path"),gWt.forEach(t),dsr=r(p9,":"),p9.forEach(t),msr=i(Sa),he=n(Sa,"UL",{});var _e=s(he);UF=n(_e,"LI",{});var eQe=s(UF);XMe=n(eQe,"STRONG",{});var hWt=s(XMe);csr=r(hWt,"bart"),hWt.forEach(t),fsr=r(eQe," \u2014 "),WH=n(eQe,"A",{href:!0});var uWt=s(WH);gsr=r(uWt,"BartForConditionalGeneration"),uWt.forEach(t),hsr=r(eQe," (BART model)"),eQe.forEach(t),usr=i(_e),HF=n(_e,"LI",{});var oQe=s(HF);zMe=n(oQe,"STRONG",{});var pWt=s(zMe);psr=r(pWt,"bigbird_pegasus"),pWt.forEach(t),_sr=r(oQe," \u2014 "),UH=n(oQe,"A",{href:!0});var _Wt=s(UH);bsr=r(_Wt,"BigBirdPegasusForConditionalGeneration"),_Wt.forEach(t),vsr=r(oQe," (BigBird-Pegasus model)"),oQe.forEach(t),Fsr=i(_e),JF=n(_e,"LI",{});var rQe=s(JF);QMe=n(rQe,"STRONG",{});var bWt=s(QMe);Tsr=r(bWt,"blenderbot"),bWt.forEach(t),Msr=r(rQe," \u2014 "),HH=n(rQe,"A",{href:!0});var vWt=s(HH);Esr=r(vWt,"BlenderbotForConditionalGeneration"),vWt.forEach(t),Csr=r(rQe," (Blenderbot model)"),rQe.forEach(t),wsr=i(_e),YF=n(_e,"LI",{});var tQe=s(YF);WMe=n(tQe,"STRONG",{});var FWt=s(WMe);Asr=r(FWt,"blenderbot-small"),FWt.forEach(t),Lsr=r(tQe," \u2014 "),JH=n(tQe,"A",{href:!0});var TWt=s(JH);ysr=r(TWt,"BlenderbotSmallForConditionalGeneration"),TWt.forEach(t),xsr=r(tQe," (BlenderbotSmall model)"),tQe.forEach(t),$sr=i(_e),ZF=n(_e,"LI",{});var aQe=s(ZF);UMe=n(aQe,"STRONG",{});var MWt=s(UMe);ksr=r(MWt,"encoder-decoder"),MWt.forEach(t),Ssr=r(aQe," \u2014 "),YH=n(aQe,"A",{href:!0});var EWt=s(YH);Rsr=r(EWt,"EncoderDecoderModel"),EWt.forEach(t),Psr=r(aQe," (Encoder decoder model)"),aQe.forEach(t),Bsr=i(_e),KF=n(_e,"LI",{});var nQe=s(KF);HMe=n(nQe,"STRONG",{});var CWt=s(HMe);Isr=r(CWt,"fsmt"),CWt.forEach(t),Nsr=r(nQe," \u2014 "),ZH=n(nQe,"A",{href:!0});var wWt=s(ZH);qsr=r(wWt,"FSMTForConditionalGeneration"),wWt.forEach(t),jsr=r(nQe," (FairSeq Machine-Translation model)"),nQe.forEach(t),Dsr=i(_e),eT=n(_e,"LI",{});var sQe=s(eT);JMe=n(sQe,"STRONG",{});var AWt=s(JMe);Gsr=r(AWt,"led"),AWt.forEach(t),Osr=r(sQe," \u2014 "),KH=n(sQe,"A",{href:!0});var LWt=s(KH);Vsr=r(LWt,"LEDForConditionalGeneration"),LWt.forEach(t),Xsr=r(sQe," (LED model)"),sQe.forEach(t),zsr=i(_e),oT=n(_e,"LI",{});var lQe=s(oT);YMe=n(lQe,"STRONG",{});var yWt=s(YMe);Qsr=r(yWt,"longt5"),yWt.forEach(t),Wsr=r(lQe," \u2014 "),eJ=n(lQe,"A",{href:!0});var xWt=s(eJ);Usr=r(xWt,"LongT5ForConditionalGeneration"),xWt.forEach(t),Hsr=r(lQe," (LongT5 model)"),lQe.forEach(t),Jsr=i(_e),rT=n(_e,"LI",{});var iQe=s(rT);ZMe=n(iQe,"STRONG",{});var $Wt=s(ZMe);Ysr=r($Wt,"m2m_100"),$Wt.forEach(t),Zsr=r(iQe," \u2014 "),oJ=n(iQe,"A",{href:!0});var kWt=s(oJ);Ksr=r(kWt,"M2M100ForConditionalGeneration"),kWt.forEach(t),elr=r(iQe," (M2M100 model)"),iQe.forEach(t),olr=i(_e),tT=n(_e,"LI",{});var dQe=s(tT);KMe=n(dQe,"STRONG",{});var SWt=s(KMe);rlr=r(SWt,"marian"),SWt.forEach(t),tlr=r(dQe," \u2014 "),rJ=n(dQe,"A",{href:!0});var RWt=s(rJ);alr=r(RWt,"MarianMTModel"),RWt.forEach(t),nlr=r(dQe," (Marian model)"),dQe.forEach(t),slr=i(_e),aT=n(_e,"LI",{});var mQe=s(aT);eEe=n(mQe,"STRONG",{});var PWt=s(eEe);llr=r(PWt,"mbart"),PWt.forEach(t),ilr=r(mQe," \u2014 "),tJ=n(mQe,"A",{href:!0});var BWt=s(tJ);dlr=r(BWt,"MBartForConditionalGeneration"),BWt.forEach(t),mlr=r(mQe," (mBART model)"),mQe.forEach(t),clr=i(_e),nT=n(_e,"LI",{});var cQe=s(nT);oEe=n(cQe,"STRONG",{});var IWt=s(oEe);flr=r(IWt,"mt5"),IWt.forEach(t),glr=r(cQe," \u2014 "),aJ=n(cQe,"A",{href:!0});var NWt=s(aJ);hlr=r(NWt,"MT5ForConditionalGeneration"),NWt.forEach(t),ulr=r(cQe," (MT5 model)"),cQe.forEach(t),plr=i(_e),sT=n(_e,"LI",{});var fQe=s(sT);rEe=n(fQe,"STRONG",{});var qWt=s(rEe);_lr=r(qWt,"mvp"),qWt.forEach(t),blr=r(fQe," \u2014 "),nJ=n(fQe,"A",{href:!0});var jWt=s(nJ);vlr=r(jWt,"MvpForConditionalGeneration"),jWt.forEach(t),Flr=r(fQe," (MVP model)"),fQe.forEach(t),Tlr=i(_e),lT=n(_e,"LI",{});var gQe=s(lT);tEe=n(gQe,"STRONG",{});var DWt=s(tEe);Mlr=r(DWt,"nllb"),DWt.forEach(t),Elr=r(gQe," \u2014 "),sJ=n(gQe,"A",{href:!0});var GWt=s(sJ);Clr=r(GWt,"M2M100ForConditionalGeneration"),GWt.forEach(t),wlr=r(gQe," (NLLB model)"),gQe.forEach(t),Alr=i(_e),iT=n(_e,"LI",{});var hQe=s(iT);aEe=n(hQe,"STRONG",{});var OWt=s(aEe);Llr=r(OWt,"pegasus"),OWt.forEach(t),ylr=r(hQe," \u2014 "),lJ=n(hQe,"A",{href:!0});var VWt=s(lJ);xlr=r(VWt,"PegasusForConditionalGeneration"),VWt.forEach(t),$lr=r(hQe," (Pegasus model)"),hQe.forEach(t),klr=i(_e),dT=n(_e,"LI",{});var uQe=s(dT);nEe=n(uQe,"STRONG",{});var XWt=s(nEe);Slr=r(XWt,"pegasus_x"),XWt.forEach(t),Rlr=r(uQe," \u2014 "),iJ=n(uQe,"A",{href:!0});var zWt=s(iJ);Plr=r(zWt,"PegasusXForConditionalGeneration"),zWt.forEach(t),Blr=r(uQe," (PEGASUS-X model)"),uQe.forEach(t),Ilr=i(_e),mT=n(_e,"LI",{});var pQe=s(mT);sEe=n(pQe,"STRONG",{});var QWt=s(sEe);Nlr=r(QWt,"plbart"),QWt.forEach(t),qlr=r(pQe," \u2014 "),dJ=n(pQe,"A",{href:!0});var WWt=s(dJ);jlr=r(WWt,"PLBartForConditionalGeneration"),WWt.forEach(t),Dlr=r(pQe," (PLBart model)"),pQe.forEach(t),Glr=i(_e),cT=n(_e,"LI",{});var _Qe=s(cT);lEe=n(_Qe,"STRONG",{});var UWt=s(lEe);Olr=r(UWt,"prophetnet"),UWt.forEach(t),Vlr=r(_Qe," \u2014 "),mJ=n(_Qe,"A",{href:!0});var HWt=s(mJ);Xlr=r(HWt,"ProphetNetForConditionalGeneration"),HWt.forEach(t),zlr=r(_Qe," (ProphetNet model)"),_Qe.forEach(t),Qlr=i(_e),fT=n(_e,"LI",{});var bQe=s(fT);iEe=n(bQe,"STRONG",{});var JWt=s(iEe);Wlr=r(JWt,"t5"),JWt.forEach(t),Ulr=r(bQe," \u2014 "),cJ=n(bQe,"A",{href:!0});var YWt=s(cJ);Hlr=r(YWt,"T5ForConditionalGeneration"),YWt.forEach(t),Jlr=r(bQe," (T5 model)"),bQe.forEach(t),Ylr=i(_e),gT=n(_e,"LI",{});var vQe=s(gT);dEe=n(vQe,"STRONG",{});var ZWt=s(dEe);Zlr=r(ZWt,"xlm-prophetnet"),ZWt.forEach(t),Klr=r(vQe," \u2014 "),fJ=n(vQe,"A",{href:!0});var KWt=s(fJ);eir=r(KWt,"XLMProphetNetForConditionalGeneration"),KWt.forEach(t),oir=r(vQe," (XLM-ProphetNet model)"),vQe.forEach(t),_e.forEach(t),rir=i(Sa),hT=n(Sa,"P",{});var FQe=s(hT);tir=r(FQe,"The model is set in evaluation mode by default using "),mEe=n(FQe,"CODE",{});var eUt=s(mEe);air=r(eUt,"model.eval()"),eUt.forEach(t),nir=r(FQe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cEe=n(FQe,"CODE",{});var oUt=s(cEe);sir=r(oUt,"model.train()"),oUt.forEach(t),FQe.forEach(t),lir=i(Sa),T(uT.$$.fragment,Sa),Sa.forEach(t),Xl.forEach(t),_ao=i(c),Yd=n(c,"H2",{class:!0});var Iso=s(Yd);pT=n(Iso,"A",{id:!0,class:!0,href:!0});var rUt=s(pT);fEe=n(rUt,"SPAN",{});var tUt=s(fEe);T(_k.$$.fragment,tUt),tUt.forEach(t),rUt.forEach(t),iir=i(Iso),gEe=n(Iso,"SPAN",{});var aUt=s(gEe);dir=r(aUt,"AutoModelForSequenceClassification"),aUt.forEach(t),Iso.forEach(t),bao=i(c),Oo=n(c,"DIV",{class:!0});var zl=s(Oo);T(bk.$$.fragment,zl),mir=i(zl),Zd=n(zl,"P",{});var yme=s(Zd);cir=r(yme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),gJ=n(yme,"A",{href:!0});var nUt=s(gJ);fir=r(nUt,"from_pretrained()"),nUt.forEach(t),gir=r(yme," class method or the "),hJ=n(yme,"A",{href:!0});var sUt=s(hJ);hir=r(sUt,"from_config()"),sUt.forEach(t),uir=r(yme,` class
method.`),yme.forEach(t),pir=i(zl),vk=n(zl,"P",{});var Nso=s(vk);_ir=r(Nso,"This class cannot be instantiated directly using "),hEe=n(Nso,"CODE",{});var lUt=s(hEe);bir=r(lUt,"__init__()"),lUt.forEach(t),vir=r(Nso," (throws an error)."),Nso.forEach(t),Fir=i(zl),yt=n(zl,"DIV",{class:!0});var _9=s(yt);T(Fk.$$.fragment,_9),Tir=i(_9),uEe=n(_9,"P",{});var iUt=s(uEe);Mir=r(iUt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),iUt.forEach(t),Eir=i(_9),Kd=n(_9,"P",{});var xme=s(Kd);Cir=r(xme,`Note:
Loading a model from its configuration file does `),pEe=n(xme,"STRONG",{});var dUt=s(pEe);wir=r(dUt,"not"),dUt.forEach(t),Air=r(xme,` load the model weights. It only affects the
model\u2019s configuration. Use `),uJ=n(xme,"A",{href:!0});var mUt=s(uJ);Lir=r(mUt,"from_pretrained()"),mUt.forEach(t),yir=r(xme," to load the model weights."),xme.forEach(t),xir=i(_9),T(_T.$$.fragment,_9),_9.forEach(t),$ir=i(zl),no=n(zl,"DIV",{class:!0});var Ra=s(no);T(Tk.$$.fragment,Ra),kir=i(Ra),_Ee=n(Ra,"P",{});var cUt=s(_Ee);Sir=r(cUt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),cUt.forEach(t),Rir=i(Ra),fn=n(Ra,"P",{});var b9=s(fn);Pir=r(b9,"The model class to instantiate is selected based on the "),bEe=n(b9,"CODE",{});var fUt=s(bEe);Bir=r(fUt,"model_type"),fUt.forEach(t),Iir=r(b9,` property of the config object (either
passed as an argument or loaded from `),vEe=n(b9,"CODE",{});var gUt=s(vEe);Nir=r(gUt,"pretrained_model_name_or_path"),gUt.forEach(t),qir=r(b9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FEe=n(b9,"CODE",{});var hUt=s(FEe);jir=r(hUt,"pretrained_model_name_or_path"),hUt.forEach(t),Dir=r(b9,":"),b9.forEach(t),Gir=i(Ra),j=n(Ra,"UL",{});var D=s(j);bT=n(D,"LI",{});var TQe=s(bT);TEe=n(TQe,"STRONG",{});var uUt=s(TEe);Oir=r(uUt,"albert"),uUt.forEach(t),Vir=r(TQe," \u2014 "),pJ=n(TQe,"A",{href:!0});var pUt=s(pJ);Xir=r(pUt,"AlbertForSequenceClassification"),pUt.forEach(t),zir=r(TQe," (ALBERT model)"),TQe.forEach(t),Qir=i(D),vT=n(D,"LI",{});var MQe=s(vT);MEe=n(MQe,"STRONG",{});var _Ut=s(MEe);Wir=r(_Ut,"bart"),_Ut.forEach(t),Uir=r(MQe," \u2014 "),_J=n(MQe,"A",{href:!0});var bUt=s(_J);Hir=r(bUt,"BartForSequenceClassification"),bUt.forEach(t),Jir=r(MQe," (BART model)"),MQe.forEach(t),Yir=i(D),FT=n(D,"LI",{});var EQe=s(FT);EEe=n(EQe,"STRONG",{});var vUt=s(EEe);Zir=r(vUt,"bert"),vUt.forEach(t),Kir=r(EQe," \u2014 "),bJ=n(EQe,"A",{href:!0});var FUt=s(bJ);edr=r(FUt,"BertForSequenceClassification"),FUt.forEach(t),odr=r(EQe," (BERT model)"),EQe.forEach(t),rdr=i(D),TT=n(D,"LI",{});var CQe=s(TT);CEe=n(CQe,"STRONG",{});var TUt=s(CEe);tdr=r(TUt,"big_bird"),TUt.forEach(t),adr=r(CQe," \u2014 "),vJ=n(CQe,"A",{href:!0});var MUt=s(vJ);ndr=r(MUt,"BigBirdForSequenceClassification"),MUt.forEach(t),sdr=r(CQe," (BigBird model)"),CQe.forEach(t),ldr=i(D),MT=n(D,"LI",{});var wQe=s(MT);wEe=n(wQe,"STRONG",{});var EUt=s(wEe);idr=r(EUt,"bigbird_pegasus"),EUt.forEach(t),ddr=r(wQe," \u2014 "),FJ=n(wQe,"A",{href:!0});var CUt=s(FJ);mdr=r(CUt,"BigBirdPegasusForSequenceClassification"),CUt.forEach(t),cdr=r(wQe," (BigBird-Pegasus model)"),wQe.forEach(t),fdr=i(D),ET=n(D,"LI",{});var AQe=s(ET);AEe=n(AQe,"STRONG",{});var wUt=s(AEe);gdr=r(wUt,"bloom"),wUt.forEach(t),hdr=r(AQe," \u2014 "),TJ=n(AQe,"A",{href:!0});var AUt=s(TJ);udr=r(AUt,"BloomForSequenceClassification"),AUt.forEach(t),pdr=r(AQe," (BLOOM model)"),AQe.forEach(t),_dr=i(D),CT=n(D,"LI",{});var LQe=s(CT);LEe=n(LQe,"STRONG",{});var LUt=s(LEe);bdr=r(LUt,"camembert"),LUt.forEach(t),vdr=r(LQe," \u2014 "),MJ=n(LQe,"A",{href:!0});var yUt=s(MJ);Fdr=r(yUt,"CamembertForSequenceClassification"),yUt.forEach(t),Tdr=r(LQe," (CamemBERT model)"),LQe.forEach(t),Mdr=i(D),wT=n(D,"LI",{});var yQe=s(wT);yEe=n(yQe,"STRONG",{});var xUt=s(yEe);Edr=r(xUt,"canine"),xUt.forEach(t),Cdr=r(yQe," \u2014 "),EJ=n(yQe,"A",{href:!0});var $Ut=s(EJ);wdr=r($Ut,"CanineForSequenceClassification"),$Ut.forEach(t),Adr=r(yQe," (CANINE model)"),yQe.forEach(t),Ldr=i(D),AT=n(D,"LI",{});var xQe=s(AT);xEe=n(xQe,"STRONG",{});var kUt=s(xEe);ydr=r(kUt,"convbert"),kUt.forEach(t),xdr=r(xQe," \u2014 "),CJ=n(xQe,"A",{href:!0});var SUt=s(CJ);$dr=r(SUt,"ConvBertForSequenceClassification"),SUt.forEach(t),kdr=r(xQe," (ConvBERT model)"),xQe.forEach(t),Sdr=i(D),LT=n(D,"LI",{});var $Qe=s(LT);$Ee=n($Qe,"STRONG",{});var RUt=s($Ee);Rdr=r(RUt,"ctrl"),RUt.forEach(t),Pdr=r($Qe," \u2014 "),wJ=n($Qe,"A",{href:!0});var PUt=s(wJ);Bdr=r(PUt,"CTRLForSequenceClassification"),PUt.forEach(t),Idr=r($Qe," (CTRL model)"),$Qe.forEach(t),Ndr=i(D),yT=n(D,"LI",{});var kQe=s(yT);kEe=n(kQe,"STRONG",{});var BUt=s(kEe);qdr=r(BUt,"data2vec-text"),BUt.forEach(t),jdr=r(kQe," \u2014 "),AJ=n(kQe,"A",{href:!0});var IUt=s(AJ);Ddr=r(IUt,"Data2VecTextForSequenceClassification"),IUt.forEach(t),Gdr=r(kQe," (Data2VecText model)"),kQe.forEach(t),Odr=i(D),xT=n(D,"LI",{});var SQe=s(xT);SEe=n(SQe,"STRONG",{});var NUt=s(SEe);Vdr=r(NUt,"deberta"),NUt.forEach(t),Xdr=r(SQe," \u2014 "),LJ=n(SQe,"A",{href:!0});var qUt=s(LJ);zdr=r(qUt,"DebertaForSequenceClassification"),qUt.forEach(t),Qdr=r(SQe," (DeBERTa model)"),SQe.forEach(t),Wdr=i(D),$T=n(D,"LI",{});var RQe=s($T);REe=n(RQe,"STRONG",{});var jUt=s(REe);Udr=r(jUt,"deberta-v2"),jUt.forEach(t),Hdr=r(RQe," \u2014 "),yJ=n(RQe,"A",{href:!0});var DUt=s(yJ);Jdr=r(DUt,"DebertaV2ForSequenceClassification"),DUt.forEach(t),Ydr=r(RQe," (DeBERTa-v2 model)"),RQe.forEach(t),Zdr=i(D),kT=n(D,"LI",{});var PQe=s(kT);PEe=n(PQe,"STRONG",{});var GUt=s(PEe);Kdr=r(GUt,"distilbert"),GUt.forEach(t),emr=r(PQe," \u2014 "),xJ=n(PQe,"A",{href:!0});var OUt=s(xJ);omr=r(OUt,"DistilBertForSequenceClassification"),OUt.forEach(t),rmr=r(PQe," (DistilBERT model)"),PQe.forEach(t),tmr=i(D),ST=n(D,"LI",{});var BQe=s(ST);BEe=n(BQe,"STRONG",{});var VUt=s(BEe);amr=r(VUt,"electra"),VUt.forEach(t),nmr=r(BQe," \u2014 "),$J=n(BQe,"A",{href:!0});var XUt=s($J);smr=r(XUt,"ElectraForSequenceClassification"),XUt.forEach(t),lmr=r(BQe," (ELECTRA model)"),BQe.forEach(t),imr=i(D),RT=n(D,"LI",{});var IQe=s(RT);IEe=n(IQe,"STRONG",{});var zUt=s(IEe);dmr=r(zUt,"ernie"),zUt.forEach(t),mmr=r(IQe," \u2014 "),kJ=n(IQe,"A",{href:!0});var QUt=s(kJ);cmr=r(QUt,"ErnieForSequenceClassification"),QUt.forEach(t),fmr=r(IQe," (ERNIE model)"),IQe.forEach(t),gmr=i(D),PT=n(D,"LI",{});var NQe=s(PT);NEe=n(NQe,"STRONG",{});var WUt=s(NEe);hmr=r(WUt,"esm"),WUt.forEach(t),umr=r(NQe," \u2014 "),SJ=n(NQe,"A",{href:!0});var UUt=s(SJ);pmr=r(UUt,"EsmForSequenceClassification"),UUt.forEach(t),_mr=r(NQe," (ESM model)"),NQe.forEach(t),bmr=i(D),BT=n(D,"LI",{});var qQe=s(BT);qEe=n(qQe,"STRONG",{});var HUt=s(qEe);vmr=r(HUt,"flaubert"),HUt.forEach(t),Fmr=r(qQe," \u2014 "),RJ=n(qQe,"A",{href:!0});var JUt=s(RJ);Tmr=r(JUt,"FlaubertForSequenceClassification"),JUt.forEach(t),Mmr=r(qQe," (FlauBERT model)"),qQe.forEach(t),Emr=i(D),IT=n(D,"LI",{});var jQe=s(IT);jEe=n(jQe,"STRONG",{});var YUt=s(jEe);Cmr=r(YUt,"fnet"),YUt.forEach(t),wmr=r(jQe," \u2014 "),PJ=n(jQe,"A",{href:!0});var ZUt=s(PJ);Amr=r(ZUt,"FNetForSequenceClassification"),ZUt.forEach(t),Lmr=r(jQe," (FNet model)"),jQe.forEach(t),ymr=i(D),NT=n(D,"LI",{});var DQe=s(NT);DEe=n(DQe,"STRONG",{});var KUt=s(DEe);xmr=r(KUt,"funnel"),KUt.forEach(t),$mr=r(DQe," \u2014 "),BJ=n(DQe,"A",{href:!0});var eHt=s(BJ);kmr=r(eHt,"FunnelForSequenceClassification"),eHt.forEach(t),Smr=r(DQe," (Funnel Transformer model)"),DQe.forEach(t),Rmr=i(D),qT=n(D,"LI",{});var GQe=s(qT);GEe=n(GQe,"STRONG",{});var oHt=s(GEe);Pmr=r(oHt,"gpt2"),oHt.forEach(t),Bmr=r(GQe," \u2014 "),IJ=n(GQe,"A",{href:!0});var rHt=s(IJ);Imr=r(rHt,"GPT2ForSequenceClassification"),rHt.forEach(t),Nmr=r(GQe," (OpenAI GPT-2 model)"),GQe.forEach(t),qmr=i(D),jT=n(D,"LI",{});var OQe=s(jT);OEe=n(OQe,"STRONG",{});var tHt=s(OEe);jmr=r(tHt,"gpt_neo"),tHt.forEach(t),Dmr=r(OQe," \u2014 "),NJ=n(OQe,"A",{href:!0});var aHt=s(NJ);Gmr=r(aHt,"GPTNeoForSequenceClassification"),aHt.forEach(t),Omr=r(OQe," (GPT Neo model)"),OQe.forEach(t),Vmr=i(D),DT=n(D,"LI",{});var VQe=s(DT);VEe=n(VQe,"STRONG",{});var nHt=s(VEe);Xmr=r(nHt,"gptj"),nHt.forEach(t),zmr=r(VQe," \u2014 "),qJ=n(VQe,"A",{href:!0});var sHt=s(qJ);Qmr=r(sHt,"GPTJForSequenceClassification"),sHt.forEach(t),Wmr=r(VQe," (GPT-J model)"),VQe.forEach(t),Umr=i(D),GT=n(D,"LI",{});var XQe=s(GT);XEe=n(XQe,"STRONG",{});var lHt=s(XEe);Hmr=r(lHt,"ibert"),lHt.forEach(t),Jmr=r(XQe," \u2014 "),jJ=n(XQe,"A",{href:!0});var iHt=s(jJ);Ymr=r(iHt,"IBertForSequenceClassification"),iHt.forEach(t),Zmr=r(XQe," (I-BERT model)"),XQe.forEach(t),Kmr=i(D),OT=n(D,"LI",{});var zQe=s(OT);zEe=n(zQe,"STRONG",{});var dHt=s(zEe);ecr=r(dHt,"layoutlm"),dHt.forEach(t),ocr=r(zQe," \u2014 "),DJ=n(zQe,"A",{href:!0});var mHt=s(DJ);rcr=r(mHt,"LayoutLMForSequenceClassification"),mHt.forEach(t),tcr=r(zQe," (LayoutLM model)"),zQe.forEach(t),acr=i(D),VT=n(D,"LI",{});var QQe=s(VT);QEe=n(QQe,"STRONG",{});var cHt=s(QEe);ncr=r(cHt,"layoutlmv2"),cHt.forEach(t),scr=r(QQe," \u2014 "),GJ=n(QQe,"A",{href:!0});var fHt=s(GJ);lcr=r(fHt,"LayoutLMv2ForSequenceClassification"),fHt.forEach(t),icr=r(QQe," (LayoutLMv2 model)"),QQe.forEach(t),dcr=i(D),XT=n(D,"LI",{});var WQe=s(XT);WEe=n(WQe,"STRONG",{});var gHt=s(WEe);mcr=r(gHt,"layoutlmv3"),gHt.forEach(t),ccr=r(WQe," \u2014 "),OJ=n(WQe,"A",{href:!0});var hHt=s(OJ);fcr=r(hHt,"LayoutLMv3ForSequenceClassification"),hHt.forEach(t),gcr=r(WQe," (LayoutLMv3 model)"),WQe.forEach(t),hcr=i(D),zT=n(D,"LI",{});var UQe=s(zT);UEe=n(UQe,"STRONG",{});var uHt=s(UEe);ucr=r(uHt,"led"),uHt.forEach(t),pcr=r(UQe," \u2014 "),VJ=n(UQe,"A",{href:!0});var pHt=s(VJ);_cr=r(pHt,"LEDForSequenceClassification"),pHt.forEach(t),bcr=r(UQe," (LED model)"),UQe.forEach(t),vcr=i(D),QT=n(D,"LI",{});var HQe=s(QT);HEe=n(HQe,"STRONG",{});var _Ht=s(HEe);Fcr=r(_Ht,"lilt"),_Ht.forEach(t),Tcr=r(HQe," \u2014 "),XJ=n(HQe,"A",{href:!0});var bHt=s(XJ);Mcr=r(bHt,"LiltForSequenceClassification"),bHt.forEach(t),Ecr=r(HQe," (LiLT model)"),HQe.forEach(t),Ccr=i(D),WT=n(D,"LI",{});var JQe=s(WT);JEe=n(JQe,"STRONG",{});var vHt=s(JEe);wcr=r(vHt,"longformer"),vHt.forEach(t),Acr=r(JQe," \u2014 "),zJ=n(JQe,"A",{href:!0});var FHt=s(zJ);Lcr=r(FHt,"LongformerForSequenceClassification"),FHt.forEach(t),ycr=r(JQe," (Longformer model)"),JQe.forEach(t),xcr=i(D),UT=n(D,"LI",{});var YQe=s(UT);YEe=n(YQe,"STRONG",{});var THt=s(YEe);$cr=r(THt,"luke"),THt.forEach(t),kcr=r(YQe," \u2014 "),QJ=n(YQe,"A",{href:!0});var MHt=s(QJ);Scr=r(MHt,"LukeForSequenceClassification"),MHt.forEach(t),Rcr=r(YQe," (LUKE model)"),YQe.forEach(t),Pcr=i(D),HT=n(D,"LI",{});var ZQe=s(HT);ZEe=n(ZQe,"STRONG",{});var EHt=s(ZEe);Bcr=r(EHt,"markuplm"),EHt.forEach(t),Icr=r(ZQe," \u2014 "),WJ=n(ZQe,"A",{href:!0});var CHt=s(WJ);Ncr=r(CHt,"MarkupLMForSequenceClassification"),CHt.forEach(t),qcr=r(ZQe," (MarkupLM model)"),ZQe.forEach(t),jcr=i(D),JT=n(D,"LI",{});var KQe=s(JT);KEe=n(KQe,"STRONG",{});var wHt=s(KEe);Dcr=r(wHt,"mbart"),wHt.forEach(t),Gcr=r(KQe," \u2014 "),UJ=n(KQe,"A",{href:!0});var AHt=s(UJ);Ocr=r(AHt,"MBartForSequenceClassification"),AHt.forEach(t),Vcr=r(KQe," (mBART model)"),KQe.forEach(t),Xcr=i(D),YT=n(D,"LI",{});var eWe=s(YT);e4e=n(eWe,"STRONG",{});var LHt=s(e4e);zcr=r(LHt,"megatron-bert"),LHt.forEach(t),Qcr=r(eWe," \u2014 "),HJ=n(eWe,"A",{href:!0});var yHt=s(HJ);Wcr=r(yHt,"MegatronBertForSequenceClassification"),yHt.forEach(t),Ucr=r(eWe," (Megatron-BERT model)"),eWe.forEach(t),Hcr=i(D),ZT=n(D,"LI",{});var oWe=s(ZT);o4e=n(oWe,"STRONG",{});var xHt=s(o4e);Jcr=r(xHt,"mobilebert"),xHt.forEach(t),Ycr=r(oWe," \u2014 "),JJ=n(oWe,"A",{href:!0});var $Ht=s(JJ);Zcr=r($Ht,"MobileBertForSequenceClassification"),$Ht.forEach(t),Kcr=r(oWe," (MobileBERT model)"),oWe.forEach(t),efr=i(D),KT=n(D,"LI",{});var rWe=s(KT);r4e=n(rWe,"STRONG",{});var kHt=s(r4e);ofr=r(kHt,"mpnet"),kHt.forEach(t),rfr=r(rWe," \u2014 "),YJ=n(rWe,"A",{href:!0});var SHt=s(YJ);tfr=r(SHt,"MPNetForSequenceClassification"),SHt.forEach(t),afr=r(rWe," (MPNet model)"),rWe.forEach(t),nfr=i(D),eM=n(D,"LI",{});var tWe=s(eM);t4e=n(tWe,"STRONG",{});var RHt=s(t4e);sfr=r(RHt,"mvp"),RHt.forEach(t),lfr=r(tWe," \u2014 "),ZJ=n(tWe,"A",{href:!0});var PHt=s(ZJ);ifr=r(PHt,"MvpForSequenceClassification"),PHt.forEach(t),dfr=r(tWe," (MVP model)"),tWe.forEach(t),mfr=i(D),oM=n(D,"LI",{});var aWe=s(oM);a4e=n(aWe,"STRONG",{});var BHt=s(a4e);cfr=r(BHt,"nezha"),BHt.forEach(t),ffr=r(aWe," \u2014 "),KJ=n(aWe,"A",{href:!0});var IHt=s(KJ);gfr=r(IHt,"NezhaForSequenceClassification"),IHt.forEach(t),hfr=r(aWe," (Nezha model)"),aWe.forEach(t),ufr=i(D),rM=n(D,"LI",{});var nWe=s(rM);n4e=n(nWe,"STRONG",{});var NHt=s(n4e);pfr=r(NHt,"nystromformer"),NHt.forEach(t),_fr=r(nWe," \u2014 "),eY=n(nWe,"A",{href:!0});var qHt=s(eY);bfr=r(qHt,"NystromformerForSequenceClassification"),qHt.forEach(t),vfr=r(nWe," (Nystr\xF6mformer model)"),nWe.forEach(t),Ffr=i(D),tM=n(D,"LI",{});var sWe=s(tM);s4e=n(sWe,"STRONG",{});var jHt=s(s4e);Tfr=r(jHt,"openai-gpt"),jHt.forEach(t),Mfr=r(sWe," \u2014 "),oY=n(sWe,"A",{href:!0});var DHt=s(oY);Efr=r(DHt,"OpenAIGPTForSequenceClassification"),DHt.forEach(t),Cfr=r(sWe," (OpenAI GPT model)"),sWe.forEach(t),wfr=i(D),aM=n(D,"LI",{});var lWe=s(aM);l4e=n(lWe,"STRONG",{});var GHt=s(l4e);Afr=r(GHt,"opt"),GHt.forEach(t),Lfr=r(lWe," \u2014 "),rY=n(lWe,"A",{href:!0});var OHt=s(rY);yfr=r(OHt,"OPTForSequenceClassification"),OHt.forEach(t),xfr=r(lWe," (OPT model)"),lWe.forEach(t),$fr=i(D),nM=n(D,"LI",{});var iWe=s(nM);i4e=n(iWe,"STRONG",{});var VHt=s(i4e);kfr=r(VHt,"perceiver"),VHt.forEach(t),Sfr=r(iWe," \u2014 "),tY=n(iWe,"A",{href:!0});var XHt=s(tY);Rfr=r(XHt,"PerceiverForSequenceClassification"),XHt.forEach(t),Pfr=r(iWe," (Perceiver model)"),iWe.forEach(t),Bfr=i(D),sM=n(D,"LI",{});var dWe=s(sM);d4e=n(dWe,"STRONG",{});var zHt=s(d4e);Ifr=r(zHt,"plbart"),zHt.forEach(t),Nfr=r(dWe," \u2014 "),aY=n(dWe,"A",{href:!0});var QHt=s(aY);qfr=r(QHt,"PLBartForSequenceClassification"),QHt.forEach(t),jfr=r(dWe," (PLBart model)"),dWe.forEach(t),Dfr=i(D),lM=n(D,"LI",{});var mWe=s(lM);m4e=n(mWe,"STRONG",{});var WHt=s(m4e);Gfr=r(WHt,"qdqbert"),WHt.forEach(t),Ofr=r(mWe," \u2014 "),nY=n(mWe,"A",{href:!0});var UHt=s(nY);Vfr=r(UHt,"QDQBertForSequenceClassification"),UHt.forEach(t),Xfr=r(mWe," (QDQBert model)"),mWe.forEach(t),zfr=i(D),iM=n(D,"LI",{});var cWe=s(iM);c4e=n(cWe,"STRONG",{});var HHt=s(c4e);Qfr=r(HHt,"reformer"),HHt.forEach(t),Wfr=r(cWe," \u2014 "),sY=n(cWe,"A",{href:!0});var JHt=s(sY);Ufr=r(JHt,"ReformerForSequenceClassification"),JHt.forEach(t),Hfr=r(cWe," (Reformer model)"),cWe.forEach(t),Jfr=i(D),dM=n(D,"LI",{});var fWe=s(dM);f4e=n(fWe,"STRONG",{});var YHt=s(f4e);Yfr=r(YHt,"rembert"),YHt.forEach(t),Zfr=r(fWe," \u2014 "),lY=n(fWe,"A",{href:!0});var ZHt=s(lY);Kfr=r(ZHt,"RemBertForSequenceClassification"),ZHt.forEach(t),egr=r(fWe," (RemBERT model)"),fWe.forEach(t),ogr=i(D),mM=n(D,"LI",{});var gWe=s(mM);g4e=n(gWe,"STRONG",{});var KHt=s(g4e);rgr=r(KHt,"roberta"),KHt.forEach(t),tgr=r(gWe," \u2014 "),iY=n(gWe,"A",{href:!0});var eJt=s(iY);agr=r(eJt,"RobertaForSequenceClassification"),eJt.forEach(t),ngr=r(gWe," (RoBERTa model)"),gWe.forEach(t),sgr=i(D),cM=n(D,"LI",{});var hWe=s(cM);h4e=n(hWe,"STRONG",{});var oJt=s(h4e);lgr=r(oJt,"roformer"),oJt.forEach(t),igr=r(hWe," \u2014 "),dY=n(hWe,"A",{href:!0});var rJt=s(dY);dgr=r(rJt,"RoFormerForSequenceClassification"),rJt.forEach(t),mgr=r(hWe," (RoFormer model)"),hWe.forEach(t),cgr=i(D),fM=n(D,"LI",{});var uWe=s(fM);u4e=n(uWe,"STRONG",{});var tJt=s(u4e);fgr=r(tJt,"squeezebert"),tJt.forEach(t),ggr=r(uWe," \u2014 "),mY=n(uWe,"A",{href:!0});var aJt=s(mY);hgr=r(aJt,"SqueezeBertForSequenceClassification"),aJt.forEach(t),ugr=r(uWe," (SqueezeBERT model)"),uWe.forEach(t),pgr=i(D),gM=n(D,"LI",{});var pWe=s(gM);p4e=n(pWe,"STRONG",{});var nJt=s(p4e);_gr=r(nJt,"tapas"),nJt.forEach(t),bgr=r(pWe," \u2014 "),cY=n(pWe,"A",{href:!0});var sJt=s(cY);vgr=r(sJt,"TapasForSequenceClassification"),sJt.forEach(t),Fgr=r(pWe," (TAPAS model)"),pWe.forEach(t),Tgr=i(D),hM=n(D,"LI",{});var _We=s(hM);_4e=n(_We,"STRONG",{});var lJt=s(_4e);Mgr=r(lJt,"transfo-xl"),lJt.forEach(t),Egr=r(_We," \u2014 "),fY=n(_We,"A",{href:!0});var iJt=s(fY);Cgr=r(iJt,"TransfoXLForSequenceClassification"),iJt.forEach(t),wgr=r(_We," (Transformer-XL model)"),_We.forEach(t),Agr=i(D),uM=n(D,"LI",{});var bWe=s(uM);b4e=n(bWe,"STRONG",{});var dJt=s(b4e);Lgr=r(dJt,"xlm"),dJt.forEach(t),ygr=r(bWe," \u2014 "),gY=n(bWe,"A",{href:!0});var mJt=s(gY);xgr=r(mJt,"XLMForSequenceClassification"),mJt.forEach(t),$gr=r(bWe," (XLM model)"),bWe.forEach(t),kgr=i(D),pM=n(D,"LI",{});var vWe=s(pM);v4e=n(vWe,"STRONG",{});var cJt=s(v4e);Sgr=r(cJt,"xlm-roberta"),cJt.forEach(t),Rgr=r(vWe," \u2014 "),hY=n(vWe,"A",{href:!0});var fJt=s(hY);Pgr=r(fJt,"XLMRobertaForSequenceClassification"),fJt.forEach(t),Bgr=r(vWe," (XLM-RoBERTa model)"),vWe.forEach(t),Igr=i(D),_M=n(D,"LI",{});var FWe=s(_M);F4e=n(FWe,"STRONG",{});var gJt=s(F4e);Ngr=r(gJt,"xlm-roberta-xl"),gJt.forEach(t),qgr=r(FWe," \u2014 "),uY=n(FWe,"A",{href:!0});var hJt=s(uY);jgr=r(hJt,"XLMRobertaXLForSequenceClassification"),hJt.forEach(t),Dgr=r(FWe," (XLM-RoBERTa-XL model)"),FWe.forEach(t),Ggr=i(D),bM=n(D,"LI",{});var TWe=s(bM);T4e=n(TWe,"STRONG",{});var uJt=s(T4e);Ogr=r(uJt,"xlnet"),uJt.forEach(t),Vgr=r(TWe," \u2014 "),pY=n(TWe,"A",{href:!0});var pJt=s(pY);Xgr=r(pJt,"XLNetForSequenceClassification"),pJt.forEach(t),zgr=r(TWe," (XLNet model)"),TWe.forEach(t),Qgr=i(D),vM=n(D,"LI",{});var MWe=s(vM);M4e=n(MWe,"STRONG",{});var _Jt=s(M4e);Wgr=r(_Jt,"yoso"),_Jt.forEach(t),Ugr=r(MWe," \u2014 "),_Y=n(MWe,"A",{href:!0});var bJt=s(_Y);Hgr=r(bJt,"YosoForSequenceClassification"),bJt.forEach(t),Jgr=r(MWe," (YOSO model)"),MWe.forEach(t),D.forEach(t),Ygr=i(Ra),FM=n(Ra,"P",{});var EWe=s(FM);Zgr=r(EWe,"The model is set in evaluation mode by default using "),E4e=n(EWe,"CODE",{});var vJt=s(E4e);Kgr=r(vJt,"model.eval()"),vJt.forEach(t),ehr=r(EWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),C4e=n(EWe,"CODE",{});var FJt=s(C4e);ohr=r(FJt,"model.train()"),FJt.forEach(t),EWe.forEach(t),rhr=i(Ra),T(TM.$$.fragment,Ra),Ra.forEach(t),zl.forEach(t),vao=i(c),em=n(c,"H2",{class:!0});var qso=s(em);MM=n(qso,"A",{id:!0,class:!0,href:!0});var TJt=s(MM);w4e=n(TJt,"SPAN",{});var MJt=s(w4e);T(Mk.$$.fragment,MJt),MJt.forEach(t),TJt.forEach(t),thr=i(qso),A4e=n(qso,"SPAN",{});var EJt=s(A4e);ahr=r(EJt,"AutoModelForMultipleChoice"),EJt.forEach(t),qso.forEach(t),Fao=i(c),Vo=n(c,"DIV",{class:!0});var Ql=s(Vo);T(Ek.$$.fragment,Ql),nhr=i(Ql),om=n(Ql,"P",{});var $me=s(om);shr=r($me,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),bY=n($me,"A",{href:!0});var CJt=s(bY);lhr=r(CJt,"from_pretrained()"),CJt.forEach(t),ihr=r($me," class method or the "),vY=n($me,"A",{href:!0});var wJt=s(vY);dhr=r(wJt,"from_config()"),wJt.forEach(t),mhr=r($me,` class
method.`),$me.forEach(t),chr=i(Ql),Ck=n(Ql,"P",{});var jso=s(Ck);fhr=r(jso,"This class cannot be instantiated directly using "),L4e=n(jso,"CODE",{});var AJt=s(L4e);ghr=r(AJt,"__init__()"),AJt.forEach(t),hhr=r(jso," (throws an error)."),jso.forEach(t),uhr=i(Ql),xt=n(Ql,"DIV",{class:!0});var v9=s(xt);T(wk.$$.fragment,v9),phr=i(v9),y4e=n(v9,"P",{});var LJt=s(y4e);_hr=r(LJt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),LJt.forEach(t),bhr=i(v9),rm=n(v9,"P",{});var kme=s(rm);vhr=r(kme,`Note:
Loading a model from its configuration file does `),x4e=n(kme,"STRONG",{});var yJt=s(x4e);Fhr=r(yJt,"not"),yJt.forEach(t),Thr=r(kme,` load the model weights. It only affects the
model\u2019s configuration. Use `),FY=n(kme,"A",{href:!0});var xJt=s(FY);Mhr=r(xJt,"from_pretrained()"),xJt.forEach(t),Ehr=r(kme," to load the model weights."),kme.forEach(t),Chr=i(v9),T(EM.$$.fragment,v9),v9.forEach(t),whr=i(Ql),so=n(Ql,"DIV",{class:!0});var Pa=s(so);T(Ak.$$.fragment,Pa),Ahr=i(Pa),$4e=n(Pa,"P",{});var $Jt=s($4e);Lhr=r($Jt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),$Jt.forEach(t),yhr=i(Pa),gn=n(Pa,"P",{});var F9=s(gn);xhr=r(F9,"The model class to instantiate is selected based on the "),k4e=n(F9,"CODE",{});var kJt=s(k4e);$hr=r(kJt,"model_type"),kJt.forEach(t),khr=r(F9,` property of the config object (either
passed as an argument or loaded from `),S4e=n(F9,"CODE",{});var SJt=s(S4e);Shr=r(SJt,"pretrained_model_name_or_path"),SJt.forEach(t),Rhr=r(F9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R4e=n(F9,"CODE",{});var RJt=s(R4e);Phr=r(RJt,"pretrained_model_name_or_path"),RJt.forEach(t),Bhr=r(F9,":"),F9.forEach(t),Ihr=i(Pa),K=n(Pa,"UL",{});var ee=s(K);CM=n(ee,"LI",{});var CWe=s(CM);P4e=n(CWe,"STRONG",{});var PJt=s(P4e);Nhr=r(PJt,"albert"),PJt.forEach(t),qhr=r(CWe," \u2014 "),TY=n(CWe,"A",{href:!0});var BJt=s(TY);jhr=r(BJt,"AlbertForMultipleChoice"),BJt.forEach(t),Dhr=r(CWe," (ALBERT model)"),CWe.forEach(t),Ghr=i(ee),wM=n(ee,"LI",{});var wWe=s(wM);B4e=n(wWe,"STRONG",{});var IJt=s(B4e);Ohr=r(IJt,"bert"),IJt.forEach(t),Vhr=r(wWe," \u2014 "),MY=n(wWe,"A",{href:!0});var NJt=s(MY);Xhr=r(NJt,"BertForMultipleChoice"),NJt.forEach(t),zhr=r(wWe," (BERT model)"),wWe.forEach(t),Qhr=i(ee),AM=n(ee,"LI",{});var AWe=s(AM);I4e=n(AWe,"STRONG",{});var qJt=s(I4e);Whr=r(qJt,"big_bird"),qJt.forEach(t),Uhr=r(AWe," \u2014 "),EY=n(AWe,"A",{href:!0});var jJt=s(EY);Hhr=r(jJt,"BigBirdForMultipleChoice"),jJt.forEach(t),Jhr=r(AWe," (BigBird model)"),AWe.forEach(t),Yhr=i(ee),LM=n(ee,"LI",{});var LWe=s(LM);N4e=n(LWe,"STRONG",{});var DJt=s(N4e);Zhr=r(DJt,"camembert"),DJt.forEach(t),Khr=r(LWe," \u2014 "),CY=n(LWe,"A",{href:!0});var GJt=s(CY);eur=r(GJt,"CamembertForMultipleChoice"),GJt.forEach(t),our=r(LWe," (CamemBERT model)"),LWe.forEach(t),rur=i(ee),yM=n(ee,"LI",{});var yWe=s(yM);q4e=n(yWe,"STRONG",{});var OJt=s(q4e);tur=r(OJt,"canine"),OJt.forEach(t),aur=r(yWe," \u2014 "),wY=n(yWe,"A",{href:!0});var VJt=s(wY);nur=r(VJt,"CanineForMultipleChoice"),VJt.forEach(t),sur=r(yWe," (CANINE model)"),yWe.forEach(t),lur=i(ee),xM=n(ee,"LI",{});var xWe=s(xM);j4e=n(xWe,"STRONG",{});var XJt=s(j4e);iur=r(XJt,"convbert"),XJt.forEach(t),dur=r(xWe," \u2014 "),AY=n(xWe,"A",{href:!0});var zJt=s(AY);mur=r(zJt,"ConvBertForMultipleChoice"),zJt.forEach(t),cur=r(xWe," (ConvBERT model)"),xWe.forEach(t),fur=i(ee),$M=n(ee,"LI",{});var $We=s($M);D4e=n($We,"STRONG",{});var QJt=s(D4e);gur=r(QJt,"data2vec-text"),QJt.forEach(t),hur=r($We," \u2014 "),LY=n($We,"A",{href:!0});var WJt=s(LY);uur=r(WJt,"Data2VecTextForMultipleChoice"),WJt.forEach(t),pur=r($We," (Data2VecText model)"),$We.forEach(t),_ur=i(ee),kM=n(ee,"LI",{});var kWe=s(kM);G4e=n(kWe,"STRONG",{});var UJt=s(G4e);bur=r(UJt,"deberta-v2"),UJt.forEach(t),vur=r(kWe," \u2014 "),yY=n(kWe,"A",{href:!0});var HJt=s(yY);Fur=r(HJt,"DebertaV2ForMultipleChoice"),HJt.forEach(t),Tur=r(kWe," (DeBERTa-v2 model)"),kWe.forEach(t),Mur=i(ee),SM=n(ee,"LI",{});var SWe=s(SM);O4e=n(SWe,"STRONG",{});var JJt=s(O4e);Eur=r(JJt,"distilbert"),JJt.forEach(t),Cur=r(SWe," \u2014 "),xY=n(SWe,"A",{href:!0});var YJt=s(xY);wur=r(YJt,"DistilBertForMultipleChoice"),YJt.forEach(t),Aur=r(SWe," (DistilBERT model)"),SWe.forEach(t),Lur=i(ee),RM=n(ee,"LI",{});var RWe=s(RM);V4e=n(RWe,"STRONG",{});var ZJt=s(V4e);yur=r(ZJt,"electra"),ZJt.forEach(t),xur=r(RWe," \u2014 "),$Y=n(RWe,"A",{href:!0});var KJt=s($Y);$ur=r(KJt,"ElectraForMultipleChoice"),KJt.forEach(t),kur=r(RWe," (ELECTRA model)"),RWe.forEach(t),Sur=i(ee),PM=n(ee,"LI",{});var PWe=s(PM);X4e=n(PWe,"STRONG",{});var eYt=s(X4e);Rur=r(eYt,"ernie"),eYt.forEach(t),Pur=r(PWe," \u2014 "),kY=n(PWe,"A",{href:!0});var oYt=s(kY);Bur=r(oYt,"ErnieForMultipleChoice"),oYt.forEach(t),Iur=r(PWe," (ERNIE model)"),PWe.forEach(t),Nur=i(ee),BM=n(ee,"LI",{});var BWe=s(BM);z4e=n(BWe,"STRONG",{});var rYt=s(z4e);qur=r(rYt,"flaubert"),rYt.forEach(t),jur=r(BWe," \u2014 "),SY=n(BWe,"A",{href:!0});var tYt=s(SY);Dur=r(tYt,"FlaubertForMultipleChoice"),tYt.forEach(t),Gur=r(BWe," (FlauBERT model)"),BWe.forEach(t),Our=i(ee),IM=n(ee,"LI",{});var IWe=s(IM);Q4e=n(IWe,"STRONG",{});var aYt=s(Q4e);Vur=r(aYt,"fnet"),aYt.forEach(t),Xur=r(IWe," \u2014 "),RY=n(IWe,"A",{href:!0});var nYt=s(RY);zur=r(nYt,"FNetForMultipleChoice"),nYt.forEach(t),Qur=r(IWe," (FNet model)"),IWe.forEach(t),Wur=i(ee),NM=n(ee,"LI",{});var NWe=s(NM);W4e=n(NWe,"STRONG",{});var sYt=s(W4e);Uur=r(sYt,"funnel"),sYt.forEach(t),Hur=r(NWe," \u2014 "),PY=n(NWe,"A",{href:!0});var lYt=s(PY);Jur=r(lYt,"FunnelForMultipleChoice"),lYt.forEach(t),Yur=r(NWe," (Funnel Transformer model)"),NWe.forEach(t),Zur=i(ee),qM=n(ee,"LI",{});var qWe=s(qM);U4e=n(qWe,"STRONG",{});var iYt=s(U4e);Kur=r(iYt,"ibert"),iYt.forEach(t),epr=r(qWe," \u2014 "),BY=n(qWe,"A",{href:!0});var dYt=s(BY);opr=r(dYt,"IBertForMultipleChoice"),dYt.forEach(t),rpr=r(qWe," (I-BERT model)"),qWe.forEach(t),tpr=i(ee),jM=n(ee,"LI",{});var jWe=s(jM);H4e=n(jWe,"STRONG",{});var mYt=s(H4e);apr=r(mYt,"longformer"),mYt.forEach(t),npr=r(jWe," \u2014 "),IY=n(jWe,"A",{href:!0});var cYt=s(IY);spr=r(cYt,"LongformerForMultipleChoice"),cYt.forEach(t),lpr=r(jWe," (Longformer model)"),jWe.forEach(t),ipr=i(ee),DM=n(ee,"LI",{});var DWe=s(DM);J4e=n(DWe,"STRONG",{});var fYt=s(J4e);dpr=r(fYt,"luke"),fYt.forEach(t),mpr=r(DWe," \u2014 "),NY=n(DWe,"A",{href:!0});var gYt=s(NY);cpr=r(gYt,"LukeForMultipleChoice"),gYt.forEach(t),fpr=r(DWe," (LUKE model)"),DWe.forEach(t),gpr=i(ee),GM=n(ee,"LI",{});var GWe=s(GM);Y4e=n(GWe,"STRONG",{});var hYt=s(Y4e);hpr=r(hYt,"megatron-bert"),hYt.forEach(t),upr=r(GWe," \u2014 "),qY=n(GWe,"A",{href:!0});var uYt=s(qY);ppr=r(uYt,"MegatronBertForMultipleChoice"),uYt.forEach(t),_pr=r(GWe," (Megatron-BERT model)"),GWe.forEach(t),bpr=i(ee),OM=n(ee,"LI",{});var OWe=s(OM);Z4e=n(OWe,"STRONG",{});var pYt=s(Z4e);vpr=r(pYt,"mobilebert"),pYt.forEach(t),Fpr=r(OWe," \u2014 "),jY=n(OWe,"A",{href:!0});var _Yt=s(jY);Tpr=r(_Yt,"MobileBertForMultipleChoice"),_Yt.forEach(t),Mpr=r(OWe," (MobileBERT model)"),OWe.forEach(t),Epr=i(ee),VM=n(ee,"LI",{});var VWe=s(VM);K4e=n(VWe,"STRONG",{});var bYt=s(K4e);Cpr=r(bYt,"mpnet"),bYt.forEach(t),wpr=r(VWe," \u2014 "),DY=n(VWe,"A",{href:!0});var vYt=s(DY);Apr=r(vYt,"MPNetForMultipleChoice"),vYt.forEach(t),Lpr=r(VWe," (MPNet model)"),VWe.forEach(t),ypr=i(ee),XM=n(ee,"LI",{});var XWe=s(XM);eCe=n(XWe,"STRONG",{});var FYt=s(eCe);xpr=r(FYt,"nezha"),FYt.forEach(t),$pr=r(XWe," \u2014 "),GY=n(XWe,"A",{href:!0});var TYt=s(GY);kpr=r(TYt,"NezhaForMultipleChoice"),TYt.forEach(t),Spr=r(XWe," (Nezha model)"),XWe.forEach(t),Rpr=i(ee),zM=n(ee,"LI",{});var zWe=s(zM);oCe=n(zWe,"STRONG",{});var MYt=s(oCe);Ppr=r(MYt,"nystromformer"),MYt.forEach(t),Bpr=r(zWe," \u2014 "),OY=n(zWe,"A",{href:!0});var EYt=s(OY);Ipr=r(EYt,"NystromformerForMultipleChoice"),EYt.forEach(t),Npr=r(zWe," (Nystr\xF6mformer model)"),zWe.forEach(t),qpr=i(ee),QM=n(ee,"LI",{});var QWe=s(QM);rCe=n(QWe,"STRONG",{});var CYt=s(rCe);jpr=r(CYt,"qdqbert"),CYt.forEach(t),Dpr=r(QWe," \u2014 "),VY=n(QWe,"A",{href:!0});var wYt=s(VY);Gpr=r(wYt,"QDQBertForMultipleChoice"),wYt.forEach(t),Opr=r(QWe," (QDQBert model)"),QWe.forEach(t),Vpr=i(ee),WM=n(ee,"LI",{});var WWe=s(WM);tCe=n(WWe,"STRONG",{});var AYt=s(tCe);Xpr=r(AYt,"rembert"),AYt.forEach(t),zpr=r(WWe," \u2014 "),XY=n(WWe,"A",{href:!0});var LYt=s(XY);Qpr=r(LYt,"RemBertForMultipleChoice"),LYt.forEach(t),Wpr=r(WWe," (RemBERT model)"),WWe.forEach(t),Upr=i(ee),UM=n(ee,"LI",{});var UWe=s(UM);aCe=n(UWe,"STRONG",{});var yYt=s(aCe);Hpr=r(yYt,"roberta"),yYt.forEach(t),Jpr=r(UWe," \u2014 "),zY=n(UWe,"A",{href:!0});var xYt=s(zY);Ypr=r(xYt,"RobertaForMultipleChoice"),xYt.forEach(t),Zpr=r(UWe," (RoBERTa model)"),UWe.forEach(t),Kpr=i(ee),HM=n(ee,"LI",{});var HWe=s(HM);nCe=n(HWe,"STRONG",{});var $Yt=s(nCe);e_r=r($Yt,"roformer"),$Yt.forEach(t),o_r=r(HWe," \u2014 "),QY=n(HWe,"A",{href:!0});var kYt=s(QY);r_r=r(kYt,"RoFormerForMultipleChoice"),kYt.forEach(t),t_r=r(HWe," (RoFormer model)"),HWe.forEach(t),a_r=i(ee),JM=n(ee,"LI",{});var JWe=s(JM);sCe=n(JWe,"STRONG",{});var SYt=s(sCe);n_r=r(SYt,"squeezebert"),SYt.forEach(t),s_r=r(JWe," \u2014 "),WY=n(JWe,"A",{href:!0});var RYt=s(WY);l_r=r(RYt,"SqueezeBertForMultipleChoice"),RYt.forEach(t),i_r=r(JWe," (SqueezeBERT model)"),JWe.forEach(t),d_r=i(ee),YM=n(ee,"LI",{});var YWe=s(YM);lCe=n(YWe,"STRONG",{});var PYt=s(lCe);m_r=r(PYt,"xlm"),PYt.forEach(t),c_r=r(YWe," \u2014 "),UY=n(YWe,"A",{href:!0});var BYt=s(UY);f_r=r(BYt,"XLMForMultipleChoice"),BYt.forEach(t),g_r=r(YWe," (XLM model)"),YWe.forEach(t),h_r=i(ee),ZM=n(ee,"LI",{});var ZWe=s(ZM);iCe=n(ZWe,"STRONG",{});var IYt=s(iCe);u_r=r(IYt,"xlm-roberta"),IYt.forEach(t),p_r=r(ZWe," \u2014 "),HY=n(ZWe,"A",{href:!0});var NYt=s(HY);__r=r(NYt,"XLMRobertaForMultipleChoice"),NYt.forEach(t),b_r=r(ZWe," (XLM-RoBERTa model)"),ZWe.forEach(t),v_r=i(ee),KM=n(ee,"LI",{});var KWe=s(KM);dCe=n(KWe,"STRONG",{});var qYt=s(dCe);F_r=r(qYt,"xlm-roberta-xl"),qYt.forEach(t),T_r=r(KWe," \u2014 "),JY=n(KWe,"A",{href:!0});var jYt=s(JY);M_r=r(jYt,"XLMRobertaXLForMultipleChoice"),jYt.forEach(t),E_r=r(KWe," (XLM-RoBERTa-XL model)"),KWe.forEach(t),C_r=i(ee),eE=n(ee,"LI",{});var eUe=s(eE);mCe=n(eUe,"STRONG",{});var DYt=s(mCe);w_r=r(DYt,"xlnet"),DYt.forEach(t),A_r=r(eUe," \u2014 "),YY=n(eUe,"A",{href:!0});var GYt=s(YY);L_r=r(GYt,"XLNetForMultipleChoice"),GYt.forEach(t),y_r=r(eUe," (XLNet model)"),eUe.forEach(t),x_r=i(ee),oE=n(ee,"LI",{});var oUe=s(oE);cCe=n(oUe,"STRONG",{});var OYt=s(cCe);$_r=r(OYt,"yoso"),OYt.forEach(t),k_r=r(oUe," \u2014 "),ZY=n(oUe,"A",{href:!0});var VYt=s(ZY);S_r=r(VYt,"YosoForMultipleChoice"),VYt.forEach(t),R_r=r(oUe," (YOSO model)"),oUe.forEach(t),ee.forEach(t),P_r=i(Pa),rE=n(Pa,"P",{});var rUe=s(rE);B_r=r(rUe,"The model is set in evaluation mode by default using "),fCe=n(rUe,"CODE",{});var XYt=s(fCe);I_r=r(XYt,"model.eval()"),XYt.forEach(t),N_r=r(rUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gCe=n(rUe,"CODE",{});var zYt=s(gCe);q_r=r(zYt,"model.train()"),zYt.forEach(t),rUe.forEach(t),j_r=i(Pa),T(tE.$$.fragment,Pa),Pa.forEach(t),Ql.forEach(t),Tao=i(c),tm=n(c,"H2",{class:!0});var Dso=s(tm);aE=n(Dso,"A",{id:!0,class:!0,href:!0});var QYt=s(aE);hCe=n(QYt,"SPAN",{});var WYt=s(hCe);T(Lk.$$.fragment,WYt),WYt.forEach(t),QYt.forEach(t),D_r=i(Dso),uCe=n(Dso,"SPAN",{});var UYt=s(uCe);G_r=r(UYt,"AutoModelForNextSentencePrediction"),UYt.forEach(t),Dso.forEach(t),Mao=i(c),Xo=n(c,"DIV",{class:!0});var Wl=s(Xo);T(yk.$$.fragment,Wl),O_r=i(Wl),am=n(Wl,"P",{});var Sme=s(am);V_r=r(Sme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),KY=n(Sme,"A",{href:!0});var HYt=s(KY);X_r=r(HYt,"from_pretrained()"),HYt.forEach(t),z_r=r(Sme," class method or the "),eZ=n(Sme,"A",{href:!0});var JYt=s(eZ);Q_r=r(JYt,"from_config()"),JYt.forEach(t),W_r=r(Sme,` class
method.`),Sme.forEach(t),U_r=i(Wl),xk=n(Wl,"P",{});var Gso=s(xk);H_r=r(Gso,"This class cannot be instantiated directly using "),pCe=n(Gso,"CODE",{});var YYt=s(pCe);J_r=r(YYt,"__init__()"),YYt.forEach(t),Y_r=r(Gso," (throws an error)."),Gso.forEach(t),Z_r=i(Wl),$t=n(Wl,"DIV",{class:!0});var T9=s($t);T($k.$$.fragment,T9),K_r=i(T9),_Ce=n(T9,"P",{});var ZYt=s(_Ce);e1r=r(ZYt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),ZYt.forEach(t),o1r=i(T9),nm=n(T9,"P",{});var Rme=s(nm);r1r=r(Rme,`Note:
Loading a model from its configuration file does `),bCe=n(Rme,"STRONG",{});var KYt=s(bCe);t1r=r(KYt,"not"),KYt.forEach(t),a1r=r(Rme,` load the model weights. It only affects the
model\u2019s configuration. Use `),oZ=n(Rme,"A",{href:!0});var eZt=s(oZ);n1r=r(eZt,"from_pretrained()"),eZt.forEach(t),s1r=r(Rme," to load the model weights."),Rme.forEach(t),l1r=i(T9),T(nE.$$.fragment,T9),T9.forEach(t),i1r=i(Wl),lo=n(Wl,"DIV",{class:!0});var Ba=s(lo);T(kk.$$.fragment,Ba),d1r=i(Ba),vCe=n(Ba,"P",{});var oZt=s(vCe);m1r=r(oZt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),oZt.forEach(t),c1r=i(Ba),hn=n(Ba,"P",{});var M9=s(hn);f1r=r(M9,"The model class to instantiate is selected based on the "),FCe=n(M9,"CODE",{});var rZt=s(FCe);g1r=r(rZt,"model_type"),rZt.forEach(t),h1r=r(M9,` property of the config object (either
passed as an argument or loaded from `),TCe=n(M9,"CODE",{});var tZt=s(TCe);u1r=r(tZt,"pretrained_model_name_or_path"),tZt.forEach(t),p1r=r(M9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MCe=n(M9,"CODE",{});var aZt=s(MCe);_1r=r(aZt,"pretrained_model_name_or_path"),aZt.forEach(t),b1r=r(M9,":"),M9.forEach(t),v1r=i(Ba),Ue=n(Ba,"UL",{});var ht=s(Ue);sE=n(ht,"LI",{});var tUe=s(sE);ECe=n(tUe,"STRONG",{});var nZt=s(ECe);F1r=r(nZt,"bert"),nZt.forEach(t),T1r=r(tUe," \u2014 "),rZ=n(tUe,"A",{href:!0});var sZt=s(rZ);M1r=r(sZt,"BertForNextSentencePrediction"),sZt.forEach(t),E1r=r(tUe," (BERT model)"),tUe.forEach(t),C1r=i(ht),lE=n(ht,"LI",{});var aUe=s(lE);CCe=n(aUe,"STRONG",{});var lZt=s(CCe);w1r=r(lZt,"ernie"),lZt.forEach(t),A1r=r(aUe," \u2014 "),tZ=n(aUe,"A",{href:!0});var iZt=s(tZ);L1r=r(iZt,"ErnieForNextSentencePrediction"),iZt.forEach(t),y1r=r(aUe," (ERNIE model)"),aUe.forEach(t),x1r=i(ht),iE=n(ht,"LI",{});var nUe=s(iE);wCe=n(nUe,"STRONG",{});var dZt=s(wCe);$1r=r(dZt,"fnet"),dZt.forEach(t),k1r=r(nUe," \u2014 "),aZ=n(nUe,"A",{href:!0});var mZt=s(aZ);S1r=r(mZt,"FNetForNextSentencePrediction"),mZt.forEach(t),R1r=r(nUe," (FNet model)"),nUe.forEach(t),P1r=i(ht),dE=n(ht,"LI",{});var sUe=s(dE);ACe=n(sUe,"STRONG",{});var cZt=s(ACe);B1r=r(cZt,"megatron-bert"),cZt.forEach(t),I1r=r(sUe," \u2014 "),nZ=n(sUe,"A",{href:!0});var fZt=s(nZ);N1r=r(fZt,"MegatronBertForNextSentencePrediction"),fZt.forEach(t),q1r=r(sUe," (Megatron-BERT model)"),sUe.forEach(t),j1r=i(ht),mE=n(ht,"LI",{});var lUe=s(mE);LCe=n(lUe,"STRONG",{});var gZt=s(LCe);D1r=r(gZt,"mobilebert"),gZt.forEach(t),G1r=r(lUe," \u2014 "),sZ=n(lUe,"A",{href:!0});var hZt=s(sZ);O1r=r(hZt,"MobileBertForNextSentencePrediction"),hZt.forEach(t),V1r=r(lUe," (MobileBERT model)"),lUe.forEach(t),X1r=i(ht),cE=n(ht,"LI",{});var iUe=s(cE);yCe=n(iUe,"STRONG",{});var uZt=s(yCe);z1r=r(uZt,"nezha"),uZt.forEach(t),Q1r=r(iUe," \u2014 "),lZ=n(iUe,"A",{href:!0});var pZt=s(lZ);W1r=r(pZt,"NezhaForNextSentencePrediction"),pZt.forEach(t),U1r=r(iUe," (Nezha model)"),iUe.forEach(t),H1r=i(ht),fE=n(ht,"LI",{});var dUe=s(fE);xCe=n(dUe,"STRONG",{});var _Zt=s(xCe);J1r=r(_Zt,"qdqbert"),_Zt.forEach(t),Y1r=r(dUe," \u2014 "),iZ=n(dUe,"A",{href:!0});var bZt=s(iZ);Z1r=r(bZt,"QDQBertForNextSentencePrediction"),bZt.forEach(t),K1r=r(dUe," (QDQBert model)"),dUe.forEach(t),ht.forEach(t),e2r=i(Ba),gE=n(Ba,"P",{});var mUe=s(gE);o2r=r(mUe,"The model is set in evaluation mode by default using "),$Ce=n(mUe,"CODE",{});var vZt=s($Ce);r2r=r(vZt,"model.eval()"),vZt.forEach(t),t2r=r(mUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),kCe=n(mUe,"CODE",{});var FZt=s(kCe);a2r=r(FZt,"model.train()"),FZt.forEach(t),mUe.forEach(t),n2r=i(Ba),T(hE.$$.fragment,Ba),Ba.forEach(t),Wl.forEach(t),Eao=i(c),sm=n(c,"H2",{class:!0});var Oso=s(sm);uE=n(Oso,"A",{id:!0,class:!0,href:!0});var TZt=s(uE);SCe=n(TZt,"SPAN",{});var MZt=s(SCe);T(Sk.$$.fragment,MZt),MZt.forEach(t),TZt.forEach(t),s2r=i(Oso),RCe=n(Oso,"SPAN",{});var EZt=s(RCe);l2r=r(EZt,"AutoModelForTokenClassification"),EZt.forEach(t),Oso.forEach(t),Cao=i(c),zo=n(c,"DIV",{class:!0});var Ul=s(zo);T(Rk.$$.fragment,Ul),i2r=i(Ul),lm=n(Ul,"P",{});var Pme=s(lm);d2r=r(Pme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),dZ=n(Pme,"A",{href:!0});var CZt=s(dZ);m2r=r(CZt,"from_pretrained()"),CZt.forEach(t),c2r=r(Pme," class method or the "),mZ=n(Pme,"A",{href:!0});var wZt=s(mZ);f2r=r(wZt,"from_config()"),wZt.forEach(t),g2r=r(Pme,` class
method.`),Pme.forEach(t),h2r=i(Ul),Pk=n(Ul,"P",{});var Vso=s(Pk);u2r=r(Vso,"This class cannot be instantiated directly using "),PCe=n(Vso,"CODE",{});var AZt=s(PCe);p2r=r(AZt,"__init__()"),AZt.forEach(t),_2r=r(Vso," (throws an error)."),Vso.forEach(t),b2r=i(Ul),kt=n(Ul,"DIV",{class:!0});var E9=s(kt);T(Bk.$$.fragment,E9),v2r=i(E9),BCe=n(E9,"P",{});var LZt=s(BCe);F2r=r(LZt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),LZt.forEach(t),T2r=i(E9),im=n(E9,"P",{});var Bme=s(im);M2r=r(Bme,`Note:
Loading a model from its configuration file does `),ICe=n(Bme,"STRONG",{});var yZt=s(ICe);E2r=r(yZt,"not"),yZt.forEach(t),C2r=r(Bme,` load the model weights. It only affects the
model\u2019s configuration. Use `),cZ=n(Bme,"A",{href:!0});var xZt=s(cZ);w2r=r(xZt,"from_pretrained()"),xZt.forEach(t),A2r=r(Bme," to load the model weights."),Bme.forEach(t),L2r=i(E9),T(pE.$$.fragment,E9),E9.forEach(t),y2r=i(Ul),io=n(Ul,"DIV",{class:!0});var Ia=s(io);T(Ik.$$.fragment,Ia),x2r=i(Ia),NCe=n(Ia,"P",{});var $Zt=s(NCe);$2r=r($Zt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),$Zt.forEach(t),k2r=i(Ia),un=n(Ia,"P",{});var C9=s(un);S2r=r(C9,"The model class to instantiate is selected based on the "),qCe=n(C9,"CODE",{});var kZt=s(qCe);R2r=r(kZt,"model_type"),kZt.forEach(t),P2r=r(C9,` property of the config object (either
passed as an argument or loaded from `),jCe=n(C9,"CODE",{});var SZt=s(jCe);B2r=r(SZt,"pretrained_model_name_or_path"),SZt.forEach(t),I2r=r(C9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DCe=n(C9,"CODE",{});var RZt=s(DCe);N2r=r(RZt,"pretrained_model_name_or_path"),RZt.forEach(t),q2r=r(C9,":"),C9.forEach(t),j2r=i(Ia),U=n(Ia,"UL",{});var J=s(U);_E=n(J,"LI",{});var cUe=s(_E);GCe=n(cUe,"STRONG",{});var PZt=s(GCe);D2r=r(PZt,"albert"),PZt.forEach(t),G2r=r(cUe," \u2014 "),fZ=n(cUe,"A",{href:!0});var BZt=s(fZ);O2r=r(BZt,"AlbertForTokenClassification"),BZt.forEach(t),V2r=r(cUe," (ALBERT model)"),cUe.forEach(t),X2r=i(J),bE=n(J,"LI",{});var fUe=s(bE);OCe=n(fUe,"STRONG",{});var IZt=s(OCe);z2r=r(IZt,"bert"),IZt.forEach(t),Q2r=r(fUe," \u2014 "),gZ=n(fUe,"A",{href:!0});var NZt=s(gZ);W2r=r(NZt,"BertForTokenClassification"),NZt.forEach(t),U2r=r(fUe," (BERT model)"),fUe.forEach(t),H2r=i(J),vE=n(J,"LI",{});var gUe=s(vE);VCe=n(gUe,"STRONG",{});var qZt=s(VCe);J2r=r(qZt,"big_bird"),qZt.forEach(t),Y2r=r(gUe," \u2014 "),hZ=n(gUe,"A",{href:!0});var jZt=s(hZ);Z2r=r(jZt,"BigBirdForTokenClassification"),jZt.forEach(t),K2r=r(gUe," (BigBird model)"),gUe.forEach(t),ebr=i(J),FE=n(J,"LI",{});var hUe=s(FE);XCe=n(hUe,"STRONG",{});var DZt=s(XCe);obr=r(DZt,"bloom"),DZt.forEach(t),rbr=r(hUe," \u2014 "),uZ=n(hUe,"A",{href:!0});var GZt=s(uZ);tbr=r(GZt,"BloomForTokenClassification"),GZt.forEach(t),abr=r(hUe," (BLOOM model)"),hUe.forEach(t),nbr=i(J),TE=n(J,"LI",{});var uUe=s(TE);zCe=n(uUe,"STRONG",{});var OZt=s(zCe);sbr=r(OZt,"camembert"),OZt.forEach(t),lbr=r(uUe," \u2014 "),pZ=n(uUe,"A",{href:!0});var VZt=s(pZ);ibr=r(VZt,"CamembertForTokenClassification"),VZt.forEach(t),dbr=r(uUe," (CamemBERT model)"),uUe.forEach(t),mbr=i(J),ME=n(J,"LI",{});var pUe=s(ME);QCe=n(pUe,"STRONG",{});var XZt=s(QCe);cbr=r(XZt,"canine"),XZt.forEach(t),fbr=r(pUe," \u2014 "),_Z=n(pUe,"A",{href:!0});var zZt=s(_Z);gbr=r(zZt,"CanineForTokenClassification"),zZt.forEach(t),hbr=r(pUe," (CANINE model)"),pUe.forEach(t),ubr=i(J),EE=n(J,"LI",{});var _Ue=s(EE);WCe=n(_Ue,"STRONG",{});var QZt=s(WCe);pbr=r(QZt,"convbert"),QZt.forEach(t),_br=r(_Ue," \u2014 "),bZ=n(_Ue,"A",{href:!0});var WZt=s(bZ);bbr=r(WZt,"ConvBertForTokenClassification"),WZt.forEach(t),vbr=r(_Ue," (ConvBERT model)"),_Ue.forEach(t),Fbr=i(J),CE=n(J,"LI",{});var bUe=s(CE);UCe=n(bUe,"STRONG",{});var UZt=s(UCe);Tbr=r(UZt,"data2vec-text"),UZt.forEach(t),Mbr=r(bUe," \u2014 "),vZ=n(bUe,"A",{href:!0});var HZt=s(vZ);Ebr=r(HZt,"Data2VecTextForTokenClassification"),HZt.forEach(t),Cbr=r(bUe," (Data2VecText model)"),bUe.forEach(t),wbr=i(J),wE=n(J,"LI",{});var vUe=s(wE);HCe=n(vUe,"STRONG",{});var JZt=s(HCe);Abr=r(JZt,"deberta"),JZt.forEach(t),Lbr=r(vUe," \u2014 "),FZ=n(vUe,"A",{href:!0});var YZt=s(FZ);ybr=r(YZt,"DebertaForTokenClassification"),YZt.forEach(t),xbr=r(vUe," (DeBERTa model)"),vUe.forEach(t),$br=i(J),AE=n(J,"LI",{});var FUe=s(AE);JCe=n(FUe,"STRONG",{});var ZZt=s(JCe);kbr=r(ZZt,"deberta-v2"),ZZt.forEach(t),Sbr=r(FUe," \u2014 "),TZ=n(FUe,"A",{href:!0});var KZt=s(TZ);Rbr=r(KZt,"DebertaV2ForTokenClassification"),KZt.forEach(t),Pbr=r(FUe," (DeBERTa-v2 model)"),FUe.forEach(t),Bbr=i(J),LE=n(J,"LI",{});var TUe=s(LE);YCe=n(TUe,"STRONG",{});var eKt=s(YCe);Ibr=r(eKt,"distilbert"),eKt.forEach(t),Nbr=r(TUe," \u2014 "),MZ=n(TUe,"A",{href:!0});var oKt=s(MZ);qbr=r(oKt,"DistilBertForTokenClassification"),oKt.forEach(t),jbr=r(TUe," (DistilBERT model)"),TUe.forEach(t),Dbr=i(J),yE=n(J,"LI",{});var MUe=s(yE);ZCe=n(MUe,"STRONG",{});var rKt=s(ZCe);Gbr=r(rKt,"electra"),rKt.forEach(t),Obr=r(MUe," \u2014 "),EZ=n(MUe,"A",{href:!0});var tKt=s(EZ);Vbr=r(tKt,"ElectraForTokenClassification"),tKt.forEach(t),Xbr=r(MUe," (ELECTRA model)"),MUe.forEach(t),zbr=i(J),xE=n(J,"LI",{});var EUe=s(xE);KCe=n(EUe,"STRONG",{});var aKt=s(KCe);Qbr=r(aKt,"ernie"),aKt.forEach(t),Wbr=r(EUe," \u2014 "),CZ=n(EUe,"A",{href:!0});var nKt=s(CZ);Ubr=r(nKt,"ErnieForTokenClassification"),nKt.forEach(t),Hbr=r(EUe," (ERNIE model)"),EUe.forEach(t),Jbr=i(J),$E=n(J,"LI",{});var CUe=s($E);e3e=n(CUe,"STRONG",{});var sKt=s(e3e);Ybr=r(sKt,"esm"),sKt.forEach(t),Zbr=r(CUe," \u2014 "),wZ=n(CUe,"A",{href:!0});var lKt=s(wZ);Kbr=r(lKt,"EsmForTokenClassification"),lKt.forEach(t),evr=r(CUe," (ESM model)"),CUe.forEach(t),ovr=i(J),kE=n(J,"LI",{});var wUe=s(kE);o3e=n(wUe,"STRONG",{});var iKt=s(o3e);rvr=r(iKt,"flaubert"),iKt.forEach(t),tvr=r(wUe," \u2014 "),AZ=n(wUe,"A",{href:!0});var dKt=s(AZ);avr=r(dKt,"FlaubertForTokenClassification"),dKt.forEach(t),nvr=r(wUe," (FlauBERT model)"),wUe.forEach(t),svr=i(J),SE=n(J,"LI",{});var AUe=s(SE);r3e=n(AUe,"STRONG",{});var mKt=s(r3e);lvr=r(mKt,"fnet"),mKt.forEach(t),ivr=r(AUe," \u2014 "),LZ=n(AUe,"A",{href:!0});var cKt=s(LZ);dvr=r(cKt,"FNetForTokenClassification"),cKt.forEach(t),mvr=r(AUe," (FNet model)"),AUe.forEach(t),cvr=i(J),RE=n(J,"LI",{});var LUe=s(RE);t3e=n(LUe,"STRONG",{});var fKt=s(t3e);fvr=r(fKt,"funnel"),fKt.forEach(t),gvr=r(LUe," \u2014 "),yZ=n(LUe,"A",{href:!0});var gKt=s(yZ);hvr=r(gKt,"FunnelForTokenClassification"),gKt.forEach(t),uvr=r(LUe," (Funnel Transformer model)"),LUe.forEach(t),pvr=i(J),PE=n(J,"LI",{});var yUe=s(PE);a3e=n(yUe,"STRONG",{});var hKt=s(a3e);_vr=r(hKt,"gpt2"),hKt.forEach(t),bvr=r(yUe," \u2014 "),xZ=n(yUe,"A",{href:!0});var uKt=s(xZ);vvr=r(uKt,"GPT2ForTokenClassification"),uKt.forEach(t),Fvr=r(yUe," (OpenAI GPT-2 model)"),yUe.forEach(t),Tvr=i(J),BE=n(J,"LI",{});var xUe=s(BE);n3e=n(xUe,"STRONG",{});var pKt=s(n3e);Mvr=r(pKt,"ibert"),pKt.forEach(t),Evr=r(xUe," \u2014 "),$Z=n(xUe,"A",{href:!0});var _Kt=s($Z);Cvr=r(_Kt,"IBertForTokenClassification"),_Kt.forEach(t),wvr=r(xUe," (I-BERT model)"),xUe.forEach(t),Avr=i(J),IE=n(J,"LI",{});var $Ue=s(IE);s3e=n($Ue,"STRONG",{});var bKt=s(s3e);Lvr=r(bKt,"layoutlm"),bKt.forEach(t),yvr=r($Ue," \u2014 "),kZ=n($Ue,"A",{href:!0});var vKt=s(kZ);xvr=r(vKt,"LayoutLMForTokenClassification"),vKt.forEach(t),$vr=r($Ue," (LayoutLM model)"),$Ue.forEach(t),kvr=i(J),NE=n(J,"LI",{});var kUe=s(NE);l3e=n(kUe,"STRONG",{});var FKt=s(l3e);Svr=r(FKt,"layoutlmv2"),FKt.forEach(t),Rvr=r(kUe," \u2014 "),SZ=n(kUe,"A",{href:!0});var TKt=s(SZ);Pvr=r(TKt,"LayoutLMv2ForTokenClassification"),TKt.forEach(t),Bvr=r(kUe," (LayoutLMv2 model)"),kUe.forEach(t),Ivr=i(J),qE=n(J,"LI",{});var SUe=s(qE);i3e=n(SUe,"STRONG",{});var MKt=s(i3e);Nvr=r(MKt,"layoutlmv3"),MKt.forEach(t),qvr=r(SUe," \u2014 "),RZ=n(SUe,"A",{href:!0});var EKt=s(RZ);jvr=r(EKt,"LayoutLMv3ForTokenClassification"),EKt.forEach(t),Dvr=r(SUe," (LayoutLMv3 model)"),SUe.forEach(t),Gvr=i(J),jE=n(J,"LI",{});var RUe=s(jE);d3e=n(RUe,"STRONG",{});var CKt=s(d3e);Ovr=r(CKt,"lilt"),CKt.forEach(t),Vvr=r(RUe," \u2014 "),PZ=n(RUe,"A",{href:!0});var wKt=s(PZ);Xvr=r(wKt,"LiltForTokenClassification"),wKt.forEach(t),zvr=r(RUe," (LiLT model)"),RUe.forEach(t),Qvr=i(J),DE=n(J,"LI",{});var PUe=s(DE);m3e=n(PUe,"STRONG",{});var AKt=s(m3e);Wvr=r(AKt,"longformer"),AKt.forEach(t),Uvr=r(PUe," \u2014 "),BZ=n(PUe,"A",{href:!0});var LKt=s(BZ);Hvr=r(LKt,"LongformerForTokenClassification"),LKt.forEach(t),Jvr=r(PUe," (Longformer model)"),PUe.forEach(t),Yvr=i(J),GE=n(J,"LI",{});var BUe=s(GE);c3e=n(BUe,"STRONG",{});var yKt=s(c3e);Zvr=r(yKt,"luke"),yKt.forEach(t),Kvr=r(BUe," \u2014 "),IZ=n(BUe,"A",{href:!0});var xKt=s(IZ);eFr=r(xKt,"LukeForTokenClassification"),xKt.forEach(t),oFr=r(BUe," (LUKE model)"),BUe.forEach(t),rFr=i(J),OE=n(J,"LI",{});var IUe=s(OE);f3e=n(IUe,"STRONG",{});var $Kt=s(f3e);tFr=r($Kt,"markuplm"),$Kt.forEach(t),aFr=r(IUe," \u2014 "),NZ=n(IUe,"A",{href:!0});var kKt=s(NZ);nFr=r(kKt,"MarkupLMForTokenClassification"),kKt.forEach(t),sFr=r(IUe," (MarkupLM model)"),IUe.forEach(t),lFr=i(J),VE=n(J,"LI",{});var NUe=s(VE);g3e=n(NUe,"STRONG",{});var SKt=s(g3e);iFr=r(SKt,"megatron-bert"),SKt.forEach(t),dFr=r(NUe," \u2014 "),qZ=n(NUe,"A",{href:!0});var RKt=s(qZ);mFr=r(RKt,"MegatronBertForTokenClassification"),RKt.forEach(t),cFr=r(NUe," (Megatron-BERT model)"),NUe.forEach(t),fFr=i(J),XE=n(J,"LI",{});var qUe=s(XE);h3e=n(qUe,"STRONG",{});var PKt=s(h3e);gFr=r(PKt,"mobilebert"),PKt.forEach(t),hFr=r(qUe," \u2014 "),jZ=n(qUe,"A",{href:!0});var BKt=s(jZ);uFr=r(BKt,"MobileBertForTokenClassification"),BKt.forEach(t),pFr=r(qUe," (MobileBERT model)"),qUe.forEach(t),_Fr=i(J),zE=n(J,"LI",{});var jUe=s(zE);u3e=n(jUe,"STRONG",{});var IKt=s(u3e);bFr=r(IKt,"mpnet"),IKt.forEach(t),vFr=r(jUe," \u2014 "),DZ=n(jUe,"A",{href:!0});var NKt=s(DZ);FFr=r(NKt,"MPNetForTokenClassification"),NKt.forEach(t),TFr=r(jUe," (MPNet model)"),jUe.forEach(t),MFr=i(J),QE=n(J,"LI",{});var DUe=s(QE);p3e=n(DUe,"STRONG",{});var qKt=s(p3e);EFr=r(qKt,"nezha"),qKt.forEach(t),CFr=r(DUe," \u2014 "),GZ=n(DUe,"A",{href:!0});var jKt=s(GZ);wFr=r(jKt,"NezhaForTokenClassification"),jKt.forEach(t),AFr=r(DUe," (Nezha model)"),DUe.forEach(t),LFr=i(J),WE=n(J,"LI",{});var GUe=s(WE);_3e=n(GUe,"STRONG",{});var DKt=s(_3e);yFr=r(DKt,"nystromformer"),DKt.forEach(t),xFr=r(GUe," \u2014 "),OZ=n(GUe,"A",{href:!0});var GKt=s(OZ);$Fr=r(GKt,"NystromformerForTokenClassification"),GKt.forEach(t),kFr=r(GUe," (Nystr\xF6mformer model)"),GUe.forEach(t),SFr=i(J),UE=n(J,"LI",{});var OUe=s(UE);b3e=n(OUe,"STRONG",{});var OKt=s(b3e);RFr=r(OKt,"qdqbert"),OKt.forEach(t),PFr=r(OUe," \u2014 "),VZ=n(OUe,"A",{href:!0});var VKt=s(VZ);BFr=r(VKt,"QDQBertForTokenClassification"),VKt.forEach(t),IFr=r(OUe," (QDQBert model)"),OUe.forEach(t),NFr=i(J),HE=n(J,"LI",{});var VUe=s(HE);v3e=n(VUe,"STRONG",{});var XKt=s(v3e);qFr=r(XKt,"rembert"),XKt.forEach(t),jFr=r(VUe," \u2014 "),XZ=n(VUe,"A",{href:!0});var zKt=s(XZ);DFr=r(zKt,"RemBertForTokenClassification"),zKt.forEach(t),GFr=r(VUe," (RemBERT model)"),VUe.forEach(t),OFr=i(J),JE=n(J,"LI",{});var XUe=s(JE);F3e=n(XUe,"STRONG",{});var QKt=s(F3e);VFr=r(QKt,"roberta"),QKt.forEach(t),XFr=r(XUe," \u2014 "),zZ=n(XUe,"A",{href:!0});var WKt=s(zZ);zFr=r(WKt,"RobertaForTokenClassification"),WKt.forEach(t),QFr=r(XUe," (RoBERTa model)"),XUe.forEach(t),WFr=i(J),YE=n(J,"LI",{});var zUe=s(YE);T3e=n(zUe,"STRONG",{});var UKt=s(T3e);UFr=r(UKt,"roformer"),UKt.forEach(t),HFr=r(zUe," \u2014 "),QZ=n(zUe,"A",{href:!0});var HKt=s(QZ);JFr=r(HKt,"RoFormerForTokenClassification"),HKt.forEach(t),YFr=r(zUe," (RoFormer model)"),zUe.forEach(t),ZFr=i(J),ZE=n(J,"LI",{});var QUe=s(ZE);M3e=n(QUe,"STRONG",{});var JKt=s(M3e);KFr=r(JKt,"squeezebert"),JKt.forEach(t),eTr=r(QUe," \u2014 "),WZ=n(QUe,"A",{href:!0});var YKt=s(WZ);oTr=r(YKt,"SqueezeBertForTokenClassification"),YKt.forEach(t),rTr=r(QUe," (SqueezeBERT model)"),QUe.forEach(t),tTr=i(J),KE=n(J,"LI",{});var WUe=s(KE);E3e=n(WUe,"STRONG",{});var ZKt=s(E3e);aTr=r(ZKt,"xlm"),ZKt.forEach(t),nTr=r(WUe," \u2014 "),UZ=n(WUe,"A",{href:!0});var KKt=s(UZ);sTr=r(KKt,"XLMForTokenClassification"),KKt.forEach(t),lTr=r(WUe," (XLM model)"),WUe.forEach(t),iTr=i(J),e4=n(J,"LI",{});var UUe=s(e4);C3e=n(UUe,"STRONG",{});var eea=s(C3e);dTr=r(eea,"xlm-roberta"),eea.forEach(t),mTr=r(UUe," \u2014 "),HZ=n(UUe,"A",{href:!0});var oea=s(HZ);cTr=r(oea,"XLMRobertaForTokenClassification"),oea.forEach(t),fTr=r(UUe," (XLM-RoBERTa model)"),UUe.forEach(t),gTr=i(J),o4=n(J,"LI",{});var HUe=s(o4);w3e=n(HUe,"STRONG",{});var rea=s(w3e);hTr=r(rea,"xlm-roberta-xl"),rea.forEach(t),uTr=r(HUe," \u2014 "),JZ=n(HUe,"A",{href:!0});var tea=s(JZ);pTr=r(tea,"XLMRobertaXLForTokenClassification"),tea.forEach(t),_Tr=r(HUe," (XLM-RoBERTa-XL model)"),HUe.forEach(t),bTr=i(J),r4=n(J,"LI",{});var JUe=s(r4);A3e=n(JUe,"STRONG",{});var aea=s(A3e);vTr=r(aea,"xlnet"),aea.forEach(t),FTr=r(JUe," \u2014 "),YZ=n(JUe,"A",{href:!0});var nea=s(YZ);TTr=r(nea,"XLNetForTokenClassification"),nea.forEach(t),MTr=r(JUe," (XLNet model)"),JUe.forEach(t),ETr=i(J),t4=n(J,"LI",{});var YUe=s(t4);L3e=n(YUe,"STRONG",{});var sea=s(L3e);CTr=r(sea,"yoso"),sea.forEach(t),wTr=r(YUe," \u2014 "),ZZ=n(YUe,"A",{href:!0});var lea=s(ZZ);ATr=r(lea,"YosoForTokenClassification"),lea.forEach(t),LTr=r(YUe," (YOSO model)"),YUe.forEach(t),J.forEach(t),yTr=i(Ia),a4=n(Ia,"P",{});var ZUe=s(a4);xTr=r(ZUe,"The model is set in evaluation mode by default using "),y3e=n(ZUe,"CODE",{});var iea=s(y3e);$Tr=r(iea,"model.eval()"),iea.forEach(t),kTr=r(ZUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),x3e=n(ZUe,"CODE",{});var dea=s(x3e);STr=r(dea,"model.train()"),dea.forEach(t),ZUe.forEach(t),RTr=i(Ia),T(n4.$$.fragment,Ia),Ia.forEach(t),Ul.forEach(t),wao=i(c),dm=n(c,"H2",{class:!0});var Xso=s(dm);s4=n(Xso,"A",{id:!0,class:!0,href:!0});var mea=s(s4);$3e=n(mea,"SPAN",{});var cea=s($3e);T(Nk.$$.fragment,cea),cea.forEach(t),mea.forEach(t),PTr=i(Xso),k3e=n(Xso,"SPAN",{});var fea=s(k3e);BTr=r(fea,"AutoModelForQuestionAnswering"),fea.forEach(t),Xso.forEach(t),Aao=i(c),Qo=n(c,"DIV",{class:!0});var Hl=s(Qo);T(qk.$$.fragment,Hl),ITr=i(Hl),mm=n(Hl,"P",{});var Ime=s(mm);NTr=r(Ime,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),KZ=n(Ime,"A",{href:!0});var gea=s(KZ);qTr=r(gea,"from_pretrained()"),gea.forEach(t),jTr=r(Ime," class method or the "),eK=n(Ime,"A",{href:!0});var hea=s(eK);DTr=r(hea,"from_config()"),hea.forEach(t),GTr=r(Ime,` class
method.`),Ime.forEach(t),OTr=i(Hl),jk=n(Hl,"P",{});var zso=s(jk);VTr=r(zso,"This class cannot be instantiated directly using "),S3e=n(zso,"CODE",{});var uea=s(S3e);XTr=r(uea,"__init__()"),uea.forEach(t),zTr=r(zso," (throws an error)."),zso.forEach(t),QTr=i(Hl),St=n(Hl,"DIV",{class:!0});var w9=s(St);T(Dk.$$.fragment,w9),WTr=i(w9),R3e=n(w9,"P",{});var pea=s(R3e);UTr=r(pea,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),pea.forEach(t),HTr=i(w9),cm=n(w9,"P",{});var Nme=s(cm);JTr=r(Nme,`Note:
Loading a model from its configuration file does `),P3e=n(Nme,"STRONG",{});var _ea=s(P3e);YTr=r(_ea,"not"),_ea.forEach(t),ZTr=r(Nme,` load the model weights. It only affects the
model\u2019s configuration. Use `),oK=n(Nme,"A",{href:!0});var bea=s(oK);KTr=r(bea,"from_pretrained()"),bea.forEach(t),eMr=r(Nme," to load the model weights."),Nme.forEach(t),oMr=i(w9),T(l4.$$.fragment,w9),w9.forEach(t),rMr=i(Hl),mo=n(Hl,"DIV",{class:!0});var Na=s(mo);T(Gk.$$.fragment,Na),tMr=i(Na),B3e=n(Na,"P",{});var vea=s(B3e);aMr=r(vea,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),vea.forEach(t),nMr=i(Na),pn=n(Na,"P",{});var A9=s(pn);sMr=r(A9,"The model class to instantiate is selected based on the "),I3e=n(A9,"CODE",{});var Fea=s(I3e);lMr=r(Fea,"model_type"),Fea.forEach(t),iMr=r(A9,` property of the config object (either
passed as an argument or loaded from `),N3e=n(A9,"CODE",{});var Tea=s(N3e);dMr=r(Tea,"pretrained_model_name_or_path"),Tea.forEach(t),mMr=r(A9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q3e=n(A9,"CODE",{});var Mea=s(q3e);cMr=r(Mea,"pretrained_model_name_or_path"),Mea.forEach(t),fMr=r(A9,":"),A9.forEach(t),gMr=i(Na),O=n(Na,"UL",{});var X=s(O);i4=n(X,"LI",{});var KUe=s(i4);j3e=n(KUe,"STRONG",{});var Eea=s(j3e);hMr=r(Eea,"albert"),Eea.forEach(t),uMr=r(KUe," \u2014 "),rK=n(KUe,"A",{href:!0});var Cea=s(rK);pMr=r(Cea,"AlbertForQuestionAnswering"),Cea.forEach(t),_Mr=r(KUe," (ALBERT model)"),KUe.forEach(t),bMr=i(X),d4=n(X,"LI",{});var eHe=s(d4);D3e=n(eHe,"STRONG",{});var wea=s(D3e);vMr=r(wea,"bart"),wea.forEach(t),FMr=r(eHe," \u2014 "),tK=n(eHe,"A",{href:!0});var Aea=s(tK);TMr=r(Aea,"BartForQuestionAnswering"),Aea.forEach(t),MMr=r(eHe," (BART model)"),eHe.forEach(t),EMr=i(X),m4=n(X,"LI",{});var oHe=s(m4);G3e=n(oHe,"STRONG",{});var Lea=s(G3e);CMr=r(Lea,"bert"),Lea.forEach(t),wMr=r(oHe," \u2014 "),aK=n(oHe,"A",{href:!0});var yea=s(aK);AMr=r(yea,"BertForQuestionAnswering"),yea.forEach(t),LMr=r(oHe," (BERT model)"),oHe.forEach(t),yMr=i(X),c4=n(X,"LI",{});var rHe=s(c4);O3e=n(rHe,"STRONG",{});var xea=s(O3e);xMr=r(xea,"big_bird"),xea.forEach(t),$Mr=r(rHe," \u2014 "),nK=n(rHe,"A",{href:!0});var $ea=s(nK);kMr=r($ea,"BigBirdForQuestionAnswering"),$ea.forEach(t),SMr=r(rHe," (BigBird model)"),rHe.forEach(t),RMr=i(X),f4=n(X,"LI",{});var tHe=s(f4);V3e=n(tHe,"STRONG",{});var kea=s(V3e);PMr=r(kea,"bigbird_pegasus"),kea.forEach(t),BMr=r(tHe," \u2014 "),sK=n(tHe,"A",{href:!0});var Sea=s(sK);IMr=r(Sea,"BigBirdPegasusForQuestionAnswering"),Sea.forEach(t),NMr=r(tHe," (BigBird-Pegasus model)"),tHe.forEach(t),qMr=i(X),g4=n(X,"LI",{});var aHe=s(g4);X3e=n(aHe,"STRONG",{});var Rea=s(X3e);jMr=r(Rea,"bloom"),Rea.forEach(t),DMr=r(aHe," \u2014 "),lK=n(aHe,"A",{href:!0});var Pea=s(lK);GMr=r(Pea,"BloomForQuestionAnswering"),Pea.forEach(t),OMr=r(aHe," (BLOOM model)"),aHe.forEach(t),VMr=i(X),h4=n(X,"LI",{});var nHe=s(h4);z3e=n(nHe,"STRONG",{});var Bea=s(z3e);XMr=r(Bea,"camembert"),Bea.forEach(t),zMr=r(nHe," \u2014 "),iK=n(nHe,"A",{href:!0});var Iea=s(iK);QMr=r(Iea,"CamembertForQuestionAnswering"),Iea.forEach(t),WMr=r(nHe," (CamemBERT model)"),nHe.forEach(t),UMr=i(X),u4=n(X,"LI",{});var sHe=s(u4);Q3e=n(sHe,"STRONG",{});var Nea=s(Q3e);HMr=r(Nea,"canine"),Nea.forEach(t),JMr=r(sHe," \u2014 "),dK=n(sHe,"A",{href:!0});var qea=s(dK);YMr=r(qea,"CanineForQuestionAnswering"),qea.forEach(t),ZMr=r(sHe," (CANINE model)"),sHe.forEach(t),KMr=i(X),p4=n(X,"LI",{});var lHe=s(p4);W3e=n(lHe,"STRONG",{});var jea=s(W3e);eEr=r(jea,"convbert"),jea.forEach(t),oEr=r(lHe," \u2014 "),mK=n(lHe,"A",{href:!0});var Dea=s(mK);rEr=r(Dea,"ConvBertForQuestionAnswering"),Dea.forEach(t),tEr=r(lHe," (ConvBERT model)"),lHe.forEach(t),aEr=i(X),_4=n(X,"LI",{});var iHe=s(_4);U3e=n(iHe,"STRONG",{});var Gea=s(U3e);nEr=r(Gea,"data2vec-text"),Gea.forEach(t),sEr=r(iHe," \u2014 "),cK=n(iHe,"A",{href:!0});var Oea=s(cK);lEr=r(Oea,"Data2VecTextForQuestionAnswering"),Oea.forEach(t),iEr=r(iHe," (Data2VecText model)"),iHe.forEach(t),dEr=i(X),b4=n(X,"LI",{});var dHe=s(b4);H3e=n(dHe,"STRONG",{});var Vea=s(H3e);mEr=r(Vea,"deberta"),Vea.forEach(t),cEr=r(dHe," \u2014 "),fK=n(dHe,"A",{href:!0});var Xea=s(fK);fEr=r(Xea,"DebertaForQuestionAnswering"),Xea.forEach(t),gEr=r(dHe," (DeBERTa model)"),dHe.forEach(t),hEr=i(X),v4=n(X,"LI",{});var mHe=s(v4);J3e=n(mHe,"STRONG",{});var zea=s(J3e);uEr=r(zea,"deberta-v2"),zea.forEach(t),pEr=r(mHe," \u2014 "),gK=n(mHe,"A",{href:!0});var Qea=s(gK);_Er=r(Qea,"DebertaV2ForQuestionAnswering"),Qea.forEach(t),bEr=r(mHe," (DeBERTa-v2 model)"),mHe.forEach(t),vEr=i(X),F4=n(X,"LI",{});var cHe=s(F4);Y3e=n(cHe,"STRONG",{});var Wea=s(Y3e);FEr=r(Wea,"distilbert"),Wea.forEach(t),TEr=r(cHe," \u2014 "),hK=n(cHe,"A",{href:!0});var Uea=s(hK);MEr=r(Uea,"DistilBertForQuestionAnswering"),Uea.forEach(t),EEr=r(cHe," (DistilBERT model)"),cHe.forEach(t),CEr=i(X),T4=n(X,"LI",{});var fHe=s(T4);Z3e=n(fHe,"STRONG",{});var Hea=s(Z3e);wEr=r(Hea,"electra"),Hea.forEach(t),AEr=r(fHe," \u2014 "),uK=n(fHe,"A",{href:!0});var Jea=s(uK);LEr=r(Jea,"ElectraForQuestionAnswering"),Jea.forEach(t),yEr=r(fHe," (ELECTRA model)"),fHe.forEach(t),xEr=i(X),M4=n(X,"LI",{});var gHe=s(M4);K3e=n(gHe,"STRONG",{});var Yea=s(K3e);$Er=r(Yea,"ernie"),Yea.forEach(t),kEr=r(gHe," \u2014 "),pK=n(gHe,"A",{href:!0});var Zea=s(pK);SEr=r(Zea,"ErnieForQuestionAnswering"),Zea.forEach(t),REr=r(gHe," (ERNIE model)"),gHe.forEach(t),PEr=i(X),E4=n(X,"LI",{});var hHe=s(E4);e5e=n(hHe,"STRONG",{});var Kea=s(e5e);BEr=r(Kea,"flaubert"),Kea.forEach(t),IEr=r(hHe," \u2014 "),_K=n(hHe,"A",{href:!0});var eoa=s(_K);NEr=r(eoa,"FlaubertForQuestionAnsweringSimple"),eoa.forEach(t),qEr=r(hHe," (FlauBERT model)"),hHe.forEach(t),jEr=i(X),C4=n(X,"LI",{});var uHe=s(C4);o5e=n(uHe,"STRONG",{});var ooa=s(o5e);DEr=r(ooa,"fnet"),ooa.forEach(t),GEr=r(uHe," \u2014 "),bK=n(uHe,"A",{href:!0});var roa=s(bK);OEr=r(roa,"FNetForQuestionAnswering"),roa.forEach(t),VEr=r(uHe," (FNet model)"),uHe.forEach(t),XEr=i(X),w4=n(X,"LI",{});var pHe=s(w4);r5e=n(pHe,"STRONG",{});var toa=s(r5e);zEr=r(toa,"funnel"),toa.forEach(t),QEr=r(pHe," \u2014 "),vK=n(pHe,"A",{href:!0});var aoa=s(vK);WEr=r(aoa,"FunnelForQuestionAnswering"),aoa.forEach(t),UEr=r(pHe," (Funnel Transformer model)"),pHe.forEach(t),HEr=i(X),A4=n(X,"LI",{});var _He=s(A4);t5e=n(_He,"STRONG",{});var noa=s(t5e);JEr=r(noa,"gptj"),noa.forEach(t),YEr=r(_He," \u2014 "),FK=n(_He,"A",{href:!0});var soa=s(FK);ZEr=r(soa,"GPTJForQuestionAnswering"),soa.forEach(t),KEr=r(_He," (GPT-J model)"),_He.forEach(t),e4r=i(X),L4=n(X,"LI",{});var bHe=s(L4);a5e=n(bHe,"STRONG",{});var loa=s(a5e);o4r=r(loa,"ibert"),loa.forEach(t),r4r=r(bHe," \u2014 "),TK=n(bHe,"A",{href:!0});var ioa=s(TK);t4r=r(ioa,"IBertForQuestionAnswering"),ioa.forEach(t),a4r=r(bHe," (I-BERT model)"),bHe.forEach(t),n4r=i(X),y4=n(X,"LI",{});var vHe=s(y4);n5e=n(vHe,"STRONG",{});var doa=s(n5e);s4r=r(doa,"layoutlmv2"),doa.forEach(t),l4r=r(vHe," \u2014 "),MK=n(vHe,"A",{href:!0});var moa=s(MK);i4r=r(moa,"LayoutLMv2ForQuestionAnswering"),moa.forEach(t),d4r=r(vHe," (LayoutLMv2 model)"),vHe.forEach(t),m4r=i(X),x4=n(X,"LI",{});var FHe=s(x4);s5e=n(FHe,"STRONG",{});var coa=s(s5e);c4r=r(coa,"layoutlmv3"),coa.forEach(t),f4r=r(FHe," \u2014 "),EK=n(FHe,"A",{href:!0});var foa=s(EK);g4r=r(foa,"LayoutLMv3ForQuestionAnswering"),foa.forEach(t),h4r=r(FHe," (LayoutLMv3 model)"),FHe.forEach(t),u4r=i(X),$4=n(X,"LI",{});var THe=s($4);l5e=n(THe,"STRONG",{});var goa=s(l5e);p4r=r(goa,"led"),goa.forEach(t),_4r=r(THe," \u2014 "),CK=n(THe,"A",{href:!0});var hoa=s(CK);b4r=r(hoa,"LEDForQuestionAnswering"),hoa.forEach(t),v4r=r(THe," (LED model)"),THe.forEach(t),F4r=i(X),k4=n(X,"LI",{});var MHe=s(k4);i5e=n(MHe,"STRONG",{});var uoa=s(i5e);T4r=r(uoa,"lilt"),uoa.forEach(t),M4r=r(MHe," \u2014 "),wK=n(MHe,"A",{href:!0});var poa=s(wK);E4r=r(poa,"LiltForQuestionAnswering"),poa.forEach(t),C4r=r(MHe," (LiLT model)"),MHe.forEach(t),w4r=i(X),S4=n(X,"LI",{});var EHe=s(S4);d5e=n(EHe,"STRONG",{});var _oa=s(d5e);A4r=r(_oa,"longformer"),_oa.forEach(t),L4r=r(EHe," \u2014 "),AK=n(EHe,"A",{href:!0});var boa=s(AK);y4r=r(boa,"LongformerForQuestionAnswering"),boa.forEach(t),x4r=r(EHe," (Longformer model)"),EHe.forEach(t),$4r=i(X),R4=n(X,"LI",{});var CHe=s(R4);m5e=n(CHe,"STRONG",{});var voa=s(m5e);k4r=r(voa,"luke"),voa.forEach(t),S4r=r(CHe," \u2014 "),LK=n(CHe,"A",{href:!0});var Foa=s(LK);R4r=r(Foa,"LukeForQuestionAnswering"),Foa.forEach(t),P4r=r(CHe," (LUKE model)"),CHe.forEach(t),B4r=i(X),P4=n(X,"LI",{});var wHe=s(P4);c5e=n(wHe,"STRONG",{});var Toa=s(c5e);I4r=r(Toa,"lxmert"),Toa.forEach(t),N4r=r(wHe," \u2014 "),yK=n(wHe,"A",{href:!0});var Moa=s(yK);q4r=r(Moa,"LxmertForQuestionAnswering"),Moa.forEach(t),j4r=r(wHe," (LXMERT model)"),wHe.forEach(t),D4r=i(X),B4=n(X,"LI",{});var AHe=s(B4);f5e=n(AHe,"STRONG",{});var Eoa=s(f5e);G4r=r(Eoa,"markuplm"),Eoa.forEach(t),O4r=r(AHe," \u2014 "),xK=n(AHe,"A",{href:!0});var Coa=s(xK);V4r=r(Coa,"MarkupLMForQuestionAnswering"),Coa.forEach(t),X4r=r(AHe," (MarkupLM model)"),AHe.forEach(t),z4r=i(X),I4=n(X,"LI",{});var LHe=s(I4);g5e=n(LHe,"STRONG",{});var woa=s(g5e);Q4r=r(woa,"mbart"),woa.forEach(t),W4r=r(LHe," \u2014 "),$K=n(LHe,"A",{href:!0});var Aoa=s($K);U4r=r(Aoa,"MBartForQuestionAnswering"),Aoa.forEach(t),H4r=r(LHe," (mBART model)"),LHe.forEach(t),J4r=i(X),N4=n(X,"LI",{});var yHe=s(N4);h5e=n(yHe,"STRONG",{});var Loa=s(h5e);Y4r=r(Loa,"megatron-bert"),Loa.forEach(t),Z4r=r(yHe," \u2014 "),kK=n(yHe,"A",{href:!0});var yoa=s(kK);K4r=r(yoa,"MegatronBertForQuestionAnswering"),yoa.forEach(t),eCr=r(yHe," (Megatron-BERT model)"),yHe.forEach(t),oCr=i(X),q4=n(X,"LI",{});var xHe=s(q4);u5e=n(xHe,"STRONG",{});var xoa=s(u5e);rCr=r(xoa,"mobilebert"),xoa.forEach(t),tCr=r(xHe," \u2014 "),SK=n(xHe,"A",{href:!0});var $oa=s(SK);aCr=r($oa,"MobileBertForQuestionAnswering"),$oa.forEach(t),nCr=r(xHe," (MobileBERT model)"),xHe.forEach(t),sCr=i(X),j4=n(X,"LI",{});var $He=s(j4);p5e=n($He,"STRONG",{});var koa=s(p5e);lCr=r(koa,"mpnet"),koa.forEach(t),iCr=r($He," \u2014 "),RK=n($He,"A",{href:!0});var Soa=s(RK);dCr=r(Soa,"MPNetForQuestionAnswering"),Soa.forEach(t),mCr=r($He," (MPNet model)"),$He.forEach(t),cCr=i(X),D4=n(X,"LI",{});var kHe=s(D4);_5e=n(kHe,"STRONG",{});var Roa=s(_5e);fCr=r(Roa,"mvp"),Roa.forEach(t),gCr=r(kHe," \u2014 "),PK=n(kHe,"A",{href:!0});var Poa=s(PK);hCr=r(Poa,"MvpForQuestionAnswering"),Poa.forEach(t),uCr=r(kHe," (MVP model)"),kHe.forEach(t),pCr=i(X),G4=n(X,"LI",{});var SHe=s(G4);b5e=n(SHe,"STRONG",{});var Boa=s(b5e);_Cr=r(Boa,"nezha"),Boa.forEach(t),bCr=r(SHe," \u2014 "),BK=n(SHe,"A",{href:!0});var Ioa=s(BK);vCr=r(Ioa,"NezhaForQuestionAnswering"),Ioa.forEach(t),FCr=r(SHe," (Nezha model)"),SHe.forEach(t),TCr=i(X),O4=n(X,"LI",{});var RHe=s(O4);v5e=n(RHe,"STRONG",{});var Noa=s(v5e);MCr=r(Noa,"nystromformer"),Noa.forEach(t),ECr=r(RHe," \u2014 "),IK=n(RHe,"A",{href:!0});var qoa=s(IK);CCr=r(qoa,"NystromformerForQuestionAnswering"),qoa.forEach(t),wCr=r(RHe," (Nystr\xF6mformer model)"),RHe.forEach(t),ACr=i(X),V4=n(X,"LI",{});var PHe=s(V4);F5e=n(PHe,"STRONG",{});var joa=s(F5e);LCr=r(joa,"opt"),joa.forEach(t),yCr=r(PHe," \u2014 "),NK=n(PHe,"A",{href:!0});var Doa=s(NK);xCr=r(Doa,"OPTForQuestionAnswering"),Doa.forEach(t),$Cr=r(PHe," (OPT model)"),PHe.forEach(t),kCr=i(X),X4=n(X,"LI",{});var BHe=s(X4);T5e=n(BHe,"STRONG",{});var Goa=s(T5e);SCr=r(Goa,"qdqbert"),Goa.forEach(t),RCr=r(BHe," \u2014 "),qK=n(BHe,"A",{href:!0});var Ooa=s(qK);PCr=r(Ooa,"QDQBertForQuestionAnswering"),Ooa.forEach(t),BCr=r(BHe," (QDQBert model)"),BHe.forEach(t),ICr=i(X),z4=n(X,"LI",{});var IHe=s(z4);M5e=n(IHe,"STRONG",{});var Voa=s(M5e);NCr=r(Voa,"reformer"),Voa.forEach(t),qCr=r(IHe," \u2014 "),jK=n(IHe,"A",{href:!0});var Xoa=s(jK);jCr=r(Xoa,"ReformerForQuestionAnswering"),Xoa.forEach(t),DCr=r(IHe," (Reformer model)"),IHe.forEach(t),GCr=i(X),Q4=n(X,"LI",{});var NHe=s(Q4);E5e=n(NHe,"STRONG",{});var zoa=s(E5e);OCr=r(zoa,"rembert"),zoa.forEach(t),VCr=r(NHe," \u2014 "),DK=n(NHe,"A",{href:!0});var Qoa=s(DK);XCr=r(Qoa,"RemBertForQuestionAnswering"),Qoa.forEach(t),zCr=r(NHe," (RemBERT model)"),NHe.forEach(t),QCr=i(X),W4=n(X,"LI",{});var qHe=s(W4);C5e=n(qHe,"STRONG",{});var Woa=s(C5e);WCr=r(Woa,"roberta"),Woa.forEach(t),UCr=r(qHe," \u2014 "),GK=n(qHe,"A",{href:!0});var Uoa=s(GK);HCr=r(Uoa,"RobertaForQuestionAnswering"),Uoa.forEach(t),JCr=r(qHe," (RoBERTa model)"),qHe.forEach(t),YCr=i(X),U4=n(X,"LI",{});var jHe=s(U4);w5e=n(jHe,"STRONG",{});var Hoa=s(w5e);ZCr=r(Hoa,"roformer"),Hoa.forEach(t),KCr=r(jHe," \u2014 "),OK=n(jHe,"A",{href:!0});var Joa=s(OK);e3r=r(Joa,"RoFormerForQuestionAnswering"),Joa.forEach(t),o3r=r(jHe," (RoFormer model)"),jHe.forEach(t),r3r=i(X),H4=n(X,"LI",{});var DHe=s(H4);A5e=n(DHe,"STRONG",{});var Yoa=s(A5e);t3r=r(Yoa,"splinter"),Yoa.forEach(t),a3r=r(DHe," \u2014 "),VK=n(DHe,"A",{href:!0});var Zoa=s(VK);n3r=r(Zoa,"SplinterForQuestionAnswering"),Zoa.forEach(t),s3r=r(DHe," (Splinter model)"),DHe.forEach(t),l3r=i(X),J4=n(X,"LI",{});var GHe=s(J4);L5e=n(GHe,"STRONG",{});var Koa=s(L5e);i3r=r(Koa,"squeezebert"),Koa.forEach(t),d3r=r(GHe," \u2014 "),XK=n(GHe,"A",{href:!0});var era=s(XK);m3r=r(era,"SqueezeBertForQuestionAnswering"),era.forEach(t),c3r=r(GHe," (SqueezeBERT model)"),GHe.forEach(t),f3r=i(X),Y4=n(X,"LI",{});var OHe=s(Y4);y5e=n(OHe,"STRONG",{});var ora=s(y5e);g3r=r(ora,"xlm"),ora.forEach(t),h3r=r(OHe," \u2014 "),zK=n(OHe,"A",{href:!0});var rra=s(zK);u3r=r(rra,"XLMForQuestionAnsweringSimple"),rra.forEach(t),p3r=r(OHe," (XLM model)"),OHe.forEach(t),_3r=i(X),Z4=n(X,"LI",{});var VHe=s(Z4);x5e=n(VHe,"STRONG",{});var tra=s(x5e);b3r=r(tra,"xlm-roberta"),tra.forEach(t),v3r=r(VHe," \u2014 "),QK=n(VHe,"A",{href:!0});var ara=s(QK);F3r=r(ara,"XLMRobertaForQuestionAnswering"),ara.forEach(t),T3r=r(VHe," (XLM-RoBERTa model)"),VHe.forEach(t),M3r=i(X),K4=n(X,"LI",{});var XHe=s(K4);$5e=n(XHe,"STRONG",{});var nra=s($5e);E3r=r(nra,"xlm-roberta-xl"),nra.forEach(t),C3r=r(XHe," \u2014 "),WK=n(XHe,"A",{href:!0});var sra=s(WK);w3r=r(sra,"XLMRobertaXLForQuestionAnswering"),sra.forEach(t),A3r=r(XHe," (XLM-RoBERTa-XL model)"),XHe.forEach(t),L3r=i(X),eC=n(X,"LI",{});var zHe=s(eC);k5e=n(zHe,"STRONG",{});var lra=s(k5e);y3r=r(lra,"xlnet"),lra.forEach(t),x3r=r(zHe," \u2014 "),UK=n(zHe,"A",{href:!0});var ira=s(UK);$3r=r(ira,"XLNetForQuestionAnsweringSimple"),ira.forEach(t),k3r=r(zHe," (XLNet model)"),zHe.forEach(t),S3r=i(X),oC=n(X,"LI",{});var QHe=s(oC);S5e=n(QHe,"STRONG",{});var dra=s(S5e);R3r=r(dra,"yoso"),dra.forEach(t),P3r=r(QHe," \u2014 "),HK=n(QHe,"A",{href:!0});var mra=s(HK);B3r=r(mra,"YosoForQuestionAnswering"),mra.forEach(t),I3r=r(QHe," (YOSO model)"),QHe.forEach(t),X.forEach(t),N3r=i(Na),rC=n(Na,"P",{});var WHe=s(rC);q3r=r(WHe,"The model is set in evaluation mode by default using "),R5e=n(WHe,"CODE",{});var cra=s(R5e);j3r=r(cra,"model.eval()"),cra.forEach(t),D3r=r(WHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),P5e=n(WHe,"CODE",{});var fra=s(P5e);G3r=r(fra,"model.train()"),fra.forEach(t),WHe.forEach(t),O3r=i(Na),T(tC.$$.fragment,Na),Na.forEach(t),Hl.forEach(t),Lao=i(c),fm=n(c,"H2",{class:!0});var Qso=s(fm);aC=n(Qso,"A",{id:!0,class:!0,href:!0});var gra=s(aC);B5e=n(gra,"SPAN",{});var hra=s(B5e);T(Ok.$$.fragment,hra),hra.forEach(t),gra.forEach(t),V3r=i(Qso),I5e=n(Qso,"SPAN",{});var ura=s(I5e);X3r=r(ura,"AutoModelForTableQuestionAnswering"),ura.forEach(t),Qso.forEach(t),yao=i(c),Wo=n(c,"DIV",{class:!0});var Jl=s(Wo);T(Vk.$$.fragment,Jl),z3r=i(Jl),gm=n(Jl,"P",{});var qme=s(gm);Q3r=r(qme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),JK=n(qme,"A",{href:!0});var pra=s(JK);W3r=r(pra,"from_pretrained()"),pra.forEach(t),U3r=r(qme," class method or the "),YK=n(qme,"A",{href:!0});var _ra=s(YK);H3r=r(_ra,"from_config()"),_ra.forEach(t),J3r=r(qme,` class
method.`),qme.forEach(t),Y3r=i(Jl),Xk=n(Jl,"P",{});var Wso=s(Xk);Z3r=r(Wso,"This class cannot be instantiated directly using "),N5e=n(Wso,"CODE",{});var bra=s(N5e);K3r=r(bra,"__init__()"),bra.forEach(t),e5r=r(Wso," (throws an error)."),Wso.forEach(t),o5r=i(Jl),Rt=n(Jl,"DIV",{class:!0});var L9=s(Rt);T(zk.$$.fragment,L9),r5r=i(L9),q5e=n(L9,"P",{});var vra=s(q5e);t5r=r(vra,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),vra.forEach(t),a5r=i(L9),hm=n(L9,"P",{});var jme=s(hm);n5r=r(jme,`Note:
Loading a model from its configuration file does `),j5e=n(jme,"STRONG",{});var Fra=s(j5e);s5r=r(Fra,"not"),Fra.forEach(t),l5r=r(jme,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZK=n(jme,"A",{href:!0});var Tra=s(ZK);i5r=r(Tra,"from_pretrained()"),Tra.forEach(t),d5r=r(jme," to load the model weights."),jme.forEach(t),m5r=i(L9),T(nC.$$.fragment,L9),L9.forEach(t),c5r=i(Jl),co=n(Jl,"DIV",{class:!0});var qa=s(co);T(Qk.$$.fragment,qa),f5r=i(qa),D5e=n(qa,"P",{});var Mra=s(D5e);g5r=r(Mra,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Mra.forEach(t),h5r=i(qa),_n=n(qa,"P",{});var y9=s(_n);u5r=r(y9,"The model class to instantiate is selected based on the "),G5e=n(y9,"CODE",{});var Era=s(G5e);p5r=r(Era,"model_type"),Era.forEach(t),_5r=r(y9,` property of the config object (either
passed as an argument or loaded from `),O5e=n(y9,"CODE",{});var Cra=s(O5e);b5r=r(Cra,"pretrained_model_name_or_path"),Cra.forEach(t),v5r=r(y9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),V5e=n(y9,"CODE",{});var wra=s(V5e);F5r=r(wra,"pretrained_model_name_or_path"),wra.forEach(t),T5r=r(y9,":"),y9.forEach(t),M5r=i(qa),X5e=n(qa,"UL",{});var Ara=s(X5e);sC=n(Ara,"LI",{});var UHe=s(sC);z5e=n(UHe,"STRONG",{});var Lra=s(z5e);E5r=r(Lra,"tapas"),Lra.forEach(t),C5r=r(UHe," \u2014 "),KK=n(UHe,"A",{href:!0});var yra=s(KK);w5r=r(yra,"TapasForQuestionAnswering"),yra.forEach(t),A5r=r(UHe," (TAPAS model)"),UHe.forEach(t),Ara.forEach(t),L5r=i(qa),lC=n(qa,"P",{});var HHe=s(lC);y5r=r(HHe,"The model is set in evaluation mode by default using "),Q5e=n(HHe,"CODE",{});var xra=s(Q5e);x5r=r(xra,"model.eval()"),xra.forEach(t),$5r=r(HHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),W5e=n(HHe,"CODE",{});var $ra=s(W5e);k5r=r($ra,"model.train()"),$ra.forEach(t),HHe.forEach(t),S5r=i(qa),T(iC.$$.fragment,qa),qa.forEach(t),Jl.forEach(t),xao=i(c),um=n(c,"H2",{class:!0});var Uso=s(um);dC=n(Uso,"A",{id:!0,class:!0,href:!0});var kra=s(dC);U5e=n(kra,"SPAN",{});var Sra=s(U5e);T(Wk.$$.fragment,Sra),Sra.forEach(t),kra.forEach(t),R5r=i(Uso),H5e=n(Uso,"SPAN",{});var Rra=s(H5e);P5r=r(Rra,"AutoModelForDocumentQuestionAnswering"),Rra.forEach(t),Uso.forEach(t),$ao=i(c),Uo=n(c,"DIV",{class:!0});var Yl=s(Uo);T(Uk.$$.fragment,Yl),B5r=i(Yl),pm=n(Yl,"P",{});var Dme=s(pm);I5r=r(Dme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),eee=n(Dme,"A",{href:!0});var Pra=s(eee);N5r=r(Pra,"from_pretrained()"),Pra.forEach(t),q5r=r(Dme," class method or the "),oee=n(Dme,"A",{href:!0});var Bra=s(oee);j5r=r(Bra,"from_config()"),Bra.forEach(t),D5r=r(Dme,` class
method.`),Dme.forEach(t),G5r=i(Yl),Hk=n(Yl,"P",{});var Hso=s(Hk);O5r=r(Hso,"This class cannot be instantiated directly using "),J5e=n(Hso,"CODE",{});var Ira=s(J5e);V5r=r(Ira,"__init__()"),Ira.forEach(t),X5r=r(Hso," (throws an error)."),Hso.forEach(t),z5r=i(Yl),Pt=n(Yl,"DIV",{class:!0});var x9=s(Pt);T(Jk.$$.fragment,x9),Q5r=i(x9),Y5e=n(x9,"P",{});var Nra=s(Y5e);W5r=r(Nra,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Nra.forEach(t),U5r=i(x9),_m=n(x9,"P",{});var Gme=s(_m);H5r=r(Gme,`Note:
Loading a model from its configuration file does `),Z5e=n(Gme,"STRONG",{});var qra=s(Z5e);J5r=r(qra,"not"),qra.forEach(t),Y5r=r(Gme,` load the model weights. It only affects the
model\u2019s configuration. Use `),ree=n(Gme,"A",{href:!0});var jra=s(ree);Z5r=r(jra,"from_pretrained()"),jra.forEach(t),K5r=r(Gme," to load the model weights."),Gme.forEach(t),e0r=i(x9),T(mC.$$.fragment,x9),x9.forEach(t),o0r=i(Yl),fo=n(Yl,"DIV",{class:!0});var ja=s(fo);T(Yk.$$.fragment,ja),r0r=i(ja),K5e=n(ja,"P",{});var Dra=s(K5e);t0r=r(Dra,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Dra.forEach(t),a0r=i(ja),bn=n(ja,"P",{});var $9=s(bn);n0r=r($9,"The model class to instantiate is selected based on the "),e0e=n($9,"CODE",{});var Gra=s(e0e);s0r=r(Gra,"model_type"),Gra.forEach(t),l0r=r($9,` property of the config object (either
passed as an argument or loaded from `),o0e=n($9,"CODE",{});var Ora=s(o0e);i0r=r(Ora,"pretrained_model_name_or_path"),Ora.forEach(t),d0r=r($9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r0e=n($9,"CODE",{});var Vra=s(r0e);m0r=r(Vra,"pretrained_model_name_or_path"),Vra.forEach(t),c0r=r($9,":"),$9.forEach(t),f0r=i(ja),bm=n(ja,"UL",{});var Ome=s(bm);cC=n(Ome,"LI",{});var JHe=s(cC);t0e=n(JHe,"STRONG",{});var Xra=s(t0e);g0r=r(Xra,"layoutlm"),Xra.forEach(t),h0r=r(JHe," \u2014 "),tee=n(JHe,"A",{href:!0});var zra=s(tee);u0r=r(zra,"LayoutLMForQuestionAnswering"),zra.forEach(t),p0r=r(JHe," (LayoutLM model)"),JHe.forEach(t),_0r=i(Ome),fC=n(Ome,"LI",{});var YHe=s(fC);a0e=n(YHe,"STRONG",{});var Qra=s(a0e);b0r=r(Qra,"layoutlmv2"),Qra.forEach(t),v0r=r(YHe," \u2014 "),aee=n(YHe,"A",{href:!0});var Wra=s(aee);F0r=r(Wra,"LayoutLMv2ForQuestionAnswering"),Wra.forEach(t),T0r=r(YHe," (LayoutLMv2 model)"),YHe.forEach(t),M0r=i(Ome),gC=n(Ome,"LI",{});var ZHe=s(gC);n0e=n(ZHe,"STRONG",{});var Ura=s(n0e);E0r=r(Ura,"layoutlmv3"),Ura.forEach(t),C0r=r(ZHe," \u2014 "),nee=n(ZHe,"A",{href:!0});var Hra=s(nee);w0r=r(Hra,"LayoutLMv3ForQuestionAnswering"),Hra.forEach(t),A0r=r(ZHe," (LayoutLMv3 model)"),ZHe.forEach(t),Ome.forEach(t),L0r=i(ja),hC=n(ja,"P",{});var KHe=s(hC);y0r=r(KHe,"The model is set in evaluation mode by default using "),s0e=n(KHe,"CODE",{});var Jra=s(s0e);x0r=r(Jra,"model.eval()"),Jra.forEach(t),$0r=r(KHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l0e=n(KHe,"CODE",{});var Yra=s(l0e);k0r=r(Yra,"model.train()"),Yra.forEach(t),KHe.forEach(t),S0r=i(ja),T(uC.$$.fragment,ja),ja.forEach(t),Yl.forEach(t),kao=i(c),vm=n(c,"H2",{class:!0});var Jso=s(vm);pC=n(Jso,"A",{id:!0,class:!0,href:!0});var Zra=s(pC);i0e=n(Zra,"SPAN",{});var Kra=s(i0e);T(Zk.$$.fragment,Kra),Kra.forEach(t),Zra.forEach(t),R0r=i(Jso),d0e=n(Jso,"SPAN",{});var eta=s(d0e);P0r=r(eta,"AutoModelForImageClassification"),eta.forEach(t),Jso.forEach(t),Sao=i(c),Ho=n(c,"DIV",{class:!0});var Zl=s(Ho);T(Kk.$$.fragment,Zl),B0r=i(Zl),Fm=n(Zl,"P",{});var Vme=s(Fm);I0r=r(Vme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),see=n(Vme,"A",{href:!0});var ota=s(see);N0r=r(ota,"from_pretrained()"),ota.forEach(t),q0r=r(Vme," class method or the "),lee=n(Vme,"A",{href:!0});var rta=s(lee);j0r=r(rta,"from_config()"),rta.forEach(t),D0r=r(Vme,` class
method.`),Vme.forEach(t),G0r=i(Zl),eS=n(Zl,"P",{});var Yso=s(eS);O0r=r(Yso,"This class cannot be instantiated directly using "),m0e=n(Yso,"CODE",{});var tta=s(m0e);V0r=r(tta,"__init__()"),tta.forEach(t),X0r=r(Yso," (throws an error)."),Yso.forEach(t),z0r=i(Zl),Bt=n(Zl,"DIV",{class:!0});var k9=s(Bt);T(oS.$$.fragment,k9),Q0r=i(k9),c0e=n(k9,"P",{});var ata=s(c0e);W0r=r(ata,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),ata.forEach(t),U0r=i(k9),Tm=n(k9,"P",{});var Xme=s(Tm);H0r=r(Xme,`Note:
Loading a model from its configuration file does `),f0e=n(Xme,"STRONG",{});var nta=s(f0e);J0r=r(nta,"not"),nta.forEach(t),Y0r=r(Xme,` load the model weights. It only affects the
model\u2019s configuration. Use `),iee=n(Xme,"A",{href:!0});var sta=s(iee);Z0r=r(sta,"from_pretrained()"),sta.forEach(t),K0r=r(Xme," to load the model weights."),Xme.forEach(t),ewr=i(k9),T(_C.$$.fragment,k9),k9.forEach(t),owr=i(Zl),go=n(Zl,"DIV",{class:!0});var Da=s(go);T(rS.$$.fragment,Da),rwr=i(Da),g0e=n(Da,"P",{});var lta=s(g0e);twr=r(lta,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),lta.forEach(t),awr=i(Da),vn=n(Da,"P",{});var S9=s(vn);nwr=r(S9,"The model class to instantiate is selected based on the "),h0e=n(S9,"CODE",{});var ita=s(h0e);swr=r(ita,"model_type"),ita.forEach(t),lwr=r(S9,` property of the config object (either
passed as an argument or loaded from `),u0e=n(S9,"CODE",{});var dta=s(u0e);iwr=r(dta,"pretrained_model_name_or_path"),dta.forEach(t),dwr=r(S9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),p0e=n(S9,"CODE",{});var mta=s(p0e);mwr=r(mta,"pretrained_model_name_or_path"),mta.forEach(t),cwr=r(S9,":"),S9.forEach(t),fwr=i(Da),be=n(Da,"UL",{});var Fe=s(be);bC=n(Fe,"LI",{});var eJe=s(bC);_0e=n(eJe,"STRONG",{});var cta=s(_0e);gwr=r(cta,"beit"),cta.forEach(t),hwr=r(eJe," \u2014 "),dee=n(eJe,"A",{href:!0});var fta=s(dee);uwr=r(fta,"BeitForImageClassification"),fta.forEach(t),pwr=r(eJe," (BEiT model)"),eJe.forEach(t),_wr=i(Fe),vC=n(Fe,"LI",{});var oJe=s(vC);b0e=n(oJe,"STRONG",{});var gta=s(b0e);bwr=r(gta,"convnext"),gta.forEach(t),vwr=r(oJe," \u2014 "),mee=n(oJe,"A",{href:!0});var hta=s(mee);Fwr=r(hta,"ConvNextForImageClassification"),hta.forEach(t),Twr=r(oJe," (ConvNeXT model)"),oJe.forEach(t),Mwr=i(Fe),FC=n(Fe,"LI",{});var rJe=s(FC);v0e=n(rJe,"STRONG",{});var uta=s(v0e);Ewr=r(uta,"cvt"),uta.forEach(t),Cwr=r(rJe," \u2014 "),cee=n(rJe,"A",{href:!0});var pta=s(cee);wwr=r(pta,"CvtForImageClassification"),pta.forEach(t),Awr=r(rJe," (CvT model)"),rJe.forEach(t),Lwr=i(Fe),TC=n(Fe,"LI",{});var tJe=s(TC);F0e=n(tJe,"STRONG",{});var _ta=s(F0e);ywr=r(_ta,"data2vec-vision"),_ta.forEach(t),xwr=r(tJe," \u2014 "),fee=n(tJe,"A",{href:!0});var bta=s(fee);$wr=r(bta,"Data2VecVisionForImageClassification"),bta.forEach(t),kwr=r(tJe," (Data2VecVision model)"),tJe.forEach(t),Swr=i(Fe),kl=n(Fe,"LI",{});var CN=s(kl);T0e=n(CN,"STRONG",{});var vta=s(T0e);Rwr=r(vta,"deit"),vta.forEach(t),Pwr=r(CN," \u2014 "),gee=n(CN,"A",{href:!0});var Fta=s(gee);Bwr=r(Fta,"DeiTForImageClassification"),Fta.forEach(t),Iwr=r(CN," or "),hee=n(CN,"A",{href:!0});var Tta=s(hee);Nwr=r(Tta,"DeiTForImageClassificationWithTeacher"),Tta.forEach(t),qwr=r(CN," (DeiT model)"),CN.forEach(t),jwr=i(Fe),MC=n(Fe,"LI",{});var aJe=s(MC);M0e=n(aJe,"STRONG",{});var Mta=s(M0e);Dwr=r(Mta,"imagegpt"),Mta.forEach(t),Gwr=r(aJe," \u2014 "),uee=n(aJe,"A",{href:!0});var Eta=s(uee);Owr=r(Eta,"ImageGPTForImageClassification"),Eta.forEach(t),Vwr=r(aJe," (ImageGPT model)"),aJe.forEach(t),Xwr=i(Fe),Sl=n(Fe,"LI",{});var wN=s(Sl);E0e=n(wN,"STRONG",{});var Cta=s(E0e);zwr=r(Cta,"levit"),Cta.forEach(t),Qwr=r(wN," \u2014 "),pee=n(wN,"A",{href:!0});var wta=s(pee);Wwr=r(wta,"LevitForImageClassification"),wta.forEach(t),Uwr=r(wN," or "),_ee=n(wN,"A",{href:!0});var Ata=s(_ee);Hwr=r(Ata,"LevitForImageClassificationWithTeacher"),Ata.forEach(t),Jwr=r(wN," (LeViT model)"),wN.forEach(t),Ywr=i(Fe),EC=n(Fe,"LI",{});var nJe=s(EC);C0e=n(nJe,"STRONG",{});var Lta=s(C0e);Zwr=r(Lta,"mobilevit"),Lta.forEach(t),Kwr=r(nJe," \u2014 "),bee=n(nJe,"A",{href:!0});var yta=s(bee);eAr=r(yta,"MobileViTForImageClassification"),yta.forEach(t),oAr=r(nJe," (MobileViT model)"),nJe.forEach(t),rAr=i(Fe),It=n(Fe,"LI",{});var zf=s(It);w0e=n(zf,"STRONG",{});var xta=s(w0e);tAr=r(xta,"perceiver"),xta.forEach(t),aAr=r(zf," \u2014 "),vee=n(zf,"A",{href:!0});var $ta=s(vee);nAr=r($ta,"PerceiverForImageClassificationLearned"),$ta.forEach(t),sAr=r(zf," or "),Fee=n(zf,"A",{href:!0});var kta=s(Fee);lAr=r(kta,"PerceiverForImageClassificationFourier"),kta.forEach(t),iAr=r(zf," or "),Tee=n(zf,"A",{href:!0});var Sta=s(Tee);dAr=r(Sta,"PerceiverForImageClassificationConvProcessing"),Sta.forEach(t),mAr=r(zf," (Perceiver model)"),zf.forEach(t),cAr=i(Fe),CC=n(Fe,"LI",{});var sJe=s(CC);A0e=n(sJe,"STRONG",{});var Rta=s(A0e);fAr=r(Rta,"poolformer"),Rta.forEach(t),gAr=r(sJe," \u2014 "),Mee=n(sJe,"A",{href:!0});var Pta=s(Mee);hAr=r(Pta,"PoolFormerForImageClassification"),Pta.forEach(t),uAr=r(sJe," (PoolFormer model)"),sJe.forEach(t),pAr=i(Fe),wC=n(Fe,"LI",{});var lJe=s(wC);L0e=n(lJe,"STRONG",{});var Bta=s(L0e);_Ar=r(Bta,"regnet"),Bta.forEach(t),bAr=r(lJe," \u2014 "),Eee=n(lJe,"A",{href:!0});var Ita=s(Eee);vAr=r(Ita,"RegNetForImageClassification"),Ita.forEach(t),FAr=r(lJe," (RegNet model)"),lJe.forEach(t),TAr=i(Fe),AC=n(Fe,"LI",{});var iJe=s(AC);y0e=n(iJe,"STRONG",{});var Nta=s(y0e);MAr=r(Nta,"resnet"),Nta.forEach(t),EAr=r(iJe," \u2014 "),Cee=n(iJe,"A",{href:!0});var qta=s(Cee);CAr=r(qta,"ResNetForImageClassification"),qta.forEach(t),wAr=r(iJe," (ResNet model)"),iJe.forEach(t),AAr=i(Fe),LC=n(Fe,"LI",{});var dJe=s(LC);x0e=n(dJe,"STRONG",{});var jta=s(x0e);LAr=r(jta,"segformer"),jta.forEach(t),yAr=r(dJe," \u2014 "),wee=n(dJe,"A",{href:!0});var Dta=s(wee);xAr=r(Dta,"SegformerForImageClassification"),Dta.forEach(t),$Ar=r(dJe," (SegFormer model)"),dJe.forEach(t),kAr=i(Fe),yC=n(Fe,"LI",{});var mJe=s(yC);$0e=n(mJe,"STRONG",{});var Gta=s($0e);SAr=r(Gta,"swin"),Gta.forEach(t),RAr=r(mJe," \u2014 "),Aee=n(mJe,"A",{href:!0});var Ota=s(Aee);PAr=r(Ota,"SwinForImageClassification"),Ota.forEach(t),BAr=r(mJe," (Swin Transformer model)"),mJe.forEach(t),IAr=i(Fe),xC=n(Fe,"LI",{});var cJe=s(xC);k0e=n(cJe,"STRONG",{});var Vta=s(k0e);NAr=r(Vta,"swinv2"),Vta.forEach(t),qAr=r(cJe," \u2014 "),Lee=n(cJe,"A",{href:!0});var Xta=s(Lee);jAr=r(Xta,"Swinv2ForImageClassification"),Xta.forEach(t),DAr=r(cJe," (Swin Transformer V2 model)"),cJe.forEach(t),GAr=i(Fe),$C=n(Fe,"LI",{});var fJe=s($C);S0e=n(fJe,"STRONG",{});var zta=s(S0e);OAr=r(zta,"van"),zta.forEach(t),VAr=r(fJe," \u2014 "),yee=n(fJe,"A",{href:!0});var Qta=s(yee);XAr=r(Qta,"VanForImageClassification"),Qta.forEach(t),zAr=r(fJe," (VAN model)"),fJe.forEach(t),QAr=i(Fe),kC=n(Fe,"LI",{});var gJe=s(kC);R0e=n(gJe,"STRONG",{});var Wta=s(R0e);WAr=r(Wta,"vit"),Wta.forEach(t),UAr=r(gJe," \u2014 "),xee=n(gJe,"A",{href:!0});var Uta=s(xee);HAr=r(Uta,"ViTForImageClassification"),Uta.forEach(t),JAr=r(gJe," (ViT model)"),gJe.forEach(t),YAr=i(Fe),SC=n(Fe,"LI",{});var hJe=s(SC);P0e=n(hJe,"STRONG",{});var Hta=s(P0e);ZAr=r(Hta,"vit_msn"),Hta.forEach(t),KAr=r(hJe," \u2014 "),$ee=n(hJe,"A",{href:!0});var Jta=s($ee);e6r=r(Jta,"ViTMSNForImageClassification"),Jta.forEach(t),o6r=r(hJe," (ViTMSN model)"),hJe.forEach(t),Fe.forEach(t),r6r=i(Da),RC=n(Da,"P",{});var uJe=s(RC);t6r=r(uJe,"The model is set in evaluation mode by default using "),B0e=n(uJe,"CODE",{});var Yta=s(B0e);a6r=r(Yta,"model.eval()"),Yta.forEach(t),n6r=r(uJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),I0e=n(uJe,"CODE",{});var Zta=s(I0e);s6r=r(Zta,"model.train()"),Zta.forEach(t),uJe.forEach(t),l6r=i(Da),T(PC.$$.fragment,Da),Da.forEach(t),Zl.forEach(t),Rao=i(c),Mm=n(c,"H2",{class:!0});var Zso=s(Mm);BC=n(Zso,"A",{id:!0,class:!0,href:!0});var Kta=s(BC);N0e=n(Kta,"SPAN",{});var eaa=s(N0e);T(tS.$$.fragment,eaa),eaa.forEach(t),Kta.forEach(t),i6r=i(Zso),q0e=n(Zso,"SPAN",{});var oaa=s(q0e);d6r=r(oaa,"AutoModelForVideoClassification"),oaa.forEach(t),Zso.forEach(t),Pao=i(c),Jo=n(c,"DIV",{class:!0});var Kl=s(Jo);T(aS.$$.fragment,Kl),m6r=i(Kl),Em=n(Kl,"P",{});var zme=s(Em);c6r=r(zme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),kee=n(zme,"A",{href:!0});var raa=s(kee);f6r=r(raa,"from_pretrained()"),raa.forEach(t),g6r=r(zme," class method or the "),See=n(zme,"A",{href:!0});var taa=s(See);h6r=r(taa,"from_config()"),taa.forEach(t),u6r=r(zme,` class
method.`),zme.forEach(t),p6r=i(Kl),nS=n(Kl,"P",{});var Kso=s(nS);_6r=r(Kso,"This class cannot be instantiated directly using "),j0e=n(Kso,"CODE",{});var aaa=s(j0e);b6r=r(aaa,"__init__()"),aaa.forEach(t),v6r=r(Kso," (throws an error)."),Kso.forEach(t),F6r=i(Kl),Nt=n(Kl,"DIV",{class:!0});var R9=s(Nt);T(sS.$$.fragment,R9),T6r=i(R9),D0e=n(R9,"P",{});var naa=s(D0e);M6r=r(naa,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),naa.forEach(t),E6r=i(R9),Cm=n(R9,"P",{});var Qme=s(Cm);C6r=r(Qme,`Note:
Loading a model from its configuration file does `),G0e=n(Qme,"STRONG",{});var saa=s(G0e);w6r=r(saa,"not"),saa.forEach(t),A6r=r(Qme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ree=n(Qme,"A",{href:!0});var laa=s(Ree);L6r=r(laa,"from_pretrained()"),laa.forEach(t),y6r=r(Qme," to load the model weights."),Qme.forEach(t),x6r=i(R9),T(IC.$$.fragment,R9),R9.forEach(t),$6r=i(Kl),ho=n(Kl,"DIV",{class:!0});var Ga=s(ho);T(lS.$$.fragment,Ga),k6r=i(Ga),O0e=n(Ga,"P",{});var iaa=s(O0e);S6r=r(iaa,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),iaa.forEach(t),R6r=i(Ga),Fn=n(Ga,"P",{});var P9=s(Fn);P6r=r(P9,"The model class to instantiate is selected based on the "),V0e=n(P9,"CODE",{});var daa=s(V0e);B6r=r(daa,"model_type"),daa.forEach(t),I6r=r(P9,` property of the config object (either
passed as an argument or loaded from `),X0e=n(P9,"CODE",{});var maa=s(X0e);N6r=r(maa,"pretrained_model_name_or_path"),maa.forEach(t),q6r=r(P9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z0e=n(P9,"CODE",{});var caa=s(z0e);j6r=r(caa,"pretrained_model_name_or_path"),caa.forEach(t),D6r=r(P9,":"),P9.forEach(t),G6r=i(Ga),Q0e=n(Ga,"UL",{});var faa=s(Q0e);NC=n(faa,"LI",{});var pJe=s(NC);W0e=n(pJe,"STRONG",{});var gaa=s(W0e);O6r=r(gaa,"videomae"),gaa.forEach(t),V6r=r(pJe," \u2014 "),Pee=n(pJe,"A",{href:!0});var haa=s(Pee);X6r=r(haa,"VideoMAEForVideoClassification"),haa.forEach(t),z6r=r(pJe," (VideoMAE model)"),pJe.forEach(t),faa.forEach(t),Q6r=i(Ga),qC=n(Ga,"P",{});var _Je=s(qC);W6r=r(_Je,"The model is set in evaluation mode by default using "),U0e=n(_Je,"CODE",{});var uaa=s(U0e);U6r=r(uaa,"model.eval()"),uaa.forEach(t),H6r=r(_Je,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),H0e=n(_Je,"CODE",{});var paa=s(H0e);J6r=r(paa,"model.train()"),paa.forEach(t),_Je.forEach(t),Y6r=i(Ga),T(jC.$$.fragment,Ga),Ga.forEach(t),Kl.forEach(t),Bao=i(c),wm=n(c,"H2",{class:!0});var elo=s(wm);DC=n(elo,"A",{id:!0,class:!0,href:!0});var _aa=s(DC);J0e=n(_aa,"SPAN",{});var baa=s(J0e);T(iS.$$.fragment,baa),baa.forEach(t),_aa.forEach(t),Z6r=i(elo),Y0e=n(elo,"SPAN",{});var vaa=s(Y0e);K6r=r(vaa,"AutoModelForVision2Seq"),vaa.forEach(t),elo.forEach(t),Iao=i(c),Yo=n(c,"DIV",{class:!0});var ei=s(Yo);T(dS.$$.fragment,ei),e7r=i(ei),Am=n(ei,"P",{});var Wme=s(Am);o7r=r(Wme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Bee=n(Wme,"A",{href:!0});var Faa=s(Bee);r7r=r(Faa,"from_pretrained()"),Faa.forEach(t),t7r=r(Wme," class method or the "),Iee=n(Wme,"A",{href:!0});var Taa=s(Iee);a7r=r(Taa,"from_config()"),Taa.forEach(t),n7r=r(Wme,` class
method.`),Wme.forEach(t),s7r=i(ei),mS=n(ei,"P",{});var olo=s(mS);l7r=r(olo,"This class cannot be instantiated directly using "),Z0e=n(olo,"CODE",{});var Maa=s(Z0e);i7r=r(Maa,"__init__()"),Maa.forEach(t),d7r=r(olo," (throws an error)."),olo.forEach(t),m7r=i(ei),qt=n(ei,"DIV",{class:!0});var B9=s(qt);T(cS.$$.fragment,B9),c7r=i(B9),K0e=n(B9,"P",{});var Eaa=s(K0e);f7r=r(Eaa,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Eaa.forEach(t),g7r=i(B9),Lm=n(B9,"P",{});var Ume=s(Lm);h7r=r(Ume,`Note:
Loading a model from its configuration file does `),ewe=n(Ume,"STRONG",{});var Caa=s(ewe);u7r=r(Caa,"not"),Caa.forEach(t),p7r=r(Ume,` load the model weights. It only affects the
model\u2019s configuration. Use `),Nee=n(Ume,"A",{href:!0});var waa=s(Nee);_7r=r(waa,"from_pretrained()"),waa.forEach(t),b7r=r(Ume," to load the model weights."),Ume.forEach(t),v7r=i(B9),T(GC.$$.fragment,B9),B9.forEach(t),F7r=i(ei),uo=n(ei,"DIV",{class:!0});var Oa=s(uo);T(fS.$$.fragment,Oa),T7r=i(Oa),owe=n(Oa,"P",{});var Aaa=s(owe);M7r=r(Aaa,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Aaa.forEach(t),E7r=i(Oa),Tn=n(Oa,"P",{});var I9=s(Tn);C7r=r(I9,"The model class to instantiate is selected based on the "),rwe=n(I9,"CODE",{});var Laa=s(rwe);w7r=r(Laa,"model_type"),Laa.forEach(t),A7r=r(I9,` property of the config object (either
passed as an argument or loaded from `),twe=n(I9,"CODE",{});var yaa=s(twe);L7r=r(yaa,"pretrained_model_name_or_path"),yaa.forEach(t),y7r=r(I9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),awe=n(I9,"CODE",{});var xaa=s(awe);x7r=r(xaa,"pretrained_model_name_or_path"),xaa.forEach(t),$7r=r(I9,":"),I9.forEach(t),k7r=i(Oa),nwe=n(Oa,"UL",{});var $aa=s(nwe);OC=n($aa,"LI",{});var bJe=s(OC);swe=n(bJe,"STRONG",{});var kaa=s(swe);S7r=r(kaa,"vision-encoder-decoder"),kaa.forEach(t),R7r=r(bJe," \u2014 "),qee=n(bJe,"A",{href:!0});var Saa=s(qee);P7r=r(Saa,"VisionEncoderDecoderModel"),Saa.forEach(t),B7r=r(bJe," (Vision Encoder decoder model)"),bJe.forEach(t),$aa.forEach(t),I7r=i(Oa),VC=n(Oa,"P",{});var vJe=s(VC);N7r=r(vJe,"The model is set in evaluation mode by default using "),lwe=n(vJe,"CODE",{});var Raa=s(lwe);q7r=r(Raa,"model.eval()"),Raa.forEach(t),j7r=r(vJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),iwe=n(vJe,"CODE",{});var Paa=s(iwe);D7r=r(Paa,"model.train()"),Paa.forEach(t),vJe.forEach(t),G7r=i(Oa),T(XC.$$.fragment,Oa),Oa.forEach(t),ei.forEach(t),Nao=i(c),ym=n(c,"H2",{class:!0});var rlo=s(ym);zC=n(rlo,"A",{id:!0,class:!0,href:!0});var Baa=s(zC);dwe=n(Baa,"SPAN",{});var Iaa=s(dwe);T(gS.$$.fragment,Iaa),Iaa.forEach(t),Baa.forEach(t),O7r=i(rlo),mwe=n(rlo,"SPAN",{});var Naa=s(mwe);V7r=r(Naa,"AutoModelForVisualQuestionAnswering"),Naa.forEach(t),rlo.forEach(t),qao=i(c),Zo=n(c,"DIV",{class:!0});var oi=s(Zo);T(hS.$$.fragment,oi),X7r=i(oi),xm=n(oi,"P",{});var Hme=s(xm);z7r=r(Hme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),jee=n(Hme,"A",{href:!0});var qaa=s(jee);Q7r=r(qaa,"from_pretrained()"),qaa.forEach(t),W7r=r(Hme," class method or the "),Dee=n(Hme,"A",{href:!0});var jaa=s(Dee);U7r=r(jaa,"from_config()"),jaa.forEach(t),H7r=r(Hme,` class
method.`),Hme.forEach(t),J7r=i(oi),uS=n(oi,"P",{});var tlo=s(uS);Y7r=r(tlo,"This class cannot be instantiated directly using "),cwe=n(tlo,"CODE",{});var Daa=s(cwe);Z7r=r(Daa,"__init__()"),Daa.forEach(t),K7r=r(tlo," (throws an error)."),tlo.forEach(t),e8r=i(oi),jt=n(oi,"DIV",{class:!0});var N9=s(jt);T(pS.$$.fragment,N9),o8r=i(N9),fwe=n(N9,"P",{});var Gaa=s(fwe);r8r=r(Gaa,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Gaa.forEach(t),t8r=i(N9),$m=n(N9,"P",{});var Jme=s($m);a8r=r(Jme,`Note:
Loading a model from its configuration file does `),gwe=n(Jme,"STRONG",{});var Oaa=s(gwe);n8r=r(Oaa,"not"),Oaa.forEach(t),s8r=r(Jme,` load the model weights. It only affects the
model\u2019s configuration. Use `),Gee=n(Jme,"A",{href:!0});var Vaa=s(Gee);l8r=r(Vaa,"from_pretrained()"),Vaa.forEach(t),i8r=r(Jme," to load the model weights."),Jme.forEach(t),d8r=i(N9),T(QC.$$.fragment,N9),N9.forEach(t),m8r=i(oi),po=n(oi,"DIV",{class:!0});var Va=s(po);T(_S.$$.fragment,Va),c8r=i(Va),hwe=n(Va,"P",{});var Xaa=s(hwe);f8r=r(Xaa,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),Xaa.forEach(t),g8r=i(Va),Mn=n(Va,"P",{});var q9=s(Mn);h8r=r(q9,"The model class to instantiate is selected based on the "),uwe=n(q9,"CODE",{});var zaa=s(uwe);u8r=r(zaa,"model_type"),zaa.forEach(t),p8r=r(q9,` property of the config object (either
passed as an argument or loaded from `),pwe=n(q9,"CODE",{});var Qaa=s(pwe);_8r=r(Qaa,"pretrained_model_name_or_path"),Qaa.forEach(t),b8r=r(q9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_we=n(q9,"CODE",{});var Waa=s(_we);v8r=r(Waa,"pretrained_model_name_or_path"),Waa.forEach(t),F8r=r(q9,":"),q9.forEach(t),T8r=i(Va),bwe=n(Va,"UL",{});var Uaa=s(bwe);WC=n(Uaa,"LI",{});var FJe=s(WC);vwe=n(FJe,"STRONG",{});var Haa=s(vwe);M8r=r(Haa,"vilt"),Haa.forEach(t),E8r=r(FJe," \u2014 "),Oee=n(FJe,"A",{href:!0});var Jaa=s(Oee);C8r=r(Jaa,"ViltForQuestionAnswering"),Jaa.forEach(t),w8r=r(FJe," (ViLT model)"),FJe.forEach(t),Uaa.forEach(t),A8r=i(Va),UC=n(Va,"P",{});var TJe=s(UC);L8r=r(TJe,"The model is set in evaluation mode by default using "),Fwe=n(TJe,"CODE",{});var Yaa=s(Fwe);y8r=r(Yaa,"model.eval()"),Yaa.forEach(t),x8r=r(TJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Twe=n(TJe,"CODE",{});var Zaa=s(Twe);$8r=r(Zaa,"model.train()"),Zaa.forEach(t),TJe.forEach(t),k8r=i(Va),T(HC.$$.fragment,Va),Va.forEach(t),oi.forEach(t),jao=i(c),km=n(c,"H2",{class:!0});var alo=s(km);JC=n(alo,"A",{id:!0,class:!0,href:!0});var Kaa=s(JC);Mwe=n(Kaa,"SPAN",{});var ena=s(Mwe);T(bS.$$.fragment,ena),ena.forEach(t),Kaa.forEach(t),S8r=i(alo),Ewe=n(alo,"SPAN",{});var ona=s(Ewe);R8r=r(ona,"AutoModelForAudioClassification"),ona.forEach(t),alo.forEach(t),Dao=i(c),Ko=n(c,"DIV",{class:!0});var ri=s(Ko);T(vS.$$.fragment,ri),P8r=i(ri),Sm=n(ri,"P",{});var Yme=s(Sm);B8r=r(Yme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),Vee=n(Yme,"A",{href:!0});var rna=s(Vee);I8r=r(rna,"from_pretrained()"),rna.forEach(t),N8r=r(Yme," class method or the "),Xee=n(Yme,"A",{href:!0});var tna=s(Xee);q8r=r(tna,"from_config()"),tna.forEach(t),j8r=r(Yme,` class
method.`),Yme.forEach(t),D8r=i(ri),FS=n(ri,"P",{});var nlo=s(FS);G8r=r(nlo,"This class cannot be instantiated directly using "),Cwe=n(nlo,"CODE",{});var ana=s(Cwe);O8r=r(ana,"__init__()"),ana.forEach(t),V8r=r(nlo," (throws an error)."),nlo.forEach(t),X8r=i(ri),Dt=n(ri,"DIV",{class:!0});var j9=s(Dt);T(TS.$$.fragment,j9),z8r=i(j9),wwe=n(j9,"P",{});var nna=s(wwe);Q8r=r(nna,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),nna.forEach(t),W8r=i(j9),Rm=n(j9,"P",{});var Zme=s(Rm);U8r=r(Zme,`Note:
Loading a model from its configuration file does `),Awe=n(Zme,"STRONG",{});var sna=s(Awe);H8r=r(sna,"not"),sna.forEach(t),J8r=r(Zme,` load the model weights. It only affects the
model\u2019s configuration. Use `),zee=n(Zme,"A",{href:!0});var lna=s(zee);Y8r=r(lna,"from_pretrained()"),lna.forEach(t),Z8r=r(Zme," to load the model weights."),Zme.forEach(t),K8r=i(j9),T(YC.$$.fragment,j9),j9.forEach(t),eLr=i(ri),_o=n(ri,"DIV",{class:!0});var Xa=s(_o);T(MS.$$.fragment,Xa),oLr=i(Xa),Lwe=n(Xa,"P",{});var ina=s(Lwe);rLr=r(ina,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),ina.forEach(t),tLr=i(Xa),En=n(Xa,"P",{});var D9=s(En);aLr=r(D9,"The model class to instantiate is selected based on the "),ywe=n(D9,"CODE",{});var dna=s(ywe);nLr=r(dna,"model_type"),dna.forEach(t),sLr=r(D9,` property of the config object (either
passed as an argument or loaded from `),xwe=n(D9,"CODE",{});var mna=s(xwe);lLr=r(mna,"pretrained_model_name_or_path"),mna.forEach(t),iLr=r(D9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$we=n(D9,"CODE",{});var cna=s($we);dLr=r(cna,"pretrained_model_name_or_path"),cna.forEach(t),mLr=r(D9,":"),D9.forEach(t),cLr=i(Xa),Be=n(Xa,"UL",{});var We=s(Be);ZC=n(We,"LI",{});var MJe=s(ZC);kwe=n(MJe,"STRONG",{});var fna=s(kwe);fLr=r(fna,"data2vec-audio"),fna.forEach(t),gLr=r(MJe," \u2014 "),Qee=n(MJe,"A",{href:!0});var gna=s(Qee);hLr=r(gna,"Data2VecAudioForSequenceClassification"),gna.forEach(t),uLr=r(MJe," (Data2VecAudio model)"),MJe.forEach(t),pLr=i(We),KC=n(We,"LI",{});var EJe=s(KC);Swe=n(EJe,"STRONG",{});var hna=s(Swe);_Lr=r(hna,"hubert"),hna.forEach(t),bLr=r(EJe," \u2014 "),Wee=n(EJe,"A",{href:!0});var una=s(Wee);vLr=r(una,"HubertForSequenceClassification"),una.forEach(t),FLr=r(EJe," (Hubert model)"),EJe.forEach(t),TLr=i(We),e3=n(We,"LI",{});var CJe=s(e3);Rwe=n(CJe,"STRONG",{});var pna=s(Rwe);MLr=r(pna,"sew"),pna.forEach(t),ELr=r(CJe," \u2014 "),Uee=n(CJe,"A",{href:!0});var _na=s(Uee);CLr=r(_na,"SEWForSequenceClassification"),_na.forEach(t),wLr=r(CJe," (SEW model)"),CJe.forEach(t),ALr=i(We),o3=n(We,"LI",{});var wJe=s(o3);Pwe=n(wJe,"STRONG",{});var bna=s(Pwe);LLr=r(bna,"sew-d"),bna.forEach(t),yLr=r(wJe," \u2014 "),Hee=n(wJe,"A",{href:!0});var vna=s(Hee);xLr=r(vna,"SEWDForSequenceClassification"),vna.forEach(t),$Lr=r(wJe," (SEW-D model)"),wJe.forEach(t),kLr=i(We),r3=n(We,"LI",{});var AJe=s(r3);Bwe=n(AJe,"STRONG",{});var Fna=s(Bwe);SLr=r(Fna,"unispeech"),Fna.forEach(t),RLr=r(AJe," \u2014 "),Jee=n(AJe,"A",{href:!0});var Tna=s(Jee);PLr=r(Tna,"UniSpeechForSequenceClassification"),Tna.forEach(t),BLr=r(AJe," (UniSpeech model)"),AJe.forEach(t),ILr=i(We),t3=n(We,"LI",{});var LJe=s(t3);Iwe=n(LJe,"STRONG",{});var Mna=s(Iwe);NLr=r(Mna,"unispeech-sat"),Mna.forEach(t),qLr=r(LJe," \u2014 "),Yee=n(LJe,"A",{href:!0});var Ena=s(Yee);jLr=r(Ena,"UniSpeechSatForSequenceClassification"),Ena.forEach(t),DLr=r(LJe," (UniSpeechSat model)"),LJe.forEach(t),GLr=i(We),a3=n(We,"LI",{});var yJe=s(a3);Nwe=n(yJe,"STRONG",{});var Cna=s(Nwe);OLr=r(Cna,"wav2vec2"),Cna.forEach(t),VLr=r(yJe," \u2014 "),Zee=n(yJe,"A",{href:!0});var wna=s(Zee);XLr=r(wna,"Wav2Vec2ForSequenceClassification"),wna.forEach(t),zLr=r(yJe," (Wav2Vec2 model)"),yJe.forEach(t),QLr=i(We),n3=n(We,"LI",{});var xJe=s(n3);qwe=n(xJe,"STRONG",{});var Ana=s(qwe);WLr=r(Ana,"wav2vec2-conformer"),Ana.forEach(t),ULr=r(xJe," \u2014 "),Kee=n(xJe,"A",{href:!0});var Lna=s(Kee);HLr=r(Lna,"Wav2Vec2ConformerForSequenceClassification"),Lna.forEach(t),JLr=r(xJe," (Wav2Vec2-Conformer model)"),xJe.forEach(t),YLr=i(We),s3=n(We,"LI",{});var $Je=s(s3);jwe=n($Je,"STRONG",{});var yna=s(jwe);ZLr=r(yna,"wavlm"),yna.forEach(t),KLr=r($Je," \u2014 "),eoe=n($Je,"A",{href:!0});var xna=s(eoe);eyr=r(xna,"WavLMForSequenceClassification"),xna.forEach(t),oyr=r($Je," (WavLM model)"),$Je.forEach(t),We.forEach(t),ryr=i(Xa),l3=n(Xa,"P",{});var kJe=s(l3);tyr=r(kJe,"The model is set in evaluation mode by default using "),Dwe=n(kJe,"CODE",{});var $na=s(Dwe);ayr=r($na,"model.eval()"),$na.forEach(t),nyr=r(kJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gwe=n(kJe,"CODE",{});var kna=s(Gwe);syr=r(kna,"model.train()"),kna.forEach(t),kJe.forEach(t),lyr=i(Xa),T(i3.$$.fragment,Xa),Xa.forEach(t),ri.forEach(t),Gao=i(c),Pm=n(c,"H2",{class:!0});var slo=s(Pm);d3=n(slo,"A",{id:!0,class:!0,href:!0});var Sna=s(d3);Owe=n(Sna,"SPAN",{});var Rna=s(Owe);T(ES.$$.fragment,Rna),Rna.forEach(t),Sna.forEach(t),iyr=i(slo),Vwe=n(slo,"SPAN",{});var Pna=s(Vwe);dyr=r(Pna,"AutoModelForAudioFrameClassification"),Pna.forEach(t),slo.forEach(t),Oao=i(c),er=n(c,"DIV",{class:!0});var ti=s(er);T(CS.$$.fragment,ti),myr=i(ti),Bm=n(ti,"P",{});var Kme=s(Bm);cyr=r(Kme,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),ooe=n(Kme,"A",{href:!0});var Bna=s(ooe);fyr=r(Bna,"from_pretrained()"),Bna.forEach(t),gyr=r(Kme," class method or the "),roe=n(Kme,"A",{href:!0});var Ina=s(roe);hyr=r(Ina,"from_config()"),Ina.forEach(t),uyr=r(Kme,` class
method.`),Kme.forEach(t),pyr=i(ti),wS=n(ti,"P",{});var llo=s(wS);_yr=r(llo,"This class cannot be instantiated directly using "),Xwe=n(llo,"CODE",{});var Nna=s(Xwe);byr=r(Nna,"__init__()"),Nna.forEach(t),vyr=r(llo," (throws an error)."),llo.forEach(t),Fyr=i(ti),Gt=n(ti,"DIV",{class:!0});var G9=s(Gt);T(AS.$$.fragment,G9),Tyr=i(G9),zwe=n(G9,"P",{});var qna=s(zwe);Myr=r(qna,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),qna.forEach(t),Eyr=i(G9),Im=n(G9,"P",{});var ece=s(Im);Cyr=r(ece,`Note:
Loading a model from its configuration file does `),Qwe=n(ece,"STRONG",{});var jna=s(Qwe);wyr=r(jna,"not"),jna.forEach(t),Ayr=r(ece,` load the model weights. It only affects the
model\u2019s configuration. Use `),toe=n(ece,"A",{href:!0});var Dna=s(toe);Lyr=r(Dna,"from_pretrained()"),Dna.forEach(t),yyr=r(ece," to load the model weights."),ece.forEach(t),xyr=i(G9),T(m3.$$.fragment,G9),G9.forEach(t),$yr=i(ti),bo=n(ti,"DIV",{class:!0});var za=s(bo);T(LS.$$.fragment,za),kyr=i(za),Wwe=n(za,"P",{});var Gna=s(Wwe);Syr=r(Gna,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Gna.forEach(t),Ryr=i(za),Cn=n(za,"P",{});var O9=s(Cn);Pyr=r(O9,"The model class to instantiate is selected based on the "),Uwe=n(O9,"CODE",{});var Ona=s(Uwe);Byr=r(Ona,"model_type"),Ona.forEach(t),Iyr=r(O9,` property of the config object (either
passed as an argument or loaded from `),Hwe=n(O9,"CODE",{});var Vna=s(Hwe);Nyr=r(Vna,"pretrained_model_name_or_path"),Vna.forEach(t),qyr=r(O9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jwe=n(O9,"CODE",{});var Xna=s(Jwe);jyr=r(Xna,"pretrained_model_name_or_path"),Xna.forEach(t),Dyr=r(O9,":"),O9.forEach(t),Gyr=i(za),ut=n(za,"UL",{});var ai=s(ut);c3=n(ai,"LI",{});var SJe=s(c3);Ywe=n(SJe,"STRONG",{});var zna=s(Ywe);Oyr=r(zna,"data2vec-audio"),zna.forEach(t),Vyr=r(SJe," \u2014 "),aoe=n(SJe,"A",{href:!0});var Qna=s(aoe);Xyr=r(Qna,"Data2VecAudioForAudioFrameClassification"),Qna.forEach(t),zyr=r(SJe," (Data2VecAudio model)"),SJe.forEach(t),Qyr=i(ai),f3=n(ai,"LI",{});var RJe=s(f3);Zwe=n(RJe,"STRONG",{});var Wna=s(Zwe);Wyr=r(Wna,"unispeech-sat"),Wna.forEach(t),Uyr=r(RJe," \u2014 "),noe=n(RJe,"A",{href:!0});var Una=s(noe);Hyr=r(Una,"UniSpeechSatForAudioFrameClassification"),Una.forEach(t),Jyr=r(RJe," (UniSpeechSat model)"),RJe.forEach(t),Yyr=i(ai),g3=n(ai,"LI",{});var PJe=s(g3);Kwe=n(PJe,"STRONG",{});var Hna=s(Kwe);Zyr=r(Hna,"wav2vec2"),Hna.forEach(t),Kyr=r(PJe," \u2014 "),soe=n(PJe,"A",{href:!0});var Jna=s(soe);e9r=r(Jna,"Wav2Vec2ForAudioFrameClassification"),Jna.forEach(t),o9r=r(PJe," (Wav2Vec2 model)"),PJe.forEach(t),r9r=i(ai),h3=n(ai,"LI",{});var BJe=s(h3);eAe=n(BJe,"STRONG",{});var Yna=s(eAe);t9r=r(Yna,"wav2vec2-conformer"),Yna.forEach(t),a9r=r(BJe," \u2014 "),loe=n(BJe,"A",{href:!0});var Zna=s(loe);n9r=r(Zna,"Wav2Vec2ConformerForAudioFrameClassification"),Zna.forEach(t),s9r=r(BJe," (Wav2Vec2-Conformer model)"),BJe.forEach(t),l9r=i(ai),u3=n(ai,"LI",{});var IJe=s(u3);oAe=n(IJe,"STRONG",{});var Kna=s(oAe);i9r=r(Kna,"wavlm"),Kna.forEach(t),d9r=r(IJe," \u2014 "),ioe=n(IJe,"A",{href:!0});var esa=s(ioe);m9r=r(esa,"WavLMForAudioFrameClassification"),esa.forEach(t),c9r=r(IJe," (WavLM model)"),IJe.forEach(t),ai.forEach(t),f9r=i(za),p3=n(za,"P",{});var NJe=s(p3);g9r=r(NJe,"The model is set in evaluation mode by default using "),rAe=n(NJe,"CODE",{});var osa=s(rAe);h9r=r(osa,"model.eval()"),osa.forEach(t),u9r=r(NJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),tAe=n(NJe,"CODE",{});var rsa=s(tAe);p9r=r(rsa,"model.train()"),rsa.forEach(t),NJe.forEach(t),_9r=i(za),T(_3.$$.fragment,za),za.forEach(t),ti.forEach(t),Vao=i(c),Nm=n(c,"H2",{class:!0});var ilo=s(Nm);b3=n(ilo,"A",{id:!0,class:!0,href:!0});var tsa=s(b3);aAe=n(tsa,"SPAN",{});var asa=s(aAe);T(yS.$$.fragment,asa),asa.forEach(t),tsa.forEach(t),b9r=i(ilo),nAe=n(ilo,"SPAN",{});var nsa=s(nAe);v9r=r(nsa,"AutoModelForCTC"),nsa.forEach(t),ilo.forEach(t),Xao=i(c),or=n(c,"DIV",{class:!0});var ni=s(or);T(xS.$$.fragment,ni),F9r=i(ni),qm=n(ni,"P",{});var oce=s(qm);T9r=r(oce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),doe=n(oce,"A",{href:!0});var ssa=s(doe);M9r=r(ssa,"from_pretrained()"),ssa.forEach(t),E9r=r(oce," class method or the "),moe=n(oce,"A",{href:!0});var lsa=s(moe);C9r=r(lsa,"from_config()"),lsa.forEach(t),w9r=r(oce,` class
method.`),oce.forEach(t),A9r=i(ni),$S=n(ni,"P",{});var dlo=s($S);L9r=r(dlo,"This class cannot be instantiated directly using "),sAe=n(dlo,"CODE",{});var isa=s(sAe);y9r=r(isa,"__init__()"),isa.forEach(t),x9r=r(dlo," (throws an error)."),dlo.forEach(t),$9r=i(ni),Ot=n(ni,"DIV",{class:!0});var V9=s(Ot);T(kS.$$.fragment,V9),k9r=i(V9),lAe=n(V9,"P",{});var dsa=s(lAe);S9r=r(dsa,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),dsa.forEach(t),R9r=i(V9),jm=n(V9,"P",{});var rce=s(jm);P9r=r(rce,`Note:
Loading a model from its configuration file does `),iAe=n(rce,"STRONG",{});var msa=s(iAe);B9r=r(msa,"not"),msa.forEach(t),I9r=r(rce,` load the model weights. It only affects the
model\u2019s configuration. Use `),coe=n(rce,"A",{href:!0});var csa=s(coe);N9r=r(csa,"from_pretrained()"),csa.forEach(t),q9r=r(rce," to load the model weights."),rce.forEach(t),j9r=i(V9),T(v3.$$.fragment,V9),V9.forEach(t),D9r=i(ni),vo=n(ni,"DIV",{class:!0});var Qa=s(vo);T(SS.$$.fragment,Qa),G9r=i(Qa),dAe=n(Qa,"P",{});var fsa=s(dAe);O9r=r(fsa,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),fsa.forEach(t),V9r=i(Qa),wn=n(Qa,"P",{});var X9=s(wn);X9r=r(X9,"The model class to instantiate is selected based on the "),mAe=n(X9,"CODE",{});var gsa=s(mAe);z9r=r(gsa,"model_type"),gsa.forEach(t),Q9r=r(X9,` property of the config object (either
passed as an argument or loaded from `),cAe=n(X9,"CODE",{});var hsa=s(cAe);W9r=r(hsa,"pretrained_model_name_or_path"),hsa.forEach(t),U9r=r(X9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fAe=n(X9,"CODE",{});var usa=s(fAe);H9r=r(usa,"pretrained_model_name_or_path"),usa.forEach(t),J9r=r(X9,":"),X9.forEach(t),Y9r=i(Qa),Le=n(Qa,"UL",{});var Ie=s(Le);F3=n(Ie,"LI",{});var qJe=s(F3);gAe=n(qJe,"STRONG",{});var psa=s(gAe);Z9r=r(psa,"data2vec-audio"),psa.forEach(t),K9r=r(qJe," \u2014 "),foe=n(qJe,"A",{href:!0});var _sa=s(foe);exr=r(_sa,"Data2VecAudioForCTC"),_sa.forEach(t),oxr=r(qJe," (Data2VecAudio model)"),qJe.forEach(t),rxr=i(Ie),T3=n(Ie,"LI",{});var jJe=s(T3);hAe=n(jJe,"STRONG",{});var bsa=s(hAe);txr=r(bsa,"hubert"),bsa.forEach(t),axr=r(jJe," \u2014 "),goe=n(jJe,"A",{href:!0});var vsa=s(goe);nxr=r(vsa,"HubertForCTC"),vsa.forEach(t),sxr=r(jJe," (Hubert model)"),jJe.forEach(t),lxr=i(Ie),M3=n(Ie,"LI",{});var DJe=s(M3);uAe=n(DJe,"STRONG",{});var Fsa=s(uAe);ixr=r(Fsa,"mctct"),Fsa.forEach(t),dxr=r(DJe," \u2014 "),hoe=n(DJe,"A",{href:!0});var Tsa=s(hoe);mxr=r(Tsa,"MCTCTForCTC"),Tsa.forEach(t),cxr=r(DJe," (M-CTC-T model)"),DJe.forEach(t),fxr=i(Ie),E3=n(Ie,"LI",{});var GJe=s(E3);pAe=n(GJe,"STRONG",{});var Msa=s(pAe);gxr=r(Msa,"sew"),Msa.forEach(t),hxr=r(GJe," \u2014 "),uoe=n(GJe,"A",{href:!0});var Esa=s(uoe);uxr=r(Esa,"SEWForCTC"),Esa.forEach(t),pxr=r(GJe," (SEW model)"),GJe.forEach(t),_xr=i(Ie),C3=n(Ie,"LI",{});var OJe=s(C3);_Ae=n(OJe,"STRONG",{});var Csa=s(_Ae);bxr=r(Csa,"sew-d"),Csa.forEach(t),vxr=r(OJe," \u2014 "),poe=n(OJe,"A",{href:!0});var wsa=s(poe);Fxr=r(wsa,"SEWDForCTC"),wsa.forEach(t),Txr=r(OJe," (SEW-D model)"),OJe.forEach(t),Mxr=i(Ie),w3=n(Ie,"LI",{});var VJe=s(w3);bAe=n(VJe,"STRONG",{});var Asa=s(bAe);Exr=r(Asa,"unispeech"),Asa.forEach(t),Cxr=r(VJe," \u2014 "),_oe=n(VJe,"A",{href:!0});var Lsa=s(_oe);wxr=r(Lsa,"UniSpeechForCTC"),Lsa.forEach(t),Axr=r(VJe," (UniSpeech model)"),VJe.forEach(t),Lxr=i(Ie),A3=n(Ie,"LI",{});var XJe=s(A3);vAe=n(XJe,"STRONG",{});var ysa=s(vAe);yxr=r(ysa,"unispeech-sat"),ysa.forEach(t),xxr=r(XJe," \u2014 "),boe=n(XJe,"A",{href:!0});var xsa=s(boe);$xr=r(xsa,"UniSpeechSatForCTC"),xsa.forEach(t),kxr=r(XJe," (UniSpeechSat model)"),XJe.forEach(t),Sxr=i(Ie),L3=n(Ie,"LI",{});var zJe=s(L3);FAe=n(zJe,"STRONG",{});var $sa=s(FAe);Rxr=r($sa,"wav2vec2"),$sa.forEach(t),Pxr=r(zJe," \u2014 "),voe=n(zJe,"A",{href:!0});var ksa=s(voe);Bxr=r(ksa,"Wav2Vec2ForCTC"),ksa.forEach(t),Ixr=r(zJe," (Wav2Vec2 model)"),zJe.forEach(t),Nxr=i(Ie),y3=n(Ie,"LI",{});var QJe=s(y3);TAe=n(QJe,"STRONG",{});var Ssa=s(TAe);qxr=r(Ssa,"wav2vec2-conformer"),Ssa.forEach(t),jxr=r(QJe," \u2014 "),Foe=n(QJe,"A",{href:!0});var Rsa=s(Foe);Dxr=r(Rsa,"Wav2Vec2ConformerForCTC"),Rsa.forEach(t),Gxr=r(QJe," (Wav2Vec2-Conformer model)"),QJe.forEach(t),Oxr=i(Ie),x3=n(Ie,"LI",{});var WJe=s(x3);MAe=n(WJe,"STRONG",{});var Psa=s(MAe);Vxr=r(Psa,"wavlm"),Psa.forEach(t),Xxr=r(WJe," \u2014 "),Toe=n(WJe,"A",{href:!0});var Bsa=s(Toe);zxr=r(Bsa,"WavLMForCTC"),Bsa.forEach(t),Qxr=r(WJe," (WavLM model)"),WJe.forEach(t),Ie.forEach(t),Wxr=i(Qa),$3=n(Qa,"P",{});var UJe=s($3);Uxr=r(UJe,"The model is set in evaluation mode by default using "),EAe=n(UJe,"CODE",{});var Isa=s(EAe);Hxr=r(Isa,"model.eval()"),Isa.forEach(t),Jxr=r(UJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),CAe=n(UJe,"CODE",{});var Nsa=s(CAe);Yxr=r(Nsa,"model.train()"),Nsa.forEach(t),UJe.forEach(t),Zxr=i(Qa),T(k3.$$.fragment,Qa),Qa.forEach(t),ni.forEach(t),zao=i(c),Dm=n(c,"H2",{class:!0});var mlo=s(Dm);S3=n(mlo,"A",{id:!0,class:!0,href:!0});var qsa=s(S3);wAe=n(qsa,"SPAN",{});var jsa=s(wAe);T(RS.$$.fragment,jsa),jsa.forEach(t),qsa.forEach(t),Kxr=i(mlo),AAe=n(mlo,"SPAN",{});var Dsa=s(AAe);e$r=r(Dsa,"AutoModelForSpeechSeq2Seq"),Dsa.forEach(t),mlo.forEach(t),Qao=i(c),rr=n(c,"DIV",{class:!0});var si=s(rr);T(PS.$$.fragment,si),o$r=i(si),Gm=n(si,"P",{});var tce=s(Gm);r$r=r(tce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Moe=n(tce,"A",{href:!0});var Gsa=s(Moe);t$r=r(Gsa,"from_pretrained()"),Gsa.forEach(t),a$r=r(tce," class method or the "),Eoe=n(tce,"A",{href:!0});var Osa=s(Eoe);n$r=r(Osa,"from_config()"),Osa.forEach(t),s$r=r(tce,` class
method.`),tce.forEach(t),l$r=i(si),BS=n(si,"P",{});var clo=s(BS);i$r=r(clo,"This class cannot be instantiated directly using "),LAe=n(clo,"CODE",{});var Vsa=s(LAe);d$r=r(Vsa,"__init__()"),Vsa.forEach(t),m$r=r(clo," (throws an error)."),clo.forEach(t),c$r=i(si),Vt=n(si,"DIV",{class:!0});var z9=s(Vt);T(IS.$$.fragment,z9),f$r=i(z9),yAe=n(z9,"P",{});var Xsa=s(yAe);g$r=r(Xsa,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Xsa.forEach(t),h$r=i(z9),Om=n(z9,"P",{});var ace=s(Om);u$r=r(ace,`Note:
Loading a model from its configuration file does `),xAe=n(ace,"STRONG",{});var zsa=s(xAe);p$r=r(zsa,"not"),zsa.forEach(t),_$r=r(ace,` load the model weights. It only affects the
model\u2019s configuration. Use `),Coe=n(ace,"A",{href:!0});var Qsa=s(Coe);b$r=r(Qsa,"from_pretrained()"),Qsa.forEach(t),v$r=r(ace," to load the model weights."),ace.forEach(t),F$r=i(z9),T(R3.$$.fragment,z9),z9.forEach(t),T$r=i(si),Fo=n(si,"DIV",{class:!0});var Wa=s(Fo);T(NS.$$.fragment,Wa),M$r=i(Wa),$Ae=n(Wa,"P",{});var Wsa=s($Ae);E$r=r(Wsa,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),Wsa.forEach(t),C$r=i(Wa),An=n(Wa,"P",{});var Q9=s(An);w$r=r(Q9,"The model class to instantiate is selected based on the "),kAe=n(Q9,"CODE",{});var Usa=s(kAe);A$r=r(Usa,"model_type"),Usa.forEach(t),L$r=r(Q9,` property of the config object (either
passed as an argument or loaded from `),SAe=n(Q9,"CODE",{});var Hsa=s(SAe);y$r=r(Hsa,"pretrained_model_name_or_path"),Hsa.forEach(t),x$r=r(Q9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RAe=n(Q9,"CODE",{});var Jsa=s(RAe);$$r=r(Jsa,"pretrained_model_name_or_path"),Jsa.forEach(t),k$r=r(Q9,":"),Q9.forEach(t),S$r=i(Wa),Vm=n(Wa,"UL",{});var nce=s(Vm);P3=n(nce,"LI",{});var HJe=s(P3);PAe=n(HJe,"STRONG",{});var Ysa=s(PAe);R$r=r(Ysa,"speech-encoder-decoder"),Ysa.forEach(t),P$r=r(HJe," \u2014 "),woe=n(HJe,"A",{href:!0});var Zsa=s(woe);B$r=r(Zsa,"SpeechEncoderDecoderModel"),Zsa.forEach(t),I$r=r(HJe," (Speech Encoder decoder model)"),HJe.forEach(t),N$r=i(nce),B3=n(nce,"LI",{});var JJe=s(B3);BAe=n(JJe,"STRONG",{});var Ksa=s(BAe);q$r=r(Ksa,"speech_to_text"),Ksa.forEach(t),j$r=r(JJe," \u2014 "),Aoe=n(JJe,"A",{href:!0});var ela=s(Aoe);D$r=r(ela,"Speech2TextForConditionalGeneration"),ela.forEach(t),G$r=r(JJe," (Speech2Text model)"),JJe.forEach(t),O$r=i(nce),I3=n(nce,"LI",{});var YJe=s(I3);IAe=n(YJe,"STRONG",{});var ola=s(IAe);V$r=r(ola,"whisper"),ola.forEach(t),X$r=r(YJe," \u2014 "),Loe=n(YJe,"A",{href:!0});var rla=s(Loe);z$r=r(rla,"WhisperForConditionalGeneration"),rla.forEach(t),Q$r=r(YJe," (Whisper model)"),YJe.forEach(t),nce.forEach(t),W$r=i(Wa),N3=n(Wa,"P",{});var ZJe=s(N3);U$r=r(ZJe,"The model is set in evaluation mode by default using "),NAe=n(ZJe,"CODE",{});var tla=s(NAe);H$r=r(tla,"model.eval()"),tla.forEach(t),J$r=r(ZJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qAe=n(ZJe,"CODE",{});var ala=s(qAe);Y$r=r(ala,"model.train()"),ala.forEach(t),ZJe.forEach(t),Z$r=i(Wa),T(q3.$$.fragment,Wa),Wa.forEach(t),si.forEach(t),Wao=i(c),Xm=n(c,"H2",{class:!0});var flo=s(Xm);j3=n(flo,"A",{id:!0,class:!0,href:!0});var nla=s(j3);jAe=n(nla,"SPAN",{});var sla=s(jAe);T(qS.$$.fragment,sla),sla.forEach(t),nla.forEach(t),K$r=i(flo),DAe=n(flo,"SPAN",{});var lla=s(DAe);ekr=r(lla,"AutoModelForAudioXVector"),lla.forEach(t),flo.forEach(t),Uao=i(c),tr=n(c,"DIV",{class:!0});var li=s(tr);T(jS.$$.fragment,li),okr=i(li),zm=n(li,"P",{});var sce=s(zm);rkr=r(sce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),yoe=n(sce,"A",{href:!0});var ila=s(yoe);tkr=r(ila,"from_pretrained()"),ila.forEach(t),akr=r(sce," class method or the "),xoe=n(sce,"A",{href:!0});var dla=s(xoe);nkr=r(dla,"from_config()"),dla.forEach(t),skr=r(sce,` class
method.`),sce.forEach(t),lkr=i(li),DS=n(li,"P",{});var glo=s(DS);ikr=r(glo,"This class cannot be instantiated directly using "),GAe=n(glo,"CODE",{});var mla=s(GAe);dkr=r(mla,"__init__()"),mla.forEach(t),mkr=r(glo," (throws an error)."),glo.forEach(t),ckr=i(li),Xt=n(li,"DIV",{class:!0});var W9=s(Xt);T(GS.$$.fragment,W9),fkr=i(W9),OAe=n(W9,"P",{});var cla=s(OAe);gkr=r(cla,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),cla.forEach(t),hkr=i(W9),Qm=n(W9,"P",{});var lce=s(Qm);ukr=r(lce,`Note:
Loading a model from its configuration file does `),VAe=n(lce,"STRONG",{});var fla=s(VAe);pkr=r(fla,"not"),fla.forEach(t),_kr=r(lce,` load the model weights. It only affects the
model\u2019s configuration. Use `),$oe=n(lce,"A",{href:!0});var gla=s($oe);bkr=r(gla,"from_pretrained()"),gla.forEach(t),vkr=r(lce," to load the model weights."),lce.forEach(t),Fkr=i(W9),T(D3.$$.fragment,W9),W9.forEach(t),Tkr=i(li),To=n(li,"DIV",{class:!0});var Ua=s(To);T(OS.$$.fragment,Ua),Mkr=i(Ua),XAe=n(Ua,"P",{});var hla=s(XAe);Ekr=r(hla,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),hla.forEach(t),Ckr=i(Ua),Ln=n(Ua,"P",{});var U9=s(Ln);wkr=r(U9,"The model class to instantiate is selected based on the "),zAe=n(U9,"CODE",{});var ula=s(zAe);Akr=r(ula,"model_type"),ula.forEach(t),Lkr=r(U9,` property of the config object (either
passed as an argument or loaded from `),QAe=n(U9,"CODE",{});var pla=s(QAe);ykr=r(pla,"pretrained_model_name_or_path"),pla.forEach(t),xkr=r(U9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),WAe=n(U9,"CODE",{});var _la=s(WAe);$kr=r(_la,"pretrained_model_name_or_path"),_la.forEach(t),kkr=r(U9,":"),U9.forEach(t),Skr=i(Ua),pt=n(Ua,"UL",{});var ii=s(pt);G3=n(ii,"LI",{});var KJe=s(G3);UAe=n(KJe,"STRONG",{});var bla=s(UAe);Rkr=r(bla,"data2vec-audio"),bla.forEach(t),Pkr=r(KJe," \u2014 "),koe=n(KJe,"A",{href:!0});var vla=s(koe);Bkr=r(vla,"Data2VecAudioForXVector"),vla.forEach(t),Ikr=r(KJe," (Data2VecAudio model)"),KJe.forEach(t),Nkr=i(ii),O3=n(ii,"LI",{});var eYe=s(O3);HAe=n(eYe,"STRONG",{});var Fla=s(HAe);qkr=r(Fla,"unispeech-sat"),Fla.forEach(t),jkr=r(eYe," \u2014 "),Soe=n(eYe,"A",{href:!0});var Tla=s(Soe);Dkr=r(Tla,"UniSpeechSatForXVector"),Tla.forEach(t),Gkr=r(eYe," (UniSpeechSat model)"),eYe.forEach(t),Okr=i(ii),V3=n(ii,"LI",{});var oYe=s(V3);JAe=n(oYe,"STRONG",{});var Mla=s(JAe);Vkr=r(Mla,"wav2vec2"),Mla.forEach(t),Xkr=r(oYe," \u2014 "),Roe=n(oYe,"A",{href:!0});var Ela=s(Roe);zkr=r(Ela,"Wav2Vec2ForXVector"),Ela.forEach(t),Qkr=r(oYe," (Wav2Vec2 model)"),oYe.forEach(t),Wkr=i(ii),X3=n(ii,"LI",{});var rYe=s(X3);YAe=n(rYe,"STRONG",{});var Cla=s(YAe);Ukr=r(Cla,"wav2vec2-conformer"),Cla.forEach(t),Hkr=r(rYe," \u2014 "),Poe=n(rYe,"A",{href:!0});var wla=s(Poe);Jkr=r(wla,"Wav2Vec2ConformerForXVector"),wla.forEach(t),Ykr=r(rYe," (Wav2Vec2-Conformer model)"),rYe.forEach(t),Zkr=i(ii),z3=n(ii,"LI",{});var tYe=s(z3);ZAe=n(tYe,"STRONG",{});var Ala=s(ZAe);Kkr=r(Ala,"wavlm"),Ala.forEach(t),eSr=r(tYe," \u2014 "),Boe=n(tYe,"A",{href:!0});var Lla=s(Boe);oSr=r(Lla,"WavLMForXVector"),Lla.forEach(t),rSr=r(tYe," (WavLM model)"),tYe.forEach(t),ii.forEach(t),tSr=i(Ua),Q3=n(Ua,"P",{});var aYe=s(Q3);aSr=r(aYe,"The model is set in evaluation mode by default using "),KAe=n(aYe,"CODE",{});var yla=s(KAe);nSr=r(yla,"model.eval()"),yla.forEach(t),sSr=r(aYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),e6e=n(aYe,"CODE",{});var xla=s(e6e);lSr=r(xla,"model.train()"),xla.forEach(t),aYe.forEach(t),iSr=i(Ua),T(W3.$$.fragment,Ua),Ua.forEach(t),li.forEach(t),Hao=i(c),Wm=n(c,"H2",{class:!0});var hlo=s(Wm);U3=n(hlo,"A",{id:!0,class:!0,href:!0});var $la=s(U3);o6e=n($la,"SPAN",{});var kla=s(o6e);T(VS.$$.fragment,kla),kla.forEach(t),$la.forEach(t),dSr=i(hlo),r6e=n(hlo,"SPAN",{});var Sla=s(r6e);mSr=r(Sla,"AutoModelForMaskedImageModeling"),Sla.forEach(t),hlo.forEach(t),Jao=i(c),ar=n(c,"DIV",{class:!0});var di=s(ar);T(XS.$$.fragment,di),cSr=i(di),Um=n(di,"P",{});var ice=s(Um);fSr=r(ice,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Ioe=n(ice,"A",{href:!0});var Rla=s(Ioe);gSr=r(Rla,"from_pretrained()"),Rla.forEach(t),hSr=r(ice," class method or the "),Noe=n(ice,"A",{href:!0});var Pla=s(Noe);uSr=r(Pla,"from_config()"),Pla.forEach(t),pSr=r(ice,` class
method.`),ice.forEach(t),_Sr=i(di),zS=n(di,"P",{});var ulo=s(zS);bSr=r(ulo,"This class cannot be instantiated directly using "),t6e=n(ulo,"CODE",{});var Bla=s(t6e);vSr=r(Bla,"__init__()"),Bla.forEach(t),FSr=r(ulo," (throws an error)."),ulo.forEach(t),TSr=i(di),zt=n(di,"DIV",{class:!0});var H9=s(zt);T(QS.$$.fragment,H9),MSr=i(H9),a6e=n(H9,"P",{});var Ila=s(a6e);ESr=r(Ila,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),Ila.forEach(t),CSr=i(H9),Hm=n(H9,"P",{});var dce=s(Hm);wSr=r(dce,`Note:
Loading a model from its configuration file does `),n6e=n(dce,"STRONG",{});var Nla=s(n6e);ASr=r(Nla,"not"),Nla.forEach(t),LSr=r(dce,` load the model weights. It only affects the
model\u2019s configuration. Use `),qoe=n(dce,"A",{href:!0});var qla=s(qoe);ySr=r(qla,"from_pretrained()"),qla.forEach(t),xSr=r(dce," to load the model weights."),dce.forEach(t),$Sr=i(H9),T(H3.$$.fragment,H9),H9.forEach(t),kSr=i(di),Mo=n(di,"DIV",{class:!0});var Ha=s(Mo);T(WS.$$.fragment,Ha),SSr=i(Ha),s6e=n(Ha,"P",{});var jla=s(s6e);RSr=r(jla,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),jla.forEach(t),PSr=i(Ha),yn=n(Ha,"P",{});var J9=s(yn);BSr=r(J9,"The model class to instantiate is selected based on the "),l6e=n(J9,"CODE",{});var Dla=s(l6e);ISr=r(Dla,"model_type"),Dla.forEach(t),NSr=r(J9,` property of the config object (either
passed as an argument or loaded from `),i6e=n(J9,"CODE",{});var Gla=s(i6e);qSr=r(Gla,"pretrained_model_name_or_path"),Gla.forEach(t),jSr=r(J9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d6e=n(J9,"CODE",{});var Ola=s(d6e);DSr=r(Ola,"pretrained_model_name_or_path"),Ola.forEach(t),GSr=r(J9,":"),J9.forEach(t),OSr=i(Ha),xn=n(Ha,"UL",{});var Y9=s(xn);J3=n(Y9,"LI",{});var nYe=s(J3);m6e=n(nYe,"STRONG",{});var Vla=s(m6e);VSr=r(Vla,"deit"),Vla.forEach(t),XSr=r(nYe," \u2014 "),joe=n(nYe,"A",{href:!0});var Xla=s(joe);zSr=r(Xla,"DeiTForMaskedImageModeling"),Xla.forEach(t),QSr=r(nYe," (DeiT model)"),nYe.forEach(t),WSr=i(Y9),Y3=n(Y9,"LI",{});var sYe=s(Y3);c6e=n(sYe,"STRONG",{});var zla=s(c6e);USr=r(zla,"swin"),zla.forEach(t),HSr=r(sYe," \u2014 "),Doe=n(sYe,"A",{href:!0});var Qla=s(Doe);JSr=r(Qla,"SwinForMaskedImageModeling"),Qla.forEach(t),YSr=r(sYe," (Swin Transformer model)"),sYe.forEach(t),ZSr=i(Y9),Z3=n(Y9,"LI",{});var lYe=s(Z3);f6e=n(lYe,"STRONG",{});var Wla=s(f6e);KSr=r(Wla,"swinv2"),Wla.forEach(t),eRr=r(lYe," \u2014 "),Goe=n(lYe,"A",{href:!0});var Ula=s(Goe);oRr=r(Ula,"Swinv2ForMaskedImageModeling"),Ula.forEach(t),rRr=r(lYe," (Swin Transformer V2 model)"),lYe.forEach(t),tRr=i(Y9),K3=n(Y9,"LI",{});var iYe=s(K3);g6e=n(iYe,"STRONG",{});var Hla=s(g6e);aRr=r(Hla,"vit"),Hla.forEach(t),nRr=r(iYe," \u2014 "),Ooe=n(iYe,"A",{href:!0});var Jla=s(Ooe);sRr=r(Jla,"ViTForMaskedImageModeling"),Jla.forEach(t),lRr=r(iYe," (ViT model)"),iYe.forEach(t),Y9.forEach(t),iRr=i(Ha),e5=n(Ha,"P",{});var dYe=s(e5);dRr=r(dYe,"The model is set in evaluation mode by default using "),h6e=n(dYe,"CODE",{});var Yla=s(h6e);mRr=r(Yla,"model.eval()"),Yla.forEach(t),cRr=r(dYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u6e=n(dYe,"CODE",{});var Zla=s(u6e);fRr=r(Zla,"model.train()"),Zla.forEach(t),dYe.forEach(t),gRr=i(Ha),T(o5.$$.fragment,Ha),Ha.forEach(t),di.forEach(t),Yao=i(c),Jm=n(c,"H2",{class:!0});var plo=s(Jm);r5=n(plo,"A",{id:!0,class:!0,href:!0});var Kla=s(r5);p6e=n(Kla,"SPAN",{});var eia=s(p6e);T(US.$$.fragment,eia),eia.forEach(t),Kla.forEach(t),hRr=i(plo),_6e=n(plo,"SPAN",{});var oia=s(_6e);uRr=r(oia,"AutoModelForObjectDetection"),oia.forEach(t),plo.forEach(t),Zao=i(c),nr=n(c,"DIV",{class:!0});var mi=s(nr);T(HS.$$.fragment,mi),pRr=i(mi),Ym=n(mi,"P",{});var mce=s(Ym);_Rr=r(mce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Voe=n(mce,"A",{href:!0});var ria=s(Voe);bRr=r(ria,"from_pretrained()"),ria.forEach(t),vRr=r(mce," class method or the "),Xoe=n(mce,"A",{href:!0});var tia=s(Xoe);FRr=r(tia,"from_config()"),tia.forEach(t),TRr=r(mce,` class
method.`),mce.forEach(t),MRr=i(mi),JS=n(mi,"P",{});var _lo=s(JS);ERr=r(_lo,"This class cannot be instantiated directly using "),b6e=n(_lo,"CODE",{});var aia=s(b6e);CRr=r(aia,"__init__()"),aia.forEach(t),wRr=r(_lo," (throws an error)."),_lo.forEach(t),ARr=i(mi),Qt=n(mi,"DIV",{class:!0});var Z9=s(Qt);T(YS.$$.fragment,Z9),LRr=i(Z9),v6e=n(Z9,"P",{});var nia=s(v6e);yRr=r(nia,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),nia.forEach(t),xRr=i(Z9),Zm=n(Z9,"P",{});var cce=s(Zm);$Rr=r(cce,`Note:
Loading a model from its configuration file does `),F6e=n(cce,"STRONG",{});var sia=s(F6e);kRr=r(sia,"not"),sia.forEach(t),SRr=r(cce,` load the model weights. It only affects the
model\u2019s configuration. Use `),zoe=n(cce,"A",{href:!0});var lia=s(zoe);RRr=r(lia,"from_pretrained()"),lia.forEach(t),PRr=r(cce," to load the model weights."),cce.forEach(t),BRr=i(Z9),T(t5.$$.fragment,Z9),Z9.forEach(t),IRr=i(mi),Eo=n(mi,"DIV",{class:!0});var Ja=s(Eo);T(ZS.$$.fragment,Ja),NRr=i(Ja),T6e=n(Ja,"P",{});var iia=s(T6e);qRr=r(iia,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),iia.forEach(t),jRr=i(Ja),$n=n(Ja,"P",{});var K9=s($n);DRr=r(K9,"The model class to instantiate is selected based on the "),M6e=n(K9,"CODE",{});var dia=s(M6e);GRr=r(dia,"model_type"),dia.forEach(t),ORr=r(K9,` property of the config object (either
passed as an argument or loaded from `),E6e=n(K9,"CODE",{});var mia=s(E6e);VRr=r(mia,"pretrained_model_name_or_path"),mia.forEach(t),XRr=r(K9,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C6e=n(K9,"CODE",{});var cia=s(C6e);zRr=r(cia,"pretrained_model_name_or_path"),cia.forEach(t),QRr=r(K9,":"),K9.forEach(t),WRr=i(Ja),_t=n(Ja,"UL",{});var ci=s(_t);a5=n(ci,"LI",{});var mYe=s(a5);w6e=n(mYe,"STRONG",{});var fia=s(w6e);URr=r(fia,"conditional_detr"),fia.forEach(t),HRr=r(mYe," \u2014 "),Qoe=n(mYe,"A",{href:!0});var gia=s(Qoe);JRr=r(gia,"ConditionalDetrForObjectDetection"),gia.forEach(t),YRr=r(mYe," (Conditional DETR model)"),mYe.forEach(t),ZRr=i(ci),n5=n(ci,"LI",{});var cYe=s(n5);A6e=n(cYe,"STRONG",{});var hia=s(A6e);KRr=r(hia,"deformable_detr"),hia.forEach(t),ePr=r(cYe," \u2014 "),Woe=n(cYe,"A",{href:!0});var uia=s(Woe);oPr=r(uia,"DeformableDetrForObjectDetection"),uia.forEach(t),rPr=r(cYe," (Deformable DETR model)"),cYe.forEach(t),tPr=i(ci),s5=n(ci,"LI",{});var fYe=s(s5);L6e=n(fYe,"STRONG",{});var pia=s(L6e);aPr=r(pia,"detr"),pia.forEach(t),nPr=r(fYe," \u2014 "),Uoe=n(fYe,"A",{href:!0});var _ia=s(Uoe);sPr=r(_ia,"DetrForObjectDetection"),_ia.forEach(t),lPr=r(fYe," (DETR model)"),fYe.forEach(t),iPr=i(ci),l5=n(ci,"LI",{});var gYe=s(l5);y6e=n(gYe,"STRONG",{});var bia=s(y6e);dPr=r(bia,"table-transformer"),bia.forEach(t),mPr=r(gYe," \u2014 "),Hoe=n(gYe,"A",{href:!0});var via=s(Hoe);cPr=r(via,"TableTransformerForObjectDetection"),via.forEach(t),fPr=r(gYe," (Table Transformer model)"),gYe.forEach(t),gPr=i(ci),i5=n(ci,"LI",{});var hYe=s(i5);x6e=n(hYe,"STRONG",{});var Fia=s(x6e);hPr=r(Fia,"yolos"),Fia.forEach(t),uPr=r(hYe," \u2014 "),Joe=n(hYe,"A",{href:!0});var Tia=s(Joe);pPr=r(Tia,"YolosForObjectDetection"),Tia.forEach(t),_Pr=r(hYe," (YOLOS model)"),hYe.forEach(t),ci.forEach(t),bPr=i(Ja),d5=n(Ja,"P",{});var uYe=s(d5);vPr=r(uYe,"The model is set in evaluation mode by default using "),$6e=n(uYe,"CODE",{});var Mia=s($6e);FPr=r(Mia,"model.eval()"),Mia.forEach(t),TPr=r(uYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),k6e=n(uYe,"CODE",{});var Eia=s(k6e);MPr=r(Eia,"model.train()"),Eia.forEach(t),uYe.forEach(t),EPr=i(Ja),T(m5.$$.fragment,Ja),Ja.forEach(t),mi.forEach(t),Kao=i(c),Km=n(c,"H2",{class:!0});var blo=s(Km);c5=n(blo,"A",{id:!0,class:!0,href:!0});var Cia=s(c5);S6e=n(Cia,"SPAN",{});var wia=s(S6e);T(KS.$$.fragment,wia),wia.forEach(t),Cia.forEach(t),CPr=i(blo),R6e=n(blo,"SPAN",{});var Aia=s(R6e);wPr=r(Aia,"AutoModelForImageSegmentation"),Aia.forEach(t),blo.forEach(t),eno=i(c),sr=n(c,"DIV",{class:!0});var fi=s(sr);T(eR.$$.fragment,fi),APr=i(fi),ec=n(fi,"P",{});var fce=s(ec);LPr=r(fce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),Yoe=n(fce,"A",{href:!0});var Lia=s(Yoe);yPr=r(Lia,"from_pretrained()"),Lia.forEach(t),xPr=r(fce," class method or the "),Zoe=n(fce,"A",{href:!0});var yia=s(Zoe);$Pr=r(yia,"from_config()"),yia.forEach(t),kPr=r(fce,` class
method.`),fce.forEach(t),SPr=i(fi),oR=n(fi,"P",{});var vlo=s(oR);RPr=r(vlo,"This class cannot be instantiated directly using "),P6e=n(vlo,"CODE",{});var xia=s(P6e);PPr=r(xia,"__init__()"),xia.forEach(t),BPr=r(vlo," (throws an error)."),vlo.forEach(t),IPr=i(fi),Wt=n(fi,"DIV",{class:!0});var ex=s(Wt);T(rR.$$.fragment,ex),NPr=i(ex),B6e=n(ex,"P",{});var $ia=s(B6e);qPr=r($ia,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),$ia.forEach(t),jPr=i(ex),oc=n(ex,"P",{});var gce=s(oc);DPr=r(gce,`Note:
Loading a model from its configuration file does `),I6e=n(gce,"STRONG",{});var kia=s(I6e);GPr=r(kia,"not"),kia.forEach(t),OPr=r(gce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Koe=n(gce,"A",{href:!0});var Sia=s(Koe);VPr=r(Sia,"from_pretrained()"),Sia.forEach(t),XPr=r(gce," to load the model weights."),gce.forEach(t),zPr=i(ex),T(f5.$$.fragment,ex),ex.forEach(t),QPr=i(fi),Co=n(fi,"DIV",{class:!0});var Ya=s(Co);T(tR.$$.fragment,Ya),WPr=i(Ya),N6e=n(Ya,"P",{});var Ria=s(N6e);UPr=r(Ria,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),Ria.forEach(t),HPr=i(Ya),kn=n(Ya,"P",{});var ox=s(kn);JPr=r(ox,"The model class to instantiate is selected based on the "),q6e=n(ox,"CODE",{});var Pia=s(q6e);YPr=r(Pia,"model_type"),Pia.forEach(t),ZPr=r(ox,` property of the config object (either
passed as an argument or loaded from `),j6e=n(ox,"CODE",{});var Bia=s(j6e);KPr=r(Bia,"pretrained_model_name_or_path"),Bia.forEach(t),eBr=r(ox,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),D6e=n(ox,"CODE",{});var Iia=s(D6e);oBr=r(Iia,"pretrained_model_name_or_path"),Iia.forEach(t),rBr=r(ox,":"),ox.forEach(t),tBr=i(Ya),G6e=n(Ya,"UL",{});var Nia=s(G6e);g5=n(Nia,"LI",{});var pYe=s(g5);O6e=n(pYe,"STRONG",{});var qia=s(O6e);aBr=r(qia,"detr"),qia.forEach(t),nBr=r(pYe," \u2014 "),ere=n(pYe,"A",{href:!0});var jia=s(ere);sBr=r(jia,"DetrForSegmentation"),jia.forEach(t),lBr=r(pYe," (DETR model)"),pYe.forEach(t),Nia.forEach(t),iBr=i(Ya),h5=n(Ya,"P",{});var _Ye=s(h5);dBr=r(_Ye,"The model is set in evaluation mode by default using "),V6e=n(_Ye,"CODE",{});var Dia=s(V6e);mBr=r(Dia,"model.eval()"),Dia.forEach(t),cBr=r(_Ye,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X6e=n(_Ye,"CODE",{});var Gia=s(X6e);fBr=r(Gia,"model.train()"),Gia.forEach(t),_Ye.forEach(t),gBr=i(Ya),T(u5.$$.fragment,Ya),Ya.forEach(t),fi.forEach(t),ono=i(c),rc=n(c,"H2",{class:!0});var Flo=s(rc);p5=n(Flo,"A",{id:!0,class:!0,href:!0});var Oia=s(p5);z6e=n(Oia,"SPAN",{});var Via=s(z6e);T(aR.$$.fragment,Via),Via.forEach(t),Oia.forEach(t),hBr=i(Flo),Q6e=n(Flo,"SPAN",{});var Xia=s(Q6e);uBr=r(Xia,"AutoModelForSemanticSegmentation"),Xia.forEach(t),Flo.forEach(t),rno=i(c),lr=n(c,"DIV",{class:!0});var gi=s(lr);T(nR.$$.fragment,gi),pBr=i(gi),tc=n(gi,"P",{});var hce=s(tc);_Br=r(hce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),ore=n(hce,"A",{href:!0});var zia=s(ore);bBr=r(zia,"from_pretrained()"),zia.forEach(t),vBr=r(hce," class method or the "),rre=n(hce,"A",{href:!0});var Qia=s(rre);FBr=r(Qia,"from_config()"),Qia.forEach(t),TBr=r(hce,` class
method.`),hce.forEach(t),MBr=i(gi),sR=n(gi,"P",{});var Tlo=s(sR);EBr=r(Tlo,"This class cannot be instantiated directly using "),W6e=n(Tlo,"CODE",{});var Wia=s(W6e);CBr=r(Wia,"__init__()"),Wia.forEach(t),wBr=r(Tlo," (throws an error)."),Tlo.forEach(t),ABr=i(gi),Ut=n(gi,"DIV",{class:!0});var rx=s(Ut);T(lR.$$.fragment,rx),LBr=i(rx),U6e=n(rx,"P",{});var Uia=s(U6e);yBr=r(Uia,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Uia.forEach(t),xBr=i(rx),ac=n(rx,"P",{});var uce=s(ac);$Br=r(uce,`Note:
Loading a model from its configuration file does `),H6e=n(uce,"STRONG",{});var Hia=s(H6e);kBr=r(Hia,"not"),Hia.forEach(t),SBr=r(uce,` load the model weights. It only affects the
model\u2019s configuration. Use `),tre=n(uce,"A",{href:!0});var Jia=s(tre);RBr=r(Jia,"from_pretrained()"),Jia.forEach(t),PBr=r(uce," to load the model weights."),uce.forEach(t),BBr=i(rx),T(_5.$$.fragment,rx),rx.forEach(t),IBr=i(gi),wo=n(gi,"DIV",{class:!0});var Za=s(wo);T(iR.$$.fragment,Za),NBr=i(Za),J6e=n(Za,"P",{});var Yia=s(J6e);qBr=r(Yia,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Yia.forEach(t),jBr=i(Za),Sn=n(Za,"P",{});var tx=s(Sn);DBr=r(tx,"The model class to instantiate is selected based on the "),Y6e=n(tx,"CODE",{});var Zia=s(Y6e);GBr=r(Zia,"model_type"),Zia.forEach(t),OBr=r(tx,` property of the config object (either
passed as an argument or loaded from `),Z6e=n(tx,"CODE",{});var Kia=s(Z6e);VBr=r(Kia,"pretrained_model_name_or_path"),Kia.forEach(t),XBr=r(tx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K6e=n(tx,"CODE",{});var eda=s(K6e);zBr=r(eda,"pretrained_model_name_or_path"),eda.forEach(t),QBr=r(tx,":"),tx.forEach(t),WBr=i(Za),bt=n(Za,"UL",{});var hi=s(bt);b5=n(hi,"LI",{});var bYe=s(b5);e7e=n(bYe,"STRONG",{});var oda=s(e7e);UBr=r(oda,"beit"),oda.forEach(t),HBr=r(bYe," \u2014 "),are=n(bYe,"A",{href:!0});var rda=s(are);JBr=r(rda,"BeitForSemanticSegmentation"),rda.forEach(t),YBr=r(bYe," (BEiT model)"),bYe.forEach(t),ZBr=i(hi),v5=n(hi,"LI",{});var vYe=s(v5);o7e=n(vYe,"STRONG",{});var tda=s(o7e);KBr=r(tda,"data2vec-vision"),tda.forEach(t),eIr=r(vYe," \u2014 "),nre=n(vYe,"A",{href:!0});var ada=s(nre);oIr=r(ada,"Data2VecVisionForSemanticSegmentation"),ada.forEach(t),rIr=r(vYe," (Data2VecVision model)"),vYe.forEach(t),tIr=i(hi),F5=n(hi,"LI",{});var FYe=s(F5);r7e=n(FYe,"STRONG",{});var nda=s(r7e);aIr=r(nda,"dpt"),nda.forEach(t),nIr=r(FYe," \u2014 "),sre=n(FYe,"A",{href:!0});var sda=s(sre);sIr=r(sda,"DPTForSemanticSegmentation"),sda.forEach(t),lIr=r(FYe," (DPT model)"),FYe.forEach(t),iIr=i(hi),T5=n(hi,"LI",{});var TYe=s(T5);t7e=n(TYe,"STRONG",{});var lda=s(t7e);dIr=r(lda,"mobilevit"),lda.forEach(t),mIr=r(TYe," \u2014 "),lre=n(TYe,"A",{href:!0});var ida=s(lre);cIr=r(ida,"MobileViTForSemanticSegmentation"),ida.forEach(t),fIr=r(TYe," (MobileViT model)"),TYe.forEach(t),gIr=i(hi),M5=n(hi,"LI",{});var MYe=s(M5);a7e=n(MYe,"STRONG",{});var dda=s(a7e);hIr=r(dda,"segformer"),dda.forEach(t),uIr=r(MYe," \u2014 "),ire=n(MYe,"A",{href:!0});var mda=s(ire);pIr=r(mda,"SegformerForSemanticSegmentation"),mda.forEach(t),_Ir=r(MYe," (SegFormer model)"),MYe.forEach(t),hi.forEach(t),bIr=i(Za),E5=n(Za,"P",{});var EYe=s(E5);vIr=r(EYe,"The model is set in evaluation mode by default using "),n7e=n(EYe,"CODE",{});var cda=s(n7e);FIr=r(cda,"model.eval()"),cda.forEach(t),TIr=r(EYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),s7e=n(EYe,"CODE",{});var fda=s(s7e);MIr=r(fda,"model.train()"),fda.forEach(t),EYe.forEach(t),EIr=i(Za),T(C5.$$.fragment,Za),Za.forEach(t),gi.forEach(t),tno=i(c),nc=n(c,"H2",{class:!0});var Mlo=s(nc);w5=n(Mlo,"A",{id:!0,class:!0,href:!0});var gda=s(w5);l7e=n(gda,"SPAN",{});var hda=s(l7e);T(dR.$$.fragment,hda),hda.forEach(t),gda.forEach(t),CIr=i(Mlo),i7e=n(Mlo,"SPAN",{});var uda=s(i7e);wIr=r(uda,"AutoModelForInstanceSegmentation"),uda.forEach(t),Mlo.forEach(t),ano=i(c),ir=n(c,"DIV",{class:!0});var ui=s(ir);T(mR.$$.fragment,ui),AIr=i(ui),sc=n(ui,"P",{});var pce=s(sc);LIr=r(pce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),dre=n(pce,"A",{href:!0});var pda=s(dre);yIr=r(pda,"from_pretrained()"),pda.forEach(t),xIr=r(pce," class method or the "),mre=n(pce,"A",{href:!0});var _da=s(mre);$Ir=r(_da,"from_config()"),_da.forEach(t),kIr=r(pce,` class
method.`),pce.forEach(t),SIr=i(ui),cR=n(ui,"P",{});var Elo=s(cR);RIr=r(Elo,"This class cannot be instantiated directly using "),d7e=n(Elo,"CODE",{});var bda=s(d7e);PIr=r(bda,"__init__()"),bda.forEach(t),BIr=r(Elo," (throws an error)."),Elo.forEach(t),IIr=i(ui),Ht=n(ui,"DIV",{class:!0});var ax=s(Ht);T(fR.$$.fragment,ax),NIr=i(ax),m7e=n(ax,"P",{});var vda=s(m7e);qIr=r(vda,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),vda.forEach(t),jIr=i(ax),lc=n(ax,"P",{});var _ce=s(lc);DIr=r(_ce,`Note:
Loading a model from its configuration file does `),c7e=n(_ce,"STRONG",{});var Fda=s(c7e);GIr=r(Fda,"not"),Fda.forEach(t),OIr=r(_ce,` load the model weights. It only affects the
model\u2019s configuration. Use `),cre=n(_ce,"A",{href:!0});var Tda=s(cre);VIr=r(Tda,"from_pretrained()"),Tda.forEach(t),XIr=r(_ce," to load the model weights."),_ce.forEach(t),zIr=i(ax),T(A5.$$.fragment,ax),ax.forEach(t),QIr=i(ui),Ao=n(ui,"DIV",{class:!0});var Ka=s(Ao);T(gR.$$.fragment,Ka),WIr=i(Ka),f7e=n(Ka,"P",{});var Mda=s(f7e);UIr=r(Mda,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Mda.forEach(t),HIr=i(Ka),Rn=n(Ka,"P",{});var nx=s(Rn);JIr=r(nx,"The model class to instantiate is selected based on the "),g7e=n(nx,"CODE",{});var Eda=s(g7e);YIr=r(Eda,"model_type"),Eda.forEach(t),ZIr=r(nx,` property of the config object (either
passed as an argument or loaded from `),h7e=n(nx,"CODE",{});var Cda=s(h7e);KIr=r(Cda,"pretrained_model_name_or_path"),Cda.forEach(t),eNr=r(nx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u7e=n(nx,"CODE",{});var wda=s(u7e);oNr=r(wda,"pretrained_model_name_or_path"),wda.forEach(t),rNr=r(nx,":"),nx.forEach(t),tNr=i(Ka),p7e=n(Ka,"UL",{});var Ada=s(p7e);L5=n(Ada,"LI",{});var CYe=s(L5);_7e=n(CYe,"STRONG",{});var Lda=s(_7e);aNr=r(Lda,"maskformer"),Lda.forEach(t),nNr=r(CYe," \u2014 "),fre=n(CYe,"A",{href:!0});var yda=s(fre);sNr=r(yda,"MaskFormerForInstanceSegmentation"),yda.forEach(t),lNr=r(CYe," (MaskFormer model)"),CYe.forEach(t),Ada.forEach(t),iNr=i(Ka),y5=n(Ka,"P",{});var wYe=s(y5);dNr=r(wYe,"The model is set in evaluation mode by default using "),b7e=n(wYe,"CODE",{});var xda=s(b7e);mNr=r(xda,"model.eval()"),xda.forEach(t),cNr=r(wYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v7e=n(wYe,"CODE",{});var $da=s(v7e);fNr=r($da,"model.train()"),$da.forEach(t),wYe.forEach(t),gNr=i(Ka),T(x5.$$.fragment,Ka),Ka.forEach(t),ui.forEach(t),nno=i(c),ic=n(c,"H2",{class:!0});var Clo=s(ic);$5=n(Clo,"A",{id:!0,class:!0,href:!0});var kda=s($5);F7e=n(kda,"SPAN",{});var Sda=s(F7e);T(hR.$$.fragment,Sda),Sda.forEach(t),kda.forEach(t),hNr=i(Clo),T7e=n(Clo,"SPAN",{});var Rda=s(T7e);uNr=r(Rda,"AutoModelForZeroShotObjectDetection"),Rda.forEach(t),Clo.forEach(t),sno=i(c),dr=n(c,"DIV",{class:!0});var pi=s(dr);T(uR.$$.fragment,pi),pNr=i(pi),dc=n(pi,"P",{});var bce=s(dc);_Nr=r(bce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),gre=n(bce,"A",{href:!0});var Pda=s(gre);bNr=r(Pda,"from_pretrained()"),Pda.forEach(t),vNr=r(bce," class method or the "),hre=n(bce,"A",{href:!0});var Bda=s(hre);FNr=r(Bda,"from_config()"),Bda.forEach(t),TNr=r(bce,` class
method.`),bce.forEach(t),MNr=i(pi),pR=n(pi,"P",{});var wlo=s(pR);ENr=r(wlo,"This class cannot be instantiated directly using "),M7e=n(wlo,"CODE",{});var Ida=s(M7e);CNr=r(Ida,"__init__()"),Ida.forEach(t),wNr=r(wlo," (throws an error)."),wlo.forEach(t),ANr=i(pi),Jt=n(pi,"DIV",{class:!0});var sx=s(Jt);T(_R.$$.fragment,sx),LNr=i(sx),E7e=n(sx,"P",{});var Nda=s(E7e);yNr=r(Nda,"Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),Nda.forEach(t),xNr=i(sx),mc=n(sx,"P",{});var vce=s(mc);$Nr=r(vce,`Note:
Loading a model from its configuration file does `),C7e=n(vce,"STRONG",{});var qda=s(C7e);kNr=r(qda,"not"),qda.forEach(t),SNr=r(vce,` load the model weights. It only affects the
model\u2019s configuration. Use `),ure=n(vce,"A",{href:!0});var jda=s(ure);RNr=r(jda,"from_pretrained()"),jda.forEach(t),PNr=r(vce," to load the model weights."),vce.forEach(t),BNr=i(sx),T(k5.$$.fragment,sx),sx.forEach(t),INr=i(pi),Lo=n(pi,"DIV",{class:!0});var en=s(Lo);T(bR.$$.fragment,en),NNr=i(en),w7e=n(en,"P",{});var Dda=s(w7e);qNr=r(Dda,"Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),Dda.forEach(t),jNr=i(en),Pn=n(en,"P",{});var lx=s(Pn);DNr=r(lx,"The model class to instantiate is selected based on the "),A7e=n(lx,"CODE",{});var Gda=s(A7e);GNr=r(Gda,"model_type"),Gda.forEach(t),ONr=r(lx,` property of the config object (either
passed as an argument or loaded from `),L7e=n(lx,"CODE",{});var Oda=s(L7e);VNr=r(Oda,"pretrained_model_name_or_path"),Oda.forEach(t),XNr=r(lx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y7e=n(lx,"CODE",{});var Vda=s(y7e);zNr=r(Vda,"pretrained_model_name_or_path"),Vda.forEach(t),QNr=r(lx,":"),lx.forEach(t),WNr=i(en),x7e=n(en,"UL",{});var Xda=s(x7e);S5=n(Xda,"LI",{});var AYe=s(S5);$7e=n(AYe,"STRONG",{});var zda=s($7e);UNr=r(zda,"owlvit"),zda.forEach(t),HNr=r(AYe," \u2014 "),pre=n(AYe,"A",{href:!0});var Qda=s(pre);JNr=r(Qda,"OwlViTForObjectDetection"),Qda.forEach(t),YNr=r(AYe," (OWL-ViT model)"),AYe.forEach(t),Xda.forEach(t),ZNr=i(en),R5=n(en,"P",{});var LYe=s(R5);KNr=r(LYe,"The model is set in evaluation mode by default using "),k7e=n(LYe,"CODE",{});var Wda=s(k7e);eqr=r(Wda,"model.eval()"),Wda.forEach(t),oqr=r(LYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),S7e=n(LYe,"CODE",{});var Uda=s(S7e);rqr=r(Uda,"model.train()"),Uda.forEach(t),LYe.forEach(t),tqr=i(en),T(P5.$$.fragment,en),en.forEach(t),pi.forEach(t),lno=i(c),cc=n(c,"H2",{class:!0});var Alo=s(cc);B5=n(Alo,"A",{id:!0,class:!0,href:!0});var Hda=s(B5);R7e=n(Hda,"SPAN",{});var Jda=s(R7e);T(vR.$$.fragment,Jda),Jda.forEach(t),Hda.forEach(t),aqr=i(Alo),P7e=n(Alo,"SPAN",{});var Yda=s(P7e);nqr=r(Yda,"TFAutoModel"),Yda.forEach(t),Alo.forEach(t),ino=i(c),mr=n(c,"DIV",{class:!0});var _i=s(mr);T(FR.$$.fragment,_i),sqr=i(_i),fc=n(_i,"P",{});var Fce=s(fc);lqr=r(Fce,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),_re=n(Fce,"A",{href:!0});var Zda=s(_re);iqr=r(Zda,"from_pretrained()"),Zda.forEach(t),dqr=r(Fce," class method or the "),bre=n(Fce,"A",{href:!0});var Kda=s(bre);mqr=r(Kda,"from_config()"),Kda.forEach(t),cqr=r(Fce,` class
method.`),Fce.forEach(t),fqr=i(_i),TR=n(_i,"P",{});var Llo=s(TR);gqr=r(Llo,"This class cannot be instantiated directly using "),B7e=n(Llo,"CODE",{});var ema=s(B7e);hqr=r(ema,"__init__()"),ema.forEach(t),uqr=r(Llo," (throws an error)."),Llo.forEach(t),pqr=i(_i),Yt=n(_i,"DIV",{class:!0});var ix=s(Yt);T(MR.$$.fragment,ix),_qr=i(ix),I7e=n(ix,"P",{});var oma=s(I7e);bqr=r(oma,"Instantiates one of the base model classes of the library from a configuration."),oma.forEach(t),vqr=i(ix),gc=n(ix,"P",{});var Tce=s(gc);Fqr=r(Tce,`Note:
Loading a model from its configuration file does `),N7e=n(Tce,"STRONG",{});var rma=s(N7e);Tqr=r(rma,"not"),rma.forEach(t),Mqr=r(Tce,` load the model weights. It only affects the
model\u2019s configuration. Use `),vre=n(Tce,"A",{href:!0});var tma=s(vre);Eqr=r(tma,"from_pretrained()"),tma.forEach(t),Cqr=r(Tce," to load the model weights."),Tce.forEach(t),wqr=i(ix),T(I5.$$.fragment,ix),ix.forEach(t),Aqr=i(_i),Dr=n(_i,"DIV",{class:!0});var bi=s(Dr);T(ER.$$.fragment,bi),Lqr=i(bi),q7e=n(bi,"P",{});var ama=s(q7e);yqr=r(ama,"Instantiate one of the base model classes of the library from a pretrained model."),ama.forEach(t),xqr=i(bi),Bn=n(bi,"P",{});var dx=s(Bn);$qr=r(dx,"The model class to instantiate is selected based on the "),j7e=n(dx,"CODE",{});var nma=s(j7e);kqr=r(nma,"model_type"),nma.forEach(t),Sqr=r(dx,` property of the config object (either
passed as an argument or loaded from `),D7e=n(dx,"CODE",{});var sma=s(D7e);Rqr=r(sma,"pretrained_model_name_or_path"),sma.forEach(t),Pqr=r(dx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G7e=n(dx,"CODE",{});var lma=s(G7e);Bqr=r(lma,"pretrained_model_name_or_path"),lma.forEach(t),Iqr=r(dx,":"),dx.forEach(t),Nqr=i(bi),P=n(bi,"UL",{});var I=s(P);N5=n(I,"LI",{});var yYe=s(N5);O7e=n(yYe,"STRONG",{});var ima=s(O7e);qqr=r(ima,"albert"),ima.forEach(t),jqr=r(yYe," \u2014 "),Fre=n(yYe,"A",{href:!0});var dma=s(Fre);Dqr=r(dma,"TFAlbertModel"),dma.forEach(t),Gqr=r(yYe," (ALBERT model)"),yYe.forEach(t),Oqr=i(I),q5=n(I,"LI",{});var xYe=s(q5);V7e=n(xYe,"STRONG",{});var mma=s(V7e);Vqr=r(mma,"bart"),mma.forEach(t),Xqr=r(xYe," \u2014 "),Tre=n(xYe,"A",{href:!0});var cma=s(Tre);zqr=r(cma,"TFBartModel"),cma.forEach(t),Qqr=r(xYe," (BART model)"),xYe.forEach(t),Wqr=i(I),j5=n(I,"LI",{});var $Ye=s(j5);X7e=n($Ye,"STRONG",{});var fma=s(X7e);Uqr=r(fma,"bert"),fma.forEach(t),Hqr=r($Ye," \u2014 "),Mre=n($Ye,"A",{href:!0});var gma=s(Mre);Jqr=r(gma,"TFBertModel"),gma.forEach(t),Yqr=r($Ye," (BERT model)"),$Ye.forEach(t),Zqr=i(I),D5=n(I,"LI",{});var kYe=s(D5);z7e=n(kYe,"STRONG",{});var hma=s(z7e);Kqr=r(hma,"blenderbot"),hma.forEach(t),ejr=r(kYe," \u2014 "),Ere=n(kYe,"A",{href:!0});var uma=s(Ere);ojr=r(uma,"TFBlenderbotModel"),uma.forEach(t),rjr=r(kYe," (Blenderbot model)"),kYe.forEach(t),tjr=i(I),G5=n(I,"LI",{});var SYe=s(G5);Q7e=n(SYe,"STRONG",{});var pma=s(Q7e);ajr=r(pma,"blenderbot-small"),pma.forEach(t),njr=r(SYe," \u2014 "),Cre=n(SYe,"A",{href:!0});var _ma=s(Cre);sjr=r(_ma,"TFBlenderbotSmallModel"),_ma.forEach(t),ljr=r(SYe," (BlenderbotSmall model)"),SYe.forEach(t),ijr=i(I),O5=n(I,"LI",{});var RYe=s(O5);W7e=n(RYe,"STRONG",{});var bma=s(W7e);djr=r(bma,"camembert"),bma.forEach(t),mjr=r(RYe," \u2014 "),wre=n(RYe,"A",{href:!0});var vma=s(wre);cjr=r(vma,"TFCamembertModel"),vma.forEach(t),fjr=r(RYe," (CamemBERT model)"),RYe.forEach(t),gjr=i(I),V5=n(I,"LI",{});var PYe=s(V5);U7e=n(PYe,"STRONG",{});var Fma=s(U7e);hjr=r(Fma,"clip"),Fma.forEach(t),ujr=r(PYe," \u2014 "),Are=n(PYe,"A",{href:!0});var Tma=s(Are);pjr=r(Tma,"TFCLIPModel"),Tma.forEach(t),_jr=r(PYe," (CLIP model)"),PYe.forEach(t),bjr=i(I),X5=n(I,"LI",{});var BYe=s(X5);H7e=n(BYe,"STRONG",{});var Mma=s(H7e);vjr=r(Mma,"convbert"),Mma.forEach(t),Fjr=r(BYe," \u2014 "),Lre=n(BYe,"A",{href:!0});var Ema=s(Lre);Tjr=r(Ema,"TFConvBertModel"),Ema.forEach(t),Mjr=r(BYe," (ConvBERT model)"),BYe.forEach(t),Ejr=i(I),z5=n(I,"LI",{});var IYe=s(z5);J7e=n(IYe,"STRONG",{});var Cma=s(J7e);Cjr=r(Cma,"convnext"),Cma.forEach(t),wjr=r(IYe," \u2014 "),yre=n(IYe,"A",{href:!0});var wma=s(yre);Ajr=r(wma,"TFConvNextModel"),wma.forEach(t),Ljr=r(IYe," (ConvNeXT model)"),IYe.forEach(t),yjr=i(I),Q5=n(I,"LI",{});var NYe=s(Q5);Y7e=n(NYe,"STRONG",{});var Ama=s(Y7e);xjr=r(Ama,"ctrl"),Ama.forEach(t),$jr=r(NYe," \u2014 "),xre=n(NYe,"A",{href:!0});var Lma=s(xre);kjr=r(Lma,"TFCTRLModel"),Lma.forEach(t),Sjr=r(NYe," (CTRL model)"),NYe.forEach(t),Rjr=i(I),W5=n(I,"LI",{});var qYe=s(W5);Z7e=n(qYe,"STRONG",{});var yma=s(Z7e);Pjr=r(yma,"cvt"),yma.forEach(t),Bjr=r(qYe," \u2014 "),$re=n(qYe,"A",{href:!0});var xma=s($re);Ijr=r(xma,"TFCvtModel"),xma.forEach(t),Njr=r(qYe," (CvT model)"),qYe.forEach(t),qjr=i(I),U5=n(I,"LI",{});var jYe=s(U5);K7e=n(jYe,"STRONG",{});var $ma=s(K7e);jjr=r($ma,"data2vec-vision"),$ma.forEach(t),Djr=r(jYe," \u2014 "),kre=n(jYe,"A",{href:!0});var kma=s(kre);Gjr=r(kma,"TFData2VecVisionModel"),kma.forEach(t),Ojr=r(jYe," (Data2VecVision model)"),jYe.forEach(t),Vjr=i(I),H5=n(I,"LI",{});var DYe=s(H5);e8e=n(DYe,"STRONG",{});var Sma=s(e8e);Xjr=r(Sma,"deberta"),Sma.forEach(t),zjr=r(DYe," \u2014 "),Sre=n(DYe,"A",{href:!0});var Rma=s(Sre);Qjr=r(Rma,"TFDebertaModel"),Rma.forEach(t),Wjr=r(DYe," (DeBERTa model)"),DYe.forEach(t),Ujr=i(I),J5=n(I,"LI",{});var GYe=s(J5);o8e=n(GYe,"STRONG",{});var Pma=s(o8e);Hjr=r(Pma,"deberta-v2"),Pma.forEach(t),Jjr=r(GYe," \u2014 "),Rre=n(GYe,"A",{href:!0});var Bma=s(Rre);Yjr=r(Bma,"TFDebertaV2Model"),Bma.forEach(t),Zjr=r(GYe," (DeBERTa-v2 model)"),GYe.forEach(t),Kjr=i(I),Y5=n(I,"LI",{});var OYe=s(Y5);r8e=n(OYe,"STRONG",{});var Ima=s(r8e);eDr=r(Ima,"deit"),Ima.forEach(t),oDr=r(OYe," \u2014 "),Pre=n(OYe,"A",{href:!0});var Nma=s(Pre);rDr=r(Nma,"TFDeiTModel"),Nma.forEach(t),tDr=r(OYe," (DeiT model)"),OYe.forEach(t),aDr=i(I),Z5=n(I,"LI",{});var VYe=s(Z5);t8e=n(VYe,"STRONG",{});var qma=s(t8e);nDr=r(qma,"distilbert"),qma.forEach(t),sDr=r(VYe," \u2014 "),Bre=n(VYe,"A",{href:!0});var jma=s(Bre);lDr=r(jma,"TFDistilBertModel"),jma.forEach(t),iDr=r(VYe," (DistilBERT model)"),VYe.forEach(t),dDr=i(I),K5=n(I,"LI",{});var XYe=s(K5);a8e=n(XYe,"STRONG",{});var Dma=s(a8e);mDr=r(Dma,"dpr"),Dma.forEach(t),cDr=r(XYe," \u2014 "),Ire=n(XYe,"A",{href:!0});var Gma=s(Ire);fDr=r(Gma,"TFDPRQuestionEncoder"),Gma.forEach(t),gDr=r(XYe," (DPR model)"),XYe.forEach(t),hDr=i(I),e0=n(I,"LI",{});var zYe=s(e0);n8e=n(zYe,"STRONG",{});var Oma=s(n8e);uDr=r(Oma,"electra"),Oma.forEach(t),pDr=r(zYe," \u2014 "),Nre=n(zYe,"A",{href:!0});var Vma=s(Nre);_Dr=r(Vma,"TFElectraModel"),Vma.forEach(t),bDr=r(zYe," (ELECTRA model)"),zYe.forEach(t),vDr=i(I),o0=n(I,"LI",{});var QYe=s(o0);s8e=n(QYe,"STRONG",{});var Xma=s(s8e);FDr=r(Xma,"esm"),Xma.forEach(t),TDr=r(QYe," \u2014 "),qre=n(QYe,"A",{href:!0});var zma=s(qre);MDr=r(zma,"TFEsmModel"),zma.forEach(t),EDr=r(QYe," (ESM model)"),QYe.forEach(t),CDr=i(I),r0=n(I,"LI",{});var WYe=s(r0);l8e=n(WYe,"STRONG",{});var Qma=s(l8e);wDr=r(Qma,"flaubert"),Qma.forEach(t),ADr=r(WYe," \u2014 "),jre=n(WYe,"A",{href:!0});var Wma=s(jre);LDr=r(Wma,"TFFlaubertModel"),Wma.forEach(t),yDr=r(WYe," (FlauBERT model)"),WYe.forEach(t),xDr=i(I),Rl=n(I,"LI",{});var AN=s(Rl);i8e=n(AN,"STRONG",{});var Uma=s(i8e);$Dr=r(Uma,"funnel"),Uma.forEach(t),kDr=r(AN," \u2014 "),Dre=n(AN,"A",{href:!0});var Hma=s(Dre);SDr=r(Hma,"TFFunnelModel"),Hma.forEach(t),RDr=r(AN," or "),Gre=n(AN,"A",{href:!0});var Jma=s(Gre);PDr=r(Jma,"TFFunnelBaseModel"),Jma.forEach(t),BDr=r(AN," (Funnel Transformer model)"),AN.forEach(t),IDr=i(I),t0=n(I,"LI",{});var UYe=s(t0);d8e=n(UYe,"STRONG",{});var Yma=s(d8e);NDr=r(Yma,"gpt2"),Yma.forEach(t),qDr=r(UYe," \u2014 "),Ore=n(UYe,"A",{href:!0});var Zma=s(Ore);jDr=r(Zma,"TFGPT2Model"),Zma.forEach(t),DDr=r(UYe," (OpenAI GPT-2 model)"),UYe.forEach(t),GDr=i(I),a0=n(I,"LI",{});var HYe=s(a0);m8e=n(HYe,"STRONG",{});var Kma=s(m8e);ODr=r(Kma,"gptj"),Kma.forEach(t),VDr=r(HYe," \u2014 "),Vre=n(HYe,"A",{href:!0});var eca=s(Vre);XDr=r(eca,"TFGPTJModel"),eca.forEach(t),zDr=r(HYe," (GPT-J model)"),HYe.forEach(t),QDr=i(I),n0=n(I,"LI",{});var JYe=s(n0);c8e=n(JYe,"STRONG",{});var oca=s(c8e);WDr=r(oca,"groupvit"),oca.forEach(t),UDr=r(JYe," \u2014 "),Xre=n(JYe,"A",{href:!0});var rca=s(Xre);HDr=r(rca,"TFGroupViTModel"),rca.forEach(t),JDr=r(JYe," (GroupViT model)"),JYe.forEach(t),YDr=i(I),s0=n(I,"LI",{});var YYe=s(s0);f8e=n(YYe,"STRONG",{});var tca=s(f8e);ZDr=r(tca,"hubert"),tca.forEach(t),KDr=r(YYe," \u2014 "),zre=n(YYe,"A",{href:!0});var aca=s(zre);eGr=r(aca,"TFHubertModel"),aca.forEach(t),oGr=r(YYe," (Hubert model)"),YYe.forEach(t),rGr=i(I),l0=n(I,"LI",{});var ZYe=s(l0);g8e=n(ZYe,"STRONG",{});var nca=s(g8e);tGr=r(nca,"layoutlm"),nca.forEach(t),aGr=r(ZYe," \u2014 "),Qre=n(ZYe,"A",{href:!0});var sca=s(Qre);nGr=r(sca,"TFLayoutLMModel"),sca.forEach(t),sGr=r(ZYe," (LayoutLM model)"),ZYe.forEach(t),lGr=i(I),i0=n(I,"LI",{});var KYe=s(i0);h8e=n(KYe,"STRONG",{});var lca=s(h8e);iGr=r(lca,"layoutlmv3"),lca.forEach(t),dGr=r(KYe," \u2014 "),Wre=n(KYe,"A",{href:!0});var ica=s(Wre);mGr=r(ica,"TFLayoutLMv3Model"),ica.forEach(t),cGr=r(KYe," (LayoutLMv3 model)"),KYe.forEach(t),fGr=i(I),d0=n(I,"LI",{});var eZe=s(d0);u8e=n(eZe,"STRONG",{});var dca=s(u8e);gGr=r(dca,"led"),dca.forEach(t),hGr=r(eZe," \u2014 "),Ure=n(eZe,"A",{href:!0});var mca=s(Ure);uGr=r(mca,"TFLEDModel"),mca.forEach(t),pGr=r(eZe," (LED model)"),eZe.forEach(t),_Gr=i(I),m0=n(I,"LI",{});var oZe=s(m0);p8e=n(oZe,"STRONG",{});var cca=s(p8e);bGr=r(cca,"longformer"),cca.forEach(t),vGr=r(oZe," \u2014 "),Hre=n(oZe,"A",{href:!0});var fca=s(Hre);FGr=r(fca,"TFLongformerModel"),fca.forEach(t),TGr=r(oZe," (Longformer model)"),oZe.forEach(t),MGr=i(I),c0=n(I,"LI",{});var rZe=s(c0);_8e=n(rZe,"STRONG",{});var gca=s(_8e);EGr=r(gca,"lxmert"),gca.forEach(t),CGr=r(rZe," \u2014 "),Jre=n(rZe,"A",{href:!0});var hca=s(Jre);wGr=r(hca,"TFLxmertModel"),hca.forEach(t),AGr=r(rZe," (LXMERT model)"),rZe.forEach(t),LGr=i(I),f0=n(I,"LI",{});var tZe=s(f0);b8e=n(tZe,"STRONG",{});var uca=s(b8e);yGr=r(uca,"marian"),uca.forEach(t),xGr=r(tZe," \u2014 "),Yre=n(tZe,"A",{href:!0});var pca=s(Yre);$Gr=r(pca,"TFMarianModel"),pca.forEach(t),kGr=r(tZe," (Marian model)"),tZe.forEach(t),SGr=i(I),g0=n(I,"LI",{});var aZe=s(g0);v8e=n(aZe,"STRONG",{});var _ca=s(v8e);RGr=r(_ca,"mbart"),_ca.forEach(t),PGr=r(aZe," \u2014 "),Zre=n(aZe,"A",{href:!0});var bca=s(Zre);BGr=r(bca,"TFMBartModel"),bca.forEach(t),IGr=r(aZe," (mBART model)"),aZe.forEach(t),NGr=i(I),h0=n(I,"LI",{});var nZe=s(h0);F8e=n(nZe,"STRONG",{});var vca=s(F8e);qGr=r(vca,"mobilebert"),vca.forEach(t),jGr=r(nZe," \u2014 "),Kre=n(nZe,"A",{href:!0});var Fca=s(Kre);DGr=r(Fca,"TFMobileBertModel"),Fca.forEach(t),GGr=r(nZe," (MobileBERT model)"),nZe.forEach(t),OGr=i(I),u0=n(I,"LI",{});var sZe=s(u0);T8e=n(sZe,"STRONG",{});var Tca=s(T8e);VGr=r(Tca,"mobilevit"),Tca.forEach(t),XGr=r(sZe," \u2014 "),ete=n(sZe,"A",{href:!0});var Mca=s(ete);zGr=r(Mca,"TFMobileViTModel"),Mca.forEach(t),QGr=r(sZe," (MobileViT model)"),sZe.forEach(t),WGr=i(I),p0=n(I,"LI",{});var lZe=s(p0);M8e=n(lZe,"STRONG",{});var Eca=s(M8e);UGr=r(Eca,"mpnet"),Eca.forEach(t),HGr=r(lZe," \u2014 "),ote=n(lZe,"A",{href:!0});var Cca=s(ote);JGr=r(Cca,"TFMPNetModel"),Cca.forEach(t),YGr=r(lZe," (MPNet model)"),lZe.forEach(t),ZGr=i(I),_0=n(I,"LI",{});var iZe=s(_0);E8e=n(iZe,"STRONG",{});var wca=s(E8e);KGr=r(wca,"mt5"),wca.forEach(t),eOr=r(iZe," \u2014 "),rte=n(iZe,"A",{href:!0});var Aca=s(rte);oOr=r(Aca,"TFMT5Model"),Aca.forEach(t),rOr=r(iZe," (MT5 model)"),iZe.forEach(t),tOr=i(I),b0=n(I,"LI",{});var dZe=s(b0);C8e=n(dZe,"STRONG",{});var Lca=s(C8e);aOr=r(Lca,"openai-gpt"),Lca.forEach(t),nOr=r(dZe," \u2014 "),tte=n(dZe,"A",{href:!0});var yca=s(tte);sOr=r(yca,"TFOpenAIGPTModel"),yca.forEach(t),lOr=r(dZe," (OpenAI GPT model)"),dZe.forEach(t),iOr=i(I),v0=n(I,"LI",{});var mZe=s(v0);w8e=n(mZe,"STRONG",{});var xca=s(w8e);dOr=r(xca,"opt"),xca.forEach(t),mOr=r(mZe," \u2014 "),ate=n(mZe,"A",{href:!0});var $ca=s(ate);cOr=r($ca,"TFOPTModel"),$ca.forEach(t),fOr=r(mZe," (OPT model)"),mZe.forEach(t),gOr=i(I),F0=n(I,"LI",{});var cZe=s(F0);A8e=n(cZe,"STRONG",{});var kca=s(A8e);hOr=r(kca,"pegasus"),kca.forEach(t),uOr=r(cZe," \u2014 "),nte=n(cZe,"A",{href:!0});var Sca=s(nte);pOr=r(Sca,"TFPegasusModel"),Sca.forEach(t),_Or=r(cZe," (Pegasus model)"),cZe.forEach(t),bOr=i(I),T0=n(I,"LI",{});var fZe=s(T0);L8e=n(fZe,"STRONG",{});var Rca=s(L8e);vOr=r(Rca,"regnet"),Rca.forEach(t),FOr=r(fZe," \u2014 "),ste=n(fZe,"A",{href:!0});var Pca=s(ste);TOr=r(Pca,"TFRegNetModel"),Pca.forEach(t),MOr=r(fZe," (RegNet model)"),fZe.forEach(t),EOr=i(I),M0=n(I,"LI",{});var gZe=s(M0);y8e=n(gZe,"STRONG",{});var Bca=s(y8e);COr=r(Bca,"rembert"),Bca.forEach(t),wOr=r(gZe," \u2014 "),lte=n(gZe,"A",{href:!0});var Ica=s(lte);AOr=r(Ica,"TFRemBertModel"),Ica.forEach(t),LOr=r(gZe," (RemBERT model)"),gZe.forEach(t),yOr=i(I),E0=n(I,"LI",{});var hZe=s(E0);x8e=n(hZe,"STRONG",{});var Nca=s(x8e);xOr=r(Nca,"resnet"),Nca.forEach(t),$Or=r(hZe," \u2014 "),ite=n(hZe,"A",{href:!0});var qca=s(ite);kOr=r(qca,"TFResNetModel"),qca.forEach(t),SOr=r(hZe," (ResNet model)"),hZe.forEach(t),ROr=i(I),C0=n(I,"LI",{});var uZe=s(C0);$8e=n(uZe,"STRONG",{});var jca=s($8e);POr=r(jca,"roberta"),jca.forEach(t),BOr=r(uZe," \u2014 "),dte=n(uZe,"A",{href:!0});var Dca=s(dte);IOr=r(Dca,"TFRobertaModel"),Dca.forEach(t),NOr=r(uZe," (RoBERTa model)"),uZe.forEach(t),qOr=i(I),w0=n(I,"LI",{});var pZe=s(w0);k8e=n(pZe,"STRONG",{});var Gca=s(k8e);jOr=r(Gca,"roformer"),Gca.forEach(t),DOr=r(pZe," \u2014 "),mte=n(pZe,"A",{href:!0});var Oca=s(mte);GOr=r(Oca,"TFRoFormerModel"),Oca.forEach(t),OOr=r(pZe," (RoFormer model)"),pZe.forEach(t),VOr=i(I),A0=n(I,"LI",{});var _Ze=s(A0);S8e=n(_Ze,"STRONG",{});var Vca=s(S8e);XOr=r(Vca,"segformer"),Vca.forEach(t),zOr=r(_Ze," \u2014 "),cte=n(_Ze,"A",{href:!0});var Xca=s(cte);QOr=r(Xca,"TFSegformerModel"),Xca.forEach(t),WOr=r(_Ze," (SegFormer model)"),_Ze.forEach(t),UOr=i(I),L0=n(I,"LI",{});var bZe=s(L0);R8e=n(bZe,"STRONG",{});var zca=s(R8e);HOr=r(zca,"speech_to_text"),zca.forEach(t),JOr=r(bZe," \u2014 "),fte=n(bZe,"A",{href:!0});var Qca=s(fte);YOr=r(Qca,"TFSpeech2TextModel"),Qca.forEach(t),ZOr=r(bZe," (Speech2Text model)"),bZe.forEach(t),KOr=i(I),y0=n(I,"LI",{});var vZe=s(y0);P8e=n(vZe,"STRONG",{});var Wca=s(P8e);eVr=r(Wca,"swin"),Wca.forEach(t),oVr=r(vZe," \u2014 "),gte=n(vZe,"A",{href:!0});var Uca=s(gte);rVr=r(Uca,"TFSwinModel"),Uca.forEach(t),tVr=r(vZe," (Swin Transformer model)"),vZe.forEach(t),aVr=i(I),x0=n(I,"LI",{});var FZe=s(x0);B8e=n(FZe,"STRONG",{});var Hca=s(B8e);nVr=r(Hca,"t5"),Hca.forEach(t),sVr=r(FZe," \u2014 "),hte=n(FZe,"A",{href:!0});var Jca=s(hte);lVr=r(Jca,"TFT5Model"),Jca.forEach(t),iVr=r(FZe," (T5 model)"),FZe.forEach(t),dVr=i(I),$0=n(I,"LI",{});var TZe=s($0);I8e=n(TZe,"STRONG",{});var Yca=s(I8e);mVr=r(Yca,"tapas"),Yca.forEach(t),cVr=r(TZe," \u2014 "),ute=n(TZe,"A",{href:!0});var Zca=s(ute);fVr=r(Zca,"TFTapasModel"),Zca.forEach(t),gVr=r(TZe," (TAPAS model)"),TZe.forEach(t),hVr=i(I),k0=n(I,"LI",{});var MZe=s(k0);N8e=n(MZe,"STRONG",{});var Kca=s(N8e);uVr=r(Kca,"transfo-xl"),Kca.forEach(t),pVr=r(MZe," \u2014 "),pte=n(MZe,"A",{href:!0});var efa=s(pte);_Vr=r(efa,"TFTransfoXLModel"),efa.forEach(t),bVr=r(MZe," (Transformer-XL model)"),MZe.forEach(t),vVr=i(I),S0=n(I,"LI",{});var EZe=s(S0);q8e=n(EZe,"STRONG",{});var ofa=s(q8e);FVr=r(ofa,"vit"),ofa.forEach(t),TVr=r(EZe," \u2014 "),_te=n(EZe,"A",{href:!0});var rfa=s(_te);MVr=r(rfa,"TFViTModel"),rfa.forEach(t),EVr=r(EZe," (ViT model)"),EZe.forEach(t),CVr=i(I),R0=n(I,"LI",{});var CZe=s(R0);j8e=n(CZe,"STRONG",{});var tfa=s(j8e);wVr=r(tfa,"vit_mae"),tfa.forEach(t),AVr=r(CZe," \u2014 "),bte=n(CZe,"A",{href:!0});var afa=s(bte);LVr=r(afa,"TFViTMAEModel"),afa.forEach(t),yVr=r(CZe," (ViTMAE model)"),CZe.forEach(t),xVr=i(I),P0=n(I,"LI",{});var wZe=s(P0);D8e=n(wZe,"STRONG",{});var nfa=s(D8e);$Vr=r(nfa,"wav2vec2"),nfa.forEach(t),kVr=r(wZe," \u2014 "),vte=n(wZe,"A",{href:!0});var sfa=s(vte);SVr=r(sfa,"TFWav2Vec2Model"),sfa.forEach(t),RVr=r(wZe," (Wav2Vec2 model)"),wZe.forEach(t),PVr=i(I),B0=n(I,"LI",{});var AZe=s(B0);G8e=n(AZe,"STRONG",{});var lfa=s(G8e);BVr=r(lfa,"whisper"),lfa.forEach(t),IVr=r(AZe," \u2014 "),Fte=n(AZe,"A",{href:!0});var ifa=s(Fte);NVr=r(ifa,"TFWhisperModel"),ifa.forEach(t),qVr=r(AZe," (Whisper model)"),AZe.forEach(t),jVr=i(I),I0=n(I,"LI",{});var LZe=s(I0);O8e=n(LZe,"STRONG",{});var dfa=s(O8e);DVr=r(dfa,"xglm"),dfa.forEach(t),GVr=r(LZe," \u2014 "),Tte=n(LZe,"A",{href:!0});var mfa=s(Tte);OVr=r(mfa,"TFXGLMModel"),mfa.forEach(t),VVr=r(LZe," (XGLM model)"),LZe.forEach(t),XVr=i(I),N0=n(I,"LI",{});var yZe=s(N0);V8e=n(yZe,"STRONG",{});var cfa=s(V8e);zVr=r(cfa,"xlm"),cfa.forEach(t),QVr=r(yZe," \u2014 "),Mte=n(yZe,"A",{href:!0});var ffa=s(Mte);WVr=r(ffa,"TFXLMModel"),ffa.forEach(t),UVr=r(yZe," (XLM model)"),yZe.forEach(t),HVr=i(I),q0=n(I,"LI",{});var xZe=s(q0);X8e=n(xZe,"STRONG",{});var gfa=s(X8e);JVr=r(gfa,"xlm-roberta"),gfa.forEach(t),YVr=r(xZe," \u2014 "),Ete=n(xZe,"A",{href:!0});var hfa=s(Ete);ZVr=r(hfa,"TFXLMRobertaModel"),hfa.forEach(t),KVr=r(xZe," (XLM-RoBERTa model)"),xZe.forEach(t),eXr=i(I),j0=n(I,"LI",{});var $Ze=s(j0);z8e=n($Ze,"STRONG",{});var ufa=s(z8e);oXr=r(ufa,"xlnet"),ufa.forEach(t),rXr=r($Ze," \u2014 "),Cte=n($Ze,"A",{href:!0});var pfa=s(Cte);tXr=r(pfa,"TFXLNetModel"),pfa.forEach(t),aXr=r($Ze," (XLNet model)"),$Ze.forEach(t),I.forEach(t),nXr=i(bi),T(D0.$$.fragment,bi),bi.forEach(t),_i.forEach(t),dno=i(c),hc=n(c,"H2",{class:!0});var ylo=s(hc);G0=n(ylo,"A",{id:!0,class:!0,href:!0});var _fa=s(G0);Q8e=n(_fa,"SPAN",{});var bfa=s(Q8e);T(CR.$$.fragment,bfa),bfa.forEach(t),_fa.forEach(t),sXr=i(ylo),W8e=n(ylo,"SPAN",{});var vfa=s(W8e);lXr=r(vfa,"TFAutoModelForPreTraining"),vfa.forEach(t),ylo.forEach(t),mno=i(c),cr=n(c,"DIV",{class:!0});var vi=s(cr);T(wR.$$.fragment,vi),iXr=i(vi),uc=n(vi,"P",{});var Mce=s(uc);dXr=r(Mce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),wte=n(Mce,"A",{href:!0});var Ffa=s(wte);mXr=r(Ffa,"from_pretrained()"),Ffa.forEach(t),cXr=r(Mce," class method or the "),Ate=n(Mce,"A",{href:!0});var Tfa=s(Ate);fXr=r(Tfa,"from_config()"),Tfa.forEach(t),gXr=r(Mce,` class
method.`),Mce.forEach(t),hXr=i(vi),AR=n(vi,"P",{});var xlo=s(AR);uXr=r(xlo,"This class cannot be instantiated directly using "),U8e=n(xlo,"CODE",{});var Mfa=s(U8e);pXr=r(Mfa,"__init__()"),Mfa.forEach(t),_Xr=r(xlo," (throws an error)."),xlo.forEach(t),bXr=i(vi),Zt=n(vi,"DIV",{class:!0});var mx=s(Zt);T(LR.$$.fragment,mx),vXr=i(mx),H8e=n(mx,"P",{});var Efa=s(H8e);FXr=r(Efa,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Efa.forEach(t),TXr=i(mx),pc=n(mx,"P",{});var Ece=s(pc);MXr=r(Ece,`Note:
Loading a model from its configuration file does `),J8e=n(Ece,"STRONG",{});var Cfa=s(J8e);EXr=r(Cfa,"not"),Cfa.forEach(t),CXr=r(Ece,` load the model weights. It only affects the
model\u2019s configuration. Use `),Lte=n(Ece,"A",{href:!0});var wfa=s(Lte);wXr=r(wfa,"from_pretrained()"),wfa.forEach(t),AXr=r(Ece," to load the model weights."),Ece.forEach(t),LXr=i(mx),T(O0.$$.fragment,mx),mx.forEach(t),yXr=i(vi),Gr=n(vi,"DIV",{class:!0});var Fi=s(Gr);T(yR.$$.fragment,Fi),xXr=i(Fi),Y8e=n(Fi,"P",{});var Afa=s(Y8e);$Xr=r(Afa,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Afa.forEach(t),kXr=i(Fi),In=n(Fi,"P",{});var cx=s(In);SXr=r(cx,"The model class to instantiate is selected based on the "),Z8e=n(cx,"CODE",{});var Lfa=s(Z8e);RXr=r(Lfa,"model_type"),Lfa.forEach(t),PXr=r(cx,` property of the config object (either
passed as an argument or loaded from `),K8e=n(cx,"CODE",{});var yfa=s(K8e);BXr=r(yfa,"pretrained_model_name_or_path"),yfa.forEach(t),IXr=r(cx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eLe=n(cx,"CODE",{});var xfa=s(eLe);NXr=r(xfa,"pretrained_model_name_or_path"),xfa.forEach(t),qXr=r(cx,":"),cx.forEach(t),jXr=i(Fi),le=n(Fi,"UL",{});var me=s(le);V0=n(me,"LI",{});var kZe=s(V0);oLe=n(kZe,"STRONG",{});var $fa=s(oLe);DXr=r($fa,"albert"),$fa.forEach(t),GXr=r(kZe," \u2014 "),yte=n(kZe,"A",{href:!0});var kfa=s(yte);OXr=r(kfa,"TFAlbertForPreTraining"),kfa.forEach(t),VXr=r(kZe," (ALBERT model)"),kZe.forEach(t),XXr=i(me),X0=n(me,"LI",{});var SZe=s(X0);rLe=n(SZe,"STRONG",{});var Sfa=s(rLe);zXr=r(Sfa,"bart"),Sfa.forEach(t),QXr=r(SZe," \u2014 "),xte=n(SZe,"A",{href:!0});var Rfa=s(xte);WXr=r(Rfa,"TFBartForConditionalGeneration"),Rfa.forEach(t),UXr=r(SZe," (BART model)"),SZe.forEach(t),HXr=i(me),z0=n(me,"LI",{});var RZe=s(z0);tLe=n(RZe,"STRONG",{});var Pfa=s(tLe);JXr=r(Pfa,"bert"),Pfa.forEach(t),YXr=r(RZe," \u2014 "),$te=n(RZe,"A",{href:!0});var Bfa=s($te);ZXr=r(Bfa,"TFBertForPreTraining"),Bfa.forEach(t),KXr=r(RZe," (BERT model)"),RZe.forEach(t),ezr=i(me),Q0=n(me,"LI",{});var PZe=s(Q0);aLe=n(PZe,"STRONG",{});var Ifa=s(aLe);ozr=r(Ifa,"camembert"),Ifa.forEach(t),rzr=r(PZe," \u2014 "),kte=n(PZe,"A",{href:!0});var Nfa=s(kte);tzr=r(Nfa,"TFCamembertForMaskedLM"),Nfa.forEach(t),azr=r(PZe," (CamemBERT model)"),PZe.forEach(t),nzr=i(me),W0=n(me,"LI",{});var BZe=s(W0);nLe=n(BZe,"STRONG",{});var qfa=s(nLe);szr=r(qfa,"ctrl"),qfa.forEach(t),lzr=r(BZe," \u2014 "),Ste=n(BZe,"A",{href:!0});var jfa=s(Ste);izr=r(jfa,"TFCTRLLMHeadModel"),jfa.forEach(t),dzr=r(BZe," (CTRL model)"),BZe.forEach(t),mzr=i(me),U0=n(me,"LI",{});var IZe=s(U0);sLe=n(IZe,"STRONG",{});var Dfa=s(sLe);czr=r(Dfa,"distilbert"),Dfa.forEach(t),fzr=r(IZe," \u2014 "),Rte=n(IZe,"A",{href:!0});var Gfa=s(Rte);gzr=r(Gfa,"TFDistilBertForMaskedLM"),Gfa.forEach(t),hzr=r(IZe," (DistilBERT model)"),IZe.forEach(t),uzr=i(me),H0=n(me,"LI",{});var NZe=s(H0);lLe=n(NZe,"STRONG",{});var Ofa=s(lLe);pzr=r(Ofa,"electra"),Ofa.forEach(t),_zr=r(NZe," \u2014 "),Pte=n(NZe,"A",{href:!0});var Vfa=s(Pte);bzr=r(Vfa,"TFElectraForPreTraining"),Vfa.forEach(t),vzr=r(NZe," (ELECTRA model)"),NZe.forEach(t),Fzr=i(me),J0=n(me,"LI",{});var qZe=s(J0);iLe=n(qZe,"STRONG",{});var Xfa=s(iLe);Tzr=r(Xfa,"flaubert"),Xfa.forEach(t),Mzr=r(qZe," \u2014 "),Bte=n(qZe,"A",{href:!0});var zfa=s(Bte);Ezr=r(zfa,"TFFlaubertWithLMHeadModel"),zfa.forEach(t),Czr=r(qZe," (FlauBERT model)"),qZe.forEach(t),wzr=i(me),Y0=n(me,"LI",{});var jZe=s(Y0);dLe=n(jZe,"STRONG",{});var Qfa=s(dLe);Azr=r(Qfa,"funnel"),Qfa.forEach(t),Lzr=r(jZe," \u2014 "),Ite=n(jZe,"A",{href:!0});var Wfa=s(Ite);yzr=r(Wfa,"TFFunnelForPreTraining"),Wfa.forEach(t),xzr=r(jZe," (Funnel Transformer model)"),jZe.forEach(t),$zr=i(me),Z0=n(me,"LI",{});var DZe=s(Z0);mLe=n(DZe,"STRONG",{});var Ufa=s(mLe);kzr=r(Ufa,"gpt2"),Ufa.forEach(t),Szr=r(DZe," \u2014 "),Nte=n(DZe,"A",{href:!0});var Hfa=s(Nte);Rzr=r(Hfa,"TFGPT2LMHeadModel"),Hfa.forEach(t),Pzr=r(DZe," (OpenAI GPT-2 model)"),DZe.forEach(t),Bzr=i(me),K0=n(me,"LI",{});var GZe=s(K0);cLe=n(GZe,"STRONG",{});var Jfa=s(cLe);Izr=r(Jfa,"layoutlm"),Jfa.forEach(t),Nzr=r(GZe," \u2014 "),qte=n(GZe,"A",{href:!0});var Yfa=s(qte);qzr=r(Yfa,"TFLayoutLMForMaskedLM"),Yfa.forEach(t),jzr=r(GZe," (LayoutLM model)"),GZe.forEach(t),Dzr=i(me),ew=n(me,"LI",{});var OZe=s(ew);fLe=n(OZe,"STRONG",{});var Zfa=s(fLe);Gzr=r(Zfa,"lxmert"),Zfa.forEach(t),Ozr=r(OZe," \u2014 "),jte=n(OZe,"A",{href:!0});var Kfa=s(jte);Vzr=r(Kfa,"TFLxmertForPreTraining"),Kfa.forEach(t),Xzr=r(OZe," (LXMERT model)"),OZe.forEach(t),zzr=i(me),ow=n(me,"LI",{});var VZe=s(ow);gLe=n(VZe,"STRONG",{});var ega=s(gLe);Qzr=r(ega,"mobilebert"),ega.forEach(t),Wzr=r(VZe," \u2014 "),Dte=n(VZe,"A",{href:!0});var oga=s(Dte);Uzr=r(oga,"TFMobileBertForPreTraining"),oga.forEach(t),Hzr=r(VZe," (MobileBERT model)"),VZe.forEach(t),Jzr=i(me),rw=n(me,"LI",{});var XZe=s(rw);hLe=n(XZe,"STRONG",{});var rga=s(hLe);Yzr=r(rga,"mpnet"),rga.forEach(t),Zzr=r(XZe," \u2014 "),Gte=n(XZe,"A",{href:!0});var tga=s(Gte);Kzr=r(tga,"TFMPNetForMaskedLM"),tga.forEach(t),eQr=r(XZe," (MPNet model)"),XZe.forEach(t),oQr=i(me),tw=n(me,"LI",{});var zZe=s(tw);uLe=n(zZe,"STRONG",{});var aga=s(uLe);rQr=r(aga,"openai-gpt"),aga.forEach(t),tQr=r(zZe," \u2014 "),Ote=n(zZe,"A",{href:!0});var nga=s(Ote);aQr=r(nga,"TFOpenAIGPTLMHeadModel"),nga.forEach(t),nQr=r(zZe," (OpenAI GPT model)"),zZe.forEach(t),sQr=i(me),aw=n(me,"LI",{});var QZe=s(aw);pLe=n(QZe,"STRONG",{});var sga=s(pLe);lQr=r(sga,"roberta"),sga.forEach(t),iQr=r(QZe," \u2014 "),Vte=n(QZe,"A",{href:!0});var lga=s(Vte);dQr=r(lga,"TFRobertaForMaskedLM"),lga.forEach(t),mQr=r(QZe," (RoBERTa model)"),QZe.forEach(t),cQr=i(me),nw=n(me,"LI",{});var WZe=s(nw);_Le=n(WZe,"STRONG",{});var iga=s(_Le);fQr=r(iga,"t5"),iga.forEach(t),gQr=r(WZe," \u2014 "),Xte=n(WZe,"A",{href:!0});var dga=s(Xte);hQr=r(dga,"TFT5ForConditionalGeneration"),dga.forEach(t),uQr=r(WZe," (T5 model)"),WZe.forEach(t),pQr=i(me),sw=n(me,"LI",{});var UZe=s(sw);bLe=n(UZe,"STRONG",{});var mga=s(bLe);_Qr=r(mga,"tapas"),mga.forEach(t),bQr=r(UZe," \u2014 "),zte=n(UZe,"A",{href:!0});var cga=s(zte);vQr=r(cga,"TFTapasForMaskedLM"),cga.forEach(t),FQr=r(UZe," (TAPAS model)"),UZe.forEach(t),TQr=i(me),lw=n(me,"LI",{});var HZe=s(lw);vLe=n(HZe,"STRONG",{});var fga=s(vLe);MQr=r(fga,"transfo-xl"),fga.forEach(t),EQr=r(HZe," \u2014 "),Qte=n(HZe,"A",{href:!0});var gga=s(Qte);CQr=r(gga,"TFTransfoXLLMHeadModel"),gga.forEach(t),wQr=r(HZe," (Transformer-XL model)"),HZe.forEach(t),AQr=i(me),iw=n(me,"LI",{});var JZe=s(iw);FLe=n(JZe,"STRONG",{});var hga=s(FLe);LQr=r(hga,"vit_mae"),hga.forEach(t),yQr=r(JZe," \u2014 "),Wte=n(JZe,"A",{href:!0});var uga=s(Wte);xQr=r(uga,"TFViTMAEForPreTraining"),uga.forEach(t),$Qr=r(JZe," (ViTMAE model)"),JZe.forEach(t),kQr=i(me),dw=n(me,"LI",{});var YZe=s(dw);TLe=n(YZe,"STRONG",{});var pga=s(TLe);SQr=r(pga,"xlm"),pga.forEach(t),RQr=r(YZe," \u2014 "),Ute=n(YZe,"A",{href:!0});var _ga=s(Ute);PQr=r(_ga,"TFXLMWithLMHeadModel"),_ga.forEach(t),BQr=r(YZe," (XLM model)"),YZe.forEach(t),IQr=i(me),mw=n(me,"LI",{});var ZZe=s(mw);MLe=n(ZZe,"STRONG",{});var bga=s(MLe);NQr=r(bga,"xlm-roberta"),bga.forEach(t),qQr=r(ZZe," \u2014 "),Hte=n(ZZe,"A",{href:!0});var vga=s(Hte);jQr=r(vga,"TFXLMRobertaForMaskedLM"),vga.forEach(t),DQr=r(ZZe," (XLM-RoBERTa model)"),ZZe.forEach(t),GQr=i(me),cw=n(me,"LI",{});var KZe=s(cw);ELe=n(KZe,"STRONG",{});var Fga=s(ELe);OQr=r(Fga,"xlnet"),Fga.forEach(t),VQr=r(KZe," \u2014 "),Jte=n(KZe,"A",{href:!0});var Tga=s(Jte);XQr=r(Tga,"TFXLNetLMHeadModel"),Tga.forEach(t),zQr=r(KZe," (XLNet model)"),KZe.forEach(t),me.forEach(t),QQr=i(Fi),T(fw.$$.fragment,Fi),Fi.forEach(t),vi.forEach(t),cno=i(c),_c=n(c,"H2",{class:!0});var $lo=s(_c);gw=n($lo,"A",{id:!0,class:!0,href:!0});var Mga=s(gw);CLe=n(Mga,"SPAN",{});var Ega=s(CLe);T(xR.$$.fragment,Ega),Ega.forEach(t),Mga.forEach(t),WQr=i($lo),wLe=n($lo,"SPAN",{});var Cga=s(wLe);UQr=r(Cga,"TFAutoModelForCausalLM"),Cga.forEach(t),$lo.forEach(t),fno=i(c),fr=n(c,"DIV",{class:!0});var Ti=s(fr);T($R.$$.fragment,Ti),HQr=i(Ti),bc=n(Ti,"P",{});var Cce=s(bc);JQr=r(Cce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Yte=n(Cce,"A",{href:!0});var wga=s(Yte);YQr=r(wga,"from_pretrained()"),wga.forEach(t),ZQr=r(Cce," class method or the "),Zte=n(Cce,"A",{href:!0});var Aga=s(Zte);KQr=r(Aga,"from_config()"),Aga.forEach(t),eWr=r(Cce,` class
method.`),Cce.forEach(t),oWr=i(Ti),kR=n(Ti,"P",{});var klo=s(kR);rWr=r(klo,"This class cannot be instantiated directly using "),ALe=n(klo,"CODE",{});var Lga=s(ALe);tWr=r(Lga,"__init__()"),Lga.forEach(t),aWr=r(klo," (throws an error)."),klo.forEach(t),nWr=i(Ti),Kt=n(Ti,"DIV",{class:!0});var fx=s(Kt);T(SR.$$.fragment,fx),sWr=i(fx),LLe=n(fx,"P",{});var yga=s(LLe);lWr=r(yga,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),yga.forEach(t),iWr=i(fx),vc=n(fx,"P",{});var wce=s(vc);dWr=r(wce,`Note:
Loading a model from its configuration file does `),yLe=n(wce,"STRONG",{});var xga=s(yLe);mWr=r(xga,"not"),xga.forEach(t),cWr=r(wce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Kte=n(wce,"A",{href:!0});var $ga=s(Kte);fWr=r($ga,"from_pretrained()"),$ga.forEach(t),gWr=r(wce," to load the model weights."),wce.forEach(t),hWr=i(fx),T(hw.$$.fragment,fx),fx.forEach(t),uWr=i(Ti),Or=n(Ti,"DIV",{class:!0});var Mi=s(Or);T(RR.$$.fragment,Mi),pWr=i(Mi),xLe=n(Mi,"P",{});var kga=s(xLe);_Wr=r(kga,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),kga.forEach(t),bWr=i(Mi),Nn=n(Mi,"P",{});var gx=s(Nn);vWr=r(gx,"The model class to instantiate is selected based on the "),$Le=n(gx,"CODE",{});var Sga=s($Le);FWr=r(Sga,"model_type"),Sga.forEach(t),TWr=r(gx,` property of the config object (either
passed as an argument or loaded from `),kLe=n(gx,"CODE",{});var Rga=s(kLe);MWr=r(Rga,"pretrained_model_name_or_path"),Rga.forEach(t),EWr=r(gx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SLe=n(gx,"CODE",{});var Pga=s(SLe);CWr=r(Pga,"pretrained_model_name_or_path"),Pga.forEach(t),wWr=r(gx,":"),gx.forEach(t),AWr=i(Mi),Me=n(Mi,"UL",{});var Ce=s(Me);uw=n(Ce,"LI",{});var eKe=s(uw);RLe=n(eKe,"STRONG",{});var Bga=s(RLe);LWr=r(Bga,"bert"),Bga.forEach(t),yWr=r(eKe," \u2014 "),eae=n(eKe,"A",{href:!0});var Iga=s(eae);xWr=r(Iga,"TFBertLMHeadModel"),Iga.forEach(t),$Wr=r(eKe," (BERT model)"),eKe.forEach(t),kWr=i(Ce),pw=n(Ce,"LI",{});var oKe=s(pw);PLe=n(oKe,"STRONG",{});var Nga=s(PLe);SWr=r(Nga,"camembert"),Nga.forEach(t),RWr=r(oKe," \u2014 "),oae=n(oKe,"A",{href:!0});var qga=s(oae);PWr=r(qga,"TFCamembertForCausalLM"),qga.forEach(t),BWr=r(oKe," (CamemBERT model)"),oKe.forEach(t),IWr=i(Ce),_w=n(Ce,"LI",{});var rKe=s(_w);BLe=n(rKe,"STRONG",{});var jga=s(BLe);NWr=r(jga,"ctrl"),jga.forEach(t),qWr=r(rKe," \u2014 "),rae=n(rKe,"A",{href:!0});var Dga=s(rae);jWr=r(Dga,"TFCTRLLMHeadModel"),Dga.forEach(t),DWr=r(rKe," (CTRL model)"),rKe.forEach(t),GWr=i(Ce),bw=n(Ce,"LI",{});var tKe=s(bw);ILe=n(tKe,"STRONG",{});var Gga=s(ILe);OWr=r(Gga,"gpt2"),Gga.forEach(t),VWr=r(tKe," \u2014 "),tae=n(tKe,"A",{href:!0});var Oga=s(tae);XWr=r(Oga,"TFGPT2LMHeadModel"),Oga.forEach(t),zWr=r(tKe," (OpenAI GPT-2 model)"),tKe.forEach(t),QWr=i(Ce),vw=n(Ce,"LI",{});var aKe=s(vw);NLe=n(aKe,"STRONG",{});var Vga=s(NLe);WWr=r(Vga,"gptj"),Vga.forEach(t),UWr=r(aKe," \u2014 "),aae=n(aKe,"A",{href:!0});var Xga=s(aae);HWr=r(Xga,"TFGPTJForCausalLM"),Xga.forEach(t),JWr=r(aKe," (GPT-J model)"),aKe.forEach(t),YWr=i(Ce),Fw=n(Ce,"LI",{});var nKe=s(Fw);qLe=n(nKe,"STRONG",{});var zga=s(qLe);ZWr=r(zga,"openai-gpt"),zga.forEach(t),KWr=r(nKe," \u2014 "),nae=n(nKe,"A",{href:!0});var Qga=s(nae);eUr=r(Qga,"TFOpenAIGPTLMHeadModel"),Qga.forEach(t),oUr=r(nKe," (OpenAI GPT model)"),nKe.forEach(t),rUr=i(Ce),Tw=n(Ce,"LI",{});var sKe=s(Tw);jLe=n(sKe,"STRONG",{});var Wga=s(jLe);tUr=r(Wga,"opt"),Wga.forEach(t),aUr=r(sKe," \u2014 "),sae=n(sKe,"A",{href:!0});var Uga=s(sae);nUr=r(Uga,"TFOPTForCausalLM"),Uga.forEach(t),sUr=r(sKe," (OPT model)"),sKe.forEach(t),lUr=i(Ce),Mw=n(Ce,"LI",{});var lKe=s(Mw);DLe=n(lKe,"STRONG",{});var Hga=s(DLe);iUr=r(Hga,"rembert"),Hga.forEach(t),dUr=r(lKe," \u2014 "),lae=n(lKe,"A",{href:!0});var Jga=s(lae);mUr=r(Jga,"TFRemBertForCausalLM"),Jga.forEach(t),cUr=r(lKe," (RemBERT model)"),lKe.forEach(t),fUr=i(Ce),Ew=n(Ce,"LI",{});var iKe=s(Ew);GLe=n(iKe,"STRONG",{});var Yga=s(GLe);gUr=r(Yga,"roberta"),Yga.forEach(t),hUr=r(iKe," \u2014 "),iae=n(iKe,"A",{href:!0});var Zga=s(iae);uUr=r(Zga,"TFRobertaForCausalLM"),Zga.forEach(t),pUr=r(iKe," (RoBERTa model)"),iKe.forEach(t),_Ur=i(Ce),Cw=n(Ce,"LI",{});var dKe=s(Cw);OLe=n(dKe,"STRONG",{});var Kga=s(OLe);bUr=r(Kga,"roformer"),Kga.forEach(t),vUr=r(dKe," \u2014 "),dae=n(dKe,"A",{href:!0});var eha=s(dae);FUr=r(eha,"TFRoFormerForCausalLM"),eha.forEach(t),TUr=r(dKe," (RoFormer model)"),dKe.forEach(t),MUr=i(Ce),ww=n(Ce,"LI",{});var mKe=s(ww);VLe=n(mKe,"STRONG",{});var oha=s(VLe);EUr=r(oha,"transfo-xl"),oha.forEach(t),CUr=r(mKe," \u2014 "),mae=n(mKe,"A",{href:!0});var rha=s(mae);wUr=r(rha,"TFTransfoXLLMHeadModel"),rha.forEach(t),AUr=r(mKe," (Transformer-XL model)"),mKe.forEach(t),LUr=i(Ce),Aw=n(Ce,"LI",{});var cKe=s(Aw);XLe=n(cKe,"STRONG",{});var tha=s(XLe);yUr=r(tha,"xglm"),tha.forEach(t),xUr=r(cKe," \u2014 "),cae=n(cKe,"A",{href:!0});var aha=s(cae);$Ur=r(aha,"TFXGLMForCausalLM"),aha.forEach(t),kUr=r(cKe," (XGLM model)"),cKe.forEach(t),SUr=i(Ce),Lw=n(Ce,"LI",{});var fKe=s(Lw);zLe=n(fKe,"STRONG",{});var nha=s(zLe);RUr=r(nha,"xlm"),nha.forEach(t),PUr=r(fKe," \u2014 "),fae=n(fKe,"A",{href:!0});var sha=s(fae);BUr=r(sha,"TFXLMWithLMHeadModel"),sha.forEach(t),IUr=r(fKe," (XLM model)"),fKe.forEach(t),NUr=i(Ce),yw=n(Ce,"LI",{});var gKe=s(yw);QLe=n(gKe,"STRONG",{});var lha=s(QLe);qUr=r(lha,"xlnet"),lha.forEach(t),jUr=r(gKe," \u2014 "),gae=n(gKe,"A",{href:!0});var iha=s(gae);DUr=r(iha,"TFXLNetLMHeadModel"),iha.forEach(t),GUr=r(gKe," (XLNet model)"),gKe.forEach(t),Ce.forEach(t),OUr=i(Mi),T(xw.$$.fragment,Mi),Mi.forEach(t),Ti.forEach(t),gno=i(c),Fc=n(c,"H2",{class:!0});var Slo=s(Fc);$w=n(Slo,"A",{id:!0,class:!0,href:!0});var dha=s($w);WLe=n(dha,"SPAN",{});var mha=s(WLe);T(PR.$$.fragment,mha),mha.forEach(t),dha.forEach(t),VUr=i(Slo),ULe=n(Slo,"SPAN",{});var cha=s(ULe);XUr=r(cha,"TFAutoModelForImageClassification"),cha.forEach(t),Slo.forEach(t),hno=i(c),gr=n(c,"DIV",{class:!0});var Ei=s(gr);T(BR.$$.fragment,Ei),zUr=i(Ei),Tc=n(Ei,"P",{});var Ace=s(Tc);QUr=r(Ace,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),hae=n(Ace,"A",{href:!0});var fha=s(hae);WUr=r(fha,"from_pretrained()"),fha.forEach(t),UUr=r(Ace," class method or the "),uae=n(Ace,"A",{href:!0});var gha=s(uae);HUr=r(gha,"from_config()"),gha.forEach(t),JUr=r(Ace,` class
method.`),Ace.forEach(t),YUr=i(Ei),IR=n(Ei,"P",{});var Rlo=s(IR);ZUr=r(Rlo,"This class cannot be instantiated directly using "),HLe=n(Rlo,"CODE",{});var hha=s(HLe);KUr=r(hha,"__init__()"),hha.forEach(t),eHr=r(Rlo," (throws an error)."),Rlo.forEach(t),oHr=i(Ei),ea=n(Ei,"DIV",{class:!0});var hx=s(ea);T(NR.$$.fragment,hx),rHr=i(hx),JLe=n(hx,"P",{});var uha=s(JLe);tHr=r(uha,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),uha.forEach(t),aHr=i(hx),Mc=n(hx,"P",{});var Lce=s(Mc);nHr=r(Lce,`Note:
Loading a model from its configuration file does `),YLe=n(Lce,"STRONG",{});var pha=s(YLe);sHr=r(pha,"not"),pha.forEach(t),lHr=r(Lce,` load the model weights. It only affects the
model\u2019s configuration. Use `),pae=n(Lce,"A",{href:!0});var _ha=s(pae);iHr=r(_ha,"from_pretrained()"),_ha.forEach(t),dHr=r(Lce," to load the model weights."),Lce.forEach(t),mHr=i(hx),T(kw.$$.fragment,hx),hx.forEach(t),cHr=i(Ei),Vr=n(Ei,"DIV",{class:!0});var Ci=s(Vr);T(qR.$$.fragment,Ci),fHr=i(Ci),ZLe=n(Ci,"P",{});var bha=s(ZLe);gHr=r(bha,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),bha.forEach(t),hHr=i(Ci),qn=n(Ci,"P",{});var ux=s(qn);uHr=r(ux,"The model class to instantiate is selected based on the "),KLe=n(ux,"CODE",{});var vha=s(KLe);pHr=r(vha,"model_type"),vha.forEach(t),_Hr=r(ux,` property of the config object (either
passed as an argument or loaded from `),eye=n(ux,"CODE",{});var Fha=s(eye);bHr=r(Fha,"pretrained_model_name_or_path"),Fha.forEach(t),vHr=r(ux,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oye=n(ux,"CODE",{});var Tha=s(oye);FHr=r(Tha,"pretrained_model_name_or_path"),Tha.forEach(t),THr=r(ux,":"),ux.forEach(t),MHr=i(Ci),ye=n(Ci,"UL",{});var Ne=s(ye);Sw=n(Ne,"LI",{});var hKe=s(Sw);rye=n(hKe,"STRONG",{});var Mha=s(rye);EHr=r(Mha,"convnext"),Mha.forEach(t),CHr=r(hKe," \u2014 "),_ae=n(hKe,"A",{href:!0});var Eha=s(_ae);wHr=r(Eha,"TFConvNextForImageClassification"),Eha.forEach(t),AHr=r(hKe," (ConvNeXT model)"),hKe.forEach(t),LHr=i(Ne),Rw=n(Ne,"LI",{});var uKe=s(Rw);tye=n(uKe,"STRONG",{});var Cha=s(tye);yHr=r(Cha,"cvt"),Cha.forEach(t),xHr=r(uKe," \u2014 "),bae=n(uKe,"A",{href:!0});var wha=s(bae);$Hr=r(wha,"TFCvtForImageClassification"),wha.forEach(t),kHr=r(uKe," (CvT model)"),uKe.forEach(t),SHr=i(Ne),Pw=n(Ne,"LI",{});var pKe=s(Pw);aye=n(pKe,"STRONG",{});var Aha=s(aye);RHr=r(Aha,"data2vec-vision"),Aha.forEach(t),PHr=r(pKe," \u2014 "),vae=n(pKe,"A",{href:!0});var Lha=s(vae);BHr=r(Lha,"TFData2VecVisionForImageClassification"),Lha.forEach(t),IHr=r(pKe," (Data2VecVision model)"),pKe.forEach(t),NHr=i(Ne),Pl=n(Ne,"LI",{});var LN=s(Pl);nye=n(LN,"STRONG",{});var yha=s(nye);qHr=r(yha,"deit"),yha.forEach(t),jHr=r(LN," \u2014 "),Fae=n(LN,"A",{href:!0});var xha=s(Fae);DHr=r(xha,"TFDeiTForImageClassification"),xha.forEach(t),GHr=r(LN," or "),Tae=n(LN,"A",{href:!0});var $ha=s(Tae);OHr=r($ha,"TFDeiTForImageClassificationWithTeacher"),$ha.forEach(t),VHr=r(LN," (DeiT model)"),LN.forEach(t),XHr=i(Ne),Bw=n(Ne,"LI",{});var _Ke=s(Bw);sye=n(_Ke,"STRONG",{});var kha=s(sye);zHr=r(kha,"mobilevit"),kha.forEach(t),QHr=r(_Ke," \u2014 "),Mae=n(_Ke,"A",{href:!0});var Sha=s(Mae);WHr=r(Sha,"TFMobileViTForImageClassification"),Sha.forEach(t),UHr=r(_Ke," (MobileViT model)"),_Ke.forEach(t),HHr=i(Ne),Iw=n(Ne,"LI",{});var bKe=s(Iw);lye=n(bKe,"STRONG",{});var Rha=s(lye);JHr=r(Rha,"regnet"),Rha.forEach(t),YHr=r(bKe," \u2014 "),Eae=n(bKe,"A",{href:!0});var Pha=s(Eae);ZHr=r(Pha,"TFRegNetForImageClassification"),Pha.forEach(t),KHr=r(bKe," (RegNet model)"),bKe.forEach(t),eJr=i(Ne),Nw=n(Ne,"LI",{});var vKe=s(Nw);iye=n(vKe,"STRONG",{});var Bha=s(iye);oJr=r(Bha,"resnet"),Bha.forEach(t),rJr=r(vKe," \u2014 "),Cae=n(vKe,"A",{href:!0});var Iha=s(Cae);tJr=r(Iha,"TFResNetForImageClassification"),Iha.forEach(t),aJr=r(vKe," (ResNet model)"),vKe.forEach(t),nJr=i(Ne),qw=n(Ne,"LI",{});var FKe=s(qw);dye=n(FKe,"STRONG",{});var Nha=s(dye);sJr=r(Nha,"segformer"),Nha.forEach(t),lJr=r(FKe," \u2014 "),wae=n(FKe,"A",{href:!0});var qha=s(wae);iJr=r(qha,"TFSegformerForImageClassification"),qha.forEach(t),dJr=r(FKe," (SegFormer model)"),FKe.forEach(t),mJr=i(Ne),jw=n(Ne,"LI",{});var TKe=s(jw);mye=n(TKe,"STRONG",{});var jha=s(mye);cJr=r(jha,"swin"),jha.forEach(t),fJr=r(TKe," \u2014 "),Aae=n(TKe,"A",{href:!0});var Dha=s(Aae);gJr=r(Dha,"TFSwinForImageClassification"),Dha.forEach(t),hJr=r(TKe," (Swin Transformer model)"),TKe.forEach(t),uJr=i(Ne),Dw=n(Ne,"LI",{});var MKe=s(Dw);cye=n(MKe,"STRONG",{});var Gha=s(cye);pJr=r(Gha,"vit"),Gha.forEach(t),_Jr=r(MKe," \u2014 "),Lae=n(MKe,"A",{href:!0});var Oha=s(Lae);bJr=r(Oha,"TFViTForImageClassification"),Oha.forEach(t),vJr=r(MKe," (ViT model)"),MKe.forEach(t),Ne.forEach(t),FJr=i(Ci),T(Gw.$$.fragment,Ci),Ci.forEach(t),Ei.forEach(t),uno=i(c),Ec=n(c,"H2",{class:!0});var Plo=s(Ec);Ow=n(Plo,"A",{id:!0,class:!0,href:!0});var Vha=s(Ow);fye=n(Vha,"SPAN",{});var Xha=s(fye);T(jR.$$.fragment,Xha),Xha.forEach(t),Vha.forEach(t),TJr=i(Plo),gye=n(Plo,"SPAN",{});var zha=s(gye);MJr=r(zha,"TFAutoModelForSemanticSegmentation"),zha.forEach(t),Plo.forEach(t),pno=i(c),hr=n(c,"DIV",{class:!0});var wi=s(hr);T(DR.$$.fragment,wi),EJr=i(wi),Cc=n(wi,"P",{});var yce=s(Cc);CJr=r(yce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),yae=n(yce,"A",{href:!0});var Qha=s(yae);wJr=r(Qha,"from_pretrained()"),Qha.forEach(t),AJr=r(yce," class method or the "),xae=n(yce,"A",{href:!0});var Wha=s(xae);LJr=r(Wha,"from_config()"),Wha.forEach(t),yJr=r(yce,` class
method.`),yce.forEach(t),xJr=i(wi),GR=n(wi,"P",{});var Blo=s(GR);$Jr=r(Blo,"This class cannot be instantiated directly using "),hye=n(Blo,"CODE",{});var Uha=s(hye);kJr=r(Uha,"__init__()"),Uha.forEach(t),SJr=r(Blo," (throws an error)."),Blo.forEach(t),RJr=i(wi),oa=n(wi,"DIV",{class:!0});var px=s(oa);T(OR.$$.fragment,px),PJr=i(px),uye=n(px,"P",{});var Hha=s(uye);BJr=r(Hha,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Hha.forEach(t),IJr=i(px),wc=n(px,"P",{});var xce=s(wc);NJr=r(xce,`Note:
Loading a model from its configuration file does `),pye=n(xce,"STRONG",{});var Jha=s(pye);qJr=r(Jha,"not"),Jha.forEach(t),jJr=r(xce,` load the model weights. It only affects the
model\u2019s configuration. Use `),$ae=n(xce,"A",{href:!0});var Yha=s($ae);DJr=r(Yha,"from_pretrained()"),Yha.forEach(t),GJr=r(xce," to load the model weights."),xce.forEach(t),OJr=i(px),T(Vw.$$.fragment,px),px.forEach(t),VJr=i(wi),Xr=n(wi,"DIV",{class:!0});var Ai=s(Xr);T(VR.$$.fragment,Ai),XJr=i(Ai),_ye=n(Ai,"P",{});var Zha=s(_ye);zJr=r(Zha,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Zha.forEach(t),QJr=i(Ai),jn=n(Ai,"P",{});var _x=s(jn);WJr=r(_x,"The model class to instantiate is selected based on the "),bye=n(_x,"CODE",{});var Kha=s(bye);UJr=r(Kha,"model_type"),Kha.forEach(t),HJr=r(_x,` property of the config object (either
passed as an argument or loaded from `),vye=n(_x,"CODE",{});var eua=s(vye);JJr=r(eua,"pretrained_model_name_or_path"),eua.forEach(t),YJr=r(_x,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fye=n(_x,"CODE",{});var oua=s(Fye);ZJr=r(oua,"pretrained_model_name_or_path"),oua.forEach(t),KJr=r(_x,":"),_x.forEach(t),eYr=i(Ai),Ac=n(Ai,"UL",{});var $ce=s(Ac);Xw=n($ce,"LI",{});var EKe=s(Xw);Tye=n(EKe,"STRONG",{});var rua=s(Tye);oYr=r(rua,"data2vec-vision"),rua.forEach(t),rYr=r(EKe," \u2014 "),kae=n(EKe,"A",{href:!0});var tua=s(kae);tYr=r(tua,"TFData2VecVisionForSemanticSegmentation"),tua.forEach(t),aYr=r(EKe," (Data2VecVision model)"),EKe.forEach(t),nYr=i($ce),zw=n($ce,"LI",{});var CKe=s(zw);Mye=n(CKe,"STRONG",{});var aua=s(Mye);sYr=r(aua,"mobilevit"),aua.forEach(t),lYr=r(CKe," \u2014 "),Sae=n(CKe,"A",{href:!0});var nua=s(Sae);iYr=r(nua,"TFMobileViTForSemanticSegmentation"),nua.forEach(t),dYr=r(CKe," (MobileViT model)"),CKe.forEach(t),mYr=i($ce),Qw=n($ce,"LI",{});var wKe=s(Qw);Eye=n(wKe,"STRONG",{});var sua=s(Eye);cYr=r(sua,"segformer"),sua.forEach(t),fYr=r(wKe," \u2014 "),Rae=n(wKe,"A",{href:!0});var lua=s(Rae);gYr=r(lua,"TFSegformerForSemanticSegmentation"),lua.forEach(t),hYr=r(wKe," (SegFormer model)"),wKe.forEach(t),$ce.forEach(t),uYr=i(Ai),T(Ww.$$.fragment,Ai),Ai.forEach(t),wi.forEach(t),_no=i(c),Lc=n(c,"H2",{class:!0});var Ilo=s(Lc);Uw=n(Ilo,"A",{id:!0,class:!0,href:!0});var iua=s(Uw);Cye=n(iua,"SPAN",{});var dua=s(Cye);T(XR.$$.fragment,dua),dua.forEach(t),iua.forEach(t),pYr=i(Ilo),wye=n(Ilo,"SPAN",{});var mua=s(wye);_Yr=r(mua,"TFAutoModelForMaskedLM"),mua.forEach(t),Ilo.forEach(t),bno=i(c),ur=n(c,"DIV",{class:!0});var Li=s(ur);T(zR.$$.fragment,Li),bYr=i(Li),yc=n(Li,"P",{});var kce=s(yc);vYr=r(kce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Pae=n(kce,"A",{href:!0});var cua=s(Pae);FYr=r(cua,"from_pretrained()"),cua.forEach(t),TYr=r(kce," class method or the "),Bae=n(kce,"A",{href:!0});var fua=s(Bae);MYr=r(fua,"from_config()"),fua.forEach(t),EYr=r(kce,` class
method.`),kce.forEach(t),CYr=i(Li),QR=n(Li,"P",{});var Nlo=s(QR);wYr=r(Nlo,"This class cannot be instantiated directly using "),Aye=n(Nlo,"CODE",{});var gua=s(Aye);AYr=r(gua,"__init__()"),gua.forEach(t),LYr=r(Nlo," (throws an error)."),Nlo.forEach(t),yYr=i(Li),ra=n(Li,"DIV",{class:!0});var bx=s(ra);T(WR.$$.fragment,bx),xYr=i(bx),Lye=n(bx,"P",{});var hua=s(Lye);$Yr=r(hua,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),hua.forEach(t),kYr=i(bx),xc=n(bx,"P",{});var Sce=s(xc);SYr=r(Sce,`Note:
Loading a model from its configuration file does `),yye=n(Sce,"STRONG",{});var uua=s(yye);RYr=r(uua,"not"),uua.forEach(t),PYr=r(Sce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Iae=n(Sce,"A",{href:!0});var pua=s(Iae);BYr=r(pua,"from_pretrained()"),pua.forEach(t),IYr=r(Sce," to load the model weights."),Sce.forEach(t),NYr=i(bx),T(Hw.$$.fragment,bx),bx.forEach(t),qYr=i(Li),zr=n(Li,"DIV",{class:!0});var yi=s(zr);T(UR.$$.fragment,yi),jYr=i(yi),xye=n(yi,"P",{});var _ua=s(xye);DYr=r(_ua,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),_ua.forEach(t),GYr=i(yi),Dn=n(yi,"P",{});var vx=s(Dn);OYr=r(vx,"The model class to instantiate is selected based on the "),$ye=n(vx,"CODE",{});var bua=s($ye);VYr=r(bua,"model_type"),bua.forEach(t),XYr=r(vx,` property of the config object (either
passed as an argument or loaded from `),kye=n(vx,"CODE",{});var vua=s(kye);zYr=r(vua,"pretrained_model_name_or_path"),vua.forEach(t),QYr=r(vx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sye=n(vx,"CODE",{});var Fua=s(Sye);WYr=r(Fua,"pretrained_model_name_or_path"),Fua.forEach(t),UYr=r(vx,":"),vx.forEach(t),HYr=i(yi),ce=n(yi,"UL",{});var ue=s(ce);Jw=n(ue,"LI",{});var AKe=s(Jw);Rye=n(AKe,"STRONG",{});var Tua=s(Rye);JYr=r(Tua,"albert"),Tua.forEach(t),YYr=r(AKe," \u2014 "),Nae=n(AKe,"A",{href:!0});var Mua=s(Nae);ZYr=r(Mua,"TFAlbertForMaskedLM"),Mua.forEach(t),KYr=r(AKe," (ALBERT model)"),AKe.forEach(t),eZr=i(ue),Yw=n(ue,"LI",{});var LKe=s(Yw);Pye=n(LKe,"STRONG",{});var Eua=s(Pye);oZr=r(Eua,"bert"),Eua.forEach(t),rZr=r(LKe," \u2014 "),qae=n(LKe,"A",{href:!0});var Cua=s(qae);tZr=r(Cua,"TFBertForMaskedLM"),Cua.forEach(t),aZr=r(LKe," (BERT model)"),LKe.forEach(t),nZr=i(ue),Zw=n(ue,"LI",{});var yKe=s(Zw);Bye=n(yKe,"STRONG",{});var wua=s(Bye);sZr=r(wua,"camembert"),wua.forEach(t),lZr=r(yKe," \u2014 "),jae=n(yKe,"A",{href:!0});var Aua=s(jae);iZr=r(Aua,"TFCamembertForMaskedLM"),Aua.forEach(t),dZr=r(yKe," (CamemBERT model)"),yKe.forEach(t),mZr=i(ue),Kw=n(ue,"LI",{});var xKe=s(Kw);Iye=n(xKe,"STRONG",{});var Lua=s(Iye);cZr=r(Lua,"convbert"),Lua.forEach(t),fZr=r(xKe," \u2014 "),Dae=n(xKe,"A",{href:!0});var yua=s(Dae);gZr=r(yua,"TFConvBertForMaskedLM"),yua.forEach(t),hZr=r(xKe," (ConvBERT model)"),xKe.forEach(t),uZr=i(ue),eA=n(ue,"LI",{});var $Ke=s(eA);Nye=n($Ke,"STRONG",{});var xua=s(Nye);pZr=r(xua,"deberta"),xua.forEach(t),_Zr=r($Ke," \u2014 "),Gae=n($Ke,"A",{href:!0});var $ua=s(Gae);bZr=r($ua,"TFDebertaForMaskedLM"),$ua.forEach(t),vZr=r($Ke," (DeBERTa model)"),$Ke.forEach(t),FZr=i(ue),oA=n(ue,"LI",{});var kKe=s(oA);qye=n(kKe,"STRONG",{});var kua=s(qye);TZr=r(kua,"deberta-v2"),kua.forEach(t),MZr=r(kKe," \u2014 "),Oae=n(kKe,"A",{href:!0});var Sua=s(Oae);EZr=r(Sua,"TFDebertaV2ForMaskedLM"),Sua.forEach(t),CZr=r(kKe," (DeBERTa-v2 model)"),kKe.forEach(t),wZr=i(ue),rA=n(ue,"LI",{});var SKe=s(rA);jye=n(SKe,"STRONG",{});var Rua=s(jye);AZr=r(Rua,"distilbert"),Rua.forEach(t),LZr=r(SKe," \u2014 "),Vae=n(SKe,"A",{href:!0});var Pua=s(Vae);yZr=r(Pua,"TFDistilBertForMaskedLM"),Pua.forEach(t),xZr=r(SKe," (DistilBERT model)"),SKe.forEach(t),$Zr=i(ue),tA=n(ue,"LI",{});var RKe=s(tA);Dye=n(RKe,"STRONG",{});var Bua=s(Dye);kZr=r(Bua,"electra"),Bua.forEach(t),SZr=r(RKe," \u2014 "),Xae=n(RKe,"A",{href:!0});var Iua=s(Xae);RZr=r(Iua,"TFElectraForMaskedLM"),Iua.forEach(t),PZr=r(RKe," (ELECTRA model)"),RKe.forEach(t),BZr=i(ue),aA=n(ue,"LI",{});var PKe=s(aA);Gye=n(PKe,"STRONG",{});var Nua=s(Gye);IZr=r(Nua,"esm"),Nua.forEach(t),NZr=r(PKe," \u2014 "),zae=n(PKe,"A",{href:!0});var qua=s(zae);qZr=r(qua,"TFEsmForMaskedLM"),qua.forEach(t),jZr=r(PKe," (ESM model)"),PKe.forEach(t),DZr=i(ue),nA=n(ue,"LI",{});var BKe=s(nA);Oye=n(BKe,"STRONG",{});var jua=s(Oye);GZr=r(jua,"flaubert"),jua.forEach(t),OZr=r(BKe," \u2014 "),Qae=n(BKe,"A",{href:!0});var Dua=s(Qae);VZr=r(Dua,"TFFlaubertWithLMHeadModel"),Dua.forEach(t),XZr=r(BKe," (FlauBERT model)"),BKe.forEach(t),zZr=i(ue),sA=n(ue,"LI",{});var IKe=s(sA);Vye=n(IKe,"STRONG",{});var Gua=s(Vye);QZr=r(Gua,"funnel"),Gua.forEach(t),WZr=r(IKe," \u2014 "),Wae=n(IKe,"A",{href:!0});var Oua=s(Wae);UZr=r(Oua,"TFFunnelForMaskedLM"),Oua.forEach(t),HZr=r(IKe," (Funnel Transformer model)"),IKe.forEach(t),JZr=i(ue),lA=n(ue,"LI",{});var NKe=s(lA);Xye=n(NKe,"STRONG",{});var Vua=s(Xye);YZr=r(Vua,"layoutlm"),Vua.forEach(t),ZZr=r(NKe," \u2014 "),Uae=n(NKe,"A",{href:!0});var Xua=s(Uae);KZr=r(Xua,"TFLayoutLMForMaskedLM"),Xua.forEach(t),eKr=r(NKe," (LayoutLM model)"),NKe.forEach(t),oKr=i(ue),iA=n(ue,"LI",{});var qKe=s(iA);zye=n(qKe,"STRONG",{});var zua=s(zye);rKr=r(zua,"longformer"),zua.forEach(t),tKr=r(qKe," \u2014 "),Hae=n(qKe,"A",{href:!0});var Qua=s(Hae);aKr=r(Qua,"TFLongformerForMaskedLM"),Qua.forEach(t),nKr=r(qKe," (Longformer model)"),qKe.forEach(t),sKr=i(ue),dA=n(ue,"LI",{});var jKe=s(dA);Qye=n(jKe,"STRONG",{});var Wua=s(Qye);lKr=r(Wua,"mobilebert"),Wua.forEach(t),iKr=r(jKe," \u2014 "),Jae=n(jKe,"A",{href:!0});var Uua=s(Jae);dKr=r(Uua,"TFMobileBertForMaskedLM"),Uua.forEach(t),mKr=r(jKe," (MobileBERT model)"),jKe.forEach(t),cKr=i(ue),mA=n(ue,"LI",{});var DKe=s(mA);Wye=n(DKe,"STRONG",{});var Hua=s(Wye);fKr=r(Hua,"mpnet"),Hua.forEach(t),gKr=r(DKe," \u2014 "),Yae=n(DKe,"A",{href:!0});var Jua=s(Yae);hKr=r(Jua,"TFMPNetForMaskedLM"),Jua.forEach(t),uKr=r(DKe," (MPNet model)"),DKe.forEach(t),pKr=i(ue),cA=n(ue,"LI",{});var GKe=s(cA);Uye=n(GKe,"STRONG",{});var Yua=s(Uye);_Kr=r(Yua,"rembert"),Yua.forEach(t),bKr=r(GKe," \u2014 "),Zae=n(GKe,"A",{href:!0});var Zua=s(Zae);vKr=r(Zua,"TFRemBertForMaskedLM"),Zua.forEach(t),FKr=r(GKe," (RemBERT model)"),GKe.forEach(t),TKr=i(ue),fA=n(ue,"LI",{});var OKe=s(fA);Hye=n(OKe,"STRONG",{});var Kua=s(Hye);MKr=r(Kua,"roberta"),Kua.forEach(t),EKr=r(OKe," \u2014 "),Kae=n(OKe,"A",{href:!0});var epa=s(Kae);CKr=r(epa,"TFRobertaForMaskedLM"),epa.forEach(t),wKr=r(OKe," (RoBERTa model)"),OKe.forEach(t),AKr=i(ue),gA=n(ue,"LI",{});var VKe=s(gA);Jye=n(VKe,"STRONG",{});var opa=s(Jye);LKr=r(opa,"roformer"),opa.forEach(t),yKr=r(VKe," \u2014 "),ene=n(VKe,"A",{href:!0});var rpa=s(ene);xKr=r(rpa,"TFRoFormerForMaskedLM"),rpa.forEach(t),$Kr=r(VKe," (RoFormer model)"),VKe.forEach(t),kKr=i(ue),hA=n(ue,"LI",{});var XKe=s(hA);Yye=n(XKe,"STRONG",{});var tpa=s(Yye);SKr=r(tpa,"tapas"),tpa.forEach(t),RKr=r(XKe," \u2014 "),one=n(XKe,"A",{href:!0});var apa=s(one);PKr=r(apa,"TFTapasForMaskedLM"),apa.forEach(t),BKr=r(XKe," (TAPAS model)"),XKe.forEach(t),IKr=i(ue),uA=n(ue,"LI",{});var zKe=s(uA);Zye=n(zKe,"STRONG",{});var npa=s(Zye);NKr=r(npa,"xlm"),npa.forEach(t),qKr=r(zKe," \u2014 "),rne=n(zKe,"A",{href:!0});var spa=s(rne);jKr=r(spa,"TFXLMWithLMHeadModel"),spa.forEach(t),DKr=r(zKe," (XLM model)"),zKe.forEach(t),GKr=i(ue),pA=n(ue,"LI",{});var QKe=s(pA);Kye=n(QKe,"STRONG",{});var lpa=s(Kye);OKr=r(lpa,"xlm-roberta"),lpa.forEach(t),VKr=r(QKe," \u2014 "),tne=n(QKe,"A",{href:!0});var ipa=s(tne);XKr=r(ipa,"TFXLMRobertaForMaskedLM"),ipa.forEach(t),zKr=r(QKe," (XLM-RoBERTa model)"),QKe.forEach(t),ue.forEach(t),QKr=i(yi),T(_A.$$.fragment,yi),yi.forEach(t),Li.forEach(t),vno=i(c),$c=n(c,"H2",{class:!0});var qlo=s($c);bA=n(qlo,"A",{id:!0,class:!0,href:!0});var dpa=s(bA);e9e=n(dpa,"SPAN",{});var mpa=s(e9e);T(HR.$$.fragment,mpa),mpa.forEach(t),dpa.forEach(t),WKr=i(qlo),o9e=n(qlo,"SPAN",{});var cpa=s(o9e);UKr=r(cpa,"TFAutoModelForSeq2SeqLM"),cpa.forEach(t),qlo.forEach(t),Fno=i(c),pr=n(c,"DIV",{class:!0});var xi=s(pr);T(JR.$$.fragment,xi),HKr=i(xi),kc=n(xi,"P",{});var Rce=s(kc);JKr=r(Rce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),ane=n(Rce,"A",{href:!0});var fpa=s(ane);YKr=r(fpa,"from_pretrained()"),fpa.forEach(t),ZKr=r(Rce," class method or the "),nne=n(Rce,"A",{href:!0});var gpa=s(nne);KKr=r(gpa,"from_config()"),gpa.forEach(t),eet=r(Rce,` class
method.`),Rce.forEach(t),oet=i(xi),YR=n(xi,"P",{});var jlo=s(YR);ret=r(jlo,"This class cannot be instantiated directly using "),r9e=n(jlo,"CODE",{});var hpa=s(r9e);tet=r(hpa,"__init__()"),hpa.forEach(t),aet=r(jlo," (throws an error)."),jlo.forEach(t),net=i(xi),ta=n(xi,"DIV",{class:!0});var Fx=s(ta);T(ZR.$$.fragment,Fx),set=i(Fx),t9e=n(Fx,"P",{});var upa=s(t9e);iet=r(upa,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),upa.forEach(t),det=i(Fx),Sc=n(Fx,"P",{});var Pce=s(Sc);met=r(Pce,`Note:
Loading a model from its configuration file does `),a9e=n(Pce,"STRONG",{});var ppa=s(a9e);cet=r(ppa,"not"),ppa.forEach(t),fet=r(Pce,` load the model weights. It only affects the
model\u2019s configuration. Use `),sne=n(Pce,"A",{href:!0});var _pa=s(sne);get=r(_pa,"from_pretrained()"),_pa.forEach(t),het=r(Pce," to load the model weights."),Pce.forEach(t),uet=i(Fx),T(vA.$$.fragment,Fx),Fx.forEach(t),pet=i(xi),Qr=n(xi,"DIV",{class:!0});var $i=s(Qr);T(KR.$$.fragment,$i),_et=i($i),n9e=n($i,"P",{});var bpa=s(n9e);bet=r(bpa,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),bpa.forEach(t),vet=i($i),Gn=n($i,"P",{});var Tx=s(Gn);Fet=r(Tx,"The model class to instantiate is selected based on the "),s9e=n(Tx,"CODE",{});var vpa=s(s9e);Tet=r(vpa,"model_type"),vpa.forEach(t),Met=r(Tx,` property of the config object (either
passed as an argument or loaded from `),l9e=n(Tx,"CODE",{});var Fpa=s(l9e);Eet=r(Fpa,"pretrained_model_name_or_path"),Fpa.forEach(t),Cet=r(Tx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i9e=n(Tx,"CODE",{});var Tpa=s(i9e);wet=r(Tpa,"pretrained_model_name_or_path"),Tpa.forEach(t),Aet=r(Tx,":"),Tx.forEach(t),Let=i($i),xe=n($i,"UL",{});var qe=s(xe);FA=n(qe,"LI",{});var WKe=s(FA);d9e=n(WKe,"STRONG",{});var Mpa=s(d9e);yet=r(Mpa,"bart"),Mpa.forEach(t),xet=r(WKe," \u2014 "),lne=n(WKe,"A",{href:!0});var Epa=s(lne);$et=r(Epa,"TFBartForConditionalGeneration"),Epa.forEach(t),ket=r(WKe," (BART model)"),WKe.forEach(t),Set=i(qe),TA=n(qe,"LI",{});var UKe=s(TA);m9e=n(UKe,"STRONG",{});var Cpa=s(m9e);Ret=r(Cpa,"blenderbot"),Cpa.forEach(t),Pet=r(UKe," \u2014 "),ine=n(UKe,"A",{href:!0});var wpa=s(ine);Bet=r(wpa,"TFBlenderbotForConditionalGeneration"),wpa.forEach(t),Iet=r(UKe," (Blenderbot model)"),UKe.forEach(t),Net=i(qe),MA=n(qe,"LI",{});var HKe=s(MA);c9e=n(HKe,"STRONG",{});var Apa=s(c9e);qet=r(Apa,"blenderbot-small"),Apa.forEach(t),jet=r(HKe," \u2014 "),dne=n(HKe,"A",{href:!0});var Lpa=s(dne);Det=r(Lpa,"TFBlenderbotSmallForConditionalGeneration"),Lpa.forEach(t),Get=r(HKe," (BlenderbotSmall model)"),HKe.forEach(t),Oet=i(qe),EA=n(qe,"LI",{});var JKe=s(EA);f9e=n(JKe,"STRONG",{});var ypa=s(f9e);Vet=r(ypa,"encoder-decoder"),ypa.forEach(t),Xet=r(JKe," \u2014 "),mne=n(JKe,"A",{href:!0});var xpa=s(mne);zet=r(xpa,"TFEncoderDecoderModel"),xpa.forEach(t),Qet=r(JKe," (Encoder decoder model)"),JKe.forEach(t),Wet=i(qe),CA=n(qe,"LI",{});var YKe=s(CA);g9e=n(YKe,"STRONG",{});var $pa=s(g9e);Uet=r($pa,"led"),$pa.forEach(t),Het=r(YKe," \u2014 "),cne=n(YKe,"A",{href:!0});var kpa=s(cne);Jet=r(kpa,"TFLEDForConditionalGeneration"),kpa.forEach(t),Yet=r(YKe," (LED model)"),YKe.forEach(t),Zet=i(qe),wA=n(qe,"LI",{});var ZKe=s(wA);h9e=n(ZKe,"STRONG",{});var Spa=s(h9e);Ket=r(Spa,"marian"),Spa.forEach(t),eot=r(ZKe," \u2014 "),fne=n(ZKe,"A",{href:!0});var Rpa=s(fne);oot=r(Rpa,"TFMarianMTModel"),Rpa.forEach(t),rot=r(ZKe," (Marian model)"),ZKe.forEach(t),tot=i(qe),AA=n(qe,"LI",{});var KKe=s(AA);u9e=n(KKe,"STRONG",{});var Ppa=s(u9e);aot=r(Ppa,"mbart"),Ppa.forEach(t),not=r(KKe," \u2014 "),gne=n(KKe,"A",{href:!0});var Bpa=s(gne);sot=r(Bpa,"TFMBartForConditionalGeneration"),Bpa.forEach(t),lot=r(KKe," (mBART model)"),KKe.forEach(t),iot=i(qe),LA=n(qe,"LI",{});var eeo=s(LA);p9e=n(eeo,"STRONG",{});var Ipa=s(p9e);dot=r(Ipa,"mt5"),Ipa.forEach(t),mot=r(eeo," \u2014 "),hne=n(eeo,"A",{href:!0});var Npa=s(hne);cot=r(Npa,"TFMT5ForConditionalGeneration"),Npa.forEach(t),fot=r(eeo," (MT5 model)"),eeo.forEach(t),got=i(qe),yA=n(qe,"LI",{});var oeo=s(yA);_9e=n(oeo,"STRONG",{});var qpa=s(_9e);hot=r(qpa,"pegasus"),qpa.forEach(t),uot=r(oeo," \u2014 "),une=n(oeo,"A",{href:!0});var jpa=s(une);pot=r(jpa,"TFPegasusForConditionalGeneration"),jpa.forEach(t),_ot=r(oeo," (Pegasus model)"),oeo.forEach(t),bot=i(qe),xA=n(qe,"LI",{});var reo=s(xA);b9e=n(reo,"STRONG",{});var Dpa=s(b9e);vot=r(Dpa,"t5"),Dpa.forEach(t),Fot=r(reo," \u2014 "),pne=n(reo,"A",{href:!0});var Gpa=s(pne);Tot=r(Gpa,"TFT5ForConditionalGeneration"),Gpa.forEach(t),Mot=r(reo," (T5 model)"),reo.forEach(t),qe.forEach(t),Eot=i($i),T($A.$$.fragment,$i),$i.forEach(t),xi.forEach(t),Tno=i(c),Rc=n(c,"H2",{class:!0});var Dlo=s(Rc);kA=n(Dlo,"A",{id:!0,class:!0,href:!0});var Opa=s(kA);v9e=n(Opa,"SPAN",{});var Vpa=s(v9e);T(eP.$$.fragment,Vpa),Vpa.forEach(t),Opa.forEach(t),Cot=i(Dlo),F9e=n(Dlo,"SPAN",{});var Xpa=s(F9e);wot=r(Xpa,"TFAutoModelForSequenceClassification"),Xpa.forEach(t),Dlo.forEach(t),Mno=i(c),_r=n(c,"DIV",{class:!0});var ki=s(_r);T(oP.$$.fragment,ki),Aot=i(ki),Pc=n(ki,"P",{});var Bce=s(Pc);Lot=r(Bce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),_ne=n(Bce,"A",{href:!0});var zpa=s(_ne);yot=r(zpa,"from_pretrained()"),zpa.forEach(t),xot=r(Bce," class method or the "),bne=n(Bce,"A",{href:!0});var Qpa=s(bne);$ot=r(Qpa,"from_config()"),Qpa.forEach(t),kot=r(Bce,` class
method.`),Bce.forEach(t),Sot=i(ki),rP=n(ki,"P",{});var Glo=s(rP);Rot=r(Glo,"This class cannot be instantiated directly using "),T9e=n(Glo,"CODE",{});var Wpa=s(T9e);Pot=r(Wpa,"__init__()"),Wpa.forEach(t),Bot=r(Glo," (throws an error)."),Glo.forEach(t),Iot=i(ki),aa=n(ki,"DIV",{class:!0});var Mx=s(aa);T(tP.$$.fragment,Mx),Not=i(Mx),M9e=n(Mx,"P",{});var Upa=s(M9e);qot=r(Upa,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Upa.forEach(t),jot=i(Mx),Bc=n(Mx,"P",{});var Ice=s(Bc);Dot=r(Ice,`Note:
Loading a model from its configuration file does `),E9e=n(Ice,"STRONG",{});var Hpa=s(E9e);Got=r(Hpa,"not"),Hpa.forEach(t),Oot=r(Ice,` load the model weights. It only affects the
model\u2019s configuration. Use `),vne=n(Ice,"A",{href:!0});var Jpa=s(vne);Vot=r(Jpa,"from_pretrained()"),Jpa.forEach(t),Xot=r(Ice," to load the model weights."),Ice.forEach(t),zot=i(Mx),T(SA.$$.fragment,Mx),Mx.forEach(t),Qot=i(ki),Wr=n(ki,"DIV",{class:!0});var Si=s(Wr);T(aP.$$.fragment,Si),Wot=i(Si),C9e=n(Si,"P",{});var Ypa=s(C9e);Uot=r(Ypa,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),Ypa.forEach(t),Hot=i(Si),On=n(Si,"P",{});var Ex=s(On);Jot=r(Ex,"The model class to instantiate is selected based on the "),w9e=n(Ex,"CODE",{});var Zpa=s(w9e);Yot=r(Zpa,"model_type"),Zpa.forEach(t),Zot=r(Ex,` property of the config object (either
passed as an argument or loaded from `),A9e=n(Ex,"CODE",{});var Kpa=s(A9e);Kot=r(Kpa,"pretrained_model_name_or_path"),Kpa.forEach(t),ert=r(Ex,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L9e=n(Ex,"CODE",{});var e_a=s(L9e);ort=r(e_a,"pretrained_model_name_or_path"),e_a.forEach(t),rrt=r(Ex,":"),Ex.forEach(t),trt=i(Si),re=n(Si,"UL",{});var ae=s(re);RA=n(ae,"LI",{});var teo=s(RA);y9e=n(teo,"STRONG",{});var o_a=s(y9e);art=r(o_a,"albert"),o_a.forEach(t),nrt=r(teo," \u2014 "),Fne=n(teo,"A",{href:!0});var r_a=s(Fne);srt=r(r_a,"TFAlbertForSequenceClassification"),r_a.forEach(t),lrt=r(teo," (ALBERT model)"),teo.forEach(t),irt=i(ae),PA=n(ae,"LI",{});var aeo=s(PA);x9e=n(aeo,"STRONG",{});var t_a=s(x9e);drt=r(t_a,"bert"),t_a.forEach(t),mrt=r(aeo," \u2014 "),Tne=n(aeo,"A",{href:!0});var a_a=s(Tne);crt=r(a_a,"TFBertForSequenceClassification"),a_a.forEach(t),frt=r(aeo," (BERT model)"),aeo.forEach(t),grt=i(ae),BA=n(ae,"LI",{});var neo=s(BA);$9e=n(neo,"STRONG",{});var n_a=s($9e);hrt=r(n_a,"camembert"),n_a.forEach(t),urt=r(neo," \u2014 "),Mne=n(neo,"A",{href:!0});var s_a=s(Mne);prt=r(s_a,"TFCamembertForSequenceClassification"),s_a.forEach(t),_rt=r(neo," (CamemBERT model)"),neo.forEach(t),brt=i(ae),IA=n(ae,"LI",{});var seo=s(IA);k9e=n(seo,"STRONG",{});var l_a=s(k9e);vrt=r(l_a,"convbert"),l_a.forEach(t),Frt=r(seo," \u2014 "),Ene=n(seo,"A",{href:!0});var i_a=s(Ene);Trt=r(i_a,"TFConvBertForSequenceClassification"),i_a.forEach(t),Mrt=r(seo," (ConvBERT model)"),seo.forEach(t),Ert=i(ae),NA=n(ae,"LI",{});var leo=s(NA);S9e=n(leo,"STRONG",{});var d_a=s(S9e);Crt=r(d_a,"ctrl"),d_a.forEach(t),wrt=r(leo," \u2014 "),Cne=n(leo,"A",{href:!0});var m_a=s(Cne);Art=r(m_a,"TFCTRLForSequenceClassification"),m_a.forEach(t),Lrt=r(leo," (CTRL model)"),leo.forEach(t),yrt=i(ae),qA=n(ae,"LI",{});var ieo=s(qA);R9e=n(ieo,"STRONG",{});var c_a=s(R9e);xrt=r(c_a,"deberta"),c_a.forEach(t),$rt=r(ieo," \u2014 "),wne=n(ieo,"A",{href:!0});var f_a=s(wne);krt=r(f_a,"TFDebertaForSequenceClassification"),f_a.forEach(t),Srt=r(ieo," (DeBERTa model)"),ieo.forEach(t),Rrt=i(ae),jA=n(ae,"LI",{});var deo=s(jA);P9e=n(deo,"STRONG",{});var g_a=s(P9e);Prt=r(g_a,"deberta-v2"),g_a.forEach(t),Brt=r(deo," \u2014 "),Ane=n(deo,"A",{href:!0});var h_a=s(Ane);Irt=r(h_a,"TFDebertaV2ForSequenceClassification"),h_a.forEach(t),Nrt=r(deo," (DeBERTa-v2 model)"),deo.forEach(t),qrt=i(ae),DA=n(ae,"LI",{});var meo=s(DA);B9e=n(meo,"STRONG",{});var u_a=s(B9e);jrt=r(u_a,"distilbert"),u_a.forEach(t),Drt=r(meo," \u2014 "),Lne=n(meo,"A",{href:!0});var p_a=s(Lne);Grt=r(p_a,"TFDistilBertForSequenceClassification"),p_a.forEach(t),Ort=r(meo," (DistilBERT model)"),meo.forEach(t),Vrt=i(ae),GA=n(ae,"LI",{});var ceo=s(GA);I9e=n(ceo,"STRONG",{});var __a=s(I9e);Xrt=r(__a,"electra"),__a.forEach(t),zrt=r(ceo," \u2014 "),yne=n(ceo,"A",{href:!0});var b_a=s(yne);Qrt=r(b_a,"TFElectraForSequenceClassification"),b_a.forEach(t),Wrt=r(ceo," (ELECTRA model)"),ceo.forEach(t),Urt=i(ae),OA=n(ae,"LI",{});var feo=s(OA);N9e=n(feo,"STRONG",{});var v_a=s(N9e);Hrt=r(v_a,"esm"),v_a.forEach(t),Jrt=r(feo," \u2014 "),xne=n(feo,"A",{href:!0});var F_a=s(xne);Yrt=r(F_a,"TFEsmForSequenceClassification"),F_a.forEach(t),Zrt=r(feo," (ESM model)"),feo.forEach(t),Krt=i(ae),VA=n(ae,"LI",{});var geo=s(VA);q9e=n(geo,"STRONG",{});var T_a=s(q9e);ett=r(T_a,"flaubert"),T_a.forEach(t),ott=r(geo," \u2014 "),$ne=n(geo,"A",{href:!0});var M_a=s($ne);rtt=r(M_a,"TFFlaubertForSequenceClassification"),M_a.forEach(t),ttt=r(geo," (FlauBERT model)"),geo.forEach(t),att=i(ae),XA=n(ae,"LI",{});var heo=s(XA);j9e=n(heo,"STRONG",{});var E_a=s(j9e);ntt=r(E_a,"funnel"),E_a.forEach(t),stt=r(heo," \u2014 "),kne=n(heo,"A",{href:!0});var C_a=s(kne);ltt=r(C_a,"TFFunnelForSequenceClassification"),C_a.forEach(t),itt=r(heo," (Funnel Transformer model)"),heo.forEach(t),dtt=i(ae),zA=n(ae,"LI",{});var ueo=s(zA);D9e=n(ueo,"STRONG",{});var w_a=s(D9e);mtt=r(w_a,"gpt2"),w_a.forEach(t),ctt=r(ueo," \u2014 "),Sne=n(ueo,"A",{href:!0});var A_a=s(Sne);ftt=r(A_a,"TFGPT2ForSequenceClassification"),A_a.forEach(t),gtt=r(ueo," (OpenAI GPT-2 model)"),ueo.forEach(t),htt=i(ae),QA=n(ae,"LI",{});var peo=s(QA);G9e=n(peo,"STRONG",{});var L_a=s(G9e);utt=r(L_a,"gptj"),L_a.forEach(t),ptt=r(peo," \u2014 "),Rne=n(peo,"A",{href:!0});var y_a=s(Rne);_tt=r(y_a,"TFGPTJForSequenceClassification"),y_a.forEach(t),btt=r(peo," (GPT-J model)"),peo.forEach(t),vtt=i(ae),WA=n(ae,"LI",{});var _eo=s(WA);O9e=n(_eo,"STRONG",{});var x_a=s(O9e);Ftt=r(x_a,"layoutlm"),x_a.forEach(t),Ttt=r(_eo," \u2014 "),Pne=n(_eo,"A",{href:!0});var $_a=s(Pne);Mtt=r($_a,"TFLayoutLMForSequenceClassification"),$_a.forEach(t),Ett=r(_eo," (LayoutLM model)"),_eo.forEach(t),Ctt=i(ae),UA=n(ae,"LI",{});var beo=s(UA);V9e=n(beo,"STRONG",{});var k_a=s(V9e);wtt=r(k_a,"layoutlmv3"),k_a.forEach(t),Att=r(beo," \u2014 "),Bne=n(beo,"A",{href:!0});var S_a=s(Bne);Ltt=r(S_a,"TFLayoutLMv3ForSequenceClassification"),S_a.forEach(t),ytt=r(beo," (LayoutLMv3 model)"),beo.forEach(t),xtt=i(ae),HA=n(ae,"LI",{});var veo=s(HA);X9e=n(veo,"STRONG",{});var R_a=s(X9e);$tt=r(R_a,"longformer"),R_a.forEach(t),ktt=r(veo," \u2014 "),Ine=n(veo,"A",{href:!0});var P_a=s(Ine);Stt=r(P_a,"TFLongformerForSequenceClassification"),P_a.forEach(t),Rtt=r(veo," (Longformer model)"),veo.forEach(t),Ptt=i(ae),JA=n(ae,"LI",{});var Feo=s(JA);z9e=n(Feo,"STRONG",{});var B_a=s(z9e);Btt=r(B_a,"mobilebert"),B_a.forEach(t),Itt=r(Feo," \u2014 "),Nne=n(Feo,"A",{href:!0});var I_a=s(Nne);Ntt=r(I_a,"TFMobileBertForSequenceClassification"),I_a.forEach(t),qtt=r(Feo," (MobileBERT model)"),Feo.forEach(t),jtt=i(ae),YA=n(ae,"LI",{});var Teo=s(YA);Q9e=n(Teo,"STRONG",{});var N_a=s(Q9e);Dtt=r(N_a,"mpnet"),N_a.forEach(t),Gtt=r(Teo," \u2014 "),qne=n(Teo,"A",{href:!0});var q_a=s(qne);Ott=r(q_a,"TFMPNetForSequenceClassification"),q_a.forEach(t),Vtt=r(Teo," (MPNet model)"),Teo.forEach(t),Xtt=i(ae),ZA=n(ae,"LI",{});var Meo=s(ZA);W9e=n(Meo,"STRONG",{});var j_a=s(W9e);ztt=r(j_a,"openai-gpt"),j_a.forEach(t),Qtt=r(Meo," \u2014 "),jne=n(Meo,"A",{href:!0});var D_a=s(jne);Wtt=r(D_a,"TFOpenAIGPTForSequenceClassification"),D_a.forEach(t),Utt=r(Meo," (OpenAI GPT model)"),Meo.forEach(t),Htt=i(ae),KA=n(ae,"LI",{});var Eeo=s(KA);U9e=n(Eeo,"STRONG",{});var G_a=s(U9e);Jtt=r(G_a,"rembert"),G_a.forEach(t),Ytt=r(Eeo," \u2014 "),Dne=n(Eeo,"A",{href:!0});var O_a=s(Dne);Ztt=r(O_a,"TFRemBertForSequenceClassification"),O_a.forEach(t),Ktt=r(Eeo," (RemBERT model)"),Eeo.forEach(t),eat=i(ae),e6=n(ae,"LI",{});var Ceo=s(e6);H9e=n(Ceo,"STRONG",{});var V_a=s(H9e);oat=r(V_a,"roberta"),V_a.forEach(t),rat=r(Ceo," \u2014 "),Gne=n(Ceo,"A",{href:!0});var X_a=s(Gne);tat=r(X_a,"TFRobertaForSequenceClassification"),X_a.forEach(t),aat=r(Ceo," (RoBERTa model)"),Ceo.forEach(t),nat=i(ae),o6=n(ae,"LI",{});var weo=s(o6);J9e=n(weo,"STRONG",{});var z_a=s(J9e);sat=r(z_a,"roformer"),z_a.forEach(t),lat=r(weo," \u2014 "),One=n(weo,"A",{href:!0});var Q_a=s(One);iat=r(Q_a,"TFRoFormerForSequenceClassification"),Q_a.forEach(t),dat=r(weo," (RoFormer model)"),weo.forEach(t),mat=i(ae),r6=n(ae,"LI",{});var Aeo=s(r6);Y9e=n(Aeo,"STRONG",{});var W_a=s(Y9e);cat=r(W_a,"tapas"),W_a.forEach(t),fat=r(Aeo," \u2014 "),Vne=n(Aeo,"A",{href:!0});var U_a=s(Vne);gat=r(U_a,"TFTapasForSequenceClassification"),U_a.forEach(t),hat=r(Aeo," (TAPAS model)"),Aeo.forEach(t),uat=i(ae),t6=n(ae,"LI",{});var Leo=s(t6);Z9e=n(Leo,"STRONG",{});var H_a=s(Z9e);pat=r(H_a,"transfo-xl"),H_a.forEach(t),_at=r(Leo," \u2014 "),Xne=n(Leo,"A",{href:!0});var J_a=s(Xne);bat=r(J_a,"TFTransfoXLForSequenceClassification"),J_a.forEach(t),vat=r(Leo," (Transformer-XL model)"),Leo.forEach(t),Fat=i(ae),a6=n(ae,"LI",{});var yeo=s(a6);K9e=n(yeo,"STRONG",{});var Y_a=s(K9e);Tat=r(Y_a,"xlm"),Y_a.forEach(t),Mat=r(yeo," \u2014 "),zne=n(yeo,"A",{href:!0});var Z_a=s(zne);Eat=r(Z_a,"TFXLMForSequenceClassification"),Z_a.forEach(t),Cat=r(yeo," (XLM model)"),yeo.forEach(t),wat=i(ae),n6=n(ae,"LI",{});var xeo=s(n6);exe=n(xeo,"STRONG",{});var K_a=s(exe);Aat=r(K_a,"xlm-roberta"),K_a.forEach(t),Lat=r(xeo," \u2014 "),Qne=n(xeo,"A",{href:!0});var e1a=s(Qne);yat=r(e1a,"TFXLMRobertaForSequenceClassification"),e1a.forEach(t),xat=r(xeo," (XLM-RoBERTa model)"),xeo.forEach(t),$at=i(ae),s6=n(ae,"LI",{});var $eo=s(s6);oxe=n($eo,"STRONG",{});var o1a=s(oxe);kat=r(o1a,"xlnet"),o1a.forEach(t),Sat=r($eo," \u2014 "),Wne=n($eo,"A",{href:!0});var r1a=s(Wne);Rat=r(r1a,"TFXLNetForSequenceClassification"),r1a.forEach(t),Pat=r($eo," (XLNet model)"),$eo.forEach(t),ae.forEach(t),Bat=i(Si),T(l6.$$.fragment,Si),Si.forEach(t),ki.forEach(t),Eno=i(c),Ic=n(c,"H2",{class:!0});var Olo=s(Ic);i6=n(Olo,"A",{id:!0,class:!0,href:!0});var t1a=s(i6);rxe=n(t1a,"SPAN",{});var a1a=s(rxe);T(nP.$$.fragment,a1a),a1a.forEach(t),t1a.forEach(t),Iat=i(Olo),txe=n(Olo,"SPAN",{});var n1a=s(txe);Nat=r(n1a,"TFAutoModelForMultipleChoice"),n1a.forEach(t),Olo.forEach(t),Cno=i(c),br=n(c,"DIV",{class:!0});var Ri=s(br);T(sP.$$.fragment,Ri),qat=i(Ri),Nc=n(Ri,"P",{});var Nce=s(Nc);jat=r(Nce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Une=n(Nce,"A",{href:!0});var s1a=s(Une);Dat=r(s1a,"from_pretrained()"),s1a.forEach(t),Gat=r(Nce," class method or the "),Hne=n(Nce,"A",{href:!0});var l1a=s(Hne);Oat=r(l1a,"from_config()"),l1a.forEach(t),Vat=r(Nce,` class
method.`),Nce.forEach(t),Xat=i(Ri),lP=n(Ri,"P",{});var Vlo=s(lP);zat=r(Vlo,"This class cannot be instantiated directly using "),axe=n(Vlo,"CODE",{});var i1a=s(axe);Qat=r(i1a,"__init__()"),i1a.forEach(t),Wat=r(Vlo," (throws an error)."),Vlo.forEach(t),Uat=i(Ri),na=n(Ri,"DIV",{class:!0});var Cx=s(na);T(iP.$$.fragment,Cx),Hat=i(Cx),nxe=n(Cx,"P",{});var d1a=s(nxe);Jat=r(d1a,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),d1a.forEach(t),Yat=i(Cx),qc=n(Cx,"P",{});var qce=s(qc);Zat=r(qce,`Note:
Loading a model from its configuration file does `),sxe=n(qce,"STRONG",{});var m1a=s(sxe);Kat=r(m1a,"not"),m1a.forEach(t),ent=r(qce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jne=n(qce,"A",{href:!0});var c1a=s(Jne);ont=r(c1a,"from_pretrained()"),c1a.forEach(t),rnt=r(qce," to load the model weights."),qce.forEach(t),tnt=i(Cx),T(d6.$$.fragment,Cx),Cx.forEach(t),ant=i(Ri),Ur=n(Ri,"DIV",{class:!0});var Pi=s(Ur);T(dP.$$.fragment,Pi),nnt=i(Pi),lxe=n(Pi,"P",{});var f1a=s(lxe);snt=r(f1a,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),f1a.forEach(t),lnt=i(Pi),Vn=n(Pi,"P",{});var wx=s(Vn);int=r(wx,"The model class to instantiate is selected based on the "),ixe=n(wx,"CODE",{});var g1a=s(ixe);dnt=r(g1a,"model_type"),g1a.forEach(t),mnt=r(wx,` property of the config object (either
passed as an argument or loaded from `),dxe=n(wx,"CODE",{});var h1a=s(dxe);cnt=r(h1a,"pretrained_model_name_or_path"),h1a.forEach(t),fnt=r(wx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mxe=n(wx,"CODE",{});var u1a=s(mxe);gnt=r(u1a,"pretrained_model_name_or_path"),u1a.forEach(t),hnt=r(wx,":"),wx.forEach(t),unt=i(Pi),ve=n(Pi,"UL",{});var Te=s(ve);m6=n(Te,"LI",{});var keo=s(m6);cxe=n(keo,"STRONG",{});var p1a=s(cxe);pnt=r(p1a,"albert"),p1a.forEach(t),_nt=r(keo," \u2014 "),Yne=n(keo,"A",{href:!0});var _1a=s(Yne);bnt=r(_1a,"TFAlbertForMultipleChoice"),_1a.forEach(t),vnt=r(keo," (ALBERT model)"),keo.forEach(t),Fnt=i(Te),c6=n(Te,"LI",{});var Seo=s(c6);fxe=n(Seo,"STRONG",{});var b1a=s(fxe);Tnt=r(b1a,"bert"),b1a.forEach(t),Mnt=r(Seo," \u2014 "),Zne=n(Seo,"A",{href:!0});var v1a=s(Zne);Ent=r(v1a,"TFBertForMultipleChoice"),v1a.forEach(t),Cnt=r(Seo," (BERT model)"),Seo.forEach(t),wnt=i(Te),f6=n(Te,"LI",{});var Reo=s(f6);gxe=n(Reo,"STRONG",{});var F1a=s(gxe);Ant=r(F1a,"camembert"),F1a.forEach(t),Lnt=r(Reo," \u2014 "),Kne=n(Reo,"A",{href:!0});var T1a=s(Kne);ynt=r(T1a,"TFCamembertForMultipleChoice"),T1a.forEach(t),xnt=r(Reo," (CamemBERT model)"),Reo.forEach(t),$nt=i(Te),g6=n(Te,"LI",{});var Peo=s(g6);hxe=n(Peo,"STRONG",{});var M1a=s(hxe);knt=r(M1a,"convbert"),M1a.forEach(t),Snt=r(Peo," \u2014 "),ese=n(Peo,"A",{href:!0});var E1a=s(ese);Rnt=r(E1a,"TFConvBertForMultipleChoice"),E1a.forEach(t),Pnt=r(Peo," (ConvBERT model)"),Peo.forEach(t),Bnt=i(Te),h6=n(Te,"LI",{});var Beo=s(h6);uxe=n(Beo,"STRONG",{});var C1a=s(uxe);Int=r(C1a,"distilbert"),C1a.forEach(t),Nnt=r(Beo," \u2014 "),ose=n(Beo,"A",{href:!0});var w1a=s(ose);qnt=r(w1a,"TFDistilBertForMultipleChoice"),w1a.forEach(t),jnt=r(Beo," (DistilBERT model)"),Beo.forEach(t),Dnt=i(Te),u6=n(Te,"LI",{});var Ieo=s(u6);pxe=n(Ieo,"STRONG",{});var A1a=s(pxe);Gnt=r(A1a,"electra"),A1a.forEach(t),Ont=r(Ieo," \u2014 "),rse=n(Ieo,"A",{href:!0});var L1a=s(rse);Vnt=r(L1a,"TFElectraForMultipleChoice"),L1a.forEach(t),Xnt=r(Ieo," (ELECTRA model)"),Ieo.forEach(t),znt=i(Te),p6=n(Te,"LI",{});var Neo=s(p6);_xe=n(Neo,"STRONG",{});var y1a=s(_xe);Qnt=r(y1a,"flaubert"),y1a.forEach(t),Wnt=r(Neo," \u2014 "),tse=n(Neo,"A",{href:!0});var x1a=s(tse);Unt=r(x1a,"TFFlaubertForMultipleChoice"),x1a.forEach(t),Hnt=r(Neo," (FlauBERT model)"),Neo.forEach(t),Jnt=i(Te),_6=n(Te,"LI",{});var qeo=s(_6);bxe=n(qeo,"STRONG",{});var $1a=s(bxe);Ynt=r($1a,"funnel"),$1a.forEach(t),Znt=r(qeo," \u2014 "),ase=n(qeo,"A",{href:!0});var k1a=s(ase);Knt=r(k1a,"TFFunnelForMultipleChoice"),k1a.forEach(t),est=r(qeo," (Funnel Transformer model)"),qeo.forEach(t),ost=i(Te),b6=n(Te,"LI",{});var jeo=s(b6);vxe=n(jeo,"STRONG",{});var S1a=s(vxe);rst=r(S1a,"longformer"),S1a.forEach(t),tst=r(jeo," \u2014 "),nse=n(jeo,"A",{href:!0});var R1a=s(nse);ast=r(R1a,"TFLongformerForMultipleChoice"),R1a.forEach(t),nst=r(jeo," (Longformer model)"),jeo.forEach(t),sst=i(Te),v6=n(Te,"LI",{});var Deo=s(v6);Fxe=n(Deo,"STRONG",{});var P1a=s(Fxe);lst=r(P1a,"mobilebert"),P1a.forEach(t),ist=r(Deo," \u2014 "),sse=n(Deo,"A",{href:!0});var B1a=s(sse);dst=r(B1a,"TFMobileBertForMultipleChoice"),B1a.forEach(t),mst=r(Deo," (MobileBERT model)"),Deo.forEach(t),cst=i(Te),F6=n(Te,"LI",{});var Geo=s(F6);Txe=n(Geo,"STRONG",{});var I1a=s(Txe);fst=r(I1a,"mpnet"),I1a.forEach(t),gst=r(Geo," \u2014 "),lse=n(Geo,"A",{href:!0});var N1a=s(lse);hst=r(N1a,"TFMPNetForMultipleChoice"),N1a.forEach(t),ust=r(Geo," (MPNet model)"),Geo.forEach(t),pst=i(Te),T6=n(Te,"LI",{});var Oeo=s(T6);Mxe=n(Oeo,"STRONG",{});var q1a=s(Mxe);_st=r(q1a,"rembert"),q1a.forEach(t),bst=r(Oeo," \u2014 "),ise=n(Oeo,"A",{href:!0});var j1a=s(ise);vst=r(j1a,"TFRemBertForMultipleChoice"),j1a.forEach(t),Fst=r(Oeo," (RemBERT model)"),Oeo.forEach(t),Tst=i(Te),M6=n(Te,"LI",{});var Veo=s(M6);Exe=n(Veo,"STRONG",{});var D1a=s(Exe);Mst=r(D1a,"roberta"),D1a.forEach(t),Est=r(Veo," \u2014 "),dse=n(Veo,"A",{href:!0});var G1a=s(dse);Cst=r(G1a,"TFRobertaForMultipleChoice"),G1a.forEach(t),wst=r(Veo," (RoBERTa model)"),Veo.forEach(t),Ast=i(Te),E6=n(Te,"LI",{});var Xeo=s(E6);Cxe=n(Xeo,"STRONG",{});var O1a=s(Cxe);Lst=r(O1a,"roformer"),O1a.forEach(t),yst=r(Xeo," \u2014 "),mse=n(Xeo,"A",{href:!0});var V1a=s(mse);xst=r(V1a,"TFRoFormerForMultipleChoice"),V1a.forEach(t),$st=r(Xeo," (RoFormer model)"),Xeo.forEach(t),kst=i(Te),C6=n(Te,"LI",{});var zeo=s(C6);wxe=n(zeo,"STRONG",{});var X1a=s(wxe);Sst=r(X1a,"xlm"),X1a.forEach(t),Rst=r(zeo," \u2014 "),cse=n(zeo,"A",{href:!0});var z1a=s(cse);Pst=r(z1a,"TFXLMForMultipleChoice"),z1a.forEach(t),Bst=r(zeo," (XLM model)"),zeo.forEach(t),Ist=i(Te),w6=n(Te,"LI",{});var Qeo=s(w6);Axe=n(Qeo,"STRONG",{});var Q1a=s(Axe);Nst=r(Q1a,"xlm-roberta"),Q1a.forEach(t),qst=r(Qeo," \u2014 "),fse=n(Qeo,"A",{href:!0});var W1a=s(fse);jst=r(W1a,"TFXLMRobertaForMultipleChoice"),W1a.forEach(t),Dst=r(Qeo," (XLM-RoBERTa model)"),Qeo.forEach(t),Gst=i(Te),A6=n(Te,"LI",{});var Weo=s(A6);Lxe=n(Weo,"STRONG",{});var U1a=s(Lxe);Ost=r(U1a,"xlnet"),U1a.forEach(t),Vst=r(Weo," \u2014 "),gse=n(Weo,"A",{href:!0});var H1a=s(gse);Xst=r(H1a,"TFXLNetForMultipleChoice"),H1a.forEach(t),zst=r(Weo," (XLNet model)"),Weo.forEach(t),Te.forEach(t),Qst=i(Pi),T(L6.$$.fragment,Pi),Pi.forEach(t),Ri.forEach(t),wno=i(c),jc=n(c,"H2",{class:!0});var Xlo=s(jc);y6=n(Xlo,"A",{id:!0,class:!0,href:!0});var J1a=s(y6);yxe=n(J1a,"SPAN",{});var Y1a=s(yxe);T(mP.$$.fragment,Y1a),Y1a.forEach(t),J1a.forEach(t),Wst=i(Xlo),xxe=n(Xlo,"SPAN",{});var Z1a=s(xxe);Ust=r(Z1a,"TFAutoModelForNextSentencePrediction"),Z1a.forEach(t),Xlo.forEach(t),Ano=i(c),vr=n(c,"DIV",{class:!0});var Bi=s(vr);T(cP.$$.fragment,Bi),Hst=i(Bi),Dc=n(Bi,"P",{});var jce=s(Dc);Jst=r(jce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),hse=n(jce,"A",{href:!0});var K1a=s(hse);Yst=r(K1a,"from_pretrained()"),K1a.forEach(t),Zst=r(jce," class method or the "),use=n(jce,"A",{href:!0});var e2a=s(use);Kst=r(e2a,"from_config()"),e2a.forEach(t),elt=r(jce,` class
method.`),jce.forEach(t),olt=i(Bi),fP=n(Bi,"P",{});var zlo=s(fP);rlt=r(zlo,"This class cannot be instantiated directly using "),$xe=n(zlo,"CODE",{});var o2a=s($xe);tlt=r(o2a,"__init__()"),o2a.forEach(t),alt=r(zlo," (throws an error)."),zlo.forEach(t),nlt=i(Bi),sa=n(Bi,"DIV",{class:!0});var Ax=s(sa);T(gP.$$.fragment,Ax),slt=i(Ax),kxe=n(Ax,"P",{});var r2a=s(kxe);llt=r(r2a,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),r2a.forEach(t),ilt=i(Ax),Gc=n(Ax,"P",{});var Dce=s(Gc);dlt=r(Dce,`Note:
Loading a model from its configuration file does `),Sxe=n(Dce,"STRONG",{});var t2a=s(Sxe);mlt=r(t2a,"not"),t2a.forEach(t),clt=r(Dce,` load the model weights. It only affects the
model\u2019s configuration. Use `),pse=n(Dce,"A",{href:!0});var a2a=s(pse);flt=r(a2a,"from_pretrained()"),a2a.forEach(t),glt=r(Dce," to load the model weights."),Dce.forEach(t),hlt=i(Ax),T(x6.$$.fragment,Ax),Ax.forEach(t),ult=i(Bi),Hr=n(Bi,"DIV",{class:!0});var Ii=s(Hr);T(hP.$$.fragment,Ii),plt=i(Ii),Rxe=n(Ii,"P",{});var n2a=s(Rxe);_lt=r(n2a,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),n2a.forEach(t),blt=i(Ii),Xn=n(Ii,"P",{});var Lx=s(Xn);vlt=r(Lx,"The model class to instantiate is selected based on the "),Pxe=n(Lx,"CODE",{});var s2a=s(Pxe);Flt=r(s2a,"model_type"),s2a.forEach(t),Tlt=r(Lx,` property of the config object (either
passed as an argument or loaded from `),Bxe=n(Lx,"CODE",{});var l2a=s(Bxe);Mlt=r(l2a,"pretrained_model_name_or_path"),l2a.forEach(t),Elt=r(Lx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Ixe=n(Lx,"CODE",{});var i2a=s(Ixe);Clt=r(i2a,"pretrained_model_name_or_path"),i2a.forEach(t),wlt=r(Lx,":"),Lx.forEach(t),Alt=i(Ii),uP=n(Ii,"UL",{});var Qlo=s(uP);$6=n(Qlo,"LI",{});var Ueo=s($6);Nxe=n(Ueo,"STRONG",{});var d2a=s(Nxe);Llt=r(d2a,"bert"),d2a.forEach(t),ylt=r(Ueo," \u2014 "),_se=n(Ueo,"A",{href:!0});var m2a=s(_se);xlt=r(m2a,"TFBertForNextSentencePrediction"),m2a.forEach(t),$lt=r(Ueo," (BERT model)"),Ueo.forEach(t),klt=i(Qlo),k6=n(Qlo,"LI",{});var Heo=s(k6);qxe=n(Heo,"STRONG",{});var c2a=s(qxe);Slt=r(c2a,"mobilebert"),c2a.forEach(t),Rlt=r(Heo," \u2014 "),bse=n(Heo,"A",{href:!0});var f2a=s(bse);Plt=r(f2a,"TFMobileBertForNextSentencePrediction"),f2a.forEach(t),Blt=r(Heo," (MobileBERT model)"),Heo.forEach(t),Qlo.forEach(t),Ilt=i(Ii),T(S6.$$.fragment,Ii),Ii.forEach(t),Bi.forEach(t),Lno=i(c),Oc=n(c,"H2",{class:!0});var Wlo=s(Oc);R6=n(Wlo,"A",{id:!0,class:!0,href:!0});var g2a=s(R6);jxe=n(g2a,"SPAN",{});var h2a=s(jxe);T(pP.$$.fragment,h2a),h2a.forEach(t),g2a.forEach(t),Nlt=i(Wlo),Dxe=n(Wlo,"SPAN",{});var u2a=s(Dxe);qlt=r(u2a,"TFAutoModelForTableQuestionAnswering"),u2a.forEach(t),Wlo.forEach(t),yno=i(c),Fr=n(c,"DIV",{class:!0});var Ni=s(Fr);T(_P.$$.fragment,Ni),jlt=i(Ni),Vc=n(Ni,"P",{});var Gce=s(Vc);Dlt=r(Gce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),vse=n(Gce,"A",{href:!0});var p2a=s(vse);Glt=r(p2a,"from_pretrained()"),p2a.forEach(t),Olt=r(Gce," class method or the "),Fse=n(Gce,"A",{href:!0});var _2a=s(Fse);Vlt=r(_2a,"from_config()"),_2a.forEach(t),Xlt=r(Gce,` class
method.`),Gce.forEach(t),zlt=i(Ni),bP=n(Ni,"P",{});var Ulo=s(bP);Qlt=r(Ulo,"This class cannot be instantiated directly using "),Gxe=n(Ulo,"CODE",{});var b2a=s(Gxe);Wlt=r(b2a,"__init__()"),b2a.forEach(t),Ult=r(Ulo," (throws an error)."),Ulo.forEach(t),Hlt=i(Ni),la=n(Ni,"DIV",{class:!0});var yx=s(la);T(vP.$$.fragment,yx),Jlt=i(yx),Oxe=n(yx,"P",{});var v2a=s(Oxe);Ylt=r(v2a,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),v2a.forEach(t),Zlt=i(yx),Xc=n(yx,"P",{});var Oce=s(Xc);Klt=r(Oce,`Note:
Loading a model from its configuration file does `),Vxe=n(Oce,"STRONG",{});var F2a=s(Vxe);eit=r(F2a,"not"),F2a.forEach(t),oit=r(Oce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Tse=n(Oce,"A",{href:!0});var T2a=s(Tse);rit=r(T2a,"from_pretrained()"),T2a.forEach(t),tit=r(Oce," to load the model weights."),Oce.forEach(t),ait=i(yx),T(P6.$$.fragment,yx),yx.forEach(t),nit=i(Ni),Jr=n(Ni,"DIV",{class:!0});var qi=s(Jr);T(FP.$$.fragment,qi),sit=i(qi),Xxe=n(qi,"P",{});var M2a=s(Xxe);lit=r(M2a,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),M2a.forEach(t),iit=i(qi),zn=n(qi,"P",{});var xx=s(zn);dit=r(xx,"The model class to instantiate is selected based on the "),zxe=n(xx,"CODE",{});var E2a=s(zxe);mit=r(E2a,"model_type"),E2a.forEach(t),cit=r(xx,` property of the config object (either
passed as an argument or loaded from `),Qxe=n(xx,"CODE",{});var C2a=s(Qxe);fit=r(C2a,"pretrained_model_name_or_path"),C2a.forEach(t),git=r(xx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wxe=n(xx,"CODE",{});var w2a=s(Wxe);hit=r(w2a,"pretrained_model_name_or_path"),w2a.forEach(t),uit=r(xx,":"),xx.forEach(t),pit=i(qi),Uxe=n(qi,"UL",{});var A2a=s(Uxe);B6=n(A2a,"LI",{});var Jeo=s(B6);Hxe=n(Jeo,"STRONG",{});var L2a=s(Hxe);_it=r(L2a,"tapas"),L2a.forEach(t),bit=r(Jeo," \u2014 "),Mse=n(Jeo,"A",{href:!0});var y2a=s(Mse);vit=r(y2a,"TFTapasForQuestionAnswering"),y2a.forEach(t),Fit=r(Jeo," (TAPAS model)"),Jeo.forEach(t),A2a.forEach(t),Tit=i(qi),T(I6.$$.fragment,qi),qi.forEach(t),Ni.forEach(t),xno=i(c),zc=n(c,"H2",{class:!0});var Hlo=s(zc);N6=n(Hlo,"A",{id:!0,class:!0,href:!0});var x2a=s(N6);Jxe=n(x2a,"SPAN",{});var $2a=s(Jxe);T(TP.$$.fragment,$2a),$2a.forEach(t),x2a.forEach(t),Mit=i(Hlo),Yxe=n(Hlo,"SPAN",{});var k2a=s(Yxe);Eit=r(k2a,"TFAutoModelForDocumentQuestionAnswering"),k2a.forEach(t),Hlo.forEach(t),$no=i(c),Tr=n(c,"DIV",{class:!0});var ji=s(Tr);T(MP.$$.fragment,ji),Cit=i(ji),Qc=n(ji,"P",{});var Vce=s(Qc);wit=r(Vce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),Ese=n(Vce,"A",{href:!0});var S2a=s(Ese);Ait=r(S2a,"from_pretrained()"),S2a.forEach(t),Lit=r(Vce," class method or the "),Cse=n(Vce,"A",{href:!0});var R2a=s(Cse);yit=r(R2a,"from_config()"),R2a.forEach(t),xit=r(Vce,` class
method.`),Vce.forEach(t),$it=i(ji),EP=n(ji,"P",{});var Jlo=s(EP);kit=r(Jlo,"This class cannot be instantiated directly using "),Zxe=n(Jlo,"CODE",{});var P2a=s(Zxe);Sit=r(P2a,"__init__()"),P2a.forEach(t),Rit=r(Jlo," (throws an error)."),Jlo.forEach(t),Pit=i(ji),ia=n(ji,"DIV",{class:!0});var $x=s(ia);T(CP.$$.fragment,$x),Bit=i($x),Kxe=n($x,"P",{});var B2a=s(Kxe);Iit=r(B2a,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),B2a.forEach(t),Nit=i($x),Wc=n($x,"P",{});var Xce=s(Wc);qit=r(Xce,`Note:
Loading a model from its configuration file does `),e$e=n(Xce,"STRONG",{});var I2a=s(e$e);jit=r(I2a,"not"),I2a.forEach(t),Dit=r(Xce,` load the model weights. It only affects the
model\u2019s configuration. Use `),wse=n(Xce,"A",{href:!0});var N2a=s(wse);Git=r(N2a,"from_pretrained()"),N2a.forEach(t),Oit=r(Xce," to load the model weights."),Xce.forEach(t),Vit=i($x),T(q6.$$.fragment,$x),$x.forEach(t),Xit=i(ji),Yr=n(ji,"DIV",{class:!0});var Di=s(Yr);T(wP.$$.fragment,Di),zit=i(Di),o$e=n(Di,"P",{});var q2a=s(o$e);Qit=r(q2a,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),q2a.forEach(t),Wit=i(Di),Qn=n(Di,"P",{});var kx=s(Qn);Uit=r(kx,"The model class to instantiate is selected based on the "),r$e=n(kx,"CODE",{});var j2a=s(r$e);Hit=r(j2a,"model_type"),j2a.forEach(t),Jit=r(kx,` property of the config object (either
passed as an argument or loaded from `),t$e=n(kx,"CODE",{});var D2a=s(t$e);Yit=r(D2a,"pretrained_model_name_or_path"),D2a.forEach(t),Zit=r(kx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a$e=n(kx,"CODE",{});var G2a=s(a$e);Kit=r(G2a,"pretrained_model_name_or_path"),G2a.forEach(t),edt=r(kx,":"),kx.forEach(t),odt=i(Di),n$e=n(Di,"UL",{});var O2a=s(n$e);j6=n(O2a,"LI",{});var Yeo=s(j6);s$e=n(Yeo,"STRONG",{});var V2a=s(s$e);rdt=r(V2a,"layoutlm"),V2a.forEach(t),tdt=r(Yeo," \u2014 "),Ase=n(Yeo,"A",{href:!0});var X2a=s(Ase);adt=r(X2a,"TFLayoutLMForQuestionAnswering"),X2a.forEach(t),ndt=r(Yeo," (LayoutLM model)"),Yeo.forEach(t),O2a.forEach(t),sdt=i(Di),T(D6.$$.fragment,Di),Di.forEach(t),ji.forEach(t),kno=i(c),Uc=n(c,"H2",{class:!0});var Ylo=s(Uc);G6=n(Ylo,"A",{id:!0,class:!0,href:!0});var z2a=s(G6);l$e=n(z2a,"SPAN",{});var Q2a=s(l$e);T(AP.$$.fragment,Q2a),Q2a.forEach(t),z2a.forEach(t),ldt=i(Ylo),i$e=n(Ylo,"SPAN",{});var W2a=s(i$e);idt=r(W2a,"TFAutoModelForTokenClassification"),W2a.forEach(t),Ylo.forEach(t),Sno=i(c),Mr=n(c,"DIV",{class:!0});var Gi=s(Mr);T(LP.$$.fragment,Gi),ddt=i(Gi),Hc=n(Gi,"P",{});var zce=s(Hc);mdt=r(zce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Lse=n(zce,"A",{href:!0});var U2a=s(Lse);cdt=r(U2a,"from_pretrained()"),U2a.forEach(t),fdt=r(zce," class method or the "),yse=n(zce,"A",{href:!0});var H2a=s(yse);gdt=r(H2a,"from_config()"),H2a.forEach(t),hdt=r(zce,` class
method.`),zce.forEach(t),udt=i(Gi),yP=n(Gi,"P",{});var Zlo=s(yP);pdt=r(Zlo,"This class cannot be instantiated directly using "),d$e=n(Zlo,"CODE",{});var J2a=s(d$e);_dt=r(J2a,"__init__()"),J2a.forEach(t),bdt=r(Zlo," (throws an error)."),Zlo.forEach(t),vdt=i(Gi),da=n(Gi,"DIV",{class:!0});var Sx=s(da);T(xP.$$.fragment,Sx),Fdt=i(Sx),m$e=n(Sx,"P",{});var Y2a=s(m$e);Tdt=r(Y2a,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Y2a.forEach(t),Mdt=i(Sx),Jc=n(Sx,"P",{});var Qce=s(Jc);Edt=r(Qce,`Note:
Loading a model from its configuration file does `),c$e=n(Qce,"STRONG",{});var Z2a=s(c$e);Cdt=r(Z2a,"not"),Z2a.forEach(t),wdt=r(Qce,` load the model weights. It only affects the
model\u2019s configuration. Use `),xse=n(Qce,"A",{href:!0});var K2a=s(xse);Adt=r(K2a,"from_pretrained()"),K2a.forEach(t),Ldt=r(Qce," to load the model weights."),Qce.forEach(t),ydt=i(Sx),T(O6.$$.fragment,Sx),Sx.forEach(t),xdt=i(Gi),Zr=n(Gi,"DIV",{class:!0});var Oi=s(Zr);T($P.$$.fragment,Oi),$dt=i(Oi),f$e=n(Oi,"P",{});var eba=s(f$e);kdt=r(eba,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),eba.forEach(t),Sdt=i(Oi),Wn=n(Oi,"P",{});var Rx=s(Wn);Rdt=r(Rx,"The model class to instantiate is selected based on the "),g$e=n(Rx,"CODE",{});var oba=s(g$e);Pdt=r(oba,"model_type"),oba.forEach(t),Bdt=r(Rx,` property of the config object (either
passed as an argument or loaded from `),h$e=n(Rx,"CODE",{});var rba=s(h$e);Idt=r(rba,"pretrained_model_name_or_path"),rba.forEach(t),Ndt=r(Rx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u$e=n(Rx,"CODE",{});var tba=s(u$e);qdt=r(tba,"pretrained_model_name_or_path"),tba.forEach(t),jdt=r(Rx,":"),Rx.forEach(t),Ddt=i(Oi),ie=n(Oi,"UL",{});var ge=s(ie);V6=n(ge,"LI",{});var Zeo=s(V6);p$e=n(Zeo,"STRONG",{});var aba=s(p$e);Gdt=r(aba,"albert"),aba.forEach(t),Odt=r(Zeo," \u2014 "),$se=n(Zeo,"A",{href:!0});var nba=s($se);Vdt=r(nba,"TFAlbertForTokenClassification"),nba.forEach(t),Xdt=r(Zeo," (ALBERT model)"),Zeo.forEach(t),zdt=i(ge),X6=n(ge,"LI",{});var Keo=s(X6);_$e=n(Keo,"STRONG",{});var sba=s(_$e);Qdt=r(sba,"bert"),sba.forEach(t),Wdt=r(Keo," \u2014 "),kse=n(Keo,"A",{href:!0});var lba=s(kse);Udt=r(lba,"TFBertForTokenClassification"),lba.forEach(t),Hdt=r(Keo," (BERT model)"),Keo.forEach(t),Jdt=i(ge),z6=n(ge,"LI",{});var eoo=s(z6);b$e=n(eoo,"STRONG",{});var iba=s(b$e);Ydt=r(iba,"camembert"),iba.forEach(t),Zdt=r(eoo," \u2014 "),Sse=n(eoo,"A",{href:!0});var dba=s(Sse);Kdt=r(dba,"TFCamembertForTokenClassification"),dba.forEach(t),emt=r(eoo," (CamemBERT model)"),eoo.forEach(t),omt=i(ge),Q6=n(ge,"LI",{});var ooo=s(Q6);v$e=n(ooo,"STRONG",{});var mba=s(v$e);rmt=r(mba,"convbert"),mba.forEach(t),tmt=r(ooo," \u2014 "),Rse=n(ooo,"A",{href:!0});var cba=s(Rse);amt=r(cba,"TFConvBertForTokenClassification"),cba.forEach(t),nmt=r(ooo," (ConvBERT model)"),ooo.forEach(t),smt=i(ge),W6=n(ge,"LI",{});var roo=s(W6);F$e=n(roo,"STRONG",{});var fba=s(F$e);lmt=r(fba,"deberta"),fba.forEach(t),imt=r(roo," \u2014 "),Pse=n(roo,"A",{href:!0});var gba=s(Pse);dmt=r(gba,"TFDebertaForTokenClassification"),gba.forEach(t),mmt=r(roo," (DeBERTa model)"),roo.forEach(t),cmt=i(ge),U6=n(ge,"LI",{});var too=s(U6);T$e=n(too,"STRONG",{});var hba=s(T$e);fmt=r(hba,"deberta-v2"),hba.forEach(t),gmt=r(too," \u2014 "),Bse=n(too,"A",{href:!0});var uba=s(Bse);hmt=r(uba,"TFDebertaV2ForTokenClassification"),uba.forEach(t),umt=r(too," (DeBERTa-v2 model)"),too.forEach(t),pmt=i(ge),H6=n(ge,"LI",{});var aoo=s(H6);M$e=n(aoo,"STRONG",{});var pba=s(M$e);_mt=r(pba,"distilbert"),pba.forEach(t),bmt=r(aoo," \u2014 "),Ise=n(aoo,"A",{href:!0});var _ba=s(Ise);vmt=r(_ba,"TFDistilBertForTokenClassification"),_ba.forEach(t),Fmt=r(aoo," (DistilBERT model)"),aoo.forEach(t),Tmt=i(ge),J6=n(ge,"LI",{});var noo=s(J6);E$e=n(noo,"STRONG",{});var bba=s(E$e);Mmt=r(bba,"electra"),bba.forEach(t),Emt=r(noo," \u2014 "),Nse=n(noo,"A",{href:!0});var vba=s(Nse);Cmt=r(vba,"TFElectraForTokenClassification"),vba.forEach(t),wmt=r(noo," (ELECTRA model)"),noo.forEach(t),Amt=i(ge),Y6=n(ge,"LI",{});var soo=s(Y6);C$e=n(soo,"STRONG",{});var Fba=s(C$e);Lmt=r(Fba,"esm"),Fba.forEach(t),ymt=r(soo," \u2014 "),qse=n(soo,"A",{href:!0});var Tba=s(qse);xmt=r(Tba,"TFEsmForTokenClassification"),Tba.forEach(t),$mt=r(soo," (ESM model)"),soo.forEach(t),kmt=i(ge),Z6=n(ge,"LI",{});var loo=s(Z6);w$e=n(loo,"STRONG",{});var Mba=s(w$e);Smt=r(Mba,"flaubert"),Mba.forEach(t),Rmt=r(loo," \u2014 "),jse=n(loo,"A",{href:!0});var Eba=s(jse);Pmt=r(Eba,"TFFlaubertForTokenClassification"),Eba.forEach(t),Bmt=r(loo," (FlauBERT model)"),loo.forEach(t),Imt=i(ge),K6=n(ge,"LI",{});var ioo=s(K6);A$e=n(ioo,"STRONG",{});var Cba=s(A$e);Nmt=r(Cba,"funnel"),Cba.forEach(t),qmt=r(ioo," \u2014 "),Dse=n(ioo,"A",{href:!0});var wba=s(Dse);jmt=r(wba,"TFFunnelForTokenClassification"),wba.forEach(t),Dmt=r(ioo," (Funnel Transformer model)"),ioo.forEach(t),Gmt=i(ge),e7=n(ge,"LI",{});var doo=s(e7);L$e=n(doo,"STRONG",{});var Aba=s(L$e);Omt=r(Aba,"layoutlm"),Aba.forEach(t),Vmt=r(doo," \u2014 "),Gse=n(doo,"A",{href:!0});var Lba=s(Gse);Xmt=r(Lba,"TFLayoutLMForTokenClassification"),Lba.forEach(t),zmt=r(doo," (LayoutLM model)"),doo.forEach(t),Qmt=i(ge),o7=n(ge,"LI",{});var moo=s(o7);y$e=n(moo,"STRONG",{});var yba=s(y$e);Wmt=r(yba,"layoutlmv3"),yba.forEach(t),Umt=r(moo," \u2014 "),Ose=n(moo,"A",{href:!0});var xba=s(Ose);Hmt=r(xba,"TFLayoutLMv3ForTokenClassification"),xba.forEach(t),Jmt=r(moo," (LayoutLMv3 model)"),moo.forEach(t),Ymt=i(ge),r7=n(ge,"LI",{});var coo=s(r7);x$e=n(coo,"STRONG",{});var $ba=s(x$e);Zmt=r($ba,"longformer"),$ba.forEach(t),Kmt=r(coo," \u2014 "),Vse=n(coo,"A",{href:!0});var kba=s(Vse);ect=r(kba,"TFLongformerForTokenClassification"),kba.forEach(t),oct=r(coo," (Longformer model)"),coo.forEach(t),rct=i(ge),t7=n(ge,"LI",{});var foo=s(t7);$$e=n(foo,"STRONG",{});var Sba=s($$e);tct=r(Sba,"mobilebert"),Sba.forEach(t),act=r(foo," \u2014 "),Xse=n(foo,"A",{href:!0});var Rba=s(Xse);nct=r(Rba,"TFMobileBertForTokenClassification"),Rba.forEach(t),sct=r(foo," (MobileBERT model)"),foo.forEach(t),lct=i(ge),a7=n(ge,"LI",{});var goo=s(a7);k$e=n(goo,"STRONG",{});var Pba=s(k$e);ict=r(Pba,"mpnet"),Pba.forEach(t),dct=r(goo," \u2014 "),zse=n(goo,"A",{href:!0});var Bba=s(zse);mct=r(Bba,"TFMPNetForTokenClassification"),Bba.forEach(t),cct=r(goo," (MPNet model)"),goo.forEach(t),fct=i(ge),n7=n(ge,"LI",{});var hoo=s(n7);S$e=n(hoo,"STRONG",{});var Iba=s(S$e);gct=r(Iba,"rembert"),Iba.forEach(t),hct=r(hoo," \u2014 "),Qse=n(hoo,"A",{href:!0});var Nba=s(Qse);uct=r(Nba,"TFRemBertForTokenClassification"),Nba.forEach(t),pct=r(hoo," (RemBERT model)"),hoo.forEach(t),_ct=i(ge),s7=n(ge,"LI",{});var uoo=s(s7);R$e=n(uoo,"STRONG",{});var qba=s(R$e);bct=r(qba,"roberta"),qba.forEach(t),vct=r(uoo," \u2014 "),Wse=n(uoo,"A",{href:!0});var jba=s(Wse);Fct=r(jba,"TFRobertaForTokenClassification"),jba.forEach(t),Tct=r(uoo," (RoBERTa model)"),uoo.forEach(t),Mct=i(ge),l7=n(ge,"LI",{});var poo=s(l7);P$e=n(poo,"STRONG",{});var Dba=s(P$e);Ect=r(Dba,"roformer"),Dba.forEach(t),Cct=r(poo," \u2014 "),Use=n(poo,"A",{href:!0});var Gba=s(Use);wct=r(Gba,"TFRoFormerForTokenClassification"),Gba.forEach(t),Act=r(poo," (RoFormer model)"),poo.forEach(t),Lct=i(ge),i7=n(ge,"LI",{});var _oo=s(i7);B$e=n(_oo,"STRONG",{});var Oba=s(B$e);yct=r(Oba,"xlm"),Oba.forEach(t),xct=r(_oo," \u2014 "),Hse=n(_oo,"A",{href:!0});var Vba=s(Hse);$ct=r(Vba,"TFXLMForTokenClassification"),Vba.forEach(t),kct=r(_oo," (XLM model)"),_oo.forEach(t),Sct=i(ge),d7=n(ge,"LI",{});var boo=s(d7);I$e=n(boo,"STRONG",{});var Xba=s(I$e);Rct=r(Xba,"xlm-roberta"),Xba.forEach(t),Pct=r(boo," \u2014 "),Jse=n(boo,"A",{href:!0});var zba=s(Jse);Bct=r(zba,"TFXLMRobertaForTokenClassification"),zba.forEach(t),Ict=r(boo," (XLM-RoBERTa model)"),boo.forEach(t),Nct=i(ge),m7=n(ge,"LI",{});var voo=s(m7);N$e=n(voo,"STRONG",{});var Qba=s(N$e);qct=r(Qba,"xlnet"),Qba.forEach(t),jct=r(voo," \u2014 "),Yse=n(voo,"A",{href:!0});var Wba=s(Yse);Dct=r(Wba,"TFXLNetForTokenClassification"),Wba.forEach(t),Gct=r(voo," (XLNet model)"),voo.forEach(t),ge.forEach(t),Oct=i(Oi),T(c7.$$.fragment,Oi),Oi.forEach(t),Gi.forEach(t),Rno=i(c),Yc=n(c,"H2",{class:!0});var Klo=s(Yc);f7=n(Klo,"A",{id:!0,class:!0,href:!0});var Uba=s(f7);q$e=n(Uba,"SPAN",{});var Hba=s(q$e);T(kP.$$.fragment,Hba),Hba.forEach(t),Uba.forEach(t),Vct=i(Klo),j$e=n(Klo,"SPAN",{});var Jba=s(j$e);Xct=r(Jba,"TFAutoModelForQuestionAnswering"),Jba.forEach(t),Klo.forEach(t),Pno=i(c),Er=n(c,"DIV",{class:!0});var Vi=s(Er);T(SP.$$.fragment,Vi),zct=i(Vi),Zc=n(Vi,"P",{});var Wce=s(Zc);Qct=r(Wce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Zse=n(Wce,"A",{href:!0});var Yba=s(Zse);Wct=r(Yba,"from_pretrained()"),Yba.forEach(t),Uct=r(Wce," class method or the "),Kse=n(Wce,"A",{href:!0});var Zba=s(Kse);Hct=r(Zba,"from_config()"),Zba.forEach(t),Jct=r(Wce,` class
method.`),Wce.forEach(t),Yct=i(Vi),RP=n(Vi,"P",{});var eio=s(RP);Zct=r(eio,"This class cannot be instantiated directly using "),D$e=n(eio,"CODE",{});var Kba=s(D$e);Kct=r(Kba,"__init__()"),Kba.forEach(t),eft=r(eio," (throws an error)."),eio.forEach(t),oft=i(Vi),ma=n(Vi,"DIV",{class:!0});var Px=s(ma);T(PP.$$.fragment,Px),rft=i(Px),G$e=n(Px,"P",{});var eva=s(G$e);tft=r(eva,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),eva.forEach(t),aft=i(Px),Kc=n(Px,"P",{});var Uce=s(Kc);nft=r(Uce,`Note:
Loading a model from its configuration file does `),O$e=n(Uce,"STRONG",{});var ova=s(O$e);sft=r(ova,"not"),ova.forEach(t),lft=r(Uce,` load the model weights. It only affects the
model\u2019s configuration. Use `),ele=n(Uce,"A",{href:!0});var rva=s(ele);ift=r(rva,"from_pretrained()"),rva.forEach(t),dft=r(Uce," to load the model weights."),Uce.forEach(t),mft=i(Px),T(g7.$$.fragment,Px),Px.forEach(t),cft=i(Vi),Kr=n(Vi,"DIV",{class:!0});var Xi=s(Kr);T(BP.$$.fragment,Xi),fft=i(Xi),V$e=n(Xi,"P",{});var tva=s(V$e);gft=r(tva,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),tva.forEach(t),hft=i(Xi),Un=n(Xi,"P",{});var Bx=s(Un);uft=r(Bx,"The model class to instantiate is selected based on the "),X$e=n(Bx,"CODE",{});var ava=s(X$e);pft=r(ava,"model_type"),ava.forEach(t),_ft=r(Bx,` property of the config object (either
passed as an argument or loaded from `),z$e=n(Bx,"CODE",{});var nva=s(z$e);bft=r(nva,"pretrained_model_name_or_path"),nva.forEach(t),vft=r(Bx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q$e=n(Bx,"CODE",{});var sva=s(Q$e);Fft=r(sva,"pretrained_model_name_or_path"),sva.forEach(t),Tft=r(Bx,":"),Bx.forEach(t),Mft=i(Xi),fe=n(Xi,"UL",{});var pe=s(fe);h7=n(pe,"LI",{});var Foo=s(h7);W$e=n(Foo,"STRONG",{});var lva=s(W$e);Eft=r(lva,"albert"),lva.forEach(t),Cft=r(Foo," \u2014 "),ole=n(Foo,"A",{href:!0});var iva=s(ole);wft=r(iva,"TFAlbertForQuestionAnswering"),iva.forEach(t),Aft=r(Foo," (ALBERT model)"),Foo.forEach(t),Lft=i(pe),u7=n(pe,"LI",{});var Too=s(u7);U$e=n(Too,"STRONG",{});var dva=s(U$e);yft=r(dva,"bert"),dva.forEach(t),xft=r(Too," \u2014 "),rle=n(Too,"A",{href:!0});var mva=s(rle);$ft=r(mva,"TFBertForQuestionAnswering"),mva.forEach(t),kft=r(Too," (BERT model)"),Too.forEach(t),Sft=i(pe),p7=n(pe,"LI",{});var Moo=s(p7);H$e=n(Moo,"STRONG",{});var cva=s(H$e);Rft=r(cva,"camembert"),cva.forEach(t),Pft=r(Moo," \u2014 "),tle=n(Moo,"A",{href:!0});var fva=s(tle);Bft=r(fva,"TFCamembertForQuestionAnswering"),fva.forEach(t),Ift=r(Moo," (CamemBERT model)"),Moo.forEach(t),Nft=i(pe),_7=n(pe,"LI",{});var Eoo=s(_7);J$e=n(Eoo,"STRONG",{});var gva=s(J$e);qft=r(gva,"convbert"),gva.forEach(t),jft=r(Eoo," \u2014 "),ale=n(Eoo,"A",{href:!0});var hva=s(ale);Dft=r(hva,"TFConvBertForQuestionAnswering"),hva.forEach(t),Gft=r(Eoo," (ConvBERT model)"),Eoo.forEach(t),Oft=i(pe),b7=n(pe,"LI",{});var Coo=s(b7);Y$e=n(Coo,"STRONG",{});var uva=s(Y$e);Vft=r(uva,"deberta"),uva.forEach(t),Xft=r(Coo," \u2014 "),nle=n(Coo,"A",{href:!0});var pva=s(nle);zft=r(pva,"TFDebertaForQuestionAnswering"),pva.forEach(t),Qft=r(Coo," (DeBERTa model)"),Coo.forEach(t),Wft=i(pe),v7=n(pe,"LI",{});var woo=s(v7);Z$e=n(woo,"STRONG",{});var _va=s(Z$e);Uft=r(_va,"deberta-v2"),_va.forEach(t),Hft=r(woo," \u2014 "),sle=n(woo,"A",{href:!0});var bva=s(sle);Jft=r(bva,"TFDebertaV2ForQuestionAnswering"),bva.forEach(t),Yft=r(woo," (DeBERTa-v2 model)"),woo.forEach(t),Zft=i(pe),F7=n(pe,"LI",{});var Aoo=s(F7);K$e=n(Aoo,"STRONG",{});var vva=s(K$e);Kft=r(vva,"distilbert"),vva.forEach(t),egt=r(Aoo," \u2014 "),lle=n(Aoo,"A",{href:!0});var Fva=s(lle);ogt=r(Fva,"TFDistilBertForQuestionAnswering"),Fva.forEach(t),rgt=r(Aoo," (DistilBERT model)"),Aoo.forEach(t),tgt=i(pe),T7=n(pe,"LI",{});var Loo=s(T7);eke=n(Loo,"STRONG",{});var Tva=s(eke);agt=r(Tva,"electra"),Tva.forEach(t),ngt=r(Loo," \u2014 "),ile=n(Loo,"A",{href:!0});var Mva=s(ile);sgt=r(Mva,"TFElectraForQuestionAnswering"),Mva.forEach(t),lgt=r(Loo," (ELECTRA model)"),Loo.forEach(t),igt=i(pe),M7=n(pe,"LI",{});var yoo=s(M7);oke=n(yoo,"STRONG",{});var Eva=s(oke);dgt=r(Eva,"flaubert"),Eva.forEach(t),mgt=r(yoo," \u2014 "),dle=n(yoo,"A",{href:!0});var Cva=s(dle);cgt=r(Cva,"TFFlaubertForQuestionAnsweringSimple"),Cva.forEach(t),fgt=r(yoo," (FlauBERT model)"),yoo.forEach(t),ggt=i(pe),E7=n(pe,"LI",{});var xoo=s(E7);rke=n(xoo,"STRONG",{});var wva=s(rke);hgt=r(wva,"funnel"),wva.forEach(t),ugt=r(xoo," \u2014 "),mle=n(xoo,"A",{href:!0});var Ava=s(mle);pgt=r(Ava,"TFFunnelForQuestionAnswering"),Ava.forEach(t),_gt=r(xoo," (Funnel Transformer model)"),xoo.forEach(t),bgt=i(pe),C7=n(pe,"LI",{});var $oo=s(C7);tke=n($oo,"STRONG",{});var Lva=s(tke);vgt=r(Lva,"gptj"),Lva.forEach(t),Fgt=r($oo," \u2014 "),cle=n($oo,"A",{href:!0});var yva=s(cle);Tgt=r(yva,"TFGPTJForQuestionAnswering"),yva.forEach(t),Mgt=r($oo," (GPT-J model)"),$oo.forEach(t),Egt=i(pe),w7=n(pe,"LI",{});var koo=s(w7);ake=n(koo,"STRONG",{});var xva=s(ake);Cgt=r(xva,"layoutlmv3"),xva.forEach(t),wgt=r(koo," \u2014 "),fle=n(koo,"A",{href:!0});var $va=s(fle);Agt=r($va,"TFLayoutLMv3ForQuestionAnswering"),$va.forEach(t),Lgt=r(koo," (LayoutLMv3 model)"),koo.forEach(t),ygt=i(pe),A7=n(pe,"LI",{});var Soo=s(A7);nke=n(Soo,"STRONG",{});var kva=s(nke);xgt=r(kva,"longformer"),kva.forEach(t),$gt=r(Soo," \u2014 "),gle=n(Soo,"A",{href:!0});var Sva=s(gle);kgt=r(Sva,"TFLongformerForQuestionAnswering"),Sva.forEach(t),Sgt=r(Soo," (Longformer model)"),Soo.forEach(t),Rgt=i(pe),L7=n(pe,"LI",{});var Roo=s(L7);ske=n(Roo,"STRONG",{});var Rva=s(ske);Pgt=r(Rva,"mobilebert"),Rva.forEach(t),Bgt=r(Roo," \u2014 "),hle=n(Roo,"A",{href:!0});var Pva=s(hle);Igt=r(Pva,"TFMobileBertForQuestionAnswering"),Pva.forEach(t),Ngt=r(Roo," (MobileBERT model)"),Roo.forEach(t),qgt=i(pe),y7=n(pe,"LI",{});var Poo=s(y7);lke=n(Poo,"STRONG",{});var Bva=s(lke);jgt=r(Bva,"mpnet"),Bva.forEach(t),Dgt=r(Poo," \u2014 "),ule=n(Poo,"A",{href:!0});var Iva=s(ule);Ggt=r(Iva,"TFMPNetForQuestionAnswering"),Iva.forEach(t),Ogt=r(Poo," (MPNet model)"),Poo.forEach(t),Vgt=i(pe),x7=n(pe,"LI",{});var Boo=s(x7);ike=n(Boo,"STRONG",{});var Nva=s(ike);Xgt=r(Nva,"rembert"),Nva.forEach(t),zgt=r(Boo," \u2014 "),ple=n(Boo,"A",{href:!0});var qva=s(ple);Qgt=r(qva,"TFRemBertForQuestionAnswering"),qva.forEach(t),Wgt=r(Boo," (RemBERT model)"),Boo.forEach(t),Ugt=i(pe),$7=n(pe,"LI",{});var Ioo=s($7);dke=n(Ioo,"STRONG",{});var jva=s(dke);Hgt=r(jva,"roberta"),jva.forEach(t),Jgt=r(Ioo," \u2014 "),_le=n(Ioo,"A",{href:!0});var Dva=s(_le);Ygt=r(Dva,"TFRobertaForQuestionAnswering"),Dva.forEach(t),Zgt=r(Ioo," (RoBERTa model)"),Ioo.forEach(t),Kgt=i(pe),k7=n(pe,"LI",{});var Noo=s(k7);mke=n(Noo,"STRONG",{});var Gva=s(mke);eht=r(Gva,"roformer"),Gva.forEach(t),oht=r(Noo," \u2014 "),ble=n(Noo,"A",{href:!0});var Ova=s(ble);rht=r(Ova,"TFRoFormerForQuestionAnswering"),Ova.forEach(t),tht=r(Noo," (RoFormer model)"),Noo.forEach(t),aht=i(pe),S7=n(pe,"LI",{});var qoo=s(S7);cke=n(qoo,"STRONG",{});var Vva=s(cke);nht=r(Vva,"xlm"),Vva.forEach(t),sht=r(qoo," \u2014 "),vle=n(qoo,"A",{href:!0});var Xva=s(vle);lht=r(Xva,"TFXLMForQuestionAnsweringSimple"),Xva.forEach(t),iht=r(qoo," (XLM model)"),qoo.forEach(t),dht=i(pe),R7=n(pe,"LI",{});var joo=s(R7);fke=n(joo,"STRONG",{});var zva=s(fke);mht=r(zva,"xlm-roberta"),zva.forEach(t),cht=r(joo," \u2014 "),Fle=n(joo,"A",{href:!0});var Qva=s(Fle);fht=r(Qva,"TFXLMRobertaForQuestionAnswering"),Qva.forEach(t),ght=r(joo," (XLM-RoBERTa model)"),joo.forEach(t),hht=i(pe),P7=n(pe,"LI",{});var Doo=s(P7);gke=n(Doo,"STRONG",{});var Wva=s(gke);uht=r(Wva,"xlnet"),Wva.forEach(t),pht=r(Doo," \u2014 "),Tle=n(Doo,"A",{href:!0});var Uva=s(Tle);_ht=r(Uva,"TFXLNetForQuestionAnsweringSimple"),Uva.forEach(t),bht=r(Doo," (XLNet model)"),Doo.forEach(t),pe.forEach(t),vht=i(Xi),T(B7.$$.fragment,Xi),Xi.forEach(t),Vi.forEach(t),Bno=i(c),ef=n(c,"H2",{class:!0});var oio=s(ef);I7=n(oio,"A",{id:!0,class:!0,href:!0});var Hva=s(I7);hke=n(Hva,"SPAN",{});var Jva=s(hke);T(IP.$$.fragment,Jva),Jva.forEach(t),Hva.forEach(t),Fht=i(oio),uke=n(oio,"SPAN",{});var Yva=s(uke);Tht=r(Yva,"TFAutoModelForVision2Seq"),Yva.forEach(t),oio.forEach(t),Ino=i(c),Cr=n(c,"DIV",{class:!0});var zi=s(Cr);T(NP.$$.fragment,zi),Mht=i(zi),of=n(zi,"P",{});var Hce=s(of);Eht=r(Hce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Mle=n(Hce,"A",{href:!0});var Zva=s(Mle);Cht=r(Zva,"from_pretrained()"),Zva.forEach(t),wht=r(Hce," class method or the "),Ele=n(Hce,"A",{href:!0});var Kva=s(Ele);Aht=r(Kva,"from_config()"),Kva.forEach(t),Lht=r(Hce,` class
method.`),Hce.forEach(t),yht=i(zi),qP=n(zi,"P",{});var rio=s(qP);xht=r(rio,"This class cannot be instantiated directly using "),pke=n(rio,"CODE",{});var eFa=s(pke);$ht=r(eFa,"__init__()"),eFa.forEach(t),kht=r(rio," (throws an error)."),rio.forEach(t),Sht=i(zi),ca=n(zi,"DIV",{class:!0});var Ix=s(ca);T(jP.$$.fragment,Ix),Rht=i(Ix),_ke=n(Ix,"P",{});var oFa=s(_ke);Pht=r(oFa,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),oFa.forEach(t),Bht=i(Ix),rf=n(Ix,"P",{});var Jce=s(rf);Iht=r(Jce,`Note:
Loading a model from its configuration file does `),bke=n(Jce,"STRONG",{});var rFa=s(bke);Nht=r(rFa,"not"),rFa.forEach(t),qht=r(Jce,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cle=n(Jce,"A",{href:!0});var tFa=s(Cle);jht=r(tFa,"from_pretrained()"),tFa.forEach(t),Dht=r(Jce," to load the model weights."),Jce.forEach(t),Ght=i(Ix),T(N7.$$.fragment,Ix),Ix.forEach(t),Oht=i(zi),et=n(zi,"DIV",{class:!0});var Qi=s(et);T(DP.$$.fragment,Qi),Vht=i(Qi),vke=n(Qi,"P",{});var aFa=s(vke);Xht=r(aFa,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),aFa.forEach(t),zht=i(Qi),Hn=n(Qi,"P",{});var Nx=s(Hn);Qht=r(Nx,"The model class to instantiate is selected based on the "),Fke=n(Nx,"CODE",{});var nFa=s(Fke);Wht=r(nFa,"model_type"),nFa.forEach(t),Uht=r(Nx,` property of the config object (either
passed as an argument or loaded from `),Tke=n(Nx,"CODE",{});var sFa=s(Tke);Hht=r(sFa,"pretrained_model_name_or_path"),sFa.forEach(t),Jht=r(Nx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Mke=n(Nx,"CODE",{});var lFa=s(Mke);Yht=r(lFa,"pretrained_model_name_or_path"),lFa.forEach(t),Zht=r(Nx,":"),Nx.forEach(t),Kht=i(Qi),Eke=n(Qi,"UL",{});var iFa=s(Eke);q7=n(iFa,"LI",{});var Goo=s(q7);Cke=n(Goo,"STRONG",{});var dFa=s(Cke);eut=r(dFa,"vision-encoder-decoder"),dFa.forEach(t),out=r(Goo," \u2014 "),wle=n(Goo,"A",{href:!0});var mFa=s(wle);rut=r(mFa,"TFVisionEncoderDecoderModel"),mFa.forEach(t),tut=r(Goo," (Vision Encoder decoder model)"),Goo.forEach(t),iFa.forEach(t),aut=i(Qi),T(j7.$$.fragment,Qi),Qi.forEach(t),zi.forEach(t),Nno=i(c),tf=n(c,"H2",{class:!0});var tio=s(tf);D7=n(tio,"A",{id:!0,class:!0,href:!0});var cFa=s(D7);wke=n(cFa,"SPAN",{});var fFa=s(wke);T(GP.$$.fragment,fFa),fFa.forEach(t),cFa.forEach(t),nut=i(tio),Ake=n(tio,"SPAN",{});var gFa=s(Ake);sut=r(gFa,"TFAutoModelForSpeechSeq2Seq"),gFa.forEach(t),tio.forEach(t),qno=i(c),wr=n(c,"DIV",{class:!0});var Wi=s(wr);T(OP.$$.fragment,Wi),lut=i(Wi),af=n(Wi,"P",{});var Yce=s(af);iut=r(Yce,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Ale=n(Yce,"A",{href:!0});var hFa=s(Ale);dut=r(hFa,"from_pretrained()"),hFa.forEach(t),mut=r(Yce," class method or the "),Lle=n(Yce,"A",{href:!0});var uFa=s(Lle);cut=r(uFa,"from_config()"),uFa.forEach(t),fut=r(Yce,` class
method.`),Yce.forEach(t),gut=i(Wi),VP=n(Wi,"P",{});var aio=s(VP);hut=r(aio,"This class cannot be instantiated directly using "),Lke=n(aio,"CODE",{});var pFa=s(Lke);uut=r(pFa,"__init__()"),pFa.forEach(t),put=r(aio," (throws an error)."),aio.forEach(t),_ut=i(Wi),fa=n(Wi,"DIV",{class:!0});var qx=s(fa);T(XP.$$.fragment,qx),but=i(qx),yke=n(qx,"P",{});var _Fa=s(yke);vut=r(_Fa,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),_Fa.forEach(t),Fut=i(qx),nf=n(qx,"P",{});var Zce=s(nf);Tut=r(Zce,`Note:
Loading a model from its configuration file does `),xke=n(Zce,"STRONG",{});var bFa=s(xke);Mut=r(bFa,"not"),bFa.forEach(t),Eut=r(Zce,` load the model weights. It only affects the
model\u2019s configuration. Use `),yle=n(Zce,"A",{href:!0});var vFa=s(yle);Cut=r(vFa,"from_pretrained()"),vFa.forEach(t),wut=r(Zce," to load the model weights."),Zce.forEach(t),Aut=i(qx),T(G7.$$.fragment,qx),qx.forEach(t),Lut=i(Wi),ot=n(Wi,"DIV",{class:!0});var Ui=s(ot);T(zP.$$.fragment,Ui),yut=i(Ui),$ke=n(Ui,"P",{});var FFa=s($ke);xut=r(FFa,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),FFa.forEach(t),$ut=i(Ui),Jn=n(Ui,"P",{});var jx=s(Jn);kut=r(jx,"The model class to instantiate is selected based on the "),kke=n(jx,"CODE",{});var TFa=s(kke);Sut=r(TFa,"model_type"),TFa.forEach(t),Rut=r(jx,` property of the config object (either
passed as an argument or loaded from `),Ske=n(jx,"CODE",{});var MFa=s(Ske);Put=r(MFa,"pretrained_model_name_or_path"),MFa.forEach(t),But=r(jx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rke=n(jx,"CODE",{});var EFa=s(Rke);Iut=r(EFa,"pretrained_model_name_or_path"),EFa.forEach(t),Nut=r(jx,":"),jx.forEach(t),qut=i(Ui),QP=n(Ui,"UL",{});var nio=s(QP);O7=n(nio,"LI",{});var Ooo=s(O7);Pke=n(Ooo,"STRONG",{});var CFa=s(Pke);jut=r(CFa,"speech_to_text"),CFa.forEach(t),Dut=r(Ooo," \u2014 "),xle=n(Ooo,"A",{href:!0});var wFa=s(xle);Gut=r(wFa,"TFSpeech2TextForConditionalGeneration"),wFa.forEach(t),Out=r(Ooo," (Speech2Text model)"),Ooo.forEach(t),Vut=i(nio),V7=n(nio,"LI",{});var Voo=s(V7);Bke=n(Voo,"STRONG",{});var AFa=s(Bke);Xut=r(AFa,"whisper"),AFa.forEach(t),zut=r(Voo," \u2014 "),$le=n(Voo,"A",{href:!0});var LFa=s($le);Qut=r(LFa,"TFWhisperForConditionalGeneration"),LFa.forEach(t),Wut=r(Voo," (Whisper model)"),Voo.forEach(t),nio.forEach(t),Uut=i(Ui),T(X7.$$.fragment,Ui),Ui.forEach(t),Wi.forEach(t),jno=i(c),sf=n(c,"H2",{class:!0});var sio=s(sf);z7=n(sio,"A",{id:!0,class:!0,href:!0});var yFa=s(z7);Ike=n(yFa,"SPAN",{});var xFa=s(Ike);T(WP.$$.fragment,xFa),xFa.forEach(t),yFa.forEach(t),Hut=i(sio),Nke=n(sio,"SPAN",{});var $Fa=s(Nke);Jut=r($Fa,"FlaxAutoModel"),$Fa.forEach(t),sio.forEach(t),Dno=i(c),Ar=n(c,"DIV",{class:!0});var Hi=s(Ar);T(UP.$$.fragment,Hi),Yut=i(Hi),lf=n(Hi,"P",{});var Kce=s(lf);Zut=r(Kce,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),kle=n(Kce,"A",{href:!0});var kFa=s(kle);Kut=r(kFa,"from_pretrained()"),kFa.forEach(t),ept=r(Kce," class method or the "),Sle=n(Kce,"A",{href:!0});var SFa=s(Sle);opt=r(SFa,"from_config()"),SFa.forEach(t),rpt=r(Kce,` class
method.`),Kce.forEach(t),tpt=i(Hi),HP=n(Hi,"P",{});var lio=s(HP);apt=r(lio,"This class cannot be instantiated directly using "),qke=n(lio,"CODE",{});var RFa=s(qke);npt=r(RFa,"__init__()"),RFa.forEach(t),spt=r(lio," (throws an error)."),lio.forEach(t),lpt=i(Hi),ga=n(Hi,"DIV",{class:!0});var Dx=s(ga);T(JP.$$.fragment,Dx),ipt=i(Dx),jke=n(Dx,"P",{});var PFa=s(jke);dpt=r(PFa,"Instantiates one of the base model classes of the library from a configuration."),PFa.forEach(t),mpt=i(Dx),df=n(Dx,"P",{});var efe=s(df);cpt=r(efe,`Note:
Loading a model from its configuration file does `),Dke=n(efe,"STRONG",{});var BFa=s(Dke);fpt=r(BFa,"not"),BFa.forEach(t),gpt=r(efe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Rle=n(efe,"A",{href:!0});var IFa=s(Rle);hpt=r(IFa,"from_pretrained()"),IFa.forEach(t),upt=r(efe," to load the model weights."),efe.forEach(t),ppt=i(Dx),T(Q7.$$.fragment,Dx),Dx.forEach(t),_pt=i(Hi),rt=n(Hi,"DIV",{class:!0});var Ji=s(rt);T(YP.$$.fragment,Ji),bpt=i(Ji),Gke=n(Ji,"P",{});var NFa=s(Gke);vpt=r(NFa,"Instantiate one of the base model classes of the library from a pretrained model."),NFa.forEach(t),Fpt=i(Ji),Yn=n(Ji,"P",{});var Gx=s(Yn);Tpt=r(Gx,"The model class to instantiate is selected based on the "),Oke=n(Gx,"CODE",{});var qFa=s(Oke);Mpt=r(qFa,"model_type"),qFa.forEach(t),Ept=r(Gx,` property of the config object (either
passed as an argument or loaded from `),Vke=n(Gx,"CODE",{});var jFa=s(Vke);Cpt=r(jFa,"pretrained_model_name_or_path"),jFa.forEach(t),wpt=r(Gx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Xke=n(Gx,"CODE",{});var DFa=s(Xke);Apt=r(DFa,"pretrained_model_name_or_path"),DFa.forEach(t),Lpt=r(Gx,":"),Gx.forEach(t),ypt=i(Ji),te=n(Ji,"UL",{});var ne=s(te);W7=n(ne,"LI",{});var Xoo=s(W7);zke=n(Xoo,"STRONG",{});var GFa=s(zke);xpt=r(GFa,"albert"),GFa.forEach(t),$pt=r(Xoo," \u2014 "),Ple=n(Xoo,"A",{href:!0});var OFa=s(Ple);kpt=r(OFa,"FlaxAlbertModel"),OFa.forEach(t),Spt=r(Xoo," (ALBERT model)"),Xoo.forEach(t),Rpt=i(ne),U7=n(ne,"LI",{});var zoo=s(U7);Qke=n(zoo,"STRONG",{});var VFa=s(Qke);Ppt=r(VFa,"bart"),VFa.forEach(t),Bpt=r(zoo," \u2014 "),Ble=n(zoo,"A",{href:!0});var XFa=s(Ble);Ipt=r(XFa,"FlaxBartModel"),XFa.forEach(t),Npt=r(zoo," (BART model)"),zoo.forEach(t),qpt=i(ne),H7=n(ne,"LI",{});var Qoo=s(H7);Wke=n(Qoo,"STRONG",{});var zFa=s(Wke);jpt=r(zFa,"beit"),zFa.forEach(t),Dpt=r(Qoo," \u2014 "),Ile=n(Qoo,"A",{href:!0});var QFa=s(Ile);Gpt=r(QFa,"FlaxBeitModel"),QFa.forEach(t),Opt=r(Qoo," (BEiT model)"),Qoo.forEach(t),Vpt=i(ne),J7=n(ne,"LI",{});var Woo=s(J7);Uke=n(Woo,"STRONG",{});var WFa=s(Uke);Xpt=r(WFa,"bert"),WFa.forEach(t),zpt=r(Woo," \u2014 "),Nle=n(Woo,"A",{href:!0});var UFa=s(Nle);Qpt=r(UFa,"FlaxBertModel"),UFa.forEach(t),Wpt=r(Woo," (BERT model)"),Woo.forEach(t),Upt=i(ne),Y7=n(ne,"LI",{});var Uoo=s(Y7);Hke=n(Uoo,"STRONG",{});var HFa=s(Hke);Hpt=r(HFa,"big_bird"),HFa.forEach(t),Jpt=r(Uoo," \u2014 "),qle=n(Uoo,"A",{href:!0});var JFa=s(qle);Ypt=r(JFa,"FlaxBigBirdModel"),JFa.forEach(t),Zpt=r(Uoo," (BigBird model)"),Uoo.forEach(t),Kpt=i(ne),Z7=n(ne,"LI",{});var Hoo=s(Z7);Jke=n(Hoo,"STRONG",{});var YFa=s(Jke);e_t=r(YFa,"blenderbot"),YFa.forEach(t),o_t=r(Hoo," \u2014 "),jle=n(Hoo,"A",{href:!0});var ZFa=s(jle);r_t=r(ZFa,"FlaxBlenderbotModel"),ZFa.forEach(t),t_t=r(Hoo," (Blenderbot model)"),Hoo.forEach(t),a_t=i(ne),K7=n(ne,"LI",{});var Joo=s(K7);Yke=n(Joo,"STRONG",{});var KFa=s(Yke);n_t=r(KFa,"blenderbot-small"),KFa.forEach(t),s_t=r(Joo," \u2014 "),Dle=n(Joo,"A",{href:!0});var eTa=s(Dle);l_t=r(eTa,"FlaxBlenderbotSmallModel"),eTa.forEach(t),i_t=r(Joo," (BlenderbotSmall model)"),Joo.forEach(t),d_t=i(ne),e8=n(ne,"LI",{});var Yoo=s(e8);Zke=n(Yoo,"STRONG",{});var oTa=s(Zke);m_t=r(oTa,"clip"),oTa.forEach(t),c_t=r(Yoo," \u2014 "),Gle=n(Yoo,"A",{href:!0});var rTa=s(Gle);f_t=r(rTa,"FlaxCLIPModel"),rTa.forEach(t),g_t=r(Yoo," (CLIP model)"),Yoo.forEach(t),h_t=i(ne),o8=n(ne,"LI",{});var Zoo=s(o8);Kke=n(Zoo,"STRONG",{});var tTa=s(Kke);u_t=r(tTa,"distilbert"),tTa.forEach(t),p_t=r(Zoo," \u2014 "),Ole=n(Zoo,"A",{href:!0});var aTa=s(Ole);__t=r(aTa,"FlaxDistilBertModel"),aTa.forEach(t),b_t=r(Zoo," (DistilBERT model)"),Zoo.forEach(t),v_t=i(ne),r8=n(ne,"LI",{});var Koo=s(r8);eSe=n(Koo,"STRONG",{});var nTa=s(eSe);F_t=r(nTa,"electra"),nTa.forEach(t),T_t=r(Koo," \u2014 "),Vle=n(Koo,"A",{href:!0});var sTa=s(Vle);M_t=r(sTa,"FlaxElectraModel"),sTa.forEach(t),E_t=r(Koo," (ELECTRA model)"),Koo.forEach(t),C_t=i(ne),t8=n(ne,"LI",{});var ero=s(t8);oSe=n(ero,"STRONG",{});var lTa=s(oSe);w_t=r(lTa,"gpt2"),lTa.forEach(t),A_t=r(ero," \u2014 "),Xle=n(ero,"A",{href:!0});var iTa=s(Xle);L_t=r(iTa,"FlaxGPT2Model"),iTa.forEach(t),y_t=r(ero," (OpenAI GPT-2 model)"),ero.forEach(t),x_t=i(ne),a8=n(ne,"LI",{});var oro=s(a8);rSe=n(oro,"STRONG",{});var dTa=s(rSe);$_t=r(dTa,"gpt_neo"),dTa.forEach(t),k_t=r(oro," \u2014 "),zle=n(oro,"A",{href:!0});var mTa=s(zle);S_t=r(mTa,"FlaxGPTNeoModel"),mTa.forEach(t),R_t=r(oro," (GPT Neo model)"),oro.forEach(t),P_t=i(ne),n8=n(ne,"LI",{});var rro=s(n8);tSe=n(rro,"STRONG",{});var cTa=s(tSe);B_t=r(cTa,"gptj"),cTa.forEach(t),I_t=r(rro," \u2014 "),Qle=n(rro,"A",{href:!0});var fTa=s(Qle);N_t=r(fTa,"FlaxGPTJModel"),fTa.forEach(t),q_t=r(rro," (GPT-J model)"),rro.forEach(t),j_t=i(ne),s8=n(ne,"LI",{});var tro=s(s8);aSe=n(tro,"STRONG",{});var gTa=s(aSe);D_t=r(gTa,"longt5"),gTa.forEach(t),G_t=r(tro," \u2014 "),Wle=n(tro,"A",{href:!0});var hTa=s(Wle);O_t=r(hTa,"FlaxLongT5Model"),hTa.forEach(t),V_t=r(tro," (LongT5 model)"),tro.forEach(t),X_t=i(ne),l8=n(ne,"LI",{});var aro=s(l8);nSe=n(aro,"STRONG",{});var uTa=s(nSe);z_t=r(uTa,"marian"),uTa.forEach(t),Q_t=r(aro," \u2014 "),Ule=n(aro,"A",{href:!0});var pTa=s(Ule);W_t=r(pTa,"FlaxMarianModel"),pTa.forEach(t),U_t=r(aro," (Marian model)"),aro.forEach(t),H_t=i(ne),i8=n(ne,"LI",{});var nro=s(i8);sSe=n(nro,"STRONG",{});var _Ta=s(sSe);J_t=r(_Ta,"mbart"),_Ta.forEach(t),Y_t=r(nro," \u2014 "),Hle=n(nro,"A",{href:!0});var bTa=s(Hle);Z_t=r(bTa,"FlaxMBartModel"),bTa.forEach(t),K_t=r(nro," (mBART model)"),nro.forEach(t),e1t=i(ne),d8=n(ne,"LI",{});var sro=s(d8);lSe=n(sro,"STRONG",{});var vTa=s(lSe);o1t=r(vTa,"mt5"),vTa.forEach(t),r1t=r(sro," \u2014 "),Jle=n(sro,"A",{href:!0});var FTa=s(Jle);t1t=r(FTa,"FlaxMT5Model"),FTa.forEach(t),a1t=r(sro," (MT5 model)"),sro.forEach(t),n1t=i(ne),m8=n(ne,"LI",{});var lro=s(m8);iSe=n(lro,"STRONG",{});var TTa=s(iSe);s1t=r(TTa,"opt"),TTa.forEach(t),l1t=r(lro," \u2014 "),Yle=n(lro,"A",{href:!0});var MTa=s(Yle);i1t=r(MTa,"FlaxOPTModel"),MTa.forEach(t),d1t=r(lro," (OPT model)"),lro.forEach(t),m1t=i(ne),c8=n(ne,"LI",{});var iro=s(c8);dSe=n(iro,"STRONG",{});var ETa=s(dSe);c1t=r(ETa,"pegasus"),ETa.forEach(t),f1t=r(iro," \u2014 "),Zle=n(iro,"A",{href:!0});var CTa=s(Zle);g1t=r(CTa,"FlaxPegasusModel"),CTa.forEach(t),h1t=r(iro," (Pegasus model)"),iro.forEach(t),u1t=i(ne),f8=n(ne,"LI",{});var dro=s(f8);mSe=n(dro,"STRONG",{});var wTa=s(mSe);p1t=r(wTa,"roberta"),wTa.forEach(t),_1t=r(dro," \u2014 "),Kle=n(dro,"A",{href:!0});var ATa=s(Kle);b1t=r(ATa,"FlaxRobertaModel"),ATa.forEach(t),v1t=r(dro," (RoBERTa model)"),dro.forEach(t),F1t=i(ne),g8=n(ne,"LI",{});var mro=s(g8);cSe=n(mro,"STRONG",{});var LTa=s(cSe);T1t=r(LTa,"roformer"),LTa.forEach(t),M1t=r(mro," \u2014 "),eie=n(mro,"A",{href:!0});var yTa=s(eie);E1t=r(yTa,"FlaxRoFormerModel"),yTa.forEach(t),C1t=r(mro," (RoFormer model)"),mro.forEach(t),w1t=i(ne),h8=n(ne,"LI",{});var cro=s(h8);fSe=n(cro,"STRONG",{});var xTa=s(fSe);A1t=r(xTa,"t5"),xTa.forEach(t),L1t=r(cro," \u2014 "),oie=n(cro,"A",{href:!0});var $Ta=s(oie);y1t=r($Ta,"FlaxT5Model"),$Ta.forEach(t),x1t=r(cro," (T5 model)"),cro.forEach(t),$1t=i(ne),u8=n(ne,"LI",{});var fro=s(u8);gSe=n(fro,"STRONG",{});var kTa=s(gSe);k1t=r(kTa,"vision-text-dual-encoder"),kTa.forEach(t),S1t=r(fro," \u2014 "),rie=n(fro,"A",{href:!0});var STa=s(rie);R1t=r(STa,"FlaxVisionTextDualEncoderModel"),STa.forEach(t),P1t=r(fro," (VisionTextDualEncoder model)"),fro.forEach(t),B1t=i(ne),p8=n(ne,"LI",{});var gro=s(p8);hSe=n(gro,"STRONG",{});var RTa=s(hSe);I1t=r(RTa,"vit"),RTa.forEach(t),N1t=r(gro," \u2014 "),tie=n(gro,"A",{href:!0});var PTa=s(tie);q1t=r(PTa,"FlaxViTModel"),PTa.forEach(t),j1t=r(gro," (ViT model)"),gro.forEach(t),D1t=i(ne),_8=n(ne,"LI",{});var hro=s(_8);uSe=n(hro,"STRONG",{});var BTa=s(uSe);G1t=r(BTa,"wav2vec2"),BTa.forEach(t),O1t=r(hro," \u2014 "),aie=n(hro,"A",{href:!0});var ITa=s(aie);V1t=r(ITa,"FlaxWav2Vec2Model"),ITa.forEach(t),X1t=r(hro," (Wav2Vec2 model)"),hro.forEach(t),z1t=i(ne),b8=n(ne,"LI",{});var uro=s(b8);pSe=n(uro,"STRONG",{});var NTa=s(pSe);Q1t=r(NTa,"xglm"),NTa.forEach(t),W1t=r(uro," \u2014 "),nie=n(uro,"A",{href:!0});var qTa=s(nie);U1t=r(qTa,"FlaxXGLMModel"),qTa.forEach(t),H1t=r(uro," (XGLM model)"),uro.forEach(t),J1t=i(ne),v8=n(ne,"LI",{});var pro=s(v8);_Se=n(pro,"STRONG",{});var jTa=s(_Se);Y1t=r(jTa,"xlm-roberta"),jTa.forEach(t),Z1t=r(pro," \u2014 "),sie=n(pro,"A",{href:!0});var DTa=s(sie);K1t=r(DTa,"FlaxXLMRobertaModel"),DTa.forEach(t),e2t=r(pro," (XLM-RoBERTa model)"),pro.forEach(t),ne.forEach(t),o2t=i(Ji),T(F8.$$.fragment,Ji),Ji.forEach(t),Hi.forEach(t),Gno=i(c),mf=n(c,"H2",{class:!0});var iio=s(mf);T8=n(iio,"A",{id:!0,class:!0,href:!0});var GTa=s(T8);bSe=n(GTa,"SPAN",{});var OTa=s(bSe);T(ZP.$$.fragment,OTa),OTa.forEach(t),GTa.forEach(t),r2t=i(iio),vSe=n(iio,"SPAN",{});var VTa=s(vSe);t2t=r(VTa,"FlaxAutoModelForCausalLM"),VTa.forEach(t),iio.forEach(t),Ono=i(c),Lr=n(c,"DIV",{class:!0});var Yi=s(Lr);T(KP.$$.fragment,Yi),a2t=i(Yi),cf=n(Yi,"P",{});var ofe=s(cf);n2t=r(ofe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),lie=n(ofe,"A",{href:!0});var XTa=s(lie);s2t=r(XTa,"from_pretrained()"),XTa.forEach(t),l2t=r(ofe," class method or the "),iie=n(ofe,"A",{href:!0});var zTa=s(iie);i2t=r(zTa,"from_config()"),zTa.forEach(t),d2t=r(ofe,` class
method.`),ofe.forEach(t),m2t=i(Yi),eB=n(Yi,"P",{});var dio=s(eB);c2t=r(dio,"This class cannot be instantiated directly using "),FSe=n(dio,"CODE",{});var QTa=s(FSe);f2t=r(QTa,"__init__()"),QTa.forEach(t),g2t=r(dio," (throws an error)."),dio.forEach(t),h2t=i(Yi),ha=n(Yi,"DIV",{class:!0});var Ox=s(ha);T(oB.$$.fragment,Ox),u2t=i(Ox),TSe=n(Ox,"P",{});var WTa=s(TSe);p2t=r(WTa,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),WTa.forEach(t),_2t=i(Ox),ff=n(Ox,"P",{});var rfe=s(ff);b2t=r(rfe,`Note:
Loading a model from its configuration file does `),MSe=n(rfe,"STRONG",{});var UTa=s(MSe);v2t=r(UTa,"not"),UTa.forEach(t),F2t=r(rfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),die=n(rfe,"A",{href:!0});var HTa=s(die);T2t=r(HTa,"from_pretrained()"),HTa.forEach(t),M2t=r(rfe," to load the model weights."),rfe.forEach(t),E2t=i(Ox),T(M8.$$.fragment,Ox),Ox.forEach(t),C2t=i(Yi),tt=n(Yi,"DIV",{class:!0});var Zi=s(tt);T(rB.$$.fragment,Zi),w2t=i(Zi),ESe=n(Zi,"P",{});var JTa=s(ESe);A2t=r(JTa,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),JTa.forEach(t),L2t=i(Zi),Zn=n(Zi,"P",{});var Vx=s(Zn);y2t=r(Vx,"The model class to instantiate is selected based on the "),CSe=n(Vx,"CODE",{});var YTa=s(CSe);x2t=r(YTa,"model_type"),YTa.forEach(t),$2t=r(Vx,` property of the config object (either
passed as an argument or loaded from `),wSe=n(Vx,"CODE",{});var ZTa=s(wSe);k2t=r(ZTa,"pretrained_model_name_or_path"),ZTa.forEach(t),S2t=r(Vx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ASe=n(Vx,"CODE",{});var KTa=s(ASe);R2t=r(KTa,"pretrained_model_name_or_path"),KTa.forEach(t),P2t=r(Vx,":"),Vx.forEach(t),B2t=i(Zi),$e=n(Zi,"UL",{});var je=s($e);E8=n(je,"LI",{});var _ro=s(E8);LSe=n(_ro,"STRONG",{});var eMa=s(LSe);I2t=r(eMa,"bart"),eMa.forEach(t),N2t=r(_ro," \u2014 "),mie=n(_ro,"A",{href:!0});var oMa=s(mie);q2t=r(oMa,"FlaxBartForCausalLM"),oMa.forEach(t),j2t=r(_ro," (BART model)"),_ro.forEach(t),D2t=i(je),C8=n(je,"LI",{});var bro=s(C8);ySe=n(bro,"STRONG",{});var rMa=s(ySe);G2t=r(rMa,"bert"),rMa.forEach(t),O2t=r(bro," \u2014 "),cie=n(bro,"A",{href:!0});var tMa=s(cie);V2t=r(tMa,"FlaxBertForCausalLM"),tMa.forEach(t),X2t=r(bro," (BERT model)"),bro.forEach(t),z2t=i(je),w8=n(je,"LI",{});var vro=s(w8);xSe=n(vro,"STRONG",{});var aMa=s(xSe);Q2t=r(aMa,"big_bird"),aMa.forEach(t),W2t=r(vro," \u2014 "),fie=n(vro,"A",{href:!0});var nMa=s(fie);U2t=r(nMa,"FlaxBigBirdForCausalLM"),nMa.forEach(t),H2t=r(vro," (BigBird model)"),vro.forEach(t),J2t=i(je),A8=n(je,"LI",{});var Fro=s(A8);$Se=n(Fro,"STRONG",{});var sMa=s($Se);Y2t=r(sMa,"electra"),sMa.forEach(t),Z2t=r(Fro," \u2014 "),gie=n(Fro,"A",{href:!0});var lMa=s(gie);K2t=r(lMa,"FlaxElectraForCausalLM"),lMa.forEach(t),ebt=r(Fro," (ELECTRA model)"),Fro.forEach(t),obt=i(je),L8=n(je,"LI",{});var Tro=s(L8);kSe=n(Tro,"STRONG",{});var iMa=s(kSe);rbt=r(iMa,"gpt2"),iMa.forEach(t),tbt=r(Tro," \u2014 "),hie=n(Tro,"A",{href:!0});var dMa=s(hie);abt=r(dMa,"FlaxGPT2LMHeadModel"),dMa.forEach(t),nbt=r(Tro," (OpenAI GPT-2 model)"),Tro.forEach(t),sbt=i(je),y8=n(je,"LI",{});var Mro=s(y8);SSe=n(Mro,"STRONG",{});var mMa=s(SSe);lbt=r(mMa,"gpt_neo"),mMa.forEach(t),ibt=r(Mro," \u2014 "),uie=n(Mro,"A",{href:!0});var cMa=s(uie);dbt=r(cMa,"FlaxGPTNeoForCausalLM"),cMa.forEach(t),mbt=r(Mro," (GPT Neo model)"),Mro.forEach(t),cbt=i(je),x8=n(je,"LI",{});var Ero=s(x8);RSe=n(Ero,"STRONG",{});var fMa=s(RSe);fbt=r(fMa,"gptj"),fMa.forEach(t),gbt=r(Ero," \u2014 "),pie=n(Ero,"A",{href:!0});var gMa=s(pie);hbt=r(gMa,"FlaxGPTJForCausalLM"),gMa.forEach(t),ubt=r(Ero," (GPT-J model)"),Ero.forEach(t),pbt=i(je),$8=n(je,"LI",{});var Cro=s($8);PSe=n(Cro,"STRONG",{});var hMa=s(PSe);_bt=r(hMa,"opt"),hMa.forEach(t),bbt=r(Cro," \u2014 "),_ie=n(Cro,"A",{href:!0});var uMa=s(_ie);vbt=r(uMa,"FlaxOPTForCausalLM"),uMa.forEach(t),Fbt=r(Cro," (OPT model)"),Cro.forEach(t),Tbt=i(je),k8=n(je,"LI",{});var wro=s(k8);BSe=n(wro,"STRONG",{});var pMa=s(BSe);Mbt=r(pMa,"roberta"),pMa.forEach(t),Ebt=r(wro," \u2014 "),bie=n(wro,"A",{href:!0});var _Ma=s(bie);Cbt=r(_Ma,"FlaxRobertaForCausalLM"),_Ma.forEach(t),wbt=r(wro," (RoBERTa model)"),wro.forEach(t),Abt=i(je),S8=n(je,"LI",{});var Aro=s(S8);ISe=n(Aro,"STRONG",{});var bMa=s(ISe);Lbt=r(bMa,"xglm"),bMa.forEach(t),ybt=r(Aro," \u2014 "),vie=n(Aro,"A",{href:!0});var vMa=s(vie);xbt=r(vMa,"FlaxXGLMForCausalLM"),vMa.forEach(t),$bt=r(Aro," (XGLM model)"),Aro.forEach(t),je.forEach(t),kbt=i(Zi),T(R8.$$.fragment,Zi),Zi.forEach(t),Yi.forEach(t),Vno=i(c),gf=n(c,"H2",{class:!0});var mio=s(gf);P8=n(mio,"A",{id:!0,class:!0,href:!0});var FMa=s(P8);NSe=n(FMa,"SPAN",{});var TMa=s(NSe);T(tB.$$.fragment,TMa),TMa.forEach(t),FMa.forEach(t),Sbt=i(mio),qSe=n(mio,"SPAN",{});var MMa=s(qSe);Rbt=r(MMa,"FlaxAutoModelForPreTraining"),MMa.forEach(t),mio.forEach(t),Xno=i(c),yr=n(c,"DIV",{class:!0});var Ki=s(yr);T(aB.$$.fragment,Ki),Pbt=i(Ki),hf=n(Ki,"P",{});var tfe=s(hf);Bbt=r(tfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Fie=n(tfe,"A",{href:!0});var EMa=s(Fie);Ibt=r(EMa,"from_pretrained()"),EMa.forEach(t),Nbt=r(tfe," class method or the "),Tie=n(tfe,"A",{href:!0});var CMa=s(Tie);qbt=r(CMa,"from_config()"),CMa.forEach(t),jbt=r(tfe,` class
method.`),tfe.forEach(t),Dbt=i(Ki),nB=n(Ki,"P",{});var cio=s(nB);Gbt=r(cio,"This class cannot be instantiated directly using "),jSe=n(cio,"CODE",{});var wMa=s(jSe);Obt=r(wMa,"__init__()"),wMa.forEach(t),Vbt=r(cio," (throws an error)."),cio.forEach(t),Xbt=i(Ki),ua=n(Ki,"DIV",{class:!0});var Xx=s(ua);T(sB.$$.fragment,Xx),zbt=i(Xx),DSe=n(Xx,"P",{});var AMa=s(DSe);Qbt=r(AMa,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),AMa.forEach(t),Wbt=i(Xx),uf=n(Xx,"P",{});var afe=s(uf);Ubt=r(afe,`Note:
Loading a model from its configuration file does `),GSe=n(afe,"STRONG",{});var LMa=s(GSe);Hbt=r(LMa,"not"),LMa.forEach(t),Jbt=r(afe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Mie=n(afe,"A",{href:!0});var yMa=s(Mie);Ybt=r(yMa,"from_pretrained()"),yMa.forEach(t),Zbt=r(afe," to load the model weights."),afe.forEach(t),Kbt=i(Xx),T(B8.$$.fragment,Xx),Xx.forEach(t),evt=i(Ki),at=n(Ki,"DIV",{class:!0});var ed=s(at);T(lB.$$.fragment,ed),ovt=i(ed),OSe=n(ed,"P",{});var xMa=s(OSe);rvt=r(xMa,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),xMa.forEach(t),tvt=i(ed),Kn=n(ed,"P",{});var zx=s(Kn);avt=r(zx,"The model class to instantiate is selected based on the "),VSe=n(zx,"CODE",{});var $Ma=s(VSe);nvt=r($Ma,"model_type"),$Ma.forEach(t),svt=r(zx,` property of the config object (either
passed as an argument or loaded from `),XSe=n(zx,"CODE",{});var kMa=s(XSe);lvt=r(kMa,"pretrained_model_name_or_path"),kMa.forEach(t),ivt=r(zx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zSe=n(zx,"CODE",{});var SMa=s(zSe);dvt=r(SMa,"pretrained_model_name_or_path"),SMa.forEach(t),mvt=r(zx,":"),zx.forEach(t),cvt=i(ed),Ee=n(ed,"UL",{});var we=s(Ee);I8=n(we,"LI",{});var Lro=s(I8);QSe=n(Lro,"STRONG",{});var RMa=s(QSe);fvt=r(RMa,"albert"),RMa.forEach(t),gvt=r(Lro," \u2014 "),Eie=n(Lro,"A",{href:!0});var PMa=s(Eie);hvt=r(PMa,"FlaxAlbertForPreTraining"),PMa.forEach(t),uvt=r(Lro," (ALBERT model)"),Lro.forEach(t),pvt=i(we),N8=n(we,"LI",{});var yro=s(N8);WSe=n(yro,"STRONG",{});var BMa=s(WSe);_vt=r(BMa,"bart"),BMa.forEach(t),bvt=r(yro," \u2014 "),Cie=n(yro,"A",{href:!0});var IMa=s(Cie);vvt=r(IMa,"FlaxBartForConditionalGeneration"),IMa.forEach(t),Fvt=r(yro," (BART model)"),yro.forEach(t),Tvt=i(we),q8=n(we,"LI",{});var xro=s(q8);USe=n(xro,"STRONG",{});var NMa=s(USe);Mvt=r(NMa,"bert"),NMa.forEach(t),Evt=r(xro," \u2014 "),wie=n(xro,"A",{href:!0});var qMa=s(wie);Cvt=r(qMa,"FlaxBertForPreTraining"),qMa.forEach(t),wvt=r(xro," (BERT model)"),xro.forEach(t),Avt=i(we),j8=n(we,"LI",{});var $ro=s(j8);HSe=n($ro,"STRONG",{});var jMa=s(HSe);Lvt=r(jMa,"big_bird"),jMa.forEach(t),yvt=r($ro," \u2014 "),Aie=n($ro,"A",{href:!0});var DMa=s(Aie);xvt=r(DMa,"FlaxBigBirdForPreTraining"),DMa.forEach(t),$vt=r($ro," (BigBird model)"),$ro.forEach(t),kvt=i(we),D8=n(we,"LI",{});var kro=s(D8);JSe=n(kro,"STRONG",{});var GMa=s(JSe);Svt=r(GMa,"electra"),GMa.forEach(t),Rvt=r(kro," \u2014 "),Lie=n(kro,"A",{href:!0});var OMa=s(Lie);Pvt=r(OMa,"FlaxElectraForPreTraining"),OMa.forEach(t),Bvt=r(kro," (ELECTRA model)"),kro.forEach(t),Ivt=i(we),G8=n(we,"LI",{});var Sro=s(G8);YSe=n(Sro,"STRONG",{});var VMa=s(YSe);Nvt=r(VMa,"longt5"),VMa.forEach(t),qvt=r(Sro," \u2014 "),yie=n(Sro,"A",{href:!0});var XMa=s(yie);jvt=r(XMa,"FlaxLongT5ForConditionalGeneration"),XMa.forEach(t),Dvt=r(Sro," (LongT5 model)"),Sro.forEach(t),Gvt=i(we),O8=n(we,"LI",{});var Rro=s(O8);ZSe=n(Rro,"STRONG",{});var zMa=s(ZSe);Ovt=r(zMa,"mbart"),zMa.forEach(t),Vvt=r(Rro," \u2014 "),xie=n(Rro,"A",{href:!0});var QMa=s(xie);Xvt=r(QMa,"FlaxMBartForConditionalGeneration"),QMa.forEach(t),zvt=r(Rro," (mBART model)"),Rro.forEach(t),Qvt=i(we),V8=n(we,"LI",{});var Pro=s(V8);KSe=n(Pro,"STRONG",{});var WMa=s(KSe);Wvt=r(WMa,"mt5"),WMa.forEach(t),Uvt=r(Pro," \u2014 "),$ie=n(Pro,"A",{href:!0});var UMa=s($ie);Hvt=r(UMa,"FlaxMT5ForConditionalGeneration"),UMa.forEach(t),Jvt=r(Pro," (MT5 model)"),Pro.forEach(t),Yvt=i(we),X8=n(we,"LI",{});var Bro=s(X8);eRe=n(Bro,"STRONG",{});var HMa=s(eRe);Zvt=r(HMa,"roberta"),HMa.forEach(t),Kvt=r(Bro," \u2014 "),kie=n(Bro,"A",{href:!0});var JMa=s(kie);eFt=r(JMa,"FlaxRobertaForMaskedLM"),JMa.forEach(t),oFt=r(Bro," (RoBERTa model)"),Bro.forEach(t),rFt=i(we),z8=n(we,"LI",{});var Iro=s(z8);oRe=n(Iro,"STRONG",{});var YMa=s(oRe);tFt=r(YMa,"roformer"),YMa.forEach(t),aFt=r(Iro," \u2014 "),Sie=n(Iro,"A",{href:!0});var ZMa=s(Sie);nFt=r(ZMa,"FlaxRoFormerForMaskedLM"),ZMa.forEach(t),sFt=r(Iro," (RoFormer model)"),Iro.forEach(t),lFt=i(we),Q8=n(we,"LI",{});var Nro=s(Q8);rRe=n(Nro,"STRONG",{});var KMa=s(rRe);iFt=r(KMa,"t5"),KMa.forEach(t),dFt=r(Nro," \u2014 "),Rie=n(Nro,"A",{href:!0});var eEa=s(Rie);mFt=r(eEa,"FlaxT5ForConditionalGeneration"),eEa.forEach(t),cFt=r(Nro," (T5 model)"),Nro.forEach(t),fFt=i(we),W8=n(we,"LI",{});var qro=s(W8);tRe=n(qro,"STRONG",{});var oEa=s(tRe);gFt=r(oEa,"wav2vec2"),oEa.forEach(t),hFt=r(qro," \u2014 "),Pie=n(qro,"A",{href:!0});var rEa=s(Pie);uFt=r(rEa,"FlaxWav2Vec2ForPreTraining"),rEa.forEach(t),pFt=r(qro," (Wav2Vec2 model)"),qro.forEach(t),_Ft=i(we),U8=n(we,"LI",{});var jro=s(U8);aRe=n(jro,"STRONG",{});var tEa=s(aRe);bFt=r(tEa,"xlm-roberta"),tEa.forEach(t),vFt=r(jro," \u2014 "),Bie=n(jro,"A",{href:!0});var aEa=s(Bie);FFt=r(aEa,"FlaxXLMRobertaForMaskedLM"),aEa.forEach(t),TFt=r(jro," (XLM-RoBERTa model)"),jro.forEach(t),we.forEach(t),MFt=i(ed),T(H8.$$.fragment,ed),ed.forEach(t),Ki.forEach(t),zno=i(c),pf=n(c,"H2",{class:!0});var fio=s(pf);J8=n(fio,"A",{id:!0,class:!0,href:!0});var nEa=s(J8);nRe=n(nEa,"SPAN",{});var sEa=s(nRe);T(iB.$$.fragment,sEa),sEa.forEach(t),nEa.forEach(t),EFt=i(fio),sRe=n(fio,"SPAN",{});var lEa=s(sRe);CFt=r(lEa,"FlaxAutoModelForMaskedLM"),lEa.forEach(t),fio.forEach(t),Qno=i(c),xr=n(c,"DIV",{class:!0});var od=s(xr);T(dB.$$.fragment,od),wFt=i(od),_f=n(od,"P",{});var nfe=s(_f);AFt=r(nfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Iie=n(nfe,"A",{href:!0});var iEa=s(Iie);LFt=r(iEa,"from_pretrained()"),iEa.forEach(t),yFt=r(nfe," class method or the "),Nie=n(nfe,"A",{href:!0});var dEa=s(Nie);xFt=r(dEa,"from_config()"),dEa.forEach(t),$Ft=r(nfe,` class
method.`),nfe.forEach(t),kFt=i(od),mB=n(od,"P",{});var gio=s(mB);SFt=r(gio,"This class cannot be instantiated directly using "),lRe=n(gio,"CODE",{});var mEa=s(lRe);RFt=r(mEa,"__init__()"),mEa.forEach(t),PFt=r(gio," (throws an error)."),gio.forEach(t),BFt=i(od),pa=n(od,"DIV",{class:!0});var Qx=s(pa);T(cB.$$.fragment,Qx),IFt=i(Qx),iRe=n(Qx,"P",{});var cEa=s(iRe);NFt=r(cEa,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),cEa.forEach(t),qFt=i(Qx),bf=n(Qx,"P",{});var sfe=s(bf);jFt=r(sfe,`Note:
Loading a model from its configuration file does `),dRe=n(sfe,"STRONG",{});var fEa=s(dRe);DFt=r(fEa,"not"),fEa.forEach(t),GFt=r(sfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),qie=n(sfe,"A",{href:!0});var gEa=s(qie);OFt=r(gEa,"from_pretrained()"),gEa.forEach(t),VFt=r(sfe," to load the model weights."),sfe.forEach(t),XFt=i(Qx),T(Y8.$$.fragment,Qx),Qx.forEach(t),zFt=i(od),nt=n(od,"DIV",{class:!0});var rd=s(nt);T(fB.$$.fragment,rd),QFt=i(rd),mRe=n(rd,"P",{});var hEa=s(mRe);WFt=r(hEa,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),hEa.forEach(t),UFt=i(rd),es=n(rd,"P",{});var Wx=s(es);HFt=r(Wx,"The model class to instantiate is selected based on the "),cRe=n(Wx,"CODE",{});var uEa=s(cRe);JFt=r(uEa,"model_type"),uEa.forEach(t),YFt=r(Wx,` property of the config object (either
passed as an argument or loaded from `),fRe=n(Wx,"CODE",{});var pEa=s(fRe);ZFt=r(pEa,"pretrained_model_name_or_path"),pEa.forEach(t),KFt=r(Wx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gRe=n(Wx,"CODE",{});var _Ea=s(gRe);eTt=r(_Ea,"pretrained_model_name_or_path"),_Ea.forEach(t),oTt=r(Wx,":"),Wx.forEach(t),rTt=i(rd),ke=n(rd,"UL",{});var De=s(ke);Z8=n(De,"LI",{});var Dro=s(Z8);hRe=n(Dro,"STRONG",{});var bEa=s(hRe);tTt=r(bEa,"albert"),bEa.forEach(t),aTt=r(Dro," \u2014 "),jie=n(Dro,"A",{href:!0});var vEa=s(jie);nTt=r(vEa,"FlaxAlbertForMaskedLM"),vEa.forEach(t),sTt=r(Dro," (ALBERT model)"),Dro.forEach(t),lTt=i(De),K8=n(De,"LI",{});var Gro=s(K8);uRe=n(Gro,"STRONG",{});var FEa=s(uRe);iTt=r(FEa,"bart"),FEa.forEach(t),dTt=r(Gro," \u2014 "),Die=n(Gro,"A",{href:!0});var TEa=s(Die);mTt=r(TEa,"FlaxBartForConditionalGeneration"),TEa.forEach(t),cTt=r(Gro," (BART model)"),Gro.forEach(t),fTt=i(De),eL=n(De,"LI",{});var Oro=s(eL);pRe=n(Oro,"STRONG",{});var MEa=s(pRe);gTt=r(MEa,"bert"),MEa.forEach(t),hTt=r(Oro," \u2014 "),Gie=n(Oro,"A",{href:!0});var EEa=s(Gie);uTt=r(EEa,"FlaxBertForMaskedLM"),EEa.forEach(t),pTt=r(Oro," (BERT model)"),Oro.forEach(t),_Tt=i(De),oL=n(De,"LI",{});var Vro=s(oL);_Re=n(Vro,"STRONG",{});var CEa=s(_Re);bTt=r(CEa,"big_bird"),CEa.forEach(t),vTt=r(Vro," \u2014 "),Oie=n(Vro,"A",{href:!0});var wEa=s(Oie);FTt=r(wEa,"FlaxBigBirdForMaskedLM"),wEa.forEach(t),TTt=r(Vro," (BigBird model)"),Vro.forEach(t),MTt=i(De),rL=n(De,"LI",{});var Xro=s(rL);bRe=n(Xro,"STRONG",{});var AEa=s(bRe);ETt=r(AEa,"distilbert"),AEa.forEach(t),CTt=r(Xro," \u2014 "),Vie=n(Xro,"A",{href:!0});var LEa=s(Vie);wTt=r(LEa,"FlaxDistilBertForMaskedLM"),LEa.forEach(t),ATt=r(Xro," (DistilBERT model)"),Xro.forEach(t),LTt=i(De),tL=n(De,"LI",{});var zro=s(tL);vRe=n(zro,"STRONG",{});var yEa=s(vRe);yTt=r(yEa,"electra"),yEa.forEach(t),xTt=r(zro," \u2014 "),Xie=n(zro,"A",{href:!0});var xEa=s(Xie);$Tt=r(xEa,"FlaxElectraForMaskedLM"),xEa.forEach(t),kTt=r(zro," (ELECTRA model)"),zro.forEach(t),STt=i(De),aL=n(De,"LI",{});var Qro=s(aL);FRe=n(Qro,"STRONG",{});var $Ea=s(FRe);RTt=r($Ea,"mbart"),$Ea.forEach(t),PTt=r(Qro," \u2014 "),zie=n(Qro,"A",{href:!0});var kEa=s(zie);BTt=r(kEa,"FlaxMBartForConditionalGeneration"),kEa.forEach(t),ITt=r(Qro," (mBART model)"),Qro.forEach(t),NTt=i(De),nL=n(De,"LI",{});var Wro=s(nL);TRe=n(Wro,"STRONG",{});var SEa=s(TRe);qTt=r(SEa,"roberta"),SEa.forEach(t),jTt=r(Wro," \u2014 "),Qie=n(Wro,"A",{href:!0});var REa=s(Qie);DTt=r(REa,"FlaxRobertaForMaskedLM"),REa.forEach(t),GTt=r(Wro," (RoBERTa model)"),Wro.forEach(t),OTt=i(De),sL=n(De,"LI",{});var Uro=s(sL);MRe=n(Uro,"STRONG",{});var PEa=s(MRe);VTt=r(PEa,"roformer"),PEa.forEach(t),XTt=r(Uro," \u2014 "),Wie=n(Uro,"A",{href:!0});var BEa=s(Wie);zTt=r(BEa,"FlaxRoFormerForMaskedLM"),BEa.forEach(t),QTt=r(Uro," (RoFormer model)"),Uro.forEach(t),WTt=i(De),lL=n(De,"LI",{});var Hro=s(lL);ERe=n(Hro,"STRONG",{});var IEa=s(ERe);UTt=r(IEa,"xlm-roberta"),IEa.forEach(t),HTt=r(Hro," \u2014 "),Uie=n(Hro,"A",{href:!0});var NEa=s(Uie);JTt=r(NEa,"FlaxXLMRobertaForMaskedLM"),NEa.forEach(t),YTt=r(Hro," (XLM-RoBERTa model)"),Hro.forEach(t),De.forEach(t),ZTt=i(rd),T(iL.$$.fragment,rd),rd.forEach(t),od.forEach(t),Wno=i(c),vf=n(c,"H2",{class:!0});var hio=s(vf);dL=n(hio,"A",{id:!0,class:!0,href:!0});var qEa=s(dL);CRe=n(qEa,"SPAN",{});var jEa=s(CRe);T(gB.$$.fragment,jEa),jEa.forEach(t),qEa.forEach(t),KTt=i(hio),wRe=n(hio,"SPAN",{});var DEa=s(wRe);eMt=r(DEa,"FlaxAutoModelForSeq2SeqLM"),DEa.forEach(t),hio.forEach(t),Uno=i(c),$r=n(c,"DIV",{class:!0});var td=s($r);T(hB.$$.fragment,td),oMt=i(td),Ff=n(td,"P",{});var lfe=s(Ff);rMt=r(lfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Hie=n(lfe,"A",{href:!0});var GEa=s(Hie);tMt=r(GEa,"from_pretrained()"),GEa.forEach(t),aMt=r(lfe," class method or the "),Jie=n(lfe,"A",{href:!0});var OEa=s(Jie);nMt=r(OEa,"from_config()"),OEa.forEach(t),sMt=r(lfe,` class
method.`),lfe.forEach(t),lMt=i(td),uB=n(td,"P",{});var uio=s(uB);iMt=r(uio,"This class cannot be instantiated directly using "),ARe=n(uio,"CODE",{});var VEa=s(ARe);dMt=r(VEa,"__init__()"),VEa.forEach(t),mMt=r(uio," (throws an error)."),uio.forEach(t),cMt=i(td),_a=n(td,"DIV",{class:!0});var Ux=s(_a);T(pB.$$.fragment,Ux),fMt=i(Ux),LRe=n(Ux,"P",{});var XEa=s(LRe);gMt=r(XEa,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),XEa.forEach(t),hMt=i(Ux),Tf=n(Ux,"P",{});var ife=s(Tf);uMt=r(ife,`Note:
Loading a model from its configuration file does `),yRe=n(ife,"STRONG",{});var zEa=s(yRe);pMt=r(zEa,"not"),zEa.forEach(t),_Mt=r(ife,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yie=n(ife,"A",{href:!0});var QEa=s(Yie);bMt=r(QEa,"from_pretrained()"),QEa.forEach(t),vMt=r(ife," to load the model weights."),ife.forEach(t),FMt=i(Ux),T(mL.$$.fragment,Ux),Ux.forEach(t),TMt=i(td),st=n(td,"DIV",{class:!0});var ad=s(st);T(_B.$$.fragment,ad),MMt=i(ad),xRe=n(ad,"P",{});var WEa=s(xRe);EMt=r(WEa,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),WEa.forEach(t),CMt=i(ad),os=n(ad,"P",{});var Hx=s(os);wMt=r(Hx,"The model class to instantiate is selected based on the "),$Re=n(Hx,"CODE",{});var UEa=s($Re);AMt=r(UEa,"model_type"),UEa.forEach(t),LMt=r(Hx,` property of the config object (either
passed as an argument or loaded from `),kRe=n(Hx,"CODE",{});var HEa=s(kRe);yMt=r(HEa,"pretrained_model_name_or_path"),HEa.forEach(t),xMt=r(Hx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SRe=n(Hx,"CODE",{});var JEa=s(SRe);$Mt=r(JEa,"pretrained_model_name_or_path"),JEa.forEach(t),kMt=r(Hx,":"),Hx.forEach(t),SMt=i(ad),Se=n(ad,"UL",{});var Ge=s(Se);cL=n(Ge,"LI",{});var Jro=s(cL);RRe=n(Jro,"STRONG",{});var YEa=s(RRe);RMt=r(YEa,"bart"),YEa.forEach(t),PMt=r(Jro," \u2014 "),Zie=n(Jro,"A",{href:!0});var ZEa=s(Zie);BMt=r(ZEa,"FlaxBartForConditionalGeneration"),ZEa.forEach(t),IMt=r(Jro," (BART model)"),Jro.forEach(t),NMt=i(Ge),fL=n(Ge,"LI",{});var Yro=s(fL);PRe=n(Yro,"STRONG",{});var KEa=s(PRe);qMt=r(KEa,"blenderbot"),KEa.forEach(t),jMt=r(Yro," \u2014 "),Kie=n(Yro,"A",{href:!0});var e4a=s(Kie);DMt=r(e4a,"FlaxBlenderbotForConditionalGeneration"),e4a.forEach(t),GMt=r(Yro," (Blenderbot model)"),Yro.forEach(t),OMt=i(Ge),gL=n(Ge,"LI",{});var Zro=s(gL);BRe=n(Zro,"STRONG",{});var o4a=s(BRe);VMt=r(o4a,"blenderbot-small"),o4a.forEach(t),XMt=r(Zro," \u2014 "),ede=n(Zro,"A",{href:!0});var r4a=s(ede);zMt=r(r4a,"FlaxBlenderbotSmallForConditionalGeneration"),r4a.forEach(t),QMt=r(Zro," (BlenderbotSmall model)"),Zro.forEach(t),WMt=i(Ge),hL=n(Ge,"LI",{});var Kro=s(hL);IRe=n(Kro,"STRONG",{});var t4a=s(IRe);UMt=r(t4a,"encoder-decoder"),t4a.forEach(t),HMt=r(Kro," \u2014 "),ode=n(Kro,"A",{href:!0});var a4a=s(ode);JMt=r(a4a,"FlaxEncoderDecoderModel"),a4a.forEach(t),YMt=r(Kro," (Encoder decoder model)"),Kro.forEach(t),ZMt=i(Ge),uL=n(Ge,"LI",{});var eto=s(uL);NRe=n(eto,"STRONG",{});var n4a=s(NRe);KMt=r(n4a,"longt5"),n4a.forEach(t),eEt=r(eto," \u2014 "),rde=n(eto,"A",{href:!0});var s4a=s(rde);oEt=r(s4a,"FlaxLongT5ForConditionalGeneration"),s4a.forEach(t),rEt=r(eto," (LongT5 model)"),eto.forEach(t),tEt=i(Ge),pL=n(Ge,"LI",{});var oto=s(pL);qRe=n(oto,"STRONG",{});var l4a=s(qRe);aEt=r(l4a,"marian"),l4a.forEach(t),nEt=r(oto," \u2014 "),tde=n(oto,"A",{href:!0});var i4a=s(tde);sEt=r(i4a,"FlaxMarianMTModel"),i4a.forEach(t),lEt=r(oto," (Marian model)"),oto.forEach(t),iEt=i(Ge),_L=n(Ge,"LI",{});var rto=s(_L);jRe=n(rto,"STRONG",{});var d4a=s(jRe);dEt=r(d4a,"mbart"),d4a.forEach(t),mEt=r(rto," \u2014 "),ade=n(rto,"A",{href:!0});var m4a=s(ade);cEt=r(m4a,"FlaxMBartForConditionalGeneration"),m4a.forEach(t),fEt=r(rto," (mBART model)"),rto.forEach(t),gEt=i(Ge),bL=n(Ge,"LI",{});var tto=s(bL);DRe=n(tto,"STRONG",{});var c4a=s(DRe);hEt=r(c4a,"mt5"),c4a.forEach(t),uEt=r(tto," \u2014 "),nde=n(tto,"A",{href:!0});var f4a=s(nde);pEt=r(f4a,"FlaxMT5ForConditionalGeneration"),f4a.forEach(t),_Et=r(tto," (MT5 model)"),tto.forEach(t),bEt=i(Ge),vL=n(Ge,"LI",{});var ato=s(vL);GRe=n(ato,"STRONG",{});var g4a=s(GRe);vEt=r(g4a,"pegasus"),g4a.forEach(t),FEt=r(ato," \u2014 "),sde=n(ato,"A",{href:!0});var h4a=s(sde);TEt=r(h4a,"FlaxPegasusForConditionalGeneration"),h4a.forEach(t),MEt=r(ato," (Pegasus model)"),ato.forEach(t),EEt=i(Ge),FL=n(Ge,"LI",{});var nto=s(FL);ORe=n(nto,"STRONG",{});var u4a=s(ORe);CEt=r(u4a,"t5"),u4a.forEach(t),wEt=r(nto," \u2014 "),lde=n(nto,"A",{href:!0});var p4a=s(lde);AEt=r(p4a,"FlaxT5ForConditionalGeneration"),p4a.forEach(t),LEt=r(nto," (T5 model)"),nto.forEach(t),Ge.forEach(t),yEt=i(ad),T(TL.$$.fragment,ad),ad.forEach(t),td.forEach(t),Hno=i(c),Mf=n(c,"H2",{class:!0});var pio=s(Mf);ML=n(pio,"A",{id:!0,class:!0,href:!0});var _4a=s(ML);VRe=n(_4a,"SPAN",{});var b4a=s(VRe);T(bB.$$.fragment,b4a),b4a.forEach(t),_4a.forEach(t),xEt=i(pio),XRe=n(pio,"SPAN",{});var v4a=s(XRe);$Et=r(v4a,"FlaxAutoModelForSequenceClassification"),v4a.forEach(t),pio.forEach(t),Jno=i(c),kr=n(c,"DIV",{class:!0});var nd=s(kr);T(vB.$$.fragment,nd),kEt=i(nd),Ef=n(nd,"P",{});var dfe=s(Ef);SEt=r(dfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),ide=n(dfe,"A",{href:!0});var F4a=s(ide);REt=r(F4a,"from_pretrained()"),F4a.forEach(t),PEt=r(dfe," class method or the "),dde=n(dfe,"A",{href:!0});var T4a=s(dde);BEt=r(T4a,"from_config()"),T4a.forEach(t),IEt=r(dfe,` class
method.`),dfe.forEach(t),NEt=i(nd),FB=n(nd,"P",{});var _io=s(FB);qEt=r(_io,"This class cannot be instantiated directly using "),zRe=n(_io,"CODE",{});var M4a=s(zRe);jEt=r(M4a,"__init__()"),M4a.forEach(t),DEt=r(_io," (throws an error)."),_io.forEach(t),GEt=i(nd),ba=n(nd,"DIV",{class:!0});var Jx=s(ba);T(TB.$$.fragment,Jx),OEt=i(Jx),QRe=n(Jx,"P",{});var E4a=s(QRe);VEt=r(E4a,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),E4a.forEach(t),XEt=i(Jx),Cf=n(Jx,"P",{});var mfe=s(Cf);zEt=r(mfe,`Note:
Loading a model from its configuration file does `),WRe=n(mfe,"STRONG",{});var C4a=s(WRe);QEt=r(C4a,"not"),C4a.forEach(t),WEt=r(mfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),mde=n(mfe,"A",{href:!0});var w4a=s(mde);UEt=r(w4a,"from_pretrained()"),w4a.forEach(t),HEt=r(mfe," to load the model weights."),mfe.forEach(t),JEt=i(Jx),T(EL.$$.fragment,Jx),Jx.forEach(t),YEt=i(nd),lt=n(nd,"DIV",{class:!0});var sd=s(lt);T(MB.$$.fragment,sd),ZEt=i(sd),URe=n(sd,"P",{});var A4a=s(URe);KEt=r(A4a,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),A4a.forEach(t),e4t=i(sd),rs=n(sd,"P",{});var Yx=s(rs);o4t=r(Yx,"The model class to instantiate is selected based on the "),HRe=n(Yx,"CODE",{});var L4a=s(HRe);r4t=r(L4a,"model_type"),L4a.forEach(t),t4t=r(Yx,` property of the config object (either
passed as an argument or loaded from `),JRe=n(Yx,"CODE",{});var y4a=s(JRe);a4t=r(y4a,"pretrained_model_name_or_path"),y4a.forEach(t),n4t=r(Yx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),YRe=n(Yx,"CODE",{});var x4a=s(YRe);s4t=r(x4a,"pretrained_model_name_or_path"),x4a.forEach(t),l4t=r(Yx,":"),Yx.forEach(t),i4t=i(sd),Re=n(sd,"UL",{});var Oe=s(Re);CL=n(Oe,"LI",{});var sto=s(CL);ZRe=n(sto,"STRONG",{});var $4a=s(ZRe);d4t=r($4a,"albert"),$4a.forEach(t),m4t=r(sto," \u2014 "),cde=n(sto,"A",{href:!0});var k4a=s(cde);c4t=r(k4a,"FlaxAlbertForSequenceClassification"),k4a.forEach(t),f4t=r(sto," (ALBERT model)"),sto.forEach(t),g4t=i(Oe),wL=n(Oe,"LI",{});var lto=s(wL);KRe=n(lto,"STRONG",{});var S4a=s(KRe);h4t=r(S4a,"bart"),S4a.forEach(t),u4t=r(lto," \u2014 "),fde=n(lto,"A",{href:!0});var R4a=s(fde);p4t=r(R4a,"FlaxBartForSequenceClassification"),R4a.forEach(t),_4t=r(lto," (BART model)"),lto.forEach(t),b4t=i(Oe),AL=n(Oe,"LI",{});var ito=s(AL);ePe=n(ito,"STRONG",{});var P4a=s(ePe);v4t=r(P4a,"bert"),P4a.forEach(t),F4t=r(ito," \u2014 "),gde=n(ito,"A",{href:!0});var B4a=s(gde);T4t=r(B4a,"FlaxBertForSequenceClassification"),B4a.forEach(t),M4t=r(ito," (BERT model)"),ito.forEach(t),E4t=i(Oe),LL=n(Oe,"LI",{});var dto=s(LL);oPe=n(dto,"STRONG",{});var I4a=s(oPe);C4t=r(I4a,"big_bird"),I4a.forEach(t),w4t=r(dto," \u2014 "),hde=n(dto,"A",{href:!0});var N4a=s(hde);A4t=r(N4a,"FlaxBigBirdForSequenceClassification"),N4a.forEach(t),L4t=r(dto," (BigBird model)"),dto.forEach(t),y4t=i(Oe),yL=n(Oe,"LI",{});var mto=s(yL);rPe=n(mto,"STRONG",{});var q4a=s(rPe);x4t=r(q4a,"distilbert"),q4a.forEach(t),$4t=r(mto," \u2014 "),ude=n(mto,"A",{href:!0});var j4a=s(ude);k4t=r(j4a,"FlaxDistilBertForSequenceClassification"),j4a.forEach(t),S4t=r(mto," (DistilBERT model)"),mto.forEach(t),R4t=i(Oe),xL=n(Oe,"LI",{});var cto=s(xL);tPe=n(cto,"STRONG",{});var D4a=s(tPe);P4t=r(D4a,"electra"),D4a.forEach(t),B4t=r(cto," \u2014 "),pde=n(cto,"A",{href:!0});var G4a=s(pde);I4t=r(G4a,"FlaxElectraForSequenceClassification"),G4a.forEach(t),N4t=r(cto," (ELECTRA model)"),cto.forEach(t),q4t=i(Oe),$L=n(Oe,"LI",{});var fto=s($L);aPe=n(fto,"STRONG",{});var O4a=s(aPe);j4t=r(O4a,"mbart"),O4a.forEach(t),D4t=r(fto," \u2014 "),_de=n(fto,"A",{href:!0});var V4a=s(_de);G4t=r(V4a,"FlaxMBartForSequenceClassification"),V4a.forEach(t),O4t=r(fto," (mBART model)"),fto.forEach(t),V4t=i(Oe),kL=n(Oe,"LI",{});var gto=s(kL);nPe=n(gto,"STRONG",{});var X4a=s(nPe);X4t=r(X4a,"roberta"),X4a.forEach(t),z4t=r(gto," \u2014 "),bde=n(gto,"A",{href:!0});var z4a=s(bde);Q4t=r(z4a,"FlaxRobertaForSequenceClassification"),z4a.forEach(t),W4t=r(gto," (RoBERTa model)"),gto.forEach(t),U4t=i(Oe),SL=n(Oe,"LI",{});var hto=s(SL);sPe=n(hto,"STRONG",{});var Q4a=s(sPe);H4t=r(Q4a,"roformer"),Q4a.forEach(t),J4t=r(hto," \u2014 "),vde=n(hto,"A",{href:!0});var W4a=s(vde);Y4t=r(W4a,"FlaxRoFormerForSequenceClassification"),W4a.forEach(t),Z4t=r(hto," (RoFormer model)"),hto.forEach(t),K4t=i(Oe),RL=n(Oe,"LI",{});var uto=s(RL);lPe=n(uto,"STRONG",{});var U4a=s(lPe);eCt=r(U4a,"xlm-roberta"),U4a.forEach(t),oCt=r(uto," \u2014 "),Fde=n(uto,"A",{href:!0});var H4a=s(Fde);rCt=r(H4a,"FlaxXLMRobertaForSequenceClassification"),H4a.forEach(t),tCt=r(uto," (XLM-RoBERTa model)"),uto.forEach(t),Oe.forEach(t),aCt=i(sd),T(PL.$$.fragment,sd),sd.forEach(t),nd.forEach(t),Yno=i(c),wf=n(c,"H2",{class:!0});var bio=s(wf);BL=n(bio,"A",{id:!0,class:!0,href:!0});var J4a=s(BL);iPe=n(J4a,"SPAN",{});var Y4a=s(iPe);T(EB.$$.fragment,Y4a),Y4a.forEach(t),J4a.forEach(t),nCt=i(bio),dPe=n(bio,"SPAN",{});var Z4a=s(dPe);sCt=r(Z4a,"FlaxAutoModelForQuestionAnswering"),Z4a.forEach(t),bio.forEach(t),Zno=i(c),Sr=n(c,"DIV",{class:!0});var ld=s(Sr);T(CB.$$.fragment,ld),lCt=i(ld),Af=n(ld,"P",{});var cfe=s(Af);iCt=r(cfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Tde=n(cfe,"A",{href:!0});var K4a=s(Tde);dCt=r(K4a,"from_pretrained()"),K4a.forEach(t),mCt=r(cfe," class method or the "),Mde=n(cfe,"A",{href:!0});var eCa=s(Mde);cCt=r(eCa,"from_config()"),eCa.forEach(t),fCt=r(cfe,` class
method.`),cfe.forEach(t),gCt=i(ld),wB=n(ld,"P",{});var vio=s(wB);hCt=r(vio,"This class cannot be instantiated directly using "),mPe=n(vio,"CODE",{});var oCa=s(mPe);uCt=r(oCa,"__init__()"),oCa.forEach(t),pCt=r(vio," (throws an error)."),vio.forEach(t),_Ct=i(ld),va=n(ld,"DIV",{class:!0});var Zx=s(va);T(AB.$$.fragment,Zx),bCt=i(Zx),cPe=n(Zx,"P",{});var rCa=s(cPe);vCt=r(rCa,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),rCa.forEach(t),FCt=i(Zx),Lf=n(Zx,"P",{});var ffe=s(Lf);TCt=r(ffe,`Note:
Loading a model from its configuration file does `),fPe=n(ffe,"STRONG",{});var tCa=s(fPe);MCt=r(tCa,"not"),tCa.forEach(t),ECt=r(ffe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ede=n(ffe,"A",{href:!0});var aCa=s(Ede);CCt=r(aCa,"from_pretrained()"),aCa.forEach(t),wCt=r(ffe," to load the model weights."),ffe.forEach(t),ACt=i(Zx),T(IL.$$.fragment,Zx),Zx.forEach(t),LCt=i(ld),it=n(ld,"DIV",{class:!0});var id=s(it);T(LB.$$.fragment,id),yCt=i(id),gPe=n(id,"P",{});var nCa=s(gPe);xCt=r(nCa,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),nCa.forEach(t),$Ct=i(id),ts=n(id,"P",{});var Kx=s(ts);kCt=r(Kx,"The model class to instantiate is selected based on the "),hPe=n(Kx,"CODE",{});var sCa=s(hPe);SCt=r(sCa,"model_type"),sCa.forEach(t),RCt=r(Kx,` property of the config object (either
passed as an argument or loaded from `),uPe=n(Kx,"CODE",{});var lCa=s(uPe);PCt=r(lCa,"pretrained_model_name_or_path"),lCa.forEach(t),BCt=r(Kx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pPe=n(Kx,"CODE",{});var iCa=s(pPe);ICt=r(iCa,"pretrained_model_name_or_path"),iCa.forEach(t),NCt=r(Kx,":"),Kx.forEach(t),qCt=i(id),Pe=n(id,"UL",{});var Ve=s(Pe);NL=n(Ve,"LI",{});var pto=s(NL);_Pe=n(pto,"STRONG",{});var dCa=s(_Pe);jCt=r(dCa,"albert"),dCa.forEach(t),DCt=r(pto," \u2014 "),Cde=n(pto,"A",{href:!0});var mCa=s(Cde);GCt=r(mCa,"FlaxAlbertForQuestionAnswering"),mCa.forEach(t),OCt=r(pto," (ALBERT model)"),pto.forEach(t),VCt=i(Ve),qL=n(Ve,"LI",{});var _to=s(qL);bPe=n(_to,"STRONG",{});var cCa=s(bPe);XCt=r(cCa,"bart"),cCa.forEach(t),zCt=r(_to," \u2014 "),wde=n(_to,"A",{href:!0});var fCa=s(wde);QCt=r(fCa,"FlaxBartForQuestionAnswering"),fCa.forEach(t),WCt=r(_to," (BART model)"),_to.forEach(t),UCt=i(Ve),jL=n(Ve,"LI",{});var bto=s(jL);vPe=n(bto,"STRONG",{});var gCa=s(vPe);HCt=r(gCa,"bert"),gCa.forEach(t),JCt=r(bto," \u2014 "),Ade=n(bto,"A",{href:!0});var hCa=s(Ade);YCt=r(hCa,"FlaxBertForQuestionAnswering"),hCa.forEach(t),ZCt=r(bto," (BERT model)"),bto.forEach(t),KCt=i(Ve),DL=n(Ve,"LI",{});var vto=s(DL);FPe=n(vto,"STRONG",{});var uCa=s(FPe);e3t=r(uCa,"big_bird"),uCa.forEach(t),o3t=r(vto," \u2014 "),Lde=n(vto,"A",{href:!0});var pCa=s(Lde);r3t=r(pCa,"FlaxBigBirdForQuestionAnswering"),pCa.forEach(t),t3t=r(vto," (BigBird model)"),vto.forEach(t),a3t=i(Ve),GL=n(Ve,"LI",{});var Fto=s(GL);TPe=n(Fto,"STRONG",{});var _Ca=s(TPe);n3t=r(_Ca,"distilbert"),_Ca.forEach(t),s3t=r(Fto," \u2014 "),yde=n(Fto,"A",{href:!0});var bCa=s(yde);l3t=r(bCa,"FlaxDistilBertForQuestionAnswering"),bCa.forEach(t),i3t=r(Fto," (DistilBERT model)"),Fto.forEach(t),d3t=i(Ve),OL=n(Ve,"LI",{});var Tto=s(OL);MPe=n(Tto,"STRONG",{});var vCa=s(MPe);m3t=r(vCa,"electra"),vCa.forEach(t),c3t=r(Tto," \u2014 "),xde=n(Tto,"A",{href:!0});var FCa=s(xde);f3t=r(FCa,"FlaxElectraForQuestionAnswering"),FCa.forEach(t),g3t=r(Tto," (ELECTRA model)"),Tto.forEach(t),h3t=i(Ve),VL=n(Ve,"LI",{});var Mto=s(VL);EPe=n(Mto,"STRONG",{});var TCa=s(EPe);u3t=r(TCa,"mbart"),TCa.forEach(t),p3t=r(Mto," \u2014 "),$de=n(Mto,"A",{href:!0});var MCa=s($de);_3t=r(MCa,"FlaxMBartForQuestionAnswering"),MCa.forEach(t),b3t=r(Mto," (mBART model)"),Mto.forEach(t),v3t=i(Ve),XL=n(Ve,"LI",{});var Eto=s(XL);CPe=n(Eto,"STRONG",{});var ECa=s(CPe);F3t=r(ECa,"roberta"),ECa.forEach(t),T3t=r(Eto," \u2014 "),kde=n(Eto,"A",{href:!0});var CCa=s(kde);M3t=r(CCa,"FlaxRobertaForQuestionAnswering"),CCa.forEach(t),E3t=r(Eto," (RoBERTa model)"),Eto.forEach(t),C3t=i(Ve),zL=n(Ve,"LI",{});var Cto=s(zL);wPe=n(Cto,"STRONG",{});var wCa=s(wPe);w3t=r(wCa,"roformer"),wCa.forEach(t),A3t=r(Cto," \u2014 "),Sde=n(Cto,"A",{href:!0});var ACa=s(Sde);L3t=r(ACa,"FlaxRoFormerForQuestionAnswering"),ACa.forEach(t),y3t=r(Cto," (RoFormer model)"),Cto.forEach(t),x3t=i(Ve),QL=n(Ve,"LI",{});var wto=s(QL);APe=n(wto,"STRONG",{});var LCa=s(APe);$3t=r(LCa,"xlm-roberta"),LCa.forEach(t),k3t=r(wto," \u2014 "),Rde=n(wto,"A",{href:!0});var yCa=s(Rde);S3t=r(yCa,"FlaxXLMRobertaForQuestionAnswering"),yCa.forEach(t),R3t=r(wto," (XLM-RoBERTa model)"),wto.forEach(t),Ve.forEach(t),P3t=i(id),T(WL.$$.fragment,id),id.forEach(t),ld.forEach(t),Kno=i(c),yf=n(c,"H2",{class:!0});var Fio=s(yf);UL=n(Fio,"A",{id:!0,class:!0,href:!0});var xCa=s(UL);LPe=n(xCa,"SPAN",{});var $Ca=s(LPe);T(yB.$$.fragment,$Ca),$Ca.forEach(t),xCa.forEach(t),B3t=i(Fio),yPe=n(Fio,"SPAN",{});var kCa=s(yPe);I3t=r(kCa,"FlaxAutoModelForTokenClassification"),kCa.forEach(t),Fio.forEach(t),eso=i(c),Rr=n(c,"DIV",{class:!0});var dd=s(Rr);T(xB.$$.fragment,dd),N3t=i(dd),xf=n(dd,"P",{});var gfe=s(xf);q3t=r(gfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Pde=n(gfe,"A",{href:!0});var SCa=s(Pde);j3t=r(SCa,"from_pretrained()"),SCa.forEach(t),D3t=r(gfe," class method or the "),Bde=n(gfe,"A",{href:!0});var RCa=s(Bde);G3t=r(RCa,"from_config()"),RCa.forEach(t),O3t=r(gfe,` class
method.`),gfe.forEach(t),V3t=i(dd),$B=n(dd,"P",{});var Tio=s($B);X3t=r(Tio,"This class cannot be instantiated directly using "),xPe=n(Tio,"CODE",{});var PCa=s(xPe);z3t=r(PCa,"__init__()"),PCa.forEach(t),Q3t=r(Tio," (throws an error)."),Tio.forEach(t),W3t=i(dd),Fa=n(dd,"DIV",{class:!0});var e$=s(Fa);T(kB.$$.fragment,e$),U3t=i(e$),$Pe=n(e$,"P",{});var BCa=s($Pe);H3t=r(BCa,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),BCa.forEach(t),J3t=i(e$),$f=n(e$,"P",{});var hfe=s($f);Y3t=r(hfe,`Note:
Loading a model from its configuration file does `),kPe=n(hfe,"STRONG",{});var ICa=s(kPe);Z3t=r(ICa,"not"),ICa.forEach(t),K3t=r(hfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ide=n(hfe,"A",{href:!0});var NCa=s(Ide);e5t=r(NCa,"from_pretrained()"),NCa.forEach(t),o5t=r(hfe," to load the model weights."),hfe.forEach(t),r5t=i(e$),T(HL.$$.fragment,e$),e$.forEach(t),t5t=i(dd),dt=n(dd,"DIV",{class:!0});var md=s(dt);T(SB.$$.fragment,md),a5t=i(md),SPe=n(md,"P",{});var qCa=s(SPe);n5t=r(qCa,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),qCa.forEach(t),s5t=i(md),as=n(md,"P",{});var o$=s(as);l5t=r(o$,"The model class to instantiate is selected based on the "),RPe=n(o$,"CODE",{});var jCa=s(RPe);i5t=r(jCa,"model_type"),jCa.forEach(t),d5t=r(o$,` property of the config object (either
passed as an argument or loaded from `),PPe=n(o$,"CODE",{});var DCa=s(PPe);m5t=r(DCa,"pretrained_model_name_or_path"),DCa.forEach(t),c5t=r(o$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),BPe=n(o$,"CODE",{});var GCa=s(BPe);f5t=r(GCa,"pretrained_model_name_or_path"),GCa.forEach(t),g5t=r(o$,":"),o$.forEach(t),h5t=i(md),ze=n(md,"UL",{});var yo=s(ze);JL=n(yo,"LI",{});var Ato=s(JL);IPe=n(Ato,"STRONG",{});var OCa=s(IPe);u5t=r(OCa,"albert"),OCa.forEach(t),p5t=r(Ato," \u2014 "),Nde=n(Ato,"A",{href:!0});var VCa=s(Nde);_5t=r(VCa,"FlaxAlbertForTokenClassification"),VCa.forEach(t),b5t=r(Ato," (ALBERT model)"),Ato.forEach(t),v5t=i(yo),YL=n(yo,"LI",{});var Lto=s(YL);NPe=n(Lto,"STRONG",{});var XCa=s(NPe);F5t=r(XCa,"bert"),XCa.forEach(t),T5t=r(Lto," \u2014 "),qde=n(Lto,"A",{href:!0});var zCa=s(qde);M5t=r(zCa,"FlaxBertForTokenClassification"),zCa.forEach(t),E5t=r(Lto," (BERT model)"),Lto.forEach(t),C5t=i(yo),ZL=n(yo,"LI",{});var yto=s(ZL);qPe=n(yto,"STRONG",{});var QCa=s(qPe);w5t=r(QCa,"big_bird"),QCa.forEach(t),A5t=r(yto," \u2014 "),jde=n(yto,"A",{href:!0});var WCa=s(jde);L5t=r(WCa,"FlaxBigBirdForTokenClassification"),WCa.forEach(t),y5t=r(yto," (BigBird model)"),yto.forEach(t),x5t=i(yo),KL=n(yo,"LI",{});var xto=s(KL);jPe=n(xto,"STRONG",{});var UCa=s(jPe);$5t=r(UCa,"distilbert"),UCa.forEach(t),k5t=r(xto," \u2014 "),Dde=n(xto,"A",{href:!0});var HCa=s(Dde);S5t=r(HCa,"FlaxDistilBertForTokenClassification"),HCa.forEach(t),R5t=r(xto," (DistilBERT model)"),xto.forEach(t),P5t=i(yo),ey=n(yo,"LI",{});var $to=s(ey);DPe=n($to,"STRONG",{});var JCa=s(DPe);B5t=r(JCa,"electra"),JCa.forEach(t),I5t=r($to," \u2014 "),Gde=n($to,"A",{href:!0});var YCa=s(Gde);N5t=r(YCa,"FlaxElectraForTokenClassification"),YCa.forEach(t),q5t=r($to," (ELECTRA model)"),$to.forEach(t),j5t=i(yo),oy=n(yo,"LI",{});var kto=s(oy);GPe=n(kto,"STRONG",{});var ZCa=s(GPe);D5t=r(ZCa,"roberta"),ZCa.forEach(t),G5t=r(kto," \u2014 "),Ode=n(kto,"A",{href:!0});var KCa=s(Ode);O5t=r(KCa,"FlaxRobertaForTokenClassification"),KCa.forEach(t),V5t=r(kto," (RoBERTa model)"),kto.forEach(t),X5t=i(yo),ry=n(yo,"LI",{});var Sto=s(ry);OPe=n(Sto,"STRONG",{});var e3a=s(OPe);z5t=r(e3a,"roformer"),e3a.forEach(t),Q5t=r(Sto," \u2014 "),Vde=n(Sto,"A",{href:!0});var o3a=s(Vde);W5t=r(o3a,"FlaxRoFormerForTokenClassification"),o3a.forEach(t),U5t=r(Sto," (RoFormer model)"),Sto.forEach(t),H5t=i(yo),ty=n(yo,"LI",{});var Rto=s(ty);VPe=n(Rto,"STRONG",{});var r3a=s(VPe);J5t=r(r3a,"xlm-roberta"),r3a.forEach(t),Y5t=r(Rto," \u2014 "),Xde=n(Rto,"A",{href:!0});var t3a=s(Xde);Z5t=r(t3a,"FlaxXLMRobertaForTokenClassification"),t3a.forEach(t),K5t=r(Rto," (XLM-RoBERTa model)"),Rto.forEach(t),yo.forEach(t),e0t=i(md),T(ay.$$.fragment,md),md.forEach(t),dd.forEach(t),oso=i(c),kf=n(c,"H2",{class:!0});var Mio=s(kf);ny=n(Mio,"A",{id:!0,class:!0,href:!0});var a3a=s(ny);XPe=n(a3a,"SPAN",{});var n3a=s(XPe);T(RB.$$.fragment,n3a),n3a.forEach(t),a3a.forEach(t),o0t=i(Mio),zPe=n(Mio,"SPAN",{});var s3a=s(zPe);r0t=r(s3a,"FlaxAutoModelForMultipleChoice"),s3a.forEach(t),Mio.forEach(t),rso=i(c),Pr=n(c,"DIV",{class:!0});var cd=s(Pr);T(PB.$$.fragment,cd),t0t=i(cd),Sf=n(cd,"P",{});var ufe=s(Sf);a0t=r(ufe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),zde=n(ufe,"A",{href:!0});var l3a=s(zde);n0t=r(l3a,"from_pretrained()"),l3a.forEach(t),s0t=r(ufe," class method or the "),Qde=n(ufe,"A",{href:!0});var i3a=s(Qde);l0t=r(i3a,"from_config()"),i3a.forEach(t),i0t=r(ufe,` class
method.`),ufe.forEach(t),d0t=i(cd),BB=n(cd,"P",{});var Eio=s(BB);m0t=r(Eio,"This class cannot be instantiated directly using "),QPe=n(Eio,"CODE",{});var d3a=s(QPe);c0t=r(d3a,"__init__()"),d3a.forEach(t),f0t=r(Eio," (throws an error)."),Eio.forEach(t),g0t=i(cd),Ta=n(cd,"DIV",{class:!0});var r$=s(Ta);T(IB.$$.fragment,r$),h0t=i(r$),WPe=n(r$,"P",{});var m3a=s(WPe);u0t=r(m3a,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),m3a.forEach(t),p0t=i(r$),Rf=n(r$,"P",{});var pfe=s(Rf);_0t=r(pfe,`Note:
Loading a model from its configuration file does `),UPe=n(pfe,"STRONG",{});var c3a=s(UPe);b0t=r(c3a,"not"),c3a.forEach(t),v0t=r(pfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Wde=n(pfe,"A",{href:!0});var f3a=s(Wde);F0t=r(f3a,"from_pretrained()"),f3a.forEach(t),T0t=r(pfe," to load the model weights."),pfe.forEach(t),M0t=i(r$),T(sy.$$.fragment,r$),r$.forEach(t),E0t=i(cd),mt=n(cd,"DIV",{class:!0});var fd=s(mt);T(NB.$$.fragment,fd),C0t=i(fd),HPe=n(fd,"P",{});var g3a=s(HPe);w0t=r(g3a,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),g3a.forEach(t),A0t=i(fd),ns=n(fd,"P",{});var t$=s(ns);L0t=r(t$,"The model class to instantiate is selected based on the "),JPe=n(t$,"CODE",{});var h3a=s(JPe);y0t=r(h3a,"model_type"),h3a.forEach(t),x0t=r(t$,` property of the config object (either
passed as an argument or loaded from `),YPe=n(t$,"CODE",{});var u3a=s(YPe);$0t=r(u3a,"pretrained_model_name_or_path"),u3a.forEach(t),k0t=r(t$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZPe=n(t$,"CODE",{});var p3a=s(ZPe);S0t=r(p3a,"pretrained_model_name_or_path"),p3a.forEach(t),R0t=r(t$,":"),t$.forEach(t),P0t=i(fd),Qe=n(fd,"UL",{});var xo=s(Qe);ly=n(xo,"LI",{});var Pto=s(ly);KPe=n(Pto,"STRONG",{});var _3a=s(KPe);B0t=r(_3a,"albert"),_3a.forEach(t),I0t=r(Pto," \u2014 "),Ude=n(Pto,"A",{href:!0});var b3a=s(Ude);N0t=r(b3a,"FlaxAlbertForMultipleChoice"),b3a.forEach(t),q0t=r(Pto," (ALBERT model)"),Pto.forEach(t),j0t=i(xo),iy=n(xo,"LI",{});var Bto=s(iy);eBe=n(Bto,"STRONG",{});var v3a=s(eBe);D0t=r(v3a,"bert"),v3a.forEach(t),G0t=r(Bto," \u2014 "),Hde=n(Bto,"A",{href:!0});var F3a=s(Hde);O0t=r(F3a,"FlaxBertForMultipleChoice"),F3a.forEach(t),V0t=r(Bto," (BERT model)"),Bto.forEach(t),X0t=i(xo),dy=n(xo,"LI",{});var Ito=s(dy);oBe=n(Ito,"STRONG",{});var T3a=s(oBe);z0t=r(T3a,"big_bird"),T3a.forEach(t),Q0t=r(Ito," \u2014 "),Jde=n(Ito,"A",{href:!0});var M3a=s(Jde);W0t=r(M3a,"FlaxBigBirdForMultipleChoice"),M3a.forEach(t),U0t=r(Ito," (BigBird model)"),Ito.forEach(t),H0t=i(xo),my=n(xo,"LI",{});var Nto=s(my);rBe=n(Nto,"STRONG",{});var E3a=s(rBe);J0t=r(E3a,"distilbert"),E3a.forEach(t),Y0t=r(Nto," \u2014 "),Yde=n(Nto,"A",{href:!0});var C3a=s(Yde);Z0t=r(C3a,"FlaxDistilBertForMultipleChoice"),C3a.forEach(t),K0t=r(Nto," (DistilBERT model)"),Nto.forEach(t),ewt=i(xo),cy=n(xo,"LI",{});var qto=s(cy);tBe=n(qto,"STRONG",{});var w3a=s(tBe);owt=r(w3a,"electra"),w3a.forEach(t),rwt=r(qto," \u2014 "),Zde=n(qto,"A",{href:!0});var A3a=s(Zde);twt=r(A3a,"FlaxElectraForMultipleChoice"),A3a.forEach(t),awt=r(qto," (ELECTRA model)"),qto.forEach(t),nwt=i(xo),fy=n(xo,"LI",{});var jto=s(fy);aBe=n(jto,"STRONG",{});var L3a=s(aBe);swt=r(L3a,"roberta"),L3a.forEach(t),lwt=r(jto," \u2014 "),Kde=n(jto,"A",{href:!0});var y3a=s(Kde);iwt=r(y3a,"FlaxRobertaForMultipleChoice"),y3a.forEach(t),dwt=r(jto," (RoBERTa model)"),jto.forEach(t),mwt=i(xo),gy=n(xo,"LI",{});var Dto=s(gy);nBe=n(Dto,"STRONG",{});var x3a=s(nBe);cwt=r(x3a,"roformer"),x3a.forEach(t),fwt=r(Dto," \u2014 "),eme=n(Dto,"A",{href:!0});var $3a=s(eme);gwt=r($3a,"FlaxRoFormerForMultipleChoice"),$3a.forEach(t),hwt=r(Dto," (RoFormer model)"),Dto.forEach(t),uwt=i(xo),hy=n(xo,"LI",{});var Gto=s(hy);sBe=n(Gto,"STRONG",{});var k3a=s(sBe);pwt=r(k3a,"xlm-roberta"),k3a.forEach(t),_wt=r(Gto," \u2014 "),ome=n(Gto,"A",{href:!0});var S3a=s(ome);bwt=r(S3a,"FlaxXLMRobertaForMultipleChoice"),S3a.forEach(t),vwt=r(Gto," (XLM-RoBERTa model)"),Gto.forEach(t),xo.forEach(t),Fwt=i(fd),T(uy.$$.fragment,fd),fd.forEach(t),cd.forEach(t),tso=i(c),Pf=n(c,"H2",{class:!0});var Cio=s(Pf);py=n(Cio,"A",{id:!0,class:!0,href:!0});var R3a=s(py);lBe=n(R3a,"SPAN",{});var P3a=s(lBe);T(qB.$$.fragment,P3a),P3a.forEach(t),R3a.forEach(t),Twt=i(Cio),iBe=n(Cio,"SPAN",{});var B3a=s(iBe);Mwt=r(B3a,"FlaxAutoModelForNextSentencePrediction"),B3a.forEach(t),Cio.forEach(t),aso=i(c),Br=n(c,"DIV",{class:!0});var gd=s(Br);T(jB.$$.fragment,gd),Ewt=i(gd),Bf=n(gd,"P",{});var _fe=s(Bf);Cwt=r(_fe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),rme=n(_fe,"A",{href:!0});var I3a=s(rme);wwt=r(I3a,"from_pretrained()"),I3a.forEach(t),Awt=r(_fe," class method or the "),tme=n(_fe,"A",{href:!0});var N3a=s(tme);Lwt=r(N3a,"from_config()"),N3a.forEach(t),ywt=r(_fe,` class
method.`),_fe.forEach(t),xwt=i(gd),DB=n(gd,"P",{});var wio=s(DB);$wt=r(wio,"This class cannot be instantiated directly using "),dBe=n(wio,"CODE",{});var q3a=s(dBe);kwt=r(q3a,"__init__()"),q3a.forEach(t),Swt=r(wio," (throws an error)."),wio.forEach(t),Rwt=i(gd),Ma=n(gd,"DIV",{class:!0});var a$=s(Ma);T(GB.$$.fragment,a$),Pwt=i(a$),mBe=n(a$,"P",{});var j3a=s(mBe);Bwt=r(j3a,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),j3a.forEach(t),Iwt=i(a$),If=n(a$,"P",{});var bfe=s(If);Nwt=r(bfe,`Note:
Loading a model from its configuration file does `),cBe=n(bfe,"STRONG",{});var D3a=s(cBe);qwt=r(D3a,"not"),D3a.forEach(t),jwt=r(bfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),ame=n(bfe,"A",{href:!0});var G3a=s(ame);Dwt=r(G3a,"from_pretrained()"),G3a.forEach(t),Gwt=r(bfe," to load the model weights."),bfe.forEach(t),Owt=i(a$),T(_y.$$.fragment,a$),a$.forEach(t),Vwt=i(gd),ct=n(gd,"DIV",{class:!0});var hd=s(ct);T(OB.$$.fragment,hd),Xwt=i(hd),fBe=n(hd,"P",{});var O3a=s(fBe);zwt=r(O3a,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),O3a.forEach(t),Qwt=i(hd),ss=n(hd,"P",{});var n$=s(ss);Wwt=r(n$,"The model class to instantiate is selected based on the "),gBe=n(n$,"CODE",{});var V3a=s(gBe);Uwt=r(V3a,"model_type"),V3a.forEach(t),Hwt=r(n$,` property of the config object (either
passed as an argument or loaded from `),hBe=n(n$,"CODE",{});var X3a=s(hBe);Jwt=r(X3a,"pretrained_model_name_or_path"),X3a.forEach(t),Ywt=r(n$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uBe=n(n$,"CODE",{});var z3a=s(uBe);Zwt=r(z3a,"pretrained_model_name_or_path"),z3a.forEach(t),Kwt=r(n$,":"),n$.forEach(t),eAt=i(hd),pBe=n(hd,"UL",{});var Q3a=s(pBe);by=n(Q3a,"LI",{});var Oto=s(by);_Be=n(Oto,"STRONG",{});var W3a=s(_Be);oAt=r(W3a,"bert"),W3a.forEach(t),rAt=r(Oto," \u2014 "),nme=n(Oto,"A",{href:!0});var U3a=s(nme);tAt=r(U3a,"FlaxBertForNextSentencePrediction"),U3a.forEach(t),aAt=r(Oto," (BERT model)"),Oto.forEach(t),Q3a.forEach(t),nAt=i(hd),T(vy.$$.fragment,hd),hd.forEach(t),gd.forEach(t),nso=i(c),Nf=n(c,"H2",{class:!0});var Aio=s(Nf);Fy=n(Aio,"A",{id:!0,class:!0,href:!0});var H3a=s(Fy);bBe=n(H3a,"SPAN",{});var J3a=s(bBe);T(VB.$$.fragment,J3a),J3a.forEach(t),H3a.forEach(t),sAt=i(Aio),vBe=n(Aio,"SPAN",{});var Y3a=s(vBe);lAt=r(Y3a,"FlaxAutoModelForImageClassification"),Y3a.forEach(t),Aio.forEach(t),sso=i(c),Ir=n(c,"DIV",{class:!0});var ud=s(Ir);T(XB.$$.fragment,ud),iAt=i(ud),qf=n(ud,"P",{});var vfe=s(qf);dAt=r(vfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),sme=n(vfe,"A",{href:!0});var Z3a=s(sme);mAt=r(Z3a,"from_pretrained()"),Z3a.forEach(t),cAt=r(vfe," class method or the "),lme=n(vfe,"A",{href:!0});var K3a=s(lme);fAt=r(K3a,"from_config()"),K3a.forEach(t),gAt=r(vfe,` class
method.`),vfe.forEach(t),hAt=i(ud),zB=n(ud,"P",{});var Lio=s(zB);uAt=r(Lio,"This class cannot be instantiated directly using "),FBe=n(Lio,"CODE",{});var e5a=s(FBe);pAt=r(e5a,"__init__()"),e5a.forEach(t),_At=r(Lio," (throws an error)."),Lio.forEach(t),bAt=i(ud),Ea=n(ud,"DIV",{class:!0});var s$=s(Ea);T(QB.$$.fragment,s$),vAt=i(s$),TBe=n(s$,"P",{});var o5a=s(TBe);FAt=r(o5a,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),o5a.forEach(t),TAt=i(s$),jf=n(s$,"P",{});var Ffe=s(jf);MAt=r(Ffe,`Note:
Loading a model from its configuration file does `),MBe=n(Ffe,"STRONG",{});var r5a=s(MBe);EAt=r(r5a,"not"),r5a.forEach(t),CAt=r(Ffe,` load the model weights. It only affects the
model\u2019s configuration. Use `),ime=n(Ffe,"A",{href:!0});var t5a=s(ime);wAt=r(t5a,"from_pretrained()"),t5a.forEach(t),AAt=r(Ffe," to load the model weights."),Ffe.forEach(t),LAt=i(s$),T(Ty.$$.fragment,s$),s$.forEach(t),yAt=i(ud),ft=n(ud,"DIV",{class:!0});var pd=s(ft);T(WB.$$.fragment,pd),xAt=i(pd),EBe=n(pd,"P",{});var a5a=s(EBe);$At=r(a5a,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),a5a.forEach(t),kAt=i(pd),ls=n(pd,"P",{});var l$=s(ls);SAt=r(l$,"The model class to instantiate is selected based on the "),CBe=n(l$,"CODE",{});var n5a=s(CBe);RAt=r(n5a,"model_type"),n5a.forEach(t),PAt=r(l$,` property of the config object (either
passed as an argument or loaded from `),wBe=n(l$,"CODE",{});var s5a=s(wBe);BAt=r(s5a,"pretrained_model_name_or_path"),s5a.forEach(t),IAt=r(l$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ABe=n(l$,"CODE",{});var l5a=s(ABe);NAt=r(l5a,"pretrained_model_name_or_path"),l5a.forEach(t),qAt=r(l$,":"),l$.forEach(t),jAt=i(pd),UB=n(pd,"UL",{});var yio=s(UB);My=n(yio,"LI",{});var Vto=s(My);LBe=n(Vto,"STRONG",{});var i5a=s(LBe);DAt=r(i5a,"beit"),i5a.forEach(t),GAt=r(Vto," \u2014 "),dme=n(Vto,"A",{href:!0});var d5a=s(dme);OAt=r(d5a,"FlaxBeitForImageClassification"),d5a.forEach(t),VAt=r(Vto," (BEiT model)"),Vto.forEach(t),XAt=i(yio),Ey=n(yio,"LI",{});var Xto=s(Ey);yBe=n(Xto,"STRONG",{});var m5a=s(yBe);zAt=r(m5a,"vit"),m5a.forEach(t),QAt=r(Xto," \u2014 "),mme=n(Xto,"A",{href:!0});var c5a=s(mme);WAt=r(c5a,"FlaxViTForImageClassification"),c5a.forEach(t),UAt=r(Xto," (ViT model)"),Xto.forEach(t),yio.forEach(t),HAt=i(pd),T(Cy.$$.fragment,pd),pd.forEach(t),ud.forEach(t),lso=i(c),Df=n(c,"H2",{class:!0});var xio=s(Df);wy=n(xio,"A",{id:!0,class:!0,href:!0});var f5a=s(wy);xBe=n(f5a,"SPAN",{});var g5a=s(xBe);T(HB.$$.fragment,g5a),g5a.forEach(t),f5a.forEach(t),JAt=i(xio),$Be=n(xio,"SPAN",{});var h5a=s($Be);YAt=r(h5a,"FlaxAutoModelForVision2Seq"),h5a.forEach(t),xio.forEach(t),iso=i(c),Nr=n(c,"DIV",{class:!0});var _d=s(Nr);T(JB.$$.fragment,_d),ZAt=i(_d),Gf=n(_d,"P",{});var Tfe=s(Gf);KAt=r(Tfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),cme=n(Tfe,"A",{href:!0});var u5a=s(cme);e6t=r(u5a,"from_pretrained()"),u5a.forEach(t),o6t=r(Tfe," class method or the "),fme=n(Tfe,"A",{href:!0});var p5a=s(fme);r6t=r(p5a,"from_config()"),p5a.forEach(t),t6t=r(Tfe,` class
method.`),Tfe.forEach(t),a6t=i(_d),YB=n(_d,"P",{});var $io=s(YB);n6t=r($io,"This class cannot be instantiated directly using "),kBe=n($io,"CODE",{});var _5a=s(kBe);s6t=r(_5a,"__init__()"),_5a.forEach(t),l6t=r($io," (throws an error)."),$io.forEach(t),i6t=i(_d),Ca=n(_d,"DIV",{class:!0});var i$=s(Ca);T(ZB.$$.fragment,i$),d6t=i(i$),SBe=n(i$,"P",{});var b5a=s(SBe);m6t=r(b5a,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),b5a.forEach(t),c6t=i(i$),Of=n(i$,"P",{});var Mfe=s(Of);f6t=r(Mfe,`Note:
Loading a model from its configuration file does `),RBe=n(Mfe,"STRONG",{});var v5a=s(RBe);g6t=r(v5a,"not"),v5a.forEach(t),h6t=r(Mfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),gme=n(Mfe,"A",{href:!0});var F5a=s(gme);u6t=r(F5a,"from_pretrained()"),F5a.forEach(t),p6t=r(Mfe," to load the model weights."),Mfe.forEach(t),_6t=i(i$),T(Ay.$$.fragment,i$),i$.forEach(t),b6t=i(_d),gt=n(_d,"DIV",{class:!0});var bd=s(gt);T(KB.$$.fragment,bd),v6t=i(bd),PBe=n(bd,"P",{});var T5a=s(PBe);F6t=r(T5a,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),T5a.forEach(t),T6t=i(bd),is=n(bd,"P",{});var d$=s(is);M6t=r(d$,"The model class to instantiate is selected based on the "),BBe=n(d$,"CODE",{});var M5a=s(BBe);E6t=r(M5a,"model_type"),M5a.forEach(t),C6t=r(d$,` property of the config object (either
passed as an argument or loaded from `),IBe=n(d$,"CODE",{});var E5a=s(IBe);w6t=r(E5a,"pretrained_model_name_or_path"),E5a.forEach(t),A6t=r(d$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NBe=n(d$,"CODE",{});var C5a=s(NBe);L6t=r(C5a,"pretrained_model_name_or_path"),C5a.forEach(t),y6t=r(d$,":"),d$.forEach(t),x6t=i(bd),qBe=n(bd,"UL",{});var w5a=s(qBe);Ly=n(w5a,"LI",{});var zto=s(Ly);jBe=n(zto,"STRONG",{});var A5a=s(jBe);$6t=r(A5a,"vision-encoder-decoder"),A5a.forEach(t),k6t=r(zto," \u2014 "),hme=n(zto,"A",{href:!0});var L5a=s(hme);S6t=r(L5a,"FlaxVisionEncoderDecoderModel"),L5a.forEach(t),R6t=r(zto," (Vision Encoder decoder model)"),zto.forEach(t),w5a.forEach(t),P6t=i(bd),T(yy.$$.fragment,bd),bd.forEach(t),_d.forEach(t),this.h()},h(){m(g,"name","hf:doc:metadata"),m(g,"content",JSON.stringify(zwa)),m(f,"id","auto-classes"),m(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(f,"href","#auto-classes"),m(u,"class","relative group"),m(ms,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig"),m(fs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),m(gs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),m(wd,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),m(Jf,"id","extending-the-auto-classes"),m(Jf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Jf,"href","#extending-the-auto-classes"),m(Ad,"class","relative group"),m(Zf,"id","transformers.AutoConfig"),m(Zf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Zf,"href","#transformers.AutoConfig"),m(Ld,"class","relative group"),m(PN,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),m(BN,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig"),m(IN,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartConfig"),m(NN,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig"),m(qN,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertConfig"),m(jN,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig"),m(DN,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig"),m(GN,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),m(ON,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig"),m(VN,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),m(XN,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig"),m(zN,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig"),m(QN,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig"),m(WN,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig"),m(UN,"href","/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegConfig"),m(HN,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig"),m(JN,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig"),m(YN,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig"),m(ZN,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig"),m(KN,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig"),m(eq,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig"),m(oq,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),m(rq,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig"),m(tq,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),m(aq,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig"),m(nq,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config"),m(sq,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),m(lq,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig"),m(iq,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig"),m(dq,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig"),m(mq,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig"),m(cq,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig"),m(fq,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig"),m(gq,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig"),m(hq,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig"),m(uq,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),m(pq,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig"),m(_q,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig"),m(bq,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig"),m(vq,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig"),m(Fq,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig"),m(Tq,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig"),m(Mq,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig"),m(Eq,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig"),m(Cq,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config"),m(wq,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),m(Aq,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),m(Lq,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig"),m(yq,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig"),m(xq,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig"),m($q,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig"),m(kq,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig"),m(Sq,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig"),m(Rq,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig"),m(Pq,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),m(Bq,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),m(Iq,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDConfig"),m(Nq,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig"),m(qq,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig"),m(jq,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig"),m(Dq,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config"),m(Gq,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig"),m(Oq,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig"),m(Vq,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config"),m(Xq,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig"),m(zq,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig"),m(Qq,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig"),m(Wq,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig"),m(Uq,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig"),m(Hq,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),m(Jq,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig"),m(Yq,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig"),m(Zq,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig"),m(Kq,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config"),m(ej,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig"),m(oj,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig"),m(rj,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig"),m(tj,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),m(aj,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig"),m(nj,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig"),m(sj,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig"),m(lj,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig"),m(ij,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig"),m(dj,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig"),m(mj,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig"),m(cj,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig"),m(fj,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig"),m(gj,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagConfig"),m(hj,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmConfig"),m(uj,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig"),m(pj,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig"),m(_j,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig"),m(bj,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig"),m(vj,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig"),m(Fj,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig"),m(Tj,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig"),m(Mj,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig"),m(Ej,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig"),m(Cj,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig"),m(wj,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),m(Aj,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),m(Lj,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),m(yj,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig"),m(xj,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),m($j,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig"),m(kj,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config"),m(Sj,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Config"),m(Rj,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig"),m(Pj,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig"),m(Bj,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig"),m(Ij,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),m(Nj,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),m(qj,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig"),m(jj,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig"),m(Dj,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),m(Gj,"href","/docs/transformers/main/en/model_doc/van#transformers.VanConfig"),m(Oj,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig"),m(Vj,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig"),m(Xj,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),m(zj,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),m(Qj,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig"),m(Wj,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig"),m(Uj,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig"),m(Hj,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig"),m(Jj,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),m(Yj,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),m(Zj,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig"),m(Kj,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig"),m(eD,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig"),m(oD,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig"),m(rD,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig"),m(tD,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),m(aD,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),m(nD,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),m(sD,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig"),m(lD,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig"),m(iD,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig"),m(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(yu,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(xu,"id","transformers.AutoTokenizer"),m(xu,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(xu,"href","#transformers.AutoTokenizer"),m(xd,"class","relative group"),m(dD,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),m(mD,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),m(cD,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),m(fD,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizer"),m(gD,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizerFast"),m(hD,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizer"),m(uD,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizerFast"),m(pD,"href","/docs/transformers/main/en/model_doc/bartpho#transformers.BartphoTokenizer"),m(_D,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(bD,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(vD,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),m(FD,"href","/docs/transformers/main/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),m(TD,"href","/docs/transformers/main/en/model_doc/bertweet#transformers.BertweetTokenizer"),m(MD,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizer"),m(ED,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),m(CD,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),m(wD,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),m(AD,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),m(LD,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),m(yD,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),m(xD,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomTokenizerFast"),m($D,"href","/docs/transformers/main/en/model_doc/byt5#transformers.ByT5Tokenizer"),m(kD,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizer"),m(SD,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizerFast"),m(RD,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineTokenizer"),m(PD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(BD,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(ID,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(ND,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(qD,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizer"),m(jD,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),m(DD,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizer"),m(GD,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),m(OD,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizer"),m(VD,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizerFast"),m(XD,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLTokenizer"),m(zD,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),m(QD,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),m(WD,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizer"),m(UD,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizerFast"),m(HD,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),m(JD,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),m(YD,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizer"),m(ZD,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),m(KD,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),m(eG,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),m(oG,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizer"),m(rG,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizerFast"),m(tG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(aG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(nG,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmTokenizer"),m(sG,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertTokenizer"),m(lG,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizer"),m(iG,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizerFast"),m(dG,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTTokenizer"),m(mG,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizer"),m(cG,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizerFast"),m(fG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(gG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),m(hG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(uG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),m(pG,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),m(_G,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseTokenizer"),m(bG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(vG,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),m(FG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(TG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(MG,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizer"),m(EG,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizerFast"),m(CG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),m(wG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),m(AG,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),m(LG,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),m(yG,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),m(xG,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),m($G,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),m(kG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),m(SG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),m(RG,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),m(PG,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),m(BG,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizer"),m(IG,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizerFast"),m(NG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),m(qG,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),m(jG,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizer"),m(DG,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizerFast"),m(GG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),m(OG,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),m(VG,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeTokenizer"),m(XG,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizer"),m(zG,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),m(QG,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),m(WG,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianTokenizer"),m(UG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizer"),m(HG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizerFast"),m(JG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50Tokenizer"),m(YG,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50TokenizerFast"),m(ZG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(KG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(eO,"href","/docs/transformers/main/en/model_doc/mluke#transformers.MLukeTokenizer"),m(oO,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),m(rO,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),m(tO,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizer"),m(aO,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),m(nO,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),m(sO,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),m(lO,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizer"),m(iO,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizerFast"),m(dO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(mO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(cO,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizer"),m(fO,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizerFast"),m(gO,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),m(hO,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),m(uO,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),m(pO,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),m(_O,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),m(bO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(vO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(FO,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),m(TO,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),m(MO,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),m(EO,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),m(CO,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverTokenizer"),m(wO,"href","/docs/transformers/main/en/model_doc/phobert#transformers.PhobertTokenizer"),m(AO,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartTokenizer"),m(LO,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),m(yO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(xO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m($O,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagTokenizer"),m(kO,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizer"),m(SO,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizerFast"),m(RO,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizer"),m(PO,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizerFast"),m(BO,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizer"),m(IO,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizerFast"),m(NO,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizer"),m(qO,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),m(jO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),m(DO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),m(GO,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizer"),m(OO,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),m(VO,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),m(XO,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),m(zO,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizer"),m(QO,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizerFast"),m(WO,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),m(UO,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),m(HO,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),m(JO,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),m(YO,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasTokenizer"),m(ZO,"href","/docs/transformers/main/en/model_doc/tapex#transformers.TapexTokenizer"),m(KO,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),m(eV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(oV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(rV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),m(tV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),m(aV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),m(nV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),m(sV,"href","/docs/transformers/main/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),m(lV,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperTokenizer"),m(iV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),m(dV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),m(mV,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizer"),m(cV,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizerFast"),m(fV,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMTokenizer"),m(gV,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),m(hV,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),m(uV,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),m(pV,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),m(_V,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),m(bV,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizer"),m(vV,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),m(FV,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),m(TV,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),m(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(gp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(hp,"id","transformers.AutoFeatureExtractor"),m(hp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(hp,"href","#transformers.AutoFeatureExtractor"),m($d,"class","relative group"),m(MV,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),m(EV,"href","/docs/transformers/main/en/model_doc/beit#transformers.models.beit.image_processing_beit.BeitImageProcessor"),m(CV,"href","/docs/transformers/main/en/model_doc/clip#transformers.models.clip.image_processing_clip.CLIPImageProcessor"),m(wV,"href","/docs/transformers/main/en/model_doc/vit#transformers.models.vit.image_processing_vit.ViTImageProcessor"),m(AV,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrFeatureExtractor"),m(LV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor"),m(yV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor"),m(xV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m($V,"href","/docs/transformers/main/en/model_doc/beit#transformers.models.beit.image_processing_beit.BeitImageProcessor"),m(kV,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrFeatureExtractor"),m(SV,"href","/docs/transformers/main/en/model_doc/deit#transformers.models.deit.image_processing_deit.DeiTImageProcessor"),m(RV,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),m(PV,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutFeatureExtractor"),m(BV,"href","/docs/transformers/main/en/model_doc/dpt#transformers.models.dpt.image_processing_dpt.DPTImageProcessor"),m(IV,"href","/docs/transformers/main/en/model_doc/flava#transformers.models.flava.image_processing_flava.FlavaImageProcessor"),m(NV,"href","/docs/transformers/main/en/model_doc/glpn#transformers.models.glpn.image_processing_glpn.GLPNImageProcessor"),m(qV,"href","/docs/transformers/main/en/model_doc/clip#transformers.models.clip.image_processing_clip.CLIPImageProcessor"),m(jV,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(DV,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.models.imagegpt.image_processing_imagegpt.ImageGPTImageProcessor"),m(GV,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.models.layoutlmv2.image_processing_layoutlmv2.LayoutLMv2ImageProcessor"),m(OV,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.models.layoutlmv3.image_processing_layoutlmv3.LayoutLMv3ImageProcessor"),m(VV,"href","/docs/transformers/main/en/model_doc/levit#transformers.models.levit.image_processing_levit.LevitImageProcessor"),m(XV,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),m(zV,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),m(QV,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.models.mobilevit.image_processing_mobilevit.MobileViTImageProcessor"),m(WV,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),m(UV,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.models.perceiver.image_processing_perceiver.PerceiverImageProcessor"),m(HV,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.models.poolformer.image_processing_poolformer.PoolFormerImageProcessor"),m(JV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor"),m(YV,"href","/docs/transformers/main/en/model_doc/convnext#transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor"),m(ZV,"href","/docs/transformers/main/en/model_doc/segformer#transformers.models.segformer.image_processing_segformer.SegformerImageProcessor"),m(KV,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),m(eX,"href","/docs/transformers/main/en/model_doc/vit#transformers.models.vit.image_processing_vit.ViTImageProcessor"),m(oX,"href","/docs/transformers/main/en/model_doc/vit#transformers.models.vit.image_processing_vit.ViTImageProcessor"),m(rX,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),m(tX,"href","/docs/transformers/main/en/model_doc/convnext#transformers.models.convnext.image_processing_convnext.ConvNextImageProcessor"),m(aX,"href","/docs/transformers/main/en/model_doc/videomae#transformers.models.videomae.image_processing_videomae.VideoMAEImageProcessor"),m(nX,"href","/docs/transformers/main/en/model_doc/vilt#transformers.models.vilt.image_processing_vilt.ViltImageProcessor"),m(sX,"href","/docs/transformers/main/en/model_doc/vit#transformers.models.vit.image_processing_vit.ViTImageProcessor"),m(lX,"href","/docs/transformers/main/en/model_doc/vit#transformers.models.vit.image_processing_vit.ViTImageProcessor"),m(iX,"href","/docs/transformers/main/en/model_doc/vit#transformers.models.vit.image_processing_vit.ViTImageProcessor"),m(dX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(mX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),m(cX,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperFeatureExtractor"),m(fX,"href","/docs/transformers/main/en/model_doc/clip#transformers.models.clip.image_processing_clip.CLIPImageProcessor"),m(gX,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosFeatureExtractor"),m(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(i_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(d_,"id","transformers.AutoProcessor"),m(d_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(d_,"href","#transformers.AutoProcessor"),m(kd,"class","relative group"),m(hX,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),m(uX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),m(pX,"href","/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegProcessor"),m(_X,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaProcessor"),m(bX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),m(vX,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),m(FX,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),m(TX,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),m(MX,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMProcessor"),m(EX,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTProcessor"),m(CX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(wX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(AX,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),m(LX,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),m(yX,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRProcessor"),m(xX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m($X,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(kX,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltProcessor"),m(SX,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),m(RX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(PX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(BX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),m(IX,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperProcessor"),m(NX,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPProcessor"),m(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(B_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(I_,"id","transformers.AutoModel"),m(I_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(I_,"href","#transformers.AutoModel"),m(Rd,"class","relative group"),m(qX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(jX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(DX,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(GX,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel"),m(OX,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartModel"),m(VX,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitModel"),m(XX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),m(zX,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),m(QX,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel"),m(WX,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),m(UX,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel"),m(HX,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),m(JX,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel"),m(YX,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel"),m(ZX,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineModel"),m(KX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel"),m(ez,"href","/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegModel"),m(oz,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel"),m(rz,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel"),m(tz,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel"),m(az,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel"),m(nz,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel"),m(sz,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel"),m(lz,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel"),m(iz,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel"),m(dz,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel"),m(mz,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel"),m(cz,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model"),m(fz,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),m(gz,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel"),m(hz,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel"),m(uz,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrModel"),m(pz,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel"),m(_z,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel"),m(bz,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder"),m(vz,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel"),m(Fz,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel"),m(Tz,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel"),m(Mz,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmModel"),m(Ez,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel"),m(Cz,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel"),m(wz,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel"),m(Az,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel"),m(Lz,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel"),m(yz,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel"),m(xz,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel"),m($z,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model"),m(kz,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel"),m(Sz,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),m(Rz,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel"),m(Pz,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel"),m(Bz,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel"),m(Iz,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel"),m(Nz,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel"),m(qz,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel"),m(jz,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel"),m(Dz,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),m(Gz,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),m(Oz,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDModel"),m(Vz,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitModel"),m(Xz,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltModel"),m(zz,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel"),m(Qz,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model"),m(Wz,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeModel"),m(Uz,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel"),m(Hz,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),m(Jz,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianModel"),m(Yz,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel"),m(Zz,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel"),m(Kz,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel"),m(eQ,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel"),m(oQ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel"),m(rQ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel"),m(tQ,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel"),m(aQ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel"),m(nQ,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model"),m(sQ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel"),m(lQ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel"),m(iQ,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),m(dQ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel"),m(mQ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),m(cQ,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTModel"),m(fQ,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel"),m(gQ,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel"),m(hQ,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel"),m(uQ,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel"),m(pQ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel"),m(_Q,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel"),m(bQ,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel"),m(vQ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel"),m(FQ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel"),m(TQ,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel"),m(MQ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel"),m(EQ,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel"),m(CQ,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),m(wQ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel"),m(AQ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel"),m(LQ,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel"),m(yQ,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWModel"),m(xQ,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel"),m($Q,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel"),m(kQ,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel"),m(SQ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel"),m(RQ,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinModel"),m(PQ,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model"),m(BQ,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Model"),m(IQ,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerModel"),m(NQ,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel"),m(qQ,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel"),m(jQ,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),m(DQ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel"),m(GQ,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel"),m(OQ,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),m(VQ,"href","/docs/transformers/main/en/model_doc/van#transformers.VanModel"),m(XQ,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel"),m(zQ,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel"),m(QQ,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),m(WQ,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel"),m(UQ,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTModel"),m(HQ,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel"),m(JQ,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel"),m(YQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),m(ZQ,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),m(KQ,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel"),m(eW,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel"),m(oW,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel"),m(rW,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel"),m(tW,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel"),m(aW,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),m(nW,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),m(sW,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),m(lW,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel"),m(iW,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel"),m(dW,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel"),m(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(lb,"id","transformers.AutoModelForPreTraining"),m(lb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(lb,"href","#transformers.AutoModelForPreTraining"),m(Id,"class","relative group"),m(mW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(cW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(fW,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(gW,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining"),m(hW,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),m(uW,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining"),m(pW,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),m(_W,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),m(bW,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),m(vW,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),m(FW,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),m(TW,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),m(MW,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),m(EW,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),m(CW,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining"),m(wW,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining"),m(AW,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),m(LW,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining"),m(yW,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining"),m(xW,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),m($W,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining"),m(kW,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),m(SW,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),m(RW,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),m(PW,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),m(BW,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),m(IW,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining"),m(NW,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),m(qW,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),m(jW,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),m(DW,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),m(GW,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining"),m(OW,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),m(VW,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),m(XW,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),m(zW,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining"),m(QW,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),m(WW,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),m(UW,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),m(HW,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),m(JW,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),m(YW,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),m(ZW,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),m(KW,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),m(eU,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),m(oU,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),m(rU,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),m(tU,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),m(aU,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),m(nU,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),m(sU,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),m(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(nv,"id","transformers.AutoModelForCausalLM"),m(nv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(nv,"href","#transformers.AutoModelForCausalLM"),m(jd,"class","relative group"),m(lU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(iU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(dU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(mU,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM"),m(cU,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel"),m(fU,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),m(gU,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),m(hU,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),m(uU,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),m(pU,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),m(_U,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),m(bU,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM"),m(vU,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM"),m(FU,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),m(TU,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),m(MU,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM"),m(EU,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM"),m(CU,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),m(wU,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),m(AU,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),m(LU,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM"),m(yU,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM"),m(xU,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM"),m($U,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM"),m(kU,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),m(SU,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM"),m(RU,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),m(PU,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM"),m(BU,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM"),m(IU,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM"),m(NU,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),m(qU,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),m(jU,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),m(DU,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM"),m(GU,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM"),m(OU,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM"),m(VU,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),m(XU,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),m(zU,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM"),m(QU,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM"),m(WU,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),m(UU,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),m(HU,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),m(JU,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),m(YU,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),m(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Yv,"id","transformers.AutoModelForDepthEstimation"),m(Yv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Yv,"href","#transformers.AutoModelForDepthEstimation"),m(Od,"class","relative group"),m(ZU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(KU,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(eH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(oH,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForDepthEstimation"),m(rH,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNForDepthEstimation"),m(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(tF,"id","transformers.AutoModelForMaskedLM"),m(tF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(tF,"href","#transformers.AutoModelForMaskedLM"),m(zd,"class","relative group"),m(tH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(aH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(nH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(sH,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM"),m(lH,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),m(iH,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM"),m(dH,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),m(mH,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),m(cH,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),m(fH,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),m(gH,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),m(hH,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),m(uH,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),m(pH,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM"),m(_H,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM"),m(bH,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),m(vH,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM"),m(FH,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM"),m(TH,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),m(MH,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),m(EH,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),m(CH,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),m(wH,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),m(AH,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),m(LH,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),m(yH,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),m(xH,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),m($H,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM"),m(kH,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),m(SH,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),m(RH,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),m(PH,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM"),m(BH,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM"),m(IH,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),m(NH,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),m(qH,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),m(jH,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),m(DH,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),m(GH,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),m(OH,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),m(VH,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM"),m(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(QF,"id","transformers.AutoModelForSeq2SeqLM"),m(QF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(QF,"href","#transformers.AutoModelForSeq2SeqLM"),m(Ud,"class","relative group"),m(XH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(zH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(QH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(WH,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),m(UH,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),m(HH,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),m(JH,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),m(YH,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),m(ZH,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),m(KH,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration"),m(eJ,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),m(oJ,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),m(rJ,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel"),m(tJ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),m(aJ,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),m(nJ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),m(sJ,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),m(lJ,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),m(iJ,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration"),m(dJ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),m(mJ,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),m(cJ,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),m(fJ,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),m(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(pT,"id","transformers.AutoModelForSequenceClassification"),m(pT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(pT,"href","#transformers.AutoModelForSequenceClassification"),m(Yd,"class","relative group"),m(gJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(hJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(uJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(pJ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification"),m(_J,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification"),m(bJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification"),m(vJ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),m(FJ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),m(TJ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification"),m(MJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),m(EJ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification"),m(CJ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),m(wJ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),m(AJ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),m(LJ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),m(yJ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),m(xJ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),m($J,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification"),m(kJ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification"),m(SJ,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification"),m(RJ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),m(PJ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification"),m(BJ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),m(IJ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),m(NJ,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),m(qJ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),m(jJ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification"),m(DJ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),m(GJ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),m(OJ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),m(VJ,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification"),m(XJ,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForSequenceClassification"),m(zJ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),m(QJ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification"),m(WJ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification"),m(UJ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification"),m(HJ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),m(JJ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),m(YJ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),m(ZJ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification"),m(KJ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),m(eY,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),m(oY,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),m(rY,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification"),m(tY,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),m(aY,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),m(nY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),m(sY,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),m(lY,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),m(iY,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),m(dY,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),m(mY,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),m(cY,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification"),m(fY,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),m(gY,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification"),m(hY,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),m(uY,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),m(pY,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),m(_Y,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification"),m(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(MM,"id","transformers.AutoModelForMultipleChoice"),m(MM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(MM,"href","#transformers.AutoModelForMultipleChoice"),m(em,"class","relative group"),m(bY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(vY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(FY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(TY,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice"),m(MY,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice"),m(EY,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),m(CY,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),m(wY,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice"),m(AY,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),m(LY,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),m(yY,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),m(xY,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),m($Y,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice"),m(kY,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice"),m(SY,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),m(RY,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice"),m(PY,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),m(BY,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice"),m(IY,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),m(NY,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice"),m(qY,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),m(jY,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),m(DY,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),m(GY,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),m(OY,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),m(VY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),m(XY,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),m(zY,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),m(QY,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),m(WY,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),m(UY,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice"),m(HY,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),m(JY,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),m(YY,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),m(ZY,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice"),m(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(aE,"id","transformers.AutoModelForNextSentencePrediction"),m(aE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(aE,"href","#transformers.AutoModelForNextSentencePrediction"),m(tm,"class","relative group"),m(KY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(eZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(oZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(rZ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction"),m(tZ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction"),m(aZ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),m(nZ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),m(sZ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),m(lZ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),m(iZ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),m(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(uE,"id","transformers.AutoModelForTokenClassification"),m(uE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(uE,"href","#transformers.AutoModelForTokenClassification"),m(sm,"class","relative group"),m(dZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(mZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(cZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(fZ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification"),m(gZ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification"),m(hZ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),m(uZ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification"),m(pZ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification"),m(_Z,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification"),m(bZ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),m(vZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),m(FZ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification"),m(TZ,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),m(MZ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),m(EZ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification"),m(CZ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification"),m(wZ,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification"),m(AZ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),m(LZ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification"),m(yZ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification"),m(xZ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),m($Z,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification"),m(kZ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),m(SZ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),m(RZ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),m(PZ,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForTokenClassification"),m(BZ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification"),m(IZ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification"),m(NZ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification"),m(qZ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),m(jZ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),m(DZ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),m(GZ,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification"),m(OZ,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),m(VZ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),m(XZ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification"),m(zZ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification"),m(QZ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),m(WZ,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),m(UZ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification"),m(HZ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),m(JZ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),m(YZ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),m(ZZ,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification"),m(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(s4,"id","transformers.AutoModelForQuestionAnswering"),m(s4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(s4,"href","#transformers.AutoModelForQuestionAnswering"),m(dm,"class","relative group"),m(KZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(eK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(oK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(rK,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),m(tK,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering"),m(aK,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering"),m(nK,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),m(sK,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),m(lK,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering"),m(iK,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),m(dK,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering"),m(mK,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),m(cK,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),m(fK,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),m(gK,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),m(hK,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),m(uK,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),m(pK,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering"),m(_K,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),m(bK,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),m(vK,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),m(FK,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),m(TK,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),m(MK,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),m(EK,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),m(CK,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering"),m(wK,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForQuestionAnswering"),m(AK,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),m(LK,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering"),m(yK,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),m(xK,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering"),m($K,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),m(kK,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),m(SK,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),m(RK,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),m(PK,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),m(BK,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),m(IK,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),m(NK,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering"),m(qK,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),m(jK,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),m(DK,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),m(GK,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),m(OK,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),m(VK,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),m(XK,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),m(zK,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),m(QK,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),m(WK,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),m(UK,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),m(HK,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),m(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(aC,"id","transformers.AutoModelForTableQuestionAnswering"),m(aC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(aC,"href","#transformers.AutoModelForTableQuestionAnswering"),m(fm,"class","relative group"),m(JK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(YK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(ZK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(KK,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),m(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(dC,"id","transformers.AutoModelForDocumentQuestionAnswering"),m(dC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(dC,"href","#transformers.AutoModelForDocumentQuestionAnswering"),m(um,"class","relative group"),m(eee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(oee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(ree,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(tee,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering"),m(aee,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),m(nee,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),m(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(pC,"id","transformers.AutoModelForImageClassification"),m(pC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(pC,"href","#transformers.AutoModelForImageClassification"),m(vm,"class","relative group"),m(see,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(lee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(iee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(dee,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification"),m(mee,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification"),m(cee,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification"),m(fee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),m(gee,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification"),m(hee,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),m(uee,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),m(pee,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification"),m(_ee,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),m(bee,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),m(vee,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),m(Fee,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),m(Tee,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),m(Mee,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),m(Eee,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification"),m(Cee,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification"),m(wee,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification"),m(Aee,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification"),m(Lee,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),m(yee,"href","/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification"),m(xee,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification"),m($ee,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification"),m(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(BC,"id","transformers.AutoModelForVideoClassification"),m(BC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(BC,"href","#transformers.AutoModelForVideoClassification"),m(Mm,"class","relative group"),m(kee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(See,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Ree,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Pee,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),m(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(DC,"id","transformers.AutoModelForVision2Seq"),m(DC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(DC,"href","#transformers.AutoModelForVision2Seq"),m(wm,"class","relative group"),m(Bee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Iee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Nee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(qee,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),m(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(zC,"id","transformers.AutoModelForVisualQuestionAnswering"),m(zC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(zC,"href","#transformers.AutoModelForVisualQuestionAnswering"),m(ym,"class","relative group"),m(jee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Dee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Gee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Oee,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),m(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(JC,"id","transformers.AutoModelForAudioClassification"),m(JC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(JC,"href","#transformers.AutoModelForAudioClassification"),m(km,"class","relative group"),m(Vee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Xee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(zee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Qee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),m(Wee,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification"),m(Uee,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification"),m(Hee,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),m(Jee,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),m(Yee,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),m(Zee,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),m(Kee,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),m(eoe,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),m(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(d3,"id","transformers.AutoModelForAudioFrameClassification"),m(d3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(d3,"href","#transformers.AutoModelForAudioFrameClassification"),m(Pm,"class","relative group"),m(ooe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(roe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(toe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(aoe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),m(noe,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),m(soe,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),m(loe,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),m(ioe,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),m(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(b3,"id","transformers.AutoModelForCTC"),m(b3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(b3,"href","#transformers.AutoModelForCTC"),m(Nm,"class","relative group"),m(doe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(moe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(coe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(foe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),m(goe,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC"),m(hoe,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC"),m(uoe,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC"),m(poe,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC"),m(_oe,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC"),m(boe,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),m(voe,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),m(Foe,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),m(Toe,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC"),m(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(S3,"id","transformers.AutoModelForSpeechSeq2Seq"),m(S3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(S3,"href","#transformers.AutoModelForSpeechSeq2Seq"),m(Dm,"class","relative group"),m(Moe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Eoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Coe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(woe,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),m(Aoe,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),m(Loe,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration"),m(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(j3,"id","transformers.AutoModelForAudioXVector"),m(j3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(j3,"href","#transformers.AutoModelForAudioXVector"),m(Xm,"class","relative group"),m(yoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(xoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m($oe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(koe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),m(Soe,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),m(Roe,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),m(Poe,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),m(Boe,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector"),m(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(U3,"id","transformers.AutoModelForMaskedImageModeling"),m(U3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(U3,"href","#transformers.AutoModelForMaskedImageModeling"),m(Wm,"class","relative group"),m(Ioe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Noe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(qoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(joe,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),m(Doe,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),m(Goe,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),m(Ooe,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),m(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(r5,"id","transformers.AutoModelForObjectDetection"),m(r5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(r5,"href","#transformers.AutoModelForObjectDetection"),m(Jm,"class","relative group"),m(Voe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Xoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(zoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Qoe,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection"),m(Woe,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection"),m(Uoe,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection"),m(Hoe,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection"),m(Joe,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection"),m(Eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(c5,"id","transformers.AutoModelForImageSegmentation"),m(c5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(c5,"href","#transformers.AutoModelForImageSegmentation"),m(Km,"class","relative group"),m(Yoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Zoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Koe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ere,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation"),m(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(p5,"id","transformers.AutoModelForSemanticSegmentation"),m(p5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(p5,"href","#transformers.AutoModelForSemanticSegmentation"),m(rc,"class","relative group"),m(ore,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(rre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(tre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(are,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),m(nre,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),m(sre,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),m(lre,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),m(ire,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),m(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(w5,"id","transformers.AutoModelForInstanceSegmentation"),m(w5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(w5,"href","#transformers.AutoModelForInstanceSegmentation"),m(nc,"class","relative group"),m(dre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(mre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(cre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(fre,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),m(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($5,"id","transformers.AutoModelForZeroShotObjectDetection"),m($5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m($5,"href","#transformers.AutoModelForZeroShotObjectDetection"),m(ic,"class","relative group"),m(gre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(hre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(ure,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(pre,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection"),m(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(B5,"id","transformers.TFAutoModel"),m(B5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(B5,"href","#transformers.TFAutoModel"),m(cc,"class","relative group"),m(_re,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(bre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(vre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Fre,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel"),m(Tre,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel"),m(Mre,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel"),m(Ere,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),m(Cre,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),m(wre,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel"),m(Are,"href","/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel"),m(Lre,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel"),m(yre,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel"),m(xre,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel"),m($re,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel"),m(kre,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),m(Sre,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel"),m(Rre,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),m(Pre,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel"),m(Bre,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel"),m(Ire,"href","/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),m(Nre,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel"),m(qre,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmModel"),m(jre,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel"),m(Dre,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel"),m(Gre,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel"),m(Ore,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model"),m(Vre,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel"),m(Xre,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel"),m(zre,"href","/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel"),m(Qre,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),m(Wre,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model"),m(Ure,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel"),m(Hre,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel"),m(Jre,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel"),m(Yre,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel"),m(Zre,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel"),m(Kre,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel"),m(ete,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel"),m(ote,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel"),m(rte,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model"),m(tte,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),m(ate,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel"),m(nte,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel"),m(ste,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel"),m(lte,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel"),m(ite,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel"),m(dte,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel"),m(mte,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel"),m(cte,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel"),m(fte,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),m(gte,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel"),m(hte,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model"),m(ute,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel"),m(pte,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),m(_te,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel"),m(bte,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel"),m(vte,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),m(Fte,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel"),m(Tte,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel"),m(Mte,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel"),m(Ete,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),m(Cte,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel"),m(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(G0,"id","transformers.TFAutoModelForPreTraining"),m(G0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(G0,"href","#transformers.TFAutoModelForPreTraining"),m(hc,"class","relative group"),m(wte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ate,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Lte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(yte,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining"),m(xte,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),m($te,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining"),m(kte,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),m(Ste,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),m(Rte,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),m(Pte,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining"),m(Bte,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),m(Ite,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),m(Nte,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),m(qte,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),m(jte,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),m(Dte,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),m(Gte,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),m(Ote,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),m(Vte,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),m(Xte,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),m(zte,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),m(Qte,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),m(Wte,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),m(Ute,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),m(Hte,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),m(Jte,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),m(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(gw,"id","transformers.TFAutoModelForCausalLM"),m(gw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(gw,"href","#transformers.TFAutoModelForCausalLM"),m(_c,"class","relative group"),m(Yte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Zte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Kte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(eae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel"),m(oae,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),m(rae,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),m(tae,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),m(aae,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),m(nae,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),m(sae,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM"),m(lae,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),m(iae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),m(dae,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),m(mae,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),m(cae,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM"),m(fae,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),m(gae,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),m(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($w,"id","transformers.TFAutoModelForImageClassification"),m($w,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m($w,"href","#transformers.TFAutoModelForImageClassification"),m(Fc,"class","relative group"),m(hae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(uae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(pae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_ae,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),m(bae,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification"),m(vae,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),m(Fae,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification"),m(Tae,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),m(Mae,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification"),m(Eae,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),m(Cae,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification"),m(wae,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),m(Aae,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification"),m(Lae,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification"),m(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ow,"id","transformers.TFAutoModelForSemanticSegmentation"),m(Ow,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Ow,"href","#transformers.TFAutoModelForSemanticSegmentation"),m(Ec,"class","relative group"),m(yae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(xae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m($ae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(kae,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation"),m(Sae,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation"),m(Rae,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation"),m(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Uw,"id","transformers.TFAutoModelForMaskedLM"),m(Uw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Uw,"href","#transformers.TFAutoModelForMaskedLM"),m(Lc,"class","relative group"),m(Pae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Bae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Iae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Nae,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),m(qae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM"),m(jae,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),m(Dae,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),m(Gae,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),m(Oae,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),m(Vae,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),m(Xae,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM"),m(zae,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForMaskedLM"),m(Qae,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),m(Wae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),m(Uae,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),m(Hae,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),m(Jae,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),m(Yae,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),m(Zae,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),m(Kae,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),m(ene,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),m(one,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),m(rne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),m(tne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),m(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(bA,"id","transformers.TFAutoModelForSeq2SeqLM"),m(bA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(bA,"href","#transformers.TFAutoModelForSeq2SeqLM"),m($c,"class","relative group"),m(ane,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(nne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(sne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(lne,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),m(ine,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),m(dne,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),m(mne,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),m(cne,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),m(fne,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel"),m(gne,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),m(hne,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),m(une,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),m(pne,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),m(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(kA,"id","transformers.TFAutoModelForSequenceClassification"),m(kA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(kA,"href","#transformers.TFAutoModelForSequenceClassification"),m(Rc,"class","relative group"),m(_ne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(bne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(vne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Fne,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),m(Tne,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification"),m(Mne,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),m(Ene,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),m(Cne,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),m(wne,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),m(Ane,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),m(Lne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),m(yne,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),m(xne,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForSequenceClassification"),m($ne,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),m(kne,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),m(Sne,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),m(Rne,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),m(Pne,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),m(Bne,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification"),m(Ine,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),m(Nne,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),m(qne,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),m(jne,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),m(Dne,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),m(Gne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),m(One,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),m(Vne,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),m(Xne,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),m(zne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),m(Qne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),m(Wne,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),m(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(i6,"id","transformers.TFAutoModelForMultipleChoice"),m(i6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(i6,"href","#transformers.TFAutoModelForMultipleChoice"),m(Ic,"class","relative group"),m(Une,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Hne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Jne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Yne,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),m(Zne,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice"),m(Kne,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),m(ese,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),m(ose,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),m(rse,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),m(tse,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),m(ase,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),m(nse,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),m(sse,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),m(lse,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),m(ise,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),m(dse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),m(mse,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),m(cse,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),m(fse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),m(gse,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),m(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(y6,"id","transformers.TFAutoModelForNextSentencePrediction"),m(y6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(y6,"href","#transformers.TFAutoModelForNextSentencePrediction"),m(jc,"class","relative group"),m(hse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(use,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(pse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(_se,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),m(bse,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),m(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(R6,"id","transformers.TFAutoModelForTableQuestionAnswering"),m(R6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(R6,"href","#transformers.TFAutoModelForTableQuestionAnswering"),m(Oc,"class","relative group"),m(vse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Fse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Tse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Mse,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),m(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(N6,"id","transformers.TFAutoModelForDocumentQuestionAnswering"),m(N6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(N6,"href","#transformers.TFAutoModelForDocumentQuestionAnswering"),m(zc,"class","relative group"),m(Ese,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Cse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(wse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ia,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ase,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering"),m(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(G6,"id","transformers.TFAutoModelForTokenClassification"),m(G6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(G6,"href","#transformers.TFAutoModelForTokenClassification"),m(Uc,"class","relative group"),m(Lse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(yse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(xse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(da,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($se,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),m(kse,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification"),m(Sse,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),m(Rse,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),m(Pse,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),m(Bse,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),m(Ise,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),m(Nse,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification"),m(qse,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForTokenClassification"),m(jse,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),m(Dse,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),m(Gse,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),m(Ose,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification"),m(Vse,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),m(Xse,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),m(zse,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),m(Qse,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),m(Wse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),m(Use,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),m(Hse,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),m(Jse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),m(Yse,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),m(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(f7,"id","transformers.TFAutoModelForQuestionAnswering"),m(f7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(f7,"href","#transformers.TFAutoModelForQuestionAnswering"),m(Yc,"class","relative group"),m(Zse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Kse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(ele,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ole,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),m(rle,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),m(tle,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),m(ale,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),m(nle,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),m(sle,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),m(lle,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),m(ile,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),m(dle,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),m(mle,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),m(cle,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),m(fle,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering"),m(gle,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),m(hle,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),m(ule,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),m(ple,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),m(_le,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),m(ble,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),m(vle,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),m(Fle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),m(Tle,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),m(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(I7,"id","transformers.TFAutoModelForVision2Seq"),m(I7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(I7,"href","#transformers.TFAutoModelForVision2Seq"),m(ef,"class","relative group"),m(Mle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ele,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Cle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(wle,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),m(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(D7,"id","transformers.TFAutoModelForSpeechSeq2Seq"),m(D7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(D7,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),m(tf,"class","relative group"),m(Ale,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Lle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(yle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(xle,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),m($le,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration"),m(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(z7,"id","transformers.FlaxAutoModel"),m(z7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(z7,"href","#transformers.FlaxAutoModel"),m(sf,"class","relative group"),m(kle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Sle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Rle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ga,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ple,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel"),m(Ble,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel"),m(Ile,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel"),m(Nle,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel"),m(qle,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),m(jle,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),m(Dle,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),m(Gle,"href","/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel"),m(Ole,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),m(Vle,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel"),m(Xle,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model"),m(zle,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),m(Qle,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel"),m(Wle,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model"),m(Ule,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel"),m(Hle,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel"),m(Jle,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model"),m(Yle,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel"),m(Zle,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel"),m(Kle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel"),m(eie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel"),m(oie,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model"),m(rie,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),m(tie,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel"),m(aie,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),m(nie,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel"),m(sie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),m(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(T8,"id","transformers.FlaxAutoModelForCausalLM"),m(T8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(T8,"href","#transformers.FlaxAutoModelForCausalLM"),m(mf,"class","relative group"),m(lie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(iie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(die,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ha,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(mie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM"),m(cie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM"),m(fie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),m(gie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),m(hie,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),m(uie,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),m(pie,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),m(_ie,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),m(bie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),m(vie,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),m(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(P8,"id","transformers.FlaxAutoModelForPreTraining"),m(P8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(P8,"href","#transformers.FlaxAutoModelForPreTraining"),m(gf,"class","relative group"),m(Fie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Tie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Mie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ua,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Eie,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),m(Cie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),m(wie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining"),m(Aie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),m(Lie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),m(yie,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),m(xie,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),m($ie,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),m(kie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),m(Sie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),m(Rie,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),m(Pie,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),m(Bie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),m(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(J8,"id","transformers.FlaxAutoModelForMaskedLM"),m(J8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(J8,"href","#transformers.FlaxAutoModelForMaskedLM"),m(pf,"class","relative group"),m(Iie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Nie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(qie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(pa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(jie,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),m(Die,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),m(Gie,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),m(Oie,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),m(Vie,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),m(Xie,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),m(zie,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),m(Qie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),m(Wie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),m(Uie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),m(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(dL,"id","transformers.FlaxAutoModelForSeq2SeqLM"),m(dL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(dL,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),m(vf,"class","relative group"),m(Hie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Jie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Yie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(_a,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Zie,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),m(Kie,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),m(ede,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),m(ode,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),m(rde,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),m(tde,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel"),m(ade,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),m(nde,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),m(sde,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),m(lde,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),m(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ML,"id","transformers.FlaxAutoModelForSequenceClassification"),m(ML,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ML,"href","#transformers.FlaxAutoModelForSequenceClassification"),m(Mf,"class","relative group"),m(ide,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(dde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(mde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(ba,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(cde,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),m(fde,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),m(gde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),m(hde,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),m(ude,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),m(pde,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),m(_de,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),m(bde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),m(vde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),m(Fde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),m(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(BL,"id","transformers.FlaxAutoModelForQuestionAnswering"),m(BL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(BL,"href","#transformers.FlaxAutoModelForQuestionAnswering"),m(wf,"class","relative group"),m(Tde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Mde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Ede,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(va,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Cde,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),m(wde,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),m(Ade,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),m(Lde,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),m(yde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),m(xde,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),m($de,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),m(kde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),m(Sde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),m(Rde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),m(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(UL,"id","transformers.FlaxAutoModelForTokenClassification"),m(UL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(UL,"href","#transformers.FlaxAutoModelForTokenClassification"),m(yf,"class","relative group"),m(Pde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Bde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Ide,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Nde,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),m(qde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),m(jde,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),m(Dde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),m(Gde,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),m(Ode,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),m(Vde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),m(Xde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),m(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(ny,"id","transformers.FlaxAutoModelForMultipleChoice"),m(ny,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ny,"href","#transformers.FlaxAutoModelForMultipleChoice"),m(kf,"class","relative group"),m(zde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Qde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(Wde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ude,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),m(Hde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),m(Jde,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),m(Yde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),m(Zde,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),m(Kde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),m(eme,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),m(ome,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),m(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(py,"id","transformers.FlaxAutoModelForNextSentencePrediction"),m(py,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(py,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),m(Pf,"class","relative group"),m(rme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(tme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(ame,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(nme,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),m(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Fy,"id","transformers.FlaxAutoModelForImageClassification"),m(Fy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Fy,"href","#transformers.FlaxAutoModelForImageClassification"),m(Nf,"class","relative group"),m(sme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(lme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(ime,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(dme,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),m(mme,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification"),m(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(wy,"id","transformers.FlaxAutoModelForVision2Seq"),m(wy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(wy,"href","#transformers.FlaxAutoModelForVision2Seq"),m(Df,"class","relative group"),m(cme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(fme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),m(gme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),m(Ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(hme,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),m(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),m(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(c,_){e(document.head,g),b(c,v,_),b(c,u,_),e(u,f),e(f,p),M(d,p,null),e(u,h),e(u,$o),e($o,vd),b(c,Qf,_),b(c,Tt,_),e(Tt,Fd),e(Tt,Td),e(Td,m$),e(Tt,Wf),b(c,Xe,_),b(c,He,_),e(He,Md),e(He,ms),e(ms,c$),e(He,cs),e(He,fs),e(fs,f$),e(He,Ed),e(He,gs),e(gs,g$),e(He,Cd),b(c,Uf,_),M(on,c,_),b(c,Je,_),b(c,Ae,_),e(Ae,yN),e(Ae,wd),e(wd,xN),e(Ae,$N),b(c,ko,_),b(c,rn,_),e(rn,kN),e(rn,Hf),e(Hf,SN),e(rn,kio),b(c,Qto,_),b(c,Ad,_),e(Ad,Jf),e(Jf,Efe),M(h$,Efe,null),e(Ad,Sio),e(Ad,Cfe),e(Cfe,Rio),b(c,Wto,_),b(c,hs,_),e(hs,Pio),e(hs,wfe),e(wfe,Bio),e(hs,Iio),e(hs,Afe),e(Afe,Nio),e(hs,qio),b(c,Uto,_),M(u$,c,_),b(c,Hto,_),b(c,RN,_),e(RN,jio),b(c,Jto,_),M(Yf,c,_),b(c,Yto,_),b(c,Ld,_),e(Ld,Zf),e(Zf,Lfe),M(p$,Lfe,null),e(Ld,Dio),e(Ld,yfe),e(yfe,Gio),b(c,Zto,_),b(c,So,_),M(_$,So,null),e(So,Oio),e(So,b$),e(b$,Vio),e(b$,PN),e(PN,Xio),e(b$,zio),e(So,Qio),e(So,v$),e(v$,Wio),e(v$,xfe),e(xfe,Uio),e(v$,Hio),e(So,Jio),e(So,qr),M(F$,qr,null),e(qr,Yio),e(qr,$fe),e($fe,Zio),e(qr,Kio),e(qr,yd),e(yd,edo),e(yd,kfe),e(kfe,odo),e(yd,rdo),e(yd,Sfe),e(Sfe,tdo),e(yd,ado),e(qr,ndo),e(qr,A),e(A,Kf),e(Kf,Rfe),e(Rfe,sdo),e(Kf,ldo),e(Kf,BN),e(BN,ido),e(Kf,ddo),e(A,mdo),e(A,eg),e(eg,Pfe),e(Pfe,cdo),e(eg,fdo),e(eg,IN),e(IN,gdo),e(eg,hdo),e(A,udo),e(A,og),e(og,Bfe),e(Bfe,pdo),e(og,_do),e(og,NN),e(NN,bdo),e(og,vdo),e(A,Fdo),e(A,rg),e(rg,Ife),e(Ife,Tdo),e(rg,Mdo),e(rg,qN),e(qN,Edo),e(rg,Cdo),e(A,wdo),e(A,tg),e(tg,Nfe),e(Nfe,Ado),e(tg,Ldo),e(tg,jN),e(jN,ydo),e(tg,xdo),e(A,$do),e(A,ag),e(ag,qfe),e(qfe,kdo),e(ag,Sdo),e(ag,DN),e(DN,Rdo),e(ag,Pdo),e(A,Bdo),e(A,ng),e(ng,jfe),e(jfe,Ido),e(ng,Ndo),e(ng,GN),e(GN,qdo),e(ng,jdo),e(A,Ddo),e(A,sg),e(sg,Dfe),e(Dfe,Gdo),e(sg,Odo),e(sg,ON),e(ON,Vdo),e(sg,Xdo),e(A,zdo),e(A,lg),e(lg,Gfe),e(Gfe,Qdo),e(lg,Wdo),e(lg,VN),e(VN,Udo),e(lg,Hdo),e(A,Jdo),e(A,ig),e(ig,Ofe),e(Ofe,Ydo),e(ig,Zdo),e(ig,XN),e(XN,Kdo),e(ig,emo),e(A,omo),e(A,dg),e(dg,Vfe),e(Vfe,rmo),e(dg,tmo),e(dg,zN),e(zN,amo),e(dg,nmo),e(A,smo),e(A,mg),e(mg,Xfe),e(Xfe,lmo),e(mg,imo),e(mg,QN),e(QN,dmo),e(mg,mmo),e(A,cmo),e(A,cg),e(cg,zfe),e(zfe,fmo),e(cg,gmo),e(cg,WN),e(WN,hmo),e(cg,umo),e(A,pmo),e(A,fg),e(fg,Qfe),e(Qfe,_mo),e(fg,bmo),e(fg,UN),e(UN,vmo),e(fg,Fmo),e(A,Tmo),e(A,gg),e(gg,Wfe),e(Wfe,Mmo),e(gg,Emo),e(gg,HN),e(HN,Cmo),e(gg,wmo),e(A,Amo),e(A,hg),e(hg,Ufe),e(Ufe,Lmo),e(hg,ymo),e(hg,JN),e(JN,xmo),e(hg,$mo),e(A,kmo),e(A,ug),e(ug,Hfe),e(Hfe,Smo),e(ug,Rmo),e(ug,YN),e(YN,Pmo),e(ug,Bmo),e(A,Imo),e(A,pg),e(pg,Jfe),e(Jfe,Nmo),e(pg,qmo),e(pg,ZN),e(ZN,jmo),e(pg,Dmo),e(A,Gmo),e(A,_g),e(_g,Yfe),e(Yfe,Omo),e(_g,Vmo),e(_g,KN),e(KN,Xmo),e(_g,zmo),e(A,Qmo),e(A,bg),e(bg,Zfe),e(Zfe,Wmo),e(bg,Umo),e(bg,eq),e(eq,Hmo),e(bg,Jmo),e(A,Ymo),e(A,vg),e(vg,Kfe),e(Kfe,Zmo),e(vg,Kmo),e(vg,oq),e(oq,eco),e(vg,oco),e(A,rco),e(A,Fg),e(Fg,ege),e(ege,tco),e(Fg,aco),e(Fg,rq),e(rq,nco),e(Fg,sco),e(A,lco),e(A,Tg),e(Tg,oge),e(oge,ico),e(Tg,dco),e(Tg,tq),e(tq,mco),e(Tg,cco),e(A,fco),e(A,Mg),e(Mg,rge),e(rge,gco),e(Mg,hco),e(Mg,aq),e(aq,uco),e(Mg,pco),e(A,_co),e(A,Eg),e(Eg,tge),e(tge,bco),e(Eg,vco),e(Eg,nq),e(nq,Fco),e(Eg,Tco),e(A,Mco),e(A,Cg),e(Cg,age),e(age,Eco),e(Cg,Cco),e(Cg,sq),e(sq,wco),e(Cg,Aco),e(A,Lco),e(A,wg),e(wg,nge),e(nge,yco),e(wg,xco),e(wg,lq),e(lq,$co),e(wg,kco),e(A,Sco),e(A,Ag),e(Ag,sge),e(sge,Rco),e(Ag,Pco),e(Ag,iq),e(iq,Bco),e(Ag,Ico),e(A,Nco),e(A,Lg),e(Lg,lge),e(lge,qco),e(Lg,jco),e(Lg,dq),e(dq,Dco),e(Lg,Gco),e(A,Oco),e(A,yg),e(yg,ige),e(ige,Vco),e(yg,Xco),e(yg,mq),e(mq,zco),e(yg,Qco),e(A,Wco),e(A,xg),e(xg,dge),e(dge,Uco),e(xg,Hco),e(xg,cq),e(cq,Jco),e(xg,Yco),e(A,Zco),e(A,$g),e($g,mge),e(mge,Kco),e($g,efo),e($g,fq),e(fq,ofo),e($g,rfo),e(A,tfo),e(A,kg),e(kg,cge),e(cge,afo),e(kg,nfo),e(kg,gq),e(gq,sfo),e(kg,lfo),e(A,ifo),e(A,Sg),e(Sg,fge),e(fge,dfo),e(Sg,mfo),e(Sg,hq),e(hq,cfo),e(Sg,ffo),e(A,gfo),e(A,Rg),e(Rg,gge),e(gge,hfo),e(Rg,ufo),e(Rg,uq),e(uq,pfo),e(Rg,_fo),e(A,bfo),e(A,Pg),e(Pg,hge),e(hge,vfo),e(Pg,Ffo),e(Pg,pq),e(pq,Tfo),e(Pg,Mfo),e(A,Efo),e(A,Bg),e(Bg,uge),e(uge,Cfo),e(Bg,wfo),e(Bg,_q),e(_q,Afo),e(Bg,Lfo),e(A,yfo),e(A,Ig),e(Ig,pge),e(pge,xfo),e(Ig,$fo),e(Ig,bq),e(bq,kfo),e(Ig,Sfo),e(A,Rfo),e(A,Ng),e(Ng,_ge),e(_ge,Pfo),e(Ng,Bfo),e(Ng,vq),e(vq,Ifo),e(Ng,Nfo),e(A,qfo),e(A,qg),e(qg,bge),e(bge,jfo),e(qg,Dfo),e(qg,Fq),e(Fq,Gfo),e(qg,Ofo),e(A,Vfo),e(A,jg),e(jg,vge),e(vge,Xfo),e(jg,zfo),e(jg,Tq),e(Tq,Qfo),e(jg,Wfo),e(A,Ufo),e(A,Dg),e(Dg,Fge),e(Fge,Hfo),e(Dg,Jfo),e(Dg,Mq),e(Mq,Yfo),e(Dg,Zfo),e(A,Kfo),e(A,Gg),e(Gg,Tge),e(Tge,ego),e(Gg,ogo),e(Gg,Eq),e(Eq,rgo),e(Gg,tgo),e(A,ago),e(A,Og),e(Og,Mge),e(Mge,ngo),e(Og,sgo),e(Og,Cq),e(Cq,lgo),e(Og,igo),e(A,dgo),e(A,Vg),e(Vg,Ege),e(Ege,mgo),e(Vg,cgo),e(Vg,wq),e(wq,fgo),e(Vg,ggo),e(A,hgo),e(A,Xg),e(Xg,Cge),e(Cge,ugo),e(Xg,pgo),e(Xg,Aq),e(Aq,_go),e(Xg,bgo),e(A,vgo),e(A,zg),e(zg,wge),e(wge,Fgo),e(zg,Tgo),e(zg,Lq),e(Lq,Mgo),e(zg,Ego),e(A,Cgo),e(A,Qg),e(Qg,Age),e(Age,wgo),e(Qg,Ago),e(Qg,yq),e(yq,Lgo),e(Qg,ygo),e(A,xgo),e(A,Wg),e(Wg,Lge),e(Lge,$go),e(Wg,kgo),e(Wg,xq),e(xq,Sgo),e(Wg,Rgo),e(A,Pgo),e(A,Ug),e(Ug,yge),e(yge,Bgo),e(Ug,Igo),e(Ug,$q),e($q,Ngo),e(Ug,qgo),e(A,jgo),e(A,Hg),e(Hg,xge),e(xge,Dgo),e(Hg,Ggo),e(Hg,kq),e(kq,Ogo),e(Hg,Vgo),e(A,Xgo),e(A,Jg),e(Jg,$ge),e($ge,zgo),e(Jg,Qgo),e(Jg,Sq),e(Sq,Wgo),e(Jg,Ugo),e(A,Hgo),e(A,Yg),e(Yg,kge),e(kge,Jgo),e(Yg,Ygo),e(Yg,Rq),e(Rq,Zgo),e(Yg,Kgo),e(A,eho),e(A,Zg),e(Zg,Sge),e(Sge,oho),e(Zg,rho),e(Zg,Pq),e(Pq,tho),e(Zg,aho),e(A,nho),e(A,Kg),e(Kg,Rge),e(Rge,sho),e(Kg,lho),e(Kg,Bq),e(Bq,iho),e(Kg,dho),e(A,mho),e(A,eh),e(eh,Pge),e(Pge,cho),e(eh,fho),e(eh,Iq),e(Iq,gho),e(eh,hho),e(A,uho),e(A,oh),e(oh,Bge),e(Bge,pho),e(oh,_ho),e(oh,Nq),e(Nq,bho),e(oh,vho),e(A,Fho),e(A,rh),e(rh,Ige),e(Ige,Tho),e(rh,Mho),e(rh,qq),e(qq,Eho),e(rh,Cho),e(A,who),e(A,th),e(th,Nge),e(Nge,Aho),e(th,Lho),e(th,jq),e(jq,yho),e(th,xho),e(A,$ho),e(A,ah),e(ah,qge),e(qge,kho),e(ah,Sho),e(ah,Dq),e(Dq,Rho),e(ah,Pho),e(A,Bho),e(A,nh),e(nh,jge),e(jge,Iho),e(nh,Nho),e(nh,Gq),e(Gq,qho),e(nh,jho),e(A,Dho),e(A,sh),e(sh,Dge),e(Dge,Gho),e(sh,Oho),e(sh,Oq),e(Oq,Vho),e(sh,Xho),e(A,zho),e(A,lh),e(lh,Gge),e(Gge,Qho),e(lh,Who),e(lh,Vq),e(Vq,Uho),e(lh,Hho),e(A,Jho),e(A,ih),e(ih,Oge),e(Oge,Yho),e(ih,Zho),e(ih,Xq),e(Xq,Kho),e(ih,euo),e(A,ouo),e(A,dh),e(dh,Vge),e(Vge,ruo),e(dh,tuo),e(dh,zq),e(zq,auo),e(dh,nuo),e(A,suo),e(A,mh),e(mh,Xge),e(Xge,luo),e(mh,iuo),e(mh,Qq),e(Qq,duo),e(mh,muo),e(A,cuo),e(A,ch),e(ch,zge),e(zge,fuo),e(ch,guo),e(ch,Wq),e(Wq,huo),e(ch,uuo),e(A,puo),e(A,fh),e(fh,Qge),e(Qge,_uo),e(fh,buo),e(fh,Uq),e(Uq,vuo),e(fh,Fuo),e(A,Tuo),e(A,gh),e(gh,Wge),e(Wge,Muo),e(gh,Euo),e(gh,Hq),e(Hq,Cuo),e(gh,wuo),e(A,Auo),e(A,hh),e(hh,Uge),e(Uge,Luo),e(hh,yuo),e(hh,Jq),e(Jq,xuo),e(hh,$uo),e(A,kuo),e(A,uh),e(uh,Hge),e(Hge,Suo),e(uh,Ruo),e(uh,Yq),e(Yq,Puo),e(uh,Buo),e(A,Iuo),e(A,ph),e(ph,Jge),e(Jge,Nuo),e(ph,quo),e(ph,Zq),e(Zq,juo),e(ph,Duo),e(A,Guo),e(A,_h),e(_h,Yge),e(Yge,Ouo),e(_h,Vuo),e(_h,Kq),e(Kq,Xuo),e(_h,zuo),e(A,Quo),e(A,bh),e(bh,Zge),e(Zge,Wuo),e(bh,Uuo),e(bh,ej),e(ej,Huo),e(bh,Juo),e(A,Yuo),e(A,vh),e(vh,Kge),e(Kge,Zuo),e(vh,Kuo),e(vh,oj),e(oj,epo),e(vh,opo),e(A,rpo),e(A,Fh),e(Fh,ehe),e(ehe,tpo),e(Fh,apo),e(Fh,rj),e(rj,npo),e(Fh,spo),e(A,lpo),e(A,Th),e(Th,ohe),e(ohe,ipo),e(Th,dpo),e(Th,tj),e(tj,mpo),e(Th,cpo),e(A,fpo),e(A,Mh),e(Mh,rhe),e(rhe,gpo),e(Mh,hpo),e(Mh,aj),e(aj,upo),e(Mh,ppo),e(A,_po),e(A,Eh),e(Eh,the),e(the,bpo),e(Eh,vpo),e(Eh,nj),e(nj,Fpo),e(Eh,Tpo),e(A,Mpo),e(A,Ch),e(Ch,ahe),e(ahe,Epo),e(Ch,Cpo),e(Ch,sj),e(sj,wpo),e(Ch,Apo),e(A,Lpo),e(A,wh),e(wh,nhe),e(nhe,ypo),e(wh,xpo),e(wh,lj),e(lj,$po),e(wh,kpo),e(A,Spo),e(A,Ah),e(Ah,she),e(she,Rpo),e(Ah,Ppo),e(Ah,ij),e(ij,Bpo),e(Ah,Ipo),e(A,Npo),e(A,Lh),e(Lh,lhe),e(lhe,qpo),e(Lh,jpo),e(Lh,dj),e(dj,Dpo),e(Lh,Gpo),e(A,Opo),e(A,yh),e(yh,ihe),e(ihe,Vpo),e(yh,Xpo),e(yh,mj),e(mj,zpo),e(yh,Qpo),e(A,Wpo),e(A,xh),e(xh,dhe),e(dhe,Upo),e(xh,Hpo),e(xh,cj),e(cj,Jpo),e(xh,Ypo),e(A,Zpo),e(A,$h),e($h,mhe),e(mhe,Kpo),e($h,e_o),e($h,fj),e(fj,o_o),e($h,r_o),e(A,t_o),e(A,kh),e(kh,che),e(che,a_o),e(kh,n_o),e(kh,gj),e(gj,s_o),e(kh,l_o),e(A,i_o),e(A,Sh),e(Sh,fhe),e(fhe,d_o),e(Sh,m_o),e(Sh,hj),e(hj,c_o),e(Sh,f_o),e(A,g_o),e(A,Rh),e(Rh,ghe),e(ghe,h_o),e(Rh,u_o),e(Rh,uj),e(uj,p_o),e(Rh,__o),e(A,b_o),e(A,Ph),e(Ph,hhe),e(hhe,v_o),e(Ph,F_o),e(Ph,pj),e(pj,T_o),e(Ph,M_o),e(A,E_o),e(A,Bh),e(Bh,uhe),e(uhe,C_o),e(Bh,w_o),e(Bh,_j),e(_j,A_o),e(Bh,L_o),e(A,y_o),e(A,Ih),e(Ih,phe),e(phe,x_o),e(Ih,$_o),e(Ih,bj),e(bj,k_o),e(Ih,S_o),e(A,R_o),e(A,Nh),e(Nh,_he),e(_he,P_o),e(Nh,B_o),e(Nh,vj),e(vj,I_o),e(Nh,N_o),e(A,q_o),e(A,qh),e(qh,bhe),e(bhe,j_o),e(qh,D_o),e(qh,Fj),e(Fj,G_o),e(qh,O_o),e(A,V_o),e(A,jh),e(jh,vhe),e(vhe,X_o),e(jh,z_o),e(jh,Tj),e(Tj,Q_o),e(jh,W_o),e(A,U_o),e(A,Dh),e(Dh,Fhe),e(Fhe,H_o),e(Dh,J_o),e(Dh,Mj),e(Mj,Y_o),e(Dh,Z_o),e(A,K_o),e(A,Gh),e(Gh,The),e(The,e1o),e(Gh,o1o),e(Gh,Ej),e(Ej,r1o),e(Gh,t1o),e(A,a1o),e(A,Oh),e(Oh,Mhe),e(Mhe,n1o),e(Oh,s1o),e(Oh,Cj),e(Cj,l1o),e(Oh,i1o),e(A,d1o),e(A,Vh),e(Vh,Ehe),e(Ehe,m1o),e(Vh,c1o),e(Vh,wj),e(wj,f1o),e(Vh,g1o),e(A,h1o),e(A,Xh),e(Xh,Che),e(Che,u1o),e(Xh,p1o),e(Xh,Aj),e(Aj,_1o),e(Xh,b1o),e(A,v1o),e(A,zh),e(zh,whe),e(whe,F1o),e(zh,T1o),e(zh,Lj),e(Lj,M1o),e(zh,E1o),e(A,C1o),e(A,Qh),e(Qh,Ahe),e(Ahe,w1o),e(Qh,A1o),e(Qh,yj),e(yj,L1o),e(Qh,y1o),e(A,x1o),e(A,Wh),e(Wh,Lhe),e(Lhe,$1o),e(Wh,k1o),e(Wh,xj),e(xj,S1o),e(Wh,R1o),e(A,P1o),e(A,Uh),e(Uh,yhe),e(yhe,B1o),e(Uh,I1o),e(Uh,$j),e($j,N1o),e(Uh,q1o),e(A,j1o),e(A,Hh),e(Hh,xhe),e(xhe,D1o),e(Hh,G1o),e(Hh,kj),e(kj,O1o),e(Hh,V1o),e(A,X1o),e(A,Jh),e(Jh,$he),e($he,z1o),e(Jh,Q1o),e(Jh,Sj),e(Sj,W1o),e(Jh,U1o),e(A,H1o),e(A,Yh),e(Yh,khe),e(khe,J1o),e(Yh,Y1o),e(Yh,Rj),e(Rj,Z1o),e(Yh,K1o),e(A,e2o),e(A,Zh),e(Zh,She),e(She,o2o),e(Zh,r2o),e(Zh,Pj),e(Pj,t2o),e(Zh,a2o),e(A,n2o),e(A,Kh),e(Kh,Rhe),e(Rhe,s2o),e(Kh,l2o),e(Kh,Bj),e(Bj,i2o),e(Kh,d2o),e(A,m2o),e(A,eu),e(eu,Phe),e(Phe,c2o),e(eu,f2o),e(eu,Ij),e(Ij,g2o),e(eu,h2o),e(A,u2o),e(A,ou),e(ou,Bhe),e(Bhe,p2o),e(ou,_2o),e(ou,Nj),e(Nj,b2o),e(ou,v2o),e(A,F2o),e(A,ru),e(ru,Ihe),e(Ihe,T2o),e(ru,M2o),e(ru,qj),e(qj,E2o),e(ru,C2o),e(A,w2o),e(A,tu),e(tu,Nhe),e(Nhe,A2o),e(tu,L2o),e(tu,jj),e(jj,y2o),e(tu,x2o),e(A,$2o),e(A,au),e(au,qhe),e(qhe,k2o),e(au,S2o),e(au,Dj),e(Dj,R2o),e(au,P2o),e(A,B2o),e(A,nu),e(nu,jhe),e(jhe,I2o),e(nu,N2o),e(nu,Gj),e(Gj,q2o),e(nu,j2o),e(A,D2o),e(A,su),e(su,Dhe),e(Dhe,G2o),e(su,O2o),e(su,Oj),e(Oj,V2o),e(su,X2o),e(A,z2o),e(A,lu),e(lu,Ghe),e(Ghe,Q2o),e(lu,W2o),e(lu,Vj),e(Vj,U2o),e(lu,H2o),e(A,J2o),e(A,iu),e(iu,Ohe),e(Ohe,Y2o),e(iu,Z2o),e(iu,Xj),e(Xj,K2o),e(iu,ebo),e(A,obo),e(A,du),e(du,Vhe),e(Vhe,rbo),e(du,tbo),e(du,zj),e(zj,abo),e(du,nbo),e(A,sbo),e(A,mu),e(mu,Xhe),e(Xhe,lbo),e(mu,ibo),e(mu,Qj),e(Qj,dbo),e(mu,mbo),e(A,cbo),e(A,cu),e(cu,zhe),e(zhe,fbo),e(cu,gbo),e(cu,Wj),e(Wj,hbo),e(cu,ubo),e(A,pbo),e(A,fu),e(fu,Qhe),e(Qhe,_bo),e(fu,bbo),e(fu,Uj),e(Uj,vbo),e(fu,Fbo),e(A,Tbo),e(A,gu),e(gu,Whe),e(Whe,Mbo),e(gu,Ebo),e(gu,Hj),e(Hj,Cbo),e(gu,wbo),e(A,Abo),e(A,hu),e(hu,Uhe),e(Uhe,Lbo),e(hu,ybo),e(hu,Jj),e(Jj,xbo),e(hu,$bo),e(A,kbo),e(A,uu),e(uu,Hhe),e(Hhe,Sbo),e(uu,Rbo),e(uu,Yj),e(Yj,Pbo),e(uu,Bbo),e(A,Ibo),e(A,pu),e(pu,Jhe),e(Jhe,Nbo),e(pu,qbo),e(pu,Zj),e(Zj,jbo),e(pu,Dbo),e(A,Gbo),e(A,_u),e(_u,Yhe),e(Yhe,Obo),e(_u,Vbo),e(_u,Kj),e(Kj,Xbo),e(_u,zbo),e(A,Qbo),e(A,bu),e(bu,Zhe),e(Zhe,Wbo),e(bu,Ubo),e(bu,eD),e(eD,Hbo),e(bu,Jbo),e(A,Ybo),e(A,vu),e(vu,Khe),e(Khe,Zbo),e(vu,Kbo),e(vu,oD),e(oD,evo),e(vu,ovo),e(A,rvo),e(A,Fu),e(Fu,eue),e(eue,tvo),e(Fu,avo),e(Fu,rD),e(rD,nvo),e(Fu,svo),e(A,lvo),e(A,Tu),e(Tu,oue),e(oue,ivo),e(Tu,dvo),e(Tu,tD),e(tD,mvo),e(Tu,cvo),e(A,fvo),e(A,Mu),e(Mu,rue),e(rue,gvo),e(Mu,hvo),e(Mu,aD),e(aD,uvo),e(Mu,pvo),e(A,_vo),e(A,Eu),e(Eu,tue),e(tue,bvo),e(Eu,vvo),e(Eu,nD),e(nD,Fvo),e(Eu,Tvo),e(A,Mvo),e(A,Cu),e(Cu,aue),e(aue,Evo),e(Cu,Cvo),e(Cu,sD),e(sD,wvo),e(Cu,Avo),e(A,Lvo),e(A,wu),e(wu,nue),e(nue,yvo),e(wu,xvo),e(wu,lD),e(lD,$vo),e(wu,kvo),e(A,Svo),e(A,Au),e(Au,sue),e(sue,Rvo),e(Au,Pvo),e(Au,iD),e(iD,Bvo),e(Au,Ivo),e(qr,Nvo),M(Lu,qr,null),e(So,qvo),e(So,yu),M(T$,yu,null),e(yu,jvo),e(yu,lue),e(lue,Dvo),b(c,Kto,_),b(c,xd,_),e(xd,xu),e(xu,iue),M(M$,iue,null),e(xd,Gvo),e(xd,due),e(due,Ovo),b(c,eao,_),b(c,Ro,_),M(E$,Ro,null),e(Ro,Vvo),e(Ro,C$),e(C$,Xvo),e(C$,dD),e(dD,zvo),e(C$,Qvo),e(Ro,Wvo),e(Ro,w$),e(w$,Uvo),e(w$,mue),e(mue,Hvo),e(w$,Jvo),e(Ro,Yvo),e(Ro,jr),M(A$,jr,null),e(jr,Zvo),e(jr,cue),e(cue,Kvo),e(jr,eFo),e(jr,tn),e(tn,oFo),e(tn,fue),e(fue,rFo),e(tn,tFo),e(tn,gue),e(gue,aFo),e(tn,nFo),e(tn,hue),e(hue,sFo),e(tn,lFo),e(jr,iFo),e(jr,k),e(k,us),e(us,uue),e(uue,dFo),e(us,mFo),e(us,mD),e(mD,cFo),e(us,fFo),e(us,cD),e(cD,gFo),e(us,hFo),e(k,uFo),e(k,ps),e(ps,pue),e(pue,pFo),e(ps,_Fo),e(ps,fD),e(fD,bFo),e(ps,vFo),e(ps,gD),e(gD,FFo),e(ps,TFo),e(k,MFo),e(k,_s),e(_s,_ue),e(_ue,EFo),e(_s,CFo),e(_s,hD),e(hD,wFo),e(_s,AFo),e(_s,uD),e(uD,LFo),e(_s,yFo),e(k,xFo),e(k,$u),e($u,bue),e(bue,$Fo),e($u,kFo),e($u,pD),e(pD,SFo),e($u,RFo),e(k,PFo),e(k,bs),e(bs,vue),e(vue,BFo),e(bs,IFo),e(bs,_D),e(_D,NFo),e(bs,qFo),e(bs,bD),e(bD,jFo),e(bs,DFo),e(k,GFo),e(k,ku),e(ku,Fue),e(Fue,OFo),e(ku,VFo),e(ku,vD),e(vD,XFo),e(ku,zFo),e(k,QFo),e(k,Su),e(Su,Tue),e(Tue,WFo),e(Su,UFo),e(Su,FD),e(FD,HFo),e(Su,JFo),e(k,YFo),e(k,Ru),e(Ru,Mue),e(Mue,ZFo),e(Ru,KFo),e(Ru,TD),e(TD,eTo),e(Ru,oTo),e(k,rTo),e(k,vs),e(vs,Eue),e(Eue,tTo),e(vs,aTo),e(vs,MD),e(MD,nTo),e(vs,sTo),e(vs,ED),e(ED,lTo),e(vs,iTo),e(k,dTo),e(k,Fs),e(Fs,Cue),e(Cue,mTo),e(Fs,cTo),e(Fs,CD),e(CD,fTo),e(Fs,gTo),e(Fs,wD),e(wD,hTo),e(Fs,uTo),e(k,pTo),e(k,Ts),e(Ts,wue),e(wue,_To),e(Ts,bTo),e(Ts,AD),e(AD,vTo),e(Ts,FTo),e(Ts,LD),e(LD,TTo),e(Ts,MTo),e(k,ETo),e(k,Pu),e(Pu,Aue),e(Aue,CTo),e(Pu,wTo),e(Pu,yD),e(yD,ATo),e(Pu,LTo),e(k,yTo),e(k,Bu),e(Bu,Lue),e(Lue,xTo),e(Bu,$To),e(Bu,xD),e(xD,kTo),e(Bu,STo),e(k,RTo),e(k,Iu),e(Iu,yue),e(yue,PTo),e(Iu,BTo),e(Iu,$D),e($D,ITo),e(Iu,NTo),e(k,qTo),e(k,Ms),e(Ms,xue),e(xue,jTo),e(Ms,DTo),e(Ms,kD),e(kD,GTo),e(Ms,OTo),e(Ms,SD),e(SD,VTo),e(Ms,XTo),e(k,zTo),e(k,Nu),e(Nu,$ue),e($ue,QTo),e(Nu,WTo),e(Nu,RD),e(RD,UTo),e(Nu,HTo),e(k,JTo),e(k,Es),e(Es,kue),e(kue,YTo),e(Es,ZTo),e(Es,PD),e(PD,KTo),e(Es,eMo),e(Es,BD),e(BD,oMo),e(Es,rMo),e(k,tMo),e(k,Cs),e(Cs,Sue),e(Sue,aMo),e(Cs,nMo),e(Cs,ID),e(ID,sMo),e(Cs,lMo),e(Cs,ND),e(ND,iMo),e(Cs,dMo),e(k,mMo),e(k,ws),e(ws,Rue),e(Rue,cMo),e(ws,fMo),e(ws,qD),e(qD,gMo),e(ws,hMo),e(ws,jD),e(jD,uMo),e(ws,pMo),e(k,_Mo),e(k,As),e(As,Pue),e(Pue,bMo),e(As,vMo),e(As,DD),e(DD,FMo),e(As,TMo),e(As,GD),e(GD,MMo),e(As,EMo),e(k,CMo),e(k,Ls),e(Ls,Bue),e(Bue,wMo),e(Ls,AMo),e(Ls,OD),e(OD,LMo),e(Ls,yMo),e(Ls,VD),e(VD,xMo),e(Ls,$Mo),e(k,kMo),e(k,qu),e(qu,Iue),e(Iue,SMo),e(qu,RMo),e(qu,XD),e(XD,PMo),e(qu,BMo),e(k,IMo),e(k,ys),e(ys,Nue),e(Nue,NMo),e(ys,qMo),e(ys,zD),e(zD,jMo),e(ys,DMo),e(ys,QD),e(QD,GMo),e(ys,OMo),e(k,VMo),e(k,xs),e(xs,que),e(que,XMo),e(xs,zMo),e(xs,WD),e(WD,QMo),e(xs,WMo),e(xs,UD),e(UD,UMo),e(xs,HMo),e(k,JMo),e(k,$s),e($s,jue),e(jue,YMo),e($s,ZMo),e($s,HD),e(HD,KMo),e($s,eEo),e($s,JD),e(JD,oEo),e($s,rEo),e(k,tEo),e(k,ks),e(ks,Due),e(Due,aEo),e(ks,nEo),e(ks,YD),e(YD,sEo),e(ks,lEo),e(ks,ZD),e(ZD,iEo),e(ks,dEo),e(k,mEo),e(k,Ss),e(Ss,Gue),e(Gue,cEo),e(Ss,fEo),e(Ss,KD),e(KD,gEo),e(Ss,hEo),e(Ss,eG),e(eG,uEo),e(Ss,pEo),e(k,_Eo),e(k,Rs),e(Rs,Oue),e(Oue,bEo),e(Rs,vEo),e(Rs,oG),e(oG,FEo),e(Rs,TEo),e(Rs,rG),e(rG,MEo),e(Rs,EEo),e(k,CEo),e(k,Ps),e(Ps,Vue),e(Vue,wEo),e(Ps,AEo),e(Ps,tG),e(tG,LEo),e(Ps,yEo),e(Ps,aG),e(aG,xEo),e(Ps,$Eo),e(k,kEo),e(k,ju),e(ju,Xue),e(Xue,SEo),e(ju,REo),e(ju,nG),e(nG,PEo),e(ju,BEo),e(k,IEo),e(k,Du),e(Du,zue),e(zue,NEo),e(Du,qEo),e(Du,sG),e(sG,jEo),e(Du,DEo),e(k,GEo),e(k,Bs),e(Bs,Que),e(Que,OEo),e(Bs,VEo),e(Bs,lG),e(lG,XEo),e(Bs,zEo),e(Bs,iG),e(iG,QEo),e(Bs,WEo),e(k,UEo),e(k,Gu),e(Gu,Wue),e(Wue,HEo),e(Gu,JEo),e(Gu,dG),e(dG,YEo),e(Gu,ZEo),e(k,KEo),e(k,Is),e(Is,Uue),e(Uue,e4o),e(Is,o4o),e(Is,mG),e(mG,r4o),e(Is,t4o),e(Is,cG),e(cG,a4o),e(Is,n4o),e(k,s4o),e(k,Ns),e(Ns,Hue),e(Hue,l4o),e(Ns,i4o),e(Ns,fG),e(fG,d4o),e(Ns,m4o),e(Ns,gG),e(gG,c4o),e(Ns,f4o),e(k,g4o),e(k,qs),e(qs,Jue),e(Jue,h4o),e(qs,u4o),e(qs,hG),e(hG,p4o),e(qs,_4o),e(qs,uG),e(uG,b4o),e(qs,v4o),e(k,F4o),e(k,Ou),e(Ou,Yue),e(Yue,T4o),e(Ou,M4o),e(Ou,pG),e(pG,E4o),e(Ou,C4o),e(k,w4o),e(k,Vu),e(Vu,Zue),e(Zue,A4o),e(Vu,L4o),e(Vu,_G),e(_G,y4o),e(Vu,x4o),e(k,$4o),e(k,js),e(js,Kue),e(Kue,k4o),e(js,S4o),e(js,bG),e(bG,R4o),e(js,P4o),e(js,vG),e(vG,B4o),e(js,I4o),e(k,N4o),e(k,Ds),e(Ds,epe),e(epe,q4o),e(Ds,j4o),e(Ds,FG),e(FG,D4o),e(Ds,G4o),e(Ds,TG),e(TG,O4o),e(Ds,V4o),e(k,X4o),e(k,Gs),e(Gs,ope),e(ope,z4o),e(Gs,Q4o),e(Gs,MG),e(MG,W4o),e(Gs,U4o),e(Gs,EG),e(EG,H4o),e(Gs,J4o),e(k,Y4o),e(k,Xu),e(Xu,rpe),e(rpe,Z4o),e(Xu,K4o),e(Xu,CG),e(CG,eCo),e(Xu,oCo),e(k,rCo),e(k,Os),e(Os,tpe),e(tpe,tCo),e(Os,aCo),e(Os,wG),e(wG,nCo),e(Os,sCo),e(Os,AG),e(AG,lCo),e(Os,iCo),e(k,dCo),e(k,Vs),e(Vs,ape),e(ape,mCo),e(Vs,cCo),e(Vs,LG),e(LG,fCo),e(Vs,gCo),e(Vs,yG),e(yG,hCo),e(Vs,uCo),e(k,pCo),e(k,Xs),e(Xs,npe),e(npe,_Co),e(Xs,bCo),e(Xs,xG),e(xG,vCo),e(Xs,FCo),e(Xs,$G),e($G,TCo),e(Xs,MCo),e(k,ECo),e(k,zs),e(zs,spe),e(spe,CCo),e(zs,wCo),e(zs,kG),e(kG,ACo),e(zs,LCo),e(zs,SG),e(SG,yCo),e(zs,xCo),e(k,$Co),e(k,Qs),e(Qs,lpe),e(lpe,kCo),e(Qs,SCo),e(Qs,RG),e(RG,RCo),e(Qs,PCo),e(Qs,PG),e(PG,BCo),e(Qs,ICo),e(k,NCo),e(k,Ws),e(Ws,ipe),e(ipe,qCo),e(Ws,jCo),e(Ws,BG),e(BG,DCo),e(Ws,GCo),e(Ws,IG),e(IG,OCo),e(Ws,VCo),e(k,XCo),e(k,Us),e(Us,dpe),e(dpe,zCo),e(Us,QCo),e(Us,NG),e(NG,WCo),e(Us,UCo),e(Us,qG),e(qG,HCo),e(Us,JCo),e(k,YCo),e(k,Hs),e(Hs,mpe),e(mpe,ZCo),e(Hs,KCo),e(Hs,jG),e(jG,e3o),e(Hs,o3o),e(Hs,DG),e(DG,r3o),e(Hs,t3o),e(k,a3o),e(k,Js),e(Js,cpe),e(cpe,n3o),e(Js,s3o),e(Js,GG),e(GG,l3o),e(Js,i3o),e(Js,OG),e(OG,d3o),e(Js,m3o),e(k,c3o),e(k,zu),e(zu,fpe),e(fpe,f3o),e(zu,g3o),e(zu,VG),e(VG,h3o),e(zu,u3o),e(k,p3o),e(k,Ys),e(Ys,gpe),e(gpe,_3o),e(Ys,b3o),e(Ys,XG),e(XG,v3o),e(Ys,F3o),e(Ys,zG),e(zG,T3o),e(Ys,M3o),e(k,E3o),e(k,Qu),e(Qu,hpe),e(hpe,C3o),e(Qu,w3o),e(Qu,QG),e(QG,A3o),e(Qu,L3o),e(k,y3o),e(k,Wu),e(Wu,upe),e(upe,x3o),e(Wu,$3o),e(Wu,WG),e(WG,k3o),e(Wu,S3o),e(k,R3o),e(k,Zs),e(Zs,ppe),e(ppe,P3o),e(Zs,B3o),e(Zs,UG),e(UG,I3o),e(Zs,N3o),e(Zs,HG),e(HG,q3o),e(Zs,j3o),e(k,D3o),e(k,Ks),e(Ks,_pe),e(_pe,G3o),e(Ks,O3o),e(Ks,JG),e(JG,V3o),e(Ks,X3o),e(Ks,YG),e(YG,z3o),e(Ks,Q3o),e(k,W3o),e(k,el),e(el,bpe),e(bpe,U3o),e(el,H3o),e(el,ZG),e(ZG,J3o),e(el,Y3o),e(el,KG),e(KG,Z3o),e(el,K3o),e(k,e5o),e(k,Uu),e(Uu,vpe),e(vpe,o5o),e(Uu,r5o),e(Uu,eO),e(eO,t5o),e(Uu,a5o),e(k,n5o),e(k,ol),e(ol,Fpe),e(Fpe,s5o),e(ol,l5o),e(ol,oO),e(oO,i5o),e(ol,d5o),e(ol,rO),e(rO,m5o),e(ol,c5o),e(k,f5o),e(k,rl),e(rl,Tpe),e(Tpe,g5o),e(rl,h5o),e(rl,tO),e(tO,u5o),e(rl,p5o),e(rl,aO),e(aO,_5o),e(rl,b5o),e(k,v5o),e(k,tl),e(tl,Mpe),e(Mpe,F5o),e(tl,T5o),e(tl,nO),e(nO,M5o),e(tl,E5o),e(tl,sO),e(sO,C5o),e(tl,w5o),e(k,A5o),e(k,al),e(al,Epe),e(Epe,L5o),e(al,y5o),e(al,lO),e(lO,x5o),e(al,$5o),e(al,iO),e(iO,k5o),e(al,S5o),e(k,R5o),e(k,nl),e(nl,Cpe),e(Cpe,P5o),e(nl,B5o),e(nl,dO),e(dO,I5o),e(nl,N5o),e(nl,mO),e(mO,q5o),e(nl,j5o),e(k,D5o),e(k,sl),e(sl,wpe),e(wpe,G5o),e(sl,O5o),e(sl,cO),e(cO,V5o),e(sl,X5o),e(sl,fO),e(fO,z5o),e(sl,Q5o),e(k,W5o),e(k,ll),e(ll,Ape),e(Ape,U5o),e(ll,H5o),e(ll,gO),e(gO,J5o),e(ll,Y5o),e(ll,hO),e(hO,Z5o),e(ll,K5o),e(k,e0o),e(k,il),e(il,Lpe),e(Lpe,o0o),e(il,r0o),e(il,uO),e(uO,t0o),e(il,a0o),e(il,pO),e(pO,n0o),e(il,s0o),e(k,l0o),e(k,Hu),e(Hu,ype),e(ype,i0o),e(Hu,d0o),e(Hu,_O),e(_O,m0o),e(Hu,c0o),e(k,f0o),e(k,dl),e(dl,xpe),e(xpe,g0o),e(dl,h0o),e(dl,bO),e(bO,u0o),e(dl,p0o),e(dl,vO),e(vO,_0o),e(dl,b0o),e(k,v0o),e(k,ml),e(ml,$pe),e($pe,F0o),e(ml,T0o),e(ml,FO),e(FO,M0o),e(ml,E0o),e(ml,TO),e(TO,C0o),e(ml,w0o),e(k,A0o),e(k,cl),e(cl,kpe),e(kpe,L0o),e(cl,y0o),e(cl,MO),e(MO,x0o),e(cl,$0o),e(cl,EO),e(EO,k0o),e(cl,S0o),e(k,R0o),e(k,Ju),e(Ju,Spe),e(Spe,P0o),e(Ju,B0o),e(Ju,CO),e(CO,I0o),e(Ju,N0o),e(k,q0o),e(k,Yu),e(Yu,Rpe),e(Rpe,j0o),e(Yu,D0o),e(Yu,wO),e(wO,G0o),e(Yu,O0o),e(k,V0o),e(k,Zu),e(Zu,Ppe),e(Ppe,X0o),e(Zu,z0o),e(Zu,AO),e(AO,Q0o),e(Zu,W0o),e(k,U0o),e(k,Ku),e(Ku,Bpe),e(Bpe,H0o),e(Ku,J0o),e(Ku,LO),e(LO,Y0o),e(Ku,Z0o),e(k,K0o),e(k,fl),e(fl,Ipe),e(Ipe,ewo),e(fl,owo),e(fl,yO),e(yO,rwo),e(fl,two),e(fl,xO),e(xO,awo),e(fl,nwo),e(k,swo),e(k,ep),e(ep,Npe),e(Npe,lwo),e(ep,iwo),e(ep,$O),e($O,dwo),e(ep,mwo),e(k,cwo),e(k,gl),e(gl,qpe),e(qpe,fwo),e(gl,gwo),e(gl,kO),e(kO,hwo),e(gl,uwo),e(gl,SO),e(SO,pwo),e(gl,_wo),e(k,bwo),e(k,hl),e(hl,jpe),e(jpe,vwo),e(hl,Fwo),e(hl,RO),e(RO,Two),e(hl,Mwo),e(hl,PO),e(PO,Ewo),e(hl,Cwo),e(k,wwo),e(k,ul),e(ul,Dpe),e(Dpe,Awo),e(ul,Lwo),e(ul,BO),e(BO,ywo),e(ul,xwo),e(ul,IO),e(IO,$wo),e(ul,kwo),e(k,Swo),e(k,pl),e(pl,Gpe),e(Gpe,Rwo),e(pl,Pwo),e(pl,NO),e(NO,Bwo),e(pl,Iwo),e(pl,qO),e(qO,Nwo),e(pl,qwo),e(k,jwo),e(k,_l),e(_l,Ope),e(Ope,Dwo),e(_l,Gwo),e(_l,jO),e(jO,Owo),e(_l,Vwo),e(_l,DO),e(DO,Xwo),e(_l,zwo),e(k,Qwo),e(k,bl),e(bl,Vpe),e(Vpe,Wwo),e(bl,Uwo),e(bl,GO),e(GO,Hwo),e(bl,Jwo),e(bl,OO),e(OO,Ywo),e(bl,Zwo),e(k,Kwo),e(k,op),e(op,Xpe),e(Xpe,eAo),e(op,oAo),e(op,VO),e(VO,rAo),e(op,tAo),e(k,aAo),e(k,rp),e(rp,zpe),e(zpe,nAo),e(rp,sAo),e(rp,XO),e(XO,lAo),e(rp,iAo),e(k,dAo),e(k,vl),e(vl,Qpe),e(Qpe,mAo),e(vl,cAo),e(vl,zO),e(zO,fAo),e(vl,gAo),e(vl,QO),e(QO,hAo),e(vl,uAo),e(k,pAo),e(k,Fl),e(Fl,Wpe),e(Wpe,_Ao),e(Fl,bAo),e(Fl,WO),e(WO,vAo),e(Fl,FAo),e(Fl,UO),e(UO,TAo),e(Fl,MAo),e(k,EAo),e(k,Tl),e(Tl,Upe),e(Upe,CAo),e(Tl,wAo),e(Tl,HO),e(HO,AAo),e(Tl,LAo),e(Tl,JO),e(JO,yAo),e(Tl,xAo),e(k,$Ao),e(k,tp),e(tp,Hpe),e(Hpe,kAo),e(tp,SAo),e(tp,YO),e(YO,RAo),e(tp,PAo),e(k,BAo),e(k,ap),e(ap,Jpe),e(Jpe,IAo),e(ap,NAo),e(ap,ZO),e(ZO,qAo),e(ap,jAo),e(k,DAo),e(k,np),e(np,Ype),e(Ype,GAo),e(np,OAo),e(np,KO),e(KO,VAo),e(np,XAo),e(k,zAo),e(k,Ml),e(Ml,Zpe),e(Zpe,QAo),e(Ml,WAo),e(Ml,eV),e(eV,UAo),e(Ml,HAo),e(Ml,oV),e(oV,JAo),e(Ml,YAo),e(k,ZAo),e(k,El),e(El,Kpe),e(Kpe,KAo),e(El,e6o),e(El,rV),e(rV,o6o),e(El,r6o),e(El,tV),e(tV,t6o),e(El,a6o),e(k,n6o),e(k,sp),e(sp,e_e),e(e_e,s6o),e(sp,l6o),e(sp,aV),e(aV,i6o),e(sp,d6o),e(k,m6o),e(k,lp),e(lp,o_e),e(o_e,c6o),e(lp,f6o),e(lp,nV),e(nV,g6o),e(lp,h6o),e(k,u6o),e(k,ip),e(ip,r_e),e(r_e,p6o),e(ip,_6o),e(ip,sV),e(sV,b6o),e(ip,v6o),e(k,F6o),e(k,dp),e(dp,t_e),e(t_e,T6o),e(dp,M6o),e(dp,lV),e(lV,E6o),e(dp,C6o),e(k,w6o),e(k,Cl),e(Cl,a_e),e(a_e,A6o),e(Cl,L6o),e(Cl,iV),e(iV,y6o),e(Cl,x6o),e(Cl,dV),e(dV,$6o),e(Cl,k6o),e(k,S6o),e(k,wl),e(wl,n_e),e(n_e,R6o),e(wl,P6o),e(wl,mV),e(mV,B6o),e(wl,I6o),e(wl,cV),e(cV,N6o),e(wl,q6o),e(k,j6o),e(k,mp),e(mp,s_e),e(s_e,D6o),e(mp,G6o),e(mp,fV),e(fV,O6o),e(mp,V6o),e(k,X6o),e(k,cp),e(cp,l_e),e(l_e,z6o),e(cp,Q6o),e(cp,gV),e(gV,W6o),e(cp,U6o),e(k,H6o),e(k,Al),e(Al,i_e),e(i_e,J6o),e(Al,Y6o),e(Al,hV),e(hV,Z6o),e(Al,K6o),e(Al,uV),e(uV,e7o),e(Al,o7o),e(k,r7o),e(k,Ll),e(Ll,d_e),e(d_e,t7o),e(Ll,a7o),e(Ll,pV),e(pV,n7o),e(Ll,s7o),e(Ll,_V),e(_V,l7o),e(Ll,i7o),e(k,d7o),e(k,yl),e(yl,m_e),e(m_e,m7o),e(yl,c7o),e(yl,bV),e(bV,f7o),e(yl,g7o),e(yl,vV),e(vV,h7o),e(yl,u7o),e(k,p7o),e(k,xl),e(xl,c_e),e(c_e,_7o),e(xl,b7o),e(xl,FV),e(FV,v7o),e(xl,F7o),e(xl,TV),e(TV,T7o),e(xl,M7o),e(jr,E7o),M(fp,jr,null),e(Ro,C7o),e(Ro,gp),M(L$,gp,null),e(gp,w7o),e(gp,f_e),e(f_e,A7o),b(c,oao,_),b(c,$d,_),e($d,hp),e(hp,g_e),M(y$,g_e,null),e($d,L7o),e($d,h_e),e(h_e,y7o),b(c,rao,_),b(c,Po,_),M(x$,Po,null),e(Po,x7o),e(Po,$$),e($$,$7o),e($$,MV),e(MV,k7o),e($$,S7o),e(Po,R7o),e(Po,k$),e(k$,P7o),e(k$,u_e),e(u_e,B7o),e(k$,I7o),e(Po,N7o),e(Po,Ye),M(S$,Ye,null),e(Ye,q7o),e(Ye,p_e),e(p_e,j7o),e(Ye,D7o),e(Ye,an),e(an,G7o),e(an,__e),e(__e,O7o),e(an,V7o),e(an,b_e),e(b_e,X7o),e(an,z7o),e(an,v_e),e(v_e,Q7o),e(an,W7o),e(Ye,U7o),e(Ye,z),e(z,up),e(up,F_e),e(F_e,H7o),e(up,J7o),e(up,EV),e(EV,Y7o),e(up,Z7o),e(z,K7o),e(z,pp),e(pp,T_e),e(T_e,e8o),e(pp,o8o),e(pp,CV),e(CV,r8o),e(pp,t8o),e(z,a8o),e(z,_p),e(_p,M_e),e(M_e,n8o),e(_p,s8o),e(_p,wV),e(wV,l8o),e(_p,i8o),e(z,d8o),e(z,bp),e(bp,E_e),e(E_e,m8o),e(bp,c8o),e(bp,AV),e(AV,f8o),e(bp,g8o),e(z,h8o),e(z,vp),e(vp,C_e),e(C_e,u8o),e(vp,p8o),e(vp,LV),e(LV,_8o),e(vp,b8o),e(z,v8o),e(z,Fp),e(Fp,w_e),e(w_e,F8o),e(Fp,T8o),e(Fp,yV),e(yV,M8o),e(Fp,E8o),e(z,C8o),e(z,Tp),e(Tp,A_e),e(A_e,w8o),e(Tp,A8o),e(Tp,xV),e(xV,L8o),e(Tp,y8o),e(z,x8o),e(z,Mp),e(Mp,L_e),e(L_e,$8o),e(Mp,k8o),e(Mp,$V),e($V,S8o),e(Mp,R8o),e(z,P8o),e(z,Ep),e(Ep,y_e),e(y_e,B8o),e(Ep,I8o),e(Ep,kV),e(kV,N8o),e(Ep,q8o),e(z,j8o),e(z,Cp),e(Cp,x_e),e(x_e,D8o),e(Cp,G8o),e(Cp,SV),e(SV,O8o),e(Cp,V8o),e(z,X8o),e(z,wp),e(wp,$_e),e($_e,z8o),e(wp,Q8o),e(wp,RV),e(RV,W8o),e(wp,U8o),e(z,H8o),e(z,Ap),e(Ap,k_e),e(k_e,J8o),e(Ap,Y8o),e(Ap,PV),e(PV,Z8o),e(Ap,K8o),e(z,eLo),e(z,Lp),e(Lp,S_e),e(S_e,oLo),e(Lp,rLo),e(Lp,BV),e(BV,tLo),e(Lp,aLo),e(z,nLo),e(z,yp),e(yp,R_e),e(R_e,sLo),e(yp,lLo),e(yp,IV),e(IV,iLo),e(yp,dLo),e(z,mLo),e(z,xp),e(xp,P_e),e(P_e,cLo),e(xp,fLo),e(xp,NV),e(NV,gLo),e(xp,hLo),e(z,uLo),e(z,$p),e($p,B_e),e(B_e,pLo),e($p,_Lo),e($p,qV),e(qV,bLo),e($p,vLo),e(z,FLo),e(z,kp),e(kp,I_e),e(I_e,TLo),e(kp,MLo),e(kp,jV),e(jV,ELo),e(kp,CLo),e(z,wLo),e(z,Sp),e(Sp,N_e),e(N_e,ALo),e(Sp,LLo),e(Sp,DV),e(DV,yLo),e(Sp,xLo),e(z,$Lo),e(z,Rp),e(Rp,q_e),e(q_e,kLo),e(Rp,SLo),e(Rp,GV),e(GV,RLo),e(Rp,PLo),e(z,BLo),e(z,Pp),e(Pp,j_e),e(j_e,ILo),e(Pp,NLo),e(Pp,OV),e(OV,qLo),e(Pp,jLo),e(z,DLo),e(z,Bp),e(Bp,D_e),e(D_e,GLo),e(Bp,OLo),e(Bp,VV),e(VV,VLo),e(Bp,XLo),e(z,zLo),e(z,Ip),e(Ip,G_e),e(G_e,QLo),e(Ip,WLo),e(Ip,XV),e(XV,ULo),e(Ip,HLo),e(z,JLo),e(z,Np),e(Np,O_e),e(O_e,YLo),e(Np,ZLo),e(Np,zV),e(zV,KLo),e(Np,eyo),e(z,oyo),e(z,qp),e(qp,V_e),e(V_e,ryo),e(qp,tyo),e(qp,QV),e(QV,ayo),e(qp,nyo),e(z,syo),e(z,jp),e(jp,X_e),e(X_e,lyo),e(jp,iyo),e(jp,WV),e(WV,dyo),e(jp,myo),e(z,cyo),e(z,Dp),e(Dp,z_e),e(z_e,fyo),e(Dp,gyo),e(Dp,UV),e(UV,hyo),e(Dp,uyo),e(z,pyo),e(z,Gp),e(Gp,Q_e),e(Q_e,_yo),e(Gp,byo),e(Gp,HV),e(HV,vyo),e(Gp,Fyo),e(z,Tyo),e(z,Op),e(Op,W_e),e(W_e,Myo),e(Op,Eyo),e(Op,JV),e(JV,Cyo),e(Op,wyo),e(z,Ayo),e(z,Vp),e(Vp,U_e),e(U_e,Lyo),e(Vp,yyo),e(Vp,YV),e(YV,xyo),e(Vp,$yo),e(z,kyo),e(z,Xp),e(Xp,H_e),e(H_e,Syo),e(Xp,Ryo),e(Xp,ZV),e(ZV,Pyo),e(Xp,Byo),e(z,Iyo),e(z,zp),e(zp,J_e),e(J_e,Nyo),e(zp,qyo),e(zp,KV),e(KV,jyo),e(zp,Dyo),e(z,Gyo),e(z,Qp),e(Qp,Y_e),e(Y_e,Oyo),e(Qp,Vyo),e(Qp,eX),e(eX,Xyo),e(Qp,zyo),e(z,Qyo),e(z,Wp),e(Wp,Z_e),e(Z_e,Wyo),e(Wp,Uyo),e(Wp,oX),e(oX,Hyo),e(Wp,Jyo),e(z,Yyo),e(z,Up),e(Up,K_e),e(K_e,Zyo),e(Up,Kyo),e(Up,rX),e(rX,e9o),e(Up,o9o),e(z,r9o),e(z,Hp),e(Hp,e1e),e(e1e,t9o),e(Hp,a9o),e(Hp,tX),e(tX,n9o),e(Hp,s9o),e(z,l9o),e(z,Jp),e(Jp,o1e),e(o1e,i9o),e(Jp,d9o),e(Jp,aX),e(aX,m9o),e(Jp,c9o),e(z,f9o),e(z,Yp),e(Yp,r1e),e(r1e,g9o),e(Yp,h9o),e(Yp,nX),e(nX,u9o),e(Yp,p9o),e(z,_9o),e(z,Zp),e(Zp,t1e),e(t1e,b9o),e(Zp,v9o),e(Zp,sX),e(sX,F9o),e(Zp,T9o),e(z,M9o),e(z,Kp),e(Kp,a1e),e(a1e,E9o),e(Kp,C9o),e(Kp,lX),e(lX,w9o),e(Kp,A9o),e(z,L9o),e(z,e_),e(e_,n1e),e(n1e,y9o),e(e_,x9o),e(e_,iX),e(iX,$9o),e(e_,k9o),e(z,S9o),e(z,o_),e(o_,s1e),e(s1e,R9o),e(o_,P9o),e(o_,dX),e(dX,B9o),e(o_,I9o),e(z,N9o),e(z,r_),e(r_,l1e),e(l1e,q9o),e(r_,j9o),e(r_,mX),e(mX,D9o),e(r_,G9o),e(z,O9o),e(z,t_),e(t_,i1e),e(i1e,V9o),e(t_,X9o),e(t_,cX),e(cX,z9o),e(t_,Q9o),e(z,W9o),e(z,a_),e(a_,d1e),e(d1e,U9o),e(a_,H9o),e(a_,fX),e(fX,J9o),e(a_,Y9o),e(z,Z9o),e(z,n_),e(n_,m1e),e(m1e,K9o),e(n_,exo),e(n_,gX),e(gX,oxo),e(n_,rxo),e(Ye,txo),M(s_,Ye,null),e(Ye,axo),M(l_,Ye,null),e(Po,nxo),e(Po,i_),M(R$,i_,null),e(i_,sxo),e(i_,c1e),e(c1e,lxo),b(c,tao,_),b(c,kd,_),e(kd,d_),e(d_,f1e),M(P$,f1e,null),e(kd,ixo),e(kd,g1e),e(g1e,dxo),b(c,aao,_),b(c,Bo,_),M(B$,Bo,null),e(Bo,mxo),e(Bo,I$),e(I$,cxo),e(I$,hX),e(hX,fxo),e(I$,gxo),e(Bo,hxo),e(Bo,N$),e(N$,uxo),e(N$,h1e),e(h1e,pxo),e(N$,_xo),e(Bo,bxo),e(Bo,Ze),M(q$,Ze,null),e(Ze,vxo),e(Ze,u1e),e(u1e,Fxo),e(Ze,Txo),e(Ze,Sd),e(Sd,Mxo),e(Sd,p1e),e(p1e,Exo),e(Sd,Cxo),e(Sd,_1e),e(_1e,wxo),e(Sd,Axo),e(Ze,Lxo),e(Ze,se),e(se,m_),e(m_,b1e),e(b1e,yxo),e(m_,xxo),e(m_,uX),e(uX,$xo),e(m_,kxo),e(se,Sxo),e(se,c_),e(c_,v1e),e(v1e,Rxo),e(c_,Pxo),e(c_,pX),e(pX,Bxo),e(c_,Ixo),e(se,Nxo),e(se,f_),e(f_,F1e),e(F1e,qxo),e(f_,jxo),e(f_,_X),e(_X,Dxo),e(f_,Gxo),e(se,Oxo),e(se,g_),e(g_,T1e),e(T1e,Vxo),e(g_,Xxo),e(g_,bX),e(bX,zxo),e(g_,Qxo),e(se,Wxo),e(se,h_),e(h_,M1e),e(M1e,Uxo),e(h_,Hxo),e(h_,vX),e(vX,Jxo),e(h_,Yxo),e(se,Zxo),e(se,u_),e(u_,E1e),e(E1e,Kxo),e(u_,e$o),e(u_,FX),e(FX,o$o),e(u_,r$o),e(se,t$o),e(se,p_),e(p_,C1e),e(C1e,a$o),e(p_,n$o),e(p_,TX),e(TX,s$o),e(p_,l$o),e(se,i$o),e(se,__),e(__,w1e),e(w1e,d$o),e(__,m$o),e(__,MX),e(MX,c$o),e(__,f$o),e(se,g$o),e(se,b_),e(b_,A1e),e(A1e,h$o),e(b_,u$o),e(b_,EX),e(EX,p$o),e(b_,_$o),e(se,b$o),e(se,v_),e(v_,L1e),e(L1e,v$o),e(v_,F$o),e(v_,CX),e(CX,T$o),e(v_,M$o),e(se,E$o),e(se,F_),e(F_,y1e),e(y1e,C$o),e(F_,w$o),e(F_,wX),e(wX,A$o),e(F_,L$o),e(se,y$o),e(se,T_),e(T_,x1e),e(x1e,x$o),e(T_,$$o),e(T_,AX),e(AX,k$o),e(T_,S$o),e(se,R$o),e(se,M_),e(M_,$1e),e($1e,P$o),e(M_,B$o),e(M_,LX),e(LX,I$o),e(M_,N$o),e(se,q$o),e(se,E_),e(E_,k1e),e(k1e,j$o),e(E_,D$o),e(E_,yX),e(yX,G$o),e(E_,O$o),e(se,V$o),e(se,C_),e(C_,S1e),e(S1e,X$o),e(C_,z$o),e(C_,xX),e(xX,Q$o),e(C_,W$o),e(se,U$o),e(se,w_),e(w_,R1e),e(R1e,H$o),e(w_,J$o),e(w_,$X),e($X,Y$o),e(w_,Z$o),e(se,K$o),e(se,A_),e(A_,P1e),e(P1e,eko),e(A_,oko),e(A_,kX),e(kX,rko),e(A_,tko),e(se,ako),e(se,L_),e(L_,B1e),e(B1e,nko),e(L_,sko),e(L_,SX),e(SX,lko),e(L_,iko),e(se,dko),e(se,y_),e(y_,I1e),e(I1e,mko),e(y_,cko),e(y_,RX),e(RX,fko),e(y_,gko),e(se,hko),e(se,x_),e(x_,N1e),e(N1e,uko),e(x_,pko),e(x_,PX),e(PX,_ko),e(x_,bko),e(se,vko),e(se,$_),e($_,q1e),e(q1e,Fko),e($_,Tko),e($_,BX),e(BX,Mko),e($_,Eko),e(se,Cko),e(se,k_),e(k_,j1e),e(j1e,wko),e(k_,Ako),e(k_,IX),e(IX,Lko),e(k_,yko),e(se,xko),e(se,S_),e(S_,D1e),e(D1e,$ko),e(S_,kko),e(S_,NX),e(NX,Sko),e(S_,Rko),e(Ze,Pko),M(R_,Ze,null),e(Ze,Bko),M(P_,Ze,null),e(Bo,Iko),e(Bo,B_),M(j$,B_,null),e(B_,Nko),e(B_,G1e),e(G1e,qko),b(c,nao,_),b(c,Rd,_),e(Rd,I_),e(I_,O1e),M(D$,O1e,null),e(Rd,jko),e(Rd,V1e),e(V1e,Dko),b(c,sao,_),b(c,Io,_),M(G$,Io,null),e(Io,Gko),e(Io,Pd),e(Pd,Oko),e(Pd,qX),e(qX,Vko),e(Pd,Xko),e(Pd,jX),e(jX,zko),e(Pd,Qko),e(Io,Wko),e(Io,O$),e(O$,Uko),e(O$,X1e),e(X1e,Hko),e(O$,Jko),e(Io,Yko),e(Io,Mt),M(V$,Mt,null),e(Mt,Zko),e(Mt,z1e),e(z1e,Kko),e(Mt,eSo),e(Mt,Bd),e(Bd,oSo),e(Bd,Q1e),e(Q1e,rSo),e(Bd,tSo),e(Bd,DX),e(DX,aSo),e(Bd,nSo),e(Mt,sSo),M(N_,Mt,null),e(Io,lSo),e(Io,Ke),M(X$,Ke,null),e(Ke,iSo),e(Ke,W1e),e(W1e,dSo),e(Ke,mSo),e(Ke,nn),e(nn,cSo),e(nn,U1e),e(U1e,fSo),e(nn,gSo),e(nn,H1e),e(H1e,hSo),e(nn,uSo),e(nn,J1e),e(J1e,pSo),e(nn,_So),e(Ke,bSo),e(Ke,y),e(y,q_),e(q_,Y1e),e(Y1e,vSo),e(q_,FSo),e(q_,GX),e(GX,TSo),e(q_,MSo),e(y,ESo),e(y,j_),e(j_,Z1e),e(Z1e,CSo),e(j_,wSo),e(j_,OX),e(OX,ASo),e(j_,LSo),e(y,ySo),e(y,D_),e(D_,K1e),e(K1e,xSo),e(D_,$So),e(D_,VX),e(VX,kSo),e(D_,SSo),e(y,RSo),e(y,G_),e(G_,e2e),e(e2e,PSo),e(G_,BSo),e(G_,XX),e(XX,ISo),e(G_,NSo),e(y,qSo),e(y,O_),e(O_,o2e),e(o2e,jSo),e(O_,DSo),e(O_,zX),e(zX,GSo),e(O_,OSo),e(y,VSo),e(y,V_),e(V_,r2e),e(r2e,XSo),e(V_,zSo),e(V_,QX),e(QX,QSo),e(V_,WSo),e(y,USo),e(y,X_),e(X_,t2e),e(t2e,HSo),e(X_,JSo),e(X_,WX),e(WX,YSo),e(X_,ZSo),e(y,KSo),e(y,z_),e(z_,a2e),e(a2e,eRo),e(z_,oRo),e(z_,UX),e(UX,rRo),e(z_,tRo),e(y,aRo),e(y,Q_),e(Q_,n2e),e(n2e,nRo),e(Q_,sRo),e(Q_,HX),e(HX,lRo),e(Q_,iRo),e(y,dRo),e(y,W_),e(W_,s2e),e(s2e,mRo),e(W_,cRo),e(W_,JX),e(JX,fRo),e(W_,gRo),e(y,hRo),e(y,U_),e(U_,l2e),e(l2e,uRo),e(U_,pRo),e(U_,YX),e(YX,_Ro),e(U_,bRo),e(y,vRo),e(y,H_),e(H_,i2e),e(i2e,FRo),e(H_,TRo),e(H_,ZX),e(ZX,MRo),e(H_,ERo),e(y,CRo),e(y,J_),e(J_,d2e),e(d2e,wRo),e(J_,ARo),e(J_,KX),e(KX,LRo),e(J_,yRo),e(y,xRo),e(y,Y_),e(Y_,m2e),e(m2e,$Ro),e(Y_,kRo),e(Y_,ez),e(ez,SRo),e(Y_,RRo),e(y,PRo),e(y,Z_),e(Z_,c2e),e(c2e,BRo),e(Z_,IRo),e(Z_,oz),e(oz,NRo),e(Z_,qRo),e(y,jRo),e(y,K_),e(K_,f2e),e(f2e,DRo),e(K_,GRo),e(K_,rz),e(rz,ORo),e(K_,VRo),e(y,XRo),e(y,e1),e(e1,g2e),e(g2e,zRo),e(e1,QRo),e(e1,tz),e(tz,WRo),e(e1,URo),e(y,HRo),e(y,o1),e(o1,h2e),e(h2e,JRo),e(o1,YRo),e(o1,az),e(az,ZRo),e(o1,KRo),e(y,ePo),e(y,r1),e(r1,u2e),e(u2e,oPo),e(r1,rPo),e(r1,nz),e(nz,tPo),e(r1,aPo),e(y,nPo),e(y,t1),e(t1,p2e),e(p2e,sPo),e(t1,lPo),e(t1,sz),e(sz,iPo),e(t1,dPo),e(y,mPo),e(y,a1),e(a1,_2e),e(_2e,cPo),e(a1,fPo),e(a1,lz),e(lz,gPo),e(a1,hPo),e(y,uPo),e(y,n1),e(n1,b2e),e(b2e,pPo),e(n1,_Po),e(n1,iz),e(iz,bPo),e(n1,vPo),e(y,FPo),e(y,s1),e(s1,v2e),e(v2e,TPo),e(s1,MPo),e(s1,dz),e(dz,EPo),e(s1,CPo),e(y,wPo),e(y,l1),e(l1,F2e),e(F2e,APo),e(l1,LPo),e(l1,mz),e(mz,yPo),e(l1,xPo),e(y,$Po),e(y,i1),e(i1,T2e),e(T2e,kPo),e(i1,SPo),e(i1,cz),e(cz,RPo),e(i1,PPo),e(y,BPo),e(y,d1),e(d1,M2e),e(M2e,IPo),e(d1,NPo),e(d1,fz),e(fz,qPo),e(d1,jPo),e(y,DPo),e(y,m1),e(m1,E2e),e(E2e,GPo),e(m1,OPo),e(m1,gz),e(gz,VPo),e(m1,XPo),e(y,zPo),e(y,c1),e(c1,C2e),e(C2e,QPo),e(c1,WPo),e(c1,hz),e(hz,UPo),e(c1,HPo),e(y,JPo),e(y,f1),e(f1,w2e),e(w2e,YPo),e(f1,ZPo),e(f1,uz),e(uz,KPo),e(f1,eBo),e(y,oBo),e(y,g1),e(g1,A2e),e(A2e,rBo),e(g1,tBo),e(g1,pz),e(pz,aBo),e(g1,nBo),e(y,sBo),e(y,h1),e(h1,L2e),e(L2e,lBo),e(h1,iBo),e(h1,_z),e(_z,dBo),e(h1,mBo),e(y,cBo),e(y,u1),e(u1,y2e),e(y2e,fBo),e(u1,gBo),e(u1,bz),e(bz,hBo),e(u1,uBo),e(y,pBo),e(y,p1),e(p1,x2e),e(x2e,_Bo),e(p1,bBo),e(p1,vz),e(vz,vBo),e(p1,FBo),e(y,TBo),e(y,_1),e(_1,$2e),e($2e,MBo),e(_1,EBo),e(_1,Fz),e(Fz,CBo),e(_1,wBo),e(y,ABo),e(y,b1),e(b1,k2e),e(k2e,LBo),e(b1,yBo),e(b1,Tz),e(Tz,xBo),e(b1,$Bo),e(y,kBo),e(y,v1),e(v1,S2e),e(S2e,SBo),e(v1,RBo),e(v1,Mz),e(Mz,PBo),e(v1,BBo),e(y,IBo),e(y,F1),e(F1,R2e),e(R2e,NBo),e(F1,qBo),e(F1,Ez),e(Ez,jBo),e(F1,DBo),e(y,GBo),e(y,T1),e(T1,P2e),e(P2e,OBo),e(T1,VBo),e(T1,Cz),e(Cz,XBo),e(T1,zBo),e(y,QBo),e(y,M1),e(M1,B2e),e(B2e,WBo),e(M1,UBo),e(M1,wz),e(wz,HBo),e(M1,JBo),e(y,YBo),e(y,E1),e(E1,I2e),e(I2e,ZBo),e(E1,KBo),e(E1,Az),e(Az,eIo),e(E1,oIo),e(y,rIo),e(y,$l),e($l,N2e),e(N2e,tIo),e($l,aIo),e($l,Lz),e(Lz,nIo),e($l,sIo),e($l,yz),e(yz,lIo),e($l,iIo),e(y,dIo),e(y,C1),e(C1,q2e),e(q2e,mIo),e(C1,cIo),e(C1,xz),e(xz,fIo),e(C1,gIo),e(y,hIo),e(y,w1),e(w1,j2e),e(j2e,uIo),e(w1,pIo),e(w1,$z),e($z,_Io),e(w1,bIo),e(y,vIo),e(y,A1),e(A1,D2e),e(D2e,FIo),e(A1,TIo),e(A1,kz),e(kz,MIo),e(A1,EIo),e(y,CIo),e(y,L1),e(L1,G2e),e(G2e,wIo),e(L1,AIo),e(L1,Sz),e(Sz,LIo),e(L1,yIo),e(y,xIo),e(y,y1),e(y1,O2e),e(O2e,$Io),e(y1,kIo),e(y1,Rz),e(Rz,SIo),e(y1,RIo),e(y,PIo),e(y,x1),e(x1,V2e),e(V2e,BIo),e(x1,IIo),e(x1,Pz),e(Pz,NIo),e(x1,qIo),e(y,jIo),e(y,$1),e($1,X2e),e(X2e,DIo),e($1,GIo),e($1,Bz),e(Bz,OIo),e($1,VIo),e(y,XIo),e(y,k1),e(k1,z2e),e(z2e,zIo),e(k1,QIo),e(k1,Iz),e(Iz,WIo),e(k1,UIo),e(y,HIo),e(y,S1),e(S1,Q2e),e(Q2e,JIo),e(S1,YIo),e(S1,Nz),e(Nz,ZIo),e(S1,KIo),e(y,eNo),e(y,R1),e(R1,W2e),e(W2e,oNo),e(R1,rNo),e(R1,qz),e(qz,tNo),e(R1,aNo),e(y,nNo),e(y,P1),e(P1,U2e),e(U2e,sNo),e(P1,lNo),e(P1,jz),e(jz,iNo),e(P1,dNo),e(y,mNo),e(y,B1),e(B1,H2e),e(H2e,cNo),e(B1,fNo),e(B1,Dz),e(Dz,gNo),e(B1,hNo),e(y,uNo),e(y,I1),e(I1,J2e),e(J2e,pNo),e(I1,_No),e(I1,Gz),e(Gz,bNo),e(I1,vNo),e(y,FNo),e(y,N1),e(N1,Y2e),e(Y2e,TNo),e(N1,MNo),e(N1,Oz),e(Oz,ENo),e(N1,CNo),e(y,wNo),e(y,q1),e(q1,Z2e),e(Z2e,ANo),e(q1,LNo),e(q1,Vz),e(Vz,yNo),e(q1,xNo),e(y,$No),e(y,j1),e(j1,K2e),e(K2e,kNo),e(j1,SNo),e(j1,Xz),e(Xz,RNo),e(j1,PNo),e(y,BNo),e(y,D1),e(D1,ebe),e(ebe,INo),e(D1,NNo),e(D1,zz),e(zz,qNo),e(D1,jNo),e(y,DNo),e(y,G1),e(G1,obe),e(obe,GNo),e(G1,ONo),e(G1,Qz),e(Qz,VNo),e(G1,XNo),e(y,zNo),e(y,O1),e(O1,rbe),e(rbe,QNo),e(O1,WNo),e(O1,Wz),e(Wz,UNo),e(O1,HNo),e(y,JNo),e(y,V1),e(V1,tbe),e(tbe,YNo),e(V1,ZNo),e(V1,Uz),e(Uz,KNo),e(V1,eqo),e(y,oqo),e(y,X1),e(X1,abe),e(abe,rqo),e(X1,tqo),e(X1,Hz),e(Hz,aqo),e(X1,nqo),e(y,sqo),e(y,z1),e(z1,nbe),e(nbe,lqo),e(z1,iqo),e(z1,Jz),e(Jz,dqo),e(z1,mqo),e(y,cqo),e(y,Q1),e(Q1,sbe),e(sbe,fqo),e(Q1,gqo),e(Q1,Yz),e(Yz,hqo),e(Q1,uqo),e(y,pqo),e(y,W1),e(W1,lbe),e(lbe,_qo),e(W1,bqo),e(W1,Zz),e(Zz,vqo),e(W1,Fqo),e(y,Tqo),e(y,U1),e(U1,ibe),e(ibe,Mqo),e(U1,Eqo),e(U1,Kz),e(Kz,Cqo),e(U1,wqo),e(y,Aqo),e(y,H1),e(H1,dbe),e(dbe,Lqo),e(H1,yqo),e(H1,eQ),e(eQ,xqo),e(H1,$qo),e(y,kqo),e(y,J1),e(J1,mbe),e(mbe,Sqo),e(J1,Rqo),e(J1,oQ),e(oQ,Pqo),e(J1,Bqo),e(y,Iqo),e(y,Y1),e(Y1,cbe),e(cbe,Nqo),e(Y1,qqo),e(Y1,rQ),e(rQ,jqo),e(Y1,Dqo),e(y,Gqo),e(y,Z1),e(Z1,fbe),e(fbe,Oqo),e(Z1,Vqo),e(Z1,tQ),e(tQ,Xqo),e(Z1,zqo),e(y,Qqo),e(y,K1),e(K1,gbe),e(gbe,Wqo),e(K1,Uqo),e(K1,aQ),e(aQ,Hqo),e(K1,Jqo),e(y,Yqo),e(y,e2),e(e2,hbe),e(hbe,Zqo),e(e2,Kqo),e(e2,nQ),e(nQ,ejo),e(e2,ojo),e(y,rjo),e(y,o2),e(o2,ube),e(ube,tjo),e(o2,ajo),e(o2,sQ),e(sQ,njo),e(o2,sjo),e(y,ljo),e(y,r2),e(r2,pbe),e(pbe,ijo),e(r2,djo),e(r2,lQ),e(lQ,mjo),e(r2,cjo),e(y,fjo),e(y,t2),e(t2,_be),e(_be,gjo),e(t2,hjo),e(t2,iQ),e(iQ,ujo),e(t2,pjo),e(y,_jo),e(y,a2),e(a2,bbe),e(bbe,bjo),e(a2,vjo),e(a2,dQ),e(dQ,Fjo),e(a2,Tjo),e(y,Mjo),e(y,n2),e(n2,vbe),e(vbe,Ejo),e(n2,Cjo),e(n2,mQ),e(mQ,wjo),e(n2,Ajo),e(y,Ljo),e(y,s2),e(s2,Fbe),e(Fbe,yjo),e(s2,xjo),e(s2,cQ),e(cQ,$jo),e(s2,kjo),e(y,Sjo),e(y,l2),e(l2,Tbe),e(Tbe,Rjo),e(l2,Pjo),e(l2,fQ),e(fQ,Bjo),e(l2,Ijo),e(y,Njo),e(y,i2),e(i2,Mbe),e(Mbe,qjo),e(i2,jjo),e(i2,gQ),e(gQ,Djo),e(i2,Gjo),e(y,Ojo),e(y,d2),e(d2,Ebe),e(Ebe,Vjo),e(d2,Xjo),e(d2,hQ),e(hQ,zjo),e(d2,Qjo),e(y,Wjo),e(y,m2),e(m2,Cbe),e(Cbe,Ujo),e(m2,Hjo),e(m2,uQ),e(uQ,Jjo),e(m2,Yjo),e(y,Zjo),e(y,c2),e(c2,wbe),e(wbe,Kjo),e(c2,eDo),e(c2,pQ),e(pQ,oDo),e(c2,rDo),e(y,tDo),e(y,f2),e(f2,Abe),e(Abe,aDo),e(f2,nDo),e(f2,_Q),e(_Q,sDo),e(f2,lDo),e(y,iDo),e(y,g2),e(g2,Lbe),e(Lbe,dDo),e(g2,mDo),e(g2,bQ),e(bQ,cDo),e(g2,fDo),e(y,gDo),e(y,h2),e(h2,ybe),e(ybe,hDo),e(h2,uDo),e(h2,vQ),e(vQ,pDo),e(h2,_Do),e(y,bDo),e(y,u2),e(u2,xbe),e(xbe,vDo),e(u2,FDo),e(u2,FQ),e(FQ,TDo),e(u2,MDo),e(y,EDo),e(y,p2),e(p2,$be),e($be,CDo),e(p2,wDo),e(p2,TQ),e(TQ,ADo),e(p2,LDo),e(y,yDo),e(y,_2),e(_2,kbe),e(kbe,xDo),e(_2,$Do),e(_2,MQ),e(MQ,kDo),e(_2,SDo),e(y,RDo),e(y,b2),e(b2,Sbe),e(Sbe,PDo),e(b2,BDo),e(b2,EQ),e(EQ,IDo),e(b2,NDo),e(y,qDo),e(y,v2),e(v2,Rbe),e(Rbe,jDo),e(v2,DDo),e(v2,CQ),e(CQ,GDo),e(v2,ODo),e(y,VDo),e(y,F2),e(F2,Pbe),e(Pbe,XDo),e(F2,zDo),e(F2,wQ),e(wQ,QDo),e(F2,WDo),e(y,UDo),e(y,T2),e(T2,Bbe),e(Bbe,HDo),e(T2,JDo),e(T2,AQ),e(AQ,YDo),e(T2,ZDo),e(y,KDo),e(y,M2),e(M2,Ibe),e(Ibe,eGo),e(M2,oGo),e(M2,LQ),e(LQ,rGo),e(M2,tGo),e(y,aGo),e(y,E2),e(E2,Nbe),e(Nbe,nGo),e(E2,sGo),e(E2,yQ),e(yQ,lGo),e(E2,iGo),e(y,dGo),e(y,C2),e(C2,qbe),e(qbe,mGo),e(C2,cGo),e(C2,xQ),e(xQ,fGo),e(C2,gGo),e(y,hGo),e(y,w2),e(w2,jbe),e(jbe,uGo),e(w2,pGo),e(w2,$Q),e($Q,_Go),e(w2,bGo),e(y,vGo),e(y,A2),e(A2,Dbe),e(Dbe,FGo),e(A2,TGo),e(A2,kQ),e(kQ,MGo),e(A2,EGo),e(y,CGo),e(y,L2),e(L2,Gbe),e(Gbe,wGo),e(L2,AGo),e(L2,SQ),e(SQ,LGo),e(L2,yGo),e(y,xGo),e(y,y2),e(y2,Obe),e(Obe,$Go),e(y2,kGo),e(y2,RQ),e(RQ,SGo),e(y2,RGo),e(y,PGo),e(y,x2),e(x2,Vbe),e(Vbe,BGo),e(x2,IGo),e(x2,PQ),e(PQ,NGo),e(x2,qGo),e(y,jGo),e(y,$2),e($2,Xbe),e(Xbe,DGo),e($2,GGo),e($2,BQ),e(BQ,OGo),e($2,VGo),e(y,XGo),e(y,k2),e(k2,zbe),e(zbe,zGo),e(k2,QGo),e(k2,IQ),e(IQ,WGo),e(k2,UGo),e(y,HGo),e(y,S2),e(S2,Qbe),e(Qbe,JGo),e(S2,YGo),e(S2,NQ),e(NQ,ZGo),e(S2,KGo),e(y,eOo),e(y,R2),e(R2,Wbe),e(Wbe,oOo),e(R2,rOo),e(R2,qQ),e(qQ,tOo),e(R2,aOo),e(y,nOo),e(y,P2),e(P2,Ube),e(Ube,sOo),e(P2,lOo),e(P2,jQ),e(jQ,iOo),e(P2,dOo),e(y,mOo),e(y,B2),e(B2,Hbe),e(Hbe,cOo),e(B2,fOo),e(B2,DQ),e(DQ,gOo),e(B2,hOo),e(y,uOo),e(y,I2),e(I2,Jbe),e(Jbe,pOo),e(I2,_Oo),e(I2,GQ),e(GQ,bOo),e(I2,vOo),e(y,FOo),e(y,N2),e(N2,Ybe),e(Ybe,TOo),e(N2,MOo),e(N2,OQ),e(OQ,EOo),e(N2,COo),e(y,wOo),e(y,q2),e(q2,Zbe),e(Zbe,AOo),e(q2,LOo),e(q2,VQ),e(VQ,yOo),e(q2,xOo),e(y,$Oo),e(y,j2),e(j2,Kbe),e(Kbe,kOo),e(j2,SOo),e(j2,XQ),e(XQ,ROo),e(j2,POo),e(y,BOo),e(y,D2),e(D2,eve),e(eve,IOo),e(D2,NOo),e(D2,zQ),e(zQ,qOo),e(D2,jOo),e(y,DOo),e(y,G2),e(G2,ove),e(ove,GOo),e(G2,OOo),e(G2,QQ),e(QQ,VOo),e(G2,XOo),e(y,zOo),e(y,O2),e(O2,rve),e(rve,QOo),e(O2,WOo),e(O2,WQ),e(WQ,UOo),e(O2,HOo),e(y,JOo),e(y,V2),e(V2,tve),e(tve,YOo),e(V2,ZOo),e(V2,UQ),e(UQ,KOo),e(V2,eVo),e(y,oVo),e(y,X2),e(X2,ave),e(ave,rVo),e(X2,tVo),e(X2,HQ),e(HQ,aVo),e(X2,nVo),e(y,sVo),e(y,z2),e(z2,nve),e(nve,lVo),e(z2,iVo),e(z2,JQ),e(JQ,dVo),e(z2,mVo),e(y,cVo),e(y,Q2),e(Q2,sve),e(sve,fVo),e(Q2,gVo),e(Q2,YQ),e(YQ,hVo),e(Q2,uVo),e(y,pVo),e(y,W2),e(W2,lve),e(lve,_Vo),e(W2,bVo),e(W2,ZQ),e(ZQ,vVo),e(W2,FVo),e(y,TVo),e(y,U2),e(U2,ive),e(ive,MVo),e(U2,EVo),e(U2,KQ),e(KQ,CVo),e(U2,wVo),e(y,AVo),e(y,H2),e(H2,dve),e(dve,LVo),e(H2,yVo),e(H2,eW),e(eW,xVo),e(H2,$Vo),e(y,kVo),e(y,J2),e(J2,mve),e(mve,SVo),e(J2,RVo),e(J2,oW),e(oW,PVo),e(J2,BVo),e(y,IVo),e(y,Y2),e(Y2,cve),e(cve,NVo),e(Y2,qVo),e(Y2,rW),e(rW,jVo),e(Y2,DVo),e(y,GVo),e(y,Z2),e(Z2,fve),e(fve,OVo),e(Z2,VVo),e(Z2,tW),e(tW,XVo),e(Z2,zVo),e(y,QVo),e(y,K2),e(K2,gve),e(gve,WVo),e(K2,UVo),e(K2,aW),e(aW,HVo),e(K2,JVo),e(y,YVo),e(y,eb),e(eb,hve),e(hve,ZVo),e(eb,KVo),e(eb,nW),e(nW,eXo),e(eb,oXo),e(y,rXo),e(y,ob),e(ob,uve),e(uve,tXo),e(ob,aXo),e(ob,sW),e(sW,nXo),e(ob,sXo),e(y,lXo),e(y,rb),e(rb,pve),e(pve,iXo),e(rb,dXo),e(rb,lW),e(lW,mXo),e(rb,cXo),e(y,fXo),e(y,tb),e(tb,_ve),e(_ve,gXo),e(tb,hXo),e(tb,iW),e(iW,uXo),e(tb,pXo),e(y,_Xo),e(y,ab),e(ab,bve),e(bve,bXo),e(ab,vXo),e(ab,dW),e(dW,FXo),e(ab,TXo),e(Ke,MXo),e(Ke,nb),e(nb,EXo),e(nb,vve),e(vve,CXo),e(nb,wXo),e(nb,Fve),e(Fve,AXo),e(Ke,LXo),M(sb,Ke,null),b(c,lao,_),b(c,Id,_),e(Id,lb),e(lb,Tve),M(z$,Tve,null),e(Id,yXo),e(Id,Mve),e(Mve,xXo),b(c,iao,_),b(c,No,_),M(Q$,No,null),e(No,$Xo),e(No,Nd),e(Nd,kXo),e(Nd,mW),e(mW,SXo),e(Nd,RXo),e(Nd,cW),e(cW,PXo),e(Nd,BXo),e(No,IXo),e(No,W$),e(W$,NXo),e(W$,Eve),e(Eve,qXo),e(W$,jXo),e(No,DXo),e(No,Et),M(U$,Et,null),e(Et,GXo),e(Et,Cve),e(Cve,OXo),e(Et,VXo),e(Et,qd),e(qd,XXo),e(qd,wve),e(wve,zXo),e(qd,QXo),e(qd,fW),e(fW,WXo),e(qd,UXo),e(Et,HXo),M(ib,Et,null),e(No,JXo),e(No,eo),M(H$,eo,null),e(eo,YXo),e(eo,Ave),e(Ave,ZXo),e(eo,KXo),e(eo,sn),e(sn,ezo),e(sn,Lve),e(Lve,ozo),e(sn,rzo),e(sn,yve),e(yve,tzo),e(sn,azo),e(sn,xve),e(xve,nzo),e(sn,szo),e(eo,lzo),e(eo,G),e(G,db),e(db,$ve),e($ve,izo),e(db,dzo),e(db,gW),e(gW,mzo),e(db,czo),e(G,fzo),e(G,mb),e(mb,kve),e(kve,gzo),e(mb,hzo),e(mb,hW),e(hW,uzo),e(mb,pzo),e(G,_zo),e(G,cb),e(cb,Sve),e(Sve,bzo),e(cb,vzo),e(cb,uW),e(uW,Fzo),e(cb,Tzo),e(G,Mzo),e(G,fb),e(fb,Rve),e(Rve,Ezo),e(fb,Czo),e(fb,pW),e(pW,wzo),e(fb,Azo),e(G,Lzo),e(G,gb),e(gb,Pve),e(Pve,yzo),e(gb,xzo),e(gb,_W),e(_W,$zo),e(gb,kzo),e(G,Szo),e(G,hb),e(hb,Bve),e(Bve,Rzo),e(hb,Pzo),e(hb,bW),e(bW,Bzo),e(hb,Izo),e(G,Nzo),e(G,ub),e(ub,Ive),e(Ive,qzo),e(ub,jzo),e(ub,vW),e(vW,Dzo),e(ub,Gzo),e(G,Ozo),e(G,pb),e(pb,Nve),e(Nve,Vzo),e(pb,Xzo),e(pb,FW),e(FW,zzo),e(pb,Qzo),e(G,Wzo),e(G,_b),e(_b,qve),e(qve,Uzo),e(_b,Hzo),e(_b,TW),e(TW,Jzo),e(_b,Yzo),e(G,Zzo),e(G,bb),e(bb,jve),e(jve,Kzo),e(bb,eQo),e(bb,MW),e(MW,oQo),e(bb,rQo),e(G,tQo),e(G,vb),e(vb,Dve),e(Dve,aQo),e(vb,nQo),e(vb,EW),e(EW,sQo),e(vb,lQo),e(G,iQo),e(G,Fb),e(Fb,Gve),e(Gve,dQo),e(Fb,mQo),e(Fb,CW),e(CW,cQo),e(Fb,fQo),e(G,gQo),e(G,Tb),e(Tb,Ove),e(Ove,hQo),e(Tb,uQo),e(Tb,wW),e(wW,pQo),e(Tb,_Qo),e(G,bQo),e(G,Mb),e(Mb,Vve),e(Vve,vQo),e(Mb,FQo),e(Mb,AW),e(AW,TQo),e(Mb,MQo),e(G,EQo),e(G,Eb),e(Eb,Xve),e(Xve,CQo),e(Eb,wQo),e(Eb,LW),e(LW,AQo),e(Eb,LQo),e(G,yQo),e(G,Cb),e(Cb,zve),e(zve,xQo),e(Cb,$Qo),e(Cb,yW),e(yW,kQo),e(Cb,SQo),e(G,RQo),e(G,wb),e(wb,Qve),e(Qve,PQo),e(wb,BQo),e(wb,xW),e(xW,IQo),e(wb,NQo),e(G,qQo),e(G,Ab),e(Ab,Wve),e(Wve,jQo),e(Ab,DQo),e(Ab,$W),e($W,GQo),e(Ab,OQo),e(G,VQo),e(G,Lb),e(Lb,Uve),e(Uve,XQo),e(Lb,zQo),e(Lb,kW),e(kW,QQo),e(Lb,WQo),e(G,UQo),e(G,yb),e(yb,Hve),e(Hve,HQo),e(yb,JQo),e(yb,SW),e(SW,YQo),e(yb,ZQo),e(G,KQo),e(G,xb),e(xb,Jve),e(Jve,eWo),e(xb,oWo),e(xb,RW),e(RW,rWo),e(xb,tWo),e(G,aWo),e(G,$b),e($b,Yve),e(Yve,nWo),e($b,sWo),e($b,PW),e(PW,lWo),e($b,iWo),e(G,dWo),e(G,kb),e(kb,Zve),e(Zve,mWo),e(kb,cWo),e(kb,BW),e(BW,fWo),e(kb,gWo),e(G,hWo),e(G,Sb),e(Sb,Kve),e(Kve,uWo),e(Sb,pWo),e(Sb,IW),e(IW,_Wo),e(Sb,bWo),e(G,vWo),e(G,Rb),e(Rb,eFe),e(eFe,FWo),e(Rb,TWo),e(Rb,NW),e(NW,MWo),e(Rb,EWo),e(G,CWo),e(G,Pb),e(Pb,oFe),e(oFe,wWo),e(Pb,AWo),e(Pb,qW),e(qW,LWo),e(Pb,yWo),e(G,xWo),e(G,Bb),e(Bb,rFe),e(rFe,$Wo),e(Bb,kWo),e(Bb,jW),e(jW,SWo),e(Bb,RWo),e(G,PWo),e(G,Ib),e(Ib,tFe),e(tFe,BWo),e(Ib,IWo),e(Ib,DW),e(DW,NWo),e(Ib,qWo),e(G,jWo),e(G,Nb),e(Nb,aFe),e(aFe,DWo),e(Nb,GWo),e(Nb,GW),e(GW,OWo),e(Nb,VWo),e(G,XWo),e(G,qb),e(qb,nFe),e(nFe,zWo),e(qb,QWo),e(qb,OW),e(OW,WWo),e(qb,UWo),e(G,HWo),e(G,jb),e(jb,sFe),e(sFe,JWo),e(jb,YWo),e(jb,VW),e(VW,ZWo),e(jb,KWo),e(G,eUo),e(G,Db),e(Db,lFe),e(lFe,oUo),e(Db,rUo),e(Db,XW),e(XW,tUo),e(Db,aUo),e(G,nUo),e(G,Gb),e(Gb,iFe),e(iFe,sUo),e(Gb,lUo),e(Gb,zW),e(zW,iUo),e(Gb,dUo),e(G,mUo),e(G,Ob),e(Ob,dFe),e(dFe,cUo),e(Ob,fUo),e(Ob,QW),e(QW,gUo),e(Ob,hUo),e(G,uUo),e(G,Vb),e(Vb,mFe),e(mFe,pUo),e(Vb,_Uo),e(Vb,WW),e(WW,bUo),e(Vb,vUo),e(G,FUo),e(G,Xb),e(Xb,cFe),e(cFe,TUo),e(Xb,MUo),e(Xb,UW),e(UW,EUo),e(Xb,CUo),e(G,wUo),e(G,zb),e(zb,fFe),e(fFe,AUo),e(zb,LUo),e(zb,HW),e(HW,yUo),e(zb,xUo),e(G,$Uo),e(G,Qb),e(Qb,gFe),e(gFe,kUo),e(Qb,SUo),e(Qb,JW),e(JW,RUo),e(Qb,PUo),e(G,BUo),e(G,Wb),e(Wb,hFe),e(hFe,IUo),e(Wb,NUo),e(Wb,YW),e(YW,qUo),e(Wb,jUo),e(G,DUo),e(G,Ub),e(Ub,uFe),e(uFe,GUo),e(Ub,OUo),e(Ub,ZW),e(ZW,VUo),e(Ub,XUo),e(G,zUo),e(G,Hb),e(Hb,pFe),e(pFe,QUo),e(Hb,WUo),e(Hb,KW),e(KW,UUo),e(Hb,HUo),e(G,JUo),e(G,Jb),e(Jb,_Fe),e(_Fe,YUo),e(Jb,ZUo),e(Jb,eU),e(eU,KUo),e(Jb,eHo),e(G,oHo),e(G,Yb),e(Yb,bFe),e(bFe,rHo),e(Yb,tHo),e(Yb,oU),e(oU,aHo),e(Yb,nHo),e(G,sHo),e(G,Zb),e(Zb,vFe),e(vFe,lHo),e(Zb,iHo),e(Zb,rU),e(rU,dHo),e(Zb,mHo),e(G,cHo),e(G,Kb),e(Kb,FFe),e(FFe,fHo),e(Kb,gHo),e(Kb,tU),e(tU,hHo),e(Kb,uHo),e(G,pHo),e(G,ev),e(ev,TFe),e(TFe,_Ho),e(ev,bHo),e(ev,aU),e(aU,vHo),e(ev,FHo),e(G,THo),e(G,ov),e(ov,MFe),e(MFe,MHo),e(ov,EHo),e(ov,nU),e(nU,CHo),e(ov,wHo),e(G,AHo),e(G,rv),e(rv,EFe),e(EFe,LHo),e(rv,yHo),e(rv,sU),e(sU,xHo),e(rv,$Ho),e(eo,kHo),e(eo,tv),e(tv,SHo),e(tv,CFe),e(CFe,RHo),e(tv,PHo),e(tv,wFe),e(wFe,BHo),e(eo,IHo),M(av,eo,null),b(c,dao,_),b(c,jd,_),e(jd,nv),e(nv,AFe),M(J$,AFe,null),e(jd,NHo),e(jd,LFe),e(LFe,qHo),b(c,mao,_),b(c,qo,_),M(Y$,qo,null),e(qo,jHo),e(qo,Dd),e(Dd,DHo),e(Dd,lU),e(lU,GHo),e(Dd,OHo),e(Dd,iU),e(iU,VHo),e(Dd,XHo),e(qo,zHo),e(qo,Z$),e(Z$,QHo),e(Z$,yFe),e(yFe,WHo),e(Z$,UHo),e(qo,HHo),e(qo,Ct),M(K$,Ct,null),e(Ct,JHo),e(Ct,xFe),e(xFe,YHo),e(Ct,ZHo),e(Ct,Gd),e(Gd,KHo),e(Gd,$Fe),e($Fe,eJo),e(Gd,oJo),e(Gd,dU),e(dU,rJo),e(Gd,tJo),e(Ct,aJo),M(sv,Ct,null),e(qo,nJo),e(qo,oo),M(ek,oo,null),e(oo,sJo),e(oo,kFe),e(kFe,lJo),e(oo,iJo),e(oo,ln),e(ln,dJo),e(ln,SFe),e(SFe,mJo),e(ln,cJo),e(ln,RFe),e(RFe,fJo),e(ln,gJo),e(ln,PFe),e(PFe,hJo),e(ln,uJo),e(oo,pJo),e(oo,W),e(W,lv),e(lv,BFe),e(BFe,_Jo),e(lv,bJo),e(lv,mU),e(mU,vJo),e(lv,FJo),e(W,TJo),e(W,iv),e(iv,IFe),e(IFe,MJo),e(iv,EJo),e(iv,cU),e(cU,CJo),e(iv,wJo),e(W,AJo),e(W,dv),e(dv,NFe),e(NFe,LJo),e(dv,yJo),e(dv,fU),e(fU,xJo),e(dv,$Jo),e(W,kJo),e(W,mv),e(mv,qFe),e(qFe,SJo),e(mv,RJo),e(mv,gU),e(gU,PJo),e(mv,BJo),e(W,IJo),e(W,cv),e(cv,jFe),e(jFe,NJo),e(cv,qJo),e(cv,hU),e(hU,jJo),e(cv,DJo),e(W,GJo),e(W,fv),e(fv,DFe),e(DFe,OJo),e(fv,VJo),e(fv,uU),e(uU,XJo),e(fv,zJo),e(W,QJo),e(W,gv),e(gv,GFe),e(GFe,WJo),e(gv,UJo),e(gv,pU),e(pU,HJo),e(gv,JJo),e(W,YJo),e(W,hv),e(hv,OFe),e(OFe,ZJo),e(hv,KJo),e(hv,_U),e(_U,eYo),e(hv,oYo),e(W,rYo),e(W,uv),e(uv,VFe),e(VFe,tYo),e(uv,aYo),e(uv,bU),e(bU,nYo),e(uv,sYo),e(W,lYo),e(W,pv),e(pv,XFe),e(XFe,iYo),e(pv,dYo),e(pv,vU),e(vU,mYo),e(pv,cYo),e(W,fYo),e(W,_v),e(_v,zFe),e(zFe,gYo),e(_v,hYo),e(_v,FU),e(FU,uYo),e(_v,pYo),e(W,_Yo),e(W,bv),e(bv,QFe),e(QFe,bYo),e(bv,vYo),e(bv,TU),e(TU,FYo),e(bv,TYo),e(W,MYo),e(W,vv),e(vv,WFe),e(WFe,EYo),e(vv,CYo),e(vv,MU),e(MU,wYo),e(vv,AYo),e(W,LYo),e(W,Fv),e(Fv,UFe),e(UFe,yYo),e(Fv,xYo),e(Fv,EU),e(EU,$Yo),e(Fv,kYo),e(W,SYo),e(W,Tv),e(Tv,HFe),e(HFe,RYo),e(Tv,PYo),e(Tv,CU),e(CU,BYo),e(Tv,IYo),e(W,NYo),e(W,Mv),e(Mv,JFe),e(JFe,qYo),e(Mv,jYo),e(Mv,wU),e(wU,DYo),e(Mv,GYo),e(W,OYo),e(W,Ev),e(Ev,YFe),e(YFe,VYo),e(Ev,XYo),e(Ev,AU),e(AU,zYo),e(Ev,QYo),e(W,WYo),e(W,Cv),e(Cv,ZFe),e(ZFe,UYo),e(Cv,HYo),e(Cv,LU),e(LU,JYo),e(Cv,YYo),e(W,ZYo),e(W,wv),e(wv,KFe),e(KFe,KYo),e(wv,eZo),e(wv,yU),e(yU,oZo),e(wv,rZo),e(W,tZo),e(W,Av),e(Av,eTe),e(eTe,aZo),e(Av,nZo),e(Av,xU),e(xU,sZo),e(Av,lZo),e(W,iZo),e(W,Lv),e(Lv,oTe),e(oTe,dZo),e(Lv,mZo),e(Lv,$U),e($U,cZo),e(Lv,fZo),e(W,gZo),e(W,yv),e(yv,rTe),e(rTe,hZo),e(yv,uZo),e(yv,kU),e(kU,pZo),e(yv,_Zo),e(W,bZo),e(W,xv),e(xv,tTe),e(tTe,vZo),e(xv,FZo),e(xv,SU),e(SU,TZo),e(xv,MZo),e(W,EZo),e(W,$v),e($v,aTe),e(aTe,CZo),e($v,wZo),e($v,RU),e(RU,AZo),e($v,LZo),e(W,yZo),e(W,kv),e(kv,nTe),e(nTe,xZo),e(kv,$Zo),e(kv,PU),e(PU,kZo),e(kv,SZo),e(W,RZo),e(W,Sv),e(Sv,sTe),e(sTe,PZo),e(Sv,BZo),e(Sv,BU),e(BU,IZo),e(Sv,NZo),e(W,qZo),e(W,Rv),e(Rv,lTe),e(lTe,jZo),e(Rv,DZo),e(Rv,IU),e(IU,GZo),e(Rv,OZo),e(W,VZo),e(W,Pv),e(Pv,iTe),e(iTe,XZo),e(Pv,zZo),e(Pv,NU),e(NU,QZo),e(Pv,WZo),e(W,UZo),e(W,Bv),e(Bv,dTe),e(dTe,HZo),e(Bv,JZo),e(Bv,qU),e(qU,YZo),e(Bv,ZZo),e(W,KZo),e(W,Iv),e(Iv,mTe),e(mTe,eKo),e(Iv,oKo),e(Iv,jU),e(jU,rKo),e(Iv,tKo),e(W,aKo),e(W,Nv),e(Nv,cTe),e(cTe,nKo),e(Nv,sKo),e(Nv,DU),e(DU,lKo),e(Nv,iKo),e(W,dKo),e(W,qv),e(qv,fTe),e(fTe,mKo),e(qv,cKo),e(qv,GU),e(GU,fKo),e(qv,gKo),e(W,hKo),e(W,jv),e(jv,gTe),e(gTe,uKo),e(jv,pKo),e(jv,OU),e(OU,_Ko),e(jv,bKo),e(W,vKo),e(W,Dv),e(Dv,hTe),e(hTe,FKo),e(Dv,TKo),e(Dv,VU),e(VU,MKo),e(Dv,EKo),e(W,CKo),e(W,Gv),e(Gv,uTe),e(uTe,wKo),e(Gv,AKo),e(Gv,XU),e(XU,LKo),e(Gv,yKo),e(W,xKo),e(W,Ov),e(Ov,pTe),e(pTe,$Ko),e(Ov,kKo),e(Ov,zU),e(zU,SKo),e(Ov,RKo),e(W,PKo),e(W,Vv),e(Vv,_Te),e(_Te,BKo),e(Vv,IKo),e(Vv,QU),e(QU,NKo),e(Vv,qKo),e(W,jKo),e(W,Xv),e(Xv,bTe),e(bTe,DKo),e(Xv,GKo),e(Xv,WU),e(WU,OKo),e(Xv,VKo),e(W,XKo),e(W,zv),e(zv,vTe),e(vTe,zKo),e(zv,QKo),e(zv,UU),e(UU,WKo),e(zv,UKo),e(W,HKo),e(W,Qv),e(Qv,FTe),e(FTe,JKo),e(Qv,YKo),e(Qv,HU),e(HU,ZKo),e(Qv,KKo),e(W,eer),e(W,Wv),e(Wv,TTe),e(TTe,oer),e(Wv,rer),e(Wv,JU),e(JU,ter),e(Wv,aer),e(W,ner),e(W,Uv),e(Uv,MTe),e(MTe,ser),e(Uv,ler),e(Uv,YU),e(YU,ier),e(Uv,der),e(oo,mer),e(oo,Hv),e(Hv,cer),e(Hv,ETe),e(ETe,fer),e(Hv,ger),e(Hv,CTe),e(CTe,her),e(oo,uer),M(Jv,oo,null),b(c,cao,_),b(c,Od,_),e(Od,Yv),e(Yv,wTe),M(ok,wTe,null),e(Od,per),e(Od,ATe),e(ATe,_er),b(c,fao,_),b(c,jo,_),M(rk,jo,null),e(jo,ber),e(jo,Vd),e(Vd,ver),e(Vd,ZU),e(ZU,Fer),e(Vd,Ter),e(Vd,KU),e(KU,Mer),e(Vd,Eer),e(jo,Cer),e(jo,tk),e(tk,wer),e(tk,LTe),e(LTe,Aer),e(tk,Ler),e(jo,yer),e(jo,wt),M(ak,wt,null),e(wt,xer),e(wt,yTe),e(yTe,$er),e(wt,ker),e(wt,Xd),e(Xd,Ser),e(Xd,xTe),e(xTe,Rer),e(Xd,Per),e(Xd,eH),e(eH,Ber),e(Xd,Ier),e(wt,Ner),M(Zv,wt,null),e(jo,qer),e(jo,ro),M(nk,ro,null),e(ro,jer),e(ro,$Te),e($Te,Der),e(ro,Ger),e(ro,dn),e(dn,Oer),e(dn,kTe),e(kTe,Ver),e(dn,Xer),e(dn,STe),e(STe,zer),e(dn,Qer),e(dn,RTe),e(RTe,Wer),e(dn,Uer),e(ro,Her),e(ro,sk),e(sk,Kv),e(Kv,PTe),e(PTe,Jer),e(Kv,Yer),e(Kv,oH),e(oH,Zer),e(Kv,Ker),e(sk,eor),e(sk,eF),e(eF,BTe),e(BTe,oor),e(eF,ror),e(eF,rH),e(rH,tor),e(eF,aor),e(ro,nor),e(ro,oF),e(oF,sor),e(oF,ITe),e(ITe,lor),e(oF,ior),e(oF,NTe),e(NTe,dor),e(ro,mor),M(rF,ro,null),b(c,gao,_),b(c,zd,_),e(zd,tF),e(tF,qTe),M(lk,qTe,null),e(zd,cor),e(zd,jTe),e(jTe,gor),b(c,hao,_),b(c,Do,_),M(ik,Do,null),e(Do,hor),e(Do,Qd),e(Qd,uor),e(Qd,tH),e(tH,por),e(Qd,_or),e(Qd,aH),e(aH,bor),e(Qd,vor),e(Do,For),e(Do,dk),e(dk,Tor),e(dk,DTe),e(DTe,Mor),e(dk,Eor),e(Do,Cor),e(Do,At),M(mk,At,null),e(At,wor),e(At,GTe),e(GTe,Aor),e(At,Lor),e(At,Wd),e(Wd,yor),e(Wd,OTe),e(OTe,xor),e(Wd,$or),e(Wd,nH),e(nH,kor),e(Wd,Sor),e(At,Ror),M(aF,At,null),e(Do,Por),e(Do,to),M(ck,to,null),e(to,Bor),e(to,VTe),e(VTe,Ior),e(to,Nor),e(to,mn),e(mn,qor),e(mn,XTe),e(XTe,jor),e(mn,Dor),e(mn,zTe),e(zTe,Gor),e(mn,Oor),e(mn,QTe),e(QTe,Vor),e(mn,Xor),e(to,zor),e(to,Y),e(Y,nF),e(nF,WTe),e(WTe,Qor),e(nF,Wor),e(nF,sH),e(sH,Uor),e(nF,Hor),e(Y,Jor),e(Y,sF),e(sF,UTe),e(UTe,Yor),e(sF,Zor),e(sF,lH),e(lH,Kor),e(sF,err),e(Y,orr),e(Y,lF),e(lF,HTe),e(HTe,rrr),e(lF,trr),e(lF,iH),e(iH,arr),e(lF,nrr),e(Y,srr),e(Y,iF),e(iF,JTe),e(JTe,lrr),e(iF,irr),e(iF,dH),e(dH,drr),e(iF,mrr),e(Y,crr),e(Y,dF),e(dF,YTe),e(YTe,frr),e(dF,grr),e(dF,mH),e(mH,hrr),e(dF,urr),e(Y,prr),e(Y,mF),e(mF,ZTe),e(ZTe,_rr),e(mF,brr),e(mF,cH),e(cH,vrr),e(mF,Frr),e(Y,Trr),e(Y,cF),e(cF,KTe),e(KTe,Mrr),e(cF,Err),e(cF,fH),e(fH,Crr),e(cF,wrr),e(Y,Arr),e(Y,fF),e(fF,eMe),e(eMe,Lrr),e(fF,yrr),e(fF,gH),e(gH,xrr),e(fF,$rr),e(Y,krr),e(Y,gF),e(gF,oMe),e(oMe,Srr),e(gF,Rrr),e(gF,hH),e(hH,Prr),e(gF,Brr),e(Y,Irr),e(Y,hF),e(hF,rMe),e(rMe,Nrr),e(hF,qrr),e(hF,uH),e(uH,jrr),e(hF,Drr),e(Y,Grr),e(Y,uF),e(uF,tMe),e(tMe,Orr),e(uF,Vrr),e(uF,pH),e(pH,Xrr),e(uF,zrr),e(Y,Qrr),e(Y,pF),e(pF,aMe),e(aMe,Wrr),e(pF,Urr),e(pF,_H),e(_H,Hrr),e(pF,Jrr),e(Y,Yrr),e(Y,_F),e(_F,nMe),e(nMe,Zrr),e(_F,Krr),e(_F,bH),e(bH,etr),e(_F,otr),e(Y,rtr),e(Y,bF),e(bF,sMe),e(sMe,ttr),e(bF,atr),e(bF,vH),e(vH,ntr),e(bF,str),e(Y,ltr),e(Y,vF),e(vF,lMe),e(lMe,itr),e(vF,dtr),e(vF,FH),e(FH,mtr),e(vF,ctr),e(Y,ftr),e(Y,FF),e(FF,iMe),e(iMe,gtr),e(FF,htr),e(FF,TH),e(TH,utr),e(FF,ptr),e(Y,_tr),e(Y,TF),e(TF,dMe),e(dMe,btr),e(TF,vtr),e(TF,MH),e(MH,Ftr),e(TF,Ttr),e(Y,Mtr),e(Y,MF),e(MF,mMe),e(mMe,Etr),e(MF,Ctr),e(MF,EH),e(EH,wtr),e(MF,Atr),e(Y,Ltr),e(Y,EF),e(EF,cMe),e(cMe,ytr),e(EF,xtr),e(EF,CH),e(CH,$tr),e(EF,ktr),e(Y,Str),e(Y,CF),e(CF,fMe),e(fMe,Rtr),e(CF,Ptr),e(CF,wH),e(wH,Btr),e(CF,Itr),e(Y,Ntr),e(Y,wF),e(wF,gMe),e(gMe,qtr),e(wF,jtr),e(wF,AH),e(AH,Dtr),e(wF,Gtr),e(Y,Otr),e(Y,AF),e(AF,hMe),e(hMe,Vtr),e(AF,Xtr),e(AF,LH),e(LH,ztr),e(AF,Qtr),e(Y,Wtr),e(Y,LF),e(LF,uMe),e(uMe,Utr),e(LF,Htr),e(LF,yH),e(yH,Jtr),e(LF,Ytr),e(Y,Ztr),e(Y,yF),e(yF,pMe),e(pMe,Ktr),e(yF,ear),e(yF,xH),e(xH,oar),e(yF,rar),e(Y,tar),e(Y,xF),e(xF,_Me),e(_Me,aar),e(xF,nar),e(xF,$H),e($H,sar),e(xF,lar),e(Y,iar),e(Y,$F),e($F,bMe),e(bMe,dar),e($F,mar),e($F,kH),e(kH,car),e($F,far),e(Y,gar),e(Y,kF),e(kF,vMe),e(vMe,har),e(kF,uar),e(kF,SH),e(SH,par),e(kF,_ar),e(Y,bar),e(Y,SF),e(SF,FMe),e(FMe,Far),e(SF,Tar),e(SF,RH),e(RH,Mar),e(SF,Ear),e(Y,Car),e(Y,RF),e(RF,TMe),e(TMe,war),e(RF,Aar),e(RF,PH),e(PH,Lar),e(RF,yar),e(Y,xar),e(Y,PF),e(PF,MMe),e(MMe,$ar),e(PF,kar),e(PF,BH),e(BH,Sar),e(PF,Rar),e(Y,Par),e(Y,BF),e(BF,EMe),e(EMe,Bar),e(BF,Iar),e(BF,IH),e(IH,Nar),e(BF,qar),e(Y,jar),e(Y,IF),e(IF,CMe),e(CMe,Dar),e(IF,Gar),e(IF,NH),e(NH,Oar),e(IF,Var),e(Y,Xar),e(Y,NF),e(NF,wMe),e(wMe,zar),e(NF,Qar),e(NF,qH),e(qH,War),e(NF,Uar),e(Y,Har),e(Y,qF),e(qF,AMe),e(AMe,Jar),e(qF,Yar),e(qF,jH),e(jH,Zar),e(qF,Kar),e(Y,enr),e(Y,jF),e(jF,LMe),e(LMe,onr),e(jF,rnr),e(jF,yMe),e(yMe,tnr),e(jF,anr),e(Y,nnr),e(Y,DF),e(DF,xMe),e(xMe,snr),e(DF,lnr),e(DF,DH),e(DH,inr),e(DF,dnr),e(Y,mnr),e(Y,GF),e(GF,$Me),e($Me,cnr),e(GF,fnr),e(GF,GH),e(GH,gnr),e(GF,hnr),e(Y,unr),e(Y,OF),e(OF,kMe),e(kMe,pnr),e(OF,_nr),e(OF,OH),e(OH,bnr),e(OF,vnr),e(Y,Fnr),e(Y,VF),e(VF,SMe),e(SMe,Tnr),e(VF,Mnr),e(VF,VH),e(VH,Enr),e(VF,Cnr),e(to,wnr),e(to,XF),e(XF,Anr),e(XF,RMe),e(RMe,Lnr),e(XF,ynr),e(XF,PMe),e(PMe,xnr),e(to,$nr),M(zF,to,null),b(c,uao,_),b(c,Ud,_),e(Ud,QF),e(QF,BMe),M(fk,BMe,null),e(Ud,knr),e(Ud,IMe),e(IMe,Snr),b(c,pao,_),b(c,Go,_),M(gk,Go,null),e(Go,Rnr),e(Go,Hd),e(Hd,Pnr),e(Hd,XH),e(XH,Bnr),e(Hd,Inr),e(Hd,zH),e(zH,Nnr),e(Hd,qnr),e(Go,jnr),e(Go,hk),e(hk,Dnr),e(hk,NMe),e(NMe,Gnr),e(hk,Onr),e(Go,Vnr),e(Go,Lt),M(uk,Lt,null),e(Lt,Xnr),e(Lt,qMe),e(qMe,znr),e(Lt,Qnr),e(Lt,Jd),e(Jd,Wnr),e(Jd,jMe),e(jMe,Unr),e(Jd,Hnr),e(Jd,QH),e(QH,Jnr),e(Jd,Ynr),e(Lt,Znr),M(WF,Lt,null),e(Go,Knr),e(Go,ao),M(pk,ao,null),e(ao,esr),e(ao,DMe),e(DMe,osr),e(ao,rsr),e(ao,cn),e(cn,tsr),e(cn,GMe),e(GMe,asr),e(cn,nsr),e(cn,OMe),e(OMe,ssr),e(cn,lsr),e(cn,VMe),e(VMe,isr),e(cn,dsr),e(ao,msr),e(ao,he),e(he,UF),e(UF,XMe),e(XMe,csr),e(UF,fsr),e(UF,WH),e(WH,gsr),e(UF,hsr),e(he,usr),e(he,HF),e(HF,zMe),e(zMe,psr),e(HF,_sr),e(HF,UH),e(UH,bsr),e(HF,vsr),e(he,Fsr),e(he,JF),e(JF,QMe),e(QMe,Tsr),e(JF,Msr),e(JF,HH),e(HH,Esr),e(JF,Csr),e(he,wsr),e(he,YF),e(YF,WMe),e(WMe,Asr),e(YF,Lsr),e(YF,JH),e(JH,ysr),e(YF,xsr),e(he,$sr),e(he,ZF),e(ZF,UMe),e(UMe,ksr),e(ZF,Ssr),e(ZF,YH),e(YH,Rsr),e(ZF,Psr),e(he,Bsr),e(he,KF),e(KF,HMe),e(HMe,Isr),e(KF,Nsr),e(KF,ZH),e(ZH,qsr),e(KF,jsr),e(he,Dsr),e(he,eT),e(eT,JMe),e(JMe,Gsr),e(eT,Osr),e(eT,KH),e(KH,Vsr),e(eT,Xsr),e(he,zsr),e(he,oT),e(oT,YMe),e(YMe,Qsr),e(oT,Wsr),e(oT,eJ),e(eJ,Usr),e(oT,Hsr),e(he,Jsr),e(he,rT),e(rT,ZMe),e(ZMe,Ysr),e(rT,Zsr),e(rT,oJ),e(oJ,Ksr),e(rT,elr),e(he,olr),e(he,tT),e(tT,KMe),e(KMe,rlr),e(tT,tlr),e(tT,rJ),e(rJ,alr),e(tT,nlr),e(he,slr),e(he,aT),e(aT,eEe),e(eEe,llr),e(aT,ilr),e(aT,tJ),e(tJ,dlr),e(aT,mlr),e(he,clr),e(he,nT),e(nT,oEe),e(oEe,flr),e(nT,glr),e(nT,aJ),e(aJ,hlr),e(nT,ulr),e(he,plr),e(he,sT),e(sT,rEe),e(rEe,_lr),e(sT,blr),e(sT,nJ),e(nJ,vlr),e(sT,Flr),e(he,Tlr),e(he,lT),e(lT,tEe),e(tEe,Mlr),e(lT,Elr),e(lT,sJ),e(sJ,Clr),e(lT,wlr),e(he,Alr),e(he,iT),e(iT,aEe),e(aEe,Llr),e(iT,ylr),e(iT,lJ),e(lJ,xlr),e(iT,$lr),e(he,klr),e(he,dT),e(dT,nEe),e(nEe,Slr),e(dT,Rlr),e(dT,iJ),e(iJ,Plr),e(dT,Blr),e(he,Ilr),e(he,mT),e(mT,sEe),e(sEe,Nlr),e(mT,qlr),e(mT,dJ),e(dJ,jlr),e(mT,Dlr),e(he,Glr),e(he,cT),e(cT,lEe),e(lEe,Olr),e(cT,Vlr),e(cT,mJ),e(mJ,Xlr),e(cT,zlr),e(he,Qlr),e(he,fT),e(fT,iEe),e(iEe,Wlr),e(fT,Ulr),e(fT,cJ),e(cJ,Hlr),e(fT,Jlr),e(he,Ylr),e(he,gT),e(gT,dEe),e(dEe,Zlr),e(gT,Klr),e(gT,fJ),e(fJ,eir),e(gT,oir),e(ao,rir),e(ao,hT),e(hT,tir),e(hT,mEe),e(mEe,air),e(hT,nir),e(hT,cEe),e(cEe,sir),e(ao,lir),M(uT,ao,null),b(c,_ao,_),b(c,Yd,_),e(Yd,pT),e(pT,fEe),M(_k,fEe,null),e(Yd,iir),e(Yd,gEe),e(gEe,dir),b(c,bao,_),b(c,Oo,_),M(bk,Oo,null),e(Oo,mir),e(Oo,Zd),e(Zd,cir),e(Zd,gJ),e(gJ,fir),e(Zd,gir),e(Zd,hJ),e(hJ,hir),e(Zd,uir),e(Oo,pir),e(Oo,vk),e(vk,_ir),e(vk,hEe),e(hEe,bir),e(vk,vir),e(Oo,Fir),e(Oo,yt),M(Fk,yt,null),e(yt,Tir),e(yt,uEe),e(uEe,Mir),e(yt,Eir),e(yt,Kd),e(Kd,Cir),e(Kd,pEe),e(pEe,wir),e(Kd,Air),e(Kd,uJ),e(uJ,Lir),e(Kd,yir),e(yt,xir),M(_T,yt,null),e(Oo,$ir),e(Oo,no),M(Tk,no,null),e(no,kir),e(no,_Ee),e(_Ee,Sir),e(no,Rir),e(no,fn),e(fn,Pir),e(fn,bEe),e(bEe,Bir),e(fn,Iir),e(fn,vEe),e(vEe,Nir),e(fn,qir),e(fn,FEe),e(FEe,jir),e(fn,Dir),e(no,Gir),e(no,j),e(j,bT),e(bT,TEe),e(TEe,Oir),e(bT,Vir),e(bT,pJ),e(pJ,Xir),e(bT,zir),e(j,Qir),e(j,vT),e(vT,MEe),e(MEe,Wir),e(vT,Uir),e(vT,_J),e(_J,Hir),e(vT,Jir),e(j,Yir),e(j,FT),e(FT,EEe),e(EEe,Zir),e(FT,Kir),e(FT,bJ),e(bJ,edr),e(FT,odr),e(j,rdr),e(j,TT),e(TT,CEe),e(CEe,tdr),e(TT,adr),e(TT,vJ),e(vJ,ndr),e(TT,sdr),e(j,ldr),e(j,MT),e(MT,wEe),e(wEe,idr),e(MT,ddr),e(MT,FJ),e(FJ,mdr),e(MT,cdr),e(j,fdr),e(j,ET),e(ET,AEe),e(AEe,gdr),e(ET,hdr),e(ET,TJ),e(TJ,udr),e(ET,pdr),e(j,_dr),e(j,CT),e(CT,LEe),e(LEe,bdr),e(CT,vdr),e(CT,MJ),e(MJ,Fdr),e(CT,Tdr),e(j,Mdr),e(j,wT),e(wT,yEe),e(yEe,Edr),e(wT,Cdr),e(wT,EJ),e(EJ,wdr),e(wT,Adr),e(j,Ldr),e(j,AT),e(AT,xEe),e(xEe,ydr),e(AT,xdr),e(AT,CJ),e(CJ,$dr),e(AT,kdr),e(j,Sdr),e(j,LT),e(LT,$Ee),e($Ee,Rdr),e(LT,Pdr),e(LT,wJ),e(wJ,Bdr),e(LT,Idr),e(j,Ndr),e(j,yT),e(yT,kEe),e(kEe,qdr),e(yT,jdr),e(yT,AJ),e(AJ,Ddr),e(yT,Gdr),e(j,Odr),e(j,xT),e(xT,SEe),e(SEe,Vdr),e(xT,Xdr),e(xT,LJ),e(LJ,zdr),e(xT,Qdr),e(j,Wdr),e(j,$T),e($T,REe),e(REe,Udr),e($T,Hdr),e($T,yJ),e(yJ,Jdr),e($T,Ydr),e(j,Zdr),e(j,kT),e(kT,PEe),e(PEe,Kdr),e(kT,emr),e(kT,xJ),e(xJ,omr),e(kT,rmr),e(j,tmr),e(j,ST),e(ST,BEe),e(BEe,amr),e(ST,nmr),e(ST,$J),e($J,smr),e(ST,lmr),e(j,imr),e(j,RT),e(RT,IEe),e(IEe,dmr),e(RT,mmr),e(RT,kJ),e(kJ,cmr),e(RT,fmr),e(j,gmr),e(j,PT),e(PT,NEe),e(NEe,hmr),e(PT,umr),e(PT,SJ),e(SJ,pmr),e(PT,_mr),e(j,bmr),e(j,BT),e(BT,qEe),e(qEe,vmr),e(BT,Fmr),e(BT,RJ),e(RJ,Tmr),e(BT,Mmr),e(j,Emr),e(j,IT),e(IT,jEe),e(jEe,Cmr),e(IT,wmr),e(IT,PJ),e(PJ,Amr),e(IT,Lmr),e(j,ymr),e(j,NT),e(NT,DEe),e(DEe,xmr),e(NT,$mr),e(NT,BJ),e(BJ,kmr),e(NT,Smr),e(j,Rmr),e(j,qT),e(qT,GEe),e(GEe,Pmr),e(qT,Bmr),e(qT,IJ),e(IJ,Imr),e(qT,Nmr),e(j,qmr),e(j,jT),e(jT,OEe),e(OEe,jmr),e(jT,Dmr),e(jT,NJ),e(NJ,Gmr),e(jT,Omr),e(j,Vmr),e(j,DT),e(DT,VEe),e(VEe,Xmr),e(DT,zmr),e(DT,qJ),e(qJ,Qmr),e(DT,Wmr),e(j,Umr),e(j,GT),e(GT,XEe),e(XEe,Hmr),e(GT,Jmr),e(GT,jJ),e(jJ,Ymr),e(GT,Zmr),e(j,Kmr),e(j,OT),e(OT,zEe),e(zEe,ecr),e(OT,ocr),e(OT,DJ),e(DJ,rcr),e(OT,tcr),e(j,acr),e(j,VT),e(VT,QEe),e(QEe,ncr),e(VT,scr),e(VT,GJ),e(GJ,lcr),e(VT,icr),e(j,dcr),e(j,XT),e(XT,WEe),e(WEe,mcr),e(XT,ccr),e(XT,OJ),e(OJ,fcr),e(XT,gcr),e(j,hcr),e(j,zT),e(zT,UEe),e(UEe,ucr),e(zT,pcr),e(zT,VJ),e(VJ,_cr),e(zT,bcr),e(j,vcr),e(j,QT),e(QT,HEe),e(HEe,Fcr),e(QT,Tcr),e(QT,XJ),e(XJ,Mcr),e(QT,Ecr),e(j,Ccr),e(j,WT),e(WT,JEe),e(JEe,wcr),e(WT,Acr),e(WT,zJ),e(zJ,Lcr),e(WT,ycr),e(j,xcr),e(j,UT),e(UT,YEe),e(YEe,$cr),e(UT,kcr),e(UT,QJ),e(QJ,Scr),e(UT,Rcr),e(j,Pcr),e(j,HT),e(HT,ZEe),e(ZEe,Bcr),e(HT,Icr),e(HT,WJ),e(WJ,Ncr),e(HT,qcr),e(j,jcr),e(j,JT),e(JT,KEe),e(KEe,Dcr),e(JT,Gcr),e(JT,UJ),e(UJ,Ocr),e(JT,Vcr),e(j,Xcr),e(j,YT),e(YT,e4e),e(e4e,zcr),e(YT,Qcr),e(YT,HJ),e(HJ,Wcr),e(YT,Ucr),e(j,Hcr),e(j,ZT),e(ZT,o4e),e(o4e,Jcr),e(ZT,Ycr),e(ZT,JJ),e(JJ,Zcr),e(ZT,Kcr),e(j,efr),e(j,KT),e(KT,r4e),e(r4e,ofr),e(KT,rfr),e(KT,YJ),e(YJ,tfr),e(KT,afr),e(j,nfr),e(j,eM),e(eM,t4e),e(t4e,sfr),e(eM,lfr),e(eM,ZJ),e(ZJ,ifr),e(eM,dfr),e(j,mfr),e(j,oM),e(oM,a4e),e(a4e,cfr),e(oM,ffr),e(oM,KJ),e(KJ,gfr),e(oM,hfr),e(j,ufr),e(j,rM),e(rM,n4e),e(n4e,pfr),e(rM,_fr),e(rM,eY),e(eY,bfr),e(rM,vfr),e(j,Ffr),e(j,tM),e(tM,s4e),e(s4e,Tfr),e(tM,Mfr),e(tM,oY),e(oY,Efr),e(tM,Cfr),e(j,wfr),e(j,aM),e(aM,l4e),e(l4e,Afr),e(aM,Lfr),e(aM,rY),e(rY,yfr),e(aM,xfr),e(j,$fr),e(j,nM),e(nM,i4e),e(i4e,kfr),e(nM,Sfr),e(nM,tY),e(tY,Rfr),e(nM,Pfr),e(j,Bfr),e(j,sM),e(sM,d4e),e(d4e,Ifr),e(sM,Nfr),e(sM,aY),e(aY,qfr),e(sM,jfr),e(j,Dfr),e(j,lM),e(lM,m4e),e(m4e,Gfr),e(lM,Ofr),e(lM,nY),e(nY,Vfr),e(lM,Xfr),e(j,zfr),e(j,iM),e(iM,c4e),e(c4e,Qfr),e(iM,Wfr),e(iM,sY),e(sY,Ufr),e(iM,Hfr),e(j,Jfr),e(j,dM),e(dM,f4e),e(f4e,Yfr),e(dM,Zfr),e(dM,lY),e(lY,Kfr),e(dM,egr),e(j,ogr),e(j,mM),e(mM,g4e),e(g4e,rgr),e(mM,tgr),e(mM,iY),e(iY,agr),e(mM,ngr),e(j,sgr),e(j,cM),e(cM,h4e),e(h4e,lgr),e(cM,igr),e(cM,dY),e(dY,dgr),e(cM,mgr),e(j,cgr),e(j,fM),e(fM,u4e),e(u4e,fgr),e(fM,ggr),e(fM,mY),e(mY,hgr),e(fM,ugr),e(j,pgr),e(j,gM),e(gM,p4e),e(p4e,_gr),e(gM,bgr),e(gM,cY),e(cY,vgr),e(gM,Fgr),e(j,Tgr),e(j,hM),e(hM,_4e),e(_4e,Mgr),e(hM,Egr),e(hM,fY),e(fY,Cgr),e(hM,wgr),e(j,Agr),e(j,uM),e(uM,b4e),e(b4e,Lgr),e(uM,ygr),e(uM,gY),e(gY,xgr),e(uM,$gr),e(j,kgr),e(j,pM),e(pM,v4e),e(v4e,Sgr),e(pM,Rgr),e(pM,hY),e(hY,Pgr),e(pM,Bgr),e(j,Igr),e(j,_M),e(_M,F4e),e(F4e,Ngr),e(_M,qgr),e(_M,uY),e(uY,jgr),e(_M,Dgr),e(j,Ggr),e(j,bM),e(bM,T4e),e(T4e,Ogr),e(bM,Vgr),e(bM,pY),e(pY,Xgr),e(bM,zgr),e(j,Qgr),e(j,vM),e(vM,M4e),e(M4e,Wgr),e(vM,Ugr),e(vM,_Y),e(_Y,Hgr),e(vM,Jgr),e(no,Ygr),e(no,FM),e(FM,Zgr),e(FM,E4e),e(E4e,Kgr),e(FM,ehr),e(FM,C4e),e(C4e,ohr),e(no,rhr),M(TM,no,null),b(c,vao,_),b(c,em,_),e(em,MM),e(MM,w4e),M(Mk,w4e,null),e(em,thr),e(em,A4e),e(A4e,ahr),b(c,Fao,_),b(c,Vo,_),M(Ek,Vo,null),e(Vo,nhr),e(Vo,om),e(om,shr),e(om,bY),e(bY,lhr),e(om,ihr),e(om,vY),e(vY,dhr),e(om,mhr),e(Vo,chr),e(Vo,Ck),e(Ck,fhr),e(Ck,L4e),e(L4e,ghr),e(Ck,hhr),e(Vo,uhr),e(Vo,xt),M(wk,xt,null),e(xt,phr),e(xt,y4e),e(y4e,_hr),e(xt,bhr),e(xt,rm),e(rm,vhr),e(rm,x4e),e(x4e,Fhr),e(rm,Thr),e(rm,FY),e(FY,Mhr),e(rm,Ehr),e(xt,Chr),M(EM,xt,null),e(Vo,whr),e(Vo,so),M(Ak,so,null),e(so,Ahr),e(so,$4e),e($4e,Lhr),e(so,yhr),e(so,gn),e(gn,xhr),e(gn,k4e),e(k4e,$hr),e(gn,khr),e(gn,S4e),e(S4e,Shr),e(gn,Rhr),e(gn,R4e),e(R4e,Phr),e(gn,Bhr),e(so,Ihr),e(so,K),e(K,CM),e(CM,P4e),e(P4e,Nhr),e(CM,qhr),e(CM,TY),e(TY,jhr),e(CM,Dhr),e(K,Ghr),e(K,wM),e(wM,B4e),e(B4e,Ohr),e(wM,Vhr),e(wM,MY),e(MY,Xhr),e(wM,zhr),e(K,Qhr),e(K,AM),e(AM,I4e),e(I4e,Whr),e(AM,Uhr),e(AM,EY),e(EY,Hhr),e(AM,Jhr),e(K,Yhr),e(K,LM),e(LM,N4e),e(N4e,Zhr),e(LM,Khr),e(LM,CY),e(CY,eur),e(LM,our),e(K,rur),e(K,yM),e(yM,q4e),e(q4e,tur),e(yM,aur),e(yM,wY),e(wY,nur),e(yM,sur),e(K,lur),e(K,xM),e(xM,j4e),e(j4e,iur),e(xM,dur),e(xM,AY),e(AY,mur),e(xM,cur),e(K,fur),e(K,$M),e($M,D4e),e(D4e,gur),e($M,hur),e($M,LY),e(LY,uur),e($M,pur),e(K,_ur),e(K,kM),e(kM,G4e),e(G4e,bur),e(kM,vur),e(kM,yY),e(yY,Fur),e(kM,Tur),e(K,Mur),e(K,SM),e(SM,O4e),e(O4e,Eur),e(SM,Cur),e(SM,xY),e(xY,wur),e(SM,Aur),e(K,Lur),e(K,RM),e(RM,V4e),e(V4e,yur),e(RM,xur),e(RM,$Y),e($Y,$ur),e(RM,kur),e(K,Sur),e(K,PM),e(PM,X4e),e(X4e,Rur),e(PM,Pur),e(PM,kY),e(kY,Bur),e(PM,Iur),e(K,Nur),e(K,BM),e(BM,z4e),e(z4e,qur),e(BM,jur),e(BM,SY),e(SY,Dur),e(BM,Gur),e(K,Our),e(K,IM),e(IM,Q4e),e(Q4e,Vur),e(IM,Xur),e(IM,RY),e(RY,zur),e(IM,Qur),e(K,Wur),e(K,NM),e(NM,W4e),e(W4e,Uur),e(NM,Hur),e(NM,PY),e(PY,Jur),e(NM,Yur),e(K,Zur),e(K,qM),e(qM,U4e),e(U4e,Kur),e(qM,epr),e(qM,BY),e(BY,opr),e(qM,rpr),e(K,tpr),e(K,jM),e(jM,H4e),e(H4e,apr),e(jM,npr),e(jM,IY),e(IY,spr),e(jM,lpr),e(K,ipr),e(K,DM),e(DM,J4e),e(J4e,dpr),e(DM,mpr),e(DM,NY),e(NY,cpr),e(DM,fpr),e(K,gpr),e(K,GM),e(GM,Y4e),e(Y4e,hpr),e(GM,upr),e(GM,qY),e(qY,ppr),e(GM,_pr),e(K,bpr),e(K,OM),e(OM,Z4e),e(Z4e,vpr),e(OM,Fpr),e(OM,jY),e(jY,Tpr),e(OM,Mpr),e(K,Epr),e(K,VM),e(VM,K4e),e(K4e,Cpr),e(VM,wpr),e(VM,DY),e(DY,Apr),e(VM,Lpr),e(K,ypr),e(K,XM),e(XM,eCe),e(eCe,xpr),e(XM,$pr),e(XM,GY),e(GY,kpr),e(XM,Spr),e(K,Rpr),e(K,zM),e(zM,oCe),e(oCe,Ppr),e(zM,Bpr),e(zM,OY),e(OY,Ipr),e(zM,Npr),e(K,qpr),e(K,QM),e(QM,rCe),e(rCe,jpr),e(QM,Dpr),e(QM,VY),e(VY,Gpr),e(QM,Opr),e(K,Vpr),e(K,WM),e(WM,tCe),e(tCe,Xpr),e(WM,zpr),e(WM,XY),e(XY,Qpr),e(WM,Wpr),e(K,Upr),e(K,UM),e(UM,aCe),e(aCe,Hpr),e(UM,Jpr),e(UM,zY),e(zY,Ypr),e(UM,Zpr),e(K,Kpr),e(K,HM),e(HM,nCe),e(nCe,e_r),e(HM,o_r),e(HM,QY),e(QY,r_r),e(HM,t_r),e(K,a_r),e(K,JM),e(JM,sCe),e(sCe,n_r),e(JM,s_r),e(JM,WY),e(WY,l_r),e(JM,i_r),e(K,d_r),e(K,YM),e(YM,lCe),e(lCe,m_r),e(YM,c_r),e(YM,UY),e(UY,f_r),e(YM,g_r),e(K,h_r),e(K,ZM),e(ZM,iCe),e(iCe,u_r),e(ZM,p_r),e(ZM,HY),e(HY,__r),e(ZM,b_r),e(K,v_r),e(K,KM),e(KM,dCe),e(dCe,F_r),e(KM,T_r),e(KM,JY),e(JY,M_r),e(KM,E_r),e(K,C_r),e(K,eE),e(eE,mCe),e(mCe,w_r),e(eE,A_r),e(eE,YY),e(YY,L_r),e(eE,y_r),e(K,x_r),e(K,oE),e(oE,cCe),e(cCe,$_r),e(oE,k_r),e(oE,ZY),e(ZY,S_r),e(oE,R_r),e(so,P_r),e(so,rE),e(rE,B_r),e(rE,fCe),e(fCe,I_r),e(rE,N_r),e(rE,gCe),e(gCe,q_r),e(so,j_r),M(tE,so,null),b(c,Tao,_),b(c,tm,_),e(tm,aE),e(aE,hCe),M(Lk,hCe,null),e(tm,D_r),e(tm,uCe),e(uCe,G_r),b(c,Mao,_),b(c,Xo,_),M(yk,Xo,null),e(Xo,O_r),e(Xo,am),e(am,V_r),e(am,KY),e(KY,X_r),e(am,z_r),e(am,eZ),e(eZ,Q_r),e(am,W_r),e(Xo,U_r),e(Xo,xk),e(xk,H_r),e(xk,pCe),e(pCe,J_r),e(xk,Y_r),e(Xo,Z_r),e(Xo,$t),M($k,$t,null),e($t,K_r),e($t,_Ce),e(_Ce,e1r),e($t,o1r),e($t,nm),e(nm,r1r),e(nm,bCe),e(bCe,t1r),e(nm,a1r),e(nm,oZ),e(oZ,n1r),e(nm,s1r),e($t,l1r),M(nE,$t,null),e(Xo,i1r),e(Xo,lo),M(kk,lo,null),e(lo,d1r),e(lo,vCe),e(vCe,m1r),e(lo,c1r),e(lo,hn),e(hn,f1r),e(hn,FCe),e(FCe,g1r),e(hn,h1r),e(hn,TCe),e(TCe,u1r),e(hn,p1r),e(hn,MCe),e(MCe,_1r),e(hn,b1r),e(lo,v1r),e(lo,Ue),e(Ue,sE),e(sE,ECe),e(ECe,F1r),e(sE,T1r),e(sE,rZ),e(rZ,M1r),e(sE,E1r),e(Ue,C1r),e(Ue,lE),e(lE,CCe),e(CCe,w1r),e(lE,A1r),e(lE,tZ),e(tZ,L1r),e(lE,y1r),e(Ue,x1r),e(Ue,iE),e(iE,wCe),e(wCe,$1r),e(iE,k1r),e(iE,aZ),e(aZ,S1r),e(iE,R1r),e(Ue,P1r),e(Ue,dE),e(dE,ACe),e(ACe,B1r),e(dE,I1r),e(dE,nZ),e(nZ,N1r),e(dE,q1r),e(Ue,j1r),e(Ue,mE),e(mE,LCe),e(LCe,D1r),e(mE,G1r),e(mE,sZ),e(sZ,O1r),e(mE,V1r),e(Ue,X1r),e(Ue,cE),e(cE,yCe),e(yCe,z1r),e(cE,Q1r),e(cE,lZ),e(lZ,W1r),e(cE,U1r),e(Ue,H1r),e(Ue,fE),e(fE,xCe),e(xCe,J1r),e(fE,Y1r),e(fE,iZ),e(iZ,Z1r),e(fE,K1r),e(lo,e2r),e(lo,gE),e(gE,o2r),e(gE,$Ce),e($Ce,r2r),e(gE,t2r),e(gE,kCe),e(kCe,a2r),e(lo,n2r),M(hE,lo,null),b(c,Eao,_),b(c,sm,_),e(sm,uE),e(uE,SCe),M(Sk,SCe,null),e(sm,s2r),e(sm,RCe),e(RCe,l2r),b(c,Cao,_),b(c,zo,_),M(Rk,zo,null),e(zo,i2r),e(zo,lm),e(lm,d2r),e(lm,dZ),e(dZ,m2r),e(lm,c2r),e(lm,mZ),e(mZ,f2r),e(lm,g2r),e(zo,h2r),e(zo,Pk),e(Pk,u2r),e(Pk,PCe),e(PCe,p2r),e(Pk,_2r),e(zo,b2r),e(zo,kt),M(Bk,kt,null),e(kt,v2r),e(kt,BCe),e(BCe,F2r),e(kt,T2r),e(kt,im),e(im,M2r),e(im,ICe),e(ICe,E2r),e(im,C2r),e(im,cZ),e(cZ,w2r),e(im,A2r),e(kt,L2r),M(pE,kt,null),e(zo,y2r),e(zo,io),M(Ik,io,null),e(io,x2r),e(io,NCe),e(NCe,$2r),e(io,k2r),e(io,un),e(un,S2r),e(un,qCe),e(qCe,R2r),e(un,P2r),e(un,jCe),e(jCe,B2r),e(un,I2r),e(un,DCe),e(DCe,N2r),e(un,q2r),e(io,j2r),e(io,U),e(U,_E),e(_E,GCe),e(GCe,D2r),e(_E,G2r),e(_E,fZ),e(fZ,O2r),e(_E,V2r),e(U,X2r),e(U,bE),e(bE,OCe),e(OCe,z2r),e(bE,Q2r),e(bE,gZ),e(gZ,W2r),e(bE,U2r),e(U,H2r),e(U,vE),e(vE,VCe),e(VCe,J2r),e(vE,Y2r),e(vE,hZ),e(hZ,Z2r),e(vE,K2r),e(U,ebr),e(U,FE),e(FE,XCe),e(XCe,obr),e(FE,rbr),e(FE,uZ),e(uZ,tbr),e(FE,abr),e(U,nbr),e(U,TE),e(TE,zCe),e(zCe,sbr),e(TE,lbr),e(TE,pZ),e(pZ,ibr),e(TE,dbr),e(U,mbr),e(U,ME),e(ME,QCe),e(QCe,cbr),e(ME,fbr),e(ME,_Z),e(_Z,gbr),e(ME,hbr),e(U,ubr),e(U,EE),e(EE,WCe),e(WCe,pbr),e(EE,_br),e(EE,bZ),e(bZ,bbr),e(EE,vbr),e(U,Fbr),e(U,CE),e(CE,UCe),e(UCe,Tbr),e(CE,Mbr),e(CE,vZ),e(vZ,Ebr),e(CE,Cbr),e(U,wbr),e(U,wE),e(wE,HCe),e(HCe,Abr),e(wE,Lbr),e(wE,FZ),e(FZ,ybr),e(wE,xbr),e(U,$br),e(U,AE),e(AE,JCe),e(JCe,kbr),e(AE,Sbr),e(AE,TZ),e(TZ,Rbr),e(AE,Pbr),e(U,Bbr),e(U,LE),e(LE,YCe),e(YCe,Ibr),e(LE,Nbr),e(LE,MZ),e(MZ,qbr),e(LE,jbr),e(U,Dbr),e(U,yE),e(yE,ZCe),e(ZCe,Gbr),e(yE,Obr),e(yE,EZ),e(EZ,Vbr),e(yE,Xbr),e(U,zbr),e(U,xE),e(xE,KCe),e(KCe,Qbr),e(xE,Wbr),e(xE,CZ),e(CZ,Ubr),e(xE,Hbr),e(U,Jbr),e(U,$E),e($E,e3e),e(e3e,Ybr),e($E,Zbr),e($E,wZ),e(wZ,Kbr),e($E,evr),e(U,ovr),e(U,kE),e(kE,o3e),e(o3e,rvr),e(kE,tvr),e(kE,AZ),e(AZ,avr),e(kE,nvr),e(U,svr),e(U,SE),e(SE,r3e),e(r3e,lvr),e(SE,ivr),e(SE,LZ),e(LZ,dvr),e(SE,mvr),e(U,cvr),e(U,RE),e(RE,t3e),e(t3e,fvr),e(RE,gvr),e(RE,yZ),e(yZ,hvr),e(RE,uvr),e(U,pvr),e(U,PE),e(PE,a3e),e(a3e,_vr),e(PE,bvr),e(PE,xZ),e(xZ,vvr),e(PE,Fvr),e(U,Tvr),e(U,BE),e(BE,n3e),e(n3e,Mvr),e(BE,Evr),e(BE,$Z),e($Z,Cvr),e(BE,wvr),e(U,Avr),e(U,IE),e(IE,s3e),e(s3e,Lvr),e(IE,yvr),e(IE,kZ),e(kZ,xvr),e(IE,$vr),e(U,kvr),e(U,NE),e(NE,l3e),e(l3e,Svr),e(NE,Rvr),e(NE,SZ),e(SZ,Pvr),e(NE,Bvr),e(U,Ivr),e(U,qE),e(qE,i3e),e(i3e,Nvr),e(qE,qvr),e(qE,RZ),e(RZ,jvr),e(qE,Dvr),e(U,Gvr),e(U,jE),e(jE,d3e),e(d3e,Ovr),e(jE,Vvr),e(jE,PZ),e(PZ,Xvr),e(jE,zvr),e(U,Qvr),e(U,DE),e(DE,m3e),e(m3e,Wvr),e(DE,Uvr),e(DE,BZ),e(BZ,Hvr),e(DE,Jvr),e(U,Yvr),e(U,GE),e(GE,c3e),e(c3e,Zvr),e(GE,Kvr),e(GE,IZ),e(IZ,eFr),e(GE,oFr),e(U,rFr),e(U,OE),e(OE,f3e),e(f3e,tFr),e(OE,aFr),e(OE,NZ),e(NZ,nFr),e(OE,sFr),e(U,lFr),e(U,VE),e(VE,g3e),e(g3e,iFr),e(VE,dFr),e(VE,qZ),e(qZ,mFr),e(VE,cFr),e(U,fFr),e(U,XE),e(XE,h3e),e(h3e,gFr),e(XE,hFr),e(XE,jZ),e(jZ,uFr),e(XE,pFr),e(U,_Fr),e(U,zE),e(zE,u3e),e(u3e,bFr),e(zE,vFr),e(zE,DZ),e(DZ,FFr),e(zE,TFr),e(U,MFr),e(U,QE),e(QE,p3e),e(p3e,EFr),e(QE,CFr),e(QE,GZ),e(GZ,wFr),e(QE,AFr),e(U,LFr),e(U,WE),e(WE,_3e),e(_3e,yFr),e(WE,xFr),e(WE,OZ),e(OZ,$Fr),e(WE,kFr),e(U,SFr),e(U,UE),e(UE,b3e),e(b3e,RFr),e(UE,PFr),e(UE,VZ),e(VZ,BFr),e(UE,IFr),e(U,NFr),e(U,HE),e(HE,v3e),e(v3e,qFr),e(HE,jFr),e(HE,XZ),e(XZ,DFr),e(HE,GFr),e(U,OFr),e(U,JE),e(JE,F3e),e(F3e,VFr),e(JE,XFr),e(JE,zZ),e(zZ,zFr),e(JE,QFr),e(U,WFr),e(U,YE),e(YE,T3e),e(T3e,UFr),e(YE,HFr),e(YE,QZ),e(QZ,JFr),e(YE,YFr),e(U,ZFr),e(U,ZE),e(ZE,M3e),e(M3e,KFr),e(ZE,eTr),e(ZE,WZ),e(WZ,oTr),e(ZE,rTr),e(U,tTr),e(U,KE),e(KE,E3e),e(E3e,aTr),e(KE,nTr),e(KE,UZ),e(UZ,sTr),e(KE,lTr),e(U,iTr),e(U,e4),e(e4,C3e),e(C3e,dTr),e(e4,mTr),e(e4,HZ),e(HZ,cTr),e(e4,fTr),e(U,gTr),e(U,o4),e(o4,w3e),e(w3e,hTr),e(o4,uTr),e(o4,JZ),e(JZ,pTr),e(o4,_Tr),e(U,bTr),e(U,r4),e(r4,A3e),e(A3e,vTr),e(r4,FTr),e(r4,YZ),e(YZ,TTr),e(r4,MTr),e(U,ETr),e(U,t4),e(t4,L3e),e(L3e,CTr),e(t4,wTr),e(t4,ZZ),e(ZZ,ATr),e(t4,LTr),e(io,yTr),e(io,a4),e(a4,xTr),e(a4,y3e),e(y3e,$Tr),e(a4,kTr),e(a4,x3e),e(x3e,STr),e(io,RTr),M(n4,io,null),b(c,wao,_),b(c,dm,_),e(dm,s4),e(s4,$3e),M(Nk,$3e,null),e(dm,PTr),e(dm,k3e),e(k3e,BTr),b(c,Aao,_),b(c,Qo,_),M(qk,Qo,null),e(Qo,ITr),e(Qo,mm),e(mm,NTr),e(mm,KZ),e(KZ,qTr),e(mm,jTr),e(mm,eK),e(eK,DTr),e(mm,GTr),e(Qo,OTr),e(Qo,jk),e(jk,VTr),e(jk,S3e),e(S3e,XTr),e(jk,zTr),e(Qo,QTr),e(Qo,St),M(Dk,St,null),e(St,WTr),e(St,R3e),e(R3e,UTr),e(St,HTr),e(St,cm),e(cm,JTr),e(cm,P3e),e(P3e,YTr),e(cm,ZTr),e(cm,oK),e(oK,KTr),e(cm,eMr),e(St,oMr),M(l4,St,null),e(Qo,rMr),e(Qo,mo),M(Gk,mo,null),e(mo,tMr),e(mo,B3e),e(B3e,aMr),e(mo,nMr),e(mo,pn),e(pn,sMr),e(pn,I3e),e(I3e,lMr),e(pn,iMr),e(pn,N3e),e(N3e,dMr),e(pn,mMr),e(pn,q3e),e(q3e,cMr),e(pn,fMr),e(mo,gMr),e(mo,O),e(O,i4),e(i4,j3e),e(j3e,hMr),e(i4,uMr),e(i4,rK),e(rK,pMr),e(i4,_Mr),e(O,bMr),e(O,d4),e(d4,D3e),e(D3e,vMr),e(d4,FMr),e(d4,tK),e(tK,TMr),e(d4,MMr),e(O,EMr),e(O,m4),e(m4,G3e),e(G3e,CMr),e(m4,wMr),e(m4,aK),e(aK,AMr),e(m4,LMr),e(O,yMr),e(O,c4),e(c4,O3e),e(O3e,xMr),e(c4,$Mr),e(c4,nK),e(nK,kMr),e(c4,SMr),e(O,RMr),e(O,f4),e(f4,V3e),e(V3e,PMr),e(f4,BMr),e(f4,sK),e(sK,IMr),e(f4,NMr),e(O,qMr),e(O,g4),e(g4,X3e),e(X3e,jMr),e(g4,DMr),e(g4,lK),e(lK,GMr),e(g4,OMr),e(O,VMr),e(O,h4),e(h4,z3e),e(z3e,XMr),e(h4,zMr),e(h4,iK),e(iK,QMr),e(h4,WMr),e(O,UMr),e(O,u4),e(u4,Q3e),e(Q3e,HMr),e(u4,JMr),e(u4,dK),e(dK,YMr),e(u4,ZMr),e(O,KMr),e(O,p4),e(p4,W3e),e(W3e,eEr),e(p4,oEr),e(p4,mK),e(mK,rEr),e(p4,tEr),e(O,aEr),e(O,_4),e(_4,U3e),e(U3e,nEr),e(_4,sEr),e(_4,cK),e(cK,lEr),e(_4,iEr),e(O,dEr),e(O,b4),e(b4,H3e),e(H3e,mEr),e(b4,cEr),e(b4,fK),e(fK,fEr),e(b4,gEr),e(O,hEr),e(O,v4),e(v4,J3e),e(J3e,uEr),e(v4,pEr),e(v4,gK),e(gK,_Er),e(v4,bEr),e(O,vEr),e(O,F4),e(F4,Y3e),e(Y3e,FEr),e(F4,TEr),e(F4,hK),e(hK,MEr),e(F4,EEr),e(O,CEr),e(O,T4),e(T4,Z3e),e(Z3e,wEr),e(T4,AEr),e(T4,uK),e(uK,LEr),e(T4,yEr),e(O,xEr),e(O,M4),e(M4,K3e),e(K3e,$Er),e(M4,kEr),e(M4,pK),e(pK,SEr),e(M4,REr),e(O,PEr),e(O,E4),e(E4,e5e),e(e5e,BEr),e(E4,IEr),e(E4,_K),e(_K,NEr),e(E4,qEr),e(O,jEr),e(O,C4),e(C4,o5e),e(o5e,DEr),e(C4,GEr),e(C4,bK),e(bK,OEr),e(C4,VEr),e(O,XEr),e(O,w4),e(w4,r5e),e(r5e,zEr),e(w4,QEr),e(w4,vK),e(vK,WEr),e(w4,UEr),e(O,HEr),e(O,A4),e(A4,t5e),e(t5e,JEr),e(A4,YEr),e(A4,FK),e(FK,ZEr),e(A4,KEr),e(O,e4r),e(O,L4),e(L4,a5e),e(a5e,o4r),e(L4,r4r),e(L4,TK),e(TK,t4r),e(L4,a4r),e(O,n4r),e(O,y4),e(y4,n5e),e(n5e,s4r),e(y4,l4r),e(y4,MK),e(MK,i4r),e(y4,d4r),e(O,m4r),e(O,x4),e(x4,s5e),e(s5e,c4r),e(x4,f4r),e(x4,EK),e(EK,g4r),e(x4,h4r),e(O,u4r),e(O,$4),e($4,l5e),e(l5e,p4r),e($4,_4r),e($4,CK),e(CK,b4r),e($4,v4r),e(O,F4r),e(O,k4),e(k4,i5e),e(i5e,T4r),e(k4,M4r),e(k4,wK),e(wK,E4r),e(k4,C4r),e(O,w4r),e(O,S4),e(S4,d5e),e(d5e,A4r),e(S4,L4r),e(S4,AK),e(AK,y4r),e(S4,x4r),e(O,$4r),e(O,R4),e(R4,m5e),e(m5e,k4r),e(R4,S4r),e(R4,LK),e(LK,R4r),e(R4,P4r),e(O,B4r),e(O,P4),e(P4,c5e),e(c5e,I4r),e(P4,N4r),e(P4,yK),e(yK,q4r),e(P4,j4r),e(O,D4r),e(O,B4),e(B4,f5e),e(f5e,G4r),e(B4,O4r),e(B4,xK),e(xK,V4r),e(B4,X4r),e(O,z4r),e(O,I4),e(I4,g5e),e(g5e,Q4r),e(I4,W4r),e(I4,$K),e($K,U4r),e(I4,H4r),e(O,J4r),e(O,N4),e(N4,h5e),e(h5e,Y4r),e(N4,Z4r),e(N4,kK),e(kK,K4r),e(N4,eCr),e(O,oCr),e(O,q4),e(q4,u5e),e(u5e,rCr),e(q4,tCr),e(q4,SK),e(SK,aCr),e(q4,nCr),e(O,sCr),e(O,j4),e(j4,p5e),e(p5e,lCr),e(j4,iCr),e(j4,RK),e(RK,dCr),e(j4,mCr),e(O,cCr),e(O,D4),e(D4,_5e),e(_5e,fCr),e(D4,gCr),e(D4,PK),e(PK,hCr),e(D4,uCr),e(O,pCr),e(O,G4),e(G4,b5e),e(b5e,_Cr),e(G4,bCr),e(G4,BK),e(BK,vCr),e(G4,FCr),e(O,TCr),e(O,O4),e(O4,v5e),e(v5e,MCr),e(O4,ECr),e(O4,IK),e(IK,CCr),e(O4,wCr),e(O,ACr),e(O,V4),e(V4,F5e),e(F5e,LCr),e(V4,yCr),e(V4,NK),e(NK,xCr),e(V4,$Cr),e(O,kCr),e(O,X4),e(X4,T5e),e(T5e,SCr),e(X4,RCr),e(X4,qK),e(qK,PCr),e(X4,BCr),e(O,ICr),e(O,z4),e(z4,M5e),e(M5e,NCr),e(z4,qCr),e(z4,jK),e(jK,jCr),e(z4,DCr),e(O,GCr),e(O,Q4),e(Q4,E5e),e(E5e,OCr),e(Q4,VCr),e(Q4,DK),e(DK,XCr),e(Q4,zCr),e(O,QCr),e(O,W4),e(W4,C5e),e(C5e,WCr),e(W4,UCr),e(W4,GK),e(GK,HCr),e(W4,JCr),e(O,YCr),e(O,U4),e(U4,w5e),e(w5e,ZCr),e(U4,KCr),e(U4,OK),e(OK,e3r),e(U4,o3r),e(O,r3r),e(O,H4),e(H4,A5e),e(A5e,t3r),e(H4,a3r),e(H4,VK),e(VK,n3r),e(H4,s3r),e(O,l3r),e(O,J4),e(J4,L5e),e(L5e,i3r),e(J4,d3r),e(J4,XK),e(XK,m3r),e(J4,c3r),e(O,f3r),e(O,Y4),e(Y4,y5e),e(y5e,g3r),e(Y4,h3r),e(Y4,zK),e(zK,u3r),e(Y4,p3r),e(O,_3r),e(O,Z4),e(Z4,x5e),e(x5e,b3r),e(Z4,v3r),e(Z4,QK),e(QK,F3r),e(Z4,T3r),e(O,M3r),e(O,K4),e(K4,$5e),e($5e,E3r),e(K4,C3r),e(K4,WK),e(WK,w3r),e(K4,A3r),e(O,L3r),e(O,eC),e(eC,k5e),e(k5e,y3r),e(eC,x3r),e(eC,UK),e(UK,$3r),e(eC,k3r),e(O,S3r),e(O,oC),e(oC,S5e),e(S5e,R3r),e(oC,P3r),e(oC,HK),e(HK,B3r),e(oC,I3r),e(mo,N3r),e(mo,rC),e(rC,q3r),e(rC,R5e),e(R5e,j3r),e(rC,D3r),e(rC,P5e),e(P5e,G3r),e(mo,O3r),M(tC,mo,null),b(c,Lao,_),b(c,fm,_),e(fm,aC),e(aC,B5e),M(Ok,B5e,null),e(fm,V3r),e(fm,I5e),e(I5e,X3r),b(c,yao,_),b(c,Wo,_),M(Vk,Wo,null),e(Wo,z3r),e(Wo,gm),e(gm,Q3r),e(gm,JK),e(JK,W3r),e(gm,U3r),e(gm,YK),e(YK,H3r),e(gm,J3r),e(Wo,Y3r),e(Wo,Xk),e(Xk,Z3r),e(Xk,N5e),e(N5e,K3r),e(Xk,e5r),e(Wo,o5r),e(Wo,Rt),M(zk,Rt,null),e(Rt,r5r),e(Rt,q5e),e(q5e,t5r),e(Rt,a5r),e(Rt,hm),e(hm,n5r),e(hm,j5e),e(j5e,s5r),e(hm,l5r),e(hm,ZK),e(ZK,i5r),e(hm,d5r),e(Rt,m5r),M(nC,Rt,null),e(Wo,c5r),e(Wo,co),M(Qk,co,null),e(co,f5r),e(co,D5e),e(D5e,g5r),e(co,h5r),e(co,_n),e(_n,u5r),e(_n,G5e),e(G5e,p5r),e(_n,_5r),e(_n,O5e),e(O5e,b5r),e(_n,v5r),e(_n,V5e),e(V5e,F5r),e(_n,T5r),e(co,M5r),e(co,X5e),e(X5e,sC),e(sC,z5e),e(z5e,E5r),e(sC,C5r),e(sC,KK),e(KK,w5r),e(sC,A5r),e(co,L5r),e(co,lC),e(lC,y5r),e(lC,Q5e),e(Q5e,x5r),e(lC,$5r),e(lC,W5e),e(W5e,k5r),e(co,S5r),M(iC,co,null),b(c,xao,_),b(c,um,_),e(um,dC),e(dC,U5e),M(Wk,U5e,null),e(um,R5r),e(um,H5e),e(H5e,P5r),b(c,$ao,_),b(c,Uo,_),M(Uk,Uo,null),e(Uo,B5r),e(Uo,pm),e(pm,I5r),e(pm,eee),e(eee,N5r),e(pm,q5r),e(pm,oee),e(oee,j5r),e(pm,D5r),e(Uo,G5r),e(Uo,Hk),e(Hk,O5r),e(Hk,J5e),e(J5e,V5r),e(Hk,X5r),e(Uo,z5r),e(Uo,Pt),M(Jk,Pt,null),e(Pt,Q5r),e(Pt,Y5e),e(Y5e,W5r),e(Pt,U5r),e(Pt,_m),e(_m,H5r),e(_m,Z5e),e(Z5e,J5r),e(_m,Y5r),e(_m,ree),e(ree,Z5r),e(_m,K5r),e(Pt,e0r),M(mC,Pt,null),e(Uo,o0r),e(Uo,fo),M(Yk,fo,null),e(fo,r0r),e(fo,K5e),e(K5e,t0r),e(fo,a0r),e(fo,bn),e(bn,n0r),e(bn,e0e),e(e0e,s0r),e(bn,l0r),e(bn,o0e),e(o0e,i0r),e(bn,d0r),e(bn,r0e),e(r0e,m0r),e(bn,c0r),e(fo,f0r),e(fo,bm),e(bm,cC),e(cC,t0e),e(t0e,g0r),e(cC,h0r),e(cC,tee),e(tee,u0r),e(cC,p0r),e(bm,_0r),e(bm,fC),e(fC,a0e),e(a0e,b0r),e(fC,v0r),e(fC,aee),e(aee,F0r),e(fC,T0r),e(bm,M0r),e(bm,gC),e(gC,n0e),e(n0e,E0r),e(gC,C0r),e(gC,nee),e(nee,w0r),e(gC,A0r),e(fo,L0r),e(fo,hC),e(hC,y0r),e(hC,s0e),e(s0e,x0r),e(hC,$0r),e(hC,l0e),e(l0e,k0r),e(fo,S0r),M(uC,fo,null),b(c,kao,_),b(c,vm,_),e(vm,pC),e(pC,i0e),M(Zk,i0e,null),e(vm,R0r),e(vm,d0e),e(d0e,P0r),b(c,Sao,_),b(c,Ho,_),M(Kk,Ho,null),e(Ho,B0r),e(Ho,Fm),e(Fm,I0r),e(Fm,see),e(see,N0r),e(Fm,q0r),e(Fm,lee),e(lee,j0r),e(Fm,D0r),e(Ho,G0r),e(Ho,eS),e(eS,O0r),e(eS,m0e),e(m0e,V0r),e(eS,X0r),e(Ho,z0r),e(Ho,Bt),M(oS,Bt,null),e(Bt,Q0r),e(Bt,c0e),e(c0e,W0r),e(Bt,U0r),e(Bt,Tm),e(Tm,H0r),e(Tm,f0e),e(f0e,J0r),e(Tm,Y0r),e(Tm,iee),e(iee,Z0r),e(Tm,K0r),e(Bt,ewr),M(_C,Bt,null),e(Ho,owr),e(Ho,go),M(rS,go,null),e(go,rwr),e(go,g0e),e(g0e,twr),e(go,awr),e(go,vn),e(vn,nwr),e(vn,h0e),e(h0e,swr),e(vn,lwr),e(vn,u0e),e(u0e,iwr),e(vn,dwr),e(vn,p0e),e(p0e,mwr),e(vn,cwr),e(go,fwr),e(go,be),e(be,bC),e(bC,_0e),e(_0e,gwr),e(bC,hwr),e(bC,dee),e(dee,uwr),e(bC,pwr),e(be,_wr),e(be,vC),e(vC,b0e),e(b0e,bwr),e(vC,vwr),e(vC,mee),e(mee,Fwr),e(vC,Twr),e(be,Mwr),e(be,FC),e(FC,v0e),e(v0e,Ewr),e(FC,Cwr),e(FC,cee),e(cee,wwr),e(FC,Awr),e(be,Lwr),e(be,TC),e(TC,F0e),e(F0e,ywr),e(TC,xwr),e(TC,fee),e(fee,$wr),e(TC,kwr),e(be,Swr),e(be,kl),e(kl,T0e),e(T0e,Rwr),e(kl,Pwr),e(kl,gee),e(gee,Bwr),e(kl,Iwr),e(kl,hee),e(hee,Nwr),e(kl,qwr),e(be,jwr),e(be,MC),e(MC,M0e),e(M0e,Dwr),e(MC,Gwr),e(MC,uee),e(uee,Owr),e(MC,Vwr),e(be,Xwr),e(be,Sl),e(Sl,E0e),e(E0e,zwr),e(Sl,Qwr),e(Sl,pee),e(pee,Wwr),e(Sl,Uwr),e(Sl,_ee),e(_ee,Hwr),e(Sl,Jwr),e(be,Ywr),e(be,EC),e(EC,C0e),e(C0e,Zwr),e(EC,Kwr),e(EC,bee),e(bee,eAr),e(EC,oAr),e(be,rAr),e(be,It),e(It,w0e),e(w0e,tAr),e(It,aAr),e(It,vee),e(vee,nAr),e(It,sAr),e(It,Fee),e(Fee,lAr),e(It,iAr),e(It,Tee),e(Tee,dAr),e(It,mAr),e(be,cAr),e(be,CC),e(CC,A0e),e(A0e,fAr),e(CC,gAr),e(CC,Mee),e(Mee,hAr),e(CC,uAr),e(be,pAr),e(be,wC),e(wC,L0e),e(L0e,_Ar),e(wC,bAr),e(wC,Eee),e(Eee,vAr),e(wC,FAr),e(be,TAr),e(be,AC),e(AC,y0e),e(y0e,MAr),e(AC,EAr),e(AC,Cee),e(Cee,CAr),e(AC,wAr),e(be,AAr),e(be,LC),e(LC,x0e),e(x0e,LAr),e(LC,yAr),e(LC,wee),e(wee,xAr),e(LC,$Ar),e(be,kAr),e(be,yC),e(yC,$0e),e($0e,SAr),e(yC,RAr),e(yC,Aee),e(Aee,PAr),e(yC,BAr),e(be,IAr),e(be,xC),e(xC,k0e),e(k0e,NAr),e(xC,qAr),e(xC,Lee),e(Lee,jAr),e(xC,DAr),e(be,GAr),e(be,$C),e($C,S0e),e(S0e,OAr),e($C,VAr),e($C,yee),e(yee,XAr),e($C,zAr),e(be,QAr),e(be,kC),e(kC,R0e),e(R0e,WAr),e(kC,UAr),e(kC,xee),e(xee,HAr),e(kC,JAr),e(be,YAr),e(be,SC),e(SC,P0e),e(P0e,ZAr),e(SC,KAr),e(SC,$ee),e($ee,e6r),e(SC,o6r),e(go,r6r),e(go,RC),e(RC,t6r),e(RC,B0e),e(B0e,a6r),e(RC,n6r),e(RC,I0e),e(I0e,s6r),e(go,l6r),M(PC,go,null),b(c,Rao,_),b(c,Mm,_),e(Mm,BC),e(BC,N0e),M(tS,N0e,null),e(Mm,i6r),e(Mm,q0e),e(q0e,d6r),b(c,Pao,_),b(c,Jo,_),M(aS,Jo,null),e(Jo,m6r),e(Jo,Em),e(Em,c6r),e(Em,kee),e(kee,f6r),e(Em,g6r),e(Em,See),e(See,h6r),e(Em,u6r),e(Jo,p6r),e(Jo,nS),e(nS,_6r),e(nS,j0e),e(j0e,b6r),e(nS,v6r),e(Jo,F6r),e(Jo,Nt),M(sS,Nt,null),e(Nt,T6r),e(Nt,D0e),e(D0e,M6r),e(Nt,E6r),e(Nt,Cm),e(Cm,C6r),e(Cm,G0e),e(G0e,w6r),e(Cm,A6r),e(Cm,Ree),e(Ree,L6r),e(Cm,y6r),e(Nt,x6r),M(IC,Nt,null),e(Jo,$6r),e(Jo,ho),M(lS,ho,null),e(ho,k6r),e(ho,O0e),e(O0e,S6r),e(ho,R6r),e(ho,Fn),e(Fn,P6r),e(Fn,V0e),e(V0e,B6r),e(Fn,I6r),e(Fn,X0e),e(X0e,N6r),e(Fn,q6r),e(Fn,z0e),e(z0e,j6r),e(Fn,D6r),e(ho,G6r),e(ho,Q0e),e(Q0e,NC),e(NC,W0e),e(W0e,O6r),e(NC,V6r),e(NC,Pee),e(Pee,X6r),e(NC,z6r),e(ho,Q6r),e(ho,qC),e(qC,W6r),e(qC,U0e),e(U0e,U6r),e(qC,H6r),e(qC,H0e),e(H0e,J6r),e(ho,Y6r),M(jC,ho,null),b(c,Bao,_),b(c,wm,_),e(wm,DC),e(DC,J0e),M(iS,J0e,null),e(wm,Z6r),e(wm,Y0e),e(Y0e,K6r),b(c,Iao,_),b(c,Yo,_),M(dS,Yo,null),e(Yo,e7r),e(Yo,Am),e(Am,o7r),e(Am,Bee),e(Bee,r7r),e(Am,t7r),e(Am,Iee),e(Iee,a7r),e(Am,n7r),e(Yo,s7r),e(Yo,mS),e(mS,l7r),e(mS,Z0e),e(Z0e,i7r),e(mS,d7r),e(Yo,m7r),e(Yo,qt),M(cS,qt,null),e(qt,c7r),e(qt,K0e),e(K0e,f7r),e(qt,g7r),e(qt,Lm),e(Lm,h7r),e(Lm,ewe),e(ewe,u7r),e(Lm,p7r),e(Lm,Nee),e(Nee,_7r),e(Lm,b7r),e(qt,v7r),M(GC,qt,null),e(Yo,F7r),e(Yo,uo),M(fS,uo,null),e(uo,T7r),e(uo,owe),e(owe,M7r),e(uo,E7r),e(uo,Tn),e(Tn,C7r),e(Tn,rwe),e(rwe,w7r),e(Tn,A7r),e(Tn,twe),e(twe,L7r),e(Tn,y7r),e(Tn,awe),e(awe,x7r),e(Tn,$7r),e(uo,k7r),e(uo,nwe),e(nwe,OC),e(OC,swe),e(swe,S7r),e(OC,R7r),e(OC,qee),e(qee,P7r),e(OC,B7r),e(uo,I7r),e(uo,VC),e(VC,N7r),e(VC,lwe),e(lwe,q7r),e(VC,j7r),e(VC,iwe),e(iwe,D7r),e(uo,G7r),M(XC,uo,null),b(c,Nao,_),b(c,ym,_),e(ym,zC),e(zC,dwe),M(gS,dwe,null),e(ym,O7r),e(ym,mwe),e(mwe,V7r),b(c,qao,_),b(c,Zo,_),M(hS,Zo,null),e(Zo,X7r),e(Zo,xm),e(xm,z7r),e(xm,jee),e(jee,Q7r),e(xm,W7r),e(xm,Dee),e(Dee,U7r),e(xm,H7r),e(Zo,J7r),e(Zo,uS),e(uS,Y7r),e(uS,cwe),e(cwe,Z7r),e(uS,K7r),e(Zo,e8r),e(Zo,jt),M(pS,jt,null),e(jt,o8r),e(jt,fwe),e(fwe,r8r),e(jt,t8r),e(jt,$m),e($m,a8r),e($m,gwe),e(gwe,n8r),e($m,s8r),e($m,Gee),e(Gee,l8r),e($m,i8r),e(jt,d8r),M(QC,jt,null),e(Zo,m8r),e(Zo,po),M(_S,po,null),e(po,c8r),e(po,hwe),e(hwe,f8r),e(po,g8r),e(po,Mn),e(Mn,h8r),e(Mn,uwe),e(uwe,u8r),e(Mn,p8r),e(Mn,pwe),e(pwe,_8r),e(Mn,b8r),e(Mn,_we),e(_we,v8r),e(Mn,F8r),e(po,T8r),e(po,bwe),e(bwe,WC),e(WC,vwe),e(vwe,M8r),e(WC,E8r),e(WC,Oee),e(Oee,C8r),e(WC,w8r),e(po,A8r),e(po,UC),e(UC,L8r),e(UC,Fwe),e(Fwe,y8r),e(UC,x8r),e(UC,Twe),e(Twe,$8r),e(po,k8r),M(HC,po,null),b(c,jao,_),b(c,km,_),e(km,JC),e(JC,Mwe),M(bS,Mwe,null),e(km,S8r),e(km,Ewe),e(Ewe,R8r),b(c,Dao,_),b(c,Ko,_),M(vS,Ko,null),e(Ko,P8r),e(Ko,Sm),e(Sm,B8r),e(Sm,Vee),e(Vee,I8r),e(Sm,N8r),e(Sm,Xee),e(Xee,q8r),e(Sm,j8r),e(Ko,D8r),e(Ko,FS),e(FS,G8r),e(FS,Cwe),e(Cwe,O8r),e(FS,V8r),e(Ko,X8r),e(Ko,Dt),M(TS,Dt,null),e(Dt,z8r),e(Dt,wwe),e(wwe,Q8r),e(Dt,W8r),e(Dt,Rm),e(Rm,U8r),e(Rm,Awe),e(Awe,H8r),e(Rm,J8r),e(Rm,zee),e(zee,Y8r),e(Rm,Z8r),e(Dt,K8r),M(YC,Dt,null),e(Ko,eLr),e(Ko,_o),M(MS,_o,null),e(_o,oLr),e(_o,Lwe),e(Lwe,rLr),e(_o,tLr),e(_o,En),e(En,aLr),e(En,ywe),e(ywe,nLr),e(En,sLr),e(En,xwe),e(xwe,lLr),e(En,iLr),e(En,$we),e($we,dLr),e(En,mLr),e(_o,cLr),e(_o,Be),e(Be,ZC),e(ZC,kwe),e(kwe,fLr),e(ZC,gLr),e(ZC,Qee),e(Qee,hLr),e(ZC,uLr),e(Be,pLr),e(Be,KC),e(KC,Swe),e(Swe,_Lr),e(KC,bLr),e(KC,Wee),e(Wee,vLr),e(KC,FLr),e(Be,TLr),e(Be,e3),e(e3,Rwe),e(Rwe,MLr),e(e3,ELr),e(e3,Uee),e(Uee,CLr),e(e3,wLr),e(Be,ALr),e(Be,o3),e(o3,Pwe),e(Pwe,LLr),e(o3,yLr),e(o3,Hee),e(Hee,xLr),e(o3,$Lr),e(Be,kLr),e(Be,r3),e(r3,Bwe),e(Bwe,SLr),e(r3,RLr),e(r3,Jee),e(Jee,PLr),e(r3,BLr),e(Be,ILr),e(Be,t3),e(t3,Iwe),e(Iwe,NLr),e(t3,qLr),e(t3,Yee),e(Yee,jLr),e(t3,DLr),e(Be,GLr),e(Be,a3),e(a3,Nwe),e(Nwe,OLr),e(a3,VLr),e(a3,Zee),e(Zee,XLr),e(a3,zLr),e(Be,QLr),e(Be,n3),e(n3,qwe),e(qwe,WLr),e(n3,ULr),e(n3,Kee),e(Kee,HLr),e(n3,JLr),e(Be,YLr),e(Be,s3),e(s3,jwe),e(jwe,ZLr),e(s3,KLr),e(s3,eoe),e(eoe,eyr),e(s3,oyr),e(_o,ryr),e(_o,l3),e(l3,tyr),e(l3,Dwe),e(Dwe,ayr),e(l3,nyr),e(l3,Gwe),e(Gwe,syr),e(_o,lyr),M(i3,_o,null),b(c,Gao,_),b(c,Pm,_),e(Pm,d3),e(d3,Owe),M(ES,Owe,null),e(Pm,iyr),e(Pm,Vwe),e(Vwe,dyr),b(c,Oao,_),b(c,er,_),M(CS,er,null),e(er,myr),e(er,Bm),e(Bm,cyr),e(Bm,ooe),e(ooe,fyr),e(Bm,gyr),e(Bm,roe),e(roe,hyr),e(Bm,uyr),e(er,pyr),e(er,wS),e(wS,_yr),e(wS,Xwe),e(Xwe,byr),e(wS,vyr),e(er,Fyr),e(er,Gt),M(AS,Gt,null),e(Gt,Tyr),e(Gt,zwe),e(zwe,Myr),e(Gt,Eyr),e(Gt,Im),e(Im,Cyr),e(Im,Qwe),e(Qwe,wyr),e(Im,Ayr),e(Im,toe),e(toe,Lyr),e(Im,yyr),e(Gt,xyr),M(m3,Gt,null),e(er,$yr),e(er,bo),M(LS,bo,null),e(bo,kyr),e(bo,Wwe),e(Wwe,Syr),e(bo,Ryr),e(bo,Cn),e(Cn,Pyr),e(Cn,Uwe),e(Uwe,Byr),e(Cn,Iyr),e(Cn,Hwe),e(Hwe,Nyr),e(Cn,qyr),e(Cn,Jwe),e(Jwe,jyr),e(Cn,Dyr),e(bo,Gyr),e(bo,ut),e(ut,c3),e(c3,Ywe),e(Ywe,Oyr),e(c3,Vyr),e(c3,aoe),e(aoe,Xyr),e(c3,zyr),e(ut,Qyr),e(ut,f3),e(f3,Zwe),e(Zwe,Wyr),e(f3,Uyr),e(f3,noe),e(noe,Hyr),e(f3,Jyr),e(ut,Yyr),e(ut,g3),e(g3,Kwe),e(Kwe,Zyr),e(g3,Kyr),e(g3,soe),e(soe,e9r),e(g3,o9r),e(ut,r9r),e(ut,h3),e(h3,eAe),e(eAe,t9r),e(h3,a9r),e(h3,loe),e(loe,n9r),e(h3,s9r),e(ut,l9r),e(ut,u3),e(u3,oAe),e(oAe,i9r),e(u3,d9r),e(u3,ioe),e(ioe,m9r),e(u3,c9r),e(bo,f9r),e(bo,p3),e(p3,g9r),e(p3,rAe),e(rAe,h9r),e(p3,u9r),e(p3,tAe),e(tAe,p9r),e(bo,_9r),M(_3,bo,null),b(c,Vao,_),b(c,Nm,_),e(Nm,b3),e(b3,aAe),M(yS,aAe,null),e(Nm,b9r),e(Nm,nAe),e(nAe,v9r),b(c,Xao,_),b(c,or,_),M(xS,or,null),e(or,F9r),e(or,qm),e(qm,T9r),e(qm,doe),e(doe,M9r),e(qm,E9r),e(qm,moe),e(moe,C9r),e(qm,w9r),e(or,A9r),e(or,$S),e($S,L9r),e($S,sAe),e(sAe,y9r),e($S,x9r),e(or,$9r),e(or,Ot),M(kS,Ot,null),e(Ot,k9r),e(Ot,lAe),e(lAe,S9r),e(Ot,R9r),e(Ot,jm),e(jm,P9r),e(jm,iAe),e(iAe,B9r),e(jm,I9r),e(jm,coe),e(coe,N9r),e(jm,q9r),e(Ot,j9r),M(v3,Ot,null),e(or,D9r),e(or,vo),M(SS,vo,null),e(vo,G9r),e(vo,dAe),e(dAe,O9r),e(vo,V9r),e(vo,wn),e(wn,X9r),e(wn,mAe),e(mAe,z9r),e(wn,Q9r),e(wn,cAe),e(cAe,W9r),e(wn,U9r),e(wn,fAe),e(fAe,H9r),e(wn,J9r),e(vo,Y9r),e(vo,Le),e(Le,F3),e(F3,gAe),e(gAe,Z9r),e(F3,K9r),e(F3,foe),e(foe,exr),e(F3,oxr),e(Le,rxr),e(Le,T3),e(T3,hAe),e(hAe,txr),e(T3,axr),e(T3,goe),e(goe,nxr),e(T3,sxr),e(Le,lxr),e(Le,M3),e(M3,uAe),e(uAe,ixr),e(M3,dxr),e(M3,hoe),e(hoe,mxr),e(M3,cxr),e(Le,fxr),e(Le,E3),e(E3,pAe),e(pAe,gxr),e(E3,hxr),e(E3,uoe),e(uoe,uxr),e(E3,pxr),e(Le,_xr),e(Le,C3),e(C3,_Ae),e(_Ae,bxr),e(C3,vxr),e(C3,poe),e(poe,Fxr),e(C3,Txr),e(Le,Mxr),e(Le,w3),e(w3,bAe),e(bAe,Exr),e(w3,Cxr),e(w3,_oe),e(_oe,wxr),e(w3,Axr),e(Le,Lxr),e(Le,A3),e(A3,vAe),e(vAe,yxr),e(A3,xxr),e(A3,boe),e(boe,$xr),e(A3,kxr),e(Le,Sxr),e(Le,L3),e(L3,FAe),e(FAe,Rxr),e(L3,Pxr),e(L3,voe),e(voe,Bxr),e(L3,Ixr),e(Le,Nxr),e(Le,y3),e(y3,TAe),e(TAe,qxr),e(y3,jxr),e(y3,Foe),e(Foe,Dxr),e(y3,Gxr),e(Le,Oxr),e(Le,x3),e(x3,MAe),e(MAe,Vxr),e(x3,Xxr),e(x3,Toe),e(Toe,zxr),e(x3,Qxr),e(vo,Wxr),e(vo,$3),e($3,Uxr),e($3,EAe),e(EAe,Hxr),e($3,Jxr),e($3,CAe),e(CAe,Yxr),e(vo,Zxr),M(k3,vo,null),b(c,zao,_),b(c,Dm,_),e(Dm,S3),e(S3,wAe),M(RS,wAe,null),e(Dm,Kxr),e(Dm,AAe),e(AAe,e$r),b(c,Qao,_),b(c,rr,_),M(PS,rr,null),e(rr,o$r),e(rr,Gm),e(Gm,r$r),e(Gm,Moe),e(Moe,t$r),e(Gm,a$r),e(Gm,Eoe),e(Eoe,n$r),e(Gm,s$r),e(rr,l$r),e(rr,BS),e(BS,i$r),e(BS,LAe),e(LAe,d$r),e(BS,m$r),e(rr,c$r),e(rr,Vt),M(IS,Vt,null),e(Vt,f$r),e(Vt,yAe),e(yAe,g$r),e(Vt,h$r),e(Vt,Om),e(Om,u$r),e(Om,xAe),e(xAe,p$r),e(Om,_$r),e(Om,Coe),e(Coe,b$r),e(Om,v$r),e(Vt,F$r),M(R3,Vt,null),e(rr,T$r),e(rr,Fo),M(NS,Fo,null),e(Fo,M$r),e(Fo,$Ae),e($Ae,E$r),e(Fo,C$r),e(Fo,An),e(An,w$r),e(An,kAe),e(kAe,A$r),e(An,L$r),e(An,SAe),e(SAe,y$r),e(An,x$r),e(An,RAe),e(RAe,$$r),e(An,k$r),e(Fo,S$r),e(Fo,Vm),e(Vm,P3),e(P3,PAe),e(PAe,R$r),e(P3,P$r),e(P3,woe),e(woe,B$r),e(P3,I$r),e(Vm,N$r),e(Vm,B3),e(B3,BAe),e(BAe,q$r),e(B3,j$r),e(B3,Aoe),e(Aoe,D$r),e(B3,G$r),e(Vm,O$r),e(Vm,I3),e(I3,IAe),e(IAe,V$r),e(I3,X$r),e(I3,Loe),e(Loe,z$r),e(I3,Q$r),e(Fo,W$r),e(Fo,N3),e(N3,U$r),e(N3,NAe),e(NAe,H$r),e(N3,J$r),e(N3,qAe),e(qAe,Y$r),e(Fo,Z$r),M(q3,Fo,null),b(c,Wao,_),b(c,Xm,_),e(Xm,j3),e(j3,jAe),M(qS,jAe,null),e(Xm,K$r),e(Xm,DAe),e(DAe,ekr),b(c,Uao,_),b(c,tr,_),M(jS,tr,null),e(tr,okr),e(tr,zm),e(zm,rkr),e(zm,yoe),e(yoe,tkr),e(zm,akr),e(zm,xoe),e(xoe,nkr),e(zm,skr),e(tr,lkr),e(tr,DS),e(DS,ikr),e(DS,GAe),e(GAe,dkr),e(DS,mkr),e(tr,ckr),e(tr,Xt),M(GS,Xt,null),e(Xt,fkr),e(Xt,OAe),e(OAe,gkr),e(Xt,hkr),e(Xt,Qm),e(Qm,ukr),e(Qm,VAe),e(VAe,pkr),e(Qm,_kr),e(Qm,$oe),e($oe,bkr),e(Qm,vkr),e(Xt,Fkr),M(D3,Xt,null),e(tr,Tkr),e(tr,To),M(OS,To,null),e(To,Mkr),e(To,XAe),e(XAe,Ekr),e(To,Ckr),e(To,Ln),e(Ln,wkr),e(Ln,zAe),e(zAe,Akr),e(Ln,Lkr),e(Ln,QAe),e(QAe,ykr),e(Ln,xkr),e(Ln,WAe),e(WAe,$kr),e(Ln,kkr),e(To,Skr),e(To,pt),e(pt,G3),e(G3,UAe),e(UAe,Rkr),e(G3,Pkr),e(G3,koe),e(koe,Bkr),e(G3,Ikr),e(pt,Nkr),e(pt,O3),e(O3,HAe),e(HAe,qkr),e(O3,jkr),e(O3,Soe),e(Soe,Dkr),e(O3,Gkr),e(pt,Okr),e(pt,V3),e(V3,JAe),e(JAe,Vkr),e(V3,Xkr),e(V3,Roe),e(Roe,zkr),e(V3,Qkr),e(pt,Wkr),e(pt,X3),e(X3,YAe),e(YAe,Ukr),e(X3,Hkr),e(X3,Poe),e(Poe,Jkr),e(X3,Ykr),e(pt,Zkr),e(pt,z3),e(z3,ZAe),e(ZAe,Kkr),e(z3,eSr),e(z3,Boe),e(Boe,oSr),e(z3,rSr),e(To,tSr),e(To,Q3),e(Q3,aSr),e(Q3,KAe),e(KAe,nSr),e(Q3,sSr),e(Q3,e6e),e(e6e,lSr),e(To,iSr),M(W3,To,null),b(c,Hao,_),b(c,Wm,_),e(Wm,U3),e(U3,o6e),M(VS,o6e,null),e(Wm,dSr),e(Wm,r6e),e(r6e,mSr),b(c,Jao,_),b(c,ar,_),M(XS,ar,null),e(ar,cSr),e(ar,Um),e(Um,fSr),e(Um,Ioe),e(Ioe,gSr),e(Um,hSr),e(Um,Noe),e(Noe,uSr),e(Um,pSr),e(ar,_Sr),e(ar,zS),e(zS,bSr),e(zS,t6e),e(t6e,vSr),e(zS,FSr),e(ar,TSr),e(ar,zt),M(QS,zt,null),e(zt,MSr),e(zt,a6e),e(a6e,ESr),e(zt,CSr),e(zt,Hm),e(Hm,wSr),e(Hm,n6e),e(n6e,ASr),e(Hm,LSr),e(Hm,qoe),e(qoe,ySr),e(Hm,xSr),e(zt,$Sr),M(H3,zt,null),e(ar,kSr),e(ar,Mo),M(WS,Mo,null),e(Mo,SSr),e(Mo,s6e),e(s6e,RSr),e(Mo,PSr),e(Mo,yn),e(yn,BSr),e(yn,l6e),e(l6e,ISr),e(yn,NSr),e(yn,i6e),e(i6e,qSr),e(yn,jSr),e(yn,d6e),e(d6e,DSr),e(yn,GSr),e(Mo,OSr),e(Mo,xn),e(xn,J3),e(J3,m6e),e(m6e,VSr),e(J3,XSr),e(J3,joe),e(joe,zSr),e(J3,QSr),e(xn,WSr),e(xn,Y3),e(Y3,c6e),e(c6e,USr),e(Y3,HSr),e(Y3,Doe),e(Doe,JSr),e(Y3,YSr),e(xn,ZSr),e(xn,Z3),e(Z3,f6e),e(f6e,KSr),e(Z3,eRr),e(Z3,Goe),e(Goe,oRr),e(Z3,rRr),e(xn,tRr),e(xn,K3),e(K3,g6e),e(g6e,aRr),e(K3,nRr),e(K3,Ooe),e(Ooe,sRr),e(K3,lRr),e(Mo,iRr),e(Mo,e5),e(e5,dRr),e(e5,h6e),e(h6e,mRr),e(e5,cRr),e(e5,u6e),e(u6e,fRr),e(Mo,gRr),M(o5,Mo,null),b(c,Yao,_),b(c,Jm,_),e(Jm,r5),e(r5,p6e),M(US,p6e,null),e(Jm,hRr),e(Jm,_6e),e(_6e,uRr),b(c,Zao,_),b(c,nr,_),M(HS,nr,null),e(nr,pRr),e(nr,Ym),e(Ym,_Rr),e(Ym,Voe),e(Voe,bRr),e(Ym,vRr),e(Ym,Xoe),e(Xoe,FRr),e(Ym,TRr),e(nr,MRr),e(nr,JS),e(JS,ERr),e(JS,b6e),e(b6e,CRr),e(JS,wRr),e(nr,ARr),e(nr,Qt),M(YS,Qt,null),e(Qt,LRr),e(Qt,v6e),e(v6e,yRr),e(Qt,xRr),e(Qt,Zm),e(Zm,$Rr),e(Zm,F6e),e(F6e,kRr),e(Zm,SRr),e(Zm,zoe),e(zoe,RRr),e(Zm,PRr),e(Qt,BRr),M(t5,Qt,null),e(nr,IRr),e(nr,Eo),M(ZS,Eo,null),e(Eo,NRr),e(Eo,T6e),e(T6e,qRr),e(Eo,jRr),e(Eo,$n),e($n,DRr),e($n,M6e),e(M6e,GRr),e($n,ORr),e($n,E6e),e(E6e,VRr),e($n,XRr),e($n,C6e),e(C6e,zRr),e($n,QRr),e(Eo,WRr),e(Eo,_t),e(_t,a5),e(a5,w6e),e(w6e,URr),e(a5,HRr),e(a5,Qoe),e(Qoe,JRr),e(a5,YRr),e(_t,ZRr),e(_t,n5),e(n5,A6e),e(A6e,KRr),e(n5,ePr),e(n5,Woe),e(Woe,oPr),e(n5,rPr),e(_t,tPr),e(_t,s5),e(s5,L6e),e(L6e,aPr),e(s5,nPr),e(s5,Uoe),e(Uoe,sPr),e(s5,lPr),e(_t,iPr),e(_t,l5),e(l5,y6e),e(y6e,dPr),e(l5,mPr),e(l5,Hoe),e(Hoe,cPr),e(l5,fPr),e(_t,gPr),e(_t,i5),e(i5,x6e),e(x6e,hPr),e(i5,uPr),e(i5,Joe),e(Joe,pPr),e(i5,_Pr),e(Eo,bPr),e(Eo,d5),e(d5,vPr),e(d5,$6e),e($6e,FPr),e(d5,TPr),e(d5,k6e),e(k6e,MPr),e(Eo,EPr),M(m5,Eo,null),b(c,Kao,_),b(c,Km,_),e(Km,c5),e(c5,S6e),M(KS,S6e,null),e(Km,CPr),e(Km,R6e),e(R6e,wPr),b(c,eno,_),b(c,sr,_),M(eR,sr,null),e(sr,APr),e(sr,ec),e(ec,LPr),e(ec,Yoe),e(Yoe,yPr),e(ec,xPr),e(ec,Zoe),e(Zoe,$Pr),e(ec,kPr),e(sr,SPr),e(sr,oR),e(oR,RPr),e(oR,P6e),e(P6e,PPr),e(oR,BPr),e(sr,IPr),e(sr,Wt),M(rR,Wt,null),e(Wt,NPr),e(Wt,B6e),e(B6e,qPr),e(Wt,jPr),e(Wt,oc),e(oc,DPr),e(oc,I6e),e(I6e,GPr),e(oc,OPr),e(oc,Koe),e(Koe,VPr),e(oc,XPr),e(Wt,zPr),M(f5,Wt,null),e(sr,QPr),e(sr,Co),M(tR,Co,null),e(Co,WPr),e(Co,N6e),e(N6e,UPr),e(Co,HPr),e(Co,kn),e(kn,JPr),e(kn,q6e),e(q6e,YPr),e(kn,ZPr),e(kn,j6e),e(j6e,KPr),e(kn,eBr),e(kn,D6e),e(D6e,oBr),e(kn,rBr),e(Co,tBr),e(Co,G6e),e(G6e,g5),e(g5,O6e),e(O6e,aBr),e(g5,nBr),e(g5,ere),e(ere,sBr),e(g5,lBr),e(Co,iBr),e(Co,h5),e(h5,dBr),e(h5,V6e),e(V6e,mBr),e(h5,cBr),e(h5,X6e),e(X6e,fBr),e(Co,gBr),M(u5,Co,null),b(c,ono,_),b(c,rc,_),e(rc,p5),e(p5,z6e),M(aR,z6e,null),e(rc,hBr),e(rc,Q6e),e(Q6e,uBr),b(c,rno,_),b(c,lr,_),M(nR,lr,null),e(lr,pBr),e(lr,tc),e(tc,_Br),e(tc,ore),e(ore,bBr),e(tc,vBr),e(tc,rre),e(rre,FBr),e(tc,TBr),e(lr,MBr),e(lr,sR),e(sR,EBr),e(sR,W6e),e(W6e,CBr),e(sR,wBr),e(lr,ABr),e(lr,Ut),M(lR,Ut,null),e(Ut,LBr),e(Ut,U6e),e(U6e,yBr),e(Ut,xBr),e(Ut,ac),e(ac,$Br),e(ac,H6e),e(H6e,kBr),e(ac,SBr),e(ac,tre),e(tre,RBr),e(ac,PBr),e(Ut,BBr),M(_5,Ut,null),e(lr,IBr),e(lr,wo),M(iR,wo,null),e(wo,NBr),e(wo,J6e),e(J6e,qBr),e(wo,jBr),e(wo,Sn),e(Sn,DBr),e(Sn,Y6e),e(Y6e,GBr),e(Sn,OBr),e(Sn,Z6e),e(Z6e,VBr),e(Sn,XBr),e(Sn,K6e),e(K6e,zBr),e(Sn,QBr),e(wo,WBr),e(wo,bt),e(bt,b5),e(b5,e7e),e(e7e,UBr),e(b5,HBr),e(b5,are),e(are,JBr),e(b5,YBr),e(bt,ZBr),e(bt,v5),e(v5,o7e),e(o7e,KBr),e(v5,eIr),e(v5,nre),e(nre,oIr),e(v5,rIr),e(bt,tIr),e(bt,F5),e(F5,r7e),e(r7e,aIr),e(F5,nIr),e(F5,sre),e(sre,sIr),e(F5,lIr),e(bt,iIr),e(bt,T5),e(T5,t7e),e(t7e,dIr),e(T5,mIr),e(T5,lre),e(lre,cIr),e(T5,fIr),e(bt,gIr),e(bt,M5),e(M5,a7e),e(a7e,hIr),e(M5,uIr),e(M5,ire),e(ire,pIr),e(M5,_Ir),e(wo,bIr),e(wo,E5),e(E5,vIr),e(E5,n7e),e(n7e,FIr),e(E5,TIr),e(E5,s7e),e(s7e,MIr),e(wo,EIr),M(C5,wo,null),b(c,tno,_),b(c,nc,_),e(nc,w5),e(w5,l7e),M(dR,l7e,null),e(nc,CIr),e(nc,i7e),e(i7e,wIr),b(c,ano,_),b(c,ir,_),M(mR,ir,null),e(ir,AIr),e(ir,sc),e(sc,LIr),e(sc,dre),e(dre,yIr),e(sc,xIr),e(sc,mre),e(mre,$Ir),e(sc,kIr),e(ir,SIr),e(ir,cR),e(cR,RIr),e(cR,d7e),e(d7e,PIr),e(cR,BIr),e(ir,IIr),e(ir,Ht),M(fR,Ht,null),e(Ht,NIr),e(Ht,m7e),e(m7e,qIr),e(Ht,jIr),e(Ht,lc),e(lc,DIr),e(lc,c7e),e(c7e,GIr),e(lc,OIr),e(lc,cre),e(cre,VIr),e(lc,XIr),e(Ht,zIr),M(A5,Ht,null),e(ir,QIr),e(ir,Ao),M(gR,Ao,null),e(Ao,WIr),e(Ao,f7e),e(f7e,UIr),e(Ao,HIr),e(Ao,Rn),e(Rn,JIr),e(Rn,g7e),e(g7e,YIr),e(Rn,ZIr),e(Rn,h7e),e(h7e,KIr),e(Rn,eNr),e(Rn,u7e),e(u7e,oNr),e(Rn,rNr),e(Ao,tNr),e(Ao,p7e),e(p7e,L5),e(L5,_7e),e(_7e,aNr),e(L5,nNr),e(L5,fre),e(fre,sNr),e(L5,lNr),e(Ao,iNr),e(Ao,y5),e(y5,dNr),e(y5,b7e),e(b7e,mNr),e(y5,cNr),e(y5,v7e),e(v7e,fNr),e(Ao,gNr),M(x5,Ao,null),b(c,nno,_),b(c,ic,_),e(ic,$5),e($5,F7e),M(hR,F7e,null),e(ic,hNr),e(ic,T7e),e(T7e,uNr),b(c,sno,_),b(c,dr,_),M(uR,dr,null),e(dr,pNr),e(dr,dc),e(dc,_Nr),e(dc,gre),e(gre,bNr),e(dc,vNr),e(dc,hre),e(hre,FNr),e(dc,TNr),e(dr,MNr),e(dr,pR),e(pR,ENr),e(pR,M7e),e(M7e,CNr),e(pR,wNr),e(dr,ANr),e(dr,Jt),M(_R,Jt,null),e(Jt,LNr),e(Jt,E7e),e(E7e,yNr),e(Jt,xNr),e(Jt,mc),e(mc,$Nr),e(mc,C7e),e(C7e,kNr),e(mc,SNr),e(mc,ure),e(ure,RNr),e(mc,PNr),e(Jt,BNr),M(k5,Jt,null),e(dr,INr),e(dr,Lo),M(bR,Lo,null),e(Lo,NNr),e(Lo,w7e),e(w7e,qNr),e(Lo,jNr),e(Lo,Pn),e(Pn,DNr),e(Pn,A7e),e(A7e,GNr),e(Pn,ONr),e(Pn,L7e),e(L7e,VNr),e(Pn,XNr),e(Pn,y7e),e(y7e,zNr),e(Pn,QNr),e(Lo,WNr),e(Lo,x7e),e(x7e,S5),e(S5,$7e),e($7e,UNr),e(S5,HNr),e(S5,pre),e(pre,JNr),e(S5,YNr),e(Lo,ZNr),e(Lo,R5),e(R5,KNr),e(R5,k7e),e(k7e,eqr),e(R5,oqr),e(R5,S7e),e(S7e,rqr),e(Lo,tqr),M(P5,Lo,null),b(c,lno,_),b(c,cc,_),e(cc,B5),e(B5,R7e),M(vR,R7e,null),e(cc,aqr),e(cc,P7e),e(P7e,nqr),b(c,ino,_),b(c,mr,_),M(FR,mr,null),e(mr,sqr),e(mr,fc),e(fc,lqr),e(fc,_re),e(_re,iqr),e(fc,dqr),e(fc,bre),e(bre,mqr),e(fc,cqr),e(mr,fqr),e(mr,TR),e(TR,gqr),e(TR,B7e),e(B7e,hqr),e(TR,uqr),e(mr,pqr),e(mr,Yt),M(MR,Yt,null),e(Yt,_qr),e(Yt,I7e),e(I7e,bqr),e(Yt,vqr),e(Yt,gc),e(gc,Fqr),e(gc,N7e),e(N7e,Tqr),e(gc,Mqr),e(gc,vre),e(vre,Eqr),e(gc,Cqr),e(Yt,wqr),M(I5,Yt,null),e(mr,Aqr),e(mr,Dr),M(ER,Dr,null),e(Dr,Lqr),e(Dr,q7e),e(q7e,yqr),e(Dr,xqr),e(Dr,Bn),e(Bn,$qr),e(Bn,j7e),e(j7e,kqr),e(Bn,Sqr),e(Bn,D7e),e(D7e,Rqr),e(Bn,Pqr),e(Bn,G7e),e(G7e,Bqr),e(Bn,Iqr),e(Dr,Nqr),e(Dr,P),e(P,N5),e(N5,O7e),e(O7e,qqr),e(N5,jqr),e(N5,Fre),e(Fre,Dqr),e(N5,Gqr),e(P,Oqr),e(P,q5),e(q5,V7e),e(V7e,Vqr),e(q5,Xqr),e(q5,Tre),e(Tre,zqr),e(q5,Qqr),e(P,Wqr),e(P,j5),e(j5,X7e),e(X7e,Uqr),e(j5,Hqr),e(j5,Mre),e(Mre,Jqr),e(j5,Yqr),e(P,Zqr),e(P,D5),e(D5,z7e),e(z7e,Kqr),e(D5,ejr),e(D5,Ere),e(Ere,ojr),e(D5,rjr),e(P,tjr),e(P,G5),e(G5,Q7e),e(Q7e,ajr),e(G5,njr),e(G5,Cre),e(Cre,sjr),e(G5,ljr),e(P,ijr),e(P,O5),e(O5,W7e),e(W7e,djr),e(O5,mjr),e(O5,wre),e(wre,cjr),e(O5,fjr),e(P,gjr),e(P,V5),e(V5,U7e),e(U7e,hjr),e(V5,ujr),e(V5,Are),e(Are,pjr),e(V5,_jr),e(P,bjr),e(P,X5),e(X5,H7e),e(H7e,vjr),e(X5,Fjr),e(X5,Lre),e(Lre,Tjr),e(X5,Mjr),e(P,Ejr),e(P,z5),e(z5,J7e),e(J7e,Cjr),e(z5,wjr),e(z5,yre),e(yre,Ajr),e(z5,Ljr),e(P,yjr),e(P,Q5),e(Q5,Y7e),e(Y7e,xjr),e(Q5,$jr),e(Q5,xre),e(xre,kjr),e(Q5,Sjr),e(P,Rjr),e(P,W5),e(W5,Z7e),e(Z7e,Pjr),e(W5,Bjr),e(W5,$re),e($re,Ijr),e(W5,Njr),e(P,qjr),e(P,U5),e(U5,K7e),e(K7e,jjr),e(U5,Djr),e(U5,kre),e(kre,Gjr),e(U5,Ojr),e(P,Vjr),e(P,H5),e(H5,e8e),e(e8e,Xjr),e(H5,zjr),e(H5,Sre),e(Sre,Qjr),e(H5,Wjr),e(P,Ujr),e(P,J5),e(J5,o8e),e(o8e,Hjr),e(J5,Jjr),e(J5,Rre),e(Rre,Yjr),e(J5,Zjr),e(P,Kjr),e(P,Y5),e(Y5,r8e),e(r8e,eDr),e(Y5,oDr),e(Y5,Pre),e(Pre,rDr),e(Y5,tDr),e(P,aDr),e(P,Z5),e(Z5,t8e),e(t8e,nDr),e(Z5,sDr),e(Z5,Bre),e(Bre,lDr),e(Z5,iDr),e(P,dDr),e(P,K5),e(K5,a8e),e(a8e,mDr),e(K5,cDr),e(K5,Ire),e(Ire,fDr),e(K5,gDr),e(P,hDr),e(P,e0),e(e0,n8e),e(n8e,uDr),e(e0,pDr),e(e0,Nre),e(Nre,_Dr),e(e0,bDr),e(P,vDr),e(P,o0),e(o0,s8e),e(s8e,FDr),e(o0,TDr),e(o0,qre),e(qre,MDr),e(o0,EDr),e(P,CDr),e(P,r0),e(r0,l8e),e(l8e,wDr),e(r0,ADr),e(r0,jre),e(jre,LDr),e(r0,yDr),e(P,xDr),e(P,Rl),e(Rl,i8e),e(i8e,$Dr),e(Rl,kDr),e(Rl,Dre),e(Dre,SDr),e(Rl,RDr),e(Rl,Gre),e(Gre,PDr),e(Rl,BDr),e(P,IDr),e(P,t0),e(t0,d8e),e(d8e,NDr),e(t0,qDr),e(t0,Ore),e(Ore,jDr),e(t0,DDr),e(P,GDr),e(P,a0),e(a0,m8e),e(m8e,ODr),e(a0,VDr),e(a0,Vre),e(Vre,XDr),e(a0,zDr),e(P,QDr),e(P,n0),e(n0,c8e),e(c8e,WDr),e(n0,UDr),e(n0,Xre),e(Xre,HDr),e(n0,JDr),e(P,YDr),e(P,s0),e(s0,f8e),e(f8e,ZDr),e(s0,KDr),e(s0,zre),e(zre,eGr),e(s0,oGr),e(P,rGr),e(P,l0),e(l0,g8e),e(g8e,tGr),e(l0,aGr),e(l0,Qre),e(Qre,nGr),e(l0,sGr),e(P,lGr),e(P,i0),e(i0,h8e),e(h8e,iGr),e(i0,dGr),e(i0,Wre),e(Wre,mGr),e(i0,cGr),e(P,fGr),e(P,d0),e(d0,u8e),e(u8e,gGr),e(d0,hGr),e(d0,Ure),e(Ure,uGr),e(d0,pGr),e(P,_Gr),e(P,m0),e(m0,p8e),e(p8e,bGr),e(m0,vGr),e(m0,Hre),e(Hre,FGr),e(m0,TGr),e(P,MGr),e(P,c0),e(c0,_8e),e(_8e,EGr),e(c0,CGr),e(c0,Jre),e(Jre,wGr),e(c0,AGr),e(P,LGr),e(P,f0),e(f0,b8e),e(b8e,yGr),e(f0,xGr),e(f0,Yre),e(Yre,$Gr),e(f0,kGr),e(P,SGr),e(P,g0),e(g0,v8e),e(v8e,RGr),e(g0,PGr),e(g0,Zre),e(Zre,BGr),e(g0,IGr),e(P,NGr),e(P,h0),e(h0,F8e),e(F8e,qGr),e(h0,jGr),e(h0,Kre),e(Kre,DGr),e(h0,GGr),e(P,OGr),e(P,u0),e(u0,T8e),e(T8e,VGr),e(u0,XGr),e(u0,ete),e(ete,zGr),e(u0,QGr),e(P,WGr),e(P,p0),e(p0,M8e),e(M8e,UGr),e(p0,HGr),e(p0,ote),e(ote,JGr),e(p0,YGr),e(P,ZGr),e(P,_0),e(_0,E8e),e(E8e,KGr),e(_0,eOr),e(_0,rte),e(rte,oOr),e(_0,rOr),e(P,tOr),e(P,b0),e(b0,C8e),e(C8e,aOr),e(b0,nOr),e(b0,tte),e(tte,sOr),e(b0,lOr),e(P,iOr),e(P,v0),e(v0,w8e),e(w8e,dOr),e(v0,mOr),e(v0,ate),e(ate,cOr),e(v0,fOr),e(P,gOr),e(P,F0),e(F0,A8e),e(A8e,hOr),e(F0,uOr),e(F0,nte),e(nte,pOr),e(F0,_Or),e(P,bOr),e(P,T0),e(T0,L8e),e(L8e,vOr),e(T0,FOr),e(T0,ste),e(ste,TOr),e(T0,MOr),e(P,EOr),e(P,M0),e(M0,y8e),e(y8e,COr),e(M0,wOr),e(M0,lte),e(lte,AOr),e(M0,LOr),e(P,yOr),e(P,E0),e(E0,x8e),e(x8e,xOr),e(E0,$Or),e(E0,ite),e(ite,kOr),e(E0,SOr),e(P,ROr),e(P,C0),e(C0,$8e),e($8e,POr),e(C0,BOr),e(C0,dte),e(dte,IOr),e(C0,NOr),e(P,qOr),e(P,w0),e(w0,k8e),e(k8e,jOr),e(w0,DOr),e(w0,mte),e(mte,GOr),e(w0,OOr),e(P,VOr),e(P,A0),e(A0,S8e),e(S8e,XOr),e(A0,zOr),e(A0,cte),e(cte,QOr),e(A0,WOr),e(P,UOr),e(P,L0),e(L0,R8e),e(R8e,HOr),e(L0,JOr),e(L0,fte),e(fte,YOr),e(L0,ZOr),e(P,KOr),e(P,y0),e(y0,P8e),e(P8e,eVr),e(y0,oVr),e(y0,gte),e(gte,rVr),e(y0,tVr),e(P,aVr),e(P,x0),e(x0,B8e),e(B8e,nVr),e(x0,sVr),e(x0,hte),e(hte,lVr),e(x0,iVr),e(P,dVr),e(P,$0),e($0,I8e),e(I8e,mVr),e($0,cVr),e($0,ute),e(ute,fVr),e($0,gVr),e(P,hVr),e(P,k0),e(k0,N8e),e(N8e,uVr),e(k0,pVr),e(k0,pte),e(pte,_Vr),e(k0,bVr),e(P,vVr),e(P,S0),e(S0,q8e),e(q8e,FVr),e(S0,TVr),e(S0,_te),e(_te,MVr),e(S0,EVr),e(P,CVr),e(P,R0),e(R0,j8e),e(j8e,wVr),e(R0,AVr),e(R0,bte),e(bte,LVr),e(R0,yVr),e(P,xVr),e(P,P0),e(P0,D8e),e(D8e,$Vr),e(P0,kVr),e(P0,vte),e(vte,SVr),e(P0,RVr),e(P,PVr),e(P,B0),e(B0,G8e),e(G8e,BVr),e(B0,IVr),e(B0,Fte),e(Fte,NVr),e(B0,qVr),e(P,jVr),e(P,I0),e(I0,O8e),e(O8e,DVr),e(I0,GVr),e(I0,Tte),e(Tte,OVr),e(I0,VVr),e(P,XVr),e(P,N0),e(N0,V8e),e(V8e,zVr),e(N0,QVr),e(N0,Mte),e(Mte,WVr),e(N0,UVr),e(P,HVr),e(P,q0),e(q0,X8e),e(X8e,JVr),e(q0,YVr),e(q0,Ete),e(Ete,ZVr),e(q0,KVr),e(P,eXr),e(P,j0),e(j0,z8e),e(z8e,oXr),e(j0,rXr),e(j0,Cte),e(Cte,tXr),e(j0,aXr),e(Dr,nXr),M(D0,Dr,null),b(c,dno,_),b(c,hc,_),e(hc,G0),e(G0,Q8e),M(CR,Q8e,null),e(hc,sXr),e(hc,W8e),e(W8e,lXr),b(c,mno,_),b(c,cr,_),M(wR,cr,null),e(cr,iXr),e(cr,uc),e(uc,dXr),e(uc,wte),e(wte,mXr),e(uc,cXr),e(uc,Ate),e(Ate,fXr),e(uc,gXr),e(cr,hXr),e(cr,AR),e(AR,uXr),e(AR,U8e),e(U8e,pXr),e(AR,_Xr),e(cr,bXr),e(cr,Zt),M(LR,Zt,null),e(Zt,vXr),e(Zt,H8e),e(H8e,FXr),e(Zt,TXr),e(Zt,pc),e(pc,MXr),e(pc,J8e),e(J8e,EXr),e(pc,CXr),e(pc,Lte),e(Lte,wXr),e(pc,AXr),e(Zt,LXr),M(O0,Zt,null),e(cr,yXr),e(cr,Gr),M(yR,Gr,null),e(Gr,xXr),e(Gr,Y8e),e(Y8e,$Xr),e(Gr,kXr),e(Gr,In),e(In,SXr),e(In,Z8e),e(Z8e,RXr),e(In,PXr),e(In,K8e),e(K8e,BXr),e(In,IXr),e(In,eLe),e(eLe,NXr),e(In,qXr),e(Gr,jXr),e(Gr,le),e(le,V0),e(V0,oLe),e(oLe,DXr),e(V0,GXr),e(V0,yte),e(yte,OXr),e(V0,VXr),e(le,XXr),e(le,X0),e(X0,rLe),e(rLe,zXr),e(X0,QXr),e(X0,xte),e(xte,WXr),e(X0,UXr),e(le,HXr),e(le,z0),e(z0,tLe),e(tLe,JXr),e(z0,YXr),e(z0,$te),e($te,ZXr),e(z0,KXr),e(le,ezr),e(le,Q0),e(Q0,aLe),e(aLe,ozr),e(Q0,rzr),e(Q0,kte),e(kte,tzr),e(Q0,azr),e(le,nzr),e(le,W0),e(W0,nLe),e(nLe,szr),e(W0,lzr),e(W0,Ste),e(Ste,izr),e(W0,dzr),e(le,mzr),e(le,U0),e(U0,sLe),e(sLe,czr),e(U0,fzr),e(U0,Rte),e(Rte,gzr),e(U0,hzr),e(le,uzr),e(le,H0),e(H0,lLe),e(lLe,pzr),e(H0,_zr),e(H0,Pte),e(Pte,bzr),e(H0,vzr),e(le,Fzr),e(le,J0),e(J0,iLe),e(iLe,Tzr),e(J0,Mzr),e(J0,Bte),e(Bte,Ezr),e(J0,Czr),e(le,wzr),e(le,Y0),e(Y0,dLe),e(dLe,Azr),e(Y0,Lzr),e(Y0,Ite),e(Ite,yzr),e(Y0,xzr),e(le,$zr),e(le,Z0),e(Z0,mLe),e(mLe,kzr),e(Z0,Szr),e(Z0,Nte),e(Nte,Rzr),e(Z0,Pzr),e(le,Bzr),e(le,K0),e(K0,cLe),e(cLe,Izr),e(K0,Nzr),e(K0,qte),e(qte,qzr),e(K0,jzr),e(le,Dzr),e(le,ew),e(ew,fLe),e(fLe,Gzr),e(ew,Ozr),e(ew,jte),e(jte,Vzr),e(ew,Xzr),e(le,zzr),e(le,ow),e(ow,gLe),e(gLe,Qzr),e(ow,Wzr),e(ow,Dte),e(Dte,Uzr),e(ow,Hzr),e(le,Jzr),e(le,rw),e(rw,hLe),e(hLe,Yzr),e(rw,Zzr),e(rw,Gte),e(Gte,Kzr),e(rw,eQr),e(le,oQr),e(le,tw),e(tw,uLe),e(uLe,rQr),e(tw,tQr),e(tw,Ote),e(Ote,aQr),e(tw,nQr),e(le,sQr),e(le,aw),e(aw,pLe),e(pLe,lQr),e(aw,iQr),e(aw,Vte),e(Vte,dQr),e(aw,mQr),e(le,cQr),e(le,nw),e(nw,_Le),e(_Le,fQr),e(nw,gQr),e(nw,Xte),e(Xte,hQr),e(nw,uQr),e(le,pQr),e(le,sw),e(sw,bLe),e(bLe,_Qr),e(sw,bQr),e(sw,zte),e(zte,vQr),e(sw,FQr),e(le,TQr),e(le,lw),e(lw,vLe),e(vLe,MQr),e(lw,EQr),e(lw,Qte),e(Qte,CQr),e(lw,wQr),e(le,AQr),e(le,iw),e(iw,FLe),e(FLe,LQr),e(iw,yQr),e(iw,Wte),e(Wte,xQr),e(iw,$Qr),e(le,kQr),e(le,dw),e(dw,TLe),e(TLe,SQr),e(dw,RQr),e(dw,Ute),e(Ute,PQr),e(dw,BQr),e(le,IQr),e(le,mw),e(mw,MLe),e(MLe,NQr),e(mw,qQr),e(mw,Hte),e(Hte,jQr),e(mw,DQr),e(le,GQr),e(le,cw),e(cw,ELe),e(ELe,OQr),e(cw,VQr),e(cw,Jte),e(Jte,XQr),e(cw,zQr),e(Gr,QQr),M(fw,Gr,null),b(c,cno,_),b(c,_c,_),e(_c,gw),e(gw,CLe),M(xR,CLe,null),e(_c,WQr),e(_c,wLe),e(wLe,UQr),b(c,fno,_),b(c,fr,_),M($R,fr,null),e(fr,HQr),e(fr,bc),e(bc,JQr),e(bc,Yte),e(Yte,YQr),e(bc,ZQr),e(bc,Zte),e(Zte,KQr),e(bc,eWr),e(fr,oWr),e(fr,kR),e(kR,rWr),e(kR,ALe),e(ALe,tWr),e(kR,aWr),e(fr,nWr),e(fr,Kt),M(SR,Kt,null),e(Kt,sWr),e(Kt,LLe),e(LLe,lWr),e(Kt,iWr),e(Kt,vc),e(vc,dWr),e(vc,yLe),e(yLe,mWr),e(vc,cWr),e(vc,Kte),e(Kte,fWr),e(vc,gWr),e(Kt,hWr),M(hw,Kt,null),e(fr,uWr),e(fr,Or),M(RR,Or,null),e(Or,pWr),e(Or,xLe),e(xLe,_Wr),e(Or,bWr),e(Or,Nn),e(Nn,vWr),e(Nn,$Le),e($Le,FWr),e(Nn,TWr),e(Nn,kLe),e(kLe,MWr),e(Nn,EWr),e(Nn,SLe),e(SLe,CWr),e(Nn,wWr),e(Or,AWr),e(Or,Me),e(Me,uw),e(uw,RLe),e(RLe,LWr),e(uw,yWr),e(uw,eae),e(eae,xWr),e(uw,$Wr),e(Me,kWr),e(Me,pw),e(pw,PLe),e(PLe,SWr),e(pw,RWr),e(pw,oae),e(oae,PWr),e(pw,BWr),e(Me,IWr),e(Me,_w),e(_w,BLe),e(BLe,NWr),e(_w,qWr),e(_w,rae),e(rae,jWr),e(_w,DWr),e(Me,GWr),e(Me,bw),e(bw,ILe),e(ILe,OWr),e(bw,VWr),e(bw,tae),e(tae,XWr),e(bw,zWr),e(Me,QWr),e(Me,vw),e(vw,NLe),e(NLe,WWr),e(vw,UWr),e(vw,aae),e(aae,HWr),e(vw,JWr),e(Me,YWr),e(Me,Fw),e(Fw,qLe),e(qLe,ZWr),e(Fw,KWr),e(Fw,nae),e(nae,eUr),e(Fw,oUr),e(Me,rUr),e(Me,Tw),e(Tw,jLe),e(jLe,tUr),e(Tw,aUr),e(Tw,sae),e(sae,nUr),e(Tw,sUr),e(Me,lUr),e(Me,Mw),e(Mw,DLe),e(DLe,iUr),e(Mw,dUr),e(Mw,lae),e(lae,mUr),e(Mw,cUr),e(Me,fUr),e(Me,Ew),e(Ew,GLe),e(GLe,gUr),e(Ew,hUr),e(Ew,iae),e(iae,uUr),e(Ew,pUr),e(Me,_Ur),e(Me,Cw),e(Cw,OLe),e(OLe,bUr),e(Cw,vUr),e(Cw,dae),e(dae,FUr),e(Cw,TUr),e(Me,MUr),e(Me,ww),e(ww,VLe),e(VLe,EUr),e(ww,CUr),e(ww,mae),e(mae,wUr),e(ww,AUr),e(Me,LUr),e(Me,Aw),e(Aw,XLe),e(XLe,yUr),e(Aw,xUr),e(Aw,cae),e(cae,$Ur),e(Aw,kUr),e(Me,SUr),e(Me,Lw),e(Lw,zLe),e(zLe,RUr),e(Lw,PUr),e(Lw,fae),e(fae,BUr),e(Lw,IUr),e(Me,NUr),e(Me,yw),e(yw,QLe),e(QLe,qUr),e(yw,jUr),e(yw,gae),e(gae,DUr),e(yw,GUr),e(Or,OUr),M(xw,Or,null),b(c,gno,_),b(c,Fc,_),e(Fc,$w),e($w,WLe),M(PR,WLe,null),e(Fc,VUr),e(Fc,ULe),e(ULe,XUr),b(c,hno,_),b(c,gr,_),M(BR,gr,null),e(gr,zUr),e(gr,Tc),e(Tc,QUr),e(Tc,hae),e(hae,WUr),e(Tc,UUr),e(Tc,uae),e(uae,HUr),e(Tc,JUr),e(gr,YUr),e(gr,IR),e(IR,ZUr),e(IR,HLe),e(HLe,KUr),e(IR,eHr),e(gr,oHr),e(gr,ea),M(NR,ea,null),e(ea,rHr),e(ea,JLe),e(JLe,tHr),e(ea,aHr),e(ea,Mc),e(Mc,nHr),e(Mc,YLe),e(YLe,sHr),e(Mc,lHr),e(Mc,pae),e(pae,iHr),e(Mc,dHr),e(ea,mHr),M(kw,ea,null),e(gr,cHr),e(gr,Vr),M(qR,Vr,null),e(Vr,fHr),e(Vr,ZLe),e(ZLe,gHr),e(Vr,hHr),e(Vr,qn),e(qn,uHr),e(qn,KLe),e(KLe,pHr),e(qn,_Hr),e(qn,eye),e(eye,bHr),e(qn,vHr),e(qn,oye),e(oye,FHr),e(qn,THr),e(Vr,MHr),e(Vr,ye),e(ye,Sw),e(Sw,rye),e(rye,EHr),e(Sw,CHr),e(Sw,_ae),e(_ae,wHr),e(Sw,AHr),e(ye,LHr),e(ye,Rw),e(Rw,tye),e(tye,yHr),e(Rw,xHr),e(Rw,bae),e(bae,$Hr),e(Rw,kHr),e(ye,SHr),e(ye,Pw),e(Pw,aye),e(aye,RHr),e(Pw,PHr),e(Pw,vae),e(vae,BHr),e(Pw,IHr),e(ye,NHr),e(ye,Pl),e(Pl,nye),e(nye,qHr),e(Pl,jHr),e(Pl,Fae),e(Fae,DHr),e(Pl,GHr),e(Pl,Tae),e(Tae,OHr),e(Pl,VHr),e(ye,XHr),e(ye,Bw),e(Bw,sye),e(sye,zHr),e(Bw,QHr),e(Bw,Mae),e(Mae,WHr),e(Bw,UHr),e(ye,HHr),e(ye,Iw),e(Iw,lye),e(lye,JHr),e(Iw,YHr),e(Iw,Eae),e(Eae,ZHr),e(Iw,KHr),e(ye,eJr),e(ye,Nw),e(Nw,iye),e(iye,oJr),e(Nw,rJr),e(Nw,Cae),e(Cae,tJr),e(Nw,aJr),e(ye,nJr),e(ye,qw),e(qw,dye),e(dye,sJr),e(qw,lJr),e(qw,wae),e(wae,iJr),e(qw,dJr),e(ye,mJr),e(ye,jw),e(jw,mye),e(mye,cJr),e(jw,fJr),e(jw,Aae),e(Aae,gJr),e(jw,hJr),e(ye,uJr),e(ye,Dw),e(Dw,cye),e(cye,pJr),e(Dw,_Jr),e(Dw,Lae),e(Lae,bJr),e(Dw,vJr),e(Vr,FJr),M(Gw,Vr,null),b(c,uno,_),b(c,Ec,_),e(Ec,Ow),e(Ow,fye),M(jR,fye,null),e(Ec,TJr),e(Ec,gye),e(gye,MJr),b(c,pno,_),b(c,hr,_),M(DR,hr,null),e(hr,EJr),e(hr,Cc),e(Cc,CJr),e(Cc,yae),e(yae,wJr),e(Cc,AJr),e(Cc,xae),e(xae,LJr),e(Cc,yJr),e(hr,xJr),e(hr,GR),e(GR,$Jr),e(GR,hye),e(hye,kJr),e(GR,SJr),e(hr,RJr),e(hr,oa),M(OR,oa,null),e(oa,PJr),e(oa,uye),e(uye,BJr),e(oa,IJr),e(oa,wc),e(wc,NJr),e(wc,pye),e(pye,qJr),e(wc,jJr),e(wc,$ae),e($ae,DJr),e(wc,GJr),e(oa,OJr),M(Vw,oa,null),e(hr,VJr),e(hr,Xr),M(VR,Xr,null),e(Xr,XJr),e(Xr,_ye),e(_ye,zJr),e(Xr,QJr),e(Xr,jn),e(jn,WJr),e(jn,bye),e(bye,UJr),e(jn,HJr),e(jn,vye),e(vye,JJr),e(jn,YJr),e(jn,Fye),e(Fye,ZJr),e(jn,KJr),e(Xr,eYr),e(Xr,Ac),e(Ac,Xw),e(Xw,Tye),e(Tye,oYr),e(Xw,rYr),e(Xw,kae),e(kae,tYr),e(Xw,aYr),e(Ac,nYr),e(Ac,zw),e(zw,Mye),e(Mye,sYr),e(zw,lYr),e(zw,Sae),e(Sae,iYr),e(zw,dYr),e(Ac,mYr),e(Ac,Qw),e(Qw,Eye),e(Eye,cYr),e(Qw,fYr),e(Qw,Rae),e(Rae,gYr),e(Qw,hYr),e(Xr,uYr),M(Ww,Xr,null),b(c,_no,_),b(c,Lc,_),e(Lc,Uw),e(Uw,Cye),M(XR,Cye,null),e(Lc,pYr),e(Lc,wye),e(wye,_Yr),b(c,bno,_),b(c,ur,_),M(zR,ur,null),e(ur,bYr),e(ur,yc),e(yc,vYr),e(yc,Pae),e(Pae,FYr),e(yc,TYr),e(yc,Bae),e(Bae,MYr),e(yc,EYr),e(ur,CYr),e(ur,QR),e(QR,wYr),e(QR,Aye),e(Aye,AYr),e(QR,LYr),e(ur,yYr),e(ur,ra),M(WR,ra,null),e(ra,xYr),e(ra,Lye),e(Lye,$Yr),e(ra,kYr),e(ra,xc),e(xc,SYr),e(xc,yye),e(yye,RYr),e(xc,PYr),e(xc,Iae),e(Iae,BYr),e(xc,IYr),e(ra,NYr),M(Hw,ra,null),e(ur,qYr),e(ur,zr),M(UR,zr,null),e(zr,jYr),e(zr,xye),e(xye,DYr),e(zr,GYr),e(zr,Dn),e(Dn,OYr),e(Dn,$ye),e($ye,VYr),e(Dn,XYr),e(Dn,kye),e(kye,zYr),e(Dn,QYr),e(Dn,Sye),e(Sye,WYr),e(Dn,UYr),e(zr,HYr),e(zr,ce),e(ce,Jw),e(Jw,Rye),e(Rye,JYr),e(Jw,YYr),e(Jw,Nae),e(Nae,ZYr),e(Jw,KYr),e(ce,eZr),e(ce,Yw),e(Yw,Pye),e(Pye,oZr),e(Yw,rZr),e(Yw,qae),e(qae,tZr),e(Yw,aZr),e(ce,nZr),e(ce,Zw),e(Zw,Bye),e(Bye,sZr),e(Zw,lZr),e(Zw,jae),e(jae,iZr),e(Zw,dZr),e(ce,mZr),e(ce,Kw),e(Kw,Iye),e(Iye,cZr),e(Kw,fZr),e(Kw,Dae),e(Dae,gZr),e(Kw,hZr),e(ce,uZr),e(ce,eA),e(eA,Nye),e(Nye,pZr),e(eA,_Zr),e(eA,Gae),e(Gae,bZr),e(eA,vZr),e(ce,FZr),e(ce,oA),e(oA,qye),e(qye,TZr),e(oA,MZr),e(oA,Oae),e(Oae,EZr),e(oA,CZr),e(ce,wZr),e(ce,rA),e(rA,jye),e(jye,AZr),e(rA,LZr),e(rA,Vae),e(Vae,yZr),e(rA,xZr),e(ce,$Zr),e(ce,tA),e(tA,Dye),e(Dye,kZr),e(tA,SZr),e(tA,Xae),e(Xae,RZr),e(tA,PZr),e(ce,BZr),e(ce,aA),e(aA,Gye),e(Gye,IZr),e(aA,NZr),e(aA,zae),e(zae,qZr),e(aA,jZr),e(ce,DZr),e(ce,nA),e(nA,Oye),e(Oye,GZr),e(nA,OZr),e(nA,Qae),e(Qae,VZr),e(nA,XZr),e(ce,zZr),e(ce,sA),e(sA,Vye),e(Vye,QZr),e(sA,WZr),e(sA,Wae),e(Wae,UZr),e(sA,HZr),e(ce,JZr),e(ce,lA),e(lA,Xye),e(Xye,YZr),e(lA,ZZr),e(lA,Uae),e(Uae,KZr),e(lA,eKr),e(ce,oKr),e(ce,iA),e(iA,zye),e(zye,rKr),e(iA,tKr),e(iA,Hae),e(Hae,aKr),e(iA,nKr),e(ce,sKr),e(ce,dA),e(dA,Qye),e(Qye,lKr),e(dA,iKr),e(dA,Jae),e(Jae,dKr),e(dA,mKr),e(ce,cKr),e(ce,mA),e(mA,Wye),e(Wye,fKr),e(mA,gKr),e(mA,Yae),e(Yae,hKr),e(mA,uKr),e(ce,pKr),e(ce,cA),e(cA,Uye),e(Uye,_Kr),e(cA,bKr),e(cA,Zae),e(Zae,vKr),e(cA,FKr),e(ce,TKr),e(ce,fA),e(fA,Hye),e(Hye,MKr),e(fA,EKr),e(fA,Kae),e(Kae,CKr),e(fA,wKr),e(ce,AKr),e(ce,gA),e(gA,Jye),e(Jye,LKr),e(gA,yKr),e(gA,ene),e(ene,xKr),e(gA,$Kr),e(ce,kKr),e(ce,hA),e(hA,Yye),e(Yye,SKr),e(hA,RKr),e(hA,one),e(one,PKr),e(hA,BKr),e(ce,IKr),e(ce,uA),e(uA,Zye),e(Zye,NKr),e(uA,qKr),e(uA,rne),e(rne,jKr),e(uA,DKr),e(ce,GKr),e(ce,pA),e(pA,Kye),e(Kye,OKr),e(pA,VKr),e(pA,tne),e(tne,XKr),e(pA,zKr),e(zr,QKr),M(_A,zr,null),b(c,vno,_),b(c,$c,_),e($c,bA),e(bA,e9e),M(HR,e9e,null),e($c,WKr),e($c,o9e),e(o9e,UKr),b(c,Fno,_),b(c,pr,_),M(JR,pr,null),e(pr,HKr),e(pr,kc),e(kc,JKr),e(kc,ane),e(ane,YKr),e(kc,ZKr),e(kc,nne),e(nne,KKr),e(kc,eet),e(pr,oet),e(pr,YR),e(YR,ret),e(YR,r9e),e(r9e,tet),e(YR,aet),e(pr,net),e(pr,ta),M(ZR,ta,null),e(ta,set),e(ta,t9e),e(t9e,iet),e(ta,det),e(ta,Sc),e(Sc,met),e(Sc,a9e),e(a9e,cet),e(Sc,fet),e(Sc,sne),e(sne,get),e(Sc,het),e(ta,uet),M(vA,ta,null),e(pr,pet),e(pr,Qr),M(KR,Qr,null),e(Qr,_et),e(Qr,n9e),e(n9e,bet),e(Qr,vet),e(Qr,Gn),e(Gn,Fet),e(Gn,s9e),e(s9e,Tet),e(Gn,Met),e(Gn,l9e),e(l9e,Eet),e(Gn,Cet),e(Gn,i9e),e(i9e,wet),e(Gn,Aet),e(Qr,Let),e(Qr,xe),e(xe,FA),e(FA,d9e),e(d9e,yet),e(FA,xet),e(FA,lne),e(lne,$et),e(FA,ket),e(xe,Set),e(xe,TA),e(TA,m9e),e(m9e,Ret),e(TA,Pet),e(TA,ine),e(ine,Bet),e(TA,Iet),e(xe,Net),e(xe,MA),e(MA,c9e),e(c9e,qet),e(MA,jet),e(MA,dne),e(dne,Det),e(MA,Get),e(xe,Oet),e(xe,EA),e(EA,f9e),e(f9e,Vet),e(EA,Xet),e(EA,mne),e(mne,zet),e(EA,Qet),e(xe,Wet),e(xe,CA),e(CA,g9e),e(g9e,Uet),e(CA,Het),e(CA,cne),e(cne,Jet),e(CA,Yet),e(xe,Zet),e(xe,wA),e(wA,h9e),e(h9e,Ket),e(wA,eot),e(wA,fne),e(fne,oot),e(wA,rot),e(xe,tot),e(xe,AA),e(AA,u9e),e(u9e,aot),e(AA,not),e(AA,gne),e(gne,sot),e(AA,lot),e(xe,iot),e(xe,LA),e(LA,p9e),e(p9e,dot),e(LA,mot),e(LA,hne),e(hne,cot),e(LA,fot),e(xe,got),e(xe,yA),e(yA,_9e),e(_9e,hot),e(yA,uot),e(yA,une),e(une,pot),e(yA,_ot),e(xe,bot),e(xe,xA),e(xA,b9e),e(b9e,vot),e(xA,Fot),e(xA,pne),e(pne,Tot),e(xA,Mot),e(Qr,Eot),M($A,Qr,null),b(c,Tno,_),b(c,Rc,_),e(Rc,kA),e(kA,v9e),M(eP,v9e,null),e(Rc,Cot),e(Rc,F9e),e(F9e,wot),b(c,Mno,_),b(c,_r,_),M(oP,_r,null),e(_r,Aot),e(_r,Pc),e(Pc,Lot),e(Pc,_ne),e(_ne,yot),e(Pc,xot),e(Pc,bne),e(bne,$ot),e(Pc,kot),e(_r,Sot),e(_r,rP),e(rP,Rot),e(rP,T9e),e(T9e,Pot),e(rP,Bot),e(_r,Iot),e(_r,aa),M(tP,aa,null),e(aa,Not),e(aa,M9e),e(M9e,qot),e(aa,jot),e(aa,Bc),e(Bc,Dot),e(Bc,E9e),e(E9e,Got),e(Bc,Oot),e(Bc,vne),e(vne,Vot),e(Bc,Xot),e(aa,zot),M(SA,aa,null),e(_r,Qot),e(_r,Wr),M(aP,Wr,null),e(Wr,Wot),e(Wr,C9e),e(C9e,Uot),e(Wr,Hot),e(Wr,On),e(On,Jot),e(On,w9e),e(w9e,Yot),e(On,Zot),e(On,A9e),e(A9e,Kot),e(On,ert),e(On,L9e),e(L9e,ort),e(On,rrt),e(Wr,trt),e(Wr,re),e(re,RA),e(RA,y9e),e(y9e,art),e(RA,nrt),e(RA,Fne),e(Fne,srt),e(RA,lrt),e(re,irt),e(re,PA),e(PA,x9e),e(x9e,drt),e(PA,mrt),e(PA,Tne),e(Tne,crt),e(PA,frt),e(re,grt),e(re,BA),e(BA,$9e),e($9e,hrt),e(BA,urt),e(BA,Mne),e(Mne,prt),e(BA,_rt),e(re,brt),e(re,IA),e(IA,k9e),e(k9e,vrt),e(IA,Frt),e(IA,Ene),e(Ene,Trt),e(IA,Mrt),e(re,Ert),e(re,NA),e(NA,S9e),e(S9e,Crt),e(NA,wrt),e(NA,Cne),e(Cne,Art),e(NA,Lrt),e(re,yrt),e(re,qA),e(qA,R9e),e(R9e,xrt),e(qA,$rt),e(qA,wne),e(wne,krt),e(qA,Srt),e(re,Rrt),e(re,jA),e(jA,P9e),e(P9e,Prt),e(jA,Brt),e(jA,Ane),e(Ane,Irt),e(jA,Nrt),e(re,qrt),e(re,DA),e(DA,B9e),e(B9e,jrt),e(DA,Drt),e(DA,Lne),e(Lne,Grt),e(DA,Ort),e(re,Vrt),e(re,GA),e(GA,I9e),e(I9e,Xrt),e(GA,zrt),e(GA,yne),e(yne,Qrt),e(GA,Wrt),e(re,Urt),e(re,OA),e(OA,N9e),e(N9e,Hrt),e(OA,Jrt),e(OA,xne),e(xne,Yrt),e(OA,Zrt),e(re,Krt),e(re,VA),e(VA,q9e),e(q9e,ett),e(VA,ott),e(VA,$ne),e($ne,rtt),e(VA,ttt),e(re,att),e(re,XA),e(XA,j9e),e(j9e,ntt),e(XA,stt),e(XA,kne),e(kne,ltt),e(XA,itt),e(re,dtt),e(re,zA),e(zA,D9e),e(D9e,mtt),e(zA,ctt),e(zA,Sne),e(Sne,ftt),e(zA,gtt),e(re,htt),e(re,QA),e(QA,G9e),e(G9e,utt),e(QA,ptt),e(QA,Rne),e(Rne,_tt),e(QA,btt),e(re,vtt),e(re,WA),e(WA,O9e),e(O9e,Ftt),e(WA,Ttt),e(WA,Pne),e(Pne,Mtt),e(WA,Ett),e(re,Ctt),e(re,UA),e(UA,V9e),e(V9e,wtt),e(UA,Att),e(UA,Bne),e(Bne,Ltt),e(UA,ytt),e(re,xtt),e(re,HA),e(HA,X9e),e(X9e,$tt),e(HA,ktt),e(HA,Ine),e(Ine,Stt),e(HA,Rtt),e(re,Ptt),e(re,JA),e(JA,z9e),e(z9e,Btt),e(JA,Itt),e(JA,Nne),e(Nne,Ntt),e(JA,qtt),e(re,jtt),e(re,YA),e(YA,Q9e),e(Q9e,Dtt),e(YA,Gtt),e(YA,qne),e(qne,Ott),e(YA,Vtt),e(re,Xtt),e(re,ZA),e(ZA,W9e),e(W9e,ztt),e(ZA,Qtt),e(ZA,jne),e(jne,Wtt),e(ZA,Utt),e(re,Htt),e(re,KA),e(KA,U9e),e(U9e,Jtt),e(KA,Ytt),e(KA,Dne),e(Dne,Ztt),e(KA,Ktt),e(re,eat),e(re,e6),e(e6,H9e),e(H9e,oat),e(e6,rat),e(e6,Gne),e(Gne,tat),e(e6,aat),e(re,nat),e(re,o6),e(o6,J9e),e(J9e,sat),e(o6,lat),e(o6,One),e(One,iat),e(o6,dat),e(re,mat),e(re,r6),e(r6,Y9e),e(Y9e,cat),e(r6,fat),e(r6,Vne),e(Vne,gat),e(r6,hat),e(re,uat),e(re,t6),e(t6,Z9e),e(Z9e,pat),e(t6,_at),e(t6,Xne),e(Xne,bat),e(t6,vat),e(re,Fat),e(re,a6),e(a6,K9e),e(K9e,Tat),e(a6,Mat),e(a6,zne),e(zne,Eat),e(a6,Cat),e(re,wat),e(re,n6),e(n6,exe),e(exe,Aat),e(n6,Lat),e(n6,Qne),e(Qne,yat),e(n6,xat),e(re,$at),e(re,s6),e(s6,oxe),e(oxe,kat),e(s6,Sat),e(s6,Wne),e(Wne,Rat),e(s6,Pat),e(Wr,Bat),M(l6,Wr,null),b(c,Eno,_),b(c,Ic,_),e(Ic,i6),e(i6,rxe),M(nP,rxe,null),e(Ic,Iat),e(Ic,txe),e(txe,Nat),b(c,Cno,_),b(c,br,_),M(sP,br,null),e(br,qat),e(br,Nc),e(Nc,jat),e(Nc,Une),e(Une,Dat),e(Nc,Gat),e(Nc,Hne),e(Hne,Oat),e(Nc,Vat),e(br,Xat),e(br,lP),e(lP,zat),e(lP,axe),e(axe,Qat),e(lP,Wat),e(br,Uat),e(br,na),M(iP,na,null),e(na,Hat),e(na,nxe),e(nxe,Jat),e(na,Yat),e(na,qc),e(qc,Zat),e(qc,sxe),e(sxe,Kat),e(qc,ent),e(qc,Jne),e(Jne,ont),e(qc,rnt),e(na,tnt),M(d6,na,null),e(br,ant),e(br,Ur),M(dP,Ur,null),e(Ur,nnt),e(Ur,lxe),e(lxe,snt),e(Ur,lnt),e(Ur,Vn),e(Vn,int),e(Vn,ixe),e(ixe,dnt),e(Vn,mnt),e(Vn,dxe),e(dxe,cnt),e(Vn,fnt),e(Vn,mxe),e(mxe,gnt),e(Vn,hnt),e(Ur,unt),e(Ur,ve),e(ve,m6),e(m6,cxe),e(cxe,pnt),e(m6,_nt),e(m6,Yne),e(Yne,bnt),e(m6,vnt),e(ve,Fnt),e(ve,c6),e(c6,fxe),e(fxe,Tnt),e(c6,Mnt),e(c6,Zne),e(Zne,Ent),e(c6,Cnt),e(ve,wnt),e(ve,f6),e(f6,gxe),e(gxe,Ant),e(f6,Lnt),e(f6,Kne),e(Kne,ynt),e(f6,xnt),e(ve,$nt),e(ve,g6),e(g6,hxe),e(hxe,knt),e(g6,Snt),e(g6,ese),e(ese,Rnt),e(g6,Pnt),e(ve,Bnt),e(ve,h6),e(h6,uxe),e(uxe,Int),e(h6,Nnt),e(h6,ose),e(ose,qnt),e(h6,jnt),e(ve,Dnt),e(ve,u6),e(u6,pxe),e(pxe,Gnt),e(u6,Ont),e(u6,rse),e(rse,Vnt),e(u6,Xnt),e(ve,znt),e(ve,p6),e(p6,_xe),e(_xe,Qnt),e(p6,Wnt),e(p6,tse),e(tse,Unt),e(p6,Hnt),e(ve,Jnt),e(ve,_6),e(_6,bxe),e(bxe,Ynt),e(_6,Znt),e(_6,ase),e(ase,Knt),e(_6,est),e(ve,ost),e(ve,b6),e(b6,vxe),e(vxe,rst),e(b6,tst),e(b6,nse),e(nse,ast),e(b6,nst),e(ve,sst),e(ve,v6),e(v6,Fxe),e(Fxe,lst),e(v6,ist),e(v6,sse),e(sse,dst),e(v6,mst),e(ve,cst),e(ve,F6),e(F6,Txe),e(Txe,fst),e(F6,gst),e(F6,lse),e(lse,hst),e(F6,ust),e(ve,pst),e(ve,T6),e(T6,Mxe),e(Mxe,_st),e(T6,bst),e(T6,ise),e(ise,vst),e(T6,Fst),e(ve,Tst),e(ve,M6),e(M6,Exe),e(Exe,Mst),e(M6,Est),e(M6,dse),e(dse,Cst),e(M6,wst),e(ve,Ast),e(ve,E6),e(E6,Cxe),e(Cxe,Lst),e(E6,yst),e(E6,mse),e(mse,xst),e(E6,$st),e(ve,kst),e(ve,C6),e(C6,wxe),e(wxe,Sst),e(C6,Rst),e(C6,cse),e(cse,Pst),e(C6,Bst),e(ve,Ist),e(ve,w6),e(w6,Axe),e(Axe,Nst),e(w6,qst),e(w6,fse),e(fse,jst),e(w6,Dst),e(ve,Gst),e(ve,A6),e(A6,Lxe),e(Lxe,Ost),e(A6,Vst),e(A6,gse),e(gse,Xst),e(A6,zst),e(Ur,Qst),M(L6,Ur,null),b(c,wno,_),b(c,jc,_),e(jc,y6),e(y6,yxe),M(mP,yxe,null),e(jc,Wst),e(jc,xxe),e(xxe,Ust),b(c,Ano,_),b(c,vr,_),M(cP,vr,null),e(vr,Hst),e(vr,Dc),e(Dc,Jst),e(Dc,hse),e(hse,Yst),e(Dc,Zst),e(Dc,use),e(use,Kst),e(Dc,elt),e(vr,olt),e(vr,fP),e(fP,rlt),e(fP,$xe),e($xe,tlt),e(fP,alt),e(vr,nlt),e(vr,sa),M(gP,sa,null),e(sa,slt),e(sa,kxe),e(kxe,llt),e(sa,ilt),e(sa,Gc),e(Gc,dlt),e(Gc,Sxe),e(Sxe,mlt),e(Gc,clt),e(Gc,pse),e(pse,flt),e(Gc,glt),e(sa,hlt),M(x6,sa,null),e(vr,ult),e(vr,Hr),M(hP,Hr,null),e(Hr,plt),e(Hr,Rxe),e(Rxe,_lt),e(Hr,blt),e(Hr,Xn),e(Xn,vlt),e(Xn,Pxe),e(Pxe,Flt),e(Xn,Tlt),e(Xn,Bxe),e(Bxe,Mlt),e(Xn,Elt),e(Xn,Ixe),e(Ixe,Clt),e(Xn,wlt),e(Hr,Alt),e(Hr,uP),e(uP,$6),e($6,Nxe),e(Nxe,Llt),e($6,ylt),e($6,_se),e(_se,xlt),e($6,$lt),e(uP,klt),e(uP,k6),e(k6,qxe),e(qxe,Slt),e(k6,Rlt),e(k6,bse),e(bse,Plt),e(k6,Blt),e(Hr,Ilt),M(S6,Hr,null),b(c,Lno,_),b(c,Oc,_),e(Oc,R6),e(R6,jxe),M(pP,jxe,null),e(Oc,Nlt),e(Oc,Dxe),e(Dxe,qlt),b(c,yno,_),b(c,Fr,_),M(_P,Fr,null),e(Fr,jlt),e(Fr,Vc),e(Vc,Dlt),e(Vc,vse),e(vse,Glt),e(Vc,Olt),e(Vc,Fse),e(Fse,Vlt),e(Vc,Xlt),e(Fr,zlt),e(Fr,bP),e(bP,Qlt),e(bP,Gxe),e(Gxe,Wlt),e(bP,Ult),e(Fr,Hlt),e(Fr,la),M(vP,la,null),e(la,Jlt),e(la,Oxe),e(Oxe,Ylt),e(la,Zlt),e(la,Xc),e(Xc,Klt),e(Xc,Vxe),e(Vxe,eit),e(Xc,oit),e(Xc,Tse),e(Tse,rit),e(Xc,tit),e(la,ait),M(P6,la,null),e(Fr,nit),e(Fr,Jr),M(FP,Jr,null),e(Jr,sit),e(Jr,Xxe),e(Xxe,lit),e(Jr,iit),e(Jr,zn),e(zn,dit),e(zn,zxe),e(zxe,mit),e(zn,cit),e(zn,Qxe),e(Qxe,fit),e(zn,git),e(zn,Wxe),e(Wxe,hit),e(zn,uit),e(Jr,pit),e(Jr,Uxe),e(Uxe,B6),e(B6,Hxe),e(Hxe,_it),e(B6,bit),e(B6,Mse),e(Mse,vit),e(B6,Fit),e(Jr,Tit),M(I6,Jr,null),b(c,xno,_),b(c,zc,_),e(zc,N6),e(N6,Jxe),M(TP,Jxe,null),e(zc,Mit),e(zc,Yxe),e(Yxe,Eit),b(c,$no,_),b(c,Tr,_),M(MP,Tr,null),e(Tr,Cit),e(Tr,Qc),e(Qc,wit),e(Qc,Ese),e(Ese,Ait),e(Qc,Lit),e(Qc,Cse),e(Cse,yit),e(Qc,xit),e(Tr,$it),e(Tr,EP),e(EP,kit),e(EP,Zxe),e(Zxe,Sit),e(EP,Rit),e(Tr,Pit),e(Tr,ia),M(CP,ia,null),e(ia,Bit),e(ia,Kxe),e(Kxe,Iit),e(ia,Nit),e(ia,Wc),e(Wc,qit),e(Wc,e$e),e(e$e,jit),e(Wc,Dit),e(Wc,wse),e(wse,Git),e(Wc,Oit),e(ia,Vit),M(q6,ia,null),e(Tr,Xit),e(Tr,Yr),M(wP,Yr,null),e(Yr,zit),e(Yr,o$e),e(o$e,Qit),e(Yr,Wit),e(Yr,Qn),e(Qn,Uit),e(Qn,r$e),e(r$e,Hit),e(Qn,Jit),e(Qn,t$e),e(t$e,Yit),e(Qn,Zit),e(Qn,a$e),e(a$e,Kit),e(Qn,edt),e(Yr,odt),e(Yr,n$e),e(n$e,j6),e(j6,s$e),e(s$e,rdt),e(j6,tdt),e(j6,Ase),e(Ase,adt),e(j6,ndt),e(Yr,sdt),M(D6,Yr,null),b(c,kno,_),b(c,Uc,_),e(Uc,G6),e(G6,l$e),M(AP,l$e,null),e(Uc,ldt),e(Uc,i$e),e(i$e,idt),b(c,Sno,_),b(c,Mr,_),M(LP,Mr,null),e(Mr,ddt),e(Mr,Hc),e(Hc,mdt),e(Hc,Lse),e(Lse,cdt),e(Hc,fdt),e(Hc,yse),e(yse,gdt),e(Hc,hdt),e(Mr,udt),e(Mr,yP),e(yP,pdt),e(yP,d$e),e(d$e,_dt),e(yP,bdt),e(Mr,vdt),e(Mr,da),M(xP,da,null),e(da,Fdt),e(da,m$e),e(m$e,Tdt),e(da,Mdt),e(da,Jc),e(Jc,Edt),e(Jc,c$e),e(c$e,Cdt),e(Jc,wdt),e(Jc,xse),e(xse,Adt),e(Jc,Ldt),e(da,ydt),M(O6,da,null),e(Mr,xdt),e(Mr,Zr),M($P,Zr,null),e(Zr,$dt),e(Zr,f$e),e(f$e,kdt),e(Zr,Sdt),e(Zr,Wn),e(Wn,Rdt),e(Wn,g$e),e(g$e,Pdt),e(Wn,Bdt),e(Wn,h$e),e(h$e,Idt),e(Wn,Ndt),e(Wn,u$e),e(u$e,qdt),e(Wn,jdt),e(Zr,Ddt),e(Zr,ie),e(ie,V6),e(V6,p$e),e(p$e,Gdt),e(V6,Odt),e(V6,$se),e($se,Vdt),e(V6,Xdt),e(ie,zdt),e(ie,X6),e(X6,_$e),e(_$e,Qdt),e(X6,Wdt),e(X6,kse),e(kse,Udt),e(X6,Hdt),e(ie,Jdt),e(ie,z6),e(z6,b$e),e(b$e,Ydt),e(z6,Zdt),e(z6,Sse),e(Sse,Kdt),e(z6,emt),e(ie,omt),e(ie,Q6),e(Q6,v$e),e(v$e,rmt),e(Q6,tmt),e(Q6,Rse),e(Rse,amt),e(Q6,nmt),e(ie,smt),e(ie,W6),e(W6,F$e),e(F$e,lmt),e(W6,imt),e(W6,Pse),e(Pse,dmt),e(W6,mmt),e(ie,cmt),e(ie,U6),e(U6,T$e),e(T$e,fmt),e(U6,gmt),e(U6,Bse),e(Bse,hmt),e(U6,umt),e(ie,pmt),e(ie,H6),e(H6,M$e),e(M$e,_mt),e(H6,bmt),e(H6,Ise),e(Ise,vmt),e(H6,Fmt),e(ie,Tmt),e(ie,J6),e(J6,E$e),e(E$e,Mmt),e(J6,Emt),e(J6,Nse),e(Nse,Cmt),e(J6,wmt),e(ie,Amt),e(ie,Y6),e(Y6,C$e),e(C$e,Lmt),e(Y6,ymt),e(Y6,qse),e(qse,xmt),e(Y6,$mt),e(ie,kmt),e(ie,Z6),e(Z6,w$e),e(w$e,Smt),e(Z6,Rmt),e(Z6,jse),e(jse,Pmt),e(Z6,Bmt),e(ie,Imt),e(ie,K6),e(K6,A$e),e(A$e,Nmt),e(K6,qmt),e(K6,Dse),e(Dse,jmt),e(K6,Dmt),e(ie,Gmt),e(ie,e7),e(e7,L$e),e(L$e,Omt),e(e7,Vmt),e(e7,Gse),e(Gse,Xmt),e(e7,zmt),e(ie,Qmt),e(ie,o7),e(o7,y$e),e(y$e,Wmt),e(o7,Umt),e(o7,Ose),e(Ose,Hmt),e(o7,Jmt),e(ie,Ymt),e(ie,r7),e(r7,x$e),e(x$e,Zmt),e(r7,Kmt),e(r7,Vse),e(Vse,ect),e(r7,oct),e(ie,rct),e(ie,t7),e(t7,$$e),e($$e,tct),e(t7,act),e(t7,Xse),e(Xse,nct),e(t7,sct),e(ie,lct),e(ie,a7),e(a7,k$e),e(k$e,ict),e(a7,dct),e(a7,zse),e(zse,mct),e(a7,cct),e(ie,fct),e(ie,n7),e(n7,S$e),e(S$e,gct),e(n7,hct),e(n7,Qse),e(Qse,uct),e(n7,pct),e(ie,_ct),e(ie,s7),e(s7,R$e),e(R$e,bct),e(s7,vct),e(s7,Wse),e(Wse,Fct),e(s7,Tct),e(ie,Mct),e(ie,l7),e(l7,P$e),e(P$e,Ect),e(l7,Cct),e(l7,Use),e(Use,wct),e(l7,Act),e(ie,Lct),e(ie,i7),e(i7,B$e),e(B$e,yct),e(i7,xct),e(i7,Hse),e(Hse,$ct),e(i7,kct),e(ie,Sct),e(ie,d7),e(d7,I$e),e(I$e,Rct),e(d7,Pct),e(d7,Jse),e(Jse,Bct),e(d7,Ict),e(ie,Nct),e(ie,m7),e(m7,N$e),e(N$e,qct),e(m7,jct),e(m7,Yse),e(Yse,Dct),e(m7,Gct),e(Zr,Oct),M(c7,Zr,null),b(c,Rno,_),b(c,Yc,_),e(Yc,f7),e(f7,q$e),M(kP,q$e,null),e(Yc,Vct),e(Yc,j$e),e(j$e,Xct),b(c,Pno,_),b(c,Er,_),M(SP,Er,null),e(Er,zct),e(Er,Zc),e(Zc,Qct),e(Zc,Zse),e(Zse,Wct),e(Zc,Uct),e(Zc,Kse),e(Kse,Hct),e(Zc,Jct),e(Er,Yct),e(Er,RP),e(RP,Zct),e(RP,D$e),e(D$e,Kct),e(RP,eft),e(Er,oft),e(Er,ma),M(PP,ma,null),e(ma,rft),e(ma,G$e),e(G$e,tft),e(ma,aft),e(ma,Kc),e(Kc,nft),e(Kc,O$e),e(O$e,sft),e(Kc,lft),e(Kc,ele),e(ele,ift),e(Kc,dft),e(ma,mft),M(g7,ma,null),e(Er,cft),e(Er,Kr),M(BP,Kr,null),e(Kr,fft),e(Kr,V$e),e(V$e,gft),e(Kr,hft),e(Kr,Un),e(Un,uft),e(Un,X$e),e(X$e,pft),e(Un,_ft),e(Un,z$e),e(z$e,bft),e(Un,vft),e(Un,Q$e),e(Q$e,Fft),e(Un,Tft),e(Kr,Mft),e(Kr,fe),e(fe,h7),e(h7,W$e),e(W$e,Eft),e(h7,Cft),e(h7,ole),e(ole,wft),e(h7,Aft),e(fe,Lft),e(fe,u7),e(u7,U$e),e(U$e,yft),e(u7,xft),e(u7,rle),e(rle,$ft),e(u7,kft),e(fe,Sft),e(fe,p7),e(p7,H$e),e(H$e,Rft),e(p7,Pft),e(p7,tle),e(tle,Bft),e(p7,Ift),e(fe,Nft),e(fe,_7),e(_7,J$e),e(J$e,qft),e(_7,jft),e(_7,ale),e(ale,Dft),e(_7,Gft),e(fe,Oft),e(fe,b7),e(b7,Y$e),e(Y$e,Vft),e(b7,Xft),e(b7,nle),e(nle,zft),e(b7,Qft),e(fe,Wft),e(fe,v7),e(v7,Z$e),e(Z$e,Uft),e(v7,Hft),e(v7,sle),e(sle,Jft),e(v7,Yft),e(fe,Zft),e(fe,F7),e(F7,K$e),e(K$e,Kft),e(F7,egt),e(F7,lle),e(lle,ogt),e(F7,rgt),e(fe,tgt),e(fe,T7),e(T7,eke),e(eke,agt),e(T7,ngt),e(T7,ile),e(ile,sgt),e(T7,lgt),e(fe,igt),e(fe,M7),e(M7,oke),e(oke,dgt),e(M7,mgt),e(M7,dle),e(dle,cgt),e(M7,fgt),e(fe,ggt),e(fe,E7),e(E7,rke),e(rke,hgt),e(E7,ugt),e(E7,mle),e(mle,pgt),e(E7,_gt),e(fe,bgt),e(fe,C7),e(C7,tke),e(tke,vgt),e(C7,Fgt),e(C7,cle),e(cle,Tgt),e(C7,Mgt),e(fe,Egt),e(fe,w7),e(w7,ake),e(ake,Cgt),e(w7,wgt),e(w7,fle),e(fle,Agt),e(w7,Lgt),e(fe,ygt),e(fe,A7),e(A7,nke),e(nke,xgt),e(A7,$gt),e(A7,gle),e(gle,kgt),e(A7,Sgt),e(fe,Rgt),e(fe,L7),e(L7,ske),e(ske,Pgt),e(L7,Bgt),e(L7,hle),e(hle,Igt),e(L7,Ngt),e(fe,qgt),e(fe,y7),e(y7,lke),e(lke,jgt),e(y7,Dgt),e(y7,ule),e(ule,Ggt),e(y7,Ogt),e(fe,Vgt),e(fe,x7),e(x7,ike),e(ike,Xgt),e(x7,zgt),e(x7,ple),e(ple,Qgt),e(x7,Wgt),e(fe,Ugt),e(fe,$7),e($7,dke),e(dke,Hgt),e($7,Jgt),e($7,_le),e(_le,Ygt),e($7,Zgt),e(fe,Kgt),e(fe,k7),e(k7,mke),e(mke,eht),e(k7,oht),e(k7,ble),e(ble,rht),e(k7,tht),e(fe,aht),e(fe,S7),e(S7,cke),e(cke,nht),e(S7,sht),e(S7,vle),e(vle,lht),e(S7,iht),e(fe,dht),e(fe,R7),e(R7,fke),e(fke,mht),e(R7,cht),e(R7,Fle),e(Fle,fht),e(R7,ght),e(fe,hht),e(fe,P7),e(P7,gke),e(gke,uht),e(P7,pht),e(P7,Tle),e(Tle,_ht),e(P7,bht),e(Kr,vht),M(B7,Kr,null),b(c,Bno,_),b(c,ef,_),e(ef,I7),e(I7,hke),M(IP,hke,null),e(ef,Fht),e(ef,uke),e(uke,Tht),b(c,Ino,_),b(c,Cr,_),M(NP,Cr,null),e(Cr,Mht),e(Cr,of),e(of,Eht),e(of,Mle),e(Mle,Cht),e(of,wht),e(of,Ele),e(Ele,Aht),e(of,Lht),e(Cr,yht),e(Cr,qP),e(qP,xht),e(qP,pke),e(pke,$ht),e(qP,kht),e(Cr,Sht),e(Cr,ca),M(jP,ca,null),e(ca,Rht),e(ca,_ke),e(_ke,Pht),e(ca,Bht),e(ca,rf),e(rf,Iht),e(rf,bke),e(bke,Nht),e(rf,qht),e(rf,Cle),e(Cle,jht),e(rf,Dht),e(ca,Ght),M(N7,ca,null),e(Cr,Oht),e(Cr,et),M(DP,et,null),e(et,Vht),e(et,vke),e(vke,Xht),e(et,zht),e(et,Hn),e(Hn,Qht),e(Hn,Fke),e(Fke,Wht),e(Hn,Uht),e(Hn,Tke),e(Tke,Hht),e(Hn,Jht),e(Hn,Mke),e(Mke,Yht),e(Hn,Zht),e(et,Kht),e(et,Eke),e(Eke,q7),e(q7,Cke),e(Cke,eut),e(q7,out),e(q7,wle),e(wle,rut),e(q7,tut),e(et,aut),M(j7,et,null),b(c,Nno,_),b(c,tf,_),e(tf,D7),e(D7,wke),M(GP,wke,null),e(tf,nut),e(tf,Ake),e(Ake,sut),b(c,qno,_),b(c,wr,_),M(OP,wr,null),e(wr,lut),e(wr,af),e(af,iut),e(af,Ale),e(Ale,dut),e(af,mut),e(af,Lle),e(Lle,cut),e(af,fut),e(wr,gut),e(wr,VP),e(VP,hut),e(VP,Lke),e(Lke,uut),e(VP,put),e(wr,_ut),e(wr,fa),M(XP,fa,null),e(fa,but),e(fa,yke),e(yke,vut),e(fa,Fut),e(fa,nf),e(nf,Tut),e(nf,xke),e(xke,Mut),e(nf,Eut),e(nf,yle),e(yle,Cut),e(nf,wut),e(fa,Aut),M(G7,fa,null),e(wr,Lut),e(wr,ot),M(zP,ot,null),e(ot,yut),e(ot,$ke),e($ke,xut),e(ot,$ut),e(ot,Jn),e(Jn,kut),e(Jn,kke),e(kke,Sut),e(Jn,Rut),e(Jn,Ske),e(Ske,Put),e(Jn,But),e(Jn,Rke),e(Rke,Iut),e(Jn,Nut),e(ot,qut),e(ot,QP),e(QP,O7),e(O7,Pke),e(Pke,jut),e(O7,Dut),e(O7,xle),e(xle,Gut),e(O7,Out),e(QP,Vut),e(QP,V7),e(V7,Bke),e(Bke,Xut),e(V7,zut),e(V7,$le),e($le,Qut),e(V7,Wut),e(ot,Uut),M(X7,ot,null),b(c,jno,_),b(c,sf,_),e(sf,z7),e(z7,Ike),M(WP,Ike,null),e(sf,Hut),e(sf,Nke),e(Nke,Jut),b(c,Dno,_),b(c,Ar,_),M(UP,Ar,null),e(Ar,Yut),e(Ar,lf),e(lf,Zut),e(lf,kle),e(kle,Kut),e(lf,ept),e(lf,Sle),e(Sle,opt),e(lf,rpt),e(Ar,tpt),e(Ar,HP),e(HP,apt),e(HP,qke),e(qke,npt),e(HP,spt),e(Ar,lpt),e(Ar,ga),M(JP,ga,null),e(ga,ipt),e(ga,jke),e(jke,dpt),e(ga,mpt),e(ga,df),e(df,cpt),e(df,Dke),e(Dke,fpt),e(df,gpt),e(df,Rle),e(Rle,hpt),e(df,upt),e(ga,ppt),M(Q7,ga,null),e(Ar,_pt),e(Ar,rt),M(YP,rt,null),e(rt,bpt),e(rt,Gke),e(Gke,vpt),e(rt,Fpt),e(rt,Yn),e(Yn,Tpt),e(Yn,Oke),e(Oke,Mpt),e(Yn,Ept),e(Yn,Vke),e(Vke,Cpt),e(Yn,wpt),e(Yn,Xke),e(Xke,Apt),e(Yn,Lpt),e(rt,ypt),e(rt,te),e(te,W7),e(W7,zke),e(zke,xpt),e(W7,$pt),e(W7,Ple),e(Ple,kpt),e(W7,Spt),e(te,Rpt),e(te,U7),e(U7,Qke),e(Qke,Ppt),e(U7,Bpt),e(U7,Ble),e(Ble,Ipt),e(U7,Npt),e(te,qpt),e(te,H7),e(H7,Wke),e(Wke,jpt),e(H7,Dpt),e(H7,Ile),e(Ile,Gpt),e(H7,Opt),e(te,Vpt),e(te,J7),e(J7,Uke),e(Uke,Xpt),e(J7,zpt),e(J7,Nle),e(Nle,Qpt),e(J7,Wpt),e(te,Upt),e(te,Y7),e(Y7,Hke),e(Hke,Hpt),e(Y7,Jpt),e(Y7,qle),e(qle,Ypt),e(Y7,Zpt),e(te,Kpt),e(te,Z7),e(Z7,Jke),e(Jke,e_t),e(Z7,o_t),e(Z7,jle),e(jle,r_t),e(Z7,t_t),e(te,a_t),e(te,K7),e(K7,Yke),e(Yke,n_t),e(K7,s_t),e(K7,Dle),e(Dle,l_t),e(K7,i_t),e(te,d_t),e(te,e8),e(e8,Zke),e(Zke,m_t),e(e8,c_t),e(e8,Gle),e(Gle,f_t),e(e8,g_t),e(te,h_t),e(te,o8),e(o8,Kke),e(Kke,u_t),e(o8,p_t),e(o8,Ole),e(Ole,__t),e(o8,b_t),e(te,v_t),e(te,r8),e(r8,eSe),e(eSe,F_t),e(r8,T_t),e(r8,Vle),e(Vle,M_t),e(r8,E_t),e(te,C_t),e(te,t8),e(t8,oSe),e(oSe,w_t),e(t8,A_t),e(t8,Xle),e(Xle,L_t),e(t8,y_t),e(te,x_t),e(te,a8),e(a8,rSe),e(rSe,$_t),e(a8,k_t),e(a8,zle),e(zle,S_t),e(a8,R_t),e(te,P_t),e(te,n8),e(n8,tSe),e(tSe,B_t),e(n8,I_t),e(n8,Qle),e(Qle,N_t),e(n8,q_t),e(te,j_t),e(te,s8),e(s8,aSe),e(aSe,D_t),e(s8,G_t),e(s8,Wle),e(Wle,O_t),e(s8,V_t),e(te,X_t),e(te,l8),e(l8,nSe),e(nSe,z_t),e(l8,Q_t),e(l8,Ule),e(Ule,W_t),e(l8,U_t),e(te,H_t),e(te,i8),e(i8,sSe),e(sSe,J_t),e(i8,Y_t),e(i8,Hle),e(Hle,Z_t),e(i8,K_t),e(te,e1t),e(te,d8),e(d8,lSe),e(lSe,o1t),e(d8,r1t),e(d8,Jle),e(Jle,t1t),e(d8,a1t),e(te,n1t),e(te,m8),e(m8,iSe),e(iSe,s1t),e(m8,l1t),e(m8,Yle),e(Yle,i1t),e(m8,d1t),e(te,m1t),e(te,c8),e(c8,dSe),e(dSe,c1t),e(c8,f1t),e(c8,Zle),e(Zle,g1t),e(c8,h1t),e(te,u1t),e(te,f8),e(f8,mSe),e(mSe,p1t),e(f8,_1t),e(f8,Kle),e(Kle,b1t),e(f8,v1t),e(te,F1t),e(te,g8),e(g8,cSe),e(cSe,T1t),e(g8,M1t),e(g8,eie),e(eie,E1t),e(g8,C1t),e(te,w1t),e(te,h8),e(h8,fSe),e(fSe,A1t),e(h8,L1t),e(h8,oie),e(oie,y1t),e(h8,x1t),e(te,$1t),e(te,u8),e(u8,gSe),e(gSe,k1t),e(u8,S1t),e(u8,rie),e(rie,R1t),e(u8,P1t),e(te,B1t),e(te,p8),e(p8,hSe),e(hSe,I1t),e(p8,N1t),e(p8,tie),e(tie,q1t),e(p8,j1t),e(te,D1t),e(te,_8),e(_8,uSe),e(uSe,G1t),e(_8,O1t),e(_8,aie),e(aie,V1t),e(_8,X1t),e(te,z1t),e(te,b8),e(b8,pSe),e(pSe,Q1t),e(b8,W1t),e(b8,nie),e(nie,U1t),e(b8,H1t),e(te,J1t),e(te,v8),e(v8,_Se),e(_Se,Y1t),e(v8,Z1t),e(v8,sie),e(sie,K1t),e(v8,e2t),e(rt,o2t),M(F8,rt,null),b(c,Gno,_),b(c,mf,_),e(mf,T8),e(T8,bSe),M(ZP,bSe,null),e(mf,r2t),e(mf,vSe),e(vSe,t2t),b(c,Ono,_),b(c,Lr,_),M(KP,Lr,null),e(Lr,a2t),e(Lr,cf),e(cf,n2t),e(cf,lie),e(lie,s2t),e(cf,l2t),e(cf,iie),e(iie,i2t),e(cf,d2t),e(Lr,m2t),e(Lr,eB),e(eB,c2t),e(eB,FSe),e(FSe,f2t),e(eB,g2t),e(Lr,h2t),e(Lr,ha),M(oB,ha,null),e(ha,u2t),e(ha,TSe),e(TSe,p2t),e(ha,_2t),e(ha,ff),e(ff,b2t),e(ff,MSe),e(MSe,v2t),e(ff,F2t),e(ff,die),e(die,T2t),e(ff,M2t),e(ha,E2t),M(M8,ha,null),e(Lr,C2t),e(Lr,tt),M(rB,tt,null),e(tt,w2t),e(tt,ESe),e(ESe,A2t),e(tt,L2t),e(tt,Zn),e(Zn,y2t),e(Zn,CSe),e(CSe,x2t),e(Zn,$2t),e(Zn,wSe),e(wSe,k2t),e(Zn,S2t),e(Zn,ASe),e(ASe,R2t),e(Zn,P2t),e(tt,B2t),e(tt,$e),e($e,E8),e(E8,LSe),e(LSe,I2t),e(E8,N2t),e(E8,mie),e(mie,q2t),e(E8,j2t),e($e,D2t),e($e,C8),e(C8,ySe),e(ySe,G2t),e(C8,O2t),e(C8,cie),e(cie,V2t),e(C8,X2t),e($e,z2t),e($e,w8),e(w8,xSe),e(xSe,Q2t),e(w8,W2t),e(w8,fie),e(fie,U2t),e(w8,H2t),e($e,J2t),e($e,A8),e(A8,$Se),e($Se,Y2t),e(A8,Z2t),e(A8,gie),e(gie,K2t),e(A8,ebt),e($e,obt),e($e,L8),e(L8,kSe),e(kSe,rbt),e(L8,tbt),e(L8,hie),e(hie,abt),e(L8,nbt),e($e,sbt),e($e,y8),e(y8,SSe),e(SSe,lbt),e(y8,ibt),e(y8,uie),e(uie,dbt),e(y8,mbt),e($e,cbt),e($e,x8),e(x8,RSe),e(RSe,fbt),e(x8,gbt),e(x8,pie),e(pie,hbt),e(x8,ubt),e($e,pbt),e($e,$8),e($8,PSe),e(PSe,_bt),e($8,bbt),e($8,_ie),e(_ie,vbt),e($8,Fbt),e($e,Tbt),e($e,k8),e(k8,BSe),e(BSe,Mbt),e(k8,Ebt),e(k8,bie),e(bie,Cbt),e(k8,wbt),e($e,Abt),e($e,S8),e(S8,ISe),e(ISe,Lbt),e(S8,ybt),e(S8,vie),e(vie,xbt),e(S8,$bt),e(tt,kbt),M(R8,tt,null),b(c,Vno,_),b(c,gf,_),e(gf,P8),e(P8,NSe),M(tB,NSe,null),e(gf,Sbt),e(gf,qSe),e(qSe,Rbt),b(c,Xno,_),b(c,yr,_),M(aB,yr,null),e(yr,Pbt),e(yr,hf),e(hf,Bbt),e(hf,Fie),e(Fie,Ibt),e(hf,Nbt),e(hf,Tie),e(Tie,qbt),e(hf,jbt),e(yr,Dbt),e(yr,nB),e(nB,Gbt),e(nB,jSe),e(jSe,Obt),e(nB,Vbt),e(yr,Xbt),e(yr,ua),M(sB,ua,null),e(ua,zbt),e(ua,DSe),e(DSe,Qbt),e(ua,Wbt),e(ua,uf),e(uf,Ubt),e(uf,GSe),e(GSe,Hbt),e(uf,Jbt),e(uf,Mie),e(Mie,Ybt),e(uf,Zbt),e(ua,Kbt),M(B8,ua,null),e(yr,evt),e(yr,at),M(lB,at,null),e(at,ovt),e(at,OSe),e(OSe,rvt),e(at,tvt),e(at,Kn),e(Kn,avt),e(Kn,VSe),e(VSe,nvt),e(Kn,svt),e(Kn,XSe),e(XSe,lvt),e(Kn,ivt),e(Kn,zSe),e(zSe,dvt),e(Kn,mvt),e(at,cvt),e(at,Ee),e(Ee,I8),e(I8,QSe),e(QSe,fvt),e(I8,gvt),e(I8,Eie),e(Eie,hvt),e(I8,uvt),e(Ee,pvt),e(Ee,N8),e(N8,WSe),e(WSe,_vt),e(N8,bvt),e(N8,Cie),e(Cie,vvt),e(N8,Fvt),e(Ee,Tvt),e(Ee,q8),e(q8,USe),e(USe,Mvt),e(q8,Evt),e(q8,wie),e(wie,Cvt),e(q8,wvt),e(Ee,Avt),e(Ee,j8),e(j8,HSe),e(HSe,Lvt),e(j8,yvt),e(j8,Aie),e(Aie,xvt),e(j8,$vt),e(Ee,kvt),e(Ee,D8),e(D8,JSe),e(JSe,Svt),e(D8,Rvt),e(D8,Lie),e(Lie,Pvt),e(D8,Bvt),e(Ee,Ivt),e(Ee,G8),e(G8,YSe),e(YSe,Nvt),e(G8,qvt),e(G8,yie),e(yie,jvt),e(G8,Dvt),e(Ee,Gvt),e(Ee,O8),e(O8,ZSe),e(ZSe,Ovt),e(O8,Vvt),e(O8,xie),e(xie,Xvt),e(O8,zvt),e(Ee,Qvt),e(Ee,V8),e(V8,KSe),e(KSe,Wvt),e(V8,Uvt),e(V8,$ie),e($ie,Hvt),e(V8,Jvt),e(Ee,Yvt),e(Ee,X8),e(X8,eRe),e(eRe,Zvt),e(X8,Kvt),e(X8,kie),e(kie,eFt),e(X8,oFt),e(Ee,rFt),e(Ee,z8),e(z8,oRe),e(oRe,tFt),e(z8,aFt),e(z8,Sie),e(Sie,nFt),e(z8,sFt),e(Ee,lFt),e(Ee,Q8),e(Q8,rRe),e(rRe,iFt),e(Q8,dFt),e(Q8,Rie),e(Rie,mFt),e(Q8,cFt),e(Ee,fFt),e(Ee,W8),e(W8,tRe),e(tRe,gFt),e(W8,hFt),e(W8,Pie),e(Pie,uFt),e(W8,pFt),e(Ee,_Ft),e(Ee,U8),e(U8,aRe),e(aRe,bFt),e(U8,vFt),e(U8,Bie),e(Bie,FFt),e(U8,TFt),e(at,MFt),M(H8,at,null),b(c,zno,_),b(c,pf,_),e(pf,J8),e(J8,nRe),M(iB,nRe,null),e(pf,EFt),e(pf,sRe),e(sRe,CFt),b(c,Qno,_),b(c,xr,_),M(dB,xr,null),e(xr,wFt),e(xr,_f),e(_f,AFt),e(_f,Iie),e(Iie,LFt),e(_f,yFt),e(_f,Nie),e(Nie,xFt),e(_f,$Ft),e(xr,kFt),e(xr,mB),e(mB,SFt),e(mB,lRe),e(lRe,RFt),e(mB,PFt),e(xr,BFt),e(xr,pa),M(cB,pa,null),e(pa,IFt),e(pa,iRe),e(iRe,NFt),e(pa,qFt),e(pa,bf),e(bf,jFt),e(bf,dRe),e(dRe,DFt),e(bf,GFt),e(bf,qie),e(qie,OFt),e(bf,VFt),e(pa,XFt),M(Y8,pa,null),e(xr,zFt),e(xr,nt),M(fB,nt,null),e(nt,QFt),e(nt,mRe),e(mRe,WFt),e(nt,UFt),e(nt,es),e(es,HFt),e(es,cRe),e(cRe,JFt),e(es,YFt),e(es,fRe),e(fRe,ZFt),e(es,KFt),e(es,gRe),e(gRe,eTt),e(es,oTt),e(nt,rTt),e(nt,ke),e(ke,Z8),e(Z8,hRe),e(hRe,tTt),e(Z8,aTt),e(Z8,jie),e(jie,nTt),e(Z8,sTt),e(ke,lTt),e(ke,K8),e(K8,uRe),e(uRe,iTt),e(K8,dTt),e(K8,Die),e(Die,mTt),e(K8,cTt),e(ke,fTt),e(ke,eL),e(eL,pRe),e(pRe,gTt),e(eL,hTt),e(eL,Gie),e(Gie,uTt),e(eL,pTt),e(ke,_Tt),e(ke,oL),e(oL,_Re),e(_Re,bTt),e(oL,vTt),e(oL,Oie),e(Oie,FTt),e(oL,TTt),e(ke,MTt),e(ke,rL),e(rL,bRe),e(bRe,ETt),e(rL,CTt),e(rL,Vie),e(Vie,wTt),e(rL,ATt),e(ke,LTt),e(ke,tL),e(tL,vRe),e(vRe,yTt),e(tL,xTt),e(tL,Xie),e(Xie,$Tt),e(tL,kTt),e(ke,STt),e(ke,aL),e(aL,FRe),e(FRe,RTt),e(aL,PTt),e(aL,zie),e(zie,BTt),e(aL,ITt),e(ke,NTt),e(ke,nL),e(nL,TRe),e(TRe,qTt),e(nL,jTt),e(nL,Qie),e(Qie,DTt),e(nL,GTt),e(ke,OTt),e(ke,sL),e(sL,MRe),e(MRe,VTt),e(sL,XTt),e(sL,Wie),e(Wie,zTt),e(sL,QTt),e(ke,WTt),e(ke,lL),e(lL,ERe),e(ERe,UTt),e(lL,HTt),e(lL,Uie),e(Uie,JTt),e(lL,YTt),e(nt,ZTt),M(iL,nt,null),b(c,Wno,_),b(c,vf,_),e(vf,dL),e(dL,CRe),M(gB,CRe,null),e(vf,KTt),e(vf,wRe),e(wRe,eMt),b(c,Uno,_),b(c,$r,_),M(hB,$r,null),e($r,oMt),e($r,Ff),e(Ff,rMt),e(Ff,Hie),e(Hie,tMt),e(Ff,aMt),e(Ff,Jie),e(Jie,nMt),e(Ff,sMt),e($r,lMt),e($r,uB),e(uB,iMt),e(uB,ARe),e(ARe,dMt),e(uB,mMt),e($r,cMt),e($r,_a),M(pB,_a,null),e(_a,fMt),e(_a,LRe),e(LRe,gMt),e(_a,hMt),e(_a,Tf),e(Tf,uMt),e(Tf,yRe),e(yRe,pMt),e(Tf,_Mt),e(Tf,Yie),e(Yie,bMt),e(Tf,vMt),e(_a,FMt),M(mL,_a,null),e($r,TMt),e($r,st),M(_B,st,null),e(st,MMt),e(st,xRe),e(xRe,EMt),e(st,CMt),e(st,os),e(os,wMt),e(os,$Re),e($Re,AMt),e(os,LMt),e(os,kRe),e(kRe,yMt),e(os,xMt),e(os,SRe),e(SRe,$Mt),e(os,kMt),e(st,SMt),e(st,Se),e(Se,cL),e(cL,RRe),e(RRe,RMt),e(cL,PMt),e(cL,Zie),e(Zie,BMt),e(cL,IMt),e(Se,NMt),e(Se,fL),e(fL,PRe),e(PRe,qMt),e(fL,jMt),e(fL,Kie),e(Kie,DMt),e(fL,GMt),e(Se,OMt),e(Se,gL),e(gL,BRe),e(BRe,VMt),e(gL,XMt),e(gL,ede),e(ede,zMt),e(gL,QMt),e(Se,WMt),e(Se,hL),e(hL,IRe),e(IRe,UMt),e(hL,HMt),e(hL,ode),e(ode,JMt),e(hL,YMt),e(Se,ZMt),e(Se,uL),e(uL,NRe),e(NRe,KMt),e(uL,eEt),e(uL,rde),e(rde,oEt),e(uL,rEt),e(Se,tEt),e(Se,pL),e(pL,qRe),e(qRe,aEt),e(pL,nEt),e(pL,tde),e(tde,sEt),e(pL,lEt),e(Se,iEt),e(Se,_L),e(_L,jRe),e(jRe,dEt),e(_L,mEt),e(_L,ade),e(ade,cEt),e(_L,fEt),e(Se,gEt),e(Se,bL),e(bL,DRe),e(DRe,hEt),e(bL,uEt),e(bL,nde),e(nde,pEt),e(bL,_Et),e(Se,bEt),e(Se,vL),e(vL,GRe),e(GRe,vEt),e(vL,FEt),e(vL,sde),e(sde,TEt),e(vL,MEt),e(Se,EEt),e(Se,FL),e(FL,ORe),e(ORe,CEt),e(FL,wEt),e(FL,lde),e(lde,AEt),e(FL,LEt),e(st,yEt),M(TL,st,null),b(c,Hno,_),b(c,Mf,_),e(Mf,ML),e(ML,VRe),M(bB,VRe,null),e(Mf,xEt),e(Mf,XRe),e(XRe,$Et),b(c,Jno,_),b(c,kr,_),M(vB,kr,null),e(kr,kEt),e(kr,Ef),e(Ef,SEt),e(Ef,ide),e(ide,REt),e(Ef,PEt),e(Ef,dde),e(dde,BEt),e(Ef,IEt),e(kr,NEt),e(kr,FB),e(FB,qEt),e(FB,zRe),e(zRe,jEt),e(FB,DEt),e(kr,GEt),e(kr,ba),M(TB,ba,null),e(ba,OEt),e(ba,QRe),e(QRe,VEt),e(ba,XEt),e(ba,Cf),e(Cf,zEt),e(Cf,WRe),e(WRe,QEt),e(Cf,WEt),e(Cf,mde),e(mde,UEt),e(Cf,HEt),e(ba,JEt),M(EL,ba,null),e(kr,YEt),e(kr,lt),M(MB,lt,null),e(lt,ZEt),e(lt,URe),e(URe,KEt),e(lt,e4t),e(lt,rs),e(rs,o4t),e(rs,HRe),e(HRe,r4t),e(rs,t4t),e(rs,JRe),e(JRe,a4t),e(rs,n4t),e(rs,YRe),e(YRe,s4t),e(rs,l4t),e(lt,i4t),e(lt,Re),e(Re,CL),e(CL,ZRe),e(ZRe,d4t),e(CL,m4t),e(CL,cde),e(cde,c4t),e(CL,f4t),e(Re,g4t),e(Re,wL),e(wL,KRe),e(KRe,h4t),e(wL,u4t),e(wL,fde),e(fde,p4t),e(wL,_4t),e(Re,b4t),e(Re,AL),e(AL,ePe),e(ePe,v4t),e(AL,F4t),e(AL,gde),e(gde,T4t),e(AL,M4t),e(Re,E4t),e(Re,LL),e(LL,oPe),e(oPe,C4t),e(LL,w4t),e(LL,hde),e(hde,A4t),e(LL,L4t),e(Re,y4t),e(Re,yL),e(yL,rPe),e(rPe,x4t),e(yL,$4t),e(yL,ude),e(ude,k4t),e(yL,S4t),e(Re,R4t),e(Re,xL),e(xL,tPe),e(tPe,P4t),e(xL,B4t),e(xL,pde),e(pde,I4t),e(xL,N4t),e(Re,q4t),e(Re,$L),e($L,aPe),e(aPe,j4t),e($L,D4t),e($L,_de),e(_de,G4t),e($L,O4t),e(Re,V4t),e(Re,kL),e(kL,nPe),e(nPe,X4t),e(kL,z4t),e(kL,bde),e(bde,Q4t),e(kL,W4t),e(Re,U4t),e(Re,SL),e(SL,sPe),e(sPe,H4t),e(SL,J4t),e(SL,vde),e(vde,Y4t),e(SL,Z4t),e(Re,K4t),e(Re,RL),e(RL,lPe),e(lPe,eCt),e(RL,oCt),e(RL,Fde),e(Fde,rCt),e(RL,tCt),e(lt,aCt),M(PL,lt,null),b(c,Yno,_),b(c,wf,_),e(wf,BL),e(BL,iPe),M(EB,iPe,null),e(wf,nCt),e(wf,dPe),e(dPe,sCt),b(c,Zno,_),b(c,Sr,_),M(CB,Sr,null),e(Sr,lCt),e(Sr,Af),e(Af,iCt),e(Af,Tde),e(Tde,dCt),e(Af,mCt),e(Af,Mde),e(Mde,cCt),e(Af,fCt),e(Sr,gCt),e(Sr,wB),e(wB,hCt),e(wB,mPe),e(mPe,uCt),e(wB,pCt),e(Sr,_Ct),e(Sr,va),M(AB,va,null),e(va,bCt),e(va,cPe),e(cPe,vCt),e(va,FCt),e(va,Lf),e(Lf,TCt),e(Lf,fPe),e(fPe,MCt),e(Lf,ECt),e(Lf,Ede),e(Ede,CCt),e(Lf,wCt),e(va,ACt),M(IL,va,null),e(Sr,LCt),e(Sr,it),M(LB,it,null),e(it,yCt),e(it,gPe),e(gPe,xCt),e(it,$Ct),e(it,ts),e(ts,kCt),e(ts,hPe),e(hPe,SCt),e(ts,RCt),e(ts,uPe),e(uPe,PCt),e(ts,BCt),e(ts,pPe),e(pPe,ICt),e(ts,NCt),e(it,qCt),e(it,Pe),e(Pe,NL),e(NL,_Pe),e(_Pe,jCt),e(NL,DCt),e(NL,Cde),e(Cde,GCt),e(NL,OCt),e(Pe,VCt),e(Pe,qL),e(qL,bPe),e(bPe,XCt),e(qL,zCt),e(qL,wde),e(wde,QCt),e(qL,WCt),e(Pe,UCt),e(Pe,jL),e(jL,vPe),e(vPe,HCt),e(jL,JCt),e(jL,Ade),e(Ade,YCt),e(jL,ZCt),e(Pe,KCt),e(Pe,DL),e(DL,FPe),e(FPe,e3t),e(DL,o3t),e(DL,Lde),e(Lde,r3t),e(DL,t3t),e(Pe,a3t),e(Pe,GL),e(GL,TPe),e(TPe,n3t),e(GL,s3t),e(GL,yde),e(yde,l3t),e(GL,i3t),e(Pe,d3t),e(Pe,OL),e(OL,MPe),e(MPe,m3t),e(OL,c3t),e(OL,xde),e(xde,f3t),e(OL,g3t),e(Pe,h3t),e(Pe,VL),e(VL,EPe),e(EPe,u3t),e(VL,p3t),e(VL,$de),e($de,_3t),e(VL,b3t),e(Pe,v3t),e(Pe,XL),e(XL,CPe),e(CPe,F3t),e(XL,T3t),e(XL,kde),e(kde,M3t),e(XL,E3t),e(Pe,C3t),e(Pe,zL),e(zL,wPe),e(wPe,w3t),e(zL,A3t),e(zL,Sde),e(Sde,L3t),e(zL,y3t),e(Pe,x3t),e(Pe,QL),e(QL,APe),e(APe,$3t),e(QL,k3t),e(QL,Rde),e(Rde,S3t),e(QL,R3t),e(it,P3t),M(WL,it,null),b(c,Kno,_),b(c,yf,_),e(yf,UL),e(UL,LPe),M(yB,LPe,null),e(yf,B3t),e(yf,yPe),e(yPe,I3t),b(c,eso,_),b(c,Rr,_),M(xB,Rr,null),e(Rr,N3t),e(Rr,xf),e(xf,q3t),e(xf,Pde),e(Pde,j3t),e(xf,D3t),e(xf,Bde),e(Bde,G3t),e(xf,O3t),e(Rr,V3t),e(Rr,$B),e($B,X3t),e($B,xPe),e(xPe,z3t),e($B,Q3t),e(Rr,W3t),e(Rr,Fa),M(kB,Fa,null),e(Fa,U3t),e(Fa,$Pe),e($Pe,H3t),e(Fa,J3t),e(Fa,$f),e($f,Y3t),e($f,kPe),e(kPe,Z3t),e($f,K3t),e($f,Ide),e(Ide,e5t),e($f,o5t),e(Fa,r5t),M(HL,Fa,null),e(Rr,t5t),e(Rr,dt),M(SB,dt,null),e(dt,a5t),e(dt,SPe),e(SPe,n5t),e(dt,s5t),e(dt,as),e(as,l5t),e(as,RPe),e(RPe,i5t),e(as,d5t),e(as,PPe),e(PPe,m5t),e(as,c5t),e(as,BPe),e(BPe,f5t),e(as,g5t),e(dt,h5t),e(dt,ze),e(ze,JL),e(JL,IPe),e(IPe,u5t),e(JL,p5t),e(JL,Nde),e(Nde,_5t),e(JL,b5t),e(ze,v5t),e(ze,YL),e(YL,NPe),e(NPe,F5t),e(YL,T5t),e(YL,qde),e(qde,M5t),e(YL,E5t),e(ze,C5t),e(ze,ZL),e(ZL,qPe),e(qPe,w5t),e(ZL,A5t),e(ZL,jde),e(jde,L5t),e(ZL,y5t),e(ze,x5t),e(ze,KL),e(KL,jPe),e(jPe,$5t),e(KL,k5t),e(KL,Dde),e(Dde,S5t),e(KL,R5t),e(ze,P5t),e(ze,ey),e(ey,DPe),e(DPe,B5t),e(ey,I5t),e(ey,Gde),e(Gde,N5t),e(ey,q5t),e(ze,j5t),e(ze,oy),e(oy,GPe),e(GPe,D5t),e(oy,G5t),e(oy,Ode),e(Ode,O5t),e(oy,V5t),e(ze,X5t),e(ze,ry),e(ry,OPe),e(OPe,z5t),e(ry,Q5t),e(ry,Vde),e(Vde,W5t),e(ry,U5t),e(ze,H5t),e(ze,ty),e(ty,VPe),e(VPe,J5t),e(ty,Y5t),e(ty,Xde),e(Xde,Z5t),e(ty,K5t),e(dt,e0t),M(ay,dt,null),b(c,oso,_),b(c,kf,_),e(kf,ny),e(ny,XPe),M(RB,XPe,null),e(kf,o0t),e(kf,zPe),e(zPe,r0t),b(c,rso,_),b(c,Pr,_),M(PB,Pr,null),e(Pr,t0t),e(Pr,Sf),e(Sf,a0t),e(Sf,zde),e(zde,n0t),e(Sf,s0t),e(Sf,Qde),e(Qde,l0t),e(Sf,i0t),e(Pr,d0t),e(Pr,BB),e(BB,m0t),e(BB,QPe),e(QPe,c0t),e(BB,f0t),e(Pr,g0t),e(Pr,Ta),M(IB,Ta,null),e(Ta,h0t),e(Ta,WPe),e(WPe,u0t),e(Ta,p0t),e(Ta,Rf),e(Rf,_0t),e(Rf,UPe),e(UPe,b0t),e(Rf,v0t),e(Rf,Wde),e(Wde,F0t),e(Rf,T0t),e(Ta,M0t),M(sy,Ta,null),e(Pr,E0t),e(Pr,mt),M(NB,mt,null),e(mt,C0t),e(mt,HPe),e(HPe,w0t),e(mt,A0t),e(mt,ns),e(ns,L0t),e(ns,JPe),e(JPe,y0t),e(ns,x0t),e(ns,YPe),e(YPe,$0t),e(ns,k0t),e(ns,ZPe),e(ZPe,S0t),e(ns,R0t),e(mt,P0t),e(mt,Qe),e(Qe,ly),e(ly,KPe),e(KPe,B0t),e(ly,I0t),e(ly,Ude),e(Ude,N0t),e(ly,q0t),e(Qe,j0t),e(Qe,iy),e(iy,eBe),e(eBe,D0t),e(iy,G0t),e(iy,Hde),e(Hde,O0t),e(iy,V0t),e(Qe,X0t),e(Qe,dy),e(dy,oBe),e(oBe,z0t),e(dy,Q0t),e(dy,Jde),e(Jde,W0t),e(dy,U0t),e(Qe,H0t),e(Qe,my),e(my,rBe),e(rBe,J0t),e(my,Y0t),e(my,Yde),e(Yde,Z0t),e(my,K0t),e(Qe,ewt),e(Qe,cy),e(cy,tBe),e(tBe,owt),e(cy,rwt),e(cy,Zde),e(Zde,twt),e(cy,awt),e(Qe,nwt),e(Qe,fy),e(fy,aBe),e(aBe,swt),e(fy,lwt),e(fy,Kde),e(Kde,iwt),e(fy,dwt),e(Qe,mwt),e(Qe,gy),e(gy,nBe),e(nBe,cwt),e(gy,fwt),e(gy,eme),e(eme,gwt),e(gy,hwt),e(Qe,uwt),e(Qe,hy),e(hy,sBe),e(sBe,pwt),e(hy,_wt),e(hy,ome),e(ome,bwt),e(hy,vwt),e(mt,Fwt),M(uy,mt,null),b(c,tso,_),b(c,Pf,_),e(Pf,py),e(py,lBe),M(qB,lBe,null),e(Pf,Twt),e(Pf,iBe),e(iBe,Mwt),b(c,aso,_),b(c,Br,_),M(jB,Br,null),e(Br,Ewt),e(Br,Bf),e(Bf,Cwt),e(Bf,rme),e(rme,wwt),e(Bf,Awt),e(Bf,tme),e(tme,Lwt),e(Bf,ywt),e(Br,xwt),e(Br,DB),e(DB,$wt),e(DB,dBe),e(dBe,kwt),e(DB,Swt),e(Br,Rwt),e(Br,Ma),M(GB,Ma,null),e(Ma,Pwt),e(Ma,mBe),e(mBe,Bwt),e(Ma,Iwt),e(Ma,If),e(If,Nwt),e(If,cBe),e(cBe,qwt),e(If,jwt),e(If,ame),e(ame,Dwt),e(If,Gwt),e(Ma,Owt),M(_y,Ma,null),e(Br,Vwt),e(Br,ct),M(OB,ct,null),e(ct,Xwt),e(ct,fBe),e(fBe,zwt),e(ct,Qwt),e(ct,ss),e(ss,Wwt),e(ss,gBe),e(gBe,Uwt),e(ss,Hwt),e(ss,hBe),e(hBe,Jwt),e(ss,Ywt),e(ss,uBe),e(uBe,Zwt),e(ss,Kwt),e(ct,eAt),e(ct,pBe),e(pBe,by),e(by,_Be),e(_Be,oAt),e(by,rAt),e(by,nme),e(nme,tAt),e(by,aAt),e(ct,nAt),M(vy,ct,null),b(c,nso,_),b(c,Nf,_),e(Nf,Fy),e(Fy,bBe),M(VB,bBe,null),e(Nf,sAt),e(Nf,vBe),e(vBe,lAt),b(c,sso,_),b(c,Ir,_),M(XB,Ir,null),e(Ir,iAt),e(Ir,qf),e(qf,dAt),e(qf,sme),e(sme,mAt),e(qf,cAt),e(qf,lme),e(lme,fAt),e(qf,gAt),e(Ir,hAt),e(Ir,zB),e(zB,uAt),e(zB,FBe),e(FBe,pAt),e(zB,_At),e(Ir,bAt),e(Ir,Ea),M(QB,Ea,null),e(Ea,vAt),e(Ea,TBe),e(TBe,FAt),e(Ea,TAt),e(Ea,jf),e(jf,MAt),e(jf,MBe),e(MBe,EAt),e(jf,CAt),e(jf,ime),e(ime,wAt),e(jf,AAt),e(Ea,LAt),M(Ty,Ea,null),e(Ir,yAt),e(Ir,ft),M(WB,ft,null),e(ft,xAt),e(ft,EBe),e(EBe,$At),e(ft,kAt),e(ft,ls),e(ls,SAt),e(ls,CBe),e(CBe,RAt),e(ls,PAt),e(ls,wBe),e(wBe,BAt),e(ls,IAt),e(ls,ABe),e(ABe,NAt),e(ls,qAt),e(ft,jAt),e(ft,UB),e(UB,My),e(My,LBe),e(LBe,DAt),e(My,GAt),e(My,dme),e(dme,OAt),e(My,VAt),e(UB,XAt),e(UB,Ey),e(Ey,yBe),e(yBe,zAt),e(Ey,QAt),e(Ey,mme),e(mme,WAt),e(Ey,UAt),e(ft,HAt),M(Cy,ft,null),b(c,lso,_),b(c,Df,_),e(Df,wy),e(wy,xBe),M(HB,xBe,null),e(Df,JAt),e(Df,$Be),e($Be,YAt),b(c,iso,_),b(c,Nr,_),M(JB,Nr,null),e(Nr,ZAt),e(Nr,Gf),e(Gf,KAt),e(Gf,cme),e(cme,e6t),e(Gf,o6t),e(Gf,fme),e(fme,r6t),e(Gf,t6t),e(Nr,a6t),e(Nr,YB),e(YB,n6t),e(YB,kBe),e(kBe,s6t),e(YB,l6t),e(Nr,i6t),e(Nr,Ca),M(ZB,Ca,null),e(Ca,d6t),e(Ca,SBe),e(SBe,m6t),e(Ca,c6t),e(Ca,Of),e(Of,f6t),e(Of,RBe),e(RBe,g6t),e(Of,h6t),e(Of,gme),e(gme,u6t),e(Of,p6t),e(Ca,_6t),M(Ay,Ca,null),e(Nr,b6t),e(Nr,gt),M(KB,gt,null),e(gt,v6t),e(gt,PBe),e(PBe,F6t),e(gt,T6t),e(gt,is),e(is,M6t),e(is,BBe),e(BBe,E6t),e(is,C6t),e(is,IBe),e(IBe,w6t),e(is,A6t),e(is,NBe),e(NBe,L6t),e(is,y6t),e(gt,x6t),e(gt,qBe),e(qBe,Ly),e(Ly,jBe),e(jBe,$6t),e(Ly,k6t),e(Ly,hme),e(hme,S6t),e(Ly,R6t),e(gt,P6t),M(yy,gt,null),dso=!0},p(c,[_]){const eI={};_&2&&(eI.$$scope={dirty:_,ctx:c}),Yf.$set(eI);const DBe={};_&2&&(DBe.$$scope={dirty:_,ctx:c}),Lu.$set(DBe);const GBe={};_&2&&(GBe.$$scope={dirty:_,ctx:c}),fp.$set(GBe);const OBe={};_&2&&(OBe.$$scope={dirty:_,ctx:c}),s_.$set(OBe);const oI={};_&2&&(oI.$$scope={dirty:_,ctx:c}),l_.$set(oI);const VBe={};_&2&&(VBe.$$scope={dirty:_,ctx:c}),R_.$set(VBe);const ds={};_&2&&(ds.$$scope={dirty:_,ctx:c}),P_.$set(ds);const XBe={};_&2&&(XBe.$$scope={dirty:_,ctx:c}),N_.$set(XBe);const zBe={};_&2&&(zBe.$$scope={dirty:_,ctx:c}),sb.$set(zBe);const QBe={};_&2&&(QBe.$$scope={dirty:_,ctx:c}),ib.$set(QBe);const rI={};_&2&&(rI.$$scope={dirty:_,ctx:c}),av.$set(rI);const WBe={};_&2&&(WBe.$$scope={dirty:_,ctx:c}),sv.$set(WBe);const tI={};_&2&&(tI.$$scope={dirty:_,ctx:c}),Jv.$set(tI);const UBe={};_&2&&(UBe.$$scope={dirty:_,ctx:c}),Zv.$set(UBe);const aI={};_&2&&(aI.$$scope={dirty:_,ctx:c}),rF.$set(aI);const HBe={};_&2&&(HBe.$$scope={dirty:_,ctx:c}),aF.$set(HBe);const JBe={};_&2&&(JBe.$$scope={dirty:_,ctx:c}),zF.$set(JBe);const YBe={};_&2&&(YBe.$$scope={dirty:_,ctx:c}),WF.$set(YBe);const Vf={};_&2&&(Vf.$$scope={dirty:_,ctx:c}),uT.$set(Vf);const ZBe={};_&2&&(ZBe.$$scope={dirty:_,ctx:c}),_T.$set(ZBe);const KBe={};_&2&&(KBe.$$scope={dirty:_,ctx:c}),TM.$set(KBe);const eIe={};_&2&&(eIe.$$scope={dirty:_,ctx:c}),EM.$set(eIe);const nI={};_&2&&(nI.$$scope={dirty:_,ctx:c}),tE.$set(nI);const oIe={};_&2&&(oIe.$$scope={dirty:_,ctx:c}),nE.$set(oIe);const rIe={};_&2&&(rIe.$$scope={dirty:_,ctx:c}),hE.$set(rIe);const tIe={};_&2&&(tIe.$$scope={dirty:_,ctx:c}),pE.$set(tIe);const vt={};_&2&&(vt.$$scope={dirty:_,ctx:c}),n4.$set(vt);const sI={};_&2&&(sI.$$scope={dirty:_,ctx:c}),l4.$set(sI);const aIe={};_&2&&(aIe.$$scope={dirty:_,ctx:c}),tC.$set(aIe);const lI={};_&2&&(lI.$$scope={dirty:_,ctx:c}),nC.$set(lI);const nIe={};_&2&&(nIe.$$scope={dirty:_,ctx:c}),iC.$set(nIe);const Ft={};_&2&&(Ft.$$scope={dirty:_,ctx:c}),mC.$set(Ft);const sIe={};_&2&&(sIe.$$scope={dirty:_,ctx:c}),uC.$set(sIe);const Xf={};_&2&&(Xf.$$scope={dirty:_,ctx:c}),_C.$set(Xf);const lIe={};_&2&&(lIe.$$scope={dirty:_,ctx:c}),PC.$set(lIe);const iIe={};_&2&&(iIe.$$scope={dirty:_,ctx:c}),IC.$set(iIe);const L={};_&2&&(L.$$scope={dirty:_,ctx:c}),jC.$set(L);const xy={};_&2&&(xy.$$scope={dirty:_,ctx:c}),GC.$set(xy);const dIe={};_&2&&(dIe.$$scope={dirty:_,ctx:c}),XC.$set(dIe);const mIe={};_&2&&(mIe.$$scope={dirty:_,ctx:c}),QC.$set(mIe);const $y={};_&2&&($y.$$scope={dirty:_,ctx:c}),HC.$set($y);const cIe={};_&2&&(cIe.$$scope={dirty:_,ctx:c}),YC.$set(cIe);const fIe={};_&2&&(fIe.$$scope={dirty:_,ctx:c}),i3.$set(fIe);const ky={};_&2&&(ky.$$scope={dirty:_,ctx:c}),m3.$set(ky);const gIe={};_&2&&(gIe.$$scope={dirty:_,ctx:c}),_3.$set(gIe);const hIe={};_&2&&(hIe.$$scope={dirty:_,ctx:c}),v3.$set(hIe);const Sy={};_&2&&(Sy.$$scope={dirty:_,ctx:c}),k3.$set(Sy);const uIe={};_&2&&(uIe.$$scope={dirty:_,ctx:c}),R3.$set(uIe);const pIe={};_&2&&(pIe.$$scope={dirty:_,ctx:c}),q3.$set(pIe);const Ry={};_&2&&(Ry.$$scope={dirty:_,ctx:c}),D3.$set(Ry);const _Ie={};_&2&&(_Ie.$$scope={dirty:_,ctx:c}),W3.$set(_Ie);const bIe={};_&2&&(bIe.$$scope={dirty:_,ctx:c}),H3.$set(bIe);const Py={};_&2&&(Py.$$scope={dirty:_,ctx:c}),o5.$set(Py);const vIe={};_&2&&(vIe.$$scope={dirty:_,ctx:c}),t5.$set(vIe);const FIe={};_&2&&(FIe.$$scope={dirty:_,ctx:c}),m5.$set(FIe);const By={};_&2&&(By.$$scope={dirty:_,ctx:c}),f5.$set(By);const TIe={};_&2&&(TIe.$$scope={dirty:_,ctx:c}),u5.$set(TIe);const MIe={};_&2&&(MIe.$$scope={dirty:_,ctx:c}),_5.$set(MIe);const Iy={};_&2&&(Iy.$$scope={dirty:_,ctx:c}),C5.$set(Iy);const EIe={};_&2&&(EIe.$$scope={dirty:_,ctx:c}),A5.$set(EIe);const CIe={};_&2&&(CIe.$$scope={dirty:_,ctx:c}),x5.$set(CIe);const Ny={};_&2&&(Ny.$$scope={dirty:_,ctx:c}),k5.$set(Ny);const wIe={};_&2&&(wIe.$$scope={dirty:_,ctx:c}),P5.$set(wIe);const AIe={};_&2&&(AIe.$$scope={dirty:_,ctx:c}),I5.$set(AIe);const qy={};_&2&&(qy.$$scope={dirty:_,ctx:c}),D0.$set(qy);const LIe={};_&2&&(LIe.$$scope={dirty:_,ctx:c}),O0.$set(LIe);const yIe={};_&2&&(yIe.$$scope={dirty:_,ctx:c}),fw.$set(yIe);const jy={};_&2&&(jy.$$scope={dirty:_,ctx:c}),hw.$set(jy);const xIe={};_&2&&(xIe.$$scope={dirty:_,ctx:c}),xw.$set(xIe);const $Ie={};_&2&&($Ie.$$scope={dirty:_,ctx:c}),kw.$set($Ie);const Dy={};_&2&&(Dy.$$scope={dirty:_,ctx:c}),Gw.$set(Dy);const kIe={};_&2&&(kIe.$$scope={dirty:_,ctx:c}),Vw.$set(kIe);const SIe={};_&2&&(SIe.$$scope={dirty:_,ctx:c}),Ww.$set(SIe);const Gy={};_&2&&(Gy.$$scope={dirty:_,ctx:c}),Hw.$set(Gy);const RIe={};_&2&&(RIe.$$scope={dirty:_,ctx:c}),_A.$set(RIe);const PIe={};_&2&&(PIe.$$scope={dirty:_,ctx:c}),vA.$set(PIe);const Oy={};_&2&&(Oy.$$scope={dirty:_,ctx:c}),$A.$set(Oy);const BIe={};_&2&&(BIe.$$scope={dirty:_,ctx:c}),SA.$set(BIe);const IIe={};_&2&&(IIe.$$scope={dirty:_,ctx:c}),l6.$set(IIe);const Vy={};_&2&&(Vy.$$scope={dirty:_,ctx:c}),d6.$set(Vy);const NIe={};_&2&&(NIe.$$scope={dirty:_,ctx:c}),L6.$set(NIe);const qIe={};_&2&&(qIe.$$scope={dirty:_,ctx:c}),x6.$set(qIe);const Xy={};_&2&&(Xy.$$scope={dirty:_,ctx:c}),S6.$set(Xy);const jIe={};_&2&&(jIe.$$scope={dirty:_,ctx:c}),P6.$set(jIe);const DIe={};_&2&&(DIe.$$scope={dirty:_,ctx:c}),I6.$set(DIe);const zy={};_&2&&(zy.$$scope={dirty:_,ctx:c}),q6.$set(zy);const GIe={};_&2&&(GIe.$$scope={dirty:_,ctx:c}),D6.$set(GIe);const OIe={};_&2&&(OIe.$$scope={dirty:_,ctx:c}),O6.$set(OIe);const Qy={};_&2&&(Qy.$$scope={dirty:_,ctx:c}),c7.$set(Qy);const VIe={};_&2&&(VIe.$$scope={dirty:_,ctx:c}),g7.$set(VIe);const XIe={};_&2&&(XIe.$$scope={dirty:_,ctx:c}),B7.$set(XIe);const Wy={};_&2&&(Wy.$$scope={dirty:_,ctx:c}),N7.$set(Wy);const zIe={};_&2&&(zIe.$$scope={dirty:_,ctx:c}),j7.$set(zIe);const QIe={};_&2&&(QIe.$$scope={dirty:_,ctx:c}),G7.$set(QIe);const Uy={};_&2&&(Uy.$$scope={dirty:_,ctx:c}),X7.$set(Uy);const WIe={};_&2&&(WIe.$$scope={dirty:_,ctx:c}),Q7.$set(WIe);const UIe={};_&2&&(UIe.$$scope={dirty:_,ctx:c}),F8.$set(UIe);const Hy={};_&2&&(Hy.$$scope={dirty:_,ctx:c}),M8.$set(Hy);const HIe={};_&2&&(HIe.$$scope={dirty:_,ctx:c}),R8.$set(HIe);const JIe={};_&2&&(JIe.$$scope={dirty:_,ctx:c}),B8.$set(JIe);const Jy={};_&2&&(Jy.$$scope={dirty:_,ctx:c}),H8.$set(Jy);const YIe={};_&2&&(YIe.$$scope={dirty:_,ctx:c}),Y8.$set(YIe);const ZIe={};_&2&&(ZIe.$$scope={dirty:_,ctx:c}),iL.$set(ZIe);const Yy={};_&2&&(Yy.$$scope={dirty:_,ctx:c}),mL.$set(Yy);const KIe={};_&2&&(KIe.$$scope={dirty:_,ctx:c}),TL.$set(KIe);const eNe={};_&2&&(eNe.$$scope={dirty:_,ctx:c}),EL.$set(eNe);const Zy={};_&2&&(Zy.$$scope={dirty:_,ctx:c}),PL.$set(Zy);const oNe={};_&2&&(oNe.$$scope={dirty:_,ctx:c}),IL.$set(oNe);const rNe={};_&2&&(rNe.$$scope={dirty:_,ctx:c}),WL.$set(rNe);const Ky={};_&2&&(Ky.$$scope={dirty:_,ctx:c}),HL.$set(Ky);const tNe={};_&2&&(tNe.$$scope={dirty:_,ctx:c}),ay.$set(tNe);const aNe={};_&2&&(aNe.$$scope={dirty:_,ctx:c}),sy.$set(aNe);const e9={};_&2&&(e9.$$scope={dirty:_,ctx:c}),uy.$set(e9);const nNe={};_&2&&(nNe.$$scope={dirty:_,ctx:c}),_y.$set(nNe);const sNe={};_&2&&(sNe.$$scope={dirty:_,ctx:c}),vy.$set(sNe);const o9={};_&2&&(o9.$$scope={dirty:_,ctx:c}),Ty.$set(o9);const lNe={};_&2&&(lNe.$$scope={dirty:_,ctx:c}),Cy.$set(lNe);const iNe={};_&2&&(iNe.$$scope={dirty:_,ctx:c}),Ay.$set(iNe);const r9={};_&2&&(r9.$$scope={dirty:_,ctx:c}),yy.$set(r9)},i(c){dso||(E(d.$$.fragment,c),E(on.$$.fragment,c),E(h$.$$.fragment,c),E(u$.$$.fragment,c),E(Yf.$$.fragment,c),E(p$.$$.fragment,c),E(_$.$$.fragment,c),E(F$.$$.fragment,c),E(Lu.$$.fragment,c),E(T$.$$.fragment,c),E(M$.$$.fragment,c),E(E$.$$.fragment,c),E(A$.$$.fragment,c),E(fp.$$.fragment,c),E(L$.$$.fragment,c),E(y$.$$.fragment,c),E(x$.$$.fragment,c),E(S$.$$.fragment,c),E(s_.$$.fragment,c),E(l_.$$.fragment,c),E(R$.$$.fragment,c),E(P$.$$.fragment,c),E(B$.$$.fragment,c),E(q$.$$.fragment,c),E(R_.$$.fragment,c),E(P_.$$.fragment,c),E(j$.$$.fragment,c),E(D$.$$.fragment,c),E(G$.$$.fragment,c),E(V$.$$.fragment,c),E(N_.$$.fragment,c),E(X$.$$.fragment,c),E(sb.$$.fragment,c),E(z$.$$.fragment,c),E(Q$.$$.fragment,c),E(U$.$$.fragment,c),E(ib.$$.fragment,c),E(H$.$$.fragment,c),E(av.$$.fragment,c),E(J$.$$.fragment,c),E(Y$.$$.fragment,c),E(K$.$$.fragment,c),E(sv.$$.fragment,c),E(ek.$$.fragment,c),E(Jv.$$.fragment,c),E(ok.$$.fragment,c),E(rk.$$.fragment,c),E(ak.$$.fragment,c),E(Zv.$$.fragment,c),E(nk.$$.fragment,c),E(rF.$$.fragment,c),E(lk.$$.fragment,c),E(ik.$$.fragment,c),E(mk.$$.fragment,c),E(aF.$$.fragment,c),E(ck.$$.fragment,c),E(zF.$$.fragment,c),E(fk.$$.fragment,c),E(gk.$$.fragment,c),E(uk.$$.fragment,c),E(WF.$$.fragment,c),E(pk.$$.fragment,c),E(uT.$$.fragment,c),E(_k.$$.fragment,c),E(bk.$$.fragment,c),E(Fk.$$.fragment,c),E(_T.$$.fragment,c),E(Tk.$$.fragment,c),E(TM.$$.fragment,c),E(Mk.$$.fragment,c),E(Ek.$$.fragment,c),E(wk.$$.fragment,c),E(EM.$$.fragment,c),E(Ak.$$.fragment,c),E(tE.$$.fragment,c),E(Lk.$$.fragment,c),E(yk.$$.fragment,c),E($k.$$.fragment,c),E(nE.$$.fragment,c),E(kk.$$.fragment,c),E(hE.$$.fragment,c),E(Sk.$$.fragment,c),E(Rk.$$.fragment,c),E(Bk.$$.fragment,c),E(pE.$$.fragment,c),E(Ik.$$.fragment,c),E(n4.$$.fragment,c),E(Nk.$$.fragment,c),E(qk.$$.fragment,c),E(Dk.$$.fragment,c),E(l4.$$.fragment,c),E(Gk.$$.fragment,c),E(tC.$$.fragment,c),E(Ok.$$.fragment,c),E(Vk.$$.fragment,c),E(zk.$$.fragment,c),E(nC.$$.fragment,c),E(Qk.$$.fragment,c),E(iC.$$.fragment,c),E(Wk.$$.fragment,c),E(Uk.$$.fragment,c),E(Jk.$$.fragment,c),E(mC.$$.fragment,c),E(Yk.$$.fragment,c),E(uC.$$.fragment,c),E(Zk.$$.fragment,c),E(Kk.$$.fragment,c),E(oS.$$.fragment,c),E(_C.$$.fragment,c),E(rS.$$.fragment,c),E(PC.$$.fragment,c),E(tS.$$.fragment,c),E(aS.$$.fragment,c),E(sS.$$.fragment,c),E(IC.$$.fragment,c),E(lS.$$.fragment,c),E(jC.$$.fragment,c),E(iS.$$.fragment,c),E(dS.$$.fragment,c),E(cS.$$.fragment,c),E(GC.$$.fragment,c),E(fS.$$.fragment,c),E(XC.$$.fragment,c),E(gS.$$.fragment,c),E(hS.$$.fragment,c),E(pS.$$.fragment,c),E(QC.$$.fragment,c),E(_S.$$.fragment,c),E(HC.$$.fragment,c),E(bS.$$.fragment,c),E(vS.$$.fragment,c),E(TS.$$.fragment,c),E(YC.$$.fragment,c),E(MS.$$.fragment,c),E(i3.$$.fragment,c),E(ES.$$.fragment,c),E(CS.$$.fragment,c),E(AS.$$.fragment,c),E(m3.$$.fragment,c),E(LS.$$.fragment,c),E(_3.$$.fragment,c),E(yS.$$.fragment,c),E(xS.$$.fragment,c),E(kS.$$.fragment,c),E(v3.$$.fragment,c),E(SS.$$.fragment,c),E(k3.$$.fragment,c),E(RS.$$.fragment,c),E(PS.$$.fragment,c),E(IS.$$.fragment,c),E(R3.$$.fragment,c),E(NS.$$.fragment,c),E(q3.$$.fragment,c),E(qS.$$.fragment,c),E(jS.$$.fragment,c),E(GS.$$.fragment,c),E(D3.$$.fragment,c),E(OS.$$.fragment,c),E(W3.$$.fragment,c),E(VS.$$.fragment,c),E(XS.$$.fragment,c),E(QS.$$.fragment,c),E(H3.$$.fragment,c),E(WS.$$.fragment,c),E(o5.$$.fragment,c),E(US.$$.fragment,c),E(HS.$$.fragment,c),E(YS.$$.fragment,c),E(t5.$$.fragment,c),E(ZS.$$.fragment,c),E(m5.$$.fragment,c),E(KS.$$.fragment,c),E(eR.$$.fragment,c),E(rR.$$.fragment,c),E(f5.$$.fragment,c),E(tR.$$.fragment,c),E(u5.$$.fragment,c),E(aR.$$.fragment,c),E(nR.$$.fragment,c),E(lR.$$.fragment,c),E(_5.$$.fragment,c),E(iR.$$.fragment,c),E(C5.$$.fragment,c),E(dR.$$.fragment,c),E(mR.$$.fragment,c),E(fR.$$.fragment,c),E(A5.$$.fragment,c),E(gR.$$.fragment,c),E(x5.$$.fragment,c),E(hR.$$.fragment,c),E(uR.$$.fragment,c),E(_R.$$.fragment,c),E(k5.$$.fragment,c),E(bR.$$.fragment,c),E(P5.$$.fragment,c),E(vR.$$.fragment,c),E(FR.$$.fragment,c),E(MR.$$.fragment,c),E(I5.$$.fragment,c),E(ER.$$.fragment,c),E(D0.$$.fragment,c),E(CR.$$.fragment,c),E(wR.$$.fragment,c),E(LR.$$.fragment,c),E(O0.$$.fragment,c),E(yR.$$.fragment,c),E(fw.$$.fragment,c),E(xR.$$.fragment,c),E($R.$$.fragment,c),E(SR.$$.fragment,c),E(hw.$$.fragment,c),E(RR.$$.fragment,c),E(xw.$$.fragment,c),E(PR.$$.fragment,c),E(BR.$$.fragment,c),E(NR.$$.fragment,c),E(kw.$$.fragment,c),E(qR.$$.fragment,c),E(Gw.$$.fragment,c),E(jR.$$.fragment,c),E(DR.$$.fragment,c),E(OR.$$.fragment,c),E(Vw.$$.fragment,c),E(VR.$$.fragment,c),E(Ww.$$.fragment,c),E(XR.$$.fragment,c),E(zR.$$.fragment,c),E(WR.$$.fragment,c),E(Hw.$$.fragment,c),E(UR.$$.fragment,c),E(_A.$$.fragment,c),E(HR.$$.fragment,c),E(JR.$$.fragment,c),E(ZR.$$.fragment,c),E(vA.$$.fragment,c),E(KR.$$.fragment,c),E($A.$$.fragment,c),E(eP.$$.fragment,c),E(oP.$$.fragment,c),E(tP.$$.fragment,c),E(SA.$$.fragment,c),E(aP.$$.fragment,c),E(l6.$$.fragment,c),E(nP.$$.fragment,c),E(sP.$$.fragment,c),E(iP.$$.fragment,c),E(d6.$$.fragment,c),E(dP.$$.fragment,c),E(L6.$$.fragment,c),E(mP.$$.fragment,c),E(cP.$$.fragment,c),E(gP.$$.fragment,c),E(x6.$$.fragment,c),E(hP.$$.fragment,c),E(S6.$$.fragment,c),E(pP.$$.fragment,c),E(_P.$$.fragment,c),E(vP.$$.fragment,c),E(P6.$$.fragment,c),E(FP.$$.fragment,c),E(I6.$$.fragment,c),E(TP.$$.fragment,c),E(MP.$$.fragment,c),E(CP.$$.fragment,c),E(q6.$$.fragment,c),E(wP.$$.fragment,c),E(D6.$$.fragment,c),E(AP.$$.fragment,c),E(LP.$$.fragment,c),E(xP.$$.fragment,c),E(O6.$$.fragment,c),E($P.$$.fragment,c),E(c7.$$.fragment,c),E(kP.$$.fragment,c),E(SP.$$.fragment,c),E(PP.$$.fragment,c),E(g7.$$.fragment,c),E(BP.$$.fragment,c),E(B7.$$.fragment,c),E(IP.$$.fragment,c),E(NP.$$.fragment,c),E(jP.$$.fragment,c),E(N7.$$.fragment,c),E(DP.$$.fragment,c),E(j7.$$.fragment,c),E(GP.$$.fragment,c),E(OP.$$.fragment,c),E(XP.$$.fragment,c),E(G7.$$.fragment,c),E(zP.$$.fragment,c),E(X7.$$.fragment,c),E(WP.$$.fragment,c),E(UP.$$.fragment,c),E(JP.$$.fragment,c),E(Q7.$$.fragment,c),E(YP.$$.fragment,c),E(F8.$$.fragment,c),E(ZP.$$.fragment,c),E(KP.$$.fragment,c),E(oB.$$.fragment,c),E(M8.$$.fragment,c),E(rB.$$.fragment,c),E(R8.$$.fragment,c),E(tB.$$.fragment,c),E(aB.$$.fragment,c),E(sB.$$.fragment,c),E(B8.$$.fragment,c),E(lB.$$.fragment,c),E(H8.$$.fragment,c),E(iB.$$.fragment,c),E(dB.$$.fragment,c),E(cB.$$.fragment,c),E(Y8.$$.fragment,c),E(fB.$$.fragment,c),E(iL.$$.fragment,c),E(gB.$$.fragment,c),E(hB.$$.fragment,c),E(pB.$$.fragment,c),E(mL.$$.fragment,c),E(_B.$$.fragment,c),E(TL.$$.fragment,c),E(bB.$$.fragment,c),E(vB.$$.fragment,c),E(TB.$$.fragment,c),E(EL.$$.fragment,c),E(MB.$$.fragment,c),E(PL.$$.fragment,c),E(EB.$$.fragment,c),E(CB.$$.fragment,c),E(AB.$$.fragment,c),E(IL.$$.fragment,c),E(LB.$$.fragment,c),E(WL.$$.fragment,c),E(yB.$$.fragment,c),E(xB.$$.fragment,c),E(kB.$$.fragment,c),E(HL.$$.fragment,c),E(SB.$$.fragment,c),E(ay.$$.fragment,c),E(RB.$$.fragment,c),E(PB.$$.fragment,c),E(IB.$$.fragment,c),E(sy.$$.fragment,c),E(NB.$$.fragment,c),E(uy.$$.fragment,c),E(qB.$$.fragment,c),E(jB.$$.fragment,c),E(GB.$$.fragment,c),E(_y.$$.fragment,c),E(OB.$$.fragment,c),E(vy.$$.fragment,c),E(VB.$$.fragment,c),E(XB.$$.fragment,c),E(QB.$$.fragment,c),E(Ty.$$.fragment,c),E(WB.$$.fragment,c),E(Cy.$$.fragment,c),E(HB.$$.fragment,c),E(JB.$$.fragment,c),E(ZB.$$.fragment,c),E(Ay.$$.fragment,c),E(KB.$$.fragment,c),E(yy.$$.fragment,c),dso=!0)},o(c){C(d.$$.fragment,c),C(on.$$.fragment,c),C(h$.$$.fragment,c),C(u$.$$.fragment,c),C(Yf.$$.fragment,c),C(p$.$$.fragment,c),C(_$.$$.fragment,c),C(F$.$$.fragment,c),C(Lu.$$.fragment,c),C(T$.$$.fragment,c),C(M$.$$.fragment,c),C(E$.$$.fragment,c),C(A$.$$.fragment,c),C(fp.$$.fragment,c),C(L$.$$.fragment,c),C(y$.$$.fragment,c),C(x$.$$.fragment,c),C(S$.$$.fragment,c),C(s_.$$.fragment,c),C(l_.$$.fragment,c),C(R$.$$.fragment,c),C(P$.$$.fragment,c),C(B$.$$.fragment,c),C(q$.$$.fragment,c),C(R_.$$.fragment,c),C(P_.$$.fragment,c),C(j$.$$.fragment,c),C(D$.$$.fragment,c),C(G$.$$.fragment,c),C(V$.$$.fragment,c),C(N_.$$.fragment,c),C(X$.$$.fragment,c),C(sb.$$.fragment,c),C(z$.$$.fragment,c),C(Q$.$$.fragment,c),C(U$.$$.fragment,c),C(ib.$$.fragment,c),C(H$.$$.fragment,c),C(av.$$.fragment,c),C(J$.$$.fragment,c),C(Y$.$$.fragment,c),C(K$.$$.fragment,c),C(sv.$$.fragment,c),C(ek.$$.fragment,c),C(Jv.$$.fragment,c),C(ok.$$.fragment,c),C(rk.$$.fragment,c),C(ak.$$.fragment,c),C(Zv.$$.fragment,c),C(nk.$$.fragment,c),C(rF.$$.fragment,c),C(lk.$$.fragment,c),C(ik.$$.fragment,c),C(mk.$$.fragment,c),C(aF.$$.fragment,c),C(ck.$$.fragment,c),C(zF.$$.fragment,c),C(fk.$$.fragment,c),C(gk.$$.fragment,c),C(uk.$$.fragment,c),C(WF.$$.fragment,c),C(pk.$$.fragment,c),C(uT.$$.fragment,c),C(_k.$$.fragment,c),C(bk.$$.fragment,c),C(Fk.$$.fragment,c),C(_T.$$.fragment,c),C(Tk.$$.fragment,c),C(TM.$$.fragment,c),C(Mk.$$.fragment,c),C(Ek.$$.fragment,c),C(wk.$$.fragment,c),C(EM.$$.fragment,c),C(Ak.$$.fragment,c),C(tE.$$.fragment,c),C(Lk.$$.fragment,c),C(yk.$$.fragment,c),C($k.$$.fragment,c),C(nE.$$.fragment,c),C(kk.$$.fragment,c),C(hE.$$.fragment,c),C(Sk.$$.fragment,c),C(Rk.$$.fragment,c),C(Bk.$$.fragment,c),C(pE.$$.fragment,c),C(Ik.$$.fragment,c),C(n4.$$.fragment,c),C(Nk.$$.fragment,c),C(qk.$$.fragment,c),C(Dk.$$.fragment,c),C(l4.$$.fragment,c),C(Gk.$$.fragment,c),C(tC.$$.fragment,c),C(Ok.$$.fragment,c),C(Vk.$$.fragment,c),C(zk.$$.fragment,c),C(nC.$$.fragment,c),C(Qk.$$.fragment,c),C(iC.$$.fragment,c),C(Wk.$$.fragment,c),C(Uk.$$.fragment,c),C(Jk.$$.fragment,c),C(mC.$$.fragment,c),C(Yk.$$.fragment,c),C(uC.$$.fragment,c),C(Zk.$$.fragment,c),C(Kk.$$.fragment,c),C(oS.$$.fragment,c),C(_C.$$.fragment,c),C(rS.$$.fragment,c),C(PC.$$.fragment,c),C(tS.$$.fragment,c),C(aS.$$.fragment,c),C(sS.$$.fragment,c),C(IC.$$.fragment,c),C(lS.$$.fragment,c),C(jC.$$.fragment,c),C(iS.$$.fragment,c),C(dS.$$.fragment,c),C(cS.$$.fragment,c),C(GC.$$.fragment,c),C(fS.$$.fragment,c),C(XC.$$.fragment,c),C(gS.$$.fragment,c),C(hS.$$.fragment,c),C(pS.$$.fragment,c),C(QC.$$.fragment,c),C(_S.$$.fragment,c),C(HC.$$.fragment,c),C(bS.$$.fragment,c),C(vS.$$.fragment,c),C(TS.$$.fragment,c),C(YC.$$.fragment,c),C(MS.$$.fragment,c),C(i3.$$.fragment,c),C(ES.$$.fragment,c),C(CS.$$.fragment,c),C(AS.$$.fragment,c),C(m3.$$.fragment,c),C(LS.$$.fragment,c),C(_3.$$.fragment,c),C(yS.$$.fragment,c),C(xS.$$.fragment,c),C(kS.$$.fragment,c),C(v3.$$.fragment,c),C(SS.$$.fragment,c),C(k3.$$.fragment,c),C(RS.$$.fragment,c),C(PS.$$.fragment,c),C(IS.$$.fragment,c),C(R3.$$.fragment,c),C(NS.$$.fragment,c),C(q3.$$.fragment,c),C(qS.$$.fragment,c),C(jS.$$.fragment,c),C(GS.$$.fragment,c),C(D3.$$.fragment,c),C(OS.$$.fragment,c),C(W3.$$.fragment,c),C(VS.$$.fragment,c),C(XS.$$.fragment,c),C(QS.$$.fragment,c),C(H3.$$.fragment,c),C(WS.$$.fragment,c),C(o5.$$.fragment,c),C(US.$$.fragment,c),C(HS.$$.fragment,c),C(YS.$$.fragment,c),C(t5.$$.fragment,c),C(ZS.$$.fragment,c),C(m5.$$.fragment,c),C(KS.$$.fragment,c),C(eR.$$.fragment,c),C(rR.$$.fragment,c),C(f5.$$.fragment,c),C(tR.$$.fragment,c),C(u5.$$.fragment,c),C(aR.$$.fragment,c),C(nR.$$.fragment,c),C(lR.$$.fragment,c),C(_5.$$.fragment,c),C(iR.$$.fragment,c),C(C5.$$.fragment,c),C(dR.$$.fragment,c),C(mR.$$.fragment,c),C(fR.$$.fragment,c),C(A5.$$.fragment,c),C(gR.$$.fragment,c),C(x5.$$.fragment,c),C(hR.$$.fragment,c),C(uR.$$.fragment,c),C(_R.$$.fragment,c),C(k5.$$.fragment,c),C(bR.$$.fragment,c),C(P5.$$.fragment,c),C(vR.$$.fragment,c),C(FR.$$.fragment,c),C(MR.$$.fragment,c),C(I5.$$.fragment,c),C(ER.$$.fragment,c),C(D0.$$.fragment,c),C(CR.$$.fragment,c),C(wR.$$.fragment,c),C(LR.$$.fragment,c),C(O0.$$.fragment,c),C(yR.$$.fragment,c),C(fw.$$.fragment,c),C(xR.$$.fragment,c),C($R.$$.fragment,c),C(SR.$$.fragment,c),C(hw.$$.fragment,c),C(RR.$$.fragment,c),C(xw.$$.fragment,c),C(PR.$$.fragment,c),C(BR.$$.fragment,c),C(NR.$$.fragment,c),C(kw.$$.fragment,c),C(qR.$$.fragment,c),C(Gw.$$.fragment,c),C(jR.$$.fragment,c),C(DR.$$.fragment,c),C(OR.$$.fragment,c),C(Vw.$$.fragment,c),C(VR.$$.fragment,c),C(Ww.$$.fragment,c),C(XR.$$.fragment,c),C(zR.$$.fragment,c),C(WR.$$.fragment,c),C(Hw.$$.fragment,c),C(UR.$$.fragment,c),C(_A.$$.fragment,c),C(HR.$$.fragment,c),C(JR.$$.fragment,c),C(ZR.$$.fragment,c),C(vA.$$.fragment,c),C(KR.$$.fragment,c),C($A.$$.fragment,c),C(eP.$$.fragment,c),C(oP.$$.fragment,c),C(tP.$$.fragment,c),C(SA.$$.fragment,c),C(aP.$$.fragment,c),C(l6.$$.fragment,c),C(nP.$$.fragment,c),C(sP.$$.fragment,c),C(iP.$$.fragment,c),C(d6.$$.fragment,c),C(dP.$$.fragment,c),C(L6.$$.fragment,c),C(mP.$$.fragment,c),C(cP.$$.fragment,c),C(gP.$$.fragment,c),C(x6.$$.fragment,c),C(hP.$$.fragment,c),C(S6.$$.fragment,c),C(pP.$$.fragment,c),C(_P.$$.fragment,c),C(vP.$$.fragment,c),C(P6.$$.fragment,c),C(FP.$$.fragment,c),C(I6.$$.fragment,c),C(TP.$$.fragment,c),C(MP.$$.fragment,c),C(CP.$$.fragment,c),C(q6.$$.fragment,c),C(wP.$$.fragment,c),C(D6.$$.fragment,c),C(AP.$$.fragment,c),C(LP.$$.fragment,c),C(xP.$$.fragment,c),C(O6.$$.fragment,c),C($P.$$.fragment,c),C(c7.$$.fragment,c),C(kP.$$.fragment,c),C(SP.$$.fragment,c),C(PP.$$.fragment,c),C(g7.$$.fragment,c),C(BP.$$.fragment,c),C(B7.$$.fragment,c),C(IP.$$.fragment,c),C(NP.$$.fragment,c),C(jP.$$.fragment,c),C(N7.$$.fragment,c),C(DP.$$.fragment,c),C(j7.$$.fragment,c),C(GP.$$.fragment,c),C(OP.$$.fragment,c),C(XP.$$.fragment,c),C(G7.$$.fragment,c),C(zP.$$.fragment,c),C(X7.$$.fragment,c),C(WP.$$.fragment,c),C(UP.$$.fragment,c),C(JP.$$.fragment,c),C(Q7.$$.fragment,c),C(YP.$$.fragment,c),C(F8.$$.fragment,c),C(ZP.$$.fragment,c),C(KP.$$.fragment,c),C(oB.$$.fragment,c),C(M8.$$.fragment,c),C(rB.$$.fragment,c),C(R8.$$.fragment,c),C(tB.$$.fragment,c),C(aB.$$.fragment,c),C(sB.$$.fragment,c),C(B8.$$.fragment,c),C(lB.$$.fragment,c),C(H8.$$.fragment,c),C(iB.$$.fragment,c),C(dB.$$.fragment,c),C(cB.$$.fragment,c),C(Y8.$$.fragment,c),C(fB.$$.fragment,c),C(iL.$$.fragment,c),C(gB.$$.fragment,c),C(hB.$$.fragment,c),C(pB.$$.fragment,c),C(mL.$$.fragment,c),C(_B.$$.fragment,c),C(TL.$$.fragment,c),C(bB.$$.fragment,c),C(vB.$$.fragment,c),C(TB.$$.fragment,c),C(EL.$$.fragment,c),C(MB.$$.fragment,c),C(PL.$$.fragment,c),C(EB.$$.fragment,c),C(CB.$$.fragment,c),C(AB.$$.fragment,c),C(IL.$$.fragment,c),C(LB.$$.fragment,c),C(WL.$$.fragment,c),C(yB.$$.fragment,c),C(xB.$$.fragment,c),C(kB.$$.fragment,c),C(HL.$$.fragment,c),C(SB.$$.fragment,c),C(ay.$$.fragment,c),C(RB.$$.fragment,c),C(PB.$$.fragment,c),C(IB.$$.fragment,c),C(sy.$$.fragment,c),C(NB.$$.fragment,c),C(uy.$$.fragment,c),C(qB.$$.fragment,c),C(jB.$$.fragment,c),C(GB.$$.fragment,c),C(_y.$$.fragment,c),C(OB.$$.fragment,c),C(vy.$$.fragment,c),C(VB.$$.fragment,c),C(XB.$$.fragment,c),C(QB.$$.fragment,c),C(Ty.$$.fragment,c),C(WB.$$.fragment,c),C(Cy.$$.fragment,c),C(HB.$$.fragment,c),C(JB.$$.fragment,c),C(ZB.$$.fragment,c),C(Ay.$$.fragment,c),C(KB.$$.fragment,c),C(yy.$$.fragment,c),dso=!1},d(c){t(g),c&&t(v),c&&t(u),w(d),c&&t(Qf),c&&t(Tt),c&&t(Xe),c&&t(He),c&&t(Uf),w(on,c),c&&t(Je),c&&t(Ae),c&&t(ko),c&&t(rn),c&&t(Qto),c&&t(Ad),w(h$),c&&t(Wto),c&&t(hs),c&&t(Uto),w(u$,c),c&&t(Hto),c&&t(RN),c&&t(Jto),w(Yf,c),c&&t(Yto),c&&t(Ld),w(p$),c&&t(Zto),c&&t(So),w(_$),w(F$),w(Lu),w(T$),c&&t(Kto),c&&t(xd),w(M$),c&&t(eao),c&&t(Ro),w(E$),w(A$),w(fp),w(L$),c&&t(oao),c&&t($d),w(y$),c&&t(rao),c&&t(Po),w(x$),w(S$),w(s_),w(l_),w(R$),c&&t(tao),c&&t(kd),w(P$),c&&t(aao),c&&t(Bo),w(B$),w(q$),w(R_),w(P_),w(j$),c&&t(nao),c&&t(Rd),w(D$),c&&t(sao),c&&t(Io),w(G$),w(V$),w(N_),w(X$),w(sb),c&&t(lao),c&&t(Id),w(z$),c&&t(iao),c&&t(No),w(Q$),w(U$),w(ib),w(H$),w(av),c&&t(dao),c&&t(jd),w(J$),c&&t(mao),c&&t(qo),w(Y$),w(K$),w(sv),w(ek),w(Jv),c&&t(cao),c&&t(Od),w(ok),c&&t(fao),c&&t(jo),w(rk),w(ak),w(Zv),w(nk),w(rF),c&&t(gao),c&&t(zd),w(lk),c&&t(hao),c&&t(Do),w(ik),w(mk),w(aF),w(ck),w(zF),c&&t(uao),c&&t(Ud),w(fk),c&&t(pao),c&&t(Go),w(gk),w(uk),w(WF),w(pk),w(uT),c&&t(_ao),c&&t(Yd),w(_k),c&&t(bao),c&&t(Oo),w(bk),w(Fk),w(_T),w(Tk),w(TM),c&&t(vao),c&&t(em),w(Mk),c&&t(Fao),c&&t(Vo),w(Ek),w(wk),w(EM),w(Ak),w(tE),c&&t(Tao),c&&t(tm),w(Lk),c&&t(Mao),c&&t(Xo),w(yk),w($k),w(nE),w(kk),w(hE),c&&t(Eao),c&&t(sm),w(Sk),c&&t(Cao),c&&t(zo),w(Rk),w(Bk),w(pE),w(Ik),w(n4),c&&t(wao),c&&t(dm),w(Nk),c&&t(Aao),c&&t(Qo),w(qk),w(Dk),w(l4),w(Gk),w(tC),c&&t(Lao),c&&t(fm),w(Ok),c&&t(yao),c&&t(Wo),w(Vk),w(zk),w(nC),w(Qk),w(iC),c&&t(xao),c&&t(um),w(Wk),c&&t($ao),c&&t(Uo),w(Uk),w(Jk),w(mC),w(Yk),w(uC),c&&t(kao),c&&t(vm),w(Zk),c&&t(Sao),c&&t(Ho),w(Kk),w(oS),w(_C),w(rS),w(PC),c&&t(Rao),c&&t(Mm),w(tS),c&&t(Pao),c&&t(Jo),w(aS),w(sS),w(IC),w(lS),w(jC),c&&t(Bao),c&&t(wm),w(iS),c&&t(Iao),c&&t(Yo),w(dS),w(cS),w(GC),w(fS),w(XC),c&&t(Nao),c&&t(ym),w(gS),c&&t(qao),c&&t(Zo),w(hS),w(pS),w(QC),w(_S),w(HC),c&&t(jao),c&&t(km),w(bS),c&&t(Dao),c&&t(Ko),w(vS),w(TS),w(YC),w(MS),w(i3),c&&t(Gao),c&&t(Pm),w(ES),c&&t(Oao),c&&t(er),w(CS),w(AS),w(m3),w(LS),w(_3),c&&t(Vao),c&&t(Nm),w(yS),c&&t(Xao),c&&t(or),w(xS),w(kS),w(v3),w(SS),w(k3),c&&t(zao),c&&t(Dm),w(RS),c&&t(Qao),c&&t(rr),w(PS),w(IS),w(R3),w(NS),w(q3),c&&t(Wao),c&&t(Xm),w(qS),c&&t(Uao),c&&t(tr),w(jS),w(GS),w(D3),w(OS),w(W3),c&&t(Hao),c&&t(Wm),w(VS),c&&t(Jao),c&&t(ar),w(XS),w(QS),w(H3),w(WS),w(o5),c&&t(Yao),c&&t(Jm),w(US),c&&t(Zao),c&&t(nr),w(HS),w(YS),w(t5),w(ZS),w(m5),c&&t(Kao),c&&t(Km),w(KS),c&&t(eno),c&&t(sr),w(eR),w(rR),w(f5),w(tR),w(u5),c&&t(ono),c&&t(rc),w(aR),c&&t(rno),c&&t(lr),w(nR),w(lR),w(_5),w(iR),w(C5),c&&t(tno),c&&t(nc),w(dR),c&&t(ano),c&&t(ir),w(mR),w(fR),w(A5),w(gR),w(x5),c&&t(nno),c&&t(ic),w(hR),c&&t(sno),c&&t(dr),w(uR),w(_R),w(k5),w(bR),w(P5),c&&t(lno),c&&t(cc),w(vR),c&&t(ino),c&&t(mr),w(FR),w(MR),w(I5),w(ER),w(D0),c&&t(dno),c&&t(hc),w(CR),c&&t(mno),c&&t(cr),w(wR),w(LR),w(O0),w(yR),w(fw),c&&t(cno),c&&t(_c),w(xR),c&&t(fno),c&&t(fr),w($R),w(SR),w(hw),w(RR),w(xw),c&&t(gno),c&&t(Fc),w(PR),c&&t(hno),c&&t(gr),w(BR),w(NR),w(kw),w(qR),w(Gw),c&&t(uno),c&&t(Ec),w(jR),c&&t(pno),c&&t(hr),w(DR),w(OR),w(Vw),w(VR),w(Ww),c&&t(_no),c&&t(Lc),w(XR),c&&t(bno),c&&t(ur),w(zR),w(WR),w(Hw),w(UR),w(_A),c&&t(vno),c&&t($c),w(HR),c&&t(Fno),c&&t(pr),w(JR),w(ZR),w(vA),w(KR),w($A),c&&t(Tno),c&&t(Rc),w(eP),c&&t(Mno),c&&t(_r),w(oP),w(tP),w(SA),w(aP),w(l6),c&&t(Eno),c&&t(Ic),w(nP),c&&t(Cno),c&&t(br),w(sP),w(iP),w(d6),w(dP),w(L6),c&&t(wno),c&&t(jc),w(mP),c&&t(Ano),c&&t(vr),w(cP),w(gP),w(x6),w(hP),w(S6),c&&t(Lno),c&&t(Oc),w(pP),c&&t(yno),c&&t(Fr),w(_P),w(vP),w(P6),w(FP),w(I6),c&&t(xno),c&&t(zc),w(TP),c&&t($no),c&&t(Tr),w(MP),w(CP),w(q6),w(wP),w(D6),c&&t(kno),c&&t(Uc),w(AP),c&&t(Sno),c&&t(Mr),w(LP),w(xP),w(O6),w($P),w(c7),c&&t(Rno),c&&t(Yc),w(kP),c&&t(Pno),c&&t(Er),w(SP),w(PP),w(g7),w(BP),w(B7),c&&t(Bno),c&&t(ef),w(IP),c&&t(Ino),c&&t(Cr),w(NP),w(jP),w(N7),w(DP),w(j7),c&&t(Nno),c&&t(tf),w(GP),c&&t(qno),c&&t(wr),w(OP),w(XP),w(G7),w(zP),w(X7),c&&t(jno),c&&t(sf),w(WP),c&&t(Dno),c&&t(Ar),w(UP),w(JP),w(Q7),w(YP),w(F8),c&&t(Gno),c&&t(mf),w(ZP),c&&t(Ono),c&&t(Lr),w(KP),w(oB),w(M8),w(rB),w(R8),c&&t(Vno),c&&t(gf),w(tB),c&&t(Xno),c&&t(yr),w(aB),w(sB),w(B8),w(lB),w(H8),c&&t(zno),c&&t(pf),w(iB),c&&t(Qno),c&&t(xr),w(dB),w(cB),w(Y8),w(fB),w(iL),c&&t(Wno),c&&t(vf),w(gB),c&&t(Uno),c&&t($r),w(hB),w(pB),w(mL),w(_B),w(TL),c&&t(Hno),c&&t(Mf),w(bB),c&&t(Jno),c&&t(kr),w(vB),w(TB),w(EL),w(MB),w(PL),c&&t(Yno),c&&t(wf),w(EB),c&&t(Zno),c&&t(Sr),w(CB),w(AB),w(IL),w(LB),w(WL),c&&t(Kno),c&&t(yf),w(yB),c&&t(eso),c&&t(Rr),w(xB),w(kB),w(HL),w(SB),w(ay),c&&t(oso),c&&t(kf),w(RB),c&&t(rso),c&&t(Pr),w(PB),w(IB),w(sy),w(NB),w(uy),c&&t(tso),c&&t(Pf),w(qB),c&&t(aso),c&&t(Br),w(jB),w(GB),w(_y),w(OB),w(vy),c&&t(nso),c&&t(Nf),w(VB),c&&t(sso),c&&t(Ir),w(XB),w(QB),w(Ty),w(WB),w(Cy),c&&t(lso),c&&t(Df),w(HB),c&&t(iso),c&&t(Nr),w(JB),w(ZB),w(Ay),w(KB),w(yy)}}}const zwa={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForDepthEstimation",title:"AutoModelForDepthEstimation"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForDocumentQuestionAnswering",title:"AutoModelForDocumentQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.AutoModelForZeroShotObjectDetection",title:"AutoModelForZeroShotObjectDetection"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForSemanticSegmentation",title:"TFAutoModelForSemanticSegmentation"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForDocumentQuestionAnswering",title:"TFAutoModelForDocumentQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function Qwa($){return S5a(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Kwa extends y5a{constructor(g){super();x5a(this,g,Qwa,Xwa,$5a,{})}}export{Kwa as default,zwa as metadata};
