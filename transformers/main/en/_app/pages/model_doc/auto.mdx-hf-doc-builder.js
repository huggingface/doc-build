import{S as S$a,i as R$a,s as P$a,e as a,k as l,w as F,t as o,M as B$a,c as n,d as t,m as i,a as s,x as T,h as r,b as d,G as e,g as b,y as M,q as E,o as C,B as w,v as I$a,L as q}from"../../chunks/vendor-hf-doc-builder.js";import{T as Vfo}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as B}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as re}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as N}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function N$a($){let g,v,u,f,p,m,h,He,Ad,eg,wt,Ld,yd,_k,og,Qe,Ze,xd,_s,bk,bs,vs,vk,$d,Fs,Fk,kd,rg,ln;return{c(){g=a("p"),v=o("If your "),u=a("code"),f=o("NewModelConfig"),p=o(" is a subclass of "),m=a("code"),h=o("~transformer.PretrainedConfig"),He=o(`, make sure its
`),Ad=a("code"),eg=o("model_type"),wt=o(" attribute is set to the same key you use when registering the config (here "),Ld=a("code"),yd=o('"new-model"'),_k=o(")."),og=l(),Qe=a("p"),Ze=o("Likewise, if your "),xd=a("code"),_s=o("NewModel"),bk=o(" is a subclass of "),bs=a("a"),vs=o("PreTrainedModel"),vk=o(`, make sure its
`),$d=a("code"),Fs=o("config_class"),Fk=o(` attribute is set to the same class you use when registering the model (here
`),kd=a("code"),rg=o("NewModelConfig"),ln=o(")."),this.h()},l(Ke){g=n(Ke,"P",{});var ye=s(g);v=r(ye,"If your "),u=n(ye,"CODE",{});var Gq=s(u);f=r(Gq,"NewModelConfig"),Gq.forEach(t),p=r(ye," is a subclass of "),m=n(ye,"CODE",{});var Sd=s(m);h=r(Sd,"~transformer.PretrainedConfig"),Sd.forEach(t),He=r(ye,`, make sure its
`),Ad=n(ye,"CODE",{});var Oq=s(Ad);eg=r(Oq,"model_type"),Oq.forEach(t),wt=r(ye," attribute is set to the same key you use when registering the config (here "),Ld=n(ye,"CODE",{});var Vq=s(Ld);yd=r(Vq,'"new-model"'),Vq.forEach(t),_k=r(ye,")."),ye.forEach(t),og=i(Ke),Qe=n(Ke,"P",{});var Po=s(Qe);Ze=r(Po,"Likewise, if your "),xd=n(Po,"CODE",{});var dn=s(xd);_s=r(dn,"NewModel"),dn.forEach(t),bk=r(Po," is a subclass of "),bs=n(Po,"A",{href:!0});var Xq=s(bs);vs=r(Xq,"PreTrainedModel"),Xq.forEach(t),vk=r(Po,`, make sure its
`),$d=n(Po,"CODE",{});var tg=s($d);Fs=r(tg,"config_class"),tg.forEach(t),Fk=r(Po,` attribute is set to the same class you use when registering the model (here
`),kd=n(Po,"CODE",{});var zq=s(kd);rg=r(zq,"NewModelConfig"),zq.forEach(t),ln=r(Po,")."),Po.forEach(t),this.h()},h(){d(bs,"href","/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel")},m(Ke,ye){b(Ke,g,ye),e(g,v),e(g,u),e(u,f),e(g,p),e(g,m),e(m,h),e(g,He),e(g,Ad),e(Ad,eg),e(g,wt),e(g,Ld),e(Ld,yd),e(g,_k),b(Ke,og,ye),b(Ke,Qe,ye),e(Qe,Ze),e(Qe,xd),e(xd,_s),e(Qe,bk),e(Qe,bs),e(bs,vs),e(Qe,vk),e(Qe,$d),e($d,Fs),e(Qe,Fk),e(Qe,kd),e(kd,rg),e(Qe,ln)},d(Ke){Ke&&t(g),Ke&&t(og),Ke&&t(Qe)}}}function q$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function j$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function D$a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var He=s(u);f=r(He,"use_auth_token=True"),He.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(m,h){b(m,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(m){m&&t(g)}}}function G$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function O$a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var He=s(u);f=r(He,"use_auth_token=True"),He.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(m,h){b(m,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(m){m&&t(g)}}}function V$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoImageProcessor

# Download image processor from huggingface.co and cache.
image_processor = AutoImageProcessor.from_pretrained("google/vit-base-patch16-224-in21k")

# If image processor files are in a directory (e.g. image processor was saved using *save_pretrained('./test/saved_model/')*)
image_processor = AutoImageProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoImageProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download image processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>image_processor = AutoImageProcessor.from_pretrained(<span class="hljs-string">&quot;google/vit-base-patch16-224-in21k&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If image processor files are in a directory (e.g. image processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>image_processor = AutoImageProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function X$a($){let g,v,u,f,p;return{c(){g=a("p"),v=o("Passing "),u=a("code"),f=o("use_auth_token=True"),p=o(" is required when you want to use a private model.")},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Passing "),u=n(h,"CODE",{});var He=s(u);f=r(He,"use_auth_token=True"),He.forEach(t),p=r(h," is required when you want to use a private model."),h.forEach(t)},m(m,h){b(m,g,h),e(g,v),e(g,u),e(u,f),e(g,p)},d(m){m&&t(g)}}}function z$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Q$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function W$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function U$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function H$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function J$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Y$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Z$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForDepthEstimation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function K$a($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDepthEstimation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForDepthEstimation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForDepthEstimation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDepthEstimation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDepthEstimation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function eka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function oka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function rka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function tka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function aka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function nka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function ska($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function lka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function ika($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function dka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function mka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function cka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function fka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function gka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function hka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function uka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function pka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = AutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function _ka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = AutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/layoutlm_tf_model_config.json")
model = AutoModelForDocumentQuestionAnswering.from_pretrained(
    "./tf_model/layoutlm_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/layoutlm_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/layoutlm_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function bka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function vka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Fka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Tka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Mka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Eka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Cka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function wka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Aka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Lka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function yka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function xka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function $ka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function kka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Ska($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Rka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Pka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Bka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Ika($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Nka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function qka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function jka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Dka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Gka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Oka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Vka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Xka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function zka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Qka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForZeroShotObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Wka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, AutoModelForZeroShotObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForZeroShotObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForZeroShotObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForZeroShotObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForZeroShotObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Uka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Hka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Jka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Yka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Zka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function Kka($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function eSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function oSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function rSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function tSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSemanticSegmentation.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function aSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function nSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function sSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function lSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function iSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function dSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function mSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function cSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function fSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function gSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function hSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function uSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function pSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")
model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function _Sa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForDocumentQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3")

# Update configuration during loading
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained("impira/layoutlm-document-qa", revision="52e01b3", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/layoutlm_pt_model_config.json")
model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
    "./pt_model/layoutlm_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForDocumentQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;impira/layoutlm-document-qa&quot;</span>, revision=<span class="hljs-string">&quot;52e01b3&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/layoutlm_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForDocumentQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/layoutlm_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function bSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function vSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function FSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function TSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function MSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function ESa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function CSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function wSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function ASa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function LSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function ySa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function xSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function $Sa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function kSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function SSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function RSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function PSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function BSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function ISa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function NSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function qSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function jSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function DSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function GSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function OSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function VSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function XSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function zSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function QSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function WSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function USa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function HSa($){let g,v,u,f,p;return f=new B({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),u=l(),F(f.$$.fragment)},l(m){g=n(m,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),u=i(m),T(f.$$.fragment,m)},m(m,h){b(m,g,h),e(g,v),b(m,u,h),M(f,m,h),p=!0},p:q,i(m){p||(E(f.$$.fragment,m),p=!0)},o(m){C(f.$$.fragment,m),p=!1},d(m){m&&t(g),m&&t(u),w(f,m)}}}function JSa($){let g,v,u,f,p,m,h,He,Ad,eg,wt,Ld,yd,_k,og,Qe,Ze,xd,_s,bk,bs,vs,vk,$d,Fs,Fk,kd,rg,ln,Ke,ye,Gq,Sd,Oq,Vq,Po,dn,Xq,tg,zq,Xfo,Zlo,Rd,ag,khe,Tk,zfo,She,Qfo,Klo,Ts,Wfo,Rhe,Ufo,Hfo,Phe,Jfo,Yfo,eio,Mk,oio,Qq,Zfo,rio,ng,tio,Pd,sg,Bhe,Ek,Kfo,Ihe,ego,aio,Bo,Ck,ogo,wk,rgo,Wq,tgo,ago,ngo,Ak,sgo,Nhe,lgo,igo,dgo,Vr,Lk,mgo,qhe,cgo,fgo,Bd,ggo,jhe,hgo,ugo,Dhe,pgo,_go,bgo,A,lg,Ghe,vgo,Fgo,Uq,Tgo,Mgo,Ego,ig,Ohe,Cgo,wgo,Hq,Ago,Lgo,ygo,dg,Vhe,xgo,$go,Jq,kgo,Sgo,Rgo,mg,Xhe,Pgo,Bgo,Yq,Igo,Ngo,qgo,cg,zhe,jgo,Dgo,Zq,Ggo,Ogo,Vgo,fg,Qhe,Xgo,zgo,Kq,Qgo,Wgo,Ugo,gg,Whe,Hgo,Jgo,ej,Ygo,Zgo,Kgo,hg,Uhe,eho,oho,oj,rho,tho,aho,ug,Hhe,nho,sho,rj,lho,iho,dho,pg,Jhe,mho,cho,tj,fho,gho,hho,_g,Yhe,uho,pho,aj,_ho,bho,vho,bg,Zhe,Fho,Tho,nj,Mho,Eho,Cho,vg,Khe,who,Aho,sj,Lho,yho,xho,Fg,eue,$ho,kho,lj,Sho,Rho,Pho,Tg,oue,Bho,Iho,ij,Nho,qho,jho,Mg,rue,Dho,Gho,dj,Oho,Vho,Xho,Eg,tue,zho,Qho,mj,Who,Uho,Hho,Cg,aue,Jho,Yho,cj,Zho,Kho,euo,wg,nue,ouo,ruo,fj,tuo,auo,nuo,Ag,sue,suo,luo,gj,iuo,duo,muo,Lg,lue,cuo,fuo,hj,guo,huo,uuo,yg,iue,puo,_uo,uj,buo,vuo,Fuo,xg,due,Tuo,Muo,pj,Euo,Cuo,wuo,$g,mue,Auo,Luo,_j,yuo,xuo,$uo,kg,cue,kuo,Suo,bj,Ruo,Puo,Buo,Sg,fue,Iuo,Nuo,vj,quo,juo,Duo,Rg,gue,Guo,Ouo,Fj,Vuo,Xuo,zuo,Pg,hue,Quo,Wuo,Tj,Uuo,Huo,Juo,Bg,uue,Yuo,Zuo,Mj,Kuo,epo,opo,Ig,pue,rpo,tpo,Ej,apo,npo,spo,Ng,_ue,lpo,ipo,Cj,dpo,mpo,cpo,qg,bue,fpo,gpo,wj,hpo,upo,ppo,jg,vue,_po,bpo,Aj,vpo,Fpo,Tpo,Dg,Fue,Mpo,Epo,Lj,Cpo,wpo,Apo,Gg,Tue,Lpo,ypo,yj,xpo,$po,kpo,Og,Mue,Spo,Rpo,xj,Ppo,Bpo,Ipo,Vg,Eue,Npo,qpo,$j,jpo,Dpo,Gpo,Xg,Cue,Opo,Vpo,kj,Xpo,zpo,Qpo,zg,wue,Wpo,Upo,Sj,Hpo,Jpo,Ypo,Qg,Aue,Zpo,Kpo,Rj,e_o,o_o,r_o,Wg,Lue,t_o,a_o,Pj,n_o,s_o,l_o,Ug,yue,i_o,d_o,Bj,m_o,c_o,f_o,Hg,xue,g_o,h_o,Ij,u_o,p_o,__o,Jg,$ue,b_o,v_o,Nj,F_o,T_o,M_o,Yg,kue,E_o,C_o,qj,w_o,A_o,L_o,Zg,Sue,y_o,x_o,jj,$_o,k_o,S_o,Kg,Rue,R_o,P_o,Dj,B_o,I_o,N_o,eh,Pue,q_o,j_o,Gj,D_o,G_o,O_o,oh,Bue,V_o,X_o,Oj,z_o,Q_o,W_o,rh,Iue,U_o,H_o,Vj,J_o,Y_o,Z_o,th,Nue,K_o,e1o,Xj,o1o,r1o,t1o,ah,que,a1o,n1o,zj,s1o,l1o,i1o,nh,jue,d1o,m1o,Qj,c1o,f1o,g1o,sh,Due,h1o,u1o,Wj,p1o,_1o,b1o,lh,Gue,v1o,F1o,Uj,T1o,M1o,E1o,ih,Oue,C1o,w1o,Hj,A1o,L1o,y1o,dh,Vue,x1o,$1o,Jj,k1o,S1o,R1o,mh,Xue,P1o,B1o,Yj,I1o,N1o,q1o,ch,zue,j1o,D1o,Zj,G1o,O1o,V1o,fh,Que,X1o,z1o,Kj,Q1o,W1o,U1o,gh,Wue,H1o,J1o,eD,Y1o,Z1o,K1o,hh,Uue,e2o,o2o,oD,r2o,t2o,a2o,uh,Hue,n2o,s2o,rD,l2o,i2o,d2o,ph,Jue,m2o,c2o,tD,f2o,g2o,h2o,_h,Yue,u2o,p2o,aD,_2o,b2o,v2o,bh,Zue,F2o,T2o,nD,M2o,E2o,C2o,vh,Kue,w2o,A2o,sD,L2o,y2o,x2o,Fh,epe,$2o,k2o,lD,S2o,R2o,P2o,Th,ope,B2o,I2o,iD,N2o,q2o,j2o,Mh,rpe,D2o,G2o,dD,O2o,V2o,X2o,Eh,tpe,z2o,Q2o,mD,W2o,U2o,H2o,Ch,ape,J2o,Y2o,cD,Z2o,K2o,ebo,wh,npe,obo,rbo,fD,tbo,abo,nbo,Ah,spe,sbo,lbo,gD,ibo,dbo,mbo,Lh,lpe,cbo,fbo,hD,gbo,hbo,ubo,yh,ipe,pbo,_bo,uD,bbo,vbo,Fbo,xh,dpe,Tbo,Mbo,pD,Ebo,Cbo,wbo,$h,mpe,Abo,Lbo,_D,ybo,xbo,$bo,kh,cpe,kbo,Sbo,bD,Rbo,Pbo,Bbo,Sh,fpe,Ibo,Nbo,vD,qbo,jbo,Dbo,Rh,gpe,Gbo,Obo,FD,Vbo,Xbo,zbo,Ph,hpe,Qbo,Wbo,TD,Ubo,Hbo,Jbo,Bh,upe,Ybo,Zbo,MD,Kbo,evo,ovo,Ih,ppe,rvo,tvo,ED,avo,nvo,svo,Nh,_pe,lvo,ivo,CD,dvo,mvo,cvo,qh,bpe,fvo,gvo,wD,hvo,uvo,pvo,jh,vpe,_vo,bvo,AD,vvo,Fvo,Tvo,Dh,Fpe,Mvo,Evo,LD,Cvo,wvo,Avo,Gh,Tpe,Lvo,yvo,yD,xvo,$vo,kvo,Oh,Mpe,Svo,Rvo,xD,Pvo,Bvo,Ivo,Vh,Epe,Nvo,qvo,$D,jvo,Dvo,Gvo,Xh,Cpe,Ovo,Vvo,kD,Xvo,zvo,Qvo,zh,wpe,Wvo,Uvo,SD,Hvo,Jvo,Yvo,Qh,Ape,Zvo,Kvo,RD,eFo,oFo,rFo,Wh,Lpe,tFo,aFo,PD,nFo,sFo,lFo,Uh,ype,iFo,dFo,BD,mFo,cFo,fFo,Hh,xpe,gFo,hFo,ID,uFo,pFo,_Fo,Jh,$pe,bFo,vFo,ND,FFo,TFo,MFo,Yh,kpe,EFo,CFo,qD,wFo,AFo,LFo,Zh,Spe,yFo,xFo,jD,$Fo,kFo,SFo,Kh,Rpe,RFo,PFo,DD,BFo,IFo,NFo,eu,Ppe,qFo,jFo,GD,DFo,GFo,OFo,ou,Bpe,VFo,XFo,OD,zFo,QFo,WFo,ru,Ipe,UFo,HFo,VD,JFo,YFo,ZFo,tu,Npe,KFo,eTo,XD,oTo,rTo,tTo,au,qpe,aTo,nTo,zD,sTo,lTo,iTo,nu,jpe,dTo,mTo,QD,cTo,fTo,gTo,su,Dpe,hTo,uTo,WD,pTo,_To,bTo,lu,Gpe,vTo,FTo,UD,TTo,MTo,ETo,iu,Ope,CTo,wTo,HD,ATo,LTo,yTo,du,Vpe,xTo,$To,JD,kTo,STo,RTo,mu,Xpe,PTo,BTo,YD,ITo,NTo,qTo,cu,zpe,jTo,DTo,ZD,GTo,OTo,VTo,fu,Qpe,XTo,zTo,KD,QTo,WTo,UTo,gu,Wpe,HTo,JTo,eG,YTo,ZTo,KTo,hu,Upe,eMo,oMo,oG,rMo,tMo,aMo,uu,Hpe,nMo,sMo,rG,lMo,iMo,dMo,pu,Jpe,mMo,cMo,tG,fMo,gMo,hMo,_u,Ype,uMo,pMo,aG,_Mo,bMo,vMo,bu,Zpe,FMo,TMo,nG,MMo,EMo,CMo,vu,Kpe,wMo,AMo,sG,LMo,yMo,xMo,Fu,e_e,$Mo,kMo,lG,SMo,RMo,PMo,Tu,o_e,BMo,IMo,iG,NMo,qMo,jMo,Mu,r_e,DMo,GMo,dG,OMo,VMo,XMo,Eu,t_e,zMo,QMo,mG,WMo,UMo,HMo,Cu,a_e,JMo,YMo,cG,ZMo,KMo,eEo,wu,n_e,oEo,rEo,fG,tEo,aEo,nEo,Au,s_e,sEo,lEo,gG,iEo,dEo,mEo,Lu,l_e,cEo,fEo,hG,gEo,hEo,uEo,yu,i_e,pEo,_Eo,uG,bEo,vEo,FEo,xu,d_e,TEo,MEo,pG,EEo,CEo,wEo,$u,m_e,AEo,LEo,_G,yEo,xEo,$Eo,ku,c_e,kEo,SEo,bG,REo,PEo,BEo,Su,f_e,IEo,NEo,vG,qEo,jEo,DEo,Ru,g_e,GEo,OEo,FG,VEo,XEo,zEo,Pu,h_e,QEo,WEo,TG,UEo,HEo,JEo,Bu,u_e,YEo,ZEo,MG,KEo,e4o,o4o,Iu,p_e,r4o,t4o,EG,a4o,n4o,s4o,Nu,__e,l4o,i4o,CG,d4o,m4o,c4o,qu,f4o,ju,yk,g4o,b_e,h4o,nio,Id,Du,v_e,xk,u4o,F_e,p4o,sio,Io,$k,_4o,kk,b4o,wG,v4o,F4o,T4o,Sk,M4o,T_e,E4o,C4o,w4o,Xr,Rk,A4o,M_e,L4o,y4o,mn,x4o,E_e,$4o,k4o,C_e,S4o,R4o,w_e,P4o,B4o,I4o,k,Ms,A_e,N4o,q4o,AG,j4o,D4o,LG,G4o,O4o,V4o,Es,L_e,X4o,z4o,yG,Q4o,W4o,xG,U4o,H4o,J4o,Cs,y_e,Y4o,Z4o,$G,K4o,eCo,kG,oCo,rCo,tCo,Gu,x_e,aCo,nCo,SG,sCo,lCo,iCo,ws,$_e,dCo,mCo,RG,cCo,fCo,PG,gCo,hCo,uCo,Ou,k_e,pCo,_Co,BG,bCo,vCo,FCo,Vu,S_e,TCo,MCo,IG,ECo,CCo,wCo,Xu,R_e,ACo,LCo,NG,yCo,xCo,$Co,As,P_e,kCo,SCo,qG,RCo,PCo,jG,BCo,ICo,NCo,Ls,B_e,qCo,jCo,DG,DCo,GCo,GG,OCo,VCo,XCo,ys,I_e,zCo,QCo,OG,WCo,UCo,VG,HCo,JCo,YCo,zu,N_e,ZCo,KCo,XG,e3o,o3o,r3o,Qu,q_e,t3o,a3o,zG,n3o,s3o,l3o,Wu,j_e,i3o,d3o,QG,m3o,c3o,f3o,xs,D_e,g3o,h3o,WG,u3o,p3o,UG,_3o,b3o,v3o,Uu,G_e,F3o,T3o,HG,M3o,E3o,C3o,$s,O_e,w3o,A3o,JG,L3o,y3o,YG,x3o,$3o,k3o,ks,V_e,S3o,R3o,ZG,P3o,B3o,KG,I3o,N3o,q3o,Ss,X_e,j3o,D3o,eO,G3o,O3o,oO,V3o,X3o,z3o,Rs,z_e,Q3o,W3o,rO,U3o,H3o,tO,J3o,Y3o,Z3o,Ps,Q_e,K3o,e5o,aO,o5o,r5o,nO,t5o,a5o,n5o,Hu,W_e,s5o,l5o,sO,i5o,d5o,m5o,Bs,U_e,c5o,f5o,lO,g5o,h5o,iO,u5o,p5o,_5o,Is,H_e,b5o,v5o,dO,F5o,T5o,mO,M5o,E5o,C5o,Ns,J_e,w5o,A5o,cO,L5o,y5o,fO,x5o,$5o,k5o,qs,Y_e,S5o,R5o,gO,P5o,B5o,hO,I5o,N5o,q5o,js,Z_e,j5o,D5o,uO,G5o,O5o,pO,V5o,X5o,z5o,Ds,K_e,Q5o,W5o,_O,U5o,H5o,bO,J5o,Y5o,Z5o,Gs,e1e,K5o,e0o,vO,o0o,r0o,FO,t0o,a0o,n0o,Ju,o1e,s0o,l0o,TO,i0o,d0o,m0o,Yu,r1e,c0o,f0o,MO,g0o,h0o,u0o,Os,t1e,p0o,_0o,EO,b0o,v0o,CO,F0o,T0o,M0o,Zu,a1e,E0o,C0o,wO,w0o,A0o,L0o,Vs,n1e,y0o,x0o,AO,$0o,k0o,LO,S0o,R0o,P0o,Xs,s1e,B0o,I0o,yO,N0o,q0o,xO,j0o,D0o,G0o,zs,l1e,O0o,V0o,$O,X0o,z0o,kO,Q0o,W0o,U0o,Ku,i1e,H0o,J0o,SO,Y0o,Z0o,K0o,ep,d1e,ewo,owo,RO,rwo,two,awo,Qs,m1e,nwo,swo,PO,lwo,iwo,BO,dwo,mwo,cwo,Ws,c1e,fwo,gwo,IO,hwo,uwo,NO,pwo,_wo,bwo,Us,f1e,vwo,Fwo,qO,Two,Mwo,jO,Ewo,Cwo,wwo,op,g1e,Awo,Lwo,DO,ywo,xwo,$wo,Hs,h1e,kwo,Swo,GO,Rwo,Pwo,OO,Bwo,Iwo,Nwo,rp,u1e,qwo,jwo,VO,Dwo,Gwo,Owo,Js,p1e,Vwo,Xwo,XO,zwo,Qwo,zO,Wwo,Uwo,Hwo,Ys,_1e,Jwo,Ywo,QO,Zwo,Kwo,WO,eAo,oAo,rAo,Zs,b1e,tAo,aAo,UO,nAo,sAo,HO,lAo,iAo,dAo,Ks,v1e,mAo,cAo,JO,fAo,gAo,YO,hAo,uAo,pAo,el,F1e,_Ao,bAo,ZO,vAo,FAo,KO,TAo,MAo,EAo,ol,T1e,CAo,wAo,eV,AAo,LAo,oV,yAo,xAo,$Ao,rl,M1e,kAo,SAo,rV,RAo,PAo,tV,BAo,IAo,NAo,tl,E1e,qAo,jAo,aV,DAo,GAo,nV,OAo,VAo,XAo,tp,C1e,zAo,QAo,sV,WAo,UAo,HAo,al,w1e,JAo,YAo,lV,ZAo,KAo,iV,e6o,o6o,r6o,ap,A1e,t6o,a6o,dV,n6o,s6o,l6o,np,L1e,i6o,d6o,mV,m6o,c6o,f6o,nl,y1e,g6o,h6o,cV,u6o,p6o,fV,_6o,b6o,v6o,sl,x1e,F6o,T6o,gV,M6o,E6o,hV,C6o,w6o,A6o,ll,$1e,L6o,y6o,uV,x6o,$6o,pV,k6o,S6o,R6o,sp,k1e,P6o,B6o,_V,I6o,N6o,q6o,il,S1e,j6o,D6o,bV,G6o,O6o,vV,V6o,X6o,z6o,dl,R1e,Q6o,W6o,FV,U6o,H6o,TV,J6o,Y6o,Z6o,ml,P1e,K6o,e7o,MV,o7o,r7o,EV,t7o,a7o,n7o,cl,B1e,s7o,l7o,CV,i7o,d7o,wV,m7o,c7o,f7o,fl,I1e,g7o,h7o,AV,u7o,p7o,LV,_7o,b7o,v7o,gl,N1e,F7o,T7o,yV,M7o,E7o,xV,C7o,w7o,A7o,hl,q1e,L7o,y7o,$V,x7o,$7o,kV,k7o,S7o,R7o,ul,j1e,P7o,B7o,SV,I7o,N7o,RV,q7o,j7o,D7o,lp,D1e,G7o,O7o,PV,V7o,X7o,z7o,pl,G1e,Q7o,W7o,BV,U7o,H7o,IV,J7o,Y7o,Z7o,_l,O1e,K7o,e8o,NV,o8o,r8o,qV,t8o,a8o,n8o,bl,V1e,s8o,l8o,jV,i8o,d8o,DV,m8o,c8o,f8o,ip,X1e,g8o,h8o,GV,u8o,p8o,_8o,dp,z1e,b8o,v8o,OV,F8o,T8o,M8o,mp,Q1e,E8o,C8o,VV,w8o,A8o,L8o,cp,W1e,y8o,x8o,XV,$8o,k8o,S8o,vl,U1e,R8o,P8o,zV,B8o,I8o,QV,N8o,q8o,j8o,fp,H1e,D8o,G8o,WV,O8o,V8o,X8o,Fl,J1e,z8o,Q8o,UV,W8o,U8o,HV,H8o,J8o,Y8o,Tl,Y1e,Z8o,K8o,JV,eLo,oLo,YV,rLo,tLo,aLo,Ml,Z1e,nLo,sLo,ZV,lLo,iLo,KV,dLo,mLo,cLo,El,K1e,fLo,gLo,eX,hLo,uLo,oX,pLo,_Lo,bLo,Cl,e2e,vLo,FLo,rX,TLo,MLo,tX,ELo,CLo,wLo,gp,o2e,ALo,LLo,aX,yLo,xLo,$Lo,wl,r2e,kLo,SLo,nX,RLo,PLo,sX,BLo,ILo,NLo,hp,t2e,qLo,jLo,lX,DLo,GLo,OLo,up,a2e,VLo,XLo,iX,zLo,QLo,WLo,Al,n2e,ULo,HLo,dX,JLo,YLo,mX,ZLo,KLo,eyo,Ll,s2e,oyo,ryo,cX,tyo,ayo,fX,nyo,syo,lyo,yl,l2e,iyo,dyo,gX,myo,cyo,hX,fyo,gyo,hyo,pp,i2e,uyo,pyo,uX,_yo,byo,vyo,_p,d2e,Fyo,Tyo,pX,Myo,Eyo,Cyo,bp,m2e,wyo,Ayo,_X,Lyo,yyo,xyo,xl,c2e,$yo,kyo,bX,Syo,Ryo,vX,Pyo,Byo,Iyo,$l,f2e,Nyo,qyo,FX,jyo,Dyo,TX,Gyo,Oyo,Vyo,vp,g2e,Xyo,zyo,MX,Qyo,Wyo,Uyo,Fp,h2e,Hyo,Jyo,EX,Yyo,Zyo,Kyo,Tp,u2e,e9o,o9o,CX,r9o,t9o,a9o,Mp,p2e,n9o,s9o,wX,l9o,i9o,d9o,kl,_2e,m9o,c9o,AX,f9o,g9o,LX,h9o,u9o,p9o,Sl,b2e,_9o,b9o,yX,v9o,F9o,xX,T9o,M9o,E9o,Ep,v2e,C9o,w9o,$X,A9o,L9o,y9o,Cp,F2e,x9o,$9o,kX,k9o,S9o,R9o,Rl,T2e,P9o,B9o,SX,I9o,N9o,RX,q9o,j9o,D9o,Pl,M2e,G9o,O9o,PX,V9o,X9o,BX,z9o,Q9o,W9o,Bl,E2e,U9o,H9o,IX,J9o,Y9o,NX,Z9o,K9o,exo,Il,C2e,oxo,rxo,qX,txo,axo,jX,nxo,sxo,lxo,wp,ixo,Ap,Pk,dxo,w2e,mxo,lio,Nd,Lp,A2e,Bk,cxo,L2e,fxo,iio,No,Ik,gxo,Nk,hxo,DX,uxo,pxo,_xo,qk,bxo,y2e,vxo,Fxo,Txo,eo,jk,Mxo,x2e,Exo,Cxo,cn,wxo,$2e,Axo,Lxo,k2e,yxo,xxo,S2e,$xo,kxo,Sxo,z,yp,R2e,Rxo,Pxo,GX,Bxo,Ixo,Nxo,xp,P2e,qxo,jxo,OX,Dxo,Gxo,Oxo,$p,B2e,Vxo,Xxo,VX,zxo,Qxo,Wxo,kp,I2e,Uxo,Hxo,XX,Jxo,Yxo,Zxo,Sp,N2e,Kxo,e$o,zX,o$o,r$o,t$o,Rp,q2e,a$o,n$o,QX,s$o,l$o,i$o,Pp,j2e,d$o,m$o,WX,c$o,f$o,g$o,Bp,D2e,h$o,u$o,UX,p$o,_$o,b$o,Ip,G2e,v$o,F$o,HX,T$o,M$o,E$o,Np,O2e,C$o,w$o,JX,A$o,L$o,y$o,qp,V2e,x$o,$$o,YX,k$o,S$o,R$o,jp,X2e,P$o,B$o,ZX,I$o,N$o,q$o,Dp,z2e,j$o,D$o,KX,G$o,O$o,V$o,Gp,Q2e,X$o,z$o,ez,Q$o,W$o,U$o,Op,W2e,H$o,J$o,oz,Y$o,Z$o,K$o,Vp,U2e,eko,oko,rz,rko,tko,ako,Xp,H2e,nko,sko,tz,lko,iko,dko,zp,J2e,mko,cko,az,fko,gko,hko,Qp,Y2e,uko,pko,nz,_ko,bko,vko,Wp,Z2e,Fko,Tko,sz,Mko,Eko,Cko,Up,K2e,wko,Ako,lz,Lko,yko,xko,Hp,ebe,$ko,kko,iz,Sko,Rko,Pko,Jp,obe,Bko,Iko,dz,Nko,qko,jko,Yp,rbe,Dko,Gko,mz,Oko,Vko,Xko,Zp,tbe,zko,Qko,cz,Wko,Uko,Hko,Kp,abe,Jko,Yko,fz,Zko,Kko,eSo,e_,nbe,oSo,rSo,gz,tSo,aSo,nSo,o_,sbe,sSo,lSo,hz,iSo,dSo,mSo,r_,lbe,cSo,fSo,uz,gSo,hSo,uSo,t_,ibe,pSo,_So,pz,bSo,vSo,FSo,a_,dbe,TSo,MSo,_z,ESo,CSo,wSo,n_,mbe,ASo,LSo,bz,ySo,xSo,$So,s_,cbe,kSo,SSo,vz,RSo,PSo,BSo,l_,fbe,ISo,NSo,Fz,qSo,jSo,DSo,i_,gbe,GSo,OSo,Tz,VSo,XSo,zSo,d_,hbe,QSo,WSo,Mz,USo,HSo,JSo,m_,ube,YSo,ZSo,Ez,KSo,eRo,oRo,c_,pbe,rRo,tRo,Cz,aRo,nRo,sRo,f_,_be,lRo,iRo,wz,dRo,mRo,cRo,g_,bbe,fRo,gRo,Az,hRo,uRo,pRo,h_,vbe,_Ro,bRo,Lz,vRo,FRo,TRo,u_,Fbe,MRo,ERo,yz,CRo,wRo,ARo,p_,Tbe,LRo,yRo,xz,xRo,$Ro,kRo,__,Mbe,SRo,RRo,$z,PRo,BRo,IRo,b_,Ebe,NRo,qRo,kz,jRo,DRo,GRo,v_,Cbe,ORo,VRo,Sz,XRo,zRo,QRo,F_,WRo,T_,URo,M_,Dk,HRo,wbe,JRo,dio,qd,E_,Abe,Gk,YRo,Lbe,ZRo,mio,qo,Ok,KRo,Vk,ePo,Rz,oPo,rPo,tPo,Xk,aPo,ybe,nPo,sPo,lPo,oo,zk,iPo,xbe,dPo,mPo,fn,cPo,$be,fPo,gPo,kbe,hPo,uPo,Sbe,pPo,_Po,bPo,oe,C_,Rbe,vPo,FPo,Pz,TPo,MPo,EPo,w_,Pbe,CPo,wPo,Bz,APo,LPo,yPo,A_,Bbe,xPo,$Po,Iz,kPo,SPo,RPo,L_,Ibe,PPo,BPo,Nz,IPo,NPo,qPo,y_,Nbe,jPo,DPo,qz,GPo,OPo,VPo,x_,qbe,XPo,zPo,jz,QPo,WPo,UPo,$_,jbe,HPo,JPo,Dz,YPo,ZPo,KPo,k_,Dbe,eBo,oBo,Gz,rBo,tBo,aBo,S_,Gbe,nBo,sBo,Oz,lBo,iBo,dBo,R_,Obe,mBo,cBo,Vz,fBo,gBo,hBo,P_,Vbe,uBo,pBo,Xz,_Bo,bBo,vBo,B_,Xbe,FBo,TBo,zz,MBo,EBo,CBo,I_,zbe,wBo,ABo,Qz,LBo,yBo,xBo,N_,Qbe,$Bo,kBo,Wz,SBo,RBo,PBo,q_,Wbe,BBo,IBo,Uz,NBo,qBo,jBo,j_,Ube,DBo,GBo,Hz,OBo,VBo,XBo,D_,Hbe,zBo,QBo,Jz,WBo,UBo,HBo,G_,Jbe,JBo,YBo,Yz,ZBo,KBo,eIo,O_,Ybe,oIo,rIo,Zz,tIo,aIo,nIo,V_,Zbe,sIo,lIo,Kz,iIo,dIo,mIo,X_,Kbe,cIo,fIo,eQ,gIo,hIo,uIo,z_,eve,pIo,_Io,oQ,bIo,vIo,FIo,Q_,ove,TIo,MIo,rQ,EIo,CIo,wIo,W_,rve,AIo,LIo,tQ,yIo,xIo,$Io,U_,tve,kIo,SIo,aQ,RIo,PIo,BIo,H_,ave,IIo,NIo,nQ,qIo,jIo,DIo,J_,nve,GIo,OIo,sQ,VIo,XIo,zIo,Y_,sve,QIo,WIo,lQ,UIo,HIo,JIo,Z_,lve,YIo,ZIo,iQ,KIo,eNo,oNo,K_,ive,rNo,tNo,dQ,aNo,nNo,sNo,e1,lNo,o1,iNo,r1,Qk,dNo,dve,mNo,cio,jd,t1,mve,Wk,cNo,cve,fNo,fio,jo,Uk,gNo,Hk,hNo,mQ,uNo,pNo,_No,Jk,bNo,fve,vNo,FNo,TNo,ro,Yk,MNo,gve,ENo,CNo,Dd,wNo,hve,ANo,LNo,uve,yNo,xNo,$No,ie,a1,pve,kNo,SNo,cQ,RNo,PNo,BNo,n1,_ve,INo,NNo,fQ,qNo,jNo,DNo,s1,bve,GNo,ONo,gQ,VNo,XNo,zNo,l1,vve,QNo,WNo,hQ,UNo,HNo,JNo,i1,Fve,YNo,ZNo,uQ,KNo,eqo,oqo,d1,Tve,rqo,tqo,pQ,aqo,nqo,sqo,m1,Mve,lqo,iqo,_Q,dqo,mqo,cqo,c1,Eve,fqo,gqo,bQ,hqo,uqo,pqo,f1,Cve,_qo,bqo,vQ,vqo,Fqo,Tqo,g1,wve,Mqo,Eqo,FQ,Cqo,wqo,Aqo,h1,Ave,Lqo,yqo,TQ,xqo,$qo,kqo,u1,Lve,Sqo,Rqo,MQ,Pqo,Bqo,Iqo,p1,yve,Nqo,qqo,EQ,jqo,Dqo,Gqo,_1,xve,Oqo,Vqo,CQ,Xqo,zqo,Qqo,b1,$ve,Wqo,Uqo,wQ,Hqo,Jqo,Yqo,v1,kve,Zqo,Kqo,AQ,ejo,ojo,rjo,F1,Sve,tjo,ajo,LQ,njo,sjo,ljo,T1,Rve,ijo,djo,yQ,mjo,cjo,fjo,M1,Pve,gjo,hjo,xQ,ujo,pjo,_jo,E1,Bve,bjo,vjo,$Q,Fjo,Tjo,Mjo,C1,Ive,Ejo,Cjo,kQ,wjo,Ajo,Ljo,w1,Nve,yjo,xjo,SQ,$jo,kjo,Sjo,A1,qve,Rjo,Pjo,RQ,Bjo,Ijo,Njo,L1,qjo,y1,jjo,x1,Zk,Djo,jve,Gjo,gio,Gd,$1,Dve,Kk,Ojo,Gve,Vjo,hio,Do,eS,Xjo,Od,zjo,PQ,Qjo,Wjo,BQ,Ujo,Hjo,Jjo,oS,Yjo,Ove,Zjo,Kjo,eDo,At,rS,oDo,Vve,rDo,tDo,Vd,aDo,Xve,nDo,sDo,IQ,lDo,iDo,dDo,k1,mDo,to,tS,cDo,zve,fDo,gDo,gn,hDo,Qve,uDo,pDo,Wve,_Do,bDo,Uve,vDo,FDo,TDo,y,S1,Hve,MDo,EDo,NQ,CDo,wDo,ADo,R1,Jve,LDo,yDo,qQ,xDo,$Do,kDo,P1,Yve,SDo,RDo,jQ,PDo,BDo,IDo,B1,Zve,NDo,qDo,DQ,jDo,DDo,GDo,I1,Kve,ODo,VDo,GQ,XDo,zDo,QDo,N1,eFe,WDo,UDo,OQ,HDo,JDo,YDo,q1,oFe,ZDo,KDo,VQ,eGo,oGo,rGo,j1,rFe,tGo,aGo,XQ,nGo,sGo,lGo,D1,tFe,iGo,dGo,zQ,mGo,cGo,fGo,G1,aFe,gGo,hGo,QQ,uGo,pGo,_Go,O1,nFe,bGo,vGo,WQ,FGo,TGo,MGo,V1,sFe,EGo,CGo,UQ,wGo,AGo,LGo,X1,lFe,yGo,xGo,HQ,$Go,kGo,SGo,z1,iFe,RGo,PGo,JQ,BGo,IGo,NGo,Q1,dFe,qGo,jGo,YQ,DGo,GGo,OGo,W1,mFe,VGo,XGo,ZQ,zGo,QGo,WGo,U1,cFe,UGo,HGo,KQ,JGo,YGo,ZGo,H1,fFe,KGo,eOo,eW,oOo,rOo,tOo,J1,gFe,aOo,nOo,oW,sOo,lOo,iOo,Y1,hFe,dOo,mOo,rW,cOo,fOo,gOo,Z1,uFe,hOo,uOo,tW,pOo,_Oo,bOo,K1,pFe,vOo,FOo,aW,TOo,MOo,EOo,e2,_Fe,COo,wOo,nW,AOo,LOo,yOo,o2,bFe,xOo,$Oo,sW,kOo,SOo,ROo,r2,vFe,POo,BOo,lW,IOo,NOo,qOo,t2,FFe,jOo,DOo,iW,GOo,OOo,VOo,a2,TFe,XOo,zOo,dW,QOo,WOo,UOo,n2,MFe,HOo,JOo,mW,YOo,ZOo,KOo,s2,EFe,eVo,oVo,cW,rVo,tVo,aVo,l2,CFe,nVo,sVo,fW,lVo,iVo,dVo,i2,wFe,mVo,cVo,gW,fVo,gVo,hVo,d2,AFe,uVo,pVo,hW,_Vo,bVo,vVo,m2,LFe,FVo,TVo,uW,MVo,EVo,CVo,c2,yFe,wVo,AVo,pW,LVo,yVo,xVo,f2,xFe,$Vo,kVo,_W,SVo,RVo,PVo,g2,$Fe,BVo,IVo,bW,NVo,qVo,jVo,h2,kFe,DVo,GVo,vW,OVo,VVo,XVo,u2,SFe,zVo,QVo,FW,WVo,UVo,HVo,p2,RFe,JVo,YVo,TW,ZVo,KVo,eXo,_2,PFe,oXo,rXo,MW,tXo,aXo,nXo,Nl,BFe,sXo,lXo,EW,iXo,dXo,CW,mXo,cXo,fXo,b2,IFe,gXo,hXo,wW,uXo,pXo,_Xo,v2,NFe,bXo,vXo,AW,FXo,TXo,MXo,F2,qFe,EXo,CXo,LW,wXo,AXo,LXo,T2,jFe,yXo,xXo,yW,$Xo,kXo,SXo,M2,DFe,RXo,PXo,xW,BXo,IXo,NXo,E2,GFe,qXo,jXo,$W,DXo,GXo,OXo,C2,OFe,VXo,XXo,kW,zXo,QXo,WXo,w2,VFe,UXo,HXo,SW,JXo,YXo,ZXo,A2,XFe,KXo,ezo,RW,ozo,rzo,tzo,L2,zFe,azo,nzo,PW,szo,lzo,izo,y2,QFe,dzo,mzo,BW,czo,fzo,gzo,x2,WFe,hzo,uzo,IW,pzo,_zo,bzo,$2,UFe,vzo,Fzo,NW,Tzo,Mzo,Ezo,k2,HFe,Czo,wzo,qW,Azo,Lzo,yzo,S2,JFe,xzo,$zo,jW,kzo,Szo,Rzo,R2,YFe,Pzo,Bzo,DW,Izo,Nzo,qzo,P2,ZFe,jzo,Dzo,GW,Gzo,Ozo,Vzo,B2,KFe,Xzo,zzo,OW,Qzo,Wzo,Uzo,I2,eTe,Hzo,Jzo,VW,Yzo,Zzo,Kzo,N2,oTe,eQo,oQo,XW,rQo,tQo,aQo,q2,rTe,nQo,sQo,zW,lQo,iQo,dQo,j2,tTe,mQo,cQo,QW,fQo,gQo,hQo,D2,aTe,uQo,pQo,WW,_Qo,bQo,vQo,G2,nTe,FQo,TQo,UW,MQo,EQo,CQo,O2,sTe,wQo,AQo,HW,LQo,yQo,xQo,V2,lTe,$Qo,kQo,JW,SQo,RQo,PQo,X2,iTe,BQo,IQo,YW,NQo,qQo,jQo,z2,dTe,DQo,GQo,ZW,OQo,VQo,XQo,Q2,mTe,zQo,QQo,KW,WQo,UQo,HQo,W2,cTe,JQo,YQo,eU,ZQo,KQo,eWo,U2,fTe,oWo,rWo,oU,tWo,aWo,nWo,H2,gTe,sWo,lWo,rU,iWo,dWo,mWo,J2,hTe,cWo,fWo,tU,gWo,hWo,uWo,Y2,uTe,pWo,_Wo,aU,bWo,vWo,FWo,Z2,pTe,TWo,MWo,nU,EWo,CWo,wWo,K2,_Te,AWo,LWo,sU,yWo,xWo,$Wo,eb,bTe,kWo,SWo,lU,RWo,PWo,BWo,ob,vTe,IWo,NWo,iU,qWo,jWo,DWo,rb,FTe,GWo,OWo,dU,VWo,XWo,zWo,tb,TTe,QWo,WWo,mU,UWo,HWo,JWo,ab,MTe,YWo,ZWo,cU,KWo,eUo,oUo,nb,ETe,rUo,tUo,fU,aUo,nUo,sUo,sb,CTe,lUo,iUo,gU,dUo,mUo,cUo,lb,wTe,fUo,gUo,hU,hUo,uUo,pUo,ib,ATe,_Uo,bUo,uU,vUo,FUo,TUo,db,LTe,MUo,EUo,pU,CUo,wUo,AUo,mb,yTe,LUo,yUo,_U,xUo,$Uo,kUo,cb,xTe,SUo,RUo,bU,PUo,BUo,IUo,fb,$Te,NUo,qUo,vU,jUo,DUo,GUo,gb,kTe,OUo,VUo,FU,XUo,zUo,QUo,hb,STe,WUo,UUo,TU,HUo,JUo,YUo,ub,RTe,ZUo,KUo,MU,eHo,oHo,rHo,pb,PTe,tHo,aHo,EU,nHo,sHo,lHo,_b,BTe,iHo,dHo,CU,mHo,cHo,fHo,bb,ITe,gHo,hHo,wU,uHo,pHo,_Ho,vb,NTe,bHo,vHo,AU,FHo,THo,MHo,Fb,qTe,EHo,CHo,LU,wHo,AHo,LHo,Tb,jTe,yHo,xHo,yU,$Ho,kHo,SHo,Mb,DTe,RHo,PHo,xU,BHo,IHo,NHo,Eb,GTe,qHo,jHo,$U,DHo,GHo,OHo,Cb,OTe,VHo,XHo,kU,zHo,QHo,WHo,wb,VTe,UHo,HHo,SU,JHo,YHo,ZHo,Ab,XTe,KHo,eJo,RU,oJo,rJo,tJo,Lb,zTe,aJo,nJo,PU,sJo,lJo,iJo,yb,QTe,dJo,mJo,BU,cJo,fJo,gJo,xb,WTe,hJo,uJo,IU,pJo,_Jo,bJo,$b,UTe,vJo,FJo,NU,TJo,MJo,EJo,kb,HTe,CJo,wJo,qU,AJo,LJo,yJo,Sb,JTe,xJo,$Jo,jU,kJo,SJo,RJo,Rb,YTe,PJo,BJo,DU,IJo,NJo,qJo,Pb,ZTe,jJo,DJo,GU,GJo,OJo,VJo,Bb,KTe,XJo,zJo,OU,QJo,WJo,UJo,Ib,eMe,HJo,JJo,VU,YJo,ZJo,KJo,Nb,oMe,eYo,oYo,XU,rYo,tYo,aYo,qb,rMe,nYo,sYo,zU,lYo,iYo,dYo,jb,tMe,mYo,cYo,QU,fYo,gYo,hYo,Db,aMe,uYo,pYo,WU,_Yo,bYo,vYo,Gb,nMe,FYo,TYo,UU,MYo,EYo,CYo,Ob,sMe,wYo,AYo,HU,LYo,yYo,xYo,Vb,lMe,$Yo,kYo,JU,SYo,RYo,PYo,Xb,iMe,BYo,IYo,YU,NYo,qYo,jYo,zb,dMe,DYo,GYo,ZU,OYo,VYo,XYo,Qb,mMe,zYo,QYo,KU,WYo,UYo,HYo,Wb,cMe,JYo,YYo,eH,ZYo,KYo,eZo,Ub,fMe,oZo,rZo,oH,tZo,aZo,nZo,Hb,gMe,sZo,lZo,rH,iZo,dZo,mZo,Jb,hMe,cZo,fZo,tH,gZo,hZo,uZo,Yb,uMe,pZo,_Zo,aH,bZo,vZo,FZo,Zb,pMe,TZo,MZo,nH,EZo,CZo,wZo,Kb,_Me,AZo,LZo,sH,yZo,xZo,$Zo,ev,bMe,kZo,SZo,lH,RZo,PZo,BZo,ov,vMe,IZo,NZo,iH,qZo,jZo,DZo,rv,GZo,FMe,OZo,VZo,TMe,XZo,zZo,tv,uio,Xd,av,MMe,aS,QZo,EMe,WZo,pio,Go,nS,UZo,zd,HZo,dH,JZo,YZo,mH,ZZo,KZo,eKo,sS,oKo,CMe,rKo,tKo,aKo,Lt,lS,nKo,wMe,sKo,lKo,Qd,iKo,AMe,dKo,mKo,cH,cKo,fKo,gKo,nv,hKo,ao,iS,uKo,LMe,pKo,_Ko,hn,bKo,yMe,vKo,FKo,xMe,TKo,MKo,$Me,EKo,CKo,wKo,G,sv,kMe,AKo,LKo,fH,yKo,xKo,$Ko,lv,SMe,kKo,SKo,gH,RKo,PKo,BKo,iv,RMe,IKo,NKo,hH,qKo,jKo,DKo,dv,PMe,GKo,OKo,uH,VKo,XKo,zKo,mv,BMe,QKo,WKo,pH,UKo,HKo,JKo,cv,IMe,YKo,ZKo,_H,KKo,eer,oer,fv,NMe,rer,ter,bH,aer,ner,ser,gv,qMe,ler,ier,vH,der,mer,cer,hv,jMe,fer,ger,FH,her,uer,per,uv,DMe,_er,ber,TH,ver,Fer,Ter,pv,GMe,Mer,Eer,MH,Cer,wer,Aer,_v,OMe,Ler,yer,EH,xer,$er,ker,bv,VMe,Ser,Rer,CH,Per,Ber,Ier,vv,XMe,Ner,qer,wH,jer,Der,Ger,Fv,zMe,Oer,Ver,AH,Xer,zer,Qer,Tv,QMe,Wer,Uer,LH,Her,Jer,Yer,Mv,WMe,Zer,Ker,yH,eor,oor,ror,Ev,UMe,tor,aor,xH,nor,sor,lor,Cv,HMe,ior,dor,$H,mor,cor,gor,wv,JMe,hor,uor,kH,por,_or,bor,Av,YMe,vor,For,SH,Tor,Mor,Eor,Lv,ZMe,Cor,wor,RH,Aor,Lor,yor,yv,KMe,xor,$or,PH,kor,Sor,Ror,xv,eEe,Por,Bor,BH,Ior,Nor,qor,$v,oEe,jor,Dor,IH,Gor,Oor,Vor,kv,rEe,Xor,zor,NH,Qor,Wor,Uor,Sv,tEe,Hor,Jor,qH,Yor,Zor,Kor,Rv,aEe,err,orr,jH,rrr,trr,arr,Pv,nEe,nrr,srr,DH,lrr,irr,drr,Bv,sEe,mrr,crr,GH,frr,grr,hrr,Iv,lEe,urr,prr,OH,_rr,brr,vrr,Nv,iEe,Frr,Trr,VH,Mrr,Err,Crr,qv,dEe,wrr,Arr,XH,Lrr,yrr,xrr,jv,mEe,$rr,krr,zH,Srr,Rrr,Prr,Dv,cEe,Brr,Irr,QH,Nrr,qrr,jrr,Gv,fEe,Drr,Grr,WH,Orr,Vrr,Xrr,Ov,gEe,zrr,Qrr,UH,Wrr,Urr,Hrr,Vv,hEe,Jrr,Yrr,HH,Zrr,Krr,etr,Xv,uEe,otr,rtr,JH,ttr,atr,ntr,zv,pEe,str,ltr,YH,itr,dtr,mtr,Qv,_Ee,ctr,ftr,ZH,gtr,htr,utr,Wv,bEe,ptr,_tr,KH,btr,vtr,Ftr,Uv,vEe,Ttr,Mtr,eJ,Etr,Ctr,wtr,Hv,FEe,Atr,Ltr,oJ,ytr,xtr,$tr,Jv,TEe,ktr,Str,rJ,Rtr,Ptr,Btr,Yv,MEe,Itr,Ntr,tJ,qtr,jtr,Dtr,Zv,EEe,Gtr,Otr,aJ,Vtr,Xtr,ztr,Kv,CEe,Qtr,Wtr,nJ,Utr,Htr,Jtr,eF,wEe,Ytr,Ztr,sJ,Ktr,ear,oar,oF,rar,AEe,tar,aar,LEe,nar,sar,rF,_io,Wd,tF,yEe,dS,lar,xEe,iar,bio,Oo,mS,dar,Ud,mar,lJ,car,far,iJ,gar,har,uar,cS,par,$Ee,_ar,bar,Far,yt,fS,Tar,kEe,Mar,Ear,Hd,Car,SEe,war,Aar,dJ,Lar,yar,xar,aF,$ar,no,gS,kar,REe,Sar,Rar,un,Par,PEe,Bar,Iar,BEe,Nar,qar,IEe,jar,Dar,Gar,W,nF,NEe,Oar,Var,mJ,Xar,zar,Qar,sF,qEe,War,Uar,cJ,Har,Jar,Yar,lF,jEe,Zar,Kar,fJ,enr,onr,rnr,iF,DEe,tnr,anr,gJ,nnr,snr,lnr,dF,GEe,inr,dnr,hJ,mnr,cnr,fnr,mF,OEe,gnr,hnr,uJ,unr,pnr,_nr,cF,VEe,bnr,vnr,pJ,Fnr,Tnr,Mnr,fF,XEe,Enr,Cnr,_J,wnr,Anr,Lnr,gF,zEe,ynr,xnr,bJ,$nr,knr,Snr,hF,QEe,Rnr,Pnr,vJ,Bnr,Inr,Nnr,uF,WEe,qnr,jnr,FJ,Dnr,Gnr,Onr,pF,UEe,Vnr,Xnr,TJ,znr,Qnr,Wnr,_F,HEe,Unr,Hnr,MJ,Jnr,Ynr,Znr,bF,JEe,Knr,esr,EJ,osr,rsr,tsr,vF,YEe,asr,nsr,CJ,ssr,lsr,isr,FF,ZEe,dsr,msr,wJ,csr,fsr,gsr,TF,KEe,hsr,usr,AJ,psr,_sr,bsr,MF,e4e,vsr,Fsr,LJ,Tsr,Msr,Esr,EF,o4e,Csr,wsr,yJ,Asr,Lsr,ysr,CF,r4e,xsr,$sr,xJ,ksr,Ssr,Rsr,wF,t4e,Psr,Bsr,$J,Isr,Nsr,qsr,AF,a4e,jsr,Dsr,kJ,Gsr,Osr,Vsr,LF,n4e,Xsr,zsr,SJ,Qsr,Wsr,Usr,yF,s4e,Hsr,Jsr,RJ,Ysr,Zsr,Ksr,xF,l4e,elr,olr,PJ,rlr,tlr,alr,$F,i4e,nlr,slr,BJ,llr,ilr,dlr,kF,d4e,mlr,clr,IJ,flr,glr,hlr,SF,m4e,ulr,plr,NJ,_lr,blr,vlr,RF,c4e,Flr,Tlr,qJ,Mlr,Elr,Clr,PF,f4e,wlr,Alr,jJ,Llr,ylr,xlr,BF,g4e,$lr,klr,DJ,Slr,Rlr,Plr,IF,h4e,Blr,Ilr,GJ,Nlr,qlr,jlr,NF,u4e,Dlr,Glr,OJ,Olr,Vlr,Xlr,qF,p4e,zlr,Qlr,VJ,Wlr,Ulr,Hlr,jF,_4e,Jlr,Ylr,XJ,Zlr,Klr,eir,DF,b4e,oir,rir,zJ,tir,air,nir,GF,v4e,sir,lir,QJ,iir,dir,mir,OF,F4e,cir,fir,WJ,gir,hir,uir,VF,T4e,pir,_ir,UJ,bir,vir,Fir,XF,M4e,Tir,Mir,HJ,Eir,Cir,wir,zF,E4e,Air,Lir,JJ,yir,xir,$ir,QF,C4e,kir,Sir,YJ,Rir,Pir,Bir,WF,w4e,Iir,Nir,ZJ,qir,jir,Dir,UF,Gir,A4e,Oir,Vir,L4e,Xir,zir,HF,vio,Jd,JF,y4e,hS,Qir,x4e,Wir,Fio,Vo,uS,Uir,Yd,Hir,KJ,Jir,Yir,eY,Zir,Kir,edr,pS,odr,$4e,rdr,tdr,adr,xt,_S,ndr,k4e,sdr,ldr,Zd,idr,S4e,ddr,mdr,oY,cdr,fdr,gdr,YF,hdr,so,bS,udr,R4e,pdr,_dr,pn,bdr,P4e,vdr,Fdr,B4e,Tdr,Mdr,I4e,Edr,Cdr,wdr,vS,ZF,N4e,Adr,Ldr,rY,ydr,xdr,$dr,KF,q4e,kdr,Sdr,tY,Rdr,Pdr,Bdr,eT,Idr,j4e,Ndr,qdr,D4e,jdr,Ddr,oT,Tio,Kd,rT,G4e,FS,Gdr,O4e,Odr,Mio,Xo,TS,Vdr,em,Xdr,aY,zdr,Qdr,nY,Wdr,Udr,Hdr,MS,Jdr,V4e,Ydr,Zdr,Kdr,$t,ES,emr,X4e,omr,rmr,om,tmr,z4e,amr,nmr,sY,smr,lmr,imr,tT,dmr,lo,CS,mmr,Q4e,cmr,fmr,_n,gmr,W4e,hmr,umr,U4e,pmr,_mr,H4e,bmr,vmr,Fmr,Y,aT,J4e,Tmr,Mmr,lY,Emr,Cmr,wmr,nT,Y4e,Amr,Lmr,iY,ymr,xmr,$mr,sT,Z4e,kmr,Smr,dY,Rmr,Pmr,Bmr,lT,K4e,Imr,Nmr,mY,qmr,jmr,Dmr,iT,eCe,Gmr,Omr,cY,Vmr,Xmr,zmr,dT,oCe,Qmr,Wmr,fY,Umr,Hmr,Jmr,mT,rCe,Ymr,Zmr,gY,Kmr,ecr,ocr,cT,tCe,rcr,tcr,hY,acr,ncr,scr,fT,aCe,lcr,icr,uY,dcr,mcr,ccr,gT,nCe,fcr,gcr,pY,hcr,ucr,pcr,hT,sCe,_cr,bcr,_Y,vcr,Fcr,Tcr,uT,lCe,Mcr,Ecr,bY,Ccr,wcr,Acr,pT,iCe,Lcr,ycr,vY,xcr,$cr,kcr,_T,dCe,Scr,Rcr,FY,Pcr,Bcr,Icr,bT,mCe,Ncr,qcr,TY,jcr,Dcr,Gcr,vT,cCe,Ocr,Vcr,MY,Xcr,zcr,Qcr,FT,fCe,Wcr,Ucr,EY,Hcr,Jcr,Ycr,TT,gCe,Zcr,Kcr,CY,efr,ofr,rfr,MT,hCe,tfr,afr,wY,nfr,sfr,lfr,ET,uCe,ifr,dfr,AY,mfr,cfr,ffr,CT,pCe,gfr,hfr,LY,ufr,pfr,_fr,wT,_Ce,bfr,vfr,yY,Ffr,Tfr,Mfr,AT,bCe,Efr,Cfr,xY,wfr,Afr,Lfr,LT,vCe,yfr,xfr,$Y,$fr,kfr,Sfr,yT,FCe,Rfr,Pfr,kY,Bfr,Ifr,Nfr,xT,TCe,qfr,jfr,SY,Dfr,Gfr,Ofr,$T,MCe,Vfr,Xfr,RY,zfr,Qfr,Wfr,kT,ECe,Ufr,Hfr,PY,Jfr,Yfr,Zfr,ST,CCe,Kfr,egr,BY,ogr,rgr,tgr,RT,wCe,agr,ngr,IY,sgr,lgr,igr,PT,ACe,dgr,mgr,NY,cgr,fgr,ggr,BT,LCe,hgr,ugr,qY,pgr,_gr,bgr,IT,yCe,vgr,Fgr,jY,Tgr,Mgr,Egr,NT,xCe,Cgr,wgr,DY,Agr,Lgr,ygr,qT,$Ce,xgr,$gr,GY,kgr,Sgr,Rgr,jT,kCe,Pgr,Bgr,SCe,Igr,Ngr,qgr,DT,RCe,jgr,Dgr,OY,Ggr,Ogr,Vgr,GT,PCe,Xgr,zgr,VY,Qgr,Wgr,Ugr,OT,BCe,Hgr,Jgr,XY,Ygr,Zgr,Kgr,VT,ICe,ehr,ohr,zY,rhr,thr,ahr,XT,nhr,NCe,shr,lhr,qCe,ihr,dhr,zT,Eio,rm,QT,jCe,wS,mhr,DCe,chr,Cio,zo,AS,fhr,tm,ghr,QY,hhr,uhr,WY,phr,_hr,bhr,LS,vhr,GCe,Fhr,Thr,Mhr,kt,yS,Ehr,OCe,Chr,whr,am,Ahr,VCe,Lhr,yhr,UY,xhr,$hr,khr,WT,Shr,io,xS,Rhr,XCe,Phr,Bhr,bn,Ihr,zCe,Nhr,qhr,QCe,jhr,Dhr,WCe,Ghr,Ohr,Vhr,pe,UT,UCe,Xhr,zhr,HY,Qhr,Whr,Uhr,HT,HCe,Hhr,Jhr,JY,Yhr,Zhr,Khr,JT,JCe,eur,our,YY,rur,tur,aur,YT,YCe,nur,sur,ZY,lur,iur,dur,ZT,ZCe,mur,cur,KY,fur,gur,hur,KT,KCe,uur,pur,eZ,_ur,bur,vur,eM,e3e,Fur,Tur,oZ,Mur,Eur,Cur,oM,o3e,wur,Aur,rZ,Lur,yur,xur,rM,r3e,$ur,kur,tZ,Sur,Rur,Pur,tM,t3e,Bur,Iur,aZ,Nur,qur,jur,aM,a3e,Dur,Gur,nZ,Our,Vur,Xur,nM,n3e,zur,Qur,sZ,Wur,Uur,Hur,sM,s3e,Jur,Yur,lZ,Zur,Kur,epr,lM,l3e,opr,rpr,iZ,tpr,apr,npr,iM,i3e,spr,lpr,dZ,ipr,dpr,mpr,dM,d3e,cpr,fpr,mZ,gpr,hpr,upr,mM,m3e,ppr,_pr,cZ,bpr,vpr,Fpr,cM,c3e,Tpr,Mpr,fZ,Epr,Cpr,wpr,fM,f3e,Apr,Lpr,gZ,ypr,xpr,$pr,gM,g3e,kpr,Spr,hZ,Rpr,Ppr,Bpr,hM,Ipr,h3e,Npr,qpr,u3e,jpr,Dpr,uM,wio,nm,pM,p3e,$S,Gpr,_3e,Opr,Aio,Qo,kS,Vpr,sm,Xpr,uZ,zpr,Qpr,pZ,Wpr,Upr,Hpr,SS,Jpr,b3e,Ypr,Zpr,Kpr,St,RS,e_r,v3e,o_r,r_r,lm,t_r,F3e,a_r,n_r,_Z,s_r,l_r,i_r,_M,d_r,mo,PS,m_r,T3e,c_r,f_r,vn,g_r,M3e,h_r,u_r,E3e,p_r,__r,C3e,b_r,v_r,F_r,I,bM,w3e,T_r,M_r,bZ,E_r,C_r,w_r,vM,A3e,A_r,L_r,vZ,y_r,x_r,$_r,FM,L3e,k_r,S_r,FZ,R_r,P_r,B_r,TM,y3e,I_r,N_r,TZ,q_r,j_r,D_r,MM,x3e,G_r,O_r,MZ,V_r,X_r,z_r,EM,$3e,Q_r,W_r,EZ,U_r,H_r,J_r,CM,k3e,Y_r,Z_r,CZ,K_r,e1r,o1r,wM,S3e,r1r,t1r,wZ,a1r,n1r,s1r,AM,R3e,l1r,i1r,AZ,d1r,m1r,c1r,LM,P3e,f1r,g1r,LZ,h1r,u1r,p1r,yM,B3e,_1r,b1r,yZ,v1r,F1r,T1r,xM,I3e,M1r,E1r,xZ,C1r,w1r,A1r,$M,N3e,L1r,y1r,$Z,x1r,$1r,k1r,kM,q3e,S1r,R1r,kZ,P1r,B1r,I1r,SM,j3e,N1r,q1r,SZ,j1r,D1r,G1r,RM,D3e,O1r,V1r,RZ,X1r,z1r,Q1r,PM,G3e,W1r,U1r,PZ,H1r,J1r,Y1r,BM,O3e,Z1r,K1r,BZ,e2r,o2r,r2r,IM,V3e,t2r,a2r,IZ,n2r,s2r,l2r,NM,X3e,i2r,d2r,NZ,m2r,c2r,f2r,qM,z3e,g2r,h2r,qZ,u2r,p2r,_2r,jM,Q3e,b2r,v2r,jZ,F2r,T2r,M2r,DM,W3e,E2r,C2r,DZ,w2r,A2r,L2r,GM,U3e,y2r,x2r,GZ,$2r,k2r,S2r,OM,H3e,R2r,P2r,OZ,B2r,I2r,N2r,VM,J3e,q2r,j2r,VZ,D2r,G2r,O2r,XM,Y3e,V2r,X2r,XZ,z2r,Q2r,W2r,zM,Z3e,U2r,H2r,zZ,J2r,Y2r,Z2r,QM,K3e,K2r,ebr,QZ,obr,rbr,tbr,WM,e5e,abr,nbr,WZ,sbr,lbr,ibr,UM,o5e,dbr,mbr,UZ,cbr,fbr,gbr,HM,r5e,hbr,ubr,HZ,pbr,_br,bbr,JM,t5e,vbr,Fbr,JZ,Tbr,Mbr,Ebr,YM,a5e,Cbr,wbr,YZ,Abr,Lbr,ybr,ZM,n5e,xbr,$br,ZZ,kbr,Sbr,Rbr,KM,s5e,Pbr,Bbr,KZ,Ibr,Nbr,qbr,eE,l5e,jbr,Dbr,eK,Gbr,Obr,Vbr,oE,i5e,Xbr,zbr,oK,Qbr,Wbr,Ubr,rE,d5e,Hbr,Jbr,rK,Ybr,Zbr,Kbr,tE,m5e,evr,ovr,tK,rvr,tvr,avr,aE,c5e,nvr,svr,aK,lvr,ivr,dvr,nE,f5e,mvr,cvr,nK,fvr,gvr,hvr,sE,g5e,uvr,pvr,sK,_vr,bvr,vvr,lE,h5e,Fvr,Tvr,lK,Mvr,Evr,Cvr,iE,u5e,wvr,Avr,iK,Lvr,yvr,xvr,dE,p5e,$vr,kvr,dK,Svr,Rvr,Pvr,mE,_5e,Bvr,Ivr,mK,Nvr,qvr,jvr,cE,b5e,Dvr,Gvr,cK,Ovr,Vvr,Xvr,fE,v5e,zvr,Qvr,fK,Wvr,Uvr,Hvr,gE,F5e,Jvr,Yvr,gK,Zvr,Kvr,eFr,hE,T5e,oFr,rFr,hK,tFr,aFr,nFr,uE,M5e,sFr,lFr,uK,iFr,dFr,mFr,pE,E5e,cFr,fFr,pK,gFr,hFr,uFr,_E,C5e,pFr,_Fr,_K,bFr,vFr,FFr,bE,w5e,TFr,MFr,bK,EFr,CFr,wFr,vE,A5e,AFr,LFr,vK,yFr,xFr,$Fr,FE,L5e,kFr,SFr,FK,RFr,PFr,BFr,TE,IFr,y5e,NFr,qFr,x5e,jFr,DFr,ME,Lio,im,EE,$5e,BS,GFr,k5e,OFr,yio,Wo,IS,VFr,dm,XFr,TK,zFr,QFr,MK,WFr,UFr,HFr,NS,JFr,S5e,YFr,ZFr,KFr,Rt,qS,eTr,R5e,oTr,rTr,mm,tTr,P5e,aTr,nTr,EK,sTr,lTr,iTr,CE,dTr,co,jS,mTr,B5e,cTr,fTr,Fn,gTr,I5e,hTr,uTr,N5e,pTr,_Tr,q5e,bTr,vTr,FTr,K,wE,j5e,TTr,MTr,CK,ETr,CTr,wTr,AE,D5e,ATr,LTr,wK,yTr,xTr,$Tr,LE,G5e,kTr,STr,AK,RTr,PTr,BTr,yE,O5e,ITr,NTr,LK,qTr,jTr,DTr,xE,V5e,GTr,OTr,yK,VTr,XTr,zTr,$E,X5e,QTr,WTr,xK,UTr,HTr,JTr,kE,z5e,YTr,ZTr,$K,KTr,eMr,oMr,SE,Q5e,rMr,tMr,kK,aMr,nMr,sMr,RE,W5e,lMr,iMr,SK,dMr,mMr,cMr,PE,U5e,fMr,gMr,RK,hMr,uMr,pMr,BE,H5e,_Mr,bMr,PK,vMr,FMr,TMr,IE,J5e,MMr,EMr,BK,CMr,wMr,AMr,NE,Y5e,LMr,yMr,IK,xMr,$Mr,kMr,qE,Z5e,SMr,RMr,NK,PMr,BMr,IMr,jE,K5e,NMr,qMr,qK,jMr,DMr,GMr,DE,e0e,OMr,VMr,jK,XMr,zMr,QMr,GE,o0e,WMr,UMr,DK,HMr,JMr,YMr,OE,r0e,ZMr,KMr,GK,eEr,oEr,rEr,VE,t0e,tEr,aEr,OK,nEr,sEr,lEr,XE,a0e,iEr,dEr,VK,mEr,cEr,fEr,zE,n0e,gEr,hEr,XK,uEr,pEr,_Er,QE,s0e,bEr,vEr,zK,FEr,TEr,MEr,WE,l0e,EEr,CEr,QK,wEr,AEr,LEr,UE,i0e,yEr,xEr,WK,$Er,kEr,SEr,HE,d0e,REr,PEr,UK,BEr,IEr,NEr,JE,m0e,qEr,jEr,HK,DEr,GEr,OEr,YE,c0e,VEr,XEr,JK,zEr,QEr,WEr,ZE,f0e,UEr,HEr,YK,JEr,YEr,ZEr,KE,g0e,KEr,e4r,ZK,o4r,r4r,t4r,e4,h0e,a4r,n4r,KK,s4r,l4r,i4r,o4,u0e,d4r,m4r,eee,c4r,f4r,g4r,r4,p0e,h4r,u4r,oee,p4r,_4r,b4r,t4,_0e,v4r,F4r,ree,T4r,M4r,E4r,a4,C4r,b0e,w4r,A4r,v0e,L4r,y4r,n4,xio,cm,s4,F0e,DS,x4r,T0e,$4r,$io,Uo,GS,k4r,fm,S4r,tee,R4r,P4r,aee,B4r,I4r,N4r,OS,q4r,M0e,j4r,D4r,G4r,Pt,VS,O4r,E0e,V4r,X4r,gm,z4r,C0e,Q4r,W4r,nee,U4r,H4r,J4r,l4,Y4r,fo,XS,Z4r,w0e,K4r,eCr,Tn,oCr,A0e,rCr,tCr,L0e,aCr,nCr,y0e,sCr,lCr,iCr,Ye,i4,x0e,dCr,mCr,see,cCr,fCr,gCr,d4,$0e,hCr,uCr,lee,pCr,_Cr,bCr,m4,k0e,vCr,FCr,iee,TCr,MCr,ECr,c4,S0e,CCr,wCr,dee,ACr,LCr,yCr,f4,R0e,xCr,$Cr,mee,kCr,SCr,RCr,g4,P0e,PCr,BCr,cee,ICr,NCr,qCr,h4,B0e,jCr,DCr,fee,GCr,OCr,VCr,u4,XCr,I0e,zCr,QCr,N0e,WCr,UCr,p4,kio,hm,_4,q0e,zS,HCr,j0e,JCr,Sio,Ho,QS,YCr,um,ZCr,gee,KCr,e3r,hee,o3r,r3r,t3r,WS,a3r,D0e,n3r,s3r,l3r,Bt,US,i3r,G0e,d3r,m3r,pm,c3r,O0e,f3r,g3r,uee,h3r,u3r,p3r,b4,_3r,go,HS,b3r,V0e,v3r,F3r,Mn,T3r,X0e,M3r,E3r,z0e,C3r,w3r,Q0e,A3r,L3r,y3r,U,v4,W0e,x3r,$3r,pee,k3r,S3r,R3r,F4,U0e,P3r,B3r,_ee,I3r,N3r,q3r,T4,H0e,j3r,D3r,bee,G3r,O3r,V3r,M4,J0e,X3r,z3r,vee,Q3r,W3r,U3r,E4,Y0e,H3r,J3r,Fee,Y3r,Z3r,K3r,C4,Z0e,e5r,o5r,Tee,r5r,t5r,a5r,w4,K0e,n5r,s5r,Mee,l5r,i5r,d5r,A4,ewe,m5r,c5r,Eee,f5r,g5r,h5r,L4,owe,u5r,p5r,Cee,_5r,b5r,v5r,y4,rwe,F5r,T5r,wee,M5r,E5r,C5r,x4,twe,w5r,A5r,Aee,L5r,y5r,x5r,$4,awe,$5r,k5r,Lee,S5r,R5r,P5r,k4,nwe,B5r,I5r,yee,N5r,q5r,j5r,S4,swe,D5r,G5r,xee,O5r,V5r,X5r,R4,lwe,z5r,Q5r,$ee,W5r,U5r,H5r,P4,iwe,J5r,Y5r,kee,Z5r,K5r,e0r,B4,dwe,o0r,r0r,See,t0r,a0r,n0r,I4,mwe,s0r,l0r,Ree,i0r,d0r,m0r,N4,cwe,c0r,f0r,Pee,g0r,h0r,u0r,q4,fwe,p0r,_0r,Bee,b0r,v0r,F0r,j4,gwe,T0r,M0r,Iee,E0r,C0r,w0r,D4,hwe,A0r,L0r,Nee,y0r,x0r,$0r,G4,uwe,k0r,S0r,qee,R0r,P0r,B0r,O4,pwe,I0r,N0r,jee,q0r,j0r,D0r,V4,_we,G0r,O0r,Dee,V0r,X0r,z0r,X4,bwe,Q0r,W0r,Gee,U0r,H0r,J0r,z4,vwe,Y0r,Z0r,Oee,K0r,ewr,owr,Q4,Fwe,rwr,twr,Vee,awr,nwr,swr,W4,Twe,lwr,iwr,Xee,dwr,mwr,cwr,U4,Mwe,fwr,gwr,zee,hwr,uwr,pwr,H4,Ewe,_wr,bwr,Qee,vwr,Fwr,Twr,J4,Cwe,Mwr,Ewr,Wee,Cwr,wwr,Awr,Y4,wwe,Lwr,ywr,Uee,xwr,$wr,kwr,Z4,Awe,Swr,Rwr,Hee,Pwr,Bwr,Iwr,K4,Lwe,Nwr,qwr,Jee,jwr,Dwr,Gwr,eC,ywe,Owr,Vwr,Yee,Xwr,zwr,Qwr,oC,xwe,Wwr,Uwr,Zee,Hwr,Jwr,Ywr,rC,$we,Zwr,Kwr,Kee,eAr,oAr,rAr,tC,kwe,tAr,aAr,eoe,nAr,sAr,lAr,aC,Swe,iAr,dAr,ooe,mAr,cAr,fAr,nC,Rwe,gAr,hAr,roe,uAr,pAr,_Ar,sC,Pwe,bAr,vAr,toe,FAr,TAr,MAr,lC,EAr,Bwe,CAr,wAr,Iwe,AAr,LAr,iC,Rio,_m,dC,Nwe,JS,yAr,qwe,xAr,Pio,Jo,YS,$Ar,bm,kAr,aoe,SAr,RAr,noe,PAr,BAr,IAr,ZS,NAr,jwe,qAr,jAr,DAr,It,KS,GAr,Dwe,OAr,VAr,vm,XAr,Gwe,zAr,QAr,soe,WAr,UAr,HAr,mC,JAr,ho,eR,YAr,Owe,ZAr,KAr,En,e6r,Vwe,o6r,r6r,Xwe,t6r,a6r,zwe,n6r,s6r,l6r,O,cC,Qwe,i6r,d6r,loe,m6r,c6r,f6r,fC,Wwe,g6r,h6r,ioe,u6r,p6r,_6r,gC,Uwe,b6r,v6r,doe,F6r,T6r,M6r,hC,Hwe,E6r,C6r,moe,w6r,A6r,L6r,uC,Jwe,y6r,x6r,coe,$6r,k6r,S6r,pC,Ywe,R6r,P6r,foe,B6r,I6r,N6r,_C,Zwe,q6r,j6r,goe,D6r,G6r,O6r,bC,Kwe,V6r,X6r,hoe,z6r,Q6r,W6r,vC,eAe,U6r,H6r,uoe,J6r,Y6r,Z6r,FC,oAe,K6r,e7r,poe,o7r,r7r,t7r,TC,rAe,a7r,n7r,_oe,s7r,l7r,i7r,MC,tAe,d7r,m7r,boe,c7r,f7r,g7r,EC,aAe,h7r,u7r,voe,p7r,_7r,b7r,CC,nAe,v7r,F7r,Foe,T7r,M7r,E7r,wC,sAe,C7r,w7r,Toe,A7r,L7r,y7r,AC,lAe,x7r,$7r,Moe,k7r,S7r,R7r,LC,iAe,P7r,B7r,Eoe,I7r,N7r,q7r,yC,dAe,j7r,D7r,Coe,G7r,O7r,V7r,xC,mAe,X7r,z7r,woe,Q7r,W7r,U7r,$C,cAe,H7r,J7r,Aoe,Y7r,Z7r,K7r,kC,fAe,e8r,o8r,Loe,r8r,t8r,a8r,SC,gAe,n8r,s8r,yoe,l8r,i8r,d8r,RC,hAe,m8r,c8r,xoe,f8r,g8r,h8r,PC,uAe,u8r,p8r,$oe,_8r,b8r,v8r,BC,pAe,F8r,T8r,koe,M8r,E8r,C8r,IC,_Ae,w8r,A8r,Soe,L8r,y8r,x8r,NC,bAe,$8r,k8r,Roe,S8r,R8r,P8r,qC,vAe,B8r,I8r,Poe,N8r,q8r,j8r,jC,FAe,D8r,G8r,Boe,O8r,V8r,X8r,DC,TAe,z8r,Q8r,Ioe,W8r,U8r,H8r,GC,MAe,J8r,Y8r,Noe,Z8r,K8r,eLr,OC,EAe,oLr,rLr,qoe,tLr,aLr,nLr,VC,CAe,sLr,lLr,joe,iLr,dLr,mLr,XC,wAe,cLr,fLr,Doe,gLr,hLr,uLr,zC,AAe,pLr,_Lr,Goe,bLr,vLr,FLr,QC,LAe,TLr,MLr,Ooe,ELr,CLr,wLr,WC,yAe,ALr,LLr,Voe,yLr,xLr,$Lr,UC,xAe,kLr,SLr,Xoe,RLr,PLr,BLr,HC,$Ae,ILr,NLr,zoe,qLr,jLr,DLr,JC,kAe,GLr,OLr,Qoe,VLr,XLr,zLr,YC,SAe,QLr,WLr,Woe,ULr,HLr,JLr,ZC,RAe,YLr,ZLr,Uoe,KLr,eyr,oyr,KC,PAe,ryr,tyr,Hoe,ayr,nyr,syr,e3,BAe,lyr,iyr,Joe,dyr,myr,cyr,o3,IAe,fyr,gyr,Yoe,hyr,uyr,pyr,r3,NAe,_yr,byr,Zoe,vyr,Fyr,Tyr,t3,qAe,Myr,Eyr,Koe,Cyr,wyr,Ayr,a3,jAe,Lyr,yyr,ere,xyr,$yr,kyr,n3,DAe,Syr,Ryr,ore,Pyr,Byr,Iyr,s3,Nyr,GAe,qyr,jyr,OAe,Dyr,Gyr,l3,Bio,Fm,i3,VAe,oR,Oyr,XAe,Vyr,Iio,Yo,rR,Xyr,Tm,zyr,rre,Qyr,Wyr,tre,Uyr,Hyr,Jyr,tR,Yyr,zAe,Zyr,Kyr,e9r,Nt,aR,o9r,QAe,r9r,t9r,Mm,a9r,WAe,n9r,s9r,are,l9r,i9r,d9r,d3,m9r,uo,nR,c9r,UAe,f9r,g9r,Cn,h9r,HAe,u9r,p9r,JAe,_9r,b9r,YAe,v9r,F9r,T9r,ZAe,m3,KAe,M9r,E9r,nre,C9r,w9r,A9r,c3,L9r,e6e,y9r,x9r,o6e,$9r,k9r,f3,Nio,Em,g3,r6e,sR,S9r,t6e,R9r,qio,Zo,lR,P9r,Cm,B9r,sre,I9r,N9r,lre,q9r,j9r,D9r,iR,G9r,a6e,O9r,V9r,X9r,qt,dR,z9r,n6e,Q9r,W9r,wm,U9r,s6e,H9r,J9r,ire,Y9r,Z9r,K9r,h3,exr,po,mR,oxr,l6e,rxr,txr,wn,axr,i6e,nxr,sxr,d6e,lxr,ixr,m6e,dxr,mxr,cxr,Am,u3,c6e,fxr,gxr,dre,hxr,uxr,pxr,p3,f6e,_xr,bxr,mre,vxr,Fxr,Txr,_3,g6e,Mxr,Exr,cre,Cxr,wxr,Axr,b3,Lxr,h6e,yxr,xxr,u6e,$xr,kxr,v3,jio,Lm,F3,p6e,cR,Sxr,_6e,Rxr,Dio,Ko,fR,Pxr,ym,Bxr,fre,Ixr,Nxr,gre,qxr,jxr,Dxr,gR,Gxr,b6e,Oxr,Vxr,Xxr,jt,hR,zxr,v6e,Qxr,Wxr,xm,Uxr,F6e,Hxr,Jxr,hre,Yxr,Zxr,Kxr,T3,e$r,_o,uR,o$r,T6e,r$r,t$r,An,a$r,M6e,n$r,s$r,E6e,l$r,i$r,C6e,d$r,m$r,c$r,ve,M3,w6e,f$r,g$r,ure,h$r,u$r,p$r,E3,A6e,_$r,b$r,pre,v$r,F$r,T$r,C3,L6e,M$r,E$r,_re,C$r,w$r,A$r,w3,y6e,L$r,y$r,bre,x$r,$$r,k$r,ql,x6e,S$r,R$r,vre,P$r,B$r,Fre,I$r,N$r,q$r,A3,$6e,j$r,D$r,Tre,G$r,O$r,V$r,jl,k6e,X$r,z$r,Mre,Q$r,W$r,Ere,U$r,H$r,J$r,L3,S6e,Y$r,Z$r,Cre,K$r,ekr,okr,y3,R6e,rkr,tkr,wre,akr,nkr,skr,Dt,P6e,lkr,ikr,Are,dkr,mkr,Lre,ckr,fkr,yre,gkr,hkr,ukr,x3,B6e,pkr,_kr,xre,bkr,vkr,Fkr,$3,I6e,Tkr,Mkr,$re,Ekr,Ckr,wkr,k3,N6e,Akr,Lkr,kre,ykr,xkr,$kr,S3,q6e,kkr,Skr,Sre,Rkr,Pkr,Bkr,R3,j6e,Ikr,Nkr,Rre,qkr,jkr,Dkr,P3,D6e,Gkr,Okr,Pre,Vkr,Xkr,zkr,B3,G6e,Qkr,Wkr,Bre,Ukr,Hkr,Jkr,I3,O6e,Ykr,Zkr,Ire,Kkr,eSr,oSr,N3,V6e,rSr,tSr,Nre,aSr,nSr,sSr,q3,lSr,X6e,iSr,dSr,z6e,mSr,cSr,j3,Gio,$m,D3,Q6e,pR,fSr,W6e,gSr,Oio,er,_R,hSr,km,uSr,qre,pSr,_Sr,jre,bSr,vSr,FSr,bR,TSr,U6e,MSr,ESr,CSr,Gt,vR,wSr,H6e,ASr,LSr,Sm,ySr,J6e,xSr,$Sr,Dre,kSr,SSr,RSr,G3,PSr,bo,FR,BSr,Y6e,ISr,NSr,Ln,qSr,Z6e,jSr,DSr,K6e,GSr,OSr,e7e,VSr,XSr,zSr,o7e,O3,r7e,QSr,WSr,Gre,USr,HSr,JSr,V3,YSr,t7e,ZSr,KSr,a7e,eRr,oRr,X3,Vio,Rm,z3,n7e,TR,rRr,s7e,tRr,Xio,or,MR,aRr,Pm,nRr,Ore,sRr,lRr,Vre,iRr,dRr,mRr,ER,cRr,l7e,fRr,gRr,hRr,Ot,CR,uRr,i7e,pRr,_Rr,Bm,bRr,d7e,vRr,FRr,Xre,TRr,MRr,ERr,Q3,CRr,vo,wR,wRr,m7e,ARr,LRr,yn,yRr,c7e,xRr,$Rr,f7e,kRr,SRr,g7e,RRr,PRr,BRr,h7e,W3,u7e,IRr,NRr,zre,qRr,jRr,DRr,U3,GRr,p7e,ORr,VRr,_7e,XRr,zRr,H3,zio,Im,J3,b7e,AR,QRr,v7e,WRr,Qio,rr,LR,URr,Nm,HRr,Qre,JRr,YRr,Wre,ZRr,KRr,ePr,yR,oPr,F7e,rPr,tPr,aPr,Vt,xR,nPr,T7e,sPr,lPr,qm,iPr,M7e,dPr,mPr,Ure,cPr,fPr,gPr,Y3,hPr,Fo,$R,uPr,E7e,pPr,_Pr,xn,bPr,C7e,vPr,FPr,w7e,TPr,MPr,A7e,EPr,CPr,wPr,L7e,Z3,y7e,APr,LPr,Hre,yPr,xPr,$Pr,K3,kPr,x7e,SPr,RPr,$7e,PPr,BPr,e5,Wio,jm,o5,k7e,kR,IPr,S7e,NPr,Uio,tr,SR,qPr,Dm,jPr,Jre,DPr,GPr,Yre,OPr,VPr,XPr,RR,zPr,R7e,QPr,WPr,UPr,Xt,PR,HPr,P7e,JPr,YPr,Gm,ZPr,B7e,KPr,eBr,Zre,oBr,rBr,tBr,r5,aBr,To,BR,nBr,I7e,sBr,lBr,$n,iBr,N7e,dBr,mBr,q7e,cBr,fBr,j7e,gBr,hBr,uBr,Ne,t5,D7e,pBr,_Br,Kre,bBr,vBr,FBr,a5,G7e,TBr,MBr,ete,EBr,CBr,wBr,n5,O7e,ABr,LBr,ote,yBr,xBr,$Br,s5,V7e,kBr,SBr,rte,RBr,PBr,BBr,l5,X7e,IBr,NBr,tte,qBr,jBr,DBr,i5,z7e,GBr,OBr,ate,VBr,XBr,zBr,d5,Q7e,QBr,WBr,nte,UBr,HBr,JBr,m5,W7e,YBr,ZBr,ste,KBr,eIr,oIr,c5,U7e,rIr,tIr,lte,aIr,nIr,sIr,f5,lIr,H7e,iIr,dIr,J7e,mIr,cIr,g5,Hio,Om,h5,Y7e,IR,fIr,Z7e,gIr,Jio,ar,NR,hIr,Vm,uIr,ite,pIr,_Ir,dte,bIr,vIr,FIr,qR,TIr,K7e,MIr,EIr,CIr,zt,jR,wIr,e8e,AIr,LIr,Xm,yIr,o8e,xIr,$Ir,mte,kIr,SIr,RIr,u5,PIr,Mo,DR,BIr,r8e,IIr,NIr,kn,qIr,t8e,jIr,DIr,a8e,GIr,OIr,n8e,VIr,XIr,zIr,Ft,p5,s8e,QIr,WIr,cte,UIr,HIr,JIr,_5,l8e,YIr,ZIr,fte,KIr,eNr,oNr,b5,i8e,rNr,tNr,gte,aNr,nNr,sNr,v5,d8e,lNr,iNr,hte,dNr,mNr,cNr,F5,m8e,fNr,gNr,ute,hNr,uNr,pNr,T5,_Nr,c8e,bNr,vNr,f8e,FNr,TNr,M5,Yio,zm,E5,g8e,GR,MNr,h8e,ENr,Zio,nr,OR,CNr,Qm,wNr,pte,ANr,LNr,_te,yNr,xNr,$Nr,VR,kNr,u8e,SNr,RNr,PNr,Qt,XR,BNr,p8e,INr,NNr,Wm,qNr,_8e,jNr,DNr,bte,GNr,ONr,VNr,C5,XNr,Eo,zR,zNr,b8e,QNr,WNr,Sn,UNr,v8e,HNr,JNr,F8e,YNr,ZNr,T8e,KNr,eqr,oqr,xe,w5,M8e,rqr,tqr,vte,aqr,nqr,sqr,A5,E8e,lqr,iqr,Fte,dqr,mqr,cqr,L5,C8e,fqr,gqr,Tte,hqr,uqr,pqr,y5,w8e,_qr,bqr,Mte,vqr,Fqr,Tqr,x5,A8e,Mqr,Eqr,Ete,Cqr,wqr,Aqr,$5,L8e,Lqr,yqr,Cte,xqr,$qr,kqr,k5,y8e,Sqr,Rqr,wte,Pqr,Bqr,Iqr,S5,x8e,Nqr,qqr,Ate,jqr,Dqr,Gqr,R5,$8e,Oqr,Vqr,Lte,Xqr,zqr,Qqr,P5,k8e,Wqr,Uqr,yte,Hqr,Jqr,Yqr,B5,Zqr,S8e,Kqr,ejr,R8e,ojr,rjr,I5,Kio,Um,N5,P8e,QR,tjr,B8e,ajr,edo,sr,WR,njr,Hm,sjr,xte,ljr,ijr,$te,djr,mjr,cjr,UR,fjr,I8e,gjr,hjr,ujr,Wt,HR,pjr,N8e,_jr,bjr,Jm,vjr,q8e,Fjr,Tjr,kte,Mjr,Ejr,Cjr,q5,wjr,Co,JR,Ajr,j8e,Ljr,yjr,Rn,xjr,D8e,$jr,kjr,G8e,Sjr,Rjr,O8e,Pjr,Bjr,Ijr,Ym,j5,V8e,Njr,qjr,Ste,jjr,Djr,Gjr,D5,X8e,Ojr,Vjr,Rte,Xjr,zjr,Qjr,G5,z8e,Wjr,Ujr,Pte,Hjr,Jjr,Yjr,O5,Zjr,Q8e,Kjr,eDr,W8e,oDr,rDr,V5,odo,Zm,X5,U8e,YR,tDr,H8e,aDr,rdo,lr,ZR,nDr,Km,sDr,Bte,lDr,iDr,Ite,dDr,mDr,cDr,KR,fDr,J8e,gDr,hDr,uDr,Ut,eP,pDr,Y8e,_Dr,bDr,ec,vDr,Z8e,FDr,TDr,Nte,MDr,EDr,CDr,z5,wDr,wo,oP,ADr,K8e,LDr,yDr,Pn,xDr,eLe,$Dr,kDr,oLe,SDr,RDr,rLe,PDr,BDr,IDr,Tt,Q5,tLe,NDr,qDr,qte,jDr,DDr,GDr,W5,aLe,ODr,VDr,jte,XDr,zDr,QDr,U5,nLe,WDr,UDr,Dte,HDr,JDr,YDr,H5,sLe,ZDr,KDr,Gte,eGr,oGr,rGr,J5,lLe,tGr,aGr,Ote,nGr,sGr,lGr,Y5,iGr,iLe,dGr,mGr,dLe,cGr,fGr,Z5,tdo,oc,K5,mLe,rP,gGr,cLe,hGr,ado,ir,tP,uGr,rc,pGr,Vte,_Gr,bGr,Xte,vGr,FGr,TGr,aP,MGr,fLe,EGr,CGr,wGr,Ht,nP,AGr,gLe,LGr,yGr,tc,xGr,hLe,$Gr,kGr,zte,SGr,RGr,PGr,e0,BGr,Ao,sP,IGr,uLe,NGr,qGr,Bn,jGr,pLe,DGr,GGr,_Le,OGr,VGr,bLe,XGr,zGr,QGr,In,o0,vLe,WGr,UGr,Qte,HGr,JGr,YGr,r0,FLe,ZGr,KGr,Wte,eOr,oOr,rOr,t0,TLe,tOr,aOr,Ute,nOr,sOr,lOr,a0,MLe,iOr,dOr,Hte,mOr,cOr,fOr,n0,gOr,ELe,hOr,uOr,CLe,pOr,_Or,s0,ndo,ac,l0,wLe,lP,bOr,ALe,vOr,sdo,dr,iP,FOr,nc,TOr,Jte,MOr,EOr,Yte,COr,wOr,AOr,dP,LOr,LLe,yOr,xOr,$Or,Jt,mP,kOr,yLe,SOr,ROr,sc,POr,xLe,BOr,IOr,Zte,NOr,qOr,jOr,i0,DOr,Lo,cP,GOr,$Le,OOr,VOr,Nn,XOr,kLe,zOr,QOr,SLe,WOr,UOr,RLe,HOr,JOr,YOr,Mt,d0,PLe,ZOr,KOr,Kte,eVr,oVr,rVr,m0,BLe,tVr,aVr,eae,nVr,sVr,lVr,c0,ILe,iVr,dVr,oae,mVr,cVr,fVr,f0,NLe,gVr,hVr,rae,uVr,pVr,_Vr,g0,qLe,bVr,vVr,tae,FVr,TVr,MVr,h0,EVr,jLe,CVr,wVr,DLe,AVr,LVr,u0,ldo,lc,p0,GLe,fP,yVr,OLe,xVr,ido,mr,gP,$Vr,ic,kVr,aae,SVr,RVr,nae,PVr,BVr,IVr,hP,NVr,VLe,qVr,jVr,DVr,Yt,uP,GVr,XLe,OVr,VVr,dc,XVr,zLe,zVr,QVr,sae,WVr,UVr,HVr,_0,JVr,yo,pP,YVr,QLe,ZVr,KVr,qn,eXr,WLe,oXr,rXr,ULe,tXr,aXr,HLe,nXr,sXr,lXr,JLe,b0,YLe,iXr,dXr,lae,mXr,cXr,fXr,v0,gXr,ZLe,hXr,uXr,KLe,pXr,_Xr,F0,ddo,mc,T0,eye,_P,bXr,oye,vXr,mdo,cr,bP,FXr,cc,TXr,iae,MXr,EXr,dae,CXr,wXr,AXr,vP,LXr,rye,yXr,xXr,$Xr,Zt,FP,kXr,tye,SXr,RXr,fc,PXr,aye,BXr,IXr,mae,NXr,qXr,jXr,M0,DXr,xo,TP,GXr,nye,OXr,VXr,jn,XXr,sye,zXr,QXr,lye,WXr,UXr,iye,HXr,JXr,YXr,fr,E0,dye,ZXr,KXr,cae,ezr,ozr,rzr,C0,mye,tzr,azr,fae,nzr,szr,lzr,w0,cye,izr,dzr,gae,mzr,czr,fzr,A0,fye,gzr,hzr,hae,uzr,pzr,_zr,L0,gye,bzr,vzr,uae,Fzr,Tzr,Mzr,y0,hye,Ezr,Czr,pae,wzr,Azr,Lzr,x0,yzr,uye,xzr,$zr,pye,kzr,Szr,$0,cdo,gc,k0,_ye,MP,Rzr,bye,Pzr,fdo,gr,EP,Bzr,hc,Izr,_ae,Nzr,qzr,bae,jzr,Dzr,Gzr,CP,Ozr,vye,Vzr,Xzr,zzr,Kt,wP,Qzr,Fye,Wzr,Uzr,uc,Hzr,Tye,Jzr,Yzr,vae,Zzr,Kzr,eQr,S0,oQr,$o,AP,rQr,Mye,tQr,aQr,Dn,nQr,Eye,sQr,lQr,Cye,iQr,dQr,wye,mQr,cQr,fQr,Aye,R0,Lye,gQr,hQr,Fae,uQr,pQr,_Qr,P0,bQr,yye,vQr,FQr,xye,TQr,MQr,B0,gdo,pc,I0,$ye,LP,EQr,kye,CQr,hdo,hr,yP,wQr,_c,AQr,Tae,LQr,yQr,Mae,xQr,$Qr,kQr,xP,SQr,Sye,RQr,PQr,BQr,ea,$P,IQr,Rye,NQr,qQr,bc,jQr,Pye,DQr,GQr,Eae,OQr,VQr,XQr,N0,zQr,ko,kP,QQr,Bye,WQr,UQr,Gn,HQr,Iye,JQr,YQr,Nye,ZQr,KQr,qye,eWr,oWr,rWr,jye,q0,Dye,tWr,aWr,Cae,nWr,sWr,lWr,j0,iWr,Gye,dWr,mWr,Oye,cWr,fWr,D0,udo,vc,G0,Vye,SP,gWr,Xye,hWr,pdo,ur,RP,uWr,Fc,pWr,wae,_Wr,bWr,Aae,vWr,FWr,TWr,PP,MWr,zye,EWr,CWr,wWr,oa,BP,AWr,Qye,LWr,yWr,Tc,xWr,Wye,$Wr,kWr,Lae,SWr,RWr,PWr,O0,BWr,zr,IP,IWr,Uye,NWr,qWr,On,jWr,Hye,DWr,GWr,Jye,OWr,VWr,Yye,XWr,zWr,QWr,P,V0,Zye,WWr,UWr,yae,HWr,JWr,YWr,X0,Kye,ZWr,KWr,xae,eUr,oUr,rUr,z0,e9e,tUr,aUr,$ae,nUr,sUr,lUr,Q0,o9e,iUr,dUr,kae,mUr,cUr,fUr,W0,r9e,gUr,hUr,Sae,uUr,pUr,_Ur,U0,t9e,bUr,vUr,Rae,FUr,TUr,MUr,H0,a9e,EUr,CUr,Pae,wUr,AUr,LUr,J0,n9e,yUr,xUr,Bae,$Ur,kUr,SUr,Y0,s9e,RUr,PUr,Iae,BUr,IUr,NUr,Z0,l9e,qUr,jUr,Nae,DUr,GUr,OUr,K0,i9e,VUr,XUr,qae,zUr,QUr,WUr,ew,d9e,UUr,HUr,jae,JUr,YUr,ZUr,ow,m9e,KUr,eHr,Dae,oHr,rHr,tHr,rw,c9e,aHr,nHr,Gae,sHr,lHr,iHr,tw,f9e,dHr,mHr,Oae,cHr,fHr,gHr,aw,g9e,hHr,uHr,Vae,pHr,_Hr,bHr,nw,h9e,vHr,FHr,Xae,THr,MHr,EHr,sw,u9e,CHr,wHr,zae,AHr,LHr,yHr,lw,p9e,xHr,$Hr,Qae,kHr,SHr,RHr,iw,_9e,PHr,BHr,Wae,IHr,NHr,qHr,Dl,b9e,jHr,DHr,Uae,GHr,OHr,Hae,VHr,XHr,zHr,dw,v9e,QHr,WHr,Jae,UHr,HHr,JHr,mw,F9e,YHr,ZHr,Yae,KHr,eJr,oJr,cw,T9e,rJr,tJr,Zae,aJr,nJr,sJr,fw,M9e,lJr,iJr,Kae,dJr,mJr,cJr,gw,E9e,fJr,gJr,ene,hJr,uJr,pJr,hw,C9e,_Jr,bJr,one,vJr,FJr,TJr,uw,w9e,MJr,EJr,rne,CJr,wJr,AJr,pw,A9e,LJr,yJr,tne,xJr,$Jr,kJr,_w,L9e,SJr,RJr,ane,PJr,BJr,IJr,bw,y9e,NJr,qJr,nne,jJr,DJr,GJr,vw,x9e,OJr,VJr,sne,XJr,zJr,QJr,Fw,$9e,WJr,UJr,lne,HJr,JJr,YJr,Tw,k9e,ZJr,KJr,ine,eYr,oYr,rYr,Mw,S9e,tYr,aYr,dne,nYr,sYr,lYr,Ew,R9e,iYr,dYr,mne,mYr,cYr,fYr,Cw,P9e,gYr,hYr,cne,uYr,pYr,_Yr,ww,B9e,bYr,vYr,fne,FYr,TYr,MYr,Aw,I9e,EYr,CYr,gne,wYr,AYr,LYr,Lw,N9e,yYr,xYr,hne,$Yr,kYr,SYr,yw,q9e,RYr,PYr,une,BYr,IYr,NYr,xw,j9e,qYr,jYr,pne,DYr,GYr,OYr,$w,D9e,VYr,XYr,_ne,zYr,QYr,WYr,kw,G9e,UYr,HYr,bne,JYr,YYr,ZYr,Sw,O9e,KYr,eZr,vne,oZr,rZr,tZr,Rw,V9e,aZr,nZr,Fne,sZr,lZr,iZr,Pw,X9e,dZr,mZr,Tne,cZr,fZr,gZr,Bw,z9e,hZr,uZr,Mne,pZr,_Zr,bZr,Iw,Q9e,vZr,FZr,Ene,TZr,MZr,EZr,Nw,W9e,CZr,wZr,Cne,AZr,LZr,yZr,qw,U9e,xZr,$Zr,wne,kZr,SZr,RZr,jw,H9e,PZr,BZr,Ane,IZr,NZr,qZr,Dw,J9e,jZr,DZr,Lne,GZr,OZr,VZr,Gw,Y9e,XZr,zZr,yne,QZr,WZr,UZr,Ow,Z9e,HZr,JZr,xne,YZr,ZZr,KZr,Vw,K9e,eKr,oKr,$ne,rKr,tKr,aKr,Xw,exe,nKr,sKr,kne,lKr,iKr,dKr,zw,oxe,mKr,cKr,Sne,fKr,gKr,hKr,Qw,_do,Mc,Ww,rxe,NP,uKr,txe,pKr,bdo,pr,qP,_Kr,Ec,bKr,Rne,vKr,FKr,Pne,TKr,MKr,EKr,jP,CKr,axe,wKr,AKr,LKr,ra,DP,yKr,nxe,xKr,$Kr,Cc,kKr,sxe,SKr,RKr,Bne,PKr,BKr,IKr,Uw,NKr,Qr,GP,qKr,lxe,jKr,DKr,Vn,GKr,ixe,OKr,VKr,dxe,XKr,zKr,mxe,QKr,WKr,UKr,de,Hw,cxe,HKr,JKr,Ine,YKr,ZKr,KKr,Jw,fxe,eet,oet,Nne,ret,tet,aet,Yw,gxe,net,set,qne,iet,det,met,Zw,hxe,cet,fet,jne,get,het,uet,Kw,uxe,pet,_et,Dne,bet,vet,Fet,eA,pxe,Tet,Met,Gne,Eet,Cet,wet,oA,_xe,Aet,Let,One,yet,xet,$et,rA,bxe,ket,Set,Vne,Ret,Pet,Bet,tA,vxe,Iet,Net,Xne,qet,jet,Det,aA,Fxe,Get,Oet,zne,Vet,Xet,zet,nA,Txe,Qet,Wet,Qne,Uet,Het,Jet,sA,Mxe,Yet,Zet,Wne,Ket,eot,oot,lA,Exe,rot,tot,Une,aot,not,sot,iA,Cxe,lot,iot,Hne,dot,mot,cot,dA,wxe,fot,got,Jne,hot,uot,pot,mA,Axe,_ot,bot,Yne,vot,Fot,Tot,cA,Lxe,Mot,Eot,Zne,Cot,wot,Aot,fA,yxe,Lot,yot,Kne,xot,$ot,kot,gA,xxe,Sot,Rot,ese,Pot,Bot,Iot,hA,$xe,Not,qot,ose,jot,Dot,Got,uA,kxe,Oot,Vot,rse,Xot,zot,Qot,pA,Sxe,Wot,Uot,tse,Hot,Jot,Yot,_A,Rxe,Zot,Kot,ase,ert,ort,rrt,bA,vdo,wc,vA,Pxe,OP,trt,Bxe,art,Fdo,_r,VP,nrt,Ac,srt,nse,lrt,irt,sse,drt,mrt,crt,XP,frt,Ixe,grt,hrt,urt,ta,zP,prt,Nxe,_rt,brt,Lc,vrt,qxe,Frt,Trt,lse,Mrt,Ert,Crt,FA,wrt,Wr,QP,Art,jxe,Lrt,yrt,Xn,xrt,Dxe,$rt,krt,Gxe,Srt,Rrt,Oxe,Prt,Brt,Irt,Ce,TA,Vxe,Nrt,qrt,ise,jrt,Drt,Grt,MA,Xxe,Ort,Vrt,dse,Xrt,zrt,Qrt,EA,zxe,Wrt,Urt,mse,Hrt,Jrt,Yrt,CA,Qxe,Zrt,Krt,cse,ett,ott,rtt,wA,Wxe,ttt,att,fse,ntt,stt,ltt,AA,Uxe,itt,dtt,gse,mtt,ctt,ftt,LA,Hxe,gtt,htt,hse,utt,ptt,_tt,yA,Jxe,btt,vtt,use,Ftt,Ttt,Mtt,xA,Yxe,Ett,Ctt,pse,wtt,Att,Ltt,$A,Zxe,ytt,xtt,_se,$tt,ktt,Stt,kA,Kxe,Rtt,Ptt,bse,Btt,Itt,Ntt,SA,e$e,qtt,jtt,vse,Dtt,Gtt,Ott,RA,o$e,Vtt,Xtt,Fse,ztt,Qtt,Wtt,PA,r$e,Utt,Htt,Tse,Jtt,Ytt,Ztt,BA,Tdo,yc,IA,t$e,WP,Ktt,a$e,eat,Mdo,br,UP,oat,xc,rat,Mse,tat,aat,Ese,nat,sat,lat,HP,iat,n$e,dat,mat,cat,aa,JP,fat,s$e,gat,hat,$c,uat,l$e,pat,_at,Cse,bat,vat,Fat,NA,Tat,Ur,YP,Mat,i$e,Eat,Cat,zn,wat,d$e,Aat,Lat,m$e,yat,xat,c$e,$at,kat,Sat,$e,qA,f$e,Rat,Pat,wse,Bat,Iat,Nat,jA,g$e,qat,jat,Ase,Dat,Gat,Oat,DA,h$e,Vat,Xat,Lse,zat,Qat,Wat,Gl,u$e,Uat,Hat,yse,Jat,Yat,xse,Zat,Kat,ent,GA,p$e,ont,rnt,$se,tnt,ant,nnt,OA,_$e,snt,lnt,kse,int,dnt,mnt,VA,b$e,cnt,fnt,Sse,gnt,hnt,unt,XA,v$e,pnt,_nt,Rse,bnt,vnt,Fnt,zA,F$e,Tnt,Mnt,Pse,Ent,Cnt,wnt,QA,T$e,Ant,Lnt,Bse,ynt,xnt,$nt,WA,Edo,kc,UA,M$e,ZP,knt,E$e,Snt,Cdo,vr,KP,Rnt,Sc,Pnt,Ise,Bnt,Int,Nse,Nnt,qnt,jnt,eB,Dnt,C$e,Gnt,Ont,Vnt,na,oB,Xnt,w$e,znt,Qnt,Rc,Wnt,A$e,Unt,Hnt,qse,Jnt,Ynt,Znt,HA,Knt,Hr,rB,est,L$e,ost,rst,Qn,tst,y$e,ast,nst,x$e,sst,lst,$$e,ist,dst,mst,Pc,JA,k$e,cst,fst,jse,gst,hst,ust,YA,S$e,pst,_st,Dse,bst,vst,Fst,ZA,R$e,Tst,Mst,Gse,Est,Cst,wst,KA,wdo,Bc,e6,P$e,tB,Ast,B$e,Lst,Ado,Fr,aB,yst,Ic,xst,Ose,$st,kst,Vse,Sst,Rst,Pst,nB,Bst,I$e,Ist,Nst,qst,sa,sB,jst,N$e,Dst,Gst,Nc,Ost,q$e,Vst,Xst,Xse,zst,Qst,Wst,o6,Ust,Jr,lB,Hst,j$e,Jst,Yst,Wn,Zst,D$e,Kst,elt,G$e,olt,rlt,O$e,tlt,alt,nlt,ge,r6,V$e,slt,llt,zse,ilt,dlt,mlt,t6,X$e,clt,flt,Qse,glt,hlt,ult,a6,z$e,plt,_lt,Wse,blt,vlt,Flt,n6,Q$e,Tlt,Mlt,Use,Elt,Clt,wlt,s6,W$e,Alt,Llt,Hse,ylt,xlt,$lt,l6,U$e,klt,Slt,Jse,Rlt,Plt,Blt,i6,H$e,Ilt,Nlt,Yse,qlt,jlt,Dlt,d6,J$e,Glt,Olt,Zse,Vlt,Xlt,zlt,m6,Y$e,Qlt,Wlt,Kse,Ult,Hlt,Jlt,c6,Z$e,Ylt,Zlt,ele,Klt,eit,oit,f6,K$e,rit,tit,ole,ait,nit,sit,g6,eke,lit,iit,rle,dit,mit,cit,h6,oke,fit,git,tle,hit,uit,pit,u6,rke,_it,bit,ale,vit,Fit,Tit,p6,tke,Mit,Eit,nle,Cit,wit,Ait,_6,ake,Lit,yit,sle,xit,$it,kit,b6,nke,Sit,Rit,lle,Pit,Bit,Iit,v6,ske,Nit,qit,ile,jit,Dit,Git,F6,lke,Oit,Vit,dle,Xit,zit,Qit,T6,ike,Wit,Uit,mle,Hit,Jit,Yit,M6,dke,Zit,Kit,cle,edt,odt,rdt,E6,Ldo,qc,C6,mke,iB,tdt,cke,adt,ydo,Tr,dB,ndt,jc,sdt,fle,ldt,idt,gle,ddt,mdt,cdt,mB,fdt,fke,gdt,hdt,udt,la,cB,pdt,gke,_dt,bdt,Dc,vdt,hke,Fdt,Tdt,hle,Mdt,Edt,Cdt,w6,wdt,Yr,fB,Adt,uke,Ldt,ydt,Un,xdt,pke,$dt,kdt,_ke,Sdt,Rdt,bke,Pdt,Bdt,Idt,ke,A6,vke,Ndt,qdt,ule,jdt,Ddt,Gdt,L6,Fke,Odt,Vdt,ple,Xdt,zdt,Qdt,y6,Tke,Wdt,Udt,_le,Hdt,Jdt,Ydt,x6,Mke,Zdt,Kdt,ble,emt,omt,rmt,$6,Eke,tmt,amt,vle,nmt,smt,lmt,k6,Cke,imt,dmt,Fle,mmt,cmt,fmt,S6,wke,gmt,hmt,Tle,umt,pmt,_mt,R6,Ake,bmt,vmt,Mle,Fmt,Tmt,Mmt,P6,Lke,Emt,Cmt,Ele,wmt,Amt,Lmt,B6,yke,ymt,xmt,Cle,$mt,kmt,Smt,I6,xdo,Gc,N6,xke,gB,Rmt,$ke,Pmt,$do,Mr,hB,Bmt,Oc,Imt,wle,Nmt,qmt,Ale,jmt,Dmt,Gmt,uB,Omt,kke,Vmt,Xmt,zmt,ia,pB,Qmt,Ske,Wmt,Umt,Vc,Hmt,Rke,Jmt,Ymt,Lle,Zmt,Kmt,ect,q6,oct,Zr,_B,rct,Pke,tct,act,Hn,nct,Bke,sct,lct,Ike,ict,dct,Nke,mct,cct,fct,ae,j6,qke,gct,hct,yle,uct,pct,_ct,D6,jke,bct,vct,xle,Fct,Tct,Mct,G6,Dke,Ect,Cct,$le,wct,Act,Lct,O6,Gke,yct,xct,kle,$ct,kct,Sct,V6,Oke,Rct,Pct,Sle,Bct,Ict,Nct,X6,Vke,qct,jct,Rle,Dct,Gct,Oct,z6,Xke,Vct,Xct,Ple,zct,Qct,Wct,Q6,zke,Uct,Hct,Ble,Jct,Yct,Zct,W6,Qke,Kct,eft,Ile,oft,rft,tft,U6,Wke,aft,nft,Nle,sft,lft,ift,H6,Uke,dft,mft,qle,cft,fft,gft,J6,Hke,hft,uft,jle,pft,_ft,bft,Y6,Jke,vft,Fft,Dle,Tft,Mft,Eft,Z6,Yke,Cft,wft,Gle,Aft,Lft,yft,K6,Zke,xft,$ft,Ole,kft,Sft,Rft,e7,Kke,Pft,Bft,Vle,Ift,Nft,qft,o7,eSe,jft,Dft,Xle,Gft,Oft,Vft,r7,oSe,Xft,zft,zle,Qft,Wft,Uft,t7,rSe,Hft,Jft,Qle,Yft,Zft,Kft,a7,tSe,egt,ogt,Wle,rgt,tgt,agt,n7,aSe,ngt,sgt,Ule,lgt,igt,dgt,s7,nSe,mgt,cgt,Hle,fgt,ggt,hgt,l7,sSe,ugt,pgt,Jle,_gt,bgt,vgt,i7,lSe,Fgt,Tgt,Yle,Mgt,Egt,Cgt,d7,iSe,wgt,Agt,Zle,Lgt,ygt,xgt,m7,dSe,$gt,kgt,Kle,Sgt,Rgt,Pgt,c7,mSe,Bgt,Igt,eie,Ngt,qgt,jgt,f7,cSe,Dgt,Ggt,oie,Ogt,Vgt,Xgt,g7,kdo,Xc,h7,fSe,bB,zgt,gSe,Qgt,Sdo,Er,vB,Wgt,zc,Ugt,rie,Hgt,Jgt,tie,Ygt,Zgt,Kgt,FB,eht,hSe,oht,rht,tht,da,TB,aht,uSe,nht,sht,Qc,lht,pSe,iht,dht,aie,mht,cht,fht,u7,ght,Kr,MB,hht,_Se,uht,pht,Jn,_ht,bSe,bht,vht,vSe,Fht,Tht,FSe,Mht,Eht,Cht,Me,p7,TSe,wht,Aht,nie,Lht,yht,xht,_7,MSe,$ht,kht,sie,Sht,Rht,Pht,b7,ESe,Bht,Iht,lie,Nht,qht,jht,v7,CSe,Dht,Ght,iie,Oht,Vht,Xht,F7,wSe,zht,Qht,die,Wht,Uht,Hht,T7,ASe,Jht,Yht,mie,Zht,Kht,eut,M7,LSe,out,rut,cie,tut,aut,nut,E7,ySe,sut,lut,fie,iut,dut,mut,C7,xSe,cut,fut,gie,gut,hut,uut,w7,$Se,put,_ut,hie,but,vut,Fut,A7,kSe,Tut,Mut,uie,Eut,Cut,wut,L7,SSe,Aut,Lut,pie,yut,xut,$ut,y7,RSe,kut,Sut,_ie,Rut,Put,But,x7,PSe,Iut,Nut,bie,qut,jut,Dut,$7,BSe,Gut,Out,vie,Vut,Xut,zut,k7,ISe,Qut,Wut,Fie,Uut,Hut,Jut,S7,NSe,Yut,Zut,Tie,Kut,ept,opt,R7,Rdo,Wc,P7,qSe,EB,rpt,jSe,tpt,Pdo,Cr,CB,apt,Uc,npt,Mie,spt,lpt,Eie,ipt,dpt,mpt,wB,cpt,DSe,fpt,gpt,hpt,ma,AB,upt,GSe,ppt,_pt,Hc,bpt,OSe,vpt,Fpt,Cie,Tpt,Mpt,Ept,B7,Cpt,et,LB,wpt,VSe,Apt,Lpt,Yn,ypt,XSe,xpt,$pt,zSe,kpt,Spt,QSe,Rpt,Ppt,Bpt,yB,I7,WSe,Ipt,Npt,wie,qpt,jpt,Dpt,N7,USe,Gpt,Opt,Aie,Vpt,Xpt,zpt,q7,Bdo,Jc,j7,HSe,xB,Qpt,JSe,Wpt,Ido,wr,$B,Upt,Yc,Hpt,Lie,Jpt,Ypt,yie,Zpt,Kpt,e_t,kB,o_t,YSe,r_t,t_t,a_t,ca,SB,n_t,ZSe,s_t,l_t,Zc,i_t,KSe,d_t,m_t,xie,c_t,f_t,g_t,D7,h_t,ot,RB,u_t,eRe,p_t,__t,Zn,b_t,oRe,v_t,F_t,rRe,T_t,M_t,tRe,E_t,C_t,w_t,aRe,G7,nRe,A_t,L_t,$ie,y_t,x_t,$_t,O7,Ndo,Kc,V7,sRe,PB,k_t,lRe,S_t,qdo,Ar,BB,R_t,ef,P_t,kie,B_t,I_t,Sie,N_t,q_t,j_t,IB,D_t,iRe,G_t,O_t,V_t,fa,NB,X_t,dRe,z_t,Q_t,of,W_t,mRe,U_t,H_t,Rie,J_t,Y_t,Z_t,X7,K_t,rt,qB,e1t,cRe,o1t,r1t,Kn,t1t,fRe,a1t,n1t,gRe,s1t,l1t,hRe,i1t,d1t,m1t,uRe,z7,pRe,c1t,f1t,Pie,g1t,h1t,u1t,Q7,jdo,rf,W7,_Re,jB,p1t,bRe,_1t,Ddo,Lr,DB,b1t,tf,v1t,Bie,F1t,T1t,Iie,M1t,E1t,C1t,GB,w1t,vRe,A1t,L1t,y1t,ga,OB,x1t,FRe,$1t,k1t,af,S1t,TRe,R1t,P1t,Nie,B1t,I1t,N1t,U7,q1t,tt,VB,j1t,MRe,D1t,G1t,es,O1t,ERe,V1t,X1t,CRe,z1t,Q1t,wRe,W1t,U1t,H1t,me,H7,ARe,J1t,Y1t,qie,Z1t,K1t,e2t,J7,LRe,o2t,r2t,jie,t2t,a2t,n2t,Y7,yRe,s2t,l2t,Die,i2t,d2t,m2t,Z7,xRe,c2t,f2t,Gie,g2t,h2t,u2t,K7,$Re,p2t,_2t,Oie,b2t,v2t,F2t,e8,kRe,T2t,M2t,Vie,E2t,C2t,w2t,o8,SRe,A2t,L2t,Xie,y2t,x2t,$2t,r8,RRe,k2t,S2t,zie,R2t,P2t,B2t,t8,PRe,I2t,N2t,Qie,q2t,j2t,D2t,a8,BRe,G2t,O2t,Wie,V2t,X2t,z2t,n8,IRe,Q2t,W2t,Uie,U2t,H2t,J2t,s8,NRe,Y2t,Z2t,Hie,K2t,ebt,obt,l8,qRe,rbt,tbt,Jie,abt,nbt,sbt,i8,jRe,lbt,ibt,Yie,dbt,mbt,cbt,d8,DRe,fbt,gbt,Zie,hbt,ubt,pbt,m8,GRe,_bt,bbt,Kie,vbt,Fbt,Tbt,c8,ORe,Mbt,Ebt,ede,Cbt,wbt,Abt,f8,VRe,Lbt,ybt,ode,xbt,$bt,kbt,g8,XRe,Sbt,Rbt,rde,Pbt,Bbt,Ibt,h8,zRe,Nbt,qbt,tde,jbt,Dbt,Gbt,u8,QRe,Obt,Vbt,ade,Xbt,zbt,Qbt,p8,WRe,Wbt,Ubt,nde,Hbt,Jbt,Ybt,_8,Gdo,nf,b8,URe,XB,Zbt,HRe,Kbt,Odo,yr,zB,evt,sf,ovt,sde,rvt,tvt,lde,avt,nvt,svt,QB,lvt,JRe,ivt,dvt,mvt,ha,WB,cvt,YRe,fvt,gvt,lf,hvt,ZRe,uvt,pvt,ide,_vt,bvt,vvt,v8,Fvt,at,UB,Tvt,KRe,Mvt,Evt,os,Cvt,ePe,wvt,Avt,oPe,Lvt,yvt,rPe,xvt,$vt,kvt,he,F8,tPe,Svt,Rvt,dde,Pvt,Bvt,Ivt,T8,aPe,Nvt,qvt,mde,jvt,Dvt,Gvt,M8,nPe,Ovt,Vvt,cde,Xvt,zvt,Qvt,E8,sPe,Wvt,Uvt,fde,Hvt,Jvt,Yvt,C8,lPe,Zvt,Kvt,gde,eFt,oFt,rFt,w8,iPe,tFt,aFt,hde,nFt,sFt,lFt,A8,dPe,iFt,dFt,ude,mFt,cFt,fFt,L8,mPe,gFt,hFt,pde,uFt,pFt,_Ft,y8,cPe,bFt,vFt,_de,FFt,TFt,MFt,x8,fPe,EFt,CFt,bde,wFt,AFt,LFt,$8,gPe,yFt,xFt,vde,$Ft,kFt,SFt,k8,hPe,RFt,PFt,Fde,BFt,IFt,NFt,S8,uPe,qFt,jFt,Tde,DFt,GFt,OFt,R8,pPe,VFt,XFt,Mde,zFt,QFt,WFt,P8,_Pe,UFt,HFt,Ede,JFt,YFt,ZFt,B8,bPe,KFt,eTt,Cde,oTt,rTt,tTt,I8,vPe,aTt,nTt,wde,sTt,lTt,iTt,N8,FPe,dTt,mTt,Ade,cTt,fTt,gTt,q8,TPe,hTt,uTt,Lde,pTt,_Tt,bTt,j8,MPe,vTt,FTt,yde,TTt,MTt,ETt,D8,EPe,CTt,wTt,xde,ATt,LTt,yTt,G8,Vdo,df,O8,CPe,HB,xTt,wPe,$Tt,Xdo,xr,JB,kTt,mf,STt,$de,RTt,PTt,kde,BTt,ITt,NTt,YB,qTt,APe,jTt,DTt,GTt,ua,ZB,OTt,LPe,VTt,XTt,cf,zTt,yPe,QTt,WTt,Sde,UTt,HTt,JTt,V8,YTt,nt,KB,ZTt,xPe,KTt,eMt,rs,oMt,$Pe,rMt,tMt,kPe,aMt,nMt,SPe,sMt,lMt,iMt,RPe,X8,PPe,dMt,mMt,Rde,cMt,fMt,gMt,z8,zdo,ff,Q8,BPe,eI,hMt,IPe,uMt,Qdo,$r,oI,pMt,gf,_Mt,Pde,bMt,vMt,Bde,FMt,TMt,MMt,rI,EMt,NPe,CMt,wMt,AMt,pa,tI,LMt,qPe,yMt,xMt,hf,$Mt,jPe,kMt,SMt,Ide,RMt,PMt,BMt,W8,IMt,st,aI,NMt,DPe,qMt,jMt,ts,DMt,GPe,GMt,OMt,OPe,VMt,XMt,VPe,zMt,QMt,WMt,nI,U8,XPe,UMt,HMt,Nde,JMt,YMt,ZMt,H8,zPe,KMt,eEt,qde,oEt,rEt,tEt,J8,Wdo,uf,Y8,QPe,sI,aEt,WPe,nEt,Udo,kr,lI,sEt,pf,lEt,jde,iEt,dEt,Dde,mEt,cEt,fEt,iI,gEt,UPe,hEt,uEt,pEt,_a,dI,_Et,HPe,bEt,vEt,_f,FEt,JPe,TEt,MEt,Gde,EEt,CEt,wEt,Z8,AEt,lt,mI,LEt,YPe,yEt,xEt,as,$Et,ZPe,kEt,SEt,KPe,REt,PEt,eBe,BEt,IEt,NEt,ne,K8,oBe,qEt,jEt,Ode,DEt,GEt,OEt,eL,rBe,VEt,XEt,Vde,zEt,QEt,WEt,oL,tBe,UEt,HEt,Xde,JEt,YEt,ZEt,rL,aBe,KEt,e4t,zde,o4t,r4t,t4t,tL,nBe,a4t,n4t,Qde,s4t,l4t,i4t,aL,sBe,d4t,m4t,Wde,c4t,f4t,g4t,nL,lBe,h4t,u4t,Ude,p4t,_4t,b4t,sL,iBe,v4t,F4t,Hde,T4t,M4t,E4t,lL,dBe,C4t,w4t,Jde,A4t,L4t,y4t,iL,mBe,x4t,$4t,Yde,k4t,S4t,R4t,dL,cBe,P4t,B4t,Zde,I4t,N4t,q4t,mL,fBe,j4t,D4t,Kde,G4t,O4t,V4t,cL,gBe,X4t,z4t,eme,Q4t,W4t,U4t,fL,hBe,H4t,J4t,ome,Y4t,Z4t,K4t,gL,uBe,eCt,oCt,rme,rCt,tCt,aCt,hL,pBe,nCt,sCt,tme,lCt,iCt,dCt,uL,_Be,mCt,cCt,ame,fCt,gCt,hCt,pL,bBe,uCt,pCt,nme,_Ct,bCt,vCt,_L,vBe,FCt,TCt,sme,MCt,ECt,CCt,bL,FBe,wCt,ACt,lme,LCt,yCt,xCt,vL,TBe,$Ct,kCt,ime,SCt,RCt,PCt,FL,MBe,BCt,ICt,dme,NCt,qCt,jCt,TL,EBe,DCt,GCt,mme,OCt,VCt,XCt,ML,CBe,zCt,QCt,cme,WCt,UCt,HCt,EL,wBe,JCt,YCt,fme,ZCt,KCt,e3t,CL,ABe,o3t,r3t,gme,t3t,a3t,n3t,wL,LBe,s3t,l3t,hme,i3t,d3t,m3t,AL,Hdo,bf,LL,yBe,cI,c3t,xBe,f3t,Jdo,Sr,fI,g3t,vf,h3t,ume,u3t,p3t,pme,_3t,b3t,v3t,gI,F3t,$Be,T3t,M3t,E3t,ba,hI,C3t,kBe,w3t,A3t,Ff,L3t,SBe,y3t,x3t,_me,$3t,k3t,S3t,yL,R3t,it,uI,P3t,RBe,B3t,I3t,ns,N3t,PBe,q3t,j3t,BBe,D3t,G3t,IBe,O3t,V3t,X3t,Se,xL,NBe,z3t,Q3t,bme,W3t,U3t,H3t,$L,qBe,J3t,Y3t,vme,Z3t,K3t,e5t,kL,jBe,o5t,r5t,Fme,t5t,a5t,n5t,SL,DBe,s5t,l5t,Tme,i5t,d5t,m5t,RL,GBe,c5t,f5t,Mme,g5t,h5t,u5t,PL,OBe,p5t,_5t,Eme,b5t,v5t,F5t,BL,VBe,T5t,M5t,Cme,E5t,C5t,w5t,IL,XBe,A5t,L5t,wme,y5t,x5t,$5t,NL,zBe,k5t,S5t,Ame,R5t,P5t,B5t,qL,QBe,I5t,N5t,Lme,q5t,j5t,D5t,jL,Ydo,Tf,DL,WBe,pI,G5t,UBe,O5t,Zdo,Rr,_I,V5t,Mf,X5t,yme,z5t,Q5t,xme,W5t,U5t,H5t,bI,J5t,HBe,Y5t,Z5t,K5t,va,vI,e0t,JBe,o0t,r0t,Ef,t0t,YBe,a0t,n0t,$me,s0t,l0t,i0t,GL,d0t,dt,FI,m0t,ZBe,c0t,f0t,ss,g0t,KBe,h0t,u0t,eIe,p0t,_0t,oIe,b0t,v0t,F0t,we,OL,rIe,T0t,M0t,kme,E0t,C0t,w0t,VL,tIe,A0t,L0t,Sme,y0t,x0t,$0t,XL,aIe,k0t,S0t,Rme,R0t,P0t,B0t,zL,nIe,I0t,N0t,Pme,q0t,j0t,D0t,QL,sIe,G0t,O0t,Bme,V0t,X0t,z0t,WL,lIe,Q0t,W0t,Ime,U0t,H0t,J0t,UL,iIe,Y0t,Z0t,Nme,K0t,ewt,owt,HL,dIe,rwt,twt,qme,awt,nwt,swt,JL,mIe,lwt,iwt,jme,dwt,mwt,cwt,YL,cIe,fwt,gwt,Dme,hwt,uwt,pwt,ZL,fIe,_wt,bwt,Gme,vwt,Fwt,Twt,KL,gIe,Mwt,Ewt,Ome,Cwt,wwt,Awt,ey,hIe,Lwt,ywt,Vme,xwt,$wt,kwt,oy,Kdo,Cf,ry,uIe,TI,Swt,pIe,Rwt,emo,Pr,MI,Pwt,wf,Bwt,Xme,Iwt,Nwt,zme,qwt,jwt,Dwt,EI,Gwt,_Ie,Owt,Vwt,Xwt,Fa,CI,zwt,bIe,Qwt,Wwt,Af,Uwt,vIe,Hwt,Jwt,Qme,Ywt,Zwt,Kwt,ty,eAt,mt,wI,oAt,FIe,rAt,tAt,ls,aAt,TIe,nAt,sAt,MIe,lAt,iAt,EIe,dAt,mAt,cAt,Re,ay,CIe,fAt,gAt,Wme,hAt,uAt,pAt,ny,wIe,_At,bAt,Ume,vAt,FAt,TAt,sy,AIe,MAt,EAt,Hme,CAt,wAt,AAt,ly,LIe,LAt,yAt,Jme,xAt,$At,kAt,iy,yIe,SAt,RAt,Yme,PAt,BAt,IAt,dy,xIe,NAt,qAt,Zme,jAt,DAt,GAt,my,$Ie,OAt,VAt,Kme,XAt,zAt,QAt,cy,kIe,WAt,UAt,ece,HAt,JAt,YAt,fy,SIe,ZAt,KAt,oce,e6t,o6t,r6t,gy,RIe,t6t,a6t,rce,n6t,s6t,l6t,hy,omo,Lf,uy,PIe,AI,i6t,BIe,d6t,rmo,Br,LI,m6t,yf,c6t,tce,f6t,g6t,ace,h6t,u6t,p6t,yI,_6t,IIe,b6t,v6t,F6t,Ta,xI,T6t,NIe,M6t,E6t,xf,C6t,qIe,w6t,A6t,nce,L6t,y6t,x6t,py,$6t,ct,$I,k6t,jIe,S6t,R6t,is,P6t,DIe,B6t,I6t,GIe,N6t,q6t,OIe,j6t,D6t,G6t,Pe,_y,VIe,O6t,V6t,sce,X6t,z6t,Q6t,by,XIe,W6t,U6t,lce,H6t,J6t,Y6t,vy,zIe,Z6t,K6t,ice,e7t,o7t,r7t,Fy,QIe,t7t,a7t,dce,n7t,s7t,l7t,Ty,WIe,i7t,d7t,mce,m7t,c7t,f7t,My,UIe,g7t,h7t,cce,u7t,p7t,_7t,Ey,HIe,b7t,v7t,fce,F7t,T7t,M7t,Cy,JIe,E7t,C7t,gce,w7t,A7t,L7t,wy,YIe,y7t,x7t,hce,$7t,k7t,S7t,Ay,ZIe,R7t,P7t,uce,B7t,I7t,N7t,Ly,tmo,$f,yy,KIe,kI,q7t,eNe,j7t,amo,Ir,SI,D7t,kf,G7t,pce,O7t,V7t,_ce,X7t,z7t,Q7t,RI,W7t,oNe,U7t,H7t,J7t,Ma,PI,Y7t,rNe,Z7t,K7t,Sf,e8t,tNe,o8t,r8t,bce,t8t,a8t,n8t,xy,s8t,ft,BI,l8t,aNe,i8t,d8t,ds,m8t,nNe,c8t,f8t,sNe,g8t,h8t,lNe,u8t,p8t,_8t,Be,$y,iNe,b8t,v8t,vce,F8t,T8t,M8t,ky,dNe,E8t,C8t,Fce,w8t,A8t,L8t,Sy,mNe,y8t,x8t,Tce,$8t,k8t,S8t,Ry,cNe,R8t,P8t,Mce,B8t,I8t,N8t,Py,fNe,q8t,j8t,Ece,D8t,G8t,O8t,By,gNe,V8t,X8t,Cce,z8t,Q8t,W8t,Iy,hNe,U8t,H8t,wce,J8t,Y8t,Z8t,Ny,uNe,K8t,eLt,Ace,oLt,rLt,tLt,qy,pNe,aLt,nLt,Lce,sLt,lLt,iLt,jy,_Ne,dLt,mLt,yce,cLt,fLt,gLt,Dy,nmo,Rf,Gy,bNe,II,hLt,vNe,uLt,smo,Nr,NI,pLt,Pf,_Lt,xce,bLt,vLt,$ce,FLt,TLt,MLt,qI,ELt,FNe,CLt,wLt,ALt,Ea,jI,LLt,TNe,yLt,xLt,Bf,$Lt,MNe,kLt,SLt,kce,RLt,PLt,BLt,Oy,ILt,gt,DI,NLt,ENe,qLt,jLt,ms,DLt,CNe,GLt,OLt,wNe,VLt,XLt,ANe,zLt,QLt,WLt,Ie,Vy,LNe,ULt,HLt,Sce,JLt,YLt,ZLt,Xy,yNe,KLt,eyt,Rce,oyt,ryt,tyt,zy,xNe,ayt,nyt,Pce,syt,lyt,iyt,Qy,$Ne,dyt,myt,Bce,cyt,fyt,gyt,Wy,kNe,hyt,uyt,Ice,pyt,_yt,byt,Uy,SNe,vyt,Fyt,Nce,Tyt,Myt,Eyt,Hy,RNe,Cyt,wyt,qce,Ayt,Lyt,yyt,Jy,PNe,xyt,$yt,jce,kyt,Syt,Ryt,Yy,BNe,Pyt,Byt,Dce,Iyt,Nyt,qyt,Zy,INe,jyt,Dyt,Gce,Gyt,Oyt,Vyt,Ky,lmo,If,e9,NNe,GI,Xyt,qNe,zyt,imo,qr,OI,Qyt,Nf,Wyt,Oce,Uyt,Hyt,Vce,Jyt,Yyt,Zyt,VI,Kyt,jNe,e9t,o9t,r9t,Ca,XI,t9t,DNe,a9t,n9t,qf,s9t,GNe,l9t,i9t,Xce,d9t,m9t,c9t,o9,f9t,ht,zI,g9t,ONe,h9t,u9t,cs,p9t,VNe,_9t,b9t,XNe,v9t,F9t,zNe,T9t,M9t,E9t,We,r9,QNe,C9t,w9t,zce,A9t,L9t,y9t,t9,WNe,x9t,$9t,Qce,k9t,S9t,R9t,a9,UNe,P9t,B9t,Wce,I9t,N9t,q9t,n9,HNe,j9t,D9t,Uce,G9t,O9t,V9t,s9,JNe,X9t,z9t,Hce,Q9t,W9t,U9t,l9,YNe,H9t,J9t,Jce,Y9t,Z9t,K9t,i9,ZNe,ext,oxt,Yce,rxt,txt,axt,d9,KNe,nxt,sxt,Zce,lxt,ixt,dxt,m9,dmo,jf,c9,eqe,QI,mxt,oqe,cxt,mmo,jr,WI,fxt,Df,gxt,Kce,hxt,uxt,efe,pxt,_xt,bxt,UI,vxt,rqe,Fxt,Txt,Mxt,wa,HI,Ext,tqe,Cxt,wxt,Gf,Axt,aqe,Lxt,yxt,ofe,xxt,$xt,kxt,f9,Sxt,ut,JI,Rxt,nqe,Pxt,Bxt,fs,Ixt,sqe,Nxt,qxt,lqe,jxt,Dxt,iqe,Gxt,Oxt,Vxt,Ue,g9,dqe,Xxt,zxt,rfe,Qxt,Wxt,Uxt,h9,mqe,Hxt,Jxt,tfe,Yxt,Zxt,Kxt,u9,cqe,e$t,o$t,afe,r$t,t$t,a$t,p9,fqe,n$t,s$t,nfe,l$t,i$t,d$t,_9,gqe,m$t,c$t,sfe,f$t,g$t,h$t,b9,hqe,u$t,p$t,lfe,_$t,b$t,v$t,v9,uqe,F$t,T$t,ife,M$t,E$t,C$t,F9,pqe,w$t,A$t,dfe,L$t,y$t,x$t,T9,cmo,Of,M9,_qe,YI,$$t,bqe,k$t,fmo,Dr,ZI,S$t,Vf,R$t,mfe,P$t,B$t,cfe,I$t,N$t,q$t,KI,j$t,vqe,D$t,G$t,O$t,Aa,eN,V$t,Fqe,X$t,z$t,Xf,Q$t,Tqe,W$t,U$t,ffe,H$t,J$t,Y$t,E9,Z$t,pt,oN,K$t,Mqe,ekt,okt,gs,rkt,Eqe,tkt,akt,Cqe,nkt,skt,wqe,lkt,ikt,dkt,Aqe,C9,Lqe,mkt,ckt,gfe,fkt,gkt,hkt,w9,gmo,zf,A9,yqe,rN,ukt,xqe,pkt,hmo,Gr,tN,_kt,Qf,bkt,hfe,vkt,Fkt,ufe,Tkt,Mkt,Ekt,aN,Ckt,$qe,wkt,Akt,Lkt,La,nN,ykt,kqe,xkt,$kt,Wf,kkt,Sqe,Skt,Rkt,pfe,Pkt,Bkt,Ikt,L9,Nkt,_t,sN,qkt,Rqe,jkt,Dkt,hs,Gkt,Pqe,Okt,Vkt,Bqe,Xkt,zkt,Iqe,Qkt,Wkt,Ukt,lN,y9,Nqe,Hkt,Jkt,_fe,Ykt,Zkt,Kkt,x9,qqe,eSt,oSt,bfe,rSt,tSt,aSt,$9,umo,Uf,k9,jqe,iN,nSt,Dqe,sSt,pmo,Or,dN,lSt,Hf,iSt,vfe,dSt,mSt,Ffe,cSt,fSt,gSt,mN,hSt,Gqe,uSt,pSt,_St,ya,cN,bSt,Oqe,vSt,FSt,Jf,TSt,Vqe,MSt,ESt,Tfe,CSt,wSt,ASt,S9,LSt,bt,fN,ySt,Xqe,xSt,$St,us,kSt,zqe,SSt,RSt,Qqe,PSt,BSt,Wqe,ISt,NSt,qSt,Uqe,R9,Hqe,jSt,DSt,Mfe,GSt,OSt,VSt,P9,_mo;return m=new re({}),ln=new B({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),Tk=new re({}),Mk=new B({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),ng=new Vfo({props:{warning:!0,$$slots:{default:[N$a]},$$scope:{ctx:$}}}),Ek=new re({}),Ck=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L677"}}),Lk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L700"}}),qu=new N({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[q$a]},$$scope:{ctx:$}}}),yk=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/configuration_auto.py#L823"}}),xk=new re({}),$k=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L451"}}),Rk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/main/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L465"}}),wp=new N({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[j$a]},$$scope:{ctx:$}}}),Pk=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/tokenization_auto.py#L666"}}),Bk=new re({}),Ik=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L206"}}),jk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/main/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L220"}}),F_=new Vfo({props:{$$slots:{default:[D$a]},$$scope:{ctx:$}}}),T_=new N({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[G$a]},$$scope:{ctx:$}}}),Dk=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/feature_extraction_auto.py#L347"}}),Gk=new re({}),Ok=new R({props:{name:"class transformers.AutoImageProcessor",anchor:"transformers.AutoImageProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/image_processing_auto.py#L190"}}),zk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoImageProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoImageProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained image_processor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a image processor file saved using the
<a href="/docs/transformers/main/en/internal/image_processing_utils#transformers.ImageProcessingMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved image processor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoImageProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model image processor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoImageProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the image processor files and override the cached versions if
they exist.`,name:"force_download"},{anchor:"transformers.AutoImageProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoImageProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoImageProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoImageProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoImageProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final image processor object. If <code>True</code>, then this
functions returns a <code>Tuple(image_processor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not image processor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>image_processor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoImageProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoImageProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are image processor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> image processor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/image_processing_auto.py#L204"}}),e1=new Vfo({props:{$$slots:{default:[O$a]},$$scope:{ctx:$}}}),o1=new N({props:{anchor:"transformers.AutoImageProcessor.from_pretrained.example",$$slots:{default:[V$a]},$$scope:{ctx:$}}}),Qk=new R({props:{name:"register",anchor:"transformers.AutoImageProcessor.register",parameters:[{name:"config_class",val:""},{name:"image_processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoImageProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoImageProcessor.register.image_processor_class",description:'<strong>image_processor_class</strong> (<a href="/docs/transformers/main/en/internal/image_processing_utils#transformers.ImageProcessingMixin">ImageProcessingMixin</a>) &#x2014; The image processor to register.',name:"image_processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/image_processing_auto.py#L349"}}),Wk=new re({}),Uk=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L98"}}),Yk=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L112"}}),L1=new Vfo({props:{$$slots:{default:[X$a]},$$scope:{ctx:$}}}),y1=new N({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[z$a]},$$scope:{ctx:$}}}),Zk=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/processing_auto.py#L293"}}),Kk=new re({}),eS=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L902"}}),rS=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegConfig">CLIPSegConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegModel">CLIPSegModel</a> (CLIPSeg model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel">ConditionalDetrModel</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel">DeformableDetrModel</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig">DonutSwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel">DonutSwinModel</a> (DonutSwin model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel">ErnieModel</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmModel">EsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel">GPTNeoXJapaneseModel</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/jukebox#transformers.JukeboxConfig">JukeboxConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/jukebox#transformers.JukeboxModel">JukeboxModel</a> (Jukebox model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltModel">LiltModel</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel">MarkupLMModel</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilenet_v2#transformers.MobileNetV2Config">MobileNetV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilenet_v2#transformers.MobileNetV2Model">MobileNetV2Model</a> (MobileNetV2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel">PegasusXModel</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertModel">RoCBertModel</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig">TableTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerModel">TableTransformerModel</a> (Table Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig">TimeSeriesTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel">TimeSeriesTransformerModel</a> (Time Series Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel">ViTMSNModel</a> (ViTMSN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel">WhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig">XCLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel">XCLIPModel</a> (X-CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),k1=new N({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[Q$a]},$$scope:{ctx:$}}}),tS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),tv=new N({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[W$a]},$$scope:{ctx:$}}}),aS=new re({}),nS=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L909"}}),lS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining">ErnieForPreTraining</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForPreTraining">RoCBertForPreTraining</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),nv=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[U$a]},$$scope:{ctx:$}}}),iS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),rF=new N({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[H$a]},$$scope:{ctx:$}}}),dS=new re({}),mS=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L924"}}),fS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM">ErnieForCausalLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig">GPTNeoXJapaneseConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM">GPTNeoXJapaneseForCausalLM</a> (GPT NeoX Japanese model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForCausalLM">RoCBertForCausalLM</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),aF=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[J$a]},$$scope:{ctx:$}}}),gS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),HF=new N({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Y$a]},$$scope:{ctx:$}}}),hS=new re({}),uS=new R({props:{name:"class transformers.AutoModelForDepthEstimation",anchor:"transformers.AutoModelForDepthEstimation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1067"}}),_S=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDepthEstimation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForDepthEstimation">DPTForDepthEstimation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/glpn#transformers.GLPNForDepthEstimation">GLPNForDepthEstimation</a> (GLPN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),YF=new N({props:{anchor:"transformers.AutoModelForDepthEstimation.from_config.example",$$slots:{default:[Z$a]},$$scope:{ctx:$}}}),bS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDepthEstimation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),oT=new N({props:{anchor:"transformers.AutoModelForDepthEstimation.from_pretrained.example",$$slots:{default:[K$a]},$$scope:{ctx:$}}}),FS=new re({}),TS=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L931"}}),ES=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM">ErnieForMaskedLM</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForMaskedLM">RoCBertForMaskedLM</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),tT=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[eka]},$$scope:{ctx:$}}}),CS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),zT=new N({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[oka]},$$scope:{ctx:$}}}),wS=new re({}),AS=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L938"}}),yS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig">PegasusXConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration">PegasusXForConditionalGeneration</a> (PEGASUS-X model)</li>
<li><a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),WT=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[rka]},$$scope:{ctx:$}}}),xS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),uM=new N({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[tka]},$$scope:{ctx:$}}}),$S=new re({}),kS=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L947"}}),RS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification">ErnieForSequenceClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification">EsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForSequenceClassification">LiltForSequenceClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification">MarkupLMForSequenceClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForSequenceClassification">RoCBertForSequenceClassification</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),_M=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[aka]},$$scope:{ctx:$}}}),PS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),ME=new N({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[nka]},$$scope:{ctx:$}}}),BS=new re({}),IS=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1003"}}),qS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice">ErnieForMultipleChoice</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForMultipleChoice">RoCBertForMultipleChoice</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),CE=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[ska]},$$scope:{ctx:$}}}),jS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),n4=new N({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[lka]},$$scope:{ctx:$}}}),DS=new re({}),GS=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1010"}}),VS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction">ErnieForNextSentencePrediction</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),l4=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[ika]},$$scope:{ctx:$}}}),XS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),p4=new N({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[dka]},$$scope:{ctx:$}}}),zS=new re({}),QS=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L996"}}),US=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification">ErnieForTokenClassification</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification">EsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForTokenClassification">LiltForTokenClassification</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification">MarkupLMForTokenClassification</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForTokenClassification">RoCBertForTokenClassification</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),b4=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[mka]},$$scope:{ctx:$}}}),HS=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),iC=new N({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[cka]},$$scope:{ctx:$}}}),JS=new re({}),YS=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L956"}}),KS=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering">BloomForQuestionAnswering</a> (BLOOM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig">ErnieConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering">ErnieForQuestionAnswering</a> (ERNIE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig">LiltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lilt#transformers.LiltForQuestionAnswering">LiltForQuestionAnswering</a> (LiLT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig">MarkupLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering">MarkupLMForQuestionAnswering</a> (MarkupLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering">OPTForQuestionAnswering</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig">RoCBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForQuestionAnswering">RoCBertForQuestionAnswering</a> (RoCBert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),mC=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[fka]},$$scope:{ctx:$}}}),eR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),l3=new N({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[gka]},$$scope:{ctx:$}}}),oR=new re({}),rR=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L963"}}),aR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),d3=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[hka]},$$scope:{ctx:$}}}),nR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),f3=new N({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[uka]},$$scope:{ctx:$}}}),sR=new re({}),lR=new R({props:{name:"class transformers.AutoModelForDocumentQuestionAnswering",anchor:"transformers.AutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L985"}}),dR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering">LayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),h3=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[pka]},$$scope:{ctx:$}}}),mR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),v3=new N({props:{anchor:"transformers.AutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[_ka]},$$scope:{ctx:$}}}),cR=new re({}),fR=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1019"}}),hR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilenet_v2#transformers.MobileNetV2Config">MobileNetV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilenet_v2#transformers.MobileNetV2ForImageClassification">MobileNetV2ForImageClassification</a> (MobileNetV2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig">ViTMSNConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification">ViTMSNForImageClassification</a> (ViTMSN model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),T3=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[bka]},$$scope:{ctx:$}}}),uR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),j3=new N({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[vka]},$$scope:{ctx:$}}}),pR=new re({}),_R=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1074"}}),vR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),G3=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[Fka]},$$scope:{ctx:$}}}),FR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),X3=new N({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[Tka]},$$scope:{ctx:$}}}),TR=new re({}),MR=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1081"}}),CR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Q3=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[Mka]},$$scope:{ctx:$}}}),wR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),H3=new N({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Eka]},$$scope:{ctx:$}}}),AR=new re({}),LR=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L974"}}),xR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Y3=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[Cka]},$$scope:{ctx:$}}}),$R=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),e5=new N({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[wka]},$$scope:{ctx:$}}}),kR=new re({}),SR=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1088"}}),PR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),r5=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[Aka]},$$scope:{ctx:$}}}),BR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),g5=new N({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[Lka]},$$scope:{ctx:$}}}),IR=new re({}),NR=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1111"}}),jR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),u5=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[yka]},$$scope:{ctx:$}}}),DR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),M5=new N({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[xka]},$$scope:{ctx:$}}}),GR=new re({}),OR=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1095"}}),XR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),C5=new N({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[$ka]},$$scope:{ctx:$}}}),zR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),I5=new N({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[kka]},$$scope:{ctx:$}}}),QR=new re({}),WR=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1102"}}),HR=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration">WhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),q5=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[Ska]},$$scope:{ctx:$}}}),JR=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),V5=new N({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[Rka]},$$scope:{ctx:$}}}),YR=new re({}),ZR=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1120"}}),eP=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),z5=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[Pka]},$$scope:{ctx:$}}}),oP=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Z5=new N({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[Bka]},$$scope:{ctx:$}}}),rP=new re({}),tP=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1127"}}),nP=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),e0=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[Ika]},$$scope:{ctx:$}}}),sP=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),s0=new N({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[Nka]},$$scope:{ctx:$}}}),lP=new re({}),iP=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1051"}}),mP=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig">ConditionalDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection">ConditionalDetrForObjectDetection</a> (Conditional DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig">DeformableDetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection">DeformableDetrForObjectDetection</a> (Deformable DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig">TableTransformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection">TableTransformerForObjectDetection</a> (Table Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),i0=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[qka]},$$scope:{ctx:$}}}),cP=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),u0=new N({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[jka]},$$scope:{ctx:$}}}),fP=new re({}),gP=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1026"}}),uP=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),_0=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[Dka]},$$scope:{ctx:$}}}),pP=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),F0=new N({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[Gka]},$$scope:{ctx:$}}}),_P=new re({}),bP=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1033"}}),FP=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilenet_v2#transformers.MobileNetV2Config">MobileNetV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilenet_v2#transformers.MobileNetV2ForSemanticSegmentation">MobileNetV2ForSemanticSegmentation</a> (MobileNetV2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),M0=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[Oka]},$$scope:{ctx:$}}}),TP=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),$0=new N({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[Vka]},$$scope:{ctx:$}}}),MP=new re({}),EP=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1042"}}),wP=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),S0=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[Xka]},$$scope:{ctx:$}}}),AP=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),B0=new N({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[zka]},$$scope:{ctx:$}}}),LP=new re({}),yP=new R({props:{name:"class transformers.AutoModelForZeroShotObjectDetection",anchor:"transformers.AutoModelForZeroShotObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_auto.py#L1058"}}),$P=new R({props:{name:"from_config",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection">OwlViTForObjectDetection</a> (OWL-ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),N0=new N({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_config.example",$$slots:{default:[Qka]},$$scope:{ctx:$}}}),kP=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),D0=new N({props:{anchor:"transformers.AutoModelForZeroShotObjectDetection.from_pretrained.example",$$slots:{default:[Wka]},$$scope:{ctx:$}}}),SP=new re({}),RP=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),BP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel">TFCvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmModel">TFEsmModel</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel">TFGroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model">TFLayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel">TFMobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel">TFWhisperModel</a> (Whisper model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel">TFXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),O0=new N({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[Uka]},$$scope:{ctx:$}}}),IP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Qw=new N({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[Hka]},$$scope:{ctx:$}}}),NP=new re({}),qP=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L451"}}),DP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Uw=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[Jka]},$$scope:{ctx:$}}}),GP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),bA=new N({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Yka]},$$scope:{ctx:$}}}),OP=new re({}),VP=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L466"}}),zP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM">TFXGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),FA=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[Zka]},$$scope:{ctx:$}}}),QP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),BA=new N({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Kka]},$$scope:{ctx:$}}}),WP=new re({}),UP=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L482"}}),JP=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification">TFCvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification">TFMobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),NA=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[eSa]},$$scope:{ctx:$}}}),YP=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),WA=new N({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[oSa]},$$scope:{ctx:$}}}),ZP=new re({}),KP=new R({props:{name:"class transformers.TFAutoModelForSemanticSegmentation",anchor:"transformers.TFAutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L491"}}),oB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation">TFData2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation">TFMobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation">TFSegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),HA=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[rSa]},$$scope:{ctx:$}}}),rB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),KA=new N({props:{anchor:"transformers.TFAutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[tSa]},$$scope:{ctx:$}}}),tB=new re({}),aB=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L507"}}),sB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForMaskedLM">TFEsmForMaskedLM</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),o6=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[aSa]},$$scope:{ctx:$}}}),lB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),E6=new N({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[nSa]},$$scope:{ctx:$}}}),iB=new re({}),dB=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L514"}}),cB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),w6=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[sSa]},$$scope:{ctx:$}}}),fB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),I6=new N({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[lSa]},$$scope:{ctx:$}}}),gB=new re({}),hB=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L523"}}),pB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForSequenceClassification">TFEsmForSequenceClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification">TFLayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),q6=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[iSa]},$$scope:{ctx:$}}}),_B=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),g7=new N({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[dSa]},$$scope:{ctx:$}}}),bB=new re({}),vB=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L570"}}),TB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),u7=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[mSa]},$$scope:{ctx:$}}}),MB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),R7=new N({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[cSa]},$$scope:{ctx:$}}}),EB=new re({}),CB=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L577"}}),AB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),B7=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[fSa]},$$scope:{ctx:$}}}),LB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),q7=new N({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[gSa]},$$scope:{ctx:$}}}),xB=new re({}),$B=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L550"}}),SB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),D7=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[hSa]},$$scope:{ctx:$}}}),RB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),O7=new N({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[uSa]},$$scope:{ctx:$}}}),PB=new re({}),BB=new R({props:{name:"class transformers.TFAutoModelForDocumentQuestionAnswering",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L539"}}),NB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering">TFLayoutLMForQuestionAnswering</a> (LayoutLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),X7=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_config.example",$$slots:{default:[pSa]},$$scope:{ctx:$}}}),qB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Q7=new N({props:{anchor:"transformers.TFAutoModelForDocumentQuestionAnswering.from_pretrained.example",$$slots:{default:[_Sa]},$$scope:{ctx:$}}}),jB=new re({}),DB=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L561"}}),OB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig">EsmConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForTokenClassification">TFEsmForTokenClassification</a> (ESM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification">TFLayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),U7=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[bSa]},$$scope:{ctx:$}}}),VB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),_8=new N({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[vSa]},$$scope:{ctx:$}}}),XB=new re({}),zB=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L532"}}),WB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering">TFLayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),v8=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[FSa]},$$scope:{ctx:$}}}),UB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),G8=new N({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[TSa]},$$scope:{ctx:$}}}),HB=new re({}),JB=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L500"}}),ZB=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),V8=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[MSa]},$$scope:{ctx:$}}}),KB=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),z8=new N({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[ESa]},$$scope:{ctx:$}}}),eI=new re({}),oI=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_tf_auto.py#L586"}}),tI=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig">WhisperConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration">TFWhisperForConditionalGeneration</a> (Whisper model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),W8=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[CSa]},$$scope:{ctx:$}}}),aI=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),J8=new N({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[wSa]},$$scope:{ctx:$}}}),sI=new re({}),lI=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),dI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Z8=new N({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[ASa]},$$scope:{ctx:$}}}),mI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),AL=new N({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[LSa]},$$scope:{ctx:$}}}),cI=new re({}),fI=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),hI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),yL=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[ySa]},$$scope:{ctx:$}}}),uI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),jL=new N({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[xSa]},$$scope:{ctx:$}}}),pI=new re({}),_I=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),vI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),GL=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[$Sa]},$$scope:{ctx:$}}}),FI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),oy=new N({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[kSa]},$$scope:{ctx:$}}}),TI=new re({}),MI=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),CI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),ty=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[SSa]},$$scope:{ctx:$}}}),wI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),hy=new N({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[RSa]},$$scope:{ctx:$}}}),AI=new re({}),LI=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),xI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/main/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),py=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[PSa]},$$scope:{ctx:$}}}),$I=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Ly=new N({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[BSa]},$$scope:{ctx:$}}}),kI=new re({}),SI=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),PI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),xy=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[ISa]},$$scope:{ctx:$}}}),BI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Dy=new N({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[NSa]},$$scope:{ctx:$}}}),II=new re({}),NI=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),jI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),Oy=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[qSa]},$$scope:{ctx:$}}}),DI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),Ky=new N({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[jSa]},$$scope:{ctx:$}}}),GI=new re({}),OI=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),XI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),o9=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[DSa]},$$scope:{ctx:$}}}),zI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),m9=new N({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[GSa]},$$scope:{ctx:$}}}),QI=new re({}),WI=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),HI=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),f9=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[OSa]},$$scope:{ctx:$}}}),JI=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),T9=new N({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[VSa]},$$scope:{ctx:$}}}),YI=new re({}),ZI=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),eN=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),E9=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[XSa]},$$scope:{ctx:$}}}),oN=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),w9=new N({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[zSa]},$$scope:{ctx:$}}}),rN=new re({}),tN=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),nN=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),L9=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[QSa]},$$scope:{ctx:$}}}),sN=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),$9=new N({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[WSa]},$$scope:{ctx:$}}}),iN=new re({}),dN=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),cN=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L389"}}),S9=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[USa]},$$scope:{ctx:$}}}),fN=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/main/src/transformers/models/auto/auto_factory.py#L417"}}),P9=new N({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[HSa]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),u=a("h1"),f=a("a"),p=a("span"),F(m.$$.fragment),h=l(),He=a("span"),Ad=o("Auto Classes"),eg=l(),wt=a("p"),Ld=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),yd=a("code"),_k=o("from_pretrained()"),og=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Qe=l(),Ze=a("p"),xd=o("Instantiating one of "),_s=a("a"),bk=o("AutoConfig"),bs=o(", "),vs=a("a"),vk=o("AutoModel"),$d=o(`, and
`),Fs=a("a"),Fk=o("AutoTokenizer"),kd=o(" will directly create a class of the relevant architecture. For instance"),rg=l(),F(ln.$$.fragment),Ke=l(),ye=a("p"),Gq=o("will create a model that is an instance of "),Sd=a("a"),Oq=o("BertModel"),Vq=o("."),Po=l(),dn=a("p"),Xq=o("There is one class of "),tg=a("code"),zq=o("AutoModel"),Xfo=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),Zlo=l(),Rd=a("h2"),ag=a("a"),khe=a("span"),F(Tk.$$.fragment),zfo=l(),She=a("span"),Qfo=o("Extending the Auto Classes"),Klo=l(),Ts=a("p"),Wfo=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Rhe=a("code"),Ufo=o("NewModel"),Hfo=o(", make sure you have a "),Phe=a("code"),Jfo=o("NewModelConfig"),Yfo=o(` then you can add those to the auto
classes like this:`),eio=l(),F(Mk.$$.fragment),oio=l(),Qq=a("p"),Zfo=o("You will then be able to use the auto classes like you would usually do!"),rio=l(),F(ng.$$.fragment),tio=l(),Pd=a("h2"),sg=a("a"),Bhe=a("span"),F(Ek.$$.fragment),Kfo=l(),Ihe=a("span"),ego=o("AutoConfig"),aio=l(),Bo=a("div"),F(Ck.$$.fragment),ogo=l(),wk=a("p"),rgo=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),Wq=a("a"),tgo=o("from_pretrained()"),ago=o(" class method."),ngo=l(),Ak=a("p"),sgo=o("This class cannot be instantiated directly using "),Nhe=a("code"),lgo=o("__init__()"),igo=o(" (throws an error)."),dgo=l(),Vr=a("div"),F(Lk.$$.fragment),mgo=l(),qhe=a("p"),cgo=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),fgo=l(),Bd=a("p"),ggo=o("The configuration class to instantiate is selected based on the "),jhe=a("code"),hgo=o("model_type"),ugo=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Dhe=a("code"),pgo=o("pretrained_model_name_or_path"),_go=o(":"),bgo=l(),A=a("ul"),lg=a("li"),Ghe=a("strong"),vgo=o("albert"),Fgo=o(" \u2014 "),Uq=a("a"),Tgo=o("AlbertConfig"),Mgo=o(" (ALBERT model)"),Ego=l(),ig=a("li"),Ohe=a("strong"),Cgo=o("bart"),wgo=o(" \u2014 "),Hq=a("a"),Ago=o("BartConfig"),Lgo=o(" (BART model)"),ygo=l(),dg=a("li"),Vhe=a("strong"),xgo=o("beit"),$go=o(" \u2014 "),Jq=a("a"),kgo=o("BeitConfig"),Sgo=o(" (BEiT model)"),Rgo=l(),mg=a("li"),Xhe=a("strong"),Pgo=o("bert"),Bgo=o(" \u2014 "),Yq=a("a"),Igo=o("BertConfig"),Ngo=o(" (BERT model)"),qgo=l(),cg=a("li"),zhe=a("strong"),jgo=o("bert-generation"),Dgo=o(" \u2014 "),Zq=a("a"),Ggo=o("BertGenerationConfig"),Ogo=o(" (Bert Generation model)"),Vgo=l(),fg=a("li"),Qhe=a("strong"),Xgo=o("big_bird"),zgo=o(" \u2014 "),Kq=a("a"),Qgo=o("BigBirdConfig"),Wgo=o(" (BigBird model)"),Ugo=l(),gg=a("li"),Whe=a("strong"),Hgo=o("bigbird_pegasus"),Jgo=o(" \u2014 "),ej=a("a"),Ygo=o("BigBirdPegasusConfig"),Zgo=o(" (BigBird-Pegasus model)"),Kgo=l(),hg=a("li"),Uhe=a("strong"),eho=o("blenderbot"),oho=o(" \u2014 "),oj=a("a"),rho=o("BlenderbotConfig"),tho=o(" (Blenderbot model)"),aho=l(),ug=a("li"),Hhe=a("strong"),nho=o("blenderbot-small"),sho=o(" \u2014 "),rj=a("a"),lho=o("BlenderbotSmallConfig"),iho=o(" (BlenderbotSmall model)"),dho=l(),pg=a("li"),Jhe=a("strong"),mho=o("bloom"),cho=o(" \u2014 "),tj=a("a"),fho=o("BloomConfig"),gho=o(" (BLOOM model)"),hho=l(),_g=a("li"),Yhe=a("strong"),uho=o("camembert"),pho=o(" \u2014 "),aj=a("a"),_ho=o("CamembertConfig"),bho=o(" (CamemBERT model)"),vho=l(),bg=a("li"),Zhe=a("strong"),Fho=o("canine"),Tho=o(" \u2014 "),nj=a("a"),Mho=o("CanineConfig"),Eho=o(" (CANINE model)"),Cho=l(),vg=a("li"),Khe=a("strong"),who=o("clip"),Aho=o(" \u2014 "),sj=a("a"),Lho=o("CLIPConfig"),yho=o(" (CLIP model)"),xho=l(),Fg=a("li"),eue=a("strong"),$ho=o("clipseg"),kho=o(" \u2014 "),lj=a("a"),Sho=o("CLIPSegConfig"),Rho=o(" (CLIPSeg model)"),Pho=l(),Tg=a("li"),oue=a("strong"),Bho=o("codegen"),Iho=o(" \u2014 "),ij=a("a"),Nho=o("CodeGenConfig"),qho=o(" (CodeGen model)"),jho=l(),Mg=a("li"),rue=a("strong"),Dho=o("conditional_detr"),Gho=o(" \u2014 "),dj=a("a"),Oho=o("ConditionalDetrConfig"),Vho=o(" (Conditional DETR model)"),Xho=l(),Eg=a("li"),tue=a("strong"),zho=o("convbert"),Qho=o(" \u2014 "),mj=a("a"),Who=o("ConvBertConfig"),Uho=o(" (ConvBERT model)"),Hho=l(),Cg=a("li"),aue=a("strong"),Jho=o("convnext"),Yho=o(" \u2014 "),cj=a("a"),Zho=o("ConvNextConfig"),Kho=o(" (ConvNeXT model)"),euo=l(),wg=a("li"),nue=a("strong"),ouo=o("ctrl"),ruo=o(" \u2014 "),fj=a("a"),tuo=o("CTRLConfig"),auo=o(" (CTRL model)"),nuo=l(),Ag=a("li"),sue=a("strong"),suo=o("cvt"),luo=o(" \u2014 "),gj=a("a"),iuo=o("CvtConfig"),duo=o(" (CvT model)"),muo=l(),Lg=a("li"),lue=a("strong"),cuo=o("data2vec-audio"),fuo=o(" \u2014 "),hj=a("a"),guo=o("Data2VecAudioConfig"),huo=o(" (Data2VecAudio model)"),uuo=l(),yg=a("li"),iue=a("strong"),puo=o("data2vec-text"),_uo=o(" \u2014 "),uj=a("a"),buo=o("Data2VecTextConfig"),vuo=o(" (Data2VecText model)"),Fuo=l(),xg=a("li"),due=a("strong"),Tuo=o("data2vec-vision"),Muo=o(" \u2014 "),pj=a("a"),Euo=o("Data2VecVisionConfig"),Cuo=o(" (Data2VecVision model)"),wuo=l(),$g=a("li"),mue=a("strong"),Auo=o("deberta"),Luo=o(" \u2014 "),_j=a("a"),yuo=o("DebertaConfig"),xuo=o(" (DeBERTa model)"),$uo=l(),kg=a("li"),cue=a("strong"),kuo=o("deberta-v2"),Suo=o(" \u2014 "),bj=a("a"),Ruo=o("DebertaV2Config"),Puo=o(" (DeBERTa-v2 model)"),Buo=l(),Sg=a("li"),fue=a("strong"),Iuo=o("decision_transformer"),Nuo=o(" \u2014 "),vj=a("a"),quo=o("DecisionTransformerConfig"),juo=o(" (Decision Transformer model)"),Duo=l(),Rg=a("li"),gue=a("strong"),Guo=o("deformable_detr"),Ouo=o(" \u2014 "),Fj=a("a"),Vuo=o("DeformableDetrConfig"),Xuo=o(" (Deformable DETR model)"),zuo=l(),Pg=a("li"),hue=a("strong"),Quo=o("deit"),Wuo=o(" \u2014 "),Tj=a("a"),Uuo=o("DeiTConfig"),Huo=o(" (DeiT model)"),Juo=l(),Bg=a("li"),uue=a("strong"),Yuo=o("detr"),Zuo=o(" \u2014 "),Mj=a("a"),Kuo=o("DetrConfig"),epo=o(" (DETR model)"),opo=l(),Ig=a("li"),pue=a("strong"),rpo=o("distilbert"),tpo=o(" \u2014 "),Ej=a("a"),apo=o("DistilBertConfig"),npo=o(" (DistilBERT model)"),spo=l(),Ng=a("li"),_ue=a("strong"),lpo=o("donut-swin"),ipo=o(" \u2014 "),Cj=a("a"),dpo=o("DonutSwinConfig"),mpo=o(" (DonutSwin model)"),cpo=l(),qg=a("li"),bue=a("strong"),fpo=o("dpr"),gpo=o(" \u2014 "),wj=a("a"),hpo=o("DPRConfig"),upo=o(" (DPR model)"),ppo=l(),jg=a("li"),vue=a("strong"),_po=o("dpt"),bpo=o(" \u2014 "),Aj=a("a"),vpo=o("DPTConfig"),Fpo=o(" (DPT model)"),Tpo=l(),Dg=a("li"),Fue=a("strong"),Mpo=o("electra"),Epo=o(" \u2014 "),Lj=a("a"),Cpo=o("ElectraConfig"),wpo=o(" (ELECTRA model)"),Apo=l(),Gg=a("li"),Tue=a("strong"),Lpo=o("encoder-decoder"),ypo=o(" \u2014 "),yj=a("a"),xpo=o("EncoderDecoderConfig"),$po=o(" (Encoder decoder model)"),kpo=l(),Og=a("li"),Mue=a("strong"),Spo=o("ernie"),Rpo=o(" \u2014 "),xj=a("a"),Ppo=o("ErnieConfig"),Bpo=o(" (ERNIE model)"),Ipo=l(),Vg=a("li"),Eue=a("strong"),Npo=o("esm"),qpo=o(" \u2014 "),$j=a("a"),jpo=o("EsmConfig"),Dpo=o(" (ESM model)"),Gpo=l(),Xg=a("li"),Cue=a("strong"),Opo=o("flaubert"),Vpo=o(" \u2014 "),kj=a("a"),Xpo=o("FlaubertConfig"),zpo=o(" (FlauBERT model)"),Qpo=l(),zg=a("li"),wue=a("strong"),Wpo=o("flava"),Upo=o(" \u2014 "),Sj=a("a"),Hpo=o("FlavaConfig"),Jpo=o(" (FLAVA model)"),Ypo=l(),Qg=a("li"),Aue=a("strong"),Zpo=o("fnet"),Kpo=o(" \u2014 "),Rj=a("a"),e_o=o("FNetConfig"),o_o=o(" (FNet model)"),r_o=l(),Wg=a("li"),Lue=a("strong"),t_o=o("fsmt"),a_o=o(" \u2014 "),Pj=a("a"),n_o=o("FSMTConfig"),s_o=o(" (FairSeq Machine-Translation model)"),l_o=l(),Ug=a("li"),yue=a("strong"),i_o=o("funnel"),d_o=o(" \u2014 "),Bj=a("a"),m_o=o("FunnelConfig"),c_o=o(" (Funnel Transformer model)"),f_o=l(),Hg=a("li"),xue=a("strong"),g_o=o("glpn"),h_o=o(" \u2014 "),Ij=a("a"),u_o=o("GLPNConfig"),p_o=o(" (GLPN model)"),__o=l(),Jg=a("li"),$ue=a("strong"),b_o=o("gpt2"),v_o=o(" \u2014 "),Nj=a("a"),F_o=o("GPT2Config"),T_o=o(" (OpenAI GPT-2 model)"),M_o=l(),Yg=a("li"),kue=a("strong"),E_o=o("gpt_neo"),C_o=o(" \u2014 "),qj=a("a"),w_o=o("GPTNeoConfig"),A_o=o(" (GPT Neo model)"),L_o=l(),Zg=a("li"),Sue=a("strong"),y_o=o("gpt_neox"),x_o=o(" \u2014 "),jj=a("a"),$_o=o("GPTNeoXConfig"),k_o=o(" (GPT NeoX model)"),S_o=l(),Kg=a("li"),Rue=a("strong"),R_o=o("gpt_neox_japanese"),P_o=o(" \u2014 "),Dj=a("a"),B_o=o("GPTNeoXJapaneseConfig"),I_o=o(" (GPT NeoX Japanese model)"),N_o=l(),eh=a("li"),Pue=a("strong"),q_o=o("gptj"),j_o=o(" \u2014 "),Gj=a("a"),D_o=o("GPTJConfig"),G_o=o(" (GPT-J model)"),O_o=l(),oh=a("li"),Bue=a("strong"),V_o=o("groupvit"),X_o=o(" \u2014 "),Oj=a("a"),z_o=o("GroupViTConfig"),Q_o=o(" (GroupViT model)"),W_o=l(),rh=a("li"),Iue=a("strong"),U_o=o("hubert"),H_o=o(" \u2014 "),Vj=a("a"),J_o=o("HubertConfig"),Y_o=o(" (Hubert model)"),Z_o=l(),th=a("li"),Nue=a("strong"),K_o=o("ibert"),e1o=o(" \u2014 "),Xj=a("a"),o1o=o("IBertConfig"),r1o=o(" (I-BERT model)"),t1o=l(),ah=a("li"),que=a("strong"),a1o=o("imagegpt"),n1o=o(" \u2014 "),zj=a("a"),s1o=o("ImageGPTConfig"),l1o=o(" (ImageGPT model)"),i1o=l(),nh=a("li"),jue=a("strong"),d1o=o("jukebox"),m1o=o(" \u2014 "),Qj=a("a"),c1o=o("JukeboxConfig"),f1o=o(" (Jukebox model)"),g1o=l(),sh=a("li"),Due=a("strong"),h1o=o("layoutlm"),u1o=o(" \u2014 "),Wj=a("a"),p1o=o("LayoutLMConfig"),_1o=o(" (LayoutLM model)"),b1o=l(),lh=a("li"),Gue=a("strong"),v1o=o("layoutlmv2"),F1o=o(" \u2014 "),Uj=a("a"),T1o=o("LayoutLMv2Config"),M1o=o(" (LayoutLMv2 model)"),E1o=l(),ih=a("li"),Oue=a("strong"),C1o=o("layoutlmv3"),w1o=o(" \u2014 "),Hj=a("a"),A1o=o("LayoutLMv3Config"),L1o=o(" (LayoutLMv3 model)"),y1o=l(),dh=a("li"),Vue=a("strong"),x1o=o("led"),$1o=o(" \u2014 "),Jj=a("a"),k1o=o("LEDConfig"),S1o=o(" (LED model)"),R1o=l(),mh=a("li"),Xue=a("strong"),P1o=o("levit"),B1o=o(" \u2014 "),Yj=a("a"),I1o=o("LevitConfig"),N1o=o(" (LeViT model)"),q1o=l(),ch=a("li"),zue=a("strong"),j1o=o("lilt"),D1o=o(" \u2014 "),Zj=a("a"),G1o=o("LiltConfig"),O1o=o(" (LiLT model)"),V1o=l(),fh=a("li"),Que=a("strong"),X1o=o("longformer"),z1o=o(" \u2014 "),Kj=a("a"),Q1o=o("LongformerConfig"),W1o=o(" (Longformer model)"),U1o=l(),gh=a("li"),Wue=a("strong"),H1o=o("longt5"),J1o=o(" \u2014 "),eD=a("a"),Y1o=o("LongT5Config"),Z1o=o(" (LongT5 model)"),K1o=l(),hh=a("li"),Uue=a("strong"),e2o=o("luke"),o2o=o(" \u2014 "),oD=a("a"),r2o=o("LukeConfig"),t2o=o(" (LUKE model)"),a2o=l(),uh=a("li"),Hue=a("strong"),n2o=o("lxmert"),s2o=o(" \u2014 "),rD=a("a"),l2o=o("LxmertConfig"),i2o=o(" (LXMERT model)"),d2o=l(),ph=a("li"),Jue=a("strong"),m2o=o("m2m_100"),c2o=o(" \u2014 "),tD=a("a"),f2o=o("M2M100Config"),g2o=o(" (M2M100 model)"),h2o=l(),_h=a("li"),Yue=a("strong"),u2o=o("marian"),p2o=o(" \u2014 "),aD=a("a"),_2o=o("MarianConfig"),b2o=o(" (Marian model)"),v2o=l(),bh=a("li"),Zue=a("strong"),F2o=o("markuplm"),T2o=o(" \u2014 "),nD=a("a"),M2o=o("MarkupLMConfig"),E2o=o(" (MarkupLM model)"),C2o=l(),vh=a("li"),Kue=a("strong"),w2o=o("maskformer"),A2o=o(" \u2014 "),sD=a("a"),L2o=o("MaskFormerConfig"),y2o=o(" (MaskFormer model)"),x2o=l(),Fh=a("li"),epe=a("strong"),$2o=o("mbart"),k2o=o(" \u2014 "),lD=a("a"),S2o=o("MBartConfig"),R2o=o(" (mBART model)"),P2o=l(),Th=a("li"),ope=a("strong"),B2o=o("mctct"),I2o=o(" \u2014 "),iD=a("a"),N2o=o("MCTCTConfig"),q2o=o(" (M-CTC-T model)"),j2o=l(),Mh=a("li"),rpe=a("strong"),D2o=o("megatron-bert"),G2o=o(" \u2014 "),dD=a("a"),O2o=o("MegatronBertConfig"),V2o=o(" (Megatron-BERT model)"),X2o=l(),Eh=a("li"),tpe=a("strong"),z2o=o("mobilebert"),Q2o=o(" \u2014 "),mD=a("a"),W2o=o("MobileBertConfig"),U2o=o(" (MobileBERT model)"),H2o=l(),Ch=a("li"),ape=a("strong"),J2o=o("mobilenet_v2"),Y2o=o(" \u2014 "),cD=a("a"),Z2o=o("MobileNetV2Config"),K2o=o(" (MobileNetV2 model)"),ebo=l(),wh=a("li"),npe=a("strong"),obo=o("mobilevit"),rbo=o(" \u2014 "),fD=a("a"),tbo=o("MobileViTConfig"),abo=o(" (MobileViT model)"),nbo=l(),Ah=a("li"),spe=a("strong"),sbo=o("mpnet"),lbo=o(" \u2014 "),gD=a("a"),ibo=o("MPNetConfig"),dbo=o(" (MPNet model)"),mbo=l(),Lh=a("li"),lpe=a("strong"),cbo=o("mt5"),fbo=o(" \u2014 "),hD=a("a"),gbo=o("MT5Config"),hbo=o(" (MT5 model)"),ubo=l(),yh=a("li"),ipe=a("strong"),pbo=o("mvp"),_bo=o(" \u2014 "),uD=a("a"),bbo=o("MvpConfig"),vbo=o(" (MVP model)"),Fbo=l(),xh=a("li"),dpe=a("strong"),Tbo=o("nezha"),Mbo=o(" \u2014 "),pD=a("a"),Ebo=o("NezhaConfig"),Cbo=o(" (Nezha model)"),wbo=l(),$h=a("li"),mpe=a("strong"),Abo=o("nystromformer"),Lbo=o(" \u2014 "),_D=a("a"),ybo=o("NystromformerConfig"),xbo=o(" (Nystr\xF6mformer model)"),$bo=l(),kh=a("li"),cpe=a("strong"),kbo=o("openai-gpt"),Sbo=o(" \u2014 "),bD=a("a"),Rbo=o("OpenAIGPTConfig"),Pbo=o(" (OpenAI GPT model)"),Bbo=l(),Sh=a("li"),fpe=a("strong"),Ibo=o("opt"),Nbo=o(" \u2014 "),vD=a("a"),qbo=o("OPTConfig"),jbo=o(" (OPT model)"),Dbo=l(),Rh=a("li"),gpe=a("strong"),Gbo=o("owlvit"),Obo=o(" \u2014 "),FD=a("a"),Vbo=o("OwlViTConfig"),Xbo=o(" (OWL-ViT model)"),zbo=l(),Ph=a("li"),hpe=a("strong"),Qbo=o("pegasus"),Wbo=o(" \u2014 "),TD=a("a"),Ubo=o("PegasusConfig"),Hbo=o(" (Pegasus model)"),Jbo=l(),Bh=a("li"),upe=a("strong"),Ybo=o("pegasus_x"),Zbo=o(" \u2014 "),MD=a("a"),Kbo=o("PegasusXConfig"),evo=o(" (PEGASUS-X model)"),ovo=l(),Ih=a("li"),ppe=a("strong"),rvo=o("perceiver"),tvo=o(" \u2014 "),ED=a("a"),avo=o("PerceiverConfig"),nvo=o(" (Perceiver model)"),svo=l(),Nh=a("li"),_pe=a("strong"),lvo=o("plbart"),ivo=o(" \u2014 "),CD=a("a"),dvo=o("PLBartConfig"),mvo=o(" (PLBart model)"),cvo=l(),qh=a("li"),bpe=a("strong"),fvo=o("poolformer"),gvo=o(" \u2014 "),wD=a("a"),hvo=o("PoolFormerConfig"),uvo=o(" (PoolFormer model)"),pvo=l(),jh=a("li"),vpe=a("strong"),_vo=o("prophetnet"),bvo=o(" \u2014 "),AD=a("a"),vvo=o("ProphetNetConfig"),Fvo=o(" (ProphetNet model)"),Tvo=l(),Dh=a("li"),Fpe=a("strong"),Mvo=o("qdqbert"),Evo=o(" \u2014 "),LD=a("a"),Cvo=o("QDQBertConfig"),wvo=o(" (QDQBert model)"),Avo=l(),Gh=a("li"),Tpe=a("strong"),Lvo=o("rag"),yvo=o(" \u2014 "),yD=a("a"),xvo=o("RagConfig"),$vo=o(" (RAG model)"),kvo=l(),Oh=a("li"),Mpe=a("strong"),Svo=o("realm"),Rvo=o(" \u2014 "),xD=a("a"),Pvo=o("RealmConfig"),Bvo=o(" (REALM model)"),Ivo=l(),Vh=a("li"),Epe=a("strong"),Nvo=o("reformer"),qvo=o(" \u2014 "),$D=a("a"),jvo=o("ReformerConfig"),Dvo=o(" (Reformer model)"),Gvo=l(),Xh=a("li"),Cpe=a("strong"),Ovo=o("regnet"),Vvo=o(" \u2014 "),kD=a("a"),Xvo=o("RegNetConfig"),zvo=o(" (RegNet model)"),Qvo=l(),zh=a("li"),wpe=a("strong"),Wvo=o("rembert"),Uvo=o(" \u2014 "),SD=a("a"),Hvo=o("RemBertConfig"),Jvo=o(" (RemBERT model)"),Yvo=l(),Qh=a("li"),Ape=a("strong"),Zvo=o("resnet"),Kvo=o(" \u2014 "),RD=a("a"),eFo=o("ResNetConfig"),oFo=o(" (ResNet model)"),rFo=l(),Wh=a("li"),Lpe=a("strong"),tFo=o("retribert"),aFo=o(" \u2014 "),PD=a("a"),nFo=o("RetriBertConfig"),sFo=o(" (RetriBERT model)"),lFo=l(),Uh=a("li"),ype=a("strong"),iFo=o("roberta"),dFo=o(" \u2014 "),BD=a("a"),mFo=o("RobertaConfig"),cFo=o(" (RoBERTa model)"),fFo=l(),Hh=a("li"),xpe=a("strong"),gFo=o("roc_bert"),hFo=o(" \u2014 "),ID=a("a"),uFo=o("RoCBertConfig"),pFo=o(" (RoCBert model)"),_Fo=l(),Jh=a("li"),$pe=a("strong"),bFo=o("roformer"),vFo=o(" \u2014 "),ND=a("a"),FFo=o("RoFormerConfig"),TFo=o(" (RoFormer model)"),MFo=l(),Yh=a("li"),kpe=a("strong"),EFo=o("segformer"),CFo=o(" \u2014 "),qD=a("a"),wFo=o("SegformerConfig"),AFo=o(" (SegFormer model)"),LFo=l(),Zh=a("li"),Spe=a("strong"),yFo=o("sew"),xFo=o(" \u2014 "),jD=a("a"),$Fo=o("SEWConfig"),kFo=o(" (SEW model)"),SFo=l(),Kh=a("li"),Rpe=a("strong"),RFo=o("sew-d"),PFo=o(" \u2014 "),DD=a("a"),BFo=o("SEWDConfig"),IFo=o(" (SEW-D model)"),NFo=l(),eu=a("li"),Ppe=a("strong"),qFo=o("speech-encoder-decoder"),jFo=o(" \u2014 "),GD=a("a"),DFo=o("SpeechEncoderDecoderConfig"),GFo=o(" (Speech Encoder decoder model)"),OFo=l(),ou=a("li"),Bpe=a("strong"),VFo=o("speech_to_text"),XFo=o(" \u2014 "),OD=a("a"),zFo=o("Speech2TextConfig"),QFo=o(" (Speech2Text model)"),WFo=l(),ru=a("li"),Ipe=a("strong"),UFo=o("speech_to_text_2"),HFo=o(" \u2014 "),VD=a("a"),JFo=o("Speech2Text2Config"),YFo=o(" (Speech2Text2 model)"),ZFo=l(),tu=a("li"),Npe=a("strong"),KFo=o("splinter"),eTo=o(" \u2014 "),XD=a("a"),oTo=o("SplinterConfig"),rTo=o(" (Splinter model)"),tTo=l(),au=a("li"),qpe=a("strong"),aTo=o("squeezebert"),nTo=o(" \u2014 "),zD=a("a"),sTo=o("SqueezeBertConfig"),lTo=o(" (SqueezeBERT model)"),iTo=l(),nu=a("li"),jpe=a("strong"),dTo=o("swin"),mTo=o(" \u2014 "),QD=a("a"),cTo=o("SwinConfig"),fTo=o(" (Swin Transformer model)"),gTo=l(),su=a("li"),Dpe=a("strong"),hTo=o("swinv2"),uTo=o(" \u2014 "),WD=a("a"),pTo=o("Swinv2Config"),_To=o(" (Swin Transformer V2 model)"),bTo=l(),lu=a("li"),Gpe=a("strong"),vTo=o("t5"),FTo=o(" \u2014 "),UD=a("a"),TTo=o("T5Config"),MTo=o(" (T5 model)"),ETo=l(),iu=a("li"),Ope=a("strong"),CTo=o("table-transformer"),wTo=o(" \u2014 "),HD=a("a"),ATo=o("TableTransformerConfig"),LTo=o(" (Table Transformer model)"),yTo=l(),du=a("li"),Vpe=a("strong"),xTo=o("tapas"),$To=o(" \u2014 "),JD=a("a"),kTo=o("TapasConfig"),STo=o(" (TAPAS model)"),RTo=l(),mu=a("li"),Xpe=a("strong"),PTo=o("time_series_transformer"),BTo=o(" \u2014 "),YD=a("a"),ITo=o("TimeSeriesTransformerConfig"),NTo=o(" (Time Series Transformer model)"),qTo=l(),cu=a("li"),zpe=a("strong"),jTo=o("trajectory_transformer"),DTo=o(" \u2014 "),ZD=a("a"),GTo=o("TrajectoryTransformerConfig"),OTo=o(" (Trajectory Transformer model)"),VTo=l(),fu=a("li"),Qpe=a("strong"),XTo=o("transfo-xl"),zTo=o(" \u2014 "),KD=a("a"),QTo=o("TransfoXLConfig"),WTo=o(" (Transformer-XL model)"),UTo=l(),gu=a("li"),Wpe=a("strong"),HTo=o("trocr"),JTo=o(" \u2014 "),eG=a("a"),YTo=o("TrOCRConfig"),ZTo=o(" (TrOCR model)"),KTo=l(),hu=a("li"),Upe=a("strong"),eMo=o("unispeech"),oMo=o(" \u2014 "),oG=a("a"),rMo=o("UniSpeechConfig"),tMo=o(" (UniSpeech model)"),aMo=l(),uu=a("li"),Hpe=a("strong"),nMo=o("unispeech-sat"),sMo=o(" \u2014 "),rG=a("a"),lMo=o("UniSpeechSatConfig"),iMo=o(" (UniSpeechSat model)"),dMo=l(),pu=a("li"),Jpe=a("strong"),mMo=o("van"),cMo=o(" \u2014 "),tG=a("a"),fMo=o("VanConfig"),gMo=o(" (VAN model)"),hMo=l(),_u=a("li"),Ype=a("strong"),uMo=o("videomae"),pMo=o(" \u2014 "),aG=a("a"),_Mo=o("VideoMAEConfig"),bMo=o(" (VideoMAE model)"),vMo=l(),bu=a("li"),Zpe=a("strong"),FMo=o("vilt"),TMo=o(" \u2014 "),nG=a("a"),MMo=o("ViltConfig"),EMo=o(" (ViLT model)"),CMo=l(),vu=a("li"),Kpe=a("strong"),wMo=o("vision-encoder-decoder"),AMo=o(" \u2014 "),sG=a("a"),LMo=o("VisionEncoderDecoderConfig"),yMo=o(" (Vision Encoder decoder model)"),xMo=l(),Fu=a("li"),e_e=a("strong"),$Mo=o("vision-text-dual-encoder"),kMo=o(" \u2014 "),lG=a("a"),SMo=o("VisionTextDualEncoderConfig"),RMo=o(" (VisionTextDualEncoder model)"),PMo=l(),Tu=a("li"),o_e=a("strong"),BMo=o("visual_bert"),IMo=o(" \u2014 "),iG=a("a"),NMo=o("VisualBertConfig"),qMo=o(" (VisualBERT model)"),jMo=l(),Mu=a("li"),r_e=a("strong"),DMo=o("vit"),GMo=o(" \u2014 "),dG=a("a"),OMo=o("ViTConfig"),VMo=o(" (ViT model)"),XMo=l(),Eu=a("li"),t_e=a("strong"),zMo=o("vit_mae"),QMo=o(" \u2014 "),mG=a("a"),WMo=o("ViTMAEConfig"),UMo=o(" (ViTMAE model)"),HMo=l(),Cu=a("li"),a_e=a("strong"),JMo=o("vit_msn"),YMo=o(" \u2014 "),cG=a("a"),ZMo=o("ViTMSNConfig"),KMo=o(" (ViTMSN model)"),eEo=l(),wu=a("li"),n_e=a("strong"),oEo=o("wav2vec2"),rEo=o(" \u2014 "),fG=a("a"),tEo=o("Wav2Vec2Config"),aEo=o(" (Wav2Vec2 model)"),nEo=l(),Au=a("li"),s_e=a("strong"),sEo=o("wav2vec2-conformer"),lEo=o(" \u2014 "),gG=a("a"),iEo=o("Wav2Vec2ConformerConfig"),dEo=o(" (Wav2Vec2-Conformer model)"),mEo=l(),Lu=a("li"),l_e=a("strong"),cEo=o("wavlm"),fEo=o(" \u2014 "),hG=a("a"),gEo=o("WavLMConfig"),hEo=o(" (WavLM model)"),uEo=l(),yu=a("li"),i_e=a("strong"),pEo=o("whisper"),_Eo=o(" \u2014 "),uG=a("a"),bEo=o("WhisperConfig"),vEo=o(" (Whisper model)"),FEo=l(),xu=a("li"),d_e=a("strong"),TEo=o("xclip"),MEo=o(" \u2014 "),pG=a("a"),EEo=o("XCLIPConfig"),CEo=o(" (X-CLIP model)"),wEo=l(),$u=a("li"),m_e=a("strong"),AEo=o("xglm"),LEo=o(" \u2014 "),_G=a("a"),yEo=o("XGLMConfig"),xEo=o(" (XGLM model)"),$Eo=l(),ku=a("li"),c_e=a("strong"),kEo=o("xlm"),SEo=o(" \u2014 "),bG=a("a"),REo=o("XLMConfig"),PEo=o(" (XLM model)"),BEo=l(),Su=a("li"),f_e=a("strong"),IEo=o("xlm-prophetnet"),NEo=o(" \u2014 "),vG=a("a"),qEo=o("XLMProphetNetConfig"),jEo=o(" (XLM-ProphetNet model)"),DEo=l(),Ru=a("li"),g_e=a("strong"),GEo=o("xlm-roberta"),OEo=o(" \u2014 "),FG=a("a"),VEo=o("XLMRobertaConfig"),XEo=o(" (XLM-RoBERTa model)"),zEo=l(),Pu=a("li"),h_e=a("strong"),QEo=o("xlm-roberta-xl"),WEo=o(" \u2014 "),TG=a("a"),UEo=o("XLMRobertaXLConfig"),HEo=o(" (XLM-RoBERTa-XL model)"),JEo=l(),Bu=a("li"),u_e=a("strong"),YEo=o("xlnet"),ZEo=o(" \u2014 "),MG=a("a"),KEo=o("XLNetConfig"),e4o=o(" (XLNet model)"),o4o=l(),Iu=a("li"),p_e=a("strong"),r4o=o("yolos"),t4o=o(" \u2014 "),EG=a("a"),a4o=o("YolosConfig"),n4o=o(" (YOLOS model)"),s4o=l(),Nu=a("li"),__e=a("strong"),l4o=o("yoso"),i4o=o(" \u2014 "),CG=a("a"),d4o=o("YosoConfig"),m4o=o(" (YOSO model)"),c4o=l(),F(qu.$$.fragment),f4o=l(),ju=a("div"),F(yk.$$.fragment),g4o=l(),b_e=a("p"),h4o=o("Register a new configuration for this class."),nio=l(),Id=a("h2"),Du=a("a"),v_e=a("span"),F(xk.$$.fragment),u4o=l(),F_e=a("span"),p4o=o("AutoTokenizer"),sio=l(),Io=a("div"),F($k.$$.fragment),_4o=l(),kk=a("p"),b4o=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),wG=a("a"),v4o=o("AutoTokenizer.from_pretrained()"),F4o=o(" class method."),T4o=l(),Sk=a("p"),M4o=o("This class cannot be instantiated directly using "),T_e=a("code"),E4o=o("__init__()"),C4o=o(" (throws an error)."),w4o=l(),Xr=a("div"),F(Rk.$$.fragment),A4o=l(),M_e=a("p"),L4o=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),y4o=l(),mn=a("p"),x4o=o("The tokenizer class to instantiate is selected based on the "),E_e=a("code"),$4o=o("model_type"),k4o=o(` property of the config object (either
passed as an argument or loaded from `),C_e=a("code"),S4o=o("pretrained_model_name_or_path"),R4o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w_e=a("code"),P4o=o("pretrained_model_name_or_path"),B4o=o(":"),I4o=l(),k=a("ul"),Ms=a("li"),A_e=a("strong"),N4o=o("albert"),q4o=o(" \u2014 "),AG=a("a"),j4o=o("AlbertTokenizer"),D4o=o(" or "),LG=a("a"),G4o=o("AlbertTokenizerFast"),O4o=o(" (ALBERT model)"),V4o=l(),Es=a("li"),L_e=a("strong"),X4o=o("bart"),z4o=o(" \u2014 "),yG=a("a"),Q4o=o("BartTokenizer"),W4o=o(" or "),xG=a("a"),U4o=o("BartTokenizerFast"),H4o=o(" (BART model)"),J4o=l(),Cs=a("li"),y_e=a("strong"),Y4o=o("barthez"),Z4o=o(" \u2014 "),$G=a("a"),K4o=o("BarthezTokenizer"),eCo=o(" or "),kG=a("a"),oCo=o("BarthezTokenizerFast"),rCo=o(" (BARThez model)"),tCo=l(),Gu=a("li"),x_e=a("strong"),aCo=o("bartpho"),nCo=o(" \u2014 "),SG=a("a"),sCo=o("BartphoTokenizer"),lCo=o(" (BARTpho model)"),iCo=l(),ws=a("li"),$_e=a("strong"),dCo=o("bert"),mCo=o(" \u2014 "),RG=a("a"),cCo=o("BertTokenizer"),fCo=o(" or "),PG=a("a"),gCo=o("BertTokenizerFast"),hCo=o(" (BERT model)"),uCo=l(),Ou=a("li"),k_e=a("strong"),pCo=o("bert-generation"),_Co=o(" \u2014 "),BG=a("a"),bCo=o("BertGenerationTokenizer"),vCo=o(" (Bert Generation model)"),FCo=l(),Vu=a("li"),S_e=a("strong"),TCo=o("bert-japanese"),MCo=o(" \u2014 "),IG=a("a"),ECo=o("BertJapaneseTokenizer"),CCo=o(" (BertJapanese model)"),wCo=l(),Xu=a("li"),R_e=a("strong"),ACo=o("bertweet"),LCo=o(" \u2014 "),NG=a("a"),yCo=o("BertweetTokenizer"),xCo=o(" (BERTweet model)"),$Co=l(),As=a("li"),P_e=a("strong"),kCo=o("big_bird"),SCo=o(" \u2014 "),qG=a("a"),RCo=o("BigBirdTokenizer"),PCo=o(" or "),jG=a("a"),BCo=o("BigBirdTokenizerFast"),ICo=o(" (BigBird model)"),NCo=l(),Ls=a("li"),B_e=a("strong"),qCo=o("bigbird_pegasus"),jCo=o(" \u2014 "),DG=a("a"),DCo=o("PegasusTokenizer"),GCo=o(" or "),GG=a("a"),OCo=o("PegasusTokenizerFast"),VCo=o(" (BigBird-Pegasus model)"),XCo=l(),ys=a("li"),I_e=a("strong"),zCo=o("blenderbot"),QCo=o(" \u2014 "),OG=a("a"),WCo=o("BlenderbotTokenizer"),UCo=o(" or "),VG=a("a"),HCo=o("BlenderbotTokenizerFast"),JCo=o(" (Blenderbot model)"),YCo=l(),zu=a("li"),N_e=a("strong"),ZCo=o("blenderbot-small"),KCo=o(" \u2014 "),XG=a("a"),e3o=o("BlenderbotSmallTokenizer"),o3o=o(" (BlenderbotSmall model)"),r3o=l(),Qu=a("li"),q_e=a("strong"),t3o=o("bloom"),a3o=o(" \u2014 "),zG=a("a"),n3o=o("BloomTokenizerFast"),s3o=o(" (BLOOM model)"),l3o=l(),Wu=a("li"),j_e=a("strong"),i3o=o("byt5"),d3o=o(" \u2014 "),QG=a("a"),m3o=o("ByT5Tokenizer"),c3o=o(" (ByT5 model)"),f3o=l(),xs=a("li"),D_e=a("strong"),g3o=o("camembert"),h3o=o(" \u2014 "),WG=a("a"),u3o=o("CamembertTokenizer"),p3o=o(" or "),UG=a("a"),_3o=o("CamembertTokenizerFast"),b3o=o(" (CamemBERT model)"),v3o=l(),Uu=a("li"),G_e=a("strong"),F3o=o("canine"),T3o=o(" \u2014 "),HG=a("a"),M3o=o("CanineTokenizer"),E3o=o(" (CANINE model)"),C3o=l(),$s=a("li"),O_e=a("strong"),w3o=o("clip"),A3o=o(" \u2014 "),JG=a("a"),L3o=o("CLIPTokenizer"),y3o=o(" or "),YG=a("a"),x3o=o("CLIPTokenizerFast"),$3o=o(" (CLIP model)"),k3o=l(),ks=a("li"),V_e=a("strong"),S3o=o("clipseg"),R3o=o(" \u2014 "),ZG=a("a"),P3o=o("CLIPTokenizer"),B3o=o(" or "),KG=a("a"),I3o=o("CLIPTokenizerFast"),N3o=o(" (CLIPSeg model)"),q3o=l(),Ss=a("li"),X_e=a("strong"),j3o=o("codegen"),D3o=o(" \u2014 "),eO=a("a"),G3o=o("CodeGenTokenizer"),O3o=o(" or "),oO=a("a"),V3o=o("CodeGenTokenizerFast"),X3o=o(" (CodeGen model)"),z3o=l(),Rs=a("li"),z_e=a("strong"),Q3o=o("convbert"),W3o=o(" \u2014 "),rO=a("a"),U3o=o("ConvBertTokenizer"),H3o=o(" or "),tO=a("a"),J3o=o("ConvBertTokenizerFast"),Y3o=o(" (ConvBERT model)"),Z3o=l(),Ps=a("li"),Q_e=a("strong"),K3o=o("cpm"),e5o=o(" \u2014 "),aO=a("a"),o5o=o("CpmTokenizer"),r5o=o(" or "),nO=a("a"),t5o=o("CpmTokenizerFast"),a5o=o(" (CPM model)"),n5o=l(),Hu=a("li"),W_e=a("strong"),s5o=o("ctrl"),l5o=o(" \u2014 "),sO=a("a"),i5o=o("CTRLTokenizer"),d5o=o(" (CTRL model)"),m5o=l(),Bs=a("li"),U_e=a("strong"),c5o=o("data2vec-text"),f5o=o(" \u2014 "),lO=a("a"),g5o=o("RobertaTokenizer"),h5o=o(" or "),iO=a("a"),u5o=o("RobertaTokenizerFast"),p5o=o(" (Data2VecText model)"),_5o=l(),Is=a("li"),H_e=a("strong"),b5o=o("deberta"),v5o=o(" \u2014 "),dO=a("a"),F5o=o("DebertaTokenizer"),T5o=o(" or "),mO=a("a"),M5o=o("DebertaTokenizerFast"),E5o=o(" (DeBERTa model)"),C5o=l(),Ns=a("li"),J_e=a("strong"),w5o=o("deberta-v2"),A5o=o(" \u2014 "),cO=a("a"),L5o=o("DebertaV2Tokenizer"),y5o=o(" or "),fO=a("a"),x5o=o("DebertaV2TokenizerFast"),$5o=o(" (DeBERTa-v2 model)"),k5o=l(),qs=a("li"),Y_e=a("strong"),S5o=o("distilbert"),R5o=o(" \u2014 "),gO=a("a"),P5o=o("DistilBertTokenizer"),B5o=o(" or "),hO=a("a"),I5o=o("DistilBertTokenizerFast"),N5o=o(" (DistilBERT model)"),q5o=l(),js=a("li"),Z_e=a("strong"),j5o=o("dpr"),D5o=o(" \u2014 "),uO=a("a"),G5o=o("DPRQuestionEncoderTokenizer"),O5o=o(" or "),pO=a("a"),V5o=o("DPRQuestionEncoderTokenizerFast"),X5o=o(" (DPR model)"),z5o=l(),Ds=a("li"),K_e=a("strong"),Q5o=o("electra"),W5o=o(" \u2014 "),_O=a("a"),U5o=o("ElectraTokenizer"),H5o=o(" or "),bO=a("a"),J5o=o("ElectraTokenizerFast"),Y5o=o(" (ELECTRA model)"),Z5o=l(),Gs=a("li"),e1e=a("strong"),K5o=o("ernie"),e0o=o(" \u2014 "),vO=a("a"),o0o=o("BertTokenizer"),r0o=o(" or "),FO=a("a"),t0o=o("BertTokenizerFast"),a0o=o(" (ERNIE model)"),n0o=l(),Ju=a("li"),o1e=a("strong"),s0o=o("esm"),l0o=o(" \u2014 "),TO=a("a"),i0o=o("EsmTokenizer"),d0o=o(" (ESM model)"),m0o=l(),Yu=a("li"),r1e=a("strong"),c0o=o("flaubert"),f0o=o(" \u2014 "),MO=a("a"),g0o=o("FlaubertTokenizer"),h0o=o(" (FlauBERT model)"),u0o=l(),Os=a("li"),t1e=a("strong"),p0o=o("fnet"),_0o=o(" \u2014 "),EO=a("a"),b0o=o("FNetTokenizer"),v0o=o(" or "),CO=a("a"),F0o=o("FNetTokenizerFast"),T0o=o(" (FNet model)"),M0o=l(),Zu=a("li"),a1e=a("strong"),E0o=o("fsmt"),C0o=o(" \u2014 "),wO=a("a"),w0o=o("FSMTTokenizer"),A0o=o(" (FairSeq Machine-Translation model)"),L0o=l(),Vs=a("li"),n1e=a("strong"),y0o=o("funnel"),x0o=o(" \u2014 "),AO=a("a"),$0o=o("FunnelTokenizer"),k0o=o(" or "),LO=a("a"),S0o=o("FunnelTokenizerFast"),R0o=o(" (Funnel Transformer model)"),P0o=l(),Xs=a("li"),s1e=a("strong"),B0o=o("gpt2"),I0o=o(" \u2014 "),yO=a("a"),N0o=o("GPT2Tokenizer"),q0o=o(" or "),xO=a("a"),j0o=o("GPT2TokenizerFast"),D0o=o(" (OpenAI GPT-2 model)"),G0o=l(),zs=a("li"),l1e=a("strong"),O0o=o("gpt_neo"),V0o=o(" \u2014 "),$O=a("a"),X0o=o("GPT2Tokenizer"),z0o=o(" or "),kO=a("a"),Q0o=o("GPT2TokenizerFast"),W0o=o(" (GPT Neo model)"),U0o=l(),Ku=a("li"),i1e=a("strong"),H0o=o("gpt_neox"),J0o=o(" \u2014 "),SO=a("a"),Y0o=o("GPTNeoXTokenizerFast"),Z0o=o(" (GPT NeoX model)"),K0o=l(),ep=a("li"),d1e=a("strong"),ewo=o("gpt_neox_japanese"),owo=o(" \u2014 "),RO=a("a"),rwo=o("GPTNeoXJapaneseTokenizer"),two=o(" (GPT NeoX Japanese model)"),awo=l(),Qs=a("li"),m1e=a("strong"),nwo=o("gptj"),swo=o(" \u2014 "),PO=a("a"),lwo=o("GPT2Tokenizer"),iwo=o(" or "),BO=a("a"),dwo=o("GPT2TokenizerFast"),mwo=o(" (GPT-J model)"),cwo=l(),Ws=a("li"),c1e=a("strong"),fwo=o("groupvit"),gwo=o(" \u2014 "),IO=a("a"),hwo=o("CLIPTokenizer"),uwo=o(" or "),NO=a("a"),pwo=o("CLIPTokenizerFast"),_wo=o(" (GroupViT model)"),bwo=l(),Us=a("li"),f1e=a("strong"),vwo=o("herbert"),Fwo=o(" \u2014 "),qO=a("a"),Two=o("HerbertTokenizer"),Mwo=o(" or "),jO=a("a"),Ewo=o("HerbertTokenizerFast"),Cwo=o(" (HerBERT model)"),wwo=l(),op=a("li"),g1e=a("strong"),Awo=o("hubert"),Lwo=o(" \u2014 "),DO=a("a"),ywo=o("Wav2Vec2CTCTokenizer"),xwo=o(" (Hubert model)"),$wo=l(),Hs=a("li"),h1e=a("strong"),kwo=o("ibert"),Swo=o(" \u2014 "),GO=a("a"),Rwo=o("RobertaTokenizer"),Pwo=o(" or "),OO=a("a"),Bwo=o("RobertaTokenizerFast"),Iwo=o(" (I-BERT model)"),Nwo=l(),rp=a("li"),u1e=a("strong"),qwo=o("jukebox"),jwo=o(" \u2014 "),VO=a("a"),Dwo=o("JukeboxTokenizer"),Gwo=o(" (Jukebox model)"),Owo=l(),Js=a("li"),p1e=a("strong"),Vwo=o("layoutlm"),Xwo=o(" \u2014 "),XO=a("a"),zwo=o("LayoutLMTokenizer"),Qwo=o(" or "),zO=a("a"),Wwo=o("LayoutLMTokenizerFast"),Uwo=o(" (LayoutLM model)"),Hwo=l(),Ys=a("li"),_1e=a("strong"),Jwo=o("layoutlmv2"),Ywo=o(" \u2014 "),QO=a("a"),Zwo=o("LayoutLMv2Tokenizer"),Kwo=o(" or "),WO=a("a"),eAo=o("LayoutLMv2TokenizerFast"),oAo=o(" (LayoutLMv2 model)"),rAo=l(),Zs=a("li"),b1e=a("strong"),tAo=o("layoutlmv3"),aAo=o(" \u2014 "),UO=a("a"),nAo=o("LayoutLMv3Tokenizer"),sAo=o(" or "),HO=a("a"),lAo=o("LayoutLMv3TokenizerFast"),iAo=o(" (LayoutLMv3 model)"),dAo=l(),Ks=a("li"),v1e=a("strong"),mAo=o("layoutxlm"),cAo=o(" \u2014 "),JO=a("a"),fAo=o("LayoutXLMTokenizer"),gAo=o(" or "),YO=a("a"),hAo=o("LayoutXLMTokenizerFast"),uAo=o(" (LayoutXLM model)"),pAo=l(),el=a("li"),F1e=a("strong"),_Ao=o("led"),bAo=o(" \u2014 "),ZO=a("a"),vAo=o("LEDTokenizer"),FAo=o(" or "),KO=a("a"),TAo=o("LEDTokenizerFast"),MAo=o(" (LED model)"),EAo=l(),ol=a("li"),T1e=a("strong"),CAo=o("lilt"),wAo=o(" \u2014 "),eV=a("a"),AAo=o("LayoutLMv3Tokenizer"),LAo=o(" or "),oV=a("a"),yAo=o("LayoutLMv3TokenizerFast"),xAo=o(" (LiLT model)"),$Ao=l(),rl=a("li"),M1e=a("strong"),kAo=o("longformer"),SAo=o(" \u2014 "),rV=a("a"),RAo=o("LongformerTokenizer"),PAo=o(" or "),tV=a("a"),BAo=o("LongformerTokenizerFast"),IAo=o(" (Longformer model)"),NAo=l(),tl=a("li"),E1e=a("strong"),qAo=o("longt5"),jAo=o(" \u2014 "),aV=a("a"),DAo=o("T5Tokenizer"),GAo=o(" or "),nV=a("a"),OAo=o("T5TokenizerFast"),VAo=o(" (LongT5 model)"),XAo=l(),tp=a("li"),C1e=a("strong"),zAo=o("luke"),QAo=o(" \u2014 "),sV=a("a"),WAo=o("LukeTokenizer"),UAo=o(" (LUKE model)"),HAo=l(),al=a("li"),w1e=a("strong"),JAo=o("lxmert"),YAo=o(" \u2014 "),lV=a("a"),ZAo=o("LxmertTokenizer"),KAo=o(" or "),iV=a("a"),e6o=o("LxmertTokenizerFast"),o6o=o(" (LXMERT model)"),r6o=l(),ap=a("li"),A1e=a("strong"),t6o=o("m2m_100"),a6o=o(" \u2014 "),dV=a("a"),n6o=o("M2M100Tokenizer"),s6o=o(" (M2M100 model)"),l6o=l(),np=a("li"),L1e=a("strong"),i6o=o("marian"),d6o=o(" \u2014 "),mV=a("a"),m6o=o("MarianTokenizer"),c6o=o(" (Marian model)"),f6o=l(),nl=a("li"),y1e=a("strong"),g6o=o("mbart"),h6o=o(" \u2014 "),cV=a("a"),u6o=o("MBartTokenizer"),p6o=o(" or "),fV=a("a"),_6o=o("MBartTokenizerFast"),b6o=o(" (mBART model)"),v6o=l(),sl=a("li"),x1e=a("strong"),F6o=o("mbart50"),T6o=o(" \u2014 "),gV=a("a"),M6o=o("MBart50Tokenizer"),E6o=o(" or "),hV=a("a"),C6o=o("MBart50TokenizerFast"),w6o=o(" (mBART-50 model)"),A6o=l(),ll=a("li"),$1e=a("strong"),L6o=o("megatron-bert"),y6o=o(" \u2014 "),uV=a("a"),x6o=o("BertTokenizer"),$6o=o(" or "),pV=a("a"),k6o=o("BertTokenizerFast"),S6o=o(" (Megatron-BERT model)"),R6o=l(),sp=a("li"),k1e=a("strong"),P6o=o("mluke"),B6o=o(" \u2014 "),_V=a("a"),I6o=o("MLukeTokenizer"),N6o=o(" (mLUKE model)"),q6o=l(),il=a("li"),S1e=a("strong"),j6o=o("mobilebert"),D6o=o(" \u2014 "),bV=a("a"),G6o=o("MobileBertTokenizer"),O6o=o(" or "),vV=a("a"),V6o=o("MobileBertTokenizerFast"),X6o=o(" (MobileBERT model)"),z6o=l(),dl=a("li"),R1e=a("strong"),Q6o=o("mpnet"),W6o=o(" \u2014 "),FV=a("a"),U6o=o("MPNetTokenizer"),H6o=o(" or "),TV=a("a"),J6o=o("MPNetTokenizerFast"),Y6o=o(" (MPNet model)"),Z6o=l(),ml=a("li"),P1e=a("strong"),K6o=o("mt5"),e7o=o(" \u2014 "),MV=a("a"),o7o=o("MT5Tokenizer"),r7o=o(" or "),EV=a("a"),t7o=o("MT5TokenizerFast"),a7o=o(" (MT5 model)"),n7o=l(),cl=a("li"),B1e=a("strong"),s7o=o("mvp"),l7o=o(" \u2014 "),CV=a("a"),i7o=o("MvpTokenizer"),d7o=o(" or "),wV=a("a"),m7o=o("MvpTokenizerFast"),c7o=o(" (MVP model)"),f7o=l(),fl=a("li"),I1e=a("strong"),g7o=o("nezha"),h7o=o(" \u2014 "),AV=a("a"),u7o=o("BertTokenizer"),p7o=o(" or "),LV=a("a"),_7o=o("BertTokenizerFast"),b7o=o(" (Nezha model)"),v7o=l(),gl=a("li"),N1e=a("strong"),F7o=o("nllb"),T7o=o(" \u2014 "),yV=a("a"),M7o=o("NllbTokenizer"),E7o=o(" or "),xV=a("a"),C7o=o("NllbTokenizerFast"),w7o=o(" (NLLB model)"),A7o=l(),hl=a("li"),q1e=a("strong"),L7o=o("nystromformer"),y7o=o(" \u2014 "),$V=a("a"),x7o=o("AlbertTokenizer"),$7o=o(" or "),kV=a("a"),k7o=o("AlbertTokenizerFast"),S7o=o(" (Nystr\xF6mformer model)"),R7o=l(),ul=a("li"),j1e=a("strong"),P7o=o("openai-gpt"),B7o=o(" \u2014 "),SV=a("a"),I7o=o("OpenAIGPTTokenizer"),N7o=o(" or "),RV=a("a"),q7o=o("OpenAIGPTTokenizerFast"),j7o=o(" (OpenAI GPT model)"),D7o=l(),lp=a("li"),D1e=a("strong"),G7o=o("opt"),O7o=o(" \u2014 "),PV=a("a"),V7o=o("GPT2Tokenizer"),X7o=o(" (OPT model)"),z7o=l(),pl=a("li"),G1e=a("strong"),Q7o=o("owlvit"),W7o=o(" \u2014 "),BV=a("a"),U7o=o("CLIPTokenizer"),H7o=o(" or "),IV=a("a"),J7o=o("CLIPTokenizerFast"),Y7o=o(" (OWL-ViT model)"),Z7o=l(),_l=a("li"),O1e=a("strong"),K7o=o("pegasus"),e8o=o(" \u2014 "),NV=a("a"),o8o=o("PegasusTokenizer"),r8o=o(" or "),qV=a("a"),t8o=o("PegasusTokenizerFast"),a8o=o(" (Pegasus model)"),n8o=l(),bl=a("li"),V1e=a("strong"),s8o=o("pegasus_x"),l8o=o(" \u2014 "),jV=a("a"),i8o=o("PegasusTokenizer"),d8o=o(" or "),DV=a("a"),m8o=o("PegasusTokenizerFast"),c8o=o(" (PEGASUS-X model)"),f8o=l(),ip=a("li"),X1e=a("strong"),g8o=o("perceiver"),h8o=o(" \u2014 "),GV=a("a"),u8o=o("PerceiverTokenizer"),p8o=o(" (Perceiver model)"),_8o=l(),dp=a("li"),z1e=a("strong"),b8o=o("phobert"),v8o=o(" \u2014 "),OV=a("a"),F8o=o("PhobertTokenizer"),T8o=o(" (PhoBERT model)"),M8o=l(),mp=a("li"),Q1e=a("strong"),E8o=o("plbart"),C8o=o(" \u2014 "),VV=a("a"),w8o=o("PLBartTokenizer"),A8o=o(" (PLBart model)"),L8o=l(),cp=a("li"),W1e=a("strong"),y8o=o("prophetnet"),x8o=o(" \u2014 "),XV=a("a"),$8o=o("ProphetNetTokenizer"),k8o=o(" (ProphetNet model)"),S8o=l(),vl=a("li"),U1e=a("strong"),R8o=o("qdqbert"),P8o=o(" \u2014 "),zV=a("a"),B8o=o("BertTokenizer"),I8o=o(" or "),QV=a("a"),N8o=o("BertTokenizerFast"),q8o=o(" (QDQBert model)"),j8o=l(),fp=a("li"),H1e=a("strong"),D8o=o("rag"),G8o=o(" \u2014 "),WV=a("a"),O8o=o("RagTokenizer"),V8o=o(" (RAG model)"),X8o=l(),Fl=a("li"),J1e=a("strong"),z8o=o("realm"),Q8o=o(" \u2014 "),UV=a("a"),W8o=o("RealmTokenizer"),U8o=o(" or "),HV=a("a"),H8o=o("RealmTokenizerFast"),J8o=o(" (REALM model)"),Y8o=l(),Tl=a("li"),Y1e=a("strong"),Z8o=o("reformer"),K8o=o(" \u2014 "),JV=a("a"),eLo=o("ReformerTokenizer"),oLo=o(" or "),YV=a("a"),rLo=o("ReformerTokenizerFast"),tLo=o(" (Reformer model)"),aLo=l(),Ml=a("li"),Z1e=a("strong"),nLo=o("rembert"),sLo=o(" \u2014 "),ZV=a("a"),lLo=o("RemBertTokenizer"),iLo=o(" or "),KV=a("a"),dLo=o("RemBertTokenizerFast"),mLo=o(" (RemBERT model)"),cLo=l(),El=a("li"),K1e=a("strong"),fLo=o("retribert"),gLo=o(" \u2014 "),eX=a("a"),hLo=o("RetriBertTokenizer"),uLo=o(" or "),oX=a("a"),pLo=o("RetriBertTokenizerFast"),_Lo=o(" (RetriBERT model)"),bLo=l(),Cl=a("li"),e2e=a("strong"),vLo=o("roberta"),FLo=o(" \u2014 "),rX=a("a"),TLo=o("RobertaTokenizer"),MLo=o(" or "),tX=a("a"),ELo=o("RobertaTokenizerFast"),CLo=o(" (RoBERTa model)"),wLo=l(),gp=a("li"),o2e=a("strong"),ALo=o("roc_bert"),LLo=o(" \u2014 "),aX=a("a"),yLo=o("RoCBertTokenizer"),xLo=o(" (RoCBert model)"),$Lo=l(),wl=a("li"),r2e=a("strong"),kLo=o("roformer"),SLo=o(" \u2014 "),nX=a("a"),RLo=o("RoFormerTokenizer"),PLo=o(" or "),sX=a("a"),BLo=o("RoFormerTokenizerFast"),ILo=o(" (RoFormer model)"),NLo=l(),hp=a("li"),t2e=a("strong"),qLo=o("speech_to_text"),jLo=o(" \u2014 "),lX=a("a"),DLo=o("Speech2TextTokenizer"),GLo=o(" (Speech2Text model)"),OLo=l(),up=a("li"),a2e=a("strong"),VLo=o("speech_to_text_2"),XLo=o(" \u2014 "),iX=a("a"),zLo=o("Speech2Text2Tokenizer"),QLo=o(" (Speech2Text2 model)"),WLo=l(),Al=a("li"),n2e=a("strong"),ULo=o("splinter"),HLo=o(" \u2014 "),dX=a("a"),JLo=o("SplinterTokenizer"),YLo=o(" or "),mX=a("a"),ZLo=o("SplinterTokenizerFast"),KLo=o(" (Splinter model)"),eyo=l(),Ll=a("li"),s2e=a("strong"),oyo=o("squeezebert"),ryo=o(" \u2014 "),cX=a("a"),tyo=o("SqueezeBertTokenizer"),ayo=o(" or "),fX=a("a"),nyo=o("SqueezeBertTokenizerFast"),syo=o(" (SqueezeBERT model)"),lyo=l(),yl=a("li"),l2e=a("strong"),iyo=o("t5"),dyo=o(" \u2014 "),gX=a("a"),myo=o("T5Tokenizer"),cyo=o(" or "),hX=a("a"),fyo=o("T5TokenizerFast"),gyo=o(" (T5 model)"),hyo=l(),pp=a("li"),i2e=a("strong"),uyo=o("tapas"),pyo=o(" \u2014 "),uX=a("a"),_yo=o("TapasTokenizer"),byo=o(" (TAPAS model)"),vyo=l(),_p=a("li"),d2e=a("strong"),Fyo=o("tapex"),Tyo=o(" \u2014 "),pX=a("a"),Myo=o("TapexTokenizer"),Eyo=o(" (TAPEX model)"),Cyo=l(),bp=a("li"),m2e=a("strong"),wyo=o("transfo-xl"),Ayo=o(" \u2014 "),_X=a("a"),Lyo=o("TransfoXLTokenizer"),yyo=o(" (Transformer-XL model)"),xyo=l(),xl=a("li"),c2e=a("strong"),$yo=o("vilt"),kyo=o(" \u2014 "),bX=a("a"),Syo=o("BertTokenizer"),Ryo=o(" or "),vX=a("a"),Pyo=o("BertTokenizerFast"),Byo=o(" (ViLT model)"),Iyo=l(),$l=a("li"),f2e=a("strong"),Nyo=o("visual_bert"),qyo=o(" \u2014 "),FX=a("a"),jyo=o("BertTokenizer"),Dyo=o(" or "),TX=a("a"),Gyo=o("BertTokenizerFast"),Oyo=o(" (VisualBERT model)"),Vyo=l(),vp=a("li"),g2e=a("strong"),Xyo=o("wav2vec2"),zyo=o(" \u2014 "),MX=a("a"),Qyo=o("Wav2Vec2CTCTokenizer"),Wyo=o(" (Wav2Vec2 model)"),Uyo=l(),Fp=a("li"),h2e=a("strong"),Hyo=o("wav2vec2-conformer"),Jyo=o(" \u2014 "),EX=a("a"),Yyo=o("Wav2Vec2CTCTokenizer"),Zyo=o(" (Wav2Vec2-Conformer model)"),Kyo=l(),Tp=a("li"),u2e=a("strong"),e9o=o("wav2vec2_phoneme"),o9o=o(" \u2014 "),CX=a("a"),r9o=o("Wav2Vec2PhonemeCTCTokenizer"),t9o=o(" (Wav2Vec2Phoneme model)"),a9o=l(),Mp=a("li"),p2e=a("strong"),n9o=o("whisper"),s9o=o(" \u2014 "),wX=a("a"),l9o=o("WhisperTokenizer"),i9o=o(" (Whisper model)"),d9o=l(),kl=a("li"),_2e=a("strong"),m9o=o("xclip"),c9o=o(" \u2014 "),AX=a("a"),f9o=o("CLIPTokenizer"),g9o=o(" or "),LX=a("a"),h9o=o("CLIPTokenizerFast"),u9o=o(" (X-CLIP model)"),p9o=l(),Sl=a("li"),b2e=a("strong"),_9o=o("xglm"),b9o=o(" \u2014 "),yX=a("a"),v9o=o("XGLMTokenizer"),F9o=o(" or "),xX=a("a"),T9o=o("XGLMTokenizerFast"),M9o=o(" (XGLM model)"),E9o=l(),Ep=a("li"),v2e=a("strong"),C9o=o("xlm"),w9o=o(" \u2014 "),$X=a("a"),A9o=o("XLMTokenizer"),L9o=o(" (XLM model)"),y9o=l(),Cp=a("li"),F2e=a("strong"),x9o=o("xlm-prophetnet"),$9o=o(" \u2014 "),kX=a("a"),k9o=o("XLMProphetNetTokenizer"),S9o=o(" (XLM-ProphetNet model)"),R9o=l(),Rl=a("li"),T2e=a("strong"),P9o=o("xlm-roberta"),B9o=o(" \u2014 "),SX=a("a"),I9o=o("XLMRobertaTokenizer"),N9o=o(" or "),RX=a("a"),q9o=o("XLMRobertaTokenizerFast"),j9o=o(" (XLM-RoBERTa model)"),D9o=l(),Pl=a("li"),M2e=a("strong"),G9o=o("xlm-roberta-xl"),O9o=o(" \u2014 "),PX=a("a"),V9o=o("XLMRobertaTokenizer"),X9o=o(" or "),BX=a("a"),z9o=o("XLMRobertaTokenizerFast"),Q9o=o(" (XLM-RoBERTa-XL model)"),W9o=l(),Bl=a("li"),E2e=a("strong"),U9o=o("xlnet"),H9o=o(" \u2014 "),IX=a("a"),J9o=o("XLNetTokenizer"),Y9o=o(" or "),NX=a("a"),Z9o=o("XLNetTokenizerFast"),K9o=o(" (XLNet model)"),exo=l(),Il=a("li"),C2e=a("strong"),oxo=o("yoso"),rxo=o(" \u2014 "),qX=a("a"),txo=o("AlbertTokenizer"),axo=o(" or "),jX=a("a"),nxo=o("AlbertTokenizerFast"),sxo=o(" (YOSO model)"),lxo=l(),F(wp.$$.fragment),ixo=l(),Ap=a("div"),F(Pk.$$.fragment),dxo=l(),w2e=a("p"),mxo=o("Register a new tokenizer in this mapping."),lio=l(),Nd=a("h2"),Lp=a("a"),A2e=a("span"),F(Bk.$$.fragment),cxo=l(),L2e=a("span"),fxo=o("AutoFeatureExtractor"),iio=l(),No=a("div"),F(Ik.$$.fragment),gxo=l(),Nk=a("p"),hxo=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),DX=a("a"),uxo=o("AutoFeatureExtractor.from_pretrained()"),pxo=o(" class method."),_xo=l(),qk=a("p"),bxo=o("This class cannot be instantiated directly using "),y2e=a("code"),vxo=o("__init__()"),Fxo=o(" (throws an error)."),Txo=l(),eo=a("div"),F(jk.$$.fragment),Mxo=l(),x2e=a("p"),Exo=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Cxo=l(),cn=a("p"),wxo=o("The feature extractor class to instantiate is selected based on the "),$2e=a("code"),Axo=o("model_type"),Lxo=o(` property of the config object
(either passed as an argument or loaded from `),k2e=a("code"),yxo=o("pretrained_model_name_or_path"),xxo=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),S2e=a("code"),$xo=o("pretrained_model_name_or_path"),kxo=o(":"),Sxo=l(),z=a("ul"),yp=a("li"),R2e=a("strong"),Rxo=o("beit"),Pxo=o(" \u2014 "),GX=a("a"),Bxo=o("BeitFeatureExtractor"),Ixo=o(" (BEiT model)"),Nxo=l(),xp=a("li"),P2e=a("strong"),qxo=o("clip"),jxo=o(" \u2014 "),OX=a("a"),Dxo=o("CLIPFeatureExtractor"),Gxo=o(" (CLIP model)"),Oxo=l(),$p=a("li"),B2e=a("strong"),Vxo=o("clipseg"),Xxo=o(" \u2014 "),VX=a("a"),zxo=o("ViTFeatureExtractor"),Qxo=o(" (CLIPSeg model)"),Wxo=l(),kp=a("li"),I2e=a("strong"),Uxo=o("conditional_detr"),Hxo=o(" \u2014 "),XX=a("a"),Jxo=o("ConditionalDetrFeatureExtractor"),Yxo=o(" (Conditional DETR model)"),Zxo=l(),Sp=a("li"),N2e=a("strong"),Kxo=o("convnext"),e$o=o(" \u2014 "),zX=a("a"),o$o=o("ConvNextFeatureExtractor"),r$o=o(" (ConvNeXT model)"),t$o=l(),Rp=a("li"),q2e=a("strong"),a$o=o("cvt"),n$o=o(" \u2014 "),QX=a("a"),s$o=o("ConvNextFeatureExtractor"),l$o=o(" (CvT model)"),i$o=l(),Pp=a("li"),j2e=a("strong"),d$o=o("data2vec-audio"),m$o=o(" \u2014 "),WX=a("a"),c$o=o("Wav2Vec2FeatureExtractor"),f$o=o(" (Data2VecAudio model)"),g$o=l(),Bp=a("li"),D2e=a("strong"),h$o=o("data2vec-vision"),u$o=o(" \u2014 "),UX=a("a"),p$o=o("BeitFeatureExtractor"),_$o=o(" (Data2VecVision model)"),b$o=l(),Ip=a("li"),G2e=a("strong"),v$o=o("deformable_detr"),F$o=o(" \u2014 "),HX=a("a"),T$o=o("DeformableDetrFeatureExtractor"),M$o=o(" (Deformable DETR model)"),E$o=l(),Np=a("li"),O2e=a("strong"),C$o=o("deit"),w$o=o(" \u2014 "),JX=a("a"),A$o=o("DeiTFeatureExtractor"),L$o=o(" (DeiT model)"),y$o=l(),qp=a("li"),V2e=a("strong"),x$o=o("detr"),$$o=o(" \u2014 "),YX=a("a"),k$o=o("DetrFeatureExtractor"),S$o=o(" (DETR model)"),R$o=l(),jp=a("li"),X2e=a("strong"),P$o=o("donut-swin"),B$o=o(" \u2014 "),ZX=a("a"),I$o=o("DonutFeatureExtractor"),N$o=o(" (DonutSwin model)"),q$o=l(),Dp=a("li"),z2e=a("strong"),j$o=o("dpt"),D$o=o(" \u2014 "),KX=a("a"),G$o=o("DPTFeatureExtractor"),O$o=o(" (DPT model)"),V$o=l(),Gp=a("li"),Q2e=a("strong"),X$o=o("flava"),z$o=o(" \u2014 "),ez=a("a"),Q$o=o("FlavaFeatureExtractor"),W$o=o(" (FLAVA model)"),U$o=l(),Op=a("li"),W2e=a("strong"),H$o=o("glpn"),J$o=o(" \u2014 "),oz=a("a"),Y$o=o("GLPNFeatureExtractor"),Z$o=o(" (GLPN model)"),K$o=l(),Vp=a("li"),U2e=a("strong"),eko=o("groupvit"),oko=o(" \u2014 "),rz=a("a"),rko=o("CLIPFeatureExtractor"),tko=o(" (GroupViT model)"),ako=l(),Xp=a("li"),H2e=a("strong"),nko=o("hubert"),sko=o(" \u2014 "),tz=a("a"),lko=o("Wav2Vec2FeatureExtractor"),iko=o(" (Hubert model)"),dko=l(),zp=a("li"),J2e=a("strong"),mko=o("imagegpt"),cko=o(" \u2014 "),az=a("a"),fko=o("ImageGPTFeatureExtractor"),gko=o(" (ImageGPT model)"),hko=l(),Qp=a("li"),Y2e=a("strong"),uko=o("layoutlmv2"),pko=o(" \u2014 "),nz=a("a"),_ko=o("LayoutLMv2FeatureExtractor"),bko=o(" (LayoutLMv2 model)"),vko=l(),Wp=a("li"),Z2e=a("strong"),Fko=o("layoutlmv3"),Tko=o(" \u2014 "),sz=a("a"),Mko=o("LayoutLMv3FeatureExtractor"),Eko=o(" (LayoutLMv3 model)"),Cko=l(),Up=a("li"),K2e=a("strong"),wko=o("levit"),Ako=o(" \u2014 "),lz=a("a"),Lko=o("LevitFeatureExtractor"),yko=o(" (LeViT model)"),xko=l(),Hp=a("li"),ebe=a("strong"),$ko=o("maskformer"),kko=o(" \u2014 "),iz=a("a"),Sko=o("MaskFormerFeatureExtractor"),Rko=o(" (MaskFormer model)"),Pko=l(),Jp=a("li"),obe=a("strong"),Bko=o("mctct"),Iko=o(" \u2014 "),dz=a("a"),Nko=o("MCTCTFeatureExtractor"),qko=o(" (M-CTC-T model)"),jko=l(),Yp=a("li"),rbe=a("strong"),Dko=o("mobilenet_v2"),Gko=o(" \u2014 "),mz=a("a"),Oko=o("MobileNetV2FeatureExtractor"),Vko=o(" (MobileNetV2 model)"),Xko=l(),Zp=a("li"),tbe=a("strong"),zko=o("mobilevit"),Qko=o(" \u2014 "),cz=a("a"),Wko=o("MobileViTFeatureExtractor"),Uko=o(" (MobileViT model)"),Hko=l(),Kp=a("li"),abe=a("strong"),Jko=o("owlvit"),Yko=o(" \u2014 "),fz=a("a"),Zko=o("OwlViTFeatureExtractor"),Kko=o(" (OWL-ViT model)"),eSo=l(),e_=a("li"),nbe=a("strong"),oSo=o("perceiver"),rSo=o(" \u2014 "),gz=a("a"),tSo=o("PerceiverFeatureExtractor"),aSo=o(" (Perceiver model)"),nSo=l(),o_=a("li"),sbe=a("strong"),sSo=o("poolformer"),lSo=o(" \u2014 "),hz=a("a"),iSo=o("PoolFormerFeatureExtractor"),dSo=o(" (PoolFormer model)"),mSo=l(),r_=a("li"),lbe=a("strong"),cSo=o("regnet"),fSo=o(" \u2014 "),uz=a("a"),gSo=o("ConvNextFeatureExtractor"),hSo=o(" (RegNet model)"),uSo=l(),t_=a("li"),ibe=a("strong"),pSo=o("resnet"),_So=o(" \u2014 "),pz=a("a"),bSo=o("ConvNextFeatureExtractor"),vSo=o(" (ResNet model)"),FSo=l(),a_=a("li"),dbe=a("strong"),TSo=o("segformer"),MSo=o(" \u2014 "),_z=a("a"),ESo=o("SegformerFeatureExtractor"),CSo=o(" (SegFormer model)"),wSo=l(),n_=a("li"),mbe=a("strong"),ASo=o("speech_to_text"),LSo=o(" \u2014 "),bz=a("a"),ySo=o("Speech2TextFeatureExtractor"),xSo=o(" (Speech2Text model)"),$So=l(),s_=a("li"),cbe=a("strong"),kSo=o("swin"),SSo=o(" \u2014 "),vz=a("a"),RSo=o("ViTFeatureExtractor"),PSo=o(" (Swin Transformer model)"),BSo=l(),l_=a("li"),fbe=a("strong"),ISo=o("swinv2"),NSo=o(" \u2014 "),Fz=a("a"),qSo=o("ViTFeatureExtractor"),jSo=o(" (Swin Transformer V2 model)"),DSo=l(),i_=a("li"),gbe=a("strong"),GSo=o("table-transformer"),OSo=o(" \u2014 "),Tz=a("a"),VSo=o("DetrFeatureExtractor"),XSo=o(" (Table Transformer model)"),zSo=l(),d_=a("li"),hbe=a("strong"),QSo=o("van"),WSo=o(" \u2014 "),Mz=a("a"),USo=o("ConvNextFeatureExtractor"),HSo=o(" (VAN model)"),JSo=l(),m_=a("li"),ube=a("strong"),YSo=o("videomae"),ZSo=o(" \u2014 "),Ez=a("a"),KSo=o("VideoMAEFeatureExtractor"),eRo=o(" (VideoMAE model)"),oRo=l(),c_=a("li"),pbe=a("strong"),rRo=o("vilt"),tRo=o(" \u2014 "),Cz=a("a"),aRo=o("ViltFeatureExtractor"),nRo=o(" (ViLT model)"),sRo=l(),f_=a("li"),_be=a("strong"),lRo=o("vit"),iRo=o(" \u2014 "),wz=a("a"),dRo=o("ViTFeatureExtractor"),mRo=o(" (ViT model)"),cRo=l(),g_=a("li"),bbe=a("strong"),fRo=o("vit_mae"),gRo=o(" \u2014 "),Az=a("a"),hRo=o("ViTFeatureExtractor"),uRo=o(" (ViTMAE model)"),pRo=l(),h_=a("li"),vbe=a("strong"),_Ro=o("vit_msn"),bRo=o(" \u2014 "),Lz=a("a"),vRo=o("ViTFeatureExtractor"),FRo=o(" (ViTMSN model)"),TRo=l(),u_=a("li"),Fbe=a("strong"),MRo=o("wav2vec2"),ERo=o(" \u2014 "),yz=a("a"),CRo=o("Wav2Vec2FeatureExtractor"),wRo=o(" (Wav2Vec2 model)"),ARo=l(),p_=a("li"),Tbe=a("strong"),LRo=o("wav2vec2-conformer"),yRo=o(" \u2014 "),xz=a("a"),xRo=o("Wav2Vec2FeatureExtractor"),$Ro=o(" (Wav2Vec2-Conformer model)"),kRo=l(),__=a("li"),Mbe=a("strong"),SRo=o("whisper"),RRo=o(" \u2014 "),$z=a("a"),PRo=o("WhisperFeatureExtractor"),BRo=o(" (Whisper model)"),IRo=l(),b_=a("li"),Ebe=a("strong"),NRo=o("xclip"),qRo=o(" \u2014 "),kz=a("a"),jRo=o("CLIPFeatureExtractor"),DRo=o(" (X-CLIP model)"),GRo=l(),v_=a("li"),Cbe=a("strong"),ORo=o("yolos"),VRo=o(" \u2014 "),Sz=a("a"),XRo=o("YolosFeatureExtractor"),zRo=o(" (YOLOS model)"),QRo=l(),F(F_.$$.fragment),WRo=l(),F(T_.$$.fragment),URo=l(),M_=a("div"),F(Dk.$$.fragment),HRo=l(),wbe=a("p"),JRo=o("Register a new feature extractor for this class."),dio=l(),qd=a("h2"),E_=a("a"),Abe=a("span"),F(Gk.$$.fragment),YRo=l(),Lbe=a("span"),ZRo=o("AutoImageProcessor"),mio=l(),qo=a("div"),F(Ok.$$.fragment),KRo=l(),Vk=a("p"),ePo=o(`This is a generic image processor class that will be instantiated as one of the image processor classes of the
library when created with the `),Rz=a("a"),oPo=o("AutoImageProcessor.from_pretrained()"),rPo=o(" class method."),tPo=l(),Xk=a("p"),aPo=o("This class cannot be instantiated directly using "),ybe=a("code"),nPo=o("__init__()"),sPo=o(" (throws an error)."),lPo=l(),oo=a("div"),F(zk.$$.fragment),iPo=l(),xbe=a("p"),dPo=o("Instantiate one of the image processor classes of the library from a pretrained model vocabulary."),mPo=l(),fn=a("p"),cPo=o("The image processor class to instantiate is selected based on the "),$be=a("code"),fPo=o("model_type"),gPo=o(` property of the config object
(either passed as an argument or loaded from `),kbe=a("code"),hPo=o("pretrained_model_name_or_path"),uPo=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Sbe=a("code"),pPo=o("pretrained_model_name_or_path"),_Po=o(":"),bPo=l(),oe=a("ul"),C_=a("li"),Rbe=a("strong"),vPo=o("beit"),FPo=o(" \u2014 "),Pz=a("a"),TPo=o("BeitImageProcessor"),MPo=o(" (BEiT model)"),EPo=l(),w_=a("li"),Pbe=a("strong"),CPo=o("clip"),wPo=o(" \u2014 "),Bz=a("a"),APo=o("CLIPImageProcessor"),LPo=o(" (CLIP model)"),yPo=l(),A_=a("li"),Bbe=a("strong"),xPo=o("convnext"),$Po=o(" \u2014 "),Iz=a("a"),kPo=o("ConvNextImageProcessor"),SPo=o(" (ConvNeXT model)"),RPo=l(),L_=a("li"),Ibe=a("strong"),PPo=o("cvt"),BPo=o(" \u2014 "),Nz=a("a"),IPo=o("ConvNextImageProcessor"),NPo=o(" (CvT model)"),qPo=l(),y_=a("li"),Nbe=a("strong"),jPo=o("data2vec-vision"),DPo=o(" \u2014 "),qz=a("a"),GPo=o("BeitImageProcessor"),OPo=o(" (Data2VecVision model)"),VPo=l(),x_=a("li"),qbe=a("strong"),XPo=o("deit"),zPo=o(" \u2014 "),jz=a("a"),QPo=o("DeiTImageProcessor"),WPo=o(" (DeiT model)"),UPo=l(),$_=a("li"),jbe=a("strong"),HPo=o("dpt"),JPo=o(" \u2014 "),Dz=a("a"),YPo=o("DPTImageProcessor"),ZPo=o(" (DPT model)"),KPo=l(),k_=a("li"),Dbe=a("strong"),eBo=o("flava"),oBo=o(" \u2014 "),Gz=a("a"),rBo=o("FlavaImageProcessor"),tBo=o(" (FLAVA model)"),aBo=l(),S_=a("li"),Gbe=a("strong"),nBo=o("glpn"),sBo=o(" \u2014 "),Oz=a("a"),lBo=o("GLPNImageProcessor"),iBo=o(" (GLPN model)"),dBo=l(),R_=a("li"),Obe=a("strong"),mBo=o("groupvit"),cBo=o(" \u2014 "),Vz=a("a"),fBo=o("CLIPImageProcessor"),gBo=o(" (GroupViT model)"),hBo=l(),P_=a("li"),Vbe=a("strong"),uBo=o("imagegpt"),pBo=o(" \u2014 "),Xz=a("a"),_Bo=o("ImageGPTImageProcessor"),bBo=o(" (ImageGPT model)"),vBo=l(),B_=a("li"),Xbe=a("strong"),FBo=o("layoutlmv2"),TBo=o(" \u2014 "),zz=a("a"),MBo=o("LayoutLMv2ImageProcessor"),EBo=o(" (LayoutLMv2 model)"),CBo=l(),I_=a("li"),zbe=a("strong"),wBo=o("layoutlmv3"),ABo=o(" \u2014 "),Qz=a("a"),LBo=o("LayoutLMv3ImageProcessor"),yBo=o(" (LayoutLMv3 model)"),xBo=l(),N_=a("li"),Qbe=a("strong"),$Bo=o("levit"),kBo=o(" \u2014 "),Wz=a("a"),SBo=o("LevitImageProcessor"),RBo=o(" (LeViT model)"),PBo=l(),q_=a("li"),Wbe=a("strong"),BBo=o("mobilenet_v2"),IBo=o(" \u2014 "),Uz=a("a"),NBo=o("MobileNetV2ImageProcessor"),qBo=o(" (MobileNetV2 model)"),jBo=l(),j_=a("li"),Ube=a("strong"),DBo=o("mobilevit"),GBo=o(" \u2014 "),Hz=a("a"),OBo=o("MobileViTImageProcessor"),VBo=o(" (MobileViT model)"),XBo=l(),D_=a("li"),Hbe=a("strong"),zBo=o("perceiver"),QBo=o(" \u2014 "),Jz=a("a"),WBo=o("PerceiverImageProcessor"),UBo=o(" (Perceiver model)"),HBo=l(),G_=a("li"),Jbe=a("strong"),JBo=o("poolformer"),YBo=o(" \u2014 "),Yz=a("a"),ZBo=o("PoolFormerImageProcessor"),KBo=o(" (PoolFormer model)"),eIo=l(),O_=a("li"),Ybe=a("strong"),oIo=o("regnet"),rIo=o(" \u2014 "),Zz=a("a"),tIo=o("ConvNextImageProcessor"),aIo=o(" (RegNet model)"),nIo=l(),V_=a("li"),Zbe=a("strong"),sIo=o("resnet"),lIo=o(" \u2014 "),Kz=a("a"),iIo=o("ConvNextImageProcessor"),dIo=o(" (ResNet model)"),mIo=l(),X_=a("li"),Kbe=a("strong"),cIo=o("segformer"),fIo=o(" \u2014 "),eQ=a("a"),gIo=o("SegformerImageProcessor"),hIo=o(" (SegFormer model)"),uIo=l(),z_=a("li"),eve=a("strong"),pIo=o("swin"),_Io=o(" \u2014 "),oQ=a("a"),bIo=o("ViTImageProcessor"),vIo=o(" (Swin Transformer model)"),FIo=l(),Q_=a("li"),ove=a("strong"),TIo=o("swinv2"),MIo=o(" \u2014 "),rQ=a("a"),EIo=o("ViTImageProcessor"),CIo=o(" (Swin Transformer V2 model)"),wIo=l(),W_=a("li"),rve=a("strong"),AIo=o("van"),LIo=o(" \u2014 "),tQ=a("a"),yIo=o("ConvNextImageProcessor"),xIo=o(" (VAN model)"),$Io=l(),U_=a("li"),tve=a("strong"),kIo=o("videomae"),SIo=o(" \u2014 "),aQ=a("a"),RIo=o("VideoMAEImageProcessor"),PIo=o(" (VideoMAE model)"),BIo=l(),H_=a("li"),ave=a("strong"),IIo=o("vilt"),NIo=o(" \u2014 "),nQ=a("a"),qIo=o("ViltImageProcessor"),jIo=o(" (ViLT model)"),DIo=l(),J_=a("li"),nve=a("strong"),GIo=o("vit"),OIo=o(" \u2014 "),sQ=a("a"),VIo=o("ViTImageProcessor"),XIo=o(" (ViT model)"),zIo=l(),Y_=a("li"),sve=a("strong"),QIo=o("vit_mae"),WIo=o(" \u2014 "),lQ=a("a"),UIo=o("ViTImageProcessor"),HIo=o(" (ViTMAE model)"),JIo=l(),Z_=a("li"),lve=a("strong"),YIo=o("vit_msn"),ZIo=o(" \u2014 "),iQ=a("a"),KIo=o("ViTImageProcessor"),eNo=o(" (ViTMSN model)"),oNo=l(),K_=a("li"),ive=a("strong"),rNo=o("xclip"),tNo=o(" \u2014 "),dQ=a("a"),aNo=o("CLIPImageProcessor"),nNo=o(" (X-CLIP model)"),sNo=l(),F(e1.$$.fragment),lNo=l(),F(o1.$$.fragment),iNo=l(),r1=a("div"),F(Qk.$$.fragment),dNo=l(),dve=a("p"),mNo=o("Register a new image processor for this class."),cio=l(),jd=a("h2"),t1=a("a"),mve=a("span"),F(Wk.$$.fragment),cNo=l(),cve=a("span"),fNo=o("AutoProcessor"),fio=l(),jo=a("div"),F(Uk.$$.fragment),gNo=l(),Hk=a("p"),hNo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),mQ=a("a"),uNo=o("AutoProcessor.from_pretrained()"),pNo=o(" class method."),_No=l(),Jk=a("p"),bNo=o("This class cannot be instantiated directly using "),fve=a("code"),vNo=o("__init__()"),FNo=o(" (throws an error)."),TNo=l(),ro=a("div"),F(Yk.$$.fragment),MNo=l(),gve=a("p"),ENo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),CNo=l(),Dd=a("p"),wNo=o("The processor class to instantiate is selected based on the "),hve=a("code"),ANo=o("model_type"),LNo=o(` property of the config object (either
passed as an argument or loaded from `),uve=a("code"),yNo=o("pretrained_model_name_or_path"),xNo=o(" if possible):"),$No=l(),ie=a("ul"),a1=a("li"),pve=a("strong"),kNo=o("clip"),SNo=o(" \u2014 "),cQ=a("a"),RNo=o("CLIPProcessor"),PNo=o(" (CLIP model)"),BNo=l(),n1=a("li"),_ve=a("strong"),INo=o("clipseg"),NNo=o(" \u2014 "),fQ=a("a"),qNo=o("CLIPSegProcessor"),jNo=o(" (CLIPSeg model)"),DNo=l(),s1=a("li"),bve=a("strong"),GNo=o("flava"),ONo=o(" \u2014 "),gQ=a("a"),VNo=o("FlavaProcessor"),XNo=o(" (FLAVA model)"),zNo=l(),l1=a("li"),vve=a("strong"),QNo=o("groupvit"),WNo=o(" \u2014 "),hQ=a("a"),UNo=o("CLIPProcessor"),HNo=o(" (GroupViT model)"),JNo=l(),i1=a("li"),Fve=a("strong"),YNo=o("layoutlmv2"),ZNo=o(" \u2014 "),uQ=a("a"),KNo=o("LayoutLMv2Processor"),eqo=o(" (LayoutLMv2 model)"),oqo=l(),d1=a("li"),Tve=a("strong"),rqo=o("layoutlmv3"),tqo=o(" \u2014 "),pQ=a("a"),aqo=o("LayoutLMv3Processor"),nqo=o(" (LayoutLMv3 model)"),sqo=l(),m1=a("li"),Mve=a("strong"),lqo=o("layoutxlm"),iqo=o(" \u2014 "),_Q=a("a"),dqo=o("LayoutXLMProcessor"),mqo=o(" (LayoutXLM model)"),cqo=l(),c1=a("li"),Eve=a("strong"),fqo=o("markuplm"),gqo=o(" \u2014 "),bQ=a("a"),hqo=o("MarkupLMProcessor"),uqo=o(" (MarkupLM model)"),pqo=l(),f1=a("li"),Cve=a("strong"),_qo=o("owlvit"),bqo=o(" \u2014 "),vQ=a("a"),vqo=o("OwlViTProcessor"),Fqo=o(" (OWL-ViT model)"),Tqo=l(),g1=a("li"),wve=a("strong"),Mqo=o("sew"),Eqo=o(" \u2014 "),FQ=a("a"),Cqo=o("Wav2Vec2Processor"),wqo=o(" (SEW model)"),Aqo=l(),h1=a("li"),Ave=a("strong"),Lqo=o("sew-d"),yqo=o(" \u2014 "),TQ=a("a"),xqo=o("Wav2Vec2Processor"),$qo=o(" (SEW-D model)"),kqo=l(),u1=a("li"),Lve=a("strong"),Sqo=o("speech_to_text"),Rqo=o(" \u2014 "),MQ=a("a"),Pqo=o("Speech2TextProcessor"),Bqo=o(" (Speech2Text model)"),Iqo=l(),p1=a("li"),yve=a("strong"),Nqo=o("speech_to_text_2"),qqo=o(" \u2014 "),EQ=a("a"),jqo=o("Speech2Text2Processor"),Dqo=o(" (Speech2Text2 model)"),Gqo=l(),_1=a("li"),xve=a("strong"),Oqo=o("trocr"),Vqo=o(" \u2014 "),CQ=a("a"),Xqo=o("TrOCRProcessor"),zqo=o(" (TrOCR model)"),Qqo=l(),b1=a("li"),$ve=a("strong"),Wqo=o("unispeech"),Uqo=o(" \u2014 "),wQ=a("a"),Hqo=o("Wav2Vec2Processor"),Jqo=o(" (UniSpeech model)"),Yqo=l(),v1=a("li"),kve=a("strong"),Zqo=o("unispeech-sat"),Kqo=o(" \u2014 "),AQ=a("a"),ejo=o("Wav2Vec2Processor"),ojo=o(" (UniSpeechSat model)"),rjo=l(),F1=a("li"),Sve=a("strong"),tjo=o("vilt"),ajo=o(" \u2014 "),LQ=a("a"),njo=o("ViltProcessor"),sjo=o(" (ViLT model)"),ljo=l(),T1=a("li"),Rve=a("strong"),ijo=o("vision-text-dual-encoder"),djo=o(" \u2014 "),yQ=a("a"),mjo=o("VisionTextDualEncoderProcessor"),cjo=o(" (VisionTextDualEncoder model)"),fjo=l(),M1=a("li"),Pve=a("strong"),gjo=o("wav2vec2"),hjo=o(" \u2014 "),xQ=a("a"),ujo=o("Wav2Vec2Processor"),pjo=o(" (Wav2Vec2 model)"),_jo=l(),E1=a("li"),Bve=a("strong"),bjo=o("wav2vec2-conformer"),vjo=o(" \u2014 "),$Q=a("a"),Fjo=o("Wav2Vec2Processor"),Tjo=o(" (Wav2Vec2-Conformer model)"),Mjo=l(),C1=a("li"),Ive=a("strong"),Ejo=o("wavlm"),Cjo=o(" \u2014 "),kQ=a("a"),wjo=o("Wav2Vec2Processor"),Ajo=o(" (WavLM model)"),Ljo=l(),w1=a("li"),Nve=a("strong"),yjo=o("whisper"),xjo=o(" \u2014 "),SQ=a("a"),$jo=o("WhisperProcessor"),kjo=o(" (Whisper model)"),Sjo=l(),A1=a("li"),qve=a("strong"),Rjo=o("xclip"),Pjo=o(" \u2014 "),RQ=a("a"),Bjo=o("XCLIPProcessor"),Ijo=o(" (X-CLIP model)"),Njo=l(),F(L1.$$.fragment),qjo=l(),F(y1.$$.fragment),jjo=l(),x1=a("div"),F(Zk.$$.fragment),Djo=l(),jve=a("p"),Gjo=o("Register a new processor for this class."),gio=l(),Gd=a("h2"),$1=a("a"),Dve=a("span"),F(Kk.$$.fragment),Ojo=l(),Gve=a("span"),Vjo=o("AutoModel"),hio=l(),Do=a("div"),F(eS.$$.fragment),Xjo=l(),Od=a("p"),zjo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),PQ=a("a"),Qjo=o("from_pretrained()"),Wjo=o(" class method or the "),BQ=a("a"),Ujo=o("from_config()"),Hjo=o(` class
method.`),Jjo=l(),oS=a("p"),Yjo=o("This class cannot be instantiated directly using "),Ove=a("code"),Zjo=o("__init__()"),Kjo=o(" (throws an error)."),eDo=l(),At=a("div"),F(rS.$$.fragment),oDo=l(),Vve=a("p"),rDo=o("Instantiates one of the base model classes of the library from a configuration."),tDo=l(),Vd=a("p"),aDo=o(`Note:
Loading a model from its configuration file does `),Xve=a("strong"),nDo=o("not"),sDo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IQ=a("a"),lDo=o("from_pretrained()"),iDo=o(" to load the model weights."),dDo=l(),F(k1.$$.fragment),mDo=l(),to=a("div"),F(tS.$$.fragment),cDo=l(),zve=a("p"),fDo=o("Instantiate one of the base model classes of the library from a pretrained model."),gDo=l(),gn=a("p"),hDo=o("The model class to instantiate is selected based on the "),Qve=a("code"),uDo=o("model_type"),pDo=o(` property of the config object (either
passed as an argument or loaded from `),Wve=a("code"),_Do=o("pretrained_model_name_or_path"),bDo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Uve=a("code"),vDo=o("pretrained_model_name_or_path"),FDo=o(":"),TDo=l(),y=a("ul"),S1=a("li"),Hve=a("strong"),MDo=o("albert"),EDo=o(" \u2014 "),NQ=a("a"),CDo=o("AlbertModel"),wDo=o(" (ALBERT model)"),ADo=l(),R1=a("li"),Jve=a("strong"),LDo=o("bart"),yDo=o(" \u2014 "),qQ=a("a"),xDo=o("BartModel"),$Do=o(" (BART model)"),kDo=l(),P1=a("li"),Yve=a("strong"),SDo=o("beit"),RDo=o(" \u2014 "),jQ=a("a"),PDo=o("BeitModel"),BDo=o(" (BEiT model)"),IDo=l(),B1=a("li"),Zve=a("strong"),NDo=o("bert"),qDo=o(" \u2014 "),DQ=a("a"),jDo=o("BertModel"),DDo=o(" (BERT model)"),GDo=l(),I1=a("li"),Kve=a("strong"),ODo=o("bert-generation"),VDo=o(" \u2014 "),GQ=a("a"),XDo=o("BertGenerationEncoder"),zDo=o(" (Bert Generation model)"),QDo=l(),N1=a("li"),eFe=a("strong"),WDo=o("big_bird"),UDo=o(" \u2014 "),OQ=a("a"),HDo=o("BigBirdModel"),JDo=o(" (BigBird model)"),YDo=l(),q1=a("li"),oFe=a("strong"),ZDo=o("bigbird_pegasus"),KDo=o(" \u2014 "),VQ=a("a"),eGo=o("BigBirdPegasusModel"),oGo=o(" (BigBird-Pegasus model)"),rGo=l(),j1=a("li"),rFe=a("strong"),tGo=o("blenderbot"),aGo=o(" \u2014 "),XQ=a("a"),nGo=o("BlenderbotModel"),sGo=o(" (Blenderbot model)"),lGo=l(),D1=a("li"),tFe=a("strong"),iGo=o("blenderbot-small"),dGo=o(" \u2014 "),zQ=a("a"),mGo=o("BlenderbotSmallModel"),cGo=o(" (BlenderbotSmall model)"),fGo=l(),G1=a("li"),aFe=a("strong"),gGo=o("bloom"),hGo=o(" \u2014 "),QQ=a("a"),uGo=o("BloomModel"),pGo=o(" (BLOOM model)"),_Go=l(),O1=a("li"),nFe=a("strong"),bGo=o("camembert"),vGo=o(" \u2014 "),WQ=a("a"),FGo=o("CamembertModel"),TGo=o(" (CamemBERT model)"),MGo=l(),V1=a("li"),sFe=a("strong"),EGo=o("canine"),CGo=o(" \u2014 "),UQ=a("a"),wGo=o("CanineModel"),AGo=o(" (CANINE model)"),LGo=l(),X1=a("li"),lFe=a("strong"),yGo=o("clip"),xGo=o(" \u2014 "),HQ=a("a"),$Go=o("CLIPModel"),kGo=o(" (CLIP model)"),SGo=l(),z1=a("li"),iFe=a("strong"),RGo=o("clipseg"),PGo=o(" \u2014 "),JQ=a("a"),BGo=o("CLIPSegModel"),IGo=o(" (CLIPSeg model)"),NGo=l(),Q1=a("li"),dFe=a("strong"),qGo=o("codegen"),jGo=o(" \u2014 "),YQ=a("a"),DGo=o("CodeGenModel"),GGo=o(" (CodeGen model)"),OGo=l(),W1=a("li"),mFe=a("strong"),VGo=o("conditional_detr"),XGo=o(" \u2014 "),ZQ=a("a"),zGo=o("ConditionalDetrModel"),QGo=o(" (Conditional DETR model)"),WGo=l(),U1=a("li"),cFe=a("strong"),UGo=o("convbert"),HGo=o(" \u2014 "),KQ=a("a"),JGo=o("ConvBertModel"),YGo=o(" (ConvBERT model)"),ZGo=l(),H1=a("li"),fFe=a("strong"),KGo=o("convnext"),eOo=o(" \u2014 "),eW=a("a"),oOo=o("ConvNextModel"),rOo=o(" (ConvNeXT model)"),tOo=l(),J1=a("li"),gFe=a("strong"),aOo=o("ctrl"),nOo=o(" \u2014 "),oW=a("a"),sOo=o("CTRLModel"),lOo=o(" (CTRL model)"),iOo=l(),Y1=a("li"),hFe=a("strong"),dOo=o("cvt"),mOo=o(" \u2014 "),rW=a("a"),cOo=o("CvtModel"),fOo=o(" (CvT model)"),gOo=l(),Z1=a("li"),uFe=a("strong"),hOo=o("data2vec-audio"),uOo=o(" \u2014 "),tW=a("a"),pOo=o("Data2VecAudioModel"),_Oo=o(" (Data2VecAudio model)"),bOo=l(),K1=a("li"),pFe=a("strong"),vOo=o("data2vec-text"),FOo=o(" \u2014 "),aW=a("a"),TOo=o("Data2VecTextModel"),MOo=o(" (Data2VecText model)"),EOo=l(),e2=a("li"),_Fe=a("strong"),COo=o("data2vec-vision"),wOo=o(" \u2014 "),nW=a("a"),AOo=o("Data2VecVisionModel"),LOo=o(" (Data2VecVision model)"),yOo=l(),o2=a("li"),bFe=a("strong"),xOo=o("deberta"),$Oo=o(" \u2014 "),sW=a("a"),kOo=o("DebertaModel"),SOo=o(" (DeBERTa model)"),ROo=l(),r2=a("li"),vFe=a("strong"),POo=o("deberta-v2"),BOo=o(" \u2014 "),lW=a("a"),IOo=o("DebertaV2Model"),NOo=o(" (DeBERTa-v2 model)"),qOo=l(),t2=a("li"),FFe=a("strong"),jOo=o("decision_transformer"),DOo=o(" \u2014 "),iW=a("a"),GOo=o("DecisionTransformerModel"),OOo=o(" (Decision Transformer model)"),VOo=l(),a2=a("li"),TFe=a("strong"),XOo=o("deformable_detr"),zOo=o(" \u2014 "),dW=a("a"),QOo=o("DeformableDetrModel"),WOo=o(" (Deformable DETR model)"),UOo=l(),n2=a("li"),MFe=a("strong"),HOo=o("deit"),JOo=o(" \u2014 "),mW=a("a"),YOo=o("DeiTModel"),ZOo=o(" (DeiT model)"),KOo=l(),s2=a("li"),EFe=a("strong"),eVo=o("detr"),oVo=o(" \u2014 "),cW=a("a"),rVo=o("DetrModel"),tVo=o(" (DETR model)"),aVo=l(),l2=a("li"),CFe=a("strong"),nVo=o("distilbert"),sVo=o(" \u2014 "),fW=a("a"),lVo=o("DistilBertModel"),iVo=o(" (DistilBERT model)"),dVo=l(),i2=a("li"),wFe=a("strong"),mVo=o("donut-swin"),cVo=o(" \u2014 "),gW=a("a"),fVo=o("DonutSwinModel"),gVo=o(" (DonutSwin model)"),hVo=l(),d2=a("li"),AFe=a("strong"),uVo=o("dpr"),pVo=o(" \u2014 "),hW=a("a"),_Vo=o("DPRQuestionEncoder"),bVo=o(" (DPR model)"),vVo=l(),m2=a("li"),LFe=a("strong"),FVo=o("dpt"),TVo=o(" \u2014 "),uW=a("a"),MVo=o("DPTModel"),EVo=o(" (DPT model)"),CVo=l(),c2=a("li"),yFe=a("strong"),wVo=o("electra"),AVo=o(" \u2014 "),pW=a("a"),LVo=o("ElectraModel"),yVo=o(" (ELECTRA model)"),xVo=l(),f2=a("li"),xFe=a("strong"),$Vo=o("ernie"),kVo=o(" \u2014 "),_W=a("a"),SVo=o("ErnieModel"),RVo=o(" (ERNIE model)"),PVo=l(),g2=a("li"),$Fe=a("strong"),BVo=o("esm"),IVo=o(" \u2014 "),bW=a("a"),NVo=o("EsmModel"),qVo=o(" (ESM model)"),jVo=l(),h2=a("li"),kFe=a("strong"),DVo=o("flaubert"),GVo=o(" \u2014 "),vW=a("a"),OVo=o("FlaubertModel"),VVo=o(" (FlauBERT model)"),XVo=l(),u2=a("li"),SFe=a("strong"),zVo=o("flava"),QVo=o(" \u2014 "),FW=a("a"),WVo=o("FlavaModel"),UVo=o(" (FLAVA model)"),HVo=l(),p2=a("li"),RFe=a("strong"),JVo=o("fnet"),YVo=o(" \u2014 "),TW=a("a"),ZVo=o("FNetModel"),KVo=o(" (FNet model)"),eXo=l(),_2=a("li"),PFe=a("strong"),oXo=o("fsmt"),rXo=o(" \u2014 "),MW=a("a"),tXo=o("FSMTModel"),aXo=o(" (FairSeq Machine-Translation model)"),nXo=l(),Nl=a("li"),BFe=a("strong"),sXo=o("funnel"),lXo=o(" \u2014 "),EW=a("a"),iXo=o("FunnelModel"),dXo=o(" or "),CW=a("a"),mXo=o("FunnelBaseModel"),cXo=o(" (Funnel Transformer model)"),fXo=l(),b2=a("li"),IFe=a("strong"),gXo=o("glpn"),hXo=o(" \u2014 "),wW=a("a"),uXo=o("GLPNModel"),pXo=o(" (GLPN model)"),_Xo=l(),v2=a("li"),NFe=a("strong"),bXo=o("gpt2"),vXo=o(" \u2014 "),AW=a("a"),FXo=o("GPT2Model"),TXo=o(" (OpenAI GPT-2 model)"),MXo=l(),F2=a("li"),qFe=a("strong"),EXo=o("gpt_neo"),CXo=o(" \u2014 "),LW=a("a"),wXo=o("GPTNeoModel"),AXo=o(" (GPT Neo model)"),LXo=l(),T2=a("li"),jFe=a("strong"),yXo=o("gpt_neox"),xXo=o(" \u2014 "),yW=a("a"),$Xo=o("GPTNeoXModel"),kXo=o(" (GPT NeoX model)"),SXo=l(),M2=a("li"),DFe=a("strong"),RXo=o("gpt_neox_japanese"),PXo=o(" \u2014 "),xW=a("a"),BXo=o("GPTNeoXJapaneseModel"),IXo=o(" (GPT NeoX Japanese model)"),NXo=l(),E2=a("li"),GFe=a("strong"),qXo=o("gptj"),jXo=o(" \u2014 "),$W=a("a"),DXo=o("GPTJModel"),GXo=o(" (GPT-J model)"),OXo=l(),C2=a("li"),OFe=a("strong"),VXo=o("groupvit"),XXo=o(" \u2014 "),kW=a("a"),zXo=o("GroupViTModel"),QXo=o(" (GroupViT model)"),WXo=l(),w2=a("li"),VFe=a("strong"),UXo=o("hubert"),HXo=o(" \u2014 "),SW=a("a"),JXo=o("HubertModel"),YXo=o(" (Hubert model)"),ZXo=l(),A2=a("li"),XFe=a("strong"),KXo=o("ibert"),ezo=o(" \u2014 "),RW=a("a"),ozo=o("IBertModel"),rzo=o(" (I-BERT model)"),tzo=l(),L2=a("li"),zFe=a("strong"),azo=o("imagegpt"),nzo=o(" \u2014 "),PW=a("a"),szo=o("ImageGPTModel"),lzo=o(" (ImageGPT model)"),izo=l(),y2=a("li"),QFe=a("strong"),dzo=o("jukebox"),mzo=o(" \u2014 "),BW=a("a"),czo=o("JukeboxModel"),fzo=o(" (Jukebox model)"),gzo=l(),x2=a("li"),WFe=a("strong"),hzo=o("layoutlm"),uzo=o(" \u2014 "),IW=a("a"),pzo=o("LayoutLMModel"),_zo=o(" (LayoutLM model)"),bzo=l(),$2=a("li"),UFe=a("strong"),vzo=o("layoutlmv2"),Fzo=o(" \u2014 "),NW=a("a"),Tzo=o("LayoutLMv2Model"),Mzo=o(" (LayoutLMv2 model)"),Ezo=l(),k2=a("li"),HFe=a("strong"),Czo=o("layoutlmv3"),wzo=o(" \u2014 "),qW=a("a"),Azo=o("LayoutLMv3Model"),Lzo=o(" (LayoutLMv3 model)"),yzo=l(),S2=a("li"),JFe=a("strong"),xzo=o("led"),$zo=o(" \u2014 "),jW=a("a"),kzo=o("LEDModel"),Szo=o(" (LED model)"),Rzo=l(),R2=a("li"),YFe=a("strong"),Pzo=o("levit"),Bzo=o(" \u2014 "),DW=a("a"),Izo=o("LevitModel"),Nzo=o(" (LeViT model)"),qzo=l(),P2=a("li"),ZFe=a("strong"),jzo=o("lilt"),Dzo=o(" \u2014 "),GW=a("a"),Gzo=o("LiltModel"),Ozo=o(" (LiLT model)"),Vzo=l(),B2=a("li"),KFe=a("strong"),Xzo=o("longformer"),zzo=o(" \u2014 "),OW=a("a"),Qzo=o("LongformerModel"),Wzo=o(" (Longformer model)"),Uzo=l(),I2=a("li"),eTe=a("strong"),Hzo=o("longt5"),Jzo=o(" \u2014 "),VW=a("a"),Yzo=o("LongT5Model"),Zzo=o(" (LongT5 model)"),Kzo=l(),N2=a("li"),oTe=a("strong"),eQo=o("luke"),oQo=o(" \u2014 "),XW=a("a"),rQo=o("LukeModel"),tQo=o(" (LUKE model)"),aQo=l(),q2=a("li"),rTe=a("strong"),nQo=o("lxmert"),sQo=o(" \u2014 "),zW=a("a"),lQo=o("LxmertModel"),iQo=o(" (LXMERT model)"),dQo=l(),j2=a("li"),tTe=a("strong"),mQo=o("m2m_100"),cQo=o(" \u2014 "),QW=a("a"),fQo=o("M2M100Model"),gQo=o(" (M2M100 model)"),hQo=l(),D2=a("li"),aTe=a("strong"),uQo=o("marian"),pQo=o(" \u2014 "),WW=a("a"),_Qo=o("MarianModel"),bQo=o(" (Marian model)"),vQo=l(),G2=a("li"),nTe=a("strong"),FQo=o("markuplm"),TQo=o(" \u2014 "),UW=a("a"),MQo=o("MarkupLMModel"),EQo=o(" (MarkupLM model)"),CQo=l(),O2=a("li"),sTe=a("strong"),wQo=o("maskformer"),AQo=o(" \u2014 "),HW=a("a"),LQo=o("MaskFormerModel"),yQo=o(" (MaskFormer model)"),xQo=l(),V2=a("li"),lTe=a("strong"),$Qo=o("mbart"),kQo=o(" \u2014 "),JW=a("a"),SQo=o("MBartModel"),RQo=o(" (mBART model)"),PQo=l(),X2=a("li"),iTe=a("strong"),BQo=o("mctct"),IQo=o(" \u2014 "),YW=a("a"),NQo=o("MCTCTModel"),qQo=o(" (M-CTC-T model)"),jQo=l(),z2=a("li"),dTe=a("strong"),DQo=o("megatron-bert"),GQo=o(" \u2014 "),ZW=a("a"),OQo=o("MegatronBertModel"),VQo=o(" (Megatron-BERT model)"),XQo=l(),Q2=a("li"),mTe=a("strong"),zQo=o("mobilebert"),QQo=o(" \u2014 "),KW=a("a"),WQo=o("MobileBertModel"),UQo=o(" (MobileBERT model)"),HQo=l(),W2=a("li"),cTe=a("strong"),JQo=o("mobilenet_v2"),YQo=o(" \u2014 "),eU=a("a"),ZQo=o("MobileNetV2Model"),KQo=o(" (MobileNetV2 model)"),eWo=l(),U2=a("li"),fTe=a("strong"),oWo=o("mobilevit"),rWo=o(" \u2014 "),oU=a("a"),tWo=o("MobileViTModel"),aWo=o(" (MobileViT model)"),nWo=l(),H2=a("li"),gTe=a("strong"),sWo=o("mpnet"),lWo=o(" \u2014 "),rU=a("a"),iWo=o("MPNetModel"),dWo=o(" (MPNet model)"),mWo=l(),J2=a("li"),hTe=a("strong"),cWo=o("mt5"),fWo=o(" \u2014 "),tU=a("a"),gWo=o("MT5Model"),hWo=o(" (MT5 model)"),uWo=l(),Y2=a("li"),uTe=a("strong"),pWo=o("mvp"),_Wo=o(" \u2014 "),aU=a("a"),bWo=o("MvpModel"),vWo=o(" (MVP model)"),FWo=l(),Z2=a("li"),pTe=a("strong"),TWo=o("nezha"),MWo=o(" \u2014 "),nU=a("a"),EWo=o("NezhaModel"),CWo=o(" (Nezha model)"),wWo=l(),K2=a("li"),_Te=a("strong"),AWo=o("nllb"),LWo=o(" \u2014 "),sU=a("a"),yWo=o("M2M100Model"),xWo=o(" (NLLB model)"),$Wo=l(),eb=a("li"),bTe=a("strong"),kWo=o("nystromformer"),SWo=o(" \u2014 "),lU=a("a"),RWo=o("NystromformerModel"),PWo=o(" (Nystr\xF6mformer model)"),BWo=l(),ob=a("li"),vTe=a("strong"),IWo=o("openai-gpt"),NWo=o(" \u2014 "),iU=a("a"),qWo=o("OpenAIGPTModel"),jWo=o(" (OpenAI GPT model)"),DWo=l(),rb=a("li"),FTe=a("strong"),GWo=o("opt"),OWo=o(" \u2014 "),dU=a("a"),VWo=o("OPTModel"),XWo=o(" (OPT model)"),zWo=l(),tb=a("li"),TTe=a("strong"),QWo=o("owlvit"),WWo=o(" \u2014 "),mU=a("a"),UWo=o("OwlViTModel"),HWo=o(" (OWL-ViT model)"),JWo=l(),ab=a("li"),MTe=a("strong"),YWo=o("pegasus"),ZWo=o(" \u2014 "),cU=a("a"),KWo=o("PegasusModel"),eUo=o(" (Pegasus model)"),oUo=l(),nb=a("li"),ETe=a("strong"),rUo=o("pegasus_x"),tUo=o(" \u2014 "),fU=a("a"),aUo=o("PegasusXModel"),nUo=o(" (PEGASUS-X model)"),sUo=l(),sb=a("li"),CTe=a("strong"),lUo=o("perceiver"),iUo=o(" \u2014 "),gU=a("a"),dUo=o("PerceiverModel"),mUo=o(" (Perceiver model)"),cUo=l(),lb=a("li"),wTe=a("strong"),fUo=o("plbart"),gUo=o(" \u2014 "),hU=a("a"),hUo=o("PLBartModel"),uUo=o(" (PLBart model)"),pUo=l(),ib=a("li"),ATe=a("strong"),_Uo=o("poolformer"),bUo=o(" \u2014 "),uU=a("a"),vUo=o("PoolFormerModel"),FUo=o(" (PoolFormer model)"),TUo=l(),db=a("li"),LTe=a("strong"),MUo=o("prophetnet"),EUo=o(" \u2014 "),pU=a("a"),CUo=o("ProphetNetModel"),wUo=o(" (ProphetNet model)"),AUo=l(),mb=a("li"),yTe=a("strong"),LUo=o("qdqbert"),yUo=o(" \u2014 "),_U=a("a"),xUo=o("QDQBertModel"),$Uo=o(" (QDQBert model)"),kUo=l(),cb=a("li"),xTe=a("strong"),SUo=o("reformer"),RUo=o(" \u2014 "),bU=a("a"),PUo=o("ReformerModel"),BUo=o(" (Reformer model)"),IUo=l(),fb=a("li"),$Te=a("strong"),NUo=o("regnet"),qUo=o(" \u2014 "),vU=a("a"),jUo=o("RegNetModel"),DUo=o(" (RegNet model)"),GUo=l(),gb=a("li"),kTe=a("strong"),OUo=o("rembert"),VUo=o(" \u2014 "),FU=a("a"),XUo=o("RemBertModel"),zUo=o(" (RemBERT model)"),QUo=l(),hb=a("li"),STe=a("strong"),WUo=o("resnet"),UUo=o(" \u2014 "),TU=a("a"),HUo=o("ResNetModel"),JUo=o(" (ResNet model)"),YUo=l(),ub=a("li"),RTe=a("strong"),ZUo=o("retribert"),KUo=o(" \u2014 "),MU=a("a"),eHo=o("RetriBertModel"),oHo=o(" (RetriBERT model)"),rHo=l(),pb=a("li"),PTe=a("strong"),tHo=o("roberta"),aHo=o(" \u2014 "),EU=a("a"),nHo=o("RobertaModel"),sHo=o(" (RoBERTa model)"),lHo=l(),_b=a("li"),BTe=a("strong"),iHo=o("roc_bert"),dHo=o(" \u2014 "),CU=a("a"),mHo=o("RoCBertModel"),cHo=o(" (RoCBert model)"),fHo=l(),bb=a("li"),ITe=a("strong"),gHo=o("roformer"),hHo=o(" \u2014 "),wU=a("a"),uHo=o("RoFormerModel"),pHo=o(" (RoFormer model)"),_Ho=l(),vb=a("li"),NTe=a("strong"),bHo=o("segformer"),vHo=o(" \u2014 "),AU=a("a"),FHo=o("SegformerModel"),THo=o(" (SegFormer model)"),MHo=l(),Fb=a("li"),qTe=a("strong"),EHo=o("sew"),CHo=o(" \u2014 "),LU=a("a"),wHo=o("SEWModel"),AHo=o(" (SEW model)"),LHo=l(),Tb=a("li"),jTe=a("strong"),yHo=o("sew-d"),xHo=o(" \u2014 "),yU=a("a"),$Ho=o("SEWDModel"),kHo=o(" (SEW-D model)"),SHo=l(),Mb=a("li"),DTe=a("strong"),RHo=o("speech_to_text"),PHo=o(" \u2014 "),xU=a("a"),BHo=o("Speech2TextModel"),IHo=o(" (Speech2Text model)"),NHo=l(),Eb=a("li"),GTe=a("strong"),qHo=o("splinter"),jHo=o(" \u2014 "),$U=a("a"),DHo=o("SplinterModel"),GHo=o(" (Splinter model)"),OHo=l(),Cb=a("li"),OTe=a("strong"),VHo=o("squeezebert"),XHo=o(" \u2014 "),kU=a("a"),zHo=o("SqueezeBertModel"),QHo=o(" (SqueezeBERT model)"),WHo=l(),wb=a("li"),VTe=a("strong"),UHo=o("swin"),HHo=o(" \u2014 "),SU=a("a"),JHo=o("SwinModel"),YHo=o(" (Swin Transformer model)"),ZHo=l(),Ab=a("li"),XTe=a("strong"),KHo=o("swinv2"),eJo=o(" \u2014 "),RU=a("a"),oJo=o("Swinv2Model"),rJo=o(" (Swin Transformer V2 model)"),tJo=l(),Lb=a("li"),zTe=a("strong"),aJo=o("t5"),nJo=o(" \u2014 "),PU=a("a"),sJo=o("T5Model"),lJo=o(" (T5 model)"),iJo=l(),yb=a("li"),QTe=a("strong"),dJo=o("table-transformer"),mJo=o(" \u2014 "),BU=a("a"),cJo=o("TableTransformerModel"),fJo=o(" (Table Transformer model)"),gJo=l(),xb=a("li"),WTe=a("strong"),hJo=o("tapas"),uJo=o(" \u2014 "),IU=a("a"),pJo=o("TapasModel"),_Jo=o(" (TAPAS model)"),bJo=l(),$b=a("li"),UTe=a("strong"),vJo=o("time_series_transformer"),FJo=o(" \u2014 "),NU=a("a"),TJo=o("TimeSeriesTransformerModel"),MJo=o(" (Time Series Transformer model)"),EJo=l(),kb=a("li"),HTe=a("strong"),CJo=o("trajectory_transformer"),wJo=o(" \u2014 "),qU=a("a"),AJo=o("TrajectoryTransformerModel"),LJo=o(" (Trajectory Transformer model)"),yJo=l(),Sb=a("li"),JTe=a("strong"),xJo=o("transfo-xl"),$Jo=o(" \u2014 "),jU=a("a"),kJo=o("TransfoXLModel"),SJo=o(" (Transformer-XL model)"),RJo=l(),Rb=a("li"),YTe=a("strong"),PJo=o("unispeech"),BJo=o(" \u2014 "),DU=a("a"),IJo=o("UniSpeechModel"),NJo=o(" (UniSpeech model)"),qJo=l(),Pb=a("li"),ZTe=a("strong"),jJo=o("unispeech-sat"),DJo=o(" \u2014 "),GU=a("a"),GJo=o("UniSpeechSatModel"),OJo=o(" (UniSpeechSat model)"),VJo=l(),Bb=a("li"),KTe=a("strong"),XJo=o("van"),zJo=o(" \u2014 "),OU=a("a"),QJo=o("VanModel"),WJo=o(" (VAN model)"),UJo=l(),Ib=a("li"),eMe=a("strong"),HJo=o("videomae"),JJo=o(" \u2014 "),VU=a("a"),YJo=o("VideoMAEModel"),ZJo=o(" (VideoMAE model)"),KJo=l(),Nb=a("li"),oMe=a("strong"),eYo=o("vilt"),oYo=o(" \u2014 "),XU=a("a"),rYo=o("ViltModel"),tYo=o(" (ViLT model)"),aYo=l(),qb=a("li"),rMe=a("strong"),nYo=o("vision-text-dual-encoder"),sYo=o(" \u2014 "),zU=a("a"),lYo=o("VisionTextDualEncoderModel"),iYo=o(" (VisionTextDualEncoder model)"),dYo=l(),jb=a("li"),tMe=a("strong"),mYo=o("visual_bert"),cYo=o(" \u2014 "),QU=a("a"),fYo=o("VisualBertModel"),gYo=o(" (VisualBERT model)"),hYo=l(),Db=a("li"),aMe=a("strong"),uYo=o("vit"),pYo=o(" \u2014 "),WU=a("a"),_Yo=o("ViTModel"),bYo=o(" (ViT model)"),vYo=l(),Gb=a("li"),nMe=a("strong"),FYo=o("vit_mae"),TYo=o(" \u2014 "),UU=a("a"),MYo=o("ViTMAEModel"),EYo=o(" (ViTMAE model)"),CYo=l(),Ob=a("li"),sMe=a("strong"),wYo=o("vit_msn"),AYo=o(" \u2014 "),HU=a("a"),LYo=o("ViTMSNModel"),yYo=o(" (ViTMSN model)"),xYo=l(),Vb=a("li"),lMe=a("strong"),$Yo=o("wav2vec2"),kYo=o(" \u2014 "),JU=a("a"),SYo=o("Wav2Vec2Model"),RYo=o(" (Wav2Vec2 model)"),PYo=l(),Xb=a("li"),iMe=a("strong"),BYo=o("wav2vec2-conformer"),IYo=o(" \u2014 "),YU=a("a"),NYo=o("Wav2Vec2ConformerModel"),qYo=o(" (Wav2Vec2-Conformer model)"),jYo=l(),zb=a("li"),dMe=a("strong"),DYo=o("wavlm"),GYo=o(" \u2014 "),ZU=a("a"),OYo=o("WavLMModel"),VYo=o(" (WavLM model)"),XYo=l(),Qb=a("li"),mMe=a("strong"),zYo=o("whisper"),QYo=o(" \u2014 "),KU=a("a"),WYo=o("WhisperModel"),UYo=o(" (Whisper model)"),HYo=l(),Wb=a("li"),cMe=a("strong"),JYo=o("xclip"),YYo=o(" \u2014 "),eH=a("a"),ZYo=o("XCLIPModel"),KYo=o(" (X-CLIP model)"),eZo=l(),Ub=a("li"),fMe=a("strong"),oZo=o("xglm"),rZo=o(" \u2014 "),oH=a("a"),tZo=o("XGLMModel"),aZo=o(" (XGLM model)"),nZo=l(),Hb=a("li"),gMe=a("strong"),sZo=o("xlm"),lZo=o(" \u2014 "),rH=a("a"),iZo=o("XLMModel"),dZo=o(" (XLM model)"),mZo=l(),Jb=a("li"),hMe=a("strong"),cZo=o("xlm-prophetnet"),fZo=o(" \u2014 "),tH=a("a"),gZo=o("XLMProphetNetModel"),hZo=o(" (XLM-ProphetNet model)"),uZo=l(),Yb=a("li"),uMe=a("strong"),pZo=o("xlm-roberta"),_Zo=o(" \u2014 "),aH=a("a"),bZo=o("XLMRobertaModel"),vZo=o(" (XLM-RoBERTa model)"),FZo=l(),Zb=a("li"),pMe=a("strong"),TZo=o("xlm-roberta-xl"),MZo=o(" \u2014 "),nH=a("a"),EZo=o("XLMRobertaXLModel"),CZo=o(" (XLM-RoBERTa-XL model)"),wZo=l(),Kb=a("li"),_Me=a("strong"),AZo=o("xlnet"),LZo=o(" \u2014 "),sH=a("a"),yZo=o("XLNetModel"),xZo=o(" (XLNet model)"),$Zo=l(),ev=a("li"),bMe=a("strong"),kZo=o("yolos"),SZo=o(" \u2014 "),lH=a("a"),RZo=o("YolosModel"),PZo=o(" (YOLOS model)"),BZo=l(),ov=a("li"),vMe=a("strong"),IZo=o("yoso"),NZo=o(" \u2014 "),iH=a("a"),qZo=o("YosoModel"),jZo=o(" (YOSO model)"),DZo=l(),rv=a("p"),GZo=o("The model is set in evaluation mode by default using "),FMe=a("code"),OZo=o("model.eval()"),VZo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),TMe=a("code"),XZo=o("model.train()"),zZo=l(),F(tv.$$.fragment),uio=l(),Xd=a("h2"),av=a("a"),MMe=a("span"),F(aS.$$.fragment),QZo=l(),EMe=a("span"),WZo=o("AutoModelForPreTraining"),pio=l(),Go=a("div"),F(nS.$$.fragment),UZo=l(),zd=a("p"),HZo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),dH=a("a"),JZo=o("from_pretrained()"),YZo=o(" class method or the "),mH=a("a"),ZZo=o("from_config()"),KZo=o(` class
method.`),eKo=l(),sS=a("p"),oKo=o("This class cannot be instantiated directly using "),CMe=a("code"),rKo=o("__init__()"),tKo=o(" (throws an error)."),aKo=l(),Lt=a("div"),F(lS.$$.fragment),nKo=l(),wMe=a("p"),sKo=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),lKo=l(),Qd=a("p"),iKo=o(`Note:
Loading a model from its configuration file does `),AMe=a("strong"),dKo=o("not"),mKo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cH=a("a"),cKo=o("from_pretrained()"),fKo=o(" to load the model weights."),gKo=l(),F(nv.$$.fragment),hKo=l(),ao=a("div"),F(iS.$$.fragment),uKo=l(),LMe=a("p"),pKo=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),_Ko=l(),hn=a("p"),bKo=o("The model class to instantiate is selected based on the "),yMe=a("code"),vKo=o("model_type"),FKo=o(` property of the config object (either
passed as an argument or loaded from `),xMe=a("code"),TKo=o("pretrained_model_name_or_path"),MKo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Me=a("code"),EKo=o("pretrained_model_name_or_path"),CKo=o(":"),wKo=l(),G=a("ul"),sv=a("li"),kMe=a("strong"),AKo=o("albert"),LKo=o(" \u2014 "),fH=a("a"),yKo=o("AlbertForPreTraining"),xKo=o(" (ALBERT model)"),$Ko=l(),lv=a("li"),SMe=a("strong"),kKo=o("bart"),SKo=o(" \u2014 "),gH=a("a"),RKo=o("BartForConditionalGeneration"),PKo=o(" (BART model)"),BKo=l(),iv=a("li"),RMe=a("strong"),IKo=o("bert"),NKo=o(" \u2014 "),hH=a("a"),qKo=o("BertForPreTraining"),jKo=o(" (BERT model)"),DKo=l(),dv=a("li"),PMe=a("strong"),GKo=o("big_bird"),OKo=o(" \u2014 "),uH=a("a"),VKo=o("BigBirdForPreTraining"),XKo=o(" (BigBird model)"),zKo=l(),mv=a("li"),BMe=a("strong"),QKo=o("bloom"),WKo=o(" \u2014 "),pH=a("a"),UKo=o("BloomForCausalLM"),HKo=o(" (BLOOM model)"),JKo=l(),cv=a("li"),IMe=a("strong"),YKo=o("camembert"),ZKo=o(" \u2014 "),_H=a("a"),KKo=o("CamembertForMaskedLM"),eer=o(" (CamemBERT model)"),oer=l(),fv=a("li"),NMe=a("strong"),rer=o("ctrl"),ter=o(" \u2014 "),bH=a("a"),aer=o("CTRLLMHeadModel"),ner=o(" (CTRL model)"),ser=l(),gv=a("li"),qMe=a("strong"),ler=o("data2vec-text"),ier=o(" \u2014 "),vH=a("a"),der=o("Data2VecTextForMaskedLM"),mer=o(" (Data2VecText model)"),cer=l(),hv=a("li"),jMe=a("strong"),fer=o("deberta"),ger=o(" \u2014 "),FH=a("a"),her=o("DebertaForMaskedLM"),uer=o(" (DeBERTa model)"),per=l(),uv=a("li"),DMe=a("strong"),_er=o("deberta-v2"),ber=o(" \u2014 "),TH=a("a"),ver=o("DebertaV2ForMaskedLM"),Fer=o(" (DeBERTa-v2 model)"),Ter=l(),pv=a("li"),GMe=a("strong"),Mer=o("distilbert"),Eer=o(" \u2014 "),MH=a("a"),Cer=o("DistilBertForMaskedLM"),wer=o(" (DistilBERT model)"),Aer=l(),_v=a("li"),OMe=a("strong"),Ler=o("electra"),yer=o(" \u2014 "),EH=a("a"),xer=o("ElectraForPreTraining"),$er=o(" (ELECTRA model)"),ker=l(),bv=a("li"),VMe=a("strong"),Ser=o("ernie"),Rer=o(" \u2014 "),CH=a("a"),Per=o("ErnieForPreTraining"),Ber=o(" (ERNIE model)"),Ier=l(),vv=a("li"),XMe=a("strong"),Ner=o("flaubert"),qer=o(" \u2014 "),wH=a("a"),jer=o("FlaubertWithLMHeadModel"),Der=o(" (FlauBERT model)"),Ger=l(),Fv=a("li"),zMe=a("strong"),Oer=o("flava"),Ver=o(" \u2014 "),AH=a("a"),Xer=o("FlavaForPreTraining"),zer=o(" (FLAVA model)"),Qer=l(),Tv=a("li"),QMe=a("strong"),Wer=o("fnet"),Uer=o(" \u2014 "),LH=a("a"),Her=o("FNetForPreTraining"),Jer=o(" (FNet model)"),Yer=l(),Mv=a("li"),WMe=a("strong"),Zer=o("fsmt"),Ker=o(" \u2014 "),yH=a("a"),eor=o("FSMTForConditionalGeneration"),oor=o(" (FairSeq Machine-Translation model)"),ror=l(),Ev=a("li"),UMe=a("strong"),tor=o("funnel"),aor=o(" \u2014 "),xH=a("a"),nor=o("FunnelForPreTraining"),sor=o(" (Funnel Transformer model)"),lor=l(),Cv=a("li"),HMe=a("strong"),ior=o("gpt2"),dor=o(" \u2014 "),$H=a("a"),mor=o("GPT2LMHeadModel"),cor=o(" (OpenAI GPT-2 model)"),gor=l(),wv=a("li"),JMe=a("strong"),hor=o("ibert"),uor=o(" \u2014 "),kH=a("a"),por=o("IBertForMaskedLM"),_or=o(" (I-BERT model)"),bor=l(),Av=a("li"),YMe=a("strong"),vor=o("layoutlm"),For=o(" \u2014 "),SH=a("a"),Tor=o("LayoutLMForMaskedLM"),Mor=o(" (LayoutLM model)"),Eor=l(),Lv=a("li"),ZMe=a("strong"),Cor=o("longformer"),wor=o(" \u2014 "),RH=a("a"),Aor=o("LongformerForMaskedLM"),Lor=o(" (Longformer model)"),yor=l(),yv=a("li"),KMe=a("strong"),xor=o("luke"),$or=o(" \u2014 "),PH=a("a"),kor=o("LukeForMaskedLM"),Sor=o(" (LUKE model)"),Ror=l(),xv=a("li"),eEe=a("strong"),Por=o("lxmert"),Bor=o(" \u2014 "),BH=a("a"),Ior=o("LxmertForPreTraining"),Nor=o(" (LXMERT model)"),qor=l(),$v=a("li"),oEe=a("strong"),jor=o("megatron-bert"),Dor=o(" \u2014 "),IH=a("a"),Gor=o("MegatronBertForPreTraining"),Oor=o(" (Megatron-BERT model)"),Vor=l(),kv=a("li"),rEe=a("strong"),Xor=o("mobilebert"),zor=o(" \u2014 "),NH=a("a"),Qor=o("MobileBertForPreTraining"),Wor=o(" (MobileBERT model)"),Uor=l(),Sv=a("li"),tEe=a("strong"),Hor=o("mpnet"),Jor=o(" \u2014 "),qH=a("a"),Yor=o("MPNetForMaskedLM"),Zor=o(" (MPNet model)"),Kor=l(),Rv=a("li"),aEe=a("strong"),err=o("mvp"),orr=o(" \u2014 "),jH=a("a"),rrr=o("MvpForConditionalGeneration"),trr=o(" (MVP model)"),arr=l(),Pv=a("li"),nEe=a("strong"),nrr=o("nezha"),srr=o(" \u2014 "),DH=a("a"),lrr=o("NezhaForPreTraining"),irr=o(" (Nezha model)"),drr=l(),Bv=a("li"),sEe=a("strong"),mrr=o("openai-gpt"),crr=o(" \u2014 "),GH=a("a"),frr=o("OpenAIGPTLMHeadModel"),grr=o(" (OpenAI GPT model)"),hrr=l(),Iv=a("li"),lEe=a("strong"),urr=o("retribert"),prr=o(" \u2014 "),OH=a("a"),_rr=o("RetriBertModel"),brr=o(" (RetriBERT model)"),vrr=l(),Nv=a("li"),iEe=a("strong"),Frr=o("roberta"),Trr=o(" \u2014 "),VH=a("a"),Mrr=o("RobertaForMaskedLM"),Err=o(" (RoBERTa model)"),Crr=l(),qv=a("li"),dEe=a("strong"),wrr=o("roc_bert"),Arr=o(" \u2014 "),XH=a("a"),Lrr=o("RoCBertForPreTraining"),yrr=o(" (RoCBert model)"),xrr=l(),jv=a("li"),mEe=a("strong"),$rr=o("splinter"),krr=o(" \u2014 "),zH=a("a"),Srr=o("SplinterForPreTraining"),Rrr=o(" (Splinter model)"),Prr=l(),Dv=a("li"),cEe=a("strong"),Brr=o("squeezebert"),Irr=o(" \u2014 "),QH=a("a"),Nrr=o("SqueezeBertForMaskedLM"),qrr=o(" (SqueezeBERT model)"),jrr=l(),Gv=a("li"),fEe=a("strong"),Drr=o("t5"),Grr=o(" \u2014 "),WH=a("a"),Orr=o("T5ForConditionalGeneration"),Vrr=o(" (T5 model)"),Xrr=l(),Ov=a("li"),gEe=a("strong"),zrr=o("tapas"),Qrr=o(" \u2014 "),UH=a("a"),Wrr=o("TapasForMaskedLM"),Urr=o(" (TAPAS model)"),Hrr=l(),Vv=a("li"),hEe=a("strong"),Jrr=o("transfo-xl"),Yrr=o(" \u2014 "),HH=a("a"),Zrr=o("TransfoXLLMHeadModel"),Krr=o(" (Transformer-XL model)"),etr=l(),Xv=a("li"),uEe=a("strong"),otr=o("unispeech"),rtr=o(" \u2014 "),JH=a("a"),ttr=o("UniSpeechForPreTraining"),atr=o(" (UniSpeech model)"),ntr=l(),zv=a("li"),pEe=a("strong"),str=o("unispeech-sat"),ltr=o(" \u2014 "),YH=a("a"),itr=o("UniSpeechSatForPreTraining"),dtr=o(" (UniSpeechSat model)"),mtr=l(),Qv=a("li"),_Ee=a("strong"),ctr=o("videomae"),ftr=o(" \u2014 "),ZH=a("a"),gtr=o("VideoMAEForPreTraining"),htr=o(" (VideoMAE model)"),utr=l(),Wv=a("li"),bEe=a("strong"),ptr=o("visual_bert"),_tr=o(" \u2014 "),KH=a("a"),btr=o("VisualBertForPreTraining"),vtr=o(" (VisualBERT model)"),Ftr=l(),Uv=a("li"),vEe=a("strong"),Ttr=o("vit_mae"),Mtr=o(" \u2014 "),eJ=a("a"),Etr=o("ViTMAEForPreTraining"),Ctr=o(" (ViTMAE model)"),wtr=l(),Hv=a("li"),FEe=a("strong"),Atr=o("wav2vec2"),Ltr=o(" \u2014 "),oJ=a("a"),ytr=o("Wav2Vec2ForPreTraining"),xtr=o(" (Wav2Vec2 model)"),$tr=l(),Jv=a("li"),TEe=a("strong"),ktr=o("wav2vec2-conformer"),Str=o(" \u2014 "),rJ=a("a"),Rtr=o("Wav2Vec2ConformerForPreTraining"),Ptr=o(" (Wav2Vec2-Conformer model)"),Btr=l(),Yv=a("li"),MEe=a("strong"),Itr=o("xlm"),Ntr=o(" \u2014 "),tJ=a("a"),qtr=o("XLMWithLMHeadModel"),jtr=o(" (XLM model)"),Dtr=l(),Zv=a("li"),EEe=a("strong"),Gtr=o("xlm-roberta"),Otr=o(" \u2014 "),aJ=a("a"),Vtr=o("XLMRobertaForMaskedLM"),Xtr=o(" (XLM-RoBERTa model)"),ztr=l(),Kv=a("li"),CEe=a("strong"),Qtr=o("xlm-roberta-xl"),Wtr=o(" \u2014 "),nJ=a("a"),Utr=o("XLMRobertaXLForMaskedLM"),Htr=o(" (XLM-RoBERTa-XL model)"),Jtr=l(),eF=a("li"),wEe=a("strong"),Ytr=o("xlnet"),Ztr=o(" \u2014 "),sJ=a("a"),Ktr=o("XLNetLMHeadModel"),ear=o(" (XLNet model)"),oar=l(),oF=a("p"),rar=o("The model is set in evaluation mode by default using "),AEe=a("code"),tar=o("model.eval()"),aar=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),LEe=a("code"),nar=o("model.train()"),sar=l(),F(rF.$$.fragment),_io=l(),Wd=a("h2"),tF=a("a"),yEe=a("span"),F(dS.$$.fragment),lar=l(),xEe=a("span"),iar=o("AutoModelForCausalLM"),bio=l(),Oo=a("div"),F(mS.$$.fragment),dar=l(),Ud=a("p"),mar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),lJ=a("a"),car=o("from_pretrained()"),far=o(" class method or the "),iJ=a("a"),gar=o("from_config()"),har=o(` class
method.`),uar=l(),cS=a("p"),par=o("This class cannot be instantiated directly using "),$Ee=a("code"),_ar=o("__init__()"),bar=o(" (throws an error)."),Far=l(),yt=a("div"),F(fS.$$.fragment),Tar=l(),kEe=a("p"),Mar=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Ear=l(),Hd=a("p"),Car=o(`Note:
Loading a model from its configuration file does `),SEe=a("strong"),war=o("not"),Aar=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dJ=a("a"),Lar=o("from_pretrained()"),yar=o(" to load the model weights."),xar=l(),F(aF.$$.fragment),$ar=l(),no=a("div"),F(gS.$$.fragment),kar=l(),REe=a("p"),Sar=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Rar=l(),un=a("p"),Par=o("The model class to instantiate is selected based on the "),PEe=a("code"),Bar=o("model_type"),Iar=o(` property of the config object (either
passed as an argument or loaded from `),BEe=a("code"),Nar=o("pretrained_model_name_or_path"),qar=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IEe=a("code"),jar=o("pretrained_model_name_or_path"),Dar=o(":"),Gar=l(),W=a("ul"),nF=a("li"),NEe=a("strong"),Oar=o("bart"),Var=o(" \u2014 "),mJ=a("a"),Xar=o("BartForCausalLM"),zar=o(" (BART model)"),Qar=l(),sF=a("li"),qEe=a("strong"),War=o("bert"),Uar=o(" \u2014 "),cJ=a("a"),Har=o("BertLMHeadModel"),Jar=o(" (BERT model)"),Yar=l(),lF=a("li"),jEe=a("strong"),Zar=o("bert-generation"),Kar=o(" \u2014 "),fJ=a("a"),enr=o("BertGenerationDecoder"),onr=o(" (Bert Generation model)"),rnr=l(),iF=a("li"),DEe=a("strong"),tnr=o("big_bird"),anr=o(" \u2014 "),gJ=a("a"),nnr=o("BigBirdForCausalLM"),snr=o(" (BigBird model)"),lnr=l(),dF=a("li"),GEe=a("strong"),inr=o("bigbird_pegasus"),dnr=o(" \u2014 "),hJ=a("a"),mnr=o("BigBirdPegasusForCausalLM"),cnr=o(" (BigBird-Pegasus model)"),fnr=l(),mF=a("li"),OEe=a("strong"),gnr=o("blenderbot"),hnr=o(" \u2014 "),uJ=a("a"),unr=o("BlenderbotForCausalLM"),pnr=o(" (Blenderbot model)"),_nr=l(),cF=a("li"),VEe=a("strong"),bnr=o("blenderbot-small"),vnr=o(" \u2014 "),pJ=a("a"),Fnr=o("BlenderbotSmallForCausalLM"),Tnr=o(" (BlenderbotSmall model)"),Mnr=l(),fF=a("li"),XEe=a("strong"),Enr=o("bloom"),Cnr=o(" \u2014 "),_J=a("a"),wnr=o("BloomForCausalLM"),Anr=o(" (BLOOM model)"),Lnr=l(),gF=a("li"),zEe=a("strong"),ynr=o("camembert"),xnr=o(" \u2014 "),bJ=a("a"),$nr=o("CamembertForCausalLM"),knr=o(" (CamemBERT model)"),Snr=l(),hF=a("li"),QEe=a("strong"),Rnr=o("codegen"),Pnr=o(" \u2014 "),vJ=a("a"),Bnr=o("CodeGenForCausalLM"),Inr=o(" (CodeGen model)"),Nnr=l(),uF=a("li"),WEe=a("strong"),qnr=o("ctrl"),jnr=o(" \u2014 "),FJ=a("a"),Dnr=o("CTRLLMHeadModel"),Gnr=o(" (CTRL model)"),Onr=l(),pF=a("li"),UEe=a("strong"),Vnr=o("data2vec-text"),Xnr=o(" \u2014 "),TJ=a("a"),znr=o("Data2VecTextForCausalLM"),Qnr=o(" (Data2VecText model)"),Wnr=l(),_F=a("li"),HEe=a("strong"),Unr=o("electra"),Hnr=o(" \u2014 "),MJ=a("a"),Jnr=o("ElectraForCausalLM"),Ynr=o(" (ELECTRA model)"),Znr=l(),bF=a("li"),JEe=a("strong"),Knr=o("ernie"),esr=o(" \u2014 "),EJ=a("a"),osr=o("ErnieForCausalLM"),rsr=o(" (ERNIE model)"),tsr=l(),vF=a("li"),YEe=a("strong"),asr=o("gpt2"),nsr=o(" \u2014 "),CJ=a("a"),ssr=o("GPT2LMHeadModel"),lsr=o(" (OpenAI GPT-2 model)"),isr=l(),FF=a("li"),ZEe=a("strong"),dsr=o("gpt_neo"),msr=o(" \u2014 "),wJ=a("a"),csr=o("GPTNeoForCausalLM"),fsr=o(" (GPT Neo model)"),gsr=l(),TF=a("li"),KEe=a("strong"),hsr=o("gpt_neox"),usr=o(" \u2014 "),AJ=a("a"),psr=o("GPTNeoXForCausalLM"),_sr=o(" (GPT NeoX model)"),bsr=l(),MF=a("li"),e4e=a("strong"),vsr=o("gpt_neox_japanese"),Fsr=o(" \u2014 "),LJ=a("a"),Tsr=o("GPTNeoXJapaneseForCausalLM"),Msr=o(" (GPT NeoX Japanese model)"),Esr=l(),EF=a("li"),o4e=a("strong"),Csr=o("gptj"),wsr=o(" \u2014 "),yJ=a("a"),Asr=o("GPTJForCausalLM"),Lsr=o(" (GPT-J model)"),ysr=l(),CF=a("li"),r4e=a("strong"),xsr=o("marian"),$sr=o(" \u2014 "),xJ=a("a"),ksr=o("MarianForCausalLM"),Ssr=o(" (Marian model)"),Rsr=l(),wF=a("li"),t4e=a("strong"),Psr=o("mbart"),Bsr=o(" \u2014 "),$J=a("a"),Isr=o("MBartForCausalLM"),Nsr=o(" (mBART model)"),qsr=l(),AF=a("li"),a4e=a("strong"),jsr=o("megatron-bert"),Dsr=o(" \u2014 "),kJ=a("a"),Gsr=o("MegatronBertForCausalLM"),Osr=o(" (Megatron-BERT model)"),Vsr=l(),LF=a("li"),n4e=a("strong"),Xsr=o("mvp"),zsr=o(" \u2014 "),SJ=a("a"),Qsr=o("MvpForCausalLM"),Wsr=o(" (MVP model)"),Usr=l(),yF=a("li"),s4e=a("strong"),Hsr=o("openai-gpt"),Jsr=o(" \u2014 "),RJ=a("a"),Ysr=o("OpenAIGPTLMHeadModel"),Zsr=o(" (OpenAI GPT model)"),Ksr=l(),xF=a("li"),l4e=a("strong"),elr=o("opt"),olr=o(" \u2014 "),PJ=a("a"),rlr=o("OPTForCausalLM"),tlr=o(" (OPT model)"),alr=l(),$F=a("li"),i4e=a("strong"),nlr=o("pegasus"),slr=o(" \u2014 "),BJ=a("a"),llr=o("PegasusForCausalLM"),ilr=o(" (Pegasus model)"),dlr=l(),kF=a("li"),d4e=a("strong"),mlr=o("plbart"),clr=o(" \u2014 "),IJ=a("a"),flr=o("PLBartForCausalLM"),glr=o(" (PLBart model)"),hlr=l(),SF=a("li"),m4e=a("strong"),ulr=o("prophetnet"),plr=o(" \u2014 "),NJ=a("a"),_lr=o("ProphetNetForCausalLM"),blr=o(" (ProphetNet model)"),vlr=l(),RF=a("li"),c4e=a("strong"),Flr=o("qdqbert"),Tlr=o(" \u2014 "),qJ=a("a"),Mlr=o("QDQBertLMHeadModel"),Elr=o(" (QDQBert model)"),Clr=l(),PF=a("li"),f4e=a("strong"),wlr=o("reformer"),Alr=o(" \u2014 "),jJ=a("a"),Llr=o("ReformerModelWithLMHead"),ylr=o(" (Reformer model)"),xlr=l(),BF=a("li"),g4e=a("strong"),$lr=o("rembert"),klr=o(" \u2014 "),DJ=a("a"),Slr=o("RemBertForCausalLM"),Rlr=o(" (RemBERT model)"),Plr=l(),IF=a("li"),h4e=a("strong"),Blr=o("roberta"),Ilr=o(" \u2014 "),GJ=a("a"),Nlr=o("RobertaForCausalLM"),qlr=o(" (RoBERTa model)"),jlr=l(),NF=a("li"),u4e=a("strong"),Dlr=o("roc_bert"),Glr=o(" \u2014 "),OJ=a("a"),Olr=o("RoCBertForCausalLM"),Vlr=o(" (RoCBert model)"),Xlr=l(),qF=a("li"),p4e=a("strong"),zlr=o("roformer"),Qlr=o(" \u2014 "),VJ=a("a"),Wlr=o("RoFormerForCausalLM"),Ulr=o(" (RoFormer model)"),Hlr=l(),jF=a("li"),_4e=a("strong"),Jlr=o("speech_to_text_2"),Ylr=o(" \u2014 "),XJ=a("a"),Zlr=o("Speech2Text2ForCausalLM"),Klr=o(" (Speech2Text2 model)"),eir=l(),DF=a("li"),b4e=a("strong"),oir=o("transfo-xl"),rir=o(" \u2014 "),zJ=a("a"),tir=o("TransfoXLLMHeadModel"),air=o(" (Transformer-XL model)"),nir=l(),GF=a("li"),v4e=a("strong"),sir=o("trocr"),lir=o(" \u2014 "),QJ=a("a"),iir=o("TrOCRForCausalLM"),dir=o(" (TrOCR model)"),mir=l(),OF=a("li"),F4e=a("strong"),cir=o("xglm"),fir=o(" \u2014 "),WJ=a("a"),gir=o("XGLMForCausalLM"),hir=o(" (XGLM model)"),uir=l(),VF=a("li"),T4e=a("strong"),pir=o("xlm"),_ir=o(" \u2014 "),UJ=a("a"),bir=o("XLMWithLMHeadModel"),vir=o(" (XLM model)"),Fir=l(),XF=a("li"),M4e=a("strong"),Tir=o("xlm-prophetnet"),Mir=o(" \u2014 "),HJ=a("a"),Eir=o("XLMProphetNetForCausalLM"),Cir=o(" (XLM-ProphetNet model)"),wir=l(),zF=a("li"),E4e=a("strong"),Air=o("xlm-roberta"),Lir=o(" \u2014 "),JJ=a("a"),yir=o("XLMRobertaForCausalLM"),xir=o(" (XLM-RoBERTa model)"),$ir=l(),QF=a("li"),C4e=a("strong"),kir=o("xlm-roberta-xl"),Sir=o(" \u2014 "),YJ=a("a"),Rir=o("XLMRobertaXLForCausalLM"),Pir=o(" (XLM-RoBERTa-XL model)"),Bir=l(),WF=a("li"),w4e=a("strong"),Iir=o("xlnet"),Nir=o(" \u2014 "),ZJ=a("a"),qir=o("XLNetLMHeadModel"),jir=o(" (XLNet model)"),Dir=l(),UF=a("p"),Gir=o("The model is set in evaluation mode by default using "),A4e=a("code"),Oir=o("model.eval()"),Vir=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),L4e=a("code"),Xir=o("model.train()"),zir=l(),F(HF.$$.fragment),vio=l(),Jd=a("h2"),JF=a("a"),y4e=a("span"),F(hS.$$.fragment),Qir=l(),x4e=a("span"),Wir=o("AutoModelForDepthEstimation"),Fio=l(),Vo=a("div"),F(uS.$$.fragment),Uir=l(),Yd=a("p"),Hir=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),KJ=a("a"),Jir=o("from_pretrained()"),Yir=o(" class method or the "),eY=a("a"),Zir=o("from_config()"),Kir=o(` class
method.`),edr=l(),pS=a("p"),odr=o("This class cannot be instantiated directly using "),$4e=a("code"),rdr=o("__init__()"),tdr=o(" (throws an error)."),adr=l(),xt=a("div"),F(_S.$$.fragment),ndr=l(),k4e=a("p"),sdr=o("Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),ldr=l(),Zd=a("p"),idr=o(`Note:
Loading a model from its configuration file does `),S4e=a("strong"),ddr=o("not"),mdr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oY=a("a"),cdr=o("from_pretrained()"),fdr=o(" to load the model weights."),gdr=l(),F(YF.$$.fragment),hdr=l(),so=a("div"),F(bS.$$.fragment),udr=l(),R4e=a("p"),pdr=o("Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),_dr=l(),pn=a("p"),bdr=o("The model class to instantiate is selected based on the "),P4e=a("code"),vdr=o("model_type"),Fdr=o(` property of the config object (either
passed as an argument or loaded from `),B4e=a("code"),Tdr=o("pretrained_model_name_or_path"),Mdr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I4e=a("code"),Edr=o("pretrained_model_name_or_path"),Cdr=o(":"),wdr=l(),vS=a("ul"),ZF=a("li"),N4e=a("strong"),Adr=o("dpt"),Ldr=o(" \u2014 "),rY=a("a"),ydr=o("DPTForDepthEstimation"),xdr=o(" (DPT model)"),$dr=l(),KF=a("li"),q4e=a("strong"),kdr=o("glpn"),Sdr=o(" \u2014 "),tY=a("a"),Rdr=o("GLPNForDepthEstimation"),Pdr=o(" (GLPN model)"),Bdr=l(),eT=a("p"),Idr=o("The model is set in evaluation mode by default using "),j4e=a("code"),Ndr=o("model.eval()"),qdr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),D4e=a("code"),jdr=o("model.train()"),Ddr=l(),F(oT.$$.fragment),Tio=l(),Kd=a("h2"),rT=a("a"),G4e=a("span"),F(FS.$$.fragment),Gdr=l(),O4e=a("span"),Odr=o("AutoModelForMaskedLM"),Mio=l(),Xo=a("div"),F(TS.$$.fragment),Vdr=l(),em=a("p"),Xdr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),aY=a("a"),zdr=o("from_pretrained()"),Qdr=o(" class method or the "),nY=a("a"),Wdr=o("from_config()"),Udr=o(` class
method.`),Hdr=l(),MS=a("p"),Jdr=o("This class cannot be instantiated directly using "),V4e=a("code"),Ydr=o("__init__()"),Zdr=o(" (throws an error)."),Kdr=l(),$t=a("div"),F(ES.$$.fragment),emr=l(),X4e=a("p"),omr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),rmr=l(),om=a("p"),tmr=o(`Note:
Loading a model from its configuration file does `),z4e=a("strong"),amr=o("not"),nmr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sY=a("a"),smr=o("from_pretrained()"),lmr=o(" to load the model weights."),imr=l(),F(tT.$$.fragment),dmr=l(),lo=a("div"),F(CS.$$.fragment),mmr=l(),Q4e=a("p"),cmr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),fmr=l(),_n=a("p"),gmr=o("The model class to instantiate is selected based on the "),W4e=a("code"),hmr=o("model_type"),umr=o(` property of the config object (either
passed as an argument or loaded from `),U4e=a("code"),pmr=o("pretrained_model_name_or_path"),_mr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H4e=a("code"),bmr=o("pretrained_model_name_or_path"),vmr=o(":"),Fmr=l(),Y=a("ul"),aT=a("li"),J4e=a("strong"),Tmr=o("albert"),Mmr=o(" \u2014 "),lY=a("a"),Emr=o("AlbertForMaskedLM"),Cmr=o(" (ALBERT model)"),wmr=l(),nT=a("li"),Y4e=a("strong"),Amr=o("bart"),Lmr=o(" \u2014 "),iY=a("a"),ymr=o("BartForConditionalGeneration"),xmr=o(" (BART model)"),$mr=l(),sT=a("li"),Z4e=a("strong"),kmr=o("bert"),Smr=o(" \u2014 "),dY=a("a"),Rmr=o("BertForMaskedLM"),Pmr=o(" (BERT model)"),Bmr=l(),lT=a("li"),K4e=a("strong"),Imr=o("big_bird"),Nmr=o(" \u2014 "),mY=a("a"),qmr=o("BigBirdForMaskedLM"),jmr=o(" (BigBird model)"),Dmr=l(),iT=a("li"),eCe=a("strong"),Gmr=o("camembert"),Omr=o(" \u2014 "),cY=a("a"),Vmr=o("CamembertForMaskedLM"),Xmr=o(" (CamemBERT model)"),zmr=l(),dT=a("li"),oCe=a("strong"),Qmr=o("convbert"),Wmr=o(" \u2014 "),fY=a("a"),Umr=o("ConvBertForMaskedLM"),Hmr=o(" (ConvBERT model)"),Jmr=l(),mT=a("li"),rCe=a("strong"),Ymr=o("data2vec-text"),Zmr=o(" \u2014 "),gY=a("a"),Kmr=o("Data2VecTextForMaskedLM"),ecr=o(" (Data2VecText model)"),ocr=l(),cT=a("li"),tCe=a("strong"),rcr=o("deberta"),tcr=o(" \u2014 "),hY=a("a"),acr=o("DebertaForMaskedLM"),ncr=o(" (DeBERTa model)"),scr=l(),fT=a("li"),aCe=a("strong"),lcr=o("deberta-v2"),icr=o(" \u2014 "),uY=a("a"),dcr=o("DebertaV2ForMaskedLM"),mcr=o(" (DeBERTa-v2 model)"),ccr=l(),gT=a("li"),nCe=a("strong"),fcr=o("distilbert"),gcr=o(" \u2014 "),pY=a("a"),hcr=o("DistilBertForMaskedLM"),ucr=o(" (DistilBERT model)"),pcr=l(),hT=a("li"),sCe=a("strong"),_cr=o("electra"),bcr=o(" \u2014 "),_Y=a("a"),vcr=o("ElectraForMaskedLM"),Fcr=o(" (ELECTRA model)"),Tcr=l(),uT=a("li"),lCe=a("strong"),Mcr=o("ernie"),Ecr=o(" \u2014 "),bY=a("a"),Ccr=o("ErnieForMaskedLM"),wcr=o(" (ERNIE model)"),Acr=l(),pT=a("li"),iCe=a("strong"),Lcr=o("flaubert"),ycr=o(" \u2014 "),vY=a("a"),xcr=o("FlaubertWithLMHeadModel"),$cr=o(" (FlauBERT model)"),kcr=l(),_T=a("li"),dCe=a("strong"),Scr=o("fnet"),Rcr=o(" \u2014 "),FY=a("a"),Pcr=o("FNetForMaskedLM"),Bcr=o(" (FNet model)"),Icr=l(),bT=a("li"),mCe=a("strong"),Ncr=o("funnel"),qcr=o(" \u2014 "),TY=a("a"),jcr=o("FunnelForMaskedLM"),Dcr=o(" (Funnel Transformer model)"),Gcr=l(),vT=a("li"),cCe=a("strong"),Ocr=o("ibert"),Vcr=o(" \u2014 "),MY=a("a"),Xcr=o("IBertForMaskedLM"),zcr=o(" (I-BERT model)"),Qcr=l(),FT=a("li"),fCe=a("strong"),Wcr=o("layoutlm"),Ucr=o(" \u2014 "),EY=a("a"),Hcr=o("LayoutLMForMaskedLM"),Jcr=o(" (LayoutLM model)"),Ycr=l(),TT=a("li"),gCe=a("strong"),Zcr=o("longformer"),Kcr=o(" \u2014 "),CY=a("a"),efr=o("LongformerForMaskedLM"),ofr=o(" (Longformer model)"),rfr=l(),MT=a("li"),hCe=a("strong"),tfr=o("luke"),afr=o(" \u2014 "),wY=a("a"),nfr=o("LukeForMaskedLM"),sfr=o(" (LUKE model)"),lfr=l(),ET=a("li"),uCe=a("strong"),ifr=o("mbart"),dfr=o(" \u2014 "),AY=a("a"),mfr=o("MBartForConditionalGeneration"),cfr=o(" (mBART model)"),ffr=l(),CT=a("li"),pCe=a("strong"),gfr=o("megatron-bert"),hfr=o(" \u2014 "),LY=a("a"),ufr=o("MegatronBertForMaskedLM"),pfr=o(" (Megatron-BERT model)"),_fr=l(),wT=a("li"),_Ce=a("strong"),bfr=o("mobilebert"),vfr=o(" \u2014 "),yY=a("a"),Ffr=o("MobileBertForMaskedLM"),Tfr=o(" (MobileBERT model)"),Mfr=l(),AT=a("li"),bCe=a("strong"),Efr=o("mpnet"),Cfr=o(" \u2014 "),xY=a("a"),wfr=o("MPNetForMaskedLM"),Afr=o(" (MPNet model)"),Lfr=l(),LT=a("li"),vCe=a("strong"),yfr=o("mvp"),xfr=o(" \u2014 "),$Y=a("a"),$fr=o("MvpForConditionalGeneration"),kfr=o(" (MVP model)"),Sfr=l(),yT=a("li"),FCe=a("strong"),Rfr=o("nezha"),Pfr=o(" \u2014 "),kY=a("a"),Bfr=o("NezhaForMaskedLM"),Ifr=o(" (Nezha model)"),Nfr=l(),xT=a("li"),TCe=a("strong"),qfr=o("nystromformer"),jfr=o(" \u2014 "),SY=a("a"),Dfr=o("NystromformerForMaskedLM"),Gfr=o(" (Nystr\xF6mformer model)"),Ofr=l(),$T=a("li"),MCe=a("strong"),Vfr=o("perceiver"),Xfr=o(" \u2014 "),RY=a("a"),zfr=o("PerceiverForMaskedLM"),Qfr=o(" (Perceiver model)"),Wfr=l(),kT=a("li"),ECe=a("strong"),Ufr=o("qdqbert"),Hfr=o(" \u2014 "),PY=a("a"),Jfr=o("QDQBertForMaskedLM"),Yfr=o(" (QDQBert model)"),Zfr=l(),ST=a("li"),CCe=a("strong"),Kfr=o("reformer"),egr=o(" \u2014 "),BY=a("a"),ogr=o("ReformerForMaskedLM"),rgr=o(" (Reformer model)"),tgr=l(),RT=a("li"),wCe=a("strong"),agr=o("rembert"),ngr=o(" \u2014 "),IY=a("a"),sgr=o("RemBertForMaskedLM"),lgr=o(" (RemBERT model)"),igr=l(),PT=a("li"),ACe=a("strong"),dgr=o("roberta"),mgr=o(" \u2014 "),NY=a("a"),cgr=o("RobertaForMaskedLM"),fgr=o(" (RoBERTa model)"),ggr=l(),BT=a("li"),LCe=a("strong"),hgr=o("roc_bert"),ugr=o(" \u2014 "),qY=a("a"),pgr=o("RoCBertForMaskedLM"),_gr=o(" (RoCBert model)"),bgr=l(),IT=a("li"),yCe=a("strong"),vgr=o("roformer"),Fgr=o(" \u2014 "),jY=a("a"),Tgr=o("RoFormerForMaskedLM"),Mgr=o(" (RoFormer model)"),Egr=l(),NT=a("li"),xCe=a("strong"),Cgr=o("squeezebert"),wgr=o(" \u2014 "),DY=a("a"),Agr=o("SqueezeBertForMaskedLM"),Lgr=o(" (SqueezeBERT model)"),ygr=l(),qT=a("li"),$Ce=a("strong"),xgr=o("tapas"),$gr=o(" \u2014 "),GY=a("a"),kgr=o("TapasForMaskedLM"),Sgr=o(" (TAPAS model)"),Rgr=l(),jT=a("li"),kCe=a("strong"),Pgr=o("wav2vec2"),Bgr=o(" \u2014 "),SCe=a("code"),Igr=o("Wav2Vec2ForMaskedLM"),Ngr=o(" (Wav2Vec2 model)"),qgr=l(),DT=a("li"),RCe=a("strong"),jgr=o("xlm"),Dgr=o(" \u2014 "),OY=a("a"),Ggr=o("XLMWithLMHeadModel"),Ogr=o(" (XLM model)"),Vgr=l(),GT=a("li"),PCe=a("strong"),Xgr=o("xlm-roberta"),zgr=o(" \u2014 "),VY=a("a"),Qgr=o("XLMRobertaForMaskedLM"),Wgr=o(" (XLM-RoBERTa model)"),Ugr=l(),OT=a("li"),BCe=a("strong"),Hgr=o("xlm-roberta-xl"),Jgr=o(" \u2014 "),XY=a("a"),Ygr=o("XLMRobertaXLForMaskedLM"),Zgr=o(" (XLM-RoBERTa-XL model)"),Kgr=l(),VT=a("li"),ICe=a("strong"),ehr=o("yoso"),ohr=o(" \u2014 "),zY=a("a"),rhr=o("YosoForMaskedLM"),thr=o(" (YOSO model)"),ahr=l(),XT=a("p"),nhr=o("The model is set in evaluation mode by default using "),NCe=a("code"),shr=o("model.eval()"),lhr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qCe=a("code"),ihr=o("model.train()"),dhr=l(),F(zT.$$.fragment),Eio=l(),rm=a("h2"),QT=a("a"),jCe=a("span"),F(wS.$$.fragment),mhr=l(),DCe=a("span"),chr=o("AutoModelForSeq2SeqLM"),Cio=l(),zo=a("div"),F(AS.$$.fragment),fhr=l(),tm=a("p"),ghr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),QY=a("a"),hhr=o("from_pretrained()"),uhr=o(" class method or the "),WY=a("a"),phr=o("from_config()"),_hr=o(` class
method.`),bhr=l(),LS=a("p"),vhr=o("This class cannot be instantiated directly using "),GCe=a("code"),Fhr=o("__init__()"),Thr=o(" (throws an error)."),Mhr=l(),kt=a("div"),F(yS.$$.fragment),Ehr=l(),OCe=a("p"),Chr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),whr=l(),am=a("p"),Ahr=o(`Note:
Loading a model from its configuration file does `),VCe=a("strong"),Lhr=o("not"),yhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),UY=a("a"),xhr=o("from_pretrained()"),$hr=o(" to load the model weights."),khr=l(),F(WT.$$.fragment),Shr=l(),io=a("div"),F(xS.$$.fragment),Rhr=l(),XCe=a("p"),Phr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Bhr=l(),bn=a("p"),Ihr=o("The model class to instantiate is selected based on the "),zCe=a("code"),Nhr=o("model_type"),qhr=o(` property of the config object (either
passed as an argument or loaded from `),QCe=a("code"),jhr=o("pretrained_model_name_or_path"),Dhr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),WCe=a("code"),Ghr=o("pretrained_model_name_or_path"),Ohr=o(":"),Vhr=l(),pe=a("ul"),UT=a("li"),UCe=a("strong"),Xhr=o("bart"),zhr=o(" \u2014 "),HY=a("a"),Qhr=o("BartForConditionalGeneration"),Whr=o(" (BART model)"),Uhr=l(),HT=a("li"),HCe=a("strong"),Hhr=o("bigbird_pegasus"),Jhr=o(" \u2014 "),JY=a("a"),Yhr=o("BigBirdPegasusForConditionalGeneration"),Zhr=o(" (BigBird-Pegasus model)"),Khr=l(),JT=a("li"),JCe=a("strong"),eur=o("blenderbot"),our=o(" \u2014 "),YY=a("a"),rur=o("BlenderbotForConditionalGeneration"),tur=o(" (Blenderbot model)"),aur=l(),YT=a("li"),YCe=a("strong"),nur=o("blenderbot-small"),sur=o(" \u2014 "),ZY=a("a"),lur=o("BlenderbotSmallForConditionalGeneration"),iur=o(" (BlenderbotSmall model)"),dur=l(),ZT=a("li"),ZCe=a("strong"),mur=o("encoder-decoder"),cur=o(" \u2014 "),KY=a("a"),fur=o("EncoderDecoderModel"),gur=o(" (Encoder decoder model)"),hur=l(),KT=a("li"),KCe=a("strong"),uur=o("fsmt"),pur=o(" \u2014 "),eZ=a("a"),_ur=o("FSMTForConditionalGeneration"),bur=o(" (FairSeq Machine-Translation model)"),vur=l(),eM=a("li"),e3e=a("strong"),Fur=o("led"),Tur=o(" \u2014 "),oZ=a("a"),Mur=o("LEDForConditionalGeneration"),Eur=o(" (LED model)"),Cur=l(),oM=a("li"),o3e=a("strong"),wur=o("longt5"),Aur=o(" \u2014 "),rZ=a("a"),Lur=o("LongT5ForConditionalGeneration"),yur=o(" (LongT5 model)"),xur=l(),rM=a("li"),r3e=a("strong"),$ur=o("m2m_100"),kur=o(" \u2014 "),tZ=a("a"),Sur=o("M2M100ForConditionalGeneration"),Rur=o(" (M2M100 model)"),Pur=l(),tM=a("li"),t3e=a("strong"),Bur=o("marian"),Iur=o(" \u2014 "),aZ=a("a"),Nur=o("MarianMTModel"),qur=o(" (Marian model)"),jur=l(),aM=a("li"),a3e=a("strong"),Dur=o("mbart"),Gur=o(" \u2014 "),nZ=a("a"),Our=o("MBartForConditionalGeneration"),Vur=o(" (mBART model)"),Xur=l(),nM=a("li"),n3e=a("strong"),zur=o("mt5"),Qur=o(" \u2014 "),sZ=a("a"),Wur=o("MT5ForConditionalGeneration"),Uur=o(" (MT5 model)"),Hur=l(),sM=a("li"),s3e=a("strong"),Jur=o("mvp"),Yur=o(" \u2014 "),lZ=a("a"),Zur=o("MvpForConditionalGeneration"),Kur=o(" (MVP model)"),epr=l(),lM=a("li"),l3e=a("strong"),opr=o("nllb"),rpr=o(" \u2014 "),iZ=a("a"),tpr=o("M2M100ForConditionalGeneration"),apr=o(" (NLLB model)"),npr=l(),iM=a("li"),i3e=a("strong"),spr=o("pegasus"),lpr=o(" \u2014 "),dZ=a("a"),ipr=o("PegasusForConditionalGeneration"),dpr=o(" (Pegasus model)"),mpr=l(),dM=a("li"),d3e=a("strong"),cpr=o("pegasus_x"),fpr=o(" \u2014 "),mZ=a("a"),gpr=o("PegasusXForConditionalGeneration"),hpr=o(" (PEGASUS-X model)"),upr=l(),mM=a("li"),m3e=a("strong"),ppr=o("plbart"),_pr=o(" \u2014 "),cZ=a("a"),bpr=o("PLBartForConditionalGeneration"),vpr=o(" (PLBart model)"),Fpr=l(),cM=a("li"),c3e=a("strong"),Tpr=o("prophetnet"),Mpr=o(" \u2014 "),fZ=a("a"),Epr=o("ProphetNetForConditionalGeneration"),Cpr=o(" (ProphetNet model)"),wpr=l(),fM=a("li"),f3e=a("strong"),Apr=o("t5"),Lpr=o(" \u2014 "),gZ=a("a"),ypr=o("T5ForConditionalGeneration"),xpr=o(" (T5 model)"),$pr=l(),gM=a("li"),g3e=a("strong"),kpr=o("xlm-prophetnet"),Spr=o(" \u2014 "),hZ=a("a"),Rpr=o("XLMProphetNetForConditionalGeneration"),Ppr=o(" (XLM-ProphetNet model)"),Bpr=l(),hM=a("p"),Ipr=o("The model is set in evaluation mode by default using "),h3e=a("code"),Npr=o("model.eval()"),qpr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u3e=a("code"),jpr=o("model.train()"),Dpr=l(),F(uM.$$.fragment),wio=l(),nm=a("h2"),pM=a("a"),p3e=a("span"),F($S.$$.fragment),Gpr=l(),_3e=a("span"),Opr=o("AutoModelForSequenceClassification"),Aio=l(),Qo=a("div"),F(kS.$$.fragment),Vpr=l(),sm=a("p"),Xpr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),uZ=a("a"),zpr=o("from_pretrained()"),Qpr=o(" class method or the "),pZ=a("a"),Wpr=o("from_config()"),Upr=o(` class
method.`),Hpr=l(),SS=a("p"),Jpr=o("This class cannot be instantiated directly using "),b3e=a("code"),Ypr=o("__init__()"),Zpr=o(" (throws an error)."),Kpr=l(),St=a("div"),F(RS.$$.fragment),e_r=l(),v3e=a("p"),o_r=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),r_r=l(),lm=a("p"),t_r=o(`Note:
Loading a model from its configuration file does `),F3e=a("strong"),a_r=o("not"),n_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_Z=a("a"),s_r=o("from_pretrained()"),l_r=o(" to load the model weights."),i_r=l(),F(_M.$$.fragment),d_r=l(),mo=a("div"),F(PS.$$.fragment),m_r=l(),T3e=a("p"),c_r=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),f_r=l(),vn=a("p"),g_r=o("The model class to instantiate is selected based on the "),M3e=a("code"),h_r=o("model_type"),u_r=o(` property of the config object (either
passed as an argument or loaded from `),E3e=a("code"),p_r=o("pretrained_model_name_or_path"),__r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C3e=a("code"),b_r=o("pretrained_model_name_or_path"),v_r=o(":"),F_r=l(),I=a("ul"),bM=a("li"),w3e=a("strong"),T_r=o("albert"),M_r=o(" \u2014 "),bZ=a("a"),E_r=o("AlbertForSequenceClassification"),C_r=o(" (ALBERT model)"),w_r=l(),vM=a("li"),A3e=a("strong"),A_r=o("bart"),L_r=o(" \u2014 "),vZ=a("a"),y_r=o("BartForSequenceClassification"),x_r=o(" (BART model)"),$_r=l(),FM=a("li"),L3e=a("strong"),k_r=o("bert"),S_r=o(" \u2014 "),FZ=a("a"),R_r=o("BertForSequenceClassification"),P_r=o(" (BERT model)"),B_r=l(),TM=a("li"),y3e=a("strong"),I_r=o("big_bird"),N_r=o(" \u2014 "),TZ=a("a"),q_r=o("BigBirdForSequenceClassification"),j_r=o(" (BigBird model)"),D_r=l(),MM=a("li"),x3e=a("strong"),G_r=o("bigbird_pegasus"),O_r=o(" \u2014 "),MZ=a("a"),V_r=o("BigBirdPegasusForSequenceClassification"),X_r=o(" (BigBird-Pegasus model)"),z_r=l(),EM=a("li"),$3e=a("strong"),Q_r=o("bloom"),W_r=o(" \u2014 "),EZ=a("a"),U_r=o("BloomForSequenceClassification"),H_r=o(" (BLOOM model)"),J_r=l(),CM=a("li"),k3e=a("strong"),Y_r=o("camembert"),Z_r=o(" \u2014 "),CZ=a("a"),K_r=o("CamembertForSequenceClassification"),e1r=o(" (CamemBERT model)"),o1r=l(),wM=a("li"),S3e=a("strong"),r1r=o("canine"),t1r=o(" \u2014 "),wZ=a("a"),a1r=o("CanineForSequenceClassification"),n1r=o(" (CANINE model)"),s1r=l(),AM=a("li"),R3e=a("strong"),l1r=o("convbert"),i1r=o(" \u2014 "),AZ=a("a"),d1r=o("ConvBertForSequenceClassification"),m1r=o(" (ConvBERT model)"),c1r=l(),LM=a("li"),P3e=a("strong"),f1r=o("ctrl"),g1r=o(" \u2014 "),LZ=a("a"),h1r=o("CTRLForSequenceClassification"),u1r=o(" (CTRL model)"),p1r=l(),yM=a("li"),B3e=a("strong"),_1r=o("data2vec-text"),b1r=o(" \u2014 "),yZ=a("a"),v1r=o("Data2VecTextForSequenceClassification"),F1r=o(" (Data2VecText model)"),T1r=l(),xM=a("li"),I3e=a("strong"),M1r=o("deberta"),E1r=o(" \u2014 "),xZ=a("a"),C1r=o("DebertaForSequenceClassification"),w1r=o(" (DeBERTa model)"),A1r=l(),$M=a("li"),N3e=a("strong"),L1r=o("deberta-v2"),y1r=o(" \u2014 "),$Z=a("a"),x1r=o("DebertaV2ForSequenceClassification"),$1r=o(" (DeBERTa-v2 model)"),k1r=l(),kM=a("li"),q3e=a("strong"),S1r=o("distilbert"),R1r=o(" \u2014 "),kZ=a("a"),P1r=o("DistilBertForSequenceClassification"),B1r=o(" (DistilBERT model)"),I1r=l(),SM=a("li"),j3e=a("strong"),N1r=o("electra"),q1r=o(" \u2014 "),SZ=a("a"),j1r=o("ElectraForSequenceClassification"),D1r=o(" (ELECTRA model)"),G1r=l(),RM=a("li"),D3e=a("strong"),O1r=o("ernie"),V1r=o(" \u2014 "),RZ=a("a"),X1r=o("ErnieForSequenceClassification"),z1r=o(" (ERNIE model)"),Q1r=l(),PM=a("li"),G3e=a("strong"),W1r=o("esm"),U1r=o(" \u2014 "),PZ=a("a"),H1r=o("EsmForSequenceClassification"),J1r=o(" (ESM model)"),Y1r=l(),BM=a("li"),O3e=a("strong"),Z1r=o("flaubert"),K1r=o(" \u2014 "),BZ=a("a"),e2r=o("FlaubertForSequenceClassification"),o2r=o(" (FlauBERT model)"),r2r=l(),IM=a("li"),V3e=a("strong"),t2r=o("fnet"),a2r=o(" \u2014 "),IZ=a("a"),n2r=o("FNetForSequenceClassification"),s2r=o(" (FNet model)"),l2r=l(),NM=a("li"),X3e=a("strong"),i2r=o("funnel"),d2r=o(" \u2014 "),NZ=a("a"),m2r=o("FunnelForSequenceClassification"),c2r=o(" (Funnel Transformer model)"),f2r=l(),qM=a("li"),z3e=a("strong"),g2r=o("gpt2"),h2r=o(" \u2014 "),qZ=a("a"),u2r=o("GPT2ForSequenceClassification"),p2r=o(" (OpenAI GPT-2 model)"),_2r=l(),jM=a("li"),Q3e=a("strong"),b2r=o("gpt_neo"),v2r=o(" \u2014 "),jZ=a("a"),F2r=o("GPTNeoForSequenceClassification"),T2r=o(" (GPT Neo model)"),M2r=l(),DM=a("li"),W3e=a("strong"),E2r=o("gptj"),C2r=o(" \u2014 "),DZ=a("a"),w2r=o("GPTJForSequenceClassification"),A2r=o(" (GPT-J model)"),L2r=l(),GM=a("li"),U3e=a("strong"),y2r=o("ibert"),x2r=o(" \u2014 "),GZ=a("a"),$2r=o("IBertForSequenceClassification"),k2r=o(" (I-BERT model)"),S2r=l(),OM=a("li"),H3e=a("strong"),R2r=o("layoutlm"),P2r=o(" \u2014 "),OZ=a("a"),B2r=o("LayoutLMForSequenceClassification"),I2r=o(" (LayoutLM model)"),N2r=l(),VM=a("li"),J3e=a("strong"),q2r=o("layoutlmv2"),j2r=o(" \u2014 "),VZ=a("a"),D2r=o("LayoutLMv2ForSequenceClassification"),G2r=o(" (LayoutLMv2 model)"),O2r=l(),XM=a("li"),Y3e=a("strong"),V2r=o("layoutlmv3"),X2r=o(" \u2014 "),XZ=a("a"),z2r=o("LayoutLMv3ForSequenceClassification"),Q2r=o(" (LayoutLMv3 model)"),W2r=l(),zM=a("li"),Z3e=a("strong"),U2r=o("led"),H2r=o(" \u2014 "),zZ=a("a"),J2r=o("LEDForSequenceClassification"),Y2r=o(" (LED model)"),Z2r=l(),QM=a("li"),K3e=a("strong"),K2r=o("lilt"),ebr=o(" \u2014 "),QZ=a("a"),obr=o("LiltForSequenceClassification"),rbr=o(" (LiLT model)"),tbr=l(),WM=a("li"),e5e=a("strong"),abr=o("longformer"),nbr=o(" \u2014 "),WZ=a("a"),sbr=o("LongformerForSequenceClassification"),lbr=o(" (Longformer model)"),ibr=l(),UM=a("li"),o5e=a("strong"),dbr=o("luke"),mbr=o(" \u2014 "),UZ=a("a"),cbr=o("LukeForSequenceClassification"),fbr=o(" (LUKE model)"),gbr=l(),HM=a("li"),r5e=a("strong"),hbr=o("markuplm"),ubr=o(" \u2014 "),HZ=a("a"),pbr=o("MarkupLMForSequenceClassification"),_br=o(" (MarkupLM model)"),bbr=l(),JM=a("li"),t5e=a("strong"),vbr=o("mbart"),Fbr=o(" \u2014 "),JZ=a("a"),Tbr=o("MBartForSequenceClassification"),Mbr=o(" (mBART model)"),Ebr=l(),YM=a("li"),a5e=a("strong"),Cbr=o("megatron-bert"),wbr=o(" \u2014 "),YZ=a("a"),Abr=o("MegatronBertForSequenceClassification"),Lbr=o(" (Megatron-BERT model)"),ybr=l(),ZM=a("li"),n5e=a("strong"),xbr=o("mobilebert"),$br=o(" \u2014 "),ZZ=a("a"),kbr=o("MobileBertForSequenceClassification"),Sbr=o(" (MobileBERT model)"),Rbr=l(),KM=a("li"),s5e=a("strong"),Pbr=o("mpnet"),Bbr=o(" \u2014 "),KZ=a("a"),Ibr=o("MPNetForSequenceClassification"),Nbr=o(" (MPNet model)"),qbr=l(),eE=a("li"),l5e=a("strong"),jbr=o("mvp"),Dbr=o(" \u2014 "),eK=a("a"),Gbr=o("MvpForSequenceClassification"),Obr=o(" (MVP model)"),Vbr=l(),oE=a("li"),i5e=a("strong"),Xbr=o("nezha"),zbr=o(" \u2014 "),oK=a("a"),Qbr=o("NezhaForSequenceClassification"),Wbr=o(" (Nezha model)"),Ubr=l(),rE=a("li"),d5e=a("strong"),Hbr=o("nystromformer"),Jbr=o(" \u2014 "),rK=a("a"),Ybr=o("NystromformerForSequenceClassification"),Zbr=o(" (Nystr\xF6mformer model)"),Kbr=l(),tE=a("li"),m5e=a("strong"),evr=o("openai-gpt"),ovr=o(" \u2014 "),tK=a("a"),rvr=o("OpenAIGPTForSequenceClassification"),tvr=o(" (OpenAI GPT model)"),avr=l(),aE=a("li"),c5e=a("strong"),nvr=o("opt"),svr=o(" \u2014 "),aK=a("a"),lvr=o("OPTForSequenceClassification"),ivr=o(" (OPT model)"),dvr=l(),nE=a("li"),f5e=a("strong"),mvr=o("perceiver"),cvr=o(" \u2014 "),nK=a("a"),fvr=o("PerceiverForSequenceClassification"),gvr=o(" (Perceiver model)"),hvr=l(),sE=a("li"),g5e=a("strong"),uvr=o("plbart"),pvr=o(" \u2014 "),sK=a("a"),_vr=o("PLBartForSequenceClassification"),bvr=o(" (PLBart model)"),vvr=l(),lE=a("li"),h5e=a("strong"),Fvr=o("qdqbert"),Tvr=o(" \u2014 "),lK=a("a"),Mvr=o("QDQBertForSequenceClassification"),Evr=o(" (QDQBert model)"),Cvr=l(),iE=a("li"),u5e=a("strong"),wvr=o("reformer"),Avr=o(" \u2014 "),iK=a("a"),Lvr=o("ReformerForSequenceClassification"),yvr=o(" (Reformer model)"),xvr=l(),dE=a("li"),p5e=a("strong"),$vr=o("rembert"),kvr=o(" \u2014 "),dK=a("a"),Svr=o("RemBertForSequenceClassification"),Rvr=o(" (RemBERT model)"),Pvr=l(),mE=a("li"),_5e=a("strong"),Bvr=o("roberta"),Ivr=o(" \u2014 "),mK=a("a"),Nvr=o("RobertaForSequenceClassification"),qvr=o(" (RoBERTa model)"),jvr=l(),cE=a("li"),b5e=a("strong"),Dvr=o("roc_bert"),Gvr=o(" \u2014 "),cK=a("a"),Ovr=o("RoCBertForSequenceClassification"),Vvr=o(" (RoCBert model)"),Xvr=l(),fE=a("li"),v5e=a("strong"),zvr=o("roformer"),Qvr=o(" \u2014 "),fK=a("a"),Wvr=o("RoFormerForSequenceClassification"),Uvr=o(" (RoFormer model)"),Hvr=l(),gE=a("li"),F5e=a("strong"),Jvr=o("squeezebert"),Yvr=o(" \u2014 "),gK=a("a"),Zvr=o("SqueezeBertForSequenceClassification"),Kvr=o(" (SqueezeBERT model)"),eFr=l(),hE=a("li"),T5e=a("strong"),oFr=o("tapas"),rFr=o(" \u2014 "),hK=a("a"),tFr=o("TapasForSequenceClassification"),aFr=o(" (TAPAS model)"),nFr=l(),uE=a("li"),M5e=a("strong"),sFr=o("transfo-xl"),lFr=o(" \u2014 "),uK=a("a"),iFr=o("TransfoXLForSequenceClassification"),dFr=o(" (Transformer-XL model)"),mFr=l(),pE=a("li"),E5e=a("strong"),cFr=o("xlm"),fFr=o(" \u2014 "),pK=a("a"),gFr=o("XLMForSequenceClassification"),hFr=o(" (XLM model)"),uFr=l(),_E=a("li"),C5e=a("strong"),pFr=o("xlm-roberta"),_Fr=o(" \u2014 "),_K=a("a"),bFr=o("XLMRobertaForSequenceClassification"),vFr=o(" (XLM-RoBERTa model)"),FFr=l(),bE=a("li"),w5e=a("strong"),TFr=o("xlm-roberta-xl"),MFr=o(" \u2014 "),bK=a("a"),EFr=o("XLMRobertaXLForSequenceClassification"),CFr=o(" (XLM-RoBERTa-XL model)"),wFr=l(),vE=a("li"),A5e=a("strong"),AFr=o("xlnet"),LFr=o(" \u2014 "),vK=a("a"),yFr=o("XLNetForSequenceClassification"),xFr=o(" (XLNet model)"),$Fr=l(),FE=a("li"),L5e=a("strong"),kFr=o("yoso"),SFr=o(" \u2014 "),FK=a("a"),RFr=o("YosoForSequenceClassification"),PFr=o(" (YOSO model)"),BFr=l(),TE=a("p"),IFr=o("The model is set in evaluation mode by default using "),y5e=a("code"),NFr=o("model.eval()"),qFr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),x5e=a("code"),jFr=o("model.train()"),DFr=l(),F(ME.$$.fragment),Lio=l(),im=a("h2"),EE=a("a"),$5e=a("span"),F(BS.$$.fragment),GFr=l(),k5e=a("span"),OFr=o("AutoModelForMultipleChoice"),yio=l(),Wo=a("div"),F(IS.$$.fragment),VFr=l(),dm=a("p"),XFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),TK=a("a"),zFr=o("from_pretrained()"),QFr=o(" class method or the "),MK=a("a"),WFr=o("from_config()"),UFr=o(` class
method.`),HFr=l(),NS=a("p"),JFr=o("This class cannot be instantiated directly using "),S5e=a("code"),YFr=o("__init__()"),ZFr=o(" (throws an error)."),KFr=l(),Rt=a("div"),F(qS.$$.fragment),eTr=l(),R5e=a("p"),oTr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),rTr=l(),mm=a("p"),tTr=o(`Note:
Loading a model from its configuration file does `),P5e=a("strong"),aTr=o("not"),nTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),EK=a("a"),sTr=o("from_pretrained()"),lTr=o(" to load the model weights."),iTr=l(),F(CE.$$.fragment),dTr=l(),co=a("div"),F(jS.$$.fragment),mTr=l(),B5e=a("p"),cTr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),fTr=l(),Fn=a("p"),gTr=o("The model class to instantiate is selected based on the "),I5e=a("code"),hTr=o("model_type"),uTr=o(` property of the config object (either
passed as an argument or loaded from `),N5e=a("code"),pTr=o("pretrained_model_name_or_path"),_Tr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q5e=a("code"),bTr=o("pretrained_model_name_or_path"),vTr=o(":"),FTr=l(),K=a("ul"),wE=a("li"),j5e=a("strong"),TTr=o("albert"),MTr=o(" \u2014 "),CK=a("a"),ETr=o("AlbertForMultipleChoice"),CTr=o(" (ALBERT model)"),wTr=l(),AE=a("li"),D5e=a("strong"),ATr=o("bert"),LTr=o(" \u2014 "),wK=a("a"),yTr=o("BertForMultipleChoice"),xTr=o(" (BERT model)"),$Tr=l(),LE=a("li"),G5e=a("strong"),kTr=o("big_bird"),STr=o(" \u2014 "),AK=a("a"),RTr=o("BigBirdForMultipleChoice"),PTr=o(" (BigBird model)"),BTr=l(),yE=a("li"),O5e=a("strong"),ITr=o("camembert"),NTr=o(" \u2014 "),LK=a("a"),qTr=o("CamembertForMultipleChoice"),jTr=o(" (CamemBERT model)"),DTr=l(),xE=a("li"),V5e=a("strong"),GTr=o("canine"),OTr=o(" \u2014 "),yK=a("a"),VTr=o("CanineForMultipleChoice"),XTr=o(" (CANINE model)"),zTr=l(),$E=a("li"),X5e=a("strong"),QTr=o("convbert"),WTr=o(" \u2014 "),xK=a("a"),UTr=o("ConvBertForMultipleChoice"),HTr=o(" (ConvBERT model)"),JTr=l(),kE=a("li"),z5e=a("strong"),YTr=o("data2vec-text"),ZTr=o(" \u2014 "),$K=a("a"),KTr=o("Data2VecTextForMultipleChoice"),eMr=o(" (Data2VecText model)"),oMr=l(),SE=a("li"),Q5e=a("strong"),rMr=o("deberta-v2"),tMr=o(" \u2014 "),kK=a("a"),aMr=o("DebertaV2ForMultipleChoice"),nMr=o(" (DeBERTa-v2 model)"),sMr=l(),RE=a("li"),W5e=a("strong"),lMr=o("distilbert"),iMr=o(" \u2014 "),SK=a("a"),dMr=o("DistilBertForMultipleChoice"),mMr=o(" (DistilBERT model)"),cMr=l(),PE=a("li"),U5e=a("strong"),fMr=o("electra"),gMr=o(" \u2014 "),RK=a("a"),hMr=o("ElectraForMultipleChoice"),uMr=o(" (ELECTRA model)"),pMr=l(),BE=a("li"),H5e=a("strong"),_Mr=o("ernie"),bMr=o(" \u2014 "),PK=a("a"),vMr=o("ErnieForMultipleChoice"),FMr=o(" (ERNIE model)"),TMr=l(),IE=a("li"),J5e=a("strong"),MMr=o("flaubert"),EMr=o(" \u2014 "),BK=a("a"),CMr=o("FlaubertForMultipleChoice"),wMr=o(" (FlauBERT model)"),AMr=l(),NE=a("li"),Y5e=a("strong"),LMr=o("fnet"),yMr=o(" \u2014 "),IK=a("a"),xMr=o("FNetForMultipleChoice"),$Mr=o(" (FNet model)"),kMr=l(),qE=a("li"),Z5e=a("strong"),SMr=o("funnel"),RMr=o(" \u2014 "),NK=a("a"),PMr=o("FunnelForMultipleChoice"),BMr=o(" (Funnel Transformer model)"),IMr=l(),jE=a("li"),K5e=a("strong"),NMr=o("ibert"),qMr=o(" \u2014 "),qK=a("a"),jMr=o("IBertForMultipleChoice"),DMr=o(" (I-BERT model)"),GMr=l(),DE=a("li"),e0e=a("strong"),OMr=o("longformer"),VMr=o(" \u2014 "),jK=a("a"),XMr=o("LongformerForMultipleChoice"),zMr=o(" (Longformer model)"),QMr=l(),GE=a("li"),o0e=a("strong"),WMr=o("luke"),UMr=o(" \u2014 "),DK=a("a"),HMr=o("LukeForMultipleChoice"),JMr=o(" (LUKE model)"),YMr=l(),OE=a("li"),r0e=a("strong"),ZMr=o("megatron-bert"),KMr=o(" \u2014 "),GK=a("a"),eEr=o("MegatronBertForMultipleChoice"),oEr=o(" (Megatron-BERT model)"),rEr=l(),VE=a("li"),t0e=a("strong"),tEr=o("mobilebert"),aEr=o(" \u2014 "),OK=a("a"),nEr=o("MobileBertForMultipleChoice"),sEr=o(" (MobileBERT model)"),lEr=l(),XE=a("li"),a0e=a("strong"),iEr=o("mpnet"),dEr=o(" \u2014 "),VK=a("a"),mEr=o("MPNetForMultipleChoice"),cEr=o(" (MPNet model)"),fEr=l(),zE=a("li"),n0e=a("strong"),gEr=o("nezha"),hEr=o(" \u2014 "),XK=a("a"),uEr=o("NezhaForMultipleChoice"),pEr=o(" (Nezha model)"),_Er=l(),QE=a("li"),s0e=a("strong"),bEr=o("nystromformer"),vEr=o(" \u2014 "),zK=a("a"),FEr=o("NystromformerForMultipleChoice"),TEr=o(" (Nystr\xF6mformer model)"),MEr=l(),WE=a("li"),l0e=a("strong"),EEr=o("qdqbert"),CEr=o(" \u2014 "),QK=a("a"),wEr=o("QDQBertForMultipleChoice"),AEr=o(" (QDQBert model)"),LEr=l(),UE=a("li"),i0e=a("strong"),yEr=o("rembert"),xEr=o(" \u2014 "),WK=a("a"),$Er=o("RemBertForMultipleChoice"),kEr=o(" (RemBERT model)"),SEr=l(),HE=a("li"),d0e=a("strong"),REr=o("roberta"),PEr=o(" \u2014 "),UK=a("a"),BEr=o("RobertaForMultipleChoice"),IEr=o(" (RoBERTa model)"),NEr=l(),JE=a("li"),m0e=a("strong"),qEr=o("roc_bert"),jEr=o(" \u2014 "),HK=a("a"),DEr=o("RoCBertForMultipleChoice"),GEr=o(" (RoCBert model)"),OEr=l(),YE=a("li"),c0e=a("strong"),VEr=o("roformer"),XEr=o(" \u2014 "),JK=a("a"),zEr=o("RoFormerForMultipleChoice"),QEr=o(" (RoFormer model)"),WEr=l(),ZE=a("li"),f0e=a("strong"),UEr=o("squeezebert"),HEr=o(" \u2014 "),YK=a("a"),JEr=o("SqueezeBertForMultipleChoice"),YEr=o(" (SqueezeBERT model)"),ZEr=l(),KE=a("li"),g0e=a("strong"),KEr=o("xlm"),e4r=o(" \u2014 "),ZK=a("a"),o4r=o("XLMForMultipleChoice"),r4r=o(" (XLM model)"),t4r=l(),e4=a("li"),h0e=a("strong"),a4r=o("xlm-roberta"),n4r=o(" \u2014 "),KK=a("a"),s4r=o("XLMRobertaForMultipleChoice"),l4r=o(" (XLM-RoBERTa model)"),i4r=l(),o4=a("li"),u0e=a("strong"),d4r=o("xlm-roberta-xl"),m4r=o(" \u2014 "),eee=a("a"),c4r=o("XLMRobertaXLForMultipleChoice"),f4r=o(" (XLM-RoBERTa-XL model)"),g4r=l(),r4=a("li"),p0e=a("strong"),h4r=o("xlnet"),u4r=o(" \u2014 "),oee=a("a"),p4r=o("XLNetForMultipleChoice"),_4r=o(" (XLNet model)"),b4r=l(),t4=a("li"),_0e=a("strong"),v4r=o("yoso"),F4r=o(" \u2014 "),ree=a("a"),T4r=o("YosoForMultipleChoice"),M4r=o(" (YOSO model)"),E4r=l(),a4=a("p"),C4r=o("The model is set in evaluation mode by default using "),b0e=a("code"),w4r=o("model.eval()"),A4r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v0e=a("code"),L4r=o("model.train()"),y4r=l(),F(n4.$$.fragment),xio=l(),cm=a("h2"),s4=a("a"),F0e=a("span"),F(DS.$$.fragment),x4r=l(),T0e=a("span"),$4r=o("AutoModelForNextSentencePrediction"),$io=l(),Uo=a("div"),F(GS.$$.fragment),k4r=l(),fm=a("p"),S4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),tee=a("a"),R4r=o("from_pretrained()"),P4r=o(" class method or the "),aee=a("a"),B4r=o("from_config()"),I4r=o(` class
method.`),N4r=l(),OS=a("p"),q4r=o("This class cannot be instantiated directly using "),M0e=a("code"),j4r=o("__init__()"),D4r=o(" (throws an error)."),G4r=l(),Pt=a("div"),F(VS.$$.fragment),O4r=l(),E0e=a("p"),V4r=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),X4r=l(),gm=a("p"),z4r=o(`Note:
Loading a model from its configuration file does `),C0e=a("strong"),Q4r=o("not"),W4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nee=a("a"),U4r=o("from_pretrained()"),H4r=o(" to load the model weights."),J4r=l(),F(l4.$$.fragment),Y4r=l(),fo=a("div"),F(XS.$$.fragment),Z4r=l(),w0e=a("p"),K4r=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),eCr=l(),Tn=a("p"),oCr=o("The model class to instantiate is selected based on the "),A0e=a("code"),rCr=o("model_type"),tCr=o(` property of the config object (either
passed as an argument or loaded from `),L0e=a("code"),aCr=o("pretrained_model_name_or_path"),nCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y0e=a("code"),sCr=o("pretrained_model_name_or_path"),lCr=o(":"),iCr=l(),Ye=a("ul"),i4=a("li"),x0e=a("strong"),dCr=o("bert"),mCr=o(" \u2014 "),see=a("a"),cCr=o("BertForNextSentencePrediction"),fCr=o(" (BERT model)"),gCr=l(),d4=a("li"),$0e=a("strong"),hCr=o("ernie"),uCr=o(" \u2014 "),lee=a("a"),pCr=o("ErnieForNextSentencePrediction"),_Cr=o(" (ERNIE model)"),bCr=l(),m4=a("li"),k0e=a("strong"),vCr=o("fnet"),FCr=o(" \u2014 "),iee=a("a"),TCr=o("FNetForNextSentencePrediction"),MCr=o(" (FNet model)"),ECr=l(),c4=a("li"),S0e=a("strong"),CCr=o("megatron-bert"),wCr=o(" \u2014 "),dee=a("a"),ACr=o("MegatronBertForNextSentencePrediction"),LCr=o(" (Megatron-BERT model)"),yCr=l(),f4=a("li"),R0e=a("strong"),xCr=o("mobilebert"),$Cr=o(" \u2014 "),mee=a("a"),kCr=o("MobileBertForNextSentencePrediction"),SCr=o(" (MobileBERT model)"),RCr=l(),g4=a("li"),P0e=a("strong"),PCr=o("nezha"),BCr=o(" \u2014 "),cee=a("a"),ICr=o("NezhaForNextSentencePrediction"),NCr=o(" (Nezha model)"),qCr=l(),h4=a("li"),B0e=a("strong"),jCr=o("qdqbert"),DCr=o(" \u2014 "),fee=a("a"),GCr=o("QDQBertForNextSentencePrediction"),OCr=o(" (QDQBert model)"),VCr=l(),u4=a("p"),XCr=o("The model is set in evaluation mode by default using "),I0e=a("code"),zCr=o("model.eval()"),QCr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),N0e=a("code"),WCr=o("model.train()"),UCr=l(),F(p4.$$.fragment),kio=l(),hm=a("h2"),_4=a("a"),q0e=a("span"),F(zS.$$.fragment),HCr=l(),j0e=a("span"),JCr=o("AutoModelForTokenClassification"),Sio=l(),Ho=a("div"),F(QS.$$.fragment),YCr=l(),um=a("p"),ZCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),gee=a("a"),KCr=o("from_pretrained()"),e3r=o(" class method or the "),hee=a("a"),o3r=o("from_config()"),r3r=o(` class
method.`),t3r=l(),WS=a("p"),a3r=o("This class cannot be instantiated directly using "),D0e=a("code"),n3r=o("__init__()"),s3r=o(" (throws an error)."),l3r=l(),Bt=a("div"),F(US.$$.fragment),i3r=l(),G0e=a("p"),d3r=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),m3r=l(),pm=a("p"),c3r=o(`Note:
Loading a model from its configuration file does `),O0e=a("strong"),f3r=o("not"),g3r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),uee=a("a"),h3r=o("from_pretrained()"),u3r=o(" to load the model weights."),p3r=l(),F(b4.$$.fragment),_3r=l(),go=a("div"),F(HS.$$.fragment),b3r=l(),V0e=a("p"),v3r=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),F3r=l(),Mn=a("p"),T3r=o("The model class to instantiate is selected based on the "),X0e=a("code"),M3r=o("model_type"),E3r=o(` property of the config object (either
passed as an argument or loaded from `),z0e=a("code"),C3r=o("pretrained_model_name_or_path"),w3r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q0e=a("code"),A3r=o("pretrained_model_name_or_path"),L3r=o(":"),y3r=l(),U=a("ul"),v4=a("li"),W0e=a("strong"),x3r=o("albert"),$3r=o(" \u2014 "),pee=a("a"),k3r=o("AlbertForTokenClassification"),S3r=o(" (ALBERT model)"),R3r=l(),F4=a("li"),U0e=a("strong"),P3r=o("bert"),B3r=o(" \u2014 "),_ee=a("a"),I3r=o("BertForTokenClassification"),N3r=o(" (BERT model)"),q3r=l(),T4=a("li"),H0e=a("strong"),j3r=o("big_bird"),D3r=o(" \u2014 "),bee=a("a"),G3r=o("BigBirdForTokenClassification"),O3r=o(" (BigBird model)"),V3r=l(),M4=a("li"),J0e=a("strong"),X3r=o("bloom"),z3r=o(" \u2014 "),vee=a("a"),Q3r=o("BloomForTokenClassification"),W3r=o(" (BLOOM model)"),U3r=l(),E4=a("li"),Y0e=a("strong"),H3r=o("camembert"),J3r=o(" \u2014 "),Fee=a("a"),Y3r=o("CamembertForTokenClassification"),Z3r=o(" (CamemBERT model)"),K3r=l(),C4=a("li"),Z0e=a("strong"),e5r=o("canine"),o5r=o(" \u2014 "),Tee=a("a"),r5r=o("CanineForTokenClassification"),t5r=o(" (CANINE model)"),a5r=l(),w4=a("li"),K0e=a("strong"),n5r=o("convbert"),s5r=o(" \u2014 "),Mee=a("a"),l5r=o("ConvBertForTokenClassification"),i5r=o(" (ConvBERT model)"),d5r=l(),A4=a("li"),ewe=a("strong"),m5r=o("data2vec-text"),c5r=o(" \u2014 "),Eee=a("a"),f5r=o("Data2VecTextForTokenClassification"),g5r=o(" (Data2VecText model)"),h5r=l(),L4=a("li"),owe=a("strong"),u5r=o("deberta"),p5r=o(" \u2014 "),Cee=a("a"),_5r=o("DebertaForTokenClassification"),b5r=o(" (DeBERTa model)"),v5r=l(),y4=a("li"),rwe=a("strong"),F5r=o("deberta-v2"),T5r=o(" \u2014 "),wee=a("a"),M5r=o("DebertaV2ForTokenClassification"),E5r=o(" (DeBERTa-v2 model)"),C5r=l(),x4=a("li"),twe=a("strong"),w5r=o("distilbert"),A5r=o(" \u2014 "),Aee=a("a"),L5r=o("DistilBertForTokenClassification"),y5r=o(" (DistilBERT model)"),x5r=l(),$4=a("li"),awe=a("strong"),$5r=o("electra"),k5r=o(" \u2014 "),Lee=a("a"),S5r=o("ElectraForTokenClassification"),R5r=o(" (ELECTRA model)"),P5r=l(),k4=a("li"),nwe=a("strong"),B5r=o("ernie"),I5r=o(" \u2014 "),yee=a("a"),N5r=o("ErnieForTokenClassification"),q5r=o(" (ERNIE model)"),j5r=l(),S4=a("li"),swe=a("strong"),D5r=o("esm"),G5r=o(" \u2014 "),xee=a("a"),O5r=o("EsmForTokenClassification"),V5r=o(" (ESM model)"),X5r=l(),R4=a("li"),lwe=a("strong"),z5r=o("flaubert"),Q5r=o(" \u2014 "),$ee=a("a"),W5r=o("FlaubertForTokenClassification"),U5r=o(" (FlauBERT model)"),H5r=l(),P4=a("li"),iwe=a("strong"),J5r=o("fnet"),Y5r=o(" \u2014 "),kee=a("a"),Z5r=o("FNetForTokenClassification"),K5r=o(" (FNet model)"),e0r=l(),B4=a("li"),dwe=a("strong"),o0r=o("funnel"),r0r=o(" \u2014 "),See=a("a"),t0r=o("FunnelForTokenClassification"),a0r=o(" (Funnel Transformer model)"),n0r=l(),I4=a("li"),mwe=a("strong"),s0r=o("gpt2"),l0r=o(" \u2014 "),Ree=a("a"),i0r=o("GPT2ForTokenClassification"),d0r=o(" (OpenAI GPT-2 model)"),m0r=l(),N4=a("li"),cwe=a("strong"),c0r=o("ibert"),f0r=o(" \u2014 "),Pee=a("a"),g0r=o("IBertForTokenClassification"),h0r=o(" (I-BERT model)"),u0r=l(),q4=a("li"),fwe=a("strong"),p0r=o("layoutlm"),_0r=o(" \u2014 "),Bee=a("a"),b0r=o("LayoutLMForTokenClassification"),v0r=o(" (LayoutLM model)"),F0r=l(),j4=a("li"),gwe=a("strong"),T0r=o("layoutlmv2"),M0r=o(" \u2014 "),Iee=a("a"),E0r=o("LayoutLMv2ForTokenClassification"),C0r=o(" (LayoutLMv2 model)"),w0r=l(),D4=a("li"),hwe=a("strong"),A0r=o("layoutlmv3"),L0r=o(" \u2014 "),Nee=a("a"),y0r=o("LayoutLMv3ForTokenClassification"),x0r=o(" (LayoutLMv3 model)"),$0r=l(),G4=a("li"),uwe=a("strong"),k0r=o("lilt"),S0r=o(" \u2014 "),qee=a("a"),R0r=o("LiltForTokenClassification"),P0r=o(" (LiLT model)"),B0r=l(),O4=a("li"),pwe=a("strong"),I0r=o("longformer"),N0r=o(" \u2014 "),jee=a("a"),q0r=o("LongformerForTokenClassification"),j0r=o(" (Longformer model)"),D0r=l(),V4=a("li"),_we=a("strong"),G0r=o("luke"),O0r=o(" \u2014 "),Dee=a("a"),V0r=o("LukeForTokenClassification"),X0r=o(" (LUKE model)"),z0r=l(),X4=a("li"),bwe=a("strong"),Q0r=o("markuplm"),W0r=o(" \u2014 "),Gee=a("a"),U0r=o("MarkupLMForTokenClassification"),H0r=o(" (MarkupLM model)"),J0r=l(),z4=a("li"),vwe=a("strong"),Y0r=o("megatron-bert"),Z0r=o(" \u2014 "),Oee=a("a"),K0r=o("MegatronBertForTokenClassification"),ewr=o(" (Megatron-BERT model)"),owr=l(),Q4=a("li"),Fwe=a("strong"),rwr=o("mobilebert"),twr=o(" \u2014 "),Vee=a("a"),awr=o("MobileBertForTokenClassification"),nwr=o(" (MobileBERT model)"),swr=l(),W4=a("li"),Twe=a("strong"),lwr=o("mpnet"),iwr=o(" \u2014 "),Xee=a("a"),dwr=o("MPNetForTokenClassification"),mwr=o(" (MPNet model)"),cwr=l(),U4=a("li"),Mwe=a("strong"),fwr=o("nezha"),gwr=o(" \u2014 "),zee=a("a"),hwr=o("NezhaForTokenClassification"),uwr=o(" (Nezha model)"),pwr=l(),H4=a("li"),Ewe=a("strong"),_wr=o("nystromformer"),bwr=o(" \u2014 "),Qee=a("a"),vwr=o("NystromformerForTokenClassification"),Fwr=o(" (Nystr\xF6mformer model)"),Twr=l(),J4=a("li"),Cwe=a("strong"),Mwr=o("qdqbert"),Ewr=o(" \u2014 "),Wee=a("a"),Cwr=o("QDQBertForTokenClassification"),wwr=o(" (QDQBert model)"),Awr=l(),Y4=a("li"),wwe=a("strong"),Lwr=o("rembert"),ywr=o(" \u2014 "),Uee=a("a"),xwr=o("RemBertForTokenClassification"),$wr=o(" (RemBERT model)"),kwr=l(),Z4=a("li"),Awe=a("strong"),Swr=o("roberta"),Rwr=o(" \u2014 "),Hee=a("a"),Pwr=o("RobertaForTokenClassification"),Bwr=o(" (RoBERTa model)"),Iwr=l(),K4=a("li"),Lwe=a("strong"),Nwr=o("roc_bert"),qwr=o(" \u2014 "),Jee=a("a"),jwr=o("RoCBertForTokenClassification"),Dwr=o(" (RoCBert model)"),Gwr=l(),eC=a("li"),ywe=a("strong"),Owr=o("roformer"),Vwr=o(" \u2014 "),Yee=a("a"),Xwr=o("RoFormerForTokenClassification"),zwr=o(" (RoFormer model)"),Qwr=l(),oC=a("li"),xwe=a("strong"),Wwr=o("squeezebert"),Uwr=o(" \u2014 "),Zee=a("a"),Hwr=o("SqueezeBertForTokenClassification"),Jwr=o(" (SqueezeBERT model)"),Ywr=l(),rC=a("li"),$we=a("strong"),Zwr=o("xlm"),Kwr=o(" \u2014 "),Kee=a("a"),eAr=o("XLMForTokenClassification"),oAr=o(" (XLM model)"),rAr=l(),tC=a("li"),kwe=a("strong"),tAr=o("xlm-roberta"),aAr=o(" \u2014 "),eoe=a("a"),nAr=o("XLMRobertaForTokenClassification"),sAr=o(" (XLM-RoBERTa model)"),lAr=l(),aC=a("li"),Swe=a("strong"),iAr=o("xlm-roberta-xl"),dAr=o(" \u2014 "),ooe=a("a"),mAr=o("XLMRobertaXLForTokenClassification"),cAr=o(" (XLM-RoBERTa-XL model)"),fAr=l(),nC=a("li"),Rwe=a("strong"),gAr=o("xlnet"),hAr=o(" \u2014 "),roe=a("a"),uAr=o("XLNetForTokenClassification"),pAr=o(" (XLNet model)"),_Ar=l(),sC=a("li"),Pwe=a("strong"),bAr=o("yoso"),vAr=o(" \u2014 "),toe=a("a"),FAr=o("YosoForTokenClassification"),TAr=o(" (YOSO model)"),MAr=l(),lC=a("p"),EAr=o("The model is set in evaluation mode by default using "),Bwe=a("code"),CAr=o("model.eval()"),wAr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Iwe=a("code"),AAr=o("model.train()"),LAr=l(),F(iC.$$.fragment),Rio=l(),_m=a("h2"),dC=a("a"),Nwe=a("span"),F(JS.$$.fragment),yAr=l(),qwe=a("span"),xAr=o("AutoModelForQuestionAnswering"),Pio=l(),Jo=a("div"),F(YS.$$.fragment),$Ar=l(),bm=a("p"),kAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),aoe=a("a"),SAr=o("from_pretrained()"),RAr=o(" class method or the "),noe=a("a"),PAr=o("from_config()"),BAr=o(` class
method.`),IAr=l(),ZS=a("p"),NAr=o("This class cannot be instantiated directly using "),jwe=a("code"),qAr=o("__init__()"),jAr=o(" (throws an error)."),DAr=l(),It=a("div"),F(KS.$$.fragment),GAr=l(),Dwe=a("p"),OAr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),VAr=l(),vm=a("p"),XAr=o(`Note:
Loading a model from its configuration file does `),Gwe=a("strong"),zAr=o("not"),QAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),soe=a("a"),WAr=o("from_pretrained()"),UAr=o(" to load the model weights."),HAr=l(),F(mC.$$.fragment),JAr=l(),ho=a("div"),F(eR.$$.fragment),YAr=l(),Owe=a("p"),ZAr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),KAr=l(),En=a("p"),e6r=o("The model class to instantiate is selected based on the "),Vwe=a("code"),o6r=o("model_type"),r6r=o(` property of the config object (either
passed as an argument or loaded from `),Xwe=a("code"),t6r=o("pretrained_model_name_or_path"),a6r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zwe=a("code"),n6r=o("pretrained_model_name_or_path"),s6r=o(":"),l6r=l(),O=a("ul"),cC=a("li"),Qwe=a("strong"),i6r=o("albert"),d6r=o(" \u2014 "),loe=a("a"),m6r=o("AlbertForQuestionAnswering"),c6r=o(" (ALBERT model)"),f6r=l(),fC=a("li"),Wwe=a("strong"),g6r=o("bart"),h6r=o(" \u2014 "),ioe=a("a"),u6r=o("BartForQuestionAnswering"),p6r=o(" (BART model)"),_6r=l(),gC=a("li"),Uwe=a("strong"),b6r=o("bert"),v6r=o(" \u2014 "),doe=a("a"),F6r=o("BertForQuestionAnswering"),T6r=o(" (BERT model)"),M6r=l(),hC=a("li"),Hwe=a("strong"),E6r=o("big_bird"),C6r=o(" \u2014 "),moe=a("a"),w6r=o("BigBirdForQuestionAnswering"),A6r=o(" (BigBird model)"),L6r=l(),uC=a("li"),Jwe=a("strong"),y6r=o("bigbird_pegasus"),x6r=o(" \u2014 "),coe=a("a"),$6r=o("BigBirdPegasusForQuestionAnswering"),k6r=o(" (BigBird-Pegasus model)"),S6r=l(),pC=a("li"),Ywe=a("strong"),R6r=o("bloom"),P6r=o(" \u2014 "),foe=a("a"),B6r=o("BloomForQuestionAnswering"),I6r=o(" (BLOOM model)"),N6r=l(),_C=a("li"),Zwe=a("strong"),q6r=o("camembert"),j6r=o(" \u2014 "),goe=a("a"),D6r=o("CamembertForQuestionAnswering"),G6r=o(" (CamemBERT model)"),O6r=l(),bC=a("li"),Kwe=a("strong"),V6r=o("canine"),X6r=o(" \u2014 "),hoe=a("a"),z6r=o("CanineForQuestionAnswering"),Q6r=o(" (CANINE model)"),W6r=l(),vC=a("li"),eAe=a("strong"),U6r=o("convbert"),H6r=o(" \u2014 "),uoe=a("a"),J6r=o("ConvBertForQuestionAnswering"),Y6r=o(" (ConvBERT model)"),Z6r=l(),FC=a("li"),oAe=a("strong"),K6r=o("data2vec-text"),e7r=o(" \u2014 "),poe=a("a"),o7r=o("Data2VecTextForQuestionAnswering"),r7r=o(" (Data2VecText model)"),t7r=l(),TC=a("li"),rAe=a("strong"),a7r=o("deberta"),n7r=o(" \u2014 "),_oe=a("a"),s7r=o("DebertaForQuestionAnswering"),l7r=o(" (DeBERTa model)"),i7r=l(),MC=a("li"),tAe=a("strong"),d7r=o("deberta-v2"),m7r=o(" \u2014 "),boe=a("a"),c7r=o("DebertaV2ForQuestionAnswering"),f7r=o(" (DeBERTa-v2 model)"),g7r=l(),EC=a("li"),aAe=a("strong"),h7r=o("distilbert"),u7r=o(" \u2014 "),voe=a("a"),p7r=o("DistilBertForQuestionAnswering"),_7r=o(" (DistilBERT model)"),b7r=l(),CC=a("li"),nAe=a("strong"),v7r=o("electra"),F7r=o(" \u2014 "),Foe=a("a"),T7r=o("ElectraForQuestionAnswering"),M7r=o(" (ELECTRA model)"),E7r=l(),wC=a("li"),sAe=a("strong"),C7r=o("ernie"),w7r=o(" \u2014 "),Toe=a("a"),A7r=o("ErnieForQuestionAnswering"),L7r=o(" (ERNIE model)"),y7r=l(),AC=a("li"),lAe=a("strong"),x7r=o("flaubert"),$7r=o(" \u2014 "),Moe=a("a"),k7r=o("FlaubertForQuestionAnsweringSimple"),S7r=o(" (FlauBERT model)"),R7r=l(),LC=a("li"),iAe=a("strong"),P7r=o("fnet"),B7r=o(" \u2014 "),Eoe=a("a"),I7r=o("FNetForQuestionAnswering"),N7r=o(" (FNet model)"),q7r=l(),yC=a("li"),dAe=a("strong"),j7r=o("funnel"),D7r=o(" \u2014 "),Coe=a("a"),G7r=o("FunnelForQuestionAnswering"),O7r=o(" (Funnel Transformer model)"),V7r=l(),xC=a("li"),mAe=a("strong"),X7r=o("gptj"),z7r=o(" \u2014 "),woe=a("a"),Q7r=o("GPTJForQuestionAnswering"),W7r=o(" (GPT-J model)"),U7r=l(),$C=a("li"),cAe=a("strong"),H7r=o("ibert"),J7r=o(" \u2014 "),Aoe=a("a"),Y7r=o("IBertForQuestionAnswering"),Z7r=o(" (I-BERT model)"),K7r=l(),kC=a("li"),fAe=a("strong"),e8r=o("layoutlmv2"),o8r=o(" \u2014 "),Loe=a("a"),r8r=o("LayoutLMv2ForQuestionAnswering"),t8r=o(" (LayoutLMv2 model)"),a8r=l(),SC=a("li"),gAe=a("strong"),n8r=o("layoutlmv3"),s8r=o(" \u2014 "),yoe=a("a"),l8r=o("LayoutLMv3ForQuestionAnswering"),i8r=o(" (LayoutLMv3 model)"),d8r=l(),RC=a("li"),hAe=a("strong"),m8r=o("led"),c8r=o(" \u2014 "),xoe=a("a"),f8r=o("LEDForQuestionAnswering"),g8r=o(" (LED model)"),h8r=l(),PC=a("li"),uAe=a("strong"),u8r=o("lilt"),p8r=o(" \u2014 "),$oe=a("a"),_8r=o("LiltForQuestionAnswering"),b8r=o(" (LiLT model)"),v8r=l(),BC=a("li"),pAe=a("strong"),F8r=o("longformer"),T8r=o(" \u2014 "),koe=a("a"),M8r=o("LongformerForQuestionAnswering"),E8r=o(" (Longformer model)"),C8r=l(),IC=a("li"),_Ae=a("strong"),w8r=o("luke"),A8r=o(" \u2014 "),Soe=a("a"),L8r=o("LukeForQuestionAnswering"),y8r=o(" (LUKE model)"),x8r=l(),NC=a("li"),bAe=a("strong"),$8r=o("lxmert"),k8r=o(" \u2014 "),Roe=a("a"),S8r=o("LxmertForQuestionAnswering"),R8r=o(" (LXMERT model)"),P8r=l(),qC=a("li"),vAe=a("strong"),B8r=o("markuplm"),I8r=o(" \u2014 "),Poe=a("a"),N8r=o("MarkupLMForQuestionAnswering"),q8r=o(" (MarkupLM model)"),j8r=l(),jC=a("li"),FAe=a("strong"),D8r=o("mbart"),G8r=o(" \u2014 "),Boe=a("a"),O8r=o("MBartForQuestionAnswering"),V8r=o(" (mBART model)"),X8r=l(),DC=a("li"),TAe=a("strong"),z8r=o("megatron-bert"),Q8r=o(" \u2014 "),Ioe=a("a"),W8r=o("MegatronBertForQuestionAnswering"),U8r=o(" (Megatron-BERT model)"),H8r=l(),GC=a("li"),MAe=a("strong"),J8r=o("mobilebert"),Y8r=o(" \u2014 "),Noe=a("a"),Z8r=o("MobileBertForQuestionAnswering"),K8r=o(" (MobileBERT model)"),eLr=l(),OC=a("li"),EAe=a("strong"),oLr=o("mpnet"),rLr=o(" \u2014 "),qoe=a("a"),tLr=o("MPNetForQuestionAnswering"),aLr=o(" (MPNet model)"),nLr=l(),VC=a("li"),CAe=a("strong"),sLr=o("mvp"),lLr=o(" \u2014 "),joe=a("a"),iLr=o("MvpForQuestionAnswering"),dLr=o(" (MVP model)"),mLr=l(),XC=a("li"),wAe=a("strong"),cLr=o("nezha"),fLr=o(" \u2014 "),Doe=a("a"),gLr=o("NezhaForQuestionAnswering"),hLr=o(" (Nezha model)"),uLr=l(),zC=a("li"),AAe=a("strong"),pLr=o("nystromformer"),_Lr=o(" \u2014 "),Goe=a("a"),bLr=o("NystromformerForQuestionAnswering"),vLr=o(" (Nystr\xF6mformer model)"),FLr=l(),QC=a("li"),LAe=a("strong"),TLr=o("opt"),MLr=o(" \u2014 "),Ooe=a("a"),ELr=o("OPTForQuestionAnswering"),CLr=o(" (OPT model)"),wLr=l(),WC=a("li"),yAe=a("strong"),ALr=o("qdqbert"),LLr=o(" \u2014 "),Voe=a("a"),yLr=o("QDQBertForQuestionAnswering"),xLr=o(" (QDQBert model)"),$Lr=l(),UC=a("li"),xAe=a("strong"),kLr=o("reformer"),SLr=o(" \u2014 "),Xoe=a("a"),RLr=o("ReformerForQuestionAnswering"),PLr=o(" (Reformer model)"),BLr=l(),HC=a("li"),$Ae=a("strong"),ILr=o("rembert"),NLr=o(" \u2014 "),zoe=a("a"),qLr=o("RemBertForQuestionAnswering"),jLr=o(" (RemBERT model)"),DLr=l(),JC=a("li"),kAe=a("strong"),GLr=o("roberta"),OLr=o(" \u2014 "),Qoe=a("a"),VLr=o("RobertaForQuestionAnswering"),XLr=o(" (RoBERTa model)"),zLr=l(),YC=a("li"),SAe=a("strong"),QLr=o("roc_bert"),WLr=o(" \u2014 "),Woe=a("a"),ULr=o("RoCBertForQuestionAnswering"),HLr=o(" (RoCBert model)"),JLr=l(),ZC=a("li"),RAe=a("strong"),YLr=o("roformer"),ZLr=o(" \u2014 "),Uoe=a("a"),KLr=o("RoFormerForQuestionAnswering"),eyr=o(" (RoFormer model)"),oyr=l(),KC=a("li"),PAe=a("strong"),ryr=o("splinter"),tyr=o(" \u2014 "),Hoe=a("a"),ayr=o("SplinterForQuestionAnswering"),nyr=o(" (Splinter model)"),syr=l(),e3=a("li"),BAe=a("strong"),lyr=o("squeezebert"),iyr=o(" \u2014 "),Joe=a("a"),dyr=o("SqueezeBertForQuestionAnswering"),myr=o(" (SqueezeBERT model)"),cyr=l(),o3=a("li"),IAe=a("strong"),fyr=o("xlm"),gyr=o(" \u2014 "),Yoe=a("a"),hyr=o("XLMForQuestionAnsweringSimple"),uyr=o(" (XLM model)"),pyr=l(),r3=a("li"),NAe=a("strong"),_yr=o("xlm-roberta"),byr=o(" \u2014 "),Zoe=a("a"),vyr=o("XLMRobertaForQuestionAnswering"),Fyr=o(" (XLM-RoBERTa model)"),Tyr=l(),t3=a("li"),qAe=a("strong"),Myr=o("xlm-roberta-xl"),Eyr=o(" \u2014 "),Koe=a("a"),Cyr=o("XLMRobertaXLForQuestionAnswering"),wyr=o(" (XLM-RoBERTa-XL model)"),Ayr=l(),a3=a("li"),jAe=a("strong"),Lyr=o("xlnet"),yyr=o(" \u2014 "),ere=a("a"),xyr=o("XLNetForQuestionAnsweringSimple"),$yr=o(" (XLNet model)"),kyr=l(),n3=a("li"),DAe=a("strong"),Syr=o("yoso"),Ryr=o(" \u2014 "),ore=a("a"),Pyr=o("YosoForQuestionAnswering"),Byr=o(" (YOSO model)"),Iyr=l(),s3=a("p"),Nyr=o("The model is set in evaluation mode by default using "),GAe=a("code"),qyr=o("model.eval()"),jyr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),OAe=a("code"),Dyr=o("model.train()"),Gyr=l(),F(l3.$$.fragment),Bio=l(),Fm=a("h2"),i3=a("a"),VAe=a("span"),F(oR.$$.fragment),Oyr=l(),XAe=a("span"),Vyr=o("AutoModelForTableQuestionAnswering"),Iio=l(),Yo=a("div"),F(rR.$$.fragment),Xyr=l(),Tm=a("p"),zyr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),rre=a("a"),Qyr=o("from_pretrained()"),Wyr=o(" class method or the "),tre=a("a"),Uyr=o("from_config()"),Hyr=o(` class
method.`),Jyr=l(),tR=a("p"),Yyr=o("This class cannot be instantiated directly using "),zAe=a("code"),Zyr=o("__init__()"),Kyr=o(" (throws an error)."),e9r=l(),Nt=a("div"),F(aR.$$.fragment),o9r=l(),QAe=a("p"),r9r=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),t9r=l(),Mm=a("p"),a9r=o(`Note:
Loading a model from its configuration file does `),WAe=a("strong"),n9r=o("not"),s9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),are=a("a"),l9r=o("from_pretrained()"),i9r=o(" to load the model weights."),d9r=l(),F(d3.$$.fragment),m9r=l(),uo=a("div"),F(nR.$$.fragment),c9r=l(),UAe=a("p"),f9r=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),g9r=l(),Cn=a("p"),h9r=o("The model class to instantiate is selected based on the "),HAe=a("code"),u9r=o("model_type"),p9r=o(` property of the config object (either
passed as an argument or loaded from `),JAe=a("code"),_9r=o("pretrained_model_name_or_path"),b9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),YAe=a("code"),v9r=o("pretrained_model_name_or_path"),F9r=o(":"),T9r=l(),ZAe=a("ul"),m3=a("li"),KAe=a("strong"),M9r=o("tapas"),E9r=o(" \u2014 "),nre=a("a"),C9r=o("TapasForQuestionAnswering"),w9r=o(" (TAPAS model)"),A9r=l(),c3=a("p"),L9r=o("The model is set in evaluation mode by default using "),e6e=a("code"),y9r=o("model.eval()"),x9r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o6e=a("code"),$9r=o("model.train()"),k9r=l(),F(f3.$$.fragment),Nio=l(),Em=a("h2"),g3=a("a"),r6e=a("span"),F(sR.$$.fragment),S9r=l(),t6e=a("span"),R9r=o("AutoModelForDocumentQuestionAnswering"),qio=l(),Zo=a("div"),F(lR.$$.fragment),P9r=l(),Cm=a("p"),B9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),sre=a("a"),I9r=o("from_pretrained()"),N9r=o(" class method or the "),lre=a("a"),q9r=o("from_config()"),j9r=o(` class
method.`),D9r=l(),iR=a("p"),G9r=o("This class cannot be instantiated directly using "),a6e=a("code"),O9r=o("__init__()"),V9r=o(" (throws an error)."),X9r=l(),qt=a("div"),F(dR.$$.fragment),z9r=l(),n6e=a("p"),Q9r=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),W9r=l(),wm=a("p"),U9r=o(`Note:
Loading a model from its configuration file does `),s6e=a("strong"),H9r=o("not"),J9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ire=a("a"),Y9r=o("from_pretrained()"),Z9r=o(" to load the model weights."),K9r=l(),F(h3.$$.fragment),exr=l(),po=a("div"),F(mR.$$.fragment),oxr=l(),l6e=a("p"),rxr=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),txr=l(),wn=a("p"),axr=o("The model class to instantiate is selected based on the "),i6e=a("code"),nxr=o("model_type"),sxr=o(` property of the config object (either
passed as an argument or loaded from `),d6e=a("code"),lxr=o("pretrained_model_name_or_path"),ixr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m6e=a("code"),dxr=o("pretrained_model_name_or_path"),mxr=o(":"),cxr=l(),Am=a("ul"),u3=a("li"),c6e=a("strong"),fxr=o("layoutlm"),gxr=o(" \u2014 "),dre=a("a"),hxr=o("LayoutLMForQuestionAnswering"),uxr=o(" (LayoutLM model)"),pxr=l(),p3=a("li"),f6e=a("strong"),_xr=o("layoutlmv2"),bxr=o(" \u2014 "),mre=a("a"),vxr=o("LayoutLMv2ForQuestionAnswering"),Fxr=o(" (LayoutLMv2 model)"),Txr=l(),_3=a("li"),g6e=a("strong"),Mxr=o("layoutlmv3"),Exr=o(" \u2014 "),cre=a("a"),Cxr=o("LayoutLMv3ForQuestionAnswering"),wxr=o(" (LayoutLMv3 model)"),Axr=l(),b3=a("p"),Lxr=o("The model is set in evaluation mode by default using "),h6e=a("code"),yxr=o("model.eval()"),xxr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u6e=a("code"),$xr=o("model.train()"),kxr=l(),F(v3.$$.fragment),jio=l(),Lm=a("h2"),F3=a("a"),p6e=a("span"),F(cR.$$.fragment),Sxr=l(),_6e=a("span"),Rxr=o("AutoModelForImageClassification"),Dio=l(),Ko=a("div"),F(fR.$$.fragment),Pxr=l(),ym=a("p"),Bxr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),fre=a("a"),Ixr=o("from_pretrained()"),Nxr=o(" class method or the "),gre=a("a"),qxr=o("from_config()"),jxr=o(` class
method.`),Dxr=l(),gR=a("p"),Gxr=o("This class cannot be instantiated directly using "),b6e=a("code"),Oxr=o("__init__()"),Vxr=o(" (throws an error)."),Xxr=l(),jt=a("div"),F(hR.$$.fragment),zxr=l(),v6e=a("p"),Qxr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Wxr=l(),xm=a("p"),Uxr=o(`Note:
Loading a model from its configuration file does `),F6e=a("strong"),Hxr=o("not"),Jxr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hre=a("a"),Yxr=o("from_pretrained()"),Zxr=o(" to load the model weights."),Kxr=l(),F(T3.$$.fragment),e$r=l(),_o=a("div"),F(uR.$$.fragment),o$r=l(),T6e=a("p"),r$r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),t$r=l(),An=a("p"),a$r=o("The model class to instantiate is selected based on the "),M6e=a("code"),n$r=o("model_type"),s$r=o(` property of the config object (either
passed as an argument or loaded from `),E6e=a("code"),l$r=o("pretrained_model_name_or_path"),i$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C6e=a("code"),d$r=o("pretrained_model_name_or_path"),m$r=o(":"),c$r=l(),ve=a("ul"),M3=a("li"),w6e=a("strong"),f$r=o("beit"),g$r=o(" \u2014 "),ure=a("a"),h$r=o("BeitForImageClassification"),u$r=o(" (BEiT model)"),p$r=l(),E3=a("li"),A6e=a("strong"),_$r=o("convnext"),b$r=o(" \u2014 "),pre=a("a"),v$r=o("ConvNextForImageClassification"),F$r=o(" (ConvNeXT model)"),T$r=l(),C3=a("li"),L6e=a("strong"),M$r=o("cvt"),E$r=o(" \u2014 "),_re=a("a"),C$r=o("CvtForImageClassification"),w$r=o(" (CvT model)"),A$r=l(),w3=a("li"),y6e=a("strong"),L$r=o("data2vec-vision"),y$r=o(" \u2014 "),bre=a("a"),x$r=o("Data2VecVisionForImageClassification"),$$r=o(" (Data2VecVision model)"),k$r=l(),ql=a("li"),x6e=a("strong"),S$r=o("deit"),R$r=o(" \u2014 "),vre=a("a"),P$r=o("DeiTForImageClassification"),B$r=o(" or "),Fre=a("a"),I$r=o("DeiTForImageClassificationWithTeacher"),N$r=o(" (DeiT model)"),q$r=l(),A3=a("li"),$6e=a("strong"),j$r=o("imagegpt"),D$r=o(" \u2014 "),Tre=a("a"),G$r=o("ImageGPTForImageClassification"),O$r=o(" (ImageGPT model)"),V$r=l(),jl=a("li"),k6e=a("strong"),X$r=o("levit"),z$r=o(" \u2014 "),Mre=a("a"),Q$r=o("LevitForImageClassification"),W$r=o(" or "),Ere=a("a"),U$r=o("LevitForImageClassificationWithTeacher"),H$r=o(" (LeViT model)"),J$r=l(),L3=a("li"),S6e=a("strong"),Y$r=o("mobilenet_v2"),Z$r=o(" \u2014 "),Cre=a("a"),K$r=o("MobileNetV2ForImageClassification"),ekr=o(" (MobileNetV2 model)"),okr=l(),y3=a("li"),R6e=a("strong"),rkr=o("mobilevit"),tkr=o(" \u2014 "),wre=a("a"),akr=o("MobileViTForImageClassification"),nkr=o(" (MobileViT model)"),skr=l(),Dt=a("li"),P6e=a("strong"),lkr=o("perceiver"),ikr=o(" \u2014 "),Are=a("a"),dkr=o("PerceiverForImageClassificationLearned"),mkr=o(" or "),Lre=a("a"),ckr=o("PerceiverForImageClassificationFourier"),fkr=o(" or "),yre=a("a"),gkr=o("PerceiverForImageClassificationConvProcessing"),hkr=o(" (Perceiver model)"),ukr=l(),x3=a("li"),B6e=a("strong"),pkr=o("poolformer"),_kr=o(" \u2014 "),xre=a("a"),bkr=o("PoolFormerForImageClassification"),vkr=o(" (PoolFormer model)"),Fkr=l(),$3=a("li"),I6e=a("strong"),Tkr=o("regnet"),Mkr=o(" \u2014 "),$re=a("a"),Ekr=o("RegNetForImageClassification"),Ckr=o(" (RegNet model)"),wkr=l(),k3=a("li"),N6e=a("strong"),Akr=o("resnet"),Lkr=o(" \u2014 "),kre=a("a"),ykr=o("ResNetForImageClassification"),xkr=o(" (ResNet model)"),$kr=l(),S3=a("li"),q6e=a("strong"),kkr=o("segformer"),Skr=o(" \u2014 "),Sre=a("a"),Rkr=o("SegformerForImageClassification"),Pkr=o(" (SegFormer model)"),Bkr=l(),R3=a("li"),j6e=a("strong"),Ikr=o("swin"),Nkr=o(" \u2014 "),Rre=a("a"),qkr=o("SwinForImageClassification"),jkr=o(" (Swin Transformer model)"),Dkr=l(),P3=a("li"),D6e=a("strong"),Gkr=o("swinv2"),Okr=o(" \u2014 "),Pre=a("a"),Vkr=o("Swinv2ForImageClassification"),Xkr=o(" (Swin Transformer V2 model)"),zkr=l(),B3=a("li"),G6e=a("strong"),Qkr=o("van"),Wkr=o(" \u2014 "),Bre=a("a"),Ukr=o("VanForImageClassification"),Hkr=o(" (VAN model)"),Jkr=l(),I3=a("li"),O6e=a("strong"),Ykr=o("vit"),Zkr=o(" \u2014 "),Ire=a("a"),Kkr=o("ViTForImageClassification"),eSr=o(" (ViT model)"),oSr=l(),N3=a("li"),V6e=a("strong"),rSr=o("vit_msn"),tSr=o(" \u2014 "),Nre=a("a"),aSr=o("ViTMSNForImageClassification"),nSr=o(" (ViTMSN model)"),sSr=l(),q3=a("p"),lSr=o("The model is set in evaluation mode by default using "),X6e=a("code"),iSr=o("model.eval()"),dSr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),z6e=a("code"),mSr=o("model.train()"),cSr=l(),F(j3.$$.fragment),Gio=l(),$m=a("h2"),D3=a("a"),Q6e=a("span"),F(pR.$$.fragment),fSr=l(),W6e=a("span"),gSr=o("AutoModelForVideoClassification"),Oio=l(),er=a("div"),F(_R.$$.fragment),hSr=l(),km=a("p"),uSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),qre=a("a"),pSr=o("from_pretrained()"),_Sr=o(" class method or the "),jre=a("a"),bSr=o("from_config()"),vSr=o(` class
method.`),FSr=l(),bR=a("p"),TSr=o("This class cannot be instantiated directly using "),U6e=a("code"),MSr=o("__init__()"),ESr=o(" (throws an error)."),CSr=l(),Gt=a("div"),F(vR.$$.fragment),wSr=l(),H6e=a("p"),ASr=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),LSr=l(),Sm=a("p"),ySr=o(`Note:
Loading a model from its configuration file does `),J6e=a("strong"),xSr=o("not"),$Sr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Dre=a("a"),kSr=o("from_pretrained()"),SSr=o(" to load the model weights."),RSr=l(),F(G3.$$.fragment),PSr=l(),bo=a("div"),F(FR.$$.fragment),BSr=l(),Y6e=a("p"),ISr=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),NSr=l(),Ln=a("p"),qSr=o("The model class to instantiate is selected based on the "),Z6e=a("code"),jSr=o("model_type"),DSr=o(` property of the config object (either
passed as an argument or loaded from `),K6e=a("code"),GSr=o("pretrained_model_name_or_path"),OSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e7e=a("code"),VSr=o("pretrained_model_name_or_path"),XSr=o(":"),zSr=l(),o7e=a("ul"),O3=a("li"),r7e=a("strong"),QSr=o("videomae"),WSr=o(" \u2014 "),Gre=a("a"),USr=o("VideoMAEForVideoClassification"),HSr=o(" (VideoMAE model)"),JSr=l(),V3=a("p"),YSr=o("The model is set in evaluation mode by default using "),t7e=a("code"),ZSr=o("model.eval()"),KSr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),a7e=a("code"),eRr=o("model.train()"),oRr=l(),F(X3.$$.fragment),Vio=l(),Rm=a("h2"),z3=a("a"),n7e=a("span"),F(TR.$$.fragment),rRr=l(),s7e=a("span"),tRr=o("AutoModelForVision2Seq"),Xio=l(),or=a("div"),F(MR.$$.fragment),aRr=l(),Pm=a("p"),nRr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Ore=a("a"),sRr=o("from_pretrained()"),lRr=o(" class method or the "),Vre=a("a"),iRr=o("from_config()"),dRr=o(` class
method.`),mRr=l(),ER=a("p"),cRr=o("This class cannot be instantiated directly using "),l7e=a("code"),fRr=o("__init__()"),gRr=o(" (throws an error)."),hRr=l(),Ot=a("div"),F(CR.$$.fragment),uRr=l(),i7e=a("p"),pRr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),_Rr=l(),Bm=a("p"),bRr=o(`Note:
Loading a model from its configuration file does `),d7e=a("strong"),vRr=o("not"),FRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Xre=a("a"),TRr=o("from_pretrained()"),MRr=o(" to load the model weights."),ERr=l(),F(Q3.$$.fragment),CRr=l(),vo=a("div"),F(wR.$$.fragment),wRr=l(),m7e=a("p"),ARr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),LRr=l(),yn=a("p"),yRr=o("The model class to instantiate is selected based on the "),c7e=a("code"),xRr=o("model_type"),$Rr=o(` property of the config object (either
passed as an argument or loaded from `),f7e=a("code"),kRr=o("pretrained_model_name_or_path"),SRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g7e=a("code"),RRr=o("pretrained_model_name_or_path"),PRr=o(":"),BRr=l(),h7e=a("ul"),W3=a("li"),u7e=a("strong"),IRr=o("vision-encoder-decoder"),NRr=o(" \u2014 "),zre=a("a"),qRr=o("VisionEncoderDecoderModel"),jRr=o(" (Vision Encoder decoder model)"),DRr=l(),U3=a("p"),GRr=o("The model is set in evaluation mode by default using "),p7e=a("code"),ORr=o("model.eval()"),VRr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_7e=a("code"),XRr=o("model.train()"),zRr=l(),F(H3.$$.fragment),zio=l(),Im=a("h2"),J3=a("a"),b7e=a("span"),F(AR.$$.fragment),QRr=l(),v7e=a("span"),WRr=o("AutoModelForVisualQuestionAnswering"),Qio=l(),rr=a("div"),F(LR.$$.fragment),URr=l(),Nm=a("p"),HRr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),Qre=a("a"),JRr=o("from_pretrained()"),YRr=o(" class method or the "),Wre=a("a"),ZRr=o("from_config()"),KRr=o(` class
method.`),ePr=l(),yR=a("p"),oPr=o("This class cannot be instantiated directly using "),F7e=a("code"),rPr=o("__init__()"),tPr=o(" (throws an error)."),aPr=l(),Vt=a("div"),F(xR.$$.fragment),nPr=l(),T7e=a("p"),sPr=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),lPr=l(),qm=a("p"),iPr=o(`Note:
Loading a model from its configuration file does `),M7e=a("strong"),dPr=o("not"),mPr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ure=a("a"),cPr=o("from_pretrained()"),fPr=o(" to load the model weights."),gPr=l(),F(Y3.$$.fragment),hPr=l(),Fo=a("div"),F($R.$$.fragment),uPr=l(),E7e=a("p"),pPr=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),_Pr=l(),xn=a("p"),bPr=o("The model class to instantiate is selected based on the "),C7e=a("code"),vPr=o("model_type"),FPr=o(` property of the config object (either
passed as an argument or loaded from `),w7e=a("code"),TPr=o("pretrained_model_name_or_path"),MPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A7e=a("code"),EPr=o("pretrained_model_name_or_path"),CPr=o(":"),wPr=l(),L7e=a("ul"),Z3=a("li"),y7e=a("strong"),APr=o("vilt"),LPr=o(" \u2014 "),Hre=a("a"),yPr=o("ViltForQuestionAnswering"),xPr=o(" (ViLT model)"),$Pr=l(),K3=a("p"),kPr=o("The model is set in evaluation mode by default using "),x7e=a("code"),SPr=o("model.eval()"),RPr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$7e=a("code"),PPr=o("model.train()"),BPr=l(),F(e5.$$.fragment),Wio=l(),jm=a("h2"),o5=a("a"),k7e=a("span"),F(kR.$$.fragment),IPr=l(),S7e=a("span"),NPr=o("AutoModelForAudioClassification"),Uio=l(),tr=a("div"),F(SR.$$.fragment),qPr=l(),Dm=a("p"),jPr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),Jre=a("a"),DPr=o("from_pretrained()"),GPr=o(" class method or the "),Yre=a("a"),OPr=o("from_config()"),VPr=o(` class
method.`),XPr=l(),RR=a("p"),zPr=o("This class cannot be instantiated directly using "),R7e=a("code"),QPr=o("__init__()"),WPr=o(" (throws an error)."),UPr=l(),Xt=a("div"),F(PR.$$.fragment),HPr=l(),P7e=a("p"),JPr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),YPr=l(),Gm=a("p"),ZPr=o(`Note:
Loading a model from its configuration file does `),B7e=a("strong"),KPr=o("not"),eBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zre=a("a"),oBr=o("from_pretrained()"),rBr=o(" to load the model weights."),tBr=l(),F(r5.$$.fragment),aBr=l(),To=a("div"),F(BR.$$.fragment),nBr=l(),I7e=a("p"),sBr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),lBr=l(),$n=a("p"),iBr=o("The model class to instantiate is selected based on the "),N7e=a("code"),dBr=o("model_type"),mBr=o(` property of the config object (either
passed as an argument or loaded from `),q7e=a("code"),cBr=o("pretrained_model_name_or_path"),fBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j7e=a("code"),gBr=o("pretrained_model_name_or_path"),hBr=o(":"),uBr=l(),Ne=a("ul"),t5=a("li"),D7e=a("strong"),pBr=o("data2vec-audio"),_Br=o(" \u2014 "),Kre=a("a"),bBr=o("Data2VecAudioForSequenceClassification"),vBr=o(" (Data2VecAudio model)"),FBr=l(),a5=a("li"),G7e=a("strong"),TBr=o("hubert"),MBr=o(" \u2014 "),ete=a("a"),EBr=o("HubertForSequenceClassification"),CBr=o(" (Hubert model)"),wBr=l(),n5=a("li"),O7e=a("strong"),ABr=o("sew"),LBr=o(" \u2014 "),ote=a("a"),yBr=o("SEWForSequenceClassification"),xBr=o(" (SEW model)"),$Br=l(),s5=a("li"),V7e=a("strong"),kBr=o("sew-d"),SBr=o(" \u2014 "),rte=a("a"),RBr=o("SEWDForSequenceClassification"),PBr=o(" (SEW-D model)"),BBr=l(),l5=a("li"),X7e=a("strong"),IBr=o("unispeech"),NBr=o(" \u2014 "),tte=a("a"),qBr=o("UniSpeechForSequenceClassification"),jBr=o(" (UniSpeech model)"),DBr=l(),i5=a("li"),z7e=a("strong"),GBr=o("unispeech-sat"),OBr=o(" \u2014 "),ate=a("a"),VBr=o("UniSpeechSatForSequenceClassification"),XBr=o(" (UniSpeechSat model)"),zBr=l(),d5=a("li"),Q7e=a("strong"),QBr=o("wav2vec2"),WBr=o(" \u2014 "),nte=a("a"),UBr=o("Wav2Vec2ForSequenceClassification"),HBr=o(" (Wav2Vec2 model)"),JBr=l(),m5=a("li"),W7e=a("strong"),YBr=o("wav2vec2-conformer"),ZBr=o(" \u2014 "),ste=a("a"),KBr=o("Wav2Vec2ConformerForSequenceClassification"),eIr=o(" (Wav2Vec2-Conformer model)"),oIr=l(),c5=a("li"),U7e=a("strong"),rIr=o("wavlm"),tIr=o(" \u2014 "),lte=a("a"),aIr=o("WavLMForSequenceClassification"),nIr=o(" (WavLM model)"),sIr=l(),f5=a("p"),lIr=o("The model is set in evaluation mode by default using "),H7e=a("code"),iIr=o("model.eval()"),dIr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),J7e=a("code"),mIr=o("model.train()"),cIr=l(),F(g5.$$.fragment),Hio=l(),Om=a("h2"),h5=a("a"),Y7e=a("span"),F(IR.$$.fragment),fIr=l(),Z7e=a("span"),gIr=o("AutoModelForAudioFrameClassification"),Jio=l(),ar=a("div"),F(NR.$$.fragment),hIr=l(),Vm=a("p"),uIr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),ite=a("a"),pIr=o("from_pretrained()"),_Ir=o(" class method or the "),dte=a("a"),bIr=o("from_config()"),vIr=o(` class
method.`),FIr=l(),qR=a("p"),TIr=o("This class cannot be instantiated directly using "),K7e=a("code"),MIr=o("__init__()"),EIr=o(" (throws an error)."),CIr=l(),zt=a("div"),F(jR.$$.fragment),wIr=l(),e8e=a("p"),AIr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),LIr=l(),Xm=a("p"),yIr=o(`Note:
Loading a model from its configuration file does `),o8e=a("strong"),xIr=o("not"),$Ir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mte=a("a"),kIr=o("from_pretrained()"),SIr=o(" to load the model weights."),RIr=l(),F(u5.$$.fragment),PIr=l(),Mo=a("div"),F(DR.$$.fragment),BIr=l(),r8e=a("p"),IIr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),NIr=l(),kn=a("p"),qIr=o("The model class to instantiate is selected based on the "),t8e=a("code"),jIr=o("model_type"),DIr=o(` property of the config object (either
passed as an argument or loaded from `),a8e=a("code"),GIr=o("pretrained_model_name_or_path"),OIr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n8e=a("code"),VIr=o("pretrained_model_name_or_path"),XIr=o(":"),zIr=l(),Ft=a("ul"),p5=a("li"),s8e=a("strong"),QIr=o("data2vec-audio"),WIr=o(" \u2014 "),cte=a("a"),UIr=o("Data2VecAudioForAudioFrameClassification"),HIr=o(" (Data2VecAudio model)"),JIr=l(),_5=a("li"),l8e=a("strong"),YIr=o("unispeech-sat"),ZIr=o(" \u2014 "),fte=a("a"),KIr=o("UniSpeechSatForAudioFrameClassification"),eNr=o(" (UniSpeechSat model)"),oNr=l(),b5=a("li"),i8e=a("strong"),rNr=o("wav2vec2"),tNr=o(" \u2014 "),gte=a("a"),aNr=o("Wav2Vec2ForAudioFrameClassification"),nNr=o(" (Wav2Vec2 model)"),sNr=l(),v5=a("li"),d8e=a("strong"),lNr=o("wav2vec2-conformer"),iNr=o(" \u2014 "),hte=a("a"),dNr=o("Wav2Vec2ConformerForAudioFrameClassification"),mNr=o(" (Wav2Vec2-Conformer model)"),cNr=l(),F5=a("li"),m8e=a("strong"),fNr=o("wavlm"),gNr=o(" \u2014 "),ute=a("a"),hNr=o("WavLMForAudioFrameClassification"),uNr=o(" (WavLM model)"),pNr=l(),T5=a("p"),_Nr=o("The model is set in evaluation mode by default using "),c8e=a("code"),bNr=o("model.eval()"),vNr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f8e=a("code"),FNr=o("model.train()"),TNr=l(),F(M5.$$.fragment),Yio=l(),zm=a("h2"),E5=a("a"),g8e=a("span"),F(GR.$$.fragment),MNr=l(),h8e=a("span"),ENr=o("AutoModelForCTC"),Zio=l(),nr=a("div"),F(OR.$$.fragment),CNr=l(),Qm=a("p"),wNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),pte=a("a"),ANr=o("from_pretrained()"),LNr=o(" class method or the "),_te=a("a"),yNr=o("from_config()"),xNr=o(` class
method.`),$Nr=l(),VR=a("p"),kNr=o("This class cannot be instantiated directly using "),u8e=a("code"),SNr=o("__init__()"),RNr=o(" (throws an error)."),PNr=l(),Qt=a("div"),F(XR.$$.fragment),BNr=l(),p8e=a("p"),INr=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),NNr=l(),Wm=a("p"),qNr=o(`Note:
Loading a model from its configuration file does `),_8e=a("strong"),jNr=o("not"),DNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bte=a("a"),GNr=o("from_pretrained()"),ONr=o(" to load the model weights."),VNr=l(),F(C5.$$.fragment),XNr=l(),Eo=a("div"),F(zR.$$.fragment),zNr=l(),b8e=a("p"),QNr=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),WNr=l(),Sn=a("p"),UNr=o("The model class to instantiate is selected based on the "),v8e=a("code"),HNr=o("model_type"),JNr=o(` property of the config object (either
passed as an argument or loaded from `),F8e=a("code"),YNr=o("pretrained_model_name_or_path"),ZNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T8e=a("code"),KNr=o("pretrained_model_name_or_path"),eqr=o(":"),oqr=l(),xe=a("ul"),w5=a("li"),M8e=a("strong"),rqr=o("data2vec-audio"),tqr=o(" \u2014 "),vte=a("a"),aqr=o("Data2VecAudioForCTC"),nqr=o(" (Data2VecAudio model)"),sqr=l(),A5=a("li"),E8e=a("strong"),lqr=o("hubert"),iqr=o(" \u2014 "),Fte=a("a"),dqr=o("HubertForCTC"),mqr=o(" (Hubert model)"),cqr=l(),L5=a("li"),C8e=a("strong"),fqr=o("mctct"),gqr=o(" \u2014 "),Tte=a("a"),hqr=o("MCTCTForCTC"),uqr=o(" (M-CTC-T model)"),pqr=l(),y5=a("li"),w8e=a("strong"),_qr=o("sew"),bqr=o(" \u2014 "),Mte=a("a"),vqr=o("SEWForCTC"),Fqr=o(" (SEW model)"),Tqr=l(),x5=a("li"),A8e=a("strong"),Mqr=o("sew-d"),Eqr=o(" \u2014 "),Ete=a("a"),Cqr=o("SEWDForCTC"),wqr=o(" (SEW-D model)"),Aqr=l(),$5=a("li"),L8e=a("strong"),Lqr=o("unispeech"),yqr=o(" \u2014 "),Cte=a("a"),xqr=o("UniSpeechForCTC"),$qr=o(" (UniSpeech model)"),kqr=l(),k5=a("li"),y8e=a("strong"),Sqr=o("unispeech-sat"),Rqr=o(" \u2014 "),wte=a("a"),Pqr=o("UniSpeechSatForCTC"),Bqr=o(" (UniSpeechSat model)"),Iqr=l(),S5=a("li"),x8e=a("strong"),Nqr=o("wav2vec2"),qqr=o(" \u2014 "),Ate=a("a"),jqr=o("Wav2Vec2ForCTC"),Dqr=o(" (Wav2Vec2 model)"),Gqr=l(),R5=a("li"),$8e=a("strong"),Oqr=o("wav2vec2-conformer"),Vqr=o(" \u2014 "),Lte=a("a"),Xqr=o("Wav2Vec2ConformerForCTC"),zqr=o(" (Wav2Vec2-Conformer model)"),Qqr=l(),P5=a("li"),k8e=a("strong"),Wqr=o("wavlm"),Uqr=o(" \u2014 "),yte=a("a"),Hqr=o("WavLMForCTC"),Jqr=o(" (WavLM model)"),Yqr=l(),B5=a("p"),Zqr=o("The model is set in evaluation mode by default using "),S8e=a("code"),Kqr=o("model.eval()"),ejr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),R8e=a("code"),ojr=o("model.train()"),rjr=l(),F(I5.$$.fragment),Kio=l(),Um=a("h2"),N5=a("a"),P8e=a("span"),F(QR.$$.fragment),tjr=l(),B8e=a("span"),ajr=o("AutoModelForSpeechSeq2Seq"),edo=l(),sr=a("div"),F(WR.$$.fragment),njr=l(),Hm=a("p"),sjr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),xte=a("a"),ljr=o("from_pretrained()"),ijr=o(" class method or the "),$te=a("a"),djr=o("from_config()"),mjr=o(` class
method.`),cjr=l(),UR=a("p"),fjr=o("This class cannot be instantiated directly using "),I8e=a("code"),gjr=o("__init__()"),hjr=o(" (throws an error)."),ujr=l(),Wt=a("div"),F(HR.$$.fragment),pjr=l(),N8e=a("p"),_jr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),bjr=l(),Jm=a("p"),vjr=o(`Note:
Loading a model from its configuration file does `),q8e=a("strong"),Fjr=o("not"),Tjr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kte=a("a"),Mjr=o("from_pretrained()"),Ejr=o(" to load the model weights."),Cjr=l(),F(q5.$$.fragment),wjr=l(),Co=a("div"),F(JR.$$.fragment),Ajr=l(),j8e=a("p"),Ljr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),yjr=l(),Rn=a("p"),xjr=o("The model class to instantiate is selected based on the "),D8e=a("code"),$jr=o("model_type"),kjr=o(` property of the config object (either
passed as an argument or loaded from `),G8e=a("code"),Sjr=o("pretrained_model_name_or_path"),Rjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O8e=a("code"),Pjr=o("pretrained_model_name_or_path"),Bjr=o(":"),Ijr=l(),Ym=a("ul"),j5=a("li"),V8e=a("strong"),Njr=o("speech-encoder-decoder"),qjr=o(" \u2014 "),Ste=a("a"),jjr=o("SpeechEncoderDecoderModel"),Djr=o(" (Speech Encoder decoder model)"),Gjr=l(),D5=a("li"),X8e=a("strong"),Ojr=o("speech_to_text"),Vjr=o(" \u2014 "),Rte=a("a"),Xjr=o("Speech2TextForConditionalGeneration"),zjr=o(" (Speech2Text model)"),Qjr=l(),G5=a("li"),z8e=a("strong"),Wjr=o("whisper"),Ujr=o(" \u2014 "),Pte=a("a"),Hjr=o("WhisperForConditionalGeneration"),Jjr=o(" (Whisper model)"),Yjr=l(),O5=a("p"),Zjr=o("The model is set in evaluation mode by default using "),Q8e=a("code"),Kjr=o("model.eval()"),eDr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),W8e=a("code"),oDr=o("model.train()"),rDr=l(),F(V5.$$.fragment),odo=l(),Zm=a("h2"),X5=a("a"),U8e=a("span"),F(YR.$$.fragment),tDr=l(),H8e=a("span"),aDr=o("AutoModelForAudioXVector"),rdo=l(),lr=a("div"),F(ZR.$$.fragment),nDr=l(),Km=a("p"),sDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),Bte=a("a"),lDr=o("from_pretrained()"),iDr=o(" class method or the "),Ite=a("a"),dDr=o("from_config()"),mDr=o(` class
method.`),cDr=l(),KR=a("p"),fDr=o("This class cannot be instantiated directly using "),J8e=a("code"),gDr=o("__init__()"),hDr=o(" (throws an error)."),uDr=l(),Ut=a("div"),F(eP.$$.fragment),pDr=l(),Y8e=a("p"),_Dr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),bDr=l(),ec=a("p"),vDr=o(`Note:
Loading a model from its configuration file does `),Z8e=a("strong"),FDr=o("not"),TDr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Nte=a("a"),MDr=o("from_pretrained()"),EDr=o(" to load the model weights."),CDr=l(),F(z5.$$.fragment),wDr=l(),wo=a("div"),F(oP.$$.fragment),ADr=l(),K8e=a("p"),LDr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),yDr=l(),Pn=a("p"),xDr=o("The model class to instantiate is selected based on the "),eLe=a("code"),$Dr=o("model_type"),kDr=o(` property of the config object (either
passed as an argument or loaded from `),oLe=a("code"),SDr=o("pretrained_model_name_or_path"),RDr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rLe=a("code"),PDr=o("pretrained_model_name_or_path"),BDr=o(":"),IDr=l(),Tt=a("ul"),Q5=a("li"),tLe=a("strong"),NDr=o("data2vec-audio"),qDr=o(" \u2014 "),qte=a("a"),jDr=o("Data2VecAudioForXVector"),DDr=o(" (Data2VecAudio model)"),GDr=l(),W5=a("li"),aLe=a("strong"),ODr=o("unispeech-sat"),VDr=o(" \u2014 "),jte=a("a"),XDr=o("UniSpeechSatForXVector"),zDr=o(" (UniSpeechSat model)"),QDr=l(),U5=a("li"),nLe=a("strong"),WDr=o("wav2vec2"),UDr=o(" \u2014 "),Dte=a("a"),HDr=o("Wav2Vec2ForXVector"),JDr=o(" (Wav2Vec2 model)"),YDr=l(),H5=a("li"),sLe=a("strong"),ZDr=o("wav2vec2-conformer"),KDr=o(" \u2014 "),Gte=a("a"),eGr=o("Wav2Vec2ConformerForXVector"),oGr=o(" (Wav2Vec2-Conformer model)"),rGr=l(),J5=a("li"),lLe=a("strong"),tGr=o("wavlm"),aGr=o(" \u2014 "),Ote=a("a"),nGr=o("WavLMForXVector"),sGr=o(" (WavLM model)"),lGr=l(),Y5=a("p"),iGr=o("The model is set in evaluation mode by default using "),iLe=a("code"),dGr=o("model.eval()"),mGr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),dLe=a("code"),cGr=o("model.train()"),fGr=l(),F(Z5.$$.fragment),tdo=l(),oc=a("h2"),K5=a("a"),mLe=a("span"),F(rP.$$.fragment),gGr=l(),cLe=a("span"),hGr=o("AutoModelForMaskedImageModeling"),ado=l(),ir=a("div"),F(tP.$$.fragment),uGr=l(),rc=a("p"),pGr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Vte=a("a"),_Gr=o("from_pretrained()"),bGr=o(" class method or the "),Xte=a("a"),vGr=o("from_config()"),FGr=o(` class
method.`),TGr=l(),aP=a("p"),MGr=o("This class cannot be instantiated directly using "),fLe=a("code"),EGr=o("__init__()"),CGr=o(" (throws an error)."),wGr=l(),Ht=a("div"),F(nP.$$.fragment),AGr=l(),gLe=a("p"),LGr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),yGr=l(),tc=a("p"),xGr=o(`Note:
Loading a model from its configuration file does `),hLe=a("strong"),$Gr=o("not"),kGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zte=a("a"),SGr=o("from_pretrained()"),RGr=o(" to load the model weights."),PGr=l(),F(e0.$$.fragment),BGr=l(),Ao=a("div"),F(sP.$$.fragment),IGr=l(),uLe=a("p"),NGr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),qGr=l(),Bn=a("p"),jGr=o("The model class to instantiate is selected based on the "),pLe=a("code"),DGr=o("model_type"),GGr=o(` property of the config object (either
passed as an argument or loaded from `),_Le=a("code"),OGr=o("pretrained_model_name_or_path"),VGr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bLe=a("code"),XGr=o("pretrained_model_name_or_path"),zGr=o(":"),QGr=l(),In=a("ul"),o0=a("li"),vLe=a("strong"),WGr=o("deit"),UGr=o(" \u2014 "),Qte=a("a"),HGr=o("DeiTForMaskedImageModeling"),JGr=o(" (DeiT model)"),YGr=l(),r0=a("li"),FLe=a("strong"),ZGr=o("swin"),KGr=o(" \u2014 "),Wte=a("a"),eOr=o("SwinForMaskedImageModeling"),oOr=o(" (Swin Transformer model)"),rOr=l(),t0=a("li"),TLe=a("strong"),tOr=o("swinv2"),aOr=o(" \u2014 "),Ute=a("a"),nOr=o("Swinv2ForMaskedImageModeling"),sOr=o(" (Swin Transformer V2 model)"),lOr=l(),a0=a("li"),MLe=a("strong"),iOr=o("vit"),dOr=o(" \u2014 "),Hte=a("a"),mOr=o("ViTForMaskedImageModeling"),cOr=o(" (ViT model)"),fOr=l(),n0=a("p"),gOr=o("The model is set in evaluation mode by default using "),ELe=a("code"),hOr=o("model.eval()"),uOr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),CLe=a("code"),pOr=o("model.train()"),_Or=l(),F(s0.$$.fragment),ndo=l(),ac=a("h2"),l0=a("a"),wLe=a("span"),F(lP.$$.fragment),bOr=l(),ALe=a("span"),vOr=o("AutoModelForObjectDetection"),sdo=l(),dr=a("div"),F(iP.$$.fragment),FOr=l(),nc=a("p"),TOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Jte=a("a"),MOr=o("from_pretrained()"),EOr=o(" class method or the "),Yte=a("a"),COr=o("from_config()"),wOr=o(` class
method.`),AOr=l(),dP=a("p"),LOr=o("This class cannot be instantiated directly using "),LLe=a("code"),yOr=o("__init__()"),xOr=o(" (throws an error)."),$Or=l(),Jt=a("div"),F(mP.$$.fragment),kOr=l(),yLe=a("p"),SOr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),ROr=l(),sc=a("p"),POr=o(`Note:
Loading a model from its configuration file does `),xLe=a("strong"),BOr=o("not"),IOr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zte=a("a"),NOr=o("from_pretrained()"),qOr=o(" to load the model weights."),jOr=l(),F(i0.$$.fragment),DOr=l(),Lo=a("div"),F(cP.$$.fragment),GOr=l(),$Le=a("p"),OOr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),VOr=l(),Nn=a("p"),XOr=o("The model class to instantiate is selected based on the "),kLe=a("code"),zOr=o("model_type"),QOr=o(` property of the config object (either
passed as an argument or loaded from `),SLe=a("code"),WOr=o("pretrained_model_name_or_path"),UOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RLe=a("code"),HOr=o("pretrained_model_name_or_path"),JOr=o(":"),YOr=l(),Mt=a("ul"),d0=a("li"),PLe=a("strong"),ZOr=o("conditional_detr"),KOr=o(" \u2014 "),Kte=a("a"),eVr=o("ConditionalDetrForObjectDetection"),oVr=o(" (Conditional DETR model)"),rVr=l(),m0=a("li"),BLe=a("strong"),tVr=o("deformable_detr"),aVr=o(" \u2014 "),eae=a("a"),nVr=o("DeformableDetrForObjectDetection"),sVr=o(" (Deformable DETR model)"),lVr=l(),c0=a("li"),ILe=a("strong"),iVr=o("detr"),dVr=o(" \u2014 "),oae=a("a"),mVr=o("DetrForObjectDetection"),cVr=o(" (DETR model)"),fVr=l(),f0=a("li"),NLe=a("strong"),gVr=o("table-transformer"),hVr=o(" \u2014 "),rae=a("a"),uVr=o("TableTransformerForObjectDetection"),pVr=o(" (Table Transformer model)"),_Vr=l(),g0=a("li"),qLe=a("strong"),bVr=o("yolos"),vVr=o(" \u2014 "),tae=a("a"),FVr=o("YolosForObjectDetection"),TVr=o(" (YOLOS model)"),MVr=l(),h0=a("p"),EVr=o("The model is set in evaluation mode by default using "),jLe=a("code"),CVr=o("model.eval()"),wVr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),DLe=a("code"),AVr=o("model.train()"),LVr=l(),F(u0.$$.fragment),ldo=l(),lc=a("h2"),p0=a("a"),GLe=a("span"),F(fP.$$.fragment),yVr=l(),OLe=a("span"),xVr=o("AutoModelForImageSegmentation"),ido=l(),mr=a("div"),F(gP.$$.fragment),$Vr=l(),ic=a("p"),kVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),aae=a("a"),SVr=o("from_pretrained()"),RVr=o(" class method or the "),nae=a("a"),PVr=o("from_config()"),BVr=o(` class
method.`),IVr=l(),hP=a("p"),NVr=o("This class cannot be instantiated directly using "),VLe=a("code"),qVr=o("__init__()"),jVr=o(" (throws an error)."),DVr=l(),Yt=a("div"),F(uP.$$.fragment),GVr=l(),XLe=a("p"),OVr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),VVr=l(),dc=a("p"),XVr=o(`Note:
Loading a model from its configuration file does `),zLe=a("strong"),zVr=o("not"),QVr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sae=a("a"),WVr=o("from_pretrained()"),UVr=o(" to load the model weights."),HVr=l(),F(_0.$$.fragment),JVr=l(),yo=a("div"),F(pP.$$.fragment),YVr=l(),QLe=a("p"),ZVr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),KVr=l(),qn=a("p"),eXr=o("The model class to instantiate is selected based on the "),WLe=a("code"),oXr=o("model_type"),rXr=o(` property of the config object (either
passed as an argument or loaded from `),ULe=a("code"),tXr=o("pretrained_model_name_or_path"),aXr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HLe=a("code"),nXr=o("pretrained_model_name_or_path"),sXr=o(":"),lXr=l(),JLe=a("ul"),b0=a("li"),YLe=a("strong"),iXr=o("detr"),dXr=o(" \u2014 "),lae=a("a"),mXr=o("DetrForSegmentation"),cXr=o(" (DETR model)"),fXr=l(),v0=a("p"),gXr=o("The model is set in evaluation mode by default using "),ZLe=a("code"),hXr=o("model.eval()"),uXr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),KLe=a("code"),pXr=o("model.train()"),_Xr=l(),F(F0.$$.fragment),ddo=l(),mc=a("h2"),T0=a("a"),eye=a("span"),F(_P.$$.fragment),bXr=l(),oye=a("span"),vXr=o("AutoModelForSemanticSegmentation"),mdo=l(),cr=a("div"),F(bP.$$.fragment),FXr=l(),cc=a("p"),TXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),iae=a("a"),MXr=o("from_pretrained()"),EXr=o(" class method or the "),dae=a("a"),CXr=o("from_config()"),wXr=o(` class
method.`),AXr=l(),vP=a("p"),LXr=o("This class cannot be instantiated directly using "),rye=a("code"),yXr=o("__init__()"),xXr=o(" (throws an error)."),$Xr=l(),Zt=a("div"),F(FP.$$.fragment),kXr=l(),tye=a("p"),SXr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),RXr=l(),fc=a("p"),PXr=o(`Note:
Loading a model from its configuration file does `),aye=a("strong"),BXr=o("not"),IXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mae=a("a"),NXr=o("from_pretrained()"),qXr=o(" to load the model weights."),jXr=l(),F(M0.$$.fragment),DXr=l(),xo=a("div"),F(TP.$$.fragment),GXr=l(),nye=a("p"),OXr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),VXr=l(),jn=a("p"),XXr=o("The model class to instantiate is selected based on the "),sye=a("code"),zXr=o("model_type"),QXr=o(` property of the config object (either
passed as an argument or loaded from `),lye=a("code"),WXr=o("pretrained_model_name_or_path"),UXr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iye=a("code"),HXr=o("pretrained_model_name_or_path"),JXr=o(":"),YXr=l(),fr=a("ul"),E0=a("li"),dye=a("strong"),ZXr=o("beit"),KXr=o(" \u2014 "),cae=a("a"),ezr=o("BeitForSemanticSegmentation"),ozr=o(" (BEiT model)"),rzr=l(),C0=a("li"),mye=a("strong"),tzr=o("data2vec-vision"),azr=o(" \u2014 "),fae=a("a"),nzr=o("Data2VecVisionForSemanticSegmentation"),szr=o(" (Data2VecVision model)"),lzr=l(),w0=a("li"),cye=a("strong"),izr=o("dpt"),dzr=o(" \u2014 "),gae=a("a"),mzr=o("DPTForSemanticSegmentation"),czr=o(" (DPT model)"),fzr=l(),A0=a("li"),fye=a("strong"),gzr=o("mobilenet_v2"),hzr=o(" \u2014 "),hae=a("a"),uzr=o("MobileNetV2ForSemanticSegmentation"),pzr=o(" (MobileNetV2 model)"),_zr=l(),L0=a("li"),gye=a("strong"),bzr=o("mobilevit"),vzr=o(" \u2014 "),uae=a("a"),Fzr=o("MobileViTForSemanticSegmentation"),Tzr=o(" (MobileViT model)"),Mzr=l(),y0=a("li"),hye=a("strong"),Ezr=o("segformer"),Czr=o(" \u2014 "),pae=a("a"),wzr=o("SegformerForSemanticSegmentation"),Azr=o(" (SegFormer model)"),Lzr=l(),x0=a("p"),yzr=o("The model is set in evaluation mode by default using "),uye=a("code"),xzr=o("model.eval()"),$zr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),pye=a("code"),kzr=o("model.train()"),Szr=l(),F($0.$$.fragment),cdo=l(),gc=a("h2"),k0=a("a"),_ye=a("span"),F(MP.$$.fragment),Rzr=l(),bye=a("span"),Pzr=o("AutoModelForInstanceSegmentation"),fdo=l(),gr=a("div"),F(EP.$$.fragment),Bzr=l(),hc=a("p"),Izr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),_ae=a("a"),Nzr=o("from_pretrained()"),qzr=o(" class method or the "),bae=a("a"),jzr=o("from_config()"),Dzr=o(` class
method.`),Gzr=l(),CP=a("p"),Ozr=o("This class cannot be instantiated directly using "),vye=a("code"),Vzr=o("__init__()"),Xzr=o(" (throws an error)."),zzr=l(),Kt=a("div"),F(wP.$$.fragment),Qzr=l(),Fye=a("p"),Wzr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Uzr=l(),uc=a("p"),Hzr=o(`Note:
Loading a model from its configuration file does `),Tye=a("strong"),Jzr=o("not"),Yzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vae=a("a"),Zzr=o("from_pretrained()"),Kzr=o(" to load the model weights."),eQr=l(),F(S0.$$.fragment),oQr=l(),$o=a("div"),F(AP.$$.fragment),rQr=l(),Mye=a("p"),tQr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),aQr=l(),Dn=a("p"),nQr=o("The model class to instantiate is selected based on the "),Eye=a("code"),sQr=o("model_type"),lQr=o(` property of the config object (either
passed as an argument or loaded from `),Cye=a("code"),iQr=o("pretrained_model_name_or_path"),dQr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wye=a("code"),mQr=o("pretrained_model_name_or_path"),cQr=o(":"),fQr=l(),Aye=a("ul"),R0=a("li"),Lye=a("strong"),gQr=o("maskformer"),hQr=o(" \u2014 "),Fae=a("a"),uQr=o("MaskFormerForInstanceSegmentation"),pQr=o(" (MaskFormer model)"),_Qr=l(),P0=a("p"),bQr=o("The model is set in evaluation mode by default using "),yye=a("code"),vQr=o("model.eval()"),FQr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),xye=a("code"),TQr=o("model.train()"),MQr=l(),F(B0.$$.fragment),gdo=l(),pc=a("h2"),I0=a("a"),$ye=a("span"),F(LP.$$.fragment),EQr=l(),kye=a("span"),CQr=o("AutoModelForZeroShotObjectDetection"),hdo=l(),hr=a("div"),F(yP.$$.fragment),wQr=l(),_c=a("p"),AQr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),Tae=a("a"),LQr=o("from_pretrained()"),yQr=o(" class method or the "),Mae=a("a"),xQr=o("from_config()"),$Qr=o(` class
method.`),kQr=l(),xP=a("p"),SQr=o("This class cannot be instantiated directly using "),Sye=a("code"),RQr=o("__init__()"),PQr=o(" (throws an error)."),BQr=l(),ea=a("div"),F($P.$$.fragment),IQr=l(),Rye=a("p"),NQr=o("Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),qQr=l(),bc=a("p"),jQr=o(`Note:
Loading a model from its configuration file does `),Pye=a("strong"),DQr=o("not"),GQr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Eae=a("a"),OQr=o("from_pretrained()"),VQr=o(" to load the model weights."),XQr=l(),F(N0.$$.fragment),zQr=l(),ko=a("div"),F(kP.$$.fragment),QQr=l(),Bye=a("p"),WQr=o("Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),UQr=l(),Gn=a("p"),HQr=o("The model class to instantiate is selected based on the "),Iye=a("code"),JQr=o("model_type"),YQr=o(` property of the config object (either
passed as an argument or loaded from `),Nye=a("code"),ZQr=o("pretrained_model_name_or_path"),KQr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qye=a("code"),eWr=o("pretrained_model_name_or_path"),oWr=o(":"),rWr=l(),jye=a("ul"),q0=a("li"),Dye=a("strong"),tWr=o("owlvit"),aWr=o(" \u2014 "),Cae=a("a"),nWr=o("OwlViTForObjectDetection"),sWr=o(" (OWL-ViT model)"),lWr=l(),j0=a("p"),iWr=o("The model is set in evaluation mode by default using "),Gye=a("code"),dWr=o("model.eval()"),mWr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Oye=a("code"),cWr=o("model.train()"),fWr=l(),F(D0.$$.fragment),udo=l(),vc=a("h2"),G0=a("a"),Vye=a("span"),F(SP.$$.fragment),gWr=l(),Xye=a("span"),hWr=o("TFAutoModel"),pdo=l(),ur=a("div"),F(RP.$$.fragment),uWr=l(),Fc=a("p"),pWr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),wae=a("a"),_Wr=o("from_pretrained()"),bWr=o(" class method or the "),Aae=a("a"),vWr=o("from_config()"),FWr=o(` class
method.`),TWr=l(),PP=a("p"),MWr=o("This class cannot be instantiated directly using "),zye=a("code"),EWr=o("__init__()"),CWr=o(" (throws an error)."),wWr=l(),oa=a("div"),F(BP.$$.fragment),AWr=l(),Qye=a("p"),LWr=o("Instantiates one of the base model classes of the library from a configuration."),yWr=l(),Tc=a("p"),xWr=o(`Note:
Loading a model from its configuration file does `),Wye=a("strong"),$Wr=o("not"),kWr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Lae=a("a"),SWr=o("from_pretrained()"),RWr=o(" to load the model weights."),PWr=l(),F(O0.$$.fragment),BWr=l(),zr=a("div"),F(IP.$$.fragment),IWr=l(),Uye=a("p"),NWr=o("Instantiate one of the base model classes of the library from a pretrained model."),qWr=l(),On=a("p"),jWr=o("The model class to instantiate is selected based on the "),Hye=a("code"),DWr=o("model_type"),GWr=o(` property of the config object (either
passed as an argument or loaded from `),Jye=a("code"),OWr=o("pretrained_model_name_or_path"),VWr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yye=a("code"),XWr=o("pretrained_model_name_or_path"),zWr=o(":"),QWr=l(),P=a("ul"),V0=a("li"),Zye=a("strong"),WWr=o("albert"),UWr=o(" \u2014 "),yae=a("a"),HWr=o("TFAlbertModel"),JWr=o(" (ALBERT model)"),YWr=l(),X0=a("li"),Kye=a("strong"),ZWr=o("bart"),KWr=o(" \u2014 "),xae=a("a"),eUr=o("TFBartModel"),oUr=o(" (BART model)"),rUr=l(),z0=a("li"),e9e=a("strong"),tUr=o("bert"),aUr=o(" \u2014 "),$ae=a("a"),nUr=o("TFBertModel"),sUr=o(" (BERT model)"),lUr=l(),Q0=a("li"),o9e=a("strong"),iUr=o("blenderbot"),dUr=o(" \u2014 "),kae=a("a"),mUr=o("TFBlenderbotModel"),cUr=o(" (Blenderbot model)"),fUr=l(),W0=a("li"),r9e=a("strong"),gUr=o("blenderbot-small"),hUr=o(" \u2014 "),Sae=a("a"),uUr=o("TFBlenderbotSmallModel"),pUr=o(" (BlenderbotSmall model)"),_Ur=l(),U0=a("li"),t9e=a("strong"),bUr=o("camembert"),vUr=o(" \u2014 "),Rae=a("a"),FUr=o("TFCamembertModel"),TUr=o(" (CamemBERT model)"),MUr=l(),H0=a("li"),a9e=a("strong"),EUr=o("clip"),CUr=o(" \u2014 "),Pae=a("a"),wUr=o("TFCLIPModel"),AUr=o(" (CLIP model)"),LUr=l(),J0=a("li"),n9e=a("strong"),yUr=o("convbert"),xUr=o(" \u2014 "),Bae=a("a"),$Ur=o("TFConvBertModel"),kUr=o(" (ConvBERT model)"),SUr=l(),Y0=a("li"),s9e=a("strong"),RUr=o("convnext"),PUr=o(" \u2014 "),Iae=a("a"),BUr=o("TFConvNextModel"),IUr=o(" (ConvNeXT model)"),NUr=l(),Z0=a("li"),l9e=a("strong"),qUr=o("ctrl"),jUr=o(" \u2014 "),Nae=a("a"),DUr=o("TFCTRLModel"),GUr=o(" (CTRL model)"),OUr=l(),K0=a("li"),i9e=a("strong"),VUr=o("cvt"),XUr=o(" \u2014 "),qae=a("a"),zUr=o("TFCvtModel"),QUr=o(" (CvT model)"),WUr=l(),ew=a("li"),d9e=a("strong"),UUr=o("data2vec-vision"),HUr=o(" \u2014 "),jae=a("a"),JUr=o("TFData2VecVisionModel"),YUr=o(" (Data2VecVision model)"),ZUr=l(),ow=a("li"),m9e=a("strong"),KUr=o("deberta"),eHr=o(" \u2014 "),Dae=a("a"),oHr=o("TFDebertaModel"),rHr=o(" (DeBERTa model)"),tHr=l(),rw=a("li"),c9e=a("strong"),aHr=o("deberta-v2"),nHr=o(" \u2014 "),Gae=a("a"),sHr=o("TFDebertaV2Model"),lHr=o(" (DeBERTa-v2 model)"),iHr=l(),tw=a("li"),f9e=a("strong"),dHr=o("deit"),mHr=o(" \u2014 "),Oae=a("a"),cHr=o("TFDeiTModel"),fHr=o(" (DeiT model)"),gHr=l(),aw=a("li"),g9e=a("strong"),hHr=o("distilbert"),uHr=o(" \u2014 "),Vae=a("a"),pHr=o("TFDistilBertModel"),_Hr=o(" (DistilBERT model)"),bHr=l(),nw=a("li"),h9e=a("strong"),vHr=o("dpr"),FHr=o(" \u2014 "),Xae=a("a"),THr=o("TFDPRQuestionEncoder"),MHr=o(" (DPR model)"),EHr=l(),sw=a("li"),u9e=a("strong"),CHr=o("electra"),wHr=o(" \u2014 "),zae=a("a"),AHr=o("TFElectraModel"),LHr=o(" (ELECTRA model)"),yHr=l(),lw=a("li"),p9e=a("strong"),xHr=o("esm"),$Hr=o(" \u2014 "),Qae=a("a"),kHr=o("TFEsmModel"),SHr=o(" (ESM model)"),RHr=l(),iw=a("li"),_9e=a("strong"),PHr=o("flaubert"),BHr=o(" \u2014 "),Wae=a("a"),IHr=o("TFFlaubertModel"),NHr=o(" (FlauBERT model)"),qHr=l(),Dl=a("li"),b9e=a("strong"),jHr=o("funnel"),DHr=o(" \u2014 "),Uae=a("a"),GHr=o("TFFunnelModel"),OHr=o(" or "),Hae=a("a"),VHr=o("TFFunnelBaseModel"),XHr=o(" (Funnel Transformer model)"),zHr=l(),dw=a("li"),v9e=a("strong"),QHr=o("gpt2"),WHr=o(" \u2014 "),Jae=a("a"),UHr=o("TFGPT2Model"),HHr=o(" (OpenAI GPT-2 model)"),JHr=l(),mw=a("li"),F9e=a("strong"),YHr=o("gptj"),ZHr=o(" \u2014 "),Yae=a("a"),KHr=o("TFGPTJModel"),eJr=o(" (GPT-J model)"),oJr=l(),cw=a("li"),T9e=a("strong"),rJr=o("groupvit"),tJr=o(" \u2014 "),Zae=a("a"),aJr=o("TFGroupViTModel"),nJr=o(" (GroupViT model)"),sJr=l(),fw=a("li"),M9e=a("strong"),lJr=o("hubert"),iJr=o(" \u2014 "),Kae=a("a"),dJr=o("TFHubertModel"),mJr=o(" (Hubert model)"),cJr=l(),gw=a("li"),E9e=a("strong"),fJr=o("layoutlm"),gJr=o(" \u2014 "),ene=a("a"),hJr=o("TFLayoutLMModel"),uJr=o(" (LayoutLM model)"),pJr=l(),hw=a("li"),C9e=a("strong"),_Jr=o("layoutlmv3"),bJr=o(" \u2014 "),one=a("a"),vJr=o("TFLayoutLMv3Model"),FJr=o(" (LayoutLMv3 model)"),TJr=l(),uw=a("li"),w9e=a("strong"),MJr=o("led"),EJr=o(" \u2014 "),rne=a("a"),CJr=o("TFLEDModel"),wJr=o(" (LED model)"),AJr=l(),pw=a("li"),A9e=a("strong"),LJr=o("longformer"),yJr=o(" \u2014 "),tne=a("a"),xJr=o("TFLongformerModel"),$Jr=o(" (Longformer model)"),kJr=l(),_w=a("li"),L9e=a("strong"),SJr=o("lxmert"),RJr=o(" \u2014 "),ane=a("a"),PJr=o("TFLxmertModel"),BJr=o(" (LXMERT model)"),IJr=l(),bw=a("li"),y9e=a("strong"),NJr=o("marian"),qJr=o(" \u2014 "),nne=a("a"),jJr=o("TFMarianModel"),DJr=o(" (Marian model)"),GJr=l(),vw=a("li"),x9e=a("strong"),OJr=o("mbart"),VJr=o(" \u2014 "),sne=a("a"),XJr=o("TFMBartModel"),zJr=o(" (mBART model)"),QJr=l(),Fw=a("li"),$9e=a("strong"),WJr=o("mobilebert"),UJr=o(" \u2014 "),lne=a("a"),HJr=o("TFMobileBertModel"),JJr=o(" (MobileBERT model)"),YJr=l(),Tw=a("li"),k9e=a("strong"),ZJr=o("mobilevit"),KJr=o(" \u2014 "),ine=a("a"),eYr=o("TFMobileViTModel"),oYr=o(" (MobileViT model)"),rYr=l(),Mw=a("li"),S9e=a("strong"),tYr=o("mpnet"),aYr=o(" \u2014 "),dne=a("a"),nYr=o("TFMPNetModel"),sYr=o(" (MPNet model)"),lYr=l(),Ew=a("li"),R9e=a("strong"),iYr=o("mt5"),dYr=o(" \u2014 "),mne=a("a"),mYr=o("TFMT5Model"),cYr=o(" (MT5 model)"),fYr=l(),Cw=a("li"),P9e=a("strong"),gYr=o("openai-gpt"),hYr=o(" \u2014 "),cne=a("a"),uYr=o("TFOpenAIGPTModel"),pYr=o(" (OpenAI GPT model)"),_Yr=l(),ww=a("li"),B9e=a("strong"),bYr=o("opt"),vYr=o(" \u2014 "),fne=a("a"),FYr=o("TFOPTModel"),TYr=o(" (OPT model)"),MYr=l(),Aw=a("li"),I9e=a("strong"),EYr=o("pegasus"),CYr=o(" \u2014 "),gne=a("a"),wYr=o("TFPegasusModel"),AYr=o(" (Pegasus model)"),LYr=l(),Lw=a("li"),N9e=a("strong"),yYr=o("regnet"),xYr=o(" \u2014 "),hne=a("a"),$Yr=o("TFRegNetModel"),kYr=o(" (RegNet model)"),SYr=l(),yw=a("li"),q9e=a("strong"),RYr=o("rembert"),PYr=o(" \u2014 "),une=a("a"),BYr=o("TFRemBertModel"),IYr=o(" (RemBERT model)"),NYr=l(),xw=a("li"),j9e=a("strong"),qYr=o("resnet"),jYr=o(" \u2014 "),pne=a("a"),DYr=o("TFResNetModel"),GYr=o(" (ResNet model)"),OYr=l(),$w=a("li"),D9e=a("strong"),VYr=o("roberta"),XYr=o(" \u2014 "),_ne=a("a"),zYr=o("TFRobertaModel"),QYr=o(" (RoBERTa model)"),WYr=l(),kw=a("li"),G9e=a("strong"),UYr=o("roformer"),HYr=o(" \u2014 "),bne=a("a"),JYr=o("TFRoFormerModel"),YYr=o(" (RoFormer model)"),ZYr=l(),Sw=a("li"),O9e=a("strong"),KYr=o("segformer"),eZr=o(" \u2014 "),vne=a("a"),oZr=o("TFSegformerModel"),rZr=o(" (SegFormer model)"),tZr=l(),Rw=a("li"),V9e=a("strong"),aZr=o("speech_to_text"),nZr=o(" \u2014 "),Fne=a("a"),sZr=o("TFSpeech2TextModel"),lZr=o(" (Speech2Text model)"),iZr=l(),Pw=a("li"),X9e=a("strong"),dZr=o("swin"),mZr=o(" \u2014 "),Tne=a("a"),cZr=o("TFSwinModel"),fZr=o(" (Swin Transformer model)"),gZr=l(),Bw=a("li"),z9e=a("strong"),hZr=o("t5"),uZr=o(" \u2014 "),Mne=a("a"),pZr=o("TFT5Model"),_Zr=o(" (T5 model)"),bZr=l(),Iw=a("li"),Q9e=a("strong"),vZr=o("tapas"),FZr=o(" \u2014 "),Ene=a("a"),TZr=o("TFTapasModel"),MZr=o(" (TAPAS model)"),EZr=l(),Nw=a("li"),W9e=a("strong"),CZr=o("transfo-xl"),wZr=o(" \u2014 "),Cne=a("a"),AZr=o("TFTransfoXLModel"),LZr=o(" (Transformer-XL model)"),yZr=l(),qw=a("li"),U9e=a("strong"),xZr=o("vit"),$Zr=o(" \u2014 "),wne=a("a"),kZr=o("TFViTModel"),SZr=o(" (ViT model)"),RZr=l(),jw=a("li"),H9e=a("strong"),PZr=o("vit_mae"),BZr=o(" \u2014 "),Ane=a("a"),IZr=o("TFViTMAEModel"),NZr=o(" (ViTMAE model)"),qZr=l(),Dw=a("li"),J9e=a("strong"),jZr=o("wav2vec2"),DZr=o(" \u2014 "),Lne=a("a"),GZr=o("TFWav2Vec2Model"),OZr=o(" (Wav2Vec2 model)"),VZr=l(),Gw=a("li"),Y9e=a("strong"),XZr=o("whisper"),zZr=o(" \u2014 "),yne=a("a"),QZr=o("TFWhisperModel"),WZr=o(" (Whisper model)"),UZr=l(),Ow=a("li"),Z9e=a("strong"),HZr=o("xglm"),JZr=o(" \u2014 "),xne=a("a"),YZr=o("TFXGLMModel"),ZZr=o(" (XGLM model)"),KZr=l(),Vw=a("li"),K9e=a("strong"),eKr=o("xlm"),oKr=o(" \u2014 "),$ne=a("a"),rKr=o("TFXLMModel"),tKr=o(" (XLM model)"),aKr=l(),Xw=a("li"),exe=a("strong"),nKr=o("xlm-roberta"),sKr=o(" \u2014 "),kne=a("a"),lKr=o("TFXLMRobertaModel"),iKr=o(" (XLM-RoBERTa model)"),dKr=l(),zw=a("li"),oxe=a("strong"),mKr=o("xlnet"),cKr=o(" \u2014 "),Sne=a("a"),fKr=o("TFXLNetModel"),gKr=o(" (XLNet model)"),hKr=l(),F(Qw.$$.fragment),_do=l(),Mc=a("h2"),Ww=a("a"),rxe=a("span"),F(NP.$$.fragment),uKr=l(),txe=a("span"),pKr=o("TFAutoModelForPreTraining"),bdo=l(),pr=a("div"),F(qP.$$.fragment),_Kr=l(),Ec=a("p"),bKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Rne=a("a"),vKr=o("from_pretrained()"),FKr=o(" class method or the "),Pne=a("a"),TKr=o("from_config()"),MKr=o(` class
method.`),EKr=l(),jP=a("p"),CKr=o("This class cannot be instantiated directly using "),axe=a("code"),wKr=o("__init__()"),AKr=o(" (throws an error)."),LKr=l(),ra=a("div"),F(DP.$$.fragment),yKr=l(),nxe=a("p"),xKr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),$Kr=l(),Cc=a("p"),kKr=o(`Note:
Loading a model from its configuration file does `),sxe=a("strong"),SKr=o("not"),RKr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Bne=a("a"),PKr=o("from_pretrained()"),BKr=o(" to load the model weights."),IKr=l(),F(Uw.$$.fragment),NKr=l(),Qr=a("div"),F(GP.$$.fragment),qKr=l(),lxe=a("p"),jKr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),DKr=l(),Vn=a("p"),GKr=o("The model class to instantiate is selected based on the "),ixe=a("code"),OKr=o("model_type"),VKr=o(` property of the config object (either
passed as an argument or loaded from `),dxe=a("code"),XKr=o("pretrained_model_name_or_path"),zKr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mxe=a("code"),QKr=o("pretrained_model_name_or_path"),WKr=o(":"),UKr=l(),de=a("ul"),Hw=a("li"),cxe=a("strong"),HKr=o("albert"),JKr=o(" \u2014 "),Ine=a("a"),YKr=o("TFAlbertForPreTraining"),ZKr=o(" (ALBERT model)"),KKr=l(),Jw=a("li"),fxe=a("strong"),eet=o("bart"),oet=o(" \u2014 "),Nne=a("a"),ret=o("TFBartForConditionalGeneration"),tet=o(" (BART model)"),aet=l(),Yw=a("li"),gxe=a("strong"),net=o("bert"),set=o(" \u2014 "),qne=a("a"),iet=o("TFBertForPreTraining"),det=o(" (BERT model)"),met=l(),Zw=a("li"),hxe=a("strong"),cet=o("camembert"),fet=o(" \u2014 "),jne=a("a"),get=o("TFCamembertForMaskedLM"),het=o(" (CamemBERT model)"),uet=l(),Kw=a("li"),uxe=a("strong"),pet=o("ctrl"),_et=o(" \u2014 "),Dne=a("a"),bet=o("TFCTRLLMHeadModel"),vet=o(" (CTRL model)"),Fet=l(),eA=a("li"),pxe=a("strong"),Tet=o("distilbert"),Met=o(" \u2014 "),Gne=a("a"),Eet=o("TFDistilBertForMaskedLM"),Cet=o(" (DistilBERT model)"),wet=l(),oA=a("li"),_xe=a("strong"),Aet=o("electra"),Let=o(" \u2014 "),One=a("a"),yet=o("TFElectraForPreTraining"),xet=o(" (ELECTRA model)"),$et=l(),rA=a("li"),bxe=a("strong"),ket=o("flaubert"),Set=o(" \u2014 "),Vne=a("a"),Ret=o("TFFlaubertWithLMHeadModel"),Pet=o(" (FlauBERT model)"),Bet=l(),tA=a("li"),vxe=a("strong"),Iet=o("funnel"),Net=o(" \u2014 "),Xne=a("a"),qet=o("TFFunnelForPreTraining"),jet=o(" (Funnel Transformer model)"),Det=l(),aA=a("li"),Fxe=a("strong"),Get=o("gpt2"),Oet=o(" \u2014 "),zne=a("a"),Vet=o("TFGPT2LMHeadModel"),Xet=o(" (OpenAI GPT-2 model)"),zet=l(),nA=a("li"),Txe=a("strong"),Qet=o("layoutlm"),Wet=o(" \u2014 "),Qne=a("a"),Uet=o("TFLayoutLMForMaskedLM"),Het=o(" (LayoutLM model)"),Jet=l(),sA=a("li"),Mxe=a("strong"),Yet=o("lxmert"),Zet=o(" \u2014 "),Wne=a("a"),Ket=o("TFLxmertForPreTraining"),eot=o(" (LXMERT model)"),oot=l(),lA=a("li"),Exe=a("strong"),rot=o("mobilebert"),tot=o(" \u2014 "),Une=a("a"),aot=o("TFMobileBertForPreTraining"),not=o(" (MobileBERT model)"),sot=l(),iA=a("li"),Cxe=a("strong"),lot=o("mpnet"),iot=o(" \u2014 "),Hne=a("a"),dot=o("TFMPNetForMaskedLM"),mot=o(" (MPNet model)"),cot=l(),dA=a("li"),wxe=a("strong"),fot=o("openai-gpt"),got=o(" \u2014 "),Jne=a("a"),hot=o("TFOpenAIGPTLMHeadModel"),uot=o(" (OpenAI GPT model)"),pot=l(),mA=a("li"),Axe=a("strong"),_ot=o("roberta"),bot=o(" \u2014 "),Yne=a("a"),vot=o("TFRobertaForMaskedLM"),Fot=o(" (RoBERTa model)"),Tot=l(),cA=a("li"),Lxe=a("strong"),Mot=o("t5"),Eot=o(" \u2014 "),Zne=a("a"),Cot=o("TFT5ForConditionalGeneration"),wot=o(" (T5 model)"),Aot=l(),fA=a("li"),yxe=a("strong"),Lot=o("tapas"),yot=o(" \u2014 "),Kne=a("a"),xot=o("TFTapasForMaskedLM"),$ot=o(" (TAPAS model)"),kot=l(),gA=a("li"),xxe=a("strong"),Sot=o("transfo-xl"),Rot=o(" \u2014 "),ese=a("a"),Pot=o("TFTransfoXLLMHeadModel"),Bot=o(" (Transformer-XL model)"),Iot=l(),hA=a("li"),$xe=a("strong"),Not=o("vit_mae"),qot=o(" \u2014 "),ose=a("a"),jot=o("TFViTMAEForPreTraining"),Dot=o(" (ViTMAE model)"),Got=l(),uA=a("li"),kxe=a("strong"),Oot=o("xlm"),Vot=o(" \u2014 "),rse=a("a"),Xot=o("TFXLMWithLMHeadModel"),zot=o(" (XLM model)"),Qot=l(),pA=a("li"),Sxe=a("strong"),Wot=o("xlm-roberta"),Uot=o(" \u2014 "),tse=a("a"),Hot=o("TFXLMRobertaForMaskedLM"),Jot=o(" (XLM-RoBERTa model)"),Yot=l(),_A=a("li"),Rxe=a("strong"),Zot=o("xlnet"),Kot=o(" \u2014 "),ase=a("a"),ert=o("TFXLNetLMHeadModel"),ort=o(" (XLNet model)"),rrt=l(),F(bA.$$.fragment),vdo=l(),wc=a("h2"),vA=a("a"),Pxe=a("span"),F(OP.$$.fragment),trt=l(),Bxe=a("span"),art=o("TFAutoModelForCausalLM"),Fdo=l(),_r=a("div"),F(VP.$$.fragment),nrt=l(),Ac=a("p"),srt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),nse=a("a"),lrt=o("from_pretrained()"),irt=o(" class method or the "),sse=a("a"),drt=o("from_config()"),mrt=o(` class
method.`),crt=l(),XP=a("p"),frt=o("This class cannot be instantiated directly using "),Ixe=a("code"),grt=o("__init__()"),hrt=o(" (throws an error)."),urt=l(),ta=a("div"),F(zP.$$.fragment),prt=l(),Nxe=a("p"),_rt=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),brt=l(),Lc=a("p"),vrt=o(`Note:
Loading a model from its configuration file does `),qxe=a("strong"),Frt=o("not"),Trt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lse=a("a"),Mrt=o("from_pretrained()"),Ert=o(" to load the model weights."),Crt=l(),F(FA.$$.fragment),wrt=l(),Wr=a("div"),F(QP.$$.fragment),Art=l(),jxe=a("p"),Lrt=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),yrt=l(),Xn=a("p"),xrt=o("The model class to instantiate is selected based on the "),Dxe=a("code"),$rt=o("model_type"),krt=o(` property of the config object (either
passed as an argument or loaded from `),Gxe=a("code"),Srt=o("pretrained_model_name_or_path"),Rrt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Oxe=a("code"),Prt=o("pretrained_model_name_or_path"),Brt=o(":"),Irt=l(),Ce=a("ul"),TA=a("li"),Vxe=a("strong"),Nrt=o("bert"),qrt=o(" \u2014 "),ise=a("a"),jrt=o("TFBertLMHeadModel"),Drt=o(" (BERT model)"),Grt=l(),MA=a("li"),Xxe=a("strong"),Ort=o("camembert"),Vrt=o(" \u2014 "),dse=a("a"),Xrt=o("TFCamembertForCausalLM"),zrt=o(" (CamemBERT model)"),Qrt=l(),EA=a("li"),zxe=a("strong"),Wrt=o("ctrl"),Urt=o(" \u2014 "),mse=a("a"),Hrt=o("TFCTRLLMHeadModel"),Jrt=o(" (CTRL model)"),Yrt=l(),CA=a("li"),Qxe=a("strong"),Zrt=o("gpt2"),Krt=o(" \u2014 "),cse=a("a"),ett=o("TFGPT2LMHeadModel"),ott=o(" (OpenAI GPT-2 model)"),rtt=l(),wA=a("li"),Wxe=a("strong"),ttt=o("gptj"),att=o(" \u2014 "),fse=a("a"),ntt=o("TFGPTJForCausalLM"),stt=o(" (GPT-J model)"),ltt=l(),AA=a("li"),Uxe=a("strong"),itt=o("openai-gpt"),dtt=o(" \u2014 "),gse=a("a"),mtt=o("TFOpenAIGPTLMHeadModel"),ctt=o(" (OpenAI GPT model)"),ftt=l(),LA=a("li"),Hxe=a("strong"),gtt=o("opt"),htt=o(" \u2014 "),hse=a("a"),utt=o("TFOPTForCausalLM"),ptt=o(" (OPT model)"),_tt=l(),yA=a("li"),Jxe=a("strong"),btt=o("rembert"),vtt=o(" \u2014 "),use=a("a"),Ftt=o("TFRemBertForCausalLM"),Ttt=o(" (RemBERT model)"),Mtt=l(),xA=a("li"),Yxe=a("strong"),Ett=o("roberta"),Ctt=o(" \u2014 "),pse=a("a"),wtt=o("TFRobertaForCausalLM"),Att=o(" (RoBERTa model)"),Ltt=l(),$A=a("li"),Zxe=a("strong"),ytt=o("roformer"),xtt=o(" \u2014 "),_se=a("a"),$tt=o("TFRoFormerForCausalLM"),ktt=o(" (RoFormer model)"),Stt=l(),kA=a("li"),Kxe=a("strong"),Rtt=o("transfo-xl"),Ptt=o(" \u2014 "),bse=a("a"),Btt=o("TFTransfoXLLMHeadModel"),Itt=o(" (Transformer-XL model)"),Ntt=l(),SA=a("li"),e$e=a("strong"),qtt=o("xglm"),jtt=o(" \u2014 "),vse=a("a"),Dtt=o("TFXGLMForCausalLM"),Gtt=o(" (XGLM model)"),Ott=l(),RA=a("li"),o$e=a("strong"),Vtt=o("xlm"),Xtt=o(" \u2014 "),Fse=a("a"),ztt=o("TFXLMWithLMHeadModel"),Qtt=o(" (XLM model)"),Wtt=l(),PA=a("li"),r$e=a("strong"),Utt=o("xlnet"),Htt=o(" \u2014 "),Tse=a("a"),Jtt=o("TFXLNetLMHeadModel"),Ytt=o(" (XLNet model)"),Ztt=l(),F(BA.$$.fragment),Tdo=l(),yc=a("h2"),IA=a("a"),t$e=a("span"),F(WP.$$.fragment),Ktt=l(),a$e=a("span"),eat=o("TFAutoModelForImageClassification"),Mdo=l(),br=a("div"),F(UP.$$.fragment),oat=l(),xc=a("p"),rat=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Mse=a("a"),tat=o("from_pretrained()"),aat=o(" class method or the "),Ese=a("a"),nat=o("from_config()"),sat=o(` class
method.`),lat=l(),HP=a("p"),iat=o("This class cannot be instantiated directly using "),n$e=a("code"),dat=o("__init__()"),mat=o(" (throws an error)."),cat=l(),aa=a("div"),F(JP.$$.fragment),fat=l(),s$e=a("p"),gat=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),hat=l(),$c=a("p"),uat=o(`Note:
Loading a model from its configuration file does `),l$e=a("strong"),pat=o("not"),_at=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cse=a("a"),bat=o("from_pretrained()"),vat=o(" to load the model weights."),Fat=l(),F(NA.$$.fragment),Tat=l(),Ur=a("div"),F(YP.$$.fragment),Mat=l(),i$e=a("p"),Eat=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Cat=l(),zn=a("p"),wat=o("The model class to instantiate is selected based on the "),d$e=a("code"),Aat=o("model_type"),Lat=o(` property of the config object (either
passed as an argument or loaded from `),m$e=a("code"),yat=o("pretrained_model_name_or_path"),xat=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c$e=a("code"),$at=o("pretrained_model_name_or_path"),kat=o(":"),Sat=l(),$e=a("ul"),qA=a("li"),f$e=a("strong"),Rat=o("convnext"),Pat=o(" \u2014 "),wse=a("a"),Bat=o("TFConvNextForImageClassification"),Iat=o(" (ConvNeXT model)"),Nat=l(),jA=a("li"),g$e=a("strong"),qat=o("cvt"),jat=o(" \u2014 "),Ase=a("a"),Dat=o("TFCvtForImageClassification"),Gat=o(" (CvT model)"),Oat=l(),DA=a("li"),h$e=a("strong"),Vat=o("data2vec-vision"),Xat=o(" \u2014 "),Lse=a("a"),zat=o("TFData2VecVisionForImageClassification"),Qat=o(" (Data2VecVision model)"),Wat=l(),Gl=a("li"),u$e=a("strong"),Uat=o("deit"),Hat=o(" \u2014 "),yse=a("a"),Jat=o("TFDeiTForImageClassification"),Yat=o(" or "),xse=a("a"),Zat=o("TFDeiTForImageClassificationWithTeacher"),Kat=o(" (DeiT model)"),ent=l(),GA=a("li"),p$e=a("strong"),ont=o("mobilevit"),rnt=o(" \u2014 "),$se=a("a"),tnt=o("TFMobileViTForImageClassification"),ant=o(" (MobileViT model)"),nnt=l(),OA=a("li"),_$e=a("strong"),snt=o("regnet"),lnt=o(" \u2014 "),kse=a("a"),int=o("TFRegNetForImageClassification"),dnt=o(" (RegNet model)"),mnt=l(),VA=a("li"),b$e=a("strong"),cnt=o("resnet"),fnt=o(" \u2014 "),Sse=a("a"),gnt=o("TFResNetForImageClassification"),hnt=o(" (ResNet model)"),unt=l(),XA=a("li"),v$e=a("strong"),pnt=o("segformer"),_nt=o(" \u2014 "),Rse=a("a"),bnt=o("TFSegformerForImageClassification"),vnt=o(" (SegFormer model)"),Fnt=l(),zA=a("li"),F$e=a("strong"),Tnt=o("swin"),Mnt=o(" \u2014 "),Pse=a("a"),Ent=o("TFSwinForImageClassification"),Cnt=o(" (Swin Transformer model)"),wnt=l(),QA=a("li"),T$e=a("strong"),Ant=o("vit"),Lnt=o(" \u2014 "),Bse=a("a"),ynt=o("TFViTForImageClassification"),xnt=o(" (ViT model)"),$nt=l(),F(WA.$$.fragment),Edo=l(),kc=a("h2"),UA=a("a"),M$e=a("span"),F(ZP.$$.fragment),knt=l(),E$e=a("span"),Snt=o("TFAutoModelForSemanticSegmentation"),Cdo=l(),vr=a("div"),F(KP.$$.fragment),Rnt=l(),Sc=a("p"),Pnt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Ise=a("a"),Bnt=o("from_pretrained()"),Int=o(" class method or the "),Nse=a("a"),Nnt=o("from_config()"),qnt=o(` class
method.`),jnt=l(),eB=a("p"),Dnt=o("This class cannot be instantiated directly using "),C$e=a("code"),Gnt=o("__init__()"),Ont=o(" (throws an error)."),Vnt=l(),na=a("div"),F(oB.$$.fragment),Xnt=l(),w$e=a("p"),znt=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Qnt=l(),Rc=a("p"),Wnt=o(`Note:
Loading a model from its configuration file does `),A$e=a("strong"),Unt=o("not"),Hnt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qse=a("a"),Jnt=o("from_pretrained()"),Ynt=o(" to load the model weights."),Znt=l(),F(HA.$$.fragment),Knt=l(),Hr=a("div"),F(rB.$$.fragment),est=l(),L$e=a("p"),ost=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),rst=l(),Qn=a("p"),tst=o("The model class to instantiate is selected based on the "),y$e=a("code"),ast=o("model_type"),nst=o(` property of the config object (either
passed as an argument or loaded from `),x$e=a("code"),sst=o("pretrained_model_name_or_path"),lst=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$$e=a("code"),ist=o("pretrained_model_name_or_path"),dst=o(":"),mst=l(),Pc=a("ul"),JA=a("li"),k$e=a("strong"),cst=o("data2vec-vision"),fst=o(" \u2014 "),jse=a("a"),gst=o("TFData2VecVisionForSemanticSegmentation"),hst=o(" (Data2VecVision model)"),ust=l(),YA=a("li"),S$e=a("strong"),pst=o("mobilevit"),_st=o(" \u2014 "),Dse=a("a"),bst=o("TFMobileViTForSemanticSegmentation"),vst=o(" (MobileViT model)"),Fst=l(),ZA=a("li"),R$e=a("strong"),Tst=o("segformer"),Mst=o(" \u2014 "),Gse=a("a"),Est=o("TFSegformerForSemanticSegmentation"),Cst=o(" (SegFormer model)"),wst=l(),F(KA.$$.fragment),wdo=l(),Bc=a("h2"),e6=a("a"),P$e=a("span"),F(tB.$$.fragment),Ast=l(),B$e=a("span"),Lst=o("TFAutoModelForMaskedLM"),Ado=l(),Fr=a("div"),F(aB.$$.fragment),yst=l(),Ic=a("p"),xst=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Ose=a("a"),$st=o("from_pretrained()"),kst=o(" class method or the "),Vse=a("a"),Sst=o("from_config()"),Rst=o(` class
method.`),Pst=l(),nB=a("p"),Bst=o("This class cannot be instantiated directly using "),I$e=a("code"),Ist=o("__init__()"),Nst=o(" (throws an error)."),qst=l(),sa=a("div"),F(sB.$$.fragment),jst=l(),N$e=a("p"),Dst=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Gst=l(),Nc=a("p"),Ost=o(`Note:
Loading a model from its configuration file does `),q$e=a("strong"),Vst=o("not"),Xst=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Xse=a("a"),zst=o("from_pretrained()"),Qst=o(" to load the model weights."),Wst=l(),F(o6.$$.fragment),Ust=l(),Jr=a("div"),F(lB.$$.fragment),Hst=l(),j$e=a("p"),Jst=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Yst=l(),Wn=a("p"),Zst=o("The model class to instantiate is selected based on the "),D$e=a("code"),Kst=o("model_type"),elt=o(` property of the config object (either
passed as an argument or loaded from `),G$e=a("code"),olt=o("pretrained_model_name_or_path"),rlt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O$e=a("code"),tlt=o("pretrained_model_name_or_path"),alt=o(":"),nlt=l(),ge=a("ul"),r6=a("li"),V$e=a("strong"),slt=o("albert"),llt=o(" \u2014 "),zse=a("a"),ilt=o("TFAlbertForMaskedLM"),dlt=o(" (ALBERT model)"),mlt=l(),t6=a("li"),X$e=a("strong"),clt=o("bert"),flt=o(" \u2014 "),Qse=a("a"),glt=o("TFBertForMaskedLM"),hlt=o(" (BERT model)"),ult=l(),a6=a("li"),z$e=a("strong"),plt=o("camembert"),_lt=o(" \u2014 "),Wse=a("a"),blt=o("TFCamembertForMaskedLM"),vlt=o(" (CamemBERT model)"),Flt=l(),n6=a("li"),Q$e=a("strong"),Tlt=o("convbert"),Mlt=o(" \u2014 "),Use=a("a"),Elt=o("TFConvBertForMaskedLM"),Clt=o(" (ConvBERT model)"),wlt=l(),s6=a("li"),W$e=a("strong"),Alt=o("deberta"),Llt=o(" \u2014 "),Hse=a("a"),ylt=o("TFDebertaForMaskedLM"),xlt=o(" (DeBERTa model)"),$lt=l(),l6=a("li"),U$e=a("strong"),klt=o("deberta-v2"),Slt=o(" \u2014 "),Jse=a("a"),Rlt=o("TFDebertaV2ForMaskedLM"),Plt=o(" (DeBERTa-v2 model)"),Blt=l(),i6=a("li"),H$e=a("strong"),Ilt=o("distilbert"),Nlt=o(" \u2014 "),Yse=a("a"),qlt=o("TFDistilBertForMaskedLM"),jlt=o(" (DistilBERT model)"),Dlt=l(),d6=a("li"),J$e=a("strong"),Glt=o("electra"),Olt=o(" \u2014 "),Zse=a("a"),Vlt=o("TFElectraForMaskedLM"),Xlt=o(" (ELECTRA model)"),zlt=l(),m6=a("li"),Y$e=a("strong"),Qlt=o("esm"),Wlt=o(" \u2014 "),Kse=a("a"),Ult=o("TFEsmForMaskedLM"),Hlt=o(" (ESM model)"),Jlt=l(),c6=a("li"),Z$e=a("strong"),Ylt=o("flaubert"),Zlt=o(" \u2014 "),ele=a("a"),Klt=o("TFFlaubertWithLMHeadModel"),eit=o(" (FlauBERT model)"),oit=l(),f6=a("li"),K$e=a("strong"),rit=o("funnel"),tit=o(" \u2014 "),ole=a("a"),ait=o("TFFunnelForMaskedLM"),nit=o(" (Funnel Transformer model)"),sit=l(),g6=a("li"),eke=a("strong"),lit=o("layoutlm"),iit=o(" \u2014 "),rle=a("a"),dit=o("TFLayoutLMForMaskedLM"),mit=o(" (LayoutLM model)"),cit=l(),h6=a("li"),oke=a("strong"),fit=o("longformer"),git=o(" \u2014 "),tle=a("a"),hit=o("TFLongformerForMaskedLM"),uit=o(" (Longformer model)"),pit=l(),u6=a("li"),rke=a("strong"),_it=o("mobilebert"),bit=o(" \u2014 "),ale=a("a"),vit=o("TFMobileBertForMaskedLM"),Fit=o(" (MobileBERT model)"),Tit=l(),p6=a("li"),tke=a("strong"),Mit=o("mpnet"),Eit=o(" \u2014 "),nle=a("a"),Cit=o("TFMPNetForMaskedLM"),wit=o(" (MPNet model)"),Ait=l(),_6=a("li"),ake=a("strong"),Lit=o("rembert"),yit=o(" \u2014 "),sle=a("a"),xit=o("TFRemBertForMaskedLM"),$it=o(" (RemBERT model)"),kit=l(),b6=a("li"),nke=a("strong"),Sit=o("roberta"),Rit=o(" \u2014 "),lle=a("a"),Pit=o("TFRobertaForMaskedLM"),Bit=o(" (RoBERTa model)"),Iit=l(),v6=a("li"),ske=a("strong"),Nit=o("roformer"),qit=o(" \u2014 "),ile=a("a"),jit=o("TFRoFormerForMaskedLM"),Dit=o(" (RoFormer model)"),Git=l(),F6=a("li"),lke=a("strong"),Oit=o("tapas"),Vit=o(" \u2014 "),dle=a("a"),Xit=o("TFTapasForMaskedLM"),zit=o(" (TAPAS model)"),Qit=l(),T6=a("li"),ike=a("strong"),Wit=o("xlm"),Uit=o(" \u2014 "),mle=a("a"),Hit=o("TFXLMWithLMHeadModel"),Jit=o(" (XLM model)"),Yit=l(),M6=a("li"),dke=a("strong"),Zit=o("xlm-roberta"),Kit=o(" \u2014 "),cle=a("a"),edt=o("TFXLMRobertaForMaskedLM"),odt=o(" (XLM-RoBERTa model)"),rdt=l(),F(E6.$$.fragment),Ldo=l(),qc=a("h2"),C6=a("a"),mke=a("span"),F(iB.$$.fragment),tdt=l(),cke=a("span"),adt=o("TFAutoModelForSeq2SeqLM"),ydo=l(),Tr=a("div"),F(dB.$$.fragment),ndt=l(),jc=a("p"),sdt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),fle=a("a"),ldt=o("from_pretrained()"),idt=o(" class method or the "),gle=a("a"),ddt=o("from_config()"),mdt=o(` class
method.`),cdt=l(),mB=a("p"),fdt=o("This class cannot be instantiated directly using "),fke=a("code"),gdt=o("__init__()"),hdt=o(" (throws an error)."),udt=l(),la=a("div"),F(cB.$$.fragment),pdt=l(),gke=a("p"),_dt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),bdt=l(),Dc=a("p"),vdt=o(`Note:
Loading a model from its configuration file does `),hke=a("strong"),Fdt=o("not"),Tdt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hle=a("a"),Mdt=o("from_pretrained()"),Edt=o(" to load the model weights."),Cdt=l(),F(w6.$$.fragment),wdt=l(),Yr=a("div"),F(fB.$$.fragment),Adt=l(),uke=a("p"),Ldt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),ydt=l(),Un=a("p"),xdt=o("The model class to instantiate is selected based on the "),pke=a("code"),$dt=o("model_type"),kdt=o(` property of the config object (either
passed as an argument or loaded from `),_ke=a("code"),Sdt=o("pretrained_model_name_or_path"),Rdt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bke=a("code"),Pdt=o("pretrained_model_name_or_path"),Bdt=o(":"),Idt=l(),ke=a("ul"),A6=a("li"),vke=a("strong"),Ndt=o("bart"),qdt=o(" \u2014 "),ule=a("a"),jdt=o("TFBartForConditionalGeneration"),Ddt=o(" (BART model)"),Gdt=l(),L6=a("li"),Fke=a("strong"),Odt=o("blenderbot"),Vdt=o(" \u2014 "),ple=a("a"),Xdt=o("TFBlenderbotForConditionalGeneration"),zdt=o(" (Blenderbot model)"),Qdt=l(),y6=a("li"),Tke=a("strong"),Wdt=o("blenderbot-small"),Udt=o(" \u2014 "),_le=a("a"),Hdt=o("TFBlenderbotSmallForConditionalGeneration"),Jdt=o(" (BlenderbotSmall model)"),Ydt=l(),x6=a("li"),Mke=a("strong"),Zdt=o("encoder-decoder"),Kdt=o(" \u2014 "),ble=a("a"),emt=o("TFEncoderDecoderModel"),omt=o(" (Encoder decoder model)"),rmt=l(),$6=a("li"),Eke=a("strong"),tmt=o("led"),amt=o(" \u2014 "),vle=a("a"),nmt=o("TFLEDForConditionalGeneration"),smt=o(" (LED model)"),lmt=l(),k6=a("li"),Cke=a("strong"),imt=o("marian"),dmt=o(" \u2014 "),Fle=a("a"),mmt=o("TFMarianMTModel"),cmt=o(" (Marian model)"),fmt=l(),S6=a("li"),wke=a("strong"),gmt=o("mbart"),hmt=o(" \u2014 "),Tle=a("a"),umt=o("TFMBartForConditionalGeneration"),pmt=o(" (mBART model)"),_mt=l(),R6=a("li"),Ake=a("strong"),bmt=o("mt5"),vmt=o(" \u2014 "),Mle=a("a"),Fmt=o("TFMT5ForConditionalGeneration"),Tmt=o(" (MT5 model)"),Mmt=l(),P6=a("li"),Lke=a("strong"),Emt=o("pegasus"),Cmt=o(" \u2014 "),Ele=a("a"),wmt=o("TFPegasusForConditionalGeneration"),Amt=o(" (Pegasus model)"),Lmt=l(),B6=a("li"),yke=a("strong"),ymt=o("t5"),xmt=o(" \u2014 "),Cle=a("a"),$mt=o("TFT5ForConditionalGeneration"),kmt=o(" (T5 model)"),Smt=l(),F(I6.$$.fragment),xdo=l(),Gc=a("h2"),N6=a("a"),xke=a("span"),F(gB.$$.fragment),Rmt=l(),$ke=a("span"),Pmt=o("TFAutoModelForSequenceClassification"),$do=l(),Mr=a("div"),F(hB.$$.fragment),Bmt=l(),Oc=a("p"),Imt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),wle=a("a"),Nmt=o("from_pretrained()"),qmt=o(" class method or the "),Ale=a("a"),jmt=o("from_config()"),Dmt=o(` class
method.`),Gmt=l(),uB=a("p"),Omt=o("This class cannot be instantiated directly using "),kke=a("code"),Vmt=o("__init__()"),Xmt=o(" (throws an error)."),zmt=l(),ia=a("div"),F(pB.$$.fragment),Qmt=l(),Ske=a("p"),Wmt=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Umt=l(),Vc=a("p"),Hmt=o(`Note:
Loading a model from its configuration file does `),Rke=a("strong"),Jmt=o("not"),Ymt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Lle=a("a"),Zmt=o("from_pretrained()"),Kmt=o(" to load the model weights."),ect=l(),F(q6.$$.fragment),oct=l(),Zr=a("div"),F(_B.$$.fragment),rct=l(),Pke=a("p"),tct=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),act=l(),Hn=a("p"),nct=o("The model class to instantiate is selected based on the "),Bke=a("code"),sct=o("model_type"),lct=o(` property of the config object (either
passed as an argument or loaded from `),Ike=a("code"),ict=o("pretrained_model_name_or_path"),dct=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nke=a("code"),mct=o("pretrained_model_name_or_path"),cct=o(":"),fct=l(),ae=a("ul"),j6=a("li"),qke=a("strong"),gct=o("albert"),hct=o(" \u2014 "),yle=a("a"),uct=o("TFAlbertForSequenceClassification"),pct=o(" (ALBERT model)"),_ct=l(),D6=a("li"),jke=a("strong"),bct=o("bert"),vct=o(" \u2014 "),xle=a("a"),Fct=o("TFBertForSequenceClassification"),Tct=o(" (BERT model)"),Mct=l(),G6=a("li"),Dke=a("strong"),Ect=o("camembert"),Cct=o(" \u2014 "),$le=a("a"),wct=o("TFCamembertForSequenceClassification"),Act=o(" (CamemBERT model)"),Lct=l(),O6=a("li"),Gke=a("strong"),yct=o("convbert"),xct=o(" \u2014 "),kle=a("a"),$ct=o("TFConvBertForSequenceClassification"),kct=o(" (ConvBERT model)"),Sct=l(),V6=a("li"),Oke=a("strong"),Rct=o("ctrl"),Pct=o(" \u2014 "),Sle=a("a"),Bct=o("TFCTRLForSequenceClassification"),Ict=o(" (CTRL model)"),Nct=l(),X6=a("li"),Vke=a("strong"),qct=o("deberta"),jct=o(" \u2014 "),Rle=a("a"),Dct=o("TFDebertaForSequenceClassification"),Gct=o(" (DeBERTa model)"),Oct=l(),z6=a("li"),Xke=a("strong"),Vct=o("deberta-v2"),Xct=o(" \u2014 "),Ple=a("a"),zct=o("TFDebertaV2ForSequenceClassification"),Qct=o(" (DeBERTa-v2 model)"),Wct=l(),Q6=a("li"),zke=a("strong"),Uct=o("distilbert"),Hct=o(" \u2014 "),Ble=a("a"),Jct=o("TFDistilBertForSequenceClassification"),Yct=o(" (DistilBERT model)"),Zct=l(),W6=a("li"),Qke=a("strong"),Kct=o("electra"),eft=o(" \u2014 "),Ile=a("a"),oft=o("TFElectraForSequenceClassification"),rft=o(" (ELECTRA model)"),tft=l(),U6=a("li"),Wke=a("strong"),aft=o("esm"),nft=o(" \u2014 "),Nle=a("a"),sft=o("TFEsmForSequenceClassification"),lft=o(" (ESM model)"),ift=l(),H6=a("li"),Uke=a("strong"),dft=o("flaubert"),mft=o(" \u2014 "),qle=a("a"),cft=o("TFFlaubertForSequenceClassification"),fft=o(" (FlauBERT model)"),gft=l(),J6=a("li"),Hke=a("strong"),hft=o("funnel"),uft=o(" \u2014 "),jle=a("a"),pft=o("TFFunnelForSequenceClassification"),_ft=o(" (Funnel Transformer model)"),bft=l(),Y6=a("li"),Jke=a("strong"),vft=o("gpt2"),Fft=o(" \u2014 "),Dle=a("a"),Tft=o("TFGPT2ForSequenceClassification"),Mft=o(" (OpenAI GPT-2 model)"),Eft=l(),Z6=a("li"),Yke=a("strong"),Cft=o("gptj"),wft=o(" \u2014 "),Gle=a("a"),Aft=o("TFGPTJForSequenceClassification"),Lft=o(" (GPT-J model)"),yft=l(),K6=a("li"),Zke=a("strong"),xft=o("layoutlm"),$ft=o(" \u2014 "),Ole=a("a"),kft=o("TFLayoutLMForSequenceClassification"),Sft=o(" (LayoutLM model)"),Rft=l(),e7=a("li"),Kke=a("strong"),Pft=o("layoutlmv3"),Bft=o(" \u2014 "),Vle=a("a"),Ift=o("TFLayoutLMv3ForSequenceClassification"),Nft=o(" (LayoutLMv3 model)"),qft=l(),o7=a("li"),eSe=a("strong"),jft=o("longformer"),Dft=o(" \u2014 "),Xle=a("a"),Gft=o("TFLongformerForSequenceClassification"),Oft=o(" (Longformer model)"),Vft=l(),r7=a("li"),oSe=a("strong"),Xft=o("mobilebert"),zft=o(" \u2014 "),zle=a("a"),Qft=o("TFMobileBertForSequenceClassification"),Wft=o(" (MobileBERT model)"),Uft=l(),t7=a("li"),rSe=a("strong"),Hft=o("mpnet"),Jft=o(" \u2014 "),Qle=a("a"),Yft=o("TFMPNetForSequenceClassification"),Zft=o(" (MPNet model)"),Kft=l(),a7=a("li"),tSe=a("strong"),egt=o("openai-gpt"),ogt=o(" \u2014 "),Wle=a("a"),rgt=o("TFOpenAIGPTForSequenceClassification"),tgt=o(" (OpenAI GPT model)"),agt=l(),n7=a("li"),aSe=a("strong"),ngt=o("rembert"),sgt=o(" \u2014 "),Ule=a("a"),lgt=o("TFRemBertForSequenceClassification"),igt=o(" (RemBERT model)"),dgt=l(),s7=a("li"),nSe=a("strong"),mgt=o("roberta"),cgt=o(" \u2014 "),Hle=a("a"),fgt=o("TFRobertaForSequenceClassification"),ggt=o(" (RoBERTa model)"),hgt=l(),l7=a("li"),sSe=a("strong"),ugt=o("roformer"),pgt=o(" \u2014 "),Jle=a("a"),_gt=o("TFRoFormerForSequenceClassification"),bgt=o(" (RoFormer model)"),vgt=l(),i7=a("li"),lSe=a("strong"),Fgt=o("tapas"),Tgt=o(" \u2014 "),Yle=a("a"),Mgt=o("TFTapasForSequenceClassification"),Egt=o(" (TAPAS model)"),Cgt=l(),d7=a("li"),iSe=a("strong"),wgt=o("transfo-xl"),Agt=o(" \u2014 "),Zle=a("a"),Lgt=o("TFTransfoXLForSequenceClassification"),ygt=o(" (Transformer-XL model)"),xgt=l(),m7=a("li"),dSe=a("strong"),$gt=o("xlm"),kgt=o(" \u2014 "),Kle=a("a"),Sgt=o("TFXLMForSequenceClassification"),Rgt=o(" (XLM model)"),Pgt=l(),c7=a("li"),mSe=a("strong"),Bgt=o("xlm-roberta"),Igt=o(" \u2014 "),eie=a("a"),Ngt=o("TFXLMRobertaForSequenceClassification"),qgt=o(" (XLM-RoBERTa model)"),jgt=l(),f7=a("li"),cSe=a("strong"),Dgt=o("xlnet"),Ggt=o(" \u2014 "),oie=a("a"),Ogt=o("TFXLNetForSequenceClassification"),Vgt=o(" (XLNet model)"),Xgt=l(),F(g7.$$.fragment),kdo=l(),Xc=a("h2"),h7=a("a"),fSe=a("span"),F(bB.$$.fragment),zgt=l(),gSe=a("span"),Qgt=o("TFAutoModelForMultipleChoice"),Sdo=l(),Er=a("div"),F(vB.$$.fragment),Wgt=l(),zc=a("p"),Ugt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),rie=a("a"),Hgt=o("from_pretrained()"),Jgt=o(" class method or the "),tie=a("a"),Ygt=o("from_config()"),Zgt=o(` class
method.`),Kgt=l(),FB=a("p"),eht=o("This class cannot be instantiated directly using "),hSe=a("code"),oht=o("__init__()"),rht=o(" (throws an error)."),tht=l(),da=a("div"),F(TB.$$.fragment),aht=l(),uSe=a("p"),nht=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),sht=l(),Qc=a("p"),lht=o(`Note:
Loading a model from its configuration file does `),pSe=a("strong"),iht=o("not"),dht=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aie=a("a"),mht=o("from_pretrained()"),cht=o(" to load the model weights."),fht=l(),F(u7.$$.fragment),ght=l(),Kr=a("div"),F(MB.$$.fragment),hht=l(),_Se=a("p"),uht=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),pht=l(),Jn=a("p"),_ht=o("The model class to instantiate is selected based on the "),bSe=a("code"),bht=o("model_type"),vht=o(` property of the config object (either
passed as an argument or loaded from `),vSe=a("code"),Fht=o("pretrained_model_name_or_path"),Tht=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FSe=a("code"),Mht=o("pretrained_model_name_or_path"),Eht=o(":"),Cht=l(),Me=a("ul"),p7=a("li"),TSe=a("strong"),wht=o("albert"),Aht=o(" \u2014 "),nie=a("a"),Lht=o("TFAlbertForMultipleChoice"),yht=o(" (ALBERT model)"),xht=l(),_7=a("li"),MSe=a("strong"),$ht=o("bert"),kht=o(" \u2014 "),sie=a("a"),Sht=o("TFBertForMultipleChoice"),Rht=o(" (BERT model)"),Pht=l(),b7=a("li"),ESe=a("strong"),Bht=o("camembert"),Iht=o(" \u2014 "),lie=a("a"),Nht=o("TFCamembertForMultipleChoice"),qht=o(" (CamemBERT model)"),jht=l(),v7=a("li"),CSe=a("strong"),Dht=o("convbert"),Ght=o(" \u2014 "),iie=a("a"),Oht=o("TFConvBertForMultipleChoice"),Vht=o(" (ConvBERT model)"),Xht=l(),F7=a("li"),wSe=a("strong"),zht=o("distilbert"),Qht=o(" \u2014 "),die=a("a"),Wht=o("TFDistilBertForMultipleChoice"),Uht=o(" (DistilBERT model)"),Hht=l(),T7=a("li"),ASe=a("strong"),Jht=o("electra"),Yht=o(" \u2014 "),mie=a("a"),Zht=o("TFElectraForMultipleChoice"),Kht=o(" (ELECTRA model)"),eut=l(),M7=a("li"),LSe=a("strong"),out=o("flaubert"),rut=o(" \u2014 "),cie=a("a"),tut=o("TFFlaubertForMultipleChoice"),aut=o(" (FlauBERT model)"),nut=l(),E7=a("li"),ySe=a("strong"),sut=o("funnel"),lut=o(" \u2014 "),fie=a("a"),iut=o("TFFunnelForMultipleChoice"),dut=o(" (Funnel Transformer model)"),mut=l(),C7=a("li"),xSe=a("strong"),cut=o("longformer"),fut=o(" \u2014 "),gie=a("a"),gut=o("TFLongformerForMultipleChoice"),hut=o(" (Longformer model)"),uut=l(),w7=a("li"),$Se=a("strong"),put=o("mobilebert"),_ut=o(" \u2014 "),hie=a("a"),but=o("TFMobileBertForMultipleChoice"),vut=o(" (MobileBERT model)"),Fut=l(),A7=a("li"),kSe=a("strong"),Tut=o("mpnet"),Mut=o(" \u2014 "),uie=a("a"),Eut=o("TFMPNetForMultipleChoice"),Cut=o(" (MPNet model)"),wut=l(),L7=a("li"),SSe=a("strong"),Aut=o("rembert"),Lut=o(" \u2014 "),pie=a("a"),yut=o("TFRemBertForMultipleChoice"),xut=o(" (RemBERT model)"),$ut=l(),y7=a("li"),RSe=a("strong"),kut=o("roberta"),Sut=o(" \u2014 "),_ie=a("a"),Rut=o("TFRobertaForMultipleChoice"),Put=o(" (RoBERTa model)"),But=l(),x7=a("li"),PSe=a("strong"),Iut=o("roformer"),Nut=o(" \u2014 "),bie=a("a"),qut=o("TFRoFormerForMultipleChoice"),jut=o(" (RoFormer model)"),Dut=l(),$7=a("li"),BSe=a("strong"),Gut=o("xlm"),Out=o(" \u2014 "),vie=a("a"),Vut=o("TFXLMForMultipleChoice"),Xut=o(" (XLM model)"),zut=l(),k7=a("li"),ISe=a("strong"),Qut=o("xlm-roberta"),Wut=o(" \u2014 "),Fie=a("a"),Uut=o("TFXLMRobertaForMultipleChoice"),Hut=o(" (XLM-RoBERTa model)"),Jut=l(),S7=a("li"),NSe=a("strong"),Yut=o("xlnet"),Zut=o(" \u2014 "),Tie=a("a"),Kut=o("TFXLNetForMultipleChoice"),ept=o(" (XLNet model)"),opt=l(),F(R7.$$.fragment),Rdo=l(),Wc=a("h2"),P7=a("a"),qSe=a("span"),F(EB.$$.fragment),rpt=l(),jSe=a("span"),tpt=o("TFAutoModelForNextSentencePrediction"),Pdo=l(),Cr=a("div"),F(CB.$$.fragment),apt=l(),Uc=a("p"),npt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Mie=a("a"),spt=o("from_pretrained()"),lpt=o(" class method or the "),Eie=a("a"),ipt=o("from_config()"),dpt=o(` class
method.`),mpt=l(),wB=a("p"),cpt=o("This class cannot be instantiated directly using "),DSe=a("code"),fpt=o("__init__()"),gpt=o(" (throws an error)."),hpt=l(),ma=a("div"),F(AB.$$.fragment),upt=l(),GSe=a("p"),ppt=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),_pt=l(),Hc=a("p"),bpt=o(`Note:
Loading a model from its configuration file does `),OSe=a("strong"),vpt=o("not"),Fpt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Cie=a("a"),Tpt=o("from_pretrained()"),Mpt=o(" to load the model weights."),Ept=l(),F(B7.$$.fragment),Cpt=l(),et=a("div"),F(LB.$$.fragment),wpt=l(),VSe=a("p"),Apt=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Lpt=l(),Yn=a("p"),ypt=o("The model class to instantiate is selected based on the "),XSe=a("code"),xpt=o("model_type"),$pt=o(` property of the config object (either
passed as an argument or loaded from `),zSe=a("code"),kpt=o("pretrained_model_name_or_path"),Spt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QSe=a("code"),Rpt=o("pretrained_model_name_or_path"),Ppt=o(":"),Bpt=l(),yB=a("ul"),I7=a("li"),WSe=a("strong"),Ipt=o("bert"),Npt=o(" \u2014 "),wie=a("a"),qpt=o("TFBertForNextSentencePrediction"),jpt=o(" (BERT model)"),Dpt=l(),N7=a("li"),USe=a("strong"),Gpt=o("mobilebert"),Opt=o(" \u2014 "),Aie=a("a"),Vpt=o("TFMobileBertForNextSentencePrediction"),Xpt=o(" (MobileBERT model)"),zpt=l(),F(q7.$$.fragment),Bdo=l(),Jc=a("h2"),j7=a("a"),HSe=a("span"),F(xB.$$.fragment),Qpt=l(),JSe=a("span"),Wpt=o("TFAutoModelForTableQuestionAnswering"),Ido=l(),wr=a("div"),F($B.$$.fragment),Upt=l(),Yc=a("p"),Hpt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Lie=a("a"),Jpt=o("from_pretrained()"),Ypt=o(" class method or the "),yie=a("a"),Zpt=o("from_config()"),Kpt=o(` class
method.`),e_t=l(),kB=a("p"),o_t=o("This class cannot be instantiated directly using "),YSe=a("code"),r_t=o("__init__()"),t_t=o(" (throws an error)."),a_t=l(),ca=a("div"),F(SB.$$.fragment),n_t=l(),ZSe=a("p"),s_t=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),l_t=l(),Zc=a("p"),i_t=o(`Note:
Loading a model from its configuration file does `),KSe=a("strong"),d_t=o("not"),m_t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xie=a("a"),c_t=o("from_pretrained()"),f_t=o(" to load the model weights."),g_t=l(),F(D7.$$.fragment),h_t=l(),ot=a("div"),F(RB.$$.fragment),u_t=l(),eRe=a("p"),p_t=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),__t=l(),Zn=a("p"),b_t=o("The model class to instantiate is selected based on the "),oRe=a("code"),v_t=o("model_type"),F_t=o(` property of the config object (either
passed as an argument or loaded from `),rRe=a("code"),T_t=o("pretrained_model_name_or_path"),M_t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tRe=a("code"),E_t=o("pretrained_model_name_or_path"),C_t=o(":"),w_t=l(),aRe=a("ul"),G7=a("li"),nRe=a("strong"),A_t=o("tapas"),L_t=o(" \u2014 "),$ie=a("a"),y_t=o("TFTapasForQuestionAnswering"),x_t=o(" (TAPAS model)"),$_t=l(),F(O7.$$.fragment),Ndo=l(),Kc=a("h2"),V7=a("a"),sRe=a("span"),F(PB.$$.fragment),k_t=l(),lRe=a("span"),S_t=o("TFAutoModelForDocumentQuestionAnswering"),qdo=l(),Ar=a("div"),F(BB.$$.fragment),R_t=l(),ef=a("p"),P_t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),kie=a("a"),B_t=o("from_pretrained()"),I_t=o(" class method or the "),Sie=a("a"),N_t=o("from_config()"),q_t=o(` class
method.`),j_t=l(),IB=a("p"),D_t=o("This class cannot be instantiated directly using "),iRe=a("code"),G_t=o("__init__()"),O_t=o(" (throws an error)."),V_t=l(),fa=a("div"),F(NB.$$.fragment),X_t=l(),dRe=a("p"),z_t=o("Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Q_t=l(),of=a("p"),W_t=o(`Note:
Loading a model from its configuration file does `),mRe=a("strong"),U_t=o("not"),H_t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Rie=a("a"),J_t=o("from_pretrained()"),Y_t=o(" to load the model weights."),Z_t=l(),F(X7.$$.fragment),K_t=l(),rt=a("div"),F(qB.$$.fragment),e1t=l(),cRe=a("p"),o1t=o("Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),r1t=l(),Kn=a("p"),t1t=o("The model class to instantiate is selected based on the "),fRe=a("code"),a1t=o("model_type"),n1t=o(` property of the config object (either
passed as an argument or loaded from `),gRe=a("code"),s1t=o("pretrained_model_name_or_path"),l1t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hRe=a("code"),i1t=o("pretrained_model_name_or_path"),d1t=o(":"),m1t=l(),uRe=a("ul"),z7=a("li"),pRe=a("strong"),c1t=o("layoutlm"),f1t=o(" \u2014 "),Pie=a("a"),g1t=o("TFLayoutLMForQuestionAnswering"),h1t=o(" (LayoutLM model)"),u1t=l(),F(Q7.$$.fragment),jdo=l(),rf=a("h2"),W7=a("a"),_Re=a("span"),F(jB.$$.fragment),p1t=l(),bRe=a("span"),_1t=o("TFAutoModelForTokenClassification"),Ddo=l(),Lr=a("div"),F(DB.$$.fragment),b1t=l(),tf=a("p"),v1t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Bie=a("a"),F1t=o("from_pretrained()"),T1t=o(" class method or the "),Iie=a("a"),M1t=o("from_config()"),E1t=o(` class
method.`),C1t=l(),GB=a("p"),w1t=o("This class cannot be instantiated directly using "),vRe=a("code"),A1t=o("__init__()"),L1t=o(" (throws an error)."),y1t=l(),ga=a("div"),F(OB.$$.fragment),x1t=l(),FRe=a("p"),$1t=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),k1t=l(),af=a("p"),S1t=o(`Note:
Loading a model from its configuration file does `),TRe=a("strong"),R1t=o("not"),P1t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Nie=a("a"),B1t=o("from_pretrained()"),I1t=o(" to load the model weights."),N1t=l(),F(U7.$$.fragment),q1t=l(),tt=a("div"),F(VB.$$.fragment),j1t=l(),MRe=a("p"),D1t=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),G1t=l(),es=a("p"),O1t=o("The model class to instantiate is selected based on the "),ERe=a("code"),V1t=o("model_type"),X1t=o(` property of the config object (either
passed as an argument or loaded from `),CRe=a("code"),z1t=o("pretrained_model_name_or_path"),Q1t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wRe=a("code"),W1t=o("pretrained_model_name_or_path"),U1t=o(":"),H1t=l(),me=a("ul"),H7=a("li"),ARe=a("strong"),J1t=o("albert"),Y1t=o(" \u2014 "),qie=a("a"),Z1t=o("TFAlbertForTokenClassification"),K1t=o(" (ALBERT model)"),e2t=l(),J7=a("li"),LRe=a("strong"),o2t=o("bert"),r2t=o(" \u2014 "),jie=a("a"),t2t=o("TFBertForTokenClassification"),a2t=o(" (BERT model)"),n2t=l(),Y7=a("li"),yRe=a("strong"),s2t=o("camembert"),l2t=o(" \u2014 "),Die=a("a"),i2t=o("TFCamembertForTokenClassification"),d2t=o(" (CamemBERT model)"),m2t=l(),Z7=a("li"),xRe=a("strong"),c2t=o("convbert"),f2t=o(" \u2014 "),Gie=a("a"),g2t=o("TFConvBertForTokenClassification"),h2t=o(" (ConvBERT model)"),u2t=l(),K7=a("li"),$Re=a("strong"),p2t=o("deberta"),_2t=o(" \u2014 "),Oie=a("a"),b2t=o("TFDebertaForTokenClassification"),v2t=o(" (DeBERTa model)"),F2t=l(),e8=a("li"),kRe=a("strong"),T2t=o("deberta-v2"),M2t=o(" \u2014 "),Vie=a("a"),E2t=o("TFDebertaV2ForTokenClassification"),C2t=o(" (DeBERTa-v2 model)"),w2t=l(),o8=a("li"),SRe=a("strong"),A2t=o("distilbert"),L2t=o(" \u2014 "),Xie=a("a"),y2t=o("TFDistilBertForTokenClassification"),x2t=o(" (DistilBERT model)"),$2t=l(),r8=a("li"),RRe=a("strong"),k2t=o("electra"),S2t=o(" \u2014 "),zie=a("a"),R2t=o("TFElectraForTokenClassification"),P2t=o(" (ELECTRA model)"),B2t=l(),t8=a("li"),PRe=a("strong"),I2t=o("esm"),N2t=o(" \u2014 "),Qie=a("a"),q2t=o("TFEsmForTokenClassification"),j2t=o(" (ESM model)"),D2t=l(),a8=a("li"),BRe=a("strong"),G2t=o("flaubert"),O2t=o(" \u2014 "),Wie=a("a"),V2t=o("TFFlaubertForTokenClassification"),X2t=o(" (FlauBERT model)"),z2t=l(),n8=a("li"),IRe=a("strong"),Q2t=o("funnel"),W2t=o(" \u2014 "),Uie=a("a"),U2t=o("TFFunnelForTokenClassification"),H2t=o(" (Funnel Transformer model)"),J2t=l(),s8=a("li"),NRe=a("strong"),Y2t=o("layoutlm"),Z2t=o(" \u2014 "),Hie=a("a"),K2t=o("TFLayoutLMForTokenClassification"),ebt=o(" (LayoutLM model)"),obt=l(),l8=a("li"),qRe=a("strong"),rbt=o("layoutlmv3"),tbt=o(" \u2014 "),Jie=a("a"),abt=o("TFLayoutLMv3ForTokenClassification"),nbt=o(" (LayoutLMv3 model)"),sbt=l(),i8=a("li"),jRe=a("strong"),lbt=o("longformer"),ibt=o(" \u2014 "),Yie=a("a"),dbt=o("TFLongformerForTokenClassification"),mbt=o(" (Longformer model)"),cbt=l(),d8=a("li"),DRe=a("strong"),fbt=o("mobilebert"),gbt=o(" \u2014 "),Zie=a("a"),hbt=o("TFMobileBertForTokenClassification"),ubt=o(" (MobileBERT model)"),pbt=l(),m8=a("li"),GRe=a("strong"),_bt=o("mpnet"),bbt=o(" \u2014 "),Kie=a("a"),vbt=o("TFMPNetForTokenClassification"),Fbt=o(" (MPNet model)"),Tbt=l(),c8=a("li"),ORe=a("strong"),Mbt=o("rembert"),Ebt=o(" \u2014 "),ede=a("a"),Cbt=o("TFRemBertForTokenClassification"),wbt=o(" (RemBERT model)"),Abt=l(),f8=a("li"),VRe=a("strong"),Lbt=o("roberta"),ybt=o(" \u2014 "),ode=a("a"),xbt=o("TFRobertaForTokenClassification"),$bt=o(" (RoBERTa model)"),kbt=l(),g8=a("li"),XRe=a("strong"),Sbt=o("roformer"),Rbt=o(" \u2014 "),rde=a("a"),Pbt=o("TFRoFormerForTokenClassification"),Bbt=o(" (RoFormer model)"),Ibt=l(),h8=a("li"),zRe=a("strong"),Nbt=o("xlm"),qbt=o(" \u2014 "),tde=a("a"),jbt=o("TFXLMForTokenClassification"),Dbt=o(" (XLM model)"),Gbt=l(),u8=a("li"),QRe=a("strong"),Obt=o("xlm-roberta"),Vbt=o(" \u2014 "),ade=a("a"),Xbt=o("TFXLMRobertaForTokenClassification"),zbt=o(" (XLM-RoBERTa model)"),Qbt=l(),p8=a("li"),WRe=a("strong"),Wbt=o("xlnet"),Ubt=o(" \u2014 "),nde=a("a"),Hbt=o("TFXLNetForTokenClassification"),Jbt=o(" (XLNet model)"),Ybt=l(),F(_8.$$.fragment),Gdo=l(),nf=a("h2"),b8=a("a"),URe=a("span"),F(XB.$$.fragment),Zbt=l(),HRe=a("span"),Kbt=o("TFAutoModelForQuestionAnswering"),Odo=l(),yr=a("div"),F(zB.$$.fragment),evt=l(),sf=a("p"),ovt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),sde=a("a"),rvt=o("from_pretrained()"),tvt=o(" class method or the "),lde=a("a"),avt=o("from_config()"),nvt=o(` class
method.`),svt=l(),QB=a("p"),lvt=o("This class cannot be instantiated directly using "),JRe=a("code"),ivt=o("__init__()"),dvt=o(" (throws an error)."),mvt=l(),ha=a("div"),F(WB.$$.fragment),cvt=l(),YRe=a("p"),fvt=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),gvt=l(),lf=a("p"),hvt=o(`Note:
Loading a model from its configuration file does `),ZRe=a("strong"),uvt=o("not"),pvt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ide=a("a"),_vt=o("from_pretrained()"),bvt=o(" to load the model weights."),vvt=l(),F(v8.$$.fragment),Fvt=l(),at=a("div"),F(UB.$$.fragment),Tvt=l(),KRe=a("p"),Mvt=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Evt=l(),os=a("p"),Cvt=o("The model class to instantiate is selected based on the "),ePe=a("code"),wvt=o("model_type"),Avt=o(` property of the config object (either
passed as an argument or loaded from `),oPe=a("code"),Lvt=o("pretrained_model_name_or_path"),yvt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rPe=a("code"),xvt=o("pretrained_model_name_or_path"),$vt=o(":"),kvt=l(),he=a("ul"),F8=a("li"),tPe=a("strong"),Svt=o("albert"),Rvt=o(" \u2014 "),dde=a("a"),Pvt=o("TFAlbertForQuestionAnswering"),Bvt=o(" (ALBERT model)"),Ivt=l(),T8=a("li"),aPe=a("strong"),Nvt=o("bert"),qvt=o(" \u2014 "),mde=a("a"),jvt=o("TFBertForQuestionAnswering"),Dvt=o(" (BERT model)"),Gvt=l(),M8=a("li"),nPe=a("strong"),Ovt=o("camembert"),Vvt=o(" \u2014 "),cde=a("a"),Xvt=o("TFCamembertForQuestionAnswering"),zvt=o(" (CamemBERT model)"),Qvt=l(),E8=a("li"),sPe=a("strong"),Wvt=o("convbert"),Uvt=o(" \u2014 "),fde=a("a"),Hvt=o("TFConvBertForQuestionAnswering"),Jvt=o(" (ConvBERT model)"),Yvt=l(),C8=a("li"),lPe=a("strong"),Zvt=o("deberta"),Kvt=o(" \u2014 "),gde=a("a"),eFt=o("TFDebertaForQuestionAnswering"),oFt=o(" (DeBERTa model)"),rFt=l(),w8=a("li"),iPe=a("strong"),tFt=o("deberta-v2"),aFt=o(" \u2014 "),hde=a("a"),nFt=o("TFDebertaV2ForQuestionAnswering"),sFt=o(" (DeBERTa-v2 model)"),lFt=l(),A8=a("li"),dPe=a("strong"),iFt=o("distilbert"),dFt=o(" \u2014 "),ude=a("a"),mFt=o("TFDistilBertForQuestionAnswering"),cFt=o(" (DistilBERT model)"),fFt=l(),L8=a("li"),mPe=a("strong"),gFt=o("electra"),hFt=o(" \u2014 "),pde=a("a"),uFt=o("TFElectraForQuestionAnswering"),pFt=o(" (ELECTRA model)"),_Ft=l(),y8=a("li"),cPe=a("strong"),bFt=o("flaubert"),vFt=o(" \u2014 "),_de=a("a"),FFt=o("TFFlaubertForQuestionAnsweringSimple"),TFt=o(" (FlauBERT model)"),MFt=l(),x8=a("li"),fPe=a("strong"),EFt=o("funnel"),CFt=o(" \u2014 "),bde=a("a"),wFt=o("TFFunnelForQuestionAnswering"),AFt=o(" (Funnel Transformer model)"),LFt=l(),$8=a("li"),gPe=a("strong"),yFt=o("gptj"),xFt=o(" \u2014 "),vde=a("a"),$Ft=o("TFGPTJForQuestionAnswering"),kFt=o(" (GPT-J model)"),SFt=l(),k8=a("li"),hPe=a("strong"),RFt=o("layoutlmv3"),PFt=o(" \u2014 "),Fde=a("a"),BFt=o("TFLayoutLMv3ForQuestionAnswering"),IFt=o(" (LayoutLMv3 model)"),NFt=l(),S8=a("li"),uPe=a("strong"),qFt=o("longformer"),jFt=o(" \u2014 "),Tde=a("a"),DFt=o("TFLongformerForQuestionAnswering"),GFt=o(" (Longformer model)"),OFt=l(),R8=a("li"),pPe=a("strong"),VFt=o("mobilebert"),XFt=o(" \u2014 "),Mde=a("a"),zFt=o("TFMobileBertForQuestionAnswering"),QFt=o(" (MobileBERT model)"),WFt=l(),P8=a("li"),_Pe=a("strong"),UFt=o("mpnet"),HFt=o(" \u2014 "),Ede=a("a"),JFt=o("TFMPNetForQuestionAnswering"),YFt=o(" (MPNet model)"),ZFt=l(),B8=a("li"),bPe=a("strong"),KFt=o("rembert"),eTt=o(" \u2014 "),Cde=a("a"),oTt=o("TFRemBertForQuestionAnswering"),rTt=o(" (RemBERT model)"),tTt=l(),I8=a("li"),vPe=a("strong"),aTt=o("roberta"),nTt=o(" \u2014 "),wde=a("a"),sTt=o("TFRobertaForQuestionAnswering"),lTt=o(" (RoBERTa model)"),iTt=l(),N8=a("li"),FPe=a("strong"),dTt=o("roformer"),mTt=o(" \u2014 "),Ade=a("a"),cTt=o("TFRoFormerForQuestionAnswering"),fTt=o(" (RoFormer model)"),gTt=l(),q8=a("li"),TPe=a("strong"),hTt=o("xlm"),uTt=o(" \u2014 "),Lde=a("a"),pTt=o("TFXLMForQuestionAnsweringSimple"),_Tt=o(" (XLM model)"),bTt=l(),j8=a("li"),MPe=a("strong"),vTt=o("xlm-roberta"),FTt=o(" \u2014 "),yde=a("a"),TTt=o("TFXLMRobertaForQuestionAnswering"),MTt=o(" (XLM-RoBERTa model)"),ETt=l(),D8=a("li"),EPe=a("strong"),CTt=o("xlnet"),wTt=o(" \u2014 "),xde=a("a"),ATt=o("TFXLNetForQuestionAnsweringSimple"),LTt=o(" (XLNet model)"),yTt=l(),F(G8.$$.fragment),Vdo=l(),df=a("h2"),O8=a("a"),CPe=a("span"),F(HB.$$.fragment),xTt=l(),wPe=a("span"),$Tt=o("TFAutoModelForVision2Seq"),Xdo=l(),xr=a("div"),F(JB.$$.fragment),kTt=l(),mf=a("p"),STt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),$de=a("a"),RTt=o("from_pretrained()"),PTt=o(" class method or the "),kde=a("a"),BTt=o("from_config()"),ITt=o(` class
method.`),NTt=l(),YB=a("p"),qTt=o("This class cannot be instantiated directly using "),APe=a("code"),jTt=o("__init__()"),DTt=o(" (throws an error)."),GTt=l(),ua=a("div"),F(ZB.$$.fragment),OTt=l(),LPe=a("p"),VTt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),XTt=l(),cf=a("p"),zTt=o(`Note:
Loading a model from its configuration file does `),yPe=a("strong"),QTt=o("not"),WTt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Sde=a("a"),UTt=o("from_pretrained()"),HTt=o(" to load the model weights."),JTt=l(),F(V8.$$.fragment),YTt=l(),nt=a("div"),F(KB.$$.fragment),ZTt=l(),xPe=a("p"),KTt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),eMt=l(),rs=a("p"),oMt=o("The model class to instantiate is selected based on the "),$Pe=a("code"),rMt=o("model_type"),tMt=o(` property of the config object (either
passed as an argument or loaded from `),kPe=a("code"),aMt=o("pretrained_model_name_or_path"),nMt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SPe=a("code"),sMt=o("pretrained_model_name_or_path"),lMt=o(":"),iMt=l(),RPe=a("ul"),X8=a("li"),PPe=a("strong"),dMt=o("vision-encoder-decoder"),mMt=o(" \u2014 "),Rde=a("a"),cMt=o("TFVisionEncoderDecoderModel"),fMt=o(" (Vision Encoder decoder model)"),gMt=l(),F(z8.$$.fragment),zdo=l(),ff=a("h2"),Q8=a("a"),BPe=a("span"),F(eI.$$.fragment),hMt=l(),IPe=a("span"),uMt=o("TFAutoModelForSpeechSeq2Seq"),Qdo=l(),$r=a("div"),F(oI.$$.fragment),pMt=l(),gf=a("p"),_Mt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Pde=a("a"),bMt=o("from_pretrained()"),vMt=o(" class method or the "),Bde=a("a"),FMt=o("from_config()"),TMt=o(` class
method.`),MMt=l(),rI=a("p"),EMt=o("This class cannot be instantiated directly using "),NPe=a("code"),CMt=o("__init__()"),wMt=o(" (throws an error)."),AMt=l(),pa=a("div"),F(tI.$$.fragment),LMt=l(),qPe=a("p"),yMt=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),xMt=l(),hf=a("p"),$Mt=o(`Note:
Loading a model from its configuration file does `),jPe=a("strong"),kMt=o("not"),SMt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ide=a("a"),RMt=o("from_pretrained()"),PMt=o(" to load the model weights."),BMt=l(),F(W8.$$.fragment),IMt=l(),st=a("div"),F(aI.$$.fragment),NMt=l(),DPe=a("p"),qMt=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),jMt=l(),ts=a("p"),DMt=o("The model class to instantiate is selected based on the "),GPe=a("code"),GMt=o("model_type"),OMt=o(` property of the config object (either
passed as an argument or loaded from `),OPe=a("code"),VMt=o("pretrained_model_name_or_path"),XMt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VPe=a("code"),zMt=o("pretrained_model_name_or_path"),QMt=o(":"),WMt=l(),nI=a("ul"),U8=a("li"),XPe=a("strong"),UMt=o("speech_to_text"),HMt=o(" \u2014 "),Nde=a("a"),JMt=o("TFSpeech2TextForConditionalGeneration"),YMt=o(" (Speech2Text model)"),ZMt=l(),H8=a("li"),zPe=a("strong"),KMt=o("whisper"),eEt=o(" \u2014 "),qde=a("a"),oEt=o("TFWhisperForConditionalGeneration"),rEt=o(" (Whisper model)"),tEt=l(),F(J8.$$.fragment),Wdo=l(),uf=a("h2"),Y8=a("a"),QPe=a("span"),F(sI.$$.fragment),aEt=l(),WPe=a("span"),nEt=o("FlaxAutoModel"),Udo=l(),kr=a("div"),F(lI.$$.fragment),sEt=l(),pf=a("p"),lEt=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),jde=a("a"),iEt=o("from_pretrained()"),dEt=o(" class method or the "),Dde=a("a"),mEt=o("from_config()"),cEt=o(` class
method.`),fEt=l(),iI=a("p"),gEt=o("This class cannot be instantiated directly using "),UPe=a("code"),hEt=o("__init__()"),uEt=o(" (throws an error)."),pEt=l(),_a=a("div"),F(dI.$$.fragment),_Et=l(),HPe=a("p"),bEt=o("Instantiates one of the base model classes of the library from a configuration."),vEt=l(),_f=a("p"),FEt=o(`Note:
Loading a model from its configuration file does `),JPe=a("strong"),TEt=o("not"),MEt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Gde=a("a"),EEt=o("from_pretrained()"),CEt=o(" to load the model weights."),wEt=l(),F(Z8.$$.fragment),AEt=l(),lt=a("div"),F(mI.$$.fragment),LEt=l(),YPe=a("p"),yEt=o("Instantiate one of the base model classes of the library from a pretrained model."),xEt=l(),as=a("p"),$Et=o("The model class to instantiate is selected based on the "),ZPe=a("code"),kEt=o("model_type"),SEt=o(` property of the config object (either
passed as an argument or loaded from `),KPe=a("code"),REt=o("pretrained_model_name_or_path"),PEt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eBe=a("code"),BEt=o("pretrained_model_name_or_path"),IEt=o(":"),NEt=l(),ne=a("ul"),K8=a("li"),oBe=a("strong"),qEt=o("albert"),jEt=o(" \u2014 "),Ode=a("a"),DEt=o("FlaxAlbertModel"),GEt=o(" (ALBERT model)"),OEt=l(),eL=a("li"),rBe=a("strong"),VEt=o("bart"),XEt=o(" \u2014 "),Vde=a("a"),zEt=o("FlaxBartModel"),QEt=o(" (BART model)"),WEt=l(),oL=a("li"),tBe=a("strong"),UEt=o("beit"),HEt=o(" \u2014 "),Xde=a("a"),JEt=o("FlaxBeitModel"),YEt=o(" (BEiT model)"),ZEt=l(),rL=a("li"),aBe=a("strong"),KEt=o("bert"),e4t=o(" \u2014 "),zde=a("a"),o4t=o("FlaxBertModel"),r4t=o(" (BERT model)"),t4t=l(),tL=a("li"),nBe=a("strong"),a4t=o("big_bird"),n4t=o(" \u2014 "),Qde=a("a"),s4t=o("FlaxBigBirdModel"),l4t=o(" (BigBird model)"),i4t=l(),aL=a("li"),sBe=a("strong"),d4t=o("blenderbot"),m4t=o(" \u2014 "),Wde=a("a"),c4t=o("FlaxBlenderbotModel"),f4t=o(" (Blenderbot model)"),g4t=l(),nL=a("li"),lBe=a("strong"),h4t=o("blenderbot-small"),u4t=o(" \u2014 "),Ude=a("a"),p4t=o("FlaxBlenderbotSmallModel"),_4t=o(" (BlenderbotSmall model)"),b4t=l(),sL=a("li"),iBe=a("strong"),v4t=o("clip"),F4t=o(" \u2014 "),Hde=a("a"),T4t=o("FlaxCLIPModel"),M4t=o(" (CLIP model)"),E4t=l(),lL=a("li"),dBe=a("strong"),C4t=o("distilbert"),w4t=o(" \u2014 "),Jde=a("a"),A4t=o("FlaxDistilBertModel"),L4t=o(" (DistilBERT model)"),y4t=l(),iL=a("li"),mBe=a("strong"),x4t=o("electra"),$4t=o(" \u2014 "),Yde=a("a"),k4t=o("FlaxElectraModel"),S4t=o(" (ELECTRA model)"),R4t=l(),dL=a("li"),cBe=a("strong"),P4t=o("gpt2"),B4t=o(" \u2014 "),Zde=a("a"),I4t=o("FlaxGPT2Model"),N4t=o(" (OpenAI GPT-2 model)"),q4t=l(),mL=a("li"),fBe=a("strong"),j4t=o("gpt_neo"),D4t=o(" \u2014 "),Kde=a("a"),G4t=o("FlaxGPTNeoModel"),O4t=o(" (GPT Neo model)"),V4t=l(),cL=a("li"),gBe=a("strong"),X4t=o("gptj"),z4t=o(" \u2014 "),eme=a("a"),Q4t=o("FlaxGPTJModel"),W4t=o(" (GPT-J model)"),U4t=l(),fL=a("li"),hBe=a("strong"),H4t=o("longt5"),J4t=o(" \u2014 "),ome=a("a"),Y4t=o("FlaxLongT5Model"),Z4t=o(" (LongT5 model)"),K4t=l(),gL=a("li"),uBe=a("strong"),eCt=o("marian"),oCt=o(" \u2014 "),rme=a("a"),rCt=o("FlaxMarianModel"),tCt=o(" (Marian model)"),aCt=l(),hL=a("li"),pBe=a("strong"),nCt=o("mbart"),sCt=o(" \u2014 "),tme=a("a"),lCt=o("FlaxMBartModel"),iCt=o(" (mBART model)"),dCt=l(),uL=a("li"),_Be=a("strong"),mCt=o("mt5"),cCt=o(" \u2014 "),ame=a("a"),fCt=o("FlaxMT5Model"),gCt=o(" (MT5 model)"),hCt=l(),pL=a("li"),bBe=a("strong"),uCt=o("opt"),pCt=o(" \u2014 "),nme=a("a"),_Ct=o("FlaxOPTModel"),bCt=o(" (OPT model)"),vCt=l(),_L=a("li"),vBe=a("strong"),FCt=o("pegasus"),TCt=o(" \u2014 "),sme=a("a"),MCt=o("FlaxPegasusModel"),ECt=o(" (Pegasus model)"),CCt=l(),bL=a("li"),FBe=a("strong"),wCt=o("roberta"),ACt=o(" \u2014 "),lme=a("a"),LCt=o("FlaxRobertaModel"),yCt=o(" (RoBERTa model)"),xCt=l(),vL=a("li"),TBe=a("strong"),$Ct=o("roformer"),kCt=o(" \u2014 "),ime=a("a"),SCt=o("FlaxRoFormerModel"),RCt=o(" (RoFormer model)"),PCt=l(),FL=a("li"),MBe=a("strong"),BCt=o("t5"),ICt=o(" \u2014 "),dme=a("a"),NCt=o("FlaxT5Model"),qCt=o(" (T5 model)"),jCt=l(),TL=a("li"),EBe=a("strong"),DCt=o("vision-text-dual-encoder"),GCt=o(" \u2014 "),mme=a("a"),OCt=o("FlaxVisionTextDualEncoderModel"),VCt=o(" (VisionTextDualEncoder model)"),XCt=l(),ML=a("li"),CBe=a("strong"),zCt=o("vit"),QCt=o(" \u2014 "),cme=a("a"),WCt=o("FlaxViTModel"),UCt=o(" (ViT model)"),HCt=l(),EL=a("li"),wBe=a("strong"),JCt=o("wav2vec2"),YCt=o(" \u2014 "),fme=a("a"),ZCt=o("FlaxWav2Vec2Model"),KCt=o(" (Wav2Vec2 model)"),e3t=l(),CL=a("li"),ABe=a("strong"),o3t=o("xglm"),r3t=o(" \u2014 "),gme=a("a"),t3t=o("FlaxXGLMModel"),a3t=o(" (XGLM model)"),n3t=l(),wL=a("li"),LBe=a("strong"),s3t=o("xlm-roberta"),l3t=o(" \u2014 "),hme=a("a"),i3t=o("FlaxXLMRobertaModel"),d3t=o(" (XLM-RoBERTa model)"),m3t=l(),F(AL.$$.fragment),Hdo=l(),bf=a("h2"),LL=a("a"),yBe=a("span"),F(cI.$$.fragment),c3t=l(),xBe=a("span"),f3t=o("FlaxAutoModelForCausalLM"),Jdo=l(),Sr=a("div"),F(fI.$$.fragment),g3t=l(),vf=a("p"),h3t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),ume=a("a"),u3t=o("from_pretrained()"),p3t=o(" class method or the "),pme=a("a"),_3t=o("from_config()"),b3t=o(` class
method.`),v3t=l(),gI=a("p"),F3t=o("This class cannot be instantiated directly using "),$Be=a("code"),T3t=o("__init__()"),M3t=o(" (throws an error)."),E3t=l(),ba=a("div"),F(hI.$$.fragment),C3t=l(),kBe=a("p"),w3t=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),A3t=l(),Ff=a("p"),L3t=o(`Note:
Loading a model from its configuration file does `),SBe=a("strong"),y3t=o("not"),x3t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_me=a("a"),$3t=o("from_pretrained()"),k3t=o(" to load the model weights."),S3t=l(),F(yL.$$.fragment),R3t=l(),it=a("div"),F(uI.$$.fragment),P3t=l(),RBe=a("p"),B3t=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),I3t=l(),ns=a("p"),N3t=o("The model class to instantiate is selected based on the "),PBe=a("code"),q3t=o("model_type"),j3t=o(` property of the config object (either
passed as an argument or loaded from `),BBe=a("code"),D3t=o("pretrained_model_name_or_path"),G3t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IBe=a("code"),O3t=o("pretrained_model_name_or_path"),V3t=o(":"),X3t=l(),Se=a("ul"),xL=a("li"),NBe=a("strong"),z3t=o("bart"),Q3t=o(" \u2014 "),bme=a("a"),W3t=o("FlaxBartForCausalLM"),U3t=o(" (BART model)"),H3t=l(),$L=a("li"),qBe=a("strong"),J3t=o("bert"),Y3t=o(" \u2014 "),vme=a("a"),Z3t=o("FlaxBertForCausalLM"),K3t=o(" (BERT model)"),e5t=l(),kL=a("li"),jBe=a("strong"),o5t=o("big_bird"),r5t=o(" \u2014 "),Fme=a("a"),t5t=o("FlaxBigBirdForCausalLM"),a5t=o(" (BigBird model)"),n5t=l(),SL=a("li"),DBe=a("strong"),s5t=o("electra"),l5t=o(" \u2014 "),Tme=a("a"),i5t=o("FlaxElectraForCausalLM"),d5t=o(" (ELECTRA model)"),m5t=l(),RL=a("li"),GBe=a("strong"),c5t=o("gpt2"),f5t=o(" \u2014 "),Mme=a("a"),g5t=o("FlaxGPT2LMHeadModel"),h5t=o(" (OpenAI GPT-2 model)"),u5t=l(),PL=a("li"),OBe=a("strong"),p5t=o("gpt_neo"),_5t=o(" \u2014 "),Eme=a("a"),b5t=o("FlaxGPTNeoForCausalLM"),v5t=o(" (GPT Neo model)"),F5t=l(),BL=a("li"),VBe=a("strong"),T5t=o("gptj"),M5t=o(" \u2014 "),Cme=a("a"),E5t=o("FlaxGPTJForCausalLM"),C5t=o(" (GPT-J model)"),w5t=l(),IL=a("li"),XBe=a("strong"),A5t=o("opt"),L5t=o(" \u2014 "),wme=a("a"),y5t=o("FlaxOPTForCausalLM"),x5t=o(" (OPT model)"),$5t=l(),NL=a("li"),zBe=a("strong"),k5t=o("roberta"),S5t=o(" \u2014 "),Ame=a("a"),R5t=o("FlaxRobertaForCausalLM"),P5t=o(" (RoBERTa model)"),B5t=l(),qL=a("li"),QBe=a("strong"),I5t=o("xglm"),N5t=o(" \u2014 "),Lme=a("a"),q5t=o("FlaxXGLMForCausalLM"),j5t=o(" (XGLM model)"),D5t=l(),F(jL.$$.fragment),Ydo=l(),Tf=a("h2"),DL=a("a"),WBe=a("span"),F(pI.$$.fragment),G5t=l(),UBe=a("span"),O5t=o("FlaxAutoModelForPreTraining"),Zdo=l(),Rr=a("div"),F(_I.$$.fragment),V5t=l(),Mf=a("p"),X5t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),yme=a("a"),z5t=o("from_pretrained()"),Q5t=o(" class method or the "),xme=a("a"),W5t=o("from_config()"),U5t=o(` class
method.`),H5t=l(),bI=a("p"),J5t=o("This class cannot be instantiated directly using "),HBe=a("code"),Y5t=o("__init__()"),Z5t=o(" (throws an error)."),K5t=l(),va=a("div"),F(vI.$$.fragment),e0t=l(),JBe=a("p"),o0t=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),r0t=l(),Ef=a("p"),t0t=o(`Note:
Loading a model from its configuration file does `),YBe=a("strong"),a0t=o("not"),n0t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$me=a("a"),s0t=o("from_pretrained()"),l0t=o(" to load the model weights."),i0t=l(),F(GL.$$.fragment),d0t=l(),dt=a("div"),F(FI.$$.fragment),m0t=l(),ZBe=a("p"),c0t=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),f0t=l(),ss=a("p"),g0t=o("The model class to instantiate is selected based on the "),KBe=a("code"),h0t=o("model_type"),u0t=o(` property of the config object (either
passed as an argument or loaded from `),eIe=a("code"),p0t=o("pretrained_model_name_or_path"),_0t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oIe=a("code"),b0t=o("pretrained_model_name_or_path"),v0t=o(":"),F0t=l(),we=a("ul"),OL=a("li"),rIe=a("strong"),T0t=o("albert"),M0t=o(" \u2014 "),kme=a("a"),E0t=o("FlaxAlbertForPreTraining"),C0t=o(" (ALBERT model)"),w0t=l(),VL=a("li"),tIe=a("strong"),A0t=o("bart"),L0t=o(" \u2014 "),Sme=a("a"),y0t=o("FlaxBartForConditionalGeneration"),x0t=o(" (BART model)"),$0t=l(),XL=a("li"),aIe=a("strong"),k0t=o("bert"),S0t=o(" \u2014 "),Rme=a("a"),R0t=o("FlaxBertForPreTraining"),P0t=o(" (BERT model)"),B0t=l(),zL=a("li"),nIe=a("strong"),I0t=o("big_bird"),N0t=o(" \u2014 "),Pme=a("a"),q0t=o("FlaxBigBirdForPreTraining"),j0t=o(" (BigBird model)"),D0t=l(),QL=a("li"),sIe=a("strong"),G0t=o("electra"),O0t=o(" \u2014 "),Bme=a("a"),V0t=o("FlaxElectraForPreTraining"),X0t=o(" (ELECTRA model)"),z0t=l(),WL=a("li"),lIe=a("strong"),Q0t=o("longt5"),W0t=o(" \u2014 "),Ime=a("a"),U0t=o("FlaxLongT5ForConditionalGeneration"),H0t=o(" (LongT5 model)"),J0t=l(),UL=a("li"),iIe=a("strong"),Y0t=o("mbart"),Z0t=o(" \u2014 "),Nme=a("a"),K0t=o("FlaxMBartForConditionalGeneration"),ewt=o(" (mBART model)"),owt=l(),HL=a("li"),dIe=a("strong"),rwt=o("mt5"),twt=o(" \u2014 "),qme=a("a"),awt=o("FlaxMT5ForConditionalGeneration"),nwt=o(" (MT5 model)"),swt=l(),JL=a("li"),mIe=a("strong"),lwt=o("roberta"),iwt=o(" \u2014 "),jme=a("a"),dwt=o("FlaxRobertaForMaskedLM"),mwt=o(" (RoBERTa model)"),cwt=l(),YL=a("li"),cIe=a("strong"),fwt=o("roformer"),gwt=o(" \u2014 "),Dme=a("a"),hwt=o("FlaxRoFormerForMaskedLM"),uwt=o(" (RoFormer model)"),pwt=l(),ZL=a("li"),fIe=a("strong"),_wt=o("t5"),bwt=o(" \u2014 "),Gme=a("a"),vwt=o("FlaxT5ForConditionalGeneration"),Fwt=o(" (T5 model)"),Twt=l(),KL=a("li"),gIe=a("strong"),Mwt=o("wav2vec2"),Ewt=o(" \u2014 "),Ome=a("a"),Cwt=o("FlaxWav2Vec2ForPreTraining"),wwt=o(" (Wav2Vec2 model)"),Awt=l(),ey=a("li"),hIe=a("strong"),Lwt=o("xlm-roberta"),ywt=o(" \u2014 "),Vme=a("a"),xwt=o("FlaxXLMRobertaForMaskedLM"),$wt=o(" (XLM-RoBERTa model)"),kwt=l(),F(oy.$$.fragment),Kdo=l(),Cf=a("h2"),ry=a("a"),uIe=a("span"),F(TI.$$.fragment),Swt=l(),pIe=a("span"),Rwt=o("FlaxAutoModelForMaskedLM"),emo=l(),Pr=a("div"),F(MI.$$.fragment),Pwt=l(),wf=a("p"),Bwt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Xme=a("a"),Iwt=o("from_pretrained()"),Nwt=o(" class method or the "),zme=a("a"),qwt=o("from_config()"),jwt=o(` class
method.`),Dwt=l(),EI=a("p"),Gwt=o("This class cannot be instantiated directly using "),_Ie=a("code"),Owt=o("__init__()"),Vwt=o(" (throws an error)."),Xwt=l(),Fa=a("div"),F(CI.$$.fragment),zwt=l(),bIe=a("p"),Qwt=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Wwt=l(),Af=a("p"),Uwt=o(`Note:
Loading a model from its configuration file does `),vIe=a("strong"),Hwt=o("not"),Jwt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qme=a("a"),Ywt=o("from_pretrained()"),Zwt=o(" to load the model weights."),Kwt=l(),F(ty.$$.fragment),eAt=l(),mt=a("div"),F(wI.$$.fragment),oAt=l(),FIe=a("p"),rAt=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),tAt=l(),ls=a("p"),aAt=o("The model class to instantiate is selected based on the "),TIe=a("code"),nAt=o("model_type"),sAt=o(` property of the config object (either
passed as an argument or loaded from `),MIe=a("code"),lAt=o("pretrained_model_name_or_path"),iAt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),EIe=a("code"),dAt=o("pretrained_model_name_or_path"),mAt=o(":"),cAt=l(),Re=a("ul"),ay=a("li"),CIe=a("strong"),fAt=o("albert"),gAt=o(" \u2014 "),Wme=a("a"),hAt=o("FlaxAlbertForMaskedLM"),uAt=o(" (ALBERT model)"),pAt=l(),ny=a("li"),wIe=a("strong"),_At=o("bart"),bAt=o(" \u2014 "),Ume=a("a"),vAt=o("FlaxBartForConditionalGeneration"),FAt=o(" (BART model)"),TAt=l(),sy=a("li"),AIe=a("strong"),MAt=o("bert"),EAt=o(" \u2014 "),Hme=a("a"),CAt=o("FlaxBertForMaskedLM"),wAt=o(" (BERT model)"),AAt=l(),ly=a("li"),LIe=a("strong"),LAt=o("big_bird"),yAt=o(" \u2014 "),Jme=a("a"),xAt=o("FlaxBigBirdForMaskedLM"),$At=o(" (BigBird model)"),kAt=l(),iy=a("li"),yIe=a("strong"),SAt=o("distilbert"),RAt=o(" \u2014 "),Yme=a("a"),PAt=o("FlaxDistilBertForMaskedLM"),BAt=o(" (DistilBERT model)"),IAt=l(),dy=a("li"),xIe=a("strong"),NAt=o("electra"),qAt=o(" \u2014 "),Zme=a("a"),jAt=o("FlaxElectraForMaskedLM"),DAt=o(" (ELECTRA model)"),GAt=l(),my=a("li"),$Ie=a("strong"),OAt=o("mbart"),VAt=o(" \u2014 "),Kme=a("a"),XAt=o("FlaxMBartForConditionalGeneration"),zAt=o(" (mBART model)"),QAt=l(),cy=a("li"),kIe=a("strong"),WAt=o("roberta"),UAt=o(" \u2014 "),ece=a("a"),HAt=o("FlaxRobertaForMaskedLM"),JAt=o(" (RoBERTa model)"),YAt=l(),fy=a("li"),SIe=a("strong"),ZAt=o("roformer"),KAt=o(" \u2014 "),oce=a("a"),e6t=o("FlaxRoFormerForMaskedLM"),o6t=o(" (RoFormer model)"),r6t=l(),gy=a("li"),RIe=a("strong"),t6t=o("xlm-roberta"),a6t=o(" \u2014 "),rce=a("a"),n6t=o("FlaxXLMRobertaForMaskedLM"),s6t=o(" (XLM-RoBERTa model)"),l6t=l(),F(hy.$$.fragment),omo=l(),Lf=a("h2"),uy=a("a"),PIe=a("span"),F(AI.$$.fragment),i6t=l(),BIe=a("span"),d6t=o("FlaxAutoModelForSeq2SeqLM"),rmo=l(),Br=a("div"),F(LI.$$.fragment),m6t=l(),yf=a("p"),c6t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),tce=a("a"),f6t=o("from_pretrained()"),g6t=o(" class method or the "),ace=a("a"),h6t=o("from_config()"),u6t=o(` class
method.`),p6t=l(),yI=a("p"),_6t=o("This class cannot be instantiated directly using "),IIe=a("code"),b6t=o("__init__()"),v6t=o(" (throws an error)."),F6t=l(),Ta=a("div"),F(xI.$$.fragment),T6t=l(),NIe=a("p"),M6t=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),E6t=l(),xf=a("p"),C6t=o(`Note:
Loading a model from its configuration file does `),qIe=a("strong"),w6t=o("not"),A6t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nce=a("a"),L6t=o("from_pretrained()"),y6t=o(" to load the model weights."),x6t=l(),F(py.$$.fragment),$6t=l(),ct=a("div"),F($I.$$.fragment),k6t=l(),jIe=a("p"),S6t=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),R6t=l(),is=a("p"),P6t=o("The model class to instantiate is selected based on the "),DIe=a("code"),B6t=o("model_type"),I6t=o(` property of the config object (either
passed as an argument or loaded from `),GIe=a("code"),N6t=o("pretrained_model_name_or_path"),q6t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),OIe=a("code"),j6t=o("pretrained_model_name_or_path"),D6t=o(":"),G6t=l(),Pe=a("ul"),_y=a("li"),VIe=a("strong"),O6t=o("bart"),V6t=o(" \u2014 "),sce=a("a"),X6t=o("FlaxBartForConditionalGeneration"),z6t=o(" (BART model)"),Q6t=l(),by=a("li"),XIe=a("strong"),W6t=o("blenderbot"),U6t=o(" \u2014 "),lce=a("a"),H6t=o("FlaxBlenderbotForConditionalGeneration"),J6t=o(" (Blenderbot model)"),Y6t=l(),vy=a("li"),zIe=a("strong"),Z6t=o("blenderbot-small"),K6t=o(" \u2014 "),ice=a("a"),e7t=o("FlaxBlenderbotSmallForConditionalGeneration"),o7t=o(" (BlenderbotSmall model)"),r7t=l(),Fy=a("li"),QIe=a("strong"),t7t=o("encoder-decoder"),a7t=o(" \u2014 "),dce=a("a"),n7t=o("FlaxEncoderDecoderModel"),s7t=o(" (Encoder decoder model)"),l7t=l(),Ty=a("li"),WIe=a("strong"),i7t=o("longt5"),d7t=o(" \u2014 "),mce=a("a"),m7t=o("FlaxLongT5ForConditionalGeneration"),c7t=o(" (LongT5 model)"),f7t=l(),My=a("li"),UIe=a("strong"),g7t=o("marian"),h7t=o(" \u2014 "),cce=a("a"),u7t=o("FlaxMarianMTModel"),p7t=o(" (Marian model)"),_7t=l(),Ey=a("li"),HIe=a("strong"),b7t=o("mbart"),v7t=o(" \u2014 "),fce=a("a"),F7t=o("FlaxMBartForConditionalGeneration"),T7t=o(" (mBART model)"),M7t=l(),Cy=a("li"),JIe=a("strong"),E7t=o("mt5"),C7t=o(" \u2014 "),gce=a("a"),w7t=o("FlaxMT5ForConditionalGeneration"),A7t=o(" (MT5 model)"),L7t=l(),wy=a("li"),YIe=a("strong"),y7t=o("pegasus"),x7t=o(" \u2014 "),hce=a("a"),$7t=o("FlaxPegasusForConditionalGeneration"),k7t=o(" (Pegasus model)"),S7t=l(),Ay=a("li"),ZIe=a("strong"),R7t=o("t5"),P7t=o(" \u2014 "),uce=a("a"),B7t=o("FlaxT5ForConditionalGeneration"),I7t=o(" (T5 model)"),N7t=l(),F(Ly.$$.fragment),tmo=l(),$f=a("h2"),yy=a("a"),KIe=a("span"),F(kI.$$.fragment),q7t=l(),eNe=a("span"),j7t=o("FlaxAutoModelForSequenceClassification"),amo=l(),Ir=a("div"),F(SI.$$.fragment),D7t=l(),kf=a("p"),G7t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),pce=a("a"),O7t=o("from_pretrained()"),V7t=o(" class method or the "),_ce=a("a"),X7t=o("from_config()"),z7t=o(` class
method.`),Q7t=l(),RI=a("p"),W7t=o("This class cannot be instantiated directly using "),oNe=a("code"),U7t=o("__init__()"),H7t=o(" (throws an error)."),J7t=l(),Ma=a("div"),F(PI.$$.fragment),Y7t=l(),rNe=a("p"),Z7t=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),K7t=l(),Sf=a("p"),e8t=o(`Note:
Loading a model from its configuration file does `),tNe=a("strong"),o8t=o("not"),r8t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bce=a("a"),t8t=o("from_pretrained()"),a8t=o(" to load the model weights."),n8t=l(),F(xy.$$.fragment),s8t=l(),ft=a("div"),F(BI.$$.fragment),l8t=l(),aNe=a("p"),i8t=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),d8t=l(),ds=a("p"),m8t=o("The model class to instantiate is selected based on the "),nNe=a("code"),c8t=o("model_type"),f8t=o(` property of the config object (either
passed as an argument or loaded from `),sNe=a("code"),g8t=o("pretrained_model_name_or_path"),h8t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lNe=a("code"),u8t=o("pretrained_model_name_or_path"),p8t=o(":"),_8t=l(),Be=a("ul"),$y=a("li"),iNe=a("strong"),b8t=o("albert"),v8t=o(" \u2014 "),vce=a("a"),F8t=o("FlaxAlbertForSequenceClassification"),T8t=o(" (ALBERT model)"),M8t=l(),ky=a("li"),dNe=a("strong"),E8t=o("bart"),C8t=o(" \u2014 "),Fce=a("a"),w8t=o("FlaxBartForSequenceClassification"),A8t=o(" (BART model)"),L8t=l(),Sy=a("li"),mNe=a("strong"),y8t=o("bert"),x8t=o(" \u2014 "),Tce=a("a"),$8t=o("FlaxBertForSequenceClassification"),k8t=o(" (BERT model)"),S8t=l(),Ry=a("li"),cNe=a("strong"),R8t=o("big_bird"),P8t=o(" \u2014 "),Mce=a("a"),B8t=o("FlaxBigBirdForSequenceClassification"),I8t=o(" (BigBird model)"),N8t=l(),Py=a("li"),fNe=a("strong"),q8t=o("distilbert"),j8t=o(" \u2014 "),Ece=a("a"),D8t=o("FlaxDistilBertForSequenceClassification"),G8t=o(" (DistilBERT model)"),O8t=l(),By=a("li"),gNe=a("strong"),V8t=o("electra"),X8t=o(" \u2014 "),Cce=a("a"),z8t=o("FlaxElectraForSequenceClassification"),Q8t=o(" (ELECTRA model)"),W8t=l(),Iy=a("li"),hNe=a("strong"),U8t=o("mbart"),H8t=o(" \u2014 "),wce=a("a"),J8t=o("FlaxMBartForSequenceClassification"),Y8t=o(" (mBART model)"),Z8t=l(),Ny=a("li"),uNe=a("strong"),K8t=o("roberta"),eLt=o(" \u2014 "),Ace=a("a"),oLt=o("FlaxRobertaForSequenceClassification"),rLt=o(" (RoBERTa model)"),tLt=l(),qy=a("li"),pNe=a("strong"),aLt=o("roformer"),nLt=o(" \u2014 "),Lce=a("a"),sLt=o("FlaxRoFormerForSequenceClassification"),lLt=o(" (RoFormer model)"),iLt=l(),jy=a("li"),_Ne=a("strong"),dLt=o("xlm-roberta"),mLt=o(" \u2014 "),yce=a("a"),cLt=o("FlaxXLMRobertaForSequenceClassification"),fLt=o(" (XLM-RoBERTa model)"),gLt=l(),F(Dy.$$.fragment),nmo=l(),Rf=a("h2"),Gy=a("a"),bNe=a("span"),F(II.$$.fragment),hLt=l(),vNe=a("span"),uLt=o("FlaxAutoModelForQuestionAnswering"),smo=l(),Nr=a("div"),F(NI.$$.fragment),pLt=l(),Pf=a("p"),_Lt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),xce=a("a"),bLt=o("from_pretrained()"),vLt=o(" class method or the "),$ce=a("a"),FLt=o("from_config()"),TLt=o(` class
method.`),MLt=l(),qI=a("p"),ELt=o("This class cannot be instantiated directly using "),FNe=a("code"),CLt=o("__init__()"),wLt=o(" (throws an error)."),ALt=l(),Ea=a("div"),F(jI.$$.fragment),LLt=l(),TNe=a("p"),yLt=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),xLt=l(),Bf=a("p"),$Lt=o(`Note:
Loading a model from its configuration file does `),MNe=a("strong"),kLt=o("not"),SLt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kce=a("a"),RLt=o("from_pretrained()"),PLt=o(" to load the model weights."),BLt=l(),F(Oy.$$.fragment),ILt=l(),gt=a("div"),F(DI.$$.fragment),NLt=l(),ENe=a("p"),qLt=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),jLt=l(),ms=a("p"),DLt=o("The model class to instantiate is selected based on the "),CNe=a("code"),GLt=o("model_type"),OLt=o(` property of the config object (either
passed as an argument or loaded from `),wNe=a("code"),VLt=o("pretrained_model_name_or_path"),XLt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ANe=a("code"),zLt=o("pretrained_model_name_or_path"),QLt=o(":"),WLt=l(),Ie=a("ul"),Vy=a("li"),LNe=a("strong"),ULt=o("albert"),HLt=o(" \u2014 "),Sce=a("a"),JLt=o("FlaxAlbertForQuestionAnswering"),YLt=o(" (ALBERT model)"),ZLt=l(),Xy=a("li"),yNe=a("strong"),KLt=o("bart"),eyt=o(" \u2014 "),Rce=a("a"),oyt=o("FlaxBartForQuestionAnswering"),ryt=o(" (BART model)"),tyt=l(),zy=a("li"),xNe=a("strong"),ayt=o("bert"),nyt=o(" \u2014 "),Pce=a("a"),syt=o("FlaxBertForQuestionAnswering"),lyt=o(" (BERT model)"),iyt=l(),Qy=a("li"),$Ne=a("strong"),dyt=o("big_bird"),myt=o(" \u2014 "),Bce=a("a"),cyt=o("FlaxBigBirdForQuestionAnswering"),fyt=o(" (BigBird model)"),gyt=l(),Wy=a("li"),kNe=a("strong"),hyt=o("distilbert"),uyt=o(" \u2014 "),Ice=a("a"),pyt=o("FlaxDistilBertForQuestionAnswering"),_yt=o(" (DistilBERT model)"),byt=l(),Uy=a("li"),SNe=a("strong"),vyt=o("electra"),Fyt=o(" \u2014 "),Nce=a("a"),Tyt=o("FlaxElectraForQuestionAnswering"),Myt=o(" (ELECTRA model)"),Eyt=l(),Hy=a("li"),RNe=a("strong"),Cyt=o("mbart"),wyt=o(" \u2014 "),qce=a("a"),Ayt=o("FlaxMBartForQuestionAnswering"),Lyt=o(" (mBART model)"),yyt=l(),Jy=a("li"),PNe=a("strong"),xyt=o("roberta"),$yt=o(" \u2014 "),jce=a("a"),kyt=o("FlaxRobertaForQuestionAnswering"),Syt=o(" (RoBERTa model)"),Ryt=l(),Yy=a("li"),BNe=a("strong"),Pyt=o("roformer"),Byt=o(" \u2014 "),Dce=a("a"),Iyt=o("FlaxRoFormerForQuestionAnswering"),Nyt=o(" (RoFormer model)"),qyt=l(),Zy=a("li"),INe=a("strong"),jyt=o("xlm-roberta"),Dyt=o(" \u2014 "),Gce=a("a"),Gyt=o("FlaxXLMRobertaForQuestionAnswering"),Oyt=o(" (XLM-RoBERTa model)"),Vyt=l(),F(Ky.$$.fragment),lmo=l(),If=a("h2"),e9=a("a"),NNe=a("span"),F(GI.$$.fragment),Xyt=l(),qNe=a("span"),zyt=o("FlaxAutoModelForTokenClassification"),imo=l(),qr=a("div"),F(OI.$$.fragment),Qyt=l(),Nf=a("p"),Wyt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Oce=a("a"),Uyt=o("from_pretrained()"),Hyt=o(" class method or the "),Vce=a("a"),Jyt=o("from_config()"),Yyt=o(` class
method.`),Zyt=l(),VI=a("p"),Kyt=o("This class cannot be instantiated directly using "),jNe=a("code"),e9t=o("__init__()"),o9t=o(" (throws an error)."),r9t=l(),Ca=a("div"),F(XI.$$.fragment),t9t=l(),DNe=a("p"),a9t=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),n9t=l(),qf=a("p"),s9t=o(`Note:
Loading a model from its configuration file does `),GNe=a("strong"),l9t=o("not"),i9t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Xce=a("a"),d9t=o("from_pretrained()"),m9t=o(" to load the model weights."),c9t=l(),F(o9.$$.fragment),f9t=l(),ht=a("div"),F(zI.$$.fragment),g9t=l(),ONe=a("p"),h9t=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),u9t=l(),cs=a("p"),p9t=o("The model class to instantiate is selected based on the "),VNe=a("code"),_9t=o("model_type"),b9t=o(` property of the config object (either
passed as an argument or loaded from `),XNe=a("code"),v9t=o("pretrained_model_name_or_path"),F9t=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zNe=a("code"),T9t=o("pretrained_model_name_or_path"),M9t=o(":"),E9t=l(),We=a("ul"),r9=a("li"),QNe=a("strong"),C9t=o("albert"),w9t=o(" \u2014 "),zce=a("a"),A9t=o("FlaxAlbertForTokenClassification"),L9t=o(" (ALBERT model)"),y9t=l(),t9=a("li"),WNe=a("strong"),x9t=o("bert"),$9t=o(" \u2014 "),Qce=a("a"),k9t=o("FlaxBertForTokenClassification"),S9t=o(" (BERT model)"),R9t=l(),a9=a("li"),UNe=a("strong"),P9t=o("big_bird"),B9t=o(" \u2014 "),Wce=a("a"),I9t=o("FlaxBigBirdForTokenClassification"),N9t=o(" (BigBird model)"),q9t=l(),n9=a("li"),HNe=a("strong"),j9t=o("distilbert"),D9t=o(" \u2014 "),Uce=a("a"),G9t=o("FlaxDistilBertForTokenClassification"),O9t=o(" (DistilBERT model)"),V9t=l(),s9=a("li"),JNe=a("strong"),X9t=o("electra"),z9t=o(" \u2014 "),Hce=a("a"),Q9t=o("FlaxElectraForTokenClassification"),W9t=o(" (ELECTRA model)"),U9t=l(),l9=a("li"),YNe=a("strong"),H9t=o("roberta"),J9t=o(" \u2014 "),Jce=a("a"),Y9t=o("FlaxRobertaForTokenClassification"),Z9t=o(" (RoBERTa model)"),K9t=l(),i9=a("li"),ZNe=a("strong"),ext=o("roformer"),oxt=o(" \u2014 "),Yce=a("a"),rxt=o("FlaxRoFormerForTokenClassification"),txt=o(" (RoFormer model)"),axt=l(),d9=a("li"),KNe=a("strong"),nxt=o("xlm-roberta"),sxt=o(" \u2014 "),Zce=a("a"),lxt=o("FlaxXLMRobertaForTokenClassification"),ixt=o(" (XLM-RoBERTa model)"),dxt=l(),F(m9.$$.fragment),dmo=l(),jf=a("h2"),c9=a("a"),eqe=a("span"),F(QI.$$.fragment),mxt=l(),oqe=a("span"),cxt=o("FlaxAutoModelForMultipleChoice"),mmo=l(),jr=a("div"),F(WI.$$.fragment),fxt=l(),Df=a("p"),gxt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Kce=a("a"),hxt=o("from_pretrained()"),uxt=o(" class method or the "),efe=a("a"),pxt=o("from_config()"),_xt=o(` class
method.`),bxt=l(),UI=a("p"),vxt=o("This class cannot be instantiated directly using "),rqe=a("code"),Fxt=o("__init__()"),Txt=o(" (throws an error)."),Mxt=l(),wa=a("div"),F(HI.$$.fragment),Ext=l(),tqe=a("p"),Cxt=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),wxt=l(),Gf=a("p"),Axt=o(`Note:
Loading a model from its configuration file does `),aqe=a("strong"),Lxt=o("not"),yxt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ofe=a("a"),xxt=o("from_pretrained()"),$xt=o(" to load the model weights."),kxt=l(),F(f9.$$.fragment),Sxt=l(),ut=a("div"),F(JI.$$.fragment),Rxt=l(),nqe=a("p"),Pxt=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Bxt=l(),fs=a("p"),Ixt=o("The model class to instantiate is selected based on the "),sqe=a("code"),Nxt=o("model_type"),qxt=o(` property of the config object (either
passed as an argument or loaded from `),lqe=a("code"),jxt=o("pretrained_model_name_or_path"),Dxt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iqe=a("code"),Gxt=o("pretrained_model_name_or_path"),Oxt=o(":"),Vxt=l(),Ue=a("ul"),g9=a("li"),dqe=a("strong"),Xxt=o("albert"),zxt=o(" \u2014 "),rfe=a("a"),Qxt=o("FlaxAlbertForMultipleChoice"),Wxt=o(" (ALBERT model)"),Uxt=l(),h9=a("li"),mqe=a("strong"),Hxt=o("bert"),Jxt=o(" \u2014 "),tfe=a("a"),Yxt=o("FlaxBertForMultipleChoice"),Zxt=o(" (BERT model)"),Kxt=l(),u9=a("li"),cqe=a("strong"),e$t=o("big_bird"),o$t=o(" \u2014 "),afe=a("a"),r$t=o("FlaxBigBirdForMultipleChoice"),t$t=o(" (BigBird model)"),a$t=l(),p9=a("li"),fqe=a("strong"),n$t=o("distilbert"),s$t=o(" \u2014 "),nfe=a("a"),l$t=o("FlaxDistilBertForMultipleChoice"),i$t=o(" (DistilBERT model)"),d$t=l(),_9=a("li"),gqe=a("strong"),m$t=o("electra"),c$t=o(" \u2014 "),sfe=a("a"),f$t=o("FlaxElectraForMultipleChoice"),g$t=o(" (ELECTRA model)"),h$t=l(),b9=a("li"),hqe=a("strong"),u$t=o("roberta"),p$t=o(" \u2014 "),lfe=a("a"),_$t=o("FlaxRobertaForMultipleChoice"),b$t=o(" (RoBERTa model)"),v$t=l(),v9=a("li"),uqe=a("strong"),F$t=o("roformer"),T$t=o(" \u2014 "),ife=a("a"),M$t=o("FlaxRoFormerForMultipleChoice"),E$t=o(" (RoFormer model)"),C$t=l(),F9=a("li"),pqe=a("strong"),w$t=o("xlm-roberta"),A$t=o(" \u2014 "),dfe=a("a"),L$t=o("FlaxXLMRobertaForMultipleChoice"),y$t=o(" (XLM-RoBERTa model)"),x$t=l(),F(T9.$$.fragment),cmo=l(),Of=a("h2"),M9=a("a"),_qe=a("span"),F(YI.$$.fragment),$$t=l(),bqe=a("span"),k$t=o("FlaxAutoModelForNextSentencePrediction"),fmo=l(),Dr=a("div"),F(ZI.$$.fragment),S$t=l(),Vf=a("p"),R$t=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),mfe=a("a"),P$t=o("from_pretrained()"),B$t=o(" class method or the "),cfe=a("a"),I$t=o("from_config()"),N$t=o(` class
method.`),q$t=l(),KI=a("p"),j$t=o("This class cannot be instantiated directly using "),vqe=a("code"),D$t=o("__init__()"),G$t=o(" (throws an error)."),O$t=l(),Aa=a("div"),F(eN.$$.fragment),V$t=l(),Fqe=a("p"),X$t=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),z$t=l(),Xf=a("p"),Q$t=o(`Note:
Loading a model from its configuration file does `),Tqe=a("strong"),W$t=o("not"),U$t=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ffe=a("a"),H$t=o("from_pretrained()"),J$t=o(" to load the model weights."),Y$t=l(),F(E9.$$.fragment),Z$t=l(),pt=a("div"),F(oN.$$.fragment),K$t=l(),Mqe=a("p"),ekt=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),okt=l(),gs=a("p"),rkt=o("The model class to instantiate is selected based on the "),Eqe=a("code"),tkt=o("model_type"),akt=o(` property of the config object (either
passed as an argument or loaded from `),Cqe=a("code"),nkt=o("pretrained_model_name_or_path"),skt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wqe=a("code"),lkt=o("pretrained_model_name_or_path"),ikt=o(":"),dkt=l(),Aqe=a("ul"),C9=a("li"),Lqe=a("strong"),mkt=o("bert"),ckt=o(" \u2014 "),gfe=a("a"),fkt=o("FlaxBertForNextSentencePrediction"),gkt=o(" (BERT model)"),hkt=l(),F(w9.$$.fragment),gmo=l(),zf=a("h2"),A9=a("a"),yqe=a("span"),F(rN.$$.fragment),ukt=l(),xqe=a("span"),pkt=o("FlaxAutoModelForImageClassification"),hmo=l(),Gr=a("div"),F(tN.$$.fragment),_kt=l(),Qf=a("p"),bkt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),hfe=a("a"),vkt=o("from_pretrained()"),Fkt=o(" class method or the "),ufe=a("a"),Tkt=o("from_config()"),Mkt=o(` class
method.`),Ekt=l(),aN=a("p"),Ckt=o("This class cannot be instantiated directly using "),$qe=a("code"),wkt=o("__init__()"),Akt=o(" (throws an error)."),Lkt=l(),La=a("div"),F(nN.$$.fragment),ykt=l(),kqe=a("p"),xkt=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),$kt=l(),Wf=a("p"),kkt=o(`Note:
Loading a model from its configuration file does `),Sqe=a("strong"),Skt=o("not"),Rkt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pfe=a("a"),Pkt=o("from_pretrained()"),Bkt=o(" to load the model weights."),Ikt=l(),F(L9.$$.fragment),Nkt=l(),_t=a("div"),F(sN.$$.fragment),qkt=l(),Rqe=a("p"),jkt=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Dkt=l(),hs=a("p"),Gkt=o("The model class to instantiate is selected based on the "),Pqe=a("code"),Okt=o("model_type"),Vkt=o(` property of the config object (either
passed as an argument or loaded from `),Bqe=a("code"),Xkt=o("pretrained_model_name_or_path"),zkt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Iqe=a("code"),Qkt=o("pretrained_model_name_or_path"),Wkt=o(":"),Ukt=l(),lN=a("ul"),y9=a("li"),Nqe=a("strong"),Hkt=o("beit"),Jkt=o(" \u2014 "),_fe=a("a"),Ykt=o("FlaxBeitForImageClassification"),Zkt=o(" (BEiT model)"),Kkt=l(),x9=a("li"),qqe=a("strong"),eSt=o("vit"),oSt=o(" \u2014 "),bfe=a("a"),rSt=o("FlaxViTForImageClassification"),tSt=o(" (ViT model)"),aSt=l(),F($9.$$.fragment),umo=l(),Uf=a("h2"),k9=a("a"),jqe=a("span"),F(iN.$$.fragment),nSt=l(),Dqe=a("span"),sSt=o("FlaxAutoModelForVision2Seq"),pmo=l(),Or=a("div"),F(dN.$$.fragment),lSt=l(),Hf=a("p"),iSt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),vfe=a("a"),dSt=o("from_pretrained()"),mSt=o(" class method or the "),Ffe=a("a"),cSt=o("from_config()"),fSt=o(` class
method.`),gSt=l(),mN=a("p"),hSt=o("This class cannot be instantiated directly using "),Gqe=a("code"),uSt=o("__init__()"),pSt=o(" (throws an error)."),_St=l(),ya=a("div"),F(cN.$$.fragment),bSt=l(),Oqe=a("p"),vSt=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),FSt=l(),Jf=a("p"),TSt=o(`Note:
Loading a model from its configuration file does `),Vqe=a("strong"),MSt=o("not"),ESt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Tfe=a("a"),CSt=o("from_pretrained()"),wSt=o(" to load the model weights."),ASt=l(),F(S9.$$.fragment),LSt=l(),bt=a("div"),F(fN.$$.fragment),ySt=l(),Xqe=a("p"),xSt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),$St=l(),us=a("p"),kSt=o("The model class to instantiate is selected based on the "),zqe=a("code"),SSt=o("model_type"),RSt=o(` property of the config object (either
passed as an argument or loaded from `),Qqe=a("code"),PSt=o("pretrained_model_name_or_path"),BSt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wqe=a("code"),ISt=o("pretrained_model_name_or_path"),NSt=o(":"),qSt=l(),Uqe=a("ul"),R9=a("li"),Hqe=a("strong"),jSt=o("vision-encoder-decoder"),DSt=o(" \u2014 "),Mfe=a("a"),GSt=o("FlaxVisionEncoderDecoderModel"),OSt=o(" (Vision Encoder decoder model)"),VSt=l(),F(P9.$$.fragment),this.h()},l(c){const _=B$a('[data-svelte="svelte-1phssyn"]',document.head);g=n(_,"META",{name:!0,content:!0}),_.forEach(t),v=i(c),u=n(c,"H1",{class:!0});var gN=s(u);f=n(gN,"A",{id:!0,class:!0,href:!0});var Jqe=s(f);p=n(Jqe,"SPAN",{});var Yqe=s(p);T(m.$$.fragment,Yqe),Yqe.forEach(t),Jqe.forEach(t),h=i(gN),He=n(gN,"SPAN",{});var Zqe=s(He);Ad=r(Zqe,"Auto Classes"),Zqe.forEach(t),gN.forEach(t),eg=i(c),wt=n(c,"P",{});var hN=s(wt);Ld=r(hN,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),yd=n(hN,"CODE",{});var Kqe=s(yd);_k=r(Kqe,"from_pretrained()"),Kqe.forEach(t),og=r(hN,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),hN.forEach(t),Qe=i(c),Ze=n(c,"P",{});var ps=s(Ze);xd=r(ps,"Instantiating one of "),_s=n(ps,"A",{href:!0});var eje=s(_s);bk=r(eje,"AutoConfig"),eje.forEach(t),bs=r(ps,", "),vs=n(ps,"A",{href:!0});var oje=s(vs);vk=r(oje,"AutoModel"),oje.forEach(t),$d=r(ps,`, and
`),Fs=n(ps,"A",{href:!0});var rje=s(Fs);Fk=r(rje,"AutoTokenizer"),rje.forEach(t),kd=r(ps," will directly create a class of the relevant architecture. For instance"),ps.forEach(t),rg=i(c),T(ln.$$.fragment,c),Ke=i(c),ye=n(c,"P",{});var uN=s(ye);Gq=r(uN,"will create a model that is an instance of "),Sd=n(uN,"A",{href:!0});var tje=s(Sd);Oq=r(tje,"BertModel"),tje.forEach(t),Vq=r(uN,"."),uN.forEach(t),Po=i(c),dn=n(c,"P",{});var pN=s(dn);Xq=r(pN,"There is one class of "),tg=n(pN,"CODE",{});var aje=s(tg);zq=r(aje,"AutoModel"),aje.forEach(t),Xfo=r(pN," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),pN.forEach(t),Zlo=i(c),Rd=n(c,"H2",{class:!0});var _N=s(Rd);ag=n(_N,"A",{id:!0,class:!0,href:!0});var nje=s(ag);khe=n(nje,"SPAN",{});var sje=s(khe);T(Tk.$$.fragment,sje),sje.forEach(t),nje.forEach(t),zfo=i(_N),She=n(_N,"SPAN",{});var lje=s(She);Qfo=r(lje,"Extending the Auto Classes"),lje.forEach(t),_N.forEach(t),Klo=i(c),Ts=n(c,"P",{});var Yf=s(Ts);Wfo=r(Yf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),Rhe=n(Yf,"CODE",{});var ije=s(Rhe);Ufo=r(ije,"NewModel"),ije.forEach(t),Hfo=r(Yf,", make sure you have a "),Phe=n(Yf,"CODE",{});var dje=s(Phe);Jfo=r(dje,"NewModelConfig"),dje.forEach(t),Yfo=r(Yf,` then you can add those to the auto
classes like this:`),Yf.forEach(t),eio=i(c),T(Mk.$$.fragment,c),oio=i(c),Qq=n(c,"P",{});var mje=s(Qq);Zfo=r(mje,"You will then be able to use the auto classes like you would usually do!"),mje.forEach(t),rio=i(c),T(ng.$$.fragment,c),tio=i(c),Pd=n(c,"H2",{class:!0});var bN=s(Pd);sg=n(bN,"A",{id:!0,class:!0,href:!0});var cje=s(sg);Bhe=n(cje,"SPAN",{});var fje=s(Bhe);T(Ek.$$.fragment,fje),fje.forEach(t),cje.forEach(t),Kfo=i(bN),Ihe=n(bN,"SPAN",{});var gje=s(Ihe);ego=r(gje,"AutoConfig"),gje.forEach(t),bN.forEach(t),aio=i(c),Bo=n(c,"DIV",{class:!0});var Et=s(Bo);T(Ck.$$.fragment,Et),ogo=i(Et),wk=n(Et,"P",{});var vN=s(wk);rgo=r(vN,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),Wq=n(vN,"A",{href:!0});var hje=s(Wq);tgo=r(hje,"from_pretrained()"),hje.forEach(t),ago=r(vN," class method."),vN.forEach(t),ngo=i(Et),Ak=n(Et,"P",{});var FN=s(Ak);sgo=r(FN,"This class cannot be instantiated directly using "),Nhe=n(FN,"CODE",{});var uje=s(Nhe);lgo=r(uje,"__init__()"),uje.forEach(t),igo=r(FN," (throws an error)."),FN.forEach(t),dgo=i(Et),Vr=n(Et,"DIV",{class:!0});var Ct=s(Vr);T(Lk.$$.fragment,Ct),mgo=i(Ct),qhe=n(Ct,"P",{});var pje=s(qhe);cgo=r(pje,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),pje.forEach(t),fgo=i(Ct),Bd=n(Ct,"P",{});var Zf=s(Bd);ggo=r(Zf,"The configuration class to instantiate is selected based on the "),jhe=n(Zf,"CODE",{});var _je=s(jhe);hgo=r(_je,"model_type"),_je.forEach(t),ugo=r(Zf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Dhe=n(Zf,"CODE",{});var bje=s(Dhe);pgo=r(bje,"pretrained_model_name_or_path"),bje.forEach(t),_go=r(Zf,":"),Zf.forEach(t),bgo=i(Ct),A=n(Ct,"UL",{});var L=s(A);lg=n(L,"LI",{});var B9=s(lg);Ghe=n(B9,"STRONG",{});var vje=s(Ghe);vgo=r(vje,"albert"),vje.forEach(t),Fgo=r(B9," \u2014 "),Uq=n(B9,"A",{href:!0});var Fje=s(Uq);Tgo=r(Fje,"AlbertConfig"),Fje.forEach(t),Mgo=r(B9," (ALBERT model)"),B9.forEach(t),Ego=i(L),ig=n(L,"LI",{});var I9=s(ig);Ohe=n(I9,"STRONG",{});var Tje=s(Ohe);Cgo=r(Tje,"bart"),Tje.forEach(t),wgo=r(I9," \u2014 "),Hq=n(I9,"A",{href:!0});var Mje=s(Hq);Ago=r(Mje,"BartConfig"),Mje.forEach(t),Lgo=r(I9," (BART model)"),I9.forEach(t),ygo=i(L),dg=n(L,"LI",{});var N9=s(dg);Vhe=n(N9,"STRONG",{});var Eje=s(Vhe);xgo=r(Eje,"beit"),Eje.forEach(t),$go=r(N9," \u2014 "),Jq=n(N9,"A",{href:!0});var Cje=s(Jq);kgo=r(Cje,"BeitConfig"),Cje.forEach(t),Sgo=r(N9," (BEiT model)"),N9.forEach(t),Rgo=i(L),mg=n(L,"LI",{});var q9=s(mg);Xhe=n(q9,"STRONG",{});var wje=s(Xhe);Pgo=r(wje,"bert"),wje.forEach(t),Bgo=r(q9," \u2014 "),Yq=n(q9,"A",{href:!0});var Aje=s(Yq);Igo=r(Aje,"BertConfig"),Aje.forEach(t),Ngo=r(q9," (BERT model)"),q9.forEach(t),qgo=i(L),cg=n(L,"LI",{});var j9=s(cg);zhe=n(j9,"STRONG",{});var Lje=s(zhe);jgo=r(Lje,"bert-generation"),Lje.forEach(t),Dgo=r(j9," \u2014 "),Zq=n(j9,"A",{href:!0});var yje=s(Zq);Ggo=r(yje,"BertGenerationConfig"),yje.forEach(t),Ogo=r(j9," (Bert Generation model)"),j9.forEach(t),Vgo=i(L),fg=n(L,"LI",{});var D9=s(fg);Qhe=n(D9,"STRONG",{});var xje=s(Qhe);Xgo=r(xje,"big_bird"),xje.forEach(t),zgo=r(D9," \u2014 "),Kq=n(D9,"A",{href:!0});var $je=s(Kq);Qgo=r($je,"BigBirdConfig"),$je.forEach(t),Wgo=r(D9," (BigBird model)"),D9.forEach(t),Ugo=i(L),gg=n(L,"LI",{});var G9=s(gg);Whe=n(G9,"STRONG",{});var kje=s(Whe);Hgo=r(kje,"bigbird_pegasus"),kje.forEach(t),Jgo=r(G9," \u2014 "),ej=n(G9,"A",{href:!0});var Sje=s(ej);Ygo=r(Sje,"BigBirdPegasusConfig"),Sje.forEach(t),Zgo=r(G9," (BigBird-Pegasus model)"),G9.forEach(t),Kgo=i(L),hg=n(L,"LI",{});var O9=s(hg);Uhe=n(O9,"STRONG",{});var Rje=s(Uhe);eho=r(Rje,"blenderbot"),Rje.forEach(t),oho=r(O9," \u2014 "),oj=n(O9,"A",{href:!0});var Pje=s(oj);rho=r(Pje,"BlenderbotConfig"),Pje.forEach(t),tho=r(O9," (Blenderbot model)"),O9.forEach(t),aho=i(L),ug=n(L,"LI",{});var V9=s(ug);Hhe=n(V9,"STRONG",{});var Bje=s(Hhe);nho=r(Bje,"blenderbot-small"),Bje.forEach(t),sho=r(V9," \u2014 "),rj=n(V9,"A",{href:!0});var Ije=s(rj);lho=r(Ije,"BlenderbotSmallConfig"),Ije.forEach(t),iho=r(V9," (BlenderbotSmall model)"),V9.forEach(t),dho=i(L),pg=n(L,"LI",{});var X9=s(pg);Jhe=n(X9,"STRONG",{});var Nje=s(Jhe);mho=r(Nje,"bloom"),Nje.forEach(t),cho=r(X9," \u2014 "),tj=n(X9,"A",{href:!0});var qje=s(tj);fho=r(qje,"BloomConfig"),qje.forEach(t),gho=r(X9," (BLOOM model)"),X9.forEach(t),hho=i(L),_g=n(L,"LI",{});var z9=s(_g);Yhe=n(z9,"STRONG",{});var jje=s(Yhe);uho=r(jje,"camembert"),jje.forEach(t),pho=r(z9," \u2014 "),aj=n(z9,"A",{href:!0});var Dje=s(aj);_ho=r(Dje,"CamembertConfig"),Dje.forEach(t),bho=r(z9," (CamemBERT model)"),z9.forEach(t),vho=i(L),bg=n(L,"LI",{});var Q9=s(bg);Zhe=n(Q9,"STRONG",{});var Gje=s(Zhe);Fho=r(Gje,"canine"),Gje.forEach(t),Tho=r(Q9," \u2014 "),nj=n(Q9,"A",{href:!0});var Oje=s(nj);Mho=r(Oje,"CanineConfig"),Oje.forEach(t),Eho=r(Q9," (CANINE model)"),Q9.forEach(t),Cho=i(L),vg=n(L,"LI",{});var W9=s(vg);Khe=n(W9,"STRONG",{});var Vje=s(Khe);who=r(Vje,"clip"),Vje.forEach(t),Aho=r(W9," \u2014 "),sj=n(W9,"A",{href:!0});var Xje=s(sj);Lho=r(Xje,"CLIPConfig"),Xje.forEach(t),yho=r(W9," (CLIP model)"),W9.forEach(t),xho=i(L),Fg=n(L,"LI",{});var U9=s(Fg);eue=n(U9,"STRONG",{});var zje=s(eue);$ho=r(zje,"clipseg"),zje.forEach(t),kho=r(U9," \u2014 "),lj=n(U9,"A",{href:!0});var Qje=s(lj);Sho=r(Qje,"CLIPSegConfig"),Qje.forEach(t),Rho=r(U9," (CLIPSeg model)"),U9.forEach(t),Pho=i(L),Tg=n(L,"LI",{});var H9=s(Tg);oue=n(H9,"STRONG",{});var Wje=s(oue);Bho=r(Wje,"codegen"),Wje.forEach(t),Iho=r(H9," \u2014 "),ij=n(H9,"A",{href:!0});var Uje=s(ij);Nho=r(Uje,"CodeGenConfig"),Uje.forEach(t),qho=r(H9," (CodeGen model)"),H9.forEach(t),jho=i(L),Mg=n(L,"LI",{});var J9=s(Mg);rue=n(J9,"STRONG",{});var Hje=s(rue);Dho=r(Hje,"conditional_detr"),Hje.forEach(t),Gho=r(J9," \u2014 "),dj=n(J9,"A",{href:!0});var Jje=s(dj);Oho=r(Jje,"ConditionalDetrConfig"),Jje.forEach(t),Vho=r(J9," (Conditional DETR model)"),J9.forEach(t),Xho=i(L),Eg=n(L,"LI",{});var Y9=s(Eg);tue=n(Y9,"STRONG",{});var Yje=s(tue);zho=r(Yje,"convbert"),Yje.forEach(t),Qho=r(Y9," \u2014 "),mj=n(Y9,"A",{href:!0});var Zje=s(mj);Who=r(Zje,"ConvBertConfig"),Zje.forEach(t),Uho=r(Y9," (ConvBERT model)"),Y9.forEach(t),Hho=i(L),Cg=n(L,"LI",{});var Z9=s(Cg);aue=n(Z9,"STRONG",{});var Kje=s(aue);Jho=r(Kje,"convnext"),Kje.forEach(t),Yho=r(Z9," \u2014 "),cj=n(Z9,"A",{href:!0});var eDe=s(cj);Zho=r(eDe,"ConvNextConfig"),eDe.forEach(t),Kho=r(Z9," (ConvNeXT model)"),Z9.forEach(t),euo=i(L),wg=n(L,"LI",{});var K9=s(wg);nue=n(K9,"STRONG",{});var oDe=s(nue);ouo=r(oDe,"ctrl"),oDe.forEach(t),ruo=r(K9," \u2014 "),fj=n(K9,"A",{href:!0});var rDe=s(fj);tuo=r(rDe,"CTRLConfig"),rDe.forEach(t),auo=r(K9," (CTRL model)"),K9.forEach(t),nuo=i(L),Ag=n(L,"LI",{});var ex=s(Ag);sue=n(ex,"STRONG",{});var tDe=s(sue);suo=r(tDe,"cvt"),tDe.forEach(t),luo=r(ex," \u2014 "),gj=n(ex,"A",{href:!0});var aDe=s(gj);iuo=r(aDe,"CvtConfig"),aDe.forEach(t),duo=r(ex," (CvT model)"),ex.forEach(t),muo=i(L),Lg=n(L,"LI",{});var ox=s(Lg);lue=n(ox,"STRONG",{});var nDe=s(lue);cuo=r(nDe,"data2vec-audio"),nDe.forEach(t),fuo=r(ox," \u2014 "),hj=n(ox,"A",{href:!0});var sDe=s(hj);guo=r(sDe,"Data2VecAudioConfig"),sDe.forEach(t),huo=r(ox," (Data2VecAudio model)"),ox.forEach(t),uuo=i(L),yg=n(L,"LI",{});var rx=s(yg);iue=n(rx,"STRONG",{});var lDe=s(iue);puo=r(lDe,"data2vec-text"),lDe.forEach(t),_uo=r(rx," \u2014 "),uj=n(rx,"A",{href:!0});var iDe=s(uj);buo=r(iDe,"Data2VecTextConfig"),iDe.forEach(t),vuo=r(rx," (Data2VecText model)"),rx.forEach(t),Fuo=i(L),xg=n(L,"LI",{});var tx=s(xg);due=n(tx,"STRONG",{});var dDe=s(due);Tuo=r(dDe,"data2vec-vision"),dDe.forEach(t),Muo=r(tx," \u2014 "),pj=n(tx,"A",{href:!0});var mDe=s(pj);Euo=r(mDe,"Data2VecVisionConfig"),mDe.forEach(t),Cuo=r(tx," (Data2VecVision model)"),tx.forEach(t),wuo=i(L),$g=n(L,"LI",{});var ax=s($g);mue=n(ax,"STRONG",{});var cDe=s(mue);Auo=r(cDe,"deberta"),cDe.forEach(t),Luo=r(ax," \u2014 "),_j=n(ax,"A",{href:!0});var fDe=s(_j);yuo=r(fDe,"DebertaConfig"),fDe.forEach(t),xuo=r(ax," (DeBERTa model)"),ax.forEach(t),$uo=i(L),kg=n(L,"LI",{});var nx=s(kg);cue=n(nx,"STRONG",{});var gDe=s(cue);kuo=r(gDe,"deberta-v2"),gDe.forEach(t),Suo=r(nx," \u2014 "),bj=n(nx,"A",{href:!0});var hDe=s(bj);Ruo=r(hDe,"DebertaV2Config"),hDe.forEach(t),Puo=r(nx," (DeBERTa-v2 model)"),nx.forEach(t),Buo=i(L),Sg=n(L,"LI",{});var sx=s(Sg);fue=n(sx,"STRONG",{});var uDe=s(fue);Iuo=r(uDe,"decision_transformer"),uDe.forEach(t),Nuo=r(sx," \u2014 "),vj=n(sx,"A",{href:!0});var pDe=s(vj);quo=r(pDe,"DecisionTransformerConfig"),pDe.forEach(t),juo=r(sx," (Decision Transformer model)"),sx.forEach(t),Duo=i(L),Rg=n(L,"LI",{});var lx=s(Rg);gue=n(lx,"STRONG",{});var _De=s(gue);Guo=r(_De,"deformable_detr"),_De.forEach(t),Ouo=r(lx," \u2014 "),Fj=n(lx,"A",{href:!0});var bDe=s(Fj);Vuo=r(bDe,"DeformableDetrConfig"),bDe.forEach(t),Xuo=r(lx," (Deformable DETR model)"),lx.forEach(t),zuo=i(L),Pg=n(L,"LI",{});var ix=s(Pg);hue=n(ix,"STRONG",{});var vDe=s(hue);Quo=r(vDe,"deit"),vDe.forEach(t),Wuo=r(ix," \u2014 "),Tj=n(ix,"A",{href:!0});var FDe=s(Tj);Uuo=r(FDe,"DeiTConfig"),FDe.forEach(t),Huo=r(ix," (DeiT model)"),ix.forEach(t),Juo=i(L),Bg=n(L,"LI",{});var TDe=s(Bg);uue=n(TDe,"STRONG",{});var XSt=s(uue);Yuo=r(XSt,"detr"),XSt.forEach(t),Zuo=r(TDe," \u2014 "),Mj=n(TDe,"A",{href:!0});var zSt=s(Mj);Kuo=r(zSt,"DetrConfig"),zSt.forEach(t),epo=r(TDe," (DETR model)"),TDe.forEach(t),opo=i(L),Ig=n(L,"LI",{});var MDe=s(Ig);pue=n(MDe,"STRONG",{});var QSt=s(pue);rpo=r(QSt,"distilbert"),QSt.forEach(t),tpo=r(MDe," \u2014 "),Ej=n(MDe,"A",{href:!0});var WSt=s(Ej);apo=r(WSt,"DistilBertConfig"),WSt.forEach(t),npo=r(MDe," (DistilBERT model)"),MDe.forEach(t),spo=i(L),Ng=n(L,"LI",{});var EDe=s(Ng);_ue=n(EDe,"STRONG",{});var USt=s(_ue);lpo=r(USt,"donut-swin"),USt.forEach(t),ipo=r(EDe," \u2014 "),Cj=n(EDe,"A",{href:!0});var HSt=s(Cj);dpo=r(HSt,"DonutSwinConfig"),HSt.forEach(t),mpo=r(EDe," (DonutSwin model)"),EDe.forEach(t),cpo=i(L),qg=n(L,"LI",{});var CDe=s(qg);bue=n(CDe,"STRONG",{});var JSt=s(bue);fpo=r(JSt,"dpr"),JSt.forEach(t),gpo=r(CDe," \u2014 "),wj=n(CDe,"A",{href:!0});var YSt=s(wj);hpo=r(YSt,"DPRConfig"),YSt.forEach(t),upo=r(CDe," (DPR model)"),CDe.forEach(t),ppo=i(L),jg=n(L,"LI",{});var wDe=s(jg);vue=n(wDe,"STRONG",{});var ZSt=s(vue);_po=r(ZSt,"dpt"),ZSt.forEach(t),bpo=r(wDe," \u2014 "),Aj=n(wDe,"A",{href:!0});var KSt=s(Aj);vpo=r(KSt,"DPTConfig"),KSt.forEach(t),Fpo=r(wDe," (DPT model)"),wDe.forEach(t),Tpo=i(L),Dg=n(L,"LI",{});var ADe=s(Dg);Fue=n(ADe,"STRONG",{});var eRt=s(Fue);Mpo=r(eRt,"electra"),eRt.forEach(t),Epo=r(ADe," \u2014 "),Lj=n(ADe,"A",{href:!0});var oRt=s(Lj);Cpo=r(oRt,"ElectraConfig"),oRt.forEach(t),wpo=r(ADe," (ELECTRA model)"),ADe.forEach(t),Apo=i(L),Gg=n(L,"LI",{});var LDe=s(Gg);Tue=n(LDe,"STRONG",{});var rRt=s(Tue);Lpo=r(rRt,"encoder-decoder"),rRt.forEach(t),ypo=r(LDe," \u2014 "),yj=n(LDe,"A",{href:!0});var tRt=s(yj);xpo=r(tRt,"EncoderDecoderConfig"),tRt.forEach(t),$po=r(LDe," (Encoder decoder model)"),LDe.forEach(t),kpo=i(L),Og=n(L,"LI",{});var yDe=s(Og);Mue=n(yDe,"STRONG",{});var aRt=s(Mue);Spo=r(aRt,"ernie"),aRt.forEach(t),Rpo=r(yDe," \u2014 "),xj=n(yDe,"A",{href:!0});var nRt=s(xj);Ppo=r(nRt,"ErnieConfig"),nRt.forEach(t),Bpo=r(yDe," (ERNIE model)"),yDe.forEach(t),Ipo=i(L),Vg=n(L,"LI",{});var xDe=s(Vg);Eue=n(xDe,"STRONG",{});var sRt=s(Eue);Npo=r(sRt,"esm"),sRt.forEach(t),qpo=r(xDe," \u2014 "),$j=n(xDe,"A",{href:!0});var lRt=s($j);jpo=r(lRt,"EsmConfig"),lRt.forEach(t),Dpo=r(xDe," (ESM model)"),xDe.forEach(t),Gpo=i(L),Xg=n(L,"LI",{});var $De=s(Xg);Cue=n($De,"STRONG",{});var iRt=s(Cue);Opo=r(iRt,"flaubert"),iRt.forEach(t),Vpo=r($De," \u2014 "),kj=n($De,"A",{href:!0});var dRt=s(kj);Xpo=r(dRt,"FlaubertConfig"),dRt.forEach(t),zpo=r($De," (FlauBERT model)"),$De.forEach(t),Qpo=i(L),zg=n(L,"LI",{});var kDe=s(zg);wue=n(kDe,"STRONG",{});var mRt=s(wue);Wpo=r(mRt,"flava"),mRt.forEach(t),Upo=r(kDe," \u2014 "),Sj=n(kDe,"A",{href:!0});var cRt=s(Sj);Hpo=r(cRt,"FlavaConfig"),cRt.forEach(t),Jpo=r(kDe," (FLAVA model)"),kDe.forEach(t),Ypo=i(L),Qg=n(L,"LI",{});var SDe=s(Qg);Aue=n(SDe,"STRONG",{});var fRt=s(Aue);Zpo=r(fRt,"fnet"),fRt.forEach(t),Kpo=r(SDe," \u2014 "),Rj=n(SDe,"A",{href:!0});var gRt=s(Rj);e_o=r(gRt,"FNetConfig"),gRt.forEach(t),o_o=r(SDe," (FNet model)"),SDe.forEach(t),r_o=i(L),Wg=n(L,"LI",{});var RDe=s(Wg);Lue=n(RDe,"STRONG",{});var hRt=s(Lue);t_o=r(hRt,"fsmt"),hRt.forEach(t),a_o=r(RDe," \u2014 "),Pj=n(RDe,"A",{href:!0});var uRt=s(Pj);n_o=r(uRt,"FSMTConfig"),uRt.forEach(t),s_o=r(RDe," (FairSeq Machine-Translation model)"),RDe.forEach(t),l_o=i(L),Ug=n(L,"LI",{});var PDe=s(Ug);yue=n(PDe,"STRONG",{});var pRt=s(yue);i_o=r(pRt,"funnel"),pRt.forEach(t),d_o=r(PDe," \u2014 "),Bj=n(PDe,"A",{href:!0});var _Rt=s(Bj);m_o=r(_Rt,"FunnelConfig"),_Rt.forEach(t),c_o=r(PDe," (Funnel Transformer model)"),PDe.forEach(t),f_o=i(L),Hg=n(L,"LI",{});var BDe=s(Hg);xue=n(BDe,"STRONG",{});var bRt=s(xue);g_o=r(bRt,"glpn"),bRt.forEach(t),h_o=r(BDe," \u2014 "),Ij=n(BDe,"A",{href:!0});var vRt=s(Ij);u_o=r(vRt,"GLPNConfig"),vRt.forEach(t),p_o=r(BDe," (GLPN model)"),BDe.forEach(t),__o=i(L),Jg=n(L,"LI",{});var IDe=s(Jg);$ue=n(IDe,"STRONG",{});var FRt=s($ue);b_o=r(FRt,"gpt2"),FRt.forEach(t),v_o=r(IDe," \u2014 "),Nj=n(IDe,"A",{href:!0});var TRt=s(Nj);F_o=r(TRt,"GPT2Config"),TRt.forEach(t),T_o=r(IDe," (OpenAI GPT-2 model)"),IDe.forEach(t),M_o=i(L),Yg=n(L,"LI",{});var NDe=s(Yg);kue=n(NDe,"STRONG",{});var MRt=s(kue);E_o=r(MRt,"gpt_neo"),MRt.forEach(t),C_o=r(NDe," \u2014 "),qj=n(NDe,"A",{href:!0});var ERt=s(qj);w_o=r(ERt,"GPTNeoConfig"),ERt.forEach(t),A_o=r(NDe," (GPT Neo model)"),NDe.forEach(t),L_o=i(L),Zg=n(L,"LI",{});var qDe=s(Zg);Sue=n(qDe,"STRONG",{});var CRt=s(Sue);y_o=r(CRt,"gpt_neox"),CRt.forEach(t),x_o=r(qDe," \u2014 "),jj=n(qDe,"A",{href:!0});var wRt=s(jj);$_o=r(wRt,"GPTNeoXConfig"),wRt.forEach(t),k_o=r(qDe," (GPT NeoX model)"),qDe.forEach(t),S_o=i(L),Kg=n(L,"LI",{});var jDe=s(Kg);Rue=n(jDe,"STRONG",{});var ARt=s(Rue);R_o=r(ARt,"gpt_neox_japanese"),ARt.forEach(t),P_o=r(jDe," \u2014 "),Dj=n(jDe,"A",{href:!0});var LRt=s(Dj);B_o=r(LRt,"GPTNeoXJapaneseConfig"),LRt.forEach(t),I_o=r(jDe," (GPT NeoX Japanese model)"),jDe.forEach(t),N_o=i(L),eh=n(L,"LI",{});var DDe=s(eh);Pue=n(DDe,"STRONG",{});var yRt=s(Pue);q_o=r(yRt,"gptj"),yRt.forEach(t),j_o=r(DDe," \u2014 "),Gj=n(DDe,"A",{href:!0});var xRt=s(Gj);D_o=r(xRt,"GPTJConfig"),xRt.forEach(t),G_o=r(DDe," (GPT-J model)"),DDe.forEach(t),O_o=i(L),oh=n(L,"LI",{});var GDe=s(oh);Bue=n(GDe,"STRONG",{});var $Rt=s(Bue);V_o=r($Rt,"groupvit"),$Rt.forEach(t),X_o=r(GDe," \u2014 "),Oj=n(GDe,"A",{href:!0});var kRt=s(Oj);z_o=r(kRt,"GroupViTConfig"),kRt.forEach(t),Q_o=r(GDe," (GroupViT model)"),GDe.forEach(t),W_o=i(L),rh=n(L,"LI",{});var ODe=s(rh);Iue=n(ODe,"STRONG",{});var SRt=s(Iue);U_o=r(SRt,"hubert"),SRt.forEach(t),H_o=r(ODe," \u2014 "),Vj=n(ODe,"A",{href:!0});var RRt=s(Vj);J_o=r(RRt,"HubertConfig"),RRt.forEach(t),Y_o=r(ODe," (Hubert model)"),ODe.forEach(t),Z_o=i(L),th=n(L,"LI",{});var VDe=s(th);Nue=n(VDe,"STRONG",{});var PRt=s(Nue);K_o=r(PRt,"ibert"),PRt.forEach(t),e1o=r(VDe," \u2014 "),Xj=n(VDe,"A",{href:!0});var BRt=s(Xj);o1o=r(BRt,"IBertConfig"),BRt.forEach(t),r1o=r(VDe," (I-BERT model)"),VDe.forEach(t),t1o=i(L),ah=n(L,"LI",{});var XDe=s(ah);que=n(XDe,"STRONG",{});var IRt=s(que);a1o=r(IRt,"imagegpt"),IRt.forEach(t),n1o=r(XDe," \u2014 "),zj=n(XDe,"A",{href:!0});var NRt=s(zj);s1o=r(NRt,"ImageGPTConfig"),NRt.forEach(t),l1o=r(XDe," (ImageGPT model)"),XDe.forEach(t),i1o=i(L),nh=n(L,"LI",{});var zDe=s(nh);jue=n(zDe,"STRONG",{});var qRt=s(jue);d1o=r(qRt,"jukebox"),qRt.forEach(t),m1o=r(zDe," \u2014 "),Qj=n(zDe,"A",{href:!0});var jRt=s(Qj);c1o=r(jRt,"JukeboxConfig"),jRt.forEach(t),f1o=r(zDe," (Jukebox model)"),zDe.forEach(t),g1o=i(L),sh=n(L,"LI",{});var QDe=s(sh);Due=n(QDe,"STRONG",{});var DRt=s(Due);h1o=r(DRt,"layoutlm"),DRt.forEach(t),u1o=r(QDe," \u2014 "),Wj=n(QDe,"A",{href:!0});var GRt=s(Wj);p1o=r(GRt,"LayoutLMConfig"),GRt.forEach(t),_1o=r(QDe," (LayoutLM model)"),QDe.forEach(t),b1o=i(L),lh=n(L,"LI",{});var WDe=s(lh);Gue=n(WDe,"STRONG",{});var ORt=s(Gue);v1o=r(ORt,"layoutlmv2"),ORt.forEach(t),F1o=r(WDe," \u2014 "),Uj=n(WDe,"A",{href:!0});var VRt=s(Uj);T1o=r(VRt,"LayoutLMv2Config"),VRt.forEach(t),M1o=r(WDe," (LayoutLMv2 model)"),WDe.forEach(t),E1o=i(L),ih=n(L,"LI",{});var UDe=s(ih);Oue=n(UDe,"STRONG",{});var XRt=s(Oue);C1o=r(XRt,"layoutlmv3"),XRt.forEach(t),w1o=r(UDe," \u2014 "),Hj=n(UDe,"A",{href:!0});var zRt=s(Hj);A1o=r(zRt,"LayoutLMv3Config"),zRt.forEach(t),L1o=r(UDe," (LayoutLMv3 model)"),UDe.forEach(t),y1o=i(L),dh=n(L,"LI",{});var HDe=s(dh);Vue=n(HDe,"STRONG",{});var QRt=s(Vue);x1o=r(QRt,"led"),QRt.forEach(t),$1o=r(HDe," \u2014 "),Jj=n(HDe,"A",{href:!0});var WRt=s(Jj);k1o=r(WRt,"LEDConfig"),WRt.forEach(t),S1o=r(HDe," (LED model)"),HDe.forEach(t),R1o=i(L),mh=n(L,"LI",{});var JDe=s(mh);Xue=n(JDe,"STRONG",{});var URt=s(Xue);P1o=r(URt,"levit"),URt.forEach(t),B1o=r(JDe," \u2014 "),Yj=n(JDe,"A",{href:!0});var HRt=s(Yj);I1o=r(HRt,"LevitConfig"),HRt.forEach(t),N1o=r(JDe," (LeViT model)"),JDe.forEach(t),q1o=i(L),ch=n(L,"LI",{});var YDe=s(ch);zue=n(YDe,"STRONG",{});var JRt=s(zue);j1o=r(JRt,"lilt"),JRt.forEach(t),D1o=r(YDe," \u2014 "),Zj=n(YDe,"A",{href:!0});var YRt=s(Zj);G1o=r(YRt,"LiltConfig"),YRt.forEach(t),O1o=r(YDe," (LiLT model)"),YDe.forEach(t),V1o=i(L),fh=n(L,"LI",{});var ZDe=s(fh);Que=n(ZDe,"STRONG",{});var ZRt=s(Que);X1o=r(ZRt,"longformer"),ZRt.forEach(t),z1o=r(ZDe," \u2014 "),Kj=n(ZDe,"A",{href:!0});var KRt=s(Kj);Q1o=r(KRt,"LongformerConfig"),KRt.forEach(t),W1o=r(ZDe," (Longformer model)"),ZDe.forEach(t),U1o=i(L),gh=n(L,"LI",{});var KDe=s(gh);Wue=n(KDe,"STRONG",{});var ePt=s(Wue);H1o=r(ePt,"longt5"),ePt.forEach(t),J1o=r(KDe," \u2014 "),eD=n(KDe,"A",{href:!0});var oPt=s(eD);Y1o=r(oPt,"LongT5Config"),oPt.forEach(t),Z1o=r(KDe," (LongT5 model)"),KDe.forEach(t),K1o=i(L),hh=n(L,"LI",{});var eGe=s(hh);Uue=n(eGe,"STRONG",{});var rPt=s(Uue);e2o=r(rPt,"luke"),rPt.forEach(t),o2o=r(eGe," \u2014 "),oD=n(eGe,"A",{href:!0});var tPt=s(oD);r2o=r(tPt,"LukeConfig"),tPt.forEach(t),t2o=r(eGe," (LUKE model)"),eGe.forEach(t),a2o=i(L),uh=n(L,"LI",{});var oGe=s(uh);Hue=n(oGe,"STRONG",{});var aPt=s(Hue);n2o=r(aPt,"lxmert"),aPt.forEach(t),s2o=r(oGe," \u2014 "),rD=n(oGe,"A",{href:!0});var nPt=s(rD);l2o=r(nPt,"LxmertConfig"),nPt.forEach(t),i2o=r(oGe," (LXMERT model)"),oGe.forEach(t),d2o=i(L),ph=n(L,"LI",{});var rGe=s(ph);Jue=n(rGe,"STRONG",{});var sPt=s(Jue);m2o=r(sPt,"m2m_100"),sPt.forEach(t),c2o=r(rGe," \u2014 "),tD=n(rGe,"A",{href:!0});var lPt=s(tD);f2o=r(lPt,"M2M100Config"),lPt.forEach(t),g2o=r(rGe," (M2M100 model)"),rGe.forEach(t),h2o=i(L),_h=n(L,"LI",{});var tGe=s(_h);Yue=n(tGe,"STRONG",{});var iPt=s(Yue);u2o=r(iPt,"marian"),iPt.forEach(t),p2o=r(tGe," \u2014 "),aD=n(tGe,"A",{href:!0});var dPt=s(aD);_2o=r(dPt,"MarianConfig"),dPt.forEach(t),b2o=r(tGe," (Marian model)"),tGe.forEach(t),v2o=i(L),bh=n(L,"LI",{});var aGe=s(bh);Zue=n(aGe,"STRONG",{});var mPt=s(Zue);F2o=r(mPt,"markuplm"),mPt.forEach(t),T2o=r(aGe," \u2014 "),nD=n(aGe,"A",{href:!0});var cPt=s(nD);M2o=r(cPt,"MarkupLMConfig"),cPt.forEach(t),E2o=r(aGe," (MarkupLM model)"),aGe.forEach(t),C2o=i(L),vh=n(L,"LI",{});var nGe=s(vh);Kue=n(nGe,"STRONG",{});var fPt=s(Kue);w2o=r(fPt,"maskformer"),fPt.forEach(t),A2o=r(nGe," \u2014 "),sD=n(nGe,"A",{href:!0});var gPt=s(sD);L2o=r(gPt,"MaskFormerConfig"),gPt.forEach(t),y2o=r(nGe," (MaskFormer model)"),nGe.forEach(t),x2o=i(L),Fh=n(L,"LI",{});var sGe=s(Fh);epe=n(sGe,"STRONG",{});var hPt=s(epe);$2o=r(hPt,"mbart"),hPt.forEach(t),k2o=r(sGe," \u2014 "),lD=n(sGe,"A",{href:!0});var uPt=s(lD);S2o=r(uPt,"MBartConfig"),uPt.forEach(t),R2o=r(sGe," (mBART model)"),sGe.forEach(t),P2o=i(L),Th=n(L,"LI",{});var lGe=s(Th);ope=n(lGe,"STRONG",{});var pPt=s(ope);B2o=r(pPt,"mctct"),pPt.forEach(t),I2o=r(lGe," \u2014 "),iD=n(lGe,"A",{href:!0});var _Pt=s(iD);N2o=r(_Pt,"MCTCTConfig"),_Pt.forEach(t),q2o=r(lGe," (M-CTC-T model)"),lGe.forEach(t),j2o=i(L),Mh=n(L,"LI",{});var iGe=s(Mh);rpe=n(iGe,"STRONG",{});var bPt=s(rpe);D2o=r(bPt,"megatron-bert"),bPt.forEach(t),G2o=r(iGe," \u2014 "),dD=n(iGe,"A",{href:!0});var vPt=s(dD);O2o=r(vPt,"MegatronBertConfig"),vPt.forEach(t),V2o=r(iGe," (Megatron-BERT model)"),iGe.forEach(t),X2o=i(L),Eh=n(L,"LI",{});var dGe=s(Eh);tpe=n(dGe,"STRONG",{});var FPt=s(tpe);z2o=r(FPt,"mobilebert"),FPt.forEach(t),Q2o=r(dGe," \u2014 "),mD=n(dGe,"A",{href:!0});var TPt=s(mD);W2o=r(TPt,"MobileBertConfig"),TPt.forEach(t),U2o=r(dGe," (MobileBERT model)"),dGe.forEach(t),H2o=i(L),Ch=n(L,"LI",{});var mGe=s(Ch);ape=n(mGe,"STRONG",{});var MPt=s(ape);J2o=r(MPt,"mobilenet_v2"),MPt.forEach(t),Y2o=r(mGe," \u2014 "),cD=n(mGe,"A",{href:!0});var EPt=s(cD);Z2o=r(EPt,"MobileNetV2Config"),EPt.forEach(t),K2o=r(mGe," (MobileNetV2 model)"),mGe.forEach(t),ebo=i(L),wh=n(L,"LI",{});var cGe=s(wh);npe=n(cGe,"STRONG",{});var CPt=s(npe);obo=r(CPt,"mobilevit"),CPt.forEach(t),rbo=r(cGe," \u2014 "),fD=n(cGe,"A",{href:!0});var wPt=s(fD);tbo=r(wPt,"MobileViTConfig"),wPt.forEach(t),abo=r(cGe," (MobileViT model)"),cGe.forEach(t),nbo=i(L),Ah=n(L,"LI",{});var fGe=s(Ah);spe=n(fGe,"STRONG",{});var APt=s(spe);sbo=r(APt,"mpnet"),APt.forEach(t),lbo=r(fGe," \u2014 "),gD=n(fGe,"A",{href:!0});var LPt=s(gD);ibo=r(LPt,"MPNetConfig"),LPt.forEach(t),dbo=r(fGe," (MPNet model)"),fGe.forEach(t),mbo=i(L),Lh=n(L,"LI",{});var gGe=s(Lh);lpe=n(gGe,"STRONG",{});var yPt=s(lpe);cbo=r(yPt,"mt5"),yPt.forEach(t),fbo=r(gGe," \u2014 "),hD=n(gGe,"A",{href:!0});var xPt=s(hD);gbo=r(xPt,"MT5Config"),xPt.forEach(t),hbo=r(gGe," (MT5 model)"),gGe.forEach(t),ubo=i(L),yh=n(L,"LI",{});var hGe=s(yh);ipe=n(hGe,"STRONG",{});var $Pt=s(ipe);pbo=r($Pt,"mvp"),$Pt.forEach(t),_bo=r(hGe," \u2014 "),uD=n(hGe,"A",{href:!0});var kPt=s(uD);bbo=r(kPt,"MvpConfig"),kPt.forEach(t),vbo=r(hGe," (MVP model)"),hGe.forEach(t),Fbo=i(L),xh=n(L,"LI",{});var uGe=s(xh);dpe=n(uGe,"STRONG",{});var SPt=s(dpe);Tbo=r(SPt,"nezha"),SPt.forEach(t),Mbo=r(uGe," \u2014 "),pD=n(uGe,"A",{href:!0});var RPt=s(pD);Ebo=r(RPt,"NezhaConfig"),RPt.forEach(t),Cbo=r(uGe," (Nezha model)"),uGe.forEach(t),wbo=i(L),$h=n(L,"LI",{});var pGe=s($h);mpe=n(pGe,"STRONG",{});var PPt=s(mpe);Abo=r(PPt,"nystromformer"),PPt.forEach(t),Lbo=r(pGe," \u2014 "),_D=n(pGe,"A",{href:!0});var BPt=s(_D);ybo=r(BPt,"NystromformerConfig"),BPt.forEach(t),xbo=r(pGe," (Nystr\xF6mformer model)"),pGe.forEach(t),$bo=i(L),kh=n(L,"LI",{});var _Ge=s(kh);cpe=n(_Ge,"STRONG",{});var IPt=s(cpe);kbo=r(IPt,"openai-gpt"),IPt.forEach(t),Sbo=r(_Ge," \u2014 "),bD=n(_Ge,"A",{href:!0});var NPt=s(bD);Rbo=r(NPt,"OpenAIGPTConfig"),NPt.forEach(t),Pbo=r(_Ge," (OpenAI GPT model)"),_Ge.forEach(t),Bbo=i(L),Sh=n(L,"LI",{});var bGe=s(Sh);fpe=n(bGe,"STRONG",{});var qPt=s(fpe);Ibo=r(qPt,"opt"),qPt.forEach(t),Nbo=r(bGe," \u2014 "),vD=n(bGe,"A",{href:!0});var jPt=s(vD);qbo=r(jPt,"OPTConfig"),jPt.forEach(t),jbo=r(bGe," (OPT model)"),bGe.forEach(t),Dbo=i(L),Rh=n(L,"LI",{});var vGe=s(Rh);gpe=n(vGe,"STRONG",{});var DPt=s(gpe);Gbo=r(DPt,"owlvit"),DPt.forEach(t),Obo=r(vGe," \u2014 "),FD=n(vGe,"A",{href:!0});var GPt=s(FD);Vbo=r(GPt,"OwlViTConfig"),GPt.forEach(t),Xbo=r(vGe," (OWL-ViT model)"),vGe.forEach(t),zbo=i(L),Ph=n(L,"LI",{});var FGe=s(Ph);hpe=n(FGe,"STRONG",{});var OPt=s(hpe);Qbo=r(OPt,"pegasus"),OPt.forEach(t),Wbo=r(FGe," \u2014 "),TD=n(FGe,"A",{href:!0});var VPt=s(TD);Ubo=r(VPt,"PegasusConfig"),VPt.forEach(t),Hbo=r(FGe," (Pegasus model)"),FGe.forEach(t),Jbo=i(L),Bh=n(L,"LI",{});var TGe=s(Bh);upe=n(TGe,"STRONG",{});var XPt=s(upe);Ybo=r(XPt,"pegasus_x"),XPt.forEach(t),Zbo=r(TGe," \u2014 "),MD=n(TGe,"A",{href:!0});var zPt=s(MD);Kbo=r(zPt,"PegasusXConfig"),zPt.forEach(t),evo=r(TGe," (PEGASUS-X model)"),TGe.forEach(t),ovo=i(L),Ih=n(L,"LI",{});var MGe=s(Ih);ppe=n(MGe,"STRONG",{});var QPt=s(ppe);rvo=r(QPt,"perceiver"),QPt.forEach(t),tvo=r(MGe," \u2014 "),ED=n(MGe,"A",{href:!0});var WPt=s(ED);avo=r(WPt,"PerceiverConfig"),WPt.forEach(t),nvo=r(MGe," (Perceiver model)"),MGe.forEach(t),svo=i(L),Nh=n(L,"LI",{});var EGe=s(Nh);_pe=n(EGe,"STRONG",{});var UPt=s(_pe);lvo=r(UPt,"plbart"),UPt.forEach(t),ivo=r(EGe," \u2014 "),CD=n(EGe,"A",{href:!0});var HPt=s(CD);dvo=r(HPt,"PLBartConfig"),HPt.forEach(t),mvo=r(EGe," (PLBart model)"),EGe.forEach(t),cvo=i(L),qh=n(L,"LI",{});var CGe=s(qh);bpe=n(CGe,"STRONG",{});var JPt=s(bpe);fvo=r(JPt,"poolformer"),JPt.forEach(t),gvo=r(CGe," \u2014 "),wD=n(CGe,"A",{href:!0});var YPt=s(wD);hvo=r(YPt,"PoolFormerConfig"),YPt.forEach(t),uvo=r(CGe," (PoolFormer model)"),CGe.forEach(t),pvo=i(L),jh=n(L,"LI",{});var wGe=s(jh);vpe=n(wGe,"STRONG",{});var ZPt=s(vpe);_vo=r(ZPt,"prophetnet"),ZPt.forEach(t),bvo=r(wGe," \u2014 "),AD=n(wGe,"A",{href:!0});var KPt=s(AD);vvo=r(KPt,"ProphetNetConfig"),KPt.forEach(t),Fvo=r(wGe," (ProphetNet model)"),wGe.forEach(t),Tvo=i(L),Dh=n(L,"LI",{});var AGe=s(Dh);Fpe=n(AGe,"STRONG",{});var eBt=s(Fpe);Mvo=r(eBt,"qdqbert"),eBt.forEach(t),Evo=r(AGe," \u2014 "),LD=n(AGe,"A",{href:!0});var oBt=s(LD);Cvo=r(oBt,"QDQBertConfig"),oBt.forEach(t),wvo=r(AGe," (QDQBert model)"),AGe.forEach(t),Avo=i(L),Gh=n(L,"LI",{});var LGe=s(Gh);Tpe=n(LGe,"STRONG",{});var rBt=s(Tpe);Lvo=r(rBt,"rag"),rBt.forEach(t),yvo=r(LGe," \u2014 "),yD=n(LGe,"A",{href:!0});var tBt=s(yD);xvo=r(tBt,"RagConfig"),tBt.forEach(t),$vo=r(LGe," (RAG model)"),LGe.forEach(t),kvo=i(L),Oh=n(L,"LI",{});var yGe=s(Oh);Mpe=n(yGe,"STRONG",{});var aBt=s(Mpe);Svo=r(aBt,"realm"),aBt.forEach(t),Rvo=r(yGe," \u2014 "),xD=n(yGe,"A",{href:!0});var nBt=s(xD);Pvo=r(nBt,"RealmConfig"),nBt.forEach(t),Bvo=r(yGe," (REALM model)"),yGe.forEach(t),Ivo=i(L),Vh=n(L,"LI",{});var xGe=s(Vh);Epe=n(xGe,"STRONG",{});var sBt=s(Epe);Nvo=r(sBt,"reformer"),sBt.forEach(t),qvo=r(xGe," \u2014 "),$D=n(xGe,"A",{href:!0});var lBt=s($D);jvo=r(lBt,"ReformerConfig"),lBt.forEach(t),Dvo=r(xGe," (Reformer model)"),xGe.forEach(t),Gvo=i(L),Xh=n(L,"LI",{});var $Ge=s(Xh);Cpe=n($Ge,"STRONG",{});var iBt=s(Cpe);Ovo=r(iBt,"regnet"),iBt.forEach(t),Vvo=r($Ge," \u2014 "),kD=n($Ge,"A",{href:!0});var dBt=s(kD);Xvo=r(dBt,"RegNetConfig"),dBt.forEach(t),zvo=r($Ge," (RegNet model)"),$Ge.forEach(t),Qvo=i(L),zh=n(L,"LI",{});var kGe=s(zh);wpe=n(kGe,"STRONG",{});var mBt=s(wpe);Wvo=r(mBt,"rembert"),mBt.forEach(t),Uvo=r(kGe," \u2014 "),SD=n(kGe,"A",{href:!0});var cBt=s(SD);Hvo=r(cBt,"RemBertConfig"),cBt.forEach(t),Jvo=r(kGe," (RemBERT model)"),kGe.forEach(t),Yvo=i(L),Qh=n(L,"LI",{});var SGe=s(Qh);Ape=n(SGe,"STRONG",{});var fBt=s(Ape);Zvo=r(fBt,"resnet"),fBt.forEach(t),Kvo=r(SGe," \u2014 "),RD=n(SGe,"A",{href:!0});var gBt=s(RD);eFo=r(gBt,"ResNetConfig"),gBt.forEach(t),oFo=r(SGe," (ResNet model)"),SGe.forEach(t),rFo=i(L),Wh=n(L,"LI",{});var RGe=s(Wh);Lpe=n(RGe,"STRONG",{});var hBt=s(Lpe);tFo=r(hBt,"retribert"),hBt.forEach(t),aFo=r(RGe," \u2014 "),PD=n(RGe,"A",{href:!0});var uBt=s(PD);nFo=r(uBt,"RetriBertConfig"),uBt.forEach(t),sFo=r(RGe," (RetriBERT model)"),RGe.forEach(t),lFo=i(L),Uh=n(L,"LI",{});var PGe=s(Uh);ype=n(PGe,"STRONG",{});var pBt=s(ype);iFo=r(pBt,"roberta"),pBt.forEach(t),dFo=r(PGe," \u2014 "),BD=n(PGe,"A",{href:!0});var _Bt=s(BD);mFo=r(_Bt,"RobertaConfig"),_Bt.forEach(t),cFo=r(PGe," (RoBERTa model)"),PGe.forEach(t),fFo=i(L),Hh=n(L,"LI",{});var BGe=s(Hh);xpe=n(BGe,"STRONG",{});var bBt=s(xpe);gFo=r(bBt,"roc_bert"),bBt.forEach(t),hFo=r(BGe," \u2014 "),ID=n(BGe,"A",{href:!0});var vBt=s(ID);uFo=r(vBt,"RoCBertConfig"),vBt.forEach(t),pFo=r(BGe," (RoCBert model)"),BGe.forEach(t),_Fo=i(L),Jh=n(L,"LI",{});var IGe=s(Jh);$pe=n(IGe,"STRONG",{});var FBt=s($pe);bFo=r(FBt,"roformer"),FBt.forEach(t),vFo=r(IGe," \u2014 "),ND=n(IGe,"A",{href:!0});var TBt=s(ND);FFo=r(TBt,"RoFormerConfig"),TBt.forEach(t),TFo=r(IGe," (RoFormer model)"),IGe.forEach(t),MFo=i(L),Yh=n(L,"LI",{});var NGe=s(Yh);kpe=n(NGe,"STRONG",{});var MBt=s(kpe);EFo=r(MBt,"segformer"),MBt.forEach(t),CFo=r(NGe," \u2014 "),qD=n(NGe,"A",{href:!0});var EBt=s(qD);wFo=r(EBt,"SegformerConfig"),EBt.forEach(t),AFo=r(NGe," (SegFormer model)"),NGe.forEach(t),LFo=i(L),Zh=n(L,"LI",{});var qGe=s(Zh);Spe=n(qGe,"STRONG",{});var CBt=s(Spe);yFo=r(CBt,"sew"),CBt.forEach(t),xFo=r(qGe," \u2014 "),jD=n(qGe,"A",{href:!0});var wBt=s(jD);$Fo=r(wBt,"SEWConfig"),wBt.forEach(t),kFo=r(qGe," (SEW model)"),qGe.forEach(t),SFo=i(L),Kh=n(L,"LI",{});var jGe=s(Kh);Rpe=n(jGe,"STRONG",{});var ABt=s(Rpe);RFo=r(ABt,"sew-d"),ABt.forEach(t),PFo=r(jGe," \u2014 "),DD=n(jGe,"A",{href:!0});var LBt=s(DD);BFo=r(LBt,"SEWDConfig"),LBt.forEach(t),IFo=r(jGe," (SEW-D model)"),jGe.forEach(t),NFo=i(L),eu=n(L,"LI",{});var DGe=s(eu);Ppe=n(DGe,"STRONG",{});var yBt=s(Ppe);qFo=r(yBt,"speech-encoder-decoder"),yBt.forEach(t),jFo=r(DGe," \u2014 "),GD=n(DGe,"A",{href:!0});var xBt=s(GD);DFo=r(xBt,"SpeechEncoderDecoderConfig"),xBt.forEach(t),GFo=r(DGe," (Speech Encoder decoder model)"),DGe.forEach(t),OFo=i(L),ou=n(L,"LI",{});var GGe=s(ou);Bpe=n(GGe,"STRONG",{});var $Bt=s(Bpe);VFo=r($Bt,"speech_to_text"),$Bt.forEach(t),XFo=r(GGe," \u2014 "),OD=n(GGe,"A",{href:!0});var kBt=s(OD);zFo=r(kBt,"Speech2TextConfig"),kBt.forEach(t),QFo=r(GGe," (Speech2Text model)"),GGe.forEach(t),WFo=i(L),ru=n(L,"LI",{});var OGe=s(ru);Ipe=n(OGe,"STRONG",{});var SBt=s(Ipe);UFo=r(SBt,"speech_to_text_2"),SBt.forEach(t),HFo=r(OGe," \u2014 "),VD=n(OGe,"A",{href:!0});var RBt=s(VD);JFo=r(RBt,"Speech2Text2Config"),RBt.forEach(t),YFo=r(OGe," (Speech2Text2 model)"),OGe.forEach(t),ZFo=i(L),tu=n(L,"LI",{});var VGe=s(tu);Npe=n(VGe,"STRONG",{});var PBt=s(Npe);KFo=r(PBt,"splinter"),PBt.forEach(t),eTo=r(VGe," \u2014 "),XD=n(VGe,"A",{href:!0});var BBt=s(XD);oTo=r(BBt,"SplinterConfig"),BBt.forEach(t),rTo=r(VGe," (Splinter model)"),VGe.forEach(t),tTo=i(L),au=n(L,"LI",{});var XGe=s(au);qpe=n(XGe,"STRONG",{});var IBt=s(qpe);aTo=r(IBt,"squeezebert"),IBt.forEach(t),nTo=r(XGe," \u2014 "),zD=n(XGe,"A",{href:!0});var NBt=s(zD);sTo=r(NBt,"SqueezeBertConfig"),NBt.forEach(t),lTo=r(XGe," (SqueezeBERT model)"),XGe.forEach(t),iTo=i(L),nu=n(L,"LI",{});var zGe=s(nu);jpe=n(zGe,"STRONG",{});var qBt=s(jpe);dTo=r(qBt,"swin"),qBt.forEach(t),mTo=r(zGe," \u2014 "),QD=n(zGe,"A",{href:!0});var jBt=s(QD);cTo=r(jBt,"SwinConfig"),jBt.forEach(t),fTo=r(zGe," (Swin Transformer model)"),zGe.forEach(t),gTo=i(L),su=n(L,"LI",{});var QGe=s(su);Dpe=n(QGe,"STRONG",{});var DBt=s(Dpe);hTo=r(DBt,"swinv2"),DBt.forEach(t),uTo=r(QGe," \u2014 "),WD=n(QGe,"A",{href:!0});var GBt=s(WD);pTo=r(GBt,"Swinv2Config"),GBt.forEach(t),_To=r(QGe," (Swin Transformer V2 model)"),QGe.forEach(t),bTo=i(L),lu=n(L,"LI",{});var WGe=s(lu);Gpe=n(WGe,"STRONG",{});var OBt=s(Gpe);vTo=r(OBt,"t5"),OBt.forEach(t),FTo=r(WGe," \u2014 "),UD=n(WGe,"A",{href:!0});var VBt=s(UD);TTo=r(VBt,"T5Config"),VBt.forEach(t),MTo=r(WGe," (T5 model)"),WGe.forEach(t),ETo=i(L),iu=n(L,"LI",{});var UGe=s(iu);Ope=n(UGe,"STRONG",{});var XBt=s(Ope);CTo=r(XBt,"table-transformer"),XBt.forEach(t),wTo=r(UGe," \u2014 "),HD=n(UGe,"A",{href:!0});var zBt=s(HD);ATo=r(zBt,"TableTransformerConfig"),zBt.forEach(t),LTo=r(UGe," (Table Transformer model)"),UGe.forEach(t),yTo=i(L),du=n(L,"LI",{});var HGe=s(du);Vpe=n(HGe,"STRONG",{});var QBt=s(Vpe);xTo=r(QBt,"tapas"),QBt.forEach(t),$To=r(HGe," \u2014 "),JD=n(HGe,"A",{href:!0});var WBt=s(JD);kTo=r(WBt,"TapasConfig"),WBt.forEach(t),STo=r(HGe," (TAPAS model)"),HGe.forEach(t),RTo=i(L),mu=n(L,"LI",{});var JGe=s(mu);Xpe=n(JGe,"STRONG",{});var UBt=s(Xpe);PTo=r(UBt,"time_series_transformer"),UBt.forEach(t),BTo=r(JGe," \u2014 "),YD=n(JGe,"A",{href:!0});var HBt=s(YD);ITo=r(HBt,"TimeSeriesTransformerConfig"),HBt.forEach(t),NTo=r(JGe," (Time Series Transformer model)"),JGe.forEach(t),qTo=i(L),cu=n(L,"LI",{});var YGe=s(cu);zpe=n(YGe,"STRONG",{});var JBt=s(zpe);jTo=r(JBt,"trajectory_transformer"),JBt.forEach(t),DTo=r(YGe," \u2014 "),ZD=n(YGe,"A",{href:!0});var YBt=s(ZD);GTo=r(YBt,"TrajectoryTransformerConfig"),YBt.forEach(t),OTo=r(YGe," (Trajectory Transformer model)"),YGe.forEach(t),VTo=i(L),fu=n(L,"LI",{});var ZGe=s(fu);Qpe=n(ZGe,"STRONG",{});var ZBt=s(Qpe);XTo=r(ZBt,"transfo-xl"),ZBt.forEach(t),zTo=r(ZGe," \u2014 "),KD=n(ZGe,"A",{href:!0});var KBt=s(KD);QTo=r(KBt,"TransfoXLConfig"),KBt.forEach(t),WTo=r(ZGe," (Transformer-XL model)"),ZGe.forEach(t),UTo=i(L),gu=n(L,"LI",{});var KGe=s(gu);Wpe=n(KGe,"STRONG",{});var eIt=s(Wpe);HTo=r(eIt,"trocr"),eIt.forEach(t),JTo=r(KGe," \u2014 "),eG=n(KGe,"A",{href:!0});var oIt=s(eG);YTo=r(oIt,"TrOCRConfig"),oIt.forEach(t),ZTo=r(KGe," (TrOCR model)"),KGe.forEach(t),KTo=i(L),hu=n(L,"LI",{});var eOe=s(hu);Upe=n(eOe,"STRONG",{});var rIt=s(Upe);eMo=r(rIt,"unispeech"),rIt.forEach(t),oMo=r(eOe," \u2014 "),oG=n(eOe,"A",{href:!0});var tIt=s(oG);rMo=r(tIt,"UniSpeechConfig"),tIt.forEach(t),tMo=r(eOe," (UniSpeech model)"),eOe.forEach(t),aMo=i(L),uu=n(L,"LI",{});var oOe=s(uu);Hpe=n(oOe,"STRONG",{});var aIt=s(Hpe);nMo=r(aIt,"unispeech-sat"),aIt.forEach(t),sMo=r(oOe," \u2014 "),rG=n(oOe,"A",{href:!0});var nIt=s(rG);lMo=r(nIt,"UniSpeechSatConfig"),nIt.forEach(t),iMo=r(oOe," (UniSpeechSat model)"),oOe.forEach(t),dMo=i(L),pu=n(L,"LI",{});var rOe=s(pu);Jpe=n(rOe,"STRONG",{});var sIt=s(Jpe);mMo=r(sIt,"van"),sIt.forEach(t),cMo=r(rOe," \u2014 "),tG=n(rOe,"A",{href:!0});var lIt=s(tG);fMo=r(lIt,"VanConfig"),lIt.forEach(t),gMo=r(rOe," (VAN model)"),rOe.forEach(t),hMo=i(L),_u=n(L,"LI",{});var tOe=s(_u);Ype=n(tOe,"STRONG",{});var iIt=s(Ype);uMo=r(iIt,"videomae"),iIt.forEach(t),pMo=r(tOe," \u2014 "),aG=n(tOe,"A",{href:!0});var dIt=s(aG);_Mo=r(dIt,"VideoMAEConfig"),dIt.forEach(t),bMo=r(tOe," (VideoMAE model)"),tOe.forEach(t),vMo=i(L),bu=n(L,"LI",{});var aOe=s(bu);Zpe=n(aOe,"STRONG",{});var mIt=s(Zpe);FMo=r(mIt,"vilt"),mIt.forEach(t),TMo=r(aOe," \u2014 "),nG=n(aOe,"A",{href:!0});var cIt=s(nG);MMo=r(cIt,"ViltConfig"),cIt.forEach(t),EMo=r(aOe," (ViLT model)"),aOe.forEach(t),CMo=i(L),vu=n(L,"LI",{});var nOe=s(vu);Kpe=n(nOe,"STRONG",{});var fIt=s(Kpe);wMo=r(fIt,"vision-encoder-decoder"),fIt.forEach(t),AMo=r(nOe," \u2014 "),sG=n(nOe,"A",{href:!0});var gIt=s(sG);LMo=r(gIt,"VisionEncoderDecoderConfig"),gIt.forEach(t),yMo=r(nOe," (Vision Encoder decoder model)"),nOe.forEach(t),xMo=i(L),Fu=n(L,"LI",{});var sOe=s(Fu);e_e=n(sOe,"STRONG",{});var hIt=s(e_e);$Mo=r(hIt,"vision-text-dual-encoder"),hIt.forEach(t),kMo=r(sOe," \u2014 "),lG=n(sOe,"A",{href:!0});var uIt=s(lG);SMo=r(uIt,"VisionTextDualEncoderConfig"),uIt.forEach(t),RMo=r(sOe," (VisionTextDualEncoder model)"),sOe.forEach(t),PMo=i(L),Tu=n(L,"LI",{});var lOe=s(Tu);o_e=n(lOe,"STRONG",{});var pIt=s(o_e);BMo=r(pIt,"visual_bert"),pIt.forEach(t),IMo=r(lOe," \u2014 "),iG=n(lOe,"A",{href:!0});var _It=s(iG);NMo=r(_It,"VisualBertConfig"),_It.forEach(t),qMo=r(lOe," (VisualBERT model)"),lOe.forEach(t),jMo=i(L),Mu=n(L,"LI",{});var iOe=s(Mu);r_e=n(iOe,"STRONG",{});var bIt=s(r_e);DMo=r(bIt,"vit"),bIt.forEach(t),GMo=r(iOe," \u2014 "),dG=n(iOe,"A",{href:!0});var vIt=s(dG);OMo=r(vIt,"ViTConfig"),vIt.forEach(t),VMo=r(iOe," (ViT model)"),iOe.forEach(t),XMo=i(L),Eu=n(L,"LI",{});var dOe=s(Eu);t_e=n(dOe,"STRONG",{});var FIt=s(t_e);zMo=r(FIt,"vit_mae"),FIt.forEach(t),QMo=r(dOe," \u2014 "),mG=n(dOe,"A",{href:!0});var TIt=s(mG);WMo=r(TIt,"ViTMAEConfig"),TIt.forEach(t),UMo=r(dOe," (ViTMAE model)"),dOe.forEach(t),HMo=i(L),Cu=n(L,"LI",{});var mOe=s(Cu);a_e=n(mOe,"STRONG",{});var MIt=s(a_e);JMo=r(MIt,"vit_msn"),MIt.forEach(t),YMo=r(mOe," \u2014 "),cG=n(mOe,"A",{href:!0});var EIt=s(cG);ZMo=r(EIt,"ViTMSNConfig"),EIt.forEach(t),KMo=r(mOe," (ViTMSN model)"),mOe.forEach(t),eEo=i(L),wu=n(L,"LI",{});var cOe=s(wu);n_e=n(cOe,"STRONG",{});var CIt=s(n_e);oEo=r(CIt,"wav2vec2"),CIt.forEach(t),rEo=r(cOe," \u2014 "),fG=n(cOe,"A",{href:!0});var wIt=s(fG);tEo=r(wIt,"Wav2Vec2Config"),wIt.forEach(t),aEo=r(cOe," (Wav2Vec2 model)"),cOe.forEach(t),nEo=i(L),Au=n(L,"LI",{});var fOe=s(Au);s_e=n(fOe,"STRONG",{});var AIt=s(s_e);sEo=r(AIt,"wav2vec2-conformer"),AIt.forEach(t),lEo=r(fOe," \u2014 "),gG=n(fOe,"A",{href:!0});var LIt=s(gG);iEo=r(LIt,"Wav2Vec2ConformerConfig"),LIt.forEach(t),dEo=r(fOe," (Wav2Vec2-Conformer model)"),fOe.forEach(t),mEo=i(L),Lu=n(L,"LI",{});var gOe=s(Lu);l_e=n(gOe,"STRONG",{});var yIt=s(l_e);cEo=r(yIt,"wavlm"),yIt.forEach(t),fEo=r(gOe," \u2014 "),hG=n(gOe,"A",{href:!0});var xIt=s(hG);gEo=r(xIt,"WavLMConfig"),xIt.forEach(t),hEo=r(gOe," (WavLM model)"),gOe.forEach(t),uEo=i(L),yu=n(L,"LI",{});var hOe=s(yu);i_e=n(hOe,"STRONG",{});var $It=s(i_e);pEo=r($It,"whisper"),$It.forEach(t),_Eo=r(hOe," \u2014 "),uG=n(hOe,"A",{href:!0});var kIt=s(uG);bEo=r(kIt,"WhisperConfig"),kIt.forEach(t),vEo=r(hOe," (Whisper model)"),hOe.forEach(t),FEo=i(L),xu=n(L,"LI",{});var uOe=s(xu);d_e=n(uOe,"STRONG",{});var SIt=s(d_e);TEo=r(SIt,"xclip"),SIt.forEach(t),MEo=r(uOe," \u2014 "),pG=n(uOe,"A",{href:!0});var RIt=s(pG);EEo=r(RIt,"XCLIPConfig"),RIt.forEach(t),CEo=r(uOe," (X-CLIP model)"),uOe.forEach(t),wEo=i(L),$u=n(L,"LI",{});var pOe=s($u);m_e=n(pOe,"STRONG",{});var PIt=s(m_e);AEo=r(PIt,"xglm"),PIt.forEach(t),LEo=r(pOe," \u2014 "),_G=n(pOe,"A",{href:!0});var BIt=s(_G);yEo=r(BIt,"XGLMConfig"),BIt.forEach(t),xEo=r(pOe," (XGLM model)"),pOe.forEach(t),$Eo=i(L),ku=n(L,"LI",{});var _Oe=s(ku);c_e=n(_Oe,"STRONG",{});var IIt=s(c_e);kEo=r(IIt,"xlm"),IIt.forEach(t),SEo=r(_Oe," \u2014 "),bG=n(_Oe,"A",{href:!0});var NIt=s(bG);REo=r(NIt,"XLMConfig"),NIt.forEach(t),PEo=r(_Oe," (XLM model)"),_Oe.forEach(t),BEo=i(L),Su=n(L,"LI",{});var bOe=s(Su);f_e=n(bOe,"STRONG",{});var qIt=s(f_e);IEo=r(qIt,"xlm-prophetnet"),qIt.forEach(t),NEo=r(bOe," \u2014 "),vG=n(bOe,"A",{href:!0});var jIt=s(vG);qEo=r(jIt,"XLMProphetNetConfig"),jIt.forEach(t),jEo=r(bOe," (XLM-ProphetNet model)"),bOe.forEach(t),DEo=i(L),Ru=n(L,"LI",{});var vOe=s(Ru);g_e=n(vOe,"STRONG",{});var DIt=s(g_e);GEo=r(DIt,"xlm-roberta"),DIt.forEach(t),OEo=r(vOe," \u2014 "),FG=n(vOe,"A",{href:!0});var GIt=s(FG);VEo=r(GIt,"XLMRobertaConfig"),GIt.forEach(t),XEo=r(vOe," (XLM-RoBERTa model)"),vOe.forEach(t),zEo=i(L),Pu=n(L,"LI",{});var FOe=s(Pu);h_e=n(FOe,"STRONG",{});var OIt=s(h_e);QEo=r(OIt,"xlm-roberta-xl"),OIt.forEach(t),WEo=r(FOe," \u2014 "),TG=n(FOe,"A",{href:!0});var VIt=s(TG);UEo=r(VIt,"XLMRobertaXLConfig"),VIt.forEach(t),HEo=r(FOe," (XLM-RoBERTa-XL model)"),FOe.forEach(t),JEo=i(L),Bu=n(L,"LI",{});var TOe=s(Bu);u_e=n(TOe,"STRONG",{});var XIt=s(u_e);YEo=r(XIt,"xlnet"),XIt.forEach(t),ZEo=r(TOe," \u2014 "),MG=n(TOe,"A",{href:!0});var zIt=s(MG);KEo=r(zIt,"XLNetConfig"),zIt.forEach(t),e4o=r(TOe," (XLNet model)"),TOe.forEach(t),o4o=i(L),Iu=n(L,"LI",{});var MOe=s(Iu);p_e=n(MOe,"STRONG",{});var QIt=s(p_e);r4o=r(QIt,"yolos"),QIt.forEach(t),t4o=r(MOe," \u2014 "),EG=n(MOe,"A",{href:!0});var WIt=s(EG);a4o=r(WIt,"YolosConfig"),WIt.forEach(t),n4o=r(MOe," (YOLOS model)"),MOe.forEach(t),s4o=i(L),Nu=n(L,"LI",{});var EOe=s(Nu);__e=n(EOe,"STRONG",{});var UIt=s(__e);l4o=r(UIt,"yoso"),UIt.forEach(t),i4o=r(EOe," \u2014 "),CG=n(EOe,"A",{href:!0});var HIt=s(CG);d4o=r(HIt,"YosoConfig"),HIt.forEach(t),m4o=r(EOe," (YOSO model)"),EOe.forEach(t),L.forEach(t),c4o=i(Ct),T(qu.$$.fragment,Ct),Ct.forEach(t),f4o=i(Et),ju=n(Et,"DIV",{class:!0});var bmo=s(ju);T(yk.$$.fragment,bmo),g4o=i(bmo),b_e=n(bmo,"P",{});var JIt=s(b_e);h4o=r(JIt,"Register a new configuration for this class."),JIt.forEach(t),bmo.forEach(t),Et.forEach(t),nio=i(c),Id=n(c,"H2",{class:!0});var vmo=s(Id);Du=n(vmo,"A",{id:!0,class:!0,href:!0});var YIt=s(Du);v_e=n(YIt,"SPAN",{});var ZIt=s(v_e);T(xk.$$.fragment,ZIt),ZIt.forEach(t),YIt.forEach(t),u4o=i(vmo),F_e=n(vmo,"SPAN",{});var KIt=s(F_e);p4o=r(KIt,"AutoTokenizer"),KIt.forEach(t),vmo.forEach(t),sio=i(c),Io=n(c,"DIV",{class:!0});var Ol=s(Io);T($k.$$.fragment,Ol),_4o=i(Ol),kk=n(Ol,"P",{});var Fmo=s(kk);b4o=r(Fmo,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),wG=n(Fmo,"A",{href:!0});var eNt=s(wG);v4o=r(eNt,"AutoTokenizer.from_pretrained()"),eNt.forEach(t),F4o=r(Fmo," class method."),Fmo.forEach(t),T4o=i(Ol),Sk=n(Ol,"P",{});var Tmo=s(Sk);M4o=r(Tmo,"This class cannot be instantiated directly using "),T_e=n(Tmo,"CODE",{});var oNt=s(T_e);E4o=r(oNt,"__init__()"),oNt.forEach(t),C4o=r(Tmo," (throws an error)."),Tmo.forEach(t),w4o=i(Ol),Xr=n(Ol,"DIV",{class:!0});var Vl=s(Xr);T(Rk.$$.fragment,Vl),A4o=i(Vl),M_e=n(Vl,"P",{});var rNt=s(M_e);L4o=r(rNt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),rNt.forEach(t),y4o=i(Vl),mn=n(Vl,"P",{});var dx=s(mn);x4o=r(dx,"The tokenizer class to instantiate is selected based on the "),E_e=n(dx,"CODE",{});var tNt=s(E_e);$4o=r(tNt,"model_type"),tNt.forEach(t),k4o=r(dx,` property of the config object (either
passed as an argument or loaded from `),C_e=n(dx,"CODE",{});var aNt=s(C_e);S4o=r(aNt,"pretrained_model_name_or_path"),aNt.forEach(t),R4o=r(dx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w_e=n(dx,"CODE",{});var nNt=s(w_e);P4o=r(nNt,"pretrained_model_name_or_path"),nNt.forEach(t),B4o=r(dx,":"),dx.forEach(t),I4o=i(Vl),k=n(Vl,"UL",{});var S=s(k);Ms=n(S,"LI",{});var TN=s(Ms);A_e=n(TN,"STRONG",{});var sNt=s(A_e);N4o=r(sNt,"albert"),sNt.forEach(t),q4o=r(TN," \u2014 "),AG=n(TN,"A",{href:!0});var lNt=s(AG);j4o=r(lNt,"AlbertTokenizer"),lNt.forEach(t),D4o=r(TN," or "),LG=n(TN,"A",{href:!0});var iNt=s(LG);G4o=r(iNt,"AlbertTokenizerFast"),iNt.forEach(t),O4o=r(TN," (ALBERT model)"),TN.forEach(t),V4o=i(S),Es=n(S,"LI",{});var MN=s(Es);L_e=n(MN,"STRONG",{});var dNt=s(L_e);X4o=r(dNt,"bart"),dNt.forEach(t),z4o=r(MN," \u2014 "),yG=n(MN,"A",{href:!0});var mNt=s(yG);Q4o=r(mNt,"BartTokenizer"),mNt.forEach(t),W4o=r(MN," or "),xG=n(MN,"A",{href:!0});var cNt=s(xG);U4o=r(cNt,"BartTokenizerFast"),cNt.forEach(t),H4o=r(MN," (BART model)"),MN.forEach(t),J4o=i(S),Cs=n(S,"LI",{});var EN=s(Cs);y_e=n(EN,"STRONG",{});var fNt=s(y_e);Y4o=r(fNt,"barthez"),fNt.forEach(t),Z4o=r(EN," \u2014 "),$G=n(EN,"A",{href:!0});var gNt=s($G);K4o=r(gNt,"BarthezTokenizer"),gNt.forEach(t),eCo=r(EN," or "),kG=n(EN,"A",{href:!0});var hNt=s(kG);oCo=r(hNt,"BarthezTokenizerFast"),hNt.forEach(t),rCo=r(EN," (BARThez model)"),EN.forEach(t),tCo=i(S),Gu=n(S,"LI",{});var COe=s(Gu);x_e=n(COe,"STRONG",{});var uNt=s(x_e);aCo=r(uNt,"bartpho"),uNt.forEach(t),nCo=r(COe," \u2014 "),SG=n(COe,"A",{href:!0});var pNt=s(SG);sCo=r(pNt,"BartphoTokenizer"),pNt.forEach(t),lCo=r(COe," (BARTpho model)"),COe.forEach(t),iCo=i(S),ws=n(S,"LI",{});var CN=s(ws);$_e=n(CN,"STRONG",{});var _Nt=s($_e);dCo=r(_Nt,"bert"),_Nt.forEach(t),mCo=r(CN," \u2014 "),RG=n(CN,"A",{href:!0});var bNt=s(RG);cCo=r(bNt,"BertTokenizer"),bNt.forEach(t),fCo=r(CN," or "),PG=n(CN,"A",{href:!0});var vNt=s(PG);gCo=r(vNt,"BertTokenizerFast"),vNt.forEach(t),hCo=r(CN," (BERT model)"),CN.forEach(t),uCo=i(S),Ou=n(S,"LI",{});var wOe=s(Ou);k_e=n(wOe,"STRONG",{});var FNt=s(k_e);pCo=r(FNt,"bert-generation"),FNt.forEach(t),_Co=r(wOe," \u2014 "),BG=n(wOe,"A",{href:!0});var TNt=s(BG);bCo=r(TNt,"BertGenerationTokenizer"),TNt.forEach(t),vCo=r(wOe," (Bert Generation model)"),wOe.forEach(t),FCo=i(S),Vu=n(S,"LI",{});var AOe=s(Vu);S_e=n(AOe,"STRONG",{});var MNt=s(S_e);TCo=r(MNt,"bert-japanese"),MNt.forEach(t),MCo=r(AOe," \u2014 "),IG=n(AOe,"A",{href:!0});var ENt=s(IG);ECo=r(ENt,"BertJapaneseTokenizer"),ENt.forEach(t),CCo=r(AOe," (BertJapanese model)"),AOe.forEach(t),wCo=i(S),Xu=n(S,"LI",{});var LOe=s(Xu);R_e=n(LOe,"STRONG",{});var CNt=s(R_e);ACo=r(CNt,"bertweet"),CNt.forEach(t),LCo=r(LOe," \u2014 "),NG=n(LOe,"A",{href:!0});var wNt=s(NG);yCo=r(wNt,"BertweetTokenizer"),wNt.forEach(t),xCo=r(LOe," (BERTweet model)"),LOe.forEach(t),$Co=i(S),As=n(S,"LI",{});var wN=s(As);P_e=n(wN,"STRONG",{});var ANt=s(P_e);kCo=r(ANt,"big_bird"),ANt.forEach(t),SCo=r(wN," \u2014 "),qG=n(wN,"A",{href:!0});var LNt=s(qG);RCo=r(LNt,"BigBirdTokenizer"),LNt.forEach(t),PCo=r(wN," or "),jG=n(wN,"A",{href:!0});var yNt=s(jG);BCo=r(yNt,"BigBirdTokenizerFast"),yNt.forEach(t),ICo=r(wN," (BigBird model)"),wN.forEach(t),NCo=i(S),Ls=n(S,"LI",{});var AN=s(Ls);B_e=n(AN,"STRONG",{});var xNt=s(B_e);qCo=r(xNt,"bigbird_pegasus"),xNt.forEach(t),jCo=r(AN," \u2014 "),DG=n(AN,"A",{href:!0});var $Nt=s(DG);DCo=r($Nt,"PegasusTokenizer"),$Nt.forEach(t),GCo=r(AN," or "),GG=n(AN,"A",{href:!0});var kNt=s(GG);OCo=r(kNt,"PegasusTokenizerFast"),kNt.forEach(t),VCo=r(AN," (BigBird-Pegasus model)"),AN.forEach(t),XCo=i(S),ys=n(S,"LI",{});var LN=s(ys);I_e=n(LN,"STRONG",{});var SNt=s(I_e);zCo=r(SNt,"blenderbot"),SNt.forEach(t),QCo=r(LN," \u2014 "),OG=n(LN,"A",{href:!0});var RNt=s(OG);WCo=r(RNt,"BlenderbotTokenizer"),RNt.forEach(t),UCo=r(LN," or "),VG=n(LN,"A",{href:!0});var PNt=s(VG);HCo=r(PNt,"BlenderbotTokenizerFast"),PNt.forEach(t),JCo=r(LN," (Blenderbot model)"),LN.forEach(t),YCo=i(S),zu=n(S,"LI",{});var yOe=s(zu);N_e=n(yOe,"STRONG",{});var BNt=s(N_e);ZCo=r(BNt,"blenderbot-small"),BNt.forEach(t),KCo=r(yOe," \u2014 "),XG=n(yOe,"A",{href:!0});var INt=s(XG);e3o=r(INt,"BlenderbotSmallTokenizer"),INt.forEach(t),o3o=r(yOe," (BlenderbotSmall model)"),yOe.forEach(t),r3o=i(S),Qu=n(S,"LI",{});var xOe=s(Qu);q_e=n(xOe,"STRONG",{});var NNt=s(q_e);t3o=r(NNt,"bloom"),NNt.forEach(t),a3o=r(xOe," \u2014 "),zG=n(xOe,"A",{href:!0});var qNt=s(zG);n3o=r(qNt,"BloomTokenizerFast"),qNt.forEach(t),s3o=r(xOe," (BLOOM model)"),xOe.forEach(t),l3o=i(S),Wu=n(S,"LI",{});var $Oe=s(Wu);j_e=n($Oe,"STRONG",{});var jNt=s(j_e);i3o=r(jNt,"byt5"),jNt.forEach(t),d3o=r($Oe," \u2014 "),QG=n($Oe,"A",{href:!0});var DNt=s(QG);m3o=r(DNt,"ByT5Tokenizer"),DNt.forEach(t),c3o=r($Oe," (ByT5 model)"),$Oe.forEach(t),f3o=i(S),xs=n(S,"LI",{});var yN=s(xs);D_e=n(yN,"STRONG",{});var GNt=s(D_e);g3o=r(GNt,"camembert"),GNt.forEach(t),h3o=r(yN," \u2014 "),WG=n(yN,"A",{href:!0});var ONt=s(WG);u3o=r(ONt,"CamembertTokenizer"),ONt.forEach(t),p3o=r(yN," or "),UG=n(yN,"A",{href:!0});var VNt=s(UG);_3o=r(VNt,"CamembertTokenizerFast"),VNt.forEach(t),b3o=r(yN," (CamemBERT model)"),yN.forEach(t),v3o=i(S),Uu=n(S,"LI",{});var kOe=s(Uu);G_e=n(kOe,"STRONG",{});var XNt=s(G_e);F3o=r(XNt,"canine"),XNt.forEach(t),T3o=r(kOe," \u2014 "),HG=n(kOe,"A",{href:!0});var zNt=s(HG);M3o=r(zNt,"CanineTokenizer"),zNt.forEach(t),E3o=r(kOe," (CANINE model)"),kOe.forEach(t),C3o=i(S),$s=n(S,"LI",{});var xN=s($s);O_e=n(xN,"STRONG",{});var QNt=s(O_e);w3o=r(QNt,"clip"),QNt.forEach(t),A3o=r(xN," \u2014 "),JG=n(xN,"A",{href:!0});var WNt=s(JG);L3o=r(WNt,"CLIPTokenizer"),WNt.forEach(t),y3o=r(xN," or "),YG=n(xN,"A",{href:!0});var UNt=s(YG);x3o=r(UNt,"CLIPTokenizerFast"),UNt.forEach(t),$3o=r(xN," (CLIP model)"),xN.forEach(t),k3o=i(S),ks=n(S,"LI",{});var $N=s(ks);V_e=n($N,"STRONG",{});var HNt=s(V_e);S3o=r(HNt,"clipseg"),HNt.forEach(t),R3o=r($N," \u2014 "),ZG=n($N,"A",{href:!0});var JNt=s(ZG);P3o=r(JNt,"CLIPTokenizer"),JNt.forEach(t),B3o=r($N," or "),KG=n($N,"A",{href:!0});var YNt=s(KG);I3o=r(YNt,"CLIPTokenizerFast"),YNt.forEach(t),N3o=r($N," (CLIPSeg model)"),$N.forEach(t),q3o=i(S),Ss=n(S,"LI",{});var kN=s(Ss);X_e=n(kN,"STRONG",{});var ZNt=s(X_e);j3o=r(ZNt,"codegen"),ZNt.forEach(t),D3o=r(kN," \u2014 "),eO=n(kN,"A",{href:!0});var KNt=s(eO);G3o=r(KNt,"CodeGenTokenizer"),KNt.forEach(t),O3o=r(kN," or "),oO=n(kN,"A",{href:!0});var eqt=s(oO);V3o=r(eqt,"CodeGenTokenizerFast"),eqt.forEach(t),X3o=r(kN," (CodeGen model)"),kN.forEach(t),z3o=i(S),Rs=n(S,"LI",{});var SN=s(Rs);z_e=n(SN,"STRONG",{});var oqt=s(z_e);Q3o=r(oqt,"convbert"),oqt.forEach(t),W3o=r(SN," \u2014 "),rO=n(SN,"A",{href:!0});var rqt=s(rO);U3o=r(rqt,"ConvBertTokenizer"),rqt.forEach(t),H3o=r(SN," or "),tO=n(SN,"A",{href:!0});var tqt=s(tO);J3o=r(tqt,"ConvBertTokenizerFast"),tqt.forEach(t),Y3o=r(SN," (ConvBERT model)"),SN.forEach(t),Z3o=i(S),Ps=n(S,"LI",{});var RN=s(Ps);Q_e=n(RN,"STRONG",{});var aqt=s(Q_e);K3o=r(aqt,"cpm"),aqt.forEach(t),e5o=r(RN," \u2014 "),aO=n(RN,"A",{href:!0});var nqt=s(aO);o5o=r(nqt,"CpmTokenizer"),nqt.forEach(t),r5o=r(RN," or "),nO=n(RN,"A",{href:!0});var sqt=s(nO);t5o=r(sqt,"CpmTokenizerFast"),sqt.forEach(t),a5o=r(RN," (CPM model)"),RN.forEach(t),n5o=i(S),Hu=n(S,"LI",{});var SOe=s(Hu);W_e=n(SOe,"STRONG",{});var lqt=s(W_e);s5o=r(lqt,"ctrl"),lqt.forEach(t),l5o=r(SOe," \u2014 "),sO=n(SOe,"A",{href:!0});var iqt=s(sO);i5o=r(iqt,"CTRLTokenizer"),iqt.forEach(t),d5o=r(SOe," (CTRL model)"),SOe.forEach(t),m5o=i(S),Bs=n(S,"LI",{});var PN=s(Bs);U_e=n(PN,"STRONG",{});var dqt=s(U_e);c5o=r(dqt,"data2vec-text"),dqt.forEach(t),f5o=r(PN," \u2014 "),lO=n(PN,"A",{href:!0});var mqt=s(lO);g5o=r(mqt,"RobertaTokenizer"),mqt.forEach(t),h5o=r(PN," or "),iO=n(PN,"A",{href:!0});var cqt=s(iO);u5o=r(cqt,"RobertaTokenizerFast"),cqt.forEach(t),p5o=r(PN," (Data2VecText model)"),PN.forEach(t),_5o=i(S),Is=n(S,"LI",{});var BN=s(Is);H_e=n(BN,"STRONG",{});var fqt=s(H_e);b5o=r(fqt,"deberta"),fqt.forEach(t),v5o=r(BN," \u2014 "),dO=n(BN,"A",{href:!0});var gqt=s(dO);F5o=r(gqt,"DebertaTokenizer"),gqt.forEach(t),T5o=r(BN," or "),mO=n(BN,"A",{href:!0});var hqt=s(mO);M5o=r(hqt,"DebertaTokenizerFast"),hqt.forEach(t),E5o=r(BN," (DeBERTa model)"),BN.forEach(t),C5o=i(S),Ns=n(S,"LI",{});var IN=s(Ns);J_e=n(IN,"STRONG",{});var uqt=s(J_e);w5o=r(uqt,"deberta-v2"),uqt.forEach(t),A5o=r(IN," \u2014 "),cO=n(IN,"A",{href:!0});var pqt=s(cO);L5o=r(pqt,"DebertaV2Tokenizer"),pqt.forEach(t),y5o=r(IN," or "),fO=n(IN,"A",{href:!0});var _qt=s(fO);x5o=r(_qt,"DebertaV2TokenizerFast"),_qt.forEach(t),$5o=r(IN," (DeBERTa-v2 model)"),IN.forEach(t),k5o=i(S),qs=n(S,"LI",{});var NN=s(qs);Y_e=n(NN,"STRONG",{});var bqt=s(Y_e);S5o=r(bqt,"distilbert"),bqt.forEach(t),R5o=r(NN," \u2014 "),gO=n(NN,"A",{href:!0});var vqt=s(gO);P5o=r(vqt,"DistilBertTokenizer"),vqt.forEach(t),B5o=r(NN," or "),hO=n(NN,"A",{href:!0});var Fqt=s(hO);I5o=r(Fqt,"DistilBertTokenizerFast"),Fqt.forEach(t),N5o=r(NN," (DistilBERT model)"),NN.forEach(t),q5o=i(S),js=n(S,"LI",{});var qN=s(js);Z_e=n(qN,"STRONG",{});var Tqt=s(Z_e);j5o=r(Tqt,"dpr"),Tqt.forEach(t),D5o=r(qN," \u2014 "),uO=n(qN,"A",{href:!0});var Mqt=s(uO);G5o=r(Mqt,"DPRQuestionEncoderTokenizer"),Mqt.forEach(t),O5o=r(qN," or "),pO=n(qN,"A",{href:!0});var Eqt=s(pO);V5o=r(Eqt,"DPRQuestionEncoderTokenizerFast"),Eqt.forEach(t),X5o=r(qN," (DPR model)"),qN.forEach(t),z5o=i(S),Ds=n(S,"LI",{});var jN=s(Ds);K_e=n(jN,"STRONG",{});var Cqt=s(K_e);Q5o=r(Cqt,"electra"),Cqt.forEach(t),W5o=r(jN," \u2014 "),_O=n(jN,"A",{href:!0});var wqt=s(_O);U5o=r(wqt,"ElectraTokenizer"),wqt.forEach(t),H5o=r(jN," or "),bO=n(jN,"A",{href:!0});var Aqt=s(bO);J5o=r(Aqt,"ElectraTokenizerFast"),Aqt.forEach(t),Y5o=r(jN," (ELECTRA model)"),jN.forEach(t),Z5o=i(S),Gs=n(S,"LI",{});var DN=s(Gs);e1e=n(DN,"STRONG",{});var Lqt=s(e1e);K5o=r(Lqt,"ernie"),Lqt.forEach(t),e0o=r(DN," \u2014 "),vO=n(DN,"A",{href:!0});var yqt=s(vO);o0o=r(yqt,"BertTokenizer"),yqt.forEach(t),r0o=r(DN," or "),FO=n(DN,"A",{href:!0});var xqt=s(FO);t0o=r(xqt,"BertTokenizerFast"),xqt.forEach(t),a0o=r(DN," (ERNIE model)"),DN.forEach(t),n0o=i(S),Ju=n(S,"LI",{});var ROe=s(Ju);o1e=n(ROe,"STRONG",{});var $qt=s(o1e);s0o=r($qt,"esm"),$qt.forEach(t),l0o=r(ROe," \u2014 "),TO=n(ROe,"A",{href:!0});var kqt=s(TO);i0o=r(kqt,"EsmTokenizer"),kqt.forEach(t),d0o=r(ROe," (ESM model)"),ROe.forEach(t),m0o=i(S),Yu=n(S,"LI",{});var POe=s(Yu);r1e=n(POe,"STRONG",{});var Sqt=s(r1e);c0o=r(Sqt,"flaubert"),Sqt.forEach(t),f0o=r(POe," \u2014 "),MO=n(POe,"A",{href:!0});var Rqt=s(MO);g0o=r(Rqt,"FlaubertTokenizer"),Rqt.forEach(t),h0o=r(POe," (FlauBERT model)"),POe.forEach(t),u0o=i(S),Os=n(S,"LI",{});var GN=s(Os);t1e=n(GN,"STRONG",{});var Pqt=s(t1e);p0o=r(Pqt,"fnet"),Pqt.forEach(t),_0o=r(GN," \u2014 "),EO=n(GN,"A",{href:!0});var Bqt=s(EO);b0o=r(Bqt,"FNetTokenizer"),Bqt.forEach(t),v0o=r(GN," or "),CO=n(GN,"A",{href:!0});var Iqt=s(CO);F0o=r(Iqt,"FNetTokenizerFast"),Iqt.forEach(t),T0o=r(GN," (FNet model)"),GN.forEach(t),M0o=i(S),Zu=n(S,"LI",{});var BOe=s(Zu);a1e=n(BOe,"STRONG",{});var Nqt=s(a1e);E0o=r(Nqt,"fsmt"),Nqt.forEach(t),C0o=r(BOe," \u2014 "),wO=n(BOe,"A",{href:!0});var qqt=s(wO);w0o=r(qqt,"FSMTTokenizer"),qqt.forEach(t),A0o=r(BOe," (FairSeq Machine-Translation model)"),BOe.forEach(t),L0o=i(S),Vs=n(S,"LI",{});var ON=s(Vs);n1e=n(ON,"STRONG",{});var jqt=s(n1e);y0o=r(jqt,"funnel"),jqt.forEach(t),x0o=r(ON," \u2014 "),AO=n(ON,"A",{href:!0});var Dqt=s(AO);$0o=r(Dqt,"FunnelTokenizer"),Dqt.forEach(t),k0o=r(ON," or "),LO=n(ON,"A",{href:!0});var Gqt=s(LO);S0o=r(Gqt,"FunnelTokenizerFast"),Gqt.forEach(t),R0o=r(ON," (Funnel Transformer model)"),ON.forEach(t),P0o=i(S),Xs=n(S,"LI",{});var VN=s(Xs);s1e=n(VN,"STRONG",{});var Oqt=s(s1e);B0o=r(Oqt,"gpt2"),Oqt.forEach(t),I0o=r(VN," \u2014 "),yO=n(VN,"A",{href:!0});var Vqt=s(yO);N0o=r(Vqt,"GPT2Tokenizer"),Vqt.forEach(t),q0o=r(VN," or "),xO=n(VN,"A",{href:!0});var Xqt=s(xO);j0o=r(Xqt,"GPT2TokenizerFast"),Xqt.forEach(t),D0o=r(VN," (OpenAI GPT-2 model)"),VN.forEach(t),G0o=i(S),zs=n(S,"LI",{});var XN=s(zs);l1e=n(XN,"STRONG",{});var zqt=s(l1e);O0o=r(zqt,"gpt_neo"),zqt.forEach(t),V0o=r(XN," \u2014 "),$O=n(XN,"A",{href:!0});var Qqt=s($O);X0o=r(Qqt,"GPT2Tokenizer"),Qqt.forEach(t),z0o=r(XN," or "),kO=n(XN,"A",{href:!0});var Wqt=s(kO);Q0o=r(Wqt,"GPT2TokenizerFast"),Wqt.forEach(t),W0o=r(XN," (GPT Neo model)"),XN.forEach(t),U0o=i(S),Ku=n(S,"LI",{});var IOe=s(Ku);i1e=n(IOe,"STRONG",{});var Uqt=s(i1e);H0o=r(Uqt,"gpt_neox"),Uqt.forEach(t),J0o=r(IOe," \u2014 "),SO=n(IOe,"A",{href:!0});var Hqt=s(SO);Y0o=r(Hqt,"GPTNeoXTokenizerFast"),Hqt.forEach(t),Z0o=r(IOe," (GPT NeoX model)"),IOe.forEach(t),K0o=i(S),ep=n(S,"LI",{});var NOe=s(ep);d1e=n(NOe,"STRONG",{});var Jqt=s(d1e);ewo=r(Jqt,"gpt_neox_japanese"),Jqt.forEach(t),owo=r(NOe," \u2014 "),RO=n(NOe,"A",{href:!0});var Yqt=s(RO);rwo=r(Yqt,"GPTNeoXJapaneseTokenizer"),Yqt.forEach(t),two=r(NOe," (GPT NeoX Japanese model)"),NOe.forEach(t),awo=i(S),Qs=n(S,"LI",{});var zN=s(Qs);m1e=n(zN,"STRONG",{});var Zqt=s(m1e);nwo=r(Zqt,"gptj"),Zqt.forEach(t),swo=r(zN," \u2014 "),PO=n(zN,"A",{href:!0});var Kqt=s(PO);lwo=r(Kqt,"GPT2Tokenizer"),Kqt.forEach(t),iwo=r(zN," or "),BO=n(zN,"A",{href:!0});var ejt=s(BO);dwo=r(ejt,"GPT2TokenizerFast"),ejt.forEach(t),mwo=r(zN," (GPT-J model)"),zN.forEach(t),cwo=i(S),Ws=n(S,"LI",{});var QN=s(Ws);c1e=n(QN,"STRONG",{});var ojt=s(c1e);fwo=r(ojt,"groupvit"),ojt.forEach(t),gwo=r(QN," \u2014 "),IO=n(QN,"A",{href:!0});var rjt=s(IO);hwo=r(rjt,"CLIPTokenizer"),rjt.forEach(t),uwo=r(QN," or "),NO=n(QN,"A",{href:!0});var tjt=s(NO);pwo=r(tjt,"CLIPTokenizerFast"),tjt.forEach(t),_wo=r(QN," (GroupViT model)"),QN.forEach(t),bwo=i(S),Us=n(S,"LI",{});var WN=s(Us);f1e=n(WN,"STRONG",{});var ajt=s(f1e);vwo=r(ajt,"herbert"),ajt.forEach(t),Fwo=r(WN," \u2014 "),qO=n(WN,"A",{href:!0});var njt=s(qO);Two=r(njt,"HerbertTokenizer"),njt.forEach(t),Mwo=r(WN," or "),jO=n(WN,"A",{href:!0});var sjt=s(jO);Ewo=r(sjt,"HerbertTokenizerFast"),sjt.forEach(t),Cwo=r(WN," (HerBERT model)"),WN.forEach(t),wwo=i(S),op=n(S,"LI",{});var qOe=s(op);g1e=n(qOe,"STRONG",{});var ljt=s(g1e);Awo=r(ljt,"hubert"),ljt.forEach(t),Lwo=r(qOe," \u2014 "),DO=n(qOe,"A",{href:!0});var ijt=s(DO);ywo=r(ijt,"Wav2Vec2CTCTokenizer"),ijt.forEach(t),xwo=r(qOe," (Hubert model)"),qOe.forEach(t),$wo=i(S),Hs=n(S,"LI",{});var UN=s(Hs);h1e=n(UN,"STRONG",{});var djt=s(h1e);kwo=r(djt,"ibert"),djt.forEach(t),Swo=r(UN," \u2014 "),GO=n(UN,"A",{href:!0});var mjt=s(GO);Rwo=r(mjt,"RobertaTokenizer"),mjt.forEach(t),Pwo=r(UN," or "),OO=n(UN,"A",{href:!0});var cjt=s(OO);Bwo=r(cjt,"RobertaTokenizerFast"),cjt.forEach(t),Iwo=r(UN," (I-BERT model)"),UN.forEach(t),Nwo=i(S),rp=n(S,"LI",{});var jOe=s(rp);u1e=n(jOe,"STRONG",{});var fjt=s(u1e);qwo=r(fjt,"jukebox"),fjt.forEach(t),jwo=r(jOe," \u2014 "),VO=n(jOe,"A",{href:!0});var gjt=s(VO);Dwo=r(gjt,"JukeboxTokenizer"),gjt.forEach(t),Gwo=r(jOe," (Jukebox model)"),jOe.forEach(t),Owo=i(S),Js=n(S,"LI",{});var HN=s(Js);p1e=n(HN,"STRONG",{});var hjt=s(p1e);Vwo=r(hjt,"layoutlm"),hjt.forEach(t),Xwo=r(HN," \u2014 "),XO=n(HN,"A",{href:!0});var ujt=s(XO);zwo=r(ujt,"LayoutLMTokenizer"),ujt.forEach(t),Qwo=r(HN," or "),zO=n(HN,"A",{href:!0});var pjt=s(zO);Wwo=r(pjt,"LayoutLMTokenizerFast"),pjt.forEach(t),Uwo=r(HN," (LayoutLM model)"),HN.forEach(t),Hwo=i(S),Ys=n(S,"LI",{});var JN=s(Ys);_1e=n(JN,"STRONG",{});var _jt=s(_1e);Jwo=r(_jt,"layoutlmv2"),_jt.forEach(t),Ywo=r(JN," \u2014 "),QO=n(JN,"A",{href:!0});var bjt=s(QO);Zwo=r(bjt,"LayoutLMv2Tokenizer"),bjt.forEach(t),Kwo=r(JN," or "),WO=n(JN,"A",{href:!0});var vjt=s(WO);eAo=r(vjt,"LayoutLMv2TokenizerFast"),vjt.forEach(t),oAo=r(JN," (LayoutLMv2 model)"),JN.forEach(t),rAo=i(S),Zs=n(S,"LI",{});var YN=s(Zs);b1e=n(YN,"STRONG",{});var Fjt=s(b1e);tAo=r(Fjt,"layoutlmv3"),Fjt.forEach(t),aAo=r(YN," \u2014 "),UO=n(YN,"A",{href:!0});var Tjt=s(UO);nAo=r(Tjt,"LayoutLMv3Tokenizer"),Tjt.forEach(t),sAo=r(YN," or "),HO=n(YN,"A",{href:!0});var Mjt=s(HO);lAo=r(Mjt,"LayoutLMv3TokenizerFast"),Mjt.forEach(t),iAo=r(YN," (LayoutLMv3 model)"),YN.forEach(t),dAo=i(S),Ks=n(S,"LI",{});var ZN=s(Ks);v1e=n(ZN,"STRONG",{});var Ejt=s(v1e);mAo=r(Ejt,"layoutxlm"),Ejt.forEach(t),cAo=r(ZN," \u2014 "),JO=n(ZN,"A",{href:!0});var Cjt=s(JO);fAo=r(Cjt,"LayoutXLMTokenizer"),Cjt.forEach(t),gAo=r(ZN," or "),YO=n(ZN,"A",{href:!0});var wjt=s(YO);hAo=r(wjt,"LayoutXLMTokenizerFast"),wjt.forEach(t),uAo=r(ZN," (LayoutXLM model)"),ZN.forEach(t),pAo=i(S),el=n(S,"LI",{});var KN=s(el);F1e=n(KN,"STRONG",{});var Ajt=s(F1e);_Ao=r(Ajt,"led"),Ajt.forEach(t),bAo=r(KN," \u2014 "),ZO=n(KN,"A",{href:!0});var Ljt=s(ZO);vAo=r(Ljt,"LEDTokenizer"),Ljt.forEach(t),FAo=r(KN," or "),KO=n(KN,"A",{href:!0});var yjt=s(KO);TAo=r(yjt,"LEDTokenizerFast"),yjt.forEach(t),MAo=r(KN," (LED model)"),KN.forEach(t),EAo=i(S),ol=n(S,"LI",{});var eq=s(ol);T1e=n(eq,"STRONG",{});var xjt=s(T1e);CAo=r(xjt,"lilt"),xjt.forEach(t),wAo=r(eq," \u2014 "),eV=n(eq,"A",{href:!0});var $jt=s(eV);AAo=r($jt,"LayoutLMv3Tokenizer"),$jt.forEach(t),LAo=r(eq," or "),oV=n(eq,"A",{href:!0});var kjt=s(oV);yAo=r(kjt,"LayoutLMv3TokenizerFast"),kjt.forEach(t),xAo=r(eq," (LiLT model)"),eq.forEach(t),$Ao=i(S),rl=n(S,"LI",{});var oq=s(rl);M1e=n(oq,"STRONG",{});var Sjt=s(M1e);kAo=r(Sjt,"longformer"),Sjt.forEach(t),SAo=r(oq," \u2014 "),rV=n(oq,"A",{href:!0});var Rjt=s(rV);RAo=r(Rjt,"LongformerTokenizer"),Rjt.forEach(t),PAo=r(oq," or "),tV=n(oq,"A",{href:!0});var Pjt=s(tV);BAo=r(Pjt,"LongformerTokenizerFast"),Pjt.forEach(t),IAo=r(oq," (Longformer model)"),oq.forEach(t),NAo=i(S),tl=n(S,"LI",{});var rq=s(tl);E1e=n(rq,"STRONG",{});var Bjt=s(E1e);qAo=r(Bjt,"longt5"),Bjt.forEach(t),jAo=r(rq," \u2014 "),aV=n(rq,"A",{href:!0});var Ijt=s(aV);DAo=r(Ijt,"T5Tokenizer"),Ijt.forEach(t),GAo=r(rq," or "),nV=n(rq,"A",{href:!0});var Njt=s(nV);OAo=r(Njt,"T5TokenizerFast"),Njt.forEach(t),VAo=r(rq," (LongT5 model)"),rq.forEach(t),XAo=i(S),tp=n(S,"LI",{});var DOe=s(tp);C1e=n(DOe,"STRONG",{});var qjt=s(C1e);zAo=r(qjt,"luke"),qjt.forEach(t),QAo=r(DOe," \u2014 "),sV=n(DOe,"A",{href:!0});var jjt=s(sV);WAo=r(jjt,"LukeTokenizer"),jjt.forEach(t),UAo=r(DOe," (LUKE model)"),DOe.forEach(t),HAo=i(S),al=n(S,"LI",{});var tq=s(al);w1e=n(tq,"STRONG",{});var Djt=s(w1e);JAo=r(Djt,"lxmert"),Djt.forEach(t),YAo=r(tq," \u2014 "),lV=n(tq,"A",{href:!0});var Gjt=s(lV);ZAo=r(Gjt,"LxmertTokenizer"),Gjt.forEach(t),KAo=r(tq," or "),iV=n(tq,"A",{href:!0});var Ojt=s(iV);e6o=r(Ojt,"LxmertTokenizerFast"),Ojt.forEach(t),o6o=r(tq," (LXMERT model)"),tq.forEach(t),r6o=i(S),ap=n(S,"LI",{});var GOe=s(ap);A1e=n(GOe,"STRONG",{});var Vjt=s(A1e);t6o=r(Vjt,"m2m_100"),Vjt.forEach(t),a6o=r(GOe," \u2014 "),dV=n(GOe,"A",{href:!0});var Xjt=s(dV);n6o=r(Xjt,"M2M100Tokenizer"),Xjt.forEach(t),s6o=r(GOe," (M2M100 model)"),GOe.forEach(t),l6o=i(S),np=n(S,"LI",{});var OOe=s(np);L1e=n(OOe,"STRONG",{});var zjt=s(L1e);i6o=r(zjt,"marian"),zjt.forEach(t),d6o=r(OOe," \u2014 "),mV=n(OOe,"A",{href:!0});var Qjt=s(mV);m6o=r(Qjt,"MarianTokenizer"),Qjt.forEach(t),c6o=r(OOe," (Marian model)"),OOe.forEach(t),f6o=i(S),nl=n(S,"LI",{});var aq=s(nl);y1e=n(aq,"STRONG",{});var Wjt=s(y1e);g6o=r(Wjt,"mbart"),Wjt.forEach(t),h6o=r(aq," \u2014 "),cV=n(aq,"A",{href:!0});var Ujt=s(cV);u6o=r(Ujt,"MBartTokenizer"),Ujt.forEach(t),p6o=r(aq," or "),fV=n(aq,"A",{href:!0});var Hjt=s(fV);_6o=r(Hjt,"MBartTokenizerFast"),Hjt.forEach(t),b6o=r(aq," (mBART model)"),aq.forEach(t),v6o=i(S),sl=n(S,"LI",{});var nq=s(sl);x1e=n(nq,"STRONG",{});var Jjt=s(x1e);F6o=r(Jjt,"mbart50"),Jjt.forEach(t),T6o=r(nq," \u2014 "),gV=n(nq,"A",{href:!0});var Yjt=s(gV);M6o=r(Yjt,"MBart50Tokenizer"),Yjt.forEach(t),E6o=r(nq," or "),hV=n(nq,"A",{href:!0});var Zjt=s(hV);C6o=r(Zjt,"MBart50TokenizerFast"),Zjt.forEach(t),w6o=r(nq," (mBART-50 model)"),nq.forEach(t),A6o=i(S),ll=n(S,"LI",{});var sq=s(ll);$1e=n(sq,"STRONG",{});var Kjt=s($1e);L6o=r(Kjt,"megatron-bert"),Kjt.forEach(t),y6o=r(sq," \u2014 "),uV=n(sq,"A",{href:!0});var eDt=s(uV);x6o=r(eDt,"BertTokenizer"),eDt.forEach(t),$6o=r(sq," or "),pV=n(sq,"A",{href:!0});var oDt=s(pV);k6o=r(oDt,"BertTokenizerFast"),oDt.forEach(t),S6o=r(sq," (Megatron-BERT model)"),sq.forEach(t),R6o=i(S),sp=n(S,"LI",{});var VOe=s(sp);k1e=n(VOe,"STRONG",{});var rDt=s(k1e);P6o=r(rDt,"mluke"),rDt.forEach(t),B6o=r(VOe," \u2014 "),_V=n(VOe,"A",{href:!0});var tDt=s(_V);I6o=r(tDt,"MLukeTokenizer"),tDt.forEach(t),N6o=r(VOe," (mLUKE model)"),VOe.forEach(t),q6o=i(S),il=n(S,"LI",{});var lq=s(il);S1e=n(lq,"STRONG",{});var aDt=s(S1e);j6o=r(aDt,"mobilebert"),aDt.forEach(t),D6o=r(lq," \u2014 "),bV=n(lq,"A",{href:!0});var nDt=s(bV);G6o=r(nDt,"MobileBertTokenizer"),nDt.forEach(t),O6o=r(lq," or "),vV=n(lq,"A",{href:!0});var sDt=s(vV);V6o=r(sDt,"MobileBertTokenizerFast"),sDt.forEach(t),X6o=r(lq," (MobileBERT model)"),lq.forEach(t),z6o=i(S),dl=n(S,"LI",{});var iq=s(dl);R1e=n(iq,"STRONG",{});var lDt=s(R1e);Q6o=r(lDt,"mpnet"),lDt.forEach(t),W6o=r(iq," \u2014 "),FV=n(iq,"A",{href:!0});var iDt=s(FV);U6o=r(iDt,"MPNetTokenizer"),iDt.forEach(t),H6o=r(iq," or "),TV=n(iq,"A",{href:!0});var dDt=s(TV);J6o=r(dDt,"MPNetTokenizerFast"),dDt.forEach(t),Y6o=r(iq," (MPNet model)"),iq.forEach(t),Z6o=i(S),ml=n(S,"LI",{});var dq=s(ml);P1e=n(dq,"STRONG",{});var mDt=s(P1e);K6o=r(mDt,"mt5"),mDt.forEach(t),e7o=r(dq," \u2014 "),MV=n(dq,"A",{href:!0});var cDt=s(MV);o7o=r(cDt,"MT5Tokenizer"),cDt.forEach(t),r7o=r(dq," or "),EV=n(dq,"A",{href:!0});var fDt=s(EV);t7o=r(fDt,"MT5TokenizerFast"),fDt.forEach(t),a7o=r(dq," (MT5 model)"),dq.forEach(t),n7o=i(S),cl=n(S,"LI",{});var mq=s(cl);B1e=n(mq,"STRONG",{});var gDt=s(B1e);s7o=r(gDt,"mvp"),gDt.forEach(t),l7o=r(mq," \u2014 "),CV=n(mq,"A",{href:!0});var hDt=s(CV);i7o=r(hDt,"MvpTokenizer"),hDt.forEach(t),d7o=r(mq," or "),wV=n(mq,"A",{href:!0});var uDt=s(wV);m7o=r(uDt,"MvpTokenizerFast"),uDt.forEach(t),c7o=r(mq," (MVP model)"),mq.forEach(t),f7o=i(S),fl=n(S,"LI",{});var cq=s(fl);I1e=n(cq,"STRONG",{});var pDt=s(I1e);g7o=r(pDt,"nezha"),pDt.forEach(t),h7o=r(cq," \u2014 "),AV=n(cq,"A",{href:!0});var _Dt=s(AV);u7o=r(_Dt,"BertTokenizer"),_Dt.forEach(t),p7o=r(cq," or "),LV=n(cq,"A",{href:!0});var bDt=s(LV);_7o=r(bDt,"BertTokenizerFast"),bDt.forEach(t),b7o=r(cq," (Nezha model)"),cq.forEach(t),v7o=i(S),gl=n(S,"LI",{});var fq=s(gl);N1e=n(fq,"STRONG",{});var vDt=s(N1e);F7o=r(vDt,"nllb"),vDt.forEach(t),T7o=r(fq," \u2014 "),yV=n(fq,"A",{href:!0});var FDt=s(yV);M7o=r(FDt,"NllbTokenizer"),FDt.forEach(t),E7o=r(fq," or "),xV=n(fq,"A",{href:!0});var TDt=s(xV);C7o=r(TDt,"NllbTokenizerFast"),TDt.forEach(t),w7o=r(fq," (NLLB model)"),fq.forEach(t),A7o=i(S),hl=n(S,"LI",{});var gq=s(hl);q1e=n(gq,"STRONG",{});var MDt=s(q1e);L7o=r(MDt,"nystromformer"),MDt.forEach(t),y7o=r(gq," \u2014 "),$V=n(gq,"A",{href:!0});var EDt=s($V);x7o=r(EDt,"AlbertTokenizer"),EDt.forEach(t),$7o=r(gq," or "),kV=n(gq,"A",{href:!0});var CDt=s(kV);k7o=r(CDt,"AlbertTokenizerFast"),CDt.forEach(t),S7o=r(gq," (Nystr\xF6mformer model)"),gq.forEach(t),R7o=i(S),ul=n(S,"LI",{});var hq=s(ul);j1e=n(hq,"STRONG",{});var wDt=s(j1e);P7o=r(wDt,"openai-gpt"),wDt.forEach(t),B7o=r(hq," \u2014 "),SV=n(hq,"A",{href:!0});var ADt=s(SV);I7o=r(ADt,"OpenAIGPTTokenizer"),ADt.forEach(t),N7o=r(hq," or "),RV=n(hq,"A",{href:!0});var LDt=s(RV);q7o=r(LDt,"OpenAIGPTTokenizerFast"),LDt.forEach(t),j7o=r(hq," (OpenAI GPT model)"),hq.forEach(t),D7o=i(S),lp=n(S,"LI",{});var XOe=s(lp);D1e=n(XOe,"STRONG",{});var yDt=s(D1e);G7o=r(yDt,"opt"),yDt.forEach(t),O7o=r(XOe," \u2014 "),PV=n(XOe,"A",{href:!0});var xDt=s(PV);V7o=r(xDt,"GPT2Tokenizer"),xDt.forEach(t),X7o=r(XOe," (OPT model)"),XOe.forEach(t),z7o=i(S),pl=n(S,"LI",{});var uq=s(pl);G1e=n(uq,"STRONG",{});var $Dt=s(G1e);Q7o=r($Dt,"owlvit"),$Dt.forEach(t),W7o=r(uq," \u2014 "),BV=n(uq,"A",{href:!0});var kDt=s(BV);U7o=r(kDt,"CLIPTokenizer"),kDt.forEach(t),H7o=r(uq," or "),IV=n(uq,"A",{href:!0});var SDt=s(IV);J7o=r(SDt,"CLIPTokenizerFast"),SDt.forEach(t),Y7o=r(uq," (OWL-ViT model)"),uq.forEach(t),Z7o=i(S),_l=n(S,"LI",{});var pq=s(_l);O1e=n(pq,"STRONG",{});var RDt=s(O1e);K7o=r(RDt,"pegasus"),RDt.forEach(t),e8o=r(pq," \u2014 "),NV=n(pq,"A",{href:!0});var PDt=s(NV);o8o=r(PDt,"PegasusTokenizer"),PDt.forEach(t),r8o=r(pq," or "),qV=n(pq,"A",{href:!0});var BDt=s(qV);t8o=r(BDt,"PegasusTokenizerFast"),BDt.forEach(t),a8o=r(pq," (Pegasus model)"),pq.forEach(t),n8o=i(S),bl=n(S,"LI",{});var _q=s(bl);V1e=n(_q,"STRONG",{});var IDt=s(V1e);s8o=r(IDt,"pegasus_x"),IDt.forEach(t),l8o=r(_q," \u2014 "),jV=n(_q,"A",{href:!0});var NDt=s(jV);i8o=r(NDt,"PegasusTokenizer"),NDt.forEach(t),d8o=r(_q," or "),DV=n(_q,"A",{href:!0});var qDt=s(DV);m8o=r(qDt,"PegasusTokenizerFast"),qDt.forEach(t),c8o=r(_q," (PEGASUS-X model)"),_q.forEach(t),f8o=i(S),ip=n(S,"LI",{});var zOe=s(ip);X1e=n(zOe,"STRONG",{});var jDt=s(X1e);g8o=r(jDt,"perceiver"),jDt.forEach(t),h8o=r(zOe," \u2014 "),GV=n(zOe,"A",{href:!0});var DDt=s(GV);u8o=r(DDt,"PerceiverTokenizer"),DDt.forEach(t),p8o=r(zOe," (Perceiver model)"),zOe.forEach(t),_8o=i(S),dp=n(S,"LI",{});var QOe=s(dp);z1e=n(QOe,"STRONG",{});var GDt=s(z1e);b8o=r(GDt,"phobert"),GDt.forEach(t),v8o=r(QOe," \u2014 "),OV=n(QOe,"A",{href:!0});var ODt=s(OV);F8o=r(ODt,"PhobertTokenizer"),ODt.forEach(t),T8o=r(QOe," (PhoBERT model)"),QOe.forEach(t),M8o=i(S),mp=n(S,"LI",{});var WOe=s(mp);Q1e=n(WOe,"STRONG",{});var VDt=s(Q1e);E8o=r(VDt,"plbart"),VDt.forEach(t),C8o=r(WOe," \u2014 "),VV=n(WOe,"A",{href:!0});var XDt=s(VV);w8o=r(XDt,"PLBartTokenizer"),XDt.forEach(t),A8o=r(WOe," (PLBart model)"),WOe.forEach(t),L8o=i(S),cp=n(S,"LI",{});var UOe=s(cp);W1e=n(UOe,"STRONG",{});var zDt=s(W1e);y8o=r(zDt,"prophetnet"),zDt.forEach(t),x8o=r(UOe," \u2014 "),XV=n(UOe,"A",{href:!0});var QDt=s(XV);$8o=r(QDt,"ProphetNetTokenizer"),QDt.forEach(t),k8o=r(UOe," (ProphetNet model)"),UOe.forEach(t),S8o=i(S),vl=n(S,"LI",{});var bq=s(vl);U1e=n(bq,"STRONG",{});var WDt=s(U1e);R8o=r(WDt,"qdqbert"),WDt.forEach(t),P8o=r(bq," \u2014 "),zV=n(bq,"A",{href:!0});var UDt=s(zV);B8o=r(UDt,"BertTokenizer"),UDt.forEach(t),I8o=r(bq," or "),QV=n(bq,"A",{href:!0});var HDt=s(QV);N8o=r(HDt,"BertTokenizerFast"),HDt.forEach(t),q8o=r(bq," (QDQBert model)"),bq.forEach(t),j8o=i(S),fp=n(S,"LI",{});var HOe=s(fp);H1e=n(HOe,"STRONG",{});var JDt=s(H1e);D8o=r(JDt,"rag"),JDt.forEach(t),G8o=r(HOe," \u2014 "),WV=n(HOe,"A",{href:!0});var YDt=s(WV);O8o=r(YDt,"RagTokenizer"),YDt.forEach(t),V8o=r(HOe," (RAG model)"),HOe.forEach(t),X8o=i(S),Fl=n(S,"LI",{});var vq=s(Fl);J1e=n(vq,"STRONG",{});var ZDt=s(J1e);z8o=r(ZDt,"realm"),ZDt.forEach(t),Q8o=r(vq," \u2014 "),UV=n(vq,"A",{href:!0});var KDt=s(UV);W8o=r(KDt,"RealmTokenizer"),KDt.forEach(t),U8o=r(vq," or "),HV=n(vq,"A",{href:!0});var eGt=s(HV);H8o=r(eGt,"RealmTokenizerFast"),eGt.forEach(t),J8o=r(vq," (REALM model)"),vq.forEach(t),Y8o=i(S),Tl=n(S,"LI",{});var Fq=s(Tl);Y1e=n(Fq,"STRONG",{});var oGt=s(Y1e);Z8o=r(oGt,"reformer"),oGt.forEach(t),K8o=r(Fq," \u2014 "),JV=n(Fq,"A",{href:!0});var rGt=s(JV);eLo=r(rGt,"ReformerTokenizer"),rGt.forEach(t),oLo=r(Fq," or "),YV=n(Fq,"A",{href:!0});var tGt=s(YV);rLo=r(tGt,"ReformerTokenizerFast"),tGt.forEach(t),tLo=r(Fq," (Reformer model)"),Fq.forEach(t),aLo=i(S),Ml=n(S,"LI",{});var Tq=s(Ml);Z1e=n(Tq,"STRONG",{});var aGt=s(Z1e);nLo=r(aGt,"rembert"),aGt.forEach(t),sLo=r(Tq," \u2014 "),ZV=n(Tq,"A",{href:!0});var nGt=s(ZV);lLo=r(nGt,"RemBertTokenizer"),nGt.forEach(t),iLo=r(Tq," or "),KV=n(Tq,"A",{href:!0});var sGt=s(KV);dLo=r(sGt,"RemBertTokenizerFast"),sGt.forEach(t),mLo=r(Tq," (RemBERT model)"),Tq.forEach(t),cLo=i(S),El=n(S,"LI",{});var Mq=s(El);K1e=n(Mq,"STRONG",{});var lGt=s(K1e);fLo=r(lGt,"retribert"),lGt.forEach(t),gLo=r(Mq," \u2014 "),eX=n(Mq,"A",{href:!0});var iGt=s(eX);hLo=r(iGt,"RetriBertTokenizer"),iGt.forEach(t),uLo=r(Mq," or "),oX=n(Mq,"A",{href:!0});var dGt=s(oX);pLo=r(dGt,"RetriBertTokenizerFast"),dGt.forEach(t),_Lo=r(Mq," (RetriBERT model)"),Mq.forEach(t),bLo=i(S),Cl=n(S,"LI",{});var Eq=s(Cl);e2e=n(Eq,"STRONG",{});var mGt=s(e2e);vLo=r(mGt,"roberta"),mGt.forEach(t),FLo=r(Eq," \u2014 "),rX=n(Eq,"A",{href:!0});var cGt=s(rX);TLo=r(cGt,"RobertaTokenizer"),cGt.forEach(t),MLo=r(Eq," or "),tX=n(Eq,"A",{href:!0});var fGt=s(tX);ELo=r(fGt,"RobertaTokenizerFast"),fGt.forEach(t),CLo=r(Eq," (RoBERTa model)"),Eq.forEach(t),wLo=i(S),gp=n(S,"LI",{});var JOe=s(gp);o2e=n(JOe,"STRONG",{});var gGt=s(o2e);ALo=r(gGt,"roc_bert"),gGt.forEach(t),LLo=r(JOe," \u2014 "),aX=n(JOe,"A",{href:!0});var hGt=s(aX);yLo=r(hGt,"RoCBertTokenizer"),hGt.forEach(t),xLo=r(JOe," (RoCBert model)"),JOe.forEach(t),$Lo=i(S),wl=n(S,"LI",{});var Cq=s(wl);r2e=n(Cq,"STRONG",{});var uGt=s(r2e);kLo=r(uGt,"roformer"),uGt.forEach(t),SLo=r(Cq," \u2014 "),nX=n(Cq,"A",{href:!0});var pGt=s(nX);RLo=r(pGt,"RoFormerTokenizer"),pGt.forEach(t),PLo=r(Cq," or "),sX=n(Cq,"A",{href:!0});var _Gt=s(sX);BLo=r(_Gt,"RoFormerTokenizerFast"),_Gt.forEach(t),ILo=r(Cq," (RoFormer model)"),Cq.forEach(t),NLo=i(S),hp=n(S,"LI",{});var YOe=s(hp);t2e=n(YOe,"STRONG",{});var bGt=s(t2e);qLo=r(bGt,"speech_to_text"),bGt.forEach(t),jLo=r(YOe," \u2014 "),lX=n(YOe,"A",{href:!0});var vGt=s(lX);DLo=r(vGt,"Speech2TextTokenizer"),vGt.forEach(t),GLo=r(YOe," (Speech2Text model)"),YOe.forEach(t),OLo=i(S),up=n(S,"LI",{});var ZOe=s(up);a2e=n(ZOe,"STRONG",{});var FGt=s(a2e);VLo=r(FGt,"speech_to_text_2"),FGt.forEach(t),XLo=r(ZOe," \u2014 "),iX=n(ZOe,"A",{href:!0});var TGt=s(iX);zLo=r(TGt,"Speech2Text2Tokenizer"),TGt.forEach(t),QLo=r(ZOe," (Speech2Text2 model)"),ZOe.forEach(t),WLo=i(S),Al=n(S,"LI",{});var wq=s(Al);n2e=n(wq,"STRONG",{});var MGt=s(n2e);ULo=r(MGt,"splinter"),MGt.forEach(t),HLo=r(wq," \u2014 "),dX=n(wq,"A",{href:!0});var EGt=s(dX);JLo=r(EGt,"SplinterTokenizer"),EGt.forEach(t),YLo=r(wq," or "),mX=n(wq,"A",{href:!0});var CGt=s(mX);ZLo=r(CGt,"SplinterTokenizerFast"),CGt.forEach(t),KLo=r(wq," (Splinter model)"),wq.forEach(t),eyo=i(S),Ll=n(S,"LI",{});var Aq=s(Ll);s2e=n(Aq,"STRONG",{});var wGt=s(s2e);oyo=r(wGt,"squeezebert"),wGt.forEach(t),ryo=r(Aq," \u2014 "),cX=n(Aq,"A",{href:!0});var AGt=s(cX);tyo=r(AGt,"SqueezeBertTokenizer"),AGt.forEach(t),ayo=r(Aq," or "),fX=n(Aq,"A",{href:!0});var LGt=s(fX);nyo=r(LGt,"SqueezeBertTokenizerFast"),LGt.forEach(t),syo=r(Aq," (SqueezeBERT model)"),Aq.forEach(t),lyo=i(S),yl=n(S,"LI",{});var Lq=s(yl);l2e=n(Lq,"STRONG",{});var yGt=s(l2e);iyo=r(yGt,"t5"),yGt.forEach(t),dyo=r(Lq," \u2014 "),gX=n(Lq,"A",{href:!0});var xGt=s(gX);myo=r(xGt,"T5Tokenizer"),xGt.forEach(t),cyo=r(Lq," or "),hX=n(Lq,"A",{href:!0});var $Gt=s(hX);fyo=r($Gt,"T5TokenizerFast"),$Gt.forEach(t),gyo=r(Lq," (T5 model)"),Lq.forEach(t),hyo=i(S),pp=n(S,"LI",{});var KOe=s(pp);i2e=n(KOe,"STRONG",{});var kGt=s(i2e);uyo=r(kGt,"tapas"),kGt.forEach(t),pyo=r(KOe," \u2014 "),uX=n(KOe,"A",{href:!0});var SGt=s(uX);_yo=r(SGt,"TapasTokenizer"),SGt.forEach(t),byo=r(KOe," (TAPAS model)"),KOe.forEach(t),vyo=i(S),_p=n(S,"LI",{});var eVe=s(_p);d2e=n(eVe,"STRONG",{});var RGt=s(d2e);Fyo=r(RGt,"tapex"),RGt.forEach(t),Tyo=r(eVe," \u2014 "),pX=n(eVe,"A",{href:!0});var PGt=s(pX);Myo=r(PGt,"TapexTokenizer"),PGt.forEach(t),Eyo=r(eVe," (TAPEX model)"),eVe.forEach(t),Cyo=i(S),bp=n(S,"LI",{});var oVe=s(bp);m2e=n(oVe,"STRONG",{});var BGt=s(m2e);wyo=r(BGt,"transfo-xl"),BGt.forEach(t),Ayo=r(oVe," \u2014 "),_X=n(oVe,"A",{href:!0});var IGt=s(_X);Lyo=r(IGt,"TransfoXLTokenizer"),IGt.forEach(t),yyo=r(oVe," (Transformer-XL model)"),oVe.forEach(t),xyo=i(S),xl=n(S,"LI",{});var yq=s(xl);c2e=n(yq,"STRONG",{});var NGt=s(c2e);$yo=r(NGt,"vilt"),NGt.forEach(t),kyo=r(yq," \u2014 "),bX=n(yq,"A",{href:!0});var qGt=s(bX);Syo=r(qGt,"BertTokenizer"),qGt.forEach(t),Ryo=r(yq," or "),vX=n(yq,"A",{href:!0});var jGt=s(vX);Pyo=r(jGt,"BertTokenizerFast"),jGt.forEach(t),Byo=r(yq," (ViLT model)"),yq.forEach(t),Iyo=i(S),$l=n(S,"LI",{});var xq=s($l);f2e=n(xq,"STRONG",{});var DGt=s(f2e);Nyo=r(DGt,"visual_bert"),DGt.forEach(t),qyo=r(xq," \u2014 "),FX=n(xq,"A",{href:!0});var GGt=s(FX);jyo=r(GGt,"BertTokenizer"),GGt.forEach(t),Dyo=r(xq," or "),TX=n(xq,"A",{href:!0});var OGt=s(TX);Gyo=r(OGt,"BertTokenizerFast"),OGt.forEach(t),Oyo=r(xq," (VisualBERT model)"),xq.forEach(t),Vyo=i(S),vp=n(S,"LI",{});var rVe=s(vp);g2e=n(rVe,"STRONG",{});var VGt=s(g2e);Xyo=r(VGt,"wav2vec2"),VGt.forEach(t),zyo=r(rVe," \u2014 "),MX=n(rVe,"A",{href:!0});var XGt=s(MX);Qyo=r(XGt,"Wav2Vec2CTCTokenizer"),XGt.forEach(t),Wyo=r(rVe," (Wav2Vec2 model)"),rVe.forEach(t),Uyo=i(S),Fp=n(S,"LI",{});var tVe=s(Fp);h2e=n(tVe,"STRONG",{});var zGt=s(h2e);Hyo=r(zGt,"wav2vec2-conformer"),zGt.forEach(t),Jyo=r(tVe," \u2014 "),EX=n(tVe,"A",{href:!0});var QGt=s(EX);Yyo=r(QGt,"Wav2Vec2CTCTokenizer"),QGt.forEach(t),Zyo=r(tVe," (Wav2Vec2-Conformer model)"),tVe.forEach(t),Kyo=i(S),Tp=n(S,"LI",{});var aVe=s(Tp);u2e=n(aVe,"STRONG",{});var WGt=s(u2e);e9o=r(WGt,"wav2vec2_phoneme"),WGt.forEach(t),o9o=r(aVe," \u2014 "),CX=n(aVe,"A",{href:!0});var UGt=s(CX);r9o=r(UGt,"Wav2Vec2PhonemeCTCTokenizer"),UGt.forEach(t),t9o=r(aVe," (Wav2Vec2Phoneme model)"),aVe.forEach(t),a9o=i(S),Mp=n(S,"LI",{});var nVe=s(Mp);p2e=n(nVe,"STRONG",{});var HGt=s(p2e);n9o=r(HGt,"whisper"),HGt.forEach(t),s9o=r(nVe," \u2014 "),wX=n(nVe,"A",{href:!0});var JGt=s(wX);l9o=r(JGt,"WhisperTokenizer"),JGt.forEach(t),i9o=r(nVe," (Whisper model)"),nVe.forEach(t),d9o=i(S),kl=n(S,"LI",{});var $q=s(kl);_2e=n($q,"STRONG",{});var YGt=s(_2e);m9o=r(YGt,"xclip"),YGt.forEach(t),c9o=r($q," \u2014 "),AX=n($q,"A",{href:!0});var ZGt=s(AX);f9o=r(ZGt,"CLIPTokenizer"),ZGt.forEach(t),g9o=r($q," or "),LX=n($q,"A",{href:!0});var KGt=s(LX);h9o=r(KGt,"CLIPTokenizerFast"),KGt.forEach(t),u9o=r($q," (X-CLIP model)"),$q.forEach(t),p9o=i(S),Sl=n(S,"LI",{});var kq=s(Sl);b2e=n(kq,"STRONG",{});var eOt=s(b2e);_9o=r(eOt,"xglm"),eOt.forEach(t),b9o=r(kq," \u2014 "),yX=n(kq,"A",{href:!0});var oOt=s(yX);v9o=r(oOt,"XGLMTokenizer"),oOt.forEach(t),F9o=r(kq," or "),xX=n(kq,"A",{href:!0});var rOt=s(xX);T9o=r(rOt,"XGLMTokenizerFast"),rOt.forEach(t),M9o=r(kq," (XGLM model)"),kq.forEach(t),E9o=i(S),Ep=n(S,"LI",{});var sVe=s(Ep);v2e=n(sVe,"STRONG",{});var tOt=s(v2e);C9o=r(tOt,"xlm"),tOt.forEach(t),w9o=r(sVe," \u2014 "),$X=n(sVe,"A",{href:!0});var aOt=s($X);A9o=r(aOt,"XLMTokenizer"),aOt.forEach(t),L9o=r(sVe," (XLM model)"),sVe.forEach(t),y9o=i(S),Cp=n(S,"LI",{});var lVe=s(Cp);F2e=n(lVe,"STRONG",{});var nOt=s(F2e);x9o=r(nOt,"xlm-prophetnet"),nOt.forEach(t),$9o=r(lVe," \u2014 "),kX=n(lVe,"A",{href:!0});var sOt=s(kX);k9o=r(sOt,"XLMProphetNetTokenizer"),sOt.forEach(t),S9o=r(lVe," (XLM-ProphetNet model)"),lVe.forEach(t),R9o=i(S),Rl=n(S,"LI",{});var Sq=s(Rl);T2e=n(Sq,"STRONG",{});var lOt=s(T2e);P9o=r(lOt,"xlm-roberta"),lOt.forEach(t),B9o=r(Sq," \u2014 "),SX=n(Sq,"A",{href:!0});var iOt=s(SX);I9o=r(iOt,"XLMRobertaTokenizer"),iOt.forEach(t),N9o=r(Sq," or "),RX=n(Sq,"A",{href:!0});var dOt=s(RX);q9o=r(dOt,"XLMRobertaTokenizerFast"),dOt.forEach(t),j9o=r(Sq," (XLM-RoBERTa model)"),Sq.forEach(t),D9o=i(S),Pl=n(S,"LI",{});var Rq=s(Pl);M2e=n(Rq,"STRONG",{});var mOt=s(M2e);G9o=r(mOt,"xlm-roberta-xl"),mOt.forEach(t),O9o=r(Rq," \u2014 "),PX=n(Rq,"A",{href:!0});var cOt=s(PX);V9o=r(cOt,"XLMRobertaTokenizer"),cOt.forEach(t),X9o=r(Rq," or "),BX=n(Rq,"A",{href:!0});var fOt=s(BX);z9o=r(fOt,"XLMRobertaTokenizerFast"),fOt.forEach(t),Q9o=r(Rq," (XLM-RoBERTa-XL model)"),Rq.forEach(t),W9o=i(S),Bl=n(S,"LI",{});var Pq=s(Bl);E2e=n(Pq,"STRONG",{});var gOt=s(E2e);U9o=r(gOt,"xlnet"),gOt.forEach(t),H9o=r(Pq," \u2014 "),IX=n(Pq,"A",{href:!0});var hOt=s(IX);J9o=r(hOt,"XLNetTokenizer"),hOt.forEach(t),Y9o=r(Pq," or "),NX=n(Pq,"A",{href:!0});var uOt=s(NX);Z9o=r(uOt,"XLNetTokenizerFast"),uOt.forEach(t),K9o=r(Pq," (XLNet model)"),Pq.forEach(t),exo=i(S),Il=n(S,"LI",{});var Bq=s(Il);C2e=n(Bq,"STRONG",{});var pOt=s(C2e);oxo=r(pOt,"yoso"),pOt.forEach(t),rxo=r(Bq," \u2014 "),qX=n(Bq,"A",{href:!0});var _Ot=s(qX);txo=r(_Ot,"AlbertTokenizer"),_Ot.forEach(t),axo=r(Bq," or "),jX=n(Bq,"A",{href:!0});var bOt=s(jX);nxo=r(bOt,"AlbertTokenizerFast"),bOt.forEach(t),sxo=r(Bq," (YOSO model)"),Bq.forEach(t),S.forEach(t),lxo=i(Vl),T(wp.$$.fragment,Vl),Vl.forEach(t),ixo=i(Ol),Ap=n(Ol,"DIV",{class:!0});var Mmo=s(Ap);T(Pk.$$.fragment,Mmo),dxo=i(Mmo),w2e=n(Mmo,"P",{});var vOt=s(w2e);mxo=r(vOt,"Register a new tokenizer in this mapping."),vOt.forEach(t),Mmo.forEach(t),Ol.forEach(t),lio=i(c),Nd=n(c,"H2",{class:!0});var Emo=s(Nd);Lp=n(Emo,"A",{id:!0,class:!0,href:!0});var FOt=s(Lp);A2e=n(FOt,"SPAN",{});var TOt=s(A2e);T(Bk.$$.fragment,TOt),TOt.forEach(t),FOt.forEach(t),cxo=i(Emo),L2e=n(Emo,"SPAN",{});var MOt=s(L2e);fxo=r(MOt,"AutoFeatureExtractor"),MOt.forEach(t),Emo.forEach(t),iio=i(c),No=n(c,"DIV",{class:!0});var Xl=s(No);T(Ik.$$.fragment,Xl),gxo=i(Xl),Nk=n(Xl,"P",{});var Cmo=s(Nk);hxo=r(Cmo,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),DX=n(Cmo,"A",{href:!0});var EOt=s(DX);uxo=r(EOt,"AutoFeatureExtractor.from_pretrained()"),EOt.forEach(t),pxo=r(Cmo," class method."),Cmo.forEach(t),_xo=i(Xl),qk=n(Xl,"P",{});var wmo=s(qk);bxo=r(wmo,"This class cannot be instantiated directly using "),y2e=n(wmo,"CODE",{});var COt=s(y2e);vxo=r(COt,"__init__()"),COt.forEach(t),Fxo=r(wmo," (throws an error)."),wmo.forEach(t),Txo=i(Xl),eo=n(Xl,"DIV",{class:!0});var xa=s(eo);T(jk.$$.fragment,xa),Mxo=i(xa),x2e=n(xa,"P",{});var wOt=s(x2e);Exo=r(wOt,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),wOt.forEach(t),Cxo=i(xa),cn=n(xa,"P",{});var mx=s(cn);wxo=r(mx,"The feature extractor class to instantiate is selected based on the "),$2e=n(mx,"CODE",{});var AOt=s($2e);Axo=r(AOt,"model_type"),AOt.forEach(t),Lxo=r(mx,` property of the config object
(either passed as an argument or loaded from `),k2e=n(mx,"CODE",{});var LOt=s(k2e);yxo=r(LOt,"pretrained_model_name_or_path"),LOt.forEach(t),xxo=r(mx,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),S2e=n(mx,"CODE",{});var yOt=s(S2e);$xo=r(yOt,"pretrained_model_name_or_path"),yOt.forEach(t),kxo=r(mx,":"),mx.forEach(t),Sxo=i(xa),z=n(xa,"UL",{});var Q=s(z);yp=n(Q,"LI",{});var iVe=s(yp);R2e=n(iVe,"STRONG",{});var xOt=s(R2e);Rxo=r(xOt,"beit"),xOt.forEach(t),Pxo=r(iVe," \u2014 "),GX=n(iVe,"A",{href:!0});var $Ot=s(GX);Bxo=r($Ot,"BeitFeatureExtractor"),$Ot.forEach(t),Ixo=r(iVe," (BEiT model)"),iVe.forEach(t),Nxo=i(Q),xp=n(Q,"LI",{});var dVe=s(xp);P2e=n(dVe,"STRONG",{});var kOt=s(P2e);qxo=r(kOt,"clip"),kOt.forEach(t),jxo=r(dVe," \u2014 "),OX=n(dVe,"A",{href:!0});var SOt=s(OX);Dxo=r(SOt,"CLIPFeatureExtractor"),SOt.forEach(t),Gxo=r(dVe," (CLIP model)"),dVe.forEach(t),Oxo=i(Q),$p=n(Q,"LI",{});var mVe=s($p);B2e=n(mVe,"STRONG",{});var ROt=s(B2e);Vxo=r(ROt,"clipseg"),ROt.forEach(t),Xxo=r(mVe," \u2014 "),VX=n(mVe,"A",{href:!0});var POt=s(VX);zxo=r(POt,"ViTFeatureExtractor"),POt.forEach(t),Qxo=r(mVe," (CLIPSeg model)"),mVe.forEach(t),Wxo=i(Q),kp=n(Q,"LI",{});var cVe=s(kp);I2e=n(cVe,"STRONG",{});var BOt=s(I2e);Uxo=r(BOt,"conditional_detr"),BOt.forEach(t),Hxo=r(cVe," \u2014 "),XX=n(cVe,"A",{href:!0});var IOt=s(XX);Jxo=r(IOt,"ConditionalDetrFeatureExtractor"),IOt.forEach(t),Yxo=r(cVe," (Conditional DETR model)"),cVe.forEach(t),Zxo=i(Q),Sp=n(Q,"LI",{});var fVe=s(Sp);N2e=n(fVe,"STRONG",{});var NOt=s(N2e);Kxo=r(NOt,"convnext"),NOt.forEach(t),e$o=r(fVe," \u2014 "),zX=n(fVe,"A",{href:!0});var qOt=s(zX);o$o=r(qOt,"ConvNextFeatureExtractor"),qOt.forEach(t),r$o=r(fVe," (ConvNeXT model)"),fVe.forEach(t),t$o=i(Q),Rp=n(Q,"LI",{});var gVe=s(Rp);q2e=n(gVe,"STRONG",{});var jOt=s(q2e);a$o=r(jOt,"cvt"),jOt.forEach(t),n$o=r(gVe," \u2014 "),QX=n(gVe,"A",{href:!0});var DOt=s(QX);s$o=r(DOt,"ConvNextFeatureExtractor"),DOt.forEach(t),l$o=r(gVe," (CvT model)"),gVe.forEach(t),i$o=i(Q),Pp=n(Q,"LI",{});var hVe=s(Pp);j2e=n(hVe,"STRONG",{});var GOt=s(j2e);d$o=r(GOt,"data2vec-audio"),GOt.forEach(t),m$o=r(hVe," \u2014 "),WX=n(hVe,"A",{href:!0});var OOt=s(WX);c$o=r(OOt,"Wav2Vec2FeatureExtractor"),OOt.forEach(t),f$o=r(hVe," (Data2VecAudio model)"),hVe.forEach(t),g$o=i(Q),Bp=n(Q,"LI",{});var uVe=s(Bp);D2e=n(uVe,"STRONG",{});var VOt=s(D2e);h$o=r(VOt,"data2vec-vision"),VOt.forEach(t),u$o=r(uVe," \u2014 "),UX=n(uVe,"A",{href:!0});var XOt=s(UX);p$o=r(XOt,"BeitFeatureExtractor"),XOt.forEach(t),_$o=r(uVe," (Data2VecVision model)"),uVe.forEach(t),b$o=i(Q),Ip=n(Q,"LI",{});var pVe=s(Ip);G2e=n(pVe,"STRONG",{});var zOt=s(G2e);v$o=r(zOt,"deformable_detr"),zOt.forEach(t),F$o=r(pVe," \u2014 "),HX=n(pVe,"A",{href:!0});var QOt=s(HX);T$o=r(QOt,"DeformableDetrFeatureExtractor"),QOt.forEach(t),M$o=r(pVe," (Deformable DETR model)"),pVe.forEach(t),E$o=i(Q),Np=n(Q,"LI",{});var _Ve=s(Np);O2e=n(_Ve,"STRONG",{});var WOt=s(O2e);C$o=r(WOt,"deit"),WOt.forEach(t),w$o=r(_Ve," \u2014 "),JX=n(_Ve,"A",{href:!0});var UOt=s(JX);A$o=r(UOt,"DeiTFeatureExtractor"),UOt.forEach(t),L$o=r(_Ve," (DeiT model)"),_Ve.forEach(t),y$o=i(Q),qp=n(Q,"LI",{});var bVe=s(qp);V2e=n(bVe,"STRONG",{});var HOt=s(V2e);x$o=r(HOt,"detr"),HOt.forEach(t),$$o=r(bVe," \u2014 "),YX=n(bVe,"A",{href:!0});var JOt=s(YX);k$o=r(JOt,"DetrFeatureExtractor"),JOt.forEach(t),S$o=r(bVe," (DETR model)"),bVe.forEach(t),R$o=i(Q),jp=n(Q,"LI",{});var vVe=s(jp);X2e=n(vVe,"STRONG",{});var YOt=s(X2e);P$o=r(YOt,"donut-swin"),YOt.forEach(t),B$o=r(vVe," \u2014 "),ZX=n(vVe,"A",{href:!0});var ZOt=s(ZX);I$o=r(ZOt,"DonutFeatureExtractor"),ZOt.forEach(t),N$o=r(vVe," (DonutSwin model)"),vVe.forEach(t),q$o=i(Q),Dp=n(Q,"LI",{});var FVe=s(Dp);z2e=n(FVe,"STRONG",{});var KOt=s(z2e);j$o=r(KOt,"dpt"),KOt.forEach(t),D$o=r(FVe," \u2014 "),KX=n(FVe,"A",{href:!0});var eVt=s(KX);G$o=r(eVt,"DPTFeatureExtractor"),eVt.forEach(t),O$o=r(FVe," (DPT model)"),FVe.forEach(t),V$o=i(Q),Gp=n(Q,"LI",{});var TVe=s(Gp);Q2e=n(TVe,"STRONG",{});var oVt=s(Q2e);X$o=r(oVt,"flava"),oVt.forEach(t),z$o=r(TVe," \u2014 "),ez=n(TVe,"A",{href:!0});var rVt=s(ez);Q$o=r(rVt,"FlavaFeatureExtractor"),rVt.forEach(t),W$o=r(TVe," (FLAVA model)"),TVe.forEach(t),U$o=i(Q),Op=n(Q,"LI",{});var MVe=s(Op);W2e=n(MVe,"STRONG",{});var tVt=s(W2e);H$o=r(tVt,"glpn"),tVt.forEach(t),J$o=r(MVe," \u2014 "),oz=n(MVe,"A",{href:!0});var aVt=s(oz);Y$o=r(aVt,"GLPNFeatureExtractor"),aVt.forEach(t),Z$o=r(MVe," (GLPN model)"),MVe.forEach(t),K$o=i(Q),Vp=n(Q,"LI",{});var EVe=s(Vp);U2e=n(EVe,"STRONG",{});var nVt=s(U2e);eko=r(nVt,"groupvit"),nVt.forEach(t),oko=r(EVe," \u2014 "),rz=n(EVe,"A",{href:!0});var sVt=s(rz);rko=r(sVt,"CLIPFeatureExtractor"),sVt.forEach(t),tko=r(EVe," (GroupViT model)"),EVe.forEach(t),ako=i(Q),Xp=n(Q,"LI",{});var CVe=s(Xp);H2e=n(CVe,"STRONG",{});var lVt=s(H2e);nko=r(lVt,"hubert"),lVt.forEach(t),sko=r(CVe," \u2014 "),tz=n(CVe,"A",{href:!0});var iVt=s(tz);lko=r(iVt,"Wav2Vec2FeatureExtractor"),iVt.forEach(t),iko=r(CVe," (Hubert model)"),CVe.forEach(t),dko=i(Q),zp=n(Q,"LI",{});var wVe=s(zp);J2e=n(wVe,"STRONG",{});var dVt=s(J2e);mko=r(dVt,"imagegpt"),dVt.forEach(t),cko=r(wVe," \u2014 "),az=n(wVe,"A",{href:!0});var mVt=s(az);fko=r(mVt,"ImageGPTFeatureExtractor"),mVt.forEach(t),gko=r(wVe," (ImageGPT model)"),wVe.forEach(t),hko=i(Q),Qp=n(Q,"LI",{});var AVe=s(Qp);Y2e=n(AVe,"STRONG",{});var cVt=s(Y2e);uko=r(cVt,"layoutlmv2"),cVt.forEach(t),pko=r(AVe," \u2014 "),nz=n(AVe,"A",{href:!0});var fVt=s(nz);_ko=r(fVt,"LayoutLMv2FeatureExtractor"),fVt.forEach(t),bko=r(AVe," (LayoutLMv2 model)"),AVe.forEach(t),vko=i(Q),Wp=n(Q,"LI",{});var LVe=s(Wp);Z2e=n(LVe,"STRONG",{});var gVt=s(Z2e);Fko=r(gVt,"layoutlmv3"),gVt.forEach(t),Tko=r(LVe," \u2014 "),sz=n(LVe,"A",{href:!0});var hVt=s(sz);Mko=r(hVt,"LayoutLMv3FeatureExtractor"),hVt.forEach(t),Eko=r(LVe," (LayoutLMv3 model)"),LVe.forEach(t),Cko=i(Q),Up=n(Q,"LI",{});var yVe=s(Up);K2e=n(yVe,"STRONG",{});var uVt=s(K2e);wko=r(uVt,"levit"),uVt.forEach(t),Ako=r(yVe," \u2014 "),lz=n(yVe,"A",{href:!0});var pVt=s(lz);Lko=r(pVt,"LevitFeatureExtractor"),pVt.forEach(t),yko=r(yVe," (LeViT model)"),yVe.forEach(t),xko=i(Q),Hp=n(Q,"LI",{});var xVe=s(Hp);ebe=n(xVe,"STRONG",{});var _Vt=s(ebe);$ko=r(_Vt,"maskformer"),_Vt.forEach(t),kko=r(xVe," \u2014 "),iz=n(xVe,"A",{href:!0});var bVt=s(iz);Sko=r(bVt,"MaskFormerFeatureExtractor"),bVt.forEach(t),Rko=r(xVe," (MaskFormer model)"),xVe.forEach(t),Pko=i(Q),Jp=n(Q,"LI",{});var $Ve=s(Jp);obe=n($Ve,"STRONG",{});var vVt=s(obe);Bko=r(vVt,"mctct"),vVt.forEach(t),Iko=r($Ve," \u2014 "),dz=n($Ve,"A",{href:!0});var FVt=s(dz);Nko=r(FVt,"MCTCTFeatureExtractor"),FVt.forEach(t),qko=r($Ve," (M-CTC-T model)"),$Ve.forEach(t),jko=i(Q),Yp=n(Q,"LI",{});var kVe=s(Yp);rbe=n(kVe,"STRONG",{});var TVt=s(rbe);Dko=r(TVt,"mobilenet_v2"),TVt.forEach(t),Gko=r(kVe," \u2014 "),mz=n(kVe,"A",{href:!0});var MVt=s(mz);Oko=r(MVt,"MobileNetV2FeatureExtractor"),MVt.forEach(t),Vko=r(kVe," (MobileNetV2 model)"),kVe.forEach(t),Xko=i(Q),Zp=n(Q,"LI",{});var SVe=s(Zp);tbe=n(SVe,"STRONG",{});var EVt=s(tbe);zko=r(EVt,"mobilevit"),EVt.forEach(t),Qko=r(SVe," \u2014 "),cz=n(SVe,"A",{href:!0});var CVt=s(cz);Wko=r(CVt,"MobileViTFeatureExtractor"),CVt.forEach(t),Uko=r(SVe," (MobileViT model)"),SVe.forEach(t),Hko=i(Q),Kp=n(Q,"LI",{});var RVe=s(Kp);abe=n(RVe,"STRONG",{});var wVt=s(abe);Jko=r(wVt,"owlvit"),wVt.forEach(t),Yko=r(RVe," \u2014 "),fz=n(RVe,"A",{href:!0});var AVt=s(fz);Zko=r(AVt,"OwlViTFeatureExtractor"),AVt.forEach(t),Kko=r(RVe," (OWL-ViT model)"),RVe.forEach(t),eSo=i(Q),e_=n(Q,"LI",{});var PVe=s(e_);nbe=n(PVe,"STRONG",{});var LVt=s(nbe);oSo=r(LVt,"perceiver"),LVt.forEach(t),rSo=r(PVe," \u2014 "),gz=n(PVe,"A",{href:!0});var yVt=s(gz);tSo=r(yVt,"PerceiverFeatureExtractor"),yVt.forEach(t),aSo=r(PVe," (Perceiver model)"),PVe.forEach(t),nSo=i(Q),o_=n(Q,"LI",{});var BVe=s(o_);sbe=n(BVe,"STRONG",{});var xVt=s(sbe);sSo=r(xVt,"poolformer"),xVt.forEach(t),lSo=r(BVe," \u2014 "),hz=n(BVe,"A",{href:!0});var $Vt=s(hz);iSo=r($Vt,"PoolFormerFeatureExtractor"),$Vt.forEach(t),dSo=r(BVe," (PoolFormer model)"),BVe.forEach(t),mSo=i(Q),r_=n(Q,"LI",{});var IVe=s(r_);lbe=n(IVe,"STRONG",{});var kVt=s(lbe);cSo=r(kVt,"regnet"),kVt.forEach(t),fSo=r(IVe," \u2014 "),uz=n(IVe,"A",{href:!0});var SVt=s(uz);gSo=r(SVt,"ConvNextFeatureExtractor"),SVt.forEach(t),hSo=r(IVe," (RegNet model)"),IVe.forEach(t),uSo=i(Q),t_=n(Q,"LI",{});var NVe=s(t_);ibe=n(NVe,"STRONG",{});var RVt=s(ibe);pSo=r(RVt,"resnet"),RVt.forEach(t),_So=r(NVe," \u2014 "),pz=n(NVe,"A",{href:!0});var PVt=s(pz);bSo=r(PVt,"ConvNextFeatureExtractor"),PVt.forEach(t),vSo=r(NVe," (ResNet model)"),NVe.forEach(t),FSo=i(Q),a_=n(Q,"LI",{});var qVe=s(a_);dbe=n(qVe,"STRONG",{});var BVt=s(dbe);TSo=r(BVt,"segformer"),BVt.forEach(t),MSo=r(qVe," \u2014 "),_z=n(qVe,"A",{href:!0});var IVt=s(_z);ESo=r(IVt,"SegformerFeatureExtractor"),IVt.forEach(t),CSo=r(qVe," (SegFormer model)"),qVe.forEach(t),wSo=i(Q),n_=n(Q,"LI",{});var jVe=s(n_);mbe=n(jVe,"STRONG",{});var NVt=s(mbe);ASo=r(NVt,"speech_to_text"),NVt.forEach(t),LSo=r(jVe," \u2014 "),bz=n(jVe,"A",{href:!0});var qVt=s(bz);ySo=r(qVt,"Speech2TextFeatureExtractor"),qVt.forEach(t),xSo=r(jVe," (Speech2Text model)"),jVe.forEach(t),$So=i(Q),s_=n(Q,"LI",{});var DVe=s(s_);cbe=n(DVe,"STRONG",{});var jVt=s(cbe);kSo=r(jVt,"swin"),jVt.forEach(t),SSo=r(DVe," \u2014 "),vz=n(DVe,"A",{href:!0});var DVt=s(vz);RSo=r(DVt,"ViTFeatureExtractor"),DVt.forEach(t),PSo=r(DVe," (Swin Transformer model)"),DVe.forEach(t),BSo=i(Q),l_=n(Q,"LI",{});var GVe=s(l_);fbe=n(GVe,"STRONG",{});var GVt=s(fbe);ISo=r(GVt,"swinv2"),GVt.forEach(t),NSo=r(GVe," \u2014 "),Fz=n(GVe,"A",{href:!0});var OVt=s(Fz);qSo=r(OVt,"ViTFeatureExtractor"),OVt.forEach(t),jSo=r(GVe," (Swin Transformer V2 model)"),GVe.forEach(t),DSo=i(Q),i_=n(Q,"LI",{});var OVe=s(i_);gbe=n(OVe,"STRONG",{});var VVt=s(gbe);GSo=r(VVt,"table-transformer"),VVt.forEach(t),OSo=r(OVe," \u2014 "),Tz=n(OVe,"A",{href:!0});var XVt=s(Tz);VSo=r(XVt,"DetrFeatureExtractor"),XVt.forEach(t),XSo=r(OVe," (Table Transformer model)"),OVe.forEach(t),zSo=i(Q),d_=n(Q,"LI",{});var VVe=s(d_);hbe=n(VVe,"STRONG",{});var zVt=s(hbe);QSo=r(zVt,"van"),zVt.forEach(t),WSo=r(VVe," \u2014 "),Mz=n(VVe,"A",{href:!0});var QVt=s(Mz);USo=r(QVt,"ConvNextFeatureExtractor"),QVt.forEach(t),HSo=r(VVe," (VAN model)"),VVe.forEach(t),JSo=i(Q),m_=n(Q,"LI",{});var XVe=s(m_);ube=n(XVe,"STRONG",{});var WVt=s(ube);YSo=r(WVt,"videomae"),WVt.forEach(t),ZSo=r(XVe," \u2014 "),Ez=n(XVe,"A",{href:!0});var UVt=s(Ez);KSo=r(UVt,"VideoMAEFeatureExtractor"),UVt.forEach(t),eRo=r(XVe," (VideoMAE model)"),XVe.forEach(t),oRo=i(Q),c_=n(Q,"LI",{});var zVe=s(c_);pbe=n(zVe,"STRONG",{});var HVt=s(pbe);rRo=r(HVt,"vilt"),HVt.forEach(t),tRo=r(zVe," \u2014 "),Cz=n(zVe,"A",{href:!0});var JVt=s(Cz);aRo=r(JVt,"ViltFeatureExtractor"),JVt.forEach(t),nRo=r(zVe," (ViLT model)"),zVe.forEach(t),sRo=i(Q),f_=n(Q,"LI",{});var QVe=s(f_);_be=n(QVe,"STRONG",{});var YVt=s(_be);lRo=r(YVt,"vit"),YVt.forEach(t),iRo=r(QVe," \u2014 "),wz=n(QVe,"A",{href:!0});var ZVt=s(wz);dRo=r(ZVt,"ViTFeatureExtractor"),ZVt.forEach(t),mRo=r(QVe," (ViT model)"),QVe.forEach(t),cRo=i(Q),g_=n(Q,"LI",{});var WVe=s(g_);bbe=n(WVe,"STRONG",{});var KVt=s(bbe);fRo=r(KVt,"vit_mae"),KVt.forEach(t),gRo=r(WVe," \u2014 "),Az=n(WVe,"A",{href:!0});var eXt=s(Az);hRo=r(eXt,"ViTFeatureExtractor"),eXt.forEach(t),uRo=r(WVe," (ViTMAE model)"),WVe.forEach(t),pRo=i(Q),h_=n(Q,"LI",{});var UVe=s(h_);vbe=n(UVe,"STRONG",{});var oXt=s(vbe);_Ro=r(oXt,"vit_msn"),oXt.forEach(t),bRo=r(UVe," \u2014 "),Lz=n(UVe,"A",{href:!0});var rXt=s(Lz);vRo=r(rXt,"ViTFeatureExtractor"),rXt.forEach(t),FRo=r(UVe," (ViTMSN model)"),UVe.forEach(t),TRo=i(Q),u_=n(Q,"LI",{});var HVe=s(u_);Fbe=n(HVe,"STRONG",{});var tXt=s(Fbe);MRo=r(tXt,"wav2vec2"),tXt.forEach(t),ERo=r(HVe," \u2014 "),yz=n(HVe,"A",{href:!0});var aXt=s(yz);CRo=r(aXt,"Wav2Vec2FeatureExtractor"),aXt.forEach(t),wRo=r(HVe," (Wav2Vec2 model)"),HVe.forEach(t),ARo=i(Q),p_=n(Q,"LI",{});var JVe=s(p_);Tbe=n(JVe,"STRONG",{});var nXt=s(Tbe);LRo=r(nXt,"wav2vec2-conformer"),nXt.forEach(t),yRo=r(JVe," \u2014 "),xz=n(JVe,"A",{href:!0});var sXt=s(xz);xRo=r(sXt,"Wav2Vec2FeatureExtractor"),sXt.forEach(t),$Ro=r(JVe," (Wav2Vec2-Conformer model)"),JVe.forEach(t),kRo=i(Q),__=n(Q,"LI",{});var YVe=s(__);Mbe=n(YVe,"STRONG",{});var lXt=s(Mbe);SRo=r(lXt,"whisper"),lXt.forEach(t),RRo=r(YVe," \u2014 "),$z=n(YVe,"A",{href:!0});var iXt=s($z);PRo=r(iXt,"WhisperFeatureExtractor"),iXt.forEach(t),BRo=r(YVe," (Whisper model)"),YVe.forEach(t),IRo=i(Q),b_=n(Q,"LI",{});var ZVe=s(b_);Ebe=n(ZVe,"STRONG",{});var dXt=s(Ebe);NRo=r(dXt,"xclip"),dXt.forEach(t),qRo=r(ZVe," \u2014 "),kz=n(ZVe,"A",{href:!0});var mXt=s(kz);jRo=r(mXt,"CLIPFeatureExtractor"),mXt.forEach(t),DRo=r(ZVe," (X-CLIP model)"),ZVe.forEach(t),GRo=i(Q),v_=n(Q,"LI",{});var KVe=s(v_);Cbe=n(KVe,"STRONG",{});var cXt=s(Cbe);ORo=r(cXt,"yolos"),cXt.forEach(t),VRo=r(KVe," \u2014 "),Sz=n(KVe,"A",{href:!0});var fXt=s(Sz);XRo=r(fXt,"YolosFeatureExtractor"),fXt.forEach(t),zRo=r(KVe," (YOLOS model)"),KVe.forEach(t),Q.forEach(t),QRo=i(xa),T(F_.$$.fragment,xa),WRo=i(xa),T(T_.$$.fragment,xa),xa.forEach(t),URo=i(Xl),M_=n(Xl,"DIV",{class:!0});var Amo=s(M_);T(Dk.$$.fragment,Amo),HRo=i(Amo),wbe=n(Amo,"P",{});var gXt=s(wbe);JRo=r(gXt,"Register a new feature extractor for this class."),gXt.forEach(t),Amo.forEach(t),Xl.forEach(t),dio=i(c),qd=n(c,"H2",{class:!0});var Lmo=s(qd);E_=n(Lmo,"A",{id:!0,class:!0,href:!0});var hXt=s(E_);Abe=n(hXt,"SPAN",{});var uXt=s(Abe);T(Gk.$$.fragment,uXt),uXt.forEach(t),hXt.forEach(t),YRo=i(Lmo),Lbe=n(Lmo,"SPAN",{});var pXt=s(Lbe);ZRo=r(pXt,"AutoImageProcessor"),pXt.forEach(t),Lmo.forEach(t),mio=i(c),qo=n(c,"DIV",{class:!0});var zl=s(qo);T(Ok.$$.fragment,zl),KRo=i(zl),Vk=n(zl,"P",{});var ymo=s(Vk);ePo=r(ymo,`This is a generic image processor class that will be instantiated as one of the image processor classes of the
library when created with the `),Rz=n(ymo,"A",{href:!0});var _Xt=s(Rz);oPo=r(_Xt,"AutoImageProcessor.from_pretrained()"),_Xt.forEach(t),rPo=r(ymo," class method."),ymo.forEach(t),tPo=i(zl),Xk=n(zl,"P",{});var xmo=s(Xk);aPo=r(xmo,"This class cannot be instantiated directly using "),ybe=n(xmo,"CODE",{});var bXt=s(ybe);nPo=r(bXt,"__init__()"),bXt.forEach(t),sPo=r(xmo," (throws an error)."),xmo.forEach(t),lPo=i(zl),oo=n(zl,"DIV",{class:!0});var $a=s(oo);T(zk.$$.fragment,$a),iPo=i($a),xbe=n($a,"P",{});var vXt=s(xbe);dPo=r(vXt,"Instantiate one of the image processor classes of the library from a pretrained model vocabulary."),vXt.forEach(t),mPo=i($a),fn=n($a,"P",{});var cx=s(fn);cPo=r(cx,"The image processor class to instantiate is selected based on the "),$be=n(cx,"CODE",{});var FXt=s($be);fPo=r(FXt,"model_type"),FXt.forEach(t),gPo=r(cx,` property of the config object
(either passed as an argument or loaded from `),kbe=n(cx,"CODE",{});var TXt=s(kbe);hPo=r(TXt,"pretrained_model_name_or_path"),TXt.forEach(t),uPo=r(cx,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Sbe=n(cx,"CODE",{});var MXt=s(Sbe);pPo=r(MXt,"pretrained_model_name_or_path"),MXt.forEach(t),_Po=r(cx,":"),cx.forEach(t),bPo=i($a),oe=n($a,"UL",{});var te=s(oe);C_=n(te,"LI",{});var eXe=s(C_);Rbe=n(eXe,"STRONG",{});var EXt=s(Rbe);vPo=r(EXt,"beit"),EXt.forEach(t),FPo=r(eXe," \u2014 "),Pz=n(eXe,"A",{href:!0});var CXt=s(Pz);TPo=r(CXt,"BeitImageProcessor"),CXt.forEach(t),MPo=r(eXe," (BEiT model)"),eXe.forEach(t),EPo=i(te),w_=n(te,"LI",{});var oXe=s(w_);Pbe=n(oXe,"STRONG",{});var wXt=s(Pbe);CPo=r(wXt,"clip"),wXt.forEach(t),wPo=r(oXe," \u2014 "),Bz=n(oXe,"A",{href:!0});var AXt=s(Bz);APo=r(AXt,"CLIPImageProcessor"),AXt.forEach(t),LPo=r(oXe," (CLIP model)"),oXe.forEach(t),yPo=i(te),A_=n(te,"LI",{});var rXe=s(A_);Bbe=n(rXe,"STRONG",{});var LXt=s(Bbe);xPo=r(LXt,"convnext"),LXt.forEach(t),$Po=r(rXe," \u2014 "),Iz=n(rXe,"A",{href:!0});var yXt=s(Iz);kPo=r(yXt,"ConvNextImageProcessor"),yXt.forEach(t),SPo=r(rXe," (ConvNeXT model)"),rXe.forEach(t),RPo=i(te),L_=n(te,"LI",{});var tXe=s(L_);Ibe=n(tXe,"STRONG",{});var xXt=s(Ibe);PPo=r(xXt,"cvt"),xXt.forEach(t),BPo=r(tXe," \u2014 "),Nz=n(tXe,"A",{href:!0});var $Xt=s(Nz);IPo=r($Xt,"ConvNextImageProcessor"),$Xt.forEach(t),NPo=r(tXe," (CvT model)"),tXe.forEach(t),qPo=i(te),y_=n(te,"LI",{});var aXe=s(y_);Nbe=n(aXe,"STRONG",{});var kXt=s(Nbe);jPo=r(kXt,"data2vec-vision"),kXt.forEach(t),DPo=r(aXe," \u2014 "),qz=n(aXe,"A",{href:!0});var SXt=s(qz);GPo=r(SXt,"BeitImageProcessor"),SXt.forEach(t),OPo=r(aXe," (Data2VecVision model)"),aXe.forEach(t),VPo=i(te),x_=n(te,"LI",{});var nXe=s(x_);qbe=n(nXe,"STRONG",{});var RXt=s(qbe);XPo=r(RXt,"deit"),RXt.forEach(t),zPo=r(nXe," \u2014 "),jz=n(nXe,"A",{href:!0});var PXt=s(jz);QPo=r(PXt,"DeiTImageProcessor"),PXt.forEach(t),WPo=r(nXe," (DeiT model)"),nXe.forEach(t),UPo=i(te),$_=n(te,"LI",{});var sXe=s($_);jbe=n(sXe,"STRONG",{});var BXt=s(jbe);HPo=r(BXt,"dpt"),BXt.forEach(t),JPo=r(sXe," \u2014 "),Dz=n(sXe,"A",{href:!0});var IXt=s(Dz);YPo=r(IXt,"DPTImageProcessor"),IXt.forEach(t),ZPo=r(sXe," (DPT model)"),sXe.forEach(t),KPo=i(te),k_=n(te,"LI",{});var lXe=s(k_);Dbe=n(lXe,"STRONG",{});var NXt=s(Dbe);eBo=r(NXt,"flava"),NXt.forEach(t),oBo=r(lXe," \u2014 "),Gz=n(lXe,"A",{href:!0});var qXt=s(Gz);rBo=r(qXt,"FlavaImageProcessor"),qXt.forEach(t),tBo=r(lXe," (FLAVA model)"),lXe.forEach(t),aBo=i(te),S_=n(te,"LI",{});var iXe=s(S_);Gbe=n(iXe,"STRONG",{});var jXt=s(Gbe);nBo=r(jXt,"glpn"),jXt.forEach(t),sBo=r(iXe," \u2014 "),Oz=n(iXe,"A",{href:!0});var DXt=s(Oz);lBo=r(DXt,"GLPNImageProcessor"),DXt.forEach(t),iBo=r(iXe," (GLPN model)"),iXe.forEach(t),dBo=i(te),R_=n(te,"LI",{});var dXe=s(R_);Obe=n(dXe,"STRONG",{});var GXt=s(Obe);mBo=r(GXt,"groupvit"),GXt.forEach(t),cBo=r(dXe," \u2014 "),Vz=n(dXe,"A",{href:!0});var OXt=s(Vz);fBo=r(OXt,"CLIPImageProcessor"),OXt.forEach(t),gBo=r(dXe," (GroupViT model)"),dXe.forEach(t),hBo=i(te),P_=n(te,"LI",{});var mXe=s(P_);Vbe=n(mXe,"STRONG",{});var VXt=s(Vbe);uBo=r(VXt,"imagegpt"),VXt.forEach(t),pBo=r(mXe," \u2014 "),Xz=n(mXe,"A",{href:!0});var XXt=s(Xz);_Bo=r(XXt,"ImageGPTImageProcessor"),XXt.forEach(t),bBo=r(mXe," (ImageGPT model)"),mXe.forEach(t),vBo=i(te),B_=n(te,"LI",{});var cXe=s(B_);Xbe=n(cXe,"STRONG",{});var zXt=s(Xbe);FBo=r(zXt,"layoutlmv2"),zXt.forEach(t),TBo=r(cXe," \u2014 "),zz=n(cXe,"A",{href:!0});var QXt=s(zz);MBo=r(QXt,"LayoutLMv2ImageProcessor"),QXt.forEach(t),EBo=r(cXe," (LayoutLMv2 model)"),cXe.forEach(t),CBo=i(te),I_=n(te,"LI",{});var fXe=s(I_);zbe=n(fXe,"STRONG",{});var WXt=s(zbe);wBo=r(WXt,"layoutlmv3"),WXt.forEach(t),ABo=r(fXe," \u2014 "),Qz=n(fXe,"A",{href:!0});var UXt=s(Qz);LBo=r(UXt,"LayoutLMv3ImageProcessor"),UXt.forEach(t),yBo=r(fXe," (LayoutLMv3 model)"),fXe.forEach(t),xBo=i(te),N_=n(te,"LI",{});var gXe=s(N_);Qbe=n(gXe,"STRONG",{});var HXt=s(Qbe);$Bo=r(HXt,"levit"),HXt.forEach(t),kBo=r(gXe," \u2014 "),Wz=n(gXe,"A",{href:!0});var JXt=s(Wz);SBo=r(JXt,"LevitImageProcessor"),JXt.forEach(t),RBo=r(gXe," (LeViT model)"),gXe.forEach(t),PBo=i(te),q_=n(te,"LI",{});var hXe=s(q_);Wbe=n(hXe,"STRONG",{});var YXt=s(Wbe);BBo=r(YXt,"mobilenet_v2"),YXt.forEach(t),IBo=r(hXe," \u2014 "),Uz=n(hXe,"A",{href:!0});var ZXt=s(Uz);NBo=r(ZXt,"MobileNetV2ImageProcessor"),ZXt.forEach(t),qBo=r(hXe," (MobileNetV2 model)"),hXe.forEach(t),jBo=i(te),j_=n(te,"LI",{});var uXe=s(j_);Ube=n(uXe,"STRONG",{});var KXt=s(Ube);DBo=r(KXt,"mobilevit"),KXt.forEach(t),GBo=r(uXe," \u2014 "),Hz=n(uXe,"A",{href:!0});var ezt=s(Hz);OBo=r(ezt,"MobileViTImageProcessor"),ezt.forEach(t),VBo=r(uXe," (MobileViT model)"),uXe.forEach(t),XBo=i(te),D_=n(te,"LI",{});var pXe=s(D_);Hbe=n(pXe,"STRONG",{});var ozt=s(Hbe);zBo=r(ozt,"perceiver"),ozt.forEach(t),QBo=r(pXe," \u2014 "),Jz=n(pXe,"A",{href:!0});var rzt=s(Jz);WBo=r(rzt,"PerceiverImageProcessor"),rzt.forEach(t),UBo=r(pXe," (Perceiver model)"),pXe.forEach(t),HBo=i(te),G_=n(te,"LI",{});var _Xe=s(G_);Jbe=n(_Xe,"STRONG",{});var tzt=s(Jbe);JBo=r(tzt,"poolformer"),tzt.forEach(t),YBo=r(_Xe," \u2014 "),Yz=n(_Xe,"A",{href:!0});var azt=s(Yz);ZBo=r(azt,"PoolFormerImageProcessor"),azt.forEach(t),KBo=r(_Xe," (PoolFormer model)"),_Xe.forEach(t),eIo=i(te),O_=n(te,"LI",{});var bXe=s(O_);Ybe=n(bXe,"STRONG",{});var nzt=s(Ybe);oIo=r(nzt,"regnet"),nzt.forEach(t),rIo=r(bXe," \u2014 "),Zz=n(bXe,"A",{href:!0});var szt=s(Zz);tIo=r(szt,"ConvNextImageProcessor"),szt.forEach(t),aIo=r(bXe," (RegNet model)"),bXe.forEach(t),nIo=i(te),V_=n(te,"LI",{});var vXe=s(V_);Zbe=n(vXe,"STRONG",{});var lzt=s(Zbe);sIo=r(lzt,"resnet"),lzt.forEach(t),lIo=r(vXe," \u2014 "),Kz=n(vXe,"A",{href:!0});var izt=s(Kz);iIo=r(izt,"ConvNextImageProcessor"),izt.forEach(t),dIo=r(vXe," (ResNet model)"),vXe.forEach(t),mIo=i(te),X_=n(te,"LI",{});var FXe=s(X_);Kbe=n(FXe,"STRONG",{});var dzt=s(Kbe);cIo=r(dzt,"segformer"),dzt.forEach(t),fIo=r(FXe," \u2014 "),eQ=n(FXe,"A",{href:!0});var mzt=s(eQ);gIo=r(mzt,"SegformerImageProcessor"),mzt.forEach(t),hIo=r(FXe," (SegFormer model)"),FXe.forEach(t),uIo=i(te),z_=n(te,"LI",{});var TXe=s(z_);eve=n(TXe,"STRONG",{});var czt=s(eve);pIo=r(czt,"swin"),czt.forEach(t),_Io=r(TXe," \u2014 "),oQ=n(TXe,"A",{href:!0});var fzt=s(oQ);bIo=r(fzt,"ViTImageProcessor"),fzt.forEach(t),vIo=r(TXe," (Swin Transformer model)"),TXe.forEach(t),FIo=i(te),Q_=n(te,"LI",{});var MXe=s(Q_);ove=n(MXe,"STRONG",{});var gzt=s(ove);TIo=r(gzt,"swinv2"),gzt.forEach(t),MIo=r(MXe," \u2014 "),rQ=n(MXe,"A",{href:!0});var hzt=s(rQ);EIo=r(hzt,"ViTImageProcessor"),hzt.forEach(t),CIo=r(MXe," (Swin Transformer V2 model)"),MXe.forEach(t),wIo=i(te),W_=n(te,"LI",{});var EXe=s(W_);rve=n(EXe,"STRONG",{});var uzt=s(rve);AIo=r(uzt,"van"),uzt.forEach(t),LIo=r(EXe," \u2014 "),tQ=n(EXe,"A",{href:!0});var pzt=s(tQ);yIo=r(pzt,"ConvNextImageProcessor"),pzt.forEach(t),xIo=r(EXe," (VAN model)"),EXe.forEach(t),$Io=i(te),U_=n(te,"LI",{});var CXe=s(U_);tve=n(CXe,"STRONG",{});var _zt=s(tve);kIo=r(_zt,"videomae"),_zt.forEach(t),SIo=r(CXe," \u2014 "),aQ=n(CXe,"A",{href:!0});var bzt=s(aQ);RIo=r(bzt,"VideoMAEImageProcessor"),bzt.forEach(t),PIo=r(CXe," (VideoMAE model)"),CXe.forEach(t),BIo=i(te),H_=n(te,"LI",{});var wXe=s(H_);ave=n(wXe,"STRONG",{});var vzt=s(ave);IIo=r(vzt,"vilt"),vzt.forEach(t),NIo=r(wXe," \u2014 "),nQ=n(wXe,"A",{href:!0});var Fzt=s(nQ);qIo=r(Fzt,"ViltImageProcessor"),Fzt.forEach(t),jIo=r(wXe," (ViLT model)"),wXe.forEach(t),DIo=i(te),J_=n(te,"LI",{});var AXe=s(J_);nve=n(AXe,"STRONG",{});var Tzt=s(nve);GIo=r(Tzt,"vit"),Tzt.forEach(t),OIo=r(AXe," \u2014 "),sQ=n(AXe,"A",{href:!0});var Mzt=s(sQ);VIo=r(Mzt,"ViTImageProcessor"),Mzt.forEach(t),XIo=r(AXe," (ViT model)"),AXe.forEach(t),zIo=i(te),Y_=n(te,"LI",{});var LXe=s(Y_);sve=n(LXe,"STRONG",{});var Ezt=s(sve);QIo=r(Ezt,"vit_mae"),Ezt.forEach(t),WIo=r(LXe," \u2014 "),lQ=n(LXe,"A",{href:!0});var Czt=s(lQ);UIo=r(Czt,"ViTImageProcessor"),Czt.forEach(t),HIo=r(LXe," (ViTMAE model)"),LXe.forEach(t),JIo=i(te),Z_=n(te,"LI",{});var yXe=s(Z_);lve=n(yXe,"STRONG",{});var wzt=s(lve);YIo=r(wzt,"vit_msn"),wzt.forEach(t),ZIo=r(yXe," \u2014 "),iQ=n(yXe,"A",{href:!0});var Azt=s(iQ);KIo=r(Azt,"ViTImageProcessor"),Azt.forEach(t),eNo=r(yXe," (ViTMSN model)"),yXe.forEach(t),oNo=i(te),K_=n(te,"LI",{});var xXe=s(K_);ive=n(xXe,"STRONG",{});var Lzt=s(ive);rNo=r(Lzt,"xclip"),Lzt.forEach(t),tNo=r(xXe," \u2014 "),dQ=n(xXe,"A",{href:!0});var yzt=s(dQ);aNo=r(yzt,"CLIPImageProcessor"),yzt.forEach(t),nNo=r(xXe," (X-CLIP model)"),xXe.forEach(t),te.forEach(t),sNo=i($a),T(e1.$$.fragment,$a),lNo=i($a),T(o1.$$.fragment,$a),$a.forEach(t),iNo=i(zl),r1=n(zl,"DIV",{class:!0});var $mo=s(r1);T(Qk.$$.fragment,$mo),dNo=i($mo),dve=n($mo,"P",{});var xzt=s(dve);mNo=r(xzt,"Register a new image processor for this class."),xzt.forEach(t),$mo.forEach(t),zl.forEach(t),cio=i(c),jd=n(c,"H2",{class:!0});var kmo=s(jd);t1=n(kmo,"A",{id:!0,class:!0,href:!0});var $zt=s(t1);mve=n($zt,"SPAN",{});var kzt=s(mve);T(Wk.$$.fragment,kzt),kzt.forEach(t),$zt.forEach(t),cNo=i(kmo),cve=n(kmo,"SPAN",{});var Szt=s(cve);fNo=r(Szt,"AutoProcessor"),Szt.forEach(t),kmo.forEach(t),fio=i(c),jo=n(c,"DIV",{class:!0});var Ql=s(jo);T(Uk.$$.fragment,Ql),gNo=i(Ql),Hk=n(Ql,"P",{});var Smo=s(Hk);hNo=r(Smo,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),mQ=n(Smo,"A",{href:!0});var Rzt=s(mQ);uNo=r(Rzt,"AutoProcessor.from_pretrained()"),Rzt.forEach(t),pNo=r(Smo," class method."),Smo.forEach(t),_No=i(Ql),Jk=n(Ql,"P",{});var Rmo=s(Jk);bNo=r(Rmo,"This class cannot be instantiated directly using "),fve=n(Rmo,"CODE",{});var Pzt=s(fve);vNo=r(Pzt,"__init__()"),Pzt.forEach(t),FNo=r(Rmo," (throws an error)."),Rmo.forEach(t),TNo=i(Ql),ro=n(Ql,"DIV",{class:!0});var ka=s(ro);T(Yk.$$.fragment,ka),MNo=i(ka),gve=n(ka,"P",{});var Bzt=s(gve);ENo=r(Bzt,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),Bzt.forEach(t),CNo=i(ka),Dd=n(ka,"P",{});var Efe=s(Dd);wNo=r(Efe,"The processor class to instantiate is selected based on the "),hve=n(Efe,"CODE",{});var Izt=s(hve);ANo=r(Izt,"model_type"),Izt.forEach(t),LNo=r(Efe,` property of the config object (either
passed as an argument or loaded from `),uve=n(Efe,"CODE",{});var Nzt=s(uve);yNo=r(Nzt,"pretrained_model_name_or_path"),Nzt.forEach(t),xNo=r(Efe," if possible):"),Efe.forEach(t),$No=i(ka),ie=n(ka,"UL",{});var ce=s(ie);a1=n(ce,"LI",{});var $Xe=s(a1);pve=n($Xe,"STRONG",{});var qzt=s(pve);kNo=r(qzt,"clip"),qzt.forEach(t),SNo=r($Xe," \u2014 "),cQ=n($Xe,"A",{href:!0});var jzt=s(cQ);RNo=r(jzt,"CLIPProcessor"),jzt.forEach(t),PNo=r($Xe," (CLIP model)"),$Xe.forEach(t),BNo=i(ce),n1=n(ce,"LI",{});var kXe=s(n1);_ve=n(kXe,"STRONG",{});var Dzt=s(_ve);INo=r(Dzt,"clipseg"),Dzt.forEach(t),NNo=r(kXe," \u2014 "),fQ=n(kXe,"A",{href:!0});var Gzt=s(fQ);qNo=r(Gzt,"CLIPSegProcessor"),Gzt.forEach(t),jNo=r(kXe," (CLIPSeg model)"),kXe.forEach(t),DNo=i(ce),s1=n(ce,"LI",{});var SXe=s(s1);bve=n(SXe,"STRONG",{});var Ozt=s(bve);GNo=r(Ozt,"flava"),Ozt.forEach(t),ONo=r(SXe," \u2014 "),gQ=n(SXe,"A",{href:!0});var Vzt=s(gQ);VNo=r(Vzt,"FlavaProcessor"),Vzt.forEach(t),XNo=r(SXe," (FLAVA model)"),SXe.forEach(t),zNo=i(ce),l1=n(ce,"LI",{});var RXe=s(l1);vve=n(RXe,"STRONG",{});var Xzt=s(vve);QNo=r(Xzt,"groupvit"),Xzt.forEach(t),WNo=r(RXe," \u2014 "),hQ=n(RXe,"A",{href:!0});var zzt=s(hQ);UNo=r(zzt,"CLIPProcessor"),zzt.forEach(t),HNo=r(RXe," (GroupViT model)"),RXe.forEach(t),JNo=i(ce),i1=n(ce,"LI",{});var PXe=s(i1);Fve=n(PXe,"STRONG",{});var Qzt=s(Fve);YNo=r(Qzt,"layoutlmv2"),Qzt.forEach(t),ZNo=r(PXe," \u2014 "),uQ=n(PXe,"A",{href:!0});var Wzt=s(uQ);KNo=r(Wzt,"LayoutLMv2Processor"),Wzt.forEach(t),eqo=r(PXe," (LayoutLMv2 model)"),PXe.forEach(t),oqo=i(ce),d1=n(ce,"LI",{});var BXe=s(d1);Tve=n(BXe,"STRONG",{});var Uzt=s(Tve);rqo=r(Uzt,"layoutlmv3"),Uzt.forEach(t),tqo=r(BXe," \u2014 "),pQ=n(BXe,"A",{href:!0});var Hzt=s(pQ);aqo=r(Hzt,"LayoutLMv3Processor"),Hzt.forEach(t),nqo=r(BXe," (LayoutLMv3 model)"),BXe.forEach(t),sqo=i(ce),m1=n(ce,"LI",{});var IXe=s(m1);Mve=n(IXe,"STRONG",{});var Jzt=s(Mve);lqo=r(Jzt,"layoutxlm"),Jzt.forEach(t),iqo=r(IXe," \u2014 "),_Q=n(IXe,"A",{href:!0});var Yzt=s(_Q);dqo=r(Yzt,"LayoutXLMProcessor"),Yzt.forEach(t),mqo=r(IXe," (LayoutXLM model)"),IXe.forEach(t),cqo=i(ce),c1=n(ce,"LI",{});var NXe=s(c1);Eve=n(NXe,"STRONG",{});var Zzt=s(Eve);fqo=r(Zzt,"markuplm"),Zzt.forEach(t),gqo=r(NXe," \u2014 "),bQ=n(NXe,"A",{href:!0});var Kzt=s(bQ);hqo=r(Kzt,"MarkupLMProcessor"),Kzt.forEach(t),uqo=r(NXe," (MarkupLM model)"),NXe.forEach(t),pqo=i(ce),f1=n(ce,"LI",{});var qXe=s(f1);Cve=n(qXe,"STRONG",{});var eQt=s(Cve);_qo=r(eQt,"owlvit"),eQt.forEach(t),bqo=r(qXe," \u2014 "),vQ=n(qXe,"A",{href:!0});var oQt=s(vQ);vqo=r(oQt,"OwlViTProcessor"),oQt.forEach(t),Fqo=r(qXe," (OWL-ViT model)"),qXe.forEach(t),Tqo=i(ce),g1=n(ce,"LI",{});var jXe=s(g1);wve=n(jXe,"STRONG",{});var rQt=s(wve);Mqo=r(rQt,"sew"),rQt.forEach(t),Eqo=r(jXe," \u2014 "),FQ=n(jXe,"A",{href:!0});var tQt=s(FQ);Cqo=r(tQt,"Wav2Vec2Processor"),tQt.forEach(t),wqo=r(jXe," (SEW model)"),jXe.forEach(t),Aqo=i(ce),h1=n(ce,"LI",{});var DXe=s(h1);Ave=n(DXe,"STRONG",{});var aQt=s(Ave);Lqo=r(aQt,"sew-d"),aQt.forEach(t),yqo=r(DXe," \u2014 "),TQ=n(DXe,"A",{href:!0});var nQt=s(TQ);xqo=r(nQt,"Wav2Vec2Processor"),nQt.forEach(t),$qo=r(DXe," (SEW-D model)"),DXe.forEach(t),kqo=i(ce),u1=n(ce,"LI",{});var GXe=s(u1);Lve=n(GXe,"STRONG",{});var sQt=s(Lve);Sqo=r(sQt,"speech_to_text"),sQt.forEach(t),Rqo=r(GXe," \u2014 "),MQ=n(GXe,"A",{href:!0});var lQt=s(MQ);Pqo=r(lQt,"Speech2TextProcessor"),lQt.forEach(t),Bqo=r(GXe," (Speech2Text model)"),GXe.forEach(t),Iqo=i(ce),p1=n(ce,"LI",{});var OXe=s(p1);yve=n(OXe,"STRONG",{});var iQt=s(yve);Nqo=r(iQt,"speech_to_text_2"),iQt.forEach(t),qqo=r(OXe," \u2014 "),EQ=n(OXe,"A",{href:!0});var dQt=s(EQ);jqo=r(dQt,"Speech2Text2Processor"),dQt.forEach(t),Dqo=r(OXe," (Speech2Text2 model)"),OXe.forEach(t),Gqo=i(ce),_1=n(ce,"LI",{});var VXe=s(_1);xve=n(VXe,"STRONG",{});var mQt=s(xve);Oqo=r(mQt,"trocr"),mQt.forEach(t),Vqo=r(VXe," \u2014 "),CQ=n(VXe,"A",{href:!0});var cQt=s(CQ);Xqo=r(cQt,"TrOCRProcessor"),cQt.forEach(t),zqo=r(VXe," (TrOCR model)"),VXe.forEach(t),Qqo=i(ce),b1=n(ce,"LI",{});var XXe=s(b1);$ve=n(XXe,"STRONG",{});var fQt=s($ve);Wqo=r(fQt,"unispeech"),fQt.forEach(t),Uqo=r(XXe," \u2014 "),wQ=n(XXe,"A",{href:!0});var gQt=s(wQ);Hqo=r(gQt,"Wav2Vec2Processor"),gQt.forEach(t),Jqo=r(XXe," (UniSpeech model)"),XXe.forEach(t),Yqo=i(ce),v1=n(ce,"LI",{});var zXe=s(v1);kve=n(zXe,"STRONG",{});var hQt=s(kve);Zqo=r(hQt,"unispeech-sat"),hQt.forEach(t),Kqo=r(zXe," \u2014 "),AQ=n(zXe,"A",{href:!0});var uQt=s(AQ);ejo=r(uQt,"Wav2Vec2Processor"),uQt.forEach(t),ojo=r(zXe," (UniSpeechSat model)"),zXe.forEach(t),rjo=i(ce),F1=n(ce,"LI",{});var QXe=s(F1);Sve=n(QXe,"STRONG",{});var pQt=s(Sve);tjo=r(pQt,"vilt"),pQt.forEach(t),ajo=r(QXe," \u2014 "),LQ=n(QXe,"A",{href:!0});var _Qt=s(LQ);njo=r(_Qt,"ViltProcessor"),_Qt.forEach(t),sjo=r(QXe," (ViLT model)"),QXe.forEach(t),ljo=i(ce),T1=n(ce,"LI",{});var WXe=s(T1);Rve=n(WXe,"STRONG",{});var bQt=s(Rve);ijo=r(bQt,"vision-text-dual-encoder"),bQt.forEach(t),djo=r(WXe," \u2014 "),yQ=n(WXe,"A",{href:!0});var vQt=s(yQ);mjo=r(vQt,"VisionTextDualEncoderProcessor"),vQt.forEach(t),cjo=r(WXe," (VisionTextDualEncoder model)"),WXe.forEach(t),fjo=i(ce),M1=n(ce,"LI",{});var UXe=s(M1);Pve=n(UXe,"STRONG",{});var FQt=s(Pve);gjo=r(FQt,"wav2vec2"),FQt.forEach(t),hjo=r(UXe," \u2014 "),xQ=n(UXe,"A",{href:!0});var TQt=s(xQ);ujo=r(TQt,"Wav2Vec2Processor"),TQt.forEach(t),pjo=r(UXe," (Wav2Vec2 model)"),UXe.forEach(t),_jo=i(ce),E1=n(ce,"LI",{});var HXe=s(E1);Bve=n(HXe,"STRONG",{});var MQt=s(Bve);bjo=r(MQt,"wav2vec2-conformer"),MQt.forEach(t),vjo=r(HXe," \u2014 "),$Q=n(HXe,"A",{href:!0});var EQt=s($Q);Fjo=r(EQt,"Wav2Vec2Processor"),EQt.forEach(t),Tjo=r(HXe," (Wav2Vec2-Conformer model)"),HXe.forEach(t),Mjo=i(ce),C1=n(ce,"LI",{});var JXe=s(C1);Ive=n(JXe,"STRONG",{});var CQt=s(Ive);Ejo=r(CQt,"wavlm"),CQt.forEach(t),Cjo=r(JXe," \u2014 "),kQ=n(JXe,"A",{href:!0});var wQt=s(kQ);wjo=r(wQt,"Wav2Vec2Processor"),wQt.forEach(t),Ajo=r(JXe," (WavLM model)"),JXe.forEach(t),Ljo=i(ce),w1=n(ce,"LI",{});var YXe=s(w1);Nve=n(YXe,"STRONG",{});var AQt=s(Nve);yjo=r(AQt,"whisper"),AQt.forEach(t),xjo=r(YXe," \u2014 "),SQ=n(YXe,"A",{href:!0});var LQt=s(SQ);$jo=r(LQt,"WhisperProcessor"),LQt.forEach(t),kjo=r(YXe," (Whisper model)"),YXe.forEach(t),Sjo=i(ce),A1=n(ce,"LI",{});var ZXe=s(A1);qve=n(ZXe,"STRONG",{});var yQt=s(qve);Rjo=r(yQt,"xclip"),yQt.forEach(t),Pjo=r(ZXe," \u2014 "),RQ=n(ZXe,"A",{href:!0});var xQt=s(RQ);Bjo=r(xQt,"XCLIPProcessor"),xQt.forEach(t),Ijo=r(ZXe," (X-CLIP model)"),ZXe.forEach(t),ce.forEach(t),Njo=i(ka),T(L1.$$.fragment,ka),qjo=i(ka),T(y1.$$.fragment,ka),ka.forEach(t),jjo=i(Ql),x1=n(Ql,"DIV",{class:!0});var Pmo=s(x1);T(Zk.$$.fragment,Pmo),Djo=i(Pmo),jve=n(Pmo,"P",{});var $Qt=s(jve);Gjo=r($Qt,"Register a new processor for this class."),$Qt.forEach(t),Pmo.forEach(t),Ql.forEach(t),gio=i(c),Gd=n(c,"H2",{class:!0});var Bmo=s(Gd);$1=n(Bmo,"A",{id:!0,class:!0,href:!0});var kQt=s($1);Dve=n(kQt,"SPAN",{});var SQt=s(Dve);T(Kk.$$.fragment,SQt),SQt.forEach(t),kQt.forEach(t),Ojo=i(Bmo),Gve=n(Bmo,"SPAN",{});var RQt=s(Gve);Vjo=r(RQt,"AutoModel"),RQt.forEach(t),Bmo.forEach(t),hio=i(c),Do=n(c,"DIV",{class:!0});var Wl=s(Do);T(eS.$$.fragment,Wl),Xjo=i(Wl),Od=n(Wl,"P",{});var Cfe=s(Od);zjo=r(Cfe,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),PQ=n(Cfe,"A",{href:!0});var PQt=s(PQ);Qjo=r(PQt,"from_pretrained()"),PQt.forEach(t),Wjo=r(Cfe," class method or the "),BQ=n(Cfe,"A",{href:!0});var BQt=s(BQ);Ujo=r(BQt,"from_config()"),BQt.forEach(t),Hjo=r(Cfe,` class
method.`),Cfe.forEach(t),Jjo=i(Wl),oS=n(Wl,"P",{});var Imo=s(oS);Yjo=r(Imo,"This class cannot be instantiated directly using "),Ove=n(Imo,"CODE",{});var IQt=s(Ove);Zjo=r(IQt,"__init__()"),IQt.forEach(t),Kjo=r(Imo," (throws an error)."),Imo.forEach(t),eDo=i(Wl),At=n(Wl,"DIV",{class:!0});var fx=s(At);T(rS.$$.fragment,fx),oDo=i(fx),Vve=n(fx,"P",{});var NQt=s(Vve);rDo=r(NQt,"Instantiates one of the base model classes of the library from a configuration."),NQt.forEach(t),tDo=i(fx),Vd=n(fx,"P",{});var wfe=s(Vd);aDo=r(wfe,`Note:
Loading a model from its configuration file does `),Xve=n(wfe,"STRONG",{});var qQt=s(Xve);nDo=r(qQt,"not"),qQt.forEach(t),sDo=r(wfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),IQ=n(wfe,"A",{href:!0});var jQt=s(IQ);lDo=r(jQt,"from_pretrained()"),jQt.forEach(t),iDo=r(wfe," to load the model weights."),wfe.forEach(t),dDo=i(fx),T(k1.$$.fragment,fx),fx.forEach(t),mDo=i(Wl),to=n(Wl,"DIV",{class:!0});var Sa=s(to);T(tS.$$.fragment,Sa),cDo=i(Sa),zve=n(Sa,"P",{});var DQt=s(zve);fDo=r(DQt,"Instantiate one of the base model classes of the library from a pretrained model."),DQt.forEach(t),gDo=i(Sa),gn=n(Sa,"P",{});var gx=s(gn);hDo=r(gx,"The model class to instantiate is selected based on the "),Qve=n(gx,"CODE",{});var GQt=s(Qve);uDo=r(GQt,"model_type"),GQt.forEach(t),pDo=r(gx,` property of the config object (either
passed as an argument or loaded from `),Wve=n(gx,"CODE",{});var OQt=s(Wve);_Do=r(OQt,"pretrained_model_name_or_path"),OQt.forEach(t),bDo=r(gx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Uve=n(gx,"CODE",{});var VQt=s(Uve);vDo=r(VQt,"pretrained_model_name_or_path"),VQt.forEach(t),FDo=r(gx,":"),gx.forEach(t),TDo=i(Sa),y=n(Sa,"UL",{});var x=s(y);S1=n(x,"LI",{});var KXe=s(S1);Hve=n(KXe,"STRONG",{});var XQt=s(Hve);MDo=r(XQt,"albert"),XQt.forEach(t),EDo=r(KXe," \u2014 "),NQ=n(KXe,"A",{href:!0});var zQt=s(NQ);CDo=r(zQt,"AlbertModel"),zQt.forEach(t),wDo=r(KXe," (ALBERT model)"),KXe.forEach(t),ADo=i(x),R1=n(x,"LI",{});var eze=s(R1);Jve=n(eze,"STRONG",{});var QQt=s(Jve);LDo=r(QQt,"bart"),QQt.forEach(t),yDo=r(eze," \u2014 "),qQ=n(eze,"A",{href:!0});var WQt=s(qQ);xDo=r(WQt,"BartModel"),WQt.forEach(t),$Do=r(eze," (BART model)"),eze.forEach(t),kDo=i(x),P1=n(x,"LI",{});var oze=s(P1);Yve=n(oze,"STRONG",{});var UQt=s(Yve);SDo=r(UQt,"beit"),UQt.forEach(t),RDo=r(oze," \u2014 "),jQ=n(oze,"A",{href:!0});var HQt=s(jQ);PDo=r(HQt,"BeitModel"),HQt.forEach(t),BDo=r(oze," (BEiT model)"),oze.forEach(t),IDo=i(x),B1=n(x,"LI",{});var rze=s(B1);Zve=n(rze,"STRONG",{});var JQt=s(Zve);NDo=r(JQt,"bert"),JQt.forEach(t),qDo=r(rze," \u2014 "),DQ=n(rze,"A",{href:!0});var YQt=s(DQ);jDo=r(YQt,"BertModel"),YQt.forEach(t),DDo=r(rze," (BERT model)"),rze.forEach(t),GDo=i(x),I1=n(x,"LI",{});var tze=s(I1);Kve=n(tze,"STRONG",{});var ZQt=s(Kve);ODo=r(ZQt,"bert-generation"),ZQt.forEach(t),VDo=r(tze," \u2014 "),GQ=n(tze,"A",{href:!0});var KQt=s(GQ);XDo=r(KQt,"BertGenerationEncoder"),KQt.forEach(t),zDo=r(tze," (Bert Generation model)"),tze.forEach(t),QDo=i(x),N1=n(x,"LI",{});var aze=s(N1);eFe=n(aze,"STRONG",{});var eWt=s(eFe);WDo=r(eWt,"big_bird"),eWt.forEach(t),UDo=r(aze," \u2014 "),OQ=n(aze,"A",{href:!0});var oWt=s(OQ);HDo=r(oWt,"BigBirdModel"),oWt.forEach(t),JDo=r(aze," (BigBird model)"),aze.forEach(t),YDo=i(x),q1=n(x,"LI",{});var nze=s(q1);oFe=n(nze,"STRONG",{});var rWt=s(oFe);ZDo=r(rWt,"bigbird_pegasus"),rWt.forEach(t),KDo=r(nze," \u2014 "),VQ=n(nze,"A",{href:!0});var tWt=s(VQ);eGo=r(tWt,"BigBirdPegasusModel"),tWt.forEach(t),oGo=r(nze," (BigBird-Pegasus model)"),nze.forEach(t),rGo=i(x),j1=n(x,"LI",{});var sze=s(j1);rFe=n(sze,"STRONG",{});var aWt=s(rFe);tGo=r(aWt,"blenderbot"),aWt.forEach(t),aGo=r(sze," \u2014 "),XQ=n(sze,"A",{href:!0});var nWt=s(XQ);nGo=r(nWt,"BlenderbotModel"),nWt.forEach(t),sGo=r(sze," (Blenderbot model)"),sze.forEach(t),lGo=i(x),D1=n(x,"LI",{});var lze=s(D1);tFe=n(lze,"STRONG",{});var sWt=s(tFe);iGo=r(sWt,"blenderbot-small"),sWt.forEach(t),dGo=r(lze," \u2014 "),zQ=n(lze,"A",{href:!0});var lWt=s(zQ);mGo=r(lWt,"BlenderbotSmallModel"),lWt.forEach(t),cGo=r(lze," (BlenderbotSmall model)"),lze.forEach(t),fGo=i(x),G1=n(x,"LI",{});var ize=s(G1);aFe=n(ize,"STRONG",{});var iWt=s(aFe);gGo=r(iWt,"bloom"),iWt.forEach(t),hGo=r(ize," \u2014 "),QQ=n(ize,"A",{href:!0});var dWt=s(QQ);uGo=r(dWt,"BloomModel"),dWt.forEach(t),pGo=r(ize," (BLOOM model)"),ize.forEach(t),_Go=i(x),O1=n(x,"LI",{});var dze=s(O1);nFe=n(dze,"STRONG",{});var mWt=s(nFe);bGo=r(mWt,"camembert"),mWt.forEach(t),vGo=r(dze," \u2014 "),WQ=n(dze,"A",{href:!0});var cWt=s(WQ);FGo=r(cWt,"CamembertModel"),cWt.forEach(t),TGo=r(dze," (CamemBERT model)"),dze.forEach(t),MGo=i(x),V1=n(x,"LI",{});var mze=s(V1);sFe=n(mze,"STRONG",{});var fWt=s(sFe);EGo=r(fWt,"canine"),fWt.forEach(t),CGo=r(mze," \u2014 "),UQ=n(mze,"A",{href:!0});var gWt=s(UQ);wGo=r(gWt,"CanineModel"),gWt.forEach(t),AGo=r(mze," (CANINE model)"),mze.forEach(t),LGo=i(x),X1=n(x,"LI",{});var cze=s(X1);lFe=n(cze,"STRONG",{});var hWt=s(lFe);yGo=r(hWt,"clip"),hWt.forEach(t),xGo=r(cze," \u2014 "),HQ=n(cze,"A",{href:!0});var uWt=s(HQ);$Go=r(uWt,"CLIPModel"),uWt.forEach(t),kGo=r(cze," (CLIP model)"),cze.forEach(t),SGo=i(x),z1=n(x,"LI",{});var fze=s(z1);iFe=n(fze,"STRONG",{});var pWt=s(iFe);RGo=r(pWt,"clipseg"),pWt.forEach(t),PGo=r(fze," \u2014 "),JQ=n(fze,"A",{href:!0});var _Wt=s(JQ);BGo=r(_Wt,"CLIPSegModel"),_Wt.forEach(t),IGo=r(fze," (CLIPSeg model)"),fze.forEach(t),NGo=i(x),Q1=n(x,"LI",{});var gze=s(Q1);dFe=n(gze,"STRONG",{});var bWt=s(dFe);qGo=r(bWt,"codegen"),bWt.forEach(t),jGo=r(gze," \u2014 "),YQ=n(gze,"A",{href:!0});var vWt=s(YQ);DGo=r(vWt,"CodeGenModel"),vWt.forEach(t),GGo=r(gze," (CodeGen model)"),gze.forEach(t),OGo=i(x),W1=n(x,"LI",{});var hze=s(W1);mFe=n(hze,"STRONG",{});var FWt=s(mFe);VGo=r(FWt,"conditional_detr"),FWt.forEach(t),XGo=r(hze," \u2014 "),ZQ=n(hze,"A",{href:!0});var TWt=s(ZQ);zGo=r(TWt,"ConditionalDetrModel"),TWt.forEach(t),QGo=r(hze," (Conditional DETR model)"),hze.forEach(t),WGo=i(x),U1=n(x,"LI",{});var uze=s(U1);cFe=n(uze,"STRONG",{});var MWt=s(cFe);UGo=r(MWt,"convbert"),MWt.forEach(t),HGo=r(uze," \u2014 "),KQ=n(uze,"A",{href:!0});var EWt=s(KQ);JGo=r(EWt,"ConvBertModel"),EWt.forEach(t),YGo=r(uze," (ConvBERT model)"),uze.forEach(t),ZGo=i(x),H1=n(x,"LI",{});var pze=s(H1);fFe=n(pze,"STRONG",{});var CWt=s(fFe);KGo=r(CWt,"convnext"),CWt.forEach(t),eOo=r(pze," \u2014 "),eW=n(pze,"A",{href:!0});var wWt=s(eW);oOo=r(wWt,"ConvNextModel"),wWt.forEach(t),rOo=r(pze," (ConvNeXT model)"),pze.forEach(t),tOo=i(x),J1=n(x,"LI",{});var _ze=s(J1);gFe=n(_ze,"STRONG",{});var AWt=s(gFe);aOo=r(AWt,"ctrl"),AWt.forEach(t),nOo=r(_ze," \u2014 "),oW=n(_ze,"A",{href:!0});var LWt=s(oW);sOo=r(LWt,"CTRLModel"),LWt.forEach(t),lOo=r(_ze," (CTRL model)"),_ze.forEach(t),iOo=i(x),Y1=n(x,"LI",{});var bze=s(Y1);hFe=n(bze,"STRONG",{});var yWt=s(hFe);dOo=r(yWt,"cvt"),yWt.forEach(t),mOo=r(bze," \u2014 "),rW=n(bze,"A",{href:!0});var xWt=s(rW);cOo=r(xWt,"CvtModel"),xWt.forEach(t),fOo=r(bze," (CvT model)"),bze.forEach(t),gOo=i(x),Z1=n(x,"LI",{});var vze=s(Z1);uFe=n(vze,"STRONG",{});var $Wt=s(uFe);hOo=r($Wt,"data2vec-audio"),$Wt.forEach(t),uOo=r(vze," \u2014 "),tW=n(vze,"A",{href:!0});var kWt=s(tW);pOo=r(kWt,"Data2VecAudioModel"),kWt.forEach(t),_Oo=r(vze," (Data2VecAudio model)"),vze.forEach(t),bOo=i(x),K1=n(x,"LI",{});var Fze=s(K1);pFe=n(Fze,"STRONG",{});var SWt=s(pFe);vOo=r(SWt,"data2vec-text"),SWt.forEach(t),FOo=r(Fze," \u2014 "),aW=n(Fze,"A",{href:!0});var RWt=s(aW);TOo=r(RWt,"Data2VecTextModel"),RWt.forEach(t),MOo=r(Fze," (Data2VecText model)"),Fze.forEach(t),EOo=i(x),e2=n(x,"LI",{});var Tze=s(e2);_Fe=n(Tze,"STRONG",{});var PWt=s(_Fe);COo=r(PWt,"data2vec-vision"),PWt.forEach(t),wOo=r(Tze," \u2014 "),nW=n(Tze,"A",{href:!0});var BWt=s(nW);AOo=r(BWt,"Data2VecVisionModel"),BWt.forEach(t),LOo=r(Tze," (Data2VecVision model)"),Tze.forEach(t),yOo=i(x),o2=n(x,"LI",{});var Mze=s(o2);bFe=n(Mze,"STRONG",{});var IWt=s(bFe);xOo=r(IWt,"deberta"),IWt.forEach(t),$Oo=r(Mze," \u2014 "),sW=n(Mze,"A",{href:!0});var NWt=s(sW);kOo=r(NWt,"DebertaModel"),NWt.forEach(t),SOo=r(Mze," (DeBERTa model)"),Mze.forEach(t),ROo=i(x),r2=n(x,"LI",{});var Eze=s(r2);vFe=n(Eze,"STRONG",{});var qWt=s(vFe);POo=r(qWt,"deberta-v2"),qWt.forEach(t),BOo=r(Eze," \u2014 "),lW=n(Eze,"A",{href:!0});var jWt=s(lW);IOo=r(jWt,"DebertaV2Model"),jWt.forEach(t),NOo=r(Eze," (DeBERTa-v2 model)"),Eze.forEach(t),qOo=i(x),t2=n(x,"LI",{});var Cze=s(t2);FFe=n(Cze,"STRONG",{});var DWt=s(FFe);jOo=r(DWt,"decision_transformer"),DWt.forEach(t),DOo=r(Cze," \u2014 "),iW=n(Cze,"A",{href:!0});var GWt=s(iW);GOo=r(GWt,"DecisionTransformerModel"),GWt.forEach(t),OOo=r(Cze," (Decision Transformer model)"),Cze.forEach(t),VOo=i(x),a2=n(x,"LI",{});var wze=s(a2);TFe=n(wze,"STRONG",{});var OWt=s(TFe);XOo=r(OWt,"deformable_detr"),OWt.forEach(t),zOo=r(wze," \u2014 "),dW=n(wze,"A",{href:!0});var VWt=s(dW);QOo=r(VWt,"DeformableDetrModel"),VWt.forEach(t),WOo=r(wze," (Deformable DETR model)"),wze.forEach(t),UOo=i(x),n2=n(x,"LI",{});var Aze=s(n2);MFe=n(Aze,"STRONG",{});var XWt=s(MFe);HOo=r(XWt,"deit"),XWt.forEach(t),JOo=r(Aze," \u2014 "),mW=n(Aze,"A",{href:!0});var zWt=s(mW);YOo=r(zWt,"DeiTModel"),zWt.forEach(t),ZOo=r(Aze," (DeiT model)"),Aze.forEach(t),KOo=i(x),s2=n(x,"LI",{});var Lze=s(s2);EFe=n(Lze,"STRONG",{});var QWt=s(EFe);eVo=r(QWt,"detr"),QWt.forEach(t),oVo=r(Lze," \u2014 "),cW=n(Lze,"A",{href:!0});var WWt=s(cW);rVo=r(WWt,"DetrModel"),WWt.forEach(t),tVo=r(Lze," (DETR model)"),Lze.forEach(t),aVo=i(x),l2=n(x,"LI",{});var yze=s(l2);CFe=n(yze,"STRONG",{});var UWt=s(CFe);nVo=r(UWt,"distilbert"),UWt.forEach(t),sVo=r(yze," \u2014 "),fW=n(yze,"A",{href:!0});var HWt=s(fW);lVo=r(HWt,"DistilBertModel"),HWt.forEach(t),iVo=r(yze," (DistilBERT model)"),yze.forEach(t),dVo=i(x),i2=n(x,"LI",{});var xze=s(i2);wFe=n(xze,"STRONG",{});var JWt=s(wFe);mVo=r(JWt,"donut-swin"),JWt.forEach(t),cVo=r(xze," \u2014 "),gW=n(xze,"A",{href:!0});var YWt=s(gW);fVo=r(YWt,"DonutSwinModel"),YWt.forEach(t),gVo=r(xze," (DonutSwin model)"),xze.forEach(t),hVo=i(x),d2=n(x,"LI",{});var $ze=s(d2);AFe=n($ze,"STRONG",{});var ZWt=s(AFe);uVo=r(ZWt,"dpr"),ZWt.forEach(t),pVo=r($ze," \u2014 "),hW=n($ze,"A",{href:!0});var KWt=s(hW);_Vo=r(KWt,"DPRQuestionEncoder"),KWt.forEach(t),bVo=r($ze," (DPR model)"),$ze.forEach(t),vVo=i(x),m2=n(x,"LI",{});var kze=s(m2);LFe=n(kze,"STRONG",{});var eUt=s(LFe);FVo=r(eUt,"dpt"),eUt.forEach(t),TVo=r(kze," \u2014 "),uW=n(kze,"A",{href:!0});var oUt=s(uW);MVo=r(oUt,"DPTModel"),oUt.forEach(t),EVo=r(kze," (DPT model)"),kze.forEach(t),CVo=i(x),c2=n(x,"LI",{});var Sze=s(c2);yFe=n(Sze,"STRONG",{});var rUt=s(yFe);wVo=r(rUt,"electra"),rUt.forEach(t),AVo=r(Sze," \u2014 "),pW=n(Sze,"A",{href:!0});var tUt=s(pW);LVo=r(tUt,"ElectraModel"),tUt.forEach(t),yVo=r(Sze," (ELECTRA model)"),Sze.forEach(t),xVo=i(x),f2=n(x,"LI",{});var Rze=s(f2);xFe=n(Rze,"STRONG",{});var aUt=s(xFe);$Vo=r(aUt,"ernie"),aUt.forEach(t),kVo=r(Rze," \u2014 "),_W=n(Rze,"A",{href:!0});var nUt=s(_W);SVo=r(nUt,"ErnieModel"),nUt.forEach(t),RVo=r(Rze," (ERNIE model)"),Rze.forEach(t),PVo=i(x),g2=n(x,"LI",{});var Pze=s(g2);$Fe=n(Pze,"STRONG",{});var sUt=s($Fe);BVo=r(sUt,"esm"),sUt.forEach(t),IVo=r(Pze," \u2014 "),bW=n(Pze,"A",{href:!0});var lUt=s(bW);NVo=r(lUt,"EsmModel"),lUt.forEach(t),qVo=r(Pze," (ESM model)"),Pze.forEach(t),jVo=i(x),h2=n(x,"LI",{});var Bze=s(h2);kFe=n(Bze,"STRONG",{});var iUt=s(kFe);DVo=r(iUt,"flaubert"),iUt.forEach(t),GVo=r(Bze," \u2014 "),vW=n(Bze,"A",{href:!0});var dUt=s(vW);OVo=r(dUt,"FlaubertModel"),dUt.forEach(t),VVo=r(Bze," (FlauBERT model)"),Bze.forEach(t),XVo=i(x),u2=n(x,"LI",{});var Ize=s(u2);SFe=n(Ize,"STRONG",{});var mUt=s(SFe);zVo=r(mUt,"flava"),mUt.forEach(t),QVo=r(Ize," \u2014 "),FW=n(Ize,"A",{href:!0});var cUt=s(FW);WVo=r(cUt,"FlavaModel"),cUt.forEach(t),UVo=r(Ize," (FLAVA model)"),Ize.forEach(t),HVo=i(x),p2=n(x,"LI",{});var Nze=s(p2);RFe=n(Nze,"STRONG",{});var fUt=s(RFe);JVo=r(fUt,"fnet"),fUt.forEach(t),YVo=r(Nze," \u2014 "),TW=n(Nze,"A",{href:!0});var gUt=s(TW);ZVo=r(gUt,"FNetModel"),gUt.forEach(t),KVo=r(Nze," (FNet model)"),Nze.forEach(t),eXo=i(x),_2=n(x,"LI",{});var qze=s(_2);PFe=n(qze,"STRONG",{});var hUt=s(PFe);oXo=r(hUt,"fsmt"),hUt.forEach(t),rXo=r(qze," \u2014 "),MW=n(qze,"A",{href:!0});var uUt=s(MW);tXo=r(uUt,"FSMTModel"),uUt.forEach(t),aXo=r(qze," (FairSeq Machine-Translation model)"),qze.forEach(t),nXo=i(x),Nl=n(x,"LI",{});var Iq=s(Nl);BFe=n(Iq,"STRONG",{});var pUt=s(BFe);sXo=r(pUt,"funnel"),pUt.forEach(t),lXo=r(Iq," \u2014 "),EW=n(Iq,"A",{href:!0});var _Ut=s(EW);iXo=r(_Ut,"FunnelModel"),_Ut.forEach(t),dXo=r(Iq," or "),CW=n(Iq,"A",{href:!0});var bUt=s(CW);mXo=r(bUt,"FunnelBaseModel"),bUt.forEach(t),cXo=r(Iq," (Funnel Transformer model)"),Iq.forEach(t),fXo=i(x),b2=n(x,"LI",{});var jze=s(b2);IFe=n(jze,"STRONG",{});var vUt=s(IFe);gXo=r(vUt,"glpn"),vUt.forEach(t),hXo=r(jze," \u2014 "),wW=n(jze,"A",{href:!0});var FUt=s(wW);uXo=r(FUt,"GLPNModel"),FUt.forEach(t),pXo=r(jze," (GLPN model)"),jze.forEach(t),_Xo=i(x),v2=n(x,"LI",{});var Dze=s(v2);NFe=n(Dze,"STRONG",{});var TUt=s(NFe);bXo=r(TUt,"gpt2"),TUt.forEach(t),vXo=r(Dze," \u2014 "),AW=n(Dze,"A",{href:!0});var MUt=s(AW);FXo=r(MUt,"GPT2Model"),MUt.forEach(t),TXo=r(Dze," (OpenAI GPT-2 model)"),Dze.forEach(t),MXo=i(x),F2=n(x,"LI",{});var Gze=s(F2);qFe=n(Gze,"STRONG",{});var EUt=s(qFe);EXo=r(EUt,"gpt_neo"),EUt.forEach(t),CXo=r(Gze," \u2014 "),LW=n(Gze,"A",{href:!0});var CUt=s(LW);wXo=r(CUt,"GPTNeoModel"),CUt.forEach(t),AXo=r(Gze," (GPT Neo model)"),Gze.forEach(t),LXo=i(x),T2=n(x,"LI",{});var Oze=s(T2);jFe=n(Oze,"STRONG",{});var wUt=s(jFe);yXo=r(wUt,"gpt_neox"),wUt.forEach(t),xXo=r(Oze," \u2014 "),yW=n(Oze,"A",{href:!0});var AUt=s(yW);$Xo=r(AUt,"GPTNeoXModel"),AUt.forEach(t),kXo=r(Oze," (GPT NeoX model)"),Oze.forEach(t),SXo=i(x),M2=n(x,"LI",{});var Vze=s(M2);DFe=n(Vze,"STRONG",{});var LUt=s(DFe);RXo=r(LUt,"gpt_neox_japanese"),LUt.forEach(t),PXo=r(Vze," \u2014 "),xW=n(Vze,"A",{href:!0});var yUt=s(xW);BXo=r(yUt,"GPTNeoXJapaneseModel"),yUt.forEach(t),IXo=r(Vze," (GPT NeoX Japanese model)"),Vze.forEach(t),NXo=i(x),E2=n(x,"LI",{});var Xze=s(E2);GFe=n(Xze,"STRONG",{});var xUt=s(GFe);qXo=r(xUt,"gptj"),xUt.forEach(t),jXo=r(Xze," \u2014 "),$W=n(Xze,"A",{href:!0});var $Ut=s($W);DXo=r($Ut,"GPTJModel"),$Ut.forEach(t),GXo=r(Xze," (GPT-J model)"),Xze.forEach(t),OXo=i(x),C2=n(x,"LI",{});var zze=s(C2);OFe=n(zze,"STRONG",{});var kUt=s(OFe);VXo=r(kUt,"groupvit"),kUt.forEach(t),XXo=r(zze," \u2014 "),kW=n(zze,"A",{href:!0});var SUt=s(kW);zXo=r(SUt,"GroupViTModel"),SUt.forEach(t),QXo=r(zze," (GroupViT model)"),zze.forEach(t),WXo=i(x),w2=n(x,"LI",{});var Qze=s(w2);VFe=n(Qze,"STRONG",{});var RUt=s(VFe);UXo=r(RUt,"hubert"),RUt.forEach(t),HXo=r(Qze," \u2014 "),SW=n(Qze,"A",{href:!0});var PUt=s(SW);JXo=r(PUt,"HubertModel"),PUt.forEach(t),YXo=r(Qze," (Hubert model)"),Qze.forEach(t),ZXo=i(x),A2=n(x,"LI",{});var Wze=s(A2);XFe=n(Wze,"STRONG",{});var BUt=s(XFe);KXo=r(BUt,"ibert"),BUt.forEach(t),ezo=r(Wze," \u2014 "),RW=n(Wze,"A",{href:!0});var IUt=s(RW);ozo=r(IUt,"IBertModel"),IUt.forEach(t),rzo=r(Wze," (I-BERT model)"),Wze.forEach(t),tzo=i(x),L2=n(x,"LI",{});var Uze=s(L2);zFe=n(Uze,"STRONG",{});var NUt=s(zFe);azo=r(NUt,"imagegpt"),NUt.forEach(t),nzo=r(Uze," \u2014 "),PW=n(Uze,"A",{href:!0});var qUt=s(PW);szo=r(qUt,"ImageGPTModel"),qUt.forEach(t),lzo=r(Uze," (ImageGPT model)"),Uze.forEach(t),izo=i(x),y2=n(x,"LI",{});var Hze=s(y2);QFe=n(Hze,"STRONG",{});var jUt=s(QFe);dzo=r(jUt,"jukebox"),jUt.forEach(t),mzo=r(Hze," \u2014 "),BW=n(Hze,"A",{href:!0});var DUt=s(BW);czo=r(DUt,"JukeboxModel"),DUt.forEach(t),fzo=r(Hze," (Jukebox model)"),Hze.forEach(t),gzo=i(x),x2=n(x,"LI",{});var Jze=s(x2);WFe=n(Jze,"STRONG",{});var GUt=s(WFe);hzo=r(GUt,"layoutlm"),GUt.forEach(t),uzo=r(Jze," \u2014 "),IW=n(Jze,"A",{href:!0});var OUt=s(IW);pzo=r(OUt,"LayoutLMModel"),OUt.forEach(t),_zo=r(Jze," (LayoutLM model)"),Jze.forEach(t),bzo=i(x),$2=n(x,"LI",{});var Yze=s($2);UFe=n(Yze,"STRONG",{});var VUt=s(UFe);vzo=r(VUt,"layoutlmv2"),VUt.forEach(t),Fzo=r(Yze," \u2014 "),NW=n(Yze,"A",{href:!0});var XUt=s(NW);Tzo=r(XUt,"LayoutLMv2Model"),XUt.forEach(t),Mzo=r(Yze," (LayoutLMv2 model)"),Yze.forEach(t),Ezo=i(x),k2=n(x,"LI",{});var Zze=s(k2);HFe=n(Zze,"STRONG",{});var zUt=s(HFe);Czo=r(zUt,"layoutlmv3"),zUt.forEach(t),wzo=r(Zze," \u2014 "),qW=n(Zze,"A",{href:!0});var QUt=s(qW);Azo=r(QUt,"LayoutLMv3Model"),QUt.forEach(t),Lzo=r(Zze," (LayoutLMv3 model)"),Zze.forEach(t),yzo=i(x),S2=n(x,"LI",{});var Kze=s(S2);JFe=n(Kze,"STRONG",{});var WUt=s(JFe);xzo=r(WUt,"led"),WUt.forEach(t),$zo=r(Kze," \u2014 "),jW=n(Kze,"A",{href:!0});var UUt=s(jW);kzo=r(UUt,"LEDModel"),UUt.forEach(t),Szo=r(Kze," (LED model)"),Kze.forEach(t),Rzo=i(x),R2=n(x,"LI",{});var eQe=s(R2);YFe=n(eQe,"STRONG",{});var HUt=s(YFe);Pzo=r(HUt,"levit"),HUt.forEach(t),Bzo=r(eQe," \u2014 "),DW=n(eQe,"A",{href:!0});var JUt=s(DW);Izo=r(JUt,"LevitModel"),JUt.forEach(t),Nzo=r(eQe," (LeViT model)"),eQe.forEach(t),qzo=i(x),P2=n(x,"LI",{});var oQe=s(P2);ZFe=n(oQe,"STRONG",{});var YUt=s(ZFe);jzo=r(YUt,"lilt"),YUt.forEach(t),Dzo=r(oQe," \u2014 "),GW=n(oQe,"A",{href:!0});var ZUt=s(GW);Gzo=r(ZUt,"LiltModel"),ZUt.forEach(t),Ozo=r(oQe," (LiLT model)"),oQe.forEach(t),Vzo=i(x),B2=n(x,"LI",{});var rQe=s(B2);KFe=n(rQe,"STRONG",{});var KUt=s(KFe);Xzo=r(KUt,"longformer"),KUt.forEach(t),zzo=r(rQe," \u2014 "),OW=n(rQe,"A",{href:!0});var eHt=s(OW);Qzo=r(eHt,"LongformerModel"),eHt.forEach(t),Wzo=r(rQe," (Longformer model)"),rQe.forEach(t),Uzo=i(x),I2=n(x,"LI",{});var tQe=s(I2);eTe=n(tQe,"STRONG",{});var oHt=s(eTe);Hzo=r(oHt,"longt5"),oHt.forEach(t),Jzo=r(tQe," \u2014 "),VW=n(tQe,"A",{href:!0});var rHt=s(VW);Yzo=r(rHt,"LongT5Model"),rHt.forEach(t),Zzo=r(tQe," (LongT5 model)"),tQe.forEach(t),Kzo=i(x),N2=n(x,"LI",{});var aQe=s(N2);oTe=n(aQe,"STRONG",{});var tHt=s(oTe);eQo=r(tHt,"luke"),tHt.forEach(t),oQo=r(aQe," \u2014 "),XW=n(aQe,"A",{href:!0});var aHt=s(XW);rQo=r(aHt,"LukeModel"),aHt.forEach(t),tQo=r(aQe," (LUKE model)"),aQe.forEach(t),aQo=i(x),q2=n(x,"LI",{});var nQe=s(q2);rTe=n(nQe,"STRONG",{});var nHt=s(rTe);nQo=r(nHt,"lxmert"),nHt.forEach(t),sQo=r(nQe," \u2014 "),zW=n(nQe,"A",{href:!0});var sHt=s(zW);lQo=r(sHt,"LxmertModel"),sHt.forEach(t),iQo=r(nQe," (LXMERT model)"),nQe.forEach(t),dQo=i(x),j2=n(x,"LI",{});var sQe=s(j2);tTe=n(sQe,"STRONG",{});var lHt=s(tTe);mQo=r(lHt,"m2m_100"),lHt.forEach(t),cQo=r(sQe," \u2014 "),QW=n(sQe,"A",{href:!0});var iHt=s(QW);fQo=r(iHt,"M2M100Model"),iHt.forEach(t),gQo=r(sQe," (M2M100 model)"),sQe.forEach(t),hQo=i(x),D2=n(x,"LI",{});var lQe=s(D2);aTe=n(lQe,"STRONG",{});var dHt=s(aTe);uQo=r(dHt,"marian"),dHt.forEach(t),pQo=r(lQe," \u2014 "),WW=n(lQe,"A",{href:!0});var mHt=s(WW);_Qo=r(mHt,"MarianModel"),mHt.forEach(t),bQo=r(lQe," (Marian model)"),lQe.forEach(t),vQo=i(x),G2=n(x,"LI",{});var iQe=s(G2);nTe=n(iQe,"STRONG",{});var cHt=s(nTe);FQo=r(cHt,"markuplm"),cHt.forEach(t),TQo=r(iQe," \u2014 "),UW=n(iQe,"A",{href:!0});var fHt=s(UW);MQo=r(fHt,"MarkupLMModel"),fHt.forEach(t),EQo=r(iQe," (MarkupLM model)"),iQe.forEach(t),CQo=i(x),O2=n(x,"LI",{});var dQe=s(O2);sTe=n(dQe,"STRONG",{});var gHt=s(sTe);wQo=r(gHt,"maskformer"),gHt.forEach(t),AQo=r(dQe," \u2014 "),HW=n(dQe,"A",{href:!0});var hHt=s(HW);LQo=r(hHt,"MaskFormerModel"),hHt.forEach(t),yQo=r(dQe," (MaskFormer model)"),dQe.forEach(t),xQo=i(x),V2=n(x,"LI",{});var mQe=s(V2);lTe=n(mQe,"STRONG",{});var uHt=s(lTe);$Qo=r(uHt,"mbart"),uHt.forEach(t),kQo=r(mQe," \u2014 "),JW=n(mQe,"A",{href:!0});var pHt=s(JW);SQo=r(pHt,"MBartModel"),pHt.forEach(t),RQo=r(mQe," (mBART model)"),mQe.forEach(t),PQo=i(x),X2=n(x,"LI",{});var cQe=s(X2);iTe=n(cQe,"STRONG",{});var _Ht=s(iTe);BQo=r(_Ht,"mctct"),_Ht.forEach(t),IQo=r(cQe," \u2014 "),YW=n(cQe,"A",{href:!0});var bHt=s(YW);NQo=r(bHt,"MCTCTModel"),bHt.forEach(t),qQo=r(cQe," (M-CTC-T model)"),cQe.forEach(t),jQo=i(x),z2=n(x,"LI",{});var fQe=s(z2);dTe=n(fQe,"STRONG",{});var vHt=s(dTe);DQo=r(vHt,"megatron-bert"),vHt.forEach(t),GQo=r(fQe," \u2014 "),ZW=n(fQe,"A",{href:!0});var FHt=s(ZW);OQo=r(FHt,"MegatronBertModel"),FHt.forEach(t),VQo=r(fQe," (Megatron-BERT model)"),fQe.forEach(t),XQo=i(x),Q2=n(x,"LI",{});var gQe=s(Q2);mTe=n(gQe,"STRONG",{});var THt=s(mTe);zQo=r(THt,"mobilebert"),THt.forEach(t),QQo=r(gQe," \u2014 "),KW=n(gQe,"A",{href:!0});var MHt=s(KW);WQo=r(MHt,"MobileBertModel"),MHt.forEach(t),UQo=r(gQe," (MobileBERT model)"),gQe.forEach(t),HQo=i(x),W2=n(x,"LI",{});var hQe=s(W2);cTe=n(hQe,"STRONG",{});var EHt=s(cTe);JQo=r(EHt,"mobilenet_v2"),EHt.forEach(t),YQo=r(hQe," \u2014 "),eU=n(hQe,"A",{href:!0});var CHt=s(eU);ZQo=r(CHt,"MobileNetV2Model"),CHt.forEach(t),KQo=r(hQe," (MobileNetV2 model)"),hQe.forEach(t),eWo=i(x),U2=n(x,"LI",{});var uQe=s(U2);fTe=n(uQe,"STRONG",{});var wHt=s(fTe);oWo=r(wHt,"mobilevit"),wHt.forEach(t),rWo=r(uQe," \u2014 "),oU=n(uQe,"A",{href:!0});var AHt=s(oU);tWo=r(AHt,"MobileViTModel"),AHt.forEach(t),aWo=r(uQe," (MobileViT model)"),uQe.forEach(t),nWo=i(x),H2=n(x,"LI",{});var pQe=s(H2);gTe=n(pQe,"STRONG",{});var LHt=s(gTe);sWo=r(LHt,"mpnet"),LHt.forEach(t),lWo=r(pQe," \u2014 "),rU=n(pQe,"A",{href:!0});var yHt=s(rU);iWo=r(yHt,"MPNetModel"),yHt.forEach(t),dWo=r(pQe," (MPNet model)"),pQe.forEach(t),mWo=i(x),J2=n(x,"LI",{});var _Qe=s(J2);hTe=n(_Qe,"STRONG",{});var xHt=s(hTe);cWo=r(xHt,"mt5"),xHt.forEach(t),fWo=r(_Qe," \u2014 "),tU=n(_Qe,"A",{href:!0});var $Ht=s(tU);gWo=r($Ht,"MT5Model"),$Ht.forEach(t),hWo=r(_Qe," (MT5 model)"),_Qe.forEach(t),uWo=i(x),Y2=n(x,"LI",{});var bQe=s(Y2);uTe=n(bQe,"STRONG",{});var kHt=s(uTe);pWo=r(kHt,"mvp"),kHt.forEach(t),_Wo=r(bQe," \u2014 "),aU=n(bQe,"A",{href:!0});var SHt=s(aU);bWo=r(SHt,"MvpModel"),SHt.forEach(t),vWo=r(bQe," (MVP model)"),bQe.forEach(t),FWo=i(x),Z2=n(x,"LI",{});var vQe=s(Z2);pTe=n(vQe,"STRONG",{});var RHt=s(pTe);TWo=r(RHt,"nezha"),RHt.forEach(t),MWo=r(vQe," \u2014 "),nU=n(vQe,"A",{href:!0});var PHt=s(nU);EWo=r(PHt,"NezhaModel"),PHt.forEach(t),CWo=r(vQe," (Nezha model)"),vQe.forEach(t),wWo=i(x),K2=n(x,"LI",{});var FQe=s(K2);_Te=n(FQe,"STRONG",{});var BHt=s(_Te);AWo=r(BHt,"nllb"),BHt.forEach(t),LWo=r(FQe," \u2014 "),sU=n(FQe,"A",{href:!0});var IHt=s(sU);yWo=r(IHt,"M2M100Model"),IHt.forEach(t),xWo=r(FQe," (NLLB model)"),FQe.forEach(t),$Wo=i(x),eb=n(x,"LI",{});var TQe=s(eb);bTe=n(TQe,"STRONG",{});var NHt=s(bTe);kWo=r(NHt,"nystromformer"),NHt.forEach(t),SWo=r(TQe," \u2014 "),lU=n(TQe,"A",{href:!0});var qHt=s(lU);RWo=r(qHt,"NystromformerModel"),qHt.forEach(t),PWo=r(TQe," (Nystr\xF6mformer model)"),TQe.forEach(t),BWo=i(x),ob=n(x,"LI",{});var MQe=s(ob);vTe=n(MQe,"STRONG",{});var jHt=s(vTe);IWo=r(jHt,"openai-gpt"),jHt.forEach(t),NWo=r(MQe," \u2014 "),iU=n(MQe,"A",{href:!0});var DHt=s(iU);qWo=r(DHt,"OpenAIGPTModel"),DHt.forEach(t),jWo=r(MQe," (OpenAI GPT model)"),MQe.forEach(t),DWo=i(x),rb=n(x,"LI",{});var EQe=s(rb);FTe=n(EQe,"STRONG",{});var GHt=s(FTe);GWo=r(GHt,"opt"),GHt.forEach(t),OWo=r(EQe," \u2014 "),dU=n(EQe,"A",{href:!0});var OHt=s(dU);VWo=r(OHt,"OPTModel"),OHt.forEach(t),XWo=r(EQe," (OPT model)"),EQe.forEach(t),zWo=i(x),tb=n(x,"LI",{});var CQe=s(tb);TTe=n(CQe,"STRONG",{});var VHt=s(TTe);QWo=r(VHt,"owlvit"),VHt.forEach(t),WWo=r(CQe," \u2014 "),mU=n(CQe,"A",{href:!0});var XHt=s(mU);UWo=r(XHt,"OwlViTModel"),XHt.forEach(t),HWo=r(CQe," (OWL-ViT model)"),CQe.forEach(t),JWo=i(x),ab=n(x,"LI",{});var wQe=s(ab);MTe=n(wQe,"STRONG",{});var zHt=s(MTe);YWo=r(zHt,"pegasus"),zHt.forEach(t),ZWo=r(wQe," \u2014 "),cU=n(wQe,"A",{href:!0});var QHt=s(cU);KWo=r(QHt,"PegasusModel"),QHt.forEach(t),eUo=r(wQe," (Pegasus model)"),wQe.forEach(t),oUo=i(x),nb=n(x,"LI",{});var AQe=s(nb);ETe=n(AQe,"STRONG",{});var WHt=s(ETe);rUo=r(WHt,"pegasus_x"),WHt.forEach(t),tUo=r(AQe," \u2014 "),fU=n(AQe,"A",{href:!0});var UHt=s(fU);aUo=r(UHt,"PegasusXModel"),UHt.forEach(t),nUo=r(AQe," (PEGASUS-X model)"),AQe.forEach(t),sUo=i(x),sb=n(x,"LI",{});var LQe=s(sb);CTe=n(LQe,"STRONG",{});var HHt=s(CTe);lUo=r(HHt,"perceiver"),HHt.forEach(t),iUo=r(LQe," \u2014 "),gU=n(LQe,"A",{href:!0});var JHt=s(gU);dUo=r(JHt,"PerceiverModel"),JHt.forEach(t),mUo=r(LQe," (Perceiver model)"),LQe.forEach(t),cUo=i(x),lb=n(x,"LI",{});var yQe=s(lb);wTe=n(yQe,"STRONG",{});var YHt=s(wTe);fUo=r(YHt,"plbart"),YHt.forEach(t),gUo=r(yQe," \u2014 "),hU=n(yQe,"A",{href:!0});var ZHt=s(hU);hUo=r(ZHt,"PLBartModel"),ZHt.forEach(t),uUo=r(yQe," (PLBart model)"),yQe.forEach(t),pUo=i(x),ib=n(x,"LI",{});var xQe=s(ib);ATe=n(xQe,"STRONG",{});var KHt=s(ATe);_Uo=r(KHt,"poolformer"),KHt.forEach(t),bUo=r(xQe," \u2014 "),uU=n(xQe,"A",{href:!0});var eJt=s(uU);vUo=r(eJt,"PoolFormerModel"),eJt.forEach(t),FUo=r(xQe," (PoolFormer model)"),xQe.forEach(t),TUo=i(x),db=n(x,"LI",{});var $Qe=s(db);LTe=n($Qe,"STRONG",{});var oJt=s(LTe);MUo=r(oJt,"prophetnet"),oJt.forEach(t),EUo=r($Qe," \u2014 "),pU=n($Qe,"A",{href:!0});var rJt=s(pU);CUo=r(rJt,"ProphetNetModel"),rJt.forEach(t),wUo=r($Qe," (ProphetNet model)"),$Qe.forEach(t),AUo=i(x),mb=n(x,"LI",{});var kQe=s(mb);yTe=n(kQe,"STRONG",{});var tJt=s(yTe);LUo=r(tJt,"qdqbert"),tJt.forEach(t),yUo=r(kQe," \u2014 "),_U=n(kQe,"A",{href:!0});var aJt=s(_U);xUo=r(aJt,"QDQBertModel"),aJt.forEach(t),$Uo=r(kQe," (QDQBert model)"),kQe.forEach(t),kUo=i(x),cb=n(x,"LI",{});var SQe=s(cb);xTe=n(SQe,"STRONG",{});var nJt=s(xTe);SUo=r(nJt,"reformer"),nJt.forEach(t),RUo=r(SQe," \u2014 "),bU=n(SQe,"A",{href:!0});var sJt=s(bU);PUo=r(sJt,"ReformerModel"),sJt.forEach(t),BUo=r(SQe," (Reformer model)"),SQe.forEach(t),IUo=i(x),fb=n(x,"LI",{});var RQe=s(fb);$Te=n(RQe,"STRONG",{});var lJt=s($Te);NUo=r(lJt,"regnet"),lJt.forEach(t),qUo=r(RQe," \u2014 "),vU=n(RQe,"A",{href:!0});var iJt=s(vU);jUo=r(iJt,"RegNetModel"),iJt.forEach(t),DUo=r(RQe," (RegNet model)"),RQe.forEach(t),GUo=i(x),gb=n(x,"LI",{});var PQe=s(gb);kTe=n(PQe,"STRONG",{});var dJt=s(kTe);OUo=r(dJt,"rembert"),dJt.forEach(t),VUo=r(PQe," \u2014 "),FU=n(PQe,"A",{href:!0});var mJt=s(FU);XUo=r(mJt,"RemBertModel"),mJt.forEach(t),zUo=r(PQe," (RemBERT model)"),PQe.forEach(t),QUo=i(x),hb=n(x,"LI",{});var BQe=s(hb);STe=n(BQe,"STRONG",{});var cJt=s(STe);WUo=r(cJt,"resnet"),cJt.forEach(t),UUo=r(BQe," \u2014 "),TU=n(BQe,"A",{href:!0});var fJt=s(TU);HUo=r(fJt,"ResNetModel"),fJt.forEach(t),JUo=r(BQe," (ResNet model)"),BQe.forEach(t),YUo=i(x),ub=n(x,"LI",{});var IQe=s(ub);RTe=n(IQe,"STRONG",{});var gJt=s(RTe);ZUo=r(gJt,"retribert"),gJt.forEach(t),KUo=r(IQe," \u2014 "),MU=n(IQe,"A",{href:!0});var hJt=s(MU);eHo=r(hJt,"RetriBertModel"),hJt.forEach(t),oHo=r(IQe," (RetriBERT model)"),IQe.forEach(t),rHo=i(x),pb=n(x,"LI",{});var NQe=s(pb);PTe=n(NQe,"STRONG",{});var uJt=s(PTe);tHo=r(uJt,"roberta"),uJt.forEach(t),aHo=r(NQe," \u2014 "),EU=n(NQe,"A",{href:!0});var pJt=s(EU);nHo=r(pJt,"RobertaModel"),pJt.forEach(t),sHo=r(NQe," (RoBERTa model)"),NQe.forEach(t),lHo=i(x),_b=n(x,"LI",{});var qQe=s(_b);BTe=n(qQe,"STRONG",{});var _Jt=s(BTe);iHo=r(_Jt,"roc_bert"),_Jt.forEach(t),dHo=r(qQe," \u2014 "),CU=n(qQe,"A",{href:!0});var bJt=s(CU);mHo=r(bJt,"RoCBertModel"),bJt.forEach(t),cHo=r(qQe," (RoCBert model)"),qQe.forEach(t),fHo=i(x),bb=n(x,"LI",{});var jQe=s(bb);ITe=n(jQe,"STRONG",{});var vJt=s(ITe);gHo=r(vJt,"roformer"),vJt.forEach(t),hHo=r(jQe," \u2014 "),wU=n(jQe,"A",{href:!0});var FJt=s(wU);uHo=r(FJt,"RoFormerModel"),FJt.forEach(t),pHo=r(jQe," (RoFormer model)"),jQe.forEach(t),_Ho=i(x),vb=n(x,"LI",{});var DQe=s(vb);NTe=n(DQe,"STRONG",{});var TJt=s(NTe);bHo=r(TJt,"segformer"),TJt.forEach(t),vHo=r(DQe," \u2014 "),AU=n(DQe,"A",{href:!0});var MJt=s(AU);FHo=r(MJt,"SegformerModel"),MJt.forEach(t),THo=r(DQe," (SegFormer model)"),DQe.forEach(t),MHo=i(x),Fb=n(x,"LI",{});var GQe=s(Fb);qTe=n(GQe,"STRONG",{});var EJt=s(qTe);EHo=r(EJt,"sew"),EJt.forEach(t),CHo=r(GQe," \u2014 "),LU=n(GQe,"A",{href:!0});var CJt=s(LU);wHo=r(CJt,"SEWModel"),CJt.forEach(t),AHo=r(GQe," (SEW model)"),GQe.forEach(t),LHo=i(x),Tb=n(x,"LI",{});var OQe=s(Tb);jTe=n(OQe,"STRONG",{});var wJt=s(jTe);yHo=r(wJt,"sew-d"),wJt.forEach(t),xHo=r(OQe," \u2014 "),yU=n(OQe,"A",{href:!0});var AJt=s(yU);$Ho=r(AJt,"SEWDModel"),AJt.forEach(t),kHo=r(OQe," (SEW-D model)"),OQe.forEach(t),SHo=i(x),Mb=n(x,"LI",{});var VQe=s(Mb);DTe=n(VQe,"STRONG",{});var LJt=s(DTe);RHo=r(LJt,"speech_to_text"),LJt.forEach(t),PHo=r(VQe," \u2014 "),xU=n(VQe,"A",{href:!0});var yJt=s(xU);BHo=r(yJt,"Speech2TextModel"),yJt.forEach(t),IHo=r(VQe," (Speech2Text model)"),VQe.forEach(t),NHo=i(x),Eb=n(x,"LI",{});var XQe=s(Eb);GTe=n(XQe,"STRONG",{});var xJt=s(GTe);qHo=r(xJt,"splinter"),xJt.forEach(t),jHo=r(XQe," \u2014 "),$U=n(XQe,"A",{href:!0});var $Jt=s($U);DHo=r($Jt,"SplinterModel"),$Jt.forEach(t),GHo=r(XQe," (Splinter model)"),XQe.forEach(t),OHo=i(x),Cb=n(x,"LI",{});var zQe=s(Cb);OTe=n(zQe,"STRONG",{});var kJt=s(OTe);VHo=r(kJt,"squeezebert"),kJt.forEach(t),XHo=r(zQe," \u2014 "),kU=n(zQe,"A",{href:!0});var SJt=s(kU);zHo=r(SJt,"SqueezeBertModel"),SJt.forEach(t),QHo=r(zQe," (SqueezeBERT model)"),zQe.forEach(t),WHo=i(x),wb=n(x,"LI",{});var QQe=s(wb);VTe=n(QQe,"STRONG",{});var RJt=s(VTe);UHo=r(RJt,"swin"),RJt.forEach(t),HHo=r(QQe," \u2014 "),SU=n(QQe,"A",{href:!0});var PJt=s(SU);JHo=r(PJt,"SwinModel"),PJt.forEach(t),YHo=r(QQe," (Swin Transformer model)"),QQe.forEach(t),ZHo=i(x),Ab=n(x,"LI",{});var WQe=s(Ab);XTe=n(WQe,"STRONG",{});var BJt=s(XTe);KHo=r(BJt,"swinv2"),BJt.forEach(t),eJo=r(WQe," \u2014 "),RU=n(WQe,"A",{href:!0});var IJt=s(RU);oJo=r(IJt,"Swinv2Model"),IJt.forEach(t),rJo=r(WQe," (Swin Transformer V2 model)"),WQe.forEach(t),tJo=i(x),Lb=n(x,"LI",{});var UQe=s(Lb);zTe=n(UQe,"STRONG",{});var NJt=s(zTe);aJo=r(NJt,"t5"),NJt.forEach(t),nJo=r(UQe," \u2014 "),PU=n(UQe,"A",{href:!0});var qJt=s(PU);sJo=r(qJt,"T5Model"),qJt.forEach(t),lJo=r(UQe," (T5 model)"),UQe.forEach(t),iJo=i(x),yb=n(x,"LI",{});var HQe=s(yb);QTe=n(HQe,"STRONG",{});var jJt=s(QTe);dJo=r(jJt,"table-transformer"),jJt.forEach(t),mJo=r(HQe," \u2014 "),BU=n(HQe,"A",{href:!0});var DJt=s(BU);cJo=r(DJt,"TableTransformerModel"),DJt.forEach(t),fJo=r(HQe," (Table Transformer model)"),HQe.forEach(t),gJo=i(x),xb=n(x,"LI",{});var JQe=s(xb);WTe=n(JQe,"STRONG",{});var GJt=s(WTe);hJo=r(GJt,"tapas"),GJt.forEach(t),uJo=r(JQe," \u2014 "),IU=n(JQe,"A",{href:!0});var OJt=s(IU);pJo=r(OJt,"TapasModel"),OJt.forEach(t),_Jo=r(JQe," (TAPAS model)"),JQe.forEach(t),bJo=i(x),$b=n(x,"LI",{});var YQe=s($b);UTe=n(YQe,"STRONG",{});var VJt=s(UTe);vJo=r(VJt,"time_series_transformer"),VJt.forEach(t),FJo=r(YQe," \u2014 "),NU=n(YQe,"A",{href:!0});var XJt=s(NU);TJo=r(XJt,"TimeSeriesTransformerModel"),XJt.forEach(t),MJo=r(YQe," (Time Series Transformer model)"),YQe.forEach(t),EJo=i(x),kb=n(x,"LI",{});var ZQe=s(kb);HTe=n(ZQe,"STRONG",{});var zJt=s(HTe);CJo=r(zJt,"trajectory_transformer"),zJt.forEach(t),wJo=r(ZQe," \u2014 "),qU=n(ZQe,"A",{href:!0});var QJt=s(qU);AJo=r(QJt,"TrajectoryTransformerModel"),QJt.forEach(t),LJo=r(ZQe," (Trajectory Transformer model)"),ZQe.forEach(t),yJo=i(x),Sb=n(x,"LI",{});var KQe=s(Sb);JTe=n(KQe,"STRONG",{});var WJt=s(JTe);xJo=r(WJt,"transfo-xl"),WJt.forEach(t),$Jo=r(KQe," \u2014 "),jU=n(KQe,"A",{href:!0});var UJt=s(jU);kJo=r(UJt,"TransfoXLModel"),UJt.forEach(t),SJo=r(KQe," (Transformer-XL model)"),KQe.forEach(t),RJo=i(x),Rb=n(x,"LI",{});var eWe=s(Rb);YTe=n(eWe,"STRONG",{});var HJt=s(YTe);PJo=r(HJt,"unispeech"),HJt.forEach(t),BJo=r(eWe," \u2014 "),DU=n(eWe,"A",{href:!0});var JJt=s(DU);IJo=r(JJt,"UniSpeechModel"),JJt.forEach(t),NJo=r(eWe," (UniSpeech model)"),eWe.forEach(t),qJo=i(x),Pb=n(x,"LI",{});var oWe=s(Pb);ZTe=n(oWe,"STRONG",{});var YJt=s(ZTe);jJo=r(YJt,"unispeech-sat"),YJt.forEach(t),DJo=r(oWe," \u2014 "),GU=n(oWe,"A",{href:!0});var ZJt=s(GU);GJo=r(ZJt,"UniSpeechSatModel"),ZJt.forEach(t),OJo=r(oWe," (UniSpeechSat model)"),oWe.forEach(t),VJo=i(x),Bb=n(x,"LI",{});var rWe=s(Bb);KTe=n(rWe,"STRONG",{});var KJt=s(KTe);XJo=r(KJt,"van"),KJt.forEach(t),zJo=r(rWe," \u2014 "),OU=n(rWe,"A",{href:!0});var eYt=s(OU);QJo=r(eYt,"VanModel"),eYt.forEach(t),WJo=r(rWe," (VAN model)"),rWe.forEach(t),UJo=i(x),Ib=n(x,"LI",{});var tWe=s(Ib);eMe=n(tWe,"STRONG",{});var oYt=s(eMe);HJo=r(oYt,"videomae"),oYt.forEach(t),JJo=r(tWe," \u2014 "),VU=n(tWe,"A",{href:!0});var rYt=s(VU);YJo=r(rYt,"VideoMAEModel"),rYt.forEach(t),ZJo=r(tWe," (VideoMAE model)"),tWe.forEach(t),KJo=i(x),Nb=n(x,"LI",{});var aWe=s(Nb);oMe=n(aWe,"STRONG",{});var tYt=s(oMe);eYo=r(tYt,"vilt"),tYt.forEach(t),oYo=r(aWe," \u2014 "),XU=n(aWe,"A",{href:!0});var aYt=s(XU);rYo=r(aYt,"ViltModel"),aYt.forEach(t),tYo=r(aWe," (ViLT model)"),aWe.forEach(t),aYo=i(x),qb=n(x,"LI",{});var nWe=s(qb);rMe=n(nWe,"STRONG",{});var nYt=s(rMe);nYo=r(nYt,"vision-text-dual-encoder"),nYt.forEach(t),sYo=r(nWe," \u2014 "),zU=n(nWe,"A",{href:!0});var sYt=s(zU);lYo=r(sYt,"VisionTextDualEncoderModel"),sYt.forEach(t),iYo=r(nWe," (VisionTextDualEncoder model)"),nWe.forEach(t),dYo=i(x),jb=n(x,"LI",{});var sWe=s(jb);tMe=n(sWe,"STRONG",{});var lYt=s(tMe);mYo=r(lYt,"visual_bert"),lYt.forEach(t),cYo=r(sWe," \u2014 "),QU=n(sWe,"A",{href:!0});var iYt=s(QU);fYo=r(iYt,"VisualBertModel"),iYt.forEach(t),gYo=r(sWe," (VisualBERT model)"),sWe.forEach(t),hYo=i(x),Db=n(x,"LI",{});var lWe=s(Db);aMe=n(lWe,"STRONG",{});var dYt=s(aMe);uYo=r(dYt,"vit"),dYt.forEach(t),pYo=r(lWe," \u2014 "),WU=n(lWe,"A",{href:!0});var mYt=s(WU);_Yo=r(mYt,"ViTModel"),mYt.forEach(t),bYo=r(lWe," (ViT model)"),lWe.forEach(t),vYo=i(x),Gb=n(x,"LI",{});var iWe=s(Gb);nMe=n(iWe,"STRONG",{});var cYt=s(nMe);FYo=r(cYt,"vit_mae"),cYt.forEach(t),TYo=r(iWe," \u2014 "),UU=n(iWe,"A",{href:!0});var fYt=s(UU);MYo=r(fYt,"ViTMAEModel"),fYt.forEach(t),EYo=r(iWe," (ViTMAE model)"),iWe.forEach(t),CYo=i(x),Ob=n(x,"LI",{});var dWe=s(Ob);sMe=n(dWe,"STRONG",{});var gYt=s(sMe);wYo=r(gYt,"vit_msn"),gYt.forEach(t),AYo=r(dWe," \u2014 "),HU=n(dWe,"A",{href:!0});var hYt=s(HU);LYo=r(hYt,"ViTMSNModel"),hYt.forEach(t),yYo=r(dWe," (ViTMSN model)"),dWe.forEach(t),xYo=i(x),Vb=n(x,"LI",{});var mWe=s(Vb);lMe=n(mWe,"STRONG",{});var uYt=s(lMe);$Yo=r(uYt,"wav2vec2"),uYt.forEach(t),kYo=r(mWe," \u2014 "),JU=n(mWe,"A",{href:!0});var pYt=s(JU);SYo=r(pYt,"Wav2Vec2Model"),pYt.forEach(t),RYo=r(mWe," (Wav2Vec2 model)"),mWe.forEach(t),PYo=i(x),Xb=n(x,"LI",{});var cWe=s(Xb);iMe=n(cWe,"STRONG",{});var _Yt=s(iMe);BYo=r(_Yt,"wav2vec2-conformer"),_Yt.forEach(t),IYo=r(cWe," \u2014 "),YU=n(cWe,"A",{href:!0});var bYt=s(YU);NYo=r(bYt,"Wav2Vec2ConformerModel"),bYt.forEach(t),qYo=r(cWe," (Wav2Vec2-Conformer model)"),cWe.forEach(t),jYo=i(x),zb=n(x,"LI",{});var fWe=s(zb);dMe=n(fWe,"STRONG",{});var vYt=s(dMe);DYo=r(vYt,"wavlm"),vYt.forEach(t),GYo=r(fWe," \u2014 "),ZU=n(fWe,"A",{href:!0});var FYt=s(ZU);OYo=r(FYt,"WavLMModel"),FYt.forEach(t),VYo=r(fWe," (WavLM model)"),fWe.forEach(t),XYo=i(x),Qb=n(x,"LI",{});var gWe=s(Qb);mMe=n(gWe,"STRONG",{});var TYt=s(mMe);zYo=r(TYt,"whisper"),TYt.forEach(t),QYo=r(gWe," \u2014 "),KU=n(gWe,"A",{href:!0});var MYt=s(KU);WYo=r(MYt,"WhisperModel"),MYt.forEach(t),UYo=r(gWe," (Whisper model)"),gWe.forEach(t),HYo=i(x),Wb=n(x,"LI",{});var hWe=s(Wb);cMe=n(hWe,"STRONG",{});var EYt=s(cMe);JYo=r(EYt,"xclip"),EYt.forEach(t),YYo=r(hWe," \u2014 "),eH=n(hWe,"A",{href:!0});var CYt=s(eH);ZYo=r(CYt,"XCLIPModel"),CYt.forEach(t),KYo=r(hWe," (X-CLIP model)"),hWe.forEach(t),eZo=i(x),Ub=n(x,"LI",{});var uWe=s(Ub);fMe=n(uWe,"STRONG",{});var wYt=s(fMe);oZo=r(wYt,"xglm"),wYt.forEach(t),rZo=r(uWe," \u2014 "),oH=n(uWe,"A",{href:!0});var AYt=s(oH);tZo=r(AYt,"XGLMModel"),AYt.forEach(t),aZo=r(uWe," (XGLM model)"),uWe.forEach(t),nZo=i(x),Hb=n(x,"LI",{});var pWe=s(Hb);gMe=n(pWe,"STRONG",{});var LYt=s(gMe);sZo=r(LYt,"xlm"),LYt.forEach(t),lZo=r(pWe," \u2014 "),rH=n(pWe,"A",{href:!0});var yYt=s(rH);iZo=r(yYt,"XLMModel"),yYt.forEach(t),dZo=r(pWe," (XLM model)"),pWe.forEach(t),mZo=i(x),Jb=n(x,"LI",{});var _We=s(Jb);hMe=n(_We,"STRONG",{});var xYt=s(hMe);cZo=r(xYt,"xlm-prophetnet"),xYt.forEach(t),fZo=r(_We," \u2014 "),tH=n(_We,"A",{href:!0});var $Yt=s(tH);gZo=r($Yt,"XLMProphetNetModel"),$Yt.forEach(t),hZo=r(_We," (XLM-ProphetNet model)"),_We.forEach(t),uZo=i(x),Yb=n(x,"LI",{});var bWe=s(Yb);uMe=n(bWe,"STRONG",{});var kYt=s(uMe);pZo=r(kYt,"xlm-roberta"),kYt.forEach(t),_Zo=r(bWe," \u2014 "),aH=n(bWe,"A",{href:!0});var SYt=s(aH);bZo=r(SYt,"XLMRobertaModel"),SYt.forEach(t),vZo=r(bWe," (XLM-RoBERTa model)"),bWe.forEach(t),FZo=i(x),Zb=n(x,"LI",{});var vWe=s(Zb);pMe=n(vWe,"STRONG",{});var RYt=s(pMe);TZo=r(RYt,"xlm-roberta-xl"),RYt.forEach(t),MZo=r(vWe," \u2014 "),nH=n(vWe,"A",{href:!0});var PYt=s(nH);EZo=r(PYt,"XLMRobertaXLModel"),PYt.forEach(t),CZo=r(vWe," (XLM-RoBERTa-XL model)"),vWe.forEach(t),wZo=i(x),Kb=n(x,"LI",{});var FWe=s(Kb);_Me=n(FWe,"STRONG",{});var BYt=s(_Me);AZo=r(BYt,"xlnet"),BYt.forEach(t),LZo=r(FWe," \u2014 "),sH=n(FWe,"A",{href:!0});var IYt=s(sH);yZo=r(IYt,"XLNetModel"),IYt.forEach(t),xZo=r(FWe," (XLNet model)"),FWe.forEach(t),$Zo=i(x),ev=n(x,"LI",{});var TWe=s(ev);bMe=n(TWe,"STRONG",{});var NYt=s(bMe);kZo=r(NYt,"yolos"),NYt.forEach(t),SZo=r(TWe," \u2014 "),lH=n(TWe,"A",{href:!0});var qYt=s(lH);RZo=r(qYt,"YolosModel"),qYt.forEach(t),PZo=r(TWe," (YOLOS model)"),TWe.forEach(t),BZo=i(x),ov=n(x,"LI",{});var MWe=s(ov);vMe=n(MWe,"STRONG",{});var jYt=s(vMe);IZo=r(jYt,"yoso"),jYt.forEach(t),NZo=r(MWe," \u2014 "),iH=n(MWe,"A",{href:!0});var DYt=s(iH);qZo=r(DYt,"YosoModel"),DYt.forEach(t),jZo=r(MWe," (YOSO model)"),MWe.forEach(t),x.forEach(t),DZo=i(Sa),rv=n(Sa,"P",{});var EWe=s(rv);GZo=r(EWe,"The model is set in evaluation mode by default using "),FMe=n(EWe,"CODE",{});var GYt=s(FMe);OZo=r(GYt,"model.eval()"),GYt.forEach(t),VZo=r(EWe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),TMe=n(EWe,"CODE",{});var OYt=s(TMe);XZo=r(OYt,"model.train()"),OYt.forEach(t),EWe.forEach(t),zZo=i(Sa),T(tv.$$.fragment,Sa),Sa.forEach(t),Wl.forEach(t),uio=i(c),Xd=n(c,"H2",{class:!0});var Nmo=s(Xd);av=n(Nmo,"A",{id:!0,class:!0,href:!0});var VYt=s(av);MMe=n(VYt,"SPAN",{});var XYt=s(MMe);T(aS.$$.fragment,XYt),XYt.forEach(t),VYt.forEach(t),QZo=i(Nmo),EMe=n(Nmo,"SPAN",{});var zYt=s(EMe);WZo=r(zYt,"AutoModelForPreTraining"),zYt.forEach(t),Nmo.forEach(t),pio=i(c),Go=n(c,"DIV",{class:!0});var Ul=s(Go);T(nS.$$.fragment,Ul),UZo=i(Ul),zd=n(Ul,"P",{});var Afe=s(zd);HZo=r(Afe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),dH=n(Afe,"A",{href:!0});var QYt=s(dH);JZo=r(QYt,"from_pretrained()"),QYt.forEach(t),YZo=r(Afe," class method or the "),mH=n(Afe,"A",{href:!0});var WYt=s(mH);ZZo=r(WYt,"from_config()"),WYt.forEach(t),KZo=r(Afe,` class
method.`),Afe.forEach(t),eKo=i(Ul),sS=n(Ul,"P",{});var qmo=s(sS);oKo=r(qmo,"This class cannot be instantiated directly using "),CMe=n(qmo,"CODE",{});var UYt=s(CMe);rKo=r(UYt,"__init__()"),UYt.forEach(t),tKo=r(qmo," (throws an error)."),qmo.forEach(t),aKo=i(Ul),Lt=n(Ul,"DIV",{class:!0});var hx=s(Lt);T(lS.$$.fragment,hx),nKo=i(hx),wMe=n(hx,"P",{});var HYt=s(wMe);sKo=r(HYt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),HYt.forEach(t),lKo=i(hx),Qd=n(hx,"P",{});var Lfe=s(Qd);iKo=r(Lfe,`Note:
Loading a model from its configuration file does `),AMe=n(Lfe,"STRONG",{});var JYt=s(AMe);dKo=r(JYt,"not"),JYt.forEach(t),mKo=r(Lfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),cH=n(Lfe,"A",{href:!0});var YYt=s(cH);cKo=r(YYt,"from_pretrained()"),YYt.forEach(t),fKo=r(Lfe," to load the model weights."),Lfe.forEach(t),gKo=i(hx),T(nv.$$.fragment,hx),hx.forEach(t),hKo=i(Ul),ao=n(Ul,"DIV",{class:!0});var Ra=s(ao);T(iS.$$.fragment,Ra),uKo=i(Ra),LMe=n(Ra,"P",{});var ZYt=s(LMe);pKo=r(ZYt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),ZYt.forEach(t),_Ko=i(Ra),hn=n(Ra,"P",{});var ux=s(hn);bKo=r(ux,"The model class to instantiate is selected based on the "),yMe=n(ux,"CODE",{});var KYt=s(yMe);vKo=r(KYt,"model_type"),KYt.forEach(t),FKo=r(ux,` property of the config object (either
passed as an argument or loaded from `),xMe=n(ux,"CODE",{});var eZt=s(xMe);TKo=r(eZt,"pretrained_model_name_or_path"),eZt.forEach(t),MKo=r(ux,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Me=n(ux,"CODE",{});var oZt=s($Me);EKo=r(oZt,"pretrained_model_name_or_path"),oZt.forEach(t),CKo=r(ux,":"),ux.forEach(t),wKo=i(Ra),G=n(Ra,"UL",{});var V=s(G);sv=n(V,"LI",{});var CWe=s(sv);kMe=n(CWe,"STRONG",{});var rZt=s(kMe);AKo=r(rZt,"albert"),rZt.forEach(t),LKo=r(CWe," \u2014 "),fH=n(CWe,"A",{href:!0});var tZt=s(fH);yKo=r(tZt,"AlbertForPreTraining"),tZt.forEach(t),xKo=r(CWe," (ALBERT model)"),CWe.forEach(t),$Ko=i(V),lv=n(V,"LI",{});var wWe=s(lv);SMe=n(wWe,"STRONG",{});var aZt=s(SMe);kKo=r(aZt,"bart"),aZt.forEach(t),SKo=r(wWe," \u2014 "),gH=n(wWe,"A",{href:!0});var nZt=s(gH);RKo=r(nZt,"BartForConditionalGeneration"),nZt.forEach(t),PKo=r(wWe," (BART model)"),wWe.forEach(t),BKo=i(V),iv=n(V,"LI",{});var AWe=s(iv);RMe=n(AWe,"STRONG",{});var sZt=s(RMe);IKo=r(sZt,"bert"),sZt.forEach(t),NKo=r(AWe," \u2014 "),hH=n(AWe,"A",{href:!0});var lZt=s(hH);qKo=r(lZt,"BertForPreTraining"),lZt.forEach(t),jKo=r(AWe," (BERT model)"),AWe.forEach(t),DKo=i(V),dv=n(V,"LI",{});var LWe=s(dv);PMe=n(LWe,"STRONG",{});var iZt=s(PMe);GKo=r(iZt,"big_bird"),iZt.forEach(t),OKo=r(LWe," \u2014 "),uH=n(LWe,"A",{href:!0});var dZt=s(uH);VKo=r(dZt,"BigBirdForPreTraining"),dZt.forEach(t),XKo=r(LWe," (BigBird model)"),LWe.forEach(t),zKo=i(V),mv=n(V,"LI",{});var yWe=s(mv);BMe=n(yWe,"STRONG",{});var mZt=s(BMe);QKo=r(mZt,"bloom"),mZt.forEach(t),WKo=r(yWe," \u2014 "),pH=n(yWe,"A",{href:!0});var cZt=s(pH);UKo=r(cZt,"BloomForCausalLM"),cZt.forEach(t),HKo=r(yWe," (BLOOM model)"),yWe.forEach(t),JKo=i(V),cv=n(V,"LI",{});var xWe=s(cv);IMe=n(xWe,"STRONG",{});var fZt=s(IMe);YKo=r(fZt,"camembert"),fZt.forEach(t),ZKo=r(xWe," \u2014 "),_H=n(xWe,"A",{href:!0});var gZt=s(_H);KKo=r(gZt,"CamembertForMaskedLM"),gZt.forEach(t),eer=r(xWe," (CamemBERT model)"),xWe.forEach(t),oer=i(V),fv=n(V,"LI",{});var $We=s(fv);NMe=n($We,"STRONG",{});var hZt=s(NMe);rer=r(hZt,"ctrl"),hZt.forEach(t),ter=r($We," \u2014 "),bH=n($We,"A",{href:!0});var uZt=s(bH);aer=r(uZt,"CTRLLMHeadModel"),uZt.forEach(t),ner=r($We," (CTRL model)"),$We.forEach(t),ser=i(V),gv=n(V,"LI",{});var kWe=s(gv);qMe=n(kWe,"STRONG",{});var pZt=s(qMe);ler=r(pZt,"data2vec-text"),pZt.forEach(t),ier=r(kWe," \u2014 "),vH=n(kWe,"A",{href:!0});var _Zt=s(vH);der=r(_Zt,"Data2VecTextForMaskedLM"),_Zt.forEach(t),mer=r(kWe," (Data2VecText model)"),kWe.forEach(t),cer=i(V),hv=n(V,"LI",{});var SWe=s(hv);jMe=n(SWe,"STRONG",{});var bZt=s(jMe);fer=r(bZt,"deberta"),bZt.forEach(t),ger=r(SWe," \u2014 "),FH=n(SWe,"A",{href:!0});var vZt=s(FH);her=r(vZt,"DebertaForMaskedLM"),vZt.forEach(t),uer=r(SWe," (DeBERTa model)"),SWe.forEach(t),per=i(V),uv=n(V,"LI",{});var RWe=s(uv);DMe=n(RWe,"STRONG",{});var FZt=s(DMe);_er=r(FZt,"deberta-v2"),FZt.forEach(t),ber=r(RWe," \u2014 "),TH=n(RWe,"A",{href:!0});var TZt=s(TH);ver=r(TZt,"DebertaV2ForMaskedLM"),TZt.forEach(t),Fer=r(RWe," (DeBERTa-v2 model)"),RWe.forEach(t),Ter=i(V),pv=n(V,"LI",{});var PWe=s(pv);GMe=n(PWe,"STRONG",{});var MZt=s(GMe);Mer=r(MZt,"distilbert"),MZt.forEach(t),Eer=r(PWe," \u2014 "),MH=n(PWe,"A",{href:!0});var EZt=s(MH);Cer=r(EZt,"DistilBertForMaskedLM"),EZt.forEach(t),wer=r(PWe," (DistilBERT model)"),PWe.forEach(t),Aer=i(V),_v=n(V,"LI",{});var BWe=s(_v);OMe=n(BWe,"STRONG",{});var CZt=s(OMe);Ler=r(CZt,"electra"),CZt.forEach(t),yer=r(BWe," \u2014 "),EH=n(BWe,"A",{href:!0});var wZt=s(EH);xer=r(wZt,"ElectraForPreTraining"),wZt.forEach(t),$er=r(BWe," (ELECTRA model)"),BWe.forEach(t),ker=i(V),bv=n(V,"LI",{});var IWe=s(bv);VMe=n(IWe,"STRONG",{});var AZt=s(VMe);Ser=r(AZt,"ernie"),AZt.forEach(t),Rer=r(IWe," \u2014 "),CH=n(IWe,"A",{href:!0});var LZt=s(CH);Per=r(LZt,"ErnieForPreTraining"),LZt.forEach(t),Ber=r(IWe," (ERNIE model)"),IWe.forEach(t),Ier=i(V),vv=n(V,"LI",{});var NWe=s(vv);XMe=n(NWe,"STRONG",{});var yZt=s(XMe);Ner=r(yZt,"flaubert"),yZt.forEach(t),qer=r(NWe," \u2014 "),wH=n(NWe,"A",{href:!0});var xZt=s(wH);jer=r(xZt,"FlaubertWithLMHeadModel"),xZt.forEach(t),Der=r(NWe," (FlauBERT model)"),NWe.forEach(t),Ger=i(V),Fv=n(V,"LI",{});var qWe=s(Fv);zMe=n(qWe,"STRONG",{});var $Zt=s(zMe);Oer=r($Zt,"flava"),$Zt.forEach(t),Ver=r(qWe," \u2014 "),AH=n(qWe,"A",{href:!0});var kZt=s(AH);Xer=r(kZt,"FlavaForPreTraining"),kZt.forEach(t),zer=r(qWe," (FLAVA model)"),qWe.forEach(t),Qer=i(V),Tv=n(V,"LI",{});var jWe=s(Tv);QMe=n(jWe,"STRONG",{});var SZt=s(QMe);Wer=r(SZt,"fnet"),SZt.forEach(t),Uer=r(jWe," \u2014 "),LH=n(jWe,"A",{href:!0});var RZt=s(LH);Her=r(RZt,"FNetForPreTraining"),RZt.forEach(t),Jer=r(jWe," (FNet model)"),jWe.forEach(t),Yer=i(V),Mv=n(V,"LI",{});var DWe=s(Mv);WMe=n(DWe,"STRONG",{});var PZt=s(WMe);Zer=r(PZt,"fsmt"),PZt.forEach(t),Ker=r(DWe," \u2014 "),yH=n(DWe,"A",{href:!0});var BZt=s(yH);eor=r(BZt,"FSMTForConditionalGeneration"),BZt.forEach(t),oor=r(DWe," (FairSeq Machine-Translation model)"),DWe.forEach(t),ror=i(V),Ev=n(V,"LI",{});var GWe=s(Ev);UMe=n(GWe,"STRONG",{});var IZt=s(UMe);tor=r(IZt,"funnel"),IZt.forEach(t),aor=r(GWe," \u2014 "),xH=n(GWe,"A",{href:!0});var NZt=s(xH);nor=r(NZt,"FunnelForPreTraining"),NZt.forEach(t),sor=r(GWe," (Funnel Transformer model)"),GWe.forEach(t),lor=i(V),Cv=n(V,"LI",{});var OWe=s(Cv);HMe=n(OWe,"STRONG",{});var qZt=s(HMe);ior=r(qZt,"gpt2"),qZt.forEach(t),dor=r(OWe," \u2014 "),$H=n(OWe,"A",{href:!0});var jZt=s($H);mor=r(jZt,"GPT2LMHeadModel"),jZt.forEach(t),cor=r(OWe," (OpenAI GPT-2 model)"),OWe.forEach(t),gor=i(V),wv=n(V,"LI",{});var VWe=s(wv);JMe=n(VWe,"STRONG",{});var DZt=s(JMe);hor=r(DZt,"ibert"),DZt.forEach(t),uor=r(VWe," \u2014 "),kH=n(VWe,"A",{href:!0});var GZt=s(kH);por=r(GZt,"IBertForMaskedLM"),GZt.forEach(t),_or=r(VWe," (I-BERT model)"),VWe.forEach(t),bor=i(V),Av=n(V,"LI",{});var XWe=s(Av);YMe=n(XWe,"STRONG",{});var OZt=s(YMe);vor=r(OZt,"layoutlm"),OZt.forEach(t),For=r(XWe," \u2014 "),SH=n(XWe,"A",{href:!0});var VZt=s(SH);Tor=r(VZt,"LayoutLMForMaskedLM"),VZt.forEach(t),Mor=r(XWe," (LayoutLM model)"),XWe.forEach(t),Eor=i(V),Lv=n(V,"LI",{});var zWe=s(Lv);ZMe=n(zWe,"STRONG",{});var XZt=s(ZMe);Cor=r(XZt,"longformer"),XZt.forEach(t),wor=r(zWe," \u2014 "),RH=n(zWe,"A",{href:!0});var zZt=s(RH);Aor=r(zZt,"LongformerForMaskedLM"),zZt.forEach(t),Lor=r(zWe," (Longformer model)"),zWe.forEach(t),yor=i(V),yv=n(V,"LI",{});var QWe=s(yv);KMe=n(QWe,"STRONG",{});var QZt=s(KMe);xor=r(QZt,"luke"),QZt.forEach(t),$or=r(QWe," \u2014 "),PH=n(QWe,"A",{href:!0});var WZt=s(PH);kor=r(WZt,"LukeForMaskedLM"),WZt.forEach(t),Sor=r(QWe," (LUKE model)"),QWe.forEach(t),Ror=i(V),xv=n(V,"LI",{});var WWe=s(xv);eEe=n(WWe,"STRONG",{});var UZt=s(eEe);Por=r(UZt,"lxmert"),UZt.forEach(t),Bor=r(WWe," \u2014 "),BH=n(WWe,"A",{href:!0});var HZt=s(BH);Ior=r(HZt,"LxmertForPreTraining"),HZt.forEach(t),Nor=r(WWe," (LXMERT model)"),WWe.forEach(t),qor=i(V),$v=n(V,"LI",{});var UWe=s($v);oEe=n(UWe,"STRONG",{});var JZt=s(oEe);jor=r(JZt,"megatron-bert"),JZt.forEach(t),Dor=r(UWe," \u2014 "),IH=n(UWe,"A",{href:!0});var YZt=s(IH);Gor=r(YZt,"MegatronBertForPreTraining"),YZt.forEach(t),Oor=r(UWe," (Megatron-BERT model)"),UWe.forEach(t),Vor=i(V),kv=n(V,"LI",{});var HWe=s(kv);rEe=n(HWe,"STRONG",{});var ZZt=s(rEe);Xor=r(ZZt,"mobilebert"),ZZt.forEach(t),zor=r(HWe," \u2014 "),NH=n(HWe,"A",{href:!0});var KZt=s(NH);Qor=r(KZt,"MobileBertForPreTraining"),KZt.forEach(t),Wor=r(HWe," (MobileBERT model)"),HWe.forEach(t),Uor=i(V),Sv=n(V,"LI",{});var JWe=s(Sv);tEe=n(JWe,"STRONG",{});var eKt=s(tEe);Hor=r(eKt,"mpnet"),eKt.forEach(t),Jor=r(JWe," \u2014 "),qH=n(JWe,"A",{href:!0});var oKt=s(qH);Yor=r(oKt,"MPNetForMaskedLM"),oKt.forEach(t),Zor=r(JWe," (MPNet model)"),JWe.forEach(t),Kor=i(V),Rv=n(V,"LI",{});var YWe=s(Rv);aEe=n(YWe,"STRONG",{});var rKt=s(aEe);err=r(rKt,"mvp"),rKt.forEach(t),orr=r(YWe," \u2014 "),jH=n(YWe,"A",{href:!0});var tKt=s(jH);rrr=r(tKt,"MvpForConditionalGeneration"),tKt.forEach(t),trr=r(YWe," (MVP model)"),YWe.forEach(t),arr=i(V),Pv=n(V,"LI",{});var ZWe=s(Pv);nEe=n(ZWe,"STRONG",{});var aKt=s(nEe);nrr=r(aKt,"nezha"),aKt.forEach(t),srr=r(ZWe," \u2014 "),DH=n(ZWe,"A",{href:!0});var nKt=s(DH);lrr=r(nKt,"NezhaForPreTraining"),nKt.forEach(t),irr=r(ZWe," (Nezha model)"),ZWe.forEach(t),drr=i(V),Bv=n(V,"LI",{});var KWe=s(Bv);sEe=n(KWe,"STRONG",{});var sKt=s(sEe);mrr=r(sKt,"openai-gpt"),sKt.forEach(t),crr=r(KWe," \u2014 "),GH=n(KWe,"A",{href:!0});var lKt=s(GH);frr=r(lKt,"OpenAIGPTLMHeadModel"),lKt.forEach(t),grr=r(KWe," (OpenAI GPT model)"),KWe.forEach(t),hrr=i(V),Iv=n(V,"LI",{});var eUe=s(Iv);lEe=n(eUe,"STRONG",{});var iKt=s(lEe);urr=r(iKt,"retribert"),iKt.forEach(t),prr=r(eUe," \u2014 "),OH=n(eUe,"A",{href:!0});var dKt=s(OH);_rr=r(dKt,"RetriBertModel"),dKt.forEach(t),brr=r(eUe," (RetriBERT model)"),eUe.forEach(t),vrr=i(V),Nv=n(V,"LI",{});var oUe=s(Nv);iEe=n(oUe,"STRONG",{});var mKt=s(iEe);Frr=r(mKt,"roberta"),mKt.forEach(t),Trr=r(oUe," \u2014 "),VH=n(oUe,"A",{href:!0});var cKt=s(VH);Mrr=r(cKt,"RobertaForMaskedLM"),cKt.forEach(t),Err=r(oUe," (RoBERTa model)"),oUe.forEach(t),Crr=i(V),qv=n(V,"LI",{});var rUe=s(qv);dEe=n(rUe,"STRONG",{});var fKt=s(dEe);wrr=r(fKt,"roc_bert"),fKt.forEach(t),Arr=r(rUe," \u2014 "),XH=n(rUe,"A",{href:!0});var gKt=s(XH);Lrr=r(gKt,"RoCBertForPreTraining"),gKt.forEach(t),yrr=r(rUe," (RoCBert model)"),rUe.forEach(t),xrr=i(V),jv=n(V,"LI",{});var tUe=s(jv);mEe=n(tUe,"STRONG",{});var hKt=s(mEe);$rr=r(hKt,"splinter"),hKt.forEach(t),krr=r(tUe," \u2014 "),zH=n(tUe,"A",{href:!0});var uKt=s(zH);Srr=r(uKt,"SplinterForPreTraining"),uKt.forEach(t),Rrr=r(tUe," (Splinter model)"),tUe.forEach(t),Prr=i(V),Dv=n(V,"LI",{});var aUe=s(Dv);cEe=n(aUe,"STRONG",{});var pKt=s(cEe);Brr=r(pKt,"squeezebert"),pKt.forEach(t),Irr=r(aUe," \u2014 "),QH=n(aUe,"A",{href:!0});var _Kt=s(QH);Nrr=r(_Kt,"SqueezeBertForMaskedLM"),_Kt.forEach(t),qrr=r(aUe," (SqueezeBERT model)"),aUe.forEach(t),jrr=i(V),Gv=n(V,"LI",{});var nUe=s(Gv);fEe=n(nUe,"STRONG",{});var bKt=s(fEe);Drr=r(bKt,"t5"),bKt.forEach(t),Grr=r(nUe," \u2014 "),WH=n(nUe,"A",{href:!0});var vKt=s(WH);Orr=r(vKt,"T5ForConditionalGeneration"),vKt.forEach(t),Vrr=r(nUe," (T5 model)"),nUe.forEach(t),Xrr=i(V),Ov=n(V,"LI",{});var sUe=s(Ov);gEe=n(sUe,"STRONG",{});var FKt=s(gEe);zrr=r(FKt,"tapas"),FKt.forEach(t),Qrr=r(sUe," \u2014 "),UH=n(sUe,"A",{href:!0});var TKt=s(UH);Wrr=r(TKt,"TapasForMaskedLM"),TKt.forEach(t),Urr=r(sUe," (TAPAS model)"),sUe.forEach(t),Hrr=i(V),Vv=n(V,"LI",{});var lUe=s(Vv);hEe=n(lUe,"STRONG",{});var MKt=s(hEe);Jrr=r(MKt,"transfo-xl"),MKt.forEach(t),Yrr=r(lUe," \u2014 "),HH=n(lUe,"A",{href:!0});var EKt=s(HH);Zrr=r(EKt,"TransfoXLLMHeadModel"),EKt.forEach(t),Krr=r(lUe," (Transformer-XL model)"),lUe.forEach(t),etr=i(V),Xv=n(V,"LI",{});var iUe=s(Xv);uEe=n(iUe,"STRONG",{});var CKt=s(uEe);otr=r(CKt,"unispeech"),CKt.forEach(t),rtr=r(iUe," \u2014 "),JH=n(iUe,"A",{href:!0});var wKt=s(JH);ttr=r(wKt,"UniSpeechForPreTraining"),wKt.forEach(t),atr=r(iUe," (UniSpeech model)"),iUe.forEach(t),ntr=i(V),zv=n(V,"LI",{});var dUe=s(zv);pEe=n(dUe,"STRONG",{});var AKt=s(pEe);str=r(AKt,"unispeech-sat"),AKt.forEach(t),ltr=r(dUe," \u2014 "),YH=n(dUe,"A",{href:!0});var LKt=s(YH);itr=r(LKt,"UniSpeechSatForPreTraining"),LKt.forEach(t),dtr=r(dUe," (UniSpeechSat model)"),dUe.forEach(t),mtr=i(V),Qv=n(V,"LI",{});var mUe=s(Qv);_Ee=n(mUe,"STRONG",{});var yKt=s(_Ee);ctr=r(yKt,"videomae"),yKt.forEach(t),ftr=r(mUe," \u2014 "),ZH=n(mUe,"A",{href:!0});var xKt=s(ZH);gtr=r(xKt,"VideoMAEForPreTraining"),xKt.forEach(t),htr=r(mUe," (VideoMAE model)"),mUe.forEach(t),utr=i(V),Wv=n(V,"LI",{});var cUe=s(Wv);bEe=n(cUe,"STRONG",{});var $Kt=s(bEe);ptr=r($Kt,"visual_bert"),$Kt.forEach(t),_tr=r(cUe," \u2014 "),KH=n(cUe,"A",{href:!0});var kKt=s(KH);btr=r(kKt,"VisualBertForPreTraining"),kKt.forEach(t),vtr=r(cUe," (VisualBERT model)"),cUe.forEach(t),Ftr=i(V),Uv=n(V,"LI",{});var fUe=s(Uv);vEe=n(fUe,"STRONG",{});var SKt=s(vEe);Ttr=r(SKt,"vit_mae"),SKt.forEach(t),Mtr=r(fUe," \u2014 "),eJ=n(fUe,"A",{href:!0});var RKt=s(eJ);Etr=r(RKt,"ViTMAEForPreTraining"),RKt.forEach(t),Ctr=r(fUe," (ViTMAE model)"),fUe.forEach(t),wtr=i(V),Hv=n(V,"LI",{});var gUe=s(Hv);FEe=n(gUe,"STRONG",{});var PKt=s(FEe);Atr=r(PKt,"wav2vec2"),PKt.forEach(t),Ltr=r(gUe," \u2014 "),oJ=n(gUe,"A",{href:!0});var BKt=s(oJ);ytr=r(BKt,"Wav2Vec2ForPreTraining"),BKt.forEach(t),xtr=r(gUe," (Wav2Vec2 model)"),gUe.forEach(t),$tr=i(V),Jv=n(V,"LI",{});var hUe=s(Jv);TEe=n(hUe,"STRONG",{});var IKt=s(TEe);ktr=r(IKt,"wav2vec2-conformer"),IKt.forEach(t),Str=r(hUe," \u2014 "),rJ=n(hUe,"A",{href:!0});var NKt=s(rJ);Rtr=r(NKt,"Wav2Vec2ConformerForPreTraining"),NKt.forEach(t),Ptr=r(hUe," (Wav2Vec2-Conformer model)"),hUe.forEach(t),Btr=i(V),Yv=n(V,"LI",{});var uUe=s(Yv);MEe=n(uUe,"STRONG",{});var qKt=s(MEe);Itr=r(qKt,"xlm"),qKt.forEach(t),Ntr=r(uUe," \u2014 "),tJ=n(uUe,"A",{href:!0});var jKt=s(tJ);qtr=r(jKt,"XLMWithLMHeadModel"),jKt.forEach(t),jtr=r(uUe," (XLM model)"),uUe.forEach(t),Dtr=i(V),Zv=n(V,"LI",{});var pUe=s(Zv);EEe=n(pUe,"STRONG",{});var DKt=s(EEe);Gtr=r(DKt,"xlm-roberta"),DKt.forEach(t),Otr=r(pUe," \u2014 "),aJ=n(pUe,"A",{href:!0});var GKt=s(aJ);Vtr=r(GKt,"XLMRobertaForMaskedLM"),GKt.forEach(t),Xtr=r(pUe," (XLM-RoBERTa model)"),pUe.forEach(t),ztr=i(V),Kv=n(V,"LI",{});var _Ue=s(Kv);CEe=n(_Ue,"STRONG",{});var OKt=s(CEe);Qtr=r(OKt,"xlm-roberta-xl"),OKt.forEach(t),Wtr=r(_Ue," \u2014 "),nJ=n(_Ue,"A",{href:!0});var VKt=s(nJ);Utr=r(VKt,"XLMRobertaXLForMaskedLM"),VKt.forEach(t),Htr=r(_Ue," (XLM-RoBERTa-XL model)"),_Ue.forEach(t),Jtr=i(V),eF=n(V,"LI",{});var bUe=s(eF);wEe=n(bUe,"STRONG",{});var XKt=s(wEe);Ytr=r(XKt,"xlnet"),XKt.forEach(t),Ztr=r(bUe," \u2014 "),sJ=n(bUe,"A",{href:!0});var zKt=s(sJ);Ktr=r(zKt,"XLNetLMHeadModel"),zKt.forEach(t),ear=r(bUe," (XLNet model)"),bUe.forEach(t),V.forEach(t),oar=i(Ra),oF=n(Ra,"P",{});var vUe=s(oF);rar=r(vUe,"The model is set in evaluation mode by default using "),AEe=n(vUe,"CODE",{});var QKt=s(AEe);tar=r(QKt,"model.eval()"),QKt.forEach(t),aar=r(vUe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),LEe=n(vUe,"CODE",{});var WKt=s(LEe);nar=r(WKt,"model.train()"),WKt.forEach(t),vUe.forEach(t),sar=i(Ra),T(rF.$$.fragment,Ra),Ra.forEach(t),Ul.forEach(t),_io=i(c),Wd=n(c,"H2",{class:!0});var jmo=s(Wd);tF=n(jmo,"A",{id:!0,class:!0,href:!0});var UKt=s(tF);yEe=n(UKt,"SPAN",{});var HKt=s(yEe);T(dS.$$.fragment,HKt),HKt.forEach(t),UKt.forEach(t),lar=i(jmo),xEe=n(jmo,"SPAN",{});var JKt=s(xEe);iar=r(JKt,"AutoModelForCausalLM"),JKt.forEach(t),jmo.forEach(t),bio=i(c),Oo=n(c,"DIV",{class:!0});var Hl=s(Oo);T(mS.$$.fragment,Hl),dar=i(Hl),Ud=n(Hl,"P",{});var yfe=s(Ud);mar=r(yfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),lJ=n(yfe,"A",{href:!0});var YKt=s(lJ);car=r(YKt,"from_pretrained()"),YKt.forEach(t),far=r(yfe," class method or the "),iJ=n(yfe,"A",{href:!0});var ZKt=s(iJ);gar=r(ZKt,"from_config()"),ZKt.forEach(t),har=r(yfe,` class
method.`),yfe.forEach(t),uar=i(Hl),cS=n(Hl,"P",{});var Dmo=s(cS);par=r(Dmo,"This class cannot be instantiated directly using "),$Ee=n(Dmo,"CODE",{});var KKt=s($Ee);_ar=r(KKt,"__init__()"),KKt.forEach(t),bar=r(Dmo," (throws an error)."),Dmo.forEach(t),Far=i(Hl),yt=n(Hl,"DIV",{class:!0});var px=s(yt);T(fS.$$.fragment,px),Tar=i(px),kEe=n(px,"P",{});var eea=s(kEe);Mar=r(eea,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),eea.forEach(t),Ear=i(px),Hd=n(px,"P",{});var xfe=s(Hd);Car=r(xfe,`Note:
Loading a model from its configuration file does `),SEe=n(xfe,"STRONG",{});var oea=s(SEe);war=r(oea,"not"),oea.forEach(t),Aar=r(xfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),dJ=n(xfe,"A",{href:!0});var rea=s(dJ);Lar=r(rea,"from_pretrained()"),rea.forEach(t),yar=r(xfe," to load the model weights."),xfe.forEach(t),xar=i(px),T(aF.$$.fragment,px),px.forEach(t),$ar=i(Hl),no=n(Hl,"DIV",{class:!0});var Pa=s(no);T(gS.$$.fragment,Pa),kar=i(Pa),REe=n(Pa,"P",{});var tea=s(REe);Sar=r(tea,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),tea.forEach(t),Rar=i(Pa),un=n(Pa,"P",{});var _x=s(un);Par=r(_x,"The model class to instantiate is selected based on the "),PEe=n(_x,"CODE",{});var aea=s(PEe);Bar=r(aea,"model_type"),aea.forEach(t),Iar=r(_x,` property of the config object (either
passed as an argument or loaded from `),BEe=n(_x,"CODE",{});var nea=s(BEe);Nar=r(nea,"pretrained_model_name_or_path"),nea.forEach(t),qar=r(_x,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IEe=n(_x,"CODE",{});var sea=s(IEe);jar=r(sea,"pretrained_model_name_or_path"),sea.forEach(t),Dar=r(_x,":"),_x.forEach(t),Gar=i(Pa),W=n(Pa,"UL",{});var H=s(W);nF=n(H,"LI",{});var FUe=s(nF);NEe=n(FUe,"STRONG",{});var lea=s(NEe);Oar=r(lea,"bart"),lea.forEach(t),Var=r(FUe," \u2014 "),mJ=n(FUe,"A",{href:!0});var iea=s(mJ);Xar=r(iea,"BartForCausalLM"),iea.forEach(t),zar=r(FUe," (BART model)"),FUe.forEach(t),Qar=i(H),sF=n(H,"LI",{});var TUe=s(sF);qEe=n(TUe,"STRONG",{});var dea=s(qEe);War=r(dea,"bert"),dea.forEach(t),Uar=r(TUe," \u2014 "),cJ=n(TUe,"A",{href:!0});var mea=s(cJ);Har=r(mea,"BertLMHeadModel"),mea.forEach(t),Jar=r(TUe," (BERT model)"),TUe.forEach(t),Yar=i(H),lF=n(H,"LI",{});var MUe=s(lF);jEe=n(MUe,"STRONG",{});var cea=s(jEe);Zar=r(cea,"bert-generation"),cea.forEach(t),Kar=r(MUe," \u2014 "),fJ=n(MUe,"A",{href:!0});var fea=s(fJ);enr=r(fea,"BertGenerationDecoder"),fea.forEach(t),onr=r(MUe," (Bert Generation model)"),MUe.forEach(t),rnr=i(H),iF=n(H,"LI",{});var EUe=s(iF);DEe=n(EUe,"STRONG",{});var gea=s(DEe);tnr=r(gea,"big_bird"),gea.forEach(t),anr=r(EUe," \u2014 "),gJ=n(EUe,"A",{href:!0});var hea=s(gJ);nnr=r(hea,"BigBirdForCausalLM"),hea.forEach(t),snr=r(EUe," (BigBird model)"),EUe.forEach(t),lnr=i(H),dF=n(H,"LI",{});var CUe=s(dF);GEe=n(CUe,"STRONG",{});var uea=s(GEe);inr=r(uea,"bigbird_pegasus"),uea.forEach(t),dnr=r(CUe," \u2014 "),hJ=n(CUe,"A",{href:!0});var pea=s(hJ);mnr=r(pea,"BigBirdPegasusForCausalLM"),pea.forEach(t),cnr=r(CUe," (BigBird-Pegasus model)"),CUe.forEach(t),fnr=i(H),mF=n(H,"LI",{});var wUe=s(mF);OEe=n(wUe,"STRONG",{});var _ea=s(OEe);gnr=r(_ea,"blenderbot"),_ea.forEach(t),hnr=r(wUe," \u2014 "),uJ=n(wUe,"A",{href:!0});var bea=s(uJ);unr=r(bea,"BlenderbotForCausalLM"),bea.forEach(t),pnr=r(wUe," (Blenderbot model)"),wUe.forEach(t),_nr=i(H),cF=n(H,"LI",{});var AUe=s(cF);VEe=n(AUe,"STRONG",{});var vea=s(VEe);bnr=r(vea,"blenderbot-small"),vea.forEach(t),vnr=r(AUe," \u2014 "),pJ=n(AUe,"A",{href:!0});var Fea=s(pJ);Fnr=r(Fea,"BlenderbotSmallForCausalLM"),Fea.forEach(t),Tnr=r(AUe," (BlenderbotSmall model)"),AUe.forEach(t),Mnr=i(H),fF=n(H,"LI",{});var LUe=s(fF);XEe=n(LUe,"STRONG",{});var Tea=s(XEe);Enr=r(Tea,"bloom"),Tea.forEach(t),Cnr=r(LUe," \u2014 "),_J=n(LUe,"A",{href:!0});var Mea=s(_J);wnr=r(Mea,"BloomForCausalLM"),Mea.forEach(t),Anr=r(LUe," (BLOOM model)"),LUe.forEach(t),Lnr=i(H),gF=n(H,"LI",{});var yUe=s(gF);zEe=n(yUe,"STRONG",{});var Eea=s(zEe);ynr=r(Eea,"camembert"),Eea.forEach(t),xnr=r(yUe," \u2014 "),bJ=n(yUe,"A",{href:!0});var Cea=s(bJ);$nr=r(Cea,"CamembertForCausalLM"),Cea.forEach(t),knr=r(yUe," (CamemBERT model)"),yUe.forEach(t),Snr=i(H),hF=n(H,"LI",{});var xUe=s(hF);QEe=n(xUe,"STRONG",{});var wea=s(QEe);Rnr=r(wea,"codegen"),wea.forEach(t),Pnr=r(xUe," \u2014 "),vJ=n(xUe,"A",{href:!0});var Aea=s(vJ);Bnr=r(Aea,"CodeGenForCausalLM"),Aea.forEach(t),Inr=r(xUe," (CodeGen model)"),xUe.forEach(t),Nnr=i(H),uF=n(H,"LI",{});var $Ue=s(uF);WEe=n($Ue,"STRONG",{});var Lea=s(WEe);qnr=r(Lea,"ctrl"),Lea.forEach(t),jnr=r($Ue," \u2014 "),FJ=n($Ue,"A",{href:!0});var yea=s(FJ);Dnr=r(yea,"CTRLLMHeadModel"),yea.forEach(t),Gnr=r($Ue," (CTRL model)"),$Ue.forEach(t),Onr=i(H),pF=n(H,"LI",{});var kUe=s(pF);UEe=n(kUe,"STRONG",{});var xea=s(UEe);Vnr=r(xea,"data2vec-text"),xea.forEach(t),Xnr=r(kUe," \u2014 "),TJ=n(kUe,"A",{href:!0});var $ea=s(TJ);znr=r($ea,"Data2VecTextForCausalLM"),$ea.forEach(t),Qnr=r(kUe," (Data2VecText model)"),kUe.forEach(t),Wnr=i(H),_F=n(H,"LI",{});var SUe=s(_F);HEe=n(SUe,"STRONG",{});var kea=s(HEe);Unr=r(kea,"electra"),kea.forEach(t),Hnr=r(SUe," \u2014 "),MJ=n(SUe,"A",{href:!0});var Sea=s(MJ);Jnr=r(Sea,"ElectraForCausalLM"),Sea.forEach(t),Ynr=r(SUe," (ELECTRA model)"),SUe.forEach(t),Znr=i(H),bF=n(H,"LI",{});var RUe=s(bF);JEe=n(RUe,"STRONG",{});var Rea=s(JEe);Knr=r(Rea,"ernie"),Rea.forEach(t),esr=r(RUe," \u2014 "),EJ=n(RUe,"A",{href:!0});var Pea=s(EJ);osr=r(Pea,"ErnieForCausalLM"),Pea.forEach(t),rsr=r(RUe," (ERNIE model)"),RUe.forEach(t),tsr=i(H),vF=n(H,"LI",{});var PUe=s(vF);YEe=n(PUe,"STRONG",{});var Bea=s(YEe);asr=r(Bea,"gpt2"),Bea.forEach(t),nsr=r(PUe," \u2014 "),CJ=n(PUe,"A",{href:!0});var Iea=s(CJ);ssr=r(Iea,"GPT2LMHeadModel"),Iea.forEach(t),lsr=r(PUe," (OpenAI GPT-2 model)"),PUe.forEach(t),isr=i(H),FF=n(H,"LI",{});var BUe=s(FF);ZEe=n(BUe,"STRONG",{});var Nea=s(ZEe);dsr=r(Nea,"gpt_neo"),Nea.forEach(t),msr=r(BUe," \u2014 "),wJ=n(BUe,"A",{href:!0});var qea=s(wJ);csr=r(qea,"GPTNeoForCausalLM"),qea.forEach(t),fsr=r(BUe," (GPT Neo model)"),BUe.forEach(t),gsr=i(H),TF=n(H,"LI",{});var IUe=s(TF);KEe=n(IUe,"STRONG",{});var jea=s(KEe);hsr=r(jea,"gpt_neox"),jea.forEach(t),usr=r(IUe," \u2014 "),AJ=n(IUe,"A",{href:!0});var Dea=s(AJ);psr=r(Dea,"GPTNeoXForCausalLM"),Dea.forEach(t),_sr=r(IUe," (GPT NeoX model)"),IUe.forEach(t),bsr=i(H),MF=n(H,"LI",{});var NUe=s(MF);e4e=n(NUe,"STRONG",{});var Gea=s(e4e);vsr=r(Gea,"gpt_neox_japanese"),Gea.forEach(t),Fsr=r(NUe," \u2014 "),LJ=n(NUe,"A",{href:!0});var Oea=s(LJ);Tsr=r(Oea,"GPTNeoXJapaneseForCausalLM"),Oea.forEach(t),Msr=r(NUe," (GPT NeoX Japanese model)"),NUe.forEach(t),Esr=i(H),EF=n(H,"LI",{});var qUe=s(EF);o4e=n(qUe,"STRONG",{});var Vea=s(o4e);Csr=r(Vea,"gptj"),Vea.forEach(t),wsr=r(qUe," \u2014 "),yJ=n(qUe,"A",{href:!0});var Xea=s(yJ);Asr=r(Xea,"GPTJForCausalLM"),Xea.forEach(t),Lsr=r(qUe," (GPT-J model)"),qUe.forEach(t),ysr=i(H),CF=n(H,"LI",{});var jUe=s(CF);r4e=n(jUe,"STRONG",{});var zea=s(r4e);xsr=r(zea,"marian"),zea.forEach(t),$sr=r(jUe," \u2014 "),xJ=n(jUe,"A",{href:!0});var Qea=s(xJ);ksr=r(Qea,"MarianForCausalLM"),Qea.forEach(t),Ssr=r(jUe," (Marian model)"),jUe.forEach(t),Rsr=i(H),wF=n(H,"LI",{});var DUe=s(wF);t4e=n(DUe,"STRONG",{});var Wea=s(t4e);Psr=r(Wea,"mbart"),Wea.forEach(t),Bsr=r(DUe," \u2014 "),$J=n(DUe,"A",{href:!0});var Uea=s($J);Isr=r(Uea,"MBartForCausalLM"),Uea.forEach(t),Nsr=r(DUe," (mBART model)"),DUe.forEach(t),qsr=i(H),AF=n(H,"LI",{});var GUe=s(AF);a4e=n(GUe,"STRONG",{});var Hea=s(a4e);jsr=r(Hea,"megatron-bert"),Hea.forEach(t),Dsr=r(GUe," \u2014 "),kJ=n(GUe,"A",{href:!0});var Jea=s(kJ);Gsr=r(Jea,"MegatronBertForCausalLM"),Jea.forEach(t),Osr=r(GUe," (Megatron-BERT model)"),GUe.forEach(t),Vsr=i(H),LF=n(H,"LI",{});var OUe=s(LF);n4e=n(OUe,"STRONG",{});var Yea=s(n4e);Xsr=r(Yea,"mvp"),Yea.forEach(t),zsr=r(OUe," \u2014 "),SJ=n(OUe,"A",{href:!0});var Zea=s(SJ);Qsr=r(Zea,"MvpForCausalLM"),Zea.forEach(t),Wsr=r(OUe," (MVP model)"),OUe.forEach(t),Usr=i(H),yF=n(H,"LI",{});var VUe=s(yF);s4e=n(VUe,"STRONG",{});var Kea=s(s4e);Hsr=r(Kea,"openai-gpt"),Kea.forEach(t),Jsr=r(VUe," \u2014 "),RJ=n(VUe,"A",{href:!0});var eoa=s(RJ);Ysr=r(eoa,"OpenAIGPTLMHeadModel"),eoa.forEach(t),Zsr=r(VUe," (OpenAI GPT model)"),VUe.forEach(t),Ksr=i(H),xF=n(H,"LI",{});var XUe=s(xF);l4e=n(XUe,"STRONG",{});var ooa=s(l4e);elr=r(ooa,"opt"),ooa.forEach(t),olr=r(XUe," \u2014 "),PJ=n(XUe,"A",{href:!0});var roa=s(PJ);rlr=r(roa,"OPTForCausalLM"),roa.forEach(t),tlr=r(XUe," (OPT model)"),XUe.forEach(t),alr=i(H),$F=n(H,"LI",{});var zUe=s($F);i4e=n(zUe,"STRONG",{});var toa=s(i4e);nlr=r(toa,"pegasus"),toa.forEach(t),slr=r(zUe," \u2014 "),BJ=n(zUe,"A",{href:!0});var aoa=s(BJ);llr=r(aoa,"PegasusForCausalLM"),aoa.forEach(t),ilr=r(zUe," (Pegasus model)"),zUe.forEach(t),dlr=i(H),kF=n(H,"LI",{});var QUe=s(kF);d4e=n(QUe,"STRONG",{});var noa=s(d4e);mlr=r(noa,"plbart"),noa.forEach(t),clr=r(QUe," \u2014 "),IJ=n(QUe,"A",{href:!0});var soa=s(IJ);flr=r(soa,"PLBartForCausalLM"),soa.forEach(t),glr=r(QUe," (PLBart model)"),QUe.forEach(t),hlr=i(H),SF=n(H,"LI",{});var WUe=s(SF);m4e=n(WUe,"STRONG",{});var loa=s(m4e);ulr=r(loa,"prophetnet"),loa.forEach(t),plr=r(WUe," \u2014 "),NJ=n(WUe,"A",{href:!0});var ioa=s(NJ);_lr=r(ioa,"ProphetNetForCausalLM"),ioa.forEach(t),blr=r(WUe," (ProphetNet model)"),WUe.forEach(t),vlr=i(H),RF=n(H,"LI",{});var UUe=s(RF);c4e=n(UUe,"STRONG",{});var doa=s(c4e);Flr=r(doa,"qdqbert"),doa.forEach(t),Tlr=r(UUe," \u2014 "),qJ=n(UUe,"A",{href:!0});var moa=s(qJ);Mlr=r(moa,"QDQBertLMHeadModel"),moa.forEach(t),Elr=r(UUe," (QDQBert model)"),UUe.forEach(t),Clr=i(H),PF=n(H,"LI",{});var HUe=s(PF);f4e=n(HUe,"STRONG",{});var coa=s(f4e);wlr=r(coa,"reformer"),coa.forEach(t),Alr=r(HUe," \u2014 "),jJ=n(HUe,"A",{href:!0});var foa=s(jJ);Llr=r(foa,"ReformerModelWithLMHead"),foa.forEach(t),ylr=r(HUe," (Reformer model)"),HUe.forEach(t),xlr=i(H),BF=n(H,"LI",{});var JUe=s(BF);g4e=n(JUe,"STRONG",{});var goa=s(g4e);$lr=r(goa,"rembert"),goa.forEach(t),klr=r(JUe," \u2014 "),DJ=n(JUe,"A",{href:!0});var hoa=s(DJ);Slr=r(hoa,"RemBertForCausalLM"),hoa.forEach(t),Rlr=r(JUe," (RemBERT model)"),JUe.forEach(t),Plr=i(H),IF=n(H,"LI",{});var YUe=s(IF);h4e=n(YUe,"STRONG",{});var uoa=s(h4e);Blr=r(uoa,"roberta"),uoa.forEach(t),Ilr=r(YUe," \u2014 "),GJ=n(YUe,"A",{href:!0});var poa=s(GJ);Nlr=r(poa,"RobertaForCausalLM"),poa.forEach(t),qlr=r(YUe," (RoBERTa model)"),YUe.forEach(t),jlr=i(H),NF=n(H,"LI",{});var ZUe=s(NF);u4e=n(ZUe,"STRONG",{});var _oa=s(u4e);Dlr=r(_oa,"roc_bert"),_oa.forEach(t),Glr=r(ZUe," \u2014 "),OJ=n(ZUe,"A",{href:!0});var boa=s(OJ);Olr=r(boa,"RoCBertForCausalLM"),boa.forEach(t),Vlr=r(ZUe," (RoCBert model)"),ZUe.forEach(t),Xlr=i(H),qF=n(H,"LI",{});var KUe=s(qF);p4e=n(KUe,"STRONG",{});var voa=s(p4e);zlr=r(voa,"roformer"),voa.forEach(t),Qlr=r(KUe," \u2014 "),VJ=n(KUe,"A",{href:!0});var Foa=s(VJ);Wlr=r(Foa,"RoFormerForCausalLM"),Foa.forEach(t),Ulr=r(KUe," (RoFormer model)"),KUe.forEach(t),Hlr=i(H),jF=n(H,"LI",{});var eHe=s(jF);_4e=n(eHe,"STRONG",{});var Toa=s(_4e);Jlr=r(Toa,"speech_to_text_2"),Toa.forEach(t),Ylr=r(eHe," \u2014 "),XJ=n(eHe,"A",{href:!0});var Moa=s(XJ);Zlr=r(Moa,"Speech2Text2ForCausalLM"),Moa.forEach(t),Klr=r(eHe," (Speech2Text2 model)"),eHe.forEach(t),eir=i(H),DF=n(H,"LI",{});var oHe=s(DF);b4e=n(oHe,"STRONG",{});var Eoa=s(b4e);oir=r(Eoa,"transfo-xl"),Eoa.forEach(t),rir=r(oHe," \u2014 "),zJ=n(oHe,"A",{href:!0});var Coa=s(zJ);tir=r(Coa,"TransfoXLLMHeadModel"),Coa.forEach(t),air=r(oHe," (Transformer-XL model)"),oHe.forEach(t),nir=i(H),GF=n(H,"LI",{});var rHe=s(GF);v4e=n(rHe,"STRONG",{});var woa=s(v4e);sir=r(woa,"trocr"),woa.forEach(t),lir=r(rHe," \u2014 "),QJ=n(rHe,"A",{href:!0});var Aoa=s(QJ);iir=r(Aoa,"TrOCRForCausalLM"),Aoa.forEach(t),dir=r(rHe," (TrOCR model)"),rHe.forEach(t),mir=i(H),OF=n(H,"LI",{});var tHe=s(OF);F4e=n(tHe,"STRONG",{});var Loa=s(F4e);cir=r(Loa,"xglm"),Loa.forEach(t),fir=r(tHe," \u2014 "),WJ=n(tHe,"A",{href:!0});var yoa=s(WJ);gir=r(yoa,"XGLMForCausalLM"),yoa.forEach(t),hir=r(tHe," (XGLM model)"),tHe.forEach(t),uir=i(H),VF=n(H,"LI",{});var aHe=s(VF);T4e=n(aHe,"STRONG",{});var xoa=s(T4e);pir=r(xoa,"xlm"),xoa.forEach(t),_ir=r(aHe," \u2014 "),UJ=n(aHe,"A",{href:!0});var $oa=s(UJ);bir=r($oa,"XLMWithLMHeadModel"),$oa.forEach(t),vir=r(aHe," (XLM model)"),aHe.forEach(t),Fir=i(H),XF=n(H,"LI",{});var nHe=s(XF);M4e=n(nHe,"STRONG",{});var koa=s(M4e);Tir=r(koa,"xlm-prophetnet"),koa.forEach(t),Mir=r(nHe," \u2014 "),HJ=n(nHe,"A",{href:!0});var Soa=s(HJ);Eir=r(Soa,"XLMProphetNetForCausalLM"),Soa.forEach(t),Cir=r(nHe," (XLM-ProphetNet model)"),nHe.forEach(t),wir=i(H),zF=n(H,"LI",{});var sHe=s(zF);E4e=n(sHe,"STRONG",{});var Roa=s(E4e);Air=r(Roa,"xlm-roberta"),Roa.forEach(t),Lir=r(sHe," \u2014 "),JJ=n(sHe,"A",{href:!0});var Poa=s(JJ);yir=r(Poa,"XLMRobertaForCausalLM"),Poa.forEach(t),xir=r(sHe," (XLM-RoBERTa model)"),sHe.forEach(t),$ir=i(H),QF=n(H,"LI",{});var lHe=s(QF);C4e=n(lHe,"STRONG",{});var Boa=s(C4e);kir=r(Boa,"xlm-roberta-xl"),Boa.forEach(t),Sir=r(lHe," \u2014 "),YJ=n(lHe,"A",{href:!0});var Ioa=s(YJ);Rir=r(Ioa,"XLMRobertaXLForCausalLM"),Ioa.forEach(t),Pir=r(lHe," (XLM-RoBERTa-XL model)"),lHe.forEach(t),Bir=i(H),WF=n(H,"LI",{});var iHe=s(WF);w4e=n(iHe,"STRONG",{});var Noa=s(w4e);Iir=r(Noa,"xlnet"),Noa.forEach(t),Nir=r(iHe," \u2014 "),ZJ=n(iHe,"A",{href:!0});var qoa=s(ZJ);qir=r(qoa,"XLNetLMHeadModel"),qoa.forEach(t),jir=r(iHe," (XLNet model)"),iHe.forEach(t),H.forEach(t),Dir=i(Pa),UF=n(Pa,"P",{});var dHe=s(UF);Gir=r(dHe,"The model is set in evaluation mode by default using "),A4e=n(dHe,"CODE",{});var joa=s(A4e);Oir=r(joa,"model.eval()"),joa.forEach(t),Vir=r(dHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),L4e=n(dHe,"CODE",{});var Doa=s(L4e);Xir=r(Doa,"model.train()"),Doa.forEach(t),dHe.forEach(t),zir=i(Pa),T(HF.$$.fragment,Pa),Pa.forEach(t),Hl.forEach(t),vio=i(c),Jd=n(c,"H2",{class:!0});var Gmo=s(Jd);JF=n(Gmo,"A",{id:!0,class:!0,href:!0});var Goa=s(JF);y4e=n(Goa,"SPAN",{});var Ooa=s(y4e);T(hS.$$.fragment,Ooa),Ooa.forEach(t),Goa.forEach(t),Qir=i(Gmo),x4e=n(Gmo,"SPAN",{});var Voa=s(x4e);Wir=r(Voa,"AutoModelForDepthEstimation"),Voa.forEach(t),Gmo.forEach(t),Fio=i(c),Vo=n(c,"DIV",{class:!0});var Jl=s(Vo);T(uS.$$.fragment,Jl),Uir=i(Jl),Yd=n(Jl,"P",{});var $fe=s(Yd);Hir=r($fe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a depth estimation head) when created
with the `),KJ=n($fe,"A",{href:!0});var Xoa=s(KJ);Jir=r(Xoa,"from_pretrained()"),Xoa.forEach(t),Yir=r($fe," class method or the "),eY=n($fe,"A",{href:!0});var zoa=s(eY);Zir=r(zoa,"from_config()"),zoa.forEach(t),Kir=r($fe,` class
method.`),$fe.forEach(t),edr=i(Jl),pS=n(Jl,"P",{});var Omo=s(pS);odr=r(Omo,"This class cannot be instantiated directly using "),$4e=n(Omo,"CODE",{});var Qoa=s($4e);rdr=r(Qoa,"__init__()"),Qoa.forEach(t),tdr=r(Omo," (throws an error)."),Omo.forEach(t),adr=i(Jl),xt=n(Jl,"DIV",{class:!0});var bx=s(xt);T(_S.$$.fragment,bx),ndr=i(bx),k4e=n(bx,"P",{});var Woa=s(k4e);sdr=r(Woa,"Instantiates one of the model classes of the library (with a depth estimation head) from a configuration."),Woa.forEach(t),ldr=i(bx),Zd=n(bx,"P",{});var kfe=s(Zd);idr=r(kfe,`Note:
Loading a model from its configuration file does `),S4e=n(kfe,"STRONG",{});var Uoa=s(S4e);ddr=r(Uoa,"not"),Uoa.forEach(t),mdr=r(kfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),oY=n(kfe,"A",{href:!0});var Hoa=s(oY);cdr=r(Hoa,"from_pretrained()"),Hoa.forEach(t),fdr=r(kfe," to load the model weights."),kfe.forEach(t),gdr=i(bx),T(YF.$$.fragment,bx),bx.forEach(t),hdr=i(Jl),so=n(Jl,"DIV",{class:!0});var Ba=s(so);T(bS.$$.fragment,Ba),udr=i(Ba),R4e=n(Ba,"P",{});var Joa=s(R4e);pdr=r(Joa,"Instantiate one of the model classes of the library (with a depth estimation head) from a pretrained model."),Joa.forEach(t),_dr=i(Ba),pn=n(Ba,"P",{});var vx=s(pn);bdr=r(vx,"The model class to instantiate is selected based on the "),P4e=n(vx,"CODE",{});var Yoa=s(P4e);vdr=r(Yoa,"model_type"),Yoa.forEach(t),Fdr=r(vx,` property of the config object (either
passed as an argument or loaded from `),B4e=n(vx,"CODE",{});var Zoa=s(B4e);Tdr=r(Zoa,"pretrained_model_name_or_path"),Zoa.forEach(t),Mdr=r(vx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I4e=n(vx,"CODE",{});var Koa=s(I4e);Edr=r(Koa,"pretrained_model_name_or_path"),Koa.forEach(t),Cdr=r(vx,":"),vx.forEach(t),wdr=i(Ba),vS=n(Ba,"UL",{});var Vmo=s(vS);ZF=n(Vmo,"LI",{});var mHe=s(ZF);N4e=n(mHe,"STRONG",{});var era=s(N4e);Adr=r(era,"dpt"),era.forEach(t),Ldr=r(mHe," \u2014 "),rY=n(mHe,"A",{href:!0});var ora=s(rY);ydr=r(ora,"DPTForDepthEstimation"),ora.forEach(t),xdr=r(mHe," (DPT model)"),mHe.forEach(t),$dr=i(Vmo),KF=n(Vmo,"LI",{});var cHe=s(KF);q4e=n(cHe,"STRONG",{});var rra=s(q4e);kdr=r(rra,"glpn"),rra.forEach(t),Sdr=r(cHe," \u2014 "),tY=n(cHe,"A",{href:!0});var tra=s(tY);Rdr=r(tra,"GLPNForDepthEstimation"),tra.forEach(t),Pdr=r(cHe," (GLPN model)"),cHe.forEach(t),Vmo.forEach(t),Bdr=i(Ba),eT=n(Ba,"P",{});var fHe=s(eT);Idr=r(fHe,"The model is set in evaluation mode by default using "),j4e=n(fHe,"CODE",{});var ara=s(j4e);Ndr=r(ara,"model.eval()"),ara.forEach(t),qdr=r(fHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),D4e=n(fHe,"CODE",{});var nra=s(D4e);jdr=r(nra,"model.train()"),nra.forEach(t),fHe.forEach(t),Ddr=i(Ba),T(oT.$$.fragment,Ba),Ba.forEach(t),Jl.forEach(t),Tio=i(c),Kd=n(c,"H2",{class:!0});var Xmo=s(Kd);rT=n(Xmo,"A",{id:!0,class:!0,href:!0});var sra=s(rT);G4e=n(sra,"SPAN",{});var lra=s(G4e);T(FS.$$.fragment,lra),lra.forEach(t),sra.forEach(t),Gdr=i(Xmo),O4e=n(Xmo,"SPAN",{});var ira=s(O4e);Odr=r(ira,"AutoModelForMaskedLM"),ira.forEach(t),Xmo.forEach(t),Mio=i(c),Xo=n(c,"DIV",{class:!0});var Yl=s(Xo);T(TS.$$.fragment,Yl),Vdr=i(Yl),em=n(Yl,"P",{});var Sfe=s(em);Xdr=r(Sfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),aY=n(Sfe,"A",{href:!0});var dra=s(aY);zdr=r(dra,"from_pretrained()"),dra.forEach(t),Qdr=r(Sfe," class method or the "),nY=n(Sfe,"A",{href:!0});var mra=s(nY);Wdr=r(mra,"from_config()"),mra.forEach(t),Udr=r(Sfe,` class
method.`),Sfe.forEach(t),Hdr=i(Yl),MS=n(Yl,"P",{});var zmo=s(MS);Jdr=r(zmo,"This class cannot be instantiated directly using "),V4e=n(zmo,"CODE",{});var cra=s(V4e);Ydr=r(cra,"__init__()"),cra.forEach(t),Zdr=r(zmo," (throws an error)."),zmo.forEach(t),Kdr=i(Yl),$t=n(Yl,"DIV",{class:!0});var Fx=s($t);T(ES.$$.fragment,Fx),emr=i(Fx),X4e=n(Fx,"P",{});var fra=s(X4e);omr=r(fra,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),fra.forEach(t),rmr=i(Fx),om=n(Fx,"P",{});var Rfe=s(om);tmr=r(Rfe,`Note:
Loading a model from its configuration file does `),z4e=n(Rfe,"STRONG",{});var gra=s(z4e);amr=r(gra,"not"),gra.forEach(t),nmr=r(Rfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),sY=n(Rfe,"A",{href:!0});var hra=s(sY);smr=r(hra,"from_pretrained()"),hra.forEach(t),lmr=r(Rfe," to load the model weights."),Rfe.forEach(t),imr=i(Fx),T(tT.$$.fragment,Fx),Fx.forEach(t),dmr=i(Yl),lo=n(Yl,"DIV",{class:!0});var Ia=s(lo);T(CS.$$.fragment,Ia),mmr=i(Ia),Q4e=n(Ia,"P",{});var ura=s(Q4e);cmr=r(ura,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),ura.forEach(t),fmr=i(Ia),_n=n(Ia,"P",{});var Tx=s(_n);gmr=r(Tx,"The model class to instantiate is selected based on the "),W4e=n(Tx,"CODE",{});var pra=s(W4e);hmr=r(pra,"model_type"),pra.forEach(t),umr=r(Tx,` property of the config object (either
passed as an argument or loaded from `),U4e=n(Tx,"CODE",{});var _ra=s(U4e);pmr=r(_ra,"pretrained_model_name_or_path"),_ra.forEach(t),_mr=r(Tx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H4e=n(Tx,"CODE",{});var bra=s(H4e);bmr=r(bra,"pretrained_model_name_or_path"),bra.forEach(t),vmr=r(Tx,":"),Tx.forEach(t),Fmr=i(Ia),Y=n(Ia,"UL",{});var Z=s(Y);aT=n(Z,"LI",{});var gHe=s(aT);J4e=n(gHe,"STRONG",{});var vra=s(J4e);Tmr=r(vra,"albert"),vra.forEach(t),Mmr=r(gHe," \u2014 "),lY=n(gHe,"A",{href:!0});var Fra=s(lY);Emr=r(Fra,"AlbertForMaskedLM"),Fra.forEach(t),Cmr=r(gHe," (ALBERT model)"),gHe.forEach(t),wmr=i(Z),nT=n(Z,"LI",{});var hHe=s(nT);Y4e=n(hHe,"STRONG",{});var Tra=s(Y4e);Amr=r(Tra,"bart"),Tra.forEach(t),Lmr=r(hHe," \u2014 "),iY=n(hHe,"A",{href:!0});var Mra=s(iY);ymr=r(Mra,"BartForConditionalGeneration"),Mra.forEach(t),xmr=r(hHe," (BART model)"),hHe.forEach(t),$mr=i(Z),sT=n(Z,"LI",{});var uHe=s(sT);Z4e=n(uHe,"STRONG",{});var Era=s(Z4e);kmr=r(Era,"bert"),Era.forEach(t),Smr=r(uHe," \u2014 "),dY=n(uHe,"A",{href:!0});var Cra=s(dY);Rmr=r(Cra,"BertForMaskedLM"),Cra.forEach(t),Pmr=r(uHe," (BERT model)"),uHe.forEach(t),Bmr=i(Z),lT=n(Z,"LI",{});var pHe=s(lT);K4e=n(pHe,"STRONG",{});var wra=s(K4e);Imr=r(wra,"big_bird"),wra.forEach(t),Nmr=r(pHe," \u2014 "),mY=n(pHe,"A",{href:!0});var Ara=s(mY);qmr=r(Ara,"BigBirdForMaskedLM"),Ara.forEach(t),jmr=r(pHe," (BigBird model)"),pHe.forEach(t),Dmr=i(Z),iT=n(Z,"LI",{});var _He=s(iT);eCe=n(_He,"STRONG",{});var Lra=s(eCe);Gmr=r(Lra,"camembert"),Lra.forEach(t),Omr=r(_He," \u2014 "),cY=n(_He,"A",{href:!0});var yra=s(cY);Vmr=r(yra,"CamembertForMaskedLM"),yra.forEach(t),Xmr=r(_He," (CamemBERT model)"),_He.forEach(t),zmr=i(Z),dT=n(Z,"LI",{});var bHe=s(dT);oCe=n(bHe,"STRONG",{});var xra=s(oCe);Qmr=r(xra,"convbert"),xra.forEach(t),Wmr=r(bHe," \u2014 "),fY=n(bHe,"A",{href:!0});var $ra=s(fY);Umr=r($ra,"ConvBertForMaskedLM"),$ra.forEach(t),Hmr=r(bHe," (ConvBERT model)"),bHe.forEach(t),Jmr=i(Z),mT=n(Z,"LI",{});var vHe=s(mT);rCe=n(vHe,"STRONG",{});var kra=s(rCe);Ymr=r(kra,"data2vec-text"),kra.forEach(t),Zmr=r(vHe," \u2014 "),gY=n(vHe,"A",{href:!0});var Sra=s(gY);Kmr=r(Sra,"Data2VecTextForMaskedLM"),Sra.forEach(t),ecr=r(vHe," (Data2VecText model)"),vHe.forEach(t),ocr=i(Z),cT=n(Z,"LI",{});var FHe=s(cT);tCe=n(FHe,"STRONG",{});var Rra=s(tCe);rcr=r(Rra,"deberta"),Rra.forEach(t),tcr=r(FHe," \u2014 "),hY=n(FHe,"A",{href:!0});var Pra=s(hY);acr=r(Pra,"DebertaForMaskedLM"),Pra.forEach(t),ncr=r(FHe," (DeBERTa model)"),FHe.forEach(t),scr=i(Z),fT=n(Z,"LI",{});var THe=s(fT);aCe=n(THe,"STRONG",{});var Bra=s(aCe);lcr=r(Bra,"deberta-v2"),Bra.forEach(t),icr=r(THe," \u2014 "),uY=n(THe,"A",{href:!0});var Ira=s(uY);dcr=r(Ira,"DebertaV2ForMaskedLM"),Ira.forEach(t),mcr=r(THe," (DeBERTa-v2 model)"),THe.forEach(t),ccr=i(Z),gT=n(Z,"LI",{});var MHe=s(gT);nCe=n(MHe,"STRONG",{});var Nra=s(nCe);fcr=r(Nra,"distilbert"),Nra.forEach(t),gcr=r(MHe," \u2014 "),pY=n(MHe,"A",{href:!0});var qra=s(pY);hcr=r(qra,"DistilBertForMaskedLM"),qra.forEach(t),ucr=r(MHe," (DistilBERT model)"),MHe.forEach(t),pcr=i(Z),hT=n(Z,"LI",{});var EHe=s(hT);sCe=n(EHe,"STRONG",{});var jra=s(sCe);_cr=r(jra,"electra"),jra.forEach(t),bcr=r(EHe," \u2014 "),_Y=n(EHe,"A",{href:!0});var Dra=s(_Y);vcr=r(Dra,"ElectraForMaskedLM"),Dra.forEach(t),Fcr=r(EHe," (ELECTRA model)"),EHe.forEach(t),Tcr=i(Z),uT=n(Z,"LI",{});var CHe=s(uT);lCe=n(CHe,"STRONG",{});var Gra=s(lCe);Mcr=r(Gra,"ernie"),Gra.forEach(t),Ecr=r(CHe," \u2014 "),bY=n(CHe,"A",{href:!0});var Ora=s(bY);Ccr=r(Ora,"ErnieForMaskedLM"),Ora.forEach(t),wcr=r(CHe," (ERNIE model)"),CHe.forEach(t),Acr=i(Z),pT=n(Z,"LI",{});var wHe=s(pT);iCe=n(wHe,"STRONG",{});var Vra=s(iCe);Lcr=r(Vra,"flaubert"),Vra.forEach(t),ycr=r(wHe," \u2014 "),vY=n(wHe,"A",{href:!0});var Xra=s(vY);xcr=r(Xra,"FlaubertWithLMHeadModel"),Xra.forEach(t),$cr=r(wHe," (FlauBERT model)"),wHe.forEach(t),kcr=i(Z),_T=n(Z,"LI",{});var AHe=s(_T);dCe=n(AHe,"STRONG",{});var zra=s(dCe);Scr=r(zra,"fnet"),zra.forEach(t),Rcr=r(AHe," \u2014 "),FY=n(AHe,"A",{href:!0});var Qra=s(FY);Pcr=r(Qra,"FNetForMaskedLM"),Qra.forEach(t),Bcr=r(AHe," (FNet model)"),AHe.forEach(t),Icr=i(Z),bT=n(Z,"LI",{});var LHe=s(bT);mCe=n(LHe,"STRONG",{});var Wra=s(mCe);Ncr=r(Wra,"funnel"),Wra.forEach(t),qcr=r(LHe," \u2014 "),TY=n(LHe,"A",{href:!0});var Ura=s(TY);jcr=r(Ura,"FunnelForMaskedLM"),Ura.forEach(t),Dcr=r(LHe," (Funnel Transformer model)"),LHe.forEach(t),Gcr=i(Z),vT=n(Z,"LI",{});var yHe=s(vT);cCe=n(yHe,"STRONG",{});var Hra=s(cCe);Ocr=r(Hra,"ibert"),Hra.forEach(t),Vcr=r(yHe," \u2014 "),MY=n(yHe,"A",{href:!0});var Jra=s(MY);Xcr=r(Jra,"IBertForMaskedLM"),Jra.forEach(t),zcr=r(yHe," (I-BERT model)"),yHe.forEach(t),Qcr=i(Z),FT=n(Z,"LI",{});var xHe=s(FT);fCe=n(xHe,"STRONG",{});var Yra=s(fCe);Wcr=r(Yra,"layoutlm"),Yra.forEach(t),Ucr=r(xHe," \u2014 "),EY=n(xHe,"A",{href:!0});var Zra=s(EY);Hcr=r(Zra,"LayoutLMForMaskedLM"),Zra.forEach(t),Jcr=r(xHe," (LayoutLM model)"),xHe.forEach(t),Ycr=i(Z),TT=n(Z,"LI",{});var $He=s(TT);gCe=n($He,"STRONG",{});var Kra=s(gCe);Zcr=r(Kra,"longformer"),Kra.forEach(t),Kcr=r($He," \u2014 "),CY=n($He,"A",{href:!0});var eta=s(CY);efr=r(eta,"LongformerForMaskedLM"),eta.forEach(t),ofr=r($He," (Longformer model)"),$He.forEach(t),rfr=i(Z),MT=n(Z,"LI",{});var kHe=s(MT);hCe=n(kHe,"STRONG",{});var ota=s(hCe);tfr=r(ota,"luke"),ota.forEach(t),afr=r(kHe," \u2014 "),wY=n(kHe,"A",{href:!0});var rta=s(wY);nfr=r(rta,"LukeForMaskedLM"),rta.forEach(t),sfr=r(kHe," (LUKE model)"),kHe.forEach(t),lfr=i(Z),ET=n(Z,"LI",{});var SHe=s(ET);uCe=n(SHe,"STRONG",{});var tta=s(uCe);ifr=r(tta,"mbart"),tta.forEach(t),dfr=r(SHe," \u2014 "),AY=n(SHe,"A",{href:!0});var ata=s(AY);mfr=r(ata,"MBartForConditionalGeneration"),ata.forEach(t),cfr=r(SHe," (mBART model)"),SHe.forEach(t),ffr=i(Z),CT=n(Z,"LI",{});var RHe=s(CT);pCe=n(RHe,"STRONG",{});var nta=s(pCe);gfr=r(nta,"megatron-bert"),nta.forEach(t),hfr=r(RHe," \u2014 "),LY=n(RHe,"A",{href:!0});var sta=s(LY);ufr=r(sta,"MegatronBertForMaskedLM"),sta.forEach(t),pfr=r(RHe," (Megatron-BERT model)"),RHe.forEach(t),_fr=i(Z),wT=n(Z,"LI",{});var PHe=s(wT);_Ce=n(PHe,"STRONG",{});var lta=s(_Ce);bfr=r(lta,"mobilebert"),lta.forEach(t),vfr=r(PHe," \u2014 "),yY=n(PHe,"A",{href:!0});var ita=s(yY);Ffr=r(ita,"MobileBertForMaskedLM"),ita.forEach(t),Tfr=r(PHe," (MobileBERT model)"),PHe.forEach(t),Mfr=i(Z),AT=n(Z,"LI",{});var BHe=s(AT);bCe=n(BHe,"STRONG",{});var dta=s(bCe);Efr=r(dta,"mpnet"),dta.forEach(t),Cfr=r(BHe," \u2014 "),xY=n(BHe,"A",{href:!0});var mta=s(xY);wfr=r(mta,"MPNetForMaskedLM"),mta.forEach(t),Afr=r(BHe," (MPNet model)"),BHe.forEach(t),Lfr=i(Z),LT=n(Z,"LI",{});var IHe=s(LT);vCe=n(IHe,"STRONG",{});var cta=s(vCe);yfr=r(cta,"mvp"),cta.forEach(t),xfr=r(IHe," \u2014 "),$Y=n(IHe,"A",{href:!0});var fta=s($Y);$fr=r(fta,"MvpForConditionalGeneration"),fta.forEach(t),kfr=r(IHe," (MVP model)"),IHe.forEach(t),Sfr=i(Z),yT=n(Z,"LI",{});var NHe=s(yT);FCe=n(NHe,"STRONG",{});var gta=s(FCe);Rfr=r(gta,"nezha"),gta.forEach(t),Pfr=r(NHe," \u2014 "),kY=n(NHe,"A",{href:!0});var hta=s(kY);Bfr=r(hta,"NezhaForMaskedLM"),hta.forEach(t),Ifr=r(NHe," (Nezha model)"),NHe.forEach(t),Nfr=i(Z),xT=n(Z,"LI",{});var qHe=s(xT);TCe=n(qHe,"STRONG",{});var uta=s(TCe);qfr=r(uta,"nystromformer"),uta.forEach(t),jfr=r(qHe," \u2014 "),SY=n(qHe,"A",{href:!0});var pta=s(SY);Dfr=r(pta,"NystromformerForMaskedLM"),pta.forEach(t),Gfr=r(qHe," (Nystr\xF6mformer model)"),qHe.forEach(t),Ofr=i(Z),$T=n(Z,"LI",{});var jHe=s($T);MCe=n(jHe,"STRONG",{});var _ta=s(MCe);Vfr=r(_ta,"perceiver"),_ta.forEach(t),Xfr=r(jHe," \u2014 "),RY=n(jHe,"A",{href:!0});var bta=s(RY);zfr=r(bta,"PerceiverForMaskedLM"),bta.forEach(t),Qfr=r(jHe," (Perceiver model)"),jHe.forEach(t),Wfr=i(Z),kT=n(Z,"LI",{});var DHe=s(kT);ECe=n(DHe,"STRONG",{});var vta=s(ECe);Ufr=r(vta,"qdqbert"),vta.forEach(t),Hfr=r(DHe," \u2014 "),PY=n(DHe,"A",{href:!0});var Fta=s(PY);Jfr=r(Fta,"QDQBertForMaskedLM"),Fta.forEach(t),Yfr=r(DHe," (QDQBert model)"),DHe.forEach(t),Zfr=i(Z),ST=n(Z,"LI",{});var GHe=s(ST);CCe=n(GHe,"STRONG",{});var Tta=s(CCe);Kfr=r(Tta,"reformer"),Tta.forEach(t),egr=r(GHe," \u2014 "),BY=n(GHe,"A",{href:!0});var Mta=s(BY);ogr=r(Mta,"ReformerForMaskedLM"),Mta.forEach(t),rgr=r(GHe," (Reformer model)"),GHe.forEach(t),tgr=i(Z),RT=n(Z,"LI",{});var OHe=s(RT);wCe=n(OHe,"STRONG",{});var Eta=s(wCe);agr=r(Eta,"rembert"),Eta.forEach(t),ngr=r(OHe," \u2014 "),IY=n(OHe,"A",{href:!0});var Cta=s(IY);sgr=r(Cta,"RemBertForMaskedLM"),Cta.forEach(t),lgr=r(OHe," (RemBERT model)"),OHe.forEach(t),igr=i(Z),PT=n(Z,"LI",{});var VHe=s(PT);ACe=n(VHe,"STRONG",{});var wta=s(ACe);dgr=r(wta,"roberta"),wta.forEach(t),mgr=r(VHe," \u2014 "),NY=n(VHe,"A",{href:!0});var Ata=s(NY);cgr=r(Ata,"RobertaForMaskedLM"),Ata.forEach(t),fgr=r(VHe," (RoBERTa model)"),VHe.forEach(t),ggr=i(Z),BT=n(Z,"LI",{});var XHe=s(BT);LCe=n(XHe,"STRONG",{});var Lta=s(LCe);hgr=r(Lta,"roc_bert"),Lta.forEach(t),ugr=r(XHe," \u2014 "),qY=n(XHe,"A",{href:!0});var yta=s(qY);pgr=r(yta,"RoCBertForMaskedLM"),yta.forEach(t),_gr=r(XHe," (RoCBert model)"),XHe.forEach(t),bgr=i(Z),IT=n(Z,"LI",{});var zHe=s(IT);yCe=n(zHe,"STRONG",{});var xta=s(yCe);vgr=r(xta,"roformer"),xta.forEach(t),Fgr=r(zHe," \u2014 "),jY=n(zHe,"A",{href:!0});var $ta=s(jY);Tgr=r($ta,"RoFormerForMaskedLM"),$ta.forEach(t),Mgr=r(zHe," (RoFormer model)"),zHe.forEach(t),Egr=i(Z),NT=n(Z,"LI",{});var QHe=s(NT);xCe=n(QHe,"STRONG",{});var kta=s(xCe);Cgr=r(kta,"squeezebert"),kta.forEach(t),wgr=r(QHe," \u2014 "),DY=n(QHe,"A",{href:!0});var Sta=s(DY);Agr=r(Sta,"SqueezeBertForMaskedLM"),Sta.forEach(t),Lgr=r(QHe," (SqueezeBERT model)"),QHe.forEach(t),ygr=i(Z),qT=n(Z,"LI",{});var WHe=s(qT);$Ce=n(WHe,"STRONG",{});var Rta=s($Ce);xgr=r(Rta,"tapas"),Rta.forEach(t),$gr=r(WHe," \u2014 "),GY=n(WHe,"A",{href:!0});var Pta=s(GY);kgr=r(Pta,"TapasForMaskedLM"),Pta.forEach(t),Sgr=r(WHe," (TAPAS model)"),WHe.forEach(t),Rgr=i(Z),jT=n(Z,"LI",{});var UHe=s(jT);kCe=n(UHe,"STRONG",{});var Bta=s(kCe);Pgr=r(Bta,"wav2vec2"),Bta.forEach(t),Bgr=r(UHe," \u2014 "),SCe=n(UHe,"CODE",{});var Ita=s(SCe);Igr=r(Ita,"Wav2Vec2ForMaskedLM"),Ita.forEach(t),Ngr=r(UHe," (Wav2Vec2 model)"),UHe.forEach(t),qgr=i(Z),DT=n(Z,"LI",{});var HHe=s(DT);RCe=n(HHe,"STRONG",{});var Nta=s(RCe);jgr=r(Nta,"xlm"),Nta.forEach(t),Dgr=r(HHe," \u2014 "),OY=n(HHe,"A",{href:!0});var qta=s(OY);Ggr=r(qta,"XLMWithLMHeadModel"),qta.forEach(t),Ogr=r(HHe," (XLM model)"),HHe.forEach(t),Vgr=i(Z),GT=n(Z,"LI",{});var JHe=s(GT);PCe=n(JHe,"STRONG",{});var jta=s(PCe);Xgr=r(jta,"xlm-roberta"),jta.forEach(t),zgr=r(JHe," \u2014 "),VY=n(JHe,"A",{href:!0});var Dta=s(VY);Qgr=r(Dta,"XLMRobertaForMaskedLM"),Dta.forEach(t),Wgr=r(JHe," (XLM-RoBERTa model)"),JHe.forEach(t),Ugr=i(Z),OT=n(Z,"LI",{});var YHe=s(OT);BCe=n(YHe,"STRONG",{});var Gta=s(BCe);Hgr=r(Gta,"xlm-roberta-xl"),Gta.forEach(t),Jgr=r(YHe," \u2014 "),XY=n(YHe,"A",{href:!0});var Ota=s(XY);Ygr=r(Ota,"XLMRobertaXLForMaskedLM"),Ota.forEach(t),Zgr=r(YHe," (XLM-RoBERTa-XL model)"),YHe.forEach(t),Kgr=i(Z),VT=n(Z,"LI",{});var ZHe=s(VT);ICe=n(ZHe,"STRONG",{});var Vta=s(ICe);ehr=r(Vta,"yoso"),Vta.forEach(t),ohr=r(ZHe," \u2014 "),zY=n(ZHe,"A",{href:!0});var Xta=s(zY);rhr=r(Xta,"YosoForMaskedLM"),Xta.forEach(t),thr=r(ZHe," (YOSO model)"),ZHe.forEach(t),Z.forEach(t),ahr=i(Ia),XT=n(Ia,"P",{});var KHe=s(XT);nhr=r(KHe,"The model is set in evaluation mode by default using "),NCe=n(KHe,"CODE",{});var zta=s(NCe);shr=r(zta,"model.eval()"),zta.forEach(t),lhr=r(KHe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qCe=n(KHe,"CODE",{});var Qta=s(qCe);ihr=r(Qta,"model.train()"),Qta.forEach(t),KHe.forEach(t),dhr=i(Ia),T(zT.$$.fragment,Ia),Ia.forEach(t),Yl.forEach(t),Eio=i(c),rm=n(c,"H2",{class:!0});var Qmo=s(rm);QT=n(Qmo,"A",{id:!0,class:!0,href:!0});var Wta=s(QT);jCe=n(Wta,"SPAN",{});var Uta=s(jCe);T(wS.$$.fragment,Uta),Uta.forEach(t),Wta.forEach(t),mhr=i(Qmo),DCe=n(Qmo,"SPAN",{});var Hta=s(DCe);chr=r(Hta,"AutoModelForSeq2SeqLM"),Hta.forEach(t),Qmo.forEach(t),Cio=i(c),zo=n(c,"DIV",{class:!0});var Zl=s(zo);T(AS.$$.fragment,Zl),fhr=i(Zl),tm=n(Zl,"P",{});var Pfe=s(tm);ghr=r(Pfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),QY=n(Pfe,"A",{href:!0});var Jta=s(QY);hhr=r(Jta,"from_pretrained()"),Jta.forEach(t),uhr=r(Pfe," class method or the "),WY=n(Pfe,"A",{href:!0});var Yta=s(WY);phr=r(Yta,"from_config()"),Yta.forEach(t),_hr=r(Pfe,` class
method.`),Pfe.forEach(t),bhr=i(Zl),LS=n(Zl,"P",{});var Wmo=s(LS);vhr=r(Wmo,"This class cannot be instantiated directly using "),GCe=n(Wmo,"CODE",{});var Zta=s(GCe);Fhr=r(Zta,"__init__()"),Zta.forEach(t),Thr=r(Wmo," (throws an error)."),Wmo.forEach(t),Mhr=i(Zl),kt=n(Zl,"DIV",{class:!0});var Mx=s(kt);T(yS.$$.fragment,Mx),Ehr=i(Mx),OCe=n(Mx,"P",{});var Kta=s(OCe);Chr=r(Kta,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Kta.forEach(t),whr=i(Mx),am=n(Mx,"P",{});var Bfe=s(am);Ahr=r(Bfe,`Note:
Loading a model from its configuration file does `),VCe=n(Bfe,"STRONG",{});var eaa=s(VCe);Lhr=r(eaa,"not"),eaa.forEach(t),yhr=r(Bfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),UY=n(Bfe,"A",{href:!0});var oaa=s(UY);xhr=r(oaa,"from_pretrained()"),oaa.forEach(t),$hr=r(Bfe," to load the model weights."),Bfe.forEach(t),khr=i(Mx),T(WT.$$.fragment,Mx),Mx.forEach(t),Shr=i(Zl),io=n(Zl,"DIV",{class:!0});var Na=s(io);T(xS.$$.fragment,Na),Rhr=i(Na),XCe=n(Na,"P",{});var raa=s(XCe);Phr=r(raa,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),raa.forEach(t),Bhr=i(Na),bn=n(Na,"P",{});var Ex=s(bn);Ihr=r(Ex,"The model class to instantiate is selected based on the "),zCe=n(Ex,"CODE",{});var taa=s(zCe);Nhr=r(taa,"model_type"),taa.forEach(t),qhr=r(Ex,` property of the config object (either
passed as an argument or loaded from `),QCe=n(Ex,"CODE",{});var aaa=s(QCe);jhr=r(aaa,"pretrained_model_name_or_path"),aaa.forEach(t),Dhr=r(Ex,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),WCe=n(Ex,"CODE",{});var naa=s(WCe);Ghr=r(naa,"pretrained_model_name_or_path"),naa.forEach(t),Ohr=r(Ex,":"),Ex.forEach(t),Vhr=i(Na),pe=n(Na,"UL",{});var Fe=s(pe);UT=n(Fe,"LI",{});var eJe=s(UT);UCe=n(eJe,"STRONG",{});var saa=s(UCe);Xhr=r(saa,"bart"),saa.forEach(t),zhr=r(eJe," \u2014 "),HY=n(eJe,"A",{href:!0});var laa=s(HY);Qhr=r(laa,"BartForConditionalGeneration"),laa.forEach(t),Whr=r(eJe," (BART model)"),eJe.forEach(t),Uhr=i(Fe),HT=n(Fe,"LI",{});var oJe=s(HT);HCe=n(oJe,"STRONG",{});var iaa=s(HCe);Hhr=r(iaa,"bigbird_pegasus"),iaa.forEach(t),Jhr=r(oJe," \u2014 "),JY=n(oJe,"A",{href:!0});var daa=s(JY);Yhr=r(daa,"BigBirdPegasusForConditionalGeneration"),daa.forEach(t),Zhr=r(oJe," (BigBird-Pegasus model)"),oJe.forEach(t),Khr=i(Fe),JT=n(Fe,"LI",{});var rJe=s(JT);JCe=n(rJe,"STRONG",{});var maa=s(JCe);eur=r(maa,"blenderbot"),maa.forEach(t),our=r(rJe," \u2014 "),YY=n(rJe,"A",{href:!0});var caa=s(YY);rur=r(caa,"BlenderbotForConditionalGeneration"),caa.forEach(t),tur=r(rJe," (Blenderbot model)"),rJe.forEach(t),aur=i(Fe),YT=n(Fe,"LI",{});var tJe=s(YT);YCe=n(tJe,"STRONG",{});var faa=s(YCe);nur=r(faa,"blenderbot-small"),faa.forEach(t),sur=r(tJe," \u2014 "),ZY=n(tJe,"A",{href:!0});var gaa=s(ZY);lur=r(gaa,"BlenderbotSmallForConditionalGeneration"),gaa.forEach(t),iur=r(tJe," (BlenderbotSmall model)"),tJe.forEach(t),dur=i(Fe),ZT=n(Fe,"LI",{});var aJe=s(ZT);ZCe=n(aJe,"STRONG",{});var haa=s(ZCe);mur=r(haa,"encoder-decoder"),haa.forEach(t),cur=r(aJe," \u2014 "),KY=n(aJe,"A",{href:!0});var uaa=s(KY);fur=r(uaa,"EncoderDecoderModel"),uaa.forEach(t),gur=r(aJe," (Encoder decoder model)"),aJe.forEach(t),hur=i(Fe),KT=n(Fe,"LI",{});var nJe=s(KT);KCe=n(nJe,"STRONG",{});var paa=s(KCe);uur=r(paa,"fsmt"),paa.forEach(t),pur=r(nJe," \u2014 "),eZ=n(nJe,"A",{href:!0});var _aa=s(eZ);_ur=r(_aa,"FSMTForConditionalGeneration"),_aa.forEach(t),bur=r(nJe," (FairSeq Machine-Translation model)"),nJe.forEach(t),vur=i(Fe),eM=n(Fe,"LI",{});var sJe=s(eM);e3e=n(sJe,"STRONG",{});var baa=s(e3e);Fur=r(baa,"led"),baa.forEach(t),Tur=r(sJe," \u2014 "),oZ=n(sJe,"A",{href:!0});var vaa=s(oZ);Mur=r(vaa,"LEDForConditionalGeneration"),vaa.forEach(t),Eur=r(sJe," (LED model)"),sJe.forEach(t),Cur=i(Fe),oM=n(Fe,"LI",{});var lJe=s(oM);o3e=n(lJe,"STRONG",{});var Faa=s(o3e);wur=r(Faa,"longt5"),Faa.forEach(t),Aur=r(lJe," \u2014 "),rZ=n(lJe,"A",{href:!0});var Taa=s(rZ);Lur=r(Taa,"LongT5ForConditionalGeneration"),Taa.forEach(t),yur=r(lJe," (LongT5 model)"),lJe.forEach(t),xur=i(Fe),rM=n(Fe,"LI",{});var iJe=s(rM);r3e=n(iJe,"STRONG",{});var Maa=s(r3e);$ur=r(Maa,"m2m_100"),Maa.forEach(t),kur=r(iJe," \u2014 "),tZ=n(iJe,"A",{href:!0});var Eaa=s(tZ);Sur=r(Eaa,"M2M100ForConditionalGeneration"),Eaa.forEach(t),Rur=r(iJe," (M2M100 model)"),iJe.forEach(t),Pur=i(Fe),tM=n(Fe,"LI",{});var dJe=s(tM);t3e=n(dJe,"STRONG",{});var Caa=s(t3e);Bur=r(Caa,"marian"),Caa.forEach(t),Iur=r(dJe," \u2014 "),aZ=n(dJe,"A",{href:!0});var waa=s(aZ);Nur=r(waa,"MarianMTModel"),waa.forEach(t),qur=r(dJe," (Marian model)"),dJe.forEach(t),jur=i(Fe),aM=n(Fe,"LI",{});var mJe=s(aM);a3e=n(mJe,"STRONG",{});var Aaa=s(a3e);Dur=r(Aaa,"mbart"),Aaa.forEach(t),Gur=r(mJe," \u2014 "),nZ=n(mJe,"A",{href:!0});var Laa=s(nZ);Our=r(Laa,"MBartForConditionalGeneration"),Laa.forEach(t),Vur=r(mJe," (mBART model)"),mJe.forEach(t),Xur=i(Fe),nM=n(Fe,"LI",{});var cJe=s(nM);n3e=n(cJe,"STRONG",{});var yaa=s(n3e);zur=r(yaa,"mt5"),yaa.forEach(t),Qur=r(cJe," \u2014 "),sZ=n(cJe,"A",{href:!0});var xaa=s(sZ);Wur=r(xaa,"MT5ForConditionalGeneration"),xaa.forEach(t),Uur=r(cJe," (MT5 model)"),cJe.forEach(t),Hur=i(Fe),sM=n(Fe,"LI",{});var fJe=s(sM);s3e=n(fJe,"STRONG",{});var $aa=s(s3e);Jur=r($aa,"mvp"),$aa.forEach(t),Yur=r(fJe," \u2014 "),lZ=n(fJe,"A",{href:!0});var kaa=s(lZ);Zur=r(kaa,"MvpForConditionalGeneration"),kaa.forEach(t),Kur=r(fJe," (MVP model)"),fJe.forEach(t),epr=i(Fe),lM=n(Fe,"LI",{});var gJe=s(lM);l3e=n(gJe,"STRONG",{});var Saa=s(l3e);opr=r(Saa,"nllb"),Saa.forEach(t),rpr=r(gJe," \u2014 "),iZ=n(gJe,"A",{href:!0});var Raa=s(iZ);tpr=r(Raa,"M2M100ForConditionalGeneration"),Raa.forEach(t),apr=r(gJe," (NLLB model)"),gJe.forEach(t),npr=i(Fe),iM=n(Fe,"LI",{});var hJe=s(iM);i3e=n(hJe,"STRONG",{});var Paa=s(i3e);spr=r(Paa,"pegasus"),Paa.forEach(t),lpr=r(hJe," \u2014 "),dZ=n(hJe,"A",{href:!0});var Baa=s(dZ);ipr=r(Baa,"PegasusForConditionalGeneration"),Baa.forEach(t),dpr=r(hJe," (Pegasus model)"),hJe.forEach(t),mpr=i(Fe),dM=n(Fe,"LI",{});var uJe=s(dM);d3e=n(uJe,"STRONG",{});var Iaa=s(d3e);cpr=r(Iaa,"pegasus_x"),Iaa.forEach(t),fpr=r(uJe," \u2014 "),mZ=n(uJe,"A",{href:!0});var Naa=s(mZ);gpr=r(Naa,"PegasusXForConditionalGeneration"),Naa.forEach(t),hpr=r(uJe," (PEGASUS-X model)"),uJe.forEach(t),upr=i(Fe),mM=n(Fe,"LI",{});var pJe=s(mM);m3e=n(pJe,"STRONG",{});var qaa=s(m3e);ppr=r(qaa,"plbart"),qaa.forEach(t),_pr=r(pJe," \u2014 "),cZ=n(pJe,"A",{href:!0});var jaa=s(cZ);bpr=r(jaa,"PLBartForConditionalGeneration"),jaa.forEach(t),vpr=r(pJe," (PLBart model)"),pJe.forEach(t),Fpr=i(Fe),cM=n(Fe,"LI",{});var _Je=s(cM);c3e=n(_Je,"STRONG",{});var Daa=s(c3e);Tpr=r(Daa,"prophetnet"),Daa.forEach(t),Mpr=r(_Je," \u2014 "),fZ=n(_Je,"A",{href:!0});var Gaa=s(fZ);Epr=r(Gaa,"ProphetNetForConditionalGeneration"),Gaa.forEach(t),Cpr=r(_Je," (ProphetNet model)"),_Je.forEach(t),wpr=i(Fe),fM=n(Fe,"LI",{});var bJe=s(fM);f3e=n(bJe,"STRONG",{});var Oaa=s(f3e);Apr=r(Oaa,"t5"),Oaa.forEach(t),Lpr=r(bJe," \u2014 "),gZ=n(bJe,"A",{href:!0});var Vaa=s(gZ);ypr=r(Vaa,"T5ForConditionalGeneration"),Vaa.forEach(t),xpr=r(bJe," (T5 model)"),bJe.forEach(t),$pr=i(Fe),gM=n(Fe,"LI",{});var vJe=s(gM);g3e=n(vJe,"STRONG",{});var Xaa=s(g3e);kpr=r(Xaa,"xlm-prophetnet"),Xaa.forEach(t),Spr=r(vJe," \u2014 "),hZ=n(vJe,"A",{href:!0});var zaa=s(hZ);Rpr=r(zaa,"XLMProphetNetForConditionalGeneration"),zaa.forEach(t),Ppr=r(vJe," (XLM-ProphetNet model)"),vJe.forEach(t),Fe.forEach(t),Bpr=i(Na),hM=n(Na,"P",{});var FJe=s(hM);Ipr=r(FJe,"The model is set in evaluation mode by default using "),h3e=n(FJe,"CODE",{});var Qaa=s(h3e);Npr=r(Qaa,"model.eval()"),Qaa.forEach(t),qpr=r(FJe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u3e=n(FJe,"CODE",{});var Waa=s(u3e);jpr=r(Waa,"model.train()"),Waa.forEach(t),FJe.forEach(t),Dpr=i(Na),T(uM.$$.fragment,Na),Na.forEach(t),Zl.forEach(t),wio=i(c),nm=n(c,"H2",{class:!0});var Umo=s(nm);pM=n(Umo,"A",{id:!0,class:!0,href:!0});var Uaa=s(pM);p3e=n(Uaa,"SPAN",{});var Haa=s(p3e);T($S.$$.fragment,Haa),Haa.forEach(t),Uaa.forEach(t),Gpr=i(Umo),_3e=n(Umo,"SPAN",{});var Jaa=s(_3e);Opr=r(Jaa,"AutoModelForSequenceClassification"),Jaa.forEach(t),Umo.forEach(t),Aio=i(c),Qo=n(c,"DIV",{class:!0});var Kl=s(Qo);T(kS.$$.fragment,Kl),Vpr=i(Kl),sm=n(Kl,"P",{});var Ife=s(sm);Xpr=r(Ife,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),uZ=n(Ife,"A",{href:!0});var Yaa=s(uZ);zpr=r(Yaa,"from_pretrained()"),Yaa.forEach(t),Qpr=r(Ife," class method or the "),pZ=n(Ife,"A",{href:!0});var Zaa=s(pZ);Wpr=r(Zaa,"from_config()"),Zaa.forEach(t),Upr=r(Ife,` class
method.`),Ife.forEach(t),Hpr=i(Kl),SS=n(Kl,"P",{});var Hmo=s(SS);Jpr=r(Hmo,"This class cannot be instantiated directly using "),b3e=n(Hmo,"CODE",{});var Kaa=s(b3e);Ypr=r(Kaa,"__init__()"),Kaa.forEach(t),Zpr=r(Hmo," (throws an error)."),Hmo.forEach(t),Kpr=i(Kl),St=n(Kl,"DIV",{class:!0});var Cx=s(St);T(RS.$$.fragment,Cx),e_r=i(Cx),v3e=n(Cx,"P",{});var ena=s(v3e);o_r=r(ena,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),ena.forEach(t),r_r=i(Cx),lm=n(Cx,"P",{});var Nfe=s(lm);t_r=r(Nfe,`Note:
Loading a model from its configuration file does `),F3e=n(Nfe,"STRONG",{});var ona=s(F3e);a_r=r(ona,"not"),ona.forEach(t),n_r=r(Nfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),_Z=n(Nfe,"A",{href:!0});var rna=s(_Z);s_r=r(rna,"from_pretrained()"),rna.forEach(t),l_r=r(Nfe," to load the model weights."),Nfe.forEach(t),i_r=i(Cx),T(_M.$$.fragment,Cx),Cx.forEach(t),d_r=i(Kl),mo=n(Kl,"DIV",{class:!0});var qa=s(mo);T(PS.$$.fragment,qa),m_r=i(qa),T3e=n(qa,"P",{});var tna=s(T3e);c_r=r(tna,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),tna.forEach(t),f_r=i(qa),vn=n(qa,"P",{});var wx=s(vn);g_r=r(wx,"The model class to instantiate is selected based on the "),M3e=n(wx,"CODE",{});var ana=s(M3e);h_r=r(ana,"model_type"),ana.forEach(t),u_r=r(wx,` property of the config object (either
passed as an argument or loaded from `),E3e=n(wx,"CODE",{});var nna=s(E3e);p_r=r(nna,"pretrained_model_name_or_path"),nna.forEach(t),__r=r(wx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C3e=n(wx,"CODE",{});var sna=s(C3e);b_r=r(sna,"pretrained_model_name_or_path"),sna.forEach(t),v_r=r(wx,":"),wx.forEach(t),F_r=i(qa),I=n(qa,"UL",{});var D=s(I);bM=n(D,"LI",{});var TJe=s(bM);w3e=n(TJe,"STRONG",{});var lna=s(w3e);T_r=r(lna,"albert"),lna.forEach(t),M_r=r(TJe," \u2014 "),bZ=n(TJe,"A",{href:!0});var ina=s(bZ);E_r=r(ina,"AlbertForSequenceClassification"),ina.forEach(t),C_r=r(TJe," (ALBERT model)"),TJe.forEach(t),w_r=i(D),vM=n(D,"LI",{});var MJe=s(vM);A3e=n(MJe,"STRONG",{});var dna=s(A3e);A_r=r(dna,"bart"),dna.forEach(t),L_r=r(MJe," \u2014 "),vZ=n(MJe,"A",{href:!0});var mna=s(vZ);y_r=r(mna,"BartForSequenceClassification"),mna.forEach(t),x_r=r(MJe," (BART model)"),MJe.forEach(t),$_r=i(D),FM=n(D,"LI",{});var EJe=s(FM);L3e=n(EJe,"STRONG",{});var cna=s(L3e);k_r=r(cna,"bert"),cna.forEach(t),S_r=r(EJe," \u2014 "),FZ=n(EJe,"A",{href:!0});var fna=s(FZ);R_r=r(fna,"BertForSequenceClassification"),fna.forEach(t),P_r=r(EJe," (BERT model)"),EJe.forEach(t),B_r=i(D),TM=n(D,"LI",{});var CJe=s(TM);y3e=n(CJe,"STRONG",{});var gna=s(y3e);I_r=r(gna,"big_bird"),gna.forEach(t),N_r=r(CJe," \u2014 "),TZ=n(CJe,"A",{href:!0});var hna=s(TZ);q_r=r(hna,"BigBirdForSequenceClassification"),hna.forEach(t),j_r=r(CJe," (BigBird model)"),CJe.forEach(t),D_r=i(D),MM=n(D,"LI",{});var wJe=s(MM);x3e=n(wJe,"STRONG",{});var una=s(x3e);G_r=r(una,"bigbird_pegasus"),una.forEach(t),O_r=r(wJe," \u2014 "),MZ=n(wJe,"A",{href:!0});var pna=s(MZ);V_r=r(pna,"BigBirdPegasusForSequenceClassification"),pna.forEach(t),X_r=r(wJe," (BigBird-Pegasus model)"),wJe.forEach(t),z_r=i(D),EM=n(D,"LI",{});var AJe=s(EM);$3e=n(AJe,"STRONG",{});var _na=s($3e);Q_r=r(_na,"bloom"),_na.forEach(t),W_r=r(AJe," \u2014 "),EZ=n(AJe,"A",{href:!0});var bna=s(EZ);U_r=r(bna,"BloomForSequenceClassification"),bna.forEach(t),H_r=r(AJe," (BLOOM model)"),AJe.forEach(t),J_r=i(D),CM=n(D,"LI",{});var LJe=s(CM);k3e=n(LJe,"STRONG",{});var vna=s(k3e);Y_r=r(vna,"camembert"),vna.forEach(t),Z_r=r(LJe," \u2014 "),CZ=n(LJe,"A",{href:!0});var Fna=s(CZ);K_r=r(Fna,"CamembertForSequenceClassification"),Fna.forEach(t),e1r=r(LJe," (CamemBERT model)"),LJe.forEach(t),o1r=i(D),wM=n(D,"LI",{});var yJe=s(wM);S3e=n(yJe,"STRONG",{});var Tna=s(S3e);r1r=r(Tna,"canine"),Tna.forEach(t),t1r=r(yJe," \u2014 "),wZ=n(yJe,"A",{href:!0});var Mna=s(wZ);a1r=r(Mna,"CanineForSequenceClassification"),Mna.forEach(t),n1r=r(yJe," (CANINE model)"),yJe.forEach(t),s1r=i(D),AM=n(D,"LI",{});var xJe=s(AM);R3e=n(xJe,"STRONG",{});var Ena=s(R3e);l1r=r(Ena,"convbert"),Ena.forEach(t),i1r=r(xJe," \u2014 "),AZ=n(xJe,"A",{href:!0});var Cna=s(AZ);d1r=r(Cna,"ConvBertForSequenceClassification"),Cna.forEach(t),m1r=r(xJe," (ConvBERT model)"),xJe.forEach(t),c1r=i(D),LM=n(D,"LI",{});var $Je=s(LM);P3e=n($Je,"STRONG",{});var wna=s(P3e);f1r=r(wna,"ctrl"),wna.forEach(t),g1r=r($Je," \u2014 "),LZ=n($Je,"A",{href:!0});var Ana=s(LZ);h1r=r(Ana,"CTRLForSequenceClassification"),Ana.forEach(t),u1r=r($Je," (CTRL model)"),$Je.forEach(t),p1r=i(D),yM=n(D,"LI",{});var kJe=s(yM);B3e=n(kJe,"STRONG",{});var Lna=s(B3e);_1r=r(Lna,"data2vec-text"),Lna.forEach(t),b1r=r(kJe," \u2014 "),yZ=n(kJe,"A",{href:!0});var yna=s(yZ);v1r=r(yna,"Data2VecTextForSequenceClassification"),yna.forEach(t),F1r=r(kJe," (Data2VecText model)"),kJe.forEach(t),T1r=i(D),xM=n(D,"LI",{});var SJe=s(xM);I3e=n(SJe,"STRONG",{});var xna=s(I3e);M1r=r(xna,"deberta"),xna.forEach(t),E1r=r(SJe," \u2014 "),xZ=n(SJe,"A",{href:!0});var $na=s(xZ);C1r=r($na,"DebertaForSequenceClassification"),$na.forEach(t),w1r=r(SJe," (DeBERTa model)"),SJe.forEach(t),A1r=i(D),$M=n(D,"LI",{});var RJe=s($M);N3e=n(RJe,"STRONG",{});var kna=s(N3e);L1r=r(kna,"deberta-v2"),kna.forEach(t),y1r=r(RJe," \u2014 "),$Z=n(RJe,"A",{href:!0});var Sna=s($Z);x1r=r(Sna,"DebertaV2ForSequenceClassification"),Sna.forEach(t),$1r=r(RJe," (DeBERTa-v2 model)"),RJe.forEach(t),k1r=i(D),kM=n(D,"LI",{});var PJe=s(kM);q3e=n(PJe,"STRONG",{});var Rna=s(q3e);S1r=r(Rna,"distilbert"),Rna.forEach(t),R1r=r(PJe," \u2014 "),kZ=n(PJe,"A",{href:!0});var Pna=s(kZ);P1r=r(Pna,"DistilBertForSequenceClassification"),Pna.forEach(t),B1r=r(PJe," (DistilBERT model)"),PJe.forEach(t),I1r=i(D),SM=n(D,"LI",{});var BJe=s(SM);j3e=n(BJe,"STRONG",{});var Bna=s(j3e);N1r=r(Bna,"electra"),Bna.forEach(t),q1r=r(BJe," \u2014 "),SZ=n(BJe,"A",{href:!0});var Ina=s(SZ);j1r=r(Ina,"ElectraForSequenceClassification"),Ina.forEach(t),D1r=r(BJe," (ELECTRA model)"),BJe.forEach(t),G1r=i(D),RM=n(D,"LI",{});var IJe=s(RM);D3e=n(IJe,"STRONG",{});var Nna=s(D3e);O1r=r(Nna,"ernie"),Nna.forEach(t),V1r=r(IJe," \u2014 "),RZ=n(IJe,"A",{href:!0});var qna=s(RZ);X1r=r(qna,"ErnieForSequenceClassification"),qna.forEach(t),z1r=r(IJe," (ERNIE model)"),IJe.forEach(t),Q1r=i(D),PM=n(D,"LI",{});var NJe=s(PM);G3e=n(NJe,"STRONG",{});var jna=s(G3e);W1r=r(jna,"esm"),jna.forEach(t),U1r=r(NJe," \u2014 "),PZ=n(NJe,"A",{href:!0});var Dna=s(PZ);H1r=r(Dna,"EsmForSequenceClassification"),Dna.forEach(t),J1r=r(NJe," (ESM model)"),NJe.forEach(t),Y1r=i(D),BM=n(D,"LI",{});var qJe=s(BM);O3e=n(qJe,"STRONG",{});var Gna=s(O3e);Z1r=r(Gna,"flaubert"),Gna.forEach(t),K1r=r(qJe," \u2014 "),BZ=n(qJe,"A",{href:!0});var Ona=s(BZ);e2r=r(Ona,"FlaubertForSequenceClassification"),Ona.forEach(t),o2r=r(qJe," (FlauBERT model)"),qJe.forEach(t),r2r=i(D),IM=n(D,"LI",{});var jJe=s(IM);V3e=n(jJe,"STRONG",{});var Vna=s(V3e);t2r=r(Vna,"fnet"),Vna.forEach(t),a2r=r(jJe," \u2014 "),IZ=n(jJe,"A",{href:!0});var Xna=s(IZ);n2r=r(Xna,"FNetForSequenceClassification"),Xna.forEach(t),s2r=r(jJe," (FNet model)"),jJe.forEach(t),l2r=i(D),NM=n(D,"LI",{});var DJe=s(NM);X3e=n(DJe,"STRONG",{});var zna=s(X3e);i2r=r(zna,"funnel"),zna.forEach(t),d2r=r(DJe," \u2014 "),NZ=n(DJe,"A",{href:!0});var Qna=s(NZ);m2r=r(Qna,"FunnelForSequenceClassification"),Qna.forEach(t),c2r=r(DJe," (Funnel Transformer model)"),DJe.forEach(t),f2r=i(D),qM=n(D,"LI",{});var GJe=s(qM);z3e=n(GJe,"STRONG",{});var Wna=s(z3e);g2r=r(Wna,"gpt2"),Wna.forEach(t),h2r=r(GJe," \u2014 "),qZ=n(GJe,"A",{href:!0});var Una=s(qZ);u2r=r(Una,"GPT2ForSequenceClassification"),Una.forEach(t),p2r=r(GJe," (OpenAI GPT-2 model)"),GJe.forEach(t),_2r=i(D),jM=n(D,"LI",{});var OJe=s(jM);Q3e=n(OJe,"STRONG",{});var Hna=s(Q3e);b2r=r(Hna,"gpt_neo"),Hna.forEach(t),v2r=r(OJe," \u2014 "),jZ=n(OJe,"A",{href:!0});var Jna=s(jZ);F2r=r(Jna,"GPTNeoForSequenceClassification"),Jna.forEach(t),T2r=r(OJe," (GPT Neo model)"),OJe.forEach(t),M2r=i(D),DM=n(D,"LI",{});var VJe=s(DM);W3e=n(VJe,"STRONG",{});var Yna=s(W3e);E2r=r(Yna,"gptj"),Yna.forEach(t),C2r=r(VJe," \u2014 "),DZ=n(VJe,"A",{href:!0});var Zna=s(DZ);w2r=r(Zna,"GPTJForSequenceClassification"),Zna.forEach(t),A2r=r(VJe," (GPT-J model)"),VJe.forEach(t),L2r=i(D),GM=n(D,"LI",{});var XJe=s(GM);U3e=n(XJe,"STRONG",{});var Kna=s(U3e);y2r=r(Kna,"ibert"),Kna.forEach(t),x2r=r(XJe," \u2014 "),GZ=n(XJe,"A",{href:!0});var esa=s(GZ);$2r=r(esa,"IBertForSequenceClassification"),esa.forEach(t),k2r=r(XJe," (I-BERT model)"),XJe.forEach(t),S2r=i(D),OM=n(D,"LI",{});var zJe=s(OM);H3e=n(zJe,"STRONG",{});var osa=s(H3e);R2r=r(osa,"layoutlm"),osa.forEach(t),P2r=r(zJe," \u2014 "),OZ=n(zJe,"A",{href:!0});var rsa=s(OZ);B2r=r(rsa,"LayoutLMForSequenceClassification"),rsa.forEach(t),I2r=r(zJe," (LayoutLM model)"),zJe.forEach(t),N2r=i(D),VM=n(D,"LI",{});var QJe=s(VM);J3e=n(QJe,"STRONG",{});var tsa=s(J3e);q2r=r(tsa,"layoutlmv2"),tsa.forEach(t),j2r=r(QJe," \u2014 "),VZ=n(QJe,"A",{href:!0});var asa=s(VZ);D2r=r(asa,"LayoutLMv2ForSequenceClassification"),asa.forEach(t),G2r=r(QJe," (LayoutLMv2 model)"),QJe.forEach(t),O2r=i(D),XM=n(D,"LI",{});var WJe=s(XM);Y3e=n(WJe,"STRONG",{});var nsa=s(Y3e);V2r=r(nsa,"layoutlmv3"),nsa.forEach(t),X2r=r(WJe," \u2014 "),XZ=n(WJe,"A",{href:!0});var ssa=s(XZ);z2r=r(ssa,"LayoutLMv3ForSequenceClassification"),ssa.forEach(t),Q2r=r(WJe," (LayoutLMv3 model)"),WJe.forEach(t),W2r=i(D),zM=n(D,"LI",{});var UJe=s(zM);Z3e=n(UJe,"STRONG",{});var lsa=s(Z3e);U2r=r(lsa,"led"),lsa.forEach(t),H2r=r(UJe," \u2014 "),zZ=n(UJe,"A",{href:!0});var isa=s(zZ);J2r=r(isa,"LEDForSequenceClassification"),isa.forEach(t),Y2r=r(UJe," (LED model)"),UJe.forEach(t),Z2r=i(D),QM=n(D,"LI",{});var HJe=s(QM);K3e=n(HJe,"STRONG",{});var dsa=s(K3e);K2r=r(dsa,"lilt"),dsa.forEach(t),ebr=r(HJe," \u2014 "),QZ=n(HJe,"A",{href:!0});var msa=s(QZ);obr=r(msa,"LiltForSequenceClassification"),msa.forEach(t),rbr=r(HJe," (LiLT model)"),HJe.forEach(t),tbr=i(D),WM=n(D,"LI",{});var JJe=s(WM);e5e=n(JJe,"STRONG",{});var csa=s(e5e);abr=r(csa,"longformer"),csa.forEach(t),nbr=r(JJe," \u2014 "),WZ=n(JJe,"A",{href:!0});var fsa=s(WZ);sbr=r(fsa,"LongformerForSequenceClassification"),fsa.forEach(t),lbr=r(JJe," (Longformer model)"),JJe.forEach(t),ibr=i(D),UM=n(D,"LI",{});var YJe=s(UM);o5e=n(YJe,"STRONG",{});var gsa=s(o5e);dbr=r(gsa,"luke"),gsa.forEach(t),mbr=r(YJe," \u2014 "),UZ=n(YJe,"A",{href:!0});var hsa=s(UZ);cbr=r(hsa,"LukeForSequenceClassification"),hsa.forEach(t),fbr=r(YJe," (LUKE model)"),YJe.forEach(t),gbr=i(D),HM=n(D,"LI",{});var ZJe=s(HM);r5e=n(ZJe,"STRONG",{});var usa=s(r5e);hbr=r(usa,"markuplm"),usa.forEach(t),ubr=r(ZJe," \u2014 "),HZ=n(ZJe,"A",{href:!0});var psa=s(HZ);pbr=r(psa,"MarkupLMForSequenceClassification"),psa.forEach(t),_br=r(ZJe," (MarkupLM model)"),ZJe.forEach(t),bbr=i(D),JM=n(D,"LI",{});var KJe=s(JM);t5e=n(KJe,"STRONG",{});var _sa=s(t5e);vbr=r(_sa,"mbart"),_sa.forEach(t),Fbr=r(KJe," \u2014 "),JZ=n(KJe,"A",{href:!0});var bsa=s(JZ);Tbr=r(bsa,"MBartForSequenceClassification"),bsa.forEach(t),Mbr=r(KJe," (mBART model)"),KJe.forEach(t),Ebr=i(D),YM=n(D,"LI",{});var eYe=s(YM);a5e=n(eYe,"STRONG",{});var vsa=s(a5e);Cbr=r(vsa,"megatron-bert"),vsa.forEach(t),wbr=r(eYe," \u2014 "),YZ=n(eYe,"A",{href:!0});var Fsa=s(YZ);Abr=r(Fsa,"MegatronBertForSequenceClassification"),Fsa.forEach(t),Lbr=r(eYe," (Megatron-BERT model)"),eYe.forEach(t),ybr=i(D),ZM=n(D,"LI",{});var oYe=s(ZM);n5e=n(oYe,"STRONG",{});var Tsa=s(n5e);xbr=r(Tsa,"mobilebert"),Tsa.forEach(t),$br=r(oYe," \u2014 "),ZZ=n(oYe,"A",{href:!0});var Msa=s(ZZ);kbr=r(Msa,"MobileBertForSequenceClassification"),Msa.forEach(t),Sbr=r(oYe," (MobileBERT model)"),oYe.forEach(t),Rbr=i(D),KM=n(D,"LI",{});var rYe=s(KM);s5e=n(rYe,"STRONG",{});var Esa=s(s5e);Pbr=r(Esa,"mpnet"),Esa.forEach(t),Bbr=r(rYe," \u2014 "),KZ=n(rYe,"A",{href:!0});var Csa=s(KZ);Ibr=r(Csa,"MPNetForSequenceClassification"),Csa.forEach(t),Nbr=r(rYe," (MPNet model)"),rYe.forEach(t),qbr=i(D),eE=n(D,"LI",{});var tYe=s(eE);l5e=n(tYe,"STRONG",{});var wsa=s(l5e);jbr=r(wsa,"mvp"),wsa.forEach(t),Dbr=r(tYe," \u2014 "),eK=n(tYe,"A",{href:!0});var Asa=s(eK);Gbr=r(Asa,"MvpForSequenceClassification"),Asa.forEach(t),Obr=r(tYe," (MVP model)"),tYe.forEach(t),Vbr=i(D),oE=n(D,"LI",{});var aYe=s(oE);i5e=n(aYe,"STRONG",{});var Lsa=s(i5e);Xbr=r(Lsa,"nezha"),Lsa.forEach(t),zbr=r(aYe," \u2014 "),oK=n(aYe,"A",{href:!0});var ysa=s(oK);Qbr=r(ysa,"NezhaForSequenceClassification"),ysa.forEach(t),Wbr=r(aYe," (Nezha model)"),aYe.forEach(t),Ubr=i(D),rE=n(D,"LI",{});var nYe=s(rE);d5e=n(nYe,"STRONG",{});var xsa=s(d5e);Hbr=r(xsa,"nystromformer"),xsa.forEach(t),Jbr=r(nYe," \u2014 "),rK=n(nYe,"A",{href:!0});var $sa=s(rK);Ybr=r($sa,"NystromformerForSequenceClassification"),$sa.forEach(t),Zbr=r(nYe," (Nystr\xF6mformer model)"),nYe.forEach(t),Kbr=i(D),tE=n(D,"LI",{});var sYe=s(tE);m5e=n(sYe,"STRONG",{});var ksa=s(m5e);evr=r(ksa,"openai-gpt"),ksa.forEach(t),ovr=r(sYe," \u2014 "),tK=n(sYe,"A",{href:!0});var Ssa=s(tK);rvr=r(Ssa,"OpenAIGPTForSequenceClassification"),Ssa.forEach(t),tvr=r(sYe," (OpenAI GPT model)"),sYe.forEach(t),avr=i(D),aE=n(D,"LI",{});var lYe=s(aE);c5e=n(lYe,"STRONG",{});var Rsa=s(c5e);nvr=r(Rsa,"opt"),Rsa.forEach(t),svr=r(lYe," \u2014 "),aK=n(lYe,"A",{href:!0});var Psa=s(aK);lvr=r(Psa,"OPTForSequenceClassification"),Psa.forEach(t),ivr=r(lYe," (OPT model)"),lYe.forEach(t),dvr=i(D),nE=n(D,"LI",{});var iYe=s(nE);f5e=n(iYe,"STRONG",{});var Bsa=s(f5e);mvr=r(Bsa,"perceiver"),Bsa.forEach(t),cvr=r(iYe," \u2014 "),nK=n(iYe,"A",{href:!0});var Isa=s(nK);fvr=r(Isa,"PerceiverForSequenceClassification"),Isa.forEach(t),gvr=r(iYe," (Perceiver model)"),iYe.forEach(t),hvr=i(D),sE=n(D,"LI",{});var dYe=s(sE);g5e=n(dYe,"STRONG",{});var Nsa=s(g5e);uvr=r(Nsa,"plbart"),Nsa.forEach(t),pvr=r(dYe," \u2014 "),sK=n(dYe,"A",{href:!0});var qsa=s(sK);_vr=r(qsa,"PLBartForSequenceClassification"),qsa.forEach(t),bvr=r(dYe," (PLBart model)"),dYe.forEach(t),vvr=i(D),lE=n(D,"LI",{});var mYe=s(lE);h5e=n(mYe,"STRONG",{});var jsa=s(h5e);Fvr=r(jsa,"qdqbert"),jsa.forEach(t),Tvr=r(mYe," \u2014 "),lK=n(mYe,"A",{href:!0});var Dsa=s(lK);Mvr=r(Dsa,"QDQBertForSequenceClassification"),Dsa.forEach(t),Evr=r(mYe," (QDQBert model)"),mYe.forEach(t),Cvr=i(D),iE=n(D,"LI",{});var cYe=s(iE);u5e=n(cYe,"STRONG",{});var Gsa=s(u5e);wvr=r(Gsa,"reformer"),Gsa.forEach(t),Avr=r(cYe," \u2014 "),iK=n(cYe,"A",{href:!0});var Osa=s(iK);Lvr=r(Osa,"ReformerForSequenceClassification"),Osa.forEach(t),yvr=r(cYe," (Reformer model)"),cYe.forEach(t),xvr=i(D),dE=n(D,"LI",{});var fYe=s(dE);p5e=n(fYe,"STRONG",{});var Vsa=s(p5e);$vr=r(Vsa,"rembert"),Vsa.forEach(t),kvr=r(fYe," \u2014 "),dK=n(fYe,"A",{href:!0});var Xsa=s(dK);Svr=r(Xsa,"RemBertForSequenceClassification"),Xsa.forEach(t),Rvr=r(fYe," (RemBERT model)"),fYe.forEach(t),Pvr=i(D),mE=n(D,"LI",{});var gYe=s(mE);_5e=n(gYe,"STRONG",{});var zsa=s(_5e);Bvr=r(zsa,"roberta"),zsa.forEach(t),Ivr=r(gYe," \u2014 "),mK=n(gYe,"A",{href:!0});var Qsa=s(mK);Nvr=r(Qsa,"RobertaForSequenceClassification"),Qsa.forEach(t),qvr=r(gYe," (RoBERTa model)"),gYe.forEach(t),jvr=i(D),cE=n(D,"LI",{});var hYe=s(cE);b5e=n(hYe,"STRONG",{});var Wsa=s(b5e);Dvr=r(Wsa,"roc_bert"),Wsa.forEach(t),Gvr=r(hYe," \u2014 "),cK=n(hYe,"A",{href:!0});var Usa=s(cK);Ovr=r(Usa,"RoCBertForSequenceClassification"),Usa.forEach(t),Vvr=r(hYe," (RoCBert model)"),hYe.forEach(t),Xvr=i(D),fE=n(D,"LI",{});var uYe=s(fE);v5e=n(uYe,"STRONG",{});var Hsa=s(v5e);zvr=r(Hsa,"roformer"),Hsa.forEach(t),Qvr=r(uYe," \u2014 "),fK=n(uYe,"A",{href:!0});var Jsa=s(fK);Wvr=r(Jsa,"RoFormerForSequenceClassification"),Jsa.forEach(t),Uvr=r(uYe," (RoFormer model)"),uYe.forEach(t),Hvr=i(D),gE=n(D,"LI",{});var pYe=s(gE);F5e=n(pYe,"STRONG",{});var Ysa=s(F5e);Jvr=r(Ysa,"squeezebert"),Ysa.forEach(t),Yvr=r(pYe," \u2014 "),gK=n(pYe,"A",{href:!0});var Zsa=s(gK);Zvr=r(Zsa,"SqueezeBertForSequenceClassification"),Zsa.forEach(t),Kvr=r(pYe," (SqueezeBERT model)"),pYe.forEach(t),eFr=i(D),hE=n(D,"LI",{});var _Ye=s(hE);T5e=n(_Ye,"STRONG",{});var Ksa=s(T5e);oFr=r(Ksa,"tapas"),Ksa.forEach(t),rFr=r(_Ye," \u2014 "),hK=n(_Ye,"A",{href:!0});var ela=s(hK);tFr=r(ela,"TapasForSequenceClassification"),ela.forEach(t),aFr=r(_Ye," (TAPAS model)"),_Ye.forEach(t),nFr=i(D),uE=n(D,"LI",{});var bYe=s(uE);M5e=n(bYe,"STRONG",{});var ola=s(M5e);sFr=r(ola,"transfo-xl"),ola.forEach(t),lFr=r(bYe," \u2014 "),uK=n(bYe,"A",{href:!0});var rla=s(uK);iFr=r(rla,"TransfoXLForSequenceClassification"),rla.forEach(t),dFr=r(bYe," (Transformer-XL model)"),bYe.forEach(t),mFr=i(D),pE=n(D,"LI",{});var vYe=s(pE);E5e=n(vYe,"STRONG",{});var tla=s(E5e);cFr=r(tla,"xlm"),tla.forEach(t),fFr=r(vYe," \u2014 "),pK=n(vYe,"A",{href:!0});var ala=s(pK);gFr=r(ala,"XLMForSequenceClassification"),ala.forEach(t),hFr=r(vYe," (XLM model)"),vYe.forEach(t),uFr=i(D),_E=n(D,"LI",{});var FYe=s(_E);C5e=n(FYe,"STRONG",{});var nla=s(C5e);pFr=r(nla,"xlm-roberta"),nla.forEach(t),_Fr=r(FYe," \u2014 "),_K=n(FYe,"A",{href:!0});var sla=s(_K);bFr=r(sla,"XLMRobertaForSequenceClassification"),sla.forEach(t),vFr=r(FYe," (XLM-RoBERTa model)"),FYe.forEach(t),FFr=i(D),bE=n(D,"LI",{});var TYe=s(bE);w5e=n(TYe,"STRONG",{});var lla=s(w5e);TFr=r(lla,"xlm-roberta-xl"),lla.forEach(t),MFr=r(TYe," \u2014 "),bK=n(TYe,"A",{href:!0});var ila=s(bK);EFr=r(ila,"XLMRobertaXLForSequenceClassification"),ila.forEach(t),CFr=r(TYe," (XLM-RoBERTa-XL model)"),TYe.forEach(t),wFr=i(D),vE=n(D,"LI",{});var MYe=s(vE);A5e=n(MYe,"STRONG",{});var dla=s(A5e);AFr=r(dla,"xlnet"),dla.forEach(t),LFr=r(MYe," \u2014 "),vK=n(MYe,"A",{href:!0});var mla=s(vK);yFr=r(mla,"XLNetForSequenceClassification"),mla.forEach(t),xFr=r(MYe," (XLNet model)"),MYe.forEach(t),$Fr=i(D),FE=n(D,"LI",{});var EYe=s(FE);L5e=n(EYe,"STRONG",{});var cla=s(L5e);kFr=r(cla,"yoso"),cla.forEach(t),SFr=r(EYe," \u2014 "),FK=n(EYe,"A",{href:!0});var fla=s(FK);RFr=r(fla,"YosoForSequenceClassification"),fla.forEach(t),PFr=r(EYe," (YOSO model)"),EYe.forEach(t),D.forEach(t),BFr=i(qa),TE=n(qa,"P",{});var CYe=s(TE);IFr=r(CYe,"The model is set in evaluation mode by default using "),y5e=n(CYe,"CODE",{});var gla=s(y5e);NFr=r(gla,"model.eval()"),gla.forEach(t),qFr=r(CYe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),x5e=n(CYe,"CODE",{});var hla=s(x5e);jFr=r(hla,"model.train()"),hla.forEach(t),CYe.forEach(t),DFr=i(qa),T(ME.$$.fragment,qa),qa.forEach(t),Kl.forEach(t),Lio=i(c),im=n(c,"H2",{class:!0});var Jmo=s(im);EE=n(Jmo,"A",{id:!0,class:!0,href:!0});var ula=s(EE);$5e=n(ula,"SPAN",{});var pla=s($5e);T(BS.$$.fragment,pla),pla.forEach(t),ula.forEach(t),GFr=i(Jmo),k5e=n(Jmo,"SPAN",{});var _la=s(k5e);OFr=r(_la,"AutoModelForMultipleChoice"),_la.forEach(t),Jmo.forEach(t),yio=i(c),Wo=n(c,"DIV",{class:!0});var ei=s(Wo);T(IS.$$.fragment,ei),VFr=i(ei),dm=n(ei,"P",{});var qfe=s(dm);XFr=r(qfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),TK=n(qfe,"A",{href:!0});var bla=s(TK);zFr=r(bla,"from_pretrained()"),bla.forEach(t),QFr=r(qfe," class method or the "),MK=n(qfe,"A",{href:!0});var vla=s(MK);WFr=r(vla,"from_config()"),vla.forEach(t),UFr=r(qfe,` class
method.`),qfe.forEach(t),HFr=i(ei),NS=n(ei,"P",{});var Ymo=s(NS);JFr=r(Ymo,"This class cannot be instantiated directly using "),S5e=n(Ymo,"CODE",{});var Fla=s(S5e);YFr=r(Fla,"__init__()"),Fla.forEach(t),ZFr=r(Ymo," (throws an error)."),Ymo.forEach(t),KFr=i(ei),Rt=n(ei,"DIV",{class:!0});var Ax=s(Rt);T(qS.$$.fragment,Ax),eTr=i(Ax),R5e=n(Ax,"P",{});var Tla=s(R5e);oTr=r(Tla,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Tla.forEach(t),rTr=i(Ax),mm=n(Ax,"P",{});var jfe=s(mm);tTr=r(jfe,`Note:
Loading a model from its configuration file does `),P5e=n(jfe,"STRONG",{});var Mla=s(P5e);aTr=r(Mla,"not"),Mla.forEach(t),nTr=r(jfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),EK=n(jfe,"A",{href:!0});var Ela=s(EK);sTr=r(Ela,"from_pretrained()"),Ela.forEach(t),lTr=r(jfe," to load the model weights."),jfe.forEach(t),iTr=i(Ax),T(CE.$$.fragment,Ax),Ax.forEach(t),dTr=i(ei),co=n(ei,"DIV",{class:!0});var ja=s(co);T(jS.$$.fragment,ja),mTr=i(ja),B5e=n(ja,"P",{});var Cla=s(B5e);cTr=r(Cla,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Cla.forEach(t),fTr=i(ja),Fn=n(ja,"P",{});var Lx=s(Fn);gTr=r(Lx,"The model class to instantiate is selected based on the "),I5e=n(Lx,"CODE",{});var wla=s(I5e);hTr=r(wla,"model_type"),wla.forEach(t),uTr=r(Lx,` property of the config object (either
passed as an argument or loaded from `),N5e=n(Lx,"CODE",{});var Ala=s(N5e);pTr=r(Ala,"pretrained_model_name_or_path"),Ala.forEach(t),_Tr=r(Lx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q5e=n(Lx,"CODE",{});var Lla=s(q5e);bTr=r(Lla,"pretrained_model_name_or_path"),Lla.forEach(t),vTr=r(Lx,":"),Lx.forEach(t),FTr=i(ja),K=n(ja,"UL",{});var ee=s(K);wE=n(ee,"LI",{});var wYe=s(wE);j5e=n(wYe,"STRONG",{});var yla=s(j5e);TTr=r(yla,"albert"),yla.forEach(t),MTr=r(wYe," \u2014 "),CK=n(wYe,"A",{href:!0});var xla=s(CK);ETr=r(xla,"AlbertForMultipleChoice"),xla.forEach(t),CTr=r(wYe," (ALBERT model)"),wYe.forEach(t),wTr=i(ee),AE=n(ee,"LI",{});var AYe=s(AE);D5e=n(AYe,"STRONG",{});var $la=s(D5e);ATr=r($la,"bert"),$la.forEach(t),LTr=r(AYe," \u2014 "),wK=n(AYe,"A",{href:!0});var kla=s(wK);yTr=r(kla,"BertForMultipleChoice"),kla.forEach(t),xTr=r(AYe," (BERT model)"),AYe.forEach(t),$Tr=i(ee),LE=n(ee,"LI",{});var LYe=s(LE);G5e=n(LYe,"STRONG",{});var Sla=s(G5e);kTr=r(Sla,"big_bird"),Sla.forEach(t),STr=r(LYe," \u2014 "),AK=n(LYe,"A",{href:!0});var Rla=s(AK);RTr=r(Rla,"BigBirdForMultipleChoice"),Rla.forEach(t),PTr=r(LYe," (BigBird model)"),LYe.forEach(t),BTr=i(ee),yE=n(ee,"LI",{});var yYe=s(yE);O5e=n(yYe,"STRONG",{});var Pla=s(O5e);ITr=r(Pla,"camembert"),Pla.forEach(t),NTr=r(yYe," \u2014 "),LK=n(yYe,"A",{href:!0});var Bla=s(LK);qTr=r(Bla,"CamembertForMultipleChoice"),Bla.forEach(t),jTr=r(yYe," (CamemBERT model)"),yYe.forEach(t),DTr=i(ee),xE=n(ee,"LI",{});var xYe=s(xE);V5e=n(xYe,"STRONG",{});var Ila=s(V5e);GTr=r(Ila,"canine"),Ila.forEach(t),OTr=r(xYe," \u2014 "),yK=n(xYe,"A",{href:!0});var Nla=s(yK);VTr=r(Nla,"CanineForMultipleChoice"),Nla.forEach(t),XTr=r(xYe," (CANINE model)"),xYe.forEach(t),zTr=i(ee),$E=n(ee,"LI",{});var $Ye=s($E);X5e=n($Ye,"STRONG",{});var qla=s(X5e);QTr=r(qla,"convbert"),qla.forEach(t),WTr=r($Ye," \u2014 "),xK=n($Ye,"A",{href:!0});var jla=s(xK);UTr=r(jla,"ConvBertForMultipleChoice"),jla.forEach(t),HTr=r($Ye," (ConvBERT model)"),$Ye.forEach(t),JTr=i(ee),kE=n(ee,"LI",{});var kYe=s(kE);z5e=n(kYe,"STRONG",{});var Dla=s(z5e);YTr=r(Dla,"data2vec-text"),Dla.forEach(t),ZTr=r(kYe," \u2014 "),$K=n(kYe,"A",{href:!0});var Gla=s($K);KTr=r(Gla,"Data2VecTextForMultipleChoice"),Gla.forEach(t),eMr=r(kYe," (Data2VecText model)"),kYe.forEach(t),oMr=i(ee),SE=n(ee,"LI",{});var SYe=s(SE);Q5e=n(SYe,"STRONG",{});var Ola=s(Q5e);rMr=r(Ola,"deberta-v2"),Ola.forEach(t),tMr=r(SYe," \u2014 "),kK=n(SYe,"A",{href:!0});var Vla=s(kK);aMr=r(Vla,"DebertaV2ForMultipleChoice"),Vla.forEach(t),nMr=r(SYe," (DeBERTa-v2 model)"),SYe.forEach(t),sMr=i(ee),RE=n(ee,"LI",{});var RYe=s(RE);W5e=n(RYe,"STRONG",{});var Xla=s(W5e);lMr=r(Xla,"distilbert"),Xla.forEach(t),iMr=r(RYe," \u2014 "),SK=n(RYe,"A",{href:!0});var zla=s(SK);dMr=r(zla,"DistilBertForMultipleChoice"),zla.forEach(t),mMr=r(RYe," (DistilBERT model)"),RYe.forEach(t),cMr=i(ee),PE=n(ee,"LI",{});var PYe=s(PE);U5e=n(PYe,"STRONG",{});var Qla=s(U5e);fMr=r(Qla,"electra"),Qla.forEach(t),gMr=r(PYe," \u2014 "),RK=n(PYe,"A",{href:!0});var Wla=s(RK);hMr=r(Wla,"ElectraForMultipleChoice"),Wla.forEach(t),uMr=r(PYe," (ELECTRA model)"),PYe.forEach(t),pMr=i(ee),BE=n(ee,"LI",{});var BYe=s(BE);H5e=n(BYe,"STRONG",{});var Ula=s(H5e);_Mr=r(Ula,"ernie"),Ula.forEach(t),bMr=r(BYe," \u2014 "),PK=n(BYe,"A",{href:!0});var Hla=s(PK);vMr=r(Hla,"ErnieForMultipleChoice"),Hla.forEach(t),FMr=r(BYe," (ERNIE model)"),BYe.forEach(t),TMr=i(ee),IE=n(ee,"LI",{});var IYe=s(IE);J5e=n(IYe,"STRONG",{});var Jla=s(J5e);MMr=r(Jla,"flaubert"),Jla.forEach(t),EMr=r(IYe," \u2014 "),BK=n(IYe,"A",{href:!0});var Yla=s(BK);CMr=r(Yla,"FlaubertForMultipleChoice"),Yla.forEach(t),wMr=r(IYe," (FlauBERT model)"),IYe.forEach(t),AMr=i(ee),NE=n(ee,"LI",{});var NYe=s(NE);Y5e=n(NYe,"STRONG",{});var Zla=s(Y5e);LMr=r(Zla,"fnet"),Zla.forEach(t),yMr=r(NYe," \u2014 "),IK=n(NYe,"A",{href:!0});var Kla=s(IK);xMr=r(Kla,"FNetForMultipleChoice"),Kla.forEach(t),$Mr=r(NYe," (FNet model)"),NYe.forEach(t),kMr=i(ee),qE=n(ee,"LI",{});var qYe=s(qE);Z5e=n(qYe,"STRONG",{});var eia=s(Z5e);SMr=r(eia,"funnel"),eia.forEach(t),RMr=r(qYe," \u2014 "),NK=n(qYe,"A",{href:!0});var oia=s(NK);PMr=r(oia,"FunnelForMultipleChoice"),oia.forEach(t),BMr=r(qYe," (Funnel Transformer model)"),qYe.forEach(t),IMr=i(ee),jE=n(ee,"LI",{});var jYe=s(jE);K5e=n(jYe,"STRONG",{});var ria=s(K5e);NMr=r(ria,"ibert"),ria.forEach(t),qMr=r(jYe," \u2014 "),qK=n(jYe,"A",{href:!0});var tia=s(qK);jMr=r(tia,"IBertForMultipleChoice"),tia.forEach(t),DMr=r(jYe," (I-BERT model)"),jYe.forEach(t),GMr=i(ee),DE=n(ee,"LI",{});var DYe=s(DE);e0e=n(DYe,"STRONG",{});var aia=s(e0e);OMr=r(aia,"longformer"),aia.forEach(t),VMr=r(DYe," \u2014 "),jK=n(DYe,"A",{href:!0});var nia=s(jK);XMr=r(nia,"LongformerForMultipleChoice"),nia.forEach(t),zMr=r(DYe," (Longformer model)"),DYe.forEach(t),QMr=i(ee),GE=n(ee,"LI",{});var GYe=s(GE);o0e=n(GYe,"STRONG",{});var sia=s(o0e);WMr=r(sia,"luke"),sia.forEach(t),UMr=r(GYe," \u2014 "),DK=n(GYe,"A",{href:!0});var lia=s(DK);HMr=r(lia,"LukeForMultipleChoice"),lia.forEach(t),JMr=r(GYe," (LUKE model)"),GYe.forEach(t),YMr=i(ee),OE=n(ee,"LI",{});var OYe=s(OE);r0e=n(OYe,"STRONG",{});var iia=s(r0e);ZMr=r(iia,"megatron-bert"),iia.forEach(t),KMr=r(OYe," \u2014 "),GK=n(OYe,"A",{href:!0});var dia=s(GK);eEr=r(dia,"MegatronBertForMultipleChoice"),dia.forEach(t),oEr=r(OYe," (Megatron-BERT model)"),OYe.forEach(t),rEr=i(ee),VE=n(ee,"LI",{});var VYe=s(VE);t0e=n(VYe,"STRONG",{});var mia=s(t0e);tEr=r(mia,"mobilebert"),mia.forEach(t),aEr=r(VYe," \u2014 "),OK=n(VYe,"A",{href:!0});var cia=s(OK);nEr=r(cia,"MobileBertForMultipleChoice"),cia.forEach(t),sEr=r(VYe," (MobileBERT model)"),VYe.forEach(t),lEr=i(ee),XE=n(ee,"LI",{});var XYe=s(XE);a0e=n(XYe,"STRONG",{});var fia=s(a0e);iEr=r(fia,"mpnet"),fia.forEach(t),dEr=r(XYe," \u2014 "),VK=n(XYe,"A",{href:!0});var gia=s(VK);mEr=r(gia,"MPNetForMultipleChoice"),gia.forEach(t),cEr=r(XYe," (MPNet model)"),XYe.forEach(t),fEr=i(ee),zE=n(ee,"LI",{});var zYe=s(zE);n0e=n(zYe,"STRONG",{});var hia=s(n0e);gEr=r(hia,"nezha"),hia.forEach(t),hEr=r(zYe," \u2014 "),XK=n(zYe,"A",{href:!0});var uia=s(XK);uEr=r(uia,"NezhaForMultipleChoice"),uia.forEach(t),pEr=r(zYe," (Nezha model)"),zYe.forEach(t),_Er=i(ee),QE=n(ee,"LI",{});var QYe=s(QE);s0e=n(QYe,"STRONG",{});var pia=s(s0e);bEr=r(pia,"nystromformer"),pia.forEach(t),vEr=r(QYe," \u2014 "),zK=n(QYe,"A",{href:!0});var _ia=s(zK);FEr=r(_ia,"NystromformerForMultipleChoice"),_ia.forEach(t),TEr=r(QYe," (Nystr\xF6mformer model)"),QYe.forEach(t),MEr=i(ee),WE=n(ee,"LI",{});var WYe=s(WE);l0e=n(WYe,"STRONG",{});var bia=s(l0e);EEr=r(bia,"qdqbert"),bia.forEach(t),CEr=r(WYe," \u2014 "),QK=n(WYe,"A",{href:!0});var via=s(QK);wEr=r(via,"QDQBertForMultipleChoice"),via.forEach(t),AEr=r(WYe," (QDQBert model)"),WYe.forEach(t),LEr=i(ee),UE=n(ee,"LI",{});var UYe=s(UE);i0e=n(UYe,"STRONG",{});var Fia=s(i0e);yEr=r(Fia,"rembert"),Fia.forEach(t),xEr=r(UYe," \u2014 "),WK=n(UYe,"A",{href:!0});var Tia=s(WK);$Er=r(Tia,"RemBertForMultipleChoice"),Tia.forEach(t),kEr=r(UYe," (RemBERT model)"),UYe.forEach(t),SEr=i(ee),HE=n(ee,"LI",{});var HYe=s(HE);d0e=n(HYe,"STRONG",{});var Mia=s(d0e);REr=r(Mia,"roberta"),Mia.forEach(t),PEr=r(HYe," \u2014 "),UK=n(HYe,"A",{href:!0});var Eia=s(UK);BEr=r(Eia,"RobertaForMultipleChoice"),Eia.forEach(t),IEr=r(HYe," (RoBERTa model)"),HYe.forEach(t),NEr=i(ee),JE=n(ee,"LI",{});var JYe=s(JE);m0e=n(JYe,"STRONG",{});var Cia=s(m0e);qEr=r(Cia,"roc_bert"),Cia.forEach(t),jEr=r(JYe," \u2014 "),HK=n(JYe,"A",{href:!0});var wia=s(HK);DEr=r(wia,"RoCBertForMultipleChoice"),wia.forEach(t),GEr=r(JYe," (RoCBert model)"),JYe.forEach(t),OEr=i(ee),YE=n(ee,"LI",{});var YYe=s(YE);c0e=n(YYe,"STRONG",{});var Aia=s(c0e);VEr=r(Aia,"roformer"),Aia.forEach(t),XEr=r(YYe," \u2014 "),JK=n(YYe,"A",{href:!0});var Lia=s(JK);zEr=r(Lia,"RoFormerForMultipleChoice"),Lia.forEach(t),QEr=r(YYe," (RoFormer model)"),YYe.forEach(t),WEr=i(ee),ZE=n(ee,"LI",{});var ZYe=s(ZE);f0e=n(ZYe,"STRONG",{});var yia=s(f0e);UEr=r(yia,"squeezebert"),yia.forEach(t),HEr=r(ZYe," \u2014 "),YK=n(ZYe,"A",{href:!0});var xia=s(YK);JEr=r(xia,"SqueezeBertForMultipleChoice"),xia.forEach(t),YEr=r(ZYe," (SqueezeBERT model)"),ZYe.forEach(t),ZEr=i(ee),KE=n(ee,"LI",{});var KYe=s(KE);g0e=n(KYe,"STRONG",{});var $ia=s(g0e);KEr=r($ia,"xlm"),$ia.forEach(t),e4r=r(KYe," \u2014 "),ZK=n(KYe,"A",{href:!0});var kia=s(ZK);o4r=r(kia,"XLMForMultipleChoice"),kia.forEach(t),r4r=r(KYe," (XLM model)"),KYe.forEach(t),t4r=i(ee),e4=n(ee,"LI",{});var eZe=s(e4);h0e=n(eZe,"STRONG",{});var Sia=s(h0e);a4r=r(Sia,"xlm-roberta"),Sia.forEach(t),n4r=r(eZe," \u2014 "),KK=n(eZe,"A",{href:!0});var Ria=s(KK);s4r=r(Ria,"XLMRobertaForMultipleChoice"),Ria.forEach(t),l4r=r(eZe," (XLM-RoBERTa model)"),eZe.forEach(t),i4r=i(ee),o4=n(ee,"LI",{});var oZe=s(o4);u0e=n(oZe,"STRONG",{});var Pia=s(u0e);d4r=r(Pia,"xlm-roberta-xl"),Pia.forEach(t),m4r=r(oZe," \u2014 "),eee=n(oZe,"A",{href:!0});var Bia=s(eee);c4r=r(Bia,"XLMRobertaXLForMultipleChoice"),Bia.forEach(t),f4r=r(oZe," (XLM-RoBERTa-XL model)"),oZe.forEach(t),g4r=i(ee),r4=n(ee,"LI",{});var rZe=s(r4);p0e=n(rZe,"STRONG",{});var Iia=s(p0e);h4r=r(Iia,"xlnet"),Iia.forEach(t),u4r=r(rZe," \u2014 "),oee=n(rZe,"A",{href:!0});var Nia=s(oee);p4r=r(Nia,"XLNetForMultipleChoice"),Nia.forEach(t),_4r=r(rZe," (XLNet model)"),rZe.forEach(t),b4r=i(ee),t4=n(ee,"LI",{});var tZe=s(t4);_0e=n(tZe,"STRONG",{});var qia=s(_0e);v4r=r(qia,"yoso"),qia.forEach(t),F4r=r(tZe," \u2014 "),ree=n(tZe,"A",{href:!0});var jia=s(ree);T4r=r(jia,"YosoForMultipleChoice"),jia.forEach(t),M4r=r(tZe," (YOSO model)"),tZe.forEach(t),ee.forEach(t),E4r=i(ja),a4=n(ja,"P",{});var aZe=s(a4);C4r=r(aZe,"The model is set in evaluation mode by default using "),b0e=n(aZe,"CODE",{});var Dia=s(b0e);w4r=r(Dia,"model.eval()"),Dia.forEach(t),A4r=r(aZe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),v0e=n(aZe,"CODE",{});var Gia=s(v0e);L4r=r(Gia,"model.train()"),Gia.forEach(t),aZe.forEach(t),y4r=i(ja),T(n4.$$.fragment,ja),ja.forEach(t),ei.forEach(t),xio=i(c),cm=n(c,"H2",{class:!0});var Zmo=s(cm);s4=n(Zmo,"A",{id:!0,class:!0,href:!0});var Oia=s(s4);F0e=n(Oia,"SPAN",{});var Via=s(F0e);T(DS.$$.fragment,Via),Via.forEach(t),Oia.forEach(t),x4r=i(Zmo),T0e=n(Zmo,"SPAN",{});var Xia=s(T0e);$4r=r(Xia,"AutoModelForNextSentencePrediction"),Xia.forEach(t),Zmo.forEach(t),$io=i(c),Uo=n(c,"DIV",{class:!0});var oi=s(Uo);T(GS.$$.fragment,oi),k4r=i(oi),fm=n(oi,"P",{});var Dfe=s(fm);S4r=r(Dfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),tee=n(Dfe,"A",{href:!0});var zia=s(tee);R4r=r(zia,"from_pretrained()"),zia.forEach(t),P4r=r(Dfe," class method or the "),aee=n(Dfe,"A",{href:!0});var Qia=s(aee);B4r=r(Qia,"from_config()"),Qia.forEach(t),I4r=r(Dfe,` class
method.`),Dfe.forEach(t),N4r=i(oi),OS=n(oi,"P",{});var Kmo=s(OS);q4r=r(Kmo,"This class cannot be instantiated directly using "),M0e=n(Kmo,"CODE",{});var Wia=s(M0e);j4r=r(Wia,"__init__()"),Wia.forEach(t),D4r=r(Kmo," (throws an error)."),Kmo.forEach(t),G4r=i(oi),Pt=n(oi,"DIV",{class:!0});var yx=s(Pt);T(VS.$$.fragment,yx),O4r=i(yx),E0e=n(yx,"P",{});var Uia=s(E0e);V4r=r(Uia,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Uia.forEach(t),X4r=i(yx),gm=n(yx,"P",{});var Gfe=s(gm);z4r=r(Gfe,`Note:
Loading a model from its configuration file does `),C0e=n(Gfe,"STRONG",{});var Hia=s(C0e);Q4r=r(Hia,"not"),Hia.forEach(t),W4r=r(Gfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),nee=n(Gfe,"A",{href:!0});var Jia=s(nee);U4r=r(Jia,"from_pretrained()"),Jia.forEach(t),H4r=r(Gfe," to load the model weights."),Gfe.forEach(t),J4r=i(yx),T(l4.$$.fragment,yx),yx.forEach(t),Y4r=i(oi),fo=n(oi,"DIV",{class:!0});var Da=s(fo);T(XS.$$.fragment,Da),Z4r=i(Da),w0e=n(Da,"P",{});var Yia=s(w0e);K4r=r(Yia,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Yia.forEach(t),eCr=i(Da),Tn=n(Da,"P",{});var xx=s(Tn);oCr=r(xx,"The model class to instantiate is selected based on the "),A0e=n(xx,"CODE",{});var Zia=s(A0e);rCr=r(Zia,"model_type"),Zia.forEach(t),tCr=r(xx,` property of the config object (either
passed as an argument or loaded from `),L0e=n(xx,"CODE",{});var Kia=s(L0e);aCr=r(Kia,"pretrained_model_name_or_path"),Kia.forEach(t),nCr=r(xx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y0e=n(xx,"CODE",{});var eda=s(y0e);sCr=r(eda,"pretrained_model_name_or_path"),eda.forEach(t),lCr=r(xx,":"),xx.forEach(t),iCr=i(Da),Ye=n(Da,"UL",{});var vt=s(Ye);i4=n(vt,"LI",{});var nZe=s(i4);x0e=n(nZe,"STRONG",{});var oda=s(x0e);dCr=r(oda,"bert"),oda.forEach(t),mCr=r(nZe," \u2014 "),see=n(nZe,"A",{href:!0});var rda=s(see);cCr=r(rda,"BertForNextSentencePrediction"),rda.forEach(t),fCr=r(nZe," (BERT model)"),nZe.forEach(t),gCr=i(vt),d4=n(vt,"LI",{});var sZe=s(d4);$0e=n(sZe,"STRONG",{});var tda=s($0e);hCr=r(tda,"ernie"),tda.forEach(t),uCr=r(sZe," \u2014 "),lee=n(sZe,"A",{href:!0});var ada=s(lee);pCr=r(ada,"ErnieForNextSentencePrediction"),ada.forEach(t),_Cr=r(sZe," (ERNIE model)"),sZe.forEach(t),bCr=i(vt),m4=n(vt,"LI",{});var lZe=s(m4);k0e=n(lZe,"STRONG",{});var nda=s(k0e);vCr=r(nda,"fnet"),nda.forEach(t),FCr=r(lZe," \u2014 "),iee=n(lZe,"A",{href:!0});var sda=s(iee);TCr=r(sda,"FNetForNextSentencePrediction"),sda.forEach(t),MCr=r(lZe," (FNet model)"),lZe.forEach(t),ECr=i(vt),c4=n(vt,"LI",{});var iZe=s(c4);S0e=n(iZe,"STRONG",{});var lda=s(S0e);CCr=r(lda,"megatron-bert"),lda.forEach(t),wCr=r(iZe," \u2014 "),dee=n(iZe,"A",{href:!0});var ida=s(dee);ACr=r(ida,"MegatronBertForNextSentencePrediction"),ida.forEach(t),LCr=r(iZe," (Megatron-BERT model)"),iZe.forEach(t),yCr=i(vt),f4=n(vt,"LI",{});var dZe=s(f4);R0e=n(dZe,"STRONG",{});var dda=s(R0e);xCr=r(dda,"mobilebert"),dda.forEach(t),$Cr=r(dZe," \u2014 "),mee=n(dZe,"A",{href:!0});var mda=s(mee);kCr=r(mda,"MobileBertForNextSentencePrediction"),mda.forEach(t),SCr=r(dZe," (MobileBERT model)"),dZe.forEach(t),RCr=i(vt),g4=n(vt,"LI",{});var mZe=s(g4);P0e=n(mZe,"STRONG",{});var cda=s(P0e);PCr=r(cda,"nezha"),cda.forEach(t),BCr=r(mZe," \u2014 "),cee=n(mZe,"A",{href:!0});var fda=s(cee);ICr=r(fda,"NezhaForNextSentencePrediction"),fda.forEach(t),NCr=r(mZe," (Nezha model)"),mZe.forEach(t),qCr=i(vt),h4=n(vt,"LI",{});var cZe=s(h4);B0e=n(cZe,"STRONG",{});var gda=s(B0e);jCr=r(gda,"qdqbert"),gda.forEach(t),DCr=r(cZe," \u2014 "),fee=n(cZe,"A",{href:!0});var hda=s(fee);GCr=r(hda,"QDQBertForNextSentencePrediction"),hda.forEach(t),OCr=r(cZe," (QDQBert model)"),cZe.forEach(t),vt.forEach(t),VCr=i(Da),u4=n(Da,"P",{});var fZe=s(u4);XCr=r(fZe,"The model is set in evaluation mode by default using "),I0e=n(fZe,"CODE",{});var uda=s(I0e);zCr=r(uda,"model.eval()"),uda.forEach(t),QCr=r(fZe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),N0e=n(fZe,"CODE",{});var pda=s(N0e);WCr=r(pda,"model.train()"),pda.forEach(t),fZe.forEach(t),UCr=i(Da),T(p4.$$.fragment,Da),Da.forEach(t),oi.forEach(t),kio=i(c),hm=n(c,"H2",{class:!0});var eco=s(hm);_4=n(eco,"A",{id:!0,class:!0,href:!0});var _da=s(_4);q0e=n(_da,"SPAN",{});var bda=s(q0e);T(zS.$$.fragment,bda),bda.forEach(t),_da.forEach(t),HCr=i(eco),j0e=n(eco,"SPAN",{});var vda=s(j0e);JCr=r(vda,"AutoModelForTokenClassification"),vda.forEach(t),eco.forEach(t),Sio=i(c),Ho=n(c,"DIV",{class:!0});var ri=s(Ho);T(QS.$$.fragment,ri),YCr=i(ri),um=n(ri,"P",{});var Ofe=s(um);ZCr=r(Ofe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),gee=n(Ofe,"A",{href:!0});var Fda=s(gee);KCr=r(Fda,"from_pretrained()"),Fda.forEach(t),e3r=r(Ofe," class method or the "),hee=n(Ofe,"A",{href:!0});var Tda=s(hee);o3r=r(Tda,"from_config()"),Tda.forEach(t),r3r=r(Ofe,` class
method.`),Ofe.forEach(t),t3r=i(ri),WS=n(ri,"P",{});var oco=s(WS);a3r=r(oco,"This class cannot be instantiated directly using "),D0e=n(oco,"CODE",{});var Mda=s(D0e);n3r=r(Mda,"__init__()"),Mda.forEach(t),s3r=r(oco," (throws an error)."),oco.forEach(t),l3r=i(ri),Bt=n(ri,"DIV",{class:!0});var $x=s(Bt);T(US.$$.fragment,$x),i3r=i($x),G0e=n($x,"P",{});var Eda=s(G0e);d3r=r(Eda,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Eda.forEach(t),m3r=i($x),pm=n($x,"P",{});var Vfe=s(pm);c3r=r(Vfe,`Note:
Loading a model from its configuration file does `),O0e=n(Vfe,"STRONG",{});var Cda=s(O0e);f3r=r(Cda,"not"),Cda.forEach(t),g3r=r(Vfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),uee=n(Vfe,"A",{href:!0});var wda=s(uee);h3r=r(wda,"from_pretrained()"),wda.forEach(t),u3r=r(Vfe," to load the model weights."),Vfe.forEach(t),p3r=i($x),T(b4.$$.fragment,$x),$x.forEach(t),_3r=i(ri),go=n(ri,"DIV",{class:!0});var Ga=s(go);T(HS.$$.fragment,Ga),b3r=i(Ga),V0e=n(Ga,"P",{});var Ada=s(V0e);v3r=r(Ada,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Ada.forEach(t),F3r=i(Ga),Mn=n(Ga,"P",{});var kx=s(Mn);T3r=r(kx,"The model class to instantiate is selected based on the "),X0e=n(kx,"CODE",{});var Lda=s(X0e);M3r=r(Lda,"model_type"),Lda.forEach(t),E3r=r(kx,` property of the config object (either
passed as an argument or loaded from `),z0e=n(kx,"CODE",{});var yda=s(z0e);C3r=r(yda,"pretrained_model_name_or_path"),yda.forEach(t),w3r=r(kx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q0e=n(kx,"CODE",{});var xda=s(Q0e);A3r=r(xda,"pretrained_model_name_or_path"),xda.forEach(t),L3r=r(kx,":"),kx.forEach(t),y3r=i(Ga),U=n(Ga,"UL",{});var J=s(U);v4=n(J,"LI",{});var gZe=s(v4);W0e=n(gZe,"STRONG",{});var $da=s(W0e);x3r=r($da,"albert"),$da.forEach(t),$3r=r(gZe," \u2014 "),pee=n(gZe,"A",{href:!0});var kda=s(pee);k3r=r(kda,"AlbertForTokenClassification"),kda.forEach(t),S3r=r(gZe," (ALBERT model)"),gZe.forEach(t),R3r=i(J),F4=n(J,"LI",{});var hZe=s(F4);U0e=n(hZe,"STRONG",{});var Sda=s(U0e);P3r=r(Sda,"bert"),Sda.forEach(t),B3r=r(hZe," \u2014 "),_ee=n(hZe,"A",{href:!0});var Rda=s(_ee);I3r=r(Rda,"BertForTokenClassification"),Rda.forEach(t),N3r=r(hZe," (BERT model)"),hZe.forEach(t),q3r=i(J),T4=n(J,"LI",{});var uZe=s(T4);H0e=n(uZe,"STRONG",{});var Pda=s(H0e);j3r=r(Pda,"big_bird"),Pda.forEach(t),D3r=r(uZe," \u2014 "),bee=n(uZe,"A",{href:!0});var Bda=s(bee);G3r=r(Bda,"BigBirdForTokenClassification"),Bda.forEach(t),O3r=r(uZe," (BigBird model)"),uZe.forEach(t),V3r=i(J),M4=n(J,"LI",{});var pZe=s(M4);J0e=n(pZe,"STRONG",{});var Ida=s(J0e);X3r=r(Ida,"bloom"),Ida.forEach(t),z3r=r(pZe," \u2014 "),vee=n(pZe,"A",{href:!0});var Nda=s(vee);Q3r=r(Nda,"BloomForTokenClassification"),Nda.forEach(t),W3r=r(pZe," (BLOOM model)"),pZe.forEach(t),U3r=i(J),E4=n(J,"LI",{});var _Ze=s(E4);Y0e=n(_Ze,"STRONG",{});var qda=s(Y0e);H3r=r(qda,"camembert"),qda.forEach(t),J3r=r(_Ze," \u2014 "),Fee=n(_Ze,"A",{href:!0});var jda=s(Fee);Y3r=r(jda,"CamembertForTokenClassification"),jda.forEach(t),Z3r=r(_Ze," (CamemBERT model)"),_Ze.forEach(t),K3r=i(J),C4=n(J,"LI",{});var bZe=s(C4);Z0e=n(bZe,"STRONG",{});var Dda=s(Z0e);e5r=r(Dda,"canine"),Dda.forEach(t),o5r=r(bZe," \u2014 "),Tee=n(bZe,"A",{href:!0});var Gda=s(Tee);r5r=r(Gda,"CanineForTokenClassification"),Gda.forEach(t),t5r=r(bZe," (CANINE model)"),bZe.forEach(t),a5r=i(J),w4=n(J,"LI",{});var vZe=s(w4);K0e=n(vZe,"STRONG",{});var Oda=s(K0e);n5r=r(Oda,"convbert"),Oda.forEach(t),s5r=r(vZe," \u2014 "),Mee=n(vZe,"A",{href:!0});var Vda=s(Mee);l5r=r(Vda,"ConvBertForTokenClassification"),Vda.forEach(t),i5r=r(vZe," (ConvBERT model)"),vZe.forEach(t),d5r=i(J),A4=n(J,"LI",{});var FZe=s(A4);ewe=n(FZe,"STRONG",{});var Xda=s(ewe);m5r=r(Xda,"data2vec-text"),Xda.forEach(t),c5r=r(FZe," \u2014 "),Eee=n(FZe,"A",{href:!0});var zda=s(Eee);f5r=r(zda,"Data2VecTextForTokenClassification"),zda.forEach(t),g5r=r(FZe," (Data2VecText model)"),FZe.forEach(t),h5r=i(J),L4=n(J,"LI",{});var TZe=s(L4);owe=n(TZe,"STRONG",{});var Qda=s(owe);u5r=r(Qda,"deberta"),Qda.forEach(t),p5r=r(TZe," \u2014 "),Cee=n(TZe,"A",{href:!0});var Wda=s(Cee);_5r=r(Wda,"DebertaForTokenClassification"),Wda.forEach(t),b5r=r(TZe," (DeBERTa model)"),TZe.forEach(t),v5r=i(J),y4=n(J,"LI",{});var MZe=s(y4);rwe=n(MZe,"STRONG",{});var Uda=s(rwe);F5r=r(Uda,"deberta-v2"),Uda.forEach(t),T5r=r(MZe," \u2014 "),wee=n(MZe,"A",{href:!0});var Hda=s(wee);M5r=r(Hda,"DebertaV2ForTokenClassification"),Hda.forEach(t),E5r=r(MZe," (DeBERTa-v2 model)"),MZe.forEach(t),C5r=i(J),x4=n(J,"LI",{});var EZe=s(x4);twe=n(EZe,"STRONG",{});var Jda=s(twe);w5r=r(Jda,"distilbert"),Jda.forEach(t),A5r=r(EZe," \u2014 "),Aee=n(EZe,"A",{href:!0});var Yda=s(Aee);L5r=r(Yda,"DistilBertForTokenClassification"),Yda.forEach(t),y5r=r(EZe," (DistilBERT model)"),EZe.forEach(t),x5r=i(J),$4=n(J,"LI",{});var CZe=s($4);awe=n(CZe,"STRONG",{});var Zda=s(awe);$5r=r(Zda,"electra"),Zda.forEach(t),k5r=r(CZe," \u2014 "),Lee=n(CZe,"A",{href:!0});var Kda=s(Lee);S5r=r(Kda,"ElectraForTokenClassification"),Kda.forEach(t),R5r=r(CZe," (ELECTRA model)"),CZe.forEach(t),P5r=i(J),k4=n(J,"LI",{});var wZe=s(k4);nwe=n(wZe,"STRONG",{});var ema=s(nwe);B5r=r(ema,"ernie"),ema.forEach(t),I5r=r(wZe," \u2014 "),yee=n(wZe,"A",{href:!0});var oma=s(yee);N5r=r(oma,"ErnieForTokenClassification"),oma.forEach(t),q5r=r(wZe," (ERNIE model)"),wZe.forEach(t),j5r=i(J),S4=n(J,"LI",{});var AZe=s(S4);swe=n(AZe,"STRONG",{});var rma=s(swe);D5r=r(rma,"esm"),rma.forEach(t),G5r=r(AZe," \u2014 "),xee=n(AZe,"A",{href:!0});var tma=s(xee);O5r=r(tma,"EsmForTokenClassification"),tma.forEach(t),V5r=r(AZe," (ESM model)"),AZe.forEach(t),X5r=i(J),R4=n(J,"LI",{});var LZe=s(R4);lwe=n(LZe,"STRONG",{});var ama=s(lwe);z5r=r(ama,"flaubert"),ama.forEach(t),Q5r=r(LZe," \u2014 "),$ee=n(LZe,"A",{href:!0});var nma=s($ee);W5r=r(nma,"FlaubertForTokenClassification"),nma.forEach(t),U5r=r(LZe," (FlauBERT model)"),LZe.forEach(t),H5r=i(J),P4=n(J,"LI",{});var yZe=s(P4);iwe=n(yZe,"STRONG",{});var sma=s(iwe);J5r=r(sma,"fnet"),sma.forEach(t),Y5r=r(yZe," \u2014 "),kee=n(yZe,"A",{href:!0});var lma=s(kee);Z5r=r(lma,"FNetForTokenClassification"),lma.forEach(t),K5r=r(yZe," (FNet model)"),yZe.forEach(t),e0r=i(J),B4=n(J,"LI",{});var xZe=s(B4);dwe=n(xZe,"STRONG",{});var ima=s(dwe);o0r=r(ima,"funnel"),ima.forEach(t),r0r=r(xZe," \u2014 "),See=n(xZe,"A",{href:!0});var dma=s(See);t0r=r(dma,"FunnelForTokenClassification"),dma.forEach(t),a0r=r(xZe," (Funnel Transformer model)"),xZe.forEach(t),n0r=i(J),I4=n(J,"LI",{});var $Ze=s(I4);mwe=n($Ze,"STRONG",{});var mma=s(mwe);s0r=r(mma,"gpt2"),mma.forEach(t),l0r=r($Ze," \u2014 "),Ree=n($Ze,"A",{href:!0});var cma=s(Ree);i0r=r(cma,"GPT2ForTokenClassification"),cma.forEach(t),d0r=r($Ze," (OpenAI GPT-2 model)"),$Ze.forEach(t),m0r=i(J),N4=n(J,"LI",{});var kZe=s(N4);cwe=n(kZe,"STRONG",{});var fma=s(cwe);c0r=r(fma,"ibert"),fma.forEach(t),f0r=r(kZe," \u2014 "),Pee=n(kZe,"A",{href:!0});var gma=s(Pee);g0r=r(gma,"IBertForTokenClassification"),gma.forEach(t),h0r=r(kZe," (I-BERT model)"),kZe.forEach(t),u0r=i(J),q4=n(J,"LI",{});var SZe=s(q4);fwe=n(SZe,"STRONG",{});var hma=s(fwe);p0r=r(hma,"layoutlm"),hma.forEach(t),_0r=r(SZe," \u2014 "),Bee=n(SZe,"A",{href:!0});var uma=s(Bee);b0r=r(uma,"LayoutLMForTokenClassification"),uma.forEach(t),v0r=r(SZe," (LayoutLM model)"),SZe.forEach(t),F0r=i(J),j4=n(J,"LI",{});var RZe=s(j4);gwe=n(RZe,"STRONG",{});var pma=s(gwe);T0r=r(pma,"layoutlmv2"),pma.forEach(t),M0r=r(RZe," \u2014 "),Iee=n(RZe,"A",{href:!0});var _ma=s(Iee);E0r=r(_ma,"LayoutLMv2ForTokenClassification"),_ma.forEach(t),C0r=r(RZe," (LayoutLMv2 model)"),RZe.forEach(t),w0r=i(J),D4=n(J,"LI",{});var PZe=s(D4);hwe=n(PZe,"STRONG",{});var bma=s(hwe);A0r=r(bma,"layoutlmv3"),bma.forEach(t),L0r=r(PZe," \u2014 "),Nee=n(PZe,"A",{href:!0});var vma=s(Nee);y0r=r(vma,"LayoutLMv3ForTokenClassification"),vma.forEach(t),x0r=r(PZe," (LayoutLMv3 model)"),PZe.forEach(t),$0r=i(J),G4=n(J,"LI",{});var BZe=s(G4);uwe=n(BZe,"STRONG",{});var Fma=s(uwe);k0r=r(Fma,"lilt"),Fma.forEach(t),S0r=r(BZe," \u2014 "),qee=n(BZe,"A",{href:!0});var Tma=s(qee);R0r=r(Tma,"LiltForTokenClassification"),Tma.forEach(t),P0r=r(BZe," (LiLT model)"),BZe.forEach(t),B0r=i(J),O4=n(J,"LI",{});var IZe=s(O4);pwe=n(IZe,"STRONG",{});var Mma=s(pwe);I0r=r(Mma,"longformer"),Mma.forEach(t),N0r=r(IZe," \u2014 "),jee=n(IZe,"A",{href:!0});var Ema=s(jee);q0r=r(Ema,"LongformerForTokenClassification"),Ema.forEach(t),j0r=r(IZe," (Longformer model)"),IZe.forEach(t),D0r=i(J),V4=n(J,"LI",{});var NZe=s(V4);_we=n(NZe,"STRONG",{});var Cma=s(_we);G0r=r(Cma,"luke"),Cma.forEach(t),O0r=r(NZe," \u2014 "),Dee=n(NZe,"A",{href:!0});var wma=s(Dee);V0r=r(wma,"LukeForTokenClassification"),wma.forEach(t),X0r=r(NZe," (LUKE model)"),NZe.forEach(t),z0r=i(J),X4=n(J,"LI",{});var qZe=s(X4);bwe=n(qZe,"STRONG",{});var Ama=s(bwe);Q0r=r(Ama,"markuplm"),Ama.forEach(t),W0r=r(qZe," \u2014 "),Gee=n(qZe,"A",{href:!0});var Lma=s(Gee);U0r=r(Lma,"MarkupLMForTokenClassification"),Lma.forEach(t),H0r=r(qZe," (MarkupLM model)"),qZe.forEach(t),J0r=i(J),z4=n(J,"LI",{});var jZe=s(z4);vwe=n(jZe,"STRONG",{});var yma=s(vwe);Y0r=r(yma,"megatron-bert"),yma.forEach(t),Z0r=r(jZe," \u2014 "),Oee=n(jZe,"A",{href:!0});var xma=s(Oee);K0r=r(xma,"MegatronBertForTokenClassification"),xma.forEach(t),ewr=r(jZe," (Megatron-BERT model)"),jZe.forEach(t),owr=i(J),Q4=n(J,"LI",{});var DZe=s(Q4);Fwe=n(DZe,"STRONG",{});var $ma=s(Fwe);rwr=r($ma,"mobilebert"),$ma.forEach(t),twr=r(DZe," \u2014 "),Vee=n(DZe,"A",{href:!0});var kma=s(Vee);awr=r(kma,"MobileBertForTokenClassification"),kma.forEach(t),nwr=r(DZe," (MobileBERT model)"),DZe.forEach(t),swr=i(J),W4=n(J,"LI",{});var GZe=s(W4);Twe=n(GZe,"STRONG",{});var Sma=s(Twe);lwr=r(Sma,"mpnet"),Sma.forEach(t),iwr=r(GZe," \u2014 "),Xee=n(GZe,"A",{href:!0});var Rma=s(Xee);dwr=r(Rma,"MPNetForTokenClassification"),Rma.forEach(t),mwr=r(GZe," (MPNet model)"),GZe.forEach(t),cwr=i(J),U4=n(J,"LI",{});var OZe=s(U4);Mwe=n(OZe,"STRONG",{});var Pma=s(Mwe);fwr=r(Pma,"nezha"),Pma.forEach(t),gwr=r(OZe," \u2014 "),zee=n(OZe,"A",{href:!0});var Bma=s(zee);hwr=r(Bma,"NezhaForTokenClassification"),Bma.forEach(t),uwr=r(OZe," (Nezha model)"),OZe.forEach(t),pwr=i(J),H4=n(J,"LI",{});var VZe=s(H4);Ewe=n(VZe,"STRONG",{});var Ima=s(Ewe);_wr=r(Ima,"nystromformer"),Ima.forEach(t),bwr=r(VZe," \u2014 "),Qee=n(VZe,"A",{href:!0});var Nma=s(Qee);vwr=r(Nma,"NystromformerForTokenClassification"),Nma.forEach(t),Fwr=r(VZe," (Nystr\xF6mformer model)"),VZe.forEach(t),Twr=i(J),J4=n(J,"LI",{});var XZe=s(J4);Cwe=n(XZe,"STRONG",{});var qma=s(Cwe);Mwr=r(qma,"qdqbert"),qma.forEach(t),Ewr=r(XZe," \u2014 "),Wee=n(XZe,"A",{href:!0});var jma=s(Wee);Cwr=r(jma,"QDQBertForTokenClassification"),jma.forEach(t),wwr=r(XZe," (QDQBert model)"),XZe.forEach(t),Awr=i(J),Y4=n(J,"LI",{});var zZe=s(Y4);wwe=n(zZe,"STRONG",{});var Dma=s(wwe);Lwr=r(Dma,"rembert"),Dma.forEach(t),ywr=r(zZe," \u2014 "),Uee=n(zZe,"A",{href:!0});var Gma=s(Uee);xwr=r(Gma,"RemBertForTokenClassification"),Gma.forEach(t),$wr=r(zZe," (RemBERT model)"),zZe.forEach(t),kwr=i(J),Z4=n(J,"LI",{});var QZe=s(Z4);Awe=n(QZe,"STRONG",{});var Oma=s(Awe);Swr=r(Oma,"roberta"),Oma.forEach(t),Rwr=r(QZe," \u2014 "),Hee=n(QZe,"A",{href:!0});var Vma=s(Hee);Pwr=r(Vma,"RobertaForTokenClassification"),Vma.forEach(t),Bwr=r(QZe," (RoBERTa model)"),QZe.forEach(t),Iwr=i(J),K4=n(J,"LI",{});var WZe=s(K4);Lwe=n(WZe,"STRONG",{});var Xma=s(Lwe);Nwr=r(Xma,"roc_bert"),Xma.forEach(t),qwr=r(WZe," \u2014 "),Jee=n(WZe,"A",{href:!0});var zma=s(Jee);jwr=r(zma,"RoCBertForTokenClassification"),zma.forEach(t),Dwr=r(WZe," (RoCBert model)"),WZe.forEach(t),Gwr=i(J),eC=n(J,"LI",{});var UZe=s(eC);ywe=n(UZe,"STRONG",{});var Qma=s(ywe);Owr=r(Qma,"roformer"),Qma.forEach(t),Vwr=r(UZe," \u2014 "),Yee=n(UZe,"A",{href:!0});var Wma=s(Yee);Xwr=r(Wma,"RoFormerForTokenClassification"),Wma.forEach(t),zwr=r(UZe," (RoFormer model)"),UZe.forEach(t),Qwr=i(J),oC=n(J,"LI",{});var HZe=s(oC);xwe=n(HZe,"STRONG",{});var Uma=s(xwe);Wwr=r(Uma,"squeezebert"),Uma.forEach(t),Uwr=r(HZe," \u2014 "),Zee=n(HZe,"A",{href:!0});var Hma=s(Zee);Hwr=r(Hma,"SqueezeBertForTokenClassification"),Hma.forEach(t),Jwr=r(HZe," (SqueezeBERT model)"),HZe.forEach(t),Ywr=i(J),rC=n(J,"LI",{});var JZe=s(rC);$we=n(JZe,"STRONG",{});var Jma=s($we);Zwr=r(Jma,"xlm"),Jma.forEach(t),Kwr=r(JZe," \u2014 "),Kee=n(JZe,"A",{href:!0});var Yma=s(Kee);eAr=r(Yma,"XLMForTokenClassification"),Yma.forEach(t),oAr=r(JZe," (XLM model)"),JZe.forEach(t),rAr=i(J),tC=n(J,"LI",{});var YZe=s(tC);kwe=n(YZe,"STRONG",{});var Zma=s(kwe);tAr=r(Zma,"xlm-roberta"),Zma.forEach(t),aAr=r(YZe," \u2014 "),eoe=n(YZe,"A",{href:!0});var Kma=s(eoe);nAr=r(Kma,"XLMRobertaForTokenClassification"),Kma.forEach(t),sAr=r(YZe," (XLM-RoBERTa model)"),YZe.forEach(t),lAr=i(J),aC=n(J,"LI",{});var ZZe=s(aC);Swe=n(ZZe,"STRONG",{});var eca=s(Swe);iAr=r(eca,"xlm-roberta-xl"),eca.forEach(t),dAr=r(ZZe," \u2014 "),ooe=n(ZZe,"A",{href:!0});var oca=s(ooe);mAr=r(oca,"XLMRobertaXLForTokenClassification"),oca.forEach(t),cAr=r(ZZe," (XLM-RoBERTa-XL model)"),ZZe.forEach(t),fAr=i(J),nC=n(J,"LI",{});var KZe=s(nC);Rwe=n(KZe,"STRONG",{});var rca=s(Rwe);gAr=r(rca,"xlnet"),rca.forEach(t),hAr=r(KZe," \u2014 "),roe=n(KZe,"A",{href:!0});var tca=s(roe);uAr=r(tca,"XLNetForTokenClassification"),tca.forEach(t),pAr=r(KZe," (XLNet model)"),KZe.forEach(t),_Ar=i(J),sC=n(J,"LI",{});var eKe=s(sC);Pwe=n(eKe,"STRONG",{});var aca=s(Pwe);bAr=r(aca,"yoso"),aca.forEach(t),vAr=r(eKe," \u2014 "),toe=n(eKe,"A",{href:!0});var nca=s(toe);FAr=r(nca,"YosoForTokenClassification"),nca.forEach(t),TAr=r(eKe," (YOSO model)"),eKe.forEach(t),J.forEach(t),MAr=i(Ga),lC=n(Ga,"P",{});var oKe=s(lC);EAr=r(oKe,"The model is set in evaluation mode by default using "),Bwe=n(oKe,"CODE",{});var sca=s(Bwe);CAr=r(sca,"model.eval()"),sca.forEach(t),wAr=r(oKe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Iwe=n(oKe,"CODE",{});var lca=s(Iwe);AAr=r(lca,"model.train()"),lca.forEach(t),oKe.forEach(t),LAr=i(Ga),T(iC.$$.fragment,Ga),Ga.forEach(t),ri.forEach(t),Rio=i(c),_m=n(c,"H2",{class:!0});var rco=s(_m);dC=n(rco,"A",{id:!0,class:!0,href:!0});var ica=s(dC);Nwe=n(ica,"SPAN",{});var dca=s(Nwe);T(JS.$$.fragment,dca),dca.forEach(t),ica.forEach(t),yAr=i(rco),qwe=n(rco,"SPAN",{});var mca=s(qwe);xAr=r(mca,"AutoModelForQuestionAnswering"),mca.forEach(t),rco.forEach(t),Pio=i(c),Jo=n(c,"DIV",{class:!0});var ti=s(Jo);T(YS.$$.fragment,ti),$Ar=i(ti),bm=n(ti,"P",{});var Xfe=s(bm);kAr=r(Xfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),aoe=n(Xfe,"A",{href:!0});var cca=s(aoe);SAr=r(cca,"from_pretrained()"),cca.forEach(t),RAr=r(Xfe," class method or the "),noe=n(Xfe,"A",{href:!0});var fca=s(noe);PAr=r(fca,"from_config()"),fca.forEach(t),BAr=r(Xfe,` class
method.`),Xfe.forEach(t),IAr=i(ti),ZS=n(ti,"P",{});var tco=s(ZS);NAr=r(tco,"This class cannot be instantiated directly using "),jwe=n(tco,"CODE",{});var gca=s(jwe);qAr=r(gca,"__init__()"),gca.forEach(t),jAr=r(tco," (throws an error)."),tco.forEach(t),DAr=i(ti),It=n(ti,"DIV",{class:!0});var Sx=s(It);T(KS.$$.fragment,Sx),GAr=i(Sx),Dwe=n(Sx,"P",{});var hca=s(Dwe);OAr=r(hca,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),hca.forEach(t),VAr=i(Sx),vm=n(Sx,"P",{});var zfe=s(vm);XAr=r(zfe,`Note:
Loading a model from its configuration file does `),Gwe=n(zfe,"STRONG",{});var uca=s(Gwe);zAr=r(uca,"not"),uca.forEach(t),QAr=r(zfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),soe=n(zfe,"A",{href:!0});var pca=s(soe);WAr=r(pca,"from_pretrained()"),pca.forEach(t),UAr=r(zfe," to load the model weights."),zfe.forEach(t),HAr=i(Sx),T(mC.$$.fragment,Sx),Sx.forEach(t),JAr=i(ti),ho=n(ti,"DIV",{class:!0});var Oa=s(ho);T(eR.$$.fragment,Oa),YAr=i(Oa),Owe=n(Oa,"P",{});var _ca=s(Owe);ZAr=r(_ca,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),_ca.forEach(t),KAr=i(Oa),En=n(Oa,"P",{});var Rx=s(En);e6r=r(Rx,"The model class to instantiate is selected based on the "),Vwe=n(Rx,"CODE",{});var bca=s(Vwe);o6r=r(bca,"model_type"),bca.forEach(t),r6r=r(Rx,` property of the config object (either
passed as an argument or loaded from `),Xwe=n(Rx,"CODE",{});var vca=s(Xwe);t6r=r(vca,"pretrained_model_name_or_path"),vca.forEach(t),a6r=r(Rx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zwe=n(Rx,"CODE",{});var Fca=s(zwe);n6r=r(Fca,"pretrained_model_name_or_path"),Fca.forEach(t),s6r=r(Rx,":"),Rx.forEach(t),l6r=i(Oa),O=n(Oa,"UL",{});var X=s(O);cC=n(X,"LI",{});var rKe=s(cC);Qwe=n(rKe,"STRONG",{});var Tca=s(Qwe);i6r=r(Tca,"albert"),Tca.forEach(t),d6r=r(rKe," \u2014 "),loe=n(rKe,"A",{href:!0});var Mca=s(loe);m6r=r(Mca,"AlbertForQuestionAnswering"),Mca.forEach(t),c6r=r(rKe," (ALBERT model)"),rKe.forEach(t),f6r=i(X),fC=n(X,"LI",{});var tKe=s(fC);Wwe=n(tKe,"STRONG",{});var Eca=s(Wwe);g6r=r(Eca,"bart"),Eca.forEach(t),h6r=r(tKe," \u2014 "),ioe=n(tKe,"A",{href:!0});var Cca=s(ioe);u6r=r(Cca,"BartForQuestionAnswering"),Cca.forEach(t),p6r=r(tKe," (BART model)"),tKe.forEach(t),_6r=i(X),gC=n(X,"LI",{});var aKe=s(gC);Uwe=n(aKe,"STRONG",{});var wca=s(Uwe);b6r=r(wca,"bert"),wca.forEach(t),v6r=r(aKe," \u2014 "),doe=n(aKe,"A",{href:!0});var Aca=s(doe);F6r=r(Aca,"BertForQuestionAnswering"),Aca.forEach(t),T6r=r(aKe," (BERT model)"),aKe.forEach(t),M6r=i(X),hC=n(X,"LI",{});var nKe=s(hC);Hwe=n(nKe,"STRONG",{});var Lca=s(Hwe);E6r=r(Lca,"big_bird"),Lca.forEach(t),C6r=r(nKe," \u2014 "),moe=n(nKe,"A",{href:!0});var yca=s(moe);w6r=r(yca,"BigBirdForQuestionAnswering"),yca.forEach(t),A6r=r(nKe," (BigBird model)"),nKe.forEach(t),L6r=i(X),uC=n(X,"LI",{});var sKe=s(uC);Jwe=n(sKe,"STRONG",{});var xca=s(Jwe);y6r=r(xca,"bigbird_pegasus"),xca.forEach(t),x6r=r(sKe," \u2014 "),coe=n(sKe,"A",{href:!0});var $ca=s(coe);$6r=r($ca,"BigBirdPegasusForQuestionAnswering"),$ca.forEach(t),k6r=r(sKe," (BigBird-Pegasus model)"),sKe.forEach(t),S6r=i(X),pC=n(X,"LI",{});var lKe=s(pC);Ywe=n(lKe,"STRONG",{});var kca=s(Ywe);R6r=r(kca,"bloom"),kca.forEach(t),P6r=r(lKe," \u2014 "),foe=n(lKe,"A",{href:!0});var Sca=s(foe);B6r=r(Sca,"BloomForQuestionAnswering"),Sca.forEach(t),I6r=r(lKe," (BLOOM model)"),lKe.forEach(t),N6r=i(X),_C=n(X,"LI",{});var iKe=s(_C);Zwe=n(iKe,"STRONG",{});var Rca=s(Zwe);q6r=r(Rca,"camembert"),Rca.forEach(t),j6r=r(iKe," \u2014 "),goe=n(iKe,"A",{href:!0});var Pca=s(goe);D6r=r(Pca,"CamembertForQuestionAnswering"),Pca.forEach(t),G6r=r(iKe," (CamemBERT model)"),iKe.forEach(t),O6r=i(X),bC=n(X,"LI",{});var dKe=s(bC);Kwe=n(dKe,"STRONG",{});var Bca=s(Kwe);V6r=r(Bca,"canine"),Bca.forEach(t),X6r=r(dKe," \u2014 "),hoe=n(dKe,"A",{href:!0});var Ica=s(hoe);z6r=r(Ica,"CanineForQuestionAnswering"),Ica.forEach(t),Q6r=r(dKe," (CANINE model)"),dKe.forEach(t),W6r=i(X),vC=n(X,"LI",{});var mKe=s(vC);eAe=n(mKe,"STRONG",{});var Nca=s(eAe);U6r=r(Nca,"convbert"),Nca.forEach(t),H6r=r(mKe," \u2014 "),uoe=n(mKe,"A",{href:!0});var qca=s(uoe);J6r=r(qca,"ConvBertForQuestionAnswering"),qca.forEach(t),Y6r=r(mKe," (ConvBERT model)"),mKe.forEach(t),Z6r=i(X),FC=n(X,"LI",{});var cKe=s(FC);oAe=n(cKe,"STRONG",{});var jca=s(oAe);K6r=r(jca,"data2vec-text"),jca.forEach(t),e7r=r(cKe," \u2014 "),poe=n(cKe,"A",{href:!0});var Dca=s(poe);o7r=r(Dca,"Data2VecTextForQuestionAnswering"),Dca.forEach(t),r7r=r(cKe," (Data2VecText model)"),cKe.forEach(t),t7r=i(X),TC=n(X,"LI",{});var fKe=s(TC);rAe=n(fKe,"STRONG",{});var Gca=s(rAe);a7r=r(Gca,"deberta"),Gca.forEach(t),n7r=r(fKe," \u2014 "),_oe=n(fKe,"A",{href:!0});var Oca=s(_oe);s7r=r(Oca,"DebertaForQuestionAnswering"),Oca.forEach(t),l7r=r(fKe," (DeBERTa model)"),fKe.forEach(t),i7r=i(X),MC=n(X,"LI",{});var gKe=s(MC);tAe=n(gKe,"STRONG",{});var Vca=s(tAe);d7r=r(Vca,"deberta-v2"),Vca.forEach(t),m7r=r(gKe," \u2014 "),boe=n(gKe,"A",{href:!0});var Xca=s(boe);c7r=r(Xca,"DebertaV2ForQuestionAnswering"),Xca.forEach(t),f7r=r(gKe," (DeBERTa-v2 model)"),gKe.forEach(t),g7r=i(X),EC=n(X,"LI",{});var hKe=s(EC);aAe=n(hKe,"STRONG",{});var zca=s(aAe);h7r=r(zca,"distilbert"),zca.forEach(t),u7r=r(hKe," \u2014 "),voe=n(hKe,"A",{href:!0});var Qca=s(voe);p7r=r(Qca,"DistilBertForQuestionAnswering"),Qca.forEach(t),_7r=r(hKe," (DistilBERT model)"),hKe.forEach(t),b7r=i(X),CC=n(X,"LI",{});var uKe=s(CC);nAe=n(uKe,"STRONG",{});var Wca=s(nAe);v7r=r(Wca,"electra"),Wca.forEach(t),F7r=r(uKe," \u2014 "),Foe=n(uKe,"A",{href:!0});var Uca=s(Foe);T7r=r(Uca,"ElectraForQuestionAnswering"),Uca.forEach(t),M7r=r(uKe," (ELECTRA model)"),uKe.forEach(t),E7r=i(X),wC=n(X,"LI",{});var pKe=s(wC);sAe=n(pKe,"STRONG",{});var Hca=s(sAe);C7r=r(Hca,"ernie"),Hca.forEach(t),w7r=r(pKe," \u2014 "),Toe=n(pKe,"A",{href:!0});var Jca=s(Toe);A7r=r(Jca,"ErnieForQuestionAnswering"),Jca.forEach(t),L7r=r(pKe," (ERNIE model)"),pKe.forEach(t),y7r=i(X),AC=n(X,"LI",{});var _Ke=s(AC);lAe=n(_Ke,"STRONG",{});var Yca=s(lAe);x7r=r(Yca,"flaubert"),Yca.forEach(t),$7r=r(_Ke," \u2014 "),Moe=n(_Ke,"A",{href:!0});var Zca=s(Moe);k7r=r(Zca,"FlaubertForQuestionAnsweringSimple"),Zca.forEach(t),S7r=r(_Ke," (FlauBERT model)"),_Ke.forEach(t),R7r=i(X),LC=n(X,"LI",{});var bKe=s(LC);iAe=n(bKe,"STRONG",{});var Kca=s(iAe);P7r=r(Kca,"fnet"),Kca.forEach(t),B7r=r(bKe," \u2014 "),Eoe=n(bKe,"A",{href:!0});var efa=s(Eoe);I7r=r(efa,"FNetForQuestionAnswering"),efa.forEach(t),N7r=r(bKe," (FNet model)"),bKe.forEach(t),q7r=i(X),yC=n(X,"LI",{});var vKe=s(yC);dAe=n(vKe,"STRONG",{});var ofa=s(dAe);j7r=r(ofa,"funnel"),ofa.forEach(t),D7r=r(vKe," \u2014 "),Coe=n(vKe,"A",{href:!0});var rfa=s(Coe);G7r=r(rfa,"FunnelForQuestionAnswering"),rfa.forEach(t),O7r=r(vKe," (Funnel Transformer model)"),vKe.forEach(t),V7r=i(X),xC=n(X,"LI",{});var FKe=s(xC);mAe=n(FKe,"STRONG",{});var tfa=s(mAe);X7r=r(tfa,"gptj"),tfa.forEach(t),z7r=r(FKe," \u2014 "),woe=n(FKe,"A",{href:!0});var afa=s(woe);Q7r=r(afa,"GPTJForQuestionAnswering"),afa.forEach(t),W7r=r(FKe," (GPT-J model)"),FKe.forEach(t),U7r=i(X),$C=n(X,"LI",{});var TKe=s($C);cAe=n(TKe,"STRONG",{});var nfa=s(cAe);H7r=r(nfa,"ibert"),nfa.forEach(t),J7r=r(TKe," \u2014 "),Aoe=n(TKe,"A",{href:!0});var sfa=s(Aoe);Y7r=r(sfa,"IBertForQuestionAnswering"),sfa.forEach(t),Z7r=r(TKe," (I-BERT model)"),TKe.forEach(t),K7r=i(X),kC=n(X,"LI",{});var MKe=s(kC);fAe=n(MKe,"STRONG",{});var lfa=s(fAe);e8r=r(lfa,"layoutlmv2"),lfa.forEach(t),o8r=r(MKe," \u2014 "),Loe=n(MKe,"A",{href:!0});var ifa=s(Loe);r8r=r(ifa,"LayoutLMv2ForQuestionAnswering"),ifa.forEach(t),t8r=r(MKe," (LayoutLMv2 model)"),MKe.forEach(t),a8r=i(X),SC=n(X,"LI",{});var EKe=s(SC);gAe=n(EKe,"STRONG",{});var dfa=s(gAe);n8r=r(dfa,"layoutlmv3"),dfa.forEach(t),s8r=r(EKe," \u2014 "),yoe=n(EKe,"A",{href:!0});var mfa=s(yoe);l8r=r(mfa,"LayoutLMv3ForQuestionAnswering"),mfa.forEach(t),i8r=r(EKe," (LayoutLMv3 model)"),EKe.forEach(t),d8r=i(X),RC=n(X,"LI",{});var CKe=s(RC);hAe=n(CKe,"STRONG",{});var cfa=s(hAe);m8r=r(cfa,"led"),cfa.forEach(t),c8r=r(CKe," \u2014 "),xoe=n(CKe,"A",{href:!0});var ffa=s(xoe);f8r=r(ffa,"LEDForQuestionAnswering"),ffa.forEach(t),g8r=r(CKe," (LED model)"),CKe.forEach(t),h8r=i(X),PC=n(X,"LI",{});var wKe=s(PC);uAe=n(wKe,"STRONG",{});var gfa=s(uAe);u8r=r(gfa,"lilt"),gfa.forEach(t),p8r=r(wKe," \u2014 "),$oe=n(wKe,"A",{href:!0});var hfa=s($oe);_8r=r(hfa,"LiltForQuestionAnswering"),hfa.forEach(t),b8r=r(wKe," (LiLT model)"),wKe.forEach(t),v8r=i(X),BC=n(X,"LI",{});var AKe=s(BC);pAe=n(AKe,"STRONG",{});var ufa=s(pAe);F8r=r(ufa,"longformer"),ufa.forEach(t),T8r=r(AKe," \u2014 "),koe=n(AKe,"A",{href:!0});var pfa=s(koe);M8r=r(pfa,"LongformerForQuestionAnswering"),pfa.forEach(t),E8r=r(AKe," (Longformer model)"),AKe.forEach(t),C8r=i(X),IC=n(X,"LI",{});var LKe=s(IC);_Ae=n(LKe,"STRONG",{});var _fa=s(_Ae);w8r=r(_fa,"luke"),_fa.forEach(t),A8r=r(LKe," \u2014 "),Soe=n(LKe,"A",{href:!0});var bfa=s(Soe);L8r=r(bfa,"LukeForQuestionAnswering"),bfa.forEach(t),y8r=r(LKe," (LUKE model)"),LKe.forEach(t),x8r=i(X),NC=n(X,"LI",{});var yKe=s(NC);bAe=n(yKe,"STRONG",{});var vfa=s(bAe);$8r=r(vfa,"lxmert"),vfa.forEach(t),k8r=r(yKe," \u2014 "),Roe=n(yKe,"A",{href:!0});var Ffa=s(Roe);S8r=r(Ffa,"LxmertForQuestionAnswering"),Ffa.forEach(t),R8r=r(yKe," (LXMERT model)"),yKe.forEach(t),P8r=i(X),qC=n(X,"LI",{});var xKe=s(qC);vAe=n(xKe,"STRONG",{});var Tfa=s(vAe);B8r=r(Tfa,"markuplm"),Tfa.forEach(t),I8r=r(xKe," \u2014 "),Poe=n(xKe,"A",{href:!0});var Mfa=s(Poe);N8r=r(Mfa,"MarkupLMForQuestionAnswering"),Mfa.forEach(t),q8r=r(xKe," (MarkupLM model)"),xKe.forEach(t),j8r=i(X),jC=n(X,"LI",{});var $Ke=s(jC);FAe=n($Ke,"STRONG",{});var Efa=s(FAe);D8r=r(Efa,"mbart"),Efa.forEach(t),G8r=r($Ke," \u2014 "),Boe=n($Ke,"A",{href:!0});var Cfa=s(Boe);O8r=r(Cfa,"MBartForQuestionAnswering"),Cfa.forEach(t),V8r=r($Ke," (mBART model)"),$Ke.forEach(t),X8r=i(X),DC=n(X,"LI",{});var kKe=s(DC);TAe=n(kKe,"STRONG",{});var wfa=s(TAe);z8r=r(wfa,"megatron-bert"),wfa.forEach(t),Q8r=r(kKe," \u2014 "),Ioe=n(kKe,"A",{href:!0});var Afa=s(Ioe);W8r=r(Afa,"MegatronBertForQuestionAnswering"),Afa.forEach(t),U8r=r(kKe," (Megatron-BERT model)"),kKe.forEach(t),H8r=i(X),GC=n(X,"LI",{});var SKe=s(GC);MAe=n(SKe,"STRONG",{});var Lfa=s(MAe);J8r=r(Lfa,"mobilebert"),Lfa.forEach(t),Y8r=r(SKe," \u2014 "),Noe=n(SKe,"A",{href:!0});var yfa=s(Noe);Z8r=r(yfa,"MobileBertForQuestionAnswering"),yfa.forEach(t),K8r=r(SKe," (MobileBERT model)"),SKe.forEach(t),eLr=i(X),OC=n(X,"LI",{});var RKe=s(OC);EAe=n(RKe,"STRONG",{});var xfa=s(EAe);oLr=r(xfa,"mpnet"),xfa.forEach(t),rLr=r(RKe," \u2014 "),qoe=n(RKe,"A",{href:!0});var $fa=s(qoe);tLr=r($fa,"MPNetForQuestionAnswering"),$fa.forEach(t),aLr=r(RKe," (MPNet model)"),RKe.forEach(t),nLr=i(X),VC=n(X,"LI",{});var PKe=s(VC);CAe=n(PKe,"STRONG",{});var kfa=s(CAe);sLr=r(kfa,"mvp"),kfa.forEach(t),lLr=r(PKe," \u2014 "),joe=n(PKe,"A",{href:!0});var Sfa=s(joe);iLr=r(Sfa,"MvpForQuestionAnswering"),Sfa.forEach(t),dLr=r(PKe," (MVP model)"),PKe.forEach(t),mLr=i(X),XC=n(X,"LI",{});var BKe=s(XC);wAe=n(BKe,"STRONG",{});var Rfa=s(wAe);cLr=r(Rfa,"nezha"),Rfa.forEach(t),fLr=r(BKe," \u2014 "),Doe=n(BKe,"A",{href:!0});var Pfa=s(Doe);gLr=r(Pfa,"NezhaForQuestionAnswering"),Pfa.forEach(t),hLr=r(BKe," (Nezha model)"),BKe.forEach(t),uLr=i(X),zC=n(X,"LI",{});var IKe=s(zC);AAe=n(IKe,"STRONG",{});var Bfa=s(AAe);pLr=r(Bfa,"nystromformer"),Bfa.forEach(t),_Lr=r(IKe," \u2014 "),Goe=n(IKe,"A",{href:!0});var Ifa=s(Goe);bLr=r(Ifa,"NystromformerForQuestionAnswering"),Ifa.forEach(t),vLr=r(IKe," (Nystr\xF6mformer model)"),IKe.forEach(t),FLr=i(X),QC=n(X,"LI",{});var NKe=s(QC);LAe=n(NKe,"STRONG",{});var Nfa=s(LAe);TLr=r(Nfa,"opt"),Nfa.forEach(t),MLr=r(NKe," \u2014 "),Ooe=n(NKe,"A",{href:!0});var qfa=s(Ooe);ELr=r(qfa,"OPTForQuestionAnswering"),qfa.forEach(t),CLr=r(NKe," (OPT model)"),NKe.forEach(t),wLr=i(X),WC=n(X,"LI",{});var qKe=s(WC);yAe=n(qKe,"STRONG",{});var jfa=s(yAe);ALr=r(jfa,"qdqbert"),jfa.forEach(t),LLr=r(qKe," \u2014 "),Voe=n(qKe,"A",{href:!0});var Dfa=s(Voe);yLr=r(Dfa,"QDQBertForQuestionAnswering"),Dfa.forEach(t),xLr=r(qKe," (QDQBert model)"),qKe.forEach(t),$Lr=i(X),UC=n(X,"LI",{});var jKe=s(UC);xAe=n(jKe,"STRONG",{});var Gfa=s(xAe);kLr=r(Gfa,"reformer"),Gfa.forEach(t),SLr=r(jKe," \u2014 "),Xoe=n(jKe,"A",{href:!0});var Ofa=s(Xoe);RLr=r(Ofa,"ReformerForQuestionAnswering"),Ofa.forEach(t),PLr=r(jKe," (Reformer model)"),jKe.forEach(t),BLr=i(X),HC=n(X,"LI",{});var DKe=s(HC);$Ae=n(DKe,"STRONG",{});var Vfa=s($Ae);ILr=r(Vfa,"rembert"),Vfa.forEach(t),NLr=r(DKe," \u2014 "),zoe=n(DKe,"A",{href:!0});var Xfa=s(zoe);qLr=r(Xfa,"RemBertForQuestionAnswering"),Xfa.forEach(t),jLr=r(DKe," (RemBERT model)"),DKe.forEach(t),DLr=i(X),JC=n(X,"LI",{});var GKe=s(JC);kAe=n(GKe,"STRONG",{});var zfa=s(kAe);GLr=r(zfa,"roberta"),zfa.forEach(t),OLr=r(GKe," \u2014 "),Qoe=n(GKe,"A",{href:!0});var Qfa=s(Qoe);VLr=r(Qfa,"RobertaForQuestionAnswering"),Qfa.forEach(t),XLr=r(GKe," (RoBERTa model)"),GKe.forEach(t),zLr=i(X),YC=n(X,"LI",{});var OKe=s(YC);SAe=n(OKe,"STRONG",{});var Wfa=s(SAe);QLr=r(Wfa,"roc_bert"),Wfa.forEach(t),WLr=r(OKe," \u2014 "),Woe=n(OKe,"A",{href:!0});var Ufa=s(Woe);ULr=r(Ufa,"RoCBertForQuestionAnswering"),Ufa.forEach(t),HLr=r(OKe," (RoCBert model)"),OKe.forEach(t),JLr=i(X),ZC=n(X,"LI",{});var VKe=s(ZC);RAe=n(VKe,"STRONG",{});var Hfa=s(RAe);YLr=r(Hfa,"roformer"),Hfa.forEach(t),ZLr=r(VKe," \u2014 "),Uoe=n(VKe,"A",{href:!0});var Jfa=s(Uoe);KLr=r(Jfa,"RoFormerForQuestionAnswering"),Jfa.forEach(t),eyr=r(VKe," (RoFormer model)"),VKe.forEach(t),oyr=i(X),KC=n(X,"LI",{});var XKe=s(KC);PAe=n(XKe,"STRONG",{});var Yfa=s(PAe);ryr=r(Yfa,"splinter"),Yfa.forEach(t),tyr=r(XKe," \u2014 "),Hoe=n(XKe,"A",{href:!0});var Zfa=s(Hoe);ayr=r(Zfa,"SplinterForQuestionAnswering"),Zfa.forEach(t),nyr=r(XKe," (Splinter model)"),XKe.forEach(t),syr=i(X),e3=n(X,"LI",{});var zKe=s(e3);BAe=n(zKe,"STRONG",{});var Kfa=s(BAe);lyr=r(Kfa,"squeezebert"),Kfa.forEach(t),iyr=r(zKe," \u2014 "),Joe=n(zKe,"A",{href:!0});var ega=s(Joe);dyr=r(ega,"SqueezeBertForQuestionAnswering"),ega.forEach(t),myr=r(zKe," (SqueezeBERT model)"),zKe.forEach(t),cyr=i(X),o3=n(X,"LI",{});var QKe=s(o3);IAe=n(QKe,"STRONG",{});var oga=s(IAe);fyr=r(oga,"xlm"),oga.forEach(t),gyr=r(QKe," \u2014 "),Yoe=n(QKe,"A",{href:!0});var rga=s(Yoe);hyr=r(rga,"XLMForQuestionAnsweringSimple"),rga.forEach(t),uyr=r(QKe," (XLM model)"),QKe.forEach(t),pyr=i(X),r3=n(X,"LI",{});var WKe=s(r3);NAe=n(WKe,"STRONG",{});var tga=s(NAe);_yr=r(tga,"xlm-roberta"),tga.forEach(t),byr=r(WKe," \u2014 "),Zoe=n(WKe,"A",{href:!0});var aga=s(Zoe);vyr=r(aga,"XLMRobertaForQuestionAnswering"),aga.forEach(t),Fyr=r(WKe," (XLM-RoBERTa model)"),WKe.forEach(t),Tyr=i(X),t3=n(X,"LI",{});var UKe=s(t3);qAe=n(UKe,"STRONG",{});var nga=s(qAe);Myr=r(nga,"xlm-roberta-xl"),nga.forEach(t),Eyr=r(UKe," \u2014 "),Koe=n(UKe,"A",{href:!0});var sga=s(Koe);Cyr=r(sga,"XLMRobertaXLForQuestionAnswering"),sga.forEach(t),wyr=r(UKe," (XLM-RoBERTa-XL model)"),UKe.forEach(t),Ayr=i(X),a3=n(X,"LI",{});var HKe=s(a3);jAe=n(HKe,"STRONG",{});var lga=s(jAe);Lyr=r(lga,"xlnet"),lga.forEach(t),yyr=r(HKe," \u2014 "),ere=n(HKe,"A",{href:!0});var iga=s(ere);xyr=r(iga,"XLNetForQuestionAnsweringSimple"),iga.forEach(t),$yr=r(HKe," (XLNet model)"),HKe.forEach(t),kyr=i(X),n3=n(X,"LI",{});var JKe=s(n3);DAe=n(JKe,"STRONG",{});var dga=s(DAe);Syr=r(dga,"yoso"),dga.forEach(t),Ryr=r(JKe," \u2014 "),ore=n(JKe,"A",{href:!0});var mga=s(ore);Pyr=r(mga,"YosoForQuestionAnswering"),mga.forEach(t),Byr=r(JKe," (YOSO model)"),JKe.forEach(t),X.forEach(t),Iyr=i(Oa),s3=n(Oa,"P",{});var YKe=s(s3);Nyr=r(YKe,"The model is set in evaluation mode by default using "),GAe=n(YKe,"CODE",{});var cga=s(GAe);qyr=r(cga,"model.eval()"),cga.forEach(t),jyr=r(YKe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),OAe=n(YKe,"CODE",{});var fga=s(OAe);Dyr=r(fga,"model.train()"),fga.forEach(t),YKe.forEach(t),Gyr=i(Oa),T(l3.$$.fragment,Oa),Oa.forEach(t),ti.forEach(t),Bio=i(c),Fm=n(c,"H2",{class:!0});var aco=s(Fm);i3=n(aco,"A",{id:!0,class:!0,href:!0});var gga=s(i3);VAe=n(gga,"SPAN",{});var hga=s(VAe);T(oR.$$.fragment,hga),hga.forEach(t),gga.forEach(t),Oyr=i(aco),XAe=n(aco,"SPAN",{});var uga=s(XAe);Vyr=r(uga,"AutoModelForTableQuestionAnswering"),uga.forEach(t),aco.forEach(t),Iio=i(c),Yo=n(c,"DIV",{class:!0});var ai=s(Yo);T(rR.$$.fragment,ai),Xyr=i(ai),Tm=n(ai,"P",{});var Qfe=s(Tm);zyr=r(Qfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),rre=n(Qfe,"A",{href:!0});var pga=s(rre);Qyr=r(pga,"from_pretrained()"),pga.forEach(t),Wyr=r(Qfe," class method or the "),tre=n(Qfe,"A",{href:!0});var _ga=s(tre);Uyr=r(_ga,"from_config()"),_ga.forEach(t),Hyr=r(Qfe,` class
method.`),Qfe.forEach(t),Jyr=i(ai),tR=n(ai,"P",{});var nco=s(tR);Yyr=r(nco,"This class cannot be instantiated directly using "),zAe=n(nco,"CODE",{});var bga=s(zAe);Zyr=r(bga,"__init__()"),bga.forEach(t),Kyr=r(nco," (throws an error)."),nco.forEach(t),e9r=i(ai),Nt=n(ai,"DIV",{class:!0});var Px=s(Nt);T(aR.$$.fragment,Px),o9r=i(Px),QAe=n(Px,"P",{});var vga=s(QAe);r9r=r(vga,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),vga.forEach(t),t9r=i(Px),Mm=n(Px,"P",{});var Wfe=s(Mm);a9r=r(Wfe,`Note:
Loading a model from its configuration file does `),WAe=n(Wfe,"STRONG",{});var Fga=s(WAe);n9r=r(Fga,"not"),Fga.forEach(t),s9r=r(Wfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),are=n(Wfe,"A",{href:!0});var Tga=s(are);l9r=r(Tga,"from_pretrained()"),Tga.forEach(t),i9r=r(Wfe," to load the model weights."),Wfe.forEach(t),d9r=i(Px),T(d3.$$.fragment,Px),Px.forEach(t),m9r=i(ai),uo=n(ai,"DIV",{class:!0});var Va=s(uo);T(nR.$$.fragment,Va),c9r=i(Va),UAe=n(Va,"P",{});var Mga=s(UAe);f9r=r(Mga,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Mga.forEach(t),g9r=i(Va),Cn=n(Va,"P",{});var Bx=s(Cn);h9r=r(Bx,"The model class to instantiate is selected based on the "),HAe=n(Bx,"CODE",{});var Ega=s(HAe);u9r=r(Ega,"model_type"),Ega.forEach(t),p9r=r(Bx,` property of the config object (either
passed as an argument or loaded from `),JAe=n(Bx,"CODE",{});var Cga=s(JAe);_9r=r(Cga,"pretrained_model_name_or_path"),Cga.forEach(t),b9r=r(Bx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),YAe=n(Bx,"CODE",{});var wga=s(YAe);v9r=r(wga,"pretrained_model_name_or_path"),wga.forEach(t),F9r=r(Bx,":"),Bx.forEach(t),T9r=i(Va),ZAe=n(Va,"UL",{});var Aga=s(ZAe);m3=n(Aga,"LI",{});var ZKe=s(m3);KAe=n(ZKe,"STRONG",{});var Lga=s(KAe);M9r=r(Lga,"tapas"),Lga.forEach(t),E9r=r(ZKe," \u2014 "),nre=n(ZKe,"A",{href:!0});var yga=s(nre);C9r=r(yga,"TapasForQuestionAnswering"),yga.forEach(t),w9r=r(ZKe," (TAPAS model)"),ZKe.forEach(t),Aga.forEach(t),A9r=i(Va),c3=n(Va,"P",{});var KKe=s(c3);L9r=r(KKe,"The model is set in evaluation mode by default using "),e6e=n(KKe,"CODE",{});var xga=s(e6e);y9r=r(xga,"model.eval()"),xga.forEach(t),x9r=r(KKe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o6e=n(KKe,"CODE",{});var $ga=s(o6e);$9r=r($ga,"model.train()"),$ga.forEach(t),KKe.forEach(t),k9r=i(Va),T(f3.$$.fragment,Va),Va.forEach(t),ai.forEach(t),Nio=i(c),Em=n(c,"H2",{class:!0});var sco=s(Em);g3=n(sco,"A",{id:!0,class:!0,href:!0});var kga=s(g3);r6e=n(kga,"SPAN",{});var Sga=s(r6e);T(sR.$$.fragment,Sga),Sga.forEach(t),kga.forEach(t),S9r=i(sco),t6e=n(sco,"SPAN",{});var Rga=s(t6e);R9r=r(Rga,"AutoModelForDocumentQuestionAnswering"),Rga.forEach(t),sco.forEach(t),qio=i(c),Zo=n(c,"DIV",{class:!0});var ni=s(Zo);T(lR.$$.fragment,ni),P9r=i(ni),Cm=n(ni,"P",{});var Ufe=s(Cm);B9r=r(Ufe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),sre=n(Ufe,"A",{href:!0});var Pga=s(sre);I9r=r(Pga,"from_pretrained()"),Pga.forEach(t),N9r=r(Ufe," class method or the "),lre=n(Ufe,"A",{href:!0});var Bga=s(lre);q9r=r(Bga,"from_config()"),Bga.forEach(t),j9r=r(Ufe,` class
method.`),Ufe.forEach(t),D9r=i(ni),iR=n(ni,"P",{});var lco=s(iR);G9r=r(lco,"This class cannot be instantiated directly using "),a6e=n(lco,"CODE",{});var Iga=s(a6e);O9r=r(Iga,"__init__()"),Iga.forEach(t),V9r=r(lco," (throws an error)."),lco.forEach(t),X9r=i(ni),qt=n(ni,"DIV",{class:!0});var Ix=s(qt);T(dR.$$.fragment,Ix),z9r=i(Ix),n6e=n(Ix,"P",{});var Nga=s(n6e);Q9r=r(Nga,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),Nga.forEach(t),W9r=i(Ix),wm=n(Ix,"P",{});var Hfe=s(wm);U9r=r(Hfe,`Note:
Loading a model from its configuration file does `),s6e=n(Hfe,"STRONG",{});var qga=s(s6e);H9r=r(qga,"not"),qga.forEach(t),J9r=r(Hfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),ire=n(Hfe,"A",{href:!0});var jga=s(ire);Y9r=r(jga,"from_pretrained()"),jga.forEach(t),Z9r=r(Hfe," to load the model weights."),Hfe.forEach(t),K9r=i(Ix),T(h3.$$.fragment,Ix),Ix.forEach(t),exr=i(ni),po=n(ni,"DIV",{class:!0});var Xa=s(po);T(mR.$$.fragment,Xa),oxr=i(Xa),l6e=n(Xa,"P",{});var Dga=s(l6e);rxr=r(Dga,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),Dga.forEach(t),txr=i(Xa),wn=n(Xa,"P",{});var Nx=s(wn);axr=r(Nx,"The model class to instantiate is selected based on the "),i6e=n(Nx,"CODE",{});var Gga=s(i6e);nxr=r(Gga,"model_type"),Gga.forEach(t),sxr=r(Nx,` property of the config object (either
passed as an argument or loaded from `),d6e=n(Nx,"CODE",{});var Oga=s(d6e);lxr=r(Oga,"pretrained_model_name_or_path"),Oga.forEach(t),ixr=r(Nx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m6e=n(Nx,"CODE",{});var Vga=s(m6e);dxr=r(Vga,"pretrained_model_name_or_path"),Vga.forEach(t),mxr=r(Nx,":"),Nx.forEach(t),cxr=i(Xa),Am=n(Xa,"UL",{});var Jfe=s(Am);u3=n(Jfe,"LI",{});var eeo=s(u3);c6e=n(eeo,"STRONG",{});var Xga=s(c6e);fxr=r(Xga,"layoutlm"),Xga.forEach(t),gxr=r(eeo," \u2014 "),dre=n(eeo,"A",{href:!0});var zga=s(dre);hxr=r(zga,"LayoutLMForQuestionAnswering"),zga.forEach(t),uxr=r(eeo," (LayoutLM model)"),eeo.forEach(t),pxr=i(Jfe),p3=n(Jfe,"LI",{});var oeo=s(p3);f6e=n(oeo,"STRONG",{});var Qga=s(f6e);_xr=r(Qga,"layoutlmv2"),Qga.forEach(t),bxr=r(oeo," \u2014 "),mre=n(oeo,"A",{href:!0});var Wga=s(mre);vxr=r(Wga,"LayoutLMv2ForQuestionAnswering"),Wga.forEach(t),Fxr=r(oeo," (LayoutLMv2 model)"),oeo.forEach(t),Txr=i(Jfe),_3=n(Jfe,"LI",{});var reo=s(_3);g6e=n(reo,"STRONG",{});var Uga=s(g6e);Mxr=r(Uga,"layoutlmv3"),Uga.forEach(t),Exr=r(reo," \u2014 "),cre=n(reo,"A",{href:!0});var Hga=s(cre);Cxr=r(Hga,"LayoutLMv3ForQuestionAnswering"),Hga.forEach(t),wxr=r(reo," (LayoutLMv3 model)"),reo.forEach(t),Jfe.forEach(t),Axr=i(Xa),b3=n(Xa,"P",{});var teo=s(b3);Lxr=r(teo,"The model is set in evaluation mode by default using "),h6e=n(teo,"CODE",{});var Jga=s(h6e);yxr=r(Jga,"model.eval()"),Jga.forEach(t),xxr=r(teo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),u6e=n(teo,"CODE",{});var Yga=s(u6e);$xr=r(Yga,"model.train()"),Yga.forEach(t),teo.forEach(t),kxr=i(Xa),T(v3.$$.fragment,Xa),Xa.forEach(t),ni.forEach(t),jio=i(c),Lm=n(c,"H2",{class:!0});var ico=s(Lm);F3=n(ico,"A",{id:!0,class:!0,href:!0});var Zga=s(F3);p6e=n(Zga,"SPAN",{});var Kga=s(p6e);T(cR.$$.fragment,Kga),Kga.forEach(t),Zga.forEach(t),Sxr=i(ico),_6e=n(ico,"SPAN",{});var eha=s(_6e);Rxr=r(eha,"AutoModelForImageClassification"),eha.forEach(t),ico.forEach(t),Dio=i(c),Ko=n(c,"DIV",{class:!0});var si=s(Ko);T(fR.$$.fragment,si),Pxr=i(si),ym=n(si,"P",{});var Yfe=s(ym);Bxr=r(Yfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),fre=n(Yfe,"A",{href:!0});var oha=s(fre);Ixr=r(oha,"from_pretrained()"),oha.forEach(t),Nxr=r(Yfe," class method or the "),gre=n(Yfe,"A",{href:!0});var rha=s(gre);qxr=r(rha,"from_config()"),rha.forEach(t),jxr=r(Yfe,` class
method.`),Yfe.forEach(t),Dxr=i(si),gR=n(si,"P",{});var dco=s(gR);Gxr=r(dco,"This class cannot be instantiated directly using "),b6e=n(dco,"CODE",{});var tha=s(b6e);Oxr=r(tha,"__init__()"),tha.forEach(t),Vxr=r(dco," (throws an error)."),dco.forEach(t),Xxr=i(si),jt=n(si,"DIV",{class:!0});var qx=s(jt);T(hR.$$.fragment,qx),zxr=i(qx),v6e=n(qx,"P",{});var aha=s(v6e);Qxr=r(aha,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),aha.forEach(t),Wxr=i(qx),xm=n(qx,"P",{});var Zfe=s(xm);Uxr=r(Zfe,`Note:
Loading a model from its configuration file does `),F6e=n(Zfe,"STRONG",{});var nha=s(F6e);Hxr=r(nha,"not"),nha.forEach(t),Jxr=r(Zfe,` load the model weights. It only affects the
model\u2019s configuration. Use `),hre=n(Zfe,"A",{href:!0});var sha=s(hre);Yxr=r(sha,"from_pretrained()"),sha.forEach(t),Zxr=r(Zfe," to load the model weights."),Zfe.forEach(t),Kxr=i(qx),T(T3.$$.fragment,qx),qx.forEach(t),e$r=i(si),_o=n(si,"DIV",{class:!0});var za=s(_o);T(uR.$$.fragment,za),o$r=i(za),T6e=n(za,"P",{});var lha=s(T6e);r$r=r(lha,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),lha.forEach(t),t$r=i(za),An=n(za,"P",{});var jx=s(An);a$r=r(jx,"The model class to instantiate is selected based on the "),M6e=n(jx,"CODE",{});var iha=s(M6e);n$r=r(iha,"model_type"),iha.forEach(t),s$r=r(jx,` property of the config object (either
passed as an argument or loaded from `),E6e=n(jx,"CODE",{});var dha=s(E6e);l$r=r(dha,"pretrained_model_name_or_path"),dha.forEach(t),i$r=r(jx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C6e=n(jx,"CODE",{});var mha=s(C6e);d$r=r(mha,"pretrained_model_name_or_path"),mha.forEach(t),m$r=r(jx,":"),jx.forEach(t),c$r=i(za),ve=n(za,"UL",{});var Te=s(ve);M3=n(Te,"LI",{});var aeo=s(M3);w6e=n(aeo,"STRONG",{});var cha=s(w6e);f$r=r(cha,"beit"),cha.forEach(t),g$r=r(aeo," \u2014 "),ure=n(aeo,"A",{href:!0});var fha=s(ure);h$r=r(fha,"BeitForImageClassification"),fha.forEach(t),u$r=r(aeo," (BEiT model)"),aeo.forEach(t),p$r=i(Te),E3=n(Te,"LI",{});var neo=s(E3);A6e=n(neo,"STRONG",{});var gha=s(A6e);_$r=r(gha,"convnext"),gha.forEach(t),b$r=r(neo," \u2014 "),pre=n(neo,"A",{href:!0});var hha=s(pre);v$r=r(hha,"ConvNextForImageClassification"),hha.forEach(t),F$r=r(neo," (ConvNeXT model)"),neo.forEach(t),T$r=i(Te),C3=n(Te,"LI",{});var seo=s(C3);L6e=n(seo,"STRONG",{});var uha=s(L6e);M$r=r(uha,"cvt"),uha.forEach(t),E$r=r(seo," \u2014 "),_re=n(seo,"A",{href:!0});var pha=s(_re);C$r=r(pha,"CvtForImageClassification"),pha.forEach(t),w$r=r(seo," (CvT model)"),seo.forEach(t),A$r=i(Te),w3=n(Te,"LI",{});var leo=s(w3);y6e=n(leo,"STRONG",{});var _ha=s(y6e);L$r=r(_ha,"data2vec-vision"),_ha.forEach(t),y$r=r(leo," \u2014 "),bre=n(leo,"A",{href:!0});var bha=s(bre);x$r=r(bha,"Data2VecVisionForImageClassification"),bha.forEach(t),$$r=r(leo," (Data2VecVision model)"),leo.forEach(t),k$r=i(Te),ql=n(Te,"LI",{});var Nq=s(ql);x6e=n(Nq,"STRONG",{});var vha=s(x6e);S$r=r(vha,"deit"),vha.forEach(t),R$r=r(Nq," \u2014 "),vre=n(Nq,"A",{href:!0});var Fha=s(vre);P$r=r(Fha,"DeiTForImageClassification"),Fha.forEach(t),B$r=r(Nq," or "),Fre=n(Nq,"A",{href:!0});var Tha=s(Fre);I$r=r(Tha,"DeiTForImageClassificationWithTeacher"),Tha.forEach(t),N$r=r(Nq," (DeiT model)"),Nq.forEach(t),q$r=i(Te),A3=n(Te,"LI",{});var ieo=s(A3);$6e=n(ieo,"STRONG",{});var Mha=s($6e);j$r=r(Mha,"imagegpt"),Mha.forEach(t),D$r=r(ieo," \u2014 "),Tre=n(ieo,"A",{href:!0});var Eha=s(Tre);G$r=r(Eha,"ImageGPTForImageClassification"),Eha.forEach(t),O$r=r(ieo," (ImageGPT model)"),ieo.forEach(t),V$r=i(Te),jl=n(Te,"LI",{});var qq=s(jl);k6e=n(qq,"STRONG",{});var Cha=s(k6e);X$r=r(Cha,"levit"),Cha.forEach(t),z$r=r(qq," \u2014 "),Mre=n(qq,"A",{href:!0});var wha=s(Mre);Q$r=r(wha,"LevitForImageClassification"),wha.forEach(t),W$r=r(qq," or "),Ere=n(qq,"A",{href:!0});var Aha=s(Ere);U$r=r(Aha,"LevitForImageClassificationWithTeacher"),Aha.forEach(t),H$r=r(qq," (LeViT model)"),qq.forEach(t),J$r=i(Te),L3=n(Te,"LI",{});var deo=s(L3);S6e=n(deo,"STRONG",{});var Lha=s(S6e);Y$r=r(Lha,"mobilenet_v2"),Lha.forEach(t),Z$r=r(deo," \u2014 "),Cre=n(deo,"A",{href:!0});var yha=s(Cre);K$r=r(yha,"MobileNetV2ForImageClassification"),yha.forEach(t),ekr=r(deo," (MobileNetV2 model)"),deo.forEach(t),okr=i(Te),y3=n(Te,"LI",{});var meo=s(y3);R6e=n(meo,"STRONG",{});var xha=s(R6e);rkr=r(xha,"mobilevit"),xha.forEach(t),tkr=r(meo," \u2014 "),wre=n(meo,"A",{href:!0});var $ha=s(wre);akr=r($ha,"MobileViTForImageClassification"),$ha.forEach(t),nkr=r(meo," (MobileViT model)"),meo.forEach(t),skr=i(Te),Dt=n(Te,"LI",{});var Kf=s(Dt);P6e=n(Kf,"STRONG",{});var kha=s(P6e);lkr=r(kha,"perceiver"),kha.forEach(t),ikr=r(Kf," \u2014 "),Are=n(Kf,"A",{href:!0});var Sha=s(Are);dkr=r(Sha,"PerceiverForImageClassificationLearned"),Sha.forEach(t),mkr=r(Kf," or "),Lre=n(Kf,"A",{href:!0});var Rha=s(Lre);ckr=r(Rha,"PerceiverForImageClassificationFourier"),Rha.forEach(t),fkr=r(Kf," or "),yre=n(Kf,"A",{href:!0});var Pha=s(yre);gkr=r(Pha,"PerceiverForImageClassificationConvProcessing"),Pha.forEach(t),hkr=r(Kf," (Perceiver model)"),Kf.forEach(t),ukr=i(Te),x3=n(Te,"LI",{});var ceo=s(x3);B6e=n(ceo,"STRONG",{});var Bha=s(B6e);pkr=r(Bha,"poolformer"),Bha.forEach(t),_kr=r(ceo," \u2014 "),xre=n(ceo,"A",{href:!0});var Iha=s(xre);bkr=r(Iha,"PoolFormerForImageClassification"),Iha.forEach(t),vkr=r(ceo," (PoolFormer model)"),ceo.forEach(t),Fkr=i(Te),$3=n(Te,"LI",{});var feo=s($3);I6e=n(feo,"STRONG",{});var Nha=s(I6e);Tkr=r(Nha,"regnet"),Nha.forEach(t),Mkr=r(feo," \u2014 "),$re=n(feo,"A",{href:!0});var qha=s($re);Ekr=r(qha,"RegNetForImageClassification"),qha.forEach(t),Ckr=r(feo," (RegNet model)"),feo.forEach(t),wkr=i(Te),k3=n(Te,"LI",{});var geo=s(k3);N6e=n(geo,"STRONG",{});var jha=s(N6e);Akr=r(jha,"resnet"),jha.forEach(t),Lkr=r(geo," \u2014 "),kre=n(geo,"A",{href:!0});var Dha=s(kre);ykr=r(Dha,"ResNetForImageClassification"),Dha.forEach(t),xkr=r(geo," (ResNet model)"),geo.forEach(t),$kr=i(Te),S3=n(Te,"LI",{});var heo=s(S3);q6e=n(heo,"STRONG",{});var Gha=s(q6e);kkr=r(Gha,"segformer"),Gha.forEach(t),Skr=r(heo," \u2014 "),Sre=n(heo,"A",{href:!0});var Oha=s(Sre);Rkr=r(Oha,"SegformerForImageClassification"),Oha.forEach(t),Pkr=r(heo," (SegFormer model)"),heo.forEach(t),Bkr=i(Te),R3=n(Te,"LI",{});var ueo=s(R3);j6e=n(ueo,"STRONG",{});var Vha=s(j6e);Ikr=r(Vha,"swin"),Vha.forEach(t),Nkr=r(ueo," \u2014 "),Rre=n(ueo,"A",{href:!0});var Xha=s(Rre);qkr=r(Xha,"SwinForImageClassification"),Xha.forEach(t),jkr=r(ueo," (Swin Transformer model)"),ueo.forEach(t),Dkr=i(Te),P3=n(Te,"LI",{});var peo=s(P3);D6e=n(peo,"STRONG",{});var zha=s(D6e);Gkr=r(zha,"swinv2"),zha.forEach(t),Okr=r(peo," \u2014 "),Pre=n(peo,"A",{href:!0});var Qha=s(Pre);Vkr=r(Qha,"Swinv2ForImageClassification"),Qha.forEach(t),Xkr=r(peo," (Swin Transformer V2 model)"),peo.forEach(t),zkr=i(Te),B3=n(Te,"LI",{});var _eo=s(B3);G6e=n(_eo,"STRONG",{});var Wha=s(G6e);Qkr=r(Wha,"van"),Wha.forEach(t),Wkr=r(_eo," \u2014 "),Bre=n(_eo,"A",{href:!0});var Uha=s(Bre);Ukr=r(Uha,"VanForImageClassification"),Uha.forEach(t),Hkr=r(_eo," (VAN model)"),_eo.forEach(t),Jkr=i(Te),I3=n(Te,"LI",{});var beo=s(I3);O6e=n(beo,"STRONG",{});var Hha=s(O6e);Ykr=r(Hha,"vit"),Hha.forEach(t),Zkr=r(beo," \u2014 "),Ire=n(beo,"A",{href:!0});var Jha=s(Ire);Kkr=r(Jha,"ViTForImageClassification"),Jha.forEach(t),eSr=r(beo," (ViT model)"),beo.forEach(t),oSr=i(Te),N3=n(Te,"LI",{});var veo=s(N3);V6e=n(veo,"STRONG",{});var Yha=s(V6e);rSr=r(Yha,"vit_msn"),Yha.forEach(t),tSr=r(veo," \u2014 "),Nre=n(veo,"A",{href:!0});var Zha=s(Nre);aSr=r(Zha,"ViTMSNForImageClassification"),Zha.forEach(t),nSr=r(veo," (ViTMSN model)"),veo.forEach(t),Te.forEach(t),sSr=i(za),q3=n(za,"P",{});var Feo=s(q3);lSr=r(Feo,"The model is set in evaluation mode by default using "),X6e=n(Feo,"CODE",{});var Kha=s(X6e);iSr=r(Kha,"model.eval()"),Kha.forEach(t),dSr=r(Feo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),z6e=n(Feo,"CODE",{});var eua=s(z6e);mSr=r(eua,"model.train()"),eua.forEach(t),Feo.forEach(t),cSr=i(za),T(j3.$$.fragment,za),za.forEach(t),si.forEach(t),Gio=i(c),$m=n(c,"H2",{class:!0});var mco=s($m);D3=n(mco,"A",{id:!0,class:!0,href:!0});var oua=s(D3);Q6e=n(oua,"SPAN",{});var rua=s(Q6e);T(pR.$$.fragment,rua),rua.forEach(t),oua.forEach(t),fSr=i(mco),W6e=n(mco,"SPAN",{});var tua=s(W6e);gSr=r(tua,"AutoModelForVideoClassification"),tua.forEach(t),mco.forEach(t),Oio=i(c),er=n(c,"DIV",{class:!0});var li=s(er);T(_R.$$.fragment,li),hSr=i(li),km=n(li,"P",{});var Kfe=s(km);uSr=r(Kfe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),qre=n(Kfe,"A",{href:!0});var aua=s(qre);pSr=r(aua,"from_pretrained()"),aua.forEach(t),_Sr=r(Kfe," class method or the "),jre=n(Kfe,"A",{href:!0});var nua=s(jre);bSr=r(nua,"from_config()"),nua.forEach(t),vSr=r(Kfe,` class
method.`),Kfe.forEach(t),FSr=i(li),bR=n(li,"P",{});var cco=s(bR);TSr=r(cco,"This class cannot be instantiated directly using "),U6e=n(cco,"CODE",{});var sua=s(U6e);MSr=r(sua,"__init__()"),sua.forEach(t),ESr=r(cco," (throws an error)."),cco.forEach(t),CSr=i(li),Gt=n(li,"DIV",{class:!0});var Dx=s(Gt);T(vR.$$.fragment,Dx),wSr=i(Dx),H6e=n(Dx,"P",{});var lua=s(H6e);ASr=r(lua,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),lua.forEach(t),LSr=i(Dx),Sm=n(Dx,"P",{});var ege=s(Sm);ySr=r(ege,`Note:
Loading a model from its configuration file does `),J6e=n(ege,"STRONG",{});var iua=s(J6e);xSr=r(iua,"not"),iua.forEach(t),$Sr=r(ege,` load the model weights. It only affects the
model\u2019s configuration. Use `),Dre=n(ege,"A",{href:!0});var dua=s(Dre);kSr=r(dua,"from_pretrained()"),dua.forEach(t),SSr=r(ege," to load the model weights."),ege.forEach(t),RSr=i(Dx),T(G3.$$.fragment,Dx),Dx.forEach(t),PSr=i(li),bo=n(li,"DIV",{class:!0});var Qa=s(bo);T(FR.$$.fragment,Qa),BSr=i(Qa),Y6e=n(Qa,"P",{});var mua=s(Y6e);ISr=r(mua,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),mua.forEach(t),NSr=i(Qa),Ln=n(Qa,"P",{});var Gx=s(Ln);qSr=r(Gx,"The model class to instantiate is selected based on the "),Z6e=n(Gx,"CODE",{});var cua=s(Z6e);jSr=r(cua,"model_type"),cua.forEach(t),DSr=r(Gx,` property of the config object (either
passed as an argument or loaded from `),K6e=n(Gx,"CODE",{});var fua=s(K6e);GSr=r(fua,"pretrained_model_name_or_path"),fua.forEach(t),OSr=r(Gx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e7e=n(Gx,"CODE",{});var gua=s(e7e);VSr=r(gua,"pretrained_model_name_or_path"),gua.forEach(t),XSr=r(Gx,":"),Gx.forEach(t),zSr=i(Qa),o7e=n(Qa,"UL",{});var hua=s(o7e);O3=n(hua,"LI",{});var Teo=s(O3);r7e=n(Teo,"STRONG",{});var uua=s(r7e);QSr=r(uua,"videomae"),uua.forEach(t),WSr=r(Teo," \u2014 "),Gre=n(Teo,"A",{href:!0});var pua=s(Gre);USr=r(pua,"VideoMAEForVideoClassification"),pua.forEach(t),HSr=r(Teo," (VideoMAE model)"),Teo.forEach(t),hua.forEach(t),JSr=i(Qa),V3=n(Qa,"P",{});var Meo=s(V3);YSr=r(Meo,"The model is set in evaluation mode by default using "),t7e=n(Meo,"CODE",{});var _ua=s(t7e);ZSr=r(_ua,"model.eval()"),_ua.forEach(t),KSr=r(Meo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),a7e=n(Meo,"CODE",{});var bua=s(a7e);eRr=r(bua,"model.train()"),bua.forEach(t),Meo.forEach(t),oRr=i(Qa),T(X3.$$.fragment,Qa),Qa.forEach(t),li.forEach(t),Vio=i(c),Rm=n(c,"H2",{class:!0});var fco=s(Rm);z3=n(fco,"A",{id:!0,class:!0,href:!0});var vua=s(z3);n7e=n(vua,"SPAN",{});var Fua=s(n7e);T(TR.$$.fragment,Fua),Fua.forEach(t),vua.forEach(t),rRr=i(fco),s7e=n(fco,"SPAN",{});var Tua=s(s7e);tRr=r(Tua,"AutoModelForVision2Seq"),Tua.forEach(t),fco.forEach(t),Xio=i(c),or=n(c,"DIV",{class:!0});var ii=s(or);T(MR.$$.fragment,ii),aRr=i(ii),Pm=n(ii,"P",{});var oge=s(Pm);nRr=r(oge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),Ore=n(oge,"A",{href:!0});var Mua=s(Ore);sRr=r(Mua,"from_pretrained()"),Mua.forEach(t),lRr=r(oge," class method or the "),Vre=n(oge,"A",{href:!0});var Eua=s(Vre);iRr=r(Eua,"from_config()"),Eua.forEach(t),dRr=r(oge,` class
method.`),oge.forEach(t),mRr=i(ii),ER=n(ii,"P",{});var gco=s(ER);cRr=r(gco,"This class cannot be instantiated directly using "),l7e=n(gco,"CODE",{});var Cua=s(l7e);fRr=r(Cua,"__init__()"),Cua.forEach(t),gRr=r(gco," (throws an error)."),gco.forEach(t),hRr=i(ii),Ot=n(ii,"DIV",{class:!0});var Ox=s(Ot);T(CR.$$.fragment,Ox),uRr=i(Ox),i7e=n(Ox,"P",{});var wua=s(i7e);pRr=r(wua,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),wua.forEach(t),_Rr=i(Ox),Bm=n(Ox,"P",{});var rge=s(Bm);bRr=r(rge,`Note:
Loading a model from its configuration file does `),d7e=n(rge,"STRONG",{});var Aua=s(d7e);vRr=r(Aua,"not"),Aua.forEach(t),FRr=r(rge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Xre=n(rge,"A",{href:!0});var Lua=s(Xre);TRr=r(Lua,"from_pretrained()"),Lua.forEach(t),MRr=r(rge," to load the model weights."),rge.forEach(t),ERr=i(Ox),T(Q3.$$.fragment,Ox),Ox.forEach(t),CRr=i(ii),vo=n(ii,"DIV",{class:!0});var Wa=s(vo);T(wR.$$.fragment,Wa),wRr=i(Wa),m7e=n(Wa,"P",{});var yua=s(m7e);ARr=r(yua,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),yua.forEach(t),LRr=i(Wa),yn=n(Wa,"P",{});var Vx=s(yn);yRr=r(Vx,"The model class to instantiate is selected based on the "),c7e=n(Vx,"CODE",{});var xua=s(c7e);xRr=r(xua,"model_type"),xua.forEach(t),$Rr=r(Vx,` property of the config object (either
passed as an argument or loaded from `),f7e=n(Vx,"CODE",{});var $ua=s(f7e);kRr=r($ua,"pretrained_model_name_or_path"),$ua.forEach(t),SRr=r(Vx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g7e=n(Vx,"CODE",{});var kua=s(g7e);RRr=r(kua,"pretrained_model_name_or_path"),kua.forEach(t),PRr=r(Vx,":"),Vx.forEach(t),BRr=i(Wa),h7e=n(Wa,"UL",{});var Sua=s(h7e);W3=n(Sua,"LI",{});var Eeo=s(W3);u7e=n(Eeo,"STRONG",{});var Rua=s(u7e);IRr=r(Rua,"vision-encoder-decoder"),Rua.forEach(t),NRr=r(Eeo," \u2014 "),zre=n(Eeo,"A",{href:!0});var Pua=s(zre);qRr=r(Pua,"VisionEncoderDecoderModel"),Pua.forEach(t),jRr=r(Eeo," (Vision Encoder decoder model)"),Eeo.forEach(t),Sua.forEach(t),DRr=i(Wa),U3=n(Wa,"P",{});var Ceo=s(U3);GRr=r(Ceo,"The model is set in evaluation mode by default using "),p7e=n(Ceo,"CODE",{});var Bua=s(p7e);ORr=r(Bua,"model.eval()"),Bua.forEach(t),VRr=r(Ceo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_7e=n(Ceo,"CODE",{});var Iua=s(_7e);XRr=r(Iua,"model.train()"),Iua.forEach(t),Ceo.forEach(t),zRr=i(Wa),T(H3.$$.fragment,Wa),Wa.forEach(t),ii.forEach(t),zio=i(c),Im=n(c,"H2",{class:!0});var hco=s(Im);J3=n(hco,"A",{id:!0,class:!0,href:!0});var Nua=s(J3);b7e=n(Nua,"SPAN",{});var qua=s(b7e);T(AR.$$.fragment,qua),qua.forEach(t),Nua.forEach(t),QRr=i(hco),v7e=n(hco,"SPAN",{});var jua=s(v7e);WRr=r(jua,"AutoModelForVisualQuestionAnswering"),jua.forEach(t),hco.forEach(t),Qio=i(c),rr=n(c,"DIV",{class:!0});var di=s(rr);T(LR.$$.fragment,di),URr=i(di),Nm=n(di,"P",{});var tge=s(Nm);HRr=r(tge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),Qre=n(tge,"A",{href:!0});var Dua=s(Qre);JRr=r(Dua,"from_pretrained()"),Dua.forEach(t),YRr=r(tge," class method or the "),Wre=n(tge,"A",{href:!0});var Gua=s(Wre);ZRr=r(Gua,"from_config()"),Gua.forEach(t),KRr=r(tge,` class
method.`),tge.forEach(t),ePr=i(di),yR=n(di,"P",{});var uco=s(yR);oPr=r(uco,"This class cannot be instantiated directly using "),F7e=n(uco,"CODE",{});var Oua=s(F7e);rPr=r(Oua,"__init__()"),Oua.forEach(t),tPr=r(uco," (throws an error)."),uco.forEach(t),aPr=i(di),Vt=n(di,"DIV",{class:!0});var Xx=s(Vt);T(xR.$$.fragment,Xx),nPr=i(Xx),T7e=n(Xx,"P",{});var Vua=s(T7e);sPr=r(Vua,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Vua.forEach(t),lPr=i(Xx),qm=n(Xx,"P",{});var age=s(qm);iPr=r(age,`Note:
Loading a model from its configuration file does `),M7e=n(age,"STRONG",{});var Xua=s(M7e);dPr=r(Xua,"not"),Xua.forEach(t),mPr=r(age,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ure=n(age,"A",{href:!0});var zua=s(Ure);cPr=r(zua,"from_pretrained()"),zua.forEach(t),fPr=r(age," to load the model weights."),age.forEach(t),gPr=i(Xx),T(Y3.$$.fragment,Xx),Xx.forEach(t),hPr=i(di),Fo=n(di,"DIV",{class:!0});var Ua=s(Fo);T($R.$$.fragment,Ua),uPr=i(Ua),E7e=n(Ua,"P",{});var Qua=s(E7e);pPr=r(Qua,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),Qua.forEach(t),_Pr=i(Ua),xn=n(Ua,"P",{});var zx=s(xn);bPr=r(zx,"The model class to instantiate is selected based on the "),C7e=n(zx,"CODE",{});var Wua=s(C7e);vPr=r(Wua,"model_type"),Wua.forEach(t),FPr=r(zx,` property of the config object (either
passed as an argument or loaded from `),w7e=n(zx,"CODE",{});var Uua=s(w7e);TPr=r(Uua,"pretrained_model_name_or_path"),Uua.forEach(t),MPr=r(zx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),A7e=n(zx,"CODE",{});var Hua=s(A7e);EPr=r(Hua,"pretrained_model_name_or_path"),Hua.forEach(t),CPr=r(zx,":"),zx.forEach(t),wPr=i(Ua),L7e=n(Ua,"UL",{});var Jua=s(L7e);Z3=n(Jua,"LI",{});var weo=s(Z3);y7e=n(weo,"STRONG",{});var Yua=s(y7e);APr=r(Yua,"vilt"),Yua.forEach(t),LPr=r(weo," \u2014 "),Hre=n(weo,"A",{href:!0});var Zua=s(Hre);yPr=r(Zua,"ViltForQuestionAnswering"),Zua.forEach(t),xPr=r(weo," (ViLT model)"),weo.forEach(t),Jua.forEach(t),$Pr=i(Ua),K3=n(Ua,"P",{});var Aeo=s(K3);kPr=r(Aeo,"The model is set in evaluation mode by default using "),x7e=n(Aeo,"CODE",{});var Kua=s(x7e);SPr=r(Kua,"model.eval()"),Kua.forEach(t),RPr=r(Aeo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$7e=n(Aeo,"CODE",{});var epa=s($7e);PPr=r(epa,"model.train()"),epa.forEach(t),Aeo.forEach(t),BPr=i(Ua),T(e5.$$.fragment,Ua),Ua.forEach(t),di.forEach(t),Wio=i(c),jm=n(c,"H2",{class:!0});var pco=s(jm);o5=n(pco,"A",{id:!0,class:!0,href:!0});var opa=s(o5);k7e=n(opa,"SPAN",{});var rpa=s(k7e);T(kR.$$.fragment,rpa),rpa.forEach(t),opa.forEach(t),IPr=i(pco),S7e=n(pco,"SPAN",{});var tpa=s(S7e);NPr=r(tpa,"AutoModelForAudioClassification"),tpa.forEach(t),pco.forEach(t),Uio=i(c),tr=n(c,"DIV",{class:!0});var mi=s(tr);T(SR.$$.fragment,mi),qPr=i(mi),Dm=n(mi,"P",{});var nge=s(Dm);jPr=r(nge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),Jre=n(nge,"A",{href:!0});var apa=s(Jre);DPr=r(apa,"from_pretrained()"),apa.forEach(t),GPr=r(nge," class method or the "),Yre=n(nge,"A",{href:!0});var npa=s(Yre);OPr=r(npa,"from_config()"),npa.forEach(t),VPr=r(nge,` class
method.`),nge.forEach(t),XPr=i(mi),RR=n(mi,"P",{});var _co=s(RR);zPr=r(_co,"This class cannot be instantiated directly using "),R7e=n(_co,"CODE",{});var spa=s(R7e);QPr=r(spa,"__init__()"),spa.forEach(t),WPr=r(_co," (throws an error)."),_co.forEach(t),UPr=i(mi),Xt=n(mi,"DIV",{class:!0});var Qx=s(Xt);T(PR.$$.fragment,Qx),HPr=i(Qx),P7e=n(Qx,"P",{});var lpa=s(P7e);JPr=r(lpa,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),lpa.forEach(t),YPr=i(Qx),Gm=n(Qx,"P",{});var sge=s(Gm);ZPr=r(sge,`Note:
Loading a model from its configuration file does `),B7e=n(sge,"STRONG",{});var ipa=s(B7e);KPr=r(ipa,"not"),ipa.forEach(t),eBr=r(sge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zre=n(sge,"A",{href:!0});var dpa=s(Zre);oBr=r(dpa,"from_pretrained()"),dpa.forEach(t),rBr=r(sge," to load the model weights."),sge.forEach(t),tBr=i(Qx),T(r5.$$.fragment,Qx),Qx.forEach(t),aBr=i(mi),To=n(mi,"DIV",{class:!0});var Ha=s(To);T(BR.$$.fragment,Ha),nBr=i(Ha),I7e=n(Ha,"P",{});var mpa=s(I7e);sBr=r(mpa,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),mpa.forEach(t),lBr=i(Ha),$n=n(Ha,"P",{});var Wx=s($n);iBr=r(Wx,"The model class to instantiate is selected based on the "),N7e=n(Wx,"CODE",{});var cpa=s(N7e);dBr=r(cpa,"model_type"),cpa.forEach(t),mBr=r(Wx,` property of the config object (either
passed as an argument or loaded from `),q7e=n(Wx,"CODE",{});var fpa=s(q7e);cBr=r(fpa,"pretrained_model_name_or_path"),fpa.forEach(t),fBr=r(Wx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),j7e=n(Wx,"CODE",{});var gpa=s(j7e);gBr=r(gpa,"pretrained_model_name_or_path"),gpa.forEach(t),hBr=r(Wx,":"),Wx.forEach(t),uBr=i(Ha),Ne=n(Ha,"UL",{});var Je=s(Ne);t5=n(Je,"LI",{});var Leo=s(t5);D7e=n(Leo,"STRONG",{});var hpa=s(D7e);pBr=r(hpa,"data2vec-audio"),hpa.forEach(t),_Br=r(Leo," \u2014 "),Kre=n(Leo,"A",{href:!0});var upa=s(Kre);bBr=r(upa,"Data2VecAudioForSequenceClassification"),upa.forEach(t),vBr=r(Leo," (Data2VecAudio model)"),Leo.forEach(t),FBr=i(Je),a5=n(Je,"LI",{});var yeo=s(a5);G7e=n(yeo,"STRONG",{});var ppa=s(G7e);TBr=r(ppa,"hubert"),ppa.forEach(t),MBr=r(yeo," \u2014 "),ete=n(yeo,"A",{href:!0});var _pa=s(ete);EBr=r(_pa,"HubertForSequenceClassification"),_pa.forEach(t),CBr=r(yeo," (Hubert model)"),yeo.forEach(t),wBr=i(Je),n5=n(Je,"LI",{});var xeo=s(n5);O7e=n(xeo,"STRONG",{});var bpa=s(O7e);ABr=r(bpa,"sew"),bpa.forEach(t),LBr=r(xeo," \u2014 "),ote=n(xeo,"A",{href:!0});var vpa=s(ote);yBr=r(vpa,"SEWForSequenceClassification"),vpa.forEach(t),xBr=r(xeo," (SEW model)"),xeo.forEach(t),$Br=i(Je),s5=n(Je,"LI",{});var $eo=s(s5);V7e=n($eo,"STRONG",{});var Fpa=s(V7e);kBr=r(Fpa,"sew-d"),Fpa.forEach(t),SBr=r($eo," \u2014 "),rte=n($eo,"A",{href:!0});var Tpa=s(rte);RBr=r(Tpa,"SEWDForSequenceClassification"),Tpa.forEach(t),PBr=r($eo," (SEW-D model)"),$eo.forEach(t),BBr=i(Je),l5=n(Je,"LI",{});var keo=s(l5);X7e=n(keo,"STRONG",{});var Mpa=s(X7e);IBr=r(Mpa,"unispeech"),Mpa.forEach(t),NBr=r(keo," \u2014 "),tte=n(keo,"A",{href:!0});var Epa=s(tte);qBr=r(Epa,"UniSpeechForSequenceClassification"),Epa.forEach(t),jBr=r(keo," (UniSpeech model)"),keo.forEach(t),DBr=i(Je),i5=n(Je,"LI",{});var Seo=s(i5);z7e=n(Seo,"STRONG",{});var Cpa=s(z7e);GBr=r(Cpa,"unispeech-sat"),Cpa.forEach(t),OBr=r(Seo," \u2014 "),ate=n(Seo,"A",{href:!0});var wpa=s(ate);VBr=r(wpa,"UniSpeechSatForSequenceClassification"),wpa.forEach(t),XBr=r(Seo," (UniSpeechSat model)"),Seo.forEach(t),zBr=i(Je),d5=n(Je,"LI",{});var Reo=s(d5);Q7e=n(Reo,"STRONG",{});var Apa=s(Q7e);QBr=r(Apa,"wav2vec2"),Apa.forEach(t),WBr=r(Reo," \u2014 "),nte=n(Reo,"A",{href:!0});var Lpa=s(nte);UBr=r(Lpa,"Wav2Vec2ForSequenceClassification"),Lpa.forEach(t),HBr=r(Reo," (Wav2Vec2 model)"),Reo.forEach(t),JBr=i(Je),m5=n(Je,"LI",{});var Peo=s(m5);W7e=n(Peo,"STRONG",{});var ypa=s(W7e);YBr=r(ypa,"wav2vec2-conformer"),ypa.forEach(t),ZBr=r(Peo," \u2014 "),ste=n(Peo,"A",{href:!0});var xpa=s(ste);KBr=r(xpa,"Wav2Vec2ConformerForSequenceClassification"),xpa.forEach(t),eIr=r(Peo," (Wav2Vec2-Conformer model)"),Peo.forEach(t),oIr=i(Je),c5=n(Je,"LI",{});var Beo=s(c5);U7e=n(Beo,"STRONG",{});var $pa=s(U7e);rIr=r($pa,"wavlm"),$pa.forEach(t),tIr=r(Beo," \u2014 "),lte=n(Beo,"A",{href:!0});var kpa=s(lte);aIr=r(kpa,"WavLMForSequenceClassification"),kpa.forEach(t),nIr=r(Beo," (WavLM model)"),Beo.forEach(t),Je.forEach(t),sIr=i(Ha),f5=n(Ha,"P",{});var Ieo=s(f5);lIr=r(Ieo,"The model is set in evaluation mode by default using "),H7e=n(Ieo,"CODE",{});var Spa=s(H7e);iIr=r(Spa,"model.eval()"),Spa.forEach(t),dIr=r(Ieo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),J7e=n(Ieo,"CODE",{});var Rpa=s(J7e);mIr=r(Rpa,"model.train()"),Rpa.forEach(t),Ieo.forEach(t),cIr=i(Ha),T(g5.$$.fragment,Ha),Ha.forEach(t),mi.forEach(t),Hio=i(c),Om=n(c,"H2",{class:!0});var bco=s(Om);h5=n(bco,"A",{id:!0,class:!0,href:!0});var Ppa=s(h5);Y7e=n(Ppa,"SPAN",{});var Bpa=s(Y7e);T(IR.$$.fragment,Bpa),Bpa.forEach(t),Ppa.forEach(t),fIr=i(bco),Z7e=n(bco,"SPAN",{});var Ipa=s(Z7e);gIr=r(Ipa,"AutoModelForAudioFrameClassification"),Ipa.forEach(t),bco.forEach(t),Jio=i(c),ar=n(c,"DIV",{class:!0});var ci=s(ar);T(NR.$$.fragment,ci),hIr=i(ci),Vm=n(ci,"P",{});var lge=s(Vm);uIr=r(lge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),ite=n(lge,"A",{href:!0});var Npa=s(ite);pIr=r(Npa,"from_pretrained()"),Npa.forEach(t),_Ir=r(lge," class method or the "),dte=n(lge,"A",{href:!0});var qpa=s(dte);bIr=r(qpa,"from_config()"),qpa.forEach(t),vIr=r(lge,` class
method.`),lge.forEach(t),FIr=i(ci),qR=n(ci,"P",{});var vco=s(qR);TIr=r(vco,"This class cannot be instantiated directly using "),K7e=n(vco,"CODE",{});var jpa=s(K7e);MIr=r(jpa,"__init__()"),jpa.forEach(t),EIr=r(vco," (throws an error)."),vco.forEach(t),CIr=i(ci),zt=n(ci,"DIV",{class:!0});var Ux=s(zt);T(jR.$$.fragment,Ux),wIr=i(Ux),e8e=n(Ux,"P",{});var Dpa=s(e8e);AIr=r(Dpa,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),Dpa.forEach(t),LIr=i(Ux),Xm=n(Ux,"P",{});var ige=s(Xm);yIr=r(ige,`Note:
Loading a model from its configuration file does `),o8e=n(ige,"STRONG",{});var Gpa=s(o8e);xIr=r(Gpa,"not"),Gpa.forEach(t),$Ir=r(ige,` load the model weights. It only affects the
model\u2019s configuration. Use `),mte=n(ige,"A",{href:!0});var Opa=s(mte);kIr=r(Opa,"from_pretrained()"),Opa.forEach(t),SIr=r(ige," to load the model weights."),ige.forEach(t),RIr=i(Ux),T(u5.$$.fragment,Ux),Ux.forEach(t),PIr=i(ci),Mo=n(ci,"DIV",{class:!0});var Ja=s(Mo);T(DR.$$.fragment,Ja),BIr=i(Ja),r8e=n(Ja,"P",{});var Vpa=s(r8e);IIr=r(Vpa,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Vpa.forEach(t),NIr=i(Ja),kn=n(Ja,"P",{});var Hx=s(kn);qIr=r(Hx,"The model class to instantiate is selected based on the "),t8e=n(Hx,"CODE",{});var Xpa=s(t8e);jIr=r(Xpa,"model_type"),Xpa.forEach(t),DIr=r(Hx,` property of the config object (either
passed as an argument or loaded from `),a8e=n(Hx,"CODE",{});var zpa=s(a8e);GIr=r(zpa,"pretrained_model_name_or_path"),zpa.forEach(t),OIr=r(Hx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n8e=n(Hx,"CODE",{});var Qpa=s(n8e);VIr=r(Qpa,"pretrained_model_name_or_path"),Qpa.forEach(t),XIr=r(Hx,":"),Hx.forEach(t),zIr=i(Ja),Ft=n(Ja,"UL",{});var fi=s(Ft);p5=n(fi,"LI",{});var Neo=s(p5);s8e=n(Neo,"STRONG",{});var Wpa=s(s8e);QIr=r(Wpa,"data2vec-audio"),Wpa.forEach(t),WIr=r(Neo," \u2014 "),cte=n(Neo,"A",{href:!0});var Upa=s(cte);UIr=r(Upa,"Data2VecAudioForAudioFrameClassification"),Upa.forEach(t),HIr=r(Neo," (Data2VecAudio model)"),Neo.forEach(t),JIr=i(fi),_5=n(fi,"LI",{});var qeo=s(_5);l8e=n(qeo,"STRONG",{});var Hpa=s(l8e);YIr=r(Hpa,"unispeech-sat"),Hpa.forEach(t),ZIr=r(qeo," \u2014 "),fte=n(qeo,"A",{href:!0});var Jpa=s(fte);KIr=r(Jpa,"UniSpeechSatForAudioFrameClassification"),Jpa.forEach(t),eNr=r(qeo," (UniSpeechSat model)"),qeo.forEach(t),oNr=i(fi),b5=n(fi,"LI",{});var jeo=s(b5);i8e=n(jeo,"STRONG",{});var Ypa=s(i8e);rNr=r(Ypa,"wav2vec2"),Ypa.forEach(t),tNr=r(jeo," \u2014 "),gte=n(jeo,"A",{href:!0});var Zpa=s(gte);aNr=r(Zpa,"Wav2Vec2ForAudioFrameClassification"),Zpa.forEach(t),nNr=r(jeo," (Wav2Vec2 model)"),jeo.forEach(t),sNr=i(fi),v5=n(fi,"LI",{});var Deo=s(v5);d8e=n(Deo,"STRONG",{});var Kpa=s(d8e);lNr=r(Kpa,"wav2vec2-conformer"),Kpa.forEach(t),iNr=r(Deo," \u2014 "),hte=n(Deo,"A",{href:!0});var e_a=s(hte);dNr=r(e_a,"Wav2Vec2ConformerForAudioFrameClassification"),e_a.forEach(t),mNr=r(Deo," (Wav2Vec2-Conformer model)"),Deo.forEach(t),cNr=i(fi),F5=n(fi,"LI",{});var Geo=s(F5);m8e=n(Geo,"STRONG",{});var o_a=s(m8e);fNr=r(o_a,"wavlm"),o_a.forEach(t),gNr=r(Geo," \u2014 "),ute=n(Geo,"A",{href:!0});var r_a=s(ute);hNr=r(r_a,"WavLMForAudioFrameClassification"),r_a.forEach(t),uNr=r(Geo," (WavLM model)"),Geo.forEach(t),fi.forEach(t),pNr=i(Ja),T5=n(Ja,"P",{});var Oeo=s(T5);_Nr=r(Oeo,"The model is set in evaluation mode by default using "),c8e=n(Oeo,"CODE",{});var t_a=s(c8e);bNr=r(t_a,"model.eval()"),t_a.forEach(t),vNr=r(Oeo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),f8e=n(Oeo,"CODE",{});var a_a=s(f8e);FNr=r(a_a,"model.train()"),a_a.forEach(t),Oeo.forEach(t),TNr=i(Ja),T(M5.$$.fragment,Ja),Ja.forEach(t),ci.forEach(t),Yio=i(c),zm=n(c,"H2",{class:!0});var Fco=s(zm);E5=n(Fco,"A",{id:!0,class:!0,href:!0});var n_a=s(E5);g8e=n(n_a,"SPAN",{});var s_a=s(g8e);T(GR.$$.fragment,s_a),s_a.forEach(t),n_a.forEach(t),MNr=i(Fco),h8e=n(Fco,"SPAN",{});var l_a=s(h8e);ENr=r(l_a,"AutoModelForCTC"),l_a.forEach(t),Fco.forEach(t),Zio=i(c),nr=n(c,"DIV",{class:!0});var gi=s(nr);T(OR.$$.fragment,gi),CNr=i(gi),Qm=n(gi,"P",{});var dge=s(Qm);wNr=r(dge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),pte=n(dge,"A",{href:!0});var i_a=s(pte);ANr=r(i_a,"from_pretrained()"),i_a.forEach(t),LNr=r(dge," class method or the "),_te=n(dge,"A",{href:!0});var d_a=s(_te);yNr=r(d_a,"from_config()"),d_a.forEach(t),xNr=r(dge,` class
method.`),dge.forEach(t),$Nr=i(gi),VR=n(gi,"P",{});var Tco=s(VR);kNr=r(Tco,"This class cannot be instantiated directly using "),u8e=n(Tco,"CODE",{});var m_a=s(u8e);SNr=r(m_a,"__init__()"),m_a.forEach(t),RNr=r(Tco," (throws an error)."),Tco.forEach(t),PNr=i(gi),Qt=n(gi,"DIV",{class:!0});var Jx=s(Qt);T(XR.$$.fragment,Jx),BNr=i(Jx),p8e=n(Jx,"P",{});var c_a=s(p8e);INr=r(c_a,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),c_a.forEach(t),NNr=i(Jx),Wm=n(Jx,"P",{});var mge=s(Wm);qNr=r(mge,`Note:
Loading a model from its configuration file does `),_8e=n(mge,"STRONG",{});var f_a=s(_8e);jNr=r(f_a,"not"),f_a.forEach(t),DNr=r(mge,` load the model weights. It only affects the
model\u2019s configuration. Use `),bte=n(mge,"A",{href:!0});var g_a=s(bte);GNr=r(g_a,"from_pretrained()"),g_a.forEach(t),ONr=r(mge," to load the model weights."),mge.forEach(t),VNr=i(Jx),T(C5.$$.fragment,Jx),Jx.forEach(t),XNr=i(gi),Eo=n(gi,"DIV",{class:!0});var Ya=s(Eo);T(zR.$$.fragment,Ya),zNr=i(Ya),b8e=n(Ya,"P",{});var h_a=s(b8e);QNr=r(h_a,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),h_a.forEach(t),WNr=i(Ya),Sn=n(Ya,"P",{});var Yx=s(Sn);UNr=r(Yx,"The model class to instantiate is selected based on the "),v8e=n(Yx,"CODE",{});var u_a=s(v8e);HNr=r(u_a,"model_type"),u_a.forEach(t),JNr=r(Yx,` property of the config object (either
passed as an argument or loaded from `),F8e=n(Yx,"CODE",{});var p_a=s(F8e);YNr=r(p_a,"pretrained_model_name_or_path"),p_a.forEach(t),ZNr=r(Yx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T8e=n(Yx,"CODE",{});var __a=s(T8e);KNr=r(__a,"pretrained_model_name_or_path"),__a.forEach(t),eqr=r(Yx,":"),Yx.forEach(t),oqr=i(Ya),xe=n(Ya,"UL",{});var qe=s(xe);w5=n(qe,"LI",{});var Veo=s(w5);M8e=n(Veo,"STRONG",{});var b_a=s(M8e);rqr=r(b_a,"data2vec-audio"),b_a.forEach(t),tqr=r(Veo," \u2014 "),vte=n(Veo,"A",{href:!0});var v_a=s(vte);aqr=r(v_a,"Data2VecAudioForCTC"),v_a.forEach(t),nqr=r(Veo," (Data2VecAudio model)"),Veo.forEach(t),sqr=i(qe),A5=n(qe,"LI",{});var Xeo=s(A5);E8e=n(Xeo,"STRONG",{});var F_a=s(E8e);lqr=r(F_a,"hubert"),F_a.forEach(t),iqr=r(Xeo," \u2014 "),Fte=n(Xeo,"A",{href:!0});var T_a=s(Fte);dqr=r(T_a,"HubertForCTC"),T_a.forEach(t),mqr=r(Xeo," (Hubert model)"),Xeo.forEach(t),cqr=i(qe),L5=n(qe,"LI",{});var zeo=s(L5);C8e=n(zeo,"STRONG",{});var M_a=s(C8e);fqr=r(M_a,"mctct"),M_a.forEach(t),gqr=r(zeo," \u2014 "),Tte=n(zeo,"A",{href:!0});var E_a=s(Tte);hqr=r(E_a,"MCTCTForCTC"),E_a.forEach(t),uqr=r(zeo," (M-CTC-T model)"),zeo.forEach(t),pqr=i(qe),y5=n(qe,"LI",{});var Qeo=s(y5);w8e=n(Qeo,"STRONG",{});var C_a=s(w8e);_qr=r(C_a,"sew"),C_a.forEach(t),bqr=r(Qeo," \u2014 "),Mte=n(Qeo,"A",{href:!0});var w_a=s(Mte);vqr=r(w_a,"SEWForCTC"),w_a.forEach(t),Fqr=r(Qeo," (SEW model)"),Qeo.forEach(t),Tqr=i(qe),x5=n(qe,"LI",{});var Weo=s(x5);A8e=n(Weo,"STRONG",{});var A_a=s(A8e);Mqr=r(A_a,"sew-d"),A_a.forEach(t),Eqr=r(Weo," \u2014 "),Ete=n(Weo,"A",{href:!0});var L_a=s(Ete);Cqr=r(L_a,"SEWDForCTC"),L_a.forEach(t),wqr=r(Weo," (SEW-D model)"),Weo.forEach(t),Aqr=i(qe),$5=n(qe,"LI",{});var Ueo=s($5);L8e=n(Ueo,"STRONG",{});var y_a=s(L8e);Lqr=r(y_a,"unispeech"),y_a.forEach(t),yqr=r(Ueo," \u2014 "),Cte=n(Ueo,"A",{href:!0});var x_a=s(Cte);xqr=r(x_a,"UniSpeechForCTC"),x_a.forEach(t),$qr=r(Ueo," (UniSpeech model)"),Ueo.forEach(t),kqr=i(qe),k5=n(qe,"LI",{});var Heo=s(k5);y8e=n(Heo,"STRONG",{});var $_a=s(y8e);Sqr=r($_a,"unispeech-sat"),$_a.forEach(t),Rqr=r(Heo," \u2014 "),wte=n(Heo,"A",{href:!0});var k_a=s(wte);Pqr=r(k_a,"UniSpeechSatForCTC"),k_a.forEach(t),Bqr=r(Heo," (UniSpeechSat model)"),Heo.forEach(t),Iqr=i(qe),S5=n(qe,"LI",{});var Jeo=s(S5);x8e=n(Jeo,"STRONG",{});var S_a=s(x8e);Nqr=r(S_a,"wav2vec2"),S_a.forEach(t),qqr=r(Jeo," \u2014 "),Ate=n(Jeo,"A",{href:!0});var R_a=s(Ate);jqr=r(R_a,"Wav2Vec2ForCTC"),R_a.forEach(t),Dqr=r(Jeo," (Wav2Vec2 model)"),Jeo.forEach(t),Gqr=i(qe),R5=n(qe,"LI",{});var Yeo=s(R5);$8e=n(Yeo,"STRONG",{});var P_a=s($8e);Oqr=r(P_a,"wav2vec2-conformer"),P_a.forEach(t),Vqr=r(Yeo," \u2014 "),Lte=n(Yeo,"A",{href:!0});var B_a=s(Lte);Xqr=r(B_a,"Wav2Vec2ConformerForCTC"),B_a.forEach(t),zqr=r(Yeo," (Wav2Vec2-Conformer model)"),Yeo.forEach(t),Qqr=i(qe),P5=n(qe,"LI",{});var Zeo=s(P5);k8e=n(Zeo,"STRONG",{});var I_a=s(k8e);Wqr=r(I_a,"wavlm"),I_a.forEach(t),Uqr=r(Zeo," \u2014 "),yte=n(Zeo,"A",{href:!0});var N_a=s(yte);Hqr=r(N_a,"WavLMForCTC"),N_a.forEach(t),Jqr=r(Zeo," (WavLM model)"),Zeo.forEach(t),qe.forEach(t),Yqr=i(Ya),B5=n(Ya,"P",{});var Keo=s(B5);Zqr=r(Keo,"The model is set in evaluation mode by default using "),S8e=n(Keo,"CODE",{});var q_a=s(S8e);Kqr=r(q_a,"model.eval()"),q_a.forEach(t),ejr=r(Keo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),R8e=n(Keo,"CODE",{});var j_a=s(R8e);ojr=r(j_a,"model.train()"),j_a.forEach(t),Keo.forEach(t),rjr=i(Ya),T(I5.$$.fragment,Ya),Ya.forEach(t),gi.forEach(t),Kio=i(c),Um=n(c,"H2",{class:!0});var Mco=s(Um);N5=n(Mco,"A",{id:!0,class:!0,href:!0});var D_a=s(N5);P8e=n(D_a,"SPAN",{});var G_a=s(P8e);T(QR.$$.fragment,G_a),G_a.forEach(t),D_a.forEach(t),tjr=i(Mco),B8e=n(Mco,"SPAN",{});var O_a=s(B8e);ajr=r(O_a,"AutoModelForSpeechSeq2Seq"),O_a.forEach(t),Mco.forEach(t),edo=i(c),sr=n(c,"DIV",{class:!0});var hi=s(sr);T(WR.$$.fragment,hi),njr=i(hi),Hm=n(hi,"P",{});var cge=s(Hm);sjr=r(cge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),xte=n(cge,"A",{href:!0});var V_a=s(xte);ljr=r(V_a,"from_pretrained()"),V_a.forEach(t),ijr=r(cge," class method or the "),$te=n(cge,"A",{href:!0});var X_a=s($te);djr=r(X_a,"from_config()"),X_a.forEach(t),mjr=r(cge,` class
method.`),cge.forEach(t),cjr=i(hi),UR=n(hi,"P",{});var Eco=s(UR);fjr=r(Eco,"This class cannot be instantiated directly using "),I8e=n(Eco,"CODE",{});var z_a=s(I8e);gjr=r(z_a,"__init__()"),z_a.forEach(t),hjr=r(Eco," (throws an error)."),Eco.forEach(t),ujr=i(hi),Wt=n(hi,"DIV",{class:!0});var Zx=s(Wt);T(HR.$$.fragment,Zx),pjr=i(Zx),N8e=n(Zx,"P",{});var Q_a=s(N8e);_jr=r(Q_a,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Q_a.forEach(t),bjr=i(Zx),Jm=n(Zx,"P",{});var fge=s(Jm);vjr=r(fge,`Note:
Loading a model from its configuration file does `),q8e=n(fge,"STRONG",{});var W_a=s(q8e);Fjr=r(W_a,"not"),W_a.forEach(t),Tjr=r(fge,` load the model weights. It only affects the
model\u2019s configuration. Use `),kte=n(fge,"A",{href:!0});var U_a=s(kte);Mjr=r(U_a,"from_pretrained()"),U_a.forEach(t),Ejr=r(fge," to load the model weights."),fge.forEach(t),Cjr=i(Zx),T(q5.$$.fragment,Zx),Zx.forEach(t),wjr=i(hi),Co=n(hi,"DIV",{class:!0});var Za=s(Co);T(JR.$$.fragment,Za),Ajr=i(Za),j8e=n(Za,"P",{});var H_a=s(j8e);Ljr=r(H_a,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),H_a.forEach(t),yjr=i(Za),Rn=n(Za,"P",{});var Kx=s(Rn);xjr=r(Kx,"The model class to instantiate is selected based on the "),D8e=n(Kx,"CODE",{});var J_a=s(D8e);$jr=r(J_a,"model_type"),J_a.forEach(t),kjr=r(Kx,` property of the config object (either
passed as an argument or loaded from `),G8e=n(Kx,"CODE",{});var Y_a=s(G8e);Sjr=r(Y_a,"pretrained_model_name_or_path"),Y_a.forEach(t),Rjr=r(Kx,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O8e=n(Kx,"CODE",{});var Z_a=s(O8e);Pjr=r(Z_a,"pretrained_model_name_or_path"),Z_a.forEach(t),Bjr=r(Kx,":"),Kx.forEach(t),Ijr=i(Za),Ym=n(Za,"UL",{});var gge=s(Ym);j5=n(gge,"LI",{});var eoo=s(j5);V8e=n(eoo,"STRONG",{});var K_a=s(V8e);Njr=r(K_a,"speech-encoder-decoder"),K_a.forEach(t),qjr=r(eoo," \u2014 "),Ste=n(eoo,"A",{href:!0});var e1a=s(Ste);jjr=r(e1a,"SpeechEncoderDecoderModel"),e1a.forEach(t),Djr=r(eoo," (Speech Encoder decoder model)"),eoo.forEach(t),Gjr=i(gge),D5=n(gge,"LI",{});var ooo=s(D5);X8e=n(ooo,"STRONG",{});var o1a=s(X8e);Ojr=r(o1a,"speech_to_text"),o1a.forEach(t),Vjr=r(ooo," \u2014 "),Rte=n(ooo,"A",{href:!0});var r1a=s(Rte);Xjr=r(r1a,"Speech2TextForConditionalGeneration"),r1a.forEach(t),zjr=r(ooo," (Speech2Text model)"),ooo.forEach(t),Qjr=i(gge),G5=n(gge,"LI",{});var roo=s(G5);z8e=n(roo,"STRONG",{});var t1a=s(z8e);Wjr=r(t1a,"whisper"),t1a.forEach(t),Ujr=r(roo," \u2014 "),Pte=n(roo,"A",{href:!0});var a1a=s(Pte);Hjr=r(a1a,"WhisperForConditionalGeneration"),a1a.forEach(t),Jjr=r(roo," (Whisper model)"),roo.forEach(t),gge.forEach(t),Yjr=i(Za),O5=n(Za,"P",{});var too=s(O5);Zjr=r(too,"The model is set in evaluation mode by default using "),Q8e=n(too,"CODE",{});var n1a=s(Q8e);Kjr=r(n1a,"model.eval()"),n1a.forEach(t),eDr=r(too,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),W8e=n(too,"CODE",{});var s1a=s(W8e);oDr=r(s1a,"model.train()"),s1a.forEach(t),too.forEach(t),rDr=i(Za),T(V5.$$.fragment,Za),Za.forEach(t),hi.forEach(t),odo=i(c),Zm=n(c,"H2",{class:!0});var Cco=s(Zm);X5=n(Cco,"A",{id:!0,class:!0,href:!0});var l1a=s(X5);U8e=n(l1a,"SPAN",{});var i1a=s(U8e);T(YR.$$.fragment,i1a),i1a.forEach(t),l1a.forEach(t),tDr=i(Cco),H8e=n(Cco,"SPAN",{});var d1a=s(H8e);aDr=r(d1a,"AutoModelForAudioXVector"),d1a.forEach(t),Cco.forEach(t),rdo=i(c),lr=n(c,"DIV",{class:!0});var ui=s(lr);T(ZR.$$.fragment,ui),nDr=i(ui),Km=n(ui,"P",{});var hge=s(Km);sDr=r(hge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),Bte=n(hge,"A",{href:!0});var m1a=s(Bte);lDr=r(m1a,"from_pretrained()"),m1a.forEach(t),iDr=r(hge," class method or the "),Ite=n(hge,"A",{href:!0});var c1a=s(Ite);dDr=r(c1a,"from_config()"),c1a.forEach(t),mDr=r(hge,` class
method.`),hge.forEach(t),cDr=i(ui),KR=n(ui,"P",{});var wco=s(KR);fDr=r(wco,"This class cannot be instantiated directly using "),J8e=n(wco,"CODE",{});var f1a=s(J8e);gDr=r(f1a,"__init__()"),f1a.forEach(t),hDr=r(wco," (throws an error)."),wco.forEach(t),uDr=i(ui),Ut=n(ui,"DIV",{class:!0});var e$=s(Ut);T(eP.$$.fragment,e$),pDr=i(e$),Y8e=n(e$,"P",{});var g1a=s(Y8e);_Dr=r(g1a,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),g1a.forEach(t),bDr=i(e$),ec=n(e$,"P",{});var uge=s(ec);vDr=r(uge,`Note:
Loading a model from its configuration file does `),Z8e=n(uge,"STRONG",{});var h1a=s(Z8e);FDr=r(h1a,"not"),h1a.forEach(t),TDr=r(uge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Nte=n(uge,"A",{href:!0});var u1a=s(Nte);MDr=r(u1a,"from_pretrained()"),u1a.forEach(t),EDr=r(uge," to load the model weights."),uge.forEach(t),CDr=i(e$),T(z5.$$.fragment,e$),e$.forEach(t),wDr=i(ui),wo=n(ui,"DIV",{class:!0});var Ka=s(wo);T(oP.$$.fragment,Ka),ADr=i(Ka),K8e=n(Ka,"P",{});var p1a=s(K8e);LDr=r(p1a,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),p1a.forEach(t),yDr=i(Ka),Pn=n(Ka,"P",{});var o$=s(Pn);xDr=r(o$,"The model class to instantiate is selected based on the "),eLe=n(o$,"CODE",{});var _1a=s(eLe);$Dr=r(_1a,"model_type"),_1a.forEach(t),kDr=r(o$,` property of the config object (either
passed as an argument or loaded from `),oLe=n(o$,"CODE",{});var b1a=s(oLe);SDr=r(b1a,"pretrained_model_name_or_path"),b1a.forEach(t),RDr=r(o$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rLe=n(o$,"CODE",{});var v1a=s(rLe);PDr=r(v1a,"pretrained_model_name_or_path"),v1a.forEach(t),BDr=r(o$,":"),o$.forEach(t),IDr=i(Ka),Tt=n(Ka,"UL",{});var pi=s(Tt);Q5=n(pi,"LI",{});var aoo=s(Q5);tLe=n(aoo,"STRONG",{});var F1a=s(tLe);NDr=r(F1a,"data2vec-audio"),F1a.forEach(t),qDr=r(aoo," \u2014 "),qte=n(aoo,"A",{href:!0});var T1a=s(qte);jDr=r(T1a,"Data2VecAudioForXVector"),T1a.forEach(t),DDr=r(aoo," (Data2VecAudio model)"),aoo.forEach(t),GDr=i(pi),W5=n(pi,"LI",{});var noo=s(W5);aLe=n(noo,"STRONG",{});var M1a=s(aLe);ODr=r(M1a,"unispeech-sat"),M1a.forEach(t),VDr=r(noo," \u2014 "),jte=n(noo,"A",{href:!0});var E1a=s(jte);XDr=r(E1a,"UniSpeechSatForXVector"),E1a.forEach(t),zDr=r(noo," (UniSpeechSat model)"),noo.forEach(t),QDr=i(pi),U5=n(pi,"LI",{});var soo=s(U5);nLe=n(soo,"STRONG",{});var C1a=s(nLe);WDr=r(C1a,"wav2vec2"),C1a.forEach(t),UDr=r(soo," \u2014 "),Dte=n(soo,"A",{href:!0});var w1a=s(Dte);HDr=r(w1a,"Wav2Vec2ForXVector"),w1a.forEach(t),JDr=r(soo," (Wav2Vec2 model)"),soo.forEach(t),YDr=i(pi),H5=n(pi,"LI",{});var loo=s(H5);sLe=n(loo,"STRONG",{});var A1a=s(sLe);ZDr=r(A1a,"wav2vec2-conformer"),A1a.forEach(t),KDr=r(loo," \u2014 "),Gte=n(loo,"A",{href:!0});var L1a=s(Gte);eGr=r(L1a,"Wav2Vec2ConformerForXVector"),L1a.forEach(t),oGr=r(loo," (Wav2Vec2-Conformer model)"),loo.forEach(t),rGr=i(pi),J5=n(pi,"LI",{});var ioo=s(J5);lLe=n(ioo,"STRONG",{});var y1a=s(lLe);tGr=r(y1a,"wavlm"),y1a.forEach(t),aGr=r(ioo," \u2014 "),Ote=n(ioo,"A",{href:!0});var x1a=s(Ote);nGr=r(x1a,"WavLMForXVector"),x1a.forEach(t),sGr=r(ioo," (WavLM model)"),ioo.forEach(t),pi.forEach(t),lGr=i(Ka),Y5=n(Ka,"P",{});var doo=s(Y5);iGr=r(doo,"The model is set in evaluation mode by default using "),iLe=n(doo,"CODE",{});var $1a=s(iLe);dGr=r($1a,"model.eval()"),$1a.forEach(t),mGr=r(doo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),dLe=n(doo,"CODE",{});var k1a=s(dLe);cGr=r(k1a,"model.train()"),k1a.forEach(t),doo.forEach(t),fGr=i(Ka),T(Z5.$$.fragment,Ka),Ka.forEach(t),ui.forEach(t),tdo=i(c),oc=n(c,"H2",{class:!0});var Aco=s(oc);K5=n(Aco,"A",{id:!0,class:!0,href:!0});var S1a=s(K5);mLe=n(S1a,"SPAN",{});var R1a=s(mLe);T(rP.$$.fragment,R1a),R1a.forEach(t),S1a.forEach(t),gGr=i(Aco),cLe=n(Aco,"SPAN",{});var P1a=s(cLe);hGr=r(P1a,"AutoModelForMaskedImageModeling"),P1a.forEach(t),Aco.forEach(t),ado=i(c),ir=n(c,"DIV",{class:!0});var _i=s(ir);T(tP.$$.fragment,_i),uGr=i(_i),rc=n(_i,"P",{});var pge=s(rc);pGr=r(pge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),Vte=n(pge,"A",{href:!0});var B1a=s(Vte);_Gr=r(B1a,"from_pretrained()"),B1a.forEach(t),bGr=r(pge," class method or the "),Xte=n(pge,"A",{href:!0});var I1a=s(Xte);vGr=r(I1a,"from_config()"),I1a.forEach(t),FGr=r(pge,` class
method.`),pge.forEach(t),TGr=i(_i),aP=n(_i,"P",{});var Lco=s(aP);MGr=r(Lco,"This class cannot be instantiated directly using "),fLe=n(Lco,"CODE",{});var N1a=s(fLe);EGr=r(N1a,"__init__()"),N1a.forEach(t),CGr=r(Lco," (throws an error)."),Lco.forEach(t),wGr=i(_i),Ht=n(_i,"DIV",{class:!0});var r$=s(Ht);T(nP.$$.fragment,r$),AGr=i(r$),gLe=n(r$,"P",{});var q1a=s(gLe);LGr=r(q1a,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),q1a.forEach(t),yGr=i(r$),tc=n(r$,"P",{});var _ge=s(tc);xGr=r(_ge,`Note:
Loading a model from its configuration file does `),hLe=n(_ge,"STRONG",{});var j1a=s(hLe);$Gr=r(j1a,"not"),j1a.forEach(t),kGr=r(_ge,` load the model weights. It only affects the
model\u2019s configuration. Use `),zte=n(_ge,"A",{href:!0});var D1a=s(zte);SGr=r(D1a,"from_pretrained()"),D1a.forEach(t),RGr=r(_ge," to load the model weights."),_ge.forEach(t),PGr=i(r$),T(e0.$$.fragment,r$),r$.forEach(t),BGr=i(_i),Ao=n(_i,"DIV",{class:!0});var en=s(Ao);T(sP.$$.fragment,en),IGr=i(en),uLe=n(en,"P",{});var G1a=s(uLe);NGr=r(G1a,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),G1a.forEach(t),qGr=i(en),Bn=n(en,"P",{});var t$=s(Bn);jGr=r(t$,"The model class to instantiate is selected based on the "),pLe=n(t$,"CODE",{});var O1a=s(pLe);DGr=r(O1a,"model_type"),O1a.forEach(t),GGr=r(t$,` property of the config object (either
passed as an argument or loaded from `),_Le=n(t$,"CODE",{});var V1a=s(_Le);OGr=r(V1a,"pretrained_model_name_or_path"),V1a.forEach(t),VGr=r(t$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bLe=n(t$,"CODE",{});var X1a=s(bLe);XGr=r(X1a,"pretrained_model_name_or_path"),X1a.forEach(t),zGr=r(t$,":"),t$.forEach(t),QGr=i(en),In=n(en,"UL",{});var a$=s(In);o0=n(a$,"LI",{});var moo=s(o0);vLe=n(moo,"STRONG",{});var z1a=s(vLe);WGr=r(z1a,"deit"),z1a.forEach(t),UGr=r(moo," \u2014 "),Qte=n(moo,"A",{href:!0});var Q1a=s(Qte);HGr=r(Q1a,"DeiTForMaskedImageModeling"),Q1a.forEach(t),JGr=r(moo," (DeiT model)"),moo.forEach(t),YGr=i(a$),r0=n(a$,"LI",{});var coo=s(r0);FLe=n(coo,"STRONG",{});var W1a=s(FLe);ZGr=r(W1a,"swin"),W1a.forEach(t),KGr=r(coo," \u2014 "),Wte=n(coo,"A",{href:!0});var U1a=s(Wte);eOr=r(U1a,"SwinForMaskedImageModeling"),U1a.forEach(t),oOr=r(coo," (Swin Transformer model)"),coo.forEach(t),rOr=i(a$),t0=n(a$,"LI",{});var foo=s(t0);TLe=n(foo,"STRONG",{});var H1a=s(TLe);tOr=r(H1a,"swinv2"),H1a.forEach(t),aOr=r(foo," \u2014 "),Ute=n(foo,"A",{href:!0});var J1a=s(Ute);nOr=r(J1a,"Swinv2ForMaskedImageModeling"),J1a.forEach(t),sOr=r(foo," (Swin Transformer V2 model)"),foo.forEach(t),lOr=i(a$),a0=n(a$,"LI",{});var goo=s(a0);MLe=n(goo,"STRONG",{});var Y1a=s(MLe);iOr=r(Y1a,"vit"),Y1a.forEach(t),dOr=r(goo," \u2014 "),Hte=n(goo,"A",{href:!0});var Z1a=s(Hte);mOr=r(Z1a,"ViTForMaskedImageModeling"),Z1a.forEach(t),cOr=r(goo," (ViT model)"),goo.forEach(t),a$.forEach(t),fOr=i(en),n0=n(en,"P",{});var hoo=s(n0);gOr=r(hoo,"The model is set in evaluation mode by default using "),ELe=n(hoo,"CODE",{});var K1a=s(ELe);hOr=r(K1a,"model.eval()"),K1a.forEach(t),uOr=r(hoo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),CLe=n(hoo,"CODE",{});var e2a=s(CLe);pOr=r(e2a,"model.train()"),e2a.forEach(t),hoo.forEach(t),_Or=i(en),T(s0.$$.fragment,en),en.forEach(t),_i.forEach(t),ndo=i(c),ac=n(c,"H2",{class:!0});var yco=s(ac);l0=n(yco,"A",{id:!0,class:!0,href:!0});var o2a=s(l0);wLe=n(o2a,"SPAN",{});var r2a=s(wLe);T(lP.$$.fragment,r2a),r2a.forEach(t),o2a.forEach(t),bOr=i(yco),ALe=n(yco,"SPAN",{});var t2a=s(ALe);vOr=r(t2a,"AutoModelForObjectDetection"),t2a.forEach(t),yco.forEach(t),sdo=i(c),dr=n(c,"DIV",{class:!0});var bi=s(dr);T(iP.$$.fragment,bi),FOr=i(bi),nc=n(bi,"P",{});var bge=s(nc);TOr=r(bge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),Jte=n(bge,"A",{href:!0});var a2a=s(Jte);MOr=r(a2a,"from_pretrained()"),a2a.forEach(t),EOr=r(bge," class method or the "),Yte=n(bge,"A",{href:!0});var n2a=s(Yte);COr=r(n2a,"from_config()"),n2a.forEach(t),wOr=r(bge,` class
method.`),bge.forEach(t),AOr=i(bi),dP=n(bi,"P",{});var xco=s(dP);LOr=r(xco,"This class cannot be instantiated directly using "),LLe=n(xco,"CODE",{});var s2a=s(LLe);yOr=r(s2a,"__init__()"),s2a.forEach(t),xOr=r(xco," (throws an error)."),xco.forEach(t),$Or=i(bi),Jt=n(bi,"DIV",{class:!0});var n$=s(Jt);T(mP.$$.fragment,n$),kOr=i(n$),yLe=n(n$,"P",{});var l2a=s(yLe);SOr=r(l2a,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),l2a.forEach(t),ROr=i(n$),sc=n(n$,"P",{});var vge=s(sc);POr=r(vge,`Note:
Loading a model from its configuration file does `),xLe=n(vge,"STRONG",{});var i2a=s(xLe);BOr=r(i2a,"not"),i2a.forEach(t),IOr=r(vge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zte=n(vge,"A",{href:!0});var d2a=s(Zte);NOr=r(d2a,"from_pretrained()"),d2a.forEach(t),qOr=r(vge," to load the model weights."),vge.forEach(t),jOr=i(n$),T(i0.$$.fragment,n$),n$.forEach(t),DOr=i(bi),Lo=n(bi,"DIV",{class:!0});var on=s(Lo);T(cP.$$.fragment,on),GOr=i(on),$Le=n(on,"P",{});var m2a=s($Le);OOr=r(m2a,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),m2a.forEach(t),VOr=i(on),Nn=n(on,"P",{});var s$=s(Nn);XOr=r(s$,"The model class to instantiate is selected based on the "),kLe=n(s$,"CODE",{});var c2a=s(kLe);zOr=r(c2a,"model_type"),c2a.forEach(t),QOr=r(s$,` property of the config object (either
passed as an argument or loaded from `),SLe=n(s$,"CODE",{});var f2a=s(SLe);WOr=r(f2a,"pretrained_model_name_or_path"),f2a.forEach(t),UOr=r(s$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RLe=n(s$,"CODE",{});var g2a=s(RLe);HOr=r(g2a,"pretrained_model_name_or_path"),g2a.forEach(t),JOr=r(s$,":"),s$.forEach(t),YOr=i(on),Mt=n(on,"UL",{});var vi=s(Mt);d0=n(vi,"LI",{});var uoo=s(d0);PLe=n(uoo,"STRONG",{});var h2a=s(PLe);ZOr=r(h2a,"conditional_detr"),h2a.forEach(t),KOr=r(uoo," \u2014 "),Kte=n(uoo,"A",{href:!0});var u2a=s(Kte);eVr=r(u2a,"ConditionalDetrForObjectDetection"),u2a.forEach(t),oVr=r(uoo," (Conditional DETR model)"),uoo.forEach(t),rVr=i(vi),m0=n(vi,"LI",{});var poo=s(m0);BLe=n(poo,"STRONG",{});var p2a=s(BLe);tVr=r(p2a,"deformable_detr"),p2a.forEach(t),aVr=r(poo," \u2014 "),eae=n(poo,"A",{href:!0});var _2a=s(eae);nVr=r(_2a,"DeformableDetrForObjectDetection"),_2a.forEach(t),sVr=r(poo," (Deformable DETR model)"),poo.forEach(t),lVr=i(vi),c0=n(vi,"LI",{});var _oo=s(c0);ILe=n(_oo,"STRONG",{});var b2a=s(ILe);iVr=r(b2a,"detr"),b2a.forEach(t),dVr=r(_oo," \u2014 "),oae=n(_oo,"A",{href:!0});var v2a=s(oae);mVr=r(v2a,"DetrForObjectDetection"),v2a.forEach(t),cVr=r(_oo," (DETR model)"),_oo.forEach(t),fVr=i(vi),f0=n(vi,"LI",{});var boo=s(f0);NLe=n(boo,"STRONG",{});var F2a=s(NLe);gVr=r(F2a,"table-transformer"),F2a.forEach(t),hVr=r(boo," \u2014 "),rae=n(boo,"A",{href:!0});var T2a=s(rae);uVr=r(T2a,"TableTransformerForObjectDetection"),T2a.forEach(t),pVr=r(boo," (Table Transformer model)"),boo.forEach(t),_Vr=i(vi),g0=n(vi,"LI",{});var voo=s(g0);qLe=n(voo,"STRONG",{});var M2a=s(qLe);bVr=r(M2a,"yolos"),M2a.forEach(t),vVr=r(voo," \u2014 "),tae=n(voo,"A",{href:!0});var E2a=s(tae);FVr=r(E2a,"YolosForObjectDetection"),E2a.forEach(t),TVr=r(voo," (YOLOS model)"),voo.forEach(t),vi.forEach(t),MVr=i(on),h0=n(on,"P",{});var Foo=s(h0);EVr=r(Foo,"The model is set in evaluation mode by default using "),jLe=n(Foo,"CODE",{});var C2a=s(jLe);CVr=r(C2a,"model.eval()"),C2a.forEach(t),wVr=r(Foo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),DLe=n(Foo,"CODE",{});var w2a=s(DLe);AVr=r(w2a,"model.train()"),w2a.forEach(t),Foo.forEach(t),LVr=i(on),T(u0.$$.fragment,on),on.forEach(t),bi.forEach(t),ldo=i(c),lc=n(c,"H2",{class:!0});var $co=s(lc);p0=n($co,"A",{id:!0,class:!0,href:!0});var A2a=s(p0);GLe=n(A2a,"SPAN",{});var L2a=s(GLe);T(fP.$$.fragment,L2a),L2a.forEach(t),A2a.forEach(t),yVr=i($co),OLe=n($co,"SPAN",{});var y2a=s(OLe);xVr=r(y2a,"AutoModelForImageSegmentation"),y2a.forEach(t),$co.forEach(t),ido=i(c),mr=n(c,"DIV",{class:!0});var Fi=s(mr);T(gP.$$.fragment,Fi),$Vr=i(Fi),ic=n(Fi,"P",{});var Fge=s(ic);kVr=r(Fge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),aae=n(Fge,"A",{href:!0});var x2a=s(aae);SVr=r(x2a,"from_pretrained()"),x2a.forEach(t),RVr=r(Fge," class method or the "),nae=n(Fge,"A",{href:!0});var $2a=s(nae);PVr=r($2a,"from_config()"),$2a.forEach(t),BVr=r(Fge,` class
method.`),Fge.forEach(t),IVr=i(Fi),hP=n(Fi,"P",{});var kco=s(hP);NVr=r(kco,"This class cannot be instantiated directly using "),VLe=n(kco,"CODE",{});var k2a=s(VLe);qVr=r(k2a,"__init__()"),k2a.forEach(t),jVr=r(kco," (throws an error)."),kco.forEach(t),DVr=i(Fi),Yt=n(Fi,"DIV",{class:!0});var l$=s(Yt);T(uP.$$.fragment,l$),GVr=i(l$),XLe=n(l$,"P",{});var S2a=s(XLe);OVr=r(S2a,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),S2a.forEach(t),VVr=i(l$),dc=n(l$,"P",{});var Tge=s(dc);XVr=r(Tge,`Note:
Loading a model from its configuration file does `),zLe=n(Tge,"STRONG",{});var R2a=s(zLe);zVr=r(R2a,"not"),R2a.forEach(t),QVr=r(Tge,` load the model weights. It only affects the
model\u2019s configuration. Use `),sae=n(Tge,"A",{href:!0});var P2a=s(sae);WVr=r(P2a,"from_pretrained()"),P2a.forEach(t),UVr=r(Tge," to load the model weights."),Tge.forEach(t),HVr=i(l$),T(_0.$$.fragment,l$),l$.forEach(t),JVr=i(Fi),yo=n(Fi,"DIV",{class:!0});var rn=s(yo);T(pP.$$.fragment,rn),YVr=i(rn),QLe=n(rn,"P",{});var B2a=s(QLe);ZVr=r(B2a,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),B2a.forEach(t),KVr=i(rn),qn=n(rn,"P",{});var i$=s(qn);eXr=r(i$,"The model class to instantiate is selected based on the "),WLe=n(i$,"CODE",{});var I2a=s(WLe);oXr=r(I2a,"model_type"),I2a.forEach(t),rXr=r(i$,` property of the config object (either
passed as an argument or loaded from `),ULe=n(i$,"CODE",{});var N2a=s(ULe);tXr=r(N2a,"pretrained_model_name_or_path"),N2a.forEach(t),aXr=r(i$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),HLe=n(i$,"CODE",{});var q2a=s(HLe);nXr=r(q2a,"pretrained_model_name_or_path"),q2a.forEach(t),sXr=r(i$,":"),i$.forEach(t),lXr=i(rn),JLe=n(rn,"UL",{});var j2a=s(JLe);b0=n(j2a,"LI",{});var Too=s(b0);YLe=n(Too,"STRONG",{});var D2a=s(YLe);iXr=r(D2a,"detr"),D2a.forEach(t),dXr=r(Too," \u2014 "),lae=n(Too,"A",{href:!0});var G2a=s(lae);mXr=r(G2a,"DetrForSegmentation"),G2a.forEach(t),cXr=r(Too," (DETR model)"),Too.forEach(t),j2a.forEach(t),fXr=i(rn),v0=n(rn,"P",{});var Moo=s(v0);gXr=r(Moo,"The model is set in evaluation mode by default using "),ZLe=n(Moo,"CODE",{});var O2a=s(ZLe);hXr=r(O2a,"model.eval()"),O2a.forEach(t),uXr=r(Moo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),KLe=n(Moo,"CODE",{});var V2a=s(KLe);pXr=r(V2a,"model.train()"),V2a.forEach(t),Moo.forEach(t),_Xr=i(rn),T(F0.$$.fragment,rn),rn.forEach(t),Fi.forEach(t),ddo=i(c),mc=n(c,"H2",{class:!0});var Sco=s(mc);T0=n(Sco,"A",{id:!0,class:!0,href:!0});var X2a=s(T0);eye=n(X2a,"SPAN",{});var z2a=s(eye);T(_P.$$.fragment,z2a),z2a.forEach(t),X2a.forEach(t),bXr=i(Sco),oye=n(Sco,"SPAN",{});var Q2a=s(oye);vXr=r(Q2a,"AutoModelForSemanticSegmentation"),Q2a.forEach(t),Sco.forEach(t),mdo=i(c),cr=n(c,"DIV",{class:!0});var Ti=s(cr);T(bP.$$.fragment,Ti),FXr=i(Ti),cc=n(Ti,"P",{});var Mge=s(cc);TXr=r(Mge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),iae=n(Mge,"A",{href:!0});var W2a=s(iae);MXr=r(W2a,"from_pretrained()"),W2a.forEach(t),EXr=r(Mge," class method or the "),dae=n(Mge,"A",{href:!0});var U2a=s(dae);CXr=r(U2a,"from_config()"),U2a.forEach(t),wXr=r(Mge,` class
method.`),Mge.forEach(t),AXr=i(Ti),vP=n(Ti,"P",{});var Rco=s(vP);LXr=r(Rco,"This class cannot be instantiated directly using "),rye=n(Rco,"CODE",{});var H2a=s(rye);yXr=r(H2a,"__init__()"),H2a.forEach(t),xXr=r(Rco," (throws an error)."),Rco.forEach(t),$Xr=i(Ti),Zt=n(Ti,"DIV",{class:!0});var d$=s(Zt);T(FP.$$.fragment,d$),kXr=i(d$),tye=n(d$,"P",{});var J2a=s(tye);SXr=r(J2a,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),J2a.forEach(t),RXr=i(d$),fc=n(d$,"P",{});var Ege=s(fc);PXr=r(Ege,`Note:
Loading a model from its configuration file does `),aye=n(Ege,"STRONG",{});var Y2a=s(aye);BXr=r(Y2a,"not"),Y2a.forEach(t),IXr=r(Ege,` load the model weights. It only affects the
model\u2019s configuration. Use `),mae=n(Ege,"A",{href:!0});var Z2a=s(mae);NXr=r(Z2a,"from_pretrained()"),Z2a.forEach(t),qXr=r(Ege," to load the model weights."),Ege.forEach(t),jXr=i(d$),T(M0.$$.fragment,d$),d$.forEach(t),DXr=i(Ti),xo=n(Ti,"DIV",{class:!0});var tn=s(xo);T(TP.$$.fragment,tn),GXr=i(tn),nye=n(tn,"P",{});var K2a=s(nye);OXr=r(K2a,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),K2a.forEach(t),VXr=i(tn),jn=n(tn,"P",{});var m$=s(jn);XXr=r(m$,"The model class to instantiate is selected based on the "),sye=n(m$,"CODE",{});var eba=s(sye);zXr=r(eba,"model_type"),eba.forEach(t),QXr=r(m$,` property of the config object (either
passed as an argument or loaded from `),lye=n(m$,"CODE",{});var oba=s(lye);WXr=r(oba,"pretrained_model_name_or_path"),oba.forEach(t),UXr=r(m$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iye=n(m$,"CODE",{});var rba=s(iye);HXr=r(rba,"pretrained_model_name_or_path"),rba.forEach(t),JXr=r(m$,":"),m$.forEach(t),YXr=i(tn),fr=n(tn,"UL",{});var an=s(fr);E0=n(an,"LI",{});var Eoo=s(E0);dye=n(Eoo,"STRONG",{});var tba=s(dye);ZXr=r(tba,"beit"),tba.forEach(t),KXr=r(Eoo," \u2014 "),cae=n(Eoo,"A",{href:!0});var aba=s(cae);ezr=r(aba,"BeitForSemanticSegmentation"),aba.forEach(t),ozr=r(Eoo," (BEiT model)"),Eoo.forEach(t),rzr=i(an),C0=n(an,"LI",{});var Coo=s(C0);mye=n(Coo,"STRONG",{});var nba=s(mye);tzr=r(nba,"data2vec-vision"),nba.forEach(t),azr=r(Coo," \u2014 "),fae=n(Coo,"A",{href:!0});var sba=s(fae);nzr=r(sba,"Data2VecVisionForSemanticSegmentation"),sba.forEach(t),szr=r(Coo," (Data2VecVision model)"),Coo.forEach(t),lzr=i(an),w0=n(an,"LI",{});var woo=s(w0);cye=n(woo,"STRONG",{});var lba=s(cye);izr=r(lba,"dpt"),lba.forEach(t),dzr=r(woo," \u2014 "),gae=n(woo,"A",{href:!0});var iba=s(gae);mzr=r(iba,"DPTForSemanticSegmentation"),iba.forEach(t),czr=r(woo," (DPT model)"),woo.forEach(t),fzr=i(an),A0=n(an,"LI",{});var Aoo=s(A0);fye=n(Aoo,"STRONG",{});var dba=s(fye);gzr=r(dba,"mobilenet_v2"),dba.forEach(t),hzr=r(Aoo," \u2014 "),hae=n(Aoo,"A",{href:!0});var mba=s(hae);uzr=r(mba,"MobileNetV2ForSemanticSegmentation"),mba.forEach(t),pzr=r(Aoo," (MobileNetV2 model)"),Aoo.forEach(t),_zr=i(an),L0=n(an,"LI",{});var Loo=s(L0);gye=n(Loo,"STRONG",{});var cba=s(gye);bzr=r(cba,"mobilevit"),cba.forEach(t),vzr=r(Loo," \u2014 "),uae=n(Loo,"A",{href:!0});var fba=s(uae);Fzr=r(fba,"MobileViTForSemanticSegmentation"),fba.forEach(t),Tzr=r(Loo," (MobileViT model)"),Loo.forEach(t),Mzr=i(an),y0=n(an,"LI",{});var yoo=s(y0);hye=n(yoo,"STRONG",{});var gba=s(hye);Ezr=r(gba,"segformer"),gba.forEach(t),Czr=r(yoo," \u2014 "),pae=n(yoo,"A",{href:!0});var hba=s(pae);wzr=r(hba,"SegformerForSemanticSegmentation"),hba.forEach(t),Azr=r(yoo," (SegFormer model)"),yoo.forEach(t),an.forEach(t),Lzr=i(tn),x0=n(tn,"P",{});var xoo=s(x0);yzr=r(xoo,"The model is set in evaluation mode by default using "),uye=n(xoo,"CODE",{});var uba=s(uye);xzr=r(uba,"model.eval()"),uba.forEach(t),$zr=r(xoo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),pye=n(xoo,"CODE",{});var pba=s(pye);kzr=r(pba,"model.train()"),pba.forEach(t),xoo.forEach(t),Szr=i(tn),T($0.$$.fragment,tn),tn.forEach(t),Ti.forEach(t),cdo=i(c),gc=n(c,"H2",{class:!0});var Pco=s(gc);k0=n(Pco,"A",{id:!0,class:!0,href:!0});var _ba=s(k0);_ye=n(_ba,"SPAN",{});var bba=s(_ye);T(MP.$$.fragment,bba),bba.forEach(t),_ba.forEach(t),Rzr=i(Pco),bye=n(Pco,"SPAN",{});var vba=s(bye);Pzr=r(vba,"AutoModelForInstanceSegmentation"),vba.forEach(t),Pco.forEach(t),fdo=i(c),gr=n(c,"DIV",{class:!0});var Mi=s(gr);T(EP.$$.fragment,Mi),Bzr=i(Mi),hc=n(Mi,"P",{});var Cge=s(hc);Izr=r(Cge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),_ae=n(Cge,"A",{href:!0});var Fba=s(_ae);Nzr=r(Fba,"from_pretrained()"),Fba.forEach(t),qzr=r(Cge," class method or the "),bae=n(Cge,"A",{href:!0});var Tba=s(bae);jzr=r(Tba,"from_config()"),Tba.forEach(t),Dzr=r(Cge,` class
method.`),Cge.forEach(t),Gzr=i(Mi),CP=n(Mi,"P",{});var Bco=s(CP);Ozr=r(Bco,"This class cannot be instantiated directly using "),vye=n(Bco,"CODE",{});var Mba=s(vye);Vzr=r(Mba,"__init__()"),Mba.forEach(t),Xzr=r(Bco," (throws an error)."),Bco.forEach(t),zzr=i(Mi),Kt=n(Mi,"DIV",{class:!0});var c$=s(Kt);T(wP.$$.fragment,c$),Qzr=i(c$),Fye=n(c$,"P",{});var Eba=s(Fye);Wzr=r(Eba,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Eba.forEach(t),Uzr=i(c$),uc=n(c$,"P",{});var wge=s(uc);Hzr=r(wge,`Note:
Loading a model from its configuration file does `),Tye=n(wge,"STRONG",{});var Cba=s(Tye);Jzr=r(Cba,"not"),Cba.forEach(t),Yzr=r(wge,` load the model weights. It only affects the
model\u2019s configuration. Use `),vae=n(wge,"A",{href:!0});var wba=s(vae);Zzr=r(wba,"from_pretrained()"),wba.forEach(t),Kzr=r(wge," to load the model weights."),wge.forEach(t),eQr=i(c$),T(S0.$$.fragment,c$),c$.forEach(t),oQr=i(Mi),$o=n(Mi,"DIV",{class:!0});var nn=s($o);T(AP.$$.fragment,nn),rQr=i(nn),Mye=n(nn,"P",{});var Aba=s(Mye);tQr=r(Aba,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),Aba.forEach(t),aQr=i(nn),Dn=n(nn,"P",{});var f$=s(Dn);nQr=r(f$,"The model class to instantiate is selected based on the "),Eye=n(f$,"CODE",{});var Lba=s(Eye);sQr=r(Lba,"model_type"),Lba.forEach(t),lQr=r(f$,` property of the config object (either
passed as an argument or loaded from `),Cye=n(f$,"CODE",{});var yba=s(Cye);iQr=r(yba,"pretrained_model_name_or_path"),yba.forEach(t),dQr=r(f$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wye=n(f$,"CODE",{});var xba=s(wye);mQr=r(xba,"pretrained_model_name_or_path"),xba.forEach(t),cQr=r(f$,":"),f$.forEach(t),fQr=i(nn),Aye=n(nn,"UL",{});var $ba=s(Aye);R0=n($ba,"LI",{});var $oo=s(R0);Lye=n($oo,"STRONG",{});var kba=s(Lye);gQr=r(kba,"maskformer"),kba.forEach(t),hQr=r($oo," \u2014 "),Fae=n($oo,"A",{href:!0});var Sba=s(Fae);uQr=r(Sba,"MaskFormerForInstanceSegmentation"),Sba.forEach(t),pQr=r($oo," (MaskFormer model)"),$oo.forEach(t),$ba.forEach(t),_Qr=i(nn),P0=n(nn,"P",{});var koo=s(P0);bQr=r(koo,"The model is set in evaluation mode by default using "),yye=n(koo,"CODE",{});var Rba=s(yye);vQr=r(Rba,"model.eval()"),Rba.forEach(t),FQr=r(koo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),xye=n(koo,"CODE",{});var Pba=s(xye);TQr=r(Pba,"model.train()"),Pba.forEach(t),koo.forEach(t),MQr=i(nn),T(B0.$$.fragment,nn),nn.forEach(t),Mi.forEach(t),gdo=i(c),pc=n(c,"H2",{class:!0});var Ico=s(pc);I0=n(Ico,"A",{id:!0,class:!0,href:!0});var Bba=s(I0);$ye=n(Bba,"SPAN",{});var Iba=s($ye);T(LP.$$.fragment,Iba),Iba.forEach(t),Bba.forEach(t),EQr=i(Ico),kye=n(Ico,"SPAN",{});var Nba=s(kye);CQr=r(Nba,"AutoModelForZeroShotObjectDetection"),Nba.forEach(t),Ico.forEach(t),hdo=i(c),hr=n(c,"DIV",{class:!0});var Ei=s(hr);T(yP.$$.fragment,Ei),wQr=i(Ei),_c=n(Ei,"P",{});var Age=s(_c);AQr=r(Age,`This is a generic model class that will be instantiated as one of the model classes of the library (with a zero-shot object detection head) when created
with the `),Tae=n(Age,"A",{href:!0});var qba=s(Tae);LQr=r(qba,"from_pretrained()"),qba.forEach(t),yQr=r(Age," class method or the "),Mae=n(Age,"A",{href:!0});var jba=s(Mae);xQr=r(jba,"from_config()"),jba.forEach(t),$Qr=r(Age,` class
method.`),Age.forEach(t),kQr=i(Ei),xP=n(Ei,"P",{});var Nco=s(xP);SQr=r(Nco,"This class cannot be instantiated directly using "),Sye=n(Nco,"CODE",{});var Dba=s(Sye);RQr=r(Dba,"__init__()"),Dba.forEach(t),PQr=r(Nco," (throws an error)."),Nco.forEach(t),BQr=i(Ei),ea=n(Ei,"DIV",{class:!0});var g$=s(ea);T($P.$$.fragment,g$),IQr=i(g$),Rye=n(g$,"P",{});var Gba=s(Rye);NQr=r(Gba,"Instantiates one of the model classes of the library (with a zero-shot object detection head) from a configuration."),Gba.forEach(t),qQr=i(g$),bc=n(g$,"P",{});var Lge=s(bc);jQr=r(Lge,`Note:
Loading a model from its configuration file does `),Pye=n(Lge,"STRONG",{});var Oba=s(Pye);DQr=r(Oba,"not"),Oba.forEach(t),GQr=r(Lge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Eae=n(Lge,"A",{href:!0});var Vba=s(Eae);OQr=r(Vba,"from_pretrained()"),Vba.forEach(t),VQr=r(Lge," to load the model weights."),Lge.forEach(t),XQr=i(g$),T(N0.$$.fragment,g$),g$.forEach(t),zQr=i(Ei),ko=n(Ei,"DIV",{class:!0});var sn=s(ko);T(kP.$$.fragment,sn),QQr=i(sn),Bye=n(sn,"P",{});var Xba=s(Bye);WQr=r(Xba,"Instantiate one of the model classes of the library (with a zero-shot object detection head) from a pretrained model."),Xba.forEach(t),UQr=i(sn),Gn=n(sn,"P",{});var h$=s(Gn);HQr=r(h$,"The model class to instantiate is selected based on the "),Iye=n(h$,"CODE",{});var zba=s(Iye);JQr=r(zba,"model_type"),zba.forEach(t),YQr=r(h$,` property of the config object (either
passed as an argument or loaded from `),Nye=n(h$,"CODE",{});var Qba=s(Nye);ZQr=r(Qba,"pretrained_model_name_or_path"),Qba.forEach(t),KQr=r(h$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qye=n(h$,"CODE",{});var Wba=s(qye);eWr=r(Wba,"pretrained_model_name_or_path"),Wba.forEach(t),oWr=r(h$,":"),h$.forEach(t),rWr=i(sn),jye=n(sn,"UL",{});var Uba=s(jye);q0=n(Uba,"LI",{});var Soo=s(q0);Dye=n(Soo,"STRONG",{});var Hba=s(Dye);tWr=r(Hba,"owlvit"),Hba.forEach(t),aWr=r(Soo," \u2014 "),Cae=n(Soo,"A",{href:!0});var Jba=s(Cae);nWr=r(Jba,"OwlViTForObjectDetection"),Jba.forEach(t),sWr=r(Soo," (OWL-ViT model)"),Soo.forEach(t),Uba.forEach(t),lWr=i(sn),j0=n(sn,"P",{});var Roo=s(j0);iWr=r(Roo,"The model is set in evaluation mode by default using "),Gye=n(Roo,"CODE",{});var Yba=s(Gye);dWr=r(Yba,"model.eval()"),Yba.forEach(t),mWr=r(Roo,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Oye=n(Roo,"CODE",{});var Zba=s(Oye);cWr=r(Zba,"model.train()"),Zba.forEach(t),Roo.forEach(t),fWr=i(sn),T(D0.$$.fragment,sn),sn.forEach(t),Ei.forEach(t),udo=i(c),vc=n(c,"H2",{class:!0});var qco=s(vc);G0=n(qco,"A",{id:!0,class:!0,href:!0});var Kba=s(G0);Vye=n(Kba,"SPAN",{});var eva=s(Vye);T(SP.$$.fragment,eva),eva.forEach(t),Kba.forEach(t),gWr=i(qco),Xye=n(qco,"SPAN",{});var ova=s(Xye);hWr=r(ova,"TFAutoModel"),ova.forEach(t),qco.forEach(t),pdo=i(c),ur=n(c,"DIV",{class:!0});var Ci=s(ur);T(RP.$$.fragment,Ci),uWr=i(Ci),Fc=n(Ci,"P",{});var yge=s(Fc);pWr=r(yge,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),wae=n(yge,"A",{href:!0});var rva=s(wae);_Wr=r(rva,"from_pretrained()"),rva.forEach(t),bWr=r(yge," class method or the "),Aae=n(yge,"A",{href:!0});var tva=s(Aae);vWr=r(tva,"from_config()"),tva.forEach(t),FWr=r(yge,` class
method.`),yge.forEach(t),TWr=i(Ci),PP=n(Ci,"P",{});var jco=s(PP);MWr=r(jco,"This class cannot be instantiated directly using "),zye=n(jco,"CODE",{});var ava=s(zye);EWr=r(ava,"__init__()"),ava.forEach(t),CWr=r(jco," (throws an error)."),jco.forEach(t),wWr=i(Ci),oa=n(Ci,"DIV",{class:!0});var u$=s(oa);T(BP.$$.fragment,u$),AWr=i(u$),Qye=n(u$,"P",{});var nva=s(Qye);LWr=r(nva,"Instantiates one of the base model classes of the library from a configuration."),nva.forEach(t),yWr=i(u$),Tc=n(u$,"P",{});var xge=s(Tc);xWr=r(xge,`Note:
Loading a model from its configuration file does `),Wye=n(xge,"STRONG",{});var sva=s(Wye);$Wr=r(sva,"not"),sva.forEach(t),kWr=r(xge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Lae=n(xge,"A",{href:!0});var lva=s(Lae);SWr=r(lva,"from_pretrained()"),lva.forEach(t),RWr=r(xge," to load the model weights."),xge.forEach(t),PWr=i(u$),T(O0.$$.fragment,u$),u$.forEach(t),BWr=i(Ci),zr=n(Ci,"DIV",{class:!0});var wi=s(zr);T(IP.$$.fragment,wi),IWr=i(wi),Uye=n(wi,"P",{});var iva=s(Uye);NWr=r(iva,"Instantiate one of the base model classes of the library from a pretrained model."),iva.forEach(t),qWr=i(wi),On=n(wi,"P",{});var p$=s(On);jWr=r(p$,"The model class to instantiate is selected based on the "),Hye=n(p$,"CODE",{});var dva=s(Hye);DWr=r(dva,"model_type"),dva.forEach(t),GWr=r(p$,` property of the config object (either
passed as an argument or loaded from `),Jye=n(p$,"CODE",{});var mva=s(Jye);OWr=r(mva,"pretrained_model_name_or_path"),mva.forEach(t),VWr=r(p$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yye=n(p$,"CODE",{});var cva=s(Yye);XWr=r(cva,"pretrained_model_name_or_path"),cva.forEach(t),zWr=r(p$,":"),p$.forEach(t),QWr=i(wi),P=n(wi,"UL",{});var j=s(P);V0=n(j,"LI",{});var Poo=s(V0);Zye=n(Poo,"STRONG",{});var fva=s(Zye);WWr=r(fva,"albert"),fva.forEach(t),UWr=r(Poo," \u2014 "),yae=n(Poo,"A",{href:!0});var gva=s(yae);HWr=r(gva,"TFAlbertModel"),gva.forEach(t),JWr=r(Poo," (ALBERT model)"),Poo.forEach(t),YWr=i(j),X0=n(j,"LI",{});var Boo=s(X0);Kye=n(Boo,"STRONG",{});var hva=s(Kye);ZWr=r(hva,"bart"),hva.forEach(t),KWr=r(Boo," \u2014 "),xae=n(Boo,"A",{href:!0});var uva=s(xae);eUr=r(uva,"TFBartModel"),uva.forEach(t),oUr=r(Boo," (BART model)"),Boo.forEach(t),rUr=i(j),z0=n(j,"LI",{});var Ioo=s(z0);e9e=n(Ioo,"STRONG",{});var pva=s(e9e);tUr=r(pva,"bert"),pva.forEach(t),aUr=r(Ioo," \u2014 "),$ae=n(Ioo,"A",{href:!0});var _va=s($ae);nUr=r(_va,"TFBertModel"),_va.forEach(t),sUr=r(Ioo," (BERT model)"),Ioo.forEach(t),lUr=i(j),Q0=n(j,"LI",{});var Noo=s(Q0);o9e=n(Noo,"STRONG",{});var bva=s(o9e);iUr=r(bva,"blenderbot"),bva.forEach(t),dUr=r(Noo," \u2014 "),kae=n(Noo,"A",{href:!0});var vva=s(kae);mUr=r(vva,"TFBlenderbotModel"),vva.forEach(t),cUr=r(Noo," (Blenderbot model)"),Noo.forEach(t),fUr=i(j),W0=n(j,"LI",{});var qoo=s(W0);r9e=n(qoo,"STRONG",{});var Fva=s(r9e);gUr=r(Fva,"blenderbot-small"),Fva.forEach(t),hUr=r(qoo," \u2014 "),Sae=n(qoo,"A",{href:!0});var Tva=s(Sae);uUr=r(Tva,"TFBlenderbotSmallModel"),Tva.forEach(t),pUr=r(qoo," (BlenderbotSmall model)"),qoo.forEach(t),_Ur=i(j),U0=n(j,"LI",{});var joo=s(U0);t9e=n(joo,"STRONG",{});var Mva=s(t9e);bUr=r(Mva,"camembert"),Mva.forEach(t),vUr=r(joo," \u2014 "),Rae=n(joo,"A",{href:!0});var Eva=s(Rae);FUr=r(Eva,"TFCamembertModel"),Eva.forEach(t),TUr=r(joo," (CamemBERT model)"),joo.forEach(t),MUr=i(j),H0=n(j,"LI",{});var Doo=s(H0);a9e=n(Doo,"STRONG",{});var Cva=s(a9e);EUr=r(Cva,"clip"),Cva.forEach(t),CUr=r(Doo," \u2014 "),Pae=n(Doo,"A",{href:!0});var wva=s(Pae);wUr=r(wva,"TFCLIPModel"),wva.forEach(t),AUr=r(Doo," (CLIP model)"),Doo.forEach(t),LUr=i(j),J0=n(j,"LI",{});var Goo=s(J0);n9e=n(Goo,"STRONG",{});var Ava=s(n9e);yUr=r(Ava,"convbert"),Ava.forEach(t),xUr=r(Goo," \u2014 "),Bae=n(Goo,"A",{href:!0});var Lva=s(Bae);$Ur=r(Lva,"TFConvBertModel"),Lva.forEach(t),kUr=r(Goo," (ConvBERT model)"),Goo.forEach(t),SUr=i(j),Y0=n(j,"LI",{});var Ooo=s(Y0);s9e=n(Ooo,"STRONG",{});var yva=s(s9e);RUr=r(yva,"convnext"),yva.forEach(t),PUr=r(Ooo," \u2014 "),Iae=n(Ooo,"A",{href:!0});var xva=s(Iae);BUr=r(xva,"TFConvNextModel"),xva.forEach(t),IUr=r(Ooo," (ConvNeXT model)"),Ooo.forEach(t),NUr=i(j),Z0=n(j,"LI",{});var Voo=s(Z0);l9e=n(Voo,"STRONG",{});var $va=s(l9e);qUr=r($va,"ctrl"),$va.forEach(t),jUr=r(Voo," \u2014 "),Nae=n(Voo,"A",{href:!0});var kva=s(Nae);DUr=r(kva,"TFCTRLModel"),kva.forEach(t),GUr=r(Voo," (CTRL model)"),Voo.forEach(t),OUr=i(j),K0=n(j,"LI",{});var Xoo=s(K0);i9e=n(Xoo,"STRONG",{});var Sva=s(i9e);VUr=r(Sva,"cvt"),Sva.forEach(t),XUr=r(Xoo," \u2014 "),qae=n(Xoo,"A",{href:!0});var Rva=s(qae);zUr=r(Rva,"TFCvtModel"),Rva.forEach(t),QUr=r(Xoo," (CvT model)"),Xoo.forEach(t),WUr=i(j),ew=n(j,"LI",{});var zoo=s(ew);d9e=n(zoo,"STRONG",{});var Pva=s(d9e);UUr=r(Pva,"data2vec-vision"),Pva.forEach(t),HUr=r(zoo," \u2014 "),jae=n(zoo,"A",{href:!0});var Bva=s(jae);JUr=r(Bva,"TFData2VecVisionModel"),Bva.forEach(t),YUr=r(zoo," (Data2VecVision model)"),zoo.forEach(t),ZUr=i(j),ow=n(j,"LI",{});var Qoo=s(ow);m9e=n(Qoo,"STRONG",{});var Iva=s(m9e);KUr=r(Iva,"deberta"),Iva.forEach(t),eHr=r(Qoo," \u2014 "),Dae=n(Qoo,"A",{href:!0});var Nva=s(Dae);oHr=r(Nva,"TFDebertaModel"),Nva.forEach(t),rHr=r(Qoo," (DeBERTa model)"),Qoo.forEach(t),tHr=i(j),rw=n(j,"LI",{});var Woo=s(rw);c9e=n(Woo,"STRONG",{});var qva=s(c9e);aHr=r(qva,"deberta-v2"),qva.forEach(t),nHr=r(Woo," \u2014 "),Gae=n(Woo,"A",{href:!0});var jva=s(Gae);sHr=r(jva,"TFDebertaV2Model"),jva.forEach(t),lHr=r(Woo," (DeBERTa-v2 model)"),Woo.forEach(t),iHr=i(j),tw=n(j,"LI",{});var Uoo=s(tw);f9e=n(Uoo,"STRONG",{});var Dva=s(f9e);dHr=r(Dva,"deit"),Dva.forEach(t),mHr=r(Uoo," \u2014 "),Oae=n(Uoo,"A",{href:!0});var Gva=s(Oae);cHr=r(Gva,"TFDeiTModel"),Gva.forEach(t),fHr=r(Uoo," (DeiT model)"),Uoo.forEach(t),gHr=i(j),aw=n(j,"LI",{});var Hoo=s(aw);g9e=n(Hoo,"STRONG",{});var Ova=s(g9e);hHr=r(Ova,"distilbert"),Ova.forEach(t),uHr=r(Hoo," \u2014 "),Vae=n(Hoo,"A",{href:!0});var Vva=s(Vae);pHr=r(Vva,"TFDistilBertModel"),Vva.forEach(t),_Hr=r(Hoo," (DistilBERT model)"),Hoo.forEach(t),bHr=i(j),nw=n(j,"LI",{});var Joo=s(nw);h9e=n(Joo,"STRONG",{});var Xva=s(h9e);vHr=r(Xva,"dpr"),Xva.forEach(t),FHr=r(Joo," \u2014 "),Xae=n(Joo,"A",{href:!0});var zva=s(Xae);THr=r(zva,"TFDPRQuestionEncoder"),zva.forEach(t),MHr=r(Joo," (DPR model)"),Joo.forEach(t),EHr=i(j),sw=n(j,"LI",{});var Yoo=s(sw);u9e=n(Yoo,"STRONG",{});var Qva=s(u9e);CHr=r(Qva,"electra"),Qva.forEach(t),wHr=r(Yoo," \u2014 "),zae=n(Yoo,"A",{href:!0});var Wva=s(zae);AHr=r(Wva,"TFElectraModel"),Wva.forEach(t),LHr=r(Yoo," (ELECTRA model)"),Yoo.forEach(t),yHr=i(j),lw=n(j,"LI",{});var Zoo=s(lw);p9e=n(Zoo,"STRONG",{});var Uva=s(p9e);xHr=r(Uva,"esm"),Uva.forEach(t),$Hr=r(Zoo," \u2014 "),Qae=n(Zoo,"A",{href:!0});var Hva=s(Qae);kHr=r(Hva,"TFEsmModel"),Hva.forEach(t),SHr=r(Zoo," (ESM model)"),Zoo.forEach(t),RHr=i(j),iw=n(j,"LI",{});var Koo=s(iw);_9e=n(Koo,"STRONG",{});var Jva=s(_9e);PHr=r(Jva,"flaubert"),Jva.forEach(t),BHr=r(Koo," \u2014 "),Wae=n(Koo,"A",{href:!0});var Yva=s(Wae);IHr=r(Yva,"TFFlaubertModel"),Yva.forEach(t),NHr=r(Koo," (FlauBERT model)"),Koo.forEach(t),qHr=i(j),Dl=n(j,"LI",{});var jq=s(Dl);b9e=n(jq,"STRONG",{});var Zva=s(b9e);jHr=r(Zva,"funnel"),Zva.forEach(t),DHr=r(jq," \u2014 "),Uae=n(jq,"A",{href:!0});var Kva=s(Uae);GHr=r(Kva,"TFFunnelModel"),Kva.forEach(t),OHr=r(jq," or "),Hae=n(jq,"A",{href:!0});var eFa=s(Hae);VHr=r(eFa,"TFFunnelBaseModel"),eFa.forEach(t),XHr=r(jq," (Funnel Transformer model)"),jq.forEach(t),zHr=i(j),dw=n(j,"LI",{});var ero=s(dw);v9e=n(ero,"STRONG",{});var oFa=s(v9e);QHr=r(oFa,"gpt2"),oFa.forEach(t),WHr=r(ero," \u2014 "),Jae=n(ero,"A",{href:!0});var rFa=s(Jae);UHr=r(rFa,"TFGPT2Model"),rFa.forEach(t),HHr=r(ero," (OpenAI GPT-2 model)"),ero.forEach(t),JHr=i(j),mw=n(j,"LI",{});var oro=s(mw);F9e=n(oro,"STRONG",{});var tFa=s(F9e);YHr=r(tFa,"gptj"),tFa.forEach(t),ZHr=r(oro," \u2014 "),Yae=n(oro,"A",{href:!0});var aFa=s(Yae);KHr=r(aFa,"TFGPTJModel"),aFa.forEach(t),eJr=r(oro," (GPT-J model)"),oro.forEach(t),oJr=i(j),cw=n(j,"LI",{});var rro=s(cw);T9e=n(rro,"STRONG",{});var nFa=s(T9e);rJr=r(nFa,"groupvit"),nFa.forEach(t),tJr=r(rro," \u2014 "),Zae=n(rro,"A",{href:!0});var sFa=s(Zae);aJr=r(sFa,"TFGroupViTModel"),sFa.forEach(t),nJr=r(rro," (GroupViT model)"),rro.forEach(t),sJr=i(j),fw=n(j,"LI",{});var tro=s(fw);M9e=n(tro,"STRONG",{});var lFa=s(M9e);lJr=r(lFa,"hubert"),lFa.forEach(t),iJr=r(tro," \u2014 "),Kae=n(tro,"A",{href:!0});var iFa=s(Kae);dJr=r(iFa,"TFHubertModel"),iFa.forEach(t),mJr=r(tro," (Hubert model)"),tro.forEach(t),cJr=i(j),gw=n(j,"LI",{});var aro=s(gw);E9e=n(aro,"STRONG",{});var dFa=s(E9e);fJr=r(dFa,"layoutlm"),dFa.forEach(t),gJr=r(aro," \u2014 "),ene=n(aro,"A",{href:!0});var mFa=s(ene);hJr=r(mFa,"TFLayoutLMModel"),mFa.forEach(t),uJr=r(aro," (LayoutLM model)"),aro.forEach(t),pJr=i(j),hw=n(j,"LI",{});var nro=s(hw);C9e=n(nro,"STRONG",{});var cFa=s(C9e);_Jr=r(cFa,"layoutlmv3"),cFa.forEach(t),bJr=r(nro," \u2014 "),one=n(nro,"A",{href:!0});var fFa=s(one);vJr=r(fFa,"TFLayoutLMv3Model"),fFa.forEach(t),FJr=r(nro," (LayoutLMv3 model)"),nro.forEach(t),TJr=i(j),uw=n(j,"LI",{});var sro=s(uw);w9e=n(sro,"STRONG",{});var gFa=s(w9e);MJr=r(gFa,"led"),gFa.forEach(t),EJr=r(sro," \u2014 "),rne=n(sro,"A",{href:!0});var hFa=s(rne);CJr=r(hFa,"TFLEDModel"),hFa.forEach(t),wJr=r(sro," (LED model)"),sro.forEach(t),AJr=i(j),pw=n(j,"LI",{});var lro=s(pw);A9e=n(lro,"STRONG",{});var uFa=s(A9e);LJr=r(uFa,"longformer"),uFa.forEach(t),yJr=r(lro," \u2014 "),tne=n(lro,"A",{href:!0});var pFa=s(tne);xJr=r(pFa,"TFLongformerModel"),pFa.forEach(t),$Jr=r(lro," (Longformer model)"),lro.forEach(t),kJr=i(j),_w=n(j,"LI",{});var iro=s(_w);L9e=n(iro,"STRONG",{});var _Fa=s(L9e);SJr=r(_Fa,"lxmert"),_Fa.forEach(t),RJr=r(iro," \u2014 "),ane=n(iro,"A",{href:!0});var bFa=s(ane);PJr=r(bFa,"TFLxmertModel"),bFa.forEach(t),BJr=r(iro," (LXMERT model)"),iro.forEach(t),IJr=i(j),bw=n(j,"LI",{});var dro=s(bw);y9e=n(dro,"STRONG",{});var vFa=s(y9e);NJr=r(vFa,"marian"),vFa.forEach(t),qJr=r(dro," \u2014 "),nne=n(dro,"A",{href:!0});var FFa=s(nne);jJr=r(FFa,"TFMarianModel"),FFa.forEach(t),DJr=r(dro," (Marian model)"),dro.forEach(t),GJr=i(j),vw=n(j,"LI",{});var mro=s(vw);x9e=n(mro,"STRONG",{});var TFa=s(x9e);OJr=r(TFa,"mbart"),TFa.forEach(t),VJr=r(mro," \u2014 "),sne=n(mro,"A",{href:!0});var MFa=s(sne);XJr=r(MFa,"TFMBartModel"),MFa.forEach(t),zJr=r(mro," (mBART model)"),mro.forEach(t),QJr=i(j),Fw=n(j,"LI",{});var cro=s(Fw);$9e=n(cro,"STRONG",{});var EFa=s($9e);WJr=r(EFa,"mobilebert"),EFa.forEach(t),UJr=r(cro," \u2014 "),lne=n(cro,"A",{href:!0});var CFa=s(lne);HJr=r(CFa,"TFMobileBertModel"),CFa.forEach(t),JJr=r(cro," (MobileBERT model)"),cro.forEach(t),YJr=i(j),Tw=n(j,"LI",{});var fro=s(Tw);k9e=n(fro,"STRONG",{});var wFa=s(k9e);ZJr=r(wFa,"mobilevit"),wFa.forEach(t),KJr=r(fro," \u2014 "),ine=n(fro,"A",{href:!0});var AFa=s(ine);eYr=r(AFa,"TFMobileViTModel"),AFa.forEach(t),oYr=r(fro," (MobileViT model)"),fro.forEach(t),rYr=i(j),Mw=n(j,"LI",{});var gro=s(Mw);S9e=n(gro,"STRONG",{});var LFa=s(S9e);tYr=r(LFa,"mpnet"),LFa.forEach(t),aYr=r(gro," \u2014 "),dne=n(gro,"A",{href:!0});var yFa=s(dne);nYr=r(yFa,"TFMPNetModel"),yFa.forEach(t),sYr=r(gro," (MPNet model)"),gro.forEach(t),lYr=i(j),Ew=n(j,"LI",{});var hro=s(Ew);R9e=n(hro,"STRONG",{});var xFa=s(R9e);iYr=r(xFa,"mt5"),xFa.forEach(t),dYr=r(hro," \u2014 "),mne=n(hro,"A",{href:!0});var $Fa=s(mne);mYr=r($Fa,"TFMT5Model"),$Fa.forEach(t),cYr=r(hro," (MT5 model)"),hro.forEach(t),fYr=i(j),Cw=n(j,"LI",{});var uro=s(Cw);P9e=n(uro,"STRONG",{});var kFa=s(P9e);gYr=r(kFa,"openai-gpt"),kFa.forEach(t),hYr=r(uro," \u2014 "),cne=n(uro,"A",{href:!0});var SFa=s(cne);uYr=r(SFa,"TFOpenAIGPTModel"),SFa.forEach(t),pYr=r(uro," (OpenAI GPT model)"),uro.forEach(t),_Yr=i(j),ww=n(j,"LI",{});var pro=s(ww);B9e=n(pro,"STRONG",{});var RFa=s(B9e);bYr=r(RFa,"opt"),RFa.forEach(t),vYr=r(pro," \u2014 "),fne=n(pro,"A",{href:!0});var PFa=s(fne);FYr=r(PFa,"TFOPTModel"),PFa.forEach(t),TYr=r(pro," (OPT model)"),pro.forEach(t),MYr=i(j),Aw=n(j,"LI",{});var _ro=s(Aw);I9e=n(_ro,"STRONG",{});var BFa=s(I9e);EYr=r(BFa,"pegasus"),BFa.forEach(t),CYr=r(_ro," \u2014 "),gne=n(_ro,"A",{href:!0});var IFa=s(gne);wYr=r(IFa,"TFPegasusModel"),IFa.forEach(t),AYr=r(_ro," (Pegasus model)"),_ro.forEach(t),LYr=i(j),Lw=n(j,"LI",{});var bro=s(Lw);N9e=n(bro,"STRONG",{});var NFa=s(N9e);yYr=r(NFa,"regnet"),NFa.forEach(t),xYr=r(bro," \u2014 "),hne=n(bro,"A",{href:!0});var qFa=s(hne);$Yr=r(qFa,"TFRegNetModel"),qFa.forEach(t),kYr=r(bro," (RegNet model)"),bro.forEach(t),SYr=i(j),yw=n(j,"LI",{});var vro=s(yw);q9e=n(vro,"STRONG",{});var jFa=s(q9e);RYr=r(jFa,"rembert"),jFa.forEach(t),PYr=r(vro," \u2014 "),une=n(vro,"A",{href:!0});var DFa=s(une);BYr=r(DFa,"TFRemBertModel"),DFa.forEach(t),IYr=r(vro," (RemBERT model)"),vro.forEach(t),NYr=i(j),xw=n(j,"LI",{});var Fro=s(xw);j9e=n(Fro,"STRONG",{});var GFa=s(j9e);qYr=r(GFa,"resnet"),GFa.forEach(t),jYr=r(Fro," \u2014 "),pne=n(Fro,"A",{href:!0});var OFa=s(pne);DYr=r(OFa,"TFResNetModel"),OFa.forEach(t),GYr=r(Fro," (ResNet model)"),Fro.forEach(t),OYr=i(j),$w=n(j,"LI",{});var Tro=s($w);D9e=n(Tro,"STRONG",{});var VFa=s(D9e);VYr=r(VFa,"roberta"),VFa.forEach(t),XYr=r(Tro," \u2014 "),_ne=n(Tro,"A",{href:!0});var XFa=s(_ne);zYr=r(XFa,"TFRobertaModel"),XFa.forEach(t),QYr=r(Tro," (RoBERTa model)"),Tro.forEach(t),WYr=i(j),kw=n(j,"LI",{});var Mro=s(kw);G9e=n(Mro,"STRONG",{});var zFa=s(G9e);UYr=r(zFa,"roformer"),zFa.forEach(t),HYr=r(Mro," \u2014 "),bne=n(Mro,"A",{href:!0});var QFa=s(bne);JYr=r(QFa,"TFRoFormerModel"),QFa.forEach(t),YYr=r(Mro," (RoFormer model)"),Mro.forEach(t),ZYr=i(j),Sw=n(j,"LI",{});var Ero=s(Sw);O9e=n(Ero,"STRONG",{});var WFa=s(O9e);KYr=r(WFa,"segformer"),WFa.forEach(t),eZr=r(Ero," \u2014 "),vne=n(Ero,"A",{href:!0});var UFa=s(vne);oZr=r(UFa,"TFSegformerModel"),UFa.forEach(t),rZr=r(Ero," (SegFormer model)"),Ero.forEach(t),tZr=i(j),Rw=n(j,"LI",{});var Cro=s(Rw);V9e=n(Cro,"STRONG",{});var HFa=s(V9e);aZr=r(HFa,"speech_to_text"),HFa.forEach(t),nZr=r(Cro," \u2014 "),Fne=n(Cro,"A",{href:!0});var JFa=s(Fne);sZr=r(JFa,"TFSpeech2TextModel"),JFa.forEach(t),lZr=r(Cro," (Speech2Text model)"),Cro.forEach(t),iZr=i(j),Pw=n(j,"LI",{});var wro=s(Pw);X9e=n(wro,"STRONG",{});var YFa=s(X9e);dZr=r(YFa,"swin"),YFa.forEach(t),mZr=r(wro," \u2014 "),Tne=n(wro,"A",{href:!0});var ZFa=s(Tne);cZr=r(ZFa,"TFSwinModel"),ZFa.forEach(t),fZr=r(wro," (Swin Transformer model)"),wro.forEach(t),gZr=i(j),Bw=n(j,"LI",{});var Aro=s(Bw);z9e=n(Aro,"STRONG",{});var KFa=s(z9e);hZr=r(KFa,"t5"),KFa.forEach(t),uZr=r(Aro," \u2014 "),Mne=n(Aro,"A",{href:!0});var eTa=s(Mne);pZr=r(eTa,"TFT5Model"),eTa.forEach(t),_Zr=r(Aro," (T5 model)"),Aro.forEach(t),bZr=i(j),Iw=n(j,"LI",{});var Lro=s(Iw);Q9e=n(Lro,"STRONG",{});var oTa=s(Q9e);vZr=r(oTa,"tapas"),oTa.forEach(t),FZr=r(Lro," \u2014 "),Ene=n(Lro,"A",{href:!0});var rTa=s(Ene);TZr=r(rTa,"TFTapasModel"),rTa.forEach(t),MZr=r(Lro," (TAPAS model)"),Lro.forEach(t),EZr=i(j),Nw=n(j,"LI",{});var yro=s(Nw);W9e=n(yro,"STRONG",{});var tTa=s(W9e);CZr=r(tTa,"transfo-xl"),tTa.forEach(t),wZr=r(yro," \u2014 "),Cne=n(yro,"A",{href:!0});var aTa=s(Cne);AZr=r(aTa,"TFTransfoXLModel"),aTa.forEach(t),LZr=r(yro," (Transformer-XL model)"),yro.forEach(t),yZr=i(j),qw=n(j,"LI",{});var xro=s(qw);U9e=n(xro,"STRONG",{});var nTa=s(U9e);xZr=r(nTa,"vit"),nTa.forEach(t),$Zr=r(xro," \u2014 "),wne=n(xro,"A",{href:!0});var sTa=s(wne);kZr=r(sTa,"TFViTModel"),sTa.forEach(t),SZr=r(xro," (ViT model)"),xro.forEach(t),RZr=i(j),jw=n(j,"LI",{});var $ro=s(jw);H9e=n($ro,"STRONG",{});var lTa=s(H9e);PZr=r(lTa,"vit_mae"),lTa.forEach(t),BZr=r($ro," \u2014 "),Ane=n($ro,"A",{href:!0});var iTa=s(Ane);IZr=r(iTa,"TFViTMAEModel"),iTa.forEach(t),NZr=r($ro," (ViTMAE model)"),$ro.forEach(t),qZr=i(j),Dw=n(j,"LI",{});var kro=s(Dw);J9e=n(kro,"STRONG",{});var dTa=s(J9e);jZr=r(dTa,"wav2vec2"),dTa.forEach(t),DZr=r(kro," \u2014 "),Lne=n(kro,"A",{href:!0});var mTa=s(Lne);GZr=r(mTa,"TFWav2Vec2Model"),mTa.forEach(t),OZr=r(kro," (Wav2Vec2 model)"),kro.forEach(t),VZr=i(j),Gw=n(j,"LI",{});var Sro=s(Gw);Y9e=n(Sro,"STRONG",{});var cTa=s(Y9e);XZr=r(cTa,"whisper"),cTa.forEach(t),zZr=r(Sro," \u2014 "),yne=n(Sro,"A",{href:!0});var fTa=s(yne);QZr=r(fTa,"TFWhisperModel"),fTa.forEach(t),WZr=r(Sro," (Whisper model)"),Sro.forEach(t),UZr=i(j),Ow=n(j,"LI",{});var Rro=s(Ow);Z9e=n(Rro,"STRONG",{});var gTa=s(Z9e);HZr=r(gTa,"xglm"),gTa.forEach(t),JZr=r(Rro," \u2014 "),xne=n(Rro,"A",{href:!0});var hTa=s(xne);YZr=r(hTa,"TFXGLMModel"),hTa.forEach(t),ZZr=r(Rro," (XGLM model)"),Rro.forEach(t),KZr=i(j),Vw=n(j,"LI",{});var Pro=s(Vw);K9e=n(Pro,"STRONG",{});var uTa=s(K9e);eKr=r(uTa,"xlm"),uTa.forEach(t),oKr=r(Pro," \u2014 "),$ne=n(Pro,"A",{href:!0});var pTa=s($ne);rKr=r(pTa,"TFXLMModel"),pTa.forEach(t),tKr=r(Pro," (XLM model)"),Pro.forEach(t),aKr=i(j),Xw=n(j,"LI",{});var Bro=s(Xw);exe=n(Bro,"STRONG",{});var _Ta=s(exe);nKr=r(_Ta,"xlm-roberta"),_Ta.forEach(t),sKr=r(Bro," \u2014 "),kne=n(Bro,"A",{href:!0});var bTa=s(kne);lKr=r(bTa,"TFXLMRobertaModel"),bTa.forEach(t),iKr=r(Bro," (XLM-RoBERTa model)"),Bro.forEach(t),dKr=i(j),zw=n(j,"LI",{});var Iro=s(zw);oxe=n(Iro,"STRONG",{});var vTa=s(oxe);mKr=r(vTa,"xlnet"),vTa.forEach(t),cKr=r(Iro," \u2014 "),Sne=n(Iro,"A",{href:!0});var FTa=s(Sne);fKr=r(FTa,"TFXLNetModel"),FTa.forEach(t),gKr=r(Iro," (XLNet model)"),Iro.forEach(t),j.forEach(t),hKr=i(wi),T(Qw.$$.fragment,wi),wi.forEach(t),Ci.forEach(t),_do=i(c),Mc=n(c,"H2",{class:!0});var Dco=s(Mc);Ww=n(Dco,"A",{id:!0,class:!0,href:!0});var TTa=s(Ww);rxe=n(TTa,"SPAN",{});var MTa=s(rxe);T(NP.$$.fragment,MTa),MTa.forEach(t),TTa.forEach(t),uKr=i(Dco),txe=n(Dco,"SPAN",{});var ETa=s(txe);pKr=r(ETa,"TFAutoModelForPreTraining"),ETa.forEach(t),Dco.forEach(t),bdo=i(c),pr=n(c,"DIV",{class:!0});var Ai=s(pr);T(qP.$$.fragment,Ai),_Kr=i(Ai),Ec=n(Ai,"P",{});var $ge=s(Ec);bKr=r($ge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),Rne=n($ge,"A",{href:!0});var CTa=s(Rne);vKr=r(CTa,"from_pretrained()"),CTa.forEach(t),FKr=r($ge," class method or the "),Pne=n($ge,"A",{href:!0});var wTa=s(Pne);TKr=r(wTa,"from_config()"),wTa.forEach(t),MKr=r($ge,` class
method.`),$ge.forEach(t),EKr=i(Ai),jP=n(Ai,"P",{});var Gco=s(jP);CKr=r(Gco,"This class cannot be instantiated directly using "),axe=n(Gco,"CODE",{});var ATa=s(axe);wKr=r(ATa,"__init__()"),ATa.forEach(t),AKr=r(Gco," (throws an error)."),Gco.forEach(t),LKr=i(Ai),ra=n(Ai,"DIV",{class:!0});var _$=s(ra);T(DP.$$.fragment,_$),yKr=i(_$),nxe=n(_$,"P",{});var LTa=s(nxe);xKr=r(LTa,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),LTa.forEach(t),$Kr=i(_$),Cc=n(_$,"P",{});var kge=s(Cc);kKr=r(kge,`Note:
Loading a model from its configuration file does `),sxe=n(kge,"STRONG",{});var yTa=s(sxe);SKr=r(yTa,"not"),yTa.forEach(t),RKr=r(kge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Bne=n(kge,"A",{href:!0});var xTa=s(Bne);PKr=r(xTa,"from_pretrained()"),xTa.forEach(t),BKr=r(kge," to load the model weights."),kge.forEach(t),IKr=i(_$),T(Uw.$$.fragment,_$),_$.forEach(t),NKr=i(Ai),Qr=n(Ai,"DIV",{class:!0});var Li=s(Qr);T(GP.$$.fragment,Li),qKr=i(Li),lxe=n(Li,"P",{});var $Ta=s(lxe);jKr=r($Ta,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),$Ta.forEach(t),DKr=i(Li),Vn=n(Li,"P",{});var b$=s(Vn);GKr=r(b$,"The model class to instantiate is selected based on the "),ixe=n(b$,"CODE",{});var kTa=s(ixe);OKr=r(kTa,"model_type"),kTa.forEach(t),VKr=r(b$,` property of the config object (either
passed as an argument or loaded from `),dxe=n(b$,"CODE",{});var STa=s(dxe);XKr=r(STa,"pretrained_model_name_or_path"),STa.forEach(t),zKr=r(b$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mxe=n(b$,"CODE",{});var RTa=s(mxe);QKr=r(RTa,"pretrained_model_name_or_path"),RTa.forEach(t),WKr=r(b$,":"),b$.forEach(t),UKr=i(Li),de=n(Li,"UL",{});var fe=s(de);Hw=n(fe,"LI",{});var Nro=s(Hw);cxe=n(Nro,"STRONG",{});var PTa=s(cxe);HKr=r(PTa,"albert"),PTa.forEach(t),JKr=r(Nro," \u2014 "),Ine=n(Nro,"A",{href:!0});var BTa=s(Ine);YKr=r(BTa,"TFAlbertForPreTraining"),BTa.forEach(t),ZKr=r(Nro," (ALBERT model)"),Nro.forEach(t),KKr=i(fe),Jw=n(fe,"LI",{});var qro=s(Jw);fxe=n(qro,"STRONG",{});var ITa=s(fxe);eet=r(ITa,"bart"),ITa.forEach(t),oet=r(qro," \u2014 "),Nne=n(qro,"A",{href:!0});var NTa=s(Nne);ret=r(NTa,"TFBartForConditionalGeneration"),NTa.forEach(t),tet=r(qro," (BART model)"),qro.forEach(t),aet=i(fe),Yw=n(fe,"LI",{});var jro=s(Yw);gxe=n(jro,"STRONG",{});var qTa=s(gxe);net=r(qTa,"bert"),qTa.forEach(t),set=r(jro," \u2014 "),qne=n(jro,"A",{href:!0});var jTa=s(qne);iet=r(jTa,"TFBertForPreTraining"),jTa.forEach(t),det=r(jro," (BERT model)"),jro.forEach(t),met=i(fe),Zw=n(fe,"LI",{});var Dro=s(Zw);hxe=n(Dro,"STRONG",{});var DTa=s(hxe);cet=r(DTa,"camembert"),DTa.forEach(t),fet=r(Dro," \u2014 "),jne=n(Dro,"A",{href:!0});var GTa=s(jne);get=r(GTa,"TFCamembertForMaskedLM"),GTa.forEach(t),het=r(Dro," (CamemBERT model)"),Dro.forEach(t),uet=i(fe),Kw=n(fe,"LI",{});var Gro=s(Kw);uxe=n(Gro,"STRONG",{});var OTa=s(uxe);pet=r(OTa,"ctrl"),OTa.forEach(t),_et=r(Gro," \u2014 "),Dne=n(Gro,"A",{href:!0});var VTa=s(Dne);bet=r(VTa,"TFCTRLLMHeadModel"),VTa.forEach(t),vet=r(Gro," (CTRL model)"),Gro.forEach(t),Fet=i(fe),eA=n(fe,"LI",{});var Oro=s(eA);pxe=n(Oro,"STRONG",{});var XTa=s(pxe);Tet=r(XTa,"distilbert"),XTa.forEach(t),Met=r(Oro," \u2014 "),Gne=n(Oro,"A",{href:!0});var zTa=s(Gne);Eet=r(zTa,"TFDistilBertForMaskedLM"),zTa.forEach(t),Cet=r(Oro," (DistilBERT model)"),Oro.forEach(t),wet=i(fe),oA=n(fe,"LI",{});var Vro=s(oA);_xe=n(Vro,"STRONG",{});var QTa=s(_xe);Aet=r(QTa,"electra"),QTa.forEach(t),Let=r(Vro," \u2014 "),One=n(Vro,"A",{href:!0});var WTa=s(One);yet=r(WTa,"TFElectraForPreTraining"),WTa.forEach(t),xet=r(Vro," (ELECTRA model)"),Vro.forEach(t),$et=i(fe),rA=n(fe,"LI",{});var Xro=s(rA);bxe=n(Xro,"STRONG",{});var UTa=s(bxe);ket=r(UTa,"flaubert"),UTa.forEach(t),Set=r(Xro," \u2014 "),Vne=n(Xro,"A",{href:!0});var HTa=s(Vne);Ret=r(HTa,"TFFlaubertWithLMHeadModel"),HTa.forEach(t),Pet=r(Xro," (FlauBERT model)"),Xro.forEach(t),Bet=i(fe),tA=n(fe,"LI",{});var zro=s(tA);vxe=n(zro,"STRONG",{});var JTa=s(vxe);Iet=r(JTa,"funnel"),JTa.forEach(t),Net=r(zro," \u2014 "),Xne=n(zro,"A",{href:!0});var YTa=s(Xne);qet=r(YTa,"TFFunnelForPreTraining"),YTa.forEach(t),jet=r(zro," (Funnel Transformer model)"),zro.forEach(t),Det=i(fe),aA=n(fe,"LI",{});var Qro=s(aA);Fxe=n(Qro,"STRONG",{});var ZTa=s(Fxe);Get=r(ZTa,"gpt2"),ZTa.forEach(t),Oet=r(Qro," \u2014 "),zne=n(Qro,"A",{href:!0});var KTa=s(zne);Vet=r(KTa,"TFGPT2LMHeadModel"),KTa.forEach(t),Xet=r(Qro," (OpenAI GPT-2 model)"),Qro.forEach(t),zet=i(fe),nA=n(fe,"LI",{});var Wro=s(nA);Txe=n(Wro,"STRONG",{});var eMa=s(Txe);Qet=r(eMa,"layoutlm"),eMa.forEach(t),Wet=r(Wro," \u2014 "),Qne=n(Wro,"A",{href:!0});var oMa=s(Qne);Uet=r(oMa,"TFLayoutLMForMaskedLM"),oMa.forEach(t),Het=r(Wro," (LayoutLM model)"),Wro.forEach(t),Jet=i(fe),sA=n(fe,"LI",{});var Uro=s(sA);Mxe=n(Uro,"STRONG",{});var rMa=s(Mxe);Yet=r(rMa,"lxmert"),rMa.forEach(t),Zet=r(Uro," \u2014 "),Wne=n(Uro,"A",{href:!0});var tMa=s(Wne);Ket=r(tMa,"TFLxmertForPreTraining"),tMa.forEach(t),eot=r(Uro," (LXMERT model)"),Uro.forEach(t),oot=i(fe),lA=n(fe,"LI",{});var Hro=s(lA);Exe=n(Hro,"STRONG",{});var aMa=s(Exe);rot=r(aMa,"mobilebert"),aMa.forEach(t),tot=r(Hro," \u2014 "),Une=n(Hro,"A",{href:!0});var nMa=s(Une);aot=r(nMa,"TFMobileBertForPreTraining"),nMa.forEach(t),not=r(Hro," (MobileBERT model)"),Hro.forEach(t),sot=i(fe),iA=n(fe,"LI",{});var Jro=s(iA);Cxe=n(Jro,"STRONG",{});var sMa=s(Cxe);lot=r(sMa,"mpnet"),sMa.forEach(t),iot=r(Jro," \u2014 "),Hne=n(Jro,"A",{href:!0});var lMa=s(Hne);dot=r(lMa,"TFMPNetForMaskedLM"),lMa.forEach(t),mot=r(Jro," (MPNet model)"),Jro.forEach(t),cot=i(fe),dA=n(fe,"LI",{});var Yro=s(dA);wxe=n(Yro,"STRONG",{});var iMa=s(wxe);fot=r(iMa,"openai-gpt"),iMa.forEach(t),got=r(Yro," \u2014 "),Jne=n(Yro,"A",{href:!0});var dMa=s(Jne);hot=r(dMa,"TFOpenAIGPTLMHeadModel"),dMa.forEach(t),uot=r(Yro," (OpenAI GPT model)"),Yro.forEach(t),pot=i(fe),mA=n(fe,"LI",{});var Zro=s(mA);Axe=n(Zro,"STRONG",{});var mMa=s(Axe);_ot=r(mMa,"roberta"),mMa.forEach(t),bot=r(Zro," \u2014 "),Yne=n(Zro,"A",{href:!0});var cMa=s(Yne);vot=r(cMa,"TFRobertaForMaskedLM"),cMa.forEach(t),Fot=r(Zro," (RoBERTa model)"),Zro.forEach(t),Tot=i(fe),cA=n(fe,"LI",{});var Kro=s(cA);Lxe=n(Kro,"STRONG",{});var fMa=s(Lxe);Mot=r(fMa,"t5"),fMa.forEach(t),Eot=r(Kro," \u2014 "),Zne=n(Kro,"A",{href:!0});var gMa=s(Zne);Cot=r(gMa,"TFT5ForConditionalGeneration"),gMa.forEach(t),wot=r(Kro," (T5 model)"),Kro.forEach(t),Aot=i(fe),fA=n(fe,"LI",{});var eto=s(fA);yxe=n(eto,"STRONG",{});var hMa=s(yxe);Lot=r(hMa,"tapas"),hMa.forEach(t),yot=r(eto," \u2014 "),Kne=n(eto,"A",{href:!0});var uMa=s(Kne);xot=r(uMa,"TFTapasForMaskedLM"),uMa.forEach(t),$ot=r(eto," (TAPAS model)"),eto.forEach(t),kot=i(fe),gA=n(fe,"LI",{});var oto=s(gA);xxe=n(oto,"STRONG",{});var pMa=s(xxe);Sot=r(pMa,"transfo-xl"),pMa.forEach(t),Rot=r(oto," \u2014 "),ese=n(oto,"A",{href:!0});var _Ma=s(ese);Pot=r(_Ma,"TFTransfoXLLMHeadModel"),_Ma.forEach(t),Bot=r(oto," (Transformer-XL model)"),oto.forEach(t),Iot=i(fe),hA=n(fe,"LI",{});var rto=s(hA);$xe=n(rto,"STRONG",{});var bMa=s($xe);Not=r(bMa,"vit_mae"),bMa.forEach(t),qot=r(rto," \u2014 "),ose=n(rto,"A",{href:!0});var vMa=s(ose);jot=r(vMa,"TFViTMAEForPreTraining"),vMa.forEach(t),Dot=r(rto," (ViTMAE model)"),rto.forEach(t),Got=i(fe),uA=n(fe,"LI",{});var tto=s(uA);kxe=n(tto,"STRONG",{});var FMa=s(kxe);Oot=r(FMa,"xlm"),FMa.forEach(t),Vot=r(tto," \u2014 "),rse=n(tto,"A",{href:!0});var TMa=s(rse);Xot=r(TMa,"TFXLMWithLMHeadModel"),TMa.forEach(t),zot=r(tto," (XLM model)"),tto.forEach(t),Qot=i(fe),pA=n(fe,"LI",{});var ato=s(pA);Sxe=n(ato,"STRONG",{});var MMa=s(Sxe);Wot=r(MMa,"xlm-roberta"),MMa.forEach(t),Uot=r(ato," \u2014 "),tse=n(ato,"A",{href:!0});var EMa=s(tse);Hot=r(EMa,"TFXLMRobertaForMaskedLM"),EMa.forEach(t),Jot=r(ato," (XLM-RoBERTa model)"),ato.forEach(t),Yot=i(fe),_A=n(fe,"LI",{});var nto=s(_A);Rxe=n(nto,"STRONG",{});var CMa=s(Rxe);Zot=r(CMa,"xlnet"),CMa.forEach(t),Kot=r(nto," \u2014 "),ase=n(nto,"A",{href:!0});var wMa=s(ase);ert=r(wMa,"TFXLNetLMHeadModel"),wMa.forEach(t),ort=r(nto," (XLNet model)"),nto.forEach(t),fe.forEach(t),rrt=i(Li),T(bA.$$.fragment,Li),Li.forEach(t),Ai.forEach(t),vdo=i(c),wc=n(c,"H2",{class:!0});var Oco=s(wc);vA=n(Oco,"A",{id:!0,class:!0,href:!0});var AMa=s(vA);Pxe=n(AMa,"SPAN",{});var LMa=s(Pxe);T(OP.$$.fragment,LMa),LMa.forEach(t),AMa.forEach(t),trt=i(Oco),Bxe=n(Oco,"SPAN",{});var yMa=s(Bxe);art=r(yMa,"TFAutoModelForCausalLM"),yMa.forEach(t),Oco.forEach(t),Fdo=i(c),_r=n(c,"DIV",{class:!0});var yi=s(_r);T(VP.$$.fragment,yi),nrt=i(yi),Ac=n(yi,"P",{});var Sge=s(Ac);srt=r(Sge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),nse=n(Sge,"A",{href:!0});var xMa=s(nse);lrt=r(xMa,"from_pretrained()"),xMa.forEach(t),irt=r(Sge," class method or the "),sse=n(Sge,"A",{href:!0});var $Ma=s(sse);drt=r($Ma,"from_config()"),$Ma.forEach(t),mrt=r(Sge,` class
method.`),Sge.forEach(t),crt=i(yi),XP=n(yi,"P",{});var Vco=s(XP);frt=r(Vco,"This class cannot be instantiated directly using "),Ixe=n(Vco,"CODE",{});var kMa=s(Ixe);grt=r(kMa,"__init__()"),kMa.forEach(t),hrt=r(Vco," (throws an error)."),Vco.forEach(t),urt=i(yi),ta=n(yi,"DIV",{class:!0});var v$=s(ta);T(zP.$$.fragment,v$),prt=i(v$),Nxe=n(v$,"P",{});var SMa=s(Nxe);_rt=r(SMa,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),SMa.forEach(t),brt=i(v$),Lc=n(v$,"P",{});var Rge=s(Lc);vrt=r(Rge,`Note:
Loading a model from its configuration file does `),qxe=n(Rge,"STRONG",{});var RMa=s(qxe);Frt=r(RMa,"not"),RMa.forEach(t),Trt=r(Rge,` load the model weights. It only affects the
model\u2019s configuration. Use `),lse=n(Rge,"A",{href:!0});var PMa=s(lse);Mrt=r(PMa,"from_pretrained()"),PMa.forEach(t),Ert=r(Rge," to load the model weights."),Rge.forEach(t),Crt=i(v$),T(FA.$$.fragment,v$),v$.forEach(t),wrt=i(yi),Wr=n(yi,"DIV",{class:!0});var xi=s(Wr);T(QP.$$.fragment,xi),Art=i(xi),jxe=n(xi,"P",{});var BMa=s(jxe);Lrt=r(BMa,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),BMa.forEach(t),yrt=i(xi),Xn=n(xi,"P",{});var F$=s(Xn);xrt=r(F$,"The model class to instantiate is selected based on the "),Dxe=n(F$,"CODE",{});var IMa=s(Dxe);$rt=r(IMa,"model_type"),IMa.forEach(t),krt=r(F$,` property of the config object (either
passed as an argument or loaded from `),Gxe=n(F$,"CODE",{});var NMa=s(Gxe);Srt=r(NMa,"pretrained_model_name_or_path"),NMa.forEach(t),Rrt=r(F$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Oxe=n(F$,"CODE",{});var qMa=s(Oxe);Prt=r(qMa,"pretrained_model_name_or_path"),qMa.forEach(t),Brt=r(F$,":"),F$.forEach(t),Irt=i(xi),Ce=n(xi,"UL",{});var Ae=s(Ce);TA=n(Ae,"LI",{});var sto=s(TA);Vxe=n(sto,"STRONG",{});var jMa=s(Vxe);Nrt=r(jMa,"bert"),jMa.forEach(t),qrt=r(sto," \u2014 "),ise=n(sto,"A",{href:!0});var DMa=s(ise);jrt=r(DMa,"TFBertLMHeadModel"),DMa.forEach(t),Drt=r(sto," (BERT model)"),sto.forEach(t),Grt=i(Ae),MA=n(Ae,"LI",{});var lto=s(MA);Xxe=n(lto,"STRONG",{});var GMa=s(Xxe);Ort=r(GMa,"camembert"),GMa.forEach(t),Vrt=r(lto," \u2014 "),dse=n(lto,"A",{href:!0});var OMa=s(dse);Xrt=r(OMa,"TFCamembertForCausalLM"),OMa.forEach(t),zrt=r(lto," (CamemBERT model)"),lto.forEach(t),Qrt=i(Ae),EA=n(Ae,"LI",{});var ito=s(EA);zxe=n(ito,"STRONG",{});var VMa=s(zxe);Wrt=r(VMa,"ctrl"),VMa.forEach(t),Urt=r(ito," \u2014 "),mse=n(ito,"A",{href:!0});var XMa=s(mse);Hrt=r(XMa,"TFCTRLLMHeadModel"),XMa.forEach(t),Jrt=r(ito," (CTRL model)"),ito.forEach(t),Yrt=i(Ae),CA=n(Ae,"LI",{});var dto=s(CA);Qxe=n(dto,"STRONG",{});var zMa=s(Qxe);Zrt=r(zMa,"gpt2"),zMa.forEach(t),Krt=r(dto," \u2014 "),cse=n(dto,"A",{href:!0});var QMa=s(cse);ett=r(QMa,"TFGPT2LMHeadModel"),QMa.forEach(t),ott=r(dto," (OpenAI GPT-2 model)"),dto.forEach(t),rtt=i(Ae),wA=n(Ae,"LI",{});var mto=s(wA);Wxe=n(mto,"STRONG",{});var WMa=s(Wxe);ttt=r(WMa,"gptj"),WMa.forEach(t),att=r(mto," \u2014 "),fse=n(mto,"A",{href:!0});var UMa=s(fse);ntt=r(UMa,"TFGPTJForCausalLM"),UMa.forEach(t),stt=r(mto," (GPT-J model)"),mto.forEach(t),ltt=i(Ae),AA=n(Ae,"LI",{});var cto=s(AA);Uxe=n(cto,"STRONG",{});var HMa=s(Uxe);itt=r(HMa,"openai-gpt"),HMa.forEach(t),dtt=r(cto," \u2014 "),gse=n(cto,"A",{href:!0});var JMa=s(gse);mtt=r(JMa,"TFOpenAIGPTLMHeadModel"),JMa.forEach(t),ctt=r(cto," (OpenAI GPT model)"),cto.forEach(t),ftt=i(Ae),LA=n(Ae,"LI",{});var fto=s(LA);Hxe=n(fto,"STRONG",{});var YMa=s(Hxe);gtt=r(YMa,"opt"),YMa.forEach(t),htt=r(fto," \u2014 "),hse=n(fto,"A",{href:!0});var ZMa=s(hse);utt=r(ZMa,"TFOPTForCausalLM"),ZMa.forEach(t),ptt=r(fto," (OPT model)"),fto.forEach(t),_tt=i(Ae),yA=n(Ae,"LI",{});var gto=s(yA);Jxe=n(gto,"STRONG",{});var KMa=s(Jxe);btt=r(KMa,"rembert"),KMa.forEach(t),vtt=r(gto," \u2014 "),use=n(gto,"A",{href:!0});var eEa=s(use);Ftt=r(eEa,"TFRemBertForCausalLM"),eEa.forEach(t),Ttt=r(gto," (RemBERT model)"),gto.forEach(t),Mtt=i(Ae),xA=n(Ae,"LI",{});var hto=s(xA);Yxe=n(hto,"STRONG",{});var oEa=s(Yxe);Ett=r(oEa,"roberta"),oEa.forEach(t),Ctt=r(hto," \u2014 "),pse=n(hto,"A",{href:!0});var rEa=s(pse);wtt=r(rEa,"TFRobertaForCausalLM"),rEa.forEach(t),Att=r(hto," (RoBERTa model)"),hto.forEach(t),Ltt=i(Ae),$A=n(Ae,"LI",{});var uto=s($A);Zxe=n(uto,"STRONG",{});var tEa=s(Zxe);ytt=r(tEa,"roformer"),tEa.forEach(t),xtt=r(uto," \u2014 "),_se=n(uto,"A",{href:!0});var aEa=s(_se);$tt=r(aEa,"TFRoFormerForCausalLM"),aEa.forEach(t),ktt=r(uto," (RoFormer model)"),uto.forEach(t),Stt=i(Ae),kA=n(Ae,"LI",{});var pto=s(kA);Kxe=n(pto,"STRONG",{});var nEa=s(Kxe);Rtt=r(nEa,"transfo-xl"),nEa.forEach(t),Ptt=r(pto," \u2014 "),bse=n(pto,"A",{href:!0});var sEa=s(bse);Btt=r(sEa,"TFTransfoXLLMHeadModel"),sEa.forEach(t),Itt=r(pto," (Transformer-XL model)"),pto.forEach(t),Ntt=i(Ae),SA=n(Ae,"LI",{});var _to=s(SA);e$e=n(_to,"STRONG",{});var lEa=s(e$e);qtt=r(lEa,"xglm"),lEa.forEach(t),jtt=r(_to," \u2014 "),vse=n(_to,"A",{href:!0});var iEa=s(vse);Dtt=r(iEa,"TFXGLMForCausalLM"),iEa.forEach(t),Gtt=r(_to," (XGLM model)"),_to.forEach(t),Ott=i(Ae),RA=n(Ae,"LI",{});var bto=s(RA);o$e=n(bto,"STRONG",{});var dEa=s(o$e);Vtt=r(dEa,"xlm"),dEa.forEach(t),Xtt=r(bto," \u2014 "),Fse=n(bto,"A",{href:!0});var mEa=s(Fse);ztt=r(mEa,"TFXLMWithLMHeadModel"),mEa.forEach(t),Qtt=r(bto," (XLM model)"),bto.forEach(t),Wtt=i(Ae),PA=n(Ae,"LI",{});var vto=s(PA);r$e=n(vto,"STRONG",{});var cEa=s(r$e);Utt=r(cEa,"xlnet"),cEa.forEach(t),Htt=r(vto," \u2014 "),Tse=n(vto,"A",{href:!0});var fEa=s(Tse);Jtt=r(fEa,"TFXLNetLMHeadModel"),fEa.forEach(t),Ytt=r(vto," (XLNet model)"),vto.forEach(t),Ae.forEach(t),Ztt=i(xi),T(BA.$$.fragment,xi),xi.forEach(t),yi.forEach(t),Tdo=i(c),yc=n(c,"H2",{class:!0});var Xco=s(yc);IA=n(Xco,"A",{id:!0,class:!0,href:!0});var gEa=s(IA);t$e=n(gEa,"SPAN",{});var hEa=s(t$e);T(WP.$$.fragment,hEa),hEa.forEach(t),gEa.forEach(t),Ktt=i(Xco),a$e=n(Xco,"SPAN",{});var uEa=s(a$e);eat=r(uEa,"TFAutoModelForImageClassification"),uEa.forEach(t),Xco.forEach(t),Mdo=i(c),br=n(c,"DIV",{class:!0});var $i=s(br);T(UP.$$.fragment,$i),oat=i($i),xc=n($i,"P",{});var Pge=s(xc);rat=r(Pge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Mse=n(Pge,"A",{href:!0});var pEa=s(Mse);tat=r(pEa,"from_pretrained()"),pEa.forEach(t),aat=r(Pge," class method or the "),Ese=n(Pge,"A",{href:!0});var _Ea=s(Ese);nat=r(_Ea,"from_config()"),_Ea.forEach(t),sat=r(Pge,` class
method.`),Pge.forEach(t),lat=i($i),HP=n($i,"P",{});var zco=s(HP);iat=r(zco,"This class cannot be instantiated directly using "),n$e=n(zco,"CODE",{});var bEa=s(n$e);dat=r(bEa,"__init__()"),bEa.forEach(t),mat=r(zco," (throws an error)."),zco.forEach(t),cat=i($i),aa=n($i,"DIV",{class:!0});var T$=s(aa);T(JP.$$.fragment,T$),fat=i(T$),s$e=n(T$,"P",{});var vEa=s(s$e);gat=r(vEa,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),vEa.forEach(t),hat=i(T$),$c=n(T$,"P",{});var Bge=s($c);uat=r(Bge,`Note:
Loading a model from its configuration file does `),l$e=n(Bge,"STRONG",{});var FEa=s(l$e);pat=r(FEa,"not"),FEa.forEach(t),_at=r(Bge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cse=n(Bge,"A",{href:!0});var TEa=s(Cse);bat=r(TEa,"from_pretrained()"),TEa.forEach(t),vat=r(Bge," to load the model weights."),Bge.forEach(t),Fat=i(T$),T(NA.$$.fragment,T$),T$.forEach(t),Tat=i($i),Ur=n($i,"DIV",{class:!0});var ki=s(Ur);T(YP.$$.fragment,ki),Mat=i(ki),i$e=n(ki,"P",{});var MEa=s(i$e);Eat=r(MEa,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),MEa.forEach(t),Cat=i(ki),zn=n(ki,"P",{});var M$=s(zn);wat=r(M$,"The model class to instantiate is selected based on the "),d$e=n(M$,"CODE",{});var EEa=s(d$e);Aat=r(EEa,"model_type"),EEa.forEach(t),Lat=r(M$,` property of the config object (either
passed as an argument or loaded from `),m$e=n(M$,"CODE",{});var CEa=s(m$e);yat=r(CEa,"pretrained_model_name_or_path"),CEa.forEach(t),xat=r(M$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c$e=n(M$,"CODE",{});var wEa=s(c$e);$at=r(wEa,"pretrained_model_name_or_path"),wEa.forEach(t),kat=r(M$,":"),M$.forEach(t),Sat=i(ki),$e=n(ki,"UL",{});var je=s($e);qA=n(je,"LI",{});var Fto=s(qA);f$e=n(Fto,"STRONG",{});var AEa=s(f$e);Rat=r(AEa,"convnext"),AEa.forEach(t),Pat=r(Fto," \u2014 "),wse=n(Fto,"A",{href:!0});var LEa=s(wse);Bat=r(LEa,"TFConvNextForImageClassification"),LEa.forEach(t),Iat=r(Fto," (ConvNeXT model)"),Fto.forEach(t),Nat=i(je),jA=n(je,"LI",{});var Tto=s(jA);g$e=n(Tto,"STRONG",{});var yEa=s(g$e);qat=r(yEa,"cvt"),yEa.forEach(t),jat=r(Tto," \u2014 "),Ase=n(Tto,"A",{href:!0});var xEa=s(Ase);Dat=r(xEa,"TFCvtForImageClassification"),xEa.forEach(t),Gat=r(Tto," (CvT model)"),Tto.forEach(t),Oat=i(je),DA=n(je,"LI",{});var Mto=s(DA);h$e=n(Mto,"STRONG",{});var $Ea=s(h$e);Vat=r($Ea,"data2vec-vision"),$Ea.forEach(t),Xat=r(Mto," \u2014 "),Lse=n(Mto,"A",{href:!0});var kEa=s(Lse);zat=r(kEa,"TFData2VecVisionForImageClassification"),kEa.forEach(t),Qat=r(Mto," (Data2VecVision model)"),Mto.forEach(t),Wat=i(je),Gl=n(je,"LI",{});var Dq=s(Gl);u$e=n(Dq,"STRONG",{});var SEa=s(u$e);Uat=r(SEa,"deit"),SEa.forEach(t),Hat=r(Dq," \u2014 "),yse=n(Dq,"A",{href:!0});var REa=s(yse);Jat=r(REa,"TFDeiTForImageClassification"),REa.forEach(t),Yat=r(Dq," or "),xse=n(Dq,"A",{href:!0});var PEa=s(xse);Zat=r(PEa,"TFDeiTForImageClassificationWithTeacher"),PEa.forEach(t),Kat=r(Dq," (DeiT model)"),Dq.forEach(t),ent=i(je),GA=n(je,"LI",{});var Eto=s(GA);p$e=n(Eto,"STRONG",{});var BEa=s(p$e);ont=r(BEa,"mobilevit"),BEa.forEach(t),rnt=r(Eto," \u2014 "),$se=n(Eto,"A",{href:!0});var IEa=s($se);tnt=r(IEa,"TFMobileViTForImageClassification"),IEa.forEach(t),ant=r(Eto," (MobileViT model)"),Eto.forEach(t),nnt=i(je),OA=n(je,"LI",{});var Cto=s(OA);_$e=n(Cto,"STRONG",{});var NEa=s(_$e);snt=r(NEa,"regnet"),NEa.forEach(t),lnt=r(Cto," \u2014 "),kse=n(Cto,"A",{href:!0});var qEa=s(kse);int=r(qEa,"TFRegNetForImageClassification"),qEa.forEach(t),dnt=r(Cto," (RegNet model)"),Cto.forEach(t),mnt=i(je),VA=n(je,"LI",{});var wto=s(VA);b$e=n(wto,"STRONG",{});var jEa=s(b$e);cnt=r(jEa,"resnet"),jEa.forEach(t),fnt=r(wto," \u2014 "),Sse=n(wto,"A",{href:!0});var DEa=s(Sse);gnt=r(DEa,"TFResNetForImageClassification"),DEa.forEach(t),hnt=r(wto," (ResNet model)"),wto.forEach(t),unt=i(je),XA=n(je,"LI",{});var Ato=s(XA);v$e=n(Ato,"STRONG",{});var GEa=s(v$e);pnt=r(GEa,"segformer"),GEa.forEach(t),_nt=r(Ato," \u2014 "),Rse=n(Ato,"A",{href:!0});var OEa=s(Rse);bnt=r(OEa,"TFSegformerForImageClassification"),OEa.forEach(t),vnt=r(Ato," (SegFormer model)"),Ato.forEach(t),Fnt=i(je),zA=n(je,"LI",{});var Lto=s(zA);F$e=n(Lto,"STRONG",{});var VEa=s(F$e);Tnt=r(VEa,"swin"),VEa.forEach(t),Mnt=r(Lto," \u2014 "),Pse=n(Lto,"A",{href:!0});var XEa=s(Pse);Ent=r(XEa,"TFSwinForImageClassification"),XEa.forEach(t),Cnt=r(Lto," (Swin Transformer model)"),Lto.forEach(t),wnt=i(je),QA=n(je,"LI",{});var yto=s(QA);T$e=n(yto,"STRONG",{});var zEa=s(T$e);Ant=r(zEa,"vit"),zEa.forEach(t),Lnt=r(yto," \u2014 "),Bse=n(yto,"A",{href:!0});var QEa=s(Bse);ynt=r(QEa,"TFViTForImageClassification"),QEa.forEach(t),xnt=r(yto," (ViT model)"),yto.forEach(t),je.forEach(t),$nt=i(ki),T(WA.$$.fragment,ki),ki.forEach(t),$i.forEach(t),Edo=i(c),kc=n(c,"H2",{class:!0});var Qco=s(kc);UA=n(Qco,"A",{id:!0,class:!0,href:!0});var WEa=s(UA);M$e=n(WEa,"SPAN",{});var UEa=s(M$e);T(ZP.$$.fragment,UEa),UEa.forEach(t),WEa.forEach(t),knt=i(Qco),E$e=n(Qco,"SPAN",{});var HEa=s(E$e);Snt=r(HEa,"TFAutoModelForSemanticSegmentation"),HEa.forEach(t),Qco.forEach(t),Cdo=i(c),vr=n(c,"DIV",{class:!0});var Si=s(vr);T(KP.$$.fragment,Si),Rnt=i(Si),Sc=n(Si,"P",{});var Ige=s(Sc);Pnt=r(Ige,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),Ise=n(Ige,"A",{href:!0});var JEa=s(Ise);Bnt=r(JEa,"from_pretrained()"),JEa.forEach(t),Int=r(Ige," class method or the "),Nse=n(Ige,"A",{href:!0});var YEa=s(Nse);Nnt=r(YEa,"from_config()"),YEa.forEach(t),qnt=r(Ige,` class
method.`),Ige.forEach(t),jnt=i(Si),eB=n(Si,"P",{});var Wco=s(eB);Dnt=r(Wco,"This class cannot be instantiated directly using "),C$e=n(Wco,"CODE",{});var ZEa=s(C$e);Gnt=r(ZEa,"__init__()"),ZEa.forEach(t),Ont=r(Wco," (throws an error)."),Wco.forEach(t),Vnt=i(Si),na=n(Si,"DIV",{class:!0});var E$=s(na);T(oB.$$.fragment,E$),Xnt=i(E$),w$e=n(E$,"P",{});var KEa=s(w$e);znt=r(KEa,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),KEa.forEach(t),Qnt=i(E$),Rc=n(E$,"P",{});var Nge=s(Rc);Wnt=r(Nge,`Note:
Loading a model from its configuration file does `),A$e=n(Nge,"STRONG",{});var e4a=s(A$e);Unt=r(e4a,"not"),e4a.forEach(t),Hnt=r(Nge,` load the model weights. It only affects the
model\u2019s configuration. Use `),qse=n(Nge,"A",{href:!0});var o4a=s(qse);Jnt=r(o4a,"from_pretrained()"),o4a.forEach(t),Ynt=r(Nge," to load the model weights."),Nge.forEach(t),Znt=i(E$),T(HA.$$.fragment,E$),E$.forEach(t),Knt=i(Si),Hr=n(Si,"DIV",{class:!0});var Ri=s(Hr);T(rB.$$.fragment,Ri),est=i(Ri),L$e=n(Ri,"P",{});var r4a=s(L$e);ost=r(r4a,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),r4a.forEach(t),rst=i(Ri),Qn=n(Ri,"P",{});var C$=s(Qn);tst=r(C$,"The model class to instantiate is selected based on the "),y$e=n(C$,"CODE",{});var t4a=s(y$e);ast=r(t4a,"model_type"),t4a.forEach(t),nst=r(C$,` property of the config object (either
passed as an argument or loaded from `),x$e=n(C$,"CODE",{});var a4a=s(x$e);sst=r(a4a,"pretrained_model_name_or_path"),a4a.forEach(t),lst=r(C$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$$e=n(C$,"CODE",{});var n4a=s($$e);ist=r(n4a,"pretrained_model_name_or_path"),n4a.forEach(t),dst=r(C$,":"),C$.forEach(t),mst=i(Ri),Pc=n(Ri,"UL",{});var qge=s(Pc);JA=n(qge,"LI",{});var xto=s(JA);k$e=n(xto,"STRONG",{});var s4a=s(k$e);cst=r(s4a,"data2vec-vision"),s4a.forEach(t),fst=r(xto," \u2014 "),jse=n(xto,"A",{href:!0});var l4a=s(jse);gst=r(l4a,"TFData2VecVisionForSemanticSegmentation"),l4a.forEach(t),hst=r(xto," (Data2VecVision model)"),xto.forEach(t),ust=i(qge),YA=n(qge,"LI",{});var $to=s(YA);S$e=n($to,"STRONG",{});var i4a=s(S$e);pst=r(i4a,"mobilevit"),i4a.forEach(t),_st=r($to," \u2014 "),Dse=n($to,"A",{href:!0});var d4a=s(Dse);bst=r(d4a,"TFMobileViTForSemanticSegmentation"),d4a.forEach(t),vst=r($to," (MobileViT model)"),$to.forEach(t),Fst=i(qge),ZA=n(qge,"LI",{});var kto=s(ZA);R$e=n(kto,"STRONG",{});var m4a=s(R$e);Tst=r(m4a,"segformer"),m4a.forEach(t),Mst=r(kto," \u2014 "),Gse=n(kto,"A",{href:!0});var c4a=s(Gse);Est=r(c4a,"TFSegformerForSemanticSegmentation"),c4a.forEach(t),Cst=r(kto," (SegFormer model)"),kto.forEach(t),qge.forEach(t),wst=i(Ri),T(KA.$$.fragment,Ri),Ri.forEach(t),Si.forEach(t),wdo=i(c),Bc=n(c,"H2",{class:!0});var Uco=s(Bc);e6=n(Uco,"A",{id:!0,class:!0,href:!0});var f4a=s(e6);P$e=n(f4a,"SPAN",{});var g4a=s(P$e);T(tB.$$.fragment,g4a),g4a.forEach(t),f4a.forEach(t),Ast=i(Uco),B$e=n(Uco,"SPAN",{});var h4a=s(B$e);Lst=r(h4a,"TFAutoModelForMaskedLM"),h4a.forEach(t),Uco.forEach(t),Ado=i(c),Fr=n(c,"DIV",{class:!0});var Pi=s(Fr);T(aB.$$.fragment,Pi),yst=i(Pi),Ic=n(Pi,"P",{});var jge=s(Ic);xst=r(jge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Ose=n(jge,"A",{href:!0});var u4a=s(Ose);$st=r(u4a,"from_pretrained()"),u4a.forEach(t),kst=r(jge," class method or the "),Vse=n(jge,"A",{href:!0});var p4a=s(Vse);Sst=r(p4a,"from_config()"),p4a.forEach(t),Rst=r(jge,` class
method.`),jge.forEach(t),Pst=i(Pi),nB=n(Pi,"P",{});var Hco=s(nB);Bst=r(Hco,"This class cannot be instantiated directly using "),I$e=n(Hco,"CODE",{});var _4a=s(I$e);Ist=r(_4a,"__init__()"),_4a.forEach(t),Nst=r(Hco," (throws an error)."),Hco.forEach(t),qst=i(Pi),sa=n(Pi,"DIV",{class:!0});var w$=s(sa);T(sB.$$.fragment,w$),jst=i(w$),N$e=n(w$,"P",{});var b4a=s(N$e);Dst=r(b4a,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),b4a.forEach(t),Gst=i(w$),Nc=n(w$,"P",{});var Dge=s(Nc);Ost=r(Dge,`Note:
Loading a model from its configuration file does `),q$e=n(Dge,"STRONG",{});var v4a=s(q$e);Vst=r(v4a,"not"),v4a.forEach(t),Xst=r(Dge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Xse=n(Dge,"A",{href:!0});var F4a=s(Xse);zst=r(F4a,"from_pretrained()"),F4a.forEach(t),Qst=r(Dge," to load the model weights."),Dge.forEach(t),Wst=i(w$),T(o6.$$.fragment,w$),w$.forEach(t),Ust=i(Pi),Jr=n(Pi,"DIV",{class:!0});var Bi=s(Jr);T(lB.$$.fragment,Bi),Hst=i(Bi),j$e=n(Bi,"P",{});var T4a=s(j$e);Jst=r(T4a,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),T4a.forEach(t),Yst=i(Bi),Wn=n(Bi,"P",{});var A$=s(Wn);Zst=r(A$,"The model class to instantiate is selected based on the "),D$e=n(A$,"CODE",{});var M4a=s(D$e);Kst=r(M4a,"model_type"),M4a.forEach(t),elt=r(A$,` property of the config object (either
passed as an argument or loaded from `),G$e=n(A$,"CODE",{});var E4a=s(G$e);olt=r(E4a,"pretrained_model_name_or_path"),E4a.forEach(t),rlt=r(A$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),O$e=n(A$,"CODE",{});var C4a=s(O$e);tlt=r(C4a,"pretrained_model_name_or_path"),C4a.forEach(t),alt=r(A$,":"),A$.forEach(t),nlt=i(Bi),ge=n(Bi,"UL",{});var _e=s(ge);r6=n(_e,"LI",{});var Sto=s(r6);V$e=n(Sto,"STRONG",{});var w4a=s(V$e);slt=r(w4a,"albert"),w4a.forEach(t),llt=r(Sto," \u2014 "),zse=n(Sto,"A",{href:!0});var A4a=s(zse);ilt=r(A4a,"TFAlbertForMaskedLM"),A4a.forEach(t),dlt=r(Sto," (ALBERT model)"),Sto.forEach(t),mlt=i(_e),t6=n(_e,"LI",{});var Rto=s(t6);X$e=n(Rto,"STRONG",{});var L4a=s(X$e);clt=r(L4a,"bert"),L4a.forEach(t),flt=r(Rto," \u2014 "),Qse=n(Rto,"A",{href:!0});var y4a=s(Qse);glt=r(y4a,"TFBertForMaskedLM"),y4a.forEach(t),hlt=r(Rto," (BERT model)"),Rto.forEach(t),ult=i(_e),a6=n(_e,"LI",{});var Pto=s(a6);z$e=n(Pto,"STRONG",{});var x4a=s(z$e);plt=r(x4a,"camembert"),x4a.forEach(t),_lt=r(Pto," \u2014 "),Wse=n(Pto,"A",{href:!0});var $4a=s(Wse);blt=r($4a,"TFCamembertForMaskedLM"),$4a.forEach(t),vlt=r(Pto," (CamemBERT model)"),Pto.forEach(t),Flt=i(_e),n6=n(_e,"LI",{});var Bto=s(n6);Q$e=n(Bto,"STRONG",{});var k4a=s(Q$e);Tlt=r(k4a,"convbert"),k4a.forEach(t),Mlt=r(Bto," \u2014 "),Use=n(Bto,"A",{href:!0});var S4a=s(Use);Elt=r(S4a,"TFConvBertForMaskedLM"),S4a.forEach(t),Clt=r(Bto," (ConvBERT model)"),Bto.forEach(t),wlt=i(_e),s6=n(_e,"LI",{});var Ito=s(s6);W$e=n(Ito,"STRONG",{});var R4a=s(W$e);Alt=r(R4a,"deberta"),R4a.forEach(t),Llt=r(Ito," \u2014 "),Hse=n(Ito,"A",{href:!0});var P4a=s(Hse);ylt=r(P4a,"TFDebertaForMaskedLM"),P4a.forEach(t),xlt=r(Ito," (DeBERTa model)"),Ito.forEach(t),$lt=i(_e),l6=n(_e,"LI",{});var Nto=s(l6);U$e=n(Nto,"STRONG",{});var B4a=s(U$e);klt=r(B4a,"deberta-v2"),B4a.forEach(t),Slt=r(Nto," \u2014 "),Jse=n(Nto,"A",{href:!0});var I4a=s(Jse);Rlt=r(I4a,"TFDebertaV2ForMaskedLM"),I4a.forEach(t),Plt=r(Nto," (DeBERTa-v2 model)"),Nto.forEach(t),Blt=i(_e),i6=n(_e,"LI",{});var qto=s(i6);H$e=n(qto,"STRONG",{});var N4a=s(H$e);Ilt=r(N4a,"distilbert"),N4a.forEach(t),Nlt=r(qto," \u2014 "),Yse=n(qto,"A",{href:!0});var q4a=s(Yse);qlt=r(q4a,"TFDistilBertForMaskedLM"),q4a.forEach(t),jlt=r(qto," (DistilBERT model)"),qto.forEach(t),Dlt=i(_e),d6=n(_e,"LI",{});var jto=s(d6);J$e=n(jto,"STRONG",{});var j4a=s(J$e);Glt=r(j4a,"electra"),j4a.forEach(t),Olt=r(jto," \u2014 "),Zse=n(jto,"A",{href:!0});var D4a=s(Zse);Vlt=r(D4a,"TFElectraForMaskedLM"),D4a.forEach(t),Xlt=r(jto," (ELECTRA model)"),jto.forEach(t),zlt=i(_e),m6=n(_e,"LI",{});var Dto=s(m6);Y$e=n(Dto,"STRONG",{});var G4a=s(Y$e);Qlt=r(G4a,"esm"),G4a.forEach(t),Wlt=r(Dto," \u2014 "),Kse=n(Dto,"A",{href:!0});var O4a=s(Kse);Ult=r(O4a,"TFEsmForMaskedLM"),O4a.forEach(t),Hlt=r(Dto," (ESM model)"),Dto.forEach(t),Jlt=i(_e),c6=n(_e,"LI",{});var Gto=s(c6);Z$e=n(Gto,"STRONG",{});var V4a=s(Z$e);Ylt=r(V4a,"flaubert"),V4a.forEach(t),Zlt=r(Gto," \u2014 "),ele=n(Gto,"A",{href:!0});var X4a=s(ele);Klt=r(X4a,"TFFlaubertWithLMHeadModel"),X4a.forEach(t),eit=r(Gto," (FlauBERT model)"),Gto.forEach(t),oit=i(_e),f6=n(_e,"LI",{});var Oto=s(f6);K$e=n(Oto,"STRONG",{});var z4a=s(K$e);rit=r(z4a,"funnel"),z4a.forEach(t),tit=r(Oto," \u2014 "),ole=n(Oto,"A",{href:!0});var Q4a=s(ole);ait=r(Q4a,"TFFunnelForMaskedLM"),Q4a.forEach(t),nit=r(Oto," (Funnel Transformer model)"),Oto.forEach(t),sit=i(_e),g6=n(_e,"LI",{});var Vto=s(g6);eke=n(Vto,"STRONG",{});var W4a=s(eke);lit=r(W4a,"layoutlm"),W4a.forEach(t),iit=r(Vto," \u2014 "),rle=n(Vto,"A",{href:!0});var U4a=s(rle);dit=r(U4a,"TFLayoutLMForMaskedLM"),U4a.forEach(t),mit=r(Vto," (LayoutLM model)"),Vto.forEach(t),cit=i(_e),h6=n(_e,"LI",{});var Xto=s(h6);oke=n(Xto,"STRONG",{});var H4a=s(oke);fit=r(H4a,"longformer"),H4a.forEach(t),git=r(Xto," \u2014 "),tle=n(Xto,"A",{href:!0});var J4a=s(tle);hit=r(J4a,"TFLongformerForMaskedLM"),J4a.forEach(t),uit=r(Xto," (Longformer model)"),Xto.forEach(t),pit=i(_e),u6=n(_e,"LI",{});var zto=s(u6);rke=n(zto,"STRONG",{});var Y4a=s(rke);_it=r(Y4a,"mobilebert"),Y4a.forEach(t),bit=r(zto," \u2014 "),ale=n(zto,"A",{href:!0});var Z4a=s(ale);vit=r(Z4a,"TFMobileBertForMaskedLM"),Z4a.forEach(t),Fit=r(zto," (MobileBERT model)"),zto.forEach(t),Tit=i(_e),p6=n(_e,"LI",{});var Qto=s(p6);tke=n(Qto,"STRONG",{});var K4a=s(tke);Mit=r(K4a,"mpnet"),K4a.forEach(t),Eit=r(Qto," \u2014 "),nle=n(Qto,"A",{href:!0});var eCa=s(nle);Cit=r(eCa,"TFMPNetForMaskedLM"),eCa.forEach(t),wit=r(Qto," (MPNet model)"),Qto.forEach(t),Ait=i(_e),_6=n(_e,"LI",{});var Wto=s(_6);ake=n(Wto,"STRONG",{});var oCa=s(ake);Lit=r(oCa,"rembert"),oCa.forEach(t),yit=r(Wto," \u2014 "),sle=n(Wto,"A",{href:!0});var rCa=s(sle);xit=r(rCa,"TFRemBertForMaskedLM"),rCa.forEach(t),$it=r(Wto," (RemBERT model)"),Wto.forEach(t),kit=i(_e),b6=n(_e,"LI",{});var Uto=s(b6);nke=n(Uto,"STRONG",{});var tCa=s(nke);Sit=r(tCa,"roberta"),tCa.forEach(t),Rit=r(Uto," \u2014 "),lle=n(Uto,"A",{href:!0});var aCa=s(lle);Pit=r(aCa,"TFRobertaForMaskedLM"),aCa.forEach(t),Bit=r(Uto," (RoBERTa model)"),Uto.forEach(t),Iit=i(_e),v6=n(_e,"LI",{});var Hto=s(v6);ske=n(Hto,"STRONG",{});var nCa=s(ske);Nit=r(nCa,"roformer"),nCa.forEach(t),qit=r(Hto," \u2014 "),ile=n(Hto,"A",{href:!0});var sCa=s(ile);jit=r(sCa,"TFRoFormerForMaskedLM"),sCa.forEach(t),Dit=r(Hto," (RoFormer model)"),Hto.forEach(t),Git=i(_e),F6=n(_e,"LI",{});var Jto=s(F6);lke=n(Jto,"STRONG",{});var lCa=s(lke);Oit=r(lCa,"tapas"),lCa.forEach(t),Vit=r(Jto," \u2014 "),dle=n(Jto,"A",{href:!0});var iCa=s(dle);Xit=r(iCa,"TFTapasForMaskedLM"),iCa.forEach(t),zit=r(Jto," (TAPAS model)"),Jto.forEach(t),Qit=i(_e),T6=n(_e,"LI",{});var Yto=s(T6);ike=n(Yto,"STRONG",{});var dCa=s(ike);Wit=r(dCa,"xlm"),dCa.forEach(t),Uit=r(Yto," \u2014 "),mle=n(Yto,"A",{href:!0});var mCa=s(mle);Hit=r(mCa,"TFXLMWithLMHeadModel"),mCa.forEach(t),Jit=r(Yto," (XLM model)"),Yto.forEach(t),Yit=i(_e),M6=n(_e,"LI",{});var Zto=s(M6);dke=n(Zto,"STRONG",{});var cCa=s(dke);Zit=r(cCa,"xlm-roberta"),cCa.forEach(t),Kit=r(Zto," \u2014 "),cle=n(Zto,"A",{href:!0});var fCa=s(cle);edt=r(fCa,"TFXLMRobertaForMaskedLM"),fCa.forEach(t),odt=r(Zto," (XLM-RoBERTa model)"),Zto.forEach(t),_e.forEach(t),rdt=i(Bi),T(E6.$$.fragment,Bi),Bi.forEach(t),Pi.forEach(t),Ldo=i(c),qc=n(c,"H2",{class:!0});var Jco=s(qc);C6=n(Jco,"A",{id:!0,class:!0,href:!0});var gCa=s(C6);mke=n(gCa,"SPAN",{});var hCa=s(mke);T(iB.$$.fragment,hCa),hCa.forEach(t),gCa.forEach(t),tdt=i(Jco),cke=n(Jco,"SPAN",{});var uCa=s(cke);adt=r(uCa,"TFAutoModelForSeq2SeqLM"),uCa.forEach(t),Jco.forEach(t),ydo=i(c),Tr=n(c,"DIV",{class:!0});var Ii=s(Tr);T(dB.$$.fragment,Ii),ndt=i(Ii),jc=n(Ii,"P",{});var Gge=s(jc);sdt=r(Gge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),fle=n(Gge,"A",{href:!0});var pCa=s(fle);ldt=r(pCa,"from_pretrained()"),pCa.forEach(t),idt=r(Gge," class method or the "),gle=n(Gge,"A",{href:!0});var _Ca=s(gle);ddt=r(_Ca,"from_config()"),_Ca.forEach(t),mdt=r(Gge,` class
method.`),Gge.forEach(t),cdt=i(Ii),mB=n(Ii,"P",{});var Yco=s(mB);fdt=r(Yco,"This class cannot be instantiated directly using "),fke=n(Yco,"CODE",{});var bCa=s(fke);gdt=r(bCa,"__init__()"),bCa.forEach(t),hdt=r(Yco," (throws an error)."),Yco.forEach(t),udt=i(Ii),la=n(Ii,"DIV",{class:!0});var L$=s(la);T(cB.$$.fragment,L$),pdt=i(L$),gke=n(L$,"P",{});var vCa=s(gke);_dt=r(vCa,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),vCa.forEach(t),bdt=i(L$),Dc=n(L$,"P",{});var Oge=s(Dc);vdt=r(Oge,`Note:
Loading a model from its configuration file does `),hke=n(Oge,"STRONG",{});var FCa=s(hke);Fdt=r(FCa,"not"),FCa.forEach(t),Tdt=r(Oge,` load the model weights. It only affects the
model\u2019s configuration. Use `),hle=n(Oge,"A",{href:!0});var TCa=s(hle);Mdt=r(TCa,"from_pretrained()"),TCa.forEach(t),Edt=r(Oge," to load the model weights."),Oge.forEach(t),Cdt=i(L$),T(w6.$$.fragment,L$),L$.forEach(t),wdt=i(Ii),Yr=n(Ii,"DIV",{class:!0});var Ni=s(Yr);T(fB.$$.fragment,Ni),Adt=i(Ni),uke=n(Ni,"P",{});var MCa=s(uke);Ldt=r(MCa,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),MCa.forEach(t),ydt=i(Ni),Un=n(Ni,"P",{});var y$=s(Un);xdt=r(y$,"The model class to instantiate is selected based on the "),pke=n(y$,"CODE",{});var ECa=s(pke);$dt=r(ECa,"model_type"),ECa.forEach(t),kdt=r(y$,` property of the config object (either
passed as an argument or loaded from `),_ke=n(y$,"CODE",{});var CCa=s(_ke);Sdt=r(CCa,"pretrained_model_name_or_path"),CCa.forEach(t),Rdt=r(y$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bke=n(y$,"CODE",{});var wCa=s(bke);Pdt=r(wCa,"pretrained_model_name_or_path"),wCa.forEach(t),Bdt=r(y$,":"),y$.forEach(t),Idt=i(Ni),ke=n(Ni,"UL",{});var De=s(ke);A6=n(De,"LI",{});var Kto=s(A6);vke=n(Kto,"STRONG",{});var ACa=s(vke);Ndt=r(ACa,"bart"),ACa.forEach(t),qdt=r(Kto," \u2014 "),ule=n(Kto,"A",{href:!0});var LCa=s(ule);jdt=r(LCa,"TFBartForConditionalGeneration"),LCa.forEach(t),Ddt=r(Kto," (BART model)"),Kto.forEach(t),Gdt=i(De),L6=n(De,"LI",{});var eao=s(L6);Fke=n(eao,"STRONG",{});var yCa=s(Fke);Odt=r(yCa,"blenderbot"),yCa.forEach(t),Vdt=r(eao," \u2014 "),ple=n(eao,"A",{href:!0});var xCa=s(ple);Xdt=r(xCa,"TFBlenderbotForConditionalGeneration"),xCa.forEach(t),zdt=r(eao," (Blenderbot model)"),eao.forEach(t),Qdt=i(De),y6=n(De,"LI",{});var oao=s(y6);Tke=n(oao,"STRONG",{});var $Ca=s(Tke);Wdt=r($Ca,"blenderbot-small"),$Ca.forEach(t),Udt=r(oao," \u2014 "),_le=n(oao,"A",{href:!0});var kCa=s(_le);Hdt=r(kCa,"TFBlenderbotSmallForConditionalGeneration"),kCa.forEach(t),Jdt=r(oao," (BlenderbotSmall model)"),oao.forEach(t),Ydt=i(De),x6=n(De,"LI",{});var rao=s(x6);Mke=n(rao,"STRONG",{});var SCa=s(Mke);Zdt=r(SCa,"encoder-decoder"),SCa.forEach(t),Kdt=r(rao," \u2014 "),ble=n(rao,"A",{href:!0});var RCa=s(ble);emt=r(RCa,"TFEncoderDecoderModel"),RCa.forEach(t),omt=r(rao," (Encoder decoder model)"),rao.forEach(t),rmt=i(De),$6=n(De,"LI",{});var tao=s($6);Eke=n(tao,"STRONG",{});var PCa=s(Eke);tmt=r(PCa,"led"),PCa.forEach(t),amt=r(tao," \u2014 "),vle=n(tao,"A",{href:!0});var BCa=s(vle);nmt=r(BCa,"TFLEDForConditionalGeneration"),BCa.forEach(t),smt=r(tao," (LED model)"),tao.forEach(t),lmt=i(De),k6=n(De,"LI",{});var aao=s(k6);Cke=n(aao,"STRONG",{});var ICa=s(Cke);imt=r(ICa,"marian"),ICa.forEach(t),dmt=r(aao," \u2014 "),Fle=n(aao,"A",{href:!0});var NCa=s(Fle);mmt=r(NCa,"TFMarianMTModel"),NCa.forEach(t),cmt=r(aao," (Marian model)"),aao.forEach(t),fmt=i(De),S6=n(De,"LI",{});var nao=s(S6);wke=n(nao,"STRONG",{});var qCa=s(wke);gmt=r(qCa,"mbart"),qCa.forEach(t),hmt=r(nao," \u2014 "),Tle=n(nao,"A",{href:!0});var jCa=s(Tle);umt=r(jCa,"TFMBartForConditionalGeneration"),jCa.forEach(t),pmt=r(nao," (mBART model)"),nao.forEach(t),_mt=i(De),R6=n(De,"LI",{});var sao=s(R6);Ake=n(sao,"STRONG",{});var DCa=s(Ake);bmt=r(DCa,"mt5"),DCa.forEach(t),vmt=r(sao," \u2014 "),Mle=n(sao,"A",{href:!0});var GCa=s(Mle);Fmt=r(GCa,"TFMT5ForConditionalGeneration"),GCa.forEach(t),Tmt=r(sao," (MT5 model)"),sao.forEach(t),Mmt=i(De),P6=n(De,"LI",{});var lao=s(P6);Lke=n(lao,"STRONG",{});var OCa=s(Lke);Emt=r(OCa,"pegasus"),OCa.forEach(t),Cmt=r(lao," \u2014 "),Ele=n(lao,"A",{href:!0});var VCa=s(Ele);wmt=r(VCa,"TFPegasusForConditionalGeneration"),VCa.forEach(t),Amt=r(lao," (Pegasus model)"),lao.forEach(t),Lmt=i(De),B6=n(De,"LI",{});var iao=s(B6);yke=n(iao,"STRONG",{});var XCa=s(yke);ymt=r(XCa,"t5"),XCa.forEach(t),xmt=r(iao," \u2014 "),Cle=n(iao,"A",{href:!0});var zCa=s(Cle);$mt=r(zCa,"TFT5ForConditionalGeneration"),zCa.forEach(t),kmt=r(iao," (T5 model)"),iao.forEach(t),De.forEach(t),Smt=i(Ni),T(I6.$$.fragment,Ni),Ni.forEach(t),Ii.forEach(t),xdo=i(c),Gc=n(c,"H2",{class:!0});var Zco=s(Gc);N6=n(Zco,"A",{id:!0,class:!0,href:!0});var QCa=s(N6);xke=n(QCa,"SPAN",{});var WCa=s(xke);T(gB.$$.fragment,WCa),WCa.forEach(t),QCa.forEach(t),Rmt=i(Zco),$ke=n(Zco,"SPAN",{});var UCa=s($ke);Pmt=r(UCa,"TFAutoModelForSequenceClassification"),UCa.forEach(t),Zco.forEach(t),$do=i(c),Mr=n(c,"DIV",{class:!0});var qi=s(Mr);T(hB.$$.fragment,qi),Bmt=i(qi),Oc=n(qi,"P",{});var Vge=s(Oc);Imt=r(Vge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),wle=n(Vge,"A",{href:!0});var HCa=s(wle);Nmt=r(HCa,"from_pretrained()"),HCa.forEach(t),qmt=r(Vge," class method or the "),Ale=n(Vge,"A",{href:!0});var JCa=s(Ale);jmt=r(JCa,"from_config()"),JCa.forEach(t),Dmt=r(Vge,` class
method.`),Vge.forEach(t),Gmt=i(qi),uB=n(qi,"P",{});var Kco=s(uB);Omt=r(Kco,"This class cannot be instantiated directly using "),kke=n(Kco,"CODE",{});var YCa=s(kke);Vmt=r(YCa,"__init__()"),YCa.forEach(t),Xmt=r(Kco," (throws an error)."),Kco.forEach(t),zmt=i(qi),ia=n(qi,"DIV",{class:!0});var x$=s(ia);T(pB.$$.fragment,x$),Qmt=i(x$),Ske=n(x$,"P",{});var ZCa=s(Ske);Wmt=r(ZCa,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),ZCa.forEach(t),Umt=i(x$),Vc=n(x$,"P",{});var Xge=s(Vc);Hmt=r(Xge,`Note:
Loading a model from its configuration file does `),Rke=n(Xge,"STRONG",{});var KCa=s(Rke);Jmt=r(KCa,"not"),KCa.forEach(t),Ymt=r(Xge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Lle=n(Xge,"A",{href:!0});var e3a=s(Lle);Zmt=r(e3a,"from_pretrained()"),e3a.forEach(t),Kmt=r(Xge," to load the model weights."),Xge.forEach(t),ect=i(x$),T(q6.$$.fragment,x$),x$.forEach(t),oct=i(qi),Zr=n(qi,"DIV",{class:!0});var ji=s(Zr);T(_B.$$.fragment,ji),rct=i(ji),Pke=n(ji,"P",{});var o3a=s(Pke);tct=r(o3a,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),o3a.forEach(t),act=i(ji),Hn=n(ji,"P",{});var $$=s(Hn);nct=r($$,"The model class to instantiate is selected based on the "),Bke=n($$,"CODE",{});var r3a=s(Bke);sct=r(r3a,"model_type"),r3a.forEach(t),lct=r($$,` property of the config object (either
passed as an argument or loaded from `),Ike=n($$,"CODE",{});var t3a=s(Ike);ict=r(t3a,"pretrained_model_name_or_path"),t3a.forEach(t),dct=r($$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nke=n($$,"CODE",{});var a3a=s(Nke);mct=r(a3a,"pretrained_model_name_or_path"),a3a.forEach(t),cct=r($$,":"),$$.forEach(t),fct=i(ji),ae=n(ji,"UL",{});var se=s(ae);j6=n(se,"LI",{});var dao=s(j6);qke=n(dao,"STRONG",{});var n3a=s(qke);gct=r(n3a,"albert"),n3a.forEach(t),hct=r(dao," \u2014 "),yle=n(dao,"A",{href:!0});var s3a=s(yle);uct=r(s3a,"TFAlbertForSequenceClassification"),s3a.forEach(t),pct=r(dao," (ALBERT model)"),dao.forEach(t),_ct=i(se),D6=n(se,"LI",{});var mao=s(D6);jke=n(mao,"STRONG",{});var l3a=s(jke);bct=r(l3a,"bert"),l3a.forEach(t),vct=r(mao," \u2014 "),xle=n(mao,"A",{href:!0});var i3a=s(xle);Fct=r(i3a,"TFBertForSequenceClassification"),i3a.forEach(t),Tct=r(mao," (BERT model)"),mao.forEach(t),Mct=i(se),G6=n(se,"LI",{});var cao=s(G6);Dke=n(cao,"STRONG",{});var d3a=s(Dke);Ect=r(d3a,"camembert"),d3a.forEach(t),Cct=r(cao," \u2014 "),$le=n(cao,"A",{href:!0});var m3a=s($le);wct=r(m3a,"TFCamembertForSequenceClassification"),m3a.forEach(t),Act=r(cao," (CamemBERT model)"),cao.forEach(t),Lct=i(se),O6=n(se,"LI",{});var fao=s(O6);Gke=n(fao,"STRONG",{});var c3a=s(Gke);yct=r(c3a,"convbert"),c3a.forEach(t),xct=r(fao," \u2014 "),kle=n(fao,"A",{href:!0});var f3a=s(kle);$ct=r(f3a,"TFConvBertForSequenceClassification"),f3a.forEach(t),kct=r(fao," (ConvBERT model)"),fao.forEach(t),Sct=i(se),V6=n(se,"LI",{});var gao=s(V6);Oke=n(gao,"STRONG",{});var g3a=s(Oke);Rct=r(g3a,"ctrl"),g3a.forEach(t),Pct=r(gao," \u2014 "),Sle=n(gao,"A",{href:!0});var h3a=s(Sle);Bct=r(h3a,"TFCTRLForSequenceClassification"),h3a.forEach(t),Ict=r(gao," (CTRL model)"),gao.forEach(t),Nct=i(se),X6=n(se,"LI",{});var hao=s(X6);Vke=n(hao,"STRONG",{});var u3a=s(Vke);qct=r(u3a,"deberta"),u3a.forEach(t),jct=r(hao," \u2014 "),Rle=n(hao,"A",{href:!0});var p3a=s(Rle);Dct=r(p3a,"TFDebertaForSequenceClassification"),p3a.forEach(t),Gct=r(hao," (DeBERTa model)"),hao.forEach(t),Oct=i(se),z6=n(se,"LI",{});var uao=s(z6);Xke=n(uao,"STRONG",{});var _3a=s(Xke);Vct=r(_3a,"deberta-v2"),_3a.forEach(t),Xct=r(uao," \u2014 "),Ple=n(uao,"A",{href:!0});var b3a=s(Ple);zct=r(b3a,"TFDebertaV2ForSequenceClassification"),b3a.forEach(t),Qct=r(uao," (DeBERTa-v2 model)"),uao.forEach(t),Wct=i(se),Q6=n(se,"LI",{});var pao=s(Q6);zke=n(pao,"STRONG",{});var v3a=s(zke);Uct=r(v3a,"distilbert"),v3a.forEach(t),Hct=r(pao," \u2014 "),Ble=n(pao,"A",{href:!0});var F3a=s(Ble);Jct=r(F3a,"TFDistilBertForSequenceClassification"),F3a.forEach(t),Yct=r(pao," (DistilBERT model)"),pao.forEach(t),Zct=i(se),W6=n(se,"LI",{});var _ao=s(W6);Qke=n(_ao,"STRONG",{});var T3a=s(Qke);Kct=r(T3a,"electra"),T3a.forEach(t),eft=r(_ao," \u2014 "),Ile=n(_ao,"A",{href:!0});var M3a=s(Ile);oft=r(M3a,"TFElectraForSequenceClassification"),M3a.forEach(t),rft=r(_ao," (ELECTRA model)"),_ao.forEach(t),tft=i(se),U6=n(se,"LI",{});var bao=s(U6);Wke=n(bao,"STRONG",{});var E3a=s(Wke);aft=r(E3a,"esm"),E3a.forEach(t),nft=r(bao," \u2014 "),Nle=n(bao,"A",{href:!0});var C3a=s(Nle);sft=r(C3a,"TFEsmForSequenceClassification"),C3a.forEach(t),lft=r(bao," (ESM model)"),bao.forEach(t),ift=i(se),H6=n(se,"LI",{});var vao=s(H6);Uke=n(vao,"STRONG",{});var w3a=s(Uke);dft=r(w3a,"flaubert"),w3a.forEach(t),mft=r(vao," \u2014 "),qle=n(vao,"A",{href:!0});var A3a=s(qle);cft=r(A3a,"TFFlaubertForSequenceClassification"),A3a.forEach(t),fft=r(vao," (FlauBERT model)"),vao.forEach(t),gft=i(se),J6=n(se,"LI",{});var Fao=s(J6);Hke=n(Fao,"STRONG",{});var L3a=s(Hke);hft=r(L3a,"funnel"),L3a.forEach(t),uft=r(Fao," \u2014 "),jle=n(Fao,"A",{href:!0});var y3a=s(jle);pft=r(y3a,"TFFunnelForSequenceClassification"),y3a.forEach(t),_ft=r(Fao," (Funnel Transformer model)"),Fao.forEach(t),bft=i(se),Y6=n(se,"LI",{});var Tao=s(Y6);Jke=n(Tao,"STRONG",{});var x3a=s(Jke);vft=r(x3a,"gpt2"),x3a.forEach(t),Fft=r(Tao," \u2014 "),Dle=n(Tao,"A",{href:!0});var $3a=s(Dle);Tft=r($3a,"TFGPT2ForSequenceClassification"),$3a.forEach(t),Mft=r(Tao," (OpenAI GPT-2 model)"),Tao.forEach(t),Eft=i(se),Z6=n(se,"LI",{});var Mao=s(Z6);Yke=n(Mao,"STRONG",{});var k3a=s(Yke);Cft=r(k3a,"gptj"),k3a.forEach(t),wft=r(Mao," \u2014 "),Gle=n(Mao,"A",{href:!0});var S3a=s(Gle);Aft=r(S3a,"TFGPTJForSequenceClassification"),S3a.forEach(t),Lft=r(Mao," (GPT-J model)"),Mao.forEach(t),yft=i(se),K6=n(se,"LI",{});var Eao=s(K6);Zke=n(Eao,"STRONG",{});var R3a=s(Zke);xft=r(R3a,"layoutlm"),R3a.forEach(t),$ft=r(Eao," \u2014 "),Ole=n(Eao,"A",{href:!0});var P3a=s(Ole);kft=r(P3a,"TFLayoutLMForSequenceClassification"),P3a.forEach(t),Sft=r(Eao," (LayoutLM model)"),Eao.forEach(t),Rft=i(se),e7=n(se,"LI",{});var Cao=s(e7);Kke=n(Cao,"STRONG",{});var B3a=s(Kke);Pft=r(B3a,"layoutlmv3"),B3a.forEach(t),Bft=r(Cao," \u2014 "),Vle=n(Cao,"A",{href:!0});var I3a=s(Vle);Ift=r(I3a,"TFLayoutLMv3ForSequenceClassification"),I3a.forEach(t),Nft=r(Cao," (LayoutLMv3 model)"),Cao.forEach(t),qft=i(se),o7=n(se,"LI",{});var wao=s(o7);eSe=n(wao,"STRONG",{});var N3a=s(eSe);jft=r(N3a,"longformer"),N3a.forEach(t),Dft=r(wao," \u2014 "),Xle=n(wao,"A",{href:!0});var q3a=s(Xle);Gft=r(q3a,"TFLongformerForSequenceClassification"),q3a.forEach(t),Oft=r(wao," (Longformer model)"),wao.forEach(t),Vft=i(se),r7=n(se,"LI",{});var Aao=s(r7);oSe=n(Aao,"STRONG",{});var j3a=s(oSe);Xft=r(j3a,"mobilebert"),j3a.forEach(t),zft=r(Aao," \u2014 "),zle=n(Aao,"A",{href:!0});var D3a=s(zle);Qft=r(D3a,"TFMobileBertForSequenceClassification"),D3a.forEach(t),Wft=r(Aao," (MobileBERT model)"),Aao.forEach(t),Uft=i(se),t7=n(se,"LI",{});var Lao=s(t7);rSe=n(Lao,"STRONG",{});var G3a=s(rSe);Hft=r(G3a,"mpnet"),G3a.forEach(t),Jft=r(Lao," \u2014 "),Qle=n(Lao,"A",{href:!0});var O3a=s(Qle);Yft=r(O3a,"TFMPNetForSequenceClassification"),O3a.forEach(t),Zft=r(Lao," (MPNet model)"),Lao.forEach(t),Kft=i(se),a7=n(se,"LI",{});var yao=s(a7);tSe=n(yao,"STRONG",{});var V3a=s(tSe);egt=r(V3a,"openai-gpt"),V3a.forEach(t),ogt=r(yao," \u2014 "),Wle=n(yao,"A",{href:!0});var X3a=s(Wle);rgt=r(X3a,"TFOpenAIGPTForSequenceClassification"),X3a.forEach(t),tgt=r(yao," (OpenAI GPT model)"),yao.forEach(t),agt=i(se),n7=n(se,"LI",{});var xao=s(n7);aSe=n(xao,"STRONG",{});var z3a=s(aSe);ngt=r(z3a,"rembert"),z3a.forEach(t),sgt=r(xao," \u2014 "),Ule=n(xao,"A",{href:!0});var Q3a=s(Ule);lgt=r(Q3a,"TFRemBertForSequenceClassification"),Q3a.forEach(t),igt=r(xao," (RemBERT model)"),xao.forEach(t),dgt=i(se),s7=n(se,"LI",{});var $ao=s(s7);nSe=n($ao,"STRONG",{});var W3a=s(nSe);mgt=r(W3a,"roberta"),W3a.forEach(t),cgt=r($ao," \u2014 "),Hle=n($ao,"A",{href:!0});var U3a=s(Hle);fgt=r(U3a,"TFRobertaForSequenceClassification"),U3a.forEach(t),ggt=r($ao," (RoBERTa model)"),$ao.forEach(t),hgt=i(se),l7=n(se,"LI",{});var kao=s(l7);sSe=n(kao,"STRONG",{});var H3a=s(sSe);ugt=r(H3a,"roformer"),H3a.forEach(t),pgt=r(kao," \u2014 "),Jle=n(kao,"A",{href:!0});var J3a=s(Jle);_gt=r(J3a,"TFRoFormerForSequenceClassification"),J3a.forEach(t),bgt=r(kao," (RoFormer model)"),kao.forEach(t),vgt=i(se),i7=n(se,"LI",{});var Sao=s(i7);lSe=n(Sao,"STRONG",{});var Y3a=s(lSe);Fgt=r(Y3a,"tapas"),Y3a.forEach(t),Tgt=r(Sao," \u2014 "),Yle=n(Sao,"A",{href:!0});var Z3a=s(Yle);Mgt=r(Z3a,"TFTapasForSequenceClassification"),Z3a.forEach(t),Egt=r(Sao," (TAPAS model)"),Sao.forEach(t),Cgt=i(se),d7=n(se,"LI",{});var Rao=s(d7);iSe=n(Rao,"STRONG",{});var K3a=s(iSe);wgt=r(K3a,"transfo-xl"),K3a.forEach(t),Agt=r(Rao," \u2014 "),Zle=n(Rao,"A",{href:!0});var e5a=s(Zle);Lgt=r(e5a,"TFTransfoXLForSequenceClassification"),e5a.forEach(t),ygt=r(Rao," (Transformer-XL model)"),Rao.forEach(t),xgt=i(se),m7=n(se,"LI",{});var Pao=s(m7);dSe=n(Pao,"STRONG",{});var o5a=s(dSe);$gt=r(o5a,"xlm"),o5a.forEach(t),kgt=r(Pao," \u2014 "),Kle=n(Pao,"A",{href:!0});var r5a=s(Kle);Sgt=r(r5a,"TFXLMForSequenceClassification"),r5a.forEach(t),Rgt=r(Pao," (XLM model)"),Pao.forEach(t),Pgt=i(se),c7=n(se,"LI",{});var Bao=s(c7);mSe=n(Bao,"STRONG",{});var t5a=s(mSe);Bgt=r(t5a,"xlm-roberta"),t5a.forEach(t),Igt=r(Bao," \u2014 "),eie=n(Bao,"A",{href:!0});var a5a=s(eie);Ngt=r(a5a,"TFXLMRobertaForSequenceClassification"),a5a.forEach(t),qgt=r(Bao," (XLM-RoBERTa model)"),Bao.forEach(t),jgt=i(se),f7=n(se,"LI",{});var Iao=s(f7);cSe=n(Iao,"STRONG",{});var n5a=s(cSe);Dgt=r(n5a,"xlnet"),n5a.forEach(t),Ggt=r(Iao," \u2014 "),oie=n(Iao,"A",{href:!0});var s5a=s(oie);Ogt=r(s5a,"TFXLNetForSequenceClassification"),s5a.forEach(t),Vgt=r(Iao," (XLNet model)"),Iao.forEach(t),se.forEach(t),Xgt=i(ji),T(g7.$$.fragment,ji),ji.forEach(t),qi.forEach(t),kdo=i(c),Xc=n(c,"H2",{class:!0});var efo=s(Xc);h7=n(efo,"A",{id:!0,class:!0,href:!0});var l5a=s(h7);fSe=n(l5a,"SPAN",{});var i5a=s(fSe);T(bB.$$.fragment,i5a),i5a.forEach(t),l5a.forEach(t),zgt=i(efo),gSe=n(efo,"SPAN",{});var d5a=s(gSe);Qgt=r(d5a,"TFAutoModelForMultipleChoice"),d5a.forEach(t),efo.forEach(t),Sdo=i(c),Er=n(c,"DIV",{class:!0});var Di=s(Er);T(vB.$$.fragment,Di),Wgt=i(Di),zc=n(Di,"P",{});var zge=s(zc);Ugt=r(zge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),rie=n(zge,"A",{href:!0});var m5a=s(rie);Hgt=r(m5a,"from_pretrained()"),m5a.forEach(t),Jgt=r(zge," class method or the "),tie=n(zge,"A",{href:!0});var c5a=s(tie);Ygt=r(c5a,"from_config()"),c5a.forEach(t),Zgt=r(zge,` class
method.`),zge.forEach(t),Kgt=i(Di),FB=n(Di,"P",{});var ofo=s(FB);eht=r(ofo,"This class cannot be instantiated directly using "),hSe=n(ofo,"CODE",{});var f5a=s(hSe);oht=r(f5a,"__init__()"),f5a.forEach(t),rht=r(ofo," (throws an error)."),ofo.forEach(t),tht=i(Di),da=n(Di,"DIV",{class:!0});var k$=s(da);T(TB.$$.fragment,k$),aht=i(k$),uSe=n(k$,"P",{});var g5a=s(uSe);nht=r(g5a,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),g5a.forEach(t),sht=i(k$),Qc=n(k$,"P",{});var Qge=s(Qc);lht=r(Qge,`Note:
Loading a model from its configuration file does `),pSe=n(Qge,"STRONG",{});var h5a=s(pSe);iht=r(h5a,"not"),h5a.forEach(t),dht=r(Qge,` load the model weights. It only affects the
model\u2019s configuration. Use `),aie=n(Qge,"A",{href:!0});var u5a=s(aie);mht=r(u5a,"from_pretrained()"),u5a.forEach(t),cht=r(Qge," to load the model weights."),Qge.forEach(t),fht=i(k$),T(u7.$$.fragment,k$),k$.forEach(t),ght=i(Di),Kr=n(Di,"DIV",{class:!0});var Gi=s(Kr);T(MB.$$.fragment,Gi),hht=i(Gi),_Se=n(Gi,"P",{});var p5a=s(_Se);uht=r(p5a,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),p5a.forEach(t),pht=i(Gi),Jn=n(Gi,"P",{});var S$=s(Jn);_ht=r(S$,"The model class to instantiate is selected based on the "),bSe=n(S$,"CODE",{});var _5a=s(bSe);bht=r(_5a,"model_type"),_5a.forEach(t),vht=r(S$,` property of the config object (either
passed as an argument or loaded from `),vSe=n(S$,"CODE",{});var b5a=s(vSe);Fht=r(b5a,"pretrained_model_name_or_path"),b5a.forEach(t),Tht=r(S$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FSe=n(S$,"CODE",{});var v5a=s(FSe);Mht=r(v5a,"pretrained_model_name_or_path"),v5a.forEach(t),Eht=r(S$,":"),S$.forEach(t),Cht=i(Gi),Me=n(Gi,"UL",{});var Ee=s(Me);p7=n(Ee,"LI",{});var Nao=s(p7);TSe=n(Nao,"STRONG",{});var F5a=s(TSe);wht=r(F5a,"albert"),F5a.forEach(t),Aht=r(Nao," \u2014 "),nie=n(Nao,"A",{href:!0});var T5a=s(nie);Lht=r(T5a,"TFAlbertForMultipleChoice"),T5a.forEach(t),yht=r(Nao," (ALBERT model)"),Nao.forEach(t),xht=i(Ee),_7=n(Ee,"LI",{});var qao=s(_7);MSe=n(qao,"STRONG",{});var M5a=s(MSe);$ht=r(M5a,"bert"),M5a.forEach(t),kht=r(qao," \u2014 "),sie=n(qao,"A",{href:!0});var E5a=s(sie);Sht=r(E5a,"TFBertForMultipleChoice"),E5a.forEach(t),Rht=r(qao," (BERT model)"),qao.forEach(t),Pht=i(Ee),b7=n(Ee,"LI",{});var jao=s(b7);ESe=n(jao,"STRONG",{});var C5a=s(ESe);Bht=r(C5a,"camembert"),C5a.forEach(t),Iht=r(jao," \u2014 "),lie=n(jao,"A",{href:!0});var w5a=s(lie);Nht=r(w5a,"TFCamembertForMultipleChoice"),w5a.forEach(t),qht=r(jao," (CamemBERT model)"),jao.forEach(t),jht=i(Ee),v7=n(Ee,"LI",{});var Dao=s(v7);CSe=n(Dao,"STRONG",{});var A5a=s(CSe);Dht=r(A5a,"convbert"),A5a.forEach(t),Ght=r(Dao," \u2014 "),iie=n(Dao,"A",{href:!0});var L5a=s(iie);Oht=r(L5a,"TFConvBertForMultipleChoice"),L5a.forEach(t),Vht=r(Dao," (ConvBERT model)"),Dao.forEach(t),Xht=i(Ee),F7=n(Ee,"LI",{});var Gao=s(F7);wSe=n(Gao,"STRONG",{});var y5a=s(wSe);zht=r(y5a,"distilbert"),y5a.forEach(t),Qht=r(Gao," \u2014 "),die=n(Gao,"A",{href:!0});var x5a=s(die);Wht=r(x5a,"TFDistilBertForMultipleChoice"),x5a.forEach(t),Uht=r(Gao," (DistilBERT model)"),Gao.forEach(t),Hht=i(Ee),T7=n(Ee,"LI",{});var Oao=s(T7);ASe=n(Oao,"STRONG",{});var $5a=s(ASe);Jht=r($5a,"electra"),$5a.forEach(t),Yht=r(Oao," \u2014 "),mie=n(Oao,"A",{href:!0});var k5a=s(mie);Zht=r(k5a,"TFElectraForMultipleChoice"),k5a.forEach(t),Kht=r(Oao," (ELECTRA model)"),Oao.forEach(t),eut=i(Ee),M7=n(Ee,"LI",{});var Vao=s(M7);LSe=n(Vao,"STRONG",{});var S5a=s(LSe);out=r(S5a,"flaubert"),S5a.forEach(t),rut=r(Vao," \u2014 "),cie=n(Vao,"A",{href:!0});var R5a=s(cie);tut=r(R5a,"TFFlaubertForMultipleChoice"),R5a.forEach(t),aut=r(Vao," (FlauBERT model)"),Vao.forEach(t),nut=i(Ee),E7=n(Ee,"LI",{});var Xao=s(E7);ySe=n(Xao,"STRONG",{});var P5a=s(ySe);sut=r(P5a,"funnel"),P5a.forEach(t),lut=r(Xao," \u2014 "),fie=n(Xao,"A",{href:!0});var B5a=s(fie);iut=r(B5a,"TFFunnelForMultipleChoice"),B5a.forEach(t),dut=r(Xao," (Funnel Transformer model)"),Xao.forEach(t),mut=i(Ee),C7=n(Ee,"LI",{});var zao=s(C7);xSe=n(zao,"STRONG",{});var I5a=s(xSe);cut=r(I5a,"longformer"),I5a.forEach(t),fut=r(zao," \u2014 "),gie=n(zao,"A",{href:!0});var N5a=s(gie);gut=r(N5a,"TFLongformerForMultipleChoice"),N5a.forEach(t),hut=r(zao," (Longformer model)"),zao.forEach(t),uut=i(Ee),w7=n(Ee,"LI",{});var Qao=s(w7);$Se=n(Qao,"STRONG",{});var q5a=s($Se);put=r(q5a,"mobilebert"),q5a.forEach(t),_ut=r(Qao," \u2014 "),hie=n(Qao,"A",{href:!0});var j5a=s(hie);but=r(j5a,"TFMobileBertForMultipleChoice"),j5a.forEach(t),vut=r(Qao," (MobileBERT model)"),Qao.forEach(t),Fut=i(Ee),A7=n(Ee,"LI",{});var Wao=s(A7);kSe=n(Wao,"STRONG",{});var D5a=s(kSe);Tut=r(D5a,"mpnet"),D5a.forEach(t),Mut=r(Wao," \u2014 "),uie=n(Wao,"A",{href:!0});var G5a=s(uie);Eut=r(G5a,"TFMPNetForMultipleChoice"),G5a.forEach(t),Cut=r(Wao," (MPNet model)"),Wao.forEach(t),wut=i(Ee),L7=n(Ee,"LI",{});var Uao=s(L7);SSe=n(Uao,"STRONG",{});var O5a=s(SSe);Aut=r(O5a,"rembert"),O5a.forEach(t),Lut=r(Uao," \u2014 "),pie=n(Uao,"A",{href:!0});var V5a=s(pie);yut=r(V5a,"TFRemBertForMultipleChoice"),V5a.forEach(t),xut=r(Uao," (RemBERT model)"),Uao.forEach(t),$ut=i(Ee),y7=n(Ee,"LI",{});var Hao=s(y7);RSe=n(Hao,"STRONG",{});var X5a=s(RSe);kut=r(X5a,"roberta"),X5a.forEach(t),Sut=r(Hao," \u2014 "),_ie=n(Hao,"A",{href:!0});var z5a=s(_ie);Rut=r(z5a,"TFRobertaForMultipleChoice"),z5a.forEach(t),Put=r(Hao," (RoBERTa model)"),Hao.forEach(t),But=i(Ee),x7=n(Ee,"LI",{});var Jao=s(x7);PSe=n(Jao,"STRONG",{});var Q5a=s(PSe);Iut=r(Q5a,"roformer"),Q5a.forEach(t),Nut=r(Jao," \u2014 "),bie=n(Jao,"A",{href:!0});var W5a=s(bie);qut=r(W5a,"TFRoFormerForMultipleChoice"),W5a.forEach(t),jut=r(Jao," (RoFormer model)"),Jao.forEach(t),Dut=i(Ee),$7=n(Ee,"LI",{});var Yao=s($7);BSe=n(Yao,"STRONG",{});var U5a=s(BSe);Gut=r(U5a,"xlm"),U5a.forEach(t),Out=r(Yao," \u2014 "),vie=n(Yao,"A",{href:!0});var H5a=s(vie);Vut=r(H5a,"TFXLMForMultipleChoice"),H5a.forEach(t),Xut=r(Yao," (XLM model)"),Yao.forEach(t),zut=i(Ee),k7=n(Ee,"LI",{});var Zao=s(k7);ISe=n(Zao,"STRONG",{});var J5a=s(ISe);Qut=r(J5a,"xlm-roberta"),J5a.forEach(t),Wut=r(Zao," \u2014 "),Fie=n(Zao,"A",{href:!0});var Y5a=s(Fie);Uut=r(Y5a,"TFXLMRobertaForMultipleChoice"),Y5a.forEach(t),Hut=r(Zao," (XLM-RoBERTa model)"),Zao.forEach(t),Jut=i(Ee),S7=n(Ee,"LI",{});var Kao=s(S7);NSe=n(Kao,"STRONG",{});var Z5a=s(NSe);Yut=r(Z5a,"xlnet"),Z5a.forEach(t),Zut=r(Kao," \u2014 "),Tie=n(Kao,"A",{href:!0});var K5a=s(Tie);Kut=r(K5a,"TFXLNetForMultipleChoice"),K5a.forEach(t),ept=r(Kao," (XLNet model)"),Kao.forEach(t),Ee.forEach(t),opt=i(Gi),T(R7.$$.fragment,Gi),Gi.forEach(t),Di.forEach(t),Rdo=i(c),Wc=n(c,"H2",{class:!0});var rfo=s(Wc);P7=n(rfo,"A",{id:!0,class:!0,href:!0});var e0a=s(P7);qSe=n(e0a,"SPAN",{});var o0a=s(qSe);T(EB.$$.fragment,o0a),o0a.forEach(t),e0a.forEach(t),rpt=i(rfo),jSe=n(rfo,"SPAN",{});var r0a=s(jSe);tpt=r(r0a,"TFAutoModelForNextSentencePrediction"),r0a.forEach(t),rfo.forEach(t),Pdo=i(c),Cr=n(c,"DIV",{class:!0});var Oi=s(Cr);T(CB.$$.fragment,Oi),apt=i(Oi),Uc=n(Oi,"P",{});var Wge=s(Uc);npt=r(Wge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Mie=n(Wge,"A",{href:!0});var t0a=s(Mie);spt=r(t0a,"from_pretrained()"),t0a.forEach(t),lpt=r(Wge," class method or the "),Eie=n(Wge,"A",{href:!0});var a0a=s(Eie);ipt=r(a0a,"from_config()"),a0a.forEach(t),dpt=r(Wge,` class
method.`),Wge.forEach(t),mpt=i(Oi),wB=n(Oi,"P",{});var tfo=s(wB);cpt=r(tfo,"This class cannot be instantiated directly using "),DSe=n(tfo,"CODE",{});var n0a=s(DSe);fpt=r(n0a,"__init__()"),n0a.forEach(t),gpt=r(tfo," (throws an error)."),tfo.forEach(t),hpt=i(Oi),ma=n(Oi,"DIV",{class:!0});var R$=s(ma);T(AB.$$.fragment,R$),upt=i(R$),GSe=n(R$,"P",{});var s0a=s(GSe);ppt=r(s0a,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),s0a.forEach(t),_pt=i(R$),Hc=n(R$,"P",{});var Uge=s(Hc);bpt=r(Uge,`Note:
Loading a model from its configuration file does `),OSe=n(Uge,"STRONG",{});var l0a=s(OSe);vpt=r(l0a,"not"),l0a.forEach(t),Fpt=r(Uge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Cie=n(Uge,"A",{href:!0});var i0a=s(Cie);Tpt=r(i0a,"from_pretrained()"),i0a.forEach(t),Mpt=r(Uge," to load the model weights."),Uge.forEach(t),Ept=i(R$),T(B7.$$.fragment,R$),R$.forEach(t),Cpt=i(Oi),et=n(Oi,"DIV",{class:!0});var Vi=s(et);T(LB.$$.fragment,Vi),wpt=i(Vi),VSe=n(Vi,"P",{});var d0a=s(VSe);Apt=r(d0a,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),d0a.forEach(t),Lpt=i(Vi),Yn=n(Vi,"P",{});var P$=s(Yn);ypt=r(P$,"The model class to instantiate is selected based on the "),XSe=n(P$,"CODE",{});var m0a=s(XSe);xpt=r(m0a,"model_type"),m0a.forEach(t),$pt=r(P$,` property of the config object (either
passed as an argument or loaded from `),zSe=n(P$,"CODE",{});var c0a=s(zSe);kpt=r(c0a,"pretrained_model_name_or_path"),c0a.forEach(t),Spt=r(P$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),QSe=n(P$,"CODE",{});var f0a=s(QSe);Rpt=r(f0a,"pretrained_model_name_or_path"),f0a.forEach(t),Ppt=r(P$,":"),P$.forEach(t),Bpt=i(Vi),yB=n(Vi,"UL",{});var afo=s(yB);I7=n(afo,"LI",{});var eno=s(I7);WSe=n(eno,"STRONG",{});var g0a=s(WSe);Ipt=r(g0a,"bert"),g0a.forEach(t),Npt=r(eno," \u2014 "),wie=n(eno,"A",{href:!0});var h0a=s(wie);qpt=r(h0a,"TFBertForNextSentencePrediction"),h0a.forEach(t),jpt=r(eno," (BERT model)"),eno.forEach(t),Dpt=i(afo),N7=n(afo,"LI",{});var ono=s(N7);USe=n(ono,"STRONG",{});var u0a=s(USe);Gpt=r(u0a,"mobilebert"),u0a.forEach(t),Opt=r(ono," \u2014 "),Aie=n(ono,"A",{href:!0});var p0a=s(Aie);Vpt=r(p0a,"TFMobileBertForNextSentencePrediction"),p0a.forEach(t),Xpt=r(ono," (MobileBERT model)"),ono.forEach(t),afo.forEach(t),zpt=i(Vi),T(q7.$$.fragment,Vi),Vi.forEach(t),Oi.forEach(t),Bdo=i(c),Jc=n(c,"H2",{class:!0});var nfo=s(Jc);j7=n(nfo,"A",{id:!0,class:!0,href:!0});var _0a=s(j7);HSe=n(_0a,"SPAN",{});var b0a=s(HSe);T(xB.$$.fragment,b0a),b0a.forEach(t),_0a.forEach(t),Qpt=i(nfo),JSe=n(nfo,"SPAN",{});var v0a=s(JSe);Wpt=r(v0a,"TFAutoModelForTableQuestionAnswering"),v0a.forEach(t),nfo.forEach(t),Ido=i(c),wr=n(c,"DIV",{class:!0});var Xi=s(wr);T($B.$$.fragment,Xi),Upt=i(Xi),Yc=n(Xi,"P",{});var Hge=s(Yc);Hpt=r(Hge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),Lie=n(Hge,"A",{href:!0});var F0a=s(Lie);Jpt=r(F0a,"from_pretrained()"),F0a.forEach(t),Ypt=r(Hge," class method or the "),yie=n(Hge,"A",{href:!0});var T0a=s(yie);Zpt=r(T0a,"from_config()"),T0a.forEach(t),Kpt=r(Hge,` class
method.`),Hge.forEach(t),e_t=i(Xi),kB=n(Xi,"P",{});var sfo=s(kB);o_t=r(sfo,"This class cannot be instantiated directly using "),YSe=n(sfo,"CODE",{});var M0a=s(YSe);r_t=r(M0a,"__init__()"),M0a.forEach(t),t_t=r(sfo," (throws an error)."),sfo.forEach(t),a_t=i(Xi),ca=n(Xi,"DIV",{class:!0});var B$=s(ca);T(SB.$$.fragment,B$),n_t=i(B$),ZSe=n(B$,"P",{});var E0a=s(ZSe);s_t=r(E0a,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),E0a.forEach(t),l_t=i(B$),Zc=n(B$,"P",{});var Jge=s(Zc);i_t=r(Jge,`Note:
Loading a model from its configuration file does `),KSe=n(Jge,"STRONG",{});var C0a=s(KSe);d_t=r(C0a,"not"),C0a.forEach(t),m_t=r(Jge,` load the model weights. It only affects the
model\u2019s configuration. Use `),xie=n(Jge,"A",{href:!0});var w0a=s(xie);c_t=r(w0a,"from_pretrained()"),w0a.forEach(t),f_t=r(Jge," to load the model weights."),Jge.forEach(t),g_t=i(B$),T(D7.$$.fragment,B$),B$.forEach(t),h_t=i(Xi),ot=n(Xi,"DIV",{class:!0});var zi=s(ot);T(RB.$$.fragment,zi),u_t=i(zi),eRe=n(zi,"P",{});var A0a=s(eRe);p_t=r(A0a,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),A0a.forEach(t),__t=i(zi),Zn=n(zi,"P",{});var I$=s(Zn);b_t=r(I$,"The model class to instantiate is selected based on the "),oRe=n(I$,"CODE",{});var L0a=s(oRe);v_t=r(L0a,"model_type"),L0a.forEach(t),F_t=r(I$,` property of the config object (either
passed as an argument or loaded from `),rRe=n(I$,"CODE",{});var y0a=s(rRe);T_t=r(y0a,"pretrained_model_name_or_path"),y0a.forEach(t),M_t=r(I$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),tRe=n(I$,"CODE",{});var x0a=s(tRe);E_t=r(x0a,"pretrained_model_name_or_path"),x0a.forEach(t),C_t=r(I$,":"),I$.forEach(t),w_t=i(zi),aRe=n(zi,"UL",{});var $0a=s(aRe);G7=n($0a,"LI",{});var rno=s(G7);nRe=n(rno,"STRONG",{});var k0a=s(nRe);A_t=r(k0a,"tapas"),k0a.forEach(t),L_t=r(rno," \u2014 "),$ie=n(rno,"A",{href:!0});var S0a=s($ie);y_t=r(S0a,"TFTapasForQuestionAnswering"),S0a.forEach(t),x_t=r(rno," (TAPAS model)"),rno.forEach(t),$0a.forEach(t),$_t=i(zi),T(O7.$$.fragment,zi),zi.forEach(t),Xi.forEach(t),Ndo=i(c),Kc=n(c,"H2",{class:!0});var lfo=s(Kc);V7=n(lfo,"A",{id:!0,class:!0,href:!0});var R0a=s(V7);sRe=n(R0a,"SPAN",{});var P0a=s(sRe);T(PB.$$.fragment,P0a),P0a.forEach(t),R0a.forEach(t),k_t=i(lfo),lRe=n(lfo,"SPAN",{});var B0a=s(lRe);S_t=r(B0a,"TFAutoModelForDocumentQuestionAnswering"),B0a.forEach(t),lfo.forEach(t),qdo=i(c),Ar=n(c,"DIV",{class:!0});var Qi=s(Ar);T(BB.$$.fragment,Qi),R_t=i(Qi),ef=n(Qi,"P",{});var Yge=s(ef);P_t=r(Yge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a document question answering head) when created
with the `),kie=n(Yge,"A",{href:!0});var I0a=s(kie);B_t=r(I0a,"from_pretrained()"),I0a.forEach(t),I_t=r(Yge," class method or the "),Sie=n(Yge,"A",{href:!0});var N0a=s(Sie);N_t=r(N0a,"from_config()"),N0a.forEach(t),q_t=r(Yge,` class
method.`),Yge.forEach(t),j_t=i(Qi),IB=n(Qi,"P",{});var ifo=s(IB);D_t=r(ifo,"This class cannot be instantiated directly using "),iRe=n(ifo,"CODE",{});var q0a=s(iRe);G_t=r(q0a,"__init__()"),q0a.forEach(t),O_t=r(ifo," (throws an error)."),ifo.forEach(t),V_t=i(Qi),fa=n(Qi,"DIV",{class:!0});var N$=s(fa);T(NB.$$.fragment,N$),X_t=i(N$),dRe=n(N$,"P",{});var j0a=s(dRe);z_t=r(j0a,"Instantiates one of the model classes of the library (with a document question answering head) from a configuration."),j0a.forEach(t),Q_t=i(N$),of=n(N$,"P",{});var Zge=s(of);W_t=r(Zge,`Note:
Loading a model from its configuration file does `),mRe=n(Zge,"STRONG",{});var D0a=s(mRe);U_t=r(D0a,"not"),D0a.forEach(t),H_t=r(Zge,` load the model weights. It only affects the
model\u2019s configuration. Use `),Rie=n(Zge,"A",{href:!0});var G0a=s(Rie);J_t=r(G0a,"from_pretrained()"),G0a.forEach(t),Y_t=r(Zge," to load the model weights."),Zge.forEach(t),Z_t=i(N$),T(X7.$$.fragment,N$),N$.forEach(t),K_t=i(Qi),rt=n(Qi,"DIV",{class:!0});var Wi=s(rt);T(qB.$$.fragment,Wi),e1t=i(Wi),cRe=n(Wi,"P",{});var O0a=s(cRe);o1t=r(O0a,"Instantiate one of the model classes of the library (with a document question answering head) from a pretrained model."),O0a.forEach(t),r1t=i(Wi),Kn=n(Wi,"P",{});var q$=s(Kn);t1t=r(q$,"The model class to instantiate is selected based on the "),fRe=n(q$,"CODE",{});var V0a=s(fRe);a1t=r(V0a,"model_type"),V0a.forEach(t),n1t=r(q$,` property of the config object (either
passed as an argument or loaded from `),gRe=n(q$,"CODE",{});var X0a=s(gRe);s1t=r(X0a,"pretrained_model_name_or_path"),X0a.forEach(t),l1t=r(q$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hRe=n(q$,"CODE",{});var z0a=s(hRe);i1t=r(z0a,"pretrained_model_name_or_path"),z0a.forEach(t),d1t=r(q$,":"),q$.forEach(t),m1t=i(Wi),uRe=n(Wi,"UL",{});var Q0a=s(uRe);z7=n(Q0a,"LI",{});var tno=s(z7);pRe=n(tno,"STRONG",{});var W0a=s(pRe);c1t=r(W0a,"layoutlm"),W0a.forEach(t),f1t=r(tno," \u2014 "),Pie=n(tno,"A",{href:!0});var U0a=s(Pie);g1t=r(U0a,"TFLayoutLMForQuestionAnswering"),U0a.forEach(t),h1t=r(tno," (LayoutLM model)"),tno.forEach(t),Q0a.forEach(t),u1t=i(Wi),T(Q7.$$.fragment,Wi),Wi.forEach(t),Qi.forEach(t),jdo=i(c),rf=n(c,"H2",{class:!0});var dfo=s(rf);W7=n(dfo,"A",{id:!0,class:!0,href:!0});var H0a=s(W7);_Re=n(H0a,"SPAN",{});var J0a=s(_Re);T(jB.$$.fragment,J0a),J0a.forEach(t),H0a.forEach(t),p1t=i(dfo),bRe=n(dfo,"SPAN",{});var Y0a=s(bRe);_1t=r(Y0a,"TFAutoModelForTokenClassification"),Y0a.forEach(t),dfo.forEach(t),Ddo=i(c),Lr=n(c,"DIV",{class:!0});var Ui=s(Lr);T(DB.$$.fragment,Ui),b1t=i(Ui),tf=n(Ui,"P",{});var Kge=s(tf);v1t=r(Kge,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Bie=n(Kge,"A",{href:!0});var Z0a=s(Bie);F1t=r(Z0a,"from_pretrained()"),Z0a.forEach(t),T1t=r(Kge," class method or the "),Iie=n(Kge,"A",{href:!0});var K0a=s(Iie);M1t=r(K0a,"from_config()"),K0a.forEach(t),E1t=r(Kge,` class
method.`),Kge.forEach(t),C1t=i(Ui),GB=n(Ui,"P",{});var mfo=s(GB);w1t=r(mfo,"This class cannot be instantiated directly using "),vRe=n(mfo,"CODE",{});var ewa=s(vRe);A1t=r(ewa,"__init__()"),ewa.forEach(t),L1t=r(mfo," (throws an error)."),mfo.forEach(t),y1t=i(Ui),ga=n(Ui,"DIV",{class:!0});var j$=s(ga);T(OB.$$.fragment,j$),x1t=i(j$),FRe=n(j$,"P",{});var owa=s(FRe);$1t=r(owa,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),owa.forEach(t),k1t=i(j$),af=n(j$,"P",{});var ehe=s(af);S1t=r(ehe,`Note:
Loading a model from its configuration file does `),TRe=n(ehe,"STRONG",{});var rwa=s(TRe);R1t=r(rwa,"not"),rwa.forEach(t),P1t=r(ehe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Nie=n(ehe,"A",{href:!0});var twa=s(Nie);B1t=r(twa,"from_pretrained()"),twa.forEach(t),I1t=r(ehe," to load the model weights."),ehe.forEach(t),N1t=i(j$),T(U7.$$.fragment,j$),j$.forEach(t),q1t=i(Ui),tt=n(Ui,"DIV",{class:!0});var Hi=s(tt);T(VB.$$.fragment,Hi),j1t=i(Hi),MRe=n(Hi,"P",{});var awa=s(MRe);D1t=r(awa,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),awa.forEach(t),G1t=i(Hi),es=n(Hi,"P",{});var D$=s(es);O1t=r(D$,"The model class to instantiate is selected based on the "),ERe=n(D$,"CODE",{});var nwa=s(ERe);V1t=r(nwa,"model_type"),nwa.forEach(t),X1t=r(D$,` property of the config object (either
passed as an argument or loaded from `),CRe=n(D$,"CODE",{});var swa=s(CRe);z1t=r(swa,"pretrained_model_name_or_path"),swa.forEach(t),Q1t=r(D$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wRe=n(D$,"CODE",{});var lwa=s(wRe);W1t=r(lwa,"pretrained_model_name_or_path"),lwa.forEach(t),U1t=r(D$,":"),D$.forEach(t),H1t=i(Hi),me=n(Hi,"UL",{});var ue=s(me);H7=n(ue,"LI",{});var ano=s(H7);ARe=n(ano,"STRONG",{});var iwa=s(ARe);J1t=r(iwa,"albert"),iwa.forEach(t),Y1t=r(ano," \u2014 "),qie=n(ano,"A",{href:!0});var dwa=s(qie);Z1t=r(dwa,"TFAlbertForTokenClassification"),dwa.forEach(t),K1t=r(ano," (ALBERT model)"),ano.forEach(t),e2t=i(ue),J7=n(ue,"LI",{});var nno=s(J7);LRe=n(nno,"STRONG",{});var mwa=s(LRe);o2t=r(mwa,"bert"),mwa.forEach(t),r2t=r(nno," \u2014 "),jie=n(nno,"A",{href:!0});var cwa=s(jie);t2t=r(cwa,"TFBertForTokenClassification"),cwa.forEach(t),a2t=r(nno," (BERT model)"),nno.forEach(t),n2t=i(ue),Y7=n(ue,"LI",{});var sno=s(Y7);yRe=n(sno,"STRONG",{});var fwa=s(yRe);s2t=r(fwa,"camembert"),fwa.forEach(t),l2t=r(sno," \u2014 "),Die=n(sno,"A",{href:!0});var gwa=s(Die);i2t=r(gwa,"TFCamembertForTokenClassification"),gwa.forEach(t),d2t=r(sno," (CamemBERT model)"),sno.forEach(t),m2t=i(ue),Z7=n(ue,"LI",{});var lno=s(Z7);xRe=n(lno,"STRONG",{});var hwa=s(xRe);c2t=r(hwa,"convbert"),hwa.forEach(t),f2t=r(lno," \u2014 "),Gie=n(lno,"A",{href:!0});var uwa=s(Gie);g2t=r(uwa,"TFConvBertForTokenClassification"),uwa.forEach(t),h2t=r(lno," (ConvBERT model)"),lno.forEach(t),u2t=i(ue),K7=n(ue,"LI",{});var ino=s(K7);$Re=n(ino,"STRONG",{});var pwa=s($Re);p2t=r(pwa,"deberta"),pwa.forEach(t),_2t=r(ino," \u2014 "),Oie=n(ino,"A",{href:!0});var _wa=s(Oie);b2t=r(_wa,"TFDebertaForTokenClassification"),_wa.forEach(t),v2t=r(ino," (DeBERTa model)"),ino.forEach(t),F2t=i(ue),e8=n(ue,"LI",{});var dno=s(e8);kRe=n(dno,"STRONG",{});var bwa=s(kRe);T2t=r(bwa,"deberta-v2"),bwa.forEach(t),M2t=r(dno," \u2014 "),Vie=n(dno,"A",{href:!0});var vwa=s(Vie);E2t=r(vwa,"TFDebertaV2ForTokenClassification"),vwa.forEach(t),C2t=r(dno," (DeBERTa-v2 model)"),dno.forEach(t),w2t=i(ue),o8=n(ue,"LI",{});var mno=s(o8);SRe=n(mno,"STRONG",{});var Fwa=s(SRe);A2t=r(Fwa,"distilbert"),Fwa.forEach(t),L2t=r(mno," \u2014 "),Xie=n(mno,"A",{href:!0});var Twa=s(Xie);y2t=r(Twa,"TFDistilBertForTokenClassification"),Twa.forEach(t),x2t=r(mno," (DistilBERT model)"),mno.forEach(t),$2t=i(ue),r8=n(ue,"LI",{});var cno=s(r8);RRe=n(cno,"STRONG",{});var Mwa=s(RRe);k2t=r(Mwa,"electra"),Mwa.forEach(t),S2t=r(cno," \u2014 "),zie=n(cno,"A",{href:!0});var Ewa=s(zie);R2t=r(Ewa,"TFElectraForTokenClassification"),Ewa.forEach(t),P2t=r(cno," (ELECTRA model)"),cno.forEach(t),B2t=i(ue),t8=n(ue,"LI",{});var fno=s(t8);PRe=n(fno,"STRONG",{});var Cwa=s(PRe);I2t=r(Cwa,"esm"),Cwa.forEach(t),N2t=r(fno," \u2014 "),Qie=n(fno,"A",{href:!0});var wwa=s(Qie);q2t=r(wwa,"TFEsmForTokenClassification"),wwa.forEach(t),j2t=r(fno," (ESM model)"),fno.forEach(t),D2t=i(ue),a8=n(ue,"LI",{});var gno=s(a8);BRe=n(gno,"STRONG",{});var Awa=s(BRe);G2t=r(Awa,"flaubert"),Awa.forEach(t),O2t=r(gno," \u2014 "),Wie=n(gno,"A",{href:!0});var Lwa=s(Wie);V2t=r(Lwa,"TFFlaubertForTokenClassification"),Lwa.forEach(t),X2t=r(gno," (FlauBERT model)"),gno.forEach(t),z2t=i(ue),n8=n(ue,"LI",{});var hno=s(n8);IRe=n(hno,"STRONG",{});var ywa=s(IRe);Q2t=r(ywa,"funnel"),ywa.forEach(t),W2t=r(hno," \u2014 "),Uie=n(hno,"A",{href:!0});var xwa=s(Uie);U2t=r(xwa,"TFFunnelForTokenClassification"),xwa.forEach(t),H2t=r(hno," (Funnel Transformer model)"),hno.forEach(t),J2t=i(ue),s8=n(ue,"LI",{});var uno=s(s8);NRe=n(uno,"STRONG",{});var $wa=s(NRe);Y2t=r($wa,"layoutlm"),$wa.forEach(t),Z2t=r(uno," \u2014 "),Hie=n(uno,"A",{href:!0});var kwa=s(Hie);K2t=r(kwa,"TFLayoutLMForTokenClassification"),kwa.forEach(t),ebt=r(uno," (LayoutLM model)"),uno.forEach(t),obt=i(ue),l8=n(ue,"LI",{});var pno=s(l8);qRe=n(pno,"STRONG",{});var Swa=s(qRe);rbt=r(Swa,"layoutlmv3"),Swa.forEach(t),tbt=r(pno," \u2014 "),Jie=n(pno,"A",{href:!0});var Rwa=s(Jie);abt=r(Rwa,"TFLayoutLMv3ForTokenClassification"),Rwa.forEach(t),nbt=r(pno," (LayoutLMv3 model)"),pno.forEach(t),sbt=i(ue),i8=n(ue,"LI",{});var _no=s(i8);jRe=n(_no,"STRONG",{});var Pwa=s(jRe);lbt=r(Pwa,"longformer"),Pwa.forEach(t),ibt=r(_no," \u2014 "),Yie=n(_no,"A",{href:!0});var Bwa=s(Yie);dbt=r(Bwa,"TFLongformerForTokenClassification"),Bwa.forEach(t),mbt=r(_no," (Longformer model)"),_no.forEach(t),cbt=i(ue),d8=n(ue,"LI",{});var bno=s(d8);DRe=n(bno,"STRONG",{});var Iwa=s(DRe);fbt=r(Iwa,"mobilebert"),Iwa.forEach(t),gbt=r(bno," \u2014 "),Zie=n(bno,"A",{href:!0});var Nwa=s(Zie);hbt=r(Nwa,"TFMobileBertForTokenClassification"),Nwa.forEach(t),ubt=r(bno," (MobileBERT model)"),bno.forEach(t),pbt=i(ue),m8=n(ue,"LI",{});var vno=s(m8);GRe=n(vno,"STRONG",{});var qwa=s(GRe);_bt=r(qwa,"mpnet"),qwa.forEach(t),bbt=r(vno," \u2014 "),Kie=n(vno,"A",{href:!0});var jwa=s(Kie);vbt=r(jwa,"TFMPNetForTokenClassification"),jwa.forEach(t),Fbt=r(vno," (MPNet model)"),vno.forEach(t),Tbt=i(ue),c8=n(ue,"LI",{});var Fno=s(c8);ORe=n(Fno,"STRONG",{});var Dwa=s(ORe);Mbt=r(Dwa,"rembert"),Dwa.forEach(t),Ebt=r(Fno," \u2014 "),ede=n(Fno,"A",{href:!0});var Gwa=s(ede);Cbt=r(Gwa,"TFRemBertForTokenClassification"),Gwa.forEach(t),wbt=r(Fno," (RemBERT model)"),Fno.forEach(t),Abt=i(ue),f8=n(ue,"LI",{});var Tno=s(f8);VRe=n(Tno,"STRONG",{});var Owa=s(VRe);Lbt=r(Owa,"roberta"),Owa.forEach(t),ybt=r(Tno," \u2014 "),ode=n(Tno,"A",{href:!0});var Vwa=s(ode);xbt=r(Vwa,"TFRobertaForTokenClassification"),Vwa.forEach(t),$bt=r(Tno," (RoBERTa model)"),Tno.forEach(t),kbt=i(ue),g8=n(ue,"LI",{});var Mno=s(g8);XRe=n(Mno,"STRONG",{});var Xwa=s(XRe);Sbt=r(Xwa,"roformer"),Xwa.forEach(t),Rbt=r(Mno," \u2014 "),rde=n(Mno,"A",{href:!0});var zwa=s(rde);Pbt=r(zwa,"TFRoFormerForTokenClassification"),zwa.forEach(t),Bbt=r(Mno," (RoFormer model)"),Mno.forEach(t),Ibt=i(ue),h8=n(ue,"LI",{});var Eno=s(h8);zRe=n(Eno,"STRONG",{});var Qwa=s(zRe);Nbt=r(Qwa,"xlm"),Qwa.forEach(t),qbt=r(Eno," \u2014 "),tde=n(Eno,"A",{href:!0});var Wwa=s(tde);jbt=r(Wwa,"TFXLMForTokenClassification"),Wwa.forEach(t),Dbt=r(Eno," (XLM model)"),Eno.forEach(t),Gbt=i(ue),u8=n(ue,"LI",{});var Cno=s(u8);QRe=n(Cno,"STRONG",{});var Uwa=s(QRe);Obt=r(Uwa,"xlm-roberta"),Uwa.forEach(t),Vbt=r(Cno," \u2014 "),ade=n(Cno,"A",{href:!0});var Hwa=s(ade);Xbt=r(Hwa,"TFXLMRobertaForTokenClassification"),Hwa.forEach(t),zbt=r(Cno," (XLM-RoBERTa model)"),Cno.forEach(t),Qbt=i(ue),p8=n(ue,"LI",{});var wno=s(p8);WRe=n(wno,"STRONG",{});var Jwa=s(WRe);Wbt=r(Jwa,"xlnet"),Jwa.forEach(t),Ubt=r(wno," \u2014 "),nde=n(wno,"A",{href:!0});var Ywa=s(nde);Hbt=r(Ywa,"TFXLNetForTokenClassification"),Ywa.forEach(t),Jbt=r(wno," (XLNet model)"),wno.forEach(t),ue.forEach(t),Ybt=i(Hi),T(_8.$$.fragment,Hi),Hi.forEach(t),Ui.forEach(t),Gdo=i(c),nf=n(c,"H2",{class:!0});var cfo=s(nf);b8=n(cfo,"A",{id:!0,class:!0,href:!0});var Zwa=s(b8);URe=n(Zwa,"SPAN",{});var Kwa=s(URe);T(XB.$$.fragment,Kwa),Kwa.forEach(t),Zwa.forEach(t),Zbt=i(cfo),HRe=n(cfo,"SPAN",{});var eAa=s(HRe);Kbt=r(eAa,"TFAutoModelForQuestionAnswering"),eAa.forEach(t),cfo.forEach(t),Odo=i(c),yr=n(c,"DIV",{class:!0});var Ji=s(yr);T(zB.$$.fragment,Ji),evt=i(Ji),sf=n(Ji,"P",{});var ohe=s(sf);ovt=r(ohe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),sde=n(ohe,"A",{href:!0});var oAa=s(sde);rvt=r(oAa,"from_pretrained()"),oAa.forEach(t),tvt=r(ohe," class method or the "),lde=n(ohe,"A",{href:!0});var rAa=s(lde);avt=r(rAa,"from_config()"),rAa.forEach(t),nvt=r(ohe,` class
method.`),ohe.forEach(t),svt=i(Ji),QB=n(Ji,"P",{});var ffo=s(QB);lvt=r(ffo,"This class cannot be instantiated directly using "),JRe=n(ffo,"CODE",{});var tAa=s(JRe);ivt=r(tAa,"__init__()"),tAa.forEach(t),dvt=r(ffo," (throws an error)."),ffo.forEach(t),mvt=i(Ji),ha=n(Ji,"DIV",{class:!0});var G$=s(ha);T(WB.$$.fragment,G$),cvt=i(G$),YRe=n(G$,"P",{});var aAa=s(YRe);fvt=r(aAa,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),aAa.forEach(t),gvt=i(G$),lf=n(G$,"P",{});var rhe=s(lf);hvt=r(rhe,`Note:
Loading a model from its configuration file does `),ZRe=n(rhe,"STRONG",{});var nAa=s(ZRe);uvt=r(nAa,"not"),nAa.forEach(t),pvt=r(rhe,` load the model weights. It only affects the
model\u2019s configuration. Use `),ide=n(rhe,"A",{href:!0});var sAa=s(ide);_vt=r(sAa,"from_pretrained()"),sAa.forEach(t),bvt=r(rhe," to load the model weights."),rhe.forEach(t),vvt=i(G$),T(v8.$$.fragment,G$),G$.forEach(t),Fvt=i(Ji),at=n(Ji,"DIV",{class:!0});var Yi=s(at);T(UB.$$.fragment,Yi),Tvt=i(Yi),KRe=n(Yi,"P",{});var lAa=s(KRe);Mvt=r(lAa,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),lAa.forEach(t),Evt=i(Yi),os=n(Yi,"P",{});var O$=s(os);Cvt=r(O$,"The model class to instantiate is selected based on the "),ePe=n(O$,"CODE",{});var iAa=s(ePe);wvt=r(iAa,"model_type"),iAa.forEach(t),Avt=r(O$,` property of the config object (either
passed as an argument or loaded from `),oPe=n(O$,"CODE",{});var dAa=s(oPe);Lvt=r(dAa,"pretrained_model_name_or_path"),dAa.forEach(t),yvt=r(O$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rPe=n(O$,"CODE",{});var mAa=s(rPe);xvt=r(mAa,"pretrained_model_name_or_path"),mAa.forEach(t),$vt=r(O$,":"),O$.forEach(t),kvt=i(Yi),he=n(Yi,"UL",{});var be=s(he);F8=n(be,"LI",{});var Ano=s(F8);tPe=n(Ano,"STRONG",{});var cAa=s(tPe);Svt=r(cAa,"albert"),cAa.forEach(t),Rvt=r(Ano," \u2014 "),dde=n(Ano,"A",{href:!0});var fAa=s(dde);Pvt=r(fAa,"TFAlbertForQuestionAnswering"),fAa.forEach(t),Bvt=r(Ano," (ALBERT model)"),Ano.forEach(t),Ivt=i(be),T8=n(be,"LI",{});var Lno=s(T8);aPe=n(Lno,"STRONG",{});var gAa=s(aPe);Nvt=r(gAa,"bert"),gAa.forEach(t),qvt=r(Lno," \u2014 "),mde=n(Lno,"A",{href:!0});var hAa=s(mde);jvt=r(hAa,"TFBertForQuestionAnswering"),hAa.forEach(t),Dvt=r(Lno," (BERT model)"),Lno.forEach(t),Gvt=i(be),M8=n(be,"LI",{});var yno=s(M8);nPe=n(yno,"STRONG",{});var uAa=s(nPe);Ovt=r(uAa,"camembert"),uAa.forEach(t),Vvt=r(yno," \u2014 "),cde=n(yno,"A",{href:!0});var pAa=s(cde);Xvt=r(pAa,"TFCamembertForQuestionAnswering"),pAa.forEach(t),zvt=r(yno," (CamemBERT model)"),yno.forEach(t),Qvt=i(be),E8=n(be,"LI",{});var xno=s(E8);sPe=n(xno,"STRONG",{});var _Aa=s(sPe);Wvt=r(_Aa,"convbert"),_Aa.forEach(t),Uvt=r(xno," \u2014 "),fde=n(xno,"A",{href:!0});var bAa=s(fde);Hvt=r(bAa,"TFConvBertForQuestionAnswering"),bAa.forEach(t),Jvt=r(xno," (ConvBERT model)"),xno.forEach(t),Yvt=i(be),C8=n(be,"LI",{});var $no=s(C8);lPe=n($no,"STRONG",{});var vAa=s(lPe);Zvt=r(vAa,"deberta"),vAa.forEach(t),Kvt=r($no," \u2014 "),gde=n($no,"A",{href:!0});var FAa=s(gde);eFt=r(FAa,"TFDebertaForQuestionAnswering"),FAa.forEach(t),oFt=r($no," (DeBERTa model)"),$no.forEach(t),rFt=i(be),w8=n(be,"LI",{});var kno=s(w8);iPe=n(kno,"STRONG",{});var TAa=s(iPe);tFt=r(TAa,"deberta-v2"),TAa.forEach(t),aFt=r(kno," \u2014 "),hde=n(kno,"A",{href:!0});var MAa=s(hde);nFt=r(MAa,"TFDebertaV2ForQuestionAnswering"),MAa.forEach(t),sFt=r(kno," (DeBERTa-v2 model)"),kno.forEach(t),lFt=i(be),A8=n(be,"LI",{});var Sno=s(A8);dPe=n(Sno,"STRONG",{});var EAa=s(dPe);iFt=r(EAa,"distilbert"),EAa.forEach(t),dFt=r(Sno," \u2014 "),ude=n(Sno,"A",{href:!0});var CAa=s(ude);mFt=r(CAa,"TFDistilBertForQuestionAnswering"),CAa.forEach(t),cFt=r(Sno," (DistilBERT model)"),Sno.forEach(t),fFt=i(be),L8=n(be,"LI",{});var Rno=s(L8);mPe=n(Rno,"STRONG",{});var wAa=s(mPe);gFt=r(wAa,"electra"),wAa.forEach(t),hFt=r(Rno," \u2014 "),pde=n(Rno,"A",{href:!0});var AAa=s(pde);uFt=r(AAa,"TFElectraForQuestionAnswering"),AAa.forEach(t),pFt=r(Rno," (ELECTRA model)"),Rno.forEach(t),_Ft=i(be),y8=n(be,"LI",{});var Pno=s(y8);cPe=n(Pno,"STRONG",{});var LAa=s(cPe);bFt=r(LAa,"flaubert"),LAa.forEach(t),vFt=r(Pno," \u2014 "),_de=n(Pno,"A",{href:!0});var yAa=s(_de);FFt=r(yAa,"TFFlaubertForQuestionAnsweringSimple"),yAa.forEach(t),TFt=r(Pno," (FlauBERT model)"),Pno.forEach(t),MFt=i(be),x8=n(be,"LI",{});var Bno=s(x8);fPe=n(Bno,"STRONG",{});var xAa=s(fPe);EFt=r(xAa,"funnel"),xAa.forEach(t),CFt=r(Bno," \u2014 "),bde=n(Bno,"A",{href:!0});var $Aa=s(bde);wFt=r($Aa,"TFFunnelForQuestionAnswering"),$Aa.forEach(t),AFt=r(Bno," (Funnel Transformer model)"),Bno.forEach(t),LFt=i(be),$8=n(be,"LI",{});var Ino=s($8);gPe=n(Ino,"STRONG",{});var kAa=s(gPe);yFt=r(kAa,"gptj"),kAa.forEach(t),xFt=r(Ino," \u2014 "),vde=n(Ino,"A",{href:!0});var SAa=s(vde);$Ft=r(SAa,"TFGPTJForQuestionAnswering"),SAa.forEach(t),kFt=r(Ino," (GPT-J model)"),Ino.forEach(t),SFt=i(be),k8=n(be,"LI",{});var Nno=s(k8);hPe=n(Nno,"STRONG",{});var RAa=s(hPe);RFt=r(RAa,"layoutlmv3"),RAa.forEach(t),PFt=r(Nno," \u2014 "),Fde=n(Nno,"A",{href:!0});var PAa=s(Fde);BFt=r(PAa,"TFLayoutLMv3ForQuestionAnswering"),PAa.forEach(t),IFt=r(Nno," (LayoutLMv3 model)"),Nno.forEach(t),NFt=i(be),S8=n(be,"LI",{});var qno=s(S8);uPe=n(qno,"STRONG",{});var BAa=s(uPe);qFt=r(BAa,"longformer"),BAa.forEach(t),jFt=r(qno," \u2014 "),Tde=n(qno,"A",{href:!0});var IAa=s(Tde);DFt=r(IAa,"TFLongformerForQuestionAnswering"),IAa.forEach(t),GFt=r(qno," (Longformer model)"),qno.forEach(t),OFt=i(be),R8=n(be,"LI",{});var jno=s(R8);pPe=n(jno,"STRONG",{});var NAa=s(pPe);VFt=r(NAa,"mobilebert"),NAa.forEach(t),XFt=r(jno," \u2014 "),Mde=n(jno,"A",{href:!0});var qAa=s(Mde);zFt=r(qAa,"TFMobileBertForQuestionAnswering"),qAa.forEach(t),QFt=r(jno," (MobileBERT model)"),jno.forEach(t),WFt=i(be),P8=n(be,"LI",{});var Dno=s(P8);_Pe=n(Dno,"STRONG",{});var jAa=s(_Pe);UFt=r(jAa,"mpnet"),jAa.forEach(t),HFt=r(Dno," \u2014 "),Ede=n(Dno,"A",{href:!0});var DAa=s(Ede);JFt=r(DAa,"TFMPNetForQuestionAnswering"),DAa.forEach(t),YFt=r(Dno," (MPNet model)"),Dno.forEach(t),ZFt=i(be),B8=n(be,"LI",{});var Gno=s(B8);bPe=n(Gno,"STRONG",{});var GAa=s(bPe);KFt=r(GAa,"rembert"),GAa.forEach(t),eTt=r(Gno," \u2014 "),Cde=n(Gno,"A",{href:!0});var OAa=s(Cde);oTt=r(OAa,"TFRemBertForQuestionAnswering"),OAa.forEach(t),rTt=r(Gno," (RemBERT model)"),Gno.forEach(t),tTt=i(be),I8=n(be,"LI",{});var Ono=s(I8);vPe=n(Ono,"STRONG",{});var VAa=s(vPe);aTt=r(VAa,"roberta"),VAa.forEach(t),nTt=r(Ono," \u2014 "),wde=n(Ono,"A",{href:!0});var XAa=s(wde);sTt=r(XAa,"TFRobertaForQuestionAnswering"),XAa.forEach(t),lTt=r(Ono," (RoBERTa model)"),Ono.forEach(t),iTt=i(be),N8=n(be,"LI",{});var Vno=s(N8);FPe=n(Vno,"STRONG",{});var zAa=s(FPe);dTt=r(zAa,"roformer"),zAa.forEach(t),mTt=r(Vno," \u2014 "),Ade=n(Vno,"A",{href:!0});var QAa=s(Ade);cTt=r(QAa,"TFRoFormerForQuestionAnswering"),QAa.forEach(t),fTt=r(Vno," (RoFormer model)"),Vno.forEach(t),gTt=i(be),q8=n(be,"LI",{});var Xno=s(q8);TPe=n(Xno,"STRONG",{});var WAa=s(TPe);hTt=r(WAa,"xlm"),WAa.forEach(t),uTt=r(Xno," \u2014 "),Lde=n(Xno,"A",{href:!0});var UAa=s(Lde);pTt=r(UAa,"TFXLMForQuestionAnsweringSimple"),UAa.forEach(t),_Tt=r(Xno," (XLM model)"),Xno.forEach(t),bTt=i(be),j8=n(be,"LI",{});var zno=s(j8);MPe=n(zno,"STRONG",{});var HAa=s(MPe);vTt=r(HAa,"xlm-roberta"),HAa.forEach(t),FTt=r(zno," \u2014 "),yde=n(zno,"A",{href:!0});var JAa=s(yde);TTt=r(JAa,"TFXLMRobertaForQuestionAnswering"),JAa.forEach(t),MTt=r(zno," (XLM-RoBERTa model)"),zno.forEach(t),ETt=i(be),D8=n(be,"LI",{});var Qno=s(D8);EPe=n(Qno,"STRONG",{});var YAa=s(EPe);CTt=r(YAa,"xlnet"),YAa.forEach(t),wTt=r(Qno," \u2014 "),xde=n(Qno,"A",{href:!0});var ZAa=s(xde);ATt=r(ZAa,"TFXLNetForQuestionAnsweringSimple"),ZAa.forEach(t),LTt=r(Qno," (XLNet model)"),Qno.forEach(t),be.forEach(t),yTt=i(Yi),T(G8.$$.fragment,Yi),Yi.forEach(t),Ji.forEach(t),Vdo=i(c),df=n(c,"H2",{class:!0});var gfo=s(df);O8=n(gfo,"A",{id:!0,class:!0,href:!0});var KAa=s(O8);CPe=n(KAa,"SPAN",{});var e6a=s(CPe);T(HB.$$.fragment,e6a),e6a.forEach(t),KAa.forEach(t),xTt=i(gfo),wPe=n(gfo,"SPAN",{});var o6a=s(wPe);$Tt=r(o6a,"TFAutoModelForVision2Seq"),o6a.forEach(t),gfo.forEach(t),Xdo=i(c),xr=n(c,"DIV",{class:!0});var Zi=s(xr);T(JB.$$.fragment,Zi),kTt=i(Zi),mf=n(Zi,"P",{});var the=s(mf);STt=r(the,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),$de=n(the,"A",{href:!0});var r6a=s($de);RTt=r(r6a,"from_pretrained()"),r6a.forEach(t),PTt=r(the," class method or the "),kde=n(the,"A",{href:!0});var t6a=s(kde);BTt=r(t6a,"from_config()"),t6a.forEach(t),ITt=r(the,` class
method.`),the.forEach(t),NTt=i(Zi),YB=n(Zi,"P",{});var hfo=s(YB);qTt=r(hfo,"This class cannot be instantiated directly using "),APe=n(hfo,"CODE",{});var a6a=s(APe);jTt=r(a6a,"__init__()"),a6a.forEach(t),DTt=r(hfo," (throws an error)."),hfo.forEach(t),GTt=i(Zi),ua=n(Zi,"DIV",{class:!0});var V$=s(ua);T(ZB.$$.fragment,V$),OTt=i(V$),LPe=n(V$,"P",{});var n6a=s(LPe);VTt=r(n6a,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),n6a.forEach(t),XTt=i(V$),cf=n(V$,"P",{});var ahe=s(cf);zTt=r(ahe,`Note:
Loading a model from its configuration file does `),yPe=n(ahe,"STRONG",{});var s6a=s(yPe);QTt=r(s6a,"not"),s6a.forEach(t),WTt=r(ahe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Sde=n(ahe,"A",{href:!0});var l6a=s(Sde);UTt=r(l6a,"from_pretrained()"),l6a.forEach(t),HTt=r(ahe," to load the model weights."),ahe.forEach(t),JTt=i(V$),T(V8.$$.fragment,V$),V$.forEach(t),YTt=i(Zi),nt=n(Zi,"DIV",{class:!0});var Ki=s(nt);T(KB.$$.fragment,Ki),ZTt=i(Ki),xPe=n(Ki,"P",{});var i6a=s(xPe);KTt=r(i6a,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),i6a.forEach(t),eMt=i(Ki),rs=n(Ki,"P",{});var X$=s(rs);oMt=r(X$,"The model class to instantiate is selected based on the "),$Pe=n(X$,"CODE",{});var d6a=s($Pe);rMt=r(d6a,"model_type"),d6a.forEach(t),tMt=r(X$,` property of the config object (either
passed as an argument or loaded from `),kPe=n(X$,"CODE",{});var m6a=s(kPe);aMt=r(m6a,"pretrained_model_name_or_path"),m6a.forEach(t),nMt=r(X$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),SPe=n(X$,"CODE",{});var c6a=s(SPe);sMt=r(c6a,"pretrained_model_name_or_path"),c6a.forEach(t),lMt=r(X$,":"),X$.forEach(t),iMt=i(Ki),RPe=n(Ki,"UL",{});var f6a=s(RPe);X8=n(f6a,"LI",{});var Wno=s(X8);PPe=n(Wno,"STRONG",{});var g6a=s(PPe);dMt=r(g6a,"vision-encoder-decoder"),g6a.forEach(t),mMt=r(Wno," \u2014 "),Rde=n(Wno,"A",{href:!0});var h6a=s(Rde);cMt=r(h6a,"TFVisionEncoderDecoderModel"),h6a.forEach(t),fMt=r(Wno," (Vision Encoder decoder model)"),Wno.forEach(t),f6a.forEach(t),gMt=i(Ki),T(z8.$$.fragment,Ki),Ki.forEach(t),Zi.forEach(t),zdo=i(c),ff=n(c,"H2",{class:!0});var ufo=s(ff);Q8=n(ufo,"A",{id:!0,class:!0,href:!0});var u6a=s(Q8);BPe=n(u6a,"SPAN",{});var p6a=s(BPe);T(eI.$$.fragment,p6a),p6a.forEach(t),u6a.forEach(t),hMt=i(ufo),IPe=n(ufo,"SPAN",{});var _6a=s(IPe);uMt=r(_6a,"TFAutoModelForSpeechSeq2Seq"),_6a.forEach(t),ufo.forEach(t),Qdo=i(c),$r=n(c,"DIV",{class:!0});var ed=s($r);T(oI.$$.fragment,ed),pMt=i(ed),gf=n(ed,"P",{});var nhe=s(gf);_Mt=r(nhe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),Pde=n(nhe,"A",{href:!0});var b6a=s(Pde);bMt=r(b6a,"from_pretrained()"),b6a.forEach(t),vMt=r(nhe," class method or the "),Bde=n(nhe,"A",{href:!0});var v6a=s(Bde);FMt=r(v6a,"from_config()"),v6a.forEach(t),TMt=r(nhe,` class
method.`),nhe.forEach(t),MMt=i(ed),rI=n(ed,"P",{});var pfo=s(rI);EMt=r(pfo,"This class cannot be instantiated directly using "),NPe=n(pfo,"CODE",{});var F6a=s(NPe);CMt=r(F6a,"__init__()"),F6a.forEach(t),wMt=r(pfo," (throws an error)."),pfo.forEach(t),AMt=i(ed),pa=n(ed,"DIV",{class:!0});var z$=s(pa);T(tI.$$.fragment,z$),LMt=i(z$),qPe=n(z$,"P",{});var T6a=s(qPe);yMt=r(T6a,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),T6a.forEach(t),xMt=i(z$),hf=n(z$,"P",{});var she=s(hf);$Mt=r(she,`Note:
Loading a model from its configuration file does `),jPe=n(she,"STRONG",{});var M6a=s(jPe);kMt=r(M6a,"not"),M6a.forEach(t),SMt=r(she,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ide=n(she,"A",{href:!0});var E6a=s(Ide);RMt=r(E6a,"from_pretrained()"),E6a.forEach(t),PMt=r(she," to load the model weights."),she.forEach(t),BMt=i(z$),T(W8.$$.fragment,z$),z$.forEach(t),IMt=i(ed),st=n(ed,"DIV",{class:!0});var od=s(st);T(aI.$$.fragment,od),NMt=i(od),DPe=n(od,"P",{});var C6a=s(DPe);qMt=r(C6a,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),C6a.forEach(t),jMt=i(od),ts=n(od,"P",{});var Q$=s(ts);DMt=r(Q$,"The model class to instantiate is selected based on the "),GPe=n(Q$,"CODE",{});var w6a=s(GPe);GMt=r(w6a,"model_type"),w6a.forEach(t),OMt=r(Q$,` property of the config object (either
passed as an argument or loaded from `),OPe=n(Q$,"CODE",{});var A6a=s(OPe);VMt=r(A6a,"pretrained_model_name_or_path"),A6a.forEach(t),XMt=r(Q$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),VPe=n(Q$,"CODE",{});var L6a=s(VPe);zMt=r(L6a,"pretrained_model_name_or_path"),L6a.forEach(t),QMt=r(Q$,":"),Q$.forEach(t),WMt=i(od),nI=n(od,"UL",{});var _fo=s(nI);U8=n(_fo,"LI",{});var Uno=s(U8);XPe=n(Uno,"STRONG",{});var y6a=s(XPe);UMt=r(y6a,"speech_to_text"),y6a.forEach(t),HMt=r(Uno," \u2014 "),Nde=n(Uno,"A",{href:!0});var x6a=s(Nde);JMt=r(x6a,"TFSpeech2TextForConditionalGeneration"),x6a.forEach(t),YMt=r(Uno," (Speech2Text model)"),Uno.forEach(t),ZMt=i(_fo),H8=n(_fo,"LI",{});var Hno=s(H8);zPe=n(Hno,"STRONG",{});var $6a=s(zPe);KMt=r($6a,"whisper"),$6a.forEach(t),eEt=r(Hno," \u2014 "),qde=n(Hno,"A",{href:!0});var k6a=s(qde);oEt=r(k6a,"TFWhisperForConditionalGeneration"),k6a.forEach(t),rEt=r(Hno," (Whisper model)"),Hno.forEach(t),_fo.forEach(t),tEt=i(od),T(J8.$$.fragment,od),od.forEach(t),ed.forEach(t),Wdo=i(c),uf=n(c,"H2",{class:!0});var bfo=s(uf);Y8=n(bfo,"A",{id:!0,class:!0,href:!0});var S6a=s(Y8);QPe=n(S6a,"SPAN",{});var R6a=s(QPe);T(sI.$$.fragment,R6a),R6a.forEach(t),S6a.forEach(t),aEt=i(bfo),WPe=n(bfo,"SPAN",{});var P6a=s(WPe);nEt=r(P6a,"FlaxAutoModel"),P6a.forEach(t),bfo.forEach(t),Udo=i(c),kr=n(c,"DIV",{class:!0});var rd=s(kr);T(lI.$$.fragment,rd),sEt=i(rd),pf=n(rd,"P",{});var lhe=s(pf);lEt=r(lhe,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),jde=n(lhe,"A",{href:!0});var B6a=s(jde);iEt=r(B6a,"from_pretrained()"),B6a.forEach(t),dEt=r(lhe," class method or the "),Dde=n(lhe,"A",{href:!0});var I6a=s(Dde);mEt=r(I6a,"from_config()"),I6a.forEach(t),cEt=r(lhe,` class
method.`),lhe.forEach(t),fEt=i(rd),iI=n(rd,"P",{});var vfo=s(iI);gEt=r(vfo,"This class cannot be instantiated directly using "),UPe=n(vfo,"CODE",{});var N6a=s(UPe);hEt=r(N6a,"__init__()"),N6a.forEach(t),uEt=r(vfo," (throws an error)."),vfo.forEach(t),pEt=i(rd),_a=n(rd,"DIV",{class:!0});var W$=s(_a);T(dI.$$.fragment,W$),_Et=i(W$),HPe=n(W$,"P",{});var q6a=s(HPe);bEt=r(q6a,"Instantiates one of the base model classes of the library from a configuration."),q6a.forEach(t),vEt=i(W$),_f=n(W$,"P",{});var ihe=s(_f);FEt=r(ihe,`Note:
Loading a model from its configuration file does `),JPe=n(ihe,"STRONG",{});var j6a=s(JPe);TEt=r(j6a,"not"),j6a.forEach(t),MEt=r(ihe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Gde=n(ihe,"A",{href:!0});var D6a=s(Gde);EEt=r(D6a,"from_pretrained()"),D6a.forEach(t),CEt=r(ihe," to load the model weights."),ihe.forEach(t),wEt=i(W$),T(Z8.$$.fragment,W$),W$.forEach(t),AEt=i(rd),lt=n(rd,"DIV",{class:!0});var td=s(lt);T(mI.$$.fragment,td),LEt=i(td),YPe=n(td,"P",{});var G6a=s(YPe);yEt=r(G6a,"Instantiate one of the base model classes of the library from a pretrained model."),G6a.forEach(t),xEt=i(td),as=n(td,"P",{});var U$=s(as);$Et=r(U$,"The model class to instantiate is selected based on the "),ZPe=n(U$,"CODE",{});var O6a=s(ZPe);kEt=r(O6a,"model_type"),O6a.forEach(t),SEt=r(U$,` property of the config object (either
passed as an argument or loaded from `),KPe=n(U$,"CODE",{});var V6a=s(KPe);REt=r(V6a,"pretrained_model_name_or_path"),V6a.forEach(t),PEt=r(U$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eBe=n(U$,"CODE",{});var X6a=s(eBe);BEt=r(X6a,"pretrained_model_name_or_path"),X6a.forEach(t),IEt=r(U$,":"),U$.forEach(t),NEt=i(td),ne=n(td,"UL",{});var le=s(ne);K8=n(le,"LI",{});var Jno=s(K8);oBe=n(Jno,"STRONG",{});var z6a=s(oBe);qEt=r(z6a,"albert"),z6a.forEach(t),jEt=r(Jno," \u2014 "),Ode=n(Jno,"A",{href:!0});var Q6a=s(Ode);DEt=r(Q6a,"FlaxAlbertModel"),Q6a.forEach(t),GEt=r(Jno," (ALBERT model)"),Jno.forEach(t),OEt=i(le),eL=n(le,"LI",{});var Yno=s(eL);rBe=n(Yno,"STRONG",{});var W6a=s(rBe);VEt=r(W6a,"bart"),W6a.forEach(t),XEt=r(Yno," \u2014 "),Vde=n(Yno,"A",{href:!0});var U6a=s(Vde);zEt=r(U6a,"FlaxBartModel"),U6a.forEach(t),QEt=r(Yno," (BART model)"),Yno.forEach(t),WEt=i(le),oL=n(le,"LI",{});var Zno=s(oL);tBe=n(Zno,"STRONG",{});var H6a=s(tBe);UEt=r(H6a,"beit"),H6a.forEach(t),HEt=r(Zno," \u2014 "),Xde=n(Zno,"A",{href:!0});var J6a=s(Xde);JEt=r(J6a,"FlaxBeitModel"),J6a.forEach(t),YEt=r(Zno," (BEiT model)"),Zno.forEach(t),ZEt=i(le),rL=n(le,"LI",{});var Kno=s(rL);aBe=n(Kno,"STRONG",{});var Y6a=s(aBe);KEt=r(Y6a,"bert"),Y6a.forEach(t),e4t=r(Kno," \u2014 "),zde=n(Kno,"A",{href:!0});var Z6a=s(zde);o4t=r(Z6a,"FlaxBertModel"),Z6a.forEach(t),r4t=r(Kno," (BERT model)"),Kno.forEach(t),t4t=i(le),tL=n(le,"LI",{});var eso=s(tL);nBe=n(eso,"STRONG",{});var K6a=s(nBe);a4t=r(K6a,"big_bird"),K6a.forEach(t),n4t=r(eso," \u2014 "),Qde=n(eso,"A",{href:!0});var e7a=s(Qde);s4t=r(e7a,"FlaxBigBirdModel"),e7a.forEach(t),l4t=r(eso," (BigBird model)"),eso.forEach(t),i4t=i(le),aL=n(le,"LI",{});var oso=s(aL);sBe=n(oso,"STRONG",{});var o7a=s(sBe);d4t=r(o7a,"blenderbot"),o7a.forEach(t),m4t=r(oso," \u2014 "),Wde=n(oso,"A",{href:!0});var r7a=s(Wde);c4t=r(r7a,"FlaxBlenderbotModel"),r7a.forEach(t),f4t=r(oso," (Blenderbot model)"),oso.forEach(t),g4t=i(le),nL=n(le,"LI",{});var rso=s(nL);lBe=n(rso,"STRONG",{});var t7a=s(lBe);h4t=r(t7a,"blenderbot-small"),t7a.forEach(t),u4t=r(rso," \u2014 "),Ude=n(rso,"A",{href:!0});var a7a=s(Ude);p4t=r(a7a,"FlaxBlenderbotSmallModel"),a7a.forEach(t),_4t=r(rso," (BlenderbotSmall model)"),rso.forEach(t),b4t=i(le),sL=n(le,"LI",{});var tso=s(sL);iBe=n(tso,"STRONG",{});var n7a=s(iBe);v4t=r(n7a,"clip"),n7a.forEach(t),F4t=r(tso," \u2014 "),Hde=n(tso,"A",{href:!0});var s7a=s(Hde);T4t=r(s7a,"FlaxCLIPModel"),s7a.forEach(t),M4t=r(tso," (CLIP model)"),tso.forEach(t),E4t=i(le),lL=n(le,"LI",{});var aso=s(lL);dBe=n(aso,"STRONG",{});var l7a=s(dBe);C4t=r(l7a,"distilbert"),l7a.forEach(t),w4t=r(aso," \u2014 "),Jde=n(aso,"A",{href:!0});var i7a=s(Jde);A4t=r(i7a,"FlaxDistilBertModel"),i7a.forEach(t),L4t=r(aso," (DistilBERT model)"),aso.forEach(t),y4t=i(le),iL=n(le,"LI",{});var nso=s(iL);mBe=n(nso,"STRONG",{});var d7a=s(mBe);x4t=r(d7a,"electra"),d7a.forEach(t),$4t=r(nso," \u2014 "),Yde=n(nso,"A",{href:!0});var m7a=s(Yde);k4t=r(m7a,"FlaxElectraModel"),m7a.forEach(t),S4t=r(nso," (ELECTRA model)"),nso.forEach(t),R4t=i(le),dL=n(le,"LI",{});var sso=s(dL);cBe=n(sso,"STRONG",{});var c7a=s(cBe);P4t=r(c7a,"gpt2"),c7a.forEach(t),B4t=r(sso," \u2014 "),Zde=n(sso,"A",{href:!0});var f7a=s(Zde);I4t=r(f7a,"FlaxGPT2Model"),f7a.forEach(t),N4t=r(sso," (OpenAI GPT-2 model)"),sso.forEach(t),q4t=i(le),mL=n(le,"LI",{});var lso=s(mL);fBe=n(lso,"STRONG",{});var g7a=s(fBe);j4t=r(g7a,"gpt_neo"),g7a.forEach(t),D4t=r(lso," \u2014 "),Kde=n(lso,"A",{href:!0});var h7a=s(Kde);G4t=r(h7a,"FlaxGPTNeoModel"),h7a.forEach(t),O4t=r(lso," (GPT Neo model)"),lso.forEach(t),V4t=i(le),cL=n(le,"LI",{});var iso=s(cL);gBe=n(iso,"STRONG",{});var u7a=s(gBe);X4t=r(u7a,"gptj"),u7a.forEach(t),z4t=r(iso," \u2014 "),eme=n(iso,"A",{href:!0});var p7a=s(eme);Q4t=r(p7a,"FlaxGPTJModel"),p7a.forEach(t),W4t=r(iso," (GPT-J model)"),iso.forEach(t),U4t=i(le),fL=n(le,"LI",{});var dso=s(fL);hBe=n(dso,"STRONG",{});var _7a=s(hBe);H4t=r(_7a,"longt5"),_7a.forEach(t),J4t=r(dso," \u2014 "),ome=n(dso,"A",{href:!0});var b7a=s(ome);Y4t=r(b7a,"FlaxLongT5Model"),b7a.forEach(t),Z4t=r(dso," (LongT5 model)"),dso.forEach(t),K4t=i(le),gL=n(le,"LI",{});var mso=s(gL);uBe=n(mso,"STRONG",{});var v7a=s(uBe);eCt=r(v7a,"marian"),v7a.forEach(t),oCt=r(mso," \u2014 "),rme=n(mso,"A",{href:!0});var F7a=s(rme);rCt=r(F7a,"FlaxMarianModel"),F7a.forEach(t),tCt=r(mso," (Marian model)"),mso.forEach(t),aCt=i(le),hL=n(le,"LI",{});var cso=s(hL);pBe=n(cso,"STRONG",{});var T7a=s(pBe);nCt=r(T7a,"mbart"),T7a.forEach(t),sCt=r(cso," \u2014 "),tme=n(cso,"A",{href:!0});var M7a=s(tme);lCt=r(M7a,"FlaxMBartModel"),M7a.forEach(t),iCt=r(cso," (mBART model)"),cso.forEach(t),dCt=i(le),uL=n(le,"LI",{});var fso=s(uL);_Be=n(fso,"STRONG",{});var E7a=s(_Be);mCt=r(E7a,"mt5"),E7a.forEach(t),cCt=r(fso," \u2014 "),ame=n(fso,"A",{href:!0});var C7a=s(ame);fCt=r(C7a,"FlaxMT5Model"),C7a.forEach(t),gCt=r(fso," (MT5 model)"),fso.forEach(t),hCt=i(le),pL=n(le,"LI",{});var gso=s(pL);bBe=n(gso,"STRONG",{});var w7a=s(bBe);uCt=r(w7a,"opt"),w7a.forEach(t),pCt=r(gso," \u2014 "),nme=n(gso,"A",{href:!0});var A7a=s(nme);_Ct=r(A7a,"FlaxOPTModel"),A7a.forEach(t),bCt=r(gso," (OPT model)"),gso.forEach(t),vCt=i(le),_L=n(le,"LI",{});var hso=s(_L);vBe=n(hso,"STRONG",{});var L7a=s(vBe);FCt=r(L7a,"pegasus"),L7a.forEach(t),TCt=r(hso," \u2014 "),sme=n(hso,"A",{href:!0});var y7a=s(sme);MCt=r(y7a,"FlaxPegasusModel"),y7a.forEach(t),ECt=r(hso," (Pegasus model)"),hso.forEach(t),CCt=i(le),bL=n(le,"LI",{});var uso=s(bL);FBe=n(uso,"STRONG",{});var x7a=s(FBe);wCt=r(x7a,"roberta"),x7a.forEach(t),ACt=r(uso," \u2014 "),lme=n(uso,"A",{href:!0});var $7a=s(lme);LCt=r($7a,"FlaxRobertaModel"),$7a.forEach(t),yCt=r(uso," (RoBERTa model)"),uso.forEach(t),xCt=i(le),vL=n(le,"LI",{});var pso=s(vL);TBe=n(pso,"STRONG",{});var k7a=s(TBe);$Ct=r(k7a,"roformer"),k7a.forEach(t),kCt=r(pso," \u2014 "),ime=n(pso,"A",{href:!0});var S7a=s(ime);SCt=r(S7a,"FlaxRoFormerModel"),S7a.forEach(t),RCt=r(pso," (RoFormer model)"),pso.forEach(t),PCt=i(le),FL=n(le,"LI",{});var _so=s(FL);MBe=n(_so,"STRONG",{});var R7a=s(MBe);BCt=r(R7a,"t5"),R7a.forEach(t),ICt=r(_so," \u2014 "),dme=n(_so,"A",{href:!0});var P7a=s(dme);NCt=r(P7a,"FlaxT5Model"),P7a.forEach(t),qCt=r(_so," (T5 model)"),_so.forEach(t),jCt=i(le),TL=n(le,"LI",{});var bso=s(TL);EBe=n(bso,"STRONG",{});var B7a=s(EBe);DCt=r(B7a,"vision-text-dual-encoder"),B7a.forEach(t),GCt=r(bso," \u2014 "),mme=n(bso,"A",{href:!0});var I7a=s(mme);OCt=r(I7a,"FlaxVisionTextDualEncoderModel"),I7a.forEach(t),VCt=r(bso," (VisionTextDualEncoder model)"),bso.forEach(t),XCt=i(le),ML=n(le,"LI",{});var vso=s(ML);CBe=n(vso,"STRONG",{});var N7a=s(CBe);zCt=r(N7a,"vit"),N7a.forEach(t),QCt=r(vso," \u2014 "),cme=n(vso,"A",{href:!0});var q7a=s(cme);WCt=r(q7a,"FlaxViTModel"),q7a.forEach(t),UCt=r(vso," (ViT model)"),vso.forEach(t),HCt=i(le),EL=n(le,"LI",{});var Fso=s(EL);wBe=n(Fso,"STRONG",{});var j7a=s(wBe);JCt=r(j7a,"wav2vec2"),j7a.forEach(t),YCt=r(Fso," \u2014 "),fme=n(Fso,"A",{href:!0});var D7a=s(fme);ZCt=r(D7a,"FlaxWav2Vec2Model"),D7a.forEach(t),KCt=r(Fso," (Wav2Vec2 model)"),Fso.forEach(t),e3t=i(le),CL=n(le,"LI",{});var Tso=s(CL);ABe=n(Tso,"STRONG",{});var G7a=s(ABe);o3t=r(G7a,"xglm"),G7a.forEach(t),r3t=r(Tso," \u2014 "),gme=n(Tso,"A",{href:!0});var O7a=s(gme);t3t=r(O7a,"FlaxXGLMModel"),O7a.forEach(t),a3t=r(Tso," (XGLM model)"),Tso.forEach(t),n3t=i(le),wL=n(le,"LI",{});var Mso=s(wL);LBe=n(Mso,"STRONG",{});var V7a=s(LBe);s3t=r(V7a,"xlm-roberta"),V7a.forEach(t),l3t=r(Mso," \u2014 "),hme=n(Mso,"A",{href:!0});var X7a=s(hme);i3t=r(X7a,"FlaxXLMRobertaModel"),X7a.forEach(t),d3t=r(Mso," (XLM-RoBERTa model)"),Mso.forEach(t),le.forEach(t),m3t=i(td),T(AL.$$.fragment,td),td.forEach(t),rd.forEach(t),Hdo=i(c),bf=n(c,"H2",{class:!0});var Ffo=s(bf);LL=n(Ffo,"A",{id:!0,class:!0,href:!0});var z7a=s(LL);yBe=n(z7a,"SPAN",{});var Q7a=s(yBe);T(cI.$$.fragment,Q7a),Q7a.forEach(t),z7a.forEach(t),c3t=i(Ffo),xBe=n(Ffo,"SPAN",{});var W7a=s(xBe);f3t=r(W7a,"FlaxAutoModelForCausalLM"),W7a.forEach(t),Ffo.forEach(t),Jdo=i(c),Sr=n(c,"DIV",{class:!0});var ad=s(Sr);T(fI.$$.fragment,ad),g3t=i(ad),vf=n(ad,"P",{});var dhe=s(vf);h3t=r(dhe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),ume=n(dhe,"A",{href:!0});var U7a=s(ume);u3t=r(U7a,"from_pretrained()"),U7a.forEach(t),p3t=r(dhe," class method or the "),pme=n(dhe,"A",{href:!0});var H7a=s(pme);_3t=r(H7a,"from_config()"),H7a.forEach(t),b3t=r(dhe,` class
method.`),dhe.forEach(t),v3t=i(ad),gI=n(ad,"P",{});var Tfo=s(gI);F3t=r(Tfo,"This class cannot be instantiated directly using "),$Be=n(Tfo,"CODE",{});var J7a=s($Be);T3t=r(J7a,"__init__()"),J7a.forEach(t),M3t=r(Tfo," (throws an error)."),Tfo.forEach(t),E3t=i(ad),ba=n(ad,"DIV",{class:!0});var H$=s(ba);T(hI.$$.fragment,H$),C3t=i(H$),kBe=n(H$,"P",{});var Y7a=s(kBe);w3t=r(Y7a,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Y7a.forEach(t),A3t=i(H$),Ff=n(H$,"P",{});var mhe=s(Ff);L3t=r(mhe,`Note:
Loading a model from its configuration file does `),SBe=n(mhe,"STRONG",{});var Z7a=s(SBe);y3t=r(Z7a,"not"),Z7a.forEach(t),x3t=r(mhe,` load the model weights. It only affects the
model\u2019s configuration. Use `),_me=n(mhe,"A",{href:!0});var K7a=s(_me);$3t=r(K7a,"from_pretrained()"),K7a.forEach(t),k3t=r(mhe," to load the model weights."),mhe.forEach(t),S3t=i(H$),T(yL.$$.fragment,H$),H$.forEach(t),R3t=i(ad),it=n(ad,"DIV",{class:!0});var nd=s(it);T(uI.$$.fragment,nd),P3t=i(nd),RBe=n(nd,"P",{});var e8a=s(RBe);B3t=r(e8a,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),e8a.forEach(t),I3t=i(nd),ns=n(nd,"P",{});var J$=s(ns);N3t=r(J$,"The model class to instantiate is selected based on the "),PBe=n(J$,"CODE",{});var o8a=s(PBe);q3t=r(o8a,"model_type"),o8a.forEach(t),j3t=r(J$,` property of the config object (either
passed as an argument or loaded from `),BBe=n(J$,"CODE",{});var r8a=s(BBe);D3t=r(r8a,"pretrained_model_name_or_path"),r8a.forEach(t),G3t=r(J$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),IBe=n(J$,"CODE",{});var t8a=s(IBe);O3t=r(t8a,"pretrained_model_name_or_path"),t8a.forEach(t),V3t=r(J$,":"),J$.forEach(t),X3t=i(nd),Se=n(nd,"UL",{});var Ge=s(Se);xL=n(Ge,"LI",{});var Eso=s(xL);NBe=n(Eso,"STRONG",{});var a8a=s(NBe);z3t=r(a8a,"bart"),a8a.forEach(t),Q3t=r(Eso," \u2014 "),bme=n(Eso,"A",{href:!0});var n8a=s(bme);W3t=r(n8a,"FlaxBartForCausalLM"),n8a.forEach(t),U3t=r(Eso," (BART model)"),Eso.forEach(t),H3t=i(Ge),$L=n(Ge,"LI",{});var Cso=s($L);qBe=n(Cso,"STRONG",{});var s8a=s(qBe);J3t=r(s8a,"bert"),s8a.forEach(t),Y3t=r(Cso," \u2014 "),vme=n(Cso,"A",{href:!0});var l8a=s(vme);Z3t=r(l8a,"FlaxBertForCausalLM"),l8a.forEach(t),K3t=r(Cso," (BERT model)"),Cso.forEach(t),e5t=i(Ge),kL=n(Ge,"LI",{});var wso=s(kL);jBe=n(wso,"STRONG",{});var i8a=s(jBe);o5t=r(i8a,"big_bird"),i8a.forEach(t),r5t=r(wso," \u2014 "),Fme=n(wso,"A",{href:!0});var d8a=s(Fme);t5t=r(d8a,"FlaxBigBirdForCausalLM"),d8a.forEach(t),a5t=r(wso," (BigBird model)"),wso.forEach(t),n5t=i(Ge),SL=n(Ge,"LI",{});var Aso=s(SL);DBe=n(Aso,"STRONG",{});var m8a=s(DBe);s5t=r(m8a,"electra"),m8a.forEach(t),l5t=r(Aso," \u2014 "),Tme=n(Aso,"A",{href:!0});var c8a=s(Tme);i5t=r(c8a,"FlaxElectraForCausalLM"),c8a.forEach(t),d5t=r(Aso," (ELECTRA model)"),Aso.forEach(t),m5t=i(Ge),RL=n(Ge,"LI",{});var Lso=s(RL);GBe=n(Lso,"STRONG",{});var f8a=s(GBe);c5t=r(f8a,"gpt2"),f8a.forEach(t),f5t=r(Lso," \u2014 "),Mme=n(Lso,"A",{href:!0});var g8a=s(Mme);g5t=r(g8a,"FlaxGPT2LMHeadModel"),g8a.forEach(t),h5t=r(Lso," (OpenAI GPT-2 model)"),Lso.forEach(t),u5t=i(Ge),PL=n(Ge,"LI",{});var yso=s(PL);OBe=n(yso,"STRONG",{});var h8a=s(OBe);p5t=r(h8a,"gpt_neo"),h8a.forEach(t),_5t=r(yso," \u2014 "),Eme=n(yso,"A",{href:!0});var u8a=s(Eme);b5t=r(u8a,"FlaxGPTNeoForCausalLM"),u8a.forEach(t),v5t=r(yso," (GPT Neo model)"),yso.forEach(t),F5t=i(Ge),BL=n(Ge,"LI",{});var xso=s(BL);VBe=n(xso,"STRONG",{});var p8a=s(VBe);T5t=r(p8a,"gptj"),p8a.forEach(t),M5t=r(xso," \u2014 "),Cme=n(xso,"A",{href:!0});var _8a=s(Cme);E5t=r(_8a,"FlaxGPTJForCausalLM"),_8a.forEach(t),C5t=r(xso," (GPT-J model)"),xso.forEach(t),w5t=i(Ge),IL=n(Ge,"LI",{});var $so=s(IL);XBe=n($so,"STRONG",{});var b8a=s(XBe);A5t=r(b8a,"opt"),b8a.forEach(t),L5t=r($so," \u2014 "),wme=n($so,"A",{href:!0});var v8a=s(wme);y5t=r(v8a,"FlaxOPTForCausalLM"),v8a.forEach(t),x5t=r($so," (OPT model)"),$so.forEach(t),$5t=i(Ge),NL=n(Ge,"LI",{});var kso=s(NL);zBe=n(kso,"STRONG",{});var F8a=s(zBe);k5t=r(F8a,"roberta"),F8a.forEach(t),S5t=r(kso," \u2014 "),Ame=n(kso,"A",{href:!0});var T8a=s(Ame);R5t=r(T8a,"FlaxRobertaForCausalLM"),T8a.forEach(t),P5t=r(kso," (RoBERTa model)"),kso.forEach(t),B5t=i(Ge),qL=n(Ge,"LI",{});var Sso=s(qL);QBe=n(Sso,"STRONG",{});var M8a=s(QBe);I5t=r(M8a,"xglm"),M8a.forEach(t),N5t=r(Sso," \u2014 "),Lme=n(Sso,"A",{href:!0});var E8a=s(Lme);q5t=r(E8a,"FlaxXGLMForCausalLM"),E8a.forEach(t),j5t=r(Sso," (XGLM model)"),Sso.forEach(t),Ge.forEach(t),D5t=i(nd),T(jL.$$.fragment,nd),nd.forEach(t),ad.forEach(t),Ydo=i(c),Tf=n(c,"H2",{class:!0});var Mfo=s(Tf);DL=n(Mfo,"A",{id:!0,class:!0,href:!0});var C8a=s(DL);WBe=n(C8a,"SPAN",{});var w8a=s(WBe);T(pI.$$.fragment,w8a),w8a.forEach(t),C8a.forEach(t),G5t=i(Mfo),UBe=n(Mfo,"SPAN",{});var A8a=s(UBe);O5t=r(A8a,"FlaxAutoModelForPreTraining"),A8a.forEach(t),Mfo.forEach(t),Zdo=i(c),Rr=n(c,"DIV",{class:!0});var sd=s(Rr);T(_I.$$.fragment,sd),V5t=i(sd),Mf=n(sd,"P",{});var che=s(Mf);X5t=r(che,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),yme=n(che,"A",{href:!0});var L8a=s(yme);z5t=r(L8a,"from_pretrained()"),L8a.forEach(t),Q5t=r(che," class method or the "),xme=n(che,"A",{href:!0});var y8a=s(xme);W5t=r(y8a,"from_config()"),y8a.forEach(t),U5t=r(che,` class
method.`),che.forEach(t),H5t=i(sd),bI=n(sd,"P",{});var Efo=s(bI);J5t=r(Efo,"This class cannot be instantiated directly using "),HBe=n(Efo,"CODE",{});var x8a=s(HBe);Y5t=r(x8a,"__init__()"),x8a.forEach(t),Z5t=r(Efo," (throws an error)."),Efo.forEach(t),K5t=i(sd),va=n(sd,"DIV",{class:!0});var Y$=s(va);T(vI.$$.fragment,Y$),e0t=i(Y$),JBe=n(Y$,"P",{});var $8a=s(JBe);o0t=r($8a,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),$8a.forEach(t),r0t=i(Y$),Ef=n(Y$,"P",{});var fhe=s(Ef);t0t=r(fhe,`Note:
Loading a model from its configuration file does `),YBe=n(fhe,"STRONG",{});var k8a=s(YBe);a0t=r(k8a,"not"),k8a.forEach(t),n0t=r(fhe,` load the model weights. It only affects the
model\u2019s configuration. Use `),$me=n(fhe,"A",{href:!0});var S8a=s($me);s0t=r(S8a,"from_pretrained()"),S8a.forEach(t),l0t=r(fhe," to load the model weights."),fhe.forEach(t),i0t=i(Y$),T(GL.$$.fragment,Y$),Y$.forEach(t),d0t=i(sd),dt=n(sd,"DIV",{class:!0});var ld=s(dt);T(FI.$$.fragment,ld),m0t=i(ld),ZBe=n(ld,"P",{});var R8a=s(ZBe);c0t=r(R8a,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),R8a.forEach(t),f0t=i(ld),ss=n(ld,"P",{});var Z$=s(ss);g0t=r(Z$,"The model class to instantiate is selected based on the "),KBe=n(Z$,"CODE",{});var P8a=s(KBe);h0t=r(P8a,"model_type"),P8a.forEach(t),u0t=r(Z$,` property of the config object (either
passed as an argument or loaded from `),eIe=n(Z$,"CODE",{});var B8a=s(eIe);p0t=r(B8a,"pretrained_model_name_or_path"),B8a.forEach(t),_0t=r(Z$,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oIe=n(Z$,"CODE",{});var I8a=s(oIe);b0t=r(I8a,"pretrained_model_name_or_path"),I8a.forEach(t),v0t=r(Z$,":"),Z$.forEach(t),F0t=i(ld),we=n(ld,"UL",{});var Le=s(we);OL=n(Le,"LI",{});var Rso=s(OL);rIe=n(Rso,"STRONG",{});var N8a=s(rIe);T0t=r(N8a,"albert"),N8a.forEach(t),M0t=r(Rso," \u2014 "),kme=n(Rso,"A",{href:!0});var q8a=s(kme);E0t=r(q8a,"FlaxAlbertForPreTraining"),q8a.forEach(t),C0t=r(Rso," (ALBERT model)"),Rso.forEach(t),w0t=i(Le),VL=n(Le,"LI",{});var Pso=s(VL);tIe=n(Pso,"STRONG",{});var j8a=s(tIe);A0t=r(j8a,"bart"),j8a.forEach(t),L0t=r(Pso," \u2014 "),Sme=n(Pso,"A",{href:!0});var D8a=s(Sme);y0t=r(D8a,"FlaxBartForConditionalGeneration"),D8a.forEach(t),x0t=r(Pso," (BART model)"),Pso.forEach(t),$0t=i(Le),XL=n(Le,"LI",{});var Bso=s(XL);aIe=n(Bso,"STRONG",{});var G8a=s(aIe);k0t=r(G8a,"bert"),G8a.forEach(t),S0t=r(Bso," \u2014 "),Rme=n(Bso,"A",{href:!0});var O8a=s(Rme);R0t=r(O8a,"FlaxBertForPreTraining"),O8a.forEach(t),P0t=r(Bso," (BERT model)"),Bso.forEach(t),B0t=i(Le),zL=n(Le,"LI",{});var Iso=s(zL);nIe=n(Iso,"STRONG",{});var V8a=s(nIe);I0t=r(V8a,"big_bird"),V8a.forEach(t),N0t=r(Iso," \u2014 "),Pme=n(Iso,"A",{href:!0});var X8a=s(Pme);q0t=r(X8a,"FlaxBigBirdForPreTraining"),X8a.forEach(t),j0t=r(Iso," (BigBird model)"),Iso.forEach(t),D0t=i(Le),QL=n(Le,"LI",{});var Nso=s(QL);sIe=n(Nso,"STRONG",{});var z8a=s(sIe);G0t=r(z8a,"electra"),z8a.forEach(t),O0t=r(Nso," \u2014 "),Bme=n(Nso,"A",{href:!0});var Q8a=s(Bme);V0t=r(Q8a,"FlaxElectraForPreTraining"),Q8a.forEach(t),X0t=r(Nso," (ELECTRA model)"),Nso.forEach(t),z0t=i(Le),WL=n(Le,"LI",{});var qso=s(WL);lIe=n(qso,"STRONG",{});var W8a=s(lIe);Q0t=r(W8a,"longt5"),W8a.forEach(t),W0t=r(qso," \u2014 "),Ime=n(qso,"A",{href:!0});var U8a=s(Ime);U0t=r(U8a,"FlaxLongT5ForConditionalGeneration"),U8a.forEach(t),H0t=r(qso," (LongT5 model)"),qso.forEach(t),J0t=i(Le),UL=n(Le,"LI",{});var jso=s(UL);iIe=n(jso,"STRONG",{});var H8a=s(iIe);Y0t=r(H8a,"mbart"),H8a.forEach(t),Z0t=r(jso," \u2014 "),Nme=n(jso,"A",{href:!0});var J8a=s(Nme);K0t=r(J8a,"FlaxMBartForConditionalGeneration"),J8a.forEach(t),ewt=r(jso," (mBART model)"),jso.forEach(t),owt=i(Le),HL=n(Le,"LI",{});var Dso=s(HL);dIe=n(Dso,"STRONG",{});var Y8a=s(dIe);rwt=r(Y8a,"mt5"),Y8a.forEach(t),twt=r(Dso," \u2014 "),qme=n(Dso,"A",{href:!0});var Z8a=s(qme);awt=r(Z8a,"FlaxMT5ForConditionalGeneration"),Z8a.forEach(t),nwt=r(Dso," (MT5 model)"),Dso.forEach(t),swt=i(Le),JL=n(Le,"LI",{});var Gso=s(JL);mIe=n(Gso,"STRONG",{});var K8a=s(mIe);lwt=r(K8a,"roberta"),K8a.forEach(t),iwt=r(Gso," \u2014 "),jme=n(Gso,"A",{href:!0});var eLa=s(jme);dwt=r(eLa,"FlaxRobertaForMaskedLM"),eLa.forEach(t),mwt=r(Gso," (RoBERTa model)"),Gso.forEach(t),cwt=i(Le),YL=n(Le,"LI",{});var Oso=s(YL);cIe=n(Oso,"STRONG",{});var oLa=s(cIe);fwt=r(oLa,"roformer"),oLa.forEach(t),gwt=r(Oso," \u2014 "),Dme=n(Oso,"A",{href:!0});var rLa=s(Dme);hwt=r(rLa,"FlaxRoFormerForMaskedLM"),rLa.forEach(t),uwt=r(Oso," (RoFormer model)"),Oso.forEach(t),pwt=i(Le),ZL=n(Le,"LI",{});var Vso=s(ZL);fIe=n(Vso,"STRONG",{});var tLa=s(fIe);_wt=r(tLa,"t5"),tLa.forEach(t),bwt=r(Vso," \u2014 "),Gme=n(Vso,"A",{href:!0});var aLa=s(Gme);vwt=r(aLa,"FlaxT5ForConditionalGeneration"),aLa.forEach(t),Fwt=r(Vso," (T5 model)"),Vso.forEach(t),Twt=i(Le),KL=n(Le,"LI",{});var Xso=s(KL);gIe=n(Xso,"STRONG",{});var nLa=s(gIe);Mwt=r(nLa,"wav2vec2"),nLa.forEach(t),Ewt=r(Xso," \u2014 "),Ome=n(Xso,"A",{href:!0});var sLa=s(Ome);Cwt=r(sLa,"FlaxWav2Vec2ForPreTraining"),sLa.forEach(t),wwt=r(Xso," (Wav2Vec2 model)"),Xso.forEach(t),Awt=i(Le),ey=n(Le,"LI",{});var zso=s(ey);hIe=n(zso,"STRONG",{});var lLa=s(hIe);Lwt=r(lLa,"xlm-roberta"),lLa.forEach(t),ywt=r(zso," \u2014 "),Vme=n(zso,"A",{href:!0});var iLa=s(Vme);xwt=r(iLa,"FlaxXLMRobertaForMaskedLM"),iLa.forEach(t),$wt=r(zso," (XLM-RoBERTa model)"),zso.forEach(t),Le.forEach(t),kwt=i(ld),T(oy.$$.fragment,ld),ld.forEach(t),sd.forEach(t),Kdo=i(c),Cf=n(c,"H2",{class:!0});var Cfo=s(Cf);ry=n(Cfo,"A",{id:!0,class:!0,href:!0});var dLa=s(ry);uIe=n(dLa,"SPAN",{});var mLa=s(uIe);T(TI.$$.fragment,mLa),mLa.forEach(t),dLa.forEach(t),Swt=i(Cfo),pIe=n(Cfo,"SPAN",{});var cLa=s(pIe);Rwt=r(cLa,"FlaxAutoModelForMaskedLM"),cLa.forEach(t),Cfo.forEach(t),emo=i(c),Pr=n(c,"DIV",{class:!0});var id=s(Pr);T(MI.$$.fragment,id),Pwt=i(id),wf=n(id,"P",{});var ghe=s(wf);Bwt=r(ghe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Xme=n(ghe,"A",{href:!0});var fLa=s(Xme);Iwt=r(fLa,"from_pretrained()"),fLa.forEach(t),Nwt=r(ghe," class method or the "),zme=n(ghe,"A",{href:!0});var gLa=s(zme);qwt=r(gLa,"from_config()"),gLa.forEach(t),jwt=r(ghe,` class
method.`),ghe.forEach(t),Dwt=i(id),EI=n(id,"P",{});var wfo=s(EI);Gwt=r(wfo,"This class cannot be instantiated directly using "),_Ie=n(wfo,"CODE",{});var hLa=s(_Ie);Owt=r(hLa,"__init__()"),hLa.forEach(t),Vwt=r(wfo," (throws an error)."),wfo.forEach(t),Xwt=i(id),Fa=n(id,"DIV",{class:!0});var K$=s(Fa);T(CI.$$.fragment,K$),zwt=i(K$),bIe=n(K$,"P",{});var uLa=s(bIe);Qwt=r(uLa,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),uLa.forEach(t),Wwt=i(K$),Af=n(K$,"P",{});var hhe=s(Af);Uwt=r(hhe,`Note:
Loading a model from its configuration file does `),vIe=n(hhe,"STRONG",{});var pLa=s(vIe);Hwt=r(pLa,"not"),pLa.forEach(t),Jwt=r(hhe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qme=n(hhe,"A",{href:!0});var _La=s(Qme);Ywt=r(_La,"from_pretrained()"),_La.forEach(t),Zwt=r(hhe," to load the model weights."),hhe.forEach(t),Kwt=i(K$),T(ty.$$.fragment,K$),K$.forEach(t),eAt=i(id),mt=n(id,"DIV",{class:!0});var dd=s(mt);T(wI.$$.fragment,dd),oAt=i(dd),FIe=n(dd,"P",{});var bLa=s(FIe);rAt=r(bLa,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),bLa.forEach(t),tAt=i(dd),ls=n(dd,"P",{});var ek=s(ls);aAt=r(ek,"The model class to instantiate is selected based on the "),TIe=n(ek,"CODE",{});var vLa=s(TIe);nAt=r(vLa,"model_type"),vLa.forEach(t),sAt=r(ek,` property of the config object (either
passed as an argument or loaded from `),MIe=n(ek,"CODE",{});var FLa=s(MIe);lAt=r(FLa,"pretrained_model_name_or_path"),FLa.forEach(t),iAt=r(ek,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),EIe=n(ek,"CODE",{});var TLa=s(EIe);dAt=r(TLa,"pretrained_model_name_or_path"),TLa.forEach(t),mAt=r(ek,":"),ek.forEach(t),cAt=i(dd),Re=n(dd,"UL",{});var Oe=s(Re);ay=n(Oe,"LI",{});var Qso=s(ay);CIe=n(Qso,"STRONG",{});var MLa=s(CIe);fAt=r(MLa,"albert"),MLa.forEach(t),gAt=r(Qso," \u2014 "),Wme=n(Qso,"A",{href:!0});var ELa=s(Wme);hAt=r(ELa,"FlaxAlbertForMaskedLM"),ELa.forEach(t),uAt=r(Qso," (ALBERT model)"),Qso.forEach(t),pAt=i(Oe),ny=n(Oe,"LI",{});var Wso=s(ny);wIe=n(Wso,"STRONG",{});var CLa=s(wIe);_At=r(CLa,"bart"),CLa.forEach(t),bAt=r(Wso," \u2014 "),Ume=n(Wso,"A",{href:!0});var wLa=s(Ume);vAt=r(wLa,"FlaxBartForConditionalGeneration"),wLa.forEach(t),FAt=r(Wso," (BART model)"),Wso.forEach(t),TAt=i(Oe),sy=n(Oe,"LI",{});var Uso=s(sy);AIe=n(Uso,"STRONG",{});var ALa=s(AIe);MAt=r(ALa,"bert"),ALa.forEach(t),EAt=r(Uso," \u2014 "),Hme=n(Uso,"A",{href:!0});var LLa=s(Hme);CAt=r(LLa,"FlaxBertForMaskedLM"),LLa.forEach(t),wAt=r(Uso," (BERT model)"),Uso.forEach(t),AAt=i(Oe),ly=n(Oe,"LI",{});var Hso=s(ly);LIe=n(Hso,"STRONG",{});var yLa=s(LIe);LAt=r(yLa,"big_bird"),yLa.forEach(t),yAt=r(Hso," \u2014 "),Jme=n(Hso,"A",{href:!0});var xLa=s(Jme);xAt=r(xLa,"FlaxBigBirdForMaskedLM"),xLa.forEach(t),$At=r(Hso," (BigBird model)"),Hso.forEach(t),kAt=i(Oe),iy=n(Oe,"LI",{});var Jso=s(iy);yIe=n(Jso,"STRONG",{});var $La=s(yIe);SAt=r($La,"distilbert"),$La.forEach(t),RAt=r(Jso," \u2014 "),Yme=n(Jso,"A",{href:!0});var kLa=s(Yme);PAt=r(kLa,"FlaxDistilBertForMaskedLM"),kLa.forEach(t),BAt=r(Jso," (DistilBERT model)"),Jso.forEach(t),IAt=i(Oe),dy=n(Oe,"LI",{});var Yso=s(dy);xIe=n(Yso,"STRONG",{});var SLa=s(xIe);NAt=r(SLa,"electra"),SLa.forEach(t),qAt=r(Yso," \u2014 "),Zme=n(Yso,"A",{href:!0});var RLa=s(Zme);jAt=r(RLa,"FlaxElectraForMaskedLM"),RLa.forEach(t),DAt=r(Yso," (ELECTRA model)"),Yso.forEach(t),GAt=i(Oe),my=n(Oe,"LI",{});var Zso=s(my);$Ie=n(Zso,"STRONG",{});var PLa=s($Ie);OAt=r(PLa,"mbart"),PLa.forEach(t),VAt=r(Zso," \u2014 "),Kme=n(Zso,"A",{href:!0});var BLa=s(Kme);XAt=r(BLa,"FlaxMBartForConditionalGeneration"),BLa.forEach(t),zAt=r(Zso," (mBART model)"),Zso.forEach(t),QAt=i(Oe),cy=n(Oe,"LI",{});var Kso=s(cy);kIe=n(Kso,"STRONG",{});var ILa=s(kIe);WAt=r(ILa,"roberta"),ILa.forEach(t),UAt=r(Kso," \u2014 "),ece=n(Kso,"A",{href:!0});var NLa=s(ece);HAt=r(NLa,"FlaxRobertaForMaskedLM"),NLa.forEach(t),JAt=r(Kso," (RoBERTa model)"),Kso.forEach(t),YAt=i(Oe),fy=n(Oe,"LI",{});var elo=s(fy);SIe=n(elo,"STRONG",{});var qLa=s(SIe);ZAt=r(qLa,"roformer"),qLa.forEach(t),KAt=r(elo," \u2014 "),oce=n(elo,"A",{href:!0});var jLa=s(oce);e6t=r(jLa,"FlaxRoFormerForMaskedLM"),jLa.forEach(t),o6t=r(elo," (RoFormer model)"),elo.forEach(t),r6t=i(Oe),gy=n(Oe,"LI",{});var olo=s(gy);RIe=n(olo,"STRONG",{});var DLa=s(RIe);t6t=r(DLa,"xlm-roberta"),DLa.forEach(t),a6t=r(olo," \u2014 "),rce=n(olo,"A",{href:!0});var GLa=s(rce);n6t=r(GLa,"FlaxXLMRobertaForMaskedLM"),GLa.forEach(t),s6t=r(olo," (XLM-RoBERTa model)"),olo.forEach(t),Oe.forEach(t),l6t=i(dd),T(hy.$$.fragment,dd),dd.forEach(t),id.forEach(t),omo=i(c),Lf=n(c,"H2",{class:!0});var Afo=s(Lf);uy=n(Afo,"A",{id:!0,class:!0,href:!0});var OLa=s(uy);PIe=n(OLa,"SPAN",{});var VLa=s(PIe);T(AI.$$.fragment,VLa),VLa.forEach(t),OLa.forEach(t),i6t=i(Afo),BIe=n(Afo,"SPAN",{});var XLa=s(BIe);d6t=r(XLa,"FlaxAutoModelForSeq2SeqLM"),XLa.forEach(t),Afo.forEach(t),rmo=i(c),Br=n(c,"DIV",{class:!0});var md=s(Br);T(LI.$$.fragment,md),m6t=i(md),yf=n(md,"P",{});var uhe=s(yf);c6t=r(uhe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),tce=n(uhe,"A",{href:!0});var zLa=s(tce);f6t=r(zLa,"from_pretrained()"),zLa.forEach(t),g6t=r(uhe," class method or the "),ace=n(uhe,"A",{href:!0});var QLa=s(ace);h6t=r(QLa,"from_config()"),QLa.forEach(t),u6t=r(uhe,` class
method.`),uhe.forEach(t),p6t=i(md),yI=n(md,"P",{});var Lfo=s(yI);_6t=r(Lfo,"This class cannot be instantiated directly using "),IIe=n(Lfo,"CODE",{});var WLa=s(IIe);b6t=r(WLa,"__init__()"),WLa.forEach(t),v6t=r(Lfo," (throws an error)."),Lfo.forEach(t),F6t=i(md),Ta=n(md,"DIV",{class:!0});var ok=s(Ta);T(xI.$$.fragment,ok),T6t=i(ok),NIe=n(ok,"P",{});var ULa=s(NIe);M6t=r(ULa,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),ULa.forEach(t),E6t=i(ok),xf=n(ok,"P",{});var phe=s(xf);C6t=r(phe,`Note:
Loading a model from its configuration file does `),qIe=n(phe,"STRONG",{});var HLa=s(qIe);w6t=r(HLa,"not"),HLa.forEach(t),A6t=r(phe,` load the model weights. It only affects the
model\u2019s configuration. Use `),nce=n(phe,"A",{href:!0});var JLa=s(nce);L6t=r(JLa,"from_pretrained()"),JLa.forEach(t),y6t=r(phe," to load the model weights."),phe.forEach(t),x6t=i(ok),T(py.$$.fragment,ok),ok.forEach(t),$6t=i(md),ct=n(md,"DIV",{class:!0});var cd=s(ct);T($I.$$.fragment,cd),k6t=i(cd),jIe=n(cd,"P",{});var YLa=s(jIe);S6t=r(YLa,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),YLa.forEach(t),R6t=i(cd),is=n(cd,"P",{});var rk=s(is);P6t=r(rk,"The model class to instantiate is selected based on the "),DIe=n(rk,"CODE",{});var ZLa=s(DIe);B6t=r(ZLa,"model_type"),ZLa.forEach(t),I6t=r(rk,` property of the config object (either
passed as an argument or loaded from `),GIe=n(rk,"CODE",{});var KLa=s(GIe);N6t=r(KLa,"pretrained_model_name_or_path"),KLa.forEach(t),q6t=r(rk,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),OIe=n(rk,"CODE",{});var eya=s(OIe);j6t=r(eya,"pretrained_model_name_or_path"),eya.forEach(t),D6t=r(rk,":"),rk.forEach(t),G6t=i(cd),Pe=n(cd,"UL",{});var Ve=s(Pe);_y=n(Ve,"LI",{});var rlo=s(_y);VIe=n(rlo,"STRONG",{});var oya=s(VIe);O6t=r(oya,"bart"),oya.forEach(t),V6t=r(rlo," \u2014 "),sce=n(rlo,"A",{href:!0});var rya=s(sce);X6t=r(rya,"FlaxBartForConditionalGeneration"),rya.forEach(t),z6t=r(rlo," (BART model)"),rlo.forEach(t),Q6t=i(Ve),by=n(Ve,"LI",{});var tlo=s(by);XIe=n(tlo,"STRONG",{});var tya=s(XIe);W6t=r(tya,"blenderbot"),tya.forEach(t),U6t=r(tlo," \u2014 "),lce=n(tlo,"A",{href:!0});var aya=s(lce);H6t=r(aya,"FlaxBlenderbotForConditionalGeneration"),aya.forEach(t),J6t=r(tlo," (Blenderbot model)"),tlo.forEach(t),Y6t=i(Ve),vy=n(Ve,"LI",{});var alo=s(vy);zIe=n(alo,"STRONG",{});var nya=s(zIe);Z6t=r(nya,"blenderbot-small"),nya.forEach(t),K6t=r(alo," \u2014 "),ice=n(alo,"A",{href:!0});var sya=s(ice);e7t=r(sya,"FlaxBlenderbotSmallForConditionalGeneration"),sya.forEach(t),o7t=r(alo," (BlenderbotSmall model)"),alo.forEach(t),r7t=i(Ve),Fy=n(Ve,"LI",{});var nlo=s(Fy);QIe=n(nlo,"STRONG",{});var lya=s(QIe);t7t=r(lya,"encoder-decoder"),lya.forEach(t),a7t=r(nlo," \u2014 "),dce=n(nlo,"A",{href:!0});var iya=s(dce);n7t=r(iya,"FlaxEncoderDecoderModel"),iya.forEach(t),s7t=r(nlo," (Encoder decoder model)"),nlo.forEach(t),l7t=i(Ve),Ty=n(Ve,"LI",{});var slo=s(Ty);WIe=n(slo,"STRONG",{});var dya=s(WIe);i7t=r(dya,"longt5"),dya.forEach(t),d7t=r(slo," \u2014 "),mce=n(slo,"A",{href:!0});var mya=s(mce);m7t=r(mya,"FlaxLongT5ForConditionalGeneration"),mya.forEach(t),c7t=r(slo," (LongT5 model)"),slo.forEach(t),f7t=i(Ve),My=n(Ve,"LI",{});var llo=s(My);UIe=n(llo,"STRONG",{});var cya=s(UIe);g7t=r(cya,"marian"),cya.forEach(t),h7t=r(llo," \u2014 "),cce=n(llo,"A",{href:!0});var fya=s(cce);u7t=r(fya,"FlaxMarianMTModel"),fya.forEach(t),p7t=r(llo," (Marian model)"),llo.forEach(t),_7t=i(Ve),Ey=n(Ve,"LI",{});var ilo=s(Ey);HIe=n(ilo,"STRONG",{});var gya=s(HIe);b7t=r(gya,"mbart"),gya.forEach(t),v7t=r(ilo," \u2014 "),fce=n(ilo,"A",{href:!0});var hya=s(fce);F7t=r(hya,"FlaxMBartForConditionalGeneration"),hya.forEach(t),T7t=r(ilo," (mBART model)"),ilo.forEach(t),M7t=i(Ve),Cy=n(Ve,"LI",{});var dlo=s(Cy);JIe=n(dlo,"STRONG",{});var uya=s(JIe);E7t=r(uya,"mt5"),uya.forEach(t),C7t=r(dlo," \u2014 "),gce=n(dlo,"A",{href:!0});var pya=s(gce);w7t=r(pya,"FlaxMT5ForConditionalGeneration"),pya.forEach(t),A7t=r(dlo," (MT5 model)"),dlo.forEach(t),L7t=i(Ve),wy=n(Ve,"LI",{});var mlo=s(wy);YIe=n(mlo,"STRONG",{});var _ya=s(YIe);y7t=r(_ya,"pegasus"),_ya.forEach(t),x7t=r(mlo," \u2014 "),hce=n(mlo,"A",{href:!0});var bya=s(hce);$7t=r(bya,"FlaxPegasusForConditionalGeneration"),bya.forEach(t),k7t=r(mlo," (Pegasus model)"),mlo.forEach(t),S7t=i(Ve),Ay=n(Ve,"LI",{});var clo=s(Ay);ZIe=n(clo,"STRONG",{});var vya=s(ZIe);R7t=r(vya,"t5"),vya.forEach(t),P7t=r(clo," \u2014 "),uce=n(clo,"A",{href:!0});var Fya=s(uce);B7t=r(Fya,"FlaxT5ForConditionalGeneration"),Fya.forEach(t),I7t=r(clo," (T5 model)"),clo.forEach(t),Ve.forEach(t),N7t=i(cd),T(Ly.$$.fragment,cd),cd.forEach(t),md.forEach(t),tmo=i(c),$f=n(c,"H2",{class:!0});var yfo=s($f);yy=n(yfo,"A",{id:!0,class:!0,href:!0});var Tya=s(yy);KIe=n(Tya,"SPAN",{});var Mya=s(KIe);T(kI.$$.fragment,Mya),Mya.forEach(t),Tya.forEach(t),q7t=i(yfo),eNe=n(yfo,"SPAN",{});var Eya=s(eNe);j7t=r(Eya,"FlaxAutoModelForSequenceClassification"),Eya.forEach(t),yfo.forEach(t),amo=i(c),Ir=n(c,"DIV",{class:!0});var fd=s(Ir);T(SI.$$.fragment,fd),D7t=i(fd),kf=n(fd,"P",{});var _he=s(kf);G7t=r(_he,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),pce=n(_he,"A",{href:!0});var Cya=s(pce);O7t=r(Cya,"from_pretrained()"),Cya.forEach(t),V7t=r(_he," class method or the "),_ce=n(_he,"A",{href:!0});var wya=s(_ce);X7t=r(wya,"from_config()"),wya.forEach(t),z7t=r(_he,` class
method.`),_he.forEach(t),Q7t=i(fd),RI=n(fd,"P",{});var xfo=s(RI);W7t=r(xfo,"This class cannot be instantiated directly using "),oNe=n(xfo,"CODE",{});var Aya=s(oNe);U7t=r(Aya,"__init__()"),Aya.forEach(t),H7t=r(xfo," (throws an error)."),xfo.forEach(t),J7t=i(fd),Ma=n(fd,"DIV",{class:!0});var tk=s(Ma);T(PI.$$.fragment,tk),Y7t=i(tk),rNe=n(tk,"P",{});var Lya=s(rNe);Z7t=r(Lya,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),Lya.forEach(t),K7t=i(tk),Sf=n(tk,"P",{});var bhe=s(Sf);e8t=r(bhe,`Note:
Loading a model from its configuration file does `),tNe=n(bhe,"STRONG",{});var yya=s(tNe);o8t=r(yya,"not"),yya.forEach(t),r8t=r(bhe,` load the model weights. It only affects the
model\u2019s configuration. Use `),bce=n(bhe,"A",{href:!0});var xya=s(bce);t8t=r(xya,"from_pretrained()"),xya.forEach(t),a8t=r(bhe," to load the model weights."),bhe.forEach(t),n8t=i(tk),T(xy.$$.fragment,tk),tk.forEach(t),s8t=i(fd),ft=n(fd,"DIV",{class:!0});var gd=s(ft);T(BI.$$.fragment,gd),l8t=i(gd),aNe=n(gd,"P",{});var $ya=s(aNe);i8t=r($ya,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),$ya.forEach(t),d8t=i(gd),ds=n(gd,"P",{});var ak=s(ds);m8t=r(ak,"The model class to instantiate is selected based on the "),nNe=n(ak,"CODE",{});var kya=s(nNe);c8t=r(kya,"model_type"),kya.forEach(t),f8t=r(ak,` property of the config object (either
passed as an argument or loaded from `),sNe=n(ak,"CODE",{});var Sya=s(sNe);g8t=r(Sya,"pretrained_model_name_or_path"),Sya.forEach(t),h8t=r(ak,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lNe=n(ak,"CODE",{});var Rya=s(lNe);u8t=r(Rya,"pretrained_model_name_or_path"),Rya.forEach(t),p8t=r(ak,":"),ak.forEach(t),_8t=i(gd),Be=n(gd,"UL",{});var Xe=s(Be);$y=n(Xe,"LI",{});var flo=s($y);iNe=n(flo,"STRONG",{});var Pya=s(iNe);b8t=r(Pya,"albert"),Pya.forEach(t),v8t=r(flo," \u2014 "),vce=n(flo,"A",{href:!0});var Bya=s(vce);F8t=r(Bya,"FlaxAlbertForSequenceClassification"),Bya.forEach(t),T8t=r(flo," (ALBERT model)"),flo.forEach(t),M8t=i(Xe),ky=n(Xe,"LI",{});var glo=s(ky);dNe=n(glo,"STRONG",{});var Iya=s(dNe);E8t=r(Iya,"bart"),Iya.forEach(t),C8t=r(glo," \u2014 "),Fce=n(glo,"A",{href:!0});var Nya=s(Fce);w8t=r(Nya,"FlaxBartForSequenceClassification"),Nya.forEach(t),A8t=r(glo," (BART model)"),glo.forEach(t),L8t=i(Xe),Sy=n(Xe,"LI",{});var hlo=s(Sy);mNe=n(hlo,"STRONG",{});var qya=s(mNe);y8t=r(qya,"bert"),qya.forEach(t),x8t=r(hlo," \u2014 "),Tce=n(hlo,"A",{href:!0});var jya=s(Tce);$8t=r(jya,"FlaxBertForSequenceClassification"),jya.forEach(t),k8t=r(hlo," (BERT model)"),hlo.forEach(t),S8t=i(Xe),Ry=n(Xe,"LI",{});var ulo=s(Ry);cNe=n(ulo,"STRONG",{});var Dya=s(cNe);R8t=r(Dya,"big_bird"),Dya.forEach(t),P8t=r(ulo," \u2014 "),Mce=n(ulo,"A",{href:!0});var Gya=s(Mce);B8t=r(Gya,"FlaxBigBirdForSequenceClassification"),Gya.forEach(t),I8t=r(ulo," (BigBird model)"),ulo.forEach(t),N8t=i(Xe),Py=n(Xe,"LI",{});var plo=s(Py);fNe=n(plo,"STRONG",{});var Oya=s(fNe);q8t=r(Oya,"distilbert"),Oya.forEach(t),j8t=r(plo," \u2014 "),Ece=n(plo,"A",{href:!0});var Vya=s(Ece);D8t=r(Vya,"FlaxDistilBertForSequenceClassification"),Vya.forEach(t),G8t=r(plo," (DistilBERT model)"),plo.forEach(t),O8t=i(Xe),By=n(Xe,"LI",{});var _lo=s(By);gNe=n(_lo,"STRONG",{});var Xya=s(gNe);V8t=r(Xya,"electra"),Xya.forEach(t),X8t=r(_lo," \u2014 "),Cce=n(_lo,"A",{href:!0});var zya=s(Cce);z8t=r(zya,"FlaxElectraForSequenceClassification"),zya.forEach(t),Q8t=r(_lo," (ELECTRA model)"),_lo.forEach(t),W8t=i(Xe),Iy=n(Xe,"LI",{});var blo=s(Iy);hNe=n(blo,"STRONG",{});var Qya=s(hNe);U8t=r(Qya,"mbart"),Qya.forEach(t),H8t=r(blo," \u2014 "),wce=n(blo,"A",{href:!0});var Wya=s(wce);J8t=r(Wya,"FlaxMBartForSequenceClassification"),Wya.forEach(t),Y8t=r(blo," (mBART model)"),blo.forEach(t),Z8t=i(Xe),Ny=n(Xe,"LI",{});var vlo=s(Ny);uNe=n(vlo,"STRONG",{});var Uya=s(uNe);K8t=r(Uya,"roberta"),Uya.forEach(t),eLt=r(vlo," \u2014 "),Ace=n(vlo,"A",{href:!0});var Hya=s(Ace);oLt=r(Hya,"FlaxRobertaForSequenceClassification"),Hya.forEach(t),rLt=r(vlo," (RoBERTa model)"),vlo.forEach(t),tLt=i(Xe),qy=n(Xe,"LI",{});var Flo=s(qy);pNe=n(Flo,"STRONG",{});var Jya=s(pNe);aLt=r(Jya,"roformer"),Jya.forEach(t),nLt=r(Flo," \u2014 "),Lce=n(Flo,"A",{href:!0});var Yya=s(Lce);sLt=r(Yya,"FlaxRoFormerForSequenceClassification"),Yya.forEach(t),lLt=r(Flo," (RoFormer model)"),Flo.forEach(t),iLt=i(Xe),jy=n(Xe,"LI",{});var Tlo=s(jy);_Ne=n(Tlo,"STRONG",{});var Zya=s(_Ne);dLt=r(Zya,"xlm-roberta"),Zya.forEach(t),mLt=r(Tlo," \u2014 "),yce=n(Tlo,"A",{href:!0});var Kya=s(yce);cLt=r(Kya,"FlaxXLMRobertaForSequenceClassification"),Kya.forEach(t),fLt=r(Tlo," (XLM-RoBERTa model)"),Tlo.forEach(t),Xe.forEach(t),gLt=i(gd),T(Dy.$$.fragment,gd),gd.forEach(t),fd.forEach(t),nmo=i(c),Rf=n(c,"H2",{class:!0});var $fo=s(Rf);Gy=n($fo,"A",{id:!0,class:!0,href:!0});var e9a=s(Gy);bNe=n(e9a,"SPAN",{});var o9a=s(bNe);T(II.$$.fragment,o9a),o9a.forEach(t),e9a.forEach(t),hLt=i($fo),vNe=n($fo,"SPAN",{});var r9a=s(vNe);uLt=r(r9a,"FlaxAutoModelForQuestionAnswering"),r9a.forEach(t),$fo.forEach(t),smo=i(c),Nr=n(c,"DIV",{class:!0});var hd=s(Nr);T(NI.$$.fragment,hd),pLt=i(hd),Pf=n(hd,"P",{});var vhe=s(Pf);_Lt=r(vhe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),xce=n(vhe,"A",{href:!0});var t9a=s(xce);bLt=r(t9a,"from_pretrained()"),t9a.forEach(t),vLt=r(vhe," class method or the "),$ce=n(vhe,"A",{href:!0});var a9a=s($ce);FLt=r(a9a,"from_config()"),a9a.forEach(t),TLt=r(vhe,` class
method.`),vhe.forEach(t),MLt=i(hd),qI=n(hd,"P",{});var kfo=s(qI);ELt=r(kfo,"This class cannot be instantiated directly using "),FNe=n(kfo,"CODE",{});var n9a=s(FNe);CLt=r(n9a,"__init__()"),n9a.forEach(t),wLt=r(kfo," (throws an error)."),kfo.forEach(t),ALt=i(hd),Ea=n(hd,"DIV",{class:!0});var nk=s(Ea);T(jI.$$.fragment,nk),LLt=i(nk),TNe=n(nk,"P",{});var s9a=s(TNe);yLt=r(s9a,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),s9a.forEach(t),xLt=i(nk),Bf=n(nk,"P",{});var Fhe=s(Bf);$Lt=r(Fhe,`Note:
Loading a model from its configuration file does `),MNe=n(Fhe,"STRONG",{});var l9a=s(MNe);kLt=r(l9a,"not"),l9a.forEach(t),SLt=r(Fhe,` load the model weights. It only affects the
model\u2019s configuration. Use `),kce=n(Fhe,"A",{href:!0});var i9a=s(kce);RLt=r(i9a,"from_pretrained()"),i9a.forEach(t),PLt=r(Fhe," to load the model weights."),Fhe.forEach(t),BLt=i(nk),T(Oy.$$.fragment,nk),nk.forEach(t),ILt=i(hd),gt=n(hd,"DIV",{class:!0});var ud=s(gt);T(DI.$$.fragment,ud),NLt=i(ud),ENe=n(ud,"P",{});var d9a=s(ENe);qLt=r(d9a,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),d9a.forEach(t),jLt=i(ud),ms=n(ud,"P",{});var sk=s(ms);DLt=r(sk,"The model class to instantiate is selected based on the "),CNe=n(sk,"CODE",{});var m9a=s(CNe);GLt=r(m9a,"model_type"),m9a.forEach(t),OLt=r(sk,` property of the config object (either
passed as an argument or loaded from `),wNe=n(sk,"CODE",{});var c9a=s(wNe);VLt=r(c9a,"pretrained_model_name_or_path"),c9a.forEach(t),XLt=r(sk,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ANe=n(sk,"CODE",{});var f9a=s(ANe);zLt=r(f9a,"pretrained_model_name_or_path"),f9a.forEach(t),QLt=r(sk,":"),sk.forEach(t),WLt=i(ud),Ie=n(ud,"UL",{});var ze=s(Ie);Vy=n(ze,"LI",{});var Mlo=s(Vy);LNe=n(Mlo,"STRONG",{});var g9a=s(LNe);ULt=r(g9a,"albert"),g9a.forEach(t),HLt=r(Mlo," \u2014 "),Sce=n(Mlo,"A",{href:!0});var h9a=s(Sce);JLt=r(h9a,"FlaxAlbertForQuestionAnswering"),h9a.forEach(t),YLt=r(Mlo," (ALBERT model)"),Mlo.forEach(t),ZLt=i(ze),Xy=n(ze,"LI",{});var Elo=s(Xy);yNe=n(Elo,"STRONG",{});var u9a=s(yNe);KLt=r(u9a,"bart"),u9a.forEach(t),eyt=r(Elo," \u2014 "),Rce=n(Elo,"A",{href:!0});var p9a=s(Rce);oyt=r(p9a,"FlaxBartForQuestionAnswering"),p9a.forEach(t),ryt=r(Elo," (BART model)"),Elo.forEach(t),tyt=i(ze),zy=n(ze,"LI",{});var Clo=s(zy);xNe=n(Clo,"STRONG",{});var _9a=s(xNe);ayt=r(_9a,"bert"),_9a.forEach(t),nyt=r(Clo," \u2014 "),Pce=n(Clo,"A",{href:!0});var b9a=s(Pce);syt=r(b9a,"FlaxBertForQuestionAnswering"),b9a.forEach(t),lyt=r(Clo," (BERT model)"),Clo.forEach(t),iyt=i(ze),Qy=n(ze,"LI",{});var wlo=s(Qy);$Ne=n(wlo,"STRONG",{});var v9a=s($Ne);dyt=r(v9a,"big_bird"),v9a.forEach(t),myt=r(wlo," \u2014 "),Bce=n(wlo,"A",{href:!0});var F9a=s(Bce);cyt=r(F9a,"FlaxBigBirdForQuestionAnswering"),F9a.forEach(t),fyt=r(wlo," (BigBird model)"),wlo.forEach(t),gyt=i(ze),Wy=n(ze,"LI",{});var Alo=s(Wy);kNe=n(Alo,"STRONG",{});var T9a=s(kNe);hyt=r(T9a,"distilbert"),T9a.forEach(t),uyt=r(Alo," \u2014 "),Ice=n(Alo,"A",{href:!0});var M9a=s(Ice);pyt=r(M9a,"FlaxDistilBertForQuestionAnswering"),M9a.forEach(t),_yt=r(Alo," (DistilBERT model)"),Alo.forEach(t),byt=i(ze),Uy=n(ze,"LI",{});var Llo=s(Uy);SNe=n(Llo,"STRONG",{});var E9a=s(SNe);vyt=r(E9a,"electra"),E9a.forEach(t),Fyt=r(Llo," \u2014 "),Nce=n(Llo,"A",{href:!0});var C9a=s(Nce);Tyt=r(C9a,"FlaxElectraForQuestionAnswering"),C9a.forEach(t),Myt=r(Llo," (ELECTRA model)"),Llo.forEach(t),Eyt=i(ze),Hy=n(ze,"LI",{});var ylo=s(Hy);RNe=n(ylo,"STRONG",{});var w9a=s(RNe);Cyt=r(w9a,"mbart"),w9a.forEach(t),wyt=r(ylo," \u2014 "),qce=n(ylo,"A",{href:!0});var A9a=s(qce);Ayt=r(A9a,"FlaxMBartForQuestionAnswering"),A9a.forEach(t),Lyt=r(ylo," (mBART model)"),ylo.forEach(t),yyt=i(ze),Jy=n(ze,"LI",{});var xlo=s(Jy);PNe=n(xlo,"STRONG",{});var L9a=s(PNe);xyt=r(L9a,"roberta"),L9a.forEach(t),$yt=r(xlo," \u2014 "),jce=n(xlo,"A",{href:!0});var y9a=s(jce);kyt=r(y9a,"FlaxRobertaForQuestionAnswering"),y9a.forEach(t),Syt=r(xlo," (RoBERTa model)"),xlo.forEach(t),Ryt=i(ze),Yy=n(ze,"LI",{});var $lo=s(Yy);BNe=n($lo,"STRONG",{});var x9a=s(BNe);Pyt=r(x9a,"roformer"),x9a.forEach(t),Byt=r($lo," \u2014 "),Dce=n($lo,"A",{href:!0});var $9a=s(Dce);Iyt=r($9a,"FlaxRoFormerForQuestionAnswering"),$9a.forEach(t),Nyt=r($lo," (RoFormer model)"),$lo.forEach(t),qyt=i(ze),Zy=n(ze,"LI",{});var klo=s(Zy);INe=n(klo,"STRONG",{});var k9a=s(INe);jyt=r(k9a,"xlm-roberta"),k9a.forEach(t),Dyt=r(klo," \u2014 "),Gce=n(klo,"A",{href:!0});var S9a=s(Gce);Gyt=r(S9a,"FlaxXLMRobertaForQuestionAnswering"),S9a.forEach(t),Oyt=r(klo," (XLM-RoBERTa model)"),klo.forEach(t),ze.forEach(t),Vyt=i(ud),T(Ky.$$.fragment,ud),ud.forEach(t),hd.forEach(t),lmo=i(c),If=n(c,"H2",{class:!0});var Sfo=s(If);e9=n(Sfo,"A",{id:!0,class:!0,href:!0});var R9a=s(e9);NNe=n(R9a,"SPAN",{});var P9a=s(NNe);T(GI.$$.fragment,P9a),P9a.forEach(t),R9a.forEach(t),Xyt=i(Sfo),qNe=n(Sfo,"SPAN",{});var B9a=s(qNe);zyt=r(B9a,"FlaxAutoModelForTokenClassification"),B9a.forEach(t),Sfo.forEach(t),imo=i(c),qr=n(c,"DIV",{class:!0});var pd=s(qr);T(OI.$$.fragment,pd),Qyt=i(pd),Nf=n(pd,"P",{});var The=s(Nf);Wyt=r(The,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Oce=n(The,"A",{href:!0});var I9a=s(Oce);Uyt=r(I9a,"from_pretrained()"),I9a.forEach(t),Hyt=r(The," class method or the "),Vce=n(The,"A",{href:!0});var N9a=s(Vce);Jyt=r(N9a,"from_config()"),N9a.forEach(t),Yyt=r(The,` class
method.`),The.forEach(t),Zyt=i(pd),VI=n(pd,"P",{});var Rfo=s(VI);Kyt=r(Rfo,"This class cannot be instantiated directly using "),jNe=n(Rfo,"CODE",{});var q9a=s(jNe);e9t=r(q9a,"__init__()"),q9a.forEach(t),o9t=r(Rfo," (throws an error)."),Rfo.forEach(t),r9t=i(pd),Ca=n(pd,"DIV",{class:!0});var lk=s(Ca);T(XI.$$.fragment,lk),t9t=i(lk),DNe=n(lk,"P",{});var j9a=s(DNe);a9t=r(j9a,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),j9a.forEach(t),n9t=i(lk),qf=n(lk,"P",{});var Mhe=s(qf);s9t=r(Mhe,`Note:
Loading a model from its configuration file does `),GNe=n(Mhe,"STRONG",{});var D9a=s(GNe);l9t=r(D9a,"not"),D9a.forEach(t),i9t=r(Mhe,` load the model weights. It only affects the
model\u2019s configuration. Use `),Xce=n(Mhe,"A",{href:!0});var G9a=s(Xce);d9t=r(G9a,"from_pretrained()"),G9a.forEach(t),m9t=r(Mhe," to load the model weights."),Mhe.forEach(t),c9t=i(lk),T(o9.$$.fragment,lk),lk.forEach(t),f9t=i(pd),ht=n(pd,"DIV",{class:!0});var _d=s(ht);T(zI.$$.fragment,_d),g9t=i(_d),ONe=n(_d,"P",{});var O9a=s(ONe);h9t=r(O9a,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),O9a.forEach(t),u9t=i(_d),cs=n(_d,"P",{});var ik=s(cs);p9t=r(ik,"The model class to instantiate is selected based on the "),VNe=n(ik,"CODE",{});var V9a=s(VNe);_9t=r(V9a,"model_type"),V9a.forEach(t),b9t=r(ik,` property of the config object (either
passed as an argument or loaded from `),XNe=n(ik,"CODE",{});var X9a=s(XNe);v9t=r(X9a,"pretrained_model_name_or_path"),X9a.forEach(t),F9t=r(ik,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zNe=n(ik,"CODE",{});var z9a=s(zNe);T9t=r(z9a,"pretrained_model_name_or_path"),z9a.forEach(t),M9t=r(ik,":"),ik.forEach(t),E9t=i(_d),We=n(_d,"UL",{});var So=s(We);r9=n(So,"LI",{});var Slo=s(r9);QNe=n(Slo,"STRONG",{});var Q9a=s(QNe);C9t=r(Q9a,"albert"),Q9a.forEach(t),w9t=r(Slo," \u2014 "),zce=n(Slo,"A",{href:!0});var W9a=s(zce);A9t=r(W9a,"FlaxAlbertForTokenClassification"),W9a.forEach(t),L9t=r(Slo," (ALBERT model)"),Slo.forEach(t),y9t=i(So),t9=n(So,"LI",{});var Rlo=s(t9);WNe=n(Rlo,"STRONG",{});var U9a=s(WNe);x9t=r(U9a,"bert"),U9a.forEach(t),$9t=r(Rlo," \u2014 "),Qce=n(Rlo,"A",{href:!0});var H9a=s(Qce);k9t=r(H9a,"FlaxBertForTokenClassification"),H9a.forEach(t),S9t=r(Rlo," (BERT model)"),Rlo.forEach(t),R9t=i(So),a9=n(So,"LI",{});var Plo=s(a9);UNe=n(Plo,"STRONG",{});var J9a=s(UNe);P9t=r(J9a,"big_bird"),J9a.forEach(t),B9t=r(Plo," \u2014 "),Wce=n(Plo,"A",{href:!0});var Y9a=s(Wce);I9t=r(Y9a,"FlaxBigBirdForTokenClassification"),Y9a.forEach(t),N9t=r(Plo," (BigBird model)"),Plo.forEach(t),q9t=i(So),n9=n(So,"LI",{});var Blo=s(n9);HNe=n(Blo,"STRONG",{});var Z9a=s(HNe);j9t=r(Z9a,"distilbert"),Z9a.forEach(t),D9t=r(Blo," \u2014 "),Uce=n(Blo,"A",{href:!0});var K9a=s(Uce);G9t=r(K9a,"FlaxDistilBertForTokenClassification"),K9a.forEach(t),O9t=r(Blo," (DistilBERT model)"),Blo.forEach(t),V9t=i(So),s9=n(So,"LI",{});var Ilo=s(s9);JNe=n(Ilo,"STRONG",{});var exa=s(JNe);X9t=r(exa,"electra"),exa.forEach(t),z9t=r(Ilo," \u2014 "),Hce=n(Ilo,"A",{href:!0});var oxa=s(Hce);Q9t=r(oxa,"FlaxElectraForTokenClassification"),oxa.forEach(t),W9t=r(Ilo," (ELECTRA model)"),Ilo.forEach(t),U9t=i(So),l9=n(So,"LI",{});var Nlo=s(l9);YNe=n(Nlo,"STRONG",{});var rxa=s(YNe);H9t=r(rxa,"roberta"),rxa.forEach(t),J9t=r(Nlo," \u2014 "),Jce=n(Nlo,"A",{href:!0});var txa=s(Jce);Y9t=r(txa,"FlaxRobertaForTokenClassification"),txa.forEach(t),Z9t=r(Nlo," (RoBERTa model)"),Nlo.forEach(t),K9t=i(So),i9=n(So,"LI",{});var qlo=s(i9);ZNe=n(qlo,"STRONG",{});var axa=s(ZNe);ext=r(axa,"roformer"),axa.forEach(t),oxt=r(qlo," \u2014 "),Yce=n(qlo,"A",{href:!0});var nxa=s(Yce);rxt=r(nxa,"FlaxRoFormerForTokenClassification"),nxa.forEach(t),txt=r(qlo," (RoFormer model)"),qlo.forEach(t),axt=i(So),d9=n(So,"LI",{});var jlo=s(d9);KNe=n(jlo,"STRONG",{});var sxa=s(KNe);nxt=r(sxa,"xlm-roberta"),sxa.forEach(t),sxt=r(jlo," \u2014 "),Zce=n(jlo,"A",{href:!0});var lxa=s(Zce);lxt=r(lxa,"FlaxXLMRobertaForTokenClassification"),lxa.forEach(t),ixt=r(jlo," (XLM-RoBERTa model)"),jlo.forEach(t),So.forEach(t),dxt=i(_d),T(m9.$$.fragment,_d),_d.forEach(t),pd.forEach(t),dmo=i(c),jf=n(c,"H2",{class:!0});var Pfo=s(jf);c9=n(Pfo,"A",{id:!0,class:!0,href:!0});var ixa=s(c9);eqe=n(ixa,"SPAN",{});var dxa=s(eqe);T(QI.$$.fragment,dxa),dxa.forEach(t),ixa.forEach(t),mxt=i(Pfo),oqe=n(Pfo,"SPAN",{});var mxa=s(oqe);cxt=r(mxa,"FlaxAutoModelForMultipleChoice"),mxa.forEach(t),Pfo.forEach(t),mmo=i(c),jr=n(c,"DIV",{class:!0});var bd=s(jr);T(WI.$$.fragment,bd),fxt=i(bd),Df=n(bd,"P",{});var Ehe=s(Df);gxt=r(Ehe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Kce=n(Ehe,"A",{href:!0});var cxa=s(Kce);hxt=r(cxa,"from_pretrained()"),cxa.forEach(t),uxt=r(Ehe," class method or the "),efe=n(Ehe,"A",{href:!0});var fxa=s(efe);pxt=r(fxa,"from_config()"),fxa.forEach(t),_xt=r(Ehe,` class
method.`),Ehe.forEach(t),bxt=i(bd),UI=n(bd,"P",{});var Bfo=s(UI);vxt=r(Bfo,"This class cannot be instantiated directly using "),rqe=n(Bfo,"CODE",{});var gxa=s(rqe);Fxt=r(gxa,"__init__()"),gxa.forEach(t),Txt=r(Bfo," (throws an error)."),Bfo.forEach(t),Mxt=i(bd),wa=n(bd,"DIV",{class:!0});var dk=s(wa);T(HI.$$.fragment,dk),Ext=i(dk),tqe=n(dk,"P",{});var hxa=s(tqe);Cxt=r(hxa,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),hxa.forEach(t),wxt=i(dk),Gf=n(dk,"P",{});var Che=s(Gf);Axt=r(Che,`Note:
Loading a model from its configuration file does `),aqe=n(Che,"STRONG",{});var uxa=s(aqe);Lxt=r(uxa,"not"),uxa.forEach(t),yxt=r(Che,` load the model weights. It only affects the
model\u2019s configuration. Use `),ofe=n(Che,"A",{href:!0});var pxa=s(ofe);xxt=r(pxa,"from_pretrained()"),pxa.forEach(t),$xt=r(Che," to load the model weights."),Che.forEach(t),kxt=i(dk),T(f9.$$.fragment,dk),dk.forEach(t),Sxt=i(bd),ut=n(bd,"DIV",{class:!0});var vd=s(ut);T(JI.$$.fragment,vd),Rxt=i(vd),nqe=n(vd,"P",{});var _xa=s(nqe);Pxt=r(_xa,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),_xa.forEach(t),Bxt=i(vd),fs=n(vd,"P",{});var mk=s(fs);Ixt=r(mk,"The model class to instantiate is selected based on the "),sqe=n(mk,"CODE",{});var bxa=s(sqe);Nxt=r(bxa,"model_type"),bxa.forEach(t),qxt=r(mk,` property of the config object (either
passed as an argument or loaded from `),lqe=n(mk,"CODE",{});var vxa=s(lqe);jxt=r(vxa,"pretrained_model_name_or_path"),vxa.forEach(t),Dxt=r(mk,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iqe=n(mk,"CODE",{});var Fxa=s(iqe);Gxt=r(Fxa,"pretrained_model_name_or_path"),Fxa.forEach(t),Oxt=r(mk,":"),mk.forEach(t),Vxt=i(vd),Ue=n(vd,"UL",{});var Ro=s(Ue);g9=n(Ro,"LI",{});var Dlo=s(g9);dqe=n(Dlo,"STRONG",{});var Txa=s(dqe);Xxt=r(Txa,"albert"),Txa.forEach(t),zxt=r(Dlo," \u2014 "),rfe=n(Dlo,"A",{href:!0});var Mxa=s(rfe);Qxt=r(Mxa,"FlaxAlbertForMultipleChoice"),Mxa.forEach(t),Wxt=r(Dlo," (ALBERT model)"),Dlo.forEach(t),Uxt=i(Ro),h9=n(Ro,"LI",{});var Glo=s(h9);mqe=n(Glo,"STRONG",{});var Exa=s(mqe);Hxt=r(Exa,"bert"),Exa.forEach(t),Jxt=r(Glo," \u2014 "),tfe=n(Glo,"A",{href:!0});var Cxa=s(tfe);Yxt=r(Cxa,"FlaxBertForMultipleChoice"),Cxa.forEach(t),Zxt=r(Glo," (BERT model)"),Glo.forEach(t),Kxt=i(Ro),u9=n(Ro,"LI",{});var Olo=s(u9);cqe=n(Olo,"STRONG",{});var wxa=s(cqe);e$t=r(wxa,"big_bird"),wxa.forEach(t),o$t=r(Olo," \u2014 "),afe=n(Olo,"A",{href:!0});var Axa=s(afe);r$t=r(Axa,"FlaxBigBirdForMultipleChoice"),Axa.forEach(t),t$t=r(Olo," (BigBird model)"),Olo.forEach(t),a$t=i(Ro),p9=n(Ro,"LI",{});var Vlo=s(p9);fqe=n(Vlo,"STRONG",{});var Lxa=s(fqe);n$t=r(Lxa,"distilbert"),Lxa.forEach(t),s$t=r(Vlo," \u2014 "),nfe=n(Vlo,"A",{href:!0});var yxa=s(nfe);l$t=r(yxa,"FlaxDistilBertForMultipleChoice"),yxa.forEach(t),i$t=r(Vlo," (DistilBERT model)"),Vlo.forEach(t),d$t=i(Ro),_9=n(Ro,"LI",{});var Xlo=s(_9);gqe=n(Xlo,"STRONG",{});var xxa=s(gqe);m$t=r(xxa,"electra"),xxa.forEach(t),c$t=r(Xlo," \u2014 "),sfe=n(Xlo,"A",{href:!0});var $xa=s(sfe);f$t=r($xa,"FlaxElectraForMultipleChoice"),$xa.forEach(t),g$t=r(Xlo," (ELECTRA model)"),Xlo.forEach(t),h$t=i(Ro),b9=n(Ro,"LI",{});var zlo=s(b9);hqe=n(zlo,"STRONG",{});var kxa=s(hqe);u$t=r(kxa,"roberta"),kxa.forEach(t),p$t=r(zlo," \u2014 "),lfe=n(zlo,"A",{href:!0});var Sxa=s(lfe);_$t=r(Sxa,"FlaxRobertaForMultipleChoice"),Sxa.forEach(t),b$t=r(zlo," (RoBERTa model)"),zlo.forEach(t),v$t=i(Ro),v9=n(Ro,"LI",{});var Qlo=s(v9);uqe=n(Qlo,"STRONG",{});var Rxa=s(uqe);F$t=r(Rxa,"roformer"),Rxa.forEach(t),T$t=r(Qlo," \u2014 "),ife=n(Qlo,"A",{href:!0});var Pxa=s(ife);M$t=r(Pxa,"FlaxRoFormerForMultipleChoice"),Pxa.forEach(t),E$t=r(Qlo," (RoFormer model)"),Qlo.forEach(t),C$t=i(Ro),F9=n(Ro,"LI",{});var Wlo=s(F9);pqe=n(Wlo,"STRONG",{});var Bxa=s(pqe);w$t=r(Bxa,"xlm-roberta"),Bxa.forEach(t),A$t=r(Wlo," \u2014 "),dfe=n(Wlo,"A",{href:!0});var Ixa=s(dfe);L$t=r(Ixa,"FlaxXLMRobertaForMultipleChoice"),Ixa.forEach(t),y$t=r(Wlo," (XLM-RoBERTa model)"),Wlo.forEach(t),Ro.forEach(t),x$t=i(vd),T(T9.$$.fragment,vd),vd.forEach(t),bd.forEach(t),cmo=i(c),Of=n(c,"H2",{class:!0});var Ifo=s(Of);M9=n(Ifo,"A",{id:!0,class:!0,href:!0});var Nxa=s(M9);_qe=n(Nxa,"SPAN",{});var qxa=s(_qe);T(YI.$$.fragment,qxa),qxa.forEach(t),Nxa.forEach(t),$$t=i(Ifo),bqe=n(Ifo,"SPAN",{});var jxa=s(bqe);k$t=r(jxa,"FlaxAutoModelForNextSentencePrediction"),jxa.forEach(t),Ifo.forEach(t),fmo=i(c),Dr=n(c,"DIV",{class:!0});var Fd=s(Dr);T(ZI.$$.fragment,Fd),S$t=i(Fd),Vf=n(Fd,"P",{});var whe=s(Vf);R$t=r(whe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),mfe=n(whe,"A",{href:!0});var Dxa=s(mfe);P$t=r(Dxa,"from_pretrained()"),Dxa.forEach(t),B$t=r(whe," class method or the "),cfe=n(whe,"A",{href:!0});var Gxa=s(cfe);I$t=r(Gxa,"from_config()"),Gxa.forEach(t),N$t=r(whe,` class
method.`),whe.forEach(t),q$t=i(Fd),KI=n(Fd,"P",{});var Nfo=s(KI);j$t=r(Nfo,"This class cannot be instantiated directly using "),vqe=n(Nfo,"CODE",{});var Oxa=s(vqe);D$t=r(Oxa,"__init__()"),Oxa.forEach(t),G$t=r(Nfo," (throws an error)."),Nfo.forEach(t),O$t=i(Fd),Aa=n(Fd,"DIV",{class:!0});var ck=s(Aa);T(eN.$$.fragment,ck),V$t=i(ck),Fqe=n(ck,"P",{});var Vxa=s(Fqe);X$t=r(Vxa,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Vxa.forEach(t),z$t=i(ck),Xf=n(ck,"P",{});var Ahe=s(Xf);Q$t=r(Ahe,`Note:
Loading a model from its configuration file does `),Tqe=n(Ahe,"STRONG",{});var Xxa=s(Tqe);W$t=r(Xxa,"not"),Xxa.forEach(t),U$t=r(Ahe,` load the model weights. It only affects the
model\u2019s configuration. Use `),ffe=n(Ahe,"A",{href:!0});var zxa=s(ffe);H$t=r(zxa,"from_pretrained()"),zxa.forEach(t),J$t=r(Ahe," to load the model weights."),Ahe.forEach(t),Y$t=i(ck),T(E9.$$.fragment,ck),ck.forEach(t),Z$t=i(Fd),pt=n(Fd,"DIV",{class:!0});var Td=s(pt);T(oN.$$.fragment,Td),K$t=i(Td),Mqe=n(Td,"P",{});var Qxa=s(Mqe);ekt=r(Qxa,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Qxa.forEach(t),okt=i(Td),gs=n(Td,"P",{});var fk=s(gs);rkt=r(fk,"The model class to instantiate is selected based on the "),Eqe=n(fk,"CODE",{});var Wxa=s(Eqe);tkt=r(Wxa,"model_type"),Wxa.forEach(t),akt=r(fk,` property of the config object (either
passed as an argument or loaded from `),Cqe=n(fk,"CODE",{});var Uxa=s(Cqe);nkt=r(Uxa,"pretrained_model_name_or_path"),Uxa.forEach(t),skt=r(fk,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),wqe=n(fk,"CODE",{});var Hxa=s(wqe);lkt=r(Hxa,"pretrained_model_name_or_path"),Hxa.forEach(t),ikt=r(fk,":"),fk.forEach(t),dkt=i(Td),Aqe=n(Td,"UL",{});var Jxa=s(Aqe);C9=n(Jxa,"LI",{});var Ulo=s(C9);Lqe=n(Ulo,"STRONG",{});var Yxa=s(Lqe);mkt=r(Yxa,"bert"),Yxa.forEach(t),ckt=r(Ulo," \u2014 "),gfe=n(Ulo,"A",{href:!0});var Zxa=s(gfe);fkt=r(Zxa,"FlaxBertForNextSentencePrediction"),Zxa.forEach(t),gkt=r(Ulo," (BERT model)"),Ulo.forEach(t),Jxa.forEach(t),hkt=i(Td),T(w9.$$.fragment,Td),Td.forEach(t),Fd.forEach(t),gmo=i(c),zf=n(c,"H2",{class:!0});var qfo=s(zf);A9=n(qfo,"A",{id:!0,class:!0,href:!0});var Kxa=s(A9);yqe=n(Kxa,"SPAN",{});var e$a=s(yqe);T(rN.$$.fragment,e$a),e$a.forEach(t),Kxa.forEach(t),ukt=i(qfo),xqe=n(qfo,"SPAN",{});var o$a=s(xqe);pkt=r(o$a,"FlaxAutoModelForImageClassification"),o$a.forEach(t),qfo.forEach(t),hmo=i(c),Gr=n(c,"DIV",{class:!0});var Md=s(Gr);T(tN.$$.fragment,Md),_kt=i(Md),Qf=n(Md,"P",{});var Lhe=s(Qf);bkt=r(Lhe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),hfe=n(Lhe,"A",{href:!0});var r$a=s(hfe);vkt=r(r$a,"from_pretrained()"),r$a.forEach(t),Fkt=r(Lhe," class method or the "),ufe=n(Lhe,"A",{href:!0});var t$a=s(ufe);Tkt=r(t$a,"from_config()"),t$a.forEach(t),Mkt=r(Lhe,` class
method.`),Lhe.forEach(t),Ekt=i(Md),aN=n(Md,"P",{});var jfo=s(aN);Ckt=r(jfo,"This class cannot be instantiated directly using "),$qe=n(jfo,"CODE",{});var a$a=s($qe);wkt=r(a$a,"__init__()"),a$a.forEach(t),Akt=r(jfo," (throws an error)."),jfo.forEach(t),Lkt=i(Md),La=n(Md,"DIV",{class:!0});var gk=s(La);T(nN.$$.fragment,gk),ykt=i(gk),kqe=n(gk,"P",{});var n$a=s(kqe);xkt=r(n$a,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),n$a.forEach(t),$kt=i(gk),Wf=n(gk,"P",{});var yhe=s(Wf);kkt=r(yhe,`Note:
Loading a model from its configuration file does `),Sqe=n(yhe,"STRONG",{});var s$a=s(Sqe);Skt=r(s$a,"not"),s$a.forEach(t),Rkt=r(yhe,` load the model weights. It only affects the
model\u2019s configuration. Use `),pfe=n(yhe,"A",{href:!0});var l$a=s(pfe);Pkt=r(l$a,"from_pretrained()"),l$a.forEach(t),Bkt=r(yhe," to load the model weights."),yhe.forEach(t),Ikt=i(gk),T(L9.$$.fragment,gk),gk.forEach(t),Nkt=i(Md),_t=n(Md,"DIV",{class:!0});var Ed=s(_t);T(sN.$$.fragment,Ed),qkt=i(Ed),Rqe=n(Ed,"P",{});var i$a=s(Rqe);jkt=r(i$a,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),i$a.forEach(t),Dkt=i(Ed),hs=n(Ed,"P",{});var hk=s(hs);Gkt=r(hk,"The model class to instantiate is selected based on the "),Pqe=n(hk,"CODE",{});var d$a=s(Pqe);Okt=r(d$a,"model_type"),d$a.forEach(t),Vkt=r(hk,` property of the config object (either
passed as an argument or loaded from `),Bqe=n(hk,"CODE",{});var m$a=s(Bqe);Xkt=r(m$a,"pretrained_model_name_or_path"),m$a.forEach(t),zkt=r(hk,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Iqe=n(hk,"CODE",{});var c$a=s(Iqe);Qkt=r(c$a,"pretrained_model_name_or_path"),c$a.forEach(t),Wkt=r(hk,":"),hk.forEach(t),Ukt=i(Ed),lN=n(Ed,"UL",{});var Dfo=s(lN);y9=n(Dfo,"LI",{});var Hlo=s(y9);Nqe=n(Hlo,"STRONG",{});var f$a=s(Nqe);Hkt=r(f$a,"beit"),f$a.forEach(t),Jkt=r(Hlo," \u2014 "),_fe=n(Hlo,"A",{href:!0});var g$a=s(_fe);Ykt=r(g$a,"FlaxBeitForImageClassification"),g$a.forEach(t),Zkt=r(Hlo," (BEiT model)"),Hlo.forEach(t),Kkt=i(Dfo),x9=n(Dfo,"LI",{});var Jlo=s(x9);qqe=n(Jlo,"STRONG",{});var h$a=s(qqe);eSt=r(h$a,"vit"),h$a.forEach(t),oSt=r(Jlo," \u2014 "),bfe=n(Jlo,"A",{href:!0});var u$a=s(bfe);rSt=r(u$a,"FlaxViTForImageClassification"),u$a.forEach(t),tSt=r(Jlo," (ViT model)"),Jlo.forEach(t),Dfo.forEach(t),aSt=i(Ed),T($9.$$.fragment,Ed),Ed.forEach(t),Md.forEach(t),umo=i(c),Uf=n(c,"H2",{class:!0});var Gfo=s(Uf);k9=n(Gfo,"A",{id:!0,class:!0,href:!0});var p$a=s(k9);jqe=n(p$a,"SPAN",{});var _$a=s(jqe);T(iN.$$.fragment,_$a),_$a.forEach(t),p$a.forEach(t),nSt=i(Gfo),Dqe=n(Gfo,"SPAN",{});var b$a=s(Dqe);sSt=r(b$a,"FlaxAutoModelForVision2Seq"),b$a.forEach(t),Gfo.forEach(t),pmo=i(c),Or=n(c,"DIV",{class:!0});var Cd=s(Or);T(dN.$$.fragment,Cd),lSt=i(Cd),Hf=n(Cd,"P",{});var xhe=s(Hf);iSt=r(xhe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),vfe=n(xhe,"A",{href:!0});var v$a=s(vfe);dSt=r(v$a,"from_pretrained()"),v$a.forEach(t),mSt=r(xhe," class method or the "),Ffe=n(xhe,"A",{href:!0});var F$a=s(Ffe);cSt=r(F$a,"from_config()"),F$a.forEach(t),fSt=r(xhe,` class
method.`),xhe.forEach(t),gSt=i(Cd),mN=n(Cd,"P",{});var Ofo=s(mN);hSt=r(Ofo,"This class cannot be instantiated directly using "),Gqe=n(Ofo,"CODE",{});var T$a=s(Gqe);uSt=r(T$a,"__init__()"),T$a.forEach(t),pSt=r(Ofo," (throws an error)."),Ofo.forEach(t),_St=i(Cd),ya=n(Cd,"DIV",{class:!0});var uk=s(ya);T(cN.$$.fragment,uk),bSt=i(uk),Oqe=n(uk,"P",{});var M$a=s(Oqe);vSt=r(M$a,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),M$a.forEach(t),FSt=i(uk),Jf=n(uk,"P",{});var $he=s(Jf);TSt=r($he,`Note:
Loading a model from its configuration file does `),Vqe=n($he,"STRONG",{});var E$a=s(Vqe);MSt=r(E$a,"not"),E$a.forEach(t),ESt=r($he,` load the model weights. It only affects the
model\u2019s configuration. Use `),Tfe=n($he,"A",{href:!0});var C$a=s(Tfe);CSt=r(C$a,"from_pretrained()"),C$a.forEach(t),wSt=r($he," to load the model weights."),$he.forEach(t),ASt=i(uk),T(S9.$$.fragment,uk),uk.forEach(t),LSt=i(Cd),bt=n(Cd,"DIV",{class:!0});var wd=s(bt);T(fN.$$.fragment,wd),ySt=i(wd),Xqe=n(wd,"P",{});var w$a=s(Xqe);xSt=r(w$a,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),w$a.forEach(t),$St=i(wd),us=n(wd,"P",{});var pk=s(us);kSt=r(pk,"The model class to instantiate is selected based on the "),zqe=n(pk,"CODE",{});var A$a=s(zqe);SSt=r(A$a,"model_type"),A$a.forEach(t),RSt=r(pk,` property of the config object (either
passed as an argument or loaded from `),Qqe=n(pk,"CODE",{});var L$a=s(Qqe);PSt=r(L$a,"pretrained_model_name_or_path"),L$a.forEach(t),BSt=r(pk,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wqe=n(pk,"CODE",{});var y$a=s(Wqe);ISt=r(y$a,"pretrained_model_name_or_path"),y$a.forEach(t),NSt=r(pk,":"),pk.forEach(t),qSt=i(wd),Uqe=n(wd,"UL",{});var x$a=s(Uqe);R9=n(x$a,"LI",{});var Ylo=s(R9);Hqe=n(Ylo,"STRONG",{});var $$a=s(Hqe);jSt=r($$a,"vision-encoder-decoder"),$$a.forEach(t),DSt=r(Ylo," \u2014 "),Mfe=n(Ylo,"A",{href:!0});var k$a=s(Mfe);GSt=r(k$a,"FlaxVisionEncoderDecoderModel"),k$a.forEach(t),OSt=r(Ylo," (Vision Encoder decoder model)"),Ylo.forEach(t),x$a.forEach(t),VSt=i(wd),T(P9.$$.fragment,wd),wd.forEach(t),Cd.forEach(t),this.h()},h(){d(g,"name","hf:doc:metadata"),d(g,"content",JSON.stringify(YSa)),d(f,"id","auto-classes"),d(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(f,"href","#auto-classes"),d(u,"class","relative group"),d(_s,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig"),d(vs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoModel"),d(Fs,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer"),d(Sd,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),d(ag,"id","extending-the-auto-classes"),d(ag,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ag,"href","#extending-the-auto-classes"),d(Rd,"class","relative group"),d(sg,"id","transformers.AutoConfig"),d(sg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(sg,"href","#transformers.AutoConfig"),d(Pd,"class","relative group"),d(Wq,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),d(Uq,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertConfig"),d(Hq,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartConfig"),d(Jq,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitConfig"),d(Yq,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertConfig"),d(Zq,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationConfig"),d(Kq,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdConfig"),d(ej,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),d(oj,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotConfig"),d(rj,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),d(tj,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomConfig"),d(aj,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertConfig"),d(nj,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineConfig"),d(sj,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPConfig"),d(lj,"href","/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegConfig"),d(ij,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenConfig"),d(dj,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrConfig"),d(mj,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertConfig"),d(cj,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextConfig"),d(fj,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLConfig"),d(gj,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtConfig"),d(hj,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),d(uj,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextConfig"),d(pj,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),d(_j,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaConfig"),d(bj,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Config"),d(vj,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),d(Fj,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrConfig"),d(Tj,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTConfig"),d(Mj,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrConfig"),d(Ej,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertConfig"),d(Cj,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinConfig"),d(wj,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRConfig"),d(Aj,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTConfig"),d(Lj,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraConfig"),d(yj,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),d(xj,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieConfig"),d($j,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmConfig"),d(kj,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertConfig"),d(Sj,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaConfig"),d(Rj,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetConfig"),d(Pj,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTConfig"),d(Bj,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelConfig"),d(Ij,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNConfig"),d(Nj,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Config"),d(qj,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),d(jj,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),d(Dj,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseConfig"),d(Gj,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJConfig"),d(Oj,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTConfig"),d(Vj,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertConfig"),d(Xj,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertConfig"),d(zj,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTConfig"),d(Qj,"href","/docs/transformers/main/en/model_doc/jukebox#transformers.JukeboxConfig"),d(Wj,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMConfig"),d(Uj,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),d(Hj,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),d(Jj,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDConfig"),d(Yj,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitConfig"),d(Zj,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltConfig"),d(Kj,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerConfig"),d(eD,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Config"),d(oD,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeConfig"),d(rD,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertConfig"),d(tD,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Config"),d(aD,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianConfig"),d(nD,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMConfig"),d(sD,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerConfig"),d(lD,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartConfig"),d(iD,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTConfig"),d(dD,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),d(mD,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertConfig"),d(cD,"href","/docs/transformers/main/en/model_doc/mobilenet_v2#transformers.MobileNetV2Config"),d(fD,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTConfig"),d(gD,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetConfig"),d(hD,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Config"),d(uD,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpConfig"),d(pD,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaConfig"),d(_D,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerConfig"),d(bD,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),d(vD,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTConfig"),d(FD,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTConfig"),d(TD,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusConfig"),d(MD,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXConfig"),d(ED,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverConfig"),d(CD,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartConfig"),d(wD,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerConfig"),d(AD,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetConfig"),d(LD,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertConfig"),d(yD,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagConfig"),d(xD,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmConfig"),d($D,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerConfig"),d(kD,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetConfig"),d(SD,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertConfig"),d(RD,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetConfig"),d(PD,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertConfig"),d(BD,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaConfig"),d(ID,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertConfig"),d(ND,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerConfig"),d(qD,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerConfig"),d(jD,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWConfig"),d(DD,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDConfig"),d(GD,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),d(OD,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),d(VD,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),d(XD,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterConfig"),d(zD,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),d(QD,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinConfig"),d(WD,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Config"),d(UD,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Config"),d(HD,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerConfig"),d(JD,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasConfig"),d(YD,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerConfig"),d(ZD,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),d(KD,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),d(eG,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRConfig"),d(oG,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechConfig"),d(rG,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),d(tG,"href","/docs/transformers/main/en/model_doc/van#transformers.VanConfig"),d(aG,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEConfig"),d(nG,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltConfig"),d(sG,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),d(lG,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),d(iG,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertConfig"),d(dG,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTConfig"),d(mG,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEConfig"),d(cG,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNConfig"),d(fG,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),d(gG,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),d(hG,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMConfig"),d(uG,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperConfig"),d(pG,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPConfig"),d(_G,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMConfig"),d(bG,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMConfig"),d(vG,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),d(FG,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),d(TG,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),d(MG,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetConfig"),d(EG,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosConfig"),d(CG,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoConfig"),d(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ju,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Du,"id","transformers.AutoTokenizer"),d(Du,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Du,"href","#transformers.AutoTokenizer"),d(Id,"class","relative group"),d(wG,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),d(AG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),d(LG,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(yG,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizer"),d(xG,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartTokenizerFast"),d($G,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizer"),d(kG,"href","/docs/transformers/main/en/model_doc/barthez#transformers.BarthezTokenizerFast"),d(SG,"href","/docs/transformers/main/en/model_doc/bartpho#transformers.BartphoTokenizer"),d(RG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(PG,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(BG,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),d(IG,"href","/docs/transformers/main/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),d(NG,"href","/docs/transformers/main/en/model_doc/bertweet#transformers.BertweetTokenizer"),d(qG,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizer"),d(jG,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),d(DG,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(GG,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(OG,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),d(VG,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),d(XG,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),d(zG,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomTokenizerFast"),d(QG,"href","/docs/transformers/main/en/model_doc/byt5#transformers.ByT5Tokenizer"),d(WG,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizer"),d(UG,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertTokenizerFast"),d(HG,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineTokenizer"),d(JG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(YG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(ZG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(KG,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(eO,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizer"),d(oO,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),d(rO,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizer"),d(tO,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),d(aO,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizer"),d(nO,"href","/docs/transformers/main/en/model_doc/cpm#transformers.CpmTokenizerFast"),d(sO,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLTokenizer"),d(lO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),d(iO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(dO,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizer"),d(mO,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaTokenizerFast"),d(cO,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),d(fO,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),d(gO,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizer"),d(hO,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),d(uO,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),d(pO,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),d(_O,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizer"),d(bO,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraTokenizerFast"),d(vO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(FO,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(TO,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmTokenizer"),d(MO,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertTokenizer"),d(EO,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizer"),d(CO,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetTokenizerFast"),d(wO,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTTokenizer"),d(AO,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizer"),d(LO,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelTokenizerFast"),d(yO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(xO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d($O,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(kO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(SO,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),d(RO,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseTokenizer"),d(PO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(BO,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),d(IO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(NO,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(qO,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizer"),d(jO,"href","/docs/transformers/main/en/model_doc/herbert#transformers.HerbertTokenizerFast"),d(DO,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(GO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),d(OO,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(VO,"href","/docs/transformers/main/en/model_doc/jukebox#transformers.JukeboxTokenizer"),d(XO,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),d(zO,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),d(QO,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),d(WO,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),d(UO,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),d(HO,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),d(JO,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),d(YO,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),d(ZO,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizer"),d(KO,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDTokenizerFast"),d(eV,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),d(oV,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),d(rV,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizer"),d(tV,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerTokenizerFast"),d(aV,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),d(nV,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),d(sV,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeTokenizer"),d(lV,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizer"),d(iV,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),d(dV,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),d(mV,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianTokenizer"),d(cV,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizer"),d(fV,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartTokenizerFast"),d(gV,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50Tokenizer"),d(hV,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBart50TokenizerFast"),d(uV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(pV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(_V,"href","/docs/transformers/main/en/model_doc/mluke#transformers.MLukeTokenizer"),d(bV,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),d(vV,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),d(FV,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizer"),d(TV,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),d(MV,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),d(EV,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),d(CV,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizer"),d(wV,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpTokenizerFast"),d(AV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(LV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(yV,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizer"),d(xV,"href","/docs/transformers/main/en/model_doc/nllb#transformers.NllbTokenizerFast"),d($V,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),d(kV,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(SV,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),d(RV,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),d(PV,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Tokenizer"),d(BV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(IV,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(NV,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(qV,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(jV,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizer"),d(DV,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),d(GV,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverTokenizer"),d(OV,"href","/docs/transformers/main/en/model_doc/phobert#transformers.PhobertTokenizer"),d(VV,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartTokenizer"),d(XV,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),d(zV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(QV,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(WV,"href","/docs/transformers/main/en/model_doc/rag#transformers.RagTokenizer"),d(UV,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizer"),d(HV,"href","/docs/transformers/main/en/model_doc/realm#transformers.RealmTokenizerFast"),d(JV,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizer"),d(YV,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerTokenizerFast"),d(ZV,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizer"),d(KV,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertTokenizerFast"),d(eX,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizer"),d(oX,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),d(rX,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizer"),d(tX,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaTokenizerFast"),d(aX,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertTokenizer"),d(nX,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizer"),d(sX,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),d(lX,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),d(iX,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),d(dX,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizer"),d(mX,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterTokenizerFast"),d(cX,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),d(fX,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),d(gX,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5Tokenizer"),d(hX,"href","/docs/transformers/main/en/model_doc/mt5#transformers.T5TokenizerFast"),d(uX,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasTokenizer"),d(pX,"href","/docs/transformers/main/en/model_doc/tapex#transformers.TapexTokenizer"),d(_X,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),d(bX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(vX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(FX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizer"),d(TX,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertTokenizerFast"),d(MX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(EX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),d(CX,"href","/docs/transformers/main/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),d(wX,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperTokenizer"),d(AX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizer"),d(LX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPTokenizerFast"),d(yX,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizer"),d(xX,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMTokenizerFast"),d($X,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMTokenizer"),d(kX,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),d(SX,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),d(RX,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),d(PX,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),d(BX,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),d(IX,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizer"),d(NX,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),d(qX,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizer"),d(jX,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertTokenizerFast"),d(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ap,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Lp,"id","transformers.AutoFeatureExtractor"),d(Lp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Lp,"href","#transformers.AutoFeatureExtractor"),d(Nd,"class","relative group"),d(DX,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),d(GX,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitImageProcessor"),d(OX,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(VX,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(XX,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrFeatureExtractor"),d(zX,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(QX,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(WX,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(UX,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitImageProcessor"),d(HX,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrFeatureExtractor"),d(JX,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTImageProcessor"),d(YX,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),d(ZX,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutFeatureExtractor"),d(KX,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTImageProcessor"),d(ez,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaImageProcessor"),d(oz,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNImageProcessor"),d(rz,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(tz,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(az,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTImageProcessor"),d(nz,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor"),d(sz,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor"),d(lz,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitImageProcessor"),d(iz,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),d(dz,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),d(mz,"href","/docs/transformers/main/en/model_doc/mobilenet_v2#transformers.MobileNetV2ImageProcessor"),d(cz,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTImageProcessor"),d(fz,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),d(gz,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverImageProcessor"),d(hz,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerImageProcessor"),d(uz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(pz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(_z,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerImageProcessor"),d(bz,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),d(vz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(Fz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(Tz,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrFeatureExtractor"),d(Mz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(Ez,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEImageProcessor"),d(Cz,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltImageProcessor"),d(wz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(Az,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(Lz,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(yz,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d(xz,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),d($z,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperFeatureExtractor"),d(kz,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(Sz,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosFeatureExtractor"),d(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(M_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(E_,"id","transformers.AutoImageProcessor"),d(E_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(E_,"href","#transformers.AutoImageProcessor"),d(qd,"class","relative group"),d(Rz,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoImageProcessor.from_pretrained"),d(Pz,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitImageProcessor"),d(Bz,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(Iz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(Nz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(qz,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitImageProcessor"),d(jz,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTImageProcessor"),d(Dz,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTImageProcessor"),d(Gz,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaImageProcessor"),d(Oz,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNImageProcessor"),d(Vz,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(Xz,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTImageProcessor"),d(zz,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ImageProcessor"),d(Qz,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ImageProcessor"),d(Wz,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitImageProcessor"),d(Uz,"href","/docs/transformers/main/en/model_doc/mobilenet_v2#transformers.MobileNetV2ImageProcessor"),d(Hz,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTImageProcessor"),d(Jz,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverImageProcessor"),d(Yz,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerImageProcessor"),d(Zz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(Kz,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(eQ,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerImageProcessor"),d(oQ,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(rQ,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(tQ,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextImageProcessor"),d(aQ,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEImageProcessor"),d(nQ,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltImageProcessor"),d(sQ,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(lQ,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(iQ,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTImageProcessor"),d(dQ,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPImageProcessor"),d(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(r1,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(t1,"id","transformers.AutoProcessor"),d(t1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(t1,"href","#transformers.AutoProcessor"),d(jd,"class","relative group"),d(mQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),d(cQ,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),d(fQ,"href","/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegProcessor"),d(gQ,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaProcessor"),d(hQ,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPProcessor"),d(uQ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),d(pQ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),d(_Q,"href","/docs/transformers/main/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),d(bQ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMProcessor"),d(vQ,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTProcessor"),d(FQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(TQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(MQ,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),d(EQ,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),d(CQ,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRProcessor"),d(wQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(AQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(LQ,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltProcessor"),d(yQ,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),d(xQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d($Q,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(kQ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),d(SQ,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperProcessor"),d(RQ,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPProcessor"),d(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(x1,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($1,"id","transformers.AutoModel"),d($1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d($1,"href","#transformers.AutoModel"),d(Gd,"class","relative group"),d(PQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(BQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(IQ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(NQ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertModel"),d(qQ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartModel"),d(jQ,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitModel"),d(DQ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertModel"),d(GQ,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),d(OQ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdModel"),d(VQ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),d(XQ,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotModel"),d(zQ,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),d(QQ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomModel"),d(WQ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertModel"),d(UQ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineModel"),d(HQ,"href","/docs/transformers/main/en/model_doc/clip#transformers.CLIPModel"),d(JQ,"href","/docs/transformers/main/en/model_doc/clipseg#transformers.CLIPSegModel"),d(YQ,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenModel"),d(ZQ,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrModel"),d(KQ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertModel"),d(eW,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextModel"),d(oW,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLModel"),d(rW,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtModel"),d(tW,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioModel"),d(aW,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextModel"),d(nW,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionModel"),d(sW,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaModel"),d(lW,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2Model"),d(iW,"href","/docs/transformers/main/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),d(dW,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrModel"),d(mW,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTModel"),d(cW,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrModel"),d(fW,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertModel"),d(gW,"href","/docs/transformers/main/en/model_doc/donut#transformers.DonutSwinModel"),d(hW,"href","/docs/transformers/main/en/model_doc/dpr#transformers.DPRQuestionEncoder"),d(uW,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTModel"),d(pW,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraModel"),d(_W,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieModel"),d(bW,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmModel"),d(vW,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertModel"),d(FW,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaModel"),d(TW,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetModel"),d(MW,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTModel"),d(EW,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelModel"),d(CW,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelBaseModel"),d(wW,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNModel"),d(AW,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2Model"),d(LW,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoModel"),d(yW,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),d(xW,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseModel"),d($W,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJModel"),d(kW,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.GroupViTModel"),d(SW,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertModel"),d(RW,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertModel"),d(PW,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTModel"),d(BW,"href","/docs/transformers/main/en/model_doc/jukebox#transformers.JukeboxModel"),d(IW,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMModel"),d(NW,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),d(qW,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),d(jW,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDModel"),d(DW,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitModel"),d(GW,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltModel"),d(OW,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerModel"),d(VW,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5Model"),d(XW,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeModel"),d(zW,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertModel"),d(QW,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),d(WW,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianModel"),d(UW,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMModel"),d(HW,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerModel"),d(JW,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartModel"),d(YW,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTModel"),d(ZW,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertModel"),d(KW,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertModel"),d(eU,"href","/docs/transformers/main/en/model_doc/mobilenet_v2#transformers.MobileNetV2Model"),d(oU,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTModel"),d(rU,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetModel"),d(tU,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5Model"),d(aU,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpModel"),d(nU,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaModel"),d(sU,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100Model"),d(lU,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerModel"),d(iU,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),d(dU,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTModel"),d(mU,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTModel"),d(cU,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusModel"),d(fU,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXModel"),d(gU,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverModel"),d(hU,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartModel"),d(uU,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerModel"),d(pU,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetModel"),d(_U,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertModel"),d(bU,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModel"),d(vU,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetModel"),d(FU,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertModel"),d(TU,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetModel"),d(MU,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),d(EU,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel"),d(CU,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertModel"),d(wU,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerModel"),d(AU,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerModel"),d(LU,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWModel"),d(yU,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDModel"),d(xU,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextModel"),d($U,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterModel"),d(kU,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertModel"),d(SU,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinModel"),d(RU,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2Model"),d(PU,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5Model"),d(BU,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerModel"),d(IU,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasModel"),d(NU,"href","/docs/transformers/main/en/model_doc/time_series_transformer#transformers.TimeSeriesTransformerModel"),d(qU,"href","/docs/transformers/main/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),d(jU,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLModel"),d(DU,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechModel"),d(GU,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),d(OU,"href","/docs/transformers/main/en/model_doc/van#transformers.VanModel"),d(VU,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEModel"),d(XU,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltModel"),d(zU,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),d(QU,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertModel"),d(WU,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTModel"),d(UU,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEModel"),d(HU,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNModel"),d(JU,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),d(YU,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),d(ZU,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMModel"),d(KU,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperModel"),d(eH,"href","/docs/transformers/main/en/model_doc/xclip#transformers.XCLIPModel"),d(oH,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMModel"),d(rH,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMModel"),d(tH,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),d(aH,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),d(nH,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),d(sH,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetModel"),d(lH,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosModel"),d(iH,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoModel"),d(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(av,"id","transformers.AutoModelForPreTraining"),d(av,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(av,"href","#transformers.AutoModelForPreTraining"),d(Xd,"class","relative group"),d(dH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(mH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(cH,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(fH,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForPreTraining"),d(gH,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(hH,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForPreTraining"),d(uH,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),d(pH,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),d(_H,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),d(bH,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),d(vH,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),d(FH,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),d(TH,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),d(MH,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),d(EH,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForPreTraining"),d(CH,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForPreTraining"),d(wH,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),d(AH,"href","/docs/transformers/main/en/model_doc/flava#transformers.FlavaForPreTraining"),d(LH,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForPreTraining"),d(yH,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),d(xH,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForPreTraining"),d($H,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),d(kH,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),d(SH,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),d(RH,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),d(PH,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),d(BH,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForPreTraining"),d(IH,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),d(NH,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),d(qH,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),d(jH,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),d(DH,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForPreTraining"),d(GH,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),d(OH,"href","/docs/transformers/main/en/model_doc/retribert#transformers.RetriBertModel"),d(VH,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),d(XH,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForPreTraining"),d(zH,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForPreTraining"),d(QH,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),d(WH,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),d(UH,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),d(HH,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),d(JH,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),d(YH,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),d(ZH,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),d(KH,"href","/docs/transformers/main/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),d(eJ,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),d(oJ,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),d(rJ,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),d(tJ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(aJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),d(nJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),d(sJ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),d(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(tF,"id","transformers.AutoModelForCausalLM"),d(tF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(tF,"href","#transformers.AutoModelForCausalLM"),d(Wd,"class","relative group"),d(lJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(iJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(dJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(mJ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForCausalLM"),d(cJ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertLMHeadModel"),d(fJ,"href","/docs/transformers/main/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),d(gJ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),d(hJ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),d(uJ,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),d(pJ,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),d(_J,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForCausalLM"),d(bJ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForCausalLM"),d(vJ,"href","/docs/transformers/main/en/model_doc/codegen#transformers.CodeGenForCausalLM"),d(FJ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),d(TJ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),d(MJ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForCausalLM"),d(EJ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForCausalLM"),d(CJ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),d(wJ,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),d(AJ,"href","/docs/transformers/main/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),d(LJ,"href","/docs/transformers/main/en/model_doc/gpt_neox_japanese#transformers.GPTNeoXJapaneseForCausalLM"),d(yJ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForCausalLM"),d(xJ,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianForCausalLM"),d($J,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForCausalLM"),d(kJ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),d(SJ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForCausalLM"),d(RJ,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),d(PJ,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForCausalLM"),d(BJ,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForCausalLM"),d(IJ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForCausalLM"),d(NJ,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),d(qJ,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),d(jJ,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),d(DJ,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForCausalLM"),d(GJ,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForCausalLM"),d(OJ,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForCausalLM"),d(VJ,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForCausalLM"),d(XJ,"href","/docs/transformers/main/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),d(zJ,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),d(QJ,"href","/docs/transformers/main/en/model_doc/trocr#transformers.TrOCRForCausalLM"),d(WJ,"href","/docs/transformers/main/en/model_doc/xglm#transformers.XGLMForCausalLM"),d(UJ,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(HJ,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),d(JJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),d(YJ,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),d(ZJ,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),d(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(JF,"id","transformers.AutoModelForDepthEstimation"),d(JF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(JF,"href","#transformers.AutoModelForDepthEstimation"),d(Jd,"class","relative group"),d(KJ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(eY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(oY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(rY,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForDepthEstimation"),d(tY,"href","/docs/transformers/main/en/model_doc/glpn#transformers.GLPNForDepthEstimation"),d(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(rT,"id","transformers.AutoModelForMaskedLM"),d(rT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(rT,"href","#transformers.AutoModelForMaskedLM"),d(Kd,"class","relative group"),d(aY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(nY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(sY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(lY,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMaskedLM"),d(iY,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(dY,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM"),d(mY,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),d(cY,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMaskedLM"),d(fY,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),d(gY,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),d(hY,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForMaskedLM"),d(uY,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),d(pY,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),d(_Y,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMaskedLM"),d(bY,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMaskedLM"),d(vY,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),d(FY,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMaskedLM"),d(TY,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMaskedLM"),d(MY,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMaskedLM"),d(EY,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),d(CY,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMaskedLM"),d(wY,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMaskedLM"),d(AY,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),d(LY,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),d(yY,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),d(xY,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),d($Y,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),d(kY,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMaskedLM"),d(SY,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),d(RY,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),d(PY,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),d(BY,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForMaskedLM"),d(IY,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMaskedLM"),d(NY,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMaskedLM"),d(qY,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForMaskedLM"),d(jY,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),d(DY,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),d(GY,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForMaskedLM"),d(OY,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),d(VY,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),d(XY,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),d(zY,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMaskedLM"),d(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(QT,"id","transformers.AutoModelForSeq2SeqLM"),d(QT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(QT,"href","#transformers.AutoModelForSeq2SeqLM"),d(rm,"class","relative group"),d(QY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(WY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(UY,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(HY,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForConditionalGeneration"),d(JY,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),d(YY,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),d(ZY,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),d(KY,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),d(eZ,"href","/docs/transformers/main/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),d(oZ,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForConditionalGeneration"),d(rZ,"href","/docs/transformers/main/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),d(tZ,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),d(aZ,"href","/docs/transformers/main/en/model_doc/marian#transformers.MarianMTModel"),d(nZ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),d(sZ,"href","/docs/transformers/main/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),d(lZ,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),d(iZ,"href","/docs/transformers/main/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),d(dZ,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),d(mZ,"href","/docs/transformers/main/en/model_doc/pegasus_x#transformers.PegasusXForConditionalGeneration"),d(cZ,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),d(fZ,"href","/docs/transformers/main/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),d(gZ,"href","/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration"),d(hZ,"href","/docs/transformers/main/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),d(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(pM,"id","transformers.AutoModelForSequenceClassification"),d(pM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(pM,"href","#transformers.AutoModelForSequenceClassification"),d(nm,"class","relative group"),d(uZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(pZ,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(_Z,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(bZ,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForSequenceClassification"),d(vZ,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForSequenceClassification"),d(FZ,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForSequenceClassification"),d(TZ,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),d(MZ,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),d(EZ,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForSequenceClassification"),d(CZ,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),d(wZ,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForSequenceClassification"),d(AZ,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),d(LZ,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),d(yZ,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),d(xZ,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),d($Z,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),d(kZ,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),d(SZ,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForSequenceClassification"),d(RZ,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForSequenceClassification"),d(PZ,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForSequenceClassification"),d(BZ,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),d(IZ,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForSequenceClassification"),d(NZ,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),d(qZ,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),d(jZ,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),d(DZ,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),d(GZ,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForSequenceClassification"),d(OZ,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),d(VZ,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),d(XZ,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),d(zZ,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForSequenceClassification"),d(QZ,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForSequenceClassification"),d(WZ,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),d(UZ,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForSequenceClassification"),d(HZ,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForSequenceClassification"),d(JZ,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForSequenceClassification"),d(YZ,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),d(ZZ,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),d(KZ,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),d(eK,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForSequenceClassification"),d(oK,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),d(rK,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),d(tK,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),d(aK,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForSequenceClassification"),d(nK,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),d(sK,"href","/docs/transformers/main/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),d(lK,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),d(iK,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),d(dK,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),d(mK,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),d(cK,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForSequenceClassification"),d(fK,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),d(gK,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),d(hK,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForSequenceClassification"),d(uK,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),d(pK,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForSequenceClassification"),d(_K,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),d(bK,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),d(vK,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),d(FK,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForSequenceClassification"),d(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(EE,"id","transformers.AutoModelForMultipleChoice"),d(EE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(EE,"href","#transformers.AutoModelForMultipleChoice"),d(im,"class","relative group"),d(TK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(MK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(EK,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(CK,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForMultipleChoice"),d(wK,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForMultipleChoice"),d(AK,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),d(LK,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),d(yK,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForMultipleChoice"),d(xK,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),d($K,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),d(kK,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),d(SK,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),d(RK,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForMultipleChoice"),d(PK,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForMultipleChoice"),d(BK,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),d(IK,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForMultipleChoice"),d(NK,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),d(qK,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForMultipleChoice"),d(jK,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),d(DK,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForMultipleChoice"),d(GK,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),d(OK,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),d(VK,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),d(XK,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),d(zK,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),d(QK,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),d(WK,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),d(UK,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),d(HK,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForMultipleChoice"),d(JK,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),d(YK,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),d(ZK,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForMultipleChoice"),d(KK,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),d(eee,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),d(oee,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),d(ree,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForMultipleChoice"),d(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(s4,"id","transformers.AutoModelForNextSentencePrediction"),d(s4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(s4,"href","#transformers.AutoModelForNextSentencePrediction"),d(cm,"class","relative group"),d(tee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(aee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(nee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(see,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForNextSentencePrediction"),d(lee,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForNextSentencePrediction"),d(iee,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),d(dee,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),d(mee,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),d(cee,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),d(fee,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),d(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(_4,"id","transformers.AutoModelForTokenClassification"),d(_4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(_4,"href","#transformers.AutoModelForTokenClassification"),d(hm,"class","relative group"),d(gee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(hee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(uee,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(pee,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForTokenClassification"),d(_ee,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForTokenClassification"),d(bee,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),d(vee,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForTokenClassification"),d(Fee,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForTokenClassification"),d(Tee,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForTokenClassification"),d(Mee,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),d(Eee,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),d(Cee,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForTokenClassification"),d(wee,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),d(Aee,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),d(Lee,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForTokenClassification"),d(yee,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForTokenClassification"),d(xee,"href","/docs/transformers/main/en/model_doc/esm#transformers.EsmForTokenClassification"),d($ee,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),d(kee,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForTokenClassification"),d(See,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForTokenClassification"),d(Ree,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),d(Pee,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForTokenClassification"),d(Bee,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),d(Iee,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),d(Nee,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),d(qee,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForTokenClassification"),d(jee,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForTokenClassification"),d(Dee,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForTokenClassification"),d(Gee,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForTokenClassification"),d(Oee,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),d(Vee,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),d(Xee,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),d(zee,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForTokenClassification"),d(Qee,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),d(Wee,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),d(Uee,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForTokenClassification"),d(Hee,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForTokenClassification"),d(Jee,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForTokenClassification"),d(Yee,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),d(Zee,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),d(Kee,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForTokenClassification"),d(eoe,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),d(ooe,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),d(roe,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),d(toe,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForTokenClassification"),d(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(dC,"id","transformers.AutoModelForQuestionAnswering"),d(dC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(dC,"href","#transformers.AutoModelForQuestionAnswering"),d(_m,"class","relative group"),d(aoe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(noe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(soe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(loe,"href","/docs/transformers/main/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),d(ioe,"href","/docs/transformers/main/en/model_doc/bart#transformers.BartForQuestionAnswering"),d(doe,"href","/docs/transformers/main/en/model_doc/bert#transformers.BertForQuestionAnswering"),d(moe,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),d(coe,"href","/docs/transformers/main/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),d(foe,"href","/docs/transformers/main/en/model_doc/bloom#transformers.BloomForQuestionAnswering"),d(goe,"href","/docs/transformers/main/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),d(hoe,"href","/docs/transformers/main/en/model_doc/canine#transformers.CanineForQuestionAnswering"),d(uoe,"href","/docs/transformers/main/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),d(poe,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),d(_oe,"href","/docs/transformers/main/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),d(boe,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),d(voe,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),d(Foe,"href","/docs/transformers/main/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),d(Toe,"href","/docs/transformers/main/en/model_doc/ernie#transformers.ErnieForQuestionAnswering"),d(Moe,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),d(Eoe,"href","/docs/transformers/main/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),d(Coe,"href","/docs/transformers/main/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),d(woe,"href","/docs/transformers/main/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),d(Aoe,"href","/docs/transformers/main/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),d(Loe,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),d(yoe,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),d(xoe,"href","/docs/transformers/main/en/model_doc/led#transformers.LEDForQuestionAnswering"),d($oe,"href","/docs/transformers/main/en/model_doc/lilt#transformers.LiltForQuestionAnswering"),d(koe,"href","/docs/transformers/main/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),d(Soe,"href","/docs/transformers/main/en/model_doc/luke#transformers.LukeForQuestionAnswering"),d(Roe,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),d(Poe,"href","/docs/transformers/main/en/model_doc/markuplm#transformers.MarkupLMForQuestionAnswering"),d(Boe,"href","/docs/transformers/main/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),d(Ioe,"href","/docs/transformers/main/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),d(Noe,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),d(qoe,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),d(joe,"href","/docs/transformers/main/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),d(Doe,"href","/docs/transformers/main/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),d(Goe,"href","/docs/transformers/main/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),d(Ooe,"href","/docs/transformers/main/en/model_doc/opt#transformers.OPTForQuestionAnswering"),d(Voe,"href","/docs/transformers/main/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),d(Xoe,"href","/docs/transformers/main/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),d(zoe,"href","/docs/transformers/main/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),d(Qoe,"href","/docs/transformers/main/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),d(Woe,"href","/docs/transformers/main/en/model_doc/roc_bert#transformers.RoCBertForQuestionAnswering"),d(Uoe,"href","/docs/transformers/main/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),d(Hoe,"href","/docs/transformers/main/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),d(Joe,"href","/docs/transformers/main/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),d(Yoe,"href","/docs/transformers/main/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),d(Zoe,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),d(Koe,"href","/docs/transformers/main/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),d(ere,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),d(ore,"href","/docs/transformers/main/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),d(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(i3,"id","transformers.AutoModelForTableQuestionAnswering"),d(i3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(i3,"href","#transformers.AutoModelForTableQuestionAnswering"),d(Fm,"class","relative group"),d(rre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(tre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(are,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(nre,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),d(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(g3,"id","transformers.AutoModelForDocumentQuestionAnswering"),d(g3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(g3,"href","#transformers.AutoModelForDocumentQuestionAnswering"),d(Em,"class","relative group"),d(sre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(lre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(ire,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(dre,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.LayoutLMForQuestionAnswering"),d(mre,"href","/docs/transformers/main/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),d(cre,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),d(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(F3,"id","transformers.AutoModelForImageClassification"),d(F3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(F3,"href","#transformers.AutoModelForImageClassification"),d(Lm,"class","relative group"),d(fre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(gre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(hre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ure,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForImageClassification"),d(pre,"href","/docs/transformers/main/en/model_doc/convnext#transformers.ConvNextForImageClassification"),d(_re,"href","/docs/transformers/main/en/model_doc/cvt#transformers.CvtForImageClassification"),d(bre,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),d(vre,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassification"),d(Fre,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),d(Tre,"href","/docs/transformers/main/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),d(Mre,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassification"),d(Ere,"href","/docs/transformers/main/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),d(Cre,"href","/docs/transformers/main/en/model_doc/mobilenet_v2#transformers.MobileNetV2ForImageClassification"),d(wre,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),d(Are,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),d(Lre,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),d(yre,"href","/docs/transformers/main/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),d(xre,"href","/docs/transformers/main/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),d($re,"href","/docs/transformers/main/en/model_doc/regnet#transformers.RegNetForImageClassification"),d(kre,"href","/docs/transformers/main/en/model_doc/resnet#transformers.ResNetForImageClassification"),d(Sre,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForImageClassification"),d(Rre,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForImageClassification"),d(Pre,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),d(Bre,"href","/docs/transformers/main/en/model_doc/van#transformers.VanForImageClassification"),d(Ire,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForImageClassification"),d(Nre,"href","/docs/transformers/main/en/model_doc/vit_msn#transformers.ViTMSNForImageClassification"),d(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(D3,"id","transformers.AutoModelForVideoClassification"),d(D3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(D3,"href","#transformers.AutoModelForVideoClassification"),d($m,"class","relative group"),d(qre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(jre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Dre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Gre,"href","/docs/transformers/main/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),d(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(z3,"id","transformers.AutoModelForVision2Seq"),d(z3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(z3,"href","#transformers.AutoModelForVision2Seq"),d(Rm,"class","relative group"),d(Ore,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Vre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Xre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(zre,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),d(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(J3,"id","transformers.AutoModelForVisualQuestionAnswering"),d(J3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(J3,"href","#transformers.AutoModelForVisualQuestionAnswering"),d(Im,"class","relative group"),d(Qre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Wre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Ure,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Hre,"href","/docs/transformers/main/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),d(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(o5,"id","transformers.AutoModelForAudioClassification"),d(o5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(o5,"href","#transformers.AutoModelForAudioClassification"),d(jm,"class","relative group"),d(Jre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Yre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Zre,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Kre,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),d(ete,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForSequenceClassification"),d(ote,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForSequenceClassification"),d(rte,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),d(tte,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),d(ate,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),d(nte,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),d(ste,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),d(lte,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),d(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(h5,"id","transformers.AutoModelForAudioFrameClassification"),d(h5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(h5,"href","#transformers.AutoModelForAudioFrameClassification"),d(Om,"class","relative group"),d(ite,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(dte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(mte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(cte,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),d(fte,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),d(gte,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),d(hte,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),d(ute,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),d(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(E5,"id","transformers.AutoModelForCTC"),d(E5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(E5,"href","#transformers.AutoModelForCTC"),d(zm,"class","relative group"),d(pte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_te,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(bte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vte,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),d(Fte,"href","/docs/transformers/main/en/model_doc/hubert#transformers.HubertForCTC"),d(Tte,"href","/docs/transformers/main/en/model_doc/mctct#transformers.MCTCTForCTC"),d(Mte,"href","/docs/transformers/main/en/model_doc/sew#transformers.SEWForCTC"),d(Ete,"href","/docs/transformers/main/en/model_doc/sew-d#transformers.SEWDForCTC"),d(Cte,"href","/docs/transformers/main/en/model_doc/unispeech#transformers.UniSpeechForCTC"),d(wte,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),d(Ate,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),d(Lte,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),d(yte,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForCTC"),d(Eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(N5,"id","transformers.AutoModelForSpeechSeq2Seq"),d(N5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(N5,"href","#transformers.AutoModelForSpeechSeq2Seq"),d(Um,"class","relative group"),d(xte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d($te,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(kte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ste,"href","/docs/transformers/main/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),d(Rte,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),d(Pte,"href","/docs/transformers/main/en/model_doc/whisper#transformers.WhisperForConditionalGeneration"),d(Co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(X5,"id","transformers.AutoModelForAudioXVector"),d(X5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(X5,"href","#transformers.AutoModelForAudioXVector"),d(Zm,"class","relative group"),d(Bte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ite,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Nte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qte,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),d(jte,"href","/docs/transformers/main/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),d(Dte,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),d(Gte,"href","/docs/transformers/main/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),d(Ote,"href","/docs/transformers/main/en/model_doc/wavlm#transformers.WavLMForXVector"),d(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(K5,"id","transformers.AutoModelForMaskedImageModeling"),d(K5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(K5,"href","#transformers.AutoModelForMaskedImageModeling"),d(oc,"class","relative group"),d(Vte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Xte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(zte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Qte,"href","/docs/transformers/main/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),d(Wte,"href","/docs/transformers/main/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),d(Ute,"href","/docs/transformers/main/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),d(Hte,"href","/docs/transformers/main/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),d(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(l0,"id","transformers.AutoModelForObjectDetection"),d(l0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(l0,"href","#transformers.AutoModelForObjectDetection"),d(ac,"class","relative group"),d(Jte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Yte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Zte,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Kte,"href","/docs/transformers/main/en/model_doc/conditional_detr#transformers.ConditionalDetrForObjectDetection"),d(eae,"href","/docs/transformers/main/en/model_doc/deformable_detr#transformers.DeformableDetrForObjectDetection"),d(oae,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection"),d(rae,"href","/docs/transformers/main/en/model_doc/table-transformer#transformers.TableTransformerForObjectDetection"),d(tae,"href","/docs/transformers/main/en/model_doc/yolos#transformers.YolosForObjectDetection"),d(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(p0,"id","transformers.AutoModelForImageSegmentation"),d(p0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(p0,"href","#transformers.AutoModelForImageSegmentation"),d(lc,"class","relative group"),d(aae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(nae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(sae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(lae,"href","/docs/transformers/main/en/model_doc/detr#transformers.DetrForSegmentation"),d(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(T0,"id","transformers.AutoModelForSemanticSegmentation"),d(T0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(T0,"href","#transformers.AutoModelForSemanticSegmentation"),d(mc,"class","relative group"),d(iae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(dae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(mae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(cae,"href","/docs/transformers/main/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),d(fae,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),d(gae,"href","/docs/transformers/main/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),d(hae,"href","/docs/transformers/main/en/model_doc/mobilenet_v2#transformers.MobileNetV2ForSemanticSegmentation"),d(uae,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),d(pae,"href","/docs/transformers/main/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),d(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(k0,"id","transformers.AutoModelForInstanceSegmentation"),d(k0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(k0,"href","#transformers.AutoModelForInstanceSegmentation"),d(gc,"class","relative group"),d(_ae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(bae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(vae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Fae,"href","/docs/transformers/main/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),d($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(I0,"id","transformers.AutoModelForZeroShotObjectDetection"),d(I0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(I0,"href","#transformers.AutoModelForZeroShotObjectDetection"),d(pc,"class","relative group"),d(Tae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Mae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Eae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Cae,"href","/docs/transformers/main/en/model_doc/owlvit#transformers.OwlViTForObjectDetection"),d(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(G0,"id","transformers.TFAutoModel"),d(G0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(G0,"href","#transformers.TFAutoModel"),d(vc,"class","relative group"),d(wae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Aae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Lae,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(yae,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertModel"),d(xae,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartModel"),d($ae,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertModel"),d(kae,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),d(Sae,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),d(Rae,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertModel"),d(Pae,"href","/docs/transformers/main/en/model_doc/clip#transformers.TFCLIPModel"),d(Bae,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertModel"),d(Iae,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextModel"),d(Nae,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLModel"),d(qae,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtModel"),d(jae,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),d(Dae,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaModel"),d(Gae,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),d(Oae,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTModel"),d(Vae,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertModel"),d(Xae,"href","/docs/transformers/main/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),d(zae,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraModel"),d(Qae,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmModel"),d(Wae,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertModel"),d(Uae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelModel"),d(Hae,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelBaseModel"),d(Jae,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2Model"),d(Yae,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJModel"),d(Zae,"href","/docs/transformers/main/en/model_doc/groupvit#transformers.TFGroupViTModel"),d(Kae,"href","/docs/transformers/main/en/model_doc/hubert#transformers.TFHubertModel"),d(ene,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),d(one,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3Model"),d(rne,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDModel"),d(tne,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerModel"),d(ane,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertModel"),d(nne,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianModel"),d(sne,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartModel"),d(lne,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertModel"),d(ine,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTModel"),d(dne,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetModel"),d(mne,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5Model"),d(cne,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),d(fne,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTModel"),d(gne,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusModel"),d(hne,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetModel"),d(une,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertModel"),d(pne,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetModel"),d(_ne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaModel"),d(bne,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerModel"),d(vne,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerModel"),d(Fne,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),d(Tne,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinModel"),d(Mne,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5Model"),d(Ene,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasModel"),d(Cne,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),d(wne,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTModel"),d(Ane,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEModel"),d(Lne,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),d(yne,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperModel"),d(xne,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMModel"),d($ne,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMModel"),d(kne,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),d(Sne,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetModel"),d(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ww,"id","transformers.TFAutoModelForPreTraining"),d(Ww,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Ww,"href","#transformers.TFAutoModelForPreTraining"),d(Mc,"class","relative group"),d(Rne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Pne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Bne,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ine,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForPreTraining"),d(Nne,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),d(qne,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForPreTraining"),d(jne,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),d(Dne,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),d(Gne,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),d(One,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForPreTraining"),d(Vne,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),d(Xne,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),d(zne,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),d(Qne,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),d(Wne,"href","/docs/transformers/main/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),d(Une,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),d(Hne,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),d(Jne,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),d(Yne,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),d(Zne,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),d(Kne,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),d(ese,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),d(ose,"href","/docs/transformers/main/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),d(rse,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(tse,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),d(ase,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),d(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vA,"id","transformers.TFAutoModelForCausalLM"),d(vA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(vA,"href","#transformers.TFAutoModelForCausalLM"),d(wc,"class","relative group"),d(nse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(sse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(lse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ise,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertLMHeadModel"),d(dse,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),d(mse,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),d(cse,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),d(fse,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),d(gse,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),d(hse,"href","/docs/transformers/main/en/model_doc/opt#transformers.TFOPTForCausalLM"),d(use,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),d(pse,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),d(_se,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),d(bse,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),d(vse,"href","/docs/transformers/main/en/model_doc/xglm#transformers.TFXGLMForCausalLM"),d(Fse,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(Tse,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),d(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(IA,"id","transformers.TFAutoModelForImageClassification"),d(IA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(IA,"href","#transformers.TFAutoModelForImageClassification"),d(yc,"class","relative group"),d(Mse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ese,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Cse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(wse,"href","/docs/transformers/main/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),d(Ase,"href","/docs/transformers/main/en/model_doc/cvt#transformers.TFCvtForImageClassification"),d(Lse,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),d(yse,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassification"),d(xse,"href","/docs/transformers/main/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),d($se,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForImageClassification"),d(kse,"href","/docs/transformers/main/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),d(Sse,"href","/docs/transformers/main/en/model_doc/resnet#transformers.TFResNetForImageClassification"),d(Rse,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),d(Pse,"href","/docs/transformers/main/en/model_doc/swin#transformers.TFSwinForImageClassification"),d(Bse,"href","/docs/transformers/main/en/model_doc/vit#transformers.TFViTForImageClassification"),d(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(UA,"id","transformers.TFAutoModelForSemanticSegmentation"),d(UA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(UA,"href","#transformers.TFAutoModelForSemanticSegmentation"),d(kc,"class","relative group"),d(Ise,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Nse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(qse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(jse,"href","/docs/transformers/main/en/model_doc/data2vec#transformers.TFData2VecVisionForSemanticSegmentation"),d(Dse,"href","/docs/transformers/main/en/model_doc/mobilevit#transformers.TFMobileViTForSemanticSegmentation"),d(Gse,"href","/docs/transformers/main/en/model_doc/segformer#transformers.TFSegformerForSemanticSegmentation"),d(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(e6,"id","transformers.TFAutoModelForMaskedLM"),d(e6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(e6,"href","#transformers.TFAutoModelForMaskedLM"),d(Bc,"class","relative group"),d(Ose,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Vse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Xse,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(zse,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),d(Qse,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMaskedLM"),d(Wse,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),d(Use,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),d(Hse,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),d(Jse,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),d(Yse,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),d(Zse,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMaskedLM"),d(Kse,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForMaskedLM"),d(ele,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),d(ole,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),d(rle,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),d(tle,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),d(ale,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),d(nle,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),d(sle,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),d(lle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),d(ile,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),d(dle,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),d(mle,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),d(cle,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),d(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(C6,"id","transformers.TFAutoModelForSeq2SeqLM"),d(C6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(C6,"href","#transformers.TFAutoModelForSeq2SeqLM"),d(qc,"class","relative group"),d(fle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(gle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(hle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ule,"href","/docs/transformers/main/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),d(ple,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),d(_le,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),d(ble,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),d(vle,"href","/docs/transformers/main/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),d(Fle,"href","/docs/transformers/main/en/model_doc/marian#transformers.TFMarianMTModel"),d(Tle,"href","/docs/transformers/main/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),d(Mle,"href","/docs/transformers/main/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),d(Ele,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),d(Cle,"href","/docs/transformers/main/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),d(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(N6,"id","transformers.TFAutoModelForSequenceClassification"),d(N6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(N6,"href","#transformers.TFAutoModelForSequenceClassification"),d(Gc,"class","relative group"),d(wle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ale,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Lle,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ia,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(yle,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),d(xle,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForSequenceClassification"),d($le,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),d(kle,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),d(Sle,"href","/docs/transformers/main/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),d(Rle,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),d(Ple,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),d(Ble,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),d(Ile,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),d(Nle,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForSequenceClassification"),d(qle,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),d(jle,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),d(Dle,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),d(Gle,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),d(Ole,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),d(Vle,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForSequenceClassification"),d(Xle,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),d(zle,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),d(Qle,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),d(Wle,"href","/docs/transformers/main/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),d(Ule,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),d(Hle,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),d(Jle,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),d(Yle,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),d(Zle,"href","/docs/transformers/main/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),d(Kle,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),d(eie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),d(oie,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),d(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(h7,"id","transformers.TFAutoModelForMultipleChoice"),d(h7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(h7,"href","#transformers.TFAutoModelForMultipleChoice"),d(Xc,"class","relative group"),d(rie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(tie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(aie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(da,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(nie,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),d(sie,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForMultipleChoice"),d(lie,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),d(iie,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),d(die,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),d(mie,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),d(cie,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),d(fie,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),d(gie,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),d(hie,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),d(uie,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),d(pie,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),d(_ie,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),d(bie,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),d(vie,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),d(Fie,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),d(Tie,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),d(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(P7,"id","transformers.TFAutoModelForNextSentencePrediction"),d(P7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(P7,"href","#transformers.TFAutoModelForNextSentencePrediction"),d(Wc,"class","relative group"),d(Mie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Eie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Cie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(wie,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),d(Aie,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),d(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(j7,"id","transformers.TFAutoModelForTableQuestionAnswering"),d(j7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(j7,"href","#transformers.TFAutoModelForTableQuestionAnswering"),d(Jc,"class","relative group"),d(Lie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(yie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(xie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($ie,"href","/docs/transformers/main/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),d(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(V7,"id","transformers.TFAutoModelForDocumentQuestionAnswering"),d(V7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(V7,"href","#transformers.TFAutoModelForDocumentQuestionAnswering"),d(Kc,"class","relative group"),d(kie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Sie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Rie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Pie,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForQuestionAnswering"),d(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(W7,"id","transformers.TFAutoModelForTokenClassification"),d(W7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(W7,"href","#transformers.TFAutoModelForTokenClassification"),d(rf,"class","relative group"),d(Bie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Iie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Nie,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ga,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qie,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),d(jie,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForTokenClassification"),d(Die,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),d(Gie,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),d(Oie,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),d(Vie,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),d(Xie,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),d(zie,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForTokenClassification"),d(Qie,"href","/docs/transformers/main/en/model_doc/esm#transformers.TFEsmForTokenClassification"),d(Wie,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),d(Uie,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),d(Hie,"href","/docs/transformers/main/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),d(Jie,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForTokenClassification"),d(Yie,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),d(Zie,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),d(Kie,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),d(ede,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),d(ode,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),d(rde,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),d(tde,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),d(ade,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),d(nde,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),d(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(b8,"id","transformers.TFAutoModelForQuestionAnswering"),d(b8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(b8,"href","#transformers.TFAutoModelForQuestionAnswering"),d(nf,"class","relative group"),d(sde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(lde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(ide,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ha,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(dde,"href","/docs/transformers/main/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),d(mde,"href","/docs/transformers/main/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),d(cde,"href","/docs/transformers/main/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),d(fde,"href","/docs/transformers/main/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),d(gde,"href","/docs/transformers/main/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),d(hde,"href","/docs/transformers/main/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),d(ude,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),d(pde,"href","/docs/transformers/main/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),d(_de,"href","/docs/transformers/main/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),d(bde,"href","/docs/transformers/main/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),d(vde,"href","/docs/transformers/main/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),d(Fde,"href","/docs/transformers/main/en/model_doc/layoutlmv3#transformers.TFLayoutLMv3ForQuestionAnswering"),d(Tde,"href","/docs/transformers/main/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),d(Mde,"href","/docs/transformers/main/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),d(Ede,"href","/docs/transformers/main/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),d(Cde,"href","/docs/transformers/main/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),d(wde,"href","/docs/transformers/main/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),d(Ade,"href","/docs/transformers/main/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),d(Lde,"href","/docs/transformers/main/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),d(yde,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),d(xde,"href","/docs/transformers/main/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),d(at,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(O8,"id","transformers.TFAutoModelForVision2Seq"),d(O8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(O8,"href","#transformers.TFAutoModelForVision2Seq"),d(df,"class","relative group"),d($de,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(kde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Sde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ua,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Rde,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),d(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Q8,"id","transformers.TFAutoModelForSpeechSeq2Seq"),d(Q8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Q8,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),d(ff,"class","relative group"),d(Pde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Bde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Ide,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(pa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Nde,"href","/docs/transformers/main/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),d(qde,"href","/docs/transformers/main/en/model_doc/whisper#transformers.TFWhisperForConditionalGeneration"),d(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Y8,"id","transformers.FlaxAutoModel"),d(Y8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Y8,"href","#transformers.FlaxAutoModel"),d(uf,"class","relative group"),d(jde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Dde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Gde,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_a,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ode,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertModel"),d(Vde,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartModel"),d(Xde,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitModel"),d(zde,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertModel"),d(Qde,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),d(Wde,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),d(Ude,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),d(Hde,"href","/docs/transformers/main/en/model_doc/clip#transformers.FlaxCLIPModel"),d(Jde,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),d(Yde,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraModel"),d(Zde,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2Model"),d(Kde,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),d(eme,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJModel"),d(ome,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5Model"),d(rme,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianModel"),d(tme,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartModel"),d(ame,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5Model"),d(nme,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTModel"),d(sme,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusModel"),d(lme,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaModel"),d(ime,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerModel"),d(dme,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5Model"),d(mme,"href","/docs/transformers/main/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),d(cme,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTModel"),d(fme,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),d(gme,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMModel"),d(hme,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),d(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(LL,"id","transformers.FlaxAutoModelForCausalLM"),d(LL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(LL,"href","#transformers.FlaxAutoModelForCausalLM"),d(bf,"class","relative group"),d(ume,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(pme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(_me,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ba,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(bme,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForCausalLM"),d(vme,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForCausalLM"),d(Fme,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),d(Tme,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),d(Mme,"href","/docs/transformers/main/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),d(Eme,"href","/docs/transformers/main/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),d(Cme,"href","/docs/transformers/main/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),d(wme,"href","/docs/transformers/main/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),d(Ame,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),d(Lme,"href","/docs/transformers/main/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),d(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(DL,"id","transformers.FlaxAutoModelForPreTraining"),d(DL,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(DL,"href","#transformers.FlaxAutoModelForPreTraining"),d(Tf,"class","relative group"),d(yme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(xme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d($me,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(va,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(kme,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),d(Sme,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(Rme,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForPreTraining"),d(Pme,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),d(Bme,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),d(Ime,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),d(Nme,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(qme,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),d(jme,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),d(Dme,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),d(Gme,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),d(Ome,"href","/docs/transformers/main/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),d(Vme,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),d(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(ry,"id","transformers.FlaxAutoModelForMaskedLM"),d(ry,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(ry,"href","#transformers.FlaxAutoModelForMaskedLM"),d(Cf,"class","relative group"),d(Xme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(zme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Qme,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Fa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Wme,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),d(Ume,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(Hme,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),d(Jme,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),d(Yme,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),d(Zme,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),d(Kme,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(ece,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),d(oce,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),d(rce,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),d(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(uy,"id","transformers.FlaxAutoModelForSeq2SeqLM"),d(uy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(uy,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),d(Lf,"class","relative group"),d(tce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ace,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(nce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(sce,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),d(lce,"href","/docs/transformers/main/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),d(ice,"href","/docs/transformers/main/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),d(dce,"href","/docs/transformers/main/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),d(mce,"href","/docs/transformers/main/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),d(cce,"href","/docs/transformers/main/en/model_doc/marian#transformers.FlaxMarianMTModel"),d(fce,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),d(gce,"href","/docs/transformers/main/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),d(hce,"href","/docs/transformers/main/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),d(uce,"href","/docs/transformers/main/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),d(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(yy,"id","transformers.FlaxAutoModelForSequenceClassification"),d(yy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(yy,"href","#transformers.FlaxAutoModelForSequenceClassification"),d($f,"class","relative group"),d(pce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(_ce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(bce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ma,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(vce,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),d(Fce,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),d(Tce,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),d(Mce,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),d(Ece,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),d(Cce,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),d(wce,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),d(Ace,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),d(Lce,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),d(yce,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),d(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Gy,"id","transformers.FlaxAutoModelForQuestionAnswering"),d(Gy,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(Gy,"href","#transformers.FlaxAutoModelForQuestionAnswering"),d(Rf,"class","relative group"),d(xce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d($ce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(kce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Sce,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),d(Rce,"href","/docs/transformers/main/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),d(Pce,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),d(Bce,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),d(Ice,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),d(Nce,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),d(qce,"href","/docs/transformers/main/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),d(jce,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),d(Dce,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),d(Gce,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),d(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(e9,"id","transformers.FlaxAutoModelForTokenClassification"),d(e9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(e9,"href","#transformers.FlaxAutoModelForTokenClassification"),d(If,"class","relative group"),d(Oce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Vce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Xce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ca,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(zce,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),d(Qce,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),d(Wce,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),d(Uce,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),d(Hce,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),d(Jce,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),d(Yce,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),d(Zce,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),d(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(c9,"id","transformers.FlaxAutoModelForMultipleChoice"),d(c9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(c9,"href","#transformers.FlaxAutoModelForMultipleChoice"),d(jf,"class","relative group"),d(Kce,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(efe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(ofe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(wa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(rfe,"href","/docs/transformers/main/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),d(tfe,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),d(afe,"href","/docs/transformers/main/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),d(nfe,"href","/docs/transformers/main/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),d(sfe,"href","/docs/transformers/main/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),d(lfe,"href","/docs/transformers/main/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),d(ife,"href","/docs/transformers/main/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),d(dfe,"href","/docs/transformers/main/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),d(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(M9,"id","transformers.FlaxAutoModelForNextSentencePrediction"),d(M9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(M9,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),d(Of,"class","relative group"),d(mfe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(cfe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(ffe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(gfe,"href","/docs/transformers/main/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),d(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(A9,"id","transformers.FlaxAutoModelForImageClassification"),d(A9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(A9,"href","#transformers.FlaxAutoModelForImageClassification"),d(zf,"class","relative group"),d(hfe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ufe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(pfe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(La,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(_fe,"href","/docs/transformers/main/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),d(bfe,"href","/docs/transformers/main/en/model_doc/vit#transformers.FlaxViTForImageClassification"),d(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(k9,"id","transformers.FlaxAutoModelForVision2Seq"),d(k9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(k9,"href","#transformers.FlaxAutoModelForVision2Seq"),d(Uf,"class","relative group"),d(vfe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(Ffe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),d(Tfe,"href","/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),d(ya,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Mfe,"href","/docs/transformers/main/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),d(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(c,_){e(document.head,g),b(c,v,_),b(c,u,_),e(u,f),e(f,p),M(m,p,null),e(u,h),e(u,He),e(He,Ad),b(c,eg,_),b(c,wt,_),e(wt,Ld),e(wt,yd),e(yd,_k),e(wt,og),b(c,Qe,_),b(c,Ze,_),e(Ze,xd),e(Ze,_s),e(_s,bk),e(Ze,bs),e(Ze,vs),e(vs,vk),e(Ze,$d),e(Ze,Fs),e(Fs,Fk),e(Ze,kd),b(c,rg,_),M(ln,c,_),b(c,Ke,_),b(c,ye,_),e(ye,Gq),e(ye,Sd),e(Sd,Oq),e(ye,Vq),b(c,Po,_),b(c,dn,_),e(dn,Xq),e(dn,tg),e(tg,zq),e(dn,Xfo),b(c,Zlo,_),b(c,Rd,_),e(Rd,ag),e(ag,khe),M(Tk,khe,null),e(Rd,zfo),e(Rd,She),e(She,Qfo),b(c,Klo,_),b(c,Ts,_),e(Ts,Wfo),e(Ts,Rhe),e(Rhe,Ufo),e(Ts,Hfo),e(Ts,Phe),e(Phe,Jfo),e(Ts,Yfo),b(c,eio,_),M(Mk,c,_),b(c,oio,_),b(c,Qq,_),e(Qq,Zfo),b(c,rio,_),M(ng,c,_),b(c,tio,_),b(c,Pd,_),e(Pd,sg),e(sg,Bhe),M(Ek,Bhe,null),e(Pd,Kfo),e(Pd,Ihe),e(Ihe,ego),b(c,aio,_),b(c,Bo,_),M(Ck,Bo,null),e(Bo,ogo),e(Bo,wk),e(wk,rgo),e(wk,Wq),e(Wq,tgo),e(wk,ago),e(Bo,ngo),e(Bo,Ak),e(Ak,sgo),e(Ak,Nhe),e(Nhe,lgo),e(Ak,igo),e(Bo,dgo),e(Bo,Vr),M(Lk,Vr,null),e(Vr,mgo),e(Vr,qhe),e(qhe,cgo),e(Vr,fgo),e(Vr,Bd),e(Bd,ggo),e(Bd,jhe),e(jhe,hgo),e(Bd,ugo),e(Bd,Dhe),e(Dhe,pgo),e(Bd,_go),e(Vr,bgo),e(Vr,A),e(A,lg),e(lg,Ghe),e(Ghe,vgo),e(lg,Fgo),e(lg,Uq),e(Uq,Tgo),e(lg,Mgo),e(A,Ego),e(A,ig),e(ig,Ohe),e(Ohe,Cgo),e(ig,wgo),e(ig,Hq),e(Hq,Ago),e(ig,Lgo),e(A,ygo),e(A,dg),e(dg,Vhe),e(Vhe,xgo),e(dg,$go),e(dg,Jq),e(Jq,kgo),e(dg,Sgo),e(A,Rgo),e(A,mg),e(mg,Xhe),e(Xhe,Pgo),e(mg,Bgo),e(mg,Yq),e(Yq,Igo),e(mg,Ngo),e(A,qgo),e(A,cg),e(cg,zhe),e(zhe,jgo),e(cg,Dgo),e(cg,Zq),e(Zq,Ggo),e(cg,Ogo),e(A,Vgo),e(A,fg),e(fg,Qhe),e(Qhe,Xgo),e(fg,zgo),e(fg,Kq),e(Kq,Qgo),e(fg,Wgo),e(A,Ugo),e(A,gg),e(gg,Whe),e(Whe,Hgo),e(gg,Jgo),e(gg,ej),e(ej,Ygo),e(gg,Zgo),e(A,Kgo),e(A,hg),e(hg,Uhe),e(Uhe,eho),e(hg,oho),e(hg,oj),e(oj,rho),e(hg,tho),e(A,aho),e(A,ug),e(ug,Hhe),e(Hhe,nho),e(ug,sho),e(ug,rj),e(rj,lho),e(ug,iho),e(A,dho),e(A,pg),e(pg,Jhe),e(Jhe,mho),e(pg,cho),e(pg,tj),e(tj,fho),e(pg,gho),e(A,hho),e(A,_g),e(_g,Yhe),e(Yhe,uho),e(_g,pho),e(_g,aj),e(aj,_ho),e(_g,bho),e(A,vho),e(A,bg),e(bg,Zhe),e(Zhe,Fho),e(bg,Tho),e(bg,nj),e(nj,Mho),e(bg,Eho),e(A,Cho),e(A,vg),e(vg,Khe),e(Khe,who),e(vg,Aho),e(vg,sj),e(sj,Lho),e(vg,yho),e(A,xho),e(A,Fg),e(Fg,eue),e(eue,$ho),e(Fg,kho),e(Fg,lj),e(lj,Sho),e(Fg,Rho),e(A,Pho),e(A,Tg),e(Tg,oue),e(oue,Bho),e(Tg,Iho),e(Tg,ij),e(ij,Nho),e(Tg,qho),e(A,jho),e(A,Mg),e(Mg,rue),e(rue,Dho),e(Mg,Gho),e(Mg,dj),e(dj,Oho),e(Mg,Vho),e(A,Xho),e(A,Eg),e(Eg,tue),e(tue,zho),e(Eg,Qho),e(Eg,mj),e(mj,Who),e(Eg,Uho),e(A,Hho),e(A,Cg),e(Cg,aue),e(aue,Jho),e(Cg,Yho),e(Cg,cj),e(cj,Zho),e(Cg,Kho),e(A,euo),e(A,wg),e(wg,nue),e(nue,ouo),e(wg,ruo),e(wg,fj),e(fj,tuo),e(wg,auo),e(A,nuo),e(A,Ag),e(Ag,sue),e(sue,suo),e(Ag,luo),e(Ag,gj),e(gj,iuo),e(Ag,duo),e(A,muo),e(A,Lg),e(Lg,lue),e(lue,cuo),e(Lg,fuo),e(Lg,hj),e(hj,guo),e(Lg,huo),e(A,uuo),e(A,yg),e(yg,iue),e(iue,puo),e(yg,_uo),e(yg,uj),e(uj,buo),e(yg,vuo),e(A,Fuo),e(A,xg),e(xg,due),e(due,Tuo),e(xg,Muo),e(xg,pj),e(pj,Euo),e(xg,Cuo),e(A,wuo),e(A,$g),e($g,mue),e(mue,Auo),e($g,Luo),e($g,_j),e(_j,yuo),e($g,xuo),e(A,$uo),e(A,kg),e(kg,cue),e(cue,kuo),e(kg,Suo),e(kg,bj),e(bj,Ruo),e(kg,Puo),e(A,Buo),e(A,Sg),e(Sg,fue),e(fue,Iuo),e(Sg,Nuo),e(Sg,vj),e(vj,quo),e(Sg,juo),e(A,Duo),e(A,Rg),e(Rg,gue),e(gue,Guo),e(Rg,Ouo),e(Rg,Fj),e(Fj,Vuo),e(Rg,Xuo),e(A,zuo),e(A,Pg),e(Pg,hue),e(hue,Quo),e(Pg,Wuo),e(Pg,Tj),e(Tj,Uuo),e(Pg,Huo),e(A,Juo),e(A,Bg),e(Bg,uue),e(uue,Yuo),e(Bg,Zuo),e(Bg,Mj),e(Mj,Kuo),e(Bg,epo),e(A,opo),e(A,Ig),e(Ig,pue),e(pue,rpo),e(Ig,tpo),e(Ig,Ej),e(Ej,apo),e(Ig,npo),e(A,spo),e(A,Ng),e(Ng,_ue),e(_ue,lpo),e(Ng,ipo),e(Ng,Cj),e(Cj,dpo),e(Ng,mpo),e(A,cpo),e(A,qg),e(qg,bue),e(bue,fpo),e(qg,gpo),e(qg,wj),e(wj,hpo),e(qg,upo),e(A,ppo),e(A,jg),e(jg,vue),e(vue,_po),e(jg,bpo),e(jg,Aj),e(Aj,vpo),e(jg,Fpo),e(A,Tpo),e(A,Dg),e(Dg,Fue),e(Fue,Mpo),e(Dg,Epo),e(Dg,Lj),e(Lj,Cpo),e(Dg,wpo),e(A,Apo),e(A,Gg),e(Gg,Tue),e(Tue,Lpo),e(Gg,ypo),e(Gg,yj),e(yj,xpo),e(Gg,$po),e(A,kpo),e(A,Og),e(Og,Mue),e(Mue,Spo),e(Og,Rpo),e(Og,xj),e(xj,Ppo),e(Og,Bpo),e(A,Ipo),e(A,Vg),e(Vg,Eue),e(Eue,Npo),e(Vg,qpo),e(Vg,$j),e($j,jpo),e(Vg,Dpo),e(A,Gpo),e(A,Xg),e(Xg,Cue),e(Cue,Opo),e(Xg,Vpo),e(Xg,kj),e(kj,Xpo),e(Xg,zpo),e(A,Qpo),e(A,zg),e(zg,wue),e(wue,Wpo),e(zg,Upo),e(zg,Sj),e(Sj,Hpo),e(zg,Jpo),e(A,Ypo),e(A,Qg),e(Qg,Aue),e(Aue,Zpo),e(Qg,Kpo),e(Qg,Rj),e(Rj,e_o),e(Qg,o_o),e(A,r_o),e(A,Wg),e(Wg,Lue),e(Lue,t_o),e(Wg,a_o),e(Wg,Pj),e(Pj,n_o),e(Wg,s_o),e(A,l_o),e(A,Ug),e(Ug,yue),e(yue,i_o),e(Ug,d_o),e(Ug,Bj),e(Bj,m_o),e(Ug,c_o),e(A,f_o),e(A,Hg),e(Hg,xue),e(xue,g_o),e(Hg,h_o),e(Hg,Ij),e(Ij,u_o),e(Hg,p_o),e(A,__o),e(A,Jg),e(Jg,$ue),e($ue,b_o),e(Jg,v_o),e(Jg,Nj),e(Nj,F_o),e(Jg,T_o),e(A,M_o),e(A,Yg),e(Yg,kue),e(kue,E_o),e(Yg,C_o),e(Yg,qj),e(qj,w_o),e(Yg,A_o),e(A,L_o),e(A,Zg),e(Zg,Sue),e(Sue,y_o),e(Zg,x_o),e(Zg,jj),e(jj,$_o),e(Zg,k_o),e(A,S_o),e(A,Kg),e(Kg,Rue),e(Rue,R_o),e(Kg,P_o),e(Kg,Dj),e(Dj,B_o),e(Kg,I_o),e(A,N_o),e(A,eh),e(eh,Pue),e(Pue,q_o),e(eh,j_o),e(eh,Gj),e(Gj,D_o),e(eh,G_o),e(A,O_o),e(A,oh),e(oh,Bue),e(Bue,V_o),e(oh,X_o),e(oh,Oj),e(Oj,z_o),e(oh,Q_o),e(A,W_o),e(A,rh),e(rh,Iue),e(Iue,U_o),e(rh,H_o),e(rh,Vj),e(Vj,J_o),e(rh,Y_o),e(A,Z_o),e(A,th),e(th,Nue),e(Nue,K_o),e(th,e1o),e(th,Xj),e(Xj,o1o),e(th,r1o),e(A,t1o),e(A,ah),e(ah,que),e(que,a1o),e(ah,n1o),e(ah,zj),e(zj,s1o),e(ah,l1o),e(A,i1o),e(A,nh),e(nh,jue),e(jue,d1o),e(nh,m1o),e(nh,Qj),e(Qj,c1o),e(nh,f1o),e(A,g1o),e(A,sh),e(sh,Due),e(Due,h1o),e(sh,u1o),e(sh,Wj),e(Wj,p1o),e(sh,_1o),e(A,b1o),e(A,lh),e(lh,Gue),e(Gue,v1o),e(lh,F1o),e(lh,Uj),e(Uj,T1o),e(lh,M1o),e(A,E1o),e(A,ih),e(ih,Oue),e(Oue,C1o),e(ih,w1o),e(ih,Hj),e(Hj,A1o),e(ih,L1o),e(A,y1o),e(A,dh),e(dh,Vue),e(Vue,x1o),e(dh,$1o),e(dh,Jj),e(Jj,k1o),e(dh,S1o),e(A,R1o),e(A,mh),e(mh,Xue),e(Xue,P1o),e(mh,B1o),e(mh,Yj),e(Yj,I1o),e(mh,N1o),e(A,q1o),e(A,ch),e(ch,zue),e(zue,j1o),e(ch,D1o),e(ch,Zj),e(Zj,G1o),e(ch,O1o),e(A,V1o),e(A,fh),e(fh,Que),e(Que,X1o),e(fh,z1o),e(fh,Kj),e(Kj,Q1o),e(fh,W1o),e(A,U1o),e(A,gh),e(gh,Wue),e(Wue,H1o),e(gh,J1o),e(gh,eD),e(eD,Y1o),e(gh,Z1o),e(A,K1o),e(A,hh),e(hh,Uue),e(Uue,e2o),e(hh,o2o),e(hh,oD),e(oD,r2o),e(hh,t2o),e(A,a2o),e(A,uh),e(uh,Hue),e(Hue,n2o),e(uh,s2o),e(uh,rD),e(rD,l2o),e(uh,i2o),e(A,d2o),e(A,ph),e(ph,Jue),e(Jue,m2o),e(ph,c2o),e(ph,tD),e(tD,f2o),e(ph,g2o),e(A,h2o),e(A,_h),e(_h,Yue),e(Yue,u2o),e(_h,p2o),e(_h,aD),e(aD,_2o),e(_h,b2o),e(A,v2o),e(A,bh),e(bh,Zue),e(Zue,F2o),e(bh,T2o),e(bh,nD),e(nD,M2o),e(bh,E2o),e(A,C2o),e(A,vh),e(vh,Kue),e(Kue,w2o),e(vh,A2o),e(vh,sD),e(sD,L2o),e(vh,y2o),e(A,x2o),e(A,Fh),e(Fh,epe),e(epe,$2o),e(Fh,k2o),e(Fh,lD),e(lD,S2o),e(Fh,R2o),e(A,P2o),e(A,Th),e(Th,ope),e(ope,B2o),e(Th,I2o),e(Th,iD),e(iD,N2o),e(Th,q2o),e(A,j2o),e(A,Mh),e(Mh,rpe),e(rpe,D2o),e(Mh,G2o),e(Mh,dD),e(dD,O2o),e(Mh,V2o),e(A,X2o),e(A,Eh),e(Eh,tpe),e(tpe,z2o),e(Eh,Q2o),e(Eh,mD),e(mD,W2o),e(Eh,U2o),e(A,H2o),e(A,Ch),e(Ch,ape),e(ape,J2o),e(Ch,Y2o),e(Ch,cD),e(cD,Z2o),e(Ch,K2o),e(A,ebo),e(A,wh),e(wh,npe),e(npe,obo),e(wh,rbo),e(wh,fD),e(fD,tbo),e(wh,abo),e(A,nbo),e(A,Ah),e(Ah,spe),e(spe,sbo),e(Ah,lbo),e(Ah,gD),e(gD,ibo),e(Ah,dbo),e(A,mbo),e(A,Lh),e(Lh,lpe),e(lpe,cbo),e(Lh,fbo),e(Lh,hD),e(hD,gbo),e(Lh,hbo),e(A,ubo),e(A,yh),e(yh,ipe),e(ipe,pbo),e(yh,_bo),e(yh,uD),e(uD,bbo),e(yh,vbo),e(A,Fbo),e(A,xh),e(xh,dpe),e(dpe,Tbo),e(xh,Mbo),e(xh,pD),e(pD,Ebo),e(xh,Cbo),e(A,wbo),e(A,$h),e($h,mpe),e(mpe,Abo),e($h,Lbo),e($h,_D),e(_D,ybo),e($h,xbo),e(A,$bo),e(A,kh),e(kh,cpe),e(cpe,kbo),e(kh,Sbo),e(kh,bD),e(bD,Rbo),e(kh,Pbo),e(A,Bbo),e(A,Sh),e(Sh,fpe),e(fpe,Ibo),e(Sh,Nbo),e(Sh,vD),e(vD,qbo),e(Sh,jbo),e(A,Dbo),e(A,Rh),e(Rh,gpe),e(gpe,Gbo),e(Rh,Obo),e(Rh,FD),e(FD,Vbo),e(Rh,Xbo),e(A,zbo),e(A,Ph),e(Ph,hpe),e(hpe,Qbo),e(Ph,Wbo),e(Ph,TD),e(TD,Ubo),e(Ph,Hbo),e(A,Jbo),e(A,Bh),e(Bh,upe),e(upe,Ybo),e(Bh,Zbo),e(Bh,MD),e(MD,Kbo),e(Bh,evo),e(A,ovo),e(A,Ih),e(Ih,ppe),e(ppe,rvo),e(Ih,tvo),e(Ih,ED),e(ED,avo),e(Ih,nvo),e(A,svo),e(A,Nh),e(Nh,_pe),e(_pe,lvo),e(Nh,ivo),e(Nh,CD),e(CD,dvo),e(Nh,mvo),e(A,cvo),e(A,qh),e(qh,bpe),e(bpe,fvo),e(qh,gvo),e(qh,wD),e(wD,hvo),e(qh,uvo),e(A,pvo),e(A,jh),e(jh,vpe),e(vpe,_vo),e(jh,bvo),e(jh,AD),e(AD,vvo),e(jh,Fvo),e(A,Tvo),e(A,Dh),e(Dh,Fpe),e(Fpe,Mvo),e(Dh,Evo),e(Dh,LD),e(LD,Cvo),e(Dh,wvo),e(A,Avo),e(A,Gh),e(Gh,Tpe),e(Tpe,Lvo),e(Gh,yvo),e(Gh,yD),e(yD,xvo),e(Gh,$vo),e(A,kvo),e(A,Oh),e(Oh,Mpe),e(Mpe,Svo),e(Oh,Rvo),e(Oh,xD),e(xD,Pvo),e(Oh,Bvo),e(A,Ivo),e(A,Vh),e(Vh,Epe),e(Epe,Nvo),e(Vh,qvo),e(Vh,$D),e($D,jvo),e(Vh,Dvo),e(A,Gvo),e(A,Xh),e(Xh,Cpe),e(Cpe,Ovo),e(Xh,Vvo),e(Xh,kD),e(kD,Xvo),e(Xh,zvo),e(A,Qvo),e(A,zh),e(zh,wpe),e(wpe,Wvo),e(zh,Uvo),e(zh,SD),e(SD,Hvo),e(zh,Jvo),e(A,Yvo),e(A,Qh),e(Qh,Ape),e(Ape,Zvo),e(Qh,Kvo),e(Qh,RD),e(RD,eFo),e(Qh,oFo),e(A,rFo),e(A,Wh),e(Wh,Lpe),e(Lpe,tFo),e(Wh,aFo),e(Wh,PD),e(PD,nFo),e(Wh,sFo),e(A,lFo),e(A,Uh),e(Uh,ype),e(ype,iFo),e(Uh,dFo),e(Uh,BD),e(BD,mFo),e(Uh,cFo),e(A,fFo),e(A,Hh),e(Hh,xpe),e(xpe,gFo),e(Hh,hFo),e(Hh,ID),e(ID,uFo),e(Hh,pFo),e(A,_Fo),e(A,Jh),e(Jh,$pe),e($pe,bFo),e(Jh,vFo),e(Jh,ND),e(ND,FFo),e(Jh,TFo),e(A,MFo),e(A,Yh),e(Yh,kpe),e(kpe,EFo),e(Yh,CFo),e(Yh,qD),e(qD,wFo),e(Yh,AFo),e(A,LFo),e(A,Zh),e(Zh,Spe),e(Spe,yFo),e(Zh,xFo),e(Zh,jD),e(jD,$Fo),e(Zh,kFo),e(A,SFo),e(A,Kh),e(Kh,Rpe),e(Rpe,RFo),e(Kh,PFo),e(Kh,DD),e(DD,BFo),e(Kh,IFo),e(A,NFo),e(A,eu),e(eu,Ppe),e(Ppe,qFo),e(eu,jFo),e(eu,GD),e(GD,DFo),e(eu,GFo),e(A,OFo),e(A,ou),e(ou,Bpe),e(Bpe,VFo),e(ou,XFo),e(ou,OD),e(OD,zFo),e(ou,QFo),e(A,WFo),e(A,ru),e(ru,Ipe),e(Ipe,UFo),e(ru,HFo),e(ru,VD),e(VD,JFo),e(ru,YFo),e(A,ZFo),e(A,tu),e(tu,Npe),e(Npe,KFo),e(tu,eTo),e(tu,XD),e(XD,oTo),e(tu,rTo),e(A,tTo),e(A,au),e(au,qpe),e(qpe,aTo),e(au,nTo),e(au,zD),e(zD,sTo),e(au,lTo),e(A,iTo),e(A,nu),e(nu,jpe),e(jpe,dTo),e(nu,mTo),e(nu,QD),e(QD,cTo),e(nu,fTo),e(A,gTo),e(A,su),e(su,Dpe),e(Dpe,hTo),e(su,uTo),e(su,WD),e(WD,pTo),e(su,_To),e(A,bTo),e(A,lu),e(lu,Gpe),e(Gpe,vTo),e(lu,FTo),e(lu,UD),e(UD,TTo),e(lu,MTo),e(A,ETo),e(A,iu),e(iu,Ope),e(Ope,CTo),e(iu,wTo),e(iu,HD),e(HD,ATo),e(iu,LTo),e(A,yTo),e(A,du),e(du,Vpe),e(Vpe,xTo),e(du,$To),e(du,JD),e(JD,kTo),e(du,STo),e(A,RTo),e(A,mu),e(mu,Xpe),e(Xpe,PTo),e(mu,BTo),e(mu,YD),e(YD,ITo),e(mu,NTo),e(A,qTo),e(A,cu),e(cu,zpe),e(zpe,jTo),e(cu,DTo),e(cu,ZD),e(ZD,GTo),e(cu,OTo),e(A,VTo),e(A,fu),e(fu,Qpe),e(Qpe,XTo),e(fu,zTo),e(fu,KD),e(KD,QTo),e(fu,WTo),e(A,UTo),e(A,gu),e(gu,Wpe),e(Wpe,HTo),e(gu,JTo),e(gu,eG),e(eG,YTo),e(gu,ZTo),e(A,KTo),e(A,hu),e(hu,Upe),e(Upe,eMo),e(hu,oMo),e(hu,oG),e(oG,rMo),e(hu,tMo),e(A,aMo),e(A,uu),e(uu,Hpe),e(Hpe,nMo),e(uu,sMo),e(uu,rG),e(rG,lMo),e(uu,iMo),e(A,dMo),e(A,pu),e(pu,Jpe),e(Jpe,mMo),e(pu,cMo),e(pu,tG),e(tG,fMo),e(pu,gMo),e(A,hMo),e(A,_u),e(_u,Ype),e(Ype,uMo),e(_u,pMo),e(_u,aG),e(aG,_Mo),e(_u,bMo),e(A,vMo),e(A,bu),e(bu,Zpe),e(Zpe,FMo),e(bu,TMo),e(bu,nG),e(nG,MMo),e(bu,EMo),e(A,CMo),e(A,vu),e(vu,Kpe),e(Kpe,wMo),e(vu,AMo),e(vu,sG),e(sG,LMo),e(vu,yMo),e(A,xMo),e(A,Fu),e(Fu,e_e),e(e_e,$Mo),e(Fu,kMo),e(Fu,lG),e(lG,SMo),e(Fu,RMo),e(A,PMo),e(A,Tu),e(Tu,o_e),e(o_e,BMo),e(Tu,IMo),e(Tu,iG),e(iG,NMo),e(Tu,qMo),e(A,jMo),e(A,Mu),e(Mu,r_e),e(r_e,DMo),e(Mu,GMo),e(Mu,dG),e(dG,OMo),e(Mu,VMo),e(A,XMo),e(A,Eu),e(Eu,t_e),e(t_e,zMo),e(Eu,QMo),e(Eu,mG),e(mG,WMo),e(Eu,UMo),e(A,HMo),e(A,Cu),e(Cu,a_e),e(a_e,JMo),e(Cu,YMo),e(Cu,cG),e(cG,ZMo),e(Cu,KMo),e(A,eEo),e(A,wu),e(wu,n_e),e(n_e,oEo),e(wu,rEo),e(wu,fG),e(fG,tEo),e(wu,aEo),e(A,nEo),e(A,Au),e(Au,s_e),e(s_e,sEo),e(Au,lEo),e(Au,gG),e(gG,iEo),e(Au,dEo),e(A,mEo),e(A,Lu),e(Lu,l_e),e(l_e,cEo),e(Lu,fEo),e(Lu,hG),e(hG,gEo),e(Lu,hEo),e(A,uEo),e(A,yu),e(yu,i_e),e(i_e,pEo),e(yu,_Eo),e(yu,uG),e(uG,bEo),e(yu,vEo),e(A,FEo),e(A,xu),e(xu,d_e),e(d_e,TEo),e(xu,MEo),e(xu,pG),e(pG,EEo),e(xu,CEo),e(A,wEo),e(A,$u),e($u,m_e),e(m_e,AEo),e($u,LEo),e($u,_G),e(_G,yEo),e($u,xEo),e(A,$Eo),e(A,ku),e(ku,c_e),e(c_e,kEo),e(ku,SEo),e(ku,bG),e(bG,REo),e(ku,PEo),e(A,BEo),e(A,Su),e(Su,f_e),e(f_e,IEo),e(Su,NEo),e(Su,vG),e(vG,qEo),e(Su,jEo),e(A,DEo),e(A,Ru),e(Ru,g_e),e(g_e,GEo),e(Ru,OEo),e(Ru,FG),e(FG,VEo),e(Ru,XEo),e(A,zEo),e(A,Pu),e(Pu,h_e),e(h_e,QEo),e(Pu,WEo),e(Pu,TG),e(TG,UEo),e(Pu,HEo),e(A,JEo),e(A,Bu),e(Bu,u_e),e(u_e,YEo),e(Bu,ZEo),e(Bu,MG),e(MG,KEo),e(Bu,e4o),e(A,o4o),e(A,Iu),e(Iu,p_e),e(p_e,r4o),e(Iu,t4o),e(Iu,EG),e(EG,a4o),e(Iu,n4o),e(A,s4o),e(A,Nu),e(Nu,__e),e(__e,l4o),e(Nu,i4o),e(Nu,CG),e(CG,d4o),e(Nu,m4o),e(Vr,c4o),M(qu,Vr,null),e(Bo,f4o),e(Bo,ju),M(yk,ju,null),e(ju,g4o),e(ju,b_e),e(b_e,h4o),b(c,nio,_),b(c,Id,_),e(Id,Du),e(Du,v_e),M(xk,v_e,null),e(Id,u4o),e(Id,F_e),e(F_e,p4o),b(c,sio,_),b(c,Io,_),M($k,Io,null),e(Io,_4o),e(Io,kk),e(kk,b4o),e(kk,wG),e(wG,v4o),e(kk,F4o),e(Io,T4o),e(Io,Sk),e(Sk,M4o),e(Sk,T_e),e(T_e,E4o),e(Sk,C4o),e(Io,w4o),e(Io,Xr),M(Rk,Xr,null),e(Xr,A4o),e(Xr,M_e),e(M_e,L4o),e(Xr,y4o),e(Xr,mn),e(mn,x4o),e(mn,E_e),e(E_e,$4o),e(mn,k4o),e(mn,C_e),e(C_e,S4o),e(mn,R4o),e(mn,w_e),e(w_e,P4o),e(mn,B4o),e(Xr,I4o),e(Xr,k),e(k,Ms),e(Ms,A_e),e(A_e,N4o),e(Ms,q4o),e(Ms,AG),e(AG,j4o),e(Ms,D4o),e(Ms,LG),e(LG,G4o),e(Ms,O4o),e(k,V4o),e(k,Es),e(Es,L_e),e(L_e,X4o),e(Es,z4o),e(Es,yG),e(yG,Q4o),e(Es,W4o),e(Es,xG),e(xG,U4o),e(Es,H4o),e(k,J4o),e(k,Cs),e(Cs,y_e),e(y_e,Y4o),e(Cs,Z4o),e(Cs,$G),e($G,K4o),e(Cs,eCo),e(Cs,kG),e(kG,oCo),e(Cs,rCo),e(k,tCo),e(k,Gu),e(Gu,x_e),e(x_e,aCo),e(Gu,nCo),e(Gu,SG),e(SG,sCo),e(Gu,lCo),e(k,iCo),e(k,ws),e(ws,$_e),e($_e,dCo),e(ws,mCo),e(ws,RG),e(RG,cCo),e(ws,fCo),e(ws,PG),e(PG,gCo),e(ws,hCo),e(k,uCo),e(k,Ou),e(Ou,k_e),e(k_e,pCo),e(Ou,_Co),e(Ou,BG),e(BG,bCo),e(Ou,vCo),e(k,FCo),e(k,Vu),e(Vu,S_e),e(S_e,TCo),e(Vu,MCo),e(Vu,IG),e(IG,ECo),e(Vu,CCo),e(k,wCo),e(k,Xu),e(Xu,R_e),e(R_e,ACo),e(Xu,LCo),e(Xu,NG),e(NG,yCo),e(Xu,xCo),e(k,$Co),e(k,As),e(As,P_e),e(P_e,kCo),e(As,SCo),e(As,qG),e(qG,RCo),e(As,PCo),e(As,jG),e(jG,BCo),e(As,ICo),e(k,NCo),e(k,Ls),e(Ls,B_e),e(B_e,qCo),e(Ls,jCo),e(Ls,DG),e(DG,DCo),e(Ls,GCo),e(Ls,GG),e(GG,OCo),e(Ls,VCo),e(k,XCo),e(k,ys),e(ys,I_e),e(I_e,zCo),e(ys,QCo),e(ys,OG),e(OG,WCo),e(ys,UCo),e(ys,VG),e(VG,HCo),e(ys,JCo),e(k,YCo),e(k,zu),e(zu,N_e),e(N_e,ZCo),e(zu,KCo),e(zu,XG),e(XG,e3o),e(zu,o3o),e(k,r3o),e(k,Qu),e(Qu,q_e),e(q_e,t3o),e(Qu,a3o),e(Qu,zG),e(zG,n3o),e(Qu,s3o),e(k,l3o),e(k,Wu),e(Wu,j_e),e(j_e,i3o),e(Wu,d3o),e(Wu,QG),e(QG,m3o),e(Wu,c3o),e(k,f3o),e(k,xs),e(xs,D_e),e(D_e,g3o),e(xs,h3o),e(xs,WG),e(WG,u3o),e(xs,p3o),e(xs,UG),e(UG,_3o),e(xs,b3o),e(k,v3o),e(k,Uu),e(Uu,G_e),e(G_e,F3o),e(Uu,T3o),e(Uu,HG),e(HG,M3o),e(Uu,E3o),e(k,C3o),e(k,$s),e($s,O_e),e(O_e,w3o),e($s,A3o),e($s,JG),e(JG,L3o),e($s,y3o),e($s,YG),e(YG,x3o),e($s,$3o),e(k,k3o),e(k,ks),e(ks,V_e),e(V_e,S3o),e(ks,R3o),e(ks,ZG),e(ZG,P3o),e(ks,B3o),e(ks,KG),e(KG,I3o),e(ks,N3o),e(k,q3o),e(k,Ss),e(Ss,X_e),e(X_e,j3o),e(Ss,D3o),e(Ss,eO),e(eO,G3o),e(Ss,O3o),e(Ss,oO),e(oO,V3o),e(Ss,X3o),e(k,z3o),e(k,Rs),e(Rs,z_e),e(z_e,Q3o),e(Rs,W3o),e(Rs,rO),e(rO,U3o),e(Rs,H3o),e(Rs,tO),e(tO,J3o),e(Rs,Y3o),e(k,Z3o),e(k,Ps),e(Ps,Q_e),e(Q_e,K3o),e(Ps,e5o),e(Ps,aO),e(aO,o5o),e(Ps,r5o),e(Ps,nO),e(nO,t5o),e(Ps,a5o),e(k,n5o),e(k,Hu),e(Hu,W_e),e(W_e,s5o),e(Hu,l5o),e(Hu,sO),e(sO,i5o),e(Hu,d5o),e(k,m5o),e(k,Bs),e(Bs,U_e),e(U_e,c5o),e(Bs,f5o),e(Bs,lO),e(lO,g5o),e(Bs,h5o),e(Bs,iO),e(iO,u5o),e(Bs,p5o),e(k,_5o),e(k,Is),e(Is,H_e),e(H_e,b5o),e(Is,v5o),e(Is,dO),e(dO,F5o),e(Is,T5o),e(Is,mO),e(mO,M5o),e(Is,E5o),e(k,C5o),e(k,Ns),e(Ns,J_e),e(J_e,w5o),e(Ns,A5o),e(Ns,cO),e(cO,L5o),e(Ns,y5o),e(Ns,fO),e(fO,x5o),e(Ns,$5o),e(k,k5o),e(k,qs),e(qs,Y_e),e(Y_e,S5o),e(qs,R5o),e(qs,gO),e(gO,P5o),e(qs,B5o),e(qs,hO),e(hO,I5o),e(qs,N5o),e(k,q5o),e(k,js),e(js,Z_e),e(Z_e,j5o),e(js,D5o),e(js,uO),e(uO,G5o),e(js,O5o),e(js,pO),e(pO,V5o),e(js,X5o),e(k,z5o),e(k,Ds),e(Ds,K_e),e(K_e,Q5o),e(Ds,W5o),e(Ds,_O),e(_O,U5o),e(Ds,H5o),e(Ds,bO),e(bO,J5o),e(Ds,Y5o),e(k,Z5o),e(k,Gs),e(Gs,e1e),e(e1e,K5o),e(Gs,e0o),e(Gs,vO),e(vO,o0o),e(Gs,r0o),e(Gs,FO),e(FO,t0o),e(Gs,a0o),e(k,n0o),e(k,Ju),e(Ju,o1e),e(o1e,s0o),e(Ju,l0o),e(Ju,TO),e(TO,i0o),e(Ju,d0o),e(k,m0o),e(k,Yu),e(Yu,r1e),e(r1e,c0o),e(Yu,f0o),e(Yu,MO),e(MO,g0o),e(Yu,h0o),e(k,u0o),e(k,Os),e(Os,t1e),e(t1e,p0o),e(Os,_0o),e(Os,EO),e(EO,b0o),e(Os,v0o),e(Os,CO),e(CO,F0o),e(Os,T0o),e(k,M0o),e(k,Zu),e(Zu,a1e),e(a1e,E0o),e(Zu,C0o),e(Zu,wO),e(wO,w0o),e(Zu,A0o),e(k,L0o),e(k,Vs),e(Vs,n1e),e(n1e,y0o),e(Vs,x0o),e(Vs,AO),e(AO,$0o),e(Vs,k0o),e(Vs,LO),e(LO,S0o),e(Vs,R0o),e(k,P0o),e(k,Xs),e(Xs,s1e),e(s1e,B0o),e(Xs,I0o),e(Xs,yO),e(yO,N0o),e(Xs,q0o),e(Xs,xO),e(xO,j0o),e(Xs,D0o),e(k,G0o),e(k,zs),e(zs,l1e),e(l1e,O0o),e(zs,V0o),e(zs,$O),e($O,X0o),e(zs,z0o),e(zs,kO),e(kO,Q0o),e(zs,W0o),e(k,U0o),e(k,Ku),e(Ku,i1e),e(i1e,H0o),e(Ku,J0o),e(Ku,SO),e(SO,Y0o),e(Ku,Z0o),e(k,K0o),e(k,ep),e(ep,d1e),e(d1e,ewo),e(ep,owo),e(ep,RO),e(RO,rwo),e(ep,two),e(k,awo),e(k,Qs),e(Qs,m1e),e(m1e,nwo),e(Qs,swo),e(Qs,PO),e(PO,lwo),e(Qs,iwo),e(Qs,BO),e(BO,dwo),e(Qs,mwo),e(k,cwo),e(k,Ws),e(Ws,c1e),e(c1e,fwo),e(Ws,gwo),e(Ws,IO),e(IO,hwo),e(Ws,uwo),e(Ws,NO),e(NO,pwo),e(Ws,_wo),e(k,bwo),e(k,Us),e(Us,f1e),e(f1e,vwo),e(Us,Fwo),e(Us,qO),e(qO,Two),e(Us,Mwo),e(Us,jO),e(jO,Ewo),e(Us,Cwo),e(k,wwo),e(k,op),e(op,g1e),e(g1e,Awo),e(op,Lwo),e(op,DO),e(DO,ywo),e(op,xwo),e(k,$wo),e(k,Hs),e(Hs,h1e),e(h1e,kwo),e(Hs,Swo),e(Hs,GO),e(GO,Rwo),e(Hs,Pwo),e(Hs,OO),e(OO,Bwo),e(Hs,Iwo),e(k,Nwo),e(k,rp),e(rp,u1e),e(u1e,qwo),e(rp,jwo),e(rp,VO),e(VO,Dwo),e(rp,Gwo),e(k,Owo),e(k,Js),e(Js,p1e),e(p1e,Vwo),e(Js,Xwo),e(Js,XO),e(XO,zwo),e(Js,Qwo),e(Js,zO),e(zO,Wwo),e(Js,Uwo),e(k,Hwo),e(k,Ys),e(Ys,_1e),e(_1e,Jwo),e(Ys,Ywo),e(Ys,QO),e(QO,Zwo),e(Ys,Kwo),e(Ys,WO),e(WO,eAo),e(Ys,oAo),e(k,rAo),e(k,Zs),e(Zs,b1e),e(b1e,tAo),e(Zs,aAo),e(Zs,UO),e(UO,nAo),e(Zs,sAo),e(Zs,HO),e(HO,lAo),e(Zs,iAo),e(k,dAo),e(k,Ks),e(Ks,v1e),e(v1e,mAo),e(Ks,cAo),e(Ks,JO),e(JO,fAo),e(Ks,gAo),e(Ks,YO),e(YO,hAo),e(Ks,uAo),e(k,pAo),e(k,el),e(el,F1e),e(F1e,_Ao),e(el,bAo),e(el,ZO),e(ZO,vAo),e(el,FAo),e(el,KO),e(KO,TAo),e(el,MAo),e(k,EAo),e(k,ol),e(ol,T1e),e(T1e,CAo),e(ol,wAo),e(ol,eV),e(eV,AAo),e(ol,LAo),e(ol,oV),e(oV,yAo),e(ol,xAo),e(k,$Ao),e(k,rl),e(rl,M1e),e(M1e,kAo),e(rl,SAo),e(rl,rV),e(rV,RAo),e(rl,PAo),e(rl,tV),e(tV,BAo),e(rl,IAo),e(k,NAo),e(k,tl),e(tl,E1e),e(E1e,qAo),e(tl,jAo),e(tl,aV),e(aV,DAo),e(tl,GAo),e(tl,nV),e(nV,OAo),e(tl,VAo),e(k,XAo),e(k,tp),e(tp,C1e),e(C1e,zAo),e(tp,QAo),e(tp,sV),e(sV,WAo),e(tp,UAo),e(k,HAo),e(k,al),e(al,w1e),e(w1e,JAo),e(al,YAo),e(al,lV),e(lV,ZAo),e(al,KAo),e(al,iV),e(iV,e6o),e(al,o6o),e(k,r6o),e(k,ap),e(ap,A1e),e(A1e,t6o),e(ap,a6o),e(ap,dV),e(dV,n6o),e(ap,s6o),e(k,l6o),e(k,np),e(np,L1e),e(L1e,i6o),e(np,d6o),e(np,mV),e(mV,m6o),e(np,c6o),e(k,f6o),e(k,nl),e(nl,y1e),e(y1e,g6o),e(nl,h6o),e(nl,cV),e(cV,u6o),e(nl,p6o),e(nl,fV),e(fV,_6o),e(nl,b6o),e(k,v6o),e(k,sl),e(sl,x1e),e(x1e,F6o),e(sl,T6o),e(sl,gV),e(gV,M6o),e(sl,E6o),e(sl,hV),e(hV,C6o),e(sl,w6o),e(k,A6o),e(k,ll),e(ll,$1e),e($1e,L6o),e(ll,y6o),e(ll,uV),e(uV,x6o),e(ll,$6o),e(ll,pV),e(pV,k6o),e(ll,S6o),e(k,R6o),e(k,sp),e(sp,k1e),e(k1e,P6o),e(sp,B6o),e(sp,_V),e(_V,I6o),e(sp,N6o),e(k,q6o),e(k,il),e(il,S1e),e(S1e,j6o),e(il,D6o),e(il,bV),e(bV,G6o),e(il,O6o),e(il,vV),e(vV,V6o),e(il,X6o),e(k,z6o),e(k,dl),e(dl,R1e),e(R1e,Q6o),e(dl,W6o),e(dl,FV),e(FV,U6o),e(dl,H6o),e(dl,TV),e(TV,J6o),e(dl,Y6o),e(k,Z6o),e(k,ml),e(ml,P1e),e(P1e,K6o),e(ml,e7o),e(ml,MV),e(MV,o7o),e(ml,r7o),e(ml,EV),e(EV,t7o),e(ml,a7o),e(k,n7o),e(k,cl),e(cl,B1e),e(B1e,s7o),e(cl,l7o),e(cl,CV),e(CV,i7o),e(cl,d7o),e(cl,wV),e(wV,m7o),e(cl,c7o),e(k,f7o),e(k,fl),e(fl,I1e),e(I1e,g7o),e(fl,h7o),e(fl,AV),e(AV,u7o),e(fl,p7o),e(fl,LV),e(LV,_7o),e(fl,b7o),e(k,v7o),e(k,gl),e(gl,N1e),e(N1e,F7o),e(gl,T7o),e(gl,yV),e(yV,M7o),e(gl,E7o),e(gl,xV),e(xV,C7o),e(gl,w7o),e(k,A7o),e(k,hl),e(hl,q1e),e(q1e,L7o),e(hl,y7o),e(hl,$V),e($V,x7o),e(hl,$7o),e(hl,kV),e(kV,k7o),e(hl,S7o),e(k,R7o),e(k,ul),e(ul,j1e),e(j1e,P7o),e(ul,B7o),e(ul,SV),e(SV,I7o),e(ul,N7o),e(ul,RV),e(RV,q7o),e(ul,j7o),e(k,D7o),e(k,lp),e(lp,D1e),e(D1e,G7o),e(lp,O7o),e(lp,PV),e(PV,V7o),e(lp,X7o),e(k,z7o),e(k,pl),e(pl,G1e),e(G1e,Q7o),e(pl,W7o),e(pl,BV),e(BV,U7o),e(pl,H7o),e(pl,IV),e(IV,J7o),e(pl,Y7o),e(k,Z7o),e(k,_l),e(_l,O1e),e(O1e,K7o),e(_l,e8o),e(_l,NV),e(NV,o8o),e(_l,r8o),e(_l,qV),e(qV,t8o),e(_l,a8o),e(k,n8o),e(k,bl),e(bl,V1e),e(V1e,s8o),e(bl,l8o),e(bl,jV),e(jV,i8o),e(bl,d8o),e(bl,DV),e(DV,m8o),e(bl,c8o),e(k,f8o),e(k,ip),e(ip,X1e),e(X1e,g8o),e(ip,h8o),e(ip,GV),e(GV,u8o),e(ip,p8o),e(k,_8o),e(k,dp),e(dp,z1e),e(z1e,b8o),e(dp,v8o),e(dp,OV),e(OV,F8o),e(dp,T8o),e(k,M8o),e(k,mp),e(mp,Q1e),e(Q1e,E8o),e(mp,C8o),e(mp,VV),e(VV,w8o),e(mp,A8o),e(k,L8o),e(k,cp),e(cp,W1e),e(W1e,y8o),e(cp,x8o),e(cp,XV),e(XV,$8o),e(cp,k8o),e(k,S8o),e(k,vl),e(vl,U1e),e(U1e,R8o),e(vl,P8o),e(vl,zV),e(zV,B8o),e(vl,I8o),e(vl,QV),e(QV,N8o),e(vl,q8o),e(k,j8o),e(k,fp),e(fp,H1e),e(H1e,D8o),e(fp,G8o),e(fp,WV),e(WV,O8o),e(fp,V8o),e(k,X8o),e(k,Fl),e(Fl,J1e),e(J1e,z8o),e(Fl,Q8o),e(Fl,UV),e(UV,W8o),e(Fl,U8o),e(Fl,HV),e(HV,H8o),e(Fl,J8o),e(k,Y8o),e(k,Tl),e(Tl,Y1e),e(Y1e,Z8o),e(Tl,K8o),e(Tl,JV),e(JV,eLo),e(Tl,oLo),e(Tl,YV),e(YV,rLo),e(Tl,tLo),e(k,aLo),e(k,Ml),e(Ml,Z1e),e(Z1e,nLo),e(Ml,sLo),e(Ml,ZV),e(ZV,lLo),e(Ml,iLo),e(Ml,KV),e(KV,dLo),e(Ml,mLo),e(k,cLo),e(k,El),e(El,K1e),e(K1e,fLo),e(El,gLo),e(El,eX),e(eX,hLo),e(El,uLo),e(El,oX),e(oX,pLo),e(El,_Lo),e(k,bLo),e(k,Cl),e(Cl,e2e),e(e2e,vLo),e(Cl,FLo),e(Cl,rX),e(rX,TLo),e(Cl,MLo),e(Cl,tX),e(tX,ELo),e(Cl,CLo),e(k,wLo),e(k,gp),e(gp,o2e),e(o2e,ALo),e(gp,LLo),e(gp,aX),e(aX,yLo),e(gp,xLo),e(k,$Lo),e(k,wl),e(wl,r2e),e(r2e,kLo),e(wl,SLo),e(wl,nX),e(nX,RLo),e(wl,PLo),e(wl,sX),e(sX,BLo),e(wl,ILo),e(k,NLo),e(k,hp),e(hp,t2e),e(t2e,qLo),e(hp,jLo),e(hp,lX),e(lX,DLo),e(hp,GLo),e(k,OLo),e(k,up),e(up,a2e),e(a2e,VLo),e(up,XLo),e(up,iX),e(iX,zLo),e(up,QLo),e(k,WLo),e(k,Al),e(Al,n2e),e(n2e,ULo),e(Al,HLo),e(Al,dX),e(dX,JLo),e(Al,YLo),e(Al,mX),e(mX,ZLo),e(Al,KLo),e(k,eyo),e(k,Ll),e(Ll,s2e),e(s2e,oyo),e(Ll,ryo),e(Ll,cX),e(cX,tyo),e(Ll,ayo),e(Ll,fX),e(fX,nyo),e(Ll,syo),e(k,lyo),e(k,yl),e(yl,l2e),e(l2e,iyo),e(yl,dyo),e(yl,gX),e(gX,myo),e(yl,cyo),e(yl,hX),e(hX,fyo),e(yl,gyo),e(k,hyo),e(k,pp),e(pp,i2e),e(i2e,uyo),e(pp,pyo),e(pp,uX),e(uX,_yo),e(pp,byo),e(k,vyo),e(k,_p),e(_p,d2e),e(d2e,Fyo),e(_p,Tyo),e(_p,pX),e(pX,Myo),e(_p,Eyo),e(k,Cyo),e(k,bp),e(bp,m2e),e(m2e,wyo),e(bp,Ayo),e(bp,_X),e(_X,Lyo),e(bp,yyo),e(k,xyo),e(k,xl),e(xl,c2e),e(c2e,$yo),e(xl,kyo),e(xl,bX),e(bX,Syo),e(xl,Ryo),e(xl,vX),e(vX,Pyo),e(xl,Byo),e(k,Iyo),e(k,$l),e($l,f2e),e(f2e,Nyo),e($l,qyo),e($l,FX),e(FX,jyo),e($l,Dyo),e($l,TX),e(TX,Gyo),e($l,Oyo),e(k,Vyo),e(k,vp),e(vp,g2e),e(g2e,Xyo),e(vp,zyo),e(vp,MX),e(MX,Qyo),e(vp,Wyo),e(k,Uyo),e(k,Fp),e(Fp,h2e),e(h2e,Hyo),e(Fp,Jyo),e(Fp,EX),e(EX,Yyo),e(Fp,Zyo),e(k,Kyo),e(k,Tp),e(Tp,u2e),e(u2e,e9o),e(Tp,o9o),e(Tp,CX),e(CX,r9o),e(Tp,t9o),e(k,a9o),e(k,Mp),e(Mp,p2e),e(p2e,n9o),e(Mp,s9o),e(Mp,wX),e(wX,l9o),e(Mp,i9o),e(k,d9o),e(k,kl),e(kl,_2e),e(_2e,m9o),e(kl,c9o),e(kl,AX),e(AX,f9o),e(kl,g9o),e(kl,LX),e(LX,h9o),e(kl,u9o),e(k,p9o),e(k,Sl),e(Sl,b2e),e(b2e,_9o),e(Sl,b9o),e(Sl,yX),e(yX,v9o),e(Sl,F9o),e(Sl,xX),e(xX,T9o),e(Sl,M9o),e(k,E9o),e(k,Ep),e(Ep,v2e),e(v2e,C9o),e(Ep,w9o),e(Ep,$X),e($X,A9o),e(Ep,L9o),e(k,y9o),e(k,Cp),e(Cp,F2e),e(F2e,x9o),e(Cp,$9o),e(Cp,kX),e(kX,k9o),e(Cp,S9o),e(k,R9o),e(k,Rl),e(Rl,T2e),e(T2e,P9o),e(Rl,B9o),e(Rl,SX),e(SX,I9o),e(Rl,N9o),e(Rl,RX),e(RX,q9o),e(Rl,j9o),e(k,D9o),e(k,Pl),e(Pl,M2e),e(M2e,G9o),e(Pl,O9o),e(Pl,PX),e(PX,V9o),e(Pl,X9o),e(Pl,BX),e(BX,z9o),e(Pl,Q9o),e(k,W9o),e(k,Bl),e(Bl,E2e),e(E2e,U9o),e(Bl,H9o),e(Bl,IX),e(IX,J9o),e(Bl,Y9o),e(Bl,NX),e(NX,Z9o),e(Bl,K9o),e(k,exo),e(k,Il),e(Il,C2e),e(C2e,oxo),e(Il,rxo),e(Il,qX),e(qX,txo),e(Il,axo),e(Il,jX),e(jX,nxo),e(Il,sxo),e(Xr,lxo),M(wp,Xr,null),e(Io,ixo),e(Io,Ap),M(Pk,Ap,null),e(Ap,dxo),e(Ap,w2e),e(w2e,mxo),b(c,lio,_),b(c,Nd,_),e(Nd,Lp),e(Lp,A2e),M(Bk,A2e,null),e(Nd,cxo),e(Nd,L2e),e(L2e,fxo),b(c,iio,_),b(c,No,_),M(Ik,No,null),e(No,gxo),e(No,Nk),e(Nk,hxo),e(Nk,DX),e(DX,uxo),e(Nk,pxo),e(No,_xo),e(No,qk),e(qk,bxo),e(qk,y2e),e(y2e,vxo),e(qk,Fxo),e(No,Txo),e(No,eo),M(jk,eo,null),e(eo,Mxo),e(eo,x2e),e(x2e,Exo),e(eo,Cxo),e(eo,cn),e(cn,wxo),e(cn,$2e),e($2e,Axo),e(cn,Lxo),e(cn,k2e),e(k2e,yxo),e(cn,xxo),e(cn,S2e),e(S2e,$xo),e(cn,kxo),e(eo,Sxo),e(eo,z),e(z,yp),e(yp,R2e),e(R2e,Rxo),e(yp,Pxo),e(yp,GX),e(GX,Bxo),e(yp,Ixo),e(z,Nxo),e(z,xp),e(xp,P2e),e(P2e,qxo),e(xp,jxo),e(xp,OX),e(OX,Dxo),e(xp,Gxo),e(z,Oxo),e(z,$p),e($p,B2e),e(B2e,Vxo),e($p,Xxo),e($p,VX),e(VX,zxo),e($p,Qxo),e(z,Wxo),e(z,kp),e(kp,I2e),e(I2e,Uxo),e(kp,Hxo),e(kp,XX),e(XX,Jxo),e(kp,Yxo),e(z,Zxo),e(z,Sp),e(Sp,N2e),e(N2e,Kxo),e(Sp,e$o),e(Sp,zX),e(zX,o$o),e(Sp,r$o),e(z,t$o),e(z,Rp),e(Rp,q2e),e(q2e,a$o),e(Rp,n$o),e(Rp,QX),e(QX,s$o),e(Rp,l$o),e(z,i$o),e(z,Pp),e(Pp,j2e),e(j2e,d$o),e(Pp,m$o),e(Pp,WX),e(WX,c$o),e(Pp,f$o),e(z,g$o),e(z,Bp),e(Bp,D2e),e(D2e,h$o),e(Bp,u$o),e(Bp,UX),e(UX,p$o),e(Bp,_$o),e(z,b$o),e(z,Ip),e(Ip,G2e),e(G2e,v$o),e(Ip,F$o),e(Ip,HX),e(HX,T$o),e(Ip,M$o),e(z,E$o),e(z,Np),e(Np,O2e),e(O2e,C$o),e(Np,w$o),e(Np,JX),e(JX,A$o),e(Np,L$o),e(z,y$o),e(z,qp),e(qp,V2e),e(V2e,x$o),e(qp,$$o),e(qp,YX),e(YX,k$o),e(qp,S$o),e(z,R$o),e(z,jp),e(jp,X2e),e(X2e,P$o),e(jp,B$o),e(jp,ZX),e(ZX,I$o),e(jp,N$o),e(z,q$o),e(z,Dp),e(Dp,z2e),e(z2e,j$o),e(Dp,D$o),e(Dp,KX),e(KX,G$o),e(Dp,O$o),e(z,V$o),e(z,Gp),e(Gp,Q2e),e(Q2e,X$o),e(Gp,z$o),e(Gp,ez),e(ez,Q$o),e(Gp,W$o),e(z,U$o),e(z,Op),e(Op,W2e),e(W2e,H$o),e(Op,J$o),e(Op,oz),e(oz,Y$o),e(Op,Z$o),e(z,K$o),e(z,Vp),e(Vp,U2e),e(U2e,eko),e(Vp,oko),e(Vp,rz),e(rz,rko),e(Vp,tko),e(z,ako),e(z,Xp),e(Xp,H2e),e(H2e,nko),e(Xp,sko),e(Xp,tz),e(tz,lko),e(Xp,iko),e(z,dko),e(z,zp),e(zp,J2e),e(J2e,mko),e(zp,cko),e(zp,az),e(az,fko),e(zp,gko),e(z,hko),e(z,Qp),e(Qp,Y2e),e(Y2e,uko),e(Qp,pko),e(Qp,nz),e(nz,_ko),e(Qp,bko),e(z,vko),e(z,Wp),e(Wp,Z2e),e(Z2e,Fko),e(Wp,Tko),e(Wp,sz),e(sz,Mko),e(Wp,Eko),e(z,Cko),e(z,Up),e(Up,K2e),e(K2e,wko),e(Up,Ako),e(Up,lz),e(lz,Lko),e(Up,yko),e(z,xko),e(z,Hp),e(Hp,ebe),e(ebe,$ko),e(Hp,kko),e(Hp,iz),e(iz,Sko),e(Hp,Rko),e(z,Pko),e(z,Jp),e(Jp,obe),e(obe,Bko),e(Jp,Iko),e(Jp,dz),e(dz,Nko),e(Jp,qko),e(z,jko),e(z,Yp),e(Yp,rbe),e(rbe,Dko),e(Yp,Gko),e(Yp,mz),e(mz,Oko),e(Yp,Vko),e(z,Xko),e(z,Zp),e(Zp,tbe),e(tbe,zko),e(Zp,Qko),e(Zp,cz),e(cz,Wko),e(Zp,Uko),e(z,Hko),e(z,Kp),e(Kp,abe),e(abe,Jko),e(Kp,Yko),e(Kp,fz),e(fz,Zko),e(Kp,Kko),e(z,eSo),e(z,e_),e(e_,nbe),e(nbe,oSo),e(e_,rSo),e(e_,gz),e(gz,tSo),e(e_,aSo),e(z,nSo),e(z,o_),e(o_,sbe),e(sbe,sSo),e(o_,lSo),e(o_,hz),e(hz,iSo),e(o_,dSo),e(z,mSo),e(z,r_),e(r_,lbe),e(lbe,cSo),e(r_,fSo),e(r_,uz),e(uz,gSo),e(r_,hSo),e(z,uSo),e(z,t_),e(t_,ibe),e(ibe,pSo),e(t_,_So),e(t_,pz),e(pz,bSo),e(t_,vSo),e(z,FSo),e(z,a_),e(a_,dbe),e(dbe,TSo),e(a_,MSo),e(a_,_z),e(_z,ESo),e(a_,CSo),e(z,wSo),e(z,n_),e(n_,mbe),e(mbe,ASo),e(n_,LSo),e(n_,bz),e(bz,ySo),e(n_,xSo),e(z,$So),e(z,s_),e(s_,cbe),e(cbe,kSo),e(s_,SSo),e(s_,vz),e(vz,RSo),e(s_,PSo),e(z,BSo),e(z,l_),e(l_,fbe),e(fbe,ISo),e(l_,NSo),e(l_,Fz),e(Fz,qSo),e(l_,jSo),e(z,DSo),e(z,i_),e(i_,gbe),e(gbe,GSo),e(i_,OSo),e(i_,Tz),e(Tz,VSo),e(i_,XSo),e(z,zSo),e(z,d_),e(d_,hbe),e(hbe,QSo),e(d_,WSo),e(d_,Mz),e(Mz,USo),e(d_,HSo),e(z,JSo),e(z,m_),e(m_,ube),e(ube,YSo),e(m_,ZSo),e(m_,Ez),e(Ez,KSo),e(m_,eRo),e(z,oRo),e(z,c_),e(c_,pbe),e(pbe,rRo),e(c_,tRo),e(c_,Cz),e(Cz,aRo),e(c_,nRo),e(z,sRo),e(z,f_),e(f_,_be),e(_be,lRo),e(f_,iRo),e(f_,wz),e(wz,dRo),e(f_,mRo),e(z,cRo),e(z,g_),e(g_,bbe),e(bbe,fRo),e(g_,gRo),e(g_,Az),e(Az,hRo),e(g_,uRo),e(z,pRo),e(z,h_),e(h_,vbe),e(vbe,_Ro),e(h_,bRo),e(h_,Lz),e(Lz,vRo),e(h_,FRo),e(z,TRo),e(z,u_),e(u_,Fbe),e(Fbe,MRo),e(u_,ERo),e(u_,yz),e(yz,CRo),e(u_,wRo),e(z,ARo),e(z,p_),e(p_,Tbe),e(Tbe,LRo),e(p_,yRo),e(p_,xz),e(xz,xRo),e(p_,$Ro),e(z,kRo),e(z,__),e(__,Mbe),e(Mbe,SRo),e(__,RRo),e(__,$z),e($z,PRo),e(__,BRo),e(z,IRo),e(z,b_),e(b_,Ebe),e(Ebe,NRo),e(b_,qRo),e(b_,kz),e(kz,jRo),e(b_,DRo),e(z,GRo),e(z,v_),e(v_,Cbe),e(Cbe,ORo),e(v_,VRo),e(v_,Sz),e(Sz,XRo),e(v_,zRo),e(eo,QRo),M(F_,eo,null),e(eo,WRo),M(T_,eo,null),e(No,URo),e(No,M_),M(Dk,M_,null),e(M_,HRo),e(M_,wbe),e(wbe,JRo),b(c,dio,_),b(c,qd,_),e(qd,E_),e(E_,Abe),M(Gk,Abe,null),e(qd,YRo),e(qd,Lbe),e(Lbe,ZRo),b(c,mio,_),b(c,qo,_),M(Ok,qo,null),e(qo,KRo),e(qo,Vk),e(Vk,ePo),e(Vk,Rz),e(Rz,oPo),e(Vk,rPo),e(qo,tPo),e(qo,Xk),e(Xk,aPo),e(Xk,ybe),e(ybe,nPo),e(Xk,sPo),e(qo,lPo),e(qo,oo),M(zk,oo,null),e(oo,iPo),e(oo,xbe),e(xbe,dPo),e(oo,mPo),e(oo,fn),e(fn,cPo),e(fn,$be),e($be,fPo),e(fn,gPo),e(fn,kbe),e(kbe,hPo),e(fn,uPo),e(fn,Sbe),e(Sbe,pPo),e(fn,_Po),e(oo,bPo),e(oo,oe),e(oe,C_),e(C_,Rbe),e(Rbe,vPo),e(C_,FPo),e(C_,Pz),e(Pz,TPo),e(C_,MPo),e(oe,EPo),e(oe,w_),e(w_,Pbe),e(Pbe,CPo),e(w_,wPo),e(w_,Bz),e(Bz,APo),e(w_,LPo),e(oe,yPo),e(oe,A_),e(A_,Bbe),e(Bbe,xPo),e(A_,$Po),e(A_,Iz),e(Iz,kPo),e(A_,SPo),e(oe,RPo),e(oe,L_),e(L_,Ibe),e(Ibe,PPo),e(L_,BPo),e(L_,Nz),e(Nz,IPo),e(L_,NPo),e(oe,qPo),e(oe,y_),e(y_,Nbe),e(Nbe,jPo),e(y_,DPo),e(y_,qz),e(qz,GPo),e(y_,OPo),e(oe,VPo),e(oe,x_),e(x_,qbe),e(qbe,XPo),e(x_,zPo),e(x_,jz),e(jz,QPo),e(x_,WPo),e(oe,UPo),e(oe,$_),e($_,jbe),e(jbe,HPo),e($_,JPo),e($_,Dz),e(Dz,YPo),e($_,ZPo),e(oe,KPo),e(oe,k_),e(k_,Dbe),e(Dbe,eBo),e(k_,oBo),e(k_,Gz),e(Gz,rBo),e(k_,tBo),e(oe,aBo),e(oe,S_),e(S_,Gbe),e(Gbe,nBo),e(S_,sBo),e(S_,Oz),e(Oz,lBo),e(S_,iBo),e(oe,dBo),e(oe,R_),e(R_,Obe),e(Obe,mBo),e(R_,cBo),e(R_,Vz),e(Vz,fBo),e(R_,gBo),e(oe,hBo),e(oe,P_),e(P_,Vbe),e(Vbe,uBo),e(P_,pBo),e(P_,Xz),e(Xz,_Bo),e(P_,bBo),e(oe,vBo),e(oe,B_),e(B_,Xbe),e(Xbe,FBo),e(B_,TBo),e(B_,zz),e(zz,MBo),e(B_,EBo),e(oe,CBo),e(oe,I_),e(I_,zbe),e(zbe,wBo),e(I_,ABo),e(I_,Qz),e(Qz,LBo),e(I_,yBo),e(oe,xBo),e(oe,N_),e(N_,Qbe),e(Qbe,$Bo),e(N_,kBo),e(N_,Wz),e(Wz,SBo),e(N_,RBo),e(oe,PBo),e(oe,q_),e(q_,Wbe),e(Wbe,BBo),e(q_,IBo),e(q_,Uz),e(Uz,NBo),e(q_,qBo),e(oe,jBo),e(oe,j_),e(j_,Ube),e(Ube,DBo),e(j_,GBo),e(j_,Hz),e(Hz,OBo),e(j_,VBo),e(oe,XBo),e(oe,D_),e(D_,Hbe),e(Hbe,zBo),e(D_,QBo),e(D_,Jz),e(Jz,WBo),e(D_,UBo),e(oe,HBo),e(oe,G_),e(G_,Jbe),e(Jbe,JBo),e(G_,YBo),e(G_,Yz),e(Yz,ZBo),e(G_,KBo),e(oe,eIo),e(oe,O_),e(O_,Ybe),e(Ybe,oIo),e(O_,rIo),e(O_,Zz),e(Zz,tIo),e(O_,aIo),e(oe,nIo),e(oe,V_),e(V_,Zbe),e(Zbe,sIo),e(V_,lIo),e(V_,Kz),e(Kz,iIo),e(V_,dIo),e(oe,mIo),e(oe,X_),e(X_,Kbe),e(Kbe,cIo),e(X_,fIo),e(X_,eQ),e(eQ,gIo),e(X_,hIo),e(oe,uIo),e(oe,z_),e(z_,eve),e(eve,pIo),e(z_,_Io),e(z_,oQ),e(oQ,bIo),e(z_,vIo),e(oe,FIo),e(oe,Q_),e(Q_,ove),e(ove,TIo),e(Q_,MIo),e(Q_,rQ),e(rQ,EIo),e(Q_,CIo),e(oe,wIo),e(oe,W_),e(W_,rve),e(rve,AIo),e(W_,LIo),e(W_,tQ),e(tQ,yIo),e(W_,xIo),e(oe,$Io),e(oe,U_),e(U_,tve),e(tve,kIo),e(U_,SIo),e(U_,aQ),e(aQ,RIo),e(U_,PIo),e(oe,BIo),e(oe,H_),e(H_,ave),e(ave,IIo),e(H_,NIo),e(H_,nQ),e(nQ,qIo),e(H_,jIo),e(oe,DIo),e(oe,J_),e(J_,nve),e(nve,GIo),e(J_,OIo),e(J_,sQ),e(sQ,VIo),e(J_,XIo),e(oe,zIo),e(oe,Y_),e(Y_,sve),e(sve,QIo),e(Y_,WIo),e(Y_,lQ),e(lQ,UIo),e(Y_,HIo),e(oe,JIo),e(oe,Z_),e(Z_,lve),e(lve,YIo),e(Z_,ZIo),e(Z_,iQ),e(iQ,KIo),e(Z_,eNo),e(oe,oNo),e(oe,K_),e(K_,ive),e(ive,rNo),e(K_,tNo),e(K_,dQ),e(dQ,aNo),e(K_,nNo),e(oo,sNo),M(e1,oo,null),e(oo,lNo),M(o1,oo,null),e(qo,iNo),e(qo,r1),M(Qk,r1,null),e(r1,dNo),e(r1,dve),e(dve,mNo),b(c,cio,_),b(c,jd,_),e(jd,t1),e(t1,mve),M(Wk,mve,null),e(jd,cNo),e(jd,cve),e(cve,fNo),b(c,fio,_),b(c,jo,_),M(Uk,jo,null),e(jo,gNo),e(jo,Hk),e(Hk,hNo),e(Hk,mQ),e(mQ,uNo),e(Hk,pNo),e(jo,_No),e(jo,Jk),e(Jk,bNo),e(Jk,fve),e(fve,vNo),e(Jk,FNo),e(jo,TNo),e(jo,ro),M(Yk,ro,null),e(ro,MNo),e(ro,gve),e(gve,ENo),e(ro,CNo),e(ro,Dd),e(Dd,wNo),e(Dd,hve),e(hve,ANo),e(Dd,LNo),e(Dd,uve),e(uve,yNo),e(Dd,xNo),e(ro,$No),e(ro,ie),e(ie,a1),e(a1,pve),e(pve,kNo),e(a1,SNo),e(a1,cQ),e(cQ,RNo),e(a1,PNo),e(ie,BNo),e(ie,n1),e(n1,_ve),e(_ve,INo),e(n1,NNo),e(n1,fQ),e(fQ,qNo),e(n1,jNo),e(ie,DNo),e(ie,s1),e(s1,bve),e(bve,GNo),e(s1,ONo),e(s1,gQ),e(gQ,VNo),e(s1,XNo),e(ie,zNo),e(ie,l1),e(l1,vve),e(vve,QNo),e(l1,WNo),e(l1,hQ),e(hQ,UNo),e(l1,HNo),e(ie,JNo),e(ie,i1),e(i1,Fve),e(Fve,YNo),e(i1,ZNo),e(i1,uQ),e(uQ,KNo),e(i1,eqo),e(ie,oqo),e(ie,d1),e(d1,Tve),e(Tve,rqo),e(d1,tqo),e(d1,pQ),e(pQ,aqo),e(d1,nqo),e(ie,sqo),e(ie,m1),e(m1,Mve),e(Mve,lqo),e(m1,iqo),e(m1,_Q),e(_Q,dqo),e(m1,mqo),e(ie,cqo),e(ie,c1),e(c1,Eve),e(Eve,fqo),e(c1,gqo),e(c1,bQ),e(bQ,hqo),e(c1,uqo),e(ie,pqo),e(ie,f1),e(f1,Cve),e(Cve,_qo),e(f1,bqo),e(f1,vQ),e(vQ,vqo),e(f1,Fqo),e(ie,Tqo),e(ie,g1),e(g1,wve),e(wve,Mqo),e(g1,Eqo),e(g1,FQ),e(FQ,Cqo),e(g1,wqo),e(ie,Aqo),e(ie,h1),e(h1,Ave),e(Ave,Lqo),e(h1,yqo),e(h1,TQ),e(TQ,xqo),e(h1,$qo),e(ie,kqo),e(ie,u1),e(u1,Lve),e(Lve,Sqo),e(u1,Rqo),e(u1,MQ),e(MQ,Pqo),e(u1,Bqo),e(ie,Iqo),e(ie,p1),e(p1,yve),e(yve,Nqo),e(p1,qqo),e(p1,EQ),e(EQ,jqo),e(p1,Dqo),e(ie,Gqo),e(ie,_1),e(_1,xve),e(xve,Oqo),e(_1,Vqo),e(_1,CQ),e(CQ,Xqo),e(_1,zqo),e(ie,Qqo),e(ie,b1),e(b1,$ve),e($ve,Wqo),e(b1,Uqo),e(b1,wQ),e(wQ,Hqo),e(b1,Jqo),e(ie,Yqo),e(ie,v1),e(v1,kve),e(kve,Zqo),e(v1,Kqo),e(v1,AQ),e(AQ,ejo),e(v1,ojo),e(ie,rjo),e(ie,F1),e(F1,Sve),e(Sve,tjo),e(F1,ajo),e(F1,LQ),e(LQ,njo),e(F1,sjo),e(ie,ljo),e(ie,T1),e(T1,Rve),e(Rve,ijo),e(T1,djo),e(T1,yQ),e(yQ,mjo),e(T1,cjo),e(ie,fjo),e(ie,M1),e(M1,Pve),e(Pve,gjo),e(M1,hjo),e(M1,xQ),e(xQ,ujo),e(M1,pjo),e(ie,_jo),e(ie,E1),e(E1,Bve),e(Bve,bjo),e(E1,vjo),e(E1,$Q),e($Q,Fjo),e(E1,Tjo),e(ie,Mjo),e(ie,C1),e(C1,Ive),e(Ive,Ejo),e(C1,Cjo),e(C1,kQ),e(kQ,wjo),e(C1,Ajo),e(ie,Ljo),e(ie,w1),e(w1,Nve),e(Nve,yjo),e(w1,xjo),e(w1,SQ),e(SQ,$jo),e(w1,kjo),e(ie,Sjo),e(ie,A1),e(A1,qve),e(qve,Rjo),e(A1,Pjo),e(A1,RQ),e(RQ,Bjo),e(A1,Ijo),e(ro,Njo),M(L1,ro,null),e(ro,qjo),M(y1,ro,null),e(jo,jjo),e(jo,x1),M(Zk,x1,null),e(x1,Djo),e(x1,jve),e(jve,Gjo),b(c,gio,_),b(c,Gd,_),e(Gd,$1),e($1,Dve),M(Kk,Dve,null),e(Gd,Ojo),e(Gd,Gve),e(Gve,Vjo),b(c,hio,_),b(c,Do,_),M(eS,Do,null),e(Do,Xjo),e(Do,Od),e(Od,zjo),e(Od,PQ),e(PQ,Qjo),e(Od,Wjo),e(Od,BQ),e(BQ,Ujo),e(Od,Hjo),e(Do,Jjo),e(Do,oS),e(oS,Yjo),e(oS,Ove),e(Ove,Zjo),e(oS,Kjo),e(Do,eDo),e(Do,At),M(rS,At,null),e(At,oDo),e(At,Vve),e(Vve,rDo),e(At,tDo),e(At,Vd),e(Vd,aDo),e(Vd,Xve),e(Xve,nDo),e(Vd,sDo),e(Vd,IQ),e(IQ,lDo),e(Vd,iDo),e(At,dDo),M(k1,At,null),e(Do,mDo),e(Do,to),M(tS,to,null),e(to,cDo),e(to,zve),e(zve,fDo),e(to,gDo),e(to,gn),e(gn,hDo),e(gn,Qve),e(Qve,uDo),e(gn,pDo),e(gn,Wve),e(Wve,_Do),e(gn,bDo),e(gn,Uve),e(Uve,vDo),e(gn,FDo),e(to,TDo),e(to,y),e(y,S1),e(S1,Hve),e(Hve,MDo),e(S1,EDo),e(S1,NQ),e(NQ,CDo),e(S1,wDo),e(y,ADo),e(y,R1),e(R1,Jve),e(Jve,LDo),e(R1,yDo),e(R1,qQ),e(qQ,xDo),e(R1,$Do),e(y,kDo),e(y,P1),e(P1,Yve),e(Yve,SDo),e(P1,RDo),e(P1,jQ),e(jQ,PDo),e(P1,BDo),e(y,IDo),e(y,B1),e(B1,Zve),e(Zve,NDo),e(B1,qDo),e(B1,DQ),e(DQ,jDo),e(B1,DDo),e(y,GDo),e(y,I1),e(I1,Kve),e(Kve,ODo),e(I1,VDo),e(I1,GQ),e(GQ,XDo),e(I1,zDo),e(y,QDo),e(y,N1),e(N1,eFe),e(eFe,WDo),e(N1,UDo),e(N1,OQ),e(OQ,HDo),e(N1,JDo),e(y,YDo),e(y,q1),e(q1,oFe),e(oFe,ZDo),e(q1,KDo),e(q1,VQ),e(VQ,eGo),e(q1,oGo),e(y,rGo),e(y,j1),e(j1,rFe),e(rFe,tGo),e(j1,aGo),e(j1,XQ),e(XQ,nGo),e(j1,sGo),e(y,lGo),e(y,D1),e(D1,tFe),e(tFe,iGo),e(D1,dGo),e(D1,zQ),e(zQ,mGo),e(D1,cGo),e(y,fGo),e(y,G1),e(G1,aFe),e(aFe,gGo),e(G1,hGo),e(G1,QQ),e(QQ,uGo),e(G1,pGo),e(y,_Go),e(y,O1),e(O1,nFe),e(nFe,bGo),e(O1,vGo),e(O1,WQ),e(WQ,FGo),e(O1,TGo),e(y,MGo),e(y,V1),e(V1,sFe),e(sFe,EGo),e(V1,CGo),e(V1,UQ),e(UQ,wGo),e(V1,AGo),e(y,LGo),e(y,X1),e(X1,lFe),e(lFe,yGo),e(X1,xGo),e(X1,HQ),e(HQ,$Go),e(X1,kGo),e(y,SGo),e(y,z1),e(z1,iFe),e(iFe,RGo),e(z1,PGo),e(z1,JQ),e(JQ,BGo),e(z1,IGo),e(y,NGo),e(y,Q1),e(Q1,dFe),e(dFe,qGo),e(Q1,jGo),e(Q1,YQ),e(YQ,DGo),e(Q1,GGo),e(y,OGo),e(y,W1),e(W1,mFe),e(mFe,VGo),e(W1,XGo),e(W1,ZQ),e(ZQ,zGo),e(W1,QGo),e(y,WGo),e(y,U1),e(U1,cFe),e(cFe,UGo),e(U1,HGo),e(U1,KQ),e(KQ,JGo),e(U1,YGo),e(y,ZGo),e(y,H1),e(H1,fFe),e(fFe,KGo),e(H1,eOo),e(H1,eW),e(eW,oOo),e(H1,rOo),e(y,tOo),e(y,J1),e(J1,gFe),e(gFe,aOo),e(J1,nOo),e(J1,oW),e(oW,sOo),e(J1,lOo),e(y,iOo),e(y,Y1),e(Y1,hFe),e(hFe,dOo),e(Y1,mOo),e(Y1,rW),e(rW,cOo),e(Y1,fOo),e(y,gOo),e(y,Z1),e(Z1,uFe),e(uFe,hOo),e(Z1,uOo),e(Z1,tW),e(tW,pOo),e(Z1,_Oo),e(y,bOo),e(y,K1),e(K1,pFe),e(pFe,vOo),e(K1,FOo),e(K1,aW),e(aW,TOo),e(K1,MOo),e(y,EOo),e(y,e2),e(e2,_Fe),e(_Fe,COo),e(e2,wOo),e(e2,nW),e(nW,AOo),e(e2,LOo),e(y,yOo),e(y,o2),e(o2,bFe),e(bFe,xOo),e(o2,$Oo),e(o2,sW),e(sW,kOo),e(o2,SOo),e(y,ROo),e(y,r2),e(r2,vFe),e(vFe,POo),e(r2,BOo),e(r2,lW),e(lW,IOo),e(r2,NOo),e(y,qOo),e(y,t2),e(t2,FFe),e(FFe,jOo),e(t2,DOo),e(t2,iW),e(iW,GOo),e(t2,OOo),e(y,VOo),e(y,a2),e(a2,TFe),e(TFe,XOo),e(a2,zOo),e(a2,dW),e(dW,QOo),e(a2,WOo),e(y,UOo),e(y,n2),e(n2,MFe),e(MFe,HOo),e(n2,JOo),e(n2,mW),e(mW,YOo),e(n2,ZOo),e(y,KOo),e(y,s2),e(s2,EFe),e(EFe,eVo),e(s2,oVo),e(s2,cW),e(cW,rVo),e(s2,tVo),e(y,aVo),e(y,l2),e(l2,CFe),e(CFe,nVo),e(l2,sVo),e(l2,fW),e(fW,lVo),e(l2,iVo),e(y,dVo),e(y,i2),e(i2,wFe),e(wFe,mVo),e(i2,cVo),e(i2,gW),e(gW,fVo),e(i2,gVo),e(y,hVo),e(y,d2),e(d2,AFe),e(AFe,uVo),e(d2,pVo),e(d2,hW),e(hW,_Vo),e(d2,bVo),e(y,vVo),e(y,m2),e(m2,LFe),e(LFe,FVo),e(m2,TVo),e(m2,uW),e(uW,MVo),e(m2,EVo),e(y,CVo),e(y,c2),e(c2,yFe),e(yFe,wVo),e(c2,AVo),e(c2,pW),e(pW,LVo),e(c2,yVo),e(y,xVo),e(y,f2),e(f2,xFe),e(xFe,$Vo),e(f2,kVo),e(f2,_W),e(_W,SVo),e(f2,RVo),e(y,PVo),e(y,g2),e(g2,$Fe),e($Fe,BVo),e(g2,IVo),e(g2,bW),e(bW,NVo),e(g2,qVo),e(y,jVo),e(y,h2),e(h2,kFe),e(kFe,DVo),e(h2,GVo),e(h2,vW),e(vW,OVo),e(h2,VVo),e(y,XVo),e(y,u2),e(u2,SFe),e(SFe,zVo),e(u2,QVo),e(u2,FW),e(FW,WVo),e(u2,UVo),e(y,HVo),e(y,p2),e(p2,RFe),e(RFe,JVo),e(p2,YVo),e(p2,TW),e(TW,ZVo),e(p2,KVo),e(y,eXo),e(y,_2),e(_2,PFe),e(PFe,oXo),e(_2,rXo),e(_2,MW),e(MW,tXo),e(_2,aXo),e(y,nXo),e(y,Nl),e(Nl,BFe),e(BFe,sXo),e(Nl,lXo),e(Nl,EW),e(EW,iXo),e(Nl,dXo),e(Nl,CW),e(CW,mXo),e(Nl,cXo),e(y,fXo),e(y,b2),e(b2,IFe),e(IFe,gXo),e(b2,hXo),e(b2,wW),e(wW,uXo),e(b2,pXo),e(y,_Xo),e(y,v2),e(v2,NFe),e(NFe,bXo),e(v2,vXo),e(v2,AW),e(AW,FXo),e(v2,TXo),e(y,MXo),e(y,F2),e(F2,qFe),e(qFe,EXo),e(F2,CXo),e(F2,LW),e(LW,wXo),e(F2,AXo),e(y,LXo),e(y,T2),e(T2,jFe),e(jFe,yXo),e(T2,xXo),e(T2,yW),e(yW,$Xo),e(T2,kXo),e(y,SXo),e(y,M2),e(M2,DFe),e(DFe,RXo),e(M2,PXo),e(M2,xW),e(xW,BXo),e(M2,IXo),e(y,NXo),e(y,E2),e(E2,GFe),e(GFe,qXo),e(E2,jXo),e(E2,$W),e($W,DXo),e(E2,GXo),e(y,OXo),e(y,C2),e(C2,OFe),e(OFe,VXo),e(C2,XXo),e(C2,kW),e(kW,zXo),e(C2,QXo),e(y,WXo),e(y,w2),e(w2,VFe),e(VFe,UXo),e(w2,HXo),e(w2,SW),e(SW,JXo),e(w2,YXo),e(y,ZXo),e(y,A2),e(A2,XFe),e(XFe,KXo),e(A2,ezo),e(A2,RW),e(RW,ozo),e(A2,rzo),e(y,tzo),e(y,L2),e(L2,zFe),e(zFe,azo),e(L2,nzo),e(L2,PW),e(PW,szo),e(L2,lzo),e(y,izo),e(y,y2),e(y2,QFe),e(QFe,dzo),e(y2,mzo),e(y2,BW),e(BW,czo),e(y2,fzo),e(y,gzo),e(y,x2),e(x2,WFe),e(WFe,hzo),e(x2,uzo),e(x2,IW),e(IW,pzo),e(x2,_zo),e(y,bzo),e(y,$2),e($2,UFe),e(UFe,vzo),e($2,Fzo),e($2,NW),e(NW,Tzo),e($2,Mzo),e(y,Ezo),e(y,k2),e(k2,HFe),e(HFe,Czo),e(k2,wzo),e(k2,qW),e(qW,Azo),e(k2,Lzo),e(y,yzo),e(y,S2),e(S2,JFe),e(JFe,xzo),e(S2,$zo),e(S2,jW),e(jW,kzo),e(S2,Szo),e(y,Rzo),e(y,R2),e(R2,YFe),e(YFe,Pzo),e(R2,Bzo),e(R2,DW),e(DW,Izo),e(R2,Nzo),e(y,qzo),e(y,P2),e(P2,ZFe),e(ZFe,jzo),e(P2,Dzo),e(P2,GW),e(GW,Gzo),e(P2,Ozo),e(y,Vzo),e(y,B2),e(B2,KFe),e(KFe,Xzo),e(B2,zzo),e(B2,OW),e(OW,Qzo),e(B2,Wzo),e(y,Uzo),e(y,I2),e(I2,eTe),e(eTe,Hzo),e(I2,Jzo),e(I2,VW),e(VW,Yzo),e(I2,Zzo),e(y,Kzo),e(y,N2),e(N2,oTe),e(oTe,eQo),e(N2,oQo),e(N2,XW),e(XW,rQo),e(N2,tQo),e(y,aQo),e(y,q2),e(q2,rTe),e(rTe,nQo),e(q2,sQo),e(q2,zW),e(zW,lQo),e(q2,iQo),e(y,dQo),e(y,j2),e(j2,tTe),e(tTe,mQo),e(j2,cQo),e(j2,QW),e(QW,fQo),e(j2,gQo),e(y,hQo),e(y,D2),e(D2,aTe),e(aTe,uQo),e(D2,pQo),e(D2,WW),e(WW,_Qo),e(D2,bQo),e(y,vQo),e(y,G2),e(G2,nTe),e(nTe,FQo),e(G2,TQo),e(G2,UW),e(UW,MQo),e(G2,EQo),e(y,CQo),e(y,O2),e(O2,sTe),e(sTe,wQo),e(O2,AQo),e(O2,HW),e(HW,LQo),e(O2,yQo),e(y,xQo),e(y,V2),e(V2,lTe),e(lTe,$Qo),e(V2,kQo),e(V2,JW),e(JW,SQo),e(V2,RQo),e(y,PQo),e(y,X2),e(X2,iTe),e(iTe,BQo),e(X2,IQo),e(X2,YW),e(YW,NQo),e(X2,qQo),e(y,jQo),e(y,z2),e(z2,dTe),e(dTe,DQo),e(z2,GQo),e(z2,ZW),e(ZW,OQo),e(z2,VQo),e(y,XQo),e(y,Q2),e(Q2,mTe),e(mTe,zQo),e(Q2,QQo),e(Q2,KW),e(KW,WQo),e(Q2,UQo),e(y,HQo),e(y,W2),e(W2,cTe),e(cTe,JQo),e(W2,YQo),e(W2,eU),e(eU,ZQo),e(W2,KQo),e(y,eWo),e(y,U2),e(U2,fTe),e(fTe,oWo),e(U2,rWo),e(U2,oU),e(oU,tWo),e(U2,aWo),e(y,nWo),e(y,H2),e(H2,gTe),e(gTe,sWo),e(H2,lWo),e(H2,rU),e(rU,iWo),e(H2,dWo),e(y,mWo),e(y,J2),e(J2,hTe),e(hTe,cWo),e(J2,fWo),e(J2,tU),e(tU,gWo),e(J2,hWo),e(y,uWo),e(y,Y2),e(Y2,uTe),e(uTe,pWo),e(Y2,_Wo),e(Y2,aU),e(aU,bWo),e(Y2,vWo),e(y,FWo),e(y,Z2),e(Z2,pTe),e(pTe,TWo),e(Z2,MWo),e(Z2,nU),e(nU,EWo),e(Z2,CWo),e(y,wWo),e(y,K2),e(K2,_Te),e(_Te,AWo),e(K2,LWo),e(K2,sU),e(sU,yWo),e(K2,xWo),e(y,$Wo),e(y,eb),e(eb,bTe),e(bTe,kWo),e(eb,SWo),e(eb,lU),e(lU,RWo),e(eb,PWo),e(y,BWo),e(y,ob),e(ob,vTe),e(vTe,IWo),e(ob,NWo),e(ob,iU),e(iU,qWo),e(ob,jWo),e(y,DWo),e(y,rb),e(rb,FTe),e(FTe,GWo),e(rb,OWo),e(rb,dU),e(dU,VWo),e(rb,XWo),e(y,zWo),e(y,tb),e(tb,TTe),e(TTe,QWo),e(tb,WWo),e(tb,mU),e(mU,UWo),e(tb,HWo),e(y,JWo),e(y,ab),e(ab,MTe),e(MTe,YWo),e(ab,ZWo),e(ab,cU),e(cU,KWo),e(ab,eUo),e(y,oUo),e(y,nb),e(nb,ETe),e(ETe,rUo),e(nb,tUo),e(nb,fU),e(fU,aUo),e(nb,nUo),e(y,sUo),e(y,sb),e(sb,CTe),e(CTe,lUo),e(sb,iUo),e(sb,gU),e(gU,dUo),e(sb,mUo),e(y,cUo),e(y,lb),e(lb,wTe),e(wTe,fUo),e(lb,gUo),e(lb,hU),e(hU,hUo),e(lb,uUo),e(y,pUo),e(y,ib),e(ib,ATe),e(ATe,_Uo),e(ib,bUo),e(ib,uU),e(uU,vUo),e(ib,FUo),e(y,TUo),e(y,db),e(db,LTe),e(LTe,MUo),e(db,EUo),e(db,pU),e(pU,CUo),e(db,wUo),e(y,AUo),e(y,mb),e(mb,yTe),e(yTe,LUo),e(mb,yUo),e(mb,_U),e(_U,xUo),e(mb,$Uo),e(y,kUo),e(y,cb),e(cb,xTe),e(xTe,SUo),e(cb,RUo),e(cb,bU),e(bU,PUo),e(cb,BUo),e(y,IUo),e(y,fb),e(fb,$Te),e($Te,NUo),e(fb,qUo),e(fb,vU),e(vU,jUo),e(fb,DUo),e(y,GUo),e(y,gb),e(gb,kTe),e(kTe,OUo),e(gb,VUo),e(gb,FU),e(FU,XUo),e(gb,zUo),e(y,QUo),e(y,hb),e(hb,STe),e(STe,WUo),e(hb,UUo),e(hb,TU),e(TU,HUo),e(hb,JUo),e(y,YUo),e(y,ub),e(ub,RTe),e(RTe,ZUo),e(ub,KUo),e(ub,MU),e(MU,eHo),e(ub,oHo),e(y,rHo),e(y,pb),e(pb,PTe),e(PTe,tHo),e(pb,aHo),e(pb,EU),e(EU,nHo),e(pb,sHo),e(y,lHo),e(y,_b),e(_b,BTe),e(BTe,iHo),e(_b,dHo),e(_b,CU),e(CU,mHo),e(_b,cHo),e(y,fHo),e(y,bb),e(bb,ITe),e(ITe,gHo),e(bb,hHo),e(bb,wU),e(wU,uHo),e(bb,pHo),e(y,_Ho),e(y,vb),e(vb,NTe),e(NTe,bHo),e(vb,vHo),e(vb,AU),e(AU,FHo),e(vb,THo),e(y,MHo),e(y,Fb),e(Fb,qTe),e(qTe,EHo),e(Fb,CHo),e(Fb,LU),e(LU,wHo),e(Fb,AHo),e(y,LHo),e(y,Tb),e(Tb,jTe),e(jTe,yHo),e(Tb,xHo),e(Tb,yU),e(yU,$Ho),e(Tb,kHo),e(y,SHo),e(y,Mb),e(Mb,DTe),e(DTe,RHo),e(Mb,PHo),e(Mb,xU),e(xU,BHo),e(Mb,IHo),e(y,NHo),e(y,Eb),e(Eb,GTe),e(GTe,qHo),e(Eb,jHo),e(Eb,$U),e($U,DHo),e(Eb,GHo),e(y,OHo),e(y,Cb),e(Cb,OTe),e(OTe,VHo),e(Cb,XHo),e(Cb,kU),e(kU,zHo),e(Cb,QHo),e(y,WHo),e(y,wb),e(wb,VTe),e(VTe,UHo),e(wb,HHo),e(wb,SU),e(SU,JHo),e(wb,YHo),e(y,ZHo),e(y,Ab),e(Ab,XTe),e(XTe,KHo),e(Ab,eJo),e(Ab,RU),e(RU,oJo),e(Ab,rJo),e(y,tJo),e(y,Lb),e(Lb,zTe),e(zTe,aJo),e(Lb,nJo),e(Lb,PU),e(PU,sJo),e(Lb,lJo),e(y,iJo),e(y,yb),e(yb,QTe),e(QTe,dJo),e(yb,mJo),e(yb,BU),e(BU,cJo),e(yb,fJo),e(y,gJo),e(y,xb),e(xb,WTe),e(WTe,hJo),e(xb,uJo),e(xb,IU),e(IU,pJo),e(xb,_Jo),e(y,bJo),e(y,$b),e($b,UTe),e(UTe,vJo),e($b,FJo),e($b,NU),e(NU,TJo),e($b,MJo),e(y,EJo),e(y,kb),e(kb,HTe),e(HTe,CJo),e(kb,wJo),e(kb,qU),e(qU,AJo),e(kb,LJo),e(y,yJo),e(y,Sb),e(Sb,JTe),e(JTe,xJo),e(Sb,$Jo),e(Sb,jU),e(jU,kJo),e(Sb,SJo),e(y,RJo),e(y,Rb),e(Rb,YTe),e(YTe,PJo),e(Rb,BJo),e(Rb,DU),e(DU,IJo),e(Rb,NJo),e(y,qJo),e(y,Pb),e(Pb,ZTe),e(ZTe,jJo),e(Pb,DJo),e(Pb,GU),e(GU,GJo),e(Pb,OJo),e(y,VJo),e(y,Bb),e(Bb,KTe),e(KTe,XJo),e(Bb,zJo),e(Bb,OU),e(OU,QJo),e(Bb,WJo),e(y,UJo),e(y,Ib),e(Ib,eMe),e(eMe,HJo),e(Ib,JJo),e(Ib,VU),e(VU,YJo),e(Ib,ZJo),e(y,KJo),e(y,Nb),e(Nb,oMe),e(oMe,eYo),e(Nb,oYo),e(Nb,XU),e(XU,rYo),e(Nb,tYo),e(y,aYo),e(y,qb),e(qb,rMe),e(rMe,nYo),e(qb,sYo),e(qb,zU),e(zU,lYo),e(qb,iYo),e(y,dYo),e(y,jb),e(jb,tMe),e(tMe,mYo),e(jb,cYo),e(jb,QU),e(QU,fYo),e(jb,gYo),e(y,hYo),e(y,Db),e(Db,aMe),e(aMe,uYo),e(Db,pYo),e(Db,WU),e(WU,_Yo),e(Db,bYo),e(y,vYo),e(y,Gb),e(Gb,nMe),e(nMe,FYo),e(Gb,TYo),e(Gb,UU),e(UU,MYo),e(Gb,EYo),e(y,CYo),e(y,Ob),e(Ob,sMe),e(sMe,wYo),e(Ob,AYo),e(Ob,HU),e(HU,LYo),e(Ob,yYo),e(y,xYo),e(y,Vb),e(Vb,lMe),e(lMe,$Yo),e(Vb,kYo),e(Vb,JU),e(JU,SYo),e(Vb,RYo),e(y,PYo),e(y,Xb),e(Xb,iMe),e(iMe,BYo),e(Xb,IYo),e(Xb,YU),e(YU,NYo),e(Xb,qYo),e(y,jYo),e(y,zb),e(zb,dMe),e(dMe,DYo),e(zb,GYo),e(zb,ZU),e(ZU,OYo),e(zb,VYo),e(y,XYo),e(y,Qb),e(Qb,mMe),e(mMe,zYo),e(Qb,QYo),e(Qb,KU),e(KU,WYo),e(Qb,UYo),e(y,HYo),e(y,Wb),e(Wb,cMe),e(cMe,JYo),e(Wb,YYo),e(Wb,eH),e(eH,ZYo),e(Wb,KYo),e(y,eZo),e(y,Ub),e(Ub,fMe),e(fMe,oZo),e(Ub,rZo),e(Ub,oH),e(oH,tZo),e(Ub,aZo),e(y,nZo),e(y,Hb),e(Hb,gMe),e(gMe,sZo),e(Hb,lZo),e(Hb,rH),e(rH,iZo),e(Hb,dZo),e(y,mZo),e(y,Jb),e(Jb,hMe),e(hMe,cZo),e(Jb,fZo),e(Jb,tH),e(tH,gZo),e(Jb,hZo),e(y,uZo),e(y,Yb),e(Yb,uMe),e(uMe,pZo),e(Yb,_Zo),e(Yb,aH),e(aH,bZo),e(Yb,vZo),e(y,FZo),e(y,Zb),e(Zb,pMe),e(pMe,TZo),e(Zb,MZo),e(Zb,nH),e(nH,EZo),e(Zb,CZo),e(y,wZo),e(y,Kb),e(Kb,_Me),e(_Me,AZo),e(Kb,LZo),e(Kb,sH),e(sH,yZo),e(Kb,xZo),e(y,$Zo),e(y,ev),e(ev,bMe),e(bMe,kZo),e(ev,SZo),e(ev,lH),e(lH,RZo),e(ev,PZo),e(y,BZo),e(y,ov),e(ov,vMe),e(vMe,IZo),e(ov,NZo),e(ov,iH),e(iH,qZo),e(ov,jZo),e(to,DZo),e(to,rv),e(rv,GZo),e(rv,FMe),e(FMe,OZo),e(rv,VZo),e(rv,TMe),e(TMe,XZo),e(to,zZo),M(tv,to,null),b(c,uio,_),b(c,Xd,_),e(Xd,av),e(av,MMe),M(aS,MMe,null),e(Xd,QZo),e(Xd,EMe),e(EMe,WZo),b(c,pio,_),b(c,Go,_),M(nS,Go,null),e(Go,UZo),e(Go,zd),e(zd,HZo),e(zd,dH),e(dH,JZo),e(zd,YZo),e(zd,mH),e(mH,ZZo),e(zd,KZo),e(Go,eKo),e(Go,sS),e(sS,oKo),e(sS,CMe),e(CMe,rKo),e(sS,tKo),e(Go,aKo),e(Go,Lt),M(lS,Lt,null),e(Lt,nKo),e(Lt,wMe),e(wMe,sKo),e(Lt,lKo),e(Lt,Qd),e(Qd,iKo),e(Qd,AMe),e(AMe,dKo),e(Qd,mKo),e(Qd,cH),e(cH,cKo),e(Qd,fKo),e(Lt,gKo),M(nv,Lt,null),e(Go,hKo),e(Go,ao),M(iS,ao,null),e(ao,uKo),e(ao,LMe),e(LMe,pKo),e(ao,_Ko),e(ao,hn),e(hn,bKo),e(hn,yMe),e(yMe,vKo),e(hn,FKo),e(hn,xMe),e(xMe,TKo),e(hn,MKo),e(hn,$Me),e($Me,EKo),e(hn,CKo),e(ao,wKo),e(ao,G),e(G,sv),e(sv,kMe),e(kMe,AKo),e(sv,LKo),e(sv,fH),e(fH,yKo),e(sv,xKo),e(G,$Ko),e(G,lv),e(lv,SMe),e(SMe,kKo),e(lv,SKo),e(lv,gH),e(gH,RKo),e(lv,PKo),e(G,BKo),e(G,iv),e(iv,RMe),e(RMe,IKo),e(iv,NKo),e(iv,hH),e(hH,qKo),e(iv,jKo),e(G,DKo),e(G,dv),e(dv,PMe),e(PMe,GKo),e(dv,OKo),e(dv,uH),e(uH,VKo),e(dv,XKo),e(G,zKo),e(G,mv),e(mv,BMe),e(BMe,QKo),e(mv,WKo),e(mv,pH),e(pH,UKo),e(mv,HKo),e(G,JKo),e(G,cv),e(cv,IMe),e(IMe,YKo),e(cv,ZKo),e(cv,_H),e(_H,KKo),e(cv,eer),e(G,oer),e(G,fv),e(fv,NMe),e(NMe,rer),e(fv,ter),e(fv,bH),e(bH,aer),e(fv,ner),e(G,ser),e(G,gv),e(gv,qMe),e(qMe,ler),e(gv,ier),e(gv,vH),e(vH,der),e(gv,mer),e(G,cer),e(G,hv),e(hv,jMe),e(jMe,fer),e(hv,ger),e(hv,FH),e(FH,her),e(hv,uer),e(G,per),e(G,uv),e(uv,DMe),e(DMe,_er),e(uv,ber),e(uv,TH),e(TH,ver),e(uv,Fer),e(G,Ter),e(G,pv),e(pv,GMe),e(GMe,Mer),e(pv,Eer),e(pv,MH),e(MH,Cer),e(pv,wer),e(G,Aer),e(G,_v),e(_v,OMe),e(OMe,Ler),e(_v,yer),e(_v,EH),e(EH,xer),e(_v,$er),e(G,ker),e(G,bv),e(bv,VMe),e(VMe,Ser),e(bv,Rer),e(bv,CH),e(CH,Per),e(bv,Ber),e(G,Ier),e(G,vv),e(vv,XMe),e(XMe,Ner),e(vv,qer),e(vv,wH),e(wH,jer),e(vv,Der),e(G,Ger),e(G,Fv),e(Fv,zMe),e(zMe,Oer),e(Fv,Ver),e(Fv,AH),e(AH,Xer),e(Fv,zer),e(G,Qer),e(G,Tv),e(Tv,QMe),e(QMe,Wer),e(Tv,Uer),e(Tv,LH),e(LH,Her),e(Tv,Jer),e(G,Yer),e(G,Mv),e(Mv,WMe),e(WMe,Zer),e(Mv,Ker),e(Mv,yH),e(yH,eor),e(Mv,oor),e(G,ror),e(G,Ev),e(Ev,UMe),e(UMe,tor),e(Ev,aor),e(Ev,xH),e(xH,nor),e(Ev,sor),e(G,lor),e(G,Cv),e(Cv,HMe),e(HMe,ior),e(Cv,dor),e(Cv,$H),e($H,mor),e(Cv,cor),e(G,gor),e(G,wv),e(wv,JMe),e(JMe,hor),e(wv,uor),e(wv,kH),e(kH,por),e(wv,_or),e(G,bor),e(G,Av),e(Av,YMe),e(YMe,vor),e(Av,For),e(Av,SH),e(SH,Tor),e(Av,Mor),e(G,Eor),e(G,Lv),e(Lv,ZMe),e(ZMe,Cor),e(Lv,wor),e(Lv,RH),e(RH,Aor),e(Lv,Lor),e(G,yor),e(G,yv),e(yv,KMe),e(KMe,xor),e(yv,$or),e(yv,PH),e(PH,kor),e(yv,Sor),e(G,Ror),e(G,xv),e(xv,eEe),e(eEe,Por),e(xv,Bor),e(xv,BH),e(BH,Ior),e(xv,Nor),e(G,qor),e(G,$v),e($v,oEe),e(oEe,jor),e($v,Dor),e($v,IH),e(IH,Gor),e($v,Oor),e(G,Vor),e(G,kv),e(kv,rEe),e(rEe,Xor),e(kv,zor),e(kv,NH),e(NH,Qor),e(kv,Wor),e(G,Uor),e(G,Sv),e(Sv,tEe),e(tEe,Hor),e(Sv,Jor),e(Sv,qH),e(qH,Yor),e(Sv,Zor),e(G,Kor),e(G,Rv),e(Rv,aEe),e(aEe,err),e(Rv,orr),e(Rv,jH),e(jH,rrr),e(Rv,trr),e(G,arr),e(G,Pv),e(Pv,nEe),e(nEe,nrr),e(Pv,srr),e(Pv,DH),e(DH,lrr),e(Pv,irr),e(G,drr),e(G,Bv),e(Bv,sEe),e(sEe,mrr),e(Bv,crr),e(Bv,GH),e(GH,frr),e(Bv,grr),e(G,hrr),e(G,Iv),e(Iv,lEe),e(lEe,urr),e(Iv,prr),e(Iv,OH),e(OH,_rr),e(Iv,brr),e(G,vrr),e(G,Nv),e(Nv,iEe),e(iEe,Frr),e(Nv,Trr),e(Nv,VH),e(VH,Mrr),e(Nv,Err),e(G,Crr),e(G,qv),e(qv,dEe),e(dEe,wrr),e(qv,Arr),e(qv,XH),e(XH,Lrr),e(qv,yrr),e(G,xrr),e(G,jv),e(jv,mEe),e(mEe,$rr),e(jv,krr),e(jv,zH),e(zH,Srr),e(jv,Rrr),e(G,Prr),e(G,Dv),e(Dv,cEe),e(cEe,Brr),e(Dv,Irr),e(Dv,QH),e(QH,Nrr),e(Dv,qrr),e(G,jrr),e(G,Gv),e(Gv,fEe),e(fEe,Drr),e(Gv,Grr),e(Gv,WH),e(WH,Orr),e(Gv,Vrr),e(G,Xrr),e(G,Ov),e(Ov,gEe),e(gEe,zrr),e(Ov,Qrr),e(Ov,UH),e(UH,Wrr),e(Ov,Urr),e(G,Hrr),e(G,Vv),e(Vv,hEe),e(hEe,Jrr),e(Vv,Yrr),e(Vv,HH),e(HH,Zrr),e(Vv,Krr),e(G,etr),e(G,Xv),e(Xv,uEe),e(uEe,otr),e(Xv,rtr),e(Xv,JH),e(JH,ttr),e(Xv,atr),e(G,ntr),e(G,zv),e(zv,pEe),e(pEe,str),e(zv,ltr),e(zv,YH),e(YH,itr),e(zv,dtr),e(G,mtr),e(G,Qv),e(Qv,_Ee),e(_Ee,ctr),e(Qv,ftr),e(Qv,ZH),e(ZH,gtr),e(Qv,htr),e(G,utr),e(G,Wv),e(Wv,bEe),e(bEe,ptr),e(Wv,_tr),e(Wv,KH),e(KH,btr),e(Wv,vtr),e(G,Ftr),e(G,Uv),e(Uv,vEe),e(vEe,Ttr),e(Uv,Mtr),e(Uv,eJ),e(eJ,Etr),e(Uv,Ctr),e(G,wtr),e(G,Hv),e(Hv,FEe),e(FEe,Atr),e(Hv,Ltr),e(Hv,oJ),e(oJ,ytr),e(Hv,xtr),e(G,$tr),e(G,Jv),e(Jv,TEe),e(TEe,ktr),e(Jv,Str),e(Jv,rJ),e(rJ,Rtr),e(Jv,Ptr),e(G,Btr),e(G,Yv),e(Yv,MEe),e(MEe,Itr),e(Yv,Ntr),e(Yv,tJ),e(tJ,qtr),e(Yv,jtr),e(G,Dtr),e(G,Zv),e(Zv,EEe),e(EEe,Gtr),e(Zv,Otr),e(Zv,aJ),e(aJ,Vtr),e(Zv,Xtr),e(G,ztr),e(G,Kv),e(Kv,CEe),e(CEe,Qtr),e(Kv,Wtr),e(Kv,nJ),e(nJ,Utr),e(Kv,Htr),e(G,Jtr),e(G,eF),e(eF,wEe),e(wEe,Ytr),e(eF,Ztr),e(eF,sJ),e(sJ,Ktr),e(eF,ear),e(ao,oar),e(ao,oF),e(oF,rar),e(oF,AEe),e(AEe,tar),e(oF,aar),e(oF,LEe),e(LEe,nar),e(ao,sar),M(rF,ao,null),b(c,_io,_),b(c,Wd,_),e(Wd,tF),e(tF,yEe),M(dS,yEe,null),e(Wd,lar),e(Wd,xEe),e(xEe,iar),b(c,bio,_),b(c,Oo,_),M(mS,Oo,null),e(Oo,dar),e(Oo,Ud),e(Ud,mar),e(Ud,lJ),e(lJ,car),e(Ud,far),e(Ud,iJ),e(iJ,gar),e(Ud,har),e(Oo,uar),e(Oo,cS),e(cS,par),e(cS,$Ee),e($Ee,_ar),e(cS,bar),e(Oo,Far),e(Oo,yt),M(fS,yt,null),e(yt,Tar),e(yt,kEe),e(kEe,Mar),e(yt,Ear),e(yt,Hd),e(Hd,Car),e(Hd,SEe),e(SEe,war),e(Hd,Aar),e(Hd,dJ),e(dJ,Lar),e(Hd,yar),e(yt,xar),M(aF,yt,null),e(Oo,$ar),e(Oo,no),M(gS,no,null),e(no,kar),e(no,REe),e(REe,Sar),e(no,Rar),e(no,un),e(un,Par),e(un,PEe),e(PEe,Bar),e(un,Iar),e(un,BEe),e(BEe,Nar),e(un,qar),e(un,IEe),e(IEe,jar),e(un,Dar),e(no,Gar),e(no,W),e(W,nF),e(nF,NEe),e(NEe,Oar),e(nF,Var),e(nF,mJ),e(mJ,Xar),e(nF,zar),e(W,Qar),e(W,sF),e(sF,qEe),e(qEe,War),e(sF,Uar),e(sF,cJ),e(cJ,Har),e(sF,Jar),e(W,Yar),e(W,lF),e(lF,jEe),e(jEe,Zar),e(lF,Kar),e(lF,fJ),e(fJ,enr),e(lF,onr),e(W,rnr),e(W,iF),e(iF,DEe),e(DEe,tnr),e(iF,anr),e(iF,gJ),e(gJ,nnr),e(iF,snr),e(W,lnr),e(W,dF),e(dF,GEe),e(GEe,inr),e(dF,dnr),e(dF,hJ),e(hJ,mnr),e(dF,cnr),e(W,fnr),e(W,mF),e(mF,OEe),e(OEe,gnr),e(mF,hnr),e(mF,uJ),e(uJ,unr),e(mF,pnr),e(W,_nr),e(W,cF),e(cF,VEe),e(VEe,bnr),e(cF,vnr),e(cF,pJ),e(pJ,Fnr),e(cF,Tnr),e(W,Mnr),e(W,fF),e(fF,XEe),e(XEe,Enr),e(fF,Cnr),e(fF,_J),e(_J,wnr),e(fF,Anr),e(W,Lnr),e(W,gF),e(gF,zEe),e(zEe,ynr),e(gF,xnr),e(gF,bJ),e(bJ,$nr),e(gF,knr),e(W,Snr),e(W,hF),e(hF,QEe),e(QEe,Rnr),e(hF,Pnr),e(hF,vJ),e(vJ,Bnr),e(hF,Inr),e(W,Nnr),e(W,uF),e(uF,WEe),e(WEe,qnr),e(uF,jnr),e(uF,FJ),e(FJ,Dnr),e(uF,Gnr),e(W,Onr),e(W,pF),e(pF,UEe),e(UEe,Vnr),e(pF,Xnr),e(pF,TJ),e(TJ,znr),e(pF,Qnr),e(W,Wnr),e(W,_F),e(_F,HEe),e(HEe,Unr),e(_F,Hnr),e(_F,MJ),e(MJ,Jnr),e(_F,Ynr),e(W,Znr),e(W,bF),e(bF,JEe),e(JEe,Knr),e(bF,esr),e(bF,EJ),e(EJ,osr),e(bF,rsr),e(W,tsr),e(W,vF),e(vF,YEe),e(YEe,asr),e(vF,nsr),e(vF,CJ),e(CJ,ssr),e(vF,lsr),e(W,isr),e(W,FF),e(FF,ZEe),e(ZEe,dsr),e(FF,msr),e(FF,wJ),e(wJ,csr),e(FF,fsr),e(W,gsr),e(W,TF),e(TF,KEe),e(KEe,hsr),e(TF,usr),e(TF,AJ),e(AJ,psr),e(TF,_sr),e(W,bsr),e(W,MF),e(MF,e4e),e(e4e,vsr),e(MF,Fsr),e(MF,LJ),e(LJ,Tsr),e(MF,Msr),e(W,Esr),e(W,EF),e(EF,o4e),e(o4e,Csr),e(EF,wsr),e(EF,yJ),e(yJ,Asr),e(EF,Lsr),e(W,ysr),e(W,CF),e(CF,r4e),e(r4e,xsr),e(CF,$sr),e(CF,xJ),e(xJ,ksr),e(CF,Ssr),e(W,Rsr),e(W,wF),e(wF,t4e),e(t4e,Psr),e(wF,Bsr),e(wF,$J),e($J,Isr),e(wF,Nsr),e(W,qsr),e(W,AF),e(AF,a4e),e(a4e,jsr),e(AF,Dsr),e(AF,kJ),e(kJ,Gsr),e(AF,Osr),e(W,Vsr),e(W,LF),e(LF,n4e),e(n4e,Xsr),e(LF,zsr),e(LF,SJ),e(SJ,Qsr),e(LF,Wsr),e(W,Usr),e(W,yF),e(yF,s4e),e(s4e,Hsr),e(yF,Jsr),e(yF,RJ),e(RJ,Ysr),e(yF,Zsr),e(W,Ksr),e(W,xF),e(xF,l4e),e(l4e,elr),e(xF,olr),e(xF,PJ),e(PJ,rlr),e(xF,tlr),e(W,alr),e(W,$F),e($F,i4e),e(i4e,nlr),e($F,slr),e($F,BJ),e(BJ,llr),e($F,ilr),e(W,dlr),e(W,kF),e(kF,d4e),e(d4e,mlr),e(kF,clr),e(kF,IJ),e(IJ,flr),e(kF,glr),e(W,hlr),e(W,SF),e(SF,m4e),e(m4e,ulr),e(SF,plr),e(SF,NJ),e(NJ,_lr),e(SF,blr),e(W,vlr),e(W,RF),e(RF,c4e),e(c4e,Flr),e(RF,Tlr),e(RF,qJ),e(qJ,Mlr),e(RF,Elr),e(W,Clr),e(W,PF),e(PF,f4e),e(f4e,wlr),e(PF,Alr),e(PF,jJ),e(jJ,Llr),e(PF,ylr),e(W,xlr),e(W,BF),e(BF,g4e),e(g4e,$lr),e(BF,klr),e(BF,DJ),e(DJ,Slr),e(BF,Rlr),e(W,Plr),e(W,IF),e(IF,h4e),e(h4e,Blr),e(IF,Ilr),e(IF,GJ),e(GJ,Nlr),e(IF,qlr),e(W,jlr),e(W,NF),e(NF,u4e),e(u4e,Dlr),e(NF,Glr),e(NF,OJ),e(OJ,Olr),e(NF,Vlr),e(W,Xlr),e(W,qF),e(qF,p4e),e(p4e,zlr),e(qF,Qlr),e(qF,VJ),e(VJ,Wlr),e(qF,Ulr),e(W,Hlr),e(W,jF),e(jF,_4e),e(_4e,Jlr),e(jF,Ylr),e(jF,XJ),e(XJ,Zlr),e(jF,Klr),e(W,eir),e(W,DF),e(DF,b4e),e(b4e,oir),e(DF,rir),e(DF,zJ),e(zJ,tir),e(DF,air),e(W,nir),e(W,GF),e(GF,v4e),e(v4e,sir),e(GF,lir),e(GF,QJ),e(QJ,iir),e(GF,dir),e(W,mir),e(W,OF),e(OF,F4e),e(F4e,cir),e(OF,fir),e(OF,WJ),e(WJ,gir),e(OF,hir),e(W,uir),e(W,VF),e(VF,T4e),e(T4e,pir),e(VF,_ir),e(VF,UJ),e(UJ,bir),e(VF,vir),e(W,Fir),e(W,XF),e(XF,M4e),e(M4e,Tir),e(XF,Mir),e(XF,HJ),e(HJ,Eir),e(XF,Cir),e(W,wir),e(W,zF),e(zF,E4e),e(E4e,Air),e(zF,Lir),e(zF,JJ),e(JJ,yir),e(zF,xir),e(W,$ir),e(W,QF),e(QF,C4e),e(C4e,kir),e(QF,Sir),e(QF,YJ),e(YJ,Rir),e(QF,Pir),e(W,Bir),e(W,WF),e(WF,w4e),e(w4e,Iir),e(WF,Nir),e(WF,ZJ),e(ZJ,qir),e(WF,jir),e(no,Dir),e(no,UF),e(UF,Gir),e(UF,A4e),e(A4e,Oir),e(UF,Vir),e(UF,L4e),e(L4e,Xir),e(no,zir),M(HF,no,null),b(c,vio,_),b(c,Jd,_),e(Jd,JF),e(JF,y4e),M(hS,y4e,null),e(Jd,Qir),e(Jd,x4e),e(x4e,Wir),b(c,Fio,_),b(c,Vo,_),M(uS,Vo,null),e(Vo,Uir),e(Vo,Yd),e(Yd,Hir),e(Yd,KJ),e(KJ,Jir),e(Yd,Yir),e(Yd,eY),e(eY,Zir),e(Yd,Kir),e(Vo,edr),e(Vo,pS),e(pS,odr),e(pS,$4e),e($4e,rdr),e(pS,tdr),e(Vo,adr),e(Vo,xt),M(_S,xt,null),e(xt,ndr),e(xt,k4e),e(k4e,sdr),e(xt,ldr),e(xt,Zd),e(Zd,idr),e(Zd,S4e),e(S4e,ddr),e(Zd,mdr),e(Zd,oY),e(oY,cdr),e(Zd,fdr),e(xt,gdr),M(YF,xt,null),e(Vo,hdr),e(Vo,so),M(bS,so,null),e(so,udr),e(so,R4e),e(R4e,pdr),e(so,_dr),e(so,pn),e(pn,bdr),e(pn,P4e),e(P4e,vdr),e(pn,Fdr),e(pn,B4e),e(B4e,Tdr),e(pn,Mdr),e(pn,I4e),e(I4e,Edr),e(pn,Cdr),e(so,wdr),e(so,vS),e(vS,ZF),e(ZF,N4e),e(N4e,Adr),e(ZF,Ldr),e(ZF,rY),e(rY,ydr),e(ZF,xdr),e(vS,$dr),e(vS,KF),e(KF,q4e),e(q4e,kdr),e(KF,Sdr),e(KF,tY),e(tY,Rdr),e(KF,Pdr),e(so,Bdr),e(so,eT),e(eT,Idr),e(eT,j4e),e(j4e,Ndr),e(eT,qdr),e(eT,D4e),e(D4e,jdr),e(so,Ddr),M(oT,so,null),b(c,Tio,_),b(c,Kd,_),e(Kd,rT),e(rT,G4e),M(FS,G4e,null),e(Kd,Gdr),e(Kd,O4e),e(O4e,Odr),b(c,Mio,_),b(c,Xo,_),M(TS,Xo,null),e(Xo,Vdr),e(Xo,em),e(em,Xdr),e(em,aY),e(aY,zdr),e(em,Qdr),e(em,nY),e(nY,Wdr),e(em,Udr),e(Xo,Hdr),e(Xo,MS),e(MS,Jdr),e(MS,V4e),e(V4e,Ydr),e(MS,Zdr),e(Xo,Kdr),e(Xo,$t),M(ES,$t,null),e($t,emr),e($t,X4e),e(X4e,omr),e($t,rmr),e($t,om),e(om,tmr),e(om,z4e),e(z4e,amr),e(om,nmr),e(om,sY),e(sY,smr),e(om,lmr),e($t,imr),M(tT,$t,null),e(Xo,dmr),e(Xo,lo),M(CS,lo,null),e(lo,mmr),e(lo,Q4e),e(Q4e,cmr),e(lo,fmr),e(lo,_n),e(_n,gmr),e(_n,W4e),e(W4e,hmr),e(_n,umr),e(_n,U4e),e(U4e,pmr),e(_n,_mr),e(_n,H4e),e(H4e,bmr),e(_n,vmr),e(lo,Fmr),e(lo,Y),e(Y,aT),e(aT,J4e),e(J4e,Tmr),e(aT,Mmr),e(aT,lY),e(lY,Emr),e(aT,Cmr),e(Y,wmr),e(Y,nT),e(nT,Y4e),e(Y4e,Amr),e(nT,Lmr),e(nT,iY),e(iY,ymr),e(nT,xmr),e(Y,$mr),e(Y,sT),e(sT,Z4e),e(Z4e,kmr),e(sT,Smr),e(sT,dY),e(dY,Rmr),e(sT,Pmr),e(Y,Bmr),e(Y,lT),e(lT,K4e),e(K4e,Imr),e(lT,Nmr),e(lT,mY),e(mY,qmr),e(lT,jmr),e(Y,Dmr),e(Y,iT),e(iT,eCe),e(eCe,Gmr),e(iT,Omr),e(iT,cY),e(cY,Vmr),e(iT,Xmr),e(Y,zmr),e(Y,dT),e(dT,oCe),e(oCe,Qmr),e(dT,Wmr),e(dT,fY),e(fY,Umr),e(dT,Hmr),e(Y,Jmr),e(Y,mT),e(mT,rCe),e(rCe,Ymr),e(mT,Zmr),e(mT,gY),e(gY,Kmr),e(mT,ecr),e(Y,ocr),e(Y,cT),e(cT,tCe),e(tCe,rcr),e(cT,tcr),e(cT,hY),e(hY,acr),e(cT,ncr),e(Y,scr),e(Y,fT),e(fT,aCe),e(aCe,lcr),e(fT,icr),e(fT,uY),e(uY,dcr),e(fT,mcr),e(Y,ccr),e(Y,gT),e(gT,nCe),e(nCe,fcr),e(gT,gcr),e(gT,pY),e(pY,hcr),e(gT,ucr),e(Y,pcr),e(Y,hT),e(hT,sCe),e(sCe,_cr),e(hT,bcr),e(hT,_Y),e(_Y,vcr),e(hT,Fcr),e(Y,Tcr),e(Y,uT),e(uT,lCe),e(lCe,Mcr),e(uT,Ecr),e(uT,bY),e(bY,Ccr),e(uT,wcr),e(Y,Acr),e(Y,pT),e(pT,iCe),e(iCe,Lcr),e(pT,ycr),e(pT,vY),e(vY,xcr),e(pT,$cr),e(Y,kcr),e(Y,_T),e(_T,dCe),e(dCe,Scr),e(_T,Rcr),e(_T,FY),e(FY,Pcr),e(_T,Bcr),e(Y,Icr),e(Y,bT),e(bT,mCe),e(mCe,Ncr),e(bT,qcr),e(bT,TY),e(TY,jcr),e(bT,Dcr),e(Y,Gcr),e(Y,vT),e(vT,cCe),e(cCe,Ocr),e(vT,Vcr),e(vT,MY),e(MY,Xcr),e(vT,zcr),e(Y,Qcr),e(Y,FT),e(FT,fCe),e(fCe,Wcr),e(FT,Ucr),e(FT,EY),e(EY,Hcr),e(FT,Jcr),e(Y,Ycr),e(Y,TT),e(TT,gCe),e(gCe,Zcr),e(TT,Kcr),e(TT,CY),e(CY,efr),e(TT,ofr),e(Y,rfr),e(Y,MT),e(MT,hCe),e(hCe,tfr),e(MT,afr),e(MT,wY),e(wY,nfr),e(MT,sfr),e(Y,lfr),e(Y,ET),e(ET,uCe),e(uCe,ifr),e(ET,dfr),e(ET,AY),e(AY,mfr),e(ET,cfr),e(Y,ffr),e(Y,CT),e(CT,pCe),e(pCe,gfr),e(CT,hfr),e(CT,LY),e(LY,ufr),e(CT,pfr),e(Y,_fr),e(Y,wT),e(wT,_Ce),e(_Ce,bfr),e(wT,vfr),e(wT,yY),e(yY,Ffr),e(wT,Tfr),e(Y,Mfr),e(Y,AT),e(AT,bCe),e(bCe,Efr),e(AT,Cfr),e(AT,xY),e(xY,wfr),e(AT,Afr),e(Y,Lfr),e(Y,LT),e(LT,vCe),e(vCe,yfr),e(LT,xfr),e(LT,$Y),e($Y,$fr),e(LT,kfr),e(Y,Sfr),e(Y,yT),e(yT,FCe),e(FCe,Rfr),e(yT,Pfr),e(yT,kY),e(kY,Bfr),e(yT,Ifr),e(Y,Nfr),e(Y,xT),e(xT,TCe),e(TCe,qfr),e(xT,jfr),e(xT,SY),e(SY,Dfr),e(xT,Gfr),e(Y,Ofr),e(Y,$T),e($T,MCe),e(MCe,Vfr),e($T,Xfr),e($T,RY),e(RY,zfr),e($T,Qfr),e(Y,Wfr),e(Y,kT),e(kT,ECe),e(ECe,Ufr),e(kT,Hfr),e(kT,PY),e(PY,Jfr),e(kT,Yfr),e(Y,Zfr),e(Y,ST),e(ST,CCe),e(CCe,Kfr),e(ST,egr),e(ST,BY),e(BY,ogr),e(ST,rgr),e(Y,tgr),e(Y,RT),e(RT,wCe),e(wCe,agr),e(RT,ngr),e(RT,IY),e(IY,sgr),e(RT,lgr),e(Y,igr),e(Y,PT),e(PT,ACe),e(ACe,dgr),e(PT,mgr),e(PT,NY),e(NY,cgr),e(PT,fgr),e(Y,ggr),e(Y,BT),e(BT,LCe),e(LCe,hgr),e(BT,ugr),e(BT,qY),e(qY,pgr),e(BT,_gr),e(Y,bgr),e(Y,IT),e(IT,yCe),e(yCe,vgr),e(IT,Fgr),e(IT,jY),e(jY,Tgr),e(IT,Mgr),e(Y,Egr),e(Y,NT),e(NT,xCe),e(xCe,Cgr),e(NT,wgr),e(NT,DY),e(DY,Agr),e(NT,Lgr),e(Y,ygr),e(Y,qT),e(qT,$Ce),e($Ce,xgr),e(qT,$gr),e(qT,GY),e(GY,kgr),e(qT,Sgr),e(Y,Rgr),e(Y,jT),e(jT,kCe),e(kCe,Pgr),e(jT,Bgr),e(jT,SCe),e(SCe,Igr),e(jT,Ngr),e(Y,qgr),e(Y,DT),e(DT,RCe),e(RCe,jgr),e(DT,Dgr),e(DT,OY),e(OY,Ggr),e(DT,Ogr),e(Y,Vgr),e(Y,GT),e(GT,PCe),e(PCe,Xgr),e(GT,zgr),e(GT,VY),e(VY,Qgr),e(GT,Wgr),e(Y,Ugr),e(Y,OT),e(OT,BCe),e(BCe,Hgr),e(OT,Jgr),e(OT,XY),e(XY,Ygr),e(OT,Zgr),e(Y,Kgr),e(Y,VT),e(VT,ICe),e(ICe,ehr),e(VT,ohr),e(VT,zY),e(zY,rhr),e(VT,thr),e(lo,ahr),e(lo,XT),e(XT,nhr),e(XT,NCe),e(NCe,shr),e(XT,lhr),e(XT,qCe),e(qCe,ihr),e(lo,dhr),M(zT,lo,null),b(c,Eio,_),b(c,rm,_),e(rm,QT),e(QT,jCe),M(wS,jCe,null),e(rm,mhr),e(rm,DCe),e(DCe,chr),b(c,Cio,_),b(c,zo,_),M(AS,zo,null),e(zo,fhr),e(zo,tm),e(tm,ghr),e(tm,QY),e(QY,hhr),e(tm,uhr),e(tm,WY),e(WY,phr),e(tm,_hr),e(zo,bhr),e(zo,LS),e(LS,vhr),e(LS,GCe),e(GCe,Fhr),e(LS,Thr),e(zo,Mhr),e(zo,kt),M(yS,kt,null),e(kt,Ehr),e(kt,OCe),e(OCe,Chr),e(kt,whr),e(kt,am),e(am,Ahr),e(am,VCe),e(VCe,Lhr),e(am,yhr),e(am,UY),e(UY,xhr),e(am,$hr),e(kt,khr),M(WT,kt,null),e(zo,Shr),e(zo,io),M(xS,io,null),e(io,Rhr),e(io,XCe),e(XCe,Phr),e(io,Bhr),e(io,bn),e(bn,Ihr),e(bn,zCe),e(zCe,Nhr),e(bn,qhr),e(bn,QCe),e(QCe,jhr),e(bn,Dhr),e(bn,WCe),e(WCe,Ghr),e(bn,Ohr),e(io,Vhr),e(io,pe),e(pe,UT),e(UT,UCe),e(UCe,Xhr),e(UT,zhr),e(UT,HY),e(HY,Qhr),e(UT,Whr),e(pe,Uhr),e(pe,HT),e(HT,HCe),e(HCe,Hhr),e(HT,Jhr),e(HT,JY),e(JY,Yhr),e(HT,Zhr),e(pe,Khr),e(pe,JT),e(JT,JCe),e(JCe,eur),e(JT,our),e(JT,YY),e(YY,rur),e(JT,tur),e(pe,aur),e(pe,YT),e(YT,YCe),e(YCe,nur),e(YT,sur),e(YT,ZY),e(ZY,lur),e(YT,iur),e(pe,dur),e(pe,ZT),e(ZT,ZCe),e(ZCe,mur),e(ZT,cur),e(ZT,KY),e(KY,fur),e(ZT,gur),e(pe,hur),e(pe,KT),e(KT,KCe),e(KCe,uur),e(KT,pur),e(KT,eZ),e(eZ,_ur),e(KT,bur),e(pe,vur),e(pe,eM),e(eM,e3e),e(e3e,Fur),e(eM,Tur),e(eM,oZ),e(oZ,Mur),e(eM,Eur),e(pe,Cur),e(pe,oM),e(oM,o3e),e(o3e,wur),e(oM,Aur),e(oM,rZ),e(rZ,Lur),e(oM,yur),e(pe,xur),e(pe,rM),e(rM,r3e),e(r3e,$ur),e(rM,kur),e(rM,tZ),e(tZ,Sur),e(rM,Rur),e(pe,Pur),e(pe,tM),e(tM,t3e),e(t3e,Bur),e(tM,Iur),e(tM,aZ),e(aZ,Nur),e(tM,qur),e(pe,jur),e(pe,aM),e(aM,a3e),e(a3e,Dur),e(aM,Gur),e(aM,nZ),e(nZ,Our),e(aM,Vur),e(pe,Xur),e(pe,nM),e(nM,n3e),e(n3e,zur),e(nM,Qur),e(nM,sZ),e(sZ,Wur),e(nM,Uur),e(pe,Hur),e(pe,sM),e(sM,s3e),e(s3e,Jur),e(sM,Yur),e(sM,lZ),e(lZ,Zur),e(sM,Kur),e(pe,epr),e(pe,lM),e(lM,l3e),e(l3e,opr),e(lM,rpr),e(lM,iZ),e(iZ,tpr),e(lM,apr),e(pe,npr),e(pe,iM),e(iM,i3e),e(i3e,spr),e(iM,lpr),e(iM,dZ),e(dZ,ipr),e(iM,dpr),e(pe,mpr),e(pe,dM),e(dM,d3e),e(d3e,cpr),e(dM,fpr),e(dM,mZ),e(mZ,gpr),e(dM,hpr),e(pe,upr),e(pe,mM),e(mM,m3e),e(m3e,ppr),e(mM,_pr),e(mM,cZ),e(cZ,bpr),e(mM,vpr),e(pe,Fpr),e(pe,cM),e(cM,c3e),e(c3e,Tpr),e(cM,Mpr),e(cM,fZ),e(fZ,Epr),e(cM,Cpr),e(pe,wpr),e(pe,fM),e(fM,f3e),e(f3e,Apr),e(fM,Lpr),e(fM,gZ),e(gZ,ypr),e(fM,xpr),e(pe,$pr),e(pe,gM),e(gM,g3e),e(g3e,kpr),e(gM,Spr),e(gM,hZ),e(hZ,Rpr),e(gM,Ppr),e(io,Bpr),e(io,hM),e(hM,Ipr),e(hM,h3e),e(h3e,Npr),e(hM,qpr),e(hM,u3e),e(u3e,jpr),e(io,Dpr),M(uM,io,null),b(c,wio,_),b(c,nm,_),e(nm,pM),e(pM,p3e),M($S,p3e,null),e(nm,Gpr),e(nm,_3e),e(_3e,Opr),b(c,Aio,_),b(c,Qo,_),M(kS,Qo,null),e(Qo,Vpr),e(Qo,sm),e(sm,Xpr),e(sm,uZ),e(uZ,zpr),e(sm,Qpr),e(sm,pZ),e(pZ,Wpr),e(sm,Upr),e(Qo,Hpr),e(Qo,SS),e(SS,Jpr),e(SS,b3e),e(b3e,Ypr),e(SS,Zpr),e(Qo,Kpr),e(Qo,St),M(RS,St,null),e(St,e_r),e(St,v3e),e(v3e,o_r),e(St,r_r),e(St,lm),e(lm,t_r),e(lm,F3e),e(F3e,a_r),e(lm,n_r),e(lm,_Z),e(_Z,s_r),e(lm,l_r),e(St,i_r),M(_M,St,null),e(Qo,d_r),e(Qo,mo),M(PS,mo,null),e(mo,m_r),e(mo,T3e),e(T3e,c_r),e(mo,f_r),e(mo,vn),e(vn,g_r),e(vn,M3e),e(M3e,h_r),e(vn,u_r),e(vn,E3e),e(E3e,p_r),e(vn,__r),e(vn,C3e),e(C3e,b_r),e(vn,v_r),e(mo,F_r),e(mo,I),e(I,bM),e(bM,w3e),e(w3e,T_r),e(bM,M_r),e(bM,bZ),e(bZ,E_r),e(bM,C_r),e(I,w_r),e(I,vM),e(vM,A3e),e(A3e,A_r),e(vM,L_r),e(vM,vZ),e(vZ,y_r),e(vM,x_r),e(I,$_r),e(I,FM),e(FM,L3e),e(L3e,k_r),e(FM,S_r),e(FM,FZ),e(FZ,R_r),e(FM,P_r),e(I,B_r),e(I,TM),e(TM,y3e),e(y3e,I_r),e(TM,N_r),e(TM,TZ),e(TZ,q_r),e(TM,j_r),e(I,D_r),e(I,MM),e(MM,x3e),e(x3e,G_r),e(MM,O_r),e(MM,MZ),e(MZ,V_r),e(MM,X_r),e(I,z_r),e(I,EM),e(EM,$3e),e($3e,Q_r),e(EM,W_r),e(EM,EZ),e(EZ,U_r),e(EM,H_r),e(I,J_r),e(I,CM),e(CM,k3e),e(k3e,Y_r),e(CM,Z_r),e(CM,CZ),e(CZ,K_r),e(CM,e1r),e(I,o1r),e(I,wM),e(wM,S3e),e(S3e,r1r),e(wM,t1r),e(wM,wZ),e(wZ,a1r),e(wM,n1r),e(I,s1r),e(I,AM),e(AM,R3e),e(R3e,l1r),e(AM,i1r),e(AM,AZ),e(AZ,d1r),e(AM,m1r),e(I,c1r),e(I,LM),e(LM,P3e),e(P3e,f1r),e(LM,g1r),e(LM,LZ),e(LZ,h1r),e(LM,u1r),e(I,p1r),e(I,yM),e(yM,B3e),e(B3e,_1r),e(yM,b1r),e(yM,yZ),e(yZ,v1r),e(yM,F1r),e(I,T1r),e(I,xM),e(xM,I3e),e(I3e,M1r),e(xM,E1r),e(xM,xZ),e(xZ,C1r),e(xM,w1r),e(I,A1r),e(I,$M),e($M,N3e),e(N3e,L1r),e($M,y1r),e($M,$Z),e($Z,x1r),e($M,$1r),e(I,k1r),e(I,kM),e(kM,q3e),e(q3e,S1r),e(kM,R1r),e(kM,kZ),e(kZ,P1r),e(kM,B1r),e(I,I1r),e(I,SM),e(SM,j3e),e(j3e,N1r),e(SM,q1r),e(SM,SZ),e(SZ,j1r),e(SM,D1r),e(I,G1r),e(I,RM),e(RM,D3e),e(D3e,O1r),e(RM,V1r),e(RM,RZ),e(RZ,X1r),e(RM,z1r),e(I,Q1r),e(I,PM),e(PM,G3e),e(G3e,W1r),e(PM,U1r),e(PM,PZ),e(PZ,H1r),e(PM,J1r),e(I,Y1r),e(I,BM),e(BM,O3e),e(O3e,Z1r),e(BM,K1r),e(BM,BZ),e(BZ,e2r),e(BM,o2r),e(I,r2r),e(I,IM),e(IM,V3e),e(V3e,t2r),e(IM,a2r),e(IM,IZ),e(IZ,n2r),e(IM,s2r),e(I,l2r),e(I,NM),e(NM,X3e),e(X3e,i2r),e(NM,d2r),e(NM,NZ),e(NZ,m2r),e(NM,c2r),e(I,f2r),e(I,qM),e(qM,z3e),e(z3e,g2r),e(qM,h2r),e(qM,qZ),e(qZ,u2r),e(qM,p2r),e(I,_2r),e(I,jM),e(jM,Q3e),e(Q3e,b2r),e(jM,v2r),e(jM,jZ),e(jZ,F2r),e(jM,T2r),e(I,M2r),e(I,DM),e(DM,W3e),e(W3e,E2r),e(DM,C2r),e(DM,DZ),e(DZ,w2r),e(DM,A2r),e(I,L2r),e(I,GM),e(GM,U3e),e(U3e,y2r),e(GM,x2r),e(GM,GZ),e(GZ,$2r),e(GM,k2r),e(I,S2r),e(I,OM),e(OM,H3e),e(H3e,R2r),e(OM,P2r),e(OM,OZ),e(OZ,B2r),e(OM,I2r),e(I,N2r),e(I,VM),e(VM,J3e),e(J3e,q2r),e(VM,j2r),e(VM,VZ),e(VZ,D2r),e(VM,G2r),e(I,O2r),e(I,XM),e(XM,Y3e),e(Y3e,V2r),e(XM,X2r),e(XM,XZ),e(XZ,z2r),e(XM,Q2r),e(I,W2r),e(I,zM),e(zM,Z3e),e(Z3e,U2r),e(zM,H2r),e(zM,zZ),e(zZ,J2r),e(zM,Y2r),e(I,Z2r),e(I,QM),e(QM,K3e),e(K3e,K2r),e(QM,ebr),e(QM,QZ),e(QZ,obr),e(QM,rbr),e(I,tbr),e(I,WM),e(WM,e5e),e(e5e,abr),e(WM,nbr),e(WM,WZ),e(WZ,sbr),e(WM,lbr),e(I,ibr),e(I,UM),e(UM,o5e),e(o5e,dbr),e(UM,mbr),e(UM,UZ),e(UZ,cbr),e(UM,fbr),e(I,gbr),e(I,HM),e(HM,r5e),e(r5e,hbr),e(HM,ubr),e(HM,HZ),e(HZ,pbr),e(HM,_br),e(I,bbr),e(I,JM),e(JM,t5e),e(t5e,vbr),e(JM,Fbr),e(JM,JZ),e(JZ,Tbr),e(JM,Mbr),e(I,Ebr),e(I,YM),e(YM,a5e),e(a5e,Cbr),e(YM,wbr),e(YM,YZ),e(YZ,Abr),e(YM,Lbr),e(I,ybr),e(I,ZM),e(ZM,n5e),e(n5e,xbr),e(ZM,$br),e(ZM,ZZ),e(ZZ,kbr),e(ZM,Sbr),e(I,Rbr),e(I,KM),e(KM,s5e),e(s5e,Pbr),e(KM,Bbr),e(KM,KZ),e(KZ,Ibr),e(KM,Nbr),e(I,qbr),e(I,eE),e(eE,l5e),e(l5e,jbr),e(eE,Dbr),e(eE,eK),e(eK,Gbr),e(eE,Obr),e(I,Vbr),e(I,oE),e(oE,i5e),e(i5e,Xbr),e(oE,zbr),e(oE,oK),e(oK,Qbr),e(oE,Wbr),e(I,Ubr),e(I,rE),e(rE,d5e),e(d5e,Hbr),e(rE,Jbr),e(rE,rK),e(rK,Ybr),e(rE,Zbr),e(I,Kbr),e(I,tE),e(tE,m5e),e(m5e,evr),e(tE,ovr),e(tE,tK),e(tK,rvr),e(tE,tvr),e(I,avr),e(I,aE),e(aE,c5e),e(c5e,nvr),e(aE,svr),e(aE,aK),e(aK,lvr),e(aE,ivr),e(I,dvr),e(I,nE),e(nE,f5e),e(f5e,mvr),e(nE,cvr),e(nE,nK),e(nK,fvr),e(nE,gvr),e(I,hvr),e(I,sE),e(sE,g5e),e(g5e,uvr),e(sE,pvr),e(sE,sK),e(sK,_vr),e(sE,bvr),e(I,vvr),e(I,lE),e(lE,h5e),e(h5e,Fvr),e(lE,Tvr),e(lE,lK),e(lK,Mvr),e(lE,Evr),e(I,Cvr),e(I,iE),e(iE,u5e),e(u5e,wvr),e(iE,Avr),e(iE,iK),e(iK,Lvr),e(iE,yvr),e(I,xvr),e(I,dE),e(dE,p5e),e(p5e,$vr),e(dE,kvr),e(dE,dK),e(dK,Svr),e(dE,Rvr),e(I,Pvr),e(I,mE),e(mE,_5e),e(_5e,Bvr),e(mE,Ivr),e(mE,mK),e(mK,Nvr),e(mE,qvr),e(I,jvr),e(I,cE),e(cE,b5e),e(b5e,Dvr),e(cE,Gvr),e(cE,cK),e(cK,Ovr),e(cE,Vvr),e(I,Xvr),e(I,fE),e(fE,v5e),e(v5e,zvr),e(fE,Qvr),e(fE,fK),e(fK,Wvr),e(fE,Uvr),e(I,Hvr),e(I,gE),e(gE,F5e),e(F5e,Jvr),e(gE,Yvr),e(gE,gK),e(gK,Zvr),e(gE,Kvr),e(I,eFr),e(I,hE),e(hE,T5e),e(T5e,oFr),e(hE,rFr),e(hE,hK),e(hK,tFr),e(hE,aFr),e(I,nFr),e(I,uE),e(uE,M5e),e(M5e,sFr),e(uE,lFr),e(uE,uK),e(uK,iFr),e(uE,dFr),e(I,mFr),e(I,pE),e(pE,E5e),e(E5e,cFr),e(pE,fFr),e(pE,pK),e(pK,gFr),e(pE,hFr),e(I,uFr),e(I,_E),e(_E,C5e),e(C5e,pFr),e(_E,_Fr),e(_E,_K),e(_K,bFr),e(_E,vFr),e(I,FFr),e(I,bE),e(bE,w5e),e(w5e,TFr),e(bE,MFr),e(bE,bK),e(bK,EFr),e(bE,CFr),e(I,wFr),e(I,vE),e(vE,A5e),e(A5e,AFr),e(vE,LFr),e(vE,vK),e(vK,yFr),e(vE,xFr),e(I,$Fr),e(I,FE),e(FE,L5e),e(L5e,kFr),e(FE,SFr),e(FE,FK),e(FK,RFr),e(FE,PFr),e(mo,BFr),e(mo,TE),e(TE,IFr),e(TE,y5e),e(y5e,NFr),e(TE,qFr),e(TE,x5e),e(x5e,jFr),e(mo,DFr),M(ME,mo,null),b(c,Lio,_),b(c,im,_),e(im,EE),e(EE,$5e),M(BS,$5e,null),e(im,GFr),e(im,k5e),e(k5e,OFr),b(c,yio,_),b(c,Wo,_),M(IS,Wo,null),e(Wo,VFr),e(Wo,dm),e(dm,XFr),e(dm,TK),e(TK,zFr),e(dm,QFr),e(dm,MK),e(MK,WFr),e(dm,UFr),e(Wo,HFr),e(Wo,NS),e(NS,JFr),e(NS,S5e),e(S5e,YFr),e(NS,ZFr),e(Wo,KFr),e(Wo,Rt),M(qS,Rt,null),e(Rt,eTr),e(Rt,R5e),e(R5e,oTr),e(Rt,rTr),e(Rt,mm),e(mm,tTr),e(mm,P5e),e(P5e,aTr),e(mm,nTr),e(mm,EK),e(EK,sTr),e(mm,lTr),e(Rt,iTr),M(CE,Rt,null),e(Wo,dTr),e(Wo,co),M(jS,co,null),e(co,mTr),e(co,B5e),e(B5e,cTr),e(co,fTr),e(co,Fn),e(Fn,gTr),e(Fn,I5e),e(I5e,hTr),e(Fn,uTr),e(Fn,N5e),e(N5e,pTr),e(Fn,_Tr),e(Fn,q5e),e(q5e,bTr),e(Fn,vTr),e(co,FTr),e(co,K),e(K,wE),e(wE,j5e),e(j5e,TTr),e(wE,MTr),e(wE,CK),e(CK,ETr),e(wE,CTr),e(K,wTr),e(K,AE),e(AE,D5e),e(D5e,ATr),e(AE,LTr),e(AE,wK),e(wK,yTr),e(AE,xTr),e(K,$Tr),e(K,LE),e(LE,G5e),e(G5e,kTr),e(LE,STr),e(LE,AK),e(AK,RTr),e(LE,PTr),e(K,BTr),e(K,yE),e(yE,O5e),e(O5e,ITr),e(yE,NTr),e(yE,LK),e(LK,qTr),e(yE,jTr),e(K,DTr),e(K,xE),e(xE,V5e),e(V5e,GTr),e(xE,OTr),e(xE,yK),e(yK,VTr),e(xE,XTr),e(K,zTr),e(K,$E),e($E,X5e),e(X5e,QTr),e($E,WTr),e($E,xK),e(xK,UTr),e($E,HTr),e(K,JTr),e(K,kE),e(kE,z5e),e(z5e,YTr),e(kE,ZTr),e(kE,$K),e($K,KTr),e(kE,eMr),e(K,oMr),e(K,SE),e(SE,Q5e),e(Q5e,rMr),e(SE,tMr),e(SE,kK),e(kK,aMr),e(SE,nMr),e(K,sMr),e(K,RE),e(RE,W5e),e(W5e,lMr),e(RE,iMr),e(RE,SK),e(SK,dMr),e(RE,mMr),e(K,cMr),e(K,PE),e(PE,U5e),e(U5e,fMr),e(PE,gMr),e(PE,RK),e(RK,hMr),e(PE,uMr),e(K,pMr),e(K,BE),e(BE,H5e),e(H5e,_Mr),e(BE,bMr),e(BE,PK),e(PK,vMr),e(BE,FMr),e(K,TMr),e(K,IE),e(IE,J5e),e(J5e,MMr),e(IE,EMr),e(IE,BK),e(BK,CMr),e(IE,wMr),e(K,AMr),e(K,NE),e(NE,Y5e),e(Y5e,LMr),e(NE,yMr),e(NE,IK),e(IK,xMr),e(NE,$Mr),e(K,kMr),e(K,qE),e(qE,Z5e),e(Z5e,SMr),e(qE,RMr),e(qE,NK),e(NK,PMr),e(qE,BMr),e(K,IMr),e(K,jE),e(jE,K5e),e(K5e,NMr),e(jE,qMr),e(jE,qK),e(qK,jMr),e(jE,DMr),e(K,GMr),e(K,DE),e(DE,e0e),e(e0e,OMr),e(DE,VMr),e(DE,jK),e(jK,XMr),e(DE,zMr),e(K,QMr),e(K,GE),e(GE,o0e),e(o0e,WMr),e(GE,UMr),e(GE,DK),e(DK,HMr),e(GE,JMr),e(K,YMr),e(K,OE),e(OE,r0e),e(r0e,ZMr),e(OE,KMr),e(OE,GK),e(GK,eEr),e(OE,oEr),e(K,rEr),e(K,VE),e(VE,t0e),e(t0e,tEr),e(VE,aEr),e(VE,OK),e(OK,nEr),e(VE,sEr),e(K,lEr),e(K,XE),e(XE,a0e),e(a0e,iEr),e(XE,dEr),e(XE,VK),e(VK,mEr),e(XE,cEr),e(K,fEr),e(K,zE),e(zE,n0e),e(n0e,gEr),e(zE,hEr),e(zE,XK),e(XK,uEr),e(zE,pEr),e(K,_Er),e(K,QE),e(QE,s0e),e(s0e,bEr),e(QE,vEr),e(QE,zK),e(zK,FEr),e(QE,TEr),e(K,MEr),e(K,WE),e(WE,l0e),e(l0e,EEr),e(WE,CEr),e(WE,QK),e(QK,wEr),e(WE,AEr),e(K,LEr),e(K,UE),e(UE,i0e),e(i0e,yEr),e(UE,xEr),e(UE,WK),e(WK,$Er),e(UE,kEr),e(K,SEr),e(K,HE),e(HE,d0e),e(d0e,REr),e(HE,PEr),e(HE,UK),e(UK,BEr),e(HE,IEr),e(K,NEr),e(K,JE),e(JE,m0e),e(m0e,qEr),e(JE,jEr),e(JE,HK),e(HK,DEr),e(JE,GEr),e(K,OEr),e(K,YE),e(YE,c0e),e(c0e,VEr),e(YE,XEr),e(YE,JK),e(JK,zEr),e(YE,QEr),e(K,WEr),e(K,ZE),e(ZE,f0e),e(f0e,UEr),e(ZE,HEr),e(ZE,YK),e(YK,JEr),e(ZE,YEr),e(K,ZEr),e(K,KE),e(KE,g0e),e(g0e,KEr),e(KE,e4r),e(KE,ZK),e(ZK,o4r),e(KE,r4r),e(K,t4r),e(K,e4),e(e4,h0e),e(h0e,a4r),e(e4,n4r),e(e4,KK),e(KK,s4r),e(e4,l4r),e(K,i4r),e(K,o4),e(o4,u0e),e(u0e,d4r),e(o4,m4r),e(o4,eee),e(eee,c4r),e(o4,f4r),e(K,g4r),e(K,r4),e(r4,p0e),e(p0e,h4r),e(r4,u4r),e(r4,oee),e(oee,p4r),e(r4,_4r),e(K,b4r),e(K,t4),e(t4,_0e),e(_0e,v4r),e(t4,F4r),e(t4,ree),e(ree,T4r),e(t4,M4r),e(co,E4r),e(co,a4),e(a4,C4r),e(a4,b0e),e(b0e,w4r),e(a4,A4r),e(a4,v0e),e(v0e,L4r),e(co,y4r),M(n4,co,null),b(c,xio,_),b(c,cm,_),e(cm,s4),e(s4,F0e),M(DS,F0e,null),e(cm,x4r),e(cm,T0e),e(T0e,$4r),b(c,$io,_),b(c,Uo,_),M(GS,Uo,null),e(Uo,k4r),e(Uo,fm),e(fm,S4r),e(fm,tee),e(tee,R4r),e(fm,P4r),e(fm,aee),e(aee,B4r),e(fm,I4r),e(Uo,N4r),e(Uo,OS),e(OS,q4r),e(OS,M0e),e(M0e,j4r),e(OS,D4r),e(Uo,G4r),e(Uo,Pt),M(VS,Pt,null),e(Pt,O4r),e(Pt,E0e),e(E0e,V4r),e(Pt,X4r),e(Pt,gm),e(gm,z4r),e(gm,C0e),e(C0e,Q4r),e(gm,W4r),e(gm,nee),e(nee,U4r),e(gm,H4r),e(Pt,J4r),M(l4,Pt,null),e(Uo,Y4r),e(Uo,fo),M(XS,fo,null),e(fo,Z4r),e(fo,w0e),e(w0e,K4r),e(fo,eCr),e(fo,Tn),e(Tn,oCr),e(Tn,A0e),e(A0e,rCr),e(Tn,tCr),e(Tn,L0e),e(L0e,aCr),e(Tn,nCr),e(Tn,y0e),e(y0e,sCr),e(Tn,lCr),e(fo,iCr),e(fo,Ye),e(Ye,i4),e(i4,x0e),e(x0e,dCr),e(i4,mCr),e(i4,see),e(see,cCr),e(i4,fCr),e(Ye,gCr),e(Ye,d4),e(d4,$0e),e($0e,hCr),e(d4,uCr),e(d4,lee),e(lee,pCr),e(d4,_Cr),e(Ye,bCr),e(Ye,m4),e(m4,k0e),e(k0e,vCr),e(m4,FCr),e(m4,iee),e(iee,TCr),e(m4,MCr),e(Ye,ECr),e(Ye,c4),e(c4,S0e),e(S0e,CCr),e(c4,wCr),e(c4,dee),e(dee,ACr),e(c4,LCr),e(Ye,yCr),e(Ye,f4),e(f4,R0e),e(R0e,xCr),e(f4,$Cr),e(f4,mee),e(mee,kCr),e(f4,SCr),e(Ye,RCr),e(Ye,g4),e(g4,P0e),e(P0e,PCr),e(g4,BCr),e(g4,cee),e(cee,ICr),e(g4,NCr),e(Ye,qCr),e(Ye,h4),e(h4,B0e),e(B0e,jCr),e(h4,DCr),e(h4,fee),e(fee,GCr),e(h4,OCr),e(fo,VCr),e(fo,u4),e(u4,XCr),e(u4,I0e),e(I0e,zCr),e(u4,QCr),e(u4,N0e),e(N0e,WCr),e(fo,UCr),M(p4,fo,null),b(c,kio,_),b(c,hm,_),e(hm,_4),e(_4,q0e),M(zS,q0e,null),e(hm,HCr),e(hm,j0e),e(j0e,JCr),b(c,Sio,_),b(c,Ho,_),M(QS,Ho,null),e(Ho,YCr),e(Ho,um),e(um,ZCr),e(um,gee),e(gee,KCr),e(um,e3r),e(um,hee),e(hee,o3r),e(um,r3r),e(Ho,t3r),e(Ho,WS),e(WS,a3r),e(WS,D0e),e(D0e,n3r),e(WS,s3r),e(Ho,l3r),e(Ho,Bt),M(US,Bt,null),e(Bt,i3r),e(Bt,G0e),e(G0e,d3r),e(Bt,m3r),e(Bt,pm),e(pm,c3r),e(pm,O0e),e(O0e,f3r),e(pm,g3r),e(pm,uee),e(uee,h3r),e(pm,u3r),e(Bt,p3r),M(b4,Bt,null),e(Ho,_3r),e(Ho,go),M(HS,go,null),e(go,b3r),e(go,V0e),e(V0e,v3r),e(go,F3r),e(go,Mn),e(Mn,T3r),e(Mn,X0e),e(X0e,M3r),e(Mn,E3r),e(Mn,z0e),e(z0e,C3r),e(Mn,w3r),e(Mn,Q0e),e(Q0e,A3r),e(Mn,L3r),e(go,y3r),e(go,U),e(U,v4),e(v4,W0e),e(W0e,x3r),e(v4,$3r),e(v4,pee),e(pee,k3r),e(v4,S3r),e(U,R3r),e(U,F4),e(F4,U0e),e(U0e,P3r),e(F4,B3r),e(F4,_ee),e(_ee,I3r),e(F4,N3r),e(U,q3r),e(U,T4),e(T4,H0e),e(H0e,j3r),e(T4,D3r),e(T4,bee),e(bee,G3r),e(T4,O3r),e(U,V3r),e(U,M4),e(M4,J0e),e(J0e,X3r),e(M4,z3r),e(M4,vee),e(vee,Q3r),e(M4,W3r),e(U,U3r),e(U,E4),e(E4,Y0e),e(Y0e,H3r),e(E4,J3r),e(E4,Fee),e(Fee,Y3r),e(E4,Z3r),e(U,K3r),e(U,C4),e(C4,Z0e),e(Z0e,e5r),e(C4,o5r),e(C4,Tee),e(Tee,r5r),e(C4,t5r),e(U,a5r),e(U,w4),e(w4,K0e),e(K0e,n5r),e(w4,s5r),e(w4,Mee),e(Mee,l5r),e(w4,i5r),e(U,d5r),e(U,A4),e(A4,ewe),e(ewe,m5r),e(A4,c5r),e(A4,Eee),e(Eee,f5r),e(A4,g5r),e(U,h5r),e(U,L4),e(L4,owe),e(owe,u5r),e(L4,p5r),e(L4,Cee),e(Cee,_5r),e(L4,b5r),e(U,v5r),e(U,y4),e(y4,rwe),e(rwe,F5r),e(y4,T5r),e(y4,wee),e(wee,M5r),e(y4,E5r),e(U,C5r),e(U,x4),e(x4,twe),e(twe,w5r),e(x4,A5r),e(x4,Aee),e(Aee,L5r),e(x4,y5r),e(U,x5r),e(U,$4),e($4,awe),e(awe,$5r),e($4,k5r),e($4,Lee),e(Lee,S5r),e($4,R5r),e(U,P5r),e(U,k4),e(k4,nwe),e(nwe,B5r),e(k4,I5r),e(k4,yee),e(yee,N5r),e(k4,q5r),e(U,j5r),e(U,S4),e(S4,swe),e(swe,D5r),e(S4,G5r),e(S4,xee),e(xee,O5r),e(S4,V5r),e(U,X5r),e(U,R4),e(R4,lwe),e(lwe,z5r),e(R4,Q5r),e(R4,$ee),e($ee,W5r),e(R4,U5r),e(U,H5r),e(U,P4),e(P4,iwe),e(iwe,J5r),e(P4,Y5r),e(P4,kee),e(kee,Z5r),e(P4,K5r),e(U,e0r),e(U,B4),e(B4,dwe),e(dwe,o0r),e(B4,r0r),e(B4,See),e(See,t0r),e(B4,a0r),e(U,n0r),e(U,I4),e(I4,mwe),e(mwe,s0r),e(I4,l0r),e(I4,Ree),e(Ree,i0r),e(I4,d0r),e(U,m0r),e(U,N4),e(N4,cwe),e(cwe,c0r),e(N4,f0r),e(N4,Pee),e(Pee,g0r),e(N4,h0r),e(U,u0r),e(U,q4),e(q4,fwe),e(fwe,p0r),e(q4,_0r),e(q4,Bee),e(Bee,b0r),e(q4,v0r),e(U,F0r),e(U,j4),e(j4,gwe),e(gwe,T0r),e(j4,M0r),e(j4,Iee),e(Iee,E0r),e(j4,C0r),e(U,w0r),e(U,D4),e(D4,hwe),e(hwe,A0r),e(D4,L0r),e(D4,Nee),e(Nee,y0r),e(D4,x0r),e(U,$0r),e(U,G4),e(G4,uwe),e(uwe,k0r),e(G4,S0r),e(G4,qee),e(qee,R0r),e(G4,P0r),e(U,B0r),e(U,O4),e(O4,pwe),e(pwe,I0r),e(O4,N0r),e(O4,jee),e(jee,q0r),e(O4,j0r),e(U,D0r),e(U,V4),e(V4,_we),e(_we,G0r),e(V4,O0r),e(V4,Dee),e(Dee,V0r),e(V4,X0r),e(U,z0r),e(U,X4),e(X4,bwe),e(bwe,Q0r),e(X4,W0r),e(X4,Gee),e(Gee,U0r),e(X4,H0r),e(U,J0r),e(U,z4),e(z4,vwe),e(vwe,Y0r),e(z4,Z0r),e(z4,Oee),e(Oee,K0r),e(z4,ewr),e(U,owr),e(U,Q4),e(Q4,Fwe),e(Fwe,rwr),e(Q4,twr),e(Q4,Vee),e(Vee,awr),e(Q4,nwr),e(U,swr),e(U,W4),e(W4,Twe),e(Twe,lwr),e(W4,iwr),e(W4,Xee),e(Xee,dwr),e(W4,mwr),e(U,cwr),e(U,U4),e(U4,Mwe),e(Mwe,fwr),e(U4,gwr),e(U4,zee),e(zee,hwr),e(U4,uwr),e(U,pwr),e(U,H4),e(H4,Ewe),e(Ewe,_wr),e(H4,bwr),e(H4,Qee),e(Qee,vwr),e(H4,Fwr),e(U,Twr),e(U,J4),e(J4,Cwe),e(Cwe,Mwr),e(J4,Ewr),e(J4,Wee),e(Wee,Cwr),e(J4,wwr),e(U,Awr),e(U,Y4),e(Y4,wwe),e(wwe,Lwr),e(Y4,ywr),e(Y4,Uee),e(Uee,xwr),e(Y4,$wr),e(U,kwr),e(U,Z4),e(Z4,Awe),e(Awe,Swr),e(Z4,Rwr),e(Z4,Hee),e(Hee,Pwr),e(Z4,Bwr),e(U,Iwr),e(U,K4),e(K4,Lwe),e(Lwe,Nwr),e(K4,qwr),e(K4,Jee),e(Jee,jwr),e(K4,Dwr),e(U,Gwr),e(U,eC),e(eC,ywe),e(ywe,Owr),e(eC,Vwr),e(eC,Yee),e(Yee,Xwr),e(eC,zwr),e(U,Qwr),e(U,oC),e(oC,xwe),e(xwe,Wwr),e(oC,Uwr),e(oC,Zee),e(Zee,Hwr),e(oC,Jwr),e(U,Ywr),e(U,rC),e(rC,$we),e($we,Zwr),e(rC,Kwr),e(rC,Kee),e(Kee,eAr),e(rC,oAr),e(U,rAr),e(U,tC),e(tC,kwe),e(kwe,tAr),e(tC,aAr),e(tC,eoe),e(eoe,nAr),e(tC,sAr),e(U,lAr),e(U,aC),e(aC,Swe),e(Swe,iAr),e(aC,dAr),e(aC,ooe),e(ooe,mAr),e(aC,cAr),e(U,fAr),e(U,nC),e(nC,Rwe),e(Rwe,gAr),e(nC,hAr),e(nC,roe),e(roe,uAr),e(nC,pAr),e(U,_Ar),e(U,sC),e(sC,Pwe),e(Pwe,bAr),e(sC,vAr),e(sC,toe),e(toe,FAr),e(sC,TAr),e(go,MAr),e(go,lC),e(lC,EAr),e(lC,Bwe),e(Bwe,CAr),e(lC,wAr),e(lC,Iwe),e(Iwe,AAr),e(go,LAr),M(iC,go,null),b(c,Rio,_),b(c,_m,_),e(_m,dC),e(dC,Nwe),M(JS,Nwe,null),e(_m,yAr),e(_m,qwe),e(qwe,xAr),b(c,Pio,_),b(c,Jo,_),M(YS,Jo,null),e(Jo,$Ar),e(Jo,bm),e(bm,kAr),e(bm,aoe),e(aoe,SAr),e(bm,RAr),e(bm,noe),e(noe,PAr),e(bm,BAr),e(Jo,IAr),e(Jo,ZS),e(ZS,NAr),e(ZS,jwe),e(jwe,qAr),e(ZS,jAr),e(Jo,DAr),e(Jo,It),M(KS,It,null),e(It,GAr),e(It,Dwe),e(Dwe,OAr),e(It,VAr),e(It,vm),e(vm,XAr),e(vm,Gwe),e(Gwe,zAr),e(vm,QAr),e(vm,soe),e(soe,WAr),e(vm,UAr),e(It,HAr),M(mC,It,null),e(Jo,JAr),e(Jo,ho),M(eR,ho,null),e(ho,YAr),e(ho,Owe),e(Owe,ZAr),e(ho,KAr),e(ho,En),e(En,e6r),e(En,Vwe),e(Vwe,o6r),e(En,r6r),e(En,Xwe),e(Xwe,t6r),e(En,a6r),e(En,zwe),e(zwe,n6r),e(En,s6r),e(ho,l6r),e(ho,O),e(O,cC),e(cC,Qwe),e(Qwe,i6r),e(cC,d6r),e(cC,loe),e(loe,m6r),e(cC,c6r),e(O,f6r),e(O,fC),e(fC,Wwe),e(Wwe,g6r),e(fC,h6r),e(fC,ioe),e(ioe,u6r),e(fC,p6r),e(O,_6r),e(O,gC),e(gC,Uwe),e(Uwe,b6r),e(gC,v6r),e(gC,doe),e(doe,F6r),e(gC,T6r),e(O,M6r),e(O,hC),e(hC,Hwe),e(Hwe,E6r),e(hC,C6r),e(hC,moe),e(moe,w6r),e(hC,A6r),e(O,L6r),e(O,uC),e(uC,Jwe),e(Jwe,y6r),e(uC,x6r),e(uC,coe),e(coe,$6r),e(uC,k6r),e(O,S6r),e(O,pC),e(pC,Ywe),e(Ywe,R6r),e(pC,P6r),e(pC,foe),e(foe,B6r),e(pC,I6r),e(O,N6r),e(O,_C),e(_C,Zwe),e(Zwe,q6r),e(_C,j6r),e(_C,goe),e(goe,D6r),e(_C,G6r),e(O,O6r),e(O,bC),e(bC,Kwe),e(Kwe,V6r),e(bC,X6r),e(bC,hoe),e(hoe,z6r),e(bC,Q6r),e(O,W6r),e(O,vC),e(vC,eAe),e(eAe,U6r),e(vC,H6r),e(vC,uoe),e(uoe,J6r),e(vC,Y6r),e(O,Z6r),e(O,FC),e(FC,oAe),e(oAe,K6r),e(FC,e7r),e(FC,poe),e(poe,o7r),e(FC,r7r),e(O,t7r),e(O,TC),e(TC,rAe),e(rAe,a7r),e(TC,n7r),e(TC,_oe),e(_oe,s7r),e(TC,l7r),e(O,i7r),e(O,MC),e(MC,tAe),e(tAe,d7r),e(MC,m7r),e(MC,boe),e(boe,c7r),e(MC,f7r),e(O,g7r),e(O,EC),e(EC,aAe),e(aAe,h7r),e(EC,u7r),e(EC,voe),e(voe,p7r),e(EC,_7r),e(O,b7r),e(O,CC),e(CC,nAe),e(nAe,v7r),e(CC,F7r),e(CC,Foe),e(Foe,T7r),e(CC,M7r),e(O,E7r),e(O,wC),e(wC,sAe),e(sAe,C7r),e(wC,w7r),e(wC,Toe),e(Toe,A7r),e(wC,L7r),e(O,y7r),e(O,AC),e(AC,lAe),e(lAe,x7r),e(AC,$7r),e(AC,Moe),e(Moe,k7r),e(AC,S7r),e(O,R7r),e(O,LC),e(LC,iAe),e(iAe,P7r),e(LC,B7r),e(LC,Eoe),e(Eoe,I7r),e(LC,N7r),e(O,q7r),e(O,yC),e(yC,dAe),e(dAe,j7r),e(yC,D7r),e(yC,Coe),e(Coe,G7r),e(yC,O7r),e(O,V7r),e(O,xC),e(xC,mAe),e(mAe,X7r),e(xC,z7r),e(xC,woe),e(woe,Q7r),e(xC,W7r),e(O,U7r),e(O,$C),e($C,cAe),e(cAe,H7r),e($C,J7r),e($C,Aoe),e(Aoe,Y7r),e($C,Z7r),e(O,K7r),e(O,kC),e(kC,fAe),e(fAe,e8r),e(kC,o8r),e(kC,Loe),e(Loe,r8r),e(kC,t8r),e(O,a8r),e(O,SC),e(SC,gAe),e(gAe,n8r),e(SC,s8r),e(SC,yoe),e(yoe,l8r),e(SC,i8r),e(O,d8r),e(O,RC),e(RC,hAe),e(hAe,m8r),e(RC,c8r),e(RC,xoe),e(xoe,f8r),e(RC,g8r),e(O,h8r),e(O,PC),e(PC,uAe),e(uAe,u8r),e(PC,p8r),e(PC,$oe),e($oe,_8r),e(PC,b8r),e(O,v8r),e(O,BC),e(BC,pAe),e(pAe,F8r),e(BC,T8r),e(BC,koe),e(koe,M8r),e(BC,E8r),e(O,C8r),e(O,IC),e(IC,_Ae),e(_Ae,w8r),e(IC,A8r),e(IC,Soe),e(Soe,L8r),e(IC,y8r),e(O,x8r),e(O,NC),e(NC,bAe),e(bAe,$8r),e(NC,k8r),e(NC,Roe),e(Roe,S8r),e(NC,R8r),e(O,P8r),e(O,qC),e(qC,vAe),e(vAe,B8r),e(qC,I8r),e(qC,Poe),e(Poe,N8r),e(qC,q8r),e(O,j8r),e(O,jC),e(jC,FAe),e(FAe,D8r),e(jC,G8r),e(jC,Boe),e(Boe,O8r),e(jC,V8r),e(O,X8r),e(O,DC),e(DC,TAe),e(TAe,z8r),e(DC,Q8r),e(DC,Ioe),e(Ioe,W8r),e(DC,U8r),e(O,H8r),e(O,GC),e(GC,MAe),e(MAe,J8r),e(GC,Y8r),e(GC,Noe),e(Noe,Z8r),e(GC,K8r),e(O,eLr),e(O,OC),e(OC,EAe),e(EAe,oLr),e(OC,rLr),e(OC,qoe),e(qoe,tLr),e(OC,aLr),e(O,nLr),e(O,VC),e(VC,CAe),e(CAe,sLr),e(VC,lLr),e(VC,joe),e(joe,iLr),e(VC,dLr),e(O,mLr),e(O,XC),e(XC,wAe),e(wAe,cLr),e(XC,fLr),e(XC,Doe),e(Doe,gLr),e(XC,hLr),e(O,uLr),e(O,zC),e(zC,AAe),e(AAe,pLr),e(zC,_Lr),e(zC,Goe),e(Goe,bLr),e(zC,vLr),e(O,FLr),e(O,QC),e(QC,LAe),e(LAe,TLr),e(QC,MLr),e(QC,Ooe),e(Ooe,ELr),e(QC,CLr),e(O,wLr),e(O,WC),e(WC,yAe),e(yAe,ALr),e(WC,LLr),e(WC,Voe),e(Voe,yLr),e(WC,xLr),e(O,$Lr),e(O,UC),e(UC,xAe),e(xAe,kLr),e(UC,SLr),e(UC,Xoe),e(Xoe,RLr),e(UC,PLr),e(O,BLr),e(O,HC),e(HC,$Ae),e($Ae,ILr),e(HC,NLr),e(HC,zoe),e(zoe,qLr),e(HC,jLr),e(O,DLr),e(O,JC),e(JC,kAe),e(kAe,GLr),e(JC,OLr),e(JC,Qoe),e(Qoe,VLr),e(JC,XLr),e(O,zLr),e(O,YC),e(YC,SAe),e(SAe,QLr),e(YC,WLr),e(YC,Woe),e(Woe,ULr),e(YC,HLr),e(O,JLr),e(O,ZC),e(ZC,RAe),e(RAe,YLr),e(ZC,ZLr),e(ZC,Uoe),e(Uoe,KLr),e(ZC,eyr),e(O,oyr),e(O,KC),e(KC,PAe),e(PAe,ryr),e(KC,tyr),e(KC,Hoe),e(Hoe,ayr),e(KC,nyr),e(O,syr),e(O,e3),e(e3,BAe),e(BAe,lyr),e(e3,iyr),e(e3,Joe),e(Joe,dyr),e(e3,myr),e(O,cyr),e(O,o3),e(o3,IAe),e(IAe,fyr),e(o3,gyr),e(o3,Yoe),e(Yoe,hyr),e(o3,uyr),e(O,pyr),e(O,r3),e(r3,NAe),e(NAe,_yr),e(r3,byr),e(r3,Zoe),e(Zoe,vyr),e(r3,Fyr),e(O,Tyr),e(O,t3),e(t3,qAe),e(qAe,Myr),e(t3,Eyr),e(t3,Koe),e(Koe,Cyr),e(t3,wyr),e(O,Ayr),e(O,a3),e(a3,jAe),e(jAe,Lyr),e(a3,yyr),e(a3,ere),e(ere,xyr),e(a3,$yr),e(O,kyr),e(O,n3),e(n3,DAe),e(DAe,Syr),e(n3,Ryr),e(n3,ore),e(ore,Pyr),e(n3,Byr),e(ho,Iyr),e(ho,s3),e(s3,Nyr),e(s3,GAe),e(GAe,qyr),e(s3,jyr),e(s3,OAe),e(OAe,Dyr),e(ho,Gyr),M(l3,ho,null),b(c,Bio,_),b(c,Fm,_),e(Fm,i3),e(i3,VAe),M(oR,VAe,null),e(Fm,Oyr),e(Fm,XAe),e(XAe,Vyr),b(c,Iio,_),b(c,Yo,_),M(rR,Yo,null),e(Yo,Xyr),e(Yo,Tm),e(Tm,zyr),e(Tm,rre),e(rre,Qyr),e(Tm,Wyr),e(Tm,tre),e(tre,Uyr),e(Tm,Hyr),e(Yo,Jyr),e(Yo,tR),e(tR,Yyr),e(tR,zAe),e(zAe,Zyr),e(tR,Kyr),e(Yo,e9r),e(Yo,Nt),M(aR,Nt,null),e(Nt,o9r),e(Nt,QAe),e(QAe,r9r),e(Nt,t9r),e(Nt,Mm),e(Mm,a9r),e(Mm,WAe),e(WAe,n9r),e(Mm,s9r),e(Mm,are),e(are,l9r),e(Mm,i9r),e(Nt,d9r),M(d3,Nt,null),e(Yo,m9r),e(Yo,uo),M(nR,uo,null),e(uo,c9r),e(uo,UAe),e(UAe,f9r),e(uo,g9r),e(uo,Cn),e(Cn,h9r),e(Cn,HAe),e(HAe,u9r),e(Cn,p9r),e(Cn,JAe),e(JAe,_9r),e(Cn,b9r),e(Cn,YAe),e(YAe,v9r),e(Cn,F9r),e(uo,T9r),e(uo,ZAe),e(ZAe,m3),e(m3,KAe),e(KAe,M9r),e(m3,E9r),e(m3,nre),e(nre,C9r),e(m3,w9r),e(uo,A9r),e(uo,c3),e(c3,L9r),e(c3,e6e),e(e6e,y9r),e(c3,x9r),e(c3,o6e),e(o6e,$9r),e(uo,k9r),M(f3,uo,null),b(c,Nio,_),b(c,Em,_),e(Em,g3),e(g3,r6e),M(sR,r6e,null),e(Em,S9r),e(Em,t6e),e(t6e,R9r),b(c,qio,_),b(c,Zo,_),M(lR,Zo,null),e(Zo,P9r),e(Zo,Cm),e(Cm,B9r),e(Cm,sre),e(sre,I9r),e(Cm,N9r),e(Cm,lre),e(lre,q9r),e(Cm,j9r),e(Zo,D9r),e(Zo,iR),e(iR,G9r),e(iR,a6e),e(a6e,O9r),e(iR,V9r),e(Zo,X9r),e(Zo,qt),M(dR,qt,null),e(qt,z9r),e(qt,n6e),e(n6e,Q9r),e(qt,W9r),e(qt,wm),e(wm,U9r),e(wm,s6e),e(s6e,H9r),e(wm,J9r),e(wm,ire),e(ire,Y9r),e(wm,Z9r),e(qt,K9r),M(h3,qt,null),e(Zo,exr),e(Zo,po),M(mR,po,null),e(po,oxr),e(po,l6e),e(l6e,rxr),e(po,txr),e(po,wn),e(wn,axr),e(wn,i6e),e(i6e,nxr),e(wn,sxr),e(wn,d6e),e(d6e,lxr),e(wn,ixr),e(wn,m6e),e(m6e,dxr),e(wn,mxr),e(po,cxr),e(po,Am),e(Am,u3),e(u3,c6e),e(c6e,fxr),e(u3,gxr),e(u3,dre),e(dre,hxr),e(u3,uxr),e(Am,pxr),e(Am,p3),e(p3,f6e),e(f6e,_xr),e(p3,bxr),e(p3,mre),e(mre,vxr),e(p3,Fxr),e(Am,Txr),e(Am,_3),e(_3,g6e),e(g6e,Mxr),e(_3,Exr),e(_3,cre),e(cre,Cxr),e(_3,wxr),e(po,Axr),e(po,b3),e(b3,Lxr),e(b3,h6e),e(h6e,yxr),e(b3,xxr),e(b3,u6e),e(u6e,$xr),e(po,kxr),M(v3,po,null),b(c,jio,_),b(c,Lm,_),e(Lm,F3),e(F3,p6e),M(cR,p6e,null),e(Lm,Sxr),e(Lm,_6e),e(_6e,Rxr),b(c,Dio,_),b(c,Ko,_),M(fR,Ko,null),e(Ko,Pxr),e(Ko,ym),e(ym,Bxr),e(ym,fre),e(fre,Ixr),e(ym,Nxr),e(ym,gre),e(gre,qxr),e(ym,jxr),e(Ko,Dxr),e(Ko,gR),e(gR,Gxr),e(gR,b6e),e(b6e,Oxr),e(gR,Vxr),e(Ko,Xxr),e(Ko,jt),M(hR,jt,null),e(jt,zxr),e(jt,v6e),e(v6e,Qxr),e(jt,Wxr),e(jt,xm),e(xm,Uxr),e(xm,F6e),e(F6e,Hxr),e(xm,Jxr),e(xm,hre),e(hre,Yxr),e(xm,Zxr),e(jt,Kxr),M(T3,jt,null),e(Ko,e$r),e(Ko,_o),M(uR,_o,null),e(_o,o$r),e(_o,T6e),e(T6e,r$r),e(_o,t$r),e(_o,An),e(An,a$r),e(An,M6e),e(M6e,n$r),e(An,s$r),e(An,E6e),e(E6e,l$r),e(An,i$r),e(An,C6e),e(C6e,d$r),e(An,m$r),e(_o,c$r),e(_o,ve),e(ve,M3),e(M3,w6e),e(w6e,f$r),e(M3,g$r),e(M3,ure),e(ure,h$r),e(M3,u$r),e(ve,p$r),e(ve,E3),e(E3,A6e),e(A6e,_$r),e(E3,b$r),e(E3,pre),e(pre,v$r),e(E3,F$r),e(ve,T$r),e(ve,C3),e(C3,L6e),e(L6e,M$r),e(C3,E$r),e(C3,_re),e(_re,C$r),e(C3,w$r),e(ve,A$r),e(ve,w3),e(w3,y6e),e(y6e,L$r),e(w3,y$r),e(w3,bre),e(bre,x$r),e(w3,$$r),e(ve,k$r),e(ve,ql),e(ql,x6e),e(x6e,S$r),e(ql,R$r),e(ql,vre),e(vre,P$r),e(ql,B$r),e(ql,Fre),e(Fre,I$r),e(ql,N$r),e(ve,q$r),e(ve,A3),e(A3,$6e),e($6e,j$r),e(A3,D$r),e(A3,Tre),e(Tre,G$r),e(A3,O$r),e(ve,V$r),e(ve,jl),e(jl,k6e),e(k6e,X$r),e(jl,z$r),e(jl,Mre),e(Mre,Q$r),e(jl,W$r),e(jl,Ere),e(Ere,U$r),e(jl,H$r),e(ve,J$r),e(ve,L3),e(L3,S6e),e(S6e,Y$r),e(L3,Z$r),e(L3,Cre),e(Cre,K$r),e(L3,ekr),e(ve,okr),e(ve,y3),e(y3,R6e),e(R6e,rkr),e(y3,tkr),e(y3,wre),e(wre,akr),e(y3,nkr),e(ve,skr),e(ve,Dt),e(Dt,P6e),e(P6e,lkr),e(Dt,ikr),e(Dt,Are),e(Are,dkr),e(Dt,mkr),e(Dt,Lre),e(Lre,ckr),e(Dt,fkr),e(Dt,yre),e(yre,gkr),e(Dt,hkr),e(ve,ukr),e(ve,x3),e(x3,B6e),e(B6e,pkr),e(x3,_kr),e(x3,xre),e(xre,bkr),e(x3,vkr),e(ve,Fkr),e(ve,$3),e($3,I6e),e(I6e,Tkr),e($3,Mkr),e($3,$re),e($re,Ekr),e($3,Ckr),e(ve,wkr),e(ve,k3),e(k3,N6e),e(N6e,Akr),e(k3,Lkr),e(k3,kre),e(kre,ykr),e(k3,xkr),e(ve,$kr),e(ve,S3),e(S3,q6e),e(q6e,kkr),e(S3,Skr),e(S3,Sre),e(Sre,Rkr),e(S3,Pkr),e(ve,Bkr),e(ve,R3),e(R3,j6e),e(j6e,Ikr),e(R3,Nkr),e(R3,Rre),e(Rre,qkr),e(R3,jkr),e(ve,Dkr),e(ve,P3),e(P3,D6e),e(D6e,Gkr),e(P3,Okr),e(P3,Pre),e(Pre,Vkr),e(P3,Xkr),e(ve,zkr),e(ve,B3),e(B3,G6e),e(G6e,Qkr),e(B3,Wkr),e(B3,Bre),e(Bre,Ukr),e(B3,Hkr),e(ve,Jkr),e(ve,I3),e(I3,O6e),e(O6e,Ykr),e(I3,Zkr),e(I3,Ire),e(Ire,Kkr),e(I3,eSr),e(ve,oSr),e(ve,N3),e(N3,V6e),e(V6e,rSr),e(N3,tSr),e(N3,Nre),e(Nre,aSr),e(N3,nSr),e(_o,sSr),e(_o,q3),e(q3,lSr),e(q3,X6e),e(X6e,iSr),e(q3,dSr),e(q3,z6e),e(z6e,mSr),e(_o,cSr),M(j3,_o,null),b(c,Gio,_),b(c,$m,_),e($m,D3),e(D3,Q6e),M(pR,Q6e,null),e($m,fSr),e($m,W6e),e(W6e,gSr),b(c,Oio,_),b(c,er,_),M(_R,er,null),e(er,hSr),e(er,km),e(km,uSr),e(km,qre),e(qre,pSr),e(km,_Sr),e(km,jre),e(jre,bSr),e(km,vSr),e(er,FSr),e(er,bR),e(bR,TSr),e(bR,U6e),e(U6e,MSr),e(bR,ESr),e(er,CSr),e(er,Gt),M(vR,Gt,null),e(Gt,wSr),e(Gt,H6e),e(H6e,ASr),e(Gt,LSr),e(Gt,Sm),e(Sm,ySr),e(Sm,J6e),e(J6e,xSr),e(Sm,$Sr),e(Sm,Dre),e(Dre,kSr),e(Sm,SSr),e(Gt,RSr),M(G3,Gt,null),e(er,PSr),e(er,bo),M(FR,bo,null),e(bo,BSr),e(bo,Y6e),e(Y6e,ISr),e(bo,NSr),e(bo,Ln),e(Ln,qSr),e(Ln,Z6e),e(Z6e,jSr),e(Ln,DSr),e(Ln,K6e),e(K6e,GSr),e(Ln,OSr),e(Ln,e7e),e(e7e,VSr),e(Ln,XSr),e(bo,zSr),e(bo,o7e),e(o7e,O3),e(O3,r7e),e(r7e,QSr),e(O3,WSr),e(O3,Gre),e(Gre,USr),e(O3,HSr),e(bo,JSr),e(bo,V3),e(V3,YSr),e(V3,t7e),e(t7e,ZSr),e(V3,KSr),e(V3,a7e),e(a7e,eRr),e(bo,oRr),M(X3,bo,null),b(c,Vio,_),b(c,Rm,_),e(Rm,z3),e(z3,n7e),M(TR,n7e,null),e(Rm,rRr),e(Rm,s7e),e(s7e,tRr),b(c,Xio,_),b(c,or,_),M(MR,or,null),e(or,aRr),e(or,Pm),e(Pm,nRr),e(Pm,Ore),e(Ore,sRr),e(Pm,lRr),e(Pm,Vre),e(Vre,iRr),e(Pm,dRr),e(or,mRr),e(or,ER),e(ER,cRr),e(ER,l7e),e(l7e,fRr),e(ER,gRr),e(or,hRr),e(or,Ot),M(CR,Ot,null),e(Ot,uRr),e(Ot,i7e),e(i7e,pRr),e(Ot,_Rr),e(Ot,Bm),e(Bm,bRr),e(Bm,d7e),e(d7e,vRr),e(Bm,FRr),e(Bm,Xre),e(Xre,TRr),e(Bm,MRr),e(Ot,ERr),M(Q3,Ot,null),e(or,CRr),e(or,vo),M(wR,vo,null),e(vo,wRr),e(vo,m7e),e(m7e,ARr),e(vo,LRr),e(vo,yn),e(yn,yRr),e(yn,c7e),e(c7e,xRr),e(yn,$Rr),e(yn,f7e),e(f7e,kRr),e(yn,SRr),e(yn,g7e),e(g7e,RRr),e(yn,PRr),e(vo,BRr),e(vo,h7e),e(h7e,W3),e(W3,u7e),e(u7e,IRr),e(W3,NRr),e(W3,zre),e(zre,qRr),e(W3,jRr),e(vo,DRr),e(vo,U3),e(U3,GRr),e(U3,p7e),e(p7e,ORr),e(U3,VRr),e(U3,_7e),e(_7e,XRr),e(vo,zRr),M(H3,vo,null),b(c,zio,_),b(c,Im,_),e(Im,J3),e(J3,b7e),M(AR,b7e,null),e(Im,QRr),e(Im,v7e),e(v7e,WRr),b(c,Qio,_),b(c,rr,_),M(LR,rr,null),e(rr,URr),e(rr,Nm),e(Nm,HRr),e(Nm,Qre),e(Qre,JRr),e(Nm,YRr),e(Nm,Wre),e(Wre,ZRr),e(Nm,KRr),e(rr,ePr),e(rr,yR),e(yR,oPr),e(yR,F7e),e(F7e,rPr),e(yR,tPr),e(rr,aPr),e(rr,Vt),M(xR,Vt,null),e(Vt,nPr),e(Vt,T7e),e(T7e,sPr),e(Vt,lPr),e(Vt,qm),e(qm,iPr),e(qm,M7e),e(M7e,dPr),e(qm,mPr),e(qm,Ure),e(Ure,cPr),e(qm,fPr),e(Vt,gPr),M(Y3,Vt,null),e(rr,hPr),e(rr,Fo),M($R,Fo,null),e(Fo,uPr),e(Fo,E7e),e(E7e,pPr),e(Fo,_Pr),e(Fo,xn),e(xn,bPr),e(xn,C7e),e(C7e,vPr),e(xn,FPr),e(xn,w7e),e(w7e,TPr),e(xn,MPr),e(xn,A7e),e(A7e,EPr),e(xn,CPr),e(Fo,wPr),e(Fo,L7e),e(L7e,Z3),e(Z3,y7e),e(y7e,APr),e(Z3,LPr),e(Z3,Hre),e(Hre,yPr),e(Z3,xPr),e(Fo,$Pr),e(Fo,K3),e(K3,kPr),e(K3,x7e),e(x7e,SPr),e(K3,RPr),e(K3,$7e),e($7e,PPr),e(Fo,BPr),M(e5,Fo,null),b(c,Wio,_),b(c,jm,_),e(jm,o5),e(o5,k7e),M(kR,k7e,null),e(jm,IPr),e(jm,S7e),e(S7e,NPr),b(c,Uio,_),b(c,tr,_),M(SR,tr,null),e(tr,qPr),e(tr,Dm),e(Dm,jPr),e(Dm,Jre),e(Jre,DPr),e(Dm,GPr),e(Dm,Yre),e(Yre,OPr),e(Dm,VPr),e(tr,XPr),e(tr,RR),e(RR,zPr),e(RR,R7e),e(R7e,QPr),e(RR,WPr),e(tr,UPr),e(tr,Xt),M(PR,Xt,null),e(Xt,HPr),e(Xt,P7e),e(P7e,JPr),e(Xt,YPr),e(Xt,Gm),e(Gm,ZPr),e(Gm,B7e),e(B7e,KPr),e(Gm,eBr),e(Gm,Zre),e(Zre,oBr),e(Gm,rBr),e(Xt,tBr),M(r5,Xt,null),e(tr,aBr),e(tr,To),M(BR,To,null),e(To,nBr),e(To,I7e),e(I7e,sBr),e(To,lBr),e(To,$n),e($n,iBr),e($n,N7e),e(N7e,dBr),e($n,mBr),e($n,q7e),e(q7e,cBr),e($n,fBr),e($n,j7e),e(j7e,gBr),e($n,hBr),e(To,uBr),e(To,Ne),e(Ne,t5),e(t5,D7e),e(D7e,pBr),e(t5,_Br),e(t5,Kre),e(Kre,bBr),e(t5,vBr),e(Ne,FBr),e(Ne,a5),e(a5,G7e),e(G7e,TBr),e(a5,MBr),e(a5,ete),e(ete,EBr),e(a5,CBr),e(Ne,wBr),e(Ne,n5),e(n5,O7e),e(O7e,ABr),e(n5,LBr),e(n5,ote),e(ote,yBr),e(n5,xBr),e(Ne,$Br),e(Ne,s5),e(s5,V7e),e(V7e,kBr),e(s5,SBr),e(s5,rte),e(rte,RBr),e(s5,PBr),e(Ne,BBr),e(Ne,l5),e(l5,X7e),e(X7e,IBr),e(l5,NBr),e(l5,tte),e(tte,qBr),e(l5,jBr),e(Ne,DBr),e(Ne,i5),e(i5,z7e),e(z7e,GBr),e(i5,OBr),e(i5,ate),e(ate,VBr),e(i5,XBr),e(Ne,zBr),e(Ne,d5),e(d5,Q7e),e(Q7e,QBr),e(d5,WBr),e(d5,nte),e(nte,UBr),e(d5,HBr),e(Ne,JBr),e(Ne,m5),e(m5,W7e),e(W7e,YBr),e(m5,ZBr),e(m5,ste),e(ste,KBr),e(m5,eIr),e(Ne,oIr),e(Ne,c5),e(c5,U7e),e(U7e,rIr),e(c5,tIr),e(c5,lte),e(lte,aIr),e(c5,nIr),e(To,sIr),e(To,f5),e(f5,lIr),e(f5,H7e),e(H7e,iIr),e(f5,dIr),e(f5,J7e),e(J7e,mIr),e(To,cIr),M(g5,To,null),b(c,Hio,_),b(c,Om,_),e(Om,h5),e(h5,Y7e),M(IR,Y7e,null),e(Om,fIr),e(Om,Z7e),e(Z7e,gIr),b(c,Jio,_),b(c,ar,_),M(NR,ar,null),e(ar,hIr),e(ar,Vm),e(Vm,uIr),e(Vm,ite),e(ite,pIr),e(Vm,_Ir),e(Vm,dte),e(dte,bIr),e(Vm,vIr),e(ar,FIr),e(ar,qR),e(qR,TIr),e(qR,K7e),e(K7e,MIr),e(qR,EIr),e(ar,CIr),e(ar,zt),M(jR,zt,null),e(zt,wIr),e(zt,e8e),e(e8e,AIr),e(zt,LIr),e(zt,Xm),e(Xm,yIr),e(Xm,o8e),e(o8e,xIr),e(Xm,$Ir),e(Xm,mte),e(mte,kIr),e(Xm,SIr),e(zt,RIr),M(u5,zt,null),e(ar,PIr),e(ar,Mo),M(DR,Mo,null),e(Mo,BIr),e(Mo,r8e),e(r8e,IIr),e(Mo,NIr),e(Mo,kn),e(kn,qIr),e(kn,t8e),e(t8e,jIr),e(kn,DIr),e(kn,a8e),e(a8e,GIr),e(kn,OIr),e(kn,n8e),e(n8e,VIr),e(kn,XIr),e(Mo,zIr),e(Mo,Ft),e(Ft,p5),e(p5,s8e),e(s8e,QIr),e(p5,WIr),e(p5,cte),e(cte,UIr),e(p5,HIr),e(Ft,JIr),e(Ft,_5),e(_5,l8e),e(l8e,YIr),e(_5,ZIr),e(_5,fte),e(fte,KIr),e(_5,eNr),e(Ft,oNr),e(Ft,b5),e(b5,i8e),e(i8e,rNr),e(b5,tNr),e(b5,gte),e(gte,aNr),e(b5,nNr),e(Ft,sNr),e(Ft,v5),e(v5,d8e),e(d8e,lNr),e(v5,iNr),e(v5,hte),e(hte,dNr),e(v5,mNr),e(Ft,cNr),e(Ft,F5),e(F5,m8e),e(m8e,fNr),e(F5,gNr),e(F5,ute),e(ute,hNr),e(F5,uNr),e(Mo,pNr),e(Mo,T5),e(T5,_Nr),e(T5,c8e),e(c8e,bNr),e(T5,vNr),e(T5,f8e),e(f8e,FNr),e(Mo,TNr),M(M5,Mo,null),b(c,Yio,_),b(c,zm,_),e(zm,E5),e(E5,g8e),M(GR,g8e,null),e(zm,MNr),e(zm,h8e),e(h8e,ENr),b(c,Zio,_),b(c,nr,_),M(OR,nr,null),e(nr,CNr),e(nr,Qm),e(Qm,wNr),e(Qm,pte),e(pte,ANr),e(Qm,LNr),e(Qm,_te),e(_te,yNr),e(Qm,xNr),e(nr,$Nr),e(nr,VR),e(VR,kNr),e(VR,u8e),e(u8e,SNr),e(VR,RNr),e(nr,PNr),e(nr,Qt),M(XR,Qt,null),e(Qt,BNr),e(Qt,p8e),e(p8e,INr),e(Qt,NNr),e(Qt,Wm),e(Wm,qNr),e(Wm,_8e),e(_8e,jNr),e(Wm,DNr),e(Wm,bte),e(bte,GNr),e(Wm,ONr),e(Qt,VNr),M(C5,Qt,null),e(nr,XNr),e(nr,Eo),M(zR,Eo,null),e(Eo,zNr),e(Eo,b8e),e(b8e,QNr),e(Eo,WNr),e(Eo,Sn),e(Sn,UNr),e(Sn,v8e),e(v8e,HNr),e(Sn,JNr),e(Sn,F8e),e(F8e,YNr),e(Sn,ZNr),e(Sn,T8e),e(T8e,KNr),e(Sn,eqr),e(Eo,oqr),e(Eo,xe),e(xe,w5),e(w5,M8e),e(M8e,rqr),e(w5,tqr),e(w5,vte),e(vte,aqr),e(w5,nqr),e(xe,sqr),e(xe,A5),e(A5,E8e),e(E8e,lqr),e(A5,iqr),e(A5,Fte),e(Fte,dqr),e(A5,mqr),e(xe,cqr),e(xe,L5),e(L5,C8e),e(C8e,fqr),e(L5,gqr),e(L5,Tte),e(Tte,hqr),e(L5,uqr),e(xe,pqr),e(xe,y5),e(y5,w8e),e(w8e,_qr),e(y5,bqr),e(y5,Mte),e(Mte,vqr),e(y5,Fqr),e(xe,Tqr),e(xe,x5),e(x5,A8e),e(A8e,Mqr),e(x5,Eqr),e(x5,Ete),e(Ete,Cqr),e(x5,wqr),e(xe,Aqr),e(xe,$5),e($5,L8e),e(L8e,Lqr),e($5,yqr),e($5,Cte),e(Cte,xqr),e($5,$qr),e(xe,kqr),e(xe,k5),e(k5,y8e),e(y8e,Sqr),e(k5,Rqr),e(k5,wte),e(wte,Pqr),e(k5,Bqr),e(xe,Iqr),e(xe,S5),e(S5,x8e),e(x8e,Nqr),e(S5,qqr),e(S5,Ate),e(Ate,jqr),e(S5,Dqr),e(xe,Gqr),e(xe,R5),e(R5,$8e),e($8e,Oqr),e(R5,Vqr),e(R5,Lte),e(Lte,Xqr),e(R5,zqr),e(xe,Qqr),e(xe,P5),e(P5,k8e),e(k8e,Wqr),e(P5,Uqr),e(P5,yte),e(yte,Hqr),e(P5,Jqr),e(Eo,Yqr),e(Eo,B5),e(B5,Zqr),e(B5,S8e),e(S8e,Kqr),e(B5,ejr),e(B5,R8e),e(R8e,ojr),e(Eo,rjr),M(I5,Eo,null),b(c,Kio,_),b(c,Um,_),e(Um,N5),e(N5,P8e),M(QR,P8e,null),e(Um,tjr),e(Um,B8e),e(B8e,ajr),b(c,edo,_),b(c,sr,_),M(WR,sr,null),e(sr,njr),e(sr,Hm),e(Hm,sjr),e(Hm,xte),e(xte,ljr),e(Hm,ijr),e(Hm,$te),e($te,djr),e(Hm,mjr),e(sr,cjr),e(sr,UR),e(UR,fjr),e(UR,I8e),e(I8e,gjr),e(UR,hjr),e(sr,ujr),e(sr,Wt),M(HR,Wt,null),e(Wt,pjr),e(Wt,N8e),e(N8e,_jr),e(Wt,bjr),e(Wt,Jm),e(Jm,vjr),e(Jm,q8e),e(q8e,Fjr),e(Jm,Tjr),e(Jm,kte),e(kte,Mjr),e(Jm,Ejr),e(Wt,Cjr),M(q5,Wt,null),e(sr,wjr),e(sr,Co),M(JR,Co,null),e(Co,Ajr),e(Co,j8e),e(j8e,Ljr),e(Co,yjr),e(Co,Rn),e(Rn,xjr),e(Rn,D8e),e(D8e,$jr),e(Rn,kjr),e(Rn,G8e),e(G8e,Sjr),e(Rn,Rjr),e(Rn,O8e),e(O8e,Pjr),e(Rn,Bjr),e(Co,Ijr),e(Co,Ym),e(Ym,j5),e(j5,V8e),e(V8e,Njr),e(j5,qjr),e(j5,Ste),e(Ste,jjr),e(j5,Djr),e(Ym,Gjr),e(Ym,D5),e(D5,X8e),e(X8e,Ojr),e(D5,Vjr),e(D5,Rte),e(Rte,Xjr),e(D5,zjr),e(Ym,Qjr),e(Ym,G5),e(G5,z8e),e(z8e,Wjr),e(G5,Ujr),e(G5,Pte),e(Pte,Hjr),e(G5,Jjr),e(Co,Yjr),e(Co,O5),e(O5,Zjr),e(O5,Q8e),e(Q8e,Kjr),e(O5,eDr),e(O5,W8e),e(W8e,oDr),e(Co,rDr),M(V5,Co,null),b(c,odo,_),b(c,Zm,_),e(Zm,X5),e(X5,U8e),M(YR,U8e,null),e(Zm,tDr),e(Zm,H8e),e(H8e,aDr),b(c,rdo,_),b(c,lr,_),M(ZR,lr,null),e(lr,nDr),e(lr,Km),e(Km,sDr),e(Km,Bte),e(Bte,lDr),e(Km,iDr),e(Km,Ite),e(Ite,dDr),e(Km,mDr),e(lr,cDr),e(lr,KR),e(KR,fDr),e(KR,J8e),e(J8e,gDr),e(KR,hDr),e(lr,uDr),e(lr,Ut),M(eP,Ut,null),e(Ut,pDr),e(Ut,Y8e),e(Y8e,_Dr),e(Ut,bDr),e(Ut,ec),e(ec,vDr),e(ec,Z8e),e(Z8e,FDr),e(ec,TDr),e(ec,Nte),e(Nte,MDr),e(ec,EDr),e(Ut,CDr),M(z5,Ut,null),e(lr,wDr),e(lr,wo),M(oP,wo,null),e(wo,ADr),e(wo,K8e),e(K8e,LDr),e(wo,yDr),e(wo,Pn),e(Pn,xDr),e(Pn,eLe),e(eLe,$Dr),e(Pn,kDr),e(Pn,oLe),e(oLe,SDr),e(Pn,RDr),e(Pn,rLe),e(rLe,PDr),e(Pn,BDr),e(wo,IDr),e(wo,Tt),e(Tt,Q5),e(Q5,tLe),e(tLe,NDr),e(Q5,qDr),e(Q5,qte),e(qte,jDr),e(Q5,DDr),e(Tt,GDr),e(Tt,W5),e(W5,aLe),e(aLe,ODr),e(W5,VDr),e(W5,jte),e(jte,XDr),e(W5,zDr),e(Tt,QDr),e(Tt,U5),e(U5,nLe),e(nLe,WDr),e(U5,UDr),e(U5,Dte),e(Dte,HDr),e(U5,JDr),e(Tt,YDr),e(Tt,H5),e(H5,sLe),e(sLe,ZDr),e(H5,KDr),e(H5,Gte),e(Gte,eGr),e(H5,oGr),e(Tt,rGr),e(Tt,J5),e(J5,lLe),e(lLe,tGr),e(J5,aGr),e(J5,Ote),e(Ote,nGr),e(J5,sGr),e(wo,lGr),e(wo,Y5),e(Y5,iGr),e(Y5,iLe),e(iLe,dGr),e(Y5,mGr),e(Y5,dLe),e(dLe,cGr),e(wo,fGr),M(Z5,wo,null),b(c,tdo,_),b(c,oc,_),e(oc,K5),e(K5,mLe),M(rP,mLe,null),e(oc,gGr),e(oc,cLe),e(cLe,hGr),b(c,ado,_),b(c,ir,_),M(tP,ir,null),e(ir,uGr),e(ir,rc),e(rc,pGr),e(rc,Vte),e(Vte,_Gr),e(rc,bGr),e(rc,Xte),e(Xte,vGr),e(rc,FGr),e(ir,TGr),e(ir,aP),e(aP,MGr),e(aP,fLe),e(fLe,EGr),e(aP,CGr),e(ir,wGr),e(ir,Ht),M(nP,Ht,null),e(Ht,AGr),e(Ht,gLe),e(gLe,LGr),e(Ht,yGr),e(Ht,tc),e(tc,xGr),e(tc,hLe),e(hLe,$Gr),e(tc,kGr),e(tc,zte),e(zte,SGr),e(tc,RGr),e(Ht,PGr),M(e0,Ht,null),e(ir,BGr),e(ir,Ao),M(sP,Ao,null),e(Ao,IGr),e(Ao,uLe),e(uLe,NGr),e(Ao,qGr),e(Ao,Bn),e(Bn,jGr),e(Bn,pLe),e(pLe,DGr),e(Bn,GGr),e(Bn,_Le),e(_Le,OGr),e(Bn,VGr),e(Bn,bLe),e(bLe,XGr),e(Bn,zGr),e(Ao,QGr),e(Ao,In),e(In,o0),e(o0,vLe),e(vLe,WGr),e(o0,UGr),e(o0,Qte),e(Qte,HGr),e(o0,JGr),e(In,YGr),e(In,r0),e(r0,FLe),e(FLe,ZGr),e(r0,KGr),e(r0,Wte),e(Wte,eOr),e(r0,oOr),e(In,rOr),e(In,t0),e(t0,TLe),e(TLe,tOr),e(t0,aOr),e(t0,Ute),e(Ute,nOr),e(t0,sOr),e(In,lOr),e(In,a0),e(a0,MLe),e(MLe,iOr),e(a0,dOr),e(a0,Hte),e(Hte,mOr),e(a0,cOr),e(Ao,fOr),e(Ao,n0),e(n0,gOr),e(n0,ELe),e(ELe,hOr),e(n0,uOr),e(n0,CLe),e(CLe,pOr),e(Ao,_Or),M(s0,Ao,null),b(c,ndo,_),b(c,ac,_),e(ac,l0),e(l0,wLe),M(lP,wLe,null),e(ac,bOr),e(ac,ALe),e(ALe,vOr),b(c,sdo,_),b(c,dr,_),M(iP,dr,null),e(dr,FOr),e(dr,nc),e(nc,TOr),e(nc,Jte),e(Jte,MOr),e(nc,EOr),e(nc,Yte),e(Yte,COr),e(nc,wOr),e(dr,AOr),e(dr,dP),e(dP,LOr),e(dP,LLe),e(LLe,yOr),e(dP,xOr),e(dr,$Or),e(dr,Jt),M(mP,Jt,null),e(Jt,kOr),e(Jt,yLe),e(yLe,SOr),e(Jt,ROr),e(Jt,sc),e(sc,POr),e(sc,xLe),e(xLe,BOr),e(sc,IOr),e(sc,Zte),e(Zte,NOr),e(sc,qOr),e(Jt,jOr),M(i0,Jt,null),e(dr,DOr),e(dr,Lo),M(cP,Lo,null),e(Lo,GOr),e(Lo,$Le),e($Le,OOr),e(Lo,VOr),e(Lo,Nn),e(Nn,XOr),e(Nn,kLe),e(kLe,zOr),e(Nn,QOr),e(Nn,SLe),e(SLe,WOr),e(Nn,UOr),e(Nn,RLe),e(RLe,HOr),e(Nn,JOr),e(Lo,YOr),e(Lo,Mt),e(Mt,d0),e(d0,PLe),e(PLe,ZOr),e(d0,KOr),e(d0,Kte),e(Kte,eVr),e(d0,oVr),e(Mt,rVr),e(Mt,m0),e(m0,BLe),e(BLe,tVr),e(m0,aVr),e(m0,eae),e(eae,nVr),e(m0,sVr),e(Mt,lVr),e(Mt,c0),e(c0,ILe),e(ILe,iVr),e(c0,dVr),e(c0,oae),e(oae,mVr),e(c0,cVr),e(Mt,fVr),e(Mt,f0),e(f0,NLe),e(NLe,gVr),e(f0,hVr),e(f0,rae),e(rae,uVr),e(f0,pVr),e(Mt,_Vr),e(Mt,g0),e(g0,qLe),e(qLe,bVr),e(g0,vVr),e(g0,tae),e(tae,FVr),e(g0,TVr),e(Lo,MVr),e(Lo,h0),e(h0,EVr),e(h0,jLe),e(jLe,CVr),e(h0,wVr),e(h0,DLe),e(DLe,AVr),e(Lo,LVr),M(u0,Lo,null),b(c,ldo,_),b(c,lc,_),e(lc,p0),e(p0,GLe),M(fP,GLe,null),e(lc,yVr),e(lc,OLe),e(OLe,xVr),b(c,ido,_),b(c,mr,_),M(gP,mr,null),e(mr,$Vr),e(mr,ic),e(ic,kVr),e(ic,aae),e(aae,SVr),e(ic,RVr),e(ic,nae),e(nae,PVr),e(ic,BVr),e(mr,IVr),e(mr,hP),e(hP,NVr),e(hP,VLe),e(VLe,qVr),e(hP,jVr),e(mr,DVr),e(mr,Yt),M(uP,Yt,null),e(Yt,GVr),e(Yt,XLe),e(XLe,OVr),e(Yt,VVr),e(Yt,dc),e(dc,XVr),e(dc,zLe),e(zLe,zVr),e(dc,QVr),e(dc,sae),e(sae,WVr),e(dc,UVr),e(Yt,HVr),M(_0,Yt,null),e(mr,JVr),e(mr,yo),M(pP,yo,null),e(yo,YVr),e(yo,QLe),e(QLe,ZVr),e(yo,KVr),e(yo,qn),e(qn,eXr),e(qn,WLe),e(WLe,oXr),e(qn,rXr),e(qn,ULe),e(ULe,tXr),e(qn,aXr),e(qn,HLe),e(HLe,nXr),e(qn,sXr),e(yo,lXr),e(yo,JLe),e(JLe,b0),e(b0,YLe),e(YLe,iXr),e(b0,dXr),e(b0,lae),e(lae,mXr),e(b0,cXr),e(yo,fXr),e(yo,v0),e(v0,gXr),e(v0,ZLe),e(ZLe,hXr),e(v0,uXr),e(v0,KLe),e(KLe,pXr),e(yo,_Xr),M(F0,yo,null),b(c,ddo,_),b(c,mc,_),e(mc,T0),e(T0,eye),M(_P,eye,null),e(mc,bXr),e(mc,oye),e(oye,vXr),b(c,mdo,_),b(c,cr,_),M(bP,cr,null),e(cr,FXr),e(cr,cc),e(cc,TXr),e(cc,iae),e(iae,MXr),e(cc,EXr),e(cc,dae),e(dae,CXr),e(cc,wXr),e(cr,AXr),e(cr,vP),e(vP,LXr),e(vP,rye),e(rye,yXr),e(vP,xXr),e(cr,$Xr),e(cr,Zt),M(FP,Zt,null),e(Zt,kXr),e(Zt,tye),e(tye,SXr),e(Zt,RXr),e(Zt,fc),e(fc,PXr),e(fc,aye),e(aye,BXr),e(fc,IXr),e(fc,mae),e(mae,NXr),e(fc,qXr),e(Zt,jXr),M(M0,Zt,null),e(cr,DXr),e(cr,xo),M(TP,xo,null),e(xo,GXr),e(xo,nye),e(nye,OXr),e(xo,VXr),e(xo,jn),e(jn,XXr),e(jn,sye),e(sye,zXr),e(jn,QXr),e(jn,lye),e(lye,WXr),e(jn,UXr),e(jn,iye),e(iye,HXr),e(jn,JXr),e(xo,YXr),e(xo,fr),e(fr,E0),e(E0,dye),e(dye,ZXr),e(E0,KXr),e(E0,cae),e(cae,ezr),e(E0,ozr),e(fr,rzr),e(fr,C0),e(C0,mye),e(mye,tzr),e(C0,azr),e(C0,fae),e(fae,nzr),e(C0,szr),e(fr,lzr),e(fr,w0),e(w0,cye),e(cye,izr),e(w0,dzr),e(w0,gae),e(gae,mzr),e(w0,czr),e(fr,fzr),e(fr,A0),e(A0,fye),e(fye,gzr),e(A0,hzr),e(A0,hae),e(hae,uzr),e(A0,pzr),e(fr,_zr),e(fr,L0),e(L0,gye),e(gye,bzr),e(L0,vzr),e(L0,uae),e(uae,Fzr),e(L0,Tzr),e(fr,Mzr),e(fr,y0),e(y0,hye),e(hye,Ezr),e(y0,Czr),e(y0,pae),e(pae,wzr),e(y0,Azr),e(xo,Lzr),e(xo,x0),e(x0,yzr),e(x0,uye),e(uye,xzr),e(x0,$zr),e(x0,pye),e(pye,kzr),e(xo,Szr),M($0,xo,null),b(c,cdo,_),b(c,gc,_),e(gc,k0),e(k0,_ye),M(MP,_ye,null),e(gc,Rzr),e(gc,bye),e(bye,Pzr),b(c,fdo,_),b(c,gr,_),M(EP,gr,null),e(gr,Bzr),e(gr,hc),e(hc,Izr),e(hc,_ae),e(_ae,Nzr),e(hc,qzr),e(hc,bae),e(bae,jzr),e(hc,Dzr),e(gr,Gzr),e(gr,CP),e(CP,Ozr),e(CP,vye),e(vye,Vzr),e(CP,Xzr),e(gr,zzr),e(gr,Kt),M(wP,Kt,null),e(Kt,Qzr),e(Kt,Fye),e(Fye,Wzr),e(Kt,Uzr),e(Kt,uc),e(uc,Hzr),e(uc,Tye),e(Tye,Jzr),e(uc,Yzr),e(uc,vae),e(vae,Zzr),e(uc,Kzr),e(Kt,eQr),M(S0,Kt,null),e(gr,oQr),e(gr,$o),M(AP,$o,null),e($o,rQr),e($o,Mye),e(Mye,tQr),e($o,aQr),e($o,Dn),e(Dn,nQr),e(Dn,Eye),e(Eye,sQr),e(Dn,lQr),e(Dn,Cye),e(Cye,iQr),e(Dn,dQr),e(Dn,wye),e(wye,mQr),e(Dn,cQr),e($o,fQr),e($o,Aye),e(Aye,R0),e(R0,Lye),e(Lye,gQr),e(R0,hQr),e(R0,Fae),e(Fae,uQr),e(R0,pQr),e($o,_Qr),e($o,P0),e(P0,bQr),e(P0,yye),e(yye,vQr),e(P0,FQr),e(P0,xye),e(xye,TQr),e($o,MQr),M(B0,$o,null),b(c,gdo,_),b(c,pc,_),e(pc,I0),e(I0,$ye),M(LP,$ye,null),e(pc,EQr),e(pc,kye),e(kye,CQr),b(c,hdo,_),b(c,hr,_),M(yP,hr,null),e(hr,wQr),e(hr,_c),e(_c,AQr),e(_c,Tae),e(Tae,LQr),e(_c,yQr),e(_c,Mae),e(Mae,xQr),e(_c,$Qr),e(hr,kQr),e(hr,xP),e(xP,SQr),e(xP,Sye),e(Sye,RQr),e(xP,PQr),e(hr,BQr),e(hr,ea),M($P,ea,null),e(ea,IQr),e(ea,Rye),e(Rye,NQr),e(ea,qQr),e(ea,bc),e(bc,jQr),e(bc,Pye),e(Pye,DQr),e(bc,GQr),e(bc,Eae),e(Eae,OQr),e(bc,VQr),e(ea,XQr),M(N0,ea,null),e(hr,zQr),e(hr,ko),M(kP,ko,null),e(ko,QQr),e(ko,Bye),e(Bye,WQr),e(ko,UQr),e(ko,Gn),e(Gn,HQr),e(Gn,Iye),e(Iye,JQr),e(Gn,YQr),e(Gn,Nye),e(Nye,ZQr),e(Gn,KQr),e(Gn,qye),e(qye,eWr),e(Gn,oWr),e(ko,rWr),e(ko,jye),e(jye,q0),e(q0,Dye),e(Dye,tWr),e(q0,aWr),e(q0,Cae),e(Cae,nWr),e(q0,sWr),e(ko,lWr),e(ko,j0),e(j0,iWr),e(j0,Gye),e(Gye,dWr),e(j0,mWr),e(j0,Oye),e(Oye,cWr),e(ko,fWr),M(D0,ko,null),b(c,udo,_),b(c,vc,_),e(vc,G0),e(G0,Vye),M(SP,Vye,null),e(vc,gWr),e(vc,Xye),e(Xye,hWr),b(c,pdo,_),b(c,ur,_),M(RP,ur,null),e(ur,uWr),e(ur,Fc),e(Fc,pWr),e(Fc,wae),e(wae,_Wr),e(Fc,bWr),e(Fc,Aae),e(Aae,vWr),e(Fc,FWr),e(ur,TWr),e(ur,PP),e(PP,MWr),e(PP,zye),e(zye,EWr),e(PP,CWr),e(ur,wWr),e(ur,oa),M(BP,oa,null),e(oa,AWr),e(oa,Qye),e(Qye,LWr),e(oa,yWr),e(oa,Tc),e(Tc,xWr),e(Tc,Wye),e(Wye,$Wr),e(Tc,kWr),e(Tc,Lae),e(Lae,SWr),e(Tc,RWr),e(oa,PWr),M(O0,oa,null),e(ur,BWr),e(ur,zr),M(IP,zr,null),e(zr,IWr),e(zr,Uye),e(Uye,NWr),e(zr,qWr),e(zr,On),e(On,jWr),e(On,Hye),e(Hye,DWr),e(On,GWr),e(On,Jye),e(Jye,OWr),e(On,VWr),e(On,Yye),e(Yye,XWr),e(On,zWr),e(zr,QWr),e(zr,P),e(P,V0),e(V0,Zye),e(Zye,WWr),e(V0,UWr),e(V0,yae),e(yae,HWr),e(V0,JWr),e(P,YWr),e(P,X0),e(X0,Kye),e(Kye,ZWr),e(X0,KWr),e(X0,xae),e(xae,eUr),e(X0,oUr),e(P,rUr),e(P,z0),e(z0,e9e),e(e9e,tUr),e(z0,aUr),e(z0,$ae),e($ae,nUr),e(z0,sUr),e(P,lUr),e(P,Q0),e(Q0,o9e),e(o9e,iUr),e(Q0,dUr),e(Q0,kae),e(kae,mUr),e(Q0,cUr),e(P,fUr),e(P,W0),e(W0,r9e),e(r9e,gUr),e(W0,hUr),e(W0,Sae),e(Sae,uUr),e(W0,pUr),e(P,_Ur),e(P,U0),e(U0,t9e),e(t9e,bUr),e(U0,vUr),e(U0,Rae),e(Rae,FUr),e(U0,TUr),e(P,MUr),e(P,H0),e(H0,a9e),e(a9e,EUr),e(H0,CUr),e(H0,Pae),e(Pae,wUr),e(H0,AUr),e(P,LUr),e(P,J0),e(J0,n9e),e(n9e,yUr),e(J0,xUr),e(J0,Bae),e(Bae,$Ur),e(J0,kUr),e(P,SUr),e(P,Y0),e(Y0,s9e),e(s9e,RUr),e(Y0,PUr),e(Y0,Iae),e(Iae,BUr),e(Y0,IUr),e(P,NUr),e(P,Z0),e(Z0,l9e),e(l9e,qUr),e(Z0,jUr),e(Z0,Nae),e(Nae,DUr),e(Z0,GUr),e(P,OUr),e(P,K0),e(K0,i9e),e(i9e,VUr),e(K0,XUr),e(K0,qae),e(qae,zUr),e(K0,QUr),e(P,WUr),e(P,ew),e(ew,d9e),e(d9e,UUr),e(ew,HUr),e(ew,jae),e(jae,JUr),e(ew,YUr),e(P,ZUr),e(P,ow),e(ow,m9e),e(m9e,KUr),e(ow,eHr),e(ow,Dae),e(Dae,oHr),e(ow,rHr),e(P,tHr),e(P,rw),e(rw,c9e),e(c9e,aHr),e(rw,nHr),e(rw,Gae),e(Gae,sHr),e(rw,lHr),e(P,iHr),e(P,tw),e(tw,f9e),e(f9e,dHr),e(tw,mHr),e(tw,Oae),e(Oae,cHr),e(tw,fHr),e(P,gHr),e(P,aw),e(aw,g9e),e(g9e,hHr),e(aw,uHr),e(aw,Vae),e(Vae,pHr),e(aw,_Hr),e(P,bHr),e(P,nw),e(nw,h9e),e(h9e,vHr),e(nw,FHr),e(nw,Xae),e(Xae,THr),e(nw,MHr),e(P,EHr),e(P,sw),e(sw,u9e),e(u9e,CHr),e(sw,wHr),e(sw,zae),e(zae,AHr),e(sw,LHr),e(P,yHr),e(P,lw),e(lw,p9e),e(p9e,xHr),e(lw,$Hr),e(lw,Qae),e(Qae,kHr),e(lw,SHr),e(P,RHr),e(P,iw),e(iw,_9e),e(_9e,PHr),e(iw,BHr),e(iw,Wae),e(Wae,IHr),e(iw,NHr),e(P,qHr),e(P,Dl),e(Dl,b9e),e(b9e,jHr),e(Dl,DHr),e(Dl,Uae),e(Uae,GHr),e(Dl,OHr),e(Dl,Hae),e(Hae,VHr),e(Dl,XHr),e(P,zHr),e(P,dw),e(dw,v9e),e(v9e,QHr),e(dw,WHr),e(dw,Jae),e(Jae,UHr),e(dw,HHr),e(P,JHr),e(P,mw),e(mw,F9e),e(F9e,YHr),e(mw,ZHr),e(mw,Yae),e(Yae,KHr),e(mw,eJr),e(P,oJr),e(P,cw),e(cw,T9e),e(T9e,rJr),e(cw,tJr),e(cw,Zae),e(Zae,aJr),e(cw,nJr),e(P,sJr),e(P,fw),e(fw,M9e),e(M9e,lJr),e(fw,iJr),e(fw,Kae),e(Kae,dJr),e(fw,mJr),e(P,cJr),e(P,gw),e(gw,E9e),e(E9e,fJr),e(gw,gJr),e(gw,ene),e(ene,hJr),e(gw,uJr),e(P,pJr),e(P,hw),e(hw,C9e),e(C9e,_Jr),e(hw,bJr),e(hw,one),e(one,vJr),e(hw,FJr),e(P,TJr),e(P,uw),e(uw,w9e),e(w9e,MJr),e(uw,EJr),e(uw,rne),e(rne,CJr),e(uw,wJr),e(P,AJr),e(P,pw),e(pw,A9e),e(A9e,LJr),e(pw,yJr),e(pw,tne),e(tne,xJr),e(pw,$Jr),e(P,kJr),e(P,_w),e(_w,L9e),e(L9e,SJr),e(_w,RJr),e(_w,ane),e(ane,PJr),e(_w,BJr),e(P,IJr),e(P,bw),e(bw,y9e),e(y9e,NJr),e(bw,qJr),e(bw,nne),e(nne,jJr),e(bw,DJr),e(P,GJr),e(P,vw),e(vw,x9e),e(x9e,OJr),e(vw,VJr),e(vw,sne),e(sne,XJr),e(vw,zJr),e(P,QJr),e(P,Fw),e(Fw,$9e),e($9e,WJr),e(Fw,UJr),e(Fw,lne),e(lne,HJr),e(Fw,JJr),e(P,YJr),e(P,Tw),e(Tw,k9e),e(k9e,ZJr),e(Tw,KJr),e(Tw,ine),e(ine,eYr),e(Tw,oYr),e(P,rYr),e(P,Mw),e(Mw,S9e),e(S9e,tYr),e(Mw,aYr),e(Mw,dne),e(dne,nYr),e(Mw,sYr),e(P,lYr),e(P,Ew),e(Ew,R9e),e(R9e,iYr),e(Ew,dYr),e(Ew,mne),e(mne,mYr),e(Ew,cYr),e(P,fYr),e(P,Cw),e(Cw,P9e),e(P9e,gYr),e(Cw,hYr),e(Cw,cne),e(cne,uYr),e(Cw,pYr),e(P,_Yr),e(P,ww),e(ww,B9e),e(B9e,bYr),e(ww,vYr),e(ww,fne),e(fne,FYr),e(ww,TYr),e(P,MYr),e(P,Aw),e(Aw,I9e),e(I9e,EYr),e(Aw,CYr),e(Aw,gne),e(gne,wYr),e(Aw,AYr),e(P,LYr),e(P,Lw),e(Lw,N9e),e(N9e,yYr),e(Lw,xYr),e(Lw,hne),e(hne,$Yr),e(Lw,kYr),e(P,SYr),e(P,yw),e(yw,q9e),e(q9e,RYr),e(yw,PYr),e(yw,une),e(une,BYr),e(yw,IYr),e(P,NYr),e(P,xw),e(xw,j9e),e(j9e,qYr),e(xw,jYr),e(xw,pne),e(pne,DYr),e(xw,GYr),e(P,OYr),e(P,$w),e($w,D9e),e(D9e,VYr),e($w,XYr),e($w,_ne),e(_ne,zYr),e($w,QYr),e(P,WYr),e(P,kw),e(kw,G9e),e(G9e,UYr),e(kw,HYr),e(kw,bne),e(bne,JYr),e(kw,YYr),e(P,ZYr),e(P,Sw),e(Sw,O9e),e(O9e,KYr),e(Sw,eZr),e(Sw,vne),e(vne,oZr),e(Sw,rZr),e(P,tZr),e(P,Rw),e(Rw,V9e),e(V9e,aZr),e(Rw,nZr),e(Rw,Fne),e(Fne,sZr),e(Rw,lZr),e(P,iZr),e(P,Pw),e(Pw,X9e),e(X9e,dZr),e(Pw,mZr),e(Pw,Tne),e(Tne,cZr),e(Pw,fZr),e(P,gZr),e(P,Bw),e(Bw,z9e),e(z9e,hZr),e(Bw,uZr),e(Bw,Mne),e(Mne,pZr),e(Bw,_Zr),e(P,bZr),e(P,Iw),e(Iw,Q9e),e(Q9e,vZr),e(Iw,FZr),e(Iw,Ene),e(Ene,TZr),e(Iw,MZr),e(P,EZr),e(P,Nw),e(Nw,W9e),e(W9e,CZr),e(Nw,wZr),e(Nw,Cne),e(Cne,AZr),e(Nw,LZr),e(P,yZr),e(P,qw),e(qw,U9e),e(U9e,xZr),e(qw,$Zr),e(qw,wne),e(wne,kZr),e(qw,SZr),e(P,RZr),e(P,jw),e(jw,H9e),e(H9e,PZr),e(jw,BZr),e(jw,Ane),e(Ane,IZr),e(jw,NZr),e(P,qZr),e(P,Dw),e(Dw,J9e),e(J9e,jZr),e(Dw,DZr),e(Dw,Lne),e(Lne,GZr),e(Dw,OZr),e(P,VZr),e(P,Gw),e(Gw,Y9e),e(Y9e,XZr),e(Gw,zZr),e(Gw,yne),e(yne,QZr),e(Gw,WZr),e(P,UZr),e(P,Ow),e(Ow,Z9e),e(Z9e,HZr),e(Ow,JZr),e(Ow,xne),e(xne,YZr),e(Ow,ZZr),e(P,KZr),e(P,Vw),e(Vw,K9e),e(K9e,eKr),e(Vw,oKr),e(Vw,$ne),e($ne,rKr),e(Vw,tKr),e(P,aKr),e(P,Xw),e(Xw,exe),e(exe,nKr),e(Xw,sKr),e(Xw,kne),e(kne,lKr),e(Xw,iKr),e(P,dKr),e(P,zw),e(zw,oxe),e(oxe,mKr),e(zw,cKr),e(zw,Sne),e(Sne,fKr),e(zw,gKr),e(zr,hKr),M(Qw,zr,null),b(c,_do,_),b(c,Mc,_),e(Mc,Ww),e(Ww,rxe),M(NP,rxe,null),e(Mc,uKr),e(Mc,txe),e(txe,pKr),b(c,bdo,_),b(c,pr,_),M(qP,pr,null),e(pr,_Kr),e(pr,Ec),e(Ec,bKr),e(Ec,Rne),e(Rne,vKr),e(Ec,FKr),e(Ec,Pne),e(Pne,TKr),e(Ec,MKr),e(pr,EKr),e(pr,jP),e(jP,CKr),e(jP,axe),e(axe,wKr),e(jP,AKr),e(pr,LKr),e(pr,ra),M(DP,ra,null),e(ra,yKr),e(ra,nxe),e(nxe,xKr),e(ra,$Kr),e(ra,Cc),e(Cc,kKr),e(Cc,sxe),e(sxe,SKr),e(Cc,RKr),e(Cc,Bne),e(Bne,PKr),e(Cc,BKr),e(ra,IKr),M(Uw,ra,null),e(pr,NKr),e(pr,Qr),M(GP,Qr,null),e(Qr,qKr),e(Qr,lxe),e(lxe,jKr),e(Qr,DKr),e(Qr,Vn),e(Vn,GKr),e(Vn,ixe),e(ixe,OKr),e(Vn,VKr),e(Vn,dxe),e(dxe,XKr),e(Vn,zKr),e(Vn,mxe),e(mxe,QKr),e(Vn,WKr),e(Qr,UKr),e(Qr,de),e(de,Hw),e(Hw,cxe),e(cxe,HKr),e(Hw,JKr),e(Hw,Ine),e(Ine,YKr),e(Hw,ZKr),e(de,KKr),e(de,Jw),e(Jw,fxe),e(fxe,eet),e(Jw,oet),e(Jw,Nne),e(Nne,ret),e(Jw,tet),e(de,aet),e(de,Yw),e(Yw,gxe),e(gxe,net),e(Yw,set),e(Yw,qne),e(qne,iet),e(Yw,det),e(de,met),e(de,Zw),e(Zw,hxe),e(hxe,cet),e(Zw,fet),e(Zw,jne),e(jne,get),e(Zw,het),e(de,uet),e(de,Kw),e(Kw,uxe),e(uxe,pet),e(Kw,_et),e(Kw,Dne),e(Dne,bet),e(Kw,vet),e(de,Fet),e(de,eA),e(eA,pxe),e(pxe,Tet),e(eA,Met),e(eA,Gne),e(Gne,Eet),e(eA,Cet),e(de,wet),e(de,oA),e(oA,_xe),e(_xe,Aet),e(oA,Let),e(oA,One),e(One,yet),e(oA,xet),e(de,$et),e(de,rA),e(rA,bxe),e(bxe,ket),e(rA,Set),e(rA,Vne),e(Vne,Ret),e(rA,Pet),e(de,Bet),e(de,tA),e(tA,vxe),e(vxe,Iet),e(tA,Net),e(tA,Xne),e(Xne,qet),e(tA,jet),e(de,Det),e(de,aA),e(aA,Fxe),e(Fxe,Get),e(aA,Oet),e(aA,zne),e(zne,Vet),e(aA,Xet),e(de,zet),e(de,nA),e(nA,Txe),e(Txe,Qet),e(nA,Wet),e(nA,Qne),e(Qne,Uet),e(nA,Het),e(de,Jet),e(de,sA),e(sA,Mxe),e(Mxe,Yet),e(sA,Zet),e(sA,Wne),e(Wne,Ket),e(sA,eot),e(de,oot),e(de,lA),e(lA,Exe),e(Exe,rot),e(lA,tot),e(lA,Une),e(Une,aot),e(lA,not),e(de,sot),e(de,iA),e(iA,Cxe),e(Cxe,lot),e(iA,iot),e(iA,Hne),e(Hne,dot),e(iA,mot),e(de,cot),e(de,dA),e(dA,wxe),e(wxe,fot),e(dA,got),e(dA,Jne),e(Jne,hot),e(dA,uot),e(de,pot),e(de,mA),e(mA,Axe),e(Axe,_ot),e(mA,bot),e(mA,Yne),e(Yne,vot),e(mA,Fot),e(de,Tot),e(de,cA),e(cA,Lxe),e(Lxe,Mot),e(cA,Eot),e(cA,Zne),e(Zne,Cot),e(cA,wot),e(de,Aot),e(de,fA),e(fA,yxe),e(yxe,Lot),e(fA,yot),e(fA,Kne),e(Kne,xot),e(fA,$ot),e(de,kot),e(de,gA),e(gA,xxe),e(xxe,Sot),e(gA,Rot),e(gA,ese),e(ese,Pot),e(gA,Bot),e(de,Iot),e(de,hA),e(hA,$xe),e($xe,Not),e(hA,qot),e(hA,ose),e(ose,jot),e(hA,Dot),e(de,Got),e(de,uA),e(uA,kxe),e(kxe,Oot),e(uA,Vot),e(uA,rse),e(rse,Xot),e(uA,zot),e(de,Qot),e(de,pA),e(pA,Sxe),e(Sxe,Wot),e(pA,Uot),e(pA,tse),e(tse,Hot),e(pA,Jot),e(de,Yot),e(de,_A),e(_A,Rxe),e(Rxe,Zot),e(_A,Kot),e(_A,ase),e(ase,ert),e(_A,ort),e(Qr,rrt),M(bA,Qr,null),b(c,vdo,_),b(c,wc,_),e(wc,vA),e(vA,Pxe),M(OP,Pxe,null),e(wc,trt),e(wc,Bxe),e(Bxe,art),b(c,Fdo,_),b(c,_r,_),M(VP,_r,null),e(_r,nrt),e(_r,Ac),e(Ac,srt),e(Ac,nse),e(nse,lrt),e(Ac,irt),e(Ac,sse),e(sse,drt),e(Ac,mrt),e(_r,crt),e(_r,XP),e(XP,frt),e(XP,Ixe),e(Ixe,grt),e(XP,hrt),e(_r,urt),e(_r,ta),M(zP,ta,null),e(ta,prt),e(ta,Nxe),e(Nxe,_rt),e(ta,brt),e(ta,Lc),e(Lc,vrt),e(Lc,qxe),e(qxe,Frt),e(Lc,Trt),e(Lc,lse),e(lse,Mrt),e(Lc,Ert),e(ta,Crt),M(FA,ta,null),e(_r,wrt),e(_r,Wr),M(QP,Wr,null),e(Wr,Art),e(Wr,jxe),e(jxe,Lrt),e(Wr,yrt),e(Wr,Xn),e(Xn,xrt),e(Xn,Dxe),e(Dxe,$rt),e(Xn,krt),e(Xn,Gxe),e(Gxe,Srt),e(Xn,Rrt),e(Xn,Oxe),e(Oxe,Prt),e(Xn,Brt),e(Wr,Irt),e(Wr,Ce),e(Ce,TA),e(TA,Vxe),e(Vxe,Nrt),e(TA,qrt),e(TA,ise),e(ise,jrt),e(TA,Drt),e(Ce,Grt),e(Ce,MA),e(MA,Xxe),e(Xxe,Ort),e(MA,Vrt),e(MA,dse),e(dse,Xrt),e(MA,zrt),e(Ce,Qrt),e(Ce,EA),e(EA,zxe),e(zxe,Wrt),e(EA,Urt),e(EA,mse),e(mse,Hrt),e(EA,Jrt),e(Ce,Yrt),e(Ce,CA),e(CA,Qxe),e(Qxe,Zrt),e(CA,Krt),e(CA,cse),e(cse,ett),e(CA,ott),e(Ce,rtt),e(Ce,wA),e(wA,Wxe),e(Wxe,ttt),e(wA,att),e(wA,fse),e(fse,ntt),e(wA,stt),e(Ce,ltt),e(Ce,AA),e(AA,Uxe),e(Uxe,itt),e(AA,dtt),e(AA,gse),e(gse,mtt),e(AA,ctt),e(Ce,ftt),e(Ce,LA),e(LA,Hxe),e(Hxe,gtt),e(LA,htt),e(LA,hse),e(hse,utt),e(LA,ptt),e(Ce,_tt),e(Ce,yA),e(yA,Jxe),e(Jxe,btt),e(yA,vtt),e(yA,use),e(use,Ftt),e(yA,Ttt),e(Ce,Mtt),e(Ce,xA),e(xA,Yxe),e(Yxe,Ett),e(xA,Ctt),e(xA,pse),e(pse,wtt),e(xA,Att),e(Ce,Ltt),e(Ce,$A),e($A,Zxe),e(Zxe,ytt),e($A,xtt),e($A,_se),e(_se,$tt),e($A,ktt),e(Ce,Stt),e(Ce,kA),e(kA,Kxe),e(Kxe,Rtt),e(kA,Ptt),e(kA,bse),e(bse,Btt),e(kA,Itt),e(Ce,Ntt),e(Ce,SA),e(SA,e$e),e(e$e,qtt),e(SA,jtt),e(SA,vse),e(vse,Dtt),e(SA,Gtt),e(Ce,Ott),e(Ce,RA),e(RA,o$e),e(o$e,Vtt),e(RA,Xtt),e(RA,Fse),e(Fse,ztt),e(RA,Qtt),e(Ce,Wtt),e(Ce,PA),e(PA,r$e),e(r$e,Utt),e(PA,Htt),e(PA,Tse),e(Tse,Jtt),e(PA,Ytt),e(Wr,Ztt),M(BA,Wr,null),b(c,Tdo,_),b(c,yc,_),e(yc,IA),e(IA,t$e),M(WP,t$e,null),e(yc,Ktt),e(yc,a$e),e(a$e,eat),b(c,Mdo,_),b(c,br,_),M(UP,br,null),e(br,oat),e(br,xc),e(xc,rat),e(xc,Mse),e(Mse,tat),e(xc,aat),e(xc,Ese),e(Ese,nat),e(xc,sat),e(br,lat),e(br,HP),e(HP,iat),e(HP,n$e),e(n$e,dat),e(HP,mat),e(br,cat),e(br,aa),M(JP,aa,null),e(aa,fat),e(aa,s$e),e(s$e,gat),e(aa,hat),e(aa,$c),e($c,uat),e($c,l$e),e(l$e,pat),e($c,_at),e($c,Cse),e(Cse,bat),e($c,vat),e(aa,Fat),M(NA,aa,null),e(br,Tat),e(br,Ur),M(YP,Ur,null),e(Ur,Mat),e(Ur,i$e),e(i$e,Eat),e(Ur,Cat),e(Ur,zn),e(zn,wat),e(zn,d$e),e(d$e,Aat),e(zn,Lat),e(zn,m$e),e(m$e,yat),e(zn,xat),e(zn,c$e),e(c$e,$at),e(zn,kat),e(Ur,Sat),e(Ur,$e),e($e,qA),e(qA,f$e),e(f$e,Rat),e(qA,Pat),e(qA,wse),e(wse,Bat),e(qA,Iat),e($e,Nat),e($e,jA),e(jA,g$e),e(g$e,qat),e(jA,jat),e(jA,Ase),e(Ase,Dat),e(jA,Gat),e($e,Oat),e($e,DA),e(DA,h$e),e(h$e,Vat),e(DA,Xat),e(DA,Lse),e(Lse,zat),e(DA,Qat),e($e,Wat),e($e,Gl),e(Gl,u$e),e(u$e,Uat),e(Gl,Hat),e(Gl,yse),e(yse,Jat),e(Gl,Yat),e(Gl,xse),e(xse,Zat),e(Gl,Kat),e($e,ent),e($e,GA),e(GA,p$e),e(p$e,ont),e(GA,rnt),e(GA,$se),e($se,tnt),e(GA,ant),e($e,nnt),e($e,OA),e(OA,_$e),e(_$e,snt),e(OA,lnt),e(OA,kse),e(kse,int),e(OA,dnt),e($e,mnt),e($e,VA),e(VA,b$e),e(b$e,cnt),e(VA,fnt),e(VA,Sse),e(Sse,gnt),e(VA,hnt),e($e,unt),e($e,XA),e(XA,v$e),e(v$e,pnt),e(XA,_nt),e(XA,Rse),e(Rse,bnt),e(XA,vnt),e($e,Fnt),e($e,zA),e(zA,F$e),e(F$e,Tnt),e(zA,Mnt),e(zA,Pse),e(Pse,Ent),e(zA,Cnt),e($e,wnt),e($e,QA),e(QA,T$e),e(T$e,Ant),e(QA,Lnt),e(QA,Bse),e(Bse,ynt),e(QA,xnt),e(Ur,$nt),M(WA,Ur,null),b(c,Edo,_),b(c,kc,_),e(kc,UA),e(UA,M$e),M(ZP,M$e,null),e(kc,knt),e(kc,E$e),e(E$e,Snt),b(c,Cdo,_),b(c,vr,_),M(KP,vr,null),e(vr,Rnt),e(vr,Sc),e(Sc,Pnt),e(Sc,Ise),e(Ise,Bnt),e(Sc,Int),e(Sc,Nse),e(Nse,Nnt),e(Sc,qnt),e(vr,jnt),e(vr,eB),e(eB,Dnt),e(eB,C$e),e(C$e,Gnt),e(eB,Ont),e(vr,Vnt),e(vr,na),M(oB,na,null),e(na,Xnt),e(na,w$e),e(w$e,znt),e(na,Qnt),e(na,Rc),e(Rc,Wnt),e(Rc,A$e),e(A$e,Unt),e(Rc,Hnt),e(Rc,qse),e(qse,Jnt),e(Rc,Ynt),e(na,Znt),M(HA,na,null),e(vr,Knt),e(vr,Hr),M(rB,Hr,null),e(Hr,est),e(Hr,L$e),e(L$e,ost),e(Hr,rst),e(Hr,Qn),e(Qn,tst),e(Qn,y$e),e(y$e,ast),e(Qn,nst),e(Qn,x$e),e(x$e,sst),e(Qn,lst),e(Qn,$$e),e($$e,ist),e(Qn,dst),e(Hr,mst),e(Hr,Pc),e(Pc,JA),e(JA,k$e),e(k$e,cst),e(JA,fst),e(JA,jse),e(jse,gst),e(JA,hst),e(Pc,ust),e(Pc,YA),e(YA,S$e),e(S$e,pst),e(YA,_st),e(YA,Dse),e(Dse,bst),e(YA,vst),e(Pc,Fst),e(Pc,ZA),e(ZA,R$e),e(R$e,Tst),e(ZA,Mst),e(ZA,Gse),e(Gse,Est),e(ZA,Cst),e(Hr,wst),M(KA,Hr,null),b(c,wdo,_),b(c,Bc,_),e(Bc,e6),e(e6,P$e),M(tB,P$e,null),e(Bc,Ast),e(Bc,B$e),e(B$e,Lst),b(c,Ado,_),b(c,Fr,_),M(aB,Fr,null),e(Fr,yst),e(Fr,Ic),e(Ic,xst),e(Ic,Ose),e(Ose,$st),e(Ic,kst),e(Ic,Vse),e(Vse,Sst),e(Ic,Rst),e(Fr,Pst),e(Fr,nB),e(nB,Bst),e(nB,I$e),e(I$e,Ist),e(nB,Nst),e(Fr,qst),e(Fr,sa),M(sB,sa,null),e(sa,jst),e(sa,N$e),e(N$e,Dst),e(sa,Gst),e(sa,Nc),e(Nc,Ost),e(Nc,q$e),e(q$e,Vst),e(Nc,Xst),e(Nc,Xse),e(Xse,zst),e(Nc,Qst),e(sa,Wst),M(o6,sa,null),e(Fr,Ust),e(Fr,Jr),M(lB,Jr,null),e(Jr,Hst),e(Jr,j$e),e(j$e,Jst),e(Jr,Yst),e(Jr,Wn),e(Wn,Zst),e(Wn,D$e),e(D$e,Kst),e(Wn,elt),e(Wn,G$e),e(G$e,olt),e(Wn,rlt),e(Wn,O$e),e(O$e,tlt),e(Wn,alt),e(Jr,nlt),e(Jr,ge),e(ge,r6),e(r6,V$e),e(V$e,slt),e(r6,llt),e(r6,zse),e(zse,ilt),e(r6,dlt),e(ge,mlt),e(ge,t6),e(t6,X$e),e(X$e,clt),e(t6,flt),e(t6,Qse),e(Qse,glt),e(t6,hlt),e(ge,ult),e(ge,a6),e(a6,z$e),e(z$e,plt),e(a6,_lt),e(a6,Wse),e(Wse,blt),e(a6,vlt),e(ge,Flt),e(ge,n6),e(n6,Q$e),e(Q$e,Tlt),e(n6,Mlt),e(n6,Use),e(Use,Elt),e(n6,Clt),e(ge,wlt),e(ge,s6),e(s6,W$e),e(W$e,Alt),e(s6,Llt),e(s6,Hse),e(Hse,ylt),e(s6,xlt),e(ge,$lt),e(ge,l6),e(l6,U$e),e(U$e,klt),e(l6,Slt),e(l6,Jse),e(Jse,Rlt),e(l6,Plt),e(ge,Blt),e(ge,i6),e(i6,H$e),e(H$e,Ilt),e(i6,Nlt),e(i6,Yse),e(Yse,qlt),e(i6,jlt),e(ge,Dlt),e(ge,d6),e(d6,J$e),e(J$e,Glt),e(d6,Olt),e(d6,Zse),e(Zse,Vlt),e(d6,Xlt),e(ge,zlt),e(ge,m6),e(m6,Y$e),e(Y$e,Qlt),e(m6,Wlt),e(m6,Kse),e(Kse,Ult),e(m6,Hlt),e(ge,Jlt),e(ge,c6),e(c6,Z$e),e(Z$e,Ylt),e(c6,Zlt),e(c6,ele),e(ele,Klt),e(c6,eit),e(ge,oit),e(ge,f6),e(f6,K$e),e(K$e,rit),e(f6,tit),e(f6,ole),e(ole,ait),e(f6,nit),e(ge,sit),e(ge,g6),e(g6,eke),e(eke,lit),e(g6,iit),e(g6,rle),e(rle,dit),e(g6,mit),e(ge,cit),e(ge,h6),e(h6,oke),e(oke,fit),e(h6,git),e(h6,tle),e(tle,hit),e(h6,uit),e(ge,pit),e(ge,u6),e(u6,rke),e(rke,_it),e(u6,bit),e(u6,ale),e(ale,vit),e(u6,Fit),e(ge,Tit),e(ge,p6),e(p6,tke),e(tke,Mit),e(p6,Eit),e(p6,nle),e(nle,Cit),e(p6,wit),e(ge,Ait),e(ge,_6),e(_6,ake),e(ake,Lit),e(_6,yit),e(_6,sle),e(sle,xit),e(_6,$it),e(ge,kit),e(ge,b6),e(b6,nke),e(nke,Sit),e(b6,Rit),e(b6,lle),e(lle,Pit),e(b6,Bit),e(ge,Iit),e(ge,v6),e(v6,ske),e(ske,Nit),e(v6,qit),e(v6,ile),e(ile,jit),e(v6,Dit),e(ge,Git),e(ge,F6),e(F6,lke),e(lke,Oit),e(F6,Vit),e(F6,dle),e(dle,Xit),e(F6,zit),e(ge,Qit),e(ge,T6),e(T6,ike),e(ike,Wit),e(T6,Uit),e(T6,mle),e(mle,Hit),e(T6,Jit),e(ge,Yit),e(ge,M6),e(M6,dke),e(dke,Zit),e(M6,Kit),e(M6,cle),e(cle,edt),e(M6,odt),e(Jr,rdt),M(E6,Jr,null),b(c,Ldo,_),b(c,qc,_),e(qc,C6),e(C6,mke),M(iB,mke,null),e(qc,tdt),e(qc,cke),e(cke,adt),b(c,ydo,_),b(c,Tr,_),M(dB,Tr,null),e(Tr,ndt),e(Tr,jc),e(jc,sdt),e(jc,fle),e(fle,ldt),e(jc,idt),e(jc,gle),e(gle,ddt),e(jc,mdt),e(Tr,cdt),e(Tr,mB),e(mB,fdt),e(mB,fke),e(fke,gdt),e(mB,hdt),e(Tr,udt),e(Tr,la),M(cB,la,null),e(la,pdt),e(la,gke),e(gke,_dt),e(la,bdt),e(la,Dc),e(Dc,vdt),e(Dc,hke),e(hke,Fdt),e(Dc,Tdt),e(Dc,hle),e(hle,Mdt),e(Dc,Edt),e(la,Cdt),M(w6,la,null),e(Tr,wdt),e(Tr,Yr),M(fB,Yr,null),e(Yr,Adt),e(Yr,uke),e(uke,Ldt),e(Yr,ydt),e(Yr,Un),e(Un,xdt),e(Un,pke),e(pke,$dt),e(Un,kdt),e(Un,_ke),e(_ke,Sdt),e(Un,Rdt),e(Un,bke),e(bke,Pdt),e(Un,Bdt),e(Yr,Idt),e(Yr,ke),e(ke,A6),e(A6,vke),e(vke,Ndt),e(A6,qdt),e(A6,ule),e(ule,jdt),e(A6,Ddt),e(ke,Gdt),e(ke,L6),e(L6,Fke),e(Fke,Odt),e(L6,Vdt),e(L6,ple),e(ple,Xdt),e(L6,zdt),e(ke,Qdt),e(ke,y6),e(y6,Tke),e(Tke,Wdt),e(y6,Udt),e(y6,_le),e(_le,Hdt),e(y6,Jdt),e(ke,Ydt),e(ke,x6),e(x6,Mke),e(Mke,Zdt),e(x6,Kdt),e(x6,ble),e(ble,emt),e(x6,omt),e(ke,rmt),e(ke,$6),e($6,Eke),e(Eke,tmt),e($6,amt),e($6,vle),e(vle,nmt),e($6,smt),e(ke,lmt),e(ke,k6),e(k6,Cke),e(Cke,imt),e(k6,dmt),e(k6,Fle),e(Fle,mmt),e(k6,cmt),e(ke,fmt),e(ke,S6),e(S6,wke),e(wke,gmt),e(S6,hmt),e(S6,Tle),e(Tle,umt),e(S6,pmt),e(ke,_mt),e(ke,R6),e(R6,Ake),e(Ake,bmt),e(R6,vmt),e(R6,Mle),e(Mle,Fmt),e(R6,Tmt),e(ke,Mmt),e(ke,P6),e(P6,Lke),e(Lke,Emt),e(P6,Cmt),e(P6,Ele),e(Ele,wmt),e(P6,Amt),e(ke,Lmt),e(ke,B6),e(B6,yke),e(yke,ymt),e(B6,xmt),e(B6,Cle),e(Cle,$mt),e(B6,kmt),e(Yr,Smt),M(I6,Yr,null),b(c,xdo,_),b(c,Gc,_),e(Gc,N6),e(N6,xke),M(gB,xke,null),e(Gc,Rmt),e(Gc,$ke),e($ke,Pmt),b(c,$do,_),b(c,Mr,_),M(hB,Mr,null),e(Mr,Bmt),e(Mr,Oc),e(Oc,Imt),e(Oc,wle),e(wle,Nmt),e(Oc,qmt),e(Oc,Ale),e(Ale,jmt),e(Oc,Dmt),e(Mr,Gmt),e(Mr,uB),e(uB,Omt),e(uB,kke),e(kke,Vmt),e(uB,Xmt),e(Mr,zmt),e(Mr,ia),M(pB,ia,null),e(ia,Qmt),e(ia,Ske),e(Ske,Wmt),e(ia,Umt),e(ia,Vc),e(Vc,Hmt),e(Vc,Rke),e(Rke,Jmt),e(Vc,Ymt),e(Vc,Lle),e(Lle,Zmt),e(Vc,Kmt),e(ia,ect),M(q6,ia,null),e(Mr,oct),e(Mr,Zr),M(_B,Zr,null),e(Zr,rct),e(Zr,Pke),e(Pke,tct),e(Zr,act),e(Zr,Hn),e(Hn,nct),e(Hn,Bke),e(Bke,sct),e(Hn,lct),e(Hn,Ike),e(Ike,ict),e(Hn,dct),e(Hn,Nke),e(Nke,mct),e(Hn,cct),e(Zr,fct),e(Zr,ae),e(ae,j6),e(j6,qke),e(qke,gct),e(j6,hct),e(j6,yle),e(yle,uct),e(j6,pct),e(ae,_ct),e(ae,D6),e(D6,jke),e(jke,bct),e(D6,vct),e(D6,xle),e(xle,Fct),e(D6,Tct),e(ae,Mct),e(ae,G6),e(G6,Dke),e(Dke,Ect),e(G6,Cct),e(G6,$le),e($le,wct),e(G6,Act),e(ae,Lct),e(ae,O6),e(O6,Gke),e(Gke,yct),e(O6,xct),e(O6,kle),e(kle,$ct),e(O6,kct),e(ae,Sct),e(ae,V6),e(V6,Oke),e(Oke,Rct),e(V6,Pct),e(V6,Sle),e(Sle,Bct),e(V6,Ict),e(ae,Nct),e(ae,X6),e(X6,Vke),e(Vke,qct),e(X6,jct),e(X6,Rle),e(Rle,Dct),e(X6,Gct),e(ae,Oct),e(ae,z6),e(z6,Xke),e(Xke,Vct),e(z6,Xct),e(z6,Ple),e(Ple,zct),e(z6,Qct),e(ae,Wct),e(ae,Q6),e(Q6,zke),e(zke,Uct),e(Q6,Hct),e(Q6,Ble),e(Ble,Jct),e(Q6,Yct),e(ae,Zct),e(ae,W6),e(W6,Qke),e(Qke,Kct),e(W6,eft),e(W6,Ile),e(Ile,oft),e(W6,rft),e(ae,tft),e(ae,U6),e(U6,Wke),e(Wke,aft),e(U6,nft),e(U6,Nle),e(Nle,sft),e(U6,lft),e(ae,ift),e(ae,H6),e(H6,Uke),e(Uke,dft),e(H6,mft),e(H6,qle),e(qle,cft),e(H6,fft),e(ae,gft),e(ae,J6),e(J6,Hke),e(Hke,hft),e(J6,uft),e(J6,jle),e(jle,pft),e(J6,_ft),e(ae,bft),e(ae,Y6),e(Y6,Jke),e(Jke,vft),e(Y6,Fft),e(Y6,Dle),e(Dle,Tft),e(Y6,Mft),e(ae,Eft),e(ae,Z6),e(Z6,Yke),e(Yke,Cft),e(Z6,wft),e(Z6,Gle),e(Gle,Aft),e(Z6,Lft),e(ae,yft),e(ae,K6),e(K6,Zke),e(Zke,xft),e(K6,$ft),e(K6,Ole),e(Ole,kft),e(K6,Sft),e(ae,Rft),e(ae,e7),e(e7,Kke),e(Kke,Pft),e(e7,Bft),e(e7,Vle),e(Vle,Ift),e(e7,Nft),e(ae,qft),e(ae,o7),e(o7,eSe),e(eSe,jft),e(o7,Dft),e(o7,Xle),e(Xle,Gft),e(o7,Oft),e(ae,Vft),e(ae,r7),e(r7,oSe),e(oSe,Xft),e(r7,zft),e(r7,zle),e(zle,Qft),e(r7,Wft),e(ae,Uft),e(ae,t7),e(t7,rSe),e(rSe,Hft),e(t7,Jft),e(t7,Qle),e(Qle,Yft),e(t7,Zft),e(ae,Kft),e(ae,a7),e(a7,tSe),e(tSe,egt),e(a7,ogt),e(a7,Wle),e(Wle,rgt),e(a7,tgt),e(ae,agt),e(ae,n7),e(n7,aSe),e(aSe,ngt),e(n7,sgt),e(n7,Ule),e(Ule,lgt),e(n7,igt),e(ae,dgt),e(ae,s7),e(s7,nSe),e(nSe,mgt),e(s7,cgt),e(s7,Hle),e(Hle,fgt),e(s7,ggt),e(ae,hgt),e(ae,l7),e(l7,sSe),e(sSe,ugt),e(l7,pgt),e(l7,Jle),e(Jle,_gt),e(l7,bgt),e(ae,vgt),e(ae,i7),e(i7,lSe),e(lSe,Fgt),e(i7,Tgt),e(i7,Yle),e(Yle,Mgt),e(i7,Egt),e(ae,Cgt),e(ae,d7),e(d7,iSe),e(iSe,wgt),e(d7,Agt),e(d7,Zle),e(Zle,Lgt),e(d7,ygt),e(ae,xgt),e(ae,m7),e(m7,dSe),e(dSe,$gt),e(m7,kgt),e(m7,Kle),e(Kle,Sgt),e(m7,Rgt),e(ae,Pgt),e(ae,c7),e(c7,mSe),e(mSe,Bgt),e(c7,Igt),e(c7,eie),e(eie,Ngt),e(c7,qgt),e(ae,jgt),e(ae,f7),e(f7,cSe),e(cSe,Dgt),e(f7,Ggt),e(f7,oie),e(oie,Ogt),e(f7,Vgt),e(Zr,Xgt),M(g7,Zr,null),b(c,kdo,_),b(c,Xc,_),e(Xc,h7),e(h7,fSe),M(bB,fSe,null),e(Xc,zgt),e(Xc,gSe),e(gSe,Qgt),b(c,Sdo,_),b(c,Er,_),M(vB,Er,null),e(Er,Wgt),e(Er,zc),e(zc,Ugt),e(zc,rie),e(rie,Hgt),e(zc,Jgt),e(zc,tie),e(tie,Ygt),e(zc,Zgt),e(Er,Kgt),e(Er,FB),e(FB,eht),e(FB,hSe),e(hSe,oht),e(FB,rht),e(Er,tht),e(Er,da),M(TB,da,null),e(da,aht),e(da,uSe),e(uSe,nht),e(da,sht),e(da,Qc),e(Qc,lht),e(Qc,pSe),e(pSe,iht),e(Qc,dht),e(Qc,aie),e(aie,mht),e(Qc,cht),e(da,fht),M(u7,da,null),e(Er,ght),e(Er,Kr),M(MB,Kr,null),e(Kr,hht),e(Kr,_Se),e(_Se,uht),e(Kr,pht),e(Kr,Jn),e(Jn,_ht),e(Jn,bSe),e(bSe,bht),e(Jn,vht),e(Jn,vSe),e(vSe,Fht),e(Jn,Tht),e(Jn,FSe),e(FSe,Mht),e(Jn,Eht),e(Kr,Cht),e(Kr,Me),e(Me,p7),e(p7,TSe),e(TSe,wht),e(p7,Aht),e(p7,nie),e(nie,Lht),e(p7,yht),e(Me,xht),e(Me,_7),e(_7,MSe),e(MSe,$ht),e(_7,kht),e(_7,sie),e(sie,Sht),e(_7,Rht),e(Me,Pht),e(Me,b7),e(b7,ESe),e(ESe,Bht),e(b7,Iht),e(b7,lie),e(lie,Nht),e(b7,qht),e(Me,jht),e(Me,v7),e(v7,CSe),e(CSe,Dht),e(v7,Ght),e(v7,iie),e(iie,Oht),e(v7,Vht),e(Me,Xht),e(Me,F7),e(F7,wSe),e(wSe,zht),e(F7,Qht),e(F7,die),e(die,Wht),e(F7,Uht),e(Me,Hht),e(Me,T7),e(T7,ASe),e(ASe,Jht),e(T7,Yht),e(T7,mie),e(mie,Zht),e(T7,Kht),e(Me,eut),e(Me,M7),e(M7,LSe),e(LSe,out),e(M7,rut),e(M7,cie),e(cie,tut),e(M7,aut),e(Me,nut),e(Me,E7),e(E7,ySe),e(ySe,sut),e(E7,lut),e(E7,fie),e(fie,iut),e(E7,dut),e(Me,mut),e(Me,C7),e(C7,xSe),e(xSe,cut),e(C7,fut),e(C7,gie),e(gie,gut),e(C7,hut),e(Me,uut),e(Me,w7),e(w7,$Se),e($Se,put),e(w7,_ut),e(w7,hie),e(hie,but),e(w7,vut),e(Me,Fut),e(Me,A7),e(A7,kSe),e(kSe,Tut),e(A7,Mut),e(A7,uie),e(uie,Eut),e(A7,Cut),e(Me,wut),e(Me,L7),e(L7,SSe),e(SSe,Aut),e(L7,Lut),e(L7,pie),e(pie,yut),e(L7,xut),e(Me,$ut),e(Me,y7),e(y7,RSe),e(RSe,kut),e(y7,Sut),e(y7,_ie),e(_ie,Rut),e(y7,Put),e(Me,But),e(Me,x7),e(x7,PSe),e(PSe,Iut),e(x7,Nut),e(x7,bie),e(bie,qut),e(x7,jut),e(Me,Dut),e(Me,$7),e($7,BSe),e(BSe,Gut),e($7,Out),e($7,vie),e(vie,Vut),e($7,Xut),e(Me,zut),e(Me,k7),e(k7,ISe),e(ISe,Qut),e(k7,Wut),e(k7,Fie),e(Fie,Uut),e(k7,Hut),e(Me,Jut),e(Me,S7),e(S7,NSe),e(NSe,Yut),e(S7,Zut),e(S7,Tie),e(Tie,Kut),e(S7,ept),e(Kr,opt),M(R7,Kr,null),b(c,Rdo,_),b(c,Wc,_),e(Wc,P7),e(P7,qSe),M(EB,qSe,null),e(Wc,rpt),e(Wc,jSe),e(jSe,tpt),b(c,Pdo,_),b(c,Cr,_),M(CB,Cr,null),e(Cr,apt),e(Cr,Uc),e(Uc,npt),e(Uc,Mie),e(Mie,spt),e(Uc,lpt),e(Uc,Eie),e(Eie,ipt),e(Uc,dpt),e(Cr,mpt),e(Cr,wB),e(wB,cpt),e(wB,DSe),e(DSe,fpt),e(wB,gpt),e(Cr,hpt),e(Cr,ma),M(AB,ma,null),e(ma,upt),e(ma,GSe),e(GSe,ppt),e(ma,_pt),e(ma,Hc),e(Hc,bpt),e(Hc,OSe),e(OSe,vpt),e(Hc,Fpt),e(Hc,Cie),e(Cie,Tpt),e(Hc,Mpt),e(ma,Ept),M(B7,ma,null),e(Cr,Cpt),e(Cr,et),M(LB,et,null),e(et,wpt),e(et,VSe),e(VSe,Apt),e(et,Lpt),e(et,Yn),e(Yn,ypt),e(Yn,XSe),e(XSe,xpt),e(Yn,$pt),e(Yn,zSe),e(zSe,kpt),e(Yn,Spt),e(Yn,QSe),e(QSe,Rpt),e(Yn,Ppt),e(et,Bpt),e(et,yB),e(yB,I7),e(I7,WSe),e(WSe,Ipt),e(I7,Npt),e(I7,wie),e(wie,qpt),e(I7,jpt),e(yB,Dpt),e(yB,N7),e(N7,USe),e(USe,Gpt),e(N7,Opt),e(N7,Aie),e(Aie,Vpt),e(N7,Xpt),e(et,zpt),M(q7,et,null),b(c,Bdo,_),b(c,Jc,_),e(Jc,j7),e(j7,HSe),M(xB,HSe,null),e(Jc,Qpt),e(Jc,JSe),e(JSe,Wpt),b(c,Ido,_),b(c,wr,_),M($B,wr,null),e(wr,Upt),e(wr,Yc),e(Yc,Hpt),e(Yc,Lie),e(Lie,Jpt),e(Yc,Ypt),e(Yc,yie),e(yie,Zpt),e(Yc,Kpt),e(wr,e_t),e(wr,kB),e(kB,o_t),e(kB,YSe),e(YSe,r_t),e(kB,t_t),e(wr,a_t),e(wr,ca),M(SB,ca,null),e(ca,n_t),e(ca,ZSe),e(ZSe,s_t),e(ca,l_t),e(ca,Zc),e(Zc,i_t),e(Zc,KSe),e(KSe,d_t),e(Zc,m_t),e(Zc,xie),e(xie,c_t),e(Zc,f_t),e(ca,g_t),M(D7,ca,null),e(wr,h_t),e(wr,ot),M(RB,ot,null),e(ot,u_t),e(ot,eRe),e(eRe,p_t),e(ot,__t),e(ot,Zn),e(Zn,b_t),e(Zn,oRe),e(oRe,v_t),e(Zn,F_t),e(Zn,rRe),e(rRe,T_t),e(Zn,M_t),e(Zn,tRe),e(tRe,E_t),e(Zn,C_t),e(ot,w_t),e(ot,aRe),e(aRe,G7),e(G7,nRe),e(nRe,A_t),e(G7,L_t),e(G7,$ie),e($ie,y_t),e(G7,x_t),e(ot,$_t),M(O7,ot,null),b(c,Ndo,_),b(c,Kc,_),e(Kc,V7),e(V7,sRe),M(PB,sRe,null),e(Kc,k_t),e(Kc,lRe),e(lRe,S_t),b(c,qdo,_),b(c,Ar,_),M(BB,Ar,null),e(Ar,R_t),e(Ar,ef),e(ef,P_t),e(ef,kie),e(kie,B_t),e(ef,I_t),e(ef,Sie),e(Sie,N_t),e(ef,q_t),e(Ar,j_t),e(Ar,IB),e(IB,D_t),e(IB,iRe),e(iRe,G_t),e(IB,O_t),e(Ar,V_t),e(Ar,fa),M(NB,fa,null),e(fa,X_t),e(fa,dRe),e(dRe,z_t),e(fa,Q_t),e(fa,of),e(of,W_t),e(of,mRe),e(mRe,U_t),e(of,H_t),e(of,Rie),e(Rie,J_t),e(of,Y_t),e(fa,Z_t),M(X7,fa,null),e(Ar,K_t),e(Ar,rt),M(qB,rt,null),e(rt,e1t),e(rt,cRe),e(cRe,o1t),e(rt,r1t),e(rt,Kn),e(Kn,t1t),e(Kn,fRe),e(fRe,a1t),e(Kn,n1t),e(Kn,gRe),e(gRe,s1t),e(Kn,l1t),e(Kn,hRe),e(hRe,i1t),e(Kn,d1t),e(rt,m1t),e(rt,uRe),e(uRe,z7),e(z7,pRe),e(pRe,c1t),e(z7,f1t),e(z7,Pie),e(Pie,g1t),e(z7,h1t),e(rt,u1t),M(Q7,rt,null),b(c,jdo,_),b(c,rf,_),e(rf,W7),e(W7,_Re),M(jB,_Re,null),e(rf,p1t),e(rf,bRe),e(bRe,_1t),b(c,Ddo,_),b(c,Lr,_),M(DB,Lr,null),e(Lr,b1t),e(Lr,tf),e(tf,v1t),e(tf,Bie),e(Bie,F1t),e(tf,T1t),e(tf,Iie),e(Iie,M1t),e(tf,E1t),e(Lr,C1t),e(Lr,GB),e(GB,w1t),e(GB,vRe),e(vRe,A1t),e(GB,L1t),e(Lr,y1t),e(Lr,ga),M(OB,ga,null),e(ga,x1t),e(ga,FRe),e(FRe,$1t),e(ga,k1t),e(ga,af),e(af,S1t),e(af,TRe),e(TRe,R1t),e(af,P1t),e(af,Nie),e(Nie,B1t),e(af,I1t),e(ga,N1t),M(U7,ga,null),e(Lr,q1t),e(Lr,tt),M(VB,tt,null),e(tt,j1t),e(tt,MRe),e(MRe,D1t),e(tt,G1t),e(tt,es),e(es,O1t),e(es,ERe),e(ERe,V1t),e(es,X1t),e(es,CRe),e(CRe,z1t),e(es,Q1t),e(es,wRe),e(wRe,W1t),e(es,U1t),e(tt,H1t),e(tt,me),e(me,H7),e(H7,ARe),e(ARe,J1t),e(H7,Y1t),e(H7,qie),e(qie,Z1t),e(H7,K1t),e(me,e2t),e(me,J7),e(J7,LRe),e(LRe,o2t),e(J7,r2t),e(J7,jie),e(jie,t2t),e(J7,a2t),e(me,n2t),e(me,Y7),e(Y7,yRe),e(yRe,s2t),e(Y7,l2t),e(Y7,Die),e(Die,i2t),e(Y7,d2t),e(me,m2t),e(me,Z7),e(Z7,xRe),e(xRe,c2t),e(Z7,f2t),e(Z7,Gie),e(Gie,g2t),e(Z7,h2t),e(me,u2t),e(me,K7),e(K7,$Re),e($Re,p2t),e(K7,_2t),e(K7,Oie),e(Oie,b2t),e(K7,v2t),e(me,F2t),e(me,e8),e(e8,kRe),e(kRe,T2t),e(e8,M2t),e(e8,Vie),e(Vie,E2t),e(e8,C2t),e(me,w2t),e(me,o8),e(o8,SRe),e(SRe,A2t),e(o8,L2t),e(o8,Xie),e(Xie,y2t),e(o8,x2t),e(me,$2t),e(me,r8),e(r8,RRe),e(RRe,k2t),e(r8,S2t),e(r8,zie),e(zie,R2t),e(r8,P2t),e(me,B2t),e(me,t8),e(t8,PRe),e(PRe,I2t),e(t8,N2t),e(t8,Qie),e(Qie,q2t),e(t8,j2t),e(me,D2t),e(me,a8),e(a8,BRe),e(BRe,G2t),e(a8,O2t),e(a8,Wie),e(Wie,V2t),e(a8,X2t),e(me,z2t),e(me,n8),e(n8,IRe),e(IRe,Q2t),e(n8,W2t),e(n8,Uie),e(Uie,U2t),e(n8,H2t),e(me,J2t),e(me,s8),e(s8,NRe),e(NRe,Y2t),e(s8,Z2t),e(s8,Hie),e(Hie,K2t),e(s8,ebt),e(me,obt),e(me,l8),e(l8,qRe),e(qRe,rbt),e(l8,tbt),e(l8,Jie),e(Jie,abt),e(l8,nbt),e(me,sbt),e(me,i8),e(i8,jRe),e(jRe,lbt),e(i8,ibt),e(i8,Yie),e(Yie,dbt),e(i8,mbt),e(me,cbt),e(me,d8),e(d8,DRe),e(DRe,fbt),e(d8,gbt),e(d8,Zie),e(Zie,hbt),e(d8,ubt),e(me,pbt),e(me,m8),e(m8,GRe),e(GRe,_bt),e(m8,bbt),e(m8,Kie),e(Kie,vbt),e(m8,Fbt),e(me,Tbt),e(me,c8),e(c8,ORe),e(ORe,Mbt),e(c8,Ebt),e(c8,ede),e(ede,Cbt),e(c8,wbt),e(me,Abt),e(me,f8),e(f8,VRe),e(VRe,Lbt),e(f8,ybt),e(f8,ode),e(ode,xbt),e(f8,$bt),e(me,kbt),e(me,g8),e(g8,XRe),e(XRe,Sbt),e(g8,Rbt),e(g8,rde),e(rde,Pbt),e(g8,Bbt),e(me,Ibt),e(me,h8),e(h8,zRe),e(zRe,Nbt),e(h8,qbt),e(h8,tde),e(tde,jbt),e(h8,Dbt),e(me,Gbt),e(me,u8),e(u8,QRe),e(QRe,Obt),e(u8,Vbt),e(u8,ade),e(ade,Xbt),e(u8,zbt),e(me,Qbt),e(me,p8),e(p8,WRe),e(WRe,Wbt),e(p8,Ubt),e(p8,nde),e(nde,Hbt),e(p8,Jbt),e(tt,Ybt),M(_8,tt,null),b(c,Gdo,_),b(c,nf,_),e(nf,b8),e(b8,URe),M(XB,URe,null),e(nf,Zbt),e(nf,HRe),e(HRe,Kbt),b(c,Odo,_),b(c,yr,_),M(zB,yr,null),e(yr,evt),e(yr,sf),e(sf,ovt),e(sf,sde),e(sde,rvt),e(sf,tvt),e(sf,lde),e(lde,avt),e(sf,nvt),e(yr,svt),e(yr,QB),e(QB,lvt),e(QB,JRe),e(JRe,ivt),e(QB,dvt),e(yr,mvt),e(yr,ha),M(WB,ha,null),e(ha,cvt),e(ha,YRe),e(YRe,fvt),e(ha,gvt),e(ha,lf),e(lf,hvt),e(lf,ZRe),e(ZRe,uvt),e(lf,pvt),e(lf,ide),e(ide,_vt),e(lf,bvt),e(ha,vvt),M(v8,ha,null),e(yr,Fvt),e(yr,at),M(UB,at,null),e(at,Tvt),e(at,KRe),e(KRe,Mvt),e(at,Evt),e(at,os),e(os,Cvt),e(os,ePe),e(ePe,wvt),e(os,Avt),e(os,oPe),e(oPe,Lvt),e(os,yvt),e(os,rPe),e(rPe,xvt),e(os,$vt),e(at,kvt),e(at,he),e(he,F8),e(F8,tPe),e(tPe,Svt),e(F8,Rvt),e(F8,dde),e(dde,Pvt),e(F8,Bvt),e(he,Ivt),e(he,T8),e(T8,aPe),e(aPe,Nvt),e(T8,qvt),e(T8,mde),e(mde,jvt),e(T8,Dvt),e(he,Gvt),e(he,M8),e(M8,nPe),e(nPe,Ovt),e(M8,Vvt),e(M8,cde),e(cde,Xvt),e(M8,zvt),e(he,Qvt),e(he,E8),e(E8,sPe),e(sPe,Wvt),e(E8,Uvt),e(E8,fde),e(fde,Hvt),e(E8,Jvt),e(he,Yvt),e(he,C8),e(C8,lPe),e(lPe,Zvt),e(C8,Kvt),e(C8,gde),e(gde,eFt),e(C8,oFt),e(he,rFt),e(he,w8),e(w8,iPe),e(iPe,tFt),e(w8,aFt),e(w8,hde),e(hde,nFt),e(w8,sFt),e(he,lFt),e(he,A8),e(A8,dPe),e(dPe,iFt),e(A8,dFt),e(A8,ude),e(ude,mFt),e(A8,cFt),e(he,fFt),e(he,L8),e(L8,mPe),e(mPe,gFt),e(L8,hFt),e(L8,pde),e(pde,uFt),e(L8,pFt),e(he,_Ft),e(he,y8),e(y8,cPe),e(cPe,bFt),e(y8,vFt),e(y8,_de),e(_de,FFt),e(y8,TFt),e(he,MFt),e(he,x8),e(x8,fPe),e(fPe,EFt),e(x8,CFt),e(x8,bde),e(bde,wFt),e(x8,AFt),e(he,LFt),e(he,$8),e($8,gPe),e(gPe,yFt),e($8,xFt),e($8,vde),e(vde,$Ft),e($8,kFt),e(he,SFt),e(he,k8),e(k8,hPe),e(hPe,RFt),e(k8,PFt),e(k8,Fde),e(Fde,BFt),e(k8,IFt),e(he,NFt),e(he,S8),e(S8,uPe),e(uPe,qFt),e(S8,jFt),e(S8,Tde),e(Tde,DFt),e(S8,GFt),e(he,OFt),e(he,R8),e(R8,pPe),e(pPe,VFt),e(R8,XFt),e(R8,Mde),e(Mde,zFt),e(R8,QFt),e(he,WFt),e(he,P8),e(P8,_Pe),e(_Pe,UFt),e(P8,HFt),e(P8,Ede),e(Ede,JFt),e(P8,YFt),e(he,ZFt),e(he,B8),e(B8,bPe),e(bPe,KFt),e(B8,eTt),e(B8,Cde),e(Cde,oTt),e(B8,rTt),e(he,tTt),e(he,I8),e(I8,vPe),e(vPe,aTt),e(I8,nTt),e(I8,wde),e(wde,sTt),e(I8,lTt),e(he,iTt),e(he,N8),e(N8,FPe),e(FPe,dTt),e(N8,mTt),e(N8,Ade),e(Ade,cTt),e(N8,fTt),e(he,gTt),e(he,q8),e(q8,TPe),e(TPe,hTt),e(q8,uTt),e(q8,Lde),e(Lde,pTt),e(q8,_Tt),e(he,bTt),e(he,j8),e(j8,MPe),e(MPe,vTt),e(j8,FTt),e(j8,yde),e(yde,TTt),e(j8,MTt),e(he,ETt),e(he,D8),e(D8,EPe),e(EPe,CTt),e(D8,wTt),e(D8,xde),e(xde,ATt),e(D8,LTt),e(at,yTt),M(G8,at,null),b(c,Vdo,_),b(c,df,_),e(df,O8),e(O8,CPe),M(HB,CPe,null),e(df,xTt),e(df,wPe),e(wPe,$Tt),b(c,Xdo,_),b(c,xr,_),M(JB,xr,null),e(xr,kTt),e(xr,mf),e(mf,STt),e(mf,$de),e($de,RTt),e(mf,PTt),e(mf,kde),e(kde,BTt),e(mf,ITt),e(xr,NTt),e(xr,YB),e(YB,qTt),e(YB,APe),e(APe,jTt),e(YB,DTt),e(xr,GTt),e(xr,ua),M(ZB,ua,null),e(ua,OTt),e(ua,LPe),e(LPe,VTt),e(ua,XTt),e(ua,cf),e(cf,zTt),e(cf,yPe),e(yPe,QTt),e(cf,WTt),e(cf,Sde),e(Sde,UTt),e(cf,HTt),e(ua,JTt),M(V8,ua,null),e(xr,YTt),e(xr,nt),M(KB,nt,null),e(nt,ZTt),e(nt,xPe),e(xPe,KTt),e(nt,eMt),e(nt,rs),e(rs,oMt),e(rs,$Pe),e($Pe,rMt),e(rs,tMt),e(rs,kPe),e(kPe,aMt),e(rs,nMt),e(rs,SPe),e(SPe,sMt),e(rs,lMt),e(nt,iMt),e(nt,RPe),e(RPe,X8),e(X8,PPe),e(PPe,dMt),e(X8,mMt),e(X8,Rde),e(Rde,cMt),e(X8,fMt),e(nt,gMt),M(z8,nt,null),b(c,zdo,_),b(c,ff,_),e(ff,Q8),e(Q8,BPe),M(eI,BPe,null),e(ff,hMt),e(ff,IPe),e(IPe,uMt),b(c,Qdo,_),b(c,$r,_),M(oI,$r,null),e($r,pMt),e($r,gf),e(gf,_Mt),e(gf,Pde),e(Pde,bMt),e(gf,vMt),e(gf,Bde),e(Bde,FMt),e(gf,TMt),e($r,MMt),e($r,rI),e(rI,EMt),e(rI,NPe),e(NPe,CMt),e(rI,wMt),e($r,AMt),e($r,pa),M(tI,pa,null),e(pa,LMt),e(pa,qPe),e(qPe,yMt),e(pa,xMt),e(pa,hf),e(hf,$Mt),e(hf,jPe),e(jPe,kMt),e(hf,SMt),e(hf,Ide),e(Ide,RMt),e(hf,PMt),e(pa,BMt),M(W8,pa,null),e($r,IMt),e($r,st),M(aI,st,null),e(st,NMt),e(st,DPe),e(DPe,qMt),e(st,jMt),e(st,ts),e(ts,DMt),e(ts,GPe),e(GPe,GMt),e(ts,OMt),e(ts,OPe),e(OPe,VMt),e(ts,XMt),e(ts,VPe),e(VPe,zMt),e(ts,QMt),e(st,WMt),e(st,nI),e(nI,U8),e(U8,XPe),e(XPe,UMt),e(U8,HMt),e(U8,Nde),e(Nde,JMt),e(U8,YMt),e(nI,ZMt),e(nI,H8),e(H8,zPe),e(zPe,KMt),e(H8,eEt),e(H8,qde),e(qde,oEt),e(H8,rEt),e(st,tEt),M(J8,st,null),b(c,Wdo,_),b(c,uf,_),e(uf,Y8),e(Y8,QPe),M(sI,QPe,null),e(uf,aEt),e(uf,WPe),e(WPe,nEt),b(c,Udo,_),b(c,kr,_),M(lI,kr,null),e(kr,sEt),e(kr,pf),e(pf,lEt),e(pf,jde),e(jde,iEt),e(pf,dEt),e(pf,Dde),e(Dde,mEt),e(pf,cEt),e(kr,fEt),e(kr,iI),e(iI,gEt),e(iI,UPe),e(UPe,hEt),e(iI,uEt),e(kr,pEt),e(kr,_a),M(dI,_a,null),e(_a,_Et),e(_a,HPe),e(HPe,bEt),e(_a,vEt),e(_a,_f),e(_f,FEt),e(_f,JPe),e(JPe,TEt),e(_f,MEt),e(_f,Gde),e(Gde,EEt),e(_f,CEt),e(_a,wEt),M(Z8,_a,null),e(kr,AEt),e(kr,lt),M(mI,lt,null),e(lt,LEt),e(lt,YPe),e(YPe,yEt),e(lt,xEt),e(lt,as),e(as,$Et),e(as,ZPe),e(ZPe,kEt),e(as,SEt),e(as,KPe),e(KPe,REt),e(as,PEt),e(as,eBe),e(eBe,BEt),e(as,IEt),e(lt,NEt),e(lt,ne),e(ne,K8),e(K8,oBe),e(oBe,qEt),e(K8,jEt),e(K8,Ode),e(Ode,DEt),e(K8,GEt),e(ne,OEt),e(ne,eL),e(eL,rBe),e(rBe,VEt),e(eL,XEt),e(eL,Vde),e(Vde,zEt),e(eL,QEt),e(ne,WEt),e(ne,oL),e(oL,tBe),e(tBe,UEt),e(oL,HEt),e(oL,Xde),e(Xde,JEt),e(oL,YEt),e(ne,ZEt),e(ne,rL),e(rL,aBe),e(aBe,KEt),e(rL,e4t),e(rL,zde),e(zde,o4t),e(rL,r4t),e(ne,t4t),e(ne,tL),e(tL,nBe),e(nBe,a4t),e(tL,n4t),e(tL,Qde),e(Qde,s4t),e(tL,l4t),e(ne,i4t),e(ne,aL),e(aL,sBe),e(sBe,d4t),e(aL,m4t),e(aL,Wde),e(Wde,c4t),e(aL,f4t),e(ne,g4t),e(ne,nL),e(nL,lBe),e(lBe,h4t),e(nL,u4t),e(nL,Ude),e(Ude,p4t),e(nL,_4t),e(ne,b4t),e(ne,sL),e(sL,iBe),e(iBe,v4t),e(sL,F4t),e(sL,Hde),e(Hde,T4t),e(sL,M4t),e(ne,E4t),e(ne,lL),e(lL,dBe),e(dBe,C4t),e(lL,w4t),e(lL,Jde),e(Jde,A4t),e(lL,L4t),e(ne,y4t),e(ne,iL),e(iL,mBe),e(mBe,x4t),e(iL,$4t),e(iL,Yde),e(Yde,k4t),e(iL,S4t),e(ne,R4t),e(ne,dL),e(dL,cBe),e(cBe,P4t),e(dL,B4t),e(dL,Zde),e(Zde,I4t),e(dL,N4t),e(ne,q4t),e(ne,mL),e(mL,fBe),e(fBe,j4t),e(mL,D4t),e(mL,Kde),e(Kde,G4t),e(mL,O4t),e(ne,V4t),e(ne,cL),e(cL,gBe),e(gBe,X4t),e(cL,z4t),e(cL,eme),e(eme,Q4t),e(cL,W4t),e(ne,U4t),e(ne,fL),e(fL,hBe),e(hBe,H4t),e(fL,J4t),e(fL,ome),e(ome,Y4t),e(fL,Z4t),e(ne,K4t),e(ne,gL),e(gL,uBe),e(uBe,eCt),e(gL,oCt),e(gL,rme),e(rme,rCt),e(gL,tCt),e(ne,aCt),e(ne,hL),e(hL,pBe),e(pBe,nCt),e(hL,sCt),e(hL,tme),e(tme,lCt),e(hL,iCt),e(ne,dCt),e(ne,uL),e(uL,_Be),e(_Be,mCt),e(uL,cCt),e(uL,ame),e(ame,fCt),e(uL,gCt),e(ne,hCt),e(ne,pL),e(pL,bBe),e(bBe,uCt),e(pL,pCt),e(pL,nme),e(nme,_Ct),e(pL,bCt),e(ne,vCt),e(ne,_L),e(_L,vBe),e(vBe,FCt),e(_L,TCt),e(_L,sme),e(sme,MCt),e(_L,ECt),e(ne,CCt),e(ne,bL),e(bL,FBe),e(FBe,wCt),e(bL,ACt),e(bL,lme),e(lme,LCt),e(bL,yCt),e(ne,xCt),e(ne,vL),e(vL,TBe),e(TBe,$Ct),e(vL,kCt),e(vL,ime),e(ime,SCt),e(vL,RCt),e(ne,PCt),e(ne,FL),e(FL,MBe),e(MBe,BCt),e(FL,ICt),e(FL,dme),e(dme,NCt),e(FL,qCt),e(ne,jCt),e(ne,TL),e(TL,EBe),e(EBe,DCt),e(TL,GCt),e(TL,mme),e(mme,OCt),e(TL,VCt),e(ne,XCt),e(ne,ML),e(ML,CBe),e(CBe,zCt),e(ML,QCt),e(ML,cme),e(cme,WCt),e(ML,UCt),e(ne,HCt),e(ne,EL),e(EL,wBe),e(wBe,JCt),e(EL,YCt),e(EL,fme),e(fme,ZCt),e(EL,KCt),e(ne,e3t),e(ne,CL),e(CL,ABe),e(ABe,o3t),e(CL,r3t),e(CL,gme),e(gme,t3t),e(CL,a3t),e(ne,n3t),e(ne,wL),e(wL,LBe),e(LBe,s3t),e(wL,l3t),e(wL,hme),e(hme,i3t),e(wL,d3t),e(lt,m3t),M(AL,lt,null),b(c,Hdo,_),b(c,bf,_),e(bf,LL),e(LL,yBe),M(cI,yBe,null),e(bf,c3t),e(bf,xBe),e(xBe,f3t),b(c,Jdo,_),b(c,Sr,_),M(fI,Sr,null),e(Sr,g3t),e(Sr,vf),e(vf,h3t),e(vf,ume),e(ume,u3t),e(vf,p3t),e(vf,pme),e(pme,_3t),e(vf,b3t),e(Sr,v3t),e(Sr,gI),e(gI,F3t),e(gI,$Be),e($Be,T3t),e(gI,M3t),e(Sr,E3t),e(Sr,ba),M(hI,ba,null),e(ba,C3t),e(ba,kBe),e(kBe,w3t),e(ba,A3t),e(ba,Ff),e(Ff,L3t),e(Ff,SBe),e(SBe,y3t),e(Ff,x3t),e(Ff,_me),e(_me,$3t),e(Ff,k3t),e(ba,S3t),M(yL,ba,null),e(Sr,R3t),e(Sr,it),M(uI,it,null),e(it,P3t),e(it,RBe),e(RBe,B3t),e(it,I3t),e(it,ns),e(ns,N3t),e(ns,PBe),e(PBe,q3t),e(ns,j3t),e(ns,BBe),e(BBe,D3t),e(ns,G3t),e(ns,IBe),e(IBe,O3t),e(ns,V3t),e(it,X3t),e(it,Se),e(Se,xL),e(xL,NBe),e(NBe,z3t),e(xL,Q3t),e(xL,bme),e(bme,W3t),e(xL,U3t),e(Se,H3t),e(Se,$L),e($L,qBe),e(qBe,J3t),e($L,Y3t),e($L,vme),e(vme,Z3t),e($L,K3t),e(Se,e5t),e(Se,kL),e(kL,jBe),e(jBe,o5t),e(kL,r5t),e(kL,Fme),e(Fme,t5t),e(kL,a5t),e(Se,n5t),e(Se,SL),e(SL,DBe),e(DBe,s5t),e(SL,l5t),e(SL,Tme),e(Tme,i5t),e(SL,d5t),e(Se,m5t),e(Se,RL),e(RL,GBe),e(GBe,c5t),e(RL,f5t),e(RL,Mme),e(Mme,g5t),e(RL,h5t),e(Se,u5t),e(Se,PL),e(PL,OBe),e(OBe,p5t),e(PL,_5t),e(PL,Eme),e(Eme,b5t),e(PL,v5t),e(Se,F5t),e(Se,BL),e(BL,VBe),e(VBe,T5t),e(BL,M5t),e(BL,Cme),e(Cme,E5t),e(BL,C5t),e(Se,w5t),e(Se,IL),e(IL,XBe),e(XBe,A5t),e(IL,L5t),e(IL,wme),e(wme,y5t),e(IL,x5t),e(Se,$5t),e(Se,NL),e(NL,zBe),e(zBe,k5t),e(NL,S5t),e(NL,Ame),e(Ame,R5t),e(NL,P5t),e(Se,B5t),e(Se,qL),e(qL,QBe),e(QBe,I5t),e(qL,N5t),e(qL,Lme),e(Lme,q5t),e(qL,j5t),e(it,D5t),M(jL,it,null),b(c,Ydo,_),b(c,Tf,_),e(Tf,DL),e(DL,WBe),M(pI,WBe,null),e(Tf,G5t),e(Tf,UBe),e(UBe,O5t),b(c,Zdo,_),b(c,Rr,_),M(_I,Rr,null),e(Rr,V5t),e(Rr,Mf),e(Mf,X5t),e(Mf,yme),e(yme,z5t),e(Mf,Q5t),e(Mf,xme),e(xme,W5t),e(Mf,U5t),e(Rr,H5t),e(Rr,bI),e(bI,J5t),e(bI,HBe),e(HBe,Y5t),e(bI,Z5t),e(Rr,K5t),e(Rr,va),M(vI,va,null),e(va,e0t),e(va,JBe),e(JBe,o0t),e(va,r0t),e(va,Ef),e(Ef,t0t),e(Ef,YBe),e(YBe,a0t),e(Ef,n0t),e(Ef,$me),e($me,s0t),e(Ef,l0t),e(va,i0t),M(GL,va,null),e(Rr,d0t),e(Rr,dt),M(FI,dt,null),e(dt,m0t),e(dt,ZBe),e(ZBe,c0t),e(dt,f0t),e(dt,ss),e(ss,g0t),e(ss,KBe),e(KBe,h0t),e(ss,u0t),e(ss,eIe),e(eIe,p0t),e(ss,_0t),e(ss,oIe),e(oIe,b0t),e(ss,v0t),e(dt,F0t),e(dt,we),e(we,OL),e(OL,rIe),e(rIe,T0t),e(OL,M0t),e(OL,kme),e(kme,E0t),e(OL,C0t),e(we,w0t),e(we,VL),e(VL,tIe),e(tIe,A0t),e(VL,L0t),e(VL,Sme),e(Sme,y0t),e(VL,x0t),e(we,$0t),e(we,XL),e(XL,aIe),e(aIe,k0t),e(XL,S0t),e(XL,Rme),e(Rme,R0t),e(XL,P0t),e(we,B0t),e(we,zL),e(zL,nIe),e(nIe,I0t),e(zL,N0t),e(zL,Pme),e(Pme,q0t),e(zL,j0t),e(we,D0t),e(we,QL),e(QL,sIe),e(sIe,G0t),e(QL,O0t),e(QL,Bme),e(Bme,V0t),e(QL,X0t),e(we,z0t),e(we,WL),e(WL,lIe),e(lIe,Q0t),e(WL,W0t),e(WL,Ime),e(Ime,U0t),e(WL,H0t),e(we,J0t),e(we,UL),e(UL,iIe),e(iIe,Y0t),e(UL,Z0t),e(UL,Nme),e(Nme,K0t),e(UL,ewt),e(we,owt),e(we,HL),e(HL,dIe),e(dIe,rwt),e(HL,twt),e(HL,qme),e(qme,awt),e(HL,nwt),e(we,swt),e(we,JL),e(JL,mIe),e(mIe,lwt),e(JL,iwt),e(JL,jme),e(jme,dwt),e(JL,mwt),e(we,cwt),e(we,YL),e(YL,cIe),e(cIe,fwt),e(YL,gwt),e(YL,Dme),e(Dme,hwt),e(YL,uwt),e(we,pwt),e(we,ZL),e(ZL,fIe),e(fIe,_wt),e(ZL,bwt),e(ZL,Gme),e(Gme,vwt),e(ZL,Fwt),e(we,Twt),e(we,KL),e(KL,gIe),e(gIe,Mwt),e(KL,Ewt),e(KL,Ome),e(Ome,Cwt),e(KL,wwt),e(we,Awt),e(we,ey),e(ey,hIe),e(hIe,Lwt),e(ey,ywt),e(ey,Vme),e(Vme,xwt),e(ey,$wt),e(dt,kwt),M(oy,dt,null),b(c,Kdo,_),b(c,Cf,_),e(Cf,ry),e(ry,uIe),M(TI,uIe,null),e(Cf,Swt),e(Cf,pIe),e(pIe,Rwt),b(c,emo,_),b(c,Pr,_),M(MI,Pr,null),e(Pr,Pwt),e(Pr,wf),e(wf,Bwt),e(wf,Xme),e(Xme,Iwt),e(wf,Nwt),e(wf,zme),e(zme,qwt),e(wf,jwt),e(Pr,Dwt),e(Pr,EI),e(EI,Gwt),e(EI,_Ie),e(_Ie,Owt),e(EI,Vwt),e(Pr,Xwt),e(Pr,Fa),M(CI,Fa,null),e(Fa,zwt),e(Fa,bIe),e(bIe,Qwt),e(Fa,Wwt),e(Fa,Af),e(Af,Uwt),e(Af,vIe),e(vIe,Hwt),e(Af,Jwt),e(Af,Qme),e(Qme,Ywt),e(Af,Zwt),e(Fa,Kwt),M(ty,Fa,null),e(Pr,eAt),e(Pr,mt),M(wI,mt,null),e(mt,oAt),e(mt,FIe),e(FIe,rAt),e(mt,tAt),e(mt,ls),e(ls,aAt),e(ls,TIe),e(TIe,nAt),e(ls,sAt),e(ls,MIe),e(MIe,lAt),e(ls,iAt),e(ls,EIe),e(EIe,dAt),e(ls,mAt),e(mt,cAt),e(mt,Re),e(Re,ay),e(ay,CIe),e(CIe,fAt),e(ay,gAt),e(ay,Wme),e(Wme,hAt),e(ay,uAt),e(Re,pAt),e(Re,ny),e(ny,wIe),e(wIe,_At),e(ny,bAt),e(ny,Ume),e(Ume,vAt),e(ny,FAt),e(Re,TAt),e(Re,sy),e(sy,AIe),e(AIe,MAt),e(sy,EAt),e(sy,Hme),e(Hme,CAt),e(sy,wAt),e(Re,AAt),e(Re,ly),e(ly,LIe),e(LIe,LAt),e(ly,yAt),e(ly,Jme),e(Jme,xAt),e(ly,$At),e(Re,kAt),e(Re,iy),e(iy,yIe),e(yIe,SAt),e(iy,RAt),e(iy,Yme),e(Yme,PAt),e(iy,BAt),e(Re,IAt),e(Re,dy),e(dy,xIe),e(xIe,NAt),e(dy,qAt),e(dy,Zme),e(Zme,jAt),e(dy,DAt),e(Re,GAt),e(Re,my),e(my,$Ie),e($Ie,OAt),e(my,VAt),e(my,Kme),e(Kme,XAt),e(my,zAt),e(Re,QAt),e(Re,cy),e(cy,kIe),e(kIe,WAt),e(cy,UAt),e(cy,ece),e(ece,HAt),e(cy,JAt),e(Re,YAt),e(Re,fy),e(fy,SIe),e(SIe,ZAt),e(fy,KAt),e(fy,oce),e(oce,e6t),e(fy,o6t),e(Re,r6t),e(Re,gy),e(gy,RIe),e(RIe,t6t),e(gy,a6t),e(gy,rce),e(rce,n6t),e(gy,s6t),e(mt,l6t),M(hy,mt,null),b(c,omo,_),b(c,Lf,_),e(Lf,uy),e(uy,PIe),M(AI,PIe,null),e(Lf,i6t),e(Lf,BIe),e(BIe,d6t),b(c,rmo,_),b(c,Br,_),M(LI,Br,null),e(Br,m6t),e(Br,yf),e(yf,c6t),e(yf,tce),e(tce,f6t),e(yf,g6t),e(yf,ace),e(ace,h6t),e(yf,u6t),e(Br,p6t),e(Br,yI),e(yI,_6t),e(yI,IIe),e(IIe,b6t),e(yI,v6t),e(Br,F6t),e(Br,Ta),M(xI,Ta,null),e(Ta,T6t),e(Ta,NIe),e(NIe,M6t),e(Ta,E6t),e(Ta,xf),e(xf,C6t),e(xf,qIe),e(qIe,w6t),e(xf,A6t),e(xf,nce),e(nce,L6t),e(xf,y6t),e(Ta,x6t),M(py,Ta,null),e(Br,$6t),e(Br,ct),M($I,ct,null),e(ct,k6t),e(ct,jIe),e(jIe,S6t),e(ct,R6t),e(ct,is),e(is,P6t),e(is,DIe),e(DIe,B6t),e(is,I6t),e(is,GIe),e(GIe,N6t),e(is,q6t),e(is,OIe),e(OIe,j6t),e(is,D6t),e(ct,G6t),e(ct,Pe),e(Pe,_y),e(_y,VIe),e(VIe,O6t),e(_y,V6t),e(_y,sce),e(sce,X6t),e(_y,z6t),e(Pe,Q6t),e(Pe,by),e(by,XIe),e(XIe,W6t),e(by,U6t),e(by,lce),e(lce,H6t),e(by,J6t),e(Pe,Y6t),e(Pe,vy),e(vy,zIe),e(zIe,Z6t),e(vy,K6t),e(vy,ice),e(ice,e7t),e(vy,o7t),e(Pe,r7t),e(Pe,Fy),e(Fy,QIe),e(QIe,t7t),e(Fy,a7t),e(Fy,dce),e(dce,n7t),e(Fy,s7t),e(Pe,l7t),e(Pe,Ty),e(Ty,WIe),e(WIe,i7t),e(Ty,d7t),e(Ty,mce),e(mce,m7t),e(Ty,c7t),e(Pe,f7t),e(Pe,My),e(My,UIe),e(UIe,g7t),e(My,h7t),e(My,cce),e(cce,u7t),e(My,p7t),e(Pe,_7t),e(Pe,Ey),e(Ey,HIe),e(HIe,b7t),e(Ey,v7t),e(Ey,fce),e(fce,F7t),e(Ey,T7t),e(Pe,M7t),e(Pe,Cy),e(Cy,JIe),e(JIe,E7t),e(Cy,C7t),e(Cy,gce),e(gce,w7t),e(Cy,A7t),e(Pe,L7t),e(Pe,wy),e(wy,YIe),e(YIe,y7t),e(wy,x7t),e(wy,hce),e(hce,$7t),e(wy,k7t),e(Pe,S7t),e(Pe,Ay),e(Ay,ZIe),e(ZIe,R7t),e(Ay,P7t),e(Ay,uce),e(uce,B7t),e(Ay,I7t),e(ct,N7t),M(Ly,ct,null),b(c,tmo,_),b(c,$f,_),e($f,yy),e(yy,KIe),M(kI,KIe,null),e($f,q7t),e($f,eNe),e(eNe,j7t),b(c,amo,_),b(c,Ir,_),M(SI,Ir,null),e(Ir,D7t),e(Ir,kf),e(kf,G7t),e(kf,pce),e(pce,O7t),e(kf,V7t),e(kf,_ce),e(_ce,X7t),e(kf,z7t),e(Ir,Q7t),e(Ir,RI),e(RI,W7t),e(RI,oNe),e(oNe,U7t),e(RI,H7t),e(Ir,J7t),e(Ir,Ma),M(PI,Ma,null),e(Ma,Y7t),e(Ma,rNe),e(rNe,Z7t),e(Ma,K7t),e(Ma,Sf),e(Sf,e8t),e(Sf,tNe),e(tNe,o8t),e(Sf,r8t),e(Sf,bce),e(bce,t8t),e(Sf,a8t),e(Ma,n8t),M(xy,Ma,null),e(Ir,s8t),e(Ir,ft),M(BI,ft,null),e(ft,l8t),e(ft,aNe),e(aNe,i8t),e(ft,d8t),e(ft,ds),e(ds,m8t),e(ds,nNe),e(nNe,c8t),e(ds,f8t),e(ds,sNe),e(sNe,g8t),e(ds,h8t),e(ds,lNe),e(lNe,u8t),e(ds,p8t),e(ft,_8t),e(ft,Be),e(Be,$y),e($y,iNe),e(iNe,b8t),e($y,v8t),e($y,vce),e(vce,F8t),e($y,T8t),e(Be,M8t),e(Be,ky),e(ky,dNe),e(dNe,E8t),e(ky,C8t),e(ky,Fce),e(Fce,w8t),e(ky,A8t),e(Be,L8t),e(Be,Sy),e(Sy,mNe),e(mNe,y8t),e(Sy,x8t),e(Sy,Tce),e(Tce,$8t),e(Sy,k8t),e(Be,S8t),e(Be,Ry),e(Ry,cNe),e(cNe,R8t),e(Ry,P8t),e(Ry,Mce),e(Mce,B8t),e(Ry,I8t),e(Be,N8t),e(Be,Py),e(Py,fNe),e(fNe,q8t),e(Py,j8t),e(Py,Ece),e(Ece,D8t),e(Py,G8t),e(Be,O8t),e(Be,By),e(By,gNe),e(gNe,V8t),e(By,X8t),e(By,Cce),e(Cce,z8t),e(By,Q8t),e(Be,W8t),e(Be,Iy),e(Iy,hNe),e(hNe,U8t),e(Iy,H8t),e(Iy,wce),e(wce,J8t),e(Iy,Y8t),e(Be,Z8t),e(Be,Ny),e(Ny,uNe),e(uNe,K8t),e(Ny,eLt),e(Ny,Ace),e(Ace,oLt),e(Ny,rLt),e(Be,tLt),e(Be,qy),e(qy,pNe),e(pNe,aLt),e(qy,nLt),e(qy,Lce),e(Lce,sLt),e(qy,lLt),e(Be,iLt),e(Be,jy),e(jy,_Ne),e(_Ne,dLt),e(jy,mLt),e(jy,yce),e(yce,cLt),e(jy,fLt),e(ft,gLt),M(Dy,ft,null),b(c,nmo,_),b(c,Rf,_),e(Rf,Gy),e(Gy,bNe),M(II,bNe,null),e(Rf,hLt),e(Rf,vNe),e(vNe,uLt),b(c,smo,_),b(c,Nr,_),M(NI,Nr,null),e(Nr,pLt),e(Nr,Pf),e(Pf,_Lt),e(Pf,xce),e(xce,bLt),e(Pf,vLt),e(Pf,$ce),e($ce,FLt),e(Pf,TLt),e(Nr,MLt),e(Nr,qI),e(qI,ELt),e(qI,FNe),e(FNe,CLt),e(qI,wLt),e(Nr,ALt),e(Nr,Ea),M(jI,Ea,null),e(Ea,LLt),e(Ea,TNe),e(TNe,yLt),e(Ea,xLt),e(Ea,Bf),e(Bf,$Lt),e(Bf,MNe),e(MNe,kLt),e(Bf,SLt),e(Bf,kce),e(kce,RLt),e(Bf,PLt),e(Ea,BLt),M(Oy,Ea,null),e(Nr,ILt),e(Nr,gt),M(DI,gt,null),e(gt,NLt),e(gt,ENe),e(ENe,qLt),e(gt,jLt),e(gt,ms),e(ms,DLt),e(ms,CNe),e(CNe,GLt),e(ms,OLt),e(ms,wNe),e(wNe,VLt),e(ms,XLt),e(ms,ANe),e(ANe,zLt),e(ms,QLt),e(gt,WLt),e(gt,Ie),e(Ie,Vy),e(Vy,LNe),e(LNe,ULt),e(Vy,HLt),e(Vy,Sce),e(Sce,JLt),e(Vy,YLt),e(Ie,ZLt),e(Ie,Xy),e(Xy,yNe),e(yNe,KLt),e(Xy,eyt),e(Xy,Rce),e(Rce,oyt),e(Xy,ryt),e(Ie,tyt),e(Ie,zy),e(zy,xNe),e(xNe,ayt),e(zy,nyt),e(zy,Pce),e(Pce,syt),e(zy,lyt),e(Ie,iyt),e(Ie,Qy),e(Qy,$Ne),e($Ne,dyt),e(Qy,myt),e(Qy,Bce),e(Bce,cyt),e(Qy,fyt),e(Ie,gyt),e(Ie,Wy),e(Wy,kNe),e(kNe,hyt),e(Wy,uyt),e(Wy,Ice),e(Ice,pyt),e(Wy,_yt),e(Ie,byt),e(Ie,Uy),e(Uy,SNe),e(SNe,vyt),e(Uy,Fyt),e(Uy,Nce),e(Nce,Tyt),e(Uy,Myt),e(Ie,Eyt),e(Ie,Hy),e(Hy,RNe),e(RNe,Cyt),e(Hy,wyt),e(Hy,qce),e(qce,Ayt),e(Hy,Lyt),e(Ie,yyt),e(Ie,Jy),e(Jy,PNe),e(PNe,xyt),e(Jy,$yt),e(Jy,jce),e(jce,kyt),e(Jy,Syt),e(Ie,Ryt),e(Ie,Yy),e(Yy,BNe),e(BNe,Pyt),e(Yy,Byt),e(Yy,Dce),e(Dce,Iyt),e(Yy,Nyt),e(Ie,qyt),e(Ie,Zy),e(Zy,INe),e(INe,jyt),e(Zy,Dyt),e(Zy,Gce),e(Gce,Gyt),e(Zy,Oyt),e(gt,Vyt),M(Ky,gt,null),b(c,lmo,_),b(c,If,_),e(If,e9),e(e9,NNe),M(GI,NNe,null),e(If,Xyt),e(If,qNe),e(qNe,zyt),b(c,imo,_),b(c,qr,_),M(OI,qr,null),e(qr,Qyt),e(qr,Nf),e(Nf,Wyt),e(Nf,Oce),e(Oce,Uyt),e(Nf,Hyt),e(Nf,Vce),e(Vce,Jyt),e(Nf,Yyt),e(qr,Zyt),e(qr,VI),e(VI,Kyt),e(VI,jNe),e(jNe,e9t),e(VI,o9t),e(qr,r9t),e(qr,Ca),M(XI,Ca,null),e(Ca,t9t),e(Ca,DNe),e(DNe,a9t),e(Ca,n9t),e(Ca,qf),e(qf,s9t),e(qf,GNe),e(GNe,l9t),e(qf,i9t),e(qf,Xce),e(Xce,d9t),e(qf,m9t),e(Ca,c9t),M(o9,Ca,null),e(qr,f9t),e(qr,ht),M(zI,ht,null),e(ht,g9t),e(ht,ONe),e(ONe,h9t),e(ht,u9t),e(ht,cs),e(cs,p9t),e(cs,VNe),e(VNe,_9t),e(cs,b9t),e(cs,XNe),e(XNe,v9t),e(cs,F9t),e(cs,zNe),e(zNe,T9t),e(cs,M9t),e(ht,E9t),e(ht,We),e(We,r9),e(r9,QNe),e(QNe,C9t),e(r9,w9t),e(r9,zce),e(zce,A9t),e(r9,L9t),e(We,y9t),e(We,t9),e(t9,WNe),e(WNe,x9t),e(t9,$9t),e(t9,Qce),e(Qce,k9t),e(t9,S9t),e(We,R9t),e(We,a9),e(a9,UNe),e(UNe,P9t),e(a9,B9t),e(a9,Wce),e(Wce,I9t),e(a9,N9t),e(We,q9t),e(We,n9),e(n9,HNe),e(HNe,j9t),e(n9,D9t),e(n9,Uce),e(Uce,G9t),e(n9,O9t),e(We,V9t),e(We,s9),e(s9,JNe),e(JNe,X9t),e(s9,z9t),e(s9,Hce),e(Hce,Q9t),e(s9,W9t),e(We,U9t),e(We,l9),e(l9,YNe),e(YNe,H9t),e(l9,J9t),e(l9,Jce),e(Jce,Y9t),e(l9,Z9t),e(We,K9t),e(We,i9),e(i9,ZNe),e(ZNe,ext),e(i9,oxt),e(i9,Yce),e(Yce,rxt),e(i9,txt),e(We,axt),e(We,d9),e(d9,KNe),e(KNe,nxt),e(d9,sxt),e(d9,Zce),e(Zce,lxt),e(d9,ixt),e(ht,dxt),M(m9,ht,null),b(c,dmo,_),b(c,jf,_),e(jf,c9),e(c9,eqe),M(QI,eqe,null),e(jf,mxt),e(jf,oqe),e(oqe,cxt),b(c,mmo,_),b(c,jr,_),M(WI,jr,null),e(jr,fxt),e(jr,Df),e(Df,gxt),e(Df,Kce),e(Kce,hxt),e(Df,uxt),e(Df,efe),e(efe,pxt),e(Df,_xt),e(jr,bxt),e(jr,UI),e(UI,vxt),e(UI,rqe),e(rqe,Fxt),e(UI,Txt),e(jr,Mxt),e(jr,wa),M(HI,wa,null),e(wa,Ext),e(wa,tqe),e(tqe,Cxt),e(wa,wxt),e(wa,Gf),e(Gf,Axt),e(Gf,aqe),e(aqe,Lxt),e(Gf,yxt),e(Gf,ofe),e(ofe,xxt),e(Gf,$xt),e(wa,kxt),M(f9,wa,null),e(jr,Sxt),e(jr,ut),M(JI,ut,null),e(ut,Rxt),e(ut,nqe),e(nqe,Pxt),e(ut,Bxt),e(ut,fs),e(fs,Ixt),e(fs,sqe),e(sqe,Nxt),e(fs,qxt),e(fs,lqe),e(lqe,jxt),e(fs,Dxt),e(fs,iqe),e(iqe,Gxt),e(fs,Oxt),e(ut,Vxt),e(ut,Ue),e(Ue,g9),e(g9,dqe),e(dqe,Xxt),e(g9,zxt),e(g9,rfe),e(rfe,Qxt),e(g9,Wxt),e(Ue,Uxt),e(Ue,h9),e(h9,mqe),e(mqe,Hxt),e(h9,Jxt),e(h9,tfe),e(tfe,Yxt),e(h9,Zxt),e(Ue,Kxt),e(Ue,u9),e(u9,cqe),e(cqe,e$t),e(u9,o$t),e(u9,afe),e(afe,r$t),e(u9,t$t),e(Ue,a$t),e(Ue,p9),e(p9,fqe),e(fqe,n$t),e(p9,s$t),e(p9,nfe),e(nfe,l$t),e(p9,i$t),e(Ue,d$t),e(Ue,_9),e(_9,gqe),e(gqe,m$t),e(_9,c$t),e(_9,sfe),e(sfe,f$t),e(_9,g$t),e(Ue,h$t),e(Ue,b9),e(b9,hqe),e(hqe,u$t),e(b9,p$t),e(b9,lfe),e(lfe,_$t),e(b9,b$t),e(Ue,v$t),e(Ue,v9),e(v9,uqe),e(uqe,F$t),e(v9,T$t),e(v9,ife),e(ife,M$t),e(v9,E$t),e(Ue,C$t),e(Ue,F9),e(F9,pqe),e(pqe,w$t),e(F9,A$t),e(F9,dfe),e(dfe,L$t),e(F9,y$t),e(ut,x$t),M(T9,ut,null),b(c,cmo,_),b(c,Of,_),e(Of,M9),e(M9,_qe),M(YI,_qe,null),e(Of,$$t),e(Of,bqe),e(bqe,k$t),b(c,fmo,_),b(c,Dr,_),M(ZI,Dr,null),e(Dr,S$t),e(Dr,Vf),e(Vf,R$t),e(Vf,mfe),e(mfe,P$t),e(Vf,B$t),e(Vf,cfe),e(cfe,I$t),e(Vf,N$t),e(Dr,q$t),e(Dr,KI),e(KI,j$t),e(KI,vqe),e(vqe,D$t),e(KI,G$t),e(Dr,O$t),e(Dr,Aa),M(eN,Aa,null),e(Aa,V$t),e(Aa,Fqe),e(Fqe,X$t),e(Aa,z$t),e(Aa,Xf),e(Xf,Q$t),e(Xf,Tqe),e(Tqe,W$t),e(Xf,U$t),e(Xf,ffe),e(ffe,H$t),e(Xf,J$t),e(Aa,Y$t),M(E9,Aa,null),e(Dr,Z$t),e(Dr,pt),M(oN,pt,null),e(pt,K$t),e(pt,Mqe),e(Mqe,ekt),e(pt,okt),e(pt,gs),e(gs,rkt),e(gs,Eqe),e(Eqe,tkt),e(gs,akt),e(gs,Cqe),e(Cqe,nkt),e(gs,skt),e(gs,wqe),e(wqe,lkt),e(gs,ikt),e(pt,dkt),e(pt,Aqe),e(Aqe,C9),e(C9,Lqe),e(Lqe,mkt),e(C9,ckt),e(C9,gfe),e(gfe,fkt),e(C9,gkt),e(pt,hkt),M(w9,pt,null),b(c,gmo,_),b(c,zf,_),e(zf,A9),e(A9,yqe),M(rN,yqe,null),e(zf,ukt),e(zf,xqe),e(xqe,pkt),b(c,hmo,_),b(c,Gr,_),M(tN,Gr,null),e(Gr,_kt),e(Gr,Qf),e(Qf,bkt),e(Qf,hfe),e(hfe,vkt),e(Qf,Fkt),e(Qf,ufe),e(ufe,Tkt),e(Qf,Mkt),e(Gr,Ekt),e(Gr,aN),e(aN,Ckt),e(aN,$qe),e($qe,wkt),e(aN,Akt),e(Gr,Lkt),e(Gr,La),M(nN,La,null),e(La,ykt),e(La,kqe),e(kqe,xkt),e(La,$kt),e(La,Wf),e(Wf,kkt),e(Wf,Sqe),e(Sqe,Skt),e(Wf,Rkt),e(Wf,pfe),e(pfe,Pkt),e(Wf,Bkt),e(La,Ikt),M(L9,La,null),e(Gr,Nkt),e(Gr,_t),M(sN,_t,null),e(_t,qkt),e(_t,Rqe),e(Rqe,jkt),e(_t,Dkt),e(_t,hs),e(hs,Gkt),e(hs,Pqe),e(Pqe,Okt),e(hs,Vkt),e(hs,Bqe),e(Bqe,Xkt),e(hs,zkt),e(hs,Iqe),e(Iqe,Qkt),e(hs,Wkt),e(_t,Ukt),e(_t,lN),e(lN,y9),e(y9,Nqe),e(Nqe,Hkt),e(y9,Jkt),e(y9,_fe),e(_fe,Ykt),e(y9,Zkt),e(lN,Kkt),e(lN,x9),e(x9,qqe),e(qqe,eSt),e(x9,oSt),e(x9,bfe),e(bfe,rSt),e(x9,tSt),e(_t,aSt),M($9,_t,null),b(c,umo,_),b(c,Uf,_),e(Uf,k9),e(k9,jqe),M(iN,jqe,null),e(Uf,nSt),e(Uf,Dqe),e(Dqe,sSt),b(c,pmo,_),b(c,Or,_),M(dN,Or,null),e(Or,lSt),e(Or,Hf),e(Hf,iSt),e(Hf,vfe),e(vfe,dSt),e(Hf,mSt),e(Hf,Ffe),e(Ffe,cSt),e(Hf,fSt),e(Or,gSt),e(Or,mN),e(mN,hSt),e(mN,Gqe),e(Gqe,uSt),e(mN,pSt),e(Or,_St),e(Or,ya),M(cN,ya,null),e(ya,bSt),e(ya,Oqe),e(Oqe,vSt),e(ya,FSt),e(ya,Jf),e(Jf,TSt),e(Jf,Vqe),e(Vqe,MSt),e(Jf,ESt),e(Jf,Tfe),e(Tfe,CSt),e(Jf,wSt),e(ya,ASt),M(S9,ya,null),e(Or,LSt),e(Or,bt),M(fN,bt,null),e(bt,ySt),e(bt,Xqe),e(Xqe,xSt),e(bt,$St),e(bt,us),e(us,kSt),e(us,zqe),e(zqe,SSt),e(us,RSt),e(us,Qqe),e(Qqe,PSt),e(us,BSt),e(us,Wqe),e(Wqe,ISt),e(us,NSt),e(bt,qSt),e(bt,Uqe),e(Uqe,R9),e(R9,Hqe),e(Hqe,jSt),e(R9,DSt),e(R9,Mfe),e(Mfe,GSt),e(R9,OSt),e(bt,VSt),M(P9,bt,null),_mo=!0},p(c,[_]){const gN={};_&2&&(gN.$$scope={dirty:_,ctx:c}),ng.$set(gN);const Jqe={};_&2&&(Jqe.$$scope={dirty:_,ctx:c}),qu.$set(Jqe);const Yqe={};_&2&&(Yqe.$$scope={dirty:_,ctx:c}),wp.$set(Yqe);const Zqe={};_&2&&(Zqe.$$scope={dirty:_,ctx:c}),F_.$set(Zqe);const hN={};_&2&&(hN.$$scope={dirty:_,ctx:c}),T_.$set(hN);const Kqe={};_&2&&(Kqe.$$scope={dirty:_,ctx:c}),e1.$set(Kqe);const ps={};_&2&&(ps.$$scope={dirty:_,ctx:c}),o1.$set(ps);const eje={};_&2&&(eje.$$scope={dirty:_,ctx:c}),L1.$set(eje);const oje={};_&2&&(oje.$$scope={dirty:_,ctx:c}),y1.$set(oje);const rje={};_&2&&(rje.$$scope={dirty:_,ctx:c}),k1.$set(rje);const uN={};_&2&&(uN.$$scope={dirty:_,ctx:c}),tv.$set(uN);const tje={};_&2&&(tje.$$scope={dirty:_,ctx:c}),nv.$set(tje);const pN={};_&2&&(pN.$$scope={dirty:_,ctx:c}),rF.$set(pN);const aje={};_&2&&(aje.$$scope={dirty:_,ctx:c}),aF.$set(aje);const _N={};_&2&&(_N.$$scope={dirty:_,ctx:c}),HF.$set(_N);const nje={};_&2&&(nje.$$scope={dirty:_,ctx:c}),YF.$set(nje);const sje={};_&2&&(sje.$$scope={dirty:_,ctx:c}),oT.$set(sje);const lje={};_&2&&(lje.$$scope={dirty:_,ctx:c}),tT.$set(lje);const Yf={};_&2&&(Yf.$$scope={dirty:_,ctx:c}),zT.$set(Yf);const ije={};_&2&&(ije.$$scope={dirty:_,ctx:c}),WT.$set(ije);const dje={};_&2&&(dje.$$scope={dirty:_,ctx:c}),uM.$set(dje);const mje={};_&2&&(mje.$$scope={dirty:_,ctx:c}),_M.$set(mje);const bN={};_&2&&(bN.$$scope={dirty:_,ctx:c}),ME.$set(bN);const cje={};_&2&&(cje.$$scope={dirty:_,ctx:c}),CE.$set(cje);const fje={};_&2&&(fje.$$scope={dirty:_,ctx:c}),n4.$set(fje);const gje={};_&2&&(gje.$$scope={dirty:_,ctx:c}),l4.$set(gje);const Et={};_&2&&(Et.$$scope={dirty:_,ctx:c}),p4.$set(Et);const vN={};_&2&&(vN.$$scope={dirty:_,ctx:c}),b4.$set(vN);const hje={};_&2&&(hje.$$scope={dirty:_,ctx:c}),iC.$set(hje);const FN={};_&2&&(FN.$$scope={dirty:_,ctx:c}),mC.$set(FN);const uje={};_&2&&(uje.$$scope={dirty:_,ctx:c}),l3.$set(uje);const Ct={};_&2&&(Ct.$$scope={dirty:_,ctx:c}),d3.$set(Ct);const pje={};_&2&&(pje.$$scope={dirty:_,ctx:c}),f3.$set(pje);const Zf={};_&2&&(Zf.$$scope={dirty:_,ctx:c}),h3.$set(Zf);const _je={};_&2&&(_je.$$scope={dirty:_,ctx:c}),v3.$set(_je);const bje={};_&2&&(bje.$$scope={dirty:_,ctx:c}),T3.$set(bje);const L={};_&2&&(L.$$scope={dirty:_,ctx:c}),j3.$set(L);const B9={};_&2&&(B9.$$scope={dirty:_,ctx:c}),G3.$set(B9);const vje={};_&2&&(vje.$$scope={dirty:_,ctx:c}),X3.$set(vje);const Fje={};_&2&&(Fje.$$scope={dirty:_,ctx:c}),Q3.$set(Fje);const I9={};_&2&&(I9.$$scope={dirty:_,ctx:c}),H3.$set(I9);const Tje={};_&2&&(Tje.$$scope={dirty:_,ctx:c}),Y3.$set(Tje);const Mje={};_&2&&(Mje.$$scope={dirty:_,ctx:c}),e5.$set(Mje);const N9={};_&2&&(N9.$$scope={dirty:_,ctx:c}),r5.$set(N9);const Eje={};_&2&&(Eje.$$scope={dirty:_,ctx:c}),g5.$set(Eje);const Cje={};_&2&&(Cje.$$scope={dirty:_,ctx:c}),u5.$set(Cje);const q9={};_&2&&(q9.$$scope={dirty:_,ctx:c}),M5.$set(q9);const wje={};_&2&&(wje.$$scope={dirty:_,ctx:c}),C5.$set(wje);const Aje={};_&2&&(Aje.$$scope={dirty:_,ctx:c}),I5.$set(Aje);const j9={};_&2&&(j9.$$scope={dirty:_,ctx:c}),q5.$set(j9);const Lje={};_&2&&(Lje.$$scope={dirty:_,ctx:c}),V5.$set(Lje);const yje={};_&2&&(yje.$$scope={dirty:_,ctx:c}),z5.$set(yje);const D9={};_&2&&(D9.$$scope={dirty:_,ctx:c}),Z5.$set(D9);const xje={};_&2&&(xje.$$scope={dirty:_,ctx:c}),e0.$set(xje);const $je={};_&2&&($je.$$scope={dirty:_,ctx:c}),s0.$set($je);const G9={};_&2&&(G9.$$scope={dirty:_,ctx:c}),i0.$set(G9);const kje={};_&2&&(kje.$$scope={dirty:_,ctx:c}),u0.$set(kje);const Sje={};_&2&&(Sje.$$scope={dirty:_,ctx:c}),_0.$set(Sje);const O9={};_&2&&(O9.$$scope={dirty:_,ctx:c}),F0.$set(O9);const Rje={};_&2&&(Rje.$$scope={dirty:_,ctx:c}),M0.$set(Rje);const Pje={};_&2&&(Pje.$$scope={dirty:_,ctx:c}),$0.$set(Pje);const V9={};_&2&&(V9.$$scope={dirty:_,ctx:c}),S0.$set(V9);const Bje={};_&2&&(Bje.$$scope={dirty:_,ctx:c}),B0.$set(Bje);const Ije={};_&2&&(Ije.$$scope={dirty:_,ctx:c}),N0.$set(Ije);const X9={};_&2&&(X9.$$scope={dirty:_,ctx:c}),D0.$set(X9);const Nje={};_&2&&(Nje.$$scope={dirty:_,ctx:c}),O0.$set(Nje);const qje={};_&2&&(qje.$$scope={dirty:_,ctx:c}),Qw.$set(qje);const z9={};_&2&&(z9.$$scope={dirty:_,ctx:c}),Uw.$set(z9);const jje={};_&2&&(jje.$$scope={dirty:_,ctx:c}),bA.$set(jje);const Dje={};_&2&&(Dje.$$scope={dirty:_,ctx:c}),FA.$set(Dje);const Q9={};_&2&&(Q9.$$scope={dirty:_,ctx:c}),BA.$set(Q9);const Gje={};_&2&&(Gje.$$scope={dirty:_,ctx:c}),NA.$set(Gje);const Oje={};_&2&&(Oje.$$scope={dirty:_,ctx:c}),WA.$set(Oje);const W9={};_&2&&(W9.$$scope={dirty:_,ctx:c}),HA.$set(W9);const Vje={};_&2&&(Vje.$$scope={dirty:_,ctx:c}),KA.$set(Vje);const Xje={};_&2&&(Xje.$$scope={dirty:_,ctx:c}),o6.$set(Xje);const U9={};_&2&&(U9.$$scope={dirty:_,ctx:c}),E6.$set(U9);const zje={};_&2&&(zje.$$scope={dirty:_,ctx:c}),w6.$set(zje);const Qje={};_&2&&(Qje.$$scope={dirty:_,ctx:c}),I6.$set(Qje);const H9={};_&2&&(H9.$$scope={dirty:_,ctx:c}),q6.$set(H9);const Wje={};_&2&&(Wje.$$scope={dirty:_,ctx:c}),g7.$set(Wje);const Uje={};_&2&&(Uje.$$scope={dirty:_,ctx:c}),u7.$set(Uje);const J9={};_&2&&(J9.$$scope={dirty:_,ctx:c}),R7.$set(J9);const Hje={};_&2&&(Hje.$$scope={dirty:_,ctx:c}),B7.$set(Hje);const Jje={};_&2&&(Jje.$$scope={dirty:_,ctx:c}),q7.$set(Jje);const Y9={};_&2&&(Y9.$$scope={dirty:_,ctx:c}),D7.$set(Y9);const Yje={};_&2&&(Yje.$$scope={dirty:_,ctx:c}),O7.$set(Yje);const Zje={};_&2&&(Zje.$$scope={dirty:_,ctx:c}),X7.$set(Zje);const Z9={};_&2&&(Z9.$$scope={dirty:_,ctx:c}),Q7.$set(Z9);const Kje={};_&2&&(Kje.$$scope={dirty:_,ctx:c}),U7.$set(Kje);const eDe={};_&2&&(eDe.$$scope={dirty:_,ctx:c}),_8.$set(eDe);const K9={};_&2&&(K9.$$scope={dirty:_,ctx:c}),v8.$set(K9);const oDe={};_&2&&(oDe.$$scope={dirty:_,ctx:c}),G8.$set(oDe);const rDe={};_&2&&(rDe.$$scope={dirty:_,ctx:c}),V8.$set(rDe);const ex={};_&2&&(ex.$$scope={dirty:_,ctx:c}),z8.$set(ex);const tDe={};_&2&&(tDe.$$scope={dirty:_,ctx:c}),W8.$set(tDe);const aDe={};_&2&&(aDe.$$scope={dirty:_,ctx:c}),J8.$set(aDe);const ox={};_&2&&(ox.$$scope={dirty:_,ctx:c}),Z8.$set(ox);const nDe={};_&2&&(nDe.$$scope={dirty:_,ctx:c}),AL.$set(nDe);const sDe={};_&2&&(sDe.$$scope={dirty:_,ctx:c}),yL.$set(sDe);const rx={};_&2&&(rx.$$scope={dirty:_,ctx:c}),jL.$set(rx);const lDe={};_&2&&(lDe.$$scope={dirty:_,ctx:c}),GL.$set(lDe);const iDe={};_&2&&(iDe.$$scope={dirty:_,ctx:c}),oy.$set(iDe);const tx={};_&2&&(tx.$$scope={dirty:_,ctx:c}),ty.$set(tx);const dDe={};_&2&&(dDe.$$scope={dirty:_,ctx:c}),hy.$set(dDe);const mDe={};_&2&&(mDe.$$scope={dirty:_,ctx:c}),py.$set(mDe);const ax={};_&2&&(ax.$$scope={dirty:_,ctx:c}),Ly.$set(ax);const cDe={};_&2&&(cDe.$$scope={dirty:_,ctx:c}),xy.$set(cDe);const fDe={};_&2&&(fDe.$$scope={dirty:_,ctx:c}),Dy.$set(fDe);const nx={};_&2&&(nx.$$scope={dirty:_,ctx:c}),Oy.$set(nx);const gDe={};_&2&&(gDe.$$scope={dirty:_,ctx:c}),Ky.$set(gDe);const hDe={};_&2&&(hDe.$$scope={dirty:_,ctx:c}),o9.$set(hDe);const sx={};_&2&&(sx.$$scope={dirty:_,ctx:c}),m9.$set(sx);const uDe={};_&2&&(uDe.$$scope={dirty:_,ctx:c}),f9.$set(uDe);const pDe={};_&2&&(pDe.$$scope={dirty:_,ctx:c}),T9.$set(pDe);const lx={};_&2&&(lx.$$scope={dirty:_,ctx:c}),E9.$set(lx);const _De={};_&2&&(_De.$$scope={dirty:_,ctx:c}),w9.$set(_De);const bDe={};_&2&&(bDe.$$scope={dirty:_,ctx:c}),L9.$set(bDe);const ix={};_&2&&(ix.$$scope={dirty:_,ctx:c}),$9.$set(ix);const vDe={};_&2&&(vDe.$$scope={dirty:_,ctx:c}),S9.$set(vDe);const FDe={};_&2&&(FDe.$$scope={dirty:_,ctx:c}),P9.$set(FDe)},i(c){_mo||(E(m.$$.fragment,c),E(ln.$$.fragment,c),E(Tk.$$.fragment,c),E(Mk.$$.fragment,c),E(ng.$$.fragment,c),E(Ek.$$.fragment,c),E(Ck.$$.fragment,c),E(Lk.$$.fragment,c),E(qu.$$.fragment,c),E(yk.$$.fragment,c),E(xk.$$.fragment,c),E($k.$$.fragment,c),E(Rk.$$.fragment,c),E(wp.$$.fragment,c),E(Pk.$$.fragment,c),E(Bk.$$.fragment,c),E(Ik.$$.fragment,c),E(jk.$$.fragment,c),E(F_.$$.fragment,c),E(T_.$$.fragment,c),E(Dk.$$.fragment,c),E(Gk.$$.fragment,c),E(Ok.$$.fragment,c),E(zk.$$.fragment,c),E(e1.$$.fragment,c),E(o1.$$.fragment,c),E(Qk.$$.fragment,c),E(Wk.$$.fragment,c),E(Uk.$$.fragment,c),E(Yk.$$.fragment,c),E(L1.$$.fragment,c),E(y1.$$.fragment,c),E(Zk.$$.fragment,c),E(Kk.$$.fragment,c),E(eS.$$.fragment,c),E(rS.$$.fragment,c),E(k1.$$.fragment,c),E(tS.$$.fragment,c),E(tv.$$.fragment,c),E(aS.$$.fragment,c),E(nS.$$.fragment,c),E(lS.$$.fragment,c),E(nv.$$.fragment,c),E(iS.$$.fragment,c),E(rF.$$.fragment,c),E(dS.$$.fragment,c),E(mS.$$.fragment,c),E(fS.$$.fragment,c),E(aF.$$.fragment,c),E(gS.$$.fragment,c),E(HF.$$.fragment,c),E(hS.$$.fragment,c),E(uS.$$.fragment,c),E(_S.$$.fragment,c),E(YF.$$.fragment,c),E(bS.$$.fragment,c),E(oT.$$.fragment,c),E(FS.$$.fragment,c),E(TS.$$.fragment,c),E(ES.$$.fragment,c),E(tT.$$.fragment,c),E(CS.$$.fragment,c),E(zT.$$.fragment,c),E(wS.$$.fragment,c),E(AS.$$.fragment,c),E(yS.$$.fragment,c),E(WT.$$.fragment,c),E(xS.$$.fragment,c),E(uM.$$.fragment,c),E($S.$$.fragment,c),E(kS.$$.fragment,c),E(RS.$$.fragment,c),E(_M.$$.fragment,c),E(PS.$$.fragment,c),E(ME.$$.fragment,c),E(BS.$$.fragment,c),E(IS.$$.fragment,c),E(qS.$$.fragment,c),E(CE.$$.fragment,c),E(jS.$$.fragment,c),E(n4.$$.fragment,c),E(DS.$$.fragment,c),E(GS.$$.fragment,c),E(VS.$$.fragment,c),E(l4.$$.fragment,c),E(XS.$$.fragment,c),E(p4.$$.fragment,c),E(zS.$$.fragment,c),E(QS.$$.fragment,c),E(US.$$.fragment,c),E(b4.$$.fragment,c),E(HS.$$.fragment,c),E(iC.$$.fragment,c),E(JS.$$.fragment,c),E(YS.$$.fragment,c),E(KS.$$.fragment,c),E(mC.$$.fragment,c),E(eR.$$.fragment,c),E(l3.$$.fragment,c),E(oR.$$.fragment,c),E(rR.$$.fragment,c),E(aR.$$.fragment,c),E(d3.$$.fragment,c),E(nR.$$.fragment,c),E(f3.$$.fragment,c),E(sR.$$.fragment,c),E(lR.$$.fragment,c),E(dR.$$.fragment,c),E(h3.$$.fragment,c),E(mR.$$.fragment,c),E(v3.$$.fragment,c),E(cR.$$.fragment,c),E(fR.$$.fragment,c),E(hR.$$.fragment,c),E(T3.$$.fragment,c),E(uR.$$.fragment,c),E(j3.$$.fragment,c),E(pR.$$.fragment,c),E(_R.$$.fragment,c),E(vR.$$.fragment,c),E(G3.$$.fragment,c),E(FR.$$.fragment,c),E(X3.$$.fragment,c),E(TR.$$.fragment,c),E(MR.$$.fragment,c),E(CR.$$.fragment,c),E(Q3.$$.fragment,c),E(wR.$$.fragment,c),E(H3.$$.fragment,c),E(AR.$$.fragment,c),E(LR.$$.fragment,c),E(xR.$$.fragment,c),E(Y3.$$.fragment,c),E($R.$$.fragment,c),E(e5.$$.fragment,c),E(kR.$$.fragment,c),E(SR.$$.fragment,c),E(PR.$$.fragment,c),E(r5.$$.fragment,c),E(BR.$$.fragment,c),E(g5.$$.fragment,c),E(IR.$$.fragment,c),E(NR.$$.fragment,c),E(jR.$$.fragment,c),E(u5.$$.fragment,c),E(DR.$$.fragment,c),E(M5.$$.fragment,c),E(GR.$$.fragment,c),E(OR.$$.fragment,c),E(XR.$$.fragment,c),E(C5.$$.fragment,c),E(zR.$$.fragment,c),E(I5.$$.fragment,c),E(QR.$$.fragment,c),E(WR.$$.fragment,c),E(HR.$$.fragment,c),E(q5.$$.fragment,c),E(JR.$$.fragment,c),E(V5.$$.fragment,c),E(YR.$$.fragment,c),E(ZR.$$.fragment,c),E(eP.$$.fragment,c),E(z5.$$.fragment,c),E(oP.$$.fragment,c),E(Z5.$$.fragment,c),E(rP.$$.fragment,c),E(tP.$$.fragment,c),E(nP.$$.fragment,c),E(e0.$$.fragment,c),E(sP.$$.fragment,c),E(s0.$$.fragment,c),E(lP.$$.fragment,c),E(iP.$$.fragment,c),E(mP.$$.fragment,c),E(i0.$$.fragment,c),E(cP.$$.fragment,c),E(u0.$$.fragment,c),E(fP.$$.fragment,c),E(gP.$$.fragment,c),E(uP.$$.fragment,c),E(_0.$$.fragment,c),E(pP.$$.fragment,c),E(F0.$$.fragment,c),E(_P.$$.fragment,c),E(bP.$$.fragment,c),E(FP.$$.fragment,c),E(M0.$$.fragment,c),E(TP.$$.fragment,c),E($0.$$.fragment,c),E(MP.$$.fragment,c),E(EP.$$.fragment,c),E(wP.$$.fragment,c),E(S0.$$.fragment,c),E(AP.$$.fragment,c),E(B0.$$.fragment,c),E(LP.$$.fragment,c),E(yP.$$.fragment,c),E($P.$$.fragment,c),E(N0.$$.fragment,c),E(kP.$$.fragment,c),E(D0.$$.fragment,c),E(SP.$$.fragment,c),E(RP.$$.fragment,c),E(BP.$$.fragment,c),E(O0.$$.fragment,c),E(IP.$$.fragment,c),E(Qw.$$.fragment,c),E(NP.$$.fragment,c),E(qP.$$.fragment,c),E(DP.$$.fragment,c),E(Uw.$$.fragment,c),E(GP.$$.fragment,c),E(bA.$$.fragment,c),E(OP.$$.fragment,c),E(VP.$$.fragment,c),E(zP.$$.fragment,c),E(FA.$$.fragment,c),E(QP.$$.fragment,c),E(BA.$$.fragment,c),E(WP.$$.fragment,c),E(UP.$$.fragment,c),E(JP.$$.fragment,c),E(NA.$$.fragment,c),E(YP.$$.fragment,c),E(WA.$$.fragment,c),E(ZP.$$.fragment,c),E(KP.$$.fragment,c),E(oB.$$.fragment,c),E(HA.$$.fragment,c),E(rB.$$.fragment,c),E(KA.$$.fragment,c),E(tB.$$.fragment,c),E(aB.$$.fragment,c),E(sB.$$.fragment,c),E(o6.$$.fragment,c),E(lB.$$.fragment,c),E(E6.$$.fragment,c),E(iB.$$.fragment,c),E(dB.$$.fragment,c),E(cB.$$.fragment,c),E(w6.$$.fragment,c),E(fB.$$.fragment,c),E(I6.$$.fragment,c),E(gB.$$.fragment,c),E(hB.$$.fragment,c),E(pB.$$.fragment,c),E(q6.$$.fragment,c),E(_B.$$.fragment,c),E(g7.$$.fragment,c),E(bB.$$.fragment,c),E(vB.$$.fragment,c),E(TB.$$.fragment,c),E(u7.$$.fragment,c),E(MB.$$.fragment,c),E(R7.$$.fragment,c),E(EB.$$.fragment,c),E(CB.$$.fragment,c),E(AB.$$.fragment,c),E(B7.$$.fragment,c),E(LB.$$.fragment,c),E(q7.$$.fragment,c),E(xB.$$.fragment,c),E($B.$$.fragment,c),E(SB.$$.fragment,c),E(D7.$$.fragment,c),E(RB.$$.fragment,c),E(O7.$$.fragment,c),E(PB.$$.fragment,c),E(BB.$$.fragment,c),E(NB.$$.fragment,c),E(X7.$$.fragment,c),E(qB.$$.fragment,c),E(Q7.$$.fragment,c),E(jB.$$.fragment,c),E(DB.$$.fragment,c),E(OB.$$.fragment,c),E(U7.$$.fragment,c),E(VB.$$.fragment,c),E(_8.$$.fragment,c),E(XB.$$.fragment,c),E(zB.$$.fragment,c),E(WB.$$.fragment,c),E(v8.$$.fragment,c),E(UB.$$.fragment,c),E(G8.$$.fragment,c),E(HB.$$.fragment,c),E(JB.$$.fragment,c),E(ZB.$$.fragment,c),E(V8.$$.fragment,c),E(KB.$$.fragment,c),E(z8.$$.fragment,c),E(eI.$$.fragment,c),E(oI.$$.fragment,c),E(tI.$$.fragment,c),E(W8.$$.fragment,c),E(aI.$$.fragment,c),E(J8.$$.fragment,c),E(sI.$$.fragment,c),E(lI.$$.fragment,c),E(dI.$$.fragment,c),E(Z8.$$.fragment,c),E(mI.$$.fragment,c),E(AL.$$.fragment,c),E(cI.$$.fragment,c),E(fI.$$.fragment,c),E(hI.$$.fragment,c),E(yL.$$.fragment,c),E(uI.$$.fragment,c),E(jL.$$.fragment,c),E(pI.$$.fragment,c),E(_I.$$.fragment,c),E(vI.$$.fragment,c),E(GL.$$.fragment,c),E(FI.$$.fragment,c),E(oy.$$.fragment,c),E(TI.$$.fragment,c),E(MI.$$.fragment,c),E(CI.$$.fragment,c),E(ty.$$.fragment,c),E(wI.$$.fragment,c),E(hy.$$.fragment,c),E(AI.$$.fragment,c),E(LI.$$.fragment,c),E(xI.$$.fragment,c),E(py.$$.fragment,c),E($I.$$.fragment,c),E(Ly.$$.fragment,c),E(kI.$$.fragment,c),E(SI.$$.fragment,c),E(PI.$$.fragment,c),E(xy.$$.fragment,c),E(BI.$$.fragment,c),E(Dy.$$.fragment,c),E(II.$$.fragment,c),E(NI.$$.fragment,c),E(jI.$$.fragment,c),E(Oy.$$.fragment,c),E(DI.$$.fragment,c),E(Ky.$$.fragment,c),E(GI.$$.fragment,c),E(OI.$$.fragment,c),E(XI.$$.fragment,c),E(o9.$$.fragment,c),E(zI.$$.fragment,c),E(m9.$$.fragment,c),E(QI.$$.fragment,c),E(WI.$$.fragment,c),E(HI.$$.fragment,c),E(f9.$$.fragment,c),E(JI.$$.fragment,c),E(T9.$$.fragment,c),E(YI.$$.fragment,c),E(ZI.$$.fragment,c),E(eN.$$.fragment,c),E(E9.$$.fragment,c),E(oN.$$.fragment,c),E(w9.$$.fragment,c),E(rN.$$.fragment,c),E(tN.$$.fragment,c),E(nN.$$.fragment,c),E(L9.$$.fragment,c),E(sN.$$.fragment,c),E($9.$$.fragment,c),E(iN.$$.fragment,c),E(dN.$$.fragment,c),E(cN.$$.fragment,c),E(S9.$$.fragment,c),E(fN.$$.fragment,c),E(P9.$$.fragment,c),_mo=!0)},o(c){C(m.$$.fragment,c),C(ln.$$.fragment,c),C(Tk.$$.fragment,c),C(Mk.$$.fragment,c),C(ng.$$.fragment,c),C(Ek.$$.fragment,c),C(Ck.$$.fragment,c),C(Lk.$$.fragment,c),C(qu.$$.fragment,c),C(yk.$$.fragment,c),C(xk.$$.fragment,c),C($k.$$.fragment,c),C(Rk.$$.fragment,c),C(wp.$$.fragment,c),C(Pk.$$.fragment,c),C(Bk.$$.fragment,c),C(Ik.$$.fragment,c),C(jk.$$.fragment,c),C(F_.$$.fragment,c),C(T_.$$.fragment,c),C(Dk.$$.fragment,c),C(Gk.$$.fragment,c),C(Ok.$$.fragment,c),C(zk.$$.fragment,c),C(e1.$$.fragment,c),C(o1.$$.fragment,c),C(Qk.$$.fragment,c),C(Wk.$$.fragment,c),C(Uk.$$.fragment,c),C(Yk.$$.fragment,c),C(L1.$$.fragment,c),C(y1.$$.fragment,c),C(Zk.$$.fragment,c),C(Kk.$$.fragment,c),C(eS.$$.fragment,c),C(rS.$$.fragment,c),C(k1.$$.fragment,c),C(tS.$$.fragment,c),C(tv.$$.fragment,c),C(aS.$$.fragment,c),C(nS.$$.fragment,c),C(lS.$$.fragment,c),C(nv.$$.fragment,c),C(iS.$$.fragment,c),C(rF.$$.fragment,c),C(dS.$$.fragment,c),C(mS.$$.fragment,c),C(fS.$$.fragment,c),C(aF.$$.fragment,c),C(gS.$$.fragment,c),C(HF.$$.fragment,c),C(hS.$$.fragment,c),C(uS.$$.fragment,c),C(_S.$$.fragment,c),C(YF.$$.fragment,c),C(bS.$$.fragment,c),C(oT.$$.fragment,c),C(FS.$$.fragment,c),C(TS.$$.fragment,c),C(ES.$$.fragment,c),C(tT.$$.fragment,c),C(CS.$$.fragment,c),C(zT.$$.fragment,c),C(wS.$$.fragment,c),C(AS.$$.fragment,c),C(yS.$$.fragment,c),C(WT.$$.fragment,c),C(xS.$$.fragment,c),C(uM.$$.fragment,c),C($S.$$.fragment,c),C(kS.$$.fragment,c),C(RS.$$.fragment,c),C(_M.$$.fragment,c),C(PS.$$.fragment,c),C(ME.$$.fragment,c),C(BS.$$.fragment,c),C(IS.$$.fragment,c),C(qS.$$.fragment,c),C(CE.$$.fragment,c),C(jS.$$.fragment,c),C(n4.$$.fragment,c),C(DS.$$.fragment,c),C(GS.$$.fragment,c),C(VS.$$.fragment,c),C(l4.$$.fragment,c),C(XS.$$.fragment,c),C(p4.$$.fragment,c),C(zS.$$.fragment,c),C(QS.$$.fragment,c),C(US.$$.fragment,c),C(b4.$$.fragment,c),C(HS.$$.fragment,c),C(iC.$$.fragment,c),C(JS.$$.fragment,c),C(YS.$$.fragment,c),C(KS.$$.fragment,c),C(mC.$$.fragment,c),C(eR.$$.fragment,c),C(l3.$$.fragment,c),C(oR.$$.fragment,c),C(rR.$$.fragment,c),C(aR.$$.fragment,c),C(d3.$$.fragment,c),C(nR.$$.fragment,c),C(f3.$$.fragment,c),C(sR.$$.fragment,c),C(lR.$$.fragment,c),C(dR.$$.fragment,c),C(h3.$$.fragment,c),C(mR.$$.fragment,c),C(v3.$$.fragment,c),C(cR.$$.fragment,c),C(fR.$$.fragment,c),C(hR.$$.fragment,c),C(T3.$$.fragment,c),C(uR.$$.fragment,c),C(j3.$$.fragment,c),C(pR.$$.fragment,c),C(_R.$$.fragment,c),C(vR.$$.fragment,c),C(G3.$$.fragment,c),C(FR.$$.fragment,c),C(X3.$$.fragment,c),C(TR.$$.fragment,c),C(MR.$$.fragment,c),C(CR.$$.fragment,c),C(Q3.$$.fragment,c),C(wR.$$.fragment,c),C(H3.$$.fragment,c),C(AR.$$.fragment,c),C(LR.$$.fragment,c),C(xR.$$.fragment,c),C(Y3.$$.fragment,c),C($R.$$.fragment,c),C(e5.$$.fragment,c),C(kR.$$.fragment,c),C(SR.$$.fragment,c),C(PR.$$.fragment,c),C(r5.$$.fragment,c),C(BR.$$.fragment,c),C(g5.$$.fragment,c),C(IR.$$.fragment,c),C(NR.$$.fragment,c),C(jR.$$.fragment,c),C(u5.$$.fragment,c),C(DR.$$.fragment,c),C(M5.$$.fragment,c),C(GR.$$.fragment,c),C(OR.$$.fragment,c),C(XR.$$.fragment,c),C(C5.$$.fragment,c),C(zR.$$.fragment,c),C(I5.$$.fragment,c),C(QR.$$.fragment,c),C(WR.$$.fragment,c),C(HR.$$.fragment,c),C(q5.$$.fragment,c),C(JR.$$.fragment,c),C(V5.$$.fragment,c),C(YR.$$.fragment,c),C(ZR.$$.fragment,c),C(eP.$$.fragment,c),C(z5.$$.fragment,c),C(oP.$$.fragment,c),C(Z5.$$.fragment,c),C(rP.$$.fragment,c),C(tP.$$.fragment,c),C(nP.$$.fragment,c),C(e0.$$.fragment,c),C(sP.$$.fragment,c),C(s0.$$.fragment,c),C(lP.$$.fragment,c),C(iP.$$.fragment,c),C(mP.$$.fragment,c),C(i0.$$.fragment,c),C(cP.$$.fragment,c),C(u0.$$.fragment,c),C(fP.$$.fragment,c),C(gP.$$.fragment,c),C(uP.$$.fragment,c),C(_0.$$.fragment,c),C(pP.$$.fragment,c),C(F0.$$.fragment,c),C(_P.$$.fragment,c),C(bP.$$.fragment,c),C(FP.$$.fragment,c),C(M0.$$.fragment,c),C(TP.$$.fragment,c),C($0.$$.fragment,c),C(MP.$$.fragment,c),C(EP.$$.fragment,c),C(wP.$$.fragment,c),C(S0.$$.fragment,c),C(AP.$$.fragment,c),C(B0.$$.fragment,c),C(LP.$$.fragment,c),C(yP.$$.fragment,c),C($P.$$.fragment,c),C(N0.$$.fragment,c),C(kP.$$.fragment,c),C(D0.$$.fragment,c),C(SP.$$.fragment,c),C(RP.$$.fragment,c),C(BP.$$.fragment,c),C(O0.$$.fragment,c),C(IP.$$.fragment,c),C(Qw.$$.fragment,c),C(NP.$$.fragment,c),C(qP.$$.fragment,c),C(DP.$$.fragment,c),C(Uw.$$.fragment,c),C(GP.$$.fragment,c),C(bA.$$.fragment,c),C(OP.$$.fragment,c),C(VP.$$.fragment,c),C(zP.$$.fragment,c),C(FA.$$.fragment,c),C(QP.$$.fragment,c),C(BA.$$.fragment,c),C(WP.$$.fragment,c),C(UP.$$.fragment,c),C(JP.$$.fragment,c),C(NA.$$.fragment,c),C(YP.$$.fragment,c),C(WA.$$.fragment,c),C(ZP.$$.fragment,c),C(KP.$$.fragment,c),C(oB.$$.fragment,c),C(HA.$$.fragment,c),C(rB.$$.fragment,c),C(KA.$$.fragment,c),C(tB.$$.fragment,c),C(aB.$$.fragment,c),C(sB.$$.fragment,c),C(o6.$$.fragment,c),C(lB.$$.fragment,c),C(E6.$$.fragment,c),C(iB.$$.fragment,c),C(dB.$$.fragment,c),C(cB.$$.fragment,c),C(w6.$$.fragment,c),C(fB.$$.fragment,c),C(I6.$$.fragment,c),C(gB.$$.fragment,c),C(hB.$$.fragment,c),C(pB.$$.fragment,c),C(q6.$$.fragment,c),C(_B.$$.fragment,c),C(g7.$$.fragment,c),C(bB.$$.fragment,c),C(vB.$$.fragment,c),C(TB.$$.fragment,c),C(u7.$$.fragment,c),C(MB.$$.fragment,c),C(R7.$$.fragment,c),C(EB.$$.fragment,c),C(CB.$$.fragment,c),C(AB.$$.fragment,c),C(B7.$$.fragment,c),C(LB.$$.fragment,c),C(q7.$$.fragment,c),C(xB.$$.fragment,c),C($B.$$.fragment,c),C(SB.$$.fragment,c),C(D7.$$.fragment,c),C(RB.$$.fragment,c),C(O7.$$.fragment,c),C(PB.$$.fragment,c),C(BB.$$.fragment,c),C(NB.$$.fragment,c),C(X7.$$.fragment,c),C(qB.$$.fragment,c),C(Q7.$$.fragment,c),C(jB.$$.fragment,c),C(DB.$$.fragment,c),C(OB.$$.fragment,c),C(U7.$$.fragment,c),C(VB.$$.fragment,c),C(_8.$$.fragment,c),C(XB.$$.fragment,c),C(zB.$$.fragment,c),C(WB.$$.fragment,c),C(v8.$$.fragment,c),C(UB.$$.fragment,c),C(G8.$$.fragment,c),C(HB.$$.fragment,c),C(JB.$$.fragment,c),C(ZB.$$.fragment,c),C(V8.$$.fragment,c),C(KB.$$.fragment,c),C(z8.$$.fragment,c),C(eI.$$.fragment,c),C(oI.$$.fragment,c),C(tI.$$.fragment,c),C(W8.$$.fragment,c),C(aI.$$.fragment,c),C(J8.$$.fragment,c),C(sI.$$.fragment,c),C(lI.$$.fragment,c),C(dI.$$.fragment,c),C(Z8.$$.fragment,c),C(mI.$$.fragment,c),C(AL.$$.fragment,c),C(cI.$$.fragment,c),C(fI.$$.fragment,c),C(hI.$$.fragment,c),C(yL.$$.fragment,c),C(uI.$$.fragment,c),C(jL.$$.fragment,c),C(pI.$$.fragment,c),C(_I.$$.fragment,c),C(vI.$$.fragment,c),C(GL.$$.fragment,c),C(FI.$$.fragment,c),C(oy.$$.fragment,c),C(TI.$$.fragment,c),C(MI.$$.fragment,c),C(CI.$$.fragment,c),C(ty.$$.fragment,c),C(wI.$$.fragment,c),C(hy.$$.fragment,c),C(AI.$$.fragment,c),C(LI.$$.fragment,c),C(xI.$$.fragment,c),C(py.$$.fragment,c),C($I.$$.fragment,c),C(Ly.$$.fragment,c),C(kI.$$.fragment,c),C(SI.$$.fragment,c),C(PI.$$.fragment,c),C(xy.$$.fragment,c),C(BI.$$.fragment,c),C(Dy.$$.fragment,c),C(II.$$.fragment,c),C(NI.$$.fragment,c),C(jI.$$.fragment,c),C(Oy.$$.fragment,c),C(DI.$$.fragment,c),C(Ky.$$.fragment,c),C(GI.$$.fragment,c),C(OI.$$.fragment,c),C(XI.$$.fragment,c),C(o9.$$.fragment,c),C(zI.$$.fragment,c),C(m9.$$.fragment,c),C(QI.$$.fragment,c),C(WI.$$.fragment,c),C(HI.$$.fragment,c),C(f9.$$.fragment,c),C(JI.$$.fragment,c),C(T9.$$.fragment,c),C(YI.$$.fragment,c),C(ZI.$$.fragment,c),C(eN.$$.fragment,c),C(E9.$$.fragment,c),C(oN.$$.fragment,c),C(w9.$$.fragment,c),C(rN.$$.fragment,c),C(tN.$$.fragment,c),C(nN.$$.fragment,c),C(L9.$$.fragment,c),C(sN.$$.fragment,c),C($9.$$.fragment,c),C(iN.$$.fragment,c),C(dN.$$.fragment,c),C(cN.$$.fragment,c),C(S9.$$.fragment,c),C(fN.$$.fragment,c),C(P9.$$.fragment,c),_mo=!1},d(c){t(g),c&&t(v),c&&t(u),w(m),c&&t(eg),c&&t(wt),c&&t(Qe),c&&t(Ze),c&&t(rg),w(ln,c),c&&t(Ke),c&&t(ye),c&&t(Po),c&&t(dn),c&&t(Zlo),c&&t(Rd),w(Tk),c&&t(Klo),c&&t(Ts),c&&t(eio),w(Mk,c),c&&t(oio),c&&t(Qq),c&&t(rio),w(ng,c),c&&t(tio),c&&t(Pd),w(Ek),c&&t(aio),c&&t(Bo),w(Ck),w(Lk),w(qu),w(yk),c&&t(nio),c&&t(Id),w(xk),c&&t(sio),c&&t(Io),w($k),w(Rk),w(wp),w(Pk),c&&t(lio),c&&t(Nd),w(Bk),c&&t(iio),c&&t(No),w(Ik),w(jk),w(F_),w(T_),w(Dk),c&&t(dio),c&&t(qd),w(Gk),c&&t(mio),c&&t(qo),w(Ok),w(zk),w(e1),w(o1),w(Qk),c&&t(cio),c&&t(jd),w(Wk),c&&t(fio),c&&t(jo),w(Uk),w(Yk),w(L1),w(y1),w(Zk),c&&t(gio),c&&t(Gd),w(Kk),c&&t(hio),c&&t(Do),w(eS),w(rS),w(k1),w(tS),w(tv),c&&t(uio),c&&t(Xd),w(aS),c&&t(pio),c&&t(Go),w(nS),w(lS),w(nv),w(iS),w(rF),c&&t(_io),c&&t(Wd),w(dS),c&&t(bio),c&&t(Oo),w(mS),w(fS),w(aF),w(gS),w(HF),c&&t(vio),c&&t(Jd),w(hS),c&&t(Fio),c&&t(Vo),w(uS),w(_S),w(YF),w(bS),w(oT),c&&t(Tio),c&&t(Kd),w(FS),c&&t(Mio),c&&t(Xo),w(TS),w(ES),w(tT),w(CS),w(zT),c&&t(Eio),c&&t(rm),w(wS),c&&t(Cio),c&&t(zo),w(AS),w(yS),w(WT),w(xS),w(uM),c&&t(wio),c&&t(nm),w($S),c&&t(Aio),c&&t(Qo),w(kS),w(RS),w(_M),w(PS),w(ME),c&&t(Lio),c&&t(im),w(BS),c&&t(yio),c&&t(Wo),w(IS),w(qS),w(CE),w(jS),w(n4),c&&t(xio),c&&t(cm),w(DS),c&&t($io),c&&t(Uo),w(GS),w(VS),w(l4),w(XS),w(p4),c&&t(kio),c&&t(hm),w(zS),c&&t(Sio),c&&t(Ho),w(QS),w(US),w(b4),w(HS),w(iC),c&&t(Rio),c&&t(_m),w(JS),c&&t(Pio),c&&t(Jo),w(YS),w(KS),w(mC),w(eR),w(l3),c&&t(Bio),c&&t(Fm),w(oR),c&&t(Iio),c&&t(Yo),w(rR),w(aR),w(d3),w(nR),w(f3),c&&t(Nio),c&&t(Em),w(sR),c&&t(qio),c&&t(Zo),w(lR),w(dR),w(h3),w(mR),w(v3),c&&t(jio),c&&t(Lm),w(cR),c&&t(Dio),c&&t(Ko),w(fR),w(hR),w(T3),w(uR),w(j3),c&&t(Gio),c&&t($m),w(pR),c&&t(Oio),c&&t(er),w(_R),w(vR),w(G3),w(FR),w(X3),c&&t(Vio),c&&t(Rm),w(TR),c&&t(Xio),c&&t(or),w(MR),w(CR),w(Q3),w(wR),w(H3),c&&t(zio),c&&t(Im),w(AR),c&&t(Qio),c&&t(rr),w(LR),w(xR),w(Y3),w($R),w(e5),c&&t(Wio),c&&t(jm),w(kR),c&&t(Uio),c&&t(tr),w(SR),w(PR),w(r5),w(BR),w(g5),c&&t(Hio),c&&t(Om),w(IR),c&&t(Jio),c&&t(ar),w(NR),w(jR),w(u5),w(DR),w(M5),c&&t(Yio),c&&t(zm),w(GR),c&&t(Zio),c&&t(nr),w(OR),w(XR),w(C5),w(zR),w(I5),c&&t(Kio),c&&t(Um),w(QR),c&&t(edo),c&&t(sr),w(WR),w(HR),w(q5),w(JR),w(V5),c&&t(odo),c&&t(Zm),w(YR),c&&t(rdo),c&&t(lr),w(ZR),w(eP),w(z5),w(oP),w(Z5),c&&t(tdo),c&&t(oc),w(rP),c&&t(ado),c&&t(ir),w(tP),w(nP),w(e0),w(sP),w(s0),c&&t(ndo),c&&t(ac),w(lP),c&&t(sdo),c&&t(dr),w(iP),w(mP),w(i0),w(cP),w(u0),c&&t(ldo),c&&t(lc),w(fP),c&&t(ido),c&&t(mr),w(gP),w(uP),w(_0),w(pP),w(F0),c&&t(ddo),c&&t(mc),w(_P),c&&t(mdo),c&&t(cr),w(bP),w(FP),w(M0),w(TP),w($0),c&&t(cdo),c&&t(gc),w(MP),c&&t(fdo),c&&t(gr),w(EP),w(wP),w(S0),w(AP),w(B0),c&&t(gdo),c&&t(pc),w(LP),c&&t(hdo),c&&t(hr),w(yP),w($P),w(N0),w(kP),w(D0),c&&t(udo),c&&t(vc),w(SP),c&&t(pdo),c&&t(ur),w(RP),w(BP),w(O0),w(IP),w(Qw),c&&t(_do),c&&t(Mc),w(NP),c&&t(bdo),c&&t(pr),w(qP),w(DP),w(Uw),w(GP),w(bA),c&&t(vdo),c&&t(wc),w(OP),c&&t(Fdo),c&&t(_r),w(VP),w(zP),w(FA),w(QP),w(BA),c&&t(Tdo),c&&t(yc),w(WP),c&&t(Mdo),c&&t(br),w(UP),w(JP),w(NA),w(YP),w(WA),c&&t(Edo),c&&t(kc),w(ZP),c&&t(Cdo),c&&t(vr),w(KP),w(oB),w(HA),w(rB),w(KA),c&&t(wdo),c&&t(Bc),w(tB),c&&t(Ado),c&&t(Fr),w(aB),w(sB),w(o6),w(lB),w(E6),c&&t(Ldo),c&&t(qc),w(iB),c&&t(ydo),c&&t(Tr),w(dB),w(cB),w(w6),w(fB),w(I6),c&&t(xdo),c&&t(Gc),w(gB),c&&t($do),c&&t(Mr),w(hB),w(pB),w(q6),w(_B),w(g7),c&&t(kdo),c&&t(Xc),w(bB),c&&t(Sdo),c&&t(Er),w(vB),w(TB),w(u7),w(MB),w(R7),c&&t(Rdo),c&&t(Wc),w(EB),c&&t(Pdo),c&&t(Cr),w(CB),w(AB),w(B7),w(LB),w(q7),c&&t(Bdo),c&&t(Jc),w(xB),c&&t(Ido),c&&t(wr),w($B),w(SB),w(D7),w(RB),w(O7),c&&t(Ndo),c&&t(Kc),w(PB),c&&t(qdo),c&&t(Ar),w(BB),w(NB),w(X7),w(qB),w(Q7),c&&t(jdo),c&&t(rf),w(jB),c&&t(Ddo),c&&t(Lr),w(DB),w(OB),w(U7),w(VB),w(_8),c&&t(Gdo),c&&t(nf),w(XB),c&&t(Odo),c&&t(yr),w(zB),w(WB),w(v8),w(UB),w(G8),c&&t(Vdo),c&&t(df),w(HB),c&&t(Xdo),c&&t(xr),w(JB),w(ZB),w(V8),w(KB),w(z8),c&&t(zdo),c&&t(ff),w(eI),c&&t(Qdo),c&&t($r),w(oI),w(tI),w(W8),w(aI),w(J8),c&&t(Wdo),c&&t(uf),w(sI),c&&t(Udo),c&&t(kr),w(lI),w(dI),w(Z8),w(mI),w(AL),c&&t(Hdo),c&&t(bf),w(cI),c&&t(Jdo),c&&t(Sr),w(fI),w(hI),w(yL),w(uI),w(jL),c&&t(Ydo),c&&t(Tf),w(pI),c&&t(Zdo),c&&t(Rr),w(_I),w(vI),w(GL),w(FI),w(oy),c&&t(Kdo),c&&t(Cf),w(TI),c&&t(emo),c&&t(Pr),w(MI),w(CI),w(ty),w(wI),w(hy),c&&t(omo),c&&t(Lf),w(AI),c&&t(rmo),c&&t(Br),w(LI),w(xI),w(py),w($I),w(Ly),c&&t(tmo),c&&t($f),w(kI),c&&t(amo),c&&t(Ir),w(SI),w(PI),w(xy),w(BI),w(Dy),c&&t(nmo),c&&t(Rf),w(II),c&&t(smo),c&&t(Nr),w(NI),w(jI),w(Oy),w(DI),w(Ky),c&&t(lmo),c&&t(If),w(GI),c&&t(imo),c&&t(qr),w(OI),w(XI),w(o9),w(zI),w(m9),c&&t(dmo),c&&t(jf),w(QI),c&&t(mmo),c&&t(jr),w(WI),w(HI),w(f9),w(JI),w(T9),c&&t(cmo),c&&t(Of),w(YI),c&&t(fmo),c&&t(Dr),w(ZI),w(eN),w(E9),w(oN),w(w9),c&&t(gmo),c&&t(zf),w(rN),c&&t(hmo),c&&t(Gr),w(tN),w(nN),w(L9),w(sN),w($9),c&&t(umo),c&&t(Uf),w(iN),c&&t(pmo),c&&t(Or),w(dN),w(cN),w(S9),w(fN),w(P9)}}}const YSa={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoImageProcessor",title:"AutoImageProcessor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForDepthEstimation",title:"AutoModelForDepthEstimation"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForDocumentQuestionAnswering",title:"AutoModelForDocumentQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.AutoModelForZeroShotObjectDetection",title:"AutoModelForZeroShotObjectDetection"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForSemanticSegmentation",title:"TFAutoModelForSemanticSegmentation"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForDocumentQuestionAnswering",title:"TFAutoModelForDocumentQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function ZSa($){return I$a(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class nRa extends S$a{constructor(g){super();R$a(this,g,ZSa,JSa,P$a,{})}}export{nRa as default,YSa as metadata};
